1
00:00:00,000 --> 00:00:02,158
No último capítulo, você e eu começamos a examinar 

2
00:00:02,158 --> 00:00:04,019
o funcionamento interno de um transformador.

3
00:00:04,560 --> 00:00:07,502
Esta é uma das principais peças de tecnologia dentro de grandes modelos 

4
00:00:07,502 --> 00:00:10,200
de linguagem e de muitas outras ferramentas na onda moderna de IA.

5
00:00:10,980 --> 00:00:14,382
Ele apareceu pela primeira vez em um artigo agora famoso de 2017 chamado 

6
00:00:14,382 --> 00:00:18,157
Atenção é tudo que você precisa, e neste capítulo você e eu vamos nos aprofundar 

7
00:00:18,157 --> 00:00:21,700
no que é esse mecanismo de atenção, visualizando como ele processa os dados.

8
00:00:26,140 --> 00:00:27,946
Para recapitular rapidamente, aqui está o contexto 

9
00:00:27,946 --> 00:00:29,540
importante que quero que você tenha em mente.

10
00:00:30,000 --> 00:00:32,873
O objetivo do modelo que você e eu estamos estudando é 

11
00:00:32,873 --> 00:00:36,060
pegar um trecho de texto e prever qual palavra virá a seguir.

12
00:00:36,860 --> 00:00:40,546
O texto de entrada é dividido em pequenos pedaços que chamamos de tokens, 

13
00:00:40,546 --> 00:00:43,137
e muitas vezes são palavras ou pedaços de palavras, 

14
00:00:43,137 --> 00:00:47,172
mas apenas para tornar os exemplos deste vídeo mais fáceis para você e para mim, 

15
00:00:47,172 --> 00:00:50,560
vamos simplificar fingindo que os tokens são sempre apenas palavras.

16
00:00:51,480 --> 00:00:56,079
O primeiro passo em um transformador é associar cada token a um vetor de alta dimensão, 

17
00:00:56,079 --> 00:00:57,700
o que chamamos de incorporação.

18
00:00:57,700 --> 00:01:00,683
A ideia mais importante que quero que você tenha em mente é 

19
00:01:00,683 --> 00:01:03,618
como as direções neste espaço de alta dimensão de todas as 

20
00:01:03,618 --> 00:01:07,000
incorporações possíveis podem corresponder ao significado semântico.

21
00:01:07,680 --> 00:01:11,557
No último capítulo vimos um exemplo de como a direção pode corresponder ao gênero, 

22
00:01:11,557 --> 00:01:15,201
no sentido de que adicionar um determinado passo neste espaço pode levá-lo da 

23
00:01:15,201 --> 00:01:18,939
incorporação de um substantivo masculino à incorporação do substantivo feminino 

24
00:01:18,939 --> 00:01:19,640
correspondente.

25
00:01:20,160 --> 00:01:23,807
Esse é apenas um exemplo: você poderia imaginar quantas outras direções neste espaço de 

26
00:01:23,807 --> 00:01:27,248
alta dimensão poderiam corresponder a vários outros aspectos do significado de uma 

27
00:01:27,248 --> 00:01:27,580
palavra.

28
00:01:28,800 --> 00:01:31,904
O objetivo de um transformador é ajustar progressivamente essas 

29
00:01:31,904 --> 00:01:35,493
incorporações para que elas não apenas codifiquem uma palavra individual, 

30
00:01:35,493 --> 00:01:39,180
mas, em vez disso, incluam um significado contextual muito, muito mais rico.

31
00:01:40,140 --> 00:01:43,189
Devo dizer desde já que muitas pessoas acham o mecanismo de atenção, 

32
00:01:43,189 --> 00:01:45,488
essa peça-chave de um transformador, muito confuso, 

33
00:01:45,488 --> 00:01:48,980
então não se preocupe se levar algum tempo para que as coisas sejam absorvidas.

34
00:01:49,440 --> 00:01:52,504
Acho que antes de mergulharmos nos detalhes computacionais e em 

35
00:01:52,504 --> 00:01:55,664
todas as multiplicações de matrizes, vale a pena pensar em alguns 

36
00:01:55,664 --> 00:01:59,160
exemplos do tipo de comportamento que queremos que a atenção possibilite.

37
00:02:00,140 --> 00:02:02,908
Considere as frases toupeira verdadeira americana, 

38
00:02:02,908 --> 00:02:06,220
um mol de dióxido de carbono, e faça uma biópsia da toupeira.

39
00:02:06,700 --> 00:02:10,083
Você e eu sabemos que a palavra toupeira tem significados diferentes em cada um deles, 

40
00:02:10,083 --> 00:02:10,900
com base no contexto.

41
00:02:11,360 --> 00:02:13,908
Mas após a primeira etapa de um transformador, 

42
00:02:13,908 --> 00:02:17,108
aquele que divide o texto e associa cada token a um vetor, 

43
00:02:17,108 --> 00:02:20,417
o vetor associado ao mol seria o mesmo em todos esses casos, 

44
00:02:20,417 --> 00:02:24,104
porque essa incorporação inicial do token é efetivamente uma tabela 

45
00:02:24,104 --> 00:02:26,220
de consulta sem referência ao contexto.

46
00:02:26,620 --> 00:02:29,968
É somente na próxima etapa do transformador que os embeddings 

47
00:02:29,968 --> 00:02:33,100
circundantes têm a chance de passar informações para este.

48
00:02:33,820 --> 00:02:38,174
A imagem que você pode ter em mente é que existem múltiplas direções distintas neste 

49
00:02:38,174 --> 00:02:42,425
espaço de incorporação, codificando os múltiplos significados distintos da palavra 

50
00:02:42,425 --> 00:02:46,831
toupeira, e que um bloco de atenção bem treinado calcula o que você precisa adicionar 

51
00:02:46,831 --> 00:02:50,673
à incorporação genérica para movê-la para uma dessas direções específicas, 

52
00:02:50,673 --> 00:02:51,800
em função do contexto.

53
00:02:53,300 --> 00:02:56,180
Para dar outro exemplo, considere a incorporação da palavra torre.

54
00:02:57,060 --> 00:03:00,986
Presumivelmente, esta é uma direção muito genérica e não específica no espaço, 

55
00:03:00,986 --> 00:03:03,720
associada a muitos outros substantivos grandes e altos.

56
00:03:04,020 --> 00:03:06,957
Se esta palavra fosse imediatamente precedida por Eiffel, 

57
00:03:06,957 --> 00:03:10,653
você poderia imaginar querer que o mecanismo atualizasse esse vetor para 

58
00:03:10,653 --> 00:03:14,755
que ele aponte em uma direção que codifique mais especificamente a Torre Eiffel, 

59
00:03:14,755 --> 00:03:19,060
talvez correlacionada com vetores associados a Paris e França e coisas feitas de aço.

60
00:03:19,920 --> 00:03:22,288
Se também fosse precedido pela palavra miniatura, 

61
00:03:22,288 --> 00:03:24,610
então o vetor deveria ser atualizado ainda mais, 

62
00:03:24,610 --> 00:03:27,500
para que não se correlacione mais com coisas grandes e altas.

63
00:03:29,480 --> 00:03:32,753
De forma mais geral do que apenas refinar o significado de uma palavra, 

64
00:03:32,753 --> 00:03:36,208
o bloco de atenção permite que o modelo mova informações codificadas em uma 

65
00:03:36,208 --> 00:03:39,663
incorporação para outra, potencialmente aquelas que estão muito distantes e 

66
00:03:39,663 --> 00:03:43,300
potencialmente com informações muito mais ricas do que apenas uma única palavra.

67
00:03:43,300 --> 00:03:48,451
O que vimos no último capítulo foi como, depois de todos os vetores fluírem pela rede, 

68
00:03:48,451 --> 00:03:51,234
incluindo muitos blocos de atenção diferentes, 

69
00:03:51,234 --> 00:03:56,148
o cálculo realizado para produzir uma previsão do próximo token é inteiramente uma 

70
00:03:56,148 --> 00:03:58,280
função do último vetor na sequência.

71
00:03:59,100 --> 00:04:03,347
Imagine, por exemplo, que o texto que você insere é a maior parte de um romance de 

72
00:04:03,347 --> 00:04:07,800
mistério inteiro, até um ponto próximo ao final, onde se lê: portanto, o assassino foi.

73
00:04:08,400 --> 00:04:12,461
Se o modelo for prever com precisão a próxima palavra, o vetor final da sequência, 

74
00:04:12,461 --> 00:04:15,496
que começou sua vida simplesmente incorporando a palavra was, 

75
00:04:15,496 --> 00:04:19,606
terá que ter sido atualizado por todos os blocos de atenção para representar muito, 

76
00:04:19,606 --> 00:04:21,906
muito mais do que qualquer indivíduo. palavra, 

77
00:04:21,906 --> 00:04:25,822
codificando de alguma forma todas as informações da janela de contexto completa 

78
00:04:25,822 --> 00:04:28,220
que são relevantes para prever a próxima palavra.

79
00:04:29,500 --> 00:04:32,580
Para avançar nos cálculos, porém, vamos dar um exemplo muito mais simples.

80
00:04:32,980 --> 00:04:35,710
Imagine que a entrada inclui a frase, uma criatura 

81
00:04:35,710 --> 00:04:37,960
azul fofa vagava pela floresta verdejante.

82
00:04:38,460 --> 00:04:42,547
E, por enquanto, suponha que o único tipo de atualização com o qual nos importamos é 

83
00:04:42,547 --> 00:04:46,780
fazer com que os adjetivos ajustem os significados de seus substantivos correspondentes.

84
00:04:47,000 --> 00:04:50,722
O que estou prestes a descrever é o que chamaríamos de uma única cabeça de atenção, 

85
00:04:50,722 --> 00:04:53,558
e mais tarde veremos como o bloco de atenção consiste em muitas 

86
00:04:53,558 --> 00:04:55,420
cabeças diferentes que correm em paralelo.

87
00:04:56,140 --> 00:04:59,899
Novamente, a incorporação inicial de cada palavra é algum vetor de alta dimensão 

88
00:04:59,899 --> 00:05:03,380
que codifica apenas o significado daquela palavra específica, sem contexto.

89
00:05:04,000 --> 00:05:05,220
Na verdade, isso não é bem verdade.

90
00:05:05,380 --> 00:05:07,640
Eles também codificam a posição da palavra.

91
00:05:07,980 --> 00:05:11,518
Há muito mais a dizer sobre a forma como as posições são codificadas, 

92
00:05:11,518 --> 00:05:15,108
mas agora, tudo o que você precisa saber é que as entradas desse vetor 

93
00:05:15,108 --> 00:05:18,900
são suficientes para dizer o que é a palavra e onde ela existe no contexto.

94
00:05:19,500 --> 00:05:21,660
Vamos em frente e denotaremos esses embeddings com a letra e.

95
00:05:22,420 --> 00:05:26,206
O objetivo é fazer com que uma série de cálculos produza um novo conjunto 

96
00:05:26,206 --> 00:05:29,787
refinado de embeddings onde, por exemplo, aqueles correspondentes aos 

97
00:05:29,787 --> 00:05:33,420
substantivos ingeriram o significado de seus adjetivos correspondentes.

98
00:05:33,900 --> 00:05:37,260
E jogando o jogo do aprendizado profundo, queremos que a maioria dos cálculos 

99
00:05:37,260 --> 00:05:39,672
envolvidos se pareçam com produtos de matrizes-vetores, 

100
00:05:39,672 --> 00:05:41,869
onde as matrizes estão cheias de pesos ajustáveis, 

101
00:05:41,869 --> 00:05:43,980
coisas que o modelo aprenderá com base nos dados.

102
00:05:44,660 --> 00:05:47,083
Para ser claro, estou inventando este exemplo de adjetivos 

103
00:05:47,083 --> 00:05:49,384
atualizando substantivos apenas para ilustrar o tipo de 

104
00:05:49,384 --> 00:05:52,260
comportamento que você poderia imaginar uma cabeça de atenção fazendo.

105
00:05:52,860 --> 00:05:54,787
Tal como acontece com tanto aprendizado profundo, 

106
00:05:54,787 --> 00:05:57,485
o verdadeiro comportamento é muito mais difícil de analisar porque se 

107
00:05:57,485 --> 00:06:00,453
baseia em ajustes e ajustes de um grande número de parâmetros para minimizar 

108
00:06:00,453 --> 00:06:01,340
alguma função de custo.

109
00:06:01,680 --> 00:06:05,479
Acontece que, à medida que percorremos todas as diferentes matrizes preenchidas 

110
00:06:05,479 --> 00:06:09,420
com parâmetros envolvidos neste processo, acho que é realmente útil ter um exemplo 

111
00:06:09,420 --> 00:06:13,220
imaginado de algo que poderia ser feito para ajudar a manter tudo mais concreto.

112
00:06:14,140 --> 00:06:18,102
Para a primeira etapa deste processo, você pode imaginar cada substantivo, 

113
00:06:18,102 --> 00:06:21,960
como criatura, fazendo a pergunta: ei, há algum adjetivo na minha frente?

114
00:06:22,160 --> 00:06:25,671
E para as palavras fofo e azul, para que cada um possa responder, 

115
00:06:25,671 --> 00:06:27,960
sim, sou um adjetivo e estou nessa posição.

116
00:06:28,960 --> 00:06:32,585
Essa questão está de alguma forma codificada como mais um vetor, 

117
00:06:32,585 --> 00:06:36,100
outra lista de números, que chamamos de consulta desta palavra.

118
00:06:36,980 --> 00:06:41,421
Este vetor de consulta, porém, tem uma dimensão muito menor que o vetor de incorporação, 

119
00:06:41,421 --> 00:06:42,020
digamos 128.

120
00:06:42,940 --> 00:06:46,508
Calcular esta consulta parece pegar uma determinada matriz, 

121
00:06:46,508 --> 00:06:49,780
que rotularei de wq, e multiplicá-la pela incorporação.

122
00:06:50,960 --> 00:06:54,973
Comprimindo um pouco as coisas, vamos escrever esse vetor de consulta como q, 

123
00:06:54,973 --> 00:06:59,243
e então sempre que você me ver colocando uma matriz ao lado de uma seta como esta, 

124
00:06:59,243 --> 00:07:03,873
ela significa que multiplicar essa matriz pelo vetor no início da seta fornece o vetor em 

125
00:07:03,873 --> 00:07:04,800
a ponta da flecha.

126
00:07:05,860 --> 00:07:09,999
Nesse caso, você multiplica essa matriz por todos os embeddings no contexto, 

127
00:07:09,999 --> 00:07:12,580
produzindo um vetor de consulta para cada token.

128
00:07:13,740 --> 00:07:15,938
As entradas desta matriz são parâmetros do modelo, 

129
00:07:15,938 --> 00:07:19,430
o que significa que o verdadeiro comportamento é aprendido a partir dos dados e, 

130
00:07:19,430 --> 00:07:22,577
na prática, o que esta matriz faz em uma determinada cabeça de atenção é 

131
00:07:22,577 --> 00:07:23,440
difícil de analisar.

132
00:07:23,900 --> 00:07:27,409
Mas, para nosso bem, imaginando um exemplo que esperamos que aprenda, 

133
00:07:27,409 --> 00:07:30,619
vamos supor que esta matriz de consulta mapeia os embeddings de 

134
00:07:30,619 --> 00:07:34,078
substantivos para certas direções neste espaço de consulta menor que 

135
00:07:34,078 --> 00:07:38,040
de alguma forma codifica a noção de procurar adjetivos em posições anteriores .

136
00:07:38,780 --> 00:07:41,440
Quanto ao que isso faz com outras incorporações, quem sabe?

137
00:07:41,720 --> 00:07:44,340
Talvez tente simultaneamente atingir algum outro objetivo com eles.

138
00:07:44,540 --> 00:07:47,160
No momento, estamos focados nos substantivos.

139
00:07:47,280 --> 00:07:51,639
Ao mesmo tempo, associada a isso está uma segunda matriz chamada matriz chave, 

140
00:07:51,639 --> 00:07:54,620
que você também multiplica por cada um dos embeddings.

141
00:07:55,280 --> 00:07:58,500
Isto produz uma segunda sequência de vetores que chamamos de chaves.

142
00:07:59,420 --> 00:08:01,320
Conceitualmente, você deseja pensar nas chaves 

143
00:08:01,320 --> 00:08:03,140
como potencialmente respondendo às perguntas.

144
00:08:03,840 --> 00:08:06,757
Essa matriz chave também está repleta de parâmetros ajustáveis e, 

145
00:08:06,757 --> 00:08:10,604
assim como a matriz de consulta, mapeia os vetores de incorporação para o mesmo espaço 

146
00:08:10,604 --> 00:08:11,400
dimensional menor.

147
00:08:12,200 --> 00:08:14,824
Você pensa nas chaves como correspondendo às consultas 

148
00:08:14,824 --> 00:08:17,020
sempre que elas se alinham umas com as outras.

149
00:08:17,460 --> 00:08:20,519
Em nosso exemplo, você imaginaria que a matriz chave mapeia 

150
00:08:20,519 --> 00:08:23,833
os adjetivos como fofo e azul para vetores que estão intimamente 

151
00:08:23,833 --> 00:08:26,740
alinhados com a consulta produzida pela palavra criatura.

152
00:08:27,200 --> 00:08:30,300
Para medir o quão bem cada chave corresponde a cada consulta, 

153
00:08:30,300 --> 00:08:34,000
você calcula um produto escalar entre cada par de consulta-chave possível.

154
00:08:34,480 --> 00:08:36,767
Gosto de visualizar uma grade cheia de pontos, 

155
00:08:36,767 --> 00:08:40,077
onde os pontos maiores correspondem aos produtos escalares maiores, 

156
00:08:40,077 --> 00:08:42,559
os locais onde as chaves e as consultas se alinham.

157
00:08:43,280 --> 00:08:47,673
Para nosso exemplo de adjetivo e substantivo, seria um pouco mais parecido com isto, 

158
00:08:47,673 --> 00:08:51,084
onde se as chaves produzidas por fofo e azul realmente se alinham 

159
00:08:51,084 --> 00:08:53,823
estreitamente com a consulta produzida por criatura, 

160
00:08:53,823 --> 00:08:58,320
então os produtos escalares nesses dois pontos seriam alguns grandes números positivos.

161
00:08:59,100 --> 00:09:02,282
No jargão, o pessoal do aprendizado de máquina diria que isso significa 

162
00:09:02,282 --> 00:09:05,420
que as incorporações de fofo e azul atendem à incorporação da criatura.

163
00:09:06,040 --> 00:09:09,613
Em contraste com o produto escalar entre a chave para alguma outra 

164
00:09:09,613 --> 00:09:12,973
palavra como o e a consulta para criatura, haveria algum valor 

165
00:09:12,973 --> 00:09:16,600
pequeno ou negativo que reflete que não estão relacionados entre si.

166
00:09:17,700 --> 00:09:21,244
Portanto, temos esta grelha de valores que pode ser qualquer número real 

167
00:09:21,244 --> 00:09:24,935
desde infinito negativo até infinito, dando-nos uma pontuação da relevância 

168
00:09:24,935 --> 00:09:28,480
de cada palavra para atualizar o significado de todas as outras palavras.

169
00:09:29,200 --> 00:09:32,296
A maneira como usaremos essas pontuações é calcular uma 

170
00:09:32,296 --> 00:09:35,780
certa soma ponderada em cada coluna, ponderada pela relevância.

171
00:09:36,520 --> 00:09:40,351
Então, em vez de os valores variarem de infinito negativo a infinito, 

172
00:09:40,351 --> 00:09:44,074
o que queremos é que os números nessas colunas estejam entre 0 e 1, 

173
00:09:44,074 --> 00:09:48,180
e que cada coluna some 1, como se fossem uma distribuição de probabilidade.

174
00:09:49,280 --> 00:09:52,220
Se você está vindo do último capítulo, sabe o que precisamos fazer então.

175
00:09:52,620 --> 00:09:57,300
Calculamos um softmax ao longo de cada uma dessas colunas para normalizar os valores.

176
00:10:00,060 --> 00:10:03,210
Na nossa imagem, depois de aplicar softmax a todas as colunas, 

177
00:10:03,210 --> 00:10:05,860
preencheremos a grade com esses valores normalizados.

178
00:10:06,780 --> 00:10:10,601
Neste ponto, você pode pensar em cada coluna dando pesos de acordo com a 

179
00:10:10,601 --> 00:10:14,580
relevância da palavra à esquerda em relação ao valor correspondente no topo.

180
00:10:15,080 --> 00:10:16,840
Chamamos essa grade de padrão de atenção.

181
00:10:18,080 --> 00:10:20,530
Agora, se você olhar para o papel original do transformador, 

182
00:10:20,530 --> 00:10:22,820
há uma maneira bem compacta de eles escreverem tudo isso.

183
00:10:23,880 --> 00:10:27,499
Aqui, as variáveis q e k representam as matrizes completas dos vetores de 

184
00:10:27,499 --> 00:10:31,020
consulta e de chave, respectivamente, aqueles pequenos vetores que você 

185
00:10:31,020 --> 00:10:34,640
obtém multiplicando os embeddings pela consulta e pelas matrizes de chave.

186
00:10:35,160 --> 00:10:38,964
Esta expressão no numerador é uma forma realmente compacta de representar a 

187
00:10:38,964 --> 00:10:43,020
grade de todos os produtos escalares possíveis entre pares de chaves e consultas.

188
00:10:44,000 --> 00:10:48,501
Um pequeno detalhe técnico que não mencionei é que, para estabilidade numérica, 

189
00:10:48,501 --> 00:10:53,115
é útil dividir todos esses valores pela raiz quadrada da dimensão nesse espaço de 

190
00:10:53,115 --> 00:10:53,960
consulta chave.

191
00:10:54,480 --> 00:10:57,700
Então, esse softmax que envolve a expressão completa 

192
00:10:57,700 --> 00:11:00,800
deve ser entendido como aplicado coluna por coluna.

193
00:11:01,640 --> 00:11:04,700
Quanto ao termo v, falaremos sobre isso em um segundo.

194
00:11:05,020 --> 00:11:08,460
Antes disso, há outro detalhe técnico que até agora pulei.

195
00:11:09,040 --> 00:11:12,922
Durante o processo de treinamento, quando você executa este modelo em um determinado 

196
00:11:12,922 --> 00:11:16,531
exemplo de texto, e todos os pesos são ligeiramente ajustados e ajustados para 

197
00:11:16,531 --> 00:11:20,414
recompensá-lo ou puni-lo com base na probabilidade elevada que ele atribui à próxima 

198
00:11:20,414 --> 00:11:24,159
palavra verdadeira na passagem, ele acaba tornando todo o processo de treinamento 

199
00:11:24,159 --> 00:11:27,814
muito mais eficiente se você fizer com que ele preveja simultaneamente todos os 

200
00:11:27,814 --> 00:11:31,560
próximos tokens possíveis após cada subsequência inicial de tokens nesta passagem.

201
00:11:31,940 --> 00:11:35,408
Por exemplo, com a frase que estamos focando, ela também pode 

202
00:11:35,408 --> 00:11:39,100
prever quais palavras seguem a criatura e quais palavras seguem a.

203
00:11:39,940 --> 00:11:42,750
Isso é muito bom, porque significa que o que de outra forma seria 

204
00:11:42,750 --> 00:11:45,560
um único exemplo de treinamento efetivamente funciona como muitos.

205
00:11:46,100 --> 00:11:48,149
Para os propósitos do nosso padrão de atenção, 

206
00:11:48,149 --> 00:11:51,680
isso significa que você nunca deve permitir que palavras posteriores influenciem 

207
00:11:51,680 --> 00:11:54,993
palavras anteriores, pois, caso contrário, elas poderiam revelar a resposta 

208
00:11:54,993 --> 00:11:56,040
para o que vem a seguir.

209
00:11:56,560 --> 00:11:59,463
O que isso significa é que queremos que todos esses pontos aqui, 

210
00:11:59,463 --> 00:12:02,902
aqueles que representam os tokens posteriores que influenciam os anteriores, 

211
00:12:02,902 --> 00:12:04,600
sejam de alguma forma forçados a zero.

212
00:12:05,920 --> 00:12:09,013
A coisa mais simples que você pode pensar em fazer é defini-los iguais a zero, 

213
00:12:09,013 --> 00:12:12,420
mas se você fizesse isso as colunas não somariam mais um, elas não seriam normalizadas.

214
00:12:13,120 --> 00:12:16,608
Então, em vez disso, uma maneira comum de fazer isso é antes de aplicar softmax, 

215
00:12:16,608 --> 00:12:19,020
você define todas essas entradas como infinito negativo.

216
00:12:19,680 --> 00:12:21,835
Se você fizer isso, depois de aplicar o softmax, 

217
00:12:21,835 --> 00:12:25,180
todos serão transformados em zero, mas as colunas permanecerão normalizadas.

218
00:12:26,000 --> 00:12:27,540
Este processo é chamado de mascaramento.

219
00:12:27,540 --> 00:12:30,951
Existem versões de atenção onde você não aplica, mas em nosso exemplo GPT, 

220
00:12:30,951 --> 00:12:34,545
mesmo que isso seja mais relevante durante a fase de treinamento do que seria, 

221
00:12:34,545 --> 00:12:37,001
digamos, executá-lo como um chatbot ou algo parecido, 

222
00:12:37,001 --> 00:12:40,277
você sempre aplica esse mascaramento para evitar que tokens posteriores 

223
00:12:40,277 --> 00:12:41,460
influenciem os anteriores.

224
00:12:42,480 --> 00:12:46,072
Outro fato que vale a pena refletir sobre esse padrão de atenção 

225
00:12:46,072 --> 00:12:49,500
é como seu tamanho é igual ao quadrado do tamanho do contexto.

226
00:12:49,900 --> 00:12:52,805
É por isso que o tamanho do contexto pode ser um grande gargalo 

227
00:12:52,805 --> 00:12:55,620
para modelos de linguagem grandes, e aumentá-lo não é trivial.

228
00:12:56,300 --> 00:13:00,259
Como você imagina, motivado por um desejo por janelas de contexto cada vez maiores, 

229
00:13:00,259 --> 00:13:04,407
nos últimos anos assistimos a algumas variações no mecanismo de atenção que visa tornar 

230
00:13:04,407 --> 00:13:08,320
o contexto mais escalável, mas aqui mesmo, você e eu continuamos focados no básico.

231
00:13:10,560 --> 00:13:13,083
Ok, ótimo, calcular esse padrão permite que o modelo deduza 

232
00:13:13,083 --> 00:13:15,480
quais palavras são relevantes para quais outras palavras.

233
00:13:16,020 --> 00:13:18,280
Agora você precisa realmente atualizar os embeddings, 

234
00:13:18,280 --> 00:13:21,711
permitindo que as palavras passem informações para quaisquer outras palavras para 

235
00:13:21,711 --> 00:13:22,800
as quais sejam relevantes.

236
00:13:22,800 --> 00:13:26,690
Por exemplo, você deseja que a incorporação de Fluffy cause de alguma forma uma 

237
00:13:26,690 --> 00:13:30,289
alteração na Criatura que a mova para uma parte diferente deste espaço de 

238
00:13:30,289 --> 00:13:34,520
incorporação de 12.000 dimensões que codifica mais especificamente uma criatura Fluffy.

239
00:13:35,460 --> 00:13:39,104
O que vou fazer aqui é primeiro mostrar a maneira mais direta de fazer isso, 

240
00:13:39,104 --> 00:13:42,797
embora haja uma pequena maneira de isso ser modificado no contexto da atenção 

241
00:13:42,797 --> 00:13:43,460
multifacetada.

242
00:13:44,080 --> 00:13:46,751
A maneira mais direta seria usar uma terceira matriz, 

243
00:13:46,751 --> 00:13:51,054
o que chamamos de matriz de valores, que você multiplica pela incorporação da primeira 

244
00:13:51,054 --> 00:13:52,440
palavra, por exemplo Fluffy.

245
00:13:53,300 --> 00:13:56,005
O resultado disso é o que você chamaria de vetor de valor, 

246
00:13:56,005 --> 00:13:59,077
e isso é algo que você adiciona à incorporação da segunda palavra, 

247
00:13:59,077 --> 00:14:01,920
neste caso, algo que você adiciona à incorporação da Criatura.

248
00:14:02,600 --> 00:14:05,039
Portanto, esse vetor de valor vive no mesmo espaço 

249
00:14:05,039 --> 00:14:07,000
de dimensão muito alta que os embeddings.

250
00:14:07,460 --> 00:14:11,445
Quando você multiplica essa matriz de valores pela incorporação de uma palavra, 

251
00:14:11,445 --> 00:14:14,683
você pode pensar nisso como se esta palavra fosse relevante para 

252
00:14:14,683 --> 00:14:18,021
ajustar o significado de outra coisa, o que exatamente deveria ser 

253
00:14:18,021 --> 00:14:21,160
adicionado à incorporação dessa outra coisa para refletir esse?

254
00:14:22,140 --> 00:14:26,288
Olhando para trás em nosso diagrama, vamos deixar de lado todas as chaves e as consultas, 

255
00:14:26,288 --> 00:14:29,514
já que depois de calcular o padrão de atenção você terminou com elas, 

256
00:14:29,514 --> 00:14:32,879
então você vai pegar essa matriz de valores e multiplicá-la por cada uma 

257
00:14:32,879 --> 00:14:36,060
dessas incorporações para produzir uma sequência de vetores de valor.

258
00:14:37,120 --> 00:14:39,141
Você pode pensar nesses vetores de valor como 

259
00:14:39,141 --> 00:14:41,120
estando associados às chaves correspondentes.

260
00:14:42,320 --> 00:14:45,720
Para cada coluna neste diagrama, você multiplica cada um 

261
00:14:45,720 --> 00:14:49,240
dos vetores de valor pelo peso correspondente nessa coluna.

262
00:14:50,080 --> 00:14:52,691
Por exemplo, aqui, na incorporação de Creature, 

263
00:14:52,691 --> 00:14:56,880
você adicionaria grandes proporções dos vetores de valor para Fluffy e Blue, 

264
00:14:56,880 --> 00:15:01,560
enquanto todos os outros vetores de valor seriam zerados, ou pelo menos quase zerados.

265
00:15:02,120 --> 00:15:06,216
E finalmente, a maneira de realmente atualizar a incorporação associada a esta coluna, 

266
00:15:06,216 --> 00:15:09,654
previamente codificando algum significado livre de contexto de Criatura, 

267
00:15:09,654 --> 00:15:12,526
você adiciona todos esses valores redimensionados na coluna, 

268
00:15:12,526 --> 00:15:15,587
produzindo uma alteração que você deseja adicionar, que eu &#39; 

269
00:15:15,587 --> 00:15:19,260
rotularemos delta-e e, em seguida, adicionaremos isso à incorporação original.

270
00:15:19,680 --> 00:15:23,041
Esperançosamente, o resultado é um vetor mais refinado que codifica o 

271
00:15:23,041 --> 00:15:26,500
significado mais contextualmente rico, como o de uma criatura azul fofa.

272
00:15:27,380 --> 00:15:30,330
E é claro que você não faz isso apenas em uma incorporação, 

273
00:15:30,330 --> 00:15:33,723
você aplica a mesma soma ponderada em todas as colunas desta imagem, 

274
00:15:33,723 --> 00:15:37,559
produzindo uma sequência de alterações, adicionando todas essas alterações às 

275
00:15:37,559 --> 00:15:41,640
incorporações correspondentes, produz uma sequência completa de incorporações mais 

276
00:15:41,640 --> 00:15:43,460
refinadas saindo do bloco de atenção.

277
00:15:44,860 --> 00:15:46,891
Diminuindo o zoom, todo esse processo é o que 

278
00:15:46,891 --> 00:15:49,100
você descreveria como uma única cabeça de atenção.

279
00:15:49,600 --> 00:15:54,534
Como descrevi até agora, esse processo é parametrizado por três matrizes distintas, 

280
00:15:54,534 --> 00:15:58,940
todas preenchidas com parâmetros ajustáveis, a chave, a consulta e o valor.

281
00:15:59,500 --> 00:16:03,355
Quero reservar um momento para continuar o que começamos no capítulo anterior, 

282
00:16:03,355 --> 00:16:07,600
com a pontuação onde contamos o número total de parâmetros do modelo usando os números 

283
00:16:07,600 --> 00:16:08,040
do GPT-3.

284
00:16:09,300 --> 00:16:12,967
Cada uma dessas matrizes de chave e de consulta tem 12.288 colunas, 

285
00:16:12,967 --> 00:16:16,040
correspondendo à dimensão de incorporação, e 128 linhas, 

286
00:16:16,040 --> 00:16:19,600
correspondendo à dimensão desse espaço de consulta de chave menor.

287
00:16:20,260 --> 00:16:24,220
Isso nos dá cerca de 1,5 milhão de parâmetros adicionais para cada um.

288
00:16:24,860 --> 00:16:28,152
Se você olhar para essa matriz de valor, por outro lado, 

289
00:16:28,152 --> 00:16:32,254
a maneira como descrevi as coisas até agora sugeriria que é uma matriz 

290
00:16:32,254 --> 00:16:35,085
quadrada que tem 12.288 colunas e 12.288 linhas, 

291
00:16:35,085 --> 00:16:39,244
uma vez que tanto suas entradas quanto suas saídas residem neste espaço 

292
00:16:39,244 --> 00:16:40,920
de incorporação muito grande.

293
00:16:41,500 --> 00:16:45,140
Se for verdade, isso significaria cerca de 150 milhões de parâmetros adicionados.

294
00:16:45,660 --> 00:16:47,300
E para ser claro, você poderia fazer isso.

295
00:16:47,420 --> 00:16:49,376
Você poderia dedicar ordens de magnitude a mais 

296
00:16:49,376 --> 00:16:51,740
parâmetros ao mapa de valores do que à chave e à consulta.

297
00:16:52,060 --> 00:16:54,802
Mas, na prática, é muito mais eficiente se, em vez disso, 

298
00:16:54,802 --> 00:16:57,592
você fizer com que o número de parâmetros dedicados a esse 

299
00:16:57,592 --> 00:17:00,760
mapa de valores seja igual ao número dedicado à chave e à consulta.

300
00:17:01,460 --> 00:17:03,498
Isto é especialmente relevante no cenário de execução 

301
00:17:03,498 --> 00:17:05,160
de múltiplas cabeças de atenção em paralelo.

302
00:17:06,240 --> 00:17:08,416
A aparência disso é que o mapa de valores é fatorado 

303
00:17:08,416 --> 00:17:10,099
como um produto de duas matrizes menores.

304
00:17:11,180 --> 00:17:14,976
Conceitualmente, eu ainda encorajaria você a pensar no mapa linear geral, 

305
00:17:14,976 --> 00:17:19,131
um com entradas e saídas, ambos neste espaço de incorporação maior, por exemplo, 

306
00:17:19,131 --> 00:17:23,133
levando a incorporação do azul nesta direção de azul que você adicionaria aos 

307
00:17:23,133 --> 00:17:23,800
substantivos.

308
00:17:27,040 --> 00:17:29,981
Acontece que é um número menor de linhas, normalmente 

309
00:17:29,981 --> 00:17:32,760
do mesmo tamanho que o espaço de consulta da chave.

310
00:17:33,100 --> 00:17:35,813
O que isso significa é que você pode pensar nisso como mapear 

311
00:17:35,813 --> 00:17:38,440
os grandes vetores de incorporação em um espaço muito menor.

312
00:17:39,040 --> 00:17:40,970
Esta não é a nomenclatura convencional, mas vou 

313
00:17:40,970 --> 00:17:42,700
chamá-la de matriz de valores decrescentes.

314
00:17:43,400 --> 00:17:47,235
A segunda matriz mapeia esse espaço menor de volta ao espaço de incorporação, 

315
00:17:47,235 --> 00:17:50,580
produzindo os vetores que você usa para fazer as atualizações reais.

316
00:17:51,000 --> 00:17:54,740
Vou chamar esta de matriz de aumento de valor, o que novamente não é convencional.

317
00:17:55,160 --> 00:17:58,080
A maneira como você veria isso escrito na maioria dos artigos parece um pouco diferente.

318
00:17:58,380 --> 00:17:59,520
Falarei sobre isso em um minuto.

319
00:17:59,700 --> 00:18:02,540
Na minha opinião, isso tende a tornar as coisas um pouco mais confusas conceitualmente.

320
00:18:03,260 --> 00:18:06,777
Para usar o jargão da álgebra linear aqui, o que estamos basicamente fazendo 

321
00:18:06,777 --> 00:18:10,340
é restringir o mapa de valor geral a uma transformação de classificação baixa.

322
00:18:11,420 --> 00:18:16,211
Voltando à contagem de parâmetros, todas essas quatro matrizes têm o mesmo tamanho e, 

323
00:18:16,211 --> 00:18:20,780
somando-as, obtemos cerca de 6,3 milhões de parâmetros para uma cabeça de atenção.

324
00:18:22,040 --> 00:18:24,455
Como uma observação rápida, para ser um pouco mais preciso, 

325
00:18:24,455 --> 00:18:28,038
tudo o que foi descrito até agora é o que as pessoas chamariam de cabeça de autoatenção, 

326
00:18:28,038 --> 00:18:31,500
para distingui-la de uma variação que surge em outros modelos chamada atenção cruzada.

327
00:18:32,300 --> 00:18:36,242
Isso não é relevante para nosso exemplo GPT, mas se você estiver curioso, 

328
00:18:36,242 --> 00:18:40,450
a atenção cruzada envolve modelos que processam dois tipos distintos de dados, 

329
00:18:40,450 --> 00:18:44,552
como texto em um idioma e texto em outro idioma que faz parte de uma geração 

330
00:18:44,552 --> 00:18:49,240
contínua de uma tradução, ou talvez entrada de áudio de fala e uma transcrição contínua.

331
00:18:50,400 --> 00:18:52,700
Uma cabeça de atenção cruzada parece quase idêntica.

332
00:18:52,980 --> 00:18:55,166
A única diferença é que os mapas de chave e de 

333
00:18:55,166 --> 00:18:57,400
consulta atuam em conjuntos de dados diferentes.

334
00:18:57,840 --> 00:19:01,998
Num modelo que faz tradução, por exemplo, as chaves podem vir de um idioma, 

335
00:19:01,998 --> 00:19:05,993
enquanto as consultas vêm de outro, e o padrão de atenção pode descrever 

336
00:19:05,993 --> 00:19:09,660
quais palavras de um idioma correspondem a quais palavras de outro.

337
00:19:10,340 --> 00:19:12,731
E nesta configuração normalmente não haveria mascaramento, 

338
00:19:12,731 --> 00:19:16,340
uma vez que não há realmente qualquer noção de tokens posteriores afetando os anteriores.

339
00:19:17,180 --> 00:19:21,292
Porém, mantendo o foco na autoatenção, se você entendesse tudo até agora 

340
00:19:21,292 --> 00:19:25,180
e parasse por aqui, chegaria à essência do que realmente é a atenção.

341
00:19:25,760 --> 00:19:31,440
Tudo o que nos resta é definir o sentido em que você faz isso muitas vezes diferentes.

342
00:19:32,100 --> 00:19:35,437
Em nosso exemplo central, nos concentramos nos adjetivos que atualizam os substantivos, 

343
00:19:35,437 --> 00:19:38,055
mas é claro que há muitas maneiras diferentes pelas quais o contexto 

344
00:19:38,055 --> 00:19:39,800
pode influenciar o significado de uma palavra.

345
00:19:40,360 --> 00:19:43,242
Se as palavras bateram precederam a palavra carro, 

346
00:19:43,242 --> 00:19:46,520
isso tem implicações para a forma e estrutura desse carro.

347
00:19:47,200 --> 00:19:49,280
E muitas associações podem ser menos gramaticais.

348
00:19:49,760 --> 00:19:53,068
Se a palavra bruxo estiver em algum lugar na mesma passagem que Harry, 

349
00:19:53,068 --> 00:19:56,703
isso sugere que isso pode estar se referindo a Harry Potter, ao passo que se, 

350
00:19:56,703 --> 00:20:00,338
em vez disso, as palavras Rainha, Sussex e William estivessem nessa passagem, 

351
00:20:00,338 --> 00:20:04,440
então talvez a incorporação de Harry devesse ser atualizada para se referir ao príncipe.

352
00:20:05,040 --> 00:20:08,541
Para cada tipo diferente de atualização contextual que você possa imaginar, 

353
00:20:08,541 --> 00:20:12,043
os parâmetros dessas matrizes de chave e de consulta seriam diferentes para 

354
00:20:12,043 --> 00:20:15,545
capturar os diferentes padrões de atenção, e os parâmetros do nosso mapa de 

355
00:20:15,545 --> 00:20:19,140
valor seriam diferentes com base no que deveria ser adicionado aos embeddings.

356
00:20:19,980 --> 00:20:23,269
E, novamente, na prática, o verdadeiro comportamento desses mapas é muito mais 

357
00:20:23,269 --> 00:20:26,725
difícil de interpretar, onde os pesos são definidos para fazer tudo o que o modelo 

358
00:20:26,725 --> 00:20:30,140
precisa que eles façam para melhor cumprir seu objetivo de prever o próximo token.

359
00:20:31,400 --> 00:20:34,970
Como eu disse antes, tudo o que descrevemos é uma única cabeça de atenção, 

360
00:20:34,970 --> 00:20:38,493
e um bloco de atenção completo dentro de um transformador consiste no que 

361
00:20:38,493 --> 00:20:42,730
chamamos de atenção multicabeças, onde você executa muitas dessas operações em paralelo, 

362
00:20:42,730 --> 00:20:45,920
cada uma com sua própria consulta chave distinta. e mapas de valor.

363
00:20:47,420 --> 00:20:51,700
O GPT-3, por exemplo, usa 96 cabeças de atenção dentro de cada bloco.

364
00:20:52,020 --> 00:20:54,240
Considerando que cada um já é um pouco confuso, 

365
00:20:54,240 --> 00:20:56,460
certamente é muita coisa para guardar na cabeça.

366
00:20:56,760 --> 00:21:01,009
Apenas para explicar tudo explicitamente, isso significa que você tem 96 matrizes 

367
00:21:01,009 --> 00:21:05,000
de chave e de consulta distintas, produzindo 96 padrões de atenção distintos.

368
00:21:05,440 --> 00:21:08,538
Então, cada cabeça tem suas próprias matrizes de valores 

369
00:21:08,538 --> 00:21:12,180
distintas usadas para produzir 96 sequências de vetores de valores.

370
00:21:12,460 --> 00:21:16,680
Todos eles são somados usando os padrões de atenção correspondentes como pesos.

371
00:21:17,480 --> 00:21:21,340
O que isto significa é que para cada posição no contexto, cada token, 

372
00:21:21,340 --> 00:21:26,137
cada uma dessas cabeças produz uma proposta de mudança a ser adicionada à incorporação 

373
00:21:26,137 --> 00:21:27,020
naquela posição.

374
00:21:27,660 --> 00:21:32,052
Então o que você faz é somar todas as alterações propostas, uma para cada cabeça, 

375
00:21:32,052 --> 00:21:35,480
e adicionar o resultado à incorporação original daquela posição.

376
00:21:36,660 --> 00:21:40,376
Toda essa soma aqui seria uma fatia do que é produzido por esse 

377
00:21:40,376 --> 00:21:43,801
bloco de atenção com múltiplas cabeças, uma única daquelas 

378
00:21:43,801 --> 00:21:47,460
incorporações refinadas que aparecem na outra extremidade dele.

379
00:21:48,320 --> 00:21:50,269
Novamente, isso é muito em que pensar, então não 

380
00:21:50,269 --> 00:21:52,140
se preocupe se levar algum tempo para entender.

381
00:21:52,380 --> 00:21:55,889
A ideia geral é que, ao executar muitas cabeças distintas em paralelo, 

382
00:21:55,889 --> 00:21:59,200
você está dando ao modelo a capacidade de aprender muitas maneiras 

383
00:21:59,200 --> 00:22:01,820
distintas pelas quais o contexto muda de significado.

384
00:22:03,700 --> 00:22:07,205
Aumentando nossa contagem contínua de parâmetros com 96 cabeças, 

385
00:22:07,205 --> 00:22:10,657
cada uma incluindo sua própria variação dessas quatro matrizes, 

386
00:22:10,657 --> 00:22:15,080
cada bloco de atenção multicabeças termina com cerca de 600 milhões de parâmetros.

387
00:22:16,420 --> 00:22:19,236
Há uma coisa um pouco irritante que eu realmente deveria mencionar 

388
00:22:19,236 --> 00:22:21,800
para qualquer um de vocês que ler mais sobre transformadores.

389
00:22:22,080 --> 00:22:25,803
Você se lembra de como eu disse que o mapa de valores é fatorado nessas duas matrizes 

390
00:22:25,803 --> 00:22:29,440
distintas, que rotulei como matrizes de valor inferior e matrizes de valor superior.

391
00:22:29,960 --> 00:22:33,976
A maneira como enquadrei as coisas sugeriria que você visse esse par de 

392
00:22:33,976 --> 00:22:38,440
matrizes dentro de cada cabeça de atenção e poderia implementá-lo dessa maneira.

393
00:22:38,640 --> 00:22:39,920
Esse seria um design válido.

394
00:22:40,260 --> 00:22:42,513
Mas a maneira como você vê isso escrito nos documentos e a 

395
00:22:42,513 --> 00:22:44,920
forma como é implementado na prática parece um pouco diferente.

396
00:22:45,340 --> 00:22:48,745
Todas essas matrizes de aumento de valor para cada cabeça 

397
00:22:48,745 --> 00:22:53,150
aparecem grampeadas em uma matriz gigante que chamamos de matriz de saída, 

398
00:22:53,150 --> 00:22:56,380
associada a todo o bloco de atenção com várias cabeças.

399
00:22:56,820 --> 00:23:00,191
E quando você vê as pessoas se referindo à matriz de valores para uma determinada 

400
00:23:00,191 --> 00:23:03,686
cabeça de atenção, elas normalmente estão se referindo apenas a essa primeira etapa, 

401
00:23:03,686 --> 00:23:07,140
aquela que eu estava rotulando como a projeção descendente do valor no espaço menor.

402
00:23:08,340 --> 00:23:11,040
Para os curiosos, deixei uma nota na tela sobre isso.

403
00:23:11,260 --> 00:23:14,657
É um daqueles detalhes que corre o risco de desviar a atenção dos principais pontos 

404
00:23:14,657 --> 00:23:18,256
conceituais, mas quero destacá-lo apenas para que você saiba se leu sobre isso em outras 

405
00:23:18,256 --> 00:23:18,540
fontes.

406
00:23:19,240 --> 00:23:22,345
Deixando de lado todas as nuances técnicas, na prévia do capítulo 

407
00:23:22,345 --> 00:23:25,498
anterior vimos como os dados que fluem através de um transformador 

408
00:23:25,498 --> 00:23:28,040
não fluem apenas através de um único bloco de atenção.

409
00:23:28,640 --> 00:23:32,700
Por um lado, ele também passa por outras operações chamadas perceptrons multicamadas.

410
00:23:33,120 --> 00:23:34,880
Falaremos mais sobre eles no próximo capítulo.

411
00:23:35,180 --> 00:23:39,320
E então ele passa repetidamente por muitas cópias de ambas as operações.

412
00:23:39,980 --> 00:23:43,483
O que isto significa é que depois de uma determinada palavra absorver 

413
00:23:43,483 --> 00:23:46,886
parte do seu contexto, há muito mais hipóteses de esta incorporação 

414
00:23:46,886 --> 00:23:50,040
mais matizada ser influenciada pelo seu ambiente mais matizado.

415
00:23:50,940 --> 00:23:54,631
Quanto mais você avança na rede, com cada incorporação absorvendo cada vez mais 

416
00:23:54,631 --> 00:23:58,783
significado de todas as outras incorporações, que por sua vez estão ficando cada vez mais 

417
00:23:58,783 --> 00:24:02,798
matizadas, a esperança é que haja a capacidade de codificar ideias de nível superior e 

418
00:24:02,798 --> 00:24:06,812
mais abstratas sobre um determinado informações além de apenas descritores e estrutura 

419
00:24:06,812 --> 00:24:07,320
gramatical.

420
00:24:07,880 --> 00:24:11,391
Coisas como sentimento e tom e se é um poema e quais verdades 

421
00:24:11,391 --> 00:24:15,130
científicas subjacentes são relevantes para a peça e coisas assim.

422
00:24:16,700 --> 00:24:21,328
Voltando mais uma vez à nossa pontuação, o GPT-3 inclui 96 camadas distintas, 

423
00:24:21,328 --> 00:24:25,718
de modo que o número total de parâmetros principais de consulta e valor é 

424
00:24:25,718 --> 00:24:30,228
multiplicado por outros 96, o que eleva a soma total para pouco menos de 58 

425
00:24:30,228 --> 00:24:34,500
bilhões de parâmetros distintos dedicados a todos os cabeças de atenção.

426
00:24:34,980 --> 00:24:37,960
Isso é muito, com certeza, mas representa apenas cerca 

427
00:24:37,960 --> 00:24:40,940
de um terço dos 175 bilhões que estão na rede no total.

428
00:24:41,520 --> 00:24:44,419
Portanto, mesmo que a atenção receba toda a atenção, 

429
00:24:44,419 --> 00:24:48,140
a maioria dos parâmetros vem dos blocos situados entre essas etapas.

430
00:24:48,560 --> 00:24:51,180
No próximo capítulo, você e eu falaremos mais sobre esses outros 

431
00:24:51,180 --> 00:24:53,560
blocos e também muito mais sobre o processo de treinamento.

432
00:24:54,120 --> 00:24:57,550
Uma grande parte da história do sucesso do mecanismo de atenção não é 

433
00:24:57,550 --> 00:25:00,735
tanto qualquer tipo específico de comportamento que ele permite, 

434
00:25:00,735 --> 00:25:04,214
mas o fato de ser extremamente paralelizável, o que significa que você 

435
00:25:04,214 --> 00:25:08,380
pode executar um grande número de cálculos em um curto espaço de tempo usando GPUs. .

436
00:25:09,460 --> 00:25:13,326
Dado que uma das grandes lições sobre aprendizagem profunda nas últimas duas décadas foi 

437
00:25:13,326 --> 00:25:17,149
que a escala por si só parece proporcionar enormes melhorias qualitativas no desempenho 

438
00:25:17,149 --> 00:25:21,060
do modelo, há uma enorme vantagem nas arquiteturas paralelizáveis que permitem fazer isso.

439
00:25:22,040 --> 00:25:25,340
Se você quiser saber mais sobre essas coisas, deixei muitos links na descrição.

440
00:25:25,920 --> 00:25:28,131
Em particular, qualquer coisa produzida por Andrej 

441
00:25:28,131 --> 00:25:30,040
Karpathy ou Chris Ola tende a ser ouro puro.

442
00:25:30,560 --> 00:25:33,416
Neste vídeo, eu queria apenas chamar a atenção em sua forma atual, 

443
00:25:33,416 --> 00:25:36,230
mas se você está curioso para saber mais sobre a história de como 

444
00:25:36,230 --> 00:25:39,086
chegamos aqui e como você pode reinventar essa ideia por si mesmo, 

445
00:25:39,086 --> 00:25:42,540
meu amigo Vivek acabou de colocar alguns vídeos dando muito mais dessa motivação.

446
00:25:43,120 --> 00:25:45,425
Além disso, Britt Cruz, do canal The Art of the Problem, 

447
00:25:45,425 --> 00:25:48,460
tem um vídeo muito legal sobre a história dos grandes modelos de linguagem.

448
00:26:04,960 --> 00:26:09,200
Obrigado.

