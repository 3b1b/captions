1
00:00:00,000 --> 00:00:02,133
En el último capítulo, tú y yo empezamos a recorrer 

2
00:00:02,133 --> 00:00:04,019
el funcionamiento interno de un transformador.

3
00:00:04,560 --> 00:00:07,223
Se trata de una de las piezas clave de la tecnología de los grandes 

4
00:00:07,223 --> 00:00:10,200
modelos lingüísticos y de muchas otras herramientas de la moderna ola de IA.

5
00:00:10,980 --> 00:00:14,539
Apareció por primera vez en un artículo ya famoso de 2017 titulado Attention is All 

6
00:00:14,539 --> 00:00:16,615
You Need (La atención es todo lo que necesitas), 

7
00:00:16,615 --> 00:00:20,174
y en este capítulo tú y yo profundizaremos en lo que es este mecanismo de atención, 

8
00:00:20,174 --> 00:00:21,700
visualizando cómo procesa los datos.

9
00:00:26,140 --> 00:00:29,540
A modo de resumen rápido, éste es el contexto importante que quiero que tengas en mente.

10
00:00:30,000 --> 00:00:33,054
El objetivo del modelo que tú y yo estamos estudiando es tomar 

11
00:00:33,054 --> 00:00:36,060
un trozo de texto y predecir qué palabra viene a continuación.

12
00:00:36,860 --> 00:00:40,224
El texto de entrada se divide en pequeños trozos que llamamos tokens, 

13
00:00:40,224 --> 00:00:42,820
y que muy a menudo son palabras o trozos de palabras, 

14
00:00:42,820 --> 00:00:47,098
pero para que los ejemplos de este vídeo sean más fáciles de entender para ti y para mí, 

15
00:00:47,098 --> 00:00:50,560
vamos a simplificar suponiendo que los tokens son siempre sólo palabras.

16
00:00:51,480 --> 00:00:56,041
El primer paso de un transformador es asociar a cada token un vector de alta dimensión, 

17
00:00:56,041 --> 00:00:57,700
lo que llamamos su incrustación.

18
00:00:57,700 --> 00:01:00,769
La idea más importante que quiero que tengas en mente es cómo las 

19
00:01:00,769 --> 00:01:03,512
direcciones en este espacio de alta dimensión de todas las 

20
00:01:03,512 --> 00:01:07,000
incrustaciones posibles pueden corresponderse con el significado semántico.

21
00:01:07,680 --> 00:01:11,622
En el último capítulo vimos un ejemplo de cómo la dirección puede corresponder al género, 

22
00:01:11,622 --> 00:01:14,689
en el sentido de que añadir un determinado paso en este espacio puede 

23
00:01:14,689 --> 00:01:17,887
llevarte de la incrustación de un sustantivo masculino a la incrustación 

24
00:01:17,887 --> 00:01:19,640
del sustantivo femenino correspondiente.

25
00:01:20,160 --> 00:01:23,954
Ése es sólo un ejemplo, puedes imaginar cuántas otras direcciones en este espacio de alta 

26
00:01:23,954 --> 00:01:27,580
dimensión podrían corresponder a otros muchos aspectos del significado de una palabra.

27
00:01:28,800 --> 00:01:32,173
El objetivo de un transformador es ajustar progresivamente estas 

28
00:01:32,173 --> 00:01:36,014
incrustaciones para que no se limiten a codificar una palabra individual, 

29
00:01:36,014 --> 00:01:39,180
sino que incorporen un significado contextual mucho más rico.

30
00:01:40,140 --> 00:01:44,183
Debo decir de entrada que mucha gente encuentra muy confuso el mecanismo de atención, 

31
00:01:44,183 --> 00:01:47,099
esta pieza clave en un transformador, así que no te preocupes 

32
00:01:47,099 --> 00:01:48,980
si tardas un poco en asimilar las cosas.

33
00:01:49,440 --> 00:01:52,740
Creo que antes de sumergirnos en los detalles computacionales y en todas 

34
00:01:52,740 --> 00:01:55,859
las multiplicaciones de matrices, merece la pena pensar en un par de 

35
00:01:55,859 --> 00:01:59,160
ejemplos del tipo de comportamiento que queremos que permita la atención.

36
00:02:00,140 --> 00:02:02,835
Considera las frases topo verdadero americano, 

37
00:02:02,835 --> 00:02:06,220
un topo de dióxido de carbono, y toma una biopsia del topo.

38
00:02:06,700 --> 00:02:10,180
Tú y yo sabemos que la palabra topo tiene distintos significados en cada uno de ellos, 

39
00:02:10,180 --> 00:02:10,900
según el contexto.

40
00:02:11,360 --> 00:02:13,985
Pero después del primer paso de un transformador, 

41
00:02:13,985 --> 00:02:17,135
el que descompone el texto y asocia cada token a un vector, 

42
00:02:17,135 --> 00:02:20,549
el vector asociado al token sería el mismo en todos estos casos, 

43
00:02:20,549 --> 00:02:24,172
porque esta incrustación inicial de token es efectivamente una tabla 

44
00:02:24,172 --> 00:02:26,220
de búsqueda sin referencia al contexto.

45
00:02:26,620 --> 00:02:29,885
Sólo en el siguiente paso del transformador, las incrustaciones 

46
00:02:29,885 --> 00:02:33,100
circundantes tienen la oportunidad de pasar información a ésta.

47
00:02:33,820 --> 00:02:38,189
La imagen que puedes tener en mente es que hay múltiples direcciones distintas en este 

48
00:02:38,189 --> 00:02:42,609
espacio de incrustación que codifica los múltiples significados distintos de la palabra 

49
00:02:42,609 --> 00:02:46,827
topo, y que un bloque de atención bien entrenado calcula lo que hay que añadir a la 

50
00:02:46,827 --> 00:02:50,594
incrustación genérica para moverla a una de estas direcciones específicas, 

51
00:02:50,594 --> 00:02:51,800
en función del contexto.

52
00:02:53,300 --> 00:02:56,180
Por poner otro ejemplo, considera la incrustación de la palabra torre.

53
00:02:57,060 --> 00:03:01,192
Se trata presumiblemente de una dirección muy genérica e inespecífica en el espacio, 

54
00:03:01,192 --> 00:03:03,720
asociada a muchos otros sustantivos grandes y altos.

55
00:03:04,020 --> 00:03:06,947
Si esta palabra fuera inmediatamente precedida de Eiffel, 

56
00:03:06,947 --> 00:03:10,581
podrías imaginar que quisieras que el mecanismo actualizara este vector 

57
00:03:10,581 --> 00:03:14,971
para que apuntara en una dirección que codificara más específicamente la torre Eiffel, 

58
00:03:14,971 --> 00:03:19,060
quizá correlacionada con vectores asociados a París y Francia y a cosas de acero.

59
00:03:19,920 --> 00:03:22,316
Si además iba precedida de la palabra miniatura, 

60
00:03:22,316 --> 00:03:24,712
entonces el vector debería actualizarse aún más, 

61
00:03:24,712 --> 00:03:27,500
para que ya no se correlacione con cosas grandes y altas.

62
00:03:29,480 --> 00:03:33,435
En términos más generales que el mero refinamiento del significado de una palabra, 

63
00:03:33,435 --> 00:03:37,057
el bloque de atención permite al modelo trasladar la información codificada 

64
00:03:37,057 --> 00:03:40,011
en una incrustación a la de otra, potencialmente muy lejanas, 

65
00:03:40,011 --> 00:03:43,300
y potencialmente con información mucho más rica que una sola palabra.

66
00:03:43,300 --> 00:03:46,839
Lo que vimos en el último capítulo fue cómo después de que todos los 

67
00:03:46,839 --> 00:03:51,251
vectores fluyan a través de la red, incluyendo muchos bloques de atención diferentes, 

68
00:03:51,251 --> 00:03:54,894
el cálculo que se realiza para producir una predicción de la siguiente 

69
00:03:54,894 --> 00:03:58,280
ficha es totalmente una función del último vector de la secuencia.

70
00:03:59,100 --> 00:04:03,605
Imagina, por ejemplo, que el texto que introduces es la mayor parte de toda una novela 

71
00:04:03,605 --> 00:04:07,800
de misterio, hasta un punto cerca del final, que dice: por tanto, el asesino fue.

72
00:04:08,400 --> 00:04:11,331
Si el modelo va a predecir con exactitud la siguiente palabra, 

73
00:04:11,331 --> 00:04:15,425
ese vector final de la secuencia, que empezó su vida incrustando simplemente la palabra 

74
00:04:15,425 --> 00:04:19,612
era, tendrá que haber sido actualizado por todos los bloques de atención para representar 

75
00:04:19,612 --> 00:04:21,985
mucho, mucho más que cualquier palabra individual, 

76
00:04:21,985 --> 00:04:25,940
codificando de algún modo toda la información de la ventana de contexto completa que 

77
00:04:25,940 --> 00:04:28,220
sea relevante para predecir la siguiente palabra.

78
00:04:29,500 --> 00:04:32,580
Sin embargo, para explicar los cálculos, tomemos un ejemplo mucho más sencillo.

79
00:04:32,980 --> 00:04:35,833
Imagina que la entrada incluye la frase, una esponjosa 

80
00:04:35,833 --> 00:04:37,960
criatura azul vagaba por el verde bosque.

81
00:04:38,460 --> 00:04:42,568
Y por el momento, supongamos que el único tipo de actualización que nos importa 

82
00:04:42,568 --> 00:04:46,780
es que los adjetivos ajusten los significados de sus sustantivos correspondientes.

83
00:04:47,000 --> 00:04:50,349
Lo que voy a describir es lo que llamaríamos una sola cabeza de atención, 

84
00:04:50,349 --> 00:04:53,066
y más adelante veremos cómo el bloque de atención consta de 

85
00:04:53,066 --> 00:04:55,420
muchas cabezas diferentes que funcionan en paralelo.

86
00:04:56,140 --> 00:04:59,521
De nuevo, la incrustación inicial de cada palabra es un vector de alta 

87
00:04:59,521 --> 00:05:03,380
dimensión que sólo codifica el significado de esa palabra concreta, sin contexto.

88
00:05:04,000 --> 00:05:05,220
En realidad, eso no es del todo cierto.

89
00:05:05,380 --> 00:05:07,640
También codifican la posición de la palabra.

90
00:05:07,980 --> 00:05:11,406
Hay mucho más que decir sobre la forma en que se codifican las posiciones, 

91
00:05:11,406 --> 00:05:15,107
pero ahora mismo, todo lo que necesitas saber es que las entradas de este vector 

92
00:05:15,107 --> 00:05:18,900
son suficientes para decirte tanto qué palabra es como dónde existe en el contexto.

93
00:05:19,500 --> 00:05:21,660
Vamos a denotar estas incrustaciones con la letra e.

94
00:05:22,420 --> 00:05:26,235
El objetivo es que una serie de cálculos produzca un nuevo conjunto refinado 

95
00:05:26,235 --> 00:05:29,654
de incrustaciones en el que, por ejemplo, las correspondientes a los 

96
00:05:29,654 --> 00:05:33,420
sustantivos hayan ingerido el significado de sus correspondientes adjetivos.

97
00:05:33,900 --> 00:05:37,105
Y jugando al juego del aprendizaje profundo, queremos que la mayoría de los 

98
00:05:37,105 --> 00:05:39,382
cálculos implicados parezcan productos matriz-vector, 

99
00:05:39,382 --> 00:05:41,744
donde las matrices están llenas de pesos sintonizables, 

100
00:05:41,744 --> 00:05:43,980
cosas que el modelo aprenderá basándose en los datos.

101
00:05:44,660 --> 00:05:47,351
Para que quede claro, me estoy inventando este ejemplo de adjetivos 

102
00:05:47,351 --> 00:05:49,607
que actualizan sustantivos sólo para ilustrar el tipo de 

103
00:05:49,607 --> 00:05:52,260
comportamiento que podrías imaginar que hace un cabeza de atención.

104
00:05:52,860 --> 00:05:54,931
Como ocurre con gran parte del aprendizaje profundo, 

105
00:05:54,931 --> 00:05:57,705
el verdadero comportamiento es mucho más difícil de analizar porque se 

106
00:05:57,705 --> 00:06:00,402
basa en ajustar y afinar un gran número de parámetros para minimizar 

107
00:06:00,402 --> 00:06:01,340
alguna función de coste.

108
00:06:01,680 --> 00:06:05,343
Es sólo que, a medida que avanzamos por todas las diferentes matrices llenas de 

109
00:06:05,343 --> 00:06:09,006
parámetros que intervienen en este proceso, creo que es realmente útil tener un 

110
00:06:09,006 --> 00:06:12,807
ejemplo imaginado de algo que podría estar haciendo para ayudar a que todo sea más 

111
00:06:12,807 --> 00:06:13,220
concreto.

112
00:06:14,140 --> 00:06:17,897
Para el primer paso de este proceso, puedes imaginar que cada sustantivo, 

113
00:06:17,897 --> 00:06:21,960
como criatura, hace la pregunta, oye, ¿hay algún adjetivo sentado delante de mí?

114
00:06:22,160 --> 00:06:25,681
Y para las palabras esponjoso y azul, que cada una pueda responder, 

115
00:06:25,681 --> 00:06:27,960
sí, soy un adjetivo y estoy en esa posición.

116
00:06:28,960 --> 00:06:32,323
Esa pregunta se codifica de algún modo como otro vector, 

117
00:06:32,323 --> 00:06:36,100
otra lista de números, que llamamos la consulta de esta palabra.

118
00:06:36,980 --> 00:06:39,354
Pero este vector de consulta tiene una dimensión 

119
00:06:39,354 --> 00:06:42,020
mucho menor que el vector de incrustación, digamos 128.

120
00:06:42,940 --> 00:06:46,770
El cálculo de esta consulta consiste en tomar una matriz determinada, 

121
00:06:46,770 --> 00:06:49,780
que denominaré wq, y multiplicarla por la incrustación.

122
00:06:50,960 --> 00:06:54,886
Comprimiendo un poco las cosas, vamos a escribir ese vector de consulta como q, 

123
00:06:54,886 --> 00:06:58,321
y cada vez que me veas poner una matriz junto a una flecha como ésta, 

124
00:06:58,321 --> 00:07:01,659
es para representar que multiplicando esta matriz por el vector del 

125
00:07:01,659 --> 00:07:04,800
inicio de la flecha se obtiene el vector del final de la flecha.

126
00:07:05,860 --> 00:07:10,015
En este caso, multiplicas esta matriz por todas las incrustaciones del contexto, 

127
00:07:10,015 --> 00:07:12,580
produciendo un vector de consulta para cada token.

128
00:07:13,740 --> 00:07:16,069
Las entradas de esta matriz son parámetros del modelo, 

129
00:07:16,069 --> 00:07:19,204
lo que significa que el verdadero comportamiento se aprende de los datos, 

130
00:07:19,204 --> 00:07:22,465
y en la práctica, lo que hace esta matriz en una cabeza de atención concreta 

131
00:07:22,465 --> 00:07:23,440
es difícil de analizar.

132
00:07:23,900 --> 00:07:27,625
Pero por nuestro bien, imaginando un ejemplo que podríamos esperar que aprendiera, 

133
00:07:27,625 --> 00:07:30,902
supondremos que esta matriz de consulta asigna las incrustaciones de los 

134
00:07:30,902 --> 00:07:34,448
sustantivos a ciertas direcciones en este espacio de consulta más pequeño que, 

135
00:07:34,448 --> 00:07:38,040
de algún modo, codifica la noción de buscar adjetivos en posiciones precedentes.

136
00:07:38,780 --> 00:07:41,440
En cuanto a lo que hace con otras incrustaciones, ¿quién sabe?

137
00:07:41,720 --> 00:07:44,340
Tal vez intente alcanzar simultáneamente algún otro objetivo con ellas.

138
00:07:44,540 --> 00:07:47,160
Ahora mismo, estamos centrados en los sustantivos.

139
00:07:47,280 --> 00:07:51,458
Al mismo tiempo, asociada a ésta hay una segunda matriz llamada matriz clave, 

140
00:07:51,458 --> 00:07:54,620
que también multiplicas por cada una de las incrustaciones.

141
00:07:55,280 --> 00:07:58,500
Esto produce una segunda secuencia de vectores que llamamos claves.

142
00:07:59,420 --> 00:08:03,140
Conceptualmente, debes pensar que las claves responden potencialmente a las consultas.

143
00:08:03,840 --> 00:08:06,566
Esta matriz clave también está llena de parámetros sintonizables, 

144
00:08:06,566 --> 00:08:09,045
y al igual que la matriz de consulta, mapea los vectores de 

145
00:08:09,045 --> 00:08:11,400
incrustación a ese mismo espacio dimensional más pequeño.

146
00:08:12,200 --> 00:08:14,710
Piensa que las claves coinciden con las consultas 

147
00:08:14,710 --> 00:08:17,020
siempre que se alineen estrechamente entre sí.

148
00:08:17,460 --> 00:08:20,537
En nuestro ejemplo, imaginarías que la matriz clave asigna los 

149
00:08:20,537 --> 00:08:23,809
adjetivos como esponjoso y azul a vectores que están estrechamente 

150
00:08:23,809 --> 00:08:26,740
alineados con la consulta producida por la palabra criatura.

151
00:08:27,200 --> 00:08:30,546
Para medir lo bien que coincide cada clave con cada consulta, 

152
00:08:30,546 --> 00:08:34,000
calcula un producto punto entre cada posible par clave-consulta.

153
00:08:34,480 --> 00:08:37,079
Me gusta visualizar una cuadrícula llena de un montón de puntos, 

154
00:08:37,079 --> 00:08:40,319
donde los puntos más grandes corresponden a los productos de puntos más grandes, 

155
00:08:40,319 --> 00:08:42,559
los lugares donde se alinean las claves y las consultas.

156
00:08:43,280 --> 00:08:47,363
En nuestro ejemplo del sustantivo adjetivo, esto se parecería un poco más a esto, 

157
00:08:47,363 --> 00:08:50,999
donde si las claves producidas por esponjoso y azul realmente se alinean 

158
00:08:50,999 --> 00:08:53,688
estrechamente con la consulta producida por criatura, 

159
00:08:53,688 --> 00:08:57,423
entonces los productos de punto en estos dos puntos serían algunos números 

160
00:08:57,423 --> 00:08:58,320
positivos grandes.

161
00:08:59,100 --> 00:09:02,260
En la jerga, la gente del aprendizaje automático diría que esto significa que 

162
00:09:02,260 --> 00:09:05,420
las incrustaciones de esponjoso y azul atienden a la incrustación de criatura.

163
00:09:06,040 --> 00:09:09,371
Por el contrario, el producto punto entre la clave de otra 

164
00:09:09,371 --> 00:09:12,760
palabra como la y la consulta de criatura sería algún valor 

165
00:09:12,760 --> 00:09:16,600
pequeño o negativo que reflejara que no están relacionadas entre sí.

166
00:09:17,700 --> 00:09:21,248
Así que tenemos esta cuadrícula de valores que puede ser cualquier número real 

167
00:09:21,248 --> 00:09:24,886
desde el infinito negativo hasta el infinito, lo que nos da una puntuación de lo 

168
00:09:24,886 --> 00:09:28,480
relevante que es cada palabra para actualizar el significado de todas las demás.

169
00:09:29,200 --> 00:09:32,623
La forma en que vamos a utilizar estas puntuaciones es tomar una determinada 

170
00:09:32,623 --> 00:09:35,780
suma ponderada a lo largo de cada columna, ponderada por la relevancia.

171
00:09:36,520 --> 00:09:40,528
Así, en lugar de que los valores oscilen entre infinito negativo e infinito, 

172
00:09:40,528 --> 00:09:44,275
lo que queremos es que los números de estas columnas estén entre 0 y 1, 

173
00:09:44,275 --> 00:09:48,180
y que cada columna sume 1, como si fueran una distribución de probabilidad.

174
00:09:49,280 --> 00:09:52,220
Si vienes del último capítulo, ya sabes lo que tenemos que hacer entonces.

175
00:09:52,620 --> 00:09:55,088
Calculamos un softmax a lo largo de cada una de 

176
00:09:55,088 --> 00:09:57,300
estas columnas para normalizar los valores.

177
00:10:00,060 --> 00:10:03,190
En nuestra imagen, después de aplicar softmax a todas las columnas, 

178
00:10:03,190 --> 00:10:05,860
rellenaremos la cuadrícula con estos valores normalizados.

179
00:10:06,780 --> 00:10:10,525
Llegados a este punto, puedes pensar que cada columna tiene una ponderación según la 

180
00:10:10,525 --> 00:10:14,183
relevancia de la palabra de la izquierda para el valor correspondiente de la parte 

181
00:10:14,183 --> 00:10:14,580
superior.

182
00:10:15,080 --> 00:10:16,840
A esta cuadrícula la llamamos patrón de atención.

183
00:10:18,080 --> 00:10:20,679
Ahora bien, si te fijas en el documento original del transformador, 

184
00:10:20,679 --> 00:10:22,820
hay una forma muy compacta en la que escriben todo esto.

185
00:10:23,880 --> 00:10:27,563
Aquí las variables q y k representan las matrices completas de los vectores 

186
00:10:27,563 --> 00:10:31,247
de consulta y clave respectivamente, esos pequeños vectores que se obtienen 

187
00:10:31,247 --> 00:10:34,640
multiplicando las incrustaciones por las matrices de consulta y clave.

188
00:10:35,160 --> 00:10:39,233
Esta expresión arriba en el numerador es una forma realmente compacta de representar 

189
00:10:39,233 --> 00:10:43,020
la red de todos los productos punto posibles entre pares de claves y consultas.

190
00:10:44,000 --> 00:10:46,831
Un pequeño detalle técnico que no he mencionado es que, 

191
00:10:46,831 --> 00:10:50,016
para la estabilidad numérica, resulta útil dividir todos estos 

192
00:10:50,016 --> 00:10:53,960
valores por la raíz cuadrada de la dimensión en ese espacio de consulta clave.

193
00:10:54,480 --> 00:10:57,347
Entonces este softmax que se envuelve alrededor de la 

194
00:10:57,347 --> 00:11:00,800
expresión completa se entiende que se aplica columna por columna.

195
00:11:01,640 --> 00:11:04,700
En cuanto a ese v término, hablaremos de él en un segundo.

196
00:11:05,020 --> 00:11:08,460
Antes de eso, hay otro detalle técnico que hasta ahora me he saltado.

197
00:11:09,040 --> 00:11:12,924
Durante el proceso de entrenamiento, cuando ejecutas este modelo en un ejemplo 

198
00:11:12,924 --> 00:11:16,513
de texto dado, y todos los pesos se ajustan ligeramente y se afinan para 

199
00:11:16,513 --> 00:11:20,103
recompensarlo o castigarlo en función de la probabilidad que asigne a la 

200
00:11:20,103 --> 00:11:23,594
siguiente palabra verdadera del pasaje, resulta que todo el proceso de 

201
00:11:23,594 --> 00:11:27,331
entrenamiento es mucho más eficaz si haces que prediga simultáneamente cada 

202
00:11:27,331 --> 00:11:31,560
posible siguiente token que siga a cada subsecuencia inicial de tokens de este pasaje.

203
00:11:31,940 --> 00:11:34,910
Por ejemplo, con la frase en la que nos hemos centrado, 

204
00:11:34,910 --> 00:11:39,100
también podría predecir qué palabras siguen a criatura y qué palabras siguen a.

205
00:11:39,940 --> 00:11:42,820
Esto está muy bien, porque significa que lo que de otro modo 

206
00:11:42,820 --> 00:11:45,560
sería un único ejemplo de entrenamiento actúa como muchos.

207
00:11:46,100 --> 00:11:49,549
A efectos de nuestro patrón de atención, significa que nunca debes permitir 

208
00:11:49,549 --> 00:11:52,499
que las palabras posteriores influyan en las anteriores, ya que, 

209
00:11:52,499 --> 00:11:56,040
de lo contrario, podrían desvelar la respuesta de lo que viene a continuación.

210
00:11:56,560 --> 00:11:59,635
Lo que esto significa es que queremos que todos estos puntos de aquí, 

211
00:11:59,635 --> 00:12:02,754
los que representan fichas posteriores que influyen en las anteriores, 

212
00:12:02,754 --> 00:12:04,600
sean de alguna manera forzados a ser cero.

213
00:12:05,920 --> 00:12:08,854
Lo más sencillo que se te ocurre hacer es ponerlas igual a cero, 

214
00:12:08,854 --> 00:12:12,420
pero si hicieras eso las columnas ya no sumarían uno, no estarían normalizadas.

215
00:12:13,120 --> 00:12:15,430
Por eso, una forma habitual de hacerlo es que, 

216
00:12:15,430 --> 00:12:19,020
antes de aplicar softmax, fijes todas esas entradas en infinito negativo.

217
00:12:19,680 --> 00:12:23,346
Si haces eso, después de aplicar softmax, todos esos se convierten en cero, 

218
00:12:23,346 --> 00:12:25,180
pero las columnas siguen normalizadas.

219
00:12:26,000 --> 00:12:27,540
Este proceso se denomina enmascaramiento.

220
00:12:27,540 --> 00:12:31,240
Hay versiones de atención en las que no lo aplicas, pero en nuestro ejemplo de GPT, 

221
00:12:31,240 --> 00:12:34,720
aunque esto es más relevante durante la fase de entrenamiento de lo que sería, 

222
00:12:34,720 --> 00:12:36,922
digamos, ejecutándolo como un chatbot o algo así, 

223
00:12:36,922 --> 00:12:40,270
siempre aplicas este enmascaramiento para evitar que los tokens posteriores 

224
00:12:40,270 --> 00:12:41,460
influyan en los anteriores.

225
00:12:42,480 --> 00:12:45,942
Otro hecho sobre el que merece la pena reflexionar acerca de este patrón 

226
00:12:45,942 --> 00:12:49,500
de atención es cómo su tamaño es igual al cuadrado del tamaño del contexto.

227
00:12:49,900 --> 00:12:52,760
Por eso el tamaño del contexto puede ser un cuello de botella realmente 

228
00:12:52,760 --> 00:12:55,620
enorme para los grandes modelos lingüísticos, y ampliarlo no es trivial.

229
00:12:56,300 --> 00:12:59,305
Como imaginarás, motivado por el deseo de tener ventanas de contexto 

230
00:12:59,305 --> 00:13:02,222
cada vez más grandes, en los últimos años se han producido algunas 

231
00:13:02,222 --> 00:13:05,097
variaciones en el mecanismo de atención destinadas a hacer que el 

232
00:13:05,097 --> 00:13:08,320
contexto sea más escalable, pero aquí, tú y yo nos centramos en lo básico.

233
00:13:10,560 --> 00:13:12,867
Vale, genial, calcular este patrón permite al modelo 

234
00:13:12,867 --> 00:13:15,480
deducir qué palabras son relevantes para qué otras palabras.

235
00:13:16,020 --> 00:13:18,508
Ahora tienes que actualizar realmente las incrustaciones, 

236
00:13:18,508 --> 00:13:21,941
permitiendo que las palabras pasen información a cualquier otra palabra para la 

237
00:13:21,941 --> 00:13:22,800
que sean relevantes.

238
00:13:22,800 --> 00:13:26,834
Por ejemplo, quieres que la incrustación de Pelusa provoque de algún modo un cambio 

239
00:13:26,834 --> 00:13:30,917
en la Criatura que la desplace a una parte diferente de este espacio de incrustación 

240
00:13:30,917 --> 00:13:34,520
de 12.000 dimensiones que codifica más específicamente una criatura Pelusa.

241
00:13:35,460 --> 00:13:39,434
Lo que voy a hacer aquí es mostrarte primero la forma más directa de hacerlo, 

242
00:13:39,434 --> 00:13:43,460
aunque hay una pequeña modificación en el contexto de la atención multicabezal.

243
00:13:44,080 --> 00:13:48,485
La forma más directa sería utilizar una tercera matriz, que llamamos matriz de valores, 

244
00:13:48,485 --> 00:13:52,440
que multiplicas por la incrustación de esa primera palabra, por ejemplo Fluffy.

245
00:13:53,300 --> 00:13:56,251
El resultado de esto es lo que llamarías un vector de valores, 

246
00:13:56,251 --> 00:13:59,155
y es algo que añades a la incrustación de la segunda palabra, 

247
00:13:59,155 --> 00:14:01,920
en este caso algo que añades a la incrustación de Criatura.

248
00:14:02,600 --> 00:14:04,691
Así que este vector de valores vive en el mismo 

249
00:14:04,691 --> 00:14:07,000
espacio de muy alta dimensión que las incrustaciones.

250
00:14:07,460 --> 00:14:11,650
Cuando multiplicas esta matriz de valores por la incrustación de una palabra, 

251
00:14:11,650 --> 00:14:16,163
puedes pensar que dice: si esta palabra es relevante para ajustar el significado de 

252
00:14:16,163 --> 00:14:20,569
otra cosa, ¿qué debe añadirse exactamente a la incrustación de esa otra cosa para 

253
00:14:20,569 --> 00:14:21,160
reflejarlo?

254
00:14:22,140 --> 00:14:25,870
Volviendo a nuestro diagrama, dejemos a un lado todas las claves y las consultas, 

255
00:14:25,870 --> 00:14:29,372
ya que después de calcular el patrón de atención ya has terminado con ellas, 

256
00:14:29,372 --> 00:14:32,830
entonces vas a tomar esta matriz de valores y multiplicarla por cada una de 

257
00:14:32,830 --> 00:14:36,060
esas incrustaciones para producir una secuencia de vectores de valores.

258
00:14:37,120 --> 00:14:39,120
Puedes pensar en estos vectores de valores como si 

259
00:14:39,120 --> 00:14:41,120
estuvieran asociados a las claves correspondientes.

260
00:14:42,320 --> 00:14:45,780
Para cada columna de este diagrama, multiplica cada uno de los 

261
00:14:45,780 --> 00:14:49,240
vectores de valores por el peso correspondiente de esa columna.

262
00:14:50,080 --> 00:14:52,790
Por ejemplo, aquí, en la incrustación de Criatura, 

263
00:14:52,790 --> 00:14:57,201
estarías añadiendo grandes proporciones de los vectores de valor de Pelusa y Azul, 

264
00:14:57,201 --> 00:15:01,560
mientras que todos los demás vectores de valor se reducen a cero, o al menos casi.

265
00:15:02,120 --> 00:15:06,718
Y por último, la forma de actualizar realmente la incrustación asociada a esta columna, 

266
00:15:06,718 --> 00:15:10,533
codificando previamente algún significado libre de contexto de Criatura, 

267
00:15:10,533 --> 00:15:13,459
es sumar todos estos valores reescalados en la columna, 

268
00:15:13,459 --> 00:15:16,908
produciendo un cambio que quieres añadir, que etiquetaré delta-e, 

269
00:15:16,908 --> 00:15:19,260
y luego lo añades a la incrustación original.

270
00:15:19,680 --> 00:15:22,903
Con suerte, lo que resulta es un vector más refinado que codifica el 

271
00:15:22,903 --> 00:15:26,500
significado más rico contextualmente, como el de una criatura azul esponjosa.

272
00:15:27,380 --> 00:15:29,956
Y, por supuesto, no lo haces sólo a una incrustación, 

273
00:15:29,956 --> 00:15:33,678
sino que aplicas la misma suma ponderada a todas las columnas de esta imagen, 

274
00:15:33,678 --> 00:15:37,877
produciendo una secuencia de cambios, y sumando todos esos cambios a las incrustaciones 

275
00:15:37,877 --> 00:15:41,885
correspondientes, se produce una secuencia completa de incrustaciones más refinadas 

276
00:15:41,885 --> 00:15:43,460
que salen del bloque de atención.

277
00:15:44,860 --> 00:15:47,001
Ampliando la imagen, todo este proceso es lo que 

278
00:15:47,001 --> 00:15:49,100
se describiría como una sola cabeza de atención.

279
00:15:49,600 --> 00:15:52,779
Tal y como he descrito las cosas hasta ahora, este proceso está 

280
00:15:52,779 --> 00:15:55,859
parametrizado por tres matrices distintas, todas ellas llenas 

281
00:15:55,859 --> 00:15:58,940
de parámetros sintonizables: la clave, la consulta y el valor.

282
00:15:59,500 --> 00:16:03,081
Quiero dedicar un momento a continuar lo que empezamos en el último capítulo, 

283
00:16:03,081 --> 00:16:06,065
con el recuento en el que contamos el número total de parámetros 

284
00:16:06,065 --> 00:16:08,040
del modelo utilizando los números de GPT-3.

285
00:16:09,300 --> 00:16:12,667
Estas matrices de clave y consulta tienen cada una 12.288 columnas, 

286
00:16:12,667 --> 00:16:15,687
que coinciden con la dimensión de incrustación, y 128 filas, 

287
00:16:15,687 --> 00:16:19,600
que coinciden con la dimensión de ese espacio de consulta de clave más pequeño.

288
00:16:20,260 --> 00:16:24,220
Esto nos da 1,5 millones de parámetros más o menos para cada uno.

289
00:16:24,860 --> 00:16:30,273
En cambio, si observas esa matriz de valores, la forma en que he descrito las cosas hasta 

290
00:16:30,273 --> 00:16:35,386
ahora sugeriría que es una matriz cuadrada que tiene 12.288 columnas y 12.288 filas, 

291
00:16:35,386 --> 00:16:40,498
ya que tanto sus entradas como sus salidas viven en este espacio de incrustación tan 

292
00:16:40,498 --> 00:16:40,920
grande.

293
00:16:41,500 --> 00:16:45,140
De ser cierto, eso significaría unos 150 millones de parámetros añadidos.

294
00:16:45,660 --> 00:16:47,300
Y para que quede claro, podrías hacerlo.

295
00:16:47,420 --> 00:16:49,707
Podrías dedicar órdenes de magnitud más de parámetros 

296
00:16:49,707 --> 00:16:51,740
al mapa de valores que a la clave y la consulta.

297
00:16:52,060 --> 00:16:55,006
Pero, en la práctica, es mucho más eficaz si, en lugar de eso, 

298
00:16:55,006 --> 00:16:57,766
haces que el número de parámetros dedicados a este mapa de 

299
00:16:57,766 --> 00:17:00,760
valores sea el mismo que el dedicado a la clave y a la consulta.

300
00:17:01,460 --> 00:17:03,270
Esto es especialmente relevante en el caso de 

301
00:17:03,270 --> 00:17:05,160
ejecutar varias cabezas de atención en paralelo.

302
00:17:06,240 --> 00:17:08,315
El aspecto es que el mapa de valores se factoriza 

303
00:17:08,315 --> 00:17:10,099
como producto de dos matrices más pequeñas.

304
00:17:11,180 --> 00:17:14,663
Conceptualmente, aún te animaría a pensar en el mapa lineal general, 

305
00:17:14,663 --> 00:17:19,004
uno con entradas y salidas, ambos en este espacio de incrustación mayor, por ejemplo, 

306
00:17:19,004 --> 00:17:23,194
llevando la incrustación del azul a esta dirección de azulidad que añadirías a los 

307
00:17:23,194 --> 00:17:23,800
sustantivos.

308
00:17:27,040 --> 00:17:29,925
Es que se trata de un número menor de filas, normalmente 

309
00:17:29,925 --> 00:17:32,760
del mismo tamaño que el espacio de consulta de la clave.

310
00:17:33,100 --> 00:17:35,750
Lo que esto significa es que puedes pensar que se trata de reducir 

311
00:17:35,750 --> 00:17:38,440
los grandes vectores de incrustación a un espacio mucho más pequeño.

312
00:17:39,040 --> 00:17:42,700
No es la denominación convencional, pero voy a llamarla matriz de valores descendentes.

313
00:17:43,400 --> 00:17:47,203
La segunda matriz mapea desde este espacio más pequeño hasta el espacio de incrustación, 

314
00:17:47,203 --> 00:17:50,580
produciendo los vectores que utilizas para realizar las actualizaciones reales.

315
00:17:51,000 --> 00:17:54,740
Voy a llamar a ésta la matriz del valor hacia arriba, que tampoco es convencional.

316
00:17:55,160 --> 00:17:56,620
La forma en que verías esto escrito en la mayoría 

317
00:17:56,620 --> 00:17:58,080
de los artículos científicos es un poco diferente.

318
00:17:58,380 --> 00:17:59,520
Hablaré de ello dentro de un momento.

319
00:17:59,700 --> 00:18:02,540
En mi opinión, tiende a hacer las cosas un poco más confusas conceptualmente.

320
00:18:03,260 --> 00:18:06,778
Para utilizar la jerga del álgebra lineal, lo que estamos haciendo básicamente es 

321
00:18:06,778 --> 00:18:10,340
restringir el mapa de valores global para que sea una transformación de bajo rango.

322
00:18:11,420 --> 00:18:15,879
Volviendo al recuento de parámetros, las cuatro matrices tienen el mismo tamaño, 

323
00:18:15,879 --> 00:18:20,780
y sumándolas todas obtenemos unos 6,3 millones de parámetros para una cabeza de atención.

324
00:18:22,040 --> 00:18:24,151
Como nota al margen, para ser un poco más precisos, 

325
00:18:24,151 --> 00:18:27,602
todo lo descrito hasta ahora es lo que la gente llamaría una cabeza de autoatención, 

326
00:18:27,602 --> 00:18:30,809
para distinguirla de una variación que aparece en otros modelos y que se llama 

327
00:18:30,809 --> 00:18:31,500
atención cruzada.

328
00:18:32,300 --> 00:18:36,264
Esto no es relevante para nuestro ejemplo de GPT, pero si tienes curiosidad, 

329
00:18:36,264 --> 00:18:40,332
la atención cruzada implica modelos que procesan dos tipos distintos de datos, 

330
00:18:40,332 --> 00:18:44,502
como texto en un idioma y texto en otro idioma que forma parte de una generación 

331
00:18:44,502 --> 00:18:48,776
en curso de una traducción, o quizá entrada de audio del habla y una transcripción 

332
00:18:48,776 --> 00:18:49,240
en curso.

333
00:18:50,400 --> 00:18:52,700
Una cabeza de atención cruzada tiene un aspecto casi idéntico.

334
00:18:52,980 --> 00:18:55,123
La única diferencia es que los mapas clave y de 

335
00:18:55,123 --> 00:18:57,400
consulta actúan sobre conjuntos de datos distintos.

336
00:18:57,840 --> 00:19:00,243
En un modelo que hace traducciones, por ejemplo, 

337
00:19:00,243 --> 00:19:04,559
las claves podrían proceder de una lengua, mientras que las consultas proceden de otra, 

338
00:19:04,559 --> 00:19:08,531
y el patrón de atención podría describir qué palabras de una lengua corresponden 

339
00:19:08,531 --> 00:19:09,660
a qué palabras de otra.

340
00:19:10,340 --> 00:19:12,506
Y en este escenario no suele haber enmascaramiento, 

341
00:19:12,506 --> 00:19:15,631
ya que no existe realmente la noción de que las fichas posteriores afecten 

342
00:19:15,631 --> 00:19:16,340
a las anteriores.

343
00:19:17,180 --> 00:19:19,831
Sin embargo, si te mantuvieras centrado en la autoatención, 

344
00:19:19,831 --> 00:19:22,616
si lo comprendieras todo hasta ahora, y si te detuvieras aquí, 

345
00:19:22,616 --> 00:19:25,180
llegarías a la esencia de lo que es realmente la atención.

346
00:19:25,760 --> 00:19:31,440
Lo único que nos queda es exponer el sentido en que lo haces muchas veces.

347
00:19:32,100 --> 00:19:34,568
En nuestro ejemplo central nos hemos centrado en los adjetivos que 

348
00:19:34,568 --> 00:19:36,336
actualizan los sustantivos, pero, por supuesto, 

349
00:19:36,336 --> 00:19:38,805
hay muchas formas distintas en que el contexto puede influir en el 

350
00:19:38,805 --> 00:19:39,800
significado de una palabra.

351
00:19:40,360 --> 00:19:43,390
Si las palabras que chocaron precedieron a la palabra coche, 

352
00:19:43,390 --> 00:19:46,520
tiene implicaciones para la forma y la estructura de ese coche.

353
00:19:47,200 --> 00:19:49,280
Y muchas asociaciones podrían ser menos gramaticales.

354
00:19:49,760 --> 00:19:53,235
Si la palabra mago está en algún lugar del mismo pasaje que Harry, 

355
00:19:53,235 --> 00:19:56,918
sugiere que podría referirse a Harry Potter, mientras que si en cambio 

356
00:19:56,918 --> 00:20:00,290
las palabras Reina, Sussex y Guillermo estuvieran en ese pasaje, 

357
00:20:00,290 --> 00:20:04,440
quizá habría que actualizar la incrustación de Harry para referirse al príncipe.

358
00:20:05,040 --> 00:20:08,341
Para cada tipo diferente de actualización contextual que puedas imaginar, 

359
00:20:08,341 --> 00:20:11,733
los parámetros de estas matrices clave y de consulta serían diferentes para 

360
00:20:11,733 --> 00:20:15,258
captar los distintos patrones de atención, y los parámetros de nuestro mapa de 

361
00:20:15,258 --> 00:20:19,140
valores serían diferentes en función de lo que hubiera que añadir a las incrustaciones.

362
00:20:19,980 --> 00:20:23,380
Y de nuevo, en la práctica el verdadero comportamiento de estos mapas es mucho más 

363
00:20:23,380 --> 00:20:26,821
difícil de interpretar, ya que los pesos se ajustan para que hagan lo que el modelo 

364
00:20:26,821 --> 00:20:30,140
necesite que hagan para cumplir mejor su objetivo de predecir la siguiente ficha.

365
00:20:31,400 --> 00:20:35,007
Como he dicho antes, todo lo que hemos descrito es un único cabezal de atención, 

366
00:20:35,007 --> 00:20:38,660
y un bloque de atención completo dentro de un transformador consiste en lo que se 

367
00:20:38,660 --> 00:20:42,312
denomina atención multicabezal, en la que ejecutas muchas de estas operaciones en 

368
00:20:42,312 --> 00:20:45,920
paralelo, cada una con su propia consulta de claves y mapas de valores distintos.

369
00:20:47,420 --> 00:20:51,700
GPT-3, por ejemplo, utiliza 96 cabezas de atención dentro de cada bloque.

370
00:20:52,020 --> 00:20:54,675
Teniendo en cuenta que cada uno de ellos ya es un poco confuso, 

371
00:20:54,675 --> 00:20:56,460
sin duda es mucho que retener en la cabeza.

372
00:20:56,760 --> 00:21:00,880
Para explicarlo todo muy explícitamente, esto significa que tienes 96 matrices 

373
00:21:00,880 --> 00:21:05,000
de claves y consultas distintas que producen 96 patrones de atención distintos.

374
00:21:05,440 --> 00:21:08,834
Luego, cada cabeza tiene sus propias matrices de valores distintas, 

375
00:21:08,834 --> 00:21:12,180
que se utilizan para producir 96 secuencias de vectores de valores.

376
00:21:12,460 --> 00:21:16,680
Todos ellos se suman utilizando como pesos los patrones de atención correspondientes.

377
00:21:17,480 --> 00:21:20,747
Lo que esto significa es que para cada posición del contexto, 

378
00:21:20,747 --> 00:21:23,910
cada token, cada una de estas cabezas produce una propuesta 

379
00:21:23,910 --> 00:21:27,020
de cambio que se añadirá a la incrustación en esa posición.

380
00:21:27,660 --> 00:21:32,022
Así que lo que haces es sumar todos esos cambios propuestos, uno por cada cabeza, 

381
00:21:32,022 --> 00:21:35,480
y añades el resultado a la incrustación original de esa posición.

382
00:21:36,660 --> 00:21:41,811
Toda esta suma de aquí sería una porción de lo que sale de este bloque de atención 

383
00:21:41,811 --> 00:21:47,087
múltiple, una sola de esas incrustaciones refinadas que sale por el otro extremo del 

384
00:21:47,087 --> 00:21:47,460
mismo.

385
00:21:48,320 --> 00:21:50,189
De nuevo, hay mucho en lo que pensar, así que 

386
00:21:50,189 --> 00:21:52,140
no te preocupes si tardas un poco en asimilarlo.

387
00:21:52,380 --> 00:21:56,135
La idea general es que, al ejecutar muchas cabezas distintas en paralelo, 

388
00:21:56,135 --> 00:21:59,231
estás dando al modelo la capacidad de aprender muchas formas 

389
00:21:59,231 --> 00:22:01,820
distintas en que el contexto cambia el significado.

390
00:22:03,700 --> 00:22:07,413
Si sacamos nuestra cuenta corriente de recuento de parámetros con 96 cabezas, 

391
00:22:07,413 --> 00:22:11,080
cada una de las cuales incluye su propia variación de estas cuatro matrices, 

392
00:22:11,080 --> 00:22:15,080
cada bloque de atención multicabezas acaba teniendo unos 600 millones de parámetros.

393
00:22:16,420 --> 00:22:19,052
Hay una cosa añadida un poco molesta que realmente debería mencionar 

394
00:22:19,052 --> 00:22:21,800
para cualquiera de vosotros que siga leyendo más sobre los transformers.

395
00:22:22,080 --> 00:22:26,412
Recuerdas que dije que el mapa de valores se descompone en dos matrices distintas, 

396
00:22:26,412 --> 00:22:29,440
que denominé matrices de valor hacia abajo y hacia arriba.

397
00:22:29,960 --> 00:22:34,330
El modo en que he planteado las cosas sugeriría que ves este par de matrices dentro 

398
00:22:34,330 --> 00:22:38,440
de cada cabeza de atención, y podrías implementarlo absolutamente de este modo.

399
00:22:38,640 --> 00:22:39,920
Sería un diseño válido.

400
00:22:40,260 --> 00:22:42,643
Pero la forma en que ves esto escrito en los artículos científicos 

401
00:22:42,643 --> 00:22:44,920
y la forma en que se aplica en la práctica es un poco diferente.

402
00:22:45,340 --> 00:22:51,023
Todas estas matrices de valores de cada cabeza aparecen grapadas en una matriz gigante 

403
00:22:51,023 --> 00:22:56,380
que llamamos matriz de salida, asociada a todo el bloque de atención multicabezal.

404
00:22:56,820 --> 00:23:00,186
Y cuando ves a la gente referirse a la matriz de valores para una cabeza de 

405
00:23:00,186 --> 00:23:03,330
atención determinada, normalmente sólo se refieren a este primer paso, 

406
00:23:03,330 --> 00:23:07,140
el que yo etiqueté como la proyección del valor hacia abajo en el espacio más pequeño.

407
00:23:08,340 --> 00:23:11,040
Para los más curiosos, he dejado una nota en pantalla al respecto.

408
00:23:11,260 --> 00:23:14,794
Es uno de esos detalles que corren el riesgo de distraer de los puntos conceptuales 

409
00:23:14,794 --> 00:23:18,540
principales, pero quiero señalarlo para que lo sepas si lees sobre esto en otras fuentes.

410
00:23:19,240 --> 00:23:22,083
Dejando a un lado todos los matices técnicos, en el avance del 

411
00:23:22,083 --> 00:23:24,926
último capítulo vimos cómo los datos que fluyen a través de un 

412
00:23:24,926 --> 00:23:28,040
transformador no sólo fluyen a través de un único bloque de atención.

413
00:23:28,640 --> 00:23:32,700
Por un lado, también pasa por estas otras operaciones llamadas perceptrones multicapa.

414
00:23:33,120 --> 00:23:34,880
Hablaremos más de ellos en el próximo capítulo.

415
00:23:35,180 --> 00:23:39,320
Y luego pasa repetidamente por muchas muchas copias de estas dos operaciones.

416
00:23:39,980 --> 00:23:43,317
Lo que esto significa es que, después de que una palabra determinada se 

417
00:23:43,317 --> 00:23:46,563
impregne de parte de su contexto, hay muchas más posibilidades de que 

418
00:23:46,563 --> 00:23:50,040
esta impregnación más matizada se vea influida por su entorno más matizado.

419
00:23:50,940 --> 00:23:55,153
Cuanto más se desciende en la red, y cada incrustación adquiere cada vez más significado 

420
00:23:55,153 --> 00:23:58,751
de todas las demás incrustaciones, que a su vez son cada vez más matizadas, 

421
00:23:58,751 --> 00:24:02,917
se espera que exista la capacidad de codificar ideas de nivel superior y más abstractas 

422
00:24:02,917 --> 00:24:06,799
sobre una entrada determinada, más allá de los meros descriptores y la estructura 

423
00:24:06,799 --> 00:24:07,320
gramatical.

424
00:24:07,880 --> 00:24:11,586
Cosas como el sentimiento y el tono y si es un poema y qué verdades 

425
00:24:11,586 --> 00:24:15,130
científicas subyacentes son relevantes para la pieza y cosas así.

426
00:24:16,700 --> 00:24:21,150
Volviendo una vez más a nuestro marcador, GPT-3 incluye 96 capas distintas, 

427
00:24:21,150 --> 00:24:25,892
por lo que el número total de parámetros clave de consulta y valor se multiplica 

428
00:24:25,892 --> 00:24:30,108
por otros 96, lo que hace que la suma total sea de algo menos de 58.000 

429
00:24:30,108 --> 00:24:34,500
millones de parámetros distintos dedicados a todas las cabezas de atención.

430
00:24:34,980 --> 00:24:37,896
Es mucho, sin duda, pero sólo es un tercio de 

431
00:24:37,896 --> 00:24:40,940
los 175.000 millones que hay en total en la red.

432
00:24:41,520 --> 00:24:44,019
Así que, aunque la atención acapare toda la atención, 

433
00:24:44,019 --> 00:24:48,140
la mayoría de los parámetros proceden de los bloques que se encuentran entre estos pasos.

434
00:24:48,560 --> 00:24:51,099
En el próximo capítulo, tú y yo hablaremos más sobre esos otros 

435
00:24:51,099 --> 00:24:53,560
bloques y también mucho más sobre el proceso de entrenamiento.

436
00:24:54,120 --> 00:24:58,819
Gran parte del éxito del mecanismo de atención no radica tanto en el tipo específico de 

437
00:24:58,819 --> 00:25:03,359
comportamiento que permite, sino en el hecho de que es extremadamente paralelizable, 

438
00:25:03,359 --> 00:25:08,166
lo que significa que puedes ejecutar un gran número de cálculos en poco tiempo utilizando 

439
00:25:08,166 --> 00:25:08,380
GPU.

440
00:25:09,460 --> 00:25:12,380
Dado que una de las grandes lecciones sobre el aprendizaje profundo en 

441
00:25:12,380 --> 00:25:15,177
la última década o dos ha sido que la escala por sí sola parece dar 

442
00:25:15,177 --> 00:25:17,604
enormes mejoras cualitativas en el rendimiento del modelo, 

443
00:25:17,604 --> 00:25:21,060
hay una gran ventaja en las arquitecturas paralelizables que te permiten hacer esto.

444
00:25:22,040 --> 00:25:25,340
Si quieres saber más sobre este tema, he dejado muchos enlaces en la descripción.

445
00:25:25,920 --> 00:25:30,040
En particular, todo lo producido por Andrej Karpathy o Chris Ola suele ser oro puro.

446
00:25:30,560 --> 00:25:33,371
En este vídeo, sólo quería hablar de la atención en su forma actual, 

447
00:25:33,371 --> 00:25:36,305
pero si tienes curiosidad por saber más sobre la historia de cómo hemos 

448
00:25:36,305 --> 00:25:38,913
llegado hasta aquí y cómo podrías reinventar esta idea para ti, 

449
00:25:38,913 --> 00:25:42,540
mi amigo Vivek acaba de publicar un par de vídeos en los que ofrece mucha más motivación.

450
00:25:43,120 --> 00:25:45,239
Además, Britt Cruz, del canal El Arte del Problema, 

451
00:25:45,239 --> 00:25:48,460
tiene un vídeo muy bueno sobre la historia de los grandes modelos lingüísticos.

452
00:26:04,960 --> 00:26:09,200
Gracias.

