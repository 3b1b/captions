1
00:00:00,000 --> 00:00:04,019
در فصل آخر، من و شما شروع به قدم گذاشتن در عملکرد داخلی یک ترانسفورماتور کردیم.

2
00:00:04,560 --> 00:00:07,325
این یکی از قطعات کلیدی فناوری در مدل های زبان بزرگ 

3
00:00:07,325 --> 00:00:10,200
و بسیاری از ابزارهای دیگر در موج مدرن هوش مصنوعی است.

4
00:00:10,980 --> 00:00:14,661
این اولین بار در یک مقاله معروف در سال 2017 به نام توجه همه آن چیزی 

5
00:00:14,661 --> 00:00:18,180
است که نیاز دارید به صحنه آمد و در این فصل من و شما به بررسی این 

6
00:00:18,180 --> 00:00:21,700
مکانیسم توجه خواهیم پرداخت و نحوه پردازش داده ها را تجسم می کنیم.

7
00:00:26,140 --> 00:00:27,876
به عنوان یک جمع بندی سریع، در اینجا زمینه مهمی 

8
00:00:27,876 --> 00:00:29,540
وجود دارد که می خواهم شما در ذهن داشته باشید.

9
00:00:30,000 --> 00:00:33,056
هدف از مدلی که من و شما در حال مطالعه آن هستیم این است که 

10
00:00:33,056 --> 00:00:36,060
یک متن را برداریم و پیش‌بینی کنیم چه کلمه‌ای بعدا می‌آید.

11
00:00:36,860 --> 00:00:40,095
متن ورودی به تکه‌های کوچکی تقسیم می‌شود که ما آن‌ها را نشانه‌ها 

12
00:00:40,095 --> 00:00:43,381
می‌نامیم، و اینها اغلب کلمات یا تکه‌هایی از کلمات هستند، اما فقط 

13
00:00:43,381 --> 00:00:46,616
برای اینکه فکر کردن به مثال‌های این ویدیو برای من و شما راحت‌تر 

14
00:00:46,616 --> 00:00:50,560
باشد، بیایید با تظاهر به اینکه نشانه‌ها هستند، ساده‌سازی کنیم. همیشه فقط کلمات

15
00:00:51,480 --> 00:00:54,539
اولین مرحله در یک ترانسفورماتور این است که هر نشانه را با یک 

16
00:00:54,539 --> 00:00:57,700
بردار با ابعاد بالا مرتبط کنیم، چیزی که ما آن را تعبیه می‌کنیم.

17
00:00:57,700 --> 00:01:02,200
مهم‌ترین ایده‌ای که می‌خواهم در ذهن داشته باشید این است که چگونه جهت‌ها در 

18
00:01:02,200 --> 00:01:07,000
این فضای پربعد همه جاسازی‌های ممکن می‌توانند با معنای معنایی مطابقت داشته باشند.

19
00:01:07,680 --> 00:01:11,646
در فصل آخر مثالی را دیدیم که چگونه جهت می تواند با جنسیت مطابقت 

20
00:01:11,646 --> 00:01:15,426
داشته باشد، به این معنا که افزودن یک مرحله خاص در این فضا می 

21
00:01:15,426 --> 00:01:19,640
تواند شما را از جاسازی یک اسم مذکر به جاسازی اسم مونث مربوطه برساند.

22
00:01:20,160 --> 00:01:23,740
این تنها یک مثال است که می‌توانید تصور کنید چند جهت دیگر در این فضای 

23
00:01:23,740 --> 00:01:27,580
پربعد می‌تواند با جنبه‌های متعدد دیگری از معنای یک کلمه مطابقت داشته باشد.

24
00:01:28,800 --> 00:01:33,925
هدف یک ترانسفورماتور تنظیم تدریجی این تعبیه‌ها به گونه‌ای است که آنها صرفاً یک 

25
00:01:33,925 --> 00:01:39,180
کلمه را رمزگذاری نمی‌کنند، بلکه در عوض به معنای متنی بسیار غنی‌تری تبدیل می‌شوند.

26
00:01:40,140 --> 00:01:44,634
باید از قبل بگویم که بسیاری از مردم مکانیسم توجه، این قطعه کلید در ترانسفورماتور را بسیار 

27
00:01:44,634 --> 00:01:48,980
گیج کننده می دانند، بنابراین اگر کمی طول می کشد تا چیزها در آن فرو بروند، نگران نباشید.

28
00:01:49,440 --> 00:01:54,270
من فکر می‌کنم قبل از اینکه به جزئیات محاسباتی و همه ضرب‌های ماتریس بپردازیم، ارزش 

29
00:01:54,270 --> 00:01:59,160
آن را دارد که به چند مثال برای نوع رفتاری که می‌خواهیم توجه را فعال کنیم، فکر کنیم.

30
00:02:00,140 --> 00:02:06,220
عبارات مول واقعی آمریکایی، یک مول دی اکسید کربن را در نظر بگیرید و از خال بیوپسی بگیرید.

31
00:02:06,700 --> 00:02:10,900
من و شما می دانیم که کلمه خال در هر یک از اینها بر اساس زمینه، معانی مختلفی دارد.

32
00:02:11,360 --> 00:02:16,377
اما پس از اولین مرحله ترانسفورماتور، مرحله ای که متن را می شکند و هر نشانه را 

33
00:02:16,377 --> 00:02:21,459
با یک بردار مرتبط می کند، بردار مرتبط با مول در همه این موارد یکسان خواهد بود، 

34
00:02:21,459 --> 00:02:26,220
زیرا این جاسازی نشانه اولیه در واقع یک جدول جستجو است. بدون اشاره به زمینه

35
00:02:26,620 --> 00:02:29,886
تنها در مرحله بعدی ترانسفورماتور است که جاسازی های اطراف این 

36
00:02:29,886 --> 00:02:33,100
شانس را دارند که اطلاعات را به این ترانسفورماتور منتقل کنند.

37
00:02:33,820 --> 00:02:38,358
تصویری که ممکن است در ذهن داشته باشید این است که چندین جهت متمایز در این فضای 

38
00:02:38,358 --> 00:02:42,897
جاسازی وجود دارد که معانی متمایز چندگانه کلمه مول را رمزگذاری می کند، و اینکه 

39
00:02:42,897 --> 00:02:47,203
یک بلوک توجه به خوبی آموزش دیده محاسبه می کند که برای انتقال آن به جاسازی 

40
00:02:47,203 --> 00:02:51,800
عمومی باید چه چیزی اضافه کنید. یکی از این جهت های خاص، به عنوان تابعی از زمینه.

41
00:02:53,300 --> 00:02:56,180
برای مثال دیگر، تعبیه کلمه برج را در نظر بگیرید.

42
00:02:57,060 --> 00:03:00,390
احتمالاً این یک جهت بسیار کلی و غیر خاص در فضا است 

43
00:03:00,390 --> 00:03:03,720
که با بسیاری از اسم‌های بزرگ و بلند دیگر مرتبط است.

44
00:03:04,020 --> 00:03:08,760
اگر بلافاصله قبل از این کلمه ایفل قرار می گرفت، می توانید تصور کنید که می خواهید 

45
00:03:08,760 --> 00:03:13,910
مکانیزم این بردار را به روز کند تا به جهتی اشاره کند که به طور خاص برج ایفل را رمزگذاری 

46
00:03:13,910 --> 00:03:19,060
می کند، شاید با بردارهای مرتبط با پاریس و فرانسه و چیزهای ساخته شده از فولاد مرتبط باشد.

47
00:03:19,920 --> 00:03:23,560
اگر قبل از آن کلمه مینیاتور نیز وجود داشت، باید بردار را حتی 

48
00:03:23,560 --> 00:03:27,500
بیشتر به روز کرد تا دیگر با چیزهای بزرگ و بلند ارتباط نداشته باشد.

49
00:03:29,480 --> 00:03:34,146
به طور کلی تر از صرفاً پالایش معنای یک کلمه، بلوک توجه به مدل اجازه می دهد تا 

50
00:03:34,146 --> 00:03:38,812
اطلاعات رمزگذاری شده در یک جاسازی را به دیگری منتقل کند، به طور بالقوه مواردی 

51
00:03:38,812 --> 00:03:43,300
که بسیار دور هستند و احتمالاً با اطلاعاتی که بسیار غنی تر از یک کلمه هستند.

52
00:03:43,300 --> 00:03:48,177
چیزی که در فصل گذشته دیدیم این بود که چگونه پس از عبور همه بردارها در 

53
00:03:48,177 --> 00:03:52,915
شبکه، از جمله بسیاری از بلوک‌های توجه مختلف، محاسباتی که برای تولید 

54
00:03:52,915 --> 00:03:58,280
پیش‌بینی نشانه بعدی انجام می‌دهید، کاملاً تابعی از آخرین بردار در دنباله است.

55
00:03:59,100 --> 00:04:03,415
برای مثال تصور کنید متنی که وارد می‌کنید بیشتر یک رمان معمایی 

56
00:04:03,415 --> 00:04:07,800
است، تا نقطه‌ای نزدیک به پایان، که می‌خواند، بنابراین قاتل بود.

57
00:04:08,400 --> 00:04:13,355
اگر مدل قرار است کلمه بعدی را به طور دقیق پیش بینی کند، آن بردار نهایی در دنباله، 

58
00:04:13,355 --> 00:04:18,310
که زندگی خود را صرفاً با جاسازی کلمه آغاز کرد، باید توسط همه بلوک های توجه به روز 

59
00:04:18,310 --> 00:04:21,935
شده باشد تا بسیار، بسیار بیشتر از هر فرد دیگری را نشان دهد. 

60
00:04:21,935 --> 00:04:26,951
کلمه، به نوعی تمام اطلاعات را از پنجره زمینه کامل که برای پیش‌بینی کلمه بعدی مرتبط 

61
00:04:26,951 --> 00:04:28,220
است، رمزگذاری می‌کند.

62
00:04:29,500 --> 00:04:32,580
با این حال، برای گذر از محاسبات، مثالی بسیار ساده‌تر می‌زنیم.

63
00:04:32,980 --> 00:04:37,960
تصور کنید که ورودی شامل عبارت باشد، یک موجود آبی کرکی در جنگل سرسبز پرسه می زد.

64
00:04:38,460 --> 00:04:42,347
و فعلاً، فرض کنید که تنها نوع به‌روزرسانی که به آن اهمیت 

65
00:04:42,347 --> 00:04:46,780
می‌دهیم این است که صفت‌ها معانی اسم‌های مربوطه خود را تنظیم کنند.

66
00:04:47,000 --> 00:04:51,129
چیزی که می‌خواهم توضیح دهم چیزی است که ما آن را یک سر توجه می‌نامیم، و بعداً 

67
00:04:51,129 --> 00:04:55,420
خواهیم دید که چگونه بلوک توجه از تعداد زیادی سر مختلف به صورت موازی اجرا می‌شود.

68
00:04:56,140 --> 00:04:59,673
باز هم، جاسازی اولیه برای هر کلمه، برخی از بردارهای با ابعاد 

69
00:04:59,673 --> 00:05:03,380
بالا است که فقط معنای آن کلمه خاص را بدون زمینه رمزگذاری می کند.

70
00:05:04,000 --> 00:05:05,220
در واقع، این کاملا درست نیست.

71
00:05:05,380 --> 00:05:07,640
آنها همچنین موقعیت کلمه را رمزگذاری می کنند.

72
00:05:07,980 --> 00:05:11,469
روش‌های رمزگذاری موقعیت‌ها چیزهای بیشتری برای گفتن وجود دارد، 

73
00:05:11,469 --> 00:05:15,016
اما در حال حاضر، تنها چیزی که باید بدانید این است که ورودی‌های 

74
00:05:15,016 --> 00:05:18,900
این بردار کافی است تا به شما بگوییم کلمه چیست و کجا در متن وجود دارد.

75
00:05:19,500 --> 00:05:21,660
بیایید جلوتر برویم و این جاسازی ها را با حرف e نشان دهیم.

76
00:05:22,420 --> 00:05:27,725
هدف این است که مجموعه‌ای از محاسبات مجموعه جدیدی از تعبیه‌ها را تولید کند که برای 

77
00:05:27,725 --> 00:05:33,420
مثال، آنهایی که با اسم‌ها مطابقت دارند، معنی را از صفت‌های مربوطه خود دریافت کرده باشند.

78
00:05:33,900 --> 00:05:37,224
و با انجام بازی یادگیری عمیق، می‌خواهیم بیشتر محاسبات مربوط به 

79
00:05:37,224 --> 00:05:40,338
محصولات ماتریس-بردار به نظر برسند، جایی که ماتریس‌ها پر از 

80
00:05:40,338 --> 00:05:43,980
وزن‌های قابل تنظیم هستند، چیزهایی که مدل بر اساس داده‌ها یاد می‌گیرد.

81
00:05:44,660 --> 00:05:48,366
برای واضح بودن، من این مثال از صفت‌هایی که اسم‌ها را به‌روزرسانی می‌کنند، درست 

82
00:05:48,366 --> 00:05:52,260
می‌کنم تا نوع رفتاری را که می‌توانید تصور کنید یک سر توجه انجام می‌دهد را نشان دهم.

83
00:05:52,860 --> 00:05:56,909
همانند بسیاری از یادگیری‌های عمیق، تجزیه رفتار واقعی بسیار سخت‌تر است، زیرا مبتنی بر 

84
00:05:56,909 --> 00:06:01,149
بهینه‌سازی و تنظیم تعداد زیادی از پارامترها برای به حداقل رساندن برخی از عملکردهای هزینه 

85
00:06:01,149 --> 00:06:01,340
است.

86
00:06:01,680 --> 00:06:05,509
فقط این است که وقتی ما از میان همه ماتریس‌های مختلف پر از پارامترهایی که 

87
00:06:05,509 --> 00:06:09,390
در این فرآیند دخیل هستند قدم می‌گذاریم، فکر می‌کنم داشتن یک مثال تصوری از 

88
00:06:09,390 --> 00:06:13,220
چیزی که می‌تواند برای کمک به ملموس‌تر ماندن آن انجام دهد، واقعا مفید است.

89
00:06:14,140 --> 00:06:18,080
برای اولین مرحله از این فرآیند، ممکن است تصور کنید هر اسم، مانند 

90
00:06:18,080 --> 00:06:21,960
موجودی، این سوال را می پرسد، هی، آیا صفتی در مقابل من نشسته است؟

91
00:06:22,160 --> 00:06:24,939
و برای کلمات کرکی و آبی، به هر کدام که بتواند 

92
00:06:24,939 --> 00:06:27,960
پاسخ دهد، بله، من یک صفت هستم و در آن موقعیت هستم.

93
00:06:28,960 --> 00:06:32,559
این سوال به نوعی به عنوان یک بردار دیگر، لیست دیگری از اعداد، 

94
00:06:32,559 --> 00:06:36,100
که ما آن را پرس و جو برای این کلمه می نامیم، رمزگذاری می شود.

95
00:06:36,980 --> 00:06:42,020
این بردار پرس و جو اگرچه ابعاد بسیار کوچکتری نسبت به بردار جاسازی، مثلاً 128 دارد.

96
00:06:42,940 --> 00:06:46,329
محاسبه این پرس و جو مانند گرفتن یک ماتریس خاص است که من 

97
00:06:46,329 --> 00:06:49,780
آن را wq برچسب گذاری می کنم و آن را در جاسازی ضرب می کنم.

98
00:06:50,960 --> 00:06:55,495
با کمی فشرده کردن چیزها، بیایید آن بردار پرس و جو را به صورت q بنویسیم، و سپس 

99
00:06:55,495 --> 00:07:00,089
هر زمان که دیدید من یک ماتریس را در کنار فلشی مانند این قرار دادم، به این معنی 

100
00:07:00,089 --> 00:07:04,800
است که ضرب این ماتریس در بردار در ابتدای فلش به شما بردار را می دهد. انتهای پیکان

101
00:07:05,860 --> 00:07:09,335
در این حالت، این ماتریس را در همه جاسازی‌های موجود در زمینه 

102
00:07:09,335 --> 00:07:12,580
ضرب می‌کنید و برای هر توکن یک بردار کوئری تولید می‌کنید.

103
00:07:13,740 --> 00:07:16,781
ورودی‌های این ماتریس پارامترهای مدل هستند، به این معنی که 

104
00:07:16,781 --> 00:07:20,136
رفتار واقعی از داده‌ها آموخته می‌شود، و در عمل، آنچه این ماتریس 

105
00:07:20,136 --> 00:07:23,440
در یک سر توجه خاص انجام می‌دهد، تجزیه و تحلیل چالش برانگیز است.

106
00:07:23,900 --> 00:07:28,533
اما به خاطر خودمان، با تصور مثالی که امیدواریم یاد بگیرد، فرض می کنیم که این 

107
00:07:28,533 --> 00:07:33,346
ماتریس پرس و جو جاسازی اسم ها را به جهات خاصی در این فضای پرس و جو کوچکتر ترسیم 

108
00:07:33,346 --> 00:07:38,040
می کند که به نوعی مفهوم جستجوی صفت ها در موقعیت های قبلی را رمزگذاری می کند. .

109
00:07:38,780 --> 00:07:41,440
در مورد اینکه با جاسازی های دیگر چه می کند، چه کسی می داند؟

110
00:07:41,720 --> 00:07:44,340
شاید به طور همزمان سعی می کند با آن اهداف دیگری را محقق کند.

111
00:07:44,540 --> 00:07:47,160
در حال حاضر، ما روی اسم ها تمرکز لیزری داریم.

112
00:07:47,280 --> 00:07:50,746
در عین حال، با این ماتریس دومی به نام ماتریس کلیدی 

113
00:07:50,746 --> 00:07:54,620
همراه است که آن را نیز در هر یک از جاسازی‌ها ضرب می‌کنید.

114
00:07:55,280 --> 00:07:58,500
این یک دنباله دوم از بردارها را تولید می کند که ما آنها را کلید می نامیم.

115
00:07:59,420 --> 00:08:03,140
از نظر مفهومی، شما می‌خواهید کلیدها را به‌عنوان پاسخ‌دهی بالقوه به پرسش‌ها در نظر بگیرید.

116
00:08:03,840 --> 00:08:07,671
این ماتریس کلید همچنین پر از پارامترهای قابل تنظیم است و درست مانند ماتریس 

117
00:08:07,671 --> 00:08:11,400
پرس و جو، بردارهای جاسازی شده را به همان فضای ابعادی کوچکتر نگاشت می کند.

118
00:08:12,200 --> 00:08:14,584
شما فکر می کنید که کلیدها هر زمان که دقیقاً با 

119
00:08:14,584 --> 00:08:17,020
یکدیگر همسو می شوند، با پرس و جوها مطابقت دارند.

120
00:08:17,460 --> 00:08:21,798
در مثال ما، تصور می‌کنید که ماتریس کلید صفت‌هایی مانند کرکی و آبی را به 

121
00:08:21,798 --> 00:08:26,740
بردارهایی نگاشت می‌کند که دقیقاً با پرس و جو تولید شده توسط کلمه مخلوق همسو هستند.

122
00:08:27,200 --> 00:08:30,457
برای اندازه‌گیری میزان مطابقت هر کلید با هر پرس و جو، یک 

123
00:08:30,457 --> 00:08:34,000
محصول نقطه‌ای را بین هر جفت کلید پرس و جو ممکن محاسبه می‌کنید.

124
00:08:34,480 --> 00:08:38,617
من دوست دارم شبکه‌ای پر از یک دسته نقطه را تجسم کنم، جایی که نقاط بزرگ‌تر با محصولات 

125
00:08:38,617 --> 00:08:42,559
نقطه‌ای بزرگ‌تر، مکان‌هایی که کلیدها و پرس و جوها در آن تراز هستند، مطابقت دارند.

126
00:08:43,280 --> 00:08:48,382
برای مثال اسم صفت ما، کمی بیشتر شبیه این به نظر می رسد، جایی که اگر کلیدهای 

127
00:08:48,382 --> 00:08:53,485
تولید شده توسط کرکی و آبی واقعاً با جستار تولید شده توسط مخلوق مطابقت داشته 

128
00:08:53,485 --> 00:08:58,320
باشند، آنگاه محصولات نقطه ای در این دو نقطه اعداد مثبت بزرگی خواهند بود.

129
00:08:59,100 --> 00:09:02,316
در زبان انگلیسی، افراد یادگیری ماشینی می‌گویند که این به 

130
00:09:02,316 --> 00:09:05,420
معنای تعبیه رنگ‌های کرکی و آبی برای جاسازی موجودات است.

131
00:09:06,040 --> 00:09:11,423
بر خلاف حاصل ضرب نقطه ای بین کلید برای یک کلمه دیگر مانند the و پرس و جو برای 

132
00:09:11,423 --> 00:09:16,600
مخلوق مقداری کوچک یا منفی است که منعکس کننده موارد غیر مرتبط با یکدیگر است.

133
00:09:17,700 --> 00:09:21,154
بنابراین ما این شبکه‌ای از مقادیر را داریم که می‌تواند هر 

134
00:09:21,154 --> 00:09:24,846
عدد واقعی از بی‌نهایت منفی تا بی‌نهایت باشد، که به ما امتیازی 

135
00:09:24,846 --> 00:09:28,480
برای ارتباط هر کلمه با به‌روزرسانی معنای هر کلمه دیگر می‌دهد.

136
00:09:29,200 --> 00:09:32,440
روشی که می‌خواهیم از این امتیازها استفاده کنیم، این است که یک جمع 

137
00:09:32,440 --> 00:09:35,780
وزنی معین در امتداد هر ستون، وزن‌دهی شده بر اساس ربط، در نظر بگیریم.

138
00:09:36,520 --> 00:09:40,347
بنابراین به‌جای اینکه مقادیری از بی‌نهایت منفی تا بی‌نهایت داشته 

139
00:09:40,347 --> 00:09:44,175
باشیم، چیزی که می‌خواهیم این است که اعداد در این ستون‌ها بین 0 و 

140
00:09:44,175 --> 00:09:48,180
1 باشند و برای هر ستون تا 1 جمع شود، انگار که یک توزیع احتمال هستند.

141
00:09:49,280 --> 00:09:52,220
اگر از فصل آخر وارد می شوید، می دانید که باید چه کار کنیم.

142
00:09:52,620 --> 00:09:57,300
ما یک Softmax را در امتداد هر یک از این ستون ها محاسبه می کنیم تا مقادیر را عادی کنیم.

143
00:10:00,060 --> 00:10:03,149
در تصویر ما، پس از اعمال softmax به همه ستون‌ها، 

144
00:10:03,149 --> 00:10:05,860
شبکه را با این مقادیر نرمال شده پر می‌کنیم.

145
00:10:06,780 --> 00:10:10,770
در این مرحله شما مطمئن هستید که در مورد هر ستون به عنوان وزن دادن 

146
00:10:10,770 --> 00:10:14,580
با توجه به ارتباط کلمه سمت چپ با مقدار مربوطه در بالا فکر کنید.

147
00:10:15,080 --> 00:10:16,840
ما این شبکه را الگوی توجه می نامیم.

148
00:10:18,080 --> 00:10:20,345
حالا اگر به کاغذ ترانسفورماتور اصلی نگاه کنید، یک روش 

149
00:10:20,345 --> 00:10:22,820
واقعا فشرده وجود دارد که آنها همه اینها را یادداشت می کنند.

150
00:10:23,880 --> 00:10:29,445
در اینجا متغیرهای q و k به ترتیب آرایه‌های کامل بردارهای پرس و جو و کلید را نشان می‌دهند، 

151
00:10:29,445 --> 00:10:34,640
آن بردارهای کوچکی که با ضرب جاسازی‌ها در پرس و جو و ماتریس‌های کلید به دست می‌آورید.

152
00:10:35,160 --> 00:10:39,022
این عبارت در صورت‌حساب یک روش بسیار فشرده برای نشان دادن 

153
00:10:39,022 --> 00:10:43,020
شبکه تمام محصولات نقطه‌ای ممکن بین جفت کلید و پرس و جو است.

154
00:10:44,000 --> 00:10:48,757
یک جزئیات فنی کوچک که من به آن اشاره نکردم این است که برای ثبات 

155
00:10:48,757 --> 00:10:53,960
عددی، تقسیم همه این مقادیر بر جذر بعد در فضای پرس و جو کلیدی مفید است.

156
00:10:54,480 --> 00:10:57,671
سپس این softmax که در اطراف عبارت کامل پیچیده شده 

157
00:10:57,671 --> 00:11:00,800
است به این معنی است که ستون به ستون اعمال می شود.

158
00:11:01,640 --> 00:11:04,700
در مورد آن عبارت v، ما در یک ثانیه در مورد آن صحبت خواهیم کرد.

159
00:11:05,020 --> 00:11:08,460
قبل از آن، یک جزئیات فنی دیگر وجود دارد که تا کنون از آن صرفنظر کرده ام.

160
00:11:09,040 --> 00:11:13,692
در طول فرآیند آموزش، وقتی این مدل را بر روی یک مثال متنی خاص اجرا می‌کنید، 

161
00:11:13,692 --> 00:11:18,035
و همه وزن‌ها کمی تنظیم و تنظیم می‌شوند تا بر اساس احتمال بالایی که به 

162
00:11:18,035 --> 00:11:22,068
کلمه بعدی واقعی در متن اختصاص می‌دهد، آن را پاداش یا تنبیه کنید. 

163
00:11:22,068 --> 00:11:26,286
معلوم می‌شود که کل فرآیند آموزش را بسیار کارآمدتر می‌کند اگر همزمان 

164
00:11:26,286 --> 00:11:31,560
بخواهید هر توکن بعدی ممکن را پس از هر دنباله اولیه نشانه‌ها در این قسمت پیش‌بینی کند.

165
00:11:31,940 --> 00:11:35,693
برای مثال، با عبارتی که روی آن تمرکز کرده‌ایم، ممکن است پیش‌بینی 

166
00:11:35,693 --> 00:11:39,100
شود که چه کلماتی پس از مخلوق و چه کلماتی به دنبال آن هستند.

167
00:11:39,940 --> 00:11:42,681
این واقعاً خوب است، زیرا به این معنی است که آنچه در غیر این 

168
00:11:42,681 --> 00:11:45,560
صورت یک نمونه آموزشی واحد خواهد بود، به همان اندازه عمل می کند.

169
00:11:46,100 --> 00:11:49,573
برای اهداف الگوی توجه ما، به این معنی است که شما هرگز نمی خواهید 

170
00:11:49,573 --> 00:11:52,940
اجازه دهید کلمات بعدی بر کلمات قبلی تأثیر بگذارند، زیرا در غیر 

171
00:11:52,940 --> 00:11:56,040
این صورت آنها می توانند به نوعی پاسخ چیزهای بعدی را بدهند.

172
00:11:56,560 --> 00:12:00,555
این به این معنی است که ما می‌خواهیم همه این نقاط در اینجا، آنهایی که نشان‌دهنده 

173
00:12:00,555 --> 00:12:04,600
نشانه‌های بعدی هستند که بر موارد قبلی تأثیر می‌گذارند، به نحوی مجبور به صفر شوند.

174
00:12:05,920 --> 00:12:09,190
ساده ترین کاری که ممکن است انجام دهید این است که آنها را برابر با صفر قرار دهید، 

175
00:12:09,190 --> 00:12:12,420
اما اگر این کار را انجام دهید که ستون ها دیگر به یک جمع نمی شوند، عادی نمی شوند.

176
00:12:13,120 --> 00:12:15,953
بنابراین، در عوض، یک راه معمول برای انجام این کار این است که 

177
00:12:15,953 --> 00:12:19,020
قبل از اعمال softmax، همه آن ورودی‌ها را بی‌نهایت منفی تنظیم کنید.

178
00:12:19,680 --> 00:12:22,378
اگر این کار را انجام دهید، پس از اعمال softmax، همه 

179
00:12:22,378 --> 00:12:25,180
آن ها به صفر تبدیل می شوند، اما ستون ها عادی می مانند.

180
00:12:26,000 --> 00:12:27,540
به این فرآیند ماسکینگ می گویند.

181
00:12:27,540 --> 00:12:30,906
نسخه‌هایی از توجه وجود دارد که شما آن را به کار نمی‌برید، اما در مثال GPT 

182
00:12:30,906 --> 00:12:34,545
ما، حتی اگر این موضوع در طول مرحله آموزش بیشتر از زمانی که مثلاً آن را به‌عنوان 

183
00:12:34,545 --> 00:12:38,002
یک ربات چت یا چیزی شبیه به آن اجرا می‌کنید، مرتبط است، همیشه اعمال می‌کنید. 

184
00:12:38,002 --> 00:12:41,460
این پوشش برای جلوگیری از تأثیرگذاری توکن‌های بعدی بر روی نشانه‌های قبلی است.

185
00:12:42,480 --> 00:12:45,864
واقعیت دیگری که در مورد این الگوی توجه ارزش تأمل دارد 

186
00:12:45,864 --> 00:12:49,500
این است که چگونه اندازه آن با مربع اندازه زمینه برابر است.

187
00:12:49,900 --> 00:12:52,625
بنابراین به همین دلیل است که اندازه زمینه می‌تواند یک گلوگاه 

188
00:12:52,625 --> 00:12:55,620
واقعا بزرگ برای مدل‌های زبان بزرگ باشد و بزرگ‌کردن آن بی‌اهمیت است.

189
00:12:56,300 --> 00:13:00,098
همانطور که تصور می کنید، با انگیزه میل به پنجره های زمینه بزرگتر و 

190
00:13:00,098 --> 00:13:03,954
بزرگتر، در سالهای اخیر تغییراتی در مکانیسم توجه با هدف افزایش مقیاس 

191
00:13:03,954 --> 00:13:08,320
پذیری زمینه مشاهده شده است، اما در اینجا، من و شما بر روی اصول تمرکز می کنیم.

192
00:13:10,560 --> 00:13:13,020
خوب، عالی است، محاسبه این الگو به مدل اجازه می دهد 

193
00:13:13,020 --> 00:13:15,480
تا بفهمد کدام کلمات با کدام کلمات دیگر مرتبط هستند.

194
00:13:16,020 --> 00:13:19,274
اکنون باید در واقع جاسازی‌ها را به‌روزرسانی کنید و به کلمات 

195
00:13:19,274 --> 00:13:22,800
اجازه دهید اطلاعات را به هر کلمه دیگری که مرتبط هستند منتقل کنند.

196
00:13:22,800 --> 00:13:26,646
به عنوان مثال، شما می خواهید که تعبیه Fluffy به نحوی باعث تغییر 

197
00:13:26,646 --> 00:13:30,673
در Creature شود که آن را به قسمت دیگری از این فضای تعبیه شده 12000 

198
00:13:30,673 --> 00:13:34,520
بعدی منتقل کند که به طور خاص یک موجود Fluffy را رمزگذاری می کند.

199
00:13:35,460 --> 00:13:38,073
کاری که من در اینجا انجام می‌دهم این است که ابتدا ساده‌ترین روشی 

200
00:13:38,073 --> 00:13:40,686
را که می‌توانید این کار را انجام دهید، به شما نشان می‌دهم، اگرچه 

201
00:13:40,686 --> 00:13:43,460
روشی جزئی وجود دارد که این روش در چارچوب توجه چند جانبه اصلاح می‌شود.

202
00:13:44,080 --> 00:13:48,033
ساده‌ترین راه استفاده از ماتریس سوم است، چیزی که ماتریس ارزش 

203
00:13:48,033 --> 00:13:52,440
می‌نامیم، که آن را در جاسازی کلمه اول ضرب می‌کنید، برای مثال Fluffy.

204
00:13:53,300 --> 00:13:57,470
نتیجه این چیزی است که شما آن را بردار مقدار می نامید، و این چیزی است که به 

205
00:13:57,470 --> 00:14:01,920
تعبیه کلمه دوم اضافه می کنید، در این مورد چیزی را به جاسازی مخلوق اضافه می کنید.

206
00:14:02,600 --> 00:14:07,000
بنابراین این بردار مقدار در همان فضای بسیار بابعد جاسازی ها زندگی می کند.

207
00:14:07,460 --> 00:14:12,026
وقتی این ماتریس مقدار را در تعبیه یک کلمه ضرب می کنید، ممکن است فکر 

208
00:14:12,026 --> 00:14:16,459
کنید که می گوید، اگر این کلمه با تعدیل معنای چیز دیگری مرتبط است، 

209
00:14:16,459 --> 00:14:21,160
دقیقاً چه چیزی باید به جاسازی آن چیز دیگر اضافه شود تا منعکس شود. این؟

210
00:14:22,140 --> 00:14:26,882
با نگاهی به نمودار خود، بیایید همه کلیدها و پرس و جوها را کنار بگذاریم، زیرا 

211
00:14:26,882 --> 00:14:31,563
پس از محاسبه الگوی توجه که با آن‌ها تمام شد، این ماتریس مقدار را گرفته و در 

212
00:14:31,563 --> 00:14:36,060
هر یک از آن جاسازی‌ها ضرب می‌کنیم. برای تولید دنباله ای از بردارهای ارزش.

213
00:14:37,120 --> 00:14:41,120
ممکن است فکر کنید این بردارهای مقدار به نوعی با کلیدهای مربوطه مرتبط هستند.

214
00:14:42,320 --> 00:14:45,780
برای هر ستون در این نمودار، هر یک از بردارهای 

215
00:14:45,780 --> 00:14:49,240
مقدار را در وزن مربوطه در آن ستون ضرب می کنید.

216
00:14:50,080 --> 00:14:53,790
به عنوان مثال، در اینجا، تحت تعبیه Creature، می‌توانید نسبت‌های 

217
00:14:53,790 --> 00:14:57,617
زیادی از بردارهای مقدار را برای Fluffy و Blue اضافه کنید، در حالی 

218
00:14:57,617 --> 00:15:01,560
که تمام بردارهای ارزش دیگر صفر می‌شوند یا حداقل تقریباً صفر می‌شوند.

219
00:15:02,120 --> 00:15:06,352
و سپس در نهایت، روشی برای به روز رسانی واقعی جاسازی مرتبط با این ستون، که قبلاً 

220
00:15:06,352 --> 00:15:10,531
برخی از معنای بدون متن Creature را رمزگذاری می کرد، همه این مقادیر تغییر مقیاس 

221
00:15:10,531 --> 00:15:14,710
شده را در ستون با هم جمع می کنید، و تغییری را ایجاد می کنید که می خواهید اضافه 

222
00:15:14,710 --> 00:15:19,260
کنید، که I&#39; ll delta-e را برچسب گذاری کنید، و سپس آن را به جاسازی اصلی اضافه کنید.

223
00:15:19,680 --> 00:15:23,013
امیدواریم آنچه که در نتیجه حاصل می‌شود، یک بردار دقیق‌تر باشد که 

224
00:15:23,013 --> 00:15:26,500
معنای غنی‌تر از نظر بافتی را رمزگذاری می‌کند، مانند موجودی آبی کرکی.

225
00:15:27,380 --> 00:15:31,451
و البته شما این کار را فقط برای یک جاسازی انجام نمی‌دهید، بلکه جمع وزنی یکسانی 

226
00:15:31,451 --> 00:15:35,316
را در تمام ستون‌های این تصویر اعمال می‌کنید، دنباله‌ای از تغییرات را ایجاد 

227
00:15:35,316 --> 00:15:39,440
می‌کنید، همه آن تغییرات را به جاسازی‌های مربوطه اضافه می‌کنید، و یک دنباله کامل 

228
00:15:39,440 --> 00:15:43,460
از تغییرات را ایجاد می‌کنید. تعبیه‌های دقیق‌تری که از بلوک توجه بیرون می‌آیند.

229
00:15:44,860 --> 00:15:49,100
با زوم کردن، کل این فرآیند همان چیزی است که شما به عنوان یک سر توجه توصیف می کنید.

230
00:15:49,600 --> 00:15:53,892
همانطور که تا کنون موارد را توضیح داده‌ام، این فرآیند توسط سه ماتریس مجزا 

231
00:15:53,892 --> 00:15:58,940
پارامتربندی می‌شود که همگی با پارامترهای قابل تنظیم، کلید، پرس و جو و مقدار پر شده‌اند.

232
00:15:59,500 --> 00:16:03,796
می‌خواهم لحظه‌ای وقت بگذارم و کاری را که در فصل آخر شروع کردیم، با حفظ امتیاز که 

233
00:16:03,796 --> 00:16:08,040
در آن تعداد کل پارامترهای مدل را با استفاده از اعداد GPT-3 می‌شماریم، ادامه دهم.

234
00:16:09,300 --> 00:16:14,450
این ماتریس های کلید و پرس و جو هر کدام دارای 12288 ستون هستند که با بعد تعبیه 

235
00:16:14,450 --> 00:16:19,600
شده مطابقت دارند و 128 ردیف که با بعد فضای پرس و جوی کلید کوچکتر مطابقت دارند.

236
00:16:20,260 --> 00:16:24,220
این به ما 1.5 میلیون یا بیشتر پارامتر اضافی برای هر یک می دهد.

237
00:16:24,860 --> 00:16:30,213
اگر به آن ماتریس مقدار برعکس نگاه کنید، روشی که من تا اینجا توضیح دادم 

238
00:16:30,213 --> 00:16:35,717
نشان می دهد که این ماتریس مربعی است که دارای 12288 ستون و 12288 سطر است، 

239
00:16:35,717 --> 00:16:40,920
زیرا ورودی و خروجی هر دو در این فضای جاسازی بسیار بزرگ زندگی می کنند.

240
00:16:41,500 --> 00:16:45,140
اگر درست باشد، حدود 150 میلیون پارامتر اضافه شده است.

241
00:16:45,660 --> 00:16:47,300
و برای واضح بودن، شما می توانید این کار را انجام دهید.

242
00:16:47,420 --> 00:16:51,740
شما می توانید مقادیر بیشتری پارامتر را به نقشه مقدار اختصاص دهید تا کلید و پرس و جو.

243
00:16:52,060 --> 00:16:56,227
اما در عمل، بسیار کارآمدتر است اگر در عوض آن را طوری بسازید که تعداد پارامترهای 

244
00:16:56,227 --> 00:17:00,760
اختصاص داده شده به این نقشه مقدار با عدد اختصاص داده شده به کلید و پرس و جو یکسان باشد.

245
00:17:01,460 --> 00:17:05,160
این امر به ویژه در تنظیم اجرای موازی سرهای توجه متعدد مرتبط است.

246
00:17:06,240 --> 00:17:08,051
شکلی که به نظر می رسد این است که نقشه ارزش به 

247
00:17:08,051 --> 00:17:10,099
عنوان حاصل ضرب دو ماتریس کوچکتر در نظر گرفته می شود.

248
00:17:11,180 --> 00:17:15,503
از نظر مفهومی، من همچنان شما را تشویق می‌کنم که به نقشه خطی کلی فکر کنید، 

249
00:17:15,503 --> 00:17:19,651
نقشه‌ای با ورودی‌ها و خروجی‌ها، هر دو در این فضای جاسازی بزرگ‌تر، برای 

250
00:17:19,651 --> 00:17:23,800
مثال تعبیه رنگ آبی را به این جهت آبی که می‌توانید به اسم‌ها اضافه کنید.

251
00:17:27,040 --> 00:17:32,760
فقط این است که تعداد ردیف‌های کمتری است، معمولاً به اندازه فضای جستجوی کلید.

252
00:17:33,100 --> 00:17:35,721
این به این معنی است که می توانید آن را به عنوان نگاشت 

253
00:17:35,721 --> 00:17:38,440
بردارهای جاسازی بزرگ در فضای بسیار کوچکتر در نظر بگیرید.

254
00:17:39,040 --> 00:17:42,700
این نامگذاری مرسوم نیست، اما من آن را ماتریس مقدار پایین می نامم.

255
00:17:43,400 --> 00:17:46,739
ماتریس دوم از این فضای کوچکتر به فضای تعبیه شده برمی گردد و 

256
00:17:46,739 --> 00:17:50,580
بردارهایی را تولید می کند که برای به روز رسانی واقعی استفاده می کنید.

257
00:17:51,000 --> 00:17:54,740
من این یکی را ماتریس ارزش بالا می‌نامم که باز هم متعارف نیست.

258
00:17:55,160 --> 00:17:58,080
روشی که این نوشته را در اکثر مقالات مشاهده می کنید کمی متفاوت به نظر می رسد.

259
00:17:58,380 --> 00:17:59,520
یک دقیقه دیگر در مورد آن صحبت خواهم کرد.

260
00:17:59,700 --> 00:18:02,540
به نظر من، این امر باعث می شود همه چیز از نظر مفهومی گیج کننده تر شود.

261
00:18:03,260 --> 00:18:06,800
برای استفاده از اصطلاحات جبر خطی در اینجا، کاری که ما اساساً انجام می 

262
00:18:06,800 --> 00:18:10,340
دهیم این است که نقشه ارزش کلی را به یک تبدیل رتبه پایین محدود می کنیم.

263
00:18:11,420 --> 00:18:16,100
با برگشت به تعداد پارامترها، هر چهار این ماتریس دارای اندازه یکسانی هستند و 

264
00:18:16,100 --> 00:18:20,780
با جمع کردن همه آنها، حدود 6.3 میلیون پارامتر برای یک سر توجه به دست می‌آید.

265
00:18:22,040 --> 00:18:25,095
به عنوان یک یادداشت جانبی سریع، برای کمی دقیق تر، همه چیزهایی که تا کنون 

266
00:18:25,095 --> 00:18:28,193
شرح داده شده است چیزی است که مردم آن را سر توجه به خود می نامند، تا آن را 

267
00:18:28,193 --> 00:18:31,500
از تنوعی که در مدل های دیگر وجود دارد که به آن توجه متقاطع می گویند متمایز شود.

268
00:18:32,300 --> 00:18:37,740
این به مثال GPT ما مربوط نیست، اما اگر کنجکاو هستید، توجه متقابل شامل مدل‌هایی 

269
00:18:37,740 --> 00:18:43,455
می‌شود که دو نوع داده متمایز را پردازش می‌کنند، مانند متن در یک زبان و متن در زبان 

270
00:18:43,455 --> 00:18:49,240
دیگر که بخشی از نسل جاری ترجمه است. یا شاید ورودی صوتی گفتار و رونویسی در حال انجام.

271
00:18:50,400 --> 00:18:52,700
یک سر متقاطع تقریباً یکسان به نظر می رسد.

272
00:18:52,980 --> 00:18:57,400
تنها تفاوت این است که نقشه های کلید و پرس و جو بر روی مجموعه داده های مختلف عمل می کنند.

273
00:18:57,840 --> 00:19:01,615
برای مثال، در مدلی که ترجمه انجام می دهد، کلیدها ممکن است از یک زبان 

274
00:19:01,615 --> 00:19:05,391
بیایند، در حالی که پرس و جوها از زبان دیگری می آیند، و الگوی توجه می 

275
00:19:05,391 --> 00:19:09,660
تواند توصیف کند که کدام کلمه از یک زبان با کدام کلمه در زبان دیگر مطابقت دارد.

276
00:19:10,340 --> 00:19:13,384
و در این تنظیمات معمولاً هیچ پوششی وجود نخواهد داشت، زیرا واقعاً هیچ 

277
00:19:13,384 --> 00:19:16,340
مفهومی از نشانه‌های بعدی وجود ندارد که بر موارد قبلی تأثیر بگذارند.

278
00:19:17,180 --> 00:19:21,228
با این حال، با تمرکز بر توجه خود، اگر تا اینجا همه چیز را درک می کردید، و اگر قرار 

279
00:19:21,228 --> 00:19:25,180
بود در اینجا متوقف شوید، با جوهره آنچه که توجه واقعاً وجود دارد، از بین می رفتید.

280
00:19:25,760 --> 00:19:28,646
تنها چیزی که واقعاً برای ما باقی می‌ماند این است که حسی را که 

281
00:19:28,646 --> 00:19:31,440
در آن این کار را در زمان‌های مختلف انجام می‌دهید، بیان کنیم.

282
00:19:32,100 --> 00:19:35,998
در مثال اصلی خود، ما روی صفت‌هایی که اسم‌ها را به‌روز می‌کنند، تمرکز کردیم، اما 

283
00:19:35,998 --> 00:19:39,800
البته راه‌های مختلفی وجود دارد که بافت می‌تواند بر معنای یک کلمه تأثیر بگذارد.

284
00:19:40,360 --> 00:19:43,666
اگر کلماتی که آنها تصادف کردند، مقدم بر کلمه ماشین 

285
00:19:43,666 --> 00:19:46,520
باشد، برای شکل و ساختار آن ماشین تاثیر دارد.

286
00:19:47,200 --> 00:19:49,280
و بسیاری از تداعی ها ممکن است دستوری کمتری داشته باشند.

287
00:19:49,760 --> 00:19:54,572
اگر کلمه جادوگر جایی در همان قسمت هری باشد، نشان می‌دهد که این ممکن است به هری 

288
00:19:54,572 --> 00:19:59,506
پاتر اشاره داشته باشد، در حالی که اگر به جای آن کلمات ملکه، ساسکس و ویلیام در آن 

289
00:19:59,506 --> 00:20:04,440
قسمت وجود داشته باشند، شاید جاسازی هری باید به‌روزرسانی شود. رجوع به شاهزاده شود.

290
00:20:05,040 --> 00:20:09,584
برای هر نوع متفاوتی از به‌روزرسانی زمینه‌ای که ممکن است تصور کنید، پارامترهای 

291
00:20:09,584 --> 00:20:14,187
این ماتریس‌های کلید و پرس‌وجو برای جلب الگوهای مختلف توجه متفاوت خواهند بود، و 

292
00:20:14,187 --> 00:20:19,140
پارامترهای نقشه ارزش ما بر اساس آنچه که باید به جاسازی‌ها اضافه شود متفاوت خواهد بود.

293
00:20:19,980 --> 00:20:23,333
و باز هم، در عمل، تفسیر رفتار واقعی این نقشه‌ها بسیار دشوارتر است، 

294
00:20:23,333 --> 00:20:26,636
جایی که وزن‌ها برای انجام هر کاری که مدل به آن‌ها نیاز دارد انجام 

295
00:20:26,636 --> 00:20:30,140
می‌دهند تا به بهترین شکل به هدف خود یعنی پیش‌بینی نشانه بعدی دست یابد.

296
00:20:31,400 --> 00:20:35,068
همانطور که قبلاً گفتم، هر چیزی که توضیح دادیم یک سر توجه است، و یک بلوک 

297
00:20:35,068 --> 00:20:38,634
توجه کامل در داخل یک ترانسفورماتور شامل چیزی است که به آن توجه چند سر 

298
00:20:38,634 --> 00:20:42,251
می گویند، که در آن شما تعداد زیادی از این عملیات را به صورت موازی اجرا 

299
00:20:42,251 --> 00:20:45,920
می کنید، که هر کدام یک جستجوی کلیدی مجزای خود را دارند. و نقشه های ارزشی

300
00:20:47,420 --> 00:20:51,700
برای مثال GPT-3 از 96 سر توجه در داخل هر بلوک استفاده می کند.

301
00:20:52,020 --> 00:20:56,460
با توجه به اینکه هر یک از آنها کمی گیج کننده است، مطمئناً باید در ذهن خود نگه دارید.

302
00:20:56,760 --> 00:21:00,770
فقط برای اینکه همه چیز را خیلی واضح بیان کنیم، این بدان معناست که شما 96 

303
00:21:00,770 --> 00:21:05,000
کلید متمایز و ماتریس پرس و جو دارید که 96 الگوی توجه متمایز را تولید می کنند.

304
00:21:05,440 --> 00:21:08,810
سپس هر هد دارای ماتریس های ارزش مجزای خاص خود است 

305
00:21:08,810 --> 00:21:12,180
که برای تولید 96 دنباله بردار ارزش استفاده می شود.

306
00:21:12,460 --> 00:21:16,680
همه اینها با استفاده از الگوهای توجه مربوطه به عنوان وزن با هم جمع می شوند.

307
00:21:17,480 --> 00:21:22,078
این بدان معناست که برای هر موقعیت در زمینه، هر نشانه، هر یک از این 

308
00:21:22,078 --> 00:21:27,020
هدها یک تغییر پیشنهادی ایجاد می کند تا به جاسازی در آن موقعیت اضافه شود.

309
00:21:27,660 --> 00:21:31,621
بنابراین کاری که انجام می دهید این است که تمام تغییرات پیشنهادی را با هم جمع 

310
00:21:31,621 --> 00:21:35,480
می کنید، یکی برای هر سر، و نتیجه را به جاسازی اصلی آن موقعیت اضافه می کنید.

311
00:21:36,660 --> 00:21:42,205
کل این مجموع در اینجا یک تکه از آنچه از این بلوک توجه چند سر به دست می آید، 

312
00:21:42,205 --> 00:21:47,460
یک تکه از آن جاسازی های تصفیه شده است که از انتهای دیگر آن بیرون می آید.

313
00:21:48,320 --> 00:21:50,135
باز هم، این موضوع جای تامل زیادی دارد، بنابراین 

314
00:21:50,135 --> 00:21:52,140
اگر کمی طول کشید تا در آن غرق شوید اصلا نگران نباشید.

315
00:21:52,380 --> 00:21:57,032
ایده کلی این است که با اجرای موازی سرهای متمایز، به مدل این ظرفیت را 

316
00:21:57,032 --> 00:22:01,820
می‌دهید که روش‌های متمایز زیادی را بیاموزد که متن معنا را تغییر می‌دهد.

317
00:22:03,700 --> 00:22:09,283
با بالا بردن آمار تعداد پارامترها با 96 سر، که هر کدام شامل تغییرات خاص خود از 

318
00:22:09,283 --> 00:22:15,080
این چهار ماتریس است، هر بلوک از توجه چند سر به حدود 600 میلیون پارامتر ختم می شود.

319
00:22:16,420 --> 00:22:19,032
یک چیز کمی آزاردهنده اضافه شده است که من واقعاً باید برای هر یک از 

320
00:22:19,032 --> 00:22:21,800
شما که به خواندن بیشتر در مورد ترانسفورماتورها ادامه می دهید اشاره کنم.

321
00:22:22,080 --> 00:22:25,760
به یاد دارید که چگونه گفتم که نقشه ارزش در این دو ماتریس مجزا قرار می گیرد 

322
00:22:25,760 --> 00:22:29,440
که من آنها را به عنوان ماتریس های مقدار پایین و ارزش بالا برچسب گذاری کردم.

323
00:22:29,960 --> 00:22:34,227
روشی که من چیزها را چارچوب بندی کردم نشان می دهد که شما این جفت ماتریس را در 

324
00:22:34,227 --> 00:22:38,440
داخل هر سر توجه ببینید و کاملاً می توانید آن را از این طریق پیاده سازی کنید.

325
00:22:38,640 --> 00:22:39,920
این یک طرح معتبر خواهد بود.

326
00:22:40,260 --> 00:22:42,633
اما نحوه ای که شما این را می بینید که در مقالات نوشته 

327
00:22:42,633 --> 00:22:44,920
شده و نحوه اجرای آن در عمل کمی متفاوت به نظر می رسد.

328
00:22:45,340 --> 00:22:51,001
همه این ماتریس‌های افزایش ارزش برای هر هد در یک ماتریس غول‌پیکر که ماتریس خروجی 

329
00:22:51,001 --> 00:22:56,380
نامیده می‌شود، منگنه شده به نظر می‌رسند که با کل بلوک توجه چند سر مرتبط است.

330
00:22:56,820 --> 00:23:00,312
و وقتی می‌بینید که مردم به ماتریس ارزش برای یک سر توجه معین اشاره 

331
00:23:00,312 --> 00:23:03,752
می‌کنند، معمولاً فقط به این مرحله اول اشاره می‌کنند، مرحله‌ای که 

332
00:23:03,752 --> 00:23:07,140
من آن را به عنوان کاهش ارزش در فضای کوچک‌تر برچسب‌گذاری می‌کردم.

333
00:23:08,340 --> 00:23:11,040
برای کنجکاوهای شما، یادداشتی روی صفحه در مورد آن گذاشتم.

334
00:23:11,260 --> 00:23:14,900
این یکی از آن جزئیاتی است که خطر منحرف شدن توجه از نکات مفهومی اصلی را دارد، اما 

335
00:23:14,900 --> 00:23:18,540
من می‌خواهم آن را بیان کنم تا اگر در منابع دیگر در این مورد مطالعه کردید، بدانید.

336
00:23:19,240 --> 00:23:23,693
با کنار گذاشتن تمام نکات ظریف فنی، در پیش‌نمایش فصل آخر دیدیم که چگونه داده‌هایی که 

337
00:23:23,693 --> 00:23:28,040
از طریق یک ترانسفورماتور جریان می‌یابند، فقط از طریق یک بلوک توجه جریان نمی‌یابند.

338
00:23:28,640 --> 00:23:32,700
برای یک چیز، آن را از طریق سایر عملیات به نام پرسپترون چند لایه نیز انجام می دهد.

339
00:23:33,120 --> 00:23:34,880
در فصل بعدی بیشتر در مورد آنها صحبت خواهیم کرد.

340
00:23:35,180 --> 00:23:39,320
و سپس بارها و بارها از طریق بسیاری از کپی های بسیاری از هر دوی این عملیات می گذرد.

341
00:23:39,980 --> 00:23:44,950
این به این معنی است که پس از اینکه یک کلمه معین بخشی از بافت خود را در بر می گیرد، 

342
00:23:44,950 --> 00:23:50,040
شانس بیشتری برای این تعبیه ظریف تر وجود دارد که تحت تأثیر محیط ظریف تر خود قرار گیرد.

343
00:23:50,940 --> 00:23:55,050
هر چه در شبکه جلوتر می روید و هر جاسازی از همه جاسازی های دیگر معنی 

344
00:23:55,050 --> 00:23:58,978
بیشتری پیدا می کند، که خود آنها بیشتر و بیشتر ظریف می شوند، امید 

345
00:23:58,978 --> 00:24:03,028
این است که ظرفیت رمزگذاری ایده های سطح بالاتر و انتزاعی تر در مورد 

346
00:24:03,028 --> 00:24:07,320
یک موضوع خاص وجود داشته باشد. ورودی فراتر از توصیفگرها و ساختار دستوری.

347
00:24:07,880 --> 00:24:11,474
چیزهایی مانند احساس و لحن و اینکه آیا این یک شعر است و چه 

348
00:24:11,474 --> 00:24:15,130
حقایق علمی زیربنایی مربوط به قطعه و مواردی از این قبیل است.

349
00:24:16,700 --> 00:24:22,565
اگر یک بار دیگر به امتیازدهی خود برگردیم، GPT-3 شامل 96 لایه مجزا است، بنابراین تعداد 

350
00:24:22,565 --> 00:24:28,430
کل پارامترهای پرس و جو و ارزش کلیدی در 96 مورد دیگر ضرب می شود که مجموع کل را به کمتر 

351
00:24:28,430 --> 00:24:34,500
از 58 میلیارد پارامتر متمایز می رساند که به همه پارامترها اختصاص داده شده است. سرهای توجه

352
00:24:34,980 --> 00:24:40,940
این بسیار زیاد است، اما تنها یک سوم از 175 میلیاردی است که در کل شبکه وجود دارد.

353
00:24:41,520 --> 00:24:44,631
بنابراین حتی اگر توجه همه توجه را به خود جلب کند، اکثر 

354
00:24:44,631 --> 00:24:48,140
پارامترها از بلوک هایی می آیند که در بین این مراحل قرار دارند.

355
00:24:48,560 --> 00:24:51,132
در فصل بعدی، من و شما بیشتر در مورد آن بلوک های دیگر 

356
00:24:51,132 --> 00:24:53,560
و همچنین در مورد روند آموزش بیشتر صحبت خواهیم کرد.

357
00:24:54,120 --> 00:24:58,768
بخش بزرگی از داستان موفقیت مکانیسم توجه، رفتار خاصی نیست که آن را قادر می 

358
00:24:58,768 --> 00:25:03,354
سازد، بلکه این واقعیت است که بسیار موازی پذیر است، به این معنی که شما می 

359
00:25:03,354 --> 00:25:08,380
توانید تعداد زیادی محاسبات را در مدت زمان کوتاهی با استفاده از GPU انجام دهید. .

360
00:25:09,460 --> 00:25:13,232
با توجه به اینکه یکی از درس‌های مهم در مورد یادگیری عمیق در یکی دو دهه اخیر این 

361
00:25:13,232 --> 00:25:17,287
بوده است که مقیاس به تنهایی پیشرفت‌های کیفی زیادی را در عملکرد مدل به ارمغان می‌آورد، 

362
00:25:17,287 --> 00:25:21,060
معماری‌های موازی‌پذیر مزیت بزرگی دارند که به شما اجازه انجام این کار را می‌دهند.

363
00:25:22,040 --> 00:25:25,340
اگر می خواهید در مورد این چیزها بیشتر بدانید، لینک های زیادی در توضیحات گذاشته ام.

364
00:25:25,920 --> 00:25:30,040
به طور خاص، هر چیزی که توسط آندری کارپاتی یا کریس اولا تولید می شود، طلای خالص است.

365
00:25:30,560 --> 00:25:34,464
در این ویدیو، من می‌خواستم به شکل کنونی آن توجه را جلب کنم، اما اگر کنجکاو هستید درباره 

366
00:25:34,464 --> 00:25:38,369
تاریخچه‌ای که چگونه به اینجا رسیده‌ایم و چگونه می‌توانید این ایده را برای خودتان دوباره 

367
00:25:38,369 --> 00:25:40,587
ابداع کنید، دوست من Vivek فقط یک زوج را مطرح کرد. 

368
00:25:40,587 --> 00:25:42,540
ویدئوهایی که انگیزه بیشتری را ارائه می دهند.

369
00:25:43,120 --> 00:25:45,667
همچنین بریت کروز از کانال The Art of the Problem یک 

370
00:25:45,667 --> 00:25:48,460
ویدیوی واقعا زیبا در مورد تاریخچه مدل های زبان بزرگ دارد.

371
00:26:04,960 --> 00:26:09,200
متشکرم.

