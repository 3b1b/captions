[
 {
  "input": "In the last chapter, you and I started to step through the internal workings of a transformer.",
  "translatedText": "지난 장에서 여러분과 저는 변압기의 내부 작동 원리를 살펴봤습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.02
 },
 {
  "input": "This is one of the key pieces of technology inside large language models, and a lot of other tools in the modern wave of AI.",
  "translatedText": "이는 대규모 언어 모델과 최신 AI 물결의 다른 많은 도구에서 핵심적인 기술 중 하나입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 4.56,
  "end": 10.2
 },
 {
  "input": "It first hit the scene in a now-famous 2017 paper called Attention is All You Need, and in this chapter you and I will dig into what this attention mechanism is, visualizing how it processes data.",
  "translatedText": "주의 집중은 이제 유명한 2017년 논문 '주의 집중이 필요한 모든 것'에서 처음 소개되었으며, 이 장에서는 이 주의 집중 메커니즘이 무엇인지 자세히 살펴보고 데이터를 처리하는 방법을 시각화하여 설명합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 10.98,
  "end": 21.7
 },
 {
  "input": "As a quick recap, here's the important context I want you to have in mind.",
  "translatedText": "간단히 요약하면 다음과 같은 중요한 맥락을 염두에 두시기 바랍니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 26.14,
  "end": 29.54
 },
 {
  "input": "The goal of the model that you and I are studying is to take in a piece of text and predict what word comes next.",
  "translatedText": "여러분과 제가 연구하고 있는 모델의 목표는 텍스트 조각을 받아 다음에 어떤 단어가 나올지 예측하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 30.0,
  "end": 36.06
 },
 {
  "input": "The input text is broken up into little pieces that we call tokens, and these are very often words or pieces of words, but just to make the examples in this video easier for you and me to think about, let's simplify by pretending that tokens are always just words.",
  "translatedText": "입력 텍스트는 토큰이라고 부르는 작은 조각으로 나뉘는데, 토큰은 단어 또는 단어 조각인 경우가 많지만 이 비디오의 예를 여러분과 제가 더 쉽게 생각할 수 있도록 토큰은 항상 단어라고 가정하여 단순화해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 36.86,
  "end": 50.56
 },
 {
  "input": "The first step in a transformer is to associate each token with a high-dimensional vector, what we call its embedding.",
  "translatedText": "트랜스포머의 첫 번째 단계는 각 토큰을 고차원 벡터와 연결하는 것으로, 이를 임베딩이라고 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 51.48,
  "end": 57.7
 },
 {
  "input": "The most important idea I want you to have in mind is how directions in this high-dimensional space of all possible embeddings can correspond with semantic meaning.",
  "translatedText": "제가 염두에 두었으면 하는 가장 중요한 아이디어는 이 고차원 공간에서 가능한 모든 임베딩의 방향이 의미론적 의미와 어떻게 일치할 수 있는지에 대한 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 57.7,
  "end": 67.0
 },
 {
  "input": "In the last chapter we saw an example for how direction can correspond to gender, in the sense that adding a certain step in this space can take you from the embedding of a masculine noun to the embedding of the corresponding feminine noun.",
  "translatedText": "지난 장에서 우리는 방향이 성별에 어떻게 대응할 수 있는지에 대한 예를 보았는데, 이 공간에 특정 단계를 추가하면 남성 명사의 내포에서 해당 여성 명사의 내포로 이동할 수 있다는 의미에서입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 67.68,
  "end": 79.64
 },
 {
  "input": "That's just one example you could imagine how many other directions in this high-dimensional space could correspond to numerous other aspects of a word's meaning.",
  "translatedText": "이 고차원 공간에서 얼마나 많은 다른 방향이 단어의 의미의 수많은 다른 측면에 대응할 수 있는지 상상할 수 있는 한 가지 예일 뿐입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 80.16,
  "end": 87.58
 },
 {
  "input": "The aim of a transformer is to progressively adjust these embeddings so that they don't merely encode an individual word, but instead they bake in some much, much richer contextual meaning.",
  "translatedText": "트랜스포머의 목표는 이러한 임베딩을 점진적으로 조정하여 단순히 개별 단어를 인코딩하는 것이 아니라 훨씬 더 풍부한 문맥적 의미를 담을 수 있도록 하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 88.8,
  "end": 99.18
 },
 {
  "input": "I should say up front that a lot of people find the attention mechanism, this key piece in a transformer, very confusing, so don't worry if it takes some time for things to sink in.",
  "translatedText": "많은 사람들이 트랜스포머의 핵심 요소인 주의 집중 메커니즘을 매우 혼란스럽게 생각하기 때문에 적응하는 데 시간이 걸리더라도 걱정하지 않아도 된다는 점을 미리 말씀드립니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 100.14,
  "end": 108.98
 },
 {
  "input": "I think that before we dive into the computational details and all the matrix multiplications, it's worth thinking about a couple examples for the kind of behavior that we want attention to enable.",
  "translatedText": "계산 세부 사항과 모든 행렬 곱셈에 대해 자세히 알아보기 전에 주의가 필요한 동작의 종류에 대해 몇 가지 예를 생각해 볼 필요가 있다고 생각합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 109.44,
  "end": 119.16
 },
 {
  "input": "Consider the phrases American true mole, one mole of carbon dioxide, and take a biopsy of the mole.",
  "translatedText": "미국의 진정한 두더지, 이산화탄소 한 점, 두더지 생검이라는 문구를 생각해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 120.14,
  "end": 126.22
 },
 {
  "input": "You and I know that the word mole has different meanings in each one of these, based on the context.",
  "translatedText": "여러분과 저는 두더지라는 단어가 문맥에 따라 각각 다른 의미를 가지고 있다는 것을 알고 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 126.7,
  "end": 130.9
 },
 {
  "input": "But after the first step of a transformer, the one that breaks up the text and associates each token with a vector, the vector that's associated with mole would be the same in all of these cases, because this initial token embedding is effectively a lookup table with no reference to the context.",
  "translatedText": "그러나 텍스트를 분할하고 각 토큰을 벡터와 연결하는 트랜스포머의 첫 번째 단계 이후에는 이 초기 토큰 임베딩이 사실상 컨텍스트를 참조하지 않는 조회 테이블이므로 두더지와 연관된 벡터는 모든 경우에 동일합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.36,
  "end": 146.22
 },
 {
  "input": "It's only in the next step of the transformer that the surrounding embeddings have the chance to pass information into this one.",
  "translatedText": "트랜스포머의 다음 단계에서만 주변 임베딩이 이 트랜스포머로 정보를 전달할 수 있는 기회를 갖게 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 146.62,
  "end": 153.1
 },
 {
  "input": "The picture you might have in mind is that there are multiple distinct directions in this embedding space encoding the multiple distinct meanings of the word mole, and that a well-trained attention block calculates what you need to add to the generic embedding to move it to one of these specific directions, as a function of the context.",
  "translatedText": "이 임베딩 공간에는 두더지라는 단어의 여러 가지 의미를 인코딩하는 여러 가지 방향이 있으며, 잘 훈련된 주의 블록은 문맥의 함수에 따라 일반 임베딩에 추가해야 할 내용을 계산하여 이러한 특정 방향 중 하나로 이동시킨다는 그림을 염두에 둘 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 153.82,
  "end": 171.8
 },
 {
  "input": "To take another example, consider the embedding of the word tower.",
  "translatedText": "다른 예를 들어 타워라는 단어를 임베드하는 경우를 생각해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 173.3,
  "end": 176.18
 },
 {
  "input": "This is presumably some very generic, non-specific direction in the space, associated with lots of other large, tall nouns.",
  "translatedText": "이것은 아마도 다른 많은 크고 키가 큰 명사와 연관된 매우 일반적이고 비특이적인 공간의 방향일 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 177.06,
  "end": 183.72
 },
 {
  "input": "If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update this vector so that it points in a direction that more specifically encodes the Eiffel tower, maybe correlated with vectors associated with Paris and France and things made of steel.",
  "translatedText": "이 단어 앞에 에펠이 바로 붙는다면, 이 벡터가 에펠탑을 더 구체적으로 인코딩하는 방향, 즉 파리와 프랑스 및 강철로 만들어진 것들과 연관된 벡터를 가리키도록 메커니즘이 업데이트되기를 원한다고 상상할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 184.02,
  "end": 199.06
 },
 {
  "input": "If it was also preceded by the word miniature, then the vector should be updated even further, so that it no longer correlates with large, tall things.",
  "translatedText": "앞에 미니어처라는 단어가 붙으면 벡터가 더 이상 크고 키가 큰 물건과 연관되지 않도록 더 업데이트해야 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 199.92,
  "end": 207.5
 },
 {
  "input": "More generally than just refining the meaning of a word, the attention block allows the model to move information encoded in one embedding to that of another, potentially ones that are quite far away, and potentially with information that's much richer than just a single word.",
  "translatedText": "주의 블록은 단순히 단어의 의미를 세분화하는 것 이상으로, 모델이 하나의 임베딩에 인코딩된 정보를 다른 임베딩의 정보, 잠재적으로는 상당히 멀리 떨어져 있는 정보, 단일 단어보다 훨씬 더 풍부한 정보로 이동할 수 있게 해줍니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 209.48,
  "end": 223.3
 },
 {
  "input": "What we saw in the last chapter was how after all of the vectors flow through the network, including many different attention blocks, the computation you perform to produce a prediction of the next token is entirely a function of the last vector in the sequence.",
  "translatedText": "지난 장에서 다양한 주의 블록을 포함한 모든 벡터가 네트워크를 통과한 후, 다음 토큰을 예측하기 위해 수행하는 계산은 전적으로 시퀀스의 마지막 벡터의 함수라는 것을 살펴보았습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 223.3,
  "end": 238.28
 },
 {
  "input": "Imagine, for example, that the text you input is most of an entire mystery novel, all the way up to a point near the end, which reads, therefore the murderer was.",
  "translatedText": "예를 들어, 입력한 텍스트가 추리 소설의 대부분을 차지하며, 마지막에 가까운 부분까지 '따라서 범인은 살인자였다'라고 쓰여 있다고 상상해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 239.1,
  "end": 247.8
 },
 {
  "input": "If the model is going to accurately predict the next word, that final vector in the sequence, which began its life simply embedding the word was, will have to have been updated by all of the attention blocks to represent much, much more than any individual word, somehow encoding all of the information from the full context window that's relevant to predicting the next word.",
  "translatedText": "모델이 다음 단어를 정확하게 예측하려면 단순히 단어가 포함된 시퀀스의 마지막 벡터가 모든 주의 블록에 의해 업데이트되어 개별 단어보다 훨씬 더 많은 정보를 나타내야 하며, 어떻게든 다음 단어 예측과 관련된 전체 컨텍스트 창에서 모든 정보를 인코딩해야 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.4,
  "end": 268.22
 },
 {
  "input": "To step through the computations, though, let's take a much simpler example.",
  "translatedText": "하지만 계산을 단계별로 살펴보기 위해 훨씬 더 간단한 예를 들어 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 269.5,
  "end": 272.58
 },
 {
  "input": "Imagine that the input includes the phrase, a fluffy blue creature roamed the verdant forest.",
  "translatedText": "입력에 '푸른 숲을 돌아다니는 푹신한 푸른 생물'이라는 문구가 포함되어 있다고 상상해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 272.98,
  "end": 277.96
 },
 {
  "input": "And for the moment, suppose that the only type of update that we care about is having the adjectives adjust the meanings of their corresponding nouns.",
  "translatedText": "지금은 우리가 신경 쓰는 유일한 업데이트 유형이 형용사가 해당 명사의 의미를 조정하는 것이라고 가정해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 278.46,
  "end": 286.78
 },
 {
  "input": "What I'm about to describe is what we would call a single head of attention, and later we will see how the attention block consists of many different heads run in parallel.",
  "translatedText": "제가 지금 설명하려는 것은 하나의 주의 집중 헤드라고 할 수 있으며, 나중에 주의 집중 블록이 어떻게 여러 개의 다른 헤드로 구성되어 병렬로 실행되는지 살펴보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 287.0,
  "end": 295.42
 },
 {
  "input": "Again, the initial embedding for each word is some high dimensional vector that only encodes the meaning of that particular word with no context.",
  "translatedText": "다시 말하지만, 각 단어에 대한 초기 임베딩은 문맥 없이 특정 단어의 의미만 인코딩하는 고차원 벡터입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 296.14,
  "end": 303.38
 },
 {
  "input": "Actually, that's not quite true.",
  "translatedText": "사실 그렇지 않습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 304.0,
  "end": 305.22
 },
 {
  "input": "They also encode the position of the word.",
  "translatedText": "또한 단어의 위치도 인코딩합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 305.38,
  "end": 307.64
 },
 {
  "input": "There's a lot more to say way that positions are encoded, but right now, all you need to know is that the entries of this vector are enough to tell you both what the word is and where it exists in the context.",
  "translatedText": "위치가 인코딩되는 방식에 대해서는 더 많은 이야기가 있지만, 지금은 이 벡터의 항목으로 단어가 무엇인지, 문맥에서 어디에 존재하는지 알 수 있다는 것만 알아두면 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 307.98,
  "end": 318.9
 },
 {
  "input": "Let's go ahead and denote these embeddings with the letter e.",
  "translatedText": "이제 이러한 임베딩을 문자 e로 표시해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 319.5,
  "end": 321.66
 },
 {
  "input": "The goal is to have a series of computations produce a new refined set of embeddings where, for example, those corresponding to the nouns have ingested the meaning from their corresponding adjectives.",
  "translatedText": "목표는 일련의 계산을 통해, 예를 들어 명사에 해당하는 단어가 해당 형용사에서 의미를 가져온 새로운 세련된 임베딩 집합을 생성하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 322.42,
  "end": 333.42
 },
 {
  "input": "And playing the deep learning game, we want most of the computations involved to look like matrix-vector products, where the matrices are full of tunable weights, things that the model will learn based on data.",
  "translatedText": "그리고 딥러닝 게임에서는 대부분의 계산이 행렬-벡터 곱처럼 보이기를 원하는데, 여기서 행렬은 조정 가능한 가중치로 가득 차 있으며 모델이 데이터를 기반으로 학습하게 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 333.9,
  "end": 343.98
 },
 {
  "input": "To be clear, I'm making up this example of adjectives updating nouns just to illustrate the type of behavior that you could imagine an attention head doing.",
  "translatedText": "명확히 말씀드리자면, 저는 주의 집중력이 있는 사람이 하는 행동의 유형을 설명하기 위해 형용사가 명사를 업데이트하는 이 예시를 만들어낸 것뿐입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 344.66,
  "end": 352.26
 },
 {
  "input": "As with so much deep learning, the true behavior is much harder to parse because it's based on tweaking and tuning a huge number of parameters to minimize some cost function.",
  "translatedText": "많은 딥러닝이 그렇듯이, 비용 함수를 최소화하기 위해 수많은 매개변수를 조정하고 조정하는 것을 기반으로 하기 때문에 실제 동작은 분석하기가 훨씬 더 어렵습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 352.86,
  "end": 361.34
 },
 {
  "input": "It's just that as we step through all of different matrices filled with parameters that are involved in this process, I think it's really helpful to have an imagined example of something that it could be doing to help keep it all more concrete.",
  "translatedText": "다만 이 프로세스에 관련된 매개변수로 채워진 다양한 행렬을 모두 살펴볼 때, 이 모든 것을 보다 구체적으로 파악하는 데 도움이 될 수 있는 상상의 예가 있으면 정말 도움이 될 것 같습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 361.68,
  "end": 373.22
 },
 {
  "input": "For the first step of this process, you might imagine each noun, like creature, asking the question, hey, are there any adjectives sitting in front of me?",
  "translatedText": "이 과정의 첫 번째 단계에서는 생물과 같은 각 명사가 '내 앞에 형용사가 있나요'라는 질문을 던지는 것을 상상해 볼 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 374.14,
  "end": 381.96
 },
 {
  "input": "And for the words fluffy and blue, to each be able to answer, yeah, I'm an adjective and I'm in that position.",
  "translatedText": "그리고 푹신푹신하고 파란색이라는 단어에 대해 각각 '예, 저는 형용사이고 그 위치에 있습니다'라고 대답할 수 있어야 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 382.16,
  "end": 387.96
 },
 {
  "input": "That question is somehow encoded as yet another vector, another list of numbers, which we call the query for this word.",
  "translatedText": "이 질문은 어떻게든 또 다른 벡터, 즉 숫자의 목록으로 인코딩되며, 이를 이 단어에 대한 쿼리라고 부릅니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 388.96,
  "end": 396.1
 },
 {
  "input": "This query vector though has a much smaller dimension than the embedding vector, say 128.",
  "translatedText": "하지만 이 쿼리 벡터는 임베딩 벡터보다 훨씬 작은 크기(예: 128)를 가집니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.98,
  "end": 402.02
 },
 {
  "input": "Computing this query looks like taking a certain matrix, which I'll label wq, and multiplying it by the embedding.",
  "translatedText": "이 쿼리를 계산하는 것은 특정 행렬을 가져와서 여기에 임베딩을 곱하는 것처럼 보입니다(wq라고 레이블을 붙이겠습니다).",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 402.94,
  "end": 409.78
 },
 {
  "input": "Compressing things a bit, let's write that query vector as q, and then anytime you see me put a matrix next to an arrow like this one, it's meant to represent that multiplying this matrix by the vector at the arrow's start gives you the vector at the arrow's end.",
  "translatedText": "조금 압축해서 쿼리 벡터를 q라고 쓰고, 이렇게 화살표 옆에 행렬을 표시한 것은 이 행렬에 화살표 시작 부분의 벡터를 곱하면 화살표 끝 부분의 벡터가 나온다는 것을 나타내기 위한 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 410.96,
  "end": 424.8
 },
 {
  "input": "In this case, you multiply this matrix by all of the embeddings in the context, producing one query vector for each token.",
  "translatedText": "이 경우 이 행렬에 컨텍스트의 모든 임베딩을 곱하여 각 토큰에 대해 하나의 쿼리 벡터를 생성합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.86,
  "end": 432.58
 },
 {
  "input": "The entries of this matrix are parameters of the model, which means the true behavior is learned from data, and in practice, what this matrix does in a particular attention head is challenging to parse.",
  "translatedText": "이 행렬의 항목은 모델의 매개변수로, 데이터에서 실제 행동을 학습한다는 의미이며, 실제로 이 행렬이 특정 주의력 헤드에서 수행하는 작업은 구문 분석하기가 어렵습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 433.74,
  "end": 443.44
 },
 {
  "input": "But for our sake, imagining an example that we might hope that it would learn, we'll suppose that this query matrix maps the embeddings of nouns to certain directions in this smaller query space that somehow encodes the notion of looking for adjectives in preceding positions.",
  "translatedText": "그러나 우리가 학습하기를 바라는 예를 상상하기 위해, 이 쿼리 행렬이 명사의 포함을 이 작은 쿼리 공간에서 특정 방향으로 매핑하여 앞의 위치에서 형용사를 찾는 개념을 어떻게든 인코딩한다고 가정해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 443.9,
  "end": 458.04
 },
 {
  "input": "As to what it does to other embeddings, who knows?",
  "translatedText": "다른 임베딩에 어떤 영향을 미칠지는 누가 알겠습니까?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.78,
  "end": 461.44
 },
 {
  "input": "Maybe it simultaneously tries to accomplish some other goal with those.",
  "translatedText": "어쩌면 그것으로 다른 목표를 동시에 달성하려고 할 수도 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 461.72,
  "end": 464.34
 },
 {
  "input": "Right now, we're laser focused on the nouns.",
  "translatedText": "지금은 명사에 집중하고 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 464.54,
  "end": 467.16
 },
 {
  "input": "At the same time, associated with this is a second matrix called the key matrix, which you also multiply by every one of the embeddings.",
  "translatedText": "동시에 이와 관련된 두 번째 행렬인 키 행렬도 모든 임베딩에 곱합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 467.28,
  "end": 474.62
 },
 {
  "input": "This produces a second sequence of vectors that we call the keys.",
  "translatedText": "이렇게 하면 키라고 부르는 두 번째 벡터 시퀀스가 생성됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 475.28,
  "end": 478.5
 },
 {
  "input": "Conceptually, you want to think of the keys as potentially answering the queries.",
  "translatedText": "개념적으로 키는 쿼리에 대한 잠재적인 답변이라고 생각하면 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 479.42,
  "end": 483.14
 },
 {
  "input": "This key matrix is also full of tunable parameters, and just like the query matrix, it maps the embedding vectors to that same smaller dimensional space.",
  "translatedText": "이 키 행렬은 또한 조정 가능한 파라미터로 가득 차 있으며 쿼리 행렬과 마찬가지로 임베딩 벡터를 동일한 작은 차원 공간에 매핑합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.84,
  "end": 491.4
 },
 {
  "input": "You think of the keys as matching the queries whenever they closely align with each other.",
  "translatedText": "키는 쿼리가 서로 밀접하게 일치할 때마다 일치하는 것으로 생각하면 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.02
 },
 {
  "input": "In our example, you would imagine that the key matrix maps the adjectives like fluffy and blue to vectors that are closely aligned with the query produced by the word creature.",
  "translatedText": "이 예제에서는 키 매트릭스가 fluffy, blue와 같은 형용사를 creature라는 단어가 생성하는 쿼리와 밀접하게 일치하는 벡터에 매핑한다고 상상할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 497.46,
  "end": 506.74
 },
 {
  "input": "To measure how well each key matches each query, you compute a dot product between each possible key-query pair.",
  "translatedText": "각 키가 각 쿼리와 얼마나 잘 일치하는지 측정하려면 가능한 각 키-쿼리 쌍 사이의 도트 곱을 계산합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 507.2,
  "end": 514.0
 },
 {
  "input": "I like to visualize a grid full of a bunch of dots, where the bigger dots correspond to the larger dot products, the places where the keys and queries align.",
  "translatedText": "저는 점으로 가득 찬 그리드를 시각화하는 것을 좋아하는데, 큰 점이 더 큰 점 제품, 즉 키와 쿼리가 정렬되는 위치에 해당합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 514.48,
  "end": 522.56
 },
 {
  "input": "For our adjective noun example, that would look a little more like this, where if the keys produced by fluffy and blue really do align closely with the query produced by creature, then the dot products in these two spots would be some large positive numbers.",
  "translatedText": "형용사 명사 예제의 경우, 다음과 같이 표시되는데, 만약 플러피와 블루가 생성하는 키가 실제로 크리처가 생성하는 쿼리와 거의 일치한다면 이 두 지점의 점 곱은 큰 양수가 될 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 523.28,
  "end": 538.32
 },
 {
  "input": "In the lingo, machine learning people would say that this means the embeddings of fluffy and blue attend to the embedding of creature.",
  "translatedText": "머신 러닝 전문 용어로 말하자면, 솜털과 파란색의 임베딩은 생물의 임베딩을 의미한다고 할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.1,
  "end": 545.42
 },
 {
  "input": "By contrast to the dot product between the key for some other word like the and the query for creature would be some small or negative value that reflects that are unrelated to each other.",
  "translatedText": "반면, the와 같은 다른 단어의 키와 creature에 대한 쿼리 사이의 점 곱은 서로 관련이 없는 작은 값 또는 음수 값을 반영합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 546.04,
  "end": 556.6
 },
 {
  "input": "So we have this grid of values that can be any real number from negative infinity to infinity, giving us a score for how relevant each word is to updating the meaning of every other word.",
  "translatedText": "따라서 음의 무한대에서 무한대까지 모든 실수가 될 수 있는 값 그리드를 통해 각 단어가 다른 모든 단어의 의미를 업데이트하는 데 얼마나 관련성이 있는지에 대한 점수를 부여합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 557.7,
  "end": 568.48
 },
 {
  "input": "The way we're about to use these scores is to take a certain weighted sum along each column, weighted by the relevance.",
  "translatedText": "이 점수를 사용하는 방법은 각 열에 따라 관련성에 따라 가중치를 부여하여 특정 가중치 합계를 구하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 569.2,
  "end": 575.78
 },
 {
  "input": "So instead of having values range from negative infinity to infinity, what we want is for the numbers in these columns to be between 0 and 1, and for each column to add up to 1, as if they were a probability distribution.",
  "translatedText": "따라서 음의 무한대에서 무한대까지의 값 범위 대신 0에서 1 사이의 값과 확률 분포처럼 각 열의 숫자가 합산되어 1이 되는 것을 원합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.52,
  "end": 588.18
 },
 {
  "input": "If you're coming in from the last chapter, you know what we need to do then.",
  "translatedText": "마지막 챕터부터 읽으셨다면 어떻게 해야 할지 잘 알고 계실 겁니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 589.28,
  "end": 592.22
 },
 {
  "input": "We compute a softmax along each one of these columns to normalize the values.",
  "translatedText": "이러한 각 열을 따라 소프트맥스를 계산하여 값을 정규화합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 592.62,
  "end": 597.3
 },
 {
  "input": "In our picture, after you apply softmax to all of the columns, we'll fill in the grid with these normalized values.",
  "translatedText": "그림에서는 모든 열에 소프트맥스를 적용한 후 이러한 정규화된 값으로 그리드를 채웁니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 600.06,
  "end": 605.86
 },
 {
  "input": "At this point you're safe to think about each column as giving weights according to how relevant the word on the left is to the corresponding value at the top.",
  "translatedText": "이 시점에서 각 열은 왼쪽의 단어가 상단의 해당 값과 얼마나 관련성이 있는지에 따라 가중치를 부여한다고 생각해도 안전합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 606.78,
  "end": 614.58
 },
 {
  "input": "We call this grid an attention pattern.",
  "translatedText": "우리는 이 그리드를 주의 패턴이라고 부릅니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 615.08,
  "end": 616.84
 },
 {
  "input": "Now if you look at the original transformer paper, there's a really compact way that they write this all down.",
  "translatedText": "이제 원본 트랜스포머 종이를 보면 이 모든 것을 간결하게 적는 방식이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 618.08,
  "end": 622.82
 },
 {
  "input": "Here the variables q and k represent the full arrays of query and key vectors respectively, those little vectors you get by multiplying the embeddings by the query and the key matrices.",
  "translatedText": "여기서 변수 q와 k는 각각 쿼리 및 키 벡터의 전체 배열, 즉 임베딩에 쿼리와 키 행렬을 곱하여 얻는 작은 벡터를 나타냅니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 623.88,
  "end": 634.64
 },
 {
  "input": "This expression up in the numerator is a really compact way to represent the grid of all possible dot products between pairs of keys and queries.",
  "translatedText": "분자에 있는 이 표현식은 키와 쿼리 쌍 사이에 가능한 모든 도트 곱의 그리드를 매우 간결하게 표현하는 방법입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 635.16,
  "end": 643.02
 },
 {
  "input": "A small technical detail that I didn't mention is that for numerical stability, it happens to be helpful to divide all of these values by the square root of the dimension in that key query space.",
  "translatedText": "제가 언급하지 않은 작은 기술적 세부 사항은 수치 안정성을 위해 이 모든 값을 해당 키 쿼리 공간에서 차원의 제곱근으로 나누는 것이 도움이 된다는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 644.0,
  "end": 653.96
 },
 {
  "input": "Then this softmax that's wrapped around the full expression is meant to be understood to apply column by column.",
  "translatedText": "그런 다음 전체 표현식을 감싸고 있는 이 소프트맥스는 열 단위로 적용하는 것으로 이해해야 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 654.48,
  "end": 660.8
 },
 {
  "input": "As to that v term, we'll talk about it in just a second.",
  "translatedText": "이 V 용어에 대해서는 잠시 후에 설명하겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 661.64,
  "end": 664.7
 },
 {
  "input": "Before that, there's one other technical detail that so far I've skipped.",
  "translatedText": "그 전에 지금까지 건너뛰었던 기술적 세부 사항이 하나 더 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 665.02,
  "end": 668.46
 },
 {
  "input": "During the training process, when you run this model on a given text example, and all of the weights are slightly adjusted and tuned to either reward or punish it based on how high a probability it assigns to the true next word in the passage, it turns out to make the whole training process a lot more efficient if you simultaneously have it predict every possible next token following each initial subsequence of tokens in this passage.",
  "translatedText": "훈련 과정에서 주어진 텍스트 예제에서 이 모델을 실행하고 모든 가중치를 약간 조정하여 구절의 실제 다음 단어에 얼마나 높은 확률을 할당하는지에 따라 보상하거나 처벌하도록 조정할 때, 이 구절의 각 초기 토큰 다음에 가능한 모든 다음 토큰을 동시에 예측하도록 하면 전체 훈련 과정이 훨씬 더 효율적으로 수행되는 것으로 밝혀졌습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 669.04,
  "end": 691.56
 },
 {
  "input": "For example, with the phrase that we've been focusing on, it might also be predicting what words follow creature and what words follow the.",
  "translatedText": "예를 들어, 우리가 집중하고 있는 문구의 경우, 어떤 단어가 크리처 뒤에 오고 어떤 단어가 크리처 뒤에 오는지 예측할 수도 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 691.94,
  "end": 699.1
 },
 {
  "input": "This is really nice, because it means what would otherwise be a single training example effectively acts as many.",
  "translatedText": "이는 하나의 교육 예시가 여러 개의 교육 예시처럼 효과적으로 작동한다는 것을 의미하기 때문에 정말 좋은 일입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 699.94,
  "end": 705.56
 },
 {
  "input": "For the purposes of our attention pattern, it means that you never want to allow later words to influence earlier words, since otherwise they could kind of give away the answer for what comes next.",
  "translatedText": "주의 집중 패턴의 목적상, 나중에 나오는 단어가 앞의 단어에 영향을 미치지 않도록 해야 하는데, 그렇지 않으면 다음에 나오는 단어에 대한 답을 알려줄 수 있기 때문입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 706.1,
  "end": 716.04
 },
 {
  "input": "What this means is that we want all of these spots here, the ones representing later tokens influencing earlier ones, to somehow be forced to be zero.",
  "translatedText": "이것이 의미하는 바는 여기에 있는 모든 지점, 즉 이전 토큰에 영향을 미치는 이후 토큰을 나타내는 지점이 어떻게든 0이 되기를 원한다는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 716.56,
  "end": 724.6
 },
 {
  "input": "The simplest thing you might think to do is to set them equal to zero, but if you did that the columns wouldn't add up to one anymore, they wouldn't be normalized.",
  "translatedText": "가장 간단하게 생각할 수 있는 방법은 0으로 설정하는 것이지만, 그렇게 하면 열이 더 이상 1이 되지 않아 정규화되지 않습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 725.92,
  "end": 732.42
 },
 {
  "input": "So instead, a common way to do this is that before applying softmax, you set all of those entries to be negative infinity.",
  "translatedText": "따라서 이 작업을 수행하는 일반적인 방법은 소프트맥스를 적용하기 전에 모든 항목을 음의 무한대로 설정하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 733.12,
  "end": 739.02
 },
 {
  "input": "If you do that, then after applying softmax, all of those get turned into zero, but the columns stay normalized.",
  "translatedText": "이렇게 하면 소프트맥스를 적용한 후 모든 열이 0으로 바뀌지만 열은 정규화된 상태로 유지됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 739.68,
  "end": 745.18
 },
 {
  "input": "This process is called masking.",
  "translatedText": "이 프로세스를 마스킹이라고 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 746.0,
  "end": 747.54
 },
 {
  "input": "There are versions of attention where you don't apply it, but in our GPT example, even though this is more relevant during the training phase than it would be, say, running it as a chatbot or something like that, you do always apply this masking to prevent later tokens from influencing earlier ones.",
  "translatedText": "이 마스킹을 적용하지 않는 주의 버전도 있지만, GPT 예시에서는 챗봇 등으로 실행하는 것보다 트레이닝 단계에서 더 관련성이 높지만, 항상 이 마스킹을 적용하여 이후 토큰이 이전 토큰에 영향을 미치는 것을 방지합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 747.54,
  "end": 761.46
 },
 {
  "input": "Another fact that's worth reflecting on about this attention pattern is how its size is equal to the square of the context size.",
  "translatedText": "이 주의 집중 패턴에 대해 생각해 볼 만한 또 다른 사실은 그 크기가 컨텍스트 크기의 제곱과 같다는 점입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 762.48,
  "end": 769.5
 },
 {
  "input": "So this is why context size can be a really huge bottleneck for large language models, and scaling it up is non-trivial.",
  "translatedText": "그렇기 때문에 대규모 언어 모델에서는 컨텍스트 크기가 정말 큰 병목 현상이 될 수 있으며, 이를 확장하는 것은 간단하지 않습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 769.9,
  "end": 775.62
 },
 {
  "input": "As you imagine, motivated by a desire for bigger and bigger context windows, recent years have seen some variations to the attention mechanism aimed at making context more scalable, but right here, you and I are staying focused on the basics.",
  "translatedText": "더 큰 컨텍스트 창에 대한 열망에 힘입어 최근에는 컨텍스트의 확장성을 높이기 위해 주의 메커니즘에 몇 가지 변형이 이루어지고 있지만, 여기서는 기본에 집중하고 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 776.3,
  "end": 788.32
 },
 {
  "input": "Okay, great, computing this pattern lets the model deduce which words are relevant to which other words.",
  "translatedText": "좋아요, 이 패턴을 계산하면 모델이 어떤 단어가 어떤 다른 단어와 연관성이 있는지 추론할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 790.56,
  "end": 795.48
 },
 {
  "input": "Now you need to actually update the embeddings, allowing words to pass information to whichever other words they're relevant to.",
  "translatedText": "이제 임베딩을 실제로 업데이트하여 단어가 관련 있는 다른 단어에 정보를 전달할 수 있도록 해야 합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 796.02,
  "end": 802.8
 },
 {
  "input": "For example, you want the embedding of Fluffy to somehow cause a change to Creature that moves it to a different part of this 12,000-dimensional embedding space that more specifically encodes a Fluffy creature.",
  "translatedText": "예를 들어, 플러피 임베딩이 어떻게든 크리처를 변경하여 12,000차원 임베딩 공간의 다른 부분으로 이동시켜 플러피 크리처를 보다 구체적으로 인코딩하고 싶다고 가정해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 802.8,
  "end": 814.52
 },
 {
  "input": "What I'm going to do here is first show you the most straightforward way that you could do this, though there's a slight way that this gets modified in the context of multi-headed attention.",
  "translatedText": "여기서는 먼저 가장 간단한 방법을 보여드리려고 합니다만, 여러 사람이 주목하는 상황에서는 약간 수정되는 방법이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 815.46,
  "end": 823.46
 },
 {
  "input": "This most straightforward way would be to use a third matrix, what we call the value matrix, which you multiply by the embedding of that first word, for example Fluffy.",
  "translatedText": "가장 간단한 방법은 세 번째 행렬, 즉 값 행렬이라고 부르는 행렬을 사용하여 첫 번째 단어의 임베딩을 곱하는 것입니다(예: Fluffy).",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 824.08,
  "end": 832.44
 },
 {
  "input": "The result of this is what you would call a value vector, and this is something that you add to the embedding of the second word, in this case something you add to the embedding of Creature.",
  "translatedText": "그 결과는 값 벡터라고 할 수 있으며, 이것은 두 번째 단어의 임베딩에 추가하는 것, 이 경우에는 Creature의 임베딩에 추가하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 833.3,
  "end": 841.92
 },
 {
  "input": "So this value vector lives in the same very high-dimensional space as the embeddings.",
  "translatedText": "따라서 이 값 벡터는 임베딩과 동일한 매우 고차원적인 공간에 존재합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 842.6,
  "end": 847.0
 },
 {
  "input": "When you multiply this value matrix by the embedding of a word, you might think of it as saying, if this word is relevant to adjusting the meaning of something else, what exactly should be added to the embedding of that something else in order to reflect this?",
  "translatedText": "이 값 행렬에 단어의 임베딩을 곱하면, 이 단어가 다른 단어의 의미를 조정하는 것과 관련이 있다면 이를 반영하기 위해 다른 단어의 임베딩에 정확히 무엇을 추가해야 하는가라고 생각할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 847.46,
  "end": 861.16
 },
 {
  "input": "Looking back in our diagram, let's set aside all of the keys and the queries, since after you compute the attention pattern you're done with those, then you're going to take this value matrix and multiply it by every one of those embeddings to produce a sequence of value vectors.",
  "translatedText": "주의 패턴을 계산한 후에는 이 값 행렬을 가져와 모든 임베딩에 곱하여 일련의 값 벡터를 생성할 것이므로, 다이어그램을 다시 살펴보면 키와 쿼리는 모두 제쳐두겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 862.14,
  "end": 876.06
 },
 {
  "input": "You might think of these value vectors as being kind of associated with the corresponding keys.",
  "translatedText": "이러한 값 벡터는 해당 키와 일종의 연관성이 있다고 생각할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 877.12,
  "end": 881.12
 },
 {
  "input": "For each column in this diagram, you multiply each of the value vectors by the corresponding weight in that column.",
  "translatedText": "이 다이어그램의 각 열에 대해 각 값 벡터에 해당 열의 해당 가중치를 곱합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 882.32,
  "end": 889.24
 },
 {
  "input": "For example here, under the embedding of Creature, you would be adding large proportions of the value vectors for Fluffy and Blue, while all of the other value vectors get zeroed out, or at least nearly zeroed out.",
  "translatedText": "예를 들어 여기에서는 크리처를 임베드하면 Fluffy와 Blue에 대한 값 벡터의 많은 부분을 추가하고 다른 모든 값 벡터는 0이 되거나 적어도 거의 0에 가깝게 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 890.08,
  "end": 901.56
 },
 {
  "input": "And then finally, the way to actually update the embedding associated with this column, previously encoding some context-free meaning of Creature, you add together all of these rescaled values in the column, producing a change that you want to add, that I'll label delta-e, and then you add that to the original embedding.",
  "translatedText": "마지막으로, 이 열과 관련된 임베딩을 실제로 업데이트하는 방법은 이전에 Creature의 컨텍스트 없는 의미를 인코딩한 후 열의 모든 재조정된 값을 합산하여 추가하려는 변경 사항(델타-e라고 레이블을 지정하겠습니다)을 생성한 다음 원래 임베딩에 추가하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 902.12,
  "end": 919.26
 },
 {
  "input": "Hopefully what results is a more refined vector encoding the more contextually rich meaning, like that of a fluffy blue creature.",
  "translatedText": "푹신푹신한 파란색 생명체처럼 맥락이 풍부한 의미를 인코딩하는 더 세련된 벡터가 탄생하길 바랍니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 919.68,
  "end": 926.5
 },
 {
  "input": "And of course you don't just do this to one embedding, you apply the same weighted sum across all of the columns in this picture, producing a sequence of changes, adding all of those changes to the corresponding embeddings, produces a full sequence of more refined embeddings popping out of the attention block.",
  "translatedText": "물론 하나의 임베딩에만 이 작업을 수행하는 것이 아니라 이 그림의 모든 열에 동일한 가중치를 적용하여 일련의 변경 사항을 생성하고 해당 임베딩에 이러한 변경 사항을 모두 추가하면 관심 블록에서 더 세련된 임베딩이 튀어나오는 전체 시퀀스를 생성합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 927.38,
  "end": 943.46
 },
 {
  "input": "Zooming out, this whole process is what you would describe as a single head of attention.",
  "translatedText": "이 모든 과정을 축소하면 한 번에 집중할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 944.86,
  "end": 949.1
 },
 {
  "input": "As I've described things so far, this process is parameterized by three distinct matrices, all filled with tunable parameters, the key, the query, and the value.",
  "translatedText": "지금까지 설명했듯이 이 프로세스는 조정 가능한 매개 변수인 키, 쿼리, 값으로 채워진 세 개의 서로 다른 행렬로 매개변수화됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 949.6,
  "end": 958.94
 },
 {
  "input": "I want to take a moment to continue what we started in the last chapter, with the scorekeeping where we count up the total number of model parameters using the numbers from GPT-3.",
  "translatedText": "지난 장에서 시작한 내용을 이어서 GPT-3의 숫자를 사용하여 모델 파라미터의 총 수를 세는 점수 계산에 대해 잠시 설명하겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 959.5,
  "end": 968.04
 },
 {
  "input": "These key and query matrices each have 12,288 columns, matching the embedding dimension, and 128 rows, matching the dimension of that smaller key query space.",
  "translatedText": "이러한 키 및 쿼리 행렬은 각각 임베딩 차원과 일치하는 12,288개의 열과 더 작은 키 쿼리 공간의 차원과 일치하는 128개의 행으로 구성되어 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 969.3,
  "end": 979.6
 },
 {
  "input": "This gives us an additional 1.5 million or so parameters for each one.",
  "translatedText": "이렇게 하면 각각에 대해 150만 개 정도의 매개변수가 추가로 제공됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 980.26,
  "end": 984.22
 },
 {
  "input": "If you look at that value matrix by contrast, the way I've described things so far would suggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both its inputs and outputs live in this very large embedding space.",
  "translatedText": "이 값 행렬을 대조적으로 보면, 지금까지 설명한 방식대로라면 입력과 출력 모두 매우 큰 임베딩 공간에 있기 때문에 12,288개의 열과 12,288개의 행이 있는 정사각형 행렬이라고 볼 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 984.86,
  "end": 1000.92
 },
 {
  "input": "If true, that would mean about 150 million added parameters.",
  "translatedText": "사실이라면 약 1억 5천만 개의 매개변수가 추가되었다는 뜻입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1001.5,
  "end": 1005.14
 },
 {
  "input": "And to be clear, you could do that.",
  "translatedText": "확실히 말씀드리자면, 그렇게 할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1005.66,
  "end": 1007.3
 },
 {
  "input": "You could devote orders of magnitude more parameters to the value map than to the key and query.",
  "translatedText": "키와 쿼리보다 훨씬 더 많은 매개변수를 값 맵에 할당할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1007.42,
  "end": 1011.74
 },
 {
  "input": "But in practice, it is much more efficient if instead you make it so that the number of parameters devoted to this value map is the same as the number devoted to the key and the query.",
  "translatedText": "그러나 실제로는 이 값 맵에 할당된 매개변수의 수가 키와 쿼리에 할당된 수와 같도록 만드는 것이 훨씬 효율적입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1012.06,
  "end": 1020.76
 },
 {
  "input": "This is especially relevant in the setting of running multiple attention heads in parallel.",
  "translatedText": "이는 특히 여러 개의 주의 집중 헤드를 동시에 실행하는 설정과 관련이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1021.46,
  "end": 1025.16
 },
 {
  "input": "The way this looks is that the value map is factored as a product of two smaller matrices.",
  "translatedText": "이 방식은 값 맵이 두 개의 작은 행렬의 곱으로 인수 분해되는 방식입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1026.24,
  "end": 1030.1
 },
 {
  "input": "Conceptually, I would still encourage you to think about the overall linear map, one with inputs and outputs, both in this larger embedding space, for example taking the embedding of blue to this blueness direction that you would add to nouns.",
  "translatedText": "개념적으로는 이 더 큰 임베딩 공간에서 입력과 출력이 있는 전체 선형 맵, 예를 들어 명사에 추가할 파란색을 이 파란색 방향에 임베딩하는 것을 생각해 보는 것이 좋습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1031.18,
  "end": 1043.8
 },
 {
  "input": "It's just that it's a smaller number of rows, typically the same size as the key query space.",
  "translatedText": "다만 일반적으로 키 쿼리 공간과 같은 크기의 더 적은 수의 행일 뿐입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1047.04,
  "end": 1052.76
 },
 {
  "input": "What this means is you can think of it as mapping the large embedding vectors down to a much smaller space.",
  "translatedText": "즉, 큰 임베딩 벡터를 훨씬 작은 공간에 매핑한다고 생각하면 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1053.1,
  "end": 1058.44
 },
 {
  "input": "This is not the conventional naming, but I'm going to call this the value down matrix.",
  "translatedText": "이것은 일반적인 네이밍은 아니지만, 저는 이것을 밸류 다운 매트릭스라고 부를 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1059.04,
  "end": 1062.7
 },
 {
  "input": "The second matrix maps from this smaller space back up to the embedding space, producing the vectors that you use to make the actual updates.",
  "translatedText": "두 번째 매트릭스는 이 작은 공간에서 임베딩 공간으로 다시 매핑하여 실제 업데이트에 사용하는 벡터를 생성합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1063.4,
  "end": 1070.58
 },
 {
  "input": "I'm going to call this one the value up matrix, which again is not conventional.",
  "translatedText": "저는 이것을 밸류 업 매트릭스라고 부를 것인데, 이 역시 기존과는 다른 방식입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1071.0,
  "end": 1074.74
 },
 {
  "input": "The way that you would see this written in most papers looks a little different.",
  "translatedText": "대부분의 논문에서 볼 수 있는 방식은 조금 다릅니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1075.16,
  "end": 1078.08
 },
 {
  "input": "I'll talk about it in a minute.",
  "translatedText": "잠시 후에 말씀드리겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1078.38,
  "end": 1079.52
 },
 {
  "input": "In my opinion, it tends to make things a little more conceptually confusing.",
  "translatedText": "제 생각에는 개념적으로 조금 더 혼란스러워지는 경향이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1079.7,
  "end": 1082.54
 },
 {
  "input": "To throw in linear algebra jargon here, what we're basically doing is constraining the overall value map to be a low rank transformation.",
  "translatedText": "여기서 선형 대수 전문 용어를 사용하자면, 기본적으로 전체 값 맵을 낮은 순위의 변환으로 제한하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1083.26,
  "end": 1090.34
 },
 {
  "input": "Turning back to the parameter count, all four of these matrices have the same size, and adding them all up we get about 6.3 million parameters for one attention head.",
  "translatedText": "매개변수 수로 돌아가서, 이 네 개의 행렬은 모두 크기가 같으며, 이를 모두 더하면 하나의 주의 집중 헤드에 대해 약 630만 개의 매개변수가 생깁니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1091.42,
  "end": 1100.78
 },
 {
  "input": "As a quick side note, to be a little more accurate, everything described so far is what people would call a self-attention head, to distinguish it from a variation that comes up in other models that's called cross-attention.",
  "translatedText": "조금 더 정확하게 말하자면, 지금까지 설명한 것은 다른 모델에서 나타나는 크로스 어텐션이라는 변형과 구별하기 위해 '자기 주의력 헤드'라고 부르는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1102.04,
  "end": 1111.5
 },
 {
  "input": "This isn't relevant to our GPT example, but if you're curious, cross-attention involves models that process two distinct types of data, like text in one language and text in another language that's part of an ongoing generation of a translation, or maybe audio input of speech and an ongoing transcription.",
  "translatedText": "GPT 예시와는 관련이 없지만 궁금하신 분들을 위해 설명하자면, 교차 주의는 한 언어의 텍스트와 진행 중인 번역 생성의 일부인 다른 언어의 텍스트 또는 음성 입력과 진행 중인 전사처럼 두 가지 유형의 데이터를 처리하는 모델과 관련이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1112.3,
  "end": 1129.24
 },
 {
  "input": "A cross-attention head looks almost identical.",
  "translatedText": "크로스 어텐션 헤드는 거의 동일하게 보입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1130.4,
  "end": 1132.7
 },
 {
  "input": "The only difference is that the key and query maps act on different data sets.",
  "translatedText": "유일한 차이점은 키 맵과 쿼리 맵이 서로 다른 데이터 세트에서 작동한다는 점입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1132.98,
  "end": 1137.4
 },
 {
  "input": "In a model doing translation, for example, the keys might come from one language, while the queries come from another, and the attention pattern could describe which words from one language correspond to which words in another.",
  "translatedText": "예를 들어 번역을 수행하는 모델에서 키는 한 언어에서 나오는 반면 쿼리는 다른 언어에서 나올 수 있으며, 주의 패턴은 한 언어의 어떤 단어가 다른 언어의 어떤 단어에 해당하는지를 설명할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1137.84,
  "end": 1149.66
 },
 {
  "input": "And in this setting there would typically be no masking, since there's not really any notion of later tokens affecting earlier ones.",
  "translatedText": "그리고 이 설정에서는 일반적으로 마스킹이 발생하지 않는데, 이는 나중에 토큰이 이전 토큰에 영향을 미친다는 개념이 없기 때문입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1150.34,
  "end": 1156.34
 },
 {
  "input": "Staying focused on self-attention though, if you understood everything so far, and if you were to stop here, you would come away with the essence of what attention really is.",
  "translatedText": "하지만 자기 주의력에 집중하면서 지금까지 모든 것을 이해했다면, 그리고 여기서 멈춘다면 주의력의 본질이 무엇인지 알게 될 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1157.18,
  "end": 1165.18
 },
 {
  "input": "All that's really left to us is to lay out the sense in which you do this many many different times.",
  "translatedText": "이제 우리에게 남은 것은 이 작업을 여러 번 다양하게 수행하는 감각을 배치하는 것뿐입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1165.76,
  "end": 1171.44
 },
 {
  "input": "In our central example we focused on adjectives updating nouns, but of course there are lots of different ways that context can influence the meaning of a word.",
  "translatedText": "중심 예제에서는 명사를 업데이트하는 형용사에 초점을 맞추었지만, 물론 문맥이 단어의 의미에 영향을 미칠 수 있는 방법은 매우 다양합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1172.1,
  "end": 1179.8
 },
 {
  "input": "If the words they crashed the preceded the word car, it has implications for the shape and structure of that car.",
  "translatedText": "충돌한 단어가 자동차라는 단어 앞에 오면 해당 자동차의 모양과 구조에 영향을 미칩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1180.36,
  "end": 1186.52
 },
 {
  "input": "And a lot of associations might be less grammatical.",
  "translatedText": "그리고 많은 연관어가 문법적이지 않을 수도 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1187.2,
  "end": 1189.28
 },
 {
  "input": "If the word wizard is anywhere in the same passage as Harry, it suggests that this might be referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were in that passage, then perhaps the embedding of Harry should instead be updated to refer to the prince.",
  "translatedText": "마법사라는 단어가 해리와 같은 구절에 있다면 해리 포터를 가리키는 것일 수 있지만, 대신 여왕, 서 섹스, 윌리엄이라는 단어가 해당 구절에 있다면 해리라는 임베딩을 왕자를 가리키는 것으로 업데이트해야 할 수도 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1189.76,
  "end": 1204.44
 },
 {
  "input": "For every different type of contextual updating that you might imagine, the parameters of these key and query matrices would be different to capture the different attention patterns, and the parameters of our value map would be different based on what should be added to the embeddings.",
  "translatedText": "상상할 수 있는 모든 다양한 유형의 문맥 업데이트에 대해 다양한 관심 패턴을 포착하기 위해 이러한 키 및 쿼리 행렬의 매개변수가 달라지고, 임베딩에 추가해야 하는 항목에 따라 가치 맵의 매개변수도 달라질 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1205.04,
  "end": 1219.14
 },
 {
  "input": "And again, in practice the true behavior of these maps is much more difficult to interpret, where the weights are set to do whatever the model needs them to do to best accomplish its goal of predicting the next token.",
  "translatedText": "그리고 실제로 이러한 맵의 실제 동작은 해석하기가 훨씬 더 어려운데, 가중치는 다음 토큰을 예측하는 목표를 가장 잘 달성하기 위해 모델에 필요한 모든 작업을 수행하도록 설정되어 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1219.98,
  "end": 1230.14
 },
 {
  "input": "As I said before, everything we described is a single head of attention, and a full attention block inside a transformer consists of what's called multi-headed attention, where you run a lot of these operations in parallel, each with its own distinct key query and value maps.",
  "translatedText": "앞서 말했듯이, 앞서 설명한 모든 것은 단일 주의 블록이며, 트랜스포머 내부의 전체 주의 블록은 멀티 헤드 주의라고 하는 것으로 구성되며, 이러한 많은 작업을 병렬로 실행하고 각각 고유한 키 쿼리와 값 맵을 사용합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1231.4,
  "end": 1245.92
 },
 {
  "input": "GPT-3 for example uses 96 attention heads inside each block.",
  "translatedText": "예를 들어 GPT-3는 각 블록 내부에 96개의 주의 헤드를 사용합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1247.42,
  "end": 1251.7
 },
 {
  "input": "Considering that each one is already a bit confusing, it's certainly a lot to hold in your head.",
  "translatedText": "하나하나가 이미 약간 혼란스럽다는 점을 고려하면, 머릿속에 담아두기에는 확실히 많은 양입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1252.02,
  "end": 1256.46
 },
 {
  "input": "Just to spell it all out very explicitly, this means you have 96 distinct key and query matrices producing 96 distinct attention patterns.",
  "translatedText": "간단히 설명하자면, 96개의 서로 다른 키와 쿼리 매트릭스가 96개의 서로 다른 관심도 패턴을 생성한다는 뜻입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1256.76,
  "end": 1265.0
 },
 {
  "input": "Then each head has its own distinct value matrices used to produce 96 sequences of value vectors.",
  "translatedText": "그런 다음 각 헤드는 96개의 값 벡터 시퀀스를 생성하는 데 사용되는 고유한 값 행렬을 갖습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1265.44,
  "end": 1272.18
 },
 {
  "input": "These are all added together using the corresponding attention patterns as weights.",
  "translatedText": "이는 모두 해당 관심도 패턴을 가중치로 사용하여 합산됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1272.46,
  "end": 1276.68
 },
 {
  "input": "What this means is that for each position in the context, each token, every one of these heads produces a proposed change to be added to the embedding in that position.",
  "translatedText": "즉, 컨텍스트의 각 위치, 각 토큰에 대해 이러한 모든 헤드가 해당 위치의 임베딩에 추가할 변경 제안을 생성한다는 의미입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1277.48,
  "end": 1287.02
 },
 {
  "input": "So what you do is you sum together all of those proposed changes, one for each head, and you add the result to the original embedding of that position.",
  "translatedText": "따라서 제안된 모든 변경 사항을 각 헤드에 대해 하나씩 합산한 다음 그 결과를 해당 위치의 원래 임베딩에 추가하면 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1287.66,
  "end": 1295.48
 },
 {
  "input": "This entire sum here would be one slice of what's outputted from this multi-headed attention block, a single one of those refined embeddings that pops out the other end of it.",
  "translatedText": "이 전체 합계는 이 다중 헤드 주의 블록에서 출력되는 것의 한 조각, 즉 그 반대쪽 끝에서 튀어나오는 세련된 임베딩 중 하나에 해당합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1296.66,
  "end": 1307.46
 },
 {
  "input": "Again, this is a lot to think about, so don't worry at all if it takes some time to sink in.",
  "translatedText": "다시 말하지만, 생각할 것이 많으니 적응하는 데 시간이 걸리더라도 전혀 걱정하지 마세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1308.32,
  "end": 1312.14
 },
 {
  "input": "The overall idea is that by running many distinct heads in parallel, you're giving the model the capacity to learn many distinct ways that context changes meaning.",
  "translatedText": "전체적인 아이디어는 여러 개의 서로 다른 헤드를 병렬로 실행함으로써 모델에 컨텍스트에 따라 의미가 달라지는 다양한 방식을 학습할 수 있는 능력을 부여하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1312.38,
  "end": 1321.82
 },
 {
  "input": "Pulling up our running tally for parameter count with 96 heads, each including its own variation of these four matrices, each block of multi-headed attention ends up with around 600 million parameters.",
  "translatedText": "이 네 가지 행렬의 각 변형을 포함하여 96개의 헤드로 매개변수 수를 집계한 결과, 각 멀티헤드 관심 블록에는 약 6억 개의 매개변수가 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1323.7,
  "end": 1335.08
 },
 {
  "input": "There's one added slightly annoying thing that I should really mention for any of you who go on to read more about transformers.",
  "translatedText": "트랜스포머에 대해 더 자세히 알아보고자 하는 분들을 위해 한 가지 더 언급하고 싶은 것이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1336.42,
  "end": 1341.8
 },
 {
  "input": "You remember how I said that the value map is factored out into these two distinct matrices, which I labeled as the value down and the value up matrices.",
  "translatedText": "값 맵이 이 두 개의 서로 다른 행렬로 나뉘며, 제가 값 다운 행렬과 값 업 행렬로 레이블을 붙였다고 말씀드린 것을 기억하실 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1342.08,
  "end": 1349.44
 },
 {
  "input": "The way that I framed things would suggest that you see this pair of matrices inside each attention head, and you could absolutely implement it this way.",
  "translatedText": "제가 구성한 방식은 각 주의 집중 헤드 안에 이 한 쌍의 행렬이 있다고 생각하면 되고, 이런 식으로 구현할 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1349.96,
  "end": 1358.44
 },
 {
  "input": "That would be a valid design.",
  "translatedText": "이는 유효한 디자인이 될 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1358.64,
  "end": 1359.92
 },
 {
  "input": "But the way that you see this written in papers and the way that it's implemented in practice looks a little different.",
  "translatedText": "하지만 논문에서 보는 방식과 실제로 구현되는 방식은 조금 다릅니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1360.26,
  "end": 1364.92
 },
 {
  "input": "All of these value up matrices for each head appear stapled together in one giant matrix that we call the output matrix, associated with the entire multi-headed attention block.",
  "translatedText": "각 헤드에 대한 이러한 모든 값 업 행렬은 전체 멀티 헤드 주의 블록과 연결된 출력 행렬이라고 하는 하나의 거대한 행렬에 함께 스테이플 처리되어 나타납니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1365.34,
  "end": 1376.38
 },
 {
  "input": "And when you see people refer to the value matrix for a given attention head, they're typically only referring to this first step, the one that I was labeling as the value down projection into the smaller space.",
  "translatedText": "그리고 사람들이 주어진 주의 집중 헤드에 대한 가치 매트릭스를 언급하는 것을 볼 때, 일반적으로 이 첫 번째 단계, 즉 제가 작은 공간에 가치 하향 투영이라고 표시한 단계만 언급하는 경우가 많습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1376.82,
  "end": 1387.14
 },
 {
  "input": "For the curious among you, I've left an on-screen note about it.",
  "translatedText": "궁금하신 분들을 위해 화면에 메모를 남겨두었습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1388.34,
  "end": 1391.04
 },
 {
  "input": "It's one of those details that runs the risk of distracting from the main conceptual points, but I do want to call it out just so that you know if you read about this in other sources.",
  "translatedText": "주요 개념에서 벗어날 위험이 있는 세부 사항 중 하나이지만, 다른 출처에서 이에 대해 읽은 경우 알 수 있도록 언급하고 싶었습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1391.26,
  "end": 1398.54
 },
 {
  "input": "Setting aside all the technical nuances, in the preview from the last chapter we saw how data flowing through a transformer doesn't just flow through a single attention block.",
  "translatedText": "모든 기술적 뉘앙스를 제쳐두고, 지난 장의 미리보기에서 트랜스포머를 통해 흐르는 데이터가 단순히 하나의 주의 블록을 통과하는 것이 아니라는 점을 살펴보았습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1399.24,
  "end": 1408.04
 },
 {
  "input": "For one thing, it also goes through these other operations called multi-layer perceptrons.",
  "translatedText": "우선, 멀티 레이어 퍼셉트론이라고 하는 다른 작업도 거칩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1408.64,
  "end": 1412.7
 },
 {
  "input": "We'll talk more about those in the next chapter.",
  "translatedText": "다음 장에서 이에 대해 자세히 설명하겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1413.12,
  "end": 1414.88
 },
 {
  "input": "And then it repeatedly goes through many many copies of both of these operations.",
  "translatedText": "그리고 이 두 가지 작업을 여러 번 반복해서 수행합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1415.18,
  "end": 1419.32
 },
 {
  "input": "What this means is that after a given word imbibes some of its context, there are many more chances for this more nuanced embedding to be influenced by its more nuanced surroundings.",
  "translatedText": "즉, 특정 단어가 문맥을 일부 흡수한 후에는 더 미묘한 주변 환경에 의해 영향을 받을 가능성이 더 많아진다는 뜻입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1419.98,
  "end": 1430.04
 },
 {
  "input": "The further down the network you go, with each embedding taking in more and more meaning from all the other embeddings, which themselves are getting more and more nuanced, the hope is that there's the capacity to encode higher level and more abstract ideas about a given input beyond just descriptors and grammatical structure.",
  "translatedText": "네트워크 아래로 내려갈수록 각 임베딩이 다른 모든 임베딩에서 점점 더 많은 의미를 가져오고, 그 자체도 점점 더 미묘한 차이를 갖게 되면서, 단순한 설명자와 문법 구조를 넘어 주어진 입력에 대해 더 높은 수준의 추상적인 아이디어를 인코딩할 수 있게 될 것이라는 희망이 생겼습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1430.94,
  "end": 1447.32
 },
 {
  "input": "Things like sentiment and tone and whether it's a poem and what underlying scientific truths are relevant to the piece and things like that.",
  "translatedText": "정서와 어조, 시인지 아닌지, 작품과 관련된 과학적 진실이 무엇인지 등 여러 가지를 고려합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1447.88,
  "end": 1455.13
 },
 {
  "input": "Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the total number of key query and value parameters is multiplied by another 96, which brings the total sum to just under 58 billion distinct parameters devoted to all of the attention heads.",
  "translatedText": "점수 관리로 다시 한 번 돌아가서, GPT-3에는 96개의 고유한 레이어가 포함되어 있으므로 총 키 쿼리 및 값 매개변수 수에 96개를 곱하면 총 합계는 모든 관심 헤드에 할당된 580억 개 미만의 고유한 매개변수가 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1456.7,
  "end": 1474.5
 },
 {
  "input": "That is a lot to be sure, but it's only about a third of the 175 billion that are in the network in total.",
  "translatedText": "확실히 많은 양이지만, 이는 전체 네트워크에 있는 1,750억 개 중 약 3분의 1에 불과합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1474.98,
  "end": 1480.94
 },
 {
  "input": "So even though attention gets all of the attention, the majority of parameters come from the blocks sitting in between these steps.",
  "translatedText": "따라서 모든 관심이 집중되기는 하지만 대부분의 매개변수는 이러한 단계 사이에 있는 블록에서 발생합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1481.52,
  "end": 1488.14
 },
 {
  "input": "In the next chapter, you and I will talk more about those other blocks and also a lot more about the training process.",
  "translatedText": "다음 장에서는 이러한 다른 블록과 교육 과정에 대해 더 자세히 이야기하겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1488.56,
  "end": 1493.56
 },
 {
  "input": "A big part of the story for the success of the attention mechanism is not so much any specific kind of behavior that it enables, but the fact that it's extremely parallelizable, meaning that you can run a huge number of computations in a short time using GPUs.",
  "translatedText": "주의 메커니즘이 성공할 수 있었던 가장 큰 이유는 이 메커니즘이 구현하는 특정 종류의 동작이 아니라, 이 메커니즘이 매우 병렬화 가능하기 때문에 GPU를 사용하여 짧은 시간에 엄청난 수의 연산을 실행할 수 있다는 사실입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1494.12,
  "end": 1508.38
 },
 {
  "input": "Given that one of the big lessons about deep learning in the last decade or two has been that scale alone seems to give huge qualitative improvements in model performance, there's a huge advantage to parallelizable architectures that let you do this.",
  "translatedText": "지난 10~20년 동안 딥 러닝에 대한 큰 교훈 중 하나는 규모만으로도 모델 성능이 크게 향상된다는 것이었으므로, 이를 가능하게 하는 병렬화 가능한 아키텍처는 큰 이점이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1509.46,
  "end": 1521.06
 },
 {
  "input": "If you want to learn more about this stuff, I've left lots of links in the description.",
  "translatedText": "이에 대해 자세히 알아보시려면 설명에 많은 링크를 남겨두었습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1522.04,
  "end": 1525.34
 },
 {
  "input": "In particular, anything produced by Andrej Karpathy or Chris Ola tend to be pure gold.",
  "translatedText": "특히 안드레이 카르파시나 크리스 올라가 제작한 모든 제품은 순금인 경우가 많습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1525.92,
  "end": 1530.04
 },
 {
  "input": "In this video, I wanted to just jump into attention in its current form, but if you're curious about more of the history for how we got here and how you might reinvent this idea for yourself, my friend Vivek just put up a couple videos giving a lot more of that motivation.",
  "translatedText": "이 영상에서는 현재의 모습에 주목하고 싶었지만, 우리가 어떻게 여기까지 왔는지, 이 아이디어를 어떻게 재창조할 수 있는지 더 많은 역사가 궁금하다면 제 친구 Vivek이 방금 더 많은 동기를 부여하는 몇 가지 동영상을 올렸습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1530.56,
  "end": 1542.54
 },
 {
  "input": "Also, Britt Cruz from the channel The Art of the Problem has a really nice video about the history of large language models.",
  "translatedText": "또한 The Art of the Problem 채널의 Britt Cruz는 대규모 언어 모델의 역사에 대한 멋진 동영상을 제공합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1543.12,
  "end": 1548.46
 },
 {
  "input": "Thank you.",
  "translatedText": "감사합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1564.96,
  "end": 1569.2
 }
]