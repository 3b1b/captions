[
 {
  "input": "Matt Parker recently showed me this fact that seems completely wild.",
  "translatedText": "매트 파커는 최근 저에게 완전히 엉뚱해 보이는 사실을 보여주었습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 3.34
 },
 {
  "input": "Say you sample two random numbers, each one uniform in the range from 0 to 1, and you compute their maximum.",
  "translatedText": "0에서 1 사이의 범위에서 각각 균일한 난수 두 개를 샘플링하고 그 최대값을 계산한다고 가정해 보겠습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 3.64,
  "end": 9.78
 },
 {
  "input": "Then the result is of course another random number with this bias towards being larger.",
  "translatedText": "그러면 결과는 당연히 더 큰 쪽으로 편향된 또 다른 난수가 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 10.18,
  "end": 14.2
 },
 {
  "input": "A seemingly completely different thing you could do would be to take one of those numbers and compute its square root.",
  "translatedText": "완전히 다른 방법으로는 이러한 숫자 중 하나를 가져와 제곱근을 계산하는 것입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 20.5
 },
 {
  "input": "When you square a number that's smaller than 1, it becomes smaller, so that means when you take its square root, it becomes bigger.",
  "translatedText": "1보다 작은 숫자를 제곱하면 작아지므로 제곱근을 구하면 커진다는 뜻입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.94,
  "end": 27.06
 },
 {
  "input": "So this is another process that would give you a random value with a bias towards being larger.",
  "translatedText": "따라서 이것은 더 큰 값에 편향된 임의의 값을 제공하는 또 다른 프로세스입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 27.06,
  "end": 32.04
 },
 {
  "input": "The surprise is that both of these are the same, in the sense that the distribution describing your result is identical for both of these procedures.",
  "translatedText": "놀라운 점은 이 두 가지 절차 모두 결과를 설명하는 분포가 동일하다는 점입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 32.42,
  "end": 39.98
 },
 {
  "input": "At first it just feels really wrong that computing a maximum and a square root could give you the same thing like this, but there's actually a really nice way to visualize why this should be true.",
  "translatedText": "처음에는 최대값과 제곱근을 계산하면 이와 같은 결과를 얻을 수 있다는 것이 정말 이상하게 느껴지지만, 사실 이것이 왜 사실이어야 하는지 시각화할 수 있는 정말 좋은 방법이 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 40.58,
  "end": 49.22
 },
 {
  "input": "Well think about one of these random numbers as existing somewhere on an x-axis between And the other random number is going to exist on a y-axis, again uniform between 0 and 1.",
  "translatedText": "이 난수 중 하나는 X축의 어딘가에 존재하고 다른 난수는 Y축에 존재하며 다시 0과 1 사이에 균일하게 존재한다고 생각해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 49.6,
  "end": 60.64
 },
 {
  "input": "So thinking of the pair of these numbers as a set of coordinates, when you sample both at random, you're basically sampling a random point inside this 1 by 1 unit square.",
  "translatedText": "따라서 이 숫자 쌍을 좌표 집합으로 생각하면, 두 숫자를 무작위로 샘플링하면 기본적으로 이 1 x 1 단위 정사각형 안에 있는 임의의 점을 샘플링하게 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 61.0,
  "end": 69.92
 },
 {
  "input": "So take a moment to think about what it looks like for the maximum of these two values to be a particular number, like 0.7.",
  "translatedText": "따라서 이 두 값의 최대값이 0.7과 같은 특정 숫자가 되면 어떤 모습일지 잠시 생각해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 70.82,
  "end": 78.04
 },
 {
  "input": "Well either x1 is equal to that value and x2 is smaller than it, which puts you somewhere on this line, or x2 equals that value and x1 is smaller than that, putting you somewhere on this line.",
  "translatedText": "x1이 해당 값과 같고 x2가 그보다 작아서 이 선의 어딘가에 위치하거나, x2가 해당 값과 같고 x1이 그보다 작아서 이 선의 어딘가에 위치하는 경우입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 78.62,
  "end": 90.44
 },
 {
  "input": "In general, with continuous values, it's not very helpful to ask the probability of equaling a certain number, since the answer tends to be infinitesimal.",
  "translatedText": "일반적으로 연속형 값의 경우 대답이 무한대인 경향이 있으므로 특정 숫자와 같을 확률을 묻는 것은 그다지 도움이 되지 않습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 91.22,
  "end": 98.96
 },
 {
  "input": "But what is helpful is to ask the probability that your random value is less than or equal to a certain number.",
  "translatedText": "하지만 무작위 값이 특정 숫자보다 작거나 같을 확률을 물어보는 것이 도움이 됩니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 99.4,
  "end": 105.34
 },
 {
  "input": "In this case, what it looks like to be less than or equal to 0.7 is that you fall somewhere inside this square here, and so because everything is uniform, the probability of landing in that region is the area of that region.",
  "translatedText": "이 경우 0.7보다 작거나 같다는 것은 여기 이 사각형 안쪽 어딘가에 떨어진다는 의미이므로 모든 것이 균일하므로 해당 영역에 착지할 확률은 해당 영역의 면적입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 105.96,
  "end": 120.22
 },
 {
  "input": "In general, the probability that this maximum is less than some number r looks like r-squared.",
  "translatedText": "일반적으로 이 최대값이 어떤 숫자 r보다 작을 확률은 r-제곱과 비슷합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 120.9,
  "end": 126.48
 },
 {
  "input": "This actually has a fancy name, it's called the cumulative distribution function for the random variable.",
  "translatedText": "사실 이것은 확률 변수에 대한 누적 분포 함수라는 멋진 이름을 가지고 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 126.86,
  "end": 131.78
 },
 {
  "input": "But now, think about the other case, where you're taking a square root.",
  "translatedText": "하지만 이제 제곱근을 취하는 다른 경우를 생각해 보세요.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 132.24,
  "end": 135.18
 },
 {
  "input": "What is the probability that the square root of one of these values is less than some number r?",
  "translatedText": "이 값 중 하나의 제곱근이 어떤 숫자 R보다 작을 확률은 얼마인가요?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 135.44,
  "end": 140.32
 },
 {
  "input": "That's the same thing as asking for the value itself to be less than or equal to r-squared, and since it's all uniform, the answer there is again r-squared.",
  "translatedText": "이는 값 자체가 r-제곱보다 작거나 같아야 한다는 것과 같으며, 모두 균일하기 때문에 답은 다시 r-제곱입니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.02,
  "end": 149.6
 },
 {
  "input": "So both of these processes have the same cumulative distribution function, that's why they're identical.",
  "translatedText": "따라서 이 두 프로세스는 동일한 누적 분포 함수를 가지므로 동일합니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.24,
  "end": 155.68
 },
 {
  "input": "Essentially, identical reasoning will show that if you take the maximum of three such random variables, it has the same effect as taking the cube root of one of them.",
  "translatedText": "기본적으로 동일한 추론을 통해 이러한 무작위 변수를 최대 3개까지 가져가면 그 중 하나의 제곱근을 가져가는 것과 동일한 효과가 있음을 알 수 있습니다.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 156.2,
  "end": 163.64
 }
]