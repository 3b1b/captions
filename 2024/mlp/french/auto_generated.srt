1
00:00:00,000 --> 00:00:04,684
Si tu donnes à un grand modèle de langage la phrase "Michael Jordan joue au basket-ball", 

2
00:00:04,684 --> 00:00:07,390
et que tu lui demandes de prédire ce qui va suivre, 

3
00:00:07,390 --> 00:00:11,345
et qu'il prédit correctement le basket-ball, cela suggère que quelque part, 

4
00:00:11,345 --> 00:00:13,792
dans ses centaines de milliards de paramètres, 

5
00:00:13,792 --> 00:00:18,320
il a intégré des connaissances sur une personne spécifique et sur son sport spécifique.

6
00:00:18,940 --> 00:00:22,276
Et je pense qu'en général, toute personne qui a joué avec l'un de ces modèles 

7
00:00:22,276 --> 00:00:25,400
a la nette impression qu'il a mémorisé des tonnes et des tonnes de faits.

8
00:00:25,700 --> 00:00:29,160
On peut donc raisonnablement se demander comment cela fonctionne exactement.

9
00:00:29,160 --> 00:00:31,040
Et où vivent ces faits ?

10
00:00:35,720 --> 00:00:38,623
En décembre dernier, quelques chercheurs de Google DeepMind 

11
00:00:38,623 --> 00:00:41,624
ont publié des travaux sur cette question, et ils utilisaient 

12
00:00:41,624 --> 00:00:44,480
cet exemple précis d'appariement des athlètes à leur sport.

13
00:00:44,900 --> 00:00:48,467
Et bien qu'une compréhension mécanique complète de la façon dont les faits 

14
00:00:48,467 --> 00:00:52,509
sont stockés reste à faire, ils ont obtenu quelques résultats partiels intéressants, 

15
00:00:52,509 --> 00:00:56,124
y compris la conclusion très générale de haut niveau que les faits semblent 

16
00:00:56,124 --> 00:00:58,977
vivre à l'intérieur d'une partie spécifique de ces réseaux, 

17
00:00:58,977 --> 00:01:02,640
connus sous le nom fantaisiste de perceptrons multicouches, ou MLP en abrégé.

18
00:01:03,120 --> 00:01:06,394
Dans les derniers chapitres, toi et moi avons creusé les détails derrière 

19
00:01:06,394 --> 00:01:09,978
les transformateurs, l'architecture qui sous-tend les grands modèles de langage, 

20
00:01:09,978 --> 00:01:12,500
et qui sous-tend également beaucoup d'autres IA modernes.

21
00:01:13,060 --> 00:01:14,748
Dans le chapitre le plus récent, nous nous sommes 

22
00:01:14,748 --> 00:01:16,200
concentrés sur une pièce appelée Attention.

23
00:01:16,840 --> 00:01:20,779
Et la prochaine étape pour toi et moi est de creuser les détails de ce qui se passe à 

24
00:01:20,779 --> 00:01:24,719
l'intérieur de ces perceptrons multicouches, qui constituent l'autre grande partie du 

25
00:01:24,719 --> 00:01:25,040
réseau.

26
00:01:25,680 --> 00:01:30,100
Le calcul ici est en fait relativement simple, surtout si tu le compares à l'attention.

27
00:01:30,560 --> 00:01:32,882
Cela se résume essentiellement à une paire de multiplications 

28
00:01:32,882 --> 00:01:34,980
de matrices avec un simple quelque chose entre les deux.

29
00:01:35,720 --> 00:01:40,460
Cependant, l'interprétation de ce que font ces calculs est extrêmement difficile.

30
00:01:41,560 --> 00:01:45,696
Notre objectif principal ici est de présenter les calculs et de les rendre mémorables, 

31
00:01:45,696 --> 00:01:49,641
mais j'aimerais le faire dans le contexte d'un exemple spécifique de la façon dont 

32
00:01:49,641 --> 00:01:53,160
l'un de ces blocs pourrait, au moins en principe, stocker un fait concret.

33
00:01:53,580 --> 00:01:57,080
Plus précisément, il s'agira de stocker le fait que Michael Jordan joue au basket-ball.

34
00:01:58,080 --> 00:02:00,788
Je dois préciser que la mise en page ici est inspirée d'une conversation 

35
00:02:00,788 --> 00:02:03,200
que j'ai eue avec l'un de ces chercheurs de DeepMind, Neil Nanda.

36
00:02:04,060 --> 00:02:07,775
Pour l'essentiel, je partirai du principe que tu as regardé les deux derniers chapitres 

37
00:02:07,775 --> 00:02:10,435
ou que tu as une idée générale de ce qu'est un transformateur, 

38
00:02:10,435 --> 00:02:12,546
mais les rafraîchissements ne font jamais de mal, 

39
00:02:12,546 --> 00:02:14,700
alors voici un petit rappel du déroulement général.

40
00:02:15,340 --> 00:02:18,250
Toi et moi avons étudié un modèle qui a été entraîné à 

41
00:02:18,250 --> 00:02:21,320
prendre un morceau de texte et à prédire ce qui va suivre.

42
00:02:21,720 --> 00:02:25,135
Ce texte d'entrée est d'abord décomposé en un ensemble de jetons, 

43
00:02:25,135 --> 00:02:29,638
c'est-à-dire de petits morceaux qui sont typiquement des mots ou de petits morceaux de 

44
00:02:29,638 --> 00:02:33,054
mots, et chaque jeton est associé à un vecteur à haute dimension, 

45
00:02:33,054 --> 00:02:35,280
c'est-à-dire à une longue liste de nombres.

46
00:02:35,840 --> 00:02:40,357
Cette séquence de vecteurs passe ensuite de façon répétée par deux types d'opérations, 

47
00:02:40,357 --> 00:02:44,667
l'attention, qui permet aux vecteurs de se transmettre des informations entre eux, 

48
00:02:44,667 --> 00:02:48,821
puis les perceptrons multicouches, le truc que nous allons creuser aujourd'hui, 

49
00:02:48,821 --> 00:02:52,300
et il y a aussi une certaine étape de normalisation entre les deux.

50
00:02:53,300 --> 00:02:57,789
Après que la séquence de vecteurs a traversé de nombreuses itérations différentes 

51
00:02:57,789 --> 00:03:02,169
de ces deux blocs, on espère qu'à la fin, chaque vecteur a absorbé suffisamment 

52
00:03:02,169 --> 00:03:06,329
d'informations, à la fois du contexte, de tous les autres mots de l'entrée, 

53
00:03:06,329 --> 00:03:10,873
et aussi de la connaissance générale qui a été incorporée dans les poids du modèle 

54
00:03:10,873 --> 00:03:15,253
par l'entraînement, pour qu'il puisse être utilisé pour faire une prédiction du 

55
00:03:15,253 --> 00:03:16,020
jeton suivant.

56
00:03:16,860 --> 00:03:20,905
L'une des idées clés que je veux que tu aies à l'esprit est que tous ces vecteurs 

57
00:03:20,905 --> 00:03:25,198
vivent dans un espace à très, très haute dimension, et lorsque tu penses à cet espace, 

58
00:03:25,198 --> 00:03:28,800
différentes directions peuvent encoder différents types de signification.

59
00:03:30,120 --> 00:03:33,871
Un exemple très classique auquel j'aime me référer est que si tu regardes 

60
00:03:33,871 --> 00:03:37,521
l'intégration de la femme et que tu soustrais l'intégration de l'homme, 

61
00:03:37,521 --> 00:03:41,221
et que tu fais ce petit pas et que tu l'ajoutes à un autre nom masculin, 

62
00:03:41,221 --> 00:03:44,263
quelque chose comme l'oncle, tu atterris quelque part très, 

63
00:03:44,263 --> 00:03:46,240
très près du nom féminin correspondant.

64
00:03:46,440 --> 00:03:50,880
En ce sens, cette direction particulière encode des informations sur le genre.

65
00:03:51,640 --> 00:03:54,265
L'idée est que de nombreuses autres directions distinctes dans 

66
00:03:54,265 --> 00:03:56,765
cet espace à très haute dimension pourraient correspondre à 

67
00:03:56,765 --> 00:03:59,640
d'autres caractéristiques que le modèle pourrait vouloir représenter.

68
00:04:01,400 --> 00:04:06,180
Dans un transformateur, ces vecteurs ne se contentent pas d'encoder le sens d'un seul mot.

69
00:04:06,680 --> 00:04:08,958
Au fur et à mesure qu'ils circulent dans le réseau, 

70
00:04:08,958 --> 00:04:11,718
ils s'imprègnent d'une signification beaucoup plus riche basée 

71
00:04:11,718 --> 00:04:15,180
sur tout le contexte qui les entoure, et aussi sur les connaissances du modèle.

72
00:04:15,880 --> 00:04:19,509
En fin de compte, chacun doit coder quelque chose qui va bien au-delà de la 

73
00:04:19,509 --> 00:04:23,760
signification d'un seul mot, puisqu'il doit être suffisant pour prédire ce qui va suivre.

74
00:04:24,560 --> 00:04:29,035
Nous avons déjà vu comment les blocs d'attention te permettent d'intégrer le contexte, 

75
00:04:29,035 --> 00:04:33,459
mais la majorité des paramètres du modèle se trouvent en fait à l'intérieur des blocs 

76
00:04:33,459 --> 00:04:37,831
MLP, et l'on peut penser qu'ils offrent une capacité supplémentaire pour stocker des 

77
00:04:37,831 --> 00:04:38,140
faits.

78
00:04:38,720 --> 00:04:42,394
Comme je l'ai dit, la leçon ici va être centrée sur l'exemple concret du 

79
00:04:42,394 --> 00:04:46,120
jouet qui pourrait stocker le fait que Michael Jordan joue au basket-ball.

80
00:04:47,120 --> 00:04:49,430
Maintenant, cet exemple de jouet va exiger que toi et moi 

81
00:04:49,430 --> 00:04:51,900
fassions quelques hypothèses sur cet espace à haute dimension.

82
00:04:52,360 --> 00:04:56,747
Tout d'abord, nous supposerons qu'une des directions représente l'idée d'un prénom 

83
00:04:56,747 --> 00:05:01,451
Michael, puis qu'une autre direction presque perpendiculaire représente l'idée du nom de 

84
00:05:01,451 --> 00:05:05,785
famille Jordan, et enfin qu'une troisième direction encore représentera l'idée du 

85
00:05:05,785 --> 00:05:06,420
basket-ball.

86
00:05:07,400 --> 00:05:11,135
Plus précisément, ce que je veux dire par là, c'est que si tu regardes 

87
00:05:11,135 --> 00:05:14,291
dans le réseau et que tu extrais l'un des vecteurs traités, 

88
00:05:14,291 --> 00:05:18,289
si son produit en points avec la direction du prénom Michael est égal à un, 

89
00:05:18,289 --> 00:05:22,340
cela signifie que le vecteur codifie l'idée d'une personne portant ce prénom.

90
00:05:23,800 --> 00:05:25,752
Sinon, le produit de ce point serait nul ou négatif, 

91
00:05:25,752 --> 00:05:28,700
ce qui signifierait que le vecteur ne s'aligne pas vraiment sur cette direction.

92
00:05:29,420 --> 00:05:32,463
Et pour simplifier, ignorons complètement la question très raisonnable de savoir 

93
00:05:32,463 --> 00:05:35,320
ce que cela pourrait signifier si ce produit de points était supérieur à un.

94
00:05:36,200 --> 00:05:39,641
De même, son produit en points avec ces autres directions te 

95
00:05:39,641 --> 00:05:43,760
permettrait de savoir s'il représente le nom de famille Jordan ou basket.

96
00:05:44,740 --> 00:05:48,736
Disons qu'un vecteur est censé représenter le nom complet, Michael Jordan, 

97
00:05:48,736 --> 00:05:52,680
et que son produit en points avec ces deux directions doit être égal à un.

98
00:05:53,480 --> 00:05:57,138
Étant donné que le texte Michael Jordan s'étend sur deux tokens différents, 

99
00:05:57,138 --> 00:06:00,605
cela signifie également que nous devons supposer qu'un bloc d'attention 

100
00:06:00,605 --> 00:06:04,071
antérieur a réussi à transmettre des informations au second de ces deux 

101
00:06:04,071 --> 00:06:06,960
vecteurs afin de s'assurer qu'il peut encoder les deux noms.

102
00:06:07,940 --> 00:06:11,480
Avec tous ces éléments comme hypothèses, plongeons maintenant dans la chair de la leçon.

103
00:06:11,880 --> 00:06:14,980
Que se passe-t-il à l'intérieur d'un perceptron multicouche ?

104
00:06:17,100 --> 00:06:20,762
Tu peux penser à cette séquence de vecteurs qui s'écoulent dans le bloc, 

105
00:06:20,762 --> 00:06:24,827
et te rappeler que chaque vecteur était à l'origine associé à l'un des tokens du 

106
00:06:24,827 --> 00:06:25,580
texte d'entrée.

107
00:06:26,080 --> 00:06:29,492
Ce qui va se passer, c'est que chaque vecteur individuel de cette séquence va 

108
00:06:29,492 --> 00:06:33,297
passer par une courte série d'opérations, que nous allons décortiquer dans un instant, 

109
00:06:33,297 --> 00:06:36,360
et à la fin, nous obtiendrons un autre vecteur avec la même dimension.

110
00:06:36,880 --> 00:06:40,792
Cet autre vecteur va s'ajouter au vecteur initial qui est entré, 

111
00:06:40,792 --> 00:06:43,200
et cette somme est le résultat qui sort.

112
00:06:43,720 --> 00:06:47,646
Cette séquence d'opérations est quelque chose que tu appliques à chaque vecteur de 

113
00:06:47,646 --> 00:06:51,620
la séquence, associé à chaque jeton de l'entrée, et tout cela se passe en parallèle.

114
00:06:52,100 --> 00:06:54,797
En particulier, les vecteurs ne se parlent pas entre eux dans cette étape, 

115
00:06:54,797 --> 00:06:56,200
ils font tous un peu ce qu'ils veulent.

116
00:06:56,720 --> 00:06:59,376
Et pour toi et moi, cela rend les choses beaucoup plus simples, 

117
00:06:59,376 --> 00:07:02,614
car cela signifie que si nous comprenons ce qui arrive à un seul des vecteurs 

118
00:07:02,614 --> 00:07:06,060
à travers ce bloc, nous comprenons effectivement ce qui arrive à tous les vecteurs.

119
00:07:07,100 --> 00:07:11,583
Lorsque je dis que ce bloc va coder le fait que Michael Jordan joue au basket-ball, 

120
00:07:11,583 --> 00:07:15,853
ce que je veux dire c'est que si un vecteur entre qui code le prénom Michael et 

121
00:07:15,853 --> 00:07:20,176
le nom Jordan, alors cette séquence de calculs produira quelque chose qui inclut 

122
00:07:20,176 --> 00:07:24,020
la direction basket-ball, ce qui s'ajoutera au vecteur à cette position.

123
00:07:25,600 --> 00:07:28,016
La première étape de ce processus consiste à multiplier 

124
00:07:28,016 --> 00:07:29,700
ce vecteur par une très grande matrice.

125
00:07:30,040 --> 00:07:31,980
Il n'y a pas de surprise, il s'agit d'apprentissage en profondeur.

126
00:07:32,680 --> 00:07:35,153
Et cette matrice, comme toutes celles que nous avons vues, 

127
00:07:35,153 --> 00:07:37,879
est remplie de paramètres de modèle appris à partir des données, 

128
00:07:37,879 --> 00:07:41,443
que tu peux considérer comme un ensemble de boutons et de cadrans qui sont réglés et 

129
00:07:41,443 --> 00:07:43,540
ajustés pour déterminer le comportement du modèle.

130
00:07:44,500 --> 00:07:48,515
Une bonne façon d'envisager la multiplication matricielle est d'imaginer que chaque 

131
00:07:48,515 --> 00:07:50,761
ligne de cette matrice est son propre vecteur, 

132
00:07:50,761 --> 00:07:54,585
et de faire un tas de produits de points entre ces lignes et le vecteur traité, 

133
00:07:54,585 --> 00:07:56,880
que j'appellerai E pour embedding (intégration).

134
00:07:57,280 --> 00:08:00,659
Par exemple, supposons que la toute première ligne corresponde 

135
00:08:00,659 --> 00:08:04,040
à ce prénom Michael direction dont nous supposons qu'il existe.

136
00:08:04,320 --> 00:08:09,345
Cela signifie que la première composante de ce résultat, ce produit de point ici, 

137
00:08:09,345 --> 00:08:14,800
serait un si ce vecteur code le prénom Michael, et zéro ou négatif dans le cas contraire.

138
00:08:15,880 --> 00:08:19,416
Encore plus amusant, prends un moment pour réfléchir à ce que cela signifierait si 

139
00:08:19,416 --> 00:08:23,080
cette première rangée était cette direction prénom Michael plus nom de famille Jordan.

140
00:08:23,700 --> 00:08:25,503
Et pour plus de simplicité, permets-moi d'aller 

141
00:08:25,503 --> 00:08:27,420
de l'avant et d'écrire cela sous la forme M plus J.

142
00:08:28,080 --> 00:08:30,848
Ensuite, en prenant un produit de point avec cet encastrement E, 

143
00:08:30,848 --> 00:08:34,255
les choses se répartissent vraiment bien, de sorte que cela ressemble à M point 

144
00:08:34,255 --> 00:08:34,980
E plus J point E.

145
00:08:34,980 --> 00:08:39,753
Et remarque que cela signifie que la valeur ultime sera deux si le vecteur code le 

146
00:08:39,753 --> 00:08:44,700
nom complet Michael Jordan, et sinon ce sera un ou quelque chose de plus petit que un.

147
00:08:45,340 --> 00:08:47,260
Et ce n'est qu'une seule ligne de cette matrice.

148
00:08:47,600 --> 00:08:50,274
Tu peux considérer que toutes les autres lignes posent en 

149
00:08:50,274 --> 00:08:53,272
parallèle d'autres types de questions, qu'elles sondent d'autres 

150
00:08:53,272 --> 00:08:56,040
types de caractéristiques du vecteur en cours de traitement.

151
00:08:56,700 --> 00:08:59,818
Très souvent, cette étape consiste également à ajouter un autre vecteur à la sortie, 

152
00:08:59,818 --> 00:09:02,240
qui est plein de paramètres du modèle appris à partir des données.

153
00:09:02,240 --> 00:09:04,560
Cet autre vecteur est appelé le biais.

154
00:09:05,180 --> 00:09:08,718
Pour notre exemple, je veux que tu imagines que la valeur de ce biais dans 

155
00:09:08,718 --> 00:09:12,115
ce tout premier composant est négative de un, ce qui signifie que notre 

156
00:09:12,115 --> 00:09:15,560
résultat final ressemble à ce produit de points pertinent, mais moins un.

157
00:09:16,120 --> 00:09:20,067
Tu pourrais très raisonnablement demander pourquoi je voudrais que tu supposes 

158
00:09:20,067 --> 00:09:23,965
que le modèle a appris cela, et dans un instant tu verras pourquoi c'est très 

159
00:09:23,965 --> 00:09:28,012
propre et agréable si nous avons une valeur ici qui est positive si et seulement 

160
00:09:28,012 --> 00:09:32,160
si un vecteur encode le nom complet Michael Jordan, et sinon c'est zéro ou négatif.

161
00:09:33,040 --> 00:09:36,152
Le nombre total de lignes de cette matrice, qui correspond en 

162
00:09:36,152 --> 00:09:39,516
quelque sorte au nombre de questions posées, dans le cas du GPT-3, 

163
00:09:39,516 --> 00:09:42,780
dont nous avons suivi les chiffres, est d'un peu moins de 50 000.

164
00:09:43,100 --> 00:09:46,640
En fait, c'est exactement quatre fois le nombre de dimensions de cet espace d'intégration.

165
00:09:46,920 --> 00:09:47,900
C'est un choix de conception.

166
00:09:47,940 --> 00:09:49,629
Tu pourrais en faire plus, tu pourrais en faire moins, 

167
00:09:49,629 --> 00:09:52,240
mais le fait d'avoir un multiple propre a tendance à être convivial pour le matériel.

168
00:09:52,740 --> 00:09:57,008
Comme cette matrice pleine de poids nous place dans un espace de dimension supérieure, 

169
00:09:57,008 --> 00:09:59,020
je vais lui donner le nom abrégé de W up.

170
00:09:59,020 --> 00:10:02,734
Je vais continuer à étiqueter le vecteur que nous traitons comme E, 

171
00:10:02,734 --> 00:10:07,160
et étiqueter ce vecteur de biais comme B et remettre tout cela dans le diagramme.

172
00:10:09,180 --> 00:10:12,847
À ce stade, un problème se pose : cette opération est purement linéaire, 

173
00:10:12,847 --> 00:10:15,360
mais la langue est un processus très non linéaire.

174
00:10:15,880 --> 00:10:19,778
Si l'entrée que nous mesurons est élevée pour Michael plus Jordan, 

175
00:10:19,778 --> 00:10:24,957
elle sera aussi nécessairement déclenchée par Michael plus Phelps et Alexis plus Jordan, 

176
00:10:24,957 --> 00:10:28,100
même si ces deux éléments n'ont aucun lien conceptuel.

177
00:10:28,540 --> 00:10:32,000
Ce que tu veux vraiment, c'est un simple oui ou non pour le nom complet.

178
00:10:32,900 --> 00:10:35,183
L'étape suivante consiste donc à faire passer ce grand 

179
00:10:35,183 --> 00:10:37,840
vecteur intermédiaire par une fonction non linéaire très simple.

180
00:10:38,360 --> 00:10:41,783
Un choix courant est celui qui prend toutes les valeurs négatives et les 

181
00:10:41,783 --> 00:10:45,300
fait correspondre à zéro et laisse toutes les valeurs positives inchangées.

182
00:10:46,440 --> 00:10:49,525
Et pour continuer avec la tradition de l'apprentissage profond qui 

183
00:10:49,525 --> 00:10:51,736
consiste à utiliser des noms trop fantaisistes, 

184
00:10:51,736 --> 00:10:55,190
cette fonction très simple est souvent appelée l'unité linéaire rectifiée, 

185
00:10:55,190 --> 00:10:56,020
ou ReLU en abrégé.

186
00:10:56,020 --> 00:10:57,880
Voici à quoi ressemble le graphique.

187
00:10:58,300 --> 00:11:02,251
Donc, en prenant notre exemple imaginé où cette première entrée du vecteur 

188
00:11:02,251 --> 00:11:06,624
intermédiaire est un, si et seulement si le nom complet est Michael Jordan et zéro 

189
00:11:06,624 --> 00:11:09,628
ou négatif sinon, après l'avoir fait passer par la ReLU, 

190
00:11:09,628 --> 00:11:14,053
tu te retrouves avec une valeur très propre où toutes les valeurs zéro et négatives 

191
00:11:14,053 --> 00:11:15,740
sont simplement écrêtées à zéro.

192
00:11:16,100 --> 00:11:19,780
Ce résultat serait donc un pour le nom complet Michael Jordan et zéro sinon.

193
00:11:20,560 --> 00:11:24,120
En d'autres termes, il imite très directement le comportement d'une porte ET.

194
00:11:25,660 --> 00:11:29,183
Souvent, les modèles utilisent une fonction légèrement modifiée appelée JLU, 

195
00:11:29,183 --> 00:11:32,020
qui a la même forme de base, elle est juste un peu plus lisse.

196
00:11:32,500 --> 00:11:35,720
Mais pour ce qui nous concerne, c'est un peu plus propre si nous ne pensons qu'au ReLU.

197
00:11:36,740 --> 00:11:40,800
Aussi, lorsque tu entends les gens faire référence aux neurones d'un transformateur, 

198
00:11:40,800 --> 00:11:42,520
ils parlent de ces valeurs ici même.

199
00:11:42,900 --> 00:11:47,360
Chaque fois que tu vois l'image d'un réseau neuronal avec une couche de points et une 

200
00:11:47,360 --> 00:11:49,849
série de lignes reliées à la couche précédente, 

201
00:11:49,849 --> 00:11:52,391
comme nous l'avons vu plus tôt dans cette série, 

202
00:11:52,391 --> 00:11:56,177
c'est généralement pour exprimer cette combinaison d'une étape linéaire, 

203
00:11:56,177 --> 00:12:00,793
une multiplication de matrice, suivie d'une fonction non linéaire simple par terme comme 

204
00:12:00,793 --> 00:12:01,260
une ReLU.

205
00:12:02,500 --> 00:12:05,813
Tu dirais que ce neurone est actif chaque fois que cette valeur 

206
00:12:05,813 --> 00:12:08,920
est positive et qu'il est inactif si cette valeur est nulle.

207
00:12:10,120 --> 00:12:12,380
L'étape suivante ressemble beaucoup à la première.

208
00:12:12,560 --> 00:12:16,580
Tu multiplies par une très grande matrice et tu ajoutes un certain terme de biais.

209
00:12:16,980 --> 00:12:21,091
Dans ce cas, le nombre de dimensions dans la sortie est ramené à la taille de 

210
00:12:21,091 --> 00:12:25,520
l'espace d'intégration, je vais donc l'appeler la matrice de projection vers le bas.

211
00:12:26,220 --> 00:12:28,811
Et cette fois, au lieu de penser aux choses ligne par ligne, 

212
00:12:28,811 --> 00:12:31,360
il est en fait plus agréable d'y penser colonne par colonne.

213
00:12:31,860 --> 00:12:35,305
Tu vois, une autre façon de retenir la multiplication matricielle dans 

214
00:12:35,305 --> 00:12:38,701
ta tête est d'imaginer que l'on prend chaque colonne de la matrice et 

215
00:12:38,701 --> 00:12:42,486
qu'on la multiplie par le terme correspondant dans le vecteur qu'elle traite, 

216
00:12:42,486 --> 00:12:45,640
puis que l'on additionne toutes ces colonnes remises à l'échelle.

217
00:12:46,840 --> 00:12:49,764
La raison pour laquelle il est plus agréable de penser de cette façon 

218
00:12:49,764 --> 00:12:52,855
est qu'ici les colonnes ont la même dimension que l'espace d'intégration, 

219
00:12:52,855 --> 00:12:55,780
nous pouvons donc les considérer comme des directions dans cet espace.

220
00:12:56,140 --> 00:12:59,414
Par exemple, nous imaginerons que le modèle a appris à faire cette 

221
00:12:59,414 --> 00:13:03,080
première colonne dans cette direction de basket que nous supposons exister.

222
00:13:04,180 --> 00:13:08,450
Cela signifie que lorsque le neurone correspondant à cette première position est actif, 

223
00:13:08,450 --> 00:13:10,780
nous ajouterons cette colonne au résultat final.

224
00:13:11,140 --> 00:13:15,780
Mais si ce neurone était inactif, si ce nombre était nul, alors cela n'aurait aucun effet.

225
00:13:16,500 --> 00:13:18,060
Et il ne s'agit pas seulement de basket-ball.

226
00:13:18,220 --> 00:13:21,771
Le modèle pourrait également intégrer cette colonne et bien d'autres caractéristiques 

227
00:13:21,771 --> 00:13:25,200
qu'il souhaite associer à quelque chose qui porte le nom complet de Michael Jordan.

228
00:13:26,980 --> 00:13:31,787
Et en même temps, toutes les autres colonnes de cette matrice t'indiquent 

229
00:13:31,787 --> 00:13:36,660
ce qui sera ajouté au résultat final si le neurone correspondant est actif.

230
00:13:37,360 --> 00:13:41,389
Et si tu as un biais dans ce cas, c'est quelque chose que tu ajoutes à chaque fois, 

231
00:13:41,389 --> 00:13:43,500
quelles que soient les valeurs des neurones.

232
00:13:44,060 --> 00:13:45,280
Tu peux te demander ce que cela fait.

233
00:13:45,540 --> 00:13:47,688
Comme pour tous les objets remplis de paramètres ici, 

234
00:13:47,688 --> 00:13:49,320
c'est un peu difficile à dire exactement.

235
00:13:49,320 --> 00:13:51,914
Il y a peut-être une comptabilité que le réseau doit faire, 

236
00:13:51,914 --> 00:13:54,380
mais tu peux te sentir libre de l'ignorer pour l'instant.

237
00:13:54,860 --> 00:13:57,095
Pour rendre notre notation un peu plus compacte, 

238
00:13:57,095 --> 00:14:00,290
j'appellerai cette grande matrice W vers le bas et, de la même façon, 

239
00:14:00,290 --> 00:14:04,260
j'appellerai ce vecteur de biais B vers le bas et je le remettrai dans notre diagramme.

240
00:14:04,740 --> 00:14:08,149
Comme je l'ai indiqué plus tôt, ce que tu fais avec ce résultat final, 

241
00:14:08,149 --> 00:14:12,375
c'est l'ajouter au vecteur qui est entré dans le bloc à cette position et cela te donne 

242
00:14:12,375 --> 00:14:13,240
ce résultat final.

243
00:14:13,820 --> 00:14:19,262
Par exemple, si le vecteur qui entre codait à la fois le prénom Michael et le nom Jordan, 

244
00:14:19,262 --> 00:14:24,523
cette séquence d'opérations déclenchera la porte ET et ajoutera la direction du ballon 

245
00:14:24,523 --> 00:14:29,240
de basket, de sorte que le vecteur qui sort codera tous ces éléments ensemble.

246
00:14:29,820 --> 00:14:32,053
Et n'oublie pas qu'il s'agit d'un processus qui se 

247
00:14:32,053 --> 00:14:34,200
déroule en parallèle pour chacun de ces vecteurs.

248
00:14:34,800 --> 00:14:37,812
En particulier, si l'on prend les chiffres du GPT-3, 

249
00:14:37,812 --> 00:14:41,734
cela signifie que ce bloc ne contient pas seulement 50 000 neurones, 

250
00:14:41,734 --> 00:14:44,860
mais aussi 50 000 fois le nombre de jetons de l'entrée.

251
00:14:48,180 --> 00:14:51,127
Voilà donc toute l'opération, deux produits matriciels, 

252
00:14:51,127 --> 00:14:55,180
chacun avec un biais ajouté et une simple fonction d'écrêtage entre les deux.

253
00:14:56,080 --> 00:14:58,307
Tous ceux d'entre vous qui ont regardé les vidéos précédentes 

254
00:14:58,307 --> 00:15:00,428
de la série reconnaîtront cette structure comme le type de 

255
00:15:00,428 --> 00:15:02,620
réseau neuronal le plus basique que nous avons étudié là-bas.

256
00:15:03,080 --> 00:15:06,100
Dans cet exemple, il a été entraîné à reconnaître des chiffres manuscrits.

257
00:15:06,580 --> 00:15:10,568
Ici, dans le contexte d'un transformateur pour un grand modèle de langue, 

258
00:15:10,568 --> 00:15:14,394
il s'agit d'une pièce d'une architecture plus vaste et toute tentative 

259
00:15:14,394 --> 00:15:18,329
d'interprétation de ce qu'il fait exactement est fortement liée à l'idée 

260
00:15:18,329 --> 00:15:23,180
d'encoder des informations dans des vecteurs d'un espace d'encastrement à haute dimension.

261
00:15:24,260 --> 00:15:27,587
C'est la leçon principale, mais je veux prendre du recul et réfléchir à 

262
00:15:27,587 --> 00:15:30,823
deux choses différentes, la première étant une sorte de comptabilité, 

263
00:15:30,823 --> 00:15:34,474
et la seconde impliquant un fait très stimulant sur les dimensions supérieures 

264
00:15:34,474 --> 00:15:38,080
que je ne connaissais pas jusqu'à ce que je me penche sur les transformateurs.

265
00:15:41,080 --> 00:15:44,238
Dans les deux derniers chapitres, toi et moi avons commencé à 

266
00:15:44,238 --> 00:15:48,824
compter le nombre total de paramètres dans GPT-3 et à voir exactement où ils se trouvent, 

267
00:15:48,824 --> 00:15:50,760
alors terminons rapidement le jeu ici.

268
00:15:51,400 --> 00:15:54,849
J'ai déjà mentionné comment cette matrice de projection vers le 

269
00:15:54,849 --> 00:15:58,514
haut a un peu moins de 50 000 lignes et que chaque ligne correspond 

270
00:15:58,514 --> 00:16:02,180
à la taille de l'espace d'intégration, qui pour GPT-3 est de 12 288.

271
00:16:03,240 --> 00:16:08,337
En les multipliant, on obtient 604 millions de paramètres pour cette seule matrice, 

272
00:16:08,337 --> 00:16:12,038
et la projection vers le bas a le même nombre de paramètres, 

273
00:16:12,038 --> 00:16:13,920
mais avec une forme transposée.

274
00:16:14,500 --> 00:16:17,400
Ensemble, ils donnent donc environ 1,2 milliard de paramètres.

275
00:16:18,280 --> 00:16:21,207
Le vecteur de biais tient également compte de quelques paramètres supplémentaires, 

276
00:16:21,207 --> 00:16:24,100
mais c'est une proportion triviale du total, alors je ne vais même pas le montrer.

277
00:16:24,660 --> 00:16:29,685
Dans GPT-3, cette séquence de vecteurs d'intégration passe par non pas un, 

278
00:16:29,685 --> 00:16:34,107
mais 96 MLP distincts, de sorte que le nombre total de paramètres 

279
00:16:34,107 --> 00:16:38,060
consacrés à tous ces blocs s'élève à environ 116 milliards.

280
00:16:38,820 --> 00:16:41,917
Cela représente environ deux tiers des paramètres totaux du réseau, 

281
00:16:41,917 --> 00:16:44,832
et lorsque tu les ajoutes à tout ce que nous avions auparavant, 

282
00:16:44,832 --> 00:16:47,839
pour les blocs d'attention, l'encastrement et le désencastrement, 

283
00:16:47,839 --> 00:16:51,620
tu obtiens effectivement ce grand total de 175 milliards, comme cela a été annoncé.

284
00:16:53,060 --> 00:16:56,667
Il est probablement utile de mentionner qu'il existe un autre ensemble de paramètres 

285
00:16:56,667 --> 00:16:59,935
associés à ces étapes de normalisation que cette explication n'a pas abordé, 

286
00:16:59,935 --> 00:17:03,458
mais comme le vecteur de biais, ils représentent une proportion très insignifiante 

287
00:17:03,458 --> 00:17:03,840
du total.

288
00:17:05,900 --> 00:17:08,049
En ce qui concerne le deuxième point de réflexion, 

289
00:17:08,049 --> 00:17:11,253
tu te demandes peut-être si cet exemple central sur lequel nous avons passé 

290
00:17:11,253 --> 00:17:14,415
tant de temps reflète la façon dont les faits sont réellement stockés dans 

291
00:17:14,415 --> 00:17:15,680
les grands modèles de langage.

292
00:17:16,319 --> 00:17:20,031
Il est vrai que les lignes de cette première matrice peuvent être considérées comme des 

293
00:17:20,031 --> 00:17:23,659
directions dans cet espace d'intégration, et cela signifie que l'activation de chaque 

294
00:17:23,659 --> 00:17:27,076
neurone t'indique dans quelle mesure un vecteur donné s'aligne sur une direction 

295
00:17:27,076 --> 00:17:27,540
spécifique.

296
00:17:27,760 --> 00:17:31,000
Il est également vrai que les colonnes de cette deuxième matrice 

297
00:17:31,000 --> 00:17:34,340
t'indiquent ce qui sera ajouté au résultat si ce neurone est actif.

298
00:17:34,640 --> 00:17:36,800
Dans les deux cas, il s'agit simplement de faits mathématiques.

299
00:17:37,740 --> 00:17:42,015
Cependant, les preuves suggèrent que les neurones individuels représentent très rarement 

300
00:17:42,015 --> 00:17:44,657
une seule caractéristique propre comme Michael Jordan, 

301
00:17:44,657 --> 00:17:48,403
et il pourrait en fait y avoir une très bonne raison pour que ce soit le cas, 

302
00:17:48,403 --> 00:17:52,390
liée à une idée qui flotte autour des chercheurs en interprétabilité ces jours-ci, 

303
00:17:52,390 --> 00:17:54,120
connue sous le nom de superposition.

304
00:17:54,640 --> 00:17:58,552
C'est une hypothèse qui pourrait aider à expliquer à la fois pourquoi les modèles sont 

305
00:17:58,552 --> 00:18:02,420
particulièrement difficiles à interpréter et pourquoi ils s'adaptent étonnamment bien.

306
00:18:03,500 --> 00:18:07,536
L'idée de base est que si tu as un espace à n dimensions et que tu veux représenter un 

307
00:18:07,536 --> 00:18:11,247
tas de caractéristiques différentes en utilisant des directions qui sont toutes 

308
00:18:11,247 --> 00:18:14,170
perpendiculaires les unes aux autres dans cet espace, tu sais, 

309
00:18:14,170 --> 00:18:17,186
de façon à ce que si tu ajoutes un composant dans une direction, 

310
00:18:17,186 --> 00:18:21,269
il n'influence aucune des autres directions, alors le nombre maximum de vecteurs que tu 

311
00:18:21,269 --> 00:18:23,960
peux faire tenir est seulement n, le nombre de dimensions.

312
00:18:24,600 --> 00:18:27,620
Pour un mathématicien, en fait, c'est la définition de la dimension.

313
00:18:28,220 --> 00:18:30,852
Mais là où ça devient intéressant, c'est si tu relâches 

314
00:18:30,852 --> 00:18:33,580
un peu cette contrainte et que tu tolères un peu de bruit.

315
00:18:34,180 --> 00:18:37,377
Disons que tu permets à ces caractéristiques d'être représentées par 

316
00:18:37,377 --> 00:18:40,065
des vecteurs qui ne sont pas exactement perpendiculaires, 

317
00:18:40,065 --> 00:18:43,820
ils sont juste presque perpendiculaires, peut-être entre 89 et 91 degrés d'écart.

318
00:18:44,820 --> 00:18:48,020
Si nous étions en deux ou trois dimensions, cela ne fait aucune différence.

319
00:18:48,260 --> 00:18:51,221
Cela te laisse à peine une marge de manœuvre supplémentaire pour insérer 

320
00:18:51,221 --> 00:18:53,980
plus de vecteurs, ce qui rend d'autant plus contre-intuitif le fait 

321
00:18:53,980 --> 00:18:56,780
que pour des dimensions plus élevées, la réponse change radicalement.

322
00:18:57,660 --> 00:19:01,579
Je peux te donner une illustration vraiment rapide et sale de ceci en 

323
00:19:01,579 --> 00:19:06,057
utilisant un peu de Python qui va créer une liste de vecteurs à 100 dimensions, 

324
00:19:06,057 --> 00:19:10,089
chacun initialisé de façon aléatoire, et cette liste va contenir 10 000 

325
00:19:10,089 --> 00:19:14,400
vecteurs distincts, donc 100 fois plus de vecteurs qu'il n'y a de dimensions.

326
00:19:15,320 --> 00:19:19,900
Ce graphique ici montre la distribution des angles entre les paires de ces vecteurs.

327
00:19:20,680 --> 00:19:24,988
Comme ils ont commencé au hasard, ces angles peuvent être compris entre 0 et 180 degrés, 

328
00:19:24,988 --> 00:19:28,135
mais tu remarqueras que déjà, même pour les vecteurs aléatoires, 

329
00:19:28,135 --> 00:19:31,960
il y a une forte tendance à ce que les choses soient plus proches de 90 degrés.

330
00:19:32,500 --> 00:19:36,380
Ensuite, je vais lancer un processus d'optimisation qui, de façon itérative, 

331
00:19:36,380 --> 00:19:40,562
modifie tous ces vecteurs pour qu'ils deviennent plus perpendiculaires les uns par 

332
00:19:40,562 --> 00:19:41,520
rapport aux autres.

333
00:19:42,060 --> 00:19:44,406
Après avoir répété cette opération plusieurs fois, 

334
00:19:44,406 --> 00:19:46,660
voici à quoi ressemble la répartition des angles.

335
00:19:47,120 --> 00:19:51,868
Nous devons en fait faire un zoom ici parce que tous les angles possibles entre les 

336
00:19:51,868 --> 00:19:56,900
paires de vecteurs se situent à l'intérieur de cette plage étroite entre 89 et 91 degrés.

337
00:19:58,020 --> 00:20:02,293
En général, une conséquence de ce qu'on appelle le lemme de Johnson-Lindenstrauss est 

338
00:20:02,293 --> 00:20:06,367
que le nombre de vecteurs que tu peux entasser dans un espace et qui sont presque 

339
00:20:06,367 --> 00:20:10,840
perpendiculaires comme celui-ci croît de façon exponentielle avec le nombre de dimensions.

340
00:20:11,960 --> 00:20:14,814
Ceci est très significatif pour les grands modèles de langue, 

341
00:20:14,814 --> 00:20:18,728
qui pourraient bénéficier de l'association d'idées indépendantes avec des directions 

342
00:20:18,728 --> 00:20:19,880
presque perpendiculaires.

343
00:20:20,000 --> 00:20:22,576
Cela signifie qu'il est possible de stocker beaucoup, 

344
00:20:22,576 --> 00:20:26,440
beaucoup plus d'idées qu'il n'y a de dimensions dans l'espace qui lui est alloué.

345
00:20:27,320 --> 00:20:29,256
Cela pourrait expliquer en partie pourquoi la 

346
00:20:29,256 --> 00:20:31,740
performance du modèle semble s'adapter si bien à la taille.

347
00:20:32,540 --> 00:20:36,344
Un espace qui a 10 fois plus de dimensions peut stocker beaucoup, 

348
00:20:36,344 --> 00:20:39,400
beaucoup plus que 10 fois plus d'idées indépendantes.

349
00:20:40,420 --> 00:20:43,790
Et cela ne concerne pas seulement cet espace d'intégration où vivent les 

350
00:20:43,790 --> 00:20:47,023
vecteurs qui circulent dans le modèle, mais aussi ce vecteur plein de 

351
00:20:47,023 --> 00:20:50,440
neurones au milieu de ce perceptron multicouche que nous venons d'étudier.

352
00:20:50,960 --> 00:20:55,150
En d'autres termes, aux dimensions du GPT-3, il pourrait ne pas se contenter de sonder 

353
00:20:55,150 --> 00:20:59,388
50 000 caractéristiques, mais s'il tirait parti de cette énorme capacité supplémentaire 

354
00:20:59,388 --> 00:21:02,567
en utilisant des directions presque perpendiculaires de l'espace, 

355
00:21:02,567 --> 00:21:06,565
il pourrait sonder beaucoup, beaucoup plus de caractéristiques du vecteur en cours 

356
00:21:06,565 --> 00:21:07,240
de traitement.

357
00:21:07,780 --> 00:21:11,220
Mais si c'est le cas, cela signifie que les caractéristiques individuelles 

358
00:21:11,220 --> 00:21:14,340
ne seront pas visibles sous la forme d'un seul neurone qui s'allume.

359
00:21:14,660 --> 00:21:18,485
Il faudrait qu'il ressemble plutôt à une combinaison spécifique de neurones, 

360
00:21:18,485 --> 00:21:19,380
une superposition.

361
00:21:20,400 --> 00:21:22,878
Pour ceux d'entre vous qui sont curieux d'en savoir plus, 

362
00:21:22,878 --> 00:21:25,015
un terme de recherche clé est sparse autoencoder, 

363
00:21:25,015 --> 00:21:28,135
qui est un outil utilisé par certains spécialistes de l'interprétabilité 

364
00:21:28,135 --> 00:21:30,401
pour essayer d'extraire les vraies caractéristiques, 

365
00:21:30,401 --> 00:21:32,880
même si elles sont très superposées sur tous ces neurones.

366
00:21:33,540 --> 00:21:35,057
Je vais te donner un lien vers deux excellents 

367
00:21:35,057 --> 00:21:36,800
articles sur l'anthropologie qui traitent de ce sujet.

368
00:21:37,880 --> 00:21:40,873
À ce stade, nous n'avons pas abordé tous les détails d'un transformateur, 

369
00:21:40,873 --> 00:21:43,300
mais toi et moi avons touché les points les plus importants.

370
00:21:43,520 --> 00:21:45,580
La principale chose que je veux aborder dans un 

371
00:21:45,580 --> 00:21:47,640
prochain chapitre est le processus de formation.

372
00:21:48,460 --> 00:21:51,248
D'une part, la réponse courte à la question de savoir comment fonctionne la 

373
00:21:51,248 --> 00:21:53,010
formation est qu'il s'agit de rétropropagation, 

374
00:21:53,010 --> 00:21:55,689
et nous avons abordé la rétropagation dans un contexte distinct avec les 

375
00:21:55,689 --> 00:21:56,900
chapitres précédents de la série.

376
00:21:57,220 --> 00:22:00,754
Mais il y a plus à discuter, comme la fonction de coût spécifique utilisée pour les 

377
00:22:00,754 --> 00:22:04,498
modèles de langage, l'idée d'un réglage fin à l'aide de l'apprentissage par renforcement 

378
00:22:04,498 --> 00:22:07,780
avec un retour d'information humain, et la notion de lois de mise à l'échelle.

379
00:22:08,960 --> 00:22:10,825
Petite note pour les adeptes actifs parmi vous, 

380
00:22:10,825 --> 00:22:13,585
il y a un certain nombre de vidéos non liées à l'apprentissage machine 

381
00:22:13,585 --> 00:22:16,579
que j'ai hâte de me mettre sous la dent avant de faire ce prochain chapitre, 

382
00:22:16,579 --> 00:22:20,000
donc ça risque de prendre du temps, mais je promets que ça viendra en temps et en heure.

383
00:22:35,640 --> 00:22:37,920
Merci.

