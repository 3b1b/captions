1
00:00:00,000 --> 00:00:05,108
如果你给一个大型语言模型输入 "迈克尔-乔丹从事空白运动 

2
00:00:05,108 --> 00:00:08,807
"这个短语，然后让它预测接下来会发生什么，

3
00:00:08,807 --> 00:00:13,387
而它正确地预测了篮球，这就表明在它的数千亿个参数中，

4
00:00:13,387 --> 00:00:18,320
某个地方已经包含了关于某个特定的人和他的特定运动的知识。

5
00:00:18,940 --> 00:00:23,139
我认为，一般来说，玩过这些模型的人都会清楚地感觉到，

6
00:00:23,139 --> 00:00:25,400
它已经记住了成吨成吨的事实。

7
00:00:25,700 --> 00:00:29,160
因此，一个合理的问题是：这到底是怎么做到的？

8
00:00:29,160 --> 00:00:31,040
这些事实在哪里？

9
00:00:35,720 --> 00:00:38,259
去年 12 月，谷歌 DeepMind 

10
00:00:38,259 --> 00:00:41,052
的几位研究人员发布了有关这一问题的研究成果，

11
00:00:41,052 --> 00:00:44,480
他们使用的具体例子是将运动员与他们的运动项目进行匹配。

12
00:00:44,900 --> 00:00:48,882
虽然对事实是如何存储的完整机制理解仍未解决，

13
00:00:48,882 --> 00:00:51,959
但他们已经有了一些有趣的部分结果，

14
00:00:51,959 --> 00:00:56,304
包括一个非常普遍的高层次结论，即事实似乎存在于这

15
00:00:56,304 --> 00:01:01,372
些网络的一个特定部分中，这个部分被奇特地称为多层感知器，

16
00:01:01,372 --> 00:01:02,640
简称 MLP。

17
00:01:03,120 --> 00:01:07,727
在过去的几章中，你和我一起深入研究了变换器背后的细节、大

18
00:01:07,727 --> 00:01:12,500
型语言模型的底层架构，以及许多其他现代人工智能的底层架构。

19
00:01:13,060 --> 00:01:16,200
在最近的章节中，我们重点讨论了一篇名为《注意力》的文章。

20
00:01:16,840 --> 00:01:22,430
对你我来说，下一步就是深入研究这些多层感知器内部发生的细节，

21
00:01:22,430 --> 00:01:25,040
它们构成了网络的另一大部分。

22
00:01:25,680 --> 00:01:30,100
这里的计算其实相对简单，尤其是与注意力相比。

23
00:01:30,560 --> 00:01:34,980
它本质上是一对矩阵乘法，中间有一个简单的东西。

24
00:01:35,720 --> 00:01:40,460
然而，解释这些计算所做的事情却极具挑战性。

25
00:01:41,560 --> 00:01:44,664
在这里，我们的主要目标是逐步完成计算，

26
00:01:44,664 --> 00:01:48,585
并让人过目不忘，但我想通过一个具体的例子来说明，

27
00:01:48,585 --> 00:01:53,160
至少在原则上，这些模块中的一个是如何存储一个具体事实的。

28
00:01:53,580 --> 00:01:57,080
具体地说，就是在迈克尔-乔丹打篮球这件事上做文章。

29
00:01:58,080 --> 00:02:00,595
值得一提的是，这里的布局灵感来自我与 DeepMind 

30
00:02:00,595 --> 00:02:03,200
研究人员之一尼尔-南达（Neil Nanda）的一次谈话。

31
00:02:04,060 --> 00:02:07,775
在大多数情况下，我会假设你已经观看了前两章，

32
00:02:07,775 --> 00:02:11,828
或者你已经对变压器有了基本的了解，但温故而知新，

33
00:02:11,828 --> 00:02:14,700
所以这里要快速提醒你一下整体流程。

34
00:02:15,340 --> 00:02:18,629
你和我一直在研究一个模型，这个模型经过训练，

35
00:02:18,629 --> 00:02:21,320
可以接收一段文字并预测接下来的内容。

36
00:02:21,720 --> 00:02:25,460
输入文本首先会被分解成一堆标记，

37
00:02:25,460 --> 00:02:29,435
也就是通常是单词或单词片段的小块，

38
00:02:29,435 --> 00:02:35,280
每个标记都与一个高维向量相关联，也就是一长串数字。

39
00:02:35,840 --> 00:02:40,307
然后，这个向量序列会反复经过两种操作，

40
00:02:40,307 --> 00:02:45,716
一种是注意力操作，它允许向量之间相互传递信息，

41
00:02:45,716 --> 00:02:52,300
另一种是多层感知器操作，也就是我们今天要深入研究的东西。

42
00:02:53,300 --> 00:02:57,796
在向量序列经过这两个模块的多次迭代后，

43
00:02:57,796 --> 00:03:02,293
我们希望每个向量都能吸收足够多的信息，

44
00:03:02,293 --> 00:03:07,500
这些信息既来自上下文、输入中的所有其他单词，

45
00:03:07,500 --> 00:03:11,996
也来自通过训练植入模型权重的一般知识，

46
00:03:11,996 --> 00:03:16,020
从而可以用来预测下一个标记是什么。

47
00:03:16,860 --> 00:03:19,754
我希望你们记住的一个关键概念是，

48
00:03:19,754 --> 00:03:24,096
所有这些向量都生活在一个非常非常高的维度空间中，

49
00:03:24,096 --> 00:03:28,800
而当你思考这个空间时，不同的方向可以编码不同的意义。

50
00:03:30,120 --> 00:03:33,066
我喜欢引用的一个非常经典的例子是，

51
00:03:33,066 --> 00:03:35,840
如果你看一下 "女人 "的内嵌，

52
00:03:35,840 --> 00:03:39,826
然后减去 "男人 "的内嵌，再把这一小步加到另

53
00:03:39,826 --> 00:03:42,600
一个阳性名词上，比如 "叔叔"，

54
00:03:42,600 --> 00:03:46,240
你就会发现它与相应的阴性名词非常非常接近。

55
00:03:46,440 --> 00:03:50,880
从这个意义上说，这个特定的方向编码了性别信息。

56
00:03:51,640 --> 00:03:54,662
我们的想法是，在这个超高维空间中，

57
00:03:54,662 --> 00:03:59,640
许多其他不同的方向可能对应着模型可能想要表示的其他特征。

58
00:04:01,400 --> 00:04:03,712
不过，在转换器中，这些向量并不

59
00:04:03,712 --> 00:04:06,180
仅仅是对单个单词的含义进行编码。

60
00:04:06,680 --> 00:04:10,821
当这些信息在网络中流动时，它们会根据周

61
00:04:10,821 --> 00:04:15,180
围的环境以及模型的知识吸收更丰富的含义。

62
00:04:15,880 --> 00:04:20,676
归根结底，每一个词都需要编码远远超出一个词的含义的东西，

63
00:04:20,676 --> 00:04:23,760
因为它需要足以预测接下来会发生什么。

64
00:04:24,560 --> 00:04:31,488
我们已经看到注意力区块是如何将上下文结合在一起的，

65
00:04:31,488 --> 00:04:38,140
但实际上大部分模型参数都存在于 MLP 区块中。

66
00:04:38,720 --> 00:04:42,341
就像我说的，这堂课的中心是一个具体的玩具例子，

67
00:04:42,341 --> 00:04:46,120
说明它到底是如何存储迈克尔-乔丹打篮球的事实的。

68
00:04:47,120 --> 00:04:51,900
现在，这个玩具示例需要你我对高维空间做出一些假设。

69
00:04:52,360 --> 00:04:58,162
首先，我们假设其中一个方向代表迈克尔这个名字的概念，

70
00:04:58,162 --> 00:05:03,518
然后另一个几乎垂直的方向代表乔丹这个姓氏的概念，

71
00:05:03,518 --> 00:05:06,420
第三个方向代表篮球的概念。

72
00:05:07,400 --> 00:05:13,220
具体来说，我的意思是，如果你在网络中找到一个正在处理的向量，

73
00:05:13,220 --> 00:05:17,295
如果它与这个名字迈克尔方向的点乘积是 1，

74
00:05:17,295 --> 00:05:22,340
这就意味着这个向量编码了一个名字叫迈克尔的人的想法。

75
00:05:23,800 --> 00:05:28,700
否则，点积将为零或负，这意味着矢量并不真正与该方向一致。

76
00:05:29,420 --> 00:05:32,294
为了简单起见，让我们完全忽略一个非常合

77
00:05:32,294 --> 00:05:35,320
理的问题：如果点积大于 1 意味着什么？

78
00:05:36,200 --> 00:05:40,736
同样，它与这些其他方向的点乘积就能告诉你，

79
00:05:40,736 --> 00:05:43,760
它代表的是姓乔丹还是姓篮球。

80
00:05:44,740 --> 00:05:49,000
因此，假设一个向量要表示迈克尔-乔丹的全名，

81
00:05:49,000 --> 00:05:52,680
那么它与这两个方向的点积都必须是 1。

82
00:05:53,480 --> 00:05:56,041
由于文本迈克尔-乔丹（Michael 

83
00:05:56,041 --> 00:05:58,467
Jordan）跨越了两个不同的标记，

84
00:05:58,467 --> 00:06:01,837
这也就意味着我们必须假设先前的注意力区块已经成功地

85
00:06:01,837 --> 00:06:04,533
将信息传递给了这两个向量中的第二个向量，

86
00:06:04,533 --> 00:06:06,960
从而确保它可以对这两个名字进行编码。

87
00:06:07,940 --> 00:06:11,480
有了这些假设，现在让我们进入本课的主要内容。

88
00:06:11,880 --> 00:06:14,980
多层感知器内部发生了什么？

89
00:06:17,100 --> 00:06:21,434
你可以把这一连串的向量想象成流入程序块，记住，

90
00:06:21,434 --> 00:06:25,580
每个向量最初都与输入文本中的一个标记相关联。

91
00:06:26,080 --> 00:06:30,706
接下来，序列中的每个单独向量都会经过一系列简短的运算，

92
00:06:30,706 --> 00:06:35,846
我们稍后会解开这些运算，最后，我们会得到另一个具有相同维度的

93
00:06:35,846 --> 00:06:36,360
向量。

94
00:06:36,880 --> 00:06:43,200
另一个矢量将与流入的原始矢量相加，然后得出流出的结果。

95
00:06:43,720 --> 00:06:47,154
这一连串的操作会应用到序列中的每个向量，

96
00:06:47,154 --> 00:06:51,620
并与输入中的每个标记相关联，所有操作都是并行进行的。

97
00:06:52,100 --> 00:06:56,200
特别是，在这一步中，矢量之间并不对话，它们都在做自己的事情。

98
00:06:56,720 --> 00:06:59,427
对你我来说，这实际上让事情变得简单多了，

99
00:06:59,427 --> 00:07:03,488
因为这意味着如果我们了解了通过这个区块的一个矢量发生了什么，

100
00:07:03,488 --> 00:07:06,060
我们就能有效地了解所有矢量发生了什么。

101
00:07:07,100 --> 00:07:11,612
当我说这个区块将对迈克尔-乔丹打篮球这一事实进行编码时，

102
00:07:11,612 --> 00:07:14,190
我的意思是，如果有一个向量输入，

103
00:07:14,190 --> 00:07:17,090
其中编码了迈克尔的名字和乔丹的姓氏，

104
00:07:17,090 --> 00:07:21,119
那么这一连串的计算就会产生包含篮球这个方向的结果，

105
00:07:21,119 --> 00:07:24,020
这就是在该位置对向量进行添加的结果。

106
00:07:25,600 --> 00:07:29,700
这个过程的第一步看起来就像用一个很大的矩阵乘以该向量。

107
00:07:30,040 --> 00:07:31,980
不出意外，这就是深度学习。

108
00:07:32,680 --> 00:07:35,554
这个矩阵就像我们看到的其他矩阵一样，

109
00:07:35,554 --> 00:07:38,110
充满了从数据中学习到的模型参数，

110
00:07:38,110 --> 00:07:40,825
你可以把它想象成一堆旋钮和刻度盘，

111
00:07:40,825 --> 00:07:43,540
通过调整这些参数来决定模型的行为。

112
00:07:44,500 --> 00:07:48,565
现在，一种思考矩阵乘法的好方法是将矩阵的每一

113
00:07:48,565 --> 00:07:52,630
行都想象成自己的向量，然后在这些行和被处理的

114
00:07:52,630 --> 00:07:56,880
向量之间进行一系列点乘，我将用 E 表示嵌入。

115
00:07:57,280 --> 00:08:00,424
例如，假设第一行恰好等于我们假定存在的 

116
00:08:00,424 --> 00:08:04,040
Michael direction 这个名字。

117
00:08:04,320 --> 00:08:08,405
这就意味着，如果该向量编码的是迈克尔这个名字，

118
00:08:08,405 --> 00:08:12,846
那么输出的第一个分量，也就是这里的点积，就是 1，

119
00:08:12,846 --> 00:08:14,800
否则就是 0 或负数。

120
00:08:15,880 --> 00:08:21,564
更有趣的是，花点时间想一想，如果第一排是迈克尔加乔丹的方向，

121
00:08:21,564 --> 00:08:23,080
那将意味着什么。

122
00:08:23,700 --> 00:08:27,420
为了简单起见，让我把它写成 M 加 J。

123
00:08:28,080 --> 00:08:31,897
然后，与嵌入 E 进行点积，情况就会很好地分布开来，

124
00:08:31,897 --> 00:08:34,980
看起来就像 M 点 E 加上 J 点 E。

125
00:08:34,980 --> 00:08:39,435
请注意，如果向量编码的是迈克尔-乔丹的全名，

126
00:08:39,435 --> 00:08:44,700
那么最终值就是 2，否则就是 1 或小于 1 的值。

127
00:08:45,340 --> 00:08:47,260
这只是矩阵中的一行。

128
00:08:47,600 --> 00:08:52,737
你可以把所有其他行看作是在并行地提出一些其他类型的问题，

129
00:08:52,737 --> 00:08:56,040
探究被处理向量的一些其他类型的特征。

130
00:08:56,700 --> 00:08:59,885
很多时候，这一步还涉及向输出中添加另一个向量，

131
00:08:59,885 --> 00:09:02,240
其中包含从数据中学习到的模型参数。

132
00:09:02,240 --> 00:09:04,560
这另一个向量被称为偏差。

133
00:09:05,180 --> 00:09:08,072
在我们的例子中，我想让你想象一下，

134
00:09:08,072 --> 00:09:11,476
第一个分量中的偏差值是负 1，这意味着我

135
00:09:11,476 --> 00:09:15,560
们的最终输出看起来就像相关的点乘，但减去了 1。

136
00:09:16,120 --> 00:09:20,464
你可能会问，为什么我希望你假定模型已经学会了这一点，

137
00:09:20,464 --> 00:09:23,972
稍后你就会明白，如果我们在这里设置一个值，

138
00:09:23,972 --> 00:09:27,648
当且仅当一个向量编码了迈克尔-乔丹的全名时，

139
00:09:27,648 --> 00:09:32,160
这个值就是正值，否则就是零或负值，那就非常干净利落了。

140
00:09:33,040 --> 00:09:37,368
这个矩阵的总行数，也就是我们一直关注的 

141
00:09:37,368 --> 00:09:42,780
GPT-3 的问题数量，略低于 50,000 行。

142
00:09:43,100 --> 00:09:46,640
事实上，它正好是这个嵌入空间维数的四倍。

143
00:09:46,920 --> 00:09:47,900
这是一种设计选择。

144
00:09:47,940 --> 00:09:49,851
你可以做得更多，也可以做得更少，

145
00:09:49,851 --> 00:09:52,240
但拥有一个干净的多路径往往对硬件很友好。

146
00:09:52,740 --> 00:09:56,926
由于这个充满权重的矩阵将我们映射到了一个更高的维度空间，

147
00:09:56,926 --> 00:09:59,020
所以我把它简称为 W up。

148
00:09:59,020 --> 00:10:02,559
我会继续将我们正在处理的矢量标记为 E，

149
00:10:02,559 --> 00:10:07,160
并将这个偏置矢量标记为 B，然后将它们全部放回图中。

150
00:10:09,180 --> 00:10:12,785
在这一点上，一个问题是这种操作是纯线性的，

151
00:10:12,785 --> 00:10:15,360
但语言是一个非常非线性的过程。

152
00:10:15,880 --> 00:10:19,422
如果我们测量的迈克尔加乔丹的入选率很高，

153
00:10:19,422 --> 00:10:23,495
那么迈克尔加菲尔普斯和亚历克西斯加乔丹也必然会

154
00:10:23,495 --> 00:10:28,100
在一定程度上引发入选率，尽管这两者在概念上并不相关。

155
00:10:28,540 --> 00:10:32,000
您真正需要的是全名的简单 "是 "或 "否"。

156
00:10:32,900 --> 00:10:35,370
因此，下一步就是通过一个非常简单的

157
00:10:35,370 --> 00:10:37,840
非线性函数来传递这个大的中间向量。

158
00:10:38,360 --> 00:10:45,300
常见的选择是将所有负值映射为零，而所有正值保持不变。

159
00:10:46,440 --> 00:10:50,108
为了延续深度学习过于花哨的名称传统，

160
00:10:50,108 --> 00:10:56,020
这个非常简单的函数通常被称为整流线性单元，简称 ReLU。

161
00:10:56,020 --> 00:10:57,880
图表如下

162
00:10:58,300 --> 00:11:06,708
因此，以我们想象中的例子为例，中间向量的第一个条目是 

163
00:11:06,708 --> 00:11:15,740
1（如果且仅当全名是迈克尔-乔丹），否则就是 0 或负值。

164
00:11:16,100 --> 00:11:19,780
因此，迈克尔-乔丹全名的输出值为 1，否则为 0。

165
00:11:20,560 --> 00:11:24,120
换句话说，它非常直接地模仿了 AND 门的行为。

166
00:11:25,660 --> 00:11:28,695
通常情况下，模型会使用一种略有改动的功能，

167
00:11:28,695 --> 00:11:32,020
称为 JLU，其基本形状相同，只是更平滑一些。

168
00:11:32,500 --> 00:11:34,889
但就我们的目的而言，如果我们只考虑 ReLU，

169
00:11:34,889 --> 00:11:35,720
就会更简洁一些。

170
00:11:36,740 --> 00:11:40,243
此外，当你听到人们提到变压器的神经元时，

171
00:11:40,243 --> 00:11:42,520
他们说的就是这里的这些值。

172
00:11:42,900 --> 00:11:48,750
在本系列文章的前半部分，我们经常会看到这样一幅神经网络图，

173
00:11:48,750 --> 00:11:52,180
图中有一层点和连接上一层的几条线，

174
00:11:52,180 --> 00:11:56,619
这通常是为了表达线性步骤的组合，即矩阵乘法，

175
00:11:56,619 --> 00:12:01,260
然后是一些简单的项向非线性函数，如 ReLU。

176
00:12:02,500 --> 00:12:05,710
你可以说，只要这个值为正，这个神经元就处于激

177
00:12:05,710 --> 00:12:08,920
活状态；如果这个值为零，它就处于非激活状态。

178
00:12:10,120 --> 00:12:12,380
下一步看起来与第一步非常相似。

179
00:12:12,560 --> 00:12:16,580
你乘以一个非常大的矩阵，然后加上一定的偏差项。

180
00:12:16,980 --> 00:12:22,454
在这种情况下，输出中的维数又回到了嵌入空间的大小，

181
00:12:22,454 --> 00:12:25,520
所以我把它叫做向下投影矩阵。

182
00:12:26,220 --> 00:12:31,360
这次，与其逐行思考，不如逐列思考。

183
00:12:31,860 --> 00:12:36,890
你看，让矩阵乘法在脑中形成印象的另一种方法是，

184
00:12:36,890 --> 00:12:42,140
想象将矩阵的每一列乘以它所处理的向量中的相应项，

185
00:12:42,140 --> 00:12:45,640
然后将所有这些重新缩放的列相加。

186
00:12:46,840 --> 00:12:52,025
用这种方法来思考会更好，因为这里的列与嵌入空间的维度相同，

187
00:12:52,025 --> 00:12:55,780
所以我们可以把它们看作是嵌入空间中的方向。

188
00:12:56,140 --> 00:12:59,610
例如，我们可以设想，模型已经学会将第

189
00:12:59,610 --> 00:13:03,080
一根柱子插入我们假设存在的篮球方向。

190
00:13:04,180 --> 00:13:08,365
这意味着，当第一个位置上的相关神经元处于活动状态时，

191
00:13:08,365 --> 00:13:10,780
我们将在最终结果中添加这一列。

192
00:13:11,140 --> 00:13:14,185
但是，如果该神经元不活动，如果该数字为零，

193
00:13:14,185 --> 00:13:15,780
那么就不会有任何影响。

194
00:13:16,500 --> 00:13:18,060
而且不一定非得是篮球。

195
00:13:18,220 --> 00:13:21,710
该模型还可以在这一栏和其他许多功

196
00:13:21,710 --> 00:13:25,200
能中加入迈克尔-乔丹全名的元素。

197
00:13:26,980 --> 00:13:31,282
同时，这个矩阵中的所有其他列都在告诉你，

198
00:13:31,282 --> 00:13:36,660
如果相应的神经元处于激活状态，最终结果会增加什么。

199
00:13:37,360 --> 00:13:41,965
在这种情况下，如果存在偏差，那么无论神经元的值是多少，

200
00:13:41,965 --> 00:13:43,500
每次都会产生偏差。

201
00:13:44,060 --> 00:13:45,280
你可能会问，这是在干什么？

202
00:13:45,540 --> 00:13:49,320
就像这里所有充满参数的对象一样，很难说清楚。

203
00:13:49,320 --> 00:13:54,380
也许网络需要做一些记账工作，但你可以暂时忽略不计。

204
00:13:54,860 --> 00:13:58,043
为了使我们的符号更加简洁，我把这个大矩阵 

205
00:13:58,043 --> 00:14:02,289
W 称为 "向下"，同样把偏置向量 B 称为 "向下"，

206
00:14:02,289 --> 00:14:04,260
然后把它放回我们的图表中。

207
00:14:04,740 --> 00:14:08,990
就像我之前预览的那样，你要做的就是将最终结果

208
00:14:08,990 --> 00:14:13,240
与流入该位置块的矢量相加，从而得到最终结果。

209
00:14:13,820 --> 00:14:18,718
例如，如果输入的向量同时编码了迈克尔和乔丹这两个名字，

210
00:14:18,718 --> 00:14:22,527
那么由于这一连串的操作会触发 AND 门，

211
00:14:22,527 --> 00:14:25,430
因此会在篮球方向上进行加法运算，

212
00:14:25,430 --> 00:14:29,240
这样跳出来的向量就会把这两个名字一起编码。

213
00:14:29,820 --> 00:14:34,200
请记住，这是一个并行发生在每个矢量上的过程。

214
00:14:34,800 --> 00:14:37,603
特别是，从 GPT-3 数字来看，

215
00:14:37,603 --> 00:14:41,726
这意味着这个区块中不仅有 50,000 个神经元，

216
00:14:41,726 --> 00:14:44,860
还有 50,000 倍于输入的标记数。

217
00:14:48,180 --> 00:14:51,013
这就是整个操作过程，两个矩阵乘积，

218
00:14:51,013 --> 00:14:55,180
每个乘积都添加了偏置，中间还有一个简单的削波功能。

219
00:14:56,080 --> 00:14:58,833
看过本系列早期视频的朋友都知道，

220
00:14:58,833 --> 00:15:02,620
这种结构是我们学习过的最基本的神经网络类型。

221
00:15:03,080 --> 00:15:06,100
在这个例子中，它接受了识别手写数字的训练。

222
00:15:06,580 --> 00:15:10,785
在这里，在大型语言模型转换器的背景下，

223
00:15:10,785 --> 00:15:16,318
这是一个更大架构中的一个部分，任何试图解释它到底在

224
00:15:16,318 --> 00:15:21,852
做什么的尝试，都与将信息编码成高维嵌入空间向量的想

225
00:15:21,852 --> 00:15:23,180
法紧密相连。

226
00:15:24,260 --> 00:15:28,598
这是核心课程，但我确实想退后一步，反思两件不同的事情，

227
00:15:28,598 --> 00:15:33,098
第一件是一种簿记，第二件是关于更高维度的一个非常发人深省

228
00:15:33,098 --> 00:15:36,473
的事实，实际上，在我深入研究变形金刚之前，

229
00:15:36,473 --> 00:15:38,080
我并不知道这个事实。

230
00:15:41,080 --> 00:15:46,216
在上两章中，我们开始计算 GPT-3 中的参数总数，

231
00:15:46,216 --> 00:15:50,760
并了解它们的具体位置，现在让我们快速结束游戏。

232
00:15:51,400 --> 00:15:55,744
我已经提到过这个向上投影矩阵有不到 50,000 行，

233
00:15:55,744 --> 00:15:58,640
而且每一行都与嵌入空间的大小相匹配，

234
00:15:58,640 --> 00:16:02,180
GPT-3 的嵌入空间是 12,288 行。

235
00:16:03,240 --> 00:16:08,975
将这些参数相乘，我们可以得到该矩阵的 6.04 亿个参数，

236
00:16:08,975 --> 00:16:13,920
而向下投影的参数数量与此相同，只是形状发生了变化。

237
00:16:14,500 --> 00:16:17,400
因此，它们总共提供了约 12 亿个参数。

238
00:16:18,280 --> 00:16:22,721
偏差向量还涉及另外几个参数，但在总参数中所占比例微不足道，

239
00:16:22,721 --> 00:16:24,100
所以我就不展示了。

240
00:16:24,660 --> 00:16:29,755
在 GPT-3 中，这一连串的嵌入向量流经的不是一个，

241
00:16:29,755 --> 00:16:34,096
而是 96 个不同的 MLP，因此用于所有这些

242
00:16:34,096 --> 00:16:38,060
区块的参数总数加起来约为 1160 亿个。

243
00:16:38,820 --> 00:16:44,620
这约占网络总参数的三分之二，再加上我们之前所做的所有工作，

244
00:16:44,620 --> 00:16:49,220
如注意力区块、嵌入和解嵌入，就能得到所宣传的 

245
00:16:49,220 --> 00:16:51,620
1 750 亿个总参数。

246
00:16:53,060 --> 00:16:57,372
值得一提的还有与这些标准化步骤相关的另一组参数，

247
00:16:57,372 --> 00:17:00,965
本解释略过了这些参数，但与偏差向量一样，

248
00:17:00,965 --> 00:17:03,840
它们在总参数中所占的比例非常小。

249
00:17:05,900 --> 00:17:09,054
至于第二点思考，你可能想知道，我们花了这

250
00:17:09,054 --> 00:17:11,578
么多时间讨论的这个中心玩具示例，

251
00:17:11,578 --> 00:17:15,680
是否反映了事实在真正的大型语言模型中的实际存储方式。

252
00:17:16,319 --> 00:17:20,962
诚然，第一个矩阵的行可以被视为嵌入空间中的方向，

253
00:17:20,962 --> 00:17:26,572
这意味着每个神经元的激活可以告诉你给定向量与某个特定方向的

254
00:17:26,572 --> 00:17:27,540
吻合程度。

255
00:17:27,760 --> 00:17:30,684
同样，如果该神经元处于激活状态，

256
00:17:30,684 --> 00:17:34,340
第二个矩阵的列也会告诉你结果会增加什么。

257
00:17:34,640 --> 00:17:36,800
这两个都只是数学事实。

258
00:17:37,740 --> 00:17:41,715
不过，有证据表明，单个神经元很少能像迈克尔-乔丹那

259
00:17:41,715 --> 00:17:45,691
样代表一个单一而清晰的特征，而这种情况实际上可能有

260
00:17:45,691 --> 00:17:49,667
一个很好的原因，这与最近在可解释性研究人员中流传的

261
00:17:49,667 --> 00:17:54,120
一种被称为叠加（superposition）的观点有关。

262
00:17:54,640 --> 00:17:58,801
这一假设可能有助于解释为什么模型特别难以解释，

263
00:17:58,801 --> 00:18:02,420
也有助于解释为什么模型的扩展性出奇地好。

264
00:18:03,500 --> 00:18:07,434
其基本思想是，如果你有一个 n 维空间，

265
00:18:07,434 --> 00:18:12,549
而你想用空间中相互垂直的方向来表示一系列不同的特征，

266
00:18:12,549 --> 00:18:17,074
你知道，这样，如果你在一个方向上添加一个分量，

267
00:18:17,074 --> 00:18:22,779
它不会影响任何其他方向，那么你能容纳的向量的最大数量只有 

268
00:18:22,779 --> 00:18:23,960
n，即维数。

269
00:18:24,600 --> 00:18:27,620
实际上，对于数学家来说，这就是维度的定义。

270
00:18:28,220 --> 00:18:33,580
但有趣的地方在于，如果你稍微放宽限制，容忍一些噪音。

271
00:18:34,180 --> 00:18:39,370
假设你允许用矢量来表示这些特征，但这些矢量并不完全垂直，

272
00:18:39,370 --> 00:18:43,820
只是接近垂直，可能相距 89 到 91 度之间。

273
00:18:44,820 --> 00:18:48,020
如果我们在二维或三维空间中，这并没有什么区别。

274
00:18:48,260 --> 00:18:52,028
这几乎没有任何额外的回旋余地来容纳更多的矢量，

275
00:18:52,028 --> 00:18:56,780
这就使得更高维的答案发生了巨大的变化，这就更加违反直觉了。

276
00:18:57,660 --> 00:19:00,396
我可以用一些零碎的 Python 

277
00:19:00,396 --> 00:19:02,971
来给你一个非常快速和肮脏的说明，

278
00:19:02,971 --> 00:19:05,869
它将创建一个 100 维向量的列表，

279
00:19:05,869 --> 00:19:10,375
每个向量都是随机初始化的，这个列表将包含 10,000 

280
00:19:10,375 --> 00:19:14,400
个不同的向量，所以向量的数量是维数的 100 倍。

281
00:19:15,320 --> 00:19:19,900
这幅图显示了这些向量对之间的角度分布。

282
00:19:20,680 --> 00:19:24,381
因为它们是随机开始的，所以角度可能从 0 

283
00:19:24,381 --> 00:19:27,553
度到 180 度不等，但你会注意到，

284
00:19:27,553 --> 00:19:31,960
即使只是随机向量，也有很大的偏向于接近 90 度。

285
00:19:32,500 --> 00:19:36,709
然后，我要做的就是运行一个特定的优化过程，

286
00:19:36,709 --> 00:19:41,520
对所有这些矢量进行迭代推移，使它们彼此更加垂直。

287
00:19:42,060 --> 00:19:46,660
重复多次后，角度的分布情况如下。

288
00:19:47,120 --> 00:19:52,792
我们必须在这里放大它，因为所有可能的矢量对之间的角度都在 

289
00:19:52,792 --> 00:19:56,900
89 度到 91 度之间的这个狭窄范围内。

290
00:19:58,020 --> 00:20:02,193
一般来说，约翰逊-林登斯特劳斯(Johnson-Lind

291
00:20:02,193 --> 00:20:05,771
enstrauss) Lemma 的一个结果是，

292
00:20:05,771 --> 00:20:09,945
在一个空间中，像这样几乎垂直的向量数量会随着维数的增加而

293
00:20:09,945 --> 00:20:10,840
呈指数增长。

294
00:20:11,960 --> 00:20:14,396
这对于大型语言模型来说意义重大，

295
00:20:14,396 --> 00:20:17,595
因为将独立的想法与几乎垂直的方向联系起来，

296
00:20:17,595 --> 00:20:19,880
可能会使大型语言模型受益匪浅。

297
00:20:20,000 --> 00:20:26,440
这意味着，在它所分配的空间里，可以存储的想法要比尺寸多得多。

298
00:20:27,320 --> 00:20:29,530
这或许可以部分解释为什么模型的性

299
00:20:29,530 --> 00:20:31,740
能似乎可以随着尺寸的增大而提高。

300
00:20:32,540 --> 00:20:37,321
一个空间有 10 倍的维度，可以存储远远超过 

301
00:20:37,321 --> 00:20:39,400
10 倍的独立想法。

302
00:20:40,420 --> 00:20:44,897
这不仅与流经模型的向量所在的嵌入空间有关，

303
00:20:44,897 --> 00:20:50,440
也与我们刚刚研究过的多层感知器中间的神经元向量有关。

304
00:20:50,960 --> 00:20:54,448
也就是说，在 GPT-3 的尺寸下，

305
00:20:54,448 --> 00:20:58,324
它可能不只是探测 50,000 个特征，

306
00:20:58,324 --> 00:21:03,945
但如果它利用空间中几乎垂直的方向来利用这一巨大的新增容量，

307
00:21:03,945 --> 00:21:07,240
它就可以探测被处理向量的更多特征。

308
00:21:07,780 --> 00:21:12,352
但如果它这样做了，那就意味着单个神经元点亮时，

309
00:21:12,352 --> 00:21:14,340
单个特征是不可见的。

310
00:21:14,660 --> 00:21:19,380
它必须看起来像神经元的某种特定组合，一种叠加。

311
00:21:20,400 --> 00:21:22,865
对于任何想了解更多信息的人来说，

312
00:21:22,865 --> 00:21:26,100
这里的一个关键相关搜索词是稀疏自动编码器，

313
00:21:26,100 --> 00:21:30,106
它是一些可解释性研究人员用来尝试提取真实特征的工具，

314
00:21:30,106 --> 00:21:32,880
即使这些特征叠加在所有这些神经元上。

315
00:21:33,540 --> 00:21:36,800
我将链接到几篇非常棒的人类学文章，都是关于这个问题的。

316
00:21:37,880 --> 00:21:41,102
到此为止，我们还没有触及变压器的每一个细节，

317
00:21:41,102 --> 00:21:43,300
但我们已经触及了最重要的部分。

318
00:21:43,520 --> 00:21:47,640
我想在下一章介绍的主要内容是培训过程。

319
00:21:48,460 --> 00:21:56,900
一方面，关于训练的原理，简而言之就是反向传播。

320
00:21:57,220 --> 00:22:02,410
但还有更多的问题需要讨论，比如语言模型所使用的特定成本函数

321
00:22:02,410 --> 00:22:07,780
、利用强化学习和人类反馈进行微调的想法，以及缩放规律的概念。

322
00:22:08,960 --> 00:22:12,640
给你们中的积极追随者提个醒，在我制作下一章之前，

323
00:22:12,640 --> 00:22:15,860
还有很多与机器学习无关的视频等着我去挖掘，

324
00:22:15,860 --> 00:22:20,000
所以可能还需要一段时间，但我保证它会在适当的时候出现。

325
00:22:35,640 --> 00:22:37,920
谢谢。

