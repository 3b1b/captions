1
00:00:00,000 --> 00:00:04,515
Si alimentas a un gran modelo lingüístico con la frase Michael Jordan juega al deporte 

2
00:00:04,515 --> 00:00:07,577
de fogueo y le haces predecir lo que viene a continuación, 

3
00:00:07,577 --> 00:00:11,417
y predice correctamente el baloncesto, esto sugeriría que en algún lugar, 

4
00:00:11,417 --> 00:00:14,427
dentro de sus cientos de miles de millones de parámetros, 

5
00:00:14,427 --> 00:00:18,320
ha horneado conocimientos sobre una persona concreta y su deporte concreto.

6
00:00:18,940 --> 00:00:22,148
Y creo que, en general, cualquiera que haya jugado con uno de estos modelos 

7
00:00:22,148 --> 00:00:25,400
tiene la clara sensación de que ha memorizado toneladas y toneladas de datos.

8
00:00:25,700 --> 00:00:29,160
Así que una pregunta razonable que podrías hacerte es, ¿cómo funciona eso exactamente?

9
00:00:29,160 --> 00:00:31,040
¿Y dónde viven esos hechos?

10
00:00:35,720 --> 00:00:40,099
El pasado diciembre, unos investigadores de Google DeepMind publicaron un trabajo sobre 

11
00:00:40,099 --> 00:00:44,480
esta cuestión, y utilizaban este ejemplo concreto de emparejar atletas con sus deportes.

12
00:00:44,900 --> 00:00:49,248
Y aunque sigue sin resolverse una comprensión mecanicista completa de cómo se almacenan 

13
00:00:49,248 --> 00:00:52,509
los hechos, obtuvieron algunos resultados parciales interesantes, 

14
00:00:52,509 --> 00:00:56,858
incluida la conclusión muy general de alto nivel de que los hechos parecen vivir dentro 

15
00:00:56,858 --> 00:01:01,108
de una parte específica de estas redes, conocidas extravagantemente como perceptrones 

16
00:01:01,108 --> 00:01:02,640
multicapa, o MLP para abreviar.

17
00:01:03,120 --> 00:01:06,190
En los dos últimos capítulos, tú y yo hemos profundizado en los detalles 

18
00:01:06,190 --> 00:01:09,219
que hay detrás de los transformadores, la arquitectura subyacente a los 

19
00:01:09,219 --> 00:01:12,500
grandes modelos lingüísticos, y también subyacente a muchas otras IA modernas.

20
00:01:13,060 --> 00:01:16,200
En el capítulo más reciente, nos centramos en una pieza llamada Atención.

21
00:01:16,840 --> 00:01:20,963
Y el siguiente paso para ti y para mí es profundizar en los detalles de lo que ocurre 

22
00:01:20,963 --> 00:01:25,040
dentro de estos perceptrones multicapa, que constituyen la otra gran parte de la red.

23
00:01:25,680 --> 00:01:28,205
En realidad, el cálculo aquí es relativamente sencillo, 

24
00:01:28,205 --> 00:01:30,100
sobre todo si lo comparas con la atención.

25
00:01:30,560 --> 00:01:33,025
Se reduce esencialmente a un par de multiplicaciones 

26
00:01:33,025 --> 00:01:34,980
de matrices con un simple algo intermedio.

27
00:01:35,720 --> 00:01:40,460
Sin embargo, interpretar lo que hacen estos cálculos es sumamente difícil.

28
00:01:41,560 --> 00:01:45,474
Nuestro principal objetivo aquí es recorrer los cálculos y hacerlos memorizables, 

29
00:01:45,474 --> 00:01:49,341
pero me gustaría hacerlo en el contexto de mostrar un ejemplo específico de cómo 

30
00:01:49,341 --> 00:01:53,160
uno de estos bloques podría, al menos en principio, almacenar un hecho concreto.

31
00:01:53,580 --> 00:01:57,080
Concretamente, será almacenar el hecho de que Michael Jordan juega al baloncesto.

32
00:01:58,080 --> 00:02:00,736
Debo mencionar que el diseño aquí está inspirado en una conversación 

33
00:02:00,736 --> 00:02:03,200
que tuve con uno de esos investigadores de DeepMind, Neil Nanda.

34
00:02:04,060 --> 00:02:07,363
En su mayor parte, daré por sentado que has visto los dos últimos capítulos, 

35
00:02:07,363 --> 00:02:10,238
o bien que tienes una noción básica de lo que es un transformador, 

36
00:02:10,238 --> 00:02:13,927
pero refrescar la memoria nunca viene mal, así que aquí tienes un rápido recordatorio 

37
00:02:13,927 --> 00:02:14,700
del flujo general.

38
00:02:15,340 --> 00:02:18,378
Tú y yo hemos estado estudiando un modelo entrenado para tomar 

39
00:02:18,378 --> 00:02:21,320
un fragmento de texto y predecir lo que viene a continuación.

40
00:02:21,720 --> 00:02:26,023
Ese texto de entrada se divide primero en un montón de tokens, es decir, 

41
00:02:26,023 --> 00:02:29,797
pequeños trozos que suelen ser palabras o trocitos de palabras, 

42
00:02:29,797 --> 00:02:33,570
y cada token se asocia a un vector de alta dimensión, es decir, 

43
00:02:33,570 --> 00:02:35,280
a una larga lista de números.

44
00:02:35,840 --> 00:02:39,799
A continuación, esta secuencia de vectores pasa repetidamente por dos 

45
00:02:39,799 --> 00:02:43,758
tipos de operaciones: la atención, que permite a los vectores pasarse 

46
00:02:43,758 --> 00:02:47,039
información entre sí, y luego los perceptrones multicapa, 

47
00:02:47,039 --> 00:02:50,885
en los que vamos a profundizar hoy, y también hay un cierto paso de 

48
00:02:50,885 --> 00:02:52,300
normalización intermedio.

49
00:02:53,300 --> 00:02:56,574
Después de que la secuencia de vectores haya pasado por muchas, 

50
00:02:56,574 --> 00:02:59,747
muchas iteraciones diferentes de estos dos bloques, al final, 

51
00:02:59,747 --> 00:03:03,380
la esperanza es que cada vector haya absorbido suficiente información, 

52
00:03:03,380 --> 00:03:06,604
tanto del contexto, de todas las demás palabras de la entrada, 

53
00:03:06,604 --> 00:03:10,851
como del conocimiento general que se incorporó a los pesos del modelo a través del 

54
00:03:10,851 --> 00:03:15,354
entrenamiento, para que pueda utilizarse para hacer una predicción de qué ficha viene a 

55
00:03:15,354 --> 00:03:16,020
continuación.

56
00:03:16,860 --> 00:03:20,672
Una de las ideas clave que quiero que tengas en tu mente es que todos estos 

57
00:03:20,672 --> 00:03:25,187
vectores viven en un espacio de muy, muy alta dimensión, y cuando piensas en ese espacio, 

58
00:03:25,187 --> 00:03:28,800
diferentes direcciones pueden codificar diferentes tipos de significado.

59
00:03:30,120 --> 00:03:34,230
Así que un ejemplo muy clásico al que me gusta referirme es cómo si observas 

60
00:03:34,230 --> 00:03:37,486
la incrustación de mujer y restas la incrustación de hombre, 

61
00:03:37,486 --> 00:03:41,916
y das ese pequeño paso y lo añades a otro sustantivo masculino, algo así como tío, 

62
00:03:41,916 --> 00:03:46,240
aterrizas en algún lugar muy, muy cercano al sustantivo femenino correspondiente.

63
00:03:46,440 --> 00:03:50,880
En este sentido, esta dirección concreta codifica información de género.

64
00:03:51,640 --> 00:03:55,592
La idea es que muchas otras direcciones distintas en este espacio superdimensional 

65
00:03:55,592 --> 00:03:59,640
podrían corresponder a otras características que el modelo podría querer representar.

66
00:04:01,400 --> 00:04:03,836
Sin embargo, en un transformador, estos vectores no 

67
00:04:03,836 --> 00:04:06,180
sólo codifican el significado de una sola palabra.

68
00:04:06,680 --> 00:04:10,876
A medida que fluyen por la red, se impregnan de un significado mucho más rico, 

69
00:04:10,876 --> 00:04:15,180
basado en todo el contexto que las rodea y también en el conocimiento del modelo.

70
00:04:15,880 --> 00:04:18,564
En última instancia, cada una tiene que codificar algo mucho, 

71
00:04:18,564 --> 00:04:20,815
mucho más allá del significado de una sola palabra, 

72
00:04:20,815 --> 00:04:23,760
ya que tiene que ser suficiente para predecir lo que vendrá después.

73
00:04:24,560 --> 00:04:28,568
Ya hemos visto cómo los bloques de atención te permiten incorporar el contexto, 

74
00:04:28,568 --> 00:04:33,078
pero la mayoría de los parámetros del modelo viven en realidad dentro de los bloques MLP, 

75
00:04:33,078 --> 00:04:36,235
y una idea de lo que podrían estar haciendo es que ofrecen una 

76
00:04:36,235 --> 00:04:38,140
capacidad extra para almacenar hechos.

77
00:04:38,720 --> 00:04:42,376
Como he dicho, la lección aquí se va a centrar en el ejemplo concreto de juguete de 

78
00:04:42,376 --> 00:04:46,120
cómo podría almacenar exactamente el hecho de que Michael Jordan juegue al baloncesto.

79
00:04:47,120 --> 00:04:49,417
Ahora bien, este ejemplo de juguete va a requerir que tú y yo 

80
00:04:49,417 --> 00:04:51,900
hagamos un par de suposiciones sobre ese espacio de alta dimensión.

81
00:04:52,360 --> 00:04:56,930
En primer lugar, supondremos que una de las direcciones representa la idea del 

82
00:04:56,930 --> 00:05:01,617
nombre Michael, y luego otra dirección casi perpendicular representa la idea del 

83
00:05:01,617 --> 00:05:06,420
apellido Jordan, y luego una tercera dirección representará la idea del baloncesto.

84
00:05:07,400 --> 00:05:11,031
En concreto, lo que quiero decir con esto es que si miras en la red y 

85
00:05:11,031 --> 00:05:13,780
extraes uno de los vectores que se están procesando, 

86
00:05:13,780 --> 00:05:17,360
si su producto punto con la dirección de este nombre Michael es uno, 

87
00:05:17,360 --> 00:05:21,146
eso es lo que significaría que el vector está codificando la idea de una 

88
00:05:21,146 --> 00:05:22,340
persona con ese nombre.

89
00:05:23,800 --> 00:05:26,006
De lo contrario, ese producto punto sería cero o negativo, 

90
00:05:26,006 --> 00:05:28,700
lo que significa que el vector no se alinea realmente con esa dirección.

91
00:05:29,420 --> 00:05:32,504
Y para simplificar, ignoremos por completo la muy razonable cuestión 

92
00:05:32,504 --> 00:05:35,320
de qué significaría que ese producto punto fuera mayor que uno.

93
00:05:36,200 --> 00:05:40,206
Del mismo modo, su producto punto con estas otras direcciones 

94
00:05:40,206 --> 00:05:43,760
te diría si representa el apellido Jordan o baloncesto.

95
00:05:44,740 --> 00:05:48,353
Así que digamos que un vector pretende representar el nombre completo, 

96
00:05:48,353 --> 00:05:52,680
Michael Jordan, entonces su producto punto con ambas direcciones tendría que ser uno.

97
00:05:53,480 --> 00:05:56,749
Puesto que el texto Michael Jordan abarca dos tokens diferentes, 

98
00:05:56,749 --> 00:06:01,175
esto también significaría que tenemos que suponer que un bloque de atención anterior ha 

99
00:06:01,175 --> 00:06:05,451
pasado con éxito información al segundo de estos dos vectores para asegurarse de que 

100
00:06:05,451 --> 00:06:06,960
puede codificar ambos nombres.

101
00:06:07,940 --> 00:06:11,480
Con todas estas premisas, vamos a sumergirnos en el meollo de la lección.

102
00:06:11,880 --> 00:06:14,980
¿Qué ocurre dentro de un perceptrón multicapa?

103
00:06:17,100 --> 00:06:20,591
Puedes pensar en esta secuencia de vectores fluyendo hacia el bloque, 

104
00:06:20,591 --> 00:06:24,732
y recuerda que cada vector estaba asociado originalmente a una de las palabras del 

105
00:06:24,732 --> 00:06:25,580
texto de entrada.

106
00:06:26,080 --> 00:06:29,523
Lo que va a ocurrir es que cada vector individual de esa secuencia 

107
00:06:29,523 --> 00:06:33,378
pasa por una breve serie de operaciones, que desmenuzaremos en un momento, 

108
00:06:33,378 --> 00:06:36,360
y al final obtendremos otro vector con la misma dimensión.

109
00:06:36,880 --> 00:06:43,200
Ese otro vector se sumará al original que entró, y esa suma será el resultado que saldrá.

110
00:06:43,720 --> 00:06:48,211
Esta secuencia de operaciones es algo que se aplica a cada vector de la secuencia, 

111
00:06:48,211 --> 00:06:51,620
asociado a cada token de la entrada, y todo ocurre en paralelo.

112
00:06:52,100 --> 00:06:54,804
En concreto, los vectores no se hablan entre sí en este paso, 

113
00:06:54,804 --> 00:06:56,200
sino que hacen cada uno lo suyo.

114
00:06:56,720 --> 00:06:59,193
Y para ti y para mí, eso en realidad lo simplifica mucho, 

115
00:06:59,193 --> 00:07:02,178
porque significa que si entendemos lo que le ocurre a uno solo de los 

116
00:07:02,178 --> 00:07:05,164
vectores a través de este bloque, entendemos efectivamente lo que les 

117
00:07:05,164 --> 00:07:06,060
ocurre a todos ellos.

118
00:07:07,100 --> 00:07:11,277
Cuando digo que este bloque va a codificar el hecho de que Michael Jordan juega 

119
00:07:11,277 --> 00:07:15,664
al baloncesto, lo que quiero decir es que si entra un vector que codifica el nombre 

120
00:07:15,664 --> 00:07:20,051
Michael y el apellido Jordan, esta secuencia de cálculos producirá algo que incluya 

121
00:07:20,051 --> 00:07:24,020
esa dirección baloncesto, que es lo que se sumará al vector en esa posición.

122
00:07:25,600 --> 00:07:29,700
El primer paso de este proceso parece multiplicar ese vector por una matriz muy grande.

123
00:07:30,040 --> 00:07:31,980
No hay sorpresas, esto es aprendizaje profundo.

124
00:07:32,680 --> 00:07:34,955
Y esta matriz, como todas las demás que hemos visto, 

125
00:07:34,955 --> 00:07:37,788
está llena de parámetros del modelo que se aprenden de los datos, 

126
00:07:37,788 --> 00:07:41,479
que podrías considerar como un montón de mandos y diales que se ajustan y afinan para 

127
00:07:41,479 --> 00:07:43,540
determinar cuál es el comportamiento del modelo.

128
00:07:44,500 --> 00:07:48,518
Ahora bien, una forma agradable de pensar en la multiplicación de matrices es imaginar 

129
00:07:48,518 --> 00:07:50,782
que cada fila de esa matriz es su propio vector, 

130
00:07:50,782 --> 00:07:54,570
y tomar un montón de productos escalares entre esas filas y el vector que se está 

131
00:07:54,570 --> 00:07:56,880
procesando, que etiquetaré como E de incrustación.

132
00:07:57,280 --> 00:08:00,574
Por ejemplo, supón que esa primera fila resulta ser igual 

133
00:08:00,574 --> 00:08:04,040
a esta dirección del nombre Michael que suponemos que existe.

134
00:08:04,320 --> 00:08:09,560
Eso significaría que el primer componente de esta salida, este producto punto de aquí, 

135
00:08:09,560 --> 00:08:14,800
sería uno si ese vector codifica el nombre Miguel, y cero o negativo en caso contrario.

136
00:08:15,880 --> 00:08:19,456
Aún más divertido, tómate un momento para pensar en lo que significaría si 

137
00:08:19,456 --> 00:08:23,080
esa primera fila fuera esta dirección de nombre Michael más apellido Jordan.

138
00:08:23,700 --> 00:08:27,420
Y para simplificar, déjame escribirlo como M más J.

139
00:08:28,080 --> 00:08:31,022
Luego, tomando un producto punto con esta incrustación E, 

140
00:08:31,022 --> 00:08:34,980
las cosas se distribuyen muy bien, de modo que parece M punto E más J punto E.

141
00:08:34,980 --> 00:08:39,869
Y fíjate en que eso significa que el valor final sería dos si el vector codifica el 

142
00:08:39,869 --> 00:08:44,700
nombre completo Michael Jordan, y en caso contrario sería uno o algo menor que uno.

143
00:08:45,340 --> 00:08:47,260
Y eso es sólo una fila de esta matriz.

144
00:08:47,600 --> 00:08:52,090
Podrías pensar que todas las demás filas hacen en paralelo otro tipo de preguntas, 

145
00:08:52,090 --> 00:08:56,040
sondeando otro tipo de características del vector que se está procesando.

146
00:08:56,700 --> 00:08:59,450
Muy a menudo, este paso también implica añadir otro vector a la salida, 

147
00:08:59,450 --> 00:09:02,240
que está lleno de parámetros del modelo aprendidos a partir de los datos.

148
00:09:02,240 --> 00:09:04,560
Este otro vector se conoce como sesgo.

149
00:09:05,180 --> 00:09:08,688
Para nuestro ejemplo, quiero que imagines que el valor de este sesgo en 

150
00:09:08,688 --> 00:09:12,002
ese primer componente es uno negativo, lo que significa que nuestro 

151
00:09:12,002 --> 00:09:15,560
resultado final se parece a ese producto punto relevante, pero menos uno.

152
00:09:16,120 --> 00:09:20,156
Podrías preguntarte muy razonablemente por qué querría que supusieras que el 

153
00:09:20,156 --> 00:09:23,930
modelo ha aprendido esto, y en un momento verás por qué es muy limpio y 

154
00:09:23,930 --> 00:09:27,809
agradable si tenemos aquí un valor que es positivo si y sólo si un vector 

155
00:09:27,809 --> 00:09:32,160
codifica el nombre completo Michael Jordan, y en caso contrario es cero o negativo.

156
00:09:33,040 --> 00:09:36,269
El número total de filas de esta matriz, que es algo así como 

157
00:09:36,269 --> 00:09:39,446
el número de preguntas que se hacen, en el caso de la GPT-3, 

158
00:09:39,446 --> 00:09:42,780
cuyas cifras hemos estado siguiendo, es de algo menos de 50.000.

159
00:09:43,100 --> 00:09:44,888
De hecho, es exactamente cuatro veces el número 

160
00:09:44,888 --> 00:09:46,640
de dimensiones de este espacio de incrustación.

161
00:09:46,920 --> 00:09:47,900
Es una elección de diseño.

162
00:09:47,940 --> 00:09:50,032
Podrías hacerlo más, podrías hacerlo menos, pero tener 

163
00:09:50,032 --> 00:09:52,240
un múltiplo limpio tiende a ser amigable para el hardware.

164
00:09:52,740 --> 00:09:57,036
Como esta matriz llena de pesos nos mapea en un espacio dimensional superior, 

165
00:09:57,036 --> 00:09:59,020
voy a darle la abreviatura W arriba.

166
00:09:59,020 --> 00:10:02,021
Voy a seguir etiquetando el vector que estamos procesando como E, 

167
00:10:02,021 --> 00:10:05,977
y vamos a etiquetar este vector de polarización como B hacia arriba y volver a ponerlo 

168
00:10:05,977 --> 00:10:07,160
todo abajo en el diagrama.

169
00:10:09,180 --> 00:10:12,877
En este punto, un problema es que esta operación es puramente lineal, 

170
00:10:12,877 --> 00:10:15,360
pero el lenguaje es un proceso muy poco lineal.

171
00:10:15,880 --> 00:10:19,657
Si la entrada que estamos midiendo es alta para Michael más Jordan, 

172
00:10:19,657 --> 00:10:23,823
también tendría que serlo necesariamente para Michael más Phelps y también 

173
00:10:23,823 --> 00:10:28,100
para Alexis más Jordan, a pesar de que no estén relacionados conceptualmente.

174
00:10:28,540 --> 00:10:32,000
Lo que realmente quieres es un simple sí o no para el nombre completo.

175
00:10:32,900 --> 00:10:35,418
Así que el siguiente paso es pasar este gran vector 

176
00:10:35,418 --> 00:10:37,840
intermedio por una función no lineal muy sencilla.

177
00:10:38,360 --> 00:10:41,748
Una opción común es la que toma todos los valores negativos y 

178
00:10:41,748 --> 00:10:45,300
los asigna a cero y deja todos los valores positivos sin cambiar.

179
00:10:46,440 --> 00:10:51,203
Y siguiendo con la tradición del aprendizaje profundo de nombres demasiado rimbombantes, 

180
00:10:51,203 --> 00:10:56,020
esta función tan sencilla se suele llamar unidad lineal rectificada, o ReLU para abreviar.

181
00:10:56,020 --> 00:10:57,880
Este es el aspecto del gráfico.

182
00:10:58,300 --> 00:11:02,533
Tomando nuestro ejemplo imaginario en el que la primera entrada del vector 

183
00:11:02,533 --> 00:11:06,483
intermedio es uno, si y sólo si el nombre completo es Michael Jordan, 

184
00:11:06,483 --> 00:11:10,378
y cero o negativo en caso contrario, después de pasarlo por el ReLU, 

185
00:11:10,378 --> 00:11:14,667
acabas con un valor muy limpio en el que todos los valores cero y negativos 

186
00:11:14,667 --> 00:11:15,740
se recortan a cero.

187
00:11:16,100 --> 00:11:17,921
Así que este resultado sería uno para el nombre 

188
00:11:17,921 --> 00:11:19,780
completo Michael Jordan y cero en caso contrario.

189
00:11:20,560 --> 00:11:24,120
En otras palabras, imita muy directamente el comportamiento de una puerta AND.

190
00:11:25,660 --> 00:11:29,275
A menudo los modelos utilizan una función ligeramente modificada que se llama JLU, 

191
00:11:29,275 --> 00:11:32,020
que tiene la misma forma básica, sólo que es un poco más suave.

192
00:11:32,500 --> 00:11:35,720
Pero para nuestros fines, es un poco más limpio si sólo pensamos en la ReLU.

193
00:11:36,740 --> 00:11:40,497
Además, cuando oigas a la gente referirse a las neuronas de un transformador, 

194
00:11:40,497 --> 00:11:42,520
estarán hablando de estos valores de aquí.

195
00:11:42,900 --> 00:11:47,320
Siempre que veas esa imagen común de red neuronal con una capa de puntos y un 

196
00:11:47,320 --> 00:11:52,363
montón de líneas que conectan con la capa anterior, que hemos visto antes en esta serie, 

197
00:11:52,363 --> 00:11:57,293
eso suele transmitir esta combinación de un paso lineal, una multiplicación matricial, 

198
00:11:57,293 --> 00:12:01,260
seguida de alguna función no lineal simple en términos, como una ReLU.

199
00:12:02,500 --> 00:12:05,511
Dirías que esta neurona está activa siempre que este 

200
00:12:05,511 --> 00:12:08,920
valor sea positivo y que está inactiva si ese valor es cero.

201
00:12:10,120 --> 00:12:12,380
El siguiente paso es muy similar al primero.

202
00:12:12,560 --> 00:12:16,580
Multiplicas por una matriz muy grande y añades un determinado término de sesgo.

203
00:12:16,980 --> 00:12:21,196
En este caso, el número de dimensiones de la salida se reduce al tamaño de ese 

204
00:12:21,196 --> 00:12:25,520
espacio de incrustación, así que voy a llamarlo matriz de proyección descendente.

205
00:12:26,220 --> 00:12:28,834
Y esta vez, en lugar de pensar en las cosas fila por fila, 

206
00:12:28,834 --> 00:12:31,360
en realidad es mejor pensar en ellas columna por columna.

207
00:12:31,860 --> 00:12:36,184
Verás, otra forma de retener la multiplicación de matrices en tu cabeza es 

208
00:12:36,184 --> 00:12:40,623
imaginar que tomas cada columna de la matriz y la multiplicas por el término 

209
00:12:40,623 --> 00:12:45,640
correspondiente del vector que está procesando y sumas todas esas columnas reescaladas.

210
00:12:46,840 --> 00:12:49,733
La razón por la que es más agradable pensar de este modo es porque 

211
00:12:49,733 --> 00:12:53,015
aquí las columnas tienen la misma dimensión que el espacio de incrustación, 

212
00:12:53,015 --> 00:12:55,780
así que podemos pensar en ellas como direcciones en ese espacio.

213
00:12:56,140 --> 00:12:59,408
Por ejemplo, imaginaremos que el modelo ha aprendido a hacer esa 

214
00:12:59,408 --> 00:13:03,080
primera columna en esta dirección de baloncesto que suponemos que existe.

215
00:13:04,180 --> 00:13:07,457
Lo que eso significaría es que cuando la neurona correspondiente en esa 

216
00:13:07,457 --> 00:13:10,780
primera posición esté activa, añadiremos esta columna al resultado final.

217
00:13:11,140 --> 00:13:14,056
Pero si esa neurona estuviera inactiva, si ese número fuera cero, 

218
00:13:14,056 --> 00:13:15,780
entonces esto no tendría ningún efecto.

219
00:13:16,500 --> 00:13:18,060
Y no sólo tiene que ser baloncesto.

220
00:13:18,220 --> 00:13:21,869
El modelo también podría hornear en esta columna y muchas otras características 

221
00:13:21,869 --> 00:13:25,200
que quiera asociar a algo que tenga el nombre completo de Michael Jordan.

222
00:13:26,980 --> 00:13:31,757
Y al mismo tiempo, todas las demás columnas de esta matriz te están diciendo 

223
00:13:31,757 --> 00:13:36,660
lo que se añadirá al resultado final si la neurona correspondiente está activa.

224
00:13:37,360 --> 00:13:41,004
Y si tienes un sesgo en este caso, es algo que estás añadiendo cada vez, 

225
00:13:41,004 --> 00:13:43,500
independientemente de los valores de las neuronas.

226
00:13:44,060 --> 00:13:45,280
Te preguntarás qué hace eso.

227
00:13:45,540 --> 00:13:47,992
Como ocurre con todos los objetos llenos de parámetros aquí, 

228
00:13:47,992 --> 00:13:49,320
es difícil decirlo con exactitud.

229
00:13:49,320 --> 00:13:52,100
Tal vez haya alguna contabilidad que la red tenga que hacer, 

230
00:13:52,100 --> 00:13:54,380
pero puedes sentirte libre de ignorarla por ahora.

231
00:13:54,860 --> 00:13:57,512
Haciendo nuestra notación un poco más compacta de nuevo, 

232
00:13:57,512 --> 00:14:00,676
llamaré a esta gran matriz W hacia abajo y de forma similar llamaré 

233
00:14:00,676 --> 00:14:04,260
a ese vector de sesgo B hacia abajo y lo pondré de nuevo en nuestro diagrama.

234
00:14:04,740 --> 00:14:08,883
Como he adelantado antes, lo que haces con este resultado final es sumarlo al 

235
00:14:08,883 --> 00:14:13,240
vector que fluyó hacia el bloque en esa posición y eso te da este resultado final.

236
00:14:13,820 --> 00:14:18,960
Así, por ejemplo, si el vector que entraba codificaba tanto el nombre Michael como 

237
00:14:18,960 --> 00:14:23,914
el apellido Jordan, como esta secuencia de operaciones activará esa puerta AND, 

238
00:14:23,914 --> 00:14:29,240
sumará en la dirección baloncesto, de modo que lo que salga codificará todo eso junto.

239
00:14:29,820 --> 00:14:34,200
Y recuerda que se trata de un proceso que ocurre en cada uno de esos vectores en paralelo.

240
00:14:34,800 --> 00:14:39,954
En concreto, si tomamos los números GPT-3, significa que este bloque no sólo tiene 

241
00:14:39,954 --> 00:14:44,860
50.000 neuronas, sino que tiene 50.000 veces el número de fichas de la entrada.

242
00:14:48,180 --> 00:14:51,124
Ésa es toda la operación: dos productos matriciales, 

243
00:14:51,124 --> 00:14:55,180
cada uno con un sesgo añadido y una simple función de recorte intermedio.

244
00:14:56,080 --> 00:14:59,493
Cualquiera de vosotros que haya visto los vídeos anteriores de la serie reconocerá 

245
00:14:59,493 --> 00:15:02,620
esta estructura como el tipo más básico de red neuronal que estudiamos allí.

246
00:15:03,080 --> 00:15:06,100
En ese ejemplo, se entrenó para reconocer dígitos manuscritos.

247
00:15:06,580 --> 00:15:10,730
Aquí, en el contexto de un transformador para un gran modelo lingüístico, 

248
00:15:10,730 --> 00:15:14,711
se trata de una pieza de una arquitectura mayor y cualquier intento de 

249
00:15:14,711 --> 00:15:18,581
interpretar qué hace exactamente está muy entrelazado con la idea de 

250
00:15:18,581 --> 00:15:23,180
codificar información en vectores de un espacio de incrustación de alta dimensión.

251
00:15:24,260 --> 00:15:27,589
Ésa es la lección principal, pero quiero dar un paso atrás y reflexionar 

252
00:15:27,589 --> 00:15:31,466
sobre dos cosas diferentes, la primera de las cuales es una especie de contabilidad, 

253
00:15:31,466 --> 00:15:34,978
y la segunda implica un hecho muy sugerente sobre las dimensiones superiores 

254
00:15:34,978 --> 00:15:38,080
que en realidad no conocía hasta que indagué en los transformadores.

255
00:15:41,080 --> 00:15:45,920
En los dos últimos capítulos, tú y yo empezamos a contar el número total de parámetros de 

256
00:15:45,920 --> 00:15:50,760
GPT-3 y a ver exactamente dónde viven, así que vamos a terminar rápidamente el juego aquí.

257
00:15:51,400 --> 00:15:55,089
Ya he mencionado que esta matriz de proyección ascendente tiene 

258
00:15:55,089 --> 00:15:58,490
algo menos de 50.000 filas y que cada fila coincide con el 

259
00:15:58,490 --> 00:16:02,180
tamaño del espacio de incrustación, que para GPT-3 es de 12.288.

260
00:16:03,240 --> 00:16:07,808
Multiplicándolos, nos da 604 millones de parámetros sólo para esa matriz, 

261
00:16:07,808 --> 00:16:13,179
y la proyección hacia abajo tiene el mismo número de parámetros sólo que con una forma 

262
00:16:13,179 --> 00:16:13,920
transpuesta.

263
00:16:14,500 --> 00:16:17,400
Así que, en conjunto, dan unos 1.200 millones de parámetros.

264
00:16:18,280 --> 00:16:21,011
El vector de sesgo también tiene en cuenta un par de parámetros más, 

265
00:16:21,011 --> 00:16:24,100
pero es una proporción trivial del total, así que ni siquiera voy a mostrarlo.

266
00:16:24,660 --> 00:16:29,823
En GPT-3, esta secuencia de vectores de incrustación fluye a través no de uno, 

267
00:16:29,823 --> 00:16:34,203
sino de 96 MLP distintos, por lo que el número total de parámetros 

268
00:16:34,203 --> 00:16:38,060
dedicados a todos estos bloques suma unos 116.000 millones.

269
00:16:38,820 --> 00:16:42,279
Esto supone alrededor de 2 tercios del total de parámetros de la red, 

270
00:16:42,279 --> 00:16:46,134
y cuando lo sumas a todo lo que teníamos antes, para los bloques de atención, 

271
00:16:46,134 --> 00:16:50,285
la incrustación y la incrustación, obtienes efectivamente ese gran total de 175.000 

272
00:16:50,285 --> 00:16:51,620
millones como se anunciaba.

273
00:16:53,060 --> 00:16:56,417
Probablemente merezca la pena mencionar que hay otro conjunto de parámetros 

274
00:16:56,417 --> 00:16:59,775
asociados a esos pasos de normalización que esta explicación se ha saltado, 

275
00:16:59,775 --> 00:17:03,398
pero que, al igual que el vector de sesgo, representan una proporción muy trivial 

276
00:17:03,398 --> 00:17:03,840
del total.

277
00:17:05,900 --> 00:17:09,278
En cuanto al segundo punto de reflexión, quizá te preguntes si este ejemplo 

278
00:17:09,278 --> 00:17:12,390
central de juguete al que hemos dedicado tanto tiempo refleja cómo se 

279
00:17:12,390 --> 00:17:15,680
almacenan realmente los hechos en los grandes modelos lingüísticos reales.

280
00:17:16,319 --> 00:17:20,106
Es cierto que las filas de esa primera matriz pueden considerarse direcciones en 

281
00:17:20,106 --> 00:17:23,846
este espacio de incrustación, y eso significa que la activación de cada neurona 

282
00:17:23,846 --> 00:17:27,540
te dice cuánto se alinea un vector determinado con alguna dirección específica.

283
00:17:27,760 --> 00:17:30,943
También es cierto que las columnas de esa segunda matriz te 

284
00:17:30,943 --> 00:17:34,340
dicen lo que se añadirá al resultado si esa neurona está activa.

285
00:17:34,640 --> 00:17:36,800
Ambas cosas no son más que hechos matemáticos.

286
00:17:37,740 --> 00:17:41,659
Sin embargo, las pruebas sugieren que las neuronas individuales muy raramente 

287
00:17:41,659 --> 00:17:44,422
representan un único rasgo limpio como Michael Jordan, 

288
00:17:44,422 --> 00:17:47,889
y en realidad puede haber una muy buena razón para que esto sea así, 

289
00:17:47,889 --> 00:17:51,758
relacionada con una idea que flota estos días entre los investigadores de la 

290
00:17:51,758 --> 00:17:54,120
interpretabilidad, conocida como superposición.

291
00:17:54,640 --> 00:17:58,576
Se trata de una hipótesis que podría ayudar a explicar tanto por qué los modelos son 

292
00:17:58,576 --> 00:18:02,420
especialmente difíciles de interpretar como por qué escalan sorprendentemente bien.

293
00:18:03,500 --> 00:18:07,622
La idea básica es que si tienes un espacio de n dimensiones y quieres representar 

294
00:18:07,622 --> 00:18:11,543
un montón de características diferentes utilizando direcciones que sean todas 

295
00:18:11,543 --> 00:18:14,107
perpendiculares entre sí en ese espacio, ya sabes, 

296
00:18:14,107 --> 00:18:16,871
de forma que si añades un componente en una dirección, 

297
00:18:16,871 --> 00:18:19,284
no influya en ninguna de las otras direcciones, 

298
00:18:19,284 --> 00:18:22,703
entonces el número máximo de vectores que puedes encajar es sólo n, 

299
00:18:22,703 --> 00:18:23,960
el número de dimensiones.

300
00:18:24,600 --> 00:18:27,620
Para un matemático, en realidad, ésta es la definición de dimensión.

301
00:18:28,220 --> 00:18:30,986
Pero donde se pone interesante es si relajas un 

302
00:18:30,986 --> 00:18:33,580
poco esa restricción y toleras algo de ruido.

303
00:18:34,180 --> 00:18:37,324
Digamos que permites que esas características se representen 

304
00:18:37,324 --> 00:18:40,314
mediante vectores que no son exactamente perpendiculares, 

305
00:18:40,314 --> 00:18:43,820
sino casi perpendiculares, quizá entre 89 y 91 grados de separación.

306
00:18:44,820 --> 00:18:48,020
Si estuviéramos en dos o tres dimensiones, esto no supondría ninguna diferencia.

307
00:18:48,260 --> 00:18:51,834
Eso apenas te da margen de maniobra adicional para encajar más vectores, 

308
00:18:51,834 --> 00:18:55,115
lo que hace aún más contraintuitivo que, para dimensiones mayores, 

309
00:18:55,115 --> 00:18:56,780
la respuesta cambie drásticamente.

310
00:18:57,660 --> 00:19:01,755
Puedo darte una ilustración muy rápida y sucia de esto utilizando un 

311
00:19:01,755 --> 00:19:06,030
poco de Python que va a crear una lista de vectores de 100 dimensiones, 

312
00:19:06,030 --> 00:19:10,304
cada uno inicializado aleatoriamente, y esta lista va a contener 10.000 

313
00:19:10,304 --> 00:19:14,400
vectores distintos, es decir, 100 veces más vectores que dimensiones.

314
00:19:15,320 --> 00:19:19,900
Este gráfico de aquí muestra la distribución de ángulos entre pares de estos vectores.

315
00:19:20,680 --> 00:19:24,424
Como empezaron de forma aleatoria, esos ángulos pueden ser de 0 a 180 grados, 

316
00:19:24,424 --> 00:19:28,072
pero te darás cuenta de que, incluso en el caso de los vectores aleatorios, 

317
00:19:28,072 --> 00:19:31,960
existe un fuerte sesgo a favor de que las cosas estén más cerca de los 90 grados.

318
00:19:32,500 --> 00:19:37,121
Lo que voy a hacer es ejecutar un proceso de optimización que, de forma iterativa, 

319
00:19:37,121 --> 00:19:41,520
empuje todos estos vectores para que intenten ser más perpendiculares entre sí.

320
00:19:42,060 --> 00:19:46,660
Después de repetirlo muchas veces, éste es el aspecto de la distribución de ángulos.

321
00:19:47,120 --> 00:19:52,040
En realidad, tenemos que ampliarlo aquí, porque todos los ángulos posibles entre 

322
00:19:52,040 --> 00:19:56,900
pares de vectores se sitúan dentro de este estrecho margen entre 89 y 91 grados.

323
00:19:58,020 --> 00:20:02,583
En general, una consecuencia de algo conocido como el lema de Johnson-Lindenstrauss 

324
00:20:02,583 --> 00:20:06,602
es que el número de vectores que puedes meter en un espacio que sean casi 

325
00:20:06,602 --> 00:20:10,840
perpendiculares como éste crece exponencialmente con el número de dimensiones.

326
00:20:11,960 --> 00:20:15,197
Esto es muy significativo para los grandes modelos lingüísticos, 

327
00:20:15,197 --> 00:20:19,083
que podrían beneficiarse de asociar ideas independientes con direcciones casi 

328
00:20:19,083 --> 00:20:19,880
perpendiculares.

329
00:20:20,000 --> 00:20:23,220
Significa que puede almacenar muchísimas más ideas 

330
00:20:23,220 --> 00:20:26,440
que las dimensiones del espacio que tiene asignado.

331
00:20:27,320 --> 00:20:29,616
Esto podría explicar en parte por qué el rendimiento 

332
00:20:29,616 --> 00:20:31,740
del modelo parece escalar tan bien con el tamaño.

333
00:20:32,540 --> 00:20:36,585
Un espacio que tiene 10 veces más dimensiones puede almacenar mucho, 

334
00:20:36,585 --> 00:20:39,400
mucho más que 10 veces más ideas independientes.

335
00:20:40,420 --> 00:20:43,642
Y esto es relevante no sólo para ese espacio de incrustación donde viven 

336
00:20:43,642 --> 00:20:46,908
los vectores que fluyen a través del modelo, sino también para ese vector 

337
00:20:46,908 --> 00:20:50,440
lleno de neuronas en medio de ese perceptrón multicapa que acabamos de estudiar.

338
00:20:50,960 --> 00:20:56,452
Es decir, con los tamaños de GPT-3, no sólo podría sondear 50.000 rasgos, sino que, 

339
00:20:56,452 --> 00:21:02,271
si aprovechara esta enorme capacidad añadida utilizando direcciones casi perpendiculares 

340
00:21:02,271 --> 00:21:07,240
del espacio, podría sondear muchísimos más rasgos del vector que se procesa.

341
00:21:07,780 --> 00:21:10,942
Pero si estuviera haciendo eso, lo que significa es que los rasgos 

342
00:21:10,942 --> 00:21:14,340
individuales no van a ser visibles como una sola neurona que se ilumina.

343
00:21:14,660 --> 00:21:18,472
En lugar de eso, tendría que parecerse a alguna combinación específica de neuronas, 

344
00:21:18,472 --> 00:21:19,380
a una superposición.

345
00:21:20,400 --> 00:21:22,421
Para cualquiera que tenga curiosidad por saber más, 

346
00:21:22,421 --> 00:21:25,104
un término clave de búsqueda relevante aquí es autoencoder disperso, 

347
00:21:25,104 --> 00:21:28,253
que es una herramienta que algunas de las personas de interpretabilidad utilizan 

348
00:21:28,253 --> 00:21:30,780
para intentar extraer cuáles son las características verdaderas, 

349
00:21:30,780 --> 00:21:32,880
aunque estén muy superpuestas en todas estas neuronas.

350
00:21:33,540 --> 00:21:36,800
Voy a enlazar a un par de posts antrópicos muy buenos sobre este tema.

351
00:21:37,880 --> 00:21:41,123
Llegados a este punto, no hemos tocado todos los detalles de un transformador, 

352
00:21:41,123 --> 00:21:43,300
pero tú y yo hemos tocado los puntos más importantes.

353
00:21:43,520 --> 00:21:47,640
Lo principal que quiero tratar en un próximo capítulo es el proceso de formación.

354
00:21:48,460 --> 00:21:51,357
Por un lado, la respuesta breve sobre cómo funciona el entrenamiento 

355
00:21:51,357 --> 00:21:54,422
es que se trata de retropropagación, y hemos tratado la retropropagación 

356
00:21:54,422 --> 00:21:56,900
en un contexto aparte con capítulos anteriores de la serie.

357
00:21:57,220 --> 00:22:00,800
Pero hay más cosas que discutir, como la función de coste específica utilizada 

358
00:22:00,800 --> 00:22:04,380
para los modelos lingüísticos, la idea del ajuste fino mediante el aprendizaje 

359
00:22:04,380 --> 00:22:07,780
por refuerzo con retroalimentación humana y la noción de leyes de escalado.

360
00:22:08,960 --> 00:22:11,144
Nota rápida para los seguidores activos entre vosotros: 

361
00:22:11,144 --> 00:22:13,875
hay una serie de vídeos no relacionados con el aprendizaje automático 

362
00:22:13,875 --> 00:22:16,996
a los que estoy deseando hincar el diente antes de hacer el siguiente capítulo, 

363
00:22:16,996 --> 00:22:20,000
así que puede que tarde un poco, pero prometo que llegará a su debido tiempo.

364
00:22:35,640 --> 00:22:37,920
Gracias.

