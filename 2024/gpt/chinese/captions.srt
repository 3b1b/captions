1
00:00:00,160 --> 00:00:05,200
GPT 是 Generative Pre-trained Transformer 的缩写。

2
00:00:05,200 --> 00:00:07,140
首个单词较为直接，

3
00:00:07,140 --> 00:00:09,290
它们是用来生成新文本的机器人。

4
00:00:09,290 --> 00:00:14,480
"Pre-trained" 指的是模型经历了从大量数据中学习的过程， 

5
00:00:14,480 --> 00:00:19,990
这个词暗示了该模型还有进一步在特定任务中进行额外训练和微调的可能。

6
00:00:19,990 --> 00:00:23,030
然而，最后一个词，才是真正重要的部分。

7
00:00:23,030 --> 00:00:27,920
Transformer 是一种特定类型的神经网络，一个机器学习模型，

8
00:00:27,920 --> 00:00:31,740
它是现今 AI 高速发展的核心创新。

9
00:00:31,740 --> 00:00:34,500
我希望通过这个视频和接下来的章节，

10
00:00:34,500 --> 00:00:36,520
以一种便于理解的方式，

11
00:00:36,520 --> 00:00:39,150
阐述 Transformer 内部实际发生的过程。

12
00:00:39,150 --> 00:00:42,640
我们将逐步探索流经它的数据。

13
00:00:42,640 --> 00:00:47,750
你可以使用 Transformer 构建许多不同类型的模型。

14
00:00:47,750 --> 00:00:50,650
有些模型接受音频输入并生成文字。

15
00:00:50,650 --> 00:00:53,760
这句话来自一个反向工作的模型，

16
00:00:54,000 --> 00:00:56,120
只需要文本输入就能生成人工语音。

17
00:00:56,120 --> 00:00:59,360
所有那些在 2022 年风靡全球的工具，

18
00:00:59,360 --> 00:01:04,239
如 DALL-E 和 MidJourney，能够将文本描述转化为图像，

19
00:01:04,239 --> 00:01:05,519
都是基于 Transformer 的。

20
00:01:05,519 --> 00:01:06,830
即使我无法让它完全理解

21
00:01:06,830 --> 00:01:09,520
"π 生物"到底是什么，

22
00:01:09,520 --> 00:01:13,040
我仍对这样的事情有可能发生感到惊讶。

23
00:01:13,040 --> 00:01:17,460
最初的 Transformer 是 Google 在 2017 年推出的，

24
00:01:17,460 --> 00:01:22,440
主要用于将一种语言的文本翻译成另一种语言。

25
00:01:22,440 --> 00:01:24,880
但我们将关注的版本，

26
00:01:24,880 --> 00:01:28,030
也就是像 ChatGPT 这样的工具所依赖的类型，

27
00:01:28,030 --> 00:01:35,070
会是一个接受一段文本（可能伴随一些图像或声音）的模型，

28
00:01:35,070 --> 00:01:38,050
然后预测文章接下来的内容。

29
00:01:38,050 --> 00:01:41,130
这种预测呈现为概率分布形式

30
00:01:41,130 --> 00:01:43,770
涵盖了很多可能接下来出现的文字片段。

31
00:01:43,770 --> 00:01:45,520
乍一看，

32
00:01:45,520 --> 00:01:47,410
你可能觉得预测下一个词

33
00:01:47,410 --> 00:01:50,400
似乎与生成新的文字有着天壤之别。

34
00:01:50,400 --> 00:01:52,600
但当你有了像这样的预测模型后，

35
00:01:52,600 --> 00:01:55,940
你可以试着让它生成一段更长的文字，

36
00:01:55,940 --> 00:01:58,750
方法就是给它一个初始的片段，

37
00:01:58,750 --> 00:02:02,290
然后随机从刚生成的概率分布中选取一个样本，

38
00:02:02,290 --> 00:02:03,690
将这个样本追加到文字中，

39
00:02:03,690 --> 00:02:05,440
接着再进行一轮预测，

40
00:02:05,440 --> 00:02:08,190
这次的预测需要基于所有新生成的文字，

41
00:02:08,190 --> 00:02:09,919
包括刚刚添加的那部分。

42
00:02:09,919 --> 00:02:10,780
我不知道你怎么看，

43
00:02:10,780 --> 00:02:13,210
但我真的觉得这个方法的效果可能并不理想。

44
00:02:13,210 --> 00:02:14,740
举个例子，在这个动画中，

45
00:02:14,740 --> 00:02:16,470
我在我的笔记本电脑上运行 GPT-2，

46
00:02:16,470 --> 00:02:19,960
并让它不断地预测与取样下一个文字块，

47
00:02:19,960 --> 00:02:22,790
尝试基于一段起始文本生成一个故事。

48
00:02:22,790 --> 00:02:26,710
结果呢，这个故事基本上没什么逻辑可言。  

49
00:02:26,710 --> 00:02:30,090
但是，如果我换成 GPT-3 的 API 调用，

50
00:02:30,090 --> 00:02:34,930
这是同样的基本模型，只是规模更大，突然间就像变魔法一样，

51
00:02:34,930 --> 00:02:36,490
我们不仅得到了一个合乎逻辑的故事，

52
00:02:36,490 --> 00:02:38,810
这个故事甚至能暗示出一个 π 生物

53
00:02:38,810 --> 00:02:41,550
可能居住在一个充满数学和计算的世界里。

54
00:02:41,550 --> 00:02:45,390
这个过程，就是通过重复的预测和选取来生成文本，

55
00:02:45,390 --> 00:02:51,890
正是你在使用ChatGPT或其他大型语言模型时所经历的，模型会逐字地生成文本。

56
00:02:51,890 --> 00:02:52,490
其实，

57
00:02:52,490 --> 00:02:54,700
我特别希望能有一种功能，即

58
00:02:54,700 --> 00:02:59,180
能看到它在选择每个新词时的底层概率分布。

59
00:03:03,921 --> 00:03:06,320
我们先从宏观角度看看

60
00:03:06,320 --> 00:03:08,480
数据是如何在 Transformer 模型中流转的。 

61
00:03:08,480 --> 00:03:13,480
接下来，我们会详细探讨、解释每一个步骤，并对其进行扩展。 

62
00:03:13,480 --> 00:03:16,730
但是大体来说，当聊天机器人生成某个特定词汇时，

63
00:03:16,730 --> 00:03:18,560
下面就是它底层的运行机制。

64
00:03:18,560 --> 00:03:22,520
首先，输入内容会被拆分成许多小片段。

65
00:03:22,520 --> 00:03:23,960
这些小片段被称为词元 (Tokens)。

66
00:03:23,960 --> 00:03:27,600
对于文本来说，这些 Token 通常是单词、单词的一小部分，

67
00:03:27,600 --> 00:03:29,840
或者其他常见的字符组合。

68
00:03:29,840 --> 00:03:32,040
如果是图像或声音，

69
00:03:32,040 --> 00:03:35,550
Token 则可能代表图像的一小块区域

70
00:03:35,550 --> 00:03:37,450
或声音的一段小片段。

71
00:03:37,450 --> 00:03:40,490
然后，每个 Token 会对应到一个向量上，

72
00:03:40,490 --> 00:03:42,310
也就是一串数字，

73
00:03:42,310 --> 00:03:45,600
这串数字的目的是以某种方式来表达该片段的含义。

74
00:03:45,600 --> 00:03:46,900
如果你把这些向量看作是

75
00:03:46,900 --> 00:03:50,100
在一个高维空间中的坐标，

76
00:03:50,100 --> 00:03:51,730
那么含义相似的词汇倾向于

77
00:03:51,730 --> 00:03:54,560
彼此接近的向量上。

78
00:03:54,560 --> 00:03:56,950
这些向量序列接下来

79
00:03:56,950 --> 00:03:59,480
会经过一个称为“注意力块”的处理过程，

80
00:03:59,480 --> 00:04:01,840
使得向量能够相互“交流” 

81
00:04:01,840 --> 00:04:04,880
并根据彼此信息更新自身的值。

82
00:04:04,880 --> 00:04:05,360
例如，

83
00:04:05,360 --> 00:04:06,950
“model”这个单词

84
00:04:06,950 --> 00:04:09,270
在“机器学习模型（model）”中的意思

85
00:04:09,270 --> 00:04:12,040
和在“时尚模特（model）”中的意思是不同的。

86
00:04:12,040 --> 00:04:13,840
注意力模块的作用

87
00:04:13,840 --> 00:04:19,200
就是要确定上下文中哪些词对更新其他词的意义有关，

88
00:04:19,200 --> 00:04:22,390
以及应该如何准确地更新这些含义。

89
00:04:22,390 --> 00:04:24,560
每当我说到“含义”这个词时，

90
00:04:24,560 --> 00:04:28,000
完全通过向量中的数字来表达。

91
00:04:28,000 --> 00:04:32,020
之后，这些向量会经过另一种处理，

92
00:04:32,020 --> 00:04:33,920
这个过程根据资料的不同，

93
00:04:33,920 --> 00:04:36,680
可能被称作多层感知机

94
00:04:36,680 --> 00:04:38,400
或者前馈层。

95
00:04:38,400 --> 00:04:40,270
这个阶段，向量不再互相“交流”，

96
00:04:40,270 --> 00:04:42,960
而是并行地经历同一处理。

97
00:04:42,960 --> 00:04:45,680
虽然这个步骤比较难以理解，

98
00:04:45,680 --> 00:04:46,560
但我们会在后面讨论，

99
00:04:46,560 --> 00:04:48,190
这个步骤有点像

100
00:04:48,190 --> 00:04:51,290
对每个向量提出一系列的问题，

101
00:04:51,290 --> 00:04:54,930
然后根据这些问题的答案来更新向量。

102
00:04:54,930 --> 00:04:56,500
这两个处理阶段的操作

103
00:04:56,500 --> 00:05:00,750
本质上都是大量的矩阵乘法，

104
00:05:00,750 --> 00:05:03,280
我们要学习的主要是 

105
00:05:03,470 --> 00:05:05,440
如何解读这些背后的矩阵。

106
00:05:05,440 --> 00:05:11,090
在讲解中，我省略了一些中间步骤的归一化细节，

107
00:05:11,090 --> 00:05:13,560
毕竟这只是宏观概览。

108
00:05:13,560 --> 00:05:15,690
接下来，过程基本上是重复的。 

109
00:05:15,690 --> 00:05:19,440
你需要在注意力模块和多层感知机（MLP）模块之间不断切换，

110
00:05:19,440 --> 00:05:20,940
直到最后，

111
00:05:20,940 --> 00:05:22,220
我们期望通过某种方式，

112
00:05:22,220 --> 00:05:28,840
文章的核心意义已经被完全融入到序列的最后一个向量中。

113
00:05:28,840 --> 00:05:31,800
然后对这最后一个向量进行特定操作，

114
00:05:31,800 --> 00:05:35,440
产生一个覆盖所有可能 Token 的概率分布，

115
00:05:35,440 --> 00:05:38,990
这些 Token 代表的是可能接下来出现的任何小段文本。

116
00:05:38,990 --> 00:05:39,820
就像我说的，

117
00:05:39,820 --> 00:05:43,620
一旦拥有了这样一个工具，它可以根据一小段文本预测下一步，

118
00:05:43,620 --> 00:05:44,700
你就可以给它输入一些初始文本，

119
00:05:44,700 --> 00:05:49,220
让它不断地进行预测下一步，

120
00:05:49,220 --> 00:05:51,440
从概率分布中抽样，添加到现有文本，

121
00:05:51,440 --> 00:05:53,590
然后不断重复这个过程。

122
00:05:53,590 --> 00:05:56,070
了解这一点的人可能还记得， 早在

123
00:05:56,070 --> 00:05:58,140
ChatGPT 出现之前，

124
00:05:58,140 --> 00:06:00,880
GPT-3 的早期演示就是这样的，

125
00:06:00,880 --> 00:06:04,560
根据一段起始文本自动补全故事和文章。 

126
00:06:04,560 --> 00:06:08,170
将这样的工具转化为聊天机器人的一个简单方法是，

127
00:06:08,170 --> 00:06:10,600
就是准备一段文本，

128
00:06:10,600 --> 00:06:15,040
设定出用户与一个有帮助的 AI 助手交互的场景，

129
00:06:15,040 --> 00:06:16,960
这就是所谓的系统提示。

130
00:06:16,960 --> 00:06:19,550
然后，你可以利用用户的初始问题

131
00:06:19,550 --> 00:06:21,640
或提示词作为对话的开头，

132
00:06:21,640 --> 00:06:23,580
接着让 AI 开始预测

133
00:06:23,580 --> 00:06:26,730
这个有用的 AI 助手会如何进行回应。

134
00:06:26,730 --> 00:06:31,810
为了使这个过程运行得更好，还需要额外的训练步骤，

135
00:06:31,810 --> 00:06:33,990
不过总的来说，这就是基本的思路。

136
00:06:33,990 --> 00:06:42,670
在这一章节中，我们将深入讨论网络开始和结束时发生的事情，

137
00:06:42,670 --> 00:06:44,610
同时，我也会花大量的时间

138
00:06:44,610 --> 00:06:46,900
回顾一些重要的背景知识，

139
00:06:46,900 --> 00:06:50,800
这些知识对于熟悉 Transformer 的机器学习工程师来说，

140
00:06:50,800 --> 00:06:52,400
都是基础常识。

141
00:06:52,400 --> 00:06:55,710
如果你已经对背景知识比较熟悉，而且迫不及待想要了解更多，

142
00:06:55,710 --> 00:06:57,910
那么你可以选择直接跳到下一章节，

143
00:06:57,910 --> 00:07:03,490
这一章节将会关注 Transformer 的核心部分，即注意力模块。

144
00:07:03,490 --> 00:07:07,040
在这之后，我还会详细讨论多层感知机模块，

145
00:07:07,040 --> 00:07:07,910
训练过程，

146
00:07:07,910 --> 00:07:12,050
以及之前被省略的其他一些细节。

147
00:07:12,050 --> 00:07:13,190
作为背景信息，

148
00:07:13,190 --> 00:07:16,260
这些视频是我们的深度学习系列课程的补充部分，

149
00:07:16,260 --> 00:07:20,730
你不一定非得按照顺序来看，

150
00:07:20,730 --> 00:07:23,460
但在深入研究 Transformer 之前，

151
00:07:23,460 --> 00:07:24,830
我认为有必要确保

152
00:07:24,830 --> 00:07:28,890
我们对深度学习的基本概念和架构有共同的理解。

153
00:07:28,890 --> 00:07:33,190
这里需要明确的是，机器学习是一种方法论，

154
00:07:33,190 --> 00:07:38,150
它涉及到使用数据来指导模型的行为模式。

155
00:07:38,150 --> 00:07:39,990
具体来说，

156
00:07:39,990 --> 00:07:42,360
你可能需要一个函数，输入一张图片， 

157
00:07:42,360 --> 00:07:44,470
输出对应的标签描述，

158
00:07:44,470 --> 00:07:48,280
或者预测给定文本片段的下一个单词，

159
00:07:48,280 --> 00:07:52,970
或者其他需要直觉和模式识别的任务，

160
00:07:52,970 --> 00:07:55,040
虽然我们现在已经习以为常，

161
00:07:55,040 --> 00:07:57,480
机器学习的核心思想在于，我们不再尝试

162
00:07:57,480 --> 00:08:00,670
去编写固定的程序来完成这些任务，

163
00:08:00,670 --> 00:08:04,020
这是在 AI 的最早阶段人们会做的事情。

164
00:08:04,020 --> 00:08:08,080
而是构建一个具有可调节参数的灵活结构，

165
00:08:08,080 --> 00:08:10,160
就像一系列的旋钮和调节器，

166
00:08:10,160 --> 00:08:15,400
然后通过大量实例输入和期望输出的学习，

167
00:08:15,400 --> 00:08:18,250
调整和微调参数的值，

168
00:08:18,250 --> 00:08:20,160
以此来模拟这种直觉行为。

169
00:08:20,160 --> 00:08:24,900
比如，可能最直观的机器学习入门模型就是线性回归了，

170
00:08:24,900 --> 00:08:27,570
这里你把输入和输出都视为单个数字，

171
00:08:27,570 --> 00:08:30,730
如房子的面积和价格，

172
00:08:30,730 --> 00:08:35,120
你要做的，就是找出一条最拟合这些数据的直线，

173
00:08:35,120 --> 00:08:37,460
以此来预测将来的房价。

174
00:08:37,460 --> 00:08:40,400
这条线由两个连续的参数，

175
00:08:40,400 --> 00:08:42,390
即斜率和 y 轴截距。

176
00:08:42,390 --> 00:08:44,760
线性回归的目标就是

177
00:08:44,760 --> 00:08:48,910
确定这些参数以尽可能匹配数据。

178
00:08:48,910 --> 00:08:52,400
不用说，深度学习模型会更复杂。

179
00:08:52,400 --> 00:08:58,120
比如，GPT-3 就拥有 1750 亿个参数，而不仅仅是两个。

180
00:08:58,120 --> 00:08:59,200
但值得注意的是，

181
00:08:59,200 --> 00:09:03,760
并不是简单地构建一个参数众多的庞大模型就能有效工作，

182
00:09:04,010 --> 00:09:07,120
这样做可能会导致模型严重过拟合训练数据，

183
00:09:07,120 --> 00:09:09,440
或者训练起来极其困难。

184
00:09:09,440 --> 00:09:12,120
深度学习涵盖了一系列

185
00:09:12,120 --> 00:09:16,200
在过去几十年里证明了具有出色扩展能力的模型类别。

186
00:09:16,200 --> 00:09:19,520
它们之所以能够成功，关键在于都采用了相同的训练算法：

187
00:09:19,520 --> 00:09:23,140
即反向传播，我们在前面的章节已经介绍过这一点。

188
00:09:23,140 --> 00:09:25,230
你需要理解的是，

189
00:09:25,230 --> 00:09:28,560
要让这种训练算法能在大规模应用中顺利进行，

190
00:09:28,800 --> 00:09:31,830
模型必须遵循一种特定的结构。

191
00:09:31,830 --> 00:09:33,760
如果你对这种结构有所了解，

192
00:09:33,760 --> 00:09:37,760
就能更好地理解 Transformer 处理语言的方式及其背后的逻辑，

193
00:09:37,760 --> 00:09:40,560
否则某些设计选择可能显得有些随意。

194
00:09:40,560 --> 00:09:43,600
首先，不管你构建的是哪种模型，

195
00:09:43,600 --> 00:09:46,690
输入都必须是一个实数数组。

196
00:09:46,690 --> 00:09:51,040
这可能只是一个数字列表，也可能是一个二维数组，

197
00:09:51,040 --> 00:09:53,760
或者更常见的是更高维度的数组，

198
00:09:53,760 --> 00:09:56,320
这种通用的术语我们称之为张量。

199
00:09:56,510 --> 00:10:01,810
这些输入数据通常会被逐步转换成多个不同的层，

200
00:10:01,810 --> 00:10:06,000
每一层都构成了实数数组，

201
00:10:06,000 --> 00:10:07,450
直到最后一层，

202
00:10:07,450 --> 00:10:09,260
你可以将其视为输出层。

203
00:10:09,260 --> 00:10:09,680
例如，

204
00:10:09,680 --> 00:10:13,700
我们的文本处理模型的最终输出层是一个数字列表，

205
00:10:13,700 --> 00:10:17,100
这些数字代表了所有可能的下一词汇的概率分布。

206
00:10:17,100 --> 00:10:18,170
在深度学习领域，

207
00:10:18,170 --> 00:10:21,600
这些模型的参数通常被称作权重。

208
00:10:21,600 --> 00:10:24,130
这样称呼的原因是，这些模型的一个核心特点是

209
00:10:24,130 --> 00:10:26,720
这些参数与正在处理的数据之间的唯一交互方式

210
00:10:26,720 --> 00:10:29,960
就是通过权重和。

211
00:10:29,960 --> 00:10:32,840
虽然模型中也会穿插一些非线性函数，

212
00:10:32,840 --> 00:10:35,140
但它们并不依赖于这些参数。

213
00:10:35,140 --> 00:10:36,200
通常来说，

214
00:10:36,200 --> 00:10:40,060
我们不会直接看到这些权重和的裸露形式，

215
00:10:40,060 --> 00:10:45,510
而是会发现它们被作为矩阵向量乘积的不同部分封装起来。

216
00:10:45,510 --> 00:10:48,180
这其实是在表达同一种概念。

217
00:10:48,180 --> 00:10:51,030
如果你回想一下矩阵向量乘法是如何运作的，

218
00:10:51,030 --> 00:10:54,500
输出中的每一部分都像是一个权重和。

219
00:10:54,500 --> 00:10:57,060
更直观的方式是，

220
00:10:57,060 --> 00:11:01,340
将这些可调参数填充的矩阵想象成

221
00:11:01,340 --> 00:11:06,240
对处理中数据进行向量转换的工具。

222
00:11:06,240 --> 00:11:10,510
例如，GPT-3 中的那 1750 亿个权重

223
00:11:10,510 --> 00:11:14,330
就被组织在大约 28,000 个不同的矩阵中。

224
00:11:14,330 --> 00:11:17,520
这些矩阵又被分为八个不同的类别，

225
00:11:17,520 --> 00:11:18,900
你和我将要做的就是

226
00:11:18,900 --> 00:11:20,800
逐一理解这些类别，

227
00:11:20,800 --> 00:11:22,540
了解每种类型的功能。

228
00:11:22,540 --> 00:11:24,470
接下来的过程会非常有趣，

229
00:11:24,470 --> 00:11:27,120
我们将参考 GPT-3 的具体数据

230
00:11:27,120 --> 00:11:31,680
来统计这 1750 亿是如何分配的。

231
00:11:31,680 --> 00:11:34,720
即使现在有更大更好的模型，

232
00:11:34,720 --> 00:11:35,780
GPT-3 模型仍具有独特的魅力，

233
00:11:35,780 --> 00:11:39,350
作为第一个引发全球关注的大语言模型，

234
00:11:39,350 --> 00:11:40,860
影响力并未局限于机器学习社区。

235
00:11:40,860 --> 00:11:42,480
实际上，

236
00:11:42,480 --> 00:11:47,120
对于更现代的模型，公司往往对具体的数据保持更严格的保密。

237
00:11:47,120 --> 00:11:48,820
在这里，我想说明的是，

238
00:11:48,820 --> 00:11:52,960
当你深入探索像 ChatGPT 这样的工具的内部机制时，

239
00:11:52,960 --> 00:11:57,970
你会发现几乎所有的计算过程都体现为矩阵和向量的乘积。

240
00:11:57,970 --> 00:12:01,440
在这海量的数字中，很容易迷失方向，

241
00:12:01,440 --> 00:12:06,400
但你需要在心中清楚地区分两个概念：模型的权重 

242
00:12:06,400 --> 00:12:10,360
（我将用蓝色或红色表示）和正在处理的数据

243
00:12:10,360 --> 00:12:11,880
（我将用灰色表示）。

244
00:12:11,880 --> 00:12:13,880
权重就是模型的“大脑”。

245
00:12:13,880 --> 00:12:18,400
这些是在训练过程中学习到的，它们决定了模型的行为模式。 

246
00:12:18,400 --> 00:12:20,640
正在处理的数据仅仅是编码了

247
00:12:20,640 --> 00:12:24,340
某次操作中模型接收的具体输入， 

248
00:12:24,340 --> 00:12:26,400
比如一段文本示例。

249
00:12:26,400 --> 00:12:29,040
理解了上述基础知识后，

250
00:12:29,040 --> 00:12:32,260
让我们探讨文本处理示例的第一步：

251
00:12:32,260 --> 00:12:34,780
将输入分割成小片段，

252
00:12:34,780 --> 00:12:36,620
并将这些片段转换成向量。

253
00:12:36,620 --> 00:12:38,960
我之前提到过，这些小片段被称为 Tokens，

254
00:12:38,960 --> 00:12:41,260
它们可能是单词的一部分或是标点符号，

255
00:12:41,260 --> 00:12:44,750
但在本章，特别是在下一章中，

256
00:12:44,750 --> 00:12:48,650
我倾向于简化理解，假设它们完整地对应于单词。

257
00:12:48,650 --> 00:12:49,980
因为我们人类用单词来思考，

258
00:12:49,980 --> 00:12:54,180
通过参考小例子和解释每一步可以使这个过程更加容易理解。

259
00:12:54,180 --> 00:12:58,900
模型拥有一个预设的词汇库，包含所有可能的单词，

260
00:12:58,900 --> 00:13:03,340
比如说有 50,000 个。我们将首先遇到的一个矩阵

261
00:13:03,340 --> 00:13:05,190
叫做嵌入矩阵，

262
00:13:05,190 --> 00:13:08,450
它为每个单词都分配了一个独立的列。

263
00:13:08,450 --> 00:13:14,390
这些列定义了第一步中每个单词转换成的向量。

264
00:13:14,390 --> 00:13:18,650
我们将其称为 we，就像我们看到的所有其他矩阵一样，

265
00:13:18,650 --> 00:13:23,530
它的初始值是随机的，但基于数据进行学习和调整。

266
00:13:23,530 --> 00:13:28,530
在 Transformers 出现之前，机器学习中就已经普遍采用了将单词转换为向量的做法，

267
00:13:28,530 --> 00:13:31,120
虽然这对于初次接触的人来说可能有些奇怪，

268
00:13:31,120 --> 00:13:33,550
但它为接下来的一切建立了基础，

269
00:13:33,550 --> 00:13:35,770
因此，我们需要花一些时间来熟悉它。

270
00:13:35,770 --> 00:13:37,560
我们通常称这种转换为词嵌入，

271
00:13:37,560 --> 00:13:40,980
这种表述让你可以从几何的角度去理解这些向量，

272
00:13:40,980 --> 00:13:43,350
把它们想象成高维空间中的点。

273
00:13:43,350 --> 00:13:48,770
将三个数字看作是三维空间中的坐标点很简单，

274
00:13:48,770 --> 00:13:52,400
但词向量的维度远远超出这个范畴。

275
00:13:52,400 --> 00:13:56,960
在 GPT-3 中，它们的维度高达 12,288，如你所见，

276
00:13:56,960 --> 00:14:00,400
选择一个有很多不同方向的空间进行工作是很重要的。

277
00:14:00,400 --> 00:14:04,810
就像你可以在三维空间中选择一个二维切片，

278
00:14:04,810 --> 00:14:07,600
并将所有点投影到这个切片上一样，

279
00:14:07,760 --> 00:14:11,120
为了让简单模型输出的词向量能够被动态展示，

280
00:14:11,120 --> 00:14:16,800
我采取了相似的方法，选择了一个高维空间中的三维“切片”，

281
00:14:16,800 --> 00:14:20,420
并将词向量映射到这个切片上来展示它们。

282
00:14:20,420 --> 00:14:24,850
这里的关键思想是，模型在训练过程中调整和微调权重，

283
00:14:24,850 --> 00:14:29,080
 以确定词具体如何被嵌入为向量，

284
00:14:29,080 --> 00:14:31,000
它会倾向于找到一组嵌入，

285
00:14:31,000 --> 00:14:34,610
使得这个空间中的方向含有特定的语义意义。

286
00:14:34,610 --> 00:14:37,520
对于我目前运行的这个简单的词向量模型来说，

287
00:14:37,520 --> 00:14:42,080
如果进行搜索，找到所有与“塔楼”最相似的词向量，

288
00:14:42,080 --> 00:14:46,220
你会发现这些词都有着类似的“塔楼感”。

289
00:14:46,220 --> 00:14:48,580
如果你想在家里用 Python 试一试，

290
00:14:48,580 --> 00:14:51,570
这就是我用来制作动画的模型。

291
00:14:51,570 --> 00:14:52,790
虽然它不是一个 Transformer 模型，

292
00:14:52,790 --> 00:14:54,680
但足以说明一个观点：

293
00:14:54,680 --> 00:14:58,190
空间中的方向能够传达特定的语义。

294
00:14:58,190 --> 00:15:00,060
一个经典的例子是，

295
00:15:00,060 --> 00:15:03,850
如果你计算“女人”和“男人”向量之间的差值，

296
00:15:03,850 --> 00:15:06,820
你会发现这个差异可以被可视化为空间中的一个小向量，

297
00:15:06,820 --> 00:15:09,600
连接一个词的尖端和另一个词的尖端，

298
00:15:09,600 --> 00:15:13,590
这个差异与“国王”和“女王”之间的差值非常相似。

299
00:15:13,590 --> 00:15:18,020
所以假设你不知道表示“女性君主”的词，

300
00:15:18,020 --> 00:15:22,080
你可以通过向“国王”向量添加“女人减男人”的方向，

301
00:15:22,080 --> 00:15:25,420
并搜索最接近这个点的词向量来找到它。

302
00:15:25,420 --> 00:15:26,980
至少在理论上是这样。

303
00:15:26,980 --> 00:15:31,200
虽然这是我正在使用的模型的一个经典例子，

304
00:15:31,240 --> 00:15:35,300
但实际上，真正的“女王”嵌入实际上比这种方法预想的要远一些，

305
00:15:35,300 --> 00:15:38,390
这可能是因为在训练数据中，

306
00:15:38,390 --> 00:15:40,720
“女王”并不仅仅是“国王”的女性版本。

307
00:15:40,720 --> 00:15:42,580
深入挖掘时，

308
00:15:42,580 --> 00:15:46,200
我发现通过家族关系来解释这一现象似乎更为恰当。

309
00:15:46,200 --> 00:15:48,260
关键在于，在训练过程中，

310
00:15:48,260 --> 00:15:50,770
模型发现采用这样的嵌入方式更为有利，

311
00:15:50,770 --> 00:15:55,410
即这个空间中的一个方向能够编码性别信息。

312
00:15:55,410 --> 00:15:59,210
另一个例子是，如果你从“意大利”的向量表示中

313
00:15:59,210 --> 00:16:01,660
减去“德国”的向量表示，

314
00:16:01,660 --> 00:16:04,800
再加上“希特勒”的向量表示，

315
00:16:04,800 --> 00:16:08,500
结果非常接近于“墨索里尼”的向量表示。

316
00:16:08,500 --> 00:16:13,100
这就好像模型学会了将某些方向与“意大利”特性相关联，

317
00:16:13,100 --> 00:16:15,590
而将其他方向与二战轴心国的领导人相关联。

318
00:16:15,590 --> 00:16:19,410
我个人最喜欢的一个例子是，在某些模型中，

319
00:16:19,410 --> 00:16:23,930
如果你计算“德国”和“日本”的向量差值，然后加上“寿司”的向量，

320
00:16:23,930 --> 00:16:26,290
你得到的结果会非常接近“德国香肠”。

321
00:16:26,290 --> 00:16:29,980
此外，在寻找最近邻居的过程中，

322
00:16:29,980 --> 00:16:33,840
我还惊喜地发现“猫”离“野兽”和“怪物”都很近。

323
00:16:33,840 --> 00:16:37,380
有一个有用的数学概念，

324
00:16:37,380 --> 00:16:38,960
尤其对于接下来的章节非常重要，

325
00:16:38,960 --> 00:16:40,780
那就是两个向量的点积

326
00:16:40,780 --> 00:16:43,680
可以被视为一种衡量它们是否对齐的方法。

327
00:16:43,680 --> 00:16:44,920
从计算角度看，

328
00:16:44,920 --> 00:16:49,120
点积涉及到逐一乘以对应元素，

329
00:16:49,120 --> 00:16:50,440
然后进行求和，

330
00:16:50,440 --> 00:16:54,240
这很好，因为我们的很多计算看起来就像是权重求和。

331
00:16:54,240 --> 00:16:55,400
从几何角度来看，

332
00:16:55,400 --> 00:17:00,240
当两个向量指向相似方向时，点积为正；

333
00:17:00,240 --> 00:17:02,230
如果它们垂直，点积为零；

334
00:17:02,230 --> 00:17:05,520
当它们指向相反方向时，点积为负。

335
00:17:05,520 --> 00:17:06,589
例如，

336
00:17:06,589 --> 00:17:09,230
假设你在测试这个模型，

337
00:17:09,230 --> 00:17:12,970
从“cats”（复数）的向量表示中减去“cat”（单数）的向量表示

338
00:17:12,970 --> 00:17:17,030
可能会在这个空间中找到表示复数概念的方向。

339
00:17:17,030 --> 00:17:17,760
为了验证这个观点，

340
00:17:17,760 --> 00:17:19,210
我将计算某个向量

341
00:17:19,210 --> 00:17:23,020
与一些特定的单数名词嵌入的点积，

342
00:17:23,020 --> 00:17:26,560
并将其与相应的复数名词的点积进行比较。

343
00:17:26,560 --> 00:17:28,030
如果你试一试，

344
00:17:28,030 --> 00:17:29,650
你会发现复数名词的点积值

345
00:17:29,650 --> 00:17:33,670
通常比单数的更高，

346
00:17:33,670 --> 00:17:36,370
这表明它们在某种方向上的对齐更为紧密。

347
00:17:36,370 --> 00:17:38,480
更有趣的是，如果你将这个点积操作

348
00:17:38,480 --> 00:17:41,440
应用到“一”、“二”、“三”等词汇的嵌入上，

349
00:17:41,440 --> 00:17:43,940
会发现得到的数值是逐渐增加的，

350
00:17:43,940 --> 00:17:46,720
就像我们能够量化地衡量

351
00:17:46,720 --> 00:17:48,950
模型认为一个词的"复数程度"。

352
00:17:48,950 --> 00:17:53,640
再次说明，单词的嵌入方式是通过数据学习得到的。

353
00:17:53,640 --> 00:17:57,600
这种嵌入矩阵揭示了每个词汇的变化过程，

354
00:17:57,600 --> 00:18:01,430
它是我们模型中的第一批权重，根据 GPT-3 的数据，

355
00:18:01,430 --> 00:18:05,810
其词汇量具体为 50,257，但要注意，

356
00:18:05,810 --> 00:18:09,760
实际上它指的不是单词本身，而是 Tokens。

357
00:18:10,400 --> 00:18:13,050
嵌入的维度是 12,288。

358
00:18:13,050 --> 00:18:17,910
将这两者相乘，我们得到大约有 6.17 亿个权重。

359
00:18:17,910 --> 00:18:20,050
我们将这个数字加入到我们的累计计数中，

360
00:18:20,050 --> 00:18:23,790
最后，我们应该得到 1750 亿个权重。

361
00:18:23,790 --> 00:18:25,580
在谈到 transformer 时，

362
00:18:25,580 --> 00:18:29,370
你会想到这些嵌入空间中的向量

363
00:18:29,370 --> 00:18:31,960
不仅仅代表着单个词汇。

364
00:18:31,960 --> 00:18:36,170
它们还携带了词汇位置的信息，

365
00:18:36,170 --> 00:18:37,970
这一点我们稍后会详细说明。

366
00:18:37,970 --> 00:18:39,230
但更关键的是，

367
00:18:39,230 --> 00:18:43,340
这些向量能够吸纳并反映语境。

368
00:18:43,340 --> 00:18:47,240
举个例子，一个最初代表“国王”的向量，

369
00:18:47,240 --> 00:18:51,530
在网络中的各个环节的作用下，可能会逐渐变化，

370
00:18:51,530 --> 00:18:55,480
因此最后，它指向的方向会更具体、更微妙，

371
00:18:55,480 --> 00:18:59,200
以某种方式编码了一位生活在苏格兰的国王，

372
00:18:59,200 --> 00:19:02,540
在杀死前任国王后取得其职位的国王，

373
00:19:02,540 --> 00:19:05,360
此人的描绘方式充满了莎士比亚式的语言。

374
00:19:05,360 --> 00:19:07,910
想想你对某个词汇的理解通常是怎样形成的。

375
00:19:07,910 --> 00:19:11,760
那个词的意义很大程度上是由其所处的环境决定的，

376
00:19:11,760 --> 00:19:15,110
有时这甚至包括来自很远的上下文。

377
00:19:15,110 --> 00:19:19,600
因此，在构建一个能预测下一个词汇的模型时，

378
00:19:19,600 --> 00:19:23,970
关键目标就是让它能够高效地融合上下文信息。

379
00:19:23,970 --> 00:19:25,710
明确一点，在第一步，

380
00:19:25,710 --> 00:19:28,480
当我们根据输入文本创建向量数组时，

381
00:19:28,480 --> 00:19:31,810
每个向量都是直接从嵌入矩阵中选取的。

382
00:19:31,810 --> 00:19:34,870
这意味着，起初，每个向量仅能代表一个单词的含义，

383
00:19:34,870 --> 00:19:36,870
而不涉及其周边环境的信息。

384
00:19:36,870 --> 00:19:41,580
但我们的主要目标是让这些向量通过网络传递，

385
00:19:41,580 --> 00:19:49,360
使每一个向量都能获得比单个词更丰富、更具体的含义。

386
00:19:49,360 --> 00:19:52,580
这个网络每次只能处理一定数量的向量，

387
00:19:52,580 --> 00:19:54,230
这就是所谓的上下文大小。

388
00:19:54,230 --> 00:19:57,950
对于 GPT-3，它的训练上下文大小为 2048，

389
00:19:57,950 --> 00:20:00,240
意味着数据在网络中流动时，

390
00:20:00,350 --> 00:20:02,870
总是看起来像一串 2048 列的数组， 

391
00:20:02,870 --> 00:20:05,630
每一列都有 12000 个维度。

392
00:20:05,630 --> 00:20:11,900
这个上下文大小限制了 Transformer 在预测下一个词的过程中可以纳入的文本量。

393
00:20:11,900 --> 00:20:14,880
这就解释了为什么如果和一些聊天机器人

394
00:20:14,880 --> 00:20:16,520
比如 ChatGPT 的早期版本

395
00:20:16,520 --> 00:20:20,710
进行长对话时，你可能会感觉到机器人似乎在对话中迷失了方向，

396
00:20:20,710 --> 00:20:22,070
尤其是当对话持续过长时。

397
00:20:22,070 --> 00:20:26,000
我们会在适当的时候详细讨论注意力机制的细节，

398
00:20:26,000 --> 00:20:29,440
但先让我们简单了解一下最终阶段的处理过程。

399
00:20:29,440 --> 00:20:29,770
请记住，

400
00:20:29,770 --> 00:20:35,210
最终的目标是产生一个概率分布，预测下一个可能出现的 Token。

401
00:20:35,210 --> 00:20:38,320
举例来说，如果最后一个词是“教授”，

402
00:20:38,320 --> 00:20:41,290
上下文中包含了“哈利·波特”等词语，

403
00:20:41,290 --> 00:20:44,800
紧接着出现的是“最不喜欢的老师”，

404
00:20:44,800 --> 00:20:46,050
如果允许我稍微发挥一下，

405
00:20:46,050 --> 00:20:48,970
假设 Tokens 就是完整的单词。

406
00:20:48,970 --> 00:20:52,400
那么，一个经过良好训练并对哈利·波特世界有所了解的网络，

407
00:20:52,400 --> 00:20:55,810
会很可能给“斯内普”这个词赋予一个较高的权重。

408
00:20:55,810 --> 00:20:58,360
此过程涉及两个不同的步骤。

409
00:20:58,360 --> 00:21:00,760
首先，使用另一个矩阵，

410
00:21:00,760 --> 00:21:03,440
将上下文中的最后一个向量映射到

411
00:21:03,440 --> 00:21:05,510
一个包含 50,000 个值的列表，

412
00:21:05,510 --> 00:21:07,570
词汇表中的每个 token 都对应一个值。

413
00:21:07,570 --> 00:21:12,080
接着，通过一个函数，把这些值转换成概率分布。

414
00:21:12,080 --> 00:21:15,410
这个函数叫 softmax，我们稍后会详细讨论。

415
00:21:15,410 --> 00:21:17,910
但在此之前，你可能会觉得，

416
00:21:17,910 --> 00:21:21,070
仅仅基于最后一个嵌入来做出预测似乎有些奇怪，

417
00:21:21,070 --> 00:21:25,340
毕竟在最后一层中还有成千上万的其他向量，

418
00:21:25,340 --> 00:21:28,840
每个向量都蕴含着丰富的上下文意义。

419
00:21:28,840 --> 00:21:31,380
这是因为在训练过程中，

420
00:21:31,380 --> 00:21:40,160
如果我们利用最终层的每一个向量来预测其后可能出现的内容，被证明是更高效的方法。

421
00:21:40,160 --> 00:21:42,740
关于训练的更多细节我们稍后还会提到，

422
00:21:42,740 --> 00:21:45,430
现在先简单指出这一点。

423
00:21:45,430 --> 00:21:50,080
这个矩阵被称为 unembedding 矩阵，我们用标签 Wu 来标记它。

424
00:21:50,080 --> 00:21:53,830
就像我们见过的所有权重矩阵一样，这个矩阵的初始值是随机的，

425
00:21:53,830 --> 00:21:56,430
但在训练过程中，这些值会被更新。

426
00:21:56,430 --> 00:21:58,150
关于参数总数的统计，

427
00:21:58,150 --> 00:22:01,950
这个 unembedding 矩阵为词汇表中的每个单词都分配了一行，

428
00:22:01,950 --> 00:22:05,940
每一行包含与嵌入维度相同数量的元素。

429
00:22:05,940 --> 00:22:09,440
这与嵌入（embedding）矩阵非常相似，只不过是把顺序倒过来了，

430
00:22:09,440 --> 00:22:13,130
因此它为网络增加了另外 6.17 亿个参数。

431
00:22:13,130 --> 00:22:15,920
到目前为止，我们的参数总数已经超过了 10 亿，

432
00:22:15,920 --> 00:22:21,970
这只是我们最终要达到的 1750 亿的一小部分。

433
00:22:21,970 --> 00:22:24,430
在这一章的最后一个小课中，

434
00:22:24,430 --> 00:22:26,920
我想更详细地讨论一下 softmax 函数，

435
00:22:26,920 --> 00:22:30,560
因为它在我们探索注意力机制时会再次成为焦点。

436
00:22:30,560 --> 00:22:36,160
如果你想让一串数字成为概率分布，

437
00:22:36,310 --> 00:22:38,980
比如预测下一个可能出现的词的概率，

438
00:22:38,980 --> 00:22:41,600
那么这些数字每个都得在 0 到 1 之间，

439
00:22:41,600 --> 00:22:44,560
并且加起来总和为 1。

440
00:22:44,560 --> 00:22:45,920
但是，

441
00:22:45,920 --> 00:22:47,680
如果你正在进行深度学习的实践，

442
00:22:47,680 --> 00:22:50,640
你所做的每一步操作都可能看起来像是矩阵和向量的乘法，

443
00:22:50,640 --> 00:22:54,650
那么你得到的结果可能并不符合这个条件。

444
00:22:54,650 --> 00:22:57,920
这些值可能是负的，也可能远大于 1，

445
00:22:57,920 --> 00:23:00,460
而且加起来的和几乎确定不会是 1。

446
00:23:00,460 --> 00:23:01,690
Softmax 就是一种标准方法，

447
00:23:01,690 --> 00:23:05,330
可以把任何一组数字转换成一个有效的分布，

448
00:23:05,330 --> 00:23:09,120
使得最大的数值非常接近 1，

449
00:23:09,120 --> 00:23:11,240
而较小的值将会非常接近 0。

450
00:23:11,240 --> 00:23:13,210
了解这一点就足够了。

451
00:23:13,210 --> 00:23:14,080
但如果你感到好奇，

452
00:23:14,080 --> 00:23:18,720
具体的工作原理是：首先对每个数值进行 e 的指数运算，

453
00:23:18,720 --> 00:23:21,280
这样就得到了一组正数；

454
00:23:21,280 --> 00:23:24,470
然后取所有正数的和，

455
00:23:24,470 --> 00:23:26,710
然后用每个数除以这个总和，

456
00:23:26,710 --> 00:23:29,620
这样就把它们标准化为一个总和为 1 的列表。

457
00:23:29,620 --> 00:23:32,450
你会注意到，如果输入中的某个数值

458
00:23:32,450 --> 00:23:34,490
明显大于其他数值，

459
00:23:34,490 --> 00:23:38,000
那么在输出中，这个数值对应的项就会在分布中占主导地位，

460
00:23:38,000 --> 00:23:42,990
几乎确定你在采样时会选择这个最大的输入值。

461
00:23:42,990 --> 00:23:45,210
但这种方法比直接挑选最大值更为细腻，

462
00:23:45,210 --> 00:23:48,100
因为当其他数值也接近最大值时，

463
00:23:48,100 --> 00:23:51,120
它们在整体分布中同样能获得重要的比重，

464
00:23:51,120 --> 00:23:52,870
而且随着你不断改变输入，

465
00:23:52,870 --> 00:23:54,980
一切都会连续地变化。

466
00:23:54,980 --> 00:23:55,940
在一些情况下，

467
00:23:55,940 --> 00:23:59,690
比如当 ChatGPT 利用这个分布生成下一个单词时，

468
00:23:59,690 --> 00:24:01,980
可以为这个函数增加一些趣味性，

469
00:24:01,980 --> 00:24:09,180
可以通过在指数的分母里添加一个常量 t 来实现。 

470
00:24:09,180 --> 00:24:10,550
我们称之为“温度”，

471
00:24:10,550 --> 00:24:15,300
因其在某种程度上与热力学方程中温度的作用相似。

472
00:24:15,300 --> 00:24:17,760
它的效果是，当 t 值较大时，

473
00:24:17,760 --> 00:24:19,770
会使较小的数值获得更多的权重，

474
00:24:19,770 --> 00:24:24,250
使得分布稍微均匀一些。而如果 t 值较小，

475
00:24:24,250 --> 00:24:28,330
则较大的数值则会更加明显地占据主导，极端情况下，

476
00:24:28,330 --> 00:24:32,640
如果把 t 设为 0，那么所有的权重都会集中在最大的值上。

477
00:24:32,640 --> 00:24:33,690
例如，

478
00:24:33,690 --> 00:24:36,200
我将用 GPT-3 生成一个故事

479
00:24:36,200 --> 00:24:39,600
种子文本是"从前，有一个 A"

480
00:24:39,600 --> 00:24:42,750
但我会在每次测试中使用不同的温度。

481
00:24:42,750 --> 00:24:48,400
温度为 0 意味着它总是选择最可预测的词，

482
00:24:48,400 --> 00:24:52,320
而你所得到的结果就变成了一个陈词滥调的金发姑娘故事。

483
00:24:52,940 --> 00:24:56,640
较高的温度给它提供了选择不太可能出现的词的机会，

484
00:24:56,640 --> 00:24:57,920
但这也伴随着风险。

485
00:24:57,920 --> 00:25:00,800
在这个例子中，故事的开始部分较为原创，

486
00:25:00,800 --> 00:25:03,530
讲述的是韩国的一位年轻网页艺术家，

487
00:25:03,530 --> 00:25:06,000
但很快就变得毫无意义。

488
00:25:06,000 --> 00:25:07,310
严格地说，

489
00:25:07,310 --> 00:25:11,040
API 实际上并不允许你选择大于 2 的温度。

490
00:25:11,040 --> 00:25:12,950
这个限制并没有数学上的根据，

491
00:25:12,950 --> 00:25:15,710
只是一个人为的限制，我猜，

492
00:25:15,710 --> 00:25:19,680
目的是为了防止他们的工具产生太过荒诞的结果。

493
00:25:19,780 --> 00:25:20,770
所以，如果你感到好奇，

494
00:25:20,770 --> 00:25:22,800
这个动画的工作原理是这样的：

495
00:25:22,800 --> 00:25:26,510
我选择了 GPT-3 生成的可能性最高的前 20 个 Token，

496
00:25:26,510 --> 00:25:29,360
这看起来是他们能给我的最多的数量。

497
00:25:29,360 --> 00:25:32,480
然后，我会根据 1/5 的指数来调整这些概率。

498
00:25:32,480 --> 00:25:33,850
再给你介绍一个专业术语，

499
00:25:33,850 --> 00:25:39,180
在这个上下文中，我们通常把这个函数的输出成分称作概率，

500
00:25:39,180 --> 00:25:43,630
人们通常将输入称为 logits，有的人说 logits，

501
00:25:43,630 --> 00:25:46,320
有的人说 logits，我选择说 logits。

502
00:25:46,410 --> 00:25:48,030
举个例子，当你输入一段文本时，

503
00:25:48,030 --> 00:25:50,420
所有这些词向量就会通过网络流动，

504
00:25:50,420 --> 00:25:53,990
并与 unembedding 矩阵进行最终的乘法运算。

505
00:25:53,990 --> 00:25:57,520
机器学习专家会把这种原始、

506
00:25:57,520 --> 00:26:01,360
未标准化的输出成分称为下一个词预测的 logits。

507
00:26:01,360 --> 00:26:04,880
这一章的主要目标是

508
00:26:04,880 --> 00:26:08,480
为理解注意力机制打下基础，

509
00:26:08,480 --> 00:26:10,850
就像电影《龙威小子》里的基本功训练“上蜡刮蜡”。

510
00:26:10,850 --> 00:26:14,890
你看，如果你对词嵌入、softmax 有深入的理解，

511
00:26:14,890 --> 00:26:17,530
点积如何衡量相似度，

512
00:26:17,530 --> 00:26:25,140
以及大部分计算看起来都像是填满可调参数的矩阵乘法有着深刻的理解，

513
00:26:25,140 --> 00:26:27,690
那么掌握注意力机制——

514
00:26:27,690 --> 00:26:30,730
现代 AI 浪潮中的关键技术，

515
00:26:30,730 --> 00:26:32,640
对你来说应该会比较容易。

516
00:26:32,640 --> 00:26:34,400
为此，欢迎在下一章中加入我。

517
00:26:34,400 --> 00:26:36,570
发布这篇文章时，

518
00:26:36,570 --> 00:26:41,540
下一章的草稿已经可以供赞助者审阅。

519
00:26:41,540 --> 00:26:44,240
最终版应该在一两周内公开。

520
00:26:44,240 --> 00:26:47,610
这通常取决于我根据审阅结果做出的修改有多大。

521
00:26:47,610 --> 00:26:50,080
与此同时，如果你想深入研究注意力机制，

522
00:26:50,080 --> 00:26:52,720
如果你想帮助这个频道，那么它就在那里等你。
