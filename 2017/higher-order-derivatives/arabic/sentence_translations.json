[
 {
  "input": "In the next chapter about Taylor series, I make frequent reference to higher order derivatives. ",
  "translatedText": "في الفصل التالي عن متسلسلة تايلور، سأشير بشكل متكرر إلى المشتقات ذات الرتبة الأعلى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 4.02,
  "end": 9.46
 },
 {
  "input": "And if you're already comfortable with second derivatives, third derivatives, and so on, great! ",
  "translatedText": "وإذا كنت مرتاحًا بالفعل للمشتقات الثانية، والمشتقات الثالثة، وما إلى ذلك، فهذا رائع! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.1,
  "end": 13.98
 },
 {
  "input": "Feel free to just skip ahead to the main event now. ",
  "translatedText": "لا تتردد في الانتقال إلى الحدث الرئيسي الآن. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.42,
  "end": 16.66
 },
 {
  "input": "You won't hurt my feelings. ",
  "translatedText": "أنت لن تؤذي مشاعري. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 16.88,
  "end": 17.8
 },
 {
  "input": "But somehow, I've managed not to bring up higher order derivatives at all so far in this series. ",
  "translatedText": "لكن بطريقة ما، تمكنت من عدم ذكر مشتقات ذات ترتيب أعلى على الإطلاق حتى الآن في هذه السلسلة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.96,
  "end": 24.02
 },
 {
  "input": "So for the sake of completeness, I thought I'd give you this little footnote just to go over them very quickly. ",
  "translatedText": "لذا، ومن أجل الاكتمال، فكرت في أن أعطيكم هذه الحاشية الصغيرة لاستعراضها بسرعة كبيرة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 24.52,
  "end": 29.08
 },
 {
  "input": "I'll focus mainly on the second derivative, showing what it looks like in the context of graphs and motion, and leave you to think about the analogies for higher orders. ",
  "translatedText": "سأركز بشكل أساسي على المشتق الثاني، موضحًا كيف يبدو في سياق الرسوم البيانية والحركة، وأترك لك التفكير في أوجه التشابه مع الطلبات الأعلى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 29.64,
  "end": 38.56
 },
 {
  "input": "Given some function f of x, the derivative can be interpreted as the slope of this graph above some point, right? ",
  "translatedText": "بالنظر إلى بعض الوظائف f لـ x، يمكن تفسير المشتق على أنه ميل هذا الرسم البياني فوق نقطة ما، أليس كذلك؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 40.1,
  "end": 47.18
 },
 {
  "input": "A steep slope means a high value for the derivative, a downward slope means a negative derivative. ",
  "translatedText": "المنحدر الحاد يعني قيمة عالية للمشتق، والمنحدر الهبوطي يعني مشتق سلبي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.76,
  "end": 52.46
 },
 {
  "input": "So the second derivative, whose notation I'll explain in just a moment, is the derivative of the derivative, meaning it tells you how that slope is changing. ",
  "translatedText": "لذا فإن المشتقة الثانية، التي سأشرح ترميزها بعد قليل، هي مشتقة المشتقة، مما يعني أنها تخبرك بكيفية تغير هذا الميل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.24,
  "end": 62.26
 },
 {
  "input": "The way to see that at a glance is to think about how the graph of f of x curves. ",
  "translatedText": "طريقة رؤية ذلك بنظرة سريعة هي التفكير في كيفية منحنيات الرسم البياني لـ f لـ x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 63.28,
  "end": 67.46
 },
 {
  "input": "At points where it curves upwards, the slope is increasing, and that means the second derivative is positive. ",
  "translatedText": "وعند النقاط التي ينحني فيها لأعلى، يزداد الميل، وهذا يعني أن المشتقة الثانية تكون موجبة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.14,
  "end": 75.2
 },
 {
  "input": "At points where it's curving downwards, the slope is decreasing, so the second derivative is negative. ",
  "translatedText": "عند النقاط التي ينحني فيها للأسفل، يتناقص الميل، وبالتالي تكون المشتقة الثانية سالبة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 77.8,
  "end": 83.06
 },
 {
  "input": "For example, a graph like this one has a very positive second derivative at the point 4, since the slope is rapidly increasing around that point, whereas a graph like this one still has a positive second derivative at the same point, but it's smaller, the slope only increases slowly. ",
  "translatedText": "على سبيل المثال، رسم بياني مثل هذا له مشتق ثانٍ موجب جدًا عند النقطة 4، نظرًا لأن الميل يتزايد بسرعة حول تلك النقطة، في حين أن رسمًا بيانيًا مثل هذا لا يزال به مشتق ثانٍ موجب عند نفس النقطة، لكنه أصغر. المنحدر يزداد ببطء فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 86.0,
  "end": 105.64
 },
 {
  "input": "At points where there's not really any curvature, the second derivative is just 0. ",
  "translatedText": "في النقاط التي لا يوجد فيها أي انحناء، تكون قيمة المشتقة الثانية 0 فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.5,
  "end": 110.9
 },
 {
  "input": "As far as notation goes, you could try writing it like this, indicating some small change to the derivative function, divided by some small change to x, where as always the use of this letter d suggests that what you really want to consider is what this ratio approaches as dx, both dx's in this case, approach 0. ",
  "translatedText": "فيما يتعلق بالترميز، يمكنك محاولة كتابته على هذا النحو، للإشارة إلى بعض التغيير الطفيف في الدالة المشتقة، مقسومًا على بعض التغيير الطفيف في x، حيث يشير استخدام هذا الحرف d، كما هو الحال دائمًا، إلى أن ما تريد حقًا أخذه في الاعتبار هو ما تقترب هذه النسبة من dx، وكلا dx في هذه الحالة يقترب من 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.38,
  "end": 134.44
 },
 {
  "input": "That's pretty awkward and clunky, so the standard is to abbreviate this as d squared f divided by dx squared. ",
  "translatedText": "هذا أمر غريب ومعقد جدًا، لذا فإن المعيار هو اختصاره إلى d تربيع f مقسومًا على dx تربيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 135.54,
  "end": 143.18
 },
 {
  "input": "And even though it's not terribly important for getting an intuition for the second derivative, I think it might be worth showing you how you can read this notation. ",
  "translatedText": "وعلى الرغم من أنه ليس مهمًا للغاية للحصول على حدس للمشتق الثاني، أعتقد أنه قد يكون من المفيد أن أوضح لك كيف يمكنك قراءة هذا الترميز. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.36,
  "end": 152.5
 },
 {
  "input": "To start off, think of some input to your function, and then take two small steps to the right, each one with a size of dx. ",
  "translatedText": "للبدء، فكر في بعض المدخلات لوظيفتك، ثم اتخذ خطوتين صغيرتين إلى اليمين، كل واحدة بحجم dx. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.16,
  "end": 160.86
 },
 {
  "input": "I'm choosing rather big steps here so we'll be able to see what's going on, but in principle keep in the back of your mind that dx should be rather tiny. ",
  "translatedText": "أختار خطوات كبيرة إلى حد ما هنا حتى نتمكن من رؤية ما يحدث، ولكن من حيث المبدأ ضع في اعتبارك أن dx يجب أن يكون صغيرًا إلى حد ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 162.0,
  "end": 169.68
 },
 {
  "input": "The first step causes some change to the function, which I'll call df1, and the second step causes some similar but possibly slightly different change, which I'll call df2. ",
  "translatedText": "تسبب الخطوة الأولى بعض التغيير في الوظيفة، والتي سأسميها df1، والخطوة الثانية تسبب بعض التغييرات المشابهة ولكن ربما تكون مختلفة قليلاً، والتي سأسميها df2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 170.9,
  "end": 182.48
 },
 {
  "input": "The difference between these changes, the change in how the function changes, is what we'll call ddf. ",
  "translatedText": "الفرق بين هذه التغييرات، التغيير في كيفية تغير الوظيفة، هو ما سنسميه ddf. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.33,
  "end": 190.66
 },
 {
  "input": "You should think of this as really small, typically proportional to the size of dx squared, so if you substituted in 0.01 for dx, you would expect this ddf to be about proportional to 0.0001, and the second derivative is the size of this change to the change divided by the size of dx squared, or more precisely, whatever that ratio approaches as dx approaches 0. ",
  "translatedText": "يجب أن تفكر في هذا على أنه صغير حقًا، ويتناسب عادةً مع حجم dx تربيع، لذلك إذا استبدلت بـ 0.01 بالنسبة إلى dx، تتوقع أن يكون ddf متناسبًا تقريبًا مع 0.0001، والمشتق الثاني هو حجم هذا التغير في التغير مقسومًا على حجم dx تربيع، أو بشكل أكثر دقة، مهما كانت تلك النسبة تقترب عندما يقترب dx من 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 192.02,
  "end": 221.64
 },
 {
  "input": "Even though it's not like this letter d is a variable being multiplied by f, for the sake of more compact notation you'd write it as d2f divided by dx2, and you don't typically bother with any parentheses on the bottom. ",
  "translatedText": "على الرغم من أن هذا الحرف d ليس متغيرًا يتم ضربه في f، إلا أنه من أجل تدوين أكثر إحكامًا، يمكنك كتابته بالشكل d2f مقسومًا على dx2، ولا تهتم عادةً بأي قوسين في الأسفل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.0,
  "end": 237.78
 },
 {
  "input": "Maybe the most visceral understanding of the second derivative is that it represents acceleration. ",
  "translatedText": "ربما يكون الفهم الأكثر عمقًا للمشتق الثاني هو أنه يمثل التسارع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 239.04,
  "end": 244.24
 },
 {
  "input": "Given some movement along a line, suppose you have some function that records the distance traveled versus time, maybe its graph looks like this, steadily increasing over time. ",
  "translatedText": "بالنظر إلى بعض الحركة على طول الخط، لنفترض أن لديك وظيفة ما تسجل المسافة المقطوعة مقابل الوقت، ربما يبدو الرسم البياني الخاص بها هكذا، ويتزايد بشكل مطرد بمرور الوقت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 245.18,
  "end": 255.82
 },
 {
  "input": "Then its derivative tells you velocity at each point in time, for example the graph might look like this bump, increasing up to some maximum, and decreasing back to zero. ",
  "translatedText": "ثم يخبرك مشتقها بالسرعة عند كل نقطة زمنية، على سبيل المثال، قد يبدو الرسم البياني مثل هذا النتوء، حيث يزيد إلى الحد الأقصى، ثم يتناقص مرة أخرى إلى الصفر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 256.74,
  "end": 266.3
 },
 {
  "input": "So the second derivative tells you the rate of change for the velocity, which is the acceleration at each point in time. ",
  "translatedText": "إذن، تخبرك المشتقة الثانية بمعدل تغير السرعة، وهو التسارع عند كل نقطة زمنية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 267.2,
  "end": 273.9
 },
 {
  "input": "In this example, the second derivative is positive for the first half of the journey, which indicates speeding up, that's the sensation of being pushed back into your car seat, or rather, having the car seat push you forward. ",
  "translatedText": "في هذا المثال، يكون المشتق الثاني موجبًا للنصف الأول من الرحلة، وهو ما يشير إلى السرعة، وهو الإحساس بأنك تُدفع للخلف إلى مقعد السيارة، أو بالأحرى، أن مقعد السيارة يدفعك للأمام. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.92,
  "end": 286.82
 },
 {
  "input": "A negative second derivative indicates slowing down, negative acceleration. ",
  "translatedText": "يشير المشتق الثاني السلبي إلى التباطؤ والتسارع السلبي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 287.54,
  "end": 292.52
 },
 {
  "input": "The third derivative, and this is not a joke, is called jerk. ",
  "translatedText": "المشتق الثالث، وهذه ليست مزحة، يسمى رعشة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.0,
  "end": 297.08
 },
 {
  "input": "So if the jerk is not zero, it means that the strength of the acceleration itself is changing. ",
  "translatedText": "فإذا لم تكن الرعشة صفرًا، فهذا يعني أن قوة التسارع نفسها تتغير. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.84,
  "end": 303.92
 },
 {
  "input": "One of the most useful things about higher order derivatives is how they help us in approximating functions, which is exactly the topic of the next chapter on Taylor series, so I'll see you there. ",
  "translatedText": "واحدة من أكثر الأشياء المفيدة حول المشتقات ذات الرتبة الأعلى هي كيف أنها تساعدنا في تقريب الدوال، وهو بالضبط موضوع الفصل التالي عن متسلسلة تايلور، لذلك أراكم هناك.  ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.28,
  "end": 316.62
 }
]