1
00:00:04,020 --> 00:00:09,920
ההנחה הקשה כאן היא שצפיתם בחלק 3, מה שנותן הדרכה אינטואיטיבית של אלגוריתם ההפצה לאחור.

2
00:00:11,040 --> 00:00:14,220
כאן נהיה קצת יותר פורמליים וצוללים לתוך החשבון הרלוונטי.

3
00:00:14,820 --> 00:00:21,400
זה נורמלי שזה לפחות קצת מבלבל, אז המנטרה לעצור ולהרהר באופן קבוע חלה כאן כמו בכל מקום אחר.

4
00:00:21,940 --> 00:00:27,653
המטרה העיקרית שלנו היא להראות כיצד אנשים בלימוד מכונה בדרך כלל חושבים על כלל השרשרת 

5
00:00:27,653 --> 00:00:33,640
מחשבון בהקשר של רשתות, שיש לו תחושה שונה מהאופן שבו רוב קורסי החישוב המבוא ניגשים לנושא.

6
00:00:34,340 --> 00:00:38,740
לאלו מכם שלא מרגישים בנוח עם החשבון הרלוונטי, יש לי סדרה שלמה בנושא.

7
00:00:39,960 --> 00:00:46,020
נתחיל עם רשת פשוטה ביותר, כזו שבה בכל שכבה יש נוירון בודד.

8
00:00:46,320 --> 00:00:50,520
רשת זו נקבעת על ידי שלושה משקלים ושלוש הטיות, והמטרה 

9
00:00:50,520 --> 00:00:54,880
שלנו היא להבין עד כמה פונקציית העלות רגישה למשתנים אלו.

10
00:00:55,419 --> 00:01:02,320
כך אנו יודעים אילו התאמות למונחים אלו יגרמו לירידה היעילה ביותר בפונקציית העלות.

11
00:01:02,320 --> 00:01:04,840
אנחנו רק נתמקד בקשר בין שני הנוירונים האחרונים.

12
00:01:05,980 --> 00:01:11,360
בוא נסמן את ההפעלה של הנוירון האחרון הזה עם L, המציין באיזו שכבה הוא נמצא.

13
00:01:11,680 --> 00:01:15,560
אז ההפעלה של הנוירון הקודם היא AL-1.

14
00:01:16,360 --> 00:01:20,218
אלה לא מעריכים, הם רק דרך להוסיף לאינדקס את מה שאנחנו מדברים עליו, 

15
00:01:20,218 --> 00:01:23,040
מכיוון שאני רוצה לשמור מנויים למדדים שונים בהמשך.

16
00:01:23,720 --> 00:01:29,857
נניח שהערך שאנו רוצים שההפעלה האחרונה תהיה עבור דוגמה לאימון נתונה הוא y, 

17
00:01:29,857 --> 00:01:32,180
לדוגמה, y עשוי להיות 0 או 1.

18
00:01:32,840 --> 00:01:39,240
אז העלות של רשת זו עבור דוגמה אחת לאימון היא AL-y2.

19
00:01:40,260 --> 00:01:44,380
נסמן את העלות של דוגמה אחת לאימון כ-c0.

20
00:01:45,900 --> 00:01:51,750
להזכירך, ההפעלה האחרונה הזו נקבעת על ידי משקל, שאקרא לו wL, 

21
00:01:51,750 --> 00:01:57,600
כפול ההפעלה של הנוירון הקודם פלוס הטיה כלשהי, שאכנה אותה bL.

22
00:01:57,600 --> 00:02:01,320
ואז אתה שואב את זה דרך איזו פונקציה לא ליניארית מיוחדת כמו הסיגמואיד או ReLU.

23
00:02:01,800 --> 00:02:05,928
למעשה, זה יקל עלינו אם ניתן שם מיוחד לסכום המשוקלל הזה, 

24
00:02:05,928 --> 00:02:09,320
כמו z, עם אותו כתב עילית כמו ההפעלה הרלוונטית.

25
00:02:10,380 --> 00:02:15,221
זה הרבה מונחים, ודרך שבה אתה יכול להמשיג את זה היא שהמשקל, 

26
00:02:15,221 --> 00:02:21,048
הפעולה הקודמת וההטיה ביחד משמשים לחישוב z, שבתורו מאפשר לנו לחשב את a, 

27
00:02:21,048 --> 00:02:25,480
אשר לבסוף, יחד עם y קבוע, מאפשר אנחנו מחשבים את העלות.

28
00:02:27,340 --> 00:02:35,060
וכמובן, AL-1 מושפע מהמשקל שלו ומההטיה שלו וכאלה, אבל אנחנו לא מתכוונים להתמקד בזה עכשיו.

29
00:02:35,700 --> 00:02:37,620
כל אלה הם רק מספרים, נכון?

30
00:02:38,060 --> 00:02:41,040
וזה יכול להיות נחמד לחשוב שלכל אחד מהם יש שורת מספרים קטנה משלו.

31
00:02:41,720 --> 00:02:49,000
המטרה הראשונה שלנו היא להבין עד כמה רגישה פונקציית העלות לשינויים קטנים במשקל שלנו wL.

32
00:02:49,540 --> 00:02:54,860
או לנסח אחרת, מהי הנגזרת של c ביחס ל-wL?

33
00:02:55,600 --> 00:03:01,570
כשאתה רואה את המונח del w הזה, תחשוב על זה כעל איזה דחיפה זעירה ל-w, 

34
00:03:01,570 --> 00:03:08,060
כמו שינוי ב-0.01, וחשבו על המונח Del c הזה כמשמעותי מה הדחיפה שתתקבל לעלות.

35
00:03:08,060 --> 00:03:10,220
מה שאנחנו רוצים זה היחס שלהם.

36
00:03:11,260 --> 00:03:16,367
מבחינה קונספטואלית, דחיפה זעירה זו ל-wL גורמת לדחיפה כלשהי ל-zL, 

37
00:03:16,367 --> 00:03:21,240
אשר בתורה גורמת לדחיפה כלשהי ל-AL, אשר משפיעה ישירות על העלות.

38
00:03:23,120 --> 00:03:28,322
אז אנחנו מפרקים את הדברים על ידי הסתכלות תחילה על היחס של שינוי 

39
00:03:28,322 --> 00:03:33,200
זעיר ל-zL לשינוי הזעיר הזה w, כלומר, הנגזרת של zL ביחס ל-wL.

40
00:03:33,200 --> 00:03:39,218
באופן דומה, אתה מחשיב את היחס בין השינוי ל-AL לשינוי הזעיר ב-zL שגרם לו, 

41
00:03:39,218 --> 00:03:44,660
כמו גם את היחס בין הדחיפה הסופי ל-c לבין הדחיפה הבינונית הזו ל-AL.

42
00:03:45,740 --> 00:03:50,393
זה ממש כאן הוא כלל השרשרת, שבו הכפלת שלושת היחסים 

43
00:03:50,393 --> 00:03:55,140
הללו נותנת לנו את הרגישות של c לשינויים קטנים ב-wL.

44
00:03:56,880 --> 00:04:02,418
אז על המסך כרגע, יש הרבה סמלים, וקח רגע כדי לוודא שזה ברור מה הם כולם, 

45
00:04:02,418 --> 00:04:06,240
כי עכשיו אנחנו הולכים לחשב את הנגזרות הרלוונטיות.

46
00:04:07,440 --> 00:04:14,180
הנגזרת של c ביחס ל-AL מתבררת להיות 2AL-y.

47
00:04:14,180 --> 00:04:18,430
המשמעות היא שהגודל שלו פרופורציונלי להבדל בין התפוקה של הרשת 

48
00:04:18,430 --> 00:04:22,959
לבין הדבר שאנחנו רוצים שהיא תהיה, כך שאם הפלט הזה היה שונה מאוד, 

49
00:04:22,959 --> 00:04:27,140
אפילו לשינויים קלים יש השפעה גדולה על פונקציית העלות הסופית.

50
00:04:27,840 --> 00:04:34,195
הנגזרת של AL ביחס ל-zL היא רק הנגזרת של הפונקציה הסיגמואידית שלנו, 

51
00:04:34,195 --> 00:04:37,420
או כל אי-לינאריות שתבחר להשתמש בה.

52
00:04:37,420 --> 00:04:46,160
הנגזרת של zL ביחס ל-wL יוצאת AL-1.

53
00:04:46,160 --> 00:04:49,790
אני לא יודע מה איתכם, אבל אני חושב שקל להיתקע עם ראש למטה 

54
00:04:49,790 --> 00:04:53,420
בנוסחאות מבלי לקחת רגע לשבת ולהזכיר לעצמכם מה כולן אומרות.

55
00:04:53,920 --> 00:04:58,608
במקרה של נגזרת אחרונה זו, הכמות שהדחיפה הקטנה למשקל השפיעה 

56
00:04:58,608 --> 00:05:02,820
על השכבה האחרונה תלויה במידת העוצמה של הנוירון הקודם.

57
00:05:03,380 --> 00:05:08,280
זכרו, כאן נכנס הרעיון של נוירונים-שה-יורים-ביחד-חווט-יחד.

58
00:05:09,200 --> 00:05:15,720
וכל זה הוא הנגזרת ביחס ל-wL בלבד של העלות עבור דוגמה ספציפית לאימון בודד.

59
00:05:16,440 --> 00:05:22,190
מכיוון שפונקציית העלות המלאה כוללת ממוצע של כל העלויות הללו על פני הרבה 

60
00:05:22,190 --> 00:05:28,660
דוגמאות אימון שונות, הנגזרת שלה דורשת ממוצע של ביטוי זה על פני כל דוגמאות ההדרכה.

61
00:05:28,660 --> 00:05:33,712
כמובן, זה רק מרכיב אחד של וקטור הגרדיאנט, אשר בנוי מהנגזרות 

62
00:05:33,712 --> 00:05:38,260
החלקיות של פונקציית העלות ביחס לכל אותם משקלים והטיות.

63
00:05:40,640 --> 00:05:45,260
אבל למרות שזו רק אחת מהנגזרות החלקיות הרבות שאנחנו צריכים, זה יותר מ-50% מהעבודה.

64
00:05:46,340 --> 00:05:49,720
הרגישות להטיה, למשל, כמעט זהה.

65
00:05:50,040 --> 00:05:55,020
אנחנו רק צריכים לשנות את המונח del z del w עבור a del z del b.

66
00:05:58,420 --> 00:06:02,400
ואם אתה מסתכל על הנוסחה הרלוונטית, הנגזרת הזו יוצאת כ-1.

67
00:06:06,140 --> 00:06:11,030
כמו כן, וכאן נכנס הרעיון של התפשטות לאחור, ניתן לראות 

68
00:06:11,030 --> 00:06:15,740
עד כמה פונקציית העלות הזו רגישה להפעלת השכבה הקודמת.

69
00:06:15,740 --> 00:06:25,660
כלומר, הנגזרת הראשונית הזו בביטוי כלל השרשרת, הרגישות של z להפעלה הקודמת, יוצאת כמשקל wL.

70
00:06:26,640 --> 00:06:32,385
ושוב, למרות שלא נוכל להשפיע ישירות על הפעלת השכבה הקודמת, זה מועיל לעקוב אחריה, 

71
00:06:32,385 --> 00:06:37,556
כי עכשיו אנחנו יכולים פשוט להמשיך ולחזור על אותו רעיון כללי שרשרת לאחור 

72
00:06:37,556 --> 00:06:42,440
כדי לראות עד כמה רגישה פונקציית העלות ל משקלים קודמים והטיות קודמות.

73
00:06:43,180 --> 00:06:47,189
ואולי תחשבו שזו דוגמה פשוטה מדי, מכיוון שלכל השכבות יש נוירון אחד, 

74
00:06:47,189 --> 00:06:51,020
והדברים הולכים להיות מסובכים באופן אקספוננציאלי עבור רשת אמיתית.

75
00:06:51,700 --> 00:06:56,008
אבל בכנות, לא כל כך הרבה משתנה כשאנחנו נותנים לשכבות מספר נוירונים, 

76
00:06:56,008 --> 00:06:58,860
באמת שיש רק עוד כמה מדדים שצריך לעקוב אחריהם.

77
00:06:59,380 --> 00:07:07,160
במקום שההפעלה של שכבה נתונה פשוט תהיה AL, יהיה לה גם מנוי שמציין באיזה נוירון בשכבה זו.

78
00:07:07,160 --> 00:07:14,420
בוא נשתמש באות k כדי לאינדקס את השכבה L-1, וב-j כדי להוסיף את השכבה L.

79
00:07:15,260 --> 00:07:20,021
לגבי העלות, שוב אנו מסתכלים מהי הפלט הרצוי, אך הפעם נחבר את 

80
00:07:20,021 --> 00:07:25,180
הריבועים של ההבדלים בין הפעלת השכבה האחרונה הללו לבין הפלט הרצוי.

81
00:07:26,080 --> 00:07:30,840
כלומר, אתה לוקח סכום מעל ALj מינוס yj בריבוע.

82
00:07:33,040 --> 00:07:38,943
מכיוון שיש הרבה יותר משקלים, לכל אחד צריך להיות עוד כמה מדדים כדי לעקוב אחר היכן 

83
00:07:38,943 --> 00:07:44,920
הוא נמצא, אז בואו נקרא למשקל הקצה המחבר את הנוירון ה-k הזה לנוירון ה-j', WLjk.

84
00:07:45,620 --> 00:07:49,278
המדדים האלה אולי מרגישים קצת לאחור בהתחלה, אבל הם תואמים את 

85
00:07:49,278 --> 00:07:53,120
האופן שבו היית מוסיף את מטריצת המשקל שעליה דיברתי בסרטון חלק 1.

86
00:07:53,620 --> 00:07:58,168
ממש כמו קודם, עדיין נחמד לתת שם לסכום המשוקלל הרלוונטי, כמו z, 

87
00:07:58,168 --> 00:08:04,160
כך שההפעלה של השכבה האחרונה היא רק הפונקציה המיוחדת שלך, כמו הסיגמואיד, המוחל על z.

88
00:08:04,660 --> 00:08:09,170
אתה יכול לראות למה אני מתכוון, כאשר כל אלה הם בעצם אותן משוואות 

89
00:08:09,170 --> 00:08:13,680
שהיו לנו קודם במקרה של נוירון-לשכבה, רק שזה נראה קצת יותר מסובך.

90
00:08:15,440 --> 00:08:23,420
ואכן, הביטוי הנגזר של כלל השרשרת המתאר עד כמה העלות רגישה למשקל ספציפי נראה זהה בעצם.

91
00:08:23,920 --> 00:08:26,840
אני אשאיר לך לעצור ולחשוב על כל אחד מהמונחים האלה אם תרצה.

92
00:08:28,979 --> 00:08:36,659
מה שכן משתנה כאן הוא הנגזרת של העלות ביחס לאחת ההפעלה בשכבה L-1.

93
00:08:37,780 --> 00:08:42,880
במקרה זה, ההבדל הוא שהנוירון משפיע על תפקוד העלות דרך מספר נתיבים שונים.

94
00:08:44,680 --> 00:08:50,334
כלומר, מצד אחד, זה משפיע על AL0, שמשחק תפקיד בפונקציית העלות, 

95
00:08:50,334 --> 00:08:57,540
אבל יש לו השפעה גם על AL1, שגם משחק תפקיד בפונקציית העלות, וצריך להוסיף את אלה.

96
00:08:59,820 --> 00:09:03,040
וזה, ובכן, זה פחות או יותר.

97
00:09:03,500 --> 00:09:08,244
ברגע שאתה יודע עד כמה פונקציית העלות רגישה להפעלות בשכבה שנייה אחרונה זו, 

98
00:09:08,244 --> 00:09:12,860
אתה יכול פשוט לחזור על התהליך עבור כל המשקולות וההטיות המוזנות לשכבה זו.

99
00:09:13,900 --> 00:09:14,960
אז טפחו לעצמכם על השכם!

100
00:09:15,300 --> 00:09:19,572
אם כל זה הגיוני, עכשיו הסתכלת עמוק לתוך לב ליבה של התפשטות לאחור, 

101
00:09:19,572 --> 00:09:22,680
סוס העבודה מאחורי האופן שבו רשתות עצביות לומדות.

102
00:09:23,300 --> 00:09:28,300
ביטויי כלל שרשרת אלו נותנים לך את הנגזרות הקובעות כל רכיב 

103
00:09:28,300 --> 00:09:33,300
בשיפוע שעוזר למזער את עלות הרשת על ידי ירידה חוזרת ונשנית.

104
00:09:34,300 --> 00:09:39,861
אם אתה יושב בחיבוק ידיים וחושב על כל זה, מדובר בהרבה שכבות של מורכבות לעטוף את דעתך, 

105
00:09:39,861 --> 00:09:42,740
אז אל תדאג אם ייקח למוח שלך זמן לעכל את הכל.

