1
00:00:00,000 --> 00:00:11,160
ההנחה הקשה כאן היא שצפיתם בחלק 3, מה שנותן הדרכה אינטואיטיבית של אלגוריתם ההפצה לאחור.

2
00:00:11,160 --> 00:00:14,920
כאן נהיה קצת יותר פורמליים וצוללים לתוך החשבון הרלוונטי.

3
00:00:14,920 --> 00:00:22,000
זה נורמלי שזה לפחות קצת מבלבל, אז המנטרה לעצור ולהרהר באופן קבוע חלה כאן כמו בכל מקום אחר.

4
00:00:22,000 --> 00:00:28,143
המטרה העיקרית שלנו היא להראות כיצד אנשים בלימוד מכונה בדרך כלל חושבים על כלל השרשרת

5
00:00:28,143 --> 00:00:34,580
מחשבון בהקשר של רשתות, שיש לו תחושה שונה מהאופן שבו רוב קורסי החישוב המבוא ניגשים לנושא.

6
00:00:34,580 --> 00:00:39,300
לאלו מכם שלא מרגישים בנוח עם החשבון הרלוונטי, יש לי סדרה שלמה בנושא.

7
00:00:39,300 --> 00:00:46,780
נתחיל עם רשת פשוטה ביותר, כזו שבה בכל שכבה יש נוירון בודד.

8
00:00:46,780 --> 00:00:51,127
רשת זו נקבעת על ידי שלושה משקלים ושלוש הטיות, והמטרה

9
00:00:51,127 --> 00:00:55,640
שלנו היא להבין עד כמה פונקציית העלות רגישה למשתנים אלו.

10
00:00:55,640 --> 00:01:01,100
כך אנו יודעים אילו התאמות למונחים אלו יגרמו לירידה היעילה ביותר בפונקציית העלות.

11
00:01:01,100 --> 00:01:05,360
אנחנו רק נתמקד בקשר בין שני הנוירונים האחרונים.

12
00:01:05,360 --> 00:01:11,800
בוא נסמן את ההפעלה של הנוירון האחרון הזה עם L, המציין באיזו שכבה הוא נמצא.

13
00:01:11,800 --> 00:01:16,560
אז ההפעלה של הנוירון הקודם היא AL-1.

14
00:01:16,560 --> 00:01:20,262
אלה לא מעריכים, הם רק דרך להוסיף לאינדקס את מה שאנחנו מדברים

15
00:01:20,262 --> 00:01:23,600
עליו, מכיוון שאני רוצה לשמור מנויים למדדים שונים בהמשך.

16
00:01:23,600 --> 00:01:28,032
נניח שהערך שאנו רוצים שההפעלה האחרונה תהיה עבור

17
00:01:28,032 --> 00:01:33,020
דוגמה לאימון נתונה הוא y, לדוגמה, y עשוי להיות 0 או 1.

18
00:01:33,020 --> 00:01:39,040
אז העלות של רשת זו עבור דוגמה אחת לאימון היא AL-y2.

19
00:01:39,040 --> 00:01:46,120
נסמן את העלות של דוגמה אחת לאימון כ-c0.

20
00:01:46,120 --> 00:01:51,860
להזכירך, ההפעלה האחרונה הזו נקבעת על ידי משקל, שאקרא לו wL,

21
00:01:51,860 --> 00:01:57,600
כפול ההפעלה של הנוירון הקודם פלוס הטיה כלשהי, שאכנה אותה bL.

22
00:01:57,600 --> 00:02:01,560
ואז אתה שואב את זה דרך איזו פונקציה לא ליניארית מיוחדת כמו הסיגמואיד או ReLU.

23
00:02:01,560 --> 00:02:06,080
למעשה, זה יקל עלינו אם ניתן שם מיוחד לסכום המשוקלל

24
00:02:06,080 --> 00:02:10,600
הזה, כמו z, עם אותו כתב עילית כמו ההפעלה הרלוונטית.

25
00:02:10,600 --> 00:02:15,974
זה הרבה מונחים, ודרך שבה אתה יכול להמשיג את זה היא שהמשקל,

26
00:02:15,974 --> 00:02:21,439
הפעולה הקודמת וההטיה ביחד משמשים לחישוב z, שבתורו מאפשר לנו

27
00:02:21,439 --> 00:02:27,360
לחשב את a, אשר לבסוף, יחד עם y קבוע, מאפשר אנחנו מחשבים את העלות.

28
00:02:27,360 --> 00:02:35,920
וכמובן, AL-1 מושפע מהמשקל שלו ומההטיה שלו וכאלה, אבל אנחנו לא מתכוונים להתמקד בזה עכשיו.

29
00:02:35,920 --> 00:02:38,120
כל אלה הם רק מספרים, נכון?

30
00:02:38,120 --> 00:02:41,960
וזה יכול להיות נחמד לחשוב שלכל אחד מהם יש שורת מספרים קטנה משלו.

31
00:02:41,960 --> 00:02:49,820
המטרה הראשונה שלנו היא להבין עד כמה רגישה פונקציית העלות לשינויים קטנים במשקל שלנו wL.

32
00:02:49,820 --> 00:02:55,740
או לנסח אחרת, מהי הנגזרת של c ביחס ל-wL?

33
00:02:55,740 --> 00:03:01,554
כשאתה רואה את המונח del w הזה, תחשוב על זה כעל איזה דחיפה זעירה ל-w, כמו שינוי ב-0.

34
00:03:01,554 --> 00:03:08,820
01, וחשבו על המונח Del c הזה כמשמעותי מה הדחיפה שתתקבל לעלות.

35
00:03:08,820 --> 00:03:10,900
מה שאנחנו רוצים זה היחס שלהם.

36
00:03:10,900 --> 00:03:17,205
מבחינה קונספטואלית, דחיפה זעירה זו ל-wL גורמת לדחיפה כלשהי ל-zL,

37
00:03:17,205 --> 00:03:23,220
אשר בתורה גורמת לדחיפה כלשהי ל-AL, אשר משפיעה ישירות על העלות.

38
00:03:23,220 --> 00:03:28,443
אז אנחנו מפרקים את הדברים על ידי הסתכלות תחילה על היחס של שינוי

39
00:03:28,443 --> 00:03:33,340
זעיר ל-zL לשינוי הזעיר הזה w, כלומר, הנגזרת של zL ביחס ל-wL.

40
00:03:33,340 --> 00:03:39,574
באופן דומה, אתה מחשיב את היחס בין השינוי ל-AL לשינוי הזעיר ב-zL שגרם

41
00:03:39,574 --> 00:03:45,900
לו, כמו גם את היחס בין הדחיפה הסופי ל-c לבין הדחיפה הבינונית הזו ל-AL.

42
00:03:45,900 --> 00:03:51,563
זה ממש כאן הוא כלל השרשרת, שבו הכפלת שלושת היחסים

43
00:03:51,563 --> 00:03:57,340
הללו נותנת לנו את הרגישות של c לשינויים קטנים ב-wL.

44
00:03:57,340 --> 00:04:02,315
אז על המסך כרגע, יש הרבה סמלים, וקח רגע כדי לוודא שזה ברור

45
00:04:02,315 --> 00:04:07,460
מה הם כולם, כי עכשיו אנחנו הולכים לחשב את הנגזרות הרלוונטיות.

46
00:04:07,460 --> 00:04:14,220
הנגזרת של c ביחס ל-AL מתבררת להיות 2AL-y.

47
00:04:14,220 --> 00:04:18,863
המשמעות היא שהגודל שלו פרופורציונלי להבדל בין התפוקה של הרשת

48
00:04:18,863 --> 00:04:23,355
לבין הדבר שאנחנו רוצים שהיא תהיה, כך שאם הפלט הזה היה שונה

49
00:04:23,355 --> 00:04:28,380
מאוד, אפילו לשינויים קלים יש השפעה גדולה על פונקציית העלות הסופית.

50
00:04:28,380 --> 00:04:32,765
הנגזרת של AL ביחס ל-zL היא רק הנגזרת של הפונקציה

51
00:04:32,765 --> 00:04:37,420
הסיגמואידית שלנו, או כל אי-לינאריות שתבחר להשתמש בה.

52
00:04:37,420 --> 00:04:46,180
הנגזרת של zL ביחס ל-wL יוצאת AL-1.

53
00:04:46,180 --> 00:04:50,180
אני לא יודע מה איתכם, אבל אני חושב שקל להיתקע עם ראש למטה

54
00:04:50,180 --> 00:04:54,180
בנוסחאות מבלי לקחת רגע לשבת ולהזכיר לעצמכם מה כולן אומרות.

55
00:04:54,180 --> 00:04:58,942
במקרה של נגזרת אחרונה זו, הכמות שהדחיפה הקטנה למשקל השפיעה

56
00:04:58,942 --> 00:05:03,220
על השכבה האחרונה תלויה במידת העוצמה של הנוירון הקודם.

57
00:05:03,220 --> 00:05:09,320
זכרו, כאן נכנס הרעיון של נוירונים-שה-יורים-ביחד-חווט-יחד.

58
00:05:09,320 --> 00:05:16,580
וכל זה הוא הנגזרת ביחס ל-wL בלבד של העלות עבור דוגמה ספציפית לאימון בודד.

59
00:05:16,580 --> 00:05:22,208
מכיוון שפונקציית העלות המלאה כוללת ממוצע של כל העלויות הללו על פני הרבה

60
00:05:22,208 --> 00:05:28,540
דוגמאות אימון שונות, הנגזרת שלה דורשת ממוצע של ביטוי זה על פני כל דוגמאות ההדרכה.

61
00:05:28,540 --> 00:05:34,982
כמובן, זה רק מרכיב אחד של וקטור הגרדיאנט, אשר בנוי מהנגזרות

62
00:05:34,982 --> 00:05:40,780
החלקיות של פונקציית העלות ביחס לכל אותם משקלים והטיות.

63
00:05:40,780 --> 00:05:46,460
אבל למרות שזו רק אחת מהנגזרות החלקיות הרבות שאנחנו צריכים, זה יותר מ-50% מהעבודה.

64
00:05:46,460 --> 00:05:50,300
הרגישות להטיה, למשל, כמעט זהה.

65
00:05:50,300 --> 00:05:58,980
אנחנו רק צריכים לשנות את המונח del z del w עבור a del z del b.

66
00:05:58,980 --> 00:06:04,700
ואם אתה מסתכל על הנוסחה הרלוונטית, הנגזרת הזו יוצאת כ-1.

67
00:06:04,700 --> 00:06:10,548
כמו כן, וכאן נכנס הרעיון של התפשטות לאחור, ניתן לראות

68
00:06:10,548 --> 00:06:16,180
עד כמה פונקציית העלות הזו רגישה להפעלת השכבה הקודמת.

69
00:06:16,180 --> 00:06:25,420
כלומר, הנגזרת הראשונית הזו בביטוי כלל השרשרת, הרגישות של z להפעלה הקודמת, יוצאת כמשקל wL.

70
00:06:25,420 --> 00:06:31,479
ושוב, למרות שלא נוכל להשפיע ישירות על הפעלת השכבה הקודמת, זה מועיל לעקוב

71
00:06:31,479 --> 00:06:37,538
אחריה, כי עכשיו אנחנו יכולים פשוט להמשיך ולחזור על אותו רעיון כללי שרשרת

72
00:06:37,538 --> 00:06:43,680
לאחור כדי לראות עד כמה רגישה פונקציית העלות ל משקלים קודמים והטיות קודמות.

73
00:06:43,680 --> 00:06:47,587
ואולי תחשבו שזו דוגמה פשוטה מדי, מכיוון שלכל השכבות יש נוירון אחד,

74
00:06:47,587 --> 00:06:51,320
והדברים הולכים להיות מסובכים באופן אקספוננציאלי עבור רשת אמיתית.

75
00:06:51,320 --> 00:06:55,426
אבל בכנות, לא כל כך הרבה משתנה כשאנחנו נותנים לשכבות מספר

76
00:06:55,426 --> 00:06:59,320
נוירונים, באמת שיש רק עוד כמה מדדים שצריך לעקוב אחריהם.

77
00:06:59,320 --> 00:07:07,920
במקום שההפעלה של שכבה נתונה פשוט תהיה AL, יהיה לה גם מנוי שמציין באיזה נוירון בשכבה זו.

78
00:07:07,920 --> 00:07:15,280
בוא נשתמש באות k כדי לאינדקס את השכבה L-1, וב-j כדי להוסיף את השכבה L.

79
00:07:15,280 --> 00:07:20,483
לגבי העלות, שוב אנו מסתכלים מהי הפלט הרצוי, אך הפעם נחבר את

80
00:07:20,483 --> 00:07:26,120
הריבועים של ההבדלים בין הפעלת השכבה האחרונה הללו לבין הפלט הרצוי.

81
00:07:26,120 --> 00:07:33,280
כלומר, אתה לוקח סכום מעל ALj מינוס yj בריבוע.

82
00:07:33,280 --> 00:07:39,471
מכיוון שיש הרבה יותר משקלים, לכל אחד צריך להיות עוד כמה מדדים כדי לעקוב אחר היכן

83
00:07:39,471 --> 00:07:45,740
הוא נמצא, אז בואו נקרא למשקל הקצה המחבר את הנוירון ה-k הזה לנוירון ה-j&#39;, WLjk.

84
00:07:45,740 --> 00:07:49,671
המדדים האלה אולי מרגישים קצת לאחור בהתחלה, אבל הם תואמים את

85
00:07:49,671 --> 00:07:53,800
האופן שבו היית מוסיף את מטריצת המשקל שעליה דיברתי בסרטון חלק 1.

86
00:07:53,800 --> 00:07:59,466
ממש כמו קודם, עדיין נחמד לתת שם לסכום המשוקלל הרלוונטי, כמו z, כך שההפעלה

87
00:07:59,466 --> 00:08:04,980
של השכבה האחרונה היא רק הפונקציה המיוחדת שלך, כמו הסיגמואיד, המוחל על z.

88
00:08:04,980 --> 00:08:10,200
אתה יכול לראות למה אני מתכוון, כאשר כל אלה הם בעצם אותן משוואות

89
00:08:10,200 --> 00:08:15,420
שהיו לנו קודם במקרה של נוירון-לשכבה, רק שזה נראה קצת יותר מסובך.

90
00:08:15,420 --> 00:08:23,540
ואכן, הביטוי הנגזר של כלל השרשרת המתאר עד כמה העלות רגישה למשקל ספציפי נראה זהה בעצם.

91
00:08:23,540 --> 00:08:29,420
אני אשאיר לך לעצור ולחשוב על כל אחד מהמונחים האלה אם תרצה.

92
00:08:29,420 --> 00:08:37,820
מה שכן משתנה כאן הוא הנגזרת של העלות ביחס לאחת ההפעלה בשכבה L-1.

93
00:08:37,820 --> 00:08:43,540
במקרה זה, ההבדל הוא שהנוירון משפיע על תפקוד העלות דרך מספר נתיבים שונים.

94
00:08:43,540 --> 00:08:51,761
כלומר, מצד אחד, זה משפיע על AL0, שמשחק תפקיד בפונקציית העלות, אבל יש

95
00:08:51,761 --> 00:09:00,340
לו השפעה גם על AL1, שגם משחק תפקיד בפונקציית העלות, וצריך להוסיף את אלה.

96
00:09:00,340 --> 00:09:03,680
וזה, ובכן, זה פחות או יותר.

97
00:09:03,680 --> 00:09:08,870
ברגע שאתה יודע עד כמה פונקציית העלות רגישה להפעלות בשכבה שנייה אחרונה זו,

98
00:09:08,870 --> 00:09:13,920
אתה יכול פשוט לחזור על התהליך עבור כל המשקולות וההטיות המוזנות לשכבה זו.

99
00:09:13,920 --> 00:09:15,420
אז טפחו לעצמכם על השכם!

100
00:09:15,420 --> 00:09:19,705
אם כל זה הגיוני, עכשיו הסתכלת עמוק לתוך לב ליבה של התפשטות

101
00:09:19,705 --> 00:09:23,700
לאחור, סוס העבודה מאחורי האופן שבו רשתות עצביות לומדות.

102
00:09:23,700 --> 00:09:29,360
ביטויי כלל שרשרת אלו נותנים לך את הנגזרות הקובעות כל רכיב

103
00:09:29,360 --> 00:09:35,020
בשיפוע שעוזר למזער את עלות הרשת על ידי ירידה חוזרת ונשנית.

104
00:09:35,020 --> 00:09:36,913
אם אתה יושב בחיבוק ידיים וחושב על כל זה, מדובר בהרבה שכבות של

105
00:09:36,913 --> 00:09:38,960
מורכבות לעטוף את דעתך, אז אל תדאג אם ייקח למוח שלך זמן לעכל את הכל.

