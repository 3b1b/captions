1
00:00:04,020 --> 00:00:08,420
The hard assumption here is that you've watched part 3, giving an intuitive walkthrough

2
00:00:08,420 --> 00:00:09,920
of the backpropagation algorithm.

3
00:00:11,040 --> 00:00:14,220
Here we get a little more formal and dive into the relevant calculus.

4
00:00:14,820 --> 00:00:18,540
It's normal for this to be at least a little confusing, so the mantra to regularly pause

5
00:00:18,540 --> 00:00:21,400
and ponder certainly applies as much here as anywhere else.

6
00:00:21,940 --> 00:00:26,640
Our main goal is to show how people in machine learning commonly think about the chain rule

7
00:00:26,640 --> 00:00:31,880
from calculus in the context of networks, which has a different feel from how most introductory

8
00:00:31,880 --> 00:00:33,640
calculus courses approach the subject.

9
00:00:34,340 --> 00:00:38,320
For those of you uncomfortable with the relevant calculus, I do have a whole series on the

10
00:00:38,320 --> 00:00:38,740
topic.

11
00:00:39,960 --> 00:00:44,900
Let's start off with an extremely simple network, one where each layer has a single

12
00:00:44,900 --> 00:00:46,020
neuron in it.

13
00:00:46,320 --> 00:00:51,860
This network is determined by three weights and three biases, and our goal is to understand

14
00:00:51,860 --> 00:00:54,880
how sensitive the cost function is to these variables.

15
00:00:55,420 --> 00:00:59,760
That way, we know which adjustments to those terms will cause the most efficient decrease

16
00:00:59,760 --> 00:01:00,820
to the cost function.

17
00:01:01,960 --> 00:01:04,840
And we're just going to focus on the connection between the last two neurons.

18
00:01:05,980 --> 00:01:10,440
Let's label the activation of that last neuron with a superscript L, indicating which

19
00:01:10,440 --> 00:01:15,560
layer it's in, so the activation of the previous neuron is Al-1.

20
00:01:16,360 --> 00:01:19,920
These are not exponents, they're just a way of indexing what we're talking about,

21
00:01:20,020 --> 00:01:23,040
since I want to save subscripts for different indices later on.

22
00:01:23,720 --> 00:01:28,520
Let's say that the value we want this last activation to be for a given training example

23
00:01:28,520 --> 00:01:32,180
is y, for example, y might be 0 or 1.

24
00:01:32,840 --> 00:01:39,240
So the cost of this network for a single training example is Al-y2.

25
00:01:40,260 --> 00:01:44,380
We'll denote the cost of that one training example as c0.

26
00:01:45,900 --> 00:01:51,600
As a reminder, this last activation is determined by a weight, which I'm going to call WL,

27
00:01:51,600 --> 00:01:56,640
times the previous neuron's activation plus some bias, which I'll call BL.

28
00:01:57,420 --> 00:02:01,320
And then you pump that through some special nonlinear function like the sigmoid or ReLU.

29
00:02:01,800 --> 00:02:05,360
It's actually going to make things easier for us if we give a special name to this weighted

30
00:02:05,360 --> 00:02:09,320
sum, like z, with the same superscript as the relevant activations.

31
00:02:10,380 --> 00:02:15,280
This is a lot of terms, and a way you might conceptualize it is that the weight, previous

32
00:02:15,280 --> 00:02:20,700
action and the bias all together are used to compute z, which in turn lets us compute

33
00:02:20,700 --> 00:02:25,480
a, which finally, along with a constant y, lets us compute the cost.

34
00:02:27,340 --> 00:02:33,480
And of course Al-1 is influenced by its own weight and bias and such, but we're not

35
00:02:33,480 --> 00:02:35,060
going to focus on that right now.

36
00:02:35,700 --> 00:02:37,620
All of these are just numbers, right?

37
00:02:38,060 --> 00:02:41,040
And it can be nice to think of each one as having its own little number line.

38
00:02:41,720 --> 00:02:47,580
Our first goal is to understand how sensitive the cost function is to small changes in our

39
00:02:47,580 --> 00:02:49,000
weight WL.

40
00:02:49,540 --> 00:02:54,860
Or phrase differently, what is the derivative of c with respect to WL?

41
00:02:55,600 --> 00:03:01,240
When you see this del W term, think of it as meaning some tiny nudge to W, like a change

42
00:03:01,240 --> 00:03:08,060
by 0.01, and think of this del c term as meaning whatever the resulting nudge to the cost is.

43
00:03:08,060 --> 00:03:10,220
What we want is their ratio.

44
00:03:11,260 --> 00:03:17,800
Conceptually, this tiny nudge to WL causes some nudge to ZL, which in turn causes some

45
00:03:17,800 --> 00:03:21,240
nudge to AL, which directly influences the cost.

46
00:03:23,120 --> 00:03:28,060
So we break things up by first looking at the ratio of a tiny change to ZL to this tiny

47
00:03:28,060 --> 00:03:33,200
change W, that is, the derivative of ZL with respect to WL.

48
00:03:33,200 --> 00:03:38,880
Likewise, you then consider the ratio of the change to AL to the tiny change in ZL that

49
00:03:38,880 --> 00:03:43,980
caused it, as well as the ratio between the final nudge to c and this intermediate nudge

50
00:03:43,980 --> 00:03:44,660
to AL.

51
00:03:45,740 --> 00:03:51,840
This right here is the chain rule, where multiplying together these three ratios gives us the sensitivity

52
00:03:51,840 --> 00:03:55,140
of c to small changes in WL.

53
00:03:56,880 --> 00:04:01,600
So on screen right now, there's a lot of symbols, and take a moment to make sure it's

54
00:04:01,600 --> 00:04:06,240
clear what they all are, because now we're going to compute the relevant derivatives.

55
00:04:07,440 --> 00:04:13,160
The derivative of c with respect to AL works out to be 2AL-y.

56
00:04:13,980 --> 00:04:18,540
Notice this means its size is proportional to the difference between the network's

57
00:04:18,540 --> 00:04:24,020
output and the thing we want it to be, so if that output was very different, even slight

58
00:04:24,020 --> 00:04:27,140
changes stand to have a big impact on the final cost function.

59
00:04:27,840 --> 00:04:33,700
The derivative of AL with respect to ZL is just the derivative of our sigmoid function,

60
00:04:33,800 --> 00:04:36,180
or whatever nonlinearity you choose to use.

61
00:04:37,220 --> 00:04:44,660
And the derivative of ZL with respect to WL comes out to be AL-1.

62
00:04:45,760 --> 00:04:49,100
Now I don't know about you, but I think it's easy to get stuck head down in the

63
00:04:49,100 --> 00:04:53,420
formulas without taking a moment to sit back and remind yourself of what they all mean.

64
00:04:53,920 --> 00:04:58,800
In the case of this last derivative, the amount that the small nudge to the weight influenced

65
00:04:58,800 --> 00:05:02,820
the last layer depends on how strong the previous neuron is.

66
00:05:03,380 --> 00:05:08,280
Remember, this is where the neurons-that-fire-together-wire-together idea comes in.

67
00:05:09,200 --> 00:05:14,860
And all of this is the derivative with respect to WL only of the cost for a specific single

68
00:05:14,860 --> 00:05:15,720
training example.

69
00:05:16,440 --> 00:05:20,940
Since the full cost function involves averaging together all those costs across many different

70
00:05:20,940 --> 00:05:26,860
training examples, its derivative requires averaging this expression over all training

71
00:05:26,860 --> 00:05:27,460
examples.

72
00:05:28,380 --> 00:05:33,000
And of course, that is just one component of the gradient vector, which itself is built

73
00:05:33,000 --> 00:05:37,580
up from the partial derivatives of the cost function with respect to all those weights

74
00:05:37,580 --> 00:05:38,260
and biases.

75
00:05:40,640 --> 00:05:44,280
But even though that's just one of the many partial derivatives we need, it's more than

76
00:05:44,280 --> 00:05:45,260
50% of the work.

77
00:05:46,340 --> 00:05:49,720
The sensitivity to the bias, for example, is almost identical.

78
00:05:50,040 --> 00:05:55,020
We just need to change out this del z del w term for a del z del b.

79
00:05:58,420 --> 00:06:02,400
And if you look at the relevant formula, that derivative comes out to be 1.

80
00:06:06,140 --> 00:06:11,700
Also, and this is where the idea of propagating backwards comes in, you can see how sensitive

81
00:06:11,700 --> 00:06:15,740
this cost function is to the activation of the previous layer.

82
00:06:15,740 --> 00:06:21,620
Namely, this initial derivative in the chain rule expression, the sensitivity of z to the

83
00:06:21,620 --> 00:06:25,660
previous activation, comes out to be the weight WL.

84
00:06:26,640 --> 00:06:30,120
And again, even though we're not going to be able to directly influence that previous

85
00:06:30,120 --> 00:06:35,340
layer activation, it's helpful to keep track of, because now we can just keep iterating

86
00:06:35,340 --> 00:06:40,820
this same chain rule idea backwards to see how sensitive the cost function is to previous

87
00:06:40,820 --> 00:06:42,440
weights and previous biases.

88
00:06:43,180 --> 00:06:47,720
And you might think this is an overly simple example, since all layers have one neuron,

89
00:06:47,880 --> 00:06:51,020
and things are going to get exponentially more complicated for a real network.

90
00:06:51,700 --> 00:06:56,660
But honestly, not that much changes when we give the layers multiple neurons, really it's

91
00:06:56,660 --> 00:06:58,860
just a few more indices to keep track of.

92
00:06:59,380 --> 00:07:03,660
Rather than the activation of a given layer simply being AL, it's also going to have

93
00:07:03,660 --> 00:07:07,160
a subscript indicating which neuron of that layer it is.

94
00:07:07,160 --> 00:07:14,420
Let's use the letter k to index the layer L-1, and j to index the layer L.

95
00:07:15,260 --> 00:07:20,740
For the cost, again we look at what the desired output is, but this time we add up the squares

96
00:07:20,740 --> 00:07:25,180
of the differences between these last layer activations and the desired output.

97
00:07:26,080 --> 00:07:30,840
That is, you take a sum over ALj minus Yj squared.

98
00:07:33,040 --> 00:07:36,580
Since there's a lot more weights, each one has to have a couple more indices to keep

99
00:07:36,580 --> 00:07:41,080
track of where it is, so let's call the weight of the edge connecting this kth neuron

100
00:07:41,080 --> 00:07:44,920
to the jth neuron, WLjk.

101
00:07:45,620 --> 00:07:49,620
Those indices might feel a little backwards at first, but it lines up with how you'd

102
00:07:49,620 --> 00:07:53,120
index the weight matrix I talked about in the part 1 video.

103
00:07:53,620 --> 00:07:57,680
Just as before, it's still nice to give a name to the relevant weighted sum, like

104
00:07:57,680 --> 00:08:03,000
z, so that the activation of the last layer is just your special function, like the sigmoid,

105
00:08:03,300 --> 00:08:04,160
applied to z.

106
00:08:04,660 --> 00:08:09,140
You can see what I mean, where all of these are essentially the same equations we had

107
00:08:09,140 --> 00:08:13,680
before in the one-neuron-per-layer case, it's just that it looks a little more complicated.

108
00:08:15,440 --> 00:08:20,820
And indeed, the chain-ruled derivative expression describing how sensitive the cost is to a

109
00:08:20,820 --> 00:08:23,420
specific weight looks essentially the same.

110
00:08:23,920 --> 00:08:26,840
I'll leave it to you to pause and think about each of those terms if you want.

111
00:08:28,980 --> 00:08:34,860
What does change here, though, is the derivative of the cost with respect to one of the activations

112
00:08:34,860 --> 00:08:36,660
in the layer L-1.

113
00:08:37,780 --> 00:08:42,040
In this case, the difference is that the neuron influences the cost function through multiple

114
00:08:42,040 --> 00:08:42,880
different paths.

115
00:08:44,680 --> 00:08:51,160
That is, on the one hand, it influences AL0, which plays a role in the cost function, but

116
00:08:51,160 --> 00:08:56,520
it also has an influence on AL1, which also plays a role in the cost function, and you

117
00:08:56,520 --> 00:08:57,540
have to add those up.

118
00:08:59,820 --> 00:09:03,040
And that, well, that's pretty much it.

119
00:09:03,500 --> 00:09:07,980
Once you know how sensitive the cost function is to the activations in this second-to-last

120
00:09:07,980 --> 00:09:12,460
layer, you can just repeat the process for all the weights and biases feeding into that

121
00:09:12,460 --> 00:09:12,860
layer.

122
00:09:13,900 --> 00:09:14,960
So pat yourself on the back!

123
00:09:15,300 --> 00:09:20,580
If all of this makes sense, you have now looked deep into the heart of backpropagation, the

124
00:09:20,580 --> 00:09:22,680
workhorse behind how neural networks learn.

125
00:09:23,300 --> 00:09:27,860
These chain rule expressions give you the derivatives that determine each component

126
00:09:27,860 --> 00:09:33,300
in the gradient that helps minimize the cost of the network by repeatedly stepping downhill.

127
00:09:34,300 --> 00:09:39,000
If you sit back and think about all that, this is a lot of layers of complexity to wrap

128
00:09:39,000 --> 00:09:43,080
your mind around, so don't worry if it takes time for your mind to digest it all.

