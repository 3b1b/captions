[
 {
  "input": "When I first learned about Taylor series, I definitely didn't appreciate just how important they are. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   14.912,
   20.18
  ]
 },
 {
  "input": "But time and time again they come up in math, physics, and many fields of engineering because they're one of the most powerful tools that math has to offer for approximating functions. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   20.18,
   30.08
  ]
 },
 {
  "input": "I think one of the first times this clicked for me as a student was not in a calculus class, but a physics class. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   30.08,
   35.96
  ]
 },
 {
  "input": "We were studying a certain problem that had to do with the potential energy of a pendulum, and for that you need an expression for how high the weight of the pendulum is above its lowest point, and when you work that out it comes out to be proportional to 1 minus the cosine of the angle between the pendulum and the vertical. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   35.96,
   54.08
  ]
 },
 {
  "input": "The specifics of the problem we were trying to solve are beyond the point here, but what I'll say is that this cosine function made the problem awkward and unwieldy, and made it less clear how pendulums relate to other oscillating phenomena. ",
  "translatedText": "ตอนที่ฉันรู้เกี่ยวกับซีรีส์ของ Taylor ครั้งแรก ฉันไม่รู้สึกซาบซึ้งเลยว่ามันสำคัญแค่ไหน แต่ครั้งแล้วครั้งเล่ามักมีวิชาคณิตศาสตร์ ฟิสิกส์ และวิศวกรรมศาสตร์หลายแขนง เพราะมันเป็นหนึ่งในเครื่องมือที่ทรงพลังที่สุดที่คณิตศาสตร์มีให้สำหรับการประมาณฟังก์ชัน ฉันคิดว่านี่เป็นครั้งแรกที่สิ่งนี้โดนใจฉัน เนื่องจากนักเรียนไม่ได้อยู่ในชั้นเรียนแคลคูลัส แต่เป็นชั้นเรียนฟิสิกส์ เรากำลังศึกษาปัญหาบางอย่างที่เกี่ยวข้องกับพลังงานศักย์ของลูกตุ้ม และเพื่อจุดประสงค์นี้ คุณต้องแสดงให้เห็นว่าน้ำหนักของลูกตุ้มอยู่เหนือจุดต่ำสุดของมันสูงแค่ไหน และเมื่อคุณทำงานออกมา ผลลัพธ์ที่ได้ก็คือ แปรผันเป็น 1 ลบโคไซน์ของมุมระหว่างลูกตุ้มกับแนวตั้ง ปัญหาเฉพาะที่เราพยายามแก้ไขนั้นอยู่นอกเหนือประเด็นนี้ แต่สิ่งที่ฉันจะพูดคือฟังก์ชันโคไซน์นี้ทำให้ปัญหายุ่งยากและยุ่งยาก และทำให้ไม่ชัดเจนว่าลูกตุ้มเกี่ยวข้องกับปรากฏการณ์การสั่นอื่นๆ อย่างไร แต่ถ้าคุณประมาณโคไซน์ของทีต้าเป็น 1 ลบทีต้ากำลังสอง ส่วน 2 ทุกอย่างเข้าที่ง่ายกว่ามาก หากคุณไม่เคยเห็นอะไรแบบนี้มาก่อน การประมาณเช่นนั้นอาจดูเหมือนอยู่นอกขอบเขตโดยสิ้นเชิง หากคุณวาดกราฟโคไซน์ของทีต้าพร้อมกับฟังก์ชันนี้ 1 ลบทีต้ากำลังสอง ส่วน 2 พวกมันดูเหมือนจะอยู่ใกล้กัน อย่างน้อยก็สำหรับมุมเล็กๆ ใกล้ 0 แต่คุณคิดจะประมาณค่านี้อย่างไร และคุณจะทำยังไง หากำลังสองอันนั้นเจอไหม? ",
  "model": "nmt",
  "time_range": [
   54.08,
   67.68
  ]
 },
 {
  "input": "But if you approximate cosine of theta as 1 minus theta squared over 2, everything just fell into place much more easily. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   67.68,
   77.08
  ]
 },
 {
  "input": "If you've never seen anything like this before, an approximation like that might seem completely out of left field. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   77.08,
   83.9
  ]
 },
 {
  "input": "If you graph cosine of theta along with this function, 1 minus theta squared over 2, they do seem rather close to each other, at least for small angles near 0, but how would you even think to make this approximation, and how would you find that particular quadratic? ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   83.9,
   101.36
  ]
 },
 {
  "input": "The study of Taylor series is largely about taking non-polynomial functions and finding polynomials that approximate them near some input. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   101.36,
   109.66
  ]
 },
 {
  "input": "The motive here is that polynomials tend to be much easier to deal with than other functions. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   109.66,
   113.94
  ]
 },
 {
  "input": "They're easier to compute, easier to take derivatives, easier to integrate, just all around more friendly. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   113.94,
   120.7
  ]
 },
 {
  "input": "So let's take a look at that function, cosine of x, and really take a moment to think about how you might construct a quadratic approximation near x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   120.7,
   131.22
  ]
 },
 {
  "input": "That is, among all of the possible polynomials that look like c0 plus c1 times x plus c2 times x squared, for some choice of these constants, c0, c1, and c2, find the one that most resembles cosine of x near x equals 0, whose graph kind of spoons with the graph of cosine x at that point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   131.22,
   153.5
  ]
 },
 {
  "input": "Well, first of all, at the input 0, the value of cosine of x is 1, so if our approximation is going to be any good at all, it should also equal 1 at the input x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   153.5,
   165.86
  ]
 },
 {
  "input": "Plugging in 0 just results in whatever c0 is, so we can set that equal to 1. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   165.86,
   173.26
  ]
 },
 {
  "input": "This leaves us free to choose constants c1 and c2 to make this approximation as good as we can, but nothing we do with them is going to change the fact that the polynomial equals 1 at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   173.26,
   185.58
  ]
 },
 {
  "input": "It would also be good if our approximation had the same tangent slope as cosine x at this point of interest. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   185.58,
   191.7
  ]
 },
 {
  "input": "Otherwise, the approximation drifts away from the cosine graph much faster than it needs to. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   191.7,
   196.74
  ]
 },
 {
  "input": "The derivative of cosine is negative sine, and at x equals 0, that equals 0, meaning the tangent line is perfectly flat. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   196.74,
   207.5
  ]
 },
 {
  "input": "On the other hand, when you work out the derivative of our quadratic, you get c1 plus 2 times c2 times x. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   207.5,
   215.24
  ]
 },
 {
  "input": "At x equals 0, this just equals whatever we choose for c1. ",
  "translatedText": "การศึกษาอนุกรมเทย์เลอร์ส่วนใหญ่เกี่ยวกับการหาฟังก์ชันที่ไม่ใช่พหุนามและการค้นหาพหุนามที่ประมาณค่าเหล่านั้นใกล้กับข้อมูลนำเข้าบางส่วน  เหตุผลก็คือพหุนามมักจะจัดการได้ง่ายกว่าฟังก์ชันอื่นๆ มาก พวกมันคำนวณง่ายกว่า หาอนุพันธ์ง่ายกว่า บูรณาการง่ายกว่า และเป็นมิตรมากขึ้น ลองมาดูฟังก์ชันนั้น โคไซน์ของ x แล้วใช้เวลาคิดสักนิดว่า คุณจะสร้างการประมาณกำลังสองใกล้ x เท่ากับ 0 ได้อย่างไร นั่นคือ ในบรรดาพหุนามที่เป็นไปได้ทั้งหมดที่ดูเหมือน c0 บวก c1 คูณ x บวก c2 คูณ x กำลังสอง สำหรับตัวเลือกค่าคงที่เหล่านี้ c0, c1 และ c2 ให้หาค่าที่คล้ายกับโคไซน์ของ x ใกล้ x เท่ากับ 0 มากที่สุด ซึ่งมีกราฟแบบช้อนซึ่งมีกราฟโคไซน์ x ณ จุดนั้น อย่างแรกเลย ที่อินพุต 0 ค่าโคไซน์ของ x เท่ากับ 1 ดังนั้นหากการประมาณของเราออกมาดีเลย มันควรจะเท่ากับ 1 ที่อินพุต x เท่ากับ 0 ด้วย การเสียบ 0 จะให้ผลลัพธ์อะไรก็ตามที่ c0 เป็น เราก็เลยตั้งค่าให้เท่ากับ 1 ได้ นี่ทำให้เรามีอิสระที่จะเลือกค่าคงที่ c1 และ c2 เพื่อให้การประมาณค่านี้ดีที่สุดเท่าที่เราจะทำได้ แต่เราไม่ทำอะไรกับค่าคงที่เหล่านี้ ที่จะเปลี่ยนข้อเท็จจริงที่ว่าพหุนามเท่ากับ 1 ที่ x เท่ากับ 0 มันคงจะดีถ้าการประมาณของเรามีความชันแทนเจนต์เท่ากับโคไซน์ x ที่จุดสนใจนี้ มิฉะนั้น การประมาณจะเบี่ยงเบนไปจากกราฟโคไซน์เร็วกว่าที่จำเป็นมาก อนุพันธ์ของโคไซน์คือไซน์ลบ และที่ x เท่ากับ 0 นั่นเท่ากับ 0 หมายความว่าเส้นสัมผัสจะแบนราบอย่างสมบูรณ์ ในทางกลับกัน เมื่อคุณหาอนุพันธ์ของกำลังสอง คุณจะได้ c1 บวก 2 คูณ c2 คูณ x ที่ x เท่ากับ 0, นี่ก็แค่เท่ากับสิ่งที่เราเลือกสำหรับ c1 ค่าคงที่ c1 นี้ควบคุมอนุพันธ์ของการประมาณได้อย่างสมบูรณ์ รอบ x เท่ากับ 0 การตั้งค่าให้เท่ากับ 0 จะทำให้การประมาณค่าของเรามีเส้นสัมผัสแบนราบ ณ จุดนี้ด้วย นี่ทำให้เราเปลี่ยน c2 ได้อย่างอิสระ แต่ค่าและความชันของพหุนามที่ x เท่ากับ 0 ล็อคอยู่กับที่เพื่อให้ตรงกับโคไซน์ สิ่งสุดท้ายที่ต้องใช้ประโยชน์คือกราฟโคไซน์โค้งลงเหนือ x เท่ากับ 0 และมีอนุพันธ์อันดับสองเป็นลบ หรืออีกนัยหนึ่ง แม้ว่าอัตราการเปลี่ยนแปลงจะเป็น 0 ณ จุดนั้น แต่อัตราการเปลี่ยนแปลงเองก็กำลังลดลงรอบจุดนั้น โดยเฉพาะอย่างยิ่ง เนื่องจากอนุพันธ์ของมันคือลบไซน์ของ x อนุพันธ์อันดับสองของมันคือลบโคไซน์ของ x และที่ x เท่ากับ 0 นั่นเท่ากับลบ 1 ในลักษณะเดียวกับที่เราอยากให้อนุพันธ์ของการประมาณตรงกับโคไซน์ เพื่อว่าค่าของมันจะไม่แยกจากกันอย่างรวดเร็วโดยไม่จำเป็น ทำให้แน่ใจว่าอนุพันธ์อันดับสองที่ตรงกันจะทำให้พวกมันโค้งในอัตราเดียวกัน ความชันของพหุนามไม่ได้เบี่ยงเบนไปจากความชันของโคไซน์ x เร็วกว่าที่ควรจะเป็น เมื่อดึงอนุพันธ์แบบเดิมที่เราเคยมีมา แล้วหาอนุพันธ์ของมัน เราจะเห็นว่าอนุพันธ์อันดับสองของพหุนามนี้เป็น 2 คูณ c2 พอดี เพื่อให้แน่ใจว่าอนุพันธ์อันดับสองนี้เท่ากับลบ 1 ที่ x เท่ากับ 0 ด้วย 2 คูณ c2 ต้องเป็นลบ 1 หมายความว่า c2 เองควรเป็นลบ 1 ครึ่งหนึ่ง และนี่ให้ค่าประมาณ 1 บวก 0x ลบ 1 ครึ่ง x กำลังสอง และเพื่อให้รู้ว่ามันดีแค่ไหน ถ้าคุณประมาณโคไซน์เป็น 0 1 เมื่อใช้พหุนามนี้ คุณจะประมาณค่าได้ว่าเป็น 0 995. ",
  "model": "nmt",
  "time_range": [
   215.24,
   220.28
  ]
 },
 {
  "input": "So this constant c1 has complete control over the derivative of our approximation around x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   220.28,
   227.2
  ]
 },
 {
  "input": "Setting it equal to 0 ensures that our approximation also has a flat tangent line at this point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   227.2,
   233.48
  ]
 },
 {
  "input": "This leaves us free to change c2, but the value and slope of our polynomial at x equals 0 are locked in place to match that of cosine. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   233.48,
   244.36
  ]
 },
 {
  "input": "The final thing to take advantage of is the fact that the cosine graph curves downward above x equals 0, it has a negative second derivative. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   244.36,
   253.46
  ]
 },
 {
  "input": "Or in other words, even though the rate of change is 0 at that point, the rate of change itself is decreasing around that point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   253.46,
   261.3
  ]
 },
 {
  "input": "Specifically, since its derivative is negative sine of x, its second derivative is negative cosine of x, and at x equals 0, that equals negative 1. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   261.3,
   273.14
  ]
 },
 {
  "input": "Now in the same way that we wanted the derivative of our approximation to match that of the cosine, so that their values wouldn't drift apart needlessly quickly, making sure that their second derivatives match will ensure that they curve at the same rate, that the slope of our polynomial doesn't drift away from the slope of cosine x any more quickly than it needs to. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   273.14,
   294.5
  ]
 },
 {
  "input": "Pulling up the same derivative we had before, and then taking its derivative, we see that the second derivative of this polynomial is exactly 2 times c2. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   294.5,
   305.02
  ]
 },
 {
  "input": "So to make sure that this second derivative also equals negative 1 at x equals 0, 2 times c2 has to be negative 1, meaning c2 itself should be negative 1 half. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   305.02,
   316.82
  ]
 },
 {
  "input": "And this gives us the approximation 1 plus 0x minus 1 half x squared. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   316.82,
   323.18
  ]
 },
 {
  "input": "And to get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial, you'd estimate it to be 0.995. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   323.18,
   332.86
  ]
 },
 {
  "input": "And this is the true value of cosine of 0.1. ",
  "translatedText": "และนี่คือค่าที่แท้จริงของโคไซน์ของ 0 1. ",
  "model": "nmt",
  "time_range": [
   332.86,
   336.02
  ]
 },
 {
  "input": "It's a really good approximation! ",
  "translatedText": "เป็นการประมาณที่ดีจริงๆ! ",
  "model": "nmt",
  "time_range": [
   336.02,
   340.42
  ]
 },
 {
  "input": "Take a moment to reflect on what just happened. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   340.42,
   343.0
  ]
 },
 {
  "input": "You had 3 degrees of freedom with this quadratic approximation, the constants c0, c1, and c2. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   343.0,
   349.54
  ]
 },
 {
  "input": "c0 was responsible for making sure that the output of the approximation matches that of cosine x at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   349.54,
   357.18
  ]
 },
 {
  "input": "c1 was in charge of making sure that the derivatives match at that point, and c2 was responsible for making sure that the second derivatives match up. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   357.18,
   369.42
  ]
 },
 {
  "input": "This ensures that the way your approximation changes as you move away from x equals 0, and the way that the rate of change itself changes, is as similar as possible to the behavior of cosine x, given the amount of control you have. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   369.42,
   384.34
  ]
 },
 {
  "input": "You could give yourself more control by allowing more terms in your polynomial and matching higher order derivatives. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   384.34,
   390.86
  ]
 },
 {
  "input": "For example, let's say you added on the term c3 times x3 for some constant c3. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   390.86,
   396.58
  ]
 },
 {
  "input": "In that case, if you take the third derivative of a cubic polynomial, anything that's quadratic or smaller goes to 0. ",
  "translatedText": "ใช้เวลาสักครู่เพื่อไตร่ตรองถึงสิ่งที่เกิดขึ้น คุณมีระดับอิสระ 3 องศาด้วยการประมาณกำลังสองนี้ ค่าคงที่ c0, c1 และ c2 c0 มีหน้าที่ตรวจสอบให้แน่ใจว่าผลลัพธ์ของการประมาณตรงกับโคไซน์ x ที่ x เท่ากับ 0 c1 มีหน้าที่ตรวจสอบให้แน่ใจว่าอนุพันธ์อันดับสองตรงกัน ณ จุดนั้น และ c2 มีหน้าที่ตรวจสอบให้แน่ใจว่าอนุพันธ์อันดับสองตรงกัน วิธีนี้ทำให้แน่ใจได้ว่าการเปลี่ยนแปลงการประมาณเมื่อคุณเคลื่อนห่างจาก x เท่ากับ 0 และวิธีที่อัตราการเปลี่ยนแปลงเปลี่ยนแปลงจะใกล้เคียงกับพฤติกรรมของโคไซน์ x มากที่สุดเท่าที่จะเป็นไปได้ เมื่อพิจารณาจากปริมาณการควบคุมที่คุณมี คุณสามารถควบคุมตัวเองได้มากขึ้นโดยอนุญาตให้มีเงื่อนไขมากขึ้นในพหุนามของคุณและจับคู่อนุพันธ์ลำดับที่สูงกว่า  ตัวอย่างเช่น สมมติว่าคุณบวกคำว่า c3 คูณ x3 สำหรับค่าคงที่ c3 ในกรณีนั้น หากคุณหาอนุพันธ์อันดับสามของพหุนามลูกบาศก์ สิ่งใดก็ตามที่เป็นกำลังสองหรือน้อยกว่าจะเป็น 0 สำหรับเทอมสุดท้ายนั้น หลังจากวนกฎยกกำลัง 3 ครั้ง จะดูเหมือน 1 คูณ 2 คูณ 3 คูณ c3 ในทางกลับกัน อนุพันธ์อันดับสามของโคไซน์ x ออกมาเป็นไซน์ x ซึ่งเท่ากับ 0 ที่ x เท่ากับ 0 ดังนั้นเพื่อให้แน่ใจว่าอนุพันธ์อันดับสามตรงกัน ค่าคงที่ c3 ควรเป็น 0 หรืออีกนัยหนึ่ง ไม่เพียงแต่ 1 ลบ 1 ครึ่ง x2 จะเป็นค่าประมาณโคไซน์กำลังสองที่ดีที่สุดเท่าที่จะเป็นไปได้ แต่ยังเป็นการประมาณกำลังสามที่ดีที่สุดด้วย คุณสามารถปรับปรุงได้โดยการเพิ่มเงื่อนไขลำดับที่สี่ นั่นคือ c4 คูณ x กำลังสี่ อนุพันธ์อันดับสี่ของโคไซน์คือตัวมันเอง ซึ่งเท่ากับ 1 ที่ x เท่ากับ 0 แล้วอนุพันธ์อันดับสี่ของพหุนามกับเทอมใหม่นี้คืออะไร? ",
  "model": "nmt",
  "time_range": [
   396.58,
   405.7
  ]
 },
 {
  "input": "As for that last term, after 3 iterations of the power rule, it looks like 1 times 2 times 3 times c3. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   405.7,
   416.7
  ]
 },
 {
  "input": "On the other hand, the third derivative of cosine x comes out to sine x, which equals 0 at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   416.7,
   424.02
  ]
 },
 {
  "input": "So to make sure that the third derivatives match, the constant c3 should be 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   424.02,
   429.92
  ]
 },
 {
  "input": "Or in other words, not only is 1 minus 1 half x2 the best possible quadratic approximation of cosine, it's also the best possible cubic approximation. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   429.92,
   441.58
  ]
 },
 {
  "input": "You can make an improvement by adding on a fourth order term, c4 times x to the fourth. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   441.58,
   448.06
  ]
 },
 {
  "input": "The fourth derivative of cosine is itself, which equals 1 at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   448.06,
   454.34
  ]
 },
 {
  "input": "And what's the fourth derivative of our polynomial with this new term? ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   454.34,
   458.26
  ]
 },
 {
  "input": "Well, when you keep applying the power rule over and over, with those exponents all hopping down in front, you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   458.26,
   471.7
  ]
 },
 {
  "input": "So if we want this to match the fourth derivative of cosine x, which is 1, c4 has to be 1 over 24. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   471.7,
   479.28
  ]
 },
 {
  "input": "And indeed, the polynomial 1 minus 1 half x2 plus 1 24 times x to the fourth, which looks like this, is a very close approximation for cosine x around x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   479.28,
   493.82
  ]
 },
 {
  "input": "In any physics problem involving the cosine of a small angle, for example, predictions would be almost unnoticeably different if you substituted this polynomial for cosine of x. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   493.82,
   506.22
  ]
 },
 {
  "input": "Now take a step back and notice a few things happening with this process. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   506.22,
   510.62
  ]
 },
 {
  "input": "First of all, factorial terms come up very naturally in this process. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   510.62,
   515.06
  ]
 },
 {
  "input": "When you take n successive derivatives of the function x to the n, letting the power rule keep cascading on down, what you'll be left with is 1 times 2 times 3 on and on and on up to whatever n is. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   515.06,
   529.46
  ]
 },
 {
  "input": "So you don't simply set the coefficients of the polynomial equal to whatever derivative you want. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   529.46,
   534.78
  ]
 },
 {
  "input": "You have to divide by the appropriate factorial to cancel out this effect. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   534.78,
   539.5
  ]
 },
 {
  "input": "For example, that x to the fourth coefficient was the fourth derivative of cosine, 1, but divided by 4 factorial, 24. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   539.5,
   549.54
  ]
 },
 {
  "input": "The second thing to notice is that adding on new terms, like this c4 times x to the fourth, doesn't mess up what the old terms should be, and that's really important. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   549.54,
   560.14
  ]
 },
 {
  "input": "For example, the second derivative of this polynomial at x equals 0 is still equal to 2 times the second coefficient, even after you introduce higher order terms. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   560.14,
   571.06
  ]
 },
 {
  "input": "And it's because we're plugging in x equals 0, so the second derivative of any higher order term, which all include an x, will just wash away. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   571.06,
   580.82
  ]
 },
 {
  "input": "And the same goes for any other derivative, which is why each derivative of a polynomial at x equals 0 is controlled by one and only one of the coefficients. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   580.82,
   592.68
  ]
 },
 {
  "input": "If instead you were approximating near an input other than 0, like x equals pi, in order to get the same effect, you would have to write your polynomial in terms of powers of x minus pi, or whatever input you're looking at. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   592.68,
   606.48
  ]
 },
 {
  "input": "This makes it look noticeably more complicated, but all we're doing is making sure that the point pi looks and behaves like 0, so that plugging in x equals pi will result in a lot of nice cancellation that leaves only one constant. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   606.48,
   622.7
  ]
 },
 {
  "input": "And finally, on a more philosophical level, notice how what we're doing here is basically taking information about higher order derivatives of a function at a single point, and translating that into information about the value of the function near that point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   622.7,
   641.42
  ]
 },
 {
  "input": "You can take as many derivatives of cosine as you want. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   641.42,
   644.58
  ]
 },
 {
  "input": "It follows this nice cyclic pattern, cosine of x, negative sine of x, negative cosine, sine, and then repeat. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   644.58,
   652.38
  ]
 },
 {
  "input": "And the value of each one of these is easy to compute at x equals 0, it gives this cyclic pattern 1, 0, negative 1, 0, and then repeat. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   652.38,
   662.06
  ]
 },
 {
  "input": "And knowing the values of all those higher order derivatives is a lot of information about cosine of x, even though it only involves plugging in a single number, x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   662.06,
   674.54
  ]
 },
 {
  "input": "So what we're doing is leveraging that information to get an approximation around this input, and you do it by creating a polynomial whose higher order derivatives are designed to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   674.54,
   691.66
  ]
 },
 {
  "input": "And to do that, you just make each coefficient of the polynomial follow that same pattern, but you have to divide each one by the appropriate factorial. ",
  "translatedText": "ทีนี้ เมื่อคุณใช้กฎยกกำลังซ้ำไปซ้ำมา โดยที่เลขชี้กำลังทั้งหมดกระโดดลงมาข้างหน้า คุณจะจบลงด้วย 1 คูณ 2 คูณ 3 คูณ 4 คูณ c4 ซึ่งก็คือ 24 คูณ c4 แล้วถ้าเราอยากให้นี่ตรงกับอนุพันธ์อันดับสี่ของโคไซน์ x ซึ่งก็คือ 1, c4 ต้องเป็น 1 ส่วน 24 ที่จริง พหุนาม 1 ลบ 1 ครึ่ง x2 บวก 1 24 คูณ x กำลังสี่ ซึ่งเป็นแบบนี้ เป็นค่าประมาณที่ใกล้เคียงมากสำหรับโคไซน์ x รอบ x เท่ากับ 0 ตัวอย่างเช่น ในโจทย์ฟิสิกส์ใดๆ ที่เกี่ยวข้องกับโคไซน์ของมุมเล็ก การทำนายจะแตกต่างไปจนแทบมองไม่เห็นถ้าคุณแทนพหุนามนี้ด้วยโคไซน์ของ x ย้อนกลับไปและสังเกตบางสิ่งที่เกิดขึ้นกับกระบวนการนี้ ประการแรก เงื่อนไขแฟกทอเรียลจะเกิดขึ้นอย่างเป็นธรรมชาติในกระบวนการนี้ เมื่อคุณหาอนุพันธ์ต่อเนื่องของฟังก์ชัน x กำลัง n โดยปล่อยให้กฎยกกำลังต่อเรียงลงมา คุณจะเหลือ 1 คูณ 2 คูณ 3 ไปเรื่อยๆ ขึ้นกับ n ใดๆ คุณจึงไม่เพียงแค่ตั้งค่าสัมประสิทธิ์ของพหุนามเท่ากับอนุพันธ์ใดๆ ที่คุณต้องการ คุณต้องหารด้วยแฟกทอเรียลที่เหมาะสมเพื่อยกเลิกผลกระทบนี้ ตัวอย่างเช่น x กำลังสี่สัมประสิทธิ์คืออนุพันธ์อันดับสี่ของโคไซน์ 1 แต่หารด้วย 4 แฟคทอเรียล 24 สิ่งที่สองที่ต้องสังเกตคือการเพิ่มเทอมใหม่ เช่น c4 นี้คูณ x กำลังสี่ ไม่ได้ทำให้เทอมเก่าควรเป็นเหมือนเดิม และนั่นสำคัญมาก ตัวอย่างเช่น อนุพันธ์อันดับสองของพหุนามที่ x เท่ากับ 0 ยังคงเท่ากับ 2 คูณสัมประสิทธิ์ที่สอง แม้ว่าคุณจะแนะนำเงื่อนไขลำดับที่สูงกว่าแล้วก็ตาม และเป็นเพราะเราแทนค่า x เท่ากับ 0 อนุพันธ์อันดับสองของเทอมลำดับที่สูงกว่าใดๆ ซึ่งรวมถึง x ด้วย จะถูกล้างออกไป และเช่นเดียวกันกับอนุพันธ์อื่นๆ ซึ่งเป็นสาเหตุที่อนุพันธ์แต่ละตัวของพหุนามที่ x เท่ากับ 0 ถูกควบคุมโดยสัมประสิทธิ์ตัวเดียวเท่านั้น หากคุณประมาณค่าใกล้ค่าเข้าอื่นที่ไม่ใช่ 0 เช่น x เท่ากับ ไพ เพื่อให้ได้ผลลัพธ์แบบเดียวกัน คุณจะต้องเขียนพหุนามในรูปของกำลังของ x ลบ pi หรือค่าใดๆ ก็ตามที่คุณกำลังดูอยู่ นี่ทำให้มันดูซับซ้อนขึ้นอย่างเห็นได้ชัด แต่สิ่งที่เราทำคือทำให้แน่ใจว่าจุด pi ดูและมีพฤติกรรมเป็น 0 ดังนั้นการเสียบ x เท่ากับ pi จะทำให้เกิดการยกเลิกที่ดีมากมายจนเหลือเพียงค่าคงที่เดียว และสุดท้าย ในระดับปรัชญามากขึ้น สังเกตว่าสิ่งที่เรากำลังทำอยู่นี้ โดยพื้นฐานแล้วนำข้อมูลเกี่ยวกับอนุพันธ์ลำดับที่สูงกว่าของฟังก์ชัน ณ จุดเดียว และแปลสิ่งนั้นเป็นข้อมูลเกี่ยวกับค่าของฟังก์ชันที่อยู่ใกล้จุดนั้น คุณสามารถหาอนุพันธ์ของโคไซน์ได้มากเท่าที่คุณต้องการ มันเป็นไปตามรูปแบบวงจรสวยๆ โคไซน์ของ x ลบไซน์ของ x โคไซน์ลบ ไซน์ แล้วทำซ้ำ และค่าของแต่ละค่าเหล่านี้นั้น คำนวณได้ง่ายที่ x เท่ากับ 0 มันให้รูปแบบวงจรนี้เป็น 1, 0, ลบ 1, 0 แล้วทำซ้ำ และการรู้ค่าของอนุพันธ์อันดับสูงๆ ทั้งหมดนั้น มีข้อมูลมากมายเกี่ยวกับโคไซน์ของ x แม้ว่าจะแทนเลขตัวเดียว แต่ x ก็เท่ากับ 0 สิ่งที่เรากำลังทำคือใช้ประโยชน์จากข้อมูลนั้น เพื่อประมาณค่าอินพุตนี้ และคุณทำได้โดยสร้างพหุนามที่มีอนุพันธ์ลำดับที่สูงกว่า ออกแบบมาให้จับคู่กับโคไซน์ ตามหลัง 1, 0, ลบ 1 0 รูปแบบวงจร ในการทำเช่นนั้น คุณแค่ทำให้สัมประสิทธิ์ของพหุนามแต่ละตัวเป็นไปตามรูปแบบเดียวกัน แต่คุณต้องหารแต่ละตัวด้วยแฟกทอเรียลที่เหมาะสม อย่างที่ผมได้กล่าวไว้ก่อนหน้านี้ นี่คือสิ่งที่ยกเลิกผลกระทบแบบเรียงซ้อนของแอปพลิเคชันกฎกำลังจำนวนมาก พหุนามที่คุณได้รับจากการหยุดกระบวนการนี้ ณ จุดใดๆ เรียกว่าพหุนามเทย์เลอร์สำหรับโคไซน์ของ x โดยทั่วไปแล้ว ถ้าเป็นนามธรรมมากกว่านั้น ถ้าเราจัดการกับฟังก์ชันอื่นที่ไม่ใช่โคไซน์ คุณจะต้องคำนวณอนุพันธ์ของมัน อนุพันธ์อันดับสองของมัน และอื่นๆ โดยได้เทอมมากเท่าที่คุณต้องการ แล้วคุณประเมินแต่ละเทอมได้ ของพวกเขาที่ x เท่ากับ 0 สำหรับการประมาณพหุนาม ค่าสัมประสิทธิ์ของแต่ละเทอม x ถึง n ควรเป็นค่าของอนุพันธ์อันดับที่ n ของฟังก์ชันที่ประเมินไว้ที่ 0 แต่หารด้วย n แฟคทอเรียล สูตรที่ค่อนข้างเป็นนามธรรมทั้งหมดนี้เป็นสิ่งที่คุณจะเห็นในข้อความหรือรายวิชาใดๆ ที่เกี่ยวข้องกับพหุนามของเทย์เลอร์ เมื่อคุณเห็นสิ่งนี้ ให้คิดกับตัวเองว่าค่าคงที่จะทำให้ค่าของพหุนามตรงกับค่าของ f เทอมถัดไปทำให้แน่ใจได้ว่าความชันของพหุนามตรงกับความชันของฟังก์ชันที่ x เท่ากับ 0 เทอมถัดไปช่วยให้แน่ใจว่าอัตราที่ความชันเปลี่ยนแปลงจะเท่ากัน ณ จุดนั้น และต่อๆ ไป ขึ้นอยู่กับจำนวนเทอมที่คุณต้องการ และยิ่งคุณเลือกเทอมมากเท่าไร การประมาณก็จะยิ่งใกล้มากขึ้นเท่านั้น แต่ข้อดีก็คือ พหุนามที่คุณจะได้จะซับซ้อนมากขึ้น และเพื่อให้ทุกอย่างเป็นภาพรวมมากขึ้น, หากคุณต้องการประมาณค่าใกล้อินพุตบางตัวที่ไม่ใช่ 0, ซึ่งเราจะเรียกว่า a, คุณต้องเขียนพหุนามนี้ในรูปของกำลังของ x ลบ a, แล้วคุณจะหาค่าอนุพันธ์ของ f ทั้งหมดได้ ที่อินพุตนั้น นี่คือลักษณะพหุนามของเทย์เลอร์โดยภาพรวมทั้งหมด การเปลี่ยนค่าของการเปลี่ยนแปลงโดยที่การประมาณนี้โอบกอดฟังก์ชันดั้งเดิม โดยที่อนุพันธ์ลำดับที่สูงกว่าจะเท่ากับค่าของฟังก์ชันดั้งเดิม ตัวอย่างที่มีความหมายที่ง่ายที่สุดตัวอย่างหนึ่งคือฟังก์ชัน e กำลัง x รอบอินพุต x เท่ากับ 0 การคำนวณอนุพันธ์นั้นดีมาก ดีเท่าที่ทำได้ เพราะอนุพันธ์ของ e กำลัง x คือตัวมันเอง ดังนั้นอนุพันธ์อันดับสองก็เป็น e กำลัง x เหมือนกัน เช่นเดียวกับอันดับสามของมัน และอื่นๆ แล้วที่จุด x เท่ากับ 0 ทั้งหมดนี้เท่ากับ 1 และนั่นหมายความว่า การประมาณพหุนามของเราควรเป็น 1 บวก 1 คูณ x บวก 1 ส่วน 2 คูณ x กำลังสอง บวก 1 ส่วน 3 แฟคทอเรียล คูณ x กำลังสาม และอื่นๆ ขึ้นอยู่กับจำนวนเทอมที่คุณต้องการ พวกนี้คือพหุนามเทย์เลอร์สำหรับ e กำลัง x โอเค เพื่อใช้เป็นพื้นฐาน ในการแสดงให้คุณเห็นว่าหัวข้อต่างๆ ของแคลคูลัสมีความเชื่อมโยงกันอย่างไร ผมขอหันไปหาเรื่องสนุกๆ เป็นวิธีที่แตกต่างไปจากเดิมอย่างสิ้นเชิงในการทำความเข้าใจเทอมลำดับที่สองของพหุนามเทย์เลอร์ แต่ ทางเรขาคณิต มันเกี่ยวข้องกับทฤษฎีบทพื้นฐานของแคลคูลัส ซึ่งฉันได้พูดถึงไปแล้วในบทที่ 1 และ 8 หากคุณต้องการทบทวนความรู้อย่างรวดเร็ว เช่นเดียวกับที่เราทำในวิดีโอเหล่านั้น ให้พิจารณาฟังก์ชันที่ให้พื้นที่ใต้กราฟระหว่างจุดซ้ายคงที่กับจุดขวาที่แปรผันได้ สิ่งที่เราจะทำตรงนี้ คือคิดถึงวิธีประมาณฟังก์ชันพื้นที่นี้ ไม่ใช่ฟังก์ชันของกราฟอย่างที่เราเคยทำมาก่อน การมุ่งเน้นไปที่พื้นที่นั้นคือสิ่งที่จะทำให้เทอมลำดับที่สองปรากฏขึ้น จำไว้ว่า ทฤษฎีบทพื้นฐานของแคลคูลัสก็คือ กราฟนี้แทนอนุพันธ์ของฟังก์ชันพื้นที่ และเป็นเพราะการขยับ dx เล็กน้อยไปทางขอบขวาของพื้นที่ จะได้พื้นที่ใหม่ประมาณ เท่ากับความสูงของกราฟคูณ dx . ",
  "model": "nmt",
  "time_range": [
   691.66,
   700.14
  ]
 },
 {
  "input": "Like I mentioned before, this is what cancels out the cascading effect of many power rule applications. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   700.14,
   707.34
  ]
 },
 {
  "input": "The polynomials you get by stopping this process at any point are called Taylor polynomials for cosine of x. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   707.34,
   713.86
  ]
 },
 {
  "input": "More generally, and hence more abstractly, if we were dealing with some other function other than cosine, you would compute its derivative, its second derivative, and so on, getting as many terms as you'd like, and you would evaluate each one of them at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   713.86,
   729.78
  ]
 },
 {
  "input": "For the polynomial approximation, the coefficient of each x to the n term should be the value of the nth derivative of the function evaluated at 0, but divided by n factorial. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   729.78,
   743.9
  ]
 },
 {
  "input": "This whole rather abstract formula is something you'll likely see in any text or course that touches on Taylor polynomials. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   743.9,
   751.94
  ]
 },
 {
  "input": "When you see it, think to yourself that the constant term ensures that the value of the polynomial matches with the value of f. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   751.94,
   759.2
  ]
 },
 {
  "input": "The next term ensures that the slope of the polynomial matches the slope of the function at x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   759.2,
   766.36
  ]
 },
 {
  "input": "The next term ensures that the rate at which the slope changes is the same at that point, and so on, depending on how many terms you want. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   766.36,
   774.68
  ]
 },
 {
  "input": "And the more terms you choose, the closer the approximation, but the tradeoff is that the polynomial you'd get would be more complicated. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   774.68,
   782.72
  ]
 },
 {
  "input": "And to make things even more general, if you wanted to approximate near some input other than 0, which we'll call a, you would write this polynomial in terms of powers of x minus a, and you would evaluate all the derivatives of f at that input, a. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   782.72,
   799.32
  ]
 },
 {
  "input": "This is what Taylor polynomials look like in their fullest generality. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   799.32,
   804.28
  ]
 },
 {
  "input": "Changing the value of a changes where this approximation is hugging the original function, where its higher order derivatives will be equal to those of the original function. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   804.28,
   816.0
  ]
 },
 {
  "input": "One of the simplest meaningful examples of this is the function e to the x around the input x equals 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   816.0,
   823.28
  ]
 },
 {
  "input": "Computing the derivatives is super nice, as nice as it gets, because the derivative of e to the x is itself, so the second derivative is also e to the x, as is its third, and so on. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   823.28,
   834.46
  ]
 },
 {
  "input": "So at the point x equals 0, all of these are equal to 1. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   834.46,
   839.24
  ]
 },
 {
  "input": "And what that means is our polynomial approximation should look like 1 plus 1 times x plus 1 over 2 times x squared plus 1 over 3 factorial times x cubed, and so on, depending on how many terms you want. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   839.24,
   859.84
  ]
 },
 {
  "input": "These are the Taylor polynomials for e to the x. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   859.84,
   862.8
  ]
 },
 {
  "input": "Ok, so with that as a foundation, in the spirit of showing you just how connected all the topics of calculus are, let me turn to something kind of fun, a completely different way to understand this second order term of the Taylor polynomials, but geometrically. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   862.8,
   881.42
  ]
 },
 {
  "input": "It's related to the fundamental theorem of calculus, which I talked about in chapters 1 and 8 if you need a quick refresher. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   881.42,
   888.2
  ]
 },
 {
  "input": "Like we did in those videos, consider a function that gives the area under some graph between a fixed left point and a variable right point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   888.2,
   896.28
  ]
 },
 {
  "input": "What we're going to do here is think about how to approximate this area function, not the function for the graph itself, like we've been doing before. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   896.28,
   905.12
  ]
 },
 {
  "input": "Focusing on that area is what's going to make the second order term pop out. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   905.12,
   909.92
  ]
 },
 {
  "input": "Remember, the fundamental theorem of calculus is that this graph itself represents the derivative of the area function, and it's because a slight nudge dx to the right bound of the area gives a new bit of area approximately equal to the height of the graph times dx. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   909.92,
   930.48
  ]
 },
 {
  "input": "That approximation is increasingly accurate for smaller and smaller choices of dx. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   930.48,
   936.06
  ]
 },
 {
  "input": "But if you wanted to be more accurate about this change in area, given some change in x that isn't meant to approach 0, you would have to take into account this portion right here, which is approximately a triangle. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   936.06,
   948.86
  ]
 },
 {
  "input": "Let's name the starting input a, and the nudged input above it x, so that change is x-a. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   948.86,
   958.62
  ]
 },
 {
  "input": "The base of that little triangle is that change, x-a, and its height is the slope of the graph times x-a. ",
  "translatedText": "การประมาณนั้นแม่นยำมากขึ้นสำหรับตัวเลือก dx ที่น้อยลงเรื่อยๆ แต่ถ้าคุณอยากให้แม่นยำมากขึ้นเกี่ยวกับการเปลี่ยนแปลงพื้นที่นี้ เมื่อพิจารณาการเปลี่ยนแปลงของ x ที่ไม่ได้หมายถึงเข้าใกล้ 0 คุณจะต้องคำนึงถึงส่วนนี้ตรงนี้ ซึ่งมีขนาดประมาณสามเหลี่ยม ลองตั้งชื่ออินพุตเริ่มต้น a และอินพุตที่เขยิบไว้ด้านบน x เพื่อให้การเปลี่ยนแปลงนั้นคือ xa ฐานของสามเหลี่ยมเล็กๆ นั้นคือการเปลี่ยนแปลง xa และความสูงของมันคือความชันของกราฟคูณ xa เนื่องจากกราฟนี้เป็นอนุพันธ์ของฟังก์ชันพื้นที่ ความชันของกราฟจึงเป็นอนุพันธ์อันดับสองของฟังก์ชันพื้นที่ ซึ่งประเมินที่อินพุต a ดังนั้นพื้นที่ของสามเหลี่ยมนี้ 1 ครึ่งฐานคูณสูง เท่ากับ 1 ครึ่งหนึ่งของอนุพันธ์อันดับสองของฟังก์ชันพื้นที่นี้ หาค่าที่ a คูณด้วย xa กำลังสอง และนี่คือสิ่งที่คุณเห็นจากพหุนามเทย์เลอร์พอดี ถ้าคุณรู้ข้อมูลอนุพันธ์ต่างๆ เกี่ยวกับพื้นที่นี้ทำงานที่จุด a คุณจะประมาณพื้นที่ที่จุด x ได้อย่างไร? ",
  "model": "nmt",
  "time_range": [
   958.62,
   968.54
  ]
 },
 {
  "input": "Since this graph is the derivative of the area function, its slope is the second derivative of the area function, evaluated at the input a. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   968.54,
   978.58
  ]
 },
 {
  "input": "So the area of this triangle, 1 half base times height, is 1 half times the second derivative of this area function, evaluated at a, multiplied by x-a squared. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   978.58,
   991.3
  ]
 },
 {
  "input": "And this is exactly what you would see with a Taylor polynomial. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   991.3,
   995.18
  ]
 },
 {
  "input": "If you knew the various derivative information about this area function at the point a, how would you approximate the area at the point x? ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   995.18,
   1006.04
  ]
 },
 {
  "input": "You have to include all that area up to a, f of a, plus the area of this rectangle here, which is the first derivative, times x-a, plus the area of that little triangle, which is 1 half times the second derivative, times x-a squared. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1006.04,
   1022.88
  ]
 },
 {
  "input": "I really like this, because even though it looks a bit messy all written out, each one of the terms has a very clear meaning that you can just point to on the diagram. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1022.88,
   1033.7
  ]
 },
 {
  "input": "If you wanted, we could call it an end here, and you would have a phenomenally useful tool for approximations with these Taylor polynomials. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1033.7,
   1041.7
  ]
 },
 {
  "input": "But if you're thinking like a mathematician, one question you might ask is whether or not it makes sense to never stop and just add infinitely many terms. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1041.7,
   1051.74
  ]
 },
 {
  "input": "In math, an infinite sum is called a series, so even though one of these approximations with finitely many terms is called a Taylor polynomial, adding all infinitely many terms gives what's called a Taylor series. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1051.74,
   1065.72
  ]
 },
 {
  "input": "You have to be really careful with the idea of an infinite series, because it doesn't actually make sense to add infinitely many things, you can only hit the plus button on the calculator so many times. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1065.72,
   1077.84
  ]
 },
 {
  "input": "But if you have a series where adding more and more of the terms, which makes sense at each step, gets you increasingly close to some specific value, you say that the series converges to that value. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1077.84,
   1090.8
  ]
 },
 {
  "input": "Or if you're comfortable extending the definition of equality to include this kind of series convergence, you'd say that the series as a whole, this infinite sum, equals the value that it's converging to. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1090.8,
   1103.88
  ]
 },
 {
  "input": "For example, look at the Taylor polynomial for e to the x, and plug in some input, like x equals 1. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1103.88,
   1111.28
  ]
 },
 {
  "input": "As you add more and more polynomial terms, the total sum gets closer and closer to the value e, so you say that this infinite series converges to the number e, or what's saying the same thing, that it equals the number e. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1111.28,
   1128.08
  ]
 },
 {
  "input": "In fact, it turns out that if you plug in any other value of x, like x equals 2, and look at the value of the higher and higher order Taylor polynomials at this value, they will converge towards e to the x, which is e squared. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1128.08,
   1145.32
  ]
 },
 {
  "input": "This is true for any input, no matter how far away from 0 it is, even though these Taylor polynomials are constructed only from derivative information gathered at the input 0. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1145.32,
   1158.54
  ]
 },
 {
  "input": "In a case like this, we say that e to the x equals its own Taylor series at all inputs x, which is kind of a magical thing to have happen. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1158.54,
   1169.0
  ]
 },
 {
  "input": "Even though this is also true for a couple other important functions, like sine and cosine, sometimes these series only converge within a certain range around the input whose derivative information you're using. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1169.0,
   1181.64
  ]
 },
 {
  "input": "If you worked out the Taylor series for the natural log of x around the input x equals 1, which is built by evaluating the higher order derivatives of the natural log of x at x equals 1, this is what it would look like. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1181.64,
   1196.34
  ]
 },
 {
  "input": "When you plug in an input between 0 and 2, adding more and more terms of this series will indeed get you closer and closer to the natural log of that input. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1196.34,
   1206.46
  ]
 },
 {
  "input": "But outside of that range, even by just a little bit, the series fails to approach anything. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1206.46,
   1212.58
  ]
 },
 {
  "input": "As you add on more and more terms, the sum bounces back and forth wildly. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1212.58,
   1218.26
  ]
 },
 {
  "input": "It does not, as you might expect, approach the natural log of that value, even though the natural log of x is perfectly well defined for inputs above 2. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1218.26,
   1228.64
  ]
 },
 {
  "input": "In some sense, the derivative information of ln of x at x equals 1 doesn't propagate out that far. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1228.64,
   1236.74
  ]
 },
 {
  "input": "In a case like this, where adding more terms of the series doesn't approach anything, you say the series diverges. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1236.74,
   1244.28
  ]
 },
 {
  "input": "And that maximum distance between the input you're approximating near and points where the outputs of these polynomials actually converge is called the radius of convergence for the Taylor series. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1244.28,
   1257.04
  ]
 },
 {
  "input": "There remains more to learn about Taylor series. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1257.04,
   1259.62
  ]
 },
 {
  "input": "There are many use cases, tactics for placing bounds on the error of these approximations, tests for understanding when series do and don't converge, and for that matter, there remains more to learn about calculus as a whole and the countless topics not touched by this series. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1259.62,
   1275.62
  ]
 },
 {
  "input": "The goal with these videos is to give you the fundamental intuitions that make you feel confident and efficient in learning more on your own, and potentially even rediscovering more of the topic for yourself. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1275.62,
   1288.2
  ]
 },
 {
  "input": "In the case of Taylor series, the fundamental intuition to keep in mind as you explore more of what there is, is that they translate derivative information at a single point to approximation information around that point. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1288.2,
   1304.32
  ]
 },
 {
  "input": "Thank you once again to everybody who supported this series. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1304.32,
   1307.32
  ]
 },
 {
  "input": "The next series like it will be on probability, and if you want early access as those videos are made, you know where to go. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   1307.32,
   1313.0
  ]
 }
]