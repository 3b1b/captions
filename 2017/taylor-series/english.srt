1
00:00:14,912 --> 00:00:18,600
When I first learned about Taylor series, I definitely didn't appreciate just how

2
00:00:18,600 --> 00:00:20,180
important they are.

3
00:00:20,180 --> 00:00:24,800
But time and time again they come up in math, physics, and many fields of engineering because

4
00:00:24,800 --> 00:00:30,080
they're one of the most powerful tools that math has to offer for approximating functions.

5
00:00:30,080 --> 00:00:34,000
I think one of the first times this clicked for me as a student was not in a calculus

6
00:00:34,000 --> 00:00:35,960
class, but a physics class.

7
00:00:35,960 --> 00:00:40,560
We were studying a certain problem that had to do with the potential energy of a pendulum,

8
00:00:40,560 --> 00:00:45,000
and for that you need an expression for how high the weight of the pendulum is above its

9
00:00:45,000 --> 00:00:49,720
lowest point, and when you work that out it comes out to be proportional to 1 minus the

10
00:00:49,720 --> 00:00:54,080
cosine of the angle between the pendulum and the vertical.

11
00:00:54,080 --> 00:00:57,840
The specifics of the problem we were trying to solve are beyond the point here, but what

12
00:00:57,840 --> 00:01:03,360
I'll say is that this cosine function made the problem awkward and unwieldy, and made

13
00:01:03,360 --> 00:01:07,680
it less clear how pendulums relate to other oscillating phenomena.

14
00:01:07,680 --> 00:01:14,440
But if you approximate cosine of theta as 1 minus theta squared over 2, everything just

15
00:01:14,440 --> 00:01:17,080
fell into place much more easily.

16
00:01:17,080 --> 00:01:21,360
If you've never seen anything like this before, an approximation like that might seem

17
00:01:21,360 --> 00:01:23,900
completely out of left field.

18
00:01:23,900 --> 00:01:29,440
If you graph cosine of theta along with this function, 1 minus theta squared over 2, they

19
00:01:29,440 --> 00:01:34,720
do seem rather close to each other, at least for small angles near 0, but how would you

20
00:01:34,720 --> 00:01:41,360
even think to make this approximation, and how would you find that particular quadratic?

21
00:01:41,360 --> 00:01:46,220
The study of Taylor series is largely about taking non-polynomial functions and finding

22
00:01:46,220 --> 00:01:49,660
polynomials that approximate them near some input.

23
00:01:49,820 --> 00:01:53,940
The motive here is that polynomials tend to be much easier to deal with than other functions.

24
00:01:53,940 --> 00:01:58,420
They're easier to compute, easier to take derivatives, easier to integrate, just all

25
00:01:58,420 --> 00:02:00,700
around more friendly.

26
00:02:00,700 --> 00:02:05,400
So let's take a look at that function, cosine of x, and really take a moment to think about

27
00:02:05,400 --> 00:02:11,220
how you might construct a quadratic approximation near x equals 0.

28
00:02:11,220 --> 00:02:18,340
That is, among all of the possible polynomials that look like c0 plus c1 times x plus c2

29
00:02:18,340 --> 00:02:24,860
times x squared, for some choice of these constants, c0, c1, and c2, find the one that

30
00:02:24,860 --> 00:02:30,940
most resembles cosine of x near x equals 0, whose graph kind of spoons with the graph

31
00:02:30,940 --> 00:02:33,500
of cosine x at that point.

32
00:02:33,500 --> 00:02:40,020
Well, first of all, at the input 0, the value of cosine of x is 1, so if our approximation

33
00:02:40,020 --> 00:02:45,860
is going to be any good at all, it should also equal 1 at the input x equals 0.

34
00:02:45,860 --> 00:02:53,260
Plugging in 0 just results in whatever c0 is, so we can set that equal to 1.

35
00:02:53,260 --> 00:02:57,580
This leaves us free to choose constants c1 and c2 to make this approximation as good

36
00:02:57,580 --> 00:03:01,860
as we can, but nothing we do with them is going to change the fact that the polynomial

37
00:03:01,860 --> 00:03:05,580
equals 1 at x equals 0.

38
00:03:05,580 --> 00:03:10,220
It would also be good if our approximation had the same tangent slope as cosine x at

39
00:03:10,220 --> 00:03:11,700
this point of interest.

40
00:03:11,740 --> 00:03:16,740
Otherwise, the approximation drifts away from the cosine graph much faster than it needs to.

41
00:03:18,300 --> 00:03:24,100
The derivative of cosine is negative sine, and at x equals 0, that equals 0, meaning

42
00:03:24,100 --> 00:03:27,500
the tangent line is perfectly flat.

43
00:03:27,500 --> 00:03:33,260
On the other hand, when you work out the derivative of our quadratic, you get c1 plus 2 times

44
00:03:33,260 --> 00:03:35,240
c2 times x.

45
00:03:35,240 --> 00:03:40,280
At x equals 0, this just equals whatever we choose for c1.

46
00:03:40,280 --> 00:03:45,440
So this constant c1 has complete control over the derivative of our approximation around

47
00:03:45,440 --> 00:03:47,200
x equals 0.

48
00:03:47,200 --> 00:03:53,480
Setting it equal to 0 ensures that our approximation also has a flat tangent line at this point.

49
00:03:53,480 --> 00:03:58,760
This leaves us free to change c2, but the value and slope of our polynomial at x equals

50
00:03:58,760 --> 00:04:04,360
0 are locked in place to match that of cosine.

51
00:04:04,360 --> 00:04:08,940
The final thing to take advantage of is the fact that the cosine graph curves downward

52
00:04:08,980 --> 00:04:13,460
above x equals 0, it has a negative second derivative.

53
00:04:13,460 --> 00:04:17,820
Or in other words, even though the rate of change is 0 at that point, the rate of change

54
00:04:17,820 --> 00:04:21,300
itself is decreasing around that point.

55
00:04:21,300 --> 00:04:26,980
Specifically, since its derivative is negative sine of x, its second derivative is negative

56
00:04:26,980 --> 00:04:33,140
cosine of x, and at x equals 0, that equals negative 1.

57
00:04:33,140 --> 00:04:37,020
Now in the same way that we wanted the derivative of our approximation to match that of the

58
00:04:37,100 --> 00:04:41,980
cosine, so that their values wouldn't drift apart needlessly quickly, making sure that

59
00:04:41,980 --> 00:04:47,260
their second derivatives match will ensure that they curve at the same rate, that the

60
00:04:47,260 --> 00:04:52,260
slope of our polynomial doesn't drift away from the slope of cosine x any more quickly

61
00:04:52,260 --> 00:04:54,500
than it needs to.

62
00:04:54,500 --> 00:04:59,280
Pulling up the same derivative we had before, and then taking its derivative, we see that

63
00:04:59,280 --> 00:05:05,020
the second derivative of this polynomial is exactly 2 times c2.

64
00:05:05,020 --> 00:05:10,620
So to make sure that this second derivative also equals negative 1 at x equals 0, 2 times

65
00:05:10,620 --> 00:05:16,820
c2 has to be negative 1, meaning c2 itself should be negative 1 half.

66
00:05:16,820 --> 00:05:23,180
And this gives us the approximation 1 plus 0x minus 1 half x squared.

67
00:05:23,180 --> 00:05:29,460
And to get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial,

68
00:05:29,460 --> 00:05:32,860
you'd estimate it to be 0.995.

69
00:05:32,860 --> 00:05:36,020
And this is the true value of cosine of 0.1.

70
00:05:36,020 --> 00:05:40,420
It's a really good approximation!

71
00:05:40,420 --> 00:05:43,000
Take a moment to reflect on what just happened.

72
00:05:43,000 --> 00:05:49,540
You had 3 degrees of freedom with this quadratic approximation, the constants c0, c1, and c2.

73
00:05:49,540 --> 00:05:54,520
c0 was responsible for making sure that the output of the approximation matches that of

74
00:05:54,520 --> 00:05:57,180
cosine x at x equals 0.

75
00:05:57,180 --> 00:06:05,100
c1 was in charge of making sure that the derivatives match at that point, and c2 was

76
00:06:05,100 --> 00:06:09,420
responsible for making sure that the second derivatives match up.

77
00:06:09,420 --> 00:06:14,820
This ensures that the way your approximation changes as you move away from x equals 0,

78
00:06:14,820 --> 00:06:19,620
and the way that the rate of change itself changes, is as similar as possible to the

79
00:06:19,620 --> 00:06:24,340
behavior of cosine x, given the amount of control you have.

80
00:06:24,340 --> 00:06:28,860
You could give yourself more control by allowing more terms in your polynomial and matching

81
00:06:28,860 --> 00:06:30,860
higher order derivatives.

82
00:06:30,860 --> 00:06:36,580
For example, let's say you added on the term c3 times x3 for some constant c3.

83
00:06:36,580 --> 00:06:42,860
In that case, if you take the third derivative of a cubic polynomial, anything that's quadratic

84
00:06:42,860 --> 00:06:45,700
or smaller goes to 0.

85
00:06:45,700 --> 00:06:52,420
As for that last term, after 3 iterations of the power rule, it looks like 1 times 2

86
00:06:52,420 --> 00:06:56,700
times 3 times c3.

87
00:06:56,700 --> 00:07:01,860
On the other hand, the third derivative of cosine x comes out to sine x, which equals

88
00:07:01,860 --> 00:07:04,020
0 at x equals 0.

89
00:07:04,020 --> 00:07:09,920
So to make sure that the third derivatives match, the constant c3 should be 0.

90
00:07:09,920 --> 00:07:15,940
Or in other words, not only is 1 minus 1 half x2 the best possible quadratic approximation

91
00:07:15,940 --> 00:07:21,580
of cosine, it's also the best possible cubic approximation.

92
00:07:21,580 --> 00:07:28,060
You can make an improvement by adding on a fourth order term, c4 times x to the fourth.

93
00:07:28,060 --> 00:07:34,340
The fourth derivative of cosine is itself, which equals 1 at x equals 0.

94
00:07:34,340 --> 00:07:38,260
And what's the fourth derivative of our polynomial with this new term?

95
00:07:38,260 --> 00:07:43,160
Well, when you keep applying the power rule over and over, with those exponents all hopping

96
00:07:43,160 --> 00:07:50,240
down in front, you end up with 1 times 2 times 3 times 4 times c4, which is 24 times

97
00:07:50,240 --> 00:07:51,700
c4.

98
00:07:51,700 --> 00:07:58,280
So if we want this to match the fourth derivative of cosine x, which is 1, c4 has to be 1 over

99
00:07:58,280 --> 00:07:59,280
24.

100
00:07:59,280 --> 00:08:06,660
And indeed, the polynomial 1 minus 1 half x2 plus 1 24 times x to the fourth, which

101
00:08:06,660 --> 00:08:13,820
looks like this, is a very close approximation for cosine x around x equals 0.

102
00:08:13,820 --> 00:08:18,540
In any physics problem involving the cosine of a small angle, for example, predictions

103
00:08:18,540 --> 00:08:23,520
would be almost unnoticeably different if you substituted this polynomial for cosine

104
00:08:23,520 --> 00:08:26,220
of x.

105
00:08:26,220 --> 00:08:30,620
Now take a step back and notice a few things happening with this process.

106
00:08:30,620 --> 00:08:35,060
First of all, factorial terms come up very naturally in this process.

107
00:08:35,060 --> 00:08:39,500
When you take n successive derivatives of the function x to the n, letting the power

108
00:08:39,500 --> 00:08:46,580
rule keep cascading on down, what you'll be left with is 1 times 2 times 3 on and on

109
00:08:46,580 --> 00:08:49,460
and on up to whatever n is.

110
00:08:49,460 --> 00:08:53,780
So you don't simply set the coefficients of the polynomial equal to whatever derivative

111
00:08:53,780 --> 00:08:54,780
you want.

112
00:08:54,780 --> 00:08:59,500
You have to divide by the appropriate factorial to cancel out this effect.

113
00:08:59,500 --> 00:09:05,260
For example, that x to the fourth coefficient was the fourth derivative of cosine, 1, but

114
00:09:05,260 --> 00:09:09,540
divided by 4 factorial, 24.

115
00:09:09,540 --> 00:09:14,500
The second thing to notice is that adding on new terms, like this c4 times x to the

116
00:09:14,500 --> 00:09:20,140
fourth, doesn't mess up what the old terms should be, and that's really important.

117
00:09:20,140 --> 00:09:25,740
For example, the second derivative of this polynomial at x equals 0 is still equal to

118
00:09:25,740 --> 00:09:31,060
2 times the second coefficient, even after you introduce higher order terms.

119
00:09:31,060 --> 00:09:35,860
And it's because we're plugging in x equals 0, so the second derivative of any higher

120
00:09:35,860 --> 00:09:40,820
order term, which all include an x, will just wash away.

121
00:09:40,820 --> 00:09:45,780
And the same goes for any other derivative, which is why each derivative of a polynomial

122
00:09:45,780 --> 00:09:52,680
at x equals 0 is controlled by one and only one of the coefficients.

123
00:09:52,680 --> 00:09:58,220
If instead you were approximating near an input other than 0, like x equals pi, in order

124
00:09:58,220 --> 00:10:02,320
to get the same effect, you would have to write your polynomial in terms of powers of

125
00:10:02,320 --> 00:10:06,480
x minus pi, or whatever input you're looking at.

126
00:10:06,480 --> 00:10:10,760
This makes it look noticeably more complicated, but all we're doing is making sure that

127
00:10:10,760 --> 00:10:17,140
the point pi looks and behaves like 0, so that plugging in x equals pi will result in

128
00:10:17,140 --> 00:10:22,700
a lot of nice cancellation that leaves only one constant.

129
00:10:22,700 --> 00:10:27,320
And finally, on a more philosophical level, notice how what we're doing here is basically

130
00:10:27,320 --> 00:10:33,740
taking information about higher order derivatives of a function at a single point, and translating

131
00:10:33,740 --> 00:10:41,420
that into information about the value of the function near that point.

132
00:10:41,420 --> 00:10:44,580
You can take as many derivatives of cosine as you want.

133
00:10:44,580 --> 00:10:49,460
It follows this nice cyclic pattern, cosine of x, negative sine of x, negative cosine,

134
00:10:49,460 --> 00:10:52,380
sine, and then repeat.

135
00:10:52,380 --> 00:10:56,900
And the value of each one of these is easy to compute at x equals 0, it gives this cyclic

136
00:10:56,900 --> 00:11:02,060
pattern 1, 0, negative 1, 0, and then repeat.

137
00:11:02,060 --> 00:11:06,660
And knowing the values of all those higher order derivatives is a lot of information

138
00:11:06,660 --> 00:11:14,540
about cosine of x, even though it only involves plugging in a single number, x equals 0.

139
00:11:14,540 --> 00:11:19,260
So what we're doing is leveraging that information to get an approximation around

140
00:11:19,260 --> 00:11:24,740
this input, and you do it by creating a polynomial whose higher order derivatives are designed

141
00:11:24,740 --> 00:11:31,660
to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern.

142
00:11:31,660 --> 00:11:36,900
And to do that, you just make each coefficient of the polynomial follow that same pattern,

143
00:11:36,900 --> 00:11:40,140
but you have to divide each one by the appropriate factorial.

144
00:11:40,180 --> 00:11:44,660
Like I mentioned before, this is what cancels out the cascading effect of many power rule

145
00:11:44,660 --> 00:11:47,340
applications.

146
00:11:47,340 --> 00:11:52,100
The polynomials you get by stopping this process at any point are called Taylor polynomials

147
00:11:52,100 --> 00:11:53,860
for cosine of x.

148
00:11:53,860 --> 00:11:58,440
More generally, and hence more abstractly, if we were dealing with some other function

149
00:11:58,440 --> 00:12:03,860
other than cosine, you would compute its derivative, its second derivative, and so on, getting

150
00:12:03,860 --> 00:12:09,780
as many terms as you'd like, and you would evaluate each one of them at x equals 0.

151
00:12:09,820 --> 00:12:16,660
For the polynomial approximation, the coefficient of each x to the n term should be the value

152
00:12:16,660 --> 00:12:23,900
of the nth derivative of the function evaluated at 0, but divided by n factorial.

153
00:12:23,900 --> 00:12:29,400
This whole rather abstract formula is something you'll likely see in any text or course

154
00:12:29,400 --> 00:12:31,940
that touches on Taylor polynomials.

155
00:12:31,940 --> 00:12:36,420
When you see it, think to yourself that the constant term ensures that the value of the

156
00:12:36,420 --> 00:12:39,200
polynomial matches with the value of f.

157
00:12:39,280 --> 00:12:44,600
The next term ensures that the slope of the polynomial matches the slope of the function

158
00:12:44,600 --> 00:12:46,360
at x equals 0.

159
00:12:46,360 --> 00:12:51,280
The next term ensures that the rate at which the slope changes is the same at that point,

160
00:12:51,280 --> 00:12:54,680
and so on, depending on how many terms you want.

161
00:12:54,680 --> 00:12:58,400
And the more terms you choose, the closer the approximation, but the tradeoff is that

162
00:12:58,400 --> 00:13:02,720
the polynomial you'd get would be more complicated.

163
00:13:02,720 --> 00:13:07,040
And to make things even more general, if you wanted to approximate near some input other

164
00:13:07,080 --> 00:13:13,080
than 0, which we'll call a, you would write this polynomial in terms of powers of x minus

165
00:13:13,080 --> 00:13:19,320
a, and you would evaluate all the derivatives of f at that input, a.

166
00:13:19,320 --> 00:13:24,280
This is what Taylor polynomials look like in their fullest generality.

167
00:13:24,280 --> 00:13:29,600
Changing the value of a changes where this approximation is hugging the original function,

168
00:13:29,600 --> 00:13:36,000
where its higher order derivatives will be equal to those of the original function.

169
00:13:36,040 --> 00:13:40,560
One of the simplest meaningful examples of this is the function e to the x around the

170
00:13:40,560 --> 00:13:43,280
input x equals 0.

171
00:13:43,280 --> 00:13:47,520
Computing the derivatives is super nice, as nice as it gets, because the derivative of

172
00:13:47,520 --> 00:13:53,180
e to the x is itself, so the second derivative is also e to the x, as is its third, and so

173
00:13:53,180 --> 00:13:54,460
on.

174
00:13:54,460 --> 00:13:59,240
So at the point x equals 0, all of these are equal to 1.

175
00:13:59,240 --> 00:14:09,000
And what that means is our polynomial approximation should look like 1 plus 1 times x plus 1 over

176
00:14:09,000 --> 00:14:17,480
2 times x squared plus 1 over 3 factorial times x cubed, and so on, depending on how

177
00:14:17,480 --> 00:14:19,840
many terms you want.

178
00:14:19,840 --> 00:14:22,800
These are the Taylor polynomials for e to the x.

179
00:14:22,800 --> 00:14:31,360
Ok, so with that as a foundation, in the spirit of showing you just how connected all the

180
00:14:31,360 --> 00:14:36,280
topics of calculus are, let me turn to something kind of fun, a completely different way to

181
00:14:36,280 --> 00:14:41,420
understand this second order term of the Taylor polynomials, but geometrically.

182
00:14:41,420 --> 00:14:45,160
It's related to the fundamental theorem of calculus, which I talked about in chapters

183
00:14:45,160 --> 00:14:48,200
1 and 8 if you need a quick refresher.

184
00:14:48,200 --> 00:14:53,340
Like we did in those videos, consider a function that gives the area under some graph between

185
00:14:53,340 --> 00:14:56,280
a fixed left point and a variable right point.

186
00:14:56,280 --> 00:15:01,480
What we're going to do here is think about how to approximate this area function, not

187
00:15:01,480 --> 00:15:05,120
the function for the graph itself, like we've been doing before.

188
00:15:05,120 --> 00:15:09,920
Focusing on that area is what's going to make the second order term pop out.

189
00:15:09,920 --> 00:15:16,460
Remember, the fundamental theorem of calculus is that this graph itself represents the derivative

190
00:15:16,460 --> 00:15:21,780
of the area function, and it's because a slight nudge dx to the right bound of the

191
00:15:21,780 --> 00:15:30,480
area gives a new bit of area approximately equal to the height of the graph times dx.

192
00:15:30,480 --> 00:15:36,060
That approximation is increasingly accurate for smaller and smaller choices of dx.

193
00:15:36,060 --> 00:15:39,700
But if you wanted to be more accurate about this change in area, given some change in

194
00:15:39,700 --> 00:15:44,900
x that isn't meant to approach 0, you would have to take into account this portion right

195
00:15:44,900 --> 00:15:48,860
here, which is approximately a triangle.

196
00:15:48,860 --> 00:15:56,460
Let's name the starting input a, and the nudged input above it x, so that change is

197
00:15:56,460 --> 00:15:58,620
x-a.

198
00:15:58,620 --> 00:16:06,140
The base of that little triangle is that change, x-a, and its height is the slope of the graph

199
00:16:06,140 --> 00:16:08,540
times x-a.

200
00:16:08,540 --> 00:16:14,140
Since this graph is the derivative of the area function, its slope is the second derivative

201
00:16:14,180 --> 00:16:18,580
of the area function, evaluated at the input a.

202
00:16:18,580 --> 00:16:24,140
So the area of this triangle, 1 half base times height, is 1 half times the second derivative

203
00:16:24,140 --> 00:16:31,300
of this area function, evaluated at a, multiplied by x-a squared.

204
00:16:31,300 --> 00:16:35,180
And this is exactly what you would see with a Taylor polynomial.

205
00:16:35,180 --> 00:16:40,920
If you knew the various derivative information about this area function at the point a, how

206
00:16:40,920 --> 00:16:46,040
would you approximate the area at the point x?

207
00:16:46,040 --> 00:16:52,480
You have to include all that area up to a, f of a, plus the area of this rectangle here,

208
00:16:52,480 --> 00:16:58,240
which is the first derivative, times x-a, plus the area of that little triangle, which

209
00:16:58,240 --> 00:17:02,880
is 1 half times the second derivative, times x-a squared.

210
00:17:02,880 --> 00:17:07,220
I really like this, because even though it looks a bit messy all written out, each one

211
00:17:07,220 --> 00:17:13,700
of the terms has a very clear meaning that you can just point to on the diagram.

212
00:17:13,700 --> 00:17:17,720
If you wanted, we could call it an end here, and you would have a phenomenally useful tool

213
00:17:17,720 --> 00:17:21,700
for approximations with these Taylor polynomials.

214
00:17:21,700 --> 00:17:26,460
But if you're thinking like a mathematician, one question you might ask is whether or not

215
00:17:26,460 --> 00:17:31,740
it makes sense to never stop and just add infinitely many terms.

216
00:17:31,740 --> 00:17:37,040
In math, an infinite sum is called a series, so even though one of these approximations

217
00:17:37,040 --> 00:17:42,880
with finitely many terms is called a Taylor polynomial, adding all infinitely many terms

218
00:17:42,880 --> 00:17:45,720
gives what's called a Taylor series.

219
00:17:45,720 --> 00:17:49,760
You have to be really careful with the idea of an infinite series, because it doesn't

220
00:17:49,760 --> 00:17:54,400
actually make sense to add infinitely many things, you can only hit the plus button on

221
00:17:54,400 --> 00:17:57,840
the calculator so many times.

222
00:17:57,840 --> 00:18:01,800
But if you have a series where adding more and more of the terms, which makes sense at

223
00:18:01,800 --> 00:18:08,000
each step, gets you increasingly close to some specific value, you say that the series

224
00:18:08,000 --> 00:18:10,800
converges to that value.

225
00:18:10,800 --> 00:18:15,440
Or if you're comfortable extending the definition of equality to include this kind of series

226
00:18:15,440 --> 00:18:21,240
convergence, you'd say that the series as a whole, this infinite sum, equals the value

227
00:18:21,240 --> 00:18:23,880
that it's converging to.

228
00:18:23,880 --> 00:18:29,320
For example, look at the Taylor polynomial for e to the x, and plug in some input, like

229
00:18:29,320 --> 00:18:31,280
x equals 1.

230
00:18:31,280 --> 00:18:37,060
As you add more and more polynomial terms, the total sum gets closer and closer to the

231
00:18:37,060 --> 00:18:44,000
value e, so you say that this infinite series converges to the number e, or what's saying

232
00:18:44,000 --> 00:18:48,080
the same thing, that it equals the number e.

233
00:18:48,080 --> 00:18:53,800
In fact, it turns out that if you plug in any other value of x, like x equals 2, and

234
00:18:53,800 --> 00:18:59,200
look at the value of the higher and higher order Taylor polynomials at this value, they

235
00:18:59,200 --> 00:19:05,320
will converge towards e to the x, which is e squared.

236
00:19:05,320 --> 00:19:11,340
This is true for any input, no matter how far away from 0 it is, even though these Taylor

237
00:19:11,340 --> 00:19:18,540
polynomials are constructed only from derivative information gathered at the input 0.

238
00:19:18,540 --> 00:19:24,320
In a case like this, we say that e to the x equals its own Taylor series at all inputs

239
00:19:24,320 --> 00:19:29,000
x, which is kind of a magical thing to have happen.

240
00:19:29,000 --> 00:19:34,280
Even though this is also true for a couple other important functions, like sine and cosine,

241
00:19:34,280 --> 00:19:39,320
sometimes these series only converge within a certain range around the input whose derivative

242
00:19:39,320 --> 00:19:41,640
information you're using.

243
00:19:41,640 --> 00:19:46,640
If you worked out the Taylor series for the natural log of x around the input x equals

244
00:19:46,640 --> 00:19:52,380
1, which is built by evaluating the higher order derivatives of the natural log of x

245
00:19:52,380 --> 00:19:56,340
at x equals 1, this is what it would look like.

246
00:19:56,340 --> 00:20:01,500
When you plug in an input between 0 and 2, adding more and more terms of this series

247
00:20:01,500 --> 00:20:06,460
will indeed get you closer and closer to the natural log of that input.

248
00:20:06,460 --> 00:20:12,580
But outside of that range, even by just a little bit, the series fails to approach anything.

249
00:20:12,580 --> 00:20:18,260
As you add on more and more terms, the sum bounces back and forth wildly.

250
00:20:18,260 --> 00:20:23,620
It does not, as you might expect, approach the natural log of that value, even though

251
00:20:23,620 --> 00:20:28,640
the natural log of x is perfectly well defined for inputs above 2.

252
00:20:28,640 --> 00:20:34,520
In some sense, the derivative information of ln of x at x equals 1 doesn't propagate

253
00:20:34,520 --> 00:20:36,740
out that far.

254
00:20:36,740 --> 00:20:41,240
In a case like this, where adding more terms of the series doesn't approach anything,

255
00:20:41,240 --> 00:20:44,280
you say the series diverges.

256
00:20:44,280 --> 00:20:48,640
And that maximum distance between the input you're approximating near and points where

257
00:20:48,640 --> 00:20:54,380
the outputs of these polynomials actually converge is called the radius of convergence

258
00:20:54,380 --> 00:20:57,040
for the Taylor series.

259
00:20:57,040 --> 00:20:59,620
There remains more to learn about Taylor series.

260
00:20:59,620 --> 00:21:04,740
There are many use cases, tactics for placing bounds on the error of these approximations,

261
00:21:04,740 --> 00:21:09,540
tests for understanding when series do and don't converge, and for that matter, there

262
00:21:09,540 --> 00:21:13,760
remains more to learn about calculus as a whole and the countless topics not touched

263
00:21:13,760 --> 00:21:15,620
by this series.

264
00:21:15,620 --> 00:21:19,960
The goal with these videos is to give you the fundamental intuitions that make you feel

265
00:21:19,960 --> 00:21:25,440
confident and efficient in learning more on your own, and potentially even rediscovering

266
00:21:25,440 --> 00:21:28,200
more of the topic for yourself.

267
00:21:28,200 --> 00:21:33,080
In the case of Taylor series, the fundamental intuition to keep in mind as you explore more

268
00:21:33,080 --> 00:21:39,260
of what there is, is that they translate derivative information at a single point to approximation

269
00:21:39,260 --> 00:21:44,320
information around that point.

270
00:21:44,320 --> 00:21:47,320
Thank you once again to everybody who supported this series.

271
00:21:47,320 --> 00:21:51,540
The next series like it will be on probability, and if you want early access as those videos

272
00:21:51,540 --> 00:21:53,000
are made, you know where to go.

