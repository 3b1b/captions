1
00:00:14,640 --> 00:00:18,660
When I first learned about Taylor series, I definitely didn't appreciate just how

2
00:00:18,660 --> 00:00:19,700
important they are.

3
00:00:20,120 --> 00:00:24,680
But time and time again they come up in math, physics, and many fields of engineering because

4
00:00:24,680 --> 00:00:29,180
they're one of the most powerful tools that math has to offer for approximating functions.

5
00:00:30,000 --> 00:00:33,660
I think one of the first times this clicked for me as a student was not in a calculus

6
00:00:33,660 --> 00:00:35,420
class but a physics class.

7
00:00:35,840 --> 00:00:39,780
We were studying a certain problem that had to do with the potential energy of a pendulum,

8
00:00:40,280 --> 00:00:45,060
and for that you need an expression for how high the weight of the pendulum is above its

9
00:00:45,060 --> 00:00:49,860
lowest point, and when you work that out it comes out to be proportional to 1 minus the

10
00:00:49,860 --> 00:00:53,000
cosine of the angle between the pendulum and the vertical.

11
00:00:53,580 --> 00:00:57,800
The specifics of the problem we were trying to solve are beyond the point here, but what

12
00:00:57,800 --> 00:01:03,360
I'll say is that this cosine function made the problem awkward and unwieldy, and made

13
00:01:03,360 --> 00:01:06,520
it less clear how pendulums relate to other oscillating phenomena.

14
00:01:07,460 --> 00:01:14,460
But if you approximate cosine of theta as 1 minus theta squared over 2, everything just

15
00:01:14,460 --> 00:01:15,960
fell into place much more easily.

16
00:01:16,660 --> 00:01:21,240
If you've never seen anything like this before, an approximation like that might seem

17
00:01:21,240 --> 00:01:22,780
completely out of left field.

18
00:01:23,820 --> 00:01:29,540
If you graph cosine of theta along with this function, 1 minus theta squared over 2, they

19
00:01:29,540 --> 00:01:34,780
do seem rather close to each other, at least for small angles near 0, but how would you

20
00:01:34,780 --> 00:01:39,420
even think to make this approximation, and how would you find that particular quadratic?

21
00:01:41,220 --> 00:01:46,240
The study of Taylor series is largely about taking non-polynomial functions and finding

22
00:01:46,240 --> 00:01:48,840
polynomials that approximate them near some input.

23
00:01:48,840 --> 00:01:53,760
The motive here is that polynomials tend to be much easier to deal with than other functions,

24
00:01:54,340 --> 00:01:58,540
they're easier to compute, easier to take derivatives, easier to integrate, just all

25
00:01:58,540 --> 00:01:59,480
around more friendly.

26
00:02:00,680 --> 00:02:05,460
So let's take a look at that function, cosine of x, and really take a moment to think about

27
00:02:05,460 --> 00:02:10,220
how you might construct a quadratic approximation near x equals 0.

28
00:02:10,940 --> 00:02:18,180
That is, among all of the possible polynomials that look like c0 plus c1 times x plus c2

29
00:02:18,180 --> 00:02:24,940
times x squared, for some choice of these constants, c0, c1, and c2, find the one that

30
00:02:24,940 --> 00:02:31,000
most resembles cosine of x near x equals 0, whose graph kind of spoons with the graph

31
00:02:31,000 --> 00:02:32,660
of cosine x at that point.

32
00:02:33,860 --> 00:02:40,000
First of all, at the input 0, the value of cosine of x is 1, so if our approximation

33
00:02:40,000 --> 00:02:44,920
is any good at all, it should also equal 1 at the input x equals 0.

34
00:02:45,820 --> 00:02:50,940
Plugging in 0 just results in whatever c0 is, so we can set that equal to 1.

35
00:02:53,080 --> 00:02:57,580
This leaves us free to choose constants c1 and c2 to make this approximation as good

36
00:02:57,580 --> 00:03:01,740
as we can, but nothing we do with them is going to change the fact that the polynomial

37
00:03:01,740 --> 00:03:04,000
equals 1 at x equals 0.

38
00:03:04,960 --> 00:03:10,180
It would also be good if our approximation had the same tangent slope as cosine x at

39
00:03:10,180 --> 00:03:11,120
this point of interest.

40
00:03:11,900 --> 00:03:16,340
Otherwise the approximation drifts away from the cosine graph much faster than it needs

41
00:03:16,340 --> 00:03:16,700
to.

42
00:03:18,200 --> 00:03:24,140
The derivative of cosine is negative sine, and at x equals 0, that equals 0, meaning

43
00:03:24,140 --> 00:03:25,840
the tangent line is perfectly flat.

44
00:03:26,960 --> 00:03:33,180
On the other hand, when you work out the derivative of our quadratic, you get c1 plus 2 times

45
00:03:33,180 --> 00:03:34,400
c2 times x.

46
00:03:35,320 --> 00:03:39,420
At x equals 0, this just equals whatever we choose for c1.

47
00:03:40,260 --> 00:03:45,400
So this constant c1 has complete control over the derivative of our approximation around

48
00:03:45,400 --> 00:03:46,340
x equals 0.

49
00:03:47,120 --> 00:03:52,300
Setting it equal to 0 ensures that our approximation also has a flat tangent line at this point.

50
00:03:53,000 --> 00:03:58,540
This leaves us free to change c2, but the value and the slope of our polynomial at x

51
00:03:58,540 --> 00:04:02,620
equals 0 are locked in place to match that of cosine.

52
00:04:04,260 --> 00:04:08,760
The final thing to take advantage of is the fact that the cosine graph curves downward

53
00:04:08,760 --> 00:04:12,440
above x equals 0, it has a negative second derivative.

54
00:04:13,380 --> 00:04:17,760
Or in other words, even though the rate of change is 0 at that point, the rate of change

55
00:04:17,760 --> 00:04:20,460
itself is decreasing around that point.

56
00:04:21,280 --> 00:04:27,000
Specifically, since its derivative is negative sine of x, its second derivative is negative

57
00:04:27,000 --> 00:04:31,840
cosine of x, and at x equals 0, that equals negative 1.

58
00:04:33,080 --> 00:04:37,080
Now in the same way that we wanted the derivative of our approximation to match that of the

59
00:04:37,080 --> 00:04:42,080
cosine so that their values wouldn't drift apart needlessly quickly, making sure that

60
00:04:42,080 --> 00:04:47,480
their second derivatives match will ensure that they curve at the same rate, that the

61
00:04:47,480 --> 00:04:52,300
slope of our polynomial doesn't drift away from the slope of cosine x any more quickly

62
00:04:52,300 --> 00:04:53,320
than it needs to.

63
00:04:54,220 --> 00:04:59,300
Pulling up the same derivative we had before, and then taking its derivative, we see that

64
00:04:59,300 --> 00:05:04,040
the second derivative of this polynomial is exactly 2 times c2.

65
00:05:04,960 --> 00:05:10,660
So to make sure that this second derivative also equals negative 1 at x equals 0, 2 times

66
00:05:10,660 --> 00:05:15,580
c2 has to be negative 1, meaning c2 itself should be negative 1 half.

67
00:05:16,380 --> 00:05:22,140
This gives us the approximation 1 plus 0x minus 1 half x squared.

68
00:05:23,200 --> 00:05:29,600
To get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial, you'd

69
00:05:29,600 --> 00:05:35,820
estimate it to be 0.995, and this is the true value of cosine of 0.1.

70
00:05:36,640 --> 00:05:38,440
It's a really good approximation!

71
00:05:40,300 --> 00:05:42,520
Take a moment to reflect on what just happened.

72
00:05:42,520 --> 00:05:49,020
You had 3 degrees of freedom with this quadratic approximation, the constants c0, c1, and c2.

73
00:05:49,520 --> 00:05:54,660
c0 was responsible for making sure that the output of the approximation matches that of

74
00:05:54,660 --> 00:06:00,640
cosine x at x equals 0, c1 was in charge of making sure that the derivatives match at

75
00:06:00,640 --> 00:06:08,240
that point, and c2 was responsible for making sure that the second derivatives match up.

76
00:06:08,940 --> 00:06:14,220
This ensures that the way your approximation changes as you move away from x equals 0,

77
00:06:14,800 --> 00:06:19,720
and the way that the rate of change itself changes, is as similar as possible to the

78
00:06:19,720 --> 00:06:23,160
behaviour of cosine x, given the amount of control you have.

79
00:06:24,080 --> 00:06:28,880
You could give yourself more control by allowing more terms in your polynomial and matching

80
00:06:28,880 --> 00:06:30,140
higher order derivatives.

81
00:06:30,840 --> 00:06:36,580
For example, let's say you added on the term c3 times x cubed for some constant c3.

82
00:06:36,580 --> 00:06:42,880
In that case, if you take the third derivative of a cubic polynomial, anything quadratic

83
00:06:42,880 --> 00:06:44,280
or smaller goes to 0.

84
00:06:45,560 --> 00:06:52,240
As for that last term, after 3 iterations of the power rule, it looks like 1 times 2

85
00:06:52,240 --> 00:06:54,460
times 3 times c3.

86
00:06:56,460 --> 00:07:01,840
On the other hand, the third derivative of cosine x comes out to sine x, which equals

87
00:07:01,840 --> 00:07:03,280
0 at x equals 0.

88
00:07:03,280 --> 00:07:08,760
So to make sure that the third derivatives match, the constant c3 should be 0.

89
00:07:09,880 --> 00:07:15,920
Or in other words, not only is 1 minus Â½ x2 the best possible quadratic approximation

90
00:07:15,920 --> 00:07:19,580
of cosine, it's also the best possible cubic approximation.

91
00:07:21,280 --> 00:07:27,060
You can make an improvement by adding on a fourth order term, c4 times x to the fourth.

92
00:07:27,880 --> 00:07:33,320
The fourth derivative of cosine is itself, which equals 1 at x equals 0.

93
00:07:34,300 --> 00:07:37,460
And what's the fourth derivative of our polynomial with this new term?

94
00:07:38,620 --> 00:07:43,180
Well, when you keep applying the power rule over and over, with those exponents all hopping

95
00:07:43,180 --> 00:07:51,000
down in front, you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4.

96
00:07:51,400 --> 00:07:58,240
So if we want this to match the fourth derivative of cosine x, which is 1, c4 has to be 1 over

97
00:07:58,240 --> 00:07:58,760
24.

98
00:07:59,820 --> 00:08:07,220
And indeed, the polynomial 1 minus Â½ x2 plus 1 24 times x to the fourth, which looks like

99
00:08:07,220 --> 00:08:12,840
this, is a very close approximation for cosine x around x equals 0.

100
00:08:13,740 --> 00:08:18,460
In any physics problem involving the cosine of a small angle, for example, predictions

101
00:08:18,460 --> 00:08:23,600
would be almost unnoticeably different if you substituted this polynomial for cosine

102
00:08:23,600 --> 00:08:24,060
of x.

103
00:08:26,100 --> 00:08:29,760
Take a step back and notice a few things happening with this process.

104
00:08:30,520 --> 00:08:34,200
First of all, factorial terms come up very naturally in this process.

105
00:08:35,020 --> 00:08:39,600
When you take n successive derivatives of the function x to the n, letting the power

106
00:08:39,600 --> 00:08:46,680
rule keep cascading on down, what you'll be left with is 1 times 2 times 3 on and on

107
00:08:46,680 --> 00:08:48,580
up to whatever n is.

108
00:08:49,220 --> 00:08:53,780
So you don't simply set the coefficients of the polynomial equal to whatever derivative

109
00:08:53,780 --> 00:08:58,540
you want, you have to divide by the appropriate factorial to cancel out this effect.

110
00:08:59,400 --> 00:09:05,340
For example, that x to the fourth coefficient was the fourth derivative of cosine, 1, but

111
00:09:05,340 --> 00:09:07,780
divided by 4 factorial, 24.

112
00:09:09,400 --> 00:09:16,660
The second thing to notice is that adding on new terms, like this c4 times x to the

113
00:09:16,660 --> 00:09:19,300
old terms should be, and that's really important.

114
00:09:20,100 --> 00:09:25,640
For example, the second derivative of this polynomial at x equals 0 is still equal to

115
00:09:25,640 --> 00:09:30,080
2 times the second coefficient, even after you introduce higher order terms.

116
00:09:30,960 --> 00:09:36,000
And it's because we're plugging in x equals 0, so the second derivative of any higher

117
00:09:36,000 --> 00:09:39,780
order term, which all include an x, will just wash away.

118
00:09:40,740 --> 00:09:45,560
And the same goes for any other derivative, which is why each derivative of a polynomial

119
00:09:45,560 --> 00:09:50,280
at x equals 0 is controlled by one and only one of the coefficients.

120
00:09:52,640 --> 00:09:58,260
If instead you were approximating near an input other than 0, like x equals pi, in order

121
00:09:58,260 --> 00:10:02,940
to get the same effect you would have to write your polynomial in terms of powers of x minus

122
00:10:02,940 --> 00:10:05,720
pi, or whatever input you're looking at.

123
00:10:06,320 --> 00:10:10,840
This makes it look noticeably more complicated, but all we're doing is making sure that

124
00:10:10,840 --> 00:10:17,240
the point pi looks and behaves like 0, so that plugging in x equals pi will result in

125
00:10:17,240 --> 00:10:20,220
a lot of nice cancellation that leaves only one constant.

126
00:10:22,380 --> 00:10:27,340
And finally, on a more philosophical level, notice how what we're doing here is basically

127
00:10:27,340 --> 00:10:33,680
taking information about higher order derivatives of a function at a single point, and translating

128
00:10:33,680 --> 00:10:37,780
that into information about the value of the function near that point.

129
00:10:40,960 --> 00:10:44,120
You can take as many derivatives of cosine as you want.

130
00:10:44,600 --> 00:10:49,320
It follows this nice cyclic pattern, cosine of x, negative sine of x, negative cosine,

131
00:10:49,600 --> 00:10:51,020
sine, and then repeat.

132
00:10:52,320 --> 00:10:55,660
And the value of each one of these is easy to compute at x equals 0.

133
00:10:56,100 --> 00:11:01,100
It gives this cyclic pattern 1, 0, negative 1, 0, and then repeat.

134
00:11:02,000 --> 00:11:06,520
And knowing the values of all those higher order derivatives is a lot of information

135
00:11:06,520 --> 00:11:12,480
about cosine of x, even though it only involves plugging in a single number, x equals 0.

136
00:11:14,260 --> 00:11:19,900
So what we're doing is leveraging that information to get an approximation around this input,

137
00:11:20,300 --> 00:11:25,280
and you do it by creating a polynomial whose higher order derivatives are designed to match

138
00:11:25,280 --> 00:11:30,660
up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern.

139
00:11:31,420 --> 00:11:36,340
And to do that, you just make each coefficient of the polynomial follow that same pattern,

140
00:11:36,820 --> 00:11:39,440
but you have to divide each one by the appropriate factorial.

141
00:11:40,120 --> 00:11:44,540
Like I mentioned before, this is what cancels out the cascading effect of many power rule

142
00:11:44,540 --> 00:11:45,260
applications.

143
00:11:47,280 --> 00:11:52,100
The polynomials you get by stopping this process at any point are called Taylor polynomials

144
00:11:52,100 --> 00:11:53,160
for cosine of x.

145
00:11:53,900 --> 00:11:58,280
More generally, and hence more abstractly, if we were dealing with some other function

146
00:11:58,280 --> 00:12:03,860
other than cosine, you would compute its derivative, its second derivative, and so on, getting

147
00:12:03,860 --> 00:12:08,400
as many terms as you'd like, and evaluate each one of them at x equals 0.

148
00:12:09,580 --> 00:12:15,600
Then for the polynomial approximation, the coefficient of each x to the n term should

149
00:12:15,600 --> 00:12:21,880
be the value of the nth derivative of the function evaluated at 0, but divided by n

150
00:12:21,880 --> 00:12:22,440
factorial.

151
00:12:23,480 --> 00:12:29,460
This whole rather abstract formula is something you'll likely see in any text or course

152
00:12:29,460 --> 00:12:31,200
that touches on Taylor polynomials.

153
00:12:31,780 --> 00:12:36,400
And when you see it, think to yourself that the constant term ensures that the value of

154
00:12:36,400 --> 00:12:41,720
the polynomial matches with the value of f, the next term ensures that the slope of the

155
00:12:41,720 --> 00:12:47,660
polynomial matches the slope of the function at x equals 0, the next term ensures that

156
00:12:47,660 --> 00:12:52,420
the rate at which the slope changes is the same at that point, and so on, depending on

157
00:12:52,420 --> 00:12:53,520
how many terms you want.

158
00:12:54,620 --> 00:12:58,460
And the more terms you choose, the closer the approximation, but the tradeoff is that

159
00:12:58,460 --> 00:13:00,980
the polynomial you'd get would be more complicated.

160
00:13:02,640 --> 00:13:07,100
And to make things even more general, if you wanted to approximate near some input other

161
00:13:07,100 --> 00:13:13,040
than 0, which we'll call a, you would write this polynomial in terms of powers of x minus

162
00:13:13,040 --> 00:13:17,780
a, and you would evaluate all the derivatives of f at that input, a.

163
00:13:18,680 --> 00:13:23,120
This is what Taylor polynomials look like in their fullest generality.

164
00:13:24,000 --> 00:13:29,160
Changing the value of a changes where this approximation is hugging the original function,

165
00:13:29,580 --> 00:13:33,740
where its higher order derivatives will be equal to those of the original function.

166
00:13:35,880 --> 00:13:40,640
One of the simplest meaningful examples of this is the function e to the x around the

167
00:13:40,640 --> 00:13:41,900
input x equals 0.

168
00:13:42,760 --> 00:13:47,600
Computing the derivatives is super nice, as nice as it gets, because the derivative of

169
00:13:47,600 --> 00:13:53,240
e to the x is itself, so the second derivative is also e to the x, as is its third, and so

170
00:13:53,240 --> 00:13:53,580
on.

171
00:13:54,340 --> 00:13:58,240
So at the point x equals 0, all of these are equal to 1.

172
00:13:59,120 --> 00:14:08,880
And what that means is our polynomial approximation should look like 1 plus 1 times x plus 1 over

173
00:14:08,880 --> 00:14:18,080
2 times x2 plus 1 over 3 factorial times x3, and so on, depending on how many terms

174
00:14:18,080 --> 00:14:18,540
you want.

175
00:14:19,400 --> 00:14:22,700
These are the Taylor polynomials for e to the x.

176
00:14:26,380 --> 00:14:31,460
Ok, so with that as a foundation, in the spirit of showing you just how connected all the

177
00:14:31,460 --> 00:14:36,380
topics of calculus are, let me turn to something kind of fun, a completely different way to

178
00:14:36,380 --> 00:14:40,520
understand this second order term of the Taylor polynomials, but geometrically.

179
00:14:41,400 --> 00:14:44,880
It's related to the fundamental theorem of calculus, which I talked about in chapters

180
00:14:44,880 --> 00:14:47,260
1 and 8 if you need a quick refresher.

181
00:14:47,980 --> 00:14:53,340
Like we did in those videos, consider a function that gives the area under some graph between

182
00:14:53,340 --> 00:14:56,140
a fixed left point and a variable right point.

183
00:14:56,980 --> 00:15:01,500
What we're going to do here is think about how to approximate this area function, not

184
00:15:01,500 --> 00:15:04,180
the function for the graph itself, like we've been doing before.

185
00:15:04,900 --> 00:15:09,440
Focusing on that area is what's going to make the second order term pop out.

186
00:15:10,440 --> 00:15:16,180
Remember, the fundamental theorem of calculus is that this graph itself represents the derivative

187
00:15:16,180 --> 00:15:21,920
of the area function, and it's because a slight nudge dx to the right bound of the

188
00:15:21,920 --> 00:15:29,200
area gives a new bit of area approximately equal to the height of the graph times dx.

189
00:15:30,040 --> 00:15:34,480
And that approximation is increasingly accurate for smaller and smaller choices of dx.

190
00:15:35,980 --> 00:15:39,840
But if you wanted to be more accurate about this change in area, given some change in

191
00:15:39,840 --> 00:15:44,960
x that isn't meant to approach 0, you would have to take into account this portion right

192
00:15:44,960 --> 00:15:47,960
here, which is approximately a triangle.

193
00:15:49,600 --> 00:15:56,520
Let's name the starting input a, and the nudged input above it x, so that change is

194
00:15:56,520 --> 00:15:57,460
x-a.

195
00:15:58,100 --> 00:16:06,080
The base of that little triangle is that change, x-a, and its height is the slope of the graph

196
00:16:06,080 --> 00:16:07,600
times x-a.

197
00:16:08,420 --> 00:16:14,060
Since this graph is the derivative of the area function, its slope is the second derivative

198
00:16:14,060 --> 00:16:17,120
of the area function, evaluated at the input a.

199
00:16:18,440 --> 00:16:24,140
So the area of this triangle, 1 half base times height, is 1 half times the second derivative

200
00:16:24,140 --> 00:16:29,900
of this area function, evaluated at a, multiplied by x-a2.

201
00:16:30,960 --> 00:16:34,380
And this is exactly what you would see with a Taylor polynomial.

202
00:16:34,880 --> 00:16:41,000
If you knew the various derivative information about this area function at the point a, how

203
00:16:41,000 --> 00:16:43,660
would you approximate the area at the point x?

204
00:16:45,360 --> 00:16:51,540
Well you have to include all that area up to a, f of a, plus the area of this rectangle

205
00:16:51,540 --> 00:16:57,740
here, which is the first derivative, times x-a, plus the area of that little triangle,

206
00:16:58,160 --> 00:17:01,680
which is 1 half times the second derivative, times x-a2.

207
00:17:02,560 --> 00:17:07,260
I really like this, because even though it looks a bit messy all written out, each one

208
00:17:07,260 --> 00:17:11,080
of the terms has a very clear meaning that you can just point to on the diagram.

209
00:17:13,400 --> 00:17:17,780
If you wanted, we could call it an end here, and you would have a phenomenally useful tool

210
00:17:17,780 --> 00:17:20,460
for approximating these Taylor polynomials.

211
00:17:21,400 --> 00:17:26,500
But if you're thinking like a mathematician, one question you might ask is whether or not

212
00:17:26,500 --> 00:17:30,460
it makes sense to never stop and just add infinitely many terms.

213
00:17:31,380 --> 00:17:37,020
In math, an infinite sum is called a series, so even though one of these approximations

214
00:17:37,020 --> 00:17:42,520
with finitely many terms is called a Taylor polynomial, adding all infinitely many terms

215
00:17:42,520 --> 00:17:44,520
gives what's called a Taylor series.

216
00:17:45,260 --> 00:17:49,480
You have to be really careful with the idea of an infinite series, because it doesn't

217
00:17:49,480 --> 00:17:54,440
actually make sense to add infinitely many things, you can only hit the plus button on

218
00:17:54,440 --> 00:17:56,080
the calculator so many times.

219
00:17:57,440 --> 00:18:01,800
But if you have a series where adding more and more of the terms, which makes sense at

220
00:18:01,800 --> 00:18:07,400
each step, gets you increasingly close to some specific value, what you say is that

221
00:18:07,400 --> 00:18:09,740
the series converges to that value.

222
00:18:10,320 --> 00:18:14,880
Or, if you're comfortable extending the definition of equality to include this kind

223
00:18:14,880 --> 00:18:20,360
of series convergence, you'd say that the series as a whole, this infinite sum, equals

224
00:18:20,360 --> 00:18:22,360
the value it's converging to.

225
00:18:23,460 --> 00:18:29,300
For example, look at the Taylor polynomial for e to the x, and plug in some input, like

226
00:18:29,300 --> 00:18:30,160
x equals 1.

227
00:18:31,140 --> 00:18:37,180
As you add more and more polynomial terms, the total sum gets closer and closer to the

228
00:18:37,180 --> 00:18:45,760
value e, so you say that this infinite series converges to the number e, or that it equals

229
00:18:45,760 --> 00:18:46,700
the number e.

230
00:18:47,840 --> 00:18:53,800
In fact, it turns out that if you plug in any other value of x, like x equals 2, and

231
00:18:53,800 --> 00:18:59,300
look at the value of the higher and higher order Taylor polynomials at this value, they

232
00:18:59,300 --> 00:19:04,020
will converge towards e to the x, which is e squared.

233
00:19:04,680 --> 00:19:10,800
This is true for any input, no matter how far away from 0 it is, even though these Taylor

234
00:19:10,800 --> 00:19:16,180
polynomials are constructed only from derivative information gathered at the input 0.

235
00:19:18,270 --> 00:19:24,340
In a case like this, we say that e to the x equals its own Taylor series at all inputs

236
00:19:24,340 --> 00:19:27,480
x, which is kind of a magical thing to have happen.

237
00:19:28,380 --> 00:19:33,900
Even though this is also true for a couple other important functions, like sine and cosine,

238
00:19:34,060 --> 00:19:39,280
sometimes these series only converge within a certain range around the input whose derivative

239
00:19:39,280 --> 00:19:40,500
information you're using.

240
00:19:41,580 --> 00:19:46,600
If you work out the Taylor series for the natural log of x around the input x equals

241
00:19:46,600 --> 00:19:51,960
1, which is built by evaluating the higher order derivatives of the natural log of x

242
00:19:51,960 --> 00:19:55,620
at x equals 1, this is what it would look like.

243
00:19:56,080 --> 00:20:01,200
When you plug in an input between 0 and 2, adding more and more terms of this series

244
00:20:01,200 --> 00:20:05,520
will indeed get you closer and closer to the natural log of that input.

245
00:20:06,400 --> 00:20:11,700
But outside of that range, even by just a little bit, the series fails to approach anything.

246
00:20:12,480 --> 00:20:17,440
As you add on more and more terms, the sum bounces back and forth wildly.

247
00:20:18,100 --> 00:20:23,540
It does not, as you might expect, approach the natural log of that value, even though

248
00:20:23,540 --> 00:20:27,540
the natural log of x is perfectly well defined for inputs above 2.

249
00:20:28,460 --> 00:20:34,460
In some sense, the derivative information of ln of x at x equals 1 doesn't propagate

250
00:20:34,460 --> 00:20:35,360
out that far.

251
00:20:36,580 --> 00:20:40,680
In a case like this, where adding more terms of the series doesn't approach anything,

252
00:20:41,200 --> 00:20:43,080
you say that the series diverges.

253
00:20:44,180 --> 00:20:48,700
And that maximum distance between the input you're approximating near and points where

254
00:20:48,700 --> 00:20:54,040
the outputs of these polynomials actually converge is called the radius of convergence

255
00:20:54,040 --> 00:20:55,560
for the Taylor series.

256
00:20:56,840 --> 00:20:59,160
There remains more to learn about Taylor series.

257
00:20:59,500 --> 00:21:04,180
There are many use cases, tactics for placing bounds on the error of these approximations,

258
00:21:04,680 --> 00:21:09,580
tests for understanding when series do and don't converge, and for that matter, there

259
00:21:09,580 --> 00:21:13,760
remains more to learn about calculus as a whole, and the countless topics not touched

260
00:21:13,760 --> 00:21:14,580
by this series.

261
00:21:15,320 --> 00:21:20,060
The goal with these videos is to give you the fundamental intuitions that make you feel

262
00:21:20,060 --> 00:21:25,500
confident and efficient in learning more on your own, and potentially even rediscovering

263
00:21:25,500 --> 00:21:27,140
more of the topic for yourself.

264
00:21:28,060 --> 00:21:33,100
In the case of Taylor series, the fundamental intuition to keep in mind as you explore more

265
00:21:33,100 --> 00:21:39,060
of what there is, is that they translate derivative information at a single point to approximation

266
00:21:39,060 --> 00:21:41,160
information around that point.

267
00:21:43,920 --> 00:21:46,600
Thank you once again to everybody who supported this series.

268
00:21:47,300 --> 00:21:51,520
The next series like it will be on probability, and if you want early access as those videos

269
00:21:51,520 --> 00:21:53,060
are made, you know where to go.

270
00:22:11,160 --> 00:22:19,060
Thank you.

