1
00:00:14,640 --> 00:00:17,395
When I first learned about Taylor series, I definitely 

2
00:00:17,395 --> 00:00:19,700
didn't appreciate just how important they are.

3
00:00:20,120 --> 00:00:22,828
But time and time again they come up in math, physics, 

4
00:00:22,828 --> 00:00:25,930
and many fields of engineering because they're one of the most 

5
00:00:25,930 --> 00:00:29,180
powerful tools that math has to offer for approximating functions.

6
00:00:30,000 --> 00:00:32,710
I think one of the first times this clicked for me as a 

7
00:00:32,710 --> 00:00:35,420
student was not in a calculus class but a physics class.

8
00:00:35,840 --> 00:00:40,103
We were studying a certain problem that had to do with the potential energy of a 

9
00:00:40,103 --> 00:00:44,156
pendulum, and for that you need an expression for how high the weight of the 

10
00:00:44,156 --> 00:00:48,473
pendulum is above its lowest point, and when you work that out it comes out to be 

11
00:00:48,473 --> 00:00:53,000
proportional to 1 minus the cosine of the angle between the pendulum and the vertical.

12
00:00:53,580 --> 00:00:57,875
The specifics of the problem we were trying to solve are beyond the point here, 

13
00:00:57,875 --> 00:01:02,493
but what I'll say is that this cosine function made the problem awkward and unwieldy, 

14
00:01:02,493 --> 00:01:06,520
and made it less clear how pendulums relate to other oscillating phenomena.

15
00:01:07,460 --> 00:01:12,517
But if you approximate cosine of theta as 1 minus theta squared over 2, 

16
00:01:12,517 --> 00:01:15,960
everything just fell into place much more easily.

17
00:01:16,660 --> 00:01:19,214
If you've never seen anything like this before, 

18
00:01:19,214 --> 00:01:22,780
an approximation like that might seem completely out of left field.

19
00:01:23,820 --> 00:01:28,804
If you graph cosine of theta along with this function, 1 minus theta squared over 2, 

20
00:01:28,804 --> 00:01:33,203
they do seem rather close to each other, at least for small angles near 0, 

21
00:01:33,203 --> 00:01:36,546
but how would you even think to make this approximation, 

22
00:01:36,546 --> 00:01:39,420
and how would you find that particular quadratic?

23
00:01:41,220 --> 00:01:44,864
The study of Taylor series is largely about taking non-polynomial 

24
00:01:44,864 --> 00:01:48,840
functions and finding polynomials that approximate them near some input.

25
00:01:48,840 --> 00:01:52,404
The motive here is that polynomials tend to be much easier to deal 

26
00:01:52,404 --> 00:01:55,277
with than other functions, they're easier to compute, 

27
00:01:55,277 --> 00:01:59,480
easier to take derivatives, easier to integrate, just all around more friendly.

28
00:02:00,680 --> 00:02:03,819
So let's take a look at that function, cosine of x, 

29
00:02:03,819 --> 00:02:08,408
and really take a moment to think about how you might construct a quadratic 

30
00:02:08,408 --> 00:02:10,220
approximation near x equals 0.

31
00:02:10,940 --> 00:02:16,445
That is, among all of the possible polynomials that look like c0 plus c1 

32
00:02:16,445 --> 00:02:21,950
times x plus c2 times x squared, for some choice of these constants, c0, 

33
00:02:21,950 --> 00:02:27,531
c1, and c2, find the one that most resembles cosine of x near x equals 0, 

34
00:02:27,531 --> 00:02:32,660
whose graph kind of spoons with the graph of cosine x at that point.

35
00:02:33,860 --> 00:02:38,298
First of all, at the input 0, the value of cosine of x is 1, 

36
00:02:38,298 --> 00:02:43,683
so if our approximation is any good at all, it should also equal 1 at the 

37
00:02:43,683 --> 00:02:44,920
input x equals 0.

38
00:02:45,820 --> 00:02:50,940
Plugging in 0 just results in whatever c0 is, so we can set that equal to 1.

39
00:02:53,080 --> 00:02:56,608
This leaves us free to choose constants c1 and c2 to make this 

40
00:02:56,608 --> 00:03:00,192
approximation as good as we can, but nothing we do with them is 

41
00:03:00,192 --> 00:03:04,000
going to change the fact that the polynomial equals 1 at x equals 0.

42
00:03:04,960 --> 00:03:08,154
It would also be good if our approximation had the same 

43
00:03:08,154 --> 00:03:11,120
tangent slope as cosine x at this point of interest.

44
00:03:11,900 --> 00:03:14,484
Otherwise the approximation drifts away from the 

45
00:03:14,484 --> 00:03:16,700
cosine graph much faster than it needs to.

46
00:03:18,200 --> 00:03:22,147
The derivative of cosine is negative sine, and at x equals 0, 

47
00:03:22,147 --> 00:03:25,840
that equals 0, meaning the tangent line is perfectly flat.

48
00:03:26,960 --> 00:03:31,920
On the other hand, when you work out the derivative of our quadratic, 

49
00:03:31,920 --> 00:03:34,400
you get c1 plus 2 times c2 times x.

50
00:03:35,320 --> 00:03:39,420
At x equals 0, this just equals whatever we choose for c1.

51
00:03:40,260 --> 00:03:43,300
So this constant c1 has complete control over the 

52
00:03:43,300 --> 00:03:46,340
derivative of our approximation around x equals 0.

53
00:03:47,120 --> 00:03:49,979
Setting it equal to 0 ensures that our approximation 

54
00:03:49,979 --> 00:03:52,300
also has a flat tangent line at this point.

55
00:03:53,000 --> 00:03:57,810
This leaves us free to change c2, but the value and the slope of our 

56
00:03:57,810 --> 00:04:02,620
polynomial at x equals 0 are locked in place to match that of cosine.

57
00:04:04,260 --> 00:04:08,379
The final thing to take advantage of is the fact that the cosine graph 

58
00:04:08,379 --> 00:04:12,440
curves downward above x equals 0, it has a negative second derivative.

59
00:04:13,380 --> 00:04:17,251
Or in other words, even though the rate of change is 0 at that point, 

60
00:04:17,251 --> 00:04:20,459
the rate of change itself is decreasing around that point.

61
00:04:21,279 --> 00:04:25,446
Specifically, since its derivative is negative sine of x, 

62
00:04:25,446 --> 00:04:31,840
its second derivative is negative cosine of x, and at x equals 0, that equals negative 1.

63
00:04:33,080 --> 00:04:37,150
Now in the same way that we wanted the derivative of our approximation to 

64
00:04:37,150 --> 00:04:41,934
match that of the cosine so that their values wouldn't drift apart needlessly quickly, 

65
00:04:41,934 --> 00:04:45,784
making sure that their second derivatives match will ensure that they 

66
00:04:45,784 --> 00:04:49,690
curve at the same rate, that the slope of our polynomial doesn't drift 

67
00:04:49,690 --> 00:04:53,320
away from the slope of cosine x any more quickly than it needs to.

68
00:04:54,220 --> 00:04:59,226
Pulling up the same derivative we had before, and then taking its derivative, 

69
00:04:59,226 --> 00:05:04,040
we see that the second derivative of this polynomial is exactly 2 times c2.

70
00:05:04,960 --> 00:05:10,436
So to make sure that this second derivative also equals negative 1 at x equals 0, 

71
00:05:10,436 --> 00:05:15,580
2 times c2 has to be negative 1, meaning c2 itself should be negative 1 half.

72
00:05:16,380 --> 00:05:22,140
This gives us the approximation 1 plus 0x minus 1 half x squared.

73
00:05:23,200 --> 00:05:29,977
To get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial, 

74
00:05:29,977 --> 00:05:35,820
you'd estimate it to be 0.995, and this is the true value of cosine of 0.1.

75
00:05:36,640 --> 00:05:38,440
It's a really good approximation!

76
00:05:40,300 --> 00:05:42,520
Take a moment to reflect on what just happened.

77
00:05:42,520 --> 00:05:46,993
You had 3 degrees of freedom with this quadratic approximation, 

78
00:05:46,993 --> 00:05:49,020
the constants c0, c1, and c2.

79
00:05:49,520 --> 00:05:55,807
c0 was responsible for making sure that the output of the approximation matches that of 

80
00:05:55,807 --> 00:06:01,952
cosine x at x equals 0, c1 was in charge of making sure that the derivatives match at 

81
00:06:01,952 --> 00:06:08,240
that point, and c2 was responsible for making sure that the second derivatives match up.

82
00:06:08,940 --> 00:06:14,272
This ensures that the way your approximation changes as you move away from x equals 0, 

83
00:06:14,272 --> 00:06:17,459
and the way that the rate of change itself changes, 

84
00:06:17,459 --> 00:06:20,892
is as similar as possible to the behaviour of cosine x, 

85
00:06:20,892 --> 00:06:23,160
given the amount of control you have.

86
00:06:24,080 --> 00:06:27,187
You could give yourself more control by allowing more terms 

87
00:06:27,187 --> 00:06:30,140
in your polynomial and matching higher order derivatives.

88
00:06:30,840 --> 00:06:36,580
For example, let's say you added on the term c3 times x cubed for some constant c3.

89
00:06:36,580 --> 00:06:41,480
In that case, if you take the third derivative of a cubic polynomial, 

90
00:06:41,480 --> 00:06:44,280
anything quadratic or smaller goes to 0.

91
00:06:45,560 --> 00:06:50,882
As for that last term, after 3 iterations of the power rule, 

92
00:06:50,882 --> 00:06:54,460
it looks like 1 times 2 times 3 times c3.

93
00:06:56,460 --> 00:07:01,340
On the other hand, the third derivative of cosine x comes out to sine x, 

94
00:07:01,340 --> 00:07:03,280
which equals 0 at x equals 0.

95
00:07:03,280 --> 00:07:08,760
So to make sure that the third derivatives match, the constant c3 should be 0.

96
00:07:09,880 --> 00:07:14,696
Or in other words, not only is 1 minus ½ x2 the best possible quadratic 

97
00:07:14,696 --> 00:07:19,580
approximation of cosine, it's also the best possible cubic approximation.

98
00:07:21,280 --> 00:07:27,060
You can make an improvement by adding on a fourth order term, c4 times x to the fourth.

99
00:07:27,880 --> 00:07:33,320
The fourth derivative of cosine is itself, which equals 1 at x equals 0.

100
00:07:34,300 --> 00:07:37,460
And what's the fourth derivative of our polynomial with this new term?

101
00:07:38,620 --> 00:07:42,677
Well, when you keep applying the power rule over and over, 

102
00:07:42,677 --> 00:07:45,979
with those exponents all hopping down in front, 

103
00:07:45,979 --> 00:07:51,000
you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4.

104
00:07:51,400 --> 00:07:56,131
So if we want this to match the fourth derivative of cosine x, 

105
00:07:56,131 --> 00:07:58,760
which is 1, c4 has to be 1 over 24.

106
00:07:59,820 --> 00:08:05,873
And indeed, the polynomial 1 minus ½ x2 plus 1 24 times x to the fourth, 

107
00:08:05,873 --> 00:08:12,840
which looks like this, is a very close approximation for cosine x around x equals 0.

108
00:08:13,740 --> 00:08:18,112
In any physics problem involving the cosine of a small angle, for example, 

109
00:08:18,112 --> 00:08:23,127
predictions would be almost unnoticeably different if you substituted this polynomial 

110
00:08:23,127 --> 00:08:24,060
for cosine of x.

111
00:08:26,100 --> 00:08:29,760
Take a step back and notice a few things happening with this process.

112
00:08:30,520 --> 00:08:34,200
First of all, factorial terms come up very naturally in this process.

113
00:08:35,020 --> 00:08:39,801
When you take n successive derivatives of the function x to the n, 

114
00:08:39,801 --> 00:08:43,156
letting the power rule keep cascading on down, 

115
00:08:43,156 --> 00:08:48,580
what you'll be left with is 1 times 2 times 3 on and on up to whatever n is.

116
00:08:49,220 --> 00:08:53,988
So you don't simply set the coefficients of the polynomial equal to whatever derivative 

117
00:08:53,988 --> 00:08:58,540
you want, you have to divide by the appropriate factorial to cancel out this effect.

118
00:08:59,400 --> 00:09:05,344
For example, that x to the fourth coefficient was the fourth derivative of cosine, 

119
00:09:05,344 --> 00:09:07,780
1, but divided by 4 factorial, 24.

120
00:09:09,400 --> 00:09:13,568
The second thing to notice is that adding on new terms, 

121
00:09:13,568 --> 00:09:19,300
like this c4 times x to the old terms should be, and that's really important.

122
00:09:20,100 --> 00:09:25,213
For example, the second derivative of this polynomial at x equals 0 is still equal 

123
00:09:25,213 --> 00:09:30,080
to 2 times the second coefficient, even after you introduce higher order terms.

124
00:09:30,960 --> 00:09:33,879
And it's because we're plugging in x equals 0, 

125
00:09:33,879 --> 00:09:38,537
so the second derivative of any higher order term, which all include an x, 

126
00:09:38,537 --> 00:09:39,780
will just wash away.

127
00:09:40,740 --> 00:09:45,479
And the same goes for any other derivative, which is why each derivative of a 

128
00:09:45,479 --> 00:09:50,280
polynomial at x equals 0 is controlled by one and only one of the coefficients.

129
00:09:52,640 --> 00:09:57,353
If instead you were approximating near an input other than 0, like x equals pi, 

130
00:09:57,353 --> 00:10:01,772
in order to get the same effect you would have to write your polynomial in 

131
00:10:01,772 --> 00:10:05,720
terms of powers of x minus pi, or whatever input you're looking at.

132
00:10:06,320 --> 00:10:09,208
This makes it look noticeably more complicated, 

133
00:10:09,208 --> 00:10:13,961
but all we're doing is making sure that the point pi looks and behaves like 0, 

134
00:10:13,961 --> 00:10:18,715
so that plugging in x equals pi will result in a lot of nice cancellation that 

135
00:10:18,715 --> 00:10:20,220
leaves only one constant.

136
00:10:22,380 --> 00:10:27,731
And finally, on a more philosophical level, notice how what we're doing here is basically 

137
00:10:27,731 --> 00:10:32,666
taking information about higher order derivatives of a function at a single point, 

138
00:10:32,666 --> 00:10:37,780
and translating that into information about the value of the function near that point.

139
00:10:40,960 --> 00:10:44,120
You can take as many derivatives of cosine as you want.

140
00:10:44,600 --> 00:10:47,544
It follows this nice cyclic pattern, cosine of x, 

141
00:10:47,544 --> 00:10:51,020
negative sine of x, negative cosine, sine, and then repeat.

142
00:10:52,320 --> 00:10:55,660
And the value of each one of these is easy to compute at x equals 0.

143
00:10:56,100 --> 00:11:01,100
It gives this cyclic pattern 1, 0, negative 1, 0, and then repeat.

144
00:11:02,000 --> 00:11:07,149
And knowing the values of all those higher order derivatives is a lot of information 

145
00:11:07,149 --> 00:11:12,480
about cosine of x, even though it only involves plugging in a single number, x equals 0.

146
00:11:14,260 --> 00:11:19,603
So what we're doing is leveraging that information to get an approximation around this 

147
00:11:19,603 --> 00:11:25,131
input, and you do it by creating a polynomial whose higher order derivatives are designed 

148
00:11:25,131 --> 00:11:30,660
to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern.

149
00:11:31,420 --> 00:11:35,482
And to do that, you just make each coefficient of the polynomial follow that 

150
00:11:35,482 --> 00:11:39,440
same pattern, but you have to divide each one by the appropriate factorial.

151
00:11:40,120 --> 00:11:42,615
Like I mentioned before, this is what cancels out 

152
00:11:42,615 --> 00:11:45,260
the cascading effect of many power rule applications.

153
00:11:47,280 --> 00:11:50,111
The polynomials you get by stopping this process at 

154
00:11:50,111 --> 00:11:53,160
any point are called Taylor polynomials for cosine of x.

155
00:11:53,900 --> 00:11:58,847
More generally, and hence more abstractly, if we were dealing with some other function 

156
00:11:58,847 --> 00:12:03,794
other than cosine, you would compute its derivative, its second derivative, and so on, 

157
00:12:03,794 --> 00:12:08,400
getting as many terms as you'd like, and evaluate each one of them at x equals 0.

158
00:12:09,580 --> 00:12:15,938
Then for the polynomial approximation, the coefficient of each x to the n term should be 

159
00:12:15,938 --> 00:12:20,511
the value of the nth derivative of the function evaluated at 0, 

160
00:12:20,511 --> 00:12:22,440
but divided by n factorial.

161
00:12:23,480 --> 00:12:27,371
This whole rather abstract formula is something you'll likely 

162
00:12:27,371 --> 00:12:31,200
see in any text or course that touches on Taylor polynomials.

163
00:12:31,780 --> 00:12:36,139
And when you see it, think to yourself that the constant term ensures that 

164
00:12:36,139 --> 00:12:39,452
the value of the polynomial matches with the value of f, 

165
00:12:39,452 --> 00:12:43,696
the next term ensures that the slope of the polynomial matches the slope 

166
00:12:43,696 --> 00:12:48,114
of the function at x equals 0, the next term ensures that the rate at which 

167
00:12:48,114 --> 00:12:51,369
the slope changes is the same at that point, and so on, 

168
00:12:51,369 --> 00:12:53,520
depending on how many terms you want.

169
00:12:54,620 --> 00:12:57,451
And the more terms you choose, the closer the approximation, 

170
00:12:57,451 --> 00:13:00,980
but the tradeoff is that the polynomial you'd get would be more complicated.

171
00:13:02,640 --> 00:13:07,727
And to make things even more general, if you wanted to approximate near some input 

172
00:13:07,727 --> 00:13:12,937
other than 0, which we'll call a, you would write this polynomial in terms of powers 

173
00:13:12,937 --> 00:13:17,780
of x minus a, and you would evaluate all the derivatives of f at that input, a.

174
00:13:18,680 --> 00:13:23,120
This is what Taylor polynomials look like in their fullest generality.

175
00:13:24,000 --> 00:13:28,534
Changing the value of a changes where this approximation is hugging the original 

176
00:13:28,534 --> 00:13:33,236
function, where its higher order derivatives will be equal to those of the original 

177
00:13:33,236 --> 00:13:33,740
function.

178
00:13:35,880 --> 00:13:38,860
One of the simplest meaningful examples of this is 

179
00:13:38,860 --> 00:13:41,900
the function e to the x around the input x equals 0.

180
00:13:42,760 --> 00:13:46,406
Computing the derivatives is super nice, as nice as it gets, 

181
00:13:46,406 --> 00:13:49,275
because the derivative of e to the x is itself, 

182
00:13:49,275 --> 00:13:53,580
so the second derivative is also e to the x, as is its third, and so on.

183
00:13:54,340 --> 00:13:58,240
So at the point x equals 0, all of these are equal to 1.

184
00:13:59,120 --> 00:14:05,627
And what that means is our polynomial approximation should look 

185
00:14:05,627 --> 00:14:13,659
like 1 plus 1 times x plus 1 over 2 times x2 plus 1 over 3 factorial times x3, 

186
00:14:13,659 --> 00:14:18,540
and so on, depending on how many terms you want.

187
00:14:19,400 --> 00:14:22,700
These are the Taylor polynomials for e to the x.

188
00:14:26,380 --> 00:14:31,039
Ok, so with that as a foundation, in the spirit of showing you just how connected all 

189
00:14:31,039 --> 00:14:34,614
the topics of calculus are, let me turn to something kind of fun, 

190
00:14:34,614 --> 00:14:38,840
a completely different way to understand this second order term of the Taylor 

191
00:14:38,840 --> 00:14:40,520
polynomials, but geometrically.

192
00:14:41,400 --> 00:14:43,904
It's related to the fundamental theorem of calculus, 

193
00:14:43,904 --> 00:14:47,260
which I talked about in chapters 1 and 8 if you need a quick refresher.

194
00:14:47,980 --> 00:14:52,001
Like we did in those videos, consider a function that gives the area 

195
00:14:52,001 --> 00:14:56,140
under some graph between a fixed left point and a variable right point.

196
00:14:56,980 --> 00:15:00,915
What we're going to do here is think about how to approximate this area function, 

197
00:15:00,915 --> 00:15:04,180
not the function for the graph itself, like we've been doing before.

198
00:15:04,900 --> 00:15:09,440
Focusing on that area is what's going to make the second order term pop out.

199
00:15:10,440 --> 00:15:16,575
Remember, the fundamental theorem of calculus is that this graph itself represents the 

200
00:15:16,575 --> 00:15:22,711
derivative of the area function, and it's because a slight nudge dx to the right bound 

201
00:15:22,711 --> 00:15:28,988
of the area gives a new bit of area approximately equal to the height of the graph times 

202
00:15:28,988 --> 00:15:29,200
dx.

203
00:15:30,040 --> 00:15:34,480
And that approximation is increasingly accurate for smaller and smaller choices of dx.

204
00:15:35,980 --> 00:15:39,601
But if you wanted to be more accurate about this change in area, 

205
00:15:39,601 --> 00:15:42,666
given some change in x that isn't meant to approach 0, 

206
00:15:42,666 --> 00:15:46,065
you would have to take into account this portion right here, 

207
00:15:46,065 --> 00:15:47,960
which is approximately a triangle.

208
00:15:49,600 --> 00:15:57,460
Let's name the starting input a, and the nudged input above it x, so that change is x-a.

209
00:15:58,100 --> 00:16:02,985
The base of that little triangle is that change, x-a, 

210
00:16:02,985 --> 00:16:07,600
and its height is the slope of the graph times x-a.

211
00:16:08,420 --> 00:16:11,987
Since this graph is the derivative of the area function, 

212
00:16:11,987 --> 00:16:17,120
its slope is the second derivative of the area function, evaluated at the input a.

213
00:16:18,440 --> 00:16:22,662
So the area of this triangle, 1 half base times height, 

214
00:16:22,662 --> 00:16:28,467
is 1 half times the second derivative of this area function, evaluated at a, 

215
00:16:28,467 --> 00:16:29,900
multiplied by x-a2.

216
00:16:30,960 --> 00:16:34,380
And this is exactly what you would see with a Taylor polynomial.

217
00:16:34,880 --> 00:16:40,478
If you knew the various derivative information about this area function at the point a, 

218
00:16:40,478 --> 00:16:43,660
how would you approximate the area at the point x?

219
00:16:45,360 --> 00:16:49,316
Well you have to include all that area up to a, f of a, 

220
00:16:49,316 --> 00:16:54,968
plus the area of this rectangle here, which is the first derivative, times x-a, 

221
00:16:54,968 --> 00:17:00,902
plus the area of that little triangle, which is 1 half times the second derivative, 

222
00:17:00,902 --> 00:17:01,680
times x-a2.

223
00:17:02,560 --> 00:17:06,539
I really like this, because even though it looks a bit messy all written out, 

224
00:17:06,539 --> 00:17:11,079
each one of the terms has a very clear meaning that you can just point to on the diagram.

225
00:17:13,400 --> 00:17:16,877
If you wanted, we could call it an end here, and you would have a 

226
00:17:16,877 --> 00:17:20,460
phenomenally useful tool for approximating these Taylor polynomials.

227
00:17:21,400 --> 00:17:25,812
But if you're thinking like a mathematician, one question you might ask is 

228
00:17:25,812 --> 00:17:30,460
whether or not it makes sense to never stop and just add infinitely many terms.

229
00:17:31,380 --> 00:17:35,883
In math, an infinite sum is called a series, so even though one of these 

230
00:17:35,883 --> 00:17:40,263
approximations with finitely many terms is called a Taylor polynomial, 

231
00:17:40,263 --> 00:17:44,520
adding all infinitely many terms gives what's called a Taylor series.

232
00:17:45,260 --> 00:17:48,848
You have to be really careful with the idea of an infinite series, 

233
00:17:48,848 --> 00:17:52,598
because it doesn't actually make sense to add infinitely many things, 

234
00:17:52,598 --> 00:17:56,080
you can only hit the plus button on the calculator so many times.

235
00:17:57,440 --> 00:18:01,380
But if you have a series where adding more and more of the terms, 

236
00:18:01,380 --> 00:18:06,396
which makes sense at each step, gets you increasingly close to some specific value, 

237
00:18:06,396 --> 00:18:09,740
what you say is that the series converges to that value.

238
00:18:10,320 --> 00:18:14,293
Or, if you're comfortable extending the definition of equality to 

239
00:18:14,293 --> 00:18:19,049
include this kind of series convergence, you'd say that the series as a whole, 

240
00:18:19,049 --> 00:18:22,360
this infinite sum, equals the value it's converging to.

241
00:18:23,460 --> 00:18:27,452
For example, look at the Taylor polynomial for e to the x, 

242
00:18:27,452 --> 00:18:30,160
and plug in some input, like x equals 1.

243
00:18:31,140 --> 00:18:36,190
As you add more and more polynomial terms, the total sum gets 

244
00:18:36,190 --> 00:18:41,404
closer and closer to the value e, so you say that this infinite 

245
00:18:41,404 --> 00:18:46,700
series converges to the number e, or that it equals the number e.

246
00:18:47,840 --> 00:18:53,639
In fact, it turns out that if you plug in any other value of x, like x equals 2, 

247
00:18:53,639 --> 00:18:59,867
and look at the value of the higher and higher order Taylor polynomials at this value, 

248
00:18:59,867 --> 00:19:04,020
they will converge towards e to the x, which is e squared.

249
00:19:04,680 --> 00:19:08,951
This is true for any input, no matter how far away from 0 it is, 

250
00:19:08,951 --> 00:19:14,602
even though these Taylor polynomials are constructed only from derivative information 

251
00:19:14,602 --> 00:19:16,180
gathered at the input 0.

252
00:19:18,270 --> 00:19:24,276
In a case like this, we say that e to the x equals its own Taylor series at all inputs x, 

253
00:19:24,276 --> 00:19:27,480
which is kind of a magical thing to have happen.

254
00:19:28,380 --> 00:19:32,400
Even though this is also true for a couple other important functions, 

255
00:19:32,400 --> 00:19:36,306
like sine and cosine, sometimes these series only converge within a 

256
00:19:36,306 --> 00:19:40,500
certain range around the input whose derivative information you're using.

257
00:19:41,580 --> 00:19:47,273
If you work out the Taylor series for the natural log of x around the input x equals 1, 

258
00:19:47,273 --> 00:19:51,996
which is built by evaluating the higher order derivatives of the natural 

259
00:19:51,996 --> 00:19:55,620
log of x at x equals 1, this is what it would look like.

260
00:19:56,080 --> 00:20:00,800
When you plug in an input between 0 and 2, adding more and more terms of this 

261
00:20:00,800 --> 00:20:05,520
series will indeed get you closer and closer to the natural log of that input.

262
00:20:06,400 --> 00:20:09,510
But outside of that range, even by just a little bit, 

263
00:20:09,510 --> 00:20:11,700
the series fails to approach anything.

264
00:20:12,480 --> 00:20:17,440
As you add on more and more terms, the sum bounces back and forth wildly.

265
00:20:18,100 --> 00:20:22,695
It does not, as you might expect, approach the natural log of that value, 

266
00:20:22,695 --> 00:20:27,540
even though the natural log of x is perfectly well defined for inputs above 2.

267
00:20:28,460 --> 00:20:31,839
In some sense, the derivative information of ln 

268
00:20:31,839 --> 00:20:35,360
of x at x equals 1 doesn't propagate out that far.

269
00:20:36,580 --> 00:20:41,277
In a case like this, where adding more terms of the series doesn't approach anything, 

270
00:20:41,277 --> 00:20:43,080
you say that the series diverges.

271
00:20:44,180 --> 00:20:47,953
And that maximum distance between the input you're approximating 

272
00:20:47,953 --> 00:20:51,669
near and points where the outputs of these polynomials actually 

273
00:20:51,669 --> 00:20:55,560
converge is called the radius of convergence for the Taylor series.

274
00:20:56,840 --> 00:20:59,160
There remains more to learn about Taylor series.

275
00:20:59,500 --> 00:21:03,242
There are many use cases, tactics for placing bounds on the error of 

276
00:21:03,242 --> 00:21:07,636
these approximations, tests for understanding when series do and don't converge, 

277
00:21:07,636 --> 00:21:11,759
and for that matter, there remains more to learn about calculus as a whole, 

278
00:21:11,759 --> 00:21:14,580
and the countless topics not touched by this series.

279
00:21:15,320 --> 00:21:19,241
The goal with these videos is to give you the fundamental intuitions 

280
00:21:19,241 --> 00:21:23,389
that make you feel confident and efficient in learning more on your own, 

281
00:21:23,389 --> 00:21:27,140
and potentially even rediscovering more of the topic for yourself.

282
00:21:28,060 --> 00:21:32,327
In the case of Taylor series, the fundamental intuition to keep in mind 

283
00:21:32,327 --> 00:21:36,595
as you explore more of what there is, is that they translate derivative 

284
00:21:36,595 --> 00:21:41,160
information at a single point to approximation information around that point.

285
00:21:43,920 --> 00:21:46,600
Thank you once again to everybody who supported this series.

286
00:21:47,300 --> 00:21:49,529
The next series like it will be on probability, 

287
00:21:49,529 --> 00:21:53,060
and if you want early access as those videos are made, you know where to go.

288
00:22:11,160 --> 00:22:19,060
Thank you.

