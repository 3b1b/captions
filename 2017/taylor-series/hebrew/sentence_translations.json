[
 {
  "input": "When I first learned about Taylor series, I definitely didn't appreciate just how important they are. ",
  "translatedText": "כאשר למדתי לראשונה על סדרות טיילור, בהחלט לא הערכתי עד כמה הן חשובות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.64,
  "end": 19.7
 },
 {
  "input": "But time and time again they come up in math, physics, and many fields of engineering because they're one of the most powerful tools that math has to offer for approximating functions. ",
  "translatedText": "אבל פעם אחר פעם הם מופיעים במתמטיקה, בפיזיקה ובתחומים רבים של הנדסה מכיוון שהם אחד הכלים החזקים ביותר שיש למתמטיקה להציע לקירוב פונקציות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.12,
  "end": 29.18
 },
 {
  "input": "I think one of the first times this clicked for me as a student was not in a calculus class, but a physics class. ",
  "translatedText": "אני חושב שאחת הפעמים הראשונות שזה השפיע עליי כתלמיד לא הייתה בשיעור חשבון, אלא בשיעור פיזיקה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 30.0,
  "end": 35.42
 },
 {
  "input": "We were studying a certain problem that had to do with the potential energy of a pendulum, and for that you need an expression for how high the weight of the pendulum is above its lowest point, and when you work that out it comes out to be proportional to 1 minus the cosine of the angle between the pendulum and the vertical. ",
  "translatedText": "חקרנו בעיה מסוימת שקשורה לאנרגיה הפוטנציאלית של מטוטלת, ולשם כך צריך ביטוי לכמה גבוה המשקל של המטוטלת מעל הנקודה הנמוכה ביותר שלה, וכשמחשבים את זה זה יוצא פרופורציונלי ל-1 פחות הקוסינוס של הזווית בין המטוטלת לאנך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.84,
  "end": 53.0
 },
 {
  "input": "The specifics of the problem we were trying to solve are beyond the point here, but what I'll say is that this cosine function made the problem awkward and unwieldy, and made it less clear how pendulums relate to other oscillating phenomena. ",
  "translatedText": "הפרטים הספציפיים של הבעיה שניסינו לפתור הם מעבר לעניין כאן, אבל מה שאני אגיד הוא שפונקציית הקוסינוס הזו הפכה את הבעיה למסורבלת ומסורבלת, והבהירה פחות איך מטוטלות קשורות לתופעות נדנודות אחרות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.58,
  "end": 66.52
 },
 {
  "input": "But if you approximate cosine of theta as 1 minus theta squared over 2, everything just fell into place much more easily. ",
  "translatedText": "אבל אם אתה מעריך את הקוסינוס של תטא כ-1 מינוס תטא בריבוע על פני 2, הכל פשוט נפל למקומו הרבה יותר בקלות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.46,
  "end": 75.96
 },
 {
  "input": "If you've never seen anything like this before, an approximation like that might seem completely out of left field. ",
  "translatedText": "אם מעולם לא ראית דבר כזה בעבר, קירוב כזה עשוי להיראות לגמרי מחוץ לשדה השמאלי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.66,
  "end": 82.78
 },
 {
  "input": "If you graph cosine of theta along with this function, 1 minus theta squared over 2, they do seem rather close to each other, at least for small angles near 0, but how would you even think to make this approximation, and how would you find that particular quadratic? ",
  "translatedText": "אם אתה מצייר את הקוסינוס של תטא יחד עם הפונקציה הזו, 1 פחות תטא בריבוע על פני 2, הם אכן נראים קרובים זה לזה, לפחות עבור זוויות קטנות ליד 0, אבל איך אתה בכלל חושב לעשות את הקירוב הזה, ואיך היית למצוא את הריבוע הספציפי הזה? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 83.82,
  "end": 99.42
 },
 {
  "input": "The study of Taylor series is largely about taking non-polynomial functions and finding polynomials that approximate them near some input. ",
  "translatedText": "המחקר של סדרת טיילור עוסק במידה רבה בנטילת פונקציות לא פולינומיות ומציאת פולינומים שמתקרבים אליהם ליד קלט כלשהו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 101.22,
  "end": 108.84
 },
 {
  "input": "The motive here is that polynomials tend to be much easier to deal with than other functions. ",
  "translatedText": "המניע כאן הוא שפולינומים נוטים להיות הרבה יותר קלים להתמודדות מאשר פונקציות אחרות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.84,
  "end": 113.76
 },
 {
  "input": "They're easier to compute, easier to take derivatives, easier to integrate, just all around more friendly. ",
  "translatedText": "קל יותר לחשב אותם, קל יותר לקחת נגזרות, קל יותר לשילוב, פשוט יותר ידידותי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 114.34,
  "end": 119.48
 },
 {
  "input": "So let's take a look at that function, cosine of x, and really take a moment to think about how you might construct a quadratic approximation near x equals 0. ",
  "translatedText": "אז בואו נסתכל על הפונקציה הזו, הקוסינוס של x, ובאמת נקדיש רגע לחשוב איך אפשר לבנות קירוב ריבועי ליד x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.68,
  "end": 130.22
 },
 {
  "input": "That is, among all of the possible polynomials that look like c0 plus c1 times x plus c2 times x squared, for some choice of these constants, c0, c1, and c2, find the one that most resembles cosine of x near x equals 0, whose graph kind of spoons with the graph of cosine x at that point. ",
  "translatedText": "כלומר, בין כל הפולינומים האפשריים שנראים כמו c0 ועוד c1 כפול x ועוד c2 כפול x בריבוע, עבור בחירה מסוימת של הקבועים הללו, c0, c1 ו-c2, מצא את זה שהכי דומה לקוסינוס של x ליד x שווה ל-0 , שהגרף שלו סוג של כפיות עם הגרף של קוסינוס x באותה נקודה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 130.94,
  "end": 152.66
 },
 {
  "input": "Well, first of all, at the input 0, the value of cosine of x is 1, so if our approximation is going to be any good at all, it should also equal 1 at the input x equals 0. ",
  "translatedText": "ובכן, קודם כל, בכניסה 0, הערך של הקוסינוס של x הוא 1, אז אם הקירוב שלנו הולך להיות טוב בכלל, הוא צריך להיות שווה גם ל-1 בכניסה x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.86,
  "end": 164.92
 },
 {
  "input": "Plugging in 0 just results in whatever c0 is, so we can set that equal to 1. ",
  "translatedText": "חיבור של 0 רק מביא למה ש- c0 הוא, אז אנחנו יכולים להגדיר את זה שווה ל-1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.82,
  "end": 170.94
 },
 {
  "input": "This leaves us free to choose constants c1 and c2 to make this approximation as good as we can, but nothing we do with them is going to change the fact that the polynomial equals 1 at x equals 0. ",
  "translatedText": "זה משאיר אותנו חופשיים לבחור בקבועים c1 ו-c2 כדי להפוך את הקירוב הזה טוב ככל האפשר, אבל שום דבר שנעשה איתם לא ישנה את העובדה שהפולינום שווה ל-1 ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.08,
  "end": 184.0
 },
 {
  "input": "It would also be good if our approximation had the same tangent slope as cosine x at this point of interest. ",
  "translatedText": "זה יהיה גם טוב אם לקירוב שלנו יהיה אותו שיפוע משיק כמו קוסינוס x בנקודת עניין זו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 184.96,
  "end": 191.12
 },
 {
  "input": "Otherwise, the approximation drifts away from the cosine graph much faster than it needs to. ",
  "translatedText": "אחרת, הקירוב מתרחק מגרף הקוסינוס הרבה יותר מהר ממה שהוא צריך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.9,
  "end": 196.7
 },
 {
  "input": "The derivative of cosine is negative sine, and at x equals 0, that equals 0, meaning the tangent line is perfectly flat. ",
  "translatedText": "הנגזרת של קוסינוס היא סינוס שלילי, וב-x שווה ל-0, זה שווה ל-0, כלומר קו המשיק שטוח לחלוטין. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 205.84
 },
 {
  "input": "On the other hand, when you work out the derivative of our quadratic, you get c1 plus 2 times c2 times x. ",
  "translatedText": "מצד שני, כשמחשבים את הנגזרת של הריבוע שלנו, מקבלים c1 פלוס 2 כפול c2 כפול x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 214.4
 },
 {
  "input": "At x equals 0, this just equals whatever we choose for c1. ",
  "translatedText": "ב-x שווה ל-0, זה פשוט שווה לכל מה שנבחר עבור c1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.32,
  "end": 219.42
 },
 {
  "input": "So this constant c1 has complete control over the derivative of our approximation around x equals 0. ",
  "translatedText": "אז לקבוע זה c1 יש שליטה מלאה על הנגזרת של הקירוב שלנו סביב x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.26,
  "end": 226.34
 },
 {
  "input": "Setting it equal to 0 ensures that our approximation also has a flat tangent line at this point. ",
  "translatedText": "הגדרתו שווה ל-0 מבטיחה שגם לקירוב שלנו יש קו משיק שטוח בנקודה זו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 227.12,
  "end": 232.3
 },
 {
  "input": "This leaves us free to change c2, but the value and slope of our polynomial at x equals 0 are locked in place to match that of cosine. ",
  "translatedText": "זה משאיר אותנו חופשיים לשנות את c2, אבל הערך והשיפוע של הפולינום שלנו ב-x שווה ל-0 נעולים במקומם כדי להתאים לזה של קוסינוס. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 233.0,
  "end": 242.62
 },
 {
  "input": "The final thing to take advantage of is the fact that the cosine graph curves downward above x equals 0, it has a negative second derivative. ",
  "translatedText": "הדבר האחרון שצריך לנצל הוא העובדה שגרף הקוסינוס מתעקל כלפי מטה מעל x שווה ל-0, יש לו נגזרת שנייה שלילית. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 244.26,
  "end": 252.44
 },
 {
  "input": "Or in other words, even though the rate of change is 0 at that point, the rate of change itself is decreasing around that point. ",
  "translatedText": "או במילים אחרות, למרות שקצב השינוי הוא 0 באותה נקודה, קצב השינוי עצמו יורד סביב הנקודה הזו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.38,
  "end": 260.46
 },
 {
  "input": "Specifically, since its derivative is negative sine of x, its second derivative is negative cosine of x, and at x equals 0, that equals negative 1. ",
  "translatedText": "באופן ספציפי, מכיוון שהנגזרת שלו היא סינוס שלילי של x, הנגזרת השנייה שלו היא קוסינוס שלילי של x, וב-x שווה ל-0, זה שווה ל-1 שלילי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 261.28,
  "end": 271.84
 },
 {
  "input": "Now in the same way that we wanted the derivative of our approximation to match that of the cosine, so that their values wouldn't drift apart needlessly quickly, making sure that their second derivatives match will ensure that they curve at the same rate, that the slope of our polynomial doesn't drift away from the slope of cosine x any more quickly than it needs to. ",
  "translatedText": "עכשיו באותו האופן שבו רצינו שהנגזרת של הקירוב שלנו תתאים לזו של הקוסינוס, כדי שהערכים שלהם לא יתרחקו במהירות מיותרת, לוודא שהתאמת הנגזרות השניות שלהם תבטיח שהם מתעקלים באותו קצב, זה השיפוע של הפולינום שלנו לא מתרחק מהשיפוע של קוסינוס x מהר יותר ממה שהוא צריך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 273.08,
  "end": 293.32
 },
 {
  "input": "Pulling up the same derivative we had before, and then taking its derivative, we see that the second derivative of this polynomial is exactly 2 times c2. ",
  "translatedText": "משיכת אותה נגזרת שהייתה לנו קודם, ואז לוקחים את הנגזרת שלה, אנו רואים שהנגזרת השנייה של הפולינום הזה היא בדיוק 2 כפול c2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.22,
  "end": 304.04
 },
 {
  "input": "So to make sure that this second derivative also equals negative 1 at x equals 0, 2 times c2 has to be negative 1, meaning c2 itself should be negative 1 half. ",
  "translatedText": "אז כדי לוודא שהנגזרת השנייה הזו שווה גם ל-1 שלילי ב-x שווה ל-0, 2 כפול c2 צריך להיות שלילי 1, כלומר c2 עצמו צריך להיות שלילי 1 חצי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.96,
  "end": 315.58
 },
 {
  "input": "And this gives us the approximation 1 plus 0x minus 1 half x squared. ",
  "translatedText": "וזה נותן לנו את הקירוב 1 פלוס 0x מינוס 1 חצי x בריבוע. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.38,
  "end": 322.14
 },
 {
  "input": "And to get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial, you'd estimate it to be 0.995. ",
  "translatedText": "וכדי לקבל תחושה עד כמה זה טוב, אם אתה מעריך קוסינוס של 0.1 באמצעות פולינום זה, אתה מעריך אותו כ-0.995. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.2,
  "end": 331.6
 },
 {
  "input": "And this is the true value of cosine of 0.1. ",
  "translatedText": "וזה הערך האמיתי של קוסינוס של 0.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.52,
  "end": 335.82
 },
 {
  "input": "It's a really good approximation! ",
  "translatedText": "זה קירוב ממש טוב! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.64,
  "end": 338.44
 },
 {
  "input": "Take a moment to reflect on what just happened. ",
  "translatedText": "קחו רגע להרהר במה שקרה זה עתה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.3,
  "end": 342.52
 },
 {
  "input": "You had 3 degrees of freedom with this quadratic approximation, the constants c0, c1, and c2. ",
  "translatedText": "היו לך 3 דרגות חופש עם הקירוב הריבועי הזה, הקבועים c0, c1 ו-c2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.52,
  "end": 349.02
 },
 {
  "input": "c0 was responsible for making sure that the output of the approximation matches that of cosine x at x equals 0. ",
  "translatedText": "c0 היה אחראי לוודא שהפלט של הקירוב תואם לזה של קוסינוס x ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.52,
  "end": 356.44
 },
 {
  "input": "c1 was in charge of making sure that the derivatives match at that point, and c2 was responsible for making sure that the second derivatives match up. ",
  "translatedText": "c1 היה אחראי לוודא שהנגזרות תואמות בשלב זה, ו-c2 הייתה אחראית לוודא שהנגזרות השניות תואמות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.12,
  "end": 368.24
 },
 {
  "input": "This ensures that the way your approximation changes as you move away from x equals 0, and the way that the rate of change itself changes, is as similar as possible to the behavior of cosine x, given the amount of control you have. ",
  "translatedText": "זה מבטיח שהאופן שבו הקירוב שלך משתנה ככל שאתה מתרחק מ-x שווה ל-0, והאופן שבו קצב השינוי עצמו משתנה, יהיה דומה ככל האפשר להתנהגות של קוסינוס x, בהתחשב בכמות השליטה שיש לך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 368.94,
  "end": 383.16
 },
 {
  "input": "You could give yourself more control by allowing more terms in your polynomial and matching higher order derivatives. ",
  "translatedText": "אתה יכול לתת לעצמך יותר שליטה על ידי התרת מונחים נוספים בפולינום שלך והתאמת נגזרות מסדר גבוה יותר. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 384.08,
  "end": 390.14
 },
 {
  "input": "For example, let's say you added on the term c3 times x3 for some constant c3. ",
  "translatedText": "לדוגמה, נניח שהוספת על המונח c3 כפול x3 עבור איזה קבוע c3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.84,
  "end": 396.58
 },
 {
  "input": "In that case, if you take the third derivative of a cubic polynomial, anything that's quadratic or smaller goes to 0. ",
  "translatedText": "במקרה כזה, אם אתה לוקח את הנגזרת השלישית של פולינום מעוקב, כל דבר שהוא ריבועי או קטן יותר יעבור ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.58,
  "end": 404.28
 },
 {
  "input": "As for that last term, after 3 iterations of the power rule, it looks like 1 times 2 times 3 times c3. ",
  "translatedText": "לגבי אותו מונח אחרון, לאחר 3 איטרציות של כלל החזקה, זה נראה כמו 1 כפול 2 כפול 3 פעמים c3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 405.56,
  "end": 414.46
 },
 {
  "input": "On the other hand, the third derivative of cosine x comes out to sine x, which equals 0 at x equals 0. ",
  "translatedText": "מצד שני, הנגזרת השלישית של קוסינוס x יוצאת לסינוס x, ששווה ל-0 ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.46,
  "end": 423.28
 },
 {
  "input": "So to make sure that the third derivatives match, the constant c3 should be 0. ",
  "translatedText": "אז כדי לוודא שהנגזרות השלישיות תואמות, הקבוע c3 צריך להיות 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.28,
  "end": 428.76
 },
 {
  "input": "Or in other words, not only is 1 minus 1 half x2 the best possible quadratic approximation of cosine, it's also the best possible cubic approximation. ",
  "translatedText": "או במילים אחרות, לא רק ש-1 מינוס 1 חצי x2 הוא הקירוב הריבועי הטוב ביותר של קוסינוס, זה גם הקירוב המעוקב הטוב ביותר האפשרי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 429.88,
  "end": 439.58
 },
 {
  "input": "You can make an improvement by adding on a fourth order term, c4 times x to the fourth. ",
  "translatedText": "אתה יכול לעשות שיפור על ידי הוספת מונח מסדר רביעי, c4 כפול x לרביעי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.28,
  "end": 447.06
 },
 {
  "input": "The fourth derivative of cosine is itself, which equals 1 at x equals 0. ",
  "translatedText": "הנגזרת הרביעית של קוסינוס היא עצמה, ששווה ל-1 ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.88,
  "end": 453.32
 },
 {
  "input": "And what's the fourth derivative of our polynomial with this new term? ",
  "translatedText": "ומהי הנגזרת הרביעית של הפולינום שלנו עם המונח החדש הזה? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.3,
  "end": 457.46
 },
 {
  "input": "Well, when you keep applying the power rule over and over, with those exponents all hopping down in front, you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4. ",
  "translatedText": "ובכן, כשאתה ממשיך ליישם את כלל הכוח שוב ושוב, כשהמעריכים האלה כולם קופצים למטה מלפנים, אתה בסופו של דבר עם 1 כפול 2 כפול 3 כפול 4 כפול c4, שהם 24 כפול c4. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.62,
  "end": 471.0
 },
 {
  "input": "So if we want this to match the fourth derivative of cosine x, which is 1, c4 has to be 1 over 24. ",
  "translatedText": "אז אם אנחנו רוצים שזה יתאים לנגזרת הרביעית של קוסינוס x, שהיא 1, c4 חייב להיות 1 על 24. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.4,
  "end": 478.76
 },
 {
  "input": "And indeed, the polynomial 1 minus 1 half x2 plus 1 24 times x to the fourth, which looks like this, is a very close approximation for cosine x around x equals 0. ",
  "translatedText": "ואכן, הפולינום 1 פחות 1 חצי x2 פלוס 1 24 כפול x עד הרביעי, שנראה כך, הוא קירוב קרוב מאוד לקוסינוס x סביב x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.82,
  "end": 492.84
 },
 {
  "input": "In any physics problem involving the cosine of a small angle, for example, predictions would be almost unnoticeably different if you substituted this polynomial for cosine of x. ",
  "translatedText": "בכל בעיה פיזיקה המערבת את הקוסינוס של זווית קטנה, למשל, התחזיות יהיו שונות כמעט באופן בלתי מורגש אם תחליף את הפולינום הזה בקוסינוס של x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.74,
  "end": 504.06
 },
 {
  "input": "Now take a step back and notice a few things happening with this process. ",
  "translatedText": "עכשיו קחו צעד אחורה ושימו לב לכמה דברים שקורים בתהליך הזה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "First of all, factorial terms come up very naturally in this process. ",
  "translatedText": "קודם כל, מונחים פקטוריאליים עולים באופן טבעי בתהליך הזה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.52,
  "end": 514.2
 },
 {
  "input": "When you take n successive derivatives of the function x to the n, letting the power rule keep cascading on down, what you'll be left with is 1 times 2 times 3 on and on and on up to whatever n is. ",
  "translatedText": "כאשר אתה לוקח n נגזרות עוקבות של הפונקציה x ל-n, נותנים לכלל הכוח להמשיך להלך למטה, מה שיישאר לך הוא 1 כפול 2 כפול 3 והלאה והלאה עד מה שיהיה n. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.02,
  "end": 528.58
 },
 {
  "input": "So you don't simply set the coefficients of the polynomial equal to whatever derivative you want. ",
  "translatedText": "אז אתה לא פשוט מגדיר את המקדמים של הפולינום שווים לכל נגזרת שאתה רוצה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.22,
  "end": 534.24
 },
 {
  "input": "You have to divide by the appropriate factorial to cancel out this effect. ",
  "translatedText": "אתה צריך לחלק בפקטוריאלי המתאים כדי לבטל את האפקט הזה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.68,
  "end": 538.54
 },
 {
  "input": "For example, that x to the fourth coefficient was the fourth derivative of cosine, 1, but divided by 4 factorial, 24. ",
  "translatedText": "לדוגמה, ש-x למקדם הרביעי היה הנגזרת הרביעית של קוסינוס, 1, אך חלקי 4 פקטוריאליים, 24. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.4,
  "end": 547.78
 },
 {
  "input": "The second thing to notice is that adding on new terms, like this c4 times x to the fourth, doesn't mess up what the old terms should be, and that's really important. ",
  "translatedText": "הדבר השני שיש לשים לב אליו הוא שהוספת מונחים חדשים, כמו זה c4 כפול x לרביעי, לא פוגעת במה שהמונחים הישנים צריכים להיות, וזה באמת חשוב. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.4,
  "end": 559.3
 },
 {
  "input": "For example, the second derivative of this polynomial at x equals 0 is still equal to 2 times the second coefficient, even after you introduce higher order terms. ",
  "translatedText": "לדוגמה, הנגזרת השנייה של הפולינום הזה ב-x שווה ל-0 עדיין שווה לפי 2 מהמקדם השני, גם לאחר שהכנסת מונחים מסדר גבוה יותר. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.1,
  "end": 570.08
 },
 {
  "input": "And it's because we're plugging in x equals 0, so the second derivative of any higher order term, which all include an x, will just wash away. ",
  "translatedText": "וזה בגלל שאנחנו מחברים x שווה ל-0, אז הנגזרת השנייה של כל מונח מסדר גבוה יותר, שכוללת x, פשוט תשטוף. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 579.78
 },
 {
  "input": "And the same goes for any other derivative, which is why each derivative of a polynomial at x equals 0 is controlled by one and only one of the coefficients. ",
  "translatedText": "וכך גם לגבי כל נגזרת אחרת, וזו הסיבה שכל נגזרת של פולינום ב-x שווה ל-0 נשלטת על ידי אחד ויחיד מהמקדמים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 580.74,
  "end": 590.28
 },
 {
  "input": "If instead you were approximating near an input other than 0, like x equals pi, in order to get the same effect, you would have to write your polynomial in terms of powers of x minus pi, or whatever input you're looking at. ",
  "translatedText": "אם במקום זאת היית מקרוב ליד קלט שאינו 0, כמו x שווה ל-pi, כדי לקבל את אותו אפקט, תצטרך לכתוב את הפולינום שלך במונחים של חזקות של x מינוס pi, או כל קלט שאתה מסתכל עליו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.64,
  "end": 605.72
 },
 {
  "input": "This makes it look noticeably more complicated, but all we're doing is making sure that the point pi looks and behaves like 0, so that plugging in x equals pi will result in a lot of nice cancellation that leaves only one constant. ",
  "translatedText": "זה גורם לזה להיראות מסובך יותר באופן ניכר, אבל כל מה שאנחנו עושים זה לוודא שהנקודה pi נראית ומתנהגת כמו 0, כך שחיבור x שווה ל-pi יביא להרבה ביטול נחמד שישאיר רק קבוע אחד. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 606.32,
  "end": 620.22
 },
 {
  "input": "And finally, on a more philosophical level, notice how what we're doing here is basically taking information about higher order derivatives of a function at a single point, and translating that into information about the value of the function near that point. ",
  "translatedText": "ולבסוף, ברמה פילוסופית יותר, שימו לב איך מה שאנחנו עושים כאן זה בעצם לקחת מידע על נגזרות מסדר גבוה של פונקציה בנקודה אחת, ולתרגם את זה למידע על הערך של הפונקציה ליד אותה נקודה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.38,
  "end": 637.78
 },
 {
  "input": "You can take as many derivatives of cosine as you want. ",
  "translatedText": "אתה יכול לקחת כמה נגזרות של קוסינוס שאתה רוצה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 640.96,
  "end": 644.12
 },
 {
  "input": "It follows this nice cyclic pattern, cosine of x, negative sine of x, negative cosine, sine, and then repeat. ",
  "translatedText": "הוא עוקב אחר התבנית המחזורית הנחמדה הזו, קוסינוס של x, סינוס שלילי של x, קוסינוס שלילי, סינוס, ולאחר מכן חזרה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.6,
  "end": 651.02
 },
 {
  "input": "And the value of each one of these is easy to compute at x equals 0, it gives this cyclic pattern 1, 0, negative 1, 0, and then repeat. ",
  "translatedText": "וקל לחשב את הערך של כל אחד מאלה ב-x שווה ל-0, זה נותן לתבנית המחזורית הזו 1, 0, שלילי 1, 0, ואז לחזור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.32,
  "end": 661.1
 },
 {
  "input": "And knowing the values of all those higher order derivatives is a lot of information about cosine of x, even though it only involves plugging in a single number, x equals 0. ",
  "translatedText": "ולדעת את הערכים של כל אותן נגזרות מסדר גבוה יותר זה הרבה מידע על הקוסינוס של x, למרות שזה כרוך רק בחיבור של מספר בודד, x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.0,
  "end": 672.48
 },
 {
  "input": "So what we're doing is leveraging that information to get an approximation around this input, and you do it by creating a polynomial whose higher order derivatives are designed to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern. ",
  "translatedText": "אז מה שאנחנו עושים זה למנף את המידע הזה כדי לקבל קירוב סביב הקלט הזה, ואתה עושה את זה על ידי יצירת פולינום שנגזרות מסדר גבוה יותר שלו מתוכננות להתאים לאלו של קוסינוס, בעקבות אותו 1, 0, שלילי 1, 0, דפוס מחזורי. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 674.26,
  "end": 690.66
 },
 {
  "input": "And to do that, you just make each coefficient of the polynomial follow that same pattern, but you have to divide each one by the appropriate factorial. ",
  "translatedText": "וכדי לעשות זאת, אתה פשוט גורם לכל מקדם של הפולינום לעקוב אחר אותה תבנית, אבל אתה צריך לחלק כל אחד מהם בפקטור המתאים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.42,
  "end": 699.44
 },
 {
  "input": "Like I mentioned before, this is what cancels out the cascading effect of many power rule applications. ",
  "translatedText": "כמו שציינתי קודם, זה מה שמבטל את האפקט המדורג של יישומי כלל כוח רבים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.12,
  "end": 705.26
 },
 {
  "input": "The polynomials you get by stopping this process at any point are called Taylor polynomials for cosine of x. ",
  "translatedText": "הפולינומים שאתה מקבל על ידי עצירת התהליך הזה בכל נקודה נקראים פולינומים טיילור עבור קוסינוס של x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.28,
  "end": 713.16
 },
 {
  "input": "More generally, and hence more abstractly, if we were dealing with some other function other than cosine, you would compute its derivative, its second derivative, and so on, getting as many terms as you'd like, and you would evaluate each one of them at x equals 0. ",
  "translatedText": "באופן כללי יותר, ומכאן בצורה מופשטת יותר, אם היינו עוסקים בפונקציה אחרת מלבד קוסינוס, היית מחשב את הנגזרת שלה, הנגזרת השנייה שלה, וכן הלאה, מקבל כמה מונחים שתרצה, והיית מעריך כל אחד מהם מהם ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.9,
  "end": 728.4
 },
 {
  "input": "For the polynomial approximation, the coefficient of each x to the n term should be the value of the nth derivative of the function evaluated at 0, but divided by n factorial. ",
  "translatedText": "עבור הקירוב הפולינומי, המקדם של כל x לאיבר n צריך להיות הערך של הנגזרת ה-n של הפונקציה המוערכת ב-0, אך מחולק ב-n פקטור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.58,
  "end": 742.44
 },
 {
  "input": "This whole rather abstract formula is something you'll likely see in any text or course that touches on Taylor polynomials. ",
  "translatedText": "כל הנוסחה המופשטת למדי הזו היא משהו שסביר להניח שתראו בכל טקסט או קורס שנוגעים בפולינומים של טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.48,
  "end": 751.2
 },
 {
  "input": "When you see it, think to yourself that the constant term ensures that the value of the polynomial matches with the value of f. ",
  "translatedText": "כשאתה רואה את זה, תחשוב לעצמך שהמונח הקבוע מבטיח שהערך של הפולינום תואם את הערך של f. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 751.78,
  "end": 758.66
 },
 {
  "input": "The next term ensures that the slope of the polynomial matches the slope of the function at x equals 0. ",
  "translatedText": "האיבר הבא מבטיח שהשיפוע של הפולינום מתאים לשיפוע הפונקציה ב-x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.2,
  "end": 765.54
 },
 {
  "input": "The next term ensures that the rate at which the slope changes is the same at that point, and so on, depending on how many terms you want. ",
  "translatedText": "המונח הבא מבטיח שהקצב שבו משתנה השיפוע יהיה זהה באותה נקודה, וכן הלאה, תלוי בכמה מונחים אתה רוצה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.36,
  "end": 773.52
 },
 {
  "input": "And the more terms you choose, the closer the approximation, but the tradeoff is that the polynomial you'd get would be more complicated. ",
  "translatedText": "וככל שתבחרו יותר מונחים, כך הקירוב קרוב יותר, אבל ההחלפה היא שהפולינום שתקבל יהיה יותר מסובך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 774.62,
  "end": 780.98
 },
 {
  "input": "And to make things even more general, if you wanted to approximate near some input other than 0, which we'll call a, you would write this polynomial in terms of powers of x minus a, and you would evaluate all the derivatives of f at that input, a. ",
  "translatedText": "וכדי להפוך את הדברים אפילו יותר כלליים, אם אתה רוצה לקרב ליד קלט כלשהו מלבד 0, שנקרא לו a, היית כותב את הפולינום הזה במונחים של חזקות של x מינוס a, והיית מעריך את כל הנגזרות של f באותו קלט, א. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 782.64,
  "end": 797.78
 },
 {
  "input": "This is what Taylor polynomials look like in their fullest generality. ",
  "translatedText": "כך נראים פולינומים של טיילור במלוא הכלליות שלהם. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.68,
  "end": 803.12
 },
 {
  "input": "Changing the value of a changes where this approximation is hugging the original function, where its higher order derivatives will be equal to those of the original function. ",
  "translatedText": "שינוי הערך של משתנה כאשר הקירוב הזה מחבק את הפונקציה המקורית, כאשר הנגזרות מהסדר הגבוה שלה יהיו שוות לאלו של הפונקציה המקורית. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 804.0,
  "end": 813.74
 },
 {
  "input": "One of the simplest meaningful examples of this is the function e to the x around the input x equals 0. ",
  "translatedText": "אחת הדוגמאות המשמעותיות ביותר לכך היא הפונקציה e ל-x סביב הקלט x שווה ל-0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 815.88,
  "end": 821.9
 },
 {
  "input": "Computing the derivatives is super nice, as nice as it gets, because the derivative of e to the x is itself, so the second derivative is also e to the x, as is its third, and so on. ",
  "translatedText": "חישוב הנגזרות הוא סופר נחמד, עד כמה שזה יהיה נחמד, כי הנגזרת של e ל-x היא עצמה, אז הנגזרת השנייה היא גם e ל-x, כמו גם השלישית שלה, וכן הלאה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 822.76,
  "end": 833.58
 },
 {
  "input": "So at the point x equals 0, all of these are equal to 1. ",
  "translatedText": "אז בנקודה x שווה ל-0, כל אלה שווים ל-1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 834.34,
  "end": 838.24
 },
 {
  "input": "And what that means is our polynomial approximation should look like 1 plus 1 times x plus 1 over 2 times x squared plus 1 over 3 factorial times x cubed, and so on, depending on how many terms you want. ",
  "translatedText": "ומה שזה אומר הוא שקירוב הפולינום שלנו צריך להיראות כמו 1 פלוס 1 כפול x פלוס 1 על פני 2 כפול x בריבוע פלוס 1 על פני 3 כפול פקטורי x קובייה, וכן הלאה, תלוי בכמה איברים אתה רוצה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.12,
  "end": 858.54
 },
 {
  "input": "These are the Taylor polynomials for e to the x. ",
  "translatedText": "אלו הם הפולינומים של טיילור עבור e עד ה-x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 859.4,
  "end": 862.7
 },
 {
  "input": "Ok, so with that as a foundation, in the spirit of showing you just how connected all the topics of calculus are, let me turn to something kind of fun, a completely different way to understand this second order term of the Taylor polynomials, but geometrically. ",
  "translatedText": "אוקיי, אז עם זה כבסיס, ברוח של להראות לך עד כמה כל נושאי החשבון קשורים, הרשו לי לפנות למשהו מהנה, דרך אחרת לגמרי להבין את המונח הזה מסדר שני של פולינומי טיילור, אבל מבחינה גיאומטרית. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 866.38,
  "end": 880.52
 },
 {
  "input": "It's related to the fundamental theorem of calculus, which I talked about in chapters 1 and 8 if you need a quick refresher. ",
  "translatedText": "זה קשור למשפט היסודי של החשבון, עליו דיברתי בפרקים 1 ו-8 אם אתה צריך רענון מהיר. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.4,
  "end": 887.26
 },
 {
  "input": "Like we did in those videos, consider a function that gives the area under some graph between a fixed left point and a variable right point. ",
  "translatedText": "כמו שעשינו בסרטונים האלה, שקול פונקציה שנותנת את השטח מתחת לגרף כלשהו בין נקודה שמאלית קבועה לנקודת ימין משתנה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 887.98,
  "end": 896.14
 },
 {
  "input": "What we're going to do here is think about how to approximate this area function, not the function for the graph itself, like we've been doing before. ",
  "translatedText": "מה שאנחנו הולכים לעשות כאן זה לחשוב על איך להעריך את פונקציית השטח הזו, לא את הפונקציה של הגרף עצמו, כמו שעשינו בעבר. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.98,
  "end": 904.18
 },
 {
  "input": "Focusing on that area is what's going to make the second order term pop out. ",
  "translatedText": "התמקדות בתחום הזה היא מה שיגרום למונח מסדר שני לצוץ החוצה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.9,
  "end": 909.44
 },
 {
  "input": "Remember, the fundamental theorem of calculus is that this graph itself represents the derivative of the area function, and it's because a slight nudge dx to the right bound of the area gives a new bit of area approximately equal to the height of the graph times dx. ",
  "translatedText": "זכור, משפט היסוד של החשבון הוא שהגרף הזה עצמו מייצג את הנגזרת של פונקציית השטח, וזה בגלל שדחיפה קלה dx לגבול הימני של השטח נותן פיסת שטח חדשה השווה בערך לגובה הגרף כפול dx . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 910.44,
  "end": 929.2
 },
 {
  "input": "That approximation is increasingly accurate for smaller and smaller choices of dx. ",
  "translatedText": "הקירוב הזה מדויק יותר ויותר עבור אפשרויות קטנות יותר ויותר של dx. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.04,
  "end": 934.48
 },
 {
  "input": "But if you wanted to be more accurate about this change in area, given some change in x that isn't meant to approach 0, you would have to take into account this portion right here, which is approximately a triangle. ",
  "translatedText": "אבל אם אתה רוצה להיות מדויק יותר לגבי השינוי הזה בשטח, בהינתן שינוי כלשהו ב-x שלא אמור להתקרב ל-0, תצטרך לקחת בחשבון את החלק הזה ממש כאן, שהוא בערך משולש. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 935.98,
  "end": 947.96
 },
 {
  "input": "Let's name the starting input a, and the nudged input above it x, so that change is x-a. ",
  "translatedText": "בואו נקרא לקלט ההתחלתי a, ולקלט המודח מעליו x, כך שהשינוי הוא xa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.6,
  "end": 957.46
 },
 {
  "input": "The base of that little triangle is that change, x-a, and its height is the slope of the graph times x-a. ",
  "translatedText": "הבסיס של אותו משולש קטן הוא השינוי, xa, וגובהו הוא השיפוע של הגרף כפול xa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 958.1,
  "end": 967.6
 },
 {
  "input": "Since this graph is the derivative of the area function, its slope is the second derivative of the area function, evaluated at the input a. ",
  "translatedText": "מכיוון שגרף זה הוא הנגזרת של פונקציית השטח, השיפוע שלו הוא הנגזרת השנייה של פונקציית השטח, המוערך בקלט a. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 968.42,
  "end": 977.12
 },
 {
  "input": "So the area of this triangle, 1 half base times height, is 1 half times the second derivative of this area function, evaluated at a, multiplied by x-a squared. ",
  "translatedText": "אז השטח של משולש זה, 1 חצי בסיס כפול גובה, הוא 1 חצי כפול מהנגזרת השנייה של פונקציית שטח זו, מוערך ב-a, כפול xa בריבוע. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.44,
  "end": 989.9
 },
 {
  "input": "And this is exactly what you would see with a Taylor polynomial. ",
  "translatedText": "וזה בדיוק מה שהיית רואה עם פולינום טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 990.96,
  "end": 994.38
 },
 {
  "input": "If you knew the various derivative information about this area function at the point a, how would you approximate the area at the point x? ",
  "translatedText": "אם היית מכיר את המידע הנגזרת השונים על פונקציית שטח זו בנקודה a, כיצד היית מקרוב את השטח בנקודה x? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.88,
  "end": 1003.66
 },
 {
  "input": "You have to include all that area up to a, f of a, plus the area of this rectangle here, which is the first derivative, times x-a, plus the area of that little triangle, which is 1 half times the second derivative, times x-a squared. ",
  "translatedText": "אתה צריך לכלול את כל השטח הזה עד a, f של a, בתוספת השטח של המלבן הזה כאן, שהוא הנגזרת הראשונה, כפול xa, בתוספת השטח של המשולש הקטן הזה, שהוא 1 חצי כפול הנגזרת השנייה, כפול xa בריבוע. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.36,
  "end": 1021.68
 },
 {
  "input": "I really like this, because even though it looks a bit messy all written out, each one of the terms has a very clear meaning that you can just point to on the diagram. ",
  "translatedText": "אני מאוד אוהב את זה, כי למרות שזה נראה קצת מבולגן הכל כתוב, לכל אחד מהמונחים יש משמעות מאוד ברורה שאתה יכול פשוט להצביע עליה בתרשים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1022.56,
  "end": 1031.08
 },
 {
  "input": "If you wanted, we could call it an end here, and you would have a phenomenally useful tool for approximations with these Taylor polynomials. ",
  "translatedText": "אם תרצה, נוכל לקרוא לזה סוף כאן, והיה לך כלי שימושי בצורה פנומנלית לקירוב עם פולינומים אלה של טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.4,
  "end": 1040.46
 },
 {
  "input": "But if you're thinking like a mathematician, one question you might ask is whether or not it makes sense to never stop and just add infinitely many terms. ",
  "translatedText": "אבל אם אתה חושב כמו מתמטיקאי, שאלה אחת שאתה עשוי לשאול היא האם זה הגיוני לעולם לא להפסיק ולהוסיף אינסוף מונחים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.4,
  "end": 1050.46
 },
 {
  "input": "In math, an infinite sum is called a series, so even though one of these approximations with finitely many terms is called a Taylor polynomial, adding all infinitely many terms gives what's called a Taylor series. ",
  "translatedText": "במתמטיקה, סכום אינסופי נקרא סדרה, כך שלמרות שאחד מהקירובים הללו עם מספר סופי של איברים נקרא פולינום טיילור, הוספת כל אינסוף האיברים נותנת מה שנקרא סדרת טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1051.38,
  "end": 1064.52
 },
 {
  "input": "You have to be really careful with the idea of an infinite series, because it doesn't actually make sense to add infinitely many things, you can only hit the plus button on the calculator so many times. ",
  "translatedText": "אתה צריך להיות ממש זהיר עם הרעיון של סדרה אינסופית, כי זה לא באמת הגיוני להוסיף אינסוף דברים, אתה יכול רק ללחוץ על כפתור הפלוס במחשבון כל כך הרבה פעמים. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1065.26,
  "end": 1076.08
 },
 {
  "input": "But if you have a series where adding more and more of the terms, which makes sense at each step, gets you increasingly close to some specific value, you say that the series converges to that value. ",
  "translatedText": "אבל אם יש לך סדרה שבה הוספת עוד ועוד מהמונחים, שזה הגיוני בכל שלב, מקרבת אותך יותר ויותר לערך ספציפי כלשהו, אתה אומר שהסדרה מתכנסת לערך הזה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1077.44,
  "end": 1089.74
 },
 {
  "input": "Or if you're comfortable extending the definition of equality to include this kind of series convergence, you'd say that the series as a whole, this infinite sum, equals the value that it's converging to. ",
  "translatedText": "או אם אתה מרגיש בנוח להרחיב את הגדרת השוויון כך שתכלול סוג זה של התכנסות סדרה, היית אומר שהסדרה כולה, הסכום האינסופי הזה, שווה לערך שאליו היא מתכנסת. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1090.32,
  "end": 1102.36
 },
 {
  "input": "For example, look at the Taylor polynomial for e to the x, and plug in some input, like x equals 1. ",
  "translatedText": "לדוגמה, הסתכל על פולינום טיילור עבור e ל-x, וחבר קלט כלשהו, כמו x שווה ל-1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.46,
  "end": 1110.16
 },
 {
  "input": "As you add more and more polynomial terms, the total sum gets closer and closer to the value e, so you say that this infinite series converges to the number e, or what's saying the same thing, that it equals the number e. ",
  "translatedText": "ככל שמוסיפים עוד ועוד איברים פולינומים, הסכום הכולל מתקרב יותר ויותר לערך e, אז אתה אומר שהסדרה האינסופית הזו מתכנסת למספר e, או מה שאומר אותו דבר, שהיא שווה למספר e. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1111.14,
  "end": 1126.7
 },
 {
  "input": "In fact, it turns out that if you plug in any other value of x, like x equals 2, and look at the value of the higher and higher order Taylor polynomials at this value, they will converge towards e to the x, which is e squared. ",
  "translatedText": "למעשה, מסתבר שאם תחבר כל ערך אחר של x, כמו x שווה 2, ותסתכל על הערך של פולינומי טיילור מהסדר הגבוה והגבוה יותר בערך הזה, הם יתכנסו לכיוון e ל-x, שהוא ה' בריבוע. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1127.84,
  "end": 1144.02
 },
 {
  "input": "This is true for any input, no matter how far away from 0 it is, even though these Taylor polynomials are constructed only from derivative information gathered at the input 0. ",
  "translatedText": "זה נכון לכל קלט, לא משנה כמה הוא רחוק מ-0, למרות שהפולינומים של טיילור בנויים רק ממידע נגזרת שנאסף בקלט 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1144.68,
  "end": 1156.18
 },
 {
  "input": "In a case like this, we say that e to the x equals its own Taylor series at all inputs x, which is kind of a magical thing to have happen. ",
  "translatedText": "במקרה כזה, אנו אומרים ש-e ל-x שווה לסדרת טיילור משלה בכל הכניסות x, וזה סוג של דבר קסום שקרה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1158.27,
  "end": 1167.48
 },
 {
  "input": "Even though this is also true for a couple other important functions, like sine and cosine, sometimes these series only converge within a certain range around the input whose derivative information you're using. ",
  "translatedText": "למרות שזה נכון גם לכמה פונקציות חשובות אחרות, כמו סינוס וקוסינוס, לפעמים הסדרות הללו מתכנסות רק בטווח מסוים סביב הקלט שבו אתה משתמש במידע הנגזרת שלו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1180.5
 },
 {
  "input": "If you worked out the Taylor series for the natural log of x around the input x equals 1, which is built by evaluating the higher order derivatives of the natural log of x at x equals 1, this is what it would look like. ",
  "translatedText": "אם חישבת את סדרת טיילור עבור הלוג הטבעי של x סביב הקלט x שווה ל-1, אשר נבנה על ידי הערכת הנגזרות מהסדר הגבוה של הלוג הטבעי של x ב-x שווה ל-1, כך זה ייראה. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1181.58,
  "end": 1195.62
 },
 {
  "input": "When you plug in an input between 0 and 2, adding more and more terms of this series will indeed get you closer and closer to the natural log of that input. ",
  "translatedText": "כאשר אתה מחבר קלט בין 0 ל-2, הוספת עוד ועוד מונחים מהסדרה הזו אכן תקרב אותך יותר ויותר ללוג הטבעי של אותה קלט. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1196.08,
  "end": 1205.52
 },
 {
  "input": "But outside of that range, even by just a little bit, the series fails to approach anything. ",
  "translatedText": "אבל מחוץ לטווח הזה, אפילו במעט, הסדרה לא מצליחה להתקרב לשום דבר. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1206.4,
  "end": 1211.7
 },
 {
  "input": "As you add on more and more terms, the sum bounces back and forth wildly. ",
  "translatedText": "ככל שמוסיפים עוד ועוד תנאים, הסכום קופץ קדימה ואחורה בפראות. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1212.48,
  "end": 1217.44
 },
 {
  "input": "It does not, as you might expect, approach the natural log of that value, even though the natural log of x is perfectly well defined for inputs above 2. ",
  "translatedText": "הוא אינו מתקרב, כפי שניתן לצפות, ללוג הטבעי של הערך הזה, למרות שהלוג הטבעי של x מוגדר היטב עבור קלט מעל 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.1,
  "end": 1227.54
 },
 {
  "input": "In some sense, the derivative information of ln of x at x equals 1 doesn't propagate out that far. ",
  "translatedText": "במובן מסוים, המידע הנגזרת של ln של x ב-x שווה ל-1 לא מתפשט כל כך רחוק. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.46,
  "end": 1235.36
 },
 {
  "input": "In a case like this, where adding more terms of the series doesn't approach anything, you say the series diverges. ",
  "translatedText": "במקרה כזה, שבו הוספת עוד מונחים מהסדרה לא מתקרבת לשום דבר, אתה אומר שהסדרה מתפצלת. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1236.58,
  "end": 1243.08
 },
 {
  "input": "And that maximum distance between the input you're approximating near and points where the outputs of these polynomials actually converge is called the radius of convergence for the Taylor series. ",
  "translatedText": "והמרחק המקסימלי הזה בין הקלט שאתה מתקרב ליד לנקודות שבהן הפלטים של הפולינומים האלה מתכנסים בפועל נקרא רדיוס ההתכנסות עבור סדרת טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.18,
  "end": 1255.56
 },
 {
  "input": "There remains more to learn about Taylor series. ",
  "translatedText": "נותר עוד ללמוד על סדרת טיילור. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1256.84,
  "end": 1259.16
 },
 {
  "input": "There are many use cases, tactics for placing bounds on the error of these approximations, tests for understanding when series do and don't converge, and for that matter, there remains more to learn about calculus as a whole and the countless topics not touched by this series. ",
  "translatedText": "ישנם מקרי שימוש רבים, טקטיקות להצבת גבולות לטעות של קירובים אלה, מבחנים להבנה מתי סדרות מתכנסות ואינן מתכנסות, ולצורך העניין, נותר עוד ללמוד על החשבון בכללותו ועל אינספור הנושאים שלא נוגעים בהם. על ידי הסדרה הזו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1259.5,
  "end": 1274.58
 },
 {
  "input": "The goal with these videos is to give you the fundamental intuitions that make you feel confident and efficient in learning more on your own, and potentially even rediscovering more of the topic for yourself. ",
  "translatedText": "המטרה עם הסרטונים האלה היא לתת לך את האינטואיציות הבסיסיות שגורמות לך להרגיש בטוח ויעיל ללמוד יותר בעצמך, ואולי אפילו לגלות מחדש יותר מהנושא בעצמך. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1275.32,
  "end": 1287.14
 },
 {
  "input": "In the case of Taylor series, the fundamental intuition to keep in mind as you explore more of what there is, is that they translate derivative information at a single point to approximation information around that point. ",
  "translatedText": "במקרה של סדרת טיילור, האינטואיציה הבסיסית שיש לזכור כשאתה חוקר יותר ממה שיש, היא שהם מתרגמים מידע נגזר בנקודה אחת למידע קירוב סביב הנקודה הזו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1288.06,
  "end": 1301.16
 },
 {
  "input": "Thank you once again to everybody who supported this series. ",
  "translatedText": "תודה שוב לכל מי שתמך בסדרה הזו. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1303.92,
  "end": 1306.6
 },
 {
  "input": "The next series like it will be on probability, and if you want early access as those videos are made, you know where to go. ",
  "translatedText": "הסדרה הבאה כמוה תהיה בהסתברות, ואם אתה רוצה גישה מוקדמת עם יצירת הסרטונים האלה, אתה יודע לאן ללכת. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1307.3,
  "end": 1339.06
 }
]