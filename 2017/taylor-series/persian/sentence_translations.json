[
 {
  "input": "When I first learned about Taylor series, I definitely didn't appreciate just how important they are. ",
  "translatedText": "وقتی برای اولین بار در مورد سریال های تیلور یاد گرفتم، قطعاً از اهمیت آنها قدردانی نکردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.64,
  "end": 19.7
 },
 {
  "input": "But time and time again they come up in math, physics, and many fields of engineering because they're one of the most powerful tools that math has to offer for approximating functions. ",
  "translatedText": "اما بارها و بارها در ریاضیات، فیزیک و بسیاری از زمینه‌های مهندسی مطرح می‌شوند، زیرا یکی از قوی‌ترین ابزارهایی هستند که ریاضیات برای تقریب توابع ارائه می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.12,
  "end": 29.18
 },
 {
  "input": "I think one of the first times this clicked for me as a student was not in a calculus class, but a physics class. ",
  "translatedText": "فکر می کنم یکی از اولین بارهایی که برای من به عنوان یک دانش آموز کلیک کرد، در کلاس حساب دیفرانسیل و انتگرال نبود، بلکه یک کلاس فیزیک بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 30.0,
  "end": 35.42
 },
 {
  "input": "We were studying a certain problem that had to do with the potential energy of a pendulum, and for that you need an expression for how high the weight of the pendulum is above its lowest point, and when you work that out it comes out to be proportional to 1 minus the cosine of the angle between the pendulum and the vertical. ",
  "translatedText": "ما در حال مطالعه یک مسئله خاص بودیم که مربوط به انرژی پتانسیل یک آونگ بود، و برای آن شما نیاز به بیانی دارید که وزن آونگ از پایین‌ترین نقطه خود چقدر است، و زمانی که آن را انجام می‌دهید، مشخص می‌شود. متناسب با 1 منهای کسینوس زاویه بین آونگ و عمود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.84,
  "end": 53.0
 },
 {
  "input": "The specifics of the problem we were trying to solve are beyond the point here, but what I'll say is that this cosine function made the problem awkward and unwieldy, and made it less clear how pendulums relate to other oscillating phenomena. ",
  "translatedText": "ویژگی‌های مسئله‌ای که ما در تلاش برای حل آن بودیم فراتر از موضوع اینجاست، اما چیزی که من می‌گویم این است که این تابع کسینوس مسئله را ناخوشایند و بی‌حرکت می‌کند، و چگونگی ارتباط آونگ‌ها را با سایر پدیده‌های نوسانی کمتر روشن می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.58,
  "end": 66.52
 },
 {
  "input": "But if you approximate cosine of theta as 1 minus theta squared over 2, everything just fell into place much more easily. ",
  "translatedText": "اما اگر کسینوس تتا را 1 منهای تتا مجذور 2 تقریبی کنید، همه چیز خیلی راحت‌تر در جای خود قرار می‌گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.46,
  "end": 75.96
 },
 {
  "input": "If you've never seen anything like this before, an approximation like that might seem completely out of left field. ",
  "translatedText": "اگر قبلاً چنین چیزی را ندیده‌اید، ممکن است تقریبی مانند آن کاملاً خارج از قسمت چپ به نظر برسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.66,
  "end": 82.78
 },
 {
  "input": "If you graph cosine of theta along with this function, 1 minus theta squared over 2, they do seem rather close to each other, at least for small angles near 0, but how would you even think to make this approximation, and how would you find that particular quadratic? ",
  "translatedText": "اگر کسینوس تتا را همراه با این تابع ترسیم کنید، 1 منهای تتا مجذور 2، آنها تقریباً نزدیک به یکدیگر به نظر می رسند، حداقل برای زوایای کوچک نزدیک 0، اما اصلاً چگونه فکر می کنید این تقریب را انجام دهید، و چگونه می خواهید آن درجه دوم خاص را پیدا کنید؟ مطالعه سری تیلور عمدتاً در مورد گرفتن توابع غیر چند جمله‌ای و یافتن چند جمله‌ای است که آنها را در نزدیکی برخی ورودی‌ها تقریب می‌کنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 83.82,
  "end": 99.42
 },
 {
  "input": "The study of Taylor series is largely about taking non-polynomial functions and finding polynomials that approximate them near some input. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 101.22,
  "end": 108.84
 },
 {
  "input": "The motive here is that polynomials tend to be much easier to deal with than other functions. ",
  "translatedText": "انگیزه در اینجا این است که برخورد با چند جمله ای ها بسیار آسان تر از سایر توابع است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.84,
  "end": 113.76
 },
 {
  "input": "They're easier to compute, easier to take derivatives, easier to integrate, just all around more friendly. ",
  "translatedText": "محاسبه آنها آسان تر، مشتقات آسان تر، ادغام آسان تر، فقط در اطراف دوستانه تر هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 114.34,
  "end": 119.48
 },
 {
  "input": "So let's take a look at that function, cosine of x, and really take a moment to think about how you might construct a quadratic approximation near x equals 0. ",
  "translatedText": "بنابراین بیایید به آن تابع، کسینوس x نگاهی بیندازیم و واقعاً یک لحظه به این فکر کنیم که چگونه می‌توان یک تقریب درجه دوم نزدیک x برابر با 0 ایجاد کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.68,
  "end": 130.22
 },
 {
  "input": "That is, among all of the possible polynomials that look like c0 plus c1 times x plus c2 times x squared, for some choice of these constants, c0, c1, and c2, find the one that most resembles cosine of x near x equals 0, whose graph kind of spoons with the graph of cosine x at that point. ",
  "translatedText": "یعنی از بین همه چند جمله ای های ممکن که شبیه c0 به اضافه c1 ضربدر x به اضافه c2 ضربدر x مربع هستند، برای برخی از این ثابت ها، c0، c1 و c2، یکی را پیدا کنید که بیشتر شبیه کسینوس x نزدیک x برابر با 0 باشد. ، که نمودار آن نوعی قاشق با نمودار کسینوس x در آن نقطه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 130.94,
  "end": 152.66
 },
 {
  "input": "Well, first of all, at the input 0, the value of cosine of x is 1, so if our approximation is going to be any good at all, it should also equal 1 at the input x equals 0. ",
  "translatedText": "خوب، اول از همه، در ورودی 0، مقدار کسینوس x 1 است، بنابراین اگر تقریب ما اصلاً خوب باشد، در ورودی x نیز باید برابر با 1 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.86,
  "end": 164.92
 },
 {
  "input": "Plugging in 0 just results in whatever c0 is, so we can set that equal to 1. ",
  "translatedText": "وصل کردن 0 فقط باعث می شود که c0 باشد، بنابراین می توانیم آن را برابر با 1 قرار دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.82,
  "end": 170.94
 },
 {
  "input": "This leaves us free to choose constants c1 and c2 to make this approximation as good as we can, but nothing we do with them is going to change the fact that the polynomial equals 1 at x equals 0. ",
  "translatedText": "این ما را آزاد می‌گذارد تا ثابت‌های c1 و c2 را انتخاب کنیم تا این تقریب به بهترین شکل ممکن انجام شود، اما هیچ کاری که با آنها انجام می‌دهیم این واقعیت را تغییر نمی‌دهد که چند جمله‌ای برابر 1 در x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.08,
  "end": 184.0
 },
 {
  "input": "It would also be good if our approximation had the same tangent slope as cosine x at this point of interest. ",
  "translatedText": "همچنین اگر تقریب ما شیب مماس مشابه کسینوس x را در این نقطه مورد نظر داشته باشد، خوب خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 184.96,
  "end": 191.12
 },
 {
  "input": "Otherwise, the approximation drifts away from the cosine graph much faster than it needs to. ",
  "translatedText": "در غیر این صورت، تقریب بسیار سریعتر از آنچه که نیاز است از نمودار کسینوس دور می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.9,
  "end": 196.7
 },
 {
  "input": "The derivative of cosine is negative sine, and at x equals 0, that equals 0, meaning the tangent line is perfectly flat. ",
  "translatedText": "مشتق کسینوس سینوس منفی است و در x برابر با 0 است، یعنی 0، یعنی خط مماس کاملاً مسطح است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 205.84
 },
 {
  "input": "On the other hand, when you work out the derivative of our quadratic, you get c1 plus 2 times c2 times x. ",
  "translatedText": "از طرف دیگر، وقتی مشتق درجه دوم ما را محاسبه می کنید، c1 به اضافه 2 برابر c2 ضربدر x دریافت می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 214.4
 },
 {
  "input": "At x equals 0, this just equals whatever we choose for c1. ",
  "translatedText": "در x برابر با 0 است، این فقط با هر چیزی که برای c1 انتخاب می کنیم برابر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.32,
  "end": 219.42
 },
 {
  "input": "So this constant c1 has complete control over the derivative of our approximation around x equals 0. ",
  "translatedText": "بنابراین این ثابت c1 کنترل کاملی بر مشتق تقریب ما در اطراف x برابر با 0 دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.26,
  "end": 226.34
 },
 {
  "input": "Setting it equal to 0 ensures that our approximation also has a flat tangent line at this point. ",
  "translatedText": "تنظیم آن برابر با 0 تضمین می کند که تقریب ما نیز یک خط مماس صاف در این نقطه دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 227.12,
  "end": 232.3
 },
 {
  "input": "This leaves us free to change c2, but the value and slope of our polynomial at x equals 0 are locked in place to match that of cosine. ",
  "translatedText": "این ما را برای تغییر c2 باز می‌گذارد، اما مقدار و شیب چند جمله‌ای ما در x برابر با 0 است تا با کسینوس مطابقت داشته باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 233.0,
  "end": 242.62
 },
 {
  "input": "The final thing to take advantage of is the fact that the cosine graph curves downward above x equals 0, it has a negative second derivative. ",
  "translatedText": "آخرین چیزی که باید از آن استفاده کرد این واقعیت است که نمودار کسینوس به سمت پایین بالای x برابر با 0 است، مشتق دوم منفی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 244.26,
  "end": 252.44
 },
 {
  "input": "Or in other words, even though the rate of change is 0 at that point, the rate of change itself is decreasing around that point. ",
  "translatedText": "یا به عبارت دیگر، حتی اگر نرخ تغییر در آن نقطه 0 باشد، خود نرخ تغییر در اطراف آن نقطه در حال کاهش است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.38,
  "end": 260.46
 },
 {
  "input": "Specifically, since its derivative is negative sine of x, its second derivative is negative cosine of x, and at x equals 0, that equals negative 1. ",
  "translatedText": "به طور خاص، از آنجایی که مشتق آن سینوس منفی x است، مشتق دوم آن کسینوس منفی x است و در x برابر با 0 است که برابر با 1 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 261.28,
  "end": 271.84
 },
 {
  "input": "Now in the same way that we wanted the derivative of our approximation to match that of the cosine, so that their values wouldn't drift apart needlessly quickly, making sure that their second derivatives match will ensure that they curve at the same rate, that the slope of our polynomial doesn't drift away from the slope of cosine x any more quickly than it needs to. ",
  "translatedText": "اکنون به همان روشی که می‌خواستیم مشتق تقریب ما با مشتق کسینوس مطابقت داشته باشد، به طوری که مقادیر آنها به سرعت از هم جدا نشوند، اطمینان حاصل کنیم که مشتقات دوم آنها مطابقت دارند، اطمینان حاصل می‌کند که آنها با همان سرعت منحنی می‌شوند. شیب چند جمله ای ما با سرعت بیشتری از شیب کسینوس x دور نمی شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 273.08,
  "end": 293.32
 },
 {
  "input": "Pulling up the same derivative we had before, and then taking its derivative, we see that the second derivative of this polynomial is exactly 2 times c2. ",
  "translatedText": "با کشیدن همان مشتقی که قبلا داشتیم و سپس مشتق آن را می گیریم، می بینیم که مشتق دوم این چند جمله ای دقیقاً 2 برابر c2 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.22,
  "end": 304.04
 },
 {
  "input": "So to make sure that this second derivative also equals negative 1 at x equals 0, 2 times c2 has to be negative 1, meaning c2 itself should be negative 1 half. ",
  "translatedText": "بنابراین برای اطمینان از اینکه این مشتق دوم نیز برابر با منفی 1 در x برابر با 0 است، 2 برابر c2 باید منفی 1 باشد، به این معنی که خود c2 باید 1 نیمه منفی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.96,
  "end": 315.58
 },
 {
  "input": "And this gives us the approximation 1 plus 0x minus 1 half x squared. ",
  "translatedText": "و این به ما تقریب 1 به اضافه 0x منهای 1 نصف x مربع را می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.38,
  "end": 322.14
 },
 {
  "input": "And to get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial, you'd estimate it to be 0.995. ",
  "translatedText": "و اگر کسینوس را 0 تخمین بزنید، برای اینکه بفهمید چقدر خوب است. 1 با استفاده از این چند جمله ای، آن را 0 تخمین می زنید. 995. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.2,
  "end": 331.6
 },
 {
  "input": "And this is the true value of cosine of 0.1. ",
  "translatedText": "و این مقدار واقعی کسینوس 0 است. 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.52,
  "end": 335.82
 },
 {
  "input": "It's a really good approximation! ",
  "translatedText": "واقعاً تقریب خوبی است! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.64,
  "end": 338.44
 },
 {
  "input": "Take a moment to reflect on what just happened. ",
  "translatedText": "لحظه ای را به تأمل در مورد آنچه که اخیراً رخ داده است اختصاص دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.3,
  "end": 342.52
 },
 {
  "input": "You had 3 degrees of freedom with this quadratic approximation, the constants c0, c1, and c2. ",
  "translatedText": "شما با این تقریب درجه دوم یعنی ثابت های c0 و c1 و c2 3 درجه آزادی داشتید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.52,
  "end": 349.02
 },
 {
  "input": "c0 was responsible for making sure that the output of the approximation matches that of cosine x at x equals 0. ",
  "translatedText": "c0 وظیفه داشت اطمینان حاصل کند که خروجی تقریب با کسینوس x در x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.52,
  "end": 356.44
 },
 {
  "input": "c1 was in charge of making sure that the derivatives match at that point, and c2 was responsible for making sure that the second derivatives match up. ",
  "translatedText": "c1 مسئول اطمینان از مطابقت مشتقات در آن نقطه بود و c2 مسئول اطمینان از مطابقت مشتقات دوم بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.12,
  "end": 368.24
 },
 {
  "input": "This ensures that the way your approximation changes as you move away from x equals 0, and the way that the rate of change itself changes, is as similar as possible to the behavior of cosine x, given the amount of control you have. ",
  "translatedText": "این تضمین می کند که نحوه تغییر تقریب شما با دور شدن از x برابر با 0 باشد و نحوه تغییر خود نرخ تغییر تا حد ممکن شبیه رفتار کسینوس x با توجه به میزان کنترل شما باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 368.94,
  "end": 383.16
 },
 {
  "input": "You could give yourself more control by allowing more terms in your polynomial and matching higher order derivatives. ",
  "translatedText": "شما می توانید با اجازه دادن به عبارت های بیشتر در چند جمله ای خود و مطابقت با مشتقات مرتبه بالاتر، کنترل بیشتری به خود بدهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 384.08,
  "end": 390.14
 },
 {
  "input": "For example, let's say you added on the term c3 times x3 for some constant c3. ",
  "translatedText": "به عنوان مثال، فرض کنید شما در عبارت c3 برابر x3 برای مقداری c3 ثابت اضافه کرده اید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.84,
  "end": 396.58
 },
 {
  "input": "In that case, if you take the third derivative of a cubic polynomial, anything that's quadratic or smaller goes to 0. ",
  "translatedText": "در این صورت، اگر مشتق سوم یک چند جمله ای مکعبی را بگیرید، هر چیزی که درجه دوم یا کوچکتر باشد به 0 می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.58,
  "end": 404.28
 },
 {
  "input": "As for that last term, after 3 iterations of the power rule, it looks like 1 times 2 times 3 times c3. ",
  "translatedText": "در مورد آخرین ترم، پس از 3 تکرار از قانون قدرت، به نظر می رسد 1 ضربدر 2 بار 3 برابر c3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 405.56,
  "end": 414.46
 },
 {
  "input": "On the other hand, the third derivative of cosine x comes out to sine x, which equals 0 at x equals 0. ",
  "translatedText": "از طرف دیگر، مشتق سوم کسینوس x به سینوس x می رسد که برابر 0 در x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.46,
  "end": 423.28
 },
 {
  "input": "So to make sure that the third derivatives match, the constant c3 should be 0. ",
  "translatedText": "بنابراین برای اطمینان از مطابقت مشتقات سوم، ثابت c3 باید 0 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.28,
  "end": 428.76
 },
 {
  "input": "Or in other words, not only is 1 minus 1 half x2 the best possible quadratic approximation of cosine, it's also the best possible cubic approximation. ",
  "translatedText": "یا به عبارت دیگر، نه تنها 1 منهای 1 نصف x2 بهترین تقریب درجه دوم ممکن کسینوس است، بلکه بهترین تقریب مکعبی ممکن است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 429.88,
  "end": 439.58
 },
 {
  "input": "You can make an improvement by adding on a fourth order term, c4 times x to the fourth. ",
  "translatedText": "شما می توانید با اضافه کردن یک عبارت مرتبه چهارم، c4 برابر x به چهارم، بهبودی ایجاد کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.28,
  "end": 447.06
 },
 {
  "input": "The fourth derivative of cosine is itself, which equals 1 at x equals 0. ",
  "translatedText": "چهارمین مشتق کسینوس خودش است که برابر 1 در x برابر 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.88,
  "end": 453.32
 },
 {
  "input": "And what's the fourth derivative of our polynomial with this new term? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.3,
  "end": 457.46
 },
 {
  "input": "Well, when you keep applying the power rule over and over, with those exponents all hopping down in front, you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4. ",
  "translatedText": "و چهارمین مشتق چند جمله ای ما با این عبارت جدید چیست؟ خوب، وقتی قانون توان را بارها و بارها به کار می‌برید، در حالی که این توانگرها همگی به سمت پایین می‌پرند، در نهایت با 1 ضربدر 2 برابر 3 برابر 4 برابر c4 مواجه می‌شوید که 24 برابر c4 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.62,
  "end": 471.0
 },
 {
  "input": "So if we want this to match the fourth derivative of cosine x, which is 1, c4 has to be 1 over 24. ",
  "translatedText": "بنابراین اگر بخواهیم با مشتق چهارم کسینوس x که 1 است مطابقت داشته باشد، c4 باید 1 بر 24 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.4,
  "end": 478.76
 },
 {
  "input": "And indeed, the polynomial 1 minus 1 half x2 plus 1 24 times x to the fourth, which looks like this, is a very close approximation for cosine x around x equals 0. ",
  "translatedText": "و در واقع، چند جمله ای 1 منهای 1 نصف x2 به اضافه 1 24 برابر x به چهارمی که به نظر می رسد، تقریبی بسیار نزدیک برای کسینوس x در اطراف x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.82,
  "end": 492.84
 },
 {
  "input": "In any physics problem involving the cosine of a small angle, for example, predictions would be almost unnoticeably different if you substituted this polynomial for cosine of x. ",
  "translatedText": "برای مثال، در هر مسئله فیزیک که کسینوس یک زاویه کوچک را در بر می گیرد، اگر شما این چند جمله ای را به جای کسینوس x جایگزین کنید، پیش بینی ها تقریباً به طور محسوسی متفاوت خواهند بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.74,
  "end": 504.06
 },
 {
  "input": "Now take a step back and notice a few things happening with this process. ",
  "translatedText": "حالا یک قدم به عقب بردارید و متوجه چند اتفاق در این فرآیند شوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "First of all, factorial terms come up very naturally in this process. ",
  "translatedText": "اول از همه، اصطلاحات فاکتوریل به طور طبیعی در این فرآیند به وجود می آیند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.52,
  "end": 514.2
 },
 {
  "input": "When you take n successive derivatives of the function x to the n, letting the power rule keep cascading on down, what you'll be left with is 1 times 2 times 3 on and on and on up to whatever n is. ",
  "translatedText": "وقتی n مشتق متوالی از تابع x را به n می‌گیرید، اجازه می‌دهید قانون قدرت به صورت آبشاری به سمت پایین ادامه یابد، چیزی که برای شما باقی می‌ماند 1 ضربدر 2 ضربدر 3 روی و روی و تا هر n است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.02,
  "end": 528.58
 },
 {
  "input": "So you don't simply set the coefficients of the polynomial equal to whatever derivative you want. ",
  "translatedText": "بنابراین شما به سادگی ضرایب چند جمله ای را با هر مشتقی که می خواهید برابر نمی کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.22,
  "end": 534.24
 },
 {
  "input": "You have to divide by the appropriate factorial to cancel out this effect. ",
  "translatedText": "برای خنثی کردن این اثر باید بر فاکتوریل مناسب تقسیم کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.68,
  "end": 538.54
 },
 {
  "input": "For example, that x to the fourth coefficient was the fourth derivative of cosine, 1, but divided by 4 factorial, 24. ",
  "translatedText": "به عنوان مثال، x به ضریب چهارم چهارمین مشتق کسینوس، 1 بود، اما تقسیم بر 4 فاکتوریل، 24. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.4,
  "end": 547.78
 },
 {
  "input": "The second thing to notice is that adding on new terms, like this c4 times x to the fourth, doesn't mess up what the old terms should be, and that's really important. ",
  "translatedText": "دومین نکته ای که باید به آن توجه کرد این است که اضافه کردن عبارت های جدید، مانند این c4 برابر x به چهارم، شرایط قدیمی را به هم نمی ریزد، و این واقعا مهم است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.4,
  "end": 559.3
 },
 {
  "input": "For example, the second derivative of this polynomial at x equals 0 is still equal to 2 times the second coefficient, even after you introduce higher order terms. ",
  "translatedText": "به عنوان مثال، مشتق دوم این چند جمله ای در x برابر با 0 است، حتی پس از اینکه شما عبارات مرتبه بالاتر را معرفی کردید، باز هم برابر با 2 برابر ضریب دوم است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.1,
  "end": 570.08
 },
 {
  "input": "And it's because we're plugging in x equals 0, so the second derivative of any higher order term, which all include an x, will just wash away. ",
  "translatedText": "و به این دلیل است که ما x را برابر 0 وصل می کنیم، بنابراین مشتق دوم هر عبارت مرتبه بالاتر، که همگی شامل یک x است، فقط پاک می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 579.78
 },
 {
  "input": "And the same goes for any other derivative, which is why each derivative of a polynomial at x equals 0 is controlled by one and only one of the coefficients. ",
  "translatedText": "و همین امر در مورد هر مشتق دیگری نیز صدق می کند، به همین دلیل است که هر مشتق چند جمله ای در x برابر با 0 توسط یک و تنها یکی از ضرایب کنترل می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 580.74,
  "end": 590.28
 },
 {
  "input": "If instead you were approximating near an input other than 0, like x equals pi, in order to get the same effect, you would have to write your polynomial in terms of powers of x minus pi, or whatever input you're looking at. ",
  "translatedText": "اگر در عوض نزدیک ورودی دیگری غیر از 0 تقریب می‌زنید، مانند x برابر با پی، برای به دست آوردن همان اثر، باید چند جمله‌ای خود را بر حسب توان x منهای پی یا هر ورودی که به آن نگاه می‌کنید بنویسید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.64,
  "end": 605.72
 },
 {
  "input": "This makes it look noticeably more complicated, but all we're doing is making sure that the point pi looks and behaves like 0, so that plugging in x equals pi will result in a lot of nice cancellation that leaves only one constant. ",
  "translatedText": "این باعث می‌شود که به‌طور محسوسی پیچیده‌تر به نظر برسد، اما تمام کاری که ما انجام می‌دهیم این است که مطمئن شویم نقطه pi شبیه ۰ به نظر می‌رسد و رفتار می‌کند، به طوری که وصل کردن x برابر با pi منجر به لغو بسیار خوبی می‌شود که تنها یک ثابت باقی می‌گذارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 606.32,
  "end": 620.22
 },
 {
  "input": "And finally, on a more philosophical level, notice how what we're doing here is basically taking information about higher order derivatives of a function at a single point, and translating that into information about the value of the function near that point. ",
  "translatedText": "و در نهایت، در یک سطح فلسفی تر، توجه کنید که چگونه کاری که ما در اینجا انجام می دهیم، اساساً اطلاعات مربوط به مشتقات مرتبه بالاتر یک تابع را در یک نقطه واحد می گیریم و آن را به اطلاعاتی در مورد مقدار تابع نزدیک به آن نقطه ترجمه می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.38,
  "end": 637.78
 },
 {
  "input": "You can take as many derivatives of cosine as you want. ",
  "translatedText": "شما می توانید هر تعداد مشتق از کسینوس را که می خواهید بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 640.96,
  "end": 644.12
 },
 {
  "input": "It follows this nice cyclic pattern, cosine of x, negative sine of x, negative cosine, sine, and then repeat. ",
  "translatedText": "از این الگوی چرخه ای خوب پیروی می کند، کسینوس x، سینوس منفی x، کسینوس منفی، سینوس، و سپس تکرار می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.6,
  "end": 651.02
 },
 {
  "input": "And the value of each one of these is easy to compute at x equals 0, it gives this cyclic pattern 1, 0, negative 1, 0, and then repeat. ",
  "translatedText": "و مقدار هر یک از اینها به راحتی قابل محاسبه در x برابر با 0 است، به این الگوی چرخه ای 1، 0، منفی 1، 0 می دهد و سپس تکرار می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.32,
  "end": 661.1
 },
 {
  "input": "And knowing the values of all those higher order derivatives is a lot of information about cosine of x, even though it only involves plugging in a single number, x equals 0. ",
  "translatedText": "و دانستن مقادیر تمام مشتقات مرتبه بالاتر اطلاعات زیادی در مورد کسینوس x است، حتی اگر فقط یک عدد را وصل کنید، x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.0,
  "end": 672.48
 },
 {
  "input": "So what we're doing is leveraging that information to get an approximation around this input, and you do it by creating a polynomial whose higher order derivatives are designed to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern. ",
  "translatedText": "بنابراین کاری که ما انجام می‌دهیم این است که از آن اطلاعات برای بدست آوردن تقریبی در اطراف این ورودی استفاده می‌کنیم، و شما این کار را با ایجاد یک چند جمله‌ای انجام می‌دهید که مشتقات مرتبه بالاتر آن برای مطابقت با مشتقات کسینوس طراحی شده‌اند، به دنبال همان 1، 0، منفی 1، 0، الگوی چرخه ای. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 674.26,
  "end": 690.66
 },
 {
  "input": "And to do that, you just make each coefficient of the polynomial follow that same pattern, but you have to divide each one by the appropriate factorial. ",
  "translatedText": "و برای انجام این کار، فقط هر ضریب چند جمله ای را از همان الگوی پیروی می کنید، اما باید هر یک را بر فاکتوریل مناسب تقسیم کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.42,
  "end": 699.44
 },
 {
  "input": "Like I mentioned before, this is what cancels out the cascading effect of many power rule applications. ",
  "translatedText": "همانطور که قبلاً اشاره کردم، این چیزی است که اثر آبشاری بسیاری از برنامه‌های کاربردی قوانین قدرت را خنثی می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.12,
  "end": 705.26
 },
 {
  "input": "The polynomials you get by stopping this process at any point are called Taylor polynomials for cosine of x. ",
  "translatedText": "چندجمله ای هایی که با توقف این فرآیند در هر نقطه به دست می آورید، چند جمله ای های تیلور برای کسینوس x نامیده می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.28,
  "end": 713.16
 },
 {
  "input": "More generally, and hence more abstractly, if we were dealing with some other function other than cosine, you would compute its derivative, its second derivative, and so on, getting as many terms as you'd like, and you would evaluate each one of them at x equals 0. ",
  "translatedText": "به‌طور کلی‌تر و در نتیجه انتزاعی‌تر، اگر با تابع دیگری غیر از کسینوس سر و کار داشتیم، مشتق آن، مشتق دوم آن و غیره را محاسبه می‌کردید و هر تعداد عبارت را که می‌خواهید به دست می‌آورید، و هر کدام را ارزیابی می‌کردید. از آنها در x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.9,
  "end": 728.4
 },
 {
  "input": "For the polynomial approximation, the coefficient of each x to the n term should be the value of the nth derivative of the function evaluated at 0, but divided by n factorial. ",
  "translatedText": "برای تقریب چند جمله ای، ضریب هر x به n جمله باید مقدار مشتق nام تابع ارزیابی شده در 0 باشد، اما تقسیم بر n فاکتوریل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.58,
  "end": 742.44
 },
 {
  "input": "This whole rather abstract formula is something you'll likely see in any text or course that touches on Taylor polynomials. ",
  "translatedText": "این فرمول کاملاً انتزاعی چیزی است که احتمالاً در هر متن یا دوره ای که چند جمله ای های تیلور را لمس می کند، خواهید دید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.48,
  "end": 751.2
 },
 {
  "input": "When you see it, think to yourself that the constant term ensures that the value of the polynomial matches with the value of f. ",
  "translatedText": "وقتی آن را می بینید، با خود فکر کنید که عبارت ثابت تضمین می کند که مقدار چند جمله ای با مقدار f مطابقت دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 751.78,
  "end": 758.66
 },
 {
  "input": "The next term ensures that the slope of the polynomial matches the slope of the function at x equals 0. ",
  "translatedText": "عبارت بعدی تضمین می کند که شیب چند جمله ای با شیب تابع در x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.2,
  "end": 765.54
 },
 {
  "input": "The next term ensures that the rate at which the slope changes is the same at that point, and so on, depending on how many terms you want. ",
  "translatedText": "عبارت بعدی تضمین می کند که نرخ تغییر شیب در آن نقطه یکسان است و به همین ترتیب بسته به تعداد ترم هایی که می خواهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.36,
  "end": 773.52
 },
 {
  "input": "And the more terms you choose, the closer the approximation, but the tradeoff is that the polynomial you'd get would be more complicated. ",
  "translatedText": "و هرچه عبارات بیشتری را انتخاب کنید، تقریب نزدیک‌تر می‌شود، اما موازنه این است که چند جمله‌ای که می‌گیرید پیچیده‌تر خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 774.62,
  "end": 780.98
 },
 {
  "input": "And to make things even more general, if you wanted to approximate near some input other than 0, which we'll call a, you would write this polynomial in terms of powers of x minus a, and you would evaluate all the derivatives of f at that input, a. ",
  "translatedText": "و برای کلی‌تر کردن مسائل، اگر می‌خواهید به ورودی دیگری به غیر از 0 که a می‌گوییم تقریب بزنید، این چند جمله‌ای را بر حسب توان x منهای a می‌نویسید و تمام مشتقات f را ارزیابی می‌کنید. در آن ورودی، الف. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 782.64,
  "end": 797.78
 },
 {
  "input": "This is what Taylor polynomials look like in their fullest generality. ",
  "translatedText": "این همان چیزی است که چند جمله ای های تیلور در کلیت کامل خود به نظر می رسند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.68,
  "end": 803.12
 },
 {
  "input": "Changing the value of a changes where this approximation is hugging the original function, where its higher order derivatives will be equal to those of the original function. ",
  "translatedText": "تغییر مقدار یک تغییر در جایی که این تقریب تابع اصلی را در آغوش می‌گیرد، جایی که مشتقات مرتبه بالاتر آن برابر با مشتقات تابع اصلی هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 804.0,
  "end": 813.74
 },
 {
  "input": "One of the simplest meaningful examples of this is the function e to the x around the input x equals 0. ",
  "translatedText": "یکی از ساده‌ترین مثال‌های معنی‌دار در این مورد، تابع e به x در اطراف ورودی x برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 815.88,
  "end": 821.9
 },
 {
  "input": "Computing the derivatives is super nice, as nice as it gets, because the derivative of e to the x is itself, so the second derivative is also e to the x, as is its third, and so on. ",
  "translatedText": "محاسبه مشتقات بسیار خوب است، به همان اندازه که خوب است، زیرا مشتق e به x خودش است، بنابراین مشتق دوم نیز e به x است، مانند سوم آن، و غیره. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 822.76,
  "end": 833.58
 },
 {
  "input": "So at the point x equals 0, all of these are equal to 1. ",
  "translatedText": "بنابراین در نقطه x برابر با 0، همه اینها برابر با 1 هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 834.34,
  "end": 838.24
 },
 {
  "input": "And what that means is our polynomial approximation should look like 1 plus 1 times x plus 1 over 2 times x squared plus 1 over 3 factorial times x cubed, and so on, depending on how many terms you want. ",
  "translatedText": "و این به این معنی است که تقریب چند جمله‌ای ما بسته به اینکه چند جمله می‌خواهید، باید شبیه 1 به علاوه 1 ضربدر x به اضافه 1 بر 2 برابر x مربع به علاوه 1 بر 3 فاکتوریل ضربدر x مکعب و غیره باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.12,
  "end": 858.54
 },
 {
  "input": "These are the Taylor polynomials for e to the x. ",
  "translatedText": "این چند جمله ای های تیلور از e تا x هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 859.4,
  "end": 862.7
 },
 {
  "input": "Ok, so with that as a foundation, in the spirit of showing you just how connected all the topics of calculus are, let me turn to something kind of fun, a completely different way to understand this second order term of the Taylor polynomials, but geometrically. ",
  "translatedText": "خوب، پس با آن به عنوان پایه، برای اینکه به شما نشان دهم که همه موضوعات حساب دیفرانسیل و انتگرال چقدر به هم مرتبط هستند، اجازه دهید به چیزی سرگرم کننده بپردازم، راهی کاملا متفاوت برای درک این جمله مرتبه دوم چند جمله ای های تیلور، اما به صورت هندسی این مربوط به قضیه اساسی حساب دیفرانسیل و انتگرال است که اگر نیاز به تجدید نظر سریع دارید در فصل های 1 و 8 در مورد آن صحبت کردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 866.38,
  "end": 880.52
 },
 {
  "input": "It's related to the fundamental theorem of calculus, which I talked about in chapters 1 and 8 if you need a quick refresher. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.4,
  "end": 887.26
 },
 {
  "input": "Like we did in those videos, consider a function that gives the area under some graph between a fixed left point and a variable right point. ",
  "translatedText": "مانند آنچه در آن ویدیوها انجام دادیم، تابعی را در نظر بگیرید که ناحیه زیر یک نمودار بین یک نقطه چپ ثابت و یک نقطه سمت راست متغیر را نشان می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 887.98,
  "end": 896.14
 },
 {
  "input": "What we're going to do here is think about how to approximate this area function, not the function for the graph itself, like we've been doing before. ",
  "translatedText": "کاری که ما در اینجا انجام می دهیم این است که به نحوه تقریبی این تابع ناحیه فکر کنیم، نه تابع خود نمودار، همانطور که قبلاً انجام می دادیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.98,
  "end": 904.18
 },
 {
  "input": "Focusing on that area is what's going to make the second order term pop out. ",
  "translatedText": "تمرکز بر آن منطقه چیزی است که باعث می شود اصطلاح مرتبه دوم ظاهر شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.9,
  "end": 909.44
 },
 {
  "input": "Remember, the fundamental theorem of calculus is that this graph itself represents the derivative of the area function, and it's because a slight nudge dx to the right bound of the area gives a new bit of area approximately equal to the height of the graph times dx. ",
  "translatedText": "به یاد داشته باشید، قضیه اساسی حساب دیفرانسیل و انتگرال این است که این نمودار خود مشتق تابع مساحت را نشان می‌دهد، و به این دلیل است که یک حرکت جزئی dx به سمت راست ناحیه، بیت جدیدی از مساحت تقریباً برابر با ارتفاع نمودار ضربدر dx می‌دهد. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 910.44,
  "end": 929.2
 },
 {
  "input": "That approximation is increasingly accurate for smaller and smaller choices of dx. ",
  "translatedText": "این تقریب برای انتخاب های کوچکتر و کوچکتر dx به طور فزاینده ای دقیق است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.04,
  "end": 934.48
 },
 {
  "input": "But if you wanted to be more accurate about this change in area, given some change in x that isn't meant to approach 0, you would have to take into account this portion right here, which is approximately a triangle. ",
  "translatedText": "اما اگر می‌خواهید در مورد این تغییر مساحت دقیق‌تر باشید، با توجه به مقداری تغییر در x که قرار نیست به 0 نزدیک شود، باید این بخش را دقیقاً در اینجا در نظر بگیرید که تقریباً یک مثلث است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 935.98,
  "end": 947.96
 },
 {
  "input": "Let's name the starting input a, and the nudged input above it x, so that change is x-a. ",
  "translatedText": "اجازه دهید ورودی شروع را a، و ورودی نوجدار بالای آن را x نامگذاری کنیم، بنابراین آن تغییر xa است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.6,
  "end": 957.46
 },
 {
  "input": "The base of that little triangle is that change, x-a, and its height is the slope of the graph times x-a. ",
  "translatedText": "پایه آن مثلث کوچک آن تغییر، xa و ارتفاع آن شیب نمودار ضربدر xa است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 958.1,
  "end": 967.6
 },
 {
  "input": "Since this graph is the derivative of the area function, its slope is the second derivative of the area function, evaluated at the input a. ",
  "translatedText": "از آنجایی که این نمودار مشتق تابع مساحت است، شیب آن دومین مشتق تابع مساحت است که در ورودی a ارزیابی می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 968.42,
  "end": 977.12
 },
 {
  "input": "So the area of this triangle, 1 half base times height, is 1 half times the second derivative of this area function, evaluated at a, multiplied by x-a squared. ",
  "translatedText": "بنابراین مساحت این مثلث، 1 نصف پایه ضربدر ارتفاع، 1 نیم برابر دومین مشتق تابع مساحت است که در a ارزیابی می شود، ضرب در مجذور xa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.44,
  "end": 989.9
 },
 {
  "input": "And this is exactly what you would see with a Taylor polynomial. ",
  "translatedText": "و این دقیقاً همان چیزی است که با چند جمله ای تیلور می بینید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 990.96,
  "end": 994.38
 },
 {
  "input": "If you knew the various derivative information about this area function at the point a, how would you approximate the area at the point x? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.88,
  "end": 1003.66
 },
 {
  "input": "You have to include all that area up to a, f of a, plus the area of this rectangle here, which is the first derivative, times x-a, plus the area of that little triangle, which is 1 half times the second derivative, times x-a squared. ",
  "translatedText": "اگر اطلاعات مشتق مختلف مربوط به این تابع ناحیه را در نقطه a می دانستید، مساحت نقطه x را چگونه تقریب می کنید؟ شما باید تمام آن مساحت را تا a، f از a، به اضافه مساحت این مستطیل در اینجا، که مشتق اول است، ضربدر xa، به اضافه مساحت آن مثلث کوچک، که 1 نصف برابر مشتق دوم است، اضافه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.36,
  "end": 1021.68
 },
 {
  "input": "I really like this, because even though it looks a bit messy all written out, each one of the terms has a very clear meaning that you can just point to on the diagram. ",
  "translatedText": "xa مربع من واقعاً این را دوست دارم، زیرا اگرچه به نظر می رسد کمی نامرتب است، اما هر یک از اصطلاحات معنای بسیار واضحی دارد که شما فقط می توانید در نمودار به آن اشاره کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1022.56,
  "end": 1031.08
 },
 {
  "input": "If you wanted, we could call it an end here, and you would have a phenomenally useful tool for approximations with these Taylor polynomials. ",
  "translatedText": "اگر می‌خواهید، می‌توانیم آن را پایان بدانیم، و شما یک ابزار فوق‌العاده مفید برای تقریب با این چند جمله‌ای تیلور خواهید داشت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.4,
  "end": 1040.46
 },
 {
  "input": "But if you're thinking like a mathematician, one question you might ask is whether or not it makes sense to never stop and just add infinitely many terms. ",
  "translatedText": "اما اگر مانند یک ریاضیدان فکر می کنید، یک سوال ممکن است بپرسید این است که آیا منطقی است که هرگز متوقف نشوید و فقط بی نهایت اصطلاحات را اضافه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.4,
  "end": 1050.46
 },
 {
  "input": "In math, an infinite sum is called a series, so even though one of these approximations with finitely many terms is called a Taylor polynomial, adding all infinitely many terms gives what's called a Taylor series. ",
  "translatedText": "در ریاضیات، یک مجموع نامتناهی را یک سری می‌گویند، بنابراین حتی اگر یکی از این تقریب‌ها با تعداد نامتناهی چند جمله‌ای تیلور نامیده می‌شود، با جمع کردن تمام جمله‌های بی‌نهایت، چیزی به‌دست می‌آید که سری تیلور نامیده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1051.38,
  "end": 1064.52
 },
 {
  "input": "You have to be really careful with the idea of an infinite series, because it doesn't actually make sense to add infinitely many things, you can only hit the plus button on the calculator so many times. ",
  "translatedText": "شما باید واقعا مراقب ایده یک سری بی نهایت باشید، زیرا در واقع اضافه کردن بی‌نهایت چیزها منطقی نیست، فقط می‌توانید چند بار دکمه پلاس را روی ماشین حساب بزنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1065.26,
  "end": 1076.08
 },
 {
  "input": "But if you have a series where adding more and more of the terms, which makes sense at each step, gets you increasingly close to some specific value, you say that the series converges to that value. ",
  "translatedText": "اما اگر مجموعه‌ای دارید که در آن افزودن عبارات بیشتر و بیشتر، که در هر مرحله منطقی است، شما را به مقداری خاص نزدیک می‌کند، می‌گویید که مجموعه به آن مقدار همگرا می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1077.44,
  "end": 1089.74
 },
 {
  "input": "Or if you're comfortable extending the definition of equality to include this kind of series convergence, you'd say that the series as a whole, this infinite sum, equals the value that it's converging to. ",
  "translatedText": "یا اگر می‌خواهید تعریف برابری را برای این نوع هم‌گرایی سری بسط دهید، می‌گویید که مجموعه به‌عنوان یک کل، این مجموع نامتناهی، برابر با مقداری است که به آن همگرا می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1090.32,
  "end": 1102.36
 },
 {
  "input": "For example, look at the Taylor polynomial for e to the x, and plug in some input, like x equals 1. ",
  "translatedText": "به عنوان مثال، به چند جمله ای تیلور برای e به x نگاه کنید و برخی از ورودی ها را وصل کنید، مانند x برابر با 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.46,
  "end": 1110.16
 },
 {
  "input": "As you add more and more polynomial terms, the total sum gets closer and closer to the value e, so you say that this infinite series converges to the number e, or what's saying the same thing, that it equals the number e. ",
  "translatedText": "با اضافه کردن عبارات چند جمله ای بیشتر و بیشتر، مجموع کل به مقدار e نزدیک و نزدیکتر می شود، بنابراین می گویید که این سری نامتناهی به عدد e همگرا می شود، یا همان چیزی که می گوید برابر است با عدد e. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1111.14,
  "end": 1126.7
 },
 {
  "input": "In fact, it turns out that if you plug in any other value of x, like x equals 2, and look at the value of the higher and higher order Taylor polynomials at this value, they will converge towards e to the x, which is e squared. ",
  "translatedText": "در واقع، معلوم می شود که اگر هر مقدار دیگری از x را وصل کنید، مانند x برابر 2، و به مقدار چندجمله ای های مرتبه بالاتر و بالاتر تیلور در این مقدار نگاه کنید، آنها به سمت e به x همگرا می شوند، که e مربع این برای هر ورودی صادق است، مهم نیست که چقدر از 0 دور باشد، حتی اگر این چند جمله ای های تیلور فقط از اطلاعات مشتق جمع آوری شده در ورودی 0 ساخته شده باشند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1127.84,
  "end": 1144.02
 },
 {
  "input": "This is true for any input, no matter how far away from 0 it is, even though these Taylor polynomials are constructed only from derivative information gathered at the input 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1144.68,
  "end": 1156.18
 },
 {
  "input": "In a case like this, we say that e to the x equals its own Taylor series at all inputs x, which is kind of a magical thing to have happen. ",
  "translatedText": "در موردی مانند این، می گوییم که e به x برابر است با سری تیلور خودش در تمام ورودی های x، که به نوعی اتفاق جادویی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1158.27,
  "end": 1167.48
 },
 {
  "input": "Even though this is also true for a couple other important functions, like sine and cosine, sometimes these series only converge within a certain range around the input whose derivative information you're using. ",
  "translatedText": "حتی اگر این مورد برای چند توابع مهم دیگر مانند سینوس و کسینوس نیز صادق است، گاهی اوقات این سری‌ها فقط در محدوده خاصی حول ورودی که اطلاعات مشتق آن را استفاده می‌کنید همگرا می‌شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1180.5
 },
 {
  "input": "If you worked out the Taylor series for the natural log of x around the input x equals 1, which is built by evaluating the higher order derivatives of the natural log of x at x equals 1, this is what it would look like. ",
  "translatedText": "اگر سری تیلور را برای لاگ طبیعی x در اطراف ورودی x برابر 1 بسازید، که با ارزیابی مشتقات مرتبه بالاتر لگاریتم طبیعی x در x برابر با 1 ساخته می‌شود، این شکلی است که به نظر می‌رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1181.58,
  "end": 1195.62
 },
 {
  "input": "When you plug in an input between 0 and 2, adding more and more terms of this series will indeed get you closer and closer to the natural log of that input. ",
  "translatedText": "وقتی یک ورودی بین 0 و 2 را وصل می‌کنید، افزودن عبارت‌های بیشتر و بیشتر از این سری در واقع شما را به گزارش طبیعی آن ورودی نزدیک‌تر و نزدیک‌تر می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1196.08,
  "end": 1205.52
 },
 {
  "input": "But outside of that range, even by just a little bit, the series fails to approach anything. ",
  "translatedText": "اما خارج از این محدوده، حتی اندکی، سریال نمی تواند به چیزی نزدیک شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1206.4,
  "end": 1211.7
 },
 {
  "input": "As you add on more and more terms, the sum bounces back and forth wildly. ",
  "translatedText": "با اضافه کردن شرایط بیشتر و بیشتر، مجموع به شدت به جلو و عقب باز می گردد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1212.48,
  "end": 1217.44
 },
 {
  "input": "It does not, as you might expect, approach the natural log of that value, even though the natural log of x is perfectly well defined for inputs above 2. ",
  "translatedText": "همانطور که ممکن است انتظار داشته باشید، به گزارش طبیعی آن مقدار نزدیک نمی شود، حتی اگر گزارش طبیعی x برای ورودی های بالای 2 کاملاً به خوبی تعریف شده باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.1,
  "end": 1227.54
 },
 {
  "input": "In some sense, the derivative information of ln of x at x equals 1 doesn't propagate out that far. ",
  "translatedText": "به نوعی، اطلاعات مشتق ln از x در x برابر با 1 است، تا این اندازه منتشر نمی شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.46,
  "end": 1235.36
 },
 {
  "input": "In a case like this, where adding more terms of the series doesn't approach anything, you say the series diverges. ",
  "translatedText": "در چنین موردی که اضافه کردن اصطلاحات بیشتر به سریال به چیزی نزدیک نمی شود، می گویید سریال از هم جدا می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1236.58,
  "end": 1243.08
 },
 {
  "input": "And that maximum distance between the input you're approximating near and points where the outputs of these polynomials actually converge is called the radius of convergence for the Taylor series. ",
  "translatedText": "و حداکثر فاصله بین ورودی که نزدیک آن هستید و نقاطی که خروجی‌های این چندجمله‌ای‌ها واقعاً همگرا می‌شوند، شعاع همگرایی برای سری تیلور نامیده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.18,
  "end": 1255.56
 },
 {
  "input": "There remains more to learn about Taylor series. ",
  "translatedText": "چیزهای بیشتری در مورد سریال تیلور وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1256.84,
  "end": 1259.16
 },
 {
  "input": "There are many use cases, tactics for placing bounds on the error of these approximations, tests for understanding when series do and don't converge, and for that matter, there remains more to learn about calculus as a whole and the countless topics not touched by this series. ",
  "translatedText": "موارد استفاده زیادی وجود دارد، تاکتیک‌هایی برای قرار دادن مرزها بر روی خطای این تقریب‌ها، آزمون‌هایی برای فهمیدن اینکه چه زمانی سری‌ها همگرا می‌شوند و نمی‌شوند، و به همین دلیل، چیزهای بیشتری برای یادگیری در مورد حساب دیفرانسیل و انتگرال به‌عنوان یک کل و موضوعات بی‌شماری باقی می‌ماند که لمس نشده‌اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1259.5,
  "end": 1274.58
 },
 {
  "input": "The goal with these videos is to give you the fundamental intuitions that make you feel confident and efficient in learning more on your own, and potentially even rediscovering more of the topic for yourself. ",
  "translatedText": "توسط این سریال هدف این ویدیوها ارائه شهود اساسی به شما است که باعث می شود در یادگیری بیشتر به تنهایی احساس اعتماد به نفس و کارآمدی داشته باشید و به طور بالقوه حتی بیشتر موضوع را برای خود دوباره کشف کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1275.32,
  "end": 1287.14
 },
 {
  "input": "In the case of Taylor series, the fundamental intuition to keep in mind as you explore more of what there is, is that they translate derivative information at a single point to approximation information around that point. ",
  "translatedText": "در مورد سری تیلور، شهود اساسی که باید در حین کاوش بیشتر در مورد آنچه وجود دارد به خاطر بسپارید، این است که آنها اطلاعات مشتق را در یک نقطه به اطلاعات تقریبی در اطراف آن نقطه ترجمه می کنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1288.06,
  "end": 1301.16
 },
 {
  "input": "Thank you once again to everybody who supported this series. ",
  "translatedText": "یک بار دیگر از همه کسانی که از این سریال حمایت کردند تشکر می کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1303.92,
  "end": 1306.6
 },
 {
  "input": "The next series like it will be on probability, and if you want early access as those videos are made, you know where to go. ",
  "translatedText": "سری بعدی مانند آن به احتمال زیاد خواهد بود، و اگر می‌خواهید با ساخت آن ویدیوها دسترسی اولیه داشته باشید، می‌دانید کجا باید بروید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1307.3,
  "end": 1339.06
 }
]