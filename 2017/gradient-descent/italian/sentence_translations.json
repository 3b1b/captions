[
 {
  "input": "Last video I laid out the structure of a neural network.",
  "translatedText": "Nell'ultimo video ho presentato la struttura di una rete neurale.",
  "n_reviews": 0,
  "start": 4.18,
  "end": 7.28
 },
 {
  "input": "I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video.",
  "translatedText": "Farò un breve riepilogo qui in modo che sia fresco nelle nostre menti, quindi ho due obiettivi principali per questo video.",
  "n_reviews": 0,
  "start": 7.68,
  "end": 12.6
 },
 {
  "input": "The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well.",
  "translatedText": "Il primo è introdurre l’idea della discesa del gradiente, che è alla base non solo del modo in cui le reti neurali apprendono, ma anche del funzionamento di molti altri sistemi di apprendimento automatico.",
  "n_reviews": 0,
  "start": 13.1,
  "end": 20.6
 },
 {
  "input": "Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for.",
  "translatedText": "Successivamente approfondiremo un po' di più il funzionamento di questa particolare rete e cosa finiscono per cercare quegli strati nascosti di neuroni.",
  "n_reviews": 0,
  "start": 21.12,
  "end": 27.94
 },
 {
  "input": "As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks.",
  "translatedText": "Come promemoria, il nostro obiettivo qui è il classico esempio di riconoscimento delle cifre scritte a mano, il ciao mondo delle reti neurali.",
  "n_reviews": 0,
  "start": 28.98,
  "end": 36.22
 },
 {
  "input": "These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1.",
  "translatedText": "Queste cifre vengono visualizzate su una griglia di 28x28 pixel, ciascun pixel con un valore di scala di grigio compreso tra 0 e 1.",
  "n_reviews": 0,
  "start": 37.02,
  "end": 43.42
 },
 {
  "input": "Those are what determine the activations of 784 neurons in the input layer of the network.",
  "translatedText": "Questi sono ciò che determina l'attivazione di 784 neuroni nello strato di input della rete.",
  "n_reviews": 0,
  "start": 43.82,
  "end": 50.04
 },
 {
  "input": "And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias.",
  "translatedText": "E poi l'attivazione di ciascun neurone negli strati successivi si basa su una somma ponderata di tutte le attivazioni nello strato precedente, più un numero speciale chiamato bias.",
  "n_reviews": 0,
  "start": 51.18,
  "end": 60.82
 },
 {
  "input": "Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video.",
  "translatedText": "Poi componi quella somma con qualche altra funzione, come lo schiacciamento del sigmoide, o un relu, come ho visto nell'ultimo video.",
  "n_reviews": 0,
  "start": 62.16,
  "end": 68.94
 },
 {
  "input": "In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does.",
  "translatedText": "In totale, data la scelta un po' arbitraria di due strati nascosti con 16 neuroni ciascuno, la rete ha circa 13.000 pesi e bias che possiamo regolare, e sono questi valori che determinano esattamente cosa fa effettivamente la rete.",
  "n_reviews": 0,
  "start": 69.48,
  "end": 84.38
 },
 {
  "input": "Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit.",
  "translatedText": "Quindi ciò che intendiamo quando diciamo che questa rete classifica una determinata cifra è che il più luminoso di quei 10 neuroni nello strato finale corrisponde a quella cifra.",
  "n_reviews": 0,
  "start": 84.88,
  "end": 93.3
 },
 {
  "input": "And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits.",
  "translatedText": "E ricorda, la motivazione che avevamo in mente qui per la struttura a strati era che forse il secondo strato poteva riprendere i bordi, e il terzo strato poteva riprendere modelli come anelli e linee, e l'ultimo poteva semplicemente mettere insieme quelli modelli per riconoscere le cifre.",
  "n_reviews": 0,
  "start": 94.1,
  "end": 108.8
 },
 {
  "input": "So here, we learn how the network learns.",
  "translatedText": "Quindi qui impariamo come apprende la rete.",
  "n_reviews": 0,
  "start": 109.8,
  "end": 112.24
 },
 {
  "input": "What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data.",
  "translatedText": "Quello che vogliamo è un algoritmo in cui puoi mostrare a questa rete un sacco di dati di addestramento, che si presentano sotto forma di un mucchio di immagini diverse di cifre scritte a mano, insieme alle etichette per quello che dovrebbero essere, e sarà aggiustare questi 13.000 pesi e bias in modo da migliorare le sue prestazioni sui dati di allenamento.",
  "n_reviews": 0,
  "start": 112.64,
  "end": 130.12
 },
 {
  "input": "Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data.",
  "translatedText": "Si spera che questa struttura a strati significhi che ciò che apprende si generalizzi in immagini oltre i dati di addestramento.",
  "n_reviews": 0,
  "start": 130.72,
  "end": 136.86
 },
 {
  "input": "The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images.",
  "translatedText": "Il modo in cui lo testiamo è che dopo aver addestrato la rete, le mostri più dati etichettati mai visti prima e vedi con quanta precisione classifica quelle nuove immagini.",
  "n_reviews": 0,
  "start": 137.64,
  "end": 146.7
 },
 {
  "input": "Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be.",
  "translatedText": "Fortunatamente per noi, e ciò che rende questo esempio così comune per cominciare, è che le brave persone dietro il database MNIST hanno messo insieme una raccolta di decine di migliaia di immagini di cifre scritte a mano, ognuna etichettata con i numeri che dovrebbero Essere.",
  "n_reviews": 0,
  "start": 151.12,
  "end": 164.2
 },
 {
  "input": "And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise.",
  "translatedText": "E per quanto provocatorio sia descrivere una macchina in grado di apprendere, una volta visto come funziona, sembra molto meno una folle premessa fantascientifica e molto più un esercizio di calcolo.",
  "n_reviews": 0,
  "start": 164.9,
  "end": 175.48
 },
 {
  "input": "I mean, basically it comes down to finding the minimum of a certain function.",
  "translatedText": "Voglio dire, fondamentalmente si tratta di trovare il minimo di una certa funzione.",
  "n_reviews": 0,
  "start": 176.2,
  "end": 179.96
 },
 {
  "input": "Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
  "translatedText": "Ricorda, concettualmente, pensiamo che ciascun neurone sia connesso a tutti i neuroni dello strato precedente, e i pesi nella somma ponderata che definisce la sua attivazione sono un po' come i punti di forza di quelle connessioni, e il bias è una qualche indicazione di se quel neurone tende ad essere attivo o inattivo.",
  "n_reviews": 0,
  "start": 181.94,
  "end": 198.96
 },
 {
  "input": "And to start things off, we're just going to initialize all of those weights and biases totally randomly.",
  "translatedText": "E per iniziare, inizializzeremo tutti questi pesi e pregiudizi in modo totalmente casuale.",
  "n_reviews": 0,
  "start": 199.72,
  "end": 204.4
 },
 {
  "input": "Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random.",
  "translatedText": "Inutile dire che questa rete funzionerà in modo piuttosto orribile su un dato esempio di formazione, poiché sta semplicemente facendo qualcosa di casuale.",
  "n_reviews": 0,
  "start": 204.94,
  "end": 210.72
 },
 {
  "input": "For example, you feed in this image of a 3, and the output layer just looks like a mess.",
  "translatedText": "Ad esempio, inserisci questa immagine di un 3 e il livello di output sembra semplicemente un disastro.",
  "n_reviews": 0,
  "start": 211.04,
  "end": 216.02
 },
 {
  "input": "So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash.",
  "translatedText": "Quindi quello che fai è definire una funzione di costo, un modo per dire al computer, no, cattivo computer, che l'output dovrebbe avere attivazioni che sono 0 per la maggior parte dei neuroni, ma 1 per questo neurone, quello che mi hai dato è totale spazzatura.",
  "n_reviews": 0,
  "start": 216.6,
  "end": 230.76
 },
 {
  "input": "To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example.",
  "translatedText": "Per dirlo in modo un po' più matematico, sommi i quadrati delle differenze tra ciascuna di quelle attivazioni di output dei rifiuti e il valore che vuoi che abbiano, e questo è quello che chiameremo il costo di un singolo esempio di formazione.",
  "n_reviews": 0,
  "start": 231.72,
  "end": 245.02
 },
 {
  "input": "Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing.",
  "translatedText": "Si noti che questa somma è piccola quando la rete classifica correttamente l'immagine con sicurezza, ma è grande quando sembra che la rete non sappia cosa sta facendo.",
  "n_reviews": 0,
  "start": 245.96,
  "end": 256.4
 },
 {
  "input": "So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal.",
  "translatedText": "Quindi quello che fai è considerare il costo medio di tutte le decine di migliaia di esempi di formazione a tua disposizione.",
  "n_reviews": 0,
  "start": 258.64,
  "end": 265.44
 },
 {
  "input": "This average cost is our measure for how lousy the network is, and how bad the computer should feel.",
  "translatedText": "Questo costo medio è la nostra misura di quanto sia pessima la rete e di quanto dovrebbe sentirsi pessimo il computer.",
  "n_reviews": 0,
  "start": 267.04,
  "end": 272.74
 },
 {
  "input": "And that's a complicated thing.",
  "translatedText": "E questa è una cosa complicata.",
  "n_reviews": 0,
  "start": 273.42,
  "end": 274.6
 },
 {
  "input": "Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases?",
  "translatedText": "Ricordi che la rete stessa era fondamentalmente una funzione, che accetta 784 numeri come input, i valori dei pixel, e restituisce 10 numeri come output, e in un certo senso è parametrizzata da tutti questi pesi e pregiudizi?",
  "n_reviews": 0,
  "start": 275.04,
  "end": 288.8
 },
 {
  "input": "Well the cost function is a layer of complexity on top of that.",
  "translatedText": "Ebbene, la funzione di costo è uno strato di complessità in più.",
  "n_reviews": 0,
  "start": 289.5,
  "end": 292.82
 },
 {
  "input": "It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data.",
  "translatedText": "Prende come input quei circa 13.000 pesi e pregiudizi e sputa un singolo numero che descrive quanto siano gravi tali pesi e pregiudizi, e il modo in cui viene definito dipende dal comportamento della rete su tutte le decine di migliaia di dati di addestramento.",
  "n_reviews": 0,
  "start": 293.1,
  "end": 308.9
 },
 {
  "input": "That's a lot to think about.",
  "translatedText": "C'è molto a cui pensare.",
  "n_reviews": 0,
  "start": 309.52,
  "end": 311.0
 },
 {
  "input": "But just telling the computer what a crappy job it's doing isn't very helpful.",
  "translatedText": "Ma limitarsi a dire al computer che lavoro schifoso sta facendo non è molto utile.",
  "n_reviews": 0,
  "start": 312.4,
  "end": 315.82
 },
 {
  "input": "You want to tell it how to change those weights and biases so that it gets better.",
  "translatedText": "Vuoi dirgli come cambiare quei pesi e pregiudizi in modo che migliori.",
  "n_reviews": 0,
  "start": 316.22,
  "end": 320.06
 },
 {
  "input": "To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output.",
  "translatedText": "Per rendere più semplice, anziché faticare a immaginare una funzione con 13.000 input, immagina una semplice funzione che abbia un numero come input e un numero come output.",
  "n_reviews": 0,
  "start": 320.78,
  "end": 330.48
 },
 {
  "input": "How do you find an input that minimizes the value of this function?",
  "translatedText": "Come trovi un input che minimizzi il valore di questa funzione?",
  "n_reviews": 0,
  "start": 331.48,
  "end": 335.3
 },
 {
  "input": "Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function.",
  "translatedText": "Gli studenti di calcolo sapranno che a volte è possibile calcolare esplicitamente quel minimo, ma ciò non è sempre fattibile per funzioni veramente complicate, certamente non nella versione da 13.000 input di questa situazione per la nostra folle e complicata funzione di costo della rete neurale.",
  "n_reviews": 0,
  "start": 336.46,
  "end": 351.08
 },
 {
  "input": "A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower.",
  "translatedText": "Una tattica più flessibile è quella di iniziare da qualsiasi input e capire in quale direzione dovresti procedere per ridurre tale output.",
  "n_reviews": 0,
  "start": 351.58,
  "end": 359.2
 },
 {
  "input": "Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative.",
  "translatedText": "Nello specifico, se riesci a calcolare la pendenza della funzione nel punto in cui ti trovi, spostati a sinistra se la pendenza è positiva e sposta l'input a destra se la pendenza è negativa.",
  "n_reviews": 0,
  "start": 360.08,
  "end": 369.9
 },
 {
  "input": "If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function.",
  "translatedText": "Se lo fai ripetutamente, controllando in ogni punto la nuova pendenza e facendo il passo appropriato, ti avvicinerai ad un minimo locale della funzione.",
  "n_reviews": 0,
  "start": 371.96,
  "end": 379.84
 },
 {
  "input": "The image you might have in mind here is a ball rolling down a hill.",
  "translatedText": "L'immagine che potresti avere in mente qui è una palla che rotola giù da una collina.",
  "n_reviews": 0,
  "start": 380.64,
  "end": 383.8
 },
 {
  "input": "Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function.",
  "translatedText": "Nota, anche per questa funzione di input singolo davvero semplificata, ci sono molte possibili valli in cui potresti atterrare, a seconda dell'input casuale da cui inizi, e non c'è alcuna garanzia che il minimo locale in cui atterri sarà il valore più piccolo possibile della funzione di costo.",
  "n_reviews": 0,
  "start": 384.62,
  "end": 399.4
 },
 {
  "input": "That will carry over to our neural network case as well.",
  "translatedText": "Ciò si ripercuoterà anche sul caso della nostra rete neurale.",
  "n_reviews": 0,
  "start": 400.22,
  "end": 402.62
 },
 {
  "input": "I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that helps you from overshooting.",
  "translatedText": "Voglio anche che tu noti come se rendi le dimensioni dei tuoi passi proporzionali alla pendenza, quando la pendenza si appiattisce verso il minimo, i tuoi passi diventano sempre più piccoli e questo ti aiuta a non superare il limite.",
  "n_reviews": 0,
  "start": 403.18,
  "end": 414.6
 },
 {
  "input": "Bumping up the complexity a bit, imagine instead a function with two inputs and one output.",
  "translatedText": "Aumentando un po' la complessità, immagina invece una funzione con due input e un output.",
  "n_reviews": 0,
  "start": 415.94,
  "end": 420.98
 },
 {
  "input": "You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it.",
  "translatedText": "Potresti pensare allo spazio di input come al piano xy e alla funzione di costo come rappresentata graficamente come una superficie sopra di esso.",
  "n_reviews": 0,
  "start": 421.5,
  "end": 428.14
 },
 {
  "input": "Instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly.",
  "translatedText": "Invece di chiedere informazioni sulla pendenza della funzione, devi chiederti in quale direzione dovresti muoverti in questo spazio di input in modo da diminuire più rapidamente l'output della funzione.",
  "n_reviews": 0,
  "start": 428.76,
  "end": 438.96
 },
 {
  "input": "In other words, what's the downhill direction?",
  "translatedText": "In altre parole, qual è la direzione in discesa?",
  "n_reviews": 0,
  "start": 439.72,
  "end": 441.76
 },
 {
  "input": "Again, it's helpful to think of a ball rolling down that hill.",
  "translatedText": "Ancora una volta, è utile pensare a una palla che rotola giù da quella collina.",
  "n_reviews": 0,
  "start": 442.38,
  "end": 445.56
 },
 {
  "input": "Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly.",
  "translatedText": "Quelli di voi che hanno familiarità con il calcolo multivariabile sapranno che il gradiente di una funzione ti dà la direzione dell'ascesa più ripida, quale direzione dovresti fare per aumentare la funzione più rapidamente.",
  "n_reviews": 0,
  "start": 446.66,
  "end": 458.78
 },
 {
  "input": "Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly.",
  "translatedText": "Naturalmente, prendendo il negativo di quel gradiente si ottiene la direzione del passo che diminuisce la funzione più rapidamente.",
  "n_reviews": 0,
  "start": 459.56,
  "end": 466.04
 },
 {
  "input": "Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is.",
  "translatedText": "Ancor di più, la lunghezza di questo vettore gradiente è un'indicazione di quanto sia ripido il pendio più ripido.",
  "n_reviews": 0,
  "start": 467.24,
  "end": 473.84
 },
 {
  "input": "If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic.",
  "translatedText": "Se non hai familiarità con il calcolo multivariabile e desideri saperne di più, dai un'occhiata ad alcuni dei lavori che ho svolto per Khan Academy sull'argomento.",
  "n_reviews": 0,
  "start": 474.54,
  "end": 480.34
 },
 {
  "input": "Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is.",
  "translatedText": "Onestamente, però, tutto ciò che conta per me e te in questo momento è che in linea di principio esiste un modo per calcolare questo vettore, questo vettore che ti dice qual è la direzione in discesa e quanto è ripida.",
  "n_reviews": 0,
  "start": 480.86,
  "end": 491.9
 },
 {
  "input": "You'll be okay if that's all you know and you're not rock solid on the details.",
  "translatedText": "Starai bene se questo è tutto quello che sai e non sei solido come una roccia sui dettagli.",
  "n_reviews": 0,
  "start": 492.4,
  "end": 496.12
 },
 {
  "input": "If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over.",
  "translatedText": "Se riesci a capirlo, l'algoritmo per minimizzare la funzione consiste nel calcolare questa direzione del gradiente, quindi fare un piccolo passo in discesa e ripeterlo ancora e ancora.",
  "n_reviews": 0,
  "start": 497.2,
  "end": 506.74
 },
 {
  "input": "It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs.",
  "translatedText": "È la stessa idea di base per una funzione che ha 13.000 input invece di 2 input.",
  "n_reviews": 0,
  "start": 507.7,
  "end": 512.82
 },
 {
  "input": "Imagine organizing all 13,000 weights and biases of our network into a giant column vector.",
  "translatedText": "Immagina di organizzare tutti i 13.000 pesi e pregiudizi della nostra rete in un gigantesco vettore di colonne.",
  "n_reviews": 0,
  "start": 513.4,
  "end": 519.46
 },
 {
  "input": "The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function.",
  "translatedText": "Il gradiente negativo della funzione di costo è solo un vettore, è una direzione all'interno di questo spazio di input follemente enorme che ti dice quali spinte a tutti quei numeri causeranno la diminuzione più rapida della funzione di costo.",
  "n_reviews": 0,
  "start": 520.14,
  "end": 534.88
 },
 {
  "input": "And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make.",
  "translatedText": "E ovviamente, con la nostra funzione di costo appositamente progettata, modificare i pesi e i bias per ridurli significa far sì che l'output della rete su ciascun dato di addestramento assomigli meno a un array casuale di 10 valori e più a una decisione effettiva che vogliamo. farlo.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 550.82
 },
 {
  "input": "It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples.",
  "translatedText": "È importante ricordare che questa funzione di costo implica una media su tutti i dati di addestramento, quindi se la riduci al minimo, significa che ci sono prestazioni migliori su tutti questi campioni.",
  "n_reviews": 0,
  "start": 551.44,
  "end": 561.18
 },
 {
  "input": "The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video.",
  "translatedText": "L'algoritmo per calcolare questo gradiente in modo efficiente, che è effettivamente il cuore dell'apprendimento di una rete neurale, si chiama backpropagation, ed è ciò di cui parlerò nel prossimo video.",
  "n_reviews": 0,
  "start": 563.82,
  "end": 573.98
 },
 {
  "input": "There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas.",
  "translatedText": "Lì, voglio davvero prendermi il tempo per esaminare cosa succede esattamente a ciascun peso e bias per un dato dato di addestramento, cercando di dare un'idea intuitiva di ciò che sta accadendo oltre la pila di calcoli e formule pertinenti.",
  "n_reviews": 0,
  "start": 574.66,
  "end": 587.1
 },
 {
  "input": "Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function.",
  "translatedText": "Proprio qui, proprio ora, la cosa principale che voglio che tu sappia, indipendentemente dai dettagli di implementazione, è che ciò che intendiamo quando parliamo di apprendimento in rete è che sta semplicemente minimizzando una funzione di costo.",
  "n_reviews": 0,
  "start": 587.78,
  "end": 598.36
 },
 {
  "input": "And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill.",
  "translatedText": "E notate, una conseguenza di ciò è che è importante che questa funzione di costo abbia un output abbastanza regolare, in modo da poter trovare un minimo locale facendo piccoli passi verso il basso.",
  "n_reviews": 0,
  "start": 599.3,
  "end": 608.1
 },
 {
  "input": "This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are.",
  "translatedText": "Questo è il motivo per cui, tra l’altro, i neuroni artificiali hanno attivazioni che variano continuamente, anziché essere semplicemente attivi o inattivi in modo binario, come lo sono i neuroni biologici.",
  "n_reviews": 0,
  "start": 609.26,
  "end": 619.14
 },
 {
  "input": "This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent.",
  "translatedText": "Questo processo di spostamento ripetuto dell'input di una funzione di un multiplo del gradiente negativo è chiamato discesa del gradiente.",
  "n_reviews": 0,
  "start": 620.22,
  "end": 626.76
 },
 {
  "input": "It's a way to converge towards some local minimum of a cost function, basically a valley in this graph.",
  "translatedText": "È un modo per convergere verso un minimo locale di una funzione di costo, sostanzialmente una valle in questo grafico.",
  "n_reviews": 0,
  "start": 627.3,
  "end": 632.58
 },
 {
  "input": "I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this.",
  "translatedText": "Sto ancora mostrando l'immagine di una funzione con due input, ovviamente, perché i nudge in uno spazio di input a 13.000 dimensioni sono un po' difficili da comprendere, ma esiste un bel modo non spaziale di pensarci.",
  "n_reviews": 0,
  "start": 633.44,
  "end": 644.26
 },
 {
  "input": "Each component of the negative gradient tells us two things.",
  "translatedText": "Ogni componente del gradiente negativo ci dice due cose.",
  "n_reviews": 0,
  "start": 645.08,
  "end": 648.44
 },
 {
  "input": "The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down.",
  "translatedText": "Il segno, ovviamente, ci dice se la componente corrispondente del vettore di input deve essere spostata verso l'alto o verso il basso.",
  "n_reviews": 0,
  "start": 649.06,
  "end": 655.14
 },
 {
  "input": "But importantly, the relative magnitudes of all these components kind of tells you which changes matter more.",
  "translatedText": "Ma, cosa ancora più importante, l’entità relativa di tutti questi componenti indica quali cambiamenti contano di più.",
  "n_reviews": 0,
  "start": 655.8,
  "end": 662.72
 },
 {
  "input": "You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight.",
  "translatedText": "Vedete, nella nostra rete, un aggiustamento a uno dei pesi potrebbe avere un impatto molto maggiore sulla funzione di costo rispetto all'aggiustamento a qualche altro peso.",
  "n_reviews": 0,
  "start": 665.22,
  "end": 673.04
 },
 {
  "input": "Some of these connections just matter more for our training data.",
  "translatedText": "Alcune di queste connessioni contano di più per i nostri dati di addestramento.",
  "n_reviews": 0,
  "start": 674.8,
  "end": 678.2
 },
 {
  "input": "So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck.",
  "translatedText": "Quindi un modo in cui puoi pensare a questo vettore gradiente della nostra enorme funzione di costo è che codifica l'importanza relativa di ogni peso e pregiudizio, cioè quale di questi cambiamenti porterà il maggior rapporto qualità-prezzo.",
  "n_reviews": 0,
  "start": 679.32,
  "end": 692.4
 },
 {
  "input": "This really is just another way of thinking about direction.",
  "translatedText": "Questo è davvero solo un altro modo di pensare alla direzione.",
  "n_reviews": 0,
  "start": 693.62,
  "end": 696.64
 },
 {
  "input": "To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction.",
  "translatedText": "Per fare un esempio più semplice, se hai una funzione con due variabili come input e calcoli che il suo gradiente in un punto particolare risulta come 3,1, allora da un lato puoi interpretarlo come se dicessi che quando tu' Stando su quell'input, muovendoti lungo questa direzione la funzione aumenta più rapidamente, ovvero quando rappresenti graficamente la funzione sopra il piano dei punti di input, quel vettore è ciò che ti dà la direzione diritta in salita.",
  "n_reviews": 0,
  "start": 697.1,
  "end": 722.26
 },
 {
  "input": "But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck.",
  "translatedText": "Ma un altro modo di leggerlo è dire che le modifiche a questa prima variabile hanno 3 volte l'importanza delle modifiche alla seconda variabile, che almeno nelle vicinanze dell'input rilevante, spostare il valore x porta molto più effetto per il tuo secchio.",
  "n_reviews": 0,
  "start": 722.86,
  "end": 736.9
 },
 {
  "input": "Let's zoom out and sum up where we are so far.",
  "translatedText": "Riduciamo lo zoom e riassumiamo dove siamo finora.",
  "n_reviews": 0,
  "start": 739.88,
  "end": 742.34
 },
 {
  "input": "The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums.",
  "translatedText": "La rete stessa è questa funzione con 784 ingressi e 10 uscite, definite in termini di tutte queste somme ponderate.",
  "n_reviews": 0,
  "start": 742.84,
  "end": 750.04
 },
 {
  "input": "The cost function is a layer of complexity on top of that.",
  "translatedText": "La funzione di costo è uno strato di complessità in più.",
  "n_reviews": 0,
  "start": 750.64,
  "end": 753.68
 },
 {
  "input": "It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples.",
  "translatedText": "Prende i 13.000 pesi e pregiudizi come input e produce un'unica misura di pessimazza basata sugli esempi di formazione.",
  "n_reviews": 0,
  "start": 753.98,
  "end": 761.72
 },
 {
  "input": "And the gradient of the cost function is one more layer of complexity still.",
  "translatedText": "E il gradiente della funzione di costo rappresenta ancora un ulteriore livello di complessità.",
  "n_reviews": 0,
  "start": 762.44,
  "end": 766.9
 },
 {
  "input": "It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most.",
  "translatedText": "Ci dice quali spinte a tutti questi pesi e pregiudizi causano il cambiamento più rapido nel valore della funzione di costo, che potresti interpretare come dire quali cambiamenti a quali pesi contano di più.",
  "n_reviews": 0,
  "start": 767.36,
  "end": 777.88
 },
 {
  "input": "So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before?",
  "translatedText": "Quindi, quando inizializzi la rete con pesi e bias casuali e li regoli molte volte in base a questo processo di discesa del gradiente, quanto bene si comporta effettivamente su immagini mai viste prima?",
  "n_reviews": 0,
  "start": 782.56,
  "end": 793.2
 },
 {
  "input": "The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly.",
  "translatedText": "Quello che ho descritto qui, con i due strati nascosti di 16 neuroni ciascuno, scelti soprattutto per ragioni estetiche, non è male, classificando correttamente circa il 96% delle nuove immagini che vede.",
  "n_reviews": 0,
  "start": 794.1,
  "end": 805.96
 },
 {
  "input": "And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack.",
  "translatedText": "E onestamente, se guardi alcuni degli esempi in cui si incasina, ti senti obbligato a darci un taglio.",
  "n_reviews": 0,
  "start": 806.68,
  "end": 812.54
 },
 {
  "input": "Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%.",
  "translatedText": "Ora, se giochi con la struttura dei livelli nascosti e apporti un paio di modifiche, puoi ottenere questo fino al 98%.",
  "n_reviews": 0,
  "start": 816.22,
  "end": 821.76
 },
 {
  "input": "And that's pretty good!",
  "translatedText": "E questo è abbastanza buono!",
  "n_reviews": 0,
  "start": 821.76,
  "end": 822.72
 },
 {
  "input": "It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for.",
  "translatedText": "Non è il massimo, puoi sicuramente ottenere prestazioni migliori diventando più sofisticato di questa semplice rete vanilla, ma dato quanto sia scoraggiante il compito iniziale, penso che ci sia qualcosa di incredibile nel fatto che qualsiasi rete riesca così bene su immagini mai viste prima, dato che non gli abbiamo mai detto specificatamente quali modelli cercare.",
  "n_reviews": 0,
  "start": 823.02,
  "end": 841.42
 },
 {
  "input": "Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits.",
  "translatedText": "Originariamente, il modo in cui ho motivato questa struttura era descrivendo una speranza che potremmo avere, che il secondo strato potesse captare piccoli bordi, che il terzo strato mettesse insieme quei bordi per riconoscere anelli e linee più lunghe, e che questi potessero essere ricomposti insieme per riconoscere le cifre.",
  "n_reviews": 0,
  "start": 842.56,
  "end": 857.18
 },
 {
  "input": "So is this what our network is actually doing?",
  "translatedText": "Quindi è questo ciò che sta effettivamente facendo la nostra rete?",
  "n_reviews": 0,
  "start": 857.96,
  "end": 860.4
 },
 {
  "input": "Well, for this one at least, not at all.",
  "translatedText": "Beh, almeno per questo, per niente.",
  "n_reviews": 0,
  "start": 861.08,
  "end": 864.4
 },
 {
  "input": "Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on?",
  "translatedText": "Ricordi come nell'ultimo video abbiamo visto come i pesi delle connessioni da tutti i neuroni del primo strato a un dato neurone del secondo strato possono essere visualizzati come un dato modello di pixel che il neurone del secondo strato sta rilevando?",
  "n_reviews": 0,
  "start": 864.82,
  "end": 877.06
 },
 {
  "input": "Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there.",
  "translatedText": "Bene, quando lo facciamo effettivamente per i pesi associati a queste transizioni, dal primo strato al successivo, invece di raccogliere piccoli bordi isolati qua e là, sembrano, beh, quasi casuali, solo con alcuni schemi molto vaghi in il mezzo lì.",
  "n_reviews": 0,
  "start": 877.78,
  "end": 893.68
 },
 {
  "input": "It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for.",
  "translatedText": "Sembrerebbe che nell'insondabilmente ampio spazio di 13.000 dimensioni dei possibili pesi e pregiudizi, la nostra rete si sia trovata un piccolo e felice minimo locale che, nonostante abbia classificato con successo la maggior parte delle immagini, non riprende esattamente gli schemi che avremmo potuto sperare.",
  "n_reviews": 0,
  "start": 893.76,
  "end": 908.96
 },
 {
  "input": "And to really drive this point home, watch what happens when you input a random image.",
  "translatedText": "E per chiarire davvero questo punto, guarda cosa succede quando inserisci un'immagine casuale.",
  "n_reviews": 0,
  "start": 909.78,
  "end": 913.82
 },
 {
  "input": "If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5.",
  "translatedText": "Se il sistema fosse intelligente, potresti aspettarti che si senta incerto, magari non attivando realmente nessuno di quei 10 neuroni in uscita o attivandoli tutti in modo uniforme, ma invece ti dà con sicurezza qualche risposta senza senso, come se fosse sicuro che questo rumore casuale è un 5 così come l'immagine reale di un 5 è un 5.",
  "n_reviews": 0,
  "start": 914.32,
  "end": 934.16
 },
 {
  "input": "Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them.",
  "translatedText": "In altre parole, anche se questa rete è in grado di riconoscere le cifre abbastanza bene, non ha idea di come disegnarle.",
  "n_reviews": 0,
  "start": 934.54,
  "end": 940.7
 },
 {
  "input": "A lot of this is because it's such a tightly constrained training setup.",
  "translatedText": "In gran parte ciò è dovuto al fatto che si tratta di un'impostazione di allenamento così strettamente vincolata.",
  "n_reviews": 0,
  "start": 941.42,
  "end": 945.24
 },
 {
  "input": "I mean, put yourself in the network's shoes here.",
  "translatedText": "Voglio dire, mettiti nei panni della rete qui.",
  "n_reviews": 0,
  "start": 945.88,
  "end": 947.74
 },
 {
  "input": "From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions.",
  "translatedText": "Dal suo punto di vista, l’intero universo non consiste altro che di cifre immobili chiaramente definite centrate in una minuscola griglia, e la sua funzione di costo non gli ha mai dato alcun incentivo ad essere altro che completamente fiduciosi nelle sue decisioni.",
  "n_reviews": 0,
  "start": 948.14,
  "end": 961.08
 },
 {
  "input": "So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns.",
  "translatedText": "Quindi, con questa come immagine di ciò che stanno realmente facendo i neuroni del secondo strato, potreste chiedervi perché introdurrei questa rete con la motivazione di cogliere bordi e schemi.",
  "n_reviews": 0,
  "start": 962.12,
  "end": 969.92
 },
 {
  "input": "I mean, that's just not at all what it ends up doing.",
  "translatedText": "Voglio dire, non è affatto quello che finisce per fare.",
  "n_reviews": 0,
  "start": 969.92,
  "end": 972.3
 },
 {
  "input": "Well, this is not meant to be our end goal, but instead a starting point.",
  "translatedText": "Ebbene, questo non vuole essere il nostro obiettivo finale, ma piuttosto un punto di partenza.",
  "n_reviews": 0,
  "start": 973.38,
  "end": 977.18
 },
 {
  "input": "Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems.",
  "translatedText": "Francamente, questa è una tecnologia vecchia, del tipo studiato negli anni '80 e '90, e devi capirla prima di poter comprendere varianti moderne più dettagliate, ed è chiaramente in grado di risolvere alcuni problemi interessanti, ma più approfondisci cosa quegli strati nascosti stanno davvero facendo, tanto meno intelligenti sembrano.",
  "n_reviews": 0,
  "start": 977.64,
  "end": 994.74
 },
 {
  "input": "Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow.",
  "translatedText": "Spostando per un momento l'attenzione da come le reti apprendono a come impari tu, ciò accadrà solo se ti impegnerai attivamente con il materiale qui in qualche modo.",
  "n_reviews": 0,
  "start": 998.48,
  "end": 1006.3
 },
 {
  "input": "One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns.",
  "translatedText": "Una cosa piuttosto semplice che voglio che tu faccia è semplicemente fermarti adesso e pensare profondamente per un momento a quali modifiche potresti apportare a questo sistema e al modo in cui percepisce le immagini se volessi che rilevasse meglio cose come bordi e motivi.",
  "n_reviews": 0,
  "start": 1007.06,
  "end": 1020.88
 },
 {
  "input": "But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks.",
  "translatedText": "Ma meglio di così, per interagire davvero con il materiale, consiglio vivamente il libro di Michael Nielsen sull'apprendimento profondo e le reti neurali.",
  "n_reviews": 0,
  "start": 1021.48,
  "end": 1029.1
 },
 {
  "input": "In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing.",
  "translatedText": "In esso puoi trovare il codice e i dati da scaricare e con cui giocare per questo esatto esempio, e il libro ti guiderà passo dopo passo su cosa sta facendo quel codice.",
  "n_reviews": 0,
  "start": 1029.68,
  "end": 1038.36
 },
 {
  "input": "What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts.",
  "translatedText": "La cosa fantastica è che questo libro è gratuito e disponibile al pubblico, quindi se ne trai qualcosa, prendi in considerazione l'idea di unirti a me per fare una donazione a favore degli sforzi di Nielsen.",
  "n_reviews": 0,
  "start": 1039.3,
  "end": 1047.66
 },
 {
  "input": "I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill.",
  "translatedText": "Ho anche collegato un paio di altre risorse che mi piacciono molto nella descrizione, incluso il fenomenale e bellissimo post sul blog di Chris Ola e gli articoli in Distill.",
  "n_reviews": 0,
  "start": 1047.66,
  "end": 1056.5
 },
 {
  "input": "To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee.",
  "translatedText": "Per chiudere qui per gli ultimi minuti, voglio tornare a un frammento dell'intervista che ho avuto con Leisha Lee.",
  "n_reviews": 0,
  "start": 1058.28,
  "end": 1063.88
 },
 {
  "input": "You might remember her from the last video, she did her PhD work in deep learning.",
  "translatedText": "Potresti ricordarla dall'ultimo video, ha svolto il suo dottorato di ricerca in deep learning.",
  "n_reviews": 0,
  "start": 1064.3,
  "end": 1067.72
 },
 {
  "input": "In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning.",
  "translatedText": "In questo piccolo frammento parla di due articoli recenti che approfondiscono davvero il modo in cui alcune delle più moderne reti di riconoscimento delle immagini stanno effettivamente imparando.",
  "n_reviews": 0,
  "start": 1068.3,
  "end": 1075.78
 },
 {
  "input": "Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training.",
  "translatedText": "Giusto per stabilire il punto in cui eravamo nella conversazione, il primo articolo ha preso una di queste reti neurali particolarmente profonde che è davvero brava nel riconoscimento delle immagini, e invece di addestrarla su un set di dati opportunamente etichettato, ha mescolato tutte le etichette prima dell'addestramento.",
  "n_reviews": 0,
  "start": 1076.12,
  "end": 1088.74
 },
 {
  "input": "Obviously the testing accuracy here was no better than random, since everything is just randomly labeled, but it was still able to achieve the same training accuracy as you would on a properly labeled dataset.",
  "translatedText": "Ovviamente la precisione del test qui non era migliore di quella casuale, poiché tutto è etichettato in modo casuale, ma è stato comunque in grado di ottenere la stessa precisione di addestramento che si otterrebbe su un set di dati correttamente etichettato.",
  "n_reviews": 0,
  "start": 1089.48,
  "end": 1100.88
 },
 {
  "input": "Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization?",
  "translatedText": "Fondamentalmente, i milioni di pesi per questa particolare rete erano sufficienti per memorizzare semplicemente i dati casuali, il che solleva la questione se minimizzare questa funzione di costo corrisponda effettivamente a qualsiasi tipo di struttura nell'immagine, o si tratta solo di memorizzazione?",
  "n_reviews": 0,
  "start": 1101.6,
  "end": 1116.4
 },
 {
  "input": "If you look at that accuracy curve, if you were just training on a random dataset, that curve sort of went down very slowly in almost kind of a linear fashion, so you're really struggling to find that local minima of possible, you know, the right weights that would get you that accuracy.",
  "translatedText": "Se guardi quella curva di precisione, se ti stessi allenando su un set di dati casuale, quella curva scendeva molto lentamente in modo quasi lineare, quindi fai davvero fatica a trovare quel minimo locale di possibile, sai , i pesi giusti che ti darebbero quella precisione.",
  "n_reviews": 0,
  "start": 1131.44,
  "end": 1152.14
 },
 {
  "input": "Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima.",
  "translatedText": "Mentre se ti stai effettivamente allenando su un set di dati strutturato, uno che ha le etichette giuste, all'inizio giocheri un po', ma poi scendi molto velocemente per arrivare a quel livello di precisione, e quindi in un certo senso è era più facile trovare i massimi locali.",
  "n_reviews": 0,
  "start": 1152.24,
  "end": 1168.22
 },
 {
  "input": "And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily.",
  "translatedText": "E quindi la cosa interessante è che porta alla luce un altro documento di un paio di anni fa, che presenta molte più semplificazioni sui livelli di rete, ma uno dei risultati diceva che se si guarda al panorama dell'ottimizzazione, i minimi locali che queste reti tendono ad apprendere sono in realtà di pari qualità, quindi in un certo senso se il tuo set di dati è strutturato, dovresti essere in grado di trovarlo molto più facilmente.",
  "n_reviews": 0,
  "start": 1168.54,
  "end": 1194.32
 },
 {
  "input": "My thanks, as always, to those of you supporting on Patreon.",
  "translatedText": "I miei ringraziamenti, come sempre, a quelli di voi che sostengono su Patreon.",
  "n_reviews": 0,
  "start": 1198.16,
  "end": 1201.18
 },
 {
  "input": "I've said before just what a game changer Patreon is, but these videos really would not be possible without you.",
  "translatedText": "Ho già detto in precedenza che Patreon rappresenta una svolta, ma questi video non sarebbero davvero possibili senza di te.",
  "n_reviews": 0,
  "start": 1201.52,
  "end": 1206.8
 },
 {
  "input": "I also want to give a special thanks to the VC firm Amplify Partners, in their support of these initial videos in the series.",
  "translatedText": "Voglio anche ringraziare in modo speciale la società di VC Amplify Partners, per il suo supporto a questi video iniziali della serie.",
  "n_reviews": 0,
  "start": 1207.46,
  "end": 1212.78
 }
]