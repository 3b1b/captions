1
00:00:00,000 --> 00:00:07,240
Nell&#39;ultimo video ho presentato la struttura di una rete neurale.

2
00:00:07,240 --> 00:00:10,295
Farò un breve riepilogo qui in modo che sia fresco nelle nostre

3
00:00:10,295 --> 00:00:13,160
menti, quindi ho due obiettivi principali per questo video.

4
00:00:13,160 --> 00:00:15,719
Il primo è introdurre l’idea della discesa del gradiente, che è alla

5
00:00:15,719 --> 00:00:18,203
base non solo del modo in cui le reti neurali apprendono, ma anche

6
00:00:18,203 --> 00:00:20,800
del funzionamento di molti altri sistemi di apprendimento automatico.

7
00:00:20,800 --> 00:00:25,040
Successivamente approfondiremo un po&#39; di più il funzionamento di questa

8
00:00:25,040 --> 00:00:29,560
particolare rete e cosa finiscono per cercare quegli strati nascosti di neuroni.

9
00:00:29,560 --> 00:00:33,030
Come promemoria, il nostro obiettivo qui è il classico esempio di

10
00:00:33,030 --> 00:00:37,080
riconoscimento delle cifre scritte a mano, il ciao mondo delle reti neurali.

11
00:00:37,080 --> 00:00:40,615
Queste cifre vengono visualizzate su una griglia di 28x28 pixel,

12
00:00:40,615 --> 00:00:44,260
ciascun pixel con un valore di scala di grigio compreso tra 0 e 1.

13
00:00:44,260 --> 00:00:47,793
Questi sono ciò che determina l&#39;attivazione

14
00:00:47,793 --> 00:00:51,400
di 784 neuroni nello strato di input della rete.

15
00:00:51,400 --> 00:00:56,393
L&#39;attivazione di ciascun neurone negli strati successivi si basa su una somma

16
00:00:56,393 --> 00:01:01,386
ponderata di tutte le attivazioni dello strato precedente, più un numero speciale

17
00:01:01,386 --> 00:01:02,300
chiamato bias.

18
00:01:02,300 --> 00:01:06,273
Componi quella somma con qualche altra funzione, come lo schiacciamento

19
00:01:06,273 --> 00:01:09,640
del sigmoide o un ReLU, come ho visto nell&#39;ultimo video.

20
00:01:09,640 --> 00:01:14,822
In totale, data la scelta un po&#39; arbitraria di due strati nascosti con 16

21
00:01:14,822 --> 00:01:19,938
neuroni ciascuno, la rete ha circa 13.000 pesi e bias che possiamo regolare,

22
00:01:19,938 --> 00:01:25,320
e sono questi valori che determinano esattamente cosa fa effettivamente la rete.

23
00:01:25,320 --> 00:01:29,700
E ciò che intendiamo quando diciamo che questa rete classifica una determinata cifra è

24
00:01:29,700 --> 00:01:34,080
che il più luminoso di quei 10 neuroni nello strato finale corrisponde a quella cifra.

25
00:01:34,080 --> 00:01:38,051
E ricorda, la motivazione che avevamo in mente per la struttura a strati

26
00:01:38,051 --> 00:01:41,751
era che forse il secondo strato poteva riprendere i bordi, il terzo

27
00:01:41,751 --> 00:01:45,450
strato poteva riprendere schemi come anelli e linee, e l&#39;ultimo

28
00:01:45,450 --> 00:01:49,640
poteva semplicemente mettere insieme quegli schemi per riconoscere le cifre.

29
00:01:49,640 --> 00:01:52,880
Quindi qui impariamo come apprende la rete.

30
00:01:52,880 --> 00:01:56,495
Quello che vogliamo è un algoritmo in cui puoi mostrare a questa rete un

31
00:01:56,495 --> 00:01:59,863
sacco di dati di addestramento, che si presentano sotto forma di un

32
00:01:59,863 --> 00:02:03,627
mucchio di immagini diverse di cifre scritte a mano, insieme alle etichette

33
00:02:03,627 --> 00:02:07,144
per quello che dovrebbero essere, e sarà aggiustare questi 13.000 pesi

34
00:02:07,144 --> 00:02:10,760
e bias in modo da migliorare le sue prestazioni sui dati di allenamento.

35
00:02:10,760 --> 00:02:14,162
Si spera che questa struttura a strati significhi che ciò che

36
00:02:14,162 --> 00:02:17,840
apprende si generalizzi in immagini oltre i dati di addestramento.

37
00:02:17,840 --> 00:02:24,372
Il modo in cui lo testiamo è che dopo aver addestrato la rete, le mostri più

38
00:02:24,372 --> 00:02:31,160
dati etichettati e vedi con quanta precisione classifica quelle nuove immagini.

39
00:02:31,160 --> 00:02:34,565
Fortunatamente per noi, e ciò che rende questo un esempio comune con

40
00:02:34,565 --> 00:02:38,021
cui cominciare, è che le brave persone dietro il database MNIST hanno

41
00:02:38,021 --> 00:02:41,476
messo insieme una raccolta di decine di migliaia di immagini di cifre

42
00:02:41,476 --> 00:02:45,080
scritte a mano, ciascuna etichettata con i numeri che dovrebbero essere.

43
00:02:45,080 --> 00:02:48,538
E per quanto provocatorio sia descrivere una macchina in grado di

44
00:02:48,538 --> 00:02:51,944
apprendere, una volta visto come funziona, sembra molto meno una

45
00:02:51,944 --> 00:02:55,560
folle premessa fantascientifica e molto più un esercizio di calcolo.

46
00:02:55,560 --> 00:03:01,040
Voglio dire, fondamentalmente si tratta di trovare il minimo di una certa funzione.

47
00:03:01,040 --> 00:03:05,479
Ricorda, concettualmente pensiamo che ciascun neurone sia connesso a tutti i

48
00:03:05,479 --> 00:03:10,150
neuroni dello strato precedente, e i pesi nella somma ponderata che definisce la

49
00:03:10,150 --> 00:03:14,878
sua attivazione sono un po&#39; come i punti di forza di quelle connessioni, e il

50
00:03:14,878 --> 00:03:19,780
bias è una qualche indicazione di se quel neurone tende ad essere attivo o inattivo.

51
00:03:19,780 --> 00:03:22,659
E per iniziare, inizializzeremo tutti questi pesi

52
00:03:22,659 --> 00:03:25,020
e pregiudizi in modo totalmente casuale.

53
00:03:25,020 --> 00:03:27,908
Inutile dire che questa rete funzionerà in modo pessimo con un dato

54
00:03:27,908 --> 00:03:31,180
esempio di formazione, poiché sta semplicemente facendo qualcosa di casuale.

55
00:03:31,180 --> 00:03:33,972
Ad esempio, inserisci questa immagine di un 3 e il

56
00:03:33,972 --> 00:03:36,820
livello di output sembra semplicemente un disastro.

57
00:03:36,820 --> 00:03:40,805
Quindi quello che fai è definire una funzione di costo, un modo per dire

58
00:03:40,805 --> 00:03:45,118
al computer, no, cattivo computer, che l&#39;output dovrebbe avere attivazioni

59
00:03:45,118 --> 00:03:48,940
che sono 0 per la maggior parte dei neuroni, ma 1 per questo neurone.

60
00:03:48,940 --> 00:03:51,740
Ciò che mi hai dato è pura spazzatura.

61
00:03:51,740 --> 00:03:56,500
Per dirlo in modo un po&#39; più matematico, sommi i quadrati delle differenze tra

62
00:03:56,500 --> 00:04:01,489
ciascuna di quelle attivazioni di output dei rifiuti e il valore che vuoi che abbiano,

63
00:04:01,489 --> 00:04:06,020
e questo è quello che chiameremo il costo di un singolo esempio di formazione.

64
00:04:06,020 --> 00:04:12,717
Si noti che questa somma è piccola quando la rete classifica correttamente l&#39;immagine

65
00:04:12,717 --> 00:04:18,820
con sicurezza, ma è grande quando sembra che la rete non sappia cosa sta facendo.

66
00:04:18,820 --> 00:04:23,200
Quindi quello che fai è considerare il costo medio di tutte le

67
00:04:23,200 --> 00:04:27,580
decine di migliaia di esempi di formazione a tua disposizione.

68
00:04:27,580 --> 00:04:30,487
Questo costo medio è la nostra misura di quanto sia scadente

69
00:04:30,487 --> 00:04:33,300
la rete e di quanto pessimo dovrebbe sentirsi il computer.

70
00:04:33,300 --> 00:04:35,300
E questa è una cosa complicata.

71
00:04:35,300 --> 00:04:40,015
Ricordi che la rete stessa era fondamentalmente una funzione, che accetta

72
00:04:40,015 --> 00:04:44,602
784 numeri come input, i valori dei pixel, e restituisce 10 numeri come

73
00:04:44,602 --> 00:04:49,700
output, e in un certo senso è parametrizzata da tutti questi pesi e pregiudizi?

74
00:04:49,700 --> 00:04:53,340
La funzione di costo è uno strato di complessità in più.

75
00:04:53,340 --> 00:04:58,405
Prende come input quei circa 13.000 pesi e pregiudizi e sputa un singolo numero che

76
00:04:58,405 --> 00:05:03,471
descrive quanto siano gravi tali pesi e pregiudizi, e il modo in cui viene definito

77
00:05:03,471 --> 00:05:08,235
dipende dal comportamento della rete su tutte le decine di migliaia di dati di

78
00:05:08,235 --> 00:05:09,140
addestramento.

79
00:05:09,140 --> 00:05:12,460
C&#39;è molto a cui pensare.

80
00:05:12,460 --> 00:05:16,380
Ma limitarsi a dire al computer che lavoro schifoso sta facendo non è molto utile.

81
00:05:16,380 --> 00:05:21,300
Vuoi dirgli come cambiare quei pesi e pregiudizi in modo che migliori.

82
00:05:21,300 --> 00:05:26,370
Per rendere più semplice, anziché faticare a immaginare una funzione con 13.000 input,

83
00:05:26,370 --> 00:05:31,440
immagina una semplice funzione che abbia un numero come input e un numero come output.

84
00:05:31,440 --> 00:05:36,420
Come trovi un input che minimizzi il valore di questa funzione?

85
00:05:36,420 --> 00:05:39,841
Gli studenti di calcolo sapranno che a volte è possibile calcolare

86
00:05:39,841 --> 00:05:43,468
esplicitamente quel minimo, ma ciò non è sempre fattibile per funzioni

87
00:05:43,468 --> 00:05:47,094
veramente complicate, certamente non nella versione da 13.000 input di

88
00:05:47,094 --> 00:05:51,640
questa situazione per la nostra folle e complicata funzione di costo della rete neurale.

89
00:05:51,640 --> 00:05:55,720
Una tattica più flessibile è quella di iniziare da qualsiasi input e

90
00:05:55,720 --> 00:05:59,860
capire in quale direzione dovresti procedere per ridurre tale output.

91
00:05:59,860 --> 00:06:04,190
Nello specifico, se riesci a calcolare la pendenza della funzione

92
00:06:04,190 --> 00:06:08,389
nel punto in cui ti trovi, spostati a sinistra se la pendenza è

93
00:06:08,389 --> 00:06:12,720
positiva e sposta l&#39;input a destra se la pendenza è negativa.

94
00:06:12,720 --> 00:06:16,465
Se lo fai ripetutamente, controllando in ogni punto la nuova pendenza e

95
00:06:16,465 --> 00:06:20,680
facendo il passo appropriato, ti avvicinerai ad un minimo locale della funzione.

96
00:06:20,680 --> 00:06:22,767
E l&#39;immagine che potresti avere in mente qui

97
00:06:22,767 --> 00:06:24,600
è una palla che rotola giù da una collina.

98
00:06:24,600 --> 00:06:28,302
E nota, anche per questa funzione di input singolo davvero semplificata, ci

99
00:06:28,302 --> 00:06:32,151
sono molte possibili valli in cui potresti atterrare, a seconda dell&#39;input

100
00:06:32,151 --> 00:06:35,854
casuale da cui inizi, e non c&#39;è alcuna garanzia che il minimo locale in

101
00:06:35,854 --> 00:06:39,460
cui atterri sarà il valore più piccolo possibile della funzione di costo.

102
00:06:39,460 --> 00:06:43,180
Ciò si ripercuoterà anche sul caso della nostra rete neurale.

103
00:06:43,180 --> 00:06:47,730
E voglio anche che tu noti come se rendi le dimensioni dei tuoi passi proporzionali

104
00:06:47,730 --> 00:06:52,010
alla pendenza, quando la pendenza si appiattisce verso il minimo, i tuoi passi

105
00:06:52,010 --> 00:06:56,020
diventano sempre più piccoli, e questo ti aiuta a non superare il limite.

106
00:06:56,020 --> 00:06:58,830
Aumentando un po&#39; la complessità, immagina

107
00:06:58,830 --> 00:07:01,640
invece una funzione con due input e un output.

108
00:07:01,640 --> 00:07:05,355
Potresti pensare allo spazio di input come al piano xy e alla funzione di

109
00:07:05,355 --> 00:07:09,020
costo come rappresentata graficamente come una superficie sopra di esso.

110
00:07:09,020 --> 00:07:12,554
Invece di chiedere informazioni sulla pendenza della funzione, devi

111
00:07:12,554 --> 00:07:16,037
chiederti in quale direzione dovresti muoverti in questo spazio di

112
00:07:16,037 --> 00:07:19,780
input in modo da diminuire più rapidamente l&#39;output della funzione.

113
00:07:19,780 --> 00:07:22,340
In altre parole, qual è la direzione in discesa?

114
00:07:22,340 --> 00:07:26,740
E ancora, è utile pensare a una palla che rotola giù da quella collina.

115
00:07:26,740 --> 00:07:30,911
Quelli di voi che hanno familiarità con il calcolo multivariabile sapranno

116
00:07:30,911 --> 00:07:34,915
che il gradiente di una funzione ti dà la direzione dell&#39;ascesa più

117
00:07:34,915 --> 00:07:39,420
ripida, quale direzione dovresti fare per aumentare la funzione più rapidamente.

118
00:07:39,420 --> 00:07:43,379
Naturalmente, prendendo il negativo di quel gradiente si ottiene

119
00:07:43,379 --> 00:07:47,460
la direzione del passo che diminuisce la funzione più rapidamente.

120
00:07:47,460 --> 00:07:50,870
Ancor di più, la lunghezza di questo vettore gradiente è

121
00:07:50,870 --> 00:07:54,580
un&#39;indicazione di quanto sia ripido il pendio più ripido.

122
00:07:54,580 --> 00:07:57,858
Ora, se non hai familiarità con il calcolo multivariabile e desideri saperne di più, dai

123
00:07:57,858 --> 00:08:01,100
un&#39;occhiata ad alcuni dei lavori che ho svolto per Khan Academy sull&#39;argomento.

124
00:08:01,100 --> 00:08:04,646
Onestamente, però, tutto ciò che conta per me e te in questo momento è

125
00:08:04,646 --> 00:08:08,193
che in linea di principio esiste un modo per calcolare questo vettore,

126
00:08:08,193 --> 00:08:12,040
questo vettore che ti dice qual è la direzione in discesa e quanto è ripida.

127
00:08:12,040 --> 00:08:14,716
Starai bene se questo è tutto quello che sai e

128
00:08:14,716 --> 00:08:17,280
non sei solido come una roccia sui dettagli.

129
00:08:17,280 --> 00:08:20,562
Perché se riesci a capirlo, l&#39;algoritmo per minimizzare

130
00:08:20,562 --> 00:08:24,008
la funzione è calcolare questa direzione del gradiente, quindi

131
00:08:24,008 --> 00:08:27,400
fare un piccolo passo in discesa e ripeterlo ancora e ancora.

132
00:08:27,400 --> 00:08:33,700
È la stessa idea di base per una funzione che ha 13.000 input invece di 2 input.

133
00:08:33,700 --> 00:08:36,997
Immagina di organizzare tutti i 13.000 pesi e pregiudizi

134
00:08:36,997 --> 00:08:40,180
della nostra rete in un gigantesco vettore di colonne.

135
00:08:40,180 --> 00:08:45,314
Il gradiente negativo della funzione di costo è solo un vettore, è una direzione

136
00:08:45,314 --> 00:08:50,702
all&#39;interno di questo spazio di input follemente enorme che ti dice quali spinte

137
00:08:50,702 --> 00:08:55,900
a tutti quei numeri causeranno la diminuzione più rapida della funzione di costo.

138
00:08:55,900 --> 00:08:59,731
E ovviamente, con la nostra funzione di costo appositamente progettata,

139
00:08:59,731 --> 00:09:03,616
modificare i pesi e i bias per ridurli significa far sì che l&#39;output

140
00:09:03,616 --> 00:09:07,341
della rete su ciascun dato di addestramento assomigli meno a un array

141
00:09:07,341 --> 00:09:11,280
casuale di 10 valori e più a una decisione effettiva che vogliamo. farlo.

142
00:09:11,280 --> 00:09:15,733
È importante ricordare che questa funzione di costo implica una media

143
00:09:15,733 --> 00:09:19,869
su tutti i dati di addestramento, quindi se la riduci al minimo,

144
00:09:19,869 --> 00:09:24,260
significa che ci sono prestazioni migliori su tutti questi campioni.

145
00:09:24,260 --> 00:09:27,535
L&#39;algoritmo per calcolare questo gradiente in modo efficiente, che

146
00:09:27,535 --> 00:09:30,764
è effettivamente il cuore dell&#39;apprendimento di una rete neurale,

147
00:09:30,764 --> 00:09:34,040
si chiama backpropagation, ed è ciò di cui parlerò nel prossimo video.

148
00:09:34,040 --> 00:09:38,852
Lì, voglio davvero prendermi il tempo per esaminare cosa succede esattamente a ciascun

149
00:09:38,852 --> 00:09:43,443
peso e pregiudizio per un dato dato di addestramento, cercando di dare un&#39;idea

150
00:09:43,443 --> 00:09:47,980
intuitiva di ciò che sta accadendo oltre la pila di calcoli e formule pertinenti.

151
00:09:47,980 --> 00:09:52,049
Proprio qui, proprio ora, la cosa principale che voglio che tu sappia, indipendentemente

152
00:09:52,049 --> 00:09:55,570
dai dettagli di implementazione, è che ciò che intendiamo quando parliamo di

153
00:09:55,570 --> 00:09:59,320
apprendimento in rete è che sta semplicemente minimizzando una funzione di costo.

154
00:09:59,320 --> 00:10:02,508
E notate, una conseguenza di ciò è che è importante che questa

155
00:10:02,508 --> 00:10:05,848
funzione di costo abbia un output abbastanza regolare, in modo da

156
00:10:05,848 --> 00:10:09,340
poter trovare un minimo locale facendo piccoli passi verso il basso.

157
00:10:09,340 --> 00:10:13,091
Questo è il motivo per cui, tra l&#39;altro, i neuroni artificiali hanno

158
00:10:13,091 --> 00:10:16,894
attivazioni che variano continuamente, piuttosto che essere semplicemente

159
00:10:16,894 --> 00:10:20,440
attivi o inattivi in modo binario, come lo sono i neuroni biologici.

160
00:10:20,440 --> 00:10:23,677
Questo processo di spostamento ripetuto dell&#39;input di una funzione

161
00:10:23,677 --> 00:10:26,960
di un multiplo del gradiente negativo è chiamato discesa del gradiente.

162
00:10:26,960 --> 00:10:29,751
È un modo per convergere verso un minimo locale di una

163
00:10:29,751 --> 00:10:33,000
funzione di costo, sostanzialmente una valle in questo grafico.

164
00:10:33,000 --> 00:10:37,073
Sto ancora mostrando l&#39;immagine di una funzione con due input, ovviamente,

165
00:10:37,073 --> 00:10:40,888
perché i nudge in uno spazio di input a 13.000 dimensioni sono un po&#39;

166
00:10:40,888 --> 00:10:45,220
difficili da comprendere, ma in realtà esiste un bel modo non spaziale di pensarci.

167
00:10:45,220 --> 00:10:49,100
Ogni componente del gradiente negativo ci dice due cose.

168
00:10:49,100 --> 00:10:52,309
Il segno, ovviamente, ci dice se la componente corrispondente del

169
00:10:52,309 --> 00:10:55,860
vettore di input deve essere spostata verso l&#39;alto o verso il basso.

170
00:10:55,860 --> 00:11:00,740
Ma, cosa ancora più importante, l’entità relativa di tutti

171
00:11:00,740 --> 00:11:05,620
questi componenti indica quali cambiamenti contano di più.

172
00:11:05,620 --> 00:11:10,114
Vedete, nella nostra rete, un aggiustamento a uno dei pesi potrebbe avere un impatto

173
00:11:10,114 --> 00:11:14,662
molto maggiore sulla funzione di costo rispetto all&#39;aggiustamento a qualche altro

174
00:11:14,662 --> 00:11:14,980
peso.

175
00:11:14,980 --> 00:11:19,440
Alcune di queste connessioni contano di più per i nostri dati di addestramento.

176
00:11:19,440 --> 00:11:24,326
Quindi un modo in cui puoi pensare a questo vettore gradiente della nostra enorme

177
00:11:24,326 --> 00:11:29,511
funzione di costo è che codifica l&#39;importanza relativa di ogni peso e pregiudizio,

178
00:11:29,511 --> 00:11:34,100
cioè quale di questi cambiamenti porterà il maggior rapporto qualità-prezzo.

179
00:11:34,100 --> 00:11:37,360
Questo è davvero solo un altro modo di pensare alla direzione.

180
00:11:37,360 --> 00:11:41,602
Per fare un esempio più semplice, se hai una funzione con due variabili come

181
00:11:41,602 --> 00:11:45,954
input e calcoli che il suo gradiente in un punto particolare risulta come 3,1,

182
00:11:45,954 --> 00:11:50,252
allora da un lato puoi interpretarlo come se dicessi che quando sei stando su

183
00:11:50,252 --> 00:11:54,384
quell&#39;input, muovendosi lungo questa direzione la funzione aumenta più

184
00:11:54,384 --> 00:11:58,737
rapidamente, quindi quando rappresenti graficamente la funzione sopra il piano

185
00:11:58,737 --> 00:12:03,200
dei punti di input, quel vettore è ciò che ti dà la direzione diritta in salita.

186
00:12:03,200 --> 00:12:07,956
Ma un altro modo di leggerlo è dire che le modifiche a questa prima variabile hanno tre

187
00:12:07,956 --> 00:12:12,821
volte l&#39;importanza delle modifiche alla seconda variabile, che almeno nelle vicinanze

188
00:12:12,821 --> 00:12:17,253
dell&#39;input rilevante, spostare il valore x porta molto più effetto per il tuo

189
00:12:17,253 --> 00:12:17,740
secchio.

190
00:12:17,740 --> 00:12:22,880
Va bene, rimpiccioliamo e riassumiamo dove siamo finora.

191
00:12:22,880 --> 00:12:26,663
La rete stessa è questa funzione con 784 ingressi e 10

192
00:12:26,663 --> 00:12:30,860
uscite, definite in termini di tutte queste somme ponderate.

193
00:12:30,860 --> 00:12:34,160
La funzione di costo è uno strato di complessità in più.

194
00:12:34,160 --> 00:12:38,810
Prende i 13.000 pesi e pregiudizi come input e produce un&#39;unica

195
00:12:38,810 --> 00:12:42,640
misura di pessimazza basata sugli esempi di formazione.

196
00:12:42,640 --> 00:12:45,211
Il gradiente della funzione di costo rappresenta

197
00:12:45,211 --> 00:12:47,520
ancora un ulteriore livello di complessità.

198
00:12:47,520 --> 00:12:52,393
Ci dice quali spinte a tutti questi pesi e pregiudizi causano il

199
00:12:52,393 --> 00:12:57,791
cambiamento più rapido nel valore della funzione di costo, che potresti

200
00:12:57,791 --> 00:13:03,040
interpretare come dire quali cambiamenti a quali pesi contano di più.

201
00:13:03,040 --> 00:13:06,571
Quindi, quando inizializzi la rete con pesi e bias casuali e li

202
00:13:06,571 --> 00:13:10,488
regoli molte volte in base a questo processo di discesa del gradiente,

203
00:13:10,488 --> 00:13:14,240
quanto bene si comporta effettivamente su immagini mai viste prima?

204
00:13:14,240 --> 00:13:18,507
Quello che ho descritto qui, con i due strati nascosti di 16 neuroni

205
00:13:18,507 --> 00:13:22,466
ciascuno, scelti soprattutto per ragioni estetiche, non è male,

206
00:13:22,466 --> 00:13:26,920
classificando correttamente circa il 96% delle nuove immagini che vede.

207
00:13:26,920 --> 00:13:31,655
E onestamente, se guardi alcuni degli esempi in cui

208
00:13:31,655 --> 00:13:36,300
si incasina, ti senti obbligato a darci un taglio.

209
00:13:36,300 --> 00:13:38,803
Se giochi con la struttura dei livelli nascosti e apporti

210
00:13:38,803 --> 00:13:41,220
un paio di modifiche, puoi ottenere questo fino al 98%.

211
00:13:41,220 --> 00:13:42,900
E questo è abbastanza buono!

212
00:13:42,900 --> 00:13:46,781
Non è il massimo, puoi sicuramente ottenere prestazioni migliori diventando

213
00:13:46,781 --> 00:13:50,458
più sofisticato di questa semplice rete vanilla, ma considerando quanto

214
00:13:50,458 --> 00:13:54,492
sia scoraggiante il compito iniziale, penso che ci sia qualcosa di incredibile

215
00:13:54,492 --> 00:13:58,322
nel fatto che qualsiasi rete riesca così bene su immagini mai viste prima,

216
00:13:58,322 --> 00:14:02,000
dato che noi non gli ho mai detto specificamente quali modelli cercare.

217
00:14:02,000 --> 00:14:05,993
Originariamente, il modo in cui ho motivato questa struttura era descrivendo una

218
00:14:05,993 --> 00:14:10,036
speranza che potremmo avere, che il secondo strato potesse captare piccoli bordi,

219
00:14:10,036 --> 00:14:14,128
che il terzo strato mettesse insieme quei bordi per riconoscere anelli e linee più

220
00:14:14,128 --> 00:14:18,220
lunghe, e che questi potessero essere ricomposti insieme per riconoscere le cifre.

221
00:14:18,220 --> 00:14:21,040
Quindi è questo ciò che sta effettivamente facendo la nostra rete?

222
00:14:21,040 --> 00:14:24,880
Beh, almeno per questo, per niente.

223
00:14:24,880 --> 00:14:29,147
Ricordi come nell&#39;ultimo video abbiamo visto come i pesi delle connessioni da tutti

224
00:14:29,147 --> 00:14:32,978
i neuroni del primo strato a un dato neurone del secondo strato possono essere

225
00:14:32,978 --> 00:14:36,906
visualizzati come un dato modello di pixel che il neurone del secondo strato sta

226
00:14:36,906 --> 00:14:37,440
rilevando?

227
00:14:37,440 --> 00:14:43,195
Bene, quando lo facciamo per i pesi associati a queste transizioni,

228
00:14:43,195 --> 00:14:48,613
invece di raccogliere piccoli bordi isolati qua e là, sembrano,

229
00:14:48,613 --> 00:14:54,200
beh, quasi casuali, solo con alcuni schemi molto vaghi nel mezzo.

230
00:14:54,200 --> 00:14:58,097
Sembrerebbe che nell&#39;insondabilmente ampio spazio di 13.000 dimensioni dei

231
00:14:58,097 --> 00:15:01,995
possibili pesi e pregiudizi, la nostra rete si sia trovata un piccolo e felice

232
00:15:01,995 --> 00:15:05,892
minimo locale che, nonostante abbia classificato con successo la maggior parte

233
00:15:05,892 --> 00:15:09,840
delle immagini, non riprende esattamente gli schemi che avremmo potuto sperare.

234
00:15:09,840 --> 00:15:12,195
E per chiarire davvero questo punto, guarda cosa

235
00:15:12,195 --> 00:15:14,600
succede quando inserisci un&#39;immagine casuale.

236
00:15:14,600 --> 00:15:19,604
Se il sistema fosse intelligente, potresti aspettarti che si senta incerto, magari non

237
00:15:19,604 --> 00:15:24,493
attivando realmente nessuno di quei 10 neuroni in uscita o attivandoli tutti in modo

238
00:15:24,493 --> 00:15:29,325
uniforme, ma invece ti dà con sicurezza qualche risposta senza senso, come se fosse

239
00:15:29,325 --> 00:15:34,214
sicuro che questo casuale il rumore è un 5 così come un&#39;immagine reale di un 5 è

240
00:15:34,214 --> 00:15:34,560
un 5.

241
00:15:34,560 --> 00:15:38,358
In altre parole, anche se questa rete è in grado di riconoscere

242
00:15:38,358 --> 00:15:41,800
le cifre abbastanza bene, non ha idea di come disegnarle.

243
00:15:41,800 --> 00:15:43,430
In gran parte ciò è dovuto al fatto che si tratta di

244
00:15:43,430 --> 00:15:45,400
un&#39;impostazione di allenamento così strettamente vincolata.

245
00:15:45,400 --> 00:15:48,220
Voglio dire, mettiti nei panni della rete qui.

246
00:15:48,220 --> 00:15:52,553
Dal suo punto di vista, l’intero universo non consiste altro che di cifre immobili

247
00:15:52,553 --> 00:15:57,095
chiaramente definite centrate in una minuscola griglia, e la sua funzione di costo non

248
00:15:57,095 --> 00:16:01,585
gli ha mai dato alcun incentivo ad essere altro che completamente fiduciosi nelle sue

249
00:16:01,585 --> 00:16:02,160
decisioni.

250
00:16:02,160 --> 00:16:04,699
Quindi, con questa come immagine di ciò che stanno realmente

251
00:16:04,699 --> 00:16:07,364
facendo i neuroni del secondo strato, potreste chiedervi perché

252
00:16:07,364 --> 00:16:10,320
introdurrei questa rete con la motivazione di cogliere bordi e schemi.

253
00:16:10,320 --> 00:16:13,040
Voglio dire, non è affatto quello che finisce per fare.

254
00:16:13,040 --> 00:16:15,470
Ebbene, questo non vuole essere il nostro obiettivo

255
00:16:15,470 --> 00:16:17,480
finale, ma piuttosto un punto di partenza.

256
00:16:17,480 --> 00:16:22,697
Francamente, questa è una tecnologia vecchia, del tipo studiato negli anni &#39;80 e

257
00:16:22,697 --> 00:16:27,915
&#39;90, e devi capirla prima di poter comprendere varianti moderne più dettagliate,

258
00:16:27,915 --> 00:16:33,440
ed è chiaramente in grado di risolvere alcuni problemi interessanti, ma più approfondisci

259
00:16:33,440 --> 00:16:38,720
cosa quegli strati nascosti stanno davvero facendo, tanto meno intelligenti sembrano.

260
00:16:38,720 --> 00:16:42,816
Spostando per un momento l&#39;attenzione da come le reti apprendono a come impari

261
00:16:42,816 --> 00:16:47,160
tu, ciò accadrà solo se ti impegnerai attivamente con il materiale qui in qualche modo.

262
00:16:47,160 --> 00:16:50,840
Una cosa piuttosto semplice che voglio che tu faccia è semplicemente

263
00:16:50,840 --> 00:16:54,733
fermarti adesso e pensare profondamente per un momento a quali modifiche

264
00:16:54,733 --> 00:16:58,306
potresti apportare a questo sistema e al modo in cui percepisce le

265
00:16:58,306 --> 00:17:01,880
immagini se volessi che rilevasse meglio cose come bordi e motivi.

266
00:17:01,880 --> 00:17:05,824
Ma meglio di così, per interagire davvero con il materiale, consiglio vivamente

267
00:17:05,824 --> 00:17:09,720
il libro di Michael Nielsen sull&#39;apprendimento profondo e le reti neurali.

268
00:17:09,720 --> 00:17:14,369
In esso puoi trovare il codice e i dati da scaricare e con cui giocare per questo

269
00:17:14,369 --> 00:17:19,360
esatto esempio, e il libro ti guiderà passo dopo passo su cosa sta facendo quel codice.

270
00:17:19,360 --> 00:17:22,062
La cosa fantastica è che questo libro è gratuito e disponibile al

271
00:17:22,062 --> 00:17:25,092
pubblico, quindi se ne trai qualcosa, prendi in considerazione l&#39;idea

272
00:17:25,092 --> 00:17:28,040
di unirti a me per fare una donazione a favore degli sforzi di Nielsen.

273
00:17:28,040 --> 00:17:33,288
Ho anche collegato un paio di altre risorse che mi piacciono molto nella descrizione,

274
00:17:33,288 --> 00:17:38,720
incluso il fenomenale e bellissimo post sul blog di Chris Ola e gli articoli in Distill.

275
00:17:38,720 --> 00:17:41,604
Per chiudere qui per gli ultimi minuti, voglio tornare a un

276
00:17:41,604 --> 00:17:44,440
frammento dell&#39;intervista che ho avuto con Leisha Lee.

277
00:17:44,440 --> 00:17:46,335
Potresti ricordarla dall&#39;ultimo video, ha

278
00:17:46,335 --> 00:17:48,520
svolto il suo dottorato di ricerca in deep learning.

279
00:17:48,520 --> 00:17:51,020
In questo piccolo frammento, parla di due articoli recenti che

280
00:17:51,020 --> 00:17:53,561
approfondiscono davvero il modo in cui alcune delle più moderne

281
00:17:53,561 --> 00:17:56,380
reti di riconoscimento delle immagini stanno effettivamente imparando.

282
00:17:56,380 --> 00:17:59,674
Giusto per stabilire a che punto eravamo nella conversazione, il primo articolo ha

283
00:17:59,674 --> 00:18:02,929
preso una di queste reti neurali particolarmente profonde che è davvero brava nel

284
00:18:02,929 --> 00:18:06,422
riconoscimento delle immagini, e invece di addestrarla su un set di dati opportunamente

285
00:18:06,422 --> 00:18:09,400
etichettato, ha mescolato tutte le etichette prima dell&#39;addestramento.

286
00:18:09,400 --> 00:18:12,338
Ovviamente la precisione del test qui non sarebbe stata migliore di

287
00:18:12,338 --> 00:18:15,320
quella casuale, dal momento che tutto è etichettato in modo casuale.

288
00:18:15,320 --> 00:18:18,121
Ma è stato comunque in grado di ottenere la stessa precisione di

289
00:18:18,121 --> 00:18:21,440
addestramento che si otterrebbe su un set di dati correttamente etichettato.

290
00:18:21,440 --> 00:18:25,508
Fondamentalmente, i milioni di pesi per questa particolare rete erano sufficienti

291
00:18:25,508 --> 00:18:29,328
per memorizzare semplicemente i dati casuali, il che solleva la questione se

292
00:18:29,328 --> 00:18:33,098
minimizzare questa funzione di costo corrisponda effettivamente a qualsiasi

293
00:18:33,098 --> 00:18:36,720
tipo di struttura nell&#39;immagine, o si tratti solo di memorizzazione?

294
00:18:36,720 --> 00:18:40,120
. . . per memorizzare l&#39;intero set di dati di quale sia la classificazione corretta.

295
00:18:40,120 --> 00:18:43,718
E così un paio di, sei mesi dopo, all&#39;ICML di quest&#39;anno, non c&#39;era

296
00:18:43,718 --> 00:18:47,676
esattamente un documento di confutazione, ma un documento che affrontava alcuni aspetti

297
00:18:47,676 --> 00:18:51,230
del tipo, ehi, in realtà queste reti stanno facendo qualcosa di un po&#39; più

298
00:18:51,230 --> 00:18:52,220
intelligente di così.

299
00:18:52,220 --> 00:18:58,608
Se guardi quella curva di precisione, se ti stessi allenando su un set di dati

300
00:18:58,608 --> 00:19:05,240
casuale, quella curva è scesa molto, sai, molto lentamente in modo quasi lineare.

301
00:19:05,240 --> 00:19:08,520
Quindi stai davvero lottando per trovare i minimi locali

302
00:19:08,520 --> 00:19:12,320
possibili, sai, i pesi giusti che ti darebbero quella precisione.

303
00:19:12,320 --> 00:19:16,000
Mentre se ti stai effettivamente allenando su un set di dati strutturato,

304
00:19:16,000 --> 00:19:19,630
uno che ha le etichette giuste, sai, all&#39;inizio giocheri un po&#39;,

305
00:19:19,630 --> 00:19:23,360
ma poi scendi molto velocemente per arrivare a quel livello di precisione.

306
00:19:23,360 --> 00:19:28,580
E quindi in un certo senso è stato più facile trovare i massimi locali.

307
00:19:28,580 --> 00:19:34,360
E quindi la cosa interessante è che porta alla luce un altro documento di un

308
00:19:34,360 --> 00:19:40,140
paio di anni fa, che contiene molte più semplificazioni sui livelli di rete.

309
00:19:40,140 --> 00:19:44,714
Ma uno dei risultati è stato che, se si guarda al panorama dell’ottimizzazione, i

310
00:19:44,714 --> 00:19:49,400
minimi locali che queste reti tendono ad apprendere sono in realtà di pari qualità.

311
00:19:49,400 --> 00:19:51,949
Quindi, in un certo senso, se il tuo set di dati è strutturato,

312
00:19:51,949 --> 00:19:54,300
dovresti essere in grado di trovarlo molto più facilmente.

313
00:19:54,300 --> 00:20:01,140
I miei ringraziamenti come sempre a quelli di voi che sostengono su Patreon.

314
00:20:01,140 --> 00:20:04,099
Ho già detto in precedenza quale sia la svolta su Patreon,

315
00:20:04,099 --> 00:20:07,160
ma questi video non sarebbero davvero possibili senza di te.

316
00:20:07,160 --> 00:20:10,200
Voglio anche ringraziare in modo speciale la società di VC Amplify

317
00:20:10,200 --> 00:20:13,240
Partners e il loro supporto per questi video iniziali della serie.

318
00:20:13,240 --> 00:20:33,140
Grazie.

