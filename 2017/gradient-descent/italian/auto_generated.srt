1
00:00:04,180 --> 00:00:07,280
Nell'ultimo video ho presentato la struttura di una rete neurale.

2
00:00:07,680 --> 00:00:10,269
Farò un breve riepilogo in modo da averlo fresco. 

3
00:00:10,269 --> 00:00:12,600
Ho due obiettivi principali per questo video.

4
00:00:13,100 --> 00:00:15,426
Il primo è introdurre l’idea della discesa del gradiente, 

5
00:00:15,426 --> 00:00:18,193
che è alla base non solo del modo in cui le reti neurali apprendono, 

6
00:00:18,193 --> 00:00:20,600
ma anche di molti altri sistemi di apprendimento automatico.

7
00:00:21,120 --> 00:00:24,650
Dopo approfondiremo un po' di più il funzionamento di questa particolare 

8
00:00:24,650 --> 00:00:27,940
rete e cosa finiscono per cercare quegli strati nascosti di neuroni.

9
00:00:28,980 --> 00:00:32,298
Come promemoria, il nostro obiettivo qui è il classico esempio di 

10
00:00:32,298 --> 00:00:36,220
riconoscimento delle cifre scritte a mano, l'ABC del mondo delle reti neurali.

11
00:00:37,020 --> 00:00:40,195
Queste cifre vengono visualizzate su una griglia di 28x28 pixel, 

12
00:00:40,195 --> 00:00:43,420
ciascun pixel con un valore in scala di grigio compreso tra 0 e 1.

13
00:00:43,820 --> 00:00:46,863
Questi sono ciò che determinano l'attivazione 

14
00:00:46,863 --> 00:00:50,040
di 784 neuroni nello strato di input della rete.

15
00:00:51,180 --> 00:00:55,678
E poi l'attivazione di ciascun neurone negli strati successivi si basa su una somma 

16
00:00:55,678 --> 00:00:58,838
ponderata di tutte le attivazioni nello strato precedente, 

17
00:00:58,838 --> 00:01:00,820
più un numero speciale chiamato bias.

18
00:01:02,160 --> 00:01:05,461
Poi si compone quella somma con qualche altra funzione, 

19
00:01:05,461 --> 00:01:08,940
come la sigmoide, o una ReLU, come visto nell'ultimo video.

20
00:01:09,480 --> 00:01:14,253
In totale, data la scelta un po' arbitraria di due strati nascosti con 16 

21
00:01:14,253 --> 00:01:19,219
neuroni ciascuno, la rete ha circa 13.000 pesi e bias che possiamo regolare, 

22
00:01:19,219 --> 00:01:24,380
e sono questi valori che determinano esattamente cosa fa effettivamente la rete.

23
00:01:24,880 --> 00:01:29,140
Quindi ciò che intendiamo quando diciamo che questa rete classifica una cifra è che 

24
00:01:29,140 --> 00:01:33,300
il più luminoso di quei 10 neuroni nello strato finale corrisponde a quella cifra.

25
00:01:34,100 --> 00:01:37,710
E ricorda, la motivazione che avevamo in mente qui per la struttura a 

26
00:01:37,710 --> 00:01:41,011
strati era che forse il secondo strato poteva rilevare i bordi, 

27
00:01:41,011 --> 00:01:44,364
e il terzo strato poteva riprendere modelli come anelli e linee, 

28
00:01:44,364 --> 00:01:48,800
e l'ultimo poteva semplicemente mettere insieme quei modelli per riconoscere le cifre.

29
00:01:49,800 --> 00:01:52,240
Quindi, ora impariamo come apprende la rete.

30
00:01:52,640 --> 00:01:56,903
Quello che vogliamo è un algoritmo che mostra a questa rete un sacco di dati di 

31
00:01:56,903 --> 00:02:01,486
addestramento, nella forma di un mucchio di immagini diverse di cifre scritte a mano, 

32
00:02:01,486 --> 00:02:04,470
insieme alle etichette di quello che dovrebbero essere, 

33
00:02:04,470 --> 00:02:08,840
e che aggiusta questi 13.000 pesi e bias in modo da migliorare le sue prestazioni 

34
00:02:08,840 --> 00:02:10,120
sui dati di allenamento.

35
00:02:10,720 --> 00:02:13,711
Si spera che questa struttura a strati apprenda qualcosa 

36
00:02:13,711 --> 00:02:16,860
che si generalizzi a immagini oltre i dati di addestramento.

37
00:02:17,640 --> 00:02:20,920
Il modo in cui la testiamo è che dopo aver addestrato la rete, 

38
00:02:20,920 --> 00:02:25,190
le si mostra più dati etichettati mai visti prima e si vede con quanta precisione 

39
00:02:25,190 --> 00:02:26,700
classifica le nuove immagini.

40
00:02:31,120 --> 00:02:35,327
Fortunatamente per noi, e ciò che rende questo esempio così comune per cominciare, 

41
00:02:35,327 --> 00:02:39,687
è che le brave persone dietro il dataset MNIST hanno messo insieme decine di migliaia 

42
00:02:39,687 --> 00:02:44,200
di immagini scritte a mano, ognuna etichettata con i numeri che dovrebbero rappresentare.

43
00:02:44,900 --> 00:02:49,046
E per quanto provocatorio sia parlare di una macchina in grado di apprendere, 

44
00:02:49,046 --> 00:02:52,662
una volta visto come funziona, sembra molto meno una folle premessa 

45
00:02:52,662 --> 00:02:55,480
fantascientifica e molto più un esercizio di calcolo.

46
00:02:56,200 --> 00:02:59,960
Voglio dire, fondamentalmente si tratta di trovare il minimo di una certa funzione.

47
00:03:01,940 --> 00:03:06,075
Ricorda, concettualmente, pensiamo che ciascun neurone sia connesso a tutti i 

48
00:03:06,075 --> 00:03:10,370
neuroni dello strato precedente, e i pesi nella somma ponderata che definisce la 

49
00:03:10,370 --> 00:03:14,241
sua attivazione sono un po' come i punti di forza di quelle connessioni, 

50
00:03:14,241 --> 00:03:18,960
e il bias è una qualche indicazione di se quel neurone tende ad essere attivo o inattivo.

51
00:03:19,720 --> 00:03:24,400
E per iniziare, inizializzeremo tutti questi pesi e bias in modo totalmente casuale.

52
00:03:24,940 --> 00:03:28,575
Inutile dire che questa rete funzionerà male su un campione di addestramento, 

53
00:03:28,575 --> 00:03:30,720
sta semplicemente facendo qualcosa di casuale.

54
00:03:31,040 --> 00:03:33,554
Ad esempio, se inserisci questa immagine di un 3 il 

55
00:03:33,554 --> 00:03:36,020
livello di output sembra semplicemente un disastro.

56
00:03:36,600 --> 00:03:41,471
Quindi quello che fai è definire una funzione di costo, un modo per dire al computer, 

57
00:03:41,471 --> 00:03:46,228
no, cattivo computer, l'output dovrebbe avere attivazioni che sono 0 per la maggior 

58
00:03:46,228 --> 00:03:50,760
parte dei neuroni, ma 1 per questo neurone, quello che mi hai dato è spazzatura.

59
00:03:51,720 --> 00:03:55,973
Per dirlo in modo un po' più matematico, sommi i quadrati delle differenze tra 

60
00:03:55,973 --> 00:04:00,658
ciascuna di quelle attivazioni di output dei rifiuti e il valore che vuoi che abbiano, 

61
00:04:00,658 --> 00:04:05,020
e questo è quello che chiameremo il costo di un singolo esempio di addestramento.

62
00:04:05,960 --> 00:04:11,336
Si noti che questa somma è piccola quando la rete classifica correttamente l'immagine 

63
00:04:11,336 --> 00:04:16,399
con sicurezza, ma è grande quando sembra che la rete non sappia cosa sta facendo.

64
00:04:18,640 --> 00:04:21,986
Quindi quello che fai è considerare il costo medio di tutte le 

65
00:04:21,986 --> 00:04:25,440
decine di migliaia di esempi di addestramento a tua disposizione.

66
00:04:27,040 --> 00:04:29,938
Questo costo medio è la nostra misura di quanto sia pessima 

67
00:04:29,938 --> 00:04:32,740
la rete e di quanto dovrebbe sentirsi pessimo il computer.

68
00:04:33,420 --> 00:04:34,600
E questa è una cosa complicata.

69
00:04:35,040 --> 00:04:38,935
Ricordi che la rete stessa era fondamentalmente una funzione, 

70
00:04:38,935 --> 00:04:42,391
che accetta 784 numeri come input, i valori dei pixel, 

71
00:04:42,391 --> 00:04:47,040
e restituisce 10 numeri come output, e in un certo senso è parametrizzata 

72
00:04:47,040 --> 00:04:48,800
da tutti questi pesi e bias?

73
00:04:49,500 --> 00:04:52,820
Ebbene, la funzione di costo è uno livello di complessità in più.

74
00:04:53,100 --> 00:04:58,620
Prende come input quei circa 13.000 pesi e bias e sputa un singolo numero che descrive 

75
00:04:58,620 --> 00:05:03,760
quanto siano gravi tali pesi e bias, e il modo in cui viene definito dipende dal 

76
00:05:03,760 --> 00:05:08,900
comportamento della rete su tutte le decine di migliaia di dati di addestramento.

77
00:05:09,520 --> 00:05:11,000
C'è molto a cui pensare.

78
00:05:12,400 --> 00:05:15,820
Ma limitarsi a insultare il computer non è molto utile.

79
00:05:16,220 --> 00:05:20,060
Vuoi dirgli come cambiare quei pesi e bias in modo che migliori.

80
00:05:20,780 --> 00:05:25,685
Per renderla più semplice, anziché faticare a immaginare una funzione con 13.000 input, 

81
00:05:25,685 --> 00:05:30,480
immagina una semplice funzione che abbia un numero come input e un numero come output.

82
00:05:31,480 --> 00:05:35,300
Come trovi un input che minimizzi il valore di questa funzione?

83
00:05:36,460 --> 00:05:40,034
Gli studenti di analisi sapranno che a volte è possibile calcolare 

84
00:05:40,034 --> 00:05:44,463
esplicitamente quel minimo, ma ciò non è sempre fattibile per funzioni complicate, 

85
00:05:44,463 --> 00:05:48,038
certamente non nella versione da 13.000 input di questa situazione 

86
00:05:48,038 --> 00:05:51,080
per la nostra folle funzione di costo della rete neurale.

87
00:05:51,580 --> 00:05:55,390
Una tattica più flessibile è quella di iniziare da qualsiasi input e 

88
00:05:55,390 --> 00:05:59,200
capire in quale direzione dovresti procedere per ridurre tale output.

89
00:06:00,080 --> 00:06:03,473
Nello specifico, se riesci a calcolare la pendenza della funzione 

90
00:06:03,473 --> 00:06:06,660
nel punto in cui ti trovi, spostati a sinistra se la pendenza 

91
00:06:06,660 --> 00:06:09,900
è positiva e sposta l'input a destra se la pendenza è negativa.

92
00:06:11,960 --> 00:06:15,692
Se lo fai ripetutamente, controllando in ogni punto la nuova pendenza e 

93
00:06:15,692 --> 00:06:19,840
facendo il passo appropriato, ti avvicinerai ad un minimo locale della funzione.

94
00:06:20,640 --> 00:06:23,800
L'immagine da avere in mente qui è una palla che rotola giù da una collina.

95
00:06:24,620 --> 00:06:27,511
Nota, anche per questa funzione davvero semplificata, 

96
00:06:27,511 --> 00:06:30,564
ci sono molte possibili valli in cui potresti atterrare, 

97
00:06:30,564 --> 00:06:34,259
a seconda dell'input casuale da cui inizi, e non c'è alcuna garanzia 

98
00:06:34,259 --> 00:06:38,114
che il minimo locale in cui arrivi sarà il valore più piccolo possibile 

99
00:06:38,114 --> 00:06:39,400
della funzione di costo.

100
00:06:40,220 --> 00:06:42,620
Ciò si ripercuoterà anche sul caso della nostra rete neurale.

101
00:06:43,180 --> 00:06:47,697
Voglio anche che noti come se rendi le dimensioni dei passi proporzionali alla pendenza, 

102
00:06:47,697 --> 00:06:50,285
quando la pendenza si appiattisce verso il minimo, 

103
00:06:50,285 --> 00:06:54,600
i tuoi passi diventano sempre più piccoli e questo ti aiuta a non superare il limite.

104
00:06:55,940 --> 00:07:00,980
Aumentando un po' la complessità, immagina invece una funzione con due input e un output.

105
00:07:01,500 --> 00:07:04,733
Potresti pensare allo spazio di input come al piano x y 

106
00:07:04,733 --> 00:07:08,140
e alla funzione di costo come una superficie sopra di esso.

107
00:07:08,760 --> 00:07:11,941
Invece di chiedere informazioni sulla pendenza della funzione, 

108
00:07:11,941 --> 00:07:15,425
devi chiederti in quale direzione dovresti muoverti in questo spazio 

109
00:07:15,425 --> 00:07:18,960
di input in modo da diminuire più rapidamente l'output della funzione.

110
00:07:19,720 --> 00:07:21,760
In altre parole, qual è la direzione di discesa?

111
00:07:22,380 --> 00:07:25,560
Ancora, è utile pensare a una palla che rotola giù da quella collina.

112
00:07:26,660 --> 00:07:30,626
Quelli di voi che hanno familiarità con l'analisi multivariata sapranno 

113
00:07:30,626 --> 00:07:34,813
che il gradiente di una funzione ti dà la direzione dell'ascesa più ripida, 

114
00:07:34,813 --> 00:07:38,780
quale direzione dovresti fare per aumentare la funzione più rapidamente.

115
00:07:39,560 --> 00:07:42,724
Naturalmente, prendendo l'opposto di quel gradiente si ottiene 

116
00:07:42,724 --> 00:07:46,040
la direzione del passo che diminuisce la funzione più rapidamente.

117
00:07:47,240 --> 00:07:50,539
Ancor di più, la lunghezza di questo vettore gradiente è 

118
00:07:50,539 --> 00:07:53,840
un'indicazione di quanto sia ripido il pendio più ripido.

119
00:07:54,540 --> 00:07:57,232
Se non hai familiarità con il calcolo multivariato, 

120
00:07:57,232 --> 00:08:00,340
dai un'occhiata a dei lavori che ho svolto per Khan Academy.

121
00:08:00,860 --> 00:08:04,455
Onestamente, però, tutto ciò che conta per me e te in questo momento è 

122
00:08:04,455 --> 00:08:08,051
che in linea di principio esiste un modo per calcolare questo vettore, 

123
00:08:08,051 --> 00:08:11,900
questo vettore che ti dice qual è la direzione in discesa e quanto è ripida.

124
00:08:12,400 --> 00:08:16,120
Sei a posto se questo è tutto quello che sai.

125
00:08:17,200 --> 00:08:20,362
Se riesci a capirlo, l'algoritmo per minimizzare la funzione 

126
00:08:20,362 --> 00:08:23,214
consiste nel calcolare questa direzione del gradiente, 

127
00:08:23,214 --> 00:08:26,740
quindi fare un piccolo passo in discesa e ripeterlo ancora e ancora.

128
00:08:27,700 --> 00:08:32,820
È la stessa idea di base per una funzione che ha 13.000 input invece di 2 input.

129
00:08:33,400 --> 00:08:36,343
Immagina di organizzare tutti i 13.000 pesi e bias 

130
00:08:36,343 --> 00:08:39,460
della nostra rete in un gigantesco vettore di colonne.

131
00:08:40,140 --> 00:08:44,307
L'opposto del gradiente della funzione di costo è solo un vettore, 

132
00:08:44,307 --> 00:08:49,220
è una direzione all'interno di questo spazio di input enorme che ti dice quali 

133
00:08:49,220 --> 00:08:54,320
modifiche a tutti quei numeri causeranno la diminuzione più rapida della funzione 

134
00:08:54,320 --> 00:08:54,880
di costo.

135
00:08:55,640 --> 00:08:59,585
E ovviamente, con la nostra funzione di costo appositamente progettata, 

136
00:08:59,585 --> 00:09:03,312
modificare i pesi e i bias per ridurli significa fa sì che l'output 

137
00:09:03,312 --> 00:09:07,148
della rete su ciascun dato di addestramento assomigli meno a un array 

138
00:09:07,148 --> 00:09:10,820
casuale di 10 valori e più a una decisione che vogliamo che prenda.

139
00:09:11,440 --> 00:09:14,636
È importante ricordare che questa funzione di costo include una 

140
00:09:14,636 --> 00:09:18,183
media su tutti i dati di addestramento, quindi se la riduci al minimo, 

141
00:09:18,183 --> 00:09:21,180
significa che è una prestazione migliore su tutti quei dati.

142
00:09:23,820 --> 00:09:26,973
L'algoritmo per calcolare questo gradiente in modo efficiente, 

143
00:09:26,973 --> 00:09:30,476
che è effettivamente il cuore dell'apprendimento di una rete neurale, 

144
00:09:30,476 --> 00:09:33,980
si chiama backpropagation, ed è ciò di cui parlerò nel prossimo video.

145
00:09:34,660 --> 00:09:38,754
Lì, voglio davvero prendermi il tempo per esaminare cosa succede esattamente a 

146
00:09:38,754 --> 00:09:41,605
ciascun peso e bias per un dato dato di addestramento, 

147
00:09:41,605 --> 00:09:45,596
cercando di dare un'idea intuitiva di ciò che sta accadendo oltre la pila di 

148
00:09:45,596 --> 00:09:47,100
calcoli e formule pertinenti.

149
00:09:47,780 --> 00:09:50,821
Proprio qui, proprio ora, la cosa principale che voglio che tu sappia, 

150
00:09:50,821 --> 00:09:53,005
indipendentemente dai dettagli di implementazione, 

151
00:09:53,005 --> 00:09:56,261
è che ciò che intendiamo quando parliamo di apprendimento in rete è che sta 

152
00:09:56,261 --> 00:09:58,360
semplicemente minimizzando una funzione di costo.

153
00:09:59,300 --> 00:10:02,114
E notate, una conseguenza di ciò è che è importante che questa 

154
00:10:02,114 --> 00:10:04,571
funzione di costo abbia un output abbastanza regolare, 

155
00:10:04,571 --> 00:10:08,100
in modo da poter trovare un minimo locale facendo piccoli passi verso il basso.

156
00:10:09,260 --> 00:10:12,585
Questo è il motivo per cui, tra l’altro, i neuroni artificiali hanno 

157
00:10:12,585 --> 00:10:15,862
attivazioni che variano continuamente, anziché essere semplicemente 

158
00:10:15,862 --> 00:10:19,140
attivi o inattivi in modo binario, come lo sono i neuroni biologici.

159
00:10:20,220 --> 00:10:23,537
Questo processo di spostamento ripetuto dell'input di una funzione di 

160
00:10:23,537 --> 00:10:26,760
un multiplo del gradiente negativo è chiamato discesa del gradiente.

161
00:10:27,300 --> 00:10:30,611
È un modo per convergere verso un minimo locale di una funzione di costo, 

162
00:10:30,611 --> 00:10:32,580
sostanzialmente una valle in questo grafico.

163
00:10:33,440 --> 00:10:37,162
Sto ancora mostrando l'immagine di una funzione con due input, ovviamente, 

164
00:10:37,162 --> 00:10:40,636
perché i nudge in uno spazio di input a 13.000 dimensioni sono un po' 

165
00:10:40,636 --> 00:10:44,260
difficili da comprendere, ma esiste un bel modo non spaziale di pensarci.

166
00:10:45,080 --> 00:10:48,440
Ogni componente del gradiente negativo ci dice due cose.

167
00:10:49,060 --> 00:10:52,054
Il segno, ovviamente, ci dice se la componente corrispondente del 

168
00:10:52,054 --> 00:10:55,140
vettore di input deve essere spostata verso l'alto o verso il basso.

169
00:10:55,800 --> 00:10:59,289
Ma, cosa ancora più importante, l’entità relativa di tutti 

170
00:10:59,289 --> 00:11:02,720
questi componenti indica quali cambiamenti contano di più.

171
00:11:05,220 --> 00:11:09,084
Vedete, nella nostra rete, un aggiustamento a uno dei pesi potrebbe avere un impatto 

172
00:11:09,084 --> 00:11:13,040
molto maggiore sulla funzione di costo rispetto all'aggiustamento a qualche altro peso.

173
00:11:14,800 --> 00:11:18,200
Alcune di queste connessioni contano di più per i nostri dati di addestramento.

174
00:11:19,320 --> 00:11:23,512
Quindi un modo in cui puoi pensare a questo vettore gradiente della nostra 

175
00:11:23,512 --> 00:11:28,151
enorme funzione di costo è che codifica l'importanza relativa di ogni peso e bias, 

176
00:11:28,151 --> 00:11:32,400
cioè quale di questi cambiamenti porterà il maggior rapporto qualità-prezzo.

177
00:11:33,620 --> 00:11:36,640
Questo è davvero solo un altro modo di pensare alla direzione.

178
00:11:37,100 --> 00:11:41,275
Per fare un esempio più semplice, se hai una funzione con due variabili come 

179
00:11:41,275 --> 00:11:45,558
input e calcoli che il suo gradiente in un punto particolare risulta come 3,1, 

180
00:11:45,558 --> 00:11:49,788
allora da un lato puoi interpretarlo come se dicessi che quando tu' Stando su 

181
00:11:49,788 --> 00:11:54,343
quell'input, muovendoti lungo questa direzione la funzione aumenta più rapidamente, 

182
00:11:54,343 --> 00:11:59,006
ovvero quando rappresenti graficamente la funzione sopra il piano dei punti di input, 

183
00:11:59,006 --> 00:12:02,260
quel vettore è ciò che ti dà la direzione diritta in salita.

184
00:12:02,860 --> 00:12:07,540
Ma un altro modo di leggerlo è dire che le modifiche a questa prima variabile hanno 3 

185
00:12:07,540 --> 00:12:10,750
volte l'importanza delle modifiche alla seconda variabile, 

186
00:12:10,750 --> 00:12:13,417
che almeno nelle vicinanze dell'input rilevante, 

187
00:12:13,417 --> 00:12:16,900
spostare il valore x porta molto più effetto per il tuo secchio.

188
00:12:19,880 --> 00:12:22,340
Riduciamo lo zoom e riassumiamo dove siamo finora.

189
00:12:22,840 --> 00:12:26,784
La rete stessa è questa funzione con 784 ingressi e 10 uscite, 

190
00:12:26,784 --> 00:12:30,040
definite in termini di tutte queste somme ponderate.

191
00:12:30,640 --> 00:12:33,680
La funzione di costo è uno strato di complessità in più.

192
00:12:33,980 --> 00:12:37,850
Prende i 13.000 pesi e bias come input e produce un'unica 

193
00:12:37,850 --> 00:12:41,720
misura di pessimazza basata sugli esempi di addestramento.

194
00:12:42,440 --> 00:12:44,859
E il gradiente della funzione di costo rappresenta 

195
00:12:44,859 --> 00:12:46,900
ancora un ulteriore livello di complessità.

196
00:12:47,360 --> 00:12:51,094
Ci dice quali spinte a tutti questi pesi e bias causano il cambiamento 

197
00:12:51,094 --> 00:12:53,566
più rapido nel valore della funzione di costo, 

198
00:12:53,566 --> 00:12:57,880
che potresti interpretare come dire quali cambiamenti a quali pesi contano di più.

199
00:13:02,560 --> 00:13:05,931
Quindi, quando inizializzi la rete con pesi e bias casuali e li 

200
00:13:05,931 --> 00:13:09,670
regoli molte volte in base a questo processo di discesa del gradiente, 

201
00:13:09,670 --> 00:13:13,200
quanto bene si comporta effettivamente su immagini mai viste prima?

202
00:13:14,100 --> 00:13:18,692
Quello che ho descritto qui, con i due strati nascosti di 16 neuroni ciascuno, 

203
00:13:18,692 --> 00:13:21,832
scelti soprattutto per ragioni estetiche, non è male, 

204
00:13:21,832 --> 00:13:25,960
classificando correttamente circa il 96% delle nuove immagini che vede.

205
00:13:26,680 --> 00:13:30,414
E onestamente, se guardi alcuni degli esempi in cui si incasina, 

206
00:13:30,414 --> 00:13:32,540
ti senti obbligato a darci un taglio.

207
00:13:36,220 --> 00:13:40,210
Ora, se giochi con la struttura dei livelli nascosti e apporti un paio di modifiche, 

208
00:13:40,210 --> 00:13:41,760
puoi ottenere questo fino al 98%.

209
00:13:41,760 --> 00:13:42,720
E questo è abbastanza buono!

210
00:13:43,020 --> 00:13:46,819
Non è il massimo, puoi sicuramente ottenere prestazioni migliori diventando 

211
00:13:46,819 --> 00:13:49,270
più sofisticato di questa semplice rete vanilla, 

212
00:13:49,270 --> 00:13:51,919
ma dato quanto sia scoraggiante il compito iniziale, 

213
00:13:51,919 --> 00:13:55,420
penso che ci sia qualcosa di incredibile nel fatto che qualsiasi rete 

214
00:13:55,420 --> 00:13:58,969
riesca così bene su immagini mai viste prima, dato che non gli abbiamo 

215
00:13:58,969 --> 00:14:01,420
mai detto specificatamente quali modelli cercare.

216
00:14:02,560 --> 00:14:06,170
Originariamente, il modo in cui ho motivato questa struttura era descrivendo una 

217
00:14:06,170 --> 00:14:09,825
speranza che potremmo avere, che il secondo strato potesse captare piccoli bordi, 

218
00:14:09,825 --> 00:14:13,525
che il terzo strato mettesse insieme quei bordi per riconoscere anelli e linee più 

219
00:14:13,525 --> 00:14:17,180
lunghe, e che questi potessero essere ricomposti insieme per riconoscere le cifre.

220
00:14:17,960 --> 00:14:20,400
Quindi è questo ciò che sta effettivamente facendo la nostra rete?

221
00:14:21,080 --> 00:14:24,400
Beh, almeno per questo, per niente.

222
00:14:24,820 --> 00:14:28,867
Ricordi come nell'ultimo video abbiamo visto come i pesi delle connessioni da tutti 

223
00:14:28,867 --> 00:14:32,674
i neuroni del primo strato a un dato neurone del secondo strato possono essere 

224
00:14:32,674 --> 00:14:36,578
visualizzati come un dato modello di pixel che il neurone del secondo strato sta 

225
00:14:36,578 --> 00:14:37,060
rilevando?

226
00:14:37,780 --> 00:14:43,080
Bene, quando lo facciamo effettivamente per i pesi associati a queste transizioni, 

227
00:14:43,080 --> 00:14:48,571
dal primo strato al successivo, invece di raccogliere piccoli bordi isolati qua e là, 

228
00:14:48,571 --> 00:14:53,680
sembrano, beh, quasi casuali, solo con alcuni schemi molto vaghi in il mezzo lì.

229
00:14:53,760 --> 00:14:57,485
Sembrerebbe che nell'insondabilmente ampio spazio di 13.000 dimensioni dei 

230
00:14:57,485 --> 00:15:01,111
possibili pesi e bias, la nostra rete si sia trovata un piccolo e felice 

231
00:15:01,111 --> 00:15:04,737
minimo locale che, nonostante abbia classificato con successo la maggior 

232
00:15:04,737 --> 00:15:08,960
parte delle immagini, non riprende esattamente gli schemi che avremmo potuto sperare.

233
00:15:09,780 --> 00:15:11,885
E per chiarire davvero questo punto, guarda cosa 

234
00:15:11,885 --> 00:15:13,820
succede quando inserisci un'immagine casuale.

235
00:15:14,320 --> 00:15:18,781
Se il sistema fosse intelligente, potresti aspettarti che si senta incerto, 

236
00:15:18,781 --> 00:15:23,594
magari non attivando realmente nessuno di quei 10 neuroni in uscita o attivandoli 

237
00:15:23,594 --> 00:15:28,524
tutti in modo uniforme, ma invece ti dà con sicurezza qualche risposta senza senso, 

238
00:15:28,524 --> 00:15:33,455
come se fosse sicuro che questo rumore casuale è un 5 così come l'immagine reale di 

239
00:15:33,455 --> 00:15:34,160
un 5 è un 5.

240
00:15:34,540 --> 00:15:39,121
In altre parole, anche se questa rete è in grado di riconoscere le cifre abbastanza bene, 

241
00:15:39,121 --> 00:15:40,700
non ha idea di come disegnarle.

242
00:15:41,420 --> 00:15:43,227
In gran parte ciò è dovuto al fatto che si tratta di 

243
00:15:43,227 --> 00:15:45,240
un'impostazione di allenamento così strettamente vincolata.

244
00:15:45,880 --> 00:15:47,740
Voglio dire, mettiti nei panni della rete qui.

245
00:15:48,140 --> 00:15:52,177
Dal suo punto di vista, l’intero universo non consiste altro che di cifre immobili 

246
00:15:52,177 --> 00:15:54,901
chiaramente definite centrate in una minuscola griglia, 

247
00:15:54,901 --> 00:15:58,939
e la sua funzione di costo non gli ha mai dato alcun incentivo ad essere altro che 

248
00:15:58,939 --> 00:16:01,080
completamente fiduciosi nelle sue decisioni.

249
00:16:02,120 --> 00:16:04,560
Quindi, con questa come immagine di ciò che stanno realmente 

250
00:16:04,560 --> 00:16:07,119
facendo i neuroni del secondo strato, potreste chiedervi perché 

251
00:16:07,119 --> 00:16:09,920
introdurrei questa rete con la motivazione di cogliere bordi e schemi.

252
00:16:09,920 --> 00:16:12,300
Voglio dire, non è affatto quello che finisce per fare.

253
00:16:13,380 --> 00:16:15,805
Ebbene, questo non vuole essere il nostro obiettivo finale, 

254
00:16:15,805 --> 00:16:17,180
ma piuttosto un punto di partenza.

255
00:16:17,640 --> 00:16:22,003
Francamente, questa è una tecnologia vecchia, del tipo studiato negli anni '80 e '90, 

256
00:16:22,003 --> 00:16:25,860
e devi capirla prima di poter comprendere varianti moderne più dettagliate, 

257
00:16:25,860 --> 00:16:29,361
ed è chiaramente in grado di risolvere alcuni problemi interessanti, 

258
00:16:29,361 --> 00:16:33,065
ma più approfondisci cosa quegli strati nascosti stanno davvero facendo, 

259
00:16:33,065 --> 00:16:34,740
tanto meno intelligenti sembrano.

260
00:16:38,480 --> 00:16:42,390
Spostando per un momento l'attenzione da come le reti apprendono a come impari tu, 

261
00:16:42,390 --> 00:16:46,300
ciò accadrà solo se ti impegnerai attivamente con il materiale qui in qualche modo.

262
00:16:47,060 --> 00:16:50,527
Una cosa piuttosto semplice che voglio che tu faccia è semplicemente 

263
00:16:50,527 --> 00:16:53,693
fermarti adesso e pensare profondamente per un momento a quali 

264
00:16:53,693 --> 00:16:56,859
modifiche potresti apportare a questo sistema e al modo in cui 

265
00:16:56,859 --> 00:17:00,880
percepisce le immagini se volessi che rilevasse meglio cose come bordi e motivi.

266
00:17:01,480 --> 00:17:04,448
Ma meglio di così, per interagire davvero con il materiale, 

267
00:17:04,448 --> 00:17:08,209
consiglio vivamente il libro di Michael Nielsen sull'apprendimento profondo 

268
00:17:08,209 --> 00:17:09,099
e le reti neurali.

269
00:17:09,680 --> 00:17:13,891
In esso puoi trovare il codice e i dati da scaricare e con cui giocare per questo 

270
00:17:13,891 --> 00:17:18,359
esatto esempio, e il libro ti guiderà passo dopo passo su cosa sta facendo quel codice.

271
00:17:19,300 --> 00:17:22,369
La cosa fantastica è che questo libro è gratuito e disponibile al pubblico, 

272
00:17:22,369 --> 00:17:25,196
quindi se ne trai qualcosa, prendi in considerazione l'idea di unirti 

273
00:17:25,196 --> 00:17:27,660
a me per fare una donazione a favore degli sforzi di Nielsen.

274
00:17:27,660 --> 00:17:32,029
Ho anche collegato un paio di altre risorse che mi piacciono molto nella descrizione, 

275
00:17:32,029 --> 00:17:36,500
incluso il fenomenale e bellissimo post sul blog di Chris Ola e gli articoli in Distill.

276
00:17:38,280 --> 00:17:41,080
Per chiudere qui per gli ultimi minuti, voglio tornare a 

277
00:17:41,080 --> 00:17:43,880
un frammento dell'intervista che ho avuto con Leisha Lee.

278
00:17:44,300 --> 00:17:46,082
Potresti ricordarla dall'ultimo video, ha svolto 

279
00:17:46,082 --> 00:17:47,720
il suo dottorato di ricerca in deep learning.

280
00:17:48,300 --> 00:17:50,666
In questo piccolo frammento parla di due articoli recenti che 

281
00:17:50,666 --> 00:17:53,108
approfondiscono davvero il modo in cui alcune delle più moderne 

282
00:17:53,108 --> 00:17:55,780
reti di riconoscimento delle immagini stanno effettivamente imparando.

283
00:17:56,120 --> 00:17:58,667
Giusto per stabilire il punto in cui eravamo nella conversazione, 

284
00:17:58,667 --> 00:18:01,716
il primo articolo ha preso una di queste reti neurali particolarmente profonde 

285
00:18:01,716 --> 00:18:03,838
che è davvero brava nel riconoscimento delle immagini, 

286
00:18:03,838 --> 00:18:06,540
e invece di addestrarla su un set di dati opportunamente etichettato, 

287
00:18:06,540 --> 00:18:08,740
ha mescolato tutte le etichette prima dell'addestramento.

288
00:18:09,480 --> 00:18:12,737
Ovviamente la precisione del test qui non era migliore di quella casuale, 

289
00:18:12,737 --> 00:18:16,478
poiché tutto è etichettato in modo casuale, ma è stato comunque in grado di ottenere 

290
00:18:16,478 --> 00:18:20,351
la stessa precisione di addestramento che si otterrebbe su un set di dati correttamente 

291
00:18:20,351 --> 00:18:20,880
etichettato.

292
00:18:21,600 --> 00:18:25,019
Fondamentalmente, i milioni di pesi per questa particolare rete erano 

293
00:18:25,019 --> 00:18:27,852
sufficienti per memorizzare semplicemente i dati casuali, 

294
00:18:27,852 --> 00:18:31,759
il che solleva la questione se minimizzare questa funzione di costo corrisponda 

295
00:18:31,759 --> 00:18:34,690
effettivamente a qualsiasi tipo di struttura nell'immagine, 

296
00:18:34,690 --> 00:18:36,400
o si tratta solo di memorizzazione?

297
00:18:51,440 --> 00:18:58,088
Se guardi quella curva di precisione, se ti stessi allenando su un set di dati casuale, 

298
00:18:58,088 --> 00:19:02,772
quella curva scendeva molto lentamente in modo quasi lineare, 

299
00:19:02,772 --> 00:19:07,984
quindi fai davvero fatica a trovare quel minimo locale di possibile, 

300
00:19:07,984 --> 00:19:12,140
sai , i pesi giusti che ti darebbero quella precisione.

301
00:19:12,240 --> 00:19:16,493
Mentre se ti stai effettivamente allenando su un set di dati strutturato, 

302
00:19:16,493 --> 00:19:19,942
uno che ha le etichette giuste, all'inizio giocheri un po', 

303
00:19:19,942 --> 00:19:24,253
ma poi scendi molto velocemente per arrivare a quel livello di precisione, 

304
00:19:24,253 --> 00:19:28,220
e quindi in un certo senso è era più facile trovare i massimi locali.

305
00:19:28,540 --> 00:19:33,542
E quindi la cosa interessante è che porta alla luce un altro documento di un paio di 

306
00:19:33,542 --> 00:19:37,604
anni fa, che presenta molte più semplificazioni sui livelli di rete, 

307
00:19:37,604 --> 00:19:42,195
ma uno dei risultati diceva che se si guarda al panorama dell'ottimizzazione, 

308
00:19:42,195 --> 00:19:47,256
i minimi locali che queste reti tendono ad apprendere sono in realtà di pari qualità, 

309
00:19:47,256 --> 00:19:50,906
quindi in un certo senso se il tuo set di dati è strutturato, 

310
00:19:50,906 --> 00:19:54,320
dovresti essere in grado di trovarlo molto più facilmente.

311
00:19:58,160 --> 00:20:01,180
I miei ringraziamenti, come sempre, a quelli di voi che sostengono su Patreon.

312
00:20:01,520 --> 00:20:04,224
Ho già detto in precedenza che Patreon rappresenta una svolta, 

313
00:20:04,224 --> 00:20:06,800
ma questi video non sarebbero davvero possibili senza di te.

314
00:20:07,460 --> 00:20:10,540
Voglio anche ringraziare in modo speciale la società di VC Amplify Partners, 

315
00:20:10,540 --> 00:20:12,780
per il suo supporto a questi video iniziali della serie.

