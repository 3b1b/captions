1
00:00:04,180 --> 00:00:07,280
Nell'ultimo video ho presentato la struttura di una rete neurale.

2
00:00:07,680 --> 00:00:10,269
Farò un breve riepilogo in modo da averlo fresco. 

3
00:00:10,269 --> 00:00:12,600
Ho due obiettivi principali per questo video.

4
00:00:13,100 --> 00:00:15,426
Il primo è introdurre l’idea della discesa del gradiente, 

5
00:00:15,426 --> 00:00:18,193
che è alla base non solo del modo in cui le reti neurali apprendono, 

6
00:00:18,193 --> 00:00:20,600
ma anche di molti altri sistemi di apprendimento automatico.

7
00:00:21,120 --> 00:00:24,650
Dopo approfondiremo un po' di più il funzionamento di questa particolare 

8
00:00:24,650 --> 00:00:27,940
rete e cosa finiscono per cercare quegli strati nascosti di neuroni.

9
00:00:28,980 --> 00:00:32,298
Come promemoria, il nostro obiettivo qui è il classico esempio di 

10
00:00:32,298 --> 00:00:36,220
riconoscimento delle cifre scritte a mano, l'ABC del mondo delle reti neurali.

11
00:00:37,020 --> 00:00:40,195
Queste cifre vengono visualizzate su una griglia di 28x28 pixel, 

12
00:00:40,195 --> 00:00:43,420
ciascun pixel con un valore in scala di grigio compreso tra 0 e 1.

13
00:00:43,820 --> 00:00:46,863
Questi sono ciò che determinano l'attivazione 

14
00:00:46,863 --> 00:00:50,040
di 784 neuroni nello strato di input della rete.

15
00:00:51,180 --> 00:00:55,678
E poi l'attivazione di ciascun neurone negli strati successivi si basa su una somma 

16
00:00:55,678 --> 00:00:58,838
ponderata di tutte le attivazioni nello strato precedente, 

17
00:00:58,838 --> 00:01:00,820
più un numero speciale chiamato bias.

18
00:01:02,160 --> 00:01:05,461
Poi si compone quella somma con qualche altra funzione, 

19
00:01:05,461 --> 00:01:08,940
come la sigmoide, o una ReLU, come visto nell'ultimo video.

20
00:01:09,480 --> 00:01:14,253
In totale, data la scelta un po' arbitraria di due strati nascosti con 16 

21
00:01:14,253 --> 00:01:19,219
neuroni ciascuno, la rete ha circa 13.000 pesi e bias che possiamo regolare, 

22
00:01:19,219 --> 00:01:24,380
e sono questi valori che determinano esattamente cosa fa effettivamente la rete.

23
00:01:24,880 --> 00:01:29,137
Quindi ciò che intendiamo quando diciamo che questa rete classifica una determinata cifra 

24
00:01:29,137 --> 00:01:33,300
è che il più luminoso di quei 10 neuroni nello strato finale corrisponde a quella cifra.

25
00:01:34,100 --> 00:01:37,660
E ricorda, la motivazione che avevamo in mente qui per la struttura a 

26
00:01:37,660 --> 00:01:41,017
strati era che forse il secondo strato poteva riprendere i bordi, 

27
00:01:41,017 --> 00:01:44,323
e il terzo strato poteva riprendere modelli come anelli e linee, 

28
00:01:44,323 --> 00:01:48,800
e l'ultimo poteva semplicemente mettere insieme quelli modelli per riconoscere le cifre.

29
00:01:49,800 --> 00:01:52,240
Quindi qui impariamo come apprende la rete.

30
00:01:52,640 --> 00:01:57,010
Quello che vogliamo è un algoritmo in cui puoi mostrare a questa rete un sacco di dati di 

31
00:01:57,010 --> 00:02:01,282
addestramento, che si presentano sotto forma di un mucchio di immagini diverse di cifre 

32
00:02:01,282 --> 00:02:04,827
scritte a mano, insieme alle etichette per quello che dovrebbero essere, 

33
00:02:04,827 --> 00:02:09,148
e sarà aggiustare questi 13.000 pesi e bias in modo da migliorare le sue prestazioni sui 

34
00:02:09,148 --> 00:02:10,120
dati di allenamento.

35
00:02:10,720 --> 00:02:13,694
Si spera che questa struttura a strati significhi che ciò che 

36
00:02:13,694 --> 00:02:16,860
apprende si generalizzi in immagini oltre i dati di addestramento.

37
00:02:17,640 --> 00:02:20,958
Il modo in cui lo testiamo è che dopo aver addestrato la rete, 

38
00:02:20,958 --> 00:02:25,541
le mostri più dati etichettati mai visti prima e vedi con quanta precisione classifica 

39
00:02:25,541 --> 00:02:26,700
quelle nuove immagini.

40
00:02:31,120 --> 00:02:35,039
Fortunatamente per noi, e ciò che rende questo esempio così comune per cominciare, 

41
00:02:35,039 --> 00:02:38,250
è che le brave persone dietro il database MNIST hanno messo insieme 

42
00:02:38,250 --> 00:02:41,650
una raccolta di decine di migliaia di immagini di cifre scritte a mano, 

43
00:02:41,650 --> 00:02:44,200
ognuna etichettata con i numeri che dovrebbero Essere.

44
00:02:44,900 --> 00:02:49,046
E per quanto provocatorio sia descrivere una macchina in grado di apprendere, 

45
00:02:49,046 --> 00:02:52,662
una volta visto come funziona, sembra molto meno una folle premessa 

46
00:02:52,662 --> 00:02:55,480
fantascientifica e molto più un esercizio di calcolo.

47
00:02:56,200 --> 00:02:59,960
Voglio dire, fondamentalmente si tratta di trovare il minimo di una certa funzione.

48
00:03:01,940 --> 00:03:06,075
Ricorda, concettualmente, pensiamo che ciascun neurone sia connesso a tutti i 

49
00:03:06,075 --> 00:03:10,370
neuroni dello strato precedente, e i pesi nella somma ponderata che definisce la 

50
00:03:10,370 --> 00:03:14,241
sua attivazione sono un po' come i punti di forza di quelle connessioni, 

51
00:03:14,241 --> 00:03:18,960
e il bias è una qualche indicazione di se quel neurone tende ad essere attivo o inattivo.

52
00:03:19,720 --> 00:03:24,400
E per iniziare, inizializzeremo tutti questi pesi e pregiudizi in modo totalmente casuale.

53
00:03:24,940 --> 00:03:27,867
Inutile dire che questa rete funzionerà in modo piuttosto orribile su un dato 

54
00:03:27,867 --> 00:03:30,720
esempio di formazione, poiché sta semplicemente facendo qualcosa di casuale.

55
00:03:31,040 --> 00:03:33,530
Ad esempio, inserisci questa immagine di un 3 e il 

56
00:03:33,530 --> 00:03:36,020
livello di output sembra semplicemente un disastro.

57
00:03:36,600 --> 00:03:41,265
Quindi quello che fai è definire una funzione di costo, un modo per dire al computer, 

58
00:03:41,265 --> 00:03:46,039
no, cattivo computer, che l'output dovrebbe avere attivazioni che sono 0 per la maggior 

59
00:03:46,039 --> 00:03:50,760
parte dei neuroni, ma 1 per questo neurone, quello che mi hai dato è totale spazzatura.

60
00:03:51,720 --> 00:03:56,026
Per dirlo in modo un po' più matematico, sommi i quadrati delle differenze tra 

61
00:03:56,026 --> 00:04:00,768
ciascuna di quelle attivazioni di output dei rifiuti e il valore che vuoi che abbiano, 

62
00:04:00,768 --> 00:04:05,020
e questo è quello che chiameremo il costo di un singolo esempio di formazione.

63
00:04:05,960 --> 00:04:11,336
Si noti che questa somma è piccola quando la rete classifica correttamente l'immagine 

64
00:04:11,336 --> 00:04:16,399
con sicurezza, ma è grande quando sembra che la rete non sappia cosa sta facendo.

65
00:04:18,640 --> 00:04:22,067
Quindi quello che fai è considerare il costo medio di tutte le 

66
00:04:22,067 --> 00:04:25,440
decine di migliaia di esempi di formazione a tua disposizione.

67
00:04:27,040 --> 00:04:29,938
Questo costo medio è la nostra misura di quanto sia pessima 

68
00:04:29,938 --> 00:04:32,740
la rete e di quanto dovrebbe sentirsi pessimo il computer.

69
00:04:33,420 --> 00:04:34,600
E questa è una cosa complicata.

70
00:04:35,040 --> 00:04:38,831
Ricordi che la rete stessa era fondamentalmente una funzione, 

71
00:04:38,831 --> 00:04:42,195
che accetta 784 numeri come input, i valori dei pixel, 

72
00:04:42,195 --> 00:04:46,720
e restituisce 10 numeri come output, e in un certo senso è parametrizzata 

73
00:04:46,720 --> 00:04:48,800
da tutti questi pesi e pregiudizi?

74
00:04:49,500 --> 00:04:52,820
Ebbene, la funzione di costo è uno strato di complessità in più.

75
00:04:53,100 --> 00:04:58,185
Prende come input quei circa 13.000 pesi e pregiudizi e sputa un singolo numero che 

76
00:04:58,185 --> 00:05:01,332
descrive quanto siano gravi tali pesi e pregiudizi, 

77
00:05:01,332 --> 00:05:06,660
e il modo in cui viene definito dipende dal comportamento della rete su tutte le decine 

78
00:05:06,660 --> 00:05:08,900
di migliaia di dati di addestramento.

79
00:05:09,520 --> 00:05:11,000
C'è molto a cui pensare.

80
00:05:12,400 --> 00:05:15,820
Ma limitarsi a dire al computer che lavoro schifoso sta facendo non è molto utile.

81
00:05:16,220 --> 00:05:20,060
Vuoi dirgli come cambiare quei pesi e pregiudizi in modo che migliori.

82
00:05:20,780 --> 00:05:25,658
Per rendere più semplice, anziché faticare a immaginare una funzione con 13.000 input, 

83
00:05:25,658 --> 00:05:30,480
immagina una semplice funzione che abbia un numero come input e un numero come output.

84
00:05:31,480 --> 00:05:35,300
Come trovi un input che minimizzi il valore di questa funzione?

85
00:05:36,460 --> 00:05:39,758
Gli studenti di calcolo sapranno che a volte è possibile calcolare 

86
00:05:39,758 --> 00:05:43,253
esplicitamente quel minimo, ma ciò non è sempre fattibile per funzioni 

87
00:05:43,253 --> 00:05:46,748
veramente complicate, certamente non nella versione da 13.000 input di 

88
00:05:46,748 --> 00:05:51,080
questa situazione per la nostra folle e complicata funzione di costo della rete neurale.

89
00:05:51,580 --> 00:05:55,390
Una tattica più flessibile è quella di iniziare da qualsiasi input e 

90
00:05:55,390 --> 00:05:59,200
capire in quale direzione dovresti procedere per ridurre tale output.

91
00:06:00,080 --> 00:06:03,473
Nello specifico, se riesci a calcolare la pendenza della funzione 

92
00:06:03,473 --> 00:06:06,660
nel punto in cui ti trovi, spostati a sinistra se la pendenza 

93
00:06:06,660 --> 00:06:09,900
è positiva e sposta l'input a destra se la pendenza è negativa.

94
00:06:11,960 --> 00:06:15,692
Se lo fai ripetutamente, controllando in ogni punto la nuova pendenza e 

95
00:06:15,692 --> 00:06:19,840
facendo il passo appropriato, ti avvicinerai ad un minimo locale della funzione.

96
00:06:20,640 --> 00:06:23,800
L'immagine che potresti avere in mente qui è una palla che rotola giù da una collina.

97
00:06:24,620 --> 00:06:28,189
Nota, anche per questa funzione di input singolo davvero semplificata, 

98
00:06:28,189 --> 00:06:31,054
ci sono molte possibili valli in cui potresti atterrare, 

99
00:06:31,054 --> 00:06:34,724
a seconda dell'input casuale da cui inizi, e non c'è alcuna garanzia che 

100
00:06:34,724 --> 00:06:38,495
il minimo locale in cui atterri sarà il valore più piccolo possibile della 

101
00:06:38,495 --> 00:06:39,400
funzione di costo.

102
00:06:40,220 --> 00:06:42,620
Ciò si ripercuoterà anche sul caso della nostra rete neurale.

103
00:06:43,180 --> 00:06:47,199
Voglio anche che tu noti come se rendi le dimensioni dei tuoi passi proporzionali 

104
00:06:47,199 --> 00:06:50,433
alla pendenza, quando la pendenza si appiattisce verso il minimo, 

105
00:06:50,433 --> 00:06:54,600
i tuoi passi diventano sempre più piccoli e questo ti aiuta a non superare il limite.

106
00:06:55,940 --> 00:07:00,980
Aumentando un po' la complessità, immagina invece una funzione con due input e un output.

107
00:07:01,500 --> 00:07:04,865
Potresti pensare allo spazio di input come al piano xy e alla funzione di 

108
00:07:04,865 --> 00:07:08,140
costo come rappresentata graficamente come una superficie sopra di esso.

109
00:07:08,760 --> 00:07:11,941
Invece di chiedere informazioni sulla pendenza della funzione, 

110
00:07:11,941 --> 00:07:15,425
devi chiederti in quale direzione dovresti muoverti in questo spazio 

111
00:07:15,425 --> 00:07:18,960
di input in modo da diminuire più rapidamente l'output della funzione.

112
00:07:19,720 --> 00:07:21,760
In altre parole, qual è la direzione in discesa?

113
00:07:22,380 --> 00:07:25,560
Ancora una volta, è utile pensare a una palla che rotola giù da quella collina.

114
00:07:26,660 --> 00:07:30,736
Quelli di voi che hanno familiarità con il calcolo multivariabile sapranno 

115
00:07:30,736 --> 00:07:34,866
che il gradiente di una funzione ti dà la direzione dell'ascesa più ripida, 

116
00:07:34,866 --> 00:07:38,780
quale direzione dovresti fare per aumentare la funzione più rapidamente.

117
00:07:39,560 --> 00:07:42,775
Naturalmente, prendendo il negativo di quel gradiente si ottiene 

118
00:07:42,775 --> 00:07:46,040
la direzione del passo che diminuisce la funzione più rapidamente.

119
00:07:47,240 --> 00:07:50,539
Ancor di più, la lunghezza di questo vettore gradiente è 

120
00:07:50,539 --> 00:07:53,840
un'indicazione di quanto sia ripido il pendio più ripido.

121
00:07:54,540 --> 00:07:57,386
Se non hai familiarità con il calcolo multivariabile e desideri saperne di più, 

122
00:07:57,386 --> 00:08:00,340
dai un'occhiata ad alcuni dei lavori che ho svolto per Khan Academy sull'argomento.

123
00:08:00,860 --> 00:08:04,455
Onestamente, però, tutto ciò che conta per me e te in questo momento è 

124
00:08:04,455 --> 00:08:08,051
che in linea di principio esiste un modo per calcolare questo vettore, 

125
00:08:08,051 --> 00:08:11,900
questo vettore che ti dice qual è la direzione in discesa e quanto è ripida.

126
00:08:12,400 --> 00:08:14,321
Starai bene se questo è tutto quello che sai e 

127
00:08:14,321 --> 00:08:16,120
non sei solido come una roccia sui dettagli.

128
00:08:17,200 --> 00:08:20,362
Se riesci a capirlo, l'algoritmo per minimizzare la funzione 

129
00:08:20,362 --> 00:08:23,214
consiste nel calcolare questa direzione del gradiente, 

130
00:08:23,214 --> 00:08:26,740
quindi fare un piccolo passo in discesa e ripeterlo ancora e ancora.

131
00:08:27,700 --> 00:08:32,820
È la stessa idea di base per una funzione che ha 13.000 input invece di 2 input.

132
00:08:33,400 --> 00:08:36,511
Immagina di organizzare tutti i 13.000 pesi e pregiudizi 

133
00:08:36,511 --> 00:08:39,460
della nostra rete in un gigantesco vettore di colonne.

134
00:08:40,140 --> 00:08:44,082
Il gradiente negativo della funzione di costo è solo un vettore, 

135
00:08:44,082 --> 00:08:48,874
è una direzione all'interno di questo spazio di input follemente enorme che ti 

136
00:08:48,874 --> 00:08:53,788
dice quali spinte a tutti quei numeri causeranno la diminuzione più rapida della 

137
00:08:53,788 --> 00:08:54,880
funzione di costo.

138
00:08:55,640 --> 00:08:59,488
E ovviamente, con la nostra funzione di costo appositamente progettata, 

139
00:08:59,488 --> 00:09:03,176
modificare i pesi e i bias per ridurli significa far sì che l'output 

140
00:09:03,176 --> 00:09:06,918
della rete su ciascun dato di addestramento assomigli meno a un array 

141
00:09:06,918 --> 00:09:10,820
casuale di 10 valori e più a una decisione effettiva che vogliamo. farlo.

142
00:09:11,440 --> 00:09:14,510
È importante ricordare che questa funzione di costo implica una 

143
00:09:14,510 --> 00:09:17,917
media su tutti i dati di addestramento, quindi se la riduci al minimo, 

144
00:09:17,917 --> 00:09:21,180
significa che ci sono prestazioni migliori su tutti questi campioni.

145
00:09:23,820 --> 00:09:26,973
L'algoritmo per calcolare questo gradiente in modo efficiente, 

146
00:09:26,973 --> 00:09:30,476
che è effettivamente il cuore dell'apprendimento di una rete neurale, 

147
00:09:30,476 --> 00:09:33,980
si chiama backpropagation, ed è ciò di cui parlerò nel prossimo video.

148
00:09:34,660 --> 00:09:38,754
Lì, voglio davvero prendermi il tempo per esaminare cosa succede esattamente a 

149
00:09:38,754 --> 00:09:41,605
ciascun peso e bias per un dato dato di addestramento, 

150
00:09:41,605 --> 00:09:45,596
cercando di dare un'idea intuitiva di ciò che sta accadendo oltre la pila di 

151
00:09:45,596 --> 00:09:47,100
calcoli e formule pertinenti.

152
00:09:47,780 --> 00:09:50,821
Proprio qui, proprio ora, la cosa principale che voglio che tu sappia, 

153
00:09:50,821 --> 00:09:53,005
indipendentemente dai dettagli di implementazione, 

154
00:09:53,005 --> 00:09:56,261
è che ciò che intendiamo quando parliamo di apprendimento in rete è che sta 

155
00:09:56,261 --> 00:09:58,360
semplicemente minimizzando una funzione di costo.

156
00:09:59,300 --> 00:10:02,114
E notate, una conseguenza di ciò è che è importante che questa 

157
00:10:02,114 --> 00:10:04,571
funzione di costo abbia un output abbastanza regolare, 

158
00:10:04,571 --> 00:10:08,100
in modo da poter trovare un minimo locale facendo piccoli passi verso il basso.

159
00:10:09,260 --> 00:10:12,585
Questo è il motivo per cui, tra l’altro, i neuroni artificiali hanno 

160
00:10:12,585 --> 00:10:15,862
attivazioni che variano continuamente, anziché essere semplicemente 

161
00:10:15,862 --> 00:10:19,140
attivi o inattivi in modo binario, come lo sono i neuroni biologici.

162
00:10:20,220 --> 00:10:23,537
Questo processo di spostamento ripetuto dell'input di una funzione di 

163
00:10:23,537 --> 00:10:26,760
un multiplo del gradiente negativo è chiamato discesa del gradiente.

164
00:10:27,300 --> 00:10:30,611
È un modo per convergere verso un minimo locale di una funzione di costo, 

165
00:10:30,611 --> 00:10:32,580
sostanzialmente una valle in questo grafico.

166
00:10:33,440 --> 00:10:37,162
Sto ancora mostrando l'immagine di una funzione con due input, ovviamente, 

167
00:10:37,162 --> 00:10:40,636
perché i nudge in uno spazio di input a 13.000 dimensioni sono un po' 

168
00:10:40,636 --> 00:10:44,260
difficili da comprendere, ma esiste un bel modo non spaziale di pensarci.

169
00:10:45,080 --> 00:10:48,440
Ogni componente del gradiente negativo ci dice due cose.

170
00:10:49,060 --> 00:10:52,054
Il segno, ovviamente, ci dice se la componente corrispondente del 

171
00:10:52,054 --> 00:10:55,140
vettore di input deve essere spostata verso l'alto o verso il basso.

172
00:10:55,800 --> 00:10:59,289
Ma, cosa ancora più importante, l’entità relativa di tutti 

173
00:10:59,289 --> 00:11:02,720
questi componenti indica quali cambiamenti contano di più.

174
00:11:05,220 --> 00:11:09,084
Vedete, nella nostra rete, un aggiustamento a uno dei pesi potrebbe avere un impatto 

175
00:11:09,084 --> 00:11:13,040
molto maggiore sulla funzione di costo rispetto all'aggiustamento a qualche altro peso.

176
00:11:14,800 --> 00:11:18,200
Alcune di queste connessioni contano di più per i nostri dati di addestramento.

177
00:11:19,320 --> 00:11:23,770
Quindi un modo in cui puoi pensare a questo vettore gradiente della nostra enorme 

178
00:11:23,770 --> 00:11:28,275
funzione di costo è che codifica l'importanza relativa di ogni peso e pregiudizio, 

179
00:11:28,275 --> 00:11:32,400
cioè quale di questi cambiamenti porterà il maggior rapporto qualità-prezzo.

180
00:11:33,620 --> 00:11:36,640
Questo è davvero solo un altro modo di pensare alla direzione.

181
00:11:37,100 --> 00:11:41,275
Per fare un esempio più semplice, se hai una funzione con due variabili come 

182
00:11:41,275 --> 00:11:45,558
input e calcoli che il suo gradiente in un punto particolare risulta come 3,1, 

183
00:11:45,558 --> 00:11:49,788
allora da un lato puoi interpretarlo come se dicessi che quando tu' Stando su 

184
00:11:49,788 --> 00:11:54,343
quell'input, muovendoti lungo questa direzione la funzione aumenta più rapidamente, 

185
00:11:54,343 --> 00:11:59,006
ovvero quando rappresenti graficamente la funzione sopra il piano dei punti di input, 

186
00:11:59,006 --> 00:12:02,260
quel vettore è ciò che ti dà la direzione diritta in salita.

187
00:12:02,860 --> 00:12:07,540
Ma un altro modo di leggerlo è dire che le modifiche a questa prima variabile hanno 3 

188
00:12:07,540 --> 00:12:10,750
volte l'importanza delle modifiche alla seconda variabile, 

189
00:12:10,750 --> 00:12:13,417
che almeno nelle vicinanze dell'input rilevante, 

190
00:12:13,417 --> 00:12:16,900
spostare il valore x porta molto più effetto per il tuo secchio.

191
00:12:19,880 --> 00:12:22,340
Riduciamo lo zoom e riassumiamo dove siamo finora.

192
00:12:22,840 --> 00:12:26,784
La rete stessa è questa funzione con 784 ingressi e 10 uscite, 

193
00:12:26,784 --> 00:12:30,040
definite in termini di tutte queste somme ponderate.

194
00:12:30,640 --> 00:12:33,680
La funzione di costo è uno strato di complessità in più.

195
00:12:33,980 --> 00:12:37,557
Prende i 13.000 pesi e pregiudizi come input e produce 

196
00:12:37,557 --> 00:12:41,720
un'unica misura di pessimazza basata sugli esempi di formazione.

197
00:12:42,440 --> 00:12:44,859
E il gradiente della funzione di costo rappresenta 

198
00:12:44,859 --> 00:12:46,900
ancora un ulteriore livello di complessità.

199
00:12:47,360 --> 00:12:50,679
Ci dice quali spinte a tutti questi pesi e pregiudizi causano il 

200
00:12:50,679 --> 00:12:53,692
cambiamento più rapido nel valore della funzione di costo, 

201
00:12:53,692 --> 00:12:57,880
che potresti interpretare come dire quali cambiamenti a quali pesi contano di più.

202
00:13:02,560 --> 00:13:05,931
Quindi, quando inizializzi la rete con pesi e bias casuali e li 

203
00:13:05,931 --> 00:13:09,670
regoli molte volte in base a questo processo di discesa del gradiente, 

204
00:13:09,670 --> 00:13:13,200
quanto bene si comporta effettivamente su immagini mai viste prima?

205
00:13:14,100 --> 00:13:18,692
Quello che ho descritto qui, con i due strati nascosti di 16 neuroni ciascuno, 

206
00:13:18,692 --> 00:13:21,832
scelti soprattutto per ragioni estetiche, non è male, 

207
00:13:21,832 --> 00:13:25,960
classificando correttamente circa il 96% delle nuove immagini che vede.

208
00:13:26,680 --> 00:13:30,414
E onestamente, se guardi alcuni degli esempi in cui si incasina, 

209
00:13:30,414 --> 00:13:32,540
ti senti obbligato a darci un taglio.

210
00:13:36,220 --> 00:13:40,210
Ora, se giochi con la struttura dei livelli nascosti e apporti un paio di modifiche, 

211
00:13:40,210 --> 00:13:41,760
puoi ottenere questo fino al 98%.

212
00:13:41,760 --> 00:13:42,720
E questo è abbastanza buono!

213
00:13:43,020 --> 00:13:46,819
Non è il massimo, puoi sicuramente ottenere prestazioni migliori diventando 

214
00:13:46,819 --> 00:13:49,270
più sofisticato di questa semplice rete vanilla, 

215
00:13:49,270 --> 00:13:51,919
ma dato quanto sia scoraggiante il compito iniziale, 

216
00:13:51,919 --> 00:13:55,420
penso che ci sia qualcosa di incredibile nel fatto che qualsiasi rete 

217
00:13:55,420 --> 00:13:58,969
riesca così bene su immagini mai viste prima, dato che non gli abbiamo 

218
00:13:58,969 --> 00:14:01,420
mai detto specificatamente quali modelli cercare.

219
00:14:02,560 --> 00:14:06,170
Originariamente, il modo in cui ho motivato questa struttura era descrivendo una 

220
00:14:06,170 --> 00:14:09,825
speranza che potremmo avere, che il secondo strato potesse captare piccoli bordi, 

221
00:14:09,825 --> 00:14:13,525
che il terzo strato mettesse insieme quei bordi per riconoscere anelli e linee più 

222
00:14:13,525 --> 00:14:17,180
lunghe, e che questi potessero essere ricomposti insieme per riconoscere le cifre.

223
00:14:17,960 --> 00:14:20,400
Quindi è questo ciò che sta effettivamente facendo la nostra rete?

224
00:14:21,080 --> 00:14:24,400
Beh, almeno per questo, per niente.

225
00:14:24,820 --> 00:14:28,867
Ricordi come nell'ultimo video abbiamo visto come i pesi delle connessioni da tutti 

226
00:14:28,867 --> 00:14:32,674
i neuroni del primo strato a un dato neurone del secondo strato possono essere 

227
00:14:32,674 --> 00:14:36,578
visualizzati come un dato modello di pixel che il neurone del secondo strato sta 

228
00:14:36,578 --> 00:14:37,060
rilevando?

229
00:14:37,780 --> 00:14:43,080
Bene, quando lo facciamo effettivamente per i pesi associati a queste transizioni, 

230
00:14:43,080 --> 00:14:48,571
dal primo strato al successivo, invece di raccogliere piccoli bordi isolati qua e là, 

231
00:14:48,571 --> 00:14:53,680
sembrano, beh, quasi casuali, solo con alcuni schemi molto vaghi in il mezzo lì.

232
00:14:53,760 --> 00:14:57,413
Sembrerebbe che nell'insondabilmente ampio spazio di 13.000 dimensioni dei 

233
00:14:57,413 --> 00:15:01,262
possibili pesi e pregiudizi, la nostra rete si sia trovata un piccolo e felice 

234
00:15:01,262 --> 00:15:05,111
minimo locale che, nonostante abbia classificato con successo la maggior parte 

235
00:15:05,111 --> 00:15:08,960
delle immagini, non riprende esattamente gli schemi che avremmo potuto sperare.

236
00:15:09,780 --> 00:15:11,885
E per chiarire davvero questo punto, guarda cosa 

237
00:15:11,885 --> 00:15:13,820
succede quando inserisci un'immagine casuale.

238
00:15:14,320 --> 00:15:18,781
Se il sistema fosse intelligente, potresti aspettarti che si senta incerto, 

239
00:15:18,781 --> 00:15:23,594
magari non attivando realmente nessuno di quei 10 neuroni in uscita o attivandoli 

240
00:15:23,594 --> 00:15:28,524
tutti in modo uniforme, ma invece ti dà con sicurezza qualche risposta senza senso, 

241
00:15:28,524 --> 00:15:33,455
come se fosse sicuro che questo rumore casuale è un 5 così come l'immagine reale di 

242
00:15:33,455 --> 00:15:34,160
un 5 è un 5.

243
00:15:34,540 --> 00:15:39,121
In altre parole, anche se questa rete è in grado di riconoscere le cifre abbastanza bene, 

244
00:15:39,121 --> 00:15:40,700
non ha idea di come disegnarle.

245
00:15:41,420 --> 00:15:43,227
In gran parte ciò è dovuto al fatto che si tratta di 

246
00:15:43,227 --> 00:15:45,240
un'impostazione di allenamento così strettamente vincolata.

247
00:15:45,880 --> 00:15:47,740
Voglio dire, mettiti nei panni della rete qui.

248
00:15:48,140 --> 00:15:52,177
Dal suo punto di vista, l’intero universo non consiste altro che di cifre immobili 

249
00:15:52,177 --> 00:15:54,901
chiaramente definite centrate in una minuscola griglia, 

250
00:15:54,901 --> 00:15:58,939
e la sua funzione di costo non gli ha mai dato alcun incentivo ad essere altro che 

251
00:15:58,939 --> 00:16:01,080
completamente fiduciosi nelle sue decisioni.

252
00:16:02,120 --> 00:16:04,560
Quindi, con questa come immagine di ciò che stanno realmente 

253
00:16:04,560 --> 00:16:07,119
facendo i neuroni del secondo strato, potreste chiedervi perché 

254
00:16:07,119 --> 00:16:09,920
introdurrei questa rete con la motivazione di cogliere bordi e schemi.

255
00:16:09,920 --> 00:16:12,300
Voglio dire, non è affatto quello che finisce per fare.

256
00:16:13,380 --> 00:16:15,805
Ebbene, questo non vuole essere il nostro obiettivo finale, 

257
00:16:15,805 --> 00:16:17,180
ma piuttosto un punto di partenza.

258
00:16:17,640 --> 00:16:22,003
Francamente, questa è una tecnologia vecchia, del tipo studiato negli anni '80 e '90, 

259
00:16:22,003 --> 00:16:25,860
e devi capirla prima di poter comprendere varianti moderne più dettagliate, 

260
00:16:25,860 --> 00:16:29,361
ed è chiaramente in grado di risolvere alcuni problemi interessanti, 

261
00:16:29,361 --> 00:16:33,065
ma più approfondisci cosa quegli strati nascosti stanno davvero facendo, 

262
00:16:33,065 --> 00:16:34,740
tanto meno intelligenti sembrano.

263
00:16:38,480 --> 00:16:42,390
Spostando per un momento l'attenzione da come le reti apprendono a come impari tu, 

264
00:16:42,390 --> 00:16:46,300
ciò accadrà solo se ti impegnerai attivamente con il materiale qui in qualche modo.

265
00:16:47,060 --> 00:16:50,527
Una cosa piuttosto semplice che voglio che tu faccia è semplicemente 

266
00:16:50,527 --> 00:16:53,693
fermarti adesso e pensare profondamente per un momento a quali 

267
00:16:53,693 --> 00:16:56,859
modifiche potresti apportare a questo sistema e al modo in cui 

268
00:16:56,859 --> 00:17:00,880
percepisce le immagini se volessi che rilevasse meglio cose come bordi e motivi.

269
00:17:01,480 --> 00:17:04,448
Ma meglio di così, per interagire davvero con il materiale, 

270
00:17:04,448 --> 00:17:08,209
consiglio vivamente il libro di Michael Nielsen sull'apprendimento profondo 

271
00:17:08,209 --> 00:17:09,099
e le reti neurali.

272
00:17:09,680 --> 00:17:13,891
In esso puoi trovare il codice e i dati da scaricare e con cui giocare per questo 

273
00:17:13,891 --> 00:17:18,359
esatto esempio, e il libro ti guiderà passo dopo passo su cosa sta facendo quel codice.

274
00:17:19,300 --> 00:17:22,369
La cosa fantastica è che questo libro è gratuito e disponibile al pubblico, 

275
00:17:22,369 --> 00:17:25,196
quindi se ne trai qualcosa, prendi in considerazione l'idea di unirti 

276
00:17:25,196 --> 00:17:27,660
a me per fare una donazione a favore degli sforzi di Nielsen.

277
00:17:27,660 --> 00:17:32,029
Ho anche collegato un paio di altre risorse che mi piacciono molto nella descrizione, 

278
00:17:32,029 --> 00:17:36,500
incluso il fenomenale e bellissimo post sul blog di Chris Ola e gli articoli in Distill.

279
00:17:38,280 --> 00:17:41,080
Per chiudere qui per gli ultimi minuti, voglio tornare a 

280
00:17:41,080 --> 00:17:43,880
un frammento dell'intervista che ho avuto con Leisha Lee.

281
00:17:44,300 --> 00:17:46,082
Potresti ricordarla dall'ultimo video, ha svolto 

282
00:17:46,082 --> 00:17:47,720
il suo dottorato di ricerca in deep learning.

283
00:17:48,300 --> 00:17:50,666
In questo piccolo frammento parla di due articoli recenti che 

284
00:17:50,666 --> 00:17:53,108
approfondiscono davvero il modo in cui alcune delle più moderne 

285
00:17:53,108 --> 00:17:55,780
reti di riconoscimento delle immagini stanno effettivamente imparando.

286
00:17:56,120 --> 00:17:58,667
Giusto per stabilire il punto in cui eravamo nella conversazione, 

287
00:17:58,667 --> 00:18:01,716
il primo articolo ha preso una di queste reti neurali particolarmente profonde 

288
00:18:01,716 --> 00:18:03,838
che è davvero brava nel riconoscimento delle immagini, 

289
00:18:03,838 --> 00:18:06,540
e invece di addestrarla su un set di dati opportunamente etichettato, 

290
00:18:06,540 --> 00:18:08,740
ha mescolato tutte le etichette prima dell'addestramento.

291
00:18:09,480 --> 00:18:12,737
Ovviamente la precisione del test qui non era migliore di quella casuale, 

292
00:18:12,737 --> 00:18:16,478
poiché tutto è etichettato in modo casuale, ma è stato comunque in grado di ottenere 

293
00:18:16,478 --> 00:18:20,351
la stessa precisione di addestramento che si otterrebbe su un set di dati correttamente 

294
00:18:20,351 --> 00:18:20,880
etichettato.

295
00:18:21,600 --> 00:18:25,019
Fondamentalmente, i milioni di pesi per questa particolare rete erano 

296
00:18:25,019 --> 00:18:27,852
sufficienti per memorizzare semplicemente i dati casuali, 

297
00:18:27,852 --> 00:18:31,759
il che solleva la questione se minimizzare questa funzione di costo corrisponda 

298
00:18:31,759 --> 00:18:34,690
effettivamente a qualsiasi tipo di struttura nell'immagine, 

299
00:18:34,690 --> 00:18:36,400
o si tratta solo di memorizzazione?

300
00:18:51,440 --> 00:18:58,088
Se guardi quella curva di precisione, se ti stessi allenando su un set di dati casuale, 

301
00:18:58,088 --> 00:19:02,772
quella curva scendeva molto lentamente in modo quasi lineare, 

302
00:19:02,772 --> 00:19:07,984
quindi fai davvero fatica a trovare quel minimo locale di possibile, 

303
00:19:07,984 --> 00:19:12,140
sai , i pesi giusti che ti darebbero quella precisione.

304
00:19:12,240 --> 00:19:16,493
Mentre se ti stai effettivamente allenando su un set di dati strutturato, 

305
00:19:16,493 --> 00:19:19,942
uno che ha le etichette giuste, all'inizio giocheri un po', 

306
00:19:19,942 --> 00:19:24,253
ma poi scendi molto velocemente per arrivare a quel livello di precisione, 

307
00:19:24,253 --> 00:19:28,220
e quindi in un certo senso è era più facile trovare i massimi locali.

308
00:19:28,540 --> 00:19:33,542
E quindi la cosa interessante è che porta alla luce un altro documento di un paio di 

309
00:19:33,542 --> 00:19:37,604
anni fa, che presenta molte più semplificazioni sui livelli di rete, 

310
00:19:37,604 --> 00:19:42,195
ma uno dei risultati diceva che se si guarda al panorama dell'ottimizzazione, 

311
00:19:42,195 --> 00:19:47,256
i minimi locali che queste reti tendono ad apprendere sono in realtà di pari qualità, 

312
00:19:47,256 --> 00:19:50,906
quindi in un certo senso se il tuo set di dati è strutturato, 

313
00:19:50,906 --> 00:19:54,320
dovresti essere in grado di trovarlo molto più facilmente.

314
00:19:58,160 --> 00:20:01,180
I miei ringraziamenti, come sempre, a quelli di voi che sostengono su Patreon.

315
00:20:01,520 --> 00:20:04,224
Ho già detto in precedenza che Patreon rappresenta una svolta, 

316
00:20:04,224 --> 00:20:06,800
ma questi video non sarebbero davvero possibili senza di te.

317
00:20:07,460 --> 00:20:10,540
Voglio anche ringraziare in modo speciale la società di VC Amplify Partners, 

318
00:20:10,540 --> 00:20:12,780
per il suo supporto a questi video iniziali della serie.

