1
00:00:04,180 --> 00:00:07,280
చివరి వీడియో నేను న్యూరల్ నెట్‌వర్క్ యొక్క నిర్మాణాన్ని రూపొందించాను.

2
00:00:07,680 --> 00:00:10,540
నేను ఇక్కడ శీఘ్ర రీక్యాప్ ఇస్తాను, తద్వారా ఇది మన మనస్సులో తాజాగా ఉంటుంది, 

3
00:00:10,540 --> 00:00:12,600
ఆపై ఈ వీడియో కోసం నాకు రెండు ప్రధాన లక్ష్యాలు ఉన్నాయి.

4
00:00:13,100 --> 00:00:15,224
మొదటిది గ్రేడియంట్ డీసెంట్ ఆలోచనను పరిచయం చేయడం, 

5
00:00:15,224 --> 00:00:17,868
ఇది న్యూరల్ నెట్‌వర్క్‌లు ఎలా నేర్చుకుంటాయో మాత్రమే కాకుండా, 

6
00:00:17,868 --> 00:00:20,600
చాలా ఇతర మెషీన్ లెర్నింగ్ కూడా ఎలా పనిచేస్తుందో తెలియజేస్తుంది.

7
00:00:21,120 --> 00:00:24,553
ఆ తర్వాత మేము ఈ నిర్దిష్ట నెట్‌వర్క్ ఎలా పని చేస్తుందో మరియు న్యూరాన్‌ల 

8
00:00:24,553 --> 00:00:27,940
యొక్క దాచిన పొరలు దేని కోసం వెతుకుతున్నాయో కొంచెం ఎక్కువ త్రవ్విస్తాము.

9
00:00:28,979 --> 00:00:34,222
రిమైండర్‌గా, ఇక్కడ మా లక్ష్యం చేతితో వ్రాసిన అంకెల గుర్తింపు యొక్క క్లాసిక్ ఉదాహరణ, 

10
00:00:34,222 --> 00:00:36,220
న్యూరల్ నెట్‌వర్క్‌ల హలో వరల్డ్.

11
00:00:37,020 --> 00:00:40,021
ఈ అంకెలు 28x28 పిక్సెల్ గ్రిడ్‌లో రెండర్ చేయబడ్డాయి, 

12
00:00:40,021 --> 00:00:43,420
ప్రతి పిక్సెల్ కొంత గ్రేస్కేల్ విలువ 0 మరియు 1 మధ్య ఉంటుంది.

13
00:00:43,820 --> 00:00:50,040
నెట్‌వర్క్ యొక్క ఇన్‌పుట్ లేయర్‌లోని 784 న్యూరాన్‌ల క్రియాశీలతను అవి నిర్ణయిస్తాయి.

14
00:00:51,180 --> 00:00:54,341
ఆపై క్రింది లేయర్‌లలోని ప్రతి న్యూరాన్‌కి క్రియాశీలత మునుపటి 

15
00:00:54,341 --> 00:00:58,073
లేయర్‌లోని అన్ని యాక్టివేషన్‌ల యొక్క వెయిటెడ్ మొత్తంపై ఆధారపడి ఉంటుంది, 

16
00:00:58,073 --> 00:01:00,820
దానితో పాటు బయాస్ అని పిలువబడే కొన్ని ప్రత్యేక సంఖ్య.

17
00:01:02,160 --> 00:01:05,500
అప్పుడు మీరు ఆ మొత్తాన్ని సిగ్మోయిడ్ స్క్విషిఫికేషన్ లేదా రెలు వంటి 

18
00:01:05,500 --> 00:01:08,940
కొన్ని ఇతర ఫంక్షన్‌తో కంపోజ్ చేయండి, నేను చివరి వీడియో ద్వారా నడిచాను.

19
00:01:09,480 --> 00:01:14,466
మొత్తంగా, ఒక్కొక్కటి 16 న్యూరాన్‌లతో రెండు దాచిన లేయర్‌లను కొంతవరకు ఏకపక్షంగా ఎంపిక 

20
00:01:14,466 --> 00:01:18,621
చేస్తే, నెట్‌వర్క్‌లో సుమారు 13,000 బరువులు మరియు పక్షపాతాలు ఉన్నాయి, 

21
00:01:18,621 --> 00:01:23,548
వీటిని మనం సర్దుబాటు చేయవచ్చు మరియు నెట్‌వర్క్ వాస్తవానికి ఏమి చేస్తుందో ఈ విలువలు 

22
00:01:23,548 --> 00:01:24,380
నిర్ణయిస్తాయి.

23
00:01:24,880 --> 00:01:29,353
ఈ నెట్‌వర్క్ ఇచ్చిన అంకెను వర్గీకరిస్తుంది అని మనం చెప్పినప్పుడు మనకు అర్థం ఏమిటంటే, 

24
00:01:29,353 --> 00:01:33,300
చివరి పొరలో ఉన్న 10 న్యూరాన్‌లలో ప్రకాశవంతమైనది ఆ అంకెకు అనుగుణంగా ఉంటుంది.

25
00:01:34,100 --> 00:01:38,902
మరియు గుర్తుంచుకోండి, లేయర్డ్ స్ట్రక్చర్ కోసం మనం ఇక్కడ దృష్టిలో ఉంచుకున్న ప్రేరణ 

26
00:01:38,902 --> 00:01:43,646
ఏమిటంటే, రెండవ పొర అంచుల నుండి ఎంచుకోవచ్చు మరియు మూడవ లేయర్ లూప్‌లు మరియు లైన్‌ల 

27
00:01:43,646 --> 00:01:48,800
వంటి నమూనాలను ఎంచుకోవచ్చు మరియు చివరిది వాటిని కలపవచ్చు. అంకెలను గుర్తించడానికి నమూనాలు.

28
00:01:49,800 --> 00:01:52,240
కాబట్టి ఇక్కడ, నెట్‌వర్క్ ఎలా నేర్చుకుంటుందో మనం నేర్చుకుంటాము.

29
00:01:52,640 --> 00:01:57,919
మేము కోరుకునేది మీరు ఈ నెట్‌వర్క్‌కు శిక్షణ డేటా యొక్క మొత్తం సమూహాన్ని చూపగల అల్గారిథమ్, 

30
00:01:57,919 --> 00:02:02,318
ఇది చేతితో వ్రాసిన అంకెల యొక్క విభిన్న చిత్రాల సమూహంతో పాటు అవి ఏవి ఉండాలో 

31
00:02:02,318 --> 00:02:07,069
లేబుల్‌లతో పాటుగా వస్తాయి మరియు ఇది శిక్షణ డేటాపై దాని పనితీరును మెరుగుపరచడానికి 

32
00:02:07,069 --> 00:02:10,120
ఆ 13,000 బరువులు మరియు పక్షపాతాలను సర్దుబాటు చేయండి.

33
00:02:10,720 --> 00:02:13,728
ఆశాజనక, ఈ లేయర్డ్ నిర్మాణం అంటే అది నేర్చుకునేది 

34
00:02:13,728 --> 00:02:16,860
ఆ శిక్షణ డేటాకు మించిన చిత్రాలకు సాధారణీకరిస్తుంది.

35
00:02:17,640 --> 00:02:21,107
మేము దానిని పరీక్షించే విధానం ఏమిటంటే, మీరు నెట్‌వర్క్‌కు శిక్షణ ఇచ్చిన తర్వాత, 

36
00:02:21,107 --> 00:02:24,185
మీరు ఇంతకు ముందెన్నడూ చూడని మరింత లేబుల్ డేటాను చూపుతారు మరియు ఆ కొత్త 

37
00:02:24,185 --> 00:02:26,700
చిత్రాలను అది ఎంత ఖచ్చితంగా వర్గీకరిస్తుందో మీరు చూస్తారు.

38
00:02:31,120 --> 00:02:35,214
అదృష్టవశాత్తూ, మరియు ప్రారంభించడానికి ఇది చాలా సాధారణ ఉదాహరణగా మారింది, 

39
00:02:35,214 --> 00:02:39,309
MNIST డేటాబేస్ వెనుక ఉన్న మంచి వ్యక్తులు పదివేల చేతివ్రాత అంకెల చిత్రాల 

40
00:02:39,309 --> 00:02:44,200
సేకరణను కలిగి ఉన్నారు, ప్రతి ఒక్కటి వారు చేయవలసిన సంఖ్యలతో లేబుల్ చేయబడ్డాయి. ఉంటుంది.

41
00:02:44,900 --> 00:02:47,662
మరియు మెషీన్‌ను నేర్చుకోవడంగా వర్ణించడం ఎంత రెచ్చగొట్టేదో, 

42
00:02:47,662 --> 00:02:51,126
అది ఎలా పనిచేస్తుందో మీరు ఒకసారి చూస్తే, అది కొన్ని వెర్రి సైన్స్ ఫిక్షన్ 

43
00:02:51,126 --> 00:02:54,543
ఆవరణలాగా చాలా తక్కువగా అనిపిస్తుంది మరియు కాలిక్యులస్ వ్యాయామం లాగా చాలా 

44
00:02:54,543 --> 00:02:55,480
ఎక్కువ అనిపిస్తుంది.

45
00:02:56,200 --> 00:02:58,307
నా ఉద్దేశ్యం, ప్రాథమికంగా ఇది ఒక నిర్దిష్ట ఫంక్షన్ 

46
00:02:58,307 --> 00:02:59,960
యొక్క కనిష్టాన్ని కనుగొనడానికి వస్తుంది.

47
00:03:01,939 --> 00:03:06,239
గుర్తుంచుకోండి, సంభావితంగా, మేము ప్రతి న్యూరాన్ మునుపటి లేయర్‌లోని అన్ని 

48
00:03:06,239 --> 00:03:10,479
న్యూరాన్‌లకు అనుసంధానించబడిందని ఆలోచిస్తున్నాము మరియు దాని క్రియాశీలతను 

49
00:03:10,479 --> 00:03:14,601
నిర్వచించే వెయిటెడ్ మొత్తంలోని బరువులు ఆ కనెక్షన్‌ల బలాలు లాగా ఉంటాయి 

50
00:03:14,601 --> 00:03:18,960
మరియు పక్షపాతం కొన్ని సూచన ఆ న్యూరాన్ చురుకుగా లేదా క్రియారహితంగా ఉంటుందా.

51
00:03:19,720 --> 00:03:22,038
మరియు విషయాలను ప్రారంభించడానికి, మేము ఆ బరువులు మరియు 

52
00:03:22,038 --> 00:03:24,400
పక్షపాతాలను పూర్తిగా యాదృచ్ఛికంగా ప్రారంభించబోతున్నాము.

53
00:03:24,940 --> 00:03:27,743
ఈ నెట్‌వర్క్ ఇచ్చిన శిక్షణ ఉదాహరణపై చాలా భయంకరంగా పని చేస్తుందని 

54
00:03:27,743 --> 00:03:30,720
ప్రత్యేకంగా చెప్పనవసరం లేదు, ఎందుకంటే ఇది యాదృచ్ఛికంగా ఏదో చేస్తోంది.

55
00:03:31,040 --> 00:03:33,556
ఉదాహరణకు, మీరు 3 యొక్క ఈ చిత్రంలో ఫీడ్ చేస్తారు 

56
00:03:33,556 --> 00:03:36,020
మరియు అవుట్‌పుట్ లేయర్ గందరగోళంగా కనిపిస్తుంది.

57
00:03:36,600 --> 00:03:41,597
కాబట్టి మీరు చేసేది ఖర్చు ఫంక్షన్‌ని నిర్వచించడం, కంప్యూటర్‌కు చెప్పే మార్గం, 

58
00:03:41,597 --> 00:03:47,171
కాదు, చెడ్డ కంప్యూటర్, ఆ అవుట్‌పుట్‌లో చాలా న్యూరాన్‌లకు 0 ఉండే యాక్టివేషన్‌లు ఉండాలి, 

59
00:03:47,171 --> 00:03:50,760
కానీ ఈ న్యూరాన్‌కు 1, మీరు నాకు ఇచ్చినది పూర్తిగా చెత్త.

60
00:03:51,720 --> 00:03:56,014
కొంచెం ఎక్కువ గణితశాస్త్రంలో చెప్పాలంటే, మీరు ఆ ప్రతి ట్రాష్ అవుట్‌పుట్ 

61
00:03:56,014 --> 00:04:00,427
యాక్టివేషన్‌ల మధ్య వ్యత్యాసాల చతురస్రాలను మరియు వాటిని కలిగి ఉండాలని మీరు 

62
00:04:00,427 --> 00:04:05,020
కోరుకునే విలువను జోడిస్తారు మరియు దీనిని మేము ఒకే శిక్షణ ఉదాహరణగా పిలుస్తాము.

63
00:04:05,960 --> 00:04:11,431
నెట్‌వర్క్ నమ్మకంగా చిత్రాన్ని సరిగ్గా వర్గీకరించినప్పుడు ఈ మొత్తం చిన్నదని గమనించండి, 

64
00:04:11,431 --> 00:04:16,399
కానీ నెట్‌వర్క్ ఏమి చేస్తుందో తెలియనట్లు అనిపించినప్పుడు అది పెద్దదిగా ఉంటుంది.

65
00:04:18,640 --> 00:04:25,440
కాబట్టి మీరు చేసేది మీ వద్ద ఉన్న పదివేల శిక్షణా ఉదాహరణల కంటే సగటు ధరను పరిగణించడం.

66
00:04:27,040 --> 00:04:30,046
ఈ సగటు ధర నెట్‌వర్క్ ఎంత అధ్వాన్నంగా ఉందో మరియు 

67
00:04:30,046 --> 00:04:32,740
కంప్యూటర్ ఎంత చెడ్డగా భావించాలో మా కొలమానం.

68
00:04:33,420 --> 00:04:34,600
మరియు అది సంక్లిష్టమైన విషయం.

69
00:04:35,040 --> 00:04:38,452
నెట్‌వర్క్ ప్రాథమికంగా ఒక ఫంక్షన్‌గా ఎలా ఉందో గుర్తుంచుకోండి, 

70
00:04:38,452 --> 00:04:42,965
ఇది 784 సంఖ్యలను ఇన్‌పుట్‌లుగా, పిక్సెల్ విలువలుగా తీసుకుంటుంది మరియు 10 సంఖ్యలను 

71
00:04:42,965 --> 00:04:47,368
దాని అవుట్‌పుట్‌గా ఉమ్మివేస్తుంది మరియు ఒక కోణంలో ఇది ఈ బరువులు మరియు పక్షపాతాల 

72
00:04:47,368 --> 00:04:48,800
ద్వారా పారామితి చేయబడిందా?

73
00:04:49,500 --> 00:04:52,820
బాగా ఖర్చు ఫంక్షన్ దాని పైన సంక్లిష్టత పొర.

74
00:04:53,100 --> 00:04:58,327
ఇది దాని ఇన్‌పుట్‌గా ఆ 13,000 లేదా అంతకంటే ఎక్కువ బరువులు మరియు పక్షపాతాలను తీసుకుంటుంది 

75
00:04:58,327 --> 00:05:03,496
మరియు ఆ బరువులు మరియు పక్షపాతాలు ఎంత చెడ్డవో వివరిస్తూ ఒకే సంఖ్యను ఉమ్మివేస్తుంది మరియు 

76
00:05:03,496 --> 00:05:08,430
అది నిర్వచించబడిన విధానం మొత్తం పదివేల శిక్షణా డేటాపై నెట్‌వర్క్ ప్రవర్తనపై ఆధారపడి 

77
00:05:08,430 --> 00:05:08,900
ఉంటుంది.

78
00:05:09,520 --> 00:05:11,000
అన్నది చాలా ఆలోచించాల్సిన విషయం.

79
00:05:12,400 --> 00:05:15,820
కానీ కంప్యూటర్‌కు అది ఎంత చెత్త పని చేస్తుందో చెప్పడం చాలా ఉపయోగకరంగా ఉండదు.

80
00:05:16,220 --> 00:05:18,968
ఆ బరువులు మరియు పక్షపాతాలను ఎలా మార్చాలో మీరు చెప్పాలనుకుంటున్నారు, 

81
00:05:18,968 --> 00:05:20,060
తద్వారా అది మెరుగుపడుతుంది.

82
00:05:20,780 --> 00:05:25,244
దీన్ని సులభతరం చేయడానికి, 13,000 ఇన్‌పుట్‌లతో ఒక ఫంక్షన్‌ను ఊహించడం కష్టపడకుండా, 

83
00:05:25,244 --> 00:05:29,818
ఒక సంఖ్యను ఇన్‌పుట్‌గా మరియు ఒక సంఖ్యను అవుట్‌పుట్‌గా కలిగి ఉండే సాధారణ ఫంక్షన్‌ను 

84
00:05:29,818 --> 00:05:30,480
ఊహించుకోండి.

85
00:05:31,480 --> 00:05:35,300
ఈ ఫంక్షన్ విలువను తగ్గించే ఇన్‌పుట్‌ను మీరు ఎలా కనుగొంటారు?

86
00:05:36,460 --> 00:05:39,825
కాలిక్యులస్ విద్యార్థులకు మీరు కొన్నిసార్లు స్పష్టంగా కనిష్టంగా 

87
00:05:39,825 --> 00:05:43,507
గుర్తించగలరని తెలుసుకుంటారు, కానీ నిజంగా సంక్లిష్టమైన ఫంక్షన్‌లకు ఇది 

88
00:05:43,507 --> 00:05:47,240
ఎల్లప్పుడూ సాధ్యపడదు, మా క్రేజీ కాంప్లికేటెడ్ న్యూరల్ నెట్‌వర్క్ ఖర్చు 

89
00:05:47,240 --> 00:05:51,080
ఫంక్షన్ కోసం ఈ పరిస్థితి యొక్క 13,000 ఇన్‌పుట్ వెర్షన్‌లో ఖచ్చితంగా కాదు.

90
00:05:51,580 --> 00:05:55,503
ఏదైనా ఇన్‌పుట్‌లో ప్రారంభించడం మరియు ఆ అవుట్‌పుట్ తక్కువగా చేయడానికి 

91
00:05:55,503 --> 00:05:59,200
మీరు ఏ దిశలో అడుగు పెట్టాలో గుర్తించడం మరింత సౌకర్యవంతమైన వ్యూహం.

92
00:06:00,080 --> 00:06:03,927
ప్రత్యేకించి, మీరు ఉన్న ఫంక్షన్ యొక్క వాలును మీరు గుర్తించగలిగితే, 

93
00:06:03,927 --> 00:06:08,751
ఆ వాలు సానుకూలంగా ఉంటే ఎడమవైపుకు మార్చండి మరియు ఆ వాలు ప్రతికూలంగా ఉంటే ఇన్‌పుట్‌ను 

94
00:06:08,751 --> 00:06:09,900
కుడివైపుకి మార్చండి.

95
00:06:11,960 --> 00:06:15,633
మీరు దీన్ని పదేపదే చేస్తే, ప్రతి పాయింట్‌లో కొత్త వాలును తనిఖీ చేసి, 

96
00:06:15,633 --> 00:06:19,840
తగిన దశను తీసుకుంటే, మీరు ఫంక్షన్‌లో కొంత స్థానిక కనిష్టాన్ని చేరుకోబోతున్నారు.

97
00:06:20,640 --> 00:06:23,800
ఇక్కడ మీ మనస్సులో ఉన్న చిత్రం కొండపై నుండి దొర్లుతున్న బంతి.

98
00:06:24,620 --> 00:06:28,245
గమనించండి, ఈ నిజంగా సరళీకృతమైన సింగిల్ ఇన్‌పుట్ ఫంక్షన్‌కి కూడా, 

99
00:06:28,245 --> 00:06:31,591
మీరు ఏ యాదృచ్ఛిక ఇన్‌పుట్‌ను ప్రారంభించాలనే దానిపై ఆధారపడి, 

100
00:06:31,591 --> 00:06:36,499
మీరు ల్యాండింగ్ చేయగల అనేక లోయలు ఉన్నాయి మరియు మీరు దిగిన స్థానిక కనీస విలువ సాధ్యమైనంత 

101
00:06:36,499 --> 00:06:39,400
చిన్నదిగా ఉంటుందని ఎటువంటి హామీ లేదు. ఖర్చు ఫంక్షన్.

102
00:06:40,220 --> 00:06:42,620
అది మన న్యూరల్ నెట్‌వర్క్ కేసుకు కూడా తీసుకువెళుతుంది.

103
00:06:43,180 --> 00:06:45,872
మీరు మీ దశల పరిమాణాలను వాలుకు అనులోమానుపాతంలో చేస్తే, 

104
00:06:45,872 --> 00:06:49,762
వాలు కనిష్ట స్థాయికి చదునుగా ఉన్నప్పుడు, మీ అడుగులు చిన్నవిగా మరియు చిన్నవిగా 

105
00:06:49,762 --> 00:06:53,552
ఉంటాయి మరియు అది ఓవర్‌షూట్ నుండి మీకు ఎలా సహాయపడుతుందో కూడా మీరు గమనించాలని 

106
00:06:53,552 --> 00:06:54,600
నేను కోరుకుంటున్నాను.

107
00:06:55,940 --> 00:06:58,684
సంక్లిష్టతను కొంచెం పెంచుతూ, బదులుగా రెండు ఇన్‌పుట్‌లు 

108
00:06:58,684 --> 00:07:00,980
మరియు ఒక అవుట్‌పుట్‌తో ఫంక్షన్‌ను ఊహించుకోండి.

109
00:07:01,500 --> 00:07:04,790
మీరు ఇన్‌పుట్ స్పేస్‌ను xy-ప్లేన్‌గా భావించవచ్చు మరియు 

110
00:07:04,790 --> 00:07:08,140
ఖర్చు ఫంక్షన్ దాని పైన ఉపరితలంగా గ్రాఫ్ చేయబడి ఉండవచ్చు.

111
00:07:08,760 --> 00:07:13,795
ఫంక్షన్ యొక్క వాలు గురించి అడగడానికి బదులుగా, మీరు ఈ ఇన్‌పుట్ స్థలంలో ఏ దిశలో 

112
00:07:13,795 --> 00:07:18,960
అడుగు పెట్టాలని అడగాలి, తద్వారా ఫంక్షన్ యొక్క అవుట్‌పుట్ చాలా త్వరగా తగ్గుతుంది.

113
00:07:19,720 --> 00:07:21,760
మరో మాటలో చెప్పాలంటే, లోతువైపు దిశ ఏమిటి?

114
00:07:22,380 --> 00:07:25,560
మళ్ళీ, ఆ కొండపై నుండి ఒక బంతిని రోలింగ్ చేయడం గురించి ఆలోచించడం ఉపయోగకరంగా ఉంటుంది.

115
00:07:26,660 --> 00:07:29,927
మీలో మల్టీవియరబుల్ కాలిక్యులస్ గురించి తెలిసిన వారికి, 

116
00:07:29,927 --> 00:07:33,908
ఫంక్షన్ యొక్క గ్రేడియంట్ మీకు ఏటవాలుగా ఉన్న ఆరోహణ దిశను ఇస్తుందని, 

117
00:07:33,908 --> 00:07:38,780
మీరు ఫంక్షన్‌ను అత్యంత వేగంగా పెంచడానికి ఏ దిశలో అడుగు పెట్టాలి అని తెలుసుకుంటారు.

118
00:07:39,560 --> 00:07:42,656
సహజంగానే తగినంత, ఆ ప్రవణత యొక్క ప్రతికూలతను తీసుకోవడం 

119
00:07:42,656 --> 00:07:46,040
వలన ఫంక్షన్‌ను చాలా త్వరగా తగ్గించే దశకు దిశను అందిస్తుంది.

120
00:07:47,240 --> 00:07:50,437
దాని కంటే ఎక్కువగా, ఈ గ్రేడియంట్ వెక్టర్ యొక్క 

121
00:07:50,437 --> 00:07:53,840
పొడవు ఆ ఏటవాలు వాలు ఎంత నిటారుగా ఉందో సూచిస్తుంది.

122
00:07:54,540 --> 00:07:57,961
మీకు మల్టీవియరబుల్ కాలిక్యులస్ గురించి తెలియకపోతే మరియు మరింత తెలుసుకోవాలనుకుంటే, 

123
00:07:57,961 --> 00:08:00,340
ఈ అంశంపై ఖాన్ అకాడమీ కోసం నేను చేసిన కొన్ని పనిని చూడండి.

124
00:08:00,860 --> 00:08:04,631
నిజాయితీగా చెప్పాలంటే, ప్రస్తుతం మీకు మరియు నాకు ముఖ్యమైనది ఏమిటంటే, 

125
00:08:04,631 --> 00:08:07,691
సూత్రప్రాయంగా ఈ వెక్టార్‌ను గణించడానికి ఒక మార్గం ఉంది, 

126
00:08:07,691 --> 00:08:11,900
ఈ వెక్టర్ లోతువైపు దిశ ఏమిటో మరియు అది ఎంత నిటారుగా ఉందో మీకు తెలియజేస్తుంది.

127
00:08:12,400 --> 00:08:16,120
మీకు తెలిసినంత మాత్రాన మీరు బాగానే ఉంటారు మరియు వివరాలపై మీరు గట్టిగా ఉండకపోతే.

128
00:08:17,200 --> 00:08:22,000
మీరు దానిని పొందగలిగితే, ఫంక్షన్‌ను కనిష్టీకరించడానికి అల్గోరిథం ఈ గ్రేడియంట్ 

129
00:08:22,000 --> 00:08:26,740
దిశను గణించడం, ఆపై ఒక చిన్న అడుగు లోతువైపు వేసి, మళ్లీ మళ్లీ పునరావృతం చేయడం.

130
00:08:27,700 --> 00:08:32,820
2 ఇన్‌పుట్‌లకు బదులుగా 13,000 ఇన్‌పుట్‌లను కలిగి ఉన్న ఫంక్షన్‌కి ఇది అదే ప్రాథమిక ఆలోచన.

131
00:08:33,400 --> 00:08:36,430
మా నెట్‌వర్క్‌లోని మొత్తం 13,000 బరువులు మరియు పక్షపాతాలను 

132
00:08:36,430 --> 00:08:39,460
ఒక జెయింట్ కాలమ్ వెక్టర్‌గా నిర్వహించడం గురించి ఆలోచించండి.

133
00:08:40,140 --> 00:08:44,259
కాస్ట్ ఫంక్షన్ యొక్క నెగటివ్ గ్రేడియంట్ అనేది వెక్టార్ మాత్రమే, 

134
00:08:44,259 --> 00:08:47,928
ఇది ఈ అతి పెద్ద ఇన్‌పుట్ స్పేస్‌లోని కొంత దిశలో ఉంటుంది, 

135
00:08:47,928 --> 00:08:52,755
ఇది ఆ సంఖ్యలన్నింటికీ ఏ నడ్జ్‌లు కాస్ట్ ఫంక్షన్‌లో అత్యంత వేగంగా తగ్గుదలని 

136
00:08:52,755 --> 00:08:54,880
కలిగిస్తుందో మీకు తెలియజేస్తుంది.

137
00:08:55,640 --> 00:08:59,134
మరియు వాస్తవానికి, మా ప్రత్యేకంగా రూపొందించిన ఖర్చు ఫంక్షన్‌తో, 

138
00:08:59,134 --> 00:09:02,793
బరువులు మరియు పక్షపాతాలను తగ్గించడానికి మార్చడం అంటే ప్రతి శిక్షణా 

139
00:09:02,793 --> 00:09:06,560
డేటాపై నెట్‌వర్క్ అవుట్‌పుట్ 10 విలువల యాదృచ్ఛిక శ్రేణి వలె తక్కువగా 

140
00:09:06,560 --> 00:09:10,820
కనిపించేలా చేయడం మరియు మనకు కావలసిన వాస్తవ నిర్ణయం వలె ఉంటుంది. అది చేయడానికి.

141
00:09:11,440 --> 00:09:16,056
గుర్తుంచుకోవడం ముఖ్యం, ఈ ఖర్చు ఫంక్షన్ మొత్తం శిక్షణ డేటాపై సగటును కలిగి ఉంటుంది, 

142
00:09:16,056 --> 00:09:20,842
కాబట్టి మీరు దానిని కనిష్టీకరించినట్లయితే, ఆ నమూనాలన్నింటిలో ఇది మెరుగైన పనితీరు అని 

143
00:09:20,842 --> 00:09:21,180
అర్థం.

144
00:09:23,820 --> 00:09:26,611
ఈ గ్రేడియంట్‌ను సమర్ధవంతంగా కంప్యూటింగ్ చేయడానికి అల్గోరిథం, 

145
00:09:26,611 --> 00:09:30,181
ఇది ఒక న్యూరల్ నెట్‌వర్క్ ఎలా నేర్చుకుంటుంది అనేదానికి ప్రభావవంతంగా గుండెకాయ, 

146
00:09:30,181 --> 00:09:33,980
దీనిని బ్యాక్‌ప్రొపగేషన్ అంటారు మరియు నేను తదుపరి వీడియో గురించి మాట్లాడబోతున్నాను.

147
00:09:34,660 --> 00:09:37,825
అక్కడ, నేను నిజంగా శిక్షణ డేటా యొక్క ప్రతి భాగం కోసం ప్రతి బరువు మరియు 

148
00:09:37,825 --> 00:09:41,571
పక్షపాతంతో సరిగ్గా ఏమి జరుగుతుందో తెలుసుకోవడానికి సమయాన్ని వెచ్చించాలనుకుంటున్నాను, 

149
00:09:41,571 --> 00:09:44,692
సంబంధిత కాలిక్యులస్ మరియు ఫార్ములాల కుప్పకు మించి ఏమి జరుగుతుందో దాని 

150
00:09:44,692 --> 00:09:47,100
గురించి స్పష్టమైన అనుభూతిని ఇవ్వడానికి ప్రయత్నిస్తాను.

151
00:09:47,780 --> 00:09:51,002
ఇక్కడే, ప్రస్తుతం, మీరు తెలుసుకోవలసిన ప్రధాన విషయం ఏమిటంటే, 

152
00:09:51,002 --> 00:09:54,385
అమలు వివరాలతో సంబంధం లేకుండా, మనం నెట్‌వర్క్ లెర్నింగ్ గురించి 

153
00:09:54,385 --> 00:09:58,360
మాట్లాడేటప్పుడు మనం అర్థం చేసుకునేది అది కేవలం ఖర్చు ఫంక్షన్‌ను తగ్గించడం.

154
00:09:59,300 --> 00:10:01,434
మరియు గమనించండి, దాని యొక్క ఒక పర్యవసానమేమిటంటే, 

155
00:10:01,434 --> 00:10:04,614
ఈ ఖర్చు ఫంక్షన్‌కు చక్కని మృదువైన అవుట్‌పుట్‌ను కలిగి ఉండటం చాలా ముఖ్యం, 

156
00:10:04,614 --> 00:10:08,100
తద్వారా మేము దిగువకు చిన్న అడుగులు వేయడం ద్వారా స్థానిక కనిష్టాన్ని కనుగొనవచ్చు.

157
00:10:09,260 --> 00:10:14,136
అందుకే, కృత్రిమ న్యూరాన్‌లు జీవసంబంధమైన న్యూరాన్‌ల మాదిరిగానే బైనరీ మార్గంలో 

158
00:10:14,136 --> 00:10:19,140
చురుకుగా లేదా క్రియారహితంగా ఉండకుండా, నిరంతరం శ్రేణి క్రియాశీలతను కలిగి ఉంటాయి.

159
00:10:20,220 --> 00:10:23,704
ప్రతికూల ప్రవణత యొక్క కొన్ని గుణిజాలతో ఫంక్షన్ యొక్క ఇన్‌పుట్‌ను 

160
00:10:23,704 --> 00:10:26,760
పదేపదే నడ్జ్ చేసే ఈ ప్రక్రియను గ్రేడియంట్ డీసెంట్ అంటారు.

161
00:10:27,300 --> 00:10:32,580
ఇది ప్రాథమికంగా ఈ గ్రాఫ్‌లోని లోయలో కొంత స్థానిక కనిష్ట ధర ఫంక్షన్‌కి కలుస్తుంది.

162
00:10:33,440 --> 00:10:36,741
నేను ఇప్పటికీ రెండు ఇన్‌పుట్‌లతో ఫంక్షన్ యొక్క చిత్రాన్ని చూపుతున్నాను, 

163
00:10:36,741 --> 00:10:40,546
ఎందుకంటే 13,000 డైమెన్షనల్ ఇన్‌పుట్ స్పేస్‌లోని నడ్జ్‌లు మీ మనస్సును చుట్టుముట్టడం 

164
00:10:40,546 --> 00:10:44,260
కొంచెం కష్టం, కానీ దీని గురించి ఆలోచించడానికి ఒక మంచి నాన్-స్పేషియల్ మార్గం ఉంది.

165
00:10:45,080 --> 00:10:48,440
ప్రతికూల ప్రవణత యొక్క ప్రతి భాగం మనకు రెండు విషయాలను చెబుతుంది.

166
00:10:49,060 --> 00:10:52,054
ఇన్‌పుట్ వెక్టార్ యొక్క సంబంధిత కాంపోనెంట్‌ను పైకి లేదా క్రిందికి 

167
00:10:52,054 --> 00:10:55,140
నడ్జ్ చేయాలా వద్దా అనే విషయాన్ని గుర్తు, వాస్తవానికి తెలియజేస్తుంది.

168
00:10:55,800 --> 00:10:59,326
కానీ ముఖ్యంగా, ఈ అన్ని భాగాల యొక్క సాపేక్ష పరిమాణాలు 

169
00:10:59,326 --> 00:11:02,720
ఏ మార్పులు మరింత ముఖ్యమైనవి అని మీకు తెలియజేస్తాయి.

170
00:11:05,220 --> 00:11:08,953
మీరు చూస్తారు, మా నెట్‌వర్క్‌లో, కొన్ని ఇతర బరువులకు సర్దుబాటు చేయడం కంటే 

171
00:11:08,953 --> 00:11:13,040
బరువులలో ఒకదానికి సర్దుబాటు చేయడం ధర పనితీరుపై చాలా ఎక్కువ ప్రభావాన్ని చూపుతుంది.

172
00:11:14,800 --> 00:11:18,200
ఈ కనెక్షన్‌లలో కొన్ని మా శిక్షణ డేటాకు మరింత ముఖ్యమైనవి.

173
00:11:19,320 --> 00:11:23,816
కాబట్టి మీరు మా మైండ్-వార్పింగ్‌గా భారీ వ్యయ ఫంక్షన్ యొక్క ఈ గ్రేడియంట్ వెక్టర్ గురించి 

174
00:11:23,816 --> 00:11:28,108
ఆలోచించగల మార్గం ఏమిటంటే, ఇది ప్రతి బరువు మరియు పక్షపాతం యొక్క సాపేక్ష ప్రాముఖ్యతను 

175
00:11:28,108 --> 00:11:32,400
ఎన్కోడ్ చేస్తుంది, అంటే, ఈ మార్పులలో ఏది మీ బక్ కోసం ఎక్కువ బ్యాంగ్ తీసుకువెళుతుంది.

176
00:11:33,620 --> 00:11:36,640
ఇది నిజంగా దిశ గురించి ఆలోచించే మరొక మార్గం.

177
00:11:37,100 --> 00:11:42,107
సరళమైన ఉదాహరణను తీసుకుంటే, మీరు ఇన్‌పుట్‌గా రెండు వేరియబుల్స్‌తో కొంత ఫంక్షన్‌ను 

178
00:11:42,107 --> 00:11:47,361
కలిగి ఉంటే, మరియు మీరు నిర్దిష్ట పాయింట్‌లో దాని గ్రేడియంట్ 3,1గా వస్తుందని గణిస్తే, 

179
00:11:47,361 --> 00:11:52,307
ఒక వైపు మీరు దానిని మీరు చెప్పినట్లు అర్థం చేసుకోవచ్చు. ఆ ఇన్‌పుట్ వద్ద నిలబడి, 

180
00:11:52,307 --> 00:11:55,583
ఈ దిశలో కదలడం వలన ఫంక్షన్‌ని చాలా త్వరగా పెంచుతుంది, 

181
00:11:55,583 --> 00:11:59,601
మీరు ఇన్‌పుట్ పాయింట్ల విమానం పైన ఫంక్షన్‌ను గ్రాఫ్ చేసినప్పుడు, 

182
00:11:59,601 --> 00:12:02,260
ఆ వెక్టార్ మీకు నేరుగా పైకి దిశను ఇస్తుంది.

183
00:12:02,860 --> 00:12:07,093
కానీ దానిని చదవడానికి మరొక మార్గం ఏమిటంటే, ఈ మొదటి వేరియబుల్‌కు మార్పులు రెండవ 

184
00:12:07,093 --> 00:12:10,951
వేరియబుల్‌కు మార్పుల కంటే 3 రెట్లు ప్రాముఖ్యతను కలిగి ఉన్నాయని చెప్పడం, 

185
00:12:10,951 --> 00:12:15,345
కనీసం సంబంధిత ఇన్‌పుట్ పరిసరాల్లో, x-విలువను నడ్జ్ చేయడం వల్ల మీ కోసం చాలా ఎక్కువ 

186
00:12:15,345 --> 00:12:16,900
బ్యాంగ్‌ను కలిగి ఉంటుంది. బక్

187
00:12:19,880 --> 00:12:22,340
జూమ్ అవుట్ చేసి, ఇప్పటివరకు మనం ఎక్కడ ఉన్నామో సంక్షిప్తం చేద్దాం.

188
00:12:22,840 --> 00:12:27,207
నెట్‌వర్క్ అనేది 784 ఇన్‌పుట్‌లు మరియు 10 అవుట్‌పుట్‌లతో కూడిన ఈ ఫంక్షన్, 

189
00:12:27,207 --> 00:12:30,040
ఈ మొత్తం వెయిటెడ్ మొత్తాల పరంగా నిర్వచించబడింది.

190
00:12:30,640 --> 00:12:33,680
ఖర్చు ఫంక్షన్ దాని పైన సంక్లిష్టత యొక్క పొర.

191
00:12:33,980 --> 00:12:37,942
ఇది 13,000 బరువులు మరియు పక్షపాతాలను ఇన్‌పుట్‌లుగా తీసుకుంటుంది 

192
00:12:37,942 --> 00:12:41,720
మరియు శిక్షణా ఉదాహరణల ఆధారంగా ఒకే కొలమానాన్ని ఉమ్మివేస్తుంది.

193
00:12:42,440 --> 00:12:46,900
మరియు వ్యయ ఫంక్షన్ యొక్క గ్రేడియంట్ ఇప్పటికీ సంక్లిష్టత యొక్క మరొక పొర.

194
00:12:47,360 --> 00:12:50,712
ఈ అన్ని బరువులు మరియు పక్షపాతాలు ధర ఫంక్షన్ యొక్క విలువలో 

195
00:12:50,712 --> 00:12:54,007
వేగవంతమైన మార్పుకు కారణమయ్యే వాటిని మాకు తెలియజేస్తుంది, 

196
00:12:54,007 --> 00:12:57,880
ఇది మీరు ఏ బరువులకు అత్యంత ముఖ్యమైన మార్పులు అని అర్థం చేసుకోవచ్చు.

197
00:13:02,560 --> 00:13:06,450
కాబట్టి, మీరు యాదృచ్ఛిక బరువులు మరియు పక్షపాతాలతో నెట్‌వర్క్‌ను ప్రారంభించినప్పుడు 

198
00:13:06,450 --> 00:13:10,387
మరియు ఈ గ్రేడియంట్ అవరోహణ ప్రక్రియ ఆధారంగా వాటిని చాలాసార్లు సర్దుబాటు చేసినప్పుడు, 

199
00:13:10,387 --> 00:13:13,200
ఇది ఇంతకు ముందెన్నడూ చూడని చిత్రాలపై ఎంత బాగా పని చేస్తుంది?

200
00:13:14,100 --> 00:13:18,293
నేను ఇక్కడ వివరించినది, 16 న్యూరాన్‌ల యొక్క రెండు దాచిన పొరలతో, 

201
00:13:18,293 --> 00:13:22,487
ఎక్కువగా సౌందర్య కారణాల కోసం ఎంపిక చేయబడింది, ఇది చెడ్డది కాదు, 

202
00:13:22,487 --> 00:13:25,960
ఇది సరిగ్గా చూసే 96% కొత్త చిత్రాలను వర్గీకరిస్తుంది.

203
00:13:26,680 --> 00:13:30,483
మరియు నిజాయితీగా, మీరు అది గందరగోళానికి గురిచేసే కొన్ని ఉదాహరణలను చూస్తే, 

204
00:13:30,483 --> 00:13:32,540
మీరు దానిని కొంచెం మందగించవలసి వస్తుంది.

205
00:13:36,220 --> 00:13:38,858
ఇప్పుడు మీరు దాచిన లేయర్ స్ట్రక్చర్‌తో ప్లే చేసి, 

206
00:13:38,858 --> 00:13:41,760
రెండు ట్వీక్‌లు చేస్తే, మీరు దీన్ని 98% వరకు పొందవచ్చు.

207
00:13:41,760 --> 00:13:42,720
మరియు అది చాలా బాగుంది!

208
00:13:43,020 --> 00:13:47,438
ఇది ఉత్తమమైనది కాదు, మీరు ఈ సాదా వెనీలా నెట్‌వర్క్ కంటే మరింత అధునాతనంగా ఉండటం 

209
00:13:47,438 --> 00:13:52,024
ద్వారా ఖచ్చితంగా మెరుగైన పనితీరును పొందవచ్చు, కానీ ప్రారంభ పని ఎంత నిరుత్సాహకరంగా 

210
00:13:52,024 --> 00:13:56,442
ఉందో చూస్తే, ఏ నెట్‌వర్క్ ఇంతకు ముందెన్నడూ చూడని చిత్రాలపై దీన్ని బాగా చేయడంలో 

211
00:13:56,442 --> 00:14:01,420
అద్భుతమైన ఏదో ఉందని నేను భావిస్తున్నాను. ఏ నమూనాల కోసం చూడాలో మేము ప్రత్యేకంగా చెప్పలేదు.

212
00:14:02,560 --> 00:14:05,640
నిజానికి, నేను ఈ నిర్మాణాన్ని ప్రేరేపించిన విధానం ఏమిటంటే, 

213
00:14:05,640 --> 00:14:09,713
మనం కలిగి ఉండగల ఒక ఆశను వివరించడం ద్వారా, రెండవ పొర చిన్న అంచులపైకి ఎదగవచ్చు, 

214
00:14:09,713 --> 00:14:13,420
మూడవ పొర లూప్‌లు మరియు పొడవైన పంక్తులను గుర్తించడానికి ఆ అంచులను ఒకచోట 

215
00:14:13,420 --> 00:14:17,180
చేర్చుతుంది మరియు వాటిని ముక్కలు చేయవచ్చు. అంకెలను గుర్తించడానికి కలిసి.

216
00:14:17,960 --> 00:14:20,400
నిజానికి మన నెట్‌వర్క్ చేస్తున్నది ఇదేనా?

217
00:14:21,079 --> 00:14:24,400
సరే, దీని కోసం కనీసం, అస్సలు కాదు.

218
00:14:24,820 --> 00:14:28,586
మొదటి లేయర్‌లోని అన్ని న్యూరాన్‌ల నుండి రెండవ లేయర్‌లోని ఇచ్చిన 

219
00:14:28,586 --> 00:14:32,705
న్యూరాన్‌కి కనెక్షన్‌ల బరువులు రెండవ లేయర్ న్యూరాన్ పొందుతున్న ఇచ్చిన 

220
00:14:32,705 --> 00:14:37,060
పిక్సెల్ నమూనాగా ఎలా విజువలైజ్ చేయబడతాయో మనం చివరిగా ఎలా చూశామో గుర్తుందా?

221
00:14:37,780 --> 00:14:42,203
సరే, ఈ పరివర్తనలతో అనుబంధించబడిన బరువుల కోసం మనం నిజంగా చేసినప్పుడు, 

222
00:14:42,203 --> 00:14:47,268
మొదటి లేయర్ నుండి తదుపరి వరకు, ఇక్కడ మరియు అక్కడక్కడ వేరుచేయబడిన చిన్న అంచులను 

223
00:14:47,268 --> 00:14:50,666
ఎంచుకునే బదులు, అవి దాదాపు యాదృచ్ఛికంగా కనిపిస్తాయి, 

224
00:14:50,666 --> 00:14:53,680
కొన్ని చాలా వదులుగా ఉండే నమూనాలతో అక్కడ మధ్యలో.

225
00:14:53,760 --> 00:14:58,340
13,000 డైమెన్షనల్ స్పేస్‌లో సాధ్యమయ్యే బరువులు మరియు పక్షపాతాలతో, 

226
00:14:58,340 --> 00:15:02,574
మా నెట్‌వర్క్ చాలా చిత్రాలను విజయవంతంగా వర్గీకరించినప్పటికీ, 

227
00:15:02,574 --> 00:15:07,433
మనం ఆశించిన నమూనాలను సరిగ్గా అందుకోలేనంత సంతోషకరమైన స్థానిక కనిష్టంగా 

228
00:15:07,433 --> 00:15:08,960
ఉన్నట్లు అనిపిస్తుంది.

229
00:15:09,780 --> 00:15:11,477
మరియు నిజంగా ఈ పాయింట్‌ని ఇంటికి తీసుకెళ్లడానికి, 

230
00:15:11,477 --> 00:15:13,820
మీరు యాదృచ్ఛిక చిత్రాన్ని ఇన్‌పుట్ చేసినప్పుడు ఏమి జరుగుతుందో చూడండి.

231
00:15:14,320 --> 00:15:18,522
సిస్టమ్ స్మార్ట్‌గా ఉంటే, అది అనిశ్చితంగా ఉంటుందని మీరు ఆశించవచ్చు, 

232
00:15:18,522 --> 00:15:23,591
బహుశా ఆ 10 అవుట్‌పుట్ న్యూరాన్‌లలో దేనినైనా సక్రియం చేయకపోవచ్చు లేదా వాటన్నింటిని 

233
00:15:23,591 --> 00:15:28,535
సమానంగా యాక్టివేట్ చేయకపోవచ్చు, కానీ బదులుగా ఇది మీకు నమ్మకంగా కొన్ని అర్ధంలేని 

234
00:15:28,535 --> 00:15:32,243
సమాధానం ఇస్తుంది, ఈ యాదృచ్ఛిక శబ్దం ఖచ్చితంగా అనిపిస్తుంది. 

235
00:15:32,243 --> 00:15:34,160
5 అంటే 5 యొక్క వాస్తవ చిత్రం 5.

236
00:15:34,540 --> 00:15:38,439
విభిన్న పదజాలంతో, ఈ నెట్‌వర్క్ అంకెలను చక్కగా గుర్తించగలిగినప్పటికీ, 

237
00:15:38,439 --> 00:15:40,700
వాటిని ఎలా గీయాలి అనే ఆలోచన దీనికి లేదు.

238
00:15:41,420 --> 00:15:45,240
ఇది చాలా కఠినంగా నిర్బంధించబడిన శిక్షణా సెటప్ కాబట్టి.

239
00:15:45,880 --> 00:15:47,740
నా ఉద్దేశ్యం, ఇక్కడ నెట్‌వర్క్ షూస్‌లో మిమ్మల్ని మీరు ఉంచుకోండి.

240
00:15:48,140 --> 00:15:52,491
దాని దృక్కోణం నుండి, మొత్తం విశ్వం ఒక చిన్న గ్రిడ్‌లో కేంద్రీకృతమై స్పష్టంగా 

241
00:15:52,491 --> 00:15:56,672
నిర్వచించబడిన కదలని అంకెలు తప్ప మరేమీ కలిగి ఉండదు మరియు దాని వ్యయ పనితీరు 

242
00:15:56,672 --> 00:16:01,080
దాని నిర్ణయాలపై పూర్తిగా నమ్మకంగా ఉండేందుకు ఎటువంటి ప్రోత్సాహాన్ని అందించలేదు.

243
00:16:02,120 --> 00:16:05,248
కాబట్టి ఆ రెండవ పొర న్యూరాన్‌లు నిజంగా ఏమి చేస్తున్నాయో దాని చిత్రంగా, 

244
00:16:05,248 --> 00:16:09,038
అంచులు మరియు నమూనాలను తీయడానికి ప్రేరణతో నేను ఈ నెట్‌వర్క్‌ను ఎందుకు పరిచయం చేస్తానని 

245
00:16:09,038 --> 00:16:09,920
మీరు ఆశ్చర్యపోవచ్చు.

246
00:16:09,920 --> 00:16:12,300
నా ఉద్దేశ్యం, అది పూర్తి చేసేది కాదు.

247
00:16:13,380 --> 00:16:17,180
సరే, ఇది మా అంతిమ లక్ష్యం కాదు, బదులుగా ఒక ప్రారంభ స్థానం.

248
00:16:17,640 --> 00:16:20,998
స్పష్టముగా, ఇది పాత సాంకేతికత, 80 మరియు 90 లలో పరిశోధించబడిన రకం, 

249
00:16:20,998 --> 00:16:25,375
మరియు మీరు మరింత వివరణాత్మక ఆధునిక రూపాంతరాలను అర్థం చేసుకునే ముందు మీరు దానిని అర్థం 

250
00:16:25,375 --> 00:16:29,192
చేసుకోవాలి మరియు ఇది స్పష్టంగా కొన్ని ఆసక్తికరమైన సమస్యలను పరిష్కరించగలదు, 

251
00:16:29,192 --> 00:16:32,958
కానీ మీరు దేని గురించి మరింత తవ్వుతారు ఆ దాచిన పొరలు నిజంగా చేస్తున్నాయి, 

252
00:16:32,958 --> 00:16:34,740
తక్కువ తెలివితేటలు కనిపిస్తున్నాయి.

253
00:16:38,480 --> 00:16:40,757
నెట్‌వర్క్‌లు ఎలా నేర్చుకుంటాయనే దాని నుండి మీరు ఎలా 

254
00:16:40,757 --> 00:16:42,948
నేర్చుకుంటారు అనేదానికి ఫోకస్‌ని ఒక క్షణం మార్చడం, 

255
00:16:42,948 --> 00:16:46,300
మీరు ఏదో ఒకవిధంగా ఇక్కడ ఉన్న మెటీరియల్‌తో చురుకుగా పాల్గొంటేనే అది జరుగుతుంది.

256
00:16:47,060 --> 00:16:49,743
మీరు చేయాలనుకుంటున్న ఒక అందమైన సాధారణ విషయం ఏమిటంటే, 

257
00:16:49,743 --> 00:16:53,235
ఇప్పుడే పాజ్ చేయండి మరియు మీరు ఈ సిస్టమ్‌లో ఎలాంటి మార్పులు చేయవచ్చు 

258
00:16:53,235 --> 00:16:56,475
మరియు అంచులు మరియు నమూనాల వంటి వాటిని మెరుగ్గా ఎంచుకోవాలని మీరు 

259
00:16:56,475 --> 00:17:00,880
కోరుకుంటే అది చిత్రాలను ఎలా గ్రహిస్తుంది అనే దాని గురించి ఒక్క క్షణం లోతుగా ఆలోచించండి.

260
00:17:01,479 --> 00:17:04,527
కానీ దాని కంటే మెరుగ్గా, వాస్తవానికి మెటీరియల్‌తో నిమగ్నమవ్వడానికి, 

261
00:17:04,527 --> 00:17:08,517
లోతైన అభ్యాసం మరియు న్యూరల్ నెట్‌వర్క్‌లపై మైఖేల్ నీల్సన్ పుస్తకాన్ని నేను బాగా సిఫార్సు 

262
00:17:08,517 --> 00:17:09,099
చేస్తున్నాను.

263
00:17:09,680 --> 00:17:13,844
దీనిలో, మీరు ఈ ఖచ్చితమైన ఉదాహరణ కోసం డౌన్‌లోడ్ చేయడానికి మరియు ప్లే చేయడానికి కోడ్ 

264
00:17:13,844 --> 00:17:18,359
మరియు డేటాను కనుగొనవచ్చు మరియు పుస్తకం ఆ కోడ్ ఏమి చేస్తుందో దశలవారీగా మీకు తెలియజేస్తుంది.

265
00:17:19,300 --> 00:17:22,736
అద్భుతం ఏమిటంటే, ఈ పుస్తకం ఉచితం మరియు పబ్లిక్‌గా అందుబాటులో ఉంది, 

266
00:17:22,736 --> 00:17:27,044
కాబట్టి మీరు దాని నుండి ఏదైనా పొందినట్లయితే, నీల్సన్ ప్రయత్నాల కోసం విరాళం ఇవ్వడంలో 

267
00:17:27,044 --> 00:17:27,660
నాతో చేరండి.

268
00:17:27,660 --> 00:17:32,254
నేను క్రిస్ ఓలా యొక్క అద్భుతమైన మరియు అందమైన బ్లాగ్ పోస్ట్ మరియు డిస్టిల్‌లోని 

269
00:17:32,254 --> 00:17:36,500
కథనాలతో సహా వివరణలో నాకు చాలా నచ్చిన రెండు ఇతర వనరులను కూడా లింక్ చేసాను.

270
00:17:38,280 --> 00:17:40,390
గత కొన్ని నిమిషాలు ఇక్కడ విషయాలను మూసివేయడానికి, 

271
00:17:40,390 --> 00:17:43,880
నేను లీషా లీతో చేసిన ఇంటర్వ్యూ యొక్క స్నిప్పెట్‌లోకి తిరిగి వెళ్లాలనుకుంటున్నాను.

272
00:17:44,300 --> 00:17:47,720
చివరి వీడియో నుండి మీరు ఆమెను గుర్తుంచుకోవచ్చు, ఆమె లోతైన అభ్యాసంలో ఆమె PhD పని చేసింది.

273
00:17:48,300 --> 00:17:52,108
ఈ చిన్న స్నిప్పెట్‌లో ఆమె కొన్ని ఆధునిక ఇమేజ్ రికగ్నిషన్ నెట్‌వర్క్‌లు వాస్తవానికి 

274
00:17:52,108 --> 00:17:55,780
ఎలా నేర్చుకుంటున్నాయో నిజంగా త్రవ్విన రెండు ఇటీవలి పేపర్ల గురించి మాట్లాడుతుంది.

275
00:17:56,120 --> 00:18:00,310
మేము సంభాషణలో ఉన్న చోట సెటప్ చేయడానికి, మొదటి పేపర్ ఇమేజ్ రికగ్నిషన్‌లో నిజంగా మంచి ఈ 

276
00:18:00,310 --> 00:18:04,598
డీప్ న్యూరల్ నెట్‌వర్క్‌లలో ఒకదాన్ని తీసుకుంది మరియు సరిగ్గా లేబుల్ చేయబడిన డేటాసెట్‌లో 

277
00:18:04,598 --> 00:18:08,740
శిక్షణ ఇవ్వడానికి బదులుగా, శిక్షణకు ముందు చుట్టూ ఉన్న అన్ని లేబుల్‌లను షఫుల్ చేసింది.

278
00:18:09,480 --> 00:18:12,940
సహజంగానే ఇక్కడ టెస్టింగ్ ఖచ్చితత్వం యాదృచ్ఛికం కంటే మెరుగైనది కాదు, 

279
00:18:12,940 --> 00:18:15,383
ఎందుకంటే ప్రతిదీ యాదృచ్ఛికంగా లేబుల్ చేయబడింది, 

280
00:18:15,383 --> 00:18:19,455
కానీ సరిగ్గా లేబుల్ చేయబడిన డేటాసెట్‌లో మీరు సాధించిన అదే శిక్షణ ఖచ్చితత్వాన్ని 

281
00:18:19,455 --> 00:18:20,880
ఇది ఇప్పటికీ సాధించగలిగింది.

282
00:18:21,600 --> 00:18:26,295
ప్రాథమికంగా, ఈ నిర్దిష్ట నెట్‌వర్క్‌కు మిలియన్ల బరువులు కేవలం యాదృచ్ఛిక డేటాను 

283
00:18:26,295 --> 00:18:31,228
గుర్తుంచుకోవడానికి సరిపోతాయి, ఈ ఖర్చు ఫంక్షన్‌ను తగ్గించడం అనేది చిత్రంలో ఏ విధమైన 

284
00:18:31,228 --> 00:18:36,400
నిర్మాణానికి అనుగుణంగా ఉంటుందా అనే ప్రశ్నను లేవనెత్తుతుంది లేదా ఇది కేవలం జ్ఞాపకం ఉందా?

285
00:18:51,440 --> 00:18:56,525
మీరు ఆ ఖచ్చితత్వ వక్రతను పరిశీలిస్తే, మీరు కేవలం యాదృచ్ఛిక డేటాసెట్‌లో 

286
00:18:56,525 --> 00:19:02,470
శిక్షణ పొందుతున్నట్లయితే, ఆ వక్రరేఖ దాదాపు సరళ పద్ధతిలో చాలా నెమ్మదిగా తగ్గుతుంది, 

287
00:19:02,470 --> 00:19:08,128
కాబట్టి మీరు సాధ్యమయ్యే స్థానిక కనిష్టాన్ని కనుగొనడంలో నిజంగా కష్టపడుతున్నారని 

288
00:19:08,128 --> 00:19:12,140
మీకు తెలుసు. , మీరు ఆ ఖచ్చితత్వాన్ని పొందే సరైన బరువులు.

289
00:19:12,240 --> 00:19:16,354
అయితే మీరు నిజంగా నిర్మాణాత్మక డేటాసెట్‌పై శిక్షణ పొందుతున్నట్లయితే, 

290
00:19:16,354 --> 00:19:20,826
సరైన లేబుల్‌లను కలిగి ఉన్నట్లయితే, మీరు ప్రారంభంలో కొంచెం ఫిడేలు చేస్తారు, 

291
00:19:20,826 --> 00:19:26,133
కానీ మీరు ఆ ఖచ్చితత్వ స్థాయికి చేరుకోవడానికి చాలా వేగంగా పడిపోయారు మరియు కొంత కోణంలో అది 

292
00:19:26,133 --> 00:19:28,220
స్థానిక గరిష్టాన్ని కనుగొనడం సులభం.

293
00:19:28,540 --> 00:19:33,696
మరియు దాని గురించి ఆసక్తికరమైన విషయం ఏమిటంటే, వాస్తవానికి కొన్ని సంవత్సరాల క్రితం నుండి 

294
00:19:33,696 --> 00:19:38,441
మరొక కాగితాన్ని వెలుగులోకి తెస్తుంది, ఇది నెట్‌వర్క్ లేయర్‌ల గురించి చాలా ఎక్కువ 

295
00:19:38,441 --> 00:19:43,480
సరళీకరణలను కలిగి ఉంది, అయితే ఫలితాలలో ఒకటి మీరు ఆప్టిమైజేషన్ ల్యాండ్‌స్కేప్‌ను చూస్తే 

296
00:19:43,480 --> 00:19:48,460
ఎలా అని చెబుతోంది, ఈ నెట్‌వర్క్‌లు నేర్చుకునే లోకల్ మినిమా వాస్తవానికి సమాన నాణ్యతతో 

297
00:19:48,460 --> 00:19:52,152
ఉంటుంది, కాబట్టి కొంత కోణంలో మీ డేటాసెట్ నిర్మాణాత్మకంగా ఉంటే, 

298
00:19:52,152 --> 00:19:54,320
మీరు దానిని మరింత సులభంగా కనుగొనగలరు.

299
00:19:58,160 --> 00:20:01,180
ఎప్పటిలాగే, మీలో పాట్రియన్‌కు మద్దతు ఇస్తున్న వారికి నా ధన్యవాదాలు.

300
00:20:01,520 --> 00:20:04,315
పాట్రియన్ గేమ్ ఛేంజర్ అంటే ఏమిటో నేను ముందే చెప్పాను, 

301
00:20:04,315 --> 00:20:06,800
కానీ మీరు లేకుండా ఈ వీడియోలు నిజంగా సాధ్యం కాదు.

302
00:20:07,460 --> 00:20:09,993
సిరీస్‌లోని ఈ ప్రారంభ వీడియోలకు మద్దతుగా VC సంస్థ యాంప్లిఫై 

303
00:20:09,993 --> 00:20:12,780
పార్ట్‌నర్‌లకు కూడా నేను ప్రత్యేక ధన్యవాదాలు చెప్పాలనుకుంటున్నాను.

