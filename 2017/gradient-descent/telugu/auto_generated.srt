1
00:00:00,000 --> 00:00:07,240
చివరి వీడియో నేను న్యూరల్ నెట్‌వర్క్ యొక్క నిర్మాణాన్ని రూపొందించాను.

2
00:00:07,240 --> 00:00:10,245
నేను ఇక్కడ శీఘ్ర రీక్యాప్ ఇస్తాను, తద్వారా ఇది మన మనస్సులో తాజాగా

3
00:00:10,245 --> 00:00:13,160
ఉంటుంది, ఆపై ఈ వీడియో కోసం నాకు రెండు ప్రధాన లక్ష్యాలు ఉన్నాయి.

4
00:00:13,160 --> 00:00:16,628
మొదటిది గ్రేడియంట్ డీసెంట్ ఆలోచనను పరిచయం చేయడం, ఇది న్యూరల్ నెట్‌వర్క్‌లు ఎలా

5
00:00:16,628 --> 00:00:20,097
నేర్చుకుంటాయో మాత్రమే కాకుండా, చాలా ఇతర మెషీన్ లెర్నింగ్ కూడా ఎలా పనిచేస్తుందో

6
00:00:20,097 --> 00:00:20,800
తెలియజేస్తుంది.

7
00:00:20,800 --> 00:00:25,180
ఆ తర్వాత మేము ఈ నిర్దిష్ట నెట్‌వర్క్ ఎలా పని చేస్తుందో మరియు న్యూరాన్‌ల

8
00:00:25,180 --> 00:00:29,560
యొక్క దాచిన పొరలు దేని కోసం వెతుకుతున్నాయో కొంచెం ఎక్కువ త్రవ్విస్తాము.

9
00:00:29,560 --> 00:00:33,480
రిమైండర్‌గా, ఇక్కడ మా లక్ష్యం చేతితో వ్రాసిన అంకెల గుర్తింపు

10
00:00:33,480 --> 00:00:37,080
యొక్క క్లాసిక్ ఉదాహరణ, న్యూరల్ నెట్‌వర్క్‌ల హలో వరల్డ్.

11
00:00:37,080 --> 00:00:40,795
ఈ అంకెలు 28x28 పిక్సెల్ గ్రిడ్‌లో రెండర్ చేయబడ్డాయి, ప్రతి

12
00:00:40,795 --> 00:00:44,260
పిక్సెల్ కొంత గ్రేస్కేల్ విలువ 0 మరియు 1 మధ్య ఉంటుంది.

13
00:00:44,260 --> 00:00:51,400
నెట్‌వర్క్ యొక్క ఇన్‌పుట్ లేయర్‌లోని 784 న్యూరాన్‌ల క్రియాశీలతను అవి నిర్ణయిస్తాయి.

14
00:00:51,400 --> 00:00:54,854
కింది లేయర్‌లలోని ప్రతి న్యూరాన్ యొక్క క్రియాశీలత మునుపటి

15
00:00:54,854 --> 00:00:58,607
లేయర్‌లోని అన్ని యాక్టివేషన్‌ల యొక్క వెయిటెడ్ మొత్తంపై ఆధారపడి

16
00:00:58,607 --> 00:01:02,300
ఉంటుంది, అలాగే కొన్ని ప్రత్యేక సంఖ్యలను బయాస్ అని పిలుస్తారు.

17
00:01:02,300 --> 00:01:06,054
మీరు ఆ మొత్తాన్ని సిగ్మోయిడ్ స్క్విషిఫికేషన్ లేదా ReLU వంటి కొన్ని

18
00:01:06,054 --> 00:01:09,640
ఇతర ఫంక్షన్‌తో కంపోజ్ చేసారు, నేను చివరి వీడియో ద్వారా నడిచాను.

19
00:01:09,640 --> 00:01:14,866
మొత్తంగా, ఒక్కొక్కటి 16 న్యూరాన్‌లతో రెండు దాచిన లేయర్‌లను కొంతవరకు ఏకపక్షంగా ఎంపిక

20
00:01:14,866 --> 00:01:19,906
చేస్తే, నెట్‌వర్క్‌లో సుమారు 13,000 బరువులు మరియు పక్షపాతాలు ఉన్నాయి, వీటిని మనం

21
00:01:19,906 --> 00:01:25,320
సర్దుబాటు చేయవచ్చు మరియు నెట్‌వర్క్ వాస్తవానికి ఏమి చేస్తుందో ఈ విలువలు నిర్ణయిస్తాయి.

22
00:01:25,320 --> 00:01:29,700
మరియు ఈ నెట్‌వర్క్ ఇచ్చిన అంకెను వర్గీకరిస్తుంది అని మనం చెప్పినప్పుడు మన ఉద్దేశ్యం

23
00:01:29,700 --> 00:01:34,080
ఏమిటంటే, చివరి పొరలోని ఆ 10 న్యూరాన్‌లలో ప్రకాశవంతమైనది ఆ అంకెకు అనుగుణంగా ఉంటుంది.

24
00:01:34,080 --> 00:01:39,000
మరియు గుర్తుంచుకోండి, లేయర్డ్ స్ట్రక్చర్ కోసం మనం మనసులో ఉంచుకున్న ప్రేరణ

25
00:01:39,000 --> 00:01:44,187
ఏమిటంటే, రెండవ లేయర్ అంచుల నుండి ఎంచుకోవచ్చు, మూడవ లేయర్ లూప్‌లు మరియు లైన్‌ల

26
00:01:44,187 --> 00:01:49,640
వంటి నమూనాలను ఎంచుకోవచ్చు మరియు చివరిది ఆ నమూనాలను కలపవచ్చు. అంకెలను గుర్తించండి.

27
00:01:49,640 --> 00:01:52,880
కాబట్టి ఇక్కడ, నెట్‌వర్క్ ఎలా నేర్చుకుంటుందో మనం నేర్చుకుంటాము.

28
00:01:52,880 --> 00:01:57,185
మేము కోరుకునేది మీరు ఈ నెట్‌వర్క్‌కు శిక్షణ డేటా యొక్క మొత్తం సమూహాన్ని

29
00:01:57,185 --> 00:02:01,550
చూపగల అల్గారిథమ్, ఇది చేతితో వ్రాసిన అంకెల యొక్క విభిన్న చిత్రాల సమూహంతో

30
00:02:01,550 --> 00:02:06,035
పాటు అవి ఏవి ఉండాలో లేబుల్‌లతో పాటుగా వస్తాయి మరియు ఇది శిక్షణ డేటాపై దాని

31
00:02:06,035 --> 00:02:10,760
పనితీరును మెరుగుపరచడానికి ఆ 13,000 బరువులు మరియు పక్షపాతాలను సర్దుబాటు చేయండి.

32
00:02:10,760 --> 00:02:14,300
ఆశాజనక ఈ లేయర్డ్ నిర్మాణం అంటే అది నేర్చుకునేది ఆ

33
00:02:14,300 --> 00:02:17,840
శిక్షణ డేటాకు మించిన చిత్రాలకు సాధారణీకరిస్తుంది.

34
00:02:17,840 --> 00:02:22,190
మేము దానిని పరీక్షించే విధానం ఏమిటంటే, మీరు నెట్‌వర్క్‌కు శిక్షణ

35
00:02:22,190 --> 00:02:26,742
ఇచ్చిన తర్వాత, మీరు దానిని మరింత లేబుల్ చేసిన డేటాను చూపుతారు మరియు

36
00:02:26,742 --> 00:02:31,160
ఆ కొత్త చిత్రాలను అది ఎంత ఖచ్చితంగా వర్గీకరిస్తారో మీరు చూస్తారు.

37
00:02:31,160 --> 00:02:35,861
అదృష్టవశాత్తూ, మరియు దీనిని ప్రారంభించడానికి ఇది ఒక సాధారణ ఉదాహరణగా మారింది,

38
00:02:35,861 --> 00:02:40,256
MNIST డేటాబేస్ వెనుక ఉన్న మంచి వ్యక్తులు పదివేల చేతివ్రాత అంకెల చిత్రాల

39
00:02:40,256 --> 00:02:45,080
సేకరణను కలిగి ఉన్నారు, ప్రతి ఒక్కటి వారు ఉండాల్సిన సంఖ్యలతో లేబుల్ చేయబడ్డాయి.

40
00:02:45,080 --> 00:02:48,773
మరియు మెషీన్‌ను నేర్చుకోవడంగా వర్ణించడం ఎంత రెచ్చగొట్టేదో, అది ఎలా పనిచేస్తుందో

41
00:02:48,773 --> 00:02:52,282
మీరు ఒకసారి చూస్తే, అది కొన్ని వెర్రి సైన్స్ ఫిక్షన్ ఆవరణలాగా చాలా తక్కువగా

42
00:02:52,282 --> 00:02:55,560
అనిపిస్తుంది మరియు కాలిక్యులస్ వ్యాయామం లాగా చాలా ఎక్కువ అనిపిస్తుంది.

43
00:02:55,560 --> 00:02:58,597
నా ఉద్దేశ్యం, ప్రాథమికంగా ఇది ఒక నిర్దిష్ట ఫంక్షన్

44
00:02:58,597 --> 00:03:01,040
యొక్క కనిష్టాన్ని కనుగొనడానికి వస్తుంది.

45
00:03:01,040 --> 00:03:05,692
గుర్తుంచుకోండి, సంభావితంగా మనం ప్రతి న్యూరాన్ మునుపటి లేయర్‌లోని అన్ని

46
00:03:05,692 --> 00:03:10,410
న్యూరాన్‌లతో అనుసంధానించబడిందని ఆలోచిస్తున్నాము మరియు దాని క్రియాశీలతను

47
00:03:10,410 --> 00:03:14,996
నిర్వచించే వెయిటెడ్ మొత్తంలోని బరువులు ఆ కనెక్షన్‌ల బలాలు లాగా ఉంటాయి

48
00:03:14,996 --> 00:03:19,780
మరియు పక్షపాతం కొంత సూచన ఆ న్యూరాన్ చురుకుగా లేదా క్రియారహితంగా ఉంటుందా.

49
00:03:19,780 --> 00:03:22,352
మరియు విషయాలను ప్రారంభించడానికి, మేము ఆ బరువులు మరియు

50
00:03:22,352 --> 00:03:25,020
పక్షపాతాలను పూర్తిగా యాదృచ్ఛికంగా ప్రారంభించబోతున్నాము.

51
00:03:25,020 --> 00:03:28,031
చెప్పనవసరం లేదు, ఈ నెట్‌వర్క్ ఇచ్చిన శిక్షణ ఉదాహరణపై భయంకరంగా పని

52
00:03:28,031 --> 00:03:31,180
చేస్తుందని చెప్పనవసరం లేదు, ఎందుకంటే ఇది యాదృచ్ఛికంగా ఏదో చేస్తోంది.

53
00:03:31,180 --> 00:03:34,000
ఉదాహరణకు, మీరు 3 యొక్క ఈ చిత్రంలో ఫీడ్ చేస్తారు

54
00:03:34,000 --> 00:03:36,820
మరియు అవుట్‌పుట్ లేయర్ గందరగోళంగా కనిపిస్తుంది.

55
00:03:36,820 --> 00:03:42,880
కాబట్టి మీరు చేసేది ఖర్చు ఫంక్షన్‌ని నిర్వచించడం, కంప్యూటర్‌కు చెప్పే మార్గం, కాదు, చెడ్డ

56
00:03:42,880 --> 00:03:48,940
కంప్యూటర్, అవుట్‌పుట్‌లో చాలా న్యూరాన్‌లకు 0, కానీ ఈ న్యూరాన్‌కు 1 యాక్టివేషన్‌లు ఉండాలి.

57
00:03:48,940 --> 00:03:51,740
మీరు నాకు ఇచ్చినది పూర్తిగా చెత్త.

58
00:03:51,740 --> 00:03:56,330
కొంచెం ఎక్కువ గణితశాస్త్రంలో చెప్పాలంటే, మీరు ఆ ప్రతి ట్రాష్ అవుట్‌పుట్

59
00:03:56,330 --> 00:04:01,047
యాక్టివేషన్‌ల మధ్య వ్యత్యాసాల చతురస్రాలను మరియు వాటిని కలిగి ఉండాలని మీరు

60
00:04:01,047 --> 00:04:06,020
కోరుకునే విలువను జోడిస్తారు మరియు దీనిని మేము ఒకే శిక్షణ ఉదాహరణగా పిలుస్తాము.

61
00:04:06,020 --> 00:04:12,688
నెట్‌వర్క్ నమ్మకంగా చిత్రాన్ని సరిగ్గా వర్గీకరించినప్పుడు ఈ మొత్తం చిన్నదని గమనించండి,

62
00:04:12,688 --> 00:04:18,820
కానీ నెట్‌వర్క్ ఏమి చేస్తుందో తెలియనట్లు అనిపించినప్పుడు అది పెద్దదిగా ఉంటుంది.

63
00:04:18,820 --> 00:04:27,580
కాబట్టి మీరు చేసేది మీ వద్ద ఉన్న పదివేల శిక్షణా ఉదాహరణల కంటే సగటు ధరను పరిగణించడం.

64
00:04:27,580 --> 00:04:30,564
ఈ సగటు ధర నెట్‌వర్క్ ఎంత అధ్వాన్నంగా ఉందో మరియు

65
00:04:30,564 --> 00:04:33,300
కంప్యూటర్ ఎంత చెడ్డగా భావించాలో మా కొలమానం.

66
00:04:33,300 --> 00:04:35,300
మరియు అది సంక్లిష్టమైన విషయం.

67
00:04:35,300 --> 00:04:39,832
నెట్‌వర్క్ ప్రాథమికంగా ఒక ఫంక్షన్‌గా ఎలా ఉందో గుర్తుంచుకోండి, ఇది 784 సంఖ్యలను

68
00:04:39,832 --> 00:04:44,651
ఇన్‌పుట్‌లుగా, పిక్సెల్ విలువలుగా తీసుకుంటుంది మరియు 10 సంఖ్యలను దాని అవుట్‌పుట్‌గా

69
00:04:44,651 --> 00:04:49,700
ఉమ్మివేస్తుంది మరియు ఒక కోణంలో ఇది ఈ బరువులు మరియు పక్షపాతాల ద్వారా పారామితి చేయబడిందా?

70
00:04:49,700 --> 00:04:53,340
ఖర్చు ఫంక్షన్ దాని పైన సంక్లిష్టత యొక్క పొర.

71
00:04:53,340 --> 00:04:58,548
ఇది దాని ఇన్‌పుట్‌గా ఆ 13,000 లేదా అంతకంటే ఎక్కువ బరువులు మరియు పక్షపాతాలను తీసుకుంటుంది

72
00:04:58,548 --> 00:05:03,697
మరియు ఆ బరువులు మరియు పక్షపాతాలు ఎంత చెడ్డవో వివరిస్తూ ఒకే సంఖ్యను ఉమ్మివేస్తుంది మరియు

73
00:05:03,697 --> 00:05:08,613
అది నిర్వచించబడిన విధానం మొత్తం పదివేల శిక్షణా డేటాపై నెట్‌వర్క్ ప్రవర్తనపై ఆధారపడి

74
00:05:08,613 --> 00:05:09,140
ఉంటుంది.

75
00:05:09,140 --> 00:05:12,460
అన్నది చాలా ఆలోచించాల్సిన విషయం.

76
00:05:12,460 --> 00:05:16,380
కానీ కంప్యూటర్‌కు అది ఎంత చెత్త పని చేస్తుందో చెప్పడం చాలా ఉపయోగకరంగా ఉండదు.

77
00:05:16,380 --> 00:05:18,737
ఆ బరువులు మరియు పక్షపాతాలను ఎలా మార్చాలో మీరు

78
00:05:18,737 --> 00:05:21,300
చెప్పాలనుకుంటున్నారు, తద్వారా అది మెరుగుపడుతుంది.

79
00:05:21,300 --> 00:05:26,112
దీన్ని సులభతరం చేయడానికి, 13,000 ఇన్‌పుట్‌లతో ఒక ఫంక్షన్‌ను ఊహించడం కష్టపడకుండా, ఒక

80
00:05:26,112 --> 00:05:30,695
సంఖ్యను ఇన్‌పుట్‌గా మరియు ఒక సంఖ్యను అవుట్‌పుట్‌గా కలిగి ఉండే సాధారణ ఫంక్షన్‌ను

81
00:05:30,695 --> 00:05:31,440
ఊహించుకోండి.

82
00:05:31,440 --> 00:05:36,420
ఈ ఫంక్షన్ విలువను తగ్గించే ఇన్‌పుట్‌ను మీరు ఎలా కనుగొంటారు?

83
00:05:36,420 --> 00:05:39,911
కాలిక్యులస్ విద్యార్థులకు మీరు కొన్నిసార్లు స్పష్టంగా కనిష్టంగా

84
00:05:39,911 --> 00:05:43,729
గుర్తించగలరని తెలుసుకుంటారు, కానీ నిజంగా సంక్లిష్టమైన ఫంక్షన్‌లకు ఇది

85
00:05:43,729 --> 00:05:47,603
ఎల్లప్పుడూ సాధ్యపడదు, మా క్రేజీ కాంప్లికేటెడ్ న్యూరల్ నెట్‌వర్క్ ఖర్చు

86
00:05:47,603 --> 00:05:51,640
ఫంక్షన్ కోసం ఈ పరిస్థితి యొక్క 13,000 ఇన్‌పుట్ వెర్షన్‌లో ఖచ్చితంగా కాదు.

87
00:05:51,640 --> 00:05:55,841
ఏదైనా ఇన్‌పుట్‌లో ప్రారంభించడం మరియు ఆ అవుట్‌పుట్ తక్కువగా చేయడానికి

88
00:05:55,841 --> 00:05:59,860
మీరు ఏ దిశలో అడుగు పెట్టాలో గుర్తించడం మరింత సౌకర్యవంతమైన వ్యూహం.

89
00:05:59,860 --> 00:06:06,178
ప్రత్యేకించి, మీరు ఉన్న ఫంక్షన్ యొక్క వాలును మీరు గుర్తించగలిగితే, ఆ వాలు సానుకూలంగా

90
00:06:06,178 --> 00:06:12,720
ఉంటే ఎడమవైపుకు మార్చండి మరియు ఆ వాలు ప్రతికూలంగా ఉంటే ఇన్‌పుట్‌ను కుడి వైపుకు మార్చండి.

91
00:06:12,720 --> 00:06:16,648
మీరు దీన్ని పదేపదే చేస్తే, ప్రతి పాయింట్ వద్ద కొత్త వాలును తనిఖీ చేసి, తగిన

92
00:06:16,648 --> 00:06:20,680
దశను తీసుకుంటే, మీరు ఫంక్షన్ యొక్క కొంత స్థానిక కనిష్టాన్ని చేరుకోబోతున్నారు.

93
00:06:20,680 --> 00:06:24,600
మరియు ఇక్కడ మీరు గుర్తుంచుకునే చిత్రం కొండపై నుండి దొర్లుతున్న బంతి.

94
00:06:24,600 --> 00:06:29,479
మరియు గమనించండి, ఈ నిజంగా సరళీకృతమైన సింగిల్ ఇన్‌పుట్ ఫంక్షన్‌కు కూడా, మీరు ఏ యాదృచ్ఛిక

95
00:06:29,479 --> 00:06:34,247
ఇన్‌పుట్‌ను ప్రారంభించాలనే దానిపై ఆధారపడి మీరు ల్యాండ్ అయ్యే అనేక లోయలు ఉన్నాయి మరియు

96
00:06:34,247 --> 00:06:38,960
మీరు దిగిన స్థానిక కనీస విలువ సాధ్యమైనంత చిన్నదిగా ఉంటుందని ఎటువంటి హామీ లేదు. ఖర్చు

97
00:06:38,960 --> 00:06:39,460
ఫంక్షన్.

98
00:06:39,460 --> 00:06:43,180
అది మా న్యూరల్ నెట్‌వర్క్ కేసుకు కూడా తీసుకువెళుతుంది.

99
00:06:43,180 --> 00:06:47,513
మరియు మీరు మీ దశల పరిమాణాలను వాలుకు అనులోమానుపాతంలో చేస్తే, వాలు కనిష్ట స్థాయికి

100
00:06:47,513 --> 00:06:51,686
చదునుగా ఉన్నప్పుడు, మీ అడుగులు చిన్నవిగా మరియు చిన్నవిగా ఉంటాయి మరియు ఆ రకమైన

101
00:06:51,686 --> 00:06:56,020
ఓవర్‌షూట్ నుండి మీకు ఎలా సహాయపడుతుందో కూడా మీరు గమనించాలని నేను కోరుకుంటున్నాను.

102
00:06:56,020 --> 00:06:59,050
సంక్లిష్టతను కొంచెం పెంచుతూ, బదులుగా రెండు ఇన్‌పుట్‌లు

103
00:06:59,050 --> 00:07:01,640
మరియు ఒక అవుట్‌పుట్‌తో ఫంక్షన్‌ను ఊహించుకోండి.

104
00:07:01,640 --> 00:07:05,264
మీరు ఇన్‌పుట్ స్పేస్‌ను xy-ప్లేన్‌గా భావించవచ్చు మరియు

105
00:07:05,264 --> 00:07:09,020
ఖర్చు ఫంక్షన్ దాని పైన ఉపరితలంగా గ్రాఫ్ చేయబడి ఉండవచ్చు.

106
00:07:09,020 --> 00:07:14,298
ఫంక్షన్ యొక్క వాలు గురించి అడగడానికి బదులుగా, మీరు ఈ ఇన్‌పుట్ స్థలంలో ఏ దిశలో

107
00:07:14,298 --> 00:07:19,780
అడుగు పెట్టాలని అడగాలి, తద్వారా ఫంక్షన్ యొక్క అవుట్‌పుట్ చాలా త్వరగా తగ్గుతుంది.

108
00:07:19,780 --> 00:07:22,340
మరో మాటలో చెప్పాలంటే, లోతువైపు దిశ ఏమిటి?

109
00:07:22,340 --> 00:07:26,740
మరలా, ఆ కొండపైకి ఒక బంతి రోలింగ్ చేయడం గురించి ఆలోచించడం సహాయకరంగా ఉంటుంది.

110
00:07:26,740 --> 00:07:31,007
మీలో మల్టీవియరబుల్ కాలిక్యులస్ గురించి తెలిసిన వారికి, ఫంక్షన్ యొక్క

111
00:07:31,007 --> 00:07:35,275
గ్రేడియంట్ మీకు ఏటవాలుగా ఉన్న ఆరోహణ దిశను ఇస్తుందని, మీరు ఫంక్షన్‌ను

112
00:07:35,275 --> 00:07:39,420
అత్యంత వేగంగా పెంచడానికి ఏ దిశలో అడుగు పెట్టాలి అని తెలుసుకుంటారు.

113
00:07:39,420 --> 00:07:43,510
సహజంగానే తగినంత, ఆ ప్రవణత యొక్క ప్రతికూలతను తీసుకోవడం వలన

114
00:07:43,510 --> 00:07:47,460
ఫంక్షన్‌ను చాలా త్వరగా తగ్గించే దశకు దిశను అందిస్తుంది.

115
00:07:47,460 --> 00:07:50,874
దాని కంటే ఎక్కువగా, ఈ గ్రేడియంట్ వెక్టర్ యొక్క

116
00:07:50,874 --> 00:07:54,580
పొడవు ఆ ఏటవాలు వాలు ఎంత నిటారుగా ఉందో సూచిస్తుంది.

117
00:07:54,580 --> 00:07:57,663
ఇప్పుడు మీకు మల్టీవియరబుల్ కాలిక్యులస్ గురించి తెలియకపోతే మరియు మరింత

118
00:07:57,663 --> 00:08:01,100
తెలుసుకోవాలనుకుంటే, ఈ అంశంపై ఖాన్ అకాడమీ కోసం నేను చేసిన కొన్ని పనిని చూడండి.

119
00:08:01,100 --> 00:08:04,818
నిజాయితీగా చెప్పాలంటే, ప్రస్తుతం మీకు మరియు నాకు ముఖ్యమైనది ఏమిటంటే,

120
00:08:04,818 --> 00:08:08,375
సూత్రప్రాయంగా ఈ వెక్టార్‌ను గణించడానికి ఒక మార్గం ఉంది, ఈ వెక్టర్

121
00:08:08,375 --> 00:08:12,040
లోతువైపు దిశ ఏమిటో మరియు అది ఎంత నిటారుగా ఉందో మీకు తెలియజేస్తుంది.

122
00:08:12,040 --> 00:08:17,280
మీకు తెలిసినంత మాత్రాన మీరు బాగానే ఉంటారు మరియు వివరాలపై మీరు గట్టిగా ఉండకపోతే.

123
00:08:17,280 --> 00:08:22,282
ఎందుకంటే మీరు దానిని పొందగలిగితే, ఫంక్షన్‌ను కనిష్టీకరించడానికి అల్గోరిథం ఈ గ్రేడియంట్

124
00:08:22,282 --> 00:08:27,400
దిశను గణించడం, ఆపై ఒక చిన్న అడుగు లోతువైపుకి వెళ్లి, దాన్ని మళ్లీ మళ్లీ పునరావృతం చేయడం.

125
00:08:27,400 --> 00:08:33,700
2 ఇన్‌పుట్‌లకు బదులుగా 13,000 ఇన్‌పుట్‌లను కలిగి ఉన్న ఫంక్షన్‌కి ఇది అదే ప్రాథమిక ఆలోచన.

126
00:08:33,700 --> 00:08:36,967
మా నెట్‌వర్క్‌లోని మొత్తం 13,000 బరువులు మరియు పక్షపాతాలను

127
00:08:36,967 --> 00:08:40,180
ఒక పెద్ద కాలమ్ వెక్టర్‌గా నిర్వహించడం గురించి ఆలోచించండి.

128
00:08:40,180 --> 00:08:45,237
కాస్ట్ ఫంక్షన్ యొక్క నెగటివ్ గ్రేడియంట్ అనేది వెక్టార్ మాత్రమే, ఇది ఈ అతి

129
00:08:45,237 --> 00:08:50,705
పెద్ద ఇన్‌పుట్ స్పేస్‌లోని కొంత దిశలో ఉంటుంది, ఇది ఆ సంఖ్యలన్నింటికీ ఏ నడ్జ్‌లు

130
00:08:50,705 --> 00:08:55,900
కాస్ట్ ఫంక్షన్‌లో అత్యంత వేగంగా తగ్గుదలని కలిగిస్తుందో మీకు తెలియజేస్తుంది.

131
00:08:55,900 --> 00:08:59,869
మరియు వాస్తవానికి, మా ప్రత్యేకంగా రూపొందించిన ఖర్చు ఫంక్షన్‌తో, బరువులు

132
00:08:59,869 --> 00:09:03,507
మరియు పక్షపాతాలను తగ్గించడానికి మార్చడం అంటే ప్రతి శిక్షణా డేటాపై

133
00:09:03,507 --> 00:09:07,531
నెట్‌వర్క్ అవుట్‌పుట్ 10 విలువల యాదృచ్ఛిక శ్రేణి వలె తక్కువగా కనిపించేలా

134
00:09:07,531 --> 00:09:11,280
చేయడం మరియు మనకు కావలసిన వాస్తవ నిర్ణయం వలె ఉంటుంది. అది చేయడానికి.

135
00:09:11,280 --> 00:09:17,993
గుర్తుంచుకోవడం ముఖ్యం, ఈ ఖర్చు ఫంక్షన్ మొత్తం శిక్షణ డేటాపై సగటును కలిగి ఉంటుంది, కాబట్టి

136
00:09:17,993 --> 00:09:24,260
మీరు దానిని కనిష్టీకరించినట్లయితే, ఆ నమూనాలన్నింటిలో ఇది మెరుగైన పనితీరు అని అర్థం.

137
00:09:24,260 --> 00:09:27,409
ఈ గ్రేడియంట్‌ను సమర్ధవంతంగా కంప్యూటింగ్ చేయడానికి అల్గోరిథం, ఇది ఒక న్యూరల్

138
00:09:27,409 --> 00:09:30,558
నెట్‌వర్క్ ఎలా నేర్చుకుంటుంది అనేదానికి ప్రభావవంతంగా హృదయాన్ని అందిస్తుంది,

139
00:09:30,558 --> 00:09:34,040
దీనిని బ్యాక్‌ప్రొపగేషన్ అంటారు మరియు నేను తదుపరి వీడియో గురించి మాట్లాడబోతున్నాను.

140
00:09:34,040 --> 00:09:37,574
అక్కడ, నేను నిజంగా శిక్షణ డేటా యొక్క ప్రతి భాగం కోసం ప్రతి బరువు మరియు

141
00:09:37,574 --> 00:09:40,512
పక్షపాతంతో సరిగ్గా ఏమి జరుగుతుందో తెలుసుకోవడానికి సమయాన్ని

142
00:09:40,512 --> 00:09:43,947
వెచ్చించాలనుకుంటున్నాను, సంబంధిత కాలిక్యులస్ మరియు ఫార్ములాల కుప్పకు

143
00:09:43,947 --> 00:09:47,980
మించి ఏమి జరుగుతుందో దాని గురించి స్పష్టమైన అనుభూతిని ఇవ్వడానికి ప్రయత్నిస్తాను.

144
00:09:47,980 --> 00:09:51,702
ఇక్కడే, ప్రస్తుతం, మీరు తెలుసుకోవలసిన ప్రధాన విషయం ఏమిటంటే, అమలు

145
00:09:51,702 --> 00:09:55,024
వివరాలతో సంబంధం లేకుండా, మనం నెట్‌వర్క్ లెర్నింగ్ గురించి

146
00:09:55,024 --> 00:09:59,320
మాట్లాడేటప్పుడు మనం అర్థం చేసుకునేది అది కేవలం ఖర్చు ఫంక్షన్‌ను తగ్గించడం.

147
00:09:59,320 --> 00:10:02,676
మరియు గమనించండి, దాని యొక్క ఒక పర్యవసానమేమిటంటే, ఈ ఖర్చు ఫంక్షన్‌కు

148
00:10:02,676 --> 00:10:05,983
చక్కని మృదువైన అవుట్‌పుట్‌ను కలిగి ఉండటం చాలా ముఖ్యం, తద్వారా మేము

149
00:10:05,983 --> 00:10:09,340
దిగువకు చిన్న అడుగులు వేయడం ద్వారా స్థానిక కనిష్టాన్ని కనుగొనవచ్చు.

150
00:10:09,340 --> 00:10:14,783
అందుకే, కృత్రిమ న్యూరాన్‌లు జీవసంబంధమైన న్యూరాన్‌ల మాదిరిగానే బైనరీ మార్గంలో

151
00:10:14,783 --> 00:10:20,440
చురుకుగా లేదా క్రియారహితంగా ఉండకుండా, నిరంతరం శ్రేణి క్రియాశీలతను కలిగి ఉంటాయి.

152
00:10:20,440 --> 00:10:23,885
ప్రతికూల ప్రవణత యొక్క కొన్ని గుణిజాలతో ఫంక్షన్ యొక్క ఇన్‌పుట్‌ను

153
00:10:23,885 --> 00:10:26,960
పదేపదే నడ్జ్ చేసే ఈ ప్రక్రియను గ్రేడియంట్ డీసెంట్ అంటారు.

154
00:10:26,960 --> 00:10:33,000
ఇది ప్రాథమికంగా ఈ గ్రాఫ్‌లోని లోయలో కొంత స్థానిక కనిష్ట ధర ఫంక్షన్‌కి కలుస్తుంది.

155
00:10:33,000 --> 00:10:37,158
నేను ఇప్పటికీ రెండు ఇన్‌పుట్‌లతో ఫంక్షన్ యొక్క చిత్రాన్ని చూపుతున్నాను, ఎందుకంటే

156
00:10:37,158 --> 00:10:41,317
13,000 డైమెన్షనల్ ఇన్‌పుట్ స్పేస్‌లోని నడ్జ్‌లు మీ మనస్సును చుట్టుముట్టడం కొంచెం

157
00:10:41,317 --> 00:10:45,220
కష్టం, అయితే దీని గురించి ఆలోచించడానికి ఒక మంచి నాన్-స్పేషియల్ మార్గం ఉంది.

158
00:10:45,220 --> 00:10:49,100
ప్రతికూల ప్రవణత యొక్క ప్రతి భాగం మనకు రెండు విషయాలను చెబుతుంది.

159
00:10:49,100 --> 00:10:52,379
ఇన్‌పుట్ వెక్టర్ యొక్క సంబంధిత కాంపోనెంట్‌ను పైకి లేదా క్రిందికి

160
00:10:52,379 --> 00:10:55,860
నడ్జ్ చేయాలా వద్దా అనే విషయాన్ని గుర్తు, వాస్తవానికి తెలియజేస్తుంది.

161
00:10:55,860 --> 00:11:00,786
కానీ ముఖ్యంగా, ఈ అన్ని భాగాల యొక్క సాపేక్ష పరిమాణాలు

162
00:11:00,786 --> 00:11:05,620
ఏ మార్పులు మరింత ముఖ్యమైనవి అని మీకు తెలియజేస్తాయి.

163
00:11:05,620 --> 00:11:10,060
మీరు చూస్తారు, మా నెట్‌వర్క్‌లో, కొన్ని ఇతర బరువులకు సర్దుబాటు చేయడం కంటే

164
00:11:10,060 --> 00:11:14,980
బరువులలో ఒకదానికి సర్దుబాటు చేయడం ధర పనితీరుపై చాలా ఎక్కువ ప్రభావాన్ని చూపుతుంది.

165
00:11:14,980 --> 00:11:19,440
ఈ కనెక్షన్‌లలో కొన్ని మా శిక్షణ డేటాకు మరింత ముఖ్యమైనవి.

166
00:11:19,440 --> 00:11:24,176
కాబట్టి మీరు ఈ గ్రేడియంట్ వెక్టార్ గురించి ఆలోచించగలిగే మార్గం ఏమిటంటే, మా మనస్సును

167
00:11:24,176 --> 00:11:29,081
కదిలించే భారీ వ్యయ ఫంక్షన్ యొక్క ప్రతి బరువు మరియు పక్షపాతం యొక్క సాపేక్ష ప్రాముఖ్యతను

168
00:11:29,081 --> 00:11:34,100
ఇది ఎన్కోడ్ చేస్తుంది, అంటే, ఈ మార్పులలో ఏది మీ బక్ కోసం ఎక్కువ బ్యాంగ్ తీసుకువెళుతుంది.

169
00:11:34,100 --> 00:11:37,360
ఇది నిజంగా దిశ గురించి ఆలోచించే మరొక మార్గం.

170
00:11:37,360 --> 00:11:42,579
సరళమైన ఉదాహరణను తీసుకుంటే, మీరు ఇన్‌పుట్‌గా రెండు వేరియబుల్స్‌తో కొంత ఫంక్షన్‌ను

171
00:11:42,579 --> 00:11:47,734
కలిగి ఉంటే, మరియు నిర్దిష్ట పాయింట్‌లో దాని గ్రేడియంట్ 3,1గా వస్తుందని గణిస్తే,

172
00:11:47,734 --> 00:11:52,889
ఒక వైపు మీరు దానిని మీరు చెప్పినట్లు అర్థం చేసుకోవచ్చు. ఆ ఇన్‌పుట్ వద్ద నిలబడి,

173
00:11:52,889 --> 00:11:58,109
ఈ దిశలో కదలడం వలన ఫంక్షన్ చాలా త్వరగా పెరుగుతుంది, మీరు ఇన్‌పుట్ పాయింట్ల విమానం

174
00:11:58,109 --> 00:12:03,200
పైన ఫంక్షన్‌ను గ్రాఫ్ చేసినప్పుడు, ఆ వెక్టార్ మీకు నేరుగా పైకి దిశను ఇస్తుంది.

175
00:12:03,200 --> 00:12:07,486
కానీ దానిని చదవడానికి మరొక మార్గం ఏమిటంటే, ఈ మొదటి వేరియబుల్‌కు మార్పులు రెండవ

176
00:12:07,486 --> 00:12:12,314
వేరియబుల్‌కు మార్పుల కంటే మూడు రెట్లు ప్రాముఖ్యతను కలిగి ఉన్నాయని చెప్పడం, కనీసం సంబంధిత

177
00:12:12,314 --> 00:12:16,926
ఇన్‌పుట్ యొక్క పరిసరాల్లో, x-విలువను నడ్జ్ చేయడం వల్ల మీ కోసం చాలా ఎక్కువ బ్యాంగ్‌ను

178
00:12:16,926 --> 00:12:17,740
కలిగి ఉంటుంది.

179
00:12:17,740 --> 00:12:22,880
బక్ సరే, జూమ్ అవుట్ చేసి, ఇప్పటివరకు మనం ఎక్కడ ఉన్నామో సంక్షిప్తం చేద్దాం.

180
00:12:22,880 --> 00:12:26,801
నెట్‌వర్క్ అనేది 784 ఇన్‌పుట్‌లు మరియు 10 అవుట్‌పుట్‌లతో

181
00:12:26,801 --> 00:12:30,860
కూడిన ఈ ఫంక్షన్, ఈ వెయిటెడ్ మొత్తాల పరంగా నిర్వచించబడింది.

182
00:12:30,860 --> 00:12:34,160
ఖర్చు ఫంక్షన్ దాని పైన సంక్లిష్టత యొక్క పొర.

183
00:12:34,160 --> 00:12:38,467
ఇది 13,000 బరువులు మరియు పక్షపాతాలను ఇన్‌పుట్‌లుగా తీసుకుంటుంది

184
00:12:38,467 --> 00:12:42,640
మరియు శిక్షణా ఉదాహరణల ఆధారంగా ఒకే కొలమానాన్ని ఉమ్మివేస్తుంది.

185
00:12:42,640 --> 00:12:47,520
ఖర్చు ఫంక్షన్ యొక్క గ్రేడియంట్ ఇప్పటికీ సంక్లిష్టత యొక్క మరొక పొర.

186
00:12:47,520 --> 00:12:52,693
ఈ బరువులు మరియు పక్షపాతాలు అన్నింటికీ ఎలాంటి నడ్జ్‌లు కాస్ట్ ఫంక్షన్

187
00:12:52,693 --> 00:12:57,941
యొక్క విలువకు వేగవంతమైన మార్పుకు కారణమవుతాయో ఇది మాకు తెలియజేస్తుంది,

188
00:12:57,941 --> 00:13:03,040
ఇది మీరు ఏ బరువులకు అత్యంత ముఖ్యమైన మార్పులు అని అర్థం చేసుకోవచ్చు.

189
00:13:03,040 --> 00:13:07,085
కాబట్టి మీరు యాదృచ్ఛిక బరువులు మరియు పక్షపాతాలతో నెట్‌వర్క్‌ను ప్రారంభించినప్పుడు

190
00:13:07,085 --> 00:13:10,588
మరియు ఈ గ్రేడియంట్ అవరోహణ ప్రక్రియ ఆధారంగా వాటిని అనేకసార్లు సర్దుబాటు

191
00:13:10,588 --> 00:13:14,240
చేసినప్పుడు, ఇది ఇంతకు ముందెన్నడూ చూడని చిత్రాలపై ఎంత బాగా పని చేస్తుంది?

192
00:13:14,240 --> 00:13:18,141
నేను ఇక్కడ వివరించినది, 16 న్యూరాన్‌ల యొక్క రెండు దాచిన

193
00:13:18,141 --> 00:13:22,182
పొరలతో, ఎక్కువగా సౌందర్య కారణాల కోసం ఎంపిక చేయబడింది, ఇది

194
00:13:22,182 --> 00:13:26,920
చెడ్డది కాదు, ఇది సరిగ్గా చూసే 96% కొత్త చిత్రాలను వర్గీకరిస్తుంది.

195
00:13:26,920 --> 00:13:31,610
మరియు నిజాయితీగా, మీరు దానిని గందరగోళానికి గురిచేసే కొన్ని

196
00:13:31,610 --> 00:13:36,300
ఉదాహరణలను చూస్తే, మీరు దానిని కొంచెం మందగించవలసి వస్తుంది.

197
00:13:36,300 --> 00:13:38,709
మీరు దాచిన లేయర్ స్ట్రక్చర్‌తో ప్లే చేసి, రెండు

198
00:13:38,709 --> 00:13:41,220
ట్వీక్‌లు చేస్తే, మీరు దీన్ని 98% వరకు పొందవచ్చు.

199
00:13:41,220 --> 00:13:42,900
మరియు అది చాలా బాగుంది!

200
00:13:42,900 --> 00:13:47,458
ఇది ఉత్తమమైనది కాదు, మీరు ఈ సాదా వెనిలా నెట్‌వర్క్ కంటే మరింత అధునాతనంగా ఉండటం

201
00:13:47,458 --> 00:13:52,190
ద్వారా ఖచ్చితంగా మెరుగైన పనితీరును పొందవచ్చు, కానీ ప్రారంభ పని ఎంత నిరుత్సాహకరంగా

202
00:13:52,190 --> 00:13:57,095
ఉందో చూస్తే, ఏ నెట్‌వర్క్ అయినా ఇంతకు ముందెన్నడూ చూడని చిత్రాలపై దీన్ని బాగా చేయడంలో

203
00:13:57,095 --> 00:14:02,000
అద్భుతమైన ఏదో ఉందని నేను భావిస్తున్నాను. ఏ నమూనాల కోసం చూడాలో ప్రత్యేకంగా చెప్పలేదు.

204
00:14:02,000 --> 00:14:05,966
వాస్తవానికి, నేను ఈ నిర్మాణాన్ని ప్రేరేపించిన మార్గం ఏమిటంటే, మనకు

205
00:14:05,966 --> 00:14:10,050
ఉండే ఆశను వివరించడం ద్వారా, రెండవ పొర చిన్న అంచులపైకి ఎదగవచ్చు, మూడవ

206
00:14:10,050 --> 00:14:13,898
లేయర్ లూప్‌లు మరియు పొడవైన గీతలను గుర్తించడానికి ఆ అంచులను ఒకచోట

207
00:14:13,898 --> 00:14:18,220
చేర్చుతుంది మరియు వాటిని ముక్కలు చేయవచ్చు. అంకెలను గుర్తించడానికి కలిసి.

208
00:14:18,220 --> 00:14:21,040
నిజానికి మన నెట్‌వర్క్ చేస్తున్నది ఇదేనా?

209
00:14:21,040 --> 00:14:24,880
సరే, దీని కోసం కనీసం, అస్సలు కాదు.

210
00:14:24,880 --> 00:14:28,726
మొదటి లేయర్‌లోని అన్ని న్యూరాన్‌ల నుండి రెండవ లేయర్‌లోని ఇచ్చిన

211
00:14:28,726 --> 00:14:32,932
న్యూరాన్‌కి కనెక్షన్‌ల బరువులు రెండవ లేయర్ న్యూరాన్ పొందుతున్న ఇచ్చిన

212
00:14:32,932 --> 00:14:37,440
పిక్సెల్ నమూనాగా ఎలా విజువలైజ్ చేయబడతాయో మనం చివరిగా ఎలా చూశామో గుర్తుందా?

213
00:14:37,440 --> 00:14:42,732
సరే, ఈ పరివర్తనలతో అనుబంధించబడిన బరువుల కోసం మనం అలా చేసినప్పుడు,

214
00:14:42,732 --> 00:14:48,185
ఇక్కడ మరియు అక్కడ ఉన్న వివిక్త చిన్న అంచులను తీయడానికి బదులుగా, అవి

215
00:14:48,185 --> 00:14:54,200
దాదాపు యాదృచ్ఛికంగా కనిపిస్తాయి, మధ్యలో కొన్ని చాలా వదులుగా ఉండే నమూనాలతో.

216
00:14:54,200 --> 00:14:59,105
13,000 డైమెన్షనల్ స్పేస్‌లో సాధ్యమయ్యే బరువులు మరియు పక్షపాతాలతో, మా

217
00:14:59,105 --> 00:15:04,081
నెట్‌వర్క్ చాలా చిత్రాలను విజయవంతంగా వర్గీకరించినప్పటికీ, మనం ఆశించిన

218
00:15:04,081 --> 00:15:09,840
నమూనాలను సరిగ్గా అందుకోలేనంత సంతోషకరమైన స్థానిక కనిష్టంగా ఉన్నట్లు అనిపిస్తుంది.

219
00:15:09,840 --> 00:15:12,021
మరియు నిజంగా ఈ పాయింట్‌ని ఇంటికి తీసుకెళ్లడానికి, మీరు

220
00:15:12,021 --> 00:15:14,600
యాదృచ్ఛిక చిత్రాన్ని ఇన్‌పుట్ చేసినప్పుడు ఏమి జరుగుతుందో చూడండి.

221
00:15:14,600 --> 00:15:19,621
సిస్టమ్ స్మార్ట్‌గా ఉంటే, అది అనిశ్చితంగా ఉంటుందని మీరు ఆశించవచ్చు, బహుశా ఆ 10

222
00:15:19,621 --> 00:15:24,643
అవుట్‌పుట్ న్యూరాన్‌లలో దేనినైనా సక్రియం చేయకపోవచ్చు లేదా వాటన్నింటిని సమానంగా

223
00:15:24,643 --> 00:15:29,411
యాక్టివేట్ చేయకపోవచ్చు, బదులుగా ఇది మీకు నమ్మకంగా కొన్ని అర్ధంలేని సమాధానం

224
00:15:29,411 --> 00:15:34,560
ఇస్తుంది, ఇది యాదృచ్ఛికంగా అనిపిస్తుంది. శబ్దం 5, అలాగే 5 యొక్క వాస్తవ చిత్రం 5.

225
00:15:34,560 --> 00:15:37,587
విభిన్న పదజాలంతో, ఈ నెట్‌వర్క్ అంకెలను చక్కగా

226
00:15:37,587 --> 00:15:41,800
గుర్తించగలిగినప్పటికీ, వాటిని ఎలా గీయాలి అనే ఆలోచన దీనికి లేదు.

227
00:15:41,800 --> 00:15:45,400
ఇది చాలా కఠినంగా నిర్బంధించబడిన శిక్షణా సెటప్ కాబట్టి.

228
00:15:45,400 --> 00:15:48,220
నా ఉద్దేశ్యం, ఇక్కడ నెట్‌వర్క్ షూస్‌లో మిమ్మల్ని మీరు ఉంచుకోండి.

229
00:15:48,220 --> 00:15:52,702
దాని దృక్కోణంలో, మొత్తం విశ్వం ఒక చిన్న గ్రిడ్‌లో కేంద్రీకృతమై స్పష్టంగా

230
00:15:52,702 --> 00:15:57,308
నిర్వచించబడిన కదలని అంకెలు తప్ప మరేమీ కలిగి ఉండదు మరియు దాని ఖర్చు పనితీరు

231
00:15:57,308 --> 00:16:02,160
దాని నిర్ణయాలపై పూర్తిగా నమ్మకంగా ఉండటానికి ఎటువంటి ప్రోత్సాహాన్ని అందించలేదు.

232
00:16:02,160 --> 00:16:06,010
కాబట్టి ఆ రెండవ పొర న్యూరాన్‌లు నిజంగా ఏమి చేస్తున్నాయో దాని చిత్రంగా, అంచులు మరియు

233
00:16:06,010 --> 00:16:09,586
నమూనాలను తీయడానికి ప్రేరణతో నేను ఈ నెట్‌వర్క్‌ను ఎందుకు పరిచయం చేస్తానని మీరు

234
00:16:09,586 --> 00:16:10,320
ఆశ్చర్యపోవచ్చు.

235
00:16:10,320 --> 00:16:13,040
నా ఉద్దేశ్యం, అది పూర్తి చేసేది కాదు.

236
00:16:13,040 --> 00:16:17,480
సరే, ఇది మా అంతిమ లక్ష్యం కాదు, బదులుగా ఒక ప్రారంభ స్థానం.

237
00:16:17,480 --> 00:16:22,711
స్పష్టముగా, ఇది పాత సాంకేతికత, 80 మరియు 90 లలో పరిశోధించబడిన రకం, మరియు మీరు మరింత

238
00:16:22,711 --> 00:16:28,131
వివరణాత్మక ఆధునిక రూపాంతరాలను అర్థం చేసుకునే ముందు మీరు దానిని అర్థం చేసుకోవాలి మరియు

239
00:16:28,131 --> 00:16:33,236
ఇది స్పష్టంగా కొన్ని ఆసక్తికరమైన సమస్యలను పరిష్కరించగలదు, కానీ మీరు దేని గురించి

240
00:16:33,236 --> 00:16:38,720
మరింత తవ్వుతారు ఆ దాచిన పొరలు నిజంగా చేస్తున్నాయి, తక్కువ తెలివితేటలు కనిపిస్తున్నాయి.

241
00:16:38,720 --> 00:16:41,810
నెట్‌వర్క్‌లు ఎలా నేర్చుకుంటాయనే దాని నుండి మీరు ఎలా నేర్చుకుంటారు

242
00:16:41,810 --> 00:16:44,623
అనేదానికి ఫోకస్‌ని ఒక క్షణం మార్చడం, మీరు ఏదో ఒకవిధంగా ఇక్కడ

243
00:16:44,623 --> 00:16:47,160
ఉన్న మెటీరియల్‌తో చురుకుగా పాల్గొంటేనే అది జరుగుతుంది.

244
00:16:47,160 --> 00:16:50,705
మీరు చేయాలనుకుంటున్న ఒక అందమైన సాధారణ విషయం ఏమిటంటే, ఇప్పుడే పాజ్

245
00:16:50,705 --> 00:16:54,412
చేయండి మరియు మీరు ఈ సిస్టమ్‌లో ఎలాంటి మార్పులు చేయవచ్చు మరియు అంచులు

246
00:16:54,412 --> 00:16:57,904
మరియు నమూనాల వంటి వాటిని మెరుగ్గా ఎంచుకోవాలని మీరు కోరుకుంటే అది

247
00:16:57,904 --> 00:17:01,880
చిత్రాలను ఎలా గ్రహిస్తుంది అనే దాని గురించి ఒక్క క్షణం లోతుగా ఆలోచించండి.

248
00:17:01,880 --> 00:17:05,639
కానీ దాని కంటే మెరుగ్గా, వాస్తవానికి మెటీరియల్‌తో నిమగ్నమవ్వడానికి, లోతైన అభ్యాసం

249
00:17:05,639 --> 00:17:09,720
మరియు న్యూరల్ నెట్‌వర్క్‌లపై మైఖేల్ నీల్సన్ పుస్తకాన్ని నేను బాగా సిఫార్సు చేస్తున్నాను.

250
00:17:09,720 --> 00:17:14,650
దీనిలో, మీరు ఈ ఖచ్చితమైన ఉదాహరణ కోసం డౌన్‌లోడ్ చేయడానికి మరియు ప్లే చేయడానికి కోడ్ మరియు

251
00:17:14,650 --> 00:17:19,360
డేటాను కనుగొనవచ్చు మరియు పుస్తకం ఆ కోడ్ ఏమి చేస్తుందో దశలవారీగా మీకు తెలియజేస్తుంది.

252
00:17:19,360 --> 00:17:23,594
అద్భుతం ఏమిటంటే, ఈ పుస్తకం ఉచితం మరియు పబ్లిక్‌గా అందుబాటులో ఉంది, కాబట్టి మీరు

253
00:17:23,594 --> 00:17:28,040
దాని నుండి ఏదైనా పొందినట్లయితే, నీల్సన్ ప్రయత్నాల కోసం విరాళం ఇవ్వడంలో నాతో చేరండి.

254
00:17:28,040 --> 00:17:33,554
నేను క్రిస్ ఓలా యొక్క అద్భుతమైన మరియు అందమైన బ్లాగ్ పోస్ట్ మరియు డిస్టిల్‌లోని

255
00:17:33,554 --> 00:17:38,720
కథనాలతో సహా వివరణలో నాకు చాలా నచ్చిన రెండు ఇతర వనరులను కూడా లింక్ చేసాను.

256
00:17:38,720 --> 00:17:41,648
గత కొన్ని నిమిషాలు ఇక్కడ విషయాలను మూసివేయడానికి, నేను లీషా లీతో

257
00:17:41,648 --> 00:17:44,440
చేసిన ఇంటర్వ్యూ స్నిప్పెట్‌లోకి తిరిగి వెళ్లాలనుకుంటున్నాను.

258
00:17:44,440 --> 00:17:48,520
చివరి వీడియో నుండి మీరు ఆమెను గుర్తుంచుకోవచ్చు, ఆమె లోతైన అభ్యాసంలో ఆమె PhD పని చేసింది.

259
00:17:48,520 --> 00:17:52,330
ఈ చిన్న స్నిప్పెట్‌లో, కొన్ని ఆధునిక ఇమేజ్ రికగ్నిషన్ నెట్‌వర్క్‌లు వాస్తవానికి

260
00:17:52,330 --> 00:17:56,380
ఎలా నేర్చుకుంటున్నాయో నిజంగా త్రవ్విన రెండు ఇటీవలి పేపర్ల గురించి ఆమె మాట్లాడుతుంది.

261
00:17:56,380 --> 00:18:00,621
మేము సంభాషణలో ఉన్న చోట సెటప్ చేయడానికి, మొదటి పేపర్ ఇమేజ్ రికగ్నిషన్‌లో నిజంగా మంచి ఈ

262
00:18:00,621 --> 00:18:04,961
డీప్ న్యూరల్ నెట్‌వర్క్‌లలో ఒకదాన్ని తీసుకుంది మరియు సరిగ్గా లేబుల్ చేయబడిన డేటాసెట్‌లో

263
00:18:04,961 --> 00:18:09,400
శిక్షణ ఇవ్వడానికి బదులుగా, ఇది శిక్షణకు ముందు చుట్టూ ఉన్న అన్ని లేబుల్‌లను షఫుల్ చేసింది.

264
00:18:09,400 --> 00:18:12,540
సహజంగానే ఇక్కడ పరీక్ష ఖచ్చితత్వం యాదృచ్ఛికంగా కంటే మెరుగైనది

265
00:18:12,540 --> 00:18:15,320
కాదు, ఎందుకంటే ప్రతిదీ యాదృచ్ఛికంగా లేబుల్ చేయబడింది.

266
00:18:15,320 --> 00:18:18,351
కానీ సరిగ్గా లేబుల్ చేయబడిన డేటాసెట్‌లో మీరు సాధించిన

267
00:18:18,351 --> 00:18:21,440
అదే శిక్షణ ఖచ్చితత్వాన్ని ఇది ఇప్పటికీ సాధించగలిగింది.

268
00:18:21,440 --> 00:18:26,268
ప్రాథమికంగా, ఈ నిర్దిష్ట నెట్‌వర్క్‌కు మిలియన్ల బరువులు కేవలం యాదృచ్ఛిక డేటాను

269
00:18:26,268 --> 00:18:31,341
గుర్తుంచుకోవడానికి సరిపోతాయి, ఈ ఖర్చు ఫంక్షన్‌ను తగ్గించడం అనేది చిత్రంలో ఏ విధమైన

270
00:18:31,341 --> 00:18:36,720
నిర్మాణానికి అనుగుణంగా ఉంటుందా అనే ప్రశ్నను లేవనెత్తుతుంది లేదా ఇది కేవలం జ్ఞాపకం ఉందా?

271
00:18:36,720 --> 00:18:40,120
. . . సరైన వర్గీకరణ ఏమిటో మొత్తం డేటాసెట్‌ను గుర్తుంచుకోవడానికి.

272
00:18:40,120 --> 00:18:44,019
ఈ సంవత్సరం ICMLలో అర్ధ సంవత్సరం తరువాత, మీకు తెలిసిన జంట, ఖచ్చితంగా

273
00:18:44,019 --> 00:18:48,091
ఖండన కాగితం లేదు, కానీ అలాంటి కొన్ని అంశాలను ప్రస్తావించిన కాగితం, హే,

274
00:18:48,091 --> 00:18:52,220
వాస్తవానికి ఈ నెట్‌వర్క్‌లు దాని కంటే కొంచెం తెలివిగా ఏదో చేస్తున్నాయి.

275
00:18:52,220 --> 00:18:58,527
మీరు ఆ ఖచ్చితత్వ వక్రతను పరిశీలిస్తే, మీరు కేవలం యాదృచ్ఛిక డేటాసెట్‌లో శిక్షణ

276
00:18:58,527 --> 00:19:05,240
పొందుతున్నట్లయితే, ఆ వక్రరేఖ చాలా నెమ్మదిగా దాదాపుగా ఒక సరళ పద్ధతిలో తగ్గిపోతుంది.

277
00:19:05,240 --> 00:19:08,604
కాబట్టి మీరు నిజంగా సాధ్యమయ్యే స్థానిక కనిష్టాన్ని కనుగొనడంలో చాలా

278
00:19:08,604 --> 00:19:12,320
కష్టపడుతున్నారు, మీకు తెలుసా, మీకు ఆ ఖచ్చితత్వాన్ని అందించే సరైన బరువులు.

279
00:19:12,320 --> 00:19:15,747
మీరు నిజంగా నిర్మాణాత్మక డేటాసెట్‌పై శిక్షణ పొందుతున్నట్లయితే, సరైన

280
00:19:15,747 --> 00:19:19,427
లేబుల్‌లను కలిగి ఉన్నట్లయితే, మీకు తెలుసా, మీరు ప్రారంభంలో కొంచెం ఫిడేలు

281
00:19:19,427 --> 00:19:23,360
చేస్తారు, కానీ ఆ ఖచ్చితత్వ స్థాయికి చేరుకోవడానికి మీరు చాలా వేగంగా పడిపోయారు.

282
00:19:23,360 --> 00:19:28,580
కాబట్టి కొంత కోణంలో స్థానిక గరిష్టాన్ని కనుగొనడం సులభం.

283
00:19:28,580 --> 00:19:32,472
మరియు దాని గురించి కూడా ఆసక్తికరమైన విషయం ఏమిటంటే, ఇది వాస్తవానికి

284
00:19:32,472 --> 00:19:36,306
కొన్ని సంవత్సరాల క్రితం నుండి మరొక పేపర్‌ను వెలుగులోకి తెస్తుంది,

285
00:19:36,306 --> 00:19:40,140
ఇది నెట్‌వర్క్ లేయర్‌ల గురించి చాలా ఎక్కువ సరళీకరణలను కలిగి ఉంది.

286
00:19:40,140 --> 00:19:44,712
కానీ ఫలితాలలో ఒకటి, మీరు ఆప్టిమైజేషన్ ల్యాండ్‌స్కేప్‌ను చూస్తే, ఈ నెట్‌వర్క్‌లు

287
00:19:44,712 --> 00:19:49,400
నేర్చుకునే స్థానిక మినిమా వాస్తవానికి సమాన నాణ్యతతో ఎలా ఉంటుందో చెప్పడం జరిగింది.

288
00:19:49,400 --> 00:19:52,006
కాబట్టి కొంత కోణంలో, మీ డేటా సెట్ నిర్మాణాత్మకంగా

289
00:19:52,006 --> 00:19:54,300
ఉంటే, మీరు దానిని మరింత సులభంగా కనుగొనగలరు.

290
00:19:54,300 --> 00:20:01,140
పాట్రియోన్‌కు మద్దతు ఇస్తున్న మీలో ఎప్పటిలాగే నా ధన్యవాదాలు.

291
00:20:01,140 --> 00:20:04,296
Patreonలో గేమ్ ఛేంజర్ అంటే ఏమిటో నేను ముందే చెప్పాను,

292
00:20:04,296 --> 00:20:07,160
కానీ మీరు లేకుండా ఈ వీడియోలు నిజంగా సాధ్యం కాదు.

293
00:20:07,160 --> 00:20:10,264
VC సంస్థ యాంప్లిఫై పార్ట్‌నర్‌లకు మరియు సిరీస్‌లోని ఈ ప్రారంభ వీడియోలకు

294
00:20:10,264 --> 00:20:13,240
వారి మద్దతుకు కూడా నేను ప్రత్యేక ధన్యవాదాలు తెలియజేయాలనుకుంటున్నాను.

295
00:20:13,240 --> 00:20:33,140
ధన్యవాదాలు.

