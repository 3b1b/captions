[
 {
  "input": "Last video I laid out the structure of a neural network.",
  "translatedText": "Im letzten Video habe ich die Struktur eines neuronalen Netzwerks dargelegt.",
  "n_reviews": 0,
  "start": 4.18,
  "end": 7.28
 },
 {
  "input": "I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video.",
  "translatedText": "Ich werde hier eine kurze Zusammenfassung geben, damit es uns noch frisch im Gedächtnis bleibt, und dann habe ich zwei Hauptziele für dieses Video.",
  "n_reviews": 0,
  "start": 7.68,
  "end": 12.6
 },
 {
  "input": "The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well.",
  "translatedText": "Die erste besteht darin, die Idee des Gradientenabstiegs vorzustellen, der nicht nur dem Lernen neuronaler Netze zugrunde liegt, sondern auch der Funktionsweise vieler anderer maschineller Lernverfahren.",
  "n_reviews": 0,
  "start": 13.1,
  "end": 20.6
 },
 {
  "input": "Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for.",
  "translatedText": "Danach werden wir uns etwas genauer damit befassen, wie dieses spezielle Netzwerk funktioniert und wonach diese verborgenen Neuronenschichten letztendlich suchen.",
  "n_reviews": 0,
  "start": 21.12,
  "end": 27.94
 },
 {
  "input": "As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks.",
  "translatedText": "Zur Erinnerung: Unser Ziel ist hier das klassische Beispiel der handschriftlichen Ziffernerkennung, die Hallo-Welt der neuronalen Netze.",
  "n_reviews": 0,
  "start": 28.98,
  "end": 36.22
 },
 {
  "input": "These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1.",
  "translatedText": "Diese Ziffern werden in einem 28x28-Pixel-Raster gerendert, wobei jedes Pixel einen Graustufenwert zwischen 0 und 1 aufweist.",
  "n_reviews": 0,
  "start": 37.02,
  "end": 43.42
 },
 {
  "input": "Those are what determine the activations of 784 neurons in the input layer of the network.",
  "translatedText": "Diese bestimmen die Aktivierung von 784 Neuronen in der Eingabeschicht des Netzwerks.",
  "n_reviews": 0,
  "start": 43.82,
  "end": 50.04
 },
 {
  "input": "And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias.",
  "translatedText": "Und dann basiert die Aktivierung für jedes Neuron in den folgenden Schichten auf einer gewichteten Summe aller Aktivierungen in der vorherigen Schicht plus einer speziellen Zahl, die als Bias bezeichnet wird.",
  "n_reviews": 0,
  "start": 51.18,
  "end": 60.82
 },
 {
  "input": "Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video.",
  "translatedText": "Dann bilden Sie diese Summe mit einer anderen Funktion, wie der Sigmoid-Squishifizierung oder einem Relu, so wie ich es im letzten Video durchgegangen bin.",
  "n_reviews": 0,
  "start": 62.16,
  "end": 68.94
 },
 {
  "input": "In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does.",
  "translatedText": "Insgesamt verfügt das Netzwerk angesichts der etwas willkürlichen Wahl von zwei versteckten Schichten mit jeweils 16 Neuronen über etwa 13.000 Gewichte und Bias, die wir anpassen können, und es sind diese Werte, die bestimmen, was genau das Netzwerk tatsächlich tut.",
  "n_reviews": 0,
  "start": 69.48,
  "end": 84.38
 },
 {
  "input": "Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit.",
  "translatedText": "Wenn wir also sagen, dass dieses Netzwerk eine bestimmte Ziffer klassifiziert, meinen wir, dass das hellste dieser 10 Neuronen in der letzten Schicht dieser Ziffer entspricht.",
  "n_reviews": 0,
  "start": 84.88,
  "end": 93.3
 },
 {
  "input": "And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits.",
  "translatedText": "Und denken Sie daran, die Motivation, die wir hier für die Schichtstruktur im Sinn hatten, war, dass die zweite Schicht vielleicht die Kanten aufnehmen könnte und die dritte Schicht Muster wie Schleifen und Linien aufgreifen könnte und die letzte Schicht diese einfach zusammenfügen könnte Muster zum Erkennen von Ziffern.",
  "n_reviews": 0,
  "start": 94.1,
  "end": 108.8
 },
 {
  "input": "So here, we learn how the network learns.",
  "translatedText": "Hier erfahren wir also, wie das Netzwerk lernt.",
  "n_reviews": 0,
  "start": 109.8,
  "end": 112.24
 },
 {
  "input": "What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data.",
  "translatedText": "Was wir wollen, ist ein Algorithmus, mit dem Sie diesem Netzwerk eine ganze Reihe von Trainingsdaten zeigen können, die in Form einer Reihe verschiedener Bilder handgeschriebener Ziffern vorliegen, zusammen mit Beschriftungen für das, was sie sein sollen, und das wird auch so sein Passen Sie diese 13.000 Gewichtungen und Verzerrungen an, um die Leistung anhand der Trainingsdaten zu verbessern.",
  "n_reviews": 0,
  "start": 112.64,
  "end": 130.12
 },
 {
  "input": "Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data.",
  "translatedText": "Hoffentlich führt diese Schichtstruktur dazu, dass sich das Gelernte auf Bilder verallgemeinern lässt, die über diese Trainingsdaten hinausgehen.",
  "n_reviews": 0,
  "start": 130.72,
  "end": 136.86
 },
 {
  "input": "The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images.",
  "translatedText": "Wir testen das so, dass Sie dem Netzwerk nach dem Training mehr beschriftete Daten zeigen, die es noch nie zuvor gesehen hat, und sehen, wie genau es diese neuen Bilder klassifiziert.",
  "n_reviews": 0,
  "start": 137.64,
  "end": 146.7
 },
 {
  "input": "Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be.",
  "translatedText": "Zum Glück für uns, und was dies zu einem so häufigen Beispiel macht, ist, dass die guten Leute hinter der MNIST-Datenbank eine Sammlung von Zehntausenden handgeschriebenen Ziffernbildern zusammengestellt haben, jedes mit den Zahlen beschriftet, die es tragen soll Sei.",
  "n_reviews": 0,
  "start": 151.12,
  "end": 164.2
 },
 {
  "input": "And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise.",
  "translatedText": "Und so provokativ es auch sein mag, eine Maschine als lernend zu bezeichnen, wenn man erst einmal sieht, wie sie funktioniert, fühlt es sich viel weniger wie eine verrückte Science-Fiction-Prämisse an, sondern viel mehr wie eine Rechenübung.",
  "n_reviews": 0,
  "start": 164.9,
  "end": 175.48
 },
 {
  "input": "I mean, basically it comes down to finding the minimum of a certain function.",
  "translatedText": "Ich meine, im Grunde kommt es darauf an, das Minimum einer bestimmten Funktion zu finden.",
  "n_reviews": 0,
  "start": 176.2,
  "end": 179.96
 },
 {
  "input": "Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
  "translatedText": "Bedenken Sie, dass wir konzeptionell davon ausgehen, dass jedes Neuron mit allen Neuronen in der vorherigen Schicht verbunden ist, und dass die Gewichte in der gewichteten Summe, die seine Aktivierung definieren, so etwas wie die Stärken dieser Verbindungen sind, und die Verzerrung ist ein gewisser Hinweis darauf ob dieses Neuron dazu neigt, aktiv oder inaktiv zu sein.",
  "n_reviews": 0,
  "start": 181.94,
  "end": 198.96
 },
 {
  "input": "And to start things off, we're just going to initialize all of those weights and biases totally randomly.",
  "translatedText": "Und zu Beginn werden wir alle diese Gewichte und Verzerrungen völlig zufällig initialisieren.",
  "n_reviews": 0,
  "start": 199.72,
  "end": 204.4
 },
 {
  "input": "Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random.",
  "translatedText": "Es erübrigt sich zu erwähnen, dass dieses Netzwerk bei einem bestimmten Trainingsbeispiel ziemlich schlecht abschneiden wird, da es einfach etwas Zufälliges tut.",
  "n_reviews": 0,
  "start": 204.94,
  "end": 210.72
 },
 {
  "input": "For example, you feed in this image of a 3, and the output layer just looks like a mess.",
  "translatedText": "Wenn Sie beispielsweise dieses Bild einer 3 einspeisen, sieht die Ausgabeebene einfach wie ein Durcheinander aus.",
  "n_reviews": 0,
  "start": 211.04,
  "end": 216.02
 },
 {
  "input": "So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash.",
  "translatedText": "Was Sie also tun, ist, eine Kostenfunktion zu definieren, eine Möglichkeit, dem Computer mitzuteilen, nein, schlechter Computer, dass die Ausgabe Aktivierungen haben sollte, die für die meisten Neuronen 0 sind, aber 1 für dieses Neuron. Was Sie mir gegeben haben, ist völliger Müll.",
  "n_reviews": 0,
  "start": 216.6,
  "end": 230.76
 },
 {
  "input": "To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example.",
  "translatedText": "Um es etwas mathematischer auszudrücken: Sie addieren die Quadrate der Differenzen zwischen jeder dieser Trash-Output-Aktivierungen und dem Wert, den sie haben sollen, und das ist, was wir die Kosten eines einzelnen Trainingsbeispiels nennen.",
  "n_reviews": 0,
  "start": 231.72,
  "end": 245.02
 },
 {
  "input": "Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing.",
  "translatedText": "Beachten Sie, dass diese Summe klein ist, wenn das Netzwerk das Bild sicher korrekt klassifiziert, aber groß ist, wenn das Netzwerk den Eindruck hat, nicht zu wissen, was es tut.",
  "n_reviews": 0,
  "start": 245.96,
  "end": 256.4
 },
 {
  "input": "So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal.",
  "translatedText": "Was Sie dann tun, ist, die durchschnittlichen Kosten für alle Zehntausende von Schulungsbeispielen zu berücksichtigen, die Ihnen zur Verfügung stehen.",
  "n_reviews": 0,
  "start": 258.64,
  "end": 265.44
 },
 {
  "input": "This average cost is our measure for how lousy the network is, and how bad the computer should feel.",
  "translatedText": "Diese durchschnittlichen Kosten sind unser Maß dafür, wie schlecht das Netzwerk ist und wie schlecht sich der Computer fühlen sollte.",
  "n_reviews": 0,
  "start": 267.04,
  "end": 272.74
 },
 {
  "input": "And that's a complicated thing.",
  "translatedText": "Und das ist eine komplizierte Sache.",
  "n_reviews": 0,
  "start": 273.42,
  "end": 274.6
 },
 {
  "input": "Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases?",
  "translatedText": "Erinnern Sie sich daran, dass das Netzwerk selbst im Grunde eine Funktion war, die 784 Zahlen als Eingaben, die Pixelwerte, aufnimmt und 10 Zahlen als Ausgabe ausgibt und in gewisser Weise durch all diese Gewichte und Vorurteile parametrisiert wird?",
  "n_reviews": 0,
  "start": 275.04,
  "end": 288.8
 },
 {
  "input": "Well the cost function is a layer of complexity on top of that.",
  "translatedText": "Nun, die Kostenfunktion ist darüber hinaus eine Ebene der Komplexität.",
  "n_reviews": 0,
  "start": 289.5,
  "end": 292.82
 },
 {
  "input": "It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data.",
  "translatedText": "Als Eingabe nimmt es diese rund 13.000 Gewichte und Bias und gibt eine einzige Zahl aus, die beschreibt, wie schlecht diese Gewichte und Bias sind, und die Art und Weise, wie sie definiert wird, hängt vom Verhalten des Netzwerks über all die Zehntausende von Trainingsdaten ab.",
  "n_reviews": 0,
  "start": 293.1,
  "end": 308.9
 },
 {
  "input": "That's a lot to think about.",
  "translatedText": "Das gibt viel zu bedenken.",
  "n_reviews": 0,
  "start": 309.52,
  "end": 311.0
 },
 {
  "input": "But just telling the computer what a crappy job it's doing isn't very helpful.",
  "translatedText": "Aber dem Computer nur zu sagen, was für eine beschissene Arbeit er macht, ist nicht sehr hilfreich.",
  "n_reviews": 0,
  "start": 312.4,
  "end": 315.82
 },
 {
  "input": "You want to tell it how to change those weights and biases so that it gets better.",
  "translatedText": "Sie möchten ihm sagen, wie diese Gewichtungen und Voreingenommenheiten geändert werden können, damit es besser wird.",
  "n_reviews": 0,
  "start": 316.22,
  "end": 320.06
 },
 {
  "input": "To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output.",
  "translatedText": "Um es einfacher zu machen, statt sich eine Funktion mit 13.000 Eingaben vorzustellen, stellen Sie sich einfach eine einfache Funktion vor, die eine Zahl als Eingabe und eine Zahl als Ausgabe hat.",
  "n_reviews": 0,
  "start": 320.78,
  "end": 330.48
 },
 {
  "input": "How do you find an input that minimizes the value of this function?",
  "translatedText": "Wie findet man eine Eingabe, die den Wert dieser Funktion minimiert?",
  "n_reviews": 0,
  "start": 331.48,
  "end": 335.3
 },
 {
  "input": "Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function.",
  "translatedText": "Infinitesimalrechnungsstudenten werden wissen, dass man dieses Minimum manchmal explizit ermitteln kann, aber das ist bei wirklich komplizierten Funktionen nicht immer machbar, schon gar nicht in der 13.000-Eingabe-Version dieser Situation für unsere verrückt komplizierte Kostenfunktion für neuronale Netze.",
  "n_reviews": 0,
  "start": 336.46,
  "end": 351.08
 },
 {
  "input": "A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower.",
  "translatedText": "Eine flexiblere Taktik besteht darin, bei einem beliebigen Input zu beginnen und herauszufinden, in welche Richtung Sie gehen sollten, um den Output zu senken.",
  "n_reviews": 0,
  "start": 351.58,
  "end": 359.2
 },
 {
  "input": "Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative.",
  "translatedText": "Konkret: Wenn Sie die Steigung der Funktion an Ihrem Standort ermitteln können, verschieben Sie die Eingabe nach links, wenn diese Steigung positiv ist, und verschieben Sie die Eingabe nach rechts, wenn diese Steigung negativ ist.",
  "n_reviews": 0,
  "start": 360.08,
  "end": 369.9
 },
 {
  "input": "If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function.",
  "translatedText": "Wenn Sie dies wiederholt tun, an jedem Punkt die neue Steigung überprüfen und den entsprechenden Schritt unternehmen, nähern Sie sich einem lokalen Minimum der Funktion.",
  "n_reviews": 0,
  "start": 371.96,
  "end": 379.84
 },
 {
  "input": "The image you might have in mind here is a ball rolling down a hill.",
  "translatedText": "Das Bild, das Sie hier vielleicht im Kopf haben, ist ein Ball, der einen Hügel hinunterrollt.",
  "n_reviews": 0,
  "start": 380.64,
  "end": 383.8
 },
 {
  "input": "Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function.",
  "translatedText": "Beachten Sie, dass es selbst für diese wirklich vereinfachte Einzeleingabefunktion viele mögliche Täler gibt, in denen Sie landen könnten, je nachdem, bei welcher Zufallseingabe Sie beginnen, und es keine Garantie dafür gibt, dass das lokale Minimum, in dem Sie landen, der kleinstmögliche Wert ist der Kostenfunktion.",
  "n_reviews": 0,
  "start": 384.62,
  "end": 399.4
 },
 {
  "input": "That will carry over to our neural network case as well.",
  "translatedText": "Das wird sich auch auf unseren Fall des neuronalen Netzwerks übertragen lassen.",
  "n_reviews": 0,
  "start": 400.22,
  "end": 402.62
 },
 {
  "input": "I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that helps you from overshooting.",
  "translatedText": "Ich möchte auch, dass Sie bemerken, dass Ihre Schritte immer kleiner werden, wenn Sie Ihre Schrittgrößen proportional zur Steigung anpassen, wenn die Steigung zum Minimum hin abflacht, und das verhindert, dass Sie überschießen.",
  "n_reviews": 0,
  "start": 403.18,
  "end": 414.6
 },
 {
  "input": "Bumping up the complexity a bit, imagine instead a function with two inputs and one output.",
  "translatedText": "Um die Komplexität etwas zu erhöhen, stellen Sie sich stattdessen eine Funktion mit zwei Eingängen und einem Ausgang vor.",
  "n_reviews": 0,
  "start": 415.94,
  "end": 420.98
 },
 {
  "input": "You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it.",
  "translatedText": "Sie können sich den Eingaberaum als die xy-Ebene vorstellen und die Kostenfunktion als eine darüber liegende Fläche grafisch darstellen.",
  "n_reviews": 0,
  "start": 421.5,
  "end": 428.14
 },
 {
  "input": "Instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly.",
  "translatedText": "Anstatt nach der Steigung der Funktion zu fragen, müssen Sie fragen, in welche Richtung Sie in diesem Eingaberaum gehen sollten, um die Ausgabe der Funktion am schnellsten zu verringern.",
  "n_reviews": 0,
  "start": 428.76,
  "end": 438.96
 },
 {
  "input": "In other words, what's the downhill direction?",
  "translatedText": "Mit anderen Worten: Wie geht es bergab?",
  "n_reviews": 0,
  "start": 439.72,
  "end": 441.76
 },
 {
  "input": "Again, it's helpful to think of a ball rolling down that hill.",
  "translatedText": "Auch hier ist es hilfreich, sich einen Ball vorzustellen, der diesen Hügel hinunterrollt.",
  "n_reviews": 0,
  "start": 442.38,
  "end": 445.56
 },
 {
  "input": "Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly.",
  "translatedText": "Diejenigen unter Ihnen, die sich mit der Multivariablenrechnung auskennen, werden wissen, dass der Gradient einer Funktion die Richtung des steilsten Anstiegs angibt, also in welche Richtung Sie gehen sollten, um die Funktion am schnellsten zu erhöhen.",
  "n_reviews": 0,
  "start": 446.66,
  "end": 458.78
 },
 {
  "input": "Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly.",
  "translatedText": "Wenn Sie das Negativ dieses Gradienten nehmen, erhalten Sie natürlich die Schrittrichtung, die die Funktion am schnellsten verringert.",
  "n_reviews": 0,
  "start": 459.56,
  "end": 466.04
 },
 {
  "input": "Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is.",
  "translatedText": "Darüber hinaus ist die Länge dieses Gradientenvektors ein Hinweis darauf, wie steil der steilste Hang ist.",
  "n_reviews": 0,
  "start": 467.24,
  "end": 473.84
 },
 {
  "input": "If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic.",
  "translatedText": "Wenn Sie mit der Multivariablenrechnung nicht vertraut sind und mehr erfahren möchten, schauen Sie sich einige meiner Arbeiten zu diesem Thema für die Khan Academy an.",
  "n_reviews": 0,
  "start": 474.54,
  "end": 480.34
 },
 {
  "input": "Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is.",
  "translatedText": "Ehrlich gesagt, für Sie und mich ist im Moment nur wichtig, dass es im Prinzip eine Möglichkeit gibt, diesen Vektor zu berechnen, diesen Vektor, der Ihnen sagt, wie die Abfahrtsrichtung verläuft und wie steil sie ist.",
  "n_reviews": 0,
  "start": 480.86,
  "end": 491.9
 },
 {
  "input": "You'll be okay if that's all you know and you're not rock solid on the details.",
  "translatedText": "Wenn das alles ist, was Sie wissen, wird es Ihnen nichts ausmachen, und Sie sind nicht ganz sicher, was die Details angeht.",
  "n_reviews": 0,
  "start": 492.4,
  "end": 496.12
 },
 {
  "input": "If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over.",
  "translatedText": "Wenn Sie das hinbekommen, besteht der Algorithmus zur Minimierung der Funktion darin, diese Gradientenrichtung zu berechnen, dann einen kleinen Schritt nach unten zu machen und dies immer wieder zu wiederholen.",
  "n_reviews": 0,
  "start": 497.2,
  "end": 506.74
 },
 {
  "input": "It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs.",
  "translatedText": "Es ist die gleiche Grundidee für eine Funktion, die 13.000 Eingänge anstelle von 2 Eingängen hat.",
  "n_reviews": 0,
  "start": 507.7,
  "end": 512.82
 },
 {
  "input": "Imagine organizing all 13,000 weights and biases of our network into a giant column vector.",
  "translatedText": "Stellen Sie sich vor, alle 13.000 Gewichtungen und Bias unseres Netzwerks in einem riesigen Spaltenvektor zu organisieren.",
  "n_reviews": 0,
  "start": 513.4,
  "end": 519.46
 },
 {
  "input": "The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function.",
  "translatedText": "Der negative Gradient der Kostenfunktion ist nur ein Vektor, es ist eine Richtung innerhalb dieses wahnsinnig großen Eingaberaums, die Ihnen sagt, welche Verschiebung all dieser Zahlen den schnellsten Rückgang der Kostenfunktion bewirken wird.",
  "n_reviews": 0,
  "start": 520.14,
  "end": 534.88
 },
 {
  "input": "And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make.",
  "translatedText": "Und mit unserer speziell entwickelten Kostenfunktion bedeutet die Änderung der Gewichtungen und Verzerrungen, um sie zu verringern, natürlich, dass die Ausgabe des Netzwerks für jedes Trainingsdatenelement weniger wie eine zufällige Anordnung von 10 Werten aussieht, sondern eher wie eine tatsächliche Entscheidung, die wir wollen es zu machen.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 550.82
 },
 {
  "input": "It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples.",
  "translatedText": "Es ist wichtig zu bedenken, dass es sich bei dieser Kostenfunktion um einen Durchschnitt aller Trainingsdaten handelt. Wenn Sie sie also minimieren, bedeutet dies, dass bei allen Stichproben eine bessere Leistung erzielt wird.",
  "n_reviews": 0,
  "start": 551.44,
  "end": 561.18
 },
 {
  "input": "The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video.",
  "translatedText": "Der Algorithmus zur effizienten Berechnung dieses Gradienten, der praktisch das Herzstück des Lernens eines neuronalen Netzwerks ist, heißt Backpropagation, und darüber werde ich im nächsten Video sprechen.",
  "n_reviews": 0,
  "start": 563.82,
  "end": 573.98
 },
 {
  "input": "There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas.",
  "translatedText": "Dort möchte ich mir wirklich die Zeit nehmen, durchzugehen, was genau mit jeder Gewichtung und Verzerrung für ein bestimmtes Stück Trainingsdaten passiert, und versuchen, ein intuitives Gefühl dafür zu vermitteln, was jenseits des Stapels relevanter Berechnungen und Formeln passiert.",
  "n_reviews": 0,
  "start": 574.66,
  "end": 587.1
 },
 {
  "input": "Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function.",
  "translatedText": "Ich möchte Sie hier und jetzt vor allem wissen lassen, unabhängig von den Implementierungsdetails: Was wir meinen, wenn wir über Netzwerklernen sprechen, ist lediglich die Minimierung einer Kostenfunktion.",
  "n_reviews": 0,
  "start": 587.78,
  "end": 598.36
 },
 {
  "input": "And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill.",
  "translatedText": "Und beachten Sie, eine Konsequenz daraus ist, dass es wichtig ist, dass diese Kostenfunktion eine schöne, gleichmäßige Ausgabe hat, damit wir durch kleine Schritte bergab ein lokales Minimum finden können.",
  "n_reviews": 0,
  "start": 599.3,
  "end": 608.1
 },
 {
  "input": "This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are.",
  "translatedText": "Aus diesem Grund weisen künstliche Neuronen übrigens kontinuierlich wechselnde Aktivierungen auf und sind nicht einfach nur binär aktiv oder inaktiv, wie es bei biologischen Neuronen der Fall ist.",
  "n_reviews": 0,
  "start": 609.26,
  "end": 619.14
 },
 {
  "input": "This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent.",
  "translatedText": "Dieser Vorgang, bei dem die Eingabe einer Funktion wiederholt um ein Vielfaches des negativen Gradienten verschoben wird, wird als Gradientenabstieg bezeichnet.",
  "n_reviews": 0,
  "start": 620.22,
  "end": 626.76
 },
 {
  "input": "It's a way to converge towards some local minimum of a cost function, basically a valley in this graph.",
  "translatedText": "Dies ist eine Möglichkeit, zu einem lokalen Minimum einer Kostenfunktion zu konvergieren, im Grunde ein Tal in diesem Diagramm.",
  "n_reviews": 0,
  "start": 627.3,
  "end": 632.58
 },
 {
  "input": "I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this.",
  "translatedText": "Ich zeige natürlich immer noch das Bild einer Funktion mit zwei Eingaben, da Stupser in einem 13.000-dimensionalen Eingaberaum etwas schwer zu verstehen sind, aber es gibt eine schöne, nicht-räumliche Möglichkeit, darüber nachzudenken.",
  "n_reviews": 0,
  "start": 633.44,
  "end": 644.26
 },
 {
  "input": "Each component of the negative gradient tells us two things.",
  "translatedText": "Jede Komponente des negativen Gradienten sagt uns zwei Dinge.",
  "n_reviews": 0,
  "start": 645.08,
  "end": 648.44
 },
 {
  "input": "The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down.",
  "translatedText": "Das Vorzeichen sagt uns natürlich, ob die entsprechende Komponente des Eingabevektors nach oben oder unten verschoben werden soll.",
  "n_reviews": 0,
  "start": 649.06,
  "end": 655.14
 },
 {
  "input": "But importantly, the relative magnitudes of all these components kind of tells you which changes matter more.",
  "translatedText": "Wichtig ist jedoch, dass die relative Größe all dieser Komponenten Aufschluss darüber gibt, welche Veränderungen wichtiger sind.",
  "n_reviews": 0,
  "start": 655.8,
  "end": 662.72
 },
 {
  "input": "You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight.",
  "translatedText": "Sie sehen, in unserem Netzwerk könnte eine Anpassung an eines der Gewichte einen viel größeren Einfluss auf die Kostenfunktion haben als die Anpassung an ein anderes Gewicht.",
  "n_reviews": 0,
  "start": 665.22,
  "end": 673.04
 },
 {
  "input": "Some of these connections just matter more for our training data.",
  "translatedText": "Einige dieser Verbindungen sind für unsere Trainingsdaten einfach wichtiger.",
  "n_reviews": 0,
  "start": 674.8,
  "end": 678.2
 },
 {
  "input": "So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck.",
  "translatedText": "Sie können sich diesen Gradientenvektor unserer überwältigend massiven Kostenfunktion also so vorstellen, dass er die relative Bedeutung jedes Gewichts und jeder Verzerrung kodiert, d. h. welche dieser Änderungen das meiste für Ihr Geld bringen wird.",
  "n_reviews": 0,
  "start": 679.32,
  "end": 692.4
 },
 {
  "input": "This really is just another way of thinking about direction.",
  "translatedText": "Das ist wirklich nur eine andere Art, über die Richtung nachzudenken.",
  "n_reviews": 0,
  "start": 693.62,
  "end": 696.64
 },
 {
  "input": "To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction.",
  "translatedText": "Um ein einfacheres Beispiel zu nennen: Wenn Sie eine Funktion mit zwei Variablen als Eingabe haben und berechnen, dass deren Gradient an einem bestimmten Punkt 3,1 beträgt, können Sie das einerseits so interpretieren, dass Sie Folgendes sagen: Wenn Sie an dieser Eingabe stehen und sich entlang dieser Richtung bewegen, erhöht sich die Funktion am schnellsten. Wenn Sie die Funktion über der Ebene der Eingabepunkte grafisch darstellen, gibt Ihnen dieser Vektor die gerade Aufwärtsrichtung an.",
  "n_reviews": 0,
  "start": 697.1,
  "end": 722.26
 },
 {
  "input": "But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck.",
  "translatedText": "Aber man kann das auch so interpretieren, dass Änderungen an dieser ersten Variablen dreimal so wichtig sind wie Änderungen an der zweiten Variablen, sodass zumindest in der Nähe der relevanten Eingabe das Verändern des x-Werts viel mehr Vorteile für Sie bringt Bock.",
  "n_reviews": 0,
  "start": 722.86,
  "end": 736.9
 },
 {
  "input": "Let's zoom out and sum up where we are so far.",
  "translatedText": "Lassen Sie uns herauszoomen und zusammenfassen, wo wir bisher stehen.",
  "n_reviews": 0,
  "start": 739.88,
  "end": 742.34
 },
 {
  "input": "The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums.",
  "translatedText": "Das Netzwerk selbst ist diese Funktion mit 784 Eingängen und 10 Ausgängen, definiert durch alle diese gewichteten Summen.",
  "n_reviews": 0,
  "start": 742.84,
  "end": 750.04
 },
 {
  "input": "The cost function is a layer of complexity on top of that.",
  "translatedText": "Darüber hinaus ist die Kostenfunktion eine Ebene der Komplexität.",
  "n_reviews": 0,
  "start": 750.64,
  "end": 753.68
 },
 {
  "input": "It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples.",
  "translatedText": "Es nimmt die 13.000 Gewichte und Verzerrungen als Eingaben und spuckt basierend auf den Trainingsbeispielen ein einzelnes Maß für die Missstände aus.",
  "n_reviews": 0,
  "start": 753.98,
  "end": 761.72
 },
 {
  "input": "And the gradient of the cost function is one more layer of complexity still.",
  "translatedText": "Und der Gradient der Kostenfunktion ist noch eine weitere Ebene der Komplexität.",
  "n_reviews": 0,
  "start": 762.44,
  "end": 766.9
 },
 {
  "input": "It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most.",
  "translatedText": "Es sagt uns, welche Anstöße bei all diesen Gewichtungen und Verzerrungen die schnellste Änderung des Werts der Kostenfunktion bewirken, was man so interpretieren könnte, dass man sagt, welche Änderungen an welchen Gewichten am wichtigsten sind.",
  "n_reviews": 0,
  "start": 767.36,
  "end": 777.88
 },
 {
  "input": "So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before?",
  "translatedText": "Wenn Sie also das Netzwerk mit zufälligen Gewichtungen und Verzerrungen initialisieren und diese basierend auf diesem Gradientenabstiegsprozess viele Male anpassen, wie gut funktioniert es dann tatsächlich bei Bildern, die es noch nie zuvor gesehen hat?",
  "n_reviews": 0,
  "start": 782.56,
  "end": 793.2
 },
 {
  "input": "The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly.",
  "translatedText": "Das hier beschriebene Bild mit den zwei verborgenen Schichten von jeweils 16 Neuronen, die hauptsächlich aus ästhetischen Gründen ausgewählt wurden, ist nicht schlecht und klassifiziert etwa 96 % der neuen Bilder, die es sieht, korrekt.",
  "n_reviews": 0,
  "start": 794.1,
  "end": 805.96
 },
 {
  "input": "And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack.",
  "translatedText": "Und ehrlich gesagt, wenn man sich einige der Beispiele anschaut, die es vermasselt, fühlt man sich gezwungen, es etwas lockerer angehen zu lassen.",
  "n_reviews": 0,
  "start": 806.68,
  "end": 812.54
 },
 {
  "input": "Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%.",
  "translatedText": "Wenn Sie nun mit der Struktur der verborgenen Ebenen herumspielen und ein paar Änderungen vornehmen, können Sie diese bis zu 98 % erreichen.",
  "n_reviews": 0,
  "start": 816.22,
  "end": 821.76
 },
 {
  "input": "And that's pretty good!",
  "translatedText": "Und das ist ziemlich gut!",
  "n_reviews": 0,
  "start": 821.76,
  "end": 822.72
 },
 {
  "input": "It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for.",
  "translatedText": "Es ist nicht das Beste, Sie können sicherlich eine bessere Leistung erzielen, wenn Sie ausgefeilter als dieses einfache Netzwerk werden, aber wenn man bedenkt, wie entmutigend die anfängliche Aufgabe ist, denke ich, dass es etwas Unglaubliches an sich hat, wenn ein Netzwerk bei Bildern, die es noch nie zuvor gesehen hat, so gut funktioniert Wir haben ihm nie ausdrücklich gesagt, nach welchen Mustern er suchen soll.",
  "n_reviews": 0,
  "start": 823.02,
  "end": 841.42
 },
 {
  "input": "Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits.",
  "translatedText": "Ursprünglich habe ich diese Struktur dadurch motiviert, dass ich die Hoffnung beschrieb, die wir haben könnten, dass die zweite Schicht kleine Kanten aufgreifen könnte, dass die dritte Schicht diese Kanten zusammenfügen würde, um Schleifen und längere Linien zu erkennen, und dass diese zusammengesetzt werden könnten zusammen, um Ziffern zu erkennen.",
  "n_reviews": 0,
  "start": 842.56,
  "end": 857.18
 },
 {
  "input": "So is this what our network is actually doing?",
  "translatedText": "Ist es also genau das, was unser Netzwerk tut?",
  "n_reviews": 0,
  "start": 857.96,
  "end": 860.4
 },
 {
  "input": "Well, for this one at least, not at all.",
  "translatedText": "Zumindest für dieses hier überhaupt nicht.",
  "n_reviews": 0,
  "start": 861.08,
  "end": 864.4
 },
 {
  "input": "Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on?",
  "translatedText": "Erinnern Sie sich daran, wie wir uns im letzten Video angeschaut haben, wie die Gewichtungen der Verbindungen von allen Neuronen in der ersten Schicht zu einem bestimmten Neuron in der zweiten Schicht als gegebenes Pixelmuster visualisiert werden können, das das Neuron der zweiten Schicht aufnimmt?",
  "n_reviews": 0,
  "start": 864.82,
  "end": 877.06
 },
 {
  "input": "Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there.",
  "translatedText": "Nun, wenn wir das tatsächlich für die Gewichtungen machen, die mit diesen Übergängen von der ersten Schicht zur nächsten verbunden sind, sehen sie, anstatt hier und da isolierte kleine Kanten aufzugreifen, fast zufällig aus, nur mit einigen sehr lockeren Mustern darin die Mitte dort.",
  "n_reviews": 0,
  "start": 877.78,
  "end": 893.68
 },
 {
  "input": "It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for.",
  "translatedText": "Es scheint, dass unser Netzwerk in dem unvorstellbar großen 13.000-dimensionalen Raum möglicher Gewichtungen und Verzerrungen ein glückliches kleines lokales Minimum gefunden hat, das trotz der erfolgreichen Klassifizierung der meisten Bilder nicht genau die Muster aufgreift, die wir uns erhofft hatten.",
  "n_reviews": 0,
  "start": 893.76,
  "end": 908.96
 },
 {
  "input": "And to really drive this point home, watch what happens when you input a random image.",
  "translatedText": "Und um diesen Punkt wirklich zu verdeutlichen, beobachten Sie, was passiert, wenn Sie ein zufälliges Bild eingeben.",
  "n_reviews": 0,
  "start": 909.78,
  "end": 913.82
 },
 {
  "input": "If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5.",
  "translatedText": "Wenn das System intelligent wäre, könnte man erwarten, dass es sich unsicher anfühlt und möglicherweise keines dieser 10 Ausgabeneuronen wirklich aktiviert oder sie alle gleichmäßig aktiviert, sondern dass es Ihnen stattdessen souverän eine unsinnige Antwort gibt, als ob es sich genauso sicher anfühlt wie dieses zufällige Geräusch ist eine 5, da ein tatsächliches Bild einer 5 eine 5 ist.",
  "n_reviews": 0,
  "start": 914.32,
  "end": 934.16
 },
 {
  "input": "Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them.",
  "translatedText": "Anders ausgedrückt: Auch wenn dieses Netzwerk Ziffern ziemlich gut erkennen kann, hat es keine Ahnung, wie man sie zeichnet.",
  "n_reviews": 0,
  "start": 934.54,
  "end": 940.7
 },
 {
  "input": "A lot of this is because it's such a tightly constrained training setup.",
  "translatedText": "Das liegt zum großen Teil daran, dass es sich um einen so eng begrenzten Trainingsaufbau handelt.",
  "n_reviews": 0,
  "start": 941.42,
  "end": 945.24
 },
 {
  "input": "I mean, put yourself in the network's shoes here.",
  "translatedText": "Ich meine, versetzen Sie sich hier in die Lage des Netzwerks.",
  "n_reviews": 0,
  "start": 945.88,
  "end": 947.74
 },
 {
  "input": "From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions.",
  "translatedText": "Aus seiner Sicht besteht das gesamte Universum nur aus klar definierten, unbeweglichen Ziffern, die in einem winzigen Raster zentriert sind, und seine Kostenfunktion gab ihm nie einen Anreiz, bei seinen Entscheidungen etwas anderes als völliges Vertrauen zu haben.",
  "n_reviews": 0,
  "start": 948.14,
  "end": 961.08
 },
 {
  "input": "So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns.",
  "translatedText": "Da dies also ein Bild davon ist, was diese Neuronen der zweiten Schicht wirklich tun, fragen Sie sich vielleicht, warum ich dieses Netzwerk mit der Motivation einführe, Kanten und Muster aufzugreifen.",
  "n_reviews": 0,
  "start": 962.12,
  "end": 969.92
 },
 {
  "input": "I mean, that's just not at all what it ends up doing.",
  "translatedText": "Ich meine, das ist einfach überhaupt nicht das, was es letztendlich tut.",
  "n_reviews": 0,
  "start": 969.92,
  "end": 972.3
 },
 {
  "input": "Well, this is not meant to be our end goal, but instead a starting point.",
  "translatedText": "Nun, dies soll nicht unser Endziel sein, sondern vielmehr ein Ausgangspunkt.",
  "n_reviews": 0,
  "start": 973.38,
  "end": 977.18
 },
 {
  "input": "Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems.",
  "translatedText": "Ehrlich gesagt handelt es sich hierbei um eine alte Technologie, wie sie in den 80er und 90er Jahren erforscht wurde, und man muss sie verstehen, bevor man detailliertere moderne Varianten verstehen kann, und sie ist eindeutig in der Lage, einige interessante Probleme zu lösen, aber je mehr man sich mit dem beschäftigt, was Je mehr diese verborgenen Schichten wirklich funktionieren, desto weniger intelligent erscheint es.",
  "n_reviews": 0,
  "start": 977.64,
  "end": 994.74
 },
 {
  "input": "Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow.",
  "translatedText": "Wenn Sie den Fokus für einen Moment von der Art und Weise, wie Netzwerke lernen, auf die Art und Weise verlagern, wie Sie lernen, gelingt das nur, wenn Sie sich irgendwie aktiv mit dem Material hier auseinandersetzen.",
  "n_reviews": 0,
  "start": 998.48,
  "end": 1006.3
 },
 {
  "input": "One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns.",
  "translatedText": "Ich möchte, dass Sie ganz einfach jetzt innehalten und einen Moment tief darüber nachdenken, welche Änderungen Sie an diesem System vornehmen könnten und wie es Bilder wahrnimmt, wenn Sie möchten, dass es Dinge wie Kanten und Muster besser erkennt.",
  "n_reviews": 0,
  "start": 1007.06,
  "end": 1020.88
 },
 {
  "input": "But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks.",
  "translatedText": "Aber noch besser: Um sich tatsächlich mit dem Material auseinanderzusetzen, empfehle ich wärmstens das Buch von Michael Nielsen über Deep Learning und neuronale Netze.",
  "n_reviews": 0,
  "start": 1021.48,
  "end": 1029.1
 },
 {
  "input": "In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing.",
  "translatedText": "Darin finden Sie den Code und die Daten zum Herunterladen und Spielen für genau dieses Beispiel, und das Buch führt Sie Schritt für Schritt durch die Funktionsweise dieses Codes.",
  "n_reviews": 0,
  "start": 1029.68,
  "end": 1038.36
 },
 {
  "input": "What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts.",
  "translatedText": "Das Tolle daran ist, dass dieses Buch kostenlos und öffentlich verfügbar ist. Wenn Sie also etwas davon haben, denken Sie darüber nach, gemeinsam mit mir eine Spende für Nielsens Bemühungen zu leisten.",
  "n_reviews": 0,
  "start": 1039.3,
  "end": 1047.66
 },
 {
  "input": "I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill.",
  "translatedText": "Ich habe in der Beschreibung auch ein paar andere Ressourcen verlinkt, die mir sehr gefallen, darunter den phänomenalen und schönen Blogbeitrag von Chris Ola und die Artikel in Distill.",
  "n_reviews": 0,
  "start": 1047.66,
  "end": 1056.5
 },
 {
  "input": "To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee.",
  "translatedText": "Um die letzten paar Minuten abzuschließen, möchte ich noch einmal auf einen Ausschnitt aus dem Interview zurückkommen, das ich mit Leisha Lee geführt habe.",
  "n_reviews": 0,
  "start": 1058.28,
  "end": 1063.88
 },
 {
  "input": "You might remember her from the last video, she did her PhD work in deep learning.",
  "translatedText": "Vielleicht erinnern Sie sich an sie aus dem letzten Video, sie hat ihre Doktorarbeit im Bereich Deep Learning gemacht.",
  "n_reviews": 0,
  "start": 1064.3,
  "end": 1067.72
 },
 {
  "input": "In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning.",
  "translatedText": "In diesem kleinen Ausschnitt spricht sie über zwei aktuelle Arbeiten, die sich intensiv damit befassen, wie einige der moderneren Bilderkennungsnetzwerke tatsächlich lernen.",
  "n_reviews": 0,
  "start": 1068.3,
  "end": 1075.78
 },
 {
  "input": "Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training.",
  "translatedText": "Nur um zu verdeutlichen, wo wir uns in der Konversation befinden: In der ersten Arbeit wurde eines dieser besonders tiefen neuronalen Netzwerke verwendet, das wirklich gut in der Bilderkennung ist, und statt es anhand eines richtig beschrifteten Datensatzes zu trainieren, wurden alle Beschriftungen vor dem Training durcheinander gebracht.",
  "n_reviews": 0,
  "start": 1076.12,
  "end": 1088.74
 },
 {
  "input": "Obviously the testing accuracy here was no better than random, since everything is just randomly labeled, but it was still able to achieve the same training accuracy as you would on a properly labeled dataset.",
  "translatedText": "Offensichtlich war die Testgenauigkeit hier nicht besser als zufällig, da alles nur zufällig beschriftet ist, aber es konnte immer noch die gleiche Trainingsgenauigkeit erreicht werden, die Sie mit einem ordnungsgemäß beschrifteten Datensatz erreichen würden.",
  "n_reviews": 0,
  "start": 1089.48,
  "end": 1100.88
 },
 {
  "input": "Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization?",
  "translatedText": "Im Grunde reichten die Millionen von Gewichten für dieses spezielle Netzwerk aus, um sich lediglich die Zufallsdaten zu merken, was die Frage aufwirft, ob die Minimierung dieser Kostenfunktion tatsächlich irgendeiner Struktur im Bild entspricht oder nur eine Speicherung ist.",
  "n_reviews": 0,
  "start": 1101.6,
  "end": 1116.4
 },
 {
  "input": "If you look at that accuracy curve, if you were just training on a random dataset, that curve sort of went down very slowly in almost kind of a linear fashion, so you're really struggling to find that local minima of possible, you know, the right weights that would get you that accuracy.",
  "translatedText": "Wenn Sie sich diese Genauigkeitskurve ansehen und nur mit einem zufälligen Datensatz trainieren, sinkt diese Kurve sehr langsam und fast linear ab, sodass Sie wirklich Schwierigkeiten haben, die lokalen Minima des Möglichen zu finden , die richtigen Gewichte, mit denen Sie diese Genauigkeit erreichen.",
  "n_reviews": 0,
  "start": 1131.44,
  "end": 1152.14
 },
 {
  "input": "Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima.",
  "translatedText": "Wenn Sie dagegen tatsächlich mit einem strukturierten Datensatz trainieren, der die richtigen Beschriftungen hat, müssen Sie am Anfang ein wenig herumfummeln, aber dann sind Sie ziemlich schnell zurückgefallen, um dieses Genauigkeitsniveau zu erreichen, und so ist es in gewissem Sinne auch so war es einfacher, diese lokalen Maxima zu finden.",
  "n_reviews": 0,
  "start": 1152.24,
  "end": 1168.22
 },
 {
  "input": "And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily.",
  "translatedText": "Und was daran auch interessant war, ist, dass es ein weiteres Papier von vor ein paar Jahren ans Licht bringt, das viel mehr Vereinfachungen zu den Netzwerkschichten enthält, aber eines der Ergebnisse war, dass man, wenn man sich die Optimierungslandschaft anschaut, Die lokalen Minima, die diese Netzwerke normalerweise lernen, sind tatsächlich von gleicher Qualität. Wenn Ihr Datensatz also strukturiert ist, sollten Sie dies in gewisser Weise viel einfacher finden können.",
  "n_reviews": 0,
  "start": 1168.54,
  "end": 1194.32
 },
 {
  "input": "My thanks, as always, to those of you supporting on Patreon.",
  "translatedText": "Mein Dank gilt wie immer allen, die Patreon unterstützen.",
  "n_reviews": 0,
  "start": 1198.16,
  "end": 1201.18
 },
 {
  "input": "I've said before just what a game changer Patreon is, but these videos really would not be possible without you.",
  "translatedText": "Ich habe bereits gesagt, was für ein Game-Changer Patreon ist, aber diese Videos wären ohne Sie wirklich nicht möglich.",
  "n_reviews": 0,
  "start": 1201.52,
  "end": 1206.8
 },
 {
  "input": "I also want to give a special thanks to the VC firm Amplify Partners, in their support of these initial videos in the series.",
  "translatedText": "Ich möchte mich auch besonders bei der VC-Firma Amplify Partners für die Unterstützung dieser ersten Videos der Serie bedanken.",
  "n_reviews": 0,
  "start": 1207.46,
  "end": 1212.78
 }
]