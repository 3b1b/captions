[
 {
  "input": "Last video I laid out the structure of a neural network.",
  "translatedText": "A legutóbbi videóban bemutattam a neurális hálózat felépítését.",
  "model": "DeepL",
  "from_community_srt": "Utolsó videó Megmutattam egy neurális hálózat szerkezetét Gyorsan beszámolok itt,",
  "n_reviews": 1,
  "start": 4.18,
  "end": 7.28
 },
 {
  "input": "I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video.",
  "translatedText": "Egy gyors összefoglalóval indítok, hogy felfrissítsem az emlékeiteket. Ezután két fő célom van a videóval.",
  "model": "DeepL",
  "from_community_srt": "csak azért, hogy friss legyen a fejünkben És akkor két fő célom van erre a videóra.",
  "n_reviews": 1,
  "start": 7.68,
  "end": 12.6
 },
 {
  "input": "The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well.",
  "translatedText": "Az első a gradiens ereszkedés fogalmának bemutatása, amely nemcsak a neurális hálózatok tanulásának, hanem sok más gépi tanulásnak is az alapja.",
  "model": "DeepL",
  "from_community_srt": "Az első az, hogy bemutassuk a gradiens süllyedés eszméjét, amely nem csak az neurális hálózatok megtanulása,",
  "n_reviews": 1,
  "start": 13.1,
  "end": 20.6
 },
 {
  "input": "Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for.",
  "translatedText": "Ezután egy kicsit mélyebben beleássuk magunkat abba, hogyan működik ez a bizonyos hálózat, és mi a rejtett neuronrétegek pontos célja.",
  "model": "DeepL",
  "from_community_srt": "de hogyan működik sok más gépi tanulás is Ezután aztán egy kicsit többet is meg fogunk ásni, hogy hogyan működik ez a hálózat És mi rejlik azok a rejtett rétegek a neuronok,",
  "n_reviews": 1,
  "start": 21.12,
  "end": 27.94
 },
 {
  "input": "As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks.",
  "translatedText": "Emlékeztetőül, a célunk itt a neurális hálózatok klasszikus példájának megvalósítása, a kézzel írt számjegyek felismerése.",
  "model": "DeepL",
  "from_community_srt": "amelyek ténylegesen keresnek Emlékeztetőül a célunk a klasszikus példa a kézírásos számjegyek felismerésére",
  "n_reviews": 1,
  "start": 28.98,
  "end": 36.22
 },
 {
  "input": "These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1.",
  "translatedText": "Ezeket a számjegyeket egy 28x28 pixeles rácsba rendezzük, minden egyes pixelhez 0 és 1 közötti szürkeárnyalatos értéket rendelve.",
  "model": "DeepL",
  "from_community_srt": "a neurális hálózatok hello világa ezek a számok 28 és 28 képpontos rácson jelenik meg minden pixelben,",
  "n_reviews": 1,
  "start": 37.02,
  "end": 43.42
 },
 {
  "input": "Those are what determine the activations of 784 neurons in the input layer of the network.",
  "translatedText": "Ezek határozzák meg a hálózat bemeneti rétegében lévő 784 neuron aktivációját.",
  "model": "DeepL",
  "from_community_srt": "néhány szürkeárnyalatos érték között 0 és 1 között ezek határozzák meg a 784 neuron a hálózat bemeneti rétegében és",
  "n_reviews": 1,
  "start": 43.82,
  "end": 50.04
 },
 {
  "input": "And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias.",
  "translatedText": "Ezután a következő rétegekben az egyes neuronok aktivációja az előző réteg összes aktivációjának súlyozott összegén alapul, plusz egy speciális számon, az úgynevezett eltolósúlyon.",
  "model": "DeepL",
  "from_community_srt": "Ezután az egyes neuronok aktiválása az alábbi rétegekben súlyozott összeg alapján történik Az előző réteg összes aktiválása és egy speciális szám,",
  "n_reviews": 1,
  "start": 51.18,
  "end": 60.82
 },
 {
  "input": "Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video.",
  "translatedText": "Utána ezt az összeget képzed valamilyen más függvénnyel, például a szigmoid tömörítéssel vagy ReLu-val, ahogy a múltkori videóban bemutattam.",
  "model": "DeepL",
  "from_community_srt": "amelyet előítéletnek neveznek akkor ezt az összeget más funkcióval írja, mint például a sigmoid squishification vagy egy ReLu-t, ahogyan átmentem az utolsó videón Összességében,",
  "n_reviews": 1,
  "start": 62.16,
  "end": 68.94
 },
 {
  "input": "In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does.",
  "translatedText": "A kissé önkényesen választott egyenként 16 neuronnal rendelkező két rejtett rétegből álló hálózatnak összesen körülbelül 13000 súlya és eltolósúlya van, amelyeket be tudunk állítani, és ezek az értékek határozzák meg, hogy pontosan mit is csinál a hálózat.",
  "model": "DeepL",
  "from_community_srt": "mivel két rejtett réteg kissé önkényes választása van, itt 16 neuron van, mindegyikük kb 13.000 súly és előítélet, amit beállíthatunk, és ezek az értékek határozzák meg, hogy pontosan mi a tényleges hálózata Akkor mit értünk,",
  "n_reviews": 1,
  "start": 69.48,
  "end": 84.38
 },
 {
  "input": "Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit.",
  "translatedText": "Amikor azt mondjuk, hogy ez a hálózat egy adott számjegyet beazonosít, ez alatt az utolsó rétegben lévő 10 neuron közül a legfényesebbhez tartozó számot értjük.",
  "model": "DeepL",
  "from_community_srt": "amikor azt mondjuk, hogy ez a hálózat egy adott számjegyet sorol fel Ez a legfrissebb a 10 neuron közül a végső rétegnek felel meg",
  "n_reviews": 1,
  "start": 84.88,
  "end": 93.3
 },
 {
  "input": "And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits.",
  "translatedText": "És ne feledjük, hogy a réteges struktúra motivációja az volt, hogy talán a második réteg megtalálja az éleket, a harmadik réteg pedig a mintákat, például a hurkokat és a vonalakat, az utolsó pedig össze tudja rakni ezeket a mintákat, hogy felismerje a számjegyeket.",
  "model": "DeepL",
  "from_community_srt": "És ne feledje, hogy a motiváció, amelyet a réteges struktúrára gondolunk, talán ez volt A második réteg felveheti az éleket, és a harmadik réteg felveheti a mintákat, mint hurkot és vonalat És az utolsó csak összegyűjti ezeket a mintákat,",
  "n_reviews": 1,
  "start": 94.1,
  "end": 108.8
 },
 {
  "input": "So here, we learn how the network learns.",
  "translatedText": "Most viszont megtudjuk, hogyan tanul a hálózat.",
  "model": "DeepL",
  "from_community_srt": "hogy felismerje a számjegyeket Tehát itt megtanuljuk, hogyan tanul a hálózat Amit csak akarunk,",
  "n_reviews": 1,
  "start": 109.8,
  "end": 112.24
 },
 {
  "input": "What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data.",
  "translatedText": "Mi egy olyan algoritmust szeretnénk, ahol megmutathatunk ennek a hálózatnak egy csomó minta adatot, amely kézzel írt számjegyek különböző képeinek formájában érkezik felcímkézve a rajtuk lévő számjegyekkel együtt, és a hálózat beállítja ezt a 13000 súlyt, hogy javítsa a minta adatokon elért eredményét.",
  "model": "DeepL",
  "from_community_srt": "egy algoritmus, ahol ez a hálózat egy csomó képzési adatot jeleníthet meg amely egy kézzel írott számjegyből álló különböző képparkok formájában jelenik meg, valamint címkékkel, amelyekről azt állítják, Ez beállítja azokat 13000 súlyt és előítéletet, hogy javítsa teljesítményét a képzési adatokon Remélhetőleg ez a réteges szerkezet azt jelenti,",
  "n_reviews": 1,
  "start": 112.64,
  "end": 130.12
 },
 {
  "input": "Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data.",
  "translatedText": "Remélhetőleg ez a réteges struktúra képes arra, hogy a tanultakat a képzési adatokon kívüli képekre is alkalmazza.",
  "model": "DeepL",
  "from_community_srt": "hogy mit tanul a képzési adatokon túlmutató képekre általánosítható És ahogy teszteljük,",
  "n_reviews": 1,
  "start": 130.72,
  "end": 136.86
 },
 {
  "input": "The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images.",
  "translatedText": "Ezt úgy teszteljük, hogy miután betanítottuk a hálózatot, több olyan felcímkézett képet mutatunk neki, amelyet még soha nem látott, és megnézzük, milyen pontosan azonosítja ezeket.",
  "model": "DeepL",
  "from_community_srt": "az az, hogy a hálózat felkészítése után Megmutatja, hogy a theta többet jelölt, hogy soha nem látott korábban, és látod,",
  "n_reviews": 1,
  "start": 137.64,
  "end": 146.7
 },
 {
  "input": "Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be.",
  "translatedText": "Szerencsénkre az MNIST adatbázist létrehozó kedves emberek összeállították ezt a több tízezer kézzel írt számjegyes képet tartalmazó gyűjteményt, amelyek mindegyike fel van címkézve a rajtuk látható számokkal. Emiatt ilyen gyakori ez példa.",
  "model": "DeepL",
  "from_community_srt": "hogy pontosan osztályozza ezeket az új képeket Szerencsére számunkra, és mi teszi ezt a közös példát az, hogy a MNIST bázis mögött álló jó emberek vannak összeállítottak egy gyűjteményt több tízezer kézzel írott digitális képen, mindegyiküket a számokkal jelölték, amiket feltételeznek.",
  "n_reviews": 1,
  "start": 151.12,
  "end": 164.2
 },
 {
  "input": "And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise.",
  "translatedText": "És bármennyire is provokatív azt állítani egy gépről, hogy tanul, ha egyszer látod hogyan működik, sokkal kevésbé tűnik valami őrült sci-fi regénynek, és sokkal inkább egy számítási gyakorlatnak.",
  "model": "DeepL",
  "from_community_srt": "Ez provokatív, mivel leírni egy gépet, mint tanulást, ha tényleg látja, hogyan működik Sokkal kevésbé érzi magát, mint egy őrült sci-fi helyszín, és sokkal jobban hasonlít egy kalkulus gyakorlatra Úgy értem,",
  "n_reviews": 1,
  "start": 164.9,
  "end": 175.48
 },
 {
  "input": "I mean, basically it comes down to finding the minimum of a certain function.",
  "translatedText": "Úgy értem, alapvetően egy bizonyos függvény minimumát kell megtalálni.",
  "model": "DeepL",
  "from_community_srt": "alapvetően lefelé fordul,",
  "n_reviews": 1,
  "start": 176.2,
  "end": 179.96
 },
 {
  "input": "Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
  "translatedText": "Ne feledjük, hogy koncepcionálisan úgy gondolunk minden neuronra, mint ami az előző réteg összes neuronjához kapcsolódik, és az aktivitást meghatározó súlyozott összeg súlyai a kapcsolatok egyfajta erősségét jelentik. A eltolósúly pedig azt jelzi, hogy az adott neuron inkább aktív vagy inaktív.",
  "model": "DeepL",
  "from_community_srt": "hogy megtalálja a minimálisan egy bizonyos funkciót Ne feledkezzünk meg arról, hogy mindegyik neuront összekapcsoljuk az előző réteg összes neuronja számára, és a súlyozott összegben az aktiválást meghatározó súlyok olyanok, mint a erősségeit És az elfogultság azt jelzi, hogy az adott neuron aktív vagy inaktív-e,",
  "n_reviews": 1,
  "start": 181.94,
  "end": 198.96
 },
 {
  "input": "And to start things off, we're just going to initialize all of those weights and biases totally randomly.",
  "translatedText": "És hogy a dolgokat elkezdjük, inicializáljuk az összes súlyt teljesen véletlenszerűen.",
  "model": "DeepL",
  "from_community_srt": "és elkezdi-e a dolgokat Csak inicializáljuk az összes súlyt, és teljesen véletlenszerűen szükségtelen,",
  "n_reviews": 1,
  "start": 199.72,
  "end": 204.4
 },
 {
  "input": "Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random.",
  "translatedText": "Mondanom sem kell, hogy ez a hálózat elég szörnyen fog teljesíteni egy példán, mivel csak valami véletlenszerűt csinál.",
  "model": "DeepL",
  "from_community_srt": "hogy ezt a hálózatot fogjuk végrehajtani meglehetősen rettenetesen egy adott képzési példánál,",
  "n_reviews": 1,
  "start": 204.94,
  "end": 210.72
 },
 {
  "input": "For example, you feed in this image of a 3, and the output layer just looks like a mess.",
  "translatedText": "Például betáplálod ezt a 3-as képet, a kimeneti rétegen meg teljes össze-visszaság látható.",
  "model": "DeepL",
  "from_community_srt": "mert csak csinál valami véletlenszerűen, például betölti ezt a képet a 3-as és a Kimeneti réteg csak úgy néz ki, mint egy rendetlenség Tehát,",
  "n_reviews": 1,
  "start": 211.04,
  "end": 216.02
 },
 {
  "input": "So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash.",
  "translatedText": "Tehát, azt teszed, hogy definiálsz egy költségfüggvényt, egy módot arra, hogy megmondd a számítógépnek: Nem! Rossz számítógép! A kimenetnek olyan aktivációkkal kell rendelkeznie, amelyek a legtöbb neuron esetében 0, de ennél a neuronnál 1, amit adtál nekem, az teljes szemét.",
  "model": "DeepL",
  "from_community_srt": "amit csinálsz, a költségfüggvényt úgy definiálod, hogy megmondja a számítógépet: \"Nincs rossz számítógép! A kimenetnek aktivitásokkal kell rendelkeznie, amelyek nulla a legtöbb neurontól, de egy ilyen neuron, amit adtál neked,",
  "n_reviews": 1,
  "start": 216.6,
  "end": 230.76
 },
 {
  "input": "To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example.",
  "translatedText": "Kicsit matekosabban kifejezve, összeadjuk az egyes szemét kimeneti aktivációk és a kívánt érték közötti különbségek négyzetét, és ezt nevezzük az adott tréningpélda költségének.",
  "model": "DeepL",
  "from_community_srt": "teljes kuka \" Azt mondani, hogy egy kicsit matematikailag, amit csinálsz, feloldod a különbségek négyzetét mindegyik trágyakimenet aktiválását és azt az értéket, amelyet szeretnél, és Ezt hívjuk egy képzési példa költségének Figyeljük meg,",
  "n_reviews": 1,
  "start": 231.72,
  "end": 245.02
 },
 {
  "input": "Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing.",
  "translatedText": "Vegyük észre, hogy ez az összeg kicsi, amikor a hálózat magabiztosan helyesen osztályozza a képet, de nagy, amikor a hálózat úgy tűnik, hogy nem tudja, mit csinál.",
  "model": "DeepL",
  "from_community_srt": "hogy ez az összeg kicsi, ha a hálózat magabiztosan osztályozza a képet helyesen De nagy, amikor a hálózat úgy tűnik, hogy nem igazán tudja,",
  "n_reviews": 1,
  "start": 245.96,
  "end": 256.4
 },
 {
  "input": "So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal.",
  "translatedText": "Így aztán azt kell tenned, hogy a rendelkezésére álló több tízezer képzési példa átlagköltségét veszed figyelembe.",
  "model": "DeepL",
  "from_community_srt": "mit csinál Így aztán mindent megtesz az átlagos költséget az Ön rendelkezésére álló több tízezer képzési példán",
  "n_reviews": 1,
  "start": 258.64,
  "end": 265.44
 },
 {
  "input": "This average cost is our measure for how lousy the network is, and how bad the computer should feel.",
  "translatedText": "Ez az átlagköltség a mi mérőszámunk arra, hogy mennyire pocsék a hálózat, és mennyire kell rosszul éreznie magát a gépnek.",
  "model": "DeepL",
  "from_community_srt": "Ez az átlagos költség az intézkedésünk, hogy milyen rossz a hálózat, és milyen rossz a számítógép érzi,",
  "n_reviews": 1,
  "start": 267.04,
  "end": 272.74
 },
 {
  "input": "And that's a complicated thing.",
  "translatedText": "És ez egy bonyolult dolog.",
  "model": "DeepL",
  "from_community_srt": "és ez bonyolult dolog Ne feledje,",
  "n_reviews": 1,
  "start": 273.42,
  "end": 274.6
 },
 {
  "input": "Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases?",
  "translatedText": "Emlékszel, hogy maga a hálózat alapvetően egy függvény volt, amely bemenetként 784 számot vesz fel, a pixelértékeket, és kimenetként 10 számot ad ki, és bizonyos értelemben a súlyok és eltolósúlyok által van paraméterezve?",
  "model": "DeepL",
  "from_community_srt": "hogy maga a hálózat alapvetően egy függvény, amelyik befogadja A 784-es szám bemeneti értékként adja meg a pixel értékét, és tíz számot tár fel kimenetként és bizonyos értelemben Mindezeket a súlyokat és előítéleteket paraméterezi",
  "n_reviews": 1,
  "start": 275.04,
  "end": 288.8
 },
 {
  "input": "Well the cost function is a layer of complexity on top of that.",
  "translatedText": "Nos, a költségfüggvény egy újabb szinttel növeli a komplexitást.",
  "model": "DeepL",
  "from_community_srt": "Míg a költségfüggvény egy komplexitási réteg,",
  "n_reviews": 1,
  "start": 289.5,
  "end": 292.82
 },
 {
  "input": "It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data.",
  "translatedText": "A rendszer bemenetként veszi ezt a körülbelül 13000 súlyt, és egyetlen számot ad ki, amely leírja, hogy mennyire rosszak ezek a súlyok. Ennek értéke mindig változik a hálózat viselkedésétől függően a több tízezernyi képzési adat során.",
  "model": "DeepL",
  "from_community_srt": "amely túllépi a bevitelt ezek a tizenháromezer nagyságú súlyok és előítéletek, és egyetlen számot tár fel, amely leírja, milyen rosszak ezek a súlyok és előítéletek és A meghatározás módja attól függ,",
  "n_reviews": 1,
  "start": 293.1,
  "end": 308.9
 },
 {
  "input": "That's a lot to think about.",
  "translatedText": "Ez sok minden, amit fejben kell tartani.",
  "model": "DeepL",
  "from_community_srt": "hogy a hálózat hogyan viselkedik a több tízezer képzési adat fölött Sokat kell gondolni De csak azt mondja a számítógépnek,",
  "n_reviews": 1,
  "start": 309.52,
  "end": 311
 },
 {
  "input": "But just telling the computer what a crappy job it's doing isn't very helpful.",
  "translatedText": "De csak annyit mondani a számítógépnek, hogy szar munkát végez, nem túl hasznos.",
  "model": "DeepL",
  "from_community_srt": "hogy egy csúnya feladat, amit csinál,",
  "n_reviews": 1,
  "start": 312.4,
  "end": 315.82
 },
 {
  "input": "You want to tell it how to change those weights and biases so that it gets better.",
  "translatedText": "Azt is meg akarod mondani neki, hogyan változtassa meg a súlyokat, hogy jobbá váljon.",
  "model": "DeepL",
  "from_community_srt": "nem nagyon segít Szeretné elmondani, hogyan kell ezeket a súlyokat és előítéleteket megváltoztatni,",
  "n_reviews": 1,
  "start": 316.22,
  "end": 320.06
 },
 {
  "input": "To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output.",
  "translatedText": "A könnyebbség kedvéért, ahelyett, hogy egy 13000 bemenettel rendelkező függvényt kellene elképzelnünk, képzeljünk el egy egyszerű függvényt, amelynek bemenete és kimenete is egy szám.",
  "model": "DeepL",
  "from_community_srt": "hogy jobb lesz? Annak érdekében, hogy egyszerűbbé tegye a 13 000 bemenettel rendelkező funkció helyett Képzeljünk csak el egy egyszerű funkciót, amelynek egy száma bemenetként és egy kimeneti számként van Hogyan találja meg azt a bemenetet,",
  "n_reviews": 1,
  "start": 320.78,
  "end": 330.48
 },
 {
  "input": "How do you find an input that minimizes the value of this function?",
  "translatedText": "Hogyan találjuk meg azt a bemenetet, amely minimalizálja ennek a függvénynek az értékét?",
  "model": "DeepL",
  "n_reviews": 1,
  "start": 331.48,
  "end": 335.3
 },
 {
  "input": "Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function.",
  "translatedText": "A kalkulust tanuló diákok tudják, hogy a minimumot néha explicit módon is ki lehet számolni, de ez nem mindig lehetséges bonyolult függvények esetén, pláne nem az őrülten bonyolult neurális hálózati költségfüggvényünk 13000 bemenetű változatában.",
  "model": "DeepL",
  "from_community_srt": "amely minimalizálja a funkció értékét? A kalkulus hallgatók tudni fogják, hogy néha kifejezetten kimutathatjátok ezt a minimumot De ez nem mindig megvalósítható az igazán bonyolult feladatokhoz Természetesen nem a tizenhárom ezer bemeneti változata ennek a helyzetnek a mi őrült bonyolult neurális hálózat költsége funkció",
  "n_reviews": 1,
  "start": 336.46,
  "end": 351.08
 },
 {
  "input": "A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower.",
  "translatedText": "Rugalmasabb taktika, ha bármilyen bemenetről indulva ki tudjuk találjuk, hogy melyik irányba kell lépnünk, hogy a kimenet alacsonyabb legyen.",
  "model": "DeepL",
  "from_community_srt": "A rugalmasabb taktika minden régi bemeneten elindul, és kitalálja, melyik irányba kell lépnie ahhoz,",
  "n_reviews": 1,
  "start": 351.58,
  "end": 359.2
 },
 {
  "input": "Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative.",
  "translatedText": "Pontosabban, ha ki tudod számolni a függvény meredekségét, akkor balra kell mozogni, ha a meredekség pozitív, és jobbra kell tolni a bemenetet, ha a meredekség negatív.",
  "model": "DeepL",
  "from_community_srt": "hogy a kimenet alacsonyabb legyen Pontosabban, ha kitalálhatja a funkció meredekségét Ezután tolja balra, ha ez a lejtés pozitív, és jobbra tolja a bemenetet,",
  "n_reviews": 1,
  "start": 360.08,
  "end": 369.9
 },
 {
  "input": "If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function.",
  "translatedText": "Ha ezt többször megismétled minden ponton ellenőrizve a meredekséget és megtéve a megfelelő lépést, akkor a függvény valamelyik helyi minimumához fogsz közelíteni.",
  "model": "DeepL",
  "from_community_srt": "ha a meredekség negatív Ha ezt többször is megismételjük minden ponton, ellenõrizzük az új lejtõt és megtesszük a megfelelõ lépést akkor hozzá fog járulni a helyi minimumhoz a funkcióhoz és",
  "n_reviews": 1,
  "start": 371.96,
  "end": 379.84
 },
 {
  "input": "The image you might have in mind here is a ball rolling down a hill.",
  "translatedText": "Ilyenkor gondolj egy dombon lefelé guruló labdára.",
  "model": "DeepL",
  "from_community_srt": "a kép, amelyre gondolhatsz itt, egy golyó,",
  "n_reviews": 1,
  "start": 380.64,
  "end": 383.8
 },
 {
  "input": "Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function.",
  "translatedText": "Vegyük észre, hogy még ennél a nagyon leegyszerűsített egyváltozós függvénynél is sok lehetséges völgyben landolhatunk, attól függően, hogy melyik véletlen helyről indulunk, és nincs garancia arra, hogy a lokális minimum, ahol landolunk, a költségfüggvény legkisebb lehetséges értéke lesz.",
  "model": "DeepL",
  "from_community_srt": "amely lefelé halad egy dombon A ténylegesen leegyszerűsített bemeneti funkciókért is észrevehető, hogy számos lehetséges völgy van, amelybe beléphet Attól függően, hogy melyik véletlenszerű bemenet kezdődik, és nincs garancia arra, hogy a helyi minimum Bejutsz a költségfunkció legkisebb lehetséges értéke Ez át fog terjedni a neurális hálózathoz is,",
  "n_reviews": 1,
  "start": 384.62,
  "end": 399.4
 },
 {
  "input": "That will carry over to our neural network case as well.",
  "translatedText": "Ez a neurális hálózatos esetünkre is igaz lesz.",
  "model": "DeepL",
  "n_reviews": 1,
  "start": 400.22,
  "end": 402.62
 },
 {
  "input": "And I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that kind of helps you from overshooting.",
  "translatedText": "Azt is szeretném, hogy észrevegyed, ha a lépések méretét a lejtővel arányossá teszed, akkor amikor a lejtő a minimum felé ellaposodik, a lépéseid egyre kisebbek lesznek, és ez segít a túllövés elkerülésében.",
  "model": "DeepL",
  "from_community_srt": "és azt is szeretném, ha észreveszed Hogyan csinálhatja lépcsőméreteit a lejtővel arányosnak? Akkor, amikor a lejtés a minimálisra süllyed, lépései kisebbek és kisebbek lesznek,",
  "n_reviews": 1,
  "start": 403.18,
  "end": 414.6
 },
 {
  "input": "Bumping up the complexity a bit, imagine instead a function with two inputs and one output.",
  "translatedText": "A bonyolultságot egy kicsit megnövelve, képzeljünk el egy függvényt két bemenettel és egy kimenettel.",
  "model": "DeepL",
  "from_community_srt": "és ez a fajta segít a túllövésnek A bonyolultság felhúzásával elképzelhető egy két bemenet és egy kimenet funkciója",
  "n_reviews": 1,
  "start": 415.94,
  "end": 420.98
 },
 {
  "input": "You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it.",
  "translatedText": "A bemeneti teret az xy-síknak, a költségfüggvényt pedig a felette lévő felületnek tekinthetjük.",
  "model": "DeepL",
  "from_community_srt": "Gondolhat arra, hogy a bemeneti tér XY sík és a költségfüggvény, mint a felett levő felület Ahelyett,",
  "n_reviews": 1,
  "start": 421.5,
  "end": 428.14
 },
 {
  "input": "Instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly.",
  "translatedText": "Most a függvény meredekségének vizsgálata helyett, azt kell megtalálnunk, hogy milyen irányba lépjünk ebben a bemeneti térben, hogy a függvény kimenete a leggyorsabban csökkenjen.",
  "model": "DeepL",
  "from_community_srt": "hogy megkérdeznéd a függvény meredekségét, meg kell kérdezned, melyik irányba kell lépnie ebben a bemeneti területen? Annak érdekében, hogy a funkció leggyorsabban csökkentse a kimenetét.",
  "n_reviews": 1,
  "start": 428.76,
  "end": 438.96
 },
 {
  "input": "In other words, what's the downhill direction?",
  "translatedText": "Más szóval, mi a lejtő iránya?",
  "model": "DeepL",
  "n_reviews": 1,
  "start": 439.72,
  "end": 441.76
 },
 {
  "input": "Again, it's helpful to think of a ball rolling down that hill.",
  "translatedText": "Ismét hasznos, ha egy golyóra gondolunk, amely legurul a dombon.",
  "model": "DeepL",
  "from_community_srt": "Mi a lejtő iránya? És újra hasznos lehet gondolni egy labdát, amely lecsúszik a dombon Azok,",
  "n_reviews": 1,
  "start": 442.38,
  "end": 445.56
 },
 {
  "input": "Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly.",
  "translatedText": "Akik ismerik a többváltozós függvényeket, azok tudják, hogy egy függvény gradiense megadja a legmeredekebb emelkedés irányát, vagyis azt, hogy melyik irányba kell lépni, hogy a kimenetet a leggyorsabban növeljük.",
  "model": "DeepL",
  "from_community_srt": "akik ismernek a többváltozós kalkulusokkal, tudni fogják, hogy egy függvény gradiense adja a legmeredekebb emelkedést Alapvetően,",
  "n_reviews": 1,
  "start": 446.66,
  "end": 458.78
 },
 {
  "input": "Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly.",
  "translatedText": "Természetesen, ha a gradiens negatívját vesszük, megkapjuk azt a lépésirányt, amely a leggyorsabban csökkenti a függvényt.",
  "model": "DeepL",
  "from_community_srt": "melyik irányba kell lépnie a funkció leggyorsabb növeléséhez Természetesen elegendő az adott gradiens negatívja, megadja azt a lépést, amely a leggyorsabban csökkenti a funkciót Még ennél is több,",
  "n_reviews": 1,
  "start": 459.56,
  "end": 466.04
 },
 {
  "input": "Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is.",
  "translatedText": "Sőt, a meredekségvektor hossza még azt is megmutatja, hogy mennyire meredek az a legmeredekebb lejtő.",
  "model": "DeepL",
  "from_community_srt": "hogy ennek a gradiensvektornak a hossza valójában jelzi, hogy milyen meredek, hogy a legmeredekebb lejtő Most,",
  "n_reviews": 1,
  "start": 467.24,
  "end": 473.84
 },
 {
  "input": "If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic.",
  "translatedText": "Ha nem ismered a többváltozós kalkulust, de többet szeretnél megtudni, nézd meg a Khan Academy-re készített videóimat.",
  "model": "DeepL",
  "from_community_srt": "ha nem ismeri a többváltozós kalkulust És szeretnél többet megtudni, nézd meg a munkámat, amit a Khan Akadémián tettem a témában Őszintén szólva,",
  "n_reviews": 1,
  "start": 474.54,
  "end": 480.34
 },
 {
  "input": "Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is.",
  "translatedText": "Őszintén szólva azonban most csak annyi számít nekünk, hogy létezik egy mód arra, hogy kiszámítsuk ezt a vektort. Azt a vektort, amely megmondja, hogy mi a lejtő iránya és milyen meredek.",
  "model": "DeepL",
  "from_community_srt": "bár minden ami számodra fontos neked és nekem Ez elvben létezik mód arra, hogy kiszámítsuk ezt a vektort. Ez a vektor, amely megmondja, hogy mi a A lejtő iránya és mennyire meredek,",
  "n_reviews": 1,
  "start": 480.86,
  "end": 491.9
 },
 {
  "input": "You'll be okay if that's all you know and you're not rock solid on the details.",
  "translatedText": "Nem gond, ha most csak ennyit tudsz, és nincs jártasságod a részletekben.",
  "model": "DeepL",
  "from_community_srt": "hogy rendben leszel, ha ez minden, amit tudsz, és nem vagy sziklaszilárd a részletekben mert ha tudod,",
  "n_reviews": 1,
  "start": 492.4,
  "end": 496.12
 },
 {
  "input": "If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over.",
  "translatedText": "Viszont ha ezeket megértetted, akkor a függvény minimalizálásának algoritmusa az, hogy kiszámítod ezt a gradiens irányt, majd teszel egy kis lépést lefelé, és ezt újra meg újra megismétled.",
  "model": "DeepL",
  "from_community_srt": "hogy az algoritmus minimalizálja a függvényt, akkor ezt a gradiens irányt kell kiszámítani, majd egy kis lépést lefelé,",
  "n_reviews": 1,
  "start": 497.2,
  "end": 506.74
 },
 {
  "input": "It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs.",
  "translatedText": "Ugyanez az alapötlet egy olyan függvény esetében, amelynek 2 bemenet helyett 13000 bemenete van.",
  "model": "DeepL",
  "from_community_srt": "és Csak ismételje meg újra és újra Ugyanaz az alapötlet egy olyan funkcióhoz, amelynek 13 000 bemenete van a két bemenet helyett,",
  "n_reviews": 1,
  "start": 507.7,
  "end": 512.82
 },
 {
  "input": "Imagine organizing all 13,000 weights and biases of our network into a giant column vector.",
  "translatedText": "Képzeljük el, hogy a hálózatunk mind a 13000 súlyát és eltolósúlyát egy hatalmas oszlopvektorba rendezzük.",
  "model": "DeepL",
  "from_community_srt": "képzeld el mindent 13 ezer súly és a hálózatunk elfogultsága egy óriási oszlopvektorba A költségfüggvény negatív gradiense csak egy vektor",
  "n_reviews": 1,
  "start": 513.4,
  "end": 519.46
 },
 {
  "input": "The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function.",
  "translatedText": "A költségfüggvény negatív gradiense csak egy vektor, ami egy irányt mutat ebben az őrülten nagy bemeneti térben, és amely megmondja, hogy mely kis változtatásokat kell az összes számon elvégezni, ami a leggyorsabb csökkenést fogja okozni a költségfüggvényben.",
  "model": "DeepL",
  "from_community_srt": "Ez valami irány az õrületesen hatalmas bemeneti helyén belül, amely megmondja, hogy melyik hogy az összes szám megmutatja a költségcsökkenés leggyorsabb csökkenését és természetesen a speciálisan tervezett költségfunkcióval",
  "n_reviews": 1,
  "start": 520.14,
  "end": 534.88
 },
 {
  "input": "And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make.",
  "translatedText": "És természetesen ha a célunknak megfelelő költségfüggvény értékét sikerül csökkenteni a súlyok megváltoztatásával, akkor a hálózat kimenete az egyes minta adatokra kevésbé fog hasonlítani egy 10 értékből álló véletlenszerű tömbre, hanem inkább egy tényleges döntésre, amelyet kapni szeretnénk.",
  "model": "DeepL",
  "from_community_srt": "A súlyok és az előítéletek csökkentése azt jelenti, hogy a hálózat kimenetét minden egyes képzési adatra ki kell alakítani Kevésbé néz ki, mint egy tíz érték véletlenszerű tömbje, és inkább egy tényleges döntés,",
  "n_reviews": 1,
  "start": 535.64,
  "end": 550.82
 },
 {
  "input": "It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples.",
  "translatedText": "Fontos megjegyezni, hogy ez a költségfüggvény az összes minta adatra kapott eredmény átlagát tartalmazza, így ha minimalizálod, az azt jelenti, hogy az összes mintán jobb teljesítményt nyújt.",
  "model": "DeepL",
  "from_community_srt": "amit akarunk Fontos megjegyezni, hogy ez a költségfüggvény átlagosan az összes képzési adatot tartalmazza Tehát ha minimalizáljuk azt, azt jelenti,",
  "n_reviews": 1,
  "start": 551.44,
  "end": 561.18
 },
 {
  "input": "The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video.",
  "translatedText": "A gradiens hatékony kiszámítására szolgáló algoritmust, amely gyakorlatilag a neurális hálózat tanulásának lelke, visszaterjesztésnek hívják, és erről fogok beszélni a következő videóban.",
  "model": "DeepL",
  "from_community_srt": "hogy ez a jobb teljesítmény minden ilyen mintán Az algoritmust, amely hatékonyan képes a gradiens kiszámítására, ami a neurális hálózat megtanulása révén valójában a szív, És ez az,",
  "n_reviews": 1,
  "start": 563.82,
  "end": 573.98
 },
 {
  "input": "There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas.",
  "translatedText": "Ott arra szeretnék időt szánni, hogy végigvegyük mi történik pontosan az egyes súlyokkal egy adott minta adat esetében, és megpróbálok intuitív magyarázatot adni arra, hogy valójában mi történik a számítások és képletek mögött.",
  "model": "DeepL",
  "from_community_srt": "amit a következő videóról fogok beszélni Itt nagyon szeretnék időt kivenni Mi történik pontosan az egyes súlyokkal és minden egyes torzítással az adott képzési adatokkal kapcsolatban? Megpróbálja intuitív érzést adni arra vonatkozóan, hogy mi történik a megfelelő kalkulusok és képletek halmán kívül Itt van most a lényeg.",
  "n_reviews": 1,
  "start": 574.66,
  "end": 587.1
 },
 {
  "input": "Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function.",
  "translatedText": "Itt és most az a legfontosabb dolog, amit szeretném, ha tudnátok a megvalósítás részleteitől függetlenül, hogy amikor a hálózat tanulásáról beszélünk, azt értjük alatta, hogy egy költségfüggvényt minimalizálunk.",
  "model": "DeepL",
  "from_community_srt": "Szeretném, ha a végrehajtás részleteitől függetlenül tudnátok hogy mit értünk, amikor egy hálózati tanulásról beszélünk, hogy csak minimalizálja a költségfüggvényt és Vegyük észre,",
  "n_reviews": 1,
  "start": 587.78,
  "end": 598.36
 },
 {
  "input": "And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill.",
  "translatedText": "És vegyük észre, hogy ennek egyik következménye, hogy a költségfüggvény kimenetének szép simának kell lennie, hogy kis lépésekkel lefelé haladva megtaláljuk a lokális minimumot.",
  "model": "DeepL",
  "from_community_srt": "hogy ennek egyik következménye, hogy ez a költségfüggvénynek jó sima kimenetre van szüksége Annak érdekében,",
  "n_reviews": 1,
  "start": 599.3,
  "end": 608.1
 },
 {
  "input": "This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are.",
  "translatedText": "Ez az oka egyébként annak, hogy a mesterséges neuronok aktivációja folytonos skálán mozog, és nem egyszerűen binárisan aktívak vagy inaktívak, mint a biológiai neuronok.",
  "model": "DeepL",
  "from_community_srt": "hogy a helyi minimális szintet lecsökkentsük a lejtőn Ezért az úton A mesterséges neuronok folyamatosan aktiválódnak, nem pedig egyszerűen aktívak vagy inaktívak bináris módon ha a biológiai neuronok így vannak",
  "n_reviews": 1,
  "start": 609.26,
  "end": 619.14
 },
 {
  "input": "This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent.",
  "translatedText": "Ezt a folyamatot, amely során egy függvény bemenetét ismételten a negatív gradienssel változtatják, gradiens ereszkedésnek nevezzük.",
  "model": "DeepL",
  "from_community_srt": "Ezt a folyamatot többszörös negatív gradiensnek egy függvény bemenetének átbillentésével nevezzük gradiens süllyesztésnek",
  "n_reviews": 1,
  "start": 620.22,
  "end": 626.76
 },
 {
  "input": "It's a way to converge towards some local minimum of a cost function, basically a valley in this graph.",
  "translatedText": "Ez egy módja annak, hogy a költségfüggvény egy lokális minimuma felé konvergáljunk, ami egy völgy ebben a gráfban.",
  "model": "DeepL",
  "from_community_srt": "Ez a módja annak, hogy egy helyi költség minimálisan egy minimális költségfüggvényhez közelítsenek egy völgyet ebben a grafikonban",
  "n_reviews": 1,
  "start": 627.3,
  "end": 632.58
 },
 {
  "input": "I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this.",
  "translatedText": "Természetesen még mindig egy kétváltozós függvény képét mutatom, mert a 13000 dimenziós térben a változtatásokat egy kicsit nehéz elképzelni, de van egy szép nem térbeli módja annak, hogy erről gondolkodjunk.",
  "model": "DeepL",
  "from_community_srt": "Természetesen két bejáratnál is megmutatom a függvény képét, mivel tizenhárom ezer dimenziós bemeneten mozog A tér egy kicsit nehéz elrejteni az elmédet, de tényleg van egy jó,",
  "n_reviews": 1,
  "start": 633.44,
  "end": 644.26
 },
 {
  "input": "Each component of the negative gradient tells us two things.",
  "translatedText": "A negatív gradiens minden egyes összetevője két dolgot mond el nekünk.",
  "model": "DeepL",
  "from_community_srt": "nem térbeli módszer erre gondolni A negatív gradiens minden komponense két dolgot mond el nekünk,",
  "n_reviews": 1,
  "start": 645.08,
  "end": 648.44
 },
 {
  "input": "The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down.",
  "translatedText": "Az előjel természetesen megmondja, hogy a bemeneti vektor megfelelő komponensét felfelé vagy lefelé kell-e tolni.",
  "model": "DeepL",
  "from_community_srt": "természetesen a jel arra utal, hogy a megfelelő A bemeneti vektor komponensét felfelé vagy lefelé kell felhúzni,",
  "n_reviews": 1,
  "start": 649.06,
  "end": 655.14
 },
 {
  "input": "But importantly, the relative magnitudes of all these components kind of tells you which changes matter more.",
  "translatedText": "De ami fontos, hogy ezen összetevők relatív nagysága megmutatja, hogy mely változások számítanak többet.",
  "model": "DeepL",
  "from_community_srt": "de fontos, hogy ezeknek az összetevőknek relatív nagysága A fajta megmondja,",
  "n_reviews": 1,
  "start": 655.8,
  "end": 662.72
 },
 {
  "input": "You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight.",
  "translatedText": "Tudod, a mi hálózatunkban az egyik súly kiigazítása sokkal nagyobb hatással lehet a költségfüggvényre, mint egy másik súly kiigazítása.",
  "model": "DeepL",
  "from_community_srt": "hogy mely változások jelentenek többet Úgy látja, hogy a hálózatunkon a súlyok valamelyikének beállítása sokkal nagyobb lehet hatással van a költségfüggvényre,",
  "n_reviews": 1,
  "start": 665.22,
  "end": 673.04
 },
 {
  "input": "Some of these connections just matter more for our training data.",
  "translatedText": "Néhány kapcsolat egyszerűen csak többet számít a minta adataink szempontjából.",
  "model": "DeepL",
  "from_community_srt": "mint egy másik súlyra való beállítás Néhány ilyen kapcsolat csak számunkra többet jelent a képzési adatokhoz",
  "n_reviews": 1,
  "start": 674.8,
  "end": 678.2
 },
 {
  "input": "So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck.",
  "translatedText": "Tehát az észbontóan masszív költségfüggvényünk gradiens vektora igazából az egyes súlyok és eltolósúlyok relatív fontosságát kódolja, vagyis azt, hogy ezek közül a változások közül melyik fogja a legtöbb vizet hajtani a malmunkra.",
  "model": "DeepL",
  "from_community_srt": "Tehát olyan módon, hogy gondolkodni tud ezen a gradiens vektorán a tudatunkon A masszív költségfüggvény az, hogy kódolja az egyes súlyok és torzítások relatív fontosságát Ez az,",
  "n_reviews": 1,
  "start": 679.32,
  "end": 692.4
 },
 {
  "input": "This really is just another way of thinking about direction.",
  "translatedText": "Ez tényleg csak egy másik módja az irányról való gondolkodásnak.",
  "model": "DeepL",
  "from_community_srt": "ami ezek közül a változások közül a leginkább a bummért jár Ez csak egy újabb gondolkodási mód",
  "n_reviews": 1,
  "start": 693.62,
  "end": 696.64
 },
 {
  "input": "To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction.",
  "translatedText": "Egy egyszerűbb példával élve, ha van valamilyen függvényünk két bemeneti változóval, és kiszámítjuk, hogy a gradiensére egy adott ponton három-egy jön ki, akkor egyrészt ezt úgy értelmezhetjük, hogy ha a bemenetnél állunk, akkor az ebben az irányban való mozgás növeli a leggyorsabban a függvényt. Így amikor a függvényt a bemeneti pontok síkja felett ábrázoljuk, akkor ez a vektor adja az egyenesen felfelé mutató irányt.",
  "model": "DeepL",
  "from_community_srt": "Egyszerűbb példa, ha van egy funkciója két változóval, mint bemenet, és te Számítsd ki, hogy a gradiens bizonyos pontokon jön ki, mint (3,1) Aztán egyrészt úgy értelmezheted azt, mint amikor azt mondod, hogy amikor az adott bemeneten állsz az ilyen irányú mozgás gyorsabban növeli a funkciót Ha a függvényt a bemeneti pontok síkja felett ábrázolja, akkor a vektor az, ami az egyenes felfelé irányuló irányt adja De egy másik módja annak,",
  "n_reviews": 1,
  "start": 697.1,
  "end": 722.26
 },
 {
  "input": "But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck.",
  "translatedText": "De ezt másképp is értelmezhetjük, történetesen, hogy az első bemenet változása háromszor olyan fontos, mint a második bemenet változása. Tehát legalábbis a releváns bemenetek szomszédságában az x-érték megváltoztatása sokkal több hasznot hoz.",
  "model": "DeepL",
  "from_community_srt": "hogy ezt olvassuk, azt jelenti, hogy megváltozik ez az első változó Háromszor nagyobb a fontossága, mint a második változóban bekövetkezett változások, amelyek legalább a releváns bemenet szomszédságában vannak Az x érték elcsúszása sokkal nagyobb bummért jár a pénzedért",
  "n_reviews": 1,
  "start": 722.86,
  "end": 736.9
 },
 {
  "input": "Let's zoom out and sum up where we are so far.",
  "translatedText": "Lépjünk kicsit hátrébb és foglaljuk össze, hol tartunk.",
  "model": "DeepL",
  "from_community_srt": "Rendben Növeljük ki, és összegezzük, ahol eddig vagyunk,",
  "n_reviews": 1,
  "start": 739.88,
  "end": 742.34
 },
 {
  "input": "The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums.",
  "translatedText": "Maga a hálózat ez a függvény 784 bemenettel és 10 kimenettel, amelyet e súlyozott összegek alapján határozunk meg.",
  "model": "DeepL",
  "from_community_srt": "és maga a hálózat maga is ezzel a funkcióval 784 bemenetet és 10 kimenetet határoz meg mindegyik súlyozott összeg tekintetében",
  "n_reviews": 1,
  "start": 742.84,
  "end": 750.04
 },
 {
  "input": "The cost function is a layer of complexity on top of that.",
  "translatedText": "A költségfüggvény egy újabb komplexitási réteg a tetején.",
  "model": "DeepL",
  "from_community_srt": "a költségfüggvény egy olyan komplexitási réteg,",
  "n_reviews": 1,
  "start": 750.64,
  "end": 753.68
 },
 {
  "input": "It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples.",
  "translatedText": "A program bemenete a 13000 súly és a képzési példák, amelyek alapján egyetlen pocséksági mérőszámot dob ki.",
  "model": "DeepL",
  "from_community_srt": "amely tetején van 13.000 súly és előítélet, mint bemenet,",
  "n_reviews": 1,
  "start": 753.98,
  "end": 761.72
 },
 {
  "input": "And the gradient of the cost function is one more layer of complexity still.",
  "translatedText": "A költségfüggvény gradiense pedig egy újabb bonyolultsági réteg.",
  "model": "DeepL",
  "from_community_srt": "és kiegyenlít egy mércét a hülyeség alapján a képzési példák és A költségfüggvény gradiense még egy további komplexitási réteg,",
  "n_reviews": 1,
  "start": 762.44,
  "end": 766.9
 },
 {
  "input": "It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most.",
  "translatedText": "Megmondja, hogy a súlyok és eltolósúlyok milyen változtatásai okozzák a leggyorsabb csökkenést a költségfüggvény értékében, amit úgy is értelmezhetünk, hogy melyik súlyok változásai számítanak a legtöbbet.",
  "model": "DeepL",
  "from_community_srt": "mégis azt mondja nekünk Ami ezeknek a súlyoknak és előítéleteknek köszönhető, a leggyorsabb változást okozzák a költségfüggvény értékében Amit értelmezhetsz, azt mondod,",
  "n_reviews": 1,
  "start": 767.36,
  "end": 777.88
 },
 {
  "input": "So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before?",
  "translatedText": "Tehát, ha a hálózatot véletlenszerű súlyokkal inicializáljuk, és ezeket a gradiens ereszkedés folyamat során többször is módosítjuk, mennyire fog jól teljesít olyan képeken, amelyeket még soha nem látott?",
  "model": "DeepL",
  "from_community_srt": "melyik változás milyen súlyú a súlyok szempontjából Így, ha a hálózatot véletlenszerű súlyokkal és előítéletekkel kezded, és sokszor beállítod ezeket a gradiens süllyedési folyamat alapján Mennyire jól működik olyan képeken, amelyeket soha nem látott? Nos,",
  "n_reviews": 1,
  "start": 782.56,
  "end": 793.2
 },
 {
  "input": "The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly.",
  "translatedText": "Az eddigiekben bemutatott hálózat, két, egyenként 16 neuronból álló rejtett réteggel, amelyet főleg esztétikai okokból választottam: Hát, nem rossz, az új képek 96%-át helyesen osztályozza.",
  "model": "DeepL",
  "from_community_srt": "amit itt leírtál a tizenhat neuronból álló két rejtett réteggel, melyek mindegyikét esztétikai okokból választották Nos, nem rossz, hogy az új képek 96 százaléka helyesen osztályozza Őszintén szólva,",
  "n_reviews": 1,
  "start": 794.1,
  "end": 805.96
 },
 {
  "input": "And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack.",
  "translatedText": "És őszintén szólva, ha megnézel néhány példát, amit elront, nem igazán tudod érte hibáztatni.",
  "model": "DeepL",
  "from_community_srt": "ha megnézed azokat a példákat, amelyekkel elrontotta magát, olyan érzést keltett,",
  "n_reviews": 1,
  "start": 806.68,
  "end": 812.54
 },
 {
  "input": "Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%.",
  "translatedText": "Ha kicsit eljátszadozol a rejtett rétegek felépítésével, és végzel néhány finomítást, akkor ezt 98%-ra tudod növelni.",
  "model": "DeepL",
  "from_community_srt": "hogy egy kicsit lassan Most, ha játszol a rejtett rétegszerkezettel és csinálsz pár csípést Tudod ezt akár 98%, és ez nagyon jó.",
  "n_reviews": 1,
  "start": 816.22,
  "end": 821.76
 },
 {
  "input": "And that's pretty good!",
  "translatedText": "És ez elég jó eredmény!",
  "model": "DeepL",
  "n_reviews": 1,
  "start": 821.76,
  "end": 822.72
 },
 {
  "input": "It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for.",
  "translatedText": "Biztosan el lehet érni jobb teljesítményt, egy kifinomultabb hálózat használatával, de tekintve, hogy mennyire ijesztő a kezdeti feladat, azt hiszem, van valami hihetetlen abban, hogy egy hálózat ilyen jól tud teljesíteni olyan képeken, amelyeket még soha nem látott, főleg, hogy soha nem mondtuk meg neki konkrétan, hogy milyen mintákat keressen.",
  "model": "DeepL",
  "from_community_srt": "Nem a legjobb Biztosan jobb teljesítményt érhet el, ha kifinomultabbá válik, mint ez a sima vaníliahálózat De mivel a kezdeti feladat megrémisztult, azt gondolom, hogy van valami? Hihetetlen bármilyen hálózatra, ami jól csinálja ezeket a képeket, amelyeket soha nem látott Tekintettel arra, hogy soha nem mondtuk el kifejezetten,",
  "n_reviews": 1,
  "start": 823.02,
  "end": 841.42
 },
 {
  "input": "Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits.",
  "translatedText": "Eredetileg abban reménykedtem, hogy arra tudom motiválni a hálózatot, hogy a második réteg felismeri a kis éleket, a harmadik réteg összerakja ezeket az éleket, hogy felismerje a hurkokat és a hosszabb vonalakat, és ezeket összeállítva felismerhetőek legyenek a számjegyeket.",
  "model": "DeepL",
  "from_community_srt": "hogy milyen mintákat keresni Eredetileg az a motiváció, hogy motiváltam ezt a struktúrát azáltal, hogy leírtam a reményt, hogy mi lehet Hogy a második réteg kis széleken felveszi Hogy a harmadik réteg összezárja azokat az éleket, hogy felismerjék a hurkot és a hosszabb vonalakat,",
  "n_reviews": 1,
  "start": 842.56,
  "end": 857.18
 },
 {
  "input": "So is this what our network is actually doing?",
  "translatedText": "De valóban ezt csinálja a hálózatunk?",
  "model": "DeepL",
  "from_community_srt": "és hogy ezeket a számokat felismerhessék Tehát ez a mi hálózatunk valójában?",
  "n_reviews": 1,
  "start": 857.96,
  "end": 860.4
 },
 {
  "input": "Well, for this one at least, not at all.",
  "translatedText": "Nos, ebben az esetben legalábbis egyáltalán nem.",
  "model": "DeepL",
  "from_community_srt": "Legalább ezt Egyáltalán nem ne feledje,",
  "n_reviews": 1,
  "start": 861.08,
  "end": 864.4
 },
 {
  "input": "Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on?",
  "translatedText": "Emlékeztek, hogy az előző videóban azt néztük meg, hogy az első réteg összes neuronja és a második réteg egy adott neuronja közötti kapcsolatok súlyai hogyan ábrázolhatók egy adott pixelmintaként, amelyet a második réteg neuronja felfog?",
  "model": "DeepL",
  "from_community_srt": "hogy az utolsó videó hogyan nézett ki a súlyok a Az első réteg összes neuronja és az adott neuron közötti kapcsolat a második rétegben Úgy lehet megjeleníteni, mint egy adott képpont mintát, amelyet a második réteg neuronja felszed Nos,",
  "n_reviews": 1,
  "start": 864.82,
  "end": 877.06
 },
 {
  "input": "Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there.",
  "translatedText": "Nos, amikor ezt alkalmazzuk az első és második réteg közötti átmenetekhez tartozó súlyokra, ahelyett, hogy itt-ott elszigetelt kis éleket vennénk észre, szinte teljesen véletlenszerűnek tűnnek, csak néhány nagyon elvont mintával a közepén.",
  "model": "DeepL",
  "from_community_srt": "amikor ténylegesen ezt tesszük az ilyen átmenetekhez kapcsolódó súlyoknál az első rétegtől a másikig Ahelyett, hogy itt-ott elszigetelt kis széleket felvenne. Szinte véletlenszerűnek tűnnek Csak tedd fel néhány nagyon laza mintát a közepén ott,",
  "n_reviews": 1,
  "start": 877.78,
  "end": 893.68
 },
 {
  "input": "It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for.",
  "translatedText": "Úgy tűnik, hogy a lehetséges súlyok és eltolósúlyok kifürkészhetetlenül nagy, 13000 dimenziós terében a hálózatunk egy kényelmes kis lokális minimumot talált magának, amely annak ellenére, hogy a legtöbb képet sikeresen osztályozza, nem éppen a remélt mintákat veszi észre.",
  "model": "DeepL",
  "from_community_srt": "úgy tűnik, hogy a feltétlenül nagy A potenciális súlyok 13 000 dimenziós teret és elfogultságát a hálózatunkban boldog kis helyi minimumnak találta annak ellenére, hogy sikeresen osztályozta a legtöbb képet, nem pontosan veszi fel azokat a mintákat, amelyekre reménykedtünk Ahhoz,",
  "n_reviews": 1,
  "start": 893.76,
  "end": 908.96
 },
 {
  "input": "And to really drive this point home, watch what happens when you input a random image.",
  "translatedText": "És hogy ezt az állításomat igazolni is tudjam, nézd meg, mi történik egy random képpel.",
  "model": "DeepL",
  "from_community_srt": "hogy valóban meghajtja ezt a pontot, otthoni figyeld, mi történik,",
  "n_reviews": 1,
  "start": 909.78,
  "end": 913.82
 },
 {
  "input": "If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5.",
  "translatedText": "Ha a rendszer okos lenne, akkor azt várnánk, hogy bizonytalannak érezze magát, talán nem aktiválva a 10 kimeneti neuron egyikét sem, vagy nem egyenletesen. Ehelyett magabiztosan ad valami ostoba választ, mintha ugyanolyan biztos lenne abban, hogy ez a véletlenszerű zaj egy 5-ös, mint abban, hogy az 5-ös valódi képe egy 5-ös.",
  "model": "DeepL",
  "from_community_srt": "ha véletlenszerű képet ad meg ha a rendszer okos volt, azt valószínűleg bizonytalanná válna, talán nem igazán aktiválja a 10 kimeneti neuronok egyikét sem Mindezt egyenletesen aktiválja De inkább Magabiztosan ad neked valami értelmetlen választ, mintha biztos lenne benne, hogy ez a véletlenszerű zaj 5, ugyanúgy, mint egy tényleges az 5-ös kép 5-ös másképp,",
  "n_reviews": 1,
  "start": 914.32,
  "end": 934.16
 },
 {
  "input": "Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them.",
  "translatedText": "Másképp fogalmazva, még ha ez a hálózat elég jól fel is ismeri a számjegyeket, fogalma sincs, hogyan kell őket megrajzolni.",
  "model": "DeepL",
  "from_community_srt": "ha ez a hálózat nagyon jól tudja felismerni a számjegyeket, fogalma sincs,",
  "n_reviews": 1,
  "start": 934.54,
  "end": 940.7
 },
 {
  "input": "A lot of this is because it's such a tightly constrained training setup.",
  "translatedText": "Ez nagyrészt azért van, mert nem ez a tanítás célja.",
  "model": "DeepL",
  "from_community_srt": "hogyan kell őket rajzolni Sok ilyen, mert ilyen szigorúan korlátozott képzés Úgy értem,",
  "n_reviews": 1,
  "start": 941.42,
  "end": 945.24
 },
 {
  "input": "I mean, put yourself in the network's shoes here.",
  "translatedText": "Úgy értem, képzeld magát a hálózat helyébe.",
  "model": "DeepL",
  "from_community_srt": "hogy itt a hálózat cipőjébe helyezem,",
  "n_reviews": 1,
  "start": 945.88,
  "end": 947.74
 },
 {
  "input": "From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions.",
  "translatedText": "Az ő szemszögéből nézve az egész világ nem áll másból, mint egy apró rácsban elhelyezett mozdulatlan számjegyekből, és a költségfüggvénye soha nem ösztönözte arra, hogy bármi mást tegyen, minthogy teljesen magabiztos legyen a döntéseiben.",
  "model": "DeepL",
  "from_community_srt": "az egész világmindenség a semmiből áll De az egyértelműen definiált, mozgatható számjegyek egy apró rácsban és költségfüggvényében soha nem adták meg Ösztönözni kell, hogy legyen bármi, de határozottan magabiztos a döntéseiben Tehát,",
  "n_reviews": 1,
  "start": 948.14,
  "end": 961.08
 },
 {
  "input": "So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns.",
  "translatedText": "Így felmerülhet benned a kérdés, hogy miért szeretném, ha a hálózat az éleket és hasonló mintákat vegye észre, ha a jelenlegi neuronok teljesen mást csinálnak.",
  "model": "DeepL",
  "from_community_srt": "ha ez a kép, amit a második réteg neuronjai valóban csinálnak Talán azon tűnődnél, hogy miért vezetném be ezt a hálózatot azzal a motivációval, hogy a széleken és a mintákon felszedjem Úgy értem,",
  "n_reviews": 1,
  "start": 962.12,
  "end": 969.92
 },
 {
  "input": "I mean, that's just not at all what it ends up doing.",
  "translatedText": "Akkor miért ezzel mutatom be a hálózat működését?",
  "model": "DeepL",
  "from_community_srt": "ez egyáltalán nem egyezik meg azzal,",
  "n_reviews": 1,
  "start": 969.92,
  "end": 972.3
 },
 {
  "input": "Well, this is not meant to be our end goal, but instead a starting point.",
  "translatedText": "Nos, mert a mostani hálózat nem a végcélunk, hanem egy kiindulópont.",
  "model": "DeepL",
  "from_community_srt": "amit csinál Nos, ez nem a végső célunk,",
  "n_reviews": 1,
  "start": 973.38,
  "end": 977.18
 },
 {
  "input": "Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems.",
  "translatedText": "Őszintén szólva, ez elég régi technológia, amit a 80-as és 90-es években kutattak. De ezt meg kell értened a részletesebb modern változatok megértéséhez. És ez is képes megoldani néhány érdekes problémát, de minél jobban beleásod magad abba, hogy mit csinálnak valójában ezek a rejtett rétegek, annál kevésbé tűnik intelligensnek.",
  "model": "DeepL",
  "from_community_srt": "hanem nyíltan kiindulópont Ez a régi technológia a fajta kutatott a 80-as és 90-es években és Ezt meg kell értenie, mielőtt megértené a részletesebb modern változatokat, és egyértelműen képes néhány érdekes problémát megoldani De minél többet ássz be, amit ezek a rejtett rétegek tényleg a kevésbé intelligensek,",
  "n_reviews": 1,
  "start": 977.64,
  "end": 994.74
 },
 {
  "input": "Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow.",
  "translatedText": "Egy pillanatra helyezzük át a hangsúlyt a hálózatok tanulási módjáról arra, hogy te hogyan tanulsz. Ez csak akkor működik, ha aktívan foglalkozol az anyaggal.",
  "model": "DeepL",
  "from_community_srt": "úgy tűnik A fókusz egy pillanatra történő elmozdítása arról, hogy a hálózatok megtanulják a tanulás módját Ez csak akkor történik, ha valamilyen módon aktívan részt vesz az anyaggal Egy nagyon egyszerű dolog,",
  "n_reviews": 1,
  "start": 998.48,
  "end": 1006.3
 },
 {
  "input": "One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns.",
  "translatedText": "Egy nagyon egyszerű dolgot szeretnék. Állítsd meg kicsit a videót, és és gondolkozz el azon, hogy mit tudnál változtatni ezen a rendszeren és azon, ahogyan a képeket érzékeli, ha azt akarod, hogy jobban észrevegye az élekhez és hurkokhoz hasonló mintákat.",
  "model": "DeepL",
  "from_community_srt": "hogy azt akarom, hogy csinálj, most szünetelsz, és egy pillanatig mélyen gondolkodj azon, hogy mit A rendszerhez esetleg végrehajtott módosítások És hogyan érzékeli a képeket, ha jobban szeretné, ha olyan dolgokra venné fel a dolgokat,",
  "n_reviews": 1,
  "start": 1007.06,
  "end": 1020.88
 },
 {
  "input": "But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks.",
  "translatedText": "De ha még ennél is jobban akarsz foglalkozni az anyaggal, nagyon ajánlom Michael Nielsen könyvét a gépi tanulásról és a neurális hálózatokról.",
  "model": "DeepL",
  "from_community_srt": "mint az élek és a minták? De annál jobb, hogy valóban vegyen részt az anyaggal én Nagyon ajánljuk Michael Nielsen könyvét a mély tanulásról és a neurális hálózatokról",
  "n_reviews": 1,
  "start": 1021.48,
  "end": 1029.1
 },
 {
  "input": "In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing.",
  "translatedText": "Itt megtalálod a kódot és az adatokat, amelyeket letölthetsz és játszhatsz az eddigiekben bemutatott példával, és a könyv lépésről lépésre végigvezet a kódon.",
  "model": "DeepL",
  "from_community_srt": "Ebben megtalálja a kódot és az adatokat, amelyeket letölteni és játszani ezzel a pontos példával És a könyv lépésről-lépésre meglátogatja Önt,",
  "n_reviews": 1,
  "start": 1029.68,
  "end": 1038.36
 },
 {
  "input": "What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts.",
  "translatedText": "A legjobb az egészben az, hogy ez a könyv nyilvános és ingyenesen elérhető, így ha hasznosnak találod, fontold meg, hogy hozzám hasonlóan adományozol az erőfeszítéséért.",
  "model": "DeepL",
  "from_community_srt": "mi a kód Ami félelmetes, hogy ez a könyv ingyenes és nyilvánosan elérhető Tehát ha valamit kapsz ki, fontold meg, hogy csatlakozol hozzám, hogy adományt csinálj Nielsen erőfeszítései ellen Én is összekapcsoltam egy pár más erőforrást,",
  "n_reviews": 1,
  "start": 1039.3,
  "end": 1047.66
 },
 {
  "input": "I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill.",
  "translatedText": "A leírásban néhány más, általam nagyon kedvelt forrást is belinkeltem, köztük Chris Ola fenomenális és gyönyörű blogbejegyzését és a Distill cikkeit.",
  "model": "DeepL",
  "from_community_srt": "amelyeket sokat szeretek a leírásban, beleértve a Chris Ola fenomenális és szép blogbejegyzése és a desztillált cikkek A dolgok lezárása az utóbbi néhány percben",
  "n_reviews": 1,
  "start": 1047.66,
  "end": 1056.5
 },
 {
  "input": "To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee.",
  "translatedText": "Az utolsó percekben lezárásként szeretnék idézni egy részletet a Leisha Lee-vel készített interjúból.",
  "model": "DeepL",
  "from_community_srt": "Szeretnék visszalépni egy olyan részletre,",
  "n_reviews": 1,
  "start": 1058.28,
  "end": 1063.88
 },
 {
  "input": "You might remember her from the last video, she did her PhD work in deep learning.",
  "translatedText": "Talán emlékeztek rá az előző videóból. A gépi tanulásból végezte a PhD-ját.",
  "model": "DeepL",
  "from_community_srt": "amellyel Leisha Lee-nal találkoztam Talán emlékszik rá az utolsó videóról.",
  "n_reviews": 1,
  "start": 1064.3,
  "end": 1067.72
 },
 {
  "input": "In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning.",
  "translatedText": "Ebben a kis részletben két nemrégiben megjelent cikkről beszél, amelyek igazán mélyre ásnak abban, hogyan tanulnak a modernebb képfelismerő hálózatok.",
  "model": "DeepL",
  "from_community_srt": "PhD munkáját mély tanulással és ebben a kis részletben végezte Két új tanulmányról beszél, amelyek valóban azonosítják, hogy a modern képfelismerő hálózatok valóban tanulnak Csak azért,",
  "n_reviews": 1,
  "start": 1068.3,
  "end": 1075.78
 },
 {
  "input": "Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training.",
  "translatedText": "Ott tartottunk az interjúban, hogy az első cikk egy különösen sok rétegű neurális hálózatot vizsgált, amely nagyon jó a képfelismerésben, de a betanítás előtt a megfelelően felcímkézett adathalmaz összes címkéjét megkeverték.",
  "model": "DeepL",
  "from_community_srt": "hogy felállítsuk, hol vagyunk a beszélgetésben, az első papír az egyik különösen mély neurális hálózatot vette Ez valóban jó a képfelismerésnél, és nem helyesen felcímkézett adatokon Állítsa be, hogy az összes címkét megcsinálta a képzés előtt Nyilvánvaló,",
  "n_reviews": 1,
  "start": 1076.12,
  "end": 1088.74
 },
 {
  "input": "Obviously the testing accuracy here was going to be no better than random, since everything's just randomly labeled. But it was still able to achieve the same training accuracy as you would on a properly labeled dataset.",
  "translatedText": "Nyilvánvaló, hogy a tesztelési pontosság nem jobb a randomnál, mivel minden csak véletlenszerűen van címkézve, de még mindig képes volt ugyanazt a képzési pontosságot elérni, mint egy megfelelően címkézett adathalmaznál.",
  "model": "DeepL",
  "from_community_srt": "hogy a tesztelési pontosság itt nem jobb, mint véletlenszerű, mivel mindent véletlenszerűen címkézett De még mindig képes volt ugyanazt a képzési pontosságot elérni,",
  "n_reviews": 1,
  "start": 1089.48,
  "end": 1100.88
 },
 {
  "input": "Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization?",
  "translatedText": "Lényegében a több millió súly elég volt a hálózatnak ahhoz, hogy szimplán megjegyezze a véletlenszerű adatokat, ami felveti a kérdést, hogy vajon a költségfüggvény minimalizálása valóban valamilyen alakzatokat fog észrevenni a képen, vagy ez csak memorizálás?",
  "model": "DeepL",
  "from_community_srt": "mint egy megfelelően címkézett adatkészleten Alapvetően ez a hálózat több millió súlya elég volt ahhoz, hogy csak a véletlenszerű adatokat tárolja Milyen kérdés merül fel arra vonatkozóan, hogy a költségfunkció minimalizálása ténylegesen megfelel-e a kép bármely szerkezetének? Vagy csak tudod?",
  "n_reviews": 1,
  "start": 1101.6,
  "end": 1116.4
 },
 {
  "input": "...to memorize the entire dataset of what the correct classification is. And so a couple of, you know, half a year later at ICML this year, there was not exactly rebuttal paper, but paper that addressed some aspects of like, hey, actually these networks are doing something a little bit smarter than that. If you look at that accuracy c",
  "translatedText": "Ha megnézzük a pontossági görbét, ha csak egy véletlenszerű adathalmazon edzenénk, akkor ez a görbe nagyon lassan, szinte lineárisan csökkenne, tehát tényleg küzdünk, hogy megtaláljuk a lehetséges helyi minimumokat, a megfelelő súlyokat, amelyekkel elérhetjük a pontosságot.",
  "model": "DeepL",
  "from_community_srt": "memorizálni az egészet Adja meg, hogy mi a helyes besorolás, tehát néhányan fél évvel később az ICML-ben ismerkedtek meg idén Nem volt pontosan a fellebbező papíralap, amely a megkérdezetteknek szólt, mint a hé Valójában ezek a hálózatok valami okosabbat csinálnak, mint ha megnézzük azt a pontossági görbét ha csak egy a Véletlen adatkészlet, hogy a görbe fajta lement nagyon tudod nagyon lassan szinte egyfajta lineáris módon Tehát tényleg igyekszel megtalálni a lehetséges helyi minimumokat tudod a megfelelő súlyokat, amelyek megkapnák a pontosságot,",
  "n_reviews": 0,
  "start": 1131.44,
  "end": 1152.14
 },
 {
  "input": "Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima.",
  "translatedText": "Míg ha egy strukturált, megfelelő címkékkel rendelkező adathalmazon edzünk, akkor az elején egy kicsit babrálunk, de aztán nagyon gyorsan eljutunk a pontossági szintre, és így bizonyos értelemben könnyebb volt megtalálni a lokális maximumot.",
  "model": "DeepL",
  "from_community_srt": "pedig ha egy olyan strukturált adathalmazon tanulsz, amelyik a Jobb címkék. Tudja, hogy eleinte egy kicsit hegedülsz, de aztán nagyon gyorsan leesett, hogy elérje Pontossági szint, és így bizonyos értelemben könnyebb volt megtalálni A helyi maximák,",
  "n_reviews": 1,
  "start": 1152.24,
  "end": 1168.22
 },
 {
  "input": "And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily.",
  "translatedText": "És ami szintén érdekes volt ebben, az az, hogy ez egy másik, néhány évvel ezelőtti tanulmányt is felidéz, amely sokkal több egyszerűsítést tartalmaz a hálózati rétegekkel kapcsolatban, de az egyik eredménye az, hogy ha megnézzük az optimalizációs domborzatot, a lokális minimumok, amelyeket ezek a hálózatok hajlamosak megtanulni, valójában azonos minőségűek, így bizonyos értelemben, ha az adatállományunk strukturált, sokkal könnyebben megtalálhatjuk azt.",
  "model": "DeepL",
  "from_community_srt": "és ezért érdekes volt, hogy az elkapta, egy másik, valójában néhány évvel ezelőtti papírt vet fel Ami sokkal több egyszerűsítéseket a hálózati rétegekről De az egyik eredmény azt mondta, hogy ha megnézzük az optimalizálási tájat, akkor a helyi minimumok, amelyeket ezek a hálózatok általában tanulnak Valójában ugyanolyan minőségű, így bizonyos értelemben, ha az adatkészleted szerkezet,",
  "n_reviews": 1,
  "start": 1168.54,
  "end": 1194.32
 },
 {
  "input": "My thanks, as always, to those of you supporting on Patreon.",
  "translatedText": "Mint mindig, köszönöm azoknak, akik támogatnak a Patreonon.",
  "model": "DeepL",
  "from_community_srt": "és könnyebben meg tudod találni Köszönetemet, mint mindig azoknak, akik támogatják a patrónust Már korábban azt mondtam,",
  "n_reviews": 1,
  "start": 1198.16,
  "end": 1201.18
 },
 {
  "input": "I've said before just what a game changer Patreon is, but these videos really would not be possible without you.",
  "translatedText": "A Patreon-os támogatás hatalmas segítség. Ezek a videók tényleg nem lennének lehetségesek nélkületek.",
  "model": "DeepL",
  "from_community_srt": "hogy egy játékváltó patreon van, de ezek a videók valóban nem lennének lehetségesek nélküled Azt is szeretnék,",
  "n_reviews": 1,
  "start": 1201.52,
  "end": 1206.8
 },
 {
  "input": "I also want to give a special thanks to the VC firm Amplify Partners and their support of these initial videos in the series. Thank you.",
  "translatedText": "Külön köszönetet szeretnék mondani az Amplify Partners cégnek is, amely támogatta e sorozat eddigi videóit.",
  "model": "DeepL",
  "from_community_srt": "hogy egy különleges. A VC cégnek köszönhetően erősíti a partnereit a sorozat kezdeti videóinak támogatásában",
  "n_reviews": 1,
  "start": 1207.46,
  "end": 1212.78
 }
]
