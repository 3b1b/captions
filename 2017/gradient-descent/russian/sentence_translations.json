[
 {
  "input": "Last video I laid out the structure of a neural network.",
  "translatedText": "В прошлом видео я изложил структуру нейронной сети.",
  "from_community_srt": "В последнем видео я изложил структуру нейронной сети Здесь я дам краткое описание структуры,",
  "n_reviews": 0,
  "start": 4.18,
  "end": 7.28
 },
 {
  "input": "I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video.",
  "translatedText": "Я подведу здесь краткий обзор, чтобы он был свеж в нашей памяти, а также у меня есть две основные цели для этого видео.",
  "from_community_srt": "чтобы освежить память И тогда у меня есть две основные цели для этого видео.",
  "n_reviews": 0,
  "start": 7.68,
  "end": 12.6
 },
 {
  "input": "The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well.",
  "translatedText": "Первый — представить идею градиентного спуска, которая лежит в основе не только того, как обучаются нейронные сети, но и того, как работают многие другие методы машинного обучения.",
  "from_community_srt": "Первый - представить идею градиентного спуска, которая лежит в основе не только того, как учатся нейронные сети, но как работает еще много других машин.",
  "n_reviews": 0,
  "start": 13.1,
  "end": 20.6
 },
 {
  "input": "Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for.",
  "translatedText": "Затем мы немного углубимся в то, как работает эта конкретная сеть и что в конечном итоге ищут эти скрытые слои нейронов.",
  "from_community_srt": "Затем, после этого, мы собираемся еще немного разобраться в том, как эта конкретная сеть работает И то, что скрывают эти скрытые слои нейронов,",
  "n_reviews": 0,
  "start": 21.12,
  "end": 27.94
 },
 {
  "input": "As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks.",
  "translatedText": "Напоминаем, что наша цель — классический пример распознавания рукописных цифр, привет, мир нейронных сетей.",
  "from_community_srt": "фактически ищет Напоминаем, что наша цель - классический пример распознавания рукописного знака привет мир нейронных сетей",
  "n_reviews": 0,
  "start": 28.98,
  "end": 36.22
 },
 {
  "input": "These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1.",
  "translatedText": "Эти цифры отображаются в сетке 28x28 пикселей, каждый пиксель имеет некоторое значение шкалы серого от 0 до 1.",
  "from_community_srt": "эти цифры отображаются на сетке размером 28 х 28 пикселей каждый пиксель с некоторым значением оттенков серого между 0 и 1",
  "n_reviews": 0,
  "start": 37.02,
  "end": 43.42
 },
 {
  "input": "Those are what determine the activations of 784 neurons in the input layer of the network.",
  "translatedText": "Именно они определяют активацию 784 нейронов входного слоя сети.",
  "from_community_srt": "это то, что определяют активации 784 нейронов во входном слое сети и Тогда активация для каждого нейрона в следующих слоях основана на взвешенной сумме",
  "n_reviews": 0,
  "start": 43.82,
  "end": 50.04
 },
 {
  "input": "And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias.",
  "translatedText": "А затем активация каждого нейрона в следующих слоях основана на взвешенной сумме всех активаций в предыдущем слое плюс некое специальное число, называемое смещением.",
  "from_community_srt": "Всех активаций в предыдущем слое плюс некоторое специальное значение,",
  "n_reviews": 0,
  "start": 51.18,
  "end": 60.82
 },
 {
  "input": "Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video.",
  "translatedText": "Затем вы составляете эту сумму с помощью какой-либо другой функции, например, сжимания сигмовидной кишки или повторения, как я рассматривал в прошлом видео.",
  "from_community_srt": "называемое смещением затем вы составляете эту сумму с помощью какой-либо другой функции, такой как сигмовидное уплотнение или ReLu, описание которого я предоставил в последнем видео В целом,",
  "n_reviews": 0,
  "start": 62.16,
  "end": 68.94
 },
 {
  "input": "In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does.",
  "translatedText": "В общей сложности, учитывая несколько произвольный выбор двух скрытых слоев по 16 нейронов каждый, сеть имеет около 13 000 весов и смещений, которые мы можем регулировать, и именно эти значения определяют, что именно делает сеть на самом деле.",
  "from_community_srt": "учитывая мой произвольный выбор двух скрытых слоев с 16 нейронами, каждая из которых имеет около 13 000 весов и смещений, которые мы можем настроить, и именно эти значения определяют, что именно сеть, которую вы видите,",
  "n_reviews": 0,
  "start": 69.48,
  "end": 84.38
 },
 {
  "input": "Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit.",
  "translatedText": "Тогда, когда мы говорим, что эта сеть классифицирует данную цифру, мы имеем в виду, что самый яркий из этих 10 нейронов в последнем слое соответствует этой цифре.",
  "from_community_srt": "действительно делает Тогда что мы имеем в виду, когда говорим, что эта сеть классифицирует данную цифру Самый яркий из этих 10 нейронов в конечном слое соответствует этой цифре",
  "n_reviews": 0,
  "start": 84.88,
  "end": 93.3
 },
 {
  "input": "And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits.",
  "translatedText": "И помните, мотивация, которую мы имели в виду здесь для многослойной структуры, заключалась в том, что, возможно, второй слой мог бы улавливать края, а третий слой мог бы улавливать такие узоры, как петли и линии, а последний мог бы просто собрать воедино эти шаблоны для распознавания цифр.",
  "from_community_srt": "И запомните, что мотивация, которую мы имели в виду здесь для многоуровневой структуры, заключалась в том, что, возможно, Второй слой может распознать кусочки, а третий слой может набирать рисунки, такие как петли и линии И последний мог просто объединить эти шаблоны, чтобы распознавать цифры Итак,",
  "n_reviews": 0,
  "start": 94.1,
  "end": 108.8
 },
 {
  "input": "So here, we learn how the network learns.",
  "translatedText": "Итак, здесь мы узнаем, как учится сеть.",
  "from_community_srt": "здесь мы узнаем, как сеть обучается Нам нужен алгоритм,",
  "n_reviews": 0,
  "start": 109.8,
  "end": 112.24
 },
 {
  "input": "What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data.",
  "translatedText": "Нам нужен алгоритм, с помощью которого вы сможете показать этой сети целый набор обучающих данных, которые представлены в виде набора различных изображений рукописных цифр вместе с метками того, какими они должны быть, и он будет отрегулируйте эти 13 000 весов и смещений, чтобы улучшить производительность на обучающих данных.",
  "from_community_srt": "в котором вы cможете показать этой сети целую кучу обучающих данных, которая поставляется в виде кучи разных изображений рукописных цифр вместе с пометками, что это за цифры Он будет корректировать эти 13000 весов и смещений для того, чтобы улучшить его производительность по данным обучения Надеемся,",
  "n_reviews": 0,
  "start": 112.64,
  "end": 130.12
 },
 {
  "input": "Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data.",
  "translatedText": "Будем надеяться, что эта многоуровневая структура будет означать, что то, что он изучает, обобщается на изображения, выходящие за рамки этих обучающих данных.",
  "from_community_srt": "что эта слоистая структура усвоит то,чему ее обучают и обобщит изображения,",
  "n_reviews": 0,
  "start": 130.72,
  "end": 136.86
 },
 {
  "input": "The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images.",
  "translatedText": "Мы тестируем это так: после обучения сети вы показываете ей больше размеченных данных, которых она никогда раньше не видела, и видите, насколько точно она классифицирует эти новые изображения.",
  "from_community_srt": "выходящие за рамки обучающих данных И мы это протестируем после обучения сети Вы показываете алгоритму дополнительные изображения, которые он раньше не видел, и увидите,",
  "n_reviews": 0,
  "start": 137.64,
  "end": 146.7
 },
 {
  "input": "Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be.",
  "translatedText": "К счастью для нас, и что делает этот пример таким распространенным, так это то, что хорошие люди, стоящие за базой данных MNIST, собрали коллекцию из десятков тысяч рукописных изображений цифр, каждое из которых помечено числами, которые они должны были быть.",
  "from_community_srt": "насколько точно он классифицирует эти новые изображения К счастью для нас и что делает этот такой распространенный пример, чтобы начать с того, что хорошие люди, стоящие за базой MNIST, собрал коллекцию из десятков тысяч рукописных цифровых изображений, каждый из которых помечен цифрами,",
  "n_reviews": 0,
  "start": 151.12,
  "end": 164.2
 },
 {
  "input": "And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise.",
  "translatedText": "И как бы провокационно ни было описание машины как обучающейся, как только вы увидите, как она работает, это станет уже не похоже на какую-то сумасшедшую научно-фантастическую предпосылку, а скорее на упражнение по математическому анализу.",
  "from_community_srt": "которые они должны были и Это провокационно, так как описывать машину как обучение, когда вы действительно видите, как это работает Он чувствует себя намного меньше, чем какая-то сумасшедшая научно-фантастическая предпосылка, а также гораздо больше, Я имею в виду,",
  "n_reviews": 0,
  "start": 164.9,
  "end": 175.48
 },
 {
  "input": "I mean, basically it comes down to finding the minimum of a certain function.",
  "translatedText": "Я имею в виду, что по сути все сводится к поиску минимума определенной функции.",
  "from_community_srt": "что в основном это сводится к поиску минимума определенной функции Помните концептуально,",
  "n_reviews": 0,
  "start": 176.2,
  "end": 179.96
 },
 {
  "input": "Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
  "translatedText": "Помните, концептуально мы думаем о том, что каждый нейрон связан со всеми нейронами предыдущего слоя, а веса во взвешенной сумме, определяющей его активацию, являются чем-то вроде силы этих связей, а смещение является некоторым показателем имеет ли этот нейрон тенденцию быть активным или неактивным.",
  "from_community_srt": "что мы думаем о каждом нейроне как о соединении для всех нейронов в предыдущем слое, а веса в взвешенной сумме, определяющие ее активацию, выглядят как сильные стороны этих связей И предвзятость - это некоторый признак того,",
  "n_reviews": 0,
  "start": 181.94,
  "end": 198.96
 },
 {
  "input": "And to start things off, we're just going to initialize all of those weights and biases totally randomly.",
  "translatedText": "И для начала мы просто собираемся инициализировать все эти веса и смещения совершенно случайным образом.",
  "from_community_srt": "что этот нейрон имеет тенденцию быть активным или неактивным и начинать Мы просто собираемся инициализировать все эти веса и предубеждения,",
  "n_reviews": 0,
  "start": 199.72,
  "end": 204.4
 },
 {
  "input": "Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random.",
  "translatedText": "Излишне говорить, что эта сеть будет работать ужасно на данном обучающем примере, поскольку она просто делает что-то случайное.",
  "from_community_srt": "совершенно бесполезно сказать, что эта сеть будет выполнять довольно ужасно на данном примере обучения, поскольку он просто делает что-то случайное,",
  "n_reviews": 0,
  "start": 204.94,
  "end": 210.72
 },
 {
  "input": "For example, you feed in this image of a 3, and the output layer just looks like a mess.",
  "translatedText": "Например, вы вводите это изображение с цифрой 3, а выходной слой выглядит как беспорядок.",
  "from_community_srt": "например, вы кормите этим изображением 3 и Выходной уровень - это просто беспорядок Итак,",
  "n_reviews": 0,
  "start": 211.04,
  "end": 216.02
 },
 {
  "input": "So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash.",
  "translatedText": "Итак, что вы делаете, так это определяете функцию стоимости, способ сообщить компьютеру (нет, плохой компьютер), что выходные данные должны иметь активации, которые равны 0 для большинства нейронов, но 1 для этого нейрона, то, что вы мне дали, — это полный мусор.",
  "from_community_srt": "что вы делаете, вы определяете функцию стоимости как способ сообщить компьютеру: «Нет плохого компьютера! Этот вывод должен иметь активацию, которая равна нулю для большинства нейронов, но для этого нейрона то, что вы дали мне, - это полный мусор \" Сказать,",
  "n_reviews": 0,
  "start": 216.6,
  "end": 230.76
 },
 {
  "input": "To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example.",
  "translatedText": "Если выразить это немного более математически, вы складываете квадраты различий между каждой из этих мусорных выходных активаций и желаемым значением, которое вы хотите, чтобы они имели, и это то, что мы будем называть стоимостью одного обучающего примера.",
  "from_community_srt": "что немного математически то, что вы делаете, это добавить квадраты различий между каждой из этих активированных выходов мусора и значения, которое вы хотите, чтобы они имели и Это то, что мы будем называть стоимостью одного примера обучения Обратите внимание:",
  "n_reviews": 0,
  "start": 231.72,
  "end": 245.02
 },
 {
  "input": "Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing.",
  "translatedText": "Обратите внимание, что эта сумма мала, когда сеть уверенно классифицирует изображение правильно, но она велика, когда кажется, что сеть не знает, что делает.",
  "from_community_srt": "эта сумма невелика, когда сеть уверенно классифицирует изображение правильно Но это большое, когда сеть кажется, что она не знает,",
  "n_reviews": 0,
  "start": 245.96,
  "end": 256.4
 },
 {
  "input": "So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal.",
  "translatedText": "Итак, что вам нужно сделать, так это оценить среднюю стоимость по всем десяткам тысяч обучающих примеров, имеющихся в вашем распоряжении.",
  "from_community_srt": "что она делает Итак, что вы делаете, считайте среднюю стоимость по всем десяткам тысяч примеров обучения в вашем распоряжении Эта средняя стоимость - это наша мера за то,",
  "n_reviews": 0,
  "start": 258.64,
  "end": 265.44
 },
 {
  "input": "This average cost is our measure for how lousy the network is, and how bad the computer should feel.",
  "translatedText": "Эта средняя стоимость является нашей мерой того, насколько паршивой является сеть и насколько плохим должен быть компьютер.",
  "from_community_srt": "насколько паршивая сеть и насколько плохо компьютер должен чувствовать,",
  "n_reviews": 0,
  "start": 267.04,
  "end": 272.74
 },
 {
  "input": "And that's a complicated thing.",
  "translatedText": "И это сложная вещь.",
  "from_community_srt": "и это сложная вещь Помните,",
  "n_reviews": 0,
  "start": 273.42,
  "end": 274.6
 },
 {
  "input": "Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases?",
  "translatedText": "Помните, что сама сеть по сути представляла собой функцию, которая принимает на вход 784 числа, значения пикселей и выдает 10 чисел на выходе, и в каком-то смысле она параметризуется всеми этими весами и смещениями?",
  "from_community_srt": "как сама сеть была в основном функцией, которая 784 числа вводит значения пикселей и выплескивает десять чисел в качестве вывода и в некотором смысле",
  "n_reviews": 0,
  "start": 275.04,
  "end": 288.8
 },
 {
  "input": "Well the cost function is a layer of complexity on top of that.",
  "translatedText": "Ну, функция стоимости — это еще один уровень сложности.",
  "from_community_srt": "Он параметризуется всеми этими весами и смещениями В то время как функция стоимости представляет собой слой сложности,",
  "n_reviews": 0,
  "start": 289.5,
  "end": 292.82
 },
 {
  "input": "It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data.",
  "translatedText": "В качестве входных данных он принимает примерно 13 000 весов и смещений и выдает одно число, описывающее, насколько плохи эти веса и смещения, а способ его определения зависит от поведения сети на всех десятках тысяч фрагментов обучающих данных.",
  "from_community_srt": "поверх которого он принимает в качестве своего входного те тринадцать тысяч или около того весов и предубеждений, и он выплескивает один номер, описывающий, насколько плохи эти веса и предубеждения и Способ его определения зависит от поведения сети по всем десяткам тысяч учебных данных",
  "n_reviews": 0,
  "start": 293.1,
  "end": 308.9
 },
 {
  "input": "That's a lot to think about.",
  "translatedText": "Об этом нужно много думать.",
  "n_reviews": 0,
  "start": 309.52,
  "end": 311.0
 },
 {
  "input": "But just telling the computer what a crappy job it's doing isn't very helpful.",
  "translatedText": "Но просто сказать компьютеру, какую дрянную работу он делает, не очень-то поможет.",
  "from_community_srt": "Об этом много думать Но просто рассказывая компьютеру, какая дрянная работа, это не очень полезно Вы хотите сказать,",
  "n_reviews": 0,
  "start": 312.4,
  "end": 315.82
 },
 {
  "input": "You want to tell it how to change those weights and biases so that it gets better.",
  "translatedText": "Вы хотите рассказать ему, как изменить эти веса и предубеждения, чтобы он стал лучше.",
  "from_community_srt": "как изменить эти веса и предубеждения,",
  "n_reviews": 0,
  "start": 316.22,
  "end": 320.06
 },
 {
  "input": "To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output.",
  "translatedText": "Чтобы упростить задачу, вместо того, чтобы изо всех сил пытаться представить функцию с 13 000 входными параметрами, просто представьте себе простую функцию, которая имеет одно число в качестве входных данных и одно число в качестве выходных данных.",
  "from_community_srt": "чтобы он стал лучше? Сделать это проще, чем пытаться представить себе функцию с 13 000 входов Представьте себе простую функцию, которая имеет один номер в качестве входного и одно число в качестве вывода Как вы находите вход,",
  "n_reviews": 0,
  "start": 320.78,
  "end": 330.48
 },
 {
  "input": "How do you find an input that minimizes the value of this function?",
  "translatedText": "Как найти входные данные, которые минимизируют значение этой функции?",
  "from_community_srt": "который минимизирует значение этой функции? Студенты исчисления будут знать,",
  "n_reviews": 0,
  "start": 331.48,
  "end": 335.3
 },
 {
  "input": "Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function.",
  "translatedText": "Студенты, изучающие математический анализ, знают, что иногда можно вычислить этот минимум явно, но это не всегда осуществимо для действительно сложных функций, особенно в версии этой ситуации с 13 000 входов для нашей безумно сложной функции стоимости нейронной сети.",
  "from_community_srt": "что иногда вы можете понять, что минимум явно Но это не всегда возможно для действительно сложных функций Конечно, не в тринадцати тысячной входной версии этой ситуации для нашей сумасшедшей сложной функции стоимости нейронной сети",
  "n_reviews": 0,
  "start": 336.46,
  "end": 351.08
 },
 {
  "input": "A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower.",
  "translatedText": "Более гибкая тактика — начать с любого входного сигнала и выяснить, в каком направлении вам следует двигаться, чтобы снизить этот выходной результат.",
  "from_community_srt": "Более гибкая тактика заключается в том, чтобы начать с любого старого ввода и выяснить, в каком направлении вы должны шагнуть,",
  "n_reviews": 0,
  "start": 351.58,
  "end": 359.2
 },
 {
  "input": "Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative.",
  "translatedText": "В частности, если вы можете определить наклон функции в том месте, где вы находитесь, затем сдвиньте влево, если этот наклон положителен, и сдвиньте входные данные вправо, если этот наклон отрицательный.",
  "from_community_srt": "чтобы сделать этот вывод ниже В частности, если вы можете определить наклон функции, в которой вы находитесь Затем сдвиньтесь влево, если этот наклон положителен и сдвиньте вход вправо,",
  "n_reviews": 0,
  "start": 360.08,
  "end": 369.9
 },
 {
  "input": "If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function.",
  "translatedText": "Если вы будете делать это неоднократно, в каждой точке проверяя новый наклон и делая соответствующий шаг, вы приблизитесь к некоторому локальному минимуму функции.",
  "from_community_srt": "если этот наклон отрицательный Если вы делаете это повторно в каждой точке, проверяя новый наклон и делая соответствующий шаг вы подходите к локальному минимуму функции и",
  "n_reviews": 0,
  "start": 371.96,
  "end": 379.84
 },
 {
  "input": "The image you might have in mind here is a ball rolling down a hill.",
  "translatedText": "Вы, возможно, имеете в виду образ мяча, катящегося с холма.",
  "from_community_srt": "изображение, которое вы, возможно, имеете в виду, это мяч,",
  "n_reviews": 0,
  "start": 380.64,
  "end": 383.8
 },
 {
  "input": "Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function.",
  "translatedText": "Обратите внимание: даже для этой действительно упрощенной функции с одним входом существует множество возможных впадин, в которые вы можете попасть, в зависимости от того, с какого случайного входа вы начинаете, и нет никакой гарантии, что локальный минимум, в который вы попадете, будет наименьшим возможным значением. функции стоимости.",
  "from_community_srt": "спускающийся с холма и Обратите внимание даже на эту очень упрощенную единую функцию ввода, есть много возможных долин, которые вы можете приземлиться В зависимости от того, какой случайный ввод вы начинаете, и нет гарантии, что местный минимум Вы приземляетесь,",
  "n_reviews": 0,
  "start": 384.62,
  "end": 399.4
 },
 {
  "input": "That will carry over to our neural network case as well.",
  "translatedText": "Это применимо и к нашему случаю с нейронной сетью.",
  "from_community_srt": "это будет наименьшее возможное значение функции стоимости Это также будет перенесено на наш случай с нейронной сетью,",
  "n_reviews": 0,
  "start": 400.22,
  "end": 402.62
 },
 {
  "input": "I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that helps you from overshooting.",
  "translatedText": "Я также хочу, чтобы вы заметили, что если вы сделаете размер шага пропорциональным наклону, то, когда уклон выравнивается к минимуму, ваши шаги будут становиться все меньше и меньше, и это поможет вам не промахнуться.",
  "from_community_srt": "и я также хочу, чтобы вы заметили Как сделать размеры шага пропорциональными наклону Затем, когда наклон сглаживается к минимуму, ваши шаги становятся все меньше и меньше, и этот вид помогает вам избежать перерегулирования Вместо того,",
  "n_reviews": 0,
  "start": 403.18,
  "end": 414.6
 },
 {
  "input": "Bumping up the complexity a bit, imagine instead a function with two inputs and one output.",
  "translatedText": "Немного усложняя, представьте себе функцию с двумя входами и одним выходом.",
  "from_community_srt": "чтобы усложнять сложность, вместо этого вы можете использовать функцию с двумя входами и одним выходом Вы можете представить входное пространство как плоскость XY,",
  "n_reviews": 0,
  "start": 415.94,
  "end": 420.98
 },
 {
  "input": "You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it.",
  "translatedText": "Вы можете думать о входном пространстве как о плоскости xy, а о функции стоимости как о графической поверхности над ней.",
  "from_community_srt": "а функцию стоимости, как графику, как поверхность над ней Теперь вместо того,",
  "n_reviews": 0,
  "start": 421.5,
  "end": 428.14
 },
 {
  "input": "Instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly.",
  "translatedText": "Вместо того, чтобы спрашивать о наклоне функции, вы должны спросить, в каком направлении вам следует двигаться в этом входном пространстве, чтобы быстрее всего уменьшить выходной результат функции.",
  "from_community_srt": "чтобы спрашивать о наклоне функции, вы должны спросить, в каком направлении вы должны входить в это пространство ввода? Чтобы быстрее уменьшить выход функции,",
  "n_reviews": 0,
  "start": 428.76,
  "end": 438.96
 },
 {
  "input": "In other words, what's the downhill direction?",
  "translatedText": "Другими словами, каково направление спуска?",
  "from_community_srt": "другими словами.",
  "n_reviews": 0,
  "start": 439.72,
  "end": 441.76
 },
 {
  "input": "Again, it's helpful to think of a ball rolling down that hill.",
  "translatedText": "Опять же, полезно представить себе мяч, катящийся с холма.",
  "from_community_srt": "Каково направление спуска? И снова полезно подумать о том, как мяч катится вниз по холму Те из вас,",
  "n_reviews": 0,
  "start": 442.38,
  "end": 445.56
 },
 {
  "input": "Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly.",
  "translatedText": "Те из вас, кто знаком с исчислением многих переменных, знают, что градиент функции указывает направление наибольшего подъема, в каком направлении вам следует сделать шаг, чтобы увеличить функцию быстрее всего.",
  "from_community_srt": "кто знаком с многовариантным исчислением, будут знать, что градиент функции дает вам направление самого крутого подъема В основном, в каком направлении вы должны быстро активировать функцию естественно,",
  "n_reviews": 0,
  "start": 446.66,
  "end": 458.78
 },
 {
  "input": "Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly.",
  "translatedText": "Вполне естественно, что отрицание этого градиента дает вам направление шага, при котором функция уменьшается быстрее всего.",
  "from_community_srt": "принимая отрицательное значение этого градиента, вы получаете направление на шаг,",
  "n_reviews": 0,
  "start": 459.56,
  "end": 466.04
 },
 {
  "input": "Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is.",
  "translatedText": "Более того, длина этого вектора градиента является показателем того, насколько крутым является самый крутой склон.",
  "from_community_srt": "который быстрее уменьшает функцию и Даже более того, длина этого вектора градиента на самом деле является показателем того, насколько крутым является самый крутой наклон Теперь,",
  "n_reviews": 0,
  "start": 467.24,
  "end": 473.84
 },
 {
  "input": "If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic.",
  "translatedText": "Если вы не знакомы с многомерным исчислением и хотите узнать больше, ознакомьтесь с некоторыми работами, которые я сделал для Академии Хана по этой теме.",
  "from_community_srt": "если вы не знакомы с многовариантным исчислением И вы хотите узнать больше о том, какую часть работы я сделал для Академии Хан по этой теме Честно говоря,",
  "n_reviews": 0,
  "start": 474.54,
  "end": 480.34
 },
 {
  "input": "Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is.",
  "translatedText": "Однако, честно говоря, для нас с вами сейчас важно только то, что в принципе существует способ вычислить этот вектор, этот вектор, который скажет вам, каково направление спуска и насколько он крутой.",
  "from_community_srt": "хотя все, что имеет значение для вас и меня прямо сейчас Это в принципе существует способ вычислить этот вектор. Этот вектор, который сообщает вам, что Наклон вниз, и как круто это будет,",
  "n_reviews": 0,
  "start": 480.86,
  "end": 491.9
 },
 {
  "input": "You'll be okay if that's all you know and you're not rock solid on the details.",
  "translatedText": "Все будет в порядке, если это все, что вы знаете, и вы не очень уверены в деталях.",
  "from_community_srt": "вы будете в порядке, если это все, что вы знаете, и вы не прочны на деталях потому что,",
  "n_reviews": 0,
  "start": 492.4,
  "end": 496.12
 },
 {
  "input": "If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over.",
  "translatedText": "Если вы можете это понять, алгоритм минимизации функции состоит в том, чтобы вычислить это направление градиента, затем сделать небольшой шаг вниз и повторять это снова и снова.",
  "from_community_srt": "если вы можете получить, что алгоритм минимизации функции состоит в том, чтобы вычислить это направление градиента, тогда сделайте небольшой шаг вниз и Просто повторите это снова и снова Это та же основная идея для функции,",
  "n_reviews": 0,
  "start": 497.2,
  "end": 506.74
 },
 {
  "input": "It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs.",
  "translatedText": "Это та же основная идея для функции, которая имеет 13 000 входов вместо двух.",
  "from_community_srt": "которая имеет 13 000 входов вместо двух входов,",
  "n_reviews": 0,
  "start": 507.7,
  "end": 512.82
 },
 {
  "input": "Imagine organizing all 13,000 weights and biases of our network into a giant column vector.",
  "translatedText": "Представьте себе организацию всех 13 000 весов и смещений нашей сети в гигантский вектор-столбец.",
  "from_community_srt": "представляющих собой организацию всего 13 000 весов и смещения нашей сети в гигантский вектор столбца",
  "n_reviews": 0,
  "start": 513.4,
  "end": 519.46
 },
 {
  "input": "The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function.",
  "translatedText": "Отрицательный градиент функции стоимости — это всего лишь вектор, это некоторое направление внутри этого безумно огромного входного пространства, которое подсказывает вам, какое подталкивание всех этих чисел приведет к наиболее быстрому уменьшению функции стоимости.",
  "from_community_srt": "Отрицательным градиентом функции стоимости является только вектор Это какое-то направление в этом безумно огромном пространстве ввода, которое говорит вам, какие подталкивание ко всем этим числам приведет к самому быстрому снижению функции затрат и",
  "n_reviews": 0,
  "start": 520.14,
  "end": 534.88
 },
 {
  "input": "And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make.",
  "translatedText": "И, конечно же, с помощью нашей специально разработанной функции стоимости изменение весов и смещений для уменьшения означает, что выходные данные сети для каждого фрагмента обучающих данных будут выглядеть не как случайный массив из 10 значений, а больше как фактическое решение, которое мы хотим это сделать.",
  "from_community_srt": "конечно, с нашей специально разработанной функцией стоимости Изменение весов и смещений для его уменьшения означает создание выходных данных сети на каждой части данных обучения Похоже, что это случайный массив из десяти значений и больше похоже на фактическое решение, которое мы хотим сделать Важно помнить,",
  "n_reviews": 0,
  "start": 535.64,
  "end": 550.82
 },
 {
  "input": "It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples.",
  "translatedText": "Важно помнить, что эта функция стоимости включает в себя среднее значение по всем обучающим данным, поэтому, если вы ее минимизируете, это означает, что она будет иметь лучшую производительность на всех этих выборках.",
  "from_community_srt": "что эта функция стоимости включает в себя среднее значение по всем данным обучения Поэтому, если вы минимизируете это, это означает,",
  "n_reviews": 0,
  "start": 551.44,
  "end": 561.18
 },
 {
  "input": "The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video.",
  "translatedText": "Алгоритм эффективного расчета этого градиента, который, по сути, является основой обучения нейронной сети, называется обратным распространением ошибки, и именно об этом я собираюсь поговорить в следующем видео.",
  "from_community_srt": "что это лучшая производительность для всех этих образцов Алгоритм для эффективного вычисления этого градиента, который эффективно является сердцем того, как учится нейронная сеть, называется обратным распространением И это то,",
  "n_reviews": 0,
  "start": 563.82,
  "end": 573.98
 },
 {
  "input": "There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas.",
  "translatedText": "Здесь я действительно хочу потратить время на то, чтобы разобраться, что именно происходит с каждым весом и смещением для данного фрагмента тренировочных данных, пытаясь дать интуитивное представление о том, что происходит за пределами кучи соответствующих расчетов и формул.",
  "from_community_srt": "о чем я буду говорить о следующем видео Там я действительно хочу потратить время, чтобы пройти Что именно происходит с каждым весом и каждым смещением для данной части данных обучения? Пытаясь дать интуитивное чувство того, что происходит за кучей соответствующих исчислений и формул Прямо здесь прямо сейчас главное.",
  "n_reviews": 0,
  "start": 574.66,
  "end": 587.1
 },
 {
  "input": "Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function.",
  "translatedText": "Прямо здесь и сейчас главное, что я хочу, чтобы вы знали, независимо от деталей реализации, это то, что, когда мы говорим о сетевом обучении, мы имеем в виду, что оно просто минимизирует функцию стоимости.",
  "from_community_srt": "Я хочу, чтобы вы знали независимо от деталей реализации это то, что мы имеем в виду, когда говорим о сетевом обучении, состоит в том, что это просто минимизирует функцию затрат и Обратите внимание,",
  "n_reviews": 0,
  "start": 587.78,
  "end": 598.36
 },
 {
  "input": "And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill.",
  "translatedText": "И обратите внимание: одним из последствий этого является то, что для этой функции стоимости важно иметь хороший плавный выходной сигнал, чтобы мы могли найти локальный минимум, делая небольшие шаги вниз.",
  "from_community_srt": "что одним из следствий этого является то, что для этой функции затрат важно иметь приятный плавный выход Чтобы мы могли найти локальный минимум,",
  "n_reviews": 0,
  "start": 599.3,
  "end": 608.1
 },
 {
  "input": "This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are.",
  "translatedText": "Вот почему, кстати, искусственные нейроны имеют постоянно меняющуюся активацию, а не просто бинарно активны или неактивны, как биологические нейроны.",
  "from_community_srt": "выполняя небольшие шаги вниз Вот почему, кстати Искусственные нейроны имеют непрерывную активацию,",
  "n_reviews": 0,
  "start": 609.26,
  "end": 619.14
 },
 {
  "input": "This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent.",
  "translatedText": "Этот процесс многократного подталкивания входных данных функции на величину, кратную отрицательному градиенту, называется градиентным спуском.",
  "from_community_srt": "а не просто активную или неактивную в двоичном режиме если способ биологических нейронов Этот процесс многократного подталкивания ввода функции некоторым кратным отрицательного градиента называется градиентным спусканием",
  "n_reviews": 0,
  "start": 620.22,
  "end": 626.76
 },
 {
  "input": "It's a way to converge towards some local minimum of a cost function, basically a valley in this graph.",
  "translatedText": "Это способ приблизиться к некоторому локальному минимуму функции стоимости, по сути, к впадине на этом графике.",
  "from_community_srt": "Это способ сходиться к некоторому локальному минимуму функции стоимости,",
  "n_reviews": 0,
  "start": 627.3,
  "end": 632.58
 },
 {
  "input": "I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this.",
  "translatedText": "Конечно, я все еще показываю изображение функции с двумя входами, потому что подталкивания в 13 000-мерном входном пространстве немного сложно усвоить, но есть хороший непространственный способ подумать об этом.",
  "from_community_srt": "в основном долины на этом графике Я все еще показываю изображение функции с двумя входами, конечно, потому что подталкивает тринадцать тысяч входных данных Пространство немного сложно окутать вокруг,",
  "n_reviews": 0,
  "start": 633.44,
  "end": 644.26
 },
 {
  "input": "Each component of the negative gradient tells us two things.",
  "translatedText": "Каждый компонент отрицательного градиента говорит нам о двух вещах.",
  "from_community_srt": "но на самом деле есть хороший не пространственный способ подумать об этом Каждая компонента отрицательного градиента говорит нам две вещи: знак,",
  "n_reviews": 0,
  "start": 645.08,
  "end": 648.44
 },
 {
  "input": "The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down.",
  "translatedText": "Знак, конечно, говорит нам, следует ли сдвинуть соответствующий компонент входного вектора вверх или вниз.",
  "from_community_srt": "конечно, говорит нам, соответствует ли соответствующая Компонент входного вектора должен подталкиваться вверх или вниз,",
  "n_reviews": 0,
  "start": 649.06,
  "end": 655.14
 },
 {
  "input": "But importantly, the relative magnitudes of all these components kind of tells you which changes matter more.",
  "translatedText": "Но что немаловажно, относительные величины всех этих компонентов подскажут вам, какие изменения имеют большее значение.",
  "from_community_srt": "но важно относительные величины всех этих компонентов Какие из вас рассказывают,",
  "n_reviews": 0,
  "start": 655.8,
  "end": 662.72
 },
 {
  "input": "You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight.",
  "translatedText": "Видите ли, в нашей сети корректировка одного из весов может оказать гораздо большее влияние на функцию стоимости, чем корректировка какого-либо другого веса.",
  "from_community_srt": "какие изменения важны Вы видите, что в нашей сети настройка на один из весов может быть намного больше влияние на функцию стоимости,",
  "n_reviews": 0,
  "start": 665.22,
  "end": 673.04
 },
 {
  "input": "Some of these connections just matter more for our training data.",
  "translatedText": "Некоторые из этих связей имеют большее значение для наших тренировочных данных.",
  "from_community_srt": "чем корректировка на какой-либо другой вес Некоторые из этих соединений имеют большее значение для наших данных обучения",
  "n_reviews": 0,
  "start": 674.8,
  "end": 678.2
 },
 {
  "input": "So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck.",
  "translatedText": "Таким образом, вы можете думать об этом градиентном векторе нашей ошеломляюще массивной функции затрат так, что он кодирует относительную важность каждого веса и смещения, то есть какое из этих изменений принесет наибольшую отдачу от вложенных средств.",
  "from_community_srt": "Таким образом, вы можете думать об этом градиентном векторе нашего разума массивная функция затрат заключается в том, что она кодирует относительную важность каждого веса и смещения То есть,",
  "n_reviews": 0,
  "start": 679.32,
  "end": 692.4
 },
 {
  "input": "This really is just another way of thinking about direction.",
  "translatedText": "На самом деле это просто еще один способ мышления о направлении.",
  "from_community_srt": "какие из этих изменений будут нести наибольший удар для вашего доллара Это действительно еще один способ задуматься о направлении",
  "n_reviews": 0,
  "start": 693.62,
  "end": 696.64
 },
 {
  "input": "To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction.",
  "translatedText": "Возьмем более простой пример: если у вас есть некоторая функция с двумя переменными в качестве входных данных, и вы вычисляете, что ее градиент в какой-то конкретной точке равен 3,1, то, с одной стороны, вы можете интерпретировать это как утверждение, что когда вы Если вы стоите на этом входе, движение в этом направлении быстрее всего увеличивает функцию: когда вы строите график функции над плоскостью входных точек, этот вектор дает вам прямое направление в гору.",
  "from_community_srt": "Чтобы взять более простой пример, если у вас есть функция с двумя переменными в качестве ввода, и вы Вычислите, что его градиент в какой-то конкретной точке выражается как (3,1) Затем, с одной стороны, вы можете интерпретировать это, говоря, что, когда вы стоите на этом входе движение по этому направлению быстрее увеличивает функцию То, что, когда вы рисуете функцию над плоскостью входных точек, этот вектор является тем,",
  "n_reviews": 0,
  "start": 697.1,
  "end": 722.26
 },
 {
  "input": "But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck.",
  "translatedText": "Но другой способ понять это — сказать, что изменения в этой первой переменной имеют в 3 раза большую важность, чем изменения во второй переменной, что, по крайней мере, вблизи соответствующего входного значения, подталкивание значения x несет гораздо большую пользу для вашего бакс.",
  "from_community_srt": "что дает вам прямое направление в гору Но еще один способ прочитать это - сказать, что изменения этой первой переменной В три раза важны изменения во второй переменной, по крайней мере, в окрестности соответствующего ввода Подталкивание значения x несет намного больший удар для вашего доллара",
  "n_reviews": 0,
  "start": 722.86,
  "end": 736.9
 },
 {
  "input": "Let's zoom out and sum up where we are so far.",
  "translatedText": "Давайте уменьшим масштаб и подведем итоги того, где мы находимся на данный момент.",
  "from_community_srt": "Отлично Давайте уменьшим масштаб и подведем итог,",
  "n_reviews": 0,
  "start": 739.88,
  "end": 742.34
 },
 {
  "input": "The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums.",
  "translatedText": "Сама сеть представляет собой эту функцию с 784 входами и 10 выходами, определяемыми через все эти взвешенные суммы.",
  "from_community_srt": "где мы находимся до сих пор, самой сетью является эта функция с 784 входа и 10 выходов,",
  "n_reviews": 0,
  "start": 742.84,
  "end": 750.04
 },
 {
  "input": "The cost function is a layer of complexity on top of that.",
  "translatedText": "Функция стоимости представляет собой еще один уровень сложности.",
  "from_community_srt": "определенных в терминах всех этих взвешенных сумм функция стоимости представляет собой слой сложности,",
  "n_reviews": 0,
  "start": 750.64,
  "end": 753.68
 },
 {
  "input": "It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples.",
  "translatedText": "Он принимает 13 000 весов и смещений в качестве входных данных и выдает единственную меру неудачи на основе обучающих примеров.",
  "from_community_srt": "поверх которого он принимает 13 000 весов и предубеждений в качестве исходных данных и выплескивают одну меру паршивости на основе примеров обучения и",
  "n_reviews": 0,
  "start": 753.98,
  "end": 761.72
 },
 {
  "input": "And the gradient of the cost function is one more layer of complexity still.",
  "translatedText": "И градиент функции стоимости — это еще один уровень сложности.",
  "from_community_srt": "Градиент функции стоимости - еще один уровень сложности,",
  "n_reviews": 0,
  "start": 762.44,
  "end": 766.9
 },
 {
  "input": "It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most.",
  "translatedText": "Он говорит нам, какие подталкивания ко всем этим весам и отклонениям вызывают наиболее быстрое изменение значения функции стоимости, что можно интерпретировать как указание того, какие изменения в каких весах имеют наибольшее значение.",
  "from_community_srt": "который все еще говорит нам То, что подталкивает все эти веса и предубеждения, вызывают самое быстрое изменение стоимости функции затрат Который вы могли бы интерпретировать, говорит, какие изменения,",
  "n_reviews": 0,
  "start": 767.36,
  "end": 777.88
 },
 {
  "input": "So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before?",
  "translatedText": "Итак, когда вы инициализируете сеть со случайными весами и смещениями и много раз настраиваете их на основе этого процесса градиентного спуска, насколько хорошо она на самом деле работает с изображениями, которых она никогда раньше не видела?",
  "from_community_srt": "вес которых имеет наибольшее значение Поэтому, когда вы инициализируете сеть со случайными весами и смещениями и настраиваете их много раз на основе этого процесса спуска градиента Насколько хорошо он работает на изображениях, которых он никогда не видел? Ну,",
  "n_reviews": 0,
  "start": 782.56,
  "end": 793.2
 },
 {
  "input": "The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly.",
  "translatedText": "Тот, который я описал здесь, с двумя скрытыми слоями по 16 нейронов в каждом, выбранными в основном из эстетических соображений, неплохой, правильно классифицируя около 96% новых изображений, которые он видит.",
  "from_community_srt": "тот, который я описал здесь, с двумя скрытыми слоями из шестнадцати нейронов, каждый из которых выбран в основном по эстетическим соображениям ну, неплохо, что он классифицирует около 96 процентов новых изображений, которые он видит правильно,",
  "n_reviews": 0,
  "start": 794.1,
  "end": 805.96
 },
 {
  "input": "And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack.",
  "translatedText": "И, честно говоря, если вы посмотрите на некоторые примеры, в которых он дает сбой, вы почувствуете необходимость немного ослабить его.",
  "from_community_srt": "и Честно говоря, если вы посмотрите на некоторые примеры,",
  "n_reviews": 0,
  "start": 806.68,
  "end": 812.54
 },
 {
  "input": "Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%.",
  "translatedText": "Теперь, если вы поиграете со структурой скрытых слоев и сделаете пару настроек, вы сможете получить до 98%.",
  "from_community_srt": "из-за которых вы чувствуете себя вынужденным немного порезать Теперь, если вы играете со скрытой структурой слоя и делаете пару настроек Вы можете получить это до 98%,",
  "n_reviews": 0,
  "start": 816.22,
  "end": 821.76
 },
 {
  "input": "And that's pretty good!",
  "translatedText": "И это очень хорошо!",
  "from_community_srt": "и это очень хорошо.",
  "n_reviews": 0,
  "start": 821.76,
  "end": 822.72
 },
 {
  "input": "It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for.",
  "translatedText": "Это не самое лучшее решение, вы, конечно, можете добиться большей производительности, если станете более сложной, чем эта простая ванильная сеть, но, учитывая, насколько сложной является первоначальная задача, я думаю, что есть что-то невероятное в том, что любая сеть так хорошо справляется с изображениями, которые она никогда раньше не видела, учитывая, что мы никогда специально не говорили ему, какие закономерности искать.",
  "from_community_srt": "Это не лучший Вы, безусловно, можете получить лучшую производительность, получив более сложную, чем эта простая ванильная сеть Но учитывая, насколько сложной является первоначальная задача, я просто думаю, что есть что-то? Невероятно, что любая сеть делает это хорошо на изображениях, которые никогда не видели раньше Учитывая, что мы никогда конкретно не говорили,",
  "n_reviews": 0,
  "start": 823.02,
  "end": 841.42
 },
 {
  "input": "Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits.",
  "translatedText": "Первоначально я мотивировал эту структуру, описывая нашу надежду на то, что второй слой сможет улавливать маленькие ребра, что третий слой будет соединять эти ребра, чтобы распознавать петли и более длинные линии, и что их можно будет соединить. вместе, чтобы распознавать цифры.",
  "from_community_srt": "какие шаблоны искать Первоначально я мотивировал эту структуру, описывая надежду на то, что у нас могут быть То, что второй слой может зацепиться за небольшие края Чтобы третий слой скомпоновал эти края для распознавания петель и более длинных строк и чтобы их можно было собрать вместе, чтобы распознавать цифры Так это то,",
  "n_reviews": 0,
  "start": 842.56,
  "end": 857.18
 },
 {
  "input": "So is this what our network is actually doing?",
  "translatedText": "Так действительно ли этим занимается наша сеть?",
  "from_community_srt": "что наша сеть на самом деле делает?",
  "n_reviews": 0,
  "start": 857.96,
  "end": 860.4
 },
 {
  "input": "Well, for this one at least, not at all.",
  "translatedText": "Ну, по крайней мере, для этого, совсем нет.",
  "from_community_srt": "Хорошо для этого, по крайней мере, Не за что",
  "n_reviews": 0,
  "start": 861.08,
  "end": 864.4
 },
 {
  "input": "Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on?",
  "translatedText": "Помните, как в прошлом видео мы рассматривали, как веса связей всех нейронов первого слоя с данным нейроном второго слоя можно визуализировать как заданный шаблон пикселей, который улавливает нейрон второго слоя?",
  "from_community_srt": "помните, как в последнем видео мы смотрели, как весы Соединения от всех нейронов в первом слое к данному нейрону во втором слое Может быть визуализирован как заданный шаблон пикселя, который нейрон второго слоя набирает Хорошо,",
  "n_reviews": 0,
  "start": 864.82,
  "end": 877.06
 },
 {
  "input": "Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there.",
  "translatedText": "Что ж, когда мы на самом деле делаем это для весов, связанных с этими переходами, от первого слоя к следующему, вместо того, чтобы собирать отдельные маленькие ребра здесь и там, они выглядят почти случайными, просто с некоторыми очень свободными шаблонами в середина там.",
  "from_community_srt": "когда мы на самом деле делаем это для весов, связанных с этими переходами от первого уровня к следующему Вместо того, чтобы собираться на изолированных маленьких краях здесь и там. Они хорошо выглядят почти случайными Просто положите некоторые очень свободные шаблоны в середине,",
  "n_reviews": 0,
  "start": 877.78,
  "end": 893.68
 },
 {
  "input": "It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for.",
  "translatedText": "Казалось бы, в непостижимо большом 13 000-мерном пространстве возможных весов и смещений наша сеть обнаружила счастливый маленький локальный минимум, который, несмотря на успешную классификацию большинства изображений, не совсем уловил закономерности, на которые мы могли надеяться.",
  "from_community_srt": "казалось бы, что в необъяснимо больших 13 000-мерное пространство возможных весов и уклонов, наша сеть оказалась очень маленьким локальным минимумом, несмотря на успешную классификацию большинства изображений, точно не подбирают шаблоны, на которые мы могли надеяться,",
  "n_reviews": 0,
  "start": 893.76,
  "end": 908.96
 },
 {
  "input": "And to really drive this point home, watch what happens when you input a random image.",
  "translatedText": "И чтобы по-настоящему понять эту мысль, посмотрите, что происходит, когда вы вводите случайное изображение.",
  "from_community_srt": "и Чтобы действительно управлять этой точкой дома, смотрите, что происходит, когда вы вводите случайное изображение если бы система была умной,",
  "n_reviews": 0,
  "start": 909.78,
  "end": 913.82
 },
 {
  "input": "If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5.",
  "translatedText": "Если бы система была умной, вы могли бы ожидать, что она будет чувствовать себя неуверенно, возможно, на самом деле не активирует ни один из этих 10 выходных нейронов или не активирует их все равномерно, но вместо этого она уверенно дает вам какой-то бессмысленный ответ, как если бы она чувствовала себя настолько же уверенным, что этот случайный шум это 5, так же как и фактическое изображение 5 — это 5.",
  "from_community_srt": "вы могли бы ожидать, что она либо почувствует неопределенность, может быть, не активирует ни один из этих 10 выходных нейронов или Активация их всех равномерно Но вместо этого Уверенно дает вам какой-то бессмысленный ответ, как будто он чувствует себя уверенным, что этот случайный шум равен 5, так как он действительно образ 5 - это 5 фразу по-разному,",
  "n_reviews": 0,
  "start": 914.32,
  "end": 934.16
 },
 {
  "input": "Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them.",
  "translatedText": "Другими словами, даже если эта сеть довольно хорошо распознает цифры, она понятия не имеет, как их рисовать.",
  "from_community_srt": "даже если эта сеть может распознавать цифры довольно хорошо, она не знает,",
  "n_reviews": 0,
  "start": 934.54,
  "end": 940.7
 },
 {
  "input": "A lot of this is because it's such a tightly constrained training setup.",
  "translatedText": "Во многом это связано с тем, что это очень жестко ограниченная система тренировок.",
  "from_community_srt": "как их привлечь Это связано с тем,",
  "n_reviews": 0,
  "start": 941.42,
  "end": 945.24
 },
 {
  "input": "I mean, put yourself in the network's shoes here.",
  "translatedText": "Я имею в виду, поставьте себя на место сети.",
  "from_community_srt": "что это такая строго ограниченная тренировочная установка Я имею в виду поставить себя в туфли сети здесь,",
  "n_reviews": 0,
  "start": 945.88,
  "end": 947.74
 },
 {
  "input": "From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions.",
  "translatedText": "С ее точки зрения, вся Вселенная состоит только из четко определенных неподвижных цифр, сосредоточенных в крошечной сетке, и ее функция стоимости никогда не давала ей никаких стимулов быть чем-то иным, кроме полной уверенности в своих решениях.",
  "from_community_srt": "с его точки зрения, вся вселенная состоит из ничего Но четко определенные неподвижные цифры, сосредоточенные в крошечной сетке, и ее функция стоимости просто никогда не давали ей Стимулирование быть чем угодно, но совершенно уверенно в своих решениях Итак,",
  "n_reviews": 0,
  "start": 948.14,
  "end": 961.08
 },
 {
  "input": "So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns.",
  "translatedText": "Итак, учитывая то, что на самом деле делают нейроны второго слоя, вы можете задаться вопросом, почему я представил эту сеть с мотивацией улавливать края и закономерности.",
  "from_community_srt": "если это изображение того, что действительно делают эти нейроны второго слоя Вы можете задаться вопросом, почему я бы представил эту сеть с мотивацией собирать по краям и узорам Я имею в виду,",
  "n_reviews": 0,
  "start": 962.12,
  "end": 969.92
 },
 {
  "input": "I mean, that's just not at all what it ends up doing.",
  "translatedText": "Я имею в виду, что в конечном итоге это совсем не то.",
  "from_community_srt": "это совсем не то, что заканчивается Ну,",
  "n_reviews": 0,
  "start": 969.92,
  "end": 972.3
 },
 {
  "input": "Well, this is not meant to be our end goal, but instead a starting point.",
  "translatedText": "Что ж, это не наша конечная цель, а отправная точка.",
  "from_community_srt": "это не значит быть нашей конечной целью,",
  "n_reviews": 0,
  "start": 973.38,
  "end": 977.18
 },
 {
  "input": "Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems.",
  "translatedText": "Честно говоря, это старая технология, исследованная в 80-х и 90-х годах, и вам нужно понять ее, прежде чем вы сможете понять более подробные современные варианты, и она явно способна решать некоторые интересные проблемы, но чем больше вы копаетесь в том, что эти скрытые слои действительно работают, тем менее разумным это кажется.",
  "from_community_srt": "но вместо этого отправной точкой откровенно Это старая технология вид, исследованный в 80-х и 90-х годах и Вам нужно понять это, прежде чем вы сможете понять более подробные современные варианты, и это, безусловно, способно решить некоторые интересные проблемы Но чем больше вы вникаете в то,",
  "n_reviews": 0,
  "start": 977.64,
  "end": 994.74
 },
 {
  "input": "Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow.",
  "translatedText": "Если на мгновение сместить фокус с того, как сети учатся, на то, как вы учитесь, это произойдет только в том случае, если вы каким-то образом активно будете изучать материал здесь.",
  "from_community_srt": "что эти скрытые слои действительно делают менее умным, Переход на какой-то момент с того, как сети узнают, как вы учитесь Это произойдет только в том случае, если вы будете активно участвовать в этом материале здесь Одна довольно простая вещь,",
  "n_reviews": 0,
  "start": 998.48,
  "end": 1006.3
 },
 {
  "input": "One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns.",
  "translatedText": "Я хочу, чтобы вы сделали одну довольно простую вещь: просто сделайте паузу прямо сейчас и на мгновение глубоко задумайтесь о том, какие изменения вы могли бы внести в эту систему и о том, как она воспринимает изображения, если вы хотите, чтобы она лучше улавливала такие вещи, как края и узоры.",
  "from_community_srt": "которую я хочу, чтобы вы сделали, это просто приостановить прямо сейчас и задуматься на мгновение о том, что Изменения, которые вы могли бы внести в эту систему И как он воспринимает образы, если вы хотите, чтобы он лучше воспринимал такие вещи,",
  "n_reviews": 0,
  "start": 1007.06,
  "end": 1020.88
 },
 {
  "input": "But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks.",
  "translatedText": "Но более того, чтобы по-настоящему углубиться в материал, я настоятельно рекомендую книгу Майкла Нильсена о глубоком обучении и нейронных сетях.",
  "from_community_srt": "как ребра и узоры? Но лучше, чем фактически заниматься материалом я Очень рекомендую книгу Майкла Нильсена по глубокому обучению и нейронным сетям",
  "n_reviews": 0,
  "start": 1021.48,
  "end": 1029.1
 },
 {
  "input": "In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing.",
  "translatedText": "В ней вы можете найти код и данные для загрузки и воспроизведения именно для этого примера, и книга шаг за шагом проведет вас через то, что делает этот код.",
  "from_community_srt": "В нем вы можете найти код и данные для загрузки и воспроизведения для этого точного примера И книга проведет вас шаг за шагом, что делает этот код Что удивительно в том,",
  "n_reviews": 0,
  "start": 1029.68,
  "end": 1038.36
 },
 {
  "input": "What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts.",
  "translatedText": "Что удивительно, так это то, что эта книга бесплатна и общедоступна, поэтому, если вы что-то из нее получите, подумайте о том, чтобы присоединиться ко мне и сделать пожертвование на усилия Нильсена.",
  "from_community_srt": "что эта книга является бесплатной и общедоступной Поэтому, если вы что-то извлечете из этого, подумайте о том, чтобы присоединиться ко мне,",
  "n_reviews": 0,
  "start": 1039.3,
  "end": 1047.66
 },
 {
  "input": "I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill.",
  "translatedText": "Я также связал в описании пару других ресурсов, которые мне очень нравятся, в том числе феноменальный и красивый пост в блоге Криса Олы и статьи в Distill.",
  "from_community_srt": "чтобы пожертвовать на усилия Нильсена Я также связал пару других ресурсов, которые мне очень нравятся в описании, включая феноменальный и красивый пост в блоге Криса Олы и статьи в дистилляции Чтобы закрыть все здесь в течение последних нескольких минут",
  "n_reviews": 0,
  "start": 1047.66,
  "end": 1056.5
 },
 {
  "input": "To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee.",
  "translatedText": "Чтобы закончить на последние несколько минут, я хочу вернуться к фрагменту интервью, которое я дал Лейше Ли.",
  "from_community_srt": "Я хочу вернуться к фрагменту интервью,",
  "n_reviews": 0,
  "start": 1058.28,
  "end": 1063.88
 },
 {
  "input": "You might remember her from the last video, she did her PhD work in deep learning.",
  "translatedText": "Возможно, вы помните ее по последнему видео: она защитила докторскую диссертацию в области глубокого обучения.",
  "from_community_srt": "которое у меня было с Лейшей Ли Вы можете вспомнить ее из последнего видео.",
  "n_reviews": 0,
  "start": 1064.3,
  "end": 1067.72
 },
 {
  "input": "In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning.",
  "translatedText": "В этом небольшом отрывке она рассказывает о двух недавних статьях, в которых действительно изучается, как на самом деле обучаются некоторые из более современных сетей распознавания изображений.",
  "from_community_srt": "Она занималась своей докторской работой в глубоком обучении и в этом маленьком фрагменте Она рассказывает о двух последних документах, которые действительно копаются в том, как некоторые из более современных сетей распознавания образов фактически учатся Просто чтобы настроить,",
  "n_reviews": 0,
  "start": 1068.3,
  "end": 1075.78
 },
 {
  "input": "Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training.",
  "translatedText": "Чтобы понять, на каком этапе разговора мы находимся, в первой статье была взята одна из этих особенно глубоких нейронных сетей, которая действительно хороша в распознавании изображений, и вместо обучения ее на правильно размеченном наборе данных перед обучением перетасованы все метки.",
  "from_community_srt": "где мы были в разговоре, первая работа взяла одну из этих особенно глубоких нейронных сетей Это действительно хорошо для распознавания образов и вместо того, чтобы обучать его соответствующим образом помеченным данным Установите его, чтобы перетасовать все ярлыки перед тренировкой Очевидно,",
  "n_reviews": 0,
  "start": 1076.12,
  "end": 1088.74
 },
 {
  "input": "Obviously the testing accuracy here was no better than random, since everything is just randomly labeled, but it was still able to achieve the same training accuracy as you would on a properly labeled dataset.",
  "translatedText": "Очевидно, что точность тестирования здесь была не лучше, чем случайная, поскольку все помечено случайным образом, но все равно удалось достичь той же точности обучения, что и на правильно маркированном наборе данных.",
  "from_community_srt": "что точность тестирования здесь не лучше, чем случайная, поскольку все просто случайно помечено Но он все еще мог достичь такой же точности обучения,",
  "n_reviews": 0,
  "start": 1089.48,
  "end": 1100.88
 },
 {
  "input": "Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization?",
  "translatedText": "По сути, миллионов весов для этой конкретной сети было достаточно, чтобы она просто запомнила случайные данные, что поднимает вопрос, действительно ли минимизация этой функции стоимости соответствует какой-либо структуре изображения или это просто запоминание?",
  "from_community_srt": "как и для правильно маркированного набора данных В основном миллионы весов для этой конкретной сети были достаточными для того, чтобы просто запомнить случайные данные Какой вопрос поднимает вопрос о том, действительно ли минимизация этой функции стоимости соответствует какой-либо структуре изображения? Или это просто ты знаешь? запомнить все",
  "n_reviews": 0,
  "start": 1101.6,
  "end": 1116.4
 },
 {
  "input": "If you look at that accuracy curve, if you were just training on a random dataset, that curve sort of went down very slowly in almost kind of a linear fashion, so you're really struggling to find that local minima of possible, you know, the right weights that would get you that accuracy.",
  "translatedText": "Если вы посмотрите на эту кривую точности, если бы вы просто тренировались на случайном наборе данных, эта кривая как бы снижалась очень медленно, почти линейно, так что вы действительно изо всех сил пытаетесь найти этот локальный минимум возможных, вы знаете , правильные веса, которые обеспечат вам такую точность.",
  "from_community_srt": "Набор данных о том, какова правильная классификация, и поэтому пара из вас знает полгода спустя в ICML в этом году Не было точно отформатированной бумажной бумаги, которая обращалась к некоторым из них: Фактически, эти сети делают что-то немного умнее, если вы посмотрите на эту кривую точности если вы просто тренировались на Случайные данные показывают, что тип кривой спустился очень точно, вы знаете очень медленно почти линейным способом Таким образом, вы действительно пытаетесь найти, что местные минимумы возможных вы знаете правильные веса, которые доставят вам такую ​​точность,",
  "n_reviews": 0,
  "start": 1131.44,
  "end": 1152.14
 },
 {
  "input": "Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima.",
  "translatedText": "В то время как, если вы на самом деле тренируетесь на структурированном наборе данных, который имеет правильные метки, вначале вы немного повозитесь, но затем вы как бы очень быстро падаете, чтобы добраться до этого уровня точности, и поэтому в некотором смысле это было легче найти эти локальные максимумы.",
  "from_community_srt": "тогда как если вы действительно тренируетесь по структурированному набору данных, который имеет Правые этикетки. Вы знаете, что вы немного заиграли в начале, но потом вы очень быстро упали, чтобы добраться до этого Уровень точности и, следовательно, в каком-то смысле было легче найти, что Местные максимумы,",
  "n_reviews": 0,
  "start": 1152.24,
  "end": 1168.22
 },
 {
  "input": "And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily.",
  "translatedText": "И что еще было интересно в этом, так это то, что это проливает свет на еще одну статью, написанную пару лет назад, в которой гораздо больше упрощений в отношении сетевых уровней, но в одном из результатов говорилось, что, если вы посмотрите на ландшафт оптимизации, локальные минимумы, которые эти сети обычно изучают, на самом деле имеют одинаковое качество, поэтому в некотором смысле, если ваш набор данных структурирован, вам будет гораздо легче найти его.",
  "from_community_srt": "и поэтому было интересно также, что это поймано, приносит в свет другую бумагу от фактически пару лет назад У чего намного больше упрощения сетевых уровней Но один из результатов заключался в том, что, если вы посмотрите на оптимизационный ландшафт, то локальные минимумы, которые эти сети имеют тенденцию изучать, Фактически с равным качеством, поэтому в некотором смысле, если ваш набор данных является структурой,",
  "n_reviews": 0,
  "start": 1168.54,
  "end": 1194.32
 },
 {
  "input": "My thanks, as always, to those of you supporting on Patreon.",
  "translatedText": "Моя благодарность, как всегда, тем из вас, кто поддерживает Patreon.",
  "from_community_srt": "и вы должны быть в состоянии найти это намного проще Моя благодарность, как всегда, тем, кто поддерживает вас на patreon Я уже говорил,",
  "n_reviews": 0,
  "start": 1198.16,
  "end": 1201.18
 },
 {
  "input": "I've said before just what a game changer Patreon is, but these videos really would not be possible without you.",
  "translatedText": "Я уже говорил, что меняет правила игры Патреон, но эти видео действительно были бы невозможны без вас.",
  "from_community_srt": "что это только что созданный игровой чейнджер, но эти видео действительно не будут возможны без тебя.",
  "n_reviews": 0,
  "start": 1201.52,
  "end": 1206.8
 },
 {
  "input": "I also want to give a special thanks to the VC firm Amplify Partners, in their support of these initial videos in the series.",
  "translatedText": "Я также хочу выразить особую благодарность венчурной фирме Amplify Partners за поддержку этих первых видеороликов из этой серии.",
  "from_community_srt": "Также хочу дать специальный. Благодаря партнерам VC фирмы amplifi в поддержке этих первых видеороликов в серии",
  "n_reviews": 0,
  "start": 1207.46,
  "end": 1212.78
 }
]