[
 {
  "input": "Last video I laid out the structure of a neural network.",
  "translatedText": "No último vídeo expus a estrutura de uma rede neural.",
  "model": "google_nmt",
  "from_community_srt": "No último vídeo, eu mostrei a estrutura de uma rede neural.",
  "n_reviews": 0,
  "start": 4.18,
  "end": 7.28
 },
 {
  "input": "I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video.",
  "translatedText": "Farei uma rápida recapitulação aqui para que fique fresco em nossas mentes, e então tenho dois objetivos principais para este vídeo.",
  "model": "google_nmt",
  "from_community_srt": "Vou dar uma rápida recapitulação aqui, só para que esteja fresco na mente. E vou ter dois objetivos para este vídeo.",
  "n_reviews": 0,
  "start": 7.68,
  "end": 12.6
 },
 {
  "input": "The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well.",
  "translatedText": "A primeira é introduzir a ideia de descida gradiente, que fundamenta não apenas o modo como as redes neurais aprendem, mas também como muitos outros aprendizados de máquina funcionam.",
  "model": "google_nmt",
  "from_community_srt": "O primeiro é apresentar a ideia da descida do gradiente, que está por traz não só de como as redes neurais aprendem, mas também de como funcionam muitos outros aprendizados de máquina.",
  "n_reviews": 0,
  "start": 13.1,
  "end": 20.6
 },
 {
  "input": "Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for.",
  "translatedText": "Depois disso, vamos nos aprofundar um pouco mais no desempenho dessa rede específica e no que essas camadas ocultas de neurônios acabam procurando.",
  "model": "google_nmt",
  "from_community_srt": "Então, depois disso, vamos nos aprofundar um pouco mais sobre como esta rede específica age e o que aquelas camadas ocultas de neurônios acabam procurando.",
  "n_reviews": 0,
  "start": 21.12,
  "end": 27.94
 },
 {
  "input": "As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks.",
  "translatedText": "Como lembrete, nosso objetivo aqui é o exemplo clássico de reconhecimento de dígitos manuscritos, o olá mundo das redes neurais.",
  "model": "google_nmt",
  "from_community_srt": "Como lembrete, nosso objetivo é o exemplo clássico do reconhecimento de dígitos manuscritos, o \"Olá, mundo!\" das redes neurais.",
  "n_reviews": 0,
  "start": 28.98,
  "end": 36.22
 },
 {
  "input": "These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1.",
  "translatedText": "Esses dígitos são renderizados em uma grade de 28x28 pixels, cada pixel com algum valor de escala de cinza entre 0 e 1.",
  "model": "google_nmt",
  "from_community_srt": "Esses dígitos são renderizados numa grade de pixels de 28x28, tendo cada pixel um valor de nível de cinza entre 0 e 1.",
  "n_reviews": 0,
  "start": 37.02,
  "end": 43.42
 },
 {
  "input": "Those are what determine the activations of 784 neurons in the input layer of the network.",
  "translatedText": "São eles que determinam as ativações de 784 neurônios na camada de entrada da rede.",
  "model": "google_nmt",
  "from_community_srt": "Isso determina as ativações de 784 neurônios na camada de entrada da rede.",
  "n_reviews": 0,
  "start": 43.82,
  "end": 50.04
 },
 {
  "input": "And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias.",
  "translatedText": "E então a ativação de cada neurônio nas camadas seguintes é baseada em uma soma ponderada de todas as ativações na camada anterior, mais algum número especial chamado polarização.",
  "model": "google_nmt",
  "from_community_srt": "E ativação para cada neurônio nas camadas seguintes é baseada numa soma ponderada de todas as ativações na camada anterior mais um número especial chamado viés.",
  "n_reviews": 0,
  "start": 51.18,
  "end": 60.82
 },
 {
  "input": "Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video.",
  "translatedText": "Então você compõe essa soma com alguma outra função, como o esmagamento sigmóide, ou um relu, como mostrei no último vídeo.",
  "model": "google_nmt",
  "from_community_srt": "Então, você compõe essa soma com outra função, como a sigmóide ou a ReLu, como mostrei no último vídeo.",
  "n_reviews": 0,
  "start": 62.16,
  "end": 68.94
 },
 {
  "input": "In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does.",
  "translatedText": "No total, dada a escolha um tanto arbitrária de duas camadas ocultas com 16 neurônios cada, a rede tem cerca de 13.000 pesos e tendências que podemos ajustar, e são esses valores que determinam exatamente o que a rede realmente faz.",
  "model": "google_nmt",
  "from_community_srt": "No total, dada a escolha meio arbitrária de duas camadas ocultas com 16 neurônios cada, a rede tem cerca de 13 mil pesos e vieses que podemos ajustar, e são esses valores que determinam o que exatamente a rede faz.",
  "n_reviews": 0,
  "start": 69.48,
  "end": 84.38
 },
 {
  "input": "Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit.",
  "translatedText": "Então o que queremos dizer quando dizemos que esta rede classifica um determinado dígito é que o mais brilhante desses 10 neurônios na camada final corresponde a esse dígito.",
  "model": "google_nmt",
  "from_community_srt": "Então, quando dizemos que esta rede classifica um dado dígito, queremos dizer que o mais brilhante dos 10 neurônios na camada final corresponde àquele dígito.",
  "n_reviews": 0,
  "start": 84.88,
  "end": 93.3
 },
 {
  "input": "And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits.",
  "translatedText": "E lembre-se, a motivação que tínhamos em mente aqui para a estrutura em camadas era que talvez a segunda camada pudesse captar as bordas, e a terceira camada pudesse captar padrões como loops e linhas, e a última poderia simplesmente juntar essas peças. padrões para reconhecer dígitos.",
  "model": "google_nmt",
  "from_community_srt": "E lembre-se da motivação que tínhamos para a estrutura em camadas: talvez a segunda camada pudesse detectar as bordas, a terceira camada pudesse detectar padrões como círculos e linhas e a última pudesse unir esses padrões para reconhecer dígitos.",
  "n_reviews": 0,
  "start": 94.1,
  "end": 108.8
 },
 {
  "input": "So here, we learn how the network learns.",
  "translatedText": "Então aqui aprendemos como a rede aprende.",
  "model": "google_nmt",
  "from_community_srt": "Então, aqui aprendemos como a rede aprende.",
  "n_reviews": 0,
  "start": 109.8,
  "end": 112.24
 },
 {
  "input": "What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data.",
  "translatedText": "O que queremos é um algoritmo onde você possa mostrar a esta rede um monte de dados de treinamento, que vêm na forma de um monte de imagens diferentes de dígitos manuscritos, junto com rótulos para o que deveriam ser, e isso vai ajuste esses 13.000 pesos e tendências para melhorar seu desempenho nos dados de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Queremos um algoritmo no qual você possa mostrar a esta rede um monte de dados de treinamento que vêm na forma de um monte de imagens diferentes de dígitos manuscritos, junto com rótulos para o que eles devem ser, e ela ajustará esses 13 mil pesos e vieses para melhorar seu desempenho nos dados de treinamento.",
  "n_reviews": 0,
  "start": 112.64,
  "end": 130.12
 },
 {
  "input": "Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data.",
  "translatedText": "Esperançosamente, essa estrutura em camadas significará que o que ela aprende será generalizado para imagens além dos dados de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Espera-se que esta estrutura em camadas signifique que o que foi aprendido se generaliza para imagens além desses dados de treinamento.",
  "n_reviews": 0,
  "start": 130.72,
  "end": 136.86
 },
 {
  "input": "The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images.",
  "translatedText": "A maneira como testamos isso é que, depois de treinar a rede, você mostra a ela mais dados rotulados que nunca foram vistos antes e vê com que precisão ela classifica essas novas imagens.",
  "model": "google_nmt",
  "from_community_srt": "E testamos isso, após treinar a rede, mostrando a ela mais dados rotulados que ela nunca tenha visto. E vemos com que precisão ela classifica essas novas imagens.",
  "n_reviews": 0,
  "start": 137.64,
  "end": 146.7
 },
 {
  "input": "Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be.",
  "translatedText": "Felizmente para nós, e o que torna este um exemplo tão comum para começar, é que as boas pessoas por trás do banco de dados MNIST reuniram uma coleção de dezenas de milhares de imagens de dígitos manuscritas, cada uma rotulada com os números que deveriam ser.",
  "model": "google_nmt",
  "from_community_srt": "Felizmente (e isto que torna este exemplo tão comum para começar), a gente boa por trás do banco de dados MNIST reuniu uma coleção de dezenas de milhares de imagens manuscritas de dígitos, cada uma rotulada com o seu número.",
  "n_reviews": 0,
  "start": 151.12,
  "end": 164.2
 },
 {
  "input": "And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise.",
  "translatedText": "E por mais provocativo que seja descrever uma máquina como aprendizagem, quando você vê como ela funciona, parece muito menos uma premissa maluca de ficção científica e muito mais um exercício de cálculo.",
  "model": "google_nmt",
  "from_community_srt": "E por mais provocante que seja descrever uma máquina como aprendendo, quando você vê como funciona, parece muito menos com uma premissa doida de ficção científica, e muito mais com um exercício de cálculo.",
  "n_reviews": 0,
  "start": 164.9,
  "end": 175.48
 },
 {
  "input": "I mean, basically it comes down to finding the minimum of a certain function.",
  "translatedText": "Quero dizer, basicamente se trata de encontrar o mínimo de uma determinada função.",
  "model": "google_nmt",
  "from_community_srt": "Basicamente, se resume a achar o mínimo de certa função.",
  "n_reviews": 0,
  "start": 176.2,
  "end": 179.96
 },
 {
  "input": "Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
  "translatedText": "Lembre-se, conceitualmente, estamos pensando em cada neurônio como estando conectado a todos os neurônios da camada anterior, e os pesos na soma ponderada que define sua ativação são como os pontos fortes dessas conexões, e o viés é alguma indicação de se esse neurônio tende a ser ativo ou inativo.",
  "model": "google_nmt",
  "from_community_srt": "Lembre-se, estamos concebendo cada neurônio como conectado com todos os neurônios na camada anterior, e os pesos na soma ponderada definindo a sua ativação são como a força dessas conexões. E o viés é uma indicação de se o neurônio tende a ser ativo ou inativo.",
  "n_reviews": 0,
  "start": 181.94,
  "end": 198.96
 },
 {
  "input": "And to start things off, we're just going to initialize all of those weights and biases totally randomly.",
  "translatedText": "E para começar, vamos inicializar todos esses pesos e tendências de forma totalmente aleatória.",
  "model": "google_nmt",
  "from_community_srt": "E para começar, vamos inicializar todos esses pesos e vieses totalmente ao acaso.",
  "n_reviews": 0,
  "start": 199.72,
  "end": 204.4
 },
 {
  "input": "Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random.",
  "translatedText": "Escusado será dizer que esta rede terá um desempenho horrível em um determinado exemplo de treinamento, já que está apenas fazendo algo aleatório.",
  "model": "google_nmt",
  "from_community_srt": "Nem preciso dizer que esta rede vai se sair muito mal num dado exemplo de treinamento, já que só está fazendo algo aleatório.",
  "n_reviews": 0,
  "start": 204.94,
  "end": 210.72
 },
 {
  "input": "For example, you feed in this image of a 3, and the output layer just looks like a mess.",
  "translatedText": "Por exemplo, você alimenta esta imagem de um 3 e a camada de saída parece uma bagunça.",
  "model": "google_nmt",
  "from_community_srt": "Por exemplo, você insere esta imagem de um 3 e a camada de saída parece uma zona.",
  "n_reviews": 0,
  "start": 211.04,
  "end": 216.02
 },
 {
  "input": "So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash.",
  "translatedText": "Então o que você faz é definir uma função de custo, uma forma de dizer ao computador, não, computador ruim, que a saída deve ter ativações que são 0 para a maioria dos neurônios, mas 1 para esse neurônio, o que você me deu é um lixo total.",
  "model": "google_nmt",
  "from_community_srt": "Então você tem que definir uma função de custo, um modo de dizer ao computador: \"Não, mau computador! Esta saída deve ter ativações que são 0 para a maioria dos neurônios, mas 1 para este.",
  "n_reviews": 0,
  "start": 216.6,
  "end": 230.76
 },
 {
  "input": "To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example.",
  "translatedText": "Para dizer isso um pouco mais matematicamente, você soma os quadrados das diferenças entre cada uma dessas ativações de saída de lixo e o valor que deseja que elas tenham, e isso é o que chamaremos de custo de um único exemplo de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "O que você me deu é puro lixo.\" Dizendo isso de forma um pouco mais matemática, você soma os quadrados das diferenças entre cada uma dessas ativações de saída ruins e o valor que você quer que elas tenham. E vamos chamar isso de custo de um único exemplo de treinamento.",
  "n_reviews": 0,
  "start": 231.72,
  "end": 245.02
 },
 {
  "input": "Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing.",
  "translatedText": "Observe que essa soma é pequena quando a rede classifica a imagem corretamente com segurança, mas é grande quando a rede parece não saber o que está fazendo.",
  "model": "google_nmt",
  "from_community_srt": "Observe que essa soma é pequena quando a rede classifica com confiança a imagem corretamente, mas é grande quando parece que a rede que não sabe o que está fazendo.",
  "n_reviews": 0,
  "start": 245.96,
  "end": 256.4
 },
 {
  "input": "So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal.",
  "translatedText": "Então o que você faz é considerar o custo médio de todas as dezenas de milhares de exemplos de treinamento à sua disposição.",
  "model": "google_nmt",
  "from_community_srt": "Então, você considera o custo médio de todas as dezenas de milhares de exemplos de treinamento ao seu dispor.",
  "n_reviews": 0,
  "start": 258.64,
  "end": 265.44
 },
 {
  "input": "This average cost is our measure for how lousy the network is, and how bad the computer should feel.",
  "translatedText": "Esse custo médio é a nossa medida de quão ruim é a rede e quão ruim o computador deve se sentir.",
  "model": "google_nmt",
  "from_community_srt": "Esse custo médio é a nossa medida de quão ruim é a rede e quão mal o computador deve se sentir.",
  "n_reviews": 0,
  "start": 267.04,
  "end": 272.74
 },
 {
  "input": "And that's a complicated thing.",
  "translatedText": "E isso é uma coisa complicada.",
  "model": "google_nmt",
  "from_community_srt": "E isso é algo complicado.",
  "n_reviews": 0,
  "start": 273.42,
  "end": 274.6
 },
 {
  "input": "Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases?",
  "translatedText": "Lembra como a rede em si era basicamente uma função, que recebe 784 números como entradas, os valores de pixel, e cospe 10 números como saída e, de certa forma, é parametrizada por todos esses pesos e tendências?",
  "model": "google_nmt",
  "from_community_srt": "Lembra que a própria rede é basicamente uma função, que pega 784 números como entradas, os valores de pixel, e emite dez números como sua saída, e que é parametrizada por todos esses pesos e vieses? Bem,",
  "n_reviews": 0,
  "start": 275.04,
  "end": 288.8
 },
 {
  "input": "Well the cost function is a layer of complexity on top of that.",
  "translatedText": "Bem, a função de custo é uma camada de complexidade além disso.",
  "model": "google_nmt",
  "from_community_srt": "a função de custo é uma camada de complexidade em cima disso.",
  "n_reviews": 0,
  "start": 289.5,
  "end": 292.82
 },
 {
  "input": "It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data.",
  "translatedText": "Ele toma como entrada esses cerca de 13.000 pesos e preconceitos e produz um único número que descreve o quão ruins são esses pesos e preconceitos, e a maneira como são definidos depende do comportamento da rede em todas as dezenas de milhares de dados de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Ela pega como entrada aqueles 13 mil pesos e vieses e emite um único número que descreve quão ruins esses pesos e vieses são, e o modo como ela é definida depende do comportamento da rede em todas as dezenas de milhares de dados de treinamento.",
  "n_reviews": 0,
  "start": 293.1,
  "end": 308.9
 },
 {
  "input": "That's a lot to think about.",
  "translatedText": "Isso é muito em que pensar.",
  "model": "google_nmt",
  "from_community_srt": "Isso é muito para pensar.",
  "n_reviews": 0,
  "start": 309.52,
  "end": 311.0
 },
 {
  "input": "But just telling the computer what a crappy job it's doing isn't very helpful.",
  "translatedText": "Mas apenas dizer ao computador que trabalho ruim ele está fazendo não ajuda muito.",
  "model": "google_nmt",
  "from_community_srt": "Mas não ajuda muito só dizer ao computador que trabalho ruim ele está fazendo.",
  "n_reviews": 0,
  "start": 312.4,
  "end": 315.82
 },
 {
  "input": "You want to tell it how to change those weights and biases so that it gets better.",
  "translatedText": "Você quer dizer como alterar esses pesos e preconceitos para que melhore.",
  "model": "google_nmt",
  "from_community_srt": "Você quer lhe dizer como alterar esses pesos e vieses para melhorar.",
  "n_reviews": 0,
  "start": 316.22,
  "end": 320.06
 },
 {
  "input": "To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output.",
  "translatedText": "Para facilitar, em vez de se esforçar para imaginar uma função com 13.000 entradas, imagine uma função simples que tenha um número como entrada e um número como saída.",
  "model": "google_nmt",
  "from_community_srt": "Para facilitar, em vez de se esforçar para imaginar uma função com 13 mil entradas, imagine uma função simples com um número como entrada e um número como saída.",
  "n_reviews": 0,
  "start": 320.78,
  "end": 330.48
 },
 {
  "input": "How do you find an input that minimizes the value of this function?",
  "translatedText": "Como você encontra uma entrada que minimiza o valor desta função?",
  "model": "google_nmt",
  "from_community_srt": "Como você encontra uma entrada que minimize o valor dessa função? Os alunos de cálculo sabem que,",
  "n_reviews": 0,
  "start": 331.48,
  "end": 335.3
 },
 {
  "input": "Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function.",
  "translatedText": "Os estudantes de cálculo saberão que às vezes você pode descobrir esse mínimo explicitamente, mas isso nem sempre é viável para funções realmente complicadas, certamente não na versão de 13.000 entradas desta situação para nossa louca e complicada função de custo de rede neural.",
  "model": "google_nmt",
  "from_community_srt": "às vezes, podemos descobrir esse mínimo explicitamente. Mas isso nem sempre é viável para funções muito complicadas. Certamente, não na versão de treze mil entradas desta situação para a nossa função de custo de rede neural doida de complicada.",
  "n_reviews": 0,
  "start": 336.46,
  "end": 351.08
 },
 {
  "input": "A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower.",
  "translatedText": "Uma tática mais flexível é começar com qualquer entrada e descobrir em que direção você deve seguir para diminuir essa saída.",
  "model": "google_nmt",
  "from_community_srt": "Uma tática mais flexível é começar com qualquer entrada e descobrir qual direção você deve seguir para diminuir essa saída.",
  "n_reviews": 0,
  "start": 351.58,
  "end": 359.2
 },
 {
  "input": "Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative.",
  "translatedText": "Especificamente, se você conseguir descobrir a inclinação da função onde está, desloque para a esquerda se a inclinação for positiva e desloque a entrada para a direita se a inclinação for negativa.",
  "model": "google_nmt",
  "from_community_srt": "Especificamente, se você puder descobrir a inclinação da função onde você está, então vá para a esquerda se a inclinação for positiva e desloque a entrada para a direita se essa inclinação for negativa.",
  "n_reviews": 0,
  "start": 360.08,
  "end": 369.9
 },
 {
  "input": "If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function.",
  "translatedText": "Se você fizer isso repetidamente, verificando a cada ponto a nova inclinação e dando o passo apropriado, você se aproximará de algum mínimo local da função.",
  "model": "google_nmt",
  "from_community_srt": "Se fizer isso repetidamente, em cada ponto verificando a nova inclinação e cumprindo a etapa adequada, você vai se aproximar de um mínimo local da função.",
  "n_reviews": 0,
  "start": 371.96,
  "end": 379.84
 },
 {
  "input": "The image you might have in mind here is a ball rolling down a hill.",
  "translatedText": "A imagem que você deve ter em mente aqui é uma bola rolando colina abaixo.",
  "model": "google_nmt",
  "from_community_srt": "E o que você pode imaginar aqui é uma bola rolando numa colina.",
  "n_reviews": 0,
  "start": 380.64,
  "end": 383.8
 },
 {
  "input": "Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function.",
  "translatedText": "Observe que, mesmo para esta função de entrada única realmente simplificada, há muitos vales possíveis em que você pode chegar, dependendo de qual entrada aleatória você inicia, e não há garantia de que o mínimo local em que você chegar será o menor valor possível da função custo.",
  "model": "google_nmt",
  "from_community_srt": "Observe que, mesmo para esta função simplificada de entrada única, há muitos vales possíveis nos quais você pode pousar, dependendo de em qual tipo de entrada aleatória você começou. E não há garantia que o mínimo local em que você pousar vai ser o menor valor possível da função de custo.",
  "n_reviews": 0,
  "start": 384.62,
  "end": 399.4
 },
 {
  "input": "That will carry over to our neural network case as well.",
  "translatedText": "Isso também será transferido para o nosso caso de rede neural.",
  "model": "google_nmt",
  "from_community_srt": "Isso vai se aplicar também ao nosso caso da rede neural.",
  "n_reviews": 0,
  "start": 400.22,
  "end": 402.62
 },
 {
  "input": "And I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that kind of helps you from overshooting.",
  "translatedText": "Também quero que você observe como se você fizer o tamanho dos seus passos proporcionais à inclinação, quando a inclinação estiver se achatando em direção ao mínimo, seus passos ficarão cada vez menores, e isso o ajudará a não ultrapassar os limites.",
  "model": "google_nmt",
  "from_community_srt": "E também quero que observe que, se você tornar os tamanhos das etapas proporcionais à inclinação, quando a inclinação estiver se achatando em direção ao mínimo, as etapas vão ficar cada vez menores, e isso ajuda a evitar passar do ponto.",
  "n_reviews": 0,
  "start": 403.18,
  "end": 414.6
 },
 {
  "input": "Bumping up the complexity a bit, imagine instead a function with two inputs and one output.",
  "translatedText": "Aumentando um pouco a complexidade, imagine, em vez disso, uma função com duas entradas e uma saída.",
  "model": "google_nmt",
  "from_community_srt": "Complicando as coisas, imagine uma função com duas entradas e uma saída.",
  "n_reviews": 0,
  "start": 415.94,
  "end": 420.98
 },
 {
  "input": "You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it.",
  "translatedText": "Você pode pensar no espaço de entrada como o plano xy e na função de custo como sendo representada graficamente como uma superfície acima dele.",
  "model": "google_nmt",
  "from_community_srt": "Você pode pensar no espaço de entradas como o plano X-Y e na função de custo como representada graficamente como uma superfície acima dela.",
  "n_reviews": 0,
  "start": 421.5,
  "end": 428.14
 },
 {
  "input": "Instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly.",
  "translatedText": "Em vez de perguntar sobre a inclinação da função, você deve perguntar em que direção deve pisar neste espaço de entrada para diminuir a saída da função mais rapidamente.",
  "model": "google_nmt",
  "from_community_srt": "Ora, em vez de perguntar sobre a inclinação da função, você deve perguntar: em qual direção devo ir neste espaço de entradas para diminuir a saída da função mais rápido?",
  "n_reviews": 0,
  "start": 428.76,
  "end": 438.96
 },
 {
  "input": "In other words, what's the downhill direction?",
  "translatedText": "Em outras palavras, qual é a direção descendente?",
  "model": "google_nmt",
  "from_community_srt": "Em outras palavras, qual é a direção em declive? E,",
  "n_reviews": 0,
  "start": 439.72,
  "end": 441.76
 },
 {
  "input": "Again, it's helpful to think of a ball rolling down that hill.",
  "translatedText": "Novamente, é útil pensar em uma bola rolando colina abaixo.",
  "model": "google_nmt",
  "from_community_srt": "novamente, é útil pensar numa bola rolando naquela colina.",
  "n_reviews": 0,
  "start": 442.38,
  "end": 445.56
 },
 {
  "input": "Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly.",
  "translatedText": "Aqueles que estão familiarizados com o cálculo multivariável saberão que o gradiente de uma função fornece a direção de subida mais íngreme, qual direção você deve pisar para aumentar a função mais rapidamente.",
  "model": "google_nmt",
  "from_community_srt": "Você familiarizados com o cálculo multivariável sabem que o gradiente de uma função lhe dá a direção de subida mais íngreme, basicamente, qual direção você deve seguir para aumentar a função mais rápido.",
  "n_reviews": 0,
  "start": 446.66,
  "end": 458.78
 },
 {
  "input": "Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly.",
  "translatedText": "Naturalmente, calcular o negativo desse gradiente fornece a direção do passo que diminui a função mais rapidamente.",
  "model": "google_nmt",
  "from_community_srt": "Naturalmente, pegar o negativo desse gradiente lhe dá a direção a seguir que diminui a função mais rápido.",
  "n_reviews": 0,
  "start": 459.56,
  "end": 466.04
 },
 {
  "input": "Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is.",
  "translatedText": "Mais do que isso, o comprimento deste vetor gradiente é uma indicação de quão íngreme é a encosta mais íngreme.",
  "model": "google_nmt",
  "from_community_srt": "Ainda mais que isso, a extensão desse vetor do gradiente, na verdade, indica quão íngreme é a inclinação mais íngreme.",
  "n_reviews": 0,
  "start": 467.24,
  "end": 473.84
 },
 {
  "input": "If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic.",
  "translatedText": "Se você não está familiarizado com cálculo multivariável e deseja aprender mais, confira alguns dos trabalhos que fiz para a Khan Academy sobre o assunto.",
  "model": "google_nmt",
  "from_community_srt": "Ora, se você não conhece o cálculo multivariável e quer saber mais, confira parte do trabalho que fiz para a Khan Academy sobre o tema.",
  "n_reviews": 0,
  "start": 474.54,
  "end": 480.34
 },
 {
  "input": "Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is.",
  "translatedText": "Honestamente, porém, tudo o que importa para você e para mim agora é que, em princípio, existe uma maneira de calcular esse vetor, esse vetor que informa qual é a direção da descida e quão íngreme ela é.",
  "model": "google_nmt",
  "from_community_srt": "Mas, honestamente, tudo que nos importa agora é que, em princípio, existe uma maneira de calcular esse vetor, que lhe diz qual é a direção descendente e quão íngreme ela é.",
  "n_reviews": 0,
  "start": 480.86,
  "end": 491.9
 },
 {
  "input": "You'll be okay if that's all you know and you're not rock solid on the details.",
  "translatedText": "Você ficará bem se isso for tudo que você sabe e não for sólido nos detalhes.",
  "model": "google_nmt",
  "from_community_srt": "Você vai ficar bem se souber só isso e não estiver firme sobre os detalhes.",
  "n_reviews": 0,
  "start": 492.4,
  "end": 496.12
 },
 {
  "input": "If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over.",
  "translatedText": "Se você conseguir isso, o algoritmo para minimizar a função é calcular essa direção do gradiente, dar um pequeno passo ladeira abaixo e repetir isso indefinidamente.",
  "model": "google_nmt",
  "from_community_srt": "Porque se você conseguir isso, o algoritmo para minimizar a função é calcular essa direção do gradiente, então dar um pequeno passo descendente e só repetir isso várias vezes.",
  "n_reviews": 0,
  "start": 497.2,
  "end": 506.74
 },
 {
  "input": "It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs.",
  "translatedText": "É a mesma ideia básica para uma função que possui 13.000 entradas em vez de 2 entradas.",
  "model": "google_nmt",
  "from_community_srt": "É a mesma ideia básica para uma função que tem 13 mil entradas, em vez de duas entradas.",
  "n_reviews": 0,
  "start": 507.7,
  "end": 512.82
 },
 {
  "input": "Imagine organizing all 13,000 weights and biases of our network into a giant column vector.",
  "translatedText": "Imagine organizar todos os 13.000 pesos e vieses da nossa rede em um vetor coluna gigante.",
  "model": "google_nmt",
  "from_community_srt": "Imagine organizar todos os 13 mil pesos e vieses da nossa rede num vetor de coluna gigante.",
  "n_reviews": 0,
  "start": 513.4,
  "end": 519.46
 },
 {
  "input": "The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function.",
  "translatedText": "O gradiente negativo da função de custo é apenas um vetor, é alguma direção dentro desse espaço de entrada insanamente enorme que informa quais ajustes em todos esses números causarão a diminuição mais rápida na função de custo.",
  "model": "google_nmt",
  "from_community_srt": "O gradiente negativo da função custo é só um vetor. É alguma direção dentro desse espaço de entradas loucamente enorme que lhe diz quais deslocamentos em todos esses números vão causar a diminuição mais rápida na função de custo.",
  "n_reviews": 0,
  "start": 520.14,
  "end": 534.88
 },
 {
  "input": "And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make.",
  "translatedText": "E, claro, com nossa função de custo especialmente projetada, alterar os pesos e as tendências para diminuí-los significa fazer com que a saída da rede em cada dado de treinamento pareça menos com uma matriz aleatória de 10 valores e mais com uma decisão real que queremos isso para fazer.",
  "model": "google_nmt",
  "from_community_srt": "Claro, com nossa função de custo especialmente projetada, alterar os pesos e vieses para diminuí-la significa fazer a saída da rede em cada dado de treinamento parecer menos um conjunto aleatório de dez valores, e mais como uma decisão real que queremos que ela tome.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 550.82
 },
 {
  "input": "It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples.",
  "translatedText": "É importante lembrar que essa função de custo envolve uma média de todos os dados de treinamento; portanto, se você minimizá-la, significa que há um melhor desempenho em todas essas amostras.",
  "model": "google_nmt",
  "from_community_srt": "É importante lembrar que essa função de custo envolve uma média de todos os dados de treinamento. Então, se você minimizá-la, significa que é um melhor desempenho em todas essas amostras.",
  "n_reviews": 0,
  "start": 551.44,
  "end": 561.18
 },
 {
  "input": "The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video.",
  "translatedText": "O algoritmo para calcular esse gradiente de forma eficiente, que é efetivamente o cerne de como uma rede neural aprende, é chamado de retropropagação, e é sobre isso que falarei no próximo vídeo.",
  "model": "google_nmt",
  "from_community_srt": "O algoritmo para calcular esse gradiente eficientemente, que é efetivamente o âmago de como uma rede neural aprende, se chama retropropagação, e vou falar dele no próximo vídeo.",
  "n_reviews": 0,
  "start": 563.82,
  "end": 573.98
 },
 {
  "input": "There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas.",
  "translatedText": "Nesse caso, eu realmente quero dedicar um tempo para analisar o que exatamente acontece com cada peso e tendência para um determinado dado de treinamento, tentando dar uma ideia intuitiva do que está acontecendo além da pilha de cálculos e fórmulas relevantes.",
  "model": "google_nmt",
  "from_community_srt": "Nele, eu quero dedicar tempo para mostrar passo a passo o que acontece exatamente com cada peso e viés para um dado específico de treinamento, tentando dar uma noção intuitiva do que acontece, além da pilha de cálculos e fórmulas relevantes.",
  "n_reviews": 0,
  "start": 574.66,
  "end": 587.1
 },
 {
  "input": "Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function.",
  "translatedText": "Aqui e agora, a principal coisa que quero que você saiba, independentemente dos detalhes de implementação, é que o que queremos dizer quando falamos sobre aprendizado em rede é que ele está apenas minimizando uma função de custo.",
  "model": "google_nmt",
  "from_community_srt": "Aqui e agora, a coisa principal que quero que você saiba, independente dos detalhes de implementação, é que, quando falamos que uma rede aprende, só queremos dizer que ela minimiza uma função de custo.",
  "n_reviews": 0,
  "start": 587.78,
  "end": 598.36
 },
 {
  "input": "And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill.",
  "translatedText": "E observe, uma consequência disso é que é importante que esta função de custo tenha um bom resultado suave, para que possamos encontrar um mínimo local dando pequenos passos ladeira abaixo.",
  "model": "google_nmt",
  "from_community_srt": "Repare que uma das conseqüências disso é que é importante que esta função de custo tenha uma saída bem fluida, para que possamos encontrar o mínimo local dando pequenos passos descendentes.",
  "n_reviews": 0,
  "start": 599.3,
  "end": 608.1
 },
 {
  "input": "This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are.",
  "translatedText": "É por isso que, aliás, os neurônios artificiais têm ativações que variam continuamente, em vez de simplesmente serem ativos ou inativos de forma binária, como acontece com os neurônios biológicos.",
  "model": "google_nmt",
  "from_community_srt": "Aliás, é por isso que neurônios artificiais têm ativações que variam continuamente, em vez de estarem ativos ou inativos binariamente, como neurônios biológicos estão.",
  "n_reviews": 0,
  "start": 609.26,
  "end": 619.14
 },
 {
  "input": "This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent.",
  "translatedText": "Este processo de empurrar repetidamente uma entrada de uma função por algum múltiplo do gradiente negativo é chamado de descida de gradiente.",
  "model": "google_nmt",
  "from_community_srt": "Esse processo de deslocar repetidamente uma entrada de uma função por algum múltiplo do gradiente negativo se chama descida do gradiente.",
  "n_reviews": 0,
  "start": 620.22,
  "end": 626.76
 },
 {
  "input": "It's a way to converge towards some local minimum of a cost function, basically a valley in this graph.",
  "translatedText": "É uma forma de convergir para algum mínimo local de uma função de custo, basicamente um vale neste gráfico.",
  "model": "google_nmt",
  "from_community_srt": "É um modo de convergir para um mínimo local de uma função de custo, basicamente um vale neste gráfico.",
  "n_reviews": 0,
  "start": 627.3,
  "end": 632.58
 },
 {
  "input": "I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this.",
  "translatedText": "Ainda estou mostrando a imagem de uma função com duas entradas, é claro, porque os empurrões em um espaço de entrada de 13.000 dimensões são um pouco difíceis de entender, mas há uma boa maneira não espacial de pensar sobre isso.",
  "model": "google_nmt",
  "from_community_srt": "Ainda estou mostrando a imagem de uma função com duas entradas, claro, porque é meio difícil entender deslocamentos num espaço de entradas de treze mil dimensões. Mas há uma boa maneira não espacial de pensar sobre isso.",
  "n_reviews": 0,
  "start": 633.44,
  "end": 644.26
 },
 {
  "input": "Each component of the negative gradient tells us two things.",
  "translatedText": "Cada componente do gradiente negativo nos diz duas coisas.",
  "model": "google_nmt",
  "from_community_srt": "Cada componente do gradiente negativo nos diz duas coisas.",
  "n_reviews": 0,
  "start": 645.08,
  "end": 648.44
 },
 {
  "input": "The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down.",
  "translatedText": "O sinal, é claro, nos diz se o componente correspondente do vetor de entrada deve ser deslocado para cima ou para baixo.",
  "model": "google_nmt",
  "from_community_srt": "O sinal, claro, nos diz se o componente correspondente do vetor de entrada deve ser deslocado para cima ou para baixo.",
  "n_reviews": 0,
  "start": 649.06,
  "end": 655.14
 },
 {
  "input": "But importantly, the relative magnitudes of all these components kind of tells you which changes matter more.",
  "translatedText": "Mas o mais importante é que as magnitudes relativas de todos esses componentes indicam quais mudanças são mais importantes.",
  "model": "google_nmt",
  "from_community_srt": "Mas algo importante é que a magnitude relativa de todos esses componentes lhe diz quais mudanças importam mais.",
  "n_reviews": 0,
  "start": 655.8,
  "end": 662.72
 },
 {
  "input": "You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight.",
  "translatedText": "Veja, em nossa rede, um ajuste em um dos pesos pode ter um impacto muito maior na função custo do que o ajuste em algum outro peso.",
  "model": "google_nmt",
  "from_community_srt": "Olha só, em nossa rede, um ajuste num dos pesos pode ter um impacto muito maior na função de custo do que o ajuste em outro peso.",
  "n_reviews": 0,
  "start": 665.22,
  "end": 673.04
 },
 {
  "input": "Some of these connections just matter more for our training data.",
  "translatedText": "Algumas dessas conexões são mais importantes para nossos dados de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Algumas dessas conexões simplesmente importam mais para nossos dados de treinamento.",
  "n_reviews": 0,
  "start": 674.8,
  "end": 678.2
 },
 {
  "input": "So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck.",
  "translatedText": "Portanto, uma maneira de pensar sobre esse vetor gradiente de nossa enorme função de custo é que ele codifica a importância relativa de cada peso e tendência, ou seja, qual dessas mudanças terá o maior retorno para seu investimento.",
  "model": "google_nmt",
  "from_community_srt": "Então, você pode pensar neste vetor de gradiente da nossa função de custo absurdamente grande como algo que codifica a importância relativa de cada peso e viés, ou seja, qual dessas mudanças vai fazer render mais a sua bufunfa.",
  "n_reviews": 0,
  "start": 679.32,
  "end": 692.4
 },
 {
  "input": "This really is just another way of thinking about direction.",
  "translatedText": "Esta é realmente apenas outra maneira de pensar sobre direção.",
  "model": "google_nmt",
  "from_community_srt": "Isso realmente não passa de outra maneira de pensar sobre direção.",
  "n_reviews": 0,
  "start": 693.62,
  "end": 696.64
 },
 {
  "input": "To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction.",
  "translatedText": "Para dar um exemplo mais simples, se você tiver alguma função com duas variáveis como entrada e calcular que seu gradiente em algum ponto específico resulta em 3,1, então, por um lado, você pode interpretar isso como dizendo que quando você &#39; Se você estiver nessa entrada, mover-se ao longo dessa direção aumenta a função mais rapidamente; quando você representa graficamente a função acima do plano dos pontos de entrada, esse vetor é o que fornece a direção ascendente reta.",
  "model": "google_nmt",
  "from_community_srt": "Dando um exemplo mais simples, se você tem uma função com duas variáveis ​​como entrada, e calcula que seu gradiente em algum ponto particular aparece como (3,1), então, por um lado, você pode interpretar isso como dizendo que, quando você está nesta entrada, mover-se ao longo desta direção aumenta a função mais rápido, que quando você representa a função graficamente acima do plano de pontos de entrada, esse vetor é o que está lhe dando a direção reta para cima.",
  "n_reviews": 0,
  "start": 697.1,
  "end": 722.26
 },
 {
  "input": "But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck.",
  "translatedText": "Mas outra maneira de ler isso é dizer que as alterações nesta primeira variável têm 3 vezes mais importância que as alterações na segunda variável, que pelo menos na vizinhança da entrada relevante, deslocar o valor x traz muito mais impacto para o seu bode.",
  "model": "google_nmt",
  "from_community_srt": "Mas outra maneira de ler isso é dizer que mudanças nessa primeira variável têm o triplo da importância das mudanças na segunda variável, que pelo menos na vizinhança da entrada relevante, deslocar o valor de x é muito mais vantajoso.",
  "n_reviews": 0,
  "start": 722.86,
  "end": 736.9
 },
 {
  "input": "Let's zoom out and sum up where we are so far.",
  "translatedText": "Vamos diminuir o zoom e resumir onde estamos até agora.",
  "model": "google_nmt",
  "from_community_srt": "OK, vamos dar um passo para trás e resumir onde estamos agora.",
  "n_reviews": 0,
  "start": 739.88,
  "end": 742.34
 },
 {
  "input": "The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums.",
  "translatedText": "A própria rede é esta função com 784 entradas e 10 saídas, definidas em termos de todas essas somas ponderadas.",
  "model": "google_nmt",
  "from_community_srt": "A rede em si é uma função com 784 entradas e 10 saídas, definida em termos de todas essas somas ponderadas.",
  "n_reviews": 0,
  "start": 742.84,
  "end": 750.04
 },
 {
  "input": "The cost function is a layer of complexity on top of that.",
  "translatedText": "A função de custo é uma camada de complexidade além disso.",
  "model": "google_nmt",
  "from_community_srt": "A função de custo é uma camada de complexidade em cima disso.",
  "n_reviews": 0,
  "start": 750.64,
  "end": 753.68
 },
 {
  "input": "It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples.",
  "translatedText": "Ele pega os 13.000 pesos e preconceitos como entradas e produz uma única medida de péssimo com base nos exemplos de treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Ela pega os 13 mil pesos e vieses como entradas e emite uma única medida de ruindade com base nos exemplos de treinamento.",
  "n_reviews": 0,
  "start": 753.98,
  "end": 761.72
 },
 {
  "input": "And the gradient of the cost function is one more layer of complexity still.",
  "translatedText": "E o gradiente da função de custo é ainda mais uma camada de complexidade.",
  "model": "google_nmt",
  "from_community_srt": "E o gradiente da função custo é mais uma camada de complexidade.",
  "n_reviews": 0,
  "start": 762.44,
  "end": 766.9
 },
 {
  "input": "It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most.",
  "translatedText": "Ele nos diz quais estímulos a todos esses pesos e vieses causam a mudança mais rápida no valor da função de custo, o que você pode interpretar como dizer quais mudanças em quais pesos são mais importantes.",
  "model": "google_nmt",
  "from_community_srt": "Ele nos diz quais deslocamentos em todos esses pesos e vieses causam a mudança mais rápida no valor da função de custo, o que você pode interpretar como dizendo:",
  "n_reviews": 0,
  "start": 767.36,
  "end": 777.88
 },
 {
  "input": "So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before?",
  "translatedText": "Então, quando você inicializa a rede com pesos e desvios aleatórios e os ajusta muitas vezes com base nesse processo de gradiente descendente, quão bem ela realmente funciona em imagens que nunca foi vista antes?",
  "model": "google_nmt",
  "from_community_srt": "\"quais mudanças em quais pesos mais importam?\" Então, quando você inicializar a rede com pesos e vieses aleatórios e ajustá-los muitas vezes com base nesse processo de descida do gradiente, como ela realmente se sai com imagens que nunca viu antes? Bem,",
  "n_reviews": 0,
  "start": 782.56,
  "end": 793.2
 },
 {
  "input": "The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly.",
  "translatedText": "Aquela que descrevi aqui, com as duas camadas ocultas de 16 neurônios cada, escolhidas principalmente por razões estéticas, não é ruim, classificando corretamente cerca de 96% das novas imagens que vê.",
  "model": "google_nmt",
  "from_community_srt": "a que descrevi aqui (aquela com duas camadas ocultas de 16 neurônios cada, escolhida principalmente por razões estéticas) bem, ela não é ruim. Ela classifica corretamente cerca de 96% das novas imagens que vê.",
  "n_reviews": 0,
  "start": 794.1,
  "end": 805.96
 },
 {
  "input": "And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack.",
  "translatedText": "E, honestamente, se você olhar alguns dos exemplos em que isso atrapalha, você se sente compelido a dar uma folga.",
  "model": "google_nmt",
  "from_community_srt": "E, sinceramente, se você olhar para alguns dos exemplos em que ela erra, dá vontade de pegar leve com ela.",
  "n_reviews": 0,
  "start": 806.68,
  "end": 812.54
 },
 {
  "input": "Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%.",
  "translatedText": "Agora, se você brincar com a estrutura da camada oculta e fizer alguns ajustes, poderá chegar a 98%.",
  "model": "google_nmt",
  "from_community_srt": "Ora, se você brincar com a estrutura de camadas ocultas e fizer alguns ajustes, ela pode chegar a 98%.",
  "n_reviews": 0,
  "start": 816.22,
  "end": 821.76
 },
 {
  "input": "And that's pretty good!",
  "translatedText": "E isso é muito bom!",
  "model": "google_nmt",
  "from_community_srt": "E isso é muito bom.",
  "n_reviews": 0,
  "start": 821.76,
  "end": 822.72
 },
 {
  "input": "It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for.",
  "translatedText": "Não é o melhor, você certamente pode obter melhor desempenho ficando mais sofisticado do que esta rede simples, mas considerando o quão assustadora é a tarefa inicial, acho que há algo incrível em qualquer rede que se sai tão bem em imagens que nunca foi vista antes, dado que nunca lhe dissemos especificamente quais padrões procurar.",
  "model": "google_nmt",
  "from_community_srt": "Não é o melhor, Com certeza, você pode ter melhor desempenho ficando mais sofisticado do que esta rede neural simples. Mas, considerando como a tarefa inicial é desafiadora, acho que há algo incrível em qualquer rede que faça isso bem em imagens que nunca tenha visto antes, dado que nunca dissemos especificamente quais padrões procurar.",
  "n_reviews": 0,
  "start": 823.02,
  "end": 841.42
 },
 {
  "input": "Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits.",
  "translatedText": "Originalmente, a forma como motivei esta estrutura foi descrevendo uma esperança que poderíamos ter, que a segunda camada pudesse captar pequenas arestas, que a terceira camada juntasse essas arestas para reconhecer loops e linhas mais longas, e que estas pudessem ser remendadas. juntos para reconhecer dígitos.",
  "model": "google_nmt",
  "from_community_srt": "Originalmente, eu motivei essa estrutura descrevendo uma esperança que poderíamos ter: que a segunda camada pudesse detectar bordinhas, que a terceira camada reunisse essas bordas para reconhecer círculos e linhas mais longas, e que elas pudessem ser reunidas para reconhecer dígitos.",
  "n_reviews": 0,
  "start": 842.56,
  "end": 857.18
 },
 {
  "input": "So is this what our network is actually doing?",
  "translatedText": "Então é isso que nossa rede está realmente fazendo?",
  "model": "google_nmt",
  "from_community_srt": "Então é isso o que a nossa rede está realmente fazendo? Bem,",
  "n_reviews": 0,
  "start": 857.96,
  "end": 860.4
 },
 {
  "input": "Well, for this one at least, not at all.",
  "translatedText": "Bem, pelo menos para este, de jeito nenhum.",
  "model": "google_nmt",
  "from_community_srt": "pelo menos esta,",
  "n_reviews": 0,
  "start": 861.08,
  "end": 864.4
 },
 {
  "input": "Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on?",
  "translatedText": "Lembra-se de como no último vídeo vimos como os pesos das conexões de todos os neurônios na primeira camada para um determinado neurônio na segunda camada podem ser visualizados como um determinado padrão de pixels que o neurônio da segunda camada está captando?",
  "model": "google_nmt",
  "from_community_srt": "de jeito nenhum! Lembra que no último vídeo vimos que os pesos das conexões de todos os neurônios na primeira camada com um determinado neurônio na segunda camada podem ser visualizados como um dado padrão de pixel que aquele neurônio da segunda camada está captando?",
  "n_reviews": 0,
  "start": 864.82,
  "end": 877.06
 },
 {
  "input": "Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there.",
  "translatedText": "Bem, quando realmente fazemos isso para os pesos associados a essas transições, da primeira camada para a próxima, em vez de pegar pequenas arestas isoladas aqui e ali, elas parecem, bem, quase aleatórias, apenas com alguns padrões muito soltos em o meio ali.",
  "model": "google_nmt",
  "from_community_srt": "Bem, quando realmente fazemos isso para os pesos associados a essas transições da primeira camada para a próxima, em vez de detectar bordinhas isoladas aqui e ali, eles parecem, bem, quase aleatórios. Só colocam uns padrões bem livres lá no meio.",
  "n_reviews": 0,
  "start": 877.78,
  "end": 893.68
 },
 {
  "input": "It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for.",
  "translatedText": "Parece que no espaço insondavelmente grande de 13.000 dimensões de possíveis pesos e tendências, a nossa rede encontrou-se como um feliz mínimo local que, apesar de classificar com sucesso a maioria das imagens, não capta exactamente os padrões que esperávamos.",
  "model": "google_nmt",
  "from_community_srt": "Parece que no espaço insondavelmente grande de 13 mil dimensões de possíveis pesos e vieses, a nossa rede encontrou um feliz mínimo local que, apesar de classificar com sucesso a maioria das imagens, não capta exatamente os padrões que esperávamos.",
  "n_reviews": 0,
  "start": 893.76,
  "end": 908.96
 },
 {
  "input": "And to really drive this point home, watch what happens when you input a random image.",
  "translatedText": "E para realmente esclarecer esse ponto, observe o que acontece quando você insere uma imagem aleatória.",
  "model": "google_nmt",
  "from_community_srt": "Para fixar essa ideia, olhe o que acontece quando você insere uma imagem aleatória.",
  "n_reviews": 0,
  "start": 909.78,
  "end": 913.82
 },
 {
  "input": "If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5.",
  "translatedText": "Se o sistema fosse inteligente, você poderia esperar que ele parecesse incerto, talvez não ativando realmente nenhum desses 10 neurônios de saída ou ativando todos eles uniformemente, mas em vez disso, ele lhe daria com segurança alguma resposta sem sentido, como se parecesse tão certo que esse ruído aleatório é um 5, pois uma imagem real de um 5 é um 5.",
  "model": "google_nmt",
  "from_community_srt": "Se o sistema fosse inteligente, você esperaria que ele se sentisse incerto, talvez não ativando nenhum daqueles 10 neurônios de saída, ou ativando-os todos uniformemente. Mas ao invés disso, ele lhe dá confiantemente uma resposta sem sentido, como se tivesse tanta certeza de que este ruído aleatório é um 5 quanto tem certeza de que uma imagem real de um 5 é um 5.",
  "n_reviews": 0,
  "start": 914.32,
  "end": 934.16
 },
 {
  "input": "Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them.",
  "translatedText": "Dito de outra forma, mesmo que esta rede consiga reconhecer dígitos muito bem, ela não tem ideia de como desenhá-los.",
  "model": "google_nmt",
  "from_community_srt": "Em outras palavras, ainda que esta rede possa reconhecer dígitos muito bem, ela não faz idéia de como desenhá-los.",
  "n_reviews": 0,
  "start": 934.54,
  "end": 940.7
 },
 {
  "input": "A lot of this is because it's such a tightly constrained training setup.",
  "translatedText": "Muito disso ocorre porque é uma configuração de treinamento muito restrita.",
  "model": "google_nmt",
  "from_community_srt": "Muito disso é porque a configuração de treinamento é muito limitada.",
  "n_reviews": 0,
  "start": 941.42,
  "end": 945.24
 },
 {
  "input": "I mean, put yourself in the network's shoes here.",
  "translatedText": "Quero dizer, coloque-se no lugar da rede aqui.",
  "model": "google_nmt",
  "from_community_srt": "Assim, ponha-se no lugar da rede aqui.",
  "n_reviews": 0,
  "start": 945.88,
  "end": 947.74
 },
 {
  "input": "From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions.",
  "translatedText": "Do seu ponto de vista, o universo inteiro consiste apenas em dígitos imóveis claramente definidos, centrados numa pequena grelha, e a sua função de custo nunca lhe deu qualquer incentivo para ser outra coisa senão totalmente confiante nas suas decisões.",
  "model": "google_nmt",
  "from_community_srt": "Do ponto de vista dela, o universo inteiro consiste em nada além de dígitos imóveis claramente definidos centralizados numa grade minúscula. E a sua função de custo nunca lhe deu nenhum incentivo para ser nada além de plenamente confiante sobre as suas decisões.",
  "n_reviews": 0,
  "start": 948.14,
  "end": 961.08
 },
 {
  "input": "So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns.",
  "translatedText": "Então, com isso como a imagem do que esses neurônios da segunda camada estão realmente fazendo, você pode se perguntar por que eu introduziria essa rede com a motivação de captar arestas e padrões.",
  "model": "google_nmt",
  "from_community_srt": "Então, se esta é a imagem do que os neurônios da segunda camada estão realmente fazendo, você pode se perguntar por que eu introduziria esta rede com a motivação de detectar bordas e padrões.",
  "n_reviews": 0,
  "start": 962.12,
  "end": 969.92
 },
 {
  "input": "I mean, that's just not at all what it ends up doing.",
  "translatedText": "Quero dizer, não é isso que acaba fazendo.",
  "model": "google_nmt",
  "from_community_srt": "Assim, isso não é nada do que ela acaba fazendo.",
  "n_reviews": 0,
  "start": 969.92,
  "end": 972.3
 },
 {
  "input": "Well, this is not meant to be our end goal, but instead a starting point.",
  "translatedText": "Bem, este não pretende ser o nosso objetivo final, mas sim um ponto de partida.",
  "model": "google_nmt",
  "from_community_srt": "Bem, esse não é para ser nosso objetivo final, mas sim um ponto de partida.",
  "n_reviews": 0,
  "start": 973.38,
  "end": 977.18
 },
 {
  "input": "Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems.",
  "translatedText": "Francamente, esta é uma tecnologia antiga, do tipo pesquisado nos anos 80 e 90, e você precisa entendê-la antes de poder entender variantes modernas mais detalhadas, e ela é claramente capaz de resolver alguns problemas interessantes, mas quanto mais você se aprofunda no que essas camadas ocultas estão realmente funcionando, menos inteligente parece.",
  "model": "google_nmt",
  "from_community_srt": "Francamente, isso é tecnologia antiga, do tipo pesquisado nos anos 80 e 90. E você precisa sim entendê-la antes de poder entender variantes modernas mais detalhadas. E ela é claramente capaz de resolver alguns problemas interessantes. Mas quanto mais você se aprofunda no que essas camadas ocultas estão realmente fazendo, menos inteligente ela parece.",
  "n_reviews": 0,
  "start": 977.64,
  "end": 994.74
 },
 {
  "input": "Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow.",
  "translatedText": "Mudando o foco por um momento de como as redes aprendem para como você aprende, isso só acontecerá se você se envolver ativamente com o material aqui de alguma forma.",
  "model": "google_nmt",
  "from_community_srt": "Mudando o foco por um momento, de como as redes aprendem para como você aprende, isso só vai acontecer se você se envolver ativamente com o material aqui de alguma forma.",
  "n_reviews": 0,
  "start": 998.48,
  "end": 1006.3
 },
 {
  "input": "One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns.",
  "translatedText": "Uma coisa muito simples que quero que você faça é apenas fazer uma pausa agora e pensar profundamente por um momento sobre quais mudanças você pode fazer neste sistema e como ele percebe as imagens se você quiser que ele capte melhor coisas como bordas e padrões.",
  "model": "google_nmt",
  "from_community_srt": "Quero que você faça uma coisa muito simples: só pause agora e pense a fundo por um momento sobre que alterações você pode fazer neste sistema e no modo como ele percebe imagens para ele detectar melhor coisas como bordas e padrões.",
  "n_reviews": 0,
  "start": 1007.06,
  "end": 1020.88
 },
 {
  "input": "But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks.",
  "translatedText": "Mas melhor do que isso, para realmente interagir com o material, recomendo fortemente o livro de Michael Nielsen sobre aprendizagem profunda e redes neurais.",
  "model": "google_nmt",
  "from_community_srt": "Mas melhor ainda, para realmente se envolver com o material, eu recomendo fortemente o livro de Michael Nielsen sobre aprendizado profundo e redes neurais.",
  "n_reviews": 0,
  "start": 1021.48,
  "end": 1029.1
 },
 {
  "input": "In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing.",
  "translatedText": "Nele, você pode encontrar o código e os dados para baixar e brincar com este exemplo exato, e o livro irá guiá-lo passo a passo sobre o que esse código está fazendo.",
  "model": "google_nmt",
  "from_community_srt": "Nele você pode encontrar o código e os dados para baixar e brincar para este exemplo exato. E o livro vai guiar você passo a passo sobre o que esse código faz.",
  "n_reviews": 0,
  "start": 1029.68,
  "end": 1038.36
 },
 {
  "input": "What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts.",
  "translatedText": "O que é incrível é que este livro é gratuito e está disponível publicamente, então, se você conseguir algo com ele, considere se juntar a mim para fazer uma doação para os esforços da Nielsen.",
  "model": "google_nmt",
  "from_community_srt": "O que é incrível é que este livro é gratuito e está disponível ao público. Então, se for útil para você, considere juntar-se a mim e fazer uma doação para os esforços de Nielsen.",
  "n_reviews": 0,
  "start": 1039.3,
  "end": 1047.66
 },
 {
  "input": "I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill.",
  "translatedText": "Também vinculei alguns outros recursos de que gosto muito na descrição, incluindo a fenomenal e bela postagem no blog de Chris Ola e os artigos no Distill.",
  "model": "google_nmt",
  "from_community_srt": "Também pus links de alguns outros recursos de que gosto muito na descrição, incluindo o post lindo e fenomenal de Chris Ola e os artigos do Distill.",
  "n_reviews": 0,
  "start": 1047.66,
  "end": 1056.5
 },
 {
  "input": "To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee.",
  "translatedText": "Para encerrar os últimos minutos, quero voltar a um trecho da entrevista que tive com Leisha Lee.",
  "model": "google_nmt",
  "from_community_srt": "Para encerrar as coisas aqui nos últimos minutos, queria voltar a um trecho da entrevista que fiz com Leisha Lee.",
  "n_reviews": 0,
  "start": 1058.28,
  "end": 1063.88
 },
 {
  "input": "You might remember her from the last video, she did her PhD work in deep learning.",
  "translatedText": "Você deve se lembrar dela do último vídeo, ela fez seu trabalho de doutorado em aprendizagem profunda.",
  "model": "google_nmt",
  "from_community_srt": "Deve se lembrar dela do último vídeo. Ela fez doutorado em aprendizado profundo.",
  "n_reviews": 0,
  "start": 1064.3,
  "end": 1067.72
 },
 {
  "input": "In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning.",
  "translatedText": "Neste pequeno trecho, ela fala sobre dois artigos recentes que realmente investigam como algumas das redes mais modernas de reconhecimento de imagem estão realmente aprendendo.",
  "model": "google_nmt",
  "from_community_srt": "e neste trechinho ela fala sobre dois artigos recentes que se aprofundam em como algumas das redes de reconhecimento de imagem mais modernas realmente aprendem.",
  "n_reviews": 0,
  "start": 1068.3,
  "end": 1075.78
 },
 {
  "input": "Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training.",
  "translatedText": "Apenas para definir onde estávamos na conversa, o primeiro artigo pegou uma dessas redes neurais particularmente profundas que é realmente boa no reconhecimento de imagens e, em vez de treiná-la em um conjunto de dados devidamente rotulado, embaralhou todos os rótulos antes do treinamento.",
  "model": "google_nmt",
  "from_community_srt": "Só para esclarecer onde estávamos na conversa, o primeiro artigo pegou uma dessas redes neurais particularmente profundas que é muito boa no reconhecimento de imagens e, em vez de treiná-la num conjunto de dados corretamente rotulado, embaralhou todos os rótulos antes do treino.",
  "n_reviews": 0,
  "start": 1076.12,
  "end": 1088.74
 },
 {
  "input": "Obviously the testing accuracy here was going to be no better than random, since everything's just randomly labeled. But it was still able to achieve the same training accuracy as you would on a properly labeled dataset.",
  "translatedText": "Obviamente, a precisão do teste aqui não foi melhor do que aleatória, já que tudo é rotulado aleatoriamente, mas ainda foi capaz de atingir a mesma precisão de treinamento que você alcançaria em um conjunto de dados devidamente rotulado.",
  "model": "google_nmt",
  "from_community_srt": "Óbvio que a precisão do teste não seria melhor do que o acaso, já que tudo estava rotulado aleatoriamente. Mas ela ainda conseguiu a mesma precisão de treinamento que conseguiria num conjunto de dados rotulado adequadamente.",
  "n_reviews": 0,
  "start": 1089.48,
  "end": 1100.88
 },
 {
  "input": "Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization?",
  "translatedText": "Basicamente, os milhões de pesos para esta rede em particular foram suficientes para que ela apenas memorizasse os dados aleatórios, o que levanta a questão de saber se a minimização desta função de custo realmente corresponde a algum tipo de estrutura na imagem, ou é apenas memorização?",
  "model": "google_nmt",
  "from_community_srt": "Basicamente, os milhões de pesos para esta rede em particular bastaram para ela memorizar os dados aleatórios. E isso levanta a questão questão: minimizar esta função de custo realmente corresponde a algum tipo de estrutura na imagem? Ou é só, sabe...",
  "n_reviews": 0,
  "start": 1101.6,
  "end": 1116.4
 },
 {
  "input": "...to memorize the entire dataset of what the correct classification is. And so a couple of, you know, half a year later at ICML this year, there was not exactly rebuttal paper, but paper that addressed some aspects of like, hey, actually these networks are doing something a little bit smarter than that. If you look at that accuracy c",
  "translatedText": "Se você olhar para aquela curva de precisão, se você estivesse apenas treinando em um conjunto de dados aleatório, essa curva desceu muito lentamente, quase de forma linear, então você está realmente lutando para encontrar os mínimos locais possíveis, você sabe , os pesos certos que proporcionariam essa precisão.",
  "model": "google_nmt",
  "from_community_srt": "memorizou todo o conjunto de dados sobre qual é a classificação correta. E, então, seis meses depois, no ICML este ano, houve não exatamente um artigo-réplica, um artigo que aborda a ideia de que, na verdade, essas redes estão fazendo algo um pouco mais inteligente do que isso. Se você olhar aquela curva de precisão, se você estivesse só treinando num conjunto de dados aleatório, essa curva desceria muito devagar, quase linearmente. Então, você tem muita dificuldade para encontrar o mínimo local, os pesos corretos que lhe dariam essa precisão.",
  "n_reviews": 0,
  "start": 1131.44,
  "end": 1152.14
 },
 {
  "input": "Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima.",
  "translatedText": "Considerando que, se você estiver realmente treinando em um conjunto de dados estruturado, que tenha os rótulos certos, você mexe um pouco no começo, mas depois cai muito rápido para chegar a esse nível de precisão e, de certa forma, é foi mais fácil encontrar esses máximos locais.",
  "model": "google_nmt",
  "from_community_srt": "Enquanto, se você  está treinando num conjunto de dados estruturados, um que tenha os rótulos certos, você não faz nada no começo, mas cai bem rápido para chegar naquele nível de precisão. E, em certo sentido, foi mais fácil encontrar esse máximo local.",
  "n_reviews": 0,
  "start": 1152.24,
  "end": 1168.22
 },
 {
  "input": "And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily.",
  "translatedText": "E o que também foi interessante sobre isso é que traz à luz outro artigo de alguns anos atrás, que tem muito mais simplificações sobre as camadas de rede, mas um dos resultados foi dizer que se você olhar para o cenário de otimização, os mínimos locais que essas redes tendem a aprender são, na verdade, de igual qualidade; portanto, em certo sentido, se o seu conjunto de dados estiver estruturado, você poderá encontrá-los com muito mais facilidade.",
  "model": "google_nmt",
  "from_community_srt": "E o que também foi interessante sobre isso é que isso traz à discussão um outro artigo de alguns anos atrás, que tem muito mais simplificações sobre as camadas da rede. Mas um dos resultados era que, se você olhar para a paisagem de otimização, os mínimos locais que essas redes tendem a aprender são, na verdade, de qualidades iguais. Então, em certo sentido, se o seu conjunto de dados é estruturado, você deve ser capaz de descobrir isso com muito mais facilidade.",
  "n_reviews": 0,
  "start": 1168.54,
  "end": 1194.32
 },
 {
  "input": "My thanks, as always, to those of you supporting on Patreon.",
  "translatedText": "Meus agradecimentos, como sempre, a todos vocês que apoiam o Patreon.",
  "model": "google_nmt",
  "from_community_srt": "Obrigado, como sempre, àqueles que apoiam no Patreon.",
  "n_reviews": 0,
  "start": 1198.16,
  "end": 1201.18
 },
 {
  "input": "I've said before just what a game changer Patreon is, but these videos really would not be possible without you.",
  "translatedText": "Eu já disse antes o que o Patreon é uma virada de jogo, mas esses vídeos realmente não seriam possíveis sem você.",
  "model": "google_nmt",
  "from_community_srt": "Já disse como o Patreon mudou as coisas, mas estes vídeos realmente não seriam possíveis sem vocês.",
  "n_reviews": 0,
  "start": 1201.52,
  "end": 1206.8
 },
 {
  "input": "I also want to give a special thanks to the VC firm Amplify Partners and their support of these initial videos in the series. Thank you.",
  "translatedText": "Também quero agradecer especialmente à empresa de capital de risco Amplify Partners, pelo apoio a esses vídeos iniciais da série.",
  "model": "google_nmt",
  "from_community_srt": "Também quero agradecer especialmente à empresa de capital de risco Amplify Partners, e ao seu apoio a estes vídeos iniciais da série.",
  "n_reviews": 0,
  "start": 1207.46,
  "end": 1212.78
 }
]