[
 {
  "input": "Here, we tackle backpropagation, the core algorithm behind how neural networks learn. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   0.0,
   9.64
  ]
 },
 {
  "input": "After a quick recap for where we are, the first thing I'll do is an intuitive walkthrough for what the algorithm is actually doing, without any reference to the formulas. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   9.64,
   17.4
  ]
 },
 {
  "input": "Then, for those of you who do want to dive into the math, the next video goes into the calculus underlying all this. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   17.4,
   24.04
  ]
 },
 {
  "input": "If you watched the last two videos, or if you're just jumping in with the appropriate background, you know what a neural network is, and how it feeds forward information. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   24.04,
   31.08
  ]
 },
 {
  "input": "Here, we're doing the classic example of recognizing handwritten digits whose pixel values get fed into the first layer of the network with 784 neurons, and I've been showing a network with two hidden layers having just 16 neurons each, and an output layer of 10 neurons, indicating which digit the network is choosing as its answer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   31.08,
   49.52
  ]
 },
 {
  "input": "I'm also expecting you to understand gradient descent, as described in the last video, and how what we mean by learning is that we want to find which weights and biases minimize a certain cost function. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   49.52,
   62.08
  ]
 },
 {
  "input": "As a quick reminder, for the cost of a single training example, you take the output the network gives, along with the output you wanted it to give, and add up the squares of the differences between each component. ",
  "translatedText": "ที่นี่ เราจัดการกับการเผยแพร่ย้อนกลับ ซึ่งเป็นอัลกอริธึมหลักที่อยู่เบื้องหลังการเรียนรู้ของโครงข่ายประสาทเทียม หลังจากการสรุปคร่าวๆ เกี่ยวกับจุดที่เราอยู่ สิ่งแรกที่ฉันจะทำคือคำแนะนำแบบเข้าใจง่ายเกี่ยวกับสิ่งที่อัลกอริทึมกำลังทำอยู่ โดยไม่ต้องอ้างอิงถึงสูตรใดๆ จากนั้น สำหรับผู้ที่ต้องการเจาะลึกคณิตศาสตร์ วิดีโอถัดไปจะพูดถึงแคลคูลัสที่เป็นรากฐานของทั้งหมดนี้ หากคุณดูวิดีโอสองรายการล่าสุด หรือหากคุณเพียงแค่กระโดดเข้ามาโดยมีพื้นหลังที่เหมาะสม คุณจะรู้ว่าโครงข่ายประสาทเทียมคืออะไร และเครือข่ายดังกล่าวส่งต่อข้อมูลอย่างไร ที่นี่ เรากำลังทำตัวอย่างคลาสสิกของการจดจำตัวเลขที่เขียนด้วยลายมือซึ่งค่าพิกเซลถูกป้อนเข้าไปในเลเยอร์แรกของเครือข่ายด้วยเซลล์ประสาท 784 ตัว และฉันได้แสดงเครือข่ายที่มีเลเยอร์ซ่อนอยู่สองชั้น โดยแต่ละเลเยอร์มีเซลล์ประสาทเพียง 16 ตัว และเอาต์พุต เลเยอร์ของเซลล์ประสาท 10 ตัว ซึ่งบ่งชี้ว่าเครือข่ายเลือกหลักใดเป็นคำตอบ ฉันคาดหวังให้คุณเข้าใจการไล่ระดับสีแบบเกรเดียนต์ด้วย ดังที่อธิบายไว้ในวิดีโอที่แล้ว และสิ่งที่เราหมายถึงโดยการเรียนรู้ก็คือ เราต้องการค้นหาว่าน้ำหนักและอคติใดที่ลดฟังก์ชันต้นทุนบางอย่างลง ขอเตือนไว้ก่อนว่า สำหรับค่าใช้จ่ายของตัวอย่างการฝึกอบรมรายการเดียว คุณจะต้องนำเอาท์พุตที่เครือข่ายให้มา ควบคู่ไปกับเอาท์พุตที่คุณต้องการให้มัน และเพิ่มกำลังสองของความแตกต่างระหว่างแต่ละส่วนประกอบ การทำเช่นนี้กับตัวอย่างการฝึกอบรมนับหมื่นรายการของคุณและเฉลี่ยผลลัพธ์ จะทำให้คุณมีค่าใช้จ่ายรวมของเครือข่าย ราวกับว่านั่นยังไม่เพียงพอ อย่างที่อธิบายไว้ในวิดีโอที่แล้ว สิ่งที่เรากำลังมองหาคือเกรเดียนต์เชิงลบของฟังก์ชันต้นทุนนี้ ซึ่งบอกคุณว่าคุณต้องเปลี่ยนน้ำหนักและอคติทั้งหมดอย่างไร การเชื่อมต่อเหล่านี้เพื่อลดต้นทุนได้อย่างมีประสิทธิภาพสูงสุด Backpropagation ซึ่งเป็นหัวข้อของวิดีโอนี้เป็นอัลกอริทึมสำหรับการคำนวณการไล่ระดับสีที่ซับซ้อนอย่างบ้าคลั่ง แนวคิดหนึ่งจากวิดีโอที่แล้ว ที่ผมอยากให้คุณยึดมั่นในใจตอนนี้ก็คือ เพราะการคิดถึงเวกเตอร์เกรเดียนต์เป็นทิศทางใน 13,000 มิติ พูดง่ายๆ เลย นอกเหนือขอบเขตจินตนาการของเรา ยังมีอีกแนวคิดหนึ่งจากวิดีโอที่แล้ว วิธีคิดเกี่ยวกับมัน ขนาดของแต่ละองค์ประกอบตรงนี้จะบอกคุณว่าฟังก์ชันต้นทุนมีความละเอียดอ่อนต่อน้ำหนักและอคติแต่ละรายการอย่างไร  ตัวอย่างเช่น สมมติว่าคุณทำตามขั้นตอนที่ฉันกำลังจะอธิบาย และคำนวณค่าเกรเดียนต์ที่เป็นลบ และส่วนประกอบที่เกี่ยวข้องกับน้ำหนักบนขอบนี้จะเป็น 3 2 ในขณะที่ส่วนประกอบที่เกี่ยวข้องกับขอบนี้ที่นี่ออกมาเป็น 0 1. ",
  "model": "nmt",
  "time_range": [
   62.08,
   75.56
  ]
 },
 {
  "input": "Doing this for all of your tens of thousands of training examples and averaging the results, this gives you the total cost of the network. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   75.56,
   83.04
  ]
 },
 {
  "input": "As if that's not enough to think about, as described in the last video, the thing that we're looking for is the negative gradient of this cost function, which tells you how you need to change all of the weights and biases, all of these connections, so as to most efficiently decrease the cost. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   83.04,
   103.08
  ]
 },
 {
  "input": "Backpropagation, the topic of this video, is an algorithm for computing that crazy complicated gradient. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   103.08,
   109.6
  ]
 },
 {
  "input": "The one idea from the last video that I really want you to hold firmly in your mind right now is that because thinking of the gradient vector as a direction in 13,000 dimensions is, to put it lightly, beyond the scope of our imaginations, there's another way you can think about it. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   109.6,
   124.62
  ]
 },
 {
  "input": "The magnitude of each component here is telling you how sensitive the cost function is to each weight and bias. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   124.62,
   131.82
  ]
 },
 {
  "input": "For example, let's say you go through the process I'm about to describe, and compute the negative gradient, and the component associated with the weight on this edge here comes out to be 3.2, while the component associated with this edge here comes out as 0.1. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   131.82,
   146.94
  ]
 },
 {
  "input": "The way you would interpret that is that the cost of the function is 32 times more sensitive to changes in that first weight, so if you were to wiggle that value a little bit, it's going to cause some change to the cost, and that change is 32 times greater than what the same wiggle to that second weight would give. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   146.94,
   165.58
  ]
 },
 {
  "input": "Personally, when I was first learning about backpropagation, I think the most confusing aspect was just the notation and index chasing of it all. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   165.58,
   175.82
  ]
 },
 {
  "input": "But once you unwrap what each part of this algorithm is really doing, each individual effect it's having is actually pretty intuitive, it's just that there's a lot of little adjustments getting layered on top of each other. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   175.82,
   187.74
  ]
 },
 {
  "input": "So I'm going to start things off here with a complete disregard for the notation, and just step through the effects each training example has on the weights and biases. ",
  "translatedText": "วิธีที่คุณจะตีความได้ว่าต้นทุนของฟังก์ชันนั้นไวต่อการเปลี่ยนแปลงของน้ำหนักแรกนั้นมากกว่า 32 เท่า ดังนั้นหากคุณขยับค่านั้นสักหน่อย มันจะทำให้เกิดการเปลี่ยนแปลงกับราคา และการเปลี่ยนแปลงนั้น มากกว่าน้ำหนักตัวที่สองที่กระดิกได้ 32 เท่า โดยส่วนตัวแล้ว ตอนที่ฉันเรียนรู้เกี่ยวกับ backpropagation เป็นครั้งแรก ฉันคิดว่าสิ่งที่น่าสับสนที่สุดคือเพียงสัญกรณ์และการไล่ตามดัชนีของมันทั้งหมด แต่เมื่อคุณแกะสิ่งที่แต่ละส่วนของอัลกอริธึมนี้ทำจริงๆ แล้ว เอฟเฟ็กต์แต่ละอย่างที่มีนั้นค่อนข้างจะเข้าใจได้ง่ายจริงๆ เพียงแต่มีการปรับเปลี่ยนเล็กๆ น้อยๆ มากมายซ้อนกันเป็นชั้นๆ ผมจะเริ่มต้นตรงนี้โดยไม่สนใจสัญกรณ์เลย และแค่ลองดูผลกระทบที่แต่ละตัวอย่างการฝึกมีต่อน้ำหนักและอคติ เนื่องจากฟังก์ชันต้นทุนเกี่ยวข้องกับการเฉลี่ยต้นทุนต่อตัวอย่างจากตัวอย่างการฝึกนับหมื่นทั้งหมด วิธีที่เราปรับน้ำหนักและอคติสำหรับขั้นตอนการไล่ระดับไล่ระดับขั้นเดียวยังขึ้นอยู่กับทุกตัวอย่างด้วย  หรือโดยหลักการแล้ว มันควรจะเป็น แต่เพื่อประสิทธิภาพในการคำนวณ เราจะใช้กลเม็ดเล็กๆ น้อยๆ ในภายหลังเพื่อป้องกันไม่ให้คุณต้องอ่านทุกตัวอย่างในทุกขั้นตอน ในกรณีอื่นๆ ตอนนี้ สิ่งที่เราจะทำคือมุ่งความสนใจไปที่ตัวอย่างเดียว นั่นคือรูป 2 นี้ ตัวอย่างการฝึกอบรมนี้ควรมีผลกระทบอย่างไรต่อการปรับน้ำหนักและอคติ สมมติว่าเราอยู่ในจุดที่เครือข่ายยังไม่ได้รับการฝึกฝนมาเป็นอย่างดี ดังนั้นการเปิดใช้งานในเอาต์พุตจึงดูค่อนข้างสุ่ม อาจเป็นประมาณ 0 5, 0. ",
  "model": "nmt",
  "time_range": [
   187.74,
   197.38
  ]
 },
 {
  "input": "Because the cost function involves averaging a certain cost per example over all the tens of thousands of training examples, the way we adjust the weights and biases for a single gradient descent step also depends on every single example. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   197.38,
   211.74
  ]
 },
 {
  "input": "Or rather, in principle it should, but for computational efficiency we'll do a little trick later to keep you from needing to hit every single example for every step. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   211.74,
   219.86
  ]
 },
 {
  "input": "In other cases, right now, all we're going to do is focus our attention on one single example, this image of a 2. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   219.86,
   226.78
  ]
 },
 {
  "input": "What effect should this one training example have on how the weights and biases get adjusted? ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   226.78,
   231.74
  ]
 },
 {
  "input": "Let's say we're at a point where the network is not well trained yet, so the activations in the output are going to look pretty random, maybe something like 0.5, 0.8, 0.2, on and on. ",
  "translatedText": "8, 0. ",
  "model": "nmt",
  "time_range": [
   231.74,
   242.78
  ]
 },
 {
  "input": "We can't directly change those activations, we only have influence on the weights and biases, but it's helpful to keep track of which adjustments we wish should take place to that output layer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   242.78,
   253.34
  ]
 },
 {
  "input": "And since we want it to classify the image as a 2, we want that third value to get nudged up while all the others get nudged down. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   253.34,
   261.7
  ]
 },
 {
  "input": "Moreover, the sizes of these nudges should be proportional to how far away each current value is from its target value. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   261.7,
   270.22
  ]
 },
 {
  "input": "For example, the increase to that number 2 neuron's activation is in a sense more important than the decrease to the number 8 neuron, which is already pretty close to where it should be. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   270.22,
   282.06
  ]
 },
 {
  "input": "So zooming in further, let's focus just on this one neuron, the one whose activation we wish to increase. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   282.06,
   287.9
  ]
 },
 {
  "input": "Remember, that activation is defined as a certain weighted sum of all the activations in the previous layer, plus a bias, which is all then plugged into something like the sigmoid squishification function, or a ReLU. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   287.9,
   301.9
  ]
 },
 {
  "input": "So there are three different avenues that can team up together to help increase that activation. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   301.9,
   308.06
  ]
 },
 {
  "input": "You can increase the bias, you can increase the weights, and you can change the activations from the previous layer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   308.06,
   315.3
  ]
 },
 {
  "input": "Focusing on how the weights should be adjusted, notice how the weights actually have differing levels of influence. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   315.3,
   321.46
  ]
 },
 {
  "input": "The connections with the brightest neurons from the preceding layer have the biggest effect since those weights are multiplied by larger activation values. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   321.46,
   331.42
  ]
 },
 {
  "input": "So if you were to increase one of those weights, it actually has a stronger influence on the ultimate cost function than increasing the weights of connections with dimmer neurons, at least as far as this one training example is concerned. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   331.42,
   344.02
  ]
 },
 {
  "input": "Remember, when we talk about gradient descent, we don't just care about whether each component should get nudged up or down, we care about which ones give you the most bang for your buck. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   344.02,
   354.02
  ]
 },
 {
  "input": "This, by the way, is at least somewhat reminiscent of a theory in neuroscience for how biological networks of neurons learn, Hebbian theory, often summed up in the phrase, neurons that fire together wire together. ",
  "translatedText": "2 ต่อไปและต่อไป เราไม่สามารถเปลี่ยนแปลงการเปิดใช้งานเหล่านั้นได้โดยตรง เราเพียงแต่มีอิทธิพลต่อน้ำหนักและอคติเท่านั้น แต่การติดตามว่าการปรับเปลี่ยนใดที่เราต้องการให้เกิดขึ้นกับเลเยอร์เอาต์พุตนั้นก็มีประโยชน์ และเนื่องจากเราต้องการให้มันจัดประเภทรูปภาพเป็น 2 เราจึงต้องการให้ค่าที่สามนั้นถูกปัดขึ้น ในขณะที่ค่าอื่นๆ ทั้งหมดจะถูกปัดลง นอกจากนี้ ขนาดของการกระตุ้นเตือนเหล่านี้ควรเป็นสัดส่วนกับระยะห่างระหว่างค่าปัจจุบันแต่ละค่าจากค่าเป้าหมาย ตัวอย่างเช่น การเพิ่มขึ้นของการกระตุ้นเซลล์ประสาทหมายเลข 2 นั้นมีความสำคัญมากกว่าการลดลงของเซลล์ประสาทหมายเลข 8 ซึ่งค่อนข้างใกล้เคียงกับตำแหน่งที่ควรจะเป็นอยู่แล้ว ถ้าจะขยายเข้าไปอีก เรามาดูที่เซลล์ประสาทอันเดียวนี้ ซึ่งเป็นเซลล์ประสาทที่เราอยากจะเพิ่มการกระตุ้น โปรดจำไว้ว่า การเปิดใช้งานนั้นถูกกำหนดให้เป็นผลรวมแบบถ่วงน้ำหนักของการเปิดใช้งานทั้งหมดในเลเยอร์ก่อนหน้า บวกกับไบแอส ซึ่งทั้งหมดจะถูกเสียบเข้ากับฟังก์ชันบางอย่าง เช่น ฟังก์ชัน sigmoid squishification หรือ ReLU ดังนั้นจึงมีสามช่องทางที่แตกต่างกันที่สามารถร่วมมือกันเพื่อช่วยเพิ่มการเปิดใช้งานนั้นได้  คุณสามารถเพิ่มอคติ คุณสามารถเพิ่มน้ำหนัก และคุณสามารถเปลี่ยนการเปิดใช้งานจากเลเยอร์ก่อนหน้าได้ โดยเน้นไปที่วิธีการปรับตุ้มน้ำหนัก ให้สังเกตว่าจริงๆ แล้วตุ้มน้ำหนักมีระดับอิทธิพลที่แตกต่างกันอย่างไร การเชื่อมต่อกับเซลล์ประสาทที่สว่างที่สุดจากเลเยอร์ก่อนหน้ามีผลมากที่สุดเนื่องจากน้ำหนักเหล่านั้นจะถูกคูณด้วยค่าการเปิดใช้งานที่มากขึ้น  ดังนั้น หากคุณจะเพิ่มน้ำหนักตัวใดตัวหนึ่ง จริงๆ แล้วมันจะมีอิทธิพลมากกว่าในฟังก์ชันต้นทุนขั้นสุดท้าย มากกว่าการเพิ่มน้ำหนักของการเชื่อมต่อกับเซลล์ประสาทที่หรี่ลง อย่างน้อยก็เท่าที่ตัวอย่างการฝึกนี้เกี่ยวข้อง โปรดจำไว้ว่า เมื่อเราพูดถึงการไล่ระดับไล่ระดับ เราไม่เพียงแต่สนใจว่าแต่ละองค์ประกอบควรถูกดันขึ้นหรือลง แต่เราสนใจว่าองค์ประกอบใดที่คุ้มค่าที่สุดสำหรับคุณ อย่างไรก็ตาม อย่างน้อยก็ค่อนข้างชวนให้นึกถึงทฤษฎีทางประสาทวิทยาศาสตร์ว่าเครือข่ายทางชีววิทยาของเซลล์ประสาทเรียนรู้ได้อย่างไร ทฤษฎีฮิบเบียน ซึ่งมักสรุปไว้ในวลีนี้ เซลล์ประสาทที่ยิงเชื่อมเข้าด้วยกัน การเพิ่มน้ำหนักครั้งใหญ่ที่สุด การเสริมสร้างการเชื่อมต่อที่ยิ่งใหญ่ที่สุดเกิดขึ้นระหว่างเซลล์ประสาทที่แอคทีฟมากที่สุดกับเซลล์ที่เราอยากให้มีความแอคทีฟมากขึ้น  ในแง่หนึ่ง เซลล์ประสาทที่กำลังส่งสัญญาณในขณะที่มองเห็น 2 จะมีการเชื่อมโยงอย่างมากกับเซลล์ประสาทที่ส่งสัญญาณเมื่อคิดถึงมัน เพื่อให้ชัดเจน ฉันไม่อยู่ในฐานะที่จะแถลงไม่ทางใดก็ทางหนึ่งว่าเครือข่ายเซลล์ประสาทเทียมมีพฤติกรรมเหมือนสมองทางชีววิทยาหรือไม่ และสิ่งนี้รวมเอาแนวคิดที่เชื่อมโยงเข้าด้วยกัน มาพร้อมกับเครื่องหมายดอกจันที่มีความหมายสองสามอัน แต่ถือเป็นการหลวมมาก การเปรียบเทียบ ฉันคิดว่ามันน่าสนใจที่จะทราบ อย่างไรก็ตาม วิธีที่สามที่เราสามารถช่วยเพิ่มการกระตุ้นของเซลล์ประสาทนี้คือโดยการเปลี่ยนการเปิดใช้งานทั้งหมดในเลเยอร์ก่อนหน้า กล่าวคือ ถ้าทุกสิ่งที่เชื่อมต่อกับเซลล์ประสาทหลัก 2 ที่มีน้ำหนักเป็นบวกนั้นสว่างขึ้น และถ้าทุกสิ่งที่เกี่ยวข้องกับน้ำหนักลบนั้นหรี่ลง เซลล์ประสาทหลัก 2 นั้นก็จะมีความกระตือรือร้นมากขึ้น และเช่นเดียวกับการเปลี่ยนแปลงน้ำหนัก คุณจะได้รับผลตอบแทนสูงสุดจากเงินที่เสียไปโดยการค้นหาการเปลี่ยนแปลงที่เป็นสัดส่วนกับขนาดของน้ำหนักที่สอดคล้องกัน แน่นอนว่าเราไม่สามารถมีอิทธิพลต่อการเปิดใช้งานเหล่านั้นได้โดยตรง เราทำได้เพียงควบคุมน้ำหนักและอคติเท่านั้น แต่เช่นเดียวกับเลเยอร์สุดท้าย การจดบันทึกว่าการเปลี่ยนแปลงที่ต้องการคืออะไรจะเป็นประโยชน์ แต่โปรดจำไว้ว่า เมื่อซูมออกหนึ่งขั้นที่นี่ นี่เป็นเพียงสิ่งที่เซลล์ประสาทเอาต์พุตหลัก 2 ต้องการเท่านั้น โปรดจำไว้ว่า เรายังต้องการให้เซลล์ประสาทอื่นๆ ทั้งหมดในเลเยอร์สุดท้ายมีการเคลื่อนไหวน้อยลง และเซลล์ประสาทเอาท์พุตอื่นๆ เหล่านั้นก็มีความคิดของตัวเองเกี่ยวกับสิ่งที่จะเกิดขึ้นกับเลเยอร์ที่สองถึงเลเยอร์สุดท้ายนั้น ดังนั้นความปรารถนาของเซลล์ประสาทหลัก 2 นี้จึงถูกรวมเข้ากับความปรารถนาของเซลล์ประสาทเอาท์พุตอื่นๆ ทั้งหมดสำหรับสิ่งที่จะเกิดขึ้นกับเลเยอร์ที่สองถึงเลเยอร์สุดท้ายนี้ อีกครั้งตามสัดส่วนของน้ำหนักที่สอดคล้องกัน และเป็นสัดส่วนกับจำนวนเซลล์ประสาทแต่ละอันที่ต้องการ เพื่อเปลี่ยน. ",
  "model": "nmt",
  "time_range": [
   354.02,
   366.94
  ]
 },
 {
  "input": "Here, the biggest increases to weights, the biggest strengthening of connections, happens between neurons which are the most active and the ones which we wish to become more active. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   366.94,
   378.1
  ]
 },
 {
  "input": "In a sense, the neurons that are firing while seeing a 2 get more strongly linked to those firing when thinking about it. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   378.1,
   385.44
  ]
 },
 {
  "input": "To be clear, I'm not in a position to make statements one way or another about whether artificial networks of neurons behave anything like biological brains, and this fires together wire together idea comes with a couple meaningful asterisks, but taken as a very loose analogy, I find it interesting to note. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   385.44,
   401.76
  ]
 },
 {
  "input": "Anyway, the third way we can help increase this neuron's activation is by changing all the activations in the previous layer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   401.76,
   409.36
  ]
 },
 {
  "input": "Namely, if everything connected to that digit 2 neuron with a positive weight got brighter, and if everything connected with a negative weight got dimmer, then that digit 2 neuron would become more active. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   409.36,
   422.68
  ]
 },
 {
  "input": "And similar to the weight changes, you're going to get the most bang for your buck by seeking changes that are proportional to the size of the corresponding weights. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   422.68,
   430.84
  ]
 },
 {
  "input": "Now of course, we cannot directly influence those activations, we only have control over the weights and biases. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   430.84,
   438.32
  ]
 },
 {
  "input": "But just as with the last layer, it's helpful to keep a note of what those desired changes are. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   438.32,
   443.96
  ]
 },
 {
  "input": "But keep in mind, zooming out one step here, this is only what that digit 2 output neuron wants. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   443.96,
   450.04
  ]
 },
 {
  "input": "Remember, we also want all the other neurons in the last layer to become less active, and each of those other output neurons has its own thoughts about what should happen to that second to last layer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   450.04,
   463.2
  ]
 },
 {
  "input": "So the desire of this digit 2 neuron is added together with the desires of all the other output neurons for what should happen to this second to last layer, again in proportion to the corresponding weights, and in proportion to how much each of those neurons needs to change. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   463.2,
   481.74
  ]
 },
 {
  "input": "This right here is where the idea of propagating backwards comes in. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   481.74,
   485.94
  ]
 },
 {
  "input": "By adding together all these desired effects, you basically get a list of nudges that you want to happen to this second to last layer. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   485.94,
   494.3
  ]
 },
 {
  "input": "And once you have those, you can recursively apply the same process to the relevant weights and biases that determine those values, repeating the same process I just walked through and moving backwards through the network. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   494.3,
   509.18
  ]
 },
 {
  "input": "And zooming out a bit further, remember that this is all just how a single training example wishes to nudge each one of those weights and biases. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   509.18,
   517.52
  ]
 },
 {
  "input": "If we only listened to what that 2 wanted, the network would ultimately be incentivized just to classify all images as a 2. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   517.52,
   524.14
  ]
 },
 {
  "input": "So what you do is go through this same backprop routine for every other training example, recording how each of them would like to change the weights and biases, and average together those desired changes. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   524.14,
   542.3
  ]
 },
 {
  "input": "This collection here of the averaged nudges to each weight and bias is, loosely speaking, the negative gradient of the cost function referenced in the last video, or at least something proportional to it. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   542.3,
   554.36
  ]
 },
 {
  "input": "I say loosely speaking only because I have yet to get quantitatively precise about those nudges, but if you understood every change I just referenced, why some are proportionally bigger than others, and how they all need to be added together, you understand the mechanics for what backpropagation is actually doing. ",
  "translatedText": "นี่คือจุดที่แนวคิดเรื่องการเผยแพร่แบบย้อนกลับเข้ามา เมื่อรวมเอฟเฟกต์ที่ต้องการทั้งหมดเข้าด้วยกัน คุณจะได้รับรายการการกระตุ้นเตือนที่คุณต้องการให้เกิดขึ้นในเลเยอร์ที่สองถึงเลเยอร์สุดท้ายนี้ และเมื่อคุณมีสิ่งเหล่านี้แล้ว คุณสามารถใช้กระบวนการเดิมซ้ำๆ กับน้ำหนักและอคติที่เกี่ยวข้องซึ่งกำหนดค่าเหล่านั้น ทำซ้ำขั้นตอนเดียวกับที่ฉันเพิ่งเดินผ่านและย้อนกลับผ่านเครือข่าย และเมื่อขยายออกไปอีกเล็กน้อย โปรดจำไว้ว่าทั้งหมดนี้เป็นเพียงวิธีที่ตัวอย่างการฝึกอบรมเดียวต้องการจะสะกิดน้ำหนักและอคติเหล่านั้น ถ้าเราเพียงแต่ฟังสิ่งที่ 2 นั้นต้องการ ในที่สุดเครือข่ายก็จะถูกจูงใจให้จัดประเภทภาพทั้งหมดเป็น 2 ดังนั้นสิ่งที่คุณทำคือทำตามขั้นตอน backprop เดียวกันนี้สำหรับตัวอย่างการฝึกอบรมอื่นๆ ทั้งหมด โดยบันทึกว่าแต่ละคนต้องการเปลี่ยนแปลงน้ำหนักและอคติอย่างไร และเฉลี่ยการเปลี่ยนแปลงที่ต้องการเหล่านั้นรวมกัน คอลเลกชันนี้ของการกระตุ้นโดยเฉลี่ยต่อน้ำหนักและอคติแต่ละอย่าง พูดง่ายๆ ก็คือความชันเชิงลบของฟังก์ชันต้นทุนที่อ้างอิงในวิดีโอที่แล้ว หรืออย่างน้อยก็มีบางอย่างที่เป็นสัดส่วนกับมัน ฉันพูดแบบหลวมๆ เพียงเพราะฉันยังไม่ได้รับความแม่นยำในเชิงปริมาณเกี่ยวกับการกระตุ้นเตือนเหล่านั้น แต่ถ้าคุณเข้าใจทุกการเปลี่ยนแปลงที่ฉันเพิ่งอ้างอิงไป เหตุใดการเปลี่ยนแปลงบางอย่างจึงใหญ่กว่าการเปลี่ยนแปลงอื่นๆ ตามสัดส่วน และวิธีที่จะรวมการเปลี่ยนแปลงทั้งหมดเข้าด้วยกัน คุณจะเข้าใจกลไกของ จริงๆ แล้ว backpropagation กำลังทำอะไรอยู่ อย่างไรก็ตาม ในทางปฏิบัติ คอมพิวเตอร์จะใช้เวลานานมากในการเพิ่มอิทธิพลของตัวอย่างการฝึกทุกตัวในทุกขั้นตอนการไล่ระดับสี ต่อไปนี้คือสิ่งที่ทำกันโดยทั่วไปแทน คุณสุ่มสับเปลี่ยนข้อมูลการฝึกของคุณและแบ่งเป็นกลุ่มย่อย สมมติว่าแต่ละอันมีตัวอย่างการฝึก 100 ตัวอย่าง จากนั้นคุณคำนวณขั้นตอนตามมินิแบทช์ ไม่ใช่การไล่ระดับที่แท้จริงของฟังก์ชันต้นทุน ซึ่งขึ้นอยู่กับข้อมูลการฝึกทั้งหมด ไม่ใช่ชุดย่อยเล็กๆ นี้ ดังนั้นจึงไม่ใช่การลงเนินที่มีประสิทธิภาพมากที่สุด แต่ชุดย่อยแต่ละชุดจะให้การประมาณที่ดีทีเดียว และที่สำคัญกว่านั้น ช่วยให้คุณเร่งความเร็วในการคำนวณได้อย่างมาก หากคุณต้องวางแผนเส้นทางของเครือข่ายของคุณภายใต้ต้นทุนที่เกี่ยวข้อง มันจะเหมือนกับคนเมาที่สะดุดล้มลงเนินอย่างไร้จุดหมายแต่ทำตามขั้นตอนอย่างรวดเร็ว แทนที่จะเป็นคนที่คำนวณอย่างรอบคอบเพื่อกำหนดทิศทางลงเนินที่แน่นอนของแต่ละก้าว ก่อนที่จะก้าวไปอย่างช้าๆและระมัดระวังไปในทิศทางนั้น เทคนิคนี้เรียกว่าการไล่ระดับสีแบบสุ่ม มีเรื่องเกิดขึ้นมากมายที่นี่ งั้นเรามาสรุปกันเองเลยดีไหม? ",
  "model": "nmt",
  "time_range": [
   554.36,
   574.1
  ]
 },
 {
  "input": "By the way, in practice, it takes computers an extremely long time to add up the influence of every training example every gradient descent step. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   574.1,
   583.12
  ]
 },
 {
  "input": "So here's what's commonly done instead. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   583.12,
   585.54
  ]
 },
 {
  "input": "You randomly shuffle your training data and divide it into a whole bunch of mini-batches, let's say each one having 100 training examples. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   585.54,
   593.38
  ]
 },
 {
  "input": "Then you compute a step according to the mini-batch. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   593.38,
   596.98
  ]
 },
 {
  "input": "It's not the actual gradient of the cost function, which depends on all of the training data, not this tiny subset, so it's not the most efficient step downhill, but each mini-batch does give you a pretty good approximation, and more importantly it gives you a significant computational speedup. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   596.98,
   612.9
  ]
 },
 {
  "input": "If you were to plot the trajectory of your network under the relevant cost surface, it would be a little more like a drunk man stumbling aimlessly down a hill but taking quick steps, rather than a carefully calculating man determining the exact downhill direction of each step before taking a very slow and careful step in that direction. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   612.9,
   631.62
  ]
 },
 {
  "input": "This technique is referred to as stochastic gradient descent. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   631.62,
   635.2
  ]
 },
 {
  "input": "There's a lot going on here, so let's just sum it up for ourselves, shall we? ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   635.2,
   640.4
  ]
 },
 {
  "input": "Backpropagation is the algorithm for determining how a single training example would like to nudge the weights and biases, not just in terms of whether they should go up or down, but in terms of what relative proportions to those changes cause the most rapid decrease to the cost. ",
  "translatedText": "Backpropagation เป็นอัลกอริธึมสำหรับพิจารณาว่าตัวอย่างการฝึกเดี่ยวต้องการจะสะกิดน้ำหนักและอคติอย่างไร ไม่ใช่แค่ในแง่ของว่าควรจะขึ้นหรือลง แต่ในแง่ของสัดส่วนสัมพันธ์กับการเปลี่ยนแปลงเหล่านั้นที่ทำให้การลดลงอย่างรวดเร็วที่สุด ค่าใช้จ่าย. ",
  "model": "nmt",
  "time_range": [
   640.4,
   656.24
  ]
 },
 {
  "input": "A true gradient descent step would involve doing this for all your tens and thousands of training examples and averaging the desired changes you get, but that's computationally slow, so instead you randomly subdivide the data into mini-batches and compute each step with respect to a mini-batch. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   656.24,
   674.0
  ]
 },
 {
  "input": "Repeatedly going through all the mini-batches and making these adjustments, you will converge towards a local minimum of the cost function, which is to say your network will end up doing a really good job on the training examples. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   674.0,
   687.54
  ]
 },
 {
  "input": "So with all of that said, every line of code that would go into implementing backprop actually corresponds with something you have now seen, at least in informal terms. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   687.54,
   697.68
  ]
 },
 {
  "input": "But sometimes knowing what the math does is only half the battle, and just representing the damn thing is where it gets all muddled and confusing. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   697.68,
   704.78
  ]
 },
 {
  "input": "So, for those of you who do want to go deeper, the next video goes through the same ideas that were just presented here, but in terms of the underlying calculus, which should hopefully make it a little more familiar as you see the topic in other resources. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   704.78,
   717.46
  ]
 },
 {
  "input": "Before that, one thing worth emphasizing is that for this algorithm to work, and this goes for all sorts of machine learning beyond just neural networks, you need a lot of training data. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   717.46,
   726.84
  ]
 },
 {
  "input": "In our case, one thing that makes handwritten digits such a nice example is that there exists the MNIST database, with so many examples that have been labeled by humans. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   726.84,
   735.38
  ]
 },
 {
  "input": "So a common challenge that those of you working in machine learning will be familiar with is just getting the labeled training data you actually need, whether that's having people label tens of thousands of images, or whatever other data type you might be dealing with. ",
  "translatedText": "",
  "model": "nmt",
  "time_range": [
   735.38,
   747.4
  ]
 }
]