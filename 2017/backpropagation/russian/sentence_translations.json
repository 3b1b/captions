[
 {
  "input": "Here, we tackle backpropagation, the core algorithm behind how neural networks learn.",
  "translatedText": "Здесь мы занимаемся обратным распространением ошибки — основным алгоритмом обучения нейронных сетей.",
  "from_community_srt": "Рассмотрим обратное распространение, основной алгоритм обучения нейронных сетей.",
  "n_reviews": 0,
  "start": 4.06,
  "end": 8.88
 },
 {
  "input": "After a quick recap for where we are, the first thing I'll do is an intuitive walkthrough for what the algorithm is actually doing, without any reference to the formulas.",
  "translatedText": "После краткого обзора того, где мы находимся, первое, что я сделаю, — это интуитивно понятное описание того, что на самом деле делает алгоритм, без каких-либо ссылок на формулы.",
  "from_community_srt": "После краткого напоминания о том, что мы узнали, я расскажу о том, что на самом деле делает алгоритм без ссылок на формулы.",
  "n_reviews": 0,
  "start": 9.4,
  "end": 17.0
 },
 {
  "input": "Then, for those of you who do want to dive into the math, the next video goes into the calculus underlying all this.",
  "translatedText": "Затем для тех из вас, кто хочет погрузиться в математику, следующее видео посвящено расчетам, лежащим в основе всего этого.",
  "from_community_srt": "Для тех из вас, кто хочет погрузиться в математику, следующее видео рассматривает математическое обоснование, лежащее в основе всего этого.",
  "n_reviews": 0,
  "start": 17.66,
  "end": 23.02
 },
 {
  "input": "If you watched the last two videos, or if you're just jumping in with the appropriate background, you know what a neural network is, and how it feeds forward information.",
  "translatedText": "Если вы смотрели два последних видео или просто знакомитесь с соответствующей информацией, вы знаете, что такое нейронная сеть и как она передает информацию.",
  "from_community_srt": "Если вы посмотрели последние два видео или вы просто пропустили, т.к. знакомы с этим, то вы знаете, что такое нейронная сеть и как она передает информацию вперед.",
  "n_reviews": 0,
  "start": 23.82,
  "end": 31.0
 },
 {
  "input": "Here, we're doing the classic example of recognizing handwritten digits whose pixel values get fed into the first layer of the network with 784 neurons, and I've been showing a network with two hidden layers having just 16 neurons each, and an output layer of 10 neurons, indicating which digit the network is choosing as its answer.",
  "translatedText": "Здесь мы приводим классический пример распознавания рукописных цифр, значения пикселей которых передаются в первый слой сети с 784 нейронами, и я показываю сеть с двумя скрытыми слоями, имеющими всего по 16 нейронов каждый, и выходом слой из 10 нейронов, указывающий, какую цифру сеть выбирает в качестве ответа.",
  "from_community_srt": "Здесь мы делаем классический пример распознавания рукописных цифр, чьи значения пикселей поступают в первый слой сети с 784 нейронами. Я показываю сеть с двумя скрытыми слоями, имеющими всего 16 нейронов, и выходной слой из 10 нейронов, указывающий, какую цифру выбирает сеть в качестве своего ответа.",
  "n_reviews": 0,
  "start": 31.68,
  "end": 49.04
 },
 {
  "input": "I'm also expecting you to understand gradient descent, as described in the last video, and how what we mean by learning is that we want to find which weights and biases minimize a certain cost function.",
  "translatedText": "Я также ожидаю, что вы поймете градиентный спуск, как описано в последнем видео, и то, что под обучением мы подразумеваем то, что хотим найти, какие веса и смещения минимизируют определенную функцию стоимости.",
  "from_community_srt": "Я также надеюсь, что вы поняли метод градиентного спуска, из последнего видео, и как мы понимаем, что мы хотим найти, какие веса и смещения сводят к минимуму определенную функцию стоимости.",
  "n_reviews": 0,
  "start": 50.04,
  "end": 61.26
 },
 {
  "input": "As a quick reminder, for the cost of a single training example, you take the output the network gives, along with the output you wanted it to give, and add up the squares of the differences between each component.",
  "translatedText": "Напоминаем, что для расчета стоимости одного обучающего примера вы берете выходные данные, которые дает сеть, а также выходные данные, которые вы хотели от нее получить, и складываете квадраты различий между каждым компонентом.",
  "from_community_srt": "В качестве быстрого напоминания о стоимости одного учебного примера, то, что вы делаете, - это результат, который выдает сеть, наряду с выходом, который вы хотели, бы получить, и вы просто добавляете квадраты разности между каждым компонентом.",
  "n_reviews": 0,
  "start": 62.04,
  "end": 74.6
 },
 {
  "input": "Doing this for all of your tens of thousands of training examples and averaging the results, this gives you the total cost of the network.",
  "translatedText": "Проделав это для всех ваших десятков тысяч обучающих примеров и усреднив результаты, вы получите общую стоимость сети.",
  "from_community_srt": "Выполняя это для всех ваших десятков тысяч примеров обучения и усредняя результаты, вы получаете общую стоимость сети.",
  "n_reviews": 0,
  "start": 75.38,
  "end": 82.2
 },
 {
  "input": "And as if that's not enough to think about, as described in the last video, the thing that we're looking for is the negative gradient of this cost function, which tells you how you need to change all of the weights and biases, all of these connections, so as to most efficiently decrease the cost.",
  "translatedText": "И как будто этого недостаточно для размышлений, как описано в последнем видео, мы ищем отрицательный градиент этой функции стоимости, которая говорит вам, как вам нужно изменить все веса и смещения, все этих соединений, чтобы наиболее эффективно снизить стоимость.",
  "from_community_srt": "И, так как этого недостаточно для ответа, как описано в последнем видео, то, мы ищем отрицательный градиент этой функции стоимости, который показывает, как вам нужно изменить все веса и смещения каждого соединения, чтобы наиболее эффективно снизить стоимость.",
  "n_reviews": 0,
  "start": 82.2,
  "end": 98.32
 },
 {
  "input": "Backpropagation, the topic of this video, is an algorithm for computing that crazy complicated gradient.",
  "translatedText": "Обратное распространение ошибки, тема этого видео, представляет собой алгоритм расчета этого безумно сложного градиента.",
  "from_community_srt": "Обратное распространение, тема этого видео, является алгоритмом вычисления этого сумасшедшего сложного градиента.",
  "n_reviews": 0,
  "start": 103.26,
  "end": 108.58
 },
 {
  "input": "And the one idea from the last video that I really want you to hold firmly in your mind right now is that because thinking of the gradient vector as a direction in 13,000 dimensions is, to put it lightly, beyond the scope of our imaginations, there's another way you can think about it.",
  "translatedText": "И единственная идея из последнего видео, которую я действительно хочу, чтобы вы прямо сейчас твердо запомнили, заключается в том, что, поскольку думать о векторе градиента как о направлении в 13 000 измерений, мягко говоря, за пределами нашего воображения, существует еще один способ подумать об этом.",
  "from_community_srt": "И одна из идей из последнего видео, которую я хочу донести проще, состоит в том, что, поскольку мысли о векторе градиенте как о направлениях в 13000 измерениях, мягко говоря, вне сферы нашего воображения, есть еще один способ,",
  "n_reviews": 0,
  "start": 109.14,
  "end": 123.58
 },
 {
  "input": "The magnitude of each component here is telling you how sensitive the cost function is to each weight and bias.",
  "translatedText": "Величина каждого компонента здесь говорит вам, насколько чувствительна функция стоимости к каждому весу и смещению.",
  "from_community_srt": "которым вы можете думать об этом: Величина каждого компонента здесь говорит вам насколько чувствительна функция стоимости к каждому весу и смещению.",
  "n_reviews": 0,
  "start": 124.6,
  "end": 130.94
 },
 {
  "input": "For example, let's say you go through the process I'm about to describe, and you compute the negative gradient, and the component associated with the weight on this edge here comes out to be 3.2, while the component associated with this edge here comes out as 0.1.",
  "translatedText": "Например, предположим, что вы выполняете процесс, который я собираюсь описать, и вычисляете отрицательный градиент, и компонент, связанный с весом на этом ребре, оказывается равным 3,2, в то время как компонент, связанный с этим ребром, равен выходит как 0,1.",
  "from_community_srt": "Например, вы повторяете процесс, который я описываю, и вы вычисляете отрицательный градиент, и компонент, связанный с весом на этом крае, составляет 3,2, в то время как компонент, связанный с этим ребром, отображается как 0,1.",
  "n_reviews": 0,
  "start": 131.8,
  "end": 146.26
 },
 {
  "input": "The way you would interpret that is that the cost of the function is 32 times more sensitive to changes in that first weight, so if you were to wiggle that value just a little bit, it's going to cause some change to the cost, and that change is 32 times greater than what the same wiggle to that second weight would give.",
  "translatedText": "Вы можете интерпретировать это следующим образом: стоимость функции в 32 раза более чувствительна к изменениям первого веса, поэтому, если вы немного измените это значение, это приведет к некоторому изменению стоимости, и это Изменение в 32 раза больше, чем то же самое покачивание второго веса.",
  "from_community_srt": "Таким образом, стоимость функции в 32 раза более чувствительна к изменениям первого веса. Поэтому, если вы хотите немного изменить значение, то это вызовет некоторое изменение стоимости, и это изменение в 32 раза больше, чем то, что даст такое же изменение второго веса.",
  "n_reviews": 0,
  "start": 146.82,
  "end": 163.06
 },
 {
  "input": "Personally, when I was first learning about backpropagation, I think the most confusing aspect was just the notation and the index chasing of it all.",
  "translatedText": "Лично, когда я впервые узнал об обратном распространении ошибки, я думаю, что самым запутанным аспектом была сама нотация и погоня за индексом во всем этом.",
  "from_community_srt": "Когда я впервые узнал о обратном распространении, мне казалось, что самым запутанным аспектом было обозначение и индекс.",
  "n_reviews": 0,
  "start": 168.42,
  "end": 175.74
 },
 {
  "input": "But once you unwrap what each part of this algorithm is really doing, each individual effect it's having is actually pretty intuitive, it's just that there's a lot of little adjustments getting layered on top of each other.",
  "translatedText": "Но как только вы разберетесь, что на самом деле делает каждая часть этого алгоритма, каждый отдельный эффект, который он оказывает, на самом деле довольно интуитивен, просто есть много маленьких настроек, накладываемых друг на друга.",
  "from_community_srt": "Но как только вы разворачиваете  каждую часть этого алгоритма, каждый отдельный элемент на самом деле довольно понятен. Получается множество небольших корректировок, которые накладываются друг на друга.",
  "n_reviews": 0,
  "start": 176.22,
  "end": 186.64
 },
 {
  "input": "So I'm going to start things off here with a complete disregard for the notation, and just step through the effects each training example has on the weights and biases.",
  "translatedText": "Итак, я собираюсь начать здесь с полного игнорирования обозначений и просто пошагово рассмотреть влияние каждого обучающего примера на веса и смещения.",
  "from_community_srt": "Поэтому я собираюсь пренебречь обозначениями и просто рассмотрю результаты того, как каждый пример обучения звасисит от веса и смещения.",
  "n_reviews": 0,
  "start": 187.74,
  "end": 196.12
 },
 {
  "input": "Because the cost function involves averaging a certain cost per example over all the tens of thousands of training examples, the way we adjust the weights and biases for a single gradient descent step also depends on every single example.",
  "translatedText": "Поскольку функция стоимости включает в себя усреднение определенной стоимости на пример по всем десяткам тысяч обучающих примеров, то, как мы корректируем веса и смещения для одного шага градиентного спуска, также зависит от каждого отдельного примера.",
  "from_community_srt": "Поскольку функция стоимости включает усредную определенную стоимость по всем десяткам тысяч примеров обучения, способ, которым мы корректируем веса и смещения для одного шага уменьшения градиента также зависит от каждого отдельного примера,",
  "n_reviews": 0,
  "start": 197.02,
  "end": 211.04
 },
 {
  "input": "Or rather, in principle it should, but for computational efficiency we'll do a little trick later to keep you from needing to hit every single example for every step.",
  "translatedText": "Вернее, в принципе так и должно быть, но для эффективности вычислений мы позже сделаем небольшой трюк, чтобы вам не приходилось обрабатывать каждый пример на каждом шаге.",
  "from_community_srt": "или, скорее, должен, но для вычислительной эффективности позже мы собираемся сделать небольшой трюк чтобы вы не нуждались в каждом конкретном примере для каждого отдельного шага.",
  "n_reviews": 0,
  "start": 211.68,
  "end": 219.2
 },
 {
  "input": "In other cases, right now, all we're going to do is focus our attention on one single example, this image of a 2.",
  "translatedText": "В других случаях прямо сейчас все, что нам нужно сделать, это сосредоточить внимание на одном-единственном примере, на этом изображении 2.",
  "from_community_srt": "Другое дело, что мы собираемся сосредоточить наше внимание на одном примере: изображение цифры 2.",
  "n_reviews": 0,
  "start": 219.2,
  "end": 225.96
 },
 {
  "input": "What effect should this one training example have on how the weights and biases get adjusted?",
  "translatedText": "Какое влияние должен оказать этот обучающий пример на корректировку весов и смещений?",
  "from_community_srt": "Какое влияние должен иметь этот пример тренировки на то, как корректируются веса и смещения? Допустим,",
  "n_reviews": 0,
  "start": 226.72,
  "end": 231.48
 },
 {
  "input": "Let's say we're at a point where the network is not well trained yet, so the activations in the output are going to look pretty random, maybe something like 0.5, 0.8, 0.2, on and on.",
  "translatedText": "Допустим, мы находимся в точке, где сеть еще недостаточно хорошо обучена, поэтому активации в выходных данных будут выглядеть довольно случайными, может быть, что-то вроде 0,5, 0,8, 0,2 и так далее.",
  "from_community_srt": "мы находимся в точке, где сеть еще недостаточно подготовлена, поэтому активации на выходе будут выглядеть довольно случайными, может быть, что-то вроде 0,5, 0,8, 0,2, и так далее.",
  "n_reviews": 0,
  "start": 232.68,
  "end": 242.0
 },
 {
  "input": "We can't directly change those activations, we only have influence on the weights and biases.",
  "translatedText": "Мы не можем напрямую изменить эти активации, мы можем влиять только на веса и предвзятости.",
  "from_community_srt": "Мы не можем напрямую изменять эти активации,",
  "n_reviews": 0,
  "start": 242.52,
  "end": 247.16
 },
 {
  "input": "But it's helpful to keep track of which adjustments we wish should take place to that output layer.",
  "translatedText": "Но полезно отслеживать, какие изменения мы хотим внести в этот выходной слой.",
  "from_community_srt": "мы можем влиять только на вес и смещение, но полезно отслеживать, какие корректировки должны быть для этого выходного слоя, и поскольку мы хотим,",
  "n_reviews": 0,
  "start": 247.16,
  "end": 252.58
 },
 {
  "input": "And since we want it to classify the image as a 2, we want that third value to get nudged up while all the others get nudged down.",
  "translatedText": "А поскольку мы хотим, чтобы изображение классифицировалось как 2, мы хотим, чтобы это третье значение было смещено вверх, а все остальные — вниз.",
  "from_community_srt": "чтобы он классифицировал изображение как 2, мы хотим, чтобы третье значение увеличивалось, а все остальные уменьшались.",
  "n_reviews": 0,
  "start": 253.36,
  "end": 261.26
 },
 {
  "input": "Moreover, the sizes of these nudges should be proportional to how far away each current value is from its target value.",
  "translatedText": "Более того, размеры этих подталкиваний должны быть пропорциональны тому, насколько далеко каждое текущее значение находится от целевого значения.",
  "from_community_srt": "Более того, размеры этих изменений должны быть пропорциональны тому, насколько большая разница между текущим и целевым значеним.",
  "n_reviews": 0,
  "start": 262.06,
  "end": 269.52
 },
 {
  "input": "For example, the increase to that number 2 neuron's activation is in a sense more important than the decrease to the number 8 neuron, which is already pretty close to where it should be.",
  "translatedText": "Например, увеличение активации нейрона номер 2 в некотором смысле более важно, чем снижение активности нейрона номер 8, который уже довольно близок к тому, где он должен быть.",
  "from_community_srt": "Например, увеличение к активации нейронов номер 2 является более важным, чем уменьшение числа нейронов числа 8, который уже близок к тому, где он должен быть.",
  "n_reviews": 0,
  "start": 270.22,
  "end": 280.9
 },
 {
  "input": "So zooming in further, let's focus just on this one neuron, the one whose activation we wish to increase.",
  "translatedText": "Итак, увеличивая масштаб, давайте сосредоточимся только на этом нейроне, том, чью активацию мы хотим увеличить.",
  "from_community_srt": "Поэтому, увеличивая масштаб, давайте сосредоточимся только на этом нейроне, активация которого мы хотим увеличить.",
  "n_reviews": 0,
  "start": 282.04,
  "end": 287.28
 },
 {
  "input": "Remember, that activation is defined as a certain weighted sum of all the activations in the previous layer, plus a bias, which is all then plugged into something like the sigmoid squishification function, or a ReLU.",
  "translatedText": "Помните, что эта активация определяется как определенная взвешенная сумма всех активаций на предыдущем уровне плюс смещение, которое затем подключается к чему-то вроде функции сжатия сигмовидной кишки или ReLU.",
  "from_community_srt": "Помните, что активация определяется как определенную взвешенную сумму всех активаций в предыдущем слое плюс смещение, которые подключены к чему-то вроде функции сигмовидного сгибания или ReLU, Таким образом,",
  "n_reviews": 0,
  "start": 288.18,
  "end": 301.04
 },
 {
  "input": "So there are three different avenues that can team up together to help increase that activation.",
  "translatedText": "Итак, есть три разных направления, которые можно объединить, чтобы повысить эту активацию.",
  "from_community_srt": "есть три разных способа, которые могут объединяться,",
  "n_reviews": 0,
  "start": 301.64,
  "end": 307.02
 },
 {
  "input": "You can increase the bias, you can increase the weights, and you can change the activations from the previous layer.",
  "translatedText": "Вы можете увеличить смещение, увеличить веса и изменить активации предыдущего слоя.",
  "from_community_srt": "чтобы помочь увеличить эту активацию: вы можете увеличить смещение, вы можете увеличить вес, и вы можете изменить активацию нейронов в предыдущем слое.",
  "n_reviews": 0,
  "start": 307.44,
  "end": 314.04
 },
 {
  "input": "Focusing on how the weights should be adjusted, notice how the weights actually have differing levels of influence.",
  "translatedText": "Сосредоточив внимание на том, как следует настраивать веса, обратите внимание на то, что на самом деле веса имеют разные уровни влияния.",
  "from_community_srt": "Сосредоточив внимание на том, как следует регулировать вес, обратите внимание на то,",
  "n_reviews": 0,
  "start": 314.94,
  "end": 320.86
 },
 {
  "input": "The connections with the brightest neurons from the preceding layer have the biggest effect since those weights are multiplied by larger activation values.",
  "translatedText": "Связи с самыми яркими нейронами предыдущего слоя имеют наибольший эффект, поскольку эти веса умножаются на более высокие значения активации.",
  "from_community_srt": "как веса имеют разные уровни влияния: связи с самыми яркими нейронами из предыдущего слоя имеют наибольший эффект, поскольку эти веса умножаются на большие значения активации.",
  "n_reviews": 0,
  "start": 321.44,
  "end": 329.1
 },
 {
  "input": "So if you were to increase one of those weights, it actually has a stronger influence on the ultimate cost function than increasing the weights of connections with dimmer neurons, at least as far as this one training example is concerned.",
  "translatedText": "Таким образом, если вы увеличите один из этих весов, это на самом деле окажет более сильное влияние на конечную функцию стоимости, чем увеличение весов связей с более тусклыми нейронами, по крайней мере, в том, что касается этого обучающего примера.",
  "from_community_srt": "Поэтому, если вы должны увеличить один из этих весов, он фактически оказывает более сильное влияние на конечную функцию стоимости чем увеличение весов связей с тусклыми нейронами, по крайней мере, насколько это касается одного примера обучения.",
  "n_reviews": 0,
  "start": 331.46,
  "end": 343.48
 },
 {
  "input": "Remember, when we talk about gradient descent, we don't just care about whether each component should get nudged up or down, we care about which ones give you the most bang for your buck.",
  "translatedText": "Помните, когда мы говорим о градиентном спуске, нас волнует не только то, должен ли каждый компонент сдвигаться вверх или вниз, нас заботит то, какие из них принесут вам максимальную отдачу от затраченных средств.",
  "from_community_srt": "Помните, когда мы говорили о градиентном уменьшении, мы не просто заботимся о том, нужно ли увеличивать или уменьшать каждый компонент, мы заботимся о том, какие из них дают вам наибольший эффект.",
  "n_reviews": 0,
  "start": 344.42,
  "end": 353.22
 },
 {
  "input": "This, by the way, is at least somewhat reminiscent of a theory in neuroscience for how biological networks of neurons learn, Hebbian theory, often summed up in the phrase, neurons that fire together wire together.",
  "translatedText": "Это, кстати, по крайней мере чем-то напоминает теорию нейронауки о том, как обучаются биологические сети нейронов, теорию Хебба, которую часто суммируют фразой: «нейроны, которые срабатывают вместе, соединяются друг с другом».",
  "from_community_srt": "Это, кстати, несколько напоминает теорию в области нейронауки как изучают биологические нейронные сети Теория Hebbian - часто суммируется во фразе «нейроны, которые запускаются вместе,",
  "n_reviews": 0,
  "start": 355.02,
  "end": 366.46
 },
 {
  "input": "Here, the biggest increases to weights, the biggest strengthening of connections, happens between neurons which are the most active, and the ones which we wish to become more active.",
  "translatedText": "Здесь наибольшее увеличение веса, наибольшее усиление связей происходит между нейронами, которые наиболее активны, и теми, которые мы хотим активизировать.",
  "from_community_srt": "соединяются». Здесь наибольшее увеличение веса, наибольшее усиление связей, происходит между наиболее активными нейронами, и те, которые мы хотим активизировать.",
  "n_reviews": 0,
  "start": 367.26,
  "end": 377.28
 },
 {
  "input": "In a sense, the neurons that are firing while seeing a 2 get more strongly linked to those are the ones firing when thinking about a 2.",
  "translatedText": "В каком-то смысле нейроны, которые срабатывают, когда видят цифру 2, становятся более прочно связанными с ними, когда мы думаем о цифре 2.",
  "from_community_srt": "В некотором смысле, нейроны, стреляющие, видя 2, сильнее привязывайтесь к тем, кто стреляет, думая о 2.",
  "n_reviews": 0,
  "start": 377.94,
  "end": 384.48
 },
 {
  "input": "To be clear, I'm not in a position to make statements one way or another about whether artificial networks of neurons behave anything like biological brains, and this fires together wire together idea comes with a couple meaningful asterisks, but taken as a very loose analogy, I find it interesting to note.",
  "translatedText": "Чтобы внести ясность, я не могу так или иначе делать заявления о том, ведут ли искусственные сети нейронов что-то вроде биологического мозга, и эта идея «сжигает вместе, соединяет вместе» сопровождается парой значащих звездочек, но воспринимается как очень расплывчатая. аналогию, мне интересно отметить.",
  "from_community_srt": "Чтобы быть ясным, я действительно не в состоянии делать заявления так или иначе о том, как искусственные сети нейронов ведут себя как биологические мозги, и эта идея объединяет вместе целую пару значащих звездочек. Но, как очень простая аналогия, мне интересно отметить.",
  "n_reviews": 0,
  "start": 385.4,
  "end": 401.02
 },
 {
  "input": "Anyway, the third way we can help increase this neuron's activation is by changing all the activations in the previous layer.",
  "translatedText": "В любом случае, третий способ увеличить активацию этого нейрона — это изменить все активации в предыдущем слое.",
  "from_community_srt": "Во всяком случае, третий способ, которым мы можем помочь увеличить активацию нейрона это изменение всех активаций в предыдущем слое,",
  "n_reviews": 0,
  "start": 401.94,
  "end": 409.04
 },
 {
  "input": "Namely, if everything connected to that digit 2 neuron with a positive weight got brighter, and if everything connected with a negative weight got dimmer, then that digit 2 neuron would become more active.",
  "translatedText": "А именно, если все, что связано с нейроном цифры 2 с положительным весом, станет ярче, а если все, что связано с отрицательным весом, станет тусклее, то этот нейрон цифры 2 станет более активным.",
  "from_community_srt": "а именно, если все, что связано с этой цифрой 2 нейроном с положительным весом, стало ярче, и если все, что связано с отрицательным весом, уменьшилось, то эта цифра 2 нейрона станет более активной.",
  "n_reviews": 0,
  "start": 409.04,
  "end": 420.68
 },
 {
  "input": "And similar to the weight changes, you're going to get the most bang for your buck by seeking changes that are proportional to the size of the corresponding weights.",
  "translatedText": "И, как и в случае с изменением веса, вы получите максимальную отдачу от вложенных средств, добиваясь изменений, пропорциональных размеру соответствующих весов.",
  "from_community_srt": "И, подобно изменениям веса, вы получите максимальную отдачу от своего доллара путем поиска изменений, которые пропорциональны размеру соответствующих весов.",
  "n_reviews": 0,
  "start": 422.54,
  "end": 430.28
 },
 {
  "input": "Now of course, we cannot directly influence those activations, we only have control over the weights and biases.",
  "translatedText": "Конечно, мы не можем напрямую влиять на эти активации, мы можем контролировать только веса и предвзятости.",
  "from_community_srt": "Теперь, конечно, мы не можем напрямую влиять на эти активации, мы имеем только контроль над весами и предубеждениями.",
  "n_reviews": 0,
  "start": 432.14,
  "end": 437.48
 },
 {
  "input": "But just as with the last layer, it's helpful to keep a note of what those desired changes are.",
  "translatedText": "Но, как и в случае с последним слоем, полезно запомнить желаемые изменения.",
  "from_community_srt": "Но так же, как и в последнем слое, полезно просто отметить, что это за желаемые изменения.",
  "n_reviews": 0,
  "start": 437.48,
  "end": 444.12
 },
 {
  "input": "But keep in mind, zooming out one step here, this is only what that digit 2 output neuron wants.",
  "translatedText": "Но имейте в виду, что уменьшение масштаба здесь на один шаг — это всего лишь то, чего хочет выходной нейрон с цифрой 2.",
  "from_community_srt": "Но имейте в виду, уменьшая на один шаг здесь, это только то, что хочет эта цифра 2.",
  "n_reviews": 0,
  "start": 444.58,
  "end": 449.2
 },
 {
  "input": "Remember, we also want all the other neurons in the last layer to become less active, and each of those other output neurons has its own thoughts about what should happen to that second to last layer.",
  "translatedText": "Помните, мы также хотим, чтобы все остальные нейроны последнего слоя стали менее активными, и каждый из этих выходных нейронов имеет свои собственные мысли о том, что должно произойти с предпоследним слоем.",
  "from_community_srt": "Помните, мы также хотим, чтобы все остальные нейроны в последнем слое стали менее активными, и каждый из этих других выходных нейронов имеет свои собственные мысли о том, что должно произойти с этим вторым-последним слоем.",
  "n_reviews": 0,
  "start": 449.76,
  "end": 459.6
 },
 {
  "input": "So, the desire of this digit 2 neuron is added together with the desires of all the other output neurons for what should happen to this second to last layer, again in proportion to the corresponding weights, and in proportion to how much each of those neurons needs to change.",
  "translatedText": "Итак, желание этого нейрона с цифрой 2 суммируется с желаниями всех остальных выходных нейронов относительно того, что должно произойти с этим предпоследним слоем, опять же пропорционально соответствующим весам и пропорционально тому, насколько сильно каждый из этих нейронов необходимо изменить.",
  "from_community_srt": "Итак, желание этой цифры 2 нейрона добавляется вместе с желаниями всех других выходных нейронов что должно произойти с этим вторым-последним слоем. Опять же, пропорционально соответствующим весам, и пропорционально тому, как каждый из этих нейронов должен измениться.",
  "n_reviews": 0,
  "start": 462.7,
  "end": 480.72
 },
 {
  "input": "This right here is where the idea of propagating backwards comes in.",
  "translatedText": "Именно здесь возникает идея обратного распространения.",
  "from_community_srt": "Здесь прямо возникает идея распространения назад.",
  "n_reviews": 0,
  "start": 481.6,
  "end": 485.48
 },
 {
  "input": "By adding together all these desired effects, you basically get a list of nudges that you want to happen to this second to last layer.",
  "translatedText": "Сложив все эти желаемые эффекты, вы, по сути, получаете список изменений, которые вы хотите сделать с предпоследним слоем.",
  "from_community_srt": "Объединив все эти желаемые эффекты, вы в основном получаете список подтасовки, которые вы хотите выполнить со вторым до последнего уровня.",
  "n_reviews": 0,
  "start": 485.82,
  "end": 493.36
 },
 {
  "input": "And once you have those, you can recursively apply the same process to the relevant weights and biases that determine those values, repeating the same process I just walked through and moving backwards through the network.",
  "translatedText": "И как только они у вас появятся, вы сможете рекурсивно применить тот же процесс к соответствующим весам и смещениям, которые определяют эти значения, повторяя тот же процесс, который я только что прошел, и двигаясь назад по сети.",
  "from_community_srt": "И как только вы их получите, вы можете рекурсивно применять тот же процесс к соответствующим весам и смещениям, которые определяют эти значения, повторяя тот же процесс, я просто прошел и двинулся назад по сети.",
  "n_reviews": 0,
  "start": 494.22,
  "end": 505.1
 },
 {
  "input": "And zooming out a bit further, remember that this is all just how a single training example wishes to nudge each one of those weights and biases.",
  "translatedText": "И, немного уменьшив масштаб, помните, что все это всего лишь то, как один обучающий пример хочет подтолкнуть каждый из этих весов и предубеждений.",
  "from_community_srt": "И немного увеличивая масштаб, помните, что все это просто как один пример тренинга хочет подтолкнуть каждый из этих весов и предубеждений.",
  "n_reviews": 0,
  "start": 508.96,
  "end": 517.0
 },
 {
  "input": "If we only listened to what that 2 wanted, the network would ultimately be incentivized just to classify all images as a 2.",
  "translatedText": "Если бы мы слушали только то, чего хочет эта цифра 2, сеть в конечном итоге была бы заинтересована просто классифицировать все изображения как 2.",
  "from_community_srt": "Если мы будем слушать только то, что хотели, сеть в конечном итоге будет стимулировать просто классифицировать все изображения как 2.",
  "n_reviews": 0,
  "start": 517.48,
  "end": 523.22
 },
 {
  "input": "So what you do is go through this same backprop routine for every other training example, recording how each of them would like to change the weights and biases, and average together those desired changes.",
  "translatedText": "Итак, вы выполняете одну и ту же процедуру обратного распространения для каждого другого обучающего примера, записывая, как каждый из них хотел бы изменить веса и смещения, и усредняете вместе эти желаемые изменения.",
  "from_community_srt": "Итак, что вы делаете, вы проходите эту же процедуру backprop для каждого другого примера обучения, записывая, как каждый из них хотел бы изменить вес и предубеждения, и вы усреднили эти желаемые изменения.",
  "n_reviews": 0,
  "start": 524.06,
  "end": 536.0
 },
 {
  "input": "This collection here of the averaged nudges to each weight and bias is, loosely speaking, the negative gradient of the cost function referenced in the last video, or at least something proportional to it.",
  "translatedText": "Этот набор усредненных подталкиваний к каждому весу и смещению, грубо говоря, представляет собой отрицательный градиент функции стоимости, упомянутой в последнем видео, или, по крайней мере, что-то пропорциональное ему.",
  "from_community_srt": "Эта коллекция здесь усредненных подтасовков к каждому весу и смещению, свободно говоря, отрицательный градиент функции стоимости, упомянутый в последнем видео, или, по крайней мере, что-то пропорциональное ему.",
  "n_reviews": 0,
  "start": 541.72,
  "end": 553.68
 },
 {
  "input": "I say loosely speaking only because I have yet to get quantitatively precise about those nudges, but if you understood every change I just referenced, why some are proportionally bigger than others, and how they all need to be added together, you understand the mechanics for what backpropagation is actually doing.",
  "translatedText": "Я говорю в общих чертах только потому, что мне еще предстоит получить точную количественную оценку этих подталкиваний, но если вы поняли каждое изменение, о котором я только что упомянул, почему некоторые из них пропорционально больше других и как их все нужно сложить вместе, вы поймете механизм что на самом деле делает обратное распространение ошибки.",
  "from_community_srt": "Я говорю «свободно говоря», только потому, что мне еще предстоит получить количественную информацию об этих подтасовках. Но если вы понимаете все изменения, о которых я только что говорил, почему некоторые из них пропорционально больше других, и как все они должны быть объединены вместе, вы понимаете механику того, что на самом деле делает backpropagation.",
  "n_reviews": 0,
  "start": 554.38,
  "end": 571.0
 },
 {
  "input": "By the way, in practice, it takes computers an extremely long time to add up the influence of every training example every gradient descent step.",
  "translatedText": "Кстати, на практике компьютерам требуется чрезвычайно много времени, чтобы сложить влияние каждого обучающего примера на каждом шаге градиентного спуска.",
  "from_community_srt": "Кстати, на практике компьютеры занимают очень много времени чтобы добавить влияние каждого отдельного примера обучения, каждого шага спуска градиента.",
  "n_reviews": 0,
  "start": 573.96,
  "end": 582.44
 },
 {
  "input": "So here's what's commonly done instead.",
  "translatedText": "Итак, вот что обычно делают вместо этого.",
  "from_community_srt": "Итак,",
  "n_reviews": 0,
  "start": 583.14,
  "end": 584.82
 },
 {
  "input": "You randomly shuffle your training data and then divide it into a whole bunch of mini-batches, let's say each one having 100 training examples.",
  "translatedText": "Вы случайным образом перемешиваете свои обучающие данные, а затем делите их на целую кучу мини-пакетов, скажем, каждый из которых имеет 100 обучающих примеров.",
  "from_community_srt": "вот что обычно делается: Вы произвольно перетасовываете свои данные обучения, а затем делите его на целую кучу мини-партий, допустим, каждый из них имеет 100 учебных примеров.",
  "n_reviews": 0,
  "start": 585.48,
  "end": 592.42
 },
 {
  "input": "Then you compute a step according to the mini-batch.",
  "translatedText": "Затем вы вычисляете шаг в соответствии с мини-пакетом.",
  "from_community_srt": "Затем вы вычисляете шаг в соответствии с мини-пакетом.",
  "n_reviews": 0,
  "start": 592.94,
  "end": 596.2
 },
 {
  "input": "It's not going to be the actual gradient of the cost function, which depends on all of the training data, not this tiny subset, so it's not the most efficient step downhill, but each mini-batch does give you a pretty good approximation, and more importantly, it gives you a significant computational speedup.",
  "translatedText": "Это не будет фактический градиент функции стоимости, который зависит от всех обучающих данных, а не от этого крошечного подмножества, так что это не самый эффективный шаг вниз, но каждый мини-пакет дает довольно хорошее приближение, и что еще более важно, это дает вам значительное ускорение вычислений.",
  "from_community_srt": "Это не будет фактическим градиентом функции стоимости, который зависит от всех данных обучения, а не от этого крошечного подмножества. Так что это не самый эффективный шаг вниз. Но каждая мини-партия действительно дает вам довольно хорошее приближение, и что более важно, это дает вам значительную вычислительную скорость.",
  "n_reviews": 0,
  "start": 596.96,
  "end": 612.12
 },
 {
  "input": "If you were to plot the trajectory of your network under the relevant cost surface, it would be a little more like a drunk man stumbling aimlessly down a hill but taking quick steps, rather than a carefully calculating man determining the exact downhill direction of each step before taking a very slow and careful step in that direction.",
  "translatedText": "Если бы вы построили траекторию своей сети по соответствующей поверхности затрат, это было бы больше похоже на пьяного мужчину, бесцельно спотыкающегося вниз по склону, но делающего быстрые шаги, чем на тщательно расчетливого человека, определяющего точное направление каждого шага вниз. прежде чем сделать очень медленный и осторожный шаг в этом направлении.",
  "from_community_srt": "Если бы вы построили траекторию своей сети под соответствующей ценовой поверхностью, это было бы немного больше, как пьяный человек, бесцельно спотыкающийся с холма, но делая быстрые шаги; а не тщательно вычисляющий человек, определяющий точное направление спуска на каждом шаге прежде чем делать очень медленный и осторожный шаг в этом направлении.",
  "n_reviews": 0,
  "start": 612.82,
  "end": 630.16
 },
 {
  "input": "This technique is referred to as stochastic gradient descent.",
  "translatedText": "Этот метод называется стохастическим градиентным спуском.",
  "from_community_srt": "Этот метод называется «стохастическим градиентным спуском».",
  "n_reviews": 0,
  "start": 631.54,
  "end": 634.66
 },
 {
  "input": "There's a lot going on here, so let's just sum it up for ourselves, shall we?",
  "translatedText": "Здесь много всего происходит, так что давайте просто подведем итоги для себя, ладно?",
  "from_community_srt": "Здесь много чего происходит, поэтому давайте просто подытожим это для себя,",
  "n_reviews": 0,
  "start": 635.96,
  "end": 639.62
 },
 {
  "input": "Backpropagation is the algorithm for determining how a single training example would like to nudge the weights and biases, not just in terms of whether they should go up or down, but in terms of what relative proportions to those changes cause the most rapid decrease to the cost.",
  "translatedText": "Обратное распространение ошибки — это алгоритм определения того, как отдельный обучающий пример хотел бы подтолкнуть веса и смещения, не только с точки зрения того, должны ли они повышаться или уменьшаться, но и с точки зрения того, какие относительные пропорции этих изменений вызывают наиболее быстрое снижение расходы.",
  "from_community_srt": "не так ли? Backpropagation - алгоритм для определения того, как один пример тренинга хотел бы подтолкнуть веса и предубеждения, не только с точки зрения того, должны ли они подниматься или опускаться, но с точки зрения того, что относительные пропорции к этим изменениям приводят к самому быстрому снижению стоимости.",
  "n_reviews": 0,
  "start": 640.44,
  "end": 655.56
 },
 {
  "input": "A true gradient descent step would involve doing this for all your tens of thousands of training examples and averaging the desired changes you get.",
  "translatedText": "Настоящий шаг градиентного спуска предполагает проделать это для всех ваших десятков тысяч обучающих примеров и усреднить желаемые изменения, которые вы получите.",
  "from_community_srt": "Истинный шаг спуска градиента будет включать в себя выполнение этого для всех ваших десятков и тысяч учебных примеров и усреднение желаемых изменений, которые вы получаете.",
  "n_reviews": 0,
  "start": 656.26,
  "end": 664.2
 },
 {
  "input": "But that's computationally slow, so instead you randomly subdivide the data into mini-batches and compute each step with respect to a mini-batch.",
  "translatedText": "Но это требует больших вычислительных затрат, поэтому вместо этого вы случайным образом разделяете данные на мини-пакеты и вычисляете каждый шаг относительно мини-пакета.",
  "from_community_srt": "Но это вычислительно медленно. Поэтому вместо этого вы произвольно подразделяете данные на эти мини-партии и вычислить каждый шаг в отношении мини-партии.",
  "n_reviews": 0,
  "start": 664.86,
  "end": 673.24
 },
 {
  "input": "Repeatedly going through all of the mini-batches and making these adjustments, you will converge towards a local minimum of the cost function, which is to say your network will end up doing a really good job on the training examples.",
  "translatedText": "Неоднократно проходя все мини-пакеты и внося эти корректировки, вы дойдете до локального минимума функции стоимости, то есть ваша сеть в конечном итоге действительно хорошо справится с обучающими примерами.",
  "from_community_srt": "Неоднократно проходя через все мини-партии и делая эти корректировки, вы сходитесь к локальному минимуму функции стоимости, то есть ваша сеть будет в конечном итоге делать действительно хорошую работу на примерах обучения.",
  "n_reviews": 0,
  "start": 674.0,
  "end": 685.54
 },
 {
  "input": "So with all of that said, every line of code that would go into implementing backprop actually corresponds with something you have now seen, at least in informal terms.",
  "translatedText": "Итак, несмотря на все вышесказанное, каждая строка кода, которая будет использоваться для реализации обратного распространения, на самом деле соответствует тому, что вы сейчас видели, по крайней мере, в неформальном плане.",
  "from_community_srt": "Таким образом, со всем сказанным, каждая строка кода, которая будет внедрять backprop фактически соответствует тому, что вы сейчас видели, по крайней мере, в неформальном плане.",
  "n_reviews": 0,
  "start": 687.24,
  "end": 696.72
 },
 {
  "input": "But sometimes knowing what the math does is only half the battle, and just representing the damn thing is where it gets all muddled and confusing.",
  "translatedText": "Но иногда знание того, что делает математика, — это только полдела, и простое представление этой чертовой штуки приводит к путанице и путанице.",
  "from_community_srt": "Но иногда знание того, что делает математика, - это только половина битвы, и просто представлять чертову вещь, где она становится все запутанной и запутанной.",
  "n_reviews": 0,
  "start": 697.56,
  "end": 704.12
 },
 {
  "input": "So for those of you who do want to go deeper, the next video goes through the same ideas that were just presented here, but in terms of the underlying calculus, which should hopefully make it a little more familiar as you see the topic in other resources.",
  "translatedText": "Итак, для тех из вас, кто хочет углубиться, в следующем видео рассматриваются те же идеи, которые только что были представлены здесь, но с точки зрения основного исчисления, что, мы надеемся, сделает его немного более знакомым, поскольку вы видите эту тему в других Ресурсы.",
  "from_community_srt": "Итак, для тех из вас, кто хочет глубже, следующее видео проходит те же идеи, которые были представлены здесь но в терминах основного исчисления, что, надеюсь, сделает его немного более знакомым, поскольку вы видите эту тему в других ресурсах.",
  "n_reviews": 0,
  "start": 704.86,
  "end": 716.42
 },
 {
  "input": "Before that, one thing worth emphasizing is that for this algorithm to work, and this goes for all sorts of machine learning beyond just neural networks, you need a lot of training data.",
  "translatedText": "Перед этим стоит подчеркнуть одну вещь: для того, чтобы этот алгоритм работал, и это касается всех видов машинного обучения, помимо нейронных сетей, вам нужно много обучающих данных.",
  "from_community_srt": "Прежде всего стоит подчеркнуть, что для того, чтобы этот алгоритм работал, и это касается всех видов машинного обучения за пределами только нейронных сетей, вам нужно много учебных данных.",
  "n_reviews": 0,
  "start": 717.34,
  "end": 725.9
 },
 {
  "input": "In our case, one thing that makes handwritten digits such a nice example is that there exists the MNIST database, with so many examples that have been labeled by humans.",
  "translatedText": "В нашем случае, одна вещь, которая делает рукописные цифры таким хорошим примером, — это то, что существует база данных MNIST с таким большим количеством примеров, которые были помечены людьми.",
  "from_community_srt": "В нашем случае одна вещь, которая делает рукописные цифры таким приятным примером заключается в том, что существует база данных MNIST с таким количеством примеров, которые были обозначены людьми.",
  "n_reviews": 0,
  "start": 726.42,
  "end": 734.74
 },
 {
  "input": "So a common challenge that those of you working in machine learning will be familiar with is just getting the labeled training data you actually need, whether that's having people label tens of thousands of images, or whatever other data type you might be dealing with.",
  "translatedText": "Таким образом, распространенная задача, с которой знакомы те из вас, кто занимается машинным обучением, — это просто получить помеченные обучающие данные, которые вам действительно нужны, будь то маркировка десятков тысяч изображений или любой другой тип данных, с которым вы можете иметь дело.",
  "from_community_srt": "Таким образом, общая задача, с которой вы работаете в машинном обучении, будет знакома с просто получает обозначенные данные обучения, которые вам действительно нужны, независимо от того, имеют ли люди метки десятки тысяч изображений или каким-либо другим типом данных, с которым вы можете иметь дело.",
  "n_reviews": 0,
  "start": 735.3,
  "end": 747.1
 }
]