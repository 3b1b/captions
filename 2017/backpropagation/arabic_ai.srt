1
00:00:00,000 --> 00:00:09,640
هنا، نتناول الانتشار العكسي، وهو الخوارزمية الأساسية وراء كيفية تعلم الشبكات العصبية.

2
00:00:09,640 --> 00:00:13,320
بعد تلخيص سريع لما نحن فيه، أول شيء سأفعله هو إجراء

3
00:00:13,320 --> 00:00:17,400
إرشادات بديهية لما تفعله الخوارزمية فعليًا، دون أي إشارة إلى الصيغ.

4
00:00:17,400 --> 00:00:21,400
ثم، بالنسبة لأولئك منكم الذين يريدون التعمق في الرياضيات، فإن

5
00:00:21,400 --> 00:00:24,040
الفيديو التالي يتناول حساب التفاضل والتكامل الأساسي لكل هذا.

6
00:00:24,040 --> 00:00:27,320
إذا شاهدت مقطعي الفيديو الأخيرين، أو إذا كنت تقفز للتو بالخلفية المناسبة،

7
00:00:27,320 --> 00:00:31,080
فأنت تعرف ما هي الشبكة العصبية، وكيف تغذي المعلومات إلى الأمام.

8
00:00:31,080 --> 00:00:35,520
هنا، نحن ننفذ المثال الكلاسيكي للتعرف على الأرقام المكتوبة بخط اليد والتي يتم إدخال قيم

9
00:00:35,520 --> 00:00:40,280
البكسل الخاصة بها في الطبقة الأولى من الشبكة التي تحتوي على 784 خلية عصبية،

10
00:00:40,280 --> 00:00:44,720
وقد قمت بعرض شبكة ذات طبقتين مخفيتين تحتوي كل منهما على 16 خلية عصبية فقط،

11
00:00:44,720 --> 00:00:49,520
ومخرج طبقة من 10 خلايا عصبية، تشير إلى الرقم الذي تختاره الشبكة كإجابة لها.

12
00:00:49,520 --> 00:00:54,480
أتوقع منك أيضًا أن تفهم النسب المتدرج، كما هو موضح في

13
00:00:54,480 --> 00:01:00,160
الفيديو الأخير، وكيف أن ما نعنيه بالتعلم هو أننا نريد

14
00:01:00,160 --> 00:01:02,080
العثور على الأوزان والتحيزات التي تقلل من دالة تكلفة معينة.

15
00:01:02,080 --> 00:01:07,560
كتذكير سريع، مقابل تكلفة مثال تدريبي واحد، فإنك تأخذ

16
00:01:07,560 --> 00:01:12,920
المخرجات التي تقدمها الشبكة، بالإضافة إلى المخرجات التي تريدها

17
00:01:12,920 --> 00:01:15,560
أن تعطيها، وتضيف مربعات الاختلافات بين كل مكون.

18
00:01:15,560 --> 00:01:20,160
عند القيام بذلك لجميع عشرات الآلاف من أمثلة التدريب الخاصة

19
00:01:20,160 --> 00:01:23,040
بك وحساب متوسط النتائج، فإن هذا يمنحك التكلفة الإجمالية للشبكة.

20
00:01:23,040 --> 00:01:26,320
كما لو أن هذا لا يكفي للتفكير فيه، كما هو موضح

21
00:01:26,320 --> 00:01:31,700
في الفيديو الأخير، فإن الشيء الذي نبحث عنه هو التدرج السلبي

22
00:01:31,700 --> 00:01:36,000
لدالة التكلفة هذه، والذي يخبرك كيف تحتاج إلى تغيير كل الأوزان

23
00:01:36,000 --> 00:01:43,080
والتحيزات، كل هذه الاتصالات، وذلك لتقليل التكلفة بشكل أكثر كفاءة.

24
00:01:43,080 --> 00:01:48,600
Backpropagation، موضوع هذا الفيديو، هو خوارزمية

25
00:01:48,600 --> 00:01:49,600
لحساب هذا التدرج المعقد والجنوني.

26
00:01:49,600 --> 00:01:53,300
الفكرة الوحيدة من الفيديو الأخير التي أريدك حقًا أن تضعها بقوة

27
00:01:53,300 --> 00:01:58,280
في ذهنك الآن هي أنه نظرًا لأن التفكير في متجه

28
00:01:58,280 --> 00:02:02,660
التدرج كاتجاه في 13000 بُعد هو، بعبارة مبسطة، خارج نطاق

29
00:02:02,660 --> 00:02:04,620
مخيلتنا، هناك فكرة أخرى الطريقة التي يمكنك التفكير في ذلك.

30
00:02:04,620 --> 00:02:09,700
يخبرك حجم كل مكون هنا بمدى

31
00:02:09,700 --> 00:02:11,820
حساسية دالة التكلفة لكل وزن وتحيز.

32
00:02:11,820 --> 00:02:15,180
على سبيل المثال، لنفترض أنك قمت بتنفيذ العملية التي أنا على وشك

33
00:02:15,180 --> 00:02:19,800
وصفها، وحساب التدرج السلبي، والمكون المرتبط بالوزن على هذه الحافة هنا

34
00:02:19,800 --> 00:02:26,940
يصبح 3. 2، في حين أن المكون المرتبط بهذه الحافة هنا يخرج كـ 0. 1.

35
00:02:26,940 --> 00:02:31,520
الطريقة التي تفسر بها ذلك هي أن تكلفة الوظيفة أكثر حساسية بمقدار

36
00:02:31,520 --> 00:02:36,100
32 مرة للتغيرات في هذا الوزن الأول، لذلك إذا قمت بتحريك هذه

37
00:02:36,100 --> 00:02:40,780
القيمة قليلاً، فسوف يتسبب ذلك في بعض التغيير في التكلفة، وهذا التغيير

38
00:02:40,780 --> 00:02:45,580
أكبر بـ 32 مرة مما ستعطيه نفس الاهتزازة لهذا الوزن الثاني.

39
00:02:45,580 --> 00:02:52,500
شخصيًا، عندما كنت أتعلم لأول مرة عن الانتشار العكسي، أعتقد أن

40
00:02:52,500 --> 00:02:55,820
الجانب الأكثر إرباكًا كان مجرد الترميز ومطاردة الفهرس لكل شيء.

41
00:02:55,820 --> 00:03:00,240
ولكن بمجرد أن تكتشف ما يفعله كل جزء من هذه الخوارزمية بالفعل،

42
00:03:00,240 --> 00:03:04,540
فإن كل تأثير فردي يحدثه يكون في الواقع بديهيًا جدًا، الأمر فقط

43
00:03:04,540 --> 00:03:07,740
أن هناك الكثير من التعديلات الصغيرة التي يتم وضعها فوق بعضها البعض.

44
00:03:07,740 --> 00:03:11,380
لذا، سأبدأ الأمور هنا مع التجاهل التام للتدوين، وسأنتقل

45
00:03:11,380 --> 00:03:17,380
فقط عبر تأثيرات كل مثال تدريبي على الأوزان والتحيزات.

46
00:03:17,380 --> 00:03:21,880
نظرًا لأن دالة التكلفة تتضمن حساب متوسط تكلفة معينة لكل مثال على

47
00:03:21,880 --> 00:03:26,980
عشرات الآلاف من أمثلة التدريب، فإن الطريقة التي نضبط بها الأوزان والتحيزات

48
00:03:26,980 --> 00:03:31,740
لخطوة نزول متدرجة واحدة تعتمد أيضًا على كل مثال على حدة.

49
00:03:31,740 --> 00:03:35,300
أو بالأحرى، من حيث المبدأ، ينبغي أن يكون الأمر كذلك، ولكن من أجل الكفاءة الحسابية،

50
00:03:35,300 --> 00:03:39,860
سنقوم بخدعة صغيرة لاحقًا لمنعك من الحاجة إلى ضرب كل مثال في كل خطوة.

51
00:03:39,860 --> 00:03:44,460
في حالات أخرى، الآن، كل ما سنفعله هو تركيز

52
00:03:44,460 --> 00:03:46,780
انتباهنا على مثال واحد، هذه الصورة للرقم 2.

53
00:03:46,780 --> 00:03:51,740
ما هو التأثير الذي يجب أن يحدثه هذا المثال التدريبي على كيفية تعديل الأوزان والتحيزات؟

54
00:03:51,740 --> 00:03:56,040
لنفترض أننا وصلنا إلى مرحلة لم يتم فيها تدريب الشبكة بشكل جيد بعد، وبالتالي فإن عمليات

55
00:03:56,040 --> 00:04:01,620
التنشيط في الإخراج ستبدو عشوائية جدًا، ربما شيء من هذا القبيل 0. 5، 0. 8, 0. 2،

56
00:04:01,620 --> 00:04:02,780
على وعلى.

57
00:04:02,780 --> 00:04:06,700
لا يمكننا تغيير تلك التنشيطات بشكل مباشر، لدينا فقط

58
00:04:06,700 --> 00:04:11,380
تأثير على الأوزان والتحيزات، ولكن من المفيد تتبع التعديلات

59
00:04:11,380 --> 00:04:13,340
التي نرغب في إجرائها على طبقة الإخراج تلك.

60
00:04:13,340 --> 00:04:18,220
وبما أننا نريدها أن تصنف الصورة على أنها 2، فإننا نريد أن

61
00:04:18,220 --> 00:04:21,700
يتم دفع القيمة الثالثة للأعلى بينما يتم دفع جميع القيم الأخرى للأسفل.

62
00:04:21,700 --> 00:04:27,620
علاوة على ذلك، يجب أن تكون أحجام هذه الدفعات متناسبة

63
00:04:27,620 --> 00:04:30,220
مع مدى بعد كل قيمة حالية عن قيمتها المستهدفة.

64
00:04:30,220 --> 00:04:35,260
على سبيل المثال، الزيادة في تنشيط الخلية العصبية رقم 2 هي إلى

65
00:04:35,260 --> 00:04:39,620
حد ما أكثر أهمية من الانخفاض في الخلية العصبية رقم 8، والتي

66
00:04:39,620 --> 00:04:42,060
هي بالفعل قريبة جدًا من المكان الذي ينبغي أن تكون فيه.

67
00:04:42,060 --> 00:04:46,260
لذا، بالتكبير أكثر، دعونا نركز فقط على هذه

68
00:04:46,260 --> 00:04:47,900
الخلية العصبية، تلك التي نرغب في زيادة تنشيطها.

69
00:04:47,900 --> 00:04:53,680
تذكر، يتم تعريف هذا التنشيط على أنه مجموع مرجح معين لجميع

70
00:04:53,680 --> 00:04:58,380
عمليات التنشيط في الطبقة السابقة، بالإضافة إلى التحيز، والذي يتم

71
00:04:58,380 --> 00:05:01,900
بعد ذلك توصيله بشيء مثل وظيفة السحق السيني، أو ReLU.

72
00:05:01,900 --> 00:05:07,060
لذلك هناك ثلاث طرق مختلفة يمكن أن

73
00:05:07,060 --> 00:05:08,060
تتعاون معًا للمساعدة في زيادة هذا التنشيط.

74
00:05:08,060 --> 00:05:12,800
يمكنك زيادة التحيز، ويمكنك زيادة الأوزان، ويمكنك

75
00:05:12,800 --> 00:05:15,300
تغيير عمليات التنشيط من الطبقة السابقة.

76
00:05:15,300 --> 00:05:19,720
بالتركيز على كيفية ضبط الأوزان، لاحظ كيف

77
00:05:19,720 --> 00:05:21,460
أن للأوزان بالفعل مستويات مختلفة من التأثير.

78
00:05:21,460 --> 00:05:25,100
إن الاتصالات مع الخلايا العصبية الأكثر سطوعًا من الطبقة السابقة لها

79
00:05:25,100 --> 00:05:31,420
التأثير الأكبر حيث يتم ضرب تلك الأوزان بقيم تنشيط أكبر.

80
00:05:31,420 --> 00:05:35,820
لذا، إذا قمت بزيادة أحد هذه الأوزان، فسيكون لها في الواقع

81
00:05:35,820 --> 00:05:40,900
تأثير أقوى على دالة التكلفة النهائية من زيادة أوزان الاتصالات مع

82
00:05:40,900 --> 00:05:44,020
الخلايا العصبية الخافتة، على الأقل فيما يتعلق بهذا المثال التدريبي.

83
00:05:44,020 --> 00:05:48,700
تذكر، عندما نتحدث عن النسب المتدرج، فإننا لا نهتم فقط

84
00:05:48,700 --> 00:05:53,020
بما إذا كان يجب دفع كل مكون لأعلى أو لأسفل،

85
00:05:53,020 --> 00:05:54,020
بل نهتم بالمكونات التي تمنحك أكبر قدر من المال.

86
00:05:54,020 --> 00:06:00,260
هذا، بالمناسبة، يذكرنا على الأقل إلى حد ما بنظرية في علم الأعصاب

87
00:06:00,260 --> 00:06:04,900
حول كيفية تعلم الشبكات البيولوجية للخلايا العصبية، وهي نظرية هيبيان، والتي غالبًا

88
00:06:04,900 --> 00:06:06,940
ما يتم تلخيصها في العبارة، الخلايا العصبية التي تشتعل معًا تترابط معًا.

89
00:06:06,940 --> 00:06:12,460
هنا، أكبر زيادات في الأوزان، وأكبر تقوية للاتصالات،

90
00:06:12,460 --> 00:06:16,860
تحدث بين الخلايا العصبية الأكثر نشاطًا وتلك

91
00:06:16,860 --> 00:06:18,100
التي نرغب في أن تصبح أكثر نشاطًا.

92
00:06:18,100 --> 00:06:22,520
بمعنى ما، فإن الخلايا العصبية التي تنشط أثناء رؤية الرقم 2 تصبح

93
00:06:22,520 --> 00:06:25,440
أكثر ارتباطًا بتلك الخلايا العصبية التي تنشط عند التفكير في الأمر.

94
00:06:25,440 --> 00:06:29,240
لأكون واضحًا، لست في وضع يسمح لي بالإدلاء ببيانات بطريقة أو بأخرى

95
00:06:29,240 --> 00:06:34,020
حول ما إذا كانت الشبكات الاصطناعية من الخلايا العصبية تتصرف مثل العقول

96
00:06:34,020 --> 00:06:39,440
البيولوجية، وهذه الفكرة التي تنطلق معًا تأتي مع نجمتين ذات معنى، ولكن

97
00:06:39,440 --> 00:06:41,760
تم اعتبارها فضفاضة للغاية تشبيهًا، أجد أنه من المثير للاهتمام ملاحظة ذلك.

98
00:06:41,760 --> 00:06:46,760
على أية حال، الطريقة الثالثة التي يمكننا من خلالها المساعدة في زيادة

99
00:06:46,760 --> 00:06:49,360
تنشيط هذه الخلايا العصبية هي تغيير جميع عمليات التنشيط في الطبقة السابقة.

100
00:06:49,360 --> 00:06:55,080
على وجه التحديد، إذا أصبح كل شيء مرتبط بالخلية العصبية ذات الرقم 2

101
00:06:55,080 --> 00:06:59,480
ذات الوزن الإيجابي أكثر سطوعًا، وإذا أصبح كل شيء مرتبط بالوزن السلبي

102
00:06:59,480 --> 00:07:02,680
أكثر خفوتًا، فإن تلك الخلية العصبية ذات الرقم 2 ستصبح أكثر نشاطًا.

103
00:07:02,680 --> 00:07:06,200
وكما هو الحال مع تغييرات الوزن، ستحصل على أقصى استفادة من

104
00:07:06,200 --> 00:07:10,840
أموالك من خلال البحث عن تغييرات تتناسب مع حجم الأوزان المقابلة.

105
00:07:10,840 --> 00:07:16,520
الآن بالطبع، لا يمكننا التأثير بشكل مباشر على

106
00:07:16,520 --> 00:07:18,320
تلك التنشيطات، لدينا فقط السيطرة على الأوزان والتحيزات.

107
00:07:18,320 --> 00:07:22,960
ولكن كما هو الحال مع الطبقة الأخيرة، من

108
00:07:22,960 --> 00:07:23,960
المفيد الاحتفاظ بملاحظة حول ماهية تلك التغييرات المرغوبة.

109
00:07:23,960 --> 00:07:29,040
لكن ضع في اعتبارك، عند تصغير خطوة واحدة هنا، فإن هذا

110
00:07:29,040 --> 00:07:30,040
هو فقط ما تريده تلك الخلية العصبية الناتجة من الرقم 2.

111
00:07:30,040 --> 00:07:34,960
تذكر أننا نريد أيضًا أن تصبح جميع الخلايا العصبية الأخرى في

112
00:07:34,960 --> 00:07:38,460
الطبقة الأخيرة أقل نشاطًا، ولكل من تلك الخلايا العصبية الأخرى أفكارها

113
00:07:38,460 --> 00:07:43,200
الخاصة حول ما يجب أن يحدث لتلك الطبقة الثانية قبل الأخيرة.

114
00:07:43,200 --> 00:07:49,220
لذلك يتم إضافة رغبة هذه الخلية العصبية ذات الرقم 2 مع رغبات

115
00:07:49,220 --> 00:07:54,800
جميع الخلايا العصبية الناتجة الأخرى فيما يتعلق بما يجب أن يحدث

116
00:07:54,800 --> 00:08:00,240
لهذه الطبقة الثانية إلى الأخيرة، مرة أخرى بما يتناسب مع الأوزان المقابلة،

117
00:08:00,240 --> 00:08:01,740
وبما يتناسب مع مقدار احتياجات كل من تلك الخلايا العصبية للتغيير.

118
00:08:01,740 --> 00:08:05,940
وهنا تأتي فكرة الانتشار العكسي.

119
00:08:05,940 --> 00:08:11,080
من خلال جمع كل هذه التأثيرات المرغوبة معًا، تحصل بشكل أساسي على

120
00:08:11,080 --> 00:08:14,300
قائمة من التنبيهات التي تريد أن تحدث لهذه الطبقة الثانية إلى الأخيرة.

121
00:08:14,300 --> 00:08:18,740
وبمجرد حصولك على هذه، يمكنك تطبيق نفس العملية بشكل متكرر

122
00:08:18,740 --> 00:08:23,400
على الأوزان والتحيزات ذات الصلة التي تحدد تلك القيم، وتكرار

123
00:08:23,400 --> 00:08:29,180
نفس العملية التي مررت بها للتو والتحرك للخلف عبر الشبكة.

124
00:08:29,180 --> 00:08:33,960
وبالتصغير أكثر قليلاً، تذكر أن هذا كله هو الطريقة التي يرغب بها

125
00:08:33,960 --> 00:08:37,520
مثال تدريبي واحد في دفع كل واحد من تلك الأوزان والتحيزات.

126
00:08:37,520 --> 00:08:41,400
إذا استمعنا فقط إلى ما يريده هذا الشخصان، فسيتم تحفيز

127
00:08:41,400 --> 00:08:44,140
الشبكة في النهاية لتصنيف جميع الصور على أنها رقم 2.

128
00:08:44,140 --> 00:08:49,500
إذن ما تفعله هو اتباع نفس روتين الدعم الخلفي لكل

129
00:08:49,500 --> 00:08:54,700
مثال تدريبي آخر، وتسجيل كيف يرغب كل منهم في

130
00:08:54,700 --> 00:09:02,300
تغيير الأوزان والتحيزات، وحساب متوسط تلك التغييرات المرغوبة معًا.

131
00:09:02,300 --> 00:09:08,260
هذه المجموعة هنا من متوسط الدفعات لكل وزن وتحيز

132
00:09:08,260 --> 00:09:12,340
هي، بشكل فضفاض، التدرج السلبي لوظيفة التكلفة المشار إليها

133
00:09:12,340 --> 00:09:14,360
في الفيديو الأخير، أو على الأقل شيء يتناسب معها.

134
00:09:14,360 --> 00:09:18,980
أقول ذلك بشكل فضفاض فقط لأنني لم أحصل بعد على دقة كمية

135
00:09:18,980 --> 00:09:23,480
بشأن تلك التنبيهات، ولكن إذا فهمت كل تغيير أشرت إليه للتو، ولماذا

136
00:09:23,480 --> 00:09:28,740
يكون بعضها أكبر نسبيًا من البعض الآخر، وكيف يجب إضافتها جميعًا معًا،

137
00:09:28,740 --> 00:09:34,100
فإنك تفهم آليات حدوث ذلك. ما يفعله الانتشار العكسي في الواقع.

138
00:09:34,100 --> 00:09:38,540
بالمناسبة، في الممارسة العملية، يستغرق الأمر وقتًا طويلاً للغاية من أجهزة

139
00:09:38,540 --> 00:09:43,120
الكمبيوتر لإضافة تأثير كل مثال تدريبي في كل خطوة نزول متدرجة.

140
00:09:43,120 --> 00:09:45,540
إذن، إليك ما يتم فعله عادةً بدلاً من ذلك.

141
00:09:45,540 --> 00:09:50,460
يمكنك خلط بيانات التدريب الخاصة بك عشوائيًا وتقسيمها إلى مجموعة كاملة من

142
00:09:50,460 --> 00:09:53,380
الدفعات الصغيرة، لنفترض أن كل واحدة تحتوي على 100 مثال تدريبي.

143
00:09:53,380 --> 00:09:56,980
ثم تقوم بحساب الخطوة وفقًا للدفعة الصغيرة.

144
00:09:56,980 --> 00:10:00,840
إنه ليس التدرج الفعلي لدالة التكلفة، والذي يعتمد على جميع

145
00:10:00,840 --> 00:10:06,260
بيانات التدريب، وليس هذه المجموعة الفرعية الصغيرة، لذا فهي ليست

146
00:10:06,260 --> 00:10:10,900
الخطوة الأكثر كفاءة إلى أسفل، ولكن كل دفعة صغيرة تمنحك

147
00:10:10,900 --> 00:10:12,900
تقريبًا جيدًا، والأهم من ذلك أنها يمنحك تسريعًا حسابيًا كبيرًا.

148
00:10:12,900 --> 00:10:16,900
إذا كنت تريد رسم مسار شبكتك تحت سطح التكلفة ذي الصلة، فسيكون

149
00:10:16,900 --> 00:10:22,020
الأمر أشبه برجل مخمور يتعثر بلا هدف أسفل التل ولكنه يتخذ

150
00:10:22,020 --> 00:10:26,880
خطوات سريعة، بدلاً من رجل يحسب بعناية ويحدد الاتجاه الدقيق لانحدار

151
00:10:26,880 --> 00:10:31,620
كل خطوة. قبل اتخاذ خطوة بطيئة وحذرة للغاية في هذا الاتجاه.

152
00:10:31,620 --> 00:10:35,200
يشار إلى هذه التقنية باسم النسب التدرج العشوائي.

153
00:10:35,200 --> 00:10:40,400
هناك الكثير مما يحدث هنا، لذا دعونا نلخص الأمر لأنفسنا، أليس كذلك؟

154
00:10:40,400 --> 00:10:45,480
إن الانتشار العكسي هو خوارزمية لتحديد كيف يرغب مثال تدريبي

155
00:10:45,480 --> 00:10:50,040
واحد في دفع الأوزان والتحيزات، ليس فقط من حيث ما

156
00:10:50,040 --> 00:10:54,780
إذا كان ينبغي أن ترتفع أم تنخفض، ولكن من حيث

157
00:10:54,780 --> 00:10:56,240
النسب النسبية لتلك التغييرات التي تسبب الانخفاض الأسرع في يكلف.

158
00:10:56,240 --> 00:11:00,720
قد تتضمن خطوة النزول المتدرج الحقيقية القيام بذلك لجميع العشرات والآلاف من

159
00:11:00,720 --> 00:11:05,920
أمثلة التدريب وحساب متوسط التغييرات المرغوبة التي تحصل عليها، ولكن هذا

160
00:11:05,920 --> 00:11:11,680
بطيء من الناحية الحسابية، لذلك بدلاً من ذلك تقوم بتقسيم البيانات عشوائيًا

161
00:11:11,680 --> 00:11:14,000
إلى دفعات صغيرة وحساب كل خطوة فيما يتعلق بـ دفعة صغيرة.

162
00:11:14,000 --> 00:11:18,600
من خلال مراجعة جميع الدفعات الصغيرة بشكل متكرر وإجراء هذه التعديلات،

163
00:11:18,600 --> 00:11:23,420
سوف تتقارب نحو الحد الأدنى المحلي لوظيفة التكلفة، مما يعني أن

164
00:11:23,420 --> 00:11:27,540
شبكتك ستؤدي في النهاية عملًا جيدًا حقًا في أمثلة التدريب.

165
00:11:27,540 --> 00:11:32,600
إذن مع كل ما قيل، فإن كل سطر من التعليمات البرمجية الذي قد يدخل

166
00:11:32,600 --> 00:11:37,680
في تنفيذ backprop يتوافق فعليًا مع شيء رأيته الآن، على الأقل بعبارات غير رسمية.

167
00:11:37,680 --> 00:11:41,900
لكن في بعض الأحيان، معرفة ما تفعله الرياضيات هو نصف المعركة فقط،

168
00:11:41,900 --> 00:11:44,780
ومجرد تمثيل الشيء اللعين هو المكان الذي يصبح فيه الأمر مشوشًا ومربكًا.

169
00:11:44,780 --> 00:11:49,360
لذا، بالنسبة لأولئك منكم الذين يريدون التعمق أكثر، فإن الفيديو التالي يتناول نفس

170
00:11:49,360 --> 00:11:53,400
الأفكار التي تم تقديمها هنا للتو، ولكن فيما يتعلق بحساب التفاضل والتكامل الأساسي،

171
00:11:53,400 --> 00:11:57,460
والذي نأمل أن يجعله مألوفًا أكثر قليلاً كما ترون الموضوع في مصادر أخرى.

172
00:11:57,460 --> 00:12:01,220
قبل ذلك، هناك شيء واحد يستحق التأكيد عليه وهو أنه لكي

173
00:12:01,220 --> 00:12:05,840
تعمل هذه الخوارزمية، وهذا ينطبق على جميع أنواع التعلم الآلي خارج

174
00:12:05,840 --> 00:12:06,840
الشبكات العصبية فقط، فأنت بحاجة إلى الكثير من بيانات التدريب.

175
00:12:06,840 --> 00:12:10,740
في حالتنا، الشيء الوحيد الذي يجعل الأرقام المكتوبة بخط اليد مثالًا رائعًا هو

176
00:12:10,740 --> 00:12:15,380
وجود قاعدة بيانات MNIST، مع العديد من الأمثلة التي تم تصنيفها بواسطة البشر.

177
00:12:15,380 --> 00:12:19,000
لذا فإن التحدي الشائع الذي سيكون العاملون في التعلم الآلي على دراية به هو مجرد

178
00:12:19,040 --> 00:12:22,880
الحصول على بيانات التدريب المصنفة التي تحتاجها بالفعل، سواء كان ذلك جعل الأشخاص يقومون بتسمية

179
00:12:22,880 --> 00:12:27,400
عشرات الآلاف من الصور، أو أي نوع آخر من البيانات التي قد تتعامل معها.

