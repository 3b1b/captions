1
00:00:00,000 --> 00:00:09,640
یہاں، ہم بیک پروپیگیشن سے نمٹتے ہیں، جو کہ نیورل نیٹ ورکس کے سیکھنے کے پیچھے بنیادی الگورتھم ہے۔

2
00:00:09,640 --> 00:00:13,320
ہم کہاں ہیں اس کی ایک فوری بازیافت کے بعد، سب سے پہلے میں جو کروں گا وہ یہ

3
00:00:13,320 --> 00:00:17,400
ہے کہ الگورتھم اصل میں کیا کر رہا ہے، فارمولوں کے حوالے کے بغیر ایک بدیہی واک تھرو۔

4
00:00:17,400 --> 00:00:21,400
پھر، آپ میں سے ان لوگوں کے لیے جو ریاضی میں غوطہ لگانا

5
00:00:21,400 --> 00:00:24,040
چاہتے ہیں، اگلی ویڈیو ان سب کے بنیادی حساب کتاب میں جاتی ہے۔

6
00:00:24,040 --> 00:00:27,320
اگر آپ نے آخری دو ویڈیوز دیکھی ہیں، یا اگر آپ مناسب پس منظر کے ساتھ کود رہے ہیں،

7
00:00:27,320 --> 00:00:31,080
تو آپ کو معلوم ہوگا کہ نیورل نیٹ ورک کیا ہے، اور یہ معلومات کو آگے کیسے بڑھاتا ہے۔

8
00:00:31,080 --> 00:00:35,520
یہاں، ہم ہاتھ سے لکھے ہوئے ہندسوں کو پہچاننے کی بہترین مثال پیش کر رہے ہیں جن کی پکسل ویلیوز نیٹ ورک

9
00:00:35,520 --> 00:00:40,280
کی پہلی پرت میں 784 نیورونز کے ساتھ مل جاتی ہیں، اور میں ایک ایسا نیٹ ورک دکھا رہا ہوں جس

10
00:00:40,280 --> 00:00:44,720
میں دو پوشیدہ پرتیں ہیں جن میں سے ہر ایک میں صرف 16 نیوران ہیں، اور ایک آؤٹ پٹ۔ 10 نیوران کی

11
00:00:44,720 --> 00:00:49,520
پرت، جس سے ظاہر ہوتا ہے کہ نیٹ ورک اپنے جواب کے طور پر کون سا ہندسہ منتخب کر رہا ہے۔

12
00:00:49,520 --> 00:00:54,480
میں آپ سے یہ بھی توقع کر رہا ہوں کہ آپ تدریجی نزول کو سمجھیں گے، جیسا کہ

13
00:00:54,480 --> 00:01:00,160
پچھلی ویڈیو میں بیان کیا گیا ہے، اور سیکھنے سے ہمارا کیا مطلب ہے کہ ہم یہ

14
00:01:00,160 --> 00:01:02,080
تلاش کرنا چاہتے ہیں کہ کون سے وزن اور تعصب کسی خاص لاگت کو کم کرتے ہیں۔

15
00:01:02,080 --> 00:01:07,560
فوری یاد دہانی کے طور پر، کسی ایک تربیتی مثال کی لاگت کے لیے، آپ نیٹ ورک

16
00:01:07,560 --> 00:01:12,920
کی طرف سے دیا جانے والا آؤٹ پٹ لیتے ہیں، اس آؤٹ پٹ کے ساتھ جو آپ

17
00:01:12,920 --> 00:01:15,560
اسے دینا چاہتے تھے، اور ہر جزو کے درمیان فرق کے مربعوں کو شامل کرتے ہیں۔

18
00:01:15,560 --> 00:01:20,160
آپ کی دسیوں ہزار تربیتی مثالوں کے لیے یہ کرنا اور نتائج کا

19
00:01:20,160 --> 00:01:23,040
اوسط، یہ آپ کو نیٹ ورک کی کل لاگت فراہم کرتا ہے۔

20
00:01:23,040 --> 00:01:26,320
گویا اس کے بارے میں سوچنا کافی نہیں ہے، جیسا کہ پچھلی ویڈیو میں بیان کیا گیا ہے،

21
00:01:26,320 --> 00:01:31,700
ہم جس چیز کی تلاش کر رہے ہیں وہ اس لاگت کے فنکشن کا منفی میلان ہے،

22
00:01:31,700 --> 00:01:36,000
جو آپ کو بتاتا ہے کہ آپ کو تمام وزن اور تعصبات کو کیسے تبدیل کرنے کی

23
00:01:36,000 --> 00:01:43,080
ضرورت ہے۔ یہ کنکشن، تاکہ سب سے زیادہ مؤثر طریقے سے لاگت کو کم کیا جا سکے.

24
00:01:43,080 --> 00:01:48,600
بیک پروپیگیشن، اس ویڈیو کا موضوع، اس پاگل پیچیدہ

25
00:01:48,600 --> 00:01:49,600
میلان کی کمپیوٹنگ کے لیے ایک الگورتھم ہے۔

26
00:01:49,600 --> 00:01:53,300
پچھلی ویڈیو کا ایک خیال جو میں واقعی میں چاہتا ہوں کہ آپ ابھی اپنے ذہن

27
00:01:53,300 --> 00:01:58,280
میں مضبوطی سے رکھیں وہ یہ ہے کہ 13,000 جہتوں میں ایک سمت کے طور پر

28
00:01:58,280 --> 00:02:02,660
گریڈیئنٹ ویکٹر کے بارے میں سوچنا، اسے ہلکے سے ڈالنا ہے، ہمارے تخیلات کے دائرہ سے

29
00:02:02,660 --> 00:02:04,620
باہر، ایک اور بات ہے۔ جس طرح سے آپ اس کے بارے میں سوچ سکتے ہیں۔

30
00:02:04,620 --> 00:02:09,700
یہاں ہر جزو کی وسعت آپ کو بتا رہی ہے کہ لاگت

31
00:02:09,700 --> 00:02:11,820
کا فنکشن ہر وزن اور تعصب کے لیے کتنا حساس ہے۔

32
00:02:11,820 --> 00:02:15,180
مثال کے طور پر، ہم کہتے ہیں کہ آپ اس عمل سے گزرتے ہیں جس کو میں بیان کرنے

33
00:02:15,180 --> 00:02:19,800
جا رہا ہوں، اور منفی میلان کی گنتی کریں، اور یہاں اس کنارے پر وزن سے وابستہ جزو

34
00:02:19,800 --> 00:02:26,940
3 نکلتا ہے۔ 2، جب کہ اس کنارے سے وابستہ جزو یہاں 0 کے طور پر نکلتا ہے۔ 1۔

35
00:02:26,940 --> 00:02:31,520
جس طرح سے آپ اس کی تشریح کریں گے وہ یہ ہے کہ فنکشن کی لاگت اس پہلے

36
00:02:31,520 --> 00:02:36,100
وزن میں ہونے والی تبدیلیوں کے مقابلے میں 32 گنا زیادہ حساس ہے، لہذا اگر آپ اس

37
00:02:36,100 --> 00:02:40,780
قدر کو تھوڑا سا ہلائیں گے، تو اس سے لاگت میں کچھ تبدیلی آئے گی، اور وہ

38
00:02:40,780 --> 00:02:45,580
تبدیلی اس سے 32 گنا زیادہ ہے جو اس دوسرے وزن کو ایک ہی ہلچل دے گا۔

39
00:02:45,580 --> 00:02:52,500
ذاتی طور پر، جب میں پہلی بار بیک پروپیگیشن کے بارے میں سیکھ رہا تھا، میرے خیال

40
00:02:52,500 --> 00:02:55,820
میں سب سے زیادہ مبہم پہلو صرف ان سب کا تعاقب کرنے کا اشارہ اور انڈیکس تھا۔

41
00:02:55,820 --> 00:03:00,240
لیکن ایک بار جب آپ اس الگورتھم کا ہر ایک حصہ واقعی کیا کر رہا

42
00:03:00,240 --> 00:03:04,540
ہے اسے کھول دیں، اس کا ہر انفرادی اثر درحقیقت کافی بدیہی ہوتا ہے،

43
00:03:04,540 --> 00:03:07,740
یہ صرف اتنا ہے کہ ایک دوسرے کے اوپر بہت سی ایڈجسٹمنٹ ہوتی ہے۔

44
00:03:07,740 --> 00:03:11,380
لہذا میں یہاں اشارے کو مکمل نظر انداز کرنے کے ساتھ چیزوں کو شروع کرنے جا رہا ہوں،

45
00:03:11,380 --> 00:03:17,380
اور ہر تربیتی مثال کے وزن اور تعصبات پر ہونے والے اثرات کے ذریعے صرف قدم اٹھاؤں گا۔

46
00:03:17,380 --> 00:03:21,880
چونکہ لاگت کے فنکشن میں تمام دسیوں ہزار تربیتی مثالوں کے مقابلے میں فی مثال ایک خاص

47
00:03:21,880 --> 00:03:26,980
لاگت کا اوسط شامل ہوتا ہے، اس لیے جس طرح سے ہم ایک گریڈینٹ ڈیسنٹ قدم کے

48
00:03:26,980 --> 00:03:31,740
لیے وزن اور تعصبات کو ایڈجسٹ کرتے ہیں وہ بھی ہر ایک مثال پر منحصر ہے۔

49
00:03:31,740 --> 00:03:35,300
یا اس کے بجائے، اصولی طور پر یہ ہونا چاہیے، لیکن کمپیوٹیشنل کارکردگی کے لیے ہم بعد میں ایک چھوٹی

50
00:03:35,300 --> 00:03:39,860
سی تدبیر کریں گے تاکہ آپ کو ہر قدم کے لیے ہر ایک مثال کو مارنے کی ضرورت نہ پڑے۔

51
00:03:39,860 --> 00:03:44,460
دوسرے معاملات میں، ابھی، ہم صرف ایک ہی مثال پر

52
00:03:44,460 --> 00:03:46,780
توجہ مرکوز کرنے جا رہے ہیں، یہ 2 کی تصویر۔

53
00:03:46,780 --> 00:03:51,740
اس ایک تربیتی مثال پر کیا اثر ہونا چاہیے کہ وزن اور تعصبات کو کیسے ایڈجسٹ کیا جاتا ہے؟

54
00:03:51,740 --> 00:03:56,040
ہم کہتے ہیں کہ ہم اس مقام پر ہیں جہاں نیٹ ورک ابھی تک اچھی طرح سے تربیت یافتہ نہیں ہے،

55
00:03:56,040 --> 00:04:01,620
لہذا آؤٹ پٹ میں ایکٹیویشنز کافی بے ترتیب نظر آنے والی ہیں، شاید کچھ 0 جیسا۔ 5، 0۔ 8، 0۔ 2،

56
00:04:01,620 --> 00:04:02,780
پر اور پر.

57
00:04:02,780 --> 00:04:06,700
ہم ان ایکٹیویشنز کو براہ راست تبدیل نہیں کر سکتے، ہم صرف وزن

58
00:04:06,700 --> 00:04:11,380
اور تعصبات پر اثر انداز ہوتے ہیں، لیکن یہ ٹریک رکھنے میں مددگار

59
00:04:11,380 --> 00:04:13,340
ہے کہ ہم اس آؤٹ پٹ پرت میں کونسی ایڈجسٹمنٹ کرنا چاہتے ہیں۔

60
00:04:13,340 --> 00:04:18,220
اور چونکہ ہم چاہتے ہیں کہ یہ تصویر کو 2 کے طور پر درجہ بندی کرے، اس لیے ہم

61
00:04:18,220 --> 00:04:21,700
چاہتے ہیں کہ اس تیسری قدر کو دھکیل دیا جائے جب کہ باقی تمام نیچے دھکیل دی جائیں۔

62
00:04:21,700 --> 00:04:27,620
مزید یہ کہ، ان nudges کے سائز متناسب ہونے چاہئیں کہ

63
00:04:27,620 --> 00:04:30,220
ہر موجودہ قدر اپنی ہدف کی قدر سے کتنی دور ہے۔

64
00:04:30,220 --> 00:04:35,260
مثال کے طور پر، اس نمبر 2 کے نیوران کی ایکٹیویشن میں اضافہ

65
00:04:35,260 --> 00:04:39,620
ایک لحاظ سے نمبر 8 کے نیوران میں کمی سے زیادہ اہم ہے،

66
00:04:39,620 --> 00:04:42,060
جو پہلے ہی اس کے کافی قریب ہے جہاں اسے ہونا چاہیے۔

67
00:04:42,060 --> 00:04:46,260
تو مزید زوم کرتے ہوئے، آئیے صرف اس ایک نیوران پر

68
00:04:46,260 --> 00:04:47,900
توجہ مرکوز کریں، جس کی ایکٹیویشن کو ہم بڑھانا چاہتے ہیں۔

69
00:04:47,900 --> 00:04:53,680
یاد رکھیں، اس ایکٹیویشن کی تعریف پچھلی پرت میں تمام ایکٹیویشنز کی ایک خاص

70
00:04:53,680 --> 00:04:58,380
وزنی رقم کے طور پر کی جاتی ہے، نیز ایک تعصب، جو پھر سب

71
00:04:58,380 --> 00:05:01,900
کچھ جیسے سگمائیڈ اسکویشیفیکیشن فنکشن، یا ایک ReLU میں پلگ ان ہوتا ہے۔

72
00:05:01,900 --> 00:05:07,060
اس لیے تین مختلف راستے ہیں جو اس ایکٹیویشن کو بڑھانے

73
00:05:07,060 --> 00:05:08,060
میں مدد کے لیے مل کر ٹیم بنا سکتے ہیں۔

74
00:05:08,060 --> 00:05:12,800
آپ تعصب کو بڑھا سکتے ہیں، آپ وزن بڑھا سکتے ہیں،

75
00:05:12,800 --> 00:05:15,300
اور آپ پچھلی پرت سے ایکٹیویشن کو تبدیل کر سکتے ہیں۔

76
00:05:15,300 --> 00:05:19,720
اس بات پر توجہ مرکوز کرتے ہوئے کہ وزن کو کس طرح ایڈجسٹ کیا جانا چاہئے،

77
00:05:19,720 --> 00:05:21,460
اس بات پر توجہ دیں کہ اصل میں وزن کے اثر کی مختلف سطحیں ہیں۔

78
00:05:21,460 --> 00:05:25,100
پچھلی پرت کے روشن ترین نیوران کے ساتھ رابطے سب سے زیادہ اثر رکھتے

79
00:05:25,100 --> 00:05:31,420
ہیں کیونکہ ان وزنوں کو بڑی ایکٹیویشن اقدار سے ضرب دیا جاتا ہے۔

80
00:05:31,420 --> 00:05:35,820
لہذا اگر آپ ان وزنوں میں سے کسی ایک کو بڑھانا چاہتے ہیں، تو اس کا اصل

81
00:05:35,820 --> 00:05:40,900
لاگت کے فنکشن پر مدھم نیوران کے ساتھ رابطوں کے وزن کو بڑھانے کے مقابلے میں زیادہ

82
00:05:40,900 --> 00:05:44,020
مضبوط اثر پڑتا ہے، کم از کم جہاں تک اس ایک تربیتی مثال کا تعلق ہے۔

83
00:05:44,020 --> 00:05:48,700
یاد رکھیں، جب ہم تدریجی نزول کے بارے میں بات کرتے ہیں، تو ہم صرف اس بات کی پرواہ

84
00:05:48,700 --> 00:05:53,020
نہیں کرتے ہیں کہ آیا ہر ایک جز کو اوپر یا نیچے کیا جانا چاہیے، ہمیں اس بات کی

85
00:05:53,020 --> 00:05:54,020
پرواہ ہے کہ کون سا آپ کو آپ کے پیسے کے لیے سب سے زیادہ دھچکا دیتا ہے۔

86
00:05:54,020 --> 00:06:00,260
یہ، ویسے، کم از کم کسی حد تک نیورو سائنس میں ایک نظریہ کی یاد دلاتا

87
00:06:00,260 --> 00:06:04,900
ہے کہ نیوران کے حیاتیاتی نیٹ ورک کس طرح سیکھتے ہیں، ہیبیئن تھیوری، جس کا خلاصہ

88
00:06:04,900 --> 00:06:06,940
اکثر اس جملے میں کیا جاتا ہے، نیوران جو ایک دوسرے کے ساتھ تار لگاتے ہیں۔

89
00:06:06,940 --> 00:06:12,460
یہاں، وزن میں سب سے بڑا اضافہ، کنکشن کی سب سے

90
00:06:12,460 --> 00:06:16,860
بڑی مضبوطی، نیوران کے درمیان ہوتی ہے جو سب سے زیادہ

91
00:06:16,860 --> 00:06:18,100
فعال ہیں اور جن کو ہم زیادہ فعال بنانا چاہتے ہیں۔

92
00:06:18,100 --> 00:06:22,520
ایک لحاظ سے، نیوران جو 2 کو دیکھتے ہوئے فائرنگ کر رہے ہیں، اس کے

93
00:06:22,520 --> 00:06:25,440
بارے میں سوچتے ہوئے فائرنگ کرنے والوں سے زیادہ مضبوطی سے جڑ جاتے ہیں۔

94
00:06:25,440 --> 00:06:29,240
واضح طور پر، میں اس پوزیشن میں نہیں ہوں کہ میں کسی نہ کسی طرح اس بارے میں بیان

95
00:06:29,240 --> 00:06:34,020
دے سکوں کہ آیا نیوران کے مصنوعی نیٹ ورک حیاتیاتی دماغوں کی طرح کچھ بھی برتاؤ کرتے ہیں، اور

96
00:06:34,020 --> 00:06:39,440
یہ ایک دوسرے کے ساتھ فائر کرتا ہے یہ خیال ایک دو معنی خیز ستارے کے ساتھ آتا ہے،

97
00:06:39,440 --> 00:06:41,760
لیکن ایک بہت ہی ڈھیلے کے طور پر لیا جاتا ہے۔ مشابہت، مجھے یہ نوٹ کرنا دلچسپ لگتا ہے۔

98
00:06:41,760 --> 00:06:46,760
بہرحال، تیسرا طریقہ جس سے ہم اس نیوران کی ایکٹیویشن کو بڑھانے میں مدد کر

99
00:06:46,760 --> 00:06:49,360
سکتے ہیں وہ ہے پچھلی پرت میں موجود تمام ایکٹیویشن کو تبدیل کر کے۔

100
00:06:49,360 --> 00:06:55,080
یعنی، اگر مثبت وزن کے ساتھ اس ہندسے 2 کے نیورون سے جڑی ہر

101
00:06:55,080 --> 00:06:59,480
چیز روشن ہو جائے، اور اگر منفی وزن کے ساتھ جڑی ہوئی ہر چیز

102
00:06:59,480 --> 00:07:02,680
مدھم ہو جائے، تو وہ ہندسہ 2 نیورون زیادہ فعال ہو جائے گا۔

103
00:07:02,680 --> 00:07:06,200
اور وزن میں ہونے والی تبدیلیوں کی طرح، آپ ان تبدیلیوں کو تلاش کرکے جو متعلقہ وزن

104
00:07:06,200 --> 00:07:10,840
کے سائز کے متناسب ہوں، اپنے پیسے کے لیے سب سے زیادہ فائدہ اٹھانے والے ہیں۔

105
00:07:10,840 --> 00:07:16,520
اب یقیناً، ہم ان سرگرمیوں پر براہ راست اثر انداز نہیں

106
00:07:16,520 --> 00:07:18,320
ہو سکتے، ہمارا صرف وزن اور تعصبات پر کنٹرول ہے۔

107
00:07:18,320 --> 00:07:22,960
لیکن بالکل اسی طرح جیسے آخری پرت کے ساتھ، اس بات

108
00:07:22,960 --> 00:07:23,960
کو نوٹ کرنا مددگار ہے کہ وہ مطلوبہ تبدیلیاں کیا ہیں۔

109
00:07:23,960 --> 00:07:29,040
لیکن ذہن میں رکھیں، یہاں ایک قدم کو زوم آؤٹ کرتے ہوئے،

110
00:07:29,040 --> 00:07:30,040
یہ وہی ہے جو ہندسہ 2 آؤٹ پٹ نیوران چاہتا ہے۔

111
00:07:30,040 --> 00:07:34,960
یاد رکھیں، ہم یہ بھی چاہتے ہیں کہ آخری تہہ میں موجود دیگر تمام نیوران

112
00:07:34,960 --> 00:07:38,460
کم فعال ہو جائیں، اور ان دوسرے آؤٹ پٹ نیورونز میں سے ہر ایک

113
00:07:38,460 --> 00:07:43,200
کے اپنے خیالات ہیں کہ اس دوسری سے آخری تہہ کا کیا ہونا چاہیے۔

114
00:07:43,200 --> 00:07:49,220
لہذا اس ہندسے 2 نیورون کی خواہش کو دوسرے تمام آؤٹ پٹ نیوران کی

115
00:07:49,220 --> 00:07:54,800
خواہشات کے ساتھ شامل کیا جاتا ہے کہ اس دوسری سے آخری تہہ

116
00:07:54,800 --> 00:08:00,240
کا کیا ہونا چاہئے، دوبارہ اسی وزن کے تناسب سے، اور اس تناسب

117
00:08:00,240 --> 00:08:01,740
میں کہ ان میں سے ہر ایک نیوران کو کتنی ضرورت ہے۔ بدلنا.

118
00:08:01,740 --> 00:08:05,940
یہ وہ جگہ ہے جہاں پیچھے کی طرف تبلیغ کرنے کا خیال آتا ہے۔

119
00:08:05,940 --> 00:08:11,080
ان تمام مطلوبہ اثرات کو ایک ساتھ شامل کرنے سے، آپ کو بنیادی طور پر ان nudges

120
00:08:11,080 --> 00:08:14,300
کی فہرست ملتی ہے جو آپ اس دوسری سے آخری پرت کے ساتھ ہونا چاہتے ہیں۔

121
00:08:14,300 --> 00:08:18,740
اور ایک بار جب آپ کے پاس یہ ہو جائیں، تو آپ اسی عمل کو متعلقہ وزن اور

122
00:08:18,740 --> 00:08:23,400
تعصبات پر بار بار لاگو کر سکتے ہیں جو ان اقدار کا تعین کرتے ہیں، اسی عمل کو

123
00:08:23,400 --> 00:08:29,180
دہراتے ہوئے جس سے میں ابھی گزرا ہوں اور نیٹ ورک کے ذریعے پیچھے کی طرف بڑھتے ہیں۔

124
00:08:29,180 --> 00:08:33,960
اور تھوڑا سا آگے بڑھاتے ہوئے، یاد رکھیں کہ یہ سب کچھ اس طرح ہے جس طرح

125
00:08:33,960 --> 00:08:37,520
ایک واحد تربیتی مثال ان وزنوں اور تعصبات میں سے ہر ایک کو دھکیلنا چاہتی ہے۔

126
00:08:37,520 --> 00:08:41,400
اگر ہم صرف وہی بات سنتے ہیں جو وہ 2 چاہتا ہے، تو نیٹ ورک کو بالآخر

127
00:08:41,400 --> 00:08:44,140
صرف تمام تصاویر کو 2 کے طور پر درجہ بندی کرنے کی ترغیب دی جائے گی۔

128
00:08:44,140 --> 00:08:49,500
لہذا آپ کیا کرتے ہیں ہر دوسری تربیتی مثال کے لیے اسی بیک پروپ روٹین سے

129
00:08:49,500 --> 00:08:54,700
گزرنا ہے، یہ ریکارڈ کرنا ہے کہ ان میں سے ہر ایک کس طرح وزن اور

130
00:08:54,700 --> 00:09:02,300
تعصبات کو تبدیل کرنا چاہے گا، اور ان مطلوبہ تبدیلیوں کو ایک ساتھ اوسط کریں۔

131
00:09:02,300 --> 00:09:08,260
یہاں ہر ایک وزن اور تعصب کے لیے اوسط nudges کا یہ

132
00:09:08,260 --> 00:09:12,340
مجموعہ ہے، ڈھیلے انداز میں، آخری ویڈیو میں حوالہ کردہ لاگت کے

133
00:09:12,340 --> 00:09:14,360
فنکشن کا منفی میلان، یا کم از کم اس کے متناسب کچھ۔

134
00:09:14,360 --> 00:09:18,980
میں صرف اس لیے کہتا ہوں کہ میں نے ان نکات کے بارے میں ابھی تک مقداری طور پر

135
00:09:18,980 --> 00:09:23,480
درستگی حاصل کرنا ہے، لیکن اگر آپ ہر اس تبدیلی کو سمجھتے ہیں جس کا میں نے ابھی حوالہ

136
00:09:23,480 --> 00:09:28,740
دیا ہے، کیوں کہ کچھ متناسب طور پر دوسروں کے مقابلے میں بڑے کیوں ہیں، اور ان سب کو

137
00:09:28,740 --> 00:09:34,100
ایک ساتھ جوڑنے کی ضرورت کیسے ہے، آپ میکانکس کو سمجھتے ہیں۔ بیک پروپیگیشن دراصل کیا کر رہی ہے۔

138
00:09:34,100 --> 00:09:38,540
ویسے، عملی طور پر، کمپیوٹرز کو ہر تربیتی مثال کے ہر تدریجی نزول قدم

139
00:09:38,540 --> 00:09:43,120
کے اثر و رسوخ کو شامل کرنے میں بہت زیادہ وقت لگتا ہے۔

140
00:09:43,120 --> 00:09:45,540
تو یہاں وہ ہے جو اس کے بجائے عام طور پر کیا جاتا ہے۔

141
00:09:45,540 --> 00:09:50,460
آپ تصادفی طور پر اپنے تربیتی ڈیٹا کو تبدیل کرتے ہیں اور اسے منی بیچوں کے پورے

142
00:09:50,460 --> 00:09:53,380
گروپ میں تقسیم کرتے ہیں، آئیے کہتے ہیں کہ ہر ایک کے پاس 100 تربیتی مثالیں ہیں۔

143
00:09:53,380 --> 00:09:56,980
پھر آپ منی بیچ کے مطابق ایک قدم کی گنتی کریں۔

144
00:09:56,980 --> 00:10:00,840
یہ لاگت کے فنکشن کا اصل میلان نہیں ہے، جس کا انحصار تمام تربیتی اعداد و شمار

145
00:10:00,840 --> 00:10:06,260
پر ہے، نہ کہ اس چھوٹے سب سیٹ پر، اس لیے یہ نیچے کی طرف سب سے

146
00:10:06,260 --> 00:10:10,900
زیادہ موثر قدم نہیں ہے، لیکن ہر منی بیچ آپ کو بہت اچھا تخمینہ فراہم کرتا ہے،

147
00:10:10,900 --> 00:10:12,900
اور اس سے بھی اہم بات یہ ہے۔ آپ کو ایک اہم کمپیوٹیشنل اسپیڈ اپ دیتا ہے۔

148
00:10:12,900 --> 00:10:16,900
اگر آپ متعلقہ لاگت کی سطح کے نیچے اپنے نیٹ ورک کی رفتار کی منصوبہ بندی کرتے ہیں، تو یہ

149
00:10:16,900 --> 00:10:22,020
کچھ زیادہ ہی ایسا ہو گا جیسے ایک نشے میں دھت آدمی کسی پہاڑی سے نیچے کی ٹھوکریں کھا رہا

150
00:10:22,020 --> 00:10:26,880
ہو لیکن تیز قدم اٹھاتا ہو، بجائے اس کے کہ کوئی احتیاط سے حساب کرنے والا آدمی ہر قدم کے

151
00:10:26,880 --> 00:10:31,620
نیچے کی سمت کا تعین کر رہا ہو۔ اس سمت میں بہت سست اور محتاط قدم اٹھانے سے پہلے۔

152
00:10:31,620 --> 00:10:35,200
اس تکنیک کو اسٹاکسٹک گریڈینٹ ڈیسنٹ کہا جاتا ہے۔

153
00:10:35,200 --> 00:10:40,400
یہاں بہت کچھ ہو رہا ہے، تو آئیے اس کا خلاصہ خود کریں، کیا ہم؟

154
00:10:40,400 --> 00:10:45,480
بیک پروپیگیشن اس بات کا تعین کرنے کے لیے الگورتھم ہے کہ کس طرح ایک واحد

155
00:10:45,480 --> 00:10:50,040
تربیتی مثال وزن اور تعصبات کو دھکیلنا چاہتی ہے، نہ صرف اس لحاظ سے کہ

156
00:10:50,040 --> 00:10:54,780
آیا انہیں اوپر جانا چاہیے یا نیچے، بلکہ اس لحاظ سے کہ ان تبدیلیوں کے لیے

157
00:10:54,780 --> 00:10:56,240
کون سے نسبتی تناسب سب سے زیادہ تیزی سے کمی کا باعث بنتے ہیں۔ لاگت.

158
00:10:56,240 --> 00:11:00,720
ایک حقیقی تدریجی نزول کے قدم میں آپ کی تمام دسیوں اور ہزاروں تربیتی مثالوں کے

159
00:11:00,720 --> 00:11:05,920
لیے ایسا کرنا اور آپ کو حاصل ہونے والی مطلوبہ تبدیلیوں کا اوسط شامل کرنا شامل

160
00:11:05,920 --> 00:11:11,680
ہے، لیکن یہ حسابی طور پر سست ہے، اس لیے اس کے بجائے آپ ڈیٹا کو

161
00:11:11,680 --> 00:11:14,000
تصادفی طور پر چھوٹے بیچوں میں تقسیم کریں اور ہر قدم کی گنتی کریں منی بیچ.

162
00:11:14,000 --> 00:11:18,600
بار بار تمام چھوٹے بیچوں سے گزرتے ہوئے اور یہ ایڈجسٹمنٹ کرتے ہوئے، آپ مقامی

163
00:11:18,600 --> 00:11:23,420
کم از کم لاگت کے فنکشن کی طرف بڑھیں گے، جس کا مطلب یہ ہے

164
00:11:23,420 --> 00:11:27,540
کہ آپ کا نیٹ ورک تربیتی مثالوں پر واقعی ایک اچھا کام کرے گا۔

165
00:11:27,540 --> 00:11:32,600
تو اس سب کے ساتھ کہا، کوڈ کی ہر سطر جو بیک پروپ کو لاگو کرنے میں جائے گی درحقیقت

166
00:11:32,600 --> 00:11:37,680
اس چیز سے مطابقت رکھتی ہے جو آپ نے اب دیکھی ہے، کم از کم غیر رسمی شرائط میں۔

167
00:11:37,680 --> 00:11:41,900
لیکن بعض اوقات یہ جاننا کہ ریاضی کیا کرتا ہے صرف آدھی جنگ ہے، اور صرف اس

168
00:11:41,900 --> 00:11:44,780
لات کی نمائندگی کرنا وہ جگہ ہے جہاں یہ سب گڑبڑ اور الجھن میں پڑ جاتا ہے۔

169
00:11:44,780 --> 00:11:49,360
لہذا، آپ میں سے ان لوگوں کے لیے جو مزید گہرائی میں جانا چاہتے ہیں، اگلی ویڈیو انہی

170
00:11:49,360 --> 00:11:53,400
خیالات سے گزرتی ہے جو ابھی یہاں پیش کیے گئے تھے، لیکن بنیادی حساب کتاب کے لحاظ سے،

171
00:11:53,400 --> 00:11:57,460
جس سے امید ہے کہ اس موضوع کو دیکھتے ہی اسے تھوڑا سا واقف کرانا چاہیے۔ دیگر وسائل.

172
00:11:57,460 --> 00:12:01,220
اس سے پہلے، ایک بات پر زور دینے کے قابل یہ ہے کہ اس الگورتھم

173
00:12:01,220 --> 00:12:05,840
کے کام کرنے کے لیے، اور یہ صرف اعصابی نیٹ ورکس کے علاوہ ہر طرح

174
00:12:05,840 --> 00:12:06,840
کی مشین لرننگ کے لیے ہے، آپ کو بہت زیادہ تربیتی ڈیٹا کی ضرورت ہے۔

175
00:12:06,840 --> 00:12:10,740
ہمارے معاملے میں، ایک چیز جو ہاتھ سے لکھے ہوئے ہندسوں کو اتنی اچھی مثال بناتی ہے وہ یہ ہے

176
00:12:10,740 --> 00:12:15,380
کہ MNIST ڈیٹا بیس موجود ہے، جس میں بہت سی مثالیں ہیں جن پر انسانوں نے لیبل لگایا ہے۔

177
00:12:15,380 --> 00:12:19,000
لہذا ایک عام چیلنج جس سے آپ میں سے مشین لرننگ میں کام کرنے والے واقف ہوں گے وہ صرف

178
00:12:19,040 --> 00:12:22,880
لیبل لگا ہوا تربیتی ڈیٹا حاصل کرنا ہے جس کی آپ کو درحقیقت ضرورت ہے، چاہے اس میں لوگ دسیوں

179
00:12:22,880 --> 00:12:27,400
ہزار امیجز پر لیبل لگا رہے ہوں، یا کوئی بھی دوسری قسم کی ڈیٹا جس سے آپ نمٹ رہے ہوں۔

