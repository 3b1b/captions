1
00:00:00,000 --> 00:00:09,640
هنا، نتناول الانتشار العكسي، وهو الخوارزمية الأساسية وراء كيفية تعلم الشبكات العصبية.

2
00:00:09,640 --> 00:00:13,520
بعد تلخيص سريع لما نحن فيه، أول شيء سأفعله هو إجراء إرشادات

3
00:00:13,520 --> 00:00:17,400
بديهية لما تفعله الخوارزمية فعليًا، دون أي إشارة إلى الصيغ.

4
00:00:17,400 --> 00:00:20,746
ثم، بالنسبة لأولئك منكم الذين يريدون التعمق في الرياضيات، فإن

5
00:00:20,746 --> 00:00:24,040
الفيديو التالي يتناول حساب التفاضل والتكامل الأساسي لكل هذا.

6
00:00:24,040 --> 00:00:27,304
إذا شاهدت مقطعي الفيديو الأخيرين، أو إذا كنت تقفز للتو بالخلفية

7
00:00:27,304 --> 00:00:31,080
المناسبة، فأنت تعرف ما هي الشبكة العصبية، وكيف تغذي المعلومات إلى الأمام.

8
00:00:31,080 --> 00:00:35,646
هنا، نحن ننفذ المثال الكلاسيكي للتعرف على الأرقام المكتوبة بخط اليد والتي يتم

9
00:00:35,646 --> 00:00:40,270
إدخال قيم البكسل الخاصة بها في الطبقة الأولى من الشبكة التي تحتوي على 784 خلية

10
00:00:40,270 --> 00:00:44,778
عصبية، وقد قمت بعرض شبكة ذات طبقتين مخفيتين تحتوي كل منهما على 16 خلية عصبية

11
00:00:44,778 --> 00:00:49,520
فقط، ومخرج طبقة من 10 خلايا عصبية، تشير إلى الرقم الذي تختاره الشبكة كإجابة لها.

12
00:00:49,520 --> 00:00:55,575
أتوقع منك أيضًا أن تفهم النسب المتدرج، كما هو موضح في الفيديو الأخير، وكيف أن ما

13
00:00:55,575 --> 00:01:02,080
نعنيه بالتعلم هو أننا نريد العثور على الأوزان والتحيزات التي تقلل من دالة تكلفة معينة.

14
00:01:02,080 --> 00:01:08,820
كتذكير سريع، مقابل تكلفة مثال تدريبي واحد، فإنك تأخذ المخرجات التي تقدمها الشبكة،

15
00:01:08,820 --> 00:01:15,560
بالإضافة إلى المخرجات التي تريدها أن تعطيها، وتضيف مربعات الاختلافات بين كل مكون.

16
00:01:15,560 --> 00:01:19,330
عند القيام بذلك لجميع عشرات الآلاف من أمثلة التدريب الخاصة بك

17
00:01:19,330 --> 00:01:23,040
وحساب متوسط النتائج، فإن هذا يمنحك التكلفة الإجمالية للشبكة.

18
00:01:23,040 --> 00:01:29,521
كما لو أن هذا لا يكفي للتفكير فيه، كما هو موضح في الفيديو الأخير، فإن الشيء

19
00:01:29,521 --> 00:01:36,002
الذي نبحث عنه هو التدرج السلبي لدالة التكلفة هذه، والذي يخبرك كيف تحتاج إلى

20
00:01:36,002 --> 00:01:43,080
تغيير كل الأوزان والتحيزات، كل هذه الاتصالات، وذلك لتقليل التكلفة بشكل أكثر كفاءة.

21
00:01:43,080 --> 00:01:49,600
Backpropagation، موضوع هذا الفيديو، هو خوارزمية لحساب هذا التدرج المعقد والجنوني.

22
00:01:49,600 --> 00:01:54,696
الفكرة الوحيدة من الفيديو الأخير التي أريدك حقًا أن تضعها بقوة في ذهنك الآن

23
00:01:54,696 --> 00:01:59,523
هي أنه نظرًا لأن التفكير في متجه التدرج كاتجاه في 13000 بُعد هو، بعبارة

24
00:01:59,523 --> 00:02:04,620
مبسطة، خارج نطاق مخيلتنا، هناك فكرة أخرى الطريقة التي يمكنك التفكير في ذلك.

25
00:02:04,620 --> 00:02:11,820
يخبرك حجم كل مكون هنا بمدى حساسية دالة التكلفة لكل وزن وتحيز.

26
00:02:11,820 --> 00:02:16,707
على سبيل المثال، لنفترض أنك قمت بتنفيذ العملية التي أنا على وشك

27
00:02:16,707 --> 00:02:21,747
وصفها، وحساب التدرج السلبي، والمكون المرتبط بالوزن على هذه الحافة

28
00:02:21,747 --> 00:02:26,940
هنا يصبح 3.2، في حين أن المكون المرتبط بهذه الحافة هنا يخرج كـ 0.1.

29
00:02:26,940 --> 00:02:33,104
الطريقة التي تفسر بها ذلك هي أن تكلفة الوظيفة أكثر حساسية بمقدار 32 مرة للتغيرات في

30
00:02:33,104 --> 00:02:39,415
هذا الوزن الأول، لذلك إذا قمت بتحريك هذه القيمة قليلاً، فسوف يتسبب ذلك في بعض التغيير

31
00:02:39,415 --> 00:02:45,580
في التكلفة، وهذا التغيير أكبر بـ 32 مرة مما ستعطيه نفس الاهتزازة لهذا الوزن الثاني.

32
00:02:45,580 --> 00:02:50,659
شخصيًا، عندما كنت أتعلم لأول مرة عن الانتشار العكسي، أعتقد أن

33
00:02:50,659 --> 00:02:55,820
الجانب الأكثر إرباكًا كان مجرد الترميز ومطاردة الفهرس لكل شيء.

34
00:02:55,820 --> 00:02:59,649
ولكن بمجرد أن تكتشف ما يفعله كل جزء من هذه الخوارزمية بالفعل،

35
00:02:59,649 --> 00:03:03,540
فإن كل تأثير فردي يحدثه يكون في الواقع بديهيًا جدًا، الأمر فقط

36
00:03:03,540 --> 00:03:07,740
أن هناك الكثير من التعديلات الصغيرة التي يتم وضعها فوق بعضها البعض.

37
00:03:07,740 --> 00:03:12,647
لذا، سأبدأ الأمور هنا مع التجاهل التام للتدوين، وسأنتقل

38
00:03:12,647 --> 00:03:17,380
فقط عبر تأثيرات كل مثال تدريبي على الأوزان والتحيزات.

39
00:03:17,380 --> 00:03:22,118
نظرًا لأن دالة التكلفة تتضمن حساب متوسط تكلفة معينة لكل مثال على

40
00:03:22,118 --> 00:03:26,856
عشرات الآلاف من أمثلة التدريب، فإن الطريقة التي نضبط بها الأوزان

41
00:03:26,856 --> 00:03:31,740
والتحيزات لخطوة نزول متدرجة واحدة تعتمد أيضًا على كل مثال على حدة.

42
00:03:31,740 --> 00:03:35,639
أو بالأحرى، من حيث المبدأ، ينبغي أن يكون الأمر كذلك، ولكن من أجل الكفاءة

43
00:03:35,639 --> 00:03:39,860
الحسابية، سنقوم بخدعة صغيرة لاحقًا لمنعك من الحاجة إلى ضرب كل مثال في كل خطوة.

44
00:03:39,860 --> 00:03:46,780
في حالات أخرى، الآن، كل ما سنفعله هو تركيز انتباهنا على مثال واحد، هذه الصورة للرقم 2.

45
00:03:46,780 --> 00:03:51,740
ما هو التأثير الذي يجب أن يحدثه هذا المثال التدريبي على كيفية تعديل الأوزان والتحيزات؟

46
00:03:51,740 --> 00:03:57,329
لنفترض أننا وصلنا إلى مرحلة لم يتم فيها تدريب الشبكة بشكل جيد بعد، وبالتالي فإن

47
00:03:57,329 --> 00:04:02,780
عمليات التنشيط في المخرجات ستبدو عشوائية جدًا، ربما مثل 0.5، 0.8، 0.2، وهكذا.

48
00:04:02,780 --> 00:04:08,334
لا يمكننا تغيير تلك التنشيطات بشكل مباشر، لدينا فقط تأثير على الأوزان والتحيزات،

49
00:04:08,334 --> 00:04:13,340
ولكن من المفيد تتبع التعديلات التي نرغب في إجرائها على طبقة الإخراج تلك.

50
00:04:13,340 --> 00:04:17,389
وبما أننا نريدها أن تصنف الصورة على أنها 2، فإننا نريد أن يتم

51
00:04:17,389 --> 00:04:21,700
دفع القيمة الثالثة للأعلى بينما يتم دفع جميع القيم الأخرى للأسفل.

52
00:04:21,700 --> 00:04:26,261
علاوة على ذلك، يجب أن تكون أحجام هذه الدفعات متناسبة

53
00:04:26,261 --> 00:04:30,220
مع مدى بعد كل قيمة حالية عن قيمتها المستهدفة.

54
00:04:30,220 --> 00:04:35,705
على سبيل المثال، الزيادة في تنشيط الخلية العصبية رقم 2 هي إلى حد ما أكثر أهمية من

55
00:04:35,705 --> 00:04:41,725
الانخفاض في الخلية العصبية رقم 8، والتي هي بالفعل قريبة جدًا من المكان الذي ينبغي أن تكون

56
00:04:41,725 --> 00:04:42,060
فيه.

57
00:04:42,060 --> 00:04:45,268
لذا، بالتكبير أكثر، دعونا نركز فقط على هذه الخلية

58
00:04:45,268 --> 00:04:47,900
العصبية، تلك التي نرغب في زيادة تنشيطها.

59
00:04:47,900 --> 00:04:54,502
تذكر، يتم تعريف هذا التنشيط على أنه مجموع مرجح معين لجميع عمليات التنشيط في الطبقة

60
00:04:54,502 --> 00:05:01,422
السابقة، بالإضافة إلى التحيز، والذي يتم بعد ذلك توصيله بشيء مثل وظيفة السحق السيني، أو

61
00:05:01,422 --> 00:05:01,900
ReLU.

62
00:05:01,900 --> 00:05:08,060
لذلك هناك ثلاث طرق مختلفة يمكن أن تتعاون معًا للمساعدة في زيادة هذا التنشيط.

63
00:05:08,060 --> 00:05:15,300
يمكنك زيادة التحيز، ويمكنك زيادة الأوزان، ويمكنك تغيير عمليات التنشيط من الطبقة السابقة.

64
00:05:15,300 --> 00:05:21,460
بالتركيز على كيفية ضبط الأوزان، لاحظ كيف أن للأوزان بالفعل مستويات مختلفة من التأثير.

65
00:05:21,460 --> 00:05:26,600
إن الاتصالات مع الخلايا العصبية الأكثر سطوعًا من الطبقة السابقة

66
00:05:26,600 --> 00:05:31,420
لها التأثير الأكبر حيث يتم ضرب تلك الأوزان بقيم تنشيط أكبر.

67
00:05:31,420 --> 00:05:35,641
لذا، إذا قمت بزيادة أحد هذه الأوزان، فسيكون لها في الواقع تأثير

68
00:05:35,641 --> 00:05:39,534
أقوى على دالة التكلفة النهائية من زيادة أوزان الاتصالات مع

69
00:05:39,534 --> 00:05:44,020
الخلايا العصبية الخافتة، على الأقل فيما يتعلق بهذا المثال التدريبي.

70
00:05:44,020 --> 00:05:49,088
تذكر، عندما نتحدث عن النسب المتدرج، فإننا لا نهتم فقط بما إذا كان يجب دفع

71
00:05:49,088 --> 00:05:54,020
كل مكون لأعلى أو لأسفل، بل نهتم بالمكونات التي تمنحك أكبر قدر من المال.

72
00:05:54,020 --> 00:05:58,444
هذا، بالمناسبة، يذكرنا على الأقل إلى حد ما بنظرية في علم الأعصاب حول كيفية

73
00:05:58,444 --> 00:06:02,692
تعلم الشبكات البيولوجية للخلايا العصبية، وهي نظرية هيبيان، والتي غالبًا

74
00:06:02,692 --> 00:06:06,940
ما يتم تلخيصها في العبارة، الخلايا العصبية التي تشتعل معًا تترابط معًا.

75
00:06:06,940 --> 00:06:12,176
هنا، أكبر زيادات في الأوزان، وأكبر تقوية للاتصالات، تحدث بين

76
00:06:12,176 --> 00:06:18,100
الخلايا العصبية الأكثر نشاطًا وتلك التي نرغب في أن تصبح أكثر نشاطًا.

77
00:06:18,100 --> 00:06:21,685
بمعنى ما، فإن الخلايا العصبية التي تنشط أثناء رؤية الرقم 2 تصبح

78
00:06:21,685 --> 00:06:25,440
أكثر ارتباطًا بتلك الخلايا العصبية التي تنشط عند التفكير في الأمر.

79
00:06:25,440 --> 00:06:29,505
لأكون واضحًا، لست في وضع يسمح لي بالإدلاء ببيانات بطريقة أو بأخرى حول

80
00:06:29,505 --> 00:06:33,396
ما إذا كانت الشبكات الاصطناعية من الخلايا العصبية تتصرف مثل العقول

81
00:06:33,396 --> 00:06:37,462
البيولوجية، وهذه الفكرة التي تنطلق معًا تأتي مع نجمتين ذات معنى، ولكن

82
00:06:37,462 --> 00:06:41,760
تم اعتبارها فضفاضة للغاية تشبيهًا، أجد أنه من المثير للاهتمام ملاحظة ذلك.

83
00:06:41,760 --> 00:06:45,427
على أية حال، الطريقة الثالثة التي يمكننا من خلالها المساعدة في زيادة

84
00:06:45,427 --> 00:06:49,360
تنشيط هذه الخلايا العصبية هي تغيير جميع عمليات التنشيط في الطبقة السابقة.

85
00:06:49,360 --> 00:06:53,756
على وجه التحديد، إذا أصبح كل شيء مرتبط بالخلية العصبية ذات الرقم 2

86
00:06:53,756 --> 00:06:58,283
ذات الوزن الإيجابي أكثر سطوعًا، وإذا أصبح كل شيء مرتبط بالوزن السلبي

87
00:06:58,283 --> 00:07:02,680
أكثر خفوتًا، فإن تلك الخلية العصبية ذات الرقم 2 ستصبح أكثر نشاطًا.

88
00:07:02,680 --> 00:07:06,559
وكما هو الحال مع تغييرات الوزن، ستحصل على أقصى استفادة من

89
00:07:06,559 --> 00:07:10,840
أموالك من خلال البحث عن تغييرات تتناسب مع حجم الأوزان المقابلة.

90
00:07:10,840 --> 00:07:14,506
الآن بالطبع، لا يمكننا التأثير بشكل مباشر على تلك

91
00:07:14,506 --> 00:07:18,320
التنشيطات، لدينا فقط السيطرة على الأوزان والتحيزات.

92
00:07:18,320 --> 00:07:21,024
ولكن كما هو الحال مع الطبقة الأخيرة، من المفيد

93
00:07:21,024 --> 00:07:23,960
الاحتفاظ بملاحظة حول ماهية تلك التغييرات المرغوبة.

94
00:07:23,960 --> 00:07:26,943
لكن ضع في اعتبارك، عند تصغير خطوة واحدة هنا، فإن هذا

95
00:07:26,943 --> 00:07:30,040
هو فقط ما تريده تلك الخلية العصبية الناتجة من الرقم 2.

96
00:07:30,040 --> 00:07:34,217
تذكر أننا نريد أيضًا أن تصبح جميع الخلايا العصبية الأخرى في

97
00:07:34,217 --> 00:07:38,534
الطبقة الأخيرة أقل نشاطًا، ولكل من تلك الخلايا العصبية الأخرى

98
00:07:38,534 --> 00:07:43,200
أفكارها الخاصة حول ما يجب أن يحدث لتلك الطبقة الثانية قبل الأخيرة.

99
00:07:43,200 --> 00:07:49,497
لذلك يتم إضافة رغبة هذه الخلية العصبية ذات الرقم 2 مع رغبات جميع الخلايا العصبية الناتجة

100
00:07:49,497 --> 00:07:55,654
الأخرى فيما يتعلق بما يجب أن يحدث لهذه الطبقة الثانية إلى الأخيرة، مرة أخرى بما يتناسب

101
00:07:55,654 --> 00:08:01,740
مع الأوزان المقابلة، وبما يتناسب مع مقدار احتياجات كل من تلك الخلايا العصبية للتغيير.

102
00:08:01,740 --> 00:08:05,940
وهنا تأتي فكرة الانتشار العكسي.

103
00:08:05,940 --> 00:08:09,932
من خلال جمع كل هذه التأثيرات المرغوبة معًا، تحصل بشكل أساسي على

104
00:08:09,932 --> 00:08:14,300
قائمة من التنبيهات التي تريد أن تحدث لهذه الطبقة الثانية إلى الأخيرة.

105
00:08:14,300 --> 00:08:21,911
وبمجرد حصولك على هذه، يمكنك تطبيق نفس العملية بشكل متكرر على الأوزان والتحيزات ذات الصلة

106
00:08:21,911 --> 00:08:29,180
التي تحدد تلك القيم، وتكرار نفس العملية التي مررت بها للتو والتحرك للخلف عبر الشبكة.

107
00:08:29,180 --> 00:08:33,281
وبالتصغير أكثر قليلاً، تذكر أن هذا كله هو الطريقة التي يرغب

108
00:08:33,281 --> 00:08:37,520
بها مثال تدريبي واحد في دفع كل واحد من تلك الأوزان والتحيزات.

109
00:08:37,520 --> 00:08:40,892
إذا استمعنا فقط إلى ما يريده هذا الشخصان، فسيتم تحفيز

110
00:08:40,892 --> 00:08:44,140
الشبكة في النهاية لتصنيف جميع الصور على أنها رقم 2.

111
00:08:44,140 --> 00:08:52,934
إذن ما تفعله هو اتباع نفس روتين الدعم الخلفي لكل مثال تدريبي آخر، وتسجيل كيف

112
00:08:52,934 --> 00:09:02,300
يرغب كل منهم في تغيير الأوزان والتحيزات، وحساب متوسط تلك التغييرات المرغوبة معًا.

113
00:09:02,300 --> 00:09:08,368
هذه المجموعة هنا من متوسط الدفعات لكل وزن وتحيز هي، بشكل فضفاض، التدرج السلبي

114
00:09:08,368 --> 00:09:14,360
لوظيفة التكلفة المشار إليها في الفيديو الأخير، أو على الأقل شيء يتناسب معها.

115
00:09:14,360 --> 00:09:20,940
أقول ذلك بشكل فضفاض فقط لأنني لم أحصل بعد على دقة كمية بشأن تلك التنبيهات، ولكن إذا

116
00:09:20,940 --> 00:09:27,598
فهمت كل تغيير أشرت إليه للتو، ولماذا يكون بعضها أكبر نسبيًا من البعض الآخر، وكيف يجب

117
00:09:27,598 --> 00:09:34,100
إضافتها جميعًا معًا، فإنك تفهم آليات حدوث ذلك. ما يفعله الانتشار العكسي في الواقع.

118
00:09:34,100 --> 00:09:38,610
بالمناسبة، في الممارسة العملية، يستغرق الأمر وقتًا طويلاً للغاية من

119
00:09:38,610 --> 00:09:43,120
أجهزة الكمبيوتر لإضافة تأثير كل مثال تدريبي في كل خطوة نزول متدرجة.

120
00:09:43,120 --> 00:09:45,540
إذن، إليك ما يتم فعله عادةً بدلاً من ذلك.

121
00:09:45,540 --> 00:09:49,575
يمكنك خلط بيانات التدريب الخاصة بك عشوائيًا وتقسيمها إلى مجموعة كاملة

122
00:09:49,575 --> 00:09:53,380
من الدفعات الصغيرة، لنفترض أن كل واحدة تحتوي على 100 مثال تدريبي.

123
00:09:53,380 --> 00:09:56,980
ثم تقوم بحساب الخطوة وفقًا للدفعة الصغيرة.

124
00:09:56,980 --> 00:10:02,198
إنه ليس التدرج الفعلي لدالة التكلفة، والذي يعتمد على جميع بيانات التدريب، وليس

125
00:10:02,198 --> 00:10:07,549
هذه المجموعة الفرعية الصغيرة، لذا فهي ليست الخطوة الأكثر كفاءة إلى أسفل، ولكن كل

126
00:10:07,549 --> 00:10:12,900
دفعة صغيرة تمنحك تقريبًا جيدًا، والأهم من ذلك أنها يمنحك تسريعًا حسابيًا كبيرًا.

127
00:10:12,900 --> 00:10:19,267
إذا كنت تريد رسم مسار شبكتك تحت سطح التكلفة ذي الصلة، فسيكون الأمر أشبه برجل مخمور

128
00:10:19,267 --> 00:10:25,328
يتعثر بلا هدف أسفل التل ولكنه يتخذ خطوات سريعة، بدلاً من رجل يحسب بعناية ويحدد

129
00:10:25,328 --> 00:10:31,620
الاتجاه الدقيق لانحدار كل خطوة. قبل اتخاذ خطوة بطيئة وحذرة للغاية في هذا الاتجاه.

130
00:10:31,620 --> 00:10:35,200
يشار إلى هذه التقنية باسم النسب التدرج العشوائي.

131
00:10:35,200 --> 00:10:40,400
هناك الكثير مما يحدث هنا، لذا دعونا نلخص الأمر لأنفسنا، أليس كذلك؟

132
00:10:40,400 --> 00:10:45,896
Backpropagation هي خوارزمية لتحديد كيف يرغب مثال تدريبي واحد في دفع الأوزان

133
00:10:45,896 --> 00:10:51,104
والتحيزات، ليس فقط فيما يتعلق بما إذا كان ينبغي أن ترتفع أم تنخفض، ولكن

134
00:10:51,104 --> 00:10:56,240
من حيث النسب النسبية لتلك التغييرات التي تسبب الانخفاض الأسرع في يكلف.

135
00:10:56,240 --> 00:11:00,873
قد تتضمن خطوة النزول المتدرج الحقيقية القيام بذلك لجميع العشرات والآلاف

136
00:11:00,873 --> 00:11:05,377
من أمثلة التدريب وحساب متوسط التغييرات المرغوبة التي تحصل عليها، ولكن

137
00:11:05,377 --> 00:11:09,817
هذا بطيء من الناحية الحسابية، لذلك بدلاً من ذلك تقوم بتقسيم البيانات

138
00:11:09,817 --> 00:11:14,000
عشوائيًا إلى دفعات صغيرة وحساب كل خطوة فيما يتعلق بـ دفعة صغيرة.

139
00:11:14,000 --> 00:11:18,155
من خلال مراجعة جميع الدفعات الصغيرة بشكل متكرر وإجراء هذه

140
00:11:18,155 --> 00:11:22,525
التعديلات، سوف تتقارب نحو الحد الأدنى المحلي لوظيفة التكلفة،

141
00:11:22,525 --> 00:11:27,540
مما يعني أن شبكتك ستؤدي في النهاية عملًا جيدًا حقًا في أمثلة التدريب.

142
00:11:27,540 --> 00:11:32,680
إذن مع كل ما قيل، فإن كل سطر من التعليمات البرمجية الذي قد يدخل في تنفيذ

143
00:11:32,680 --> 00:11:37,680
backprop يتوافق فعليًا مع شيء رأيته الآن، على الأقل بعبارات غير رسمية.

144
00:11:37,680 --> 00:11:41,073
لكن في بعض الأحيان، معرفة ما تفعله الرياضيات هو نصف المعركة فقط،

145
00:11:41,073 --> 00:11:44,780
ومجرد تمثيل الشيء اللعين هو المكان الذي يصبح فيه الأمر مشوشًا ومربكًا.

146
00:11:44,780 --> 00:11:48,934
لذا، بالنسبة لأولئك منكم الذين يريدون التعمق أكثر، فإن الفيديو التالي يتناول

147
00:11:48,934 --> 00:11:53,089
نفس الأفكار التي تم تقديمها هنا للتو، ولكن فيما يتعلق بحساب التفاضل والتكامل

148
00:11:53,089 --> 00:11:57,460
الأساسي، والذي نأمل أن يجعله مألوفًا أكثر قليلاً كما ترون الموضوع في مصادر أخرى.

149
00:11:57,460 --> 00:12:00,517
قبل ذلك، هناك شيء واحد يستحق التأكيد عليه وهو أنه لكي تعمل

150
00:12:00,517 --> 00:12:03,626
هذه الخوارزمية، وهذا ينطبق على جميع أنواع التعلم الآلي خارج

151
00:12:03,626 --> 00:12:06,840
الشبكات العصبية فقط، فأنت بحاجة إلى الكثير من بيانات التدريب.

152
00:12:06,840 --> 00:12:11,137
في حالتنا، الشيء الوحيد الذي يجعل الأرقام المكتوبة بخط اليد مثالًا رائعًا هو

153
00:12:11,137 --> 00:12:15,380
وجود قاعدة بيانات MNIST، مع العديد من الأمثلة التي تم تصنيفها بواسطة البشر.

154
00:12:15,380 --> 00:12:19,287
لذا فإن التحدي الشائع الذي سيكون العاملون في التعلم الآلي على دراية به هو مجرد

155
00:12:19,287 --> 00:12:23,244
الحصول على بيانات التدريب المصنفة التي تحتاجها بالفعل، سواء كان ذلك جعل الأشخاص

156
00:12:23,244 --> 00:12:27,400
يقومون بتسمية عشرات الآلاف من الصور، أو أي نوع آخر من البيانات التي قد تتعامل معها.

