1
00:00:04,060 --> 00:00:08,880
هنا، نتناول الانتشار العكسي، وهو الخوارزمية الأساسية وراء كيفية تعلم الشبكات العصبية. 

2
00:00:09,400 --> 00:00:13,200
بعد تلخيص سريع لما نحن فيه، أول شيء سأفعله هو إجراء إرشادات 

3
00:00:13,200 --> 00:00:17,000
بديهية لما تفعله الخوارزمية فعليًا، دون أي إشارة إلى الصيغ. 

4
00:00:17,660 --> 00:00:20,361
ثم، بالنسبة لأولئك منكم الذين يريدون التعمق في الرياضيات، فإن 

5
00:00:20,361 --> 00:00:23,020
الفيديو التالي يتناول حساب التفاضل والتكامل الأساسي لكل هذا. 

6
00:00:23,820 --> 00:00:27,149
إذا شاهدت مقطعي الفيديو الأخيرين، أو إذا كنت تقفز للتو بالخلفية 

7
00:00:27,149 --> 00:00:31,000
المناسبة، فأنت تعرف ما هي الشبكة العصبية، وكيف تغذي المعلومات إلى الأمام. 

8
00:00:31,680 --> 00:00:35,978
هنا، نحن ننفذ المثال الكلاسيكي للتعرف على الأرقام المكتوبة بخط اليد والتي يتم 

9
00:00:35,978 --> 00:00:40,332
إدخال قيم البكسل الخاصة بها في الطبقة الأولى من الشبكة التي تحتوي على 784 خلية 

10
00:00:40,332 --> 00:00:44,575
عصبية، وقد قمت بعرض شبكة ذات طبقتين مخفيتين تحتوي كل منهما على 16 خلية عصبية 

11
00:00:44,575 --> 00:00:49,040
فقط، ومخرج طبقة من 10 خلايا عصبية، تشير إلى الرقم الذي تختاره الشبكة كإجابة لها. 

12
00:00:50,040 --> 00:00:55,449
أتوقع منك أيضًا أن تفهم النسب المتدرج، كما هو موضح في الفيديو الأخير، وكيف أن ما 

13
00:00:55,449 --> 00:01:01,260
نعنيه بالتعلم هو أننا نريد العثور على الأوزان والتحيزات التي تقلل من دالة تكلفة معينة. 

14
00:01:02,040 --> 00:01:08,320
كتذكير سريع، مقابل تكلفة مثال تدريبي واحد، فإنك تأخذ المخرجات التي تقدمها الشبكة، 

15
00:01:08,320 --> 00:01:14,600
بالإضافة إلى المخرجات التي تريدها أن تعطيها، وتضيف مربعات الاختلافات بين كل مكون. 

16
00:01:15,380 --> 00:01:19,231
عند القيام بذلك لجميع عشرات الآلاف من أمثلة التدريب الخاصة بك 

17
00:01:19,231 --> 00:01:23,020
وحساب متوسط النتائج، فإن هذا يمنحك التكلفة الإجمالية للشبكة. 

18
00:01:23,020 --> 00:01:27,968
كما لو أن هذا لا يكفي للتفكير فيه، كما هو موضح في الفيديو الأخير، فإن الشيء 

19
00:01:27,968 --> 00:01:32,916
الذي نبحث عنه هو التدرج السلبي لدالة التكلفة هذه، والذي يخبرك كيف تحتاج إلى 

20
00:01:32,916 --> 00:01:38,320
تغيير كل الأوزان والتحيزات، كل هذه الاتصالات، وذلك لتقليل التكلفة بشكل أكثر كفاءة. 

21
00:01:43,260 --> 00:01:49,580
Backpropagation، موضوع هذا الفيديو، هو خوارزمية لحساب هذا التدرج المعقد والجنوني. 

22
00:01:49,580 --> 00:01:54,330
الفكرة الوحيدة من الفيديو الأخير التي أريدك حقًا أن تضعها بقوة في ذهنك الآن 

23
00:01:54,330 --> 00:01:58,830
هي أنه نظرًا لأن التفكير في متجه التدرج كاتجاه في 13000 بُعد هو، بعبارة 

24
00:01:58,830 --> 00:02:03,580
مبسطة، خارج نطاق مخيلتنا، هناك فكرة أخرى الطريقة التي يمكنك التفكير في ذلك. 

25
00:02:04,600 --> 00:02:10,940
يخبرك حجم كل مكون هنا بمدى حساسية دالة التكلفة لكل وزن وتحيز. 

26
00:02:11,800 --> 00:02:16,473
على سبيل المثال، لنفترض أنك قمت بتنفيذ العملية التي أنا على وشك 

27
00:02:16,473 --> 00:02:21,293
وصفها، وحساب التدرج السلبي، والمكون المرتبط بالوزن على هذه الحافة 

28
00:02:21,293 --> 00:02:26,260
هنا يصبح 3.2، في حين أن المكون المرتبط بهذه الحافة هنا يخرج كـ 0.1. 

29
00:02:26,820 --> 00:02:32,190
الطريقة التي تفسر بها ذلك هي أن تكلفة الوظيفة أكثر حساسية بمقدار 32 مرة للتغيرات في 

30
00:02:32,190 --> 00:02:37,689
هذا الوزن الأول، لذلك إذا قمت بتحريك هذه القيمة قليلاً، فسوف يتسبب ذلك في بعض التغيير 

31
00:02:37,689 --> 00:02:43,060
في التكلفة، وهذا التغيير أكبر بـ 32 مرة مما ستعطيه نفس الاهتزازة لهذا الوزن الثاني. 

32
00:02:48,420 --> 00:02:52,050
شخصيًا، عندما كنت أتعلم لأول مرة عن الانتشار العكسي، أعتقد أن 

33
00:02:52,050 --> 00:02:55,740
الجانب الأكثر إرباكًا كان مجرد الترميز ومطاردة الفهرس لكل شيء. 

34
00:02:56,220 --> 00:02:59,567
ولكن بمجرد أن تكتشف ما يفعله كل جزء من هذه الخوارزمية بالفعل، 

35
00:02:59,567 --> 00:03:02,968
فإن كل تأثير فردي يحدثه يكون في الواقع بديهيًا جدًا، الأمر فقط 

36
00:03:02,968 --> 00:03:06,640
أن هناك الكثير من التعديلات الصغيرة التي يتم وضعها فوق بعضها البعض. 

37
00:03:07,740 --> 00:03:12,006
لذا، سأبدأ الأمور هنا مع التجاهل التام للتدوين، وسأنتقل 

38
00:03:12,006 --> 00:03:16,120
فقط عبر تأثيرات كل مثال تدريبي على الأوزان والتحيزات. 

39
00:03:17,020 --> 00:03:21,645
نظرًا لأن دالة التكلفة تتضمن حساب متوسط تكلفة معينة لكل مثال على 

40
00:03:21,645 --> 00:03:26,271
عشرات الآلاف من أمثلة التدريب، فإن الطريقة التي نضبط بها الأوزان 

41
00:03:26,271 --> 00:03:31,040
والتحيزات لخطوة نزول متدرجة واحدة تعتمد أيضًا على كل مثال على حدة. 

42
00:03:31,680 --> 00:03:35,291
أو بالأحرى، من حيث المبدأ، ينبغي أن يكون الأمر كذلك، ولكن من أجل الكفاءة 

43
00:03:35,291 --> 00:03:39,200
الحسابية، سنقوم بخدعة صغيرة لاحقًا لمنعك من الحاجة إلى ضرب كل مثال في كل خطوة. 

44
00:03:39,200 --> 00:03:45,960
في حالات أخرى، الآن، كل ما سنفعله هو تركيز انتباهنا على مثال واحد، هذه الصورة للرقم 2. 

45
00:03:46,720 --> 00:03:51,480
ما هو التأثير الذي يجب أن يحدثه هذا المثال التدريبي على كيفية تعديل الأوزان والتحيزات؟ 

46
00:03:52,680 --> 00:03:57,398
لنفترض أننا وصلنا إلى مرحلة لم يتم فيها تدريب الشبكة بشكل جيد بعد، وبالتالي فإن 

47
00:03:57,398 --> 00:04:02,000
عمليات التنشيط في المخرجات ستبدو عشوائية جدًا، ربما مثل 0.5، 0.8، 0.2، وهكذا. 

48
00:04:02,520 --> 00:04:07,811
لا يمكننا تغيير تلك التنشيطات بشكل مباشر، لدينا فقط تأثير على الأوزان والتحيزات، 

49
00:04:07,811 --> 00:04:12,580
ولكن من المفيد تتبع التعديلات التي نرغب في إجرائها على طبقة الإخراج تلك. 

50
00:04:13,360 --> 00:04:17,186
وبما أننا نريدها أن تصنف الصورة على أنها 2، فإننا نريد أن يتم 

51
00:04:17,186 --> 00:04:21,260
دفع القيمة الثالثة للأعلى بينما يتم دفع جميع القيم الأخرى للأسفل. 

52
00:04:22,060 --> 00:04:26,053
علاوة على ذلك، يجب أن تكون أحجام هذه الدفعات متناسبة 

53
00:04:26,053 --> 00:04:29,520
مع مدى بعد كل قيمة حالية عن قيمتها المستهدفة. 

54
00:04:30,220 --> 00:04:35,167
على سبيل المثال، الزيادة في تنشيط الخلية العصبية رقم 2 هي إلى حد ما أكثر أهمية من 

55
00:04:35,167 --> 00:04:40,598
الانخفاض في الخلية العصبية رقم 8، والتي هي بالفعل قريبة جدًا من المكان الذي ينبغي أن تكون 

56
00:04:40,598 --> 00:04:40,900
فيه. 

57
00:04:42,040 --> 00:04:47,222
لذا، بالتكبير أكثر، دعونا نركز فقط على هذه الخلية العصبية، تلك التي نرغب في زيادة تنشيطها.

58
00:04:47,222 --> 00:04:47,280
 

59
00:04:48,180 --> 00:04:54,244
تذكر، يتم تعريف هذا التنشيط على أنه مجموع مرجح معين لجميع عمليات التنشيط في الطبقة 

60
00:04:54,244 --> 00:05:00,601
السابقة، بالإضافة إلى التحيز، والذي يتم بعد ذلك توصيله بشيء مثل وظيفة السحق السيني، أو 

61
00:05:00,601 --> 00:05:01,040
ReLU. 

62
00:05:01,640 --> 00:05:07,020
لذلك هناك ثلاث طرق مختلفة يمكن أن تتعاون معًا للمساعدة في زيادة هذا التنشيط. 

63
00:05:07,440 --> 00:05:14,040
يمكنك زيادة التحيز، ويمكنك زيادة الأوزان، ويمكنك تغيير عمليات التنشيط من الطبقة السابقة. 

64
00:05:14,940 --> 00:05:20,860
بالتركيز على كيفية ضبط الأوزان، لاحظ كيف أن للأوزان بالفعل مستويات مختلفة من التأثير. 

65
00:05:21,440 --> 00:05:25,393
إن الاتصالات مع الخلايا العصبية الأكثر سطوعًا من الطبقة السابقة 

66
00:05:25,393 --> 00:05:29,100
لها التأثير الأكبر حيث يتم ضرب تلك الأوزان بقيم تنشيط أكبر. 

67
00:05:31,460 --> 00:05:35,487
لذا، إذا قمت بزيادة أحد هذه الأوزان، فسيكون لها في الواقع تأثير 

68
00:05:35,487 --> 00:05:39,200
أقوى على دالة التكلفة النهائية من زيادة أوزان الاتصالات مع 

69
00:05:39,200 --> 00:05:43,480
الخلايا العصبية الخافتة، على الأقل فيما يتعلق بهذا المثال التدريبي. 

70
00:05:44,420 --> 00:05:48,880
تذكر، عندما نتحدث عن النسب المتدرج، فإننا لا نهتم فقط بما إذا كان يجب دفع 

71
00:05:48,880 --> 00:05:53,220
كل مكون لأعلى أو لأسفل، بل نهتم بالمكونات التي تمنحك أكبر قدر من المال. 

72
00:05:55,020 --> 00:05:58,937
هذا، بالمناسبة، يذكرنا على الأقل إلى حد ما بنظرية في علم الأعصاب حول كيفية 

73
00:05:58,937 --> 00:06:02,698
تعلم الشبكات البيولوجية للخلايا العصبية، وهي نظرية هيبيان، والتي غالبًا 

74
00:06:02,698 --> 00:06:06,460
ما يتم تلخيصها في العبارة، الخلايا العصبية التي تشتعل معًا تترابط معًا. 

75
00:06:07,260 --> 00:06:11,961
هنا، أكبر زيادات في الأوزان، وأكبر تقوية للاتصالات، تحدث بين 

76
00:06:11,961 --> 00:06:17,280
الخلايا العصبية الأكثر نشاطًا وتلك التي نرغب في أن تصبح أكثر نشاطًا. 

77
00:06:17,940 --> 00:06:21,135
بمعنى ما، فإن الخلايا العصبية التي تنشط أثناء رؤية الرقم 2 تصبح 

78
00:06:21,135 --> 00:06:24,480
أكثر ارتباطًا بتلك الخلايا العصبية التي تنشط عند التفكير في الأمر. 

79
00:06:25,400 --> 00:06:29,291
لأكون واضحًا، لست في وضع يسمح لي بالإدلاء ببيانات بطريقة أو بأخرى حول 

80
00:06:29,291 --> 00:06:33,015
ما إذا كانت الشبكات الاصطناعية من الخلايا العصبية تتصرف مثل العقول 

81
00:06:33,015 --> 00:06:36,906
البيولوجية، وهذه الفكرة التي تنطلق معًا تأتي مع نجمتين ذات معنى، ولكن 

82
00:06:36,906 --> 00:06:41,020
تم اعتبارها فضفاضة للغاية تشبيهًا، أجد أنه من المثير للاهتمام ملاحظة ذلك. 

83
00:06:41,940 --> 00:06:45,365
على أية حال، الطريقة الثالثة التي يمكننا من خلالها المساعدة في زيادة 

84
00:06:45,365 --> 00:06:49,040
تنشيط هذه الخلايا العصبية هي تغيير جميع عمليات التنشيط في الطبقة السابقة. 

85
00:06:49,040 --> 00:06:52,881
على وجه التحديد، إذا أصبح كل شيء مرتبط بالخلية العصبية ذات الرقم 2 

86
00:06:52,881 --> 00:06:56,838
ذات الوزن الإيجابي أكثر سطوعًا، وإذا أصبح كل شيء مرتبط بالوزن السلبي 

87
00:06:56,838 --> 00:07:00,680
أكثر خفوتًا، فإن تلك الخلية العصبية ذات الرقم 2 ستصبح أكثر نشاطًا. 

88
00:07:02,540 --> 00:07:06,219
وكما هو الحال مع تغييرات الوزن، ستحصل على أقصى استفادة من 

89
00:07:06,219 --> 00:07:10,280
أموالك من خلال البحث عن تغييرات تتناسب مع حجم الأوزان المقابلة. 

90
00:07:12,140 --> 00:07:14,757
الآن بالطبع، لا يمكننا التأثير بشكل مباشر على تلك 

91
00:07:14,757 --> 00:07:17,480
التنشيطات، لدينا فقط السيطرة على الأوزان والتحيزات. 

92
00:07:17,480 --> 00:07:20,664
ولكن كما هو الحال مع الطبقة الأخيرة، من المفيد 

93
00:07:20,664 --> 00:07:24,120
الاحتفاظ بملاحظة حول ماهية تلك التغييرات المرغوبة. 

94
00:07:24,580 --> 00:07:26,847
لكن ضع في اعتبارك، عند تصغير خطوة واحدة هنا، فإن هذا 

95
00:07:26,847 --> 00:07:29,200
هو فقط ما تريده تلك الخلية العصبية الناتجة من الرقم 2. 

96
00:07:29,760 --> 00:07:32,883
تذكر أننا نريد أيضًا أن تصبح جميع الخلايا العصبية الأخرى في 

97
00:07:32,883 --> 00:07:36,111
الطبقة الأخيرة أقل نشاطًا، ولكل من تلك الخلايا العصبية الأخرى 

98
00:07:36,111 --> 00:07:39,600
أفكارها الخاصة حول ما يجب أن يحدث لتلك الطبقة الثانية قبل الأخيرة. 

99
00:07:42,700 --> 00:07:48,821
لذلك يتم إضافة رغبة هذه الخلية العصبية ذات الرقم 2 مع رغبات جميع الخلايا العصبية الناتجة 

100
00:07:48,821 --> 00:07:54,805
الأخرى فيما يتعلق بما يجب أن يحدث لهذه الطبقة الثانية إلى الأخيرة، مرة أخرى بما يتناسب 

101
00:07:54,805 --> 00:08:00,720
مع الأوزان المقابلة، وبما يتناسب مع مقدار احتياجات كل من تلك الخلايا العصبية للتغيير. 

102
00:08:01,600 --> 00:08:05,480
وهنا تأتي فكرة الانتشار العكسي. 

103
00:08:05,820 --> 00:08:09,421
من خلال جمع كل هذه التأثيرات المرغوبة معًا، تحصل بشكل أساسي على 

104
00:08:09,421 --> 00:08:13,360
قائمة من التنبيهات التي تريد أن تحدث لهذه الطبقة الثانية إلى الأخيرة. 

105
00:08:14,220 --> 00:08:19,785
وبمجرد حصولك على هذه، يمكنك تطبيق نفس العملية بشكل متكرر على الأوزان والتحيزات ذات الصلة 

106
00:08:19,785 --> 00:08:25,100
التي تحدد تلك القيم، وتكرار نفس العملية التي مررت بها للتو والتحرك للخلف عبر الشبكة. 

107
00:08:28,960 --> 00:08:32,914
وبالتصغير أكثر قليلاً، تذكر أن هذا كله هو الطريقة التي يرغب 

108
00:08:32,914 --> 00:08:37,000
بها مثال تدريبي واحد في دفع كل واحد من تلك الأوزان والتحيزات. 

109
00:08:37,480 --> 00:08:40,404
إذا استمعنا فقط إلى ما يريده هذا الشخصان، فسيتم تحفيز 

110
00:08:40,404 --> 00:08:43,220
الشبكة في النهاية لتصنيف جميع الصور على أنها رقم 2. 

111
00:08:44,059 --> 00:08:49,842
إذن ما تفعله هو اتباع نفس روتين الدعم الخلفي لكل مثال تدريبي آخر، وتسجيل كيف 

112
00:08:49,842 --> 00:08:56,000
يرغب كل منهم في تغيير الأوزان والتحيزات، وحساب متوسط تلك التغييرات المرغوبة معًا. 

113
00:09:01,720 --> 00:09:07,738
هذه المجموعة هنا من متوسط الدفعات لكل وزن وتحيز هي، بشكل فضفاض، التدرج السلبي 

114
00:09:07,738 --> 00:09:13,680
لوظيفة التكلفة المشار إليها في الفيديو الأخير، أو على الأقل شيء يتناسب معها. 

115
00:09:14,380 --> 00:09:19,920
أقول ذلك بشكل فضفاض فقط لأنني لم أحصل بعد على دقة كمية بشأن تلك التنبيهات، ولكن إذا 

116
00:09:19,920 --> 00:09:25,525
فهمت كل تغيير أشرت إليه للتو، ولماذا يكون بعضها أكبر نسبيًا من البعض الآخر، وكيف يجب 

117
00:09:25,525 --> 00:09:31,000
إضافتها جميعًا معًا، فإنك تفهم آليات حدوث ذلك. ما يفعله الانتشار العكسي في الواقع. 

118
00:09:33,960 --> 00:09:38,200
بالمناسبة، في الممارسة العملية، يستغرق الأمر وقتًا طويلاً للغاية من 

119
00:09:38,200 --> 00:09:42,440
أجهزة الكمبيوتر لإضافة تأثير كل مثال تدريبي في كل خطوة نزول متدرجة. 

120
00:09:43,140 --> 00:09:44,820
إذن، إليك ما يتم فعله عادةً بدلاً من ذلك. 

121
00:09:45,480 --> 00:09:49,052
يمكنك خلط بيانات التدريب الخاصة بك عشوائيًا وتقسيمها إلى مجموعة كاملة 

122
00:09:49,052 --> 00:09:52,420
من الدفعات الصغيرة، لنفترض أن كل واحدة تحتوي على 100 مثال تدريبي. 

123
00:09:52,939 --> 00:09:57,280
ثم تقوم بحساب الخطوة وفقًا للدفعة الصغيرة. 

124
00:09:57,280 --> 00:10:02,144
إنه ليس التدرج الفعلي لدالة التكلفة، والذي يعتمد على جميع بيانات التدريب، وليس 

125
00:10:02,144 --> 00:10:07,132
هذه المجموعة الفرعية الصغيرة، لذا فهي ليست الخطوة الأكثر كفاءة إلى أسفل، ولكن كل 

126
00:10:07,132 --> 00:10:12,120
دفعة صغيرة تمنحك تقريبًا جيدًا، والأهم من ذلك أنها يمنحك تسريعًا حسابيًا كبيرًا. 

127
00:10:12,820 --> 00:10:18,718
إذا كنت تريد رسم مسار شبكتك تحت سطح التكلفة ذي الصلة، فسيكون الأمر أشبه برجل مخمور 

128
00:10:18,718 --> 00:10:24,332
يتعثر بلا هدف أسفل التل ولكنه يتخذ خطوات سريعة، بدلاً من رجل يحسب بعناية ويحدد 

129
00:10:24,332 --> 00:10:30,160
الاتجاه الدقيق لانحدار كل خطوة. قبل اتخاذ خطوة بطيئة وحذرة للغاية في هذا الاتجاه. 

130
00:10:31,540 --> 00:10:34,660
يشار إلى هذه التقنية باسم النسب التدرج العشوائي. 

131
00:10:35,960 --> 00:10:39,620
هناك الكثير مما يحدث هنا، لذا دعونا نلخص الأمر لأنفسنا، أليس كذلك؟ 

132
00:10:40,440 --> 00:10:45,687
Backpropagation هي خوارزمية لتحديد كيف يرغب مثال تدريبي واحد في دفع الأوزان 

133
00:10:45,687 --> 00:10:50,658
والتحيزات، ليس فقط فيما يتعلق بما إذا كان ينبغي أن ترتفع أم تنخفض، ولكن 

134
00:10:50,658 --> 00:10:55,560
من حيث النسب النسبية لتلك التغييرات التي تسبب الانخفاض الأسرع في يكلف. 

135
00:10:56,260 --> 00:11:00,689
قد تتضمن خطوة النزول المتدرج الحقيقية القيام بذلك لجميع العشرات والآلاف 

136
00:11:00,689 --> 00:11:04,996
من أمثلة التدريب وحساب متوسط التغييرات المرغوبة التي تحصل عليها، ولكن 

137
00:11:04,996 --> 00:11:09,241
هذا بطيء من الناحية الحسابية، لذلك بدلاً من ذلك تقوم بتقسيم البيانات 

138
00:11:09,241 --> 00:11:13,240
عشوائيًا إلى دفعات صغيرة وحساب كل خطوة فيما يتعلق بـ دفعة صغيرة. 

139
00:11:14,000 --> 00:11:17,541
من خلال مراجعة جميع الدفعات الصغيرة بشكل متكرر وإجراء هذه 

140
00:11:17,541 --> 00:11:21,265
التعديلات، سوف تتقارب نحو الحد الأدنى المحلي لوظيفة التكلفة، 

141
00:11:21,265 --> 00:11:25,540
مما يعني أن شبكتك ستؤدي في النهاية عملًا جيدًا حقًا في أمثلة التدريب. 

142
00:11:27,240 --> 00:11:32,045
إذن مع كل ما قيل، فإن كل سطر من التعليمات البرمجية الذي قد يدخل في تنفيذ 

143
00:11:32,045 --> 00:11:36,720
backprop يتوافق فعليًا مع شيء رأيته الآن، على الأقل بعبارات غير رسمية. 

144
00:11:37,560 --> 00:11:40,695
لكن في بعض الأحيان، معرفة ما تفعله الرياضيات هو نصف المعركة فقط، 

145
00:11:40,695 --> 00:11:44,120
ومجرد تمثيل الشيء اللعين هو المكان الذي يصبح فيه الأمر مشوشًا ومربكًا. 

146
00:11:44,860 --> 00:11:48,647
لذا، بالنسبة لأولئك منكم الذين يريدون التعمق أكثر، فإن الفيديو التالي يتناول 

147
00:11:48,647 --> 00:11:52,435
نفس الأفكار التي تم تقديمها هنا للتو، ولكن فيما يتعلق بحساب التفاضل والتكامل 

148
00:11:52,435 --> 00:11:56,420
الأساسي، والذي نأمل أن يجعله مألوفًا أكثر قليلاً كما ترون الموضوع في مصادر أخرى. 

149
00:11:57,340 --> 00:12:00,130
قبل ذلك، هناك شيء واحد يستحق التأكيد عليه وهو أنه لكي تعمل 

150
00:12:00,130 --> 00:12:02,967
هذه الخوارزمية، وهذا ينطبق على جميع أنواع التعلم الآلي خارج 

151
00:12:02,967 --> 00:12:05,900
الشبكات العصبية فقط، فأنت بحاجة إلى الكثير من بيانات التدريب. 

152
00:12:06,420 --> 00:12:10,607
في حالتنا، الشيء الوحيد الذي يجعل الأرقام المكتوبة بخط اليد مثالًا رائعًا هو 

153
00:12:10,607 --> 00:12:14,740
وجود قاعدة بيانات MNIST، مع العديد من الأمثلة التي تم تصنيفها بواسطة البشر. 

154
00:12:15,300 --> 00:12:19,136
لذا فإن التحدي الشائع الذي سيكون العاملون في التعلم الآلي على دراية به هو مجرد 

155
00:12:19,136 --> 00:12:23,020
الحصول على بيانات التدريب المصنفة التي تحتاجها بالفعل، سواء كان ذلك جعل الأشخاص 

156
00:12:23,020 --> 00:12:27,100
يقومون بتسمية عشرات الآلاف من الصور، أو أي نوع آخر من البيانات التي قد تتعامل معها. 

