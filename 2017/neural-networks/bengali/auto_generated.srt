1
00:00:00,000 --> 00:00:11,200
এটি একটি 3. এটি 28x28 পিক্সেলের একটি অত্যন্ত কম রেজোলিউশনে স্লোপিলি লেখা এবং রেন্ডার করা হয়েছে, তবে

2
00:00:11,200 --> 00:00:15,340
আপনার মস্তিষ্কের এটিকে 3 হিসাবে চিনতে কোন সমস্যা নেই। এবং আমি চাই আপনি একটু সময় নিয়ে

3
00:00:15,340 --> 00:00:20,500
উপলব্ধি করুন যে এটি কতটা পাগল যে মস্তিষ্ক এত অনায়াসে এটি করতে পারে। আমি বলতে চাচ্ছি,

4
00:00:20,500 --> 00:00:26,180
এই, এটি এবং এটিও 3s হিসাবে স্বীকৃত, যদিও প্রতিটি পিক্সেলের নির্দিষ্ট মান

5
00:00:26,180 --> 00:00:31,260
একটি চিত্র থেকে পরবর্তীতে খুব আলাদা। আপনার চোখের যে বিশেষ আলো-সংবেদনশীল কোষগুলি আপনি যখন এই

6
00:00:31,260 --> 00:00:36,020
3টি দেখেন তখন গুলি ছুড়তে থাকে, আপনি যখন এই 3টি দেখেন তখন গুলি করা থেকে একেবারেই

7
00:00:36,020 --> 00:00:42,900
আলাদা৷ কিন্তু আপনার সেই উন্মাদ-স্মার্ট ভিজ্যুয়াল কর্টেক্সের কিছু কিছু একই ধারণার প্রতিনিধিত্ব

8
00:00:42,900 --> 00:00:49,300
করে, একই সময়ে অন্যান্য ছবিকে তাদের নিজস্ব স্বতন্ত্র ধারণা হিসাবে স্বীকৃতি দেয়।

9
00:00:49,300 --> 00:00:55,820
কিন্তু আমি যদি আপনাকে বলি, আরে, বসুন এবং আমার জন্য একটি প্রোগ্রাম লিখুন যা 28x28 এর একটি

10
00:00:56,340 --> 00:01:01,780
গ্রিডে নেয় এবং 0 থেকে 10 এর মধ্যে একটি একক সংখ্যা বের করে, আপনাকে বলে যে

11
00:01:01,780 --> 00:01:07,860
অঙ্কটি কী মনে হয়, কাজটি হাস্যকরভাবে তুচ্ছ থেকে যায় ভয়ঙ্করভাবে কঠিন আপনি একটি পাথরের নীচে বসবাস

12
00:01:07,860 --> 00:01:12,020
না করা পর্যন্ত, আমি মনে করি আমার বর্তমান এবং ভবিষ্যতের জন্য মেশিন লার্নিং এবং নিউরাল নেটওয়ার্কগুলির

13
00:01:12,020 --> 00:01:16,460
প্রাসঙ্গিকতা এবং গুরুত্বকে অনুপ্রাণিত করার খুব কমই দরকার। কিন্তু আমি এখানে যা করতে চাই তা হল একটি নিউরাল

14
00:01:16,460 --> 00:01:22,020
নেটওয়ার্ক আসলে কী তা আপনাকে দেখাতে চাই, কোন ব্যাকগ্রাউন্ড অনুমান না করে, এবং এটি কী করছে তা কল্পনা করতে সাহায্য করার জন্য,

15
00:01:22,060 --> 00:01:26,860
একটি গুঞ্জন শব্দ হিসাবে নয় বরং গণিতের একটি অংশ হিসাবে। আমার আশা শুধু এই যে আপনি এমন অনুভূতিতে চলে আসবেন

16
00:01:26,860 --> 00:01:31,460
যেন গঠন নিজেই অনুপ্রাণিত হয়, এবং আপনি যখন পড়েন বা আপনি একটি নিউরাল নেটওয়ার্ক কোট-আনকোট শেখার কথা

17
00:01:31,460 --> 00:01:36,780
শুনেন তখন এর অর্থ কী তা জানেন বলে মনে করেন। এই ভিডিওটি কেবল এটির গঠন

18
00:01:36,780 --> 00:01:40,300
উপাদানের জন্য উত্সর্গীকৃত হতে চলেছে, এবং নিম্নলিখিতটি শেখার মোকাবিলা করতে চলেছে।

19
00:01:40,300 --> 00:01:45,580
আমরা যা করতে যাচ্ছি তা হল একটি নিউরাল নেটওয়ার্ক যা হাতে লেখা অঙ্ক চিনতে শিখতে পারে।

20
00:01:45,580 --> 00:01:53,540
বিষয়টি উপস্থাপন করার জন্য এটি কিছুটা ক্লাসিক উদাহরণ, এবং আমি এখানে স্থিতাবস্থায় থাকতে পেরে খুশি,

21
00:01:53,540 --> 00:01:57,340
কারণ দুটি ভিডিওর শেষে আমি আপনাকে কয়েকটি ভাল সংস্থানের দিকে নির্দেশ করতে চাই যেখানে আপনি

22
00:01:57,340 --> 00:02:01,420
আরও শিখতে পারেন এবং কোথায় আপনি যে কোডটি এটি করে তা ডাউনলোড করতে পারেন এবং আপনার

23
00:02:01,420 --> 00:02:07,820
নিজের কম্পিউটারে এটির সাথে খেলতে পারেন। নিউরাল নেটওয়ার্কগুলির অনেকগুলি রূপ রয়েছে, এবং সাম্প্রতিক বছরগুলিতে

24
00:02:07,820 --> 00:02:12,900
এই রূপগুলির জন্য গবেষণায় এক ধরণের উচ্ছ্বাস দেখা দিয়েছে, কিন্তু এই দুটি

25
00:02:12,940 --> 00:02:18,100
পরিচায়ক ভিডিওতে আপনি এবং আমি কোনও যোগ ছাড়াই সহজতম প্লেইন ভ্যানিলা ফর্মটি

26
00:02:18,100 --> 00:02:23,020
দেখতে যাচ্ছি৷ যেকোনও শক্তিশালী আধুনিক ভেরিয়েন্ট বোঝার জন্য এটি একটি প্রয়োজনীয় পূর্বশর্ত, এবং

27
00:02:23,020 --> 00:02:28,140
আমাকে বিশ্বাস করুন আমাদের মনকে ঘিরে রাখার জন্য এটিতে এখনও প্রচুর জটিলতা রয়েছে।

28
00:02:28,140 --> 00:02:33,440
তবে এই সহজতম ফর্মেও এটি হাতে লেখা অঙ্কগুলি চিনতে শিখতে পারে, যা একটি কম্পিউটারের

29
00:02:33,440 --> 00:02:39,380
পক্ষে করতে সক্ষম হওয়া একটি দুর্দান্ত জিনিস। এবং একই সময়ে আপনি দেখতে পাবেন কিভাবে এটি একটি

30
00:02:39,460 --> 00:02:45,620
দম্পতি আশা কম পড়ে যে আমাদের এটির জন্য থাকতে পারে। নাম অনুসারে, নিউরাল নেটওয়ার্কগুলি মস্তিষ্ক দ্বারা অনুপ্রাণিত

31
00:02:45,620 --> 00:02:50,820
হয়, তবে আসুন এটি ভেঙে ফেলা যাক। নিউরন কি এবং কোন অর্থে তারা একসাথে

32
00:02:50,820 --> 00:02:56,900
যুক্ত? এই মুহুর্তে যখন আমি নিউরন বলি, আমি চাই আপনি শুধু এমন একটি বিষয় নিয়ে ভাবুন যা একটি সংখ্যা

33
00:02:56,900 --> 00:03:04,380
ধারণ করে, বিশেষ করে 0 এবং 1 এর মধ্যে একটি সংখ্যা। এটা সত্যিই এর চেয়ে বেশি নয়। উদাহরণস্বরূপ, নেটওয়ার্কটি

34
00:03:04,420 --> 00:03:10,060
ইনপুট চিত্রের 28 গুণ 28 পিক্সেলের প্রতিটির সাথে সম্পর্কিত একগুচ্ছ নিউরন দিয়ে

35
00:03:10,060 --> 00:03:17,260
শুরু হয়, যা মোট 784 নিউরন। এগুলোর প্রত্যেকটিতে একটি সংখ্যা রয়েছে যা সংশ্লিষ্ট পিক্সেলের

36
00:03:17,260 --> 00:03:23,900
গ্রেস্কেল মানকে প্রতিনিধিত্ব করে, কালো পিক্সেলের জন্য 0 থেকে সাদা পিক্সেলের জন্য 1 পর্যন্ত।

37
00:03:23,900 --> 00:03:30,060
নিউরনের অভ্যন্তরে এই সংখ্যাটিকে এটির সক্রিয়করণ বলা হয়, এবং আপনার মনে যে চিত্রটি থাকতে পারে

38
00:03:30,060 --> 00:03:37,260
তা হল প্রতিটি নিউরন আলোকিত হয় যখন এটির সক্রিয়করণ একটি উচ্চ সংখ্যা হয়। সুতরাং এই 784

39
00:03:37,260 --> 00:03:47,820
নিউরনগুলির সমস্তই আমাদের নেটওয়ার্কের প্রথম স্তর তৈরি করে। এখন লাফিয়ে লাফিয়ে লাস্ট লেয়ারে, এতে

40
00:03:47,820 --> 00:03:53,780
10টি নিউরন আছে, প্রতিটি ডিজিটের একটি প্রতিনিধিত্ব করে। এই নিউরনগুলিতে সক্রিয়করণ, আবার কিছু সংখ্যা যা

41
00:03:53,780 --> 00:03:59,460
0 এবং 1 এর মধ্যে, এটি প্রতিনিধিত্ব করে যে সিস্টেমটি কতটা মনে করে যে একটি প্রদত্ত

42
00:03:59,500 --> 00:04:05,180
চিত্র একটি প্রদত্ত অঙ্কের সাথে মিলে যায়। এর মাঝে কয়েকটি স্তর রয়েছে যাকে লুকানো

43
00:04:05,180 --> 00:04:10,780
স্তর বলা হয়, যা আপাতত একটি বিশাল প্রশ্ন চিহ্ন হওয়া উচিত পৃথিবীতে কীভাবে

44
00:04:10,780 --> 00:04:15,900
অঙ্কগুলি সনাক্ত করার এই প্রক্রিয়াটি পরিচালনা করা হবে। এই নেটওয়ার্কে আমি দুটি লুকানো স্তর

45
00:04:15,900 --> 00:04:21,460
বেছে নিয়েছি, প্রতিটিতে 16টি নিউরন রয়েছে এবং স্বীকার করেই এটি একটি নির্বিচারে পছন্দ। সত্যি কথা বলতে,

46
00:04:21,460 --> 00:04:26,620
আমি কিভাবে মাত্র এক মুহুর্তে কাঠামোটিকে অনুপ্রাণিত করতে চাই তার উপর ভিত্তি করে আমি দুটি স্তর বেছে নিয়েছি, এবং 16,

47
00:04:26,620 --> 00:04:30,940
স্ক্রিনে ফিট করার জন্য এটি একটি চমৎকার সংখ্যা ছিল। অনুশীলনে এখানে একটি নির্দিষ্ট কাঠামো নিয়ে পরীক্ষার জন্য

48
00:04:30,940 --> 00:04:37,020
অনেক জায়গা রয়েছে। নেটওয়ার্ক যেভাবে কাজ করে, এক স্তরে সক্রিয়করণ পরবর্তী স্তরের

49
00:04:37,020 --> 00:04:42,340
সক্রিয়করণ নির্ধারণ করে। এবং অবশ্যই একটি তথ্য প্রক্রিয়াকরণ প্রক্রিয়া হিসাবে নেটওয়ার্কের

50
00:04:42,340 --> 00:04:47,820
হৃদয় ঠিক কিভাবে এক স্তর থেকে সক্রিয়করণ পরবর্তী স্তরে সক্রিয়তা নিয়ে

51
00:04:47,820 --> 00:04:53,340
আসে। এটাকে বোঝানো হয়েছে যে কিভাবে নিউরনের জৈবিক নেটওয়ার্কে কিছু নিউরন

52
00:04:53,380 --> 00:04:59,380
ফায়ারিং এর ফলে কিছু অন্যদের আগুন লাগে। এখন আমি এখানে যে নেটওয়ার্কটি দেখাচ্ছি তা

53
00:04:59,380 --> 00:05:04,260
ইতিমধ্যেই অঙ্কগুলি চিনতে প্রশিক্ষিত হয়েছে, এবং আমি এর দ্বারা আমি কী বোঝাতে চাই তা দেখান। এর অর্থ হল

54
00:05:04,260 --> 00:05:10,900
আপনি যদি একটি ইমেজে ফিড করেন যা ইমেজের প্রতিটি পিক্সেলের উজ্জ্বলতা অনুসারে ইনপুট স্তরের সমস্ত

55
00:05:10,900 --> 00:05:16,860
784 নিউরনকে আলোকিত করে, সেই প্যাটার্ন অ্যাক্টিভেশনের ফলে পরবর্তী স্তরে কিছু নির্দিষ্ট প্যাটার্ন তৈরি হয়,

56
00:05:16,860 --> 00:05:21,740
যা পরবর্তী স্তরে কিছু প্যাটার্ন সৃষ্টি করে। এটি, যা অবশেষে আউটপুট স্তরে কিছু প্যাটার্ন দেয়।

57
00:05:21,780 --> 00:05:27,540
এবং সেই আউটপুট স্তরের উজ্জ্বল নিউরন হল নেটওয়ার্কের পছন্দ, তাই বলতে গেলে, এই

58
00:05:27,540 --> 00:05:35,420
চিত্রটি কোন সংখ্যার প্রতিনিধিত্ব করে। এবং কীভাবে একটি স্তর পরবর্তীকে প্রভাবিত করে বা কীভাবে প্রশিক্ষণ কাজ

59
00:05:35,420 --> 00:05:40,460
করে তা নিয়ে গণিতে ঝাঁপিয়ে পড়ার আগে, আসুন কেবল আলোচনা করা যাক কেন এইরকম একটি স্তরযুক্ত

60
00:05:40,460 --> 00:05:46,340
কাঠামো বুদ্ধিমানের সাথে আচরণ করার আশা করা যুক্তিযুক্ত। আমরা এখানে কি আশা করছি? সেই মধ্যম স্তরগুলি কী

61
00:05:46,420 --> 00:05:52,420
করছে তার জন্য সেরা আশা কী? ঠিক আছে, যখন আপনি বা আমি অঙ্কগুলি চিনতে পারি, আমরা বিভিন্ন

62
00:05:52,420 --> 00:05:58,980
উপাদানকে একত্রিত করি। A 9 এর উপরে একটি লুপ আপ এবং ডানদিকে একটি লাইন রয়েছে। একটি 8 এর উপরেও একটি লুপ আপ

63
00:05:58,980 --> 00:06:05,420
আছে, কিন্তু এটি নিচের নিচে আরেকটি লুপের সাথে যুক্ত। একটি 4 মূলত তিনটি নির্দিষ্ট লাইনে ভেঙ্গে যায়, এবং

64
00:06:05,420 --> 00:06:11,500
এমন জিনিস। এখন একটি নিখুঁত বিশ্বে, আমরা আশা করতে পারি যে দ্বিতীয় থেকে শেষ স্তরের প্রতিটি নিউরন

65
00:06:11,740 --> 00:06:17,460
এই সাবকম্পোনেন্টগুলির মধ্যে একটির সাথে মিলে যায়, যে কোনও সময় আপনি একটি চিত্রে একটি লুপ আপ টপ, যেমন

66
00:06:17,460 --> 00:06:23,060
9 বা 8 এর মতো ফিড করেন, সেখানে কিছু আছে নির্দিষ্ট নিউরন যার সক্রিয়তা 1 এর কাছাকাছি হতে

67
00:06:23,060 --> 00:06:28,620
চলেছে। এবং আমি পিক্সেলের এই নির্দিষ্ট লুপ বলতে চাই না, আশা করা যায় যে কোনও

68
00:06:28,620 --> 00:06:33,980
সাধারণভাবে লুপি প্যাটার্ন এই নিউরনের উপরে সেট করে। এইভাবে, তৃতীয় স্তর থেকে শেষ স্তরে

69
00:06:33,980 --> 00:06:39,380
যাওয়ার জন্য কেবলমাত্র শিখতে হবে কোন উপ উপাদানগুলির সংমিশ্রণ কোন সংখ্যার সাথে মিলে

70
00:06:39,380 --> 00:06:44,020
যায়। অবশ্যই, এটি সমস্যার সমাধান করে, কারণ আপনি কীভাবে এই সাবকম্পোনেন্টগুলি

71
00:06:44,020 --> 00:06:48,340
চিনবেন, বা এমনকি সঠিক সাবকম্পোনেন্টগুলি কী হওয়া উচিত তা শিখবেন? এবং আমি এখনও

72
00:06:48,340 --> 00:06:52,900
একটি স্তর পরেরটিকে কীভাবে প্রভাবিত করে সে সম্পর্কেও কথা বলিনি, তবে এক মুহুর্তের জন্য এটিতে আমার সাথে চলুন।

73
00:06:52,900 --> 00:06:59,020
একটি লুপ চিনতেও উপ-সমস্যাগুলি ভেঙে যেতে পারে। এটি করার একটি যুক্তিসঙ্গত উপায় প্রথমে

74
00:06:59,020 --> 00:07:05,640
এটি তৈরি করে এমন বিভিন্ন ছোট প্রান্তগুলিকে চিনতে হবে। একইভাবে, আপনি 1 বা 4 বা

75
00:07:05,640 --> 00:07:11,280
7 ডিজিটে দেখতে পারেন এমন একটি লম্বা লাইন, ভাল এটি সত্যিই একটি দীর্ঘ প্রান্ত, অথবা আপনি এটিকে বেশ

76
00:07:11,280 --> 00:07:18,440
কয়েকটি ছোট প্রান্তের একটি নির্দিষ্ট প্যাটার্ন হিসাবে মনে করেন। তাই হয়তো আমাদের আশা হল নেটওয়ার্কের দ্বিতীয়

77
00:07:18,440 --> 00:07:24,680
স্তরের প্রতিটি নিউরন বিভিন্ন প্রাসঙ্গিক ছোট প্রান্তের সাথে মিলে যায়। হতে পারে যখন এই

78
00:07:24,680 --> 00:07:30,760
ধরনের একটি চিত্র আসে, এটি প্রায় 8 থেকে 10টি নির্দিষ্ট ছোট প্রান্তের সাথে যুক্ত সমস্ত নিউরনকে

79
00:07:31,040 --> 00:07:36,480
আলোকিত করে, যার ফলে উপরের লুপের সাথে যুক্ত নিউরনগুলি এবং একটি দীর্ঘ উল্লম্ব লাইন আলোকিত হয় এবং

80
00:07:36,480 --> 00:07:41,960
সেগুলি আলোকিত করে। একটি 9 এর সাথে যুক্ত নিউরন। আমাদের চূড়ান্ত নেটওয়ার্ক আসলে এটি করে কিনা

81
00:07:41,960 --> 00:07:46,560
তা হল আরেকটি প্রশ্ন, যেটি আমি একবার ফিরে আসব একবার আমরা কীভাবে নেটওয়ার্ককে প্রশিক্ষিত করতে

82
00:07:46,560 --> 00:07:51,800
পারি। কিন্তু এটি একটি আশা যে আমরা থাকতে পারে, এই মত স্তরযুক্ত কাঠামোর সাথে এক ধরণের

83
00:07:51,800 --> 00:07:57,440
লক্ষ্য। তদুপরি, আপনি কল্পনা করতে পারেন যে এইরকম প্রান্ত এবং নিদর্শনগুলি সনাক্ত করতে সক্ষম হওয়া

84
00:07:57,480 --> 00:08:02,440
অন্যান্য চিত্র শনাক্তকরণ কাজের জন্য সত্যিই কার্যকর হবে। এমনকি ইমেজ স্বীকৃতির বাইরেও, এমন সব

85
00:08:02,440 --> 00:08:06,640
ধরণের বুদ্ধিমান জিনিস রয়েছে যা আপনি করতে চাইতে পারেন যা বিমূর্ততার স্তরগুলিতে ভেঙে

86
00:08:06,640 --> 00:08:12,640
যায়। উদাহরণ স্বরূপ, বক্তৃতা পার্সিং এর মধ্যে রয়েছে কাঁচা অডিও নেওয়া এবং স্বতন্ত্র শব্দ বাছাই করা,

87
00:08:12,640 --> 00:08:17,760
যা একত্রিত করে নির্দিষ্ট সিলেবল তৈরি করে, যা একত্রিত হয়ে শব্দ গঠন করে, যা বাক্যাংশ

88
00:08:17,760 --> 00:08:23,360
এবং আরও বিমূর্ত চিন্তা তৈরি করে ইত্যাদি। কিন্তু এর যেকোনটি আসলে কীভাবে কাজ করে সে সম্পর্কে

89
00:08:23,400 --> 00:08:29,160
ফিরে যান, এখনই নিজেকে ডিজাইন করুন যে একটি স্তরের অ্যাক্টিভেশনগুলি ঠিক কীভাবে পরবর্তী অ্যাক্টিভেশনগুলি

90
00:08:29,160 --> 00:08:35,320
নির্ধারণ করতে পারে। লক্ষ্য হল এমন কিছু ব্যবস্থা থাকা যা পিক্সেলকে প্রান্তে, বা

91
00:08:35,320 --> 00:08:41,040
প্রান্তগুলিকে প্যাটার্নে, বা প্যাটার্নগুলিকে অঙ্কে একত্রিত করতে পারে। এবং একটি খুব সুনির্দিষ্ট উদাহরণে জুম

92
00:08:41,040 --> 00:08:47,440
করার জন্য, ধরা যাক দ্বিতীয় স্তরের একটি বিশেষ নিউরনের জন্য আশা করা যায় যে ছবিটি এখানে

93
00:08:47,680 --> 00:08:54,440
এই অঞ্চলে একটি প্রান্ত আছে কিনা। হাতের কাছে প্রশ্ন হল, নেটওয়ার্কে কি কি পরামিতি থাকা

94
00:08:54,440 --> 00:09:00,440
উচিত? আপনি কোন ডায়াল এবং নবগুলিকে টুইক করতে সক্ষম হবেন যাতে এটি সম্ভাব্যভাবে এই প্যাটার্ন, বা অন্য

95
00:09:00,440 --> 00:09:05,880
কোনও পিক্সেল প্যাটার্ন, বা প্যাটার্ন যা বিভিন্ন প্রান্ত একটি লুপ তৈরি করতে পারে এবং এই জাতীয় অন্যান্য

96
00:09:05,880 --> 00:09:11,680
জিনিসগুলি ক্যাপচার করার জন্য যথেষ্ট অভিব্যক্তিপূর্ণ? ঠিক আছে, আমরা যা করব তা হল প্রথম স্তর থেকে

97
00:09:11,680 --> 00:09:17,160
আমাদের নিউরন এবং নিউরনের মধ্যে সংযোগগুলির প্রতিটির জন্য একটি ওজন নির্ধারণ করা। এই ওজন শুধু সংখ্যা.

98
00:09:17,160 --> 00:09:23,960
তারপর প্রথম স্তর থেকে সেই সমস্ত সক্রিয়তা নিন এবং এই ওজন অনুসারে তাদের ওজনযুক্ত

99
00:09:23,960 --> 00:09:30,400
যোগফল গণনা করুন। আমি এই ওজনগুলিকে তাদের নিজস্ব একটি ছোট গ্রিডে সংগঠিত বলে মনে

100
00:09:30,400 --> 00:09:35,200
করা সহায়ক বলে মনে করি, এবং আমি ইতিবাচক ওজন নির্দেশ করতে সবুজ পিক্সেল এবং নেতিবাচক

101
00:09:35,200 --> 00:09:40,760
ওজন নির্দেশ করতে লাল পিক্সেল ব্যবহার করতে যাচ্ছি, যেখানে সেই পিক্সেলের উজ্জ্বলতা কিছুটা ওজন এর

102
00:09:40,760 --> 00:09:45,880
মান আলগা চিত্রণ. যদি আমরা এই অঞ্চলের কিছু ধনাত্মক ওজন ব্যতীত প্রায়

103
00:09:45,880 --> 00:09:51,200
সমস্ত পিক্সেলের সাথে সম্পর্কিত ওজনকে শূন্য করে দেই, তবে সমস্ত পিক্সেল মানগুলির

104
00:09:51,200 --> 00:09:56,360
ওজনযুক্ত যোগফল গ্রহণ করা আসলেই পিক্সেলের মানগুলিকে যোগ করার সমান। যে অঞ্চলটি

105
00:09:56,360 --> 00:10:02,760
আমরা যত্নশীল। এবং যদি আপনি সত্যিই এখানে একটি প্রান্ত আছে কিনা তা বাছাই করতে

106
00:10:02,760 --> 00:10:07,960
চেয়েছিলেন, আপনি যা করতে পারেন তা হল আশেপাশের পিক্সেলগুলির সাথে সম্পর্কিত কিছু নেতিবাচক ওজন। তারপর যোগফল

107
00:10:08,000 --> 00:10:12,680
সবচেয়ে বড় হয় যখন সেই মাঝের পিক্সেলগুলি উজ্জ্বল হয় কিন্তু আশেপাশের পিক্সেলগুলি গাঢ় হয়।

108
00:10:12,680 --> 00:10:19,200
আপনি যখন এইরকম একটি ওজনযুক্ত যোগফল গণনা করেন, তখন আপনি যে কোনও সংখ্যা নিয়ে আসতে পারেন, কিন্তু এই নেটওয়ার্কের জন্য

109
00:10:19,200 --> 00:10:25,200
আমরা যা চাই তা হল অ্যাক্টিভেশনের মান 0 এবং 1 এর মধ্যে থাকা। তাই একটি সাধারণ কাজ হল

110
00:10:25,200 --> 00:10:30,560
এই ওজনযুক্ত যোগফলকে এমন কিছু ফাংশনে পাম্প করা যা বাস্তব সংখ্যা রেখাকে 0 এবং 1-এর মধ্যে রেঞ্জে

111
00:10:30,560 --> 00:10:36,360
স্কুইশ করে। এবং একটি সাধারণ ফাংশন যা এটি করে তাকে সিগময়েড ফাংশন বলা হয়, যা লজিস্টিক কার্ভ

112
00:10:36,360 --> 00:10:42,760
নামেও পরিচিত। মূলত খুব নেতিবাচক ইনপুট 0 এর কাছাকাছি শেষ হয়, খুব ইতিবাচক ইনপুট 1 এর কাছাকাছি

113
00:10:42,760 --> 00:10:51,400
শেষ হয় এবং এটি ইনপুট 0 এর কাছাকাছি ক্রমশ বৃদ্ধি পায়। সুতরাং এখানে নিউরনের সক্রিয়তা মূলত

114
00:10:51,400 --> 00:10:59,320
প্রাসঙ্গিক ওজনযুক্ত যোগফল কতটা ইতিবাচক তার পরিমাপ। কিন্তু সম্ভবত এটা নয় যে আপনি নিউরন

115
00:10:59,320 --> 00:11:04,080
আলোকিত করতে চান যখন ওজনযুক্ত যোগফল 0 এর থেকে বড় হয়। হতে পারে আপনি এটি সক্রিয় করতে চান যখন

116
00:11:04,120 --> 00:11:11,520
যোগফল 10 বলার চেয়ে বড় হয়। অর্থাৎ, আপনি এটি নিষ্ক্রিয় হওয়ার জন্য কিছু পক্ষপাত চান। তারপরে আমরা

117
00:11:11,520 --> 00:11:17,560
যা করব তা হল সিগমায়েড স্কুইশিফিকেশন ফাংশনের মাধ্যমে প্লাগ করার আগে এই ওজনযুক্ত যোগফলের সাথে ঋণাত্মক 10

118
00:11:17,560 --> 00:11:23,840
এর মতো অন্য কিছু সংখ্যা যোগ করা। সেই অতিরিক্ত সংখ্যাটিকে বলা হয় পক্ষপাত। সুতরাং ওজনগুলি

119
00:11:23,840 --> 00:11:29,080
আপনাকে বলে যে দ্বিতীয় স্তরের এই নিউরনটি কোন পিক্সেল প্যাটার্নে উঠছে, এবং পক্ষপাত আপনাকে

120
00:11:29,120 --> 00:11:34,640
বলে যে নিউরন অর্থপূর্ণভাবে সক্রিয় হওয়া শুরু করার আগে ওজনযুক্ত যোগফল কত বেশি হওয়া দরকার।

121
00:11:34,640 --> 00:11:41,760
আর সেটা হল একটা নিউরন। এই স্তরের প্রতিটি নিউরন প্রথম স্তর থেকে সমস্ত 784

122
00:11:41,760 --> 00:11:49,080
পিক্সেল নিউরনের সাথে সংযুক্ত হতে চলেছে এবং সেই 784 সংযোগগুলির প্রত্যেকটির নিজস্ব ওজন

123
00:11:49,080 --> 00:11:55,320
এটির সাথে যুক্ত। এছাড়াও, প্রত্যেকটির কিছু পক্ষপাত রয়েছে, অন্য কিছু সংখ্যা যা আপনি সিগমায়েডের সাথে

124
00:11:55,320 --> 00:12:00,600
স্কুইশ করার আগে ওজনযুক্ত সমষ্টিতে যোগ করেন। এবং এটি সম্পর্কে অনেক চিন্তা! 16টি নিউরনের এই

125
00:12:00,600 --> 00:12:09,280
লুকানো স্তরের সাথে, এটি 16টি পক্ষপাত সহ মোট 784 গুণ 16 ওজন। এবং যে

126
00:12:09,280 --> 00:12:13,760
সব শুধুমাত্র সংযোগ প্রথম স্তর থেকে দ্বিতীয়. অন্যান্য স্তরগুলির মধ্যে সংযোগগুলিও তাদের

127
00:12:13,760 --> 00:12:19,600
সাথে যুক্ত একগুচ্ছ ওজন এবং পক্ষপাত রয়েছে। সমস্ত বলা এবং করা হয়েছে,

128
00:12:19,600 --> 00:12:26,680
এই নেটওয়ার্কের প্রায় 13,000 মোট ওজন এবং পক্ষপাত রয়েছে। 13,000 নব এবং ডায়াল যা এই

129
00:12:26,680 --> 00:12:32,400
নেটওয়ার্ককে বিভিন্ন উপায়ে আচরণ করতে টুইক করা এবং ঘুরানো যায়। তাই যখন আমরা শেখার কথা বলি,

130
00:12:32,400 --> 00:12:38,440
তখন যেটা বোঝানো হচ্ছে তা হল কম্পিউটারকে এই সমস্ত অনেক সংখ্যার জন্য একটি বৈধ সেটিং খুঁজে বের

131
00:12:38,440 --> 00:12:44,400
করা যাতে এটি আসলে হাতের কাছে থাকা সমস্যার সমাধান করে। একটি চিন্তা পরীক্ষা যা একবারে মজাদার

132
00:12:44,400 --> 00:12:49,440
এবং ভয়ঙ্কর রকমের তা হল বসে বসে কল্পনা করা এবং এই সমস্ত ওজন এবং পক্ষপাতগুলি

133
00:12:49,440 --> 00:12:53,960
হাত দিয়ে সেট করা, উদ্দেশ্যমূলকভাবে সংখ্যাগুলিকে টুইক করা যাতে দ্বিতীয় স্তরটি প্রান্তে উঠে যায়,

134
00:12:53,960 --> 00:12:59,680
তৃতীয় স্তরটি প্যাটার্নগুলিতে উঠে যায়, ইত্যাদি আমি ব্যক্তিগতভাবে নেটওয়ার্কটিকে মোট ব্ল্যাক বক্স হিসাবে বিবেচনা করার

135
00:12:59,680 --> 00:13:04,400
পরিবর্তে এটিকে সন্তোষজনক মনে করি, কারণ যখন নেটওয়ার্কটি আপনার প্রত্যাশা অনুযায়ী কাজ করে না, যদি আপনি

136
00:13:04,400 --> 00:13:09,040
সেই ওজন এবং পক্ষপাতগুলি আসলে কী বোঝায় তার সাথে কিছুটা সম্পর্ক তৈরি করেন , কিভাবে

137
00:13:09,040 --> 00:13:13,440
উন্নতি করতে কাঠামো পরিবর্তন করতে হয় তা নিয়ে পরীক্ষা করার জন্য আপনার কাছে একটি শুরুর জায়গা

138
00:13:13,440 --> 00:13:17,680
রয়েছে। অথবা যখন নেটওয়ার্ক কাজ করে, কিন্তু আপনি যে কারণে আশা করতে পারেন তার জন্য

139
00:13:17,680 --> 00:13:22,760
নয়, ওজন এবং পক্ষপাতগুলি কী করছে তা অনুসন্ধান করা আপনার অনুমানগুলিকে চ্যালেঞ্জ করার এবং সম্ভাব্য

140
00:13:22,760 --> 00:13:28,560
সমাধানগুলির সম্পূর্ণ স্থান প্রকাশ করার একটি ভাল উপায়। যাইহোক, এখানে আসল ফাংশনটি লিখতে

141
00:13:28,560 --> 00:13:34,840
একটু কষ্টকর, আপনি কি মনে করেন না? সুতরাং আমাকে এই সংযোগগুলিকে উপস্থাপিত করা হয়

142
00:13:34,840 --> 00:13:39,200
এমন একটি আরও নোটেশনালভাবে কমপ্যাক্ট উপায় দেখাতে দিন। আপনি যদি নিউরাল নেটওয়ার্ক সম্পর্কে আরও পড়তে চান

143
00:13:39,200 --> 00:13:45,360
তবে আপনি এটি দেখতে পাবেন। একটি ভেক্টর হিসাবে একটি কলামে একটি স্তর থেকে সমস্ত সক্রিয়করণ সংগঠিত

144
00:13:45,480 --> 00:13:53,400
করুন। তারপর একটি ম্যাট্রিক্স হিসাবে সমস্ত ওজন সংগঠিত করুন, যেখানে সেই ম্যাট্রিক্সের প্রতিটি সারি একটি

145
00:13:53,400 --> 00:13:58,680
স্তর এবং পরবর্তী স্তরের একটি নির্দিষ্ট নিউরনের মধ্যে সংযোগের সাথে মিলে যায়। এর মানে

146
00:13:58,680 --> 00:14:03,360
হল যে এই ওজন অনুসারে প্রথম স্তরে সক্রিয়করণের ওজনযুক্ত যোগফল নেওয়া আমাদের

147
00:14:03,360 --> 00:14:08,880
এখানে বামদিকে থাকা সমস্ত কিছুর ম্যাট্রিক্স ভেক্টর পণ্যের একটি শর্তের সাথে মিলে

148
00:14:08,880 --> 00:14:17,840
যায়। যাইহোক, অনেক মেশিন লার্নিং শুধুমাত্র রৈখিক বীজগণিতের ভাল উপলব্ধি করার জন্য নেমে আসে, তাই

149
00:14:17,840 --> 00:14:23,000
যারা ম্যাট্রিক্স এবং ম্যাট্রিক্স ভেক্টর গুণের অর্থ কী তা সম্পর্কে একটি সুন্দর ভিজ্যুয়াল বোঝার চান তাদের

150
00:14:23,000 --> 00:14:29,320
জন্য, আমি যে সিরিজটি করেছি তা একবার দেখুন। রৈখিক বীজগণিত, বিশেষ করে অধ্যায় 3। আমাদের

151
00:14:29,320 --> 00:14:34,200
অভিব্যক্তিতে ফিরে আসুন, এই মানগুলির প্রতিটিতে পক্ষপাতগুলিকে স্বাধীনভাবে যুক্ত করার বিষয়ে কথা বলার পরিবর্তে, আমরা

152
00:14:34,200 --> 00:14:40,440
সেই সমস্ত পক্ষপাতগুলিকে একটি ভেক্টরে সংগঠিত করে এবং পূর্ববর্তী ম্যাট্রিক্স ভেক্টর পণ্যে সম্পূর্ণ ভেক্টর যোগ

153
00:14:40,440 --> 00:14:47,240
করে এটিকে উপস্থাপন করি। তারপরে একটি চূড়ান্ত পদক্ষেপ হিসাবে, আমি এখানে বাইরের চারপাশে একটি

154
00:14:47,240 --> 00:14:51,480
সিগমায়েড মোড়ানো করব, এবং এটি যা উপস্থাপন করবে তা হল আপনি ভিতরের ভেক্টরের প্রতিটি

155
00:14:51,480 --> 00:14:58,120
নির্দিষ্ট উপাদানে সিগমায়েড ফাংশন প্রয়োগ করতে যাচ্ছেন। সুতরাং একবার আপনি এই ওজন ম্যাট্রিক্স এবং

156
00:14:58,120 --> 00:15:03,320
এই ভেক্টরগুলিকে তাদের নিজস্ব প্রতীক হিসাবে লিখে ফেললে, আপনি একটি অত্যন্ত আঁটসাঁট এবং ঝরঝরে সামান্য

157
00:15:03,480 --> 00:15:08,840
অভিব্যক্তিতে এক স্তর থেকে পরবর্তী স্তরে সক্রিয়করণের সম্পূর্ণ রূপান্তর যোগাযোগ করতে পারেন এবং এটি প্রাসঙ্গিক

158
00:15:08,840 --> 00:15:14,600
কোডটিকে অনেক সহজ এবং উভয়ই করে তোলে। অনেক দ্রুত, যেহেতু অনেক লাইব্রেরি ম্যাট্রিক্স গুণন থেকে

159
00:15:14,600 --> 00:15:21,400
হেক অপ্টিমাইজ করে। মনে রাখবেন কত আগে আমি বলেছিলাম এই নিউরনগুলি এমন জিনিস যা সংখ্যা ধারণ করে?

160
00:15:22,120 --> 00:15:26,280
অবশ্যই তারা যে নির্দিষ্ট সংখ্যাগুলি ধারণ করে তা নির্ভর করে আপনি যে চিত্রটিতে ফিড করেন

161
00:15:28,120 --> 00:15:31,960
তার উপর, তাই প্রতিটি নিউরনকে একটি ফাংশন হিসাবে ভাবা আসলে আরও নির্ভুল, যেটি পূর্ববর্তী

162
00:15:31,960 --> 00:15:37,240
স্তরের সমস্ত নিউরনের আউটপুট গ্রহণ করে এবং একটি থুতু ফেলে। 0 এবং 1 এর

163
00:15:37,240 --> 00:15:43,800
মধ্যে সংখ্যা। সত্যিই পুরো নেটওয়ার্কটি একটি ফাংশন, যেটি একটি ইনপুট হিসাবে 784টি সংখ্যা নেয়

164
00:15:43,800 --> 00:15:49,720
এবং আউটপুট হিসাবে 10টি সংখ্যা বের করে দেয়। এটি একটি অযৌক্তিকভাবে জটিল ফাংশন, যা

165
00:15:49,720 --> 00:15:54,520
এই ওজন এবং পক্ষপাতের আকারে 13,000 প্যারামিটার জড়িত যা নির্দিষ্ট প্যাটার্নগুলিতে বাছাই

166
00:15:54,520 --> 00:15:59,000
করে এবং যার মধ্যে অনেকগুলি ম্যাট্রিক্স ভেক্টর পণ্য এবং সিগমায়েড স্কুইশিফিকেশন ফাংশন পুনরাবৃত্তি

167
00:15:59,000 --> 00:16:04,760
করা জড়িত, তবে তবুও এটি কেবল একটি ফাংশন। এবং একটি উপায়ে এটি আশ্বস্ত

168
00:16:04,760 --> 00:16:09,720
করার মতো যে এটি জটিল দেখায়। আমি বলতে চাচ্ছি যদি এটি আরও সহজ হয়, তাহলে আমরা কী

169
00:16:09,720 --> 00:16:14,920
আশা করব যে এটি অঙ্কগুলি সনাক্ত করার চ্যালেঞ্জ নিতে পারে? এবং কিভাবে এটা যে চ্যালেঞ্জ নিতে?

170
00:16:14,920 --> 00:16:19,320
কিভাবে এই নেটওয়ার্ক শুধুমাত্র তথ্য দেখে উপযুক্ত ওজন এবং পক্ষপাত শিখে?

171
00:16:19,880 --> 00:16:23,960
ঠিক আছে যা আমি পরবর্তী ভিডিওতে দেখাব, এবং এই বিশেষ নেটওয়ার্কটি আসলে কী করছে তা

172
00:16:23,960 --> 00:16:29,880
আমি আরও কিছুটা খনন করব। এখন আমার মনে হয় সেই ভিডিওটি বা নতুন কোনো ভিডিও কখন

173
00:16:29,880 --> 00:16:34,840
আসবে সে সম্পর্কে অবহিত থাকার জন্য সাবস্ক্রাইব করা উচিত বলে মনে করা উচিত, কিন্তু বাস্তবে আপনার

174
00:16:34,840 --> 00:16:39,880
বেশিরভাগই ইউটিউব থেকে বিজ্ঞপ্তি পান না, তাই না? হয়তো আরও সততার সাথে আমার বলা উচিত

175
00:16:39,880 --> 00:16:44,920
সাবস্ক্রাইব করুন যাতে YouTube-এর সুপারিশ অ্যালগরিদমের অধীনে থাকা নিউরাল নেটওয়ার্কগুলি বিশ্বাস করে যে আপনি এই

176
00:16:44,920 --> 00:16:49,800
চ্যানেলের বিষয়বস্তু দেখতে চান আপনার কাছে সুপারিশ করা হয়। যাইহোক, আরো জন্য পোস্ট থাকুন.

177
00:16:50,600 --> 00:16:54,840
Patreon-এ এই ভিডিওগুলিকে সমর্থনকারী সবাইকে অনেক ধন্যবাদ। আমি এই গ্রীষ্মে সম্ভাব্যতা সিরিজে

178
00:16:54,840 --> 00:16:59,160
অগ্রগতির জন্য একটু ধীর হয়েছি, কিন্তু আমি এই প্রকল্পের পরে এটিতে আবার ঝাঁপিয়ে পড়ছি, তাই পৃষ্ঠপোষকরা

179
00:16:59,160 --> 00:17:05,640
আপনি সেখানে আপডেটের জন্য সন্ধান করতে পারেন। এখানে জিনিসগুলি বন্ধ করার জন্য আমার সাথে লীশা লি

180
00:17:05,640 --> 00:17:09,880
আছে যিনি গভীর শিক্ষার তাত্ত্বিক দিকে তার পিএইচডি কাজ করেছেন, এবং যিনি বর্তমানে অ্যামপ্লিফাই পার্টনারস নামে

181
00:17:09,880 --> 00:17:14,520
একটি ভেঞ্চার ক্যাপিটাল ফার্মে কাজ করেন যারা দয়া করে এই ভিডিওটির জন্য কিছু তহবিল সরবরাহ করেছেন৷

182
00:17:15,160 --> 00:17:19,480
তাই লীশা, আমার মনে হয় একটা জিনিস আমাদের দ্রুত তুলে ধরা উচিত হল এই সিগমায়েড ফাংশন।

183
00:17:19,480 --> 00:17:23,400
যেহেতু আমি এটি বুঝতে পেরেছি যে প্রারম্ভিক নেটওয়ার্কগুলি শূন্য এবং একের মধ্যবর্তী ব্যবধানে প্রাসঙ্গিক ওজনযুক্ত

184
00:17:23,400 --> 00:17:28,200
যোগফলকে স্কুইশ করতে এটি ব্যবহার করে, আপনি জানেন যে নিউরনের এই জৈবিক উপমা দ্বারা

185
00:17:28,200 --> 00:17:33,240
অনুপ্রাণিত হয় নিষ্ক্রিয় বা সক্রিয়। হুবহু। কিন্তু তুলনামূলকভাবে কিছু আধুনিক নেটওয়ার্ক আসলে আর সিগমায়েড

186
00:17:33,240 --> 00:17:37,800
ব্যবহার করে। হ্যাঁ। এটা কি পুরানো স্কুলের মত? হ্যাঁ বা বরং রেলুকে প্রশিক্ষণ দেওয়া অনেক সহজ

187
00:17:37,800 --> 00:17:43,880
বলে মনে হচ্ছে। আর রেলু, রেলু মানে রেক্টিফাইড লিনিয়ার ইউনিট? হ্যাঁ এটি এই ধরনের ফাংশন

188
00:17:43,880 --> 00:17:50,280
যেখানে আপনি কেবলমাত্র সর্বোচ্চ শূন্য নিচ্ছেন এবং যেখানে আপনি ভিডিওতে যা ব্যাখ্যা করছেন তার দ্বারা একটি

189
00:17:50,280 --> 00:17:56,440
দেওয়া হয়। এবং এটি যা থেকে অনুপ্রাণিত হয়েছিল তা আমি মনে করি আংশিকভাবে একটি জৈবিক সাদৃশ্য

190
00:17:56,440 --> 00:18:03,640
দ্বারা কীভাবে নিউরনগুলি সক্রিয় হবে বা হবে না। এবং তাই যদি এটি একটি নির্দিষ্ট থ্রেশহোল্ড অতিক্রম

191
00:18:03,640 --> 00:18:09,080
করে তবে এটি পরিচয় ফাংশন হবে, কিন্তু যদি এটি না হয় তবে এটি সক্রিয় হবে না তাই এটি শূন্য হবে।

192
00:18:09,080 --> 00:18:13,640
তাই এটি একটি সরলীকরণ ধরনের. সিগময়েড ব্যবহার করা প্রশিক্ষণে সাহায্য করেনি বা কিছু সময়ে

193
00:18:13,640 --> 00:18:21,320
প্রশিক্ষণ দেওয়া খুব কঠিন ছিল এবং লোকেরা কেবল রেলু চেষ্টা করেছিল এবং এটি এই অবিশ্বাস্যভাবে

194
00:18:21,320 --> 00:18:26,120
গভীর নিউরাল নেটওয়ার্কগুলির জন্য খুব ভাল কাজ করেছে। ঠিক আছে, ধন্যবাদ লীশা।

195
00:18:39,080 --> 00:18:40,060


