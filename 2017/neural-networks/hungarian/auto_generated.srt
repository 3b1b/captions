1
00:00:04,220 --> 00:00:05,400
Ez egy hármas szám.

2
00:00:06,060 --> 00:00:09,768
Hanyagul van leírva és rendkívül alacsony, 28x28 felbontású, 

3
00:00:09,768 --> 00:00:13,720
de az agyadnak nem okoz gondot felismerni, hogy ez egy 3-as szám.

4
00:00:14,340 --> 00:00:18,960
Hát nem fantasztikus az agyad, hogy ilyen könnyedén felismeri?

5
00:00:19,700 --> 00:00:23,280
Gondold végig, hogy ezeket is hármasként ismered fel, 

6
00:00:23,280 --> 00:00:28,320
még annak ellenére is, hogy az egyes képpontok nagyon különböznek egymástól.

7
00:00:28,900 --> 00:00:32,920
Amikor ezt a hármast látod akkor a szemed teljesen más fényérzékelő 

8
00:00:32,920 --> 00:00:36,940
sejtjei jeleznek az agyadnak, mint ennek a másik hármasnak a láttán.

9
00:00:37,520 --> 00:00:41,608
De van valami az őrülten intelligens vizuális kérgedben ami rájön, 

10
00:00:41,608 --> 00:00:44,781
hogy ezek ugyanazon jelentésnek a megnyilvánulásai, 

11
00:00:44,781 --> 00:00:48,260
miközben más képeket pedig elkülönít ettől a jelentéstől.

12
00:00:49,220 --> 00:00:53,365
De ha most azt mondanám neked, ülj le és írj nekem egy programot, 

13
00:00:53,365 --> 00:00:57,951
amely beolvas egy 28 x 28-as rácsot és egyetlen számot ad ki 0-9 között, 

14
00:00:57,951 --> 00:01:03,478
azt a számjegyet, amit felismerni vél? Nos, a feladat akkor a nevetségesen triviálisból 

15
00:01:03,478 --> 00:01:06,180
hirtelen vért izzasztóan bonyolulttá válna.

16
00:01:07,160 --> 00:01:10,664
Hacsak nem egy barlangban éltél eddig, valószínűleg 

17
00:01:10,664 --> 00:01:14,640
ismered a gépi tanulás és a neurális hálózatok fontosságát.

18
00:01:15,120 --> 00:01:19,311
Most arról fogok beszélni, hogy pontosan mi is az a neurális hálózat. 

19
00:01:19,311 --> 00:01:24,460
Feltételezve az előismeretek hiányát és megpróbálva matekosan vizualizálni a működést.

20
00:01:25,020 --> 00:01:28,041
Mindössze annyit szeretnék elérni, hogy a végén felismerd, 

21
00:01:28,041 --> 00:01:30,806
hogy a struktúra hálózatszerű kialakításának oka van, 

22
00:01:30,806 --> 00:01:34,340
és hogy tudd mit jelent, ha egy neurális hálózat idézőjelben "tanul".

23
00:01:35,360 --> 00:01:38,020
Ebben a videóban csak a struktúra részével foglalkozunk, 

24
00:01:38,020 --> 00:01:40,260
a következőben pedig a tanulással bírkózunk meg.

25
00:01:40,960 --> 00:01:43,269
Most egy olyan neurális hálózatot állítunk össze, 

26
00:01:43,269 --> 00:01:46,040
amely képes megtanulni a kézzel írt számjegyek felismerését.

27
00:01:49,360 --> 00:01:53,846
Ez egy klasszikus példa a téma bemutatására, és örömmel ragaszkodom a status quo-hoz, 

28
00:01:53,846 --> 00:01:58,541
mert a két videó végén mutatok majd néhány jó forrást, ahonnan még többet lehet megtudni, 

29
00:01:58,541 --> 00:02:03,080
illetve ahonnan ez a program is letölthető majd, hogy eljátszhass vele a saját gépeden.

30
00:02:05,040 --> 00:02:08,574
A neurális hálózatoknak nagyon sok változata létezik, 

31
00:02:08,574 --> 00:02:12,568
és az elmúlt években nagyon felggyorsult ezeknek a kutatása, 

32
00:02:12,568 --> 00:02:16,365
de e két bevezető videóban én csak az alapfelszereltségű, 

33
00:02:16,365 --> 00:02:19,180
extrák nélküli verzióval fogok foglalkozni.

34
00:02:19,860 --> 00:02:25,416
Ez egyfajta szükséges előfeltétele annak, hogy megértsük az erősebb modern változatokat, 

35
00:02:25,416 --> 00:02:28,600
és hidd el, hogy ez még így is elég bonyolult lesz.

36
00:02:29,120 --> 00:02:32,745
Mégis ebben a legegyszerűbb formájában is képes lesz megtanulni a kézzel 

37
00:02:32,745 --> 00:02:36,520
írt számjegyek felismerését, ami elég menő képesség egy számítógép részéről.

38
00:02:37,480 --> 00:02:39,758
Ugyanakkor azt is látni fogod, hogy hogyan nem 

39
00:02:39,758 --> 00:02:42,280
fogja beteljesíteni néhány hozzá fűzött reményünket.

40
00:02:43,380 --> 00:02:47,037
Ahogy a neve is sugallja, a neurális hálózatokat az emberi agy inspirálta. 

41
00:02:47,037 --> 00:02:48,500
Tehát érdemes ezzel kezdenünk.

42
00:02:48,520 --> 00:02:51,660
Mik azok a neuronok, és milyen értelemben kapcsolódnak egymáshoz?

43
00:02:52,500 --> 00:02:57,102
Amikor azt mondom, hogy neuron, azt akarom, hogy egy olyan dologra gondoljatok, 

44
00:02:57,102 --> 00:03:00,440
ami egy számot tárol, konkrétan egy 0 és 1 közötti számot.

45
00:03:00,680 --> 00:03:02,560
Ez az egész tényleg nem több ennél.

46
00:03:03,780 --> 00:03:09,063
Például építsünk fel egy hálózatot úgy, hogy ennek a 28x28 pixeles bemeneti képnek 

47
00:03:09,063 --> 00:03:14,220
minden egyes képpontjához rendeljünk egy neuront. Ez összesen 784 neuront jelent.

48
00:03:14,700 --> 00:03:19,633
Ezek mindegyike egy számot tartalmaz, amely a megfelelő pixel szürkeárnyalatos 

49
00:03:19,633 --> 00:03:24,380
értékét jelöli, a fekete pixelek esetén 0-tól a fehér pixeleket jelölő 1-ig.

50
00:03:25,300 --> 00:03:28,198
Ezt a számot a neuronon belül aktivációnak nevezzük, 

51
00:03:28,198 --> 00:03:31,862
és ezt úgy lehet könnyen vizualizálni, hogy minden neuron világít, 

52
00:03:31,862 --> 00:03:34,160
ha az aktivációja magas, azaz a szám nagy.

53
00:03:36,720 --> 00:03:41,860
Tehát ez a 784 neuron alkotja a hálózatunk első rétegét.

54
00:03:46,500 --> 00:03:49,184
Most ugorjunk az utolsó rétegre. Ez 10 neuront tartalmaz, 

55
00:03:49,184 --> 00:03:51,360
amelyek mindegyike egy-egy számjegyet képvisel.

56
00:03:52,040 --> 00:03:57,201
Ezeknek az idegsejteknek az aktivációja - ismét egy 0 és 1 közötti szám - azt jelzi, 

57
00:03:57,201 --> 00:04:02,120
hogy a rendszer mennyire gondolja, hogy ennek a számnak felel meg a bemeneti kép.

58
00:04:03,040 --> 00:04:06,792
Van még egy pár réteg a kettő között, az úgynevezett rejtett rétegek, 

59
00:04:06,792 --> 00:04:09,633
amit egyelőre jelöljünk csak egy óriási kérdőjellel, 

60
00:04:09,633 --> 00:04:13,600
mert mégis hogy a fenébe fogjuk megvalósítani a számfelismerés folyamatát.

61
00:04:14,260 --> 00:04:16,974
Ebben a hálózatban két rejtett réteget választottam, 

62
00:04:16,974 --> 00:04:20,560
egyenként 16 neuronnal, és bevallom, ez valójában egy önkényes döntés.

63
00:04:21,019 --> 00:04:24,735
Amiatt lett két réteg, mert ezzel motiválni akarom a hálózatot valamilyen 

64
00:04:24,735 --> 00:04:28,200
módon amire mindjárt rátérek, a 16 meg egyszerűen csak egy szép szám.

65
00:04:28,780 --> 00:04:32,340
Valójában egy csomót lehet kisérletezni a struktúra kiválasztásához.

66
00:04:33,020 --> 00:04:35,775
A hálózat úgy működik, hogy az egyik réteg aktivációs 

67
00:04:35,775 --> 00:04:38,480
szintjei meghatározzák a következő réteg aktivációit.

68
00:04:39,200 --> 00:04:44,028
És természetesen a hálózat, mint információfeldolgozó mechanizmus lényege pontosan az, 

69
00:04:44,028 --> 00:04:48,580
hogy hogyan eredményez az egyik réteg aktivációja a következő rétegben aktivációt.

70
00:04:49,140 --> 00:04:53,662
Ezzel próbáljuk lemásolni azt a működést, ahogyan a biológiai neuronhálózatokban 

71
00:04:53,662 --> 00:04:57,180
az idegsejtek egyes csoportjai más csoportok tüzelését okozzák.

72
00:04:58,120 --> 00:05:01,732
A hálózat amit most bemutatok már be lett tanítva a számjegyek felismerésére. 

73
00:05:01,732 --> 00:05:03,400
Hadd mutassam meg mit értek ezalatt.

74
00:05:03,640 --> 00:05:06,196
Ez azt jelenti, hogy ha betáplálunk egy képet, 

75
00:05:06,196 --> 00:05:10,765
ami a bemeneti réteg mind a 784 neuronját aktiválja a pixelek fényerőssége szerint, 

76
00:05:10,765 --> 00:05:15,334
akkor az aktivációknak ez a mintázata valamilyen nagyon specifikus mintát generál a 

77
00:05:15,334 --> 00:05:19,305
következő rétegben, amely valamilyen mintát okoz az azt követő rétegben, 

78
00:05:19,305 --> 00:05:22,080
ami végül valamilyen mintát ad a kimeneti rétegben.

79
00:05:22,560 --> 00:05:27,612
És a kimenti réteg legfényesebb neuronja lesz végül a rendszer tippje arra nézve, 

80
00:05:27,612 --> 00:05:29,400
hogy milyen szám van a képen.

81
00:05:32,560 --> 00:05:36,313
És mielőtt belevetnénk magunkat a rétegek egymásra hatását elemző matekba, 

82
00:05:36,313 --> 00:05:39,466
vagy hogy hogyan működik a betanítás, beszéljünk inkább arról, 

83
00:05:39,466 --> 00:05:43,520
hogy miért várhatjuk el egy réteges struktúrától, hogy intelligensen viselkedjen?

84
00:05:44,060 --> 00:05:45,220
Mire számítunk itt?

85
00:05:45,400 --> 00:05:47,600
Mégis milyen viselkedést remélünk a középső rétegektől?

86
00:05:48,920 --> 00:05:51,341
Nos, amikor mi emberek számjegyeket ismerünk fel, 

87
00:05:51,341 --> 00:05:53,520
azok különböző komponenseit illesztjük össze.

88
00:05:54,200 --> 00:05:56,820
A 9-es felül egy hurok és egy vonal a jobb oldalon.

89
00:05:57,380 --> 00:06:01,180
A 8-as szintén egy hurok felül, de most alatta is hurok található.

90
00:06:01,980 --> 00:06:06,820
A 4-est meg lényegében 3 konkrét vonal alkotja, és így tovább.

91
00:06:07,600 --> 00:06:10,358
Na mármost egy tökéletes világban remélhetnénk azt, 

92
00:06:10,358 --> 00:06:14,443
hogy az utolsó előtti réteg minden neuronja megfelel egy ilyen komponensnek, 

93
00:06:14,443 --> 00:06:18,209
hogy ha bármikor olyan képet táplálunk be, aminek hurok van a tetején, 

94
00:06:18,209 --> 00:06:21,604
mint például egy 9-es vagy 8-as, akkor lesz egy konkrét neuron, 

95
00:06:21,604 --> 00:06:23,780
amelynek aktivációja közel lesz az 1-hez.

96
00:06:24,500 --> 00:06:28,116
És persze nem csak egyetlen féle hurok, hanem mindenféle felül 

97
00:06:28,116 --> 00:06:31,560
elhelyezkedő hurok-szerű mintázat aktivizálja ezt a neuront.

98
00:06:32,440 --> 00:06:36,426
Így aztán a harmadik rétegből az utolsóba lépve csak azt kell megtanulnia, 

99
00:06:36,426 --> 00:06:40,040
hogy a számjegyek mely részkomponensek kombinációjának felelnek meg.

100
00:06:41,000 --> 00:06:43,568
Ezzel persze csak kicsit odébbgörgettük a problémát. 

101
00:06:43,568 --> 00:06:47,640
Mert hogyan ismerné fel a komponenseket, vagy tudná, melyekhez melyik szám tartozik?

102
00:06:48,060 --> 00:06:52,298
És még mindig nem beszéltem arról, hogy az egyik réteg hogyan befolyásolja a következőt, 

103
00:06:52,298 --> 00:06:53,060
de tartsatok ki.

104
00:06:53,680 --> 00:06:56,680
Egy hurok felismerése is tovább bontható.

105
00:06:57,280 --> 00:07:01,880
Ennek egyik ésszerű módja az lenne, ha először is felismernénk a különböző kis éleket, 

106
00:07:01,880 --> 00:07:02,780
amelyek alkotják.

107
00:07:03,780 --> 00:07:09,049
Hasonlóképpen azt a hosszú vonalat, ami az 1-es, 4-es és 7-es számjegyekben is szerepel, 

108
00:07:09,049 --> 00:07:14,320
is tekinthetjük egy hosszú élnek, vagy akár több kisebb él meghatározott mintázatának is.

109
00:07:15,140 --> 00:07:18,899
Szóval talán reménykedhetünk pl. abban, hogy a második réteg 

110
00:07:18,899 --> 00:07:22,720
minden neuronja ezeknek a kis meghatározott éleknek felel meg.

111
00:07:23,540 --> 00:07:27,862
Talán amikor egy ilyen kép érkezik be, az összes olyan neuron aktiválódik 

112
00:07:27,862 --> 00:07:30,899
amely ezt a nyolc-tíz egyedi kis élt reprezentálja, 

113
00:07:30,899 --> 00:07:34,696
amelyek pedig aktiválják a felső hurokhoz és a hosszú függőleges 

114
00:07:34,696 --> 00:07:39,720
vonalhoz kapcsolódó neuronokat, amelyek végül a 9-eshez tartozó neuront kapcsolják be.

115
00:07:40,680 --> 00:07:44,248
Az már más kérdés, hogy ez tényleg így zajlik-e le a hálózatunkban, 

116
00:07:44,248 --> 00:07:48,394
de erre még visszatérek, miután megnéztük, hogyan kell betanítani a hálózatot. 

117
00:07:48,394 --> 00:07:52,540
De ez lehet a reményünk, egyfajta célunk az ilyen réteges struktúra működésére.

118
00:07:53,160 --> 00:07:56,836
Sőt, talán már sejtheted, hogy az élek és minták ilyen módon történő 

119
00:07:56,836 --> 00:08:00,300
felismerése nagyon hasznos lenne más képfelismerési feladatoknál.

120
00:08:00,880 --> 00:08:04,338
És még a képfelismerésen túl is van mindenféle értelmezendő dolog, 

121
00:08:04,338 --> 00:08:07,280
amelyeket absztrakciós rétegekre bontva akarsz elvégezni.

122
00:08:08,040 --> 00:08:12,063
A beszédfelismerés például azt jelenti, hogy a nyers hanganyagból kiválogatjuk 

123
00:08:12,063 --> 00:08:16,392
a különböző hangokat, amelyek szótagokat alkotnak, amelyek együtt szavakat alkotnak, 

124
00:08:16,392 --> 00:08:20,060
amelyek mondatokká és akár nagyon elvont gondolatokká állnak össze, stb.

125
00:08:21,100 --> 00:08:25,881
De térjünk vissza arra, hogy mindez hogy is működik. Képzeld el magad, amint megtervezed, 

126
00:08:25,881 --> 00:08:29,920
hogy pontosan hogyan határozzák meg az egyik réteg aktivációi a következőét.

127
00:08:30,860 --> 00:08:35,643
A cél létrehozni egy olyan mechanizmust, amely elképzelhető módon a pixeleket élekké, 

128
00:08:35,643 --> 00:08:38,980
az éleket mintákká, vagy a mintákat számjegyekké kombinálja.

129
00:08:39,440 --> 00:08:42,634
És hogy egy nagyon konkrét példát mutassak: Tegyük fel, 

130
00:08:42,634 --> 00:08:47,710
hogy azt próbáljuk elérni, hogy a második réteg egy bizonyos neuronja meg tudja mondani, 

131
00:08:47,710 --> 00:08:50,620
hogy a képnek ebben a régiójában van-e él vagy sem.

132
00:08:51,440 --> 00:08:55,100
A kérdés az, hogy milyen paraméterekkel kell rendelkeznie a hálózatnak?

133
00:08:55,640 --> 00:08:59,459
Milyen tárcsákat kell tudjunk úgy tekergetni, hogy azzal képesek legyünk 

134
00:08:59,459 --> 00:09:03,907
kifejezni ezt a mintát, vagy bármilyen más pixelmintát? Sőt olyan beállítás is kéne, 

135
00:09:03,907 --> 00:09:07,780
ami meg tudja mondani, hogy több éldarabból mikor lesz hurok, meg hasonló.

136
00:09:08,720 --> 00:09:12,082
Nos, azt fogjuk tenni, hogy súlyokat rendelünk a neuronunk 

137
00:09:12,082 --> 00:09:15,560
és az első réteg neuronjai közötti kapcsolatok mindegyikéhez.

138
00:09:16,320 --> 00:09:17,700
Ezek a súlyok csak számok.

139
00:09:18,540 --> 00:09:21,788
Ezután vegyük az első réteg összes aktivációját, 

140
00:09:21,788 --> 00:09:25,500
és számítsuk ki a súlyozott összegüket e súlyok szerint.

141
00:09:27,700 --> 00:09:30,902
Szerintem szemléletes ezekre a súlyokra is úgy tekinteni, 

142
00:09:30,902 --> 00:09:35,706
mintha ők is egy rácsba rendeződnének. Zöld pixeleket fogok használni a pozitív súlyok 

143
00:09:35,706 --> 00:09:38,301
jelölésére, és piros pixeleket a negatívokéra, 

144
00:09:38,301 --> 00:09:41,780
ahol az adott pixel fényereje a súlyok abszolút értékét jelöli.

145
00:09:42,780 --> 00:09:46,315
Na most, ha szinte az összes képponthoz tartozó súlyunk nulla, 

146
00:09:46,315 --> 00:09:50,019
kivéve néhány pozitív súlyt ebben a régióban, amelyet vizsgálunk, 

147
00:09:50,019 --> 00:09:53,218
akkor lényegében a súlyozott összeg kiszámítása nem más, 

148
00:09:53,218 --> 00:09:57,820
mint hogy összeadjuk a pixelértékeket csak ebben a régióban, amely minket érdekel.

149
00:09:59,140 --> 00:10:02,810
És ha azt akarod igazán megállapítani, hogy itt egy él van-e, 

150
00:10:02,810 --> 00:10:06,600
akkor a környező pixelekhez célszerű negatív súlyokat rendelned.

151
00:10:07,480 --> 00:10:11,194
Ezután az összeg akkor lesz a legnagyobb, ha a középső pixelek világosak, 

152
00:10:11,194 --> 00:10:12,700
de a környező pixelek sötétek.

153
00:10:14,260 --> 00:10:18,838
Amikor egy ilyen súlyozott összeget számolunk, bármilyen számot kaphatunk, 

154
00:10:18,838 --> 00:10:23,540
de ebben a hálózatban azt szeretnénk, hogy az aktivációk 0 és 1 közé essenek.

155
00:10:24,120 --> 00:10:28,105
Ezért gyakran előfordul, hogy ezt a súlyozott összeget becsomagoljuk valamilyen 

156
00:10:28,105 --> 00:10:32,140
függvénybe, amely a valós számok sorát a 0 és 1 közötti tartományba nyomja össze.

157
00:10:32,460 --> 00:10:35,597
Az egyik általános függvény, amivel ez megoldható a szigmoid, 

158
00:10:35,597 --> 00:10:37,420
vagy más néven logisztikus függvény.

159
00:10:38,000 --> 00:10:41,893
Itt lényegében a nagyon negatív értékekből egy nulla közeli érték, 

160
00:10:41,893 --> 00:10:46,600
nagyon pozitívakból 1 közeli érték lesz, 0 környezetében pedig monoton növekszik.

161
00:10:49,120 --> 00:10:53,168
Tehát a neuron aktivációja itt alapvetően azt méri, 

162
00:10:53,168 --> 00:10:56,360
hogy a súlyozott összeg mennyire pozitív.

163
00:10:57,540 --> 00:10:59,778
Lehet viszont, hogy nem akarjuk, ha a neuron már 

164
00:10:59,778 --> 00:11:01,880
0-nál nagyobb súlyozott összeg esetén világít.

165
00:11:02,280 --> 00:11:06,360
Mondjuk azt szeretnénk, hogy csak akkor legyen aktív, ha az összeg nagyobb, mint 10.

166
00:11:06,840 --> 00:11:10,260
Vagyis el kell tolnunk az egészet az inaktivitás irányába.

167
00:11:11,380 --> 00:11:14,068
Ennek érdekében csak hozzáadunk egy másik számot, 

168
00:11:14,068 --> 00:11:16,756
például minusz 10-et ehhez a súlyozott összeghez, 

169
00:11:16,756 --> 00:11:19,660
mielőtt ráeresztenénk a szigmoid összenyomó függvényt.

170
00:11:20,580 --> 00:11:22,440
Ezt a további számot nevezzük eltolósúlynak.

171
00:11:23,460 --> 00:11:27,366
Tehát a sima súlyok megmondják, hogy a második rétegben lévő neuron milyen 

172
00:11:27,366 --> 00:11:29,919
pixelmintát vesz észre, az eltolósúly pedig azt, 

173
00:11:29,919 --> 00:11:33,096
hogy a súlyozott összegnek milyen nagynak kell lennie ahhoz, 

174
00:11:33,096 --> 00:11:35,180
hogy a neuron jelentősen aktívvá váljon.

175
00:11:36,120 --> 00:11:37,680
És ez csak egy neuron.

176
00:11:38,280 --> 00:11:44,610
A második réteg összes többi neuronja is ugyanúgy kapcsolódik az első 

177
00:11:44,610 --> 00:11:50,940
réteg 784 neuronjához, és mind a 784 kapcsolathoz saját súly tartozik.

178
00:11:51,600 --> 00:11:55,878
Továbbá mindegyiknek van egy eltolósúlya is, amelyet hozzáadunk a súlyozott összeghez, 

179
00:11:55,878 --> 00:11:57,600
mielőtt a szigmoiddal összenyomjuk.

180
00:11:58,110 --> 00:11:59,540
És ez rengeteg!

181
00:11:59,960 --> 00:12:06,146
Ezzel a 16 neuronból álló rejtett réteggel ez összesen 784-szer 16 súlyt jelent, 

182
00:12:06,146 --> 00:12:07,980
16 eltolósúllyal együtt.

183
00:12:08,840 --> 00:12:11,940
És mindez csak az első és második réteg közötti kapcsolatrendszer.

184
00:12:12,520 --> 00:12:17,340
A többi réteg közötti kapcsolatokhoz szintén egy csomó súly és eltolósúly tartozik.

185
00:12:18,340 --> 00:12:23,800
Mindent összevetve, ez a hálózat majdnem pont 13000 súlyt és eltolósúlyt tartalmaz.

186
00:12:23,800 --> 00:12:29,960
13000 tekergethető tárcsa, amelyekkel a hálózat különböző viselkedésekre bírható.

187
00:12:31,040 --> 00:12:35,046
Amikor tehát a tanulásról beszélünk, az lényegében az a folyamat, 

188
00:12:35,046 --> 00:12:38,385
amikor a számítógép beállítgatja azt a sok-sok számot, 

189
00:12:38,385 --> 00:12:41,360
hogy ezáltal meg tudja oldani az adott problémát.

190
00:12:42,620 --> 00:12:47,255
Egy egyszerre szórakoztató és rémisztő gondolatkísérlet, ha elképzeljük, ahogy leülünk, 

191
00:12:47,255 --> 00:12:50,363
és kézzel állítjuk be ezeket a súlyokat és eltolósúlyokat, 

192
00:12:50,363 --> 00:12:54,209
célzottan úgy kiválasztva az értékeiket, hogy a második réteg az éleket, 

193
00:12:54,209 --> 00:12:56,580
a harmadik réteg a mintákat ismerje fel, stb.

194
00:12:56,980 --> 00:13:00,008
Én személy szerint szívesebben gondolok erre, ahelyett, 

195
00:13:00,008 --> 00:13:04,498
hogy a hálózatot egy fekete dobozként kezeljük, mert ha a hálózat nem úgy működik, 

196
00:13:04,498 --> 00:13:08,933
ahogyan azt elvártuk, de mi mégis tisztában vagyunk a súlyok valódi funkciójával, 

197
00:13:08,933 --> 00:13:12,990
akkor van kiindulópontunk, ahol el tudunk kezdeni kísérletezni a struktúra 

198
00:13:12,990 --> 00:13:14,180
javításának érdekében.

199
00:13:14,960 --> 00:13:18,717
Vagy amikor bár működik a hálózat, de nem olyan módon amire számítottál, 

200
00:13:18,717 --> 00:13:23,246
a rendszer mélyébe tekintés jó módja annak, hogy megkérdőjelezzük a feltételezéseinket, 

201
00:13:23,246 --> 00:13:25,820
és feltárjuk a lehetséges megoldások teljes terét.

202
00:13:26,840 --> 00:13:30,680
Egyébként a tényleges függvényt itt kicsit nehézkes leírni, nem gondolod?

203
00:13:32,500 --> 00:13:37,140
Hadd mutassam meg tehát, hogyan lehet ezeket a kapcsolatokat tömörebben ábrázolni.

204
00:13:37,660 --> 00:13:40,520
Így találkozhatsz vele később, ha neurális hálózatokról olvasol.

205
00:13:41,380 --> 00:13:46,520
Rendezzük a réteg összes aktivációját egy oszlopvektorba.

206
00:13:47,380 --> 00:13:52,790
Aztán rendezzük az összes súlyt egy mátrixba, ahol a mátrix minden sora megfelel 

207
00:13:52,790 --> 00:13:58,000
az egyik réteg és a következő réteg egy adott neuronja közötti kapcsolatoknak.

208
00:13:58,540 --> 00:14:02,117
Ez azt jelenti, hogy az első réteg aktivációinak súlyozott 

209
00:14:02,117 --> 00:14:05,877
összege az említett súlyok szerint megegyezik a mátrix-vektor 

210
00:14:05,877 --> 00:14:09,880
szorzat eredményének egyik tagjával, ami itt jobb oldalon látható.

211
00:14:14,000 --> 00:14:18,216
Egyébként a gépi tanulás nagy része csak a lineáris algebra jó ismeretén múlik, 

212
00:14:18,216 --> 00:14:22,749
szóval ha bárki egy szép vizuális magyarázatot szeretne kapni a mátrixokról és arról, 

213
00:14:22,749 --> 00:14:27,282
hogy mit jelent a mátrix-vektor szorzás, az nézze meg a lineáris algebra sorozatomat, 

214
00:14:27,282 --> 00:14:28,600
különösen a 3. fejezetet.

215
00:14:29,240 --> 00:14:33,523
Visszatérve a kifejezésünkhöz. Ahelyett, hogy azt mondanánk minden egyes értékhez 

216
00:14:33,523 --> 00:14:36,814
függetlenül adjuk hozzá az eltolósúlyt, ábrázoljuk inkább úgy, 

217
00:14:36,814 --> 00:14:39,531
hogy az összes eltolósúlyt egy vektorba szervezzük, 

218
00:14:39,531 --> 00:14:42,300
és ezt adjuk hozzá az előző mátrix-vektor szorzathoz.

219
00:14:43,280 --> 00:14:48,684
Utolsó lépésként egy szigmoiddal csomagolom be kívülről, ami azt hivatott jelölni, 

220
00:14:48,684 --> 00:14:54,414
hogy a szigmoid függvényt az eredményként kapott vektor minden egyes elemére alkalmazni 

221
00:14:54,414 --> 00:14:54,740
kell.

222
00:14:55,940 --> 00:15:01,144
Tehát ha egyszer leírjuk ezt a súlymátrixot és ezeket a vektorokat külön szimbólumokként, 

223
00:15:01,144 --> 00:15:05,828
akkor az aktivációk terjedését az egyik rétegből a másikba egy rendkívül szűk és 

224
00:15:05,828 --> 00:15:10,802
takaros kis egyenlettel tudjuk kifejezni. És ez az ezt leíró kódot sokkal egyszerűbbé 

225
00:15:10,802 --> 00:15:15,660
és gyorsabbá teszi, mivel sok programkönyvtár a mátrixszorzást szénné optimalizálja.

226
00:15:17,820 --> 00:15:21,460
Ugye korábban azt mondtam, hogy a neuron egyszerű dolog, amely egy számot tárol?

227
00:15:22,220 --> 00:15:27,716
Nos, természetesen a konkrét számok, amelyeket tartalmaznak, a betáplált képtől függnek, 

228
00:15:27,716 --> 00:15:32,657
így valójában pontosabb, ha minden neuronra úgy gondolunk, mint egy függvényre, 

229
00:15:32,657 --> 00:15:36,178
amely az előző réteg összes neuronjának kimenetét veszi, 

230
00:15:36,178 --> 00:15:38,340
és egy 0 és 1 közötti számot ad ki.

231
00:15:39,200 --> 00:15:44,903
Valójában az egész hálózat csak egy függvény, amely bemenetként 784 számot fogad, 

232
00:15:44,903 --> 00:15:47,060
és kimenetként 10 számot ad ki.

233
00:15:47,560 --> 00:15:51,117
Ez egy abszurdan bonyolult függvény, amely 13000 paramétert foglal 

234
00:15:51,117 --> 00:15:55,684
magában a súlyok és eltolósúlyok formájában, amelyek bizonyos mintákat vesznek észre, 

235
00:15:55,684 --> 00:15:59,188
és amely sok iterációnyi mátrix-vektor szorzatot és azok szigmoid 

236
00:15:59,188 --> 00:16:02,640
tömörítését foglalja magában, de ez még így is csak egy függvény.

237
00:16:03,400 --> 00:16:06,660
És bizonyos értelemben megnyugtató, hogy bonyolultnak tűnik.

238
00:16:07,340 --> 00:16:09,786
Ha egyszerűbb lenne, hogyan reménykedhetnénk abban, 

239
00:16:09,786 --> 00:16:12,280
hogy meg tudja oldani a számjegyfelismerés kihívását?

240
00:16:13,340 --> 00:16:14,700
És mégis hogyan teljesíti ezt a kihívást?

241
00:16:15,080 --> 00:16:19,360
Hogyan tanulja meg ez a hálózat a megfelelő súlyokat pusztán az adatok nézegetésével?

242
00:16:20,140 --> 00:16:22,672
Nos, ezt fogom bemutatni a következő videóban, 

243
00:16:22,672 --> 00:16:26,120
hogy mit is csinál valójában ez a bizonyos hálózat, amit látunk.

244
00:16:27,580 --> 00:16:30,998
Most van az a pont, ahol azt kellene mondanom, hogy iratkozz fel, 

245
00:16:30,998 --> 00:16:34,105
hogy értesülj arról, hogy mikor jön ki az a bizonyos videó, 

246
00:16:34,105 --> 00:16:37,420
de a legtöbben tán nem is kaptok értesítést a YouTube-tól, ugye?

247
00:16:38,020 --> 00:16:40,722
Talán őszintébbnek tűnök, ha azt mondom iratkozz fel, 

248
00:16:40,722 --> 00:16:44,676
hogy a YouTube ajánló algoritmusát megvalósító neurális hálózatok azt higgyék, 

249
00:16:44,676 --> 00:16:47,880
hogy szeretnéd, ha az adott csatorna tartalmait ajánlanák neked.

250
00:16:48,560 --> 00:16:49,940
Mindenesetre maradj naprakész!

251
00:16:50,760 --> 00:16:53,500
Nagyon köszönöm mindenkinek, aki támogatja a videóimat a Patreonon.

252
00:16:54,000 --> 00:16:57,363
Ezen a nyáron kicsit lassan haladtam a valószínűséges sorozattal, 

253
00:16:57,363 --> 00:17:01,900
de a mostani projekt után újra belevágok, úgyhogy a támogatóim várhatják a frissítéseket.

254
00:17:03,600 --> 00:17:07,394
A videó végére itt van velem Lisha Lee, aki a gépi tanulásból doktorált, 

255
00:17:07,394 --> 00:17:11,709
és aki jelenleg egy Amplify Partners nevű kockázati tőkebefektető cégnél dolgozik, 

256
00:17:11,709 --> 00:17:14,619
amely a videó finanszírozásának egy részét biztosította.

257
00:17:15,460 --> 00:17:19,119
Szóval Lisha, az egyik dolog, amiről még szót kéne ejtenünk az a szigmoid függvény.

258
00:17:19,700 --> 00:17:22,770
Ha jól értem, a korai hálózatok ezt arra használják, 

259
00:17:22,770 --> 00:17:27,464
hogy a súlyozott összegeket nulla és egy közötti intervallumba szorítsák, tudod, 

260
00:17:27,464 --> 00:17:29,840
a biológiai neuronok működését utánzandó.

261
00:17:30,280 --> 00:17:30,300
Pontosan.

262
00:17:30,560 --> 00:17:34,040
De viszonylag kevés modern hálózat használ már szigmoidot.

263
00:17:34,320 --> 00:17:34,320
Igen.

264
00:17:34,440 --> 00:17:35,540
Már egy kicsit idejétmúlt, nem?

265
00:17:35,760 --> 00:17:38,980
Igen, vagyis inkább a ReLU-val sokkal könnyebb a betanítás.

266
00:17:39,400 --> 00:17:42,340
És a ReLU, az ugye korrigált lineáris függvényt jelent?

267
00:17:42,680 --> 00:17:47,567
Igen, ez egy olyen függvény, ahol csak a nulla és "a" maximumát vesszük, 

268
00:17:47,567 --> 00:17:52,187
ahol "a" onnan származik, amit a videóban elmagyaráztál. Azt hiszem, 

269
00:17:52,187 --> 00:17:55,802
részben az motiválta a kutatókat ennek kipróbálására, 

270
00:17:55,802 --> 00:18:01,360
hogy hasonlít a biológiai neuronok működésére, amelyek vagy aktiválódnak, vagy nem.

271
00:18:01,360 --> 00:18:05,874
Szóval ha az aktiváció átlép egy bizonyos küszöböt, akkor az identitásfüggvény, 

272
00:18:05,874 --> 00:18:10,840
de ha nem, akkor nem is aktiválódna, tehát nulla lenne, tehát ez egyfajta egyszerűsítés.

273
00:18:11,160 --> 00:18:14,083
A szigmoidok használata nem segített a betanításban, 

274
00:18:14,083 --> 00:18:17,172
legalábbis nagyon nehézzé vált egy bizonyos ponton túl. 

275
00:18:17,172 --> 00:18:19,820
Az emberek meg egyszerűen kipróbálták a ReLU-t, 

276
00:18:19,820 --> 00:18:24,620
ami történetesen nagyon jól működött ezeknél a hihetetlenül mély neurális hálózatoknál.

277
00:18:25,100 --> 00:18:25,640
Rendben. Köszönöm Lisha!

