[
 {
  "input": "This is a 3.",
  "translatedText": "",
  "from_community_srt": "Dies ist eine Drei.",
  "n_reviews": 0,
  "start": 4.22,
  "end": 5.4
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "",
  "from_community_srt": "Sie ist schlampig geschrieben und ist bei einer extrem niedrigen Auflösung von 28 um 28 Pixel gerendert. Aber dein Gehirn hat keine Mühe, es als eine Drei zu Erkennen.",
  "n_reviews": 0,
  "start": 6.06,
  "end": 13.72
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "",
  "from_community_srt": "Nimm doch einen Moment Zeit zum Wertschätzen, wie verrückt es ist, dass Gehirne dies so mühelos tun können? Ich meine,",
  "n_reviews": 0,
  "start": 14.34,
  "end": 18.96
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "",
  "from_community_srt": "diese sind auch erkennbar als Dreien, obwohl die spezifischen Werte von jedem Pixel von einem Bild zum Nächsten sehr verschieden sind.",
  "n_reviews": 0,
  "start": 19.7,
  "end": 28.32
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "",
  "from_community_srt": "Die speziellen lichtempfindlichen Zellen im Auge, die aktiviert werden, wenn Sie die diese Drei sehen, sind sehr verschieden sind von denen, die aktiviert werden, wenn Sie die andere Drei sehen.",
  "n_reviews": 0,
  "start": 28.9,
  "end": 36.94
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "",
  "from_community_srt": "Aber etwas in Ihrem verrückten intelligenten visuellen Kortex erkennt diese als dieselbe Idee, während zugleich andere Bilder als ihre ganz eigenen Ideen erkannt werden.",
  "n_reviews": 0,
  "start": 37.52,
  "end": 48.26
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "",
  "from_community_srt": "Aber wenn ich Ihnen sagte, schreiben Sie für mich ein Programm, das ein 28x28 Raster nimmt die Zahl darin erkennt und diese Zahl zwischen 0 und 10 ausgibt... ... dann wird aus einer kinderleichten Aufgabe eine höchst kompliziertes Unterfangen.",
  "n_reviews": 0,
  "start": 49.22,
  "end": 66.18
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "",
  "from_community_srt": "Es sei denn, man lebe hinter dem Mond, muss ich kaum die Relevanz und Bedeutung des maschinellen Lernens und neuronaler Netze für die Gegenwart die Zukunft betonen.",
  "n_reviews": 0,
  "start": 67.16,
  "end": 74.64
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "",
  "from_community_srt": "Aber was will ich hier zu tun will, ist Ihnen zu zeigen, was ein neuronales Netz tatsächlich ist. Ich gehe von keine Vorwissen aus und das Thema wird nicht als Schlagwort visualisiert, sondern als ein Stück Mathematik Meine Hoffnung ist nur,",
  "n_reviews": 0,
  "start": 75.12,
  "end": 84.46
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "",
  "from_community_srt": "dass Sie das Gefühl verlieren, dass diese Struktur selbstmotivert ist und anfangen zu wissen, was es bedeutet, wenn Sie lesen oder hören, dass ein neuronales Netz \"lernt\".",
  "n_reviews": 0,
  "start": 85.02,
  "end": 94.34
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "",
  "from_community_srt": "Dieses Video widmet sich nur den Strukturkomponenten und das folgende Video wird das \"Lernen\" bewältigen.",
  "n_reviews": 0,
  "start": 95.36,
  "end": 100.26
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "",
  "from_community_srt": "Wir setzen ein neuronales Netz zusammen, das lernen soll handgeschriebene Ziffern zu erkennen.",
  "n_reviews": 0,
  "start": 100.96,
  "end": 106.04
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "",
  "from_community_srt": "Dies ist ein klassisches Beispiel als Einführung für das Thema und ich bin zufrieden mit dem Status quo hier, denn am Ende der beiden Videos will ich Sie auf ein paar gute Ressourcen hinweisen, wo Sie mehr lernen und den Code herunterladen können und mit ihm auf Ihrem PC spielen können.",
  "n_reviews": 0,
  "start": 109.36,
  "end": 123.08
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "",
  "from_community_srt": "Es gibt viele, viele Varianten von neuronalen Netzen. Und in den letzten Jahren gab es bei der Erforschung dieser Varianten einen Boom. Aber in diesen beiden einleitenden Videos, werden wir die einfachste Form ohne Extrazusätze betrachten.",
  "n_reviews": 0,
  "start": 125.04,
  "end": 139.18
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "",
  "from_community_srt": "Dies ist eine Art notwendige Voraussetzung, um eine der leistungsfähigeren modernen Varianten zu verstehen und Vertrauen Sie mir. Es noch viel Komplexität hat für uns,",
  "n_reviews": 0,
  "start": 139.86,
  "end": 148.6
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "",
  "from_community_srt": "unseren Geist umschlingen Aber auch in dieser einfachsten Form kann es lernen, handgeschriebene Ziffern zu erkennen. Was eine ziemlich coole Fähigkeit ist für einen Computer.",
  "n_reviews": 0,
  "start": 149.12,
  "end": 156.52
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "",
  "from_community_srt": "Trotzdem werden Sie sehen, wie einige Hoffnungen nicht erfüllt werden können.",
  "n_reviews": 0,
  "start": 157.48,
  "end": 162.28
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "",
  "from_community_srt": "Wie der Name suggeriert, ziehen neurale Netzwerke ihre Inspiration vom tatsächlichen Gehirn. Lassen Sie uns das etwas herunterbrechen.",
  "n_reviews": 0,
  "start": 163.38,
  "end": 168.5
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "",
  "from_community_srt": "Was sind Neuronen und wie sind sie miteinander verbunden? Vorerst,",
  "n_reviews": 0,
  "start": 168.52,
  "end": 171.66
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "wenn ich von Neuronen spreche, möchte ich, dass Sie an ein Konstrukt denken, das eine Nummer beinhalten kann. Insbesondere eine Zahl zwischen 0 und 1.",
  "n_reviews": 0,
  "start": 172.5,
  "end": 180.44
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "",
  "from_community_srt": "Es ist wirklich nicht mehr als das.",
  "n_reviews": 0,
  "start": 180.68,
  "end": 182.56
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "",
  "from_community_srt": "Zum Beispiel: Das Netzwerk beginnt mit einem Bündel von Neuronen zu jedem der 28 mal 28 Bildpunkten des Eingabebildes, das macht: 784 Neuronen insgesamt.",
  "n_reviews": 0,
  "start": 183.78,
  "end": 194.22
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "",
  "from_community_srt": "Jedes enthält eine Zahl, die den Grauwert des entsprechenden Pixels darstellt, und dabei im Bereich von 0 für schwarze Pixel, bis 1 für weisse Pixel liegt.",
  "n_reviews": 0,
  "start": 194.7,
  "end": 204.38
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "",
  "from_community_srt": "Diese Zahl innerhalb des Neurons ist seine sogenannte Aktivierung. Das Bild, das Sie hierfür vor Augen haben könnten ist, dass das Neuron leuchtet, wenn es eine hohe Zahl hat.",
  "n_reviews": 0,
  "start": 205.3,
  "end": 214.16
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "",
  "from_community_srt": "Somit bilden diese ersten 784 Neuronen die erste Stufe des Netzwerks.",
  "n_reviews": 0,
  "start": 216.72,
  "end": 221.86
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "",
  "from_community_srt": "Wenn wir nun zur letzten Stufe springen, verbleiben 10 Neuronen für die 10 Ziffern 0-9.",
  "n_reviews": 0,
  "start": 226.5,
  "end": 231.36
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "",
  "from_community_srt": "Die Aktivierung dieser Neuronen liegt wieder zwischen 0 und 1. Diese Zahl zeigt an, wie sehr das System glaubt, dass es sich bei dem Bild um die entsprechende Zahl handelt.",
  "n_reviews": 0,
  "start": 232.04,
  "end": 242.12
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "",
  "from_community_srt": "Zwischen diesen beiden Stufen gibt es ein paar weitere - die verborgenen Stufen. Welche im Moment nur ein grosses Fragezeichen sind. Wie in aller Welt soll dieser Erkennungsprozess vom Bild zur Zahl gehandhabt werden? In diesem Netzwerk wählte ich zwei verborgene Stufen,",
  "n_reviews": 0,
  "start": 243.04,
  "end": 253.6
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "",
  "from_community_srt": "jeweils mit 16 Neuronen, wobei dies eine willkürliche Zahl ist.",
  "n_reviews": 0,
  "start": 254.26,
  "end": 260.56
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "",
  "from_community_srt": "Ehrlich gesagt, habe ich zwei Stufen gewählt, um besser auf die Funktionsweise eingehen zu können. Und 16, das war einfach eine nette Zahl die auch auf den Bildschirm passt.",
  "n_reviews": 0,
  "start": 261.02,
  "end": 268.2
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "",
  "from_community_srt": "Die gezeigte Struktur erlaubt einiges an Raum zum experimentieren.",
  "n_reviews": 0,
  "start": 268.78,
  "end": 272.34
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "",
  "from_community_srt": "Und so funktioniert's: Die Aktivierung auf einer Stufe bereitet die Aktivierung der nächsten Stufe vor.",
  "n_reviews": 0,
  "start": 273.02,
  "end": 278.48
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "",
  "from_community_srt": "Und natürlich ist das Herz des Netzes als Mechanismus der Informationsverarbeitung, ist die Bestimmung wie genau die Aktivierung einer Stufe die Aktivierung der nächsten herbeiführt.",
  "n_reviews": 0,
  "start": 279.2,
  "end": 288.58
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "",
  "from_community_srt": "Die Idee ist, dass es ungefähr analog zu biologischen neuronalen Netzwerken ist - wo somit die Aktivierung gewisser Neuronen zur Aktivierung anderer Neuronen führt.",
  "n_reviews": 0,
  "start": 289.14,
  "end": 297.18
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "",
  "from_community_srt": "Das Netzwerk hier wurde bereits trainiert um  Ziffern zu erkennen. Lassen Sie mich erläutern, was ich damit meine: Das bedeutet,",
  "n_reviews": 0,
  "start": 298.12,
  "end": 303.4
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "",
  "from_community_srt": "dass wenn ich ein Bild einfüttere, jede der 784 Neuronen der Eingangsstufe einen entsprechenden Wert für die Helligkeit des Bildpunktes erhält. Dieses Muster der Aktivierungen verursacht einige sehr spezifische Muster in der nächsten Schicht. Was ein bestimmtes Muster in der nächsten Stufe herbeiführt, welches schlussendlich ein bestimmtes Muster für die letzte Stufe erstellt.",
  "n_reviews": 0,
  "start": 303.64,
  "end": 322.08
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "",
  "from_community_srt": "Das hellste Neuron dieser Ausgabestufe ist gewissermassen die beste Schätzung des Netzwerkes dessen, was das Bild beinhaltet.",
  "n_reviews": 0,
  "start": 322.56,
  "end": 329.4
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "",
  "from_community_srt": "Und bevor wir in die Mathematik springen und uns anschauen, wie eine Schicht die andere beeinflusst, oder wie das Training funktioniert, sollten wir uns überlegen, warum es überhaupt sinnvoll ist, von dieser Schichtenstruktur intelligentes Verhalten zu erwarten.",
  "n_reviews": 0,
  "start": 332.56,
  "end": 343.52
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "",
  "from_community_srt": "Was erwarten wir denn hier?",
  "n_reviews": 0,
  "start": 344.06,
  "end": 345.22
 },
 {
  "input": "What is the best hope for what those middle layers might be doing?",
  "translatedText": "",
  "from_community_srt": "Was ist die beste Hoffnung dessen,",
  "n_reviews": 0,
  "start": 345.4,
  "end": 347.6
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "",
  "from_community_srt": "was diese Mittelschichten tun könnten? Nun, wenn Sie und ich Zahlen erkennen, so fügen wir einzelne Komponenten zusammen.",
  "n_reviews": 0,
  "start": 348.92,
  "end": 353.52
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "",
  "from_community_srt": "Ein Kreis oben und eine Linie unten im Fall der Neun, beispielsweise.",
  "n_reviews": 0,
  "start": 354.2,
  "end": 356.82
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "",
  "from_community_srt": "Eine 8 hat ebenfalls einen Kreis oben, wird aber mit einem zweiten Kreis darunter kombiniert.",
  "n_reviews": 0,
  "start": 357.38,
  "end": 361.18
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "",
  "from_community_srt": "Eine 4 kann im Grunde in drei Linien heruntergebrochen werden - und so weiter.",
  "n_reviews": 0,
  "start": 361.98,
  "end": 366.82
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "",
  "from_community_srt": "In einer perfekten Welt könnten wir hoffen, dass jedes Neuron in der zweitletzten Schicht einem dieser Unterkomponenten entspricht. Dass also für jedes Bild mit - sagen wir einem Kreis oben, wie bei der 9 oder 8, ein spezifisches Neuron besteht, dessen Aktivierung in der Nähe von 1.0 liegt.",
  "n_reviews": 0,
  "start": 367.6,
  "end": 383.78
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "",
  "from_community_srt": "Und ich meine nicht diesen spezifischen Kreis, sondern alle Kreis-artigen Muster im oberen Bereich dieses Neuron aktiviert.",
  "n_reviews": 0,
  "start": 384.5,
  "end": 391.56
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "",
  "from_community_srt": "Somit ist der letzte Schritt nur noch eine Sache des Lernens, welche Kombinationen von Teilkomponenten welchen Ziffern entspricht.",
  "n_reviews": 0,
  "start": 392.44,
  "end": 400.04
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "",
  "from_community_srt": "Natürlich verschiebt dies das Problem nur nach hinten: Denn wie würden Sie diese Subkomponenten erkennen oder nur schon lernen, was die richtigen Subkomponenten sind,",
  "n_reviews": 0,
  "start": 401.0,
  "end": 407.64
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "",
  "from_community_srt": "und ich habe noch nicht einmal darüber gesprochen, wie eine Schicht die nächste beeinflusst. Aber bleiben Sie bei mir für den Moment.",
  "n_reviews": 0,
  "start": 408.06,
  "end": 413.06
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "",
  "from_community_srt": "Denn das Erkennen eines Kreises kann auch in Teilschritte aufgetrennt werden.",
  "n_reviews": 0,
  "start": 413.68,
  "end": 416.68
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "",
  "from_community_srt": "Eine vernünftige Art dies zu tun wäre, zunächst verschiedene kleine Kanten zu erkennen.",
  "n_reviews": 0,
  "start": 417.28,
  "end": 422.78
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "",
  "from_community_srt": "Diese ähneln den längeren Strichen wie sie bspw. in den Zahlen 1, 4 oder 7 vorkommen. Nun, das sind wirklich nur länge Kanten. Stellen Sie sich also vor, dass bestimmtes Muster aus mehreren kleineren Kanten bestehen.",
  "n_reviews": 0,
  "start": 423.78,
  "end": 434.32
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "",
  "from_community_srt": "Somit wäre unsere Hoffnung, dass jedes Neuron in der zweiten Schicht des Netzes mit verschiedenen relevanten Kanten der ersten Schicht korrespondiert.",
  "n_reviews": 0,
  "start": 435.14,
  "end": 442.72
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "",
  "from_community_srt": "Wenn also ein Bild w ie dieses hier verwendet wird, werden alle Neuronen aktiviert, welche mit etwa acht bis zehn spezifischen Kanten verbunden sind. welche wiederum die zugehörigen Neuronen der oberen Schleife und einer langen vertikalen Linie aktiviert und diese aktivieren schlussendlich die Neuronen, welche mit der 9 assoziiert werden.",
  "n_reviews": 0,
  "start": 443.54,
  "end": 459.72
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "",
  "from_community_srt": "Ob unser endgültiges Netzwerk dies tatsächlich so macht, ist eine andere Frage, auf welche ich zurückkommen werde, wenn wir das Netzwerk trainieren. Aber das ist eine Hoffnung, welche wir haben könnten. Eine Art Zielvorstellung einer Schichtenstruktur.",
  "n_reviews": 0,
  "start": 460.68,
  "end": 472.54
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "",
  "from_community_srt": "Außerdem können Sie sich vorstellen, wie das Erkennen dieser Kanten und Muster auch für andere Bilderkennungsaufgaben nützlich sein könnte.",
  "n_reviews": 0,
  "start": 473.16,
  "end": 480.3
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "",
  "from_community_srt": "Und auch über Bilderkennung hinaus, gibt es alle Arten von intelligenten Dingen, die Sie in Abstraktionsebenen herunterbrechen könnten.",
  "n_reviews": 0,
  "start": 480.88,
  "end": 487.28
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "",
  "from_community_srt": "Sprachanalyse zum Beispiel beinhaltet die Verwendung roher Audiodaten und aus welchen markante Klänge und daraus wiederum Silben gewonnen werden. Diese werden zu Wörtern kombiniert, welche Sätze bilden und abstraktere Gedanken ausdrücken,",
  "n_reviews": 0,
  "start": 488.04,
  "end": 500.06
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "",
  "from_community_srt": "usw. Zurück dazu, wie das alles tatsächlich funktioniert. Stellen Sie sich vor den Prozess zu gestalten. Wie genau könnte die Aktivierungen in einer Schicht die Aktivierungen in den nächsten bestimmen?",
  "n_reviews": 0,
  "start": 501.1,
  "end": 509.92
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "",
  "from_community_srt": "Das Ziel ist es, einen Mechanismus zu haben, welcher Pixel zu Kanten kombinieren kann. Oder Kanten zu Mustern oder Muster zu Ziffern.",
  "n_reviews": 0,
  "start": 510.86,
  "end": 518.98
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "",
  "from_community_srt": "Schauen wir uns das mal an einem ganz bestimmten Beispiel an: Versuchen wir mal für ein ganz bestimmtes Neuron der zweiten Schicht zu prüfen, ob oder nicht das Bild eine Kante in dieser Region hat.",
  "n_reviews": 0,
  "start": 519.44,
  "end": 530.62
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "",
  "from_community_srt": "Die zentrale Frage ist, welche Parameter sollte das Netzwerk haben und welche Grössen verändert und angepasst werden sollten,",
  "n_reviews": 0,
  "start": 531.44,
  "end": 535.1
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "",
  "from_community_srt": "sodass sie ausdrucksstark genug sind, um möglicherweise dieses Muster zu erfassen. Oder jedes andere Pixelmuster, oder das Muster, dank welchem einige Kanten eine Schleife bilden können etc.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 547.78
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "",
  "from_community_srt": "Was wir nun tun, ist jeder Verbindung zwischen unserem Neuron und jedem Neuron der ersten Stufe ein Gewicht zu geben.",
  "n_reviews": 0,
  "start": 548.72,
  "end": 555.56
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "",
  "from_community_srt": "Diese Gewichte sind beliebige Zahlen.",
  "n_reviews": 0,
  "start": 556.32,
  "end": 557.7
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "",
  "from_community_srt": "Dann nehmen wir alle Aktivierungswerte der ersten Stufe und berechnen die gewichtete Summe ihres Einflusses.",
  "n_reviews": 0,
  "start": 558.54,
  "end": 565.5
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "",
  "from_community_srt": "Ich finde es nützlich, mir die einzelnen Gewichte als ein eigenes Muster vorzustellen Und ich verwende grüne Pixel für positive Gewichte und rote Pixel für negative Gewichte, wobei die Helligkeit jedes Pixels eine lose Darstellung des Wertes des Gewichts ist.",
  "n_reviews": 0,
  "start": 567.7,
  "end": 581.78
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "",
  "from_community_srt": "Wenn wir nun die Gewichte fast aller Pixel auf Null setzen, mit Ausnahme einiger positiver Gewichte in der Region, welche uns interessiert, und die gewichtete Summe nehmen, dann entspricht diese nur den Pixelwerten in der Region, die uns interessiert.",
  "n_reviews": 0,
  "start": 582.78,
  "end": 597.82
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "",
  "from_community_srt": "Wenn Sie nun wirklich bestätigen wollen, ob es dort eine Kante hat, so können Sie einige negative Gewichte mit den umliegenden Pixeln assoziieren.",
  "n_reviews": 0,
  "start": 599.14,
  "end": 606.6
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "",
  "from_community_srt": "So ist die Summe dann am größten, wenn die mittleren Pixel hell sind und die umgebenden Pixel dunkler.",
  "n_reviews": 0,
  "start": 607.48,
  "end": 612.7
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "Wenn Sie eine gewichtete Summe berechnen, kann eine beliebige Zahl dabei raus kommen. Aber für dieses Netzwerk wollen wir Aktivierungen erhalten, welche einen Wert zwischen 0 und 1 einnehmen.",
  "n_reviews": 0,
  "start": 614.26,
  "end": 623.54
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "Eine übliche Art, mit diesem Problem umzugehen ist, diese gewichtete Summe zu skalieren. Dies passiert in einer Funktion, welche die Auswahl reeller Zahlen in den Bereich zwischen 0 und 1 quetscht.",
  "n_reviews": 0,
  "start": 624.12,
  "end": 632.14
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "",
  "from_community_srt": "Eine bekannte Funktion, welche dies tut, ist die Sigmoid-Funktion (auch logistische Kurve genannt).",
  "n_reviews": 0,
  "start": 632.46,
  "end": 637.42
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "",
  "from_community_srt": "Kurz gesagt: Sehr negative Werte fallen in die Nähe von Null, während sehr positive Werte sich 1 nähern und die Werte steigen stetig an im Bereich um Null.",
  "n_reviews": 0,
  "start": 638.0,
  "end": 646.6
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "",
  "from_community_srt": "Aktivierung dieses Neurons ist also im Grunde ein Maß dafür, wie positiv die gewichtete Summe ist.",
  "n_reviews": 0,
  "start": 649.12,
  "end": 656.36
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "",
  "from_community_srt": "Aber vielleicht möchten Sie gar nicht, dass das Neuron aufleuchtet, sobald es einen höheren Wert als 0 hat.",
  "n_reviews": 0,
  "start": 657.54,
  "end": 661.88
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "",
  "from_community_srt": "Vielleicht möchten Sie es nur dann aktiv haben, wenn die gewichtete Summe grösser als 10 ist.",
  "n_reviews": 0,
  "start": 662.28,
  "end": 666.36
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "",
  "from_community_srt": "Das heißt, Sie wollen eine gewisse Tendenz dazu, inaktiv zu sein.",
  "n_reviews": 0,
  "start": 666.84,
  "end": 670.26
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "",
  "from_community_srt": "Was wir dann tun ist, eine andere Zahl hinzufügen - wie bspw. (-10), bevor sie durch die S-förmige Skalierungsfunktion wandert.",
  "n_reviews": 0,
  "start": 671.38,
  "end": 679.66
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "",
  "from_community_srt": "Diese zusätzliche Zahl wird Verzerrung (oder Bias) genannt.",
  "n_reviews": 0,
  "start": 680.58,
  "end": 682.44
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "",
  "from_community_srt": "Somit sagen die Gewichte, welche Pixelmuster dieses Neuron in der zweiten Schicht aufgreifen soll und die Verzerrung gibt an, wie hoch die gewichtete Summe sein muss, damit eine Aktivierung eingeleitet wird.",
  "n_reviews": 0,
  "start": 683.46,
  "end": 695.18
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "",
  "from_community_srt": "Und das ist erst ein Neuron.",
  "n_reviews": 0,
  "start": 696.12,
  "end": 697.68
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "",
  "from_community_srt": "Jedes andere Neuron in dieser Schicht ist ebenfalls mit allen 784 Pixelneuronen aus der ersten Schicht verbunden und jeder dieser Anschlüsse hat ein eigenes Gewicht, welches damit verbundenen ist.",
  "n_reviews": 0,
  "start": 698.28,
  "end": 710.94
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "",
  "from_community_srt": "Ebenfalls hat jedes eine Verzerrung, eine Zahl, welche hinzugefügt wird, bevor die Sigmoid-Funktion angewendet wird (Skalierung auf 0-1).",
  "n_reviews": 0,
  "start": 711.6,
  "end": 717.6
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "",
  "from_community_srt": "Das ergibt viele Zwischenresultate.",
  "n_reviews": 0,
  "start": 718.11,
  "end": 719.54
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "",
  "from_community_srt": "Mit 16 Schichten dieser versteckten Schichten ergibt das 784 Pixel * 16 Gewichte mit 16 Verzerrungskonstanten.",
  "n_reviews": 0,
  "start": 719.96,
  "end": 727.98
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "",
  "from_community_srt": "Und all dies ergibt erst die Verbindung der ersten und zweiten Schicht.",
  "n_reviews": 0,
  "start": 728.84,
  "end": 731.94
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "",
  "from_community_srt": "Die Verbinungen zu den weiteren Schichten haben ebenfalls einen Haufen Gewichte und Verzerrungen angehängt.",
  "n_reviews": 0,
  "start": 732.52,
  "end": 737.34
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "",
  "from_community_srt": "Schlussendlich hat dieses Netzwerk fast aufs Loch genau 13,000 Gewichte und Verzerrungen.",
  "n_reviews": 0,
  "start": 738.34,
  "end": 743.8
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "",
  "from_community_srt": "13.000 Knöpfe und Regler, die gedrückt und gedreht werden können, umd das Verhalten dieses Netzwerkes zu beeinflussen.",
  "n_reviews": 0,
  "start": 743.8,
  "end": 749.96
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "",
  "from_community_srt": "Wenn wir also von 'lernen' sprechen, beziehen wir uns darauf, dass der Computer herausfinden soll, welche Ausprägung all dieser Stellschrauben das Problem schlussendlich lösen kann.",
  "n_reviews": 0,
  "start": 751.04,
  "end": 761.36
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "",
  "from_community_srt": "Stellen Sie sich vor: Gleichzeitig lustig und schrecklich: Sie müssten alle diese Gewichte und Verzerrungen von Hand eingeben! Gezielt die Zahlen optimieren, sodass die zweite Schicht Kanten erkennt, die dritte dann Muster usw.",
  "n_reviews": 0,
  "start": 762.62,
  "end": 776.58
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "",
  "from_community_srt": "Ich persönlich finde diese Idee befriedigend - um das Netzwerk nicht als komplette Blackbox behandeln zu müssen. Denn wenn das Netzwerk nicht wunschgemäss funktioniert, und Sie ein minimales Verständnis davon haben, was diese Gewichte und Verzerrungen überhaupt bedeuten, haben Sie Handlungsmöglichkeiten und können erahnen, wie das Netzwerk verbessert werden könnte.",
  "n_reviews": 0,
  "start": 776.98,
  "end": 794.18
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "",
  "from_community_srt": "Oder: Wenn das Netzwerk funktioniert, aber vielleicht nicht aus den erwarteten Gründen, könnten Sie die Gewichte und Verzerrungen überprüfen um Ihre Annahmen zu überdenken und ggf. den Lösungsraum erweitern.",
  "n_reviews": 0,
  "start": 794.96,
  "end": 805.82
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "",
  "from_community_srt": "Zudem: Die tatsächliche Funktion zu notieren erscheint etwas mühsam,",
  "n_reviews": 0,
  "start": 806.84,
  "end": 810.68
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "",
  "from_community_srt": "finden Sie nicht? Lassen Sie mich also  eine kompaktere Notierung verwenden.",
  "n_reviews": 0,
  "start": 812.5,
  "end": 817.14
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "",
  "from_community_srt": "So würden Sie es denn auch sehen, wenn Sie sich weiter zum Thema neuronale Netze informieren möchten.",
  "n_reviews": 0,
  "start": 817.66,
  "end": 820.52
 },
 {
  "input": "Organize all of the activations from one layer into a column as a vector.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 821.38,
  "end": 820.52
 },
 {
  "input": "Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "",
  "from_community_srt": "Organisieren Sie alle Aktivierungswerte einer Schicht in die Spalte eines Vektors. Dann stellen Sie alle Gewichte in der Form einer Matrix dar, in welcher jede Zeile der Verbindung zwischen einer Schicht und einem bestimmten Neuron der nächsten Schicht entspricht",
  "n_reviews": 0,
  "start": 821.38,
  "end": 838.0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "",
  "from_community_srt": "Das bedeutet, daß die gewichtete Summe der Aktivierungen in der ersten Schich gemäss dieser Gewichte einem Ausdruck des Matrizen-Vektor-Produkts von allem auf der linken Seite entspricht.",
  "n_reviews": 0,
  "start": 838.54,
  "end": 849.88
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "",
  "from_community_srt": "Nebenbei: Der Grossteil dessen, was bei Machine Learning passiert, kann durch ein gutes Verständnis von linearer Algebra erklärt werden. Wer also eine hübsche Visualisierung dessen wünscht was Matrizen sind, oder wie Vektor-Multiplikation funktioniert, sollte sich meine Serie zur linearen Algebra anschauen. Vor allem das 3.",
  "n_reviews": 0,
  "start": 854.0,
  "end": 868.6
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "",
  "from_community_srt": "Kapitel! Zurück zu unserer Veranschaulichung: Statt die Verzerrung jeder einzelnen Zeile anzufügen, können wir sie ebenfalls in Form eines Vektors organisieren, welchen wir dem vorangegangenen Matrizen-Vektor-Produkt hinzufügen können.",
  "n_reviews": 0,
  "start": 869.24,
  "end": 882.3
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "",
  "from_community_srt": "Als letzten Schritt, packe ich das Ganze in eine Sigmoid-Funktion. Und was das darstellen soll ist, dass Sie die Sigmoid-Funktion auf jeden der resultierenden Vektorkomponenten anwenden.",
  "n_reviews": 0,
  "start": 883.28,
  "end": 894.74
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "",
  "from_community_srt": "Wenn Sie also diese Gewichtsmatrix und diese Vektoren als eigene Symbole darstellen, können Sie den gesamten Aktivierungs-Übergang von einer Stufe zur nächsten in kürzester Form notieren. Dies macht den entsprechenden Code sowohl viel einfacher zu schreiben, als auch viel schneller, da viele Bibliotheken Matrixmultiplikation optimiert haben.",
  "n_reviews": 0,
  "start": 895.94,
  "end": 915.66
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "",
  "from_community_srt": "Erinnern Sie sich, wie ich sagte, dass diese Neuronen einfach Dinge seien, die Zahlen halten können? Nun,",
  "n_reviews": 0,
  "start": 917.82,
  "end": 921.46
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "natürlich hängt dabei die spezifische Zahl davon ab, was man dem Netzwerk als Input liefert. Es wäre aber präziser zu sagen, dass jedes Neuron einer Funktion entspricht. Eine Funktion, die als eigenen Input die Resultate aller vorangegangenen Neuronen erhält, und eine Zahl zwischen 0 und 1 ausspuckt.",
  "n_reviews": 0,
  "start": 922.22,
  "end": 938.34
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "",
  "from_community_srt": "Eigentlich ist das Ganze Netzwerk einfach eine grosse Funktion, welche 784 Zahlen als Input erhält und zehn Zahlen als Output serviert.",
  "n_reviews": 0,
  "start": 939.2,
  "end": 947.06
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless.",
  "translatedText": "",
  "from_community_srt": "Es ist eine absurd komlizierte Funktion, eine die 13'000 Parameter in Form von Gewichten und Verzerrungen beinhaltet und gewisse Muster erkennt, in dem sie immer wieder Matrizen-Vektor-Produkte und Skalierungen auswertet. Aber es ist nur eine Funktion.",
  "n_reviews": 0,
  "start": 947.56,
  "end": 962.64
 },
 {
  "input": "And in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "",
  "from_community_srt": "Und gewissermassen ist die augenscheinliche Komplexität beruhigend: Wenn es irgendwie einfacher wäre,",
  "n_reviews": 0,
  "start": 963.4,
  "end": 966.66
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "",
  "from_community_srt": "welche Hoffnung hätten wir,",
  "n_reviews": 0,
  "start": 967.34,
  "end": 972.28
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "",
  "from_community_srt": "dass es der Herausforderung der Zahlenerkennung gewachsen wäre? Und wie nimmte es sich dieser Herausforderung überhaupt an?",
  "n_reviews": 0,
  "start": 973.34,
  "end": 974.7
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "",
  "from_community_srt": "Wie erkennt das Netzwerk die entsprechenden Gewichte und Verzerrungen,",
  "n_reviews": 0,
  "start": 975.08,
  "end": 979.36
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "",
  "from_community_srt": "wenn es nur entsprechende Daten erhält? Genau das werde ich im nächsten Video aufzeigen. Ebenfalls werde ich etwas detaillierter darauf eingehen, was im gezeigten Netzwerk tatsächlich abläuft.",
  "n_reviews": 0,
  "start": 980.14,
  "end": 986.12
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "",
  "from_community_srt": "Jetzt ist der Zeitpunkt da, an dem ich vermutlich an das Abonnieren und 'Gefällt-Mir-Drücken' erinnern sollte, damit Sie auf dem Laufenden bleiben können. Aber realistisch gesehen erhalten die meisten von Ihnen wahrscheinlich sowieso keine Youtube-Benachrichtigungen,",
  "n_reviews": 0,
  "start": 987.58,
  "end": 997.42
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "",
  "from_community_srt": "nicht wahr? Vielleicht sollte ich eher sagen: \"Abonniere, damit Youtube's Neuronales Netzwerk, welches die Empfehlungen generiert, dazu erzogen wird zu glauben, dass Du mehr von diesem Kanal sehen möchtest.",
  "n_reviews": 0,
  "start": 998.02,
  "end": 1007.88
 },
 {
  "input": "Anyway, stay posted for more.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1008.56,
  "end": 1009.94
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "",
  "from_community_srt": "Vielen Dank für alle Unterstützer von Patreon.",
  "n_reviews": 0,
  "start": 1010.76,
  "end": 1013.5
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "",
  "from_community_srt": "Ich war ein wenig langsam diesen Sommer was die Serie zum Thema Wahrscheinlichkeit betrifft, Aber ich mache gleich nach diesem Projekt wieder weiter. Patreons, Ihr könnt also nach Updates Ausschau halten.",
  "n_reviews": 0,
  "start": 1014.0,
  "end": 1021.9
 },
 {
  "input": "To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "",
  "from_community_srt": "Zu guter Letzt habe ich nun noch Lisha Li bei mir. Lee hat ihre Doktorarbeit über die theoretische Seite von Deep Learning geschrieben und arbeitet zurzeit bei einer Venture Capital Firma namens Amplify Partners, welche freundlicherweise die Produktion dieses Videos mitfinanziert habt.",
  "n_reviews": 0,
  "start": 1023.6,
  "end": 1034.62
 },
 {
  "input": "So Lisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "",
  "from_community_srt": "Also, Lisha: Ich denke, wir sollten schnell diese Sigmoidfunktion hervorholen.",
  "n_reviews": 0,
  "start": 1035.46,
  "end": 1039.12
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "",
  "from_community_srt": "Wie ich es verstanden habe, nutzten frühere Netzwerke diese Funktion um die relevanten gewichteten Summen in einen Intervall von 0-1 zu quetschen. Sie wissen schon, von dieser biologischen Analogie motiviert, dass ein Neuron aktiv oder inaktiv ist.",
  "n_reviews": 0,
  "start": 1039.7,
  "end": 1049.84
 },
 {
  "input": "Exactly.",
  "translatedText": "",
  "from_community_srt": "(Lisha:) Ja,",
  "n_reviews": 0,
  "start": 1050.28,
  "end": 1050.3
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "",
  "from_community_srt": "genau! (3B1B:) Aber inzwischen nutzen nur wenige moderne Netzwerke die Sigmoid-Funktion.",
  "n_reviews": 0,
  "start": 1050.56,
  "end": 1054.04
 },
 {
  "input": "Yeah.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1054.32,
  "end": 1054.32
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1054.44,
  "end": 1055.54
 },
 {
  "input": "Yeah or rather ReLU seems to be much easier to train.",
  "translatedText": "",
  "from_community_srt": "Ist das veraltet? Lisha: Ja. Bzw. scheint Relu viel leichter zu sein für's Training.",
  "n_reviews": 0,
  "start": 1055.76,
  "end": 1058.98
 },
 {
  "input": "And ReLU, ReLU stands for rectified linear unit?",
  "translatedText": "",
  "from_community_srt": "(3B1B:) Und Relu steht für entzerrte Lineareinheit?",
  "n_reviews": 0,
  "start": 1059.4,
  "end": 1062.34
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not.",
  "translatedText": "",
  "from_community_srt": "(frei übersetzt) (Lisha:) - Ja, es ist diese Art Funktion, wo Sie ein Maximum 0 und a definieren, wobei a so definiert wird, wie Du es im Video erklärt hast und woher dies stammt ist, so glaube ich, ist teilweise durch eine Analogie aus der Biologie, wonach Neuronen entweder aktiviert oder nicht aktiviert sind, je nach dem,",
  "n_reviews": 0,
  "start": 1062.68,
  "end": 1081.36
 },
 {
  "input": "And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "",
  "from_community_srt": "ob eine bestimmte Schwelle überwunden ist. Wenn dem so ist, verwenden wir die Identitätsfunktion, Wenn nicht, dann ist die Aktivierung einfach gleich Null. Das ist also eine Vereinfachung.",
  "n_reviews": 0,
  "start": 1081.36,
  "end": 1090.84
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "",
  "from_community_srt": "Sigmoid funktionierte nicht gut - oder eher: es war schwierig Verbesserungen zu erzielen. Irgendwann hat man Relu ausprobiert und es schien zu funktionieren. Sehr gut sogar - für diese unglaublich tiefgründigen Neuronalen Netzwerke.",
  "n_reviews": 0,
  "start": 1091.16,
  "end": 1104.62
 },
 {
  "input": "All right thank you Lisha.",
  "translatedText": "",
  "from_community_srt": "(3B1B:) Danke,",
  "n_reviews": 0,
  "start": 1105.1,
  "end": 1105.64
 }
]