1
00:00:04,220 --> 00:00:05,400
Αυτό είναι ένα 3.

2
00:00:06,060 --> 00:00:10,489
Είναι πρόχειρα γραμμένο και απεικονίζεται σε εξαιρετικά χαμηλή ανάλυση 28x28 pixels, 

3
00:00:10,489 --> 00:00:13,720
αλλά ο εγκέφαλός σας δεν έχει πρόβλημα να το αναγνωρίσει ως 3.

4
00:00:14,340 --> 00:00:16,650
Και θέλω να αφιερώσετε ένα λεπτό για να εκτιμήσετε πόσο τρελό 

5
00:00:16,650 --> 00:00:18,960
είναι που οι εγκέφαλοι μπορούν να το κάνουν αυτό τόσο αβίαστα.

6
00:00:19,700 --> 00:00:23,158
Θέλω να πω, αυτό, αυτό και αυτό είναι επίσης αναγνωρίσιμα ως 3s, 

7
00:00:23,158 --> 00:00:27,415
παρόλο που οι συγκεκριμένες τιμές κάθε pixel είναι πολύ διαφορετικές από τη μία 

8
00:00:27,415 --> 00:00:28,320
εικόνα στην άλλη.

9
00:00:28,900 --> 00:00:32,895
Τα συγκεκριμένα φωτοευαίσθητα κύτταρα στο μάτι σας που πυροδοτούνται όταν βλέπετε 

10
00:00:32,895 --> 00:00:36,940
αυτό το 3 είναι πολύ διαφορετικά από αυτά που πυροδοτούνται όταν βλέπετε αυτό το 3.

11
00:00:37,520 --> 00:00:41,138
Αλλά κάτι στον τρελά έξυπνο οπτικό φλοιό σας διαχωρίζει αυτές 

12
00:00:41,138 --> 00:00:44,057
τις εικόνες ως αντιπροσωπευτικές της ίδιας ιδέας, 

13
00:00:44,057 --> 00:00:48,260
ενώ ταυτόχρονα αναγνωρίζει άλλες εικόνες ως δικές τους ξεχωριστές ιδέες.

14
00:00:49,220 --> 00:00:53,295
Αλλά αν σας έλεγα, ε, κάτσε κάτω και γράψε μου ένα πρόγραμμα που θα 

15
00:00:53,295 --> 00:00:57,490
παίρνει ένα πλέγμα 28x28 εικονοστοιχείων όπως αυτό και θα βγάζει έναν 

16
00:00:57,490 --> 00:01:01,865
απλό αριθμό μεταξύ 0 και 10, λέγοντάς σας τι νομίζει ότι είναι το ψηφίο, 

17
00:01:01,865 --> 00:01:06,180
τότε η εργασία γίνεται από κωμικοτραγικά ασήμαντη σε τρομακτικά δύσκολη.

18
00:01:07,160 --> 00:01:09,759
Αν δεν έχετε ζήσει κάτω από ένα βράχο, νομίζω ότι δεν χρειάζεται 

19
00:01:09,759 --> 00:01:12,160
να αιτιολογήσω τη σημασία και τη σπουδαιότητα της μηχανικής 

20
00:01:12,160 --> 00:01:14,640
μάθησης και των νευρωνικών δικτύων για το παρόν και το μέλλον.

21
00:01:15,120 --> 00:01:18,181
Αλλά αυτό που θέλω να κάνω εδώ είναι να σας δείξω τι είναι στην πραγματικότητα 

22
00:01:18,181 --> 00:01:20,817
ένα νευρωνικό δίκτυο, χωρίς να υποθέσουμε ότι δεν υπάρχει υπόβαθρο, 

23
00:01:20,817 --> 00:01:23,064
και να σας βοηθήσω να απεικονίσετε τι κάνει, όχι ως λέξη, 

24
00:01:23,064 --> 00:01:24,460
αλλά ως ένα κομμάτι των μαθηματικών.

25
00:01:25,020 --> 00:01:28,430
Η ελπίδα μου είναι να φύγετε νιώθοντας ότι η ίδια η δομή έχει κίνητρα, 

26
00:01:28,430 --> 00:01:31,409
και να νιώσετε ότι ξέρετε τι σημαίνει όταν διαβάζετε ή ακούτε 

27
00:01:31,409 --> 00:01:34,340
για ένα νευρωνικό δίκτυο που παραθέτει το απόσπασμα "μάθηση".

28
00:01:35,360 --> 00:01:38,328
Αυτό το βίντεο θα είναι αφιερωμένο στη δομική συνιστώσα αυτού, 

29
00:01:38,328 --> 00:01:40,260
και το επόμενο θα ασχοληθεί με τη μάθηση.

30
00:01:40,960 --> 00:01:43,280
Αυτό που πρόκειται να κάνουμε είναι να δημιουργήσουμε ένα 

31
00:01:43,280 --> 00:01:46,040
νευρωνικό δίκτυο που μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία.

32
00:01:49,360 --> 00:01:52,127
Αυτό είναι ένα κάπως κλασικό παράδειγμα για την εισαγωγή του θέματος, 

33
00:01:52,127 --> 00:01:54,381
και είμαι ευτυχής που θα παραμείνω με το status quo εδώ, 

34
00:01:54,381 --> 00:01:57,821
επειδή στο τέλος των δύο βίντεο θέλω να σας υποδείξω μερικές καλές πηγές όπου μπορείτε 

35
00:01:57,821 --> 00:02:01,142
να μάθετε περισσότερα, και όπου μπορείτε να κατεβάσετε τον κώδικα που το κάνει αυτό 

36
00:02:01,142 --> 00:02:03,080
και να παίξετε με αυτόν στον δικό σας υπολογιστή.

37
00:02:05,040 --> 00:02:07,824
Υπάρχουν πολλές παραλλαγές των νευρωνικών δικτύων, 

38
00:02:07,824 --> 00:02:12,683
και τα τελευταία χρόνια υπάρχει ένα είδος έκρηξης στην έρευνα προς αυτές τις παραλλαγές, 

39
00:02:12,683 --> 00:02:17,269
αλλά σε αυτά τα δύο εισαγωγικά βίντεο εσείς και εγώ θα εξετάσουμε μόνο την πιο απλή 

40
00:02:17,269 --> 00:02:19,180
μορφή χωρίς πρόσθετες λεπτομέρειες.

41
00:02:19,860 --> 00:02:22,545
Αυτό είναι ένα είδος απαραίτητης προϋπόθεσης για την κατανόηση 

42
00:02:22,545 --> 00:02:25,615
οποιασδήποτε από τις πιο ισχυρές σύγχρονες παραλλαγές, και πιστέψτε με, 

43
00:02:25,615 --> 00:02:28,600
εξακολουθεί να έχει αρκετή πολυπλοκότητα για εμάς να την κατανοήσουμε.

44
00:02:29,120 --> 00:02:32,706
Αλλά ακόμη και σε αυτή την απλούστερη μορφή μπορεί να μάθει να 

45
00:02:32,706 --> 00:02:36,520
αναγνωρίζει χειρόγραφα ψηφία, πράγμα πολύ καλό για έναν υπολογιστή.

46
00:02:37,480 --> 00:02:39,787
Και ταυτόχρονα θα δείτε πώς δεν ανταποκρίνεται σε 

47
00:02:39,787 --> 00:02:42,280
μερικές από τις ελπίδες που μπορεί να έχουμε γι' αυτό.

48
00:02:43,380 --> 00:02:47,416
Όπως υποδηλώνει το όνομα, τα νευρωνικά δίκτυα είναι εμπνευσμένα από τον εγκέφαλο, 

49
00:02:47,416 --> 00:02:48,500
αλλά ας το αναλύσουμε.

50
00:02:48,520 --> 00:02:51,660
Ποιοι είναι οι νευρώνες και με ποια έννοια συνδέονται μεταξύ τους;

51
00:02:52,500 --> 00:02:56,497
Αυτή τη στιγμή όταν λέω νευρώνας το μόνο που θέλω να σκέφτεστε είναι ένα 

52
00:02:56,497 --> 00:03:00,440
πράγμα που κρατάει έναν αριθμό, συγκεκριμένα έναν αριθμό μεταξύ 0 και 1.

53
00:03:00,680 --> 00:03:02,560
Πραγματικά δεν είναι κάτι περισσότερο από αυτό.

54
00:03:03,780 --> 00:03:08,935
Για παράδειγμα, το δίκτυο ξεκινά με μια δέσμη νευρώνων που αντιστοιχούν σε κάθε 

55
00:03:08,935 --> 00:03:14,220
ένα από τα 28x28 εικονοστοιχεία της εικόνας εισόδου, δηλαδή 784 νευρώνες συνολικά.

56
00:03:14,700 --> 00:03:17,959
Κάθε ένα από αυτά περιέχει έναν αριθμό που αντιπροσωπεύει την τιμή 

57
00:03:17,959 --> 00:03:20,634
της κλίμακας του γκρι του αντίστοιχου εικονοστοιχείου, 

58
00:03:20,634 --> 00:03:24,380
που κυμαίνεται από 0 για μαύρα εικονοστοιχεία έως 1 για λευκά εικονοστοιχεία.

59
00:03:25,300 --> 00:03:28,429
Αυτός ο αριθμός στο εσωτερικό του νευρώνα ονομάζεται ενεργοποίησή του, 

60
00:03:28,429 --> 00:03:31,338
και η εικόνα που μπορεί να έχετε στο μυαλό σας εδώ είναι ότι κάθε 

61
00:03:31,338 --> 00:03:34,160
νευρώνας φωτίζεται όταν η ενεργοποίησή του είναι υψηλός αριθμός.

62
00:03:36,720 --> 00:03:41,860
Έτσι, όλοι αυτοί οι 784 νευρώνες αποτελούν το πρώτο επίπεδο του δικτύου μας.

63
00:03:46,500 --> 00:03:49,089
Τώρα μεταβαίνοντας στο τελευταίο επίπεδο, αυτό έχει 10 νευρώνες, 

64
00:03:49,089 --> 00:03:51,360
καθένας από τους οποίους αντιπροσωπεύει ένα από τα ψηφία.

65
00:03:52,040 --> 00:03:55,432
Η ενεργοποίηση σε αυτούς τους νευρώνες, και πάλι κάποιος αριθμός που 

66
00:03:55,432 --> 00:03:58,874
κυμαίνεται μεταξύ 0 και 1, αντιπροσωπεύει το πόσο το σύστημα πιστεύει 

67
00:03:58,874 --> 00:04:02,120
ότι μια συγκεκριμένη εικόνα αντιστοιχεί σε ένα συγκεκριμένο ψηφίο.

68
00:04:03,040 --> 00:04:06,870
Υπάρχουν επίσης μερικά ενδιάμεσα στρώματα που ονομάζονται κρυφά στρώματα, 

69
00:04:06,870 --> 00:04:10,649
τα οποία προς το παρόν θα πρέπει να είναι απλώς ένα τεράστιο ερωτηματικό 

70
00:04:10,649 --> 00:04:13,600
για το πώς θα γίνει αυτή η διαδικασία αναγνώρισης ψηφίων.

71
00:04:14,260 --> 00:04:17,888
Σε αυτό το δίκτυο επέλεξα δύο κρυφά στρώματα, το καθένα με 16 νευρώνες, 

72
00:04:17,888 --> 00:04:20,560
και ομολογουμένως αυτή είναι κάπως αυθαίρετη επιλογή.

73
00:04:21,019 --> 00:04:24,527
Για να είμαι ειλικρινής, επέλεξα δύο στρώματα με βάση το πώς θέλω να κινητοποιήσω τη 

74
00:04:24,527 --> 00:04:28,200
δομή σε λίγο, και το 16, λοιπόν, ήταν απλά ένας ωραίος αριθμός για να χωρέσει στην οθόνη.

75
00:04:28,780 --> 00:04:32,340
Στην πράξη υπάρχει πολύς χώρος για πειραματισμό με μια συγκεκριμένη δομή εδώ.

76
00:04:33,020 --> 00:04:35,639
Με τον τρόπο λειτουργίας του δικτύου, οι ενεργοποιήσεις σε 

77
00:04:35,639 --> 00:04:38,480
ένα επίπεδο καθορίζουν τις ενεργοποιήσεις του επόμενου επιπέδου.

78
00:04:39,200 --> 00:04:42,257
Και φυσικά η καρδιά του δικτύου ως μηχανισμού επεξεργασίας 

79
00:04:42,257 --> 00:04:45,418
πληροφοριών έγκειται στο πώς ακριβώς αυτές οι ενεργοποιήσεις 

80
00:04:45,418 --> 00:04:48,580
από ένα επίπεδο προκαλούν ενεργοποιήσεις στο επόμενο επίπεδο.

81
00:04:49,140 --> 00:04:52,935
Εννοείται ότι είναι χαλαρά ανάλογο με το πώς στα βιολογικά δίκτυα νευρώνων, 

82
00:04:52,935 --> 00:04:57,180
ορισμένες ομάδες νευρώνων που πυροδοτούνται προκαλούν την πυροδότηση ορισμένων άλλων.

83
00:04:58,120 --> 00:05:01,372
Τώρα το δίκτυο που παρουσιάζω εδώ έχει ήδη εκπαιδευτεί να αναγνωρίζει ψηφία, 

84
00:05:01,372 --> 00:05:03,400
και επιτρέψτε μου να σας δείξω τι εννοώ με αυτό.

85
00:05:03,640 --> 00:05:06,095
Αυτό σημαίνει ότι αν τροφοδοτήσετε μια εικόνα, 

86
00:05:06,095 --> 00:05:10,535
φωτίζοντας και τους 784 νευρώνες του επιπέδου εισόδου ανάλογα με τη φωτεινότητα κάθε 

87
00:05:10,535 --> 00:05:14,714
εικονοστοιχείου της εικόνας, αυτό το μοτίβο ενεργοποιήσεων προκαλεί κάποιο πολύ 

88
00:05:14,714 --> 00:05:19,206
συγκεκριμένο μοτίβο στο επόμενο επίπεδο, το οποίο προκαλεί κάποιο μοτίβο στο επόμενο, 

89
00:05:19,206 --> 00:05:22,080
το οποίο τελικά δίνει κάποιο μοτίβο στο επίπεδο εξόδου.

90
00:05:22,560 --> 00:05:26,395
Και ο φωτεινότερος νευρώνας αυτού του επιπέδου εξόδου είναι η επιλογή του δικτύου, 

91
00:05:26,395 --> 00:05:29,400
για να το πω έτσι, για το ψηφίο που αντιπροσωπεύει αυτή η εικόνα.

92
00:05:32,560 --> 00:05:36,572
Και προτού αρχίσουμε τα μαθηματικά για το πώς το ένα στρώμα επηρεάζει το επόμενο, 

93
00:05:36,572 --> 00:05:40,143
ή πώς λειτουργεί η εκπαίδευση, ας μιλήσουμε για το γιατί είναι λογικό να 

94
00:05:40,143 --> 00:05:43,520
περιμένουμε από μια τέτοια πολυεπίπεδη δομή να συμπεριφέρεται έξυπνα.

95
00:05:44,060 --> 00:05:45,220
Τι περιμένουμε εδώ;

96
00:05:45,400 --> 00:05:47,600
Ποια είναι η καλύτερη ελπίδα για αυτά τα μεσαία στρώματα;

97
00:05:48,920 --> 00:05:53,520
Λοιπόν, όταν εσείς ή εγώ αναγνωρίζουμε ψηφία, συνθέτουμε διάφορα στοιχεία.

98
00:05:54,200 --> 00:05:56,820
Το 9 έχει μια θηλιά πάνω και μια γραμμή στα δεξιά.

99
00:05:57,380 --> 00:06:01,180
Ένα 8 έχει επίσης έναν βρόχο επάνω, αλλά συνδυάζεται με έναν άλλο βρόχο κάτω.

100
00:06:01,980 --> 00:06:06,820
Ένα 4 βασικά αναλύεται σε τρεις συγκεκριμένες γραμμές και άλλα τέτοια πράγματα.

101
00:06:07,600 --> 00:06:11,363
Τώρα, σε έναν τέλειο κόσμο, θα μπορούσαμε να ελπίζουμε ότι κάθε νευρώνας στο 

102
00:06:11,363 --> 00:06:14,687
προτελευταίο στρώμα αντιστοιχεί σε μία από αυτές τις υποσυνιστώσες, 

103
00:06:14,687 --> 00:06:18,598
ότι κάθε φορά που τροφοδοτείτε μια εικόνα με, ας πούμε, έναν βρόχο στην κορυφή, 

104
00:06:18,598 --> 00:06:22,753
όπως ένα 9 ή ένα 8, υπάρχει κάποιος συγκεκριμένος νευρώνας του οποίου η ενεργοποίηση 

105
00:06:22,753 --> 00:06:23,780
θα είναι κοντά στο 1.

106
00:06:24,500 --> 00:06:26,942
Και δεν εννοώ αυτόν τον συγκεκριμένο βρόχο από pixels, 

107
00:06:26,942 --> 00:06:30,227
η ελπίδα θα ήταν ότι οποιοδήποτε γενικά ελικοειδές μοτίβο προς την κορυφή 

108
00:06:30,227 --> 00:06:31,560
ενεργοποιεί αυτόν τον νευρώνα.

109
00:06:32,440 --> 00:06:36,214
Με αυτόν τον τρόπο, η μετάβαση από το τρίτο στρώμα στο τελευταίο απαιτεί 

110
00:06:36,214 --> 00:06:40,040
απλώς να μάθουμε ποιος συνδυασμός υποσυνιστωσών αντιστοιχεί σε ποια ψηφία.

111
00:06:41,000 --> 00:06:44,120
Βέβαια, αυτό απλώς επιδεινώνει το πρόβλημα, διότι πώς θα αναγνωρίζατε αυτά τα 

112
00:06:44,120 --> 00:06:47,640
υποσυστήματα ή ακόμη και πώς θα μαθαίνατε ποια θα έπρεπε να είναι τα σωστά υποσυστήματα;

113
00:06:48,060 --> 00:06:51,206
Και ακόμα δεν έχω μιλήσει για το πώς το ένα στρώμα επηρεάζει το επόμενο, 

114
00:06:51,206 --> 00:06:53,060
αλλά ακολουθήστε με σε αυτό για μια στιγμή.

115
00:06:53,680 --> 00:06:56,680
Η αναγνώριση ενός βρόχου μπορεί επίσης να αναλύεται σε υποπροβλήματα.

116
00:06:57,280 --> 00:06:59,814
Ένας λογικός τρόπος για να το κάνετε αυτό θα ήταν να 

117
00:06:59,814 --> 00:07:02,780
αναγνωρίσετε πρώτα τις διάφορες μικρές άκρες που το συνθέτουν.

118
00:07:03,780 --> 00:07:07,965
Παρομοίως, μια μεγάλη γραμμή, όπως αυτή που μπορεί να δείτε στα ψηφία 1 ή 4 ή 7, 

119
00:07:07,965 --> 00:07:10,496
είναι στην πραγματικότητα απλώς μια μεγάλη ακμή, 

120
00:07:10,496 --> 00:07:14,320
ή ίσως να τη σκέφτεστε ως ένα συγκεκριμένο μοτίβο πολλών μικρότερων ακμών.

121
00:07:15,140 --> 00:07:18,721
Έτσι, ίσως η ελπίδα μας είναι ότι κάθε νευρώνας στο δεύτερο 

122
00:07:18,721 --> 00:07:22,720
στρώμα του δικτύου αντιστοιχεί στις διάφορες σχετικές μικρές ακμές.

123
00:07:23,540 --> 00:07:27,421
Ίσως όταν μια εικόνα όπως αυτή έρχεται, ανάβει όλους τους νευρώνες που 

124
00:07:27,421 --> 00:07:30,700
σχετίζονται με περίπου 8 έως 10 συγκεκριμένες μικρές ακμές, 

125
00:07:30,700 --> 00:07:34,636
οι οποίες με τη σειρά τους ανάβουν τους νευρώνες που σχετίζονται με τον 

126
00:07:34,636 --> 00:07:38,681
άνω βρόχο και μια μακριά κάθετη γραμμή, και αυτοί ανάβουν τον νευρώνα που 

127
00:07:38,681 --> 00:07:39,720
σχετίζεται με το 9.

128
00:07:40,680 --> 00:07:44,557
Το αν αυτό είναι ή όχι αυτό που πραγματικά κάνει το τελικό μας δίκτυο είναι ένα άλλο 

129
00:07:44,557 --> 00:07:47,978
ερώτημα, στο οποίο θα επανέλθω μόλις δούμε πώς θα εκπαιδεύσουμε το δίκτυο, 

130
00:07:47,978 --> 00:07:50,213
αλλά αυτή είναι μια ελπίδα που μπορεί να έχουμε, 

131
00:07:50,213 --> 00:07:52,540
ένα είδος στόχου με την πολυεπίπεδη δομή όπως αυτή.

132
00:07:53,160 --> 00:07:56,751
Επιπλέον, μπορείτε να φανταστείτε πώς η δυνατότητα ανίχνευσης ακμών και μοτίβων με 

133
00:07:56,751 --> 00:08:00,300
αυτόν τον τρόπο θα ήταν πραγματικά χρήσιμη για άλλες εργασίες αναγνώρισης εικόνων.

134
00:08:00,880 --> 00:08:02,736
Και ακόμη και πέρα από την αναγνώριση εικόνων, 

135
00:08:02,736 --> 00:08:06,015
υπάρχουν όλα τα είδη έξυπνων πραγμάτων που μπορεί να θέλετε να κάνετε και τα οποία 

136
00:08:06,015 --> 00:08:07,280
αναλύονται σε επίπεδα αφαίρεσης.

137
00:08:08,040 --> 00:08:11,113
Η ανάλυση της ομιλίας, για παράδειγμα, περιλαμβάνει τη λήψη ακατέργαστου ήχου 

138
00:08:11,113 --> 00:08:14,069
και την επιλογή ξεχωριστών ήχων, οι οποίοι συνδυάζονται για να σχηματίσουν 

139
00:08:14,069 --> 00:08:16,828
ορισμένες συλλαβές, οι οποίες συνδυάζονται για να σχηματίσουν λέξεις, 

140
00:08:16,828 --> 00:08:20,060
οι οποίες συνδυάζονται για να σχηματίσουν φράσεις και πιο αφηρημένες σκέψεις κ.λπ.

141
00:08:21,100 --> 00:08:24,475
Αλλά για να επιστρέψουμε στο πώς λειτουργούν όλα αυτά στην πραγματικότητα, 

142
00:08:24,475 --> 00:08:27,130
φανταστείτε τον εαυτό σας τώρα να σχεδιάζει πώς ακριβώς οι 

143
00:08:27,130 --> 00:08:29,920
ενεργοποιήσεις σε ένα επίπεδο μπορεί να καθορίζουν το επόμενο.

144
00:08:30,860 --> 00:08:34,681
Ο στόχος είναι να υπάρχει κάποιος μηχανισμός που θα μπορούσε να 

145
00:08:34,681 --> 00:08:38,980
συνδυάζει εικονοστοιχεία σε ακμές, ή ακμές σε μοτίβα, ή μοτίβα σε ψηφία.

146
00:08:39,440 --> 00:08:42,657
Και για να εστιάσουμε σε ένα πολύ συγκεκριμένο παράδειγμα, 

147
00:08:42,657 --> 00:08:46,366
ας πούμε ότι η ελπίδα είναι ένας συγκεκριμένος νευρώνας στο δεύτερο 

148
00:08:46,366 --> 00:08:50,620
επίπεδο να αντιληφθεί αν η εικόνα έχει ή όχι μια άκρη σε αυτή την περιοχή εδώ.

149
00:08:51,440 --> 00:08:55,100
Το ερώτημα που τίθεται είναι ποιες παραμέτρους πρέπει να έχει το δίκτυο.

150
00:08:55,640 --> 00:08:59,530
Ποιους επιλογείς και ποια κουμπιά θα πρέπει να μπορείτε να ρυθμίσετε ώστε να είναι 

151
00:08:59,530 --> 00:09:03,139
αρκετά εκφραστικό για να καταγράψει αυτό το μοτίβο ή οποιοδήποτε άλλο μοτίβο 

152
00:09:03,139 --> 00:09:07,030
εικονοστοιχείων ή το μοτίβο ότι πολλές άκρες μπορούν να κάνουν έναν βρόχο και άλλα 

153
00:09:07,030 --> 00:09:07,780
τέτοια πράγματα;

154
00:09:08,720 --> 00:09:12,117
Λοιπόν, αυτό που θα κάνουμε είναι να αναθέσουμε ένα βάρος σε κάθε μία από 

155
00:09:12,117 --> 00:09:15,560
τις συνδέσεις μεταξύ του νευρώνα μας και των νευρώνων από το πρώτο επίπεδο.

156
00:09:16,320 --> 00:09:17,700
Αυτά τα βάρη είναι απλώς αριθμοί.

157
00:09:18,540 --> 00:09:22,095
Στη συνέχεια, πάρτε όλες αυτές τις ενεργοποιήσεις από το πρώτο επίπεδο 

158
00:09:22,095 --> 00:09:25,500
και υπολογίστε το σταθμισμένο άθροισμά τους σύμφωνα με αυτά τα βάρη.

159
00:09:27,700 --> 00:09:31,116
Θεωρώ ότι είναι χρήσιμο να σκεφτούμε ότι αυτά τα βάρη είναι οργανωμένα σε 

160
00:09:31,116 --> 00:09:35,178
ένα μικρό πλέγμα, και θα χρησιμοποιήσω πράσινα εικονοστοιχεία για να δείξω θετικά βάρη, 

161
00:09:35,178 --> 00:09:37,717
και κόκκινα εικονοστοιχεία για να δείξω αρνητικά βάρη, 

162
00:09:37,717 --> 00:09:41,780
όπου η φωτεινότητα του εικονοστοιχείου είναι μια χαλαρή απεικόνιση της τιμής του βάρους.

163
00:09:42,780 --> 00:09:46,396
Τώρα, αν κάναμε τα βάρη που σχετίζονται με σχεδόν όλα τα εικονοστοιχεία μηδενικά, 

164
00:09:46,396 --> 00:09:49,439
εκτός από κάποια θετικά βάρη σε αυτή την περιοχή που μας ενδιαφέρει, 

165
00:09:49,439 --> 00:09:53,277
τότε η λήψη του σταθμισμένου αθροίσματος όλων των τιμών των εικονοστοιχείων ισοδυναμεί 

166
00:09:53,277 --> 00:09:56,981
στην πραγματικότητα με την πρόσθεση των τιμών των εικονοστοιχείων μόνο στην περιοχή 

167
00:09:56,981 --> 00:09:57,820
που μας ενδιαφέρει.

168
00:09:59,140 --> 00:10:01,868
Και αν θέλατε πραγματικά να εντοπίσετε αν υπάρχει μια άκρη εδώ, 

169
00:10:01,868 --> 00:10:05,619
αυτό που θα μπορούσατε να κάνετε είναι να έχετε κάποια αρνητικά βάρη που σχετίζονται με 

170
00:10:05,619 --> 00:10:06,600
τα γύρω εικονοστοιχεία.

171
00:10:07,480 --> 00:10:10,152
Τότε το άθροισμα είναι μεγαλύτερο όταν τα μεσαία εικονοστοιχεία 

172
00:10:10,152 --> 00:10:12,700
είναι φωτεινά αλλά τα γύρω εικονοστοιχεία είναι πιο σκοτεινά.

173
00:10:14,260 --> 00:10:16,782
Όταν υπολογίζετε ένα σταθμισμένο άθροισμα όπως αυτό, 

174
00:10:16,782 --> 00:10:19,875
μπορεί να προκύψει οποιοσδήποτε αριθμός, αλλά για αυτό το δίκτυο 

175
00:10:19,875 --> 00:10:23,540
αυτό που θέλουμε είναι οι ενεργοποιήσεις να έχουν κάποια τιμή μεταξύ 0 και 1.

176
00:10:24,120 --> 00:10:26,807
Έτσι, ένα συνηθισμένο πράγμα που κάνουμε είναι να διοχετεύουμε 

177
00:10:26,807 --> 00:10:29,495
αυτό το σταθμισμένο άθροισμα σε κάποια συνάρτηση που συμπιέζει 

178
00:10:29,495 --> 00:10:32,140
τη γραμμή των πραγματικών αριθμών στην περιοχή μεταξύ 0 και 1.

179
00:10:32,460 --> 00:10:35,841
Και μια κοινή συνάρτηση που το κάνει αυτό ονομάζεται σιγμοειδής συνάρτηση, 

180
00:10:35,841 --> 00:10:37,420
επίσης γνωστή ως λογιστική καμπύλη.

181
00:10:38,000 --> 00:10:41,440
Βασικά, οι πολύ αρνητικές είσοδοι καταλήγουν κοντά στο 0, 

182
00:10:41,440 --> 00:10:46,600
οι θετικές είσοδοι καταλήγουν κοντά στο 1 και αυξάνονται σταθερά γύρω από την είσοδο 0.

183
00:10:49,120 --> 00:10:52,678
Έτσι, η ενεργοποίηση του νευρώνα εδώ είναι ουσιαστικά ένα 

184
00:10:52,678 --> 00:10:56,360
μέτρο του πόσο θετικό είναι το σχετικό σταθμισμένο άθροισμα.

185
00:10:57,540 --> 00:10:59,710
Αλλά ίσως δεν είναι ότι θέλετε ο νευρώνας να ανάβει 

186
00:10:59,710 --> 00:11:01,880
όταν το σταθμισμένο άθροισμα είναι μεγαλύτερο από 0.

187
00:11:02,280 --> 00:11:06,360
Ίσως θέλετε να είναι ενεργή μόνο όταν το άθροισμα είναι μεγαλύτερο από 10.

188
00:11:06,840 --> 00:11:10,260
Δηλαδή, θέλετε κάποια μεροληψία για να είναι ανενεργή.

189
00:11:11,380 --> 00:11:15,450
Αυτό που θα κάνουμε τότε είναι να προσθέσουμε κάποιον άλλο αριθμό, όπως το αρνητικό 10, 

190
00:11:15,450 --> 00:11:19,104
σε αυτό το σταθμισμένο άθροισμα πριν το περάσουμε από τη συνάρτηση σιγμοειδούς 

191
00:11:19,104 --> 00:11:19,660
εξομάλυνσης.

192
00:11:20,580 --> 00:11:22,440
Αυτός ο πρόσθετος αριθμός ονομάζεται προκατάληψη.

193
00:11:23,460 --> 00:11:27,453
Έτσι, τα βάρη σας λένε ποιο μοτίβο εικονοστοιχείων λαμβάνει αυτός ο νευρώνας 

194
00:11:27,453 --> 00:11:31,290
στο δεύτερο επίπεδο και η προκατάληψη σας λέει πόσο υψηλό πρέπει να είναι 

195
00:11:31,290 --> 00:11:35,180
το σταθμισμένο άθροισμα πριν ο νευρώνας αρχίσει να ενεργοποιείται με νόημα.

196
00:11:36,120 --> 00:11:37,680
Και αυτός είναι μόνο ένας νευρώνας.

197
00:11:38,280 --> 00:11:42,457
Κάθε άλλος νευρώνας σε αυτό το στρώμα θα συνδεθεί και με τους 784 

198
00:11:42,457 --> 00:11:46,445
νευρώνες εικονοστοιχείων από το πρώτο στρώμα, και κάθε μία από 

199
00:11:46,445 --> 00:11:50,940
αυτές τις 784 συνδέσεις έχει το δικό της βάρος που σχετίζεται με αυτήν.

200
00:11:51,600 --> 00:11:54,492
Επίσης, το καθένα έχει κάποια προκατάληψη, κάποιον άλλο αριθμό που 

201
00:11:54,492 --> 00:11:57,600
προσθέτετε στο σταθμισμένο άθροισμα πριν το συμπιέσετε με το σιγμοειδές.

202
00:11:58,110 --> 00:11:59,540
Και αυτά είναι πολλά που πρέπει να σκεφτούμε!

203
00:11:59,960 --> 00:12:05,975
Με αυτό το κρυφό στρώμα των 16 νευρώνων, είναι συνολικά 784 φορές 16 βάρη, 

204
00:12:05,975 --> 00:12:07,980
μαζί με 16 προκαταλήψεις.

205
00:12:08,840 --> 00:12:11,940
Και όλα αυτά είναι μόνο οι συνδέσεις από το πρώτο στρώμα στο δεύτερο.

206
00:12:12,520 --> 00:12:14,909
Οι συνδέσεις μεταξύ των άλλων στρωμάτων έχουν επίσης μια 

207
00:12:14,909 --> 00:12:17,340
σειρά από βάρη και προκαταλήψεις που σχετίζονται με αυτές.

208
00:12:18,340 --> 00:12:23,800
Συνολικά, αυτό το δίκτυο έχει σχεδόν ακριβώς 13.000 συνολικά βάρη και προκαταλήψεις.

209
00:12:23,800 --> 00:12:26,858
13.000 κουμπιά και επιλογείς που μπορούν να ρυθμιστούν και να γυρίσουν 

210
00:12:26,858 --> 00:12:29,960
για να κάνουν αυτό το δίκτυο να συμπεριφέρεται με διαφορετικούς τρόπους.

211
00:12:31,040 --> 00:12:34,558
Έτσι, όταν μιλάμε για μάθηση, αυτό στο οποίο αναφερόμαστε είναι να βάλουμε 

212
00:12:34,558 --> 00:12:38,780
τον υπολογιστή να βρει μια έγκυρη ρύθμιση για όλους αυτούς τους πολλούς πολλούς αριθμούς, 

213
00:12:38,780 --> 00:12:41,360
έτσι ώστε να λύσει πραγματικά το συγκεκριμένο πρόβλημα.

214
00:12:42,620 --> 00:12:46,052
Ένα πείραμα σκέψης που είναι ταυτόχρονα διασκεδαστικό και κάπως τρομακτικό 

215
00:12:46,052 --> 00:12:49,439
είναι να φανταστείτε να κάθεστε και να ρυθμίζετε όλα αυτά τα βάρη και τις 

216
00:12:49,439 --> 00:12:52,781
προκαταλήψεις με το χέρι, ρυθμίζοντας σκόπιμα τους αριθμούς έτσι ώστε το 

217
00:12:52,781 --> 00:12:56,580
δεύτερο στρώμα να εντοπίζει τις ακμές, το τρίτο στρώμα να εντοπίζει τα μοτίβα κ.λπ.

218
00:12:56,980 --> 00:13:00,410
Προσωπικά το βρίσκω αυτό ικανοποιητικό, αντί να αντιμετωπίζω το δίκτυο ως 

219
00:13:00,410 --> 00:13:04,490
ένα εντελώς μαύρο κουτί, διότι όταν το δίκτυο δεν αποδίδει με τον τρόπο που περιμένετε, 

220
00:13:04,490 --> 00:13:08,060
αν έχετε δημιουργήσει μια μικρή σχέση με το τι σημαίνουν στην πραγματικότητα 

221
00:13:08,060 --> 00:13:11,259
αυτά τα βάρη και οι προκαταλήψεις, έχετε ένα σημείο εκκίνησης για να 

222
00:13:11,259 --> 00:13:14,180
πειραματιστείτε με το πώς να αλλάξετε τη δομή για να βελτιωθεί.

223
00:13:14,960 --> 00:13:18,118
Ή όταν το δίκτυο λειτουργεί, αλλά όχι για τους λόγους που θα περιμένατε, 

224
00:13:18,118 --> 00:13:21,752
η διερεύνηση του τι κάνουν τα βάρη και οι προκαταλήψεις είναι ένας καλός τρόπος για 

225
00:13:21,752 --> 00:13:25,170
να αμφισβητήσετε τις υποθέσεις σας και να εκθέσετε πραγματικά όλο τον χώρο των 

226
00:13:25,170 --> 00:13:25,820
πιθανών λύσεων.

227
00:13:26,840 --> 00:13:30,190
Παρεμπιπτόντως, η πραγματική λειτουργία εδώ είναι λίγο δυσκίνητη για να την καταγράψετε, 

228
00:13:30,190 --> 00:13:30,680
δεν νομίζετε;

229
00:13:32,500 --> 00:13:34,934
Επιτρέψτε μου λοιπόν να σας δείξω έναν πιο συμβολικά 

230
00:13:34,934 --> 00:13:37,140
συμπαγή τρόπο αναπαράστασης αυτών των συνδέσεων.

231
00:13:37,660 --> 00:13:40,520
Έτσι θα το βλέπατε αν επιλέγατε να διαβάσετε περισσότερα για τα νευρωνικά δίκτυα.

232
00:13:41,380 --> 00:13:47,164
Οργανώστε όλες τις ενεργοποιήσεις από ένα στρώμα σε μια στήλη, 

233
00:13:47,164 --> 00:13:52,490
καθώς ένας πίνακας αντιστοιχεί στις συνδέσεις μεταξύ ενός 

234
00:13:52,490 --> 00:13:58,000
στρώματος και ενός συγκεκριμένου νευρώνα στο επόμενο στρώμα.

235
00:13:58,540 --> 00:14:02,355
Αυτό σημαίνει ότι το σταθμισμένο άθροισμα των ενεργοποιήσεων στο πρώτο 

236
00:14:02,355 --> 00:14:06,171
επίπεδο σύμφωνα με αυτά τα βάρη αντιστοιχεί σε έναν από τους όρους του 

237
00:14:06,171 --> 00:14:09,880
διανυσματικού γινομένου του πίνακα όλων όσων έχουμε στα αριστερά εδώ.

238
00:14:14,000 --> 00:14:17,626
Παρεμπιπτόντως, ένα μεγάλο μέρος της μηχανικής μάθησης εξαρτάται από την καλή 

239
00:14:17,626 --> 00:14:21,253
κατανόηση της γραμμικής άλγεβρας, οπότε όσοι από εσάς θέλετε μια ωραία οπτική 

240
00:14:21,253 --> 00:14:24,740
κατανόηση των πινάκων και τι σημαίνει πολλαπλασιασμός διανυσμάτων πινάκων, 

241
00:14:24,740 --> 00:14:28,600
ρίξτε μια ματιά στη σειρά που έκανα για τη γραμμική άλγεβρα, ειδικά στο κεφάλαιο 3.

242
00:14:29,240 --> 00:14:32,323
Επιστρέφοντας στην έκφρασή μας, αντί να μιλάμε για την προσθήκη της 

243
00:14:32,323 --> 00:14:34,908
προκατάληψης σε κάθε μία από αυτές τις τιμές ανεξάρτητα, 

244
00:14:34,908 --> 00:14:38,354
την αναπαριστούμε οργανώνοντας όλες αυτές τις προκαταλήψεις σε ένα διάνυσμα 

245
00:14:38,354 --> 00:14:42,300
και προσθέτοντας ολόκληρο το διάνυσμα στο προηγούμενο διανυσματικό γινόμενο του πίνακα.

246
00:14:43,280 --> 00:14:47,084
Στη συνέχεια, ως τελικό βήμα, θα τυλίξω ένα σιγμοειδές γύρω από το εξωτερικό εδώ, 

247
00:14:47,084 --> 00:14:50,796
και αυτό που υποτίθεται ότι αντιπροσωπεύει είναι ότι θα εφαρμόσετε τη σιγμοειδή 

248
00:14:50,796 --> 00:14:54,740
συνάρτηση σε κάθε συγκεκριμένη συνιστώσα του διανύσματος που προκύπτει στο εσωτερικό.

249
00:14:55,940 --> 00:14:59,972
Έτσι, μόλις γράψετε αυτόν τον πίνακα βαρών και αυτά τα διανύσματα ως τα δικά τους 

250
00:14:59,972 --> 00:15:03,955
σύμβολα, μπορείτε να επικοινωνήσετε την πλήρη μετάβαση των ενεργοποιήσεων από το 

251
00:15:03,955 --> 00:15:07,988
ένα επίπεδο στο επόμενο σε μια εξαιρετικά σφιχτή και τακτοποιημένη μικρή έκφραση, 

252
00:15:07,988 --> 00:15:11,971
και αυτό κάνει τον σχετικό κώδικα τόσο πολύ απλούστερο όσο και πολύ πιο γρήγορο, 

253
00:15:11,971 --> 00:15:15,660
δεδομένου ότι πολλές βιβλιοθήκες βελτιστοποιούν τον πολλαπλασιασμό πινάκων.

254
00:15:17,820 --> 00:15:21,460
Θυμάστε που νωρίτερα είπα ότι αυτοί οι νευρώνες είναι απλά πράγματα που κρατούν αριθμούς;

255
00:15:22,220 --> 00:15:27,593
Φυσικά, οι συγκεκριμένοι αριθμοί που κρατούν εξαρτώνται από την εικόνα που τροφοδοτείτε, 

256
00:15:27,593 --> 00:15:31,698
οπότε είναι πιο ακριβές να σκεφτείτε κάθε νευρώνα ως μια συνάρτηση, 

257
00:15:31,698 --> 00:15:37,011
η οποία λαμβάνει τις εξόδους όλων των νευρώνων του προηγούμενου επιπέδου και δίνει έναν 

258
00:15:37,011 --> 00:15:38,340
αριθμό μεταξύ 0 και 1.

259
00:15:39,200 --> 00:15:43,043
Στην πραγματικότητα, ολόκληρο το δίκτυο είναι απλώς μια συνάρτηση, 

260
00:15:43,043 --> 00:15:47,060
η οποία δέχεται 784 αριθμούς ως είσοδο και δίνει 10 αριθμούς ως έξοδο.

261
00:15:47,560 --> 00:15:49,886
Πρόκειται για μια παράλογα περίπλοκη συνάρτηση, 

262
00:15:49,886 --> 00:15:53,377
που περιλαμβάνει 13.000 παραμέτρους με τη μορφή αυτών των βαρών και των 

263
00:15:53,377 --> 00:15:57,013
προκαταλήψεων που εντοπίζουν ορισμένα μοτίβα, και η οποία περιλαμβάνει την 

264
00:15:57,013 --> 00:16:00,697
επανάληψη πολλών διανυσματικών γινομένων πινάκων και τη σιγμοειδή συνάρτηση 

265
00:16:00,697 --> 00:16:04,333
τετραγωνισμού, αλλά είναι μια συνάρτηση, και κατά κάποιο τρόπο είναι κάπως 

266
00:16:04,333 --> 00:16:06,660
καθησυχαστικό το γεγονός ότι φαίνεται περίπλοκη.

267
00:16:07,340 --> 00:16:09,706
Θέλω να πω, αν ήταν πιο απλό, τι ελπίδα θα είχαμε ότι θα 

268
00:16:09,706 --> 00:16:12,280
μπορούσε να αντιμετωπίσει την πρόκληση της αναγνώρισης ψηφίων;

269
00:16:13,340 --> 00:16:14,700
Και πώς αντιμετωπίζει αυτή την πρόκληση;

270
00:16:15,080 --> 00:16:17,178
Πώς αυτό το δίκτυο μαθαίνει τα κατάλληλα βάρη και 

271
00:16:17,178 --> 00:16:19,360
τις προκαταλήψεις μόνο με την εξέταση των δεδομένων;

272
00:16:20,140 --> 00:16:23,375
Αυτό θα δείξω στο επόμενο βίντεο, και θα αναλύσω λίγο περισσότερο 

273
00:16:23,375 --> 00:16:26,120
τι πραγματικά κάνει το συγκεκριμένο δίκτυο που βλέπουμε.

274
00:16:27,580 --> 00:16:30,604
Τώρα είναι το σημείο που υποθέτω ότι θα έπρεπε να πω εγγραφείτε για να μείνετε 

275
00:16:30,604 --> 00:16:33,208
ειδοποιημένοι για το πότε βγαίνουν βίντεο ή οποιαδήποτε νέα βίντεο, 

276
00:16:33,208 --> 00:16:36,501
αλλά ρεαλιστικά οι περισσότεροι από εσάς δεν λαμβάνετε πραγματικά ειδοποιήσεις από το 

277
00:16:36,501 --> 00:16:37,420
YouTube, έτσι δεν είναι;

278
00:16:38,020 --> 00:16:40,061
Ίσως πιο ειλικρινά θα έπρεπε να πω εγγραφείτε, 

279
00:16:40,061 --> 00:16:43,362
ώστε τα νευρωνικά δίκτυα που διέπουν τον αλγόριθμο συστάσεων του YouTube να 

280
00:16:43,362 --> 00:16:46,620
είναι προετοιμασμένα να πιστέψουν ότι θέλετε να δείτε περιεχόμενο από αυτό 

281
00:16:46,620 --> 00:16:47,880
το κανάλι να σας προτείνεται.

282
00:16:48,560 --> 00:16:49,940
Εν πάση περιπτώσει μείνετε αναρτημένοι για περισσότερα.

283
00:16:50,760 --> 00:16:53,500
Ευχαριστούμε πολύ όλους όσους υποστηρίζουν αυτά τα βίντεο στο Patreon.

284
00:16:54,000 --> 00:16:56,704
Το καλοκαίρι άργησα λίγο να προχωρήσω με τη σειρά probability, 

285
00:16:56,704 --> 00:16:59,409
αλλά μετά από αυτό το έργο θα ξαναρχίσω να ασχολούμαι με αυτό, 

286
00:16:59,409 --> 00:17:01,900
οπότε οι προστάτες μπορούν να περιμένουν ενημερώσεις εκεί.

287
00:17:03,600 --> 00:17:05,670
Για να κλείσω τα πράγματα εδώ, έχω μαζί μου τη Leisha Lee, 

288
00:17:05,670 --> 00:17:08,267
η οποία έκανε τη διδακτορική της διατριβή στη θεωρητική πλευρά της βαθιάς 

289
00:17:08,267 --> 00:17:11,040
μάθησης και η οποία εργάζεται σήμερα σε μια εταιρεία επιχειρηματικών κεφαλαίων 

290
00:17:11,040 --> 00:17:13,953
που ονομάζεται Amplify Partners, η οποία ευγενικά παρείχε μέρος της χρηματοδότησης 

291
00:17:13,953 --> 00:17:14,619
για αυτό το βίντεο.

292
00:17:15,460 --> 00:17:17,236
Έτσι, Leisha, ένα πράγμα που νομίζω ότι πρέπει να 

293
00:17:17,236 --> 00:17:19,119
αναφέρουμε γρήγορα είναι αυτή η σιγμοειδής συνάρτηση.

294
00:17:19,700 --> 00:17:23,023
Όπως καταλαβαίνω, τα πρώιμα δίκτυα το χρησιμοποιούν αυτό για να συμπιέσουν το 

295
00:17:23,023 --> 00:17:26,048
σχετικό σταθμισμένο άθροισμα σε αυτό το διάστημα μεταξύ μηδέν και ένα, 

296
00:17:26,048 --> 00:17:29,840
με κίνητρο αυτή τη βιολογική αναλογία των νευρώνων που είναι είτε ανενεργοί είτε ενεργοί.

297
00:17:30,280 --> 00:17:30,300
Ακριβώς.

298
00:17:30,560 --> 00:17:34,040
Αλλά σχετικά λίγα σύγχρονα δίκτυα χρησιμοποιούν πλέον σιγμοειδές.

299
00:17:34,320 --> 00:17:34,320
Ναι.

300
00:17:34,440 --> 00:17:35,540
Είναι κάπως παλιάς σχολής, σωστά;

301
00:17:35,760 --> 00:17:38,980
Ναι, ή μάλλον το relu φαίνεται να εκπαιδεύεται πολύ πιο εύκολα.

302
00:17:39,400 --> 00:17:42,340
Και το relu σημαίνει διορθωμένη γραμμική μονάδα;

303
00:17:42,680 --> 00:17:47,443
Ναι, είναι αυτό το είδος συνάρτησης όπου απλά παίρνετε ένα μέγιστο του μηδενός 

304
00:17:47,443 --> 00:17:52,026
και του a όπου το a δίνεται από αυτό που εξηγούσατε στο βίντεο και αυτό που 

305
00:17:52,026 --> 00:17:56,669
νομίζω ότι ήταν ένα είδος κινήτρου, ήταν εν μέρει από μια βιολογική αναλογία 

306
00:17:56,669 --> 00:18:01,252
με το πώς οι νευρώνες είτε ενεργοποιούνται είτε όχι και έτσι αν περάσει ένα 

307
00:18:01,252 --> 00:18:04,267
ορισμένο κατώφλι θα είναι η συνάρτηση ταυτότητας, 

308
00:18:04,267 --> 00:18:08,789
αλλά αν δεν το κάνει τότε απλά δεν θα ενεργοποιηθεί, οπότε θα είναι μηδέν, 

309
00:18:08,789 --> 00:18:10,840
οπότε είναι ένα είδος απλοποίησης.

310
00:18:11,160 --> 00:18:15,462
Η χρήση σιγμοειδών δεν βοήθησε στην εκπαίδευση ή ήταν πολύ δύσκολο να 

311
00:18:15,462 --> 00:18:19,887
εκπαιδευτεί σε κάποιο σημείο και οι άνθρωποι απλά δοκίμασαν το relu και 

312
00:18:19,887 --> 00:18:24,620
έτυχε να λειτουργήσει πολύ καλά για αυτά τα απίστευτα βαθιά νευρωνικά δίκτυα.

313
00:18:25,100 --> 00:18:25,640
Εντάξει, σας ευχαριστώ Alicia.

