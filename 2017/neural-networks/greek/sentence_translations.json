[
 {
  "input": "This is a 3.",
  "translatedText": "Αυτό είναι ένα 3.",
  "model": "DeepL",
  "from_community_srt": "Αυτό είναι το τρία.",
  "n_reviews": 0,
  "start": 4.22,
  "end": 5.4
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "Είναι πρόχειρα γραμμένο και απεικονίζεται σε εξαιρετικά χαμηλή ανάλυση 28x28 pixels, αλλά ο εγκέφαλός σας δεν έχει πρόβλημα να το αναγνωρίσει ως 3.",
  "model": "DeepL",
  "from_community_srt": "Είναι τσαπατσούλικα γραμμένο και στην υπερβολικά χαμηλή ανάλυση των 28x28 pixels. Το μυαλό σας όμως δεν έχει κανένα πρόβλημα να δει ότι είναι τρία και θέλω να αυτό το εκτιμήσετε για μια στιγμή:",
  "n_reviews": 0,
  "start": 6.06,
  "end": 13.72
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "Και θέλω να αφιερώσετε ένα λεπτό για να εκτιμήσετε πόσο τρελό είναι που οι εγκέφαλοι μπορούν να το κάνουν αυτό τόσο αβίαστα.",
  "model": "DeepL",
  "from_community_srt": "Πόσο τρελό είναι που οι εγκέφαλοι μπορούν να το κάνουν τόσο αβίαστα; Θέλω να πω,",
  "n_reviews": 0,
  "start": 14.34,
  "end": 18.96
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "Θέλω να πω, αυτό, αυτό και αυτό είναι επίσης αναγνωρίσιμα ως 3s, παρόλο που οι συγκεκριμένες τιμές κάθε pixel είναι πολύ διαφορετικές από τη μία εικόνα στην άλλη.",
  "model": "DeepL",
  "from_community_srt": "αυτό, αυτό κι αυτό τα βλέπουμε ως τρία, παρόλο που η συγκεκριμένη τιμή κάθε pixel διαφέρει κατά πολύ από εικόνα σε εικόνα.",
  "n_reviews": 0,
  "start": 19.7,
  "end": 28.32
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "Τα συγκεκριμένα φωτοευαίσθητα κύτταρα στο μάτι σας που πυροδοτούνται όταν βλέπετε αυτό το 3 είναι πολύ διαφορετικά από αυτά που πυροδοτούνται όταν βλέπετε αυτό το 3.",
  "model": "DeepL",
  "from_community_srt": "Τα εξειδικευμένα φωτοευαίσθητα κύτταρα στο μάτι σας που πυροδοτούνται όταν βλέπουν αυτό το τρία είναι πολύ διαφορετικά από αυτά που πυροδοτούνται όταν βλέπουν αυτό το τρία.",
  "n_reviews": 0,
  "start": 28.9,
  "end": 36.94
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "Αλλά κάτι στον τρελά έξυπνο οπτικό φλοιό σας διαχωρίζει αυτές τις εικόνες ως αντιπροσωπευτικές της ίδιας ιδέας, ενώ ταυτόχρονα αναγνωρίζει άλλες εικόνες ως δικές τους ξεχωριστές ιδέες.",
  "model": "DeepL",
  "from_community_srt": "Αλλά κάτι σε αυτόν τον τρελά έξυπνο φλοιό σας, τα ξεμπερδεύει λες και αντιπροσωπεύουν την ίδια ιδέα, ενώ την ίδια στιγμή αναγνωρίζει άλλες εικόνες ως άλλες ξεχωριστές ιδέες.",
  "n_reviews": 0,
  "start": 37.52,
  "end": 48.26
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "Αλλά αν σας έλεγα, ε, κάτσε κάτω και γράψε μου ένα πρόγραμμα που θα παίρνει ένα πλέγμα 28x28 εικονοστοιχείων όπως αυτό και θα βγάζει έναν απλό αριθμό μεταξύ 0 και 10, λέγοντάς σας τι νομίζει ότι είναι το ψηφίο, τότε η εργασία γίνεται από κωμικοτραγικά ασήμαντη σε τρομακτικά δύσκολη.",
  "model": "DeepL",
  "from_community_srt": "Αν σας έλεγα όμως να καθίσετε κάτω και να μου γράψετε ένα πρόγραμμα που δέχεται ως είσοδο ένα πλέγμα 28x28 pixels σαν αυτό, και βγάζει ως έξοδο έναν αριθμό από το 0 ως το 10 λέγοντάς σας ποιο ψηφίο νομίζει ότι είναι... Λοιπόν, το πρόβλημα μετατρέπεται από κωμικά απλό σε αποθαρρυντικά δύσκολο.",
  "n_reviews": 0,
  "start": 49.22,
  "end": 66.18
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "Αν δεν έχετε ζήσει κάτω από ένα βράχο, νομίζω ότι δεν χρειάζεται να αιτιολογήσω τη σημασία και τη σπουδαιότητα της μηχανικής μάθησης και των νευρωνικών δικτύων για το παρόν και το μέλλον.",
  "model": "DeepL",
  "from_community_srt": "Εκτός αν ζείτε στα βουνά, νομίζω ότι δεν χρειάζεται να σας πείσω για τη συνάφεια και τη σημασία του machine learning και των νευρωνικών δικτύων,",
  "n_reviews": 0,
  "start": 67.16,
  "end": 74.64
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "Αλλά αυτό που θέλω να κάνω εδώ είναι να σας δείξω τι είναι στην πραγματικότητα ένα νευρωνικό δίκτυο, χωρίς να υποθέσουμε ότι δεν υπάρχει υπόβαθρο, και να σας βοηθήσω να απεικονίσετε τι κάνει, όχι ως λέξη, αλλά ως ένα κομμάτι των μαθηματικών.",
  "model": "DeepL",
  "from_community_srt": "τώρα και στο μέλλον, αλλά αυτό που θέλω να κάνω εδώ, είναι να σας δείξω τι είναι πραγματικά ένα νευρωνικό δίκτυο. Υποθέτοντας ότι δεν έχετε ασχοληθεί καθόλου με το θέμα, και για να σας βοηθήσω να οπτικοποιήσετε τι κάνει, όχι σαν λέξη της μόδας,",
  "n_reviews": 0,
  "start": 75.12,
  "end": 84.46
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "Η ελπίδα μου είναι να φύγετε νιώθοντας ότι η ίδια η δομή έχει κίνητρα, και να νιώσετε ότι ξέρετε τι σημαίνει όταν διαβάζετε ή ακούτε για ένα νευρωνικό δίκτυο που παραθέτει το απόσπασμα \"μάθηση\".",
  "model": "DeepL",
  "from_community_srt": "αλλά σαν μαθηματικό εργαλείο, Η ελπίδα μου είναι ότι τελειώνοντας το βίντεο θα νιώθετε τα κίνητρα που μας οδηγούν σε αυτήν τη δομή, και θα καταλαβαίνετε τι σημαίνει το \"μαθαίνει\" όταν διαβάζετε ή ακούτε για ένα νευρωνικό δίκτυο \"μάθησης\".",
  "n_reviews": 0,
  "start": 85.02,
  "end": 94.34
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "Αυτό το βίντεο θα είναι αφιερωμένο στη δομική συνιστώσα αυτού, και το επόμενο θα ασχοληθεί με τη μάθηση.",
  "model": "DeepL",
  "from_community_srt": "Αυτό το βίντεο θα είναι αφιερωμένο στο κομμάτι της δομής, ενώ το επόμενο θα ασχοληθεί με το κομμάτι της \"μάθησης\".",
  "n_reviews": 0,
  "start": 95.36,
  "end": 100.26
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "Αυτό που πρόκειται να κάνουμε είναι να δημιουργήσουμε ένα νευρωνικό δίκτυο που μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία.",
  "model": "DeepL",
  "from_community_srt": "Αυτό που θα κάνουμε είναι να φτιάξουμε ένα νευρωνικό δίκτυο που θα μάθει να αναγνωρίζει χειρόγραφα ψηφία.",
  "n_reviews": 0,
  "start": 100.96,
  "end": 106.04
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "Αυτό είναι ένα κάπως κλασικό παράδειγμα για την εισαγωγή του θέματος, και είμαι ευτυχής που θα παραμείνω με το status quo εδώ, επειδή στο τέλος των δύο βίντεο θέλω να σας υποδείξω μερικές καλές πηγές όπου μπορείτε να μάθετε περισσότερα, και όπου μπορείτε να κατεβάσετε τον κώδικα που το κάνει αυτό και να παίξετε με αυτόν στον δικό σας υπολογιστή.",
  "model": "DeepL",
  "from_community_srt": "Αυτό είναι ένα σχετικά κλασικό παράδειγμα για εισαγωγή στο θέμα και χαίρομαι που ακολουθώ την παράδοση εδώ, γιατί στο τέλος των δύο βίντεο, θέλω να σας παραπέμψω σε καναδυό καλές πηγές όπου μπορείτε να μάθετε περισσότερα και να κατεβάσετε τον κώδικα που κάνει αυτήν τη δουλειά",
  "n_reviews": 0,
  "start": 109.36,
  "end": 123.08
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "Υπάρχουν πολλές παραλλαγές των νευρωνικών δικτύων, και τα τελευταία χρόνια υπάρχει ένα είδος έκρηξης στην έρευνα προς αυτές τις παραλλαγές, αλλά σε αυτά τα δύο εισαγωγικά βίντεο εσείς και εγώ θα εξετάσουμε μόνο την πιο απλή μορφή χωρίς πρόσθετες λεπτομέρειες.",
  "model": "DeepL",
  "from_community_srt": "και να \"παίξετε\" με αυτόν στον υπολογιστή σας. Υπάρχουν πάρα πολλές διαφορετικές εκδοχές των νευρωνικών δικτύων και τα τελευταία χρόνια, έχει υπάρξει μία, ας πούμε, έκρηξη στην έρευνα αυτών των εκδοχών. Όμως σε αυτά τα δύο εισαγωγικά βίντεο, εσείς κι εγώ θα εξετάσουμε την πολύ απλή μορφή, χωρίς τα πρόσθετα στολίδια.",
  "n_reviews": 0,
  "start": 125.04,
  "end": 139.18
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "Αυτό είναι ένα είδος απαραίτητης προϋπόθεσης για την κατανόηση οποιασδήποτε από τις πιο ισχυρές σύγχρονες παραλλαγές, και πιστέψτε με, εξακολουθεί να έχει αρκετή πολυπλοκότητα για εμάς να την κατανοήσουμε.",
  "model": "DeepL",
  "from_community_srt": "Αυτή η μορφή είναι κάπως απαραίτητη προϋπόθεση στο να καταλάβετε οποιαδήποτε από τις ισχυρότερες εκδοχές και πιστέψτε με, είναι και από μόνη της αρκετά περίπλοκη.",
  "n_reviews": 0,
  "start": 139.86,
  "end": 148.6
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "Αλλά ακόμη και σε αυτή την απλούστερη μορφή μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία, πράγμα πολύ καλό για έναν υπολογιστή.",
  "model": "DeepL",
  "from_community_srt": "Ακόμη όμως και αυτή η απλούστατη μορφή, μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία, κάτι πολύ εντυπωσιακό για έναν υπολογιστή.",
  "n_reviews": 0,
  "start": 149.12,
  "end": 156.52
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "Και ταυτόχρονα θα δείτε πώς δεν ανταποκρίνεται σε μερικές από τις ελπίδες που μπορεί να έχουμε γι' αυτό.",
  "model": "DeepL",
  "from_community_srt": "Ταυτόχρονα, θα δείτε πώς, ίσως να μας απογοητεύσει σε κάποια πράγματα που μπορεί να περιμένουμε από αυτήν.",
  "n_reviews": 0,
  "start": 157.48,
  "end": 162.28
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "Όπως υποδηλώνει το όνομα, τα νευρωνικά δίκτυα είναι εμπνευσμένα από τον εγκέφαλο, αλλά ας το αναλύσουμε.",
  "model": "DeepL",
  "from_community_srt": "Όπως δείχνει και το όνομα, τα νευρωνικά δίκτυα έχουν εμπνευστεί από τους εγκεφάλους. Ας το αναλύσουμε όμως αυτό.",
  "n_reviews": 0,
  "start": 163.38,
  "end": 168.5
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "Ποιοι είναι οι νευρώνες και με ποια έννοια συνδέονται μεταξύ τους;",
  "model": "DeepL",
  "from_community_srt": "Τι είναι οι νευρώνες, και τι εννοούμε όταν λέμε ότι \"συνδέονται\" μεταξύ τους; Τώρα,",
  "n_reviews": 0,
  "start": 168.52,
  "end": 171.66
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "Αυτή τη στιγμή όταν λέω νευρώνας το μόνο που θέλω να σκέφτεστε είναι ένα πράγμα που κρατάει έναν αριθμό, συγκεκριμένα έναν αριθμό μεταξύ 0 και 1.",
  "model": "DeepL",
  "from_community_srt": "όταν λέω \"νευρώνας\", το μόνο που θέλω να σκέφτεστε είναι ένα πράγμα που αποθηκεύει έναν αριθμό. Πιο συγκεκριμένα, έναν αριθμό μεταξύ του 0 και του 1.",
  "n_reviews": 0,
  "start": 172.5,
  "end": 180.44
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "Πραγματικά δεν είναι κάτι περισσότερο από αυτό.",
  "model": "DeepL",
  "from_community_srt": "Πραγματικά δεν είναι κάτι παραπάνω από αυτό.",
  "n_reviews": 0,
  "start": 180.68,
  "end": 182.56
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "Για παράδειγμα, το δίκτυο ξεκινά με μια δέσμη νευρώνων που αντιστοιχούν σε κάθε ένα από τα 28x28 εικονοστοιχεία της εικόνας εισόδου, δηλαδή 784 νευρώνες συνολικά.",
  "model": "DeepL",
  "from_community_srt": "Πχ. το δίκτυο ξεκινάει από μία ομάδα νευρώνων που αντιστοιχούν σε καθένα από τα 28x28 pixels της εικόνας εισόδου, δηλαδή είναι 784 νευρώνες συνολικά,",
  "n_reviews": 0,
  "start": 183.78,
  "end": 194.22
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "Κάθε ένα από αυτά περιέχει έναν αριθμό που αντιπροσωπεύει την τιμή της κλίμακας του γκρι του αντίστοιχου εικονοστοιχείου, που κυμαίνεται από 0 για μαύρα εικονοστοιχεία έως 1 για λευκά εικονοστοιχεία.",
  "model": "DeepL",
  "from_community_srt": "ο καθένας εκ των οποίων κρατάει έναν αριθμό που αντιπροσωπεύει την τιμή του pixel στην κλίμακα του γκρι, με εύρος από 0 για τα μαύρα pixel μέχρι και 1 για τα άσπρα.",
  "n_reviews": 0,
  "start": 194.7,
  "end": 204.38
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "Αυτός ο αριθμός στο εσωτερικό του νευρώνα ονομάζεται ενεργοποίησή του, και η εικόνα που μπορεί να έχετε στο μυαλό σας εδώ είναι ότι κάθε νευρώνας φωτίζεται όταν η ενεργοποίησή του είναι υψηλός αριθμός.",
  "model": "DeepL",
  "from_community_srt": "Αυτόν τον αριθμό τον λέμε ενεργοποίηση του νευρώνα, και η εικόνα που ίσως σας έρχεται στο μυαλό είναι ότι κάθε νευρώνας \"ανάβει\" όταν η ενεργοποίησή του είναι ένας μεγάλος αριθμός.",
  "n_reviews": 0,
  "start": 205.3,
  "end": 214.16
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "Έτσι, όλοι αυτοί οι 784 νευρώνες αποτελούν το πρώτο επίπεδο του δικτύου μας.",
  "model": "DeepL",
  "from_community_srt": "Άρα όλοι αυτοί οι 784 νευρώνες συνθέτουν το πρώτο στρώμα του δικτύου μας.",
  "n_reviews": 0,
  "start": 216.72,
  "end": 221.86
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "Τώρα μεταβαίνοντας στο τελευταίο επίπεδο, αυτό έχει 10 νευρώνες, καθένας από τους οποίους αντιπροσωπεύει ένα από τα ψηφία.",
  "model": "DeepL",
  "from_community_srt": "Τώρα ας δούμε κατευθείαν το τελευταίο στρώμα του δικτύου, που έχει 10 νευρώνες, και ο καθένας αντιπροσωπεύει ένα από τα ψηφία.",
  "n_reviews": 0,
  "start": 226.5,
  "end": 231.36
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "Η ενεργοποίηση σε αυτούς τους νευρώνες, και πάλι κάποιος αριθμός που κυμαίνεται μεταξύ 0 και 1, αντιπροσωπεύει το πόσο το σύστημα πιστεύει ότι μια συγκεκριμένη εικόνα αντιστοιχεί σε ένα συγκεκριμένο ψηφίο.",
  "model": "DeepL",
  "from_community_srt": "Η ενεργοποίηση σε αυτούς τους νευρώνες, που είναι και πάλι ένας αριθμός ανάμεσα στο 0 και το 1, αντιπροσωπεύει το κατά πόσο το σύστημα πιστεύει ότι η δοθείσα εικόνα, αντιστοιχεί σε αυτό το ψηφίο.",
  "n_reviews": 0,
  "start": 232.04,
  "end": 242.12
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "Υπάρχουν επίσης μερικά ενδιάμεσα στρώματα που ονομάζονται κρυφά στρώματα, τα οποία προς το παρόν θα πρέπει να είναι απλώς ένα τεράστιο ερωτηματικό για το πώς θα γίνει αυτή η διαδικασία αναγνώρισης ψηφίων.",
  "model": "DeepL",
  "from_community_srt": "Υπάρχουν επίσης καναδυό στρώματα ανάμεσα που ονομάζονται \"κρυφά στρώματα\", στα οποία για την ώρα, ας βάλουμε απλά ένα τεράστιο ερωτηματικό για το πώς στο καλό λειτουργούν ώστε να επιτύχει η διαδικασία αναγνώρισης των ψηφίων.",
  "n_reviews": 0,
  "start": 243.04,
  "end": 253.6
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "Σε αυτό το δίκτυο επέλεξα δύο κρυφά στρώματα, το καθένα με 16 νευρώνες, και ομολογουμένως αυτή είναι κάπως αυθαίρετη επιλογή.",
  "model": "DeepL",
  "from_community_srt": "Σε αυτό το δίκτυο επέλεξα να έχω δύο κρυφά στρώματα, το καθένα από 16 νευρώνες, και ομολογουμένως είναι μία λίγο αυθαίρετη επιλογή.",
  "n_reviews": 0,
  "start": 254.26,
  "end": 260.56
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "Για να είμαι ειλικρινής, επέλεξα δύο στρώματα με βάση το πώς θέλω να κινητοποιήσω τη δομή σε λίγο, και το 16, λοιπόν, ήταν απλά ένας ωραίος αριθμός για να χωρέσει στην οθόνη.",
  "model": "DeepL",
  "from_community_srt": "Για να είμαι ειλικρινής, διάλεξα να έχω δύο κρυφά στρώματα, βασιζόμενος στη δομή που θέλω να υπάρχει, και 16 νευρώνες... Ε, το 16 ήταν απλά ένας ωραίος αριθμός ώστε να χωράνε οι νευρώνες στην οθόνη.",
  "n_reviews": 0,
  "start": 261.02,
  "end": 268.2
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "Στην πράξη υπάρχει πολύς χώρος για πειραματισμό με μια συγκεκριμένη δομή εδώ.",
  "model": "DeepL",
  "from_community_srt": "Υπάρχει πολύς χώρος για να πειραματιστείτε με τη δομή εδώ.",
  "n_reviews": 0,
  "start": 268.78,
  "end": 272.34
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "Με τον τρόπο λειτουργίας του δικτύου, οι ενεργοποιήσεις σε ένα επίπεδο καθορίζουν τις ενεργοποιήσεις του επόμενου επιπέδου.",
  "model": "DeepL",
  "from_community_srt": "Ο τρόπος με τον οποίο το δίκτυο χειρίζεται τις ενεργοποιήσεις σε ένα στρώμα, καθορίζει τις ενεργοποιήσεις στο επόμενο.",
  "n_reviews": 0,
  "start": 273.02,
  "end": 278.48
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "Και φυσικά η καρδιά του δικτύου ως μηχανισμού επεξεργασίας πληροφοριών έγκειται στο πώς ακριβώς αυτές οι ενεργοποιήσεις από ένα επίπεδο προκαλούν ενεργοποιήσεις στο επόμενο επίπεδο.",
  "model": "DeepL",
  "from_community_srt": "Και φυσικά, η καρδιά του δικτύου ως ένας μηχανισμός επεξεργασίας πληροφοριών, είναι το πώς ακριβώς αυτές οι ενεργοποιήσεις σε ένα στρώμα, καθορίζουν τις ενεργοποιήσεις στο επόμενο.",
  "n_reviews": 0,
  "start": 279.2,
  "end": 288.58
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "Εννοείται ότι είναι χαλαρά ανάλογο με το πώς στα βιολογικά δίκτυα νευρώνων, ορισμένες ομάδες νευρώνων που πυροδοτούνται προκαλούν την πυροδότηση ορισμένων άλλων.",
  "model": "DeepL",
  "from_community_srt": "Έχει φτιαχτεί ώστε να είναι κάπως ανάλογο με το πώς στα βιολογικά νευρωνικά δίκτυα, κάποιες ομάδες νευρώνων πυροδοτούν κάποιες άλλες ομάδες με τη σειρά τους.",
  "n_reviews": 0,
  "start": 289.14,
  "end": 297.18
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "Τώρα το δίκτυο που παρουσιάζω εδώ έχει ήδη εκπαιδευτεί να αναγνωρίζει ψηφία, και επιτρέψτε μου να σας δείξω τι εννοώ με αυτό.",
  "model": "DeepL",
  "from_community_srt": "Τώρα, το δίκτυο που δείχνω εδώ, έχει ήδη εκπαιδευτεί στο να αναγνωρίζει ψηφία, και ας σας δείξω τι εννοώ με αυτό.",
  "n_reviews": 0,
  "start": 298.12,
  "end": 303.4
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "Αυτό σημαίνει ότι αν τροφοδοτήσετε μια εικόνα, φωτίζοντας και τους 784 νευρώνες του επιπέδου εισόδου ανάλογα με τη φωτεινότητα κάθε εικονοστοιχείου της εικόνας, αυτό το μοτίβο ενεργοποιήσεων προκαλεί κάποιο πολύ συγκεκριμένο μοτίβο στο επόμενο επίπεδο, το οποίο προκαλεί κάποιο μοτίβο στο επόμενο, το οποίο τελικά δίνει κάποιο μοτίβο στο επίπεδο εξόδου.",
  "model": "DeepL",
  "from_community_srt": "Σημαίνει ότι αν του δώσω μια εικόνα, ενεργοποιώντας έτσι και τους 784 νευρώνες του στρώματος εισόδου, ανάλογα με τη φωτεινότητα κάθε pixel, αυτό το μοτίβο ενεργοποιήσεων, θα προκαλέσει κάποιο άλλο συγκεκριμένο μοτίβο στο επόμενο στρώμα, που ακολούθως θα προκαλέσει κάποιο μοτίβο στο επόμενο στρώμα,",
  "n_reviews": 0,
  "start": 303.64,
  "end": 322.08
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "Και ο φωτεινότερος νευρώνας αυτού του επιπέδου εξόδου είναι η επιλογή του δικτύου, για να το πω έτσι, για το ψηφίο που αντιπροσωπεύει αυτή η εικόνα.",
  "model": "DeepL",
  "from_community_srt": "που τελικά θα δώσει ένα μοτίβο στο στρώμα εξόδου, και ο φωτεινότερος νευρώνας του στρώματος εξόδου δείχνει, ας πούμε, το ψηφίο που το δίκτυο πιστεύει ότι αντιπροσωπεύει η εικόνα.",
  "n_reviews": 0,
  "start": 322.56,
  "end": 329.4
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "Και προτού αρχίσουμε τα μαθηματικά για το πώς το ένα στρώμα επηρεάζει το επόμενο, ή πώς λειτουργεί η εκπαίδευση, ας μιλήσουμε για το γιατί είναι λογικό να περιμένουμε από μια τέτοια πολυεπίπεδη δομή να συμπεριφέρεται έξυπνα.",
  "model": "DeepL",
  "from_community_srt": "Και πριν μπούμε στα μαθηματικά για το πώς το ένα στρώμα επηρεάζει το άλλο ή το πώς λειτουργεί η εκπαίδευση του δικτύου, ας μιλήσουμε απλά για το γιατί μας φαίνεται λογικό μία δομή με στρώματα να συμπεριφέρεται έξυπνα.",
  "n_reviews": 0,
  "start": 332.56,
  "end": 343.52
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "Τι περιμένουμε εδώ;",
  "model": "DeepL",
  "from_community_srt": "Τι περιμένουμε εδώ;",
  "n_reviews": 0,
  "start": 344.06,
  "end": 345.22
 },
 {
  "input": "What is the best hope for what those middle layers might be doing?",
  "translatedText": "Ποια είναι η καλύτερη ελπίδα για αυτά τα μεσαία στρώματα;",
  "model": "DeepL",
  "from_community_srt": "Ποια είναι η καλύτερη ελπίδα μας για το τι κάνουν αυτά τα μεσαία στρώματα; Λοιπόν,",
  "n_reviews": 0,
  "start": 345.4,
  "end": 347.6
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "Λοιπόν, όταν εσείς ή εγώ αναγνωρίζουμε ψηφία, συνθέτουμε διάφορα στοιχεία.",
  "model": "DeepL",
  "from_community_srt": "όταν εσείς ή εγώ αναγνωρίζουμε ψηφία, ενώνουμε μαζί διάφορα κομμάτια.",
  "n_reviews": 0,
  "start": 348.92,
  "end": 353.52
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "Το 9 έχει μια θηλιά πάνω και μια γραμμή στα δεξιά.",
  "model": "DeepL",
  "from_community_srt": "Ένα 9 έχει έναν κύκλο πάνω και μια γραμμή στα δεξιά, ένα 8 έχει επίσης έναν κύκλο πάνω,",
  "n_reviews": 0,
  "start": 354.2,
  "end": 356.82
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "Ένα 8 έχει επίσης έναν βρόχο επάνω, αλλά συνδυάζεται με έναν άλλο βρόχο κάτω.",
  "model": "DeepL",
  "from_community_srt": "αλλά και έναν κύκλο κάτω.",
  "n_reviews": 0,
  "start": 357.38,
  "end": 361.18
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "Ένα 4 βασικά αναλύεται σε τρεις συγκεκριμένες γραμμές και άλλα τέτοια πράγματα.",
  "model": "DeepL",
  "from_community_srt": "Ένα 4 βασικά σπάει σε τρεις συγκεκριμένες γραμμές, και τα λοιπά.",
  "n_reviews": 0,
  "start": 361.98,
  "end": 366.82
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "Τώρα, σε έναν τέλειο κόσμο, θα μπορούσαμε να ελπίζουμε ότι κάθε νευρώνας στο προτελευταίο στρώμα αντιστοιχεί σε μία από αυτές τις υποσυνιστώσες, ότι κάθε φορά που τροφοδοτείτε μια εικόνα με, ας πούμε, έναν βρόχο στην κορυφή, όπως ένα 9 ή ένα 8, υπάρχει κάποιος συγκεκριμένος νευρώνας του οποίου η ενεργοποίηση θα είναι κοντά στο 1.",
  "model": "DeepL",
  "from_community_srt": "Τώρα, σε έναν ιδανικό κόσμο, μπορεί να ελπίζαμε ότι κάθε νευρώνας του προτελευταίου στρώματος, αντιστοιχεί σε καθένα από αυτά τα \"κομμάτια\". Ότι κάθε φορά που δίνουμε μια εικόνα, ας πούμε με έναν κύκλο πάνω, όπως στο 9 ή στο 8, υπάρχει ένας συγκεκριμένος νευρώνας, του οποίου η ενεργοποίηση θα είναι κοντά στο 1.",
  "n_reviews": 0,
  "start": 367.6,
  "end": 383.78
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "Και δεν εννοώ αυτόν τον συγκεκριμένο βρόχο από pixels, η ελπίδα θα ήταν ότι οποιοδήποτε γενικά ελικοειδές μοτίβο προς την κορυφή ενεργοποιεί αυτόν τον νευρώνα.",
  "model": "DeepL",
  "from_community_srt": "Και δεν εννοώ μόνο αυτόν τον συγκεκριμένο κύκλο από pixels, η ελπίδα μας είναι ότι κάθε γενικότερο κυκλόμορφο μοτίβο στο πάνω μέρος, θα ενεργοποιούσε αυτόν τον νευρώνα.",
  "n_reviews": 0,
  "start": 384.5,
  "end": 391.56
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "Με αυτόν τον τρόπο, η μετάβαση από το τρίτο στρώμα στο τελευταίο απαιτεί απλώς να μάθουμε ποιος συνδυασμός υποσυνιστωσών αντιστοιχεί σε ποια ψηφία.",
  "model": "DeepL",
  "from_community_srt": "Έτσι, η μετάβαση από το τρίτο στο τελευταίο στρώμα, απαιτεί μόνο το να μάθουμε ποιος συνδυασμός κομματιών αντιστοιχεί σε ποια ψηφία.",
  "n_reviews": 0,
  "start": 392.44,
  "end": 400.04
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "Βέβαια, αυτό απλώς επιδεινώνει το πρόβλημα, διότι πώς θα αναγνωρίζατε αυτά τα υποσυστήματα ή ακόμη και πώς θα μαθαίνατε ποια θα έπρεπε να είναι τα σωστά υποσυστήματα;",
  "model": "DeepL",
  "from_community_srt": "Φυσικά, αυτό απλά μεταφέρει το πρόβλημα παρακάτω και δεν το λύνει. Γιατί πώς θα αναγνωρίζατε αυτά τα κομμάτια ή ακόμη και θα μαθαίνατε ποια είναι τα σωστά κομμάτια,",
  "n_reviews": 0,
  "start": 401.0,
  "end": 407.64
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "Και ακόμα δεν έχω μιλήσει για το πώς το ένα στρώμα επηρεάζει το επόμενο, αλλά ακολουθήστε με σε αυτό για μια στιγμή.",
  "model": "DeepL",
  "from_community_srt": "και ακόμη δεν έχω καν μιλήσει για το πώς ένα στρώμα επηρεάζει το επόμενο, αλλά ελάτε εδώ μαζί μου για μια στιγμή.",
  "n_reviews": 0,
  "start": 408.06,
  "end": 413.06
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "Η αναγνώριση ενός βρόχου μπορεί επίσης να αναλύεται σε υποπροβλήματα.",
  "model": "DeepL",
  "from_community_srt": "Η αναγνώριση ενός κύκλου, μπορεί κι αυτή να διασπαστεί σε υποπροβλήματα.",
  "n_reviews": 0,
  "start": 413.68,
  "end": 416.68
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "Ένας λογικός τρόπος για να το κάνετε αυτό θα ήταν να αναγνωρίσετε πρώτα τις διάφορες μικρές άκρες που το συνθέτουν.",
  "model": "DeepL",
  "from_community_srt": "Ένας λογικός τρόπος να γίνει αυτό θα ήταν να αναγνωρίσουμε πρώτα τις διάφορες μικρές ακμές που τον συνθέτουν.",
  "n_reviews": 0,
  "start": 417.28,
  "end": 422.78
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "Παρομοίως, μια μεγάλη γραμμή, όπως αυτή που μπορεί να δείτε στα ψηφία 1 ή 4 ή 7, είναι στην πραγματικότητα απλώς μια μεγάλη ακμή, ή ίσως να τη σκέφτεστε ως ένα συγκεκριμένο μοτίβο πολλών μικρότερων ακμών.",
  "model": "DeepL",
  "from_community_srt": "Παρομοίως, μία μακριά γραμμή, όπως αυτή στα ψηφία 1, 4 ή 7. Λοιπόν, αυτή είναι απλά μια μακριά ακμή, ή μπορείτε και αυτήν να τη σκεφτείτε σαν μια ακολουθία πολλών μικρότερων ακμών.",
  "n_reviews": 0,
  "start": 423.78,
  "end": 434.32
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "Έτσι, ίσως η ελπίδα μας είναι ότι κάθε νευρώνας στο δεύτερο στρώμα του δικτύου αντιστοιχεί στις διάφορες σχετικές μικρές ακμές.",
  "model": "DeepL",
  "from_community_srt": "Άρα ίσως να ελπίζουμε ότι κάθε νευρώνας στο δεύτερο στρώμα του δικτύου, αντιστοιχεί στις διάφορες μικρές ακμές.",
  "n_reviews": 0,
  "start": 435.14,
  "end": 442.72
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "Ίσως όταν μια εικόνα όπως αυτή έρχεται, ανάβει όλους τους νευρώνες που σχετίζονται με περίπου 8 έως 10 συγκεκριμένες μικρές ακμές, οι οποίες με τη σειρά τους ανάβουν τους νευρώνες που σχετίζονται με τον άνω βρόχο και μια μακριά κάθετη γραμμή, και αυτοί ανάβουν τον νευρώνα που σχετίζεται με το 9.",
  "model": "DeepL",
  "from_community_srt": "Ίσως όταν μπαίνει μια εικόνα σαν κι αυτήν, να ενεργοποιούνται όλοι οι νευρώνες που αντιστοιχούν σε περίπου 8 με 10 συγκεκριμένες μικρές ακμές, που με τη σειρά τους ενεργοποιούν τους νευρώνες για τον πάνω κύκλο και για μία μακριά κάθετη γραμμή, και μετά αυτοί ενεργοποιούν τον νευρώνα που αντιστοιχεί στο 9.",
  "n_reviews": 0,
  "start": 443.54,
  "end": 459.72
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "Το αν αυτό είναι ή όχι αυτό που πραγματικά κάνει το τελικό μας δίκτυο είναι ένα άλλο ερώτημα, στο οποίο θα επανέλθω μόλις δούμε πώς θα εκπαιδεύσουμε το δίκτυο, αλλά αυτή είναι μια ελπίδα που μπορεί να έχουμε, ένα είδος στόχου με την πολυεπίπεδη δομή όπως αυτή.",
  "model": "DeepL",
  "from_community_srt": "Το αν είναι ή όχι αυτή η πραγματική λειτουργία του τελικού μας δικτύου, είναι μια άλλη ερώτηση, στην οποία θα αναφερθώ όταν δούμε το πώς γίνεται η εκπαίδευση του δικτύου. Ίσως όμως αυτή να είναι μία ελπίδα μας. Κάτι σαν στόχος για το πώς θα είναι η δομή των στρωμάτων.",
  "n_reviews": 0,
  "start": 460.68,
  "end": 472.54
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "Επιπλέον, μπορείτε να φανταστείτε πώς η δυνατότητα ανίχνευσης ακμών και μοτίβων με αυτόν τον τρόπο θα ήταν πραγματικά χρήσιμη για άλλες εργασίες αναγνώρισης εικόνων.",
  "model": "DeepL",
  "from_community_srt": "Επιπλέον, σκεφτείτε το πώς η δυνατότητα ανίχνευσης ακμών και μοτίβων σαν αυτά θα ήταν πολύ χρήσιμη σε άλλα προβλήματα αναγνώρισης εικόνας.",
  "n_reviews": 0,
  "start": 473.16,
  "end": 480.3
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "Και ακόμη και πέρα από την αναγνώριση εικόνων, υπάρχουν όλα τα είδη έξυπνων πραγμάτων που μπορεί να θέλετε να κάνετε και τα οποία αναλύονται σε επίπεδα αφαίρεσης.",
  "model": "DeepL",
  "from_community_srt": "Και πέρα από την αναγνώριση εικόνας, υπάρχουν τόσα έξυπνα πράγματα που ίσως θέλατε να κάνετε, που μπορούν να σπάσουν σε τέτοια αφηρημένα στρώματα.",
  "n_reviews": 0,
  "start": 480.88,
  "end": 487.28
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "Η ανάλυση της ομιλίας, για παράδειγμα, περιλαμβάνει τη λήψη ακατέργαστου ήχου και την επιλογή ξεχωριστών ήχων, οι οποίοι συνδυάζονται για να σχηματίσουν ορισμένες συλλαβές, οι οποίες συνδυάζονται για να σχηματίσουν λέξεις, οι οποίες συνδυάζονται για να σχηματίσουν φράσεις και πιο αφηρημένες σκέψεις κ.λπ.",
  "model": "DeepL",
  "from_community_srt": "Η αναγνώριση ομιλίας πχ, περιλαμβάνει την ανάλυση σκέτου ήχου σε ξεχωριστούς μικρούς ήχους που συνδυάζονται για τη δημιουργία συλλαβών, που συνδυάζονται για τον σχηματισμό λέξεων, που συνδυάζονται για να φτιάξουν φράσεις και πιο αφηρημένες σκέψεις κλπ.",
  "n_reviews": 0,
  "start": 488.04,
  "end": 500.06
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "Αλλά για να επιστρέψουμε στο πώς λειτουργούν όλα αυτά στην πραγματικότητα, φανταστείτε τον εαυτό σας τώρα να σχεδιάζει πώς ακριβώς οι ενεργοποιήσεις σε ένα επίπεδο μπορεί να καθορίζουν το επόμενο.",
  "model": "DeepL",
  "from_community_srt": "Ας γυρίσουμε όμως στο πώς δουλεύει καθετί από αυτά. Φανταστείτε τον εαυτό σας αυτήν τη στιγμή να σχεδιάζει το πώς ακριβώς οι ενεργοποιήσεις σε ένα στρώμα μπορεί να καθορίζουν τις ενεργοποιήσεις του επόμενου.",
  "n_reviews": 0,
  "start": 501.1,
  "end": 509.92
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "Ο στόχος είναι να υπάρχει κάποιος μηχανισμός που θα μπορούσε να συνδυάζει εικονοστοιχεία σε ακμές, ή ακμές σε μοτίβα, ή μοτίβα σε ψηφία.",
  "model": "DeepL",
  "from_community_srt": "Ο στόχος είναι να έχουμε κάποιον μηχανισμό που πιθανώς να συνδυάζει pixels σε ακμές, ή ακμές σε μοτίβα,",
  "n_reviews": 0,
  "start": 510.86,
  "end": 518.98
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "Και για να εστιάσουμε σε ένα πολύ συγκεκριμένο παράδειγμα, ας πούμε ότι η ελπίδα είναι ένας συγκεκριμένος νευρώνας στο δεύτερο επίπεδο να αντιληφθεί αν η εικόνα έχει ή όχι μια άκρη σε αυτή την περιοχή εδώ.",
  "model": "DeepL",
  "from_community_srt": "ή μοτίβα σε ψηφία και για να επικεντρωθούμε σε ένα παράδειγμα: Έστω ότι ελπίζουμε πως ένας συγκεκριμένος νευρώνας του δεύτερου στρώματος μπορεί να ανιχνεύσει αν η εικόνα έχει ή όχι, μία ακμή σε αυτήν την περιοχή εδώ.",
  "n_reviews": 0,
  "start": 519.44,
  "end": 530.62
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "Το ερώτημα που τίθεται είναι ποιες παραμέτρους πρέπει να έχει το δίκτυο.",
  "model": "DeepL",
  "from_community_srt": "Η ερώτηση που καλούμαστε να απαντήσουμε,",
  "n_reviews": 0,
  "start": 531.44,
  "end": 535.1
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "Ποιους επιλογείς και ποια κουμπιά θα πρέπει να μπορείτε να ρυθμίσετε ώστε να είναι αρκετά εκφραστικό για να καταγράψει αυτό το μοτίβο ή οποιοδήποτε άλλο μοτίβο εικονοστοιχείων ή το μοτίβο ότι πολλές άκρες μπορούν να κάνουν έναν βρόχο και άλλα τέτοια πράγματα;",
  "model": "DeepL",
  "from_community_srt": "είναι το τι παραμέτρους θα έπρεπε να έχει το δίκτυο, τι κουμπιά και μοχλούς θα έπρεπε να πειράξετε, ώστε να μπορεί ενδεχομένως να εντοπίσει αυτό το μοτίβο ή ένα άλλο οποιοδήποτε μοτίβο από pixels ή το μοτίβο όπου μερικές ακμές συνθέτουν έναν κύκλο και άλλα τέτοια.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 547.78
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "Λοιπόν, αυτό που θα κάνουμε είναι να αναθέσουμε ένα βάρος σε κάθε μία από τις συνδέσεις μεταξύ του νευρώνα μας και των νευρώνων από το πρώτο επίπεδο.",
  "model": "DeepL",
  "from_community_srt": "Λοιπόν, αυτό που θα κάνουμε είναι να ορίσουμε ένα βάρος σε καθεμία σύνδεση μεταξύ του νευρώνα και των νευρώνων του προηγούμενου στρώματος.",
  "n_reviews": 0,
  "start": 548.72,
  "end": 555.56
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "Αυτά τα βάρη είναι απλώς αριθμοί.",
  "model": "DeepL",
  "from_community_srt": "Αυτά τα βάρη είναι απλά αριθμοί.",
  "n_reviews": 0,
  "start": 556.32,
  "end": 557.7
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "Στη συνέχεια, πάρτε όλες αυτές τις ενεργοποιήσεις από το πρώτο επίπεδο και υπολογίστε το σταθμισμένο άθροισμά τους σύμφωνα με αυτά τα βάρη.",
  "model": "DeepL",
  "from_community_srt": "Μετά, θα πάρουμε όλες αυτές τις ενεργοποιήσεις του πρώτου στρώματος και θα υπολογίσουμε το σταθμικό άθροισμα σύμφωνα με αυτά τα βάρη.",
  "n_reviews": 0,
  "start": 558.54,
  "end": 565.5
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "Θεωρώ ότι είναι χρήσιμο να σκεφτούμε ότι αυτά τα βάρη είναι οργανωμένα σε ένα μικρό πλέγμα, και θα χρησιμοποιήσω πράσινα εικονοστοιχεία για να δείξω θετικά βάρη, και κόκκινα εικονοστοιχεία για να δείξω αρνητικά βάρη, όπου η φωτεινότητα του εικονοστοιχείου είναι μια χαλαρή απεικόνιση της τιμής του βάρους.",
  "model": "DeepL",
  "from_community_srt": "Προσωπικά με βοηθάει πολύ να σκέφτομαι τα βάρη ως ένα μικρό ξεχωριστό πλέγμα, και εδώ χρησιμοποιώ πράσινα pixels για να δείξω τα θετικά βάρη και κόκκινα για να δείξω τα αρνητικά, όπου η φωτεινότητα κάποιου pixel δείχνει περίπου την τιμή του βάρους.",
  "n_reviews": 0,
  "start": 567.7,
  "end": 581.78
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "Τώρα, αν κάναμε τα βάρη που σχετίζονται με σχεδόν όλα τα εικονοστοιχεία μηδενικά, εκτός από κάποια θετικά βάρη σε αυτή την περιοχή που μας ενδιαφέρει, τότε η λήψη του σταθμισμένου αθροίσματος όλων των τιμών των εικονοστοιχείων ισοδυναμεί στην πραγματικότητα με την πρόσθεση των τιμών των εικονοστοιχείων μόνο στην περιοχή που μας ενδιαφέρει.",
  "model": "DeepL",
  "from_community_srt": "Τώρα, αν μηδενίζαμε τα βάρη σχεδόν όλων των pixels, εκτός από κάποια θετικά βάρη σε αυτήν την περιοχή που μας ενδιαφέρει, τότε παίρνοντας το σταθμικό άθροισμα όλων των τιμών των pixel, ισοδυναμεί τελικά με το να προσθέσουμε μόνο τις τιμές των pixel της περιοχής που μας ενδιαφέρει.",
  "n_reviews": 0,
  "start": 582.78,
  "end": 597.82
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "Και αν θέλατε πραγματικά να εντοπίσετε αν υπάρχει μια άκρη εδώ, αυτό που θα μπορούσατε να κάνετε είναι να έχετε κάποια αρνητικά βάρη που σχετίζονται με τα γύρω εικονοστοιχεία.",
  "model": "DeepL",
  "from_community_srt": "Και, αν πραγματικά θέλατε να δείτε αν υπάρχει ακμή εδώ,",
  "n_reviews": 0,
  "start": 599.14,
  "end": 606.6
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "Τότε το άθροισμα είναι μεγαλύτερο όταν τα μεσαία εικονοστοιχεία είναι φωτεινά αλλά τα γύρω εικονοστοιχεία είναι πιο σκοτεινά.",
  "model": "DeepL",
  "from_community_srt": "ίσως να βάζατε κάποια αρνητικά βάρη στα pixel γύρω από την περιοχή, ώστε το άθροισμα να είναι μεγαλύτερο μόνο αν τα μεσαία pixel είναι φωτεινά, αλλά τα τριγύρω σκοτεινά.",
  "n_reviews": 0,
  "start": 607.48,
  "end": 612.7
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "Όταν υπολογίζετε ένα σταθμισμένο άθροισμα όπως αυτό, μπορεί να προκύψει οποιοσδήποτε αριθμός, αλλά για αυτό το δίκτυο αυτό που θέλουμε είναι οι ενεργοποιήσεις να έχουν κάποια τιμή μεταξύ 0 και 1.",
  "model": "DeepL",
  "from_community_srt": "Όταν υπολογίζετε ένα σταθμικό άθροισμα σαν αυτό, μπορεί να καταλήξετε σε έναν οποιονδήποτε αριθμό. Σε αυτό όμως το δίκτυο, αυτό που θέλουμε είναι οι ενεργοποιήσεις να έχουν μία τιμή μεταξύ του 0 και του 1, οπότε συχνά αυτό που κάνουμε είναι να περάσουμε αυτό το άθροισμα σε κάποια",
  "n_reviews": 0,
  "start": 614.26,
  "end": 623.54
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "Έτσι, ένα συνηθισμένο πράγμα που κάνουμε είναι να διοχετεύουμε αυτό το σταθμισμένο άθροισμα σε κάποια συνάρτηση που συμπιέζει τη γραμμή των πραγματικών αριθμών στην περιοχή μεταξύ 0 και 1.",
  "model": "DeepL",
  "from_community_srt": "συνάρτηση που συμπιέζει τον πραγματικό άξονα στο διάστημα μεταξύ του 0 και του 1, και μία κοινή συνάρτηση που το κάνει αυτό,",
  "n_reviews": 0,
  "start": 624.12,
  "end": 632.14
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "Και μια κοινή συνάρτηση που το κάνει αυτό ονομάζεται σιγμοειδής συνάρτηση, επίσης γνωστή ως λογιστική καμπύλη.",
  "model": "DeepL",
  "from_community_srt": "είναι η σιγμοειδής, γνωστή και ως λογιστική παλινδρόμηση.",
  "n_reviews": 0,
  "start": 632.46,
  "end": 637.42
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "Βασικά, οι πολύ αρνητικές είσοδοι καταλήγουν κοντά στο 0, οι θετικές είσοδοι καταλήγουν κοντά στο 1 και αυξάνονται σταθερά γύρω από την είσοδο 0.",
  "model": "DeepL",
  "from_community_srt": "Βασικά, οι πολύ αρνητικές είσοδοι καταλήγουν κοντά στο 0, ενώ οι πολύ θετικές είσοδοι καταλήγουν κοντά στο 1, και στην περιοχή κοντά στην είσοδο 0 υπάρχει μία σταθερή ανοδικότητα.",
  "n_reviews": 0,
  "start": 638.0,
  "end": 646.6
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "Έτσι, η ενεργοποίηση του νευρώνα εδώ είναι ουσιαστικά ένα μέτρο του πόσο θετικό είναι το σχετικό σταθμισμένο άθροισμα.",
  "model": "DeepL",
  "from_community_srt": "Οπότε η ενεργοποίηση ενός νευρώνα εδώ μετράει βασικά το πόσο θετικό είναι το αντίστοιχο σταθμικό άθροισμα.",
  "n_reviews": 0,
  "start": 649.12,
  "end": 656.36
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "Αλλά ίσως δεν είναι ότι θέλετε ο νευρώνας να ανάβει όταν το σταθμισμένο άθροισμα είναι μεγαλύτερο από 0.",
  "model": "DeepL",
  "from_community_srt": "Ίσως όμως να μη θέλετε ο νευρώνας να ενεργοποιείται όταν το σταθμικό άθροισμα είναι πάνω από 0.",
  "n_reviews": 0,
  "start": 657.54,
  "end": 661.88
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "Ίσως θέλετε να είναι ενεργή μόνο όταν το άθροισμα είναι μεγαλύτερο από 10.",
  "model": "DeepL",
  "from_community_srt": "Ίσως θέλετε να ενεργοποιείται μόνο όταν το άθροισμα είναι πχ. πάνω από 10.",
  "n_reviews": 0,
  "start": 662.28,
  "end": 666.36
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "Δηλαδή, θέλετε κάποια μεροληψία για να είναι ανενεργή.",
  "model": "DeepL",
  "from_community_srt": "Θέλετε δηλαδή μία \"πόλωση\" που θα τον απενεργοποιεί.",
  "n_reviews": 0,
  "start": 666.84,
  "end": 670.26
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "Αυτό που θα κάνουμε τότε είναι να προσθέσουμε κάποιον άλλο αριθμό, όπως το αρνητικό 10, σε αυτό το σταθμισμένο άθροισμα πριν το περάσουμε από τη συνάρτηση σιγμοειδούς εξομάλυνσης.",
  "model": "DeepL",
  "from_community_srt": "Αυτό που κάνουμε λοιπόν είναι να προσθέσουμε έναν ακόμη αριθμό, πχ. το -10 σε αυτό το σταθμικό άθροισμα, πριν το περάσουμε στην σιγμοειδή συνάρτηση \"συμπίεσης\".",
  "n_reviews": 0,
  "start": 671.38,
  "end": 679.66
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "Αυτός ο πρόσθετος αριθμός ονομάζεται προκατάληψη.",
  "model": "DeepL",
  "from_community_srt": "Αυτός ο πρόσθετος αριθμός λέγεται \"πόλωση\".",
  "n_reviews": 0,
  "start": 680.58,
  "end": 682.44
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "Έτσι, τα βάρη σας λένε ποιο μοτίβο εικονοστοιχείων λαμβάνει αυτός ο νευρώνας στο δεύτερο επίπεδο και η προκατάληψη σας λέει πόσο υψηλό πρέπει να είναι το σταθμισμένο άθροισμα πριν ο νευρώνας αρχίσει να ενεργοποιείται με νόημα.",
  "model": "DeepL",
  "from_community_srt": "Άρα τα βάρη, σας λένε ποιο μοτίβο από pixel ανιχνεύει αυτός ο νευρώνας στο δεύτερο στρώμα, και η πόλωση σας λέει το πόσο μεγάλο πρέπει να είναι το σταθμικό άθροισμα ώστε να αρχίσει ο νευρώνας να είναι σημαντικά ενεργός.",
  "n_reviews": 0,
  "start": 683.46,
  "end": 695.18
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "Και αυτός είναι μόνο ένας νευρώνας.",
  "model": "DeepL",
  "from_community_srt": "Και αυτός είναι μόνο ένας από τους νευρώνες.",
  "n_reviews": 0,
  "start": 696.12,
  "end": 697.68
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "Κάθε άλλος νευρώνας σε αυτό το στρώμα θα συνδεθεί και με τους 784 νευρώνες εικονοστοιχείων από το πρώτο στρώμα, και κάθε μία από αυτές τις 784 συνδέσεις έχει το δικό της βάρος που σχετίζεται με αυτήν.",
  "model": "DeepL",
  "from_community_srt": "Κάθε άλλος νευρώνας σε αυτό το δίκτυο, συνδέεται με όλους τους 784 νευρώνες-pixel του πρώτου στρώματος, και καθεμία από αυτές τις 784 συνδέσεις έχει το δικό της βάρος, και κάθε νευρώνας έχει τη δική του πόλωση,",
  "n_reviews": 0,
  "start": 698.28,
  "end": 710.94
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "Επίσης, το καθένα έχει κάποια προκατάληψη, κάποιον άλλο αριθμό που προσθέτετε στο σταθμισμένο άθροισμα πριν το συμπιέσετε με το σιγμοειδές.",
  "model": "DeepL",
  "from_community_srt": "δηλαδή έναν ακόμα όρο που προσθέτεις στο σταθμικό άθροισμα πριν το \"συμπιέσεις\" με την σιγμοειδή.",
  "n_reviews": 0,
  "start": 711.6,
  "end": 717.6
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "Και αυτά είναι πολλά που πρέπει να σκεφτούμε!",
  "model": "DeepL",
  "from_community_srt": "Και αυτά είναι πολλά πράγματα!",
  "n_reviews": 0,
  "start": 718.11,
  "end": 719.54
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "Με αυτό το κρυφό στρώμα των 16 νευρώνων, είναι συνολικά 784 φορές 16 βάρη, μαζί με 16 προκαταλήψεις.",
  "model": "DeepL",
  "from_community_srt": "Με αυτό το κρυφό στρώμα των 16 νευρώνων, είναι ένα σύνολο από 784*16 βάρη μαζί με 16 πολώσεις.",
  "n_reviews": 0,
  "start": 719.96,
  "end": 727.98
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "Και όλα αυτά είναι μόνο οι συνδέσεις από το πρώτο στρώμα στο δεύτερο.",
  "model": "DeepL",
  "from_community_srt": "Και όλα αυτά είναι μόλις οι συνδέσεις του πρώτου με το δεύτερο στρώμα.",
  "n_reviews": 0,
  "start": 728.84,
  "end": 731.94
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "Οι συνδέσεις μεταξύ των άλλων στρωμάτων έχουν επίσης μια σειρά από βάρη και προκαταλήψεις που σχετίζονται με αυτές.",
  "model": "DeepL",
  "from_community_srt": "Οι συνδέσεις των άλλων στρωμάτων έχουν κι αυτές ένα σωρό από βάρη και πολώσεις συσχετισμένα με αυτές.",
  "n_reviews": 0,
  "start": 732.52,
  "end": 737.34
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "Συνολικά, αυτό το δίκτυο έχει σχεδόν ακριβώς 13.000 συνολικά βάρη και προκαταλήψεις.",
  "model": "DeepL",
  "from_community_srt": "Τελικά, αυτό το δίκτυο έχει περίπου 13.000 συνολικά βάρη και πολώσεις.",
  "n_reviews": 0,
  "start": 738.34,
  "end": 743.8
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "13.000 κουμπιά και επιλογείς που μπορούν να ρυθμιστούν και να γυρίσουν για να κάνουν αυτό το δίκτυο να συμπεριφέρεται με διαφορετικούς τρόπους.",
  "model": "DeepL",
  "from_community_srt": "13.000 κουμπιά και μοχλούς που μπορούν να πειραχτούν ώστε το δίκτυο να συμπεριφέρεται με τον τρόπο που θέλουμε.",
  "n_reviews": 0,
  "start": 743.8,
  "end": 749.96
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "Έτσι, όταν μιλάμε για μάθηση, αυτό στο οποίο αναφερόμαστε είναι να βάλουμε τον υπολογιστή να βρει μια έγκυρη ρύθμιση για όλους αυτούς τους πολλούς πολλούς αριθμούς, έτσι ώστε να λύσει πραγματικά το συγκεκριμένο πρόβλημα.",
  "model": "DeepL",
  "from_community_srt": "Οπότε, όταν μιλάμε για μάθηση, αυτό στο οποίο αναφερόμαστε, είναι το ότι βάζουμε τον υπολογιστή να βρει μία έγκυρη ρύθμιση όλων αυτών των αριθμών, ώστε τελικά να μας λύνει το πρόβλημα που θέλουμε.",
  "n_reviews": 0,
  "start": 751.04,
  "end": 761.36
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "Ένα πείραμα σκέψης που είναι ταυτόχρονα διασκεδαστικό και κάπως τρομακτικό είναι να φανταστείτε να κάθεστε και να ρυθμίζετε όλα αυτά τα βάρη και τις προκαταλήψεις με το χέρι, ρυθμίζοντας σκόπιμα τους αριθμούς έτσι ώστε το δεύτερο στρώμα να εντοπίζει τις ακμές, το τρίτο στρώμα να εντοπίζει τα μοτίβα κ.λπ.",
  "model": "DeepL",
  "from_community_srt": "Ένα νοητικό πείραμα που είναι διασκεδαστικό αλλά και τρομακτικό μαζί, είναι να φανταστείτε ότι κάθεστε και ρυθμίζετε όλα τα βάρη και τις πολώσεις με το χέρι, σκόπιμα πειράζοντας τους αριθμούς, ώστε το δεύτερο στρώμα να εντοπίζει τις ακμές, το τρίτο στρώμα να εντοπίζει τα μοτίβα κλπ.",
  "n_reviews": 0,
  "start": 762.62,
  "end": 776.58
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "Προσωπικά το βρίσκω αυτό ικανοποιητικό, αντί να αντιμετωπίζω το δίκτυο ως ένα εντελώς μαύρο κουτί, διότι όταν το δίκτυο δεν αποδίδει με τον τρόπο που περιμένετε, αν έχετε δημιουργήσει μια μικρή σχέση με το τι σημαίνουν στην πραγματικότητα αυτά τα βάρη και οι προκαταλήψεις, έχετε ένα σημείο εκκίνησης για να πειραματιστείτε με το πώς να αλλάξετε τη δομή για να βελτιωθεί.",
  "model": "DeepL",
  "from_community_srt": "Προσωπικά το βρίσκω πιο διασκεδαστικό από το να θεωρώ το δίκτυο σαν ένα μαύρο κουτί. Γιατί όταν το δίκτυο δεν συμπεριφέρεται όπως θα το περιμένατε, αν έχετε αποκτίσει μια μικρή επαφή με το τι σημαίνουν αυτά τα βάρη και οι πολώσεις, τότε έχετε ένα σημείο εκκίνησης για να πειραματιστείτε με το πώς να αλλάξετε και να βελτιώσετε τη δομή.",
  "n_reviews": 0,
  "start": 776.98,
  "end": 794.18
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "Ή όταν το δίκτυο λειτουργεί, αλλά όχι για τους λόγους που θα περιμένατε, η διερεύνηση του τι κάνουν τα βάρη και οι προκαταλήψεις είναι ένας καλός τρόπος για να αμφισβητήσετε τις υποθέσεις σας και να εκθέσετε πραγματικά όλο τον χώρο των πιθανών λύσεων.",
  "model": "DeepL",
  "from_community_srt": "Ή όταν δουλεύει το δίκτυο, όχι όμως για τους λόγους που θα περιμένατε, το να ψάξετε το τι κάνουν τα βάρη και οι ακμές, είναι ένας καλός τρόπος να τεστάρετε τις παραδοχές σας και να δείτε πραγματικά το πλήρες εύρος των πιθανών λύσεων.",
  "n_reviews": 0,
  "start": 794.96,
  "end": 805.82
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "Παρεμπιπτόντως, η πραγματική λειτουργία εδώ είναι λίγο δυσκίνητη για να την καταγράψετε, δεν νομίζετε;",
  "model": "DeepL",
  "from_community_srt": "Παρεμπιπτόντως, η πραγματική συνάρτηση εδώ είναι λίγο κουραστική στη γραφή.",
  "n_reviews": 0,
  "start": 806.84,
  "end": 810.68
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "Επιτρέψτε μου λοιπόν να σας δείξω έναν πιο συμβολικά συμπαγή τρόπο αναπαράστασης αυτών των συνδέσεων.",
  "model": "DeepL",
  "from_community_srt": "Δεν νομίζετε; Αφήστε με να σας δείξω έναν σημειογραφικά πιο συμπαγή τρόπο να αναπαραστήσετε αυτές τις συνδέσεις.",
  "n_reviews": 0,
  "start": 812.5,
  "end": 817.14
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "Έτσι θα το βλέπατε αν επιλέγατε να διαβάσετε περισσότερα για τα νευρωνικά δίκτυα.",
  "model": "DeepL",
  "from_community_srt": "Έτσι θα τα συναντούσατε, αν επιλέγατε να διαβάσετε παραπάνω για τα νευρωνικά δίκτυα.",
  "n_reviews": 0,
  "start": 817.66,
  "end": 820.52
 },
 {
  "input": "Organize all of the activations from one layer into a column as a vector. Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "Οργανώστε όλες τις ενεργοποιήσεις από ένα στρώμα σε μια στήλη, καθώς ένας πίνακας αντιστοιχεί στις συνδέσεις μεταξύ ενός στρώματος και ενός συγκεκριμένου νευρώνα στο επόμενο στρώμα.",
  "model": "DeepL",
  "from_community_srt": "Οργανώστε όλες τις ενεργοποιήσεις ενός στρώματος σε μία στήλη, ως ένα διάνυσμα. Μετά οργανώστε όλα τα βάρη ως έναν πίνακα, όπου κάθε γραμμή του πίνακα αντιστοιχεί στις συνδέσεις μεταξύ ενός στρώματος και ενός συγκεκριμένου νευρώνα του επόμενου.",
  "n_reviews": 0,
  "start": 821.38,
  "end": 838.0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "Αυτό σημαίνει ότι το σταθμισμένο άθροισμα των ενεργοποιήσεων στο πρώτο επίπεδο σύμφωνα με αυτά τα βάρη αντιστοιχεί σε έναν από τους όρους του διανυσματικού γινομένου του πίνακα όλων όσων έχουμε στα αριστερά εδώ.",
  "model": "DeepL",
  "from_community_srt": "Αυτό σημαίνει ότι το σταθμικό άθροισμα των ενεργοποιήσεων στο πρώτο στρώμα, σύμφωνα με αυτά τα βάρη, αντιστοιχεί σε έναν από τους όρους του γινομένου των πινάκων που έχουμε στα αριστερά.",
  "n_reviews": 0,
  "start": 838.54,
  "end": 849.88
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "Παρεμπιπτόντως, ένα μεγάλο μέρος της μηχανικής μάθησης εξαρτάται από την καλή κατανόηση της γραμμικής άλγεβρας, οπότε όσοι από εσάς θέλετε μια ωραία οπτική κατανόηση των πινάκων και τι σημαίνει πολλαπλασιασμός διανυσμάτων πινάκων, ρίξτε μια ματιά στη σειρά που έκανα για τη γραμμική άλγεβρα, ειδικά στο κεφάλαιο 3.",
  "model": "DeepL",
  "from_community_srt": "Παρεμπιπτόντως, μεγάλο κομμάτι του machine learning απαιτεί να έχετε μια καλή επαφή με τη γραμμική άλγεβρα. Οπότε, αν κάποιος από εσάς θέλει μία ωραία οπτική κατανόηση των πινάκων και του τι σημαίνει το γινόμενο πινάκων, ας τσεκάρει τη σειρά που έκανα για τη γραμμική άλγεβρα, και ειδικά το κεφάλαιο 3.",
  "n_reviews": 0,
  "start": 854.0,
  "end": 868.6
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "Επιστρέφοντας στην έκφρασή μας, αντί να μιλάμε για την προσθήκη της προκατάληψης σε κάθε μία από αυτές τις τιμές ανεξάρτητα, την αναπαριστούμε οργανώνοντας όλες αυτές τις προκαταλήψεις σε ένα διάνυσμα και προσθέτοντας ολόκληρο το διάνυσμα στο προηγούμενο διανυσματικό γινόμενο του πίνακα.",
  "model": "DeepL",
  "from_community_srt": "Πίσω στην έκφρασή μας, αντί να λέμε ότι προσθέτουμε την πόλωση σε κάθε τιμή ξεχωριστά, την αναπαριστούμε ως ένα διάνυσμα όλων αυτών των πολώσεων, το οποίο προσθέτουμε στο προηγούμενο γινόμενο πινάκων.",
  "n_reviews": 0,
  "start": 869.24,
  "end": 882.3
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "Στη συνέχεια, ως τελικό βήμα, θα τυλίξω ένα σιγμοειδές γύρω από το εξωτερικό εδώ, και αυτό που υποτίθεται ότι αντιπροσωπεύει είναι ότι θα εφαρμόσετε τη σιγμοειδή συνάρτηση σε κάθε συγκεκριμένη συνιστώσα του διανύσματος που προκύπτει στο εσωτερικό.",
  "model": "DeepL",
  "from_community_srt": "Τέλος, θα γράψω τη σιγμοειδή γύρω από αυτήν την έκφραση, και αυτό σημαίνει ότι θα εφαρμόσετε τη σιγμοειδή συνάρτηση σε καθεμία από τις συνιστώσες του τελικού διανύσματος στο εσωτερικό.",
  "n_reviews": 0,
  "start": 883.28,
  "end": 894.74
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "Έτσι, μόλις γράψετε αυτόν τον πίνακα βαρών και αυτά τα διανύσματα ως τα δικά τους σύμβολα, μπορείτε να επικοινωνήσετε την πλήρη μετάβαση των ενεργοποιήσεων από το ένα επίπεδο στο επόμενο σε μια εξαιρετικά σφιχτή και τακτοποιημένη μικρή έκφραση, και αυτό κάνει τον σχετικό κώδικα τόσο πολύ απλούστερο όσο και πολύ πιο γρήγορο, δεδομένου ότι πολλές βιβλιοθήκες βελτιστοποιούν τον πολλαπλασιασμό πινάκων.",
  "model": "DeepL",
  "from_community_srt": "Οπότε μόλις γράψετε αυτόν τον πίνακα βαρών και αυτά τα διανύσματα με τα δικά τους σύμβολα, μπορείτε να συμβολίσετε την πλήρη μετάβαση των ενεργοποιήσεων από το ένα στρώμα στο επόμενο με μία υπερβολικά μικρή και όμορφη έκφραση, και αυτό μετά κάνει τον σχετικό κώδικα και απλούστερο και πολύ γρηγορότερο, μιας και πολλές βιβλιοθήκες βελτιστοποιούν απίστευτα το γινόμενο πινάκων.",
  "n_reviews": 0,
  "start": 895.94,
  "end": 915.66
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "Θυμάστε που νωρίτερα είπα ότι αυτοί οι νευρώνες είναι απλά πράγματα που κρατούν αριθμούς;",
  "model": "DeepL",
  "from_community_srt": "Θυμάστε που νωρίτερα είχα πει ότι αυτοί οι νευρώνες είναι απλά πράγματα που κρατάνε αριθμούς;",
  "n_reviews": 0,
  "start": 917.82,
  "end": 921.46
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "Φυσικά, οι συγκεκριμένοι αριθμοί που κρατούν εξαρτώνται από την εικόνα που τροφοδοτείτε, οπότε είναι πιο ακριβές να σκεφτείτε κάθε νευρώνα ως μια συνάρτηση, η οποία λαμβάνει τις εξόδους όλων των νευρώνων του προηγούμενου επιπέδου και δίνει έναν αριθμό μεταξύ 0 και 1.",
  "model": "DeepL",
  "from_community_srt": "Ε, φυσικά αυτοί οι αριθμοί εξαρτώνται από την εικόνα που δίνεται ως είσοδος. Οπότε είναι πιο ακριβές να σκέφτεστε κάθε νευρώνα ως μία συνάρτηση! Μία συνάρτηση που δέχεται ως είσοδο τις τιμές όλων των νευρώνων του προηγούμενου στρώματος, και βγάζει ως έξοδο έναν αριθμό μεταξύ του 0 και του 1.",
  "n_reviews": 0,
  "start": 922.22,
  "end": 938.34
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "Στην πραγματικότητα, ολόκληρο το δίκτυο είναι απλώς μια συνάρτηση, η οποία δέχεται 784 αριθμούς ως είσοδο και δίνει 10 αριθμούς ως έξοδο.",
  "model": "DeepL",
  "from_community_srt": "Πραγματικά, ολόκληρο το δίκτυο είναι απλά μία συνάρτηση που παίρνει ως είσοδο 784 αριθμούς και βγάζει ως έξοδο 10 αριθμούς.",
  "n_reviews": 0,
  "start": 939.2,
  "end": 947.06
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless. And in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "Πρόκειται για μια παράλογα περίπλοκη συνάρτηση, που περιλαμβάνει 13.000 παραμέτρους με τη μορφή αυτών των βαρών και των προκαταλήψεων που εντοπίζουν ορισμένα μοτίβα, και η οποία περιλαμβάνει την επανάληψη πολλών διανυσματικών γινομένων πινάκων και τη σιγμοειδή συνάρτηση τετραγωνισμού, αλλά είναι μια συνάρτηση, και κατά κάποιο τρόπο είναι κάπως καθησυχαστικό το γεγονός ότι φαίνεται περίπλοκη.",
  "model": "DeepL",
  "from_community_srt": "Είναι μία αδιανόητα περίπλοκη συνάρτηση, που περιλαμβάνει 13.000 παραμέτρους με τη μορφή βαρών και πολώσεων, που ανιχνεύουν συγκεκριμένα μοτίβα και περιλαμβάνουν την εκτέλεση πάρα πολλών γινομένων πινάκων και της σιγμοειδούς συνάρτησης \"συμπίεσης\". Παρ' όλ' αυτά είναι απλά μία συνάρτηση, και με κάποιον τρόπο είναι καθησυχαστικό ότι είναι τόσο περίπλοκη. Θέλω να πω,",
  "n_reviews": 0,
  "start": 947.56,
  "end": 966.66
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "Θέλω να πω, αν ήταν πιο απλό, τι ελπίδα θα είχαμε ότι θα μπορούσε να αντιμετωπίσει την πρόκληση της αναγνώρισης ψηφίων;",
  "model": "DeepL",
  "from_community_srt": "αν ήταν έστω λίγο πιο απλή, τι ελπίδες θα είχαμε ότι θα μπορούσε να αντιμετωπίσει την πρόκληση της αναγνώρισης ψηφίων; Και πώς αντιμετωπίζει αυτήν την πρόκληση;",
  "n_reviews": 0,
  "start": 967.34,
  "end": 972.28
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "Και πώς αντιμετωπίζει αυτή την πρόκληση;",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 973.34,
  "end": 974.7
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "Πώς αυτό το δίκτυο μαθαίνει τα κατάλληλα βάρη και τις προκαταλήψεις μόνο με την εξέταση των δεδομένων;",
  "model": "DeepL",
  "from_community_srt": "Πώς μαθαίνει το δίκτυο τα κατάλληλα βάρη και τις πολώσεις, απλά κοιτώντας τα δεδομένα;",
  "n_reviews": 0,
  "start": 975.08,
  "end": 979.36
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "Αυτό θα δείξω στο επόμενο βίντεο, και θα αναλύσω λίγο περισσότερο τι πραγματικά κάνει το συγκεκριμένο δίκτυο που βλέπουμε.",
  "model": "DeepL",
  "from_community_srt": "Ε... Αυτό είναι που θα πούμε στο επόμενο βίντεο, και επίσης θα ψάξουμε λίγο ακόμα τι κάνει αυτό το δίκτυο που βλέπουμε.",
  "n_reviews": 0,
  "start": 980.14,
  "end": 986.12
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "Τώρα είναι το σημείο που υποθέτω ότι θα έπρεπε να πω εγγραφείτε για να μείνετε ειδοποιημένοι για το πότε βγαίνουν βίντεο ή οποιαδήποτε νέα βίντεο, αλλά ρεαλιστικά οι περισσότεροι από εσάς δεν λαμβάνετε πραγματικά ειδοποιήσεις από το YouTube, έτσι δεν είναι;",
  "model": "DeepL",
  "from_community_srt": "Τώρα υποθέτω είναι που πρέπει να σας πω να εγγραφείτε για να ειδοποιηθείτε όταν βγει αυτό ή οποιοδήποτε άλλο βίντεο. Στ' αλήθεια όμως, οι περισσότεροι από εσάς δεν παίρνετε ειδοποιήσεις από το YouTube,",
  "n_reviews": 0,
  "start": 987.58,
  "end": 997.42
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "Ίσως πιο ειλικρινά θα έπρεπε να πω εγγραφείτε, ώστε τα νευρωνικά δίκτυα που διέπουν τον αλγόριθμο συστάσεων του YouTube να είναι προετοιμασμένα να πιστέψουν ότι θέλετε να δείτε περιεχόμενο από αυτό το κανάλι να σας προτείνεται.",
  "model": "DeepL",
  "from_community_srt": "έτσι; Ίσως πρέπει να σας πω να εγγραφείτε, ώστε τα νευρωνικά δίκτυα που κρύβονται πίσω από τον αλγόριθμο προτάσεων του YouTube να πιστέψουν ότι θέλετε όντως να σας προτείνονται τα βίντεο αυτού του καναλιού.",
  "n_reviews": 0,
  "start": 998.02,
  "end": 1007.88
 },
 {
  "input": "Anyway, stay posted for more.",
  "translatedText": "Εν πάση περιπτώσει μείνετε αναρτημένοι για περισσότερα.",
  "model": "DeepL",
  "from_community_srt": "Τέλος πάντων, μείνετε συντονισμένοι για περισσότερα.",
  "n_reviews": 0,
  "start": 1008.56,
  "end": 1009.94
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "Ευχαριστούμε πολύ όλους όσους υποστηρίζουν αυτά τα βίντεο στο Patreon.",
  "model": "DeepL",
  "from_community_srt": "Ευχαριστώ πάρα πολύ όλους όσους υποστηρίζουν αυτά τα βίντεο στο Patreon.",
  "n_reviews": 0,
  "start": 1010.76,
  "end": 1013.5
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "Το καλοκαίρι άργησα λίγο να προχωρήσω με τη σειρά probability, αλλά μετά από αυτό το έργο θα ξαναρχίσω να ασχολούμαι με αυτό, οπότε οι προστάτες μπορούν να περιμένουν ενημερώσεις εκεί.",
  "model": "DeepL",
  "from_community_srt": "Έχω αργήσει λίγο να προχωρήσω τη σειρά για τις Πιθανότητες αυτό το καλοκαίρι, αλλά θα επιστρέψω σε αυτήν μετά από αυτό το project, οπότε εσείς οι patrons θα δείτε εκεί τις ενημερώσεις.",
  "n_reviews": 0,
  "start": 1014.0,
  "end": 1021.9
 },
 {
  "input": "To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "Για να κλείσω τα πράγματα εδώ, έχω μαζί μου τη Leisha Lee, η οποία έκανε τη διδακτορική της διατριβή στη θεωρητική πλευρά της βαθιάς μάθησης και η οποία εργάζεται σήμερα σε μια εταιρεία επιχειρηματικών κεφαλαίων που ονομάζεται Amplify Partners, η οποία ευγενικά παρείχε μέρος της χρηματοδότησης για αυτό το βίντεο.",
  "model": "DeepL",
  "from_community_srt": "Για να κλείσουμε, έχω μαζί μου την Lisha Li, που έκανε το διδακτορικό της στο θεωρητικό μέρος του deep learning και τώρα εργάζεται σε μία εταιρεία επιχειρηματικών κεφαλαίων, την Amplify Partners, η οποία ευγενικά παρείχε ένα μέρος της χρηματοδότησης για αυτό το βίντεο.",
  "n_reviews": 0,
  "start": 1023.6,
  "end": 1034.62
 },
 {
  "input": "So Lisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "Έτσι, Leisha, ένα πράγμα που νομίζω ότι πρέπει να αναφέρουμε γρήγορα είναι αυτή η σιγμοειδής συνάρτηση.",
  "model": "DeepL",
  "from_community_srt": "Οπότε Lisha, ένα πράγμα που πρέπει γρήγορα να συζητήσουμε είναι αυτή η σιγμοειδής συνάρτηση.",
  "n_reviews": 0,
  "start": 1035.46,
  "end": 1039.12
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "Όπως καταλαβαίνω, τα πρώιμα δίκτυα το χρησιμοποιούν αυτό για να συμπιέσουν το σχετικό σταθμισμένο άθροισμα σε αυτό το διάστημα μεταξύ μηδέν και ένα, με κίνητρο αυτή τη βιολογική αναλογία των νευρώνων που είναι είτε ανενεργοί είτε ενεργοί.",
  "model": "DeepL",
  "from_community_srt": "Όπως το καταλαβαίνω εγώ, τα πρώτα δίκτυα την χρησιμοποιούσαν για να συμπιέσουν το σταθμικό άθροισμα στο διάστημα μεταξύ 0 και 1. - Ξέρεις, κάπως εμπνευσμένοι από τη βιολογική αναλογία των νευρώνων που είναι ενεργοί ή ανενεργοί - Ακριβώς",
  "n_reviews": 0,
  "start": 1039.7,
  "end": 1049.84
 },
 {
  "input": "Exactly.",
  "translatedText": "Ακριβώς.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1050.28,
  "end": 1050.3
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "Αλλά σχετικά λίγα σύγχρονα δίκτυα χρησιμοποιούν πλέον σιγμοειδές.",
  "model": "DeepL",
  "from_community_srt": "- Πλέον όμως λίγα σύγχρονα δίκτυα χρησιμοποιούν τη σιγμοειδή στην πράξη.",
  "n_reviews": 0,
  "start": 1050.56,
  "end": 1054.04
 },
 {
  "input": "Yeah.",
  "translatedText": "Ναι.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1054.32,
  "end": 1054.32
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "Είναι κάπως παλιάς σχολής, σωστά;",
  "model": "DeepL",
  "from_community_srt": "Έχει παλιώσει λίγο ε;",
  "n_reviews": 0,
  "start": 1054.44,
  "end": 1055.54
 },
 {
  "input": "Yeah or rather ReLU seems to be much easier to train.",
  "translatedText": "Ναι, ή μάλλον το relu φαίνεται να εκπαιδεύεται πολύ πιο εύκολα.",
  "model": "DeepL",
  "from_community_srt": "- Ναι, ή μάλλον η ReLU δείχνει να είναι ευκολότερη… …στην εκπαίδευση.",
  "n_reviews": 0,
  "start": 1055.76,
  "end": 1058.98
 },
 {
  "input": "And ReLU, ReLU stands for rectified linear unit?",
  "translatedText": "Και το relu σημαίνει διορθωμένη γραμμική μονάδα;",
  "model": "DeepL",
  "from_community_srt": "- Και ReLU ουσιαστικά λέμε την ανορθωμένη γραμμική μοναδιαία (Rectified Linear Unit) - Ναι,",
  "n_reviews": 0,
  "start": 1059.4,
  "end": 1062.34
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not. And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "Ναι, είναι αυτό το είδος συνάρτησης όπου απλά παίρνετε ένα μέγιστο του μηδενός και του a όπου το a δίνεται από αυτό που εξηγούσατε στο βίντεο και αυτό που νομίζω ότι ήταν ένα είδος κινήτρου, ήταν εν μέρει από μια βιολογική αναλογία με το πώς οι νευρώνες είτε ενεργοποιούνται είτε όχι και έτσι αν περάσει ένα ορισμένο κατώφλι θα είναι η συνάρτηση ταυτότητας, αλλά αν δεν το κάνει τότε απλά δεν θα ενεργοποιηθεί, οπότε θα είναι μηδέν, οπότε είναι ένα είδος απλοποίησης.",
  "model": "DeepL",
  "from_community_srt": "είναι μία συνάρτηση που απλά παίρνει το μέγιστο μεταξύ του 0 και του a, όπου το a δίνεται από αυτό που εξηγούσες στο βίντεο. Και νομίζω ότι είναι μερικώς εμπνευσμένη από μία βιολογική αναλογία του πώς οι νευρώνες ενεργοποιούνται ή όχι, και ανάλογα με το αν ξεπερνιέται ένα συγκεκριμένο φράγμα, η ReLU θα ήταν απλά η ταυτοτική συνάρτηση, ενώ αν όχι, απλά δεν θα ενεργοποιούνταν και θα ήταν 0, οπότε είναι απλά μία απλοποίηση.",
  "n_reviews": 0,
  "start": 1062.68,
  "end": 1090.84
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "Η χρήση σιγμοειδών δεν βοήθησε στην εκπαίδευση ή ήταν πολύ δύσκολο να εκπαιδευτεί σε κάποιο σημείο και οι άνθρωποι απλά δοκίμασαν το relu και έτυχε να λειτουργήσει πολύ καλά για αυτά τα απίστευτα βαθιά νευρωνικά δίκτυα.",
  "model": "DeepL",
  "from_community_srt": "Η χρήση των σιγμοειδών δεν βοήθησε στην εκπαίδευση, ή την έκανε πολύ δύσκολη σε κάποια σημεία, και οι άνθρωποι απλά δοκίμασαν την ReLU και έτυχε να δουλεύει πολύ καλά για αυτά τα απίστευτα περίπλοκα νευρωνικά δίκτυα. - Μια χαρά,",
  "n_reviews": 0,
  "start": 1091.16,
  "end": 1104.62
 },
 {
  "input": "All right thank you Lisha.",
  "translatedText": "Εντάξει, σας ευχαριστώ Alicia.",
  "model": "DeepL",
  "from_community_srt": "σε ευχαριστώ Lisha.",
  "n_reviews": 0,
  "start": 1105.1,
  "end": 1105.64
 }
]