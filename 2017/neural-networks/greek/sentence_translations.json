[
 {
  "input": "This is a 3.",
  "translatedText": "Αυτό είναι ένα 3.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "Είναι πρόχειρα γραμμένο και απεικονίζεται σε εξαιρετικά χαμηλή ανάλυση 28x28 pixels, αλλά ο εγκέφαλός σας δεν έχει πρόβλημα να το αναγνωρίσει ως 3.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "Και θέλω να αφιερώσετε ένα λεπτό για να εκτιμήσετε πόσο τρελό είναι που οι εγκέφαλοι μπορούν να το κάνουν αυτό τόσο αβίαστα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "Θέλω να πω, αυτό, αυτό και αυτό είναι επίσης αναγνωρίσιμα ως 3s, παρόλο που οι συγκεκριμένες τιμές κάθε pixel είναι πολύ διαφορετικές από τη μία εικόνα στην άλλη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "Τα συγκεκριμένα φωτοευαίσθητα κύτταρα στο μάτι σας που πυροδοτούνται όταν βλέπετε αυτό το 3 είναι πολύ διαφορετικά από αυτά που πυροδοτούνται όταν βλέπετε αυτό το 3.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "Αλλά κάτι στον τρελά έξυπνο οπτικό φλοιό σας διαχωρίζει αυτές τις εικόνες ως αντιπροσωπευτικές της ίδιας ιδέας, ενώ ταυτόχρονα αναγνωρίζει άλλες εικόνες ως δικές τους ξεχωριστές ιδέες.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "Αλλά αν σας έλεγα, ε, κάτσε κάτω και γράψε μου ένα πρόγραμμα που θα παίρνει ένα πλέγμα 28x28 εικονοστοιχείων όπως αυτό και θα βγάζει έναν απλό αριθμό μεταξύ 0 και 10, λέγοντάς σας τι νομίζει ότι είναι το ψηφίο, τότε η εργασία γίνεται από κωμικοτραγικά ασήμαντη σε τρομακτικά δύσκολη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "Αν δεν έχετε ζήσει κάτω από ένα βράχο, νομίζω ότι δεν χρειάζεται να αιτιολογήσω τη σημασία και τη σπουδαιότητα της μηχανικής μάθησης και των νευρωνικών δικτύων για το παρόν και το μέλλον.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "Αλλά αυτό που θέλω να κάνω εδώ είναι να σας δείξω τι είναι στην πραγματικότητα ένα νευρωνικό δίκτυο, χωρίς να υποθέσουμε ότι δεν υπάρχει υπόβαθρο, και να σας βοηθήσω να απεικονίσετε τι κάνει, όχι ως λέξη, αλλά ως ένα κομμάτι των μαθηματικών.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "Η ελπίδα μου είναι να φύγετε νιώθοντας ότι η ίδια η δομή έχει κίνητρα, και να νιώσετε ότι ξέρετε τι σημαίνει όταν διαβάζετε ή ακούτε για ένα νευρωνικό δίκτυο που παραθέτει το απόσπασμα \"μάθηση\".",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "Αυτό το βίντεο θα είναι αφιερωμένο στη δομική συνιστώσα αυτού, και το επόμενο θα ασχοληθεί με τη μάθηση.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "Αυτό που πρόκειται να κάνουμε είναι να δημιουργήσουμε ένα νευρωνικό δίκτυο που μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "Αυτό είναι ένα κάπως κλασικό παράδειγμα για την εισαγωγή του θέματος, και είμαι ευτυχής που θα παραμείνω με το status quo εδώ, επειδή στο τέλος των δύο βίντεο θέλω να σας υποδείξω μερικές καλές πηγές όπου μπορείτε να μάθετε περισσότερα, και όπου μπορείτε να κατεβάσετε τον κώδικα που το κάνει αυτό και να παίξετε με αυτόν στον δικό σας υπολογιστή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "Υπάρχουν πολλές παραλλαγές των νευρωνικών δικτύων, και τα τελευταία χρόνια υπάρχει ένα είδος έκρηξης στην έρευνα προς αυτές τις παραλλαγές, αλλά σε αυτά τα δύο εισαγωγικά βίντεο εσείς και εγώ θα εξετάσουμε μόνο την πιο απλή μορφή χωρίς πρόσθετες λεπτομέρειες.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "Αυτό είναι ένα είδος απαραίτητης προϋπόθεσης για την κατανόηση οποιασδήποτε από τις πιο ισχυρές σύγχρονες παραλλαγές, και πιστέψτε με, εξακολουθεί να έχει αρκετή πολυπλοκότητα για εμάς να την κατανοήσουμε.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "Αλλά ακόμη και σε αυτή την απλούστερη μορφή μπορεί να μάθει να αναγνωρίζει χειρόγραφα ψηφία, πράγμα πολύ καλό για έναν υπολογιστή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "Και ταυτόχρονα θα δείτε πώς δεν ανταποκρίνεται σε μερικές από τις ελπίδες που μπορεί να έχουμε γι' αυτό.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "Όπως υποδηλώνει το όνομα, τα νευρωνικά δίκτυα είναι εμπνευσμένα από τον εγκέφαλο, αλλά ας το αναλύσουμε.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "Ποιοι είναι οι νευρώνες και με ποια έννοια συνδέονται μεταξύ τους;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "Αυτή τη στιγμή όταν λέω νευρώνας το μόνο που θέλω να σκέφτεστε είναι ένα πράγμα που κρατάει έναν αριθμό, συγκεκριμένα έναν αριθμό μεταξύ 0 και 1.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "Πραγματικά δεν είναι κάτι περισσότερο από αυτό.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "Για παράδειγμα, το δίκτυο ξεκινά με μια δέσμη νευρώνων που αντιστοιχούν σε κάθε ένα από τα 28x28 εικονοστοιχεία της εικόνας εισόδου, δηλαδή 784 νευρώνες συνολικά.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "Κάθε ένα από αυτά περιέχει έναν αριθμό που αντιπροσωπεύει την τιμή της κλίμακας του γκρι του αντίστοιχου εικονοστοιχείου, που κυμαίνεται από 0 για μαύρα εικονοστοιχεία έως 1 για λευκά εικονοστοιχεία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "Αυτός ο αριθμός στο εσωτερικό του νευρώνα ονομάζεται ενεργοποίησή του, και η εικόνα που μπορεί να έχετε στο μυαλό σας εδώ είναι ότι κάθε νευρώνας φωτίζεται όταν η ενεργοποίησή του είναι υψηλός αριθμός.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "Έτσι, όλοι αυτοί οι 784 νευρώνες αποτελούν το πρώτο επίπεδο του δικτύου μας.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "Τώρα μεταβαίνοντας στο τελευταίο επίπεδο, αυτό έχει 10 νευρώνες, καθένας από τους οποίους αντιπροσωπεύει ένα από τα ψηφία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "Η ενεργοποίηση σε αυτούς τους νευρώνες, και πάλι κάποιος αριθμός που κυμαίνεται μεταξύ 0 και 1, αντιπροσωπεύει το πόσο το σύστημα πιστεύει ότι μια συγκεκριμένη εικόνα αντιστοιχεί σε ένα συγκεκριμένο ψηφίο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "Υπάρχουν επίσης μερικά ενδιάμεσα στρώματα που ονομάζονται κρυφά στρώματα, τα οποία προς το παρόν θα πρέπει να είναι απλώς ένα τεράστιο ερωτηματικό για το πώς θα γίνει αυτή η διαδικασία αναγνώρισης ψηφίων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "Σε αυτό το δίκτυο επέλεξα δύο κρυφά στρώματα, το καθένα με 16 νευρώνες, και ομολογουμένως αυτή είναι κάπως αυθαίρετη επιλογή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "Για να είμαι ειλικρινής, επέλεξα δύο στρώματα με βάση το πώς θέλω να κινητοποιήσω τη δομή σε λίγο, και το 16, λοιπόν, ήταν απλά ένας ωραίος αριθμός για να χωρέσει στην οθόνη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "Στην πράξη υπάρχει πολύς χώρος για πειραματισμό με μια συγκεκριμένη δομή εδώ.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "Με τον τρόπο λειτουργίας του δικτύου, οι ενεργοποιήσεις σε ένα επίπεδο καθορίζουν τις ενεργοποιήσεις του επόμενου επιπέδου.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "Και φυσικά η καρδιά του δικτύου ως μηχανισμού επεξεργασίας πληροφοριών έγκειται στο πώς ακριβώς αυτές οι ενεργοποιήσεις από ένα επίπεδο προκαλούν ενεργοποιήσεις στο επόμενο επίπεδο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "Εννοείται ότι είναι χαλαρά ανάλογο με το πώς στα βιολογικά δίκτυα νευρώνων, ορισμένες ομάδες νευρώνων που πυροδοτούνται προκαλούν την πυροδότηση ορισμένων άλλων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "Τώρα το δίκτυο που παρουσιάζω εδώ έχει ήδη εκπαιδευτεί να αναγνωρίζει ψηφία, και επιτρέψτε μου να σας δείξω τι εννοώ με αυτό.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "Αυτό σημαίνει ότι αν τροφοδοτήσετε μια εικόνα, φωτίζοντας και τους 784 νευρώνες του επιπέδου εισόδου ανάλογα με τη φωτεινότητα κάθε εικονοστοιχείου της εικόνας, αυτό το μοτίβο ενεργοποιήσεων προκαλεί κάποιο πολύ συγκεκριμένο μοτίβο στο επόμενο επίπεδο, το οποίο προκαλεί κάποιο μοτίβο στο επόμενο, το οποίο τελικά δίνει κάποιο μοτίβο στο επίπεδο εξόδου.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "Και ο φωτεινότερος νευρώνας αυτού του επιπέδου εξόδου είναι η επιλογή του δικτύου, για να το πω έτσι, για το ψηφίο που αντιπροσωπεύει αυτή η εικόνα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "Και προτού αρχίσουμε τα μαθηματικά για το πώς το ένα στρώμα επηρεάζει το επόμενο, ή πώς λειτουργεί η εκπαίδευση, ας μιλήσουμε για το γιατί είναι λογικό να περιμένουμε από μια τέτοια πολυεπίπεδη δομή να συμπεριφέρεται έξυπνα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "Τι περιμένουμε εδώ;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What is the best hope for those middle layers?",
  "translatedText": "Ποια είναι η καλύτερη ελπίδα για αυτά τα μεσαία στρώματα;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "Λοιπόν, όταν εσείς ή εγώ αναγνωρίζουμε ψηφία, συνθέτουμε διάφορα στοιχεία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "Το 9 έχει μια θηλιά πάνω και μια γραμμή στα δεξιά.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "Ένα 8 έχει επίσης έναν βρόχο επάνω, αλλά συνδυάζεται με έναν άλλο βρόχο κάτω.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "Ένα 4 βασικά αναλύεται σε τρεις συγκεκριμένες γραμμές και άλλα τέτοια πράγματα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "Τώρα, σε έναν τέλειο κόσμο, θα μπορούσαμε να ελπίζουμε ότι κάθε νευρώνας στο προτελευταίο στρώμα αντιστοιχεί σε μία από αυτές τις υποσυνιστώσες, ότι κάθε φορά που τροφοδοτείτε μια εικόνα με, ας πούμε, έναν βρόχο στην κορυφή, όπως ένα 9 ή ένα 8, υπάρχει κάποιος συγκεκριμένος νευρώνας του οποίου η ενεργοποίηση θα είναι κοντά στο 1.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "Και δεν εννοώ αυτόν τον συγκεκριμένο βρόχο από pixels, η ελπίδα θα ήταν ότι οποιοδήποτε γενικά ελικοειδές μοτίβο προς την κορυφή ενεργοποιεί αυτόν τον νευρώνα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "Με αυτόν τον τρόπο, η μετάβαση από το τρίτο στρώμα στο τελευταίο απαιτεί απλώς να μάθουμε ποιος συνδυασμός υποσυνιστωσών αντιστοιχεί σε ποια ψηφία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "Βέβαια, αυτό απλώς επιδεινώνει το πρόβλημα, διότι πώς θα αναγνωρίζατε αυτά τα υποσυστήματα ή ακόμη και πώς θα μαθαίνατε ποια θα έπρεπε να είναι τα σωστά υποσυστήματα;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "Και ακόμα δεν έχω μιλήσει για το πώς το ένα στρώμα επηρεάζει το επόμενο, αλλά ακολουθήστε με σε αυτό για μια στιγμή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "Η αναγνώριση ενός βρόχου μπορεί επίσης να αναλύεται σε υποπροβλήματα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "Ένας λογικός τρόπος για να το κάνετε αυτό θα ήταν να αναγνωρίσετε πρώτα τις διάφορες μικρές άκρες που το συνθέτουν.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "Παρομοίως, μια μεγάλη γραμμή, όπως αυτή που μπορεί να δείτε στα ψηφία 1 ή 4 ή 7, είναι στην πραγματικότητα απλώς μια μεγάλη ακμή, ή ίσως να τη σκέφτεστε ως ένα συγκεκριμένο μοτίβο πολλών μικρότερων ακμών.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "Έτσι, ίσως η ελπίδα μας είναι ότι κάθε νευρώνας στο δεύτερο στρώμα του δικτύου αντιστοιχεί στις διάφορες σχετικές μικρές ακμές.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "Ίσως όταν μια εικόνα όπως αυτή έρχεται, ανάβει όλους τους νευρώνες που σχετίζονται με περίπου 8 έως 10 συγκεκριμένες μικρές ακμές, οι οποίες με τη σειρά τους ανάβουν τους νευρώνες που σχετίζονται με τον άνω βρόχο και μια μακριά κάθετη γραμμή, και αυτοί ανάβουν τον νευρώνα που σχετίζεται με το 9.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "Το αν αυτό είναι ή όχι αυτό που πραγματικά κάνει το τελικό μας δίκτυο είναι ένα άλλο ερώτημα, στο οποίο θα επανέλθω μόλις δούμε πώς θα εκπαιδεύσουμε το δίκτυο, αλλά αυτή είναι μια ελπίδα που μπορεί να έχουμε, ένα είδος στόχου με την πολυεπίπεδη δομή όπως αυτή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "Επιπλέον, μπορείτε να φανταστείτε πώς η δυνατότητα ανίχνευσης ακμών και μοτίβων με αυτόν τον τρόπο θα ήταν πραγματικά χρήσιμη για άλλες εργασίες αναγνώρισης εικόνων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "Και ακόμη και πέρα από την αναγνώριση εικόνων, υπάρχουν όλα τα είδη έξυπνων πραγμάτων που μπορεί να θέλετε να κάνετε και τα οποία αναλύονται σε επίπεδα αφαίρεσης.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "Η ανάλυση της ομιλίας, για παράδειγμα, περιλαμβάνει τη λήψη ακατέργαστου ήχου και την επιλογή ξεχωριστών ήχων, οι οποίοι συνδυάζονται για να σχηματίσουν ορισμένες συλλαβές, οι οποίες συνδυάζονται για να σχηματίσουν λέξεις, οι οποίες συνδυάζονται για να σχηματίσουν φράσεις και πιο αφηρημένες σκέψεις κ.λπ.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "Αλλά για να επιστρέψουμε στο πώς λειτουργούν όλα αυτά στην πραγματικότητα, φανταστείτε τον εαυτό σας τώρα να σχεδιάζει πώς ακριβώς οι ενεργοποιήσεις σε ένα επίπεδο μπορεί να καθορίζουν το επόμενο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "Ο στόχος είναι να υπάρχει κάποιος μηχανισμός που θα μπορούσε να συνδυάζει εικονοστοιχεία σε ακμές, ή ακμές σε μοτίβα, ή μοτίβα σε ψηφία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "Και για να εστιάσουμε σε ένα πολύ συγκεκριμένο παράδειγμα, ας πούμε ότι η ελπίδα είναι ένας συγκεκριμένος νευρώνας στο δεύτερο επίπεδο να αντιληφθεί αν η εικόνα έχει ή όχι μια άκρη σε αυτή την περιοχή εδώ.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "Το ερώτημα που τίθεται είναι ποιες παραμέτρους πρέπει να έχει το δίκτυο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "Ποιους επιλογείς και ποια κουμπιά θα πρέπει να μπορείτε να ρυθμίσετε ώστε να είναι αρκετά εκφραστικό για να καταγράψει αυτό το μοτίβο ή οποιοδήποτε άλλο μοτίβο εικονοστοιχείων ή το μοτίβο ότι πολλές άκρες μπορούν να κάνουν έναν βρόχο και άλλα τέτοια πράγματα;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "Λοιπόν, αυτό που θα κάνουμε είναι να αναθέσουμε ένα βάρος σε κάθε μία από τις συνδέσεις μεταξύ του νευρώνα μας και των νευρώνων από το πρώτο επίπεδο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "Αυτά τα βάρη είναι απλώς αριθμοί.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "Στη συνέχεια, πάρτε όλες αυτές τις ενεργοποιήσεις από το πρώτο επίπεδο και υπολογίστε το σταθμισμένο άθροισμά τους σύμφωνα με αυτά τα βάρη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "Θεωρώ ότι είναι χρήσιμο να σκεφτούμε ότι αυτά τα βάρη είναι οργανωμένα σε ένα μικρό πλέγμα, και θα χρησιμοποιήσω πράσινα εικονοστοιχεία για να δείξω θετικά βάρη, και κόκκινα εικονοστοιχεία για να δείξω αρνητικά βάρη, όπου η φωτεινότητα του εικονοστοιχείου είναι μια χαλαρή απεικόνιση της τιμής του βάρους.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "Τώρα, αν κάναμε τα βάρη που σχετίζονται με σχεδόν όλα τα εικονοστοιχεία μηδενικά, εκτός από κάποια θετικά βάρη σε αυτή την περιοχή που μας ενδιαφέρει, τότε η λήψη του σταθμισμένου αθροίσματος όλων των τιμών των εικονοστοιχείων ισοδυναμεί στην πραγματικότητα με την πρόσθεση των τιμών των εικονοστοιχείων μόνο στην περιοχή που μας ενδιαφέρει.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "Και αν θέλατε πραγματικά να εντοπίσετε αν υπάρχει μια άκρη εδώ, αυτό που θα μπορούσατε να κάνετε είναι να έχετε κάποια αρνητικά βάρη που σχετίζονται με τα γύρω εικονοστοιχεία.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "Τότε το άθροισμα είναι μεγαλύτερο όταν τα μεσαία εικονοστοιχεία είναι φωτεινά αλλά τα γύρω εικονοστοιχεία είναι πιο σκοτεινά.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "Όταν υπολογίζετε ένα σταθμισμένο άθροισμα όπως αυτό, μπορεί να προκύψει οποιοσδήποτε αριθμός, αλλά για αυτό το δίκτυο αυτό που θέλουμε είναι οι ενεργοποιήσεις να έχουν κάποια τιμή μεταξύ 0 και 1.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "Έτσι, ένα συνηθισμένο πράγμα που κάνουμε είναι να διοχετεύουμε αυτό το σταθμισμένο άθροισμα σε κάποια συνάρτηση που συμπιέζει τη γραμμή των πραγματικών αριθμών στην περιοχή μεταξύ 0 και 1.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "Και μια κοινή συνάρτηση που το κάνει αυτό ονομάζεται σιγμοειδής συνάρτηση, επίσης γνωστή ως λογιστική καμπύλη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "Βασικά, οι πολύ αρνητικές είσοδοι καταλήγουν κοντά στο 0, οι θετικές είσοδοι καταλήγουν κοντά στο 1 και αυξάνονται σταθερά γύρω από την είσοδο 0.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "Έτσι, η ενεργοποίηση του νευρώνα εδώ είναι ουσιαστικά ένα μέτρο του πόσο θετικό είναι το σχετικό σταθμισμένο άθροισμα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "Αλλά ίσως δεν είναι ότι θέλετε ο νευρώνας να ανάβει όταν το σταθμισμένο άθροισμα είναι μεγαλύτερο από 0.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "Ίσως θέλετε να είναι ενεργή μόνο όταν το άθροισμα είναι μεγαλύτερο από 10.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "Δηλαδή, θέλετε κάποια μεροληψία για να είναι ανενεργή.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "Αυτό που θα κάνουμε τότε είναι να προσθέσουμε κάποιον άλλο αριθμό, όπως το αρνητικό 10, σε αυτό το σταθμισμένο άθροισμα πριν το περάσουμε από τη συνάρτηση σιγμοειδούς εξομάλυνσης.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "Αυτός ο πρόσθετος αριθμός ονομάζεται προκατάληψη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "Έτσι, τα βάρη σας λένε ποιο μοτίβο εικονοστοιχείων λαμβάνει αυτός ο νευρώνας στο δεύτερο επίπεδο και η προκατάληψη σας λέει πόσο υψηλό πρέπει να είναι το σταθμισμένο άθροισμα πριν ο νευρώνας αρχίσει να ενεργοποιείται με νόημα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "Και αυτός είναι μόνο ένας νευρώνας.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "Κάθε άλλος νευρώνας σε αυτό το στρώμα θα συνδεθεί και με τους 784 νευρώνες εικονοστοιχείων από το πρώτο στρώμα, και κάθε μία από αυτές τις 784 συνδέσεις έχει το δικό της βάρος που σχετίζεται με αυτήν.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "Επίσης, το καθένα έχει κάποια προκατάληψη, κάποιον άλλο αριθμό που προσθέτετε στο σταθμισμένο άθροισμα πριν το συμπιέσετε με το σιγμοειδές.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "Και αυτά είναι πολλά που πρέπει να σκεφτούμε!",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "Με αυτό το κρυφό στρώμα των 16 νευρώνων, είναι συνολικά 784 φορές 16 βάρη, μαζί με 16 προκαταλήψεις.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "Και όλα αυτά είναι μόνο οι συνδέσεις από το πρώτο στρώμα στο δεύτερο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "Οι συνδέσεις μεταξύ των άλλων στρωμάτων έχουν επίσης μια σειρά από βάρη και προκαταλήψεις που σχετίζονται με αυτές.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "Συνολικά, αυτό το δίκτυο έχει σχεδόν ακριβώς 13.000 συνολικά βάρη και προκαταλήψεις.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "13.000 κουμπιά και επιλογείς που μπορούν να ρυθμιστούν και να γυρίσουν για να κάνουν αυτό το δίκτυο να συμπεριφέρεται με διαφορετικούς τρόπους.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "Έτσι, όταν μιλάμε για μάθηση, αυτό στο οποίο αναφερόμαστε είναι να βάλουμε τον υπολογιστή να βρει μια έγκυρη ρύθμιση για όλους αυτούς τους πολλούς πολλούς αριθμούς, έτσι ώστε να λύσει πραγματικά το συγκεκριμένο πρόβλημα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "Ένα πείραμα σκέψης που είναι ταυτόχρονα διασκεδαστικό και κάπως τρομακτικό είναι να φανταστείτε να κάθεστε και να ρυθμίζετε όλα αυτά τα βάρη και τις προκαταλήψεις με το χέρι, ρυθμίζοντας σκόπιμα τους αριθμούς έτσι ώστε το δεύτερο στρώμα να εντοπίζει τις ακμές, το τρίτο στρώμα να εντοπίζει τα μοτίβα κ.λπ.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "Προσωπικά το βρίσκω αυτό ικανοποιητικό, αντί να αντιμετωπίζω το δίκτυο ως ένα εντελώς μαύρο κουτί, διότι όταν το δίκτυο δεν αποδίδει με τον τρόπο που περιμένετε, αν έχετε δημιουργήσει μια μικρή σχέση με το τι σημαίνουν στην πραγματικότητα αυτά τα βάρη και οι προκαταλήψεις, έχετε ένα σημείο εκκίνησης για να πειραματιστείτε με το πώς να αλλάξετε τη δομή για να βελτιωθεί.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "Ή όταν το δίκτυο λειτουργεί, αλλά όχι για τους λόγους που θα περιμένατε, η διερεύνηση του τι κάνουν τα βάρη και οι προκαταλήψεις είναι ένας καλός τρόπος για να αμφισβητήσετε τις υποθέσεις σας και να εκθέσετε πραγματικά όλο τον χώρο των πιθανών λύσεων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "Παρεμπιπτόντως, η πραγματική λειτουργία εδώ είναι λίγο δυσκίνητη για να την καταγράψετε, δεν νομίζετε;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "Επιτρέψτε μου λοιπόν να σας δείξω έναν πιο συμβολικά συμπαγή τρόπο αναπαράστασης αυτών των συνδέσεων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "Έτσι θα το βλέπατε αν επιλέγατε να διαβάσετε περισσότερα για τα νευρωνικά δίκτυα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Organize all of the activations from one layer into a column as a matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "Οργανώστε όλες τις ενεργοποιήσεις από ένα στρώμα σε μια στήλη, καθώς ένας πίνακας αντιστοιχεί στις συνδέσεις μεταξύ ενός στρώματος και ενός συγκεκριμένου νευρώνα στο επόμενο στρώμα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "Αυτό σημαίνει ότι το σταθμισμένο άθροισμα των ενεργοποιήσεων στο πρώτο επίπεδο σύμφωνα με αυτά τα βάρη αντιστοιχεί σε έναν από τους όρους του διανυσματικού γινομένου του πίνακα όλων όσων έχουμε στα αριστερά εδώ.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "Παρεμπιπτόντως, ένα μεγάλο μέρος της μηχανικής μάθησης εξαρτάται από την καλή κατανόηση της γραμμικής άλγεβρας, οπότε όσοι από εσάς θέλετε μια ωραία οπτική κατανόηση των πινάκων και τι σημαίνει πολλαπλασιασμός διανυσμάτων πινάκων, ρίξτε μια ματιά στη σειρά που έκανα για τη γραμμική άλγεβρα, ειδικά στο κεφάλαιο 3.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "Επιστρέφοντας στην έκφρασή μας, αντί να μιλάμε για την προσθήκη της προκατάληψης σε κάθε μία από αυτές τις τιμές ανεξάρτητα, την αναπαριστούμε οργανώνοντας όλες αυτές τις προκαταλήψεις σε ένα διάνυσμα και προσθέτοντας ολόκληρο το διάνυσμα στο προηγούμενο διανυσματικό γινόμενο του πίνακα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "Στη συνέχεια, ως τελικό βήμα, θα τυλίξω ένα σιγμοειδές γύρω από το εξωτερικό εδώ, και αυτό που υποτίθεται ότι αντιπροσωπεύει είναι ότι θα εφαρμόσετε τη σιγμοειδή συνάρτηση σε κάθε συγκεκριμένη συνιστώσα του διανύσματος που προκύπτει στο εσωτερικό.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "Έτσι, μόλις γράψετε αυτόν τον πίνακα βαρών και αυτά τα διανύσματα ως τα δικά τους σύμβολα, μπορείτε να επικοινωνήσετε την πλήρη μετάβαση των ενεργοποιήσεων από το ένα επίπεδο στο επόμενο σε μια εξαιρετικά σφιχτή και τακτοποιημένη μικρή έκφραση, και αυτό κάνει τον σχετικό κώδικα τόσο πολύ απλούστερο όσο και πολύ πιο γρήγορο, δεδομένου ότι πολλές βιβλιοθήκες βελτιστοποιούν τον πολλαπλασιασμό πινάκων.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "Θυμάστε που νωρίτερα είπα ότι αυτοί οι νευρώνες είναι απλά πράγματα που κρατούν αριθμούς;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "Φυσικά, οι συγκεκριμένοι αριθμοί που κρατούν εξαρτώνται από την εικόνα που τροφοδοτείτε, οπότε είναι πιο ακριβές να σκεφτείτε κάθε νευρώνα ως μια συνάρτηση, η οποία λαμβάνει τις εξόδους όλων των νευρώνων του προηγούμενου επιπέδου και δίνει έναν αριθμό μεταξύ 0 και 1.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "Στην πραγματικότητα, ολόκληρο το δίκτυο είναι απλώς μια συνάρτηση, η οποία δέχεται 784 αριθμούς ως είσοδο και δίνει 10 αριθμούς ως έξοδο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless, and in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "Πρόκειται για μια παράλογα περίπλοκη συνάρτηση, που περιλαμβάνει 13.000 παραμέτρους με τη μορφή αυτών των βαρών και των προκαταλήψεων που εντοπίζουν ορισμένα μοτίβα, και η οποία περιλαμβάνει την επανάληψη πολλών διανυσματικών γινομένων πινάκων και τη σιγμοειδή συνάρτηση τετραγωνισμού, αλλά είναι μια συνάρτηση, και κατά κάποιο τρόπο είναι κάπως καθησυχαστικό το γεγονός ότι φαίνεται περίπλοκη.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "Θέλω να πω, αν ήταν πιο απλό, τι ελπίδα θα είχαμε ότι θα μπορούσε να αντιμετωπίσει την πρόκληση της αναγνώρισης ψηφίων;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "Και πώς αντιμετωπίζει αυτή την πρόκληση;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "Πώς αυτό το δίκτυο μαθαίνει τα κατάλληλα βάρη και τις προκαταλήψεις μόνο με την εξέταση των δεδομένων;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "Αυτό θα δείξω στο επόμενο βίντεο, και θα αναλύσω λίγο περισσότερο τι πραγματικά κάνει το συγκεκριμένο δίκτυο που βλέπουμε.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "Τώρα είναι το σημείο που υποθέτω ότι θα έπρεπε να πω εγγραφείτε για να μείνετε ειδοποιημένοι για το πότε βγαίνουν βίντεο ή οποιαδήποτε νέα βίντεο, αλλά ρεαλιστικά οι περισσότεροι από εσάς δεν λαμβάνετε πραγματικά ειδοποιήσεις από το YouTube, έτσι δεν είναι;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "Ίσως πιο ειλικρινά θα έπρεπε να πω εγγραφείτε, ώστε τα νευρωνικά δίκτυα που διέπουν τον αλγόριθμο συστάσεων του YouTube να είναι προετοιμασμένα να πιστέψουν ότι θέλετε να δείτε περιεχόμενο από αυτό το κανάλι να σας προτείνεται.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Anyway stay posted for more.",
  "translatedText": "Εν πάση περιπτώσει μείνετε αναρτημένοι για περισσότερα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "Ευχαριστούμε πολύ όλους όσους υποστηρίζουν αυτά τα βίντεο στο Patreon.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "Το καλοκαίρι άργησα λίγο να προχωρήσω με τη σειρά probability, αλλά μετά από αυτό το έργο θα ξαναρχίσω να ασχολούμαι με αυτό, οπότε οι προστάτες μπορούν να περιμένουν ενημερώσεις εκεί.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "To close things off here I have with me Leisha Lee who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "Για να κλείσω τα πράγματα εδώ, έχω μαζί μου τη Leisha Lee, η οποία έκανε τη διδακτορική της διατριβή στη θεωρητική πλευρά της βαθιάς μάθησης και η οποία εργάζεται σήμερα σε μια εταιρεία επιχειρηματικών κεφαλαίων που ονομάζεται Amplify Partners, η οποία ευγενικά παρείχε μέρος της χρηματοδότησης για αυτό το βίντεο.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So Leisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "Έτσι, Leisha, ένα πράγμα που νομίζω ότι πρέπει να αναφέρουμε γρήγορα είναι αυτή η σιγμοειδής συνάρτηση.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "Όπως καταλαβαίνω, τα πρώιμα δίκτυα το χρησιμοποιούν αυτό για να συμπιέσουν το σχετικό σταθμισμένο άθροισμα σε αυτό το διάστημα μεταξύ μηδέν και ένα, με κίνητρο αυτή τη βιολογική αναλογία των νευρώνων που είναι είτε ανενεργοί είτε ενεργοί.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Exactly.",
  "translatedText": "Ακριβώς.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "Αλλά σχετικά λίγα σύγχρονα δίκτυα χρησιμοποιούν πλέον σιγμοειδές.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Yeah.",
  "translatedText": "Ναι.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "Είναι κάπως παλιάς σχολής, σωστά;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Yeah or rather relu seems to be much easier to train.",
  "translatedText": "Ναι, ή μάλλον το relu φαίνεται να εκπαιδεύεται πολύ πιο εύκολα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And relu stands for rectified linear unit?",
  "translatedText": "Και το relu σημαίνει διορθωμένη γραμμική μονάδα;",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not and so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "Ναι, είναι αυτό το είδος συνάρτησης όπου απλά παίρνετε ένα μέγιστο του μηδενός και του a όπου το a δίνεται από αυτό που εξηγούσατε στο βίντεο και αυτό που νομίζω ότι ήταν ένα είδος κινήτρου, ήταν εν μέρει από μια βιολογική αναλογία με το πώς οι νευρώνες είτε ενεργοποιούνται είτε όχι και έτσι αν περάσει ένα ορισμένο κατώφλι θα είναι η συνάρτηση ταυτότητας, αλλά αν δεν το κάνει τότε απλά δεν θα ενεργοποιηθεί, οπότε θα είναι μηδέν, οπότε είναι ένα είδος απλοποίησης.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried relu and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "Η χρήση σιγμοειδών δεν βοήθησε στην εκπαίδευση ή ήταν πολύ δύσκολο να εκπαιδευτεί σε κάποιο σημείο και οι άνθρωποι απλά δοκίμασαν το relu και έτυχε να λειτουργήσει πολύ καλά για αυτά τα απίστευτα βαθιά νευρωνικά δίκτυα.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "All right thank you Alicia.",
  "translatedText": "Εντάξει, σας ευχαριστώ Alicia.",
  "model": "DeepL",
  "n_reviews": 0
 }
]