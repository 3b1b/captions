[
 {
  "input": "This is a 3.",
  "translatedText": "Это 3.",
  "n_reviews": 0,
  "start": 4.22,
  "end": 5.4
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "Он небрежно написан и визуализирован с чрезвычайно низким разрешением 28x28 пикселей, но ваш мозг без труда распознает его как 3.",
  "n_reviews": 0,
  "start": 6.06,
  "end": 13.72
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "И я хочу, чтобы вы на минутку оценили, насколько безумно то, что мозг может делать это так легко.",
  "n_reviews": 0,
  "start": 14.34,
  "end": 18.96
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "Я имею в виду, что это, это и это также можно распознать как 3 секунды, хотя конкретные значения каждого пикселя сильно отличаются от одного изображения к другому.",
  "n_reviews": 0,
  "start": 19.7,
  "end": 28.32
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "Конкретные светочувствительные клетки вашего глаза, которые срабатывают, когда вы видите эту цифру 3, сильно отличаются от тех, которые срабатывают, когда вы видите эту цифру 3.",
  "n_reviews": 0,
  "start": 28.9,
  "end": 36.94
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "Но что-то в вашей безумно умной зрительной коре воспринимает эти изображения как представляющие одну и ту же идею, в то же время распознавая другие изображения как отдельные идеи.",
  "n_reviews": 0,
  "start": 37.52,
  "end": 48.26
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "Но если бы я сказал вам, эй, сядьте и напишите для меня программу, которая принимает сетку размером 28x28 пикселей вот так и выводит одно число от 0 до 10, сообщая вам, что, по ее мнению, представляет собой эта цифра, ну, задача будет выглядеть так: от комично тривиального до пугающе сложного.",
  "n_reviews": 0,
  "start": 49.22,
  "end": 66.18
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "Если вы не жили под камнем, я думаю, мне вряд ли нужно объяснять актуальность и важность машинного обучения и нейронных сетей для настоящего и будущего.",
  "n_reviews": 0,
  "start": 67.16,
  "end": 74.64
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "Но здесь я хочу показать вам, что на самом деле представляет собой нейронная сеть, не предполагая никакого фона, и помочь визуализировать то, что она делает, не как модное словечко, а как часть математики.",
  "n_reviews": 0,
  "start": 75.12,
  "end": 84.46
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "Я надеюсь, что вы уйдете с ощущением, что сама структура мотивирована, и почувствуете, что знаете, что она означает, когда читаете или слышите об обучении цитированием нейронной сети.",
  "n_reviews": 0,
  "start": 85.02,
  "end": 94.34
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "Это видео будет посвящено структурному компоненту этого процесса, а следующее будет посвящено обучению.",
  "n_reviews": 0,
  "start": 95.36,
  "end": 100.26
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "Что мы собираемся сделать, так это собрать нейронную сеть, которая сможет научиться распознавать рукописные цифры.",
  "n_reviews": 0,
  "start": 100.96,
  "end": 106.04
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "Это своего рода классический пример представления темы, и я рад придерживаться здесь существующего положения вещей, потому что в конце двух видеороликов я хочу указать вам на пару хороших ресурсов, где вы можете узнать больше, и где вы можете скачать код, который делает это, и поиграть с ним на своем компьютере.",
  "n_reviews": 0,
  "start": 109.36,
  "end": 123.08
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "Существует множество вариантов нейронных сетей, и в последние годы наблюдается своего рода бум исследований этих вариантов, но в этих двух вводных видеороликах мы с вами просто рассмотрим простейшую, простую ванильную форму без каких-либо дополнительных излишеств.",
  "n_reviews": 0,
  "start": 125.04,
  "end": 139.18
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "Это своего рода необходимая предпосылка для понимания любого из более мощных современных вариантов, и, поверьте мне, нам еще предстоит осмыслить множество сложностей.",
  "n_reviews": 0,
  "start": 139.86,
  "end": 148.6
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "Но даже в этой простейшей форме он может научиться распознавать рукописные цифры, что очень здорово для компьютера.",
  "n_reviews": 0,
  "start": 149.12,
  "end": 156.52
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "И в то же время вы увидите, что он не оправдывает пары надежд, которые мы могли бы на него возлагать.",
  "n_reviews": 0,
  "start": 157.48,
  "end": 162.28
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "Как следует из названия, нейронные сети созданы по принципу мозга, но давайте разберемся в этом.",
  "n_reviews": 0,
  "start": 163.38,
  "end": 168.5
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "Что такое нейроны и в каком смысле они связаны между собой?",
  "n_reviews": 0,
  "start": 168.52,
  "end": 171.66
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "Прямо сейчас, когда я говорю «нейрон», все, о чем я хочу, чтобы вы подумали, — это о вещи, которая содержит число, особенно число от 0 до 1.",
  "n_reviews": 0,
  "start": 172.5,
  "end": 180.44
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "На самом деле это не более того.",
  "n_reviews": 0,
  "start": 180.68,
  "end": 182.56
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "Например, сеть начинается с группы нейронов, соответствующей каждому из пикселей входного изображения размером 28x28, что в общей сложности составляет 784 нейрона.",
  "n_reviews": 0,
  "start": 183.78,
  "end": 194.22
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "Каждый из них содержит число, которое представляет значение шкалы серого соответствующего пикселя в диапазоне от 0 для черных пикселей до 1 для белых пикселей.",
  "n_reviews": 0,
  "start": 194.7,
  "end": 204.38
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "Это число внутри нейрона называется его активацией, и вы, возможно, имеете в виду, что каждый нейрон светится, когда его активация имеет большое число.",
  "n_reviews": 0,
  "start": 205.3,
  "end": 214.16
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "Итак, все эти 784 нейрона составляют первый слой нашей сети.",
  "n_reviews": 0,
  "start": 216.72,
  "end": 221.86
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "Теперь перейдем к последнему слою: здесь 10 нейронов, каждый из которых представляет одну из цифр.",
  "n_reviews": 0,
  "start": 226.5,
  "end": 231.36
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "Активация этих нейронов (опять же некоторое число от 0 до 1) показывает, насколько система считает, что данное изображение соответствует данной цифре.",
  "n_reviews": 0,
  "start": 232.04,
  "end": 242.12
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "Есть также пара промежуточных слоев, называемых скрытыми слоями, которые на данный момент должны быть просто гигантским знаком вопроса о том, как, черт возьми, будет осуществляться этот процесс распознавания цифр.",
  "n_reviews": 0,
  "start": 243.04,
  "end": 253.6
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "В этой сети я выбрал два скрытых слоя, каждый из которых содержит 16 нейронов, и, надо признать, это довольно произвольный выбор.",
  "n_reviews": 0,
  "start": 254.26,
  "end": 260.56
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "Честно говоря, я выбрал два слоя, исходя из того, как я хочу мотивировать структуру в данный момент, и 16, ну, это было просто хорошее число, чтобы поместиться на экране.",
  "n_reviews": 0,
  "start": 261.02,
  "end": 268.2
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "На практике здесь есть много возможностей для экспериментов с конкретной структурой.",
  "n_reviews": 0,
  "start": 268.78,
  "end": 272.34
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "В зависимости от того, как работает сеть, активации на одном уровне определяют активации следующего уровня.",
  "n_reviews": 0,
  "start": 273.02,
  "end": 278.48
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "И, конечно же, суть сети как механизма обработки информации сводится к тому, как именно активации на одном уровне вызывают активации на следующем уровне.",
  "n_reviews": 0,
  "start": 279.2,
  "end": 288.58
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "Это должно быть во многом аналогично тому, как в биологических сетях нейронов активация одних групп нейронов вызывает активацию других.",
  "n_reviews": 0,
  "start": 289.14,
  "end": 297.18
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "Сеть, которую я здесь показываю, уже обучена распознавать цифры, и позвольте мне показать вам, что я имею в виду.",
  "n_reviews": 0,
  "start": 298.12,
  "end": 303.4
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "Это означает, что если вы подаете изображение, освещая все 784 нейрона входного слоя в соответствии с яркостью каждого пикселя изображения, этот шаблон активаций вызывает некоторый очень специфический шаблон в следующем слое, который вызывает некоторый шаблон в следующем слое. это, что, наконец, дает некоторый узор в выходном слое.",
  "n_reviews": 0,
  "start": 303.64,
  "end": 322.08
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "И самый яркий нейрон этого выходного слоя — это, так сказать, выбор сети, какую цифру представляет это изображение.",
  "n_reviews": 0,
  "start": 322.56,
  "end": 329.4
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "И прежде чем приступить к математическим расчетам того, как один слой влияет на следующий или как работает обучение, давайте просто поговорим о том, почему вообще разумно ожидать, что такая многоуровневая структура будет вести себя разумно.",
  "n_reviews": 0,
  "start": 332.56,
  "end": 343.52
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "Чего мы здесь ожидаем?",
  "n_reviews": 0,
  "start": 344.06,
  "end": 345.22
 },
 {
  "input": "What is the best hope for what those middle layers might be doing?",
  "translatedText": "Какова наилучшая надежда для этих средних слоев?",
  "n_reviews": 0,
  "start": 345.4,
  "end": 347.6
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "Что ж, когда мы с вами распознаем цифры, мы собираем воедино различные компоненты.",
  "n_reviews": 0,
  "start": 348.92,
  "end": 353.52
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "У цифры 9 есть петля вверху и линия справа.",
  "n_reviews": 0,
  "start": 354.2,
  "end": 356.82
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "У цифры 8 также есть верхняя петля, но она соединена с другой нижней петлей.",
  "n_reviews": 0,
  "start": 357.38,
  "end": 361.18
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "4 по сути разбивается на три конкретные линии и тому подобное.",
  "n_reviews": 0,
  "start": 361.98,
  "end": 366.82
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "Теперь, в идеальном мире, мы могли бы надеяться, что каждый нейрон предпоследнего слоя соответствует одному из этих подкомпонентов, и что каждый раз, когда вы подаете изображение, скажем, с петлей вверху, например, с 9 или 8, происходит некоторая конкретный нейрон, активация которого будет близка к 1.",
  "n_reviews": 0,
  "start": 367.6,
  "end": 383.78
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "И я не имею в виду эту конкретную петлю пикселей, я надеюсь, что любой вообще петлевой узор вверху активирует этот нейрон.",
  "n_reviews": 0,
  "start": 384.5,
  "end": 391.56
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "Таким образом, для перехода от третьего уровня к последнему необходимо просто узнать, какая комбинация подкомпонентов соответствует каким цифрам.",
  "n_reviews": 0,
  "start": 392.44,
  "end": 400.04
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "Конечно, это только отбрасывает проблему в сторону, потому что как вы распознаете эти подкомпоненты или даже узнаете, какими должны быть правильные подкомпоненты?",
  "n_reviews": 0,
  "start": 401.0,
  "end": 407.64
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "И я еще даже не говорил о том, как один слой влияет на следующий, но пробежимся на минутку по этому поводу.",
  "n_reviews": 0,
  "start": 408.06,
  "end": 413.06
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "Распознавание цикла также может быть разбито на подзадачи.",
  "n_reviews": 0,
  "start": 413.68,
  "end": 416.68
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "Один из разумных способов сделать это — сначала распознать различные небольшие грани, из которых он состоит.",
  "n_reviews": 0,
  "start": 417.28,
  "end": 422.78
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "Точно так же длинная линия, подобная той, которую вы можете видеть в цифрах 1, 4 или 7, на самом деле представляет собой просто длинное ребро, или, может быть, вы думаете о ней как об определенном узоре из нескольких меньших ребер.",
  "n_reviews": 0,
  "start": 423.78,
  "end": 434.32
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "Так что, возможно, мы надеемся, что каждый нейрон второго слоя сети соответствует различным значимым маленьким ребрам.",
  "n_reviews": 0,
  "start": 435.14,
  "end": 442.72
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "Возможно, когда появляется такое изображение, оно освещает все нейроны, связанные примерно с 8–10 конкретными маленькими ребрами, что, в свою очередь, освещает нейроны, связанные с верхней петлей и длинной вертикальной линией, а они освещают нейрон, связанный с 9.",
  "n_reviews": 0,
  "start": 443.54,
  "end": 459.72
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "Является ли это тем, что на самом деле делает наша окончательная сеть, — это другой вопрос, к которому я вернусь, как только мы увидим, как обучать сеть, но это надежда, которая у нас может быть, своего рода цель с многоуровневой структурой. так.",
  "n_reviews": 0,
  "start": 460.68,
  "end": 472.54
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "Более того, вы можете себе представить, как возможность обнаружения краев и узоров, подобная этой, может оказаться очень полезной для других задач распознавания изображений.",
  "n_reviews": 0,
  "start": 473.16,
  "end": 480.3
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "И даже помимо распознавания изображений, вы, возможно, захотите сделать множество интеллектуальных вещей, которые разбиваются на уровни абстракции.",
  "n_reviews": 0,
  "start": 480.88,
  "end": 487.28
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "Например, анализ речи включает в себя получение необработанного аудио и выделение отдельных звуков, которые объединяются в определенные слоги, которые объединяются в слова, которые объединяются в фразы и более абстрактные мысли и т. д.",
  "n_reviews": 0,
  "start": 488.04,
  "end": 500.06
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "Но возвращаясь к тому, как все это на самом деле работает, представьте себе, как прямо сейчас вы разрабатываете, как именно активации на одном уровне могут определять следующий.",
  "n_reviews": 0,
  "start": 501.1,
  "end": 509.92
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "Цель состоит в том, чтобы создать некий механизм, который мог бы объединять пиксели в края, края в узоры или узоры в цифры.",
  "n_reviews": 0,
  "start": 510.86,
  "end": 518.98
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "И если приблизить один очень конкретный пример, скажем, есть надежда на то, что один конкретный нейрон во втором слое поймет, имеет ли изображение край в этой области.",
  "n_reviews": 0,
  "start": 519.44,
  "end": 530.62
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "Возникает вопрос: какие параметры должна иметь сеть?",
  "n_reviews": 0,
  "start": 531.44,
  "end": 535.1
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "Какие циферблаты и ручки вы должны настроить, чтобы они были достаточно выразительными, чтобы потенциально захватить этот узор, или любой другой пиксельный узор, или узор, в котором несколько краев могут образовывать петлю, и другие подобные вещи?",
  "n_reviews": 0,
  "start": 535.64,
  "end": 547.78
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "Что ж, мы присвоим вес каждой связи между нашим нейроном и нейронами первого слоя.",
  "n_reviews": 0,
  "start": 548.72,
  "end": 555.56
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "Эти веса являются просто числами.",
  "n_reviews": 0,
  "start": 556.32,
  "end": 557.7
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "Затем возьмите все эти активации из первого слоя и вычислите их взвешенную сумму в соответствии с этими весами.",
  "n_reviews": 0,
  "start": 558.54,
  "end": 565.5
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "Я считаю полезным представить эти веса как организованные в небольшую сетку, и я собираюсь использовать зеленые пиксели для обозначения положительных весов и красные пиксели для обозначения отрицательных весов, где яркость этого пикселя составляет некоторую величину. свободное представление значения веса.",
  "n_reviews": 0,
  "start": 567.7,
  "end": 581.78
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "Теперь, если мы сделали веса, связанные почти со всеми пикселями, равными нулю, за исключением некоторых положительных весов в этой области, которые нас интересуют, тогда взвешенная сумма всех значений пикселей на самом деле будет просто складывать значения пикселя только в регион, который нас волнует.",
  "n_reviews": 0,
  "start": 582.78,
  "end": 597.82
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "И если вы действительно хотите понять, есть ли здесь край, вы можете установить отрицательные веса, связанные с окружающими пикселями.",
  "n_reviews": 0,
  "start": 599.14,
  "end": 606.6
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "Тогда сумма будет наибольшей, если средние пиксели яркие, а окружающие пиксели темнее.",
  "n_reviews": 0,
  "start": 607.48,
  "end": 612.7
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "Когда вы вычисляете взвешенную сумму, подобную этой, вы можете получить любое число, но для этой сети мы хотим, чтобы активации имели некоторое значение от 0 до 1.",
  "n_reviews": 0,
  "start": 614.26,
  "end": 623.54
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "Поэтому обычно приходится закачивать эту взвешенную сумму в некоторую функцию, которая сжимает линию действительных чисел в диапазон от 0 до 1.",
  "n_reviews": 0,
  "start": 624.12,
  "end": 632.14
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "И обычная функция, которая делает это, называется сигмовидной функцией, также известной как логистическая кривая.",
  "n_reviews": 0,
  "start": 632.46,
  "end": 637.42
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "По сути, очень отрицательные входные данные приближаются к 0, положительные входные данные — к 1, и они постепенно увеличиваются около входного значения 0.",
  "n_reviews": 0,
  "start": 638.0,
  "end": 646.6
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "Таким образом, активация нейрона здесь, по сути, является мерой того, насколько положительна соответствующая взвешенная сумма.",
  "n_reviews": 0,
  "start": 649.12,
  "end": 656.36
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "Но, возможно, дело не в том, что вы хотите, чтобы нейрон загорался, когда взвешенная сумма больше 0.",
  "n_reviews": 0,
  "start": 657.54,
  "end": 661.88
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "Возможно, вы хотите, чтобы он был активен только тогда, когда сумма больше, скажем, 10.",
  "n_reviews": 0,
  "start": 662.28,
  "end": 666.36
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "То есть вам нужна некоторая предвзятость, чтобы он был неактивным.",
  "n_reviews": 0,
  "start": 666.84,
  "end": 670.26
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "Затем мы просто добавим какое-нибудь другое число, например минус 10, к этой взвешенной сумме, прежде чем подключить ее через функцию сжатия сигмовидной кишки.",
  "n_reviews": 0,
  "start": 671.38,
  "end": 679.66
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "Это дополнительное число называется смещением.",
  "n_reviews": 0,
  "start": 680.58,
  "end": 682.44
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "Таким образом, веса говорят вам, какой шаблон пикселей улавливает этот нейрон во втором слое, а смещение говорит вам, насколько высокой должна быть взвешенная сумма, прежде чем нейрон начнет становиться значимо активным.",
  "n_reviews": 0,
  "start": 683.46,
  "end": 695.18
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "И это всего лишь один нейрон.",
  "n_reviews": 0,
  "start": 696.12,
  "end": 697.68
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "Каждый второй нейрон в этом слое будет связан со всеми 784 пиксельными нейронами первого слоя, и каждому из этих 784 соединений будет присвоен свой собственный вес.",
  "n_reviews": 0,
  "start": 698.28,
  "end": 710.94
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "Кроме того, у каждого из них есть некоторая погрешность, какое-то другое число, которое вы добавляете к взвешенной сумме, прежде чем сжимать ее сигмоидой.",
  "n_reviews": 0,
  "start": 711.6,
  "end": 717.6
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "И это есть над чем подумать!",
  "n_reviews": 0,
  "start": 718.11,
  "end": 719.54
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "С этим скрытым слоем из 16 нейронов это в общей сложности 784 раза по 16 весов, а также 16 смещений.",
  "n_reviews": 0,
  "start": 719.96,
  "end": 727.98
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "И все это — лишь связи первого слоя со вторым.",
  "n_reviews": 0,
  "start": 728.84,
  "end": 731.94
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "Связи между другими слоями также имеют множество весов и смещений, связанных с ними.",
  "n_reviews": 0,
  "start": 732.52,
  "end": 737.34
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "В целом эта сеть имеет почти ровно 13 000 весов и смещений.",
  "n_reviews": 0,
  "start": 738.34,
  "end": 743.8
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "13 000 ручек и дисков, которые можно настраивать и поворачивать, чтобы заставить эту сеть вести себя по-разному.",
  "n_reviews": 0,
  "start": 743.8,
  "end": 749.96
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "Итак, когда мы говорим об обучении, имеется в виду заставить компьютер найти допустимую настройку для всех этих многих чисел, чтобы он действительно решил поставленную задачу.",
  "n_reviews": 0,
  "start": 751.04,
  "end": 761.36
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "Один мысленный эксперимент, который одновременно забавен и отчасти ужасен, состоит в том, чтобы представить, что вы садитесь и вручную устанавливаете все эти веса и смещения, целенаправленно настраивая числа так, чтобы второй слой улавливал края, третий слой улавливал закономерности, и т. д.",
  "n_reviews": 0,
  "start": 762.62,
  "end": 776.58
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "Лично меня это удовлетворяет, а не просто рассматривать сеть как полный черный ящик, потому что, когда сеть не работает так, как вы ожидаете, если вы выстроили хоть какое-то отношение к тому, что на самом деле означают эти веса и предвзятости , у вас есть отправная точка для экспериментов с тем, как изменить структуру для улучшения.",
  "n_reviews": 0,
  "start": 776.98,
  "end": 794.18
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "Или, когда сеть работает, но не по тем причинам, которые вы могли ожидать, изучение того, что делают веса и смещения, — это хороший способ бросить вызов вашим предположениям и по-настоящему раскрыть все пространство возможных решений.",
  "n_reviews": 0,
  "start": 794.96,
  "end": 805.82
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "Кстати, записывать эту функцию немного громоздко, вам не кажется?",
  "n_reviews": 0,
  "start": 806.84,
  "end": 810.68
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "Итак, позвольте мне показать вам более компактный способ представления этих связей.",
  "n_reviews": 0,
  "start": 812.5,
  "end": 817.14
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "Вот как вы это увидите, если решите узнать больше о нейронных сетях.",
  "n_reviews": 0,
  "start": 817.66,
  "end": 820.52
 },
 {
  "input": "Organize all of the activations from one layer into a column as a vector. Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "Организуйте все активации одного слоя в столбце, поскольку матрица соответствует связям между одним слоем и конкретным нейроном в следующем слое.",
  "n_reviews": 0,
  "start": 821.38,
  "end": 838.0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "Это означает, что взятие взвешенной суммы активаций в первом слое в соответствии с этими весами соответствует одному из членов матричного векторного произведения всего, что у нас есть здесь слева.",
  "n_reviews": 0,
  "start": 838.54,
  "end": 849.88
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "Между прочим, большая часть машинного обучения сводится к хорошему пониманию линейной алгебры, поэтому для тех из вас, кто хочет получить хорошее визуальное представление о матрицах и о том, что означает умножение матриц на вектор, взгляните на серию, которую я делал. линейная алгебра, особенно глава 3.",
  "n_reviews": 0,
  "start": 854.0,
  "end": 868.6
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "Возвращаясь к нашему выражению, вместо того, чтобы говорить о добавлении смещения к каждому из этих значений независимо, мы представляем его, организуя все эти смещения в вектор и добавляя весь вектор к предыдущему произведению матрицы-вектора.",
  "n_reviews": 0,
  "start": 869.24,
  "end": 882.3
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "Затем, в качестве последнего шага, я оберну здесь сигмоиду снаружи, и это должно означать, что вы собираетесь применить сигмовидную функцию к каждому конкретному компоненту результирующего вектора внутри.",
  "n_reviews": 0,
  "start": 883.28,
  "end": 894.74
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "Итак, как только вы запишете эту весовую матрицу и эти векторы как отдельные символы, вы сможете передать полный переход активаций от одного слоя к другому в чрезвычайно сжатом и аккуратном маленьком выражении, и это делает соответствующий код намного проще и проще. намного быстрее, поскольку многие библиотеки чертовски оптимизируют умножение матриц.",
  "n_reviews": 0,
  "start": 895.94,
  "end": 915.66
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "Помните, как ранее я говорил, что эти нейроны — это просто вещи, хранящие числа?",
  "n_reviews": 0,
  "start": 917.82,
  "end": 921.46
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "Ну, конечно, конкретные числа, которые они содержат, зависят от изображения, которое вы вводите, поэтому на самом деле правильнее думать о каждом нейроне как о функции, которая принимает выходные данные всех нейронов предыдущего слоя и выдает число. между 0 и 1.",
  "n_reviews": 0,
  "start": 922.22,
  "end": 938.34
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "На самом деле вся сеть — это просто функция, которая принимает 784 числа на вход и выдаёт 10 чисел на выходе.",
  "n_reviews": 0,
  "start": 939.2,
  "end": 947.06
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless. And in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "Это абсурдно сложная функция, которая включает в себя 13 000 параметров в виде весов и смещений, которые улавливают определенные шаблоны, и которая включает в себя итерацию множества матричных векторных произведений и сигмовидной функции сжатия, но, тем не менее, это всего лишь функция, и в то, что это выглядит сложным, успокаивает.",
  "n_reviews": 0,
  "start": 947.56,
  "end": 966.66
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "Я имею в виду, если бы все было проще, какая у нас была бы надежда, что он сможет справиться с задачей распознавания цифр?",
  "n_reviews": 0,
  "start": 967.34,
  "end": 972.28
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "И как он справляется с этой задачей?",
  "n_reviews": 0,
  "start": 973.34,
  "end": 974.7
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "Как эта сеть изучает соответствующие веса и смещения, просто просматривая данные?",
  "n_reviews": 0,
  "start": 975.08,
  "end": 979.36
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "Что ж, это то, что я покажу в следующем видео, а также немного углублюсь в то, что на самом деле делает эта конкретная сеть, которую мы видим.",
  "n_reviews": 0,
  "start": 980.14,
  "end": 986.12
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "Теперь настал момент, я полагаю, я должен сказать, что подписывайтесь, чтобы получать уведомления о выходе видео или любых новых видео, но на самом деле большинство из вас на самом деле не получают уведомления от YouTube, не так ли?",
  "n_reviews": 0,
  "start": 987.58,
  "end": 997.42
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "Может быть, более честно я должен сказать, подпишитесь, чтобы нейронные сети, лежащие в основе алгоритма рекомендаций YouTube, были готовы поверить, что вы хотите, чтобы вам рекомендовали контент с этого канала.",
  "n_reviews": 0,
  "start": 998.02,
  "end": 1007.88
 },
 {
  "input": "Anyway, stay posted for more.",
  "translatedText": "В любом случае оставайтесь в курсе, чтобы узнать больше.",
  "n_reviews": 0,
  "start": 1008.56,
  "end": 1009.94
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "Большое спасибо всем, кто поддерживает эти видео на Patreon.",
  "n_reviews": 0,
  "start": 1010.76,
  "end": 1013.5
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "Этим летом я немного медленно продвигался в серии вероятностей, но я возвращаюсь к ней после этого проекта, так что, посетители, вы можете следить за обновлениями там.",
  "n_reviews": 0,
  "start": 1014.0,
  "end": 1021.9
 },
 {
  "input": "To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "В заключение, со мной здесь Лейша Ли, которая защитила докторскую диссертацию по теоретической стороне глубокого обучения и в настоящее время работает в венчурной фирме Amplify Partners, которая любезно предоставила часть финансирования для этого видео.",
  "n_reviews": 0,
  "start": 1023.6,
  "end": 1034.62
 },
 {
  "input": "So Lisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "Итак, Лейша, я думаю, нам следует быстро вспомнить об этой сигмовидной функции.",
  "n_reviews": 0,
  "start": 1035.46,
  "end": 1039.12
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "Насколько я понимаю, ранние сети используют это, чтобы сжать соответствующую взвешенную сумму в интервал между нулем и единицей, вы знаете, это отчасти мотивировано этой биологической аналогией, когда нейроны либо неактивны, либо активны.",
  "n_reviews": 0,
  "start": 1039.7,
  "end": 1049.84
 },
 {
  "input": "Exactly.",
  "translatedText": "Точно.",
  "n_reviews": 0,
  "start": 1050.28,
  "end": 1050.3
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "Но относительно немногие современные сети действительно используют сигмовидную форму.",
  "n_reviews": 0,
  "start": 1050.56,
  "end": 1054.04
 },
 {
  "input": "Yeah.",
  "translatedText": "Ага.",
  "n_reviews": 0,
  "start": 1054.32,
  "end": 1054.32
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "Это что-то вроде старой школы, да?",
  "n_reviews": 0,
  "start": 1054.44,
  "end": 1055.54
 },
 {
  "input": "Yeah or rather ReLU seems to be much easier to train.",
  "translatedText": "Да, или, скорее, релу, кажется, гораздо легче тренировать.",
  "n_reviews": 0,
  "start": 1055.76,
  "end": 1058.98
 },
 {
  "input": "And ReLU, ReLU stands for rectified linear unit?",
  "translatedText": "А relu означает выпрямленную линейную единицу?",
  "n_reviews": 0,
  "start": 1059.4,
  "end": 1062.34
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not. And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "Да, это такая функция, в которой вы просто берете максимум, равный нулю, а где a определяется тем, что вы объясняли в видео, и это было как бы мотивировано, я думаю, частично биологической аналогией с тем, как нейроны будет либо активирована, либо нет, и поэтому, если она преодолеет определенный порог, это будет функция идентичности, но если бы это не было, то она просто не была бы активирована, поэтому она была бы равна нулю, так что это своего рода упрощение.",
  "n_reviews": 0,
  "start": 1062.68,
  "end": 1090.84
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "Использование сигмоид не помогло в обучении, или в какой-то момент обучение было очень трудным, и люди просто попробовали relu, и оно очень хорошо сработало для этих невероятно глубоких нейронных сетей.",
  "n_reviews": 0,
  "start": 1091.16,
  "end": 1104.62
 },
 {
  "input": "All right thank you Lisha.",
  "translatedText": "Хорошо, спасибо, Алисия.",
  "n_reviews": 0,
  "start": 1105.1,
  "end": 1105.64
 }
]