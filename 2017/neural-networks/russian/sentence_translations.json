[
 {
  "input": "This is a 3.",
  "translatedText": "Это 3.",
  "from_community_srt": "Это тройка.",
  "n_reviews": 0,
  "start": 4.22,
  "end": 5.4
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "Он небрежно написан и визуализирован с чрезвычайно низким разрешением 28x28 пикселей, но ваш мозг без труда распознает его как 3.",
  "from_community_srt": "Она небрежно написана и визуализирована в чрезвычайно маленьком разрешении 28 на 28 пикселей. Но ваш мозг без труда узнаёт в ней тройку.",
  "n_reviews": 0,
  "start": 6.06,
  "end": 13.72
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "И я хочу, чтобы вы на минутку оценили, насколько безумно то, что мозг может делать это так легко.",
  "from_community_srt": "И я хотел бы чтобы вы оценили тот изумительный факт, что мозг может делать это с лёгкостью.",
  "n_reviews": 0,
  "start": 14.34,
  "end": 18.96
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "Я имею в виду, что это, это и это также можно распознать как 3 секунды, хотя конкретные значения каждого пикселя сильно отличаются от одного изображения к другому.",
  "from_community_srt": "Я о том, что это, это и это тоже распознаётся как тройки, хотя конкретные значения пикселей очень разнятся от картинки к картинке.",
  "n_reviews": 0,
  "start": 19.7,
  "end": 28.32
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "Конкретные светочувствительные клетки вашего глаза, которые срабатывают, когда вы видите эту цифру 3, сильно отличаются от тех, которые срабатывают, когда вы видите эту цифру 3.",
  "from_community_srt": "Набор светочувствительных клеток в вашем глазу, которые возбуждаются, когда вы видите эту тройку, сильно отличается от набора, когда вы видите эту тройку.",
  "n_reviews": 0,
  "start": 28.9,
  "end": 36.94
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "Но что-то в вашей безумно умной зрительной коре воспринимает эти изображения как представляющие одну и ту же идею, в то же время распознавая другие изображения как отдельные идеи.",
  "from_community_srt": "Но что-то в вашей невероятно умной зрительной коре, решает что они представляют одну сущность. Одновременно понимая что другие картинки описывают другие сущности.",
  "n_reviews": 0,
  "start": 37.52,
  "end": 48.26
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "Но если бы я сказал вам, эй, сядьте и напишите для меня программу, которая принимает сетку размером 28x28 пикселей вот так и выводит одно число от 0 до 10, сообщая вам, что, по ее мнению, представляет собой эта цифра, ну, задача будет выглядеть так: от комично тривиального до пугающе сложного.",
  "from_community_srt": "Но если бы я сказал вам: Эй, напиши мне программу, которая принимает на вход сетку 28 на 28 пикселей как показано, и выдаёт одно число от 0 до 9, угадывая что это за число, то задача оказалась бы от смешного простой до назойливо сложной.",
  "n_reviews": 0,
  "start": 49.22,
  "end": 66.18
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "Если вы не жили под камнем, я думаю, мне вряд ли нужно объяснять актуальность и важность машинного обучения и нейронных сетей для настоящего и будущего.",
  "from_community_srt": "Если только вы не живёте в пещере, я думаю мне не придётся долго убеждать вас в актуальности и важности машинного обучения и нейросетей в настоящем и будущем.",
  "n_reviews": 0,
  "start": 67.16,
  "end": 74.64
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "Но здесь я хочу показать вам, что на самом деле представляет собой нейронная сеть, не предполагая никакого фона, и помочь визуализировать то, что она делает, не как модное словечко, а как часть математики.",
  "from_community_srt": "Но то чего я добиваюсь - это показать вам что такое нейросеть на самом деле, предполагая что вы понятия не имеете, и помочь визуализировать её работу. Не как модное словечко, а с точки зрения математики.",
  "n_reviews": 0,
  "start": 75.12,
  "end": 84.46
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "Я надеюсь, что вы уйдете с ощущением, что сама структура мотивирована, и почувствуете, что знаете, что она означает, когда читаете или слышите об обучении цитированием нейронной сети.",
  "from_community_srt": "Я бы хотел чтобы вы получили представление о том чем вообще обусловлена такая структура и чтобы вы понимали, когда читаете или слышите, что значит так называемое \"обучение\" нейросетей.",
  "n_reviews": 0,
  "start": 85.02,
  "end": 94.34
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "Это видео будет посвящено структурному компоненту этого процесса, а следующее будет посвящено обучению.",
  "from_community_srt": "Это видео будет посвящено только структуре её компонентов, а следующее затронет обучение.",
  "n_reviews": 0,
  "start": 95.36,
  "end": 100.26
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "Что мы собираемся сделать, так это собрать нейронную сеть, которая сможет научиться распознавать рукописные цифры.",
  "from_community_srt": "Мы собираемся построить нейросеть, которую можно будет обучить распознавать написанные вручную цифры.",
  "n_reviews": 0,
  "start": 100.96,
  "end": 106.04
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "Это своего рода классический пример представления темы, и я рад придерживаться здесь существующего положения вещей, потому что в конце двух видеороликов я хочу указать вам на пару хороших ресурсов, где вы можете узнать больше, и где вы можете скачать код, который делает это, и поиграть с ним на своем компьютере.",
  "from_community_srt": "Это своего рода классический пример для введения в данную тему. И я хотел бы придерживаться здесь статуса-кво, потому-что после двух видеороликов я хочу указать вам на пару хороших ресурсов, где вы сможете узнать больше, и откуда вы сможете скачать код, решающий эту задачу, и самостоятельно поиграть с ним у себя.",
  "n_reviews": 0,
  "start": 109.36,
  "end": 123.08
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "Существует множество вариантов нейронных сетей, и в последние годы наблюдается своего рода бум исследований этих вариантов, но в этих двух вводных видеороликах мы с вами просто рассмотрим простейшую, простую ванильную форму без каких-либо дополнительных излишеств.",
  "from_community_srt": "Существует огромное количество вариантов нейросетей и в последние годы наблюдается своего рода бум в исследованиях на эту тему, но в этих двух вводных видео вы и я будем рассматривать простейший вариант, без всяких наворотов.",
  "n_reviews": 0,
  "start": 125.04,
  "end": 139.18
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "Это своего рода необходимая предпосылка для понимания любого из более мощных современных вариантов, и, поверьте мне, нам еще предстоит осмыслить множество сложностей.",
  "from_community_srt": "Это своего рода необходимый базис для понимая любых других более современных вариантов, и поверьте мне он тем не менее достаточно сложен для нашего понимания.",
  "n_reviews": 0,
  "start": 139.86,
  "end": 148.6
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "Но даже в этой простейшей форме он может научиться распознавать рукописные цифры, что очень здорово для компьютера.",
  "from_community_srt": "Но даже в такой простейшей форме сеть может обучится распознавать рукописные цифры, что совсем не плохо для компьютера.",
  "n_reviews": 0,
  "start": 149.12,
  "end": 156.52
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "И в то же время вы увидите, что он не оправдывает пары надежд, которые мы могли бы на него возлагать.",
  "from_community_srt": "Но так же вы увидите что она оправдает возможно не все наши ожидания.",
  "n_reviews": 0,
  "start": 157.48,
  "end": 162.28
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "Как следует из названия, нейронные сети созданы по принципу мозга, но давайте разберемся в этом.",
  "from_community_srt": "Как ясно из названия идея нейросетей была заимствованна у мозга. Но давайте разложим это по полочкам,",
  "n_reviews": 0,
  "start": 163.38,
  "end": 168.5
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "Что такое нейроны и в каком смысле они связаны между собой?",
  "from_community_srt": "что такое нейроны и как они связанны между собой? Сейчас,",
  "n_reviews": 0,
  "start": 168.52,
  "end": 171.66
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "Прямо сейчас, когда я говорю «нейрон», все, о чем я хочу, чтобы вы подумали, — это о вещи, которая содержит число, особенно число от 0 до 1.",
  "from_community_srt": "когда я говорю нейрон, я хочу чтобы вы представляли просто нечто, содержащее число. Конкретнее, число от 0 до 1.",
  "n_reviews": 0,
  "start": 172.5,
  "end": 180.44
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "На самом деле это не более того.",
  "from_community_srt": "На самом деле это не далеко от истины.",
  "n_reviews": 0,
  "start": 180.68,
  "end": 182.56
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "Например, сеть начинается с группы нейронов, соответствующей каждому из пикселей входного изображения размером 28x28, что в общей сложности составляет 784 нейрона.",
  "from_community_srt": "Например, нейросеть начинается с множества нейронов отвечающих за представление всех 28 на 28 пикселей, входного изображения. То есть всего 784 нейрона.",
  "n_reviews": 0,
  "start": 183.78,
  "end": 194.22
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "Каждый из них содержит число, которое представляет значение шкалы серого соответствующего пикселя в диапазоне от 0 для черных пикселей до 1 для белых пикселей.",
  "from_community_srt": "Каждый из них содержит число, выражающее градацию серого в соответствующем пикселе. В диапазоне от 0 для чёрных пикселей и до 1 для белых пикселей.",
  "n_reviews": 0,
  "start": 194.7,
  "end": 204.38
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "Это число внутри нейрона называется его активацией, и вы, возможно, имеете в виду, что каждый нейрон светится, когда его активация имеет большое число.",
  "from_community_srt": "Это число внутри нейрона называется его активацией. Вы можете представить это себе как-будто нейрон зажигается, когда содержит большее число.",
  "n_reviews": 0,
  "start": 205.3,
  "end": 214.16
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "Итак, все эти 784 нейрона составляют первый слой нашей сети.",
  "from_community_srt": "Итак, все эти 784 нейрона составляют первый слой нашей нейросети.",
  "n_reviews": 0,
  "start": 216.72,
  "end": 221.86
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "Теперь перейдем к последнему слою: здесь 10 нейронов, каждый из которых представляет одну из цифр.",
  "from_community_srt": "Перепрыгнем на последний слой, он содержит десять нейронов, каждый представляет одно число.",
  "n_reviews": 0,
  "start": 226.5,
  "end": 231.36
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "Активация этих нейронов (опять же некоторое число от 0 до 1) показывает, насколько система считает, что данное изображение соответствует данной цифре.",
  "from_community_srt": "Активация в этих нейронах, опять же число от 0 до 1, выражает насколько система уверена что входное изображение содержит соответствующую цифру.",
  "n_reviews": 0,
  "start": 232.04,
  "end": 242.12
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "Есть также пара промежуточных слоев, называемых скрытыми слоями, которые на данный момент должны быть просто гигантским знаком вопроса о том, как, черт возьми, будет осуществляться этот процесс распознавания цифр.",
  "from_community_srt": "Так же есть пара слоёв посередине, называемые скрытыми слоями, которые на данный момент будут просто большим вопросом - как, чёрт побери, будет работать этот механизм распознавания цифр.",
  "n_reviews": 0,
  "start": 243.04,
  "end": 253.6
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "В этой сети я выбрал два скрытых слоя, каждый из которых содержит 16 нейронов, и, надо признать, это довольно произвольный выбор.",
  "from_community_srt": "Для данной сети я выбрал два скрытых слоя, каждый по шестнадцать нейронов, и в принципе, это произвольный выбор.",
  "n_reviews": 0,
  "start": 254.26,
  "end": 260.56
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "Честно говоря, я выбрал два слоя, исходя из того, как я хочу мотивировать структуру в данный момент, и 16, ну, это было просто хорошее число, чтобы поместиться на экране.",
  "from_community_srt": "Но честно говоря, я выбрал два слоя представляя как я хочу чтобы она работала, об этом через секунду, а шестнадцать, ну это просто хорошо выглядит на экране.",
  "n_reviews": 0,
  "start": 261.02,
  "end": 268.2
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "На практике здесь есть много возможностей для экспериментов с конкретной структурой.",
  "from_community_srt": "На практике тут есть большое поле для экспериментов над структурой.",
  "n_reviews": 0,
  "start": 268.78,
  "end": 272.34
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "В зависимости от того, как работает сеть, активации на одном уровне определяют активации следующего уровня.",
  "from_community_srt": "Принцип работы нейросети в том, что активация в одном слое определяет активацию в следующем слое.",
  "n_reviews": 0,
  "start": 273.02,
  "end": 278.48
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "И, конечно же, суть сети как механизма обработки информации сводится к тому, как именно активации на одном уровне вызывают активации на следующем уровне.",
  "from_community_srt": "И разумеется суть нейросети как механизма обработки информации сводится к тому, как именно эти активации в одном слое приводят к активациям в следующем слое.",
  "n_reviews": 0,
  "start": 279.2,
  "end": 288.58
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "Это должно быть во многом аналогично тому, как в биологических сетях нейронов активация одних групп нейронов вызывает активацию других.",
  "from_community_srt": "Это грубо сравнивают с тем как работают биологические нейросети, некоторая группа нейронов возбуждается, вызывая возбуждение другой определённой группы.",
  "n_reviews": 0,
  "start": 289.14,
  "end": 297.18
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "Сеть, которую я здесь показываю, уже обучена распознавать цифры, и позвольте мне показать вам, что я имею в виду.",
  "from_community_srt": "Итак, сеть, которую я привожу здесь, уже обучена распознаванию цифр. Давайте объясню что я имею ввиду.",
  "n_reviews": 0,
  "start": 298.12,
  "end": 303.4
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "Это означает, что если вы подаете изображение, освещая все 784 нейрона входного слоя в соответствии с яркостью каждого пикселя изображения, этот шаблон активаций вызывает некоторый очень специфический шаблон в следующем слое, который вызывает некоторый шаблон в следующем слое. это, что, наконец, дает некоторый узор в выходном слое.",
  "from_community_srt": "Это значит, что если дать (скормить) ей картинку, зажигание всех 784 нейронов входного уровня, согласно яркости каждого пикселя на картинке, такой шаблон активаций, приведёт к конкретно определённому шаблону в следующем слое, который приведёт к какому-то шаблону в следующем, который наконец выдаст какой-то шаблон в финальном слое.",
  "n_reviews": 0,
  "start": 303.64,
  "end": 322.08
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "И самый яркий нейрон этого выходного слоя — это, так сказать, выбор сети, какую цифру представляет это изображение.",
  "from_community_srt": "И самый яркий нейрон этого выходного слоя, это, так сказать, \"выбор\" нейросети по вопросу какую цифру представляет данная картинка.",
  "n_reviews": 0,
  "start": 322.56,
  "end": 329.4
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "И прежде чем приступить к математическим расчетам того, как один слой влияет на следующий или как работает обучение, давайте просто поговорим о том, почему вообще разумно ожидать, что такая многоуровневая структура будет вести себя разумно.",
  "from_community_srt": "И прежде чем углубляться в математику того, как один слой влияет на следующий, или как происходит обучение, давайте просто поговорим почему вообще такая слоёная структура должна действовать разумно.",
  "n_reviews": 0,
  "start": 332.56,
  "end": 343.52
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "Чего мы здесь ожидаем?",
  "from_community_srt": "Чего нам ожидать,",
  "n_reviews": 0,
  "start": 344.06,
  "end": 345.22
 },
 {
  "input": "What is the best hope for what those middle layers might be doing?",
  "translatedText": "Какова наилучшая надежда для этих средних слоев?",
  "from_community_srt": "что в лучшем случае смогут делать эти промежуточные слои? Ну,",
  "n_reviews": 0,
  "start": 345.4,
  "end": 347.6
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "Что ж, когда мы с вами распознаем цифры, мы собираем воедино различные компоненты.",
  "from_community_srt": "когда вы и я распознаём цифры, мы сводим воедино различные компоненты.",
  "n_reviews": 0,
  "start": 348.92,
  "end": 353.52
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "У цифры 9 есть петля вверху и линия справа.",
  "from_community_srt": "Девятка содержит кружок вверху и линию справа.",
  "n_reviews": 0,
  "start": 354.2,
  "end": 356.82
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "У цифры 8 также есть верхняя петля, но она соединена с другой нижней петлей.",
  "from_community_srt": "Восьмёрка так же содержит кружок вверху, но и парный ему внизу.",
  "n_reviews": 0,
  "start": 357.38,
  "end": 361.18
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "4 по сути разбивается на три конкретные линии и тому подобное.",
  "from_community_srt": "Четвёрка по сути разбивается на три определённых линии, и тому подобное.",
  "n_reviews": 0,
  "start": 361.98,
  "end": 366.82
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "Теперь, в идеальном мире, мы могли бы надеяться, что каждый нейрон предпоследнего слоя соответствует одному из этих подкомпонентов, и что каждый раз, когда вы подаете изображение, скажем, с петлей вверху, например, с 9 или 8, происходит некоторая конкретный нейрон, активация которого будет близка к 1.",
  "from_community_srt": "И в идеальном мире мы можем ожидать что каждый нейрон из второго слоя и далее соотносится с одним из этих компонентов. Что каждый раз когда вы скармливаете картинку, скажем, с кружком наверху, как 9 или 8, существует определённый нейрон, чья активация станет близка к единице.",
  "n_reviews": 0,
  "start": 367.6,
  "end": 383.78
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "И я не имею в виду эту конкретную петлю пикселей, я надеюсь, что любой вообще петлевой узор вверху активирует этот нейрон.",
  "from_community_srt": "И я не имею ввиду этот конкретный набор пикселей, предполагается что, что угодно, похожее на кружок в верхней части, возбудит этот нейрон.",
  "n_reviews": 0,
  "start": 384.5,
  "end": 391.56
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "Таким образом, для перехода от третьего уровня к последнему необходимо просто узнать, какая комбинация подкомпонентов соответствует каким цифрам.",
  "from_community_srt": "Таким образом переход от третьего слоя к последнему просто представляет знания о том, какая комбинация компонентов, какой цифре соответствует.",
  "n_reviews": 0,
  "start": 392.44,
  "end": 400.04
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "Конечно, это только отбрасывает проблему в сторону, потому что как вы распознаете эти подкомпоненты или даже узнаете, какими должны быть правильные подкомпоненты?",
  "from_community_srt": "Конечно это просто перевод стрелок, ведь как распознать эти компоненты, или даже понять какие компоненты должны присутствовать.",
  "n_reviews": 0,
  "start": 401.0,
  "end": 407.64
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "И я еще даже не говорил о том, как один слой влияет на следующий, но пробежимся на минутку по этому поводу.",
  "from_community_srt": "И я всё ещё не сказал как один слой влияет на следующий, но давайте рассмотрим следующее.",
  "n_reviews": 0,
  "start": 408.06,
  "end": 413.06
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "Распознавание цикла также может быть разбито на подзадачи.",
  "from_community_srt": "Распознавание кружка так же может быть разбито на подзадачи.",
  "n_reviews": 0,
  "start": 413.68,
  "end": 416.68
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "Один из разумных способов сделать это — сначала распознать различные небольшие грани, из которых он состоит.",
  "from_community_srt": "Один из разумных способов сделать это заключается в предварительном распознавании различных маленьких граней из которых он образован.",
  "n_reviews": 0,
  "start": 417.28,
  "end": 422.78
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "Точно так же длинная линия, подобная той, которую вы можете видеть в цифрах 1, 4 или 7, на самом деле представляет собой просто длинное ребро, или, может быть, вы думаете о ней как об определенном узоре из нескольких меньших ребер.",
  "from_community_srt": "Аналогично длинная черта, подобная той что есть в цифрах 1, или 4, или 7, это всего лишь длинная грань, или её можно представить определённым шаблоном из нескольких меньших граней.",
  "n_reviews": 0,
  "start": 423.78,
  "end": 434.32
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "Так что, возможно, мы надеемся, что каждый нейрон второго слоя сети соответствует различным значимым маленьким ребрам.",
  "from_community_srt": "Так что, ВОЗМОЖНО, мы надеемся что каждый нейрон из второго слоя сети сопоставляется с различными релевантными меленькими гранями.",
  "n_reviews": 0,
  "start": 435.14,
  "end": 442.72
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "Возможно, когда появляется такое изображение, оно освещает все нейроны, связанные примерно с 8–10 конкретными маленькими ребрами, что, в свою очередь, освещает нейроны, связанные с верхней петлей и длинной вертикальной линией, а они освещают нейрон, связанный с 9.",
  "from_community_srt": "Возможно, когда на вход поступает картинка вроде этой, она зажигает все нейроны, ассоциированные с примерно 8 - 10 определёнными небольшими гранями, которые, в свою очередь, зажигают нейроны, ассоциированные с кружком вверху и длинной вертикальной чертой, а те зажигают нейрон ассоциированный с девяткой.",
  "n_reviews": 0,
  "start": 443.54,
  "end": 459.72
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "Является ли это тем, что на самом деле делает наша окончательная сеть, — это другой вопрос, к которому я вернусь, как только мы увидим, как обучать сеть, но это надежда, которая у нас может быть, своего рода цель с многоуровневой структурой. так.",
  "from_community_srt": "Будет ли в конце концов так действовать наша сеть или нет, это другой вопрос. К которому я вернусь, когда мы увидим как обучается сеть. Но это может быть нашим ориентиром, своего рода целью для такой слоёной структуры.",
  "n_reviews": 0,
  "start": 460.68,
  "end": 472.54
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "Более того, вы можете себе представить, как возможность обнаружения краев и узоров, подобная этой, может оказаться очень полезной для других задач распознавания изображений.",
  "from_community_srt": "Более того, представьте как такое определение граней и шаблонов может быть весьма полезно в задачах по распознаванию других образов.",
  "n_reviews": 0,
  "start": 473.16,
  "end": 480.3
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "И даже помимо распознавания изображений, вы, возможно, захотите сделать множество интеллектуальных вещей, которые разбиваются на уровни абстракции.",
  "from_community_srt": "И это не только распознавание образов, есть множество потенциальных интеллектуальных задач, которые разбиваются на слои абстракции.",
  "n_reviews": 0,
  "start": 480.88,
  "end": 487.28
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "Например, анализ речи включает в себя получение необработанного аудио и выделение отдельных звуков, которые объединяются в определенные слоги, которые объединяются в слова, которые объединяются в фразы и более абстрактные мысли и т. д.",
  "from_community_srt": "Разбор речи, например, требует получения сырого аудио и выделения отдельных звуков, которые комбинируются для образования слогов, которые комбинируются в слова, затем во фразы и более абстрактные мысли,",
  "n_reviews": 0,
  "start": 488.04,
  "end": 500.06
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "Но возвращаясь к тому, как все это на самом деле работает, представьте себе, как прямо сейчас вы разрабатываете, как именно активации на одном уровне могут определять следующий.",
  "from_community_srt": "и т.д. Но возвращаясь к тому как собственно что-либо из этого работает. Представьте себе сейчас идею того как активации в одном слое могут определять активации в следующем.",
  "n_reviews": 0,
  "start": 501.1,
  "end": 509.92
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "Цель состоит в том, чтобы создать некий механизм, который мог бы объединять пиксели в края, края в узоры или узоры в цифры.",
  "from_community_srt": "Цель - получить механизм, который предположительно сможет комбинировать пиксели в грани, или грани в шаблоны, или шаблоны в цифры.",
  "n_reviews": 0,
  "start": 510.86,
  "end": 518.98
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "И если приблизить один очень конкретный пример, скажем, есть надежда на то, что один конкретный нейрон во втором слое поймет, имеет ли изображение край в этой области.",
  "from_community_srt": "И чтобы сконцентрироваться на конкретном примере, предположим цель одного конкретного нейрона во втором слое, определять содержит ли картинка грань в этой, указанной области.",
  "n_reviews": 0,
  "start": 519.44,
  "end": 530.62
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "Возникает вопрос: какие параметры должна иметь сеть?",
  "from_community_srt": "Первый вопрос - какие параметры должны быть у сети.",
  "n_reviews": 0,
  "start": 531.44,
  "end": 535.1
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "Какие циферблаты и ручки вы должны настроить, чтобы они были достаточно выразительными, чтобы потенциально захватить этот узор, или любой другой пиксельный узор, или узор, в котором несколько краев могут образовывать петлю, и другие подобные вещи?",
  "from_community_srt": "Какие табло и ручки настройки должны быть доступны, достаточно выразительные, чтобы дать потенциальную возможность обнаружить этот шаблон или любой другой шаблон пикселей, или шаблон кружка из нескольких граней и тому подобное.",
  "n_reviews": 0,
  "start": 535.64,
  "end": 547.78
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "Что ж, мы присвоим вес каждой связи между нашим нейроном и нейронами первого слоя.",
  "from_community_srt": "Ну, вот что мы сделаем - мы назначим вес каждому соединению между нашим нейроном и нейронами из первого слоя.",
  "n_reviews": 0,
  "start": 548.72,
  "end": 555.56
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "Эти веса являются просто числами.",
  "from_community_srt": "Эти веса - просто числа.",
  "n_reviews": 0,
  "start": 556.32,
  "end": 557.7
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "Затем возьмите все эти активации из первого слоя и вычислите их взвешенную сумму в соответствии с этими весами.",
  "from_community_srt": "Затем возьмём все активации из первого слоя и посчитаем их взвешенную сумму согласно этим весам.",
  "n_reviews": 0,
  "start": 558.54,
  "end": 565.5
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "Я считаю полезным представить эти веса как организованные в небольшую сетку, и я собираюсь использовать зеленые пиксели для обозначения положительных весов и красные пиксели для обозначения отрицательных весов, где яркость этого пикселя составляет некоторую величину. свободное представление значения веса.",
  "from_community_srt": "Я считаю сподручно представлять эти веса собранными в свою собственную небольшую сетку, и я буду использовать зелёные пиксели для отображения положительных весов и красные пиксели для отображения отрицательных весов, где яркость пикселя - примерное выражение значения веса.",
  "n_reviews": 0,
  "start": 567.7,
  "end": 581.78
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "Теперь, если мы сделали веса, связанные почти со всеми пикселями, равными нулю, за исключением некоторых положительных весов в этой области, которые нас интересуют, тогда взвешенная сумма всех значений пикселей на самом деле будет просто складывать значения пикселя только в регион, который нас волнует.",
  "from_community_srt": "Итак, если мы установим веса, связанные с практически всеми пикселями в ноль, за исключением некоторого количества положительных весов в интересующей нас области, тогда получение взвешенной суммы всех пикселей сведётся к суммированию значений пикселей только в интересующей нас области.",
  "n_reviews": 0,
  "start": 582.78,
  "end": 597.82
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "И если вы действительно хотите понять, есть ли здесь край, вы можете установить отрицательные веса, связанные с окружающими пикселями.",
  "from_community_srt": "А если вы хотите определить есть ли там именно грань, вы можете добавить некоторое количество отрицательных весов, ассоциированных с окружающим пикселями.",
  "n_reviews": 0,
  "start": 599.14,
  "end": 606.6
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "Тогда сумма будет наибольшей, если средние пиксели яркие, а окружающие пиксели темнее.",
  "from_community_srt": "Тогда сумма будет наибольшей когда средние пиксели ярче, а окружающие их темнее.",
  "n_reviews": 0,
  "start": 607.48,
  "end": 612.7
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "Когда вы вычисляете взвешенную сумму, подобную этой, вы можете получить любое число, но для этой сети мы хотим, чтобы активации имели некоторое значение от 0 до 1.",
  "from_community_srt": "Когда вы вычислите такую взвешенную сумму у вас может получиться любое число, но для данной сети мы хотим чтобы активации представлялись значением от 0 до 1.",
  "n_reviews": 0,
  "start": 614.26,
  "end": 623.54
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "Поэтому обычно приходится закачивать эту взвешенную сумму в некоторую функцию, которая сжимает линию действительных чисел в диапазон от 0 до 1.",
  "from_community_srt": "Так что логично вогнать эту взвешенную сумму в какую-то функцию, которая втиснет реальный диапазон значений в диапазон от 0 до 1.",
  "n_reviews": 0,
  "start": 624.12,
  "end": 632.14
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "И обычная функция, которая делает это, называется сигмовидной функцией, также известной как логистическая кривая.",
  "from_community_srt": "Обычно функция, которая делает это, называется сигмоидой или логистической кривой.",
  "n_reviews": 0,
  "start": 632.46,
  "end": 637.42
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "По сути, очень отрицательные входные данные приближаются к 0, положительные входные данные — к 1, и они постепенно увеличиваются около входного значения 0.",
  "from_community_srt": "По сути, сильно отрицательный ввод оказывается близким к нулю, сильно положительный ввод оказывается близким к единице, и она монотонно возрастает на входных значения вокруг нуля.",
  "n_reviews": 0,
  "start": 638.0,
  "end": 646.6
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "Таким образом, активация нейрона здесь, по сути, является мерой того, насколько положительна соответствующая взвешенная сумма.",
  "from_community_srt": "Таким образом, активация нейрона это по сути мера того насколько положительна соответствующая взвешенная сумма.",
  "n_reviews": 0,
  "start": 649.12,
  "end": 656.36
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "Но, возможно, дело не в том, что вы хотите, чтобы нейрон загорался, когда взвешенная сумма больше 0.",
  "from_community_srt": "Но возможно не требуется чтобы нейрон зажигался когда взвешенная сумма больше нуля.",
  "n_reviews": 0,
  "start": 657.54,
  "end": 661.88
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "Возможно, вы хотите, чтобы он был активен только тогда, когда сумма больше, скажем, 10.",
  "from_community_srt": "Возможно вы хотите чтобы он активировался только когда сумма больше, например,",
  "n_reviews": 0,
  "start": 662.28,
  "end": 666.36
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "То есть вам нужна некоторая предвзятость, чтобы он был неактивным.",
  "from_community_srt": "10. То есть вам требуется некий сдвиг его активности.",
  "n_reviews": 0,
  "start": 666.84,
  "end": 670.26
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "Затем мы просто добавим какое-нибудь другое число, например минус 10, к этой взвешенной сумме, прежде чем подключить ее через функцию сжатия сигмовидной кишки.",
  "from_community_srt": "Тогда надо просто добавить некое число, например -10, к этой взвешенной сумме, до передачи её в сигмоидную функцию сжатия.",
  "n_reviews": 0,
  "start": 671.38,
  "end": 679.66
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "Это дополнительное число называется смещением.",
  "from_community_srt": "Это дополнительное число называется \"сдвиг\".",
  "n_reviews": 0,
  "start": 680.58,
  "end": 682.44
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "Таким образом, веса говорят вам, какой шаблон пикселей улавливает этот нейрон во втором слое, а смещение говорит вам, насколько высокой должна быть взвешенная сумма, прежде чем нейрон начнет становиться значимо активным.",
  "from_community_srt": "Таким образом, веса отвечают за то, какой шаблон пикселей этот нейрон из второго слоя отбирает, а сдвиг определяет насколько большой должна быть взвешенная сумма, чтобы нейрон стал достаточно активным.",
  "n_reviews": 0,
  "start": 683.46,
  "end": 695.18
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "И это всего лишь один нейрон.",
  "from_community_srt": "Это только один нейрон.",
  "n_reviews": 0,
  "start": 696.12,
  "end": 697.68
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "Каждый второй нейрон в этом слое будет связан со всеми 784 пиксельными нейронами первого слоя, и каждому из этих 784 соединений будет присвоен свой собственный вес.",
  "from_community_srt": "Каждый нейрон из этого слоя будет соединён со всеми 784 пиксельными нейронами из первого слоя. И каждое из этих 784 соединений будет иметь свой ассоциированный с ним вес.",
  "n_reviews": 0,
  "start": 698.28,
  "end": 710.94
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "Кроме того, у каждого из них есть некоторая погрешность, какое-то другое число, которое вы добавляете к взвешенной сумме, прежде чем сжимать ее сигмоидой.",
  "from_community_srt": "Так же у каждого есть сдвиг, какое-то число, добавляемое к взвешенной сумме до сжатия в сигноиде.",
  "n_reviews": 0,
  "start": 711.6,
  "end": 717.6
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "И это есть над чем подумать!",
  "from_community_srt": "И тут есть над чем задуматься.",
  "n_reviews": 0,
  "start": 718.11,
  "end": 719.54
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "С этим скрытым слоем из 16 нейронов это в общей сложности 784 раза по 16 весов, а также 16 смещений.",
  "from_community_srt": "С этим скрытым слоем из 16 нейронов, получается всего 784х16 весов, плюс 16 сдвигов.",
  "n_reviews": 0,
  "start": 719.96,
  "end": 727.98
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "И все это — лишь связи первого слоя со вторым.",
  "from_community_srt": "И всё это просто соединения между первым и вторыми слоями.",
  "n_reviews": 0,
  "start": 728.84,
  "end": 731.94
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "Связи между другими слоями также имеют множество весов и смещений, связанных с ними.",
  "from_community_srt": "Соединения между другими слоями так же содержат кучу весов и сдвигов,",
  "n_reviews": 0,
  "start": 732.52,
  "end": 737.34
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "В целом эта сеть имеет почти ровно 13 000 весов и смещений.",
  "from_community_srt": "связанным с ними. В результате, данная сеть всего содержит почти ровно 13 000 весов и сдвигов.",
  "n_reviews": 0,
  "start": 738.34,
  "end": 743.8
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "13 000 ручек и дисков, которые можно настраивать и поворачивать, чтобы заставить эту сеть вести себя по-разному.",
  "from_community_srt": "13 000 ручек и табло, которые можно крутить и настраивать чтобы менять поведение этой сети.",
  "n_reviews": 0,
  "start": 743.8,
  "end": 749.96
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "Итак, когда мы говорим об обучении, имеется в виду заставить компьютер найти допустимую настройку для всех этих многих чисел, чтобы он действительно решил поставленную задачу.",
  "from_community_srt": "Так что когда мы говорим об обучении, имеется ввиду - заставить компьютер найти корректные значения для всех, всех этих чисел, так, чтобы это решило поставленную задачу.",
  "n_reviews": 0,
  "start": 751.04,
  "end": 761.36
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "Один мысленный эксперимент, который одновременно забавен и отчасти ужасен, состоит в том, чтобы представить, что вы садитесь и вручную устанавливаете все эти веса и смещения, целенаправленно настраивая числа так, чтобы второй слой улавливал края, третий слой улавливал закономерности, и т. д.",
  "from_community_srt": "Одновременно забавный и ужасающий мысленный эксперимент, это представить себе настройку всех этих весов и сдвигов вручную, намеренный подбор чисел, чтобы второй слой выбирал грани, третий слой выбирал шаблоны и т.д.",
  "n_reviews": 0,
  "start": 762.62,
  "end": 776.58
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "Лично меня это удовлетворяет, а не просто рассматривать сеть как полный черный ящик, потому что, когда сеть не работает так, как вы ожидаете, если вы выстроили хоть какое-то отношение к тому, что на самом деле означают эти веса и предвзятости , у вас есть отправная точка для экспериментов с тем, как изменить структуру для улучшения.",
  "from_community_srt": "Лично я считаю это хорошим подходом, чем потом трактовать сеть как чёрный ящик. Потому-что когда сеть не работает так, как вы ожидаете, если вы немного представляете что на самом деле означают эти веса и сдвиги, у вас будет начальная точка для изменения структуры и улучшения результата.",
  "n_reviews": 0,
  "start": 776.98,
  "end": 794.18
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "Или, когда сеть работает, но не по тем причинам, которые вы могли ожидать, изучение того, что делают веса и смещения, — это хороший способ бросить вызов вашим предположениям и по-настоящему раскрыть все пространство возможных решений.",
  "from_community_srt": "Или если сеть работает, но неожиданным способом, вникание в то, что означают веса и сдвиги - хороший вызов вашему мышлению, открывающий всю полноту возможных решений.",
  "n_reviews": 0,
  "start": 794.96,
  "end": 805.82
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "Кстати, записывать эту функцию немного громоздко, вам не кажется?",
  "from_community_srt": "Кстати, используемая здесь запись функции имеет немого громоздкий вид,",
  "n_reviews": 0,
  "start": 806.84,
  "end": 810.68
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "Итак, позвольте мне показать вам более компактный способ представления этих связей.",
  "from_community_srt": "согласны? Так что позвольте я покажу вам более компактный способ представления этих соединений,",
  "n_reviews": 0,
  "start": 812.5,
  "end": 817.14
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "Вот как вы это увидите, если решите узнать больше о нейронных сетях.",
  "from_community_srt": "то как вы будите их видеть, если решите читать дальше про нейросети.",
  "n_reviews": 0,
  "start": 817.66,
  "end": 820.52
 },
 {
  "input": "Organize all of the activations from one layer into a column as a vector. Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "Организуйте все активации одного слоя в столбце, поскольку матрица соответствует связям между одним слоем и конкретным нейроном в следующем слое.",
  "from_community_srt": "Объединим все активации слоя в столбец - вектор. Затем объединим все веса в матрицу, каждая строка которой описывает соединения между нейронами одного слоя с конкретным нейроном следующего слоя.",
  "n_reviews": 0,
  "start": 821.38,
  "end": 838.0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "Это означает, что взятие взвешенной суммы активаций в первом слое в соответствии с этими весами соответствует одному из членов матричного векторного произведения всего, что у нас есть здесь слева.",
  "from_community_srt": "Выходит, получение взвешенной суммы активаций первого слоя в соответствии с этими весами соотносится с одним из членов матричного произведения всего того, что у нас слева.",
  "n_reviews": 0,
  "start": 838.54,
  "end": 849.88
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "Между прочим, большая часть машинного обучения сводится к хорошему пониманию линейной алгебры, поэтому для тех из вас, кто хочет получить хорошее визуальное представление о матрицах и о том, что означает умножение матриц на вектор, взгляните на серию, которую я делал. линейная алгебра, особенно глава 3.",
  "from_community_srt": "Кстати, большАя часть машинного обучения сводится к хорошему пониманию линейной алгебры, так что все, желающие увидеть простое и наглядное объяснение матриц а так же что означает матричное произведение, посмотрите серию моих видео про линейную алгебру, особенно третью главу.",
  "n_reviews": 0,
  "start": 854.0,
  "end": 868.6
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "Возвращаясь к нашему выражению, вместо того, чтобы говорить о добавлении смещения к каждому из этих значений независимо, мы представляем его, организуя все эти смещения в вектор и добавляя весь вектор к предыдущему произведению матрицы-вектора.",
  "from_community_srt": "Возвращаясь к нашему выражению, вместо добавления сдвига к каждому из этих значений по отдельности мы представим это описанием всех наших сдвигов в виде вектора, и сложением этого вектора с полученным ранее матричным произведением.",
  "n_reviews": 0,
  "start": 869.24,
  "end": 882.3
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "Затем, в качестве последнего шага, я оберну здесь сигмоиду снаружи, и это должно означать, что вы собираетесь применить сигмовидную функцию к каждому конкретному компоненту результирующего вектора внутри.",
  "from_community_srt": "Тогда останется лишь обернуть всё это в сигмоиду, что означает применение сигмоидной функции к каждому члену получившегося внутри вектора.",
  "n_reviews": 0,
  "start": 883.28,
  "end": 894.74
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "Итак, как только вы запишете эту весовую матрицу и эти векторы как отдельные символы, вы сможете передать полный переход активаций от одного слоя к другому в чрезвычайно сжатом и аккуратном маленьком выражении, и это делает соответствующий код намного проще и проще. намного быстрее, поскольку многие библиотеки чертовски оптимизируют умножение матриц.",
  "from_community_srt": "Таким образом, дав этой матрице весов и этим векторам собственные обозначения, вы сможете выражать весь переход активаций от одного слоя к следующему в виде чрезвычайно компактного и аккуратного выражения. И это делает соответствующий код и гораздо проще, и гораздо быстрее, так как многие библиотеки чертовски оптимизированы под матричные умножения.",
  "n_reviews": 0,
  "start": 895.94,
  "end": 915.66
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "Помните, как ранее я говорил, что эти нейроны — это просто вещи, хранящие числа?",
  "from_community_srt": "Помните как я ранее говорил что нейроны это просто сущности,",
  "n_reviews": 0,
  "start": 917.82,
  "end": 921.46
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "Ну, конечно, конкретные числа, которые они содержат, зависят от изображения, которое вы вводите, поэтому на самом деле правильнее думать о каждом нейроне как о функции, которая принимает выходные данные всех нейронов предыдущего слоя и выдает число. между 0 и 1.",
  "from_community_srt": "содержащие числа? Ну и, содержащиеся в них числа конечно зависят от того какое изображение вы скормили. Так что правильнее представлять каждый нейрон в виде функции, которая принимает выходы со всех нейронов предыдущего слоя и выплёвывает число от 0 до 1.",
  "n_reviews": 0,
  "start": 922.22,
  "end": 938.34
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "На самом деле вся сеть — это просто функция, которая принимает 784 числа на вход и выдаёт 10 чисел на выходе.",
  "from_community_srt": "На самом деле вся сеть - это просто функция, которая берёт на вход 784 числа и выплёвывает 10 чисел на выходе.",
  "n_reviews": 0,
  "start": 939.2,
  "end": 947.06
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless. And in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "Это абсурдно сложная функция, которая включает в себя 13 000 параметров в виде весов и смещений, которые улавливают определенные шаблоны, и которая включает в себя итерацию множества матричных векторных произведений и сигмовидной функции сжатия, но, тем не менее, это всего лишь функция, и в то, что это выглядит сложным, успокаивает.",
  "from_community_srt": "Это до абсурда сложная функция, которая включает 13 000 параметров в виде этих весов и сдвигов, которые отвечают за определённые шаблоны, и требующая выполнения множества матричных умножений и вычислений сигмоидных функций сжатия, но тем не менее, это просто функция. И в каком-то смысле это логично,",
  "n_reviews": 0,
  "start": 947.56,
  "end": 966.66
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "Я имею в виду, если бы все было проще, какая у нас была бы надежда, что он сможет справиться с задачей распознавания цифр?",
  "from_community_srt": "что она выглядит сложной, я имею ввиду, если бы она была проще, с чего бы мы решили что она способна решить задачу распознавания цифр.",
  "n_reviews": 0,
  "start": 967.34,
  "end": 972.28
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "И как он справляется с этой задачей?",
  "n_reviews": 0,
  "start": 973.34,
  "end": 974.7
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "Как эта сеть изучает соответствующие веса и смещения, просто просматривая данные?",
  "from_community_srt": "А как она решает эту задачу? Как эта сеть находит подходящие веса и сдвиги просто смотря на данные?",
  "n_reviews": 0,
  "start": 975.08,
  "end": 979.36
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "Что ж, это то, что я покажу в следующем видео, а также немного углублюсь в то, что на самом деле делает эта конкретная сеть, которую мы видим.",
  "from_community_srt": "Хм, это я покажу в следующем видео, а так же я немного углублюсь в то, что именно эта, рассмотренная нами,",
  "n_reviews": 0,
  "start": 980.14,
  "end": 986.12
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "Теперь настал момент, я полагаю, я должен сказать, что подписывайтесь, чтобы получать уведомления о выходе видео или любых новых видео, но на самом деле большинство из вас на самом деле не получают уведомления от YouTube, не так ли?",
  "from_community_srt": "сеть делает на самом деле. Теперь настало время, когда я по-видимому должен сказать: подписывайтесь чтобы быть в курсе когда выдут это или новые видео, но в реальности большинство из вас на самом деле не принимают оповещений с YouTube,",
  "n_reviews": 0,
  "start": 987.58,
  "end": 997.42
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "Может быть, более честно я должен сказать, подпишитесь, чтобы нейронные сети, лежащие в основе алгоритма рекомендаций YouTube, были готовы поверить, что вы хотите, чтобы вам рекомендовали контент с этого канала.",
  "from_community_srt": "не так ли? Может правильнее мне сказать: подписывайтесь чтобы нейросети, лежащие в основе алгоритмов рекомендации YouTube, уяснили что вы хотите видеть в рекомендациях контент с этого канала.",
  "n_reviews": 0,
  "start": 998.02,
  "end": 1007.88
 },
 {
  "input": "Anyway, stay posted for more.",
  "translatedText": "В любом случае оставайтесь в курсе, чтобы узнать больше.",
  "from_community_srt": "В любом случае, оставайтесь на связи.",
  "n_reviews": 0,
  "start": 1008.56,
  "end": 1009.94
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "Большое спасибо всем, кто поддерживает эти видео на Patreon.",
  "from_community_srt": "Большое спасибо всем, кто спонсирует эти видео на \"Patreon\".",
  "n_reviews": 0,
  "start": 1010.76,
  "end": 1013.5
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "Этим летом я немного медленно продвигался в серии вероятностей, но я возвращаюсь к ней после этого проекта, так что, посетители, вы можете следить за обновлениями там.",
  "from_community_srt": "Я немного затормозил с работой над серией о вероятности этим летом, но возьмусь за неё снова, после данного проекта, так что, Patreons (спонсоры), ожидайте там обновлений.",
  "n_reviews": 0,
  "start": 1014.0,
  "end": 1021.9
 },
 {
  "input": "To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "В заключение, со мной здесь Лейша Ли, которая защитила докторскую диссертацию по теоретической стороне глубокого обучения и в настоящее время работает в венчурной фирме Amplify Partners, которая любезно предоставила часть финансирования для этого видео.",
  "from_community_srt": "Чтобы закрыть тему, тут со мной Лиша Ли (Lisha Li), чья докторская диссертация была посвящена теоретическим основам глубокого обучения, сейчас она работает в венчурной компании \"Amplify Partners\" и она добродушно внесла свой вклад в создание данного видео.",
  "n_reviews": 0,
  "start": 1023.6,
  "end": 1034.62
 },
 {
  "input": "So Lisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "Итак, Лейша, я думаю, нам следует быстро вспомнить об этой сигмовидной функции.",
  "from_community_srt": "Итак, Лиша,",
  "n_reviews": 0,
  "start": 1035.46,
  "end": 1039.12
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "Насколько я понимаю, ранние сети используют это, чтобы сжать соответствующую взвешенную сумму в интервал между нулем и единицей, вы знаете, это отчасти мотивировано этой биологической аналогией, когда нейроны либо неактивны, либо активны.",
  "from_community_srt": "я думаю мы должны кратко затронуть тему этой сигмоидной функции, насколько я понял раньше сети использовали её чтобы сжать соответствующие взвешенные суммы в этот интервал от 0 до 1, как бы подражая биологическим нейронам, которые либо в пассивном, либо в активном состоянии.",
  "n_reviews": 0,
  "start": 1039.7,
  "end": 1049.84
 },
 {
  "input": "Exactly.",
  "translatedText": "Точно.",
  "from_community_srt": "Точно.",
  "n_reviews": 0,
  "start": 1050.28,
  "end": 1050.3
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "Но относительно немногие современные сети действительно используют сигмовидную форму.",
  "from_community_srt": "Но вообще-то уже относительно мало современных сетей используют сигмоиду,",
  "n_reviews": 0,
  "start": 1050.56,
  "end": 1054.04
 },
 {
  "input": "Yeah.",
  "translatedText": "Ага.",
  "from_community_srt": "это,",
  "n_reviews": 0,
  "start": 1054.32,
  "end": 1054.32
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "Это что-то вроде старой школы, да?",
  "from_community_srt": "типа, старая школа,",
  "n_reviews": 0,
  "start": 1054.44,
  "end": 1055.54
 },
 {
  "input": "Yeah or rather ReLU seems to be much easier to train.",
  "translatedText": "Да, или, скорее, релу, кажется, гораздо легче тренировать.",
  "from_community_srt": "так? Да, но скорее \"ReLU\" выглядит более простым для обучения.",
  "n_reviews": 0,
  "start": 1055.76,
  "end": 1058.98
 },
 {
  "input": "And ReLU, ReLU stands for rectified linear unit?",
  "translatedText": "А relu означает выпрямленную линейную единицу?",
  "from_community_srt": "И \"ReLU\" означает \"Rectified Linear Unit\" (выпрямленный линейный модуль).",
  "n_reviews": 0,
  "start": 1059.4,
  "end": 1062.34
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not. And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "Да, это такая функция, в которой вы просто берете максимум, равный нулю, а где a определяется тем, что вы объясняли в видео, и это было как бы мотивировано, я думаю, частично биологической аналогией с тем, как нейроны будет либо активирована, либо нет, и поэтому, если она преодолеет определенный порог, это будет функция идентичности, но если бы это не было, то она просто не была бы активирована, поэтому она была бы равна нулю, так что это своего рода упрощение.",
  "from_community_srt": "Да, это своего рода функция которая берёт максимум от нуля и \"a\", где \"a\" определяется тем о чём ты говорил в видео, и я думаю это было частично навеяно биологической аналогией того как нейроны могут находиться либо в активном состоянии, либо нет, и если пройден определённый порог, то отрабатывает функция, а если не пройден, тогда он просто остаётся неактивным - равным нулю. Это своего рода упрощение,",
  "n_reviews": 0,
  "start": 1062.68,
  "end": 1090.84
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "Использование сигмоид не помогло в обучении, или в какой-то момент обучение было очень трудным, и люди просто попробовали relu, и оно очень хорошо сработало для этих невероятно глубоких нейронных сетей.",
  "from_community_srt": "использование сигмоид не способствовало обучению или в какой-то момент становилось слишком сложным, и люди попробовали \"ReLU\", и оказалось что это работает очень хорошо для таких невероятно глубоких (многослойных) нейросетей.",
  "n_reviews": 0,
  "start": 1091.16,
  "end": 1104.62
 },
 {
  "input": "All right thank you Lisha.",
  "translatedText": "Хорошо, спасибо, Алисия.",
  "n_reviews": 0,
  "start": 1105.1,
  "end": 1105.64
 }
]