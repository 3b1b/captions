[
 {
  "translatedText": "Это 3.",
  "input": "This is a 3.",
  "time_range": [
   4.22,
   5.4
  ]
 },
 {
  "translatedText": "Он небрежно написан и визуализирован с чрезвычайно низким разрешением 28x28 пикселей, но ваш мозг без труда распознает его как 3.",
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "time_range": [
   6.06,
   13.72
  ]
 },
 {
  "translatedText": "И я хочу, чтобы вы на минутку оценили, насколько безумно то, что мозг может делать это так легко.",
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "time_range": [
   14.34,
   18.96
  ]
 },
 {
  "translatedText": "Я имею в виду, что это, это и это также можно распознать как 3 секунды, хотя конкретные значения каждого пикселя сильно отличаются от одного изображения к другому.",
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "time_range": [
   19.7,
   28.32
  ]
 },
 {
  "translatedText": "Конкретные светочувствительные клетки вашего глаза, которые срабатывают, когда вы видите эту цифру 3, сильно отличаются от тех, которые срабатывают, когда вы видите эту цифру 3.",
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "time_range": [
   28.9,
   36.94
  ]
 },
 {
  "translatedText": "Но что-то в вашей безумно умной зрительной коре воспринимает эти изображения как представляющие одну и ту же идею, в то же время распознавая другие изображения как отдельные идеи.",
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "time_range": [
   37.52,
   48.26
  ]
 },
 {
  "translatedText": "Но если бы я сказал вам, эй, сядьте и напишите для меня программу, которая принимает сетку размером 28x28 пикселей вот так и выводит одно число от 0 до 10, сообщая вам, что, по ее мнению, представляет собой эта цифра, ну, задача будет выглядеть так: от комично тривиального до пугающе сложного.",
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "time_range": [
   49.22,
   66.18
  ]
 },
 {
  "translatedText": "Если вы не жили под камнем, я думаю, мне вряд ли нужно объяснять актуальность и важность машинного обучения и нейронных сетей для настоящего и будущего.",
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "time_range": [
   67.16,
   74.64
  ]
 },
 {
  "translatedText": "Но здесь я хочу показать вам, что на самом деле представляет собой нейронная сеть, не предполагая никакого фона, и помочь визуализировать то, что она делает, не как модное словечко, а как часть математики.",
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "time_range": [
   75.12,
   84.46
  ]
 },
 {
  "translatedText": "Я надеюсь, что вы уйдете с ощущением, что сама структура мотивирована, и почувствуете, что знаете, что она означает, когда читаете или слышите об обучении цитированием нейронной сети.",
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "time_range": [
   85.02,
   94.34
  ]
 },
 {
  "translatedText": "Это видео будет посвящено структурному компоненту этого процесса, а следующее будет посвящено обучению.",
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "time_range": [
   95.36,
   100.26
  ]
 },
 {
  "translatedText": "Что мы собираемся сделать, так это собрать нейронную сеть, которая сможет научиться распознавать рукописные цифры.",
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "time_range": [
   100.96,
   106.04
  ]
 },
 {
  "translatedText": "Это своего рода классический пример представления темы, и я рад придерживаться здесь существующего положения вещей, потому что в конце двух видеороликов я хочу указать вам на пару хороших ресурсов, где вы можете узнать больше, и где вы можете скачать код, который делает это, и поиграть с ним на своем компьютере.",
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "time_range": [
   109.36,
   123.08
  ]
 },
 {
  "translatedText": "Существует множество вариантов нейронных сетей, и в последние годы наблюдается своего рода бум исследований этих вариантов, но в этих двух вводных видеороликах мы с вами просто рассмотрим простейшую, простую ванильную форму без каких-либо дополнительных излишеств.",
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "time_range": [
   125.04,
   139.18
  ]
 },
 {
  "translatedText": "Это своего рода необходимая предпосылка для понимания любого из более мощных современных вариантов, и, поверьте мне, нам еще предстоит осмыслить множество сложностей.",
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "time_range": [
   139.86,
   148.6
  ]
 },
 {
  "translatedText": "Но даже в этой простейшей форме он может научиться распознавать рукописные цифры, что очень здорово для компьютера.",
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "time_range": [
   149.12,
   156.52
  ]
 },
 {
  "translatedText": "И в то же время вы увидите, что он не оправдывает пары надежд, которые мы могли бы на него возлагать.",
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "time_range": [
   157.48,
   162.28
  ]
 },
 {
  "translatedText": "Как следует из названия, нейронные сети созданы по принципу мозга, но давайте разберемся в этом.",
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "time_range": [
   163.38,
   168.5
  ]
 },
 {
  "translatedText": "Что такое нейроны и в каком смысле они связаны между собой?",
  "input": "What are the neurons, and in what sense are they linked together?",
  "time_range": [
   168.52,
   171.66
  ]
 },
 {
  "translatedText": "Прямо сейчас, когда я говорю «нейрон», все, о чем я хочу, чтобы вы подумали, — это о вещи, которая содержит число, особенно число от 0 до 1.",
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "time_range": [
   172.5,
   180.44
  ]
 },
 {
  "translatedText": "На самом деле это не более того.",
  "input": "It's really not more than that.",
  "time_range": [
   180.68,
   182.56
  ]
 },
 {
  "translatedText": "Например, сеть начинается с группы нейронов, соответствующей каждому из пикселей входного изображения размером 28x28, что в общей сложности составляет 784 нейрона.",
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "time_range": [
   183.78,
   194.22
  ]
 },
 {
  "translatedText": "Каждый из них содержит число, которое представляет значение шкалы серого соответствующего пикселя в диапазоне от 0 для черных пикселей до 1 для белых пикселей.",
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "time_range": [
   194.7,
   204.38
  ]
 },
 {
  "translatedText": "Это число внутри нейрона называется его активацией, и вы, возможно, имеете в виду, что каждый нейрон светится, когда его активация имеет большое число.",
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "time_range": [
   205.3,
   214.16
  ]
 },
 {
  "translatedText": "Итак, все эти 784 нейрона составляют первый слой нашей сети.",
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "time_range": [
   216.72,
   221.86
  ]
 },
 {
  "translatedText": "Теперь перейдем к последнему слою: здесь 10 нейронов, каждый из которых представляет одну из цифр.",
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "time_range": [
   226.5,
   231.36
  ]
 },
 {
  "translatedText": "Активация этих нейронов (опять же некоторое число от 0 до 1) показывает, насколько система считает, что данное изображение соответствует данной цифре.",
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "time_range": [
   232.04,
   242.12
  ]
 },
 {
  "translatedText": "Есть также пара промежуточных слоев, называемых скрытыми слоями, которые на данный момент должны быть просто гигантским знаком вопроса о том, как, черт возьми, будет осуществляться этот процесс распознавания цифр.",
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "time_range": [
   243.04,
   253.6
  ]
 },
 {
  "translatedText": "В этой сети я выбрал два скрытых слоя, каждый из которых содержит 16 нейронов, и, надо признать, это довольно произвольный выбор.",
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "time_range": [
   254.26,
   260.56
  ]
 },
 {
  "translatedText": "Честно говоря, я выбрал два слоя, исходя из того, как я хочу мотивировать структуру в данный момент, и 16, ну, это было просто хорошее число, чтобы поместиться на экране.",
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "time_range": [
   261.02,
   268.2
  ]
 },
 {
  "translatedText": "На практике здесь есть много возможностей для экспериментов с конкретной структурой.",
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "time_range": [
   268.78,
   272.34
  ]
 },
 {
  "translatedText": "В зависимости от того, как работает сеть, активации на одном уровне определяют активации следующего уровня.",
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "time_range": [
   273.02,
   278.48
  ]
 },
 {
  "translatedText": "И, конечно же, суть сети как механизма обработки информации сводится к тому, как именно активации на одном уровне вызывают активации на следующем уровне.",
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "time_range": [
   279.2,
   288.58
  ]
 },
 {
  "translatedText": "Это должно быть во многом аналогично тому, как в биологических сетях нейронов активация одних групп нейронов вызывает активацию других.",
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "time_range": [
   289.14,
   297.18
  ]
 },
 {
  "translatedText": "Сеть, которую я здесь показываю, уже обучена распознавать цифры, и позвольте мне показать вам, что я имею в виду.",
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "time_range": [
   298.12,
   303.4
  ]
 },
 {
  "translatedText": "Это означает, что если вы подаете изображение, освещая все 784 нейрона входного слоя в соответствии с яркостью каждого пикселя изображения, этот шаблон активаций вызывает некоторый очень специфический шаблон в следующем слое, который вызывает некоторый шаблон в следующем слое. это, что, наконец, дает некоторый узор в выходном слое.",
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "time_range": [
   303.64,
   322.08
  ]
 },
 {
  "translatedText": "И самый яркий нейрон этого выходного слоя — это, так сказать, выбор сети, какую цифру представляет это изображение.",
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "time_range": [
   322.56,
   329.4
  ]
 },
 {
  "translatedText": "И прежде чем приступить к математическим расчетам того, как один слой влияет на следующий или как работает обучение, давайте просто поговорим о том, почему вообще разумно ожидать, что такая многоуровневая структура будет вести себя разумно.",
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "time_range": [
   332.56,
   343.52
  ]
 },
 {
  "translatedText": "Чего мы здесь ожидаем?",
  "input": "What are we expecting here?",
  "time_range": [
   344.06,
   345.22
  ]
 },
 {
  "translatedText": "Какова наилучшая надежда для этих средних слоев?",
  "input": "What is the best hope for those middle layers?",
  "time_range": [
   345.4,
   347.6
  ]
 },
 {
  "translatedText": "Что ж, когда мы с вами распознаем цифры, мы собираем воедино различные компоненты.",
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "time_range": [
   348.92,
   353.52
  ]
 },
 {
  "translatedText": "У цифры 9 есть петля вверху и линия справа.",
  "input": "A 9 has a loop up top and a line on the right.",
  "time_range": [
   354.2,
   356.82
  ]
 },
 {
  "translatedText": "У цифры 8 также есть верхняя петля, но она соединена с другой нижней петлей.",
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "time_range": [
   357.38,
   361.18
  ]
 },
 {
  "translatedText": "4 по сути разбивается на три конкретные линии и тому подобное.",
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "time_range": [
   361.98,
   366.82
  ]
 },
 {
  "translatedText": "Теперь, в идеальном мире, мы могли бы надеяться, что каждый нейрон предпоследнего слоя соответствует одному из этих подкомпонентов, и что каждый раз, когда вы подаете изображение, скажем, с петлей вверху, например, с 9 или 8, происходит некоторая конкретный нейрон, активация которого будет близка к 1.",
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "time_range": [
   367.6,
   383.78
  ]
 },
 {
  "translatedText": "И я не имею в виду эту конкретную петлю пикселей, я надеюсь, что любой вообще петлевой узор вверху активирует этот нейрон.",
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "time_range": [
   384.5,
   391.56
  ]
 },
 {
  "translatedText": "Таким образом, для перехода от третьего уровня к последнему необходимо просто узнать, какая комбинация подкомпонентов соответствует каким цифрам.",
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "time_range": [
   392.44,
   400.04
  ]
 },
 {
  "translatedText": "Конечно, это только отбрасывает проблему в сторону, потому что как вы распознаете эти подкомпоненты или даже узнаете, какими должны быть правильные подкомпоненты?",
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "time_range": [
   401.0,
   407.64
  ]
 },
 {
  "translatedText": "И я еще даже не говорил о том, как один слой влияет на следующий, но пробежимся на минутку по этому поводу.",
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "time_range": [
   408.06,
   413.06
  ]
 },
 {
  "translatedText": "Распознавание цикла также может быть разбито на подзадачи.",
  "input": "Recognizing a loop can also break down into subproblems.",
  "time_range": [
   413.68,
   416.68
  ]
 },
 {
  "translatedText": "Один из разумных способов сделать это — сначала распознать различные небольшие грани, из которых он состоит.",
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "time_range": [
   417.28,
   422.78
  ]
 },
 {
  "translatedText": "Точно так же длинная линия, подобная той, которую вы можете видеть в цифрах 1, 4 или 7, на самом деле представляет собой просто длинное ребро, или, может быть, вы думаете о ней как об определенном узоре из нескольких меньших ребер.",
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "time_range": [
   423.78,
   434.32
  ]
 },
 {
  "translatedText": "Так что, возможно, мы надеемся, что каждый нейрон второго слоя сети соответствует различным значимым маленьким ребрам.",
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "time_range": [
   435.14,
   442.72
  ]
 },
 {
  "translatedText": "Возможно, когда появляется такое изображение, оно освещает все нейроны, связанные примерно с 8–10 конкретными маленькими ребрами, что, в свою очередь, освещает нейроны, связанные с верхней петлей и длинной вертикальной линией, а они освещают нейрон, связанный с 9.",
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "time_range": [
   443.54,
   459.72
  ]
 },
 {
  "translatedText": "Является ли это тем, что на самом деле делает наша окончательная сеть, — это другой вопрос, к которому я вернусь, как только мы увидим, как обучать сеть, но это надежда, которая у нас может быть, своего рода цель с многоуровневой структурой. так.",
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "time_range": [
   460.68,
   472.54
  ]
 },
 {
  "translatedText": "Более того, вы можете себе представить, как возможность обнаружения краев и узоров, подобная этой, может оказаться очень полезной для других задач распознавания изображений.",
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "time_range": [
   473.16,
   480.3
  ]
 },
 {
  "translatedText": "И даже помимо распознавания изображений, вы, возможно, захотите сделать множество интеллектуальных вещей, которые разбиваются на уровни абстракции.",
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "time_range": [
   480.88,
   487.28
  ]
 },
 {
  "translatedText": "Например, анализ речи включает в себя получение необработанного аудио и выделение отдельных звуков, которые объединяются в определенные слоги, которые объединяются в слова, которые объединяются в фразы и более абстрактные мысли и т. д.",
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "time_range": [
   488.04,
   500.06
  ]
 },
 {
  "translatedText": "Но возвращаясь к тому, как все это на самом деле работает, представьте себе, как прямо сейчас вы разрабатываете, как именно активации на одном уровне могут определять следующий.",
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "time_range": [
   501.1,
   509.92
  ]
 },
 {
  "translatedText": "Цель состоит в том, чтобы создать некий механизм, который мог бы объединять пиксели в края, края в узоры или узоры в цифры.",
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "time_range": [
   510.86,
   518.98
  ]
 },
 {
  "translatedText": "И если приблизить один очень конкретный пример, скажем, есть надежда на то, что один конкретный нейрон во втором слое поймет, имеет ли изображение край в этой области.",
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "time_range": [
   519.44,
   530.62
  ]
 },
 {
  "translatedText": "Возникает вопрос: какие параметры должна иметь сеть?",
  "input": "The question at hand is what parameters should the network have?",
  "time_range": [
   531.44,
   535.1
  ]
 },
 {
  "translatedText": "Какие циферблаты и ручки вы должны настроить, чтобы они были достаточно выразительными, чтобы потенциально захватить этот узор, или любой другой пиксельный узор, или узор, в котором несколько краев могут образовывать петлю, и другие подобные вещи?",
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "time_range": [
   535.64,
   547.78
  ]
 },
 {
  "translatedText": "Что ж, мы присвоим вес каждой связи между нашим нейроном и нейронами первого слоя.",
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "time_range": [
   548.72,
   555.56
  ]
 },
 {
  "translatedText": "Эти веса являются просто числами.",
  "input": "These weights are just numbers.",
  "time_range": [
   556.32,
   557.7
  ]
 },
 {
  "translatedText": "Затем возьмите все эти активации из первого слоя и вычислите их взвешенную сумму в соответствии с этими весами.",
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "time_range": [
   558.54,
   565.5
  ]
 },
 {
  "translatedText": "Я считаю полезным представить эти веса как организованные в небольшую сетку, и я собираюсь использовать зеленые пиксели для обозначения положительных весов и красные пиксели для обозначения отрицательных весов, где яркость этого пикселя составляет некоторую величину. свободное представление значения веса.",
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "time_range": [
   567.7,
   581.78
  ]
 },
 {
  "translatedText": "Теперь, если мы сделали веса, связанные почти со всеми пикселями, равными нулю, за исключением некоторых положительных весов в этой области, которые нас интересуют, тогда взвешенная сумма всех значений пикселей на самом деле будет просто складывать значения пикселя только в регион, который нас волнует.",
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "time_range": [
   582.78,
   597.82
  ]
 },
 {
  "translatedText": "И если вы действительно хотите понять, есть ли здесь край, вы можете установить отрицательные веса, связанные с окружающими пикселями.",
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "time_range": [
   599.14,
   606.6
  ]
 },
 {
  "translatedText": "Тогда сумма будет наибольшей, если средние пиксели яркие, а окружающие пиксели темнее.",
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "time_range": [
   607.48,
   612.7
  ]
 },
 {
  "translatedText": "Когда вы вычисляете взвешенную сумму, подобную этой, вы можете получить любое число, но для этой сети мы хотим, чтобы активации имели некоторое значение от 0 до 1.",
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "time_range": [
   614.26,
   623.54
  ]
 },
 {
  "translatedText": "Поэтому обычно приходится закачивать эту взвешенную сумму в некоторую функцию, которая сжимает линию действительных чисел в диапазон от 0 до 1.",
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "time_range": [
   624.12,
   632.14
  ]
 },
 {
  "translatedText": "И обычная функция, которая делает это, называется сигмовидной функцией, также известной как логистическая кривая.",
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "time_range": [
   632.46,
   637.42
  ]
 },
 {
  "translatedText": "По сути, очень отрицательные входные данные приближаются к 0, положительные входные данные — к 1, и они постепенно увеличиваются около входного значения 0.",
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "time_range": [
   638.0,
   646.6
  ]
 },
 {
  "translatedText": "Таким образом, активация нейрона здесь, по сути, является мерой того, насколько положительна соответствующая взвешенная сумма.",
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "time_range": [
   649.12,
   656.36
  ]
 },
 {
  "translatedText": "Но, возможно, дело не в том, что вы хотите, чтобы нейрон загорался, когда взвешенная сумма больше 0.",
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "time_range": [
   657.54,
   661.88
  ]
 },
 {
  "translatedText": "Возможно, вы хотите, чтобы он был активен только тогда, когда сумма больше, скажем, 10.",
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "time_range": [
   662.28,
   666.36
  ]
 },
 {
  "translatedText": "То есть вам нужна некоторая предвзятость, чтобы он был неактивным.",
  "input": "That is, you want some bias for it to be inactive.",
  "time_range": [
   666.84,
   670.26
  ]
 },
 {
  "translatedText": "Затем мы просто добавим какое-нибудь другое число, например минус 10, к этой взвешенной сумме, прежде чем подключить ее через функцию сжатия сигмовидной кишки.",
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "time_range": [
   671.38,
   679.66
  ]
 },
 {
  "translatedText": "Это дополнительное число называется смещением.",
  "input": "That additional number is called the bias.",
  "time_range": [
   680.58,
   682.44
  ]
 },
 {
  "translatedText": "Таким образом, веса говорят вам, какой шаблон пикселей улавливает этот нейрон во втором слое, а смещение говорит вам, насколько высокой должна быть взвешенная сумма, прежде чем нейрон начнет становиться значимо активным.",
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "time_range": [
   683.46,
   695.18
  ]
 },
 {
  "translatedText": "И это всего лишь один нейрон.",
  "input": "And that is just one neuron.",
  "time_range": [
   696.12,
   697.68
  ]
 },
 {
  "translatedText": "Каждый второй нейрон в этом слое будет связан со всеми 784 пиксельными нейронами первого слоя, и каждому из этих 784 соединений будет присвоен свой собственный вес.",
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "time_range": [
   698.28,
   710.94
  ]
 },
 {
  "translatedText": "Кроме того, у каждого из них есть некоторая погрешность, какое-то другое число, которое вы добавляете к взвешенной сумме, прежде чем сжимать ее сигмоидой.",
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "time_range": [
   711.6,
   717.6
  ]
 },
 {
  "translatedText": "И это есть над чем подумать!",
  "input": "And that's a lot to think about!",
  "time_range": [
   718.11,
   719.54
  ]
 },
 {
  "translatedText": "С этим скрытым слоем из 16 нейронов это в общей сложности 784 раза по 16 весов, а также 16 смещений.",
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "time_range": [
   719.96,
   727.98
  ]
 },
 {
  "translatedText": "И все это — лишь связи первого слоя со вторым.",
  "input": "And all of that is just the connections from the first layer to the second.",
  "time_range": [
   728.84,
   731.94
  ]
 },
 {
  "translatedText": "Связи между другими слоями также имеют множество весов и смещений, связанных с ними.",
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "time_range": [
   732.52,
   737.34
  ]
 },
 {
  "translatedText": "В целом эта сеть имеет почти ровно 13 000 весов и смещений.",
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "time_range": [
   738.34,
   743.8
  ]
 },
 {
  "translatedText": "13 000 ручек и дисков, которые можно настраивать и поворачивать, чтобы заставить эту сеть вести себя по-разному.",
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "time_range": [
   743.8,
   749.96
  ]
 },
 {
  "translatedText": "Итак, когда мы говорим об обучении, имеется в виду заставить компьютер найти допустимую настройку для всех этих многих чисел, чтобы он действительно решил поставленную задачу.",
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "time_range": [
   751.04,
   761.36
  ]
 },
 {
  "translatedText": "Один мысленный эксперимент, который одновременно забавен и отчасти ужасен, состоит в том, чтобы представить, что вы садитесь и вручную устанавливаете все эти веса и смещения, целенаправленно настраивая числа так, чтобы второй слой улавливал края, третий слой улавливал закономерности, и т. д.",
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "time_range": [
   762.62,
   776.58
  ]
 },
 {
  "translatedText": "Лично меня это удовлетворяет, а не просто рассматривать сеть как полный черный ящик, потому что, когда сеть не работает так, как вы ожидаете, если вы выстроили хоть какое-то отношение к тому, что на самом деле означают эти веса и предвзятости , у вас есть отправная точка для экспериментов с тем, как изменить структуру для улучшения.",
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "time_range": [
   776.98,
   794.18
  ]
 },
 {
  "translatedText": "Или, когда сеть работает, но не по тем причинам, которые вы могли ожидать, изучение того, что делают веса и смещения, — это хороший способ бросить вызов вашим предположениям и по-настоящему раскрыть все пространство возможных решений.",
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "time_range": [
   794.96,
   805.82
  ]
 },
 {
  "translatedText": "Кстати, записывать эту функцию немного громоздко, вам не кажется?",
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "time_range": [
   806.84,
   810.68
  ]
 },
 {
  "translatedText": "Итак, позвольте мне показать вам более компактный способ представления этих связей.",
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "time_range": [
   812.5,
   817.14
  ]
 },
 {
  "translatedText": "Вот как вы это увидите, если решите узнать больше о нейронных сетях.",
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "time_range": [
   817.66,
   820.52
  ]
 },
 {
  "translatedText": "Организуйте все активации одного слоя в столбце, поскольку матрица соответствует связям между одним слоем и конкретным нейроном в следующем слое.",
  "input": "Organize all of the activations from one layer into a column as a matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "time_range": [
   821.38,
   838.0
  ]
 },
 {
  "translatedText": "Это означает, что взятие взвешенной суммы активаций в первом слое в соответствии с этими весами соответствует одному из членов матричного векторного произведения всего, что у нас есть здесь слева.",
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "time_range": [
   838.54,
   849.88
  ]
 },
 {
  "translatedText": "Между прочим, большая часть машинного обучения сводится к хорошему пониманию линейной алгебры, поэтому для тех из вас, кто хочет получить хорошее визуальное представление о матрицах и о том, что означает умножение матриц на вектор, взгляните на серию, которую я делал. линейная алгебра, особенно глава 3.",
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "time_range": [
   854.0,
   868.6
  ]
 },
 {
  "translatedText": "Возвращаясь к нашему выражению, вместо того, чтобы говорить о добавлении смещения к каждому из этих значений независимо, мы представляем его, организуя все эти смещения в вектор и добавляя весь вектор к предыдущему произведению матрицы-вектора.",
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "time_range": [
   869.24,
   882.3
  ]
 },
 {
  "translatedText": "Затем, в качестве последнего шага, я оберну здесь сигмоиду снаружи, и это должно означать, что вы собираетесь применить сигмовидную функцию к каждому конкретному компоненту результирующего вектора внутри.",
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "time_range": [
   883.28,
   894.74
  ]
 },
 {
  "translatedText": "Итак, как только вы запишете эту весовую матрицу и эти векторы как отдельные символы, вы сможете передать полный переход активаций от одного слоя к другому в чрезвычайно сжатом и аккуратном маленьком выражении, и это делает соответствующий код намного проще и проще. намного быстрее, поскольку многие библиотеки чертовски оптимизируют умножение матриц.",
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "time_range": [
   895.94,
   915.66
  ]
 },
 {
  "translatedText": "Помните, как ранее я говорил, что эти нейроны — это просто вещи, хранящие числа?",
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "time_range": [
   917.82,
   921.46
  ]
 },
 {
  "translatedText": "Ну, конечно, конкретные числа, которые они содержат, зависят от изображения, которое вы вводите, поэтому на самом деле правильнее думать о каждом нейроне как о функции, которая принимает выходные данные всех нейронов предыдущего слоя и выдает число. между 0 и 1.",
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "time_range": [
   922.22,
   938.34
  ]
 },
 {
  "translatedText": "На самом деле вся сеть — это просто функция, которая принимает 784 числа на вход и выдаёт 10 чисел на выходе.",
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "time_range": [
   939.2,
   947.06
  ]
 },
 {
  "translatedText": "Это абсурдно сложная функция, которая включает в себя 13 000 параметров в виде весов и смещений, которые улавливают определенные шаблоны, и которая включает в себя итерацию множества матричных векторных произведений и сигмовидной функции сжатия, но, тем не менее, это всего лишь функция, и в то, что это выглядит сложным, успокаивает.",
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless, and in a way it's kind of reassuring that it looks complicated.",
  "time_range": [
   947.56,
   966.66
  ]
 },
 {
  "translatedText": "Я имею в виду, если бы все было проще, какая у нас была бы надежда, что он сможет справиться с задачей распознавания цифр?",
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "time_range": [
   967.34,
   972.28
  ]
 },
 {
  "translatedText": "И как он справляется с этой задачей?",
  "input": "And how does it take on that challenge?",
  "time_range": [
   973.34,
   974.7
  ]
 },
 {
  "translatedText": "Как эта сеть изучает соответствующие веса и смещения, просто просматривая данные?",
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "time_range": [
   975.08,
   979.36
  ]
 },
 {
  "translatedText": "Что ж, это то, что я покажу в следующем видео, а также немного углублюсь в то, что на самом деле делает эта конкретная сеть, которую мы видим.",
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "time_range": [
   980.14,
   986.12
  ]
 },
 {
  "translatedText": "Теперь настал момент, я полагаю, я должен сказать, что подписывайтесь, чтобы получать уведомления о выходе видео или любых новых видео, но на самом деле большинство из вас на самом деле не получают уведомления от YouTube, не так ли?",
  "input": "Now is the point I suppose I should say subscribe to stay notified about when video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "time_range": [
   987.58,
   997.42
  ]
 },
 {
  "translatedText": "Может быть, более честно я должен сказать, подпишитесь, чтобы нейронные сети, лежащие в основе алгоритма рекомендаций YouTube, были готовы поверить, что вы хотите, чтобы вам рекомендовали контент с этого канала.",
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "time_range": [
   998.02,
   1007.88
  ]
 },
 {
  "translatedText": "В любом случае оставайтесь в курсе, чтобы узнать больше.",
  "input": "Anyway stay posted for more.",
  "time_range": [
   1008.56,
   1009.94
  ]
 },
 {
  "translatedText": "Большое спасибо всем, кто поддерживает эти видео на Patreon.",
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "time_range": [
   1010.76,
   1013.5
  ]
 },
 {
  "translatedText": "Этим летом я немного медленно продвигался в серии вероятностей, но я возвращаюсь к ней после этого проекта, так что, посетители, вы можете следить за обновлениями там.",
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "time_range": [
   1014.0,
   1021.9
  ]
 },
 {
  "translatedText": "В заключение, со мной здесь Лейша Ли, которая защитила докторскую диссертацию по теоретической стороне глубокого обучения и в настоящее время работает в венчурной фирме Amplify Partners, которая любезно предоставила часть финансирования для этого видео.",
  "input": "To close things off here I have with me Leisha Lee who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "time_range": [
   1023.6,
   1034.62
  ]
 },
 {
  "translatedText": "Итак, Лейша, я думаю, нам следует быстро вспомнить об этой сигмовидной функции.",
  "input": "So Leisha one thing I think we should quickly bring up is this sigmoid function.",
  "time_range": [
   1035.46,
   1039.12
  ]
 },
 {
  "translatedText": "Насколько я понимаю, ранние сети используют это, чтобы сжать соответствующую взвешенную сумму в интервал между нулем и единицей, вы знаете, это отчасти мотивировано этой биологической аналогией, когда нейроны либо неактивны, либо активны.",
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "time_range": [
   1039.7,
   1049.84
  ]
 },
 {
  "translatedText": "Точно.",
  "input": "Exactly.",
  "time_range": [
   1050.28,
   1050.3
  ]
 },
 {
  "translatedText": "Но относительно немногие современные сети действительно используют сигмовидную форму.",
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "time_range": [
   1050.56,
   1054.04
  ]
 },
 {
  "translatedText": "Ага.",
  "input": "Yeah.",
  "time_range": [
   1054.32,
   1054.32
  ]
 },
 {
  "translatedText": "Это что-то вроде старой школы, да?",
  "input": "It's kind of old school right?",
  "time_range": [
   1054.44,
   1055.54
  ]
 },
 {
  "translatedText": "Да, или, скорее, релу, кажется, гораздо легче тренировать.",
  "input": "Yeah or rather relu seems to be much easier to train.",
  "time_range": [
   1055.76,
   1058.98
  ]
 },
 {
  "translatedText": "А relu означает выпрямленную линейную единицу?",
  "input": "And relu stands for rectified linear unit?",
  "time_range": [
   1059.4,
   1062.34
  ]
 },
 {
  "translatedText": "Да, это такая функция, в которой вы просто берете максимум, равный нулю, а где a определяется тем, что вы объясняли в видео, и это было как бы мотивировано, я думаю, частично биологической аналогией с тем, как нейроны будет либо активирована, либо нет, и поэтому, если она преодолеет определенный порог, это будет функция идентичности, но если бы это не было, то она просто не была бы активирована, поэтому она была бы равна нулю, так что это своего рода упрощение.",
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not and so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "time_range": [
   1062.68,
   1090.84
  ]
 },
 {
  "translatedText": "Использование сигмоид не помогло в обучении, или в какой-то момент обучение было очень трудным, и люди просто попробовали relu, и оно очень хорошо сработало для этих невероятно глубоких нейронных сетей.",
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried relu and it happened to work very well for these incredibly deep neural networks.",
  "time_range": [
   1091.16,
   1104.62
  ]
 },
 {
  "translatedText": "Хорошо, спасибо, Алисия.",
  "input": "All right thank you Alicia.",
  "time_range": [
   1105.1,
   1105.64
  ]
 }
]