[
 {
  "input": "This is a 3.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 4.22,
  "end": 5.4
 },
 {
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "translatedText": "",
  "from_community_srt": "นี่คือเลขสาม เขียนอย่างลวกๆ และแสดงผลที่ความละเอียดต่ำที่ 28 x 28 pixel แต่ก็ไม่ใช่ปัญหาที่สมองคุณจะเห็นว่ามันเป็นเลขสาม ผมอยากให้คุณตระหนักถึงคุณค่า",
  "n_reviews": 0,
  "start": 6.06,
  "end": 13.72
 },
 {
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 14.34,
  "end": 18.96
 },
 {
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "translatedText": "",
  "from_community_srt": "ไม่น่าเชื่อว่าสมองเราสามารถทำมันได้อย่างง่ายดาย อันนี้ อันนี้ แล้วก็อันนี้ ก็ยังเห็นว่าเป็นเลขสาม",
  "n_reviews": 0,
  "start": 19.7,
  "end": 28.32
 },
 {
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "translatedText": "",
  "from_community_srt": "แม้ว่าข้อมูลในแต่ละpixelในแต่ละรูปจะไม่เหมือนกันก็ตาม เซลล์ที่ไวต่อแสงในดวงตาของคุณส่งสัญญาณเมื่อคุณเห็นเลขสามนี้",
  "n_reviews": 0,
  "start": 28.9,
  "end": 36.94
 },
 {
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "translatedText": "",
  "from_community_srt": "ก็เป็นคนละอันกับที่ส่งสัญญาณเมื่อคุณเห็นเลขสามรูปนี้ แต่สิ่งที่อยู่ในvisual cortex ที่ฉลาดมากของคุณ สามารถแก้ปัญหาเหล่านี้เพื่อแสดงถึงแนวคิดเดียวกันในขณะที่จดจำภาพอื่น ๆ เป็นความคิดที่แตกต่างออกไป",
  "n_reviews": 0,
  "start": 37.52,
  "end": 48.26
 },
 {
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "translatedText": "",
  "from_community_srt": "แต่ถ้าผมบอกคุณ ให้นั่งลงและเขียนโปรแกรมให้ผม โดยใช้ข้อมูลจากตารางจาก 28 x 28 pixels เช่นนี้และคืนตัวเลขเดียวระหว่าง 0 ถึง 10 บอกคุณว่ามันคิดว่ามันเป็นตัวเลขอะไร",
  "n_reviews": 0,
  "start": 49.22,
  "end": 66.18
 },
 {
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "translatedText": "",
  "from_community_srt": "งานนี้จากตลกง่ายดายกลายเป็นยากเย็นแสนเข็ญ นอกจากคุณอยู่ใต้หิน ผมคิดว่าผมแทบจะไม่จำเป็นต้องพูดถึงความเกี่ยวข้องและความสำคัญของ Machine Learning และ Neural Networkในปัจจุบันต่อไปในอนาคต",
  "n_reviews": 0,
  "start": 67.16,
  "end": 74.64
 },
 {
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "translatedText": "",
  "from_community_srt": "แต่สิ่งที่ผมต้องการจะทำคือแสดงให้คุณเห็นว่า neural network มันคืออะไรกันแน่ สมมติว่าไม่มีความรู้พื้นหลังและให้ช่วยเห็นภาพว่ามันทำอะไร ไม่ใช่buzzword แต่ราวกับเป็นส่วนหนึ่งของคณิตศาสตร์",
  "n_reviews": 0,
  "start": 75.12,
  "end": 84.46
 },
 {
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "translatedText": "",
  "from_community_srt": "ผมหวังว่าคุณจะออกมารู้สึกเหมือนโครงสร้างนี้เอง มีแรงบันดาลใจและรู้สึกเหมือนคุณรู้ว่ามันหมายถึงอะไรเมื่อคุณอ่านหรือได้ยินเกี่ยวกับ neural network",
  "n_reviews": 0,
  "start": 85.02,
  "end": 94.34
 },
 {
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "translatedText": "",
  "from_community_srt": "วิดีโอนี้เป็นจะทุ่มเทให้กับองค์ประกอบโครงสร้างของมันและอันต่อไปเป็นไปเพื่อจัดการกับการเรียนรู้",
  "n_reviews": 0,
  "start": 95.36,
  "end": 100.26
 },
 {
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "translatedText": "",
  "from_community_srt": "สิ่งที่เรากำลังจะทำคือใส่กัน neural network ที่สามารถเรียนรู้ที่จะอ่านเลขที่เขียนด้วยลายมือ",
  "n_reviews": 0,
  "start": 100.96,
  "end": 106.04
 },
 {
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "translatedText": "",
  "from_community_srt": "นี่เป็นตัวอย่างคลาสสิกสำหรับ แนะนำหัวข้อนี้และผมก็ยินดีที่จะปฏิบัติตามเดิมที่นี่เพราะในตอนท้ายของวิดีโอทั้งสองแบบที่ฉันต้องการชี้ ไปยังแหล่งข้อมูลที่ดีที่คุณสามารถเรียนรู้ได้เพิ่มเติมและที่ใดที่คุณสามารถดาวน์โหลดโค้ดที่ทำแบบนี้และเล่นกับมันได้",
  "n_reviews": 0,
  "start": 109.36,
  "end": 123.08
 },
 {
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "translatedText": "",
  "from_community_srt": "บนคอมพิวเตอร์ของคุณเอง มันมี neural network หลาย หลายรูปแบบ และในช่วงไม่กี่ปีที่ผ่านมา มีบูมในการค้นคว้าวิจัยเกี่ยวกับรูปแบบเหล่านี้ แต่ในวิดีโอแนะนำทั้งสองแบบนี้เราจะมองไปที่รูปแบบวานิลลาธรรมดาเรียบง่ายที่ไม่มีการแต่งเติม มันค่อนข้างเป็นสิ่งที่จำเป็น",
  "n_reviews": 0,
  "start": 125.04,
  "end": 139.18
 },
 {
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "translatedText": "",
  "from_community_srt": "ก่อนการทำความเข้าใจรูปแบบที่ทันสมัยและมีประสิทธิภาพ เชื่อผม มันยังมีความซับซ้อนมากมายสำหรับเราที่จะต้องเข้าใจ",
  "n_reviews": 0,
  "start": 139.86,
  "end": 148.6
 },
 {
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "translatedText": "",
  "from_community_srt": "แม้ในรูปแบบที่ง่ายที่สุดนี้ก็สามารถเรียนรู้เพื่อจดจำตัวเลขที่เขียนด้วยลายมือ ซึ่งเป็นความสามารถที่ค่อนข้างเจ๋งสำหรับคอมพิวเตอร์",
  "n_reviews": 0,
  "start": 149.12,
  "end": 156.52
 },
 {
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 157.48,
  "end": 162.28
 },
 {
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "translatedText": "",
  "from_community_srt": "และในเวลาเดียวกันคุณจะเห็นว่ามันขาดอะไรจากความคาดหมายที่เราตั้งไว้ เป็นชื่อที่เกริ่นไว้ neural network เครือข่ายประสาทได้รับแรงบันดาลใจจากสมอง  เรามาดูกัน",
  "n_reviews": 0,
  "start": 163.38,
  "end": 168.5
 },
 {
  "input": "What are the neurons, and in what sense are they linked together?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 168.52,
  "end": 171.66
 },
 {
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "อะไรคือเซลล์ประสาทและพวกเขาเชื่อมโยงกันอย่างไร? ตอนนี้เมื่อผมพูดเซลล์ประสาท ผมต้องการให้คุณคิดเป็นสิ่งที่เก็บตัวเลข",
  "n_reviews": 0,
  "start": 172.5,
  "end": 180.44
 },
 {
  "input": "It's really not more than that.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 180.68,
  "end": 182.56
 },
 {
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "translatedText": "",
  "from_community_srt": "โดยเฉพาะตัวเลขระหว่าง 0 ถึง 1 จะไม่มากไปกว่านั้น ตัวอย่างเช่นเครือข่ายเริ่มต้นด้วยเซลล์ประสาทที่มาจาก 28 x 28 pixel ของภาพที่นำเข้า",
  "n_reviews": 0,
  "start": 183.78,
  "end": 194.22
 },
 {
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "translatedText": "",
  "from_community_srt": "ซึ่งคือ 784 เซลล์ประสาททั้งหมดในแต่ละเซลล์มีจำนวนที่แสดงถึงค่า grayscale ของpixelที่ตรงกัน ตั้งแต่ 0 สำหรับ pixel สีดำถึง 1 สำหรับ pixel สีขาว",
  "n_reviews": 0,
  "start": 194.7,
  "end": 204.38
 },
 {
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "translatedText": "",
  "from_community_srt": "เลขที่อยู่ภายใน neuron เรียกว่า activation คุณอาจจะนึกภาพตามได้ว่า neuron แต่ละอันจะสว่างขึ้นเมื่อเลข activation นั้นสูง",
  "n_reviews": 0,
  "start": 205.3,
  "end": 214.16
 },
 {
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 216.72,
  "end": 221.86
 },
 {
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "translatedText": "",
  "from_community_srt": "neuron ทั้ง 784 อันรวมกันเป็น layer แรกใน network ของเรา ข้ามไปที่ layer สุดท้าย ซึ่งมีทั้งหมดสิบเ neuron แต่ละอันแทนเลขหนึ่งตัว",
  "n_reviews": 0,
  "start": 226.5,
  "end": 231.36
 },
 {
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "translatedText": "",
  "from_community_srt": "เลข activation ใน neuron เหล่านี้ อีกครั้งเลขที่อยู่ระหว่างศูนย์และหนึ่ง หมายถึง ค่าที่ระบบคิดว่าภาพที่เห็น",
  "n_reviews": 0,
  "start": 232.04,
  "end": 242.12
 },
 {
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "translatedText": "",
  "from_community_srt": "ตรงกับตัวเลขที่ระบุ นอกจากนี้ยังมี layer อีกสอง layer ตรงกลางที่เรียกว่า hidden layer ซึ่งในขณะนี้",
  "n_reviews": 0,
  "start": 243.04,
  "end": 253.6
 },
 {
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "translatedText": "",
  "from_community_srt": "ควรเป็นแค่เครื่องหมายคำถามยักษ์ ทดแทนวิธีการใดในโลกนี้ ที่จะจัดการกับวิธีการจดจำตัวเลข ใน network นี้ผมเลือก hidden layer ไว้สองชั้นซึ่งมี 16 neuron และยอมรับว่าค่อนข้างเป็นทางเลือกที่ไม่มีเหตุผล",
  "n_reviews": 0,
  "start": 254.26,
  "end": 260.56
 },
 {
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "translatedText": "",
  "from_community_srt": "ในความเป็นจริงผมเลือกสอง layer ขึ้นอยู่กับว่าวิธีที่ผมต้องการจะกระตุ้นโครงสร้างในสักครู่ และ 16 มันเป็นเพียงตัวเลขที่ดีเพื่อให้พอดีกับบนหน้าจอ ในทางปฏิบัติ",
  "n_reviews": 0,
  "start": 261.02,
  "end": 268.2
 },
 {
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 268.78,
  "end": 272.34
 },
 {
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "translatedText": "",
  "from_community_srt": "ยังมีพื้นที่จำนวนมากสำหรับการทดลองกับการโครงสร้าง วิธีที่เครือข่ายเปิดใช้งานการเปิดใช้งานในชั้นเดียวจะเป็นตัวกำหนดการเปิดใช้งานของเลเยอร์ถัดไป",
  "n_reviews": 0,
  "start": 273.02,
  "end": 278.48
 },
 {
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "translatedText": "",
  "from_community_srt": "และแน่นอนว่าหัวใจของเครือข่ายเป็นกลไกในการประมวลผลข้อมูลจะลดลงอย่างแน่นอน การเปิดใช้งานจากเลเยอร์จะทำให้เกิดการเปิดใช้งานในชั้นถัดไป",
  "n_reviews": 0,
  "start": 279.2,
  "end": 288.58
 },
 {
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "translatedText": "",
  "from_community_srt": "มันหมายถึงการหลวมคล้ายคลึงกับวิธีการในเครือข่ายทางชีววิทยาของเซลล์ประสาทบางกลุ่มของเซลล์ประสาทยิง",
  "n_reviews": 0,
  "start": 289.14,
  "end": 297.18
 },
 {
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "translatedText": "",
  "from_community_srt": "ทำให้คนอื่นบางคนดับเพลิง ตอนนี้เครือข่าย ฉันกำลังแสดงอยู่ที่นี่ได้รับการฝึกฝนให้จดจำตัวเลขแล้วแจ้งให้ฉันทราบว่าฉันหมายถึงอะไร",
  "n_reviews": 0,
  "start": 298.12,
  "end": 303.4
 },
 {
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "translatedText": "",
  "from_community_srt": "นั่นหมายความว่าถ้าคุณให้อาหารภาพแสงทั้งหมด 784 เซลล์ประสาทของชั้นข้อมูลเข้าตามความสว่างของแต่ละพิกเซลในภาพ รูปแบบการเปิดใช้งานทำให้รูปแบบที่เฉพาะเจาะจงบางอย่างในชั้นถัดไป ซึ่งทำให้รูปแบบบางอย่างในหนึ่งหลังจากนั้นหรือไม่",
  "n_reviews": 0,
  "start": 303.64,
  "end": 322.08
 },
 {
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "translatedText": "",
  "from_community_srt": "ซึ่งสุดท้ายให้รูปแบบในชั้นส่งออกและ? เซลล์ประสาทที่สว่างที่สุดของชั้นส่งออกนั้นเป็นทางเลือกของเครือข่ายเพื่อที่จะพูดว่ารูปภาพนี้เป็นภาพอะไร?",
  "n_reviews": 0,
  "start": 322.56,
  "end": 329.4
 },
 {
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "translatedText": "",
  "from_community_srt": "และก่อนที่จะกระโดดลงไปในวิชาคณิตศาสตร์สำหรับวิธีการหนึ่งชั้นมีอิทธิพลต่อการฝึกอบรมต่อไปหรืออย่างไร? ลองพูดถึงเหตุผลว่าทำไมถึงสมควรที่จะคาดหวังให้โครงสร้างแบบเลเยอร์แบบนี้ทำงานได้อย่างชาญฉลาด เราคาดหวังอะไรที่นี่?",
  "n_reviews": 0,
  "start": 332.56,
  "end": 343.52
 },
 {
  "input": "What are we expecting here?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 344.06,
  "end": 345.22
 },
 {
  "input": "What is the best hope for what those middle layers might be doing?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 345.4,
  "end": 347.6
 },
 {
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "translatedText": "",
  "from_community_srt": "อะไรคือความหวังที่ดีที่สุดสำหรับสิ่งที่ชั้นกลางเหล่านี้อาจจะทำ? เมื่อคุณหรือฉันรู้จักตัวเลขที่เรารวบรวมส่วนประกอบต่างๆไว้เก้าชิ้นจะมีวงแหวนขึ้นด้านบนและมีสายด้านขวา",
  "n_reviews": 0,
  "start": 348.92,
  "end": 353.52
 },
 {
  "input": "A 9 has a loop up top and a line on the right.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 354.2,
  "end": 356.82
 },
 {
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 357.38,
  "end": 361.18
 },
 {
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "translatedText": "",
  "from_community_srt": "8 ยังมีวงขึ้นด้านบน แต่ก็จับคู่กับอีกหนึ่งวงต่ำลง A 4 โดยทั่วไปแบ่งออกเป็นสามบรรทัดที่เฉพาะเจาะจงและสิ่งที่ต้องการที่",
  "n_reviews": 0,
  "start": 361.98,
  "end": 366.82
 },
 {
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "translatedText": "",
  "from_community_srt": "ตอนนี้ในโลกที่สมบูรณ์แบบเราอาจหวังว่าแต่ละเซลล์ประสาทจะอยู่ในชั้นที่สองถึงชั้นสุดท้าย ตรงกับคอมโพเนนต์ย่อยเหล่านี้ ทุกครั้งที่คุณป้อนข้อมูลในรูปด้วยการพูดว่าห่วงขึ้นด้านบนเช่น 9 หรือ 8 มีบางอย่างที่เฉพาะเจาะจง",
  "n_reviews": 0,
  "start": 367.6,
  "end": 383.78
 },
 {
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "translatedText": "",
  "from_community_srt": "Neuron ที่มีการเปิดใช้งานกำลังจะใกล้เคียงกับหนึ่งและฉันไม่ได้หมายถึงวงพิกเซลที่เฉพาะเจาะจงนี้หวังว่าจะเป็นที่ใด",
  "n_reviews": 0,
  "start": 384.5,
  "end": 391.56
 },
 {
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "translatedText": "",
  "from_community_srt": "รูปแบบ loopy โดยทั่วไปไปทางด้านบนจะตั้งเซลล์ประสาทชนิดนี้ออกจากชั้นที่ 3 เป็นครั้งสุดท้าย เพียงต้องการการเรียนรู้ซึ่งการรวมส่วนประกอบย่อยสอดคล้องกับตัวเลขใด",
  "n_reviews": 0,
  "start": 392.44,
  "end": 400.04
 },
 {
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "translatedText": "",
  "from_community_srt": "แน่นอนว่าเพียงแค่เตะปัญหาลงที่ถนน เนื่องจากคุณจะจำแนกองค์ประกอบย่อยเหล่านี้ได้อย่างไรหรือเรียนรู้ว่าองค์ประกอบย่อยที่ถูกต้องควรเป็นอย่างไรและฉันยังไม่ได้พูดถึงเรื่องนี้",
  "n_reviews": 0,
  "start": 401.0,
  "end": 407.64
 },
 {
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "translatedText": "",
  "from_community_srt": "ชั้นหนึ่งมีอิทธิพลต่อสิ่งใดต่อไป แต่ให้วิ่งไปกับฉันในช่วงนี้สักครู่ ตระหนักถึงห่วงยังสามารถแบ่งย่อยเป็นปัญหาย่อยได้",
  "n_reviews": 0,
  "start": 408.06,
  "end": 413.06
 },
 {
  "input": "Recognizing a loop can also break down into subproblems.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 413.68,
  "end": 416.68
 },
 {
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 417.28,
  "end": 422.78
 },
 {
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "translatedText": "",
  "from_community_srt": "วิธีหนึ่งที่สมเหตุสมผลในการทำเช่นนี้คือการจำแนกขอบเล็ก ๆ ต่างๆที่ทำให้เกิดขึ้นได้ เช่นเดียวกับเส้นยาวเช่นเดียวกับที่คุณอาจเห็นในตัวเลข 1 หรือ 4 หรือ 7 ดีที่จริงๆเพียงขอบยาวหรือบางทีคุณอาจคิดว่ามันเป็นรูปแบบบางส่วนของขอบเล็ก ๆ บางทีความหวังของเราก็คือเซลล์ประสาทแต่ละตัวอยู่ในชั้นที่สองของเครือข่าย",
  "n_reviews": 0,
  "start": 423.78,
  "end": 434.32
 },
 {
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 435.14,
  "end": 442.72
 },
 {
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "translatedText": "",
  "from_community_srt": "สอดคล้องกับขอบเล็ก ๆ ที่เกี่ยวข้อง บางทีเมื่อภาพเช่นนี้มาในนั้นไฟขึ้นทั้งหมดของเซลล์ประสาท ที่เกี่ยวข้องกับรอบแปดถึงสิบเฉพาะขอบเล็ก ๆ ซึ่งจะหมุนเวียนเซลล์ประสาทที่เกี่ยวข้องกับวงบนและเส้นแนวตั้งยาวและ ผู้ที่สว่างขึ้นเซลล์ประสาทที่เกี่ยวข้องกับเก้า",
  "n_reviews": 0,
  "start": 443.54,
  "end": 459.72
 },
 {
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "translatedText": "",
  "from_community_srt": "ไม่ว่าจะเป็น นี่คือสิ่งที่เครือข่ายสุดท้ายของเรามีอยู่จริงคือคำถามหนึ่งที่เราจะกลับมาดูเมื่อเราดูวิธีการฝึกอบรมเครือข่าย",
  "n_reviews": 0,
  "start": 460.68,
  "end": 472.54
 },
 {
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "translatedText": "",
  "from_community_srt": "แต่นี่เป็นความหวังที่เราอาจมี การจัดเรียงของเป้าหมายที่มีโครงสร้างแบบชั้นเช่นนี้ นอกจากนี้คุณสามารถจินตนาการได้ว่าการตรวจจับขอบและรูปแบบเช่นนี้จะเป็นประโยชน์อย่างแท้จริงสำหรับงานการจดจำภาพอื่น ๆ หรือไม่",
  "n_reviews": 0,
  "start": 473.16,
  "end": 480.3
 },
 {
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "translatedText": "",
  "from_community_srt": "แม้กระทั่งการรับรู้ภาพจะมีทุกสิ่งที่ชาญฉลาดที่คุณอาจต้องการทำซึ่งแบ่งออกเป็นชั้นของสิ่งที่เป็นนามธรรม",
  "n_reviews": 0,
  "start": 480.88,
  "end": 487.28
 },
 {
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "translatedText": "",
  "from_community_srt": "การแยกเสียงพูดเช่นการหยิบเสียงดิบและการเลือกเสียงที่แตกต่างซึ่งรวมกันเพื่อให้พยางค์บางเสียง",
  "n_reviews": 0,
  "start": 488.04,
  "end": 500.06
 },
 {
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "translatedText": "",
  "from_community_srt": "ซึ่งรวมกันเป็นคำที่รวมกันเพื่อทำเป็นวลีและความคิดที่เป็นนามธรรมมากขึ้นเป็นต้น แต่กลับไปที่วิธีการใด ๆ นี้จริงการทำงานภาพตัวเองในขณะนี้การออกแบบ",
  "n_reviews": 0,
  "start": 501.1,
  "end": 509.92
 },
 {
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "translatedText": "",
  "from_community_srt": "วิธี activations ในชั้นเดียวอาจกำหนด activations ในถัดไปหรือไม่ เป้าหมายคือการมีกลไกบางอย่างที่น่าจะสามารถรวมพิกเซลเข้ากับขอบได้",
  "n_reviews": 0,
  "start": 510.86,
  "end": 518.98
 },
 {
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "translatedText": "",
  "from_community_srt": "หรือขอบเป็นรูปแบบหรือรูปแบบเป็นตัวเลขและเพื่อซูมเข้าในตัวอย่างที่เฉพาะเจาะจงมาก สมมุติว่าความหวังสำหรับคนพิเศษ Neuron ในชั้นที่สองเพื่อรับภาพที่มีขอบในภูมิภาคนี้หรือไม่ คำถามในมือคือสิ่งที่ควรจะเป็นเครือข่ายของเครือข่าย",
  "n_reviews": 0,
  "start": 519.44,
  "end": 530.62
 },
 {
  "input": "The question at hand is what parameters should the network have?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 531.44,
  "end": 535.1
 },
 {
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "translatedText": "",
  "from_community_srt": "สิ่งที่หมุนและลูกบิดคุณควรจะสามารถปรับแต่งเพื่อให้มันแสดงออกมากพอที่จะสามารถจับภาพรูปแบบนี้หรือ",
  "n_reviews": 0,
  "start": 535.64,
  "end": 547.78
 },
 {
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "translatedText": "",
  "from_community_srt": "รูปแบบพิกเซลอื่นหรือรูปแบบที่ขอบหลาย ๆ สามารถสร้างลูปและสิ่งอื่น ๆ ได้หรือไม่? ดีสิ่งที่เราจะทำคือกำหนดน้ำหนักให้กับแต่ละการเชื่อมต่อระหว่างเซลล์ประสาทและเซลล์ประสาทของเราจากชั้นแรก",
  "n_reviews": 0,
  "start": 548.72,
  "end": 555.56
 },
 {
  "input": "These weights are just numbers.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 556.32,
  "end": 557.7
 },
 {
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "translatedText": "",
  "from_community_srt": "น้ำหนักเหล่านี้เป็นตัวเลขเพียงอย่างเดียว จากนั้นใช้การกระตุ้นทั้งหมดจากเลเยอร์แรกและคำนวณผลรวมน้ำหนักตามน้ำหนักเหล่านี้ I",
  "n_reviews": 0,
  "start": 558.54,
  "end": 565.5
 },
 {
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "translatedText": "",
  "from_community_srt": "หาข้อมูลที่เป็นประโยชน์ในการพิจารณาน้ำหนักเหล่านี้ว่าเป็นการจัดเป็นตารางย่อย ๆ ของตนเอง และฉันจะใช้พิกเซลสีเขียวเพื่อระบุน้ำหนักบวกและพิกเซลสีแดงเพื่อระบุน้ำหนักที่เป็นค่าลบ ในกรณีที่ความสว่างของพิกเซลนั้นเป็นภาพของค่าน้ำหนักที่หลวม? ตอนนี้ถ้าเราทำน้ำหนักที่สัมพันธ์กับจุดพิกเซลเกือบทั้งหมด",
  "n_reviews": 0,
  "start": 567.7,
  "end": 581.78
 },
 {
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "translatedText": "",
  "from_community_srt": "ยกเว้นน้ำหนักที่เป็นบวกบางส่วนในภูมิภาคนี้ที่เราใส่ใจ แล้วนำผลรวมถ่วงน้ำหนักของ ค่าพิกเซลทั้งหมดจริงๆเพียงจำนวนเงินที่จะเพิ่มค่าของพิกเซลเพียงในพื้นที่ที่เราใส่ใจ",
  "n_reviews": 0,
  "start": 582.78,
  "end": 597.82
 },
 {
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "translatedText": "",
  "from_community_srt": "และหากคุณต้องการรับข้อมูลว่ามีขอบอยู่ตรงนี้สิ่งที่คุณควรทำคือมีน้ำหนักเชิงลบ เกี่ยวข้องกับพิกเซลแวดล้อม",
  "n_reviews": 0,
  "start": 599.14,
  "end": 606.6
 },
 {
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "translatedText": "",
  "from_community_srt": "ยอดรวมนั้นใหญ่ที่สุดเมื่อพิกเซลกลางสว่าง แต่พิกเซลแวดล้อมมืด เมื่อคุณคำนวณจำนวนเงินที่ถ่วงน้ำหนักเช่นนี้คุณอาจออกมาพร้อมกับหมายเลขใดก็ได้",
  "n_reviews": 0,
  "start": 607.48,
  "end": 612.7
 },
 {
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "แต่สำหรับเครือข่ายนี้สิ่งที่เราต้องการคือการเปิดใช้งานให้มีค่าระหว่าง 0 และ 1 ดังนั้นสิ่งที่ต้องทำก็คือการทุ่มเงินจำนวนนี้",
  "n_reviews": 0,
  "start": 614.26,
  "end": 623.54
 },
 {
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "เป็นฟังก์ชันบางอย่างที่ squishes เส้นจำนวนจริงในช่วงระหว่าง 0 และ 1 และ ฟังก์ชันทั่วไปที่เรียกว่า sigmoid function หรือที่เรียกว่า logistic curve",
  "n_reviews": 0,
  "start": 624.12,
  "end": 632.14
 },
 {
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 632.46,
  "end": 637.42
 },
 {
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "translatedText": "",
  "from_community_srt": "ปัจจัยการผลิตเชิงลบโดยส่วนมากจะจบลงใกล้ศูนย์ปัจจัยการผลิตที่เป็นบวกมากใกล้เคียงกับ 1 และเพิ่มขึ้นเรื่อย ๆ ประมาณ 0 อินพุท",
  "n_reviews": 0,
  "start": 638.0,
  "end": 646.6
 },
 {
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "translatedText": "",
  "from_community_srt": "ดังนั้นการเปิดใช้งานของเซลล์ประสาทที่นี่เป็นพื้นวัดของวิธีการบวกบวกถ่วงน้ำหนักที่เกี่ยวข้องคือ",
  "n_reviews": 0,
  "start": 649.12,
  "end": 656.36
 },
 {
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "translatedText": "",
  "from_community_srt": "แต่อาจไม่ใช่ว่าคุณต้องการให้เซลล์ประสาทสว่างขึ้นเมื่อผลรวมที่มีค่ามากกว่า 0 บางทีคุณอาจต้องการให้ใช้งานได้เมื่อผลรวมใหญ่กว่าพูด 10",
  "n_reviews": 0,
  "start": 657.54,
  "end": 661.88
 },
 {
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 662.28,
  "end": 666.36
 },
 {
  "input": "That is, you want some bias for it to be inactive.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 666.84,
  "end": 670.26
 },
 {
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "translatedText": "",
  "from_community_srt": "นั่นคือคุณต้องการอคติบางอย่างที่จะไม่ใช้งาน สิ่งที่เราจะทำก็คือเพิ่มจำนวนอื่นเช่นลบ 10 เป็นจำนวนรวมที่ถ่วงนี้",
  "n_reviews": 0,
  "start": 671.38,
  "end": 679.66
 },
 {
  "input": "That additional number is called the bias.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 680.58,
  "end": 682.44
 },
 {
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "translatedText": "",
  "from_community_srt": "ก่อนที่จะเสียบผ่านฟังก์ชัน squishification sigmoid จำนวนเพิ่มเติมที่เรียกว่าอคติ ดังนั้นน้ำหนักบอกคุณว่ารูปแบบพิกเซลนี้เซลล์ประสาทในชั้นที่สองคือการรับขึ้นและอคติ บอกคุณว่าผลรวมที่ถ่วงน้ำหนักต้องเป็นอย่างไรก่อนที่เซลล์ประสาทจะเริ่มทำงานอย่างมีนัยสำคัญ และนั่นเป็นเพียงเซลล์ประสาทตัวเดียว",
  "n_reviews": 0,
  "start": 683.46,
  "end": 695.18
 },
 {
  "input": "And that is just one neuron.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 696.12,
  "end": 697.68
 },
 {
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "translatedText": "",
  "from_community_srt": "เซลล์ประสาททุกตัวในชั้นนี้จะเชื่อมต่อกับทุกเซลล์ 784 พิกเซลเซลล์ประสาทจากชั้นแรกและหนึ่งในนั้น 784 การเชื่อมต่อมีน้ำหนักของตัวเองที่เกี่ยวข้องกับมัน",
  "n_reviews": 0,
  "start": 698.28,
  "end": 710.94
 },
 {
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "translatedText": "",
  "from_community_srt": "แต่ละคนมีอคติบางจำนวนอื่น ๆ ที่คุณเพิ่มไปยังผลรวมถัวเฉลี่ยก่อน squishing กับ sigmoid และ นั่นเป็นจำนวนมากที่จะคิดเกี่ยวกับกับชั้นที่ซ่อนอยู่นี้ของ 16 เซลล์ประสาท",
  "n_reviews": 0,
  "start": 711.6,
  "end": 717.6
 },
 {
  "input": "And that's a lot to think about!",
  "translatedText": "",
  "n_reviews": 0,
  "start": 718.11,
  "end": 719.54
 },
 {
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 719.96,
  "end": 727.98
 },
 {
  "input": "And all of that is just the connections from the first layer to the second.",
  "translatedText": "",
  "from_community_srt": "นั่นคือทั้งหมด 784 ครั้ง 16 น้ำหนักพร้อมกับ 16 อคติ ทั้งหมดนี้เป็นเพียงการเชื่อมต่อจากเลเยอร์แรกไปจนถึงจุดเชื่อมต่อระหว่างชั้นอื่น ๆ",
  "n_reviews": 0,
  "start": 728.84,
  "end": 731.94
 },
 {
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 732.52,
  "end": 737.34
 },
 {
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "translatedText": "",
  "from_community_srt": "นอกจากนี้ยังมีน้ำหนักและอคติที่เกี่ยวข้องอีกด้วย ทั้งหมดกล่าวและทำเครือข่ายนี้ได้เกือบจะแน่นอน",
  "n_reviews": 0,
  "start": 738.34,
  "end": 743.8
 },
 {
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "translatedText": "",
  "from_community_srt": "น้ำหนักและอคติทั้งสิ้น 13,000 ปุ่มหมุนและลูกบิด 13,000 ปุ่มที่สามารถปรับแต่งและหมุนเพื่อทำให้เครือข่ายนี้ทำงานได้หลายวิธี",
  "n_reviews": 0,
  "start": 743.8,
  "end": 749.96
 },
 {
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "translatedText": "",
  "from_community_srt": "ดังนั้นเมื่อเราพูดถึงการเรียนรู้? สิ่งที่หมายถึงคือการทำให้คอมพิวเตอร์หาการตั้งค่าที่ถูกต้องสำหรับตัวเลขจำนวนมากทั้งหมดเหล่านี้จำนวนมากเพื่อให้สามารถแก้ปัญหาได้จริง",
  "n_reviews": 0,
  "start": 751.04,
  "end": 761.36
 },
 {
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "translatedText": "",
  "from_community_srt": "ปัญหาอยู่ในมือ หนึ่งคิด การทดลองที่สนุกสนานและน่าสะพรึงกลัวคือการจินตนาการให้นั่งลงและตั้งค่าทั้งหมดของน้ำหนักและอคติเหล่านี้ด้วยมือ ปรับแต่งตัวเลขอย่างรอบคอบเพื่อให้ชั้นที่สองหยิบขึ้นมาบนขอบชั้นที่สามจะหยิบขึ้นมาบนรูปแบบอื่น ๆ",
  "n_reviews": 0,
  "start": 762.62,
  "end": 776.58
 },
 {
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "translatedText": "",
  "from_community_srt": "ฉันเองพบความพึงพอใจมากกว่าเพียงแค่อ่านเครือข่ายเป็นกล่องสีดำทั้งหมด เพราะเมื่อเครือข่ายไม่ทำงานตามที่คุณต้องการ คาดหวังว่าคุณจะมีความสัมพันธ์กับสิ่งที่น้ำหนักและความอคติเหล่านี้จริง ๆ หมายความว่าคุณมีสถานที่เริ่มต้น",
  "n_reviews": 0,
  "start": 776.98,
  "end": 794.18
 },
 {
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "translatedText": "",
  "from_community_srt": "ทดลองใช้วิธีเปลี่ยนโครงสร้างเพื่อปรับปรุงหรือเมื่อเครือข่ายทำงาน ไม่ใช่เหตุผลที่คุณคาดหวัง การขุดเจาะสิ่งที่น้ำหนักและอคติกำลังทำอยู่เป็นวิธีที่ดีในการท้าทายสมมติฐานของคุณและเปิดเผยพื้นที่เต็มรูปแบบที่เป็นไปได้",
  "n_reviews": 0,
  "start": 794.96,
  "end": 805.82
 },
 {
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 806.84,
  "end": 810.68
 },
 {
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "translatedText": "",
  "from_community_srt": "การแก้ปัญหา โดยวิธีการทำงานจริงที่นี่เป็นเพียงเล็กน้อยยุ่งยากในการเขียนลง คุณไม่คิดเหรอ? ดังนั้นให้ฉันแสดงวิธีการที่มีขนาดกะทัดรัดมากขึ้นในรูปแบบ notationally ซึ่งแสดงว่ามีการเชื่อมต่อเหล่านี้ นี่คือสิ่งที่คุณจะเห็น",
  "n_reviews": 0,
  "start": 812.5,
  "end": 817.14
 },
 {
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 817.66,
  "end": 820.52
 },
 {
  "input": "Organize all of the activations from one layer into a column as a vector.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 821.38,
  "end": 820.52
 },
 {
  "input": "Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "translatedText": "",
  "from_community_srt": "ถ้าคุณเลือกที่จะอ่านเพิ่มเติมเกี่ยวกับเครือข่ายประสาท จัดระเบียบการเปิดใช้งานทั้งหมดจากชั้นหนึ่งเป็นคอลัมน์เป็นเวกเตอร์ จากนั้นจัดระเบียบน้ำหนักทั้งหมดเป็นเมตริกซ์ที่แต่ละแถวของเมทริกซ์นั้น สอดคล้องกับการเชื่อมต่อระหว่างชั้นหนึ่งกับเซลล์ประสาทที่เฉพาะเจาะจงในชั้นถัดไป",
  "n_reviews": 0,
  "start": 821.38,
  "end": 838.0
 },
 {
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "translatedText": "",
  "from_community_srt": "สิ่งที่หมายถึงคือการใช้น้ำหนักของการกระตุ้นในชั้นแรกตามน้ำหนักเหล่านี้หรือไม่? สอดคล้องกับเงื่อนไขข้อใดข้อหนึ่งในผลิตภัณฑ์เมตริกซ์เวกเตอร์ของทุกสิ่งทุกอย่างที่เรามีด้านซ้ายที่นี่",
  "n_reviews": 0,
  "start": 838.54,
  "end": 849.88
 },
 {
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "translatedText": "",
  "from_community_srt": "โดยวิธีการมากของการเรียนรู้เครื่องเพียงแค่ลงมามีความเข้าใจที่ดีของพีชคณิตเชิงเส้น ดังนั้นสำหรับคุณที่ต้องการความเข้าใจภาพที่ดีสำหรับเมทริกซ์และสิ่งที่การคูณเวกเตอร์เมทริกซ์หมายถึงดูที่ชุดที่ฉันทำในพีชคณิตเชิงเส้น",
  "n_reviews": 0,
  "start": 854.0,
  "end": 868.6
 },
 {
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "translatedText": "",
  "from_community_srt": "โดยเฉพาะบทที่สาม กลับไปที่การแสดงออกของเราแทนที่จะพูดถึงการเพิ่มความลำเอียงให้กับแต่ละค่าเหล่านี้อย่างอิสระ การจัดอคติเหล่านี้ให้เป็นเวกเตอร์และเพิ่มเวกเตอร์ทั้งหมดลงในผลิตภัณฑ์เวคเตอร์เมทริกซ์ก่อนหน้านี้",
  "n_reviews": 0,
  "start": 869.24,
  "end": 882.3
 },
 {
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "translatedText": "",
  "from_community_srt": "จากนั้นเป็นขั้นตอนสุดท้าย ฉันจะแร็พ sigmoid รอบด้านนอกที่นี่ และสิ่งที่ควรจะหมายถึงคือคุณจะใช้ฟังก์ชัน sigmoid กับแต่ละเฉพาะ",
  "n_reviews": 0,
  "start": 883.28,
  "end": 894.74
 },
 {
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "translatedText": "",
  "from_community_srt": "ส่วนประกอบของเวกเตอร์ที่เกิดขึ้นภายใน ดังนั้นเมื่อคุณจดเมทริกซ์น้ำหนักนี้และเวกเตอร์เหล่านี้เป็นสัญลักษณ์ของตัวเองที่คุณสามารถทำได้ สื่อสารการเปลี่ยนจากการเปิดใช้งานทั้งหมดจากชั้นหนึ่งไปยังอีกชั้นหนึ่งในการแสดงออกน้อยมากและแน่นและ นี้ทำให้รหัสที่เกี่ยวข้องทั้งง่ายมากและรวดเร็วยิ่งขึ้นเนื่องจากหลายห้องสมุดเพิ่มประสิทธิภาพ heck ออกจากการคูณเมทริกซ์",
  "n_reviews": 0,
  "start": 895.94,
  "end": 915.66
 },
 {
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 917.82,
  "end": 921.46
 },
 {
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "translatedText": "",
  "from_community_srt": "โปรดจำไว้ว่าก่อนหน้านี้ฉันกล่าวว่าเซลล์ประสาทเหล่านี้เป็นเพียงสิ่งที่ถือตัวเลข แน่นอนตัวเลขที่เฉพาะเจาะจงที่พวกเขาถือขึ้นอยู่กับภาพที่คุณฟีด ดังนั้นจึงเป็นจริงถูกต้องมากขึ้นในการคิดของเซลล์ประสาทแต่ละตัวเป็นฟังก์ชันที่ใช้เวลาใน เอาท์พุทของเซลล์ประสาททั้งหมดในชั้นก่อนหน้าและ spits ออกจำนวนระหว่างศูนย์และหนึ่ง",
  "n_reviews": 0,
  "start": 922.22,
  "end": 938.34
 },
 {
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "translatedText": "",
  "from_community_srt": "จริงๆเครือข่ายทั้งหมดเป็นเพียงหนึ่งฟังก์ชันที่ใช้เวลาค่ะ 784 เป็น input และ spits ออกสิบตัวเลขเป็นเอาท์พุท",
  "n_reviews": 0,
  "start": 939.2,
  "end": 947.06
 },
 {
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless.",
  "translatedText": "",
  "from_community_srt": "มันไร้สาระ ฟังก์ชันซับซ้อนหนึ่งที่เกี่ยวข้องกับพารามิเตอร์สามหมื่นในรูปแบบของน้ำหนักและอคติเหล่านี้ที่รับในรูปแบบบางอย่างและเกี่ยวข้องกับ iterating หลายผลิตภัณฑ์เวกเตอร์เมทริกซ์และฟังก์ชัน sigmoid squish evocation แต่มันก็เป็นเพียงแค่ฟังก์ชั่นและในแบบที่มันเป็นความมั่นใจว่ามันดูซับซ้อน",
  "n_reviews": 0,
  "start": 947.56,
  "end": 962.64
 },
 {
  "input": "And in a way it's kind of reassuring that it looks complicated.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 963.4,
  "end": 966.66
 },
 {
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "translatedText": "",
  "from_community_srt": "ฉันหมายความว่าถ้าเราหวังว่าเราจะมีความหวังที่ง่ายกว่านี้ และวิธีการที่จะใช้เวลาในการท้าทายที่?",
  "n_reviews": 0,
  "start": 967.34,
  "end": 972.28
 },
 {
  "input": "And how does it take on that challenge?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 973.34,
  "end": 974.7
 },
 {
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 975.08,
  "end": 979.36
 },
 {
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "translatedText": "",
  "from_community_srt": "เครือข่ายนี้จะเรียนรู้น้ำหนักและความลำเอียงที่เหมาะสมเพียงแค่ดูข้อมูล โอ้? นั่นคือสิ่งที่ฉันจะแสดงในวิดีโอถัดไปและฉันจะขุดเพิ่มเติมอีกนิดในสิ่งที่เครือข่ายเฉพาะที่เรากำลังดูอยู่นี้กำลังทำอยู่จริงๆ",
  "n_reviews": 0,
  "start": 980.14,
  "end": 986.12
 },
 {
  "input": "Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "translatedText": "",
  "from_community_srt": "ตอนนี้เป็นจุดที่ฉันคิดว่าฉันควรบอกว่าสมัครรับข้อมูลเพื่อรับทราบเมื่อวิดีโอหรือวิดีโอใหม่ ๆ ออกมา",
  "n_reviews": 0,
  "start": 987.58,
  "end": 997.42
 },
 {
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "translatedText": "",
  "from_community_srt": "แต่ในความสมจริงส่วนใหญ่คุณไม่ได้รับการแจ้งเตือนจาก YouTube จริงๆใช่ไหม อาจจะสุจริตมากขึ้นฉันควรบอกว่าสมัครรับข้อมูลเพื่อให้เครือข่ายประสาทที่รองรับ YouTube อัลกอริทึมคำแนะนำแนะนำให้เชื่อว่าคุณต้องการดูเนื้อหาจากช่องนี้ขอแนะนำให้คุณ ยังคงโพสต์มากขึ้น",
  "n_reviews": 0,
  "start": 998.02,
  "end": 1007.88
 },
 {
  "input": "Anyway, stay posted for more.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1008.56,
  "end": 1009.94
 },
 {
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1010.76,
  "end": 1013.5
 },
 {
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "translatedText": "",
  "from_community_srt": "ขอบคุณทุกคนที่สนับสนุนวิดีโอเหล่านี้ใน patreon ฉันได้รับความคืบหน้าในชุดความน่าจะเป็นช่วงฤดูร้อนนี้เล็กน้อย แต่ฉันกระโดดกลับเข้ามาหลังจากโครงการนี้เพื่อคุ้มครองคุณสามารถมองหาการปรับปรุงที่นั่น เพื่อปิดสิ่งต่างๆออกจากที่นี่ฉันมีกับฉัน Lisha Li",
  "n_reviews": 0,
  "start": 1014.0,
  "end": 1021.9
 },
 {
  "input": "To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "translatedText": "",
  "from_community_srt": "ลีผู้ซึ่งทำผลงานด้านการศึกษาระดับปริญญาเอกของเธอในด้านทฤษฎีของการเรียนรู้ลึก ๆ และปัจจุบันทำงานใน บริษัท ร่วมทุนที่เรียกว่าพันธมิตรขยายกิจการ",
  "n_reviews": 0,
  "start": 1023.6,
  "end": 1034.62
 },
 {
  "input": "So Lisha one thing I think we should quickly bring up is this sigmoid function.",
  "translatedText": "",
  "from_community_srt": "ใครให้ความกรุณาในการระดมทุนสำหรับวิดีโอนี้ดังนั้น Lisha จึงเป็นสิ่งหนึ่ง ฉันคิดว่าเราควรจะนำมาขึ้นเป็นฟังก์ชัน sigmoid นี้",
  "n_reviews": 0,
  "start": 1035.46,
  "end": 1039.12
 },
 {
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "translatedText": "",
  "from_community_srt": "ตามที่ฉันเข้าใจว่าเครือข่ายแรก ๆ ใช้วิธีนี้เพื่อหาค่าน้ำหนักที่เกี่ยวข้องในช่วงระหว่างศูนย์กับหนึ่ง คุณรู้ชนิดของแรงบันดาลใจจากการเปรียบเทียบทางชีววิทยาของเซลล์ประสาทนี้ไม่ว่าจะเป็นงานหรือใช้งาน (Lisha) - ถูกต้อง",
  "n_reviews": 0,
  "start": 1039.7,
  "end": 1049.84
 },
 {
  "input": "Exactly.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1050.28,
  "end": 1050.3
 },
 {
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "translatedText": "",
  "from_community_srt": "(3B1B) - แต่ค่อนข้างน้อยเครือข่ายสมัยใหม่ใช้ sigmoid อีกต่อไป นั่นเป็นเรื่องของโรงเรียนเก่าใช่มั้ย?",
  "n_reviews": 0,
  "start": 1050.56,
  "end": 1054.04
 },
 {
  "input": "Yeah.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1054.32,
  "end": 1054.32
 },
 {
  "input": "It's kind of old school right?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1054.44,
  "end": 1055.54
 },
 {
  "input": "Yeah or rather ReLU seems to be much easier to train.",
  "translatedText": "",
  "from_community_srt": "(Lisha) - ใช่หรือค่อนข้าง ReLU ดูเหมือนว่าจะฝึกได้ง่ายกว่ามาก (3B1B) - และ ReLU ย่อมาจาก rectified linear unit",
  "n_reviews": 0,
  "start": 1055.76,
  "end": 1058.98
 },
 {
  "input": "And ReLU, ReLU stands for rectified linear unit?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1059.4,
  "end": 1062.34
 },
 {
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not.",
  "translatedText": "",
  "from_community_srt": "(Lisha) - ใช่นี่เป็นฟังก์ชันแบบนี้ที่คุณใช้เวลาเพียงแค่ไม่ถึง 0 และที่ a จะได้รับโดย สิ่งที่คุณกำลังอธิบายในวิดีโอและสิ่งที่เป็นแรงบันดาลใจแบบนี้จากที่ฉันคิดว่าเป็น บางส่วนโดยทางชีวภาพ คล้ายคลึงกับวิธี เซลล์ประสาทจะทำงานได้หรือไม่และถ้าผ่านเกณฑ์หนึ่ง มันจะเป็นฟังก์ชันการระบุตัวตน",
  "n_reviews": 0,
  "start": 1062.68,
  "end": 1081.36
 },
 {
  "input": "And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "translatedText": "",
  "from_community_srt": "แต่ถ้ามันไม่ได้แล้วมันก็จะไม่ได้รับการเปิดใช้งานเพื่อให้เป็นศูนย์ดังนั้นจึงเป็นชนิดของการทำให้เข้าใจง่าย",
  "n_reviews": 0,
  "start": 1081.36,
  "end": 1090.84
 },
 {
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks.",
  "translatedText": "",
  "from_community_srt": "การใช้ sigmaids ไม่ได้ช่วยในการฝึกอบรมหรือการฝึกอบรมทำได้ยากมาก ในบางประเด็นและผู้คนเพิ่งลอง relu และมันก็เกิดขึ้นกับการทำงาน เป็นอย่างดีสำหรับคนเหล่านี้อย่างไม่น่าเชื่อ เครือข่ายประสาทเทียมลึก (3B1B) - ถูกต้อง ขอบคุณ Lisha",
  "n_reviews": 0,
  "start": 1091.16,
  "end": 1104.62
 },
 {
  "input": "All right thank you Lisha.",
  "translatedText": "",
  "from_community_srt": "ขอบคุณ Lisha",
  "n_reviews": 0,
  "start": 1105.1,
  "end": 1105.64
 }
]