[
 {
  "translatedText": "นี่คือ 3",
  "input": "This is a 3.",
  "model": "google_nmt",
  "time_range": [
   4.22,
   5.4
  ]
 },
 {
  "translatedText": "มีการเขียนและเรนเดอร์อย่างเลอะเทอะที่ความละเอียดต่ำมากที่ 28x28 พิกเซล แต่สมองของคุณไม่มีปัญหาในการจดจำว่าเป็น 3",
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "model": "google_nmt",
  "time_range": [
   6.06,
   13.72
  ]
 },
 {
  "translatedText": "และฉันอยากให้คุณใช้เวลาสักครู่เพื่อชื่นชมว่ามันบ้าแค่ไหนที่สมองสามารถทำสิ่งนี้ได้อย่างง่ายดาย",
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "model": "google_nmt",
  "time_range": [
   14.34,
   18.96
  ]
 },
 {
  "translatedText": "ฉันหมายถึง นี่ นี่ และ นี่ ยังรับรู้ได้ว่าเป็น 3 วินาที แม้ว่าค่าเฉพาะของแต่ละพิกเซลจะแตกต่างกันมากในแต่ละภาพ",
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "model": "google_nmt",
  "time_range": [
   19.7,
   28.32
  ]
 },
 {
  "translatedText": "เซลล์ที่ไวต่อแสงโดยเฉพาะในดวงตาของคุณที่กำลังยิงเมื่อคุณเห็น 3 สิ่งนี้แตกต่างอย่างมากจากเซลล์ที่ไวต่อแสงเมื่อคุณเห็น 3 นี้",
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "model": "google_nmt",
  "time_range": [
   28.9,
   36.94
  ]
 },
 {
  "translatedText": "แต่บางสิ่งบางอย่างในคอร์เทกซ์การมองเห็นที่ชาญฉลาดอย่างบ้าคลั่งของคุณนั้น สามารถแก้ไขปัญหาเหล่านี้ได้ โดยเป็นการแสดงถึงแนวคิดเดียวกัน ขณะเดียวกันก็รับรู้ถึงภาพอื่นๆ ว่าเป็นแนวคิดที่แตกต่างกันออกไป",
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "model": "google_nmt",
  "time_range": [
   37.52,
   48.26
  ]
 },
 {
  "translatedText": "แต่ถ้าฉันบอกคุณว่า เฮ้ นั่งลงแล้วเขียนโปรแกรมที่ใช้ตารางขนาด 28x28 พิกเซลแบบนี้ให้ฉัน แล้วส่งออกเป็นตัวเลขตัวเดียวระหว่าง 0 ถึง 10 เพื่อบอกคุณว่ามันคิดว่าตัวเลขนั้นคืออะไร เอาละ งานจะเริ่มต้นจาก เป็นเรื่องเล็กน้อยอย่างตลกขบขันไปจนถึงยากอย่างน่ากลัว",
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "model": "google_nmt",
  "time_range": [
   49.22,
   66.18
  ]
 },
 {
  "translatedText": "เว้นแต่ว่าคุณเคยอาศัยอยู่ใต้ก้อนหิน ฉันคิดว่าฉันแทบจะไม่จำเป็นต้องกระตุ้นความเกี่ยวข้องและความสำคัญของการเรียนรู้ของเครื่องและโครงข่ายประสาทเทียมในปัจจุบันและอนาคต",
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "model": "google_nmt",
  "time_range": [
   67.16,
   74.64
  ]
 },
 {
  "translatedText": "แต่สิ่งที่ฉันต้องการทำที่นี่คือแสดงให้คุณเห็นว่าแท้จริงแล้วโครงข่ายประสาทเทียมคืออะไร โดยไม่ต้องมีพื้นหลัง และเพื่อช่วยให้เห็นภาพว่ากำลังทำอะไรอยู่ ไม่ใช่เป็นคำศัพท์แต่เป็นชิ้นหนึ่งของคณิตศาสตร์",
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "model": "google_nmt",
  "time_range": [
   75.12,
   84.46
  ]
 },
 {
  "translatedText": "ความหวังของฉันคือการที่คุณรู้สึกราวกับว่าโครงสร้างนั้นได้รับแรงบันดาลใจ และรู้สึกเหมือนคุณรู้ว่ามันหมายถึงอะไรเมื่อคุณอ่าน หรือคุณได้ยินเกี่ยวกับการเรียนรู้แบบอ้างอิงคำพูดแบบโครงข่ายประสาทเทียม",
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "model": "google_nmt",
  "time_range": [
   85.02,
   94.34
  ]
 },
 {
  "translatedText": "วิดีโอนี้จะเน้นไปที่องค์ประกอบโครงสร้างของวิดีโอนั้น และวิดีโอต่อไปนี้จะพูดถึงการเรียนรู้",
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "model": "google_nmt",
  "time_range": [
   95.36,
   100.26
  ]
 },
 {
  "translatedText": "สิ่งที่เราจะทำคือรวบรวมโครงข่ายประสาทเทียม ที่สามารถเรียนรู้ที่จะจดจำตัวเลขที่เขียนด้วยลายมือได้",
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "model": "google_nmt",
  "time_range": [
   100.96,
   106.04
  ]
 },
 {
  "translatedText": "นี่เป็นตัวอย่างที่ค่อนข้างคลาสสิกในการแนะนำหัวข้อนี้ และฉันยินดีที่จะยึดถือสภาพที่เป็นอยู่นี้ต่อไป เพราะในตอนท้ายของวิดีโอทั้งสองนี้ ฉันอยากจะแนะนำให้คุณรู้จักแหล่งข้อมูลดีๆ สองสามแหล่งที่คุณสามารถเรียนรู้เพิ่มเติมได้ และที่ใด คุณสามารถดาวน์โหลดโค้ดที่ทำสิ่งนี้และเล่นกับมันบนคอมพิวเตอร์ของคุณเอง",
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "model": "google_nmt",
  "time_range": [
   109.36,
   123.08
  ]
 },
 {
  "translatedText": "โครงข่ายประสาทเทียมมีหลากหลายรูปแบบ และในช่วงไม่กี่ปีที่ผ่านมา มีการวิจัยเกี่ยวกับรูปแบบเหล่านี้เพิ่มมากขึ้น แต่ในวิดีโอแนะนำทั้งสองนี้ คุณและฉันกำลังจะดูรูปแบบวานิลลาธรรมดาที่สุด โดยไม่มีการตกแต่งเพิ่มเติม",
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "model": "google_nmt",
  "time_range": [
   125.04,
   139.18
  ]
 },
 {
  "translatedText": "นี่เป็นข้อกำหนดเบื้องต้นที่จำเป็นสำหรับการทำความเข้าใจตัวแปรสมัยใหม่ที่ทรงพลังกว่า และเชื่อฉันเถอะว่ายังคงมีความซับซ้อนมากมายสำหรับเราในการทำความเข้าใจ",
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "model": "google_nmt",
  "time_range": [
   139.86,
   148.6
  ]
 },
 {
  "translatedText": "แต่แม้จะอยู่ในรูปแบบที่ง่ายที่สุดนี้ ก็สามารถเรียนรู้ที่จะจดจำตัวเลขที่เขียนด้วยลายมือได้ ซึ่งถือเป็นสิ่งที่ยอดเยี่ยมสำหรับคอมพิวเตอร์ที่สามารถทำได้",
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "model": "google_nmt",
  "time_range": [
   149.12,
   156.52
  ]
 },
 {
  "translatedText": "และในเวลาเดียวกัน คุณจะเห็นว่ามันขาดความหวังสองสามประการที่เราอาจมีไว้ได้อย่างไร",
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "model": "google_nmt",
  "time_range": [
   157.48,
   162.28
  ]
 },
 {
  "translatedText": "ตามชื่อที่บ่งบอกว่าโครงข่ายประสาทเทียมได้รับแรงบันดาลใจจากสมอง แต่มาดูรายละเอียดกันดีกว่า",
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "model": "google_nmt",
  "time_range": [
   163.38,
   168.5
  ]
 },
 {
  "translatedText": "เซลล์ประสาทคืออะไร และพวกมันเชื่อมโยงเข้าด้วยกันในแง่ใด",
  "input": "What are the neurons, and in what sense are they linked together?",
  "model": "google_nmt",
  "time_range": [
   168.52,
   171.66
  ]
 },
 {
  "translatedText": "ตอนนี้เมื่อฉันพูดว่าเซลล์ประสาท สิ่งที่ฉันอยากให้คุณคิดคือสิ่งที่เก็บตัวเลข โดยเฉพาะตัวเลขระหว่าง 0 ถึง 1",
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   172.5,
   180.44
  ]
 },
 {
  "translatedText": "มันไม่ได้มากไปกว่านั้นจริงๆ",
  "input": "It's really not more than that.",
  "model": "google_nmt",
  "time_range": [
   180.68,
   182.56
  ]
 },
 {
  "translatedText": "ตัวอย่างเช่น เครือข่ายเริ่มต้นด้วยเซลล์ประสาทจำนวนหนึ่งซึ่งสอดคล้องกับแต่ละพิกเซลขนาด 28x28 พิกเซลของภาพที่นำเข้า ซึ่งมีจำนวนเซลล์ประสาททั้งหมด 784 เซลล์",
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "model": "google_nmt",
  "time_range": [
   183.78,
   194.22
  ]
 },
 {
  "translatedText": "แต่ละรายการจะมีตัวเลขที่แสดงถึงค่าระดับสีเทาของพิกเซลที่เกี่ยวข้อง ตั้งแต่ 0 สำหรับพิกเซลสีดำ จนถึง 1 สำหรับพิกเซลสีขาว",
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "model": "google_nmt",
  "time_range": [
   194.7,
   204.38
  ]
 },
 {
  "translatedText": "ตัวเลขภายในเซลล์ประสาทนี้เรียกว่าการกระตุ้น และภาพที่คุณอาจนึกถึงคือเซลล์ประสาทแต่ละอันจะสว่างขึ้นเมื่อมีการกระตุ้นจำนวนมาก",
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "model": "google_nmt",
  "time_range": [
   205.3,
   214.16
  ]
 },
 {
  "translatedText": "ดังนั้นเซลล์ประสาททั้ง 784 ตัวนี้จึงประกอบกันเป็นชั้นแรกของเครือข่ายของเรา",
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "model": "google_nmt",
  "time_range": [
   216.72,
   221.86
  ]
 },
 {
  "translatedText": "ตอนนี้กระโดดข้ามไปยังชั้นสุดท้าย จะมีเซลล์ประสาท 10 เซลล์ ซึ่งแต่ละอันเป็นตัวแทนของหนึ่งในตัวเลข",
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "model": "google_nmt",
  "time_range": [
   226.5,
   231.36
  ]
 },
 {
  "translatedText": "การกระตุ้นการทำงานของเซลล์ประสาทเหล่านี้ ซึ่งเป็นตัวเลขที่อยู่ระหว่าง 0 ถึง 1 อีกครั้ง แสดงให้เห็นว่าระบบคิดว่ารูปภาพหนึ่งๆ สอดคล้องกับตัวเลขที่กำหนดมากเพียงใด",
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "model": "google_nmt",
  "time_range": [
   232.04,
   242.12
  ]
 },
 {
  "translatedText": "นอกจากนี้ยังมีชั้นสองสามชั้นที่อยู่ระหว่างนั้น เรียกว่าชั้นที่ซ่อนอยู่ ซึ่งในขณะนี้น่าจะเป็นเพียงเครื่องหมายคำถามขนาดใหญ่ว่ากระบวนการจดจำตัวเลขนี้จะได้รับการจัดการอย่างไร",
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "model": "google_nmt",
  "time_range": [
   243.04,
   253.6
  ]
 },
 {
  "translatedText": "ในเครือข่ายนี้ ฉันเลือกเลเยอร์ที่ซ่อนอยู่สองชั้น แต่ละเลเยอร์มีเซลล์ประสาท 16 เซลล์ และยอมรับว่านั่นเป็นทางเลือกตามอำเภอใจ",
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "model": "google_nmt",
  "time_range": [
   254.26,
   260.56
  ]
 },
 {
  "translatedText": "พูดตามตรง ฉันเลือกสองชั้นโดยขึ้นอยู่กับว่าฉันต้องการกระตุ้นโครงสร้างในช่วงเวลาใดเวลาหนึ่ง และ 16 นั่นเป็นเพียงตัวเลขที่ดีที่จะพอดีกับหน้าจอ",
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "model": "google_nmt",
  "time_range": [
   261.02,
   268.2
  ]
 },
 {
  "translatedText": "ในทางปฏิบัติ มีพื้นที่มากมายสำหรับการทดลองกับโครงสร้างเฉพาะที่นี่",
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "model": "google_nmt",
  "time_range": [
   268.78,
   272.34
  ]
 },
 {
  "translatedText": "วิธีการทำงานของเครือข่าย การเปิดใช้งานในเลเยอร์หนึ่งจะกำหนดการเปิดใช้งานของเลเยอร์ถัดไป",
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "model": "google_nmt",
  "time_range": [
   273.02,
   278.48
  ]
 },
 {
  "translatedText": "และแน่นอนว่า หัวใจของเครือข่ายในฐานะกลไกการประมวลผลข้อมูลอยู่ที่ว่าการเปิดใช้งานจากเลเยอร์หนึ่งทำให้เกิดการเปิดใช้งานในเลเยอร์ถัดไปได้อย่างไร",
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "model": "google_nmt",
  "time_range": [
   279.2,
   288.58
  ]
 },
 {
  "translatedText": "มันมีความหมายที่จะคล้ายคลึงกันอย่างหลวมๆ กับวิธีที่ในเครือข่ายทางชีววิทยาของเซลล์ประสาท เซลล์ประสาทบางกลุ่มที่ยิงออกไป จะทำให้เซลล์บางตัวยิงออกไป",
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "model": "google_nmt",
  "time_range": [
   289.14,
   297.18
  ]
 },
 {
  "translatedText": "ตอนนี้เครือข่ายที่ฉันแสดงที่นี่ได้รับการฝึกอบรมให้จดจำตัวเลขแล้ว และให้ฉันแสดงให้คุณเห็นว่าฉันหมายถึงอะไร",
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "model": "google_nmt",
  "time_range": [
   298.12,
   303.4
  ]
 },
 {
  "translatedText": "หมายความว่าหากคุณป้อนรูปภาพ โดยให้แสงเซลล์ประสาททั้ง 784 เซลล์ของเลเยอร์อินพุตตามความสว่างของแต่ละพิกเซลในภาพ รูปแบบการเปิดใช้งานนั้นจะทำให้เกิดรูปแบบเฉพาะบางอย่างในเลเยอร์ถัดไป ซึ่งทำให้เกิดรูปแบบบางอย่างในเลเยอร์ถัดไป ซึ่งในที่สุดก็ให้รูปแบบบางอย่างในเลเยอร์เอาท์พุต",
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "model": "google_nmt",
  "time_range": [
   303.64,
   322.08
  ]
 },
 {
  "translatedText": "และเซลล์ประสาทที่สว่างที่สุดของเลเยอร์เอาท์พุตนั้น ก็คือตัวเลือกของเครือข่าย เพื่อที่จะบอกว่ารูปภาพนี้แสดงถึงตัวเลขใด",
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "model": "google_nmt",
  "time_range": [
   322.56,
   329.4
  ]
 },
 {
  "translatedText": "และก่อนที่จะกระโดดเข้าสู่คณิตศาสตร์ว่าเลเยอร์หนึ่งมีอิทธิพลต่อเลเยอร์ถัดไปอย่างไร หรือวิธีการฝึกอบรมทำงานอย่างไร เรามาพูดถึงเหตุผลว่าทำไมจึงสมเหตุสมผลที่จะคาดหวังว่าโครงสร้างแบบเลเยอร์เช่นนี้จะทำงานอย่างชาญฉลาด",
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "model": "google_nmt",
  "time_range": [
   332.56,
   343.52
  ]
 },
 {
  "translatedText": "เราคาดหวังอะไรที่นี่?",
  "input": "What are we expecting here?",
  "model": "google_nmt",
  "time_range": [
   344.06,
   345.22
  ]
 },
 {
  "translatedText": "ความหวังที่ดีที่สุดสำหรับชั้นกลางเหล่านั้นคืออะไร?",
  "input": "What is the best hope for those middle layers?",
  "model": "google_nmt",
  "time_range": [
   345.4,
   347.6
  ]
 },
 {
  "translatedText": "เมื่อคุณหรือฉันจำตัวเลขได้ เราจะประกอบส่วนประกอบต่างๆ เข้าด้วยกัน",
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "model": "google_nmt",
  "time_range": [
   348.92,
   353.52
  ]
 },
 {
  "translatedText": "A 9 มีห่วงด้านบนและมีเส้นทางด้านขวา",
  "input": "A 9 has a loop up top and a line on the right.",
  "model": "google_nmt",
  "time_range": [
   354.2,
   356.82
  ]
 },
 {
  "translatedText": "เลข 8 มีห่วงด้านบน แต่จะจับคู่กับอีกวงที่อยู่ด้านล่างต่ำ",
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "model": "google_nmt",
  "time_range": [
   357.38,
   361.18
  ]
 },
 {
  "translatedText": "โดยพื้นฐานแล้ว 4 แบ่งออกเป็นสามบรรทัดเฉพาะ และอะไรทำนองนั้น",
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "model": "google_nmt",
  "time_range": [
   361.98,
   366.82
  ]
 },
 {
  "translatedText": "ตอนนี้ในโลกที่สมบูรณ์แบบ เราอาจหวังว่าแต่ละเซลล์ประสาทในชั้นที่สองถึงชั้นสุดท้าย จะสอดคล้องกับหนึ่งในองค์ประกอบย่อยเหล่านี้ ซึ่งเมื่อใดก็ตามที่คุณป้อนภาพด้วยการวนซ้ำขึ้นไปด้านบน เช่น 9 หรือ 8 ก็มีบางอย่าง เซลล์ประสาทเฉพาะที่การกระตุ้นจะใกล้เคียงกับ 1",
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "model": "google_nmt",
  "time_range": [
   367.6,
   383.78
  ]
 },
 {
  "translatedText": "และฉันไม่ได้หมายถึงการวนซ้ำของพิกเซลแบบเฉพาะเจาะจงนี้ แต่หวังว่ารูปแบบการวนซ้ำโดยทั่วไปไปทางด้านบนจะทำให้เซลล์ประสาทนี้หลุดออกไป",
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "model": "google_nmt",
  "time_range": [
   384.5,
   391.56
  ]
 },
 {
  "translatedText": "ด้วยวิธีนี้ การไปจากเลเยอร์ที่สามไปยังเลเยอร์สุดท้ายเพียงแค่ต้องเรียนรู้ว่าส่วนประกอบย่อยใดที่สอดคล้องกับตัวเลขใด",
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "model": "google_nmt",
  "time_range": [
   392.44,
   400.04
  ]
 },
 {
  "translatedText": "แน่นอนว่านั่นเป็นเพียงแค่การเตะปัญหาออกไป เพราะคุณจะจดจำองค์ประกอบย่อยเหล่านี้ได้อย่างไร หรือแม้แต่เรียนรู้ว่าองค์ประกอบย่อยที่ถูกต้องควรเป็นอย่างไร",
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "model": "google_nmt",
  "time_range": [
   401.0,
   407.64
  ]
 },
 {
  "translatedText": "และฉันยังไม่ได้พูดด้วยซ้ำว่าชั้นหนึ่งมีอิทธิพลต่อชั้นถัดไปอย่างไร แต่ขอลองดูชั้นนี้กับฉันสักครู่",
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "model": "google_nmt",
  "time_range": [
   408.06,
   413.06
  ]
 },
 {
  "translatedText": "การรับรู้ลูปยังสามารถแยกย่อยเป็นปัญหาย่อยได้",
  "input": "Recognizing a loop can also break down into subproblems.",
  "model": "google_nmt",
  "time_range": [
   413.68,
   416.68
  ]
 },
 {
  "translatedText": "วิธีหนึ่งที่สมเหตุสมผลในการทำเช่นนี้คือการจดจำขอบเล็กๆ ต่างๆ ที่ประกอบกันเป็นอันดับแรก",
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "model": "google_nmt",
  "time_range": [
   417.28,
   422.78
  ]
 },
 {
  "translatedText": "ในทำนองเดียวกัน เส้นยาวเหมือนกับที่คุณเห็นในตัวเลข 1 หรือ 4 หรือ 7 จริงๆ แล้วเป็นเพียงเส้นยาว หรือบางทีคุณอาจคิดว่ามันเป็นรูปแบบหนึ่งของขอบเล็กๆ หลายเส้น",
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "model": "google_nmt",
  "time_range": [
   423.78,
   434.32
  ]
 },
 {
  "translatedText": "บางทีความหวังของเราก็คือ แต่ละเซลล์ประสาทในชั้นที่สองของเครือข่าย จะสอดคล้องกับขอบเล็กๆ ต่างๆ ที่เกี่ยวข้องกัน",
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "model": "google_nmt",
  "time_range": [
   435.14,
   442.72
  ]
 },
 {
  "translatedText": "บางที เมื่อมีภาพแบบนี้เข้ามา มันจะส่องสว่างเซลล์ประสาททั้งหมดที่เกี่ยวข้องกับขอบเล็กๆ ประมาณ 8 ถึง 10 ขอบ ซึ่งจะทำให้เซลล์ประสาทที่เกี่ยวข้องกับวงด้านบนและเส้นแนวตั้งยาวๆ สว่างขึ้น และเซลล์ประสาทเหล่านั้นจะสว่างขึ้น เซลล์ประสาทที่เกี่ยวข้องกับ 9",
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "model": "google_nmt",
  "time_range": [
   443.54,
   459.72
  ]
 },
 {
  "translatedText": "ไม่ว่านี่คือสิ่งที่เครือข่ายสุดท้ายของเราทำจริงหรือไม่นั้นเป็นอีกคำถามหนึ่ง คำถามหนึ่งที่ฉันจะกลับมาอีกครั้งเมื่อเราได้ดูวิธีฝึกเครือข่ายแล้ว แต่นี่คือความหวังที่เราอาจมี เป้าหมายประเภทหนึ่งที่มีโครงสร้างแบบเลเยอร์ แบบนี้.",
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "model": "google_nmt",
  "time_range": [
   460.68,
   472.54
  ]
 },
 {
  "translatedText": "ยิ่งไปกว่านั้น คุณสามารถจินตนาการได้ว่าความสามารถในการตรวจจับขอบและรูปแบบเช่นนี้จะมีประโยชน์มากสำหรับงานจดจำภาพอื่นๆ ได้อย่างไร",
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "model": "google_nmt",
  "time_range": [
   473.16,
   480.3
  ]
 },
 {
  "translatedText": "และนอกเหนือจากการจดจำภาพแล้ว ยังมีสิ่งชาญฉลาดทุกประเภทที่คุณอาจต้องการทำ โดยแยกย่อยออกเป็นชั้นๆ ของนามธรรม",
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "model": "google_nmt",
  "time_range": [
   480.88,
   487.28
  ]
 },
 {
  "translatedText": "ตัวอย่างเช่น การแยกวิเคราะห์คำพูดเกี่ยวข้องกับการแยกเสียงดิบและเลือกเสียงที่แตกต่างออกไป ซึ่งรวมกันเป็นพยางค์บางพยางค์ ซึ่งรวมกันเป็นคำ ซึ่งรวมกันเป็นวลีและความคิดที่เป็นนามธรรมมากขึ้น เป็นต้น",
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "model": "google_nmt",
  "time_range": [
   488.04,
   500.06
  ]
 },
 {
  "translatedText": "แต่เมื่อกลับมาดูว่าสิ่งเหล่านี้ใช้งานได้จริงอย่างไร ลองนึกภาพตัวคุณเองในตอนนี้ว่ากำลังออกแบบว่าการเปิดใช้งานในเลเยอร์หนึ่งสามารถกำหนดเลเยอร์ถัดไปได้อย่างไร",
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "model": "google_nmt",
  "time_range": [
   501.1,
   509.92
  ]
 },
 {
  "translatedText": "เป้าหมายคือการมีกลไกบางอย่างที่สามารถรวมพิกเซลเข้ากับขอบ หรือขอบเป็นรูปแบบ หรือรูปแบบเป็นตัวเลขได้",
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "model": "google_nmt",
  "time_range": [
   510.86,
   518.98
  ]
 },
 {
  "translatedText": "และเพื่อขยายไปยังตัวอย่างที่เจาะจงมาก สมมติว่ามีความหวังที่เซลล์ประสาทตัวใดตัวหนึ่งในชั้นที่สองจะพิจารณาว่าภาพนั้นมีความได้เปรียบในบริเวณนี้หรือไม่",
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "model": "google_nmt",
  "time_range": [
   519.44,
   530.62
  ]
 },
 {
  "translatedText": "คำถามที่อยู่ในมือคือ เครือข่ายควรมีพารามิเตอร์อะไรบ้าง?",
  "input": "The question at hand is what parameters should the network have?",
  "model": "google_nmt",
  "time_range": [
   531.44,
   535.1
  ]
 },
 {
  "translatedText": "คุณควรปรับแต่งแป้นหมุนและปุ่มหมุนใดเพื่อให้แสดงอารมณ์ได้มากพอที่จะจับภาพรูปแบบนี้ หรือรูปแบบพิกเซลอื่นๆ หรือรูปแบบที่ขอบหลายด้านสามารถสร้างเป็นวงได้ และอื่นๆ",
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "model": "google_nmt",
  "time_range": [
   535.64,
   547.78
  ]
 },
 {
  "translatedText": "สิ่งที่เราจะทำคือกำหนดน้ำหนักให้กับแต่ละการเชื่อมต่อระหว่างเซลล์ประสาทของเรากับเซลล์ประสาทจากชั้นแรก",
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "model": "google_nmt",
  "time_range": [
   548.72,
   555.56
  ]
 },
 {
  "translatedText": "น้ำหนักเหล่านี้เป็นเพียงตัวเลข",
  "input": "These weights are just numbers.",
  "model": "google_nmt",
  "time_range": [
   556.32,
   557.7
  ]
 },
 {
  "translatedText": "จากนั้นนำการเปิดใช้งานทั้งหมดจากเลเยอร์แรกมาคำนวณผลรวมถ่วงน้ำหนักตามน้ำหนักเหล่านี้",
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "model": "google_nmt",
  "time_range": [
   558.54,
   565.5
  ]
 },
 {
  "translatedText": "ฉันพบว่าการคิดว่าน้ำหนักเหล่านี้ถูกจัดเป็นตารางเล็กๆ ของตัวเองนั้นมีประโยชน์ และฉันจะใช้พิกเซลสีเขียวเพื่อระบุน้ำหนักที่เป็นบวก และใช้พิกเซลสีแดงเพื่อระบุน้ำหนักที่เป็นลบ โดยที่ความสว่างของพิกเซลนั้นมีค่าอยู่บ้าง การแสดงค่าน้ำหนักอย่างหลวมๆ",
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "model": "google_nmt",
  "time_range": [
   567.7,
   581.78
  ]
 },
 {
  "translatedText": "ตอนนี้ถ้าเราให้น้ำหนักที่เกี่ยวข้องกับพิกเซลเกือบทั้งหมดเป็นศูนย์ ยกเว้นน้ำหนักเชิงบวกบางส่วนในภูมิภาคนี้ที่เราสนใจ จากนั้นนำผลรวมถ่วงน้ำหนักของค่าพิกเซลทั้งหมดมารวมกันเพื่อเพิ่มค่าของพิกเซลเข้าไป ภูมิภาคที่เราใส่ใจ",
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "model": "google_nmt",
  "time_range": [
   582.78,
   597.82
  ]
 },
 {
  "translatedText": "และถ้าคุณอยากทราบว่ามีขอบตรงนี้หรือไม่ สิ่งที่คุณควรทำคือให้น้ำหนักเป็นลบที่เกี่ยวข้องกับพิกเซลรอบๆ",
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "model": "google_nmt",
  "time_range": [
   599.14,
   606.6
  ]
 },
 {
  "translatedText": "ผลรวมจะใหญ่ที่สุดเมื่อพิกเซลกลางสว่าง แต่พิกเซลโดยรอบมืดกว่า",
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "model": "google_nmt",
  "time_range": [
   607.48,
   612.7
  ]
 },
 {
  "translatedText": "เมื่อคุณคำนวณผลรวมถ่วงน้ำหนักเช่นนี้ คุณอาจได้ตัวเลขใดๆ ก็ตาม แต่สำหรับเครือข่ายนี้ สิ่งที่เราต้องการคือให้การเปิดใช้งานมีค่าอยู่ระหว่าง 0 ถึง 1",
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   614.26,
   623.54
  ]
 },
 {
  "translatedText": "สิ่งที่ต้องทำทั่วไปคือการอัดผลรวมถ่วงน้ำหนักนี้เข้าไปในฟังก์ชันที่จะบีบเส้นจำนวนจริงให้อยู่ในช่วงระหว่าง 0 ถึง 1",
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   624.12,
   632.14
  ]
 },
 {
  "translatedText": "และฟังก์ชันทั่วไปที่ทำสิ่งนี้ เรียกว่าฟังก์ชันซิกมอยด์ หรือที่เรียกว่าเส้นโค้งลอจิสติก",
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "model": "google_nmt",
  "time_range": [
   632.46,
   637.42
  ]
 },
 {
  "translatedText": "โดยพื้นฐานแล้วอินพุตที่เป็นลบจะเข้าใกล้ 0 อินพุตเชิงบวกจะเข้าใกล้ 1 และจะเพิ่มขึ้นเรื่อยๆ รอบอินพุต 0",
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "model": "google_nmt",
  "time_range": [
   638.0,
   646.6
  ]
 },
 {
  "translatedText": "ดังนั้นการกระตุ้นการทำงานของเซลล์ประสาทตรงนี้ จึงเป็นการวัดว่าผลรวมถ่วงน้ำหนักที่เกี่ยวข้องนั้นเป็นบวกเพียงใด",
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "model": "google_nmt",
  "time_range": [
   649.12,
   656.36
  ]
 },
 {
  "translatedText": "แต่บางทีอาจไม่ใช่ว่าคุณต้องการให้เซลล์ประสาทสว่างขึ้นเมื่อผลรวมถ่วงน้ำหนักมากกว่า 0",
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "model": "google_nmt",
  "time_range": [
   657.54,
   661.88
  ]
 },
 {
  "translatedText": "บางทีคุณอาจต้องการให้มันใช้งานได้เมื่อผลรวมมากกว่า 10 เท่านั้น",
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "model": "google_nmt",
  "time_range": [
   662.28,
   666.36
  ]
 },
 {
  "translatedText": "นั่นคือคุณต้องการให้มีอคติบางอย่างเพื่อให้มันไม่ทำงาน",
  "input": "That is, you want some bias for it to be inactive.",
  "model": "google_nmt",
  "time_range": [
   666.84,
   670.26
  ]
 },
 {
  "translatedText": "สิ่งที่เราจะทำคือแค่บวกเลขอื่นๆ เช่นลบ 10 เข้ากับผลบวกถ่วงน้ำหนักนี้ ก่อนที่จะแทนค่าผ่านฟังก์ชันซิกมอยด์สควิชิฟิเคชัน",
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "model": "google_nmt",
  "time_range": [
   671.38,
   679.66
  ]
 },
 {
  "translatedText": "จำนวนเพิ่มเติมนั้นเรียกว่าอคติ",
  "input": "That additional number is called the bias.",
  "model": "google_nmt",
  "time_range": [
   680.58,
   682.44
  ]
 },
 {
  "translatedText": "ดังนั้นน้ำหนักจะบอกคุณว่ารูปแบบพิกเซลของเซลล์ประสาทนี้ในเลเยอร์ที่สองกำลังรับอยู่เป็นอย่างไร และความลำเอียงจะบอกคุณว่าผลรวมถ่วงน้ำหนักจะต้องสูงเพียงใด ก่อนที่เซลล์ประสาทจะเริ่มทำงานอย่างมีความหมาย",
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "model": "google_nmt",
  "time_range": [
   683.46,
   695.18
  ]
 },
 {
  "translatedText": "และนั่นเป็นเพียงเซลล์ประสาทเดียว",
  "input": "And that is just one neuron.",
  "model": "google_nmt",
  "time_range": [
   696.12,
   697.68
  ]
 },
 {
  "translatedText": "เซลล์ประสาทอื่นๆ ทุกตัวในเลเยอร์นี้จะเชื่อมต่อกับเซลล์ประสาท 784 พิกเซลทั้งหมดจากเลเยอร์แรก และการเชื่อมต่อ 784 แต่ละอันจะมีน้ำหนักของมันเองที่เกี่ยวข้องกัน",
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "model": "google_nmt",
  "time_range": [
   698.28,
   710.94
  ]
 },
 {
  "translatedText": "นอกจากนี้ แต่ละตัวยังมีอคติอยู่ ตัวเลขอื่นๆ ที่คุณบวกเข้ากับผลรวมถ่วงน้ำหนักก่อนที่จะบีบมันด้วยซิกมอยด์",
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "model": "google_nmt",
  "time_range": [
   711.6,
   717.6
  ]
 },
 {
  "translatedText": "และนั่นเป็นเรื่องที่ต้องคิดมาก!",
  "input": "And that's a lot to think about!",
  "model": "google_nmt",
  "time_range": [
   718.11,
   719.54
  ]
 },
 {
  "translatedText": "ด้วยชั้นที่ซ่อนอยู่นี้ประกอบด้วยเซลล์ประสาท 16 เซลล์ ซึ่งรวมเป็น 784 คูณ 16 น้ำหนัก พร้อมด้วยอคติ 16 อัน",
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "model": "google_nmt",
  "time_range": [
   719.96,
   727.98
  ]
 },
 {
  "translatedText": "และทั้งหมดนั้นเป็นเพียงการเชื่อมต่อจากเลเยอร์แรกไปยังเลเยอร์ที่สอง",
  "input": "And all of that is just the connections from the first layer to the second.",
  "model": "google_nmt",
  "time_range": [
   728.84,
   731.94
  ]
 },
 {
  "translatedText": "การเชื่อมต่อระหว่างเลเยอร์อื่นๆ ยังมีน้ำหนักและอคติที่เกี่ยวข้องอยู่ด้วย",
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "model": "google_nmt",
  "time_range": [
   732.52,
   737.34
  ]
 },
 {
  "translatedText": "เมื่อพูดและทำเสร็จแล้ว เครือข่ายนี้มีน้ำหนักและอคติทั้งหมดเกือบ 13,000 รายการ",
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "model": "google_nmt",
  "time_range": [
   738.34,
   743.8
  ]
 },
 {
  "translatedText": "ปุ่มและแป้นหมุน 13,000 ปุ่มที่สามารถปรับแต่งและหมุนได้เพื่อให้เครือข่ายนี้ทำงานในรูปแบบที่แตกต่างกัน",
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "model": "google_nmt",
  "time_range": [
   743.8,
   749.96
  ]
 },
 {
  "translatedText": "เมื่อเราพูดถึงการเรียนรู้ สิ่งที่หมายถึงคือการให้คอมพิวเตอร์ ค้นหาการตั้งค่าที่ถูกต้อง สำหรับตัวเลขหลายๆ ตัวเหล่านี้ เพื่อที่มันจะแก้ปัญหาที่เกิดขึ้นได้จริง",
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "model": "google_nmt",
  "time_range": [
   751.04,
   761.36
  ]
 },
 {
  "translatedText": "การทดลองทางความคิดอย่างหนึ่งที่สนุกและน่ากลัวในคราวเดียว คือการจินตนาการถึงการนั่งลงและกำหนดน้ำหนักและอคติเหล่านี้ด้วยมือ โดยตั้งใจที่จะปรับแต่งตัวเลข เพื่อให้ชั้นที่สองหยิบขึ้นมาที่ขอบ ชั้นที่สามหยิบขึ้นมาจากรูปแบบ ฯลฯ",
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "model": "google_nmt",
  "time_range": [
   762.62,
   776.58
  ]
 },
 {
  "translatedText": "โดยส่วนตัวแล้ว ฉันพบว่าสิ่งนี้น่าพึงพอใจ มากกว่าแค่ปฏิบัติต่อเครือข่ายเสมือนเป็นกล่องดำทั้งหมด เพราะเมื่อเครือข่ายไม่ได้ดำเนินการตามที่คุณคาดหวัง หากคุณได้สร้างความสัมพันธ์ขึ้นมาเล็กน้อยกับความหมายของน้ำหนักและอคติเหล่านั้นจริงๆ คุณมีจุดเริ่มต้นสำหรับการทดลองเปลี่ยนแปลงโครงสร้างเพื่อปรับปรุง",
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "model": "google_nmt",
  "time_range": [
   776.98,
   794.18
  ]
 },
 {
  "translatedText": "หรือเมื่อเครือข่ายใช้งานได้แต่ไม่ใช่เหตุผลที่คุณอาจคาดหวัง การเจาะลึกถึงสิ่งที่น้ำหนักและอคติกำลังทำอยู่เป็นวิธีที่ดีในการท้าทายสมมติฐานของคุณและเปิดโปงแนวทางแก้ไขที่เป็นไปได้อย่างเต็มรูปแบบ",
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "model": "google_nmt",
  "time_range": [
   794.96,
   805.82
  ]
 },
 {
  "translatedText": "อย่างไรก็ตาม ฟังก์ชั่นจริงที่นี่ยุ่งยากนิดหน่อยในการเขียน คุณว่าไหม?",
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "model": "google_nmt",
  "time_range": [
   806.84,
   810.68
  ]
 },
 {
  "translatedText": "ขอผมแสดงวิธีแสดงการเชื่อมต่อเหล่านี้ให้กระชับยิ่งขึ้น",
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "model": "google_nmt",
  "time_range": [
   812.5,
   817.14
  ]
 },
 {
  "translatedText": "นี่คือวิธีที่คุณจะเห็นหากคุณเลือกที่จะอ่านเพิ่มเติมเกี่ยวกับโครงข่ายประสาทเทียม",
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "model": "google_nmt",
  "time_range": [
   817.66,
   820.52
  ]
 },
 {
  "translatedText": "จัดระเบียบการเปิดใช้งานทั้งหมดจากเลเยอร์หนึ่งลงในคอลัมน์เนื่องจากเมทริกซ์สอดคล้องกับการเชื่อมต่อระหว่างเลเยอร์หนึ่งกับเซลล์ประสาทเฉพาะในเลเยอร์ถัดไป",
  "input": "Organize all of the activations from one layer into a column as a matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "model": "google_nmt",
  "time_range": [
   821.38,
   838.0
  ]
 },
 {
  "translatedText": "ความหมายก็คือ การนำผลรวมถ่วงน้ำหนักของการกระตุ้นในชั้นแรกตามน้ำหนักเหล่านี้ สอดคล้องกับเงื่อนไขหนึ่งในผลคูณเมทริกซ์เวกเตอร์ของทุกสิ่งที่เรามีทางด้านซ้ายตรงนี้",
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "model": "google_nmt",
  "time_range": [
   838.54,
   849.88
  ]
 },
 {
  "translatedText": "อย่างไรก็ตาม แมชชีนเลิร์นนิงส่วนใหญ่เกิดจากการเข้าใจพีชคณิตเชิงเส้นเป็นอย่างดี ดังนั้น สำหรับใครก็ตามที่ต้องการความเข้าใจเกี่ยวกับเมทริกซ์ด้วยภาพ และการคูณเมทริกซ์เวกเตอร์หมายถึงอะไร ลองดูซีรีส์ที่ผมทำไว้ พีชคณิตเชิงเส้น โดยเฉพาะบทที่ 3",
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "model": "google_nmt",
  "time_range": [
   854.0,
   868.6
  ]
 },
 {
  "translatedText": "กลับมาที่นิพจน์ของเรา แทนที่จะพูดถึงการเพิ่มอคติให้กับค่าแต่ละค่าอย่างอิสระ เรานำเสนอมันโดยการจัดระเบียบอคติเหล่านั้นทั้งหมดให้เป็นเวกเตอร์ และเพิ่มเวกเตอร์ทั้งหมดลงในผลคูณเมทริกซ์เวกเตอร์ก่อนหน้า",
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "model": "google_nmt",
  "time_range": [
   869.24,
   882.3
  ]
 },
 {
  "translatedText": "ในขั้นตอนสุดท้าย ผมจะพันซิกมอยด์ไว้ด้านนอกตรงนี้ และสิ่งที่ควรจะเป็นตัวแทนคือ คุณจะใช้ฟังก์ชันซิกมอยด์กับแต่ละส่วนประกอบเฉพาะของเวกเตอร์ผลลัพธ์ที่อยู่ภายใน",
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "model": "google_nmt",
  "time_range": [
   883.28,
   894.74
  ]
 },
 {
  "translatedText": "ดังนั้นเมื่อคุณเขียนเมทริกซ์น้ำหนักนี้และเวกเตอร์เหล่านี้เป็นสัญลักษณ์ของตัวเอง คุณสามารถสื่อสารการเปลี่ยนแปลงเต็มรูปแบบของการเปิดใช้งานจากเลเยอร์หนึ่งไปยังเลเยอร์ถัดไปด้วยนิพจน์เล็กๆ น้อยๆ ที่รัดกุมและเรียบร้อยอย่างยิ่ง และสิ่งนี้ทำให้โค้ดที่เกี่ยวข้องทั้งง่ายขึ้นมากและ เร็วขึ้นมากเนื่องจากไลบรารีหลายแห่งปรับการคูณเมทริกซ์ให้เหมาะสมที่สุด",
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "model": "google_nmt",
  "time_range": [
   895.94,
   915.66
  ]
 },
 {
  "translatedText": "จำได้ไหมว่าฉันเคยกล่าวไว้ก่อนหน้านี้ว่าเซลล์ประสาทเหล่านี้เป็นเพียงสิ่งที่เก็บตัวเลขไว้?",
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "model": "google_nmt",
  "time_range": [
   917.82,
   921.46
  ]
 },
 {
  "translatedText": "แน่นอนว่า ตัวเลขเฉพาะที่พวกมันเก็บไว้นั้นขึ้นอยู่กับภาพที่คุณป้อนเข้าไป ดังนั้นจริงๆ แล้วมันจะแม่นยำกว่าถ้าคิดว่าเซลล์ประสาทแต่ละอันเป็นฟังก์ชัน ซึ่งรับเอาเอาท์พุตของเซลล์ประสาททั้งหมดในเลเยอร์ก่อนหน้าแล้วแยกตัวเลขออกมา ระหว่าง 0 ถึง 1",
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   922.22,
   938.34
  ]
 },
 {
  "translatedText": "จริงๆ แล้ว เครือข่ายทั้งหมดเป็นเพียงฟังก์ชัน หนึ่งที่รับตัวเลข 784 เป็นอินพุต และแยกตัวเลข 10 หลักเป็นเอาต์พุต",
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "model": "google_nmt",
  "time_range": [
   939.2,
   947.06
  ]
 },
 {
  "translatedText": "มันเป็นฟังก์ชันที่ซับซ้อนอย่างไร้เหตุผล ซึ่งเกี่ยวข้องกับพารามิเตอร์ 13,000 ตัวในรูปแบบของน้ำหนักและอคติเหล่านี้ซึ่งเลือกรูปแบบบางอย่าง และเกี่ยวข้องกับการวนซ้ำผลคูณเมทริกซ์เวกเตอร์จำนวนมากและฟังก์ชันการบีบซิกมอยด์ แต่มันก็เป็นเพียงฟังก์ชันหนึ่ง อย่างไรก็ตาม และใน ซึ่งทำให้มั่นใจได้ว่ามันดูซับซ้อน",
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless, and in a way it's kind of reassuring that it looks complicated.",
  "model": "google_nmt",
  "time_range": [
   947.56,
   966.66
  ]
 },
 {
  "translatedText": "ฉันหมายถึงถ้ามันง่ายกว่านี้ เราจะมีความหวังอะไรที่จะรับมือกับความท้าทายในการจดจำตัวเลขได้",
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "model": "google_nmt",
  "time_range": [
   967.34,
   972.28
  ]
 },
 {
  "translatedText": "และมันจะรับมือกับความท้าทายนั้นได้อย่างไร?",
  "input": "And how does it take on that challenge?",
  "model": "google_nmt",
  "time_range": [
   973.34,
   974.7
  ]
 },
 {
  "translatedText": "เครือข่ายนี้เรียนรู้น้ำหนักและอคติที่เหมาะสมเพียงแค่ดูข้อมูลได้อย่างไร",
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "model": "google_nmt",
  "time_range": [
   975.08,
   979.36
  ]
 },
 {
  "translatedText": "นั่นคือสิ่งที่ผมจะแสดงในวิดีโอหน้า และผมจะเจาะลึกอีกหน่อยว่าเครือข่ายเฉพาะที่เราเห็นกำลังทำอะไรอยู่จริงๆ",
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "model": "google_nmt",
  "time_range": [
   980.14,
   986.12
  ]
 },
 {
  "translatedText": "ตอนนี้เป็นประเด็นที่ฉันคิดว่าฉันควรจะสมัครเป็นสมาชิกเพื่อรับการแจ้งเตือนเมื่อมีวิดีโอหรือวิดีโอใหม่ ๆ ออกมา แต่ในความเป็นจริงแล้วพวกคุณส่วนใหญ่ไม่ได้รับการแจ้งเตือนจาก YouTube ใช่ไหม",
  "input": "Now is the point I suppose I should say subscribe to stay notified about when video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "model": "google_nmt",
  "time_range": [
   987.58,
   997.42
  ]
 },
 {
  "translatedText": "บางทีฉันควรบอกตามตรงว่าสมัครรับข้อมูลเพื่อให้โครงข่ายประสาทเทียมที่รองรับอัลกอริธึมการแนะนำของ YouTube ได้รับการออกแบบมาเพื่อเชื่อว่าคุณต้องการเห็นเนื้อหาจากช่องนี้ได้รับการแนะนำให้กับคุณ",
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "model": "google_nmt",
  "time_range": [
   998.02,
   1007.88
  ]
 },
 {
  "translatedText": "อย่างไรก็ตามโปรดโพสต์เพิ่มเติม",
  "input": "Anyway stay posted for more.",
  "model": "google_nmt",
  "time_range": [
   1008.56,
   1009.94
  ]
 },
 {
  "translatedText": "ขอบคุณมากสำหรับทุกคนที่สนับสนุนวิดีโอเหล่านี้บน Patreon",
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "model": "google_nmt",
  "time_range": [
   1010.76,
   1013.5
  ]
 },
 {
  "translatedText": "ฉันคืบหน้าได้ช้าเล็กน้อยในซีรีส์ความน่าจะเป็นในฤดูร้อนนี้ แต่ฉันก็กลับมาอีกครั้งหลังจากโปรเจ็กต์นี้ ดังนั้นผู้สนับสนุนคอยติดตามข้อมูลอัปเดตได้จากที่นั่น",
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "model": "google_nmt",
  "time_range": [
   1014.0,
   1021.9
  ]
 },
 {
  "translatedText": "เพื่อปิดเรื่องต่างๆ ที่นี่ ฉันขอร่วมกับฉัน Leisha Lee ซึ่งทำงานระดับปริญญาเอกของเธอในด้านทฤษฎีของการเรียนรู้เชิงลึก และปัจจุบันทำงานที่บริษัทร่วมลงทุนชื่อ Amplify Partners ซึ่งเป็นผู้กรุณามอบเงินทุนบางส่วนสำหรับวิดีโอนี้",
  "input": "To close things off here I have with me Leisha Lee who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "model": "google_nmt",
  "time_range": [
   1023.6,
   1034.62
  ]
 },
 {
  "translatedText": "เลอิชาสิ่งหนึ่งที่ฉันคิดว่าเราควรพูดถึงเร็วๆ คือฟังก์ชันซิกมอยด์",
  "input": "So Leisha one thing I think we should quickly bring up is this sigmoid function.",
  "model": "google_nmt",
  "time_range": [
   1035.46,
   1039.12
  ]
 },
 {
  "translatedText": "ดังที่ฉันเข้าใจ เครือข่ายในยุคแรกๆ ใช้สิ่งนี้เพื่อบีบผลรวมถ่วงน้ำหนักที่เกี่ยวข้องลงในช่วงเวลาระหว่างศูนย์ถึงหนึ่ง คุณรู้ไหมว่าได้รับแรงบันดาลใจจากการเปรียบเทียบทางชีววิทยาของเซลล์ประสาท ทั้งที่ไม่ได้ใช้งานหรือใช้งานอยู่",
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "model": "google_nmt",
  "time_range": [
   1039.7,
   1049.84
  ]
 },
 {
  "translatedText": "อย่างแน่นอน.",
  "input": "Exactly.",
  "model": "google_nmt",
  "time_range": [
   1050.28,
   1050.3
  ]
 },
 {
  "translatedText": "แต่เครือข่ายสมัยใหม่จำนวนไม่น้อยที่ใช้ sigmoid อีกต่อไป",
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "model": "google_nmt",
  "time_range": [
   1050.56,
   1054.04
  ]
 },
 {
  "translatedText": "ใช่.",
  "input": "Yeah.",
  "model": "google_nmt",
  "time_range": [
   1054.32,
   1054.32
  ]
 },
 {
  "translatedText": "มันเป็นโรงเรียนเก่าใช่มั้ย?",
  "input": "It's kind of old school right?",
  "model": "google_nmt",
  "time_range": [
   1054.44,
   1055.54
  ]
 },
 {
  "translatedText": "ใช่หรือค่อนข้าง relu ดูเหมือนจะฝึกได้ง่ายกว่ามาก",
  "input": "Yeah or rather relu seems to be much easier to train.",
  "model": "google_nmt",
  "time_range": [
   1055.76,
   1058.98
  ]
 },
 {
  "translatedText": "และ relu ย่อมาจากหน่วยเชิงเส้นที่ถูกแก้ไข?",
  "input": "And relu stands for rectified linear unit?",
  "model": "google_nmt",
  "time_range": [
   1059.4,
   1062.34
  ]
 },
 {
  "translatedText": "ใช่ มันเป็นฟังก์ชันประเภทนี้ที่คุณแค่หาค่าสูงสุดจากศูนย์ และ a โดยที่ a มาจากสิ่งที่คุณอธิบายในวิดีโอ และสิ่งที่ได้รับแรงบันดาลใจจาก ฉันคิดว่าเป็นส่วนหนึ่งจากการเปรียบเทียบทางชีววิทยากับเซลล์ประสาท จะถูกเปิดใช้งานหรือไม่ และถ้ามันผ่านเกณฑ์ที่กำหนด มันก็จะเป็นฟังก์ชันเอกลักษณ์ แต่ถ้าไม่ มันก็จะไม่ถูกเปิดใช้งาน มันจะเป็นศูนย์ ดังนั้นมันจึงเป็นการทำให้ง่ายขึ้น",
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not and so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "model": "google_nmt",
  "time_range": [
   1062.68,
   1090.84
  ]
 },
 {
  "translatedText": "การใช้ซิกมอยด์ไม่ได้ช่วยในการฝึกฝน หรือเป็นเรื่องยากมากที่จะฝึกในบางจุด และผู้คนก็ลองใช้ Relu และมันก็ทำงานได้ดีมากสำหรับโครงข่ายประสาทเทียมที่ลึกอย่างไม่น่าเชื่อเหล่านี้",
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried relu and it happened to work very well for these incredibly deep neural networks.",
  "model": "google_nmt",
  "time_range": [
   1091.16,
   1104.62
  ]
 },
 {
  "translatedText": "เอาล่ะ ขอบคุณอลิเซีย",
  "input": "All right thank you Alicia.",
  "model": "google_nmt",
  "time_range": [
   1105.1,
   1105.64
  ]
 }
]