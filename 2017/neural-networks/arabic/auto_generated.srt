1
00:00:04,220 --> 00:00:05,400
هذا هو 3.

2
00:00:06,060 --> 00:00:09,793
تمت كتابته بطريقة غير متقنة وعرضه بدقة منخفضة للغاية تبلغ 

3
00:00:09,793 --> 00:00:13,720
28 × 28 بكسل، لكن عقلك لا يجد صعوبة في التعرف عليه على أنه 3.

4
00:00:14,340 --> 00:00:16,726
وأريد منكم أن تتوقفوا للحظة لتقدروا مدى الجنون 

5
00:00:16,726 --> 00:00:18,960
الذي تستطيع به الأدمغة القيام بذلك دون عناء.

6
00:00:19,700 --> 00:00:23,942
أعني أن هذا وهذا وهذا يمكن التعرف عليهم أيضًا على أنهم 3s، على 

7
00:00:23,942 --> 00:00:28,320
الرغم من أن القيم المحددة لكل بكسل تختلف كثيرًا من صورة إلى أخرى.

8
00:00:28,900 --> 00:00:32,745
الخلايا الحساسة للضوء في عينك والتي تنشط عندما ترى هذا 

9
00:00:32,745 --> 00:00:36,940
الرقم 3 تختلف تمامًا عن تلك التي تنشط عندما ترى هذا الرقم 3.

10
00:00:37,520 --> 00:00:42,987
لكن شيئًا ما في تلك القشرة البصرية الذكية والمجنونة لديك يحل هذه المشكلات باعتبارها 

11
00:00:42,987 --> 00:00:48,260
تمثل نفس الفكرة، بينما يتعرف في نفس الوقت على الصور الأخرى كأفكار مميزة خاصة بها.

12
00:00:49,220 --> 00:00:54,934
لكن إذا أخبرتك، اجلس واكتب لي برنامجًا يأخذ شبكة بحجم 28 × 28 

13
00:00:54,934 --> 00:01:00,557
بكسل مثل هذه ويخرج رقمًا واحدًا بين 0 و10، ويخبرك بما يعتقده 

14
00:01:00,557 --> 00:01:06,180
الرقم، حسنًا، تبدأ المهمة من تافهة بشكل هزلي إلى صعبة للغاية.

15
00:01:07,160 --> 00:01:11,026
ما لم تكن تعيش تحت صخرة، أعتقد أنني لا أحتاج إلى تحفيز أهمية 

16
00:01:11,026 --> 00:01:14,640
وأهمية التعلم الآلي والشبكات العصبية في الحاضر والمستقبل.

17
00:01:15,120 --> 00:01:19,962
لكن ما أريد القيام به هنا هو أن أوضح لكم ماهية الشبكة العصبية في الواقع، دون افتراض 

18
00:01:19,962 --> 00:01:24,460
أي خلفية، وللمساعدة في تصور ما تفعله، ليس ككلمة طنانة ولكن كقطعة من الرياضيات.

19
00:01:25,020 --> 00:01:29,499
آمل أن تبتعد وأنت تشعر بأن البنية نفسها محفزة، وأن تشعر وكأنك 

20
00:01:29,499 --> 00:01:34,340
تعرف ما يعنيه عندما تقرأ، أو تسمع عن التعلم من خلال الشبكة العصبية.

21
00:01:35,360 --> 00:01:40,260
سيتم تخصيص هذا الفيديو للمكون الهيكلي لذلك، وسيتناول الفيديو التالي عملية التعلم.

22
00:01:40,960 --> 00:01:46,040
ما سنفعله هو تجميع شبكة عصبية يمكنها تعلم كيفية التعرف على الأرقام المكتوبة بخط اليد.

23
00:01:49,360 --> 00:01:54,004
يعد هذا مثالًا كلاسيكيًا إلى حد ما لتقديم الموضوع، ويسعدني الالتزام بالوضع الراهن هنا، 

24
00:01:54,004 --> 00:01:58,595
لأنه في نهاية مقطعي الفيديو، أريد أن أشير إليك إلى بعض الموارد الجيدة حيث يمكنك معرفة 

25
00:01:58,595 --> 00:02:03,080
المزيد، وأين يمكنك تنزيل الكود الذي يقوم بذلك واللعب به على جهاز الكمبيوتر الخاص بك.

26
00:02:05,040 --> 00:02:09,732
هناك العديد من المتغيرات المتعددة للشبكات العصبية، وفي السنوات الأخيرة كان 

27
00:02:09,732 --> 00:02:14,424
هناك نوع من الازدهار في الأبحاث تجاه هذه المتغيرات، ولكن في هذين الفيديوين 

28
00:02:14,424 --> 00:02:19,180
التمهيديين، سننظر أنا وأنت إلى أبسط شكل عادي من الفانيليا بدون زخرفة إضافية.

29
00:02:19,860 --> 00:02:24,346
يعد هذا نوعًا من المتطلبات الضرورية لفهم أي من المتغيرات الحديثة الأكثر قوة، 

30
00:02:24,346 --> 00:02:28,600
وثق بي أنه لا يزال يحتوي على الكثير من التعقيد الذي يتعين علينا استيعابه.

31
00:02:29,120 --> 00:02:32,737
ولكن حتى في هذا الشكل الأبسط، يمكنه تعلم كيفية التعرف على الأرقام 

32
00:02:32,737 --> 00:02:36,520
المكتوبة بخط اليد، وهو أمر رائع جدًا أن يتمكن الكمبيوتر من القيام به.

33
00:02:37,480 --> 00:02:42,280
وفي الوقت نفسه سترى كيف أنه لا يفي ببعض الآمال التي قد نعقدها عليه.

34
00:02:43,380 --> 00:02:48,500
كما يوحي الاسم، فإن الشبكات العصبية مستوحاة من الدماغ، ولكن دعونا نحلل ذلك.

35
00:02:48,520 --> 00:02:51,660
ما هي الخلايا العصبية، وبأي معنى ترتبط ببعضها البعض؟

36
00:02:52,500 --> 00:02:56,277
الآن عندما أقول الخلايا العصبية، كل ما أريدكم أن 

37
00:02:56,277 --> 00:03:00,440
تفكروا فيه هو شيء يحمل رقمًا، وتحديدًا رقمًا بين 0 و1.

38
00:03:00,680 --> 00:03:02,560
انها حقا ليست أكثر من ذلك.

39
00:03:03,780 --> 00:03:09,108
على سبيل المثال، تبدأ الشبكة بمجموعة من الخلايا العصبية المقابلة لكل بكسل 

40
00:03:09,108 --> 00:03:14,220
من 28 × 28 بكسل للصورة المدخلة، وهو ما يعادل 784 خلية عصبية في المجموع.

41
00:03:14,700 --> 00:03:19,540
يحمل كل واحد منها رقمًا يمثل قيمة التدرج الرمادي للبكسل 

42
00:03:19,540 --> 00:03:24,380
المقابل، ويتراوح من 0 للبكسل الأسود إلى 1 للبكسل الأبيض.

43
00:03:25,300 --> 00:03:29,854
هذا الرقم الموجود داخل الخلية العصبية يسمى تنشيطها، والصورة التي قد تكون 

44
00:03:29,854 --> 00:03:34,160
في ذهنك هنا هي أن كل خلية عصبية تضاء عندما يكون تنشيطها رقمًا كبيرًا.

45
00:03:36,720 --> 00:03:41,860
لذا فإن كل هذه الخلايا العصبية البالغ عددها 784 تشكل الطبقة الأولى من شبكتنا.

46
00:03:46,500 --> 00:03:51,360
ننتقل الآن إلى الطبقة الأخيرة، حيث تحتوي على 10 خلايا عصبية، تمثل كل منها أحد الأرقام.

47
00:03:52,040 --> 00:03:56,884
التنشيط في هذه الخلايا العصبية، مرة أخرى بعض الأرقام التي تقع 

48
00:03:56,884 --> 00:04:02,120
بين 0 و 1، يمثل مدى اعتقاد النظام أن صورة معينة تتوافق مع رقم معين.

49
00:04:03,040 --> 00:04:08,488
هناك أيضًا طبقتان بينهما تسمى الطبقات المخفية، والتي يجب أن تكون في الوقت الحالي 

50
00:04:08,488 --> 00:04:13,600
مجرد علامة استفهام عملاقة حول كيفية التعامل مع عملية التعرف على الأرقام هذه.

51
00:04:14,260 --> 00:04:17,437
في هذه الشبكة اخترت طبقتين مخفيتين، كل واحدة تحتوي على 16 

52
00:04:17,437 --> 00:04:20,560
خلية عصبية، ومن المسلم به أن هذا نوع من الاختيار التعسفي.

53
00:04:21,019 --> 00:04:24,560
لأكون صادقًا، اخترت طبقتين بناءً على الطريقة التي أريد بها تحفيز الهيكل 

54
00:04:24,560 --> 00:04:28,200
في لحظة واحدة فقط، و16، حسنًا، كان هذا مجرد رقم لطيف يمكن وضعه على الشاشة.

55
00:04:28,780 --> 00:04:32,340
من الناحية العملية، هناك مجال كبير للتجربة مع بنية محددة هنا.

56
00:04:33,020 --> 00:04:35,834
الطريقة التي تعمل بها الشبكة، تحدد عمليات التنشيط 

57
00:04:35,834 --> 00:04:38,480
في طبقة واحدة عمليات التنشيط في الطبقة التالية.

58
00:04:39,200 --> 00:04:44,024
وبالطبع فإن قلب الشبكة كآلية لمعالجة المعلومات يتعلق بالضبط بكيفية قيام 

59
00:04:44,024 --> 00:04:48,580
تلك التنشيطات من طبقة واحدة بإحداث عمليات التنشيط في الطبقة التالية.

60
00:04:49,140 --> 00:04:52,945
من المفترض أن يكون مشابهًا بشكل فضفاض لكيفية تحفيز بعض مجموعات الخلايا 

61
00:04:52,945 --> 00:04:57,180
العصبية في الشبكات البيولوجية للخلايا العصبية، مما يتسبب في تحفيز مجموعات أخرى.

62
00:04:58,120 --> 00:05:00,909
الآن الشبكة التي أعرضها هنا قد تم تدريبها بالفعل للتعرف 

63
00:05:00,909 --> 00:05:03,400
على الأرقام، واسمحوا لي أن أوضح لكم ما أعنيه بذلك.

64
00:05:03,640 --> 00:05:08,282
هذا يعني أنه إذا قمت بتغذية صورة ما، وإضاءة جميع الخلايا العصبية البالغ 

65
00:05:08,282 --> 00:05:12,924
عددها 784 خلية في الطبقة المدخلة وفقًا لسطوع كل بكسل في الصورة، فإن نمط 

66
00:05:12,924 --> 00:05:17,437
التنشيط هذا يسبب نمطًا محددًا للغاية في الطبقة التالية مما يسبب نمطًا 

67
00:05:17,437 --> 00:05:22,080
ما في الطبقة التالية ذلك، والذي يعطي أخيرًا بعض الأنماط في طبقة الإخراج.

68
00:05:22,560 --> 00:05:25,799
والخلايا العصبية الأكثر سطوعًا في طبقة الإخراج هذه هي 

69
00:05:25,799 --> 00:05:29,400
اختيار الشبكة، إذا جاز التعبير، للرقم الذي تمثله هذه الصورة.

70
00:05:32,560 --> 00:05:36,074
وقبل القفز إلى الرياضيات لمعرفة كيفية تأثير طبقة واحدة على 

71
00:05:36,074 --> 00:05:39,767
الطبقة التالية، أو كيفية عمل التدريب، دعنا نتحدث فقط عن السبب 

72
00:05:39,767 --> 00:05:43,520
في أنه من المعقول أن نتوقع أن تتصرف بنية الطبقات مثل هذه بذكاء.

73
00:05:44,060 --> 00:05:45,220
ماذا نتوقع هنا؟

74
00:05:45,400 --> 00:05:47,600
ما هو أفضل أمل لتلك الطبقات الوسطى؟

75
00:05:48,920 --> 00:05:53,520
حسنًا، عندما نتعرف أنت أو أنا على الأرقام، فإننا نقوم بتجميع مكونات مختلفة معًا.

76
00:05:54,200 --> 00:05:56,820
يحتوي الرقم 9 على حلقة لأعلى وخط على اليمين.

77
00:05:57,380 --> 00:06:01,180
يحتوي الرقم 8 أيضًا على حلقة لأعلى، ولكن يتم إقرانها بحلقة أخرى للأسفل.

78
00:06:01,980 --> 00:06:06,820
ينقسم الرقم 4 بشكل أساسي إلى ثلاثة أسطر محددة، وأشياء من هذا القبيل.

79
00:06:07,600 --> 00:06:12,805
الآن في عالم مثالي، قد نأمل أن تتوافق كل خلية عصبية في الطبقة الثانية إلى 

80
00:06:12,805 --> 00:06:17,870
الأخيرة مع أحد هذه المكونات الفرعية، وفي أي وقت تغذي فيه صورة، على سبيل 

81
00:06:17,870 --> 00:06:23,780
المثال، حلقة لأعلى، مثل 9 أو 8، هناك بعض خلية عصبية محددة سيكون تنشيطها قريبًا من 1.

82
00:06:24,500 --> 00:06:28,030
وأنا لا أقصد هذه الحلقة المحددة من البكسلات، الأمل هو أن 

83
00:06:28,030 --> 00:06:31,560
أي نمط متعرج بشكل عام نحو الأعلى يطلق هذه الخلية العصبية.

84
00:06:32,440 --> 00:06:36,082
بهذه الطريقة، يتطلب الانتقال من الطبقة الثالثة إلى الطبقة 

85
00:06:36,082 --> 00:06:40,040
الأخيرة معرفة أي مجموعة من المكونات الفرعية تتوافق مع أي أرقام.

86
00:06:41,000 --> 00:06:44,299
وبطبيعة الحال، فإن هذا يؤدي إلى حل المشكلة على الطريق، لأنه كيف يمكنك التعرف على 

87
00:06:44,299 --> 00:06:47,640
هذه المكونات الفرعية، أو حتى معرفة ما ينبغي أن تكون عليه المكونات الفرعية الصحيحة؟

88
00:06:48,060 --> 00:06:50,482
وما زلت لم أتحدث حتى عن كيفية تأثير طبقة واحدة 

89
00:06:50,482 --> 00:06:53,060
على الطبقة التالية، لكن تابع معي هذه الطبقة للحظة.

90
00:06:53,680 --> 00:06:56,680
يمكن أيضًا أن ينقسم التعرف على الحلقة إلى مشكلات فرعية.

91
00:06:57,280 --> 00:07:00,149
إحدى الطرق المعقولة للقيام بذلك هي التعرف أولاً 

92
00:07:00,149 --> 00:07:02,780
على الحواف الصغيرة المختلفة التي يتكون منها.

93
00:07:03,780 --> 00:07:09,014
وبالمثل، فإن الخط الطويل، مثل النوع الذي قد تراه في الأرقام 1 أو 4 أو 7، 

94
00:07:09,014 --> 00:07:14,320
هو في الواقع مجرد حافة طويلة، أو ربما تعتقد أنه نمط معين من عدة حواف أصغر.

95
00:07:15,140 --> 00:07:19,002
لذا ربما أملنا هو أن كل خلية عصبية في الطبقة الثانية 

96
00:07:19,002 --> 00:07:22,720
من الشبكة تتوافق مع مختلف الحواف الصغيرة ذات الصلة.

97
00:07:23,540 --> 00:07:28,981
ربما عندما تظهر صورة كهذه، فإنها تضيء جميع الخلايا العصبية المرتبطة بحوالي 

98
00:07:28,981 --> 00:07:34,060
8 إلى 10 حواف صغيرة محددة، والتي بدورها تضيء الخلايا العصبية المرتبطة 

99
00:07:34,060 --> 00:07:39,720
بالحلقة العلوية والخط العمودي الطويل، وتلك تضيء الخلايا العصبية المرتبطة بـ 9.

100
00:07:40,680 --> 00:07:44,494
سواء كان هذا هو ما تفعله شبكتنا النهائية بالفعل أم لا، فهو سؤال 

101
00:07:44,494 --> 00:07:48,427
آخر، سؤال سأعود إليه بمجرد أن نرى كيفية تدريب الشبكة، ولكن هذا هو 

102
00:07:48,427 --> 00:07:52,540
الأمل الذي قد يكون لدينا، نوع من الهدف مع البنية متعددة الطبقات مثله.

103
00:07:53,160 --> 00:07:56,673
علاوة على ذلك، يمكنك أن تتخيل كيف أن القدرة على اكتشاف الحواف 

104
00:07:56,673 --> 00:08:00,300
والأنماط مثل هذه ستكون مفيدة حقًا لمهام التعرف على الصور الأخرى.

105
00:08:00,880 --> 00:08:03,929
وحتى فيما هو أبعد من التعرف على الصور، هناك كل أنواع الأشياء 

106
00:08:03,929 --> 00:08:07,280
الذكية التي قد ترغب في القيام بها والتي تنقسم إلى طبقات من التجريد.

107
00:08:08,040 --> 00:08:12,178
يتضمن تحليل الكلام، على سبيل المثال، أخذ صوت خام واختيار أصوات 

108
00:08:12,178 --> 00:08:16,250
مميزة، والتي تتحد لتكوين مقاطع معينة، والتي تتحد لتشكل كلمات، 

109
00:08:16,250 --> 00:08:20,060
والتي تتحد لتكوين عبارات وأفكار أكثر تجريدًا، وما إلى ذلك.

110
00:08:21,100 --> 00:08:25,409
لكن بالعودة إلى كيفية عمل أي من هذا فعليًا، تصور نفسك الآن وأنت 

111
00:08:25,409 --> 00:08:29,920
تصمم كيف يمكن لعمليات التنشيط في طبقة واحدة أن تحدد الطبقة التالية.

112
00:08:30,860 --> 00:08:34,920
الهدف هو الحصول على آلية يمكنها دمج وحدات البكسل 

113
00:08:34,920 --> 00:08:38,980
في حواف، أو الحواف في أنماط، أو الأنماط في أرقام.

114
00:08:39,440 --> 00:08:44,763
ولتقريب مثال واحد محدد للغاية، لنفترض أن الأمل هو أن تلتقط خلية عصبية 

115
00:08:44,763 --> 00:08:50,620
معينة في الطبقة الثانية ما إذا كانت الصورة لها حافة في هذه المنطقة هنا أم لا.

116
00:08:51,440 --> 00:08:55,100
السؤال المطروح هو ما المعلمات التي يجب أن تحتوي عليها الشبكة؟

117
00:08:55,640 --> 00:08:59,624
ما هي الأقراص والمقابض التي يجب أن تكون قادرًا على تعديلها بحيث 

118
00:08:59,624 --> 00:09:03,671
تكون معبرة بدرجة كافية لالتقاط هذا النمط، أو أي نمط بكسل آخر، أو 

119
00:09:03,671 --> 00:09:07,780
النمط الذي يمكن أن تشكله عدة حواف حلقة، وأشياء أخرى من هذا القبيل؟

120
00:09:08,720 --> 00:09:12,109
حسنًا، ما سنفعله هو تعيين وزن لكل واحدة من الوصلات بين 

121
00:09:12,109 --> 00:09:15,560
الخلايا العصبية لدينا والخلايا العصبية من الطبقة الأولى.

122
00:09:16,320 --> 00:09:17,700
هذه الأوزان مجرد أرقام.

123
00:09:18,540 --> 00:09:25,500
ثم خذ كل تلك التنشيطات من الطبقة الأولى واحسب مجموعها المرجح وفقًا لهذه الأوزان.

124
00:09:27,700 --> 00:09:32,223
أجد أنه من المفيد التفكير في هذه الأوزان على أنها منظمة في شبكة صغيرة خاصة بها، 

125
00:09:32,223 --> 00:09:36,803
وسأستخدم وحدات البكسل الخضراء للإشارة إلى الأوزان الموجبة، ووحدات البكسل الحمراء 

126
00:09:36,803 --> 00:09:41,780
للإشارة إلى الأوزان السالبة، حيث يكون سطوع ذلك البكسل بعض الشيء تصوير فضفاض لقيمة الوزن.

127
00:09:42,780 --> 00:09:47,837
الآن إذا جعلنا الأوزان المرتبطة بكل وحدات البكسل تقريبًا صفرًا باستثناء بعض 

128
00:09:47,837 --> 00:09:52,828
الأوزان الموجبة في هذه المنطقة التي نهتم بها، فإن أخذ المجموع المرجح لجميع 

129
00:09:52,828 --> 00:09:57,820
قيم البكسلات يؤدي في الواقع إلى إضافة قيم البكسل فقط المنطقة التي نهتم بها.

130
00:09:59,140 --> 00:10:02,841
وإذا كنت تريد حقًا معرفة ما إذا كانت هناك حافة هنا، فإن ما يمكنك 

131
00:10:02,841 --> 00:10:06,600
فعله هو الحصول على بعض الأوزان السلبية المرتبطة بالبكسلات المحيطة.

132
00:10:07,480 --> 00:10:10,367
ثم يكون المجموع أكبر عندما تكون وحدات البكسل الوسطى 

133
00:10:10,367 --> 00:10:12,700
ساطعة ولكن وحدات البكسل المحيطة تكون أغمق.

134
00:10:14,260 --> 00:10:18,974
عند حساب مبلغ مرجح مثل هذا، قد تخرج بأي رقم، ولكن بالنسبة لهذه 

135
00:10:18,974 --> 00:10:23,540
الشبكة، ما نريده هو أن تكون عمليات التنشيط ذات قيمة بين 0 و1.

136
00:10:24,120 --> 00:10:28,035
لذا فإن الشيء الشائع الذي يجب فعله هو ضخ هذا المبلغ المرجح في 

137
00:10:28,035 --> 00:10:32,140
بعض الوظائف التي تضغط على خط الأعداد الحقيقي في النطاق بين 0 و 1.

138
00:10:32,460 --> 00:10:37,420
والدالة الشائعة التي تقوم بذلك تسمى الدالة السيني، والمعروفة أيضًا باسم المنحنى اللوجستي.

139
00:10:38,000 --> 00:10:42,265
في الأساس، تنتهي المدخلات السلبية للغاية بالقرب من 0، وتنتهي 

140
00:10:42,265 --> 00:10:46,600
المدخلات الإيجابية بالقرب من 1، وتزداد بشكل مطرد حول المدخل 0.

141
00:10:49,120 --> 00:10:56,360
لذا فإن تنشيط الخلية العصبية هنا هو في الأساس مقياس لمدى إيجابية المجموع المرجح ذي الصلة.

142
00:10:57,540 --> 00:11:01,880
ولكن ربما لا تريد أن تضيء الخلية العصبية عندما يكون المجموع المرجح أكبر من 0.

143
00:11:02,280 --> 00:11:06,360
ربما تريد أن يكون نشطًا فقط عندما يكون المجموع أكبر من 10 مثلاً.

144
00:11:06,840 --> 00:11:10,260
أي أنك تريد بعض التحيز حتى يكون غير نشط.

145
00:11:11,380 --> 00:11:15,479
ما سنفعله بعد ذلك هو إضافة رقم آخر مثل سالب 10 إلى 

146
00:11:15,479 --> 00:11:19,660
هذا المجموع المرجح قبل توصيله عبر دالة السحق السيني.

147
00:11:20,580 --> 00:11:22,440
هذا الرقم الإضافي يسمى التحيز.

148
00:11:23,460 --> 00:11:27,346
لذا فإن الأوزان تخبرك بنمط البكسل الذي تلتقطه هذه الخلية العصبية 

149
00:11:27,346 --> 00:11:31,173
في الطبقة الثانية، ويخبرك التحيز بمدى الارتفاع الذي يجب أن يكون 

150
00:11:31,173 --> 00:11:35,180
عليه المجموع المرجح قبل أن تبدأ الخلية العصبية في النشاط بشكل مفيد.

151
00:11:36,120 --> 00:11:37,680
وهذه مجرد خلية عصبية واحدة.

152
00:11:38,280 --> 00:11:44,766
سيتم توصيل كل خلية عصبية أخرى في هذه الطبقة بجميع الخلايا العصبية ذات الـ 784 بكسل 

153
00:11:44,766 --> 00:11:50,940
من الطبقة الأولى، وكل واحدة من تلك الوصلات الـ 784 لها وزنها الخاص المرتبط بها.

154
00:11:51,600 --> 00:11:54,488
أيضًا، كل واحد لديه بعض التحيز، وبعض الأرقام الأخرى 

155
00:11:54,488 --> 00:11:57,600
التي تضيفها إلى المجموع المرجح قبل سحقه باستخدام السيني.

156
00:11:58,110 --> 00:11:59,540
وهذا كثير للتفكير فيه!

157
00:11:59,960 --> 00:12:03,932
مع هذه الطبقة المخفية المكونة من 16 خلية عصبية، يكون 

158
00:12:03,932 --> 00:12:07,980
ذلك إجماليًا 784 × 16 وزنًا، بالإضافة إلى 16 انحيازًا.

159
00:12:08,840 --> 00:12:11,940
وكل ذلك مجرد اتصالات من الطبقة الأولى إلى الثانية.

160
00:12:12,520 --> 00:12:17,340
تحتوي الروابط بين الطبقات الأخرى أيضًا على مجموعة من الأوزان والتحيزات المرتبطة بها.

161
00:12:18,340 --> 00:12:23,800
بعد كل ما قيل وفعل، تحتوي هذه الشبكة على ما يقرب من 13000 إجمالي الأوزان والتحيزات.

162
00:12:23,800 --> 00:12:29,960
13000 مقبضًا وقرصًا يمكن تعديلها وتحويلها لجعل هذه الشبكة تتصرف بطرق مختلفة.

163
00:12:31,040 --> 00:12:36,431
لذلك عندما نتحدث عن التعلم، ما نشير إليه هو جعل الكمبيوتر يجد إعدادًا 

164
00:12:36,431 --> 00:12:41,360
صالحًا لكل هذه الأرقام العديدة بحيث يحل المشكلة المطروحة بالفعل.

165
00:12:42,620 --> 00:12:47,183
إحدى التجارب الفكرية التي هي ممتعة ومرعبة نوعًا ما في الوقت نفسه هي 

166
00:12:47,183 --> 00:12:51,949
تخيل الجلوس ووضع كل هذه الأوزان والتحيزات يدويًا، وتعديل الأرقام عمدًا 

167
00:12:51,949 --> 00:12:56,580
بحيث تلتقط الطبقة الثانية الحواف، وتلتقط الطبقة الثالثة الأنماط، إلخ.

168
00:12:56,980 --> 00:13:02,853
أنا شخصيا أجد هذا مرضيا بدلا من مجرد التعامل مع الشبكة كصندوق أسود كامل، لأنه عندما 

169
00:13:02,853 --> 00:13:08,446
لا تعمل الشبكة بالطريقة التي تتوقعها، إذا قمت ببناء علاقة صغيرة مع ما تعنيه هذه 

170
00:13:08,446 --> 00:13:14,180
الأوزان والتحيزات في الواقع ، لديك نقطة انطلاق لتجربة كيفية تغيير البنية لتحسينها.

171
00:13:14,960 --> 00:13:20,487
أو عندما تعمل الشبكة ولكن ليس للأسباب التي قد تتوقعها، فإن البحث في ما تفعله الأوزان 

172
00:13:20,487 --> 00:13:25,820
والتحيزات يعد طريقة جيدة لتحدي افتراضاتك وكشف المساحة الكاملة للحلول الممكنة حقًا.

173
00:13:26,840 --> 00:13:30,680
بالمناسبة، الوظيفة الفعلية هنا مرهقة بعض الشيء لتدوينها، ألا تعتقد ذلك؟

174
00:13:32,500 --> 00:13:37,140
لذلك اسمحوا لي أن أريكم طريقة أكثر إحكاما من الناحية التدوينية لتمثيل هذه الروابط.

175
00:13:37,660 --> 00:13:40,520
هذه هي الطريقة التي سترى بها الأمر إذا اخترت قراءة المزيد عن الشبكات العصبية.

176
00:13:41,380 --> 00:13:50,114
قم بتنظيم جميع عمليات التنشيط من طبقة واحدة في عمود حيث تتوافق المصفوفة 

177
00:13:50,114 --> 00:13:58,000
مع الاتصالات بين طبقة واحدة وخلايا عصبية معينة في الطبقة التالية.

178
00:13:58,540 --> 00:14:04,372
ما يعنيه ذلك هو أن أخذ المجموع المرجح لعمليات التنشيط في الطبقة الأولى وفقًا لهذه الأوزان 

179
00:14:04,372 --> 00:14:09,880
يتوافق مع أحد الحدود الموجودة في حاصل ضرب متجه المصفوفة لكل شيء لدينا على اليسار هنا.

180
00:14:14,000 --> 00:14:18,735
بالمناسبة، يعود الكثير من التعلم الآلي إلى الفهم الجيد للجبر الخطي، لذا 

181
00:14:18,735 --> 00:14:23,470
بالنسبة لأي منكم يريد فهمًا بصريًا جيدًا للمصفوفات وما يعنيه ضرب متجهات 

182
00:14:23,470 --> 00:14:28,600
المصفوفات، ألقِ نظرة على السلسلة التي قمت بها الجبر الخطي، وخاصة الفصل الثالث.

183
00:14:29,240 --> 00:14:33,636
بالعودة إلى التعبير، بدلًا من الحديث عن إضافة الانحياز إلى كل واحدة 

184
00:14:33,636 --> 00:14:38,097
من هذه القيم بشكل مستقل، فإننا نمثله من خلال تنظيم كل هذه الانحيازات 

185
00:14:38,097 --> 00:14:42,300
في متجه، وإضافة المتجه بالكامل إلى حاصل ضرب متجه المصفوفة السابق.

186
00:14:43,280 --> 00:14:48,973
ثم كخطوة أخيرة، سأقوم بلف الشكل السيني حول الخارج هنا، وما من المفترض أن يمثله 

187
00:14:48,973 --> 00:14:54,740
ذلك هو أنك ستقوم بتطبيق الدالة السيني على كل مكون محدد من المتجه الناتج بالداخل.

188
00:14:55,940 --> 00:15:01,015
لذا، بمجرد كتابة مصفوفة الوزن هذه وهذه المتجهات كرموز خاصة بها، يمكنك 

189
00:15:01,015 --> 00:15:05,944
توصيل الانتقال الكامل للتنشيطات من طبقة إلى أخرى في تعبير صغير محكم 

190
00:15:05,944 --> 00:15:11,020
للغاية وأنيق، وهذا يجعل الكود ذي الصلة أكثر بساطة وفعالية أسرع بكثير، 

191
00:15:11,020 --> 00:15:15,660
نظرًا لأن العديد من المكتبات تعمل على تحسين عملية ضرب المصفوفات.

192
00:15:17,820 --> 00:15:21,460
هل تتذكر متى قلت سابقًا أن هذه الخلايا العصبية هي ببساطة أشياء تحمل أرقامًا؟

193
00:15:22,220 --> 00:15:27,567
حسنًا بالطبع، تعتمد الأرقام المحددة التي تحتوي عليها على الصورة التي 

194
00:15:27,567 --> 00:15:33,069
تغذيها، لذا فمن الأكثر دقة التفكير في كل خلية عصبية كوظيفة، والتي تأخذ 

195
00:15:33,069 --> 00:15:38,340
مخرجات جميع الخلايا العصبية في الطبقة السابقة وتخرج رقمًا بين 0 و 1.

196
00:15:39,200 --> 00:15:47,060
في الواقع، الشبكة بأكملها هي مجرد وظيفة، تأخذ 784 رقمًا كمدخل وتخرج 10 أرقام كمخرجات.

197
00:15:47,560 --> 00:15:53,952
إنها وظيفة معقدة إلى حد سخيف، تتضمن 13000 معلمة في أشكال هذه الأوزان والتحيزات التي 

198
00:15:53,952 --> 00:16:00,420
تلتقط أنماطًا معينة، والتي تتضمن تكرار العديد من منتجات متجهات المصفوفة ووظيفة السحق 

199
00:16:00,420 --> 00:16:06,660
السيني، ولكنها مجرد وظيفة مع ذلك، وفي إنها طريقة مطمئنة نوعًا ما لأنها تبدو معقدة.

200
00:16:07,340 --> 00:16:09,767
أعني أنه لو كان الأمر أبسط، ما هو الأمل الذي سيكون لدينا 

201
00:16:09,767 --> 00:16:12,280
في أن يتمكن من مواجهة التحدي المتمثل في التعرف على الأرقام؟

202
00:16:13,340 --> 00:16:14,700
وكيف يتعامل مع هذا التحدي؟

203
00:16:15,080 --> 00:16:19,360
كيف تتعلم هذه الشبكة الأوزان والتحيزات المناسبة بمجرد النظر إلى البيانات؟

204
00:16:20,140 --> 00:16:23,130
حسنًا، هذا ما سأعرضه في الفيديو التالي، وسأتعمق 

205
00:16:23,130 --> 00:16:26,120
أيضًا في ما تفعله هذه الشبكة تحديدًا التي نراها.

206
00:16:27,580 --> 00:16:30,788
الآن هي النقطة التي أفترض أنني يجب أن أقول اشترك فيها لتبقى 

207
00:16:30,788 --> 00:16:33,997
على اطلاع عند ظهور الفيديو أو أي مقاطع فيديو جديدة، ولكن من 

208
00:16:33,997 --> 00:16:37,420
الناحية الواقعية، لا يتلقى معظمكم إشعارات من YouTube، أليس كذلك؟

209
00:16:38,020 --> 00:16:42,950
ربما يجب أن أقول بصراحة أكثر اشترك حتى تكون الشبكات العصبية التي تشكل أساس خوارزمية 

210
00:16:42,950 --> 00:16:47,880
التوصية في YouTube مهيأة للاعتقاد بأنك تريد أن ترى المحتوى من هذه القناة موصى به لك.

211
00:16:48,560 --> 00:16:49,940
على أي حال ابق على اطلاع للمزيد.

212
00:16:50,760 --> 00:16:53,500
شكرًا جزيلاً لكل من يدعم مقاطع الفيديو هذه على Patreon.

213
00:16:54,000 --> 00:16:57,895
لقد كنت بطيئًا بعض الشيء في التقدم في سلسلة الاحتمالات هذا الصيف، لكنني 

214
00:16:57,895 --> 00:17:01,900
سأعود إليها بعد هذا المشروع، لذلك يمكن للمستفيدين البحث عن التحديثات هناك.

215
00:17:03,600 --> 00:17:07,381
لاختتام الأمور هنا معي ليشا لي التي حصلت على درجة الدكتوراه في الجانب 

216
00:17:07,381 --> 00:17:11,054
النظري للتعلم العميق والتي تعمل حاليًا في شركة رأس المال الاستثماري 

217
00:17:11,054 --> 00:17:14,619
تسمى Amplify Partners والتي تفضلت بتقديم بعض التمويل لهذا الفيديو.

218
00:17:15,460 --> 00:17:19,119
لذا أعتقد أن ليشا يجب أن نذكر شيئًا واحدًا سريعًا وهو هذه الدالة السيني.

219
00:17:19,700 --> 00:17:22,936
كما أفهم، تستخدم الشبكات المبكرة هذا لضغط المجموع المرجح ذي 

220
00:17:22,936 --> 00:17:26,334
الصلة في تلك الفترة بين صفر وواحد، كما تعلمون نوعًا ما مدفوعًا 

221
00:17:26,334 --> 00:17:29,840
بهذا القياس البيولوجي للخلايا العصبية إما كونها غير نشطة أو نشطة.

222
00:17:30,280 --> 00:17:30,300
بالضبط.

223
00:17:30,560 --> 00:17:34,040
لكن عددًا قليلًا نسبيًا من الشبكات الحديثة يستخدم بالفعل السيني بعد الآن.

224
00:17:34,320 --> 00:17:34,320
نعم.

225
00:17:34,440 --> 00:17:35,540
إنها نوع من المدرسة القديمة، أليس كذلك؟

226
00:17:35,760 --> 00:17:38,980
نعم أو بالأحرى يبدو أن تدريب relu أسهل بكثير.

227
00:17:39,400 --> 00:17:42,340
و relu تعني الوحدة الخطية المصححة؟

228
00:17:42,680 --> 00:17:48,357
نعم، هذا النوع من الوظائف حيث تأخذ فقط الحد الأقصى من الصفر وحيث يتم إعطاء 

229
00:17:48,357 --> 00:17:53,883
a من خلال ما كنت تشرحه في الفيديو وما كان هذا الدافع نوعًا ما منه، أعتقد 

230
00:17:53,883 --> 00:17:59,485
أنه كان جزئيًا من خلال القياس البيولوجي مع كيفية عمل الخلايا العصبية سيتم 

231
00:17:59,485 --> 00:18:05,011
تنشيطها أم لا، وبالتالي إذا تجاوزت حدًا معينًا، فستكون وظيفة الهوية ولكن 

232
00:18:05,011 --> 00:18:10,840
إذا لم يتم تنشيطها، فلن يتم تنشيطها، لذا ستكون صفرًا، لذا فهو نوع من التبسيط.

233
00:18:11,160 --> 00:18:17,657
لم يساعد استخدام السيني في التدريب أو كان من الصعب جدًا التدريب في مرحلة ما وقد جرب 

234
00:18:17,657 --> 00:18:24,620
الأشخاص للتو relu وقد نجح الأمر بشكل جيد جدًا مع هذه الشبكات العصبية العميقة بشكل لا يصدق.

235
00:18:25,100 --> 00:18:25,640
حسنًا، شكرًا لك أليسيا.

