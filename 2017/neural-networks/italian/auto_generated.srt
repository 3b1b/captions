1
00:00:04,220 --> 00:00:05,400
Questo è un 3.

2
00:00:06,060 --> 00:00:09,915
È scritta in modo approssimativo e resa a una risoluzione estremamente bassa 

3
00:00:09,915 --> 00:00:13,720
di 28x28 pixel, ma il tuo cervello non ha problemi a riconoscerla come un 3.

4
00:00:14,340 --> 00:00:16,689
E voglio che tu ti prenda un momento per apprezzare quanto 

5
00:00:16,689 --> 00:00:18,960
sia assurdo che i cervelli riescano a farlo senza sforzo.

6
00:00:19,700 --> 00:00:23,442
Insomma, anche questo, questo e questo sono riconoscibili come 3, 

7
00:00:23,442 --> 00:00:28,320
anche se i valori specifici di ogni pixel sono molto diversi da un'immagine all'altra.

8
00:00:28,900 --> 00:00:32,944
Le particolari cellule sensibili alla luce del tuo occhio che si attivano quando 

9
00:00:32,944 --> 00:00:36,940
vedi questo 3 sono molto diverse da quelle che si attivano quando vedi questo 3.

10
00:00:37,520 --> 00:00:40,950
Ma qualcosa in quella tua corteccia visiva così intelligente 

11
00:00:40,950 --> 00:00:44,605
risolve queste immagini come se rappresentassero la stessa idea, 

12
00:00:44,605 --> 00:00:48,260
riconoscendo allo stesso tempo altre immagini come idee distinte.

13
00:00:49,220 --> 00:00:54,873
Ma se ti dicessi: "Ehi, siediti e scrivi per me un programma che prenda una griglia di 

14
00:00:54,873 --> 00:00:59,032
28x28 pixel come questa e produca un singolo numero tra 0 e 10, 

15
00:00:59,032 --> 00:01:04,490
dicendoti quale cifra pensa che sia", beh, il compito passa da comicamente banale a 

16
00:01:04,490 --> 00:01:06,180
spaventosamente difficile.

17
00:01:07,160 --> 00:01:09,011
A meno che tu non abbia vissuto sotto una roccia, 

18
00:01:09,011 --> 00:01:11,566
credo che non ci sia bisogno di motivare la rilevanza e l'importanza 

19
00:01:11,566 --> 00:01:14,640
dell'apprendimento automatico e delle reti neurali per il presente e per il futuro.

20
00:01:15,120 --> 00:01:18,233
Ma quello che voglio fare qui è mostrarti cos'è effettivamente una rete neurale, 

21
00:01:18,233 --> 00:01:20,577
partendo dal presupposto che non ci sono conoscenze di base, 

22
00:01:20,577 --> 00:01:23,691
e aiutarti a visualizzare quello che fa, non come una parola d'ordine ma come un 

23
00:01:23,691 --> 00:01:24,460
pezzo di matematica.

24
00:01:25,020 --> 00:01:28,006
La mia speranza è che tu riesca a capire che la struttura 

25
00:01:28,006 --> 00:01:31,199
stessa è motivata e che tu sappia cosa significa quando leggi 

26
00:01:31,199 --> 00:01:34,340
o senti parlare di una rete neurale che cita l'apprendimento.

27
00:01:35,360 --> 00:01:37,746
Questo video sarà dedicato alla componente strutturale, 

28
00:01:37,746 --> 00:01:40,260
mentre il successivo affronterà il tema dell'apprendimento.

29
00:01:40,960 --> 00:01:43,599
Quello che faremo è mettere insieme una rete neurale 

30
00:01:43,599 --> 00:01:46,040
che impari a riconoscere le cifre scritte a mano.

31
00:01:49,360 --> 00:01:52,802
Questo è un esempio un po' classico per introdurre l'argomento e sono 

32
00:01:52,802 --> 00:01:56,146
felice di attenermi allo status quo, perché alla fine dei due video 

33
00:01:56,146 --> 00:01:59,539
voglio indicarti un paio di buone risorse dove puoi saperne di più e 

34
00:01:59,539 --> 00:02:03,080
dove puoi scaricare il codice che fa questo e giocarci sul tuo computer.

35
00:02:05,040 --> 00:02:09,773
Esistono molte varianti delle reti neurali e negli ultimi anni c'è stato una 

36
00:02:09,773 --> 00:02:12,724
sorta di boom della ricerca su queste varianti, 

37
00:02:12,724 --> 00:02:18,257
ma in questi due video introduttivi io e te ci limiteremo a vedere la forma più semplice, 

38
00:02:18,257 --> 00:02:19,180
senza fronzoli.

39
00:02:19,860 --> 00:02:25,451
Questo è un prerequisito necessario per comprendere le varianti moderne più potenti e, 

40
00:02:25,451 --> 00:02:28,600
credimi, è ancora molto complesso da comprendere.

41
00:02:29,120 --> 00:02:33,650
Ma anche in questa forma più semplice può imparare a riconoscere le cifre scritte a mano, 

42
00:02:33,650 --> 00:02:36,520
il che è una cosa piuttosto interessante per un computer.

43
00:02:37,480 --> 00:02:39,921
E allo stesso tempo vedrai come non riesce a soddisfare un 

44
00:02:39,921 --> 00:02:42,280
paio di speranze che potremmo nutrire nei suoi confronti.

45
00:02:43,380 --> 00:02:46,974
Come suggerisce il nome, le reti neurali si ispirano al cervello, 

46
00:02:46,974 --> 00:02:48,500
ma vediamo di capire meglio.

47
00:02:48,520 --> 00:02:51,660
Quali sono i neuroni e in che senso sono collegati tra loro?

48
00:02:52,500 --> 00:02:56,252
In questo momento, quando parlo di neurone, voglio che tu pensi a un 

49
00:02:56,252 --> 00:03:00,440
oggetto che contiene un numero, nello specifico un numero compreso tra 0 e 1.

50
00:03:00,680 --> 00:03:02,560
In realtà non è molto di più.

51
00:03:03,780 --> 00:03:09,208
Ad esempio, la rete inizia con un gruppo di neuroni corrispondenti a ciascuno 

52
00:03:09,208 --> 00:03:14,220
dei 28x28 pixel dell'immagine di ingresso, per un totale di 784 neuroni.

53
00:03:14,700 --> 00:03:19,511
Ognuno di questi contiene un numero che rappresenta il valore della scala di grigi 

54
00:03:19,511 --> 00:03:24,380
del pixel corrispondente, che va da 0 per i pixel neri fino a 1 per i pixel bianchi.

55
00:03:25,300 --> 00:03:29,606
Questo numero all'interno del neurone è chiamato attivazione e l'immagine che potresti 

56
00:03:29,606 --> 00:03:33,764
avere in mente è che ogni neurone si illumina quando la sua attivazione è un numero 

57
00:03:33,764 --> 00:03:34,160
elevato.

58
00:03:36,720 --> 00:03:41,860
Quindi tutti questi 784 neuroni costituiscono il primo livello della nostra rete.

59
00:03:46,500 --> 00:03:49,057
Passando all'ultimo strato, questo ha 10 neuroni, 

60
00:03:49,057 --> 00:03:51,360
ognuno dei quali rappresenta una delle cifre.

61
00:03:52,040 --> 00:03:56,166
L'attivazione di questi neuroni, sempre un numero compreso tra 0 e 1, 

62
00:03:56,166 --> 00:04:01,058
rappresenta quanto il sistema pensa che una determinata immagine corrisponda a una 

63
00:04:01,058 --> 00:04:02,120
determinata cifra.

64
00:04:03,040 --> 00:04:06,628
Ci sono anche un paio di livelli intermedi chiamati livelli nascosti, 

65
00:04:06,628 --> 00:04:10,319
che per il momento dovrebbero essere solo un enorme punto interrogativo 

66
00:04:10,319 --> 00:04:13,600
su come verrà gestito il processo di riconoscimento delle cifre.

67
00:04:14,260 --> 00:04:17,722
In questa rete ho scelto due livelli nascosti, ciascuno con 16 neuroni, 

68
00:04:17,722 --> 00:04:20,560
e ammetto che si tratta di una scelta piuttosto arbitraria.

69
00:04:21,019 --> 00:04:24,748
A dire il vero ho scelto due livelli in base a come voglio motivare la struttura 

70
00:04:24,748 --> 00:04:28,200
tra un attimo, e 16, beh, era solo un bel numero da inserire sullo schermo.

71
00:04:28,780 --> 00:04:32,340
In pratica c'è molto spazio per sperimentare una struttura specifica.

72
00:04:33,020 --> 00:04:35,877
Per come funziona la rete, le attivazioni di uno strato 

73
00:04:35,877 --> 00:04:38,480
determinano le attivazioni dello strato successivo.

74
00:04:39,200 --> 00:04:42,374
E naturalmente il cuore della rete come meccanismo di elaborazione 

75
00:04:42,374 --> 00:04:45,737
delle informazioni si riduce esattamente al modo in cui le attivazioni 

76
00:04:45,737 --> 00:04:48,580
di uno strato producono attivazioni nello strato successivo.

77
00:04:49,140 --> 00:04:53,810
Si tratta di un'analogia con il modo in cui, nelle reti biologiche di neuroni, 

78
00:04:53,810 --> 00:04:57,180
alcuni gruppi di neuroni si attivano e ne attivano altri.

79
00:04:58,120 --> 00:05:00,788
La rete che ti mostro è già stata addestrata a 

80
00:05:00,788 --> 00:05:03,400
riconoscere le cifre e ti mostro cosa intendo.

81
00:05:03,640 --> 00:05:08,194
Ciò significa che se inserisci un'immagine, illuminando tutti i 784 neuroni dello 

82
00:05:08,194 --> 00:05:12,026
strato di input in base alla luminosità di ogni pixel dell'immagine, 

83
00:05:12,026 --> 00:05:16,914
quel modello di attivazioni provoca un modello molto specifico nello strato successivo, 

84
00:05:16,914 --> 00:05:21,524
che provoca un modello in quello successivo, che infine dà un modello nello strato 

85
00:05:21,524 --> 00:05:22,080
di output.

86
00:05:22,560 --> 00:05:26,461
E il neurone più luminoso di questo strato di uscita è la scelta della rete, 

87
00:05:26,461 --> 00:05:29,400
per così dire, su quale cifra rappresenta questa immagine.

88
00:05:32,560 --> 00:05:36,135
E prima di addentrarci nella matematica di come uno strato influenza l'altro 

89
00:05:36,135 --> 00:05:39,665
o di come funziona la formazione, parliamo del motivo per cui è ragionevole 

90
00:05:39,665 --> 00:05:43,520
aspettarsi che una struttura a strati come questa si comporti in modo intelligente.

91
00:05:44,060 --> 00:05:45,220
Cosa ci aspettiamo qui?

92
00:05:45,400 --> 00:05:47,600
Qual è la migliore speranza per questi strati intermedi?

93
00:05:48,920 --> 00:05:53,520
Quando tu o io riconosciamo delle cifre, mettiamo insieme vari componenti.

94
00:05:54,200 --> 00:05:56,820
Un 9 ha un anello in alto e una linea a destra.

95
00:05:57,380 --> 00:06:01,180
Anche l'8 ha un occhiello in alto, ma è abbinato a un altro occhiello in basso.

96
00:06:01,980 --> 00:06:06,820
Un 4 si divide fondamentalmente in tre linee specifiche e cose del genere.

97
00:06:07,600 --> 00:06:11,685
Ora, in un mondo perfetto, potremmo sperare che ogni neurone del penultimo 

98
00:06:11,685 --> 00:06:14,518
strato corrisponda a una di queste sottocomponenti, 

99
00:06:14,518 --> 00:06:18,114
in modo che ogni volta che inserisci un'immagine con, ad esempio, 

100
00:06:18,114 --> 00:06:22,036
un ciclo in alto, come un 9 o un 8, ci sia qualche neurone specifico la 

101
00:06:22,036 --> 00:06:23,780
cui attivazione sarà vicina a 1.

102
00:06:24,500 --> 00:06:27,075
E non mi riferisco a questo specifico ciclo di pixel, 

103
00:06:27,075 --> 00:06:30,510
ma la speranza è che qualsiasi modello di loop in generale verso l'alto 

104
00:06:30,510 --> 00:06:31,560
attivi questo neurone.

105
00:06:32,440 --> 00:06:36,187
In questo modo, per passare dal terzo all'ultimo livello è sufficiente 

106
00:06:36,187 --> 00:06:40,040
imparare quale combinazione di sottocomponenti corrisponde a quali cifre.

107
00:06:41,000 --> 00:06:43,123
Naturalmente, questo non fa che aggravare il problema, 

108
00:06:43,123 --> 00:06:46,404
perché come si fa a riconoscere questi sottocomponenti o a imparare quali dovrebbero 

109
00:06:46,404 --> 00:06:47,640
essere i sottocomponenti giusti?

110
00:06:48,060 --> 00:06:53,060
E non ho ancora parlato di come uno strato influenzi l'altro, ma seguimi per un momento.

111
00:06:53,680 --> 00:06:56,680
Anche il riconoscimento di un loop può essere suddiviso in sottoproblemi.

112
00:06:57,280 --> 00:07:00,310
Un modo ragionevole per farlo è quello di riconoscere 

113
00:07:00,310 --> 00:07:02,780
innanzitutto i vari bordi che lo compongono.

114
00:07:03,780 --> 00:07:08,129
Allo stesso modo, una linea lunga, come quella che puoi vedere nelle cifre 1, 

115
00:07:08,129 --> 00:07:11,531
4 o 7, è in realtà solo un bordo lungo, o forse la consideri 

116
00:07:11,531 --> 00:07:14,320
come un certo schema di diversi bordi più piccoli.

117
00:07:15,140 --> 00:07:18,703
Quindi forse la nostra speranza è che ogni neurone del 

118
00:07:18,703 --> 00:07:22,720
secondo strato della rete corrisponda ai vari bordi rilevanti.

119
00:07:23,540 --> 00:07:28,891
Forse quando arriva un'immagine come questa, si accendono tutti i neuroni associati a 

120
00:07:28,891 --> 00:07:34,243
circa 8-10 bordi specifici, che a loro volta accendono i neuroni associati all'anello 

121
00:07:34,243 --> 00:07:39,720
superiore e a una lunga linea verticale, e questi accendono il neurone associato a un 9.

122
00:07:40,680 --> 00:07:44,665
Se questo è ciò che la nostra rete finale effettivamente fa è un'altra questione, 

123
00:07:44,665 --> 00:07:47,339
su cui tornerò quando vedremo come addestrare la rete, 

124
00:07:47,339 --> 00:07:51,033
ma questa è una speranza che potremmo avere, una sorta di obiettivo con una 

125
00:07:51,033 --> 00:07:52,540
struttura a strati come questa.

126
00:07:53,160 --> 00:07:56,641
Inoltre, puoi immaginare come la capacità di rilevare bordi e schemi di questo 

127
00:07:56,641 --> 00:08:00,300
tipo possa essere davvero utile per altri compiti di riconoscimento delle immagini.

128
00:08:00,880 --> 00:08:02,909
E anche al di là del riconoscimento delle immagini, 

129
00:08:02,909 --> 00:08:06,304
ci sono tutti i tipi di cose intelligenti che potresti voler fare e che si suddividono 

130
00:08:06,304 --> 00:08:07,280
in livelli di astrazione.

131
00:08:08,040 --> 00:08:12,124
Il parsing del parlato, ad esempio, consiste nel prendere l'audio grezzo e individuare 

132
00:08:12,124 --> 00:08:15,317
i suoni distinti, che si combinano per formare determinate sillabe, 

133
00:08:15,317 --> 00:08:19,214
che si combinano per formare parole, che si combinano per formare frasi e pensieri 

134
00:08:19,214 --> 00:08:20,060
più astratti, ecc.

135
00:08:21,100 --> 00:08:24,093
Ma tornando al funzionamento effettivo di tutto questo, 

136
00:08:24,093 --> 00:08:28,530
immagina di progettare in questo momento come le attivazioni di uno strato possano 

137
00:08:28,530 --> 00:08:29,920
determinare il successivo.

138
00:08:30,860 --> 00:08:35,943
L'obiettivo è avere un meccanismo che possa combinare i pixel in bordi, 

139
00:08:35,943 --> 00:08:38,980
o i bordi in schemi, o gli schemi in cifre.

140
00:08:39,440 --> 00:08:45,061
Per ingrandire un esempio molto specifico, diciamo che la speranza è che un particolare 

141
00:08:45,061 --> 00:08:50,620
neurone del secondo livello capisca se l'immagine ha o meno un bordo in questa regione.

142
00:08:51,440 --> 00:08:55,100
La domanda da porsi è: quali parametri deve avere la rete?

143
00:08:55,640 --> 00:08:58,675
Quali sono i quadranti e le manopole che dovresti essere in grado di 

144
00:08:58,675 --> 00:09:01,973
regolare in modo che sia abbastanza espressivo da catturare potenzialmente 

145
00:09:01,973 --> 00:09:04,261
questo pattern, o qualsiasi altro pattern di pixel, 

146
00:09:04,261 --> 00:09:07,780
o il pattern per cui più bordi possono formare un loop, e altre cose del genere?

147
00:09:08,720 --> 00:09:12,113
Allora, quello che faremo è assegnare un peso a ciascuna delle 

148
00:09:12,113 --> 00:09:15,560
connessioni tra il nostro neurone e i neuroni del primo livello.

149
00:09:16,320 --> 00:09:17,700
Questi pesi sono solo numeri.

150
00:09:18,540 --> 00:09:21,954
Poi prendi tutte le attivazioni del primo livello e 

151
00:09:21,954 --> 00:09:25,500
calcola la loro somma ponderata in base a questi pesi.

152
00:09:27,700 --> 00:09:31,030
Trovo utile pensare a questi pesi come organizzati in una piccola 

153
00:09:31,030 --> 00:09:34,411
griglia a sé stante e utilizzerò i pixel verdi per indicare i pesi 

154
00:09:34,411 --> 00:09:37,187
positivi e i pixel rossi per indicare i pesi negativi, 

155
00:09:37,187 --> 00:09:40,770
dove la luminosità di quel pixel è una rappresentazione approssimativa 

156
00:09:40,770 --> 00:09:41,780
del valore del peso.

157
00:09:42,780 --> 00:09:46,369
Se i pesi associati a quasi tutti i pixel fossero pari a zero, 

158
00:09:46,369 --> 00:09:50,300
ad eccezione di alcuni pesi positivi nella regione che ci interessa, 

159
00:09:50,300 --> 00:09:55,199
allora la somma ponderata di tutti i valori dei pixel equivarrebbe a sommare i valori 

160
00:09:55,199 --> 00:09:57,820
dei pixel solo nella regione che ci interessa.

161
00:09:59,140 --> 00:10:02,374
E se volessi davvero capire se c'è un bordo qui, 

162
00:10:02,374 --> 00:10:06,600
potresti avere dei pesi negativi associati ai pixel circostanti.

163
00:10:07,480 --> 00:10:10,064
Quindi la somma è maggiore quando i pixel centrali 

164
00:10:10,064 --> 00:10:12,700
sono luminosi ma i pixel circostanti sono più scuri.

165
00:10:14,260 --> 00:10:18,928
Quando calcoli una somma ponderata come questa, puoi ottenere un numero qualsiasi, 

166
00:10:18,928 --> 00:10:23,540
ma per questa rete vogliamo che le attivazioni siano un valore compreso tra 0 e 1.

167
00:10:24,120 --> 00:10:28,048
Quindi, una cosa comune da fare è pompare questa somma ponderata in una 

168
00:10:28,048 --> 00:10:32,140
funzione che schiaccia la linea dei numeri reali nell'intervallo tra 0 e 1.

169
00:10:32,460 --> 00:10:37,420
Una funzione comune che fa questo è la funzione sigmoide, nota anche come curva logistica.

170
00:10:38,000 --> 00:10:41,769
In pratica, gli ingressi molto negativi finiscono per avvicinarsi a 0, 

171
00:10:41,769 --> 00:10:45,803
quelli positivi per avvicinarsi a 1 e il tutto cresce costantemente intorno 

172
00:10:45,803 --> 00:10:46,600
all'ingresso 0.

173
00:10:49,120 --> 00:10:52,676
Quindi l'attivazione del neurone è fondamentalmente una 

174
00:10:52,676 --> 00:10:56,360
misura di quanto sia positiva la relativa somma ponderata.

175
00:10:57,540 --> 00:10:59,619
Ma forse non è che si vuole che il neurone si 

176
00:10:59,619 --> 00:11:01,880
accenda quando la somma ponderata è maggiore di 0.

177
00:11:02,280 --> 00:11:06,360
Forse vuoi che sia attivo solo quando la somma è maggiore di 10, ad esempio.

178
00:11:06,840 --> 00:11:10,260
In altre parole, vuoi che ci sia un pregiudizio perché sia inattivo.

179
00:11:11,380 --> 00:11:15,114
A questo punto aggiungeremo un altro numero, ad esempio 10 negativo, 

180
00:11:15,114 --> 00:11:19,660
alla somma ponderata prima di inserirla nella funzione di squishificazione sigmoide.

181
00:11:20,580 --> 00:11:22,440
Questo numero aggiuntivo è chiamato bias.

182
00:11:23,460 --> 00:11:27,438
Quindi i pesi ti dicono quale modello di pixel questo neurone del secondo 

183
00:11:27,438 --> 00:11:31,362
livello sta rilevando e il bias ti dice quanto deve essere alta la somma 

184
00:11:31,362 --> 00:11:35,180
dei pesi prima che il neurone inizi ad attivarsi in modo significativo.

185
00:11:36,120 --> 00:11:37,680
E questo è solo un neurone.

186
00:11:38,280 --> 00:11:44,530
Ogni altro neurone di questo strato sarà collegato a tutti i 784 neuroni pixel 

187
00:11:44,530 --> 00:11:50,940
del primo strato e ognuna di queste 784 connessioni ha un proprio peso associato.

188
00:11:51,600 --> 00:11:54,387
Inoltre, ognuno di essi ha un bias, un altro numero che si 

189
00:11:54,387 --> 00:11:57,600
aggiunge alla somma ponderata prima di schiacciarla con la sigmoide.

190
00:11:58,110 --> 00:11:59,540
E sono tante le cose a cui pensare!

191
00:11:59,960 --> 00:12:05,935
Con questo strato nascosto di 16 neuroni, il totale è di 784 volte 16 pesi, 

192
00:12:05,935 --> 00:12:07,980
oltre a 16 polarizzazioni.

193
00:12:08,840 --> 00:12:11,940
E tutto questo è solo il collegamento tra il primo strato e il secondo.

194
00:12:12,520 --> 00:12:17,340
Anche le connessioni tra gli altri livelli hanno una serie di pesi e pregiudizi associati.

195
00:12:18,340 --> 00:12:23,800
Tutto sommato, questa rete ha quasi esattamente 13.000 pesi e pregiudizi totali.

196
00:12:23,800 --> 00:12:26,853
13.000 manopole e quadranti che possono essere regolati e 

197
00:12:26,853 --> 00:12:29,960
ruotati per far sì che la rete si comporti in modi diversi.

198
00:12:31,040 --> 00:12:34,571
Quindi, quando parliamo di apprendimento, ci riferiamo al fatto 

199
00:12:34,571 --> 00:12:38,821
che il computer deve trovare un'impostazione valida per tutti questi numeri, 

200
00:12:38,821 --> 00:12:41,360
in modo da risolvere il problema in questione.

201
00:12:42,620 --> 00:12:47,238
Un esperimento di pensiero che è allo stesso tempo divertente e terrificante è quello di 

202
00:12:47,238 --> 00:12:51,027
immaginare di sedersi e impostare a mano tutti questi pesi e pregiudizi, 

203
00:12:51,027 --> 00:12:55,282
modificando di proposito i numeri in modo che il secondo strato raccolga i bordi, 

204
00:12:55,282 --> 00:12:56,580
il terzo gli schemi, ecc.

205
00:12:56,980 --> 00:13:01,280
Personalmente lo trovo soddisfacente piuttosto che trattare la rete come una totale 

206
00:13:01,280 --> 00:13:04,863
scatola nera, perché quando la rete non funziona come avevi previsto, 

207
00:13:04,863 --> 00:13:09,112
se hai costruito un po' di relazione con il significato effettivo dei pesi e delle 

208
00:13:09,112 --> 00:13:13,412
distorsioni, hai un punto di partenza per sperimentare come modificare la struttura 

209
00:13:13,412 --> 00:13:14,180
per migliorare.

210
00:13:14,960 --> 00:13:18,131
Oppure, quando la rete funziona ma non per i motivi che ci si aspettava, 

211
00:13:18,131 --> 00:13:21,693
scavare per capire cosa stanno facendo i pesi e le distorsioni è un buon modo per 

212
00:13:21,693 --> 00:13:25,385
mettere in discussione le proprie ipotesi ed esporre l'intero spazio delle possibili 

213
00:13:25,385 --> 00:13:25,820
soluzioni.

214
00:13:26,840 --> 00:13:30,680
A proposito, la funzione attuale è un po' complicata da scrivere, non credi?

215
00:13:32,500 --> 00:13:37,140
Ti mostrerò quindi un modo più compatto di rappresentare queste connessioni.

216
00:13:37,660 --> 00:13:39,118
Questo è il modo in cui lo vedresti se decidessi di 

217
00:13:39,118 --> 00:13:40,520
approfondire le tue conoscenze sulle reti neurali.

218
00:13:41,380 --> 00:13:49,013
Organizzare tutte le attivazioni di uno strato in una colonna come una matrice 

219
00:13:49,013 --> 00:13:56,937
corrisponde alle connessioni tra uno strato e un particolare neurone dello strato 

220
00:13:56,937 --> 00:13:58,000
successivo.

221
00:13:58,540 --> 00:14:02,189
Ciò significa che la somma ponderata delle attivazioni del primo 

222
00:14:02,189 --> 00:14:05,725
strato in base a questi pesi corrisponde a uno dei termini del 

223
00:14:05,725 --> 00:14:09,880
prodotto vettoriale della matrice di tutto ciò che abbiamo qui a sinistra.

224
00:14:14,000 --> 00:14:17,390
Tra l'altro, gran parte dell'apprendimento automatico si basa su una buona 

225
00:14:17,390 --> 00:14:20,915
conoscenza dell'algebra lineare, quindi se vuoi una comprensione visiva delle 

226
00:14:20,915 --> 00:14:24,260
matrici e del significato della moltiplicazione vettoriale delle matrici, 

227
00:14:24,260 --> 00:14:27,289
dai un'occhiata alla serie che ho realizzato sull'algebra lineare, 

228
00:14:27,289 --> 00:14:28,600
in particolare al capitolo 3.

229
00:14:29,240 --> 00:14:33,560
Tornando alla nostra espressione, invece di parlare di aggiungere il bias a ciascuno di 

230
00:14:33,560 --> 00:14:37,881
questi valori in modo indipendente, lo rappresentiamo organizzando tutti questi bias in 

231
00:14:37,881 --> 00:14:42,300
un vettore e aggiungendo l'intero vettore al prodotto vettoriale della matrice precedente.

232
00:14:43,280 --> 00:14:47,081
Poi, come ultimo passo, avvolgerò una sigmoide intorno all'esterno 

233
00:14:47,081 --> 00:14:50,655
e ciò che dovrebbe rappresentare è che applicherai la funzione 

234
00:14:50,655 --> 00:14:54,740
sigmoide a ogni componente specifica del vettore risultante all'interno.

235
00:14:55,940 --> 00:15:00,627
Quindi, una volta scritta questa matrice di pesi e questi vettori come simboli propri, 

236
00:15:00,627 --> 00:15:04,345
puoi comunicare l'intera transizione delle attivazioni da uno strato 

237
00:15:04,345 --> 00:15:08,116
all'altro in una piccola espressione estremamente stretta e ordinata, 

238
00:15:08,116 --> 00:15:11,349
che rende il codice pertinente molto più semplice e veloce, 

239
00:15:11,349 --> 00:15:15,660
dato che molte librerie ottimizzano al massimo la moltiplicazione delle matrici.

240
00:15:17,820 --> 00:15:19,588
Ricordi che prima ho detto che questi neuroni sono 

241
00:15:19,588 --> 00:15:21,460
semplicemente degli oggetti che contengono dei numeri?

242
00:15:22,220 --> 00:15:27,593
Ovviamente i numeri specifici che contengono dipendono dall'immagine che inserisci, 

243
00:15:27,593 --> 00:15:33,094
quindi è più corretto pensare a ogni neurone come a una funzione che riceve le uscite 

244
00:15:33,094 --> 00:15:38,340
di tutti i neuroni dello strato precedente e produce un numero compreso tra 0 e 1.

245
00:15:39,200 --> 00:15:43,166
In realtà l'intera rete è solo una funzione che riceve 

246
00:15:43,166 --> 00:15:47,060
784 numeri come input e ne restituisce 10 come output.

247
00:15:47,560 --> 00:15:50,359
Si tratta di una funzione assurdamente complicata, 

248
00:15:50,359 --> 00:15:54,695
che prevede 13.000 parametri sotto forma di pesi e distorsioni che individuano 

249
00:15:54,695 --> 00:15:59,470
determinati schemi e che comporta l'iterazione di molti prodotti vettoriali di matrici 

250
00:15:59,470 --> 00:16:02,049
e della funzione di squishificazione sigmoide, 

251
00:16:02,049 --> 00:16:06,660
ma è comunque una funzione e in un certo senso è rassicurante che sembri complicata.

252
00:16:07,340 --> 00:16:09,810
Insomma, se fosse più semplice, che speranza avremmo che 

253
00:16:09,810 --> 00:16:12,280
possa affrontare la sfida del riconoscimento delle cifre?

254
00:16:13,340 --> 00:16:14,700
E come affronta questa sfida?

255
00:16:15,080 --> 00:16:17,356
Come fa questa rete ad apprendere i pesi e i bias 

256
00:16:17,356 --> 00:16:19,360
appropriati semplicemente osservando i dati?

257
00:16:20,140 --> 00:16:23,268
Ebbene, questo è ciò che mostrerò nel prossimo video e approfondirò 

258
00:16:23,268 --> 00:16:26,120
anche l'aspetto di questa particolare rete che stiamo vedendo.

259
00:16:27,580 --> 00:16:31,011
A questo punto dovrei dire di iscriversi per essere avvisati quando 

260
00:16:31,011 --> 00:16:34,291
escono i video o qualsiasi altro nuovo video, ma realisticamente 

261
00:16:34,291 --> 00:16:37,420
la maggior parte di voi non riceve notifiche da YouTube, vero?

262
00:16:38,020 --> 00:16:40,215
Forse, più onestamente, dovrei dire di iscriversi, 

263
00:16:40,215 --> 00:16:43,445
in modo che le reti neurali alla base dell'algoritmo di raccomandazione di 

264
00:16:43,445 --> 00:16:46,846
YouTube siano indotte a credere che tu voglia che i contenuti di questo canale 

265
00:16:46,846 --> 00:16:47,880
ti vengano raccomandati.

266
00:16:48,560 --> 00:16:49,940
In ogni caso, resta aggiornato per saperne di più.

267
00:16:50,760 --> 00:16:53,500
Grazie mille a tutti coloro che sostengono questi video su Patreon.

268
00:16:54,000 --> 00:16:57,345
Quest'estate sono stata un po' lenta nel progredire nella serie delle probabilità, 

269
00:16:57,345 --> 00:16:59,602
ma dopo questo progetto mi ci sto buttando a capofitto, 

270
00:16:59,602 --> 00:17:01,900
quindi i mecenati possono aspettarsi degli aggiornamenti.

271
00:17:03,600 --> 00:17:06,462
Per concludere, ho qui con me Leisha Lee, che ha svolto il suo dottorato 

272
00:17:06,462 --> 00:17:09,129
di ricerca sull'aspetto teorico del deep learning e che attualmente 

273
00:17:09,129 --> 00:17:11,953
lavora presso una società di venture capital chiamata Amplify Partners, 

274
00:17:11,953 --> 00:17:14,619
che ha gentilmente fornito parte dei finanziamenti per questo video.

275
00:17:15,460 --> 00:17:19,119
Quindi, Leisha, una cosa che credo dovremmo menzionare rapidamente è la funzione sigmoide.

276
00:17:19,700 --> 00:17:23,001
A quanto ho capito, le prime reti usano questo metodo per schiacciare 

277
00:17:23,001 --> 00:17:26,019
la somma ponderata in quell'intervallo compreso tra zero e uno, 

278
00:17:26,019 --> 00:17:29,840
in un certo senso motivato dall'analogia biologica tra neuroni inattivi o attivi.

279
00:17:30,280 --> 00:17:30,300
Esattamente.

280
00:17:30,560 --> 00:17:34,040
Ma sono relativamente poche le reti moderne che utilizzano la sigmoide.

281
00:17:34,320 --> 00:17:34,320
Sì.

282
00:17:34,440 --> 00:17:35,540
È una specie di vecchia scuola, giusto?

283
00:17:35,760 --> 00:17:38,980
Sì, o meglio, il relu sembra essere molto più facile da addestrare.

284
00:17:39,400 --> 00:17:42,340
E relu sta per unità lineare rettificata?

285
00:17:42,680 --> 00:17:47,362
Sì, è questo tipo di funzione in cui si prende un massimo di zero e a, 

286
00:17:47,362 --> 00:17:52,902
dove a è dato da ciò che stavi spiegando nel video e ciò che è stato motivato credo 

287
00:17:52,902 --> 00:17:58,507
sia stato in parte da un'analogia biologica con il fatto che i neuroni si attivano o 

288
00:17:58,507 --> 00:18:04,047
non si attivano e quindi se superano una certa soglia sarebbe la funzione identità, 

289
00:18:04,047 --> 00:18:08,333
ma se non lo fanno allora non si attivano e quindi sarebbe zero, 

290
00:18:08,333 --> 00:18:10,840
quindi è una sorta di semplificazione.

291
00:18:11,160 --> 00:18:16,779
L'uso delle sigmoidi non aiutava l'addestramento o era molto difficile da addestrare, 

292
00:18:16,779 --> 00:18:21,091
quindi si è provato con la relu e si è visto che funzionava molto 

293
00:18:21,091 --> 00:18:24,620
bene per queste reti neurali incredibilmente profonde.

294
00:18:25,100 --> 00:18:25,640
Bene, grazie Alicia.

