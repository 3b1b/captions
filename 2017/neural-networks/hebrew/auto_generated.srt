1
00:00:00,000 --> 00:00:11,200
זה 3. זה כתוב בצורה מרושלת ומעובד ברזולוציה נמוכה במיוחד של 28x28 פיקסלים, אבל

2
00:00:11,200 --> 00:00:15,340
המוח שלך לא מתקשה לזהות אותו כ-3. ואני רוצה שתקדישו רגע כדי להעריך

3
00:00:15,340 --> 00:00:20,500
כמה זה מטורף שהמוח יכול לעשות את זה כל כך ללא מאמץ. כלומר, זה, זה

4
00:00:20,500 --> 00:00:26,180
וזה גם ניתנים לזיהוי בתור 3s, למרות שהערכים הספציפיים של כל פיקסל

5
00:00:26,180 --> 00:00:31,260
שונים מאוד מתמונה אחת לאחרת. התאים הרגישים לאור המסוימים בעין שלך שיורים

6
00:00:31,260 --> 00:00:36,020
כשאתה רואה את ה-3 הזה שונים מאוד מאלה שיורים כשאתה רואה את ה-3

7
00:00:36,020 --> 00:00:42,900
הזה. אבל משהו בקליפת המוח הוויזואלית המשוגעת הזו שלך פותר את אלה

8
00:00:42,900 --> 00:00:49,300
כמייצגים את אותו רעיון, ובו בזמן מזהה תמונות אחרות כרעיונות נפרדים משלהם.

9
00:00:49,300 --> 00:00:55,820
אבל אם אמרתי לך, היי, שב ותכתוב עבורי תוכנית שמקבלת רשת של 28x28

10
00:00:56,340 --> 00:01:01,780
ומוציאה מספר בודד בין 0 ל-10, ואומרת לך מה היא חושבת שהספרה,

11
00:01:01,780 --> 00:01:07,860
ובכן, המשימה עוברת מטריוויאלי קומית ל קשה להחריד. אלא אם כן חיית

12
00:01:07,860 --> 00:01:12,020
מתחת לסלע, אני חושב שאני בקושי צריך להניע את הרלוונטיות והחשיבות של

13
00:01:12,020 --> 00:01:16,460
למידת מכונה ורשתות עצביות להווה ולעתיד. אבל מה שאני רוצה לעשות כאן זה

14
00:01:16,460 --> 00:01:22,020
להראות לכם מהי בעצם רשת עצבית, בהנחה שאין רקע, וכדי לעזור לדמיין מה היא עושה, לא

15
00:01:22,060 --> 00:01:26,860
בתור מילת באז אלא כקטע של מתמטיקה. התקווה שלי היא רק שתצאו בהרגשה שהמבנה

16
00:01:26,860 --> 00:01:31,460
עצמו מונע, ותרגישו שאתם יודעים מה זה אומר כשאתם קוראים או שומעים

17
00:01:31,460 --> 00:01:36,780
על רשת עצבית לומדת ציטוט-ללא ציטוט. הסרטון הזה רק יוקדש

18
00:01:36,780 --> 00:01:40,300
למרכיב המבנה של זה, והסרטון הבא יעסוק בלמידה.

19
00:01:40,300 --> 00:01:45,580
מה שאנחנו הולכים לעשות זה להרכיב רשת עצבית שיכולה ללמוד לזהות ספרות בכתב יד.

20
00:01:45,580 --> 00:01:53,540
זו דוגמה קצת קלאסית להצגת הנושא, ואני שמח להישאר עם הסטטוס קוו

21
00:01:53,540 --> 00:01:57,340
כאן, כי בסוף שני הסרטונים אני רוצה להפנות אותך לכמה משאבים

22
00:01:57,340 --> 00:02:01,420
טובים שבהם תוכל ללמוד עוד, והיכן אתה יכול להוריד את הקוד שעושה

23
00:02:01,420 --> 00:02:07,820
זאת ולשחק איתו במחשב שלך. יש הרבה וריאציות של רשתות עצביות, ובשנים האחרונות

24
00:02:07,820 --> 00:02:12,900
חלה סוג של פריחה במחקר לקראת הווריאציות האלה, אבל בשני סרטוני ההיכרות האלה

25
00:02:12,940 --> 00:02:18,100
אתה ואני רק הולכים להסתכל על צורת הווניל הפשוטה והפשוטה ביותר ללא

26
00:02:18,100 --> 00:02:23,020
תוספת סלסולים. זה סוג של תנאי הכרחי להבנת כל אחת מהגרסאות המודרניות החזקות

27
00:02:23,020 --> 00:02:28,140
יותר, ותאמין לי שעדיין יש לה הרבה מורכבות בשבילנו לכרוך את דעתנו.

28
00:02:28,140 --> 00:02:33,440
אבל אפילו בצורה הפשוטה ביותר הזו הוא יכול ללמוד לזהות ספרות בכתב יד, וזה

29
00:02:33,440 --> 00:02:39,380
דבר די מגניב למחשב להיות מסוגל לעשות. ובו בזמן תראה איך זה אכן

30
00:02:39,460 --> 00:02:45,620
נופל מתקוות זוגיות שאולי יש לנו לזה. כפי שהשם מרמז, רשתות עצביות נוצרות בהשראת

31
00:02:45,620 --> 00:02:50,820
המוח, אבל בואו נפרק את זה. מהם הנוירונים, ובאיזה מובן הם קשורים זה

32
00:02:50,820 --> 00:02:56,900
לזה? כרגע כשאני אומר נוירון, כל מה שאני רוצה שתחשוב עליו זה דבר

33
00:02:56,900 --> 00:03:04,380
שמכיל מספר, במיוחד מספר בין 0 ל-1. זה באמת לא יותר מזה. לדוגמה, הרשת

34
00:03:04,420 --> 00:03:10,060
מתחילה עם חבורה של נוירונים המקבילים לכל אחד מ-28 כפול 28 פיקסלים של תמונת

35
00:03:10,060 --> 00:03:17,260
הקלט, שהם 784 נוירונים בסך הכל. כל אחד מאלה מכיל מספר המייצג את ערך

36
00:03:17,260 --> 00:03:23,900
גווני האפור של הפיקסל המתאים, החל מ-0 עבור פיקסלים שחורים ועד 1 עבור פיקסלים לבנים.

37
00:03:23,900 --> 00:03:30,060
המספר הזה בתוך הנוירון נקרא ההפעלה שלו, והתמונה שאולי יש לך בראש

38
00:03:30,060 --> 00:03:37,260
היא שכל נוירון מואר כאשר ההפעלה שלו היא מספר גבוה. אז כל 784

39
00:03:37,260 --> 00:03:47,820
הנוירונים האלה מהווים את השכבה הראשונה של הרשת שלנו. עכשיו קופצים לשכבה האחרונה, יש לזה

40
00:03:47,820 --> 00:03:53,780
10 נוירונים, כל אחד מייצג את אחת מהספרות. ההפעלה בנוירונים האלה, שוב מספר

41
00:03:53,780 --> 00:03:59,460
שהוא בין 0 ל-1, מייצגת עד כמה המערכת חושבת שתמונה

42
00:03:59,500 --> 00:04:05,180
נתונה מתכתבת עם ספרה נתונה. יש גם כמה שכבות ביניהן הנקראות

43
00:04:05,180 --> 00:04:10,780
השכבות הנסתרות, שלעת עתה אמורות להוות סימן שאלה ענק לאיך לכל הרוחות

44
00:04:10,780 --> 00:04:15,900
התהליך הזה של זיהוי ספרות יטופל. ברשת הזו בחרתי שתי שכבות נסתרות,

45
00:04:15,900 --> 00:04:21,460
כל אחת עם 16 נוירונים, ויש להודות שזו סוג של בחירה שרירותית. למען האמת, בחרתי

46
00:04:21,460 --> 00:04:26,620
שתי שכבות על סמך איך אני רוצה להניע את המבנה ברגע אחד, ו-16, ובכן, זה

47
00:04:26,620 --> 00:04:30,940
היה רק מספר נחמד שיתאים למסך. בפועל יש כאן הרבה מקום להתנסות

48
00:04:30,940 --> 00:04:37,020
במבנה ספציפי. האופן שבו הרשת פועלת, הפעלות בשכבה אחת קובעות את ההפעלות

49
00:04:37,020 --> 00:04:42,340
של השכבה הבאה. וכמובן הלב של הרשת כמנגנון עיבוד מידע

50
00:04:42,340 --> 00:04:47,820
מסתכם בדיוק איך אותן הפעלה משכבה אחת מביאות להפעלה בשכבה

51
00:04:47,820 --> 00:04:53,340
הבאה. זה אמור להיות אנלוגי באופן רופף לאופן שבו ברשתות ביולוגיות של נוירונים

52
00:04:53,380 --> 00:04:59,380
קבוצות מסוימות של נוירונים היורות גורמות לאחרים לירות. עכשיו הרשת שאני מראה כאן כבר

53
00:04:59,380 --> 00:05:04,260
עברה הכשרה לזהות ספרות, ותן לי להראות לך למה אני מתכוון בזה. זה אומר שאם

54
00:05:04,260 --> 00:05:10,900
אתה מזין תמונה שמאירה את כל 784 הנוירונים של שכבת הקלט לפי הבהירות של

55
00:05:10,900 --> 00:05:16,860
כל פיקסל בתמונה, דפוס ההפעלה הזה גורם לאיזה דפוס מאוד ספציפי בשכבה הבאה, מה

56
00:05:16,860 --> 00:05:21,740
שגורם לדפוס כלשהו בשכבה שאחרי. זה, מה שסוף סוף נותן דפוס כלשהו בשכבת הפלט.

57
00:05:21,780 --> 00:05:27,540
והנוירון הבהיר ביותר של שכבת הפלט היא הבחירה של הרשת, כביכול, באיזו

58
00:05:27,540 --> 00:05:35,420
ספרה התמונה הזו מייצגת. ולפני שקפוץ למתמטיקה כיצד שכבה אחת משפיעה על השכבה

59
00:05:35,420 --> 00:05:40,460
הבאה, או איך האימון עובד, בואו נדבר רק על למה זה בכלל הגיוני לצפות

60
00:05:40,460 --> 00:05:46,340
ממבנה שכבות כזה להתנהג בצורה אינטליגנטית. למה אנחנו מצפים כאן? מהי התקווה הטובה ביותר

61
00:05:46,420 --> 00:05:52,420
למה שכבות הביניים האלה עשויות לעשות? ובכן, כאשר אתה או אני מזהים ספרות, אנו מחברים

62
00:05:52,420 --> 00:05:58,980
רכיבים שונים. ל-9 יש לולאה למעלה וקו מימין. ל-8 יש גם לולאה למעלה,

63
00:05:58,980 --> 00:06:05,420
אבל היא משודכת עם לולאה נוספת למטה. 4 בעצם מתפרק לשלוש שורות ספציפיות,

64
00:06:05,420 --> 00:06:11,500
ודברים כאלה. עכשיו בעולם מושלם, אנו עשויים לקוות שכל נוירון בשכבה השנייה-אחרונה מתכתב

65
00:06:11,740 --> 00:06:17,460
עם אחד מתת-הרכיבים האלה, שבכל פעם שאתה מזין תמונה עם, נגיד, לולאה

66
00:06:17,460 --> 00:06:23,060
למעלה, כמו 9 או 8, יש כמה נוירון ספציפי שהפעלתו עומדת להיות קרובה

67
00:06:23,060 --> 00:06:28,620
ל-1. ואני לא מתכוון ללולאה הספציפית הזו של פיקסלים, התקווה תהיה שכל דפוס לולאה

68
00:06:28,620 --> 00:06:33,980
בדרך כלל לכיוון העליון מפעיל את הנוירון הזה. בדרך זו, מעבר מהשכבה השלישית

69
00:06:33,980 --> 00:06:39,380
לשכבה האחרונה רק מצריך ללמוד איזה שילוב של רכיבי משנה מתאים לאיזה

70
00:06:39,380 --> 00:06:44,020
ספרות. כמובן, זה רק מעיף את הבעיה בהמשך הדרך, כי איך תזהה את

71
00:06:44,020 --> 00:06:48,340
רכיבי המשנה האלה, או אפילו תלמד מה צריכים להיות רכיבי המשנה הנכונים? ועדיין לא

72
00:06:48,340 --> 00:06:52,900
דיברתי אפילו על איך שכבה אחת משפיעה על השני, אבל רוץ איתי על זה לרגע.

73
00:06:52,900 --> 00:06:59,020
זיהוי לולאה יכול גם להתפרק לתת-בעיות. אחת הדרכים הגיוניות לעשות זאת תהיה

74
00:06:59,020 --> 00:07:05,640
לזהות תחילה את הקצוות הקטנים השונים המרכיבים אותו. באופן דומה, קו ארוך כמו מהסוג שאתה

75
00:07:05,640 --> 00:07:11,280
עשוי לראות בספרות 1 או 4 או 7, ובכן, זה באמת רק קצה ארוך, או אולי אתה חושב

76
00:07:11,280 --> 00:07:18,440
על זה כעל דפוס מסוים של כמה קצוות קטנים יותר. אז אולי התקווה שלנו היא שכל נוירון

77
00:07:18,440 --> 00:07:24,680
בשכבה השנייה של הרשת מתכתב עם הקצוות הקטנים הרלוונטיים השונים. אולי כאשר תמונה

78
00:07:24,680 --> 00:07:30,760
כמו זו נכנסת, היא מאירה את כל הנוירונים הקשורים בסביבות 8 עד 10

79
00:07:31,040 --> 00:07:36,480
קצוות קטנים ספציפיים, אשר בתורו מאירים את הנוירונים הקשורים ללולאה העליונה ולקו אנכי

80
00:07:36,480 --> 00:07:41,960
ארוך, ואלו מאירים את נוירון הקשור ל-9. האם זה מה שהרשת הסופית שלנו

81
00:07:41,960 --> 00:07:46,560
עושה או לא, זו שאלה אחרת, שאלה שאחזור אליה ברגע שנראה איך לאמן את

82
00:07:46,560 --> 00:07:51,800
הרשת. אבל זו תקווה שאולי תהיה לנו, מעין מטרה עם מבנה השכבות

83
00:07:51,800 --> 00:07:57,440
הזה. יתר על כן, אתה יכול לדמיין איך היכולת לזהות קצוות ודפוסים כמו זה

84
00:07:57,480 --> 00:08:02,440
יהיה ממש שימושי עבור משימות זיהוי תמונות אחרות. ואפילו מעבר לזיהוי תמונה, יש

85
00:08:02,440 --> 00:08:06,640
כל מיני דברים אינטליגנטיים שאולי תרצו לעשות שמתפרקים לשכבות של

86
00:08:06,640 --> 00:08:12,640
הפשטה. ניתוח דיבור, למשל, כרוך בנטילת אודיו גולמי ובחירת צלילים מובחנים,

87
00:08:12,640 --> 00:08:17,760
המשלבים את יצירת הברות מסוימות, המשתלבות ויוצרות מילים, המשלבות יצירת ביטויים

88
00:08:17,760 --> 00:08:23,360
ומחשבות מופשטות יותר, וכו'. אבל אם נחזור לאופן שבו כל זה עובד

89
00:08:23,400 --> 00:08:29,160
בפועל, דמיינו את עצמכם כעת מעצבים כיצד בדיוק ההפעלה בשכבה אחת עשויות לקבוע את

90
00:08:29,160 --> 00:08:35,320
ההפעלה בשכבה הבאה. המטרה היא לקבל מנגנון כלשהו שיכול לשלב פיקסלים לקצוות,

91
00:08:35,320 --> 00:08:41,040
או קצוות לתבניות, או דפוסים לספרות. וכדי להגדיל דוגמה אחת מאוד

92
00:08:41,040 --> 00:08:47,440
ספציפית, נניח שהתקווה היא שנוירון מסוים בשכבה השנייה יקלוט האם לתמונה

93
00:08:47,680 --> 00:08:54,440
יש קצה באזור הזה כאן. השאלה העומדת על הפרק היא אילו פרמטרים צריכים להיות

94
00:08:54,440 --> 00:09:00,440
לרשת? אילו חוגים וכפתורים אתה צריך להיות מסוגל לכוונן כך שיהיה מספיק אקספרסיבי כדי

95
00:09:00,440 --> 00:09:05,880
ללכוד את הדפוס הזה, או כל דפוס פיקסלים אחר, או את הדפוס שכמה קצוות יכולים

96
00:09:05,880 --> 00:09:11,680
ליצור לולאה, ועוד דברים כאלה? ובכן, מה שנעשה זה להקצות משקל לכל

97
00:09:11,680 --> 00:09:17,160
אחד מהקשרים בין הנוירון שלנו לנוירונים מהשכבה הראשונה. המשקולות האלה הן רק

98
00:09:17,160 --> 00:09:23,960
מספרים. לאחר מכן קח את כל ההפעלות הללו מהשכבה הראשונה וחשב את הסכום המשוקלל שלהן

99
00:09:23,960 --> 00:09:30,400
לפי משקלים אלו. אני מוצא שזה מועיל לחשוב על משקלים אלה כמאורגנים לרשת

100
00:09:30,400 --> 00:09:35,200
קטנה משלהם, ואני הולך להשתמש בפיקסלים ירוקים כדי לציין משקלים חיוביים, ובפיקסלים אדומים

101
00:09:35,200 --> 00:09:40,760
כדי לציין משקלים שליליים, כאשר הבהירות של הפיקסל הזה היא קצת תיאור רופף

102
00:09:40,760 --> 00:09:45,880
של ערך המשקל. אם היינו מאפסים את המשקולות הקשורות כמעט לכל הפיקסלים, למעט

103
00:09:45,880 --> 00:09:51,200
כמה משקלים חיוביים באזור זה שאכפת לנו מהם, אז לקחת את הסכום המשוקלל

104
00:09:51,200 --> 00:09:56,360
של כל ערכי הפיקסלים פשוט מסתכם בחיבור של ערכי הפיקסלים רק בתוך האזור

105
00:09:56,360 --> 00:10:02,760
שאכפת לנו ממנו. ואם באמת רצית להבין אם יש כאן יתרון, מה

106
00:10:02,760 --> 00:10:07,960
שאתה יכול לעשות זה כמה משקלים שליליים הקשורים לפיקסלים שמסביב. אז הסכום

107
00:10:08,000 --> 00:10:12,680
הוא הגדול ביותר כאשר הפיקסלים האמצעיים האלה בהירים אבל הפיקסלים שמסביב כהים יותר.

108
00:10:12,680 --> 00:10:19,200
כשאתה מחשב סכום משוקלל כזה, אתה עשוי לצאת עם כל מספר, אבל עבור הרשת הזו מה

109
00:10:19,200 --> 00:10:25,200
שאנחנו רוצים זה שההפעלה תהיה ערך כלשהו בין 0 ל-1. אז דבר נפוץ לעשות הוא

110
00:10:25,200 --> 00:10:30,560
לשאוב את הסכום המשוקלל הזה לאיזו פונקציה שדוחקת את קו המספרים האמיתיים לטווח שבין

111
00:10:30,560 --> 00:10:36,360
0 ל-1. ופונקציה נפוצה שעושה זאת נקראת הפונקציה הסיגמואידית, הידועה גם בתור

112
00:10:36,360 --> 00:10:42,760
עקומה לוגיסטית. בעיקרון תשומות שליליות מאוד מתקרבות ל-0, תשומות חיוביות מאוד מתקרבות ל-1,

113
00:10:42,760 --> 00:10:51,400
והיא רק גדלה בהתמדה סביב הקלט 0. אז ההפעלה של הנוירון כאן היא

114
00:10:51,400 --> 00:10:59,320
בעצם מדד למידת החיוב של הסכום המשוקלל הרלוונטי. אבל אולי זה לא שאתה

115
00:10:59,320 --> 00:11:04,080
רוצה שהנוירון יידלק כשהסכום המשוקלל גדול מ-0. אולי אתה רוצה שזה יהיה פעיל

116
00:11:04,120 --> 00:11:11,520
רק כשהסכום גדול מ-10 נניח. כלומר, אתה רוצה הטיה מסוימת כדי שזה לא יהיה פעיל. מה שנעשה

117
00:11:11,520 --> 00:11:17,560
אז הוא פשוט להוסיף מספר אחר, כמו 10 שלילי, לסכום המשוקלל הזה

118
00:11:17,560 --> 00:11:23,840
לפני שתחבר אותו דרך פונקציית הסיגמואידית. המספר הנוסף הזה נקרא ההטיה. אז

119
00:11:23,840 --> 00:11:29,080
המשקולות אומרות לך איזה דפוס פיקסלים הנוירון הזה בשכבה השנייה קולט, וההטיה אומרת לך

120
00:11:29,120 --> 00:11:34,640
כמה גבוה הסכום המשוקלל צריך להיות לפני שהנוירון יתחיל להיות פעיל בצורה משמעותית.

121
00:11:34,640 --> 00:11:41,760
וזה רק נוירון אחד. כל נוירון אחר בשכבה הזו יתחבר לכל הנוירונים

122
00:11:41,760 --> 00:11:49,080
של 784 פיקסלים מהשכבה הראשונה, ולכל אחד מאותם 784 חיבורים יש משקל

123
00:11:49,080 --> 00:11:55,320
משלו הקשור אליו. כמו כן, לכל אחד יש הטיה מסוימת, מספר אחר שאתה מוסיף על

124
00:11:55,320 --> 00:12:00,600
הסכום המשוקלל לפני שמעיכה אותו עם הסיגמואיד. וזה הרבה לחשוב על זה! עם השכבה הנסתרת הזו

125
00:12:00,600 --> 00:12:09,280
של 16 נוירונים, זה בסך הכל 784 כפול 16 משקלים, יחד עם 16 הטיות. וכל זה

126
00:12:09,280 --> 00:12:13,760
הוא רק החיבורים מהשכבה הראשונה לשניה. לקשרים בין השכבות האחרות יש

127
00:12:13,760 --> 00:12:19,600
גם חבורה של משקלים והטיות הקשורות אליהם. בכל מקרה, לרשת

128
00:12:19,600 --> 00:12:26,680
הזו יש כמעט בדיוק 13,000 משקלים והטיות. 13,000 כפתורים וחוגים שניתן לכוונן

129
00:12:26,680 --> 00:12:32,400
ולסובב כדי לגרום לרשת הזו להתנהג בדרכים שונות. אז כשאנחנו מדברים על למידה,

130
00:12:32,400 --> 00:12:38,440
מה שהכוונה היא לגרום למחשב למצוא הגדרה חוקית עבור כל המספרים הרבים האלה, כך

131
00:12:38,440 --> 00:12:44,400
שהוא יפתור למעשה את הבעיה שעל הפרק. ניסוי מחשבתי אחד שהוא מהנה ומזעזע

132
00:12:44,400 --> 00:12:49,440
בעת ובעונה אחת הוא לדמיין איך יושבים ומגדירים את כל המשקולות וההטיות

133
00:12:49,440 --> 00:12:53,960
האלה ביד, מכוונים בכוונה את המספרים כך שהשכבה השנייה תופסת את הקצוות, השכבה

134
00:12:53,960 --> 00:12:59,680
השלישית תופסת דפוסים, וכו ' אני אישית מוצא את זה מספק ולא

135
00:12:59,680 --> 00:13:04,400
רק להתייחס לרשת כאל קופסה שחורה מוחלטת, כי כשהרשת לא מתפקדת כמו

136
00:13:04,400 --> 00:13:09,040
שאתה צופה, אם בנית קצת מערכת יחסים עם המשמעות של המשקולות וההטיות

137
00:13:09,040 --> 00:13:13,440
האלה. , יש לך מקום התחלה להתנסות כיצד לשנות את המבנה כדי

138
00:13:13,440 --> 00:13:17,680
לשפר. או כשהרשת אכן עובדת, אבל לא מהסיבות שאתה עשוי לצפות, חפירה

139
00:13:17,680 --> 00:13:22,760
במה שהמשקלים וההטיות עושות היא דרך טובה לאתגר את ההנחות שלך ובאמת

140
00:13:22,760 --> 00:13:28,560
לחשוף את מלוא המרחב של הפתרונות האפשריים. אגב, הפונקציה בפועל כאן קצת

141
00:13:28,560 --> 00:13:34,840
מסורבלת לרשום, אתה לא חושב? אז הרשו לי להראות לכם דרך קומפקטית

142
00:13:34,840 --> 00:13:39,200
יותר מבחינה סימון שבה חיבורים אלה מיוצגים. כך תראה את זה אם תבחר לקרוא

143
00:13:39,200 --> 00:13:45,360
עוד על רשתות עצביות. ארגן את כל ההפעלות משכבה אחת לעמודה בתור וקטור.

144
00:13:45,480 --> 00:13:53,400
לאחר מכן ארגן את כל המשקולות כמטריצה, כאשר כל שורה של המטריצה

145
00:13:53,400 --> 00:13:58,680
הזו מתאימה לחיבורים בין שכבה אחת לנוירון מסוים בשכבה הבאה. מה שזה

146
00:13:58,680 --> 00:14:03,360
אומר הוא שלקיחת הסכום המשוקלל של ההפעלה בשכבה הראשונה לפי משקלים אלו

147
00:14:03,360 --> 00:14:08,880
מתאימה לאחד המונחים במכפלת הווקטור המטריצה של כל מה שיש לנו כאן

148
00:14:08,880 --> 00:14:17,840
משמאל. אגב, כל כך הרבה מלמידת מכונה מסתכמת רק בהבנה טובה של אלגברה לינארית,

149
00:14:17,840 --> 00:14:23,000
אז לכל אחד מכם שרוצה הבנה ויזואלית יפה של מטריצות ומה המשמעות של כפל

150
00:14:23,000 --> 00:14:29,320
וקטור מטריצה, תסתכל על הסדרה שעשיתי עליה אלגברה לינארית, במיוחד פרק 3. בחזרה

151
00:14:29,320 --> 00:14:34,200
לביטוי שלנו, במקום לדבר על הוספת ההטיה לכל אחד מהערכים הללו באופן עצמאי,

152
00:14:34,200 --> 00:14:40,440
אנו מייצגים אותו על ידי ארגון כל ההטיות הללו לווקטור, והוספת הווקטור כולו

153
00:14:40,440 --> 00:14:47,240
לתוצר הווקטור המטריצה הקודם. ואז כשלב אחרון, אעטוף סיגמואיד סביב החיצוני כאן, ומה

154
00:14:47,240 --> 00:14:51,480
שזה אמור לייצג זה שאתה הולך להחיל את פונקציית הסיגמואיד על כל

155
00:14:51,480 --> 00:14:58,120
רכיב ספציפי של הווקטור שנוצר בפנים. אז ברגע שאתה כותב את מטריצת

156
00:14:58,120 --> 00:15:03,320
המשקל הזו והווקטורים האלה כסמלים משלהם, אתה יכול לתקשר את המעבר המלא של

157
00:15:03,480 --> 00:15:08,840
הפעלות משכבה אחת לאחרת בביטוי קטן ומסודר במיוחד, וזה הופך את הקוד הרלוונטי

158
00:15:08,840 --> 00:15:14,600
להרבה יותר פשוט וגם הרבה יותר מהר, מכיוון שספריות רבות מייעלות את כפל

159
00:15:14,600 --> 00:15:21,400
המטריצה לעזאזל. זוכרים איך קודם לכן אמרתי שהנוירונים האלה הם פשוט דברים שמכילים מספרים?

160
00:15:22,120 --> 00:15:26,280
ובכן, כמובן שהמספרים הספציפיים שהם מחזיקים תלויים בתמונה שבה אתה ניזון, כך

161
00:15:28,120 --> 00:15:31,960
שלמעשה נכון יותר לחשוב על כל נוירון כפונקציה, כזו שמקבלת את

162
00:15:31,960 --> 00:15:37,240
הפלטים של כל הנוירונים בשכבה הקודמת, ויורקת החוצה מספר בין 0

163
00:15:37,240 --> 00:15:43,800
ל-1. באמת שכל הרשת היא רק פונקציה, כזו שמקבלת 784

164
00:15:43,800 --> 00:15:49,720
מספרים כקלט ויורקת 10 מספרים כפלט. זוהי פונקציה מסובכת בצורה אבסורדית,

165
00:15:49,720 --> 00:15:54,520
כזו שכוללת 13,000 פרמטרים בצורות של משקלים והטיות אלו הקולטות על

166
00:15:54,520 --> 00:15:59,000
דפוסים מסוימים, ואשר כוללת איטרציה של מוצרים וקטורים מטריצות רבים ופונקציית

167
00:15:59,000 --> 00:16:04,760
ה-squishification הסיגמואידית, אבל בכל זאת זו רק פונקציה. ובמובן מסוים זה קצת

168
00:16:04,760 --> 00:16:09,720
מרגיע שזה נראה מסובך. כלומר אם זה היה פשוט יותר, איזו תקווה הייתה

169
00:16:09,720 --> 00:16:14,920
לנו שזה יכול לעמוד באתגר של זיהוי ספרות? ואיך זה מתמודד עם האתגר הזה?

170
00:16:14,920 --> 00:16:19,320
איך הרשת הזו לומדת את המשקולות וההטיות המתאימים רק על ידי התבוננות בנתונים?

171
00:16:19,880 --> 00:16:23,960
ובכן, זה מה שאני אראה בסרטון הבא, ואני גם אחפור קצת יותר במה באמת

172
00:16:23,960 --> 00:16:29,880
הרשת הספציפית הזו עושה. עכשיו זה הנקודה שאני מניח שאני צריך להגיד הירשם

173
00:16:29,880 --> 00:16:34,840
כדי להישאר מעודכן לגבי מתי הסרטון הזה או סרטונים חדשים כלשהם יוצאים, אבל באופן מציאותי

174
00:16:34,840 --> 00:16:39,880
רובכם באמת לא מקבלים התראות מיוטיוב, נכון? אולי יותר בכנות אני צריך להגיד

175
00:16:39,880 --> 00:16:44,920
הירשמו כדי שהרשתות הנוירוניות שעומדות בבסיס אלגוריתם ההמלצה של יוטיוב יהיו מוכנות להאמין

176
00:16:44,920 --> 00:16:49,800
שאתם רוצים לראות תוכן מהערוץ הזה מומלץ לכם. בכל מקרה, תתעדכן לעוד.

177
00:16:50,600 --> 00:16:54,840
תודה רבה לכל מי שתומך בסרטונים האלה ב-Patreon. קצת איחרתי להתקדם בסדרת

178
00:16:54,840 --> 00:16:59,160
ההסתברות בקיץ הזה, אבל אני קופץ אליו בחזרה אחרי הפרויקט הזה, אז

179
00:16:59,160 --> 00:17:05,640
לפטרונים תוכלו לחפש עדכונים שם. כדי לסגור את העניינים כאן יש לי איתי

180
00:17:05,640 --> 00:17:09,880
את לישה לי שעשתה את עבודת הדוקטורט שלה בצד התיאורטי של למידה עמוקה, ועובדת

181
00:17:09,880 --> 00:17:14,520
כיום בחברת הון סיכון בשם Amplify Partners שסיפקה בחביבות חלק מהמימון לסרטון הזה.

182
00:17:15,160 --> 00:17:19,480
אז לישה, דבר אחד שאני חושב שאנחנו צריכים להעלות במהירות הוא הפונקציה הסיגמואידית הזו.

183
00:17:19,480 --> 00:17:23,400
כפי שאני מבין את זה, רשתות מוקדמות משתמשות בזה כדי לדחוס את הסכום המשוקלל הרלוונטי

184
00:17:23,400 --> 00:17:28,200
לתוך המרווח הזה שבין אפס לאחד, אתה יודע שסוג של מונע מהאנלוגיה הביולוגית הזו של

185
00:17:28,200 --> 00:17:33,240
נוירונים שאינם פעילים או פעילים. בְּדִיוּק. אבל מעט יחסית רשתות מודרניות משתמשות יותר

186
00:17:33,240 --> 00:17:37,800
ב-sigmoid. כֵּן. זה סוג של בית ספר ישן נכון? כן, או ליתר דיוק, נראה שהרבה יותר קל

187
00:17:37,800 --> 00:17:43,880
לאמן את רלו. ורלו, רלו מייצג יחידה לינארית מתוקנת? כן, זה סוג כזה

188
00:17:43,880 --> 00:17:50,280
של פונקציה שבה אתה פשוט לוקח מקסימום של אפס ו-a שבו a נתון לפי מה שהסברת

189
00:17:50,280 --> 00:17:56,440
בסרטון. ולדעתי זה היה סוג של מוטיבציה בגלל אנלוגיה ביולוגית

190
00:17:56,440 --> 00:18:03,640
לאופן שבו נוירונים יופעלו או לא. אז אם זה יעבור סף מסוים זה

191
00:18:03,640 --> 00:18:09,080
יהיה פונקציית הזהות, אבל אם לא אז זה פשוט לא היה מופעל אז זה יהיה אפס.

192
00:18:09,080 --> 00:18:13,640
אז זה סוג של פשטנות. השימוש בסיגמואידים לא עזר לאימון או שהיה

193
00:18:13,640 --> 00:18:21,320
קשה מאוד להתאמן בשלב מסוים ואנשים פשוט ניסו relu וזה עבד טוב

194
00:18:21,320 --> 00:18:26,120
מאוד עבור רשתות עצבים עמוקות להפליא. בסדר, תודה לך לישה.

195
00:18:39,080 --> 00:18:40,060
you

