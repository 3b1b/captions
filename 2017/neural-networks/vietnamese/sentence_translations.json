[
 {
  "translatedText": "Đây là số 3.",
  "input": "This is a 3.",
  "model": "google_nmt",
  "time_range": [
   4.22,
   5.4
  ]
 },
 {
  "translatedText": "Nó được viết và hiển thị một cách cẩu thả ở độ phân giải cực thấp 28x28 pixel, nhưng bộ não của bạn không gặp khó khăn gì khi nhận ra nó là số 3.",
  "input": "It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3.",
  "model": "google_nmt",
  "time_range": [
   6.06,
   13.72
  ]
 },
 {
  "translatedText": "Và tôi muốn bạn dành một chút thời gian để đánh giá cao việc bộ não có thể làm điều này một cách dễ dàng đến mức nào.",
  "input": "And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly.",
  "model": "google_nmt",
  "time_range": [
   14.34,
   18.96
  ]
 },
 {
  "translatedText": "Ý tôi là, cái này, cái này và cái này cũng có thể được nhận dạng là 3 giây, mặc dù giá trị cụ thể của từng pixel rất khác nhau giữa các hình ảnh tiếp theo.",
  "input": "I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next.",
  "model": "google_nmt",
  "time_range": [
   19.7,
   28.32
  ]
 },
 {
  "translatedText": "Các tế bào nhạy cảm với ánh sáng cụ thể trong mắt bạn đang hoạt động khi bạn nhìn thấy 3 cái này rất khác với các tế bào đang hoạt động khi bạn nhìn thấy cái này 3.",
  "input": "The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3.",
  "model": "google_nmt",
  "time_range": [
   28.9,
   36.94
  ]
 },
 {
  "translatedText": "Nhưng có điều gì đó trong vỏ não thị giác cực kỳ thông minh của bạn phân giải những điều này như thể hiện cùng một ý tưởng, đồng thời nhận ra những hình ảnh khác là ý tưởng riêng biệt của chúng.",
  "input": "But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas.",
  "model": "google_nmt",
  "time_range": [
   37.52,
   48.26
  ]
 },
 {
  "translatedText": "Nhưng nếu tôi nói với bạn, này, hãy ngồi xuống và viết cho tôi một chương trình lấy một lưới 28x28 pixel như thế này và xuất ra một số duy nhất trong khoảng từ 0 đến 10, cho bạn biết nó nghĩ chữ số đó là gì, thì nhiệm vụ sẽ bắt đầu từ hài hước tầm thường đến khó khăn đến khó khăn.",
  "input": "But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult.",
  "model": "google_nmt",
  "time_range": [
   49.22,
   66.18
  ]
 },
 {
  "translatedText": "Trừ khi bạn đang sống dưới một tảng đá, tôi nghĩ tôi hầu như không cần phải thúc đẩy sự liên quan và tầm quan trọng của học máy và mạng lưới thần kinh đối với hiện tại và tương lai.",
  "input": "Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future.",
  "model": "google_nmt",
  "time_range": [
   67.16,
   74.64
  ]
 },
 {
  "translatedText": "Nhưng điều tôi muốn làm ở đây là cho bạn thấy mạng lưới thần kinh thực sự là gì, giả sử không có kiến thức nền tảng, và giúp hình dung những gì nó đang làm, không phải như một từ thông dụng mà như một phần toán học.",
  "input": "But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math.",
  "model": "google_nmt",
  "time_range": [
   75.12,
   84.46
  ]
 },
 {
  "translatedText": "Tôi hy vọng rằng bạn sẽ cảm thấy như chính cấu trúc đó đã được thúc đẩy và cảm thấy như bạn biết ý nghĩa của nó khi đọc hoặc bạn nghe về một phương pháp học tập trích dẫn-không trích dẫn trên mạng lưới thần kinh.",
  "input": "My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning.",
  "model": "google_nmt",
  "time_range": [
   85.02,
   94.34
  ]
 },
 {
  "translatedText": "Video này sẽ chỉ dành cho thành phần cấu trúc của nó và video sau sẽ đề cập đến việc học.",
  "input": "This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning.",
  "model": "google_nmt",
  "time_range": [
   95.36,
   100.26
  ]
 },
 {
  "translatedText": "Những gì chúng ta sắp làm là tập hợp một mạng lưới thần kinh có thể học cách nhận dạng các chữ số viết tay.",
  "input": "What we're going to do is put together a neural network that can learn to recognize handwritten digits.",
  "model": "google_nmt",
  "time_range": [
   100.96,
   106.04
  ]
 },
 {
  "translatedText": "Đây là một ví dụ khá cổ điển để giới thiệu chủ đề và tôi rất vui được giữ nguyên hiện trạng ở đây vì ở cuối hai video tôi muốn chỉ cho bạn một số tài nguyên hữu ích để bạn có thể tìm hiểu thêm và tìm hiểu thêm ở đâu. bạn có thể tải xuống mã thực hiện việc này và chơi với nó trên máy tính của riêng bạn.",
  "input": "This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer.",
  "model": "google_nmt",
  "time_range": [
   109.36,
   123.08
  ]
 },
 {
  "translatedText": "Có rất nhiều biến thể của mạng lưới thần kinh và trong những năm gần đây đã có sự bùng nổ trong nghiên cứu về các biến thể này, nhưng trong hai video giới thiệu này, bạn và tôi sẽ chỉ xem xét dạng vani đơn giản nhất, không rườm rà.",
  "input": "There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills.",
  "model": "google_nmt",
  "time_range": [
   125.04,
   139.18
  ]
 },
 {
  "translatedText": "Đây là điều kiện tiên quyết cần thiết để hiểu bất kỳ biến thể hiện đại mạnh mẽ nào và tin tôi đi, nó vẫn còn rất nhiều điều phức tạp để chúng ta phải suy nghĩ.",
  "input": "This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around.",
  "model": "google_nmt",
  "time_range": [
   139.86,
   148.6
  ]
 },
 {
  "translatedText": "Nhưng ngay cả ở dạng đơn giản nhất này, nó vẫn có thể học cách nhận dạng các chữ số viết tay, đây là một điều khá thú vị đối với máy tính.",
  "input": "But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do.",
  "model": "google_nmt",
  "time_range": [
   149.12,
   156.52
  ]
 },
 {
  "translatedText": "Và đồng thời, bạn sẽ thấy nó không còn như thế nào với một vài hy vọng mà chúng ta có thể đặt ra cho nó.",
  "input": "And at the same time you'll see how it does fall short of a couple hopes that we might have for it.",
  "model": "google_nmt",
  "time_range": [
   157.48,
   162.28
  ]
 },
 {
  "translatedText": "Đúng như tên gọi, mạng lưới thần kinh được lấy cảm hứng từ bộ não, nhưng hãy chia nhỏ nó ra.",
  "input": "As the name suggests neural networks are inspired by the brain, but let's break that down.",
  "model": "google_nmt",
  "time_range": [
   163.38,
   168.5
  ]
 },
 {
  "translatedText": "Tế bào thần kinh là gì và chúng liên kết với nhau theo nghĩa nào?",
  "input": "What are the neurons, and in what sense are they linked together?",
  "model": "google_nmt",
  "time_range": [
   168.52,
   171.66
  ]
 },
 {
  "translatedText": "Ngay bây giờ khi tôi nói đến nơ-ron, tất cả những gì tôi muốn bạn nghĩ đến là một thứ chứa một số, cụ thể là một số từ 0 đến 1.",
  "input": "Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   172.5,
   180.44
  ]
 },
 {
  "translatedText": "Nó thực sự không nhiều hơn thế.",
  "input": "It's really not more than that.",
  "model": "google_nmt",
  "time_range": [
   180.68,
   182.56
  ]
 },
 {
  "translatedText": "Ví dụ: mạng bắt đầu với một loạt các nơ-ron tương ứng với mỗi pixel trong số 28x28 pixel của hình ảnh đầu vào, tổng cộng có 784 nơ-ron.",
  "input": "For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total.",
  "model": "google_nmt",
  "time_range": [
   183.78,
   194.22
  ]
 },
 {
  "translatedText": "Mỗi cái chứa một số đại diện cho giá trị thang độ xám của pixel tương ứng, từ 0 cho pixel đen đến 1 cho pixel trắng.",
  "input": "Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels.",
  "model": "google_nmt",
  "time_range": [
   194.7,
   204.38
  ]
 },
 {
  "translatedText": "Con số này bên trong nơ-ron được gọi là kích hoạt của nó, và hình ảnh mà bạn có thể nghĩ đến ở đây là mỗi nơ-ron sẽ sáng lên khi kích hoạt của nó là một số cao.",
  "input": "This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number.",
  "model": "google_nmt",
  "time_range": [
   205.3,
   214.16
  ]
 },
 {
  "translatedText": "Vậy tất cả 784 nơ-ron này tạo thành lớp đầu tiên trong mạng lưới của chúng ta.",
  "input": "So all of these 784 neurons make up the first layer of our network.",
  "model": "google_nmt",
  "time_range": [
   216.72,
   221.86
  ]
 },
 {
  "translatedText": "Bây giờ chuyển sang lớp cuối cùng, lớp này có 10 nơ-ron, mỗi nơ-ron đại diện cho một chữ số.",
  "input": "Now jumping over to the last layer, this has 10 neurons, each representing one of the digits.",
  "model": "google_nmt",
  "time_range": [
   226.5,
   231.36
  ]
 },
 {
  "translatedText": "Sự kích hoạt trong các nơ-ron này, cũng là một số nằm trong khoảng từ 0 đến 1, thể hiện mức độ hệ thống cho rằng một hình ảnh nhất định tương ứng với một chữ số nhất định.",
  "input": "The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit.",
  "model": "google_nmt",
  "time_range": [
   232.04,
   242.12
  ]
 },
 {
  "translatedText": "Ngoài ra còn có một vài lớp ở giữa được gọi là lớp ẩn, hiện tại chỉ là một dấu hỏi khổng lồ về việc quá trình nhận dạng chữ số này sẽ được xử lý như thế nào.",
  "input": "There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled.",
  "model": "google_nmt",
  "time_range": [
   243.04,
   253.6
  ]
 },
 {
  "translatedText": "Trong mạng này, tôi đã chọn hai lớp ẩn, mỗi lớp có 16 nơ-ron và phải thừa nhận rằng đó là một lựa chọn tùy ý.",
  "input": "In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice.",
  "model": "google_nmt",
  "time_range": [
   254.26,
   260.56
  ]
 },
 {
  "translatedText": "Thành thật mà nói, tôi đã chọn hai lớp dựa trên cách tôi muốn thúc đẩy cấu trúc chỉ trong giây lát và 16, đó chỉ là một con số đẹp để vừa với màn hình.",
  "input": "To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen.",
  "model": "google_nmt",
  "time_range": [
   261.02,
   268.2
  ]
 },
 {
  "translatedText": "Trong thực tế, có rất nhiều chỗ để thử nghiệm một cấu trúc cụ thể ở đây.",
  "input": "In practice there is a lot of room for experiment with a specific structure here.",
  "model": "google_nmt",
  "time_range": [
   268.78,
   272.34
  ]
 },
 {
  "translatedText": "Cách thức hoạt động của mạng, kích hoạt trong một lớp sẽ xác định kích hoạt của lớp tiếp theo.",
  "input": "The way the network operates, activations in one layer determine the activations of the next layer.",
  "model": "google_nmt",
  "time_range": [
   273.02,
   278.48
  ]
 },
 {
  "translatedText": "Và tất nhiên, trung tâm của mạng với tư cách là một cơ chế xử lý thông tin phụ thuộc vào cách chính xác những kích hoạt đó từ một lớp sẽ mang lại những kích hoạt ở lớp tiếp theo.",
  "input": "And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer.",
  "model": "google_nmt",
  "time_range": [
   279.2,
   288.58
  ]
 },
 {
  "translatedText": "Nó có ý nghĩa tương tự một cách lỏng lẻo với cách trong mạng lưới sinh học của các nơ-ron, một số nhóm nơ-ron kích hoạt sẽ khiến một số nhóm khác kích hoạt.",
  "input": "It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire.",
  "model": "google_nmt",
  "time_range": [
   289.14,
   297.18
  ]
 },
 {
  "translatedText": "Mạng mà tôi đang trình bày ở đây đã được đào tạo để nhận dạng các chữ số và để tôi cho bạn biết ý tôi khi nói điều đó.",
  "input": "Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that.",
  "model": "google_nmt",
  "time_range": [
   298.12,
   303.4
  ]
 },
 {
  "translatedText": "Điều đó có nghĩa là nếu bạn đưa vào một hình ảnh, chiếu sáng tất cả 784 nơ-ron của lớp đầu vào theo độ sáng của từng pixel trong hình ảnh, thì kiểu kích hoạt đó sẽ gây ra một số kiểu rất cụ thể ở lớp tiếp theo, tạo ra một số kiểu ở lớp tiếp theo. nó, cuối cùng nó đưa ra một số mẫu trong lớp đầu ra.",
  "input": "It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer.",
  "model": "google_nmt",
  "time_range": [
   303.64,
   322.08
  ]
 },
 {
  "translatedText": "Và nơ-ron sáng nhất của lớp đầu ra đó là sự lựa chọn của mạng, có thể nói, đối với chữ số mà hình ảnh này đại diện.",
  "input": "And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents.",
  "model": "google_nmt",
  "time_range": [
   322.56,
   329.4
  ]
 },
 {
  "translatedText": "Và trước khi chuyển sang tính toán xem lớp này ảnh hưởng như thế nào đến lớp tiếp theo hoặc cách hoạt động của quá trình đào tạo, chúng ta hãy nói về lý do tại sao việc mong đợi một cấu trúc lớp như thế này hoạt động thông minh là điều hợp lý.",
  "input": "And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently.",
  "model": "google_nmt",
  "time_range": [
   332.56,
   343.52
  ]
 },
 {
  "translatedText": "Chúng ta đang mong đợi điều gì ở đây?",
  "input": "What are we expecting here?",
  "model": "google_nmt",
  "time_range": [
   344.06,
   345.22
  ]
 },
 {
  "translatedText": "Hy vọng tốt nhất cho những lớp giữa đó là gì?",
  "input": "What is the best hope for those middle layers?",
  "model": "google_nmt",
  "time_range": [
   345.4,
   347.6
  ]
 },
 {
  "translatedText": "Chà, khi bạn hoặc tôi nhận ra các chữ số, chúng ta ghép các thành phần khác nhau lại với nhau.",
  "input": "Well, when you or I recognize digits, we piece together various components.",
  "model": "google_nmt",
  "time_range": [
   348.92,
   353.52
  ]
 },
 {
  "translatedText": "Số 9 có một vòng ở trên và một đường ở bên phải.",
  "input": "A 9 has a loop up top and a line on the right.",
  "model": "google_nmt",
  "time_range": [
   354.2,
   356.82
  ]
 },
 {
  "translatedText": "Số 8 cũng có một vòng lặp ở trên, nhưng nó được ghép với một vòng khác ở phía dưới.",
  "input": "An 8 also has a loop up top, but it's paired with another loop down low.",
  "model": "google_nmt",
  "time_range": [
   357.38,
   361.18
  ]
 },
 {
  "translatedText": "Về cơ bản, số 4 được chia thành ba dòng cụ thể và những thứ tương tự.",
  "input": "A 4 basically breaks down into three specific lines, and things like that.",
  "model": "google_nmt",
  "time_range": [
   361.98,
   366.82
  ]
 },
 {
  "translatedText": "Bây giờ, trong một thế giới hoàn hảo, chúng ta có thể hy vọng rằng mỗi nơ-ron ở lớp thứ hai đến lớp cuối cùng tương ứng với một trong các thành phần phụ này, rằng bất cứ khi nào bạn đưa vào một hình ảnh với một vòng lặp lên trên, chẳng hạn như số 9 hoặc số 8, sẽ có một số nơ-ron cụ thể có mức kích hoạt sẽ gần bằng 1.",
  "input": "Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1.",
  "model": "google_nmt",
  "time_range": [
   367.6,
   383.78
  ]
 },
 {
  "translatedText": "Và ý tôi không phải là vòng lặp pixel cụ thể này, hy vọng là bất kỳ mô hình lặp nói chung nào về phía trên sẽ kích hoạt nơ-ron này.",
  "input": "And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron.",
  "model": "google_nmt",
  "time_range": [
   384.5,
   391.56
  ]
 },
 {
  "translatedText": "Bằng cách đó, đi từ lớp thứ ba đến lớp cuối cùng chỉ cần tìm hiểu sự kết hợp của các thành phần phụ tương ứng với chữ số nào.",
  "input": "That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits.",
  "model": "google_nmt",
  "time_range": [
   392.44,
   400.04
  ]
 },
 {
  "translatedText": "Tất nhiên, điều đó chỉ giải quyết được vấn đề vì làm thế nào bạn có thể nhận ra những thành phần phụ này hoặc thậm chí tìm hiểu xem những thành phần phụ phù hợp phải là gì?",
  "input": "Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be?",
  "model": "google_nmt",
  "time_range": [
   401.0,
   407.64
  ]
 },
 {
  "translatedText": "Và tôi thậm chí còn chưa nói về việc một lớp ảnh hưởng đến lớp tiếp theo như thế nào, nhưng hãy cùng tôi nói về lớp này một lát.",
  "input": "And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment.",
  "model": "google_nmt",
  "time_range": [
   408.06,
   413.06
  ]
 },
 {
  "translatedText": "Nhận biết một vòng lặp cũng có thể chia thành các bài toán con.",
  "input": "Recognizing a loop can also break down into subproblems.",
  "model": "google_nmt",
  "time_range": [
   413.68,
   416.68
  ]
 },
 {
  "translatedText": "Một cách hợp lý để làm điều này là trước tiên hãy nhận ra các cạnh nhỏ khác nhau tạo nên nó.",
  "input": "One reasonable way to do this would be to first recognize the various little edges that make it up.",
  "model": "google_nmt",
  "time_range": [
   417.28,
   422.78
  ]
 },
 {
  "translatedText": "Tương tự, một đường dài, giống như loại bạn có thể thấy ở các chữ số 1, 4 hoặc 7, thực sự chỉ là một cạnh dài, hoặc có thể bạn nghĩ nó như một mẫu nhất định của một số cạnh nhỏ hơn.",
  "input": "Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges.",
  "model": "google_nmt",
  "time_range": [
   423.78,
   434.32
  ]
 },
 {
  "translatedText": "Vì vậy, có lẽ chúng ta hy vọng rằng mỗi nơ-ron ở lớp thứ hai của mạng tương ứng với các cạnh nhỏ có liên quan khác nhau.",
  "input": "So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges.",
  "model": "google_nmt",
  "time_range": [
   435.14,
   442.72
  ]
 },
 {
  "translatedText": "Có thể khi một hình ảnh như thế này xuất hiện, nó sẽ chiếu sáng tất cả các nơ-ron liên kết với khoảng 8 đến 10 cạnh nhỏ cụ thể, từ đó làm sáng các nơ-ron liên kết với vòng trên và một đường thẳng đứng dài, và những nơ-ron đó sẽ sáng lên nơ-ron liên kết với số 9.",
  "input": "Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9.",
  "model": "google_nmt",
  "time_range": [
   443.54,
   459.72
  ]
 },
 {
  "translatedText": "Liệu đây có phải là điều mà mạng cuối cùng của chúng ta thực sự làm hay không lại là một câu hỏi khác, câu hỏi mà tôi sẽ quay lại khi chúng ta biết cách huấn luyện mạng, nhưng đây là niềm hy vọng mà chúng ta có thể có, một loại mục tiêu với cấu trúc phân lớp như thế này.",
  "input": "Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this.",
  "model": "google_nmt",
  "time_range": [
   460.68,
   472.54
  ]
 },
 {
  "translatedText": "Hơn nữa, bạn có thể tưởng tượng việc phát hiện các cạnh và mẫu như thế này sẽ thực sự hữu ích như thế nào cho các tác vụ nhận dạng hình ảnh khác.",
  "input": "Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks.",
  "model": "google_nmt",
  "time_range": [
   473.16,
   480.3
  ]
 },
 {
  "translatedText": "Và thậm chí ngoài khả năng nhận dạng hình ảnh, có tất cả những thứ thông minh mà bạn có thể muốn thực hiện để chia thành các lớp trừu tượng.",
  "input": "And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction.",
  "model": "google_nmt",
  "time_range": [
   480.88,
   487.28
  ]
 },
 {
  "translatedText": "Ví dụ: phân tích lời nói bao gồm việc lấy âm thanh thô và chọn ra các âm thanh riêng biệt, kết hợp để tạo ra các âm tiết nhất định, kết hợp để tạo thành từ, kết hợp để tạo thành cụm từ và những suy nghĩ trừu tượng hơn, v.v.",
  "input": "Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc.",
  "model": "google_nmt",
  "time_range": [
   488.04,
   500.06
  ]
 },
 {
  "translatedText": "Nhưng quay lại cách thức hoạt động của bất kỳ thứ nào trong số này thực sự hoạt động, hãy hình dung ngay bây giờ chính bạn đang thiết kế cách chính xác các kích hoạt trong một lớp có thể xác định lớp tiếp theo.",
  "input": "But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the next.",
  "model": "google_nmt",
  "time_range": [
   501.1,
   509.92
  ]
 },
 {
  "translatedText": "Mục tiêu là có một số cơ chế có thể kết hợp các pixel thành các cạnh hoặc các cạnh thành các mẫu hoặc các mẫu thành các chữ số một cách hợp lý.",
  "input": "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits.",
  "model": "google_nmt",
  "time_range": [
   510.86,
   518.98
  ]
 },
 {
  "translatedText": "Và để phóng to một ví dụ rất cụ thể, giả sử hy vọng là một nơ-ron cụ thể ở lớp thứ hai sẽ xác định xem hình ảnh có cạnh ở vùng này ở đây hay không.",
  "input": "And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here.",
  "model": "google_nmt",
  "time_range": [
   519.44,
   530.62
  ]
 },
 {
  "translatedText": "Câu hỏi đặt ra là mạng nên có những thông số nào?",
  "input": "The question at hand is what parameters should the network have?",
  "model": "google_nmt",
  "time_range": [
   531.44,
   535.1
  ]
 },
 {
  "translatedText": "Bạn có thể điều chỉnh các mặt số và nút xoay nào sao cho đủ biểu cảm để có thể nắm bắt được mẫu này hoặc bất kỳ mẫu pixel nào khác hoặc mẫu mà một số cạnh có thể tạo thành một vòng lặp và những thứ tương tự khác?",
  "input": "What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things?",
  "model": "google_nmt",
  "time_range": [
   535.64,
   547.78
  ]
 },
 {
  "translatedText": "Chà, những gì chúng ta sẽ làm là gán trọng số cho từng kết nối giữa nơ-ron của chúng ta và các nơ-ron ở lớp đầu tiên.",
  "input": "Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer.",
  "model": "google_nmt",
  "time_range": [
   548.72,
   555.56
  ]
 },
 {
  "translatedText": "Những trọng số này chỉ là những con số.",
  "input": "These weights are just numbers.",
  "model": "google_nmt",
  "time_range": [
   556.32,
   557.7
  ]
 },
 {
  "translatedText": "Sau đó lấy tất cả các kích hoạt đó từ lớp đầu tiên và tính tổng trọng số của chúng theo các trọng số này.",
  "input": "Then take all of those activations from the first layer and compute their weighted sum according to these weights.",
  "model": "google_nmt",
  "time_range": [
   558.54,
   565.5
  ]
 },
 {
  "translatedText": "Tôi thấy hữu ích khi coi các trọng số này được sắp xếp thành một lưới nhỏ của riêng chúng và tôi sẽ sử dụng các pixel màu xanh lá cây để biểu thị các trọng số dương và các pixel màu đỏ để biểu thị các trọng số âm, trong đó độ sáng của pixel đó là một chút mô tả lỏng lẻo về giá trị của trọng lượng.",
  "input": "I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value.",
  "model": "google_nmt",
  "time_range": [
   567.7,
   581.78
  ]
 },
 {
  "translatedText": "Bây giờ, nếu chúng ta đặt các trọng số được liên kết với hầu hết tất cả các pixel bằng 0 ngoại trừ một số trọng số dương trong vùng mà chúng ta quan tâm này, thì việc lấy tổng trọng số của tất cả các giá trị pixel thực sự chỉ bằng việc cộng các giá trị của pixel chỉ trong khu vực mà chúng tôi quan tâm.",
  "input": "Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about.",
  "model": "google_nmt",
  "time_range": [
   582.78,
   597.82
  ]
 },
 {
  "translatedText": "Và nếu bạn thực sự muốn biết liệu có cạnh nào ở đây hay không, điều bạn có thể làm là có một số trọng số âm liên quan đến các pixel xung quanh.",
  "input": "And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels.",
  "model": "google_nmt",
  "time_range": [
   599.14,
   606.6
  ]
 },
 {
  "translatedText": "Khi đó tổng lớn nhất khi các pixel ở giữa đó sáng nhưng các pixel xung quanh tối hơn.",
  "input": "Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker.",
  "model": "google_nmt",
  "time_range": [
   607.48,
   612.7
  ]
 },
 {
  "translatedText": "Khi bạn tính tổng có trọng số như thế này, bạn có thể đưa ra bất kỳ số nào, nhưng đối với mạng này, điều chúng tôi muốn là kích hoạt phải có giá trị nào đó từ 0 đến 1.",
  "input": "When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   614.26,
   623.54
  ]
 },
 {
  "translatedText": "Vì vậy, một điều thông thường cần làm là bơm tổng có trọng số này vào một hàm nào đó để ép trục số thực vào khoảng từ 0 đến 1.",
  "input": "So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   624.12,
   632.14
  ]
 },
 {
  "translatedText": "Và một hàm phổ biến thực hiện điều này được gọi là hàm sigmoid, còn được gọi là đường cong logistic.",
  "input": "And a common function that does this is called the sigmoid function, also known as a logistic curve.",
  "model": "google_nmt",
  "time_range": [
   632.46,
   637.42
  ]
 },
 {
  "translatedText": "Về cơ bản, đầu vào rất âm có giá trị gần bằng 0, đầu vào dương có giá trị gần bằng 1 và chỉ tăng đều đặn xung quanh đầu vào 0.",
  "input": "Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0.",
  "model": "google_nmt",
  "time_range": [
   638.0,
   646.6
  ]
 },
 {
  "translatedText": "Vì vậy, việc kích hoạt nơ-ron ở đây về cơ bản là thước đo mức độ dương của tổng trọng số liên quan.",
  "input": "So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is.",
  "model": "google_nmt",
  "time_range": [
   649.12,
   656.36
  ]
 },
 {
  "translatedText": "Nhưng có lẽ không phải là bạn muốn nơ-ron sáng lên khi tổng trọng số lớn hơn 0.",
  "input": "But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0.",
  "model": "google_nmt",
  "time_range": [
   657.54,
   661.88
  ]
 },
 {
  "translatedText": "Có thể bạn chỉ muốn nó hoạt động khi tổng lớn hơn 10.",
  "input": "Maybe you only want it to be active when the sum is bigger than say 10.",
  "model": "google_nmt",
  "time_range": [
   662.28,
   666.36
  ]
 },
 {
  "translatedText": "Tức là bạn muốn có một số thành kiến để nó không hoạt động.",
  "input": "That is, you want some bias for it to be inactive.",
  "model": "google_nmt",
  "time_range": [
   666.84,
   670.26
  ]
 },
 {
  "translatedText": "Những gì chúng ta sẽ làm sau đó chỉ là thêm một số số khác như âm 10 vào tổng có trọng số này trước khi cắm nó vào hàm sigmoid squishification.",
  "input": "What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function.",
  "model": "google_nmt",
  "time_range": [
   671.38,
   679.66
  ]
 },
 {
  "translatedText": "Con số bổ sung đó được gọi là độ lệch.",
  "input": "That additional number is called the bias.",
  "model": "google_nmt",
  "time_range": [
   680.58,
   682.44
  ]
 },
 {
  "translatedText": "Vì vậy, các trọng số cho bạn biết mô hình pixel mà nơ-ron này ở lớp thứ hai đang chọn và độ lệch cho bạn biết tổng trọng số cần phải cao đến mức nào trước khi nơ-ron bắt đầu hoạt động có ý nghĩa.",
  "input": "So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active.",
  "model": "google_nmt",
  "time_range": [
   683.46,
   695.18
  ]
 },
 {
  "translatedText": "Và đó chỉ là một tế bào thần kinh.",
  "input": "And that is just one neuron.",
  "model": "google_nmt",
  "time_range": [
   696.12,
   697.68
  ]
 },
 {
  "translatedText": "Mọi nơ-ron khác trong lớp này sẽ được kết nối với tất cả các nơ-ron 784 pixel từ lớp đầu tiên và mỗi một trong số 784 kết nối đó có trọng số riêng gắn liền với nó.",
  "input": "Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it.",
  "model": "google_nmt",
  "time_range": [
   698.28,
   710.94
  ]
 },
 {
  "translatedText": "Ngoài ra, mỗi số có một số độ lệch, một số số khác mà bạn cộng vào tổng có trọng số trước khi ép nó bằng sigmoid.",
  "input": "Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid.",
  "model": "google_nmt",
  "time_range": [
   711.6,
   717.6
  ]
 },
 {
  "translatedText": "Và đó là rất nhiều điều để suy nghĩ!",
  "input": "And that's a lot to think about!",
  "model": "google_nmt",
  "time_range": [
   718.11,
   719.54
  ]
 },
 {
  "translatedText": "Với lớp ẩn gồm 16 nơ-ron này, tức là có tổng cộng 784 lần 16 trọng số, cùng với 16 thành kiến.",
  "input": "With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases.",
  "model": "google_nmt",
  "time_range": [
   719.96,
   727.98
  ]
 },
 {
  "translatedText": "Và tất cả những điều đó chỉ là sự kết nối từ lớp thứ nhất đến lớp thứ hai.",
  "input": "And all of that is just the connections from the first layer to the second.",
  "model": "google_nmt",
  "time_range": [
   728.84,
   731.94
  ]
 },
 {
  "translatedText": "Các kết nối giữa các lớp khác cũng có nhiều trọng số và độ lệch liên quan đến chúng.",
  "input": "The connections between the other layers also have a bunch of weights and biases associated with them.",
  "model": "google_nmt",
  "time_range": [
   732.52,
   737.34
  ]
 },
 {
  "translatedText": "Nói chung, mạng này có gần như chính xác tổng cộng 13.000 trọng số và độ lệch.",
  "input": "All said and done, this network has almost exactly 13,000 total weights and biases.",
  "model": "google_nmt",
  "time_range": [
   738.34,
   743.8
  ]
 },
 {
  "translatedText": "13.000 nút bấm và mặt số có thể được điều chỉnh và xoay để làm cho mạng này hoạt động theo những cách khác nhau.",
  "input": "13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways.",
  "model": "google_nmt",
  "time_range": [
   743.8,
   749.96
  ]
 },
 {
  "translatedText": "Vì vậy, khi chúng ta nói về việc học, điều được đề cập đến là làm cho máy tính tìm ra một cài đặt hợp lệ cho tất cả những con số này để nó thực sự giải quyết được vấn đề trước mắt.",
  "input": "So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand.",
  "model": "google_nmt",
  "time_range": [
   751.04,
   761.36
  ]
 },
 {
  "translatedText": "Một thử nghiệm tưởng tượng vừa thú vị vừa hơi đáng sợ là hãy tưởng tượng bạn ngồi xuống và thiết lập tất cả các trọng số và độ lệch này bằng tay, cố tình điều chỉnh các con số để lớp thứ hai chọn các cạnh, lớp thứ ba chọn các mẫu, vân vân.",
  "input": "One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc.",
  "model": "google_nmt",
  "time_range": [
   762.62,
   776.58
  ]
 },
 {
  "translatedText": "Cá nhân tôi thấy điều này thỏa mãn thay vì chỉ coi mạng như một hộp đen hoàn toàn, bởi vì khi mạng không hoạt động theo cách bạn dự đoán, nếu bạn đã xây dựng được một chút mối quan hệ với ý nghĩa thực sự của những trọng số và thành kiến đó. , bạn có điểm khởi đầu để thử nghiệm cách thay đổi cấu trúc để cải thiện.",
  "input": "I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve.",
  "model": "google_nmt",
  "time_range": [
   776.98,
   794.18
  ]
 },
 {
  "translatedText": "Hoặc khi mạng hoạt động nhưng không phải vì những lý do bạn có thể mong đợi, việc tìm hiểu xem trọng số và thành kiến đang làm gì là một cách hay để thách thức các giả định của bạn và thực sự khám phá toàn bộ không gian của các giải pháp khả thi.",
  "input": "Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions.",
  "model": "google_nmt",
  "time_range": [
   794.96,
   805.82
  ]
 },
 {
  "translatedText": "Nhân tiện, chức năng thực tế ở đây hơi phức tạp khi viết ra, bạn có nghĩ vậy không?",
  "input": "By the way, the actual function here is a little cumbersome to write down, don't you think?",
  "model": "google_nmt",
  "time_range": [
   806.84,
   810.68
  ]
 },
 {
  "translatedText": "Vì vậy, hãy để tôi chỉ cho bạn một cách biểu diễn các kết nối này một cách nhỏ gọn hơn.",
  "input": "So let me show you a more notationally compact way that these connections are represented.",
  "model": "google_nmt",
  "time_range": [
   812.5,
   817.14
  ]
 },
 {
  "translatedText": "Đây là cách bạn sẽ thấy nếu bạn chọn đọc thêm về mạng lưới thần kinh.",
  "input": "This is how you'd see it if you choose to read up more about neural networks.",
  "model": "google_nmt",
  "time_range": [
   817.66,
   820.52
  ]
 },
 {
  "translatedText": "Sắp xếp tất cả các kích hoạt từ một lớp vào một cột dưới dạng ma trận tương ứng với các kết nối giữa một lớp và một nơ-ron cụ thể ở lớp tiếp theo.",
  "input": "Organize all of the activations from one layer into a column as a matrix corresponds to the connections between one layer and a particular neuron in the next layer.",
  "model": "google_nmt",
  "time_range": [
   821.38,
   838.0
  ]
 },
 {
  "translatedText": "Điều đó có nghĩa là việc lấy tổng có trọng số của các lần kích hoạt trong lớp đầu tiên theo các trọng số này tương ứng với một trong các số hạng trong tích vectơ ma trận của mọi thứ chúng ta có ở bên trái ở đây.",
  "input": "What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here.",
  "model": "google_nmt",
  "time_range": [
   838.54,
   849.88
  ]
 },
 {
  "translatedText": "Nhân tiện, phần lớn việc học máy đều phụ thuộc vào việc nắm bắt tốt đại số tuyến tính, vì vậy đối với bất kỳ ai trong số các bạn muốn hiểu rõ về ma trận và ý nghĩa của phép nhân vectơ ma trận, hãy xem loạt bài tôi đã thực hiện trên đại số tuyến tính, đặc biệt là chương 3.",
  "input": "By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3.",
  "model": "google_nmt",
  "time_range": [
   854.0,
   868.6
  ]
 },
 {
  "translatedText": "Quay lại biểu thức của chúng ta, thay vì nói về việc thêm độ lệch cho từng giá trị này một cách độc lập, chúng ta biểu diễn nó bằng cách tổ chức tất cả các độ lệch đó thành một vectơ và thêm toàn bộ vectơ vào tích vectơ ma trận trước đó.",
  "input": "Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product.",
  "model": "google_nmt",
  "time_range": [
   869.24,
   882.3
  ]
 },
 {
  "translatedText": "Sau đó, bước cuối cùng, tôi sẽ bọc một sigmoid xung quanh bên ngoài ở đây và điều được cho là thể hiện rằng bạn sẽ áp dụng hàm sigmoid cho từng thành phần cụ thể của vectơ kết quả bên trong.",
  "input": "Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside.",
  "model": "google_nmt",
  "time_range": [
   883.28,
   894.74
  ]
 },
 {
  "translatedText": "Vì vậy, khi bạn viết ma trận trọng số này và các vectơ này làm ký hiệu riêng, bạn có thể truyền đạt toàn bộ quá trình chuyển đổi kích hoạt từ lớp này sang lớp tiếp theo bằng một biểu thức cực kỳ chặt chẽ và gọn gàng, và điều này làm cho mã liên quan trở nên đơn giản hơn rất nhiều và nhanh hơn rất nhiều, vì nhiều thư viện đã tối ưu hóa phép nhân ma trận.",
  "input": "So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication.",
  "model": "google_nmt",
  "time_range": [
   895.94,
   915.66
  ]
 },
 {
  "translatedText": "Hãy nhớ trước đó tôi đã nói những tế bào thần kinh này chỉ đơn giản là những thứ chứa đựng những con số?",
  "input": "Remember how earlier I said these neurons are simply things that hold numbers?",
  "model": "google_nmt",
  "time_range": [
   917.82,
   921.46
  ]
 },
 {
  "translatedText": "Tất nhiên, những con số cụ thể mà chúng chứa phụ thuộc vào hình ảnh bạn đưa vào, vì vậy sẽ chính xác hơn khi coi mỗi nơ-ron như một hàm, một hàm nhận đầu ra của tất cả các nơ-ron ở lớp trước và tạo ra một số giữa 0 và 1.",
  "input": "Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1.",
  "model": "google_nmt",
  "time_range": [
   922.22,
   938.34
  ]
 },
 {
  "translatedText": "Thực sự toàn bộ mạng chỉ là một chức năng, một chức năng lấy 784 số làm đầu vào và đưa ra 10 số làm đầu ra.",
  "input": "Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output.",
  "model": "google_nmt",
  "time_range": [
   939.2,
   947.06
  ]
 },
 {
  "translatedText": "Đó là một hàm phức tạp đến mức vô lý, một hàm bao gồm 13.000 tham số dưới dạng các trọng số và độ lệch theo các mẫu nhất định và liên quan đến việc lặp lại nhiều tích vectơ ma trận và hàm nén sigmoid, nhưng dù sao nó cũng chỉ là một hàm, và trong một theo cách đó thì có vẻ yên tâm hơn vì nó trông phức tạp.",
  "input": "It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless, and in a way it's kind of reassuring that it looks complicated.",
  "model": "google_nmt",
  "time_range": [
   947.56,
   966.66
  ]
 },
 {
  "translatedText": "Ý tôi là nếu nó đơn giản hơn chút nữa, chúng ta còn hy vọng gì nữa rằng nó có thể đương đầu với thách thức nhận dạng chữ số?",
  "input": "I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits?",
  "model": "google_nmt",
  "time_range": [
   967.34,
   972.28
  ]
 },
 {
  "translatedText": "Và nó thực hiện thử thách đó như thế nào?",
  "input": "And how does it take on that challenge?",
  "model": "google_nmt",
  "time_range": [
   973.34,
   974.7
  ]
 },
 {
  "translatedText": "Làm cách nào để mạng này tìm hiểu các trọng số và độ lệch thích hợp chỉ bằng cách xem dữ liệu?",
  "input": "How does this network learn the appropriate weights and biases just by looking at data?",
  "model": "google_nmt",
  "time_range": [
   975.08,
   979.36
  ]
 },
 {
  "translatedText": "Đó là những gì tôi sẽ trình bày trong video tiếp theo và tôi cũng sẽ tìm hiểu thêm một chút về hoạt động thực sự của mạng cụ thể mà chúng ta đang thấy này.",
  "input": "Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing.",
  "model": "google_nmt",
  "time_range": [
   980.14,
   986.12
  ]
 },
 {
  "translatedText": "Bây giờ là lúc tôi nghĩ mình nên đăng ký để được thông báo khi có video hoặc bất kỳ video mới nào xuất hiện, nhưng thực tế là hầu hết các bạn không thực sự nhận được thông báo từ YouTube, phải không?",
  "input": "Now is the point I suppose I should say subscribe to stay notified about when video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you?",
  "model": "google_nmt",
  "time_range": [
   987.58,
   997.42
  ]
 },
 {
  "translatedText": "Có lẽ thành thật mà nói hơn, tôi nên nói là đăng ký để các mạng lưới thần kinh làm nền tảng cho thuật toán đề xuất của YouTube có cơ sở tin rằng bạn muốn xem nội dung từ kênh này được đề xuất cho bạn.",
  "input": "Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you.",
  "model": "google_nmt",
  "time_range": [
   998.02,
   1007.88
  ]
 },
 {
  "translatedText": "Dù sao hãy đăng để biết thêm.",
  "input": "Anyway stay posted for more.",
  "model": "google_nmt",
  "time_range": [
   1008.56,
   1009.94
  ]
 },
 {
  "translatedText": "Cảm ơn mọi người rất nhiều vì đã ủng hộ những video này trên Patreon.",
  "input": "Thank you very much to everyone supporting these videos on Patreon.",
  "model": "google_nmt",
  "time_range": [
   1010.76,
   1013.5
  ]
 },
 {
  "translatedText": "Tôi tiến triển hơi chậm trong chuỗi xác suất vào mùa hè này, nhưng tôi sẽ quay lại với nó sau dự án này, vì vậy những khách hàng quen có thể theo dõi các thông tin cập nhật ở đó.",
  "input": "I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there.",
  "model": "google_nmt",
  "time_range": [
   1014.0,
   1021.9
  ]
 },
 {
  "translatedText": "Để kết thúc mọi chuyện ở đây, tôi có Leisha Lee, người đã làm luận án tiến sĩ về mặt lý thuyết của học sâu và hiện đang làm việc tại một công ty đầu tư mạo hiểm tên là Amplify Partners, người đã vui lòng cung cấp một số kinh phí cho video này.",
  "input": "To close things off here I have with me Leisha Lee who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video.",
  "model": "google_nmt",
  "time_range": [
   1023.6,
   1034.62
  ]
 },
 {
  "translatedText": "Vì vậy, Leisha có một điều tôi nghĩ chúng ta nên nhanh chóng đưa ra là hàm sigmoid này.",
  "input": "So Leisha one thing I think we should quickly bring up is this sigmoid function.",
  "model": "google_nmt",
  "time_range": [
   1035.46,
   1039.12
  ]
 },
 {
  "translatedText": "Theo tôi hiểu, các mạng ban đầu sử dụng điều này để gộp tổng trọng số có liên quan vào khoảng giữa 0 và 1, bạn biết đấy, loại được thúc đẩy bởi sự tương tự sinh học này của các tế bào thần kinh không hoạt động hoặc đang hoạt động.",
  "input": "As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active.",
  "model": "google_nmt",
  "time_range": [
   1039.7,
   1049.84
  ]
 },
 {
  "translatedText": "Chính xác.",
  "input": "Exactly.",
  "model": "google_nmt",
  "time_range": [
   1050.28,
   1050.3
  ]
 },
 {
  "translatedText": "Nhưng tương đối ít mạng hiện đại thực sự sử dụng sigmoid nữa.",
  "input": "But relatively few modern networks actually use sigmoid anymore.",
  "model": "google_nmt",
  "time_range": [
   1050.56,
   1054.04
  ]
 },
 {
  "translatedText": "Vâng.",
  "input": "Yeah.",
  "model": "google_nmt",
  "time_range": [
   1054.32,
   1054.32
  ]
 },
 {
  "translatedText": "Đó là loại trường học cũ phải không?",
  "input": "It's kind of old school right?",
  "model": "google_nmt",
  "time_range": [
   1054.44,
   1055.54
  ]
 },
 {
  "translatedText": "Vâng hay đúng hơn là relu có vẻ dễ huấn luyện hơn nhiều.",
  "input": "Yeah or rather relu seems to be much easier to train.",
  "model": "google_nmt",
  "time_range": [
   1055.76,
   1058.98
  ]
 },
 {
  "translatedText": "Và relu là viết tắt của đơn vị tuyến tính chỉnh lưu?",
  "input": "And relu stands for rectified linear unit?",
  "model": "google_nmt",
  "time_range": [
   1059.4,
   1062.34
  ]
 },
 {
  "translatedText": "Đúng, đây là loại chức năng trong đó bạn chỉ lấy giá trị tối đa bằng 0 và trong đó a được đưa ra bởi những gì bạn đang giải thích trong video và điều này được thúc đẩy từ đâu. Tôi nghĩ một phần là do sự tương tự sinh học với cách các tế bào thần kinh sẽ được kích hoạt hay không và vì vậy nếu nó vượt qua một ngưỡng nhất định thì đó sẽ là chức năng nhận dạng nhưng nếu không thì nó sẽ không được kích hoạt nên sẽ bằng 0 nên đó là một sự đơn giản hóa.",
  "input": "Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not and so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification.",
  "model": "google_nmt",
  "time_range": [
   1062.68,
   1090.84
  ]
 },
 {
  "translatedText": "Việc sử dụng sigmoid không giúp ích gì cho việc đào tạo hoặc ở một thời điểm nào đó rất khó đào tạo và mọi người chỉ thử relu và nó tình cờ hoạt động rất tốt đối với các mạng lưới thần kinh cực kỳ sâu này.",
  "input": "Using sigmoids didn't help training or it was very difficult to train at some point and people just tried relu and it happened to work very well for these incredibly deep neural networks.",
  "model": "google_nmt",
  "time_range": [
   1091.16,
   1104.62
  ]
 },
 {
  "translatedText": "Được rồi, cảm ơn Alicia.",
  "input": "All right thank you Alicia.",
  "model": "google_nmt",
  "time_range": [
   1105.1,
   1105.64
  ]
 }
]