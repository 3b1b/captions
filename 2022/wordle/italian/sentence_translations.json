[
 {
  "input": "The game Wurdle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.",
  "model": "nmt",
  "translatedText": "Il gioco Wurdle è diventato piuttosto virale negli ultimi due mesi, e per chi non trascura mai l&#39;opportunità di una lezione di matematica, mi viene in mente che questo gioco costituisce un ottimo esempio centrale in una lezione sulla teoria dell&#39;informazione, e in particolare un argomento noto come entropia.",
  "time_range": [
   0.0,
   13.12
  ]
 },
 {
  "input": "You see, like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.",
  "model": "nmt",
  "translatedText": "Vedete, come molte persone sono stato risucchiato dal puzzle, e come molti programmatori sono stato anche risucchiato nel tentativo di scrivere un algoritmo che potesse svolgere il gioco nel modo più ottimale possibile.",
  "time_range": [
   13.12,
   23.2
  ]
 },
 {
  "input": "And what I thought I'd do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy.",
  "model": "nmt",
  "translatedText": "E quello che ho pensato di fare qui è semplicemente parlarvi del mio processo, e spiegare alcuni dei calcoli che ci sono implicati, dato che l&#39;intero algoritmo è incentrato su questa idea di entropia.",
  "time_range": [
   23.2,
   32.08
  ]
 },
 {
  "input": "First things first, in case you haven't heard of it, what is Wurdle?",
  "model": "nmt",
  "translatedText": "Per prima cosa, nel caso non ne avessi sentito parlare, cos&#39;è Wurdle?",
  "time_range": [
   32.08,
   42.18
  ]
 },
 {
  "input": "And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we're going with this, which is to develop a little algorithm that will basically play the game for us.",
  "model": "nmt",
  "translatedText": "E per prendere due piccioni con una fava mentre analizziamo le regole del gioco, permettetemi anche di anticipare dove stiamo andando, ovvero sviluppare un piccolo algoritmo che sostanzialmente giocherà al posto nostro.",
  "time_range": [
   42.18,
   51.38
  ]
 },
 {
  "input": "Though I haven't done today's Wurdle, this is February 4th, and we'll see how the bot does.",
  "model": "nmt",
  "translatedText": "Anche se non ho fatto il Wurdle di oggi, è il 4 febbraio e vedremo come se la cava il bot.",
  "time_range": [
   51.38,
   55.86
  ]
 },
 {
  "input": "The goal of Wurdle is to guess a mystery five letter word, and you're given six different chances to guess.",
  "model": "nmt",
  "translatedText": "L&#39;obiettivo di Wurdle è indovinare una parola misteriosa di cinque lettere e ti vengono date sei diverse possibilità di indovinare.",
  "time_range": [
   55.86,
   60.86
  ]
 },
 {
  "input": "For example, my Wurdle bot suggests that I start with the guess crane.",
  "model": "nmt",
  "translatedText": "Ad esempio, il mio bot Wurdle mi suggerisce di iniziare con la gru indovinata.",
  "time_range": [
   60.86,
   65.24
  ]
 },
 {
  "input": "Each time that you make a guess, you get some information about how close your guess is to the true answer.",
  "model": "nmt",
  "translatedText": "Ogni volta che fai un&#39;ipotesi, ottieni alcune informazioni su quanto la tua ipotesi è vicina alla risposta vera.",
  "time_range": [
   65.24,
   70.94
  ]
 },
 {
  "input": "Here the grey box is telling me there's no C in the actual answer.",
  "model": "nmt",
  "translatedText": "Qui la casella grigia mi dice che non c&#39;è C nella risposta effettiva.",
  "time_range": [
   70.94,
   74.54
  ]
 },
 {
  "input": "The yellow box is telling me there is an R, but it's not in that position.",
  "model": "nmt",
  "translatedText": "La casella gialla mi dice che c&#39;è una R, ma non è in quella posizione.",
  "time_range": [
   74.54,
   78.34
  ]
 },
 {
  "input": "The green box is telling me that the secret word does have an A, and it's in the third position.",
  "model": "nmt",
  "translatedText": "La casella verde mi dice che la parola segreta ha una A ed è in terza posizione.",
  "time_range": [
   78.34,
   82.82
  ]
 },
 {
  "input": "And then there's no N and there's no E.",
  "model": "nmt",
  "translatedText": "E poi non c&#39;è né N né E.",
  "time_range": [
   82.82,
   84.3
  ]
 },
 {
  "input": "So let me just go in and tell the Wurdle bot that information.",
  "model": "nmt",
  "translatedText": "Quindi lasciami entrare e riferire quell&#39;informazione al bot Wurdle.",
  "time_range": [
   84.3,
   87.42
  ]
 },
 {
  "input": "We started with crane, we got grey, yellow, green, grey, grey.",
  "model": "nmt",
  "translatedText": "Abbiamo iniziato con la gru, siamo diventati grigi, gialli, verdi, grigi, grigi.",
  "time_range": [
   87.42,
   91.5
  ]
 },
 {
  "input": "Don't worry about all the data that it's showing right now, I'll explain that in due time.",
  "model": "nmt",
  "translatedText": "Non preoccuparti per tutti i dati che vengono mostrati in questo momento, te lo spiegherò a tempo debito.",
  "time_range": [
   91.5,
   95.46
  ]
 },
 {
  "input": "But its top suggestion for our second pick is shtick.",
  "model": "nmt",
  "translatedText": "Ma il suo suggerimento principale per la nostra seconda scelta è shtick.",
  "time_range": [
   95.46,
   99.7
  ]
 },
 {
  "input": "And your guess does have to be an actual five letter word, but as you'll see, it's pretty liberal with what it will actually let you guess.",
  "model": "nmt",
  "translatedText": "E la tua ipotesi deve essere una vera parola di cinque lettere, ma come vedrai, è piuttosto liberale con ciò che ti farà effettivamente indovinare.",
  "time_range": [
   99.7,
   105.7
  ]
 },
 {
  "input": "In this case, we try shtick.",
  "model": "nmt",
  "translatedText": "In questo caso, proviamo shtick.",
  "time_range": [
   105.7,
   108.86
  ]
 },
 {
  "input": "And alright, things are looking pretty good.",
  "model": "nmt",
  "translatedText": "E va bene, le cose sembrano piuttosto buone.",
  "time_range": [
   108.86,
   110.26
  ]
 },
 {
  "input": "We hit the S and the H, so we know the first three letters, we know that there's an R.",
  "model": "nmt",
  "translatedText": "Premiamo la S e la H, quindi conosciamo le prime tre lettere, sappiamo che c&#39;è una R.",
  "time_range": [
   110.26,
   114.74
  ]
 },
 {
  "input": "And so it's going to be like S-H-A something R, or S-H-A R something.",
  "model": "nmt",
  "translatedText": "E quindi sarà come SHA qualcosa R, o SHA R qualcosa.",
  "time_range": [
   114.74,
   119.74
  ]
 },
 {
  "input": "And it looks like the Wurdle bot knows that it's down to just two possibilities, either shard or sharp.",
  "model": "nmt",
  "translatedText": "E sembra che il bot Wurdle sappia che ci sono solo due possibilità, shard o sharp.",
  "time_range": [
   119.74,
   125.22
  ]
 },
 {
  "input": "That's kind of a toss up between them at this point, so I guess probably just because it's alphabetical it goes with shard.",
  "model": "nmt",
  "translatedText": "È una specie di scelta tra loro a questo punto, quindi immagino che probabilmente solo perché è in ordine alfabetico va con shard.",
  "time_range": [
   125.22,
   131.26
  ]
 },
 {
  "input": "Which hooray, is the actual answer.",
  "model": "nmt",
  "translatedText": "Evviva, è la vera risposta.",
  "time_range": [
   131.26,
   133.0
  ]
 },
 {
  "input": "So we got it in three.",
  "model": "nmt",
  "translatedText": "Quindi ce l&#39;abbiamo fatta in tre.",
  "time_range": [
   133.0,
   134.66
  ]
 },
 {
  "input": "If you're wondering if that's any good, the way I heard one person phrase it is that with Wurdle four is par and three is birdie.",
  "model": "nmt",
  "translatedText": "Se ti stai chiedendo se va bene, il modo in cui ho sentito dire da una persona è che con Wurdle quattro è il par e tre è birdie.",
  "time_range": [
   134.66,
   140.82
  ]
 },
 {
  "input": "Which I think is a pretty apt analogy.",
  "model": "nmt",
  "translatedText": "Il che penso sia un&#39;analogia piuttosto appropriata.",
  "time_range": [
   140.82,
   142.96
  ]
 },
 {
  "input": "You have to be consistently on your game to be getting four, but it's certainly not crazy.",
  "model": "nmt",
  "translatedText": "Devi essere costantemente in gioco per ottenerne quattro, ma certamente non è pazzesco.",
  "time_range": [
   142.96,
   147.56
  ]
 },
 {
  "input": "But when you get it in three, it just feels great.",
  "model": "nmt",
  "translatedText": "Ma quando lo ottieni in tre, è semplicemente fantastico.",
  "time_range": [
   147.56,
   150.0
  ]
 },
 {
  "input": "So if you're down for it, what I'd like to do here is just talk through my thought process from the beginning for how I approach the Wurdle bot.",
  "model": "nmt",
  "translatedText": "Quindi, se sei d&#39;accordo, quello che vorrei fare qui è semplicemente parlare del mio processo di pensiero dall&#39;inizio su come mi avvicino al bot Wurdle.",
  "time_range": [
   150.0,
   156.6
  ]
 },
 {
  "input": "And like I said, really it's an excuse for an information theory lesson.",
  "model": "nmt",
  "translatedText": "E come ho detto, in realtà è una scusa per una lezione di teoria dell&#39;informazione.",
  "time_range": [
   156.6,
   159.8
  ]
 },
 {
  "input": "The main goal is to explain what is information and what is entropy.",
  "model": "nmt",
  "translatedText": "L’obiettivo principale è spiegare cos’è l’informazione e cos’è l’entropia.",
  "time_range": [
   159.8,
   168.56
  ]
 },
 {
  "input": "My first thought in approaching this was to take a look at the relative frequencies of different letters in the English language.",
  "model": "nmt",
  "translatedText": "Il mio primo pensiero nell&#39;affrontarlo è stato quello di dare un&#39;occhiata alle frequenze relative delle diverse lettere nella lingua inglese.",
  "time_range": [
   168.56,
   173.56
  ]
 },
 {
  "input": "So I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters?",
  "model": "nmt",
  "translatedText": "Quindi ho pensato, ok, esiste un&#39;ipotesi di apertura o una coppia di ipotesi di apertura che coincida con molte di queste lettere più frequenti?",
  "time_range": [
   173.56,
   179.96
  ]
 },
 {
  "input": "And one that I was pretty fond of was doing other followed by nails.",
  "model": "nmt",
  "translatedText": "E uno a cui ero molto affezionato era farne altri seguiti dai chiodi.",
  "time_range": [
   179.96,
   183.78
  ]
 },
 {
  "input": "The thought is that if you hit a letter, you know, you get a green or a yellow, that always feels good.",
  "model": "nmt",
  "translatedText": "L&#39;idea è che se colpisci una lettera, sai, ottieni un verde o un giallo, è sempre una bella sensazione.",
  "time_range": [
   183.78,
   187.98
  ]
 },
 {
  "input": "It feels like you're getting information.",
  "model": "nmt",
  "translatedText": "Sembra che tu stia ricevendo informazioni.",
  "time_range": [
   187.98,
   189.46
  ]
 },
 {
  "input": "But in these cases, even if you don't hit and you always get grays, that's still giving you a lot of information since it's pretty rare to find a word that doesn't have any of these letters.",
  "model": "nmt",
  "translatedText": "Ma in questi casi, anche se non colpisci e ottieni sempre dei grigi, questo ti dà comunque molte informazioni poiché è piuttosto raro trovare una parola che non contenga nessuna di queste lettere.",
  "time_range": [
   189.46,
   197.64
  ]
 },
 {
  "input": "But even still, that doesn't feel super systematic, because for example, it does nothing to consider the order of the letters.",
  "model": "nmt",
  "translatedText": "Ma anche questo non sembra super sistematico, perché, ad esempio, non fa nulla considerare l&#39;ordine delle lettere.",
  "time_range": [
   197.64,
   203.52
  ]
 },
 {
  "input": "Why type nails when I could type snail?",
  "model": "nmt",
  "translatedText": "Perché scrivere chiodi quando potrei scrivere lumaca?",
  "time_range": [
   203.52,
   206.08
  ]
 },
 {
  "input": "Is it better to have that S at the end?",
  "model": "nmt",
  "translatedText": "È meglio avere quella S alla fine?",
  "time_range": [
   206.08,
   207.72
  ]
 },
 {
  "input": "I'm not really sure.",
  "model": "nmt",
  "translatedText": "Non sono veramente sicuro.",
  "time_range": [
   207.72,
   208.72
  ]
 },
 {
  "input": "Now, a friend of mine said that he liked to open with the word weary, which kind of surprised me because it has some uncommon letters in there like the W and the Y.",
  "model": "nmt",
  "translatedText": "Ora, un mio amico ha detto che gli piaceva aprire con la parola stanco, il che mi ha sorpreso perché contiene alcune lettere insolite come la W e la Y.",
  "time_range": [
   208.72,
   217.16
  ]
 },
 {
  "input": "But who knows, maybe that is a better opener.",
  "model": "nmt",
  "translatedText": "Ma chissà, forse è un&#39;apertura migliore.",
  "time_range": [
   217.16,
   219.4
  ]
 },
 {
  "input": "Is there some kind of quantitative score that we can give to judge the quality of a potential guess?",
  "model": "nmt",
  "translatedText": "Esiste una sorta di punteggio quantitativo che possiamo assegnare per giudicare la qualità di una potenziale ipotesi?",
  "time_range": [
   219.4,
   224.92
  ]
 },
 {
  "input": "Now to set up for the way that we're going to rank possible guesses, let's go back and add a little clarity to how exactly the game is set up.",
  "model": "nmt",
  "translatedText": "Ora, per impostare il modo in cui classificheremo le possibili ipotesi, torniamo indietro e aggiungiamo un po&#39; di chiarezza su come è impostato esattamente il gioco.",
  "time_range": [
   224.92,
   231.8
  ]
 },
 {
  "input": "So there's a list of words that it will allow you to enter that are considered valid guesses that's just about 13,000 words long.",
  "model": "nmt",
  "translatedText": "Quindi c&#39;è un elenco di parole che ti permetterà di inserire che sono considerate ipotesi valide che è lungo circa 13.000 parole.",
  "time_range": [
   231.8,
   237.92
  ]
 },
 {
  "input": "But when you look at it, there's a lot of really uncommon things, things like a head or Ali and ARG, the kind of words that bring about family arguments in a game of Scrabble.",
  "model": "nmt",
  "translatedText": "Ma quando lo guardi, ci sono un sacco di cose davvero insolite, cose come una testa o Ali e ARG, il tipo di parole che provocano discussioni familiari in una partita a Scarabeo.",
  "time_range": [
   237.92,
   247.04
  ]
 },
 {
  "input": "But the vibe of the game is that the answer is always going to be a decently common word.",
  "model": "nmt",
  "translatedText": "Ma l&#39;atmosfera del gioco è che la risposta sarà sempre una parola abbastanza comune.",
  "time_range": [
   247.04,
   250.6
  ]
 },
 {
  "input": "And in fact, there's another list of around 2300 words that are the possible answers.",
  "model": "nmt",
  "translatedText": "E infatti c&#39;è un altro elenco di circa 2300 parole che rappresentano le possibili risposte.",
  "time_range": [
   250.6,
   256.08
  ]
 },
 {
  "input": "And this is a human curated list, I think specifically by the game creator's girlfriend, which is kind of fun.",
  "model": "nmt",
  "translatedText": "E questa è una lista curata da persone umane, penso specificamente dalla ragazza del creatore del gioco, il che è piuttosto divertente.",
  "time_range": [
   256.08,
   261.8
  ]
 },
 {
  "input": "But what I would like to do, our challenge for this project is to see if we can write a program solving Wordle that doesn't incorporate previous knowledge about this list.",
  "model": "nmt",
  "translatedText": "Ma quello che mi piacerebbe fare, la nostra sfida per questo progetto è vedere se possiamo scrivere un programma che risolva Wordle che non incorpori le conoscenze precedenti su questo elenco.",
  "time_range": [
   261.8,
   270.72
  ]
 },
 {
  "input": "For one thing, there's plenty of pretty common five letter words that you won't find in that list.",
  "model": "nmt",
  "translatedText": "Per prima cosa, ci sono molte parole di cinque lettere piuttosto comuni che non troverai in quell&#39;elenco.",
  "time_range": [
   270.72,
   275.56
  ]
 },
 {
  "input": "So it would be better to write a program that's a little more resilient and would play Wordle against anyone, not just what happens to be the official website.",
  "model": "nmt",
  "translatedText": "Quindi sarebbe meglio scrivere un programma che sia un po&#39; più resistente e faccia giocare Wordle contro chiunque, non solo contro il sito ufficiale.",
  "time_range": [
   275.56,
   281.96
  ]
 },
 {
  "input": "And also the reason that we know what this list of possible answers is, is because it's visible in the source code.",
  "model": "nmt",
  "translatedText": "E anche il motivo per cui sappiamo qual è questo elenco di possibili risposte è perché è visibile nel codice sorgente.",
  "time_range": [
   281.96,
   287.44
  ]
 },
 {
  "input": "But the way that it's visible in the source code is in the specific order in which answers come up from day to day.",
  "model": "nmt",
  "translatedText": "Ma il modo in cui è visibile nel codice sorgente è nell&#39;ordine specifico in cui le risposte emergono di giorno in giorno.",
  "time_range": [
   287.44,
   292.84
  ]
 },
 {
  "input": "So you could always just look up what tomorrow's answer will be.",
  "model": "nmt",
  "translatedText": "Quindi potresti sempre cercare quale sarà la risposta di domani.",
  "time_range": [
   292.84,
   296.4
  ]
 },
 {
  "input": "So clearly, there's some sense in which using the list is cheating.",
  "model": "nmt",
  "translatedText": "Quindi, chiaramente, in un certo senso usare la lista è un imbroglio.",
  "time_range": [
   296.4,
   299.14
  ]
 },
 {
  "input": "And what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data like relative word frequencies in general to capture this intuition of having a preference for more common words.",
  "model": "nmt",
  "translatedText": "E ciò che rende il puzzle più interessante e una lezione di teoria dell’informazione più ricca è utilizzare invece alcuni dati più universali come le frequenze relative delle parole in generale per catturare questa intuizione di avere una preferenza per parole più comuni.",
  "time_range": [
   299.14,
   311.64
  ]
 },
 {
  "input": "So of these 13,000 possibilities, how should we choose the opening guess?",
  "model": "nmt",
  "translatedText": "Quindi tra queste 13.000 possibilità, come dovremmo scegliere l&#39;ipotesi di apertura?",
  "time_range": [
   311.64,
   316.56
  ]
 },
 {
  "input": "For example, if my friend proposes weary, how should we analyze its quality?",
  "model": "nmt",
  "translatedText": "Ad esempio, se il mio amico propone stanco, come dovremmo analizzarne la qualità?",
  "time_range": [
   316.56,
   319.96
  ]
 },
 {
  "input": "Well, the reason he said he likes that unlikely W is that he likes the long shot nature of just how good it feels if you do hit that W.",
  "model": "nmt",
  "translatedText": "Beh, il motivo per cui ha detto che gli piace quell&#39;improbabile W è che gli piace la natura a lungo termine di quanto sia bello colpire quella W.",
  "time_range": [
   319.96,
   327.88
  ]
 },
 {
  "input": "For example, if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern.",
  "model": "nmt",
  "translatedText": "Ad esempio, se il primo schema rivelato fosse qualcosa del genere, si scopre che ci sono solo 58 parole in questo lessico gigante che corrispondono a quello schema.",
  "time_range": [
   327.88,
   336.08
  ]
 },
 {
  "input": "So that's a huge reduction from 13,000.",
  "model": "nmt",
  "translatedText": "Quindi si tratta di un&#39;enorme riduzione rispetto a 13.000.",
  "time_range": [
   336.08,
   338.9
  ]
 },
 {
  "input": "But the flip side of that, of course, is that it's very uncommon to get a pattern like this.",
  "model": "nmt",
  "translatedText": "Ma il rovescio della medaglia, ovviamente, è che è molto raro ottenere uno schema come questo.",
  "time_range": [
   338.9,
   343.36
  ]
 },
 {
  "input": "Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000.",
  "model": "nmt",
  "translatedText": "Nello specifico, se ogni parola avesse la stessa probabilità di essere la risposta, la probabilità di ottenere questo schema sarebbe 58 diviso per circa 13.000.",
  "time_range": [
   343.36,
   351.68
  ]
 },
 {
  "input": "Of course, they're not equally likely to be answers.",
  "model": "nmt",
  "translatedText": "Naturalmente, non è altrettanto probabile che siano risposte.",
  "time_range": [
   351.68,
   353.88
  ]
 },
 {
  "input": "Most of these are very obscure and even questionable words.",
  "model": "nmt",
  "translatedText": "La maggior parte di queste sono parole molto oscure e persino discutibili.",
  "time_range": [
   353.88,
   356.68
  ]
 },
 {
  "input": "But at least for our first pass at all of this, let's assume that they're all equally likely and then refine that a bit later.",
  "model": "nmt",
  "translatedText": "Ma almeno per il nostro primo passaggio a tutto questo, supponiamo che siano tutti ugualmente probabili e poi perfezioniamo il tutto un po&#39; più tardi.",
  "time_range": [
   356.68,
   362.04
  ]
 },
 {
  "input": "The point is the pattern with a lot of information is by its very nature unlikely to occur.",
  "model": "nmt",
  "translatedText": "Il punto è che un modello con molte informazioni è per sua stessa natura improbabile che si verifichi.",
  "time_range": [
   362.04,
   367.36
  ]
 },
 {
  "input": "In fact, what it means to be informative is that it's unlikely.",
  "model": "nmt",
  "translatedText": "In effetti, ciò che significa essere informativo è che è improbabile.",
  "time_range": [
   367.36,
   371.92
  ]
 },
 {
  "input": "A much more probable pattern to see with this opening would be something like this, where of course there's not a W in it.",
  "model": "nmt",
  "translatedText": "Uno schema molto più probabile da vedere con questa apertura sarebbe qualcosa del genere, dove ovviamente non c&#39;è una W.",
  "time_range": [
   371.92,
   378.36
  ]
 },
 {
  "input": "Maybe there's an E, and maybe there's no A, there's no R, there's no Y.",
  "model": "nmt",
  "translatedText": "Forse c&#39;è una E, e forse non c&#39;è A, non c&#39;è R, non c&#39;è Y.",
  "time_range": [
   378.36,
   382.08
  ]
 },
 {
  "input": "In this case, there are 1400 possible matches.",
  "model": "nmt",
  "translatedText": "In questo caso ci sono 1400 corrispondenze possibili.",
  "time_range": [
   382.08,
   384.64
  ]
 },
 {
  "input": "If all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see.",
  "model": "nmt",
  "translatedText": "Se tutti fossero ugualmente probabili, la probabilità che questo sia lo schema che vedresti sarebbe di circa l’11%.",
  "time_range": [
   384.64,
   390.68
  ]
 },
 {
  "input": "So the most likely outcomes are also the least informative.",
  "model": "nmt",
  "translatedText": "Quindi i risultati più probabili sono anche quelli meno informativi.",
  "time_range": [
   390.68,
   394.32
  ]
 },
 {
  "input": "To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see.",
  "model": "nmt",
  "translatedText": "Per avere una visione più globale, lascia che ti mostri la distribuzione completa delle probabilità in tutti i diversi modelli che potresti vedere.",
  "time_range": [
   394.32,
   402.0
  ]
 },
 {
  "input": "So each bar that you're looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3 to the 5th possibilities, and they're organized from left to right, most common to least common.",
  "model": "nmt",
  "translatedText": "Quindi ogni barra che stai guardando corrisponde a un possibile schema di colori che potrebbe essere rivelato, di cui ci sono da 3 a 5 possibilità, e sono organizzati da sinistra a destra, dal più comune al meno comune.",
  "time_range": [
   402.0,
   412.96
  ]
 },
 {
  "input": "So the most common possibility here is that you get all grays.",
  "model": "nmt",
  "translatedText": "Quindi la possibilità più comune qui è che ottieni tutti i grigi.",
  "time_range": [
   412.96,
   416.2
  ]
 },
 {
  "input": "That happens about 14% of the time.",
  "model": "nmt",
  "translatedText": "Ciò accade circa il 14% delle volte.",
  "time_range": [
   416.2,
   418.8
  ]
 },
 {
  "input": "And what you're hoping for when you make a guess is that you end up somewhere out in this long tail, like over here where there's only 18 possibilities for what matches this pattern that evidently look like this.",
  "model": "nmt",
  "translatedText": "E quello che speri quando fai un&#39;ipotesi è di finire da qualche parte in questa lunga coda, come qui dove ci sono solo 18 possibilità per ciò che corrisponde a questo schema che evidentemente assomiglia a questo.",
  "time_range": [
   418.8,
   429.92
  ]
 },
 {
  "input": "Or if we venture a little farther to the left, you know, maybe we go all the way over here.",
  "model": "nmt",
  "translatedText": "O se ci avventuriamo un po&#39; più a sinistra, forse arriviamo fino a qui.",
  "time_range": [
   429.92,
   434.08
  ]
 },
 {
  "input": "Okay, here's a good puzzle for you.",
  "model": "nmt",
  "translatedText": "Ok, ecco un bel puzzle per te.",
  "time_range": [
   434.08,
   436.56
  ]
 },
 {
  "input": "What are the three words in the English language that start with a W, end with a Y, and have an R somewhere in them?",
  "model": "nmt",
  "translatedText": "Quali sono le tre parole in lingua inglese che iniziano con una W, finiscono con una Y e contengono una R da qualche parte?",
  "time_range": [
   436.56,
   442.04
  ]
 },
 {
  "input": "Turns out, the answers are, let's see, wordy, wormy, and wryly.",
  "model": "nmt",
  "translatedText": "Si scopre che le risposte sono, vediamo, prolisse, verminose e ironiche.",
  "time_range": [
   442.04,
   447.56
  ]
 },
 {
  "input": "So to judge how good this word is overall, we want some kind of measure of the expected amount of information that you're going to get from this distribution.",
  "model": "nmt",
  "translatedText": "Quindi, per giudicare quanto sia buona questa parola nel complesso, vogliamo una sorta di misura della quantità prevista di informazioni che otterrai da questa distribuzione.",
  "time_range": [
   447.56,
   456.36
  ]
 },
 {
  "input": "If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score.",
  "model": "nmt",
  "translatedText": "Se esaminiamo ogni modello e moltiplichiamo la sua probabilità che si verifichi per qualcosa che misura quanto sia informativo, forse possiamo darci un punteggio oggettivo.",
  "time_range": [
   456.36,
   466.0
  ]
 },
 {
  "input": "Now your first instinct for what that something should be might be the number of matches.",
  "model": "nmt",
  "translatedText": "Ora il tuo primo istinto su cosa dovrebbe essere quel qualcosa potrebbe essere il numero di corrispondenze.",
  "time_range": [
   466.0,
   470.28
  ]
 },
 {
  "input": "You want a lower average number of matches.",
  "model": "nmt",
  "translatedText": "Desideri un numero medio di partite inferiore.",
  "time_range": [
   470.28,
   472.96
  ]
 },
 {
  "input": "But instead I'd like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they're actually the answer.",
  "model": "nmt",
  "translatedText": "Ma mi piacerebbe invece usare una misura più universale che spesso attribuiamo alle informazioni, e che sarà più flessibile una volta che avremo una probabilità diversa assegnata a ciascuna di queste 13.000 parole per stabilire se siano o meno effettivamente la risposta.",
  "time_range": [
   472.96,
   490.6
  ]
 },
 {
  "input": "The standard unit of information is the bit, which has a little bit of a funny formula, but it's really intuitive if we just look at examples.",
  "model": "nmt",
  "translatedText": "L&#39;unità di informazione standard è il bit, che ha una formula un po&#39; divertente, ma è davvero intuitiva se guardiamo solo gli esempi.",
  "time_range": [
   490.6,
   497.8
  ]
 },
 {
  "input": "If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information.",
  "model": "nmt",
  "translatedText": "Se hai un&#39;osservazione che dimezza il tuo spazio di possibilità, diciamo che contiene un bit di informazione.",
  "time_range": [
   497.8,
   504.2
  ]
 },
 {
  "input": "In our example, the space of possibilities is all possible words, and it turns out about Half of the five letter words have an S, a little less than that, but about half.",
  "model": "nmt",
  "translatedText": "Nel nostro esempio, lo spazio delle possibilità è composto da tutte le parole possibili, e risulta che circa la metà delle parole di cinque lettere hanno una S, un po&#39; meno, ma circa la metà.",
  "time_range": [
   504.2,
   511.56
  ]
 },
 {
  "input": "So that observation would give you one bit of information.",
  "model": "nmt",
  "translatedText": "Quindi quell&#39;osservazione ti darebbe un po&#39; di informazione.",
  "time_range": [
   511.56,
   515.2
  ]
 },
 {
  "input": "If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information.",
  "model": "nmt",
  "translatedText": "Se invece un fatto nuovo riduce di un fattore quattro quello spazio di possibilità, diciamo che ha due informazioni.",
  "time_range": [
   515.2,
   522.0
  ]
 },
 {
  "input": "For example, it turns out about a quarter of these words have a T.",
  "model": "nmt",
  "translatedText": "Ad esempio, risulta che circa un quarto di queste parole hanno una T.",
  "time_range": [
   522.0,
   525.12
  ]
 },
 {
  "input": "If the observation cuts that space by a factor of eight, we say it's three bits of information, and so on and so forth.",
  "model": "nmt",
  "translatedText": "Se l&#39;osservazione taglia quello spazio di un fattore otto, diciamo che si tratta di tre bit di informazione, e così via.",
  "time_range": [
   525.12,
   530.92
  ]
 },
 {
  "input": "Four bits cuts it into a 16th, five bits cuts it into a 32nd.",
  "model": "nmt",
  "translatedText": "Quattro bit lo tagliano in un sedicesimo, cinque bit lo tagliano in un trentaduesimo.",
  "time_range": [
   530.92,
   535.0
  ]
 },
 {
  "input": "So now you might want to pause and ask yourself, what is the formula for information for the number of bits in terms of the probability of an occurrence?",
  "model": "nmt",
  "translatedText": "Quindi ora potresti voler fermarti e chiederti: qual è la formula per l&#39;informazione sul numero di bit in termini di probabilità di un evento?",
  "time_range": [
   535.0,
   544.52
  ]
 },
 {
  "input": "What we're saying here is that when you take one half to the number of bits, that's the same thing as the probability, which is the same thing as saying two to the power of the number of bits is one over the probability, which rearranges further to saying the information is the log base two of one divided by the probability.",
  "model": "nmt",
  "translatedText": "Quello che stiamo dicendo qui è che quando prendi la metà del numero di bit, è la stessa cosa della probabilità, che è la stessa cosa che dire due alla potenza del numero di bit è uno su probabilità, che riorganizza ulteriormente dicendo che l&#39;informazione è il logaritmo in base due di uno diviso per la probabilità.",
  "time_range": [
   544.52,
   559.68
  ]
 },
 {
  "input": "And sometimes you see this with one more rearrangement still, where the information is the negative log base two of the probability.",
  "model": "nmt",
  "translatedText": "E a volte lo vedi con un&#39;ulteriore riorganizzazione, dove l&#39;informazione è il logaritmo negativo in base due della probabilità.",
  "time_range": [
   559.68,
   565.68
  ]
 },
 {
  "input": "Expressed like this, it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you've cut down your possibilities in half.",
  "model": "nmt",
  "translatedText": "Espresso in questo modo, può sembrare un po&#39; strano ai non iniziati, ma in realtà è solo l&#39;idea molto intuitiva di chiedersi quante volte hai ridotto a metà le tue possibilità.",
  "time_range": [
   565.68,
   575.12
  ]
 },
 {
  "input": "Now if you're wondering, you know, I thought we were just playing a fun word game, why are logarithms entering the picture?",
  "model": "nmt",
  "translatedText": "Ora, se ti stai chiedendo, sai, pensavo stessimo solo facendo un divertente gioco di parole, perché i logaritmi stanno entrando in gioco?",
  "time_range": [
   575.12,
   579.92
  ]
 },
 {
  "input": "One reason this is a nicer unit is it's just a lot easier to talk about very unlikely events, much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.0000095.",
  "model": "nmt",
  "translatedText": "Uno dei motivi per cui questa è un&#39;unità più gradevole è che è molto più facile parlare di eventi molto improbabili, molto più facile dire che un&#39;osservazione ha 20 bit di informazione che dire che la probabilità che si verifichi questo o quell&#39;altro è 0.0000095.",
  "time_range": [
   579.92,
   593.48
  ]
 },
 {
  "input": "But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that information adds together.",
  "model": "nmt",
  "translatedText": "Ma una ragione più sostanziale per cui questa espressione logaritmica si è rivelata un&#39;aggiunta molto utile alla teoria della probabilità è il modo in cui le informazioni si sommano.",
  "time_range": [
   593.48,
   602.0
  ]
 },
 {
  "input": "For example, if one observation gives you two bits of information, cutting your space down by four, and then a second observation like your second guess in Wordle gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information.",
  "model": "nmt",
  "translatedText": "Ad esempio, se un&#39;osservazione ti fornisce due bit di informazione, riducendo il tuo spazio di quattro, e poi una seconda osservazione come la tua seconda ipotesi in Wordle ti dà altri tre bit di informazione, riducendoti ulteriormente di un altro fattore otto, il due insieme ti danno cinque informazioni.",
  "time_range": [
   602.0,
   617.36
  ]
 },
 {
  "input": "In the same way that probabilities like to multiply, information likes to add.",
  "model": "nmt",
  "translatedText": "Allo stesso modo in cui le probabilità amano moltiplicarsi, le informazioni amano sommarsi.",
  "time_range": [
   617.36,
   621.2
  ]
 },
 {
  "input": "So as soon as we're in the realm of something like an expected value, where we're adding a bunch of numbers up, the logs make it a lot nicer to deal with.",
  "model": "nmt",
  "translatedText": "Quindi non appena siamo nel campo di qualcosa come un valore atteso, dove stiamo sommando un sacco di numeri, i log rendono molto più piacevole gestirli.",
  "time_range": [
   621.2,
   628.66
  ]
 },
 {
  "input": "Let's go back to our distribution for Weary and add another little tracker on here, showing us how much information there is for each pattern.",
  "model": "nmt",
  "translatedText": "Torniamo alla nostra distribuzione per Weary e aggiungiamo qui un altro piccolo tracker, che ci mostra quante informazioni ci sono per ogni pattern.",
  "time_range": [
   628.66,
   635.56
  ]
 },
 {
  "input": "The main thing I want you to notice is that the higher the probability as we get to those more likely patterns, the lower the information, the fewer bits you gain.",
  "model": "nmt",
  "translatedText": "La cosa principale che voglio farti notare è che maggiore è la probabilità quando arriviamo a quegli schemi più probabili, minore è l&#39;informazione, meno bit guadagni.",
  "time_range": [
   635.56,
   643.5
  ]
 },
 {
  "input": "The way we measure the quality of this guess will be to take the expected value of this information, where we go through each pattern, we say how probable is it, and then we multiply that by how many bits of information do we get.",
  "model": "nmt",
  "translatedText": "Il modo in cui misuriamo la qualità di questa ipotesi sarà quello di prendere il valore atteso di queste informazioni, esaminare ogni modello, dire quanto è probabile e poi moltiplicarlo per il numero di bit di informazione che otteniamo.",
  "time_range": [
   643.5,
   654.94
  ]
 },
 {
  "input": "And in the example of Weary, that turns out to be 4.9 bits.",
  "model": "nmt",
  "translatedText": "E nell&#39;esempio di Weary, risulta essere 4.9 bit.",
  "time_range": [
   654.94,
   658.48
  ]
 },
 {
  "input": "So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times.",
  "model": "nmt",
  "translatedText": "Quindi, in media, le informazioni che ottieni da questa ipotesi di apertura equivalgono a tagliare a metà il tuo spazio di possibilità circa cinque volte.",
  "time_range": [
   658.48,
   665.66
  ]
 },
 {
  "input": "By contrast, an example of a guess with a higher expected information value would be something like Slate.",
  "model": "nmt",
  "translatedText": "Al contrario, un esempio di ipotesi con un valore informativo atteso più elevato sarebbe qualcosa come Slate.",
  "time_range": [
   665.66,
   673.22
  ]
 },
 {
  "input": "In this case you'll notice the distribution looks a lot flatter.",
  "model": "nmt",
  "translatedText": "In questo caso noterai che la distribuzione sembra molto più piatta.",
  "time_range": [
   673.22,
   676.18
  ]
 },
 {
  "input": "In particular, the most probable occurrence of all grays only has about a 6% chance of occurring, so at minimum you're getting evidently 3.9 bits of information.",
  "model": "nmt",
  "translatedText": "In particolare, l&#39;evento più probabile di tutti i grigi ha solo una probabilità del 6% circa, quindi come minimo ne ottieni evidentemente 3.9 bit di informazione.",
  "time_range": [
   676.18,
   685.94
  ]
 },
 {
  "input": "But that's a minimum, more typically you'd get something better than that.",
  "model": "nmt",
  "translatedText": "Ma questo è il minimo, più tipicamente otterresti qualcosa di meglio di così.",
  "time_range": [
   685.94,
   689.14
  ]
 },
 {
  "input": "And it turns out when you crunch the numbers on this one and add up all the relevant terms, the average information is about 5.8.",
  "model": "nmt",
  "translatedText": "E si scopre che quando si calcolano i numeri su questo e si sommano tutti i termini rilevanti, l&#39;informazione media è di circa 5.8.",
  "time_range": [
   689.14,
   696.42
  ]
 },
 {
  "input": "So in contrast with Weary, your space of possibilities will be about half as big after this first guess, on average.",
  "model": "nmt",
  "translatedText": "Quindi, a differenza di Weary, il tuo spazio di possibilità sarà in media circa la metà dopo questa prima ipotesi.",
  "time_range": [
   696.42,
   703.94
  ]
 },
 {
  "input": "There's actually a fun story about the name for this expected value of information quantity.",
  "model": "nmt",
  "translatedText": "In realtà c&#39;è una storia divertente sul nome di questo valore atteso della quantità di informazioni.",
  "time_range": [
   703.94,
   709.54
  ]
 },
 {
  "input": "Information theory was developed by Claude Shannon, who was working at Bell Labs in the 1940s, but he was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, very prominent in math and physics and the beginnings of what was becoming computer science.",
  "model": "nmt",
  "translatedText": "La teoria dell&#39;informazione fu sviluppata da Claude Shannon, che lavorava ai Bell Labs negli anni &#39;40, ma stava parlando di alcune delle sue idee ancora da pubblicare con John von Neumann, che era questo gigante intellettuale dell&#39;epoca, molto importante in matematica e fisica e gli inizi di quella che stava diventando l&#39;informatica.",
  "time_range": [
   709.54,
   724.18
  ]
 },
 {
  "input": "And when he mentioned that he didn't really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, well you should call it entropy, and for two reasons.",
  "model": "nmt",
  "translatedText": "E quando disse che non aveva un buon nome per questo valore atteso della quantità di informazioni, von Neumann presumibilmente disse, così va la storia, beh, dovresti chiamarla entropia, e per due ragioni.",
  "time_range": [
   724.18,
   734.72
  ]
 },
 {
  "input": "In the first place, your uncertainty function has been used in statistical mechanics under that name, so it already has a name, and in the second place, and more important, nobody knows what entropy really is, so in a debate you'll always have the advantage.",
  "model": "nmt",
  "translatedText": "In primo luogo, la tua funzione di incertezza è stata usata nella meccanica statistica con quel nome, quindi ha già un nome, e in secondo luogo, e cosa più importante, nessuno sa cosa sia realmente l&#39;entropia, quindi in un dibattito sarai sempre avere il vantaggio.",
  "time_range": [
   734.72,
   746.94
  ]
 },
 {
  "input": "So if the name seems a little bit mysterious, and if this story is to be believed, that's kind of by design.",
  "model": "nmt",
  "translatedText": "Quindi, se il nome sembra un po&#39; misterioso, e se si deve credere a questa storia, è in un certo senso previsto.",
  "time_range": [
   746.94,
   753.42
  ]
 },
 {
  "input": "Also if you're wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory, and for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess.",
  "model": "nmt",
  "translatedText": "Inoltre, se ti stai chiedendo quale sia la sua relazione con tutta quella seconda legge della termodinamica, materiale della fisica, c&#39;è sicuramente una connessione, ma nelle sue origini Shannon si occupava solo di pura teoria della probabilità, e per i nostri scopi qui, quando uso la parola entropia, voglio solo che tu pensi al valore informativo atteso di una particolare ipotesi.",
  "time_range": [
   753.42,
   770.82
  ]
 },
 {
  "input": "You can think of entropy as measuring two things simultaneously.",
  "model": "nmt",
  "translatedText": "Puoi pensare all&#39;entropia come alla misurazione di due cose contemporaneamente.",
  "time_range": [
   770.82,
   774.38
  ]
 },
 {
  "input": "The first one is how flat is the distribution.",
  "model": "nmt",
  "translatedText": "Il primo è quanto piatta è la distribuzione.",
  "time_range": [
   774.38,
   777.42
  ]
 },
 {
  "input": "The closer a distribution is to uniform, the higher that entropy will be.",
  "model": "nmt",
  "translatedText": "Più una distribuzione si avvicina all’uniforme, maggiore sarà l’entropia.",
  "time_range": [
   777.42,
   781.7
  ]
 },
 {
  "input": "In our case, where there are 3 to the 5th total patterns, for a uniform distribution, observing any one of them would have information log base 2 of 3 to the 5th, which happens to be 7.92, so that is the absolute maximum that you could possibly have for this entropy.",
  "model": "nmt",
  "translatedText": "Nel nostro caso, dove ci sono da 3 a 5 modelli totali, per una distribuzione uniforme, osservando uno qualsiasi di essi si otterrebbe un log delle informazioni in base 2 di 3 alla 5, che risulta essere 7.92, quindi questo è il massimo assoluto che potresti avere per questa entropia.",
  "time_range": [
   781.7,
   797.86
  ]
 },
 {
  "input": "But entropy is also kind of a measure of how many possibilities there are in the first place.",
  "model": "nmt",
  "translatedText": "Ma l’entropia è anche una sorta di misura di quante possibilità ci sono in primo luogo.",
  "time_range": [
   797.86,
   802.9
  ]
 },
 {
  "input": "For example, if you happen to have some word where there's only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be 4 bits.",
  "model": "nmt",
  "translatedText": "Ad esempio, se ti capita di avere una parola in cui ci sono solo 16 modelli possibili, e ognuno è ugualmente probabile, questa entropia, questa informazione attesa, sarebbe di 4 bit.",
  "time_range": [
   802.9,
   812.76
  ]
 },
 {
  "input": "But if you have another word where there's 64 possible patterns that could come up, and they're all equally likely, then the entropy would work out to be 6 bits.",
  "model": "nmt",
  "translatedText": "Ma se hai un&#39;altra parola in cui ci sono 64 possibili modelli che potrebbero emergere, e sono tutti ugualmente probabili, allora l&#39;entropia risulterebbe essere di 6 bit.",
  "time_range": [
   812.76,
   821.0
  ]
 },
 {
  "input": "So if you see some distribution out in the wild that has an entropy of 6 bits, it's sort of like it's saying there's as much variation and uncertainty in what's about to happen as if there were 64 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "Quindi, se vedi una distribuzione in natura che ha un&#39;entropia di 6 bit, è un po&#39; come se dicesse che ci sono tante variazioni e incertezze in ciò che sta per accadere come se ci fossero 64 risultati ugualmente probabili.",
  "time_range": [
   821.0,
   834.4
  ]
 },
 {
  "input": "For my first pass at the Wurtelebot, I basically had it just do this.",
  "model": "nmt",
  "translatedText": "Per il mio primo passaggio al Wurtelebot, praticamente ho fatto semplicemente questo.",
  "time_range": [
   834.4,
   838.36
  ]
 },
 {
  "input": "It goes through all of the possible guesses you could have, all 13,000 words, computes the entropy for each one, or more specifically, the entropy of the distribution across all patterns you might see, for each one, and picks the highest, since that's the one that's likely to chop down your space of possibilities as much as possible.",
  "model": "nmt",
  "translatedText": "Esamina tutte le possibili ipotesi che potresti avere, tutte le 13.000 parole, calcola l&#39;entropia per ciascuna di esse o, più specificamente, l&#39;entropia della distribuzione in tutti i modelli che potresti vedere, per ciascuno, e sceglie il più alto, poiché è quello che probabilmente ridurrà il più possibile il tuo spazio di possibilità.",
  "time_range": [
   838.36,
   857.2
  ]
 },
 {
  "input": "And even though I've only been talking about the first guess here, it does the same thing for the next few guesses.",
  "model": "nmt",
  "translatedText": "E anche se qui ho parlato solo della prima ipotesi, fa la stessa cosa per le prossime ipotesi.",
  "time_range": [
   857.2,
   861.68
  ]
 },
 {
  "input": "For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words.",
  "model": "nmt",
  "translatedText": "Ad esempio, dopo aver visto uno schema su quella prima ipotesi, che ti limiterebbe a un numero inferiore di parole possibili in base a ciò che corrisponde a quello, giochi semplicemente allo stesso gioco rispetto a quell&#39;insieme più piccolo di parole.",
  "time_range": [
   861.68,
   872.3
  ]
 },
 {
  "input": "For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words, you search through all 13,000 possibilities, and you find the one that maximizes that entropy.",
  "model": "nmt",
  "translatedText": "Per una seconda ipotesi proposta, guardi la distribuzione di tutti i modelli che potrebbero verificarsi da quell&#39;insieme di parole più ristretto, cerchi tutte le 13.000 possibilità e trovi quello che massimizza quell&#39;entropia.",
  "time_range": [
   872.3,
   885.48
  ]
 },
 {
  "input": "To show you how this works in action, let me just pull up a little variant of Wurtele that I wrote that shows the highlights of this analysis in the margins.",
  "model": "nmt",
  "translatedText": "Per mostrarvi come funziona in azione, lasciatemi semplicemente richiamare una piccola variante di Wurtele che ho scritto che mostra i punti salienti di questa analisi a margine.",
  "time_range": [
   885.48,
   894.46
  ]
 },
 {
  "input": "After doing all its entropy calculations, on the right here it's showing us which ones have the highest expected information.",
  "model": "nmt",
  "translatedText": "Dopo aver fatto tutti i calcoli dell&#39;entropia, qui a destra ci mostra quali hanno le informazioni attese più alte.",
  "time_range": [
   894.46,
   900.34
  ]
 },
 {
  "input": "Turns out the top answer, at least at the moment, we'll refine this later, is Tares, which means, um, of course, a vetch, the most common vetch.",
  "model": "nmt",
  "translatedText": "Sembra che la risposta migliore, almeno al momento, la perfezioneremo più tardi, è Tares, che significa, ehm, ovviamente, una veccia, la veccia più comune.",
  "time_range": [
   900.34,
   911.14
  ]
 },
 {
  "input": "Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had, but then on the right of the word here it's showing us how much actual information we got, given this particular pattern.",
  "model": "nmt",
  "translatedText": "Ogni volta che facciamo un&#39;ipotesi qui, dove forse ignoro i suoi consigli e scelgo lo slate, perché mi piace lo slate, possiamo vedere quante informazioni attese aveva, ma poi a destra della parola qui ci mostra quante informazioni effettive che abbiamo ottenuto, dato questo modello particolare.",
  "time_range": [
   911.14,
   924.98
  ]
 },
 {
  "input": "So here it looks like we were a little unlucky, we were expected to get 5.8, but we happened to get something with less than that.",
  "model": "nmt",
  "translatedText": "Quindi qui sembra che siamo stati un po&#39; sfortunati, ci aspettavamo di prenderne 5.8, ma ci è capitato di ottenere qualcosa con meno di quello.",
  "time_range": [
   924.98,
   930.66
  ]
 },
 {
  "input": "And then on the left side here it's showing us all of the different possible words given where we are now.",
  "model": "nmt",
  "translatedText": "E poi sul lato sinistro qui ci vengono mostrate tutte le diverse parole possibili data la situazione in cui ci troviamo adesso.",
  "time_range": [
   930.66,
   935.86
  ]
 },
 {
  "input": "The blue bars are telling us how likely it thinks each word is, so at the moment it's assuming each word is equally likely to occur, but we'll refine that in a moment.",
  "model": "nmt",
  "translatedText": "Le barre blu ci dicono quanto è probabile che ciascuna parola sia, quindi al momento presuppone che ogni parola abbia la stessa probabilità di verificarsi, ma lo perfezioneremo tra un momento.",
  "time_range": [
   935.86,
   944.14
  ]
 },
 {
  "input": "And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it's a uniform distribution, is just a needlessly complicated way to count the number of possibilities.",
  "model": "nmt",
  "translatedText": "E poi questa misurazione dell&#39;incertezza ci dice l&#39;entropia di questa distribuzione tra le parole possibili, che in questo momento, poiché è una distribuzione uniforme, è solo un modo inutilmente complicato per contare il numero di possibilità.",
  "time_range": [
   944.14,
   955.94
  ]
 },
 {
  "input": "For example, if we were to take 2 to the power of 13.66, that should be around the 13,000 possibilities.",
  "model": "nmt",
  "translatedText": "Ad esempio, se dovessimo portare 2 alla potenza di 13.66, dovrebbero essere circa 13.000 possibilità.",
  "time_range": [
   955.94,
   962.7
  ]
 },
 {
  "input": "I'm a little bit off here, but only because I'm not showing all the decimal places.",
  "model": "nmt",
  "translatedText": "Sono un po&#39; fuori strada, ma solo perché non mostro tutte le cifre decimali.",
  "time_range": [
   962.7,
   966.78
  ]
 },
 {
  "input": "At the moment that might feel redundant and like it's overly complicating things, but you'll see why it's useful to have both numbers in a minute.",
  "model": "nmt",
  "translatedText": "Al momento potrebbe sembrare ridondante e complicare eccessivamente le cose, ma vedrai perché è utile avere entrambi i numeri in un minuto.",
  "time_range": [
   966.78,
   972.78
  ]
 },
 {
  "input": "So here it looks like it's suggesting the highest entropy for our second guess is Ramen, which again just really doesn't feel like a word.",
  "model": "nmt",
  "translatedText": "Quindi qui sembra che suggerisca che l&#39;entropia più alta per la nostra seconda ipotesi sia Ramen, che ancora una volta non sembra proprio una parola.",
  "time_range": [
   972.78,
   979.7
  ]
 },
 {
  "input": "So to take the moral high ground here, I'm going to go ahead and type in Rains.",
  "model": "nmt",
  "translatedText": "Quindi, per prendere una posizione morale, andrò avanti e digiterò Rains.",
  "time_range": [
   979.7,
   985.66
  ]
 },
 {
  "input": "And again it looks like we were a little unlucky.",
  "model": "nmt",
  "translatedText": "E ancora una volta sembra che siamo stati un po&#39; sfortunati.",
  "time_range": [
   985.66,
   987.54
  ]
 },
 {
  "input": "We were expecting 4.3 bits and we only got 3.39 bits of information.",
  "model": "nmt",
  "translatedText": "Ci aspettavamo 4.3 bit e ne abbiamo solo 3.39 bit di informazioni.",
  "time_range": [
   987.54,
   992.1
  ]
 },
 {
  "input": "So that takes us down to 55 possibilities.",
  "model": "nmt",
  "translatedText": "Quindi questo ci porta a 55 possibilità.",
  "time_range": [
   992.1,
   995.06
  ]
 },
 {
  "input": "And here maybe I'll just actually go with what it's suggesting, which is combo, whatever that means.",
  "model": "nmt",
  "translatedText": "E qui forse seguirò semplicemente ciò che suggerisce, che è una combinazione, qualunque cosa significhi.",
  "time_range": [
   995.06,
   1000.2
  ]
 },
 {
  "input": "And okay, this is actually a good chance for a puzzle.",
  "model": "nmt",
  "translatedText": "E okay, questa è in realtà una buona occasione per un puzzle.",
  "time_range": [
   1000.2,
   1003.3
  ]
 },
 {
  "input": "It's telling us this pattern gives us 4.7 bits of information.",
  "model": "nmt",
  "translatedText": "Ci sta dicendo che questo schema ci dà 4.7 bit di informazione.",
  "time_range": [
   1003.3,
   1007.02
  ]
 },
 {
  "input": "But over on the left, before we see that pattern, there were 5.78 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "Ma a sinistra, prima di vedere lo schema, ce n&#39;erano 5.78 bit di incertezza.",
  "time_range": [
   1007.02,
   1012.4
  ]
 },
 {
  "input": "So as a quiz for you, what does that mean about the number of remaining possibilities?",
  "model": "nmt",
  "translatedText": "Quindi, come quiz per te, cosa significa riguardo al numero di possibilità rimanenti?",
  "time_range": [
   1012.4,
   1016.86
  ]
 },
 {
  "input": "Well, it means that we're reduced down to one bit of uncertainty, which is the same thing as saying that there's two possible answers.",
  "model": "nmt",
  "translatedText": "Ebbene, significa che siamo ridotti a un minimo di incertezza, il che equivale a dire che ci sono due risposte possibili.",
  "time_range": [
   1016.86,
   1024.7
  ]
 },
 {
  "input": "It's a 50-50 choice.",
  "model": "nmt",
  "translatedText": "È una scelta 50-50.",
  "time_range": [
   1024.7,
   1026.52
  ]
 },
 {
  "input": "And from here, because you and I know which words are more common, we know that the answer should be abyss.",
  "model": "nmt",
  "translatedText": "E da qui, poiché tu ed io sappiamo quali sono le parole più comuni, sappiamo che la risposta dovrebbe essere abisso.",
  "time_range": [
   1026.52,
   1031.22
  ]
 },
 {
  "input": "But as it's written right now, the program doesn't know that.",
  "model": "nmt",
  "translatedText": "Ma come è scritto proprio ora, il programma non lo sa.",
  "time_range": [
   1031.22,
   1033.54
  ]
 },
 {
  "input": "So it just keeps going, trying to gain as much information as it can, until it's only one possibility left, and then it guesses it.",
  "model": "nmt",
  "translatedText": "Quindi continua ad andare avanti, cercando di ottenere quante più informazioni possibile, finché non rimane solo una possibilità, e poi indovina.",
  "time_range": [
   1033.54,
   1040.36
  ]
 },
 {
  "input": "So obviously we need a better endgame strategy.",
  "model": "nmt",
  "translatedText": "Quindi ovviamente abbiamo bisogno di una migliore strategia di fine gioco.",
  "time_range": [
   1040.36,
   1042.7
  ]
 },
 {
  "input": "But let's say we call this version one of our wordle solver, and then we go and run some simulations to see how it does.",
  "model": "nmt",
  "translatedText": "Ma diciamo che chiamiamo questa versione uno del nostro risolutore di parole, e poi andiamo ad eseguire alcune simulazioni per vedere come funziona.",
  "time_range": [
   1042.7,
   1050.74
  ]
 },
 {
  "input": "So the way this is working is it's playing every possible wordle game.",
  "model": "nmt",
  "translatedText": "Quindi il modo in cui funziona è giocare a ogni possibile gioco di parole.",
  "time_range": [
   1050.74,
   1054.24
  ]
 },
 {
  "input": "It's going through all of those 2315 words that are the actual wordle answers.",
  "model": "nmt",
  "translatedText": "Sta esaminando tutte quelle 2315 parole che sono le vere risposte delle parole.",
  "time_range": [
   1054.24,
   1058.78
  ]
 },
 {
  "input": "It's basically using that as a testing set.",
  "model": "nmt",
  "translatedText": "Fondamentalmente lo utilizza come set di test.",
  "time_range": [
   1058.78,
   1061.34
  ]
 },
 {
  "input": "And with this naive method of not considering how common a word is, and just trying to maximize the information at each step along the way, until it gets down to one and only one choice.",
  "model": "nmt",
  "translatedText": "E con questo metodo ingenuo di non considerare quanto sia comune una parola, e di cercare semplicemente di massimizzare l&#39;informazione in ogni fase del percorso, finché non si arriva a una ed una sola scelta.",
  "time_range": [
   1061.34,
   1070.48
  ]
 },
 {
  "input": "By the end of the simulation, the average score works out to be about 4.124.",
  "model": "nmt",
  "translatedText": "Alla fine della simulazione, il punteggio medio risulta essere circa 4.124.",
  "time_range": [
   1070.48,
   1075.1
  ]
 },
 {
  "input": "Which is not bad, to be honest, I kind of expected to do worse.",
  "model": "nmt",
  "translatedText": "Il che non è male, a dire il vero, mi aspettavo di fare di peggio.",
  "time_range": [
   1075.1,
   1079.78
  ]
 },
 {
  "input": "But the people who play wordle will tell you that they can usually get it in 4.",
  "model": "nmt",
  "translatedText": "Ma le persone che giocano a Wordle ti diranno che di solito riescono a farlo in 4.",
  "time_range": [
   1079.78,
   1083.04
  ]
 },
 {
  "input": "The real challenge is to get as many in 3 as you can.",
  "model": "nmt",
  "translatedText": "La vera sfida è ottenerne il maggior numero possibile in 3.",
  "time_range": [
   1083.04,
   1085.26
  ]
 },
 {
  "input": "It's a pretty big jump between the score of 4 and the score of 3.",
  "model": "nmt",
  "translatedText": "C&#39;è un salto piuttosto grande tra il punteggio di 4 e il punteggio di 3.",
  "time_range": [
   1085.26,
   1088.92
  ]
 },
 {
  "input": "The obvious low hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that.",
  "model": "nmt",
  "translatedText": "L’ovvio frutto a portata di mano qui è quello di incorporare in qualche modo se una parola è comune o meno, e come lo facciamo esattamente.",
  "time_range": [
   1088.92,
   1103.16
  ]
 },
 {
  "input": "The way I approached it is to get a list of the relative frequencies for all of the words in the English language.",
  "model": "nmt",
  "translatedText": "Il modo in cui mi sono avvicinato è stato quello di ottenere un elenco delle frequenze relative per tutte le parole in lingua inglese.",
  "time_range": [
   1103.16,
   1108.56
  ]
 },
 {
  "input": "And I just used Mathematica's word frequency data function, which itself pulls from the Google Books English Ngram public dataset.",
  "model": "nmt",
  "translatedText": "E ho appena utilizzato la funzione dati sulla frequenza delle parole di Mathematica, che a sua volta estrae dal set di dati pubblici English Ngram di Google Libri.",
  "time_range": [
   1108.56,
   1115.52
  ]
 },
 {
  "input": "And it's kind of fun to look at, for example if we sort it from the most common words to the least common words.",
  "model": "nmt",
  "translatedText": "Ed è piuttosto divertente da guardare, ad esempio se lo ordiniamo dalle parole più comuni a quelle meno comuni.",
  "time_range": [
   1115.52,
   1120.12
  ]
 },
 {
  "input": "Evidently these are the most common, 5 letter words in the English language.",
  "model": "nmt",
  "translatedText": "Evidentemente queste sono le parole di 5 lettere più comuni nella lingua inglese.",
  "time_range": [
   1120.12,
   1123.74
  ]
 },
 {
  "input": "Or rather, these is the 8th most common.",
  "model": "nmt",
  "translatedText": "O meglio, questi sono gli 8 più comuni.",
  "time_range": [
   1123.74,
   1126.48
  ]
 },
 {
  "input": "First is which, after which there's there and there.",
  "model": "nmt",
  "translatedText": "Il primo è quale, dopodiché c&#39;è lì e là.",
  "time_range": [
   1126.48,
   1129.44
  ]
 },
 {
  "input": "First itself is not first, but 9th, and it makes sense that these other words could come about more often, where those after first are after, where, and those being just a little bit less common.",
  "model": "nmt",
  "translatedText": "Primo in sé non è primo, ma 9°, ed è logico che queste altre parole possano comparire più spesso, dove quelle dopo prima sono dopo, dove e quelle sono solo un po&#39; meno comuni.",
  "time_range": [
   1129.44,
   1139.0
  ]
 },
 {
  "input": "Now, in using this data to model how likely each of these words is to be the final answer, it shouldn't just be proportional to the frequency.",
  "model": "nmt",
  "translatedText": "Ora, utilizzando questi dati per modellare la probabilità che ciascuna di queste parole sia la risposta finale, non dovrebbe essere solo proporzionale alla frequenza.",
  "time_range": [
   1139.0,
   1147.02
  ]
 },
 {
  "input": "For example, which is given a score of 0.002 in this dataset, whereas the word braid is in some sense about 1000 times less likely.",
  "model": "nmt",
  "translatedText": "Ad esempio, a cui viene assegnato un punteggio pari a 0.002 in questo set di dati, mentre la parola treccia è in un certo senso circa 1000 volte meno probabile.",
  "time_range": [
   1147.02,
   1155.2
  ]
 },
 {
  "input": "But both of these are common enough words that they're almost certainly worth considering.",
  "model": "nmt",
  "translatedText": "Ma entrambe queste sono parole abbastanza comuni da valere quasi sicuramente la pena di essere prese in considerazione.",
  "time_range": [
   1155.2,
   1159.4
  ]
 },
 {
  "input": "So we want more of a binary cutoff.",
  "model": "nmt",
  "translatedText": "Quindi vogliamo più di un taglio binario.",
  "time_range": [
   1159.4,
   1161.9
  ]
 },
 {
  "input": "The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it's either 0 or it's 1, but there's a smoothing in between for that region of uncertainty.",
  "model": "nmt",
  "translatedText": "Il modo in cui ho proceduto è stato immaginare di prendere l&#39;intero elenco ordinato di parole, quindi disporlo su un asse x, e quindi applicare la funzione sigmoide, che è il modo standard per avere una funzione il cui output è fondamentalmente binario, è o 0 oppure è 1, ma c&#39;è un livellamento intermedio per quella regione di incertezza.",
  "time_range": [
   1161.9,
   1178.5
  ]
 },
 {
  "input": "So essentially, the probability that I'm assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis.",
  "model": "nmt",
  "translatedText": "Quindi, in sostanza, la probabilità che assegno a ciascuna parola di essere nell&#39;elenco finale sarà il valore della funzione sigmoide sopra ovunque si trovi sull&#39;asse x.",
  "time_range": [
   1178.5,
   1189.54
  ]
 },
 {
  "input": "Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from 1 to 0, and where we situate them left to right determines the cutoff.",
  "model": "nmt",
  "translatedText": "Ovviamente questo dipende da alcuni parametri, ad esempio quanto è ampio lo spazio sull&#39;asse x riempito da quelle parole determina quanto gradualmente o ripidamente scendiamo da 1 a 0, e il punto in cui le posizioniamo da sinistra a destra determina il limite.",
  "time_range": [
   1189.54,
   1203.16
  ]
 },
 {
  "input": "To be honest, the way I did this was just licking my finger and sticking it into the wind.",
  "model": "nmt",
  "translatedText": "Ad essere onesti, il modo in cui l&#39;ho fatto è stato semplicemente leccarmi il dito e alzarlo al vento.",
  "time_range": [
   1203.16,
   1207.34
  ]
 },
 {
  "input": "I looked through the sorted list and tried to find a window where when I looked at it I figured about half of these words are more likely than not to be the final answer, and used that as the cutoff.",
  "model": "nmt",
  "translatedText": "Ho esaminato l&#39;elenco ordinato e ho cercato di trovare una finestra in cui, quando l&#39;ho guardata, ho pensato che circa la metà di queste parole fosse più probabile che non fossero la risposta finale, e l&#39;ho usata come limite.",
  "time_range": [
   1207.34,
   1217.68
  ]
 },
 {
  "input": "Once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement.",
  "model": "nmt",
  "translatedText": "Una volta ottenuta una distribuzione come questa tra le parole, otteniamo un&#39;altra situazione in cui l&#39;entropia diventa una misura davvero utile.",
  "time_range": [
   1217.68,
   1224.46
  ]
 },
 {
  "input": "For example, let's say we were playing a game and we start with my old openers, which were a feather and nails, and we end up with a situation where there's four possible words that match it.",
  "model": "nmt",
  "translatedText": "Ad esempio, supponiamo che stessimo giocando e iniziamo con le mie vecchie aperture, che erano una piuma e chiodi, e finiamo con una situazione in cui ci sono quattro possibili parole che corrispondono a quella.",
  "time_range": [
   1224.46,
   1233.76
  ]
 },
 {
  "input": "And let's say we consider them all equally likely.",
  "model": "nmt",
  "translatedText": "E diciamo che li consideriamo tutti ugualmente probabili.",
  "time_range": [
   1233.76,
   1236.44
  ]
 },
 {
  "input": "Let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Lascia che ti chieda: qual è l&#39;entropia di questa distribuzione?",
  "time_range": [
   1236.44,
   1240.0
  ]
 },
 {
  "input": "Well, the information associated with each one of these possibilities is going to be the log base 2 of 4, since each one is 1 and 4, and that's 2.",
  "model": "nmt",
  "translatedText": "Bene, l&#39;informazione associata a ciascuna di queste possibilità sarà il logaritmo in base 2 di 4, poiché ognuna è 1 e 4, e cioè 2.",
  "time_range": [
   1240.0,
   1250.8
  ]
 },
 {
  "input": "Two bits of information, four possibilities.",
  "model": "nmt",
  "translatedText": "Due informazioni, quattro possibilità.",
  "time_range": [
   1250.8,
   1252.78
  ]
 },
 {
  "input": "All very well and good.",
  "model": "nmt",
  "translatedText": "Tutto molto bello e buono.",
  "time_range": [
   1252.78,
   1254.36
  ]
 },
 {
  "input": "But what if I told you that actually there's more than four matches?",
  "model": "nmt",
  "translatedText": "E se ti dicessi che in realtà ci sono più di quattro partite?",
  "time_range": [
   1254.36,
   1258.32
  ]
 },
 {
  "input": "In reality, when we look through the full word list, there are 16 words that match it.",
  "model": "nmt",
  "translatedText": "In realtà, quando esaminiamo l&#39;elenco completo delle parole, ci sono 16 parole che corrispondono.",
  "time_range": [
   1258.32,
   1262.6
  ]
 },
 {
  "input": "But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like 1 in 1000 because they're really obscure.",
  "model": "nmt",
  "translatedText": "Ma supponiamo che il nostro modello attribuisca una probabilità molto bassa alle altre 12 parole di essere effettivamente la risposta finale, qualcosa come 1 su 1000 perché sono davvero oscure.",
  "time_range": [
   1262.6,
   1271.44
  ]
 },
 {
  "input": "Now let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Ora lascia che ti chieda: qual è l&#39;entropia di questa distribuzione?",
  "time_range": [
   1271.44,
   1275.48
  ]
 },
 {
  "input": "If entropy was purely measuring the number of matches here, then you might expect it to be something like the log base 2 of 16, which would be 4, two more bits of uncertainty than we had before.",
  "model": "nmt",
  "translatedText": "Se l&#39;entropia misurasse semplicemente il numero di corrispondenze qui, allora potresti aspettarti che sia qualcosa come il logaritmo in base 2 di 16, che sarebbe 4, due bit di incertezza in più rispetto a prima.",
  "time_range": [
   1275.48,
   1286.2
  ]
 },
 {
  "input": "But of course the actual uncertainty is not really that different from what we had before.",
  "model": "nmt",
  "translatedText": "Ma ovviamente l’effettiva incertezza non è poi così diversa da quella che avevamo prima.",
  "time_range": [
   1286.2,
   1290.32
  ]
 },
 {
  "input": "Just because there's these 12 really obscure words doesn't mean that it would be all that more surprising to learn that the final answer is charm, for example.",
  "model": "nmt",
  "translatedText": "Solo perché ci sono queste 12 parole davvero oscure non significa che sarebbe ancora più sorprendente apprendere che la risposta finale è fascino, per esempio.",
  "time_range": [
   1290.32,
   1298.2
  ]
 },
 {
  "input": "So when you actually do the calculation here, and you add up the probability of each occurrence times the corresponding information, what you get is 2.11 bits.",
  "model": "nmt",
  "translatedText": "Quindi, quando fai effettivamente il calcolo qui, e sommi la probabilità di ogni occorrenza moltiplicata per le informazioni corrispondenti, quello che ottieni è 2.11 bit.",
  "time_range": [
   1298.2,
   1305.96
  ]
 },
 {
  "input": "I'm just saying, it's basically two bits, basically those four possibilities, but there's a little more uncertainty because of all of those highly unlikely events, though if you did learn them you'd get a ton of information from it.",
  "model": "nmt",
  "translatedText": "Dico solo che sono fondamentalmente due bit, fondamentalmente queste quattro possibilità, ma c&#39;è un po&#39; più di incertezza a causa di tutti quegli eventi altamente improbabili, anche se se li imparassi ne otterresti un sacco di informazioni.",
  "time_range": [
   1305.96,
   1317.12
  ]
 },
 {
  "input": "So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson.",
  "model": "nmt",
  "translatedText": "Quindi, rimpicciolendo, questo fa parte di ciò che rende Wordle un bell&#39;esempio per una lezione di teoria dell&#39;informazione.",
  "time_range": [
   1317.12,
   1321.8
  ]
 },
 {
  "input": "We have these two distinct feeling applications for entropy.",
  "model": "nmt",
  "translatedText": "Abbiamo queste due distinte applicazioni di sensazione per l&#39;entropia.",
  "time_range": [
   1321.8,
   1325.28
  ]
 },
 {
  "input": "The first one telling us what's the expected information we'll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words that we have possible.",
  "model": "nmt",
  "translatedText": "Il primo ci dice quali sono le informazioni attese che otterremo da una determinata ipotesi, e il secondo dice che possiamo misurare l&#39;incertezza rimanente tra tutte le parole che abbiamo a disposizione.",
  "time_range": [
   1325.28,
   1336.48
  ]
 },
 {
  "input": "And I should emphasize, in that first case where we're looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation.",
  "model": "nmt",
  "translatedText": "E dovrei sottolineare, nel primo caso in cui stiamo esaminando le informazioni attese di un&#39;ipotesi, una volta che abbiamo un peso disuguale per le parole, ciò influisce sul calcolo dell&#39;entropia.",
  "time_range": [
   1336.48,
   1345.0
  ]
 },
 {
  "input": "For example, let me pull up that same case we were looking at earlier of the distribution associated with Weary, but this time using a non-uniform distribution across all possible words.",
  "model": "nmt",
  "translatedText": "Ad esempio, vorrei richiamare lo stesso caso che stavamo esaminando in precedenza della distribuzione associata a Weary, ma questa volta utilizzando una distribuzione non uniforme su tutte le parole possibili.",
  "time_range": [
   1345.0,
   1354.56
  ]
 },
 {
  "input": "So let me see if I can find a part here that illustrates it pretty well.",
  "model": "nmt",
  "translatedText": "Quindi vediamo se riesco a trovare una parte qui che lo illustri abbastanza bene.",
  "time_range": [
   1354.56,
   1359.36
  ]
 },
 {
  "input": "Okay, here this is pretty good.",
  "model": "nmt",
  "translatedText": "Ok, ecco, questo è abbastanza buono.",
  "time_range": [
   1359.36,
   1362.48
  ]
 },
 {
  "input": "Here we have two adjacent patterns that are about equally likely, but one of them we're told has 32 possible words that match it.",
  "model": "nmt",
  "translatedText": "Qui abbiamo due schemi adiacenti che sono quasi altrettanto probabili, ma ci viene detto che uno di essi ha 32 possibili parole che lo corrispondono.",
  "time_range": [
   1362.48,
   1369.48
  ]
 },
 {
  "input": "And if we check what they are, these are those 32, which are all just very unlikely words as you scan your eyes over them.",
  "model": "nmt",
  "translatedText": "E se controlliamo cosa sono, queste sono quelle 32, che sono tutte parole molto improbabili mentre le guardi con gli occhi.",
  "time_range": [
   1369.48,
   1375.6
  ]
 },
 {
  "input": "It's hard to find any that feel like plausible answers, maybe yells, but if we look at the neighboring pattern in the distribution, which is considered just about as likely, we're told that it only has 8 possible matches, so a quarter as many matches, but it's about as likely.",
  "model": "nmt",
  "translatedText": "È difficile trovare risposte che sembrino plausibili, forse urla, ma se guardiamo lo schema dei vicini nella distribuzione, che è considerato altrettanto probabile, ci viene detto che ha solo 8 corrispondenze possibili, quindi un quarto di molte partite, ma è altrettanto probabile.",
  "time_range": [
   1375.6,
   1389.92
  ]
 },
 {
  "input": "And when we pull up those matches, we can see why.",
  "model": "nmt",
  "translatedText": "E quando analizziamo quei fiammiferi, possiamo capire il perché.",
  "time_range": [
   1389.92,
   1392.52
  ]
 },
 {
  "input": "Some of these are actual plausible answers, like ring, or wrath, or raps.",
  "model": "nmt",
  "translatedText": "Alcune di queste sono risposte realmente plausibili, come ring, o ira, o rap.",
  "time_range": [
   1392.52,
   1397.84
  ]
 },
 {
  "input": "To illustrate how we incorporate all that, let me pull up version 2 of the Wordlebot here, and there are two or three main differences from the first one that we saw.",
  "model": "nmt",
  "translatedText": "Per illustrare come incorporiamo tutto ciò, lasciatemi richiamare qui la versione 2 di Wordlebot e ci sono due o tre differenze principali rispetto alla prima che abbiamo visto.",
  "time_range": [
   1397.84,
   1405.96
  ]
 },
 {
  "input": "First off, like I just said, the way that we're computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer.",
  "model": "nmt",
  "translatedText": "Prima di tutto, come ho appena detto, il modo in cui calcoliamo queste entropie, questi valori attesi delle informazioni, ora utilizza distribuzioni più raffinate attraverso i modelli che incorporano la probabilità che una determinata parola sia effettivamente la risposta.",
  "time_range": [
   1405.96,
   1419.3
  ]
 },
 {
  "input": "As it happens, tears is still number 1, though the ones following are a bit different.",
  "model": "nmt",
  "translatedText": "Si dà il caso che le lacrime siano ancora la numero 1, anche se quelle che seguono sono un po&#39; diverse.",
  "time_range": [
   1419.3,
   1424.16
  ]
 },
 {
  "input": "Second, when it ranks its top picks, it's now going to keep a model of the probability that each word is the actual answer, and it'll incorporate that into its decision, which is easier to see once we have a few guesses on the table.",
  "model": "nmt",
  "translatedText": "In secondo luogo, quando classificherà le scelte migliori, manterrà un modello della probabilità che ogni parola sia la risposta effettiva e lo incorporerà nella sua decisione, il che è più facile da vedere una volta che abbiamo alcune ipotesi sulla risposta. tavolo.",
  "time_range": [
   1424.16,
   1435.52
  ]
 },
 {
  "input": "Again, ignoring its recommendation because we can't let machines rule our lives.",
  "model": "nmt",
  "translatedText": "Ancora una volta, ignorando la sua raccomandazione perché non possiamo lasciare che le macchine governino le nostre vite.",
  "time_range": [
   1435.52,
   1441.12
  ]
 },
 {
  "input": "And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches.",
  "model": "nmt",
  "translatedText": "E suppongo che dovrei menzionare un&#39;altra cosa diversa qui a sinistra, che il valore di incertezza, quel numero di bit, non è più semplicemente ridondante con il numero di possibili corrispondenze.",
  "time_range": [
   1441.12,
   1450.08
  ]
 },
 {
  "input": "Now if we pull it up and calculate 2 to the 8.02, which is a little above 256, I guess 259, what it's saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "Ora se lo tiriamo su e calcoliamo 2^8.02, che è leggermente superiore a 256, immagino 259, ciò che dice è che anche se ci sono 526 parole totali che effettivamente corrispondono a questo modello, la quantità di incertezza che ha è più simile a quella che sarebbe se ce ne fossero 259 ugualmente probabili risultati.",
  "time_range": [
   1450.08,
   1469.76
  ]
 },
 {
  "input": "You can think of it like this.",
  "model": "nmt",
  "translatedText": "Puoi pensarla in questo modo.",
  "time_range": [
   1469.76,
   1471.1
  ]
 },
 {
  "input": "It knows borx is not the answer, same with yorts and zorl and zorus, so it's a little less uncertain than it was in the previous case.",
  "model": "nmt",
  "translatedText": "Sa che borx non è la risposta, lo stesso con yorts, zorl e zorus, quindi è un po&#39; meno incerto rispetto al caso precedente.",
  "time_range": [
   1471.1,
   1477.84
  ]
 },
 {
  "input": "This number of bits will be smaller.",
  "model": "nmt",
  "translatedText": "Questo numero di bit sarà inferiore.",
  "time_range": [
   1477.84,
   1480.22
  ]
 },
 {
  "input": "And if I keep playing the game, I'm refining this down with a couple guesses that are apropos of what I would like to explain here.",
  "model": "nmt",
  "translatedText": "E se continuo a giocare, lo perfezionerò con un paio di ipotesi che sono appropriate a ciò che vorrei spiegare qui.",
  "time_range": [
   1480.22,
   1488.68
  ]
 },
 {
  "input": "By the fourth guess, if you look over at its top picks, you can see it's no longer just maximizing the entropy.",
  "model": "nmt",
  "translatedText": "Alla quarta ipotesi, se guardi le sue scelte migliori, puoi vedere che non si tratta più solo di massimizzare l&#39;entropia.",
  "time_range": [
   1488.68,
   1493.8
  ]
 },
 {
  "input": "So at this point, there's technically seven possibilities, but the only ones with a meaningful chance are dorms and words.",
  "model": "nmt",
  "translatedText": "Quindi a questo punto ci sono tecnicamente sette possibilità, ma le uniche con una possibilità significativa sono i dormitori e le parole.",
  "time_range": [
   1493.8,
   1500.78
  ]
 },
 {
  "input": "And you can see it ranks choosing both of those above all of these other values, that strictly speaking would give more information.",
  "model": "nmt",
  "translatedText": "E si vede che si colloca scegliendo entrambi al di sopra di questi altri valori, che a rigor di termini darebbero maggiori informazioni.",
  "time_range": [
   1500.78,
   1507.56
  ]
 },
 {
  "input": "The very first time I did this, I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect.",
  "model": "nmt",
  "translatedText": "La prima volta che l&#39;ho fatto, ho semplicemente sommato questi due numeri per misurare la qualità di ogni ipotesi, che in realtà ha funzionato meglio di quanto potresti sospettare.",
  "time_range": [
   1507.56,
   1514.58
  ]
 },
 {
  "input": "But it really didn't feel systematic, and I'm sure there's other approaches people could take but here's the one I landed on.",
  "model": "nmt",
  "translatedText": "Ma in realtà non mi è sembrato sistematico e sono sicuro che ci siano altri approcci che le persone potrebbero adottare, ma ecco quello a cui sono arrivato.",
  "time_range": [
   1514.58,
   1519.88
  ]
 },
 {
  "input": "If we're considering the prospect of a next guess, like in this case words, what we really care about is the expected score of our game if we do that.",
  "model": "nmt",
  "translatedText": "Se consideriamo la prospettiva di un&#39;ipotesi successiva, come in questo caso le parole, ciò che ci interessa veramente è il punteggio atteso del nostro gioco se lo facciamo.",
  "time_range": [
   1519.88,
   1528.44
  ]
 },
 {
  "input": "And to calculate that expected score, we say what's the probability that words is the actual answer, which at the moment it describes 58% to.",
  "model": "nmt",
  "translatedText": "E per calcolare il punteggio atteso, diciamo qual è la probabilità che le parole siano la risposta effettiva, che al momento corrisponde al 58%.",
  "time_range": [
   1528.44,
   1536.08
  ]
 },
 {
  "input": "We say with a 58% chance, our score in this game would be 4.",
  "model": "nmt",
  "translatedText": "Diciamo che con una probabilità del 58%, il nostro punteggio in questo gioco sarebbe 4.",
  "time_range": [
   1536.08,
   1540.4
  ]
 },
 {
  "input": "And then with the probability of 1 minus that 58%, our score will be more than that 4.",
  "model": "nmt",
  "translatedText": "E poi con la probabilità di 1 meno quel 58%, il nostro punteggio sarà superiore a 4.",
  "time_range": [
   1540.4,
   1546.24
  ]
 },
 {
  "input": "How much more we don't know, but we can estimate it based on how much uncertainty there's likely to be once we get to that point.",
  "model": "nmt",
  "translatedText": "Quanto altro non lo sappiamo, ma possiamo stimarlo in base a quanta incertezza potrebbe esserci una volta arrivati a quel punto.",
  "time_range": [
   1546.24,
   1552.92
  ]
 },
 {
  "input": "Specifically, at the moment there's 1.44 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "Nello specifico, al momento ce n&#39;è 1.44 bit di incertezza.",
  "time_range": [
   1552.92,
   1556.6
  ]
 },
 {
  "input": "If we guess words, it's telling us the expected information we'll get is 1.27 bits.",
  "model": "nmt",
  "translatedText": "Se indoviniamo le parole, ci dice che l&#39;informazione prevista che otterremo è 1.27 bit.",
  "time_range": [
   1556.6,
   1561.56
  ]
 },
 {
  "input": "So if we guess words, this difference represents how much uncertainty we're likely to be left with after that happens.",
  "model": "nmt",
  "translatedText": "Quindi, se indoviniamo le parole, questa differenza rappresenta la quantità di incertezza che probabilmente ci resterà dopo che ciò accadrà.",
  "time_range": [
   1561.56,
   1568.28
  ]
 },
 {
  "input": "What we need is some kind of function, which I'm calling f here, that associates this uncertainty with an expected score.",
  "model": "nmt",
  "translatedText": "Ciò di cui abbiamo bisogno è una sorta di funzione, che qui chiamerò f, che associ questa incertezza a un punteggio atteso.",
  "time_range": [
   1568.28,
   1573.88
  ]
 },
 {
  "input": "And the way it went about this was to just plot a bunch of the data from previous games based on version 1 of the bot to say hey what was the actual score after various points with certain very measurable amounts of uncertainty.",
  "model": "nmt",
  "translatedText": "E il modo in cui è stato fatto è stato semplicemente tracciare una serie di dati dei giochi precedenti basati sulla versione 1 del bot per dire, ehi, qual era il punteggio effettivo dopo vari punti con determinate quantità di incertezza molto misurabili.",
  "time_range": [
   1573.88,
   1587.04
  ]
 },
 {
  "input": "For example, these data points here that are sitting above a value that's around like 8.7 or so are saying for some games after a point at which there were 8.7 bits of uncertainty, it took two guesses to get the final answer.",
  "model": "nmt",
  "translatedText": "Ad esempio, questi punti dati qui si trovano sopra un valore intorno a 8.Si dice circa 7 per alcune partite dopo un punto in cui erano 8.7 bit di incertezza, ci sono volute due ipotesi per ottenere la risposta finale.",
  "time_range": [
   1587.04,
   1599.34
  ]
 },
 {
  "input": "For other games it took three guesses, for other games it took four guesses.",
  "model": "nmt",
  "translatedText": "Per altri giochi sono state necessarie tre ipotesi, per altri giochi sono state necessarie quattro ipotesi.",
  "time_range": [
   1599.34,
   1603.18
  ]
 },
 {
  "input": "If we shift over to the left here, all the points over zero are saying whenever there's zero bits of uncertainty, which is to say there's only one possibility, then the number of guesses required is always just one, which is reassuring.",
  "model": "nmt",
  "translatedText": "Se qui ci spostiamo a sinistra, tutti i punti sopra lo zero indicano che ogni volta che ci sono zero punti di incertezza, vale a dire che c&#39;è solo una possibilità, allora il numero di ipotesi richieste è sempre solo una, il che è rassicurante.",
  "time_range": [
   1603.18,
   1615.0
  ]
 },
 {
  "input": "Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess, sometimes it required two more guesses.",
  "model": "nmt",
  "translatedText": "Ogni volta che c&#39;era un po&#39; di incertezza, il che significava che essenzialmente si riducevano a due possibilità, a volte richiedeva un&#39;altra ipotesi, a volte richiedeva altre due ipotesi.",
  "time_range": [
   1615.0,
   1623.94
  ]
 },
 {
  "input": "And so on and so forth here.",
  "model": "nmt",
  "translatedText": "E chi più ne ha più ne metta qui.",
  "time_range": [
   1623.94,
   1625.98
  ]
 },
 {
  "input": "Maybe a slightly easier way to visualize this data is to bucket it together and take averages.",
  "model": "nmt",
  "translatedText": "Forse un modo leggermente più semplice per visualizzare questi dati è raggrupparli insieme e fare delle medie.",
  "time_range": [
   1625.98,
   1631.02
  ]
 },
 {
  "input": "For example this bar here saying among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.5.",
  "model": "nmt",
  "translatedText": "Ad esempio, questa barra qui dice che tra tutti i punti in cui abbiamo avuto un po&#39; di incertezza, in media il numero di nuove ipotesi richieste era di circa 1.5.",
  "time_range": [
   1631.02,
   1642.42
  ]
 },
 {
  "input": "And the bar over here saying among all of the different games where at some point the uncertainty was a little above four bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward.",
  "model": "nmt",
  "translatedText": "E la barra qui dice che tra tutti i diversi giochi dove ad un certo punto l&#39;incertezza era poco più di quattro bit, che è come restringere il campo a 16 diverse possibilità, quindi in media richiede poco più di due ipotesi da quel punto inoltrare.",
  "time_range": [
   1642.42,
   1656.24
  ]
 },
 {
  "input": "And from here I just did a regression to fit a function that seemed reasonable to this.",
  "model": "nmt",
  "translatedText": "E da qui ho semplicemente fatto una regressione per adattare una funzione che mi sembrava ragionevole.",
  "time_range": [
   1656.24,
   1660.08
  ]
 },
 {
  "input": "And remember the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be.",
  "model": "nmt",
  "translatedText": "E ricorda che il punto centrale di tutto ciò è che possiamo quantificare questa intuizione che più informazioni otteniamo da una parola, più basso sarà il punteggio atteso.",
  "time_range": [
   1660.08,
   1669.72
  ]
 },
 {
  "input": "So with this as version 2.0, if we go back and we run the same set of simulations, having it play against all 2315 possible wordle answers, how does it do?",
  "model": "nmt",
  "translatedText": "Quindi con questo come versione 2.0, se torniamo indietro ed eseguiamo la stessa serie di simulazioni, facendola giocare contro tutte le 2315 possibili risposte di parole, come va?",
  "time_range": [
   1669.72,
   1679.82
  ]
 },
 {
  "input": "Well in contrast to our first version it's definitely better, which is reassuring.",
  "model": "nmt",
  "translatedText": "Beh, a differenza della nostra prima versione è decisamente migliore, il che è rassicurante.",
  "time_range": [
   1679.82,
   1684.06
  ]
 },
 {
  "input": "All said and done the average is around 3.6, although unlike the first version there are a couple times that it loses and requires more than six in this circumstance.",
  "model": "nmt",
  "translatedText": "Tutto sommato la media è intorno a 3.6, anche se a differenza della prima versione ci sono un paio di volte che perde e ne richiede più di sei in questa circostanza.",
  "time_range": [
   1684.06,
   1692.82
  ]
 },
 {
  "input": "Presumably because there's times when it's making that tradeoff to actually go for the goal rather than maximizing information.",
  "model": "nmt",
  "translatedText": "Presumibilmente perché ci sono momenti in cui è necessario fare quel compromesso per raggiungere effettivamente l&#39;obiettivo piuttosto che massimizzare le informazioni.",
  "time_range": [
   1692.82,
   1698.98
  ]
 },
 {
  "input": "So can we do better than 3.6?",
  "model": "nmt",
  "translatedText": "Quindi possiamo fare meglio di 3.6?",
  "time_range": [
   1698.98,
   1702.14
  ]
 },
 {
  "input": "We definitely can.",
  "model": "nmt",
  "translatedText": "Possiamo sicuramente.",
  "time_range": [
   1702.14,
   1703.26
  ]
 },
 {
  "input": "Now I said at the start that it's most fun to try not incorporating the true list of wordle answers into the way that it builds its model.",
  "model": "nmt",
  "translatedText": "Ora, all&#39;inizio ho detto che è molto divertente provare a non incorporare la vera lista delle risposte di Wordle nel modo in cui costruisce il suo modello.",
  "time_range": [
   1703.26,
   1709.98
  ]
 },
 {
  "input": "But if we do incorporate it, the best performance I could get was around 3.43.",
  "model": "nmt",
  "translatedText": "Ma se lo incorporiamo, la prestazione migliore che potrei ottenere è stata di circa 3.43.",
  "time_range": [
   1709.98,
   1715.18
  ]
 },
 {
  "input": "So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.43 probably gives a max at how good we could get with that, or at least how good I could get with that.",
  "model": "nmt",
  "translatedText": "Quindi, se proviamo a diventare più sofisticati rispetto al semplice utilizzo dei dati sulla frequenza delle parole per scegliere questa distribuzione a priori, questo 3.43 probabilmente dà un massimo di quanto bene potremmo ottenere con quello, o almeno quanto bene potrei ottenere con quello.",
  "time_range": [
   1715.18,
   1726.36
  ]
 },
 {
  "input": "That best performance essentially just uses the ideas that I've been talking about here, but it goes a little farther, like it does a search for the expected information two steps forward rather than just one.",
  "model": "nmt",
  "translatedText": "Quella prestazione migliore essenzialmente utilizza semplicemente le idee di cui ho parlato qui, ma va un po&#39; oltre, come se cercasse le informazioni attese due passi avanti anziché solo uno.",
  "time_range": [
   1726.36,
   1735.66
  ]
 },
 {
  "input": "Originally I was planning on talking more about that, but I realize we've actually gone quite long as it is.",
  "model": "nmt",
  "translatedText": "Inizialmente avevo intenzione di parlarne di più, ma mi rendo conto che in realtà siamo andati avanti piuttosto a lungo così com&#39;è.",
  "time_range": [
   1735.66,
   1740.58
  ]
 },
 {
  "input": "The one thing I'll say is after doing this two-step search and then running a couple sample simulations in the top candidates, so far for me at least it's looking like Crane is the best opener.",
  "model": "nmt",
  "translatedText": "L&#39;unica cosa che dirò è che dopo aver effettuato questa ricerca in due passaggi e aver eseguito un paio di simulazioni di esempio sui migliori candidati, finora almeno per me sembra che Crane sia il miglior apripista.",
  "time_range": [
   1740.58,
   1749.5
  ]
 },
 {
  "input": "Who would have guessed?",
  "model": "nmt",
  "translatedText": "Chi l&#39;avrebbe mai detto?",
  "time_range": [
   1749.5,
   1751.08
  ]
 },
 {
  "input": "Also if you use the true wordle list to determine your space of possibilities, then the uncertainty you start with is a little over 11 bits.",
  "model": "nmt",
  "translatedText": "Inoltre, se usi l&#39;elenco delle parole vere per determinare il tuo spazio di possibilità, l&#39;incertezza con cui inizi è poco più di 11 bit.",
  "time_range": [
   1751.08,
   1758.16
  ]
 },
 {
  "input": "And it turns out, just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits.",
  "model": "nmt",
  "translatedText": "E si scopre che, solo da una ricerca con forza bruta, la massima informazione possibile attesa dopo le prime due ipotesi è di circa 10 bit.",
  "time_range": [
   1758.16,
   1766.58
  ]
 },
 {
  "input": "Which suggests that best case scenario, after your first two guesses, with perfectly optimal play, you'll be left with around one bit of uncertainty.",
  "model": "nmt",
  "translatedText": "Il che suggerisce che, nella migliore delle ipotesi, dopo le prime due ipotesi, con un gioco perfettamente ottimale, rimarrai con circa un po&#39; di incertezza.",
  "time_range": [
   1766.58,
   1775.22
  ]
 },
 {
  "input": "Which is the same as being down to two possible guesses.",
  "model": "nmt",
  "translatedText": "Il che equivale ad avere solo due possibili ipotesi.",
  "time_range": [
   1775.22,
   1777.4
  ]
 },
 {
  "input": "So I think it's fair and probably pretty conservative to say that you could never possibly write an algorithm that gets this average as low as 3, because with the words available to you, there's simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.",
  "model": "nmt",
  "translatedText": "Quindi penso che sia giusto e probabilmente piuttosto prudente dire che non potresti mai scrivere un algoritmo che porti questa media fino a 3, perché con le parole a tua disposizione, semplicemente non c&#39;è spazio per ottenere informazioni sufficienti dopo solo due passaggi per essere in grado di garantire la risposta nella terza fascia ogni volta senza fallo.",
  "time_range": [
   1777.4,
   1790.46
  ]
 }
]