1
00:00:00,000 --> 00:00:03,137
지난 한두 달 동안 워들 게임은 꽤 입소문이 났고, 

2
00:00:03,137 --> 00:00:05,518
수학 수업의 기회를 간과할 수 없는데, 

3
00:00:05,518 --> 00:00:08,764
이 게임은 정보 이론, 특히 엔트로피라는 주제에 대한 

4
00:00:08,764 --> 00:00:12,010
수업에서 매우 좋은 중심 예시가 될 수 있다는 생각이 

5
00:00:12,010 --> 00:00:12,660
들었습니다.

6
00:00:13,920 --> 00:00:16,520
많은 사람들처럼 저도 퍼즐에 빠져들었고, 

7
00:00:16,520 --> 00:00:19,347
많은 프로그래머들처럼 게임을 최대한 최적으로 

8
00:00:19,347 --> 00:00:22,740
플레이할 수 있는 알고리즘을 작성하는 데 몰두했습니다.

9
00:00:23,180 --> 00:00:25,038
전체 알고리즘이 엔트로피라는 개념에 기반을 

10
00:00:25,038 --> 00:00:26,975
두고 있기 때문에, 제가 여기서 하고자 하는 

11
00:00:26,975 --> 00:00:29,066
것은 그 과정의 일부를 여러분과 함께 이야기하고 

12
00:00:29,066 --> 00:00:31,080
그 안에 들어간 수학에 대해 설명하는 것입니다.

13
00:00:38,700 --> 00:00:40,247
먼저, 아직 들어보지 못하신 분들을 

14
00:00:40,247 --> 00:00:41,640
위해 Wurdle이란 무엇인가요?

15
00:00:42,040 --> 00:00:44,893
게임의 규칙을 살펴보는 동안 일석이조의 효과를 

16
00:00:44,893 --> 00:00:47,857
거두기 위해 기본적으로 게임을 플레이할 수 있는 

17
00:00:47,857 --> 00:00:51,040
작은 알고리즘을 개발하는 것도 미리 말씀드리겠습니다.

18
00:00:51,360 --> 00:00:53,191
오늘의 워들은 아직 해보지는 않았지만 2월 

19
00:00:53,191 --> 00:00:55,100
4일에 봇이 어떻게 작동하는지 지켜보겠습니다.

20
00:00:55,480 --> 00:00:57,662
단어 맞추기의 목표는 수수께끼의 5글자 

21
00:00:57,662 --> 00:01:00,340
단어를 맞추는 것이며, 6번의 기회가 주어집니다.

22
00:01:00,840 --> 00:01:02,521
예를 들어, 제 워들 봇은 저에게 

23
00:01:02,521 --> 00:01:04,379
추측 크레인부터 시작하라고 제안합니다.

24
00:01:05,180 --> 00:01:07,590
추측을 할 때마다 추측이 정답에 얼마나 

25
00:01:07,590 --> 00:01:10,220
근접했는지에 대한 정보를 얻을 수 있습니다.

26
00:01:10,920 --> 00:01:12,558
여기서 회색 상자는 실제 답에 

27
00:01:12,558 --> 00:01:14,100
C가 없다는 것을 알려줍니다.

28
00:01:14,520 --> 00:01:16,222
노란색 상자에 R이 있다고 표시되어 

29
00:01:16,222 --> 00:01:17,840
있지만 해당 위치에 있지 않습니다.

30
00:01:18,240 --> 00:01:20,144
녹색 상자는 비밀 단어에 A가 있고 

31
00:01:20,144 --> 00:01:22,240
세 번째 위치에 있다는 것을 알려줍니다.

32
00:01:22,720 --> 00:01:24,580
그리고 N도 없고 E도 없습니다.

33
00:01:25,200 --> 00:01:26,241
그럼 제가 들어가서 Wurdle 

34
00:01:26,241 --> 00:01:27,340
봇에게 그 정보를 알려드리겠습니다.

35
00:01:27,340 --> 00:01:28,759
크레인으로 시작해서 회색, 노란색, 

36
00:01:28,759 --> 00:01:30,320
녹색, 회색, 회색, 회색을 얻었습니다.

37
00:01:31,420 --> 00:01:33,575
지금 표시되는 모든 데이터에 대해서는 걱정하지 마세요.

38
00:01:33,575 --> 00:01:34,940
 나중에 다시 설명해 드리겠습니다.

39
00:01:35,460 --> 00:01:37,410
하지만 두 번째로 추천하고 싶은 

40
00:01:37,410 --> 00:01:38,820
제품은 바로 슈틱입니다.

41
00:01:39,560 --> 00:01:42,090
그리고 실제 다섯 글자로 된 단어여야 하지만, 

42
00:01:42,090 --> 00:01:44,718
보시다시피 실제로 추측할 수 있는 단어는 상당히 

43
00:01:44,718 --> 00:01:45,400
자유롭습니다.

44
00:01:46,200 --> 00:01:47,440
이 경우에는 shtick을 시도합니다.

45
00:01:48,780 --> 00:01:50,180
상황이 꽤 좋아 보입니다.

46
00:01:50,260 --> 00:01:52,409
S와 H를 치면 처음 세 글자를 알 수 있고, 

47
00:01:52,409 --> 00:01:53,980
R이 있다는 것을 알 수 있습니다.

48
00:01:53,980 --> 00:01:56,340
따라서 S-H-A 무언가 R 또는 

49
00:01:56,340 --> 00:01:58,700
S-H-A 무언가처럼 될 것입니다.

50
00:01:59,620 --> 00:02:01,531
그리고 Wurdle 봇은 샤드 또는 샤프, 

51
00:02:01,531 --> 00:02:03,841
두 가지 가능성으로만 좁혀진다는 것을 알고 있는 것 

52
00:02:03,841 --> 00:02:04,240
같습니다.

53
00:02:05,100 --> 00:02:06,632
현재로서는 둘 중 어느 쪽이 맞는지 

54
00:02:06,632 --> 00:02:08,317
알 수 없으므로 알파벳순으로 되어 있기 

55
00:02:08,317 --> 00:02:10,080
때문에 샤드가 더 잘 어울릴 것 같습니다.

56
00:02:11,220 --> 00:02:13,780
만세, 실제 정답은 세 가지입니다.

57
00:02:14,600 --> 00:02:18,527
어떤 분의 표현을 빌리자면, 워들에서는 4번홀은 파, 

58
00:02:18,527 --> 00:02:20,360
3번홀은 버디라고 합니다.

59
00:02:20,680 --> 00:02:22,480
꽤 적절한 비유라고 생각합니다.

60
00:02:22,480 --> 00:02:25,317
4개를 얻으려면 꾸준히 게임을 해야 하지만, 

61
00:02:25,317 --> 00:02:27,020
확실히 미친 짓은 아닙니다.

62
00:02:27,180 --> 00:02:29,920
하지만 3초 안에 해내면 기분이 좋아집니다.

63
00:02:30,880 --> 00:02:33,335
그래서 이 글에서는 제가 처음부터 워들 봇에 어떻게 

64
00:02:33,335 --> 00:02:35,621
접근했는지에 대한 저의 생각 과정을 말씀드리고자 

65
00:02:35,621 --> 00:02:35,960
합니다.

66
00:02:36,480 --> 00:02:38,047
그리고 앞서 말했듯이 정보 이론 

67
00:02:38,047 --> 00:02:39,440
수업에 대한 변명일 뿐입니다.

68
00:02:39,740 --> 00:02:41,071
주요 목표는 정보란 무엇이고 

69
00:02:41,071 --> 00:02:42,820
엔트로피란 무엇인지 설명하는 것입니다.

70
00:02:48,220 --> 00:02:51,068
이 문제에 접근하면서 가장 먼저 생각한 것은 영어의 

71
00:02:51,068 --> 00:02:53,720
여러 글자의 상대적 빈도를 살펴보는 것이었습니다.

72
00:02:54,380 --> 00:02:56,917
그래서 가장 자주 등장하는 글자를 많이 맞추는 

73
00:02:56,917 --> 00:02:59,260
오프닝 추측이나 오프닝 추측 쌍이 있을까요?

74
00:02:59,960 --> 00:03:01,549
그리고 제가 꽤 좋아했던 것은 네일아트에 

75
00:03:01,549 --> 00:03:03,000
이어서 다른 작업을 하는 것이었습니다.

76
00:03:03,760 --> 00:03:05,876
문자를 누르면 초록색이나 노란색이 나오는데, 

77
00:03:05,876 --> 00:03:08,332
이는 항상 기분이 좋고 정보를 얻는다는 느낌이 들기 

78
00:03:08,332 --> 00:03:08,840
때문입니다.

79
00:03:09,340 --> 00:03:12,087
그러나 이러한 경우, 이러한 글자가 없는 단어를 찾는 

80
00:03:12,087 --> 00:03:14,835
경우는 매우 드물기 때문에, 치지 않고 항상 회색으로 

81
00:03:14,835 --> 00:03:17,400
표시되더라도 여전히 많은 정보를 얻을 수 있습니다.

82
00:03:18,140 --> 00:03:20,719
하지만 예를 들어 글자의 순서를 고려하지 않기 

83
00:03:20,719 --> 00:03:23,200
때문에 체계적이지 않은 느낌이 들기도 합니다.

84
00:03:23,560 --> 00:03:25,300
달팽이를 입력할 수 있는데 왜 네일을 입력하나요?

85
00:03:26,080 --> 00:03:27,500
끝에 S를 붙이는 것이 더 낫나요?

86
00:03:27,820 --> 00:03:28,680
잘 모르겠습니다.

87
00:03:29,240 --> 00:03:31,763
제 친구 중 한 명이 지친이라는 단어로 여는 것을 

88
00:03:31,763 --> 00:03:34,196
좋아한다고 말했는데, 그 단어에는 W와 Y 같은 

89
00:03:34,196 --> 00:03:36,540
흔하지 않은 글자가 들어 있어서 좀 놀랐습니다.

90
00:03:37,120 --> 00:03:39,000
하지만 그게 더 좋은 오프닝일 수도 있습니다.

91
00:03:39,320 --> 00:03:41,759
잠재적 추측의 품질을 판단하기 위해 

92
00:03:41,759 --> 00:03:44,320
부여할 수 있는 정량적 점수가 있나요?

93
00:03:45,340 --> 00:03:47,282
이제 가능한 추측의 순위를 매기는 방식을 

94
00:03:47,282 --> 00:03:49,393
설정하기 위해 돌아가서 게임이 정확히 어떻게 

95
00:03:49,393 --> 00:03:51,420
설정되는지 조금 더 명확하게 설명하겠습니다.

96
00:03:51,420 --> 00:03:54,774
따라서 유효한 추측으로 간주되는 입력할 수 있는 

97
00:03:54,774 --> 00:03:57,880
단어 목록은 약 13,000단어에 불과합니다.

98
00:03:58,320 --> 00:04:00,956
하지만 살펴보면 스크래블 게임에서 가족 간의 

99
00:04:00,956 --> 00:04:03,170
다툼을 유발하는 단어인 머리나 알리, 

100
00:04:03,170 --> 00:04:05,912
ARG와 같이 정말 흔하지 않은 단어들이 많이 

101
00:04:05,912 --> 00:04:06,440
있습니다.

102
00:04:06,960 --> 00:04:08,619
하지만 게임의 분위기는 항상 답은 

103
00:04:08,619 --> 00:04:10,540
꽤나 흔한 단어가 될 것이라는 것입니다.

104
00:04:10,960 --> 00:04:12,928
실제로 약 2300개의 단어로 

105
00:04:12,928 --> 00:04:15,360
구성된 또 다른 정답 목록이 있습니다.

106
00:04:15,940 --> 00:04:18,674
특히 게임 크리에이터인 여자친구가 직접 

107
00:04:18,674 --> 00:04:21,160
큐레이션한 목록이라 더욱 재미있어요.

108
00:04:21,820 --> 00:04:24,606
하지만 이 프로젝트의 과제는 이 목록에 대한 

109
00:04:24,606 --> 00:04:27,281
사전 지식을 포함하지 않고도 워드클을 푸는 

110
00:04:27,281 --> 00:04:30,180
프로그램을 작성할 수 있는지 알아보는 것입니다.

111
00:04:30,720 --> 00:04:32,725
우선, 이 목록에서 찾을 수 없는 매우 

112
00:04:32,725 --> 00:04:34,640
일반적인 5글자 단어가 많이 있습니다.

113
00:04:34,940 --> 00:04:36,946
따라서 공식 웹사이트가 아닌 좀 더 

114
00:04:36,946 --> 00:04:39,052
탄력적이고 누구나 워드프레스에 대응할 

115
00:04:39,052 --> 00:04:41,460
수 있는 프로그램을 작성하는 것이 좋습니다.

116
00:04:41,920 --> 00:04:44,316
또한 이 가능한 답변 목록이 무엇인지 알 수 

117
00:04:44,316 --> 00:04:47,000
있는 이유는 소스 코드에 표시되어 있기 때문입니다.

118
00:04:47,000 --> 00:04:49,640
하지만 소스 코드에 표시되는 방식은 매일 

119
00:04:49,640 --> 00:04:52,510
답변이 올라오는 구체적인 순서대로 표시되므로 

120
00:04:52,510 --> 00:04:55,840
언제든지 내일의 답변이 무엇인지 찾아볼 수 있습니다.

121
00:04:56,420 --> 00:04:57,650
따라서 목록을 사용하는 것이 

122
00:04:57,650 --> 00:04:58,880
부정 행위인 것은 분명합니다.

123
00:04:59,100 --> 00:05:01,809
더 흥미로운 퍼즐과 더 풍부한 정보 이론 수업을 

124
00:05:01,809 --> 00:05:04,418
만들기 위해서는 일반적으로 더 일반적인 단어를 

125
00:05:04,418 --> 00:05:07,027
선호한다는 직관을 포착하기 위해 상대적인 단어 

126
00:05:07,027 --> 00:05:09,938
빈도와 같은 좀 더 보편적인 데이터를 사용하는 것이 

127
00:05:09,938 --> 00:05:10,440
좋습니다.

128
00:05:11,600 --> 00:05:13,843
그렇다면 이 13,000개의 가능성 중에서 

129
00:05:13,843 --> 00:05:15,900
어떻게 첫 번째 추측을 선택해야 할까요?

130
00:05:16,400 --> 00:05:18,213
예를 들어, 친구가 피곤하다고 제안하면 

131
00:05:18,213 --> 00:05:19,780
그 품질을 어떻게 분석해야 하나요?

132
00:05:20,520 --> 00:05:22,933
그가 그 가능성이 희박한 W를 좋아한다고 

133
00:05:22,933 --> 00:05:25,031
말한 이유는 W를 맞혔을 때의 기분 

134
00:05:25,031 --> 00:05:27,340
좋은 롱샷의 특성을 좋아하기 때문입니다.

135
00:05:27,920 --> 00:05:30,266
예를 들어, 첫 번째 패턴이 이와 같은 

136
00:05:30,266 --> 00:05:32,826
패턴이라면 이 거대한 어휘집에 해당 패턴과 

137
00:05:32,826 --> 00:05:35,600
일치하는 단어는 58개뿐인 것으로 밝혀졌습니다.

138
00:05:36,060 --> 00:05:38,400
이는 13,000개에서 크게 줄어든 수치입니다.

139
00:05:38,780 --> 00:05:41,047
물론 그 반대편에는 이런 패턴이 발생하는 

140
00:05:41,047 --> 00:05:43,020
경우가 매우 드물다는 점도 있습니다.

141
00:05:43,020 --> 00:05:45,649
구체적으로 각 단어가 정답일 확률이 

142
00:05:45,649 --> 00:05:48,016
똑같다면 이 패턴을 맞출 확률은 

143
00:05:48,016 --> 00:05:51,040
58을 약 13,000으로 나눈 값입니다.

144
00:05:51,580 --> 00:05:53,600
물론 이러한 답변이 모두 정답일 가능성은 없습니다.

145
00:05:53,720 --> 00:05:56,220
이 중 대부분은 매우 모호하고 의심스러운 단어입니다.

146
00:05:56,600 --> 00:05:58,266
하지만 적어도 이 모든 것을 처음 시도할 

147
00:05:58,266 --> 00:05:59,933
때는 모두 똑같이 가능성이 있다고 가정한 

148
00:05:59,933 --> 00:06:01,600
다음 나중에 조금 더 구체화해 보겠습니다.

149
00:06:02,020 --> 00:06:04,550
요점은 정보가 많은 패턴은 본질적으로 

150
00:06:04,550 --> 00:06:06,720
발생할 가능성이 낮다는 것입니다.

151
00:06:07,280 --> 00:06:10,800
사실 정보를 제공한다는 것은 가능성이 낮다는 뜻입니다.

152
00:06:11,720 --> 00:06:13,689
이 오프닝에서 볼 수 있는 훨씬 더 

153
00:06:13,689 --> 00:06:15,953
가능성 있는 패턴은 다음과 같은 것인데, 

154
00:06:15,953 --> 00:06:18,120
물론 여기에는 W가 들어 있지 않습니다.

155
00:06:18,240 --> 00:06:19,790
E가 있을 수도 있고, A가 없을 수도 있고, 

156
00:06:19,790 --> 00:06:21,400
R이 없을 수도 있고, Y가 없을 수도 있습니다.

157
00:06:22,080 --> 00:06:24,560
이 경우 가능한 일치 항목은 1400개입니다.

158
00:06:25,080 --> 00:06:27,993
모두 같은 확률이라면 이런 패턴이 

159
00:06:27,993 --> 00:06:30,600
나타날 확률은 약 11%입니다.

160
00:06:30,900 --> 00:06:32,088
따라서 가장 가능성이 높은 결과가 

161
00:06:32,088 --> 00:06:33,340
가장 정보가 적은 결과이기도 합니다.

162
00:06:34,240 --> 00:06:37,552
보다 전체적인 관점을 파악하기 위해 다양한 

163
00:06:37,552 --> 00:06:41,140
패턴에 대한 전체 확률 분포를 보여드리겠습니다.

164
00:06:41,740 --> 00:06:44,263
따라서 보고 있는 각 막대는 표시될 수 있는 

165
00:06:44,263 --> 00:06:46,080
색상의 가능한 패턴에 해당하며, 

166
00:06:46,080 --> 00:06:48,503
이 중 3~5가지 가능성이 있으며 왼쪽에서 

167
00:06:48,503 --> 00:06:51,128
오른쪽으로 가장 흔한 것부터 가장 흔하지 않은 

168
00:06:51,128 --> 00:06:52,340
것 순으로 구성됩니다.

169
00:06:52,920 --> 00:06:54,578
따라서 여기서 가장 일반적인 가능성은 

170
00:06:54,578 --> 00:06:56,000
모두 회색으로 표시되는 것입니다.

171
00:06:56,100 --> 00:06:58,120
이는 약 14% 정도 발생합니다.

172
00:06:58,580 --> 00:07:01,220
그리고 여러분이 추측할 때 기대하는 것은 이 패턴과 

173
00:07:01,220 --> 00:07:03,951
일치할 수 있는 가능성이 18개밖에 없는 이 롱테일의 

174
00:07:03,951 --> 00:07:06,500
어딘가, 예를 들어 여기와 같은 곳에서 이 패턴과 

175
00:07:06,500 --> 00:07:09,140
일치하는 것이 분명히 이렇게 생겼으면 하는 것입니다.

176
00:07:09,920 --> 00:07:12,036
또는 왼쪽으로 조금 더 나아가면 

177
00:07:12,036 --> 00:07:13,800
여기까지 갈 수도 있습니다.

178
00:07:14,940 --> 00:07:16,180
자, 여기 좋은 퍼즐이 하나 있습니다.

179
00:07:16,540 --> 00:07:19,079
영어에서 W로 시작하고 Y로 끝나며 

180
00:07:19,079 --> 00:07:22,000
어딘가에 R이 있는 세 단어는 무엇인가요?

181
00:07:22,480 --> 00:07:24,640
알고 보니 그 답은 장황하고, 

182
00:07:24,640 --> 00:07:26,800
지루하고, 엉뚱한 것이었습니다.

183
00:07:27,500 --> 00:07:30,035
따라서 이 단어가 전반적으로 얼마나 좋은지 

184
00:07:30,035 --> 00:07:32,570
판단하려면 이 배포에서 얻을 수 있는 예상 

185
00:07:32,570 --> 00:07:35,740
정보의 양을 측정할 수 있는 일종의 척도가 필요합니다.

186
00:07:35,740 --> 00:07:38,433
각 패턴을 살펴보고 발생 확률에 해당 

187
00:07:38,433 --> 00:07:41,384
패턴이 얼마나 유익한지를 측정할 수 있는 

188
00:07:41,384 --> 00:07:44,720
값을 곱하면 객관적인 점수를 얻을 수 있습니다.

189
00:07:45,960 --> 00:07:47,941
이제 그 무언가가 무엇인지에 대한 첫 번째 

190
00:07:47,941 --> 00:07:49,840
직감은 일치하는 항목의 수일 수 있습니다.

191
00:07:50,160 --> 00:07:52,400
평균 일치 횟수를 낮추고 싶습니다.

192
00:07:52,800 --> 00:07:55,614
하지만 그 대신 우리가 흔히 정보에 부여하는 보다 

193
00:07:55,614 --> 00:07:57,524
보편적인 측정법을 사용하고 싶고, 

194
00:07:57,524 --> 00:08:00,138
이 13,000개의 단어 각각에 실제 정답인지 

195
00:08:00,138 --> 00:08:02,852
아닌지에 대해 다른 확률을 부여하면 더 유연하게 

196
00:08:02,852 --> 00:08:04,260
사용할 수 있을 것입니다.

197
00:08:10,320 --> 00:08:12,584
정보의 표준 단위는 비트이며, 

198
00:08:12,584 --> 00:08:16,047
약간 재미있는 공식이 있지만 예시만 보면 매우 

199
00:08:16,047 --> 00:08:16,980
직관적입니다.

200
00:08:17,780 --> 00:08:20,344
가능성의 공간을 반으로 줄이는 관찰이 있다면, 

201
00:08:20,344 --> 00:08:23,006
우리는 그 관찰이 한 가지 정보를 가지고 있다고 

202
00:08:23,006 --> 00:08:23,500
말합니다.

203
00:08:24,180 --> 00:08:26,721
이 예에서 가능성의 공간은 가능한 모든 단어이며, 

204
00:08:26,721 --> 00:08:29,444
다섯 글자 단어의 절반 정도에 S가 포함되어 있으며, 

205
00:08:29,444 --> 00:08:31,260
그보다 조금 적지만 절반 정도입니다.

206
00:08:31,780 --> 00:08:34,320
따라서 관찰을 통해 한 가지 정보를 얻을 수 있습니다.

207
00:08:34,880 --> 00:08:37,120
대신 새로운 사실이 그 가능성의 공간을 

208
00:08:37,120 --> 00:08:39,157
4배로 줄인다면, 우리는 그 정보가 

209
00:08:39,157 --> 00:08:41,500
두 비트의 정보를 가지고 있다고 말합니다.

210
00:08:41,980 --> 00:08:43,220
예를 들어, 이 단어의 약 4분의 1에 

211
00:08:43,220 --> 00:08:44,460
T가 포함되어 있는 것으로 나타났습니다.

212
00:08:45,020 --> 00:08:47,870
관찰 결과 그 공간이 8배로 줄어들면 3비트 정보라고 

213
00:08:47,870 --> 00:08:50,720
말하는 식으로, 이와 같은 방식으로 정보가 줄어듭니다.

214
00:08:50,900 --> 00:08:52,565
4비트는 16분의 1초, 5비트는 

215
00:08:52,565 --> 00:08:53,880
30분의 1초로 줄어듭니다.

216
00:08:54,960 --> 00:08:57,458
이제 잠시 멈춰서 비트 수에 대한 

217
00:08:57,458 --> 00:09:00,087
정보를 발생 확률로 표현하는 공식이 

218
00:09:00,087 --> 00:09:02,980
무엇인지 스스로에게 물어볼 수 있을까요?

219
00:09:03,920 --> 00:09:06,636
여기서 말하는 것은 기본적으로 비트 수에 

220
00:09:06,636 --> 00:09:09,116
절반을 취하면 확률과 같다는 것인데, 

221
00:09:09,116 --> 00:09:11,951
이는 비트 수의 제곱에 2를 곱하면 확률에 

222
00:09:11,951 --> 00:09:15,022
1을 더한 것과 같고, 이는 다시 정보가 1을 

223
00:09:15,022 --> 00:09:18,093
확률로 나눈 로그 기저 2라는 식으로 재구성할 

224
00:09:18,093 --> 00:09:18,920
수 있습니다.

225
00:09:19,620 --> 00:09:22,260
그리고 때로는 정보가 확률의 음의 로그 기저 2인 

226
00:09:22,260 --> 00:09:24,900
상태에서 한 번 더 재배열된 것을 볼 수 있습니다.

227
00:09:25,660 --> 00:09:28,631
이렇게 표현하면 처음 접하는 사람에게는 다소 이상하게 

228
00:09:28,631 --> 00:09:31,405
보일 수 있지만, 실제로는 가능성을 절반으로 줄인 

229
00:09:31,405 --> 00:09:34,080
횟수를 묻는 매우 직관적인 아이디어에 불과합니다.

230
00:09:35,180 --> 00:09:37,194
재미있는 단어 게임을 하는 줄 알았는데 

231
00:09:37,194 --> 00:09:39,300
왜 대수가 그림에 들어가는지 궁금하신가요?

232
00:09:39,780 --> 00:09:42,235
이것이 더 좋은 단위인 이유 중 하나는 매우 

233
00:09:42,235 --> 00:09:44,690
가능성이 낮은 사건에 대해 이야기하기가 훨씬 

234
00:09:44,690 --> 00:09:47,145
더 쉽기 때문입니다. 관측에 20비트 정보가 

235
00:09:47,145 --> 00:09:49,600
있다고 말하는 것이 이런 일이 발생할 확률이 

236
00:09:49,600 --> 00:09:52,056
0.0000095라고 말하는 것보다 훨씬 더 

237
00:09:52,056 --> 00:09:52,940
쉽기 때문입니다.

238
00:09:53,300 --> 00:09:56,149
하지만 이 로그 식이 확률 이론에 매우 

239
00:09:56,149 --> 00:09:58,610
유용한 것으로 밝혀진 더 실질적인 

240
00:09:58,610 --> 00:10:01,460
이유는 정보가 합산되는 방식 때문입니다.

241
00:10:02,060 --> 00:10:04,971
예를 들어, 한 번의 관찰로 2비트 정보를 

242
00:10:04,971 --> 00:10:07,034
얻어 공간을 4로 줄인 다음, 

243
00:10:07,034 --> 00:10:09,703
워들에서 두 번째 추측과 같은 두 번째 

244
00:10:09,703 --> 00:10:13,342
관찰로 3비트 정보를 얻어 공간을 8로 더 줄인다면, 

245
00:10:13,342 --> 00:10:16,740
두 가지를 합하면 5비트 정보를 얻을 수 있습니다.

246
00:10:17,160 --> 00:10:18,886
확률이 곱하기를 좋아하는 것과 

247
00:10:18,886 --> 00:10:21,020
마찬가지로 정보도 더하기를 좋아합니다.

248
00:10:21,960 --> 00:10:24,669
따라서 여러 숫자를 더하는 예상값과 같은 영역에 

249
00:10:24,669 --> 00:10:27,478
들어가면 로그를 사용하면 훨씬 더 쉽게 처리할 수 

250
00:10:27,478 --> 00:10:27,980
있습니다.

251
00:10:28,480 --> 00:10:30,504
웨어러블 분포로 돌아가서 여기에 작은 

252
00:10:30,504 --> 00:10:32,529
추적기를 하나 더 추가하여 각 패턴에 

253
00:10:32,529 --> 00:10:34,940
대한 정보가 얼마나 많은지 표시해 보겠습니다.

254
00:10:35,580 --> 00:10:38,055
가장 중요한 것은 가능성이 높은 패턴에 

255
00:10:38,055 --> 00:10:40,417
도달할수록 확률이 높아질수록 얻을 수 

256
00:10:40,417 --> 00:10:42,780
있는 정보의 양이 줄어든다는 점입니다.

257
00:10:43,500 --> 00:10:45,702
이 추측의 품질을 측정하는 방법은 

258
00:10:45,702 --> 00:10:48,020
이 정보의 예상값을 취하는 것입니다.

259
00:10:48,420 --> 00:10:51,182
각 패턴을 살펴볼 때 확률이 얼마나 되는지 

260
00:10:51,182 --> 00:10:54,060
말한 다음 여기에 몇 비트의 정보를 곱합니다.

261
00:10:54,710 --> 00:10:58,120
지친의 예에서는 4.9비트로 밝혀졌습니다.

262
00:10:58,560 --> 00:11:00,866
따라서 평균적으로 이 오프닝 추측을 통해 

263
00:11:00,866 --> 00:11:03,273
얻을 수 있는 정보는 가능성의 공간을 5배 

264
00:11:03,273 --> 00:11:05,480
정도 반으로 줄이는 것과 마찬가지입니다.

265
00:11:05,960 --> 00:11:08,929
반대로 예상 정보 가치가 더 높은 추측의 

266
00:11:08,929 --> 00:11:11,640
예로는 슬레이트와 같은 것이 있습니다.

267
00:11:13,120 --> 00:11:14,370
이 경우 분포가 훨씬 평평해 

268
00:11:14,370 --> 00:11:15,620
보이는 것을 알 수 있습니다.

269
00:11:15,940 --> 00:11:19,005
특히 모든 회색 중 가장 발생 가능성이 높은 

270
00:11:19,005 --> 00:11:22,194
회색의 경우 발생 확률이 약 6%에 불과하므로 

271
00:11:22,194 --> 00:11:25,260
최소한 3.9비트의 정보를 얻을 수 있습니다.

272
00:11:25,920 --> 00:11:27,177
하지만 이는 최소한이며, 일반적으로 

273
00:11:27,177 --> 00:11:28,560
그보다 더 나은 것을 얻을 수 있습니다.

274
00:11:29,100 --> 00:11:32,500
그리고 이 숫자를 분석하고 관련 용어를 모두 

275
00:11:32,500 --> 00:11:35,900
합치면 평균 5.8개 정도의 정보가 나옵니다.

276
00:11:37,360 --> 00:11:39,154
따라서 지친 것과는 대조적으로, 

277
00:11:39,154 --> 00:11:41,048
이 첫 번째 추측 후에는 가능성의 

278
00:11:41,048 --> 00:11:43,540
공간이 평균적으로 절반 정도 줄어들게 됩니다.

279
00:11:44,420 --> 00:11:46,310
사실 이 정보량의 예상 값에 대한 

280
00:11:46,310 --> 00:11:48,300
이름에는 재미있는 이야기가 있습니다.

281
00:11:48,300 --> 00:11:51,260
정보 이론은 1940년대 벨 연구소에서 일하던 

282
00:11:51,260 --> 00:11:53,424
클로드 섀넌에 의해 개발되었는데, 

283
00:11:53,424 --> 00:11:56,385
그는 당시 수학과 물리학 분야에서 매우 저명한 

284
00:11:56,385 --> 00:11:59,346
지적 거인이자 컴퓨터 과학의 시작이었던 존 폰 

285
00:11:59,346 --> 00:12:02,193
노이만과 아직 발표되지 않은 아이디어에 대해 

286
00:12:02,193 --> 00:12:03,560
이야기하고 있었습니다.

287
00:12:04,100 --> 00:12:07,341
폰 노이만은 이 정보량의 기대값에 대한 적절한 

288
00:12:07,341 --> 00:12:11,082
이름이 없다고 언급하면서 두 가지 이유로 엔트로피라고 

289
00:12:11,082 --> 00:12:14,200
부르는 것이 좋겠다고 말한 것으로 추정됩니다.

290
00:12:14,540 --> 00:12:17,384
우선 불확실성 함수는 통계 역학에서 그 이름으로 

291
00:12:17,384 --> 00:12:19,596
사용되었기 때문에 이미 이름이 있고, 

292
00:12:19,596 --> 00:12:22,756
두 번째로 더 중요한 것은 엔트로피가 실제로 무엇인지 

293
00:12:22,756 --> 00:12:25,811
아무도 모르기 때문에 토론에서 항상 우위를 점할 수 

294
00:12:25,811 --> 00:12:26,760
있다는 것입니다.

295
00:12:27,700 --> 00:12:30,033
따라서 이름이 다소 미스터리하게 느껴지고 이 

296
00:12:30,033 --> 00:12:32,460
이야기를 믿어야 한다면 그것은 의도된 것입니다.

297
00:12:33,280 --> 00:12:36,367
또한 물리학의 열역학 제2법칙과 어떤 관련이 

298
00:12:36,367 --> 00:12:39,701
있는지 궁금하신 분들은 분명히 연관성이 있지만, 

299
00:12:39,701 --> 00:12:43,035
원래 섀넌은 순수한 확률 이론을 다루고 있었고, 

300
00:12:43,035 --> 00:12:46,122
여기서 제가 엔트로피라는 단어를 사용할 때는 

301
00:12:46,122 --> 00:12:49,580
특정 추측의 예상 정보 값을 생각해주셨으면 합니다.

302
00:12:50,700 --> 00:12:52,068
엔트로피는 두 가지를 동시에 

303
00:12:52,068 --> 00:12:53,780
측정하는 것으로 생각할 수 있습니다.

304
00:12:54,240 --> 00:12:56,780
첫 번째는 분포가 얼마나 평평한가입니다.

305
00:12:57,320 --> 00:13:01,120
분포가 균일함에 가까울수록 엔트로피가 높아집니다.

306
00:13:01,580 --> 00:13:05,139
총 패턴이 3개에서 5번째까지 있는 경우, 

307
00:13:05,139 --> 00:13:08,995
균등 분포의 경우 그 중 하나를 관찰하면 정보 

308
00:13:08,995 --> 00:13:12,554
로그 기저 2가 3에서 5번째로 7.92가 

309
00:13:12,554 --> 00:13:16,706
되므로 이 엔트로피가 가질 수 있는 절대 최대값이 

310
00:13:16,706 --> 00:13:17,300
됩니다.

311
00:13:17,840 --> 00:13:19,775
하지만 엔트로피는 애초에 얼마나 많은 

312
00:13:19,775 --> 00:13:22,080
가능성이 있는지를 나타내는 척도이기도 합니다.

313
00:13:22,320 --> 00:13:25,418
예를 들어, 가능한 패턴이 16개뿐이고 

314
00:13:25,418 --> 00:13:28,517
각각의 가능성이 동일한 단어가 있다면, 

315
00:13:28,517 --> 00:13:32,180
이 엔트로피, 즉 예상 정보는 4비트가 됩니다.

316
00:13:32,580 --> 00:13:35,252
하지만 64개의 가능한 패턴이 있고 모두 

317
00:13:35,252 --> 00:13:37,575
동일한 확률로 나타날 수 있는 다른 

318
00:13:37,575 --> 00:13:40,480
단어가 있다면 엔트로피는 6비트로 계산됩니다.

319
00:13:41,500 --> 00:13:44,191
따라서 엔트로피가 6비트인 분포가 야생에서 

320
00:13:44,191 --> 00:13:47,219
발견된다면, 이는 마치 64개의 똑같이 가능성이 

321
00:13:47,219 --> 00:13:50,023
높은 결과가 있는 것처럼 앞으로 일어날 일에 

322
00:13:50,023 --> 00:13:52,939
많은 변화와 불확실성이 존재한다고 말하는 것과 

323
00:13:52,939 --> 00:13:53,500
같습니다.

324
00:13:54,360 --> 00:13:55,914
Wurtelebot에서의 첫 번째 

325
00:13:55,914 --> 00:13:57,960
패스에서는 기본적으로 이렇게 하도록 했습니다.

326
00:13:57,960 --> 00:14:01,336
13,000개의 단어에 대해 가능한 모든 다른 

327
00:14:01,336 --> 00:14:04,452
추측을 검토하고 각 단어에 대한 엔트로피, 

328
00:14:04,452 --> 00:14:07,959
더 구체적으로는 각 단어에 대해 나타날 수 있는 

329
00:14:07,959 --> 00:14:11,465
모든 패턴에 대한 분포의 엔트로피를 계산한 다음 

330
00:14:11,465 --> 00:14:14,971
가능성의 공간을 최대한 줄일 수 있는 가장 높은 

331
00:14:14,971 --> 00:14:16,140
것을 선택합니다.

332
00:14:17,140 --> 00:14:18,952
여기서는 첫 번째 추측에 대해서만 이야기했지만, 

333
00:14:18,952 --> 00:14:20,697
다음 몇 가지 추측에 대해서도 동일한 방식으로 

334
00:14:20,697 --> 00:14:21,100
작동합니다.

335
00:14:21,560 --> 00:14:23,923
예를 들어, 첫 번째 추측에서 어떤 패턴을 

336
00:14:23,923 --> 00:14:26,384
발견한 후, 그 패턴과 일치하는 단어에 따라 

337
00:14:26,384 --> 00:14:28,550
가능한 단어의 수를 더 적게 제한하면, 

338
00:14:28,550 --> 00:14:30,815
그 적은 단어 집합에 대해 동일한 게임을 

339
00:14:30,815 --> 00:14:31,800
플레이하면 됩니다.

340
00:14:32,260 --> 00:14:34,228
제안된 두 번째 추측의 경우, 

341
00:14:34,228 --> 00:14:37,007
보다 제한된 단어 집합에서 발생할 수 있는 

342
00:14:37,007 --> 00:14:39,902
모든 패턴의 분포를 살펴보고 13,000개의 

343
00:14:39,902 --> 00:14:42,797
모든 가능성을 검색하여 엔트로피를 최대화하는 

344
00:14:42,797 --> 00:14:43,840
패턴을 찾습니다.

345
00:14:45,420 --> 00:14:47,701
이것이 실제로 어떻게 작동하는지 보여드리기 위해 

346
00:14:47,701 --> 00:14:49,814
여백에 이 분석의 하이라이트를 보여주는 제가 

347
00:14:49,814 --> 00:14:52,180
작성한 Wurtele의 작은 변형을 띄워보겠습니다.

348
00:14:53,680 --> 00:14:56,726
따라서 모든 엔트로피 계산을 수행한 후 오른쪽에 

349
00:14:56,726 --> 00:14:59,660
가장 높은 예상 정보를 가진 항목이 표시됩니다.

350
00:15:00,280 --> 00:15:05,329
적어도 현재로서는 가장 정답인 가라지가 가장 

351
00:15:05,329 --> 00:15:10,580
일반적인 가라지를 의미하는 것으로 밝혀졌습니다.

352
00:15:11,040 --> 00:15:13,418
여기서 추측을 할 때마다, 예를 들어 내가 

353
00:15:13,418 --> 00:15:16,094
슬레이트를 좋아하기 때문에 권장 사항을 무시하고 

354
00:15:16,094 --> 00:15:18,770
슬레이트로 갈 때마다 예상 정보가 얼마나 많은지 

355
00:15:18,770 --> 00:15:21,248
볼 수 있지만 여기 단어 오른쪽에는 이 특정 

356
00:15:21,248 --> 00:15:23,825
패턴이 주어졌을 때 실제 정보가 얼마나 많은지 

357
00:15:23,825 --> 00:15:24,420
표시됩니다.

358
00:15:25,000 --> 00:15:27,511
5.8점을 받을 것으로 예상했는데 그보다 낮은 

359
00:15:27,511 --> 00:15:30,120
점수를 받은 것은 조금 운이 나빴던 것 같습니다.

360
00:15:30,600 --> 00:15:32,915
그리고 여기 왼쪽에는 현재 위치에 따라 

361
00:15:32,915 --> 00:15:35,020
가능한 모든 다른 단어가 표시됩니다.

362
00:15:35,800 --> 00:15:38,146
파란색 막대는 각 단어의 발생 가능성을 알려주는 

363
00:15:38,146 --> 00:15:40,579
것으로, 현재는 각 단어가 똑같이 발생할 가능성이 

364
00:15:40,579 --> 00:15:42,925
있다고 가정하고 있지만 잠시 후에 이를 구체화할 

365
00:15:42,925 --> 00:15:43,360
것입니다.

366
00:15:44,060 --> 00:15:46,911
그리고 이 불확실성 측정은 가능한 단어에 

367
00:15:46,911 --> 00:15:49,638
대한 이 분포의 엔트로피를 알려주는데, 

368
00:15:49,638 --> 00:15:52,737
지금은 균일한 분포이기 때문에 가능성의 수를 

369
00:15:52,737 --> 00:15:55,960
계산하는 데 불필요하게 복잡한 방법일 뿐입니다.

370
00:15:56,560 --> 00:15:59,125
예를 들어 2를 13.66의 제곱으로 

371
00:15:59,125 --> 00:16:02,180
나누면 약 13,000개의 가능성이 있습니다.

372
00:16:02,900 --> 00:16:04,751
소수점 이하 자릿수를 모두 표시하지 

373
00:16:04,751 --> 00:16:06,140
않아서 그런 것일 뿐입니다.

374
00:16:06,720 --> 00:16:08,542
당장은 중복되는 것 같고 지나치게 복잡하게 

375
00:16:08,542 --> 00:16:10,441
느껴질 수 있지만, 잠시 후 두 번호를 모두 

376
00:16:10,441 --> 00:16:12,340
사용하는 것이 왜 유용한지 알게 될 것입니다.

377
00:16:12,760 --> 00:16:14,913
따라서 여기서 두 번째로 추측한 엔트로피가 

378
00:16:14,913 --> 00:16:17,605
가장 높은 것은 라만이라고 제안하는 것처럼 보이는데, 

379
00:16:17,605 --> 00:16:19,400
이 역시 단어처럼 느껴지지 않습니다.

380
00:16:19,980 --> 00:16:21,854
도덕적으로 유리한 입장에 서기 

381
00:16:21,854 --> 00:16:24,060
위해 Rains를 입력해 보겠습니다.

382
00:16:25,440 --> 00:16:27,340
이번에도 운이 나빴던 것 같습니다.

383
00:16:27,520 --> 00:16:31,360
4.3비트를 예상했는데 3.39비트만 받았습니다.

384
00:16:31,940 --> 00:16:33,940
따라서 55가지의 가능성이 있습니다.

385
00:16:34,900 --> 00:16:37,260
그리고 여기서는 콤보가 의미하는 바가 무엇이든 

386
00:16:37,260 --> 00:16:39,440
간에 실제로 제안하는 대로 따라갈 것입니다.

387
00:16:40,040 --> 00:16:41,659
그리고 이것은 사실 퍼즐을 맞출 

388
00:16:41,659 --> 00:16:42,920
수 있는 좋은 기회입니다.

389
00:16:42,920 --> 00:16:46,380
이 패턴은 4.7비트 정보를 제공합니다.

390
00:16:47,060 --> 00:16:49,500
하지만 왼쪽에서 이 패턴을 보기 전에는 

391
00:16:49,500 --> 00:16:51,720
5.78비트의 불확실성이 있었습니다.

392
00:16:52,420 --> 00:16:54,495
그렇다면 퀴즈로서 남은 가능성의 

393
00:16:54,495 --> 00:16:56,340
수에 대한 의미는 무엇일까요?

394
00:16:58,040 --> 00:17:01,098
즉, 불확실성이 1로 줄어든다는 의미인데, 

395
00:17:01,098 --> 00:17:04,540
이는 두 가지 가능한 답이 있다는 말과 같습니다.

396
00:17:04,700 --> 00:17:05,700
50대 50의 선택입니다.

397
00:17:06,500 --> 00:17:08,534
여기서부터 여러분과 저는 어떤 단어가 더 일반적인지 

398
00:17:08,534 --> 00:17:10,640
알고 있기 때문에 심연이 답이라는 것을 알고 있습니다.

399
00:17:11,180 --> 00:17:13,280
하지만 지금 작성된 프로그램에서는 이를 알지 못합니다.

400
00:17:13,540 --> 00:17:15,746
따라서 가능한 한 많은 정보를 얻으려고 

401
00:17:15,746 --> 00:17:17,853
계속 노력하여 한 가지 가능성만 남을 

402
00:17:17,853 --> 00:17:19,859
때까지 계속 시도한 다음 추측합니다.

403
00:17:20,380 --> 00:17:22,938
물론 더 나은 최종 게임 전략이 필요하지만, 

404
00:17:22,938 --> 00:17:25,701
이 워드 솔버 버전 1이라고 부르고 시뮬레이션을 

405
00:17:25,701 --> 00:17:28,260
실행하여 어떻게 작동하는지 확인해 보겠습니다.

406
00:17:30,360 --> 00:17:32,357
따라서 이 방식은 가능한 모든 

407
00:17:32,357 --> 00:17:34,120
단어 게임을 하는 것입니다.

408
00:17:34,240 --> 00:17:36,492
2315개의 단어 중 실제 단어 답변인 

409
00:17:36,492 --> 00:17:38,540
2315개의 단어를 모두 검토합니다.

410
00:17:38,540 --> 00:17:40,580
기본적으로 이를 테스트 세트로 사용하고 있습니다.

411
00:17:41,360 --> 00:17:44,144
그리고 단어가 얼마나 흔한지 고려하지 않고 각 

412
00:17:44,144 --> 00:17:46,714
단계에서 정보를 최대화하려고만 하는 순진한 

413
00:17:46,714 --> 00:17:49,820
방법으로 단 하나의 선택지가 나올 때까지 기다립니다.

414
00:17:50,360 --> 00:17:52,122
시뮬레이션이 끝날 무렵, 평균 

415
00:17:52,122 --> 00:17:54,300
점수는 약 4.124점으로 나왔습니다.

416
00:17:55,320 --> 00:17:57,531
솔직히 말해서 나쁘지 않은 수준이지만, 

417
00:17:57,531 --> 00:17:59,240
더 나빠질 것으로 예상했습니다.

418
00:17:59,660 --> 00:18:01,249
하지만 워들 플레이를 하는 사람들은 

419
00:18:01,249 --> 00:18:02,600
보통 4분이면 된다고 말합니다.

420
00:18:02,860 --> 00:18:05,380
진짜 도전은 가능한 한 많은 3개를 얻는 것입니다.

421
00:18:05,380 --> 00:18:08,080
4점과 3점 사이에는 꽤 큰 차이가 있습니다.

422
00:18:08,860 --> 00:18:11,724
여기서 가장 중요한 것은 단어의 일반화 

423
00:18:11,724 --> 00:18:14,980
여부와 그 방법을 어떻게든 통합하는 것입니다.

424
00:18:22,800 --> 00:18:25,714
제가 접근한 방식은 영어의 모든 단어에 대한 상대적 

425
00:18:25,714 --> 00:18:27,623
빈도 목록을 가져오는 것이었는데, 

426
00:18:27,623 --> 00:18:30,437
그 자체로 구글 북스 영어 Ngram 공개 데이터 

427
00:18:30,437 --> 00:18:33,352
세트에서 가져오는 Mathematica의 단어 빈도 

428
00:18:33,352 --> 00:18:34,860
데이터 함수를 사용했습니다.

429
00:18:35,460 --> 00:18:37,796
예를 들어 가장 흔한 단어부터 가장 흔하지 않은 

430
00:18:37,796 --> 00:18:39,960
단어까지 정렬해 보면 보는 재미가 쏠쏠합니다.

431
00:18:40,120 --> 00:18:41,647
분명히 이들은 영어에서 가장 

432
00:18:41,647 --> 00:18:43,080
일반적인 5글자 단어입니다.

433
00:18:43,700 --> 00:18:45,840
오히려 8번째로 흔한 유형입니다.

434
00:18:46,280 --> 00:18:47,503
첫 번째는 어떤 것이고, 그 

435
00:18:47,503 --> 00:18:48,880
다음에는 저기와 저기가 있습니다.

436
00:18:49,260 --> 00:18:51,893
첫 번째 자체는 첫 번째가 아니라 9번째이며, 

437
00:18:51,893 --> 00:18:54,122
첫 번째 뒤에 오는 것은 다음, 어디, 

438
00:18:54,122 --> 00:18:56,553
그리고 조금 덜 흔한 다른 단어가 더 자주 

439
00:18:56,553 --> 00:18:58,580
나올 수 있다는 것이 이해가 됩니다.

440
00:18:59,160 --> 00:19:02,029
이제 이 데이터를 사용하여 각 단어가 최종 

441
00:19:02,029 --> 00:19:04,300
정답이 될 가능성을 모델링할 때, 

442
00:19:04,300 --> 00:19:07,289
예를 들어 이 데이터 세트에서 0.002점을 

443
00:19:07,289 --> 00:19:10,278
받은 단어는 어떤 의미에서는 약 1000배나 

444
00:19:10,278 --> 00:19:13,625
낮은 점수를 받았기 때문에 단순히 빈도에 비례하는 

445
00:19:13,625 --> 00:19:15,060
것이 아니어야 합니다.

446
00:19:15,560 --> 00:19:17,254
하지만 이 두 단어는 모두 충분히 

447
00:19:17,254 --> 00:19:19,216
흔한 단어이므로 고려할 가치가 있으므로 

448
00:19:19,216 --> 00:19:21,000
이분법적인 컷오프가 더 바람직합니다.

449
00:19:21,860 --> 00:19:25,751
제가 생각한 방식은 이 정렬된 단어 목록을 X축에 

450
00:19:25,751 --> 00:19:29,643
정렬한 다음, 기본적으로 출력이 0이거나 1이면서 

451
00:19:29,643 --> 00:19:33,812
불확실한 영역에 대해 그 사이에 평활화가 있는 함수를 

452
00:19:33,812 --> 00:19:37,287
갖는 표준 방식인 시그모이드 함수를 적용하는 

453
00:19:37,287 --> 00:19:38,260
것이었습니다.

454
00:19:39,160 --> 00:19:42,345
따라서 기본적으로 각 단어가 최종 목록에 

455
00:19:42,345 --> 00:19:45,669
포함될 확률은 해당 단어가 X축에 위치하는 

456
00:19:45,669 --> 00:19:48,440
위의 시그모이드 함수의 값이 됩니다.

457
00:19:49,520 --> 00:19:52,280
물론 이것은 몇 가지 매개변수에 따라 달라지는데, 

458
00:19:52,280 --> 00:19:54,646
예를 들어 단어가 채우는 X축의 공간 폭에 

459
00:19:54,646 --> 00:19:57,013
따라 1에서 0까지 얼마나 점진적으로 또는 

460
00:19:57,013 --> 00:19:58,787
가파르게 떨어지느냐가 결정되고, 

461
00:19:58,787 --> 00:20:01,055
왼쪽에서 오른쪽으로 배치하는 위치에 따라 

462
00:20:01,055 --> 00:20:02,140
컷오프가 결정됩니다.

463
00:20:02,980 --> 00:20:04,709
솔직히 말해서 제가 했던 방식은 

464
00:20:04,709 --> 00:20:06,920
손가락을 핥아서 바람에 꽂는 것이었습니다.

465
00:20:07,140 --> 00:20:10,175
정렬된 목록을 살펴보고 이 단어들 중 절반 

466
00:20:10,175 --> 00:20:13,337
정도가 최종 정답일 가능성이 높다고 생각되는 

467
00:20:13,337 --> 00:20:16,120
창을 찾아서 이를 컷오프로 사용했습니다.

468
00:20:17,100 --> 00:20:19,075
이제 단어 전체에 걸쳐 이와 같은 

469
00:20:19,075 --> 00:20:21,156
분포를 가지게 되면 엔트로피가 매우 

470
00:20:21,156 --> 00:20:23,860
유용한 측정값이 되는 또 다른 상황이 생깁니다.

471
00:20:24,500 --> 00:20:26,500
예를 들어, 게임을 하다가 다른, 

472
00:20:26,500 --> 00:20:29,238
손톱이라는 기존 오프너로 시작했는데 이 단어와 

473
00:20:29,238 --> 00:20:32,186
일치하는 단어가 네 개가 나오는 상황이 발생했다고 

474
00:20:32,186 --> 00:20:33,240
가정해 보겠습니다.

475
00:20:33,560 --> 00:20:36,663
이 모든 가능성을 똑같이 고려한다고 가정했을 때, 

476
00:20:36,663 --> 00:20:38,880
이 분포의 엔트로피는 어떻게 될까요?

477
00:20:41,080 --> 00:20:45,760
이러한 각 가능성과 관련된 정보는 각각이 1과 

478
00:20:45,760 --> 00:20:50,260
4이므로 4의 로그 베이스 2가 될 것입니다.

479
00:20:50,640 --> 00:20:52,460
2비트 정보, 4가지 가능성.

480
00:20:52,760 --> 00:20:53,580
모두 아주 훌륭하고 좋습니다.

481
00:20:54,300 --> 00:20:56,152
하지만 실제로 경기 수가 4개가 

482
00:20:56,152 --> 00:20:57,800
넘는다고 하면 어떻게 될까요?

483
00:20:58,260 --> 00:21:00,416
실제로 전체 단어 목록을 살펴보면 

484
00:21:00,416 --> 00:21:02,460
일치하는 단어가 16개나 됩니다.

485
00:21:02,580 --> 00:21:05,148
하지만 우리 모델이 다른 12개의 단어가 실제로 

486
00:21:05,148 --> 00:21:07,906
최종 정답이 될 확률이 1000분의 1 정도로 매우 

487
00:21:07,906 --> 00:21:10,760
낮다고 가정해 보겠습니다(예: 정말 모호하기 때문에).

488
00:21:11,500 --> 00:21:14,260
이제 이 분포의 엔트로피가 얼마인지 물어볼까요?

489
00:21:15,420 --> 00:21:17,908
여기서 엔트로피가 순전히 일치하는 개수를 

490
00:21:17,908 --> 00:21:20,505
측정하는 것이라면, 16의 로그 기저 2와 

491
00:21:20,505 --> 00:21:22,994
같은 값으로, 이전보다 불확실성이 2비트 

492
00:21:22,994 --> 00:21:25,700
더 많은 4가 될 것으로 예상할 수 있습니다.

493
00:21:26,180 --> 00:21:29,860
물론 실제 불확실성은 이전과 크게 다르지 않습니다.

494
00:21:30,160 --> 00:21:32,455
예를 들어, 이 12개의 모호한 단어가 

495
00:21:32,455 --> 00:21:34,960
있다고 해서 최종 정답이 매력이라는 사실을 

496
00:21:34,960 --> 00:21:37,360
알게 된다면 그다지 놀랍지 않을 것입니다.

497
00:21:38,180 --> 00:21:41,954
따라서 실제로 여기서 계산을 수행하고 각 발생 

498
00:21:41,954 --> 00:21:46,020
확률에 해당 정보를 더하면 2.11비트가 나옵니다.

499
00:21:46,020 --> 00:21:48,383
기본적으로 두 가지, 기본적으로 네 가지 

500
00:21:48,383 --> 00:21:51,054
가능성이 있지만, 가능성이 매우 낮은 이벤트가 

501
00:21:51,054 --> 00:21:53,725
모두 있기 때문에 불확실성이 조금 더 있지만, 

502
00:21:53,725 --> 00:21:56,500
이를 알게 된다면 많은 정보를 얻을 수 있습니다.

503
00:21:57,160 --> 00:21:59,280
축소해서 보면, 이것이 바로 Wordle이 정보 

504
00:21:59,280 --> 00:22:01,400
이론 수업의 좋은 예가 되는 이유 중 하나입니다.

505
00:22:01,600 --> 00:22:04,640
엔트로피에 대한 두 가지 느낌의 적용이 있습니다.

506
00:22:05,160 --> 00:22:08,273
첫 번째는 주어진 추측에서 얻을 수 있는 예상 

507
00:22:08,273 --> 00:22:11,627
정보가 무엇인지 알려주고, 두 번째는 가능한 모든 

508
00:22:11,627 --> 00:22:14,741
단어 중에서 남은 불확실성을 측정할 수 있는지 

509
00:22:14,741 --> 00:22:15,460
알려줍니다.

510
00:22:16,460 --> 00:22:19,187
그리고 첫 번째 경우, 추측에 대한 예상 정보를 

511
00:22:19,187 --> 00:22:21,914
살펴볼 때 단어에 가중치가 같지 않으면 엔트로피 

512
00:22:21,914 --> 00:22:24,540
계산에 영향을 미친다는 점을 강조하고 싶습니다.

513
00:22:24,980 --> 00:22:27,776
예를 들어, 앞서 살펴본 '지친'과 관련된 

514
00:22:27,776 --> 00:22:30,573
분포의 동일한 사례를 이번에는 가능한 모든 

515
00:22:30,573 --> 00:22:33,720
단어에 걸쳐 균일하지 않은 분포를 사용하겠습니다.

516
00:22:34,500 --> 00:22:38,280
그럼 여기서 이를 잘 설명하는 부분을 찾아보겠습니다.

517
00:22:40,940 --> 00:22:42,360
자, 여기, 꽤 괜찮습니다.

518
00:22:42,360 --> 00:22:44,606
여기에는 거의 같은 확률로 인접한 두 

519
00:22:44,606 --> 00:22:46,746
개의 패턴이 있지만, 그 중 하나는 

520
00:22:46,746 --> 00:22:49,100
일치하는 단어가 32개나 된다고 합니다.

521
00:22:49,280 --> 00:22:51,649
그리고 그 단어들이 무엇인지 확인해 보면, 

522
00:22:51,649 --> 00:22:53,723
이 32개 단어는 모두 눈을 훑어보면 

523
00:22:53,723 --> 00:22:55,600
가능성이 매우 희박한 단어들입니다.

524
00:22:55,840 --> 00:22:58,471
그럴듯한 답변처럼 느껴지는 것을 찾기는 어렵고, 

525
00:22:58,471 --> 00:23:00,323
어쩌면 비명을 지르는 것 같지만, 

526
00:23:00,323 --> 00:23:03,053
가능성이 거의 비슷한 것으로 간주되는 분포의 이웃 

527
00:23:03,053 --> 00:23:05,782
패턴을 보면 일치하는 항목이 8개밖에 없다는 것을 

528
00:23:05,782 --> 00:23:06,660
알 수 있습니다.

529
00:23:06,880 --> 00:23:08,235
따라서 경기 수는 4분의 1이지만 

530
00:23:08,235 --> 00:23:09,520
그 정도는 될 가능성이 높습니다.

531
00:23:09,860 --> 00:23:11,036
그리고 그 경기 결과를 보면 

532
00:23:11,036 --> 00:23:12,140
그 이유를 알 수 있습니다.

533
00:23:12,500 --> 00:23:14,300
이 중 일부는 링이나 분노 또는 

534
00:23:14,300 --> 00:23:16,300
랩과 같은 실제 그럴듯한 답변입니다.

535
00:23:17,900 --> 00:23:19,829
이 모든 것을 통합하는 방법을 설명하기 위해 

536
00:23:19,829 --> 00:23:21,836
Wordlebot의 버전 2를 여기에서 가져와 

537
00:23:21,836 --> 00:23:22,300
보겠습니다.

538
00:23:22,560 --> 00:23:23,803
그리고 처음에 보았던 것과는 

539
00:23:23,803 --> 00:23:25,280
크게 두세 가지 차이점이 있습니다.

540
00:23:25,860 --> 00:23:28,667
우선, 방금 말씀드린 것처럼 엔트로피, 

541
00:23:28,667 --> 00:23:31,603
즉 정보의 기대값을 계산하는 방식은 이제 

542
00:23:31,603 --> 00:23:34,794
주어진 단어가 실제로 정답일 확률을 통합하는 

543
00:23:34,794 --> 00:23:38,240
패턴 전반에 걸쳐 보다 정교한 분포를 사용합니다.

544
00:23:38,880 --> 00:23:41,820
공교롭게도 눈물이 여전히 1위를 차지했지만, 

545
00:23:41,820 --> 00:23:43,820
그 다음 순위는 조금 다릅니다.

546
00:23:44,360 --> 00:23:46,907
둘째, 이제 상위 추천 순위를 매길 때 각 

547
00:23:46,907 --> 00:23:49,879
단어가 실제 정답일 확률에 대한 모델을 유지하며, 

548
00:23:49,879 --> 00:23:52,744
이를 결정에 반영하므로 몇 가지 추측을 테이블에 

549
00:23:52,744 --> 00:23:55,080
올려놓으면 더 쉽게 확인할 수 있습니다.

550
00:23:55,860 --> 00:23:57,820
다시 말하지만, 기계가 우리의 삶을 지배하도록 

551
00:23:57,820 --> 00:23:59,780
내버려둘 수 없기 때문에 이 권고를 무시합니다.

552
00:24:01,140 --> 00:24:04,764
그리고 왼쪽에 있는 또 다른 차이점은 불확실성 값, 

553
00:24:04,764 --> 00:24:07,390
즉 비트 수가 더 이상 가능한 일치의 

554
00:24:07,390 --> 00:24:09,640
수와 중복되지 않는다는 점입니다.

555
00:24:10,080 --> 00:24:14,930
이제 2를 8.02로 계산하면 256보다 약간 높은 

556
00:24:14,930 --> 00:24:19,613
259가 되는데, 이는 실제로 이 패턴과 일치하는 

557
00:24:19,613 --> 00:24:24,631
단어가 총 526개이지만 불확실성의 정도는 259개의 

558
00:24:24,631 --> 00:24:28,980
동일한 결과가 있을 때와 비슷하다는 의미입니다.

559
00:24:29,720 --> 00:24:30,740
이렇게 생각하면 됩니다.

560
00:24:31,020 --> 00:24:32,713
요르트와 조를, 조루스와 마찬가지로 

561
00:24:32,713 --> 00:24:34,660
보크가 답이 아니라는 것을 알고 있습니다.

562
00:24:34,660 --> 00:24:37,680
따라서 이전 사례보다 불확실성이 조금 덜합니다.

563
00:24:37,820 --> 00:24:39,280
이 비트 수는 더 작아집니다.

564
00:24:40,220 --> 00:24:42,106
그리고 게임을 계속 진행하면서 제가 

565
00:24:42,106 --> 00:24:44,087
여기서 설명하고자 하는 내용에 적합한 

566
00:24:44,087 --> 00:24:46,540
몇 가지 추측을 통해 이를 구체화하고 있습니다.

567
00:24:48,360 --> 00:24:50,331
네 번째 추측으로, 상위 추천을 살펴보면 

568
00:24:50,331 --> 00:24:51,960
더 이상 엔트로피를 극대화하는 데 

569
00:24:51,960 --> 00:24:53,760
그치지 않는다는 것을 알 수 있습니다.

570
00:24:54,460 --> 00:24:56,183
따라서 이 시점에서 기술적으로는 

571
00:24:56,183 --> 00:24:58,098
7가지 가능성이 있지만, 의미 있는 

572
00:24:58,098 --> 00:25:00,300
가능성이 있는 것은 기숙사와 단어뿐입니다.

573
00:25:00,300 --> 00:25:02,440
그리고 엄밀히 말하면 더 많은 정보를 제공하는 

574
00:25:02,440 --> 00:25:04,580
다른 모든 값보다 이 두 가지를 선택하는 것이 

575
00:25:04,580 --> 00:25:06,720
더 높은 순위를 차지하는 것을 볼 수 있습니다.

576
00:25:07,240 --> 00:25:09,327
처음 이 작업을 수행했을 때는 이 두 

577
00:25:09,327 --> 00:25:11,911
숫자를 합산하여 각 추측의 품질을 측정했는데, 

578
00:25:11,911 --> 00:25:13,900
실제로 생각보다 더 잘 작동했습니다.

579
00:25:14,300 --> 00:25:15,900
하지만 체계적으로 느껴지지 않았습니다.

580
00:25:16,100 --> 00:25:16,917
그리고 사람들이 취할 수 있는 

581
00:25:16,917 --> 00:25:17,880
다른 접근 방식이 있다고 확신합니다.

582
00:25:17,900 --> 00:25:19,340
하지만 제가 찾은 것은 다음과 같습니다.

583
00:25:19,760 --> 00:25:23,111
이 경우처럼 다음 추측의 가능성을 고려하는 경우, 

584
00:25:23,111 --> 00:25:25,625
우리가 정말로 신경 쓰는 것은 그렇게 

585
00:25:25,625 --> 00:25:27,900
했을 때 예상되는 게임 점수입니다.

586
00:25:28,230 --> 00:25:32,197
그리고 예상 점수를 계산하기 위해 단어가 실제 정답일 

587
00:25:32,197 --> 00:25:35,900
확률을 말하는데, 현재로서는 58%라고 설명합니다.

588
00:25:36,040 --> 00:25:37,887
58%의 확률로 이 게임의 점수는 

589
00:25:37,887 --> 00:25:39,540
4점이 될 것이라고 가정합니다.

590
00:25:40,320 --> 00:25:42,980
그리고 1의 확률에서 58%를 빼면 

591
00:25:42,980 --> 00:25:45,640
우리의 점수는 4보다 더 높아집니다.

592
00:25:46,220 --> 00:25:48,267
얼마나 더 늘어날지는 알 수 없지만, 

593
00:25:48,267 --> 00:25:50,022
그 시점에 도달하면 얼마나 많은 

594
00:25:50,022 --> 00:25:52,460
불확실성이 있을지에 따라 추정할 수 있습니다.

595
00:25:52,960 --> 00:25:55,940
특히 현재로서는 1.44 비트의 불확실성이 존재합니다.

596
00:25:56,440 --> 00:25:58,780
단어를 추측하면 예상되는 정보가 

597
00:25:58,780 --> 00:26:01,120
1.27비트임을 알 수 있습니다.

598
00:26:01,620 --> 00:26:03,470
따라서 우리가 단어를 추측한다면, 

599
00:26:03,470 --> 00:26:05,516
이 차이는 그 일이 발생한 후 얼마나 

600
00:26:05,516 --> 00:26:07,660
많은 불확실성이 남아있을지를 나타냅니다.

601
00:26:08,260 --> 00:26:09,946
우리에게 필요한 것은 이 불확실성을 

602
00:26:09,946 --> 00:26:11,885
예상 점수와 연관시키는 일종의 함수인데, 

603
00:26:11,885 --> 00:26:13,740
여기서 저는 이 함수를 f라고 부릅니다.

604
00:26:14,240 --> 00:26:17,001
이 작업을 수행하는 방식은 봇의 버전 1을 

605
00:26:17,001 --> 00:26:19,877
기반으로 이전 게임의 데이터 다수를 플롯하여 

606
00:26:19,877 --> 00:26:22,983
측정 가능한 수준의 불확실성이 있는 다양한 지점 

607
00:26:22,983 --> 00:26:26,320
이후의 실제 점수는 얼마였는지 알아보는 것이었습니다.

608
00:26:27,020 --> 00:26:29,948
예를 들어, 여기 8.7 정도의 값 위에 있는 

609
00:26:29,948 --> 00:26:32,990
데이터 포인트는 일부 게임의 경우 8.7 비트의 

610
00:26:32,990 --> 00:26:35,918
불확실성이 있는 지점 이후에는 최종 답을 얻기 

611
00:26:35,918 --> 00:26:38,960
위해 두 번의 추측이 필요했다는 것을 의미합니다.

612
00:26:39,320 --> 00:26:40,660
다른 게임의 경우 세 번의 추측이 필요했습니다.

613
00:26:40,820 --> 00:26:42,240
다른 게임의 경우 4번의 추측이 필요했습니다.

614
00:26:43,140 --> 00:26:45,776
여기서 왼쪽으로 이동하면 0이 넘는 모든 

615
00:26:45,776 --> 00:26:48,298
점은 불확실성이 0 비트, 즉 가능성이 

616
00:26:48,298 --> 00:26:50,935
하나만 있을 때 필요한 추측 횟수가 항상 

617
00:26:50,935 --> 00:26:54,260
단 한 번이라는 것을 의미하므로 안심할 수 있습니다.

618
00:26:54,780 --> 00:26:56,893
불확실성이 조금이라도 있을 때마다, 

619
00:26:56,893 --> 00:26:59,534
즉 본질적으로 두 가지 가능성만 남았을 때는 

620
00:26:59,534 --> 00:27:01,647
한 번 더 추측해야 할 때도 있고, 

621
00:27:01,647 --> 00:27:03,760
두 번 더 추측해야 할 때도 있고, 

622
00:27:03,760 --> 00:27:05,240
이런 식으로 반복했습니다.

623
00:27:05,740 --> 00:27:07,814
이 데이터를 시각화하는 조금 더 쉬운 방법은 

624
00:27:07,814 --> 00:27:10,220
데이터를 함께 버킷으로 묶어 평균을 구하는 것입니다.

625
00:27:11,000 --> 00:27:13,835
예를 들어, 여기 이 막대는 불확실성이 조금 

626
00:27:13,835 --> 00:27:16,897
있는 모든 지점 중에서 평균적으로 새로운 추측이 

627
00:27:16,897 --> 00:27:19,960
필요한 횟수가 약 1.5회였다는 것을 의미합니다.

628
00:27:22,140 --> 00:27:25,417
여기 막대는 여러 게임 중에서 어느 시점에서 

629
00:27:25,417 --> 00:27:28,170
불확실성이 4비트를 조금 넘은 경우, 

630
00:27:28,170 --> 00:27:31,447
즉 16가지 가능성으로 좁혀서 평균적으로 그 

631
00:27:31,447 --> 00:27:35,380
시점부터 두 번 이상 추측해야 한다는 것을 의미합니다.

632
00:27:36,060 --> 00:27:37,805
그리고 여기서부터 합리적인 함수를 

633
00:27:37,805 --> 00:27:39,460
맞추기 위해 회귀를 수행했습니다.

634
00:27:39,980 --> 00:27:43,017
이 모든 작업의 요점은 단어에서 더 많은 

635
00:27:43,017 --> 00:27:45,922
정보를 얻을수록 예상 점수가 낮아진다는 

636
00:27:45,922 --> 00:27:48,960
직관을 정량화하기 위한 것임을 기억하세요.

637
00:27:49,680 --> 00:27:52,463
그렇다면 버전 2.0으로 돌아가서 동일한 

638
00:27:52,463 --> 00:27:55,609
시뮬레이션 세트를 실행하여 2315개의 가능한 

639
00:27:55,609 --> 00:27:59,240
모든 단어 정답에 대해 재생하면 어떤 결과가 나올까요?

640
00:28:00,280 --> 00:28:02,103
첫 번째 버전과 비교하면 확실히 

641
00:28:02,103 --> 00:28:03,420
개선되어 안심이 됩니다.

642
00:28:04,020 --> 00:28:06,180
평균은 약 3.6입니다.

643
00:28:06,540 --> 00:28:09,218
첫 번째 버전과 달리 몇 번 패하는 경우가 

644
00:28:09,218 --> 00:28:12,120
있으며 이 상황에서는 6 개 이상이 필요합니다.

645
00:28:12,640 --> 00:28:14,936
아마도 정보를 극대화하는 것보다 실제로 목표를 

646
00:28:14,936 --> 00:28:17,498
달성하기 위해 절충점을 찾아야 할 때가 있기 때문일 

647
00:28:17,498 --> 00:28:17,940
것입니다.

648
00:28:19,040 --> 00:28:21,000
그렇다면 3.6보다 더 잘할 수 있을까요?

649
00:28:22,080 --> 00:28:22,920
물론 가능합니다.

650
00:28:23,280 --> 00:28:26,062
서두에서 실제 단어 답변 목록을 모델을 구축하는 

651
00:28:26,062 --> 00:28:28,535
방식에 통합하지 않는 것이 가장 재미있다고 

652
00:28:28,535 --> 00:28:29,360
말씀드렸습니다.

653
00:28:29,880 --> 00:28:31,927
하지만 이 기능을 통합하면 얻을 수 

654
00:28:31,927 --> 00:28:34,180
있는 최고 성능은 3.43 정도였습니다.

655
00:28:35,160 --> 00:28:37,609
따라서 단어 빈도 데이터를 사용하여 이 사전 

656
00:28:37,609 --> 00:28:40,058
분포를 선택하는 것보다 더 정교해지려고 하면 

657
00:28:40,058 --> 00:28:42,605
3.43은 아마도 우리가 얻을 수 있는 최대치 

658
00:28:42,605 --> 00:28:45,250
또는 적어도 내가 얻을 수 있는 최대치를 보여줄 

659
00:28:45,250 --> 00:28:45,740
것입니다.

660
00:28:46,240 --> 00:28:48,484
이 최상의 성능은 기본적으로 제가 여기서 

661
00:28:48,484 --> 00:28:50,240
이야기한 아이디어를 사용하지만, 

662
00:28:50,240 --> 00:28:52,290
예상되는 정보를 한 단계가 아니라 두 

663
00:28:52,290 --> 00:28:55,120
단계 더 나아가 검색하는 것처럼 조금 더 나아갑니다.

664
00:28:55,620 --> 00:28:58,649
원래는 그 부분에 대해 더 이야기하려고 했는데, 

665
00:28:58,649 --> 00:29:00,220
시간이 꽤 많이 지났네요.

666
00:29:00,580 --> 00:29:02,624
한 가지 말씀드리고 싶은 것은 이 두 단계 

667
00:29:02,624 --> 00:29:04,840
검색을 수행한 후 상위 후보에서 몇 가지 샘플 

668
00:29:04,840 --> 00:29:06,969
시뮬레이션을 실행한 결과, 적어도 지금까지는 

669
00:29:06,969 --> 00:29:09,100
Crane이 가장 좋은 오프너인 것 같습니다.

670
00:29:09,100 --> 00:29:10,060
누가 짐작할 수 있었을까요?

671
00:29:10,920 --> 00:29:14,502
또한 실제 단어 목록을 사용하여 가능성의 공간을 

672
00:29:14,502 --> 00:29:17,820
결정하면 불확실성은 11비트를 조금 넘습니다.

673
00:29:18,300 --> 00:29:20,660
무차별 대입 검색 결과, 처음 두 

674
00:29:20,660 --> 00:29:23,021
번의 추측 이후 예상 가능한 최대 

675
00:29:23,021 --> 00:29:25,880
정보는 약 10비트인 것으로 나타났습니다.

676
00:29:26,500 --> 00:29:29,110
즉, 가장 좋은 시나리오는 처음 두 번의 

677
00:29:29,110 --> 00:29:31,721
추측을 통해 완벽하게 최적의 플레이를 한 

678
00:29:31,721 --> 00:29:34,560
다음에는 약간의 불확실성이 남는다는 것입니다.

679
00:29:34,800 --> 00:29:36,098
이는 두 가지 가능한 추측으로 

680
00:29:36,098 --> 00:29:37,320
압축되는 것과 마찬가지입니다.

681
00:29:37,740 --> 00:29:40,206
그러나 이 평균을 3까지 낮추는 알고리즘을 

682
00:29:40,206 --> 00:29:42,878
작성할 수 없다고 말하는 것은 공정하고 아마도 

683
00:29:42,878 --> 00:29:45,344
꽤 보수적이라고 생각합니다. 왜냐하면 사용 

684
00:29:45,344 --> 00:29:48,016
가능한 단어로는 두 단계만으로 세 번째 슬롯의 

685
00:29:48,016 --> 00:29:50,379
답을 매번 틀림없이 보장할 수 있을 만큼 

686
00:29:50,379 --> 00:29:53,360
충분한 정보를 얻을 수 있는 여지가 없기 때문입니다.

