1
00:00:00,000 --> 00:00:04,040
بازی Wurdle در یکی دو ماه اخیر بسیار ویروسی شده است، و هرگز

2
00:00:04,040 --> 00:00:07,880
کسی فرصتی برای درس ریاضی را نادیده نمی گیرد، به ذهنم می رسد

3
00:00:07,880 --> 00:00:12,120
که این بازی یک مثال مرکزی بسیار خوب در یک درس در مورد

4
00:00:12,120 --> 00:00:13,120
تئوری اطلاعات و به طور خاص است. موضوعی که به آنتروپی معروف است.

5
00:00:13,120 --> 00:00:17,120
ببینید، من هم مانند بسیاری از افراد به نوعی در معما جذب شدم،

6
00:00:17,120 --> 00:00:21,200
و مانند بسیاری از برنامه نویسان من نیز در تلاش برای نوشتن

7
00:00:21,200 --> 00:00:23,200
الگوریتمی که بازی را به بهترین شکل ممکن انجام دهد، جذب شدم.

8
00:00:23,200 --> 00:00:26,400
و آنچه من فکر کردم اینجا انجام دهم این است که فقط با

9
00:00:26,400 --> 00:00:29,980
شما بخشی از فرآیند خود را در آن صحبت کنم، و برخی از

10
00:00:29,980 --> 00:00:32,080
ریاضیات را توضیح دهم، زیرا کل الگوریتم بر این ایده آنتروپی متمرکز است.

11
00:00:32,080 --> 00:00:42,180
اول از همه، اگر شما در مورد آن نشنیده اید، Wurdle چیست؟

12
00:00:42,180 --> 00:00:45,380
و برای کشتن دو پرنده با یک سنگ در اینجا در حالی که ما قوانین بازی را

13
00:00:45,380 --> 00:00:48,980
دنبال می کنیم، اجازه دهید پیش نمایشی هم داشته باشم که با این کار به کجا

14
00:00:48,980 --> 00:00:51,380
می رویم، یعنی ایجاد یک الگوریتم کوچک که اساساً بازی را برای ما انجام می دهد.

15
00:00:51,380 --> 00:00:54,860
اگرچه من Wurdle امروز را انجام نداده ام، اما این 4

16
00:00:54,860 --> 00:00:55,860
فوریه است، و خواهیم دید که ربات چگونه عمل می کند.

17
00:00:55,860 --> 00:00:59,580
هدف Wurdle حدس زدن یک کلمه مرموز پنج حرفی است و

18
00:00:59,580 --> 00:01:00,860
شش فرصت مختلف برای حدس زدن به شما داده می شود.

19
00:01:00,860 --> 00:01:05,240
به عنوان مثال، ربات Wurdle من پیشنهاد می کند که با جرثقیل حدس زدن شروع کنم.

20
00:01:05,240 --> 00:01:09,300
هر بار که حدس می زنید، اطلاعاتی در مورد نزدیک

21
00:01:09,300 --> 00:01:10,940
بودن حدس شما به پاسخ واقعی به دست می آورید.

22
00:01:10,940 --> 00:01:14,540
در اینجا جعبه خاکستری به من می گوید که در پاسخ واقعی C وجود ندارد.

23
00:01:14,540 --> 00:01:18,340
جعبه زرد به من می گوید R وجود دارد، اما در آن موقعیت نیست.

24
00:01:18,340 --> 00:01:21,820
جعبه سبز به من می گوید که کلمه مخفی

25
00:01:21,820 --> 00:01:22,820
دارای A است و در جایگاه سوم قرار دارد.

26
00:01:22,820 --> 00:01:24,300
و سپس نه N و نه E وجود دارد.

27
00:01:24,300 --> 00:01:27,420
بنابراین اجازه دهید من وارد شوم و این اطلاعات را به ربات Wurdle بگویم.

28
00:01:27,420 --> 00:01:31,500
ما با جرثقیل شروع کردیم، خاکستری، زرد، سبز، خاکستری، خاکستری شدیم.

29
00:01:31,500 --> 00:01:35,460
نگران تمام داده هایی که در حال حاضر نشان می دهد نباشید، در زمان مناسب آن را توضیح خواهم داد.

30
00:01:35,460 --> 00:01:39,700
اما بهترین پیشنهاد آن برای انتخاب دوم ما shtick است.

31
00:01:39,700 --> 00:01:43,500
و حدس شما باید یک کلمه پنج حرفی واقعی باشد، اما همانطور که خواهید دید،

32
00:01:43,500 --> 00:01:45,700
با آنچه که در واقع به شما اجازه حدس زدن می‌دهد بسیار آزادانه است.

33
00:01:45,700 --> 00:01:48,860
در این مورد ما shtick را امتحان می کنیم.

34
00:01:48,860 --> 00:01:50,260
و خوب، همه چیز خیلی خوب به نظر می رسد.

35
00:01:50,260 --> 00:01:54,580
S و H را می زنیم، بنابراین سه حرف اول را می دانیم، می دانیم که R وجود دارد.

36
00:01:54,740 --> 00:01:59,740
و بنابراین مانند SHA چیزی R، یا SHA R چیزی خواهد بود.

37
00:01:59,740 --> 00:02:03,200
و به نظر می‌رسد که ربات Wurdle می‌داند

38
00:02:03,200 --> 00:02:05,220
که فقط دو احتمال دارد، خرد یا تیز.

39
00:02:05,220 --> 00:02:08,620
در این مرحله این یک نوع پرت کردن بین آنهاست، بنابراین حدس می‌زنم

40
00:02:08,620 --> 00:02:11,260
احتمالاً فقط به دلیل حروف الفبا بودن آن با خرده‌ها همخوانی دارد.

41
00:02:11,260 --> 00:02:13,000
چه هورا، پاسخ واقعی است.

42
00:02:13,000 --> 00:02:14,660
بنابراین ما آن را در سه دریافت کردیم.

43
00:02:14,660 --> 00:02:17,740
اگر تعجب می کنید که آیا این چیز خوبی است، روشی که من از یک

44
00:02:17,740 --> 00:02:20,820
نفر شنیدم این است که با Wurdle چهار برابر است و سه مرغک است.

45
00:02:20,820 --> 00:02:22,960
که به نظر من تشبیه بسیار مناسبی است.

46
00:02:22,960 --> 00:02:27,560
شما باید به طور مداوم در بازی خود باشید تا به 4 برسید، اما مطمئناً دیوانه کننده نیست.

47
00:02:27,560 --> 00:02:30,000
اما وقتی آن را سه تایی دریافت می‌کنید، احساس عالی می‌کنید.

48
00:02:30,000 --> 00:02:33,800
بنابراین، اگر دوست ندارید، کاری که من می‌خواهم در اینجا انجام دهم این

49
00:02:33,800 --> 00:02:36,600
است که از ابتدا در مورد نحوه برخوردم با ربات Wurdle صحبت کنم.

50
00:02:36,600 --> 00:02:39,800
و همانطور که گفتم، واقعاً بهانه ای برای درس تئوری اطلاعات است.

51
00:02:39,800 --> 00:02:43,160
هدف اصلی این است که توضیح دهیم اطلاعات چیست و آنتروپی چیست.

52
00:02:48,560 --> 00:02:52,080
اولین فکر من در نزدیک شدن به این موضوع، نگاهی

53
00:02:52,080 --> 00:02:53,560
به بسامدهای نسبی حروف مختلف در زبان انگلیسی بود.

54
00:02:53,560 --> 00:02:57,800
بنابراین فکر کردم، خوب، آیا یک حدس اولیه یا یک جفت حدس ابتدایی

55
00:02:57,800 --> 00:02:59,960
وجود دارد که به تعداد زیادی از این حروف متداول برخورد کند؟

56
00:02:59,960 --> 00:03:03,780
و یکی که من خیلی به آن علاقه داشتم این بود که کارهای دیگری انجام می دادم و به دنبال آن میخ می زدم.

57
00:03:03,780 --> 00:03:06,980
فکر این است که اگر یک حرف بزنید، می دانید،

58
00:03:06,980 --> 00:03:07,980
سبز یا زرد می گیرید، که همیشه حس خوبی دارد.

59
00:03:07,980 --> 00:03:09,460
انگار داری اطلاعات میگیری

60
00:03:09,460 --> 00:03:13,140
اما در این موارد، حتی اگر ضربه ای نزنید و همیشه خاکستری می

61
00:03:13,140 --> 00:03:16,640
شوید، باز هم اطلاعات زیادی به شما می دهد زیرا یافتن کلمه ای

62
00:03:16,640 --> 00:03:17,640
که هیچ یک از این حروف را نداشته باشد بسیار نادر است.

63
00:03:17,640 --> 00:03:21,840
اما حتی با این حال، این امر فوق العاده سیستماتیک به نظر

64
00:03:21,840 --> 00:03:23,520
نمی رسد، زیرا برای مثال، ترتیب حروف را در نظر نمی گیرد.

65
00:03:23,520 --> 00:03:26,080
وقتی می‌توانم حلزون را تایپ کنم، چرا ناخن بنویسم؟

66
00:03:26,080 --> 00:03:27,720
آیا بهتر است آن S را در انتها داشته باشیم؟

67
00:03:27,720 --> 00:03:28,720
من واقعا اطمینان ندارم.

68
00:03:28,720 --> 00:03:33,500
حالا یکی از دوستانم گفت که دوست دارد با کلمه weary باز کند، که من

69
00:03:33,500 --> 00:03:37,160
را متعجب کرد زیرا در آن حروف غیر معمول مانند W و Y وجود دارد.

70
00:03:37,160 --> 00:03:39,400
اما چه کسی می داند، شاید بازکننده بهتری باشد.

71
00:03:39,400 --> 00:03:43,920
آیا نوعی امتیاز کمی وجود دارد که بتوانیم برای

72
00:03:43,920 --> 00:03:44,920
قضاوت در مورد کیفیت یک حدس احتمالی بدهیم؟

73
00:03:44,920 --> 00:03:48,640
اکنون برای تنظیم روشی که می‌خواهیم حدس‌های احتمالی را رتبه‌بندی کنیم، اجازه دهید

74
00:03:48,640 --> 00:03:51,800
به عقب برگردیم و کمی وضوح به نحوه دقیق تنظیم بازی اضافه کنیم.

75
00:03:51,800 --> 00:03:55,880
بنابراین فهرستی از کلمات وجود دارد که به شما امکان می دهد وارد کنید که

76
00:03:55,880 --> 00:03:57,920
حدس های معتبری در نظر گرفته می شوند که فقط حدود 13000 کلمه طولانی دارند.

77
00:03:57,920 --> 00:04:01,560
اما وقتی به آن نگاه می‌کنید، چیزهای واقعاً غیرمعمول زیادی وجود دارد، چیزهایی مانند سر

78
00:04:01,560 --> 00:04:07,040
یا علی و ARG، از جمله کلماتی که در بازی Scrabble مشاجره‌های خانوادگی ایجاد می‌کنند.

79
00:04:07,040 --> 00:04:10,600
اما جو بازی این است که پاسخ همیشه یک کلمه معمولی است.

80
00:04:10,600 --> 00:04:16,080
و در واقع، فهرست دیگری از حدود 2300 کلمه وجود دارد که پاسخ‌های ممکن است.

81
00:04:16,080 --> 00:04:20,320
و این یک لیست انتخاب شده توسط انسان است، به نظر من به

82
00:04:20,320 --> 00:04:21,800
طور خاص توسط دوست دختر سازنده بازی، که به نوعی سرگرم کننده است.

83
00:04:21,800 --> 00:04:25,560
اما کاری که من می‌خواهم انجام دهم، چالش ما برای این پروژه این است که ببینیم آیا

84
00:04:25,560 --> 00:04:30,720
می‌توانیم برنامه‌ای برای حل Wordle بنویسیم که دانش قبلی در مورد این لیست را ترکیب نکند.

85
00:04:30,720 --> 00:04:34,560
برای یک چیز، تعداد زیادی از کلمات پنج حرفی بسیار

86
00:04:34,560 --> 00:04:35,560
رایج وجود دارد که شما در آن لیست نخواهید یافت.

87
00:04:35,560 --> 00:04:38,360
بنابراین بهتر است برنامه‌ای بنویسید که کمی انعطاف‌پذیرتر باشد و وردل را در

88
00:04:38,360 --> 00:04:41,960
برابر هر کسی بازی کند، نه فقط چیزی که اتفاقاً وب‌سایت رسمی است.

89
00:04:41,960 --> 00:04:45,900
و همچنین دلیل اینکه ما می دانیم این لیست از پاسخ های

90
00:04:45,900 --> 00:04:47,440
ممکن چیست، این است که در کد منبع قابل مشاهده است.

91
00:04:47,440 --> 00:04:51,620
اما روشی که در کد منبع قابل مشاهده است به ترتیب خاصی

92
00:04:51,620 --> 00:04:52,840
است که در آن پاسخ ها هر روز ارائه می شوند.

93
00:04:52,840 --> 00:04:56,400
بنابراین همیشه می توانید به دنبال پاسخ فردا باشید.

94
00:04:56,400 --> 00:04:59,140
بنابراین واضح است که استفاده از فهرست تقلب است.

95
00:04:59,140 --> 00:05:02,900
و آنچه برای یک پازل جالب‌تر و یک درس تئوری اطلاعات غنی‌تر

96
00:05:02,900 --> 00:05:07,640
می‌سازد، استفاده از داده‌های جهانی‌تر مانند بسامدهای نسبی کلمات به طور

97
00:05:07,640 --> 00:05:11,640
کلی برای درک این شهود ترجیح دادن به کلمات رایج‌تر است.

98
00:05:11,640 --> 00:05:16,560
پس از بین این 13000 احتمال، چگونه باید حدس اولیه را انتخاب کنیم؟

99
00:05:16,560 --> 00:05:19,960
به عنوان مثال، اگر دوست من خسته را پیشنهاد دهد، چگونه باید کیفیت آن را تجزیه و تحلیل کنیم؟

100
00:05:19,960 --> 00:05:25,040
خوب، دلیلی که او گفت که W بعید را دوست دارد این است که او از

101
00:05:25,040 --> 00:05:27,880
طبیعت لانگ شات خوشش می‌آید که اگر به آن دبلیو ضربه بزنید چقدر حس خوبی دارد.

102
00:05:27,880 --> 00:05:31,400
به عنوان مثال، اگر اولین الگوی فاش شده چیزی شبیه به این باشد، پس معلوم می شود

103
00:05:31,400 --> 00:05:36,080
که تنها 58 کلمه در این واژگان غول پیکر وجود دارد که با آن الگو مطابقت دارد.

104
00:05:36,080 --> 00:05:38,900
بنابراین این کاهش بسیار زیادی از 13000 است.

105
00:05:38,900 --> 00:05:43,320
اما طرف دیگر آن، البته، این است که دریافت چنین الگویی بسیار غیر معمول است.

106
00:05:43,360 --> 00:05:47,600
به طور خاص، اگر هر کلمه به یک اندازه پاسخ باشد، احتمال

107
00:05:47,600 --> 00:05:51,680
برخورد با این الگو 58 تقسیم بر حدود 13000 خواهد بود.

108
00:05:51,680 --> 00:05:53,880
البته، آنها به یک اندازه به احتمال زیاد پاسخ نیستند.

109
00:05:53,880 --> 00:05:56,680
بیشتر اینها کلماتی بسیار مبهم و حتی مشکوک هستند.

110
00:05:56,680 --> 00:05:59,560
اما حداقل برای اولین پاس ما در تمام این موارد، بیایید فرض کنیم که همه

111
00:05:59,560 --> 00:06:02,040
آنها به یک اندازه محتمل هستند و سپس آن را کمی بعد اصلاح کنیم.

112
00:06:02,040 --> 00:06:07,360
نکته این است که الگوی با اطلاعات زیاد به دلیل ماهیت خود بعید است که رخ دهد.

113
00:06:07,360 --> 00:06:11,320
در واقع، معنای آموزنده بودن این است که بعید است.

114
00:06:11,920 --> 00:06:16,720
یک الگوی بسیار محتمل تر برای دیدن با این باز شدن چیزی

115
00:06:16,720 --> 00:06:18,360
شبیه به این خواهد بود، که البته W در آن وجود ندارد.

116
00:06:18,360 --> 00:06:22,080
شاید E وجود داشته باشد، و شاید A وجود نداشته باشد، R وجود نداشته باشد، Y وجود نداشته باشد.

117
00:06:22,080 --> 00:06:24,640
در این مورد، 1400 مسابقه احتمالی وجود دارد.

118
00:06:24,640 --> 00:06:29,600
اگر همه به یک اندازه محتمل بودند، به احتمال

119
00:06:29,600 --> 00:06:30,680
حدود 11 درصد این الگویی است که می بینید.

120
00:06:30,680 --> 00:06:34,320
بنابراین محتمل ترین نتایج نیز کمترین اطلاعات را دارند.

121
00:06:34,320 --> 00:06:38,440
برای دریافت نمای کلی‌تر در اینجا، اجازه دهید توزیع کامل احتمالات را در

122
00:06:38,440 --> 00:06:42,000
تمام الگوهای مختلف که ممکن است ببینید را به شما نشان دهم.

123
00:06:42,000 --> 00:06:46,000
بنابراین هر نواری که به آن نگاه می‌کنید مربوط به الگوی احتمالی رنگ‌هایی

124
00:06:46,000 --> 00:06:50,500
است که می‌توان آشکار کرد، که از 3 تا 5 احتمال وجود

125
00:06:50,500 --> 00:06:52,960
دارد، و آنها از چپ به راست، رایج‌ترین تا کم‌معمول‌ترین، سازمان‌دهی شده‌اند.

126
00:06:52,960 --> 00:06:56,200
بنابراین رایج ترین احتمال در اینجا این است که تمام خاکستری ها را دریافت کنید.

127
00:06:56,200 --> 00:06:58,800
این در حدود 14 درصد مواقع اتفاق می افتد.

128
00:06:58,800 --> 00:07:02,040
و وقتی حدس می‌زنید به آن امیدوار هستید این است که به جایی

129
00:07:02,040 --> 00:07:06,360
در این دم بلند برسید، مانند اینجا که تنها 18 احتمال برای آنچه

130
00:07:06,360 --> 00:07:09,920
که با این الگو مطابقت دارد و ظاهراً شبیه این است وجود دارد.

131
00:07:09,920 --> 00:07:14,080
یا اگر کمی دورتر به سمت چپ برویم، می‌دانی، شاید تا آخر اینجا برویم.

132
00:07:14,080 --> 00:07:16,560
خوب، در اینجا یک پازل خوب برای شما وجود دارد.

133
00:07:16,560 --> 00:07:20,600
سه کلمه در زبان انگلیسی که با W شروع و با

134
00:07:20,600 --> 00:07:22,040
Y ختم می شوند و در جایی R دارند کدامند؟

135
00:07:22,040 --> 00:07:27,560
به نظر می رسد، پاسخ ها، بیایید ببینیم، لفظی، کرمی، و پرخاشگر هستند.

136
00:07:27,560 --> 00:07:32,720
بنابراین برای قضاوت در مورد اینکه این کلمه به طور کلی چقدر خوب است، ما می خواهیم

137
00:07:32,720 --> 00:07:35,720
نوعی اندازه گیری از میزان اطلاعات مورد انتظاری که از این توزیع به دست می آورید.

138
00:07:36,360 --> 00:07:41,080
اگر هر الگو را مرور کنیم و احتمال وقوع آن را در دفعات چیزی که میزان

139
00:07:41,080 --> 00:07:46,000
آموزنده بودن آن را می سنجد ضرب کنیم، ممکن است به ما یک امتیاز عینی بدهد.

140
00:07:46,000 --> 00:07:50,280
اکنون اولین غریزه شما برای اینکه آن چیزی باید باشد، ممکن است تعداد مسابقات باشد.

141
00:07:50,280 --> 00:07:52,960
شما میانگین تعداد کمتری از مسابقات را می خواهید.

142
00:07:52,960 --> 00:07:57,400
اما در عوض می‌خواهم از یک اندازه‌گیری جهانی‌تر استفاده کنم که اغلب به اطلاعات

143
00:07:57,400 --> 00:08:01,040
نسبت می‌دهیم، و زمانی که احتمال متفاوتی برای هر یک از این 13000 کلمه

144
00:08:01,040 --> 00:08:04,320
در نظر بگیریم که آیا واقعاً پاسخ هستند یا نه، انعطاف‌پذیرتر خواهد بود.

145
00:08:10,600 --> 00:08:14,760
واحد استاندارد اطلاعات بیت است که کمی فرمول خنده‌دار دارد،

146
00:08:14,760 --> 00:08:17,800
اما اگر فقط به مثال‌ها نگاه کنیم، واقعاً بصری است.

147
00:08:17,800 --> 00:08:21,880
اگر مشاهده ای دارید که فضای احتمالی شما را نصف

148
00:08:21,880 --> 00:08:24,200
می کند، می گوییم که یک بیت اطلاعات دارد.

149
00:08:24,200 --> 00:08:27,680
در مثال ما، فضای احتمالات همه کلمات ممکن است، و تقریباً نیمی از

150
00:08:27,760 --> 00:08:31,560
کلمات پنج حرفی S دارند، کمی کمتر از آن، اما تقریباً نصف.

151
00:08:31,560 --> 00:08:35,200
بنابراین آن مشاهده یک بیت اطلاعات به شما می دهد.

152
00:08:35,200 --> 00:08:39,640
اگر در عوض یک واقعیت جدید آن فضای احتمالی را با ضریب

153
00:08:39,640 --> 00:08:42,000
چهار کاهش دهد، می گوییم که دارای دو بیت اطلاعات است.

154
00:08:42,000 --> 00:08:45,120
به عنوان مثال، معلوم می شود که حدود یک چهارم این کلمات دارای T هستند.

155
00:08:45,120 --> 00:08:49,720
اگر مشاهدات آن فضا را به ضریب هشت کاهش دهد،

156
00:08:49,720 --> 00:08:50,920
می گوییم سه بیت اطلاعات است و غیره و غیره.

157
00:08:50,920 --> 00:08:55,000
چهار بیت آن را به 16 برش می دهد، پنج بیت آن را به 32 برش می دهد.

158
00:08:55,000 --> 00:09:00,160
بنابراین اکنون ممکن است بخواهید مکث کنید و از خود بپرسید که

159
00:09:00,160 --> 00:09:04,520
فرمول اطلاعات برای تعداد بیت ها از نظر احتمال وقوع چیست؟

160
00:09:04,520 --> 00:09:07,920
چیزی که در اینجا می گوییم این است که وقتی یک نصف را به

161
00:09:07,920 --> 00:09:11,680
تعداد بیت ها می گیریم، این همان احتمال است، که همان چیزی است که

162
00:09:11,680 --> 00:09:16,200
بگوییم دو به توان تعداد بیت ها یک بر احتمال است، که بازآرایی می‌کند

163
00:09:16,200 --> 00:09:19,680
و می‌گوید که اطلاعات مبنای گزارش دو از یک تقسیم بر احتمال است.

164
00:09:19,680 --> 00:09:23,200
و گاهی اوقات شما این را با یک بازآرایی دیگر مشاهده می

165
00:09:23,200 --> 00:09:25,680
کنید، که در آن اطلاعات، پایه ثبت منفی دو احتمال است.

166
00:09:25,680 --> 00:09:29,120
اینطور بیان می شود، ممکن است برای افراد ناآشنا کمی عجیب

167
00:09:29,120 --> 00:09:33,400
به نظر برسد، اما واقعاً این ایده بسیار شهودی است که

168
00:09:33,400 --> 00:09:35,120
بپرسید چند بار امکانات خود را به نصف کاهش داده اید.

169
00:09:35,120 --> 00:09:37,840
حالا اگر تعجب می‌کنید، می‌دانید، من فکر می‌کردم که ما داریم یک

170
00:09:37,840 --> 00:09:39,920
بازی سرگرم‌کننده با کلمات انجام می‌دهیم، چرا لگاریتم‌ها وارد تصویر می‌شوند؟

171
00:09:39,920 --> 00:09:43,920
یکی از دلایلی که این واحد زیباتر است این است که صحبت کردن در مورد رویدادهای بسیار

172
00:09:43,920 --> 00:09:48,120
بعید بسیار ساده تر است، گفتن اینکه یک مشاهده دارای 20 بیت اطلاعات است بسیار آسان

173
00:09:48,120 --> 00:09:53,480
تر از این است که بگوییم احتمال وقوع فلان و آن 0 است. 0000095.

174
00:09:53,480 --> 00:09:57,360
اما دلیل اصلی‌تر اینکه این عبارت لگاریتمی افزوده بسیار مفیدی برای

175
00:09:57,360 --> 00:10:02,000
نظریه احتمال است، روشی است که اطلاعات با هم جمع می‌شوند.

176
00:10:02,000 --> 00:10:05,560
به عنوان مثال، اگر یک مشاهده دو بیت اطلاعات به شما بدهد، فضای شما

177
00:10:05,560 --> 00:10:10,120
را چهار بیت کاهش دهد، و سپس مشاهده دوم مانند حدس دوم شما در

178
00:10:10,120 --> 00:10:14,480
Wordle، سه بیت اطلاعات دیگر به شما بدهد، و شما را با ضریب هشت

179
00:10:14,480 --> 00:10:17,360
بیشتر کاهش دهد، دو با هم پنج بیت اطلاعات را به شما می دهند.

180
00:10:17,360 --> 00:10:21,200
همانطور که احتمالات دوست دارند ضرب شوند، اطلاعات نیز دوست دارند جمع شوند.

181
00:10:21,200 --> 00:10:24,920
بنابراین به محض اینکه در قلمرو چیزی مانند یک مقدار مورد انتظار قرار می گیریم، جایی که ما در

182
00:10:24,920 --> 00:10:28,660
حال اضافه کردن یک سری اعداد به بالا هستیم، گزارش ها رسیدگی به آن را بسیار زیباتر می کنند.

183
00:10:28,660 --> 00:10:32,600
بیایید به توزیع خود برای Weary برگردیم و یک ردیاب کوچک دیگر را در اینجا

184
00:10:32,600 --> 00:10:35,560
اضافه کنیم و به ما نشان دهد که برای هر الگو چقدر اطلاعات وجود دارد.

185
00:10:35,560 --> 00:10:38,760
نکته اصلی که می‌خواهم به آن توجه داشته باشید این است که هرچه احتمال

186
00:10:38,760 --> 00:10:43,500
بالاتر رفتن به آن الگوهای محتمل‌تر باشد، اطلاعات کمتر، بیت‌های کمتری به دست می‌آورید.

187
00:10:43,500 --> 00:10:47,360
روشی که کیفیت این حدس را اندازه گیری می کنیم به این صورت است که مقدار مورد انتظار

188
00:10:47,360 --> 00:10:51,620
این اطلاعات را می گیریم، جایی که هر الگو را مرور می کنیم، می گوییم چقدر احتمال

189
00:10:51,620 --> 00:10:54,940
دارد، و سپس آن را در چند بیت اطلاعاتی که به دست می آوریم ضرب می کنیم.

190
00:10:54,940 --> 00:10:58,480
و در مثال Weary، معلوم می شود که 4 است. 9 بیت.

191
00:10:58,480 --> 00:11:02,800
بنابراین، به طور متوسط، اطلاعاتی که از این حدس آغازین به دست می

192
00:11:02,800 --> 00:11:05,660
آورید، به اندازه نصف کردن فضای احتمالی شما در حدود پنج بار است.

193
00:11:05,660 --> 00:11:10,260
در مقابل، نمونه‌ای از حدس با ارزش اطلاعات

194
00:11:10,260 --> 00:11:13,220
مورد انتظار بالاتر چیزی شبیه Slate است.

195
00:11:13,220 --> 00:11:16,180
در این مورد متوجه خواهید شد که توزیع بسیار صاف تر به نظر می رسد.

196
00:11:16,180 --> 00:11:20,780
به طور خاص، احتمال وقوع همه خاکستری ها تنها حدود 6 درصد است،

197
00:11:20,780 --> 00:11:25,940
بنابراین حداقل شما به وضوح 3 می گیرید. 9 بیت اطلاعات

198
00:11:25,940 --> 00:11:29,140
اما این یک حداقل است، معمولاً شما چیزی بهتر از آن را دریافت می کنید.

199
00:11:29,140 --> 00:11:33,380
و وقتی اعداد را روی این یکی خرد می‌کنید و همه

200
00:11:33,380 --> 00:11:36,420
عبارت‌های مربوطه را جمع می‌کنید، میانگین اطلاعات حدود 5 است. 8.

201
00:11:36,420 --> 00:11:42,140
بنابراین بر خلاف Weary، فضای احتمالی شما پس از

202
00:11:42,140 --> 00:11:43,940
اولین حدس به طور متوسط تقریباً نصف خواهد بود.

203
00:11:43,940 --> 00:11:49,540
در واقع یک داستان سرگرم کننده در مورد نام این مقدار مورد انتظار کمیت اطلاعات وجود دارد.

204
00:11:49,540 --> 00:11:52,580
نظریه اطلاعات توسط کلود شانون که در دهه 1940 در آزمایشگاه های بل کار می کرد،

205
00:11:52,580 --> 00:11:57,620
ایجاد شد، اما او در مورد برخی از ایده های خود که هنوز منتشر نشده بود

206
00:11:57,620 --> 00:12:01,500
با جان فون نویمان، که این غول فکری بسیار برجسته آن زمان بود صحبت می کرد.

207
00:12:01,500 --> 00:12:04,180
در ریاضیات و فیزیک و آغاز آنچه در حال تبدیل شدن به علم کامپیوتر بود.

208
00:12:04,180 --> 00:12:07,260
و هنگامی که او اشاره کرد که واقعاً نام خوبی برای این مقدار

209
00:12:07,260 --> 00:12:12,540
مورد انتظار کمیت اطلاعات ندارد، ظاهراً فون نویمان گفت، بنابراین داستان ادامه

210
00:12:12,540 --> 00:12:14,720
دارد، خوب شما باید آن را آنتروپی بنامید، و به دو دلیل.

211
00:12:14,720 --> 00:12:18,400
در وهله اول، تابع عدم قطعیت شما در مکانیک آماری با آن نام استفاده شده است،

212
00:12:18,400 --> 00:12:23,100
بنابراین قبلاً یک نام دارد، و در وهله دوم، و مهمتر از آن، هیچ کس

213
00:12:23,100 --> 00:12:26,940
نمی داند آنتروپی واقعاً چیست، بنابراین در یک بحث همیشه خواهید دید مزیت را دارند

214
00:12:26,940 --> 00:12:31,420
بنابراین اگر نام کمی مرموز به نظر می رسد، و اگر

215
00:12:31,420 --> 00:12:33,420
این داستان را باید باور کرد، این یک نوع طراحی است.

216
00:12:33,420 --> 00:12:36,740
همچنین اگر در مورد رابطه آن با تمام آن قانون دوم ترمودینامیک از

217
00:12:36,740 --> 00:12:40,820
فیزیک تعجب می کنید، قطعاً ارتباطی وجود دارد، اما در اصل شانون فقط

218
00:12:40,820 --> 00:12:44,780
با نظریه احتمال محض سر و کار داشت، و برای اهداف ما در

219
00:12:44,780 --> 00:12:49,340
اینجا، زمانی که من از آنتروپی کلمه، من فقط از شما می خواهم

220
00:12:49,340 --> 00:12:50,820
که ارزش اطلاعات مورد انتظار یک حدس خاص را در نظر بگیرید.

221
00:12:50,820 --> 00:12:54,380
شما می توانید آنتروپی را به عنوان اندازه گیری دو چیز به طور همزمان در نظر بگیرید.

222
00:12:54,380 --> 00:12:57,420
اولین مورد این است که توزیع چقدر مسطح است.

223
00:12:57,420 --> 00:13:01,700
هر چه یک توزیع به یکنواخت نزدیکتر باشد، آنتروپی بالاتر خواهد بود.

224
00:13:01,700 --> 00:13:06,340
در مورد ما، جایی که الگوهای کل 3 تا 5 وجود دارد، برای توزیع یکنواخت، مشاهده هر

225
00:13:06,340 --> 00:13:11,340
یک از آنها پایه ثبت اطلاعات 2 از 3 تا 5 را خواهد داشت که اتفاقاً 7

226
00:13:11,340 --> 00:13:17,860
است. 92، بنابراین حداکثر مطلقی است که می توانید برای این آنتروپی داشته باشید.

227
00:13:17,860 --> 00:13:21,900
اما آنتروپی همچنین به نوعی معیاری است که

228
00:13:21,900 --> 00:13:22,900
در وهله اول چند احتمال وجود دارد.

229
00:13:22,900 --> 00:13:26,980
به عنوان مثال، اگر شما کلمه ای دارید که در آن فقط 16 الگوی ممکن وجود دارد، و

230
00:13:26,980 --> 00:13:32,760
هر کدام به یک اندازه احتمال دارد، این آنتروپی، این اطلاعات مورد انتظار، 4 بیت خواهد بود.

231
00:13:32,760 --> 00:13:36,880
اما اگر کلمه دیگری داشته باشید که در آن 64 الگوی احتمالی وجود دارد که می‌تواند

232
00:13:36,880 --> 00:13:41,000
ظاهر شود، و همه آنها به یک اندازه احتمال دارند، آنتروپی 6 بیت خواهد بود.

233
00:13:41,000 --> 00:13:45,800
بنابراین، اگر توزیعی را در طبیعت مشاهده کردید که دارای آنتروپی 6 بیتی

234
00:13:45,800 --> 00:13:50,000
است، به نوعی می‌گویید که تغییرات و عدم قطعیت در آنچه قرار است

235
00:13:50,000 --> 00:13:54,400
اتفاق بیفتد به اندازه‌ای است که 64 نتیجه به همان اندازه محتمل است.

236
00:13:54,400 --> 00:13:58,360
برای اولین پاسم در Wurtelebot، اساساً مجبور شدم این کار را انجام دهد.

237
00:13:58,360 --> 00:14:03,560
تمام حدس‌های ممکن را که می‌توانید داشته باشید، تمام 13000 کلمه را بررسی می‌کند، آنتروپی

238
00:14:03,560 --> 00:14:08,580
را برای هر یک محاسبه می‌کند، یا به طور خاص، آنتروپی توزیع را در

239
00:14:08,580 --> 00:14:13,040
همه الگوهایی که ممکن است ببینید، برای هر یک، و بالاترین را انتخاب می‌کند، زیرا

240
00:14:13,040 --> 00:14:17,200
این موردی که احتمالاً فضای احتمالی شما را تا حد امکان کاهش می دهد.

241
00:14:17,200 --> 00:14:20,120
و اگرچه من فقط در مورد حدس اول در اینجا صحبت کرده

242
00:14:20,120 --> 00:14:21,680
ام، برای چند حدس بعدی همین کار را انجام می دهد.

243
00:14:21,680 --> 00:14:25,100
به عنوان مثال، پس از اینکه الگویی را در اولین حدس مشاهده کردید، که شما

244
00:14:25,100 --> 00:14:29,300
را به تعداد کمتری از کلمات ممکن بر اساس آنچه با آن منطبق است

245
00:14:29,300 --> 00:14:32,300
محدود می‌کند، فقط همان بازی را با توجه به مجموعه کلمات کوچک‌تر انجام می‌دهید.

246
00:14:32,300 --> 00:14:36,500
برای یک حدس دوم پیشنهادی، به توزیع همه الگوهایی که می‌توانند از آن

247
00:14:36,500 --> 00:14:41,540
مجموعه کلمات محدودتر رخ دهند نگاه کنید، تمام 13000 احتمال را جستجو

248
00:14:41,540 --> 00:14:45,480
می‌کنید و احتمالی را پیدا می‌کنید که آنتروپی را به حداکثر می‌رساند.

249
00:14:45,480 --> 00:14:48,980
برای اینکه به شما نشان دهم چگونه این در عمل کار می کند، اجازه دهید فقط یک نوع

250
00:14:48,980 --> 00:14:54,060
کوچک از Wurtele را که نوشتم که نکات برجسته این تحلیل را در حاشیه نشان می دهد، بیاورم.

251
00:14:54,460 --> 00:14:57,820
پس از انجام تمام محاسبات آنتروپی، در سمت راست اینجا به ما

252
00:14:57,820 --> 00:15:00,340
نشان می دهد که کدام یک بالاترین اطلاعات مورد انتظار را دارند.

253
00:15:00,340 --> 00:15:04,940
به نظر می رسد که پاسخ برتر، حداقل در حال حاضر، ما بعداً آن را

254
00:15:04,940 --> 00:15:11,140
اصلاح خواهیم کرد، Tares است، که به معنای، البته، ماشک، رایج ترین ماشک است.

255
00:15:11,140 --> 00:15:14,180
هر بار که در اینجا حدس می زنیم، جایی که شاید به نوعی توصیه های آن را نادیده

256
00:15:14,180 --> 00:15:19,220
می گیرم و با تخته سنگ پیش می روم، زیرا من تخته سنگ را دوست دارم، می توانیم

257
00:15:19,220 --> 00:15:23,300
ببینیم که چقدر اطلاعات مورد انتظار آن را داشته است، اما در سمت راست کلمه اینجا به ما

258
00:15:23,340 --> 00:15:24,980
نشان می دهد که چقدر اطلاعات واقعی ما با توجه به این الگوی خاص به دست آوردیم.

259
00:15:24,980 --> 00:15:28,660
بنابراین در اینجا به نظر می رسد که ما کمی بدشانس بودیم، انتظار می رفت که 5 بگیریم. 8، اما

260
00:15:28,660 --> 00:15:30,660
اتفاقاً چیزی با کمتر از آن به دست آوردیم.

261
00:15:30,660 --> 00:15:34,020
و سپس در سمت چپ اینجا همه کلمات ممکن مختلف

262
00:15:34,020 --> 00:15:35,860
را به ما نشان می دهد که در کجا هستیم.

263
00:15:35,860 --> 00:15:39,820
نوارهای آبی به ما می‌گویند که احتمال هر کلمه چقدر است، بنابراین در حال حاضر فرض می‌کند هر

264
00:15:39,820 --> 00:15:44,140
کلمه به یک اندازه ممکن است رخ دهد، اما ما آن را در یک لحظه اصلاح می‌کنیم.

265
00:15:44,140 --> 00:15:48,580
و سپس این اندازه‌گیری عدم قطعیت آنتروپی این توزیع را در میان

266
00:15:48,580 --> 00:15:53,220
کلمات ممکن به ما می‌گوید، که در حال حاضر، به دلیل اینکه

267
00:15:53,300 --> 00:15:55,940
توزیع یکنواختی است، فقط یک راه پیچیده برای شمارش تعداد احتمالات است.

268
00:15:55,940 --> 00:16:01,700
مثلاً اگر 2 را به توان 13 بگیریم. 66، که باید

269
00:16:01,700 --> 00:16:02,700
حدود 13000 احتمال باشد.

270
00:16:02,700 --> 00:16:06,780
من از اینجا کمی دور هستم، اما فقط به این دلیل که تمام ارقام اعشار را نشان نمی دهم.

271
00:16:06,780 --> 00:16:10,260
در حال حاضر ممکن است این کار زائد به نظر برسد و چیزها را بیش از حد

272
00:16:10,260 --> 00:16:12,780
پیچیده کند، اما خواهید دید که چرا داشتن هر دو عدد در یک دقیقه مفید است.

273
00:16:12,780 --> 00:16:16,780
بنابراین در اینجا به نظر می رسد که بالاترین آنتروپی را برای حدس

274
00:16:16,780 --> 00:16:19,700
دوم ما رامن نشان می دهد، که دوباره واقعاً شبیه یک کلمه نیست.

275
00:16:19,700 --> 00:16:25,660
بنابراین برای اینکه در اینجا از اخلاقیات بالاتری برخوردار باشم، می‌روم و Rains را تایپ می‌کنم.

276
00:16:25,660 --> 00:16:27,540
و دوباره به نظر می رسد که ما کمی بدشانس بودیم.

277
00:16:27,540 --> 00:16:32,100
ما منتظر 4 بودیم. 3 بیت و ما فقط 3 بیت گرفتیم. 39 بیت اطلاعات

278
00:16:32,100 --> 00:16:35,060
بنابراین ما را به 55 احتمال کاهش می دهد.

279
00:16:35,060 --> 00:16:38,860
و در اینجا شاید من در واقع به آنچه که پیشنهاد

280
00:16:38,860 --> 00:16:40,200
می کند، که ترکیبی است، هر معنایی که دارد، ادامه دهم.

281
00:16:40,200 --> 00:16:43,300
و خوب، این در واقع فرصت خوبی برای یک پازل است.

282
00:16:43,300 --> 00:16:47,020
به ما می گوید که این الگو به ما 4 می دهد. 7 بیت اطلاعات

283
00:16:47,020 --> 00:16:52,400
اما در سمت چپ، قبل از اینکه آن الگو را ببینیم، 5 مورد وجود داشت. ۷۸ بیت عدم قطعیت

284
00:16:52,400 --> 00:16:56,860
بنابراین به عنوان یک مسابقه برای شما، این به چه معناست در مورد تعداد احتمالات باقی مانده؟

285
00:16:56,860 --> 00:17:02,280
خوب، به این معنی است که ما به یک بیت عدم قطعیت کاهش

286
00:17:02,280 --> 00:17:04,700
یافته ایم، که همان چیزی است که بگوییم دو پاسخ ممکن وجود دارد.

287
00:17:04,700 --> 00:17:06,520
این یک انتخاب 50-50 است.

288
00:17:06,520 --> 00:17:09,860
و از اینجا، چون من و شما می دانیم که کدام

289
00:17:09,860 --> 00:17:11,220
کلمات رایج تر است، می دانیم که پاسخ باید پرتگاه باشد.

290
00:17:11,220 --> 00:17:13,540
اما همانطور که در حال حاضر نوشته شده است، برنامه این را نمی داند.

291
00:17:13,540 --> 00:17:17,560
بنابراین فقط به راه خود ادامه می دهد و سعی می کند تا جایی که می تواند اطلاعات

292
00:17:17,560 --> 00:17:20,360
بیشتری به دست آورد، تا زمانی که تنها یک احتمال باقی بماند و سپس آن را حدس بزند.

293
00:17:20,360 --> 00:17:22,700
بنابراین بدیهی است که ما به یک استراتژی آخر بازی بهتر نیاز داریم.

294
00:17:22,700 --> 00:17:26,540
اما فرض کنید این نسخه را یکی از حل کننده های wordle خود می نامیم و سپس

295
00:17:26,540 --> 00:17:30,740
می رویم و شبیه سازی هایی را اجرا می کنیم تا ببینیم چگونه کار می کند.

296
00:17:30,740 --> 00:17:34,240
بنابراین روشی که این کار می کند این است که همه بازی های wordle ممکن را انجام می دهد.

297
00:17:34,240 --> 00:17:38,780
در حال بررسی تمام آن 2315 کلمه است که پاسخ های واقعی کلمه هستند.

298
00:17:38,780 --> 00:17:41,340
این اساساً از آن به عنوان یک مجموعه آزمایشی استفاده می کند.

299
00:17:41,340 --> 00:17:45,820
و با این روش ساده لوحانه در نظر نگرفتن میزان رایج بودن یک کلمه، و فقط تلاش برای به

300
00:17:45,820 --> 00:17:50,480
حداکثر رساندن اطلاعات در هر مرحله از مسیر، تا زمانی که به یک و تنها یک انتخاب می رسد.

301
00:17:50,480 --> 00:17:55,100
در پایان شبیه سازی، میانگین امتیاز حدود 4 خواهد بود. 124.

302
00:17:55,100 --> 00:17:59,780
که بد نیست، صادقانه بگویم، انتظار داشتم بدتر از این کار کنم.

303
00:17:59,780 --> 00:18:03,040
اما افرادی که wordle بازی می کنند به شما خواهند گفت که معمولاً می توانند آن را در 4 دریافت کنند.

304
00:18:03,040 --> 00:18:05,260
چالش واقعی این است که تا می توانید تعداد زیادی در 3 بدست آورید.

305
00:18:05,260 --> 00:18:08,920
این یک جهش بسیار بزرگ بین امتیاز 4 و نمره 3 است.

306
00:18:08,920 --> 00:18:13,300
میوه کم آویزان واضح در اینجا این است که به نحوی مشخص کنیم که یک

307
00:18:13,300 --> 00:18:23,160
کلمه رایج است یا نه، و دقیقاً چگونه این کار را انجام می دهیم.

308
00:18:23,160 --> 00:18:26,860
روشی که من به آن نزدیک شدم دریافت لیستی از

309
00:18:26,860 --> 00:18:28,560
بسامدهای نسبی برای همه کلمات در زبان انگلیسی است.

310
00:18:28,560 --> 00:18:32,560
و من فقط از تابع داده فرکانس کلمه Mathematica استفاده کردم، که خود

311
00:18:32,560 --> 00:18:35,520
از مجموعه داده عمومی Ngram انگلیسی کتاب های گوگل استخراج می شود.

312
00:18:35,520 --> 00:18:38,680
و نگاه کردن به آن به نوعی سرگرم کننده است، برای مثال اگر

313
00:18:38,680 --> 00:18:40,120
آن را از رایج ترین کلمات به کم رایج ترین کلمات مرتب کنیم.

314
00:18:40,120 --> 00:18:43,740
بدیهی است که اینها متداول ترین کلمات 5 حرفی در زبان انگلیسی هستند.

315
00:18:43,740 --> 00:18:46,480
یا بهتر است بگوییم، اینها هشتمین مورد رایج هستند.

316
00:18:46,480 --> 00:18:49,440
اول این است که، پس از آن وجود دارد و وجود دارد.

317
00:18:49,440 --> 00:18:53,020
اولین به خودی خود اول نیست، بلکه نهمین است، و منطقی است که

318
00:18:53,020 --> 00:18:57,840
این کلمات دیگر ممکن است بیشتر به وجود بیایند، جایی که کلمات بعد

319
00:18:57,840 --> 00:18:59,000
از اولین بعد هستند، کجا، و آنهایی که فقط کمی کمتر رایج هستند.

320
00:18:59,000 --> 00:19:04,400
حال، در استفاده از این داده‌ها برای مدل‌سازی احتمال اینکه هر یک

321
00:19:04,400 --> 00:19:06,760
از این کلمات پاسخ نهایی باشد، نباید فقط با فراوانی متناسب باشد.

322
00:19:07,020 --> 00:19:12,560
به عنوان مثال، به آن نمره 0 داده می شود. 002 در این مجموعه داده، در حالی

323
00:19:12,560 --> 00:19:15,200
که احتمال کلمه braid به نوعی حدود 1000 برابر کمتر است.

324
00:19:15,200 --> 00:19:19,400
اما هر دوی اینها به اندازه کافی کلمات رایجی هستند که تقریباً ارزش بررسی را دارند.

325
00:19:19,400 --> 00:19:21,900
بنابراین ما یک قطع باینری بیشتر می خواهیم.

326
00:19:21,900 --> 00:19:26,520
راهی که من در مورد آن رفتم این بود که تصور کنم کل این فهرست مرتب شده از

327
00:19:26,520 --> 00:19:31,060
کلمات را بگیرم، و سپس آن را بر روی محور x مرتب کنیم، و سپس تابع sigmoid

328
00:19:31,060 --> 00:19:35,540
را اعمال کنیم، که روش استاندارد برای داشتن تابعی است که خروجی آن اساساً باینری است. یا 0

329
00:19:35,540 --> 00:19:38,500
یا 1 است، اما یک هموارسازی در این بین برای آن ناحیه از عدم قطعیت وجود دارد.

330
00:19:38,500 --> 00:19:43,900
بنابراین، اساساً، احتمالی که من به هر کلمه برای قرار گرفتن در لیست نهایی اختصاص

331
00:19:43,900 --> 00:19:49,540
می‌دهم، مقدار تابع سیگموئید در بالا هرجا که روی محور x قرار می‌گیرد، خواهد بود.

332
00:19:49,540 --> 00:19:53,940
اکنون بدیهی است که این بستگی به چند پارامتر دارد، برای مثال اینکه چقدر فضایی در محور

333
00:19:53,940 --> 00:19:59,660
x آن کلمات پر می‌شود، تعیین می‌کند که چقدر تدریجی یا تند از 1 به 0

334
00:19:59,660 --> 00:20:03,000
می‌افتیم، و جایی که آنها را از چپ به راست قرار می‌دهیم، برش را تعیین می‌کند.

335
00:20:03,160 --> 00:20:07,340
صادقانه بگویم، روشی که من این کار را کردم فقط لیسیدن انگشتم و چسباندن آن به باد بود.

336
00:20:07,340 --> 00:20:10,800
من فهرست مرتب شده را نگاه کردم و سعی کردم پنجره ای پیدا کنم که

337
00:20:10,800 --> 00:20:15,280
وقتی به آن نگاه کردم متوجه شدم حدود نیمی از این کلمات بیشتر از

338
00:20:15,280 --> 00:20:17,680
اینکه پاسخ نهایی نباشند، هستند و از آن به عنوان نقطه برش استفاده کردم.

339
00:20:17,680 --> 00:20:21,840
هنگامی که توزیعی مانند این در بین کلمات داشته باشیم، موقعیت دیگری به ما می

340
00:20:21,840 --> 00:20:24,460
دهد که در آن آنتروپی به این اندازه گیری واقعا مفید تبدیل می شود.

341
00:20:24,460 --> 00:20:28,480
به عنوان مثال، فرض کنید در حال انجام یک بازی بودیم و با بازکن های

342
00:20:28,480 --> 00:20:32,480
قدیمی من که یک پر و میخ بودند شروع می کنیم و در نهایت به

343
00:20:32,480 --> 00:20:33,760
موقعیتی می رسیم که چهار کلمه ممکن است که با آن مطابقت داشته باشد.

344
00:20:33,760 --> 00:20:36,440
و بیایید بگوییم که همه آنها را به یک اندازه محتمل در نظر می گیریم.

345
00:20:36,440 --> 00:20:40,000
اجازه دهید از شما بپرسم آنتروپی این توزیع چیست؟

346
00:20:40,000 --> 00:20:45,920
خوب، اطلاعات مرتبط با هر یک از این احتمالات، پایه گزارش 2 از 4

347
00:20:45,920 --> 00:20:50,800
خواهد بود، زیرا هر کدام 1 و 4 هستند و آن 2 است.

348
00:20:50,800 --> 00:20:52,780
دو بیت اطلاعات، چهار احتمال.

349
00:20:52,780 --> 00:20:54,360
همه چیز خیلی خوب و عالی

350
00:20:54,360 --> 00:20:58,320
اما اگر به شما بگویم که در واقع بیش از چهار مسابقه وجود دارد، چه؟

351
00:20:58,320 --> 00:21:02,600
در حقیقت، وقتی فهرست کامل کلمات را بررسی می کنیم، 16 کلمه وجود دارد که با آن مطابقت دارند.

352
00:21:02,600 --> 00:21:07,260
اما فرض کنید مدل ما احتمال بسیار کمی را برای آن 12 کلمه دیگر قرار می دهد

353
00:21:07,260 --> 00:21:11,440
که واقعاً پاسخ نهایی باشد، چیزی در حدود 1 در 1000 زیرا آنها واقعا مبهم هستند.

354
00:21:11,440 --> 00:21:15,480
حالا اجازه بدهید از شما بپرسم که آنتروپی این توزیع چقدر است؟

355
00:21:15,480 --> 00:21:19,600
اگر آنتروپی صرفاً تعداد منطبق‌ها را در اینجا اندازه‌گیری می‌کرد، ممکن است

356
00:21:19,600 --> 00:21:24,760
انتظار داشته باشید که چیزی شبیه پایه گزارش 2 از 16 باشد،

357
00:21:24,760 --> 00:21:26,200
که 4 بیت خواهد بود، دو بیت عدم قطعیت بیشتر از قبل.

358
00:21:26,200 --> 00:21:30,320
اما مطمئناً عدم قطعیت واقعی واقعاً با آنچه قبلاً داشتیم متفاوت نیست.

359
00:21:30,320 --> 00:21:33,840
فقط به این دلیل که این ۱۲ کلمه واقعا مبهم وجود دارد، به این معنا

360
00:21:33,840 --> 00:21:38,200
نیست که برای مثال، دانستن اینکه پاسخ نهایی جذابیت است، بسیار شگفت‌انگیزتر خواهد بود.

361
00:21:38,200 --> 00:21:42,080
بنابراین وقتی محاسبه را در اینجا انجام می‌دهید و احتمال وقوع هر وقوع را

362
00:21:42,080 --> 00:21:45,960
ضربدر اطلاعات مربوطه جمع می‌کنید، چیزی که به دست می‌آورید 2 است. 11 بیت.

363
00:21:45,960 --> 00:21:50,280
من فقط می گویم، اساساً این دو بیت است، اساساً آن چهار احتمال، اما

364
00:21:50,280 --> 00:21:54,240
به دلیل همه آن رویدادهای بسیار بعید، کمی عدم اطمینان بیشتر وجود دارد، اگرچه

365
00:21:54,240 --> 00:21:57,120
اگر آنها را یاد بگیرید، اطلاعات زیادی از آن به دست خواهید آورد.

366
00:21:57,120 --> 00:22:00,800
بنابراین، با کوچک‌نمایی، این بخشی از چیزی است که Wordle را

367
00:22:00,800 --> 00:22:01,800
به یک مثال خوب برای درس تئوری اطلاعات تبدیل می‌کند.

368
00:22:01,800 --> 00:22:05,280
ما این دو کاربرد احساسی متمایز را برای آنتروپی داریم.

369
00:22:05,280 --> 00:22:09,640
اولی به ما می‌گوید اطلاعات مورد انتظاری که از یک حدس

370
00:22:09,640 --> 00:22:14,560
به دست می‌آوریم چیست، و دومی می‌گوید آیا می‌توانیم عدم قطعیت

371
00:22:14,560 --> 00:22:16,480
باقی‌مانده را در بین همه کلماتی که ممکن است اندازه‌گیری کنیم.

372
00:22:16,480 --> 00:22:19,800
و من باید تأکید کنم، در اولین مورد که ما به اطلاعات مورد انتظار یک حدس نگاه

373
00:22:19,800 --> 00:22:25,000
می کنیم، زمانی که وزن نابرابر کلمات را داشته باشیم، بر محاسبه آنتروپی تأثیر می گذارد.

374
00:22:25,000 --> 00:22:28,600
برای مثال، اجازه دهید همان موردی را که قبلاً در مورد

375
00:22:28,600 --> 00:22:33,560
توزیع مرتبط با Weary بررسی می‌کردیم، بیاورم، اما این بار

376
00:22:33,560 --> 00:22:34,560
با استفاده از یک توزیع غیریکنواخت در همه کلمات ممکن.

377
00:22:34,560 --> 00:22:39,360
بنابراین اجازه دهید ببینم آیا می توانم بخشی را در اینجا پیدا کنم که آن را به خوبی نشان دهد.

378
00:22:39,360 --> 00:22:42,480
خوب، اینجا خیلی خوب است.

379
00:22:42,480 --> 00:22:46,360
در اینجا ما دو الگوی مجاور داریم که احتمال آنها تقریباً یکسان است، اما یکی از آنها

380
00:22:46,360 --> 00:22:49,480
که به ما گفته شده است دارای 32 کلمه ممکن است که با آن مطابقت دارد.

381
00:22:49,480 --> 00:22:54,080
و اگر بررسی کنیم که آنها چه هستند، این 32 مورد هستند، که همه

382
00:22:54,080 --> 00:22:55,600
آنها کلمات بسیار بعید هستند که چشمان خود را روی آنها اسکن می کنید.

383
00:22:55,600 --> 00:23:00,400
به سختی می‌توان پاسخ‌هایی را پیدا کرد که شبیه پاسخ‌های قابل قبول باشد، شاید فریاد

384
00:23:00,400 --> 00:23:04,440
بزند، اما اگر به الگوی همسایه در توزیع نگاه کنیم، که تقریباً به همان اندازه

385
00:23:04,440 --> 00:23:08,920
محتمل در نظر گرفته می‌شود، به ما گفته می‌شود که فقط 8 مطابقت ممکن دارد،

386
00:23:08,920 --> 00:23:09,920
بنابراین یک چهارم بسیاری از مسابقات، اما احتمال آن تقریباً به همان اندازه است.

387
00:23:09,920 --> 00:23:12,520
و وقتی آن مسابقات را انجام دهیم، می‌توانیم دلیل آن را ببینیم.

388
00:23:12,520 --> 00:23:17,840
برخی از این ها پاسخ های واقعی هستند، مانند حلقه، خشم، یا رپ.

389
00:23:17,840 --> 00:23:22,000
برای نشان دادن اینکه چگونه همه اینها را ترکیب می کنیم، اجازه دهید نسخه 2 Wordlebot

390
00:23:22,000 --> 00:23:25,960
را اینجا بیاورم، و دو یا سه تفاوت اصلی با نسخه اولی که دیدیم وجود دارد.

391
00:23:25,960 --> 00:23:29,460
اول از همه، همانطور که قبلاً گفتم، روشی که ما این آنتروپی‌ها، این مقادیر

392
00:23:29,460 --> 00:23:34,800
مورد انتظار اطلاعات را محاسبه می‌کنیم، اکنون از توزیع‌های دقیق‌تر در سراسر الگوها استفاده

393
00:23:34,800 --> 00:23:39,300
می‌کند که احتمال اینکه یک کلمه معین واقعاً پاسخ باشد را در بر می‌گیرد.

394
00:23:39,300 --> 00:23:44,160
همانطور که اتفاق می افتد، اشک هنوز شماره 1 است، اگرچه موارد زیر کمی متفاوت هستند.

395
00:23:44,160 --> 00:23:47,920
دوم، زمانی که انتخاب های برتر خود را رتبه بندی می کند، اکنون مدلی از احتمال اینکه

396
00:23:47,920 --> 00:23:52,600
هر کلمه پاسخ واقعی است را حفظ می کند، و آن را در تصمیم خود لحاظ می

397
00:23:52,600 --> 00:23:55,520
کند، که وقتی چند حدس در مورد آن داشته باشیم، دیدن آن آسان تر است. جدول.

398
00:23:55,520 --> 00:24:01,120
باز هم، نادیده گرفتن توصیه آن، زیرا نمی توانیم اجازه دهیم ماشین ها بر زندگی ما حکومت کنند.

399
00:24:01,120 --> 00:24:05,160
و فکر می‌کنم باید به چیز دیگری اشاره کنم که در اینجا در سمت چپ است،

400
00:24:05,160 --> 00:24:10,080
این که مقدار عدم قطعیت، آن تعداد بیت‌ها، دیگر فقط با تعداد تطابق‌های ممکن اضافی نیست.

401
00:24:10,080 --> 00:24:16,520
حالا اگر آن را بالا بکشیم و 2 تا 8 را محاسبه کنیم. 02، که کمی بالاتر از 256 است،

402
00:24:16,520 --> 00:24:22,640
حدس می‌زنم 259، چیزی که می‌گوید این است که با وجود اینکه در کل 526

403
00:24:22,640 --> 00:24:26,400
کلمه وجود دارد که واقعاً با این الگو مطابقت دارند، میزان عدم قطعیت آن بیشتر

404
00:24:26,400 --> 00:24:29,760
شبیه به چیزی است که اگر 259 به یک اندازه احتمال وجود داشت. عواقب.

405
00:24:29,760 --> 00:24:31,100
شما می توانید آن را اینگونه فکر کنید.

406
00:24:31,100 --> 00:24:35,560
می‌داند که بورکس جوابگو نیست، همینطور در مورد یورتس و زورل

407
00:24:35,560 --> 00:24:37,840
و زوروس، بنابراین نسبت به حالت قبلی نامشخص کمی کمتر است.

408
00:24:37,840 --> 00:24:40,220
این تعداد بیت کمتر خواهد بود.

409
00:24:40,220 --> 00:24:44,040
و اگر به بازی ادامه دهم، این را با

410
00:24:44,040 --> 00:24:48,680
چند حدس که در اینجا توضیح می‌دهم مناسب است.

411
00:24:48,680 --> 00:24:52,520
با حدس چهارم، اگر به انتخاب های برتر آن نگاه کنید،

412
00:24:52,520 --> 00:24:53,800
می بینید که دیگر فقط آنتروپی را به حداکثر نمی رساند.

413
00:24:53,800 --> 00:24:58,480
بنابراین در این مرحله، از نظر فنی هفت احتمال وجود دارد،

414
00:24:58,480 --> 00:25:00,780
اما تنها مواردی که شانس معناداری دارند خوابگاه‌ها و کلمات هستند.

415
00:25:00,780 --> 00:25:04,760
و می‌توانید ببینید که هر دوی آن‌ها را بالاتر از همه این مقادیر

416
00:25:04,760 --> 00:25:07,560
دیگر رتبه‌بندی می‌کند، که به‌طور دقیق‌تر می‌توان اطلاعات بیشتری را ارائه کرد.

417
00:25:07,560 --> 00:25:11,200
اولین باری که این کار را انجام دادم، فقط این دو عدد را جمع کردم تا کیفیت

418
00:25:11,200 --> 00:25:14,580
هر حدس را اندازه‌گیری کنم، که در واقع بهتر از چیزی که فکر می‌کنید جواب داد.

419
00:25:14,580 --> 00:25:17,600
اما واقعاً سیستماتیک به نظر نمی‌رسید، و من مطمئن هستم که روش‌های دیگری هم وجود دارد که

420
00:25:17,600 --> 00:25:19,880
مردم می‌توانند از آن استفاده کنند، اما این همان رویکردی است که من به آن دست یافتم.

421
00:25:19,880 --> 00:25:24,200
اگر به احتمال حدس بعدی فکر می کنیم، مانند کلمات این مورد، چیزی که واقعاً به

422
00:25:24,200 --> 00:25:28,440
آن اهمیت می دهد، امتیاز مورد انتظار بازی ما در صورت انجام این کار است.

423
00:25:28,440 --> 00:25:32,880
و برای محاسبه آن امتیاز مورد انتظار، می گوییم احتمال اینکه کلمات پاسخ واقعی

424
00:25:32,880 --> 00:25:35,640
باشند چقدر است، که در حال حاضر 58٪ آن را توصیف می کند.

425
00:25:36,080 --> 00:25:40,400
می گوییم با شانس 58 درصد امتیاز ما در این بازی 4 می شود.

426
00:25:40,400 --> 00:25:46,240
و سپس با احتمال 1 منهای آن 58 درصد امتیاز ما بیشتر از آن 4 خواهد شد.

427
00:25:46,240 --> 00:25:50,640
ما چقدر بیشتر نمی دانیم، اما می توانیم آن را بر اساس

428
00:25:50,640 --> 00:25:52,920
میزان عدم قطعیت احتمالی پس از رسیدن به آن نقطه تخمین بزنیم.

429
00:25:52,920 --> 00:25:56,600
به طور خاص، در حال حاضر 1 وجود دارد. 44 بیت عدم قطعیت

430
00:25:56,600 --> 00:26:01,560
اگر کلمات را حدس بزنیم، به ما می گوید که اطلاعات مورد انتظاری که به دست می آوریم 1 است. 27 بیت.

431
00:26:01,560 --> 00:26:06,280
بنابراین اگر کلمات را حدس بزنیم، این تفاوت نشان‌دهنده میزان

432
00:26:06,280 --> 00:26:08,280
عدم قطعیتی است که بعد از این اتفاق می‌افتد.

433
00:26:08,280 --> 00:26:12,500
آنچه ما نیاز داریم نوعی تابع است که من در اینجا آن را f

434
00:26:12,500 --> 00:26:13,880
می نامم، که این عدم قطعیت را با نمره مورد انتظار مرتبط می کند.

435
00:26:13,880 --> 00:26:18,040
و روشی که در مورد این کار پیش رفت این بود که مجموعه ای از داده

436
00:26:18,040 --> 00:26:23,920
های بازی های قبلی را بر اساس نسخه 1 ربات ترسیم کنیم تا بگوییم که امتیاز

437
00:26:23,920 --> 00:26:27,040
واقعی بعد از نقاط مختلف با مقادیر بسیار قابل اندازه گیری عدم قطعیت چقدر بود.

438
00:26:27,040 --> 00:26:31,120
برای مثال، این داده‌ها در اینجا نقاطی را نشان می‌دهند که بالای یک مقدار تقریباً 8 قرار دارند. 7

439
00:26:31,120 --> 00:26:36,840
یا بیشتر برای برخی از بازی ها بعد از یک نقطه که در آن 8 بود می گویند. 7 بیت عدم

440
00:26:36,840 --> 00:26:39,340
قطعیت، دو حدس طول کشید تا به جواب نهایی رسید.

441
00:26:39,340 --> 00:26:43,180
برای بازی‌های دیگر سه حدس و برای بازی‌های دیگر چهار حدس انجام شد.

442
00:26:43,180 --> 00:26:46,920
اگر در اینجا به سمت چپ حرکت کنیم، تمام نقاط بالای صفر می‌گویند که

443
00:26:46,920 --> 00:26:51,620
هرگاه بیت‌های عدم قطعیت صفر وجود داشته باشد، یعنی فقط یک احتمال وجود

444
00:26:51,620 --> 00:26:55,000
دارد، پس تعداد حدس‌های مورد نیاز همیشه فقط یک است که اطمینان‌بخش است.

445
00:26:55,000 --> 00:26:59,020
هر زمان که یک ذره عدم قطعیت وجود داشت، به این معنی

446
00:26:59,020 --> 00:27:02,360
که اساساً فقط به دو احتمال می رسید، سپس گاهی به یک

447
00:27:02,360 --> 00:27:03,940
حدس بیشتر نیاز داشت، گاهی اوقات نیاز به دو حدس دیگر داشت.

448
00:27:03,940 --> 00:27:05,980
و غیره و غیره اینجا.

449
00:27:05,980 --> 00:27:11,020
شاید یک راه کمی ساده تر برای تجسم این داده ها این باشد که آنها را با هم جمع کنید و میانگین ها را بگیرید.

450
00:27:11,020 --> 00:27:15,940
به عنوان مثال، این نوار در اینجا می گوید در بین تمام نقاطی که در آن یک

451
00:27:15,940 --> 00:27:22,420
بیت عدم قطعیت داشتیم، به طور متوسط تعداد حدس های جدید مورد نیاز حدود 1 بود. 5.

452
00:27:22,420 --> 00:27:25,920
و نواری که در اینجا در میان همه بازی‌های مختلف می‌گوید که در

453
00:27:25,920 --> 00:27:30,480
آن عدم قطعیت کمی بالاتر از چهار بیت بود، که مانند کاهش

454
00:27:30,480 --> 00:27:35,120
آن به 16 احتمال مختلف است، سپس به طور متوسط به کمی

455
00:27:35,120 --> 00:27:36,240
بیش از دو حدس از آن نقطه نیاز دارد. رو به جلو.

456
00:27:36,240 --> 00:27:40,080
و از اینجا من فقط یک رگرسیون انجام دادم تا تابعی را که برای این کار معقول به نظر می‌رسید، جا بدهم.

457
00:27:40,080 --> 00:27:44,160
و به یاد داشته باشید که تمام هدف انجام هر یک از این کارها این است که بتوانیم این شهود

458
00:27:44,160 --> 00:27:49,720
را کمیت کنیم که هرچه اطلاعات بیشتری از یک کلمه به دست آوریم، امتیاز مورد انتظار کمتر خواهد بود.

459
00:27:49,720 --> 00:27:54,380
بنابراین با این نسخه 2. 0، اگر به عقب برگردیم و همان مجموعه شبیه‌سازی‌ها را اجرا

460
00:27:54,380 --> 00:27:59,820
کنیم و آن را با تمام 2315 پاسخ wordle ممکن بازی کنیم، چگونه انجام می‌شود؟

461
00:27:59,820 --> 00:28:04,060
خوب بر خلاف نسخه اول ما، قطعا بهتر است، که اطمینان بخش است.

462
00:28:04,060 --> 00:28:08,780
همه گفته‌ها و انجام‌ها میانگین حدود 3 است. 6، اگرچه بر خلاف نسخه اول چند بار است

463
00:28:08,780 --> 00:28:12,820
که از دست می دهد و در این شرایط به بیش از شش نیاز دارد.

464
00:28:12,820 --> 00:28:15,980
احتمالاً به این دلیل که مواقعی وجود دارد که به

465
00:28:15,980 --> 00:28:18,980
جای به حداکثر رساندن اطلاعات، به دنبال هدف است.

466
00:28:18,980 --> 00:28:22,140
پس آیا می توانیم بهتر از 3 کار کنیم. 6

467
00:28:22,140 --> 00:28:23,260
ما قطعا می توانیم.

468
00:28:23,260 --> 00:28:27,120
اکنون در ابتدا گفتم که بسیار سرگرم کننده است که سعی کنید لیست واقعی پاسخ

469
00:28:27,120 --> 00:28:29,980
های wordle را در روشی که مدل خود را ایجاد می کند ترکیب نکنید.

470
00:28:29,980 --> 00:28:35,180
اما اگر آن را در نظر بگیریم، بهترین عملکردی که می توانستم داشته باشم حدود 3 بود. 43.

471
00:28:35,180 --> 00:28:39,520
بنابراین، اگر سعی کنیم پیچیده‌تر از استفاده از داده‌های بسامد کلمه برای انتخاب این توزیع

472
00:28:39,520 --> 00:28:44,220
قبلی، این 3 باشد. 43 احتمالاً حداكثری را نشان می‌دهد كه چقدر می‌توانیم

473
00:28:44,220 --> 00:28:46,360
با آن خوب شویم، یا حداقل چقدر می‌توانم با آن خوب شوم.

474
00:28:46,360 --> 00:28:50,240
این بهترین عملکرد اساساً فقط از ایده هایی استفاده می کند که من

475
00:28:50,240 --> 00:28:53,400
در اینجا در مورد آنها صحبت کردم، اما کمی فراتر می رود، مانند

476
00:28:53,400 --> 00:28:55,660
جستجوی اطلاعات مورد انتظار دو گام به جلو و نه فقط یک قدم.

477
00:28:55,660 --> 00:28:58,720
در ابتدا من قصد داشتم بیشتر در مورد آن صحبت کنم، اما متوجه

478
00:28:58,720 --> 00:29:00,580
شدم که ما در واقع تا حدی که هست پیش رفته ایم.

479
00:29:00,580 --> 00:29:03,520
تنها چیزی که من می گویم این است که پس از انجام این جستجوی

480
00:29:03,520 --> 00:29:07,720
دو مرحله ای و سپس اجرای چند شبیه سازی نمونه در کاندیداهای برتر، حداقل

481
00:29:07,720 --> 00:29:09,500
تا کنون برای من به نظر می رسد که کرین بهترین بازکننده است.

482
00:29:09,500 --> 00:29:11,080
چه کسی حدس می زد؟

483
00:29:11,080 --> 00:29:15,680
همچنین اگر از لیست wordle واقعی برای تعیین فضای احتمالی خود استفاده کنید، عدم

484
00:29:15,680 --> 00:29:17,920
قطعیتی که با آن شروع می کنید کمی بیش از 11 بیت است.

485
00:29:18,160 --> 00:29:22,760
و معلوم شد، فقط از یک جستجوی brute force، حداکثر اطلاعات مورد

486
00:29:22,760 --> 00:29:26,580
انتظار ممکن پس از دو حدس اول حدود 10 بیت است.

487
00:29:26,580 --> 00:29:31,720
این نشان می دهد که بهترین سناریو، پس از دو حدس اول شما،

488
00:29:31,720 --> 00:29:35,220
با بازی کاملاً بهینه، تقریباً با یک بیت عدم اطمینان روبرو خواهید شد.

489
00:29:35,220 --> 00:29:37,400
که همان است که به دو حدس ممکن است.

490
00:29:37,400 --> 00:29:41,440
بنابراین من فکر می کنم منصفانه و احتمالاً محافظه کارانه است که بگوییم شما هرگز نمی

491
00:29:41,440 --> 00:29:45,620
توانید الگوریتمی بنویسید که این میانگین را به 3 برساند، زیرا با کلماتی که در

492
00:29:45,620 --> 00:29:50,460
دسترس شما هستند، به سادگی پس از دو مرحله دیگر جایی برای به دست آوردن اطلاعات

493
00:29:50,460 --> 00:29:53,820
کافی وجود ندارد. قادر به تضمین پاسخ در شکاف سوم هر بار بدون شکست است.

