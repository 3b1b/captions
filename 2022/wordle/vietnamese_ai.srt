1
00:00:00,000 --> 00:00:04,040
Trò chơi Wurdle đã lan truyền khá rộng rãi trong một hoặc hai tháng qua và không

2
00:00:04,040 --> 00:00:07,880
bao giờ người ta bỏ qua cơ hội học toán, tôi chợt nhận ra rằng trò

3
00:00:07,880 --> 00:00:12,120
chơi này là một ví dụ trung tâm rất hay trong bài học về lý thuyết

4
00:00:12,120 --> 00:00:13,120
thông tin và đặc biệt là trò chơi này. một chủ đề được gọi là entropy.

5
00:00:13,120 --> 00:00:17,120
Bạn thấy đấy, giống như nhiều người, tôi bị cuốn hút vào câu đố, và

6
00:00:17,120 --> 00:00:21,200
giống như nhiều lập trình viên, tôi cũng bị cuốn hút vào việc cố gắng

7
00:00:21,200 --> 00:00:23,200
viết một thuật toán để chơi trò chơi một cách tối ưu nhất có thể.

8
00:00:23,200 --> 00:00:26,400
Và điều tôi nghĩ tôi sẽ làm ở đây chỉ là trao đổi với bạn một

9
00:00:26,400 --> 00:00:29,980
số quy trình của tôi trong đó và giải thích một số phép toán liên

10
00:00:29,980 --> 00:00:32,080
quan đến nó, vì toàn bộ thuật toán tập trung vào ý tưởng về entropy.

11
00:00:32,080 --> 00:00:42,180
Trước hết, trong trường hợp bạn chưa từng nghe đến nó, Wurdle là gì?

12
00:00:42,180 --> 00:00:45,380
Và để một mũi tên trúng hai con chim ở đây trong khi chúng ta đi qua các

13
00:00:45,380 --> 00:00:48,980
quy tắc của trò chơi, hãy để tôi xem trước chúng ta sẽ đi đâu với điều này,

14
00:00:48,980 --> 00:00:51,380
đó là phát triển một thuật toán nhỏ về cơ bản sẽ chơi trò chơi cho chúng ta.

15
00:00:51,380 --> 00:00:54,860
Mặc dù tôi chưa thực hiện Wurdle của ngày hôm nay nhưng đây là ngày

16
00:00:54,860 --> 00:00:55,860
4 tháng 2 và chúng ta sẽ xem con bot hoạt động như thế nào.

17
00:00:55,860 --> 00:00:59,580
Mục tiêu của Wurdle là đoán một từ có năm chữ cái

18
00:00:59,580 --> 00:01:00,860
bí ẩn và bạn có sáu cơ hội đoán khác nhau.

19
00:01:00,860 --> 00:01:05,240
Ví dụ: bot Wurdle của tôi gợi ý rằng tôi nên bắt đầu với cần cẩu đoán.

20
00:01:05,240 --> 00:01:09,300
Mỗi lần bạn đoán, bạn sẽ nhận được một số thông tin về mức

21
00:01:09,300 --> 00:01:10,940
độ gần đúng của suy đoán của bạn với câu trả lời đúng.

22
00:01:10,940 --> 00:01:14,540
Ở đây, hộp màu xám cho tôi biết rằng không có chữ C trong câu trả lời thực tế.

23
00:01:14,540 --> 00:01:18,340
Ô màu vàng cho tôi biết có chữ R, nhưng nó không ở vị trí đó.

24
00:01:18,340 --> 00:01:21,820
Ô màu xanh lá cây cho tôi biết từ bí mật

25
00:01:21,820 --> 00:01:22,820
có chữ A và nó ở vị trí thứ ba.

26
00:01:22,820 --> 00:01:24,300
Và rồi không có N và không có E.

27
00:01:24,300 --> 00:01:27,420
Vì vậy, hãy để tôi vào và nói với bot Wurdle thông tin đó.

28
00:01:27,420 --> 00:01:31,500
Chúng tôi bắt đầu với cần cẩu, chúng tôi có màu xám, vàng, xanh lá cây, xám, xám.

29
00:01:31,500 --> 00:01:35,460
Đừng lo lắng về tất cả dữ liệu mà nó đang hiển thị ngay bây giờ, tôi sẽ giải thích điều đó vào thời điểm thích hợp.

30
00:01:35,460 --> 00:01:39,700
Nhưng gợi ý hàng đầu cho lựa chọn thứ hai của chúng tôi thật tồi tệ.

31
00:01:39,700 --> 00:01:43,500
Và dự đoán của bạn thực sự phải là một từ có năm chữ cái, nhưng như

32
00:01:43,500 --> 00:01:45,700
bạn sẽ thấy, nó khá tự do với những gì nó thực sự cho phép bạn đoán.

33
00:01:45,700 --> 00:01:48,860
Trong trường hợp này, chúng tôi thử shtick.

34
00:01:48,860 --> 00:01:50,260
Và được rồi, mọi thứ có vẻ khá tốt.

35
00:01:50,260 --> 00:01:54,580
Chúng ta nhấn chữ S và chữ H, nên chúng ta biết ba chữ cái đầu tiên, chúng ta biết rằng có chữ R.

36
00:01:54,740 --> 00:01:59,740
Và vì vậy nó sẽ giống như SHA gì đó R, hoặc SHA R gì đó.

37
00:01:59,740 --> 00:02:03,200
Và có vẻ như bot Wurdle biết rằng chỉ

38
00:02:03,200 --> 00:02:05,220
có hai khả năng, mảnh vỡ hoặc sắc nét.

39
00:02:05,220 --> 00:02:08,620
Vào thời điểm này, có một sự xung đột giữa chúng, vì vậy tôi đoán có lẽ chỉ

40
00:02:08,620 --> 00:02:11,260
vì nó được sắp xếp theo thứ tự bảng chữ cái nên nó đi kèm với phân đoạn.

41
00:02:11,260 --> 00:02:13,000
Hoan hô, là câu trả lời thực tế.

42
00:02:13,000 --> 00:02:14,660
Vì vậy, chúng tôi đã nhận được nó trong ba.

43
00:02:14,660 --> 00:02:17,740
Nếu bạn đang thắc mắc liệu điều đó có tốt không, thì theo cách

44
00:02:17,740 --> 00:02:20,820
tôi nghe một người nói thì Wurdle bốn là par và ba là birdie.

45
00:02:20,820 --> 00:02:22,960
Mà tôi nghĩ là một sự tương tự khá thích hợp.

46
00:02:22,960 --> 00:02:27,560
Bạn phải kiên trì trong trò chơi của mình để đạt được bốn điểm, nhưng điều đó chắc chắn không điên rồ chút nào.

47
00:02:27,560 --> 00:02:30,000
Nhưng khi bạn nhận được nó trong ba, nó sẽ cảm thấy tuyệt vời.

48
00:02:30,000 --> 00:02:33,800
Vì vậy, nếu bạn không hài lòng, điều tôi muốn làm ở đây chỉ là nói về

49
00:02:33,800 --> 00:02:36,600
quá trình suy nghĩ của tôi ngay từ đầu về cách tôi tiếp cận bot Wurdle.

50
00:02:36,600 --> 00:02:39,800
Và như tôi đã nói, thực ra đó chỉ là cái cớ để học lý thuyết thông tin.

51
00:02:39,800 --> 00:02:43,160
Mục tiêu chính là giải thích thông tin là gì và entropy là gì.

52
00:02:48,560 --> 00:02:52,080
Suy nghĩ đầu tiên của tôi khi tiếp cận vấn đề này là xem

53
00:02:52,080 --> 00:02:53,560
xét tần số tương đối của các chữ cái khác nhau trong tiếng Anh.

54
00:02:53,560 --> 00:02:57,800
Vì vậy, tôi nghĩ, được thôi, có một lần đoán mở đầu hoặc một cặp

55
00:02:57,800 --> 00:02:59,960
đoán mở đầu nào chạm được nhiều chữ cái thường gặp nhất này không?

56
00:02:59,960 --> 00:03:03,780
Và một việc mà tôi khá thích là làm những việc khác sau đó là làm móng.

57
00:03:03,780 --> 00:03:06,980
Ý nghĩ là nếu bạn nhấn vào một chữ cái, bạn biết đấy, bạn sẽ nhận

58
00:03:06,980 --> 00:03:07,980
được màu xanh lá cây hoặc màu vàng, điều đó luôn tạo cảm giác dễ chịu.

59
00:03:07,980 --> 00:03:09,460
Có cảm giác như bạn đang nhận được thông tin.

60
00:03:09,460 --> 00:03:13,140
Nhưng trong những trường hợp này, ngay cả khi bạn không đánh và luôn có

61
00:03:13,140 --> 00:03:16,640
màu xám, điều đó vẫn cung cấp cho bạn nhiều thông tin vì rất hiếm

62
00:03:16,640 --> 00:03:17,640
khi tìm thấy một từ không có bất kỳ chữ cái nào trong số này.

63
00:03:17,640 --> 00:03:21,840
Nhưng dù vậy, điều đó vẫn không mang lại cảm giác siêu hệ thống, vì

64
00:03:21,840 --> 00:03:23,520
chẳng hạn, nó không liên quan gì đến thứ tự của các chữ cái.

65
00:03:23,520 --> 00:03:26,080
Tại sao phải gõ móng tay khi tôi có thể gõ ốc?

66
00:03:26,080 --> 00:03:27,720
Có chữ S ở cuối thì tốt hơn phải không?

67
00:03:27,720 --> 00:03:28,720
Tôi không thực sự chắc chắn.

68
00:03:28,720 --> 00:03:33,500
Một người bạn của tôi nói rằng anh ấy thích mở đầu bằng từ mệt mỏi, điều này làm

69
00:03:33,500 --> 00:03:37,160
tôi khá ngạc nhiên vì trong đó có một số chữ cái không phổ biến như W và Y.

70
00:03:37,160 --> 00:03:39,400
Nhưng ai biết được, có lẽ đó là cách mở đầu tốt hơn.

71
00:03:39,400 --> 00:03:43,920
Có loại điểm định lượng nào đó mà chúng ta có thể đưa

72
00:03:43,920 --> 00:03:44,920
ra để đánh giá chất lượng của một dự đoán tiềm năng không?

73
00:03:44,920 --> 00:03:48,640
Bây giờ để thiết lập cách chúng ta sắp xếp các dự đoán có thể xảy ra,

74
00:03:48,640 --> 00:03:51,800
hãy quay lại và thêm một chút rõ ràng về cách thiết lập chính xác trò chơi.

75
00:03:51,800 --> 00:03:55,880
Vì vậy, có một danh sách các từ mà nó sẽ cho phép bạn

76
00:03:55,880 --> 00:03:57,920
nhập được coi là những từ đoán hợp lệ chỉ dài khoảng 13.000 từ.

77
00:03:57,920 --> 00:04:01,560
Nhưng khi bạn nhìn vào nó, có rất nhiều thứ thực sự không phổ biến, những thứ như cái

78
00:04:01,560 --> 00:04:07,040
đầu hay Ali và ARG, những loại từ gây ra tranh cãi trong gia đình trong trò chơi Scrabble.

79
00:04:07,040 --> 00:04:10,600
Nhưng điều thú vị của trò chơi là câu trả lời luôn là một từ khá phổ biến.

80
00:04:10,600 --> 00:04:16,080
Và trên thực tế, có một danh sách khác khoảng 2300 từ có thể là câu trả lời.

81
00:04:16,080 --> 00:04:20,320
Và đây là danh sách do con người tuyển chọn, tôi nghĩ cụ thể là do

82
00:04:20,320 --> 00:04:21,800
bạn gái của người sáng tạo trò chơi thực hiện, điều này khá thú vị.

83
00:04:21,800 --> 00:04:25,560
Nhưng điều tôi muốn làm, thách thức của chúng tôi đối với dự án này là xem liệu chúng tôi có

84
00:04:25,560 --> 00:04:30,720
thể viết một chương trình giải Wordle mà không kết hợp kiến thức trước đây về danh sách này hay không.

85
00:04:30,720 --> 00:04:34,560
Có một điều, có rất nhiều từ có năm chữ cái khá

86
00:04:34,560 --> 00:04:35,560
phổ biến mà bạn sẽ không tìm thấy trong danh sách đó.

87
00:04:35,560 --> 00:04:38,360
Vì vậy, sẽ tốt hơn nếu viết một chương trình linh hoạt hơn một chút và có thể

88
00:04:38,360 --> 00:04:41,960
chơi Wordle với bất kỳ ai, chứ không chỉ những gì xảy ra trên trang web chính thức.

89
00:04:41,960 --> 00:04:45,900
Và lý do mà chúng tôi biết danh sách các câu trả lời

90
00:04:45,900 --> 00:04:47,440
có thể có này là vì nó hiển thị trong mã nguồn.

91
00:04:47,440 --> 00:04:51,620
Nhưng cách nó hiển thị trong mã nguồn lại theo thứ tự

92
00:04:51,620 --> 00:04:52,840
cụ thể mà các câu trả lời xuất hiện hàng ngày.

93
00:04:52,840 --> 00:04:56,400
Vì vậy, bạn luôn có thể tra cứu xem câu trả lời của ngày mai sẽ là gì.

94
00:04:56,400 --> 00:04:59,140
Vì vậy, rõ ràng là việc sử dụng danh sách là gian lận.

95
00:04:59,140 --> 00:05:02,900
Và điều tạo nên một câu đố thú vị hơn và một bài học lý thuyết thông tin phong

96
00:05:02,900 --> 00:05:07,640
phú hơn là thay vào đó hãy sử dụng một số dữ liệu phổ quát hơn như tần số

97
00:05:07,640 --> 00:05:11,640
từ tương đối nói chung để nắm bắt trực giác về việc ưa thích những từ phổ biến hơn.

98
00:05:11,640 --> 00:05:16,560
Vậy trong 13.000 khả năng này, chúng ta nên chọn dự đoán mở đầu như thế nào?

99
00:05:16,560 --> 00:05:19,960
Ví dụ, nếu bạn tôi đề xuất một cách mệt mỏi, chúng ta nên phân tích chất lượng của nó như thế nào?

100
00:05:19,960 --> 00:05:25,040
Chà, lý do anh ấy nói rằng anh ấy thích chữ W không chắc chắn đó là vì anh ấy

101
00:05:25,040 --> 00:05:27,880
thích bản chất bắn xa của cảm giác tuyệt vời như thế nào nếu bạn đánh được chữ W đó.

102
00:05:27,880 --> 00:05:31,400
Ví dụ: nếu mẫu đầu tiên được tiết lộ giống như thế này, thì hóa

103
00:05:31,400 --> 00:05:36,080
ra chỉ có 58 từ trong từ điển khổng lồ này khớp với mẫu đó.

104
00:05:36,080 --> 00:05:38,900
Vì vậy, đó là một mức giảm rất lớn từ 13.000.

105
00:05:38,900 --> 00:05:43,320
Nhưng mặt trái của điều đó, tất nhiên, là rất hiếm khi có được một mẫu như thế này.

106
00:05:43,360 --> 00:05:47,600
Cụ thể, nếu mỗi từ có khả năng là câu trả lời như nhau

107
00:05:47,600 --> 00:05:51,680
thì xác suất đạt được mẫu này sẽ là 58 chia cho khoảng 13.000.

108
00:05:51,680 --> 00:05:53,880
Tất nhiên, chúng không có khả năng là câu trả lời như nhau.

109
00:05:53,880 --> 00:05:56,680
Hầu hết trong số này là những từ rất mơ hồ và thậm chí có vấn đề.

110
00:05:56,680 --> 00:05:59,560
Nhưng ít nhất trong lần đầu tiên chúng ta vượt qua tất cả những điều này, hãy giả sử rằng

111
00:05:59,560 --> 00:06:02,040
chúng đều có khả năng xảy ra như nhau và sau đó tinh chỉnh điều đó một lát sau.

112
00:06:02,040 --> 00:06:07,360
Vấn đề là mô hình có nhiều thông tin về bản chất khó có thể xảy ra.

113
00:06:07,360 --> 00:06:11,320
Trên thực tế, ý nghĩa của việc cung cấp nhiều thông tin là điều đó khó có thể xảy ra.

114
00:06:11,920 --> 00:06:16,720
Một mô hình có nhiều khả năng xảy ra hơn với phần mở đầu này

115
00:06:16,720 --> 00:06:18,360
sẽ giống như thế này, tất nhiên là không có chữ W trong đó.

116
00:06:18,360 --> 00:06:22,080
Có thể có chữ E, và có thể không có chữ A, không có chữ R, không có chữ Y.

117
00:06:22,080 --> 00:06:24,640
Trong trường hợp này, có 1400 kết quả phù hợp.

118
00:06:24,640 --> 00:06:29,600
Nếu tất cả đều có khả năng như nhau thì có xác

119
00:06:29,600 --> 00:06:30,680
suất khoảng 11% rằng đây là mô hình bạn sẽ thấy.

120
00:06:30,680 --> 00:06:34,320
Vì vậy, những kết quả có thể xảy ra nhất cũng có ít thông tin nhất.

121
00:06:34,320 --> 00:06:38,440
Để có cái nhìn toàn diện hơn ở đây, hãy để tôi chỉ cho bạn sự phân bổ

122
00:06:38,440 --> 00:06:42,000
đầy đủ các xác suất trên tất cả các mẫu khác nhau mà bạn có thể thấy.

123
00:06:42,000 --> 00:06:46,000
Vì vậy, mỗi thanh bạn đang xem tương ứng với một mẫu màu có thể

124
00:06:46,000 --> 00:06:50,500
được tiết lộ, trong đó có từ 3 đến khả năng thứ 5 và chúng

125
00:06:50,500 --> 00:06:52,960
được sắp xếp từ trái sang phải, phổ biến nhất đến ít phổ biến nhất.

126
00:06:52,960 --> 00:06:56,200
Vì vậy, khả năng phổ biến nhất ở đây là bạn có toàn màu xám.

127
00:06:56,200 --> 00:06:58,800
Điều đó xảy ra khoảng 14% thời gian.

128
00:06:58,800 --> 00:07:02,040
Và điều bạn hy vọng khi bạn đoán là bạn sẽ kết thúc ở một nơi nào

129
00:07:02,040 --> 00:07:06,360
đó trong cái đuôi dài này, giống như ở đây, nơi chỉ có 18 khả năng

130
00:07:06,360 --> 00:07:09,920
cho những gì phù hợp với mô hình này mà rõ ràng trông như thế này.

131
00:07:09,920 --> 00:07:14,080
Hoặc nếu chúng ta mạo hiểm xa hơn một chút về phía bên trái, bạn biết đấy, có thể chúng ta sẽ đi hết quãng đường tới đây.

132
00:07:14,080 --> 00:07:16,560
Được rồi, đây là một câu đố hay dành cho bạn.

133
00:07:16,560 --> 00:07:20,600
Ba từ trong tiếng Anh bắt đầu bằng chữ W, kết thúc bằng

134
00:07:20,600 --> 00:07:22,040
chữ Y và có chữ R ở đâu đó trong đó là gì?

135
00:07:22,040 --> 00:07:27,560
Hóa ra, câu trả lời là, hãy xem, dài dòng, sâu sắc và gượng gạo.

136
00:07:27,560 --> 00:07:32,720
Vì vậy, để đánh giá mức độ tốt của từ này nói chung, chúng tôi muốn có một số

137
00:07:32,720 --> 00:07:35,720
thước đo về lượng thông tin mong đợi mà bạn sẽ nhận được từ sự phân phối này.

138
00:07:36,360 --> 00:07:41,080
Nếu chúng ta xem xét từng mẫu và nhân xác suất xảy ra của nó với thứ gì đó để đo

139
00:07:41,080 --> 00:07:46,000
lường mức độ thông tin của nó, thì điều đó có thể cho chúng ta một điểm số khách quan.

140
00:07:46,000 --> 00:07:50,280
Bây giờ, bản năng đầu tiên của bạn về điều gì đó có thể là số lượng trận đấu.

141
00:07:50,280 --> 00:07:52,960
Bạn muốn số lượng trận đấu trung bình thấp hơn.

142
00:07:52,960 --> 00:07:57,400
Nhưng thay vào đó, tôi muốn sử dụng một phép đo phổ quát hơn mà chúng ta thường gán cho

143
00:07:57,400 --> 00:08:01,040
thông tin, và một phép đo sẽ linh hoạt hơn khi chúng ta gán một xác suất khác nhau cho

144
00:08:01,040 --> 00:08:04,320
mỗi từ trong số 13.000 từ này để xem liệu chúng có thực sự là câu trả lời hay không.

145
00:08:10,600 --> 00:08:14,760
Đơn vị thông tin tiêu chuẩn là bit, có công thức hơi buồn cười, nhưng

146
00:08:14,760 --> 00:08:17,800
nó thực sự trực quan nếu chúng ta chỉ nhìn vào các ví dụ.

147
00:08:17,800 --> 00:08:21,880
Nếu bạn có một quan sát làm giảm một nửa không gian khả năng

148
00:08:21,880 --> 00:08:24,200
của bạn, thì chúng tôi nói rằng nó có một chút thông tin.

149
00:08:24,200 --> 00:08:27,680
Trong ví dụ của chúng tôi, không gian của các khả năng là tất cả các từ có thể, và hóa ra khoảng

150
00:08:27,760 --> 00:08:31,560
Một nửa trong số các từ có năm chữ cái có chữ S, ít hơn thế một chút, nhưng khoảng một nửa.

151
00:08:31,560 --> 00:08:35,200
Vì vậy, quan sát đó sẽ cung cấp cho bạn một chút thông tin.

152
00:08:35,200 --> 00:08:39,640
Thay vào đó, nếu một sự kiện mới cắt giảm không gian khả năng đó

153
00:08:39,640 --> 00:08:42,000
đi bốn lần, thì chúng ta nói rằng nó có hai bit thông tin.

154
00:08:42,000 --> 00:08:45,120
Ví dụ, hóa ra khoảng một phần tư những từ này có chữ T.

155
00:08:45,120 --> 00:08:49,720
Nếu sự quan sát cắt không gian đó đi tám lần,

156
00:08:49,720 --> 00:08:50,920
chúng ta nói đó là ba bit thông tin, v.v.

157
00:08:50,920 --> 00:08:55,000
Bốn bit cắt nó thành phần 16, năm bit cắt nó thành phần 32.

158
00:08:55,000 --> 00:09:00,160
Vì vậy, bây giờ bạn có thể muốn tạm dừng và tự hỏi, công

159
00:09:00,160 --> 00:09:04,520
thức thông tin về số bit theo xác suất xảy ra là gì?

160
00:09:04,520 --> 00:09:07,920
Điều chúng tôi đang nói ở đây là khi bạn lấy một nửa số bit,

161
00:09:07,920 --> 00:09:11,680
thì nó bằng với xác suất, cũng giống như nói hai lũy thừa của

162
00:09:11,680 --> 00:09:16,200
số bit bằng một trên xác suất, tức là sắp xếp lại để nói

163
00:09:16,200 --> 00:09:19,680
rằng thông tin là log cơ số hai của một chia cho xác suất.

164
00:09:19,680 --> 00:09:23,200
Và đôi khi bạn thấy điều này với một sự sắp xếp lại nữa,

165
00:09:23,200 --> 00:09:25,680
trong đó thông tin là log âm cơ số hai của xác suất.

166
00:09:25,680 --> 00:09:29,120
Diễn đạt như thế này, nó có thể trông hơi kỳ lạ đối với những

167
00:09:29,120 --> 00:09:33,400
người chưa quen, nhưng thực sự đó chỉ là một ý tưởng rất trực quan

168
00:09:33,400 --> 00:09:35,120
khi hỏi bạn đã cắt giảm một nửa khả năng của mình bao nhiêu lần.

169
00:09:35,120 --> 00:09:37,840
Bây giờ nếu bạn đang thắc mắc, bạn biết đấy, tôi nghĩ chúng ta chỉ đang

170
00:09:37,840 --> 00:09:39,920
chơi một trò chơi chữ vui nhộn, tại sao logarit lại xuất hiện trong bức tranh?

171
00:09:39,920 --> 00:09:43,920
Một lý do khiến đây là một đơn vị đẹp hơn là vì nó dễ dàng hơn rất nhiều khi nói về

172
00:09:43,920 --> 00:09:48,120
những sự kiện rất khó xảy ra, dễ dàng hơn nhiều khi nói rằng một quan sát có 20 bit thông tin

173
00:09:48,120 --> 00:09:53,480
so với việc nói rằng xác suất xảy ra điều đó và điều đó xảy ra là 0. 0000095.

174
00:09:53,480 --> 00:09:57,360
Nhưng một lý do thực chất hơn khiến biểu thức logarit này hóa ra lại là một sự bổ

175
00:09:57,360 --> 00:10:02,000
sung rất hữu ích cho lý thuyết xác suất là cách các thông tin cộng lại với nhau.

176
00:10:02,000 --> 00:10:05,560
Ví dụ: nếu một quan sát cung cấp cho bạn hai bit thông tin, cắt giảm không gian

177
00:10:05,560 --> 00:10:10,120
của bạn xuống còn bốn, và sau đó quan sát thứ hai như dự đoán thứ hai

178
00:10:10,120 --> 00:10:14,480
của bạn trong Wordle sẽ cung cấp cho bạn ba bit thông tin khác, cắt nhỏ hơn nữa

179
00:10:14,480 --> 00:10:17,360
theo hệ số tám khác, thì cả hai cùng nhau cung cấp cho bạn năm thông tin.

180
00:10:17,360 --> 00:10:21,200
Cũng giống như cách xác suất muốn nhân lên, thông tin cũng thích cộng thêm.

181
00:10:21,200 --> 00:10:24,920
Vì vậy, ngay khi chúng ta ở trong phạm vi của một thứ gì đó giống như giá trị kỳ vọng,

182
00:10:24,920 --> 00:10:28,660
nơi chúng ta cộng một loạt các số, nhật ký sẽ giúp việc xử lý dễ dàng hơn rất nhiều.

183
00:10:28,660 --> 00:10:32,600
Hãy quay lại bản phân phối của chúng tôi cho Weary và thêm một công cụ theo

184
00:10:32,600 --> 00:10:35,560
dõi nhỏ khác vào đây, cho chúng tôi biết lượng thông tin có cho mỗi mẫu.

185
00:10:35,560 --> 00:10:38,760
Điều chính mà tôi muốn bạn chú ý là xác suất chúng ta đạt được những mẫu có

186
00:10:38,760 --> 00:10:43,500
nhiều khả năng đó càng cao thì thông tin càng thấp thì bạn thu được càng ít bit.

187
00:10:43,500 --> 00:10:47,360
Cách chúng tôi đo lường chất lượng của dự đoán này là lấy giá trị kỳ vọng của thông tin

188
00:10:47,360 --> 00:10:51,620
này, trong đó chúng tôi xem xét từng mẫu, chúng tôi cho biết khả năng xảy ra của nó là

189
00:10:51,620 --> 00:10:54,940
bao nhiêu và sau đó chúng tôi nhân giá trị đó với số lượng thông tin chúng tôi nhận được.

190
00:10:54,940 --> 00:10:58,480
Và trong ví dụ của Weary, kết quả là 4. 9 bit.

191
00:10:58,480 --> 00:11:02,800
Vì vậy, trung bình, thông tin bạn nhận được từ lần đoán mở đầu này cũng

192
00:11:02,800 --> 00:11:05,660
tốt như việc cắt đôi không gian khả năng của bạn trong khoảng năm lần.

193
00:11:05,660 --> 00:11:10,260
Ngược lại, một ví dụ về phỏng đoán có giá trị

194
00:11:10,260 --> 00:11:13,220
thông tin được mong đợi cao hơn sẽ giống như Slate.

195
00:11:13,220 --> 00:11:16,180
Trong trường hợp này bạn sẽ nhận thấy sự phân bố trông phẳng hơn rất nhiều.

196
00:11:16,180 --> 00:11:20,780
Đặc biệt, khả năng xuất hiện nhiều nhất của tất cả các màu xám chỉ có khoảng 6% khả

197
00:11:20,780 --> 00:11:25,940
năng xảy ra, vì vậy rõ ràng bạn nhận được ít nhất 3. 9 bit thông tin.

198
00:11:25,940 --> 00:11:29,140
Nhưng đó chỉ là mức tối thiểu, thông thường bạn sẽ nhận được thứ gì đó tốt hơn thế.

199
00:11:29,140 --> 00:11:33,380
Và hóa ra là khi bạn tính toán các con số trên đây và cộng tất

200
00:11:33,380 --> 00:11:36,420
cả các số hạng có liên quan, thông tin trung bình là khoảng 5. số 8.

201
00:11:36,420 --> 00:11:42,140
Vì vậy, trái ngược với Weary, trung bình không gian khả năng của

202
00:11:42,140 --> 00:11:43,940
bạn sẽ lớn khoảng một nửa sau lần đoán đầu tiên này.

203
00:11:43,940 --> 00:11:49,540
Thực sự có một câu chuyện thú vị về tên của giá trị kỳ vọng của lượng thông tin này.

204
00:11:49,540 --> 00:11:52,580
Lý thuyết thông tin được phát triển bởi Claude Shannon, người đang làm việc tại Bell Labs

205
00:11:52,580 --> 00:11:57,620
vào những năm 1940, nhưng ông ấy đang nói về một số ý tưởng chưa được công

206
00:11:57,620 --> 00:12:01,500
bố của mình với John von Neumann, một trí tuệ khổng lồ vào thời điểm đó, rất

207
00:12:01,500 --> 00:12:04,180
nổi bật. trong toán học và vật lý và sự khởi đầu của khoa học máy tính.

208
00:12:04,180 --> 00:12:07,260
Và khi anh ấy đề cập rằng anh ấy thực sự không có một cái tên hay

209
00:12:07,260 --> 00:12:12,540
cho giá trị kỳ vọng của lượng thông tin này, von Neumann được cho là đã nói,

210
00:12:12,540 --> 00:12:14,720
vì vậy câu chuyện diễn ra, bạn nên gọi nó là entropy, và vì hai lý do.

211
00:12:14,720 --> 00:12:18,400
Đầu tiên, hàm bất định của bạn đã được sử dụng trong cơ học thống kê dưới cái tên

212
00:12:18,400 --> 00:12:23,100
đó, nên nó đã có tên rồi, và thứ hai, và quan trọng hơn, không ai biết entropy

213
00:12:23,100 --> 00:12:26,940
thực sự là gì, vì vậy trong một cuộc tranh luận, bạn sẽ luôn luôn có lợi thế.

214
00:12:26,940 --> 00:12:31,420
Vì vậy, nếu cái tên có vẻ hơi bí ẩn và nếu

215
00:12:31,420 --> 00:12:33,420
câu chuyện này được tin tưởng thì đó là do thiết kế.

216
00:12:33,420 --> 00:12:36,740
Ngoài ra, nếu bạn đang thắc mắc về mối quan hệ của nó với tất cả các định

217
00:12:36,740 --> 00:12:40,820
luật thứ hai của nhiệt động lực học trong vật lý, thì chắc chắn có một mối

218
00:12:40,820 --> 00:12:44,780
liên hệ, nhưng về nguồn gốc của nó, Shannon chỉ xử lý lý thuyết xác suất thuần túy,

219
00:12:44,780 --> 00:12:49,340
và vì mục đích của chúng ta ở đây, khi tôi sử dụng từ entropy, tôi chỉ

220
00:12:49,340 --> 00:12:50,820
muốn bạn nghĩ đến giá trị thông tin mong đợi của một lần phỏng đoán cụ thể.

221
00:12:50,820 --> 00:12:54,380
Bạn có thể coi entropy như việc đo hai thứ cùng một lúc.

222
00:12:54,380 --> 00:12:57,420
Đầu tiên là mức độ phân phối bằng phẳng như thế nào.

223
00:12:57,420 --> 00:13:01,700
Sự phân bố càng gần đều thì entropy càng cao.

224
00:13:01,700 --> 00:13:06,340
Trong trường hợp của chúng tôi, khi có tổng số từ 3 đến 5 mẫu, để phân bố đồng đều, việc quan sát bất

225
00:13:06,340 --> 00:13:11,340
kỳ mẫu nào trong số chúng sẽ có nhật ký thông tin cơ sở 2 của 3 đến mẫu thứ 5, tức là

226
00:13:11,340 --> 00:13:17,860
7. 92, vậy đó là mức tối đa tuyệt đối mà bạn có thể có đối với entropy này.

227
00:13:17,860 --> 00:13:21,900
Nhưng entropy cũng là thước đo xem có bao

228
00:13:21,900 --> 00:13:22,900
nhiêu khả năng xảy ra ngay từ đầu.

229
00:13:22,900 --> 00:13:26,980
Ví dụ: nếu bạn tình cờ có một từ nào đó trong đó chỉ có 16 mẫu có thể và

230
00:13:26,980 --> 00:13:32,760
mỗi mẫu đều có khả năng như nhau, thì entropy này, thông tin mong đợi này, sẽ là 4 bit.

231
00:13:32,760 --> 00:13:36,880
Nhưng nếu bạn có một từ khác trong đó có 64 mẫu có thể xuất hiện và

232
00:13:36,880 --> 00:13:41,000
chúng đều có khả năng như nhau, thì entropy sẽ có kết quả là 6 bit.

233
00:13:41,000 --> 00:13:45,800
Vì vậy, nếu bạn thấy một số phân phối ngoài tự nhiên có entropy 6 bit, thì điều

234
00:13:45,800 --> 00:13:50,000
đó giống như nói rằng có nhiều biến thể và sự không chắc chắn về những gì

235
00:13:50,000 --> 00:13:54,400
sắp xảy ra giống như thể có 64 kết quả có khả năng xảy ra như nhau.

236
00:13:54,400 --> 00:13:58,360
Trong lần đầu tiên tôi vượt qua Wurtelebot, về cơ bản tôi chỉ cần làm điều này.

237
00:13:58,360 --> 00:14:03,560
Nó xem xét tất cả những phỏng đoán có thể có mà bạn có thể có, tất cả

238
00:14:03,560 --> 00:14:08,580
13.000 từ, tính toán entropy cho mỗi từ, hay cụ thể hơn là entropy của phân phối trên

239
00:14:08,580 --> 00:14:13,040
tất cả các mẫu mà bạn có thể thấy, cho mỗi mẫu và chọn mức cao nhất, vì

240
00:14:13,040 --> 00:14:17,200
đó là thứ có khả năng cắt giảm không gian khả năng của bạn càng nhiều càng tốt.

241
00:14:17,200 --> 00:14:20,120
Và mặc dù tôi chỉ nói về lần đoán đầu tiên ở

242
00:14:20,120 --> 00:14:21,680
đây, nhưng những lần đoán tiếp theo cũng diễn ra tương tự.

243
00:14:21,680 --> 00:14:25,100
Ví dụ: sau khi bạn thấy một số mẫu trong lần đoán đầu tiên đó, điều này sẽ

244
00:14:25,100 --> 00:14:29,300
hạn chế bạn ở số lượng từ có thể có ít hơn dựa trên những gì phù hợp

245
00:14:29,300 --> 00:14:32,300
với từ đó, bạn chỉ cần chơi cùng một trò chơi đối với nhóm từ nhỏ hơn đó.

246
00:14:32,300 --> 00:14:36,500
Đối với lần đoán thứ hai được đề xuất, bạn xem xét sự phân bố của tất

247
00:14:36,500 --> 00:14:41,540
cả các mẫu có thể xảy ra từ tập hợp từ hạn chế hơn đó, bạn tìm

248
00:14:41,540 --> 00:14:45,480
kiếm trong tất cả 13.000 khả năng và bạn tìm thấy mẫu tối đa hóa entropy đó.

249
00:14:45,480 --> 00:14:48,980
Để cho bạn thấy điều này hoạt động như thế nào trong thực tế, hãy để tôi đưa ra một biến

250
00:14:48,980 --> 00:14:54,060
thể nhỏ của Wurtele mà tôi đã viết cho thấy những điểm nổi bật của phân tích này ở bên lề.

251
00:14:54,460 --> 00:14:57,820
Sau khi thực hiện tất cả các phép tính entropy, ở bên phải nó sẽ hiển

252
00:14:57,820 --> 00:15:00,340
thị cho chúng ta những thông tin nào có thông tin được mong đợi cao nhất.

253
00:15:00,340 --> 00:15:04,940
Hóa ra câu trả lời hàng đầu, ít nhất là tại thời điểm này, chúng ta sẽ tinh chỉnh

254
00:15:04,940 --> 00:15:11,140
lại sau, là Tares, có nghĩa là, ừm, tất nhiên, đậu tằm, loại đậu tằm phổ biến nhất.

255
00:15:11,140 --> 00:15:14,180
Mỗi lần chúng ta đoán ở đây, có lẽ tôi sẽ bỏ qua các đề xuất của nó và

256
00:15:14,180 --> 00:15:19,220
chọn phương tiện chặn, bởi vì tôi thích phương tiện chặn, chúng ta có thể thấy nó có bao

257
00:15:19,220 --> 00:15:23,300
nhiêu thông tin được mong đợi, nhưng ở bên phải của từ ở đây, nó cho chúng ta thấy

258
00:15:23,340 --> 00:15:24,980
có bao nhiêu thông tin thông tin thực tế chúng tôi nhận được, dựa trên mẫu cụ thể này.

259
00:15:24,980 --> 00:15:28,660
Vì vậy ở đây có vẻ như chúng ta đã hơi xui xẻo một chút, chúng ta đã mong đợi nhận được 5. 8, nhưng

260
00:15:28,660 --> 00:15:30,660
chúng tôi tình cờ nhận được thứ ít hơn thế.

261
00:15:30,660 --> 00:15:34,020
Và ở phía bên trái, nó hiển thị cho chúng ta tất cả các

262
00:15:34,020 --> 00:15:35,860
từ khác nhau có thể có ở vị trí hiện tại của chúng ta.

263
00:15:35,860 --> 00:15:39,820
Các thanh màu xanh lam cho chúng ta biết khả năng nó nghĩ mỗi từ là bao nhiêu, vì vậy hiện tại nó

264
00:15:39,820 --> 00:15:44,140
đang giả định mỗi từ đều có khả năng xảy ra như nhau, nhưng chúng ta sẽ tinh chỉnh điều đó sau.

265
00:15:44,140 --> 00:15:48,580
Và sau đó, phép đo độ không đảm bảo này cho chúng ta biết entropy của

266
00:15:48,580 --> 00:15:53,220
phân bố này trên các từ có thể, mà hiện tại, vì nó là phân bố

267
00:15:53,300 --> 00:15:55,940
đều, chỉ là một cách phức tạp không cần thiết để đếm số khả năng.

268
00:15:55,940 --> 00:16:01,700
Ví dụ: nếu chúng ta lấy 2 lũy thừa của 13. 66, tức là

269
00:16:01,700 --> 00:16:02,700
có khoảng 13.000 khả năng.

270
00:16:02,700 --> 00:16:06,780
Ở đây tôi hơi sai một chút, nhưng chỉ vì tôi không hiển thị tất cả các chữ số thập phân.

271
00:16:06,780 --> 00:16:10,260
Hiện tại, điều này có thể khiến bạn cảm thấy dư thừa và có vẻ như mọi thứ quá phức

272
00:16:10,260 --> 00:16:12,780
tạp, nhưng bạn sẽ thấy tại sao việc có cả hai con số trong một phút lại hữu ích.

273
00:16:12,780 --> 00:16:16,780
Vì vậy, ở đây có vẻ như nó gợi ý entropy cao nhất cho lần đoán thứ hai

274
00:16:16,780 --> 00:16:19,700
của chúng ta là Ramen, một lần nữa nó thực sự không giống một từ nào cả.

275
00:16:19,700 --> 00:16:25,660
Vì vậy, để nâng cao nền tảng đạo đức ở đây, tôi sẽ tiếp tục và gõ Rains.

276
00:16:25,660 --> 00:16:27,540
Và một lần nữa có vẻ như chúng tôi hơi kém may mắn.

277
00:16:27,540 --> 00:16:32,100
Chúng tôi đã mong đợi 4. 3 bit và chúng tôi chỉ có 3. 39 bit thông tin.

278
00:16:32,100 --> 00:16:35,060
Vì vậy, điều đó đưa chúng ta xuống còn 55 khả năng.

279
00:16:35,060 --> 00:16:38,860
Và ở đây có lẽ tôi sẽ thực sự làm theo những gì nó gợi

280
00:16:38,860 --> 00:16:40,200
ý, đó là sự kết hợp, bất kể điều đó có nghĩa là gì.

281
00:16:40,200 --> 00:16:43,300
Và được rồi, đây thực sự là một cơ hội tốt để giải câu đố.

282
00:16:43,300 --> 00:16:47,020
Nó cho chúng ta biết mẫu này cho chúng ta 4. 7 bit thông tin.

283
00:16:47,020 --> 00:16:52,400
Nhưng ở bên trái, trước khi chúng ta nhìn thấy mẫu đó, có 5. 78 bit không chắc chắn.

284
00:16:52,400 --> 00:16:56,860
Vì vậy, như một câu đố dành cho bạn, điều đó có ý nghĩa gì về số khả năng còn lại?

285
00:16:56,860 --> 00:17:02,280
Chà, điều đó có nghĩa là chúng ta giảm xuống còn một chút không chắc chắn, điều

286
00:17:02,280 --> 00:17:04,700
này cũng giống như việc nói rằng có hai câu trả lời có thể xảy ra.

287
00:17:04,700 --> 00:17:06,520
Đó là sự lựa chọn 50-50.

288
00:17:06,520 --> 00:17:09,860
Và từ đây, bởi vì bạn và tôi biết những từ nào phổ

289
00:17:09,860 --> 00:17:11,220
biến hơn, chúng ta biết rằng câu trả lời sẽ là vực thẳm.

290
00:17:11,220 --> 00:17:13,540
Nhưng như nó được viết bây giờ, chương trình không biết điều đó.

291
00:17:13,540 --> 00:17:17,560
Vì vậy, nó cứ tiếp tục, cố gắng thu thập càng nhiều thông tin càng tốt,

292
00:17:17,560 --> 00:17:20,360
cho đến khi chỉ còn một khả năng duy nhất, và rồi nó đoán điều đó.

293
00:17:20,360 --> 00:17:22,700
Vì vậy, rõ ràng là chúng ta cần một chiến lược tàn cuộc tốt hơn.

294
00:17:22,700 --> 00:17:26,540
Nhưng giả sử chúng tôi gọi phiên bản này là một trong những trình giải wordle của chúng

295
00:17:26,540 --> 00:17:30,740
tôi, sau đó chúng tôi chạy một số mô phỏng để xem nó hoạt động như thế nào.

296
00:17:30,740 --> 00:17:34,240
Vì vậy, cách thức hoạt động của nó là chơi mọi trò chơi chữ có thể.

297
00:17:34,240 --> 00:17:38,780
Nó sẽ trải qua tất cả 2315 từ đó là câu trả lời từng từ thực tế.

298
00:17:38,780 --> 00:17:41,340
Về cơ bản nó sử dụng nó như một bộ thử nghiệm.

299
00:17:41,340 --> 00:17:45,820
Và với phương pháp ngây thơ này là không xem xét mức độ phổ biến của một từ mà chỉ cố gắng tối

300
00:17:45,820 --> 00:17:50,480
đa hóa thông tin ở mỗi bước trong quá trình thực hiện, cho đến khi chỉ còn một và chỉ một lựa chọn.

301
00:17:50,480 --> 00:17:55,100
Khi kết thúc mô phỏng, điểm trung bình là khoảng 4. 124.

302
00:17:55,100 --> 00:17:59,780
Điều đó không tệ, thành thật mà nói, tôi đã dự kiến sẽ làm tệ hơn.

303
00:17:59,780 --> 00:18:03,040
Nhưng những người chơi wordle sẽ nói với bạn rằng họ thường có thể chơi được trong 4.

304
00:18:03,040 --> 00:18:05,260
Thử thách thực sự là lấy được càng nhiều phần 3 càng tốt.

305
00:18:05,260 --> 00:18:08,920
Đó là một bước nhảy khá lớn giữa điểm 4 và điểm 3.

306
00:18:08,920 --> 00:18:13,300
Điểm mấu chốt rõ ràng ở đây là bằng cách nào đó kết hợp xem một từ

307
00:18:13,300 --> 00:18:23,160
có phổ biến hay không và chính xác thì chúng ta làm điều đó như thế nào.

308
00:18:23,160 --> 00:18:26,860
Cách tôi tiếp cận là lấy danh sách tần số

309
00:18:26,860 --> 00:18:28,560
tương đối của tất cả các từ trong tiếng Anh.

310
00:18:28,560 --> 00:18:32,560
Và tôi vừa sử dụng chức năng dữ liệu tần số từ của Mathematica, chức năng

311
00:18:32,560 --> 00:18:35,520
này được lấy từ tập dữ liệu công khai Ngram tiếng Anh của Google Sách.

312
00:18:35,520 --> 00:18:38,680
Và thật thú vị khi xem xét, ví dụ như nếu chúng ta sắp xếp

313
00:18:38,680 --> 00:18:40,120
nó từ những từ phổ biến nhất đến những từ ít phổ biến nhất.

314
00:18:40,120 --> 00:18:43,740
Rõ ràng đây là những từ có 5 chữ cái phổ biến nhất trong tiếng Anh.

315
00:18:43,740 --> 00:18:46,480
Hay đúng hơn, đây là điều phổ biến thứ 8.

316
00:18:46,480 --> 00:18:49,440
Đầu tiên là cái nào, sau đó có đó và có đó.

317
00:18:49,440 --> 00:18:53,020
Bản thân thứ nhất không phải là thứ nhất mà là thứ 9, và điều hợp lý

318
00:18:53,020 --> 00:18:57,840
là những từ khác này có thể xuất hiện thường xuyên hơn, trong đó những từ đứng

319
00:18:57,840 --> 00:18:59,000
sau đầu tiên là sau, ở đâu và những từ đó ít phổ biến hơn một chút.

320
00:18:59,000 --> 00:19:04,400
Bây giờ, khi sử dụng dữ liệu này để mô hình hóa khả năng mỗi từ này

321
00:19:04,400 --> 00:19:06,760
là câu trả lời cuối cùng, nó không nên chỉ tỷ lệ thuận với tần suất.

322
00:19:07,020 --> 00:19:12,560
Ví dụ: được cho điểm 0. 002 trong tập dữ liệu này, trong khi từ

323
00:19:12,560 --> 00:19:15,200
bện theo một nghĩa nào đó ít có khả năng xảy ra hơn khoảng 1000 lần.

324
00:19:15,200 --> 00:19:19,400
Nhưng cả hai đều là những từ phổ biến đến mức chúng gần như chắc chắn đáng được xem xét.

325
00:19:19,400 --> 00:19:21,900
Vì vậy, chúng tôi muốn có nhiều điểm cắt nhị phân hơn.

326
00:19:21,900 --> 00:19:26,520
Cách tôi thực hiện là tưởng tượng lấy toàn bộ danh sách các từ được sắp xếp

327
00:19:26,520 --> 00:19:31,060
này, sau đó sắp xếp nó theo trục x, sau đó áp dụng hàm sigmoid, đây là

328
00:19:31,060 --> 00:19:35,540
cách tiêu chuẩn để có một hàm có đầu ra về cơ bản là nhị phân, đó

329
00:19:35,540 --> 00:19:38,500
là 0 hoặc 1, nhưng có sự làm mịn ở giữa cho vùng không chắc chắn đó.

330
00:19:38,500 --> 00:19:43,900
Vì vậy, về cơ bản, xác suất mà tôi gán cho mỗi từ để nằm trong danh sách cuối cùng

331
00:19:43,900 --> 00:19:49,540
sẽ là giá trị của hàm sigmoid ở trên bất kỳ vị trí nào nó nằm trên trục x.

332
00:19:49,540 --> 00:19:53,940
Bây giờ, rõ ràng điều này phụ thuộc vào một số tham số, chẳng hạn như độ rộng của khoảng trắng

333
00:19:53,940 --> 00:19:59,660
trên trục x mà những từ đó điền vào sẽ xác định mức độ chúng ta giảm dần hoặc dốc

334
00:19:59,660 --> 00:20:03,000
từ 1 xuống 0 và vị trí chúng ta đặt chúng từ trái sang phải sẽ xác định điểm cắt.

335
00:20:03,160 --> 00:20:07,340
Thành thật mà nói, cách tôi làm điều này chỉ là liếm ngón tay và đưa nó theo chiều gió.

336
00:20:07,340 --> 00:20:10,800
Tôi xem qua danh sách đã sắp xếp và cố gắng tìm một cửa sổ mà

337
00:20:10,800 --> 00:20:15,280
khi nhìn vào nó, tôi nhận ra khoảng một nửa số từ này có nhiều khả

338
00:20:15,280 --> 00:20:17,680
năng là câu trả lời cuối cùng và sử dụng nó làm điểm giới hạn.

339
00:20:17,680 --> 00:20:21,840
Khi chúng ta có sự phân bố như thế này trên các từ, nó sẽ cho chúng

340
00:20:21,840 --> 00:20:24,460
ta một tình huống khác trong đó entropy trở thành phép đo thực sự hữu ích này.

341
00:20:24,460 --> 00:20:28,480
Ví dụ: giả sử chúng ta đang chơi một trò chơi và chúng ta bắt đầu với những

342
00:20:28,480 --> 00:20:32,480
từ mở đầu cũ của tôi, đó là một chiếc lông vũ và những chiếc đinh, và

343
00:20:32,480 --> 00:20:33,760
chúng ta kết thúc với một tình huống có thể có bốn từ phù hợp với nó.

344
00:20:33,760 --> 00:20:36,440
Và giả sử chúng ta coi chúng đều có khả năng xảy ra như nhau.

345
00:20:36,440 --> 00:20:40,000
Hãy để tôi hỏi bạn, entropy của phân phối này là gì?

346
00:20:40,000 --> 00:20:45,920
Chà, thông tin liên quan đến từng khả năng này sẽ là log cơ số

347
00:20:45,920 --> 00:20:50,800
2 của 4, vì mỗi khả năng là 1 và 4, và đó là 2.

348
00:20:50,800 --> 00:20:52,780
Hai thông tin, bốn khả năng.

349
00:20:52,780 --> 00:20:54,360
Tất cả đều rất tốt và tốt.

350
00:20:54,360 --> 00:20:58,320
Nhưng điều gì sẽ xảy ra nếu tôi nói với bạn rằng thực sự có nhiều hơn bốn trận đấu?

351
00:20:58,320 --> 00:21:02,600
Trên thực tế, khi chúng ta xem qua danh sách từ đầy đủ, có 16 từ phù hợp với nó.

352
00:21:02,600 --> 00:21:07,260
Nhưng giả sử mô hình của chúng tôi đặt ra xác suất rất thấp cho 12 từ còn lại

353
00:21:07,260 --> 00:21:11,440
thực sự là câu trả lời cuối cùng, khoảng 1 trên 1000 vì chúng thực sự khó hiểu.

354
00:21:11,440 --> 00:21:15,480
Bây giờ hãy để tôi hỏi bạn, entropy của phân phối này là gì?

355
00:21:15,480 --> 00:21:19,600
Nếu entropy chỉ đơn thuần là đo số lượng kết quả trùng khớp ở đây,

356
00:21:19,600 --> 00:21:24,760
thì bạn có thể mong đợi nó giống như log cơ số 2 của 16,

357
00:21:24,760 --> 00:21:26,200
tức là 4, nhiều hơn hai bit không chắc chắn so với trước đây.

358
00:21:26,200 --> 00:21:30,320
Nhưng tất nhiên, sự không chắc chắn thực tế không thực sự khác biệt so với những gì chúng ta đã có trước đây.

359
00:21:30,320 --> 00:21:33,840
Chỉ vì có 12 từ thực sự khó hiểu này không có nghĩa là sẽ ngạc

360
00:21:33,840 --> 00:21:38,200
nhiên hơn khi biết rằng câu trả lời cuối cùng là sự quyến rũ chẳng hạn.

361
00:21:38,200 --> 00:21:42,080
Vì vậy, khi bạn thực sự thực hiện phép tính ở đây và cộng xác suất của mỗi

362
00:21:42,080 --> 00:21:45,960
lần xuất hiện với thông tin tương ứng, kết quả bạn nhận được là 2. 11 bit.

363
00:21:45,960 --> 00:21:50,280
Tôi chỉ đang nói, về cơ bản nó là hai bit, về cơ bản là bốn khả năng đó,

364
00:21:50,280 --> 00:21:54,240
nhưng có một chút không chắc chắn hơn vì tất cả những sự kiện rất khó xảy ra đó,

365
00:21:54,240 --> 00:21:57,120
mặc dù nếu bạn đã tìm hiểu chúng, bạn sẽ nhận được rất nhiều thông tin từ nó.

366
00:21:57,120 --> 00:22:00,800
Vì vậy, thu nhỏ, đây là một phần lý do khiến Wordle trở

367
00:22:00,800 --> 00:22:01,800
thành một ví dụ hay cho bài học lý thuyết thông tin.

368
00:22:01,800 --> 00:22:05,280
Chúng ta có hai ứng dụng cảm nhận riêng biệt về entropy.

369
00:22:05,280 --> 00:22:09,640
Câu đầu tiên cho chúng ta biết thông tin mong đợi mà chúng ta sẽ nhận được từ một lần

370
00:22:09,640 --> 00:22:14,560
phỏng đoán nhất định và câu thứ hai cho chúng ta biết liệu chúng ta có thể đo lường độ

371
00:22:14,560 --> 00:22:16,480
không chắc chắn còn lại trong số tất cả các từ mà chúng ta có thể có hay không.

372
00:22:16,480 --> 00:22:19,800
Và tôi nên nhấn mạnh, trong trường hợp đầu tiên khi chúng ta xem xét thông tin dự kiến của một lần đoán, một

373
00:22:19,800 --> 00:22:25,000
khi chúng ta có trọng số không bằng nhau đối với các từ, điều đó sẽ ảnh hưởng đến việc tính toán entropy.

374
00:22:25,000 --> 00:22:28,600
Ví dụ: hãy để tôi đưa ra trường hợp tương tự mà chúng ta đã

375
00:22:28,600 --> 00:22:33,560
xem xét trước đó về phân phối liên quan đến Weary, nhưng lần này

376
00:22:33,560 --> 00:22:34,560
sử dụng phân phối không đồng nhất trên tất cả các từ có thể.

377
00:22:34,560 --> 00:22:39,360
Vì vậy, hãy để tôi xem liệu tôi có thể tìm thấy một phần ở đây minh họa nó khá tốt không.

378
00:22:39,360 --> 00:22:42,480
Được rồi, ở đây khá tốt.

379
00:22:42,480 --> 00:22:46,360
Ở đây chúng ta có hai mẫu liền kề có khả năng xảy ra như nhau, nhưng

380
00:22:46,360 --> 00:22:49,480
một trong số chúng được cho biết có 32 từ có thể phù hợp với nó.

381
00:22:49,480 --> 00:22:54,080
Và nếu chúng ta kiểm tra xem chúng là gì, thì đây là 32 từ đó,

382
00:22:54,080 --> 00:22:55,600
tất cả chỉ là những từ rất khó xảy ra khi bạn quét mắt qua chúng.

383
00:22:55,600 --> 00:23:00,400
Thật khó để tìm thấy bất kỳ câu trả lời hợp lý nào, có thể là đáng ngạc nhiên,

384
00:23:00,400 --> 00:23:04,440
nhưng nếu chúng ta nhìn vào mô hình lân cận trong phân phối, được coi là có khả

385
00:23:04,440 --> 00:23:08,920
năng xảy ra, chúng ta được biết rằng nó chỉ có 8 kết quả phù hợp có thể

386
00:23:08,920 --> 00:23:09,920
xảy ra, tức là một phần tư nhiều trận đấu, nhưng gần như có khả năng xảy ra.

387
00:23:09,920 --> 00:23:12,520
Và khi chúng tôi xem những trận đấu đó, chúng tôi có thể hiểu tại sao.

388
00:23:12,520 --> 00:23:17,840
Một số trong số này là những câu trả lời thực sự hợp lý, như tiếng chuông, cơn thịnh nộ hoặc tiếng rap.

389
00:23:17,840 --> 00:23:22,000
Để minh họa cách chúng tôi kết hợp tất cả những điều đó, hãy để tôi đưa ra phiên bản 2 của

390
00:23:22,000 --> 00:23:25,960
Wordlebot ở đây và có hai hoặc ba điểm khác biệt chính so với phiên bản đầu tiên mà chúng tôi thấy.

391
00:23:25,960 --> 00:23:29,460
Trước hết, như tôi vừa nói, cách chúng ta tính toán những entropy này, những giá trị

392
00:23:29,460 --> 00:23:34,800
thông tin kỳ vọng này, hiện đang sử dụng những phân bố tinh tế hơn trên các

393
00:23:34,800 --> 00:23:39,300
mẫu kết hợp xác suất mà một từ nhất định thực sự sẽ là câu trả lời.

394
00:23:39,300 --> 00:23:44,160
Thực tế thì nước mắt vẫn là số 1, dù những nước mắt sau có hơi khác một chút.

395
00:23:44,160 --> 00:23:47,920
Thứ hai, khi xếp hạng các lựa chọn hàng đầu, nó sẽ giữ một mô hình về xác suất

396
00:23:47,920 --> 00:23:52,600
mà mỗi từ là câu trả lời thực sự và nó sẽ kết hợp điều đó vào quyết định

397
00:23:52,600 --> 00:23:55,520
của mình, điều này sẽ dễ thấy hơn khi chúng ta có một vài dự đoán về bàn.

398
00:23:55,520 --> 00:24:01,120
Một lần nữa, bỏ qua khuyến nghị của nó vì chúng ta không thể để máy móc điều khiển cuộc sống của mình.

399
00:24:01,120 --> 00:24:05,160
Và tôi cho rằng tôi nên đề cập đến một điều khác ở đây là ở bên trái, giá trị không

400
00:24:05,160 --> 00:24:10,080
chắc chắn đó, số bit đó, không còn dư thừa với số lượng kết quả phù hợp có thể có.

401
00:24:10,080 --> 00:24:16,520
Bây giờ nếu chúng ta kéo nó lên và tính từ 2 đến 8. 02, cao hơn 256 một chút, tôi đoán

402
00:24:16,520 --> 00:24:22,640
là 259, điều nó nói là mặc dù có tổng cộng 526 từ thực sự

403
00:24:22,640 --> 00:24:26,400
khớp với mẫu này, mức độ không chắc chắn của nó gần giống với mức

404
00:24:26,400 --> 00:24:29,760
độ sẽ xảy ra nếu có 259 từ có khả năng như nhau kết quả.

405
00:24:29,760 --> 00:24:31,100
Bạn có thể nghĩ về nó như thế này.

406
00:24:31,100 --> 00:24:35,560
Nó biết borx không phải là câu trả lời, tương tự với yorts, zorl và

407
00:24:35,560 --> 00:24:37,840
zorus, vì vậy nó ít chắc chắn hơn một chút so với trường hợp trước.

408
00:24:37,840 --> 00:24:40,220
Số bit này sẽ nhỏ hơn.

409
00:24:40,220 --> 00:24:44,040
Và nếu tôi tiếp tục chơi trò chơi, tôi sẽ tinh chỉnh điều này bằng

410
00:24:44,040 --> 00:24:48,680
một vài phỏng đoán phù hợp với những gì tôi muốn giải thích ở đây.

411
00:24:48,680 --> 00:24:52,520
Đến lần đoán thứ tư, nếu bạn nhìn qua những lựa chọn hàng đầu của

412
00:24:52,520 --> 00:24:53,800
nó, bạn có thể thấy nó không còn chỉ tối đa hóa entropy nữa.

413
00:24:53,800 --> 00:24:58,480
Vì vậy, tại thời điểm này, về mặt kỹ thuật có bảy khả năng, nhưng những khả

414
00:24:58,480 --> 00:25:00,780
năng duy nhất có cơ hội có ý nghĩa là ký túc xá và từ ngữ.

415
00:25:00,780 --> 00:25:04,760
Và bạn có thể thấy nó xếp hạng việc chọn cả hai giá trị đó lên trên

416
00:25:04,760 --> 00:25:07,560
tất cả các giá trị khác, nói đúng ra thì sẽ cung cấp thêm thông tin.

417
00:25:07,560 --> 00:25:11,200
Lần đầu tiên tôi làm điều này, tôi chỉ cộng hai con số này để đo lường chất lượng

418
00:25:11,200 --> 00:25:14,580
của mỗi lần đoán, và chúng thực sự hoạt động tốt hơn những gì bạn có thể nghi ngờ.

419
00:25:14,580 --> 00:25:17,600
Nhưng nó thực sự có vẻ không mang tính hệ thống và tôi chắc chắn rằng có những cách

420
00:25:17,600 --> 00:25:19,880
tiếp cận khác mà mọi người có thể thực hiện nhưng đây là cách tôi đã áp dụng.

421
00:25:19,880 --> 00:25:24,200
Nếu chúng ta đang xem xét khả năng xảy ra lần đoán tiếp theo, chẳng hạn như trong trường hợp này là từ

422
00:25:24,200 --> 00:25:28,440
ngữ, thì điều chúng ta thực sự quan tâm là điểm số kỳ vọng của trò chơi nếu chúng ta làm điều đó.

423
00:25:28,440 --> 00:25:32,880
Và để tính số điểm mong đợi đó, chúng tôi nói xác suất mà các từ

424
00:25:32,880 --> 00:25:35,640
đó là câu trả lời thực sự là bao nhiêu, hiện tại nó mô tả 58%.

425
00:25:36,080 --> 00:25:40,400
Chúng tôi nói với 58% cơ hội, điểm của chúng tôi trong trò chơi này sẽ là 4.

426
00:25:40,400 --> 00:25:46,240
Và khi đó với xác suất 1 trừ 58% đó thì điểm của chúng ta sẽ lớn hơn 4 đó.

427
00:25:46,240 --> 00:25:50,640
Chúng tôi không biết còn bao nhiêu nữa, nhưng chúng tôi có thể ước tính nó dựa

428
00:25:50,640 --> 00:25:52,920
trên mức độ không chắc chắn có thể xảy ra khi chúng tôi đạt đến điểm đó.

429
00:25:52,920 --> 00:25:56,600
Cụ thể hiện tại có 1. 44 bit không chắc chắn.

430
00:25:56,600 --> 00:26:01,560
Nếu chúng ta đoán các từ, nó sẽ cho chúng ta biết thông tin mong đợi mà chúng ta sẽ nhận được là 1. 27 bit.

431
00:26:01,560 --> 00:26:06,280
Vì vậy, nếu chúng ta đoán từ, sự khác biệt này thể hiện mức độ không

432
00:26:06,280 --> 00:26:08,280
chắc chắn mà chúng ta có thể gặp phải sau khi điều đó xảy ra.

433
00:26:08,280 --> 00:26:12,500
Cái chúng ta cần là một loại hàm nào đó, mà tôi gọi là f

434
00:26:12,500 --> 00:26:13,880
ở đây, liên kết sự không chắc chắn này với điểm số kỳ vọng.

435
00:26:13,880 --> 00:26:18,040
Và cách nó diễn ra là chỉ vẽ một loạt dữ liệu từ các trò chơi trước

436
00:26:18,040 --> 00:26:23,920
dựa trên phiên bản 1 của bot để cho biết điểm thực tế sau các điểm khác

437
00:26:23,920 --> 00:26:27,040
nhau với mức độ không chắc chắn nhất định có thể đo lường được là bao nhiêu.

438
00:26:27,040 --> 00:26:31,120
Ví dụ: những điểm dữ liệu ở đây nằm trên một giá trị khoảng 8. Khoảng

439
00:26:31,120 --> 00:26:36,840
7 là nói cho một số trò chơi sau một thời điểm có 8. Có 7 điểm không

440
00:26:36,840 --> 00:26:39,340
chắc chắn, phải mất hai lần đoán mới có được câu trả lời cuối cùng.

441
00:26:39,340 --> 00:26:43,180
Đối với các trò chơi khác, phải mất ba lần đoán, đối với các trò chơi khác, phải mất bốn lần đoán.

442
00:26:43,180 --> 00:26:46,920
Nếu chúng ta chuyển sang bên trái ở đây, tất cả các điểm trên 0 đều cho biết

443
00:26:46,920 --> 00:26:51,620
bất cứ khi nào không có chút gì không chắc chắn, tức là chỉ có một khả

444
00:26:51,620 --> 00:26:55,000
năng, thì số lần dự đoán cần thiết luôn chỉ là một, điều này thật yên tâm.

445
00:26:55,000 --> 00:26:59,020
Bất cứ khi nào có một chút không chắc chắn, nghĩa là về cơ

446
00:26:59,020 --> 00:27:02,360
bản chỉ có hai khả năng xảy ra, thì đôi khi cần phải đoán

447
00:27:02,360 --> 00:27:03,940
thêm một lần nữa, đôi khi cần phải đoán thêm hai lần nữa.

448
00:27:03,940 --> 00:27:05,980
Và vân vân và vân vân ở đây.

449
00:27:05,980 --> 00:27:11,020
Có lẽ cách dễ dàng hơn một chút để hình dung dữ liệu này là gộp chúng lại với nhau và lấy giá trị trung bình.

450
00:27:11,020 --> 00:27:15,940
Ví dụ: thanh này ở đây cho biết trong số tất cả các điểm mà chúng tôi có

451
00:27:15,940 --> 00:27:22,420
một chút không chắc chắn, trung bình số lần đoán mới cần thiết là khoảng 1. 5.

452
00:27:22,420 --> 00:27:25,920
Và thanh ở đây nói về tất cả các trò chơi khác nhau mà tại một

453
00:27:25,920 --> 00:27:30,480
thời điểm nào đó độ không chắc chắn cao hơn 4 bit một chút, giống

454
00:27:30,480 --> 00:27:35,120
như thu hẹp nó xuống còn 16 khả năng khác nhau, sau đó trung bình

455
00:27:35,120 --> 00:27:36,240
nó yêu cầu nhiều hơn hai lần đoán kể từ thời điểm đó phía trước.

456
00:27:36,240 --> 00:27:40,080
Và từ đây tôi mới thực hiện một phép hồi quy để khớp với một hàm có vẻ hợp lý với điều này.

457
00:27:40,080 --> 00:27:44,160
Và hãy nhớ rằng mục đích chung của việc thực hiện bất kỳ điều nào trong số đó là để chúng ta có thể

458
00:27:44,160 --> 00:27:49,720
định lượng trực giác này rằng chúng ta càng thu được nhiều thông tin từ một từ thì điểm kỳ vọng sẽ càng thấp.

459
00:27:49,720 --> 00:27:54,380
Vì vậy, với phiên bản này là 2. 0, nếu chúng ta quay lại và chạy cùng một bộ mô phỏng, để nó

460
00:27:54,380 --> 00:27:59,820
đấu với tất cả 2315 câu trả lời từ có thể có, thì nó hoạt động như thế nào?

461
00:27:59,820 --> 00:28:04,060
Ngược lại với phiên bản đầu tiên của chúng tôi, nó chắc chắn tốt hơn, điều này thật yên tâm.

462
00:28:04,060 --> 00:28:08,780
Tất cả đã nói và làm trung bình là khoảng 3. 6, mặc dù không giống như phiên bản đầu tiên,

463
00:28:08,780 --> 00:28:12,820
có một vài lần nó bị mất và yêu cầu nhiều hơn sáu trong trường hợp này.

464
00:28:12,820 --> 00:28:15,980
Có lẽ bởi vì đôi khi nó thực hiện sự đánh đổi đó để

465
00:28:15,980 --> 00:28:18,980
thực sự đạt được mục tiêu hơn là tối đa hóa thông tin.

466
00:28:18,980 --> 00:28:22,140
Vậy chúng ta có thể làm tốt hơn 3. 6?

467
00:28:22,140 --> 00:28:23,260
Chúng tôi chắc chắn có thể.

468
00:28:23,260 --> 00:28:27,120
Bây giờ tôi đã nói ngay từ đầu rằng sẽ thú vị nhất khi thử không kết hợp danh

469
00:28:27,120 --> 00:28:29,980
sách các câu trả lời từng từ thực sự vào cách nó xây dựng mô hình của mình.

470
00:28:29,980 --> 00:28:35,180
Nhưng nếu chúng tôi kết hợp nó, hiệu suất tốt nhất tôi có thể đạt được là khoảng 3. 43.

471
00:28:35,180 --> 00:28:39,520
Vì vậy, nếu chúng ta cố gắng phức tạp hơn việc chỉ sử dụng dữ liệu tần số từ để chọn phân phối

472
00:28:39,520 --> 00:28:44,220
trước này, thì phân phối 3 này. 43 có lẽ cho biết mức độ tối đa mà chúng tôi có thể

473
00:28:44,220 --> 00:28:46,360
đạt được với điều đó, hoặc ít nhất là tôi có thể đạt được điều đó tốt đến mức nào.

474
00:28:46,360 --> 00:28:50,240
Hiệu suất tốt nhất đó về cơ bản chỉ sử dụng những ý tưởng mà tôi

475
00:28:50,240 --> 00:28:53,400
đã nói ở đây, nhưng nó còn đi xa hơn một chút, giống như việc tìm

476
00:28:53,400 --> 00:28:55,660
kiếm thông tin được mong đợi về phía trước hai bước thay vì chỉ một bước.

477
00:28:55,660 --> 00:28:58,720
Ban đầu tôi định nói nhiều hơn về vấn đề đó, nhưng tôi

478
00:28:58,720 --> 00:29:00,580
nhận ra rằng chúng ta thực sự đã đi khá lâu rồi.

479
00:29:00,580 --> 00:29:03,520
Một điều tôi sẽ nói là sau khi thực hiện tìm kiếm hai bước này và sau

480
00:29:03,520 --> 00:29:07,720
đó chạy một vài mô phỏng mẫu trong các ứng cử viên hàng đầu, đối với

481
00:29:07,720 --> 00:29:09,500
tôi, ít nhất cho đến nay, có vẻ như Crane là người mở màn tốt nhất.

482
00:29:09,500 --> 00:29:11,080
Ai có thể đoán được?

483
00:29:11,080 --> 00:29:15,680
Ngoài ra, nếu bạn sử dụng danh sách từ thực sự để xác định không gian khả năng

484
00:29:15,680 --> 00:29:17,920
của mình, thì độ không chắc chắn mà bạn bắt đầu sẽ lớn hơn 11 bit một chút.

485
00:29:18,160 --> 00:29:22,760
Và hóa ra, chỉ từ một cuộc tìm kiếm thô bạo, thông tin mong đợi

486
00:29:22,760 --> 00:29:26,580
tối đa có thể có sau hai lần đoán đầu tiên là khoảng 10 bit.

487
00:29:26,580 --> 00:29:31,720
Điều này gợi ý rằng trong trường hợp tốt nhất, sau hai lần đoán đầu tiên của

488
00:29:31,720 --> 00:29:35,220
bạn, với lối chơi hoàn toàn tối ưu, bạn sẽ còn lại một chút không chắc chắn.

489
00:29:35,220 --> 00:29:37,400
Điều này cũng giống như việc có hai khả năng phỏng đoán.

490
00:29:37,400 --> 00:29:41,440
Vì vậy, tôi nghĩ thật công bằng và có lẽ khá thận trọng khi nói rằng bạn không bao

491
00:29:41,440 --> 00:29:45,620
giờ có thể viết một thuật toán đạt mức trung bình thấp nhất là 3, bởi vì với số

492
00:29:45,620 --> 00:29:50,460
từ có sẵn cho bạn, đơn giản là không có đủ chỗ để có đủ thông tin chỉ sau

493
00:29:50,460 --> 00:29:53,820
hai bước. có thể đảm bảo câu trả lời ở ô thứ ba mọi lúc mà không thất bại.

