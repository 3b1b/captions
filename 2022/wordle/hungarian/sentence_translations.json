[
 {
  "input": "The game Wurdle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.",
  "model": "nmt",
  "translatedText": "A Wurdle játék az elmúlt egy-két hónapban eléggé elterjedt, és soha nem szabad figyelmen kívül hagyni a matematika leckék lehetőségét, eszembe jutott, hogy ez a játék nagyon jó központi példa az információelméletről szóló leckében, és különösen entrópia néven ismert téma.",
  "time_range": [
   0.0,
   13.12
  ]
 },
 {
  "input": "You see, like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.",
  "model": "nmt",
  "translatedText": "Tudja, sok emberhez hasonlóan engem is magával ragadott a rejtvény, és mint sok programozót, engem is beleélt, hogy megpróbáljak olyan algoritmust írni, amely a lehető legoptimálisabban játszaná a játékot.",
  "time_range": [
   13.12,
   23.2
  ]
 },
 {
  "input": "And what I thought I'd do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy.",
  "model": "nmt",
  "translatedText": "Arra gondoltam, hogy itt csak átbeszélem veled a folyamatomat, és elmagyarázok néhány matematikai elemet, ami belekerült, mivel az egész algoritmus az entrópia ezen gondolatán áll.",
  "time_range": [
   23.2,
   32.08
  ]
 },
 {
  "input": "First things first, in case you haven't heard of it, what is Wurdle?",
  "model": "nmt",
  "translatedText": "Először is, ha még nem hallottál róla, mi az a Wurdle?",
  "time_range": [
   32.08,
   42.18
  ]
 },
 {
  "input": "And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we're going with this, which is to develop a little algorithm that will basically play the game for us.",
  "model": "nmt",
  "translatedText": "És hogy itt két legyet öljek egy csapásra, miközben végigmegyünk a játékszabályokon, hadd nézzem meg azt is, hogy merre is tartunk ezzel, vagyis hogy dolgozzunk ki egy kis algoritmust, ami alapvetően lejátssza a játékot helyettünk.",
  "time_range": [
   42.18,
   51.38
  ]
 },
 {
  "input": "Though I haven't done today's Wurdle, this is February 4th, and we'll see how the bot does.",
  "model": "nmt",
  "translatedText": "Bár a mai Wurdle-t még nem csináltam, most február 4-e van, és meglátjuk, hogyan fog a bot.",
  "time_range": [
   51.38,
   55.86
  ]
 },
 {
  "input": "The goal of Wurdle is to guess a mystery five letter word, and you're given six different chances to guess.",
  "model": "nmt",
  "translatedText": "A Wurdle célja egy rejtélyes ötbetűs szó kitalálása, és hat különböző lehetőséget kap a kitalálásra.",
  "time_range": [
   55.86,
   60.86
  ]
 },
 {
  "input": "For example, my Wurdle bot suggests that I start with the guess crane.",
  "model": "nmt",
  "translatedText": "Például a Wurdle botom azt javasolja, hogy kezdjem a tippdaruval.",
  "time_range": [
   60.86,
   65.24
  ]
 },
 {
  "input": "Each time that you make a guess, you get some information about how close your guess is to the true answer.",
  "model": "nmt",
  "translatedText": "Valahányszor tippel, információt kap arról, hogy milyen közel áll a tippje az igaz válaszhoz.",
  "time_range": [
   65.24,
   70.94
  ]
 },
 {
  "input": "Here the grey box is telling me there's no C in the actual answer.",
  "model": "nmt",
  "translatedText": "Itt a szürke doboz azt jelzi, hogy nincs C a tényleges válaszban.",
  "time_range": [
   70.94,
   74.54
  ]
 },
 {
  "input": "The yellow box is telling me there is an R, but it's not in that position.",
  "model": "nmt",
  "translatedText": "A sárga doboz azt jelzi, hogy van egy R, de nincs abban a helyzetben.",
  "time_range": [
   74.54,
   78.34
  ]
 },
 {
  "input": "The green box is telling me that the secret word does have an A, and it's in the third position.",
  "model": "nmt",
  "translatedText": "A zöld doboz azt mondja nekem, hogy a titkos szóban van egy A, és ez a harmadik helyen van.",
  "time_range": [
   78.34,
   82.82
  ]
 },
 {
  "input": "And then there's no N and there's no E.",
  "model": "nmt",
  "translatedText": "És akkor nincs N és nincs E.",
  "time_range": [
   82.82,
   84.3
  ]
 },
 {
  "input": "So let me just go in and tell the Wurdle bot that information.",
  "model": "nmt",
  "translatedText": "Szóval hadd menjek be, és mondjam el a Wurdle botnak ezt az információt.",
  "time_range": [
   84.3,
   87.42
  ]
 },
 {
  "input": "We started with crane, we got grey, yellow, green, grey, grey.",
  "model": "nmt",
  "translatedText": "Daruval kezdtük, szürke, sárga, zöld, szürke, szürke lett.",
  "time_range": [
   87.42,
   91.5
  ]
 },
 {
  "input": "Don't worry about all the data that it's showing right now, I'll explain that in due time.",
  "model": "nmt",
  "translatedText": "Ne aggódjon a most megjelenő összes adat miatt, ezt majd elmagyarázom a megfelelő időben.",
  "time_range": [
   91.5,
   95.46
  ]
 },
 {
  "input": "But its top suggestion for our second pick is shtick.",
  "model": "nmt",
  "translatedText": "A második választásunkra vonatkozó legfontosabb javaslat azonban nem jó.",
  "time_range": [
   95.46,
   99.7
  ]
 },
 {
  "input": "And your guess does have to be an actual five letter word, but as you'll see, it's pretty liberal with what it will actually let you guess.",
  "model": "nmt",
  "translatedText": "És a tippednek tényleges ötbetűs szónak kell lennie, de amint látni fogod, meglehetősen liberális azzal kapcsolatban, hogy mit enged kitalálni.",
  "time_range": [
   99.7,
   105.7
  ]
 },
 {
  "input": "In this case, we try shtick.",
  "model": "nmt",
  "translatedText": "Ebben az esetben megpróbáljuk a shticket.",
  "time_range": [
   105.7,
   108.86
  ]
 },
 {
  "input": "And alright, things are looking pretty good.",
  "model": "nmt",
  "translatedText": "És rendben, a dolgok nagyon jól néznek ki.",
  "time_range": [
   108.86,
   110.26
  ]
 },
 {
  "input": "We hit the S and the H, so we know the first three letters, we know that there's an R.",
  "model": "nmt",
  "translatedText": "Megütjük az S-t és a H-t, tehát ismerjük az első három betűt, tudjuk, hogy van egy R.",
  "time_range": [
   110.26,
   114.74
  ]
 },
 {
  "input": "And so it's going to be like S-H-A something R, or S-H-A R something.",
  "model": "nmt",
  "translatedText": "És így olyan lesz, mint SHA valami R, vagy SHA R valami.",
  "time_range": [
   114.74,
   119.74
  ]
 },
 {
  "input": "And it looks like the Wurdle bot knows that it's down to just two possibilities, either shard or sharp.",
  "model": "nmt",
  "translatedText": "És úgy tűnik, hogy a Wurdle bot tudja, hogy csak két lehetőségre van szükség, vagy szilánkosra vagy élesre.",
  "time_range": [
   119.74,
   125.22
  ]
 },
 {
  "input": "That's kind of a toss up between them at this point, so I guess probably just because it's alphabetical it goes with shard.",
  "model": "nmt",
  "translatedText": "Ez most egyfajta feldobás köztük, úgyhogy valószínűleg csak azért, mert ábécé sorrendben van, szilánkokkal jár.",
  "time_range": [
   125.22,
   131.26
  ]
 },
 {
  "input": "Which hooray, is the actual answer.",
  "model": "nmt",
  "translatedText": "Hurrá, ez a valódi válasz.",
  "time_range": [
   131.26,
   133.0
  ]
 },
 {
  "input": "So we got it in three.",
  "model": "nmt",
  "translatedText": "Szóval hárman megkaptuk.",
  "time_range": [
   133.0,
   134.66
  ]
 },
 {
  "input": "If you're wondering if that's any good, the way I heard one person phrase it is that with Wurdle four is par and three is birdie.",
  "model": "nmt",
  "translatedText": "Ha azon tűnődsz, hogy ez jó-e, ahogy egy embertől hallottam, az az, hogy Wurdle-nél négy egyenlő, a három pedig madárka.",
  "time_range": [
   134.66,
   140.82
  ]
 },
 {
  "input": "Which I think is a pretty apt analogy.",
  "model": "nmt",
  "translatedText": "Ami szerintem elég találó hasonlat.",
  "time_range": [
   140.82,
   142.96
  ]
 },
 {
  "input": "You have to be consistently on your game to be getting four, but it's certainly not crazy.",
  "model": "nmt",
  "translatedText": "Folyamatosan kell játszania a játékban, hogy négyet kapjon, de ez biztosan nem őrültség.",
  "time_range": [
   142.96,
   147.56
  ]
 },
 {
  "input": "But when you get it in three, it just feels great.",
  "model": "nmt",
  "translatedText": "De ha háromba kapod, nagyszerű érzés.",
  "time_range": [
   147.56,
   150.0
  ]
 },
 {
  "input": "So if you're down for it, what I'd like to do here is just talk through my thought process from the beginning for how I approach the Wurdle bot.",
  "model": "nmt",
  "translatedText": "Tehát ha nem szereti, azt szeretném itt csinálni, hogy végigbeszéljem a gondolatmenetemet az elejétől kezdve, hogy hogyan közelítsem meg a Wurdle botot.",
  "time_range": [
   150.0,
   156.6
  ]
 },
 {
  "input": "And like I said, really it's an excuse for an information theory lesson.",
  "model": "nmt",
  "translatedText": "És ahogy mondtam, ez egy ürügy egy információelméleti leckére.",
  "time_range": [
   156.6,
   159.8
  ]
 },
 {
  "input": "The main goal is to explain what is information and what is entropy.",
  "model": "nmt",
  "translatedText": "A fő cél az, hogy elmagyarázzuk, mi az információ és mi az entrópia.",
  "time_range": [
   159.8,
   168.56
  ]
 },
 {
  "input": "My first thought in approaching this was to take a look at the relative frequencies of different letters in the English language.",
  "model": "nmt",
  "translatedText": "Az első gondolatom ennek megközelítése során az volt, hogy megnézzem a különböző betűk relatív gyakoriságát az angol nyelvben.",
  "time_range": [
   168.56,
   173.56
  ]
 },
 {
  "input": "So I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters?",
  "model": "nmt",
  "translatedText": "Szóval arra gondoltam, oké, van egy nyitó tipp vagy egy nyitó tipp, ami eltalálja a legtöbb ilyen leggyakoribb betűt?",
  "time_range": [
   173.56,
   179.96
  ]
 },
 {
  "input": "And one that I was pretty fond of was doing other followed by nails.",
  "model": "nmt",
  "translatedText": "És az egyik, amit nagyon szerettem, az volt, hogy másokat csináltam, amiket a körmök követtek.",
  "time_range": [
   179.96,
   183.78
  ]
 },
 {
  "input": "The thought is that if you hit a letter, you know, you get a green or a yellow, that always feels good.",
  "model": "nmt",
  "translatedText": "A gondolat az, hogy ha megütsz egy betűt, tudod, kapsz egy zöldet vagy sárgát, az mindig jó érzés.",
  "time_range": [
   183.78,
   187.98
  ]
 },
 {
  "input": "It feels like you're getting information.",
  "model": "nmt",
  "translatedText": "Olyan érzés, mintha információkat kapsz.",
  "time_range": [
   187.98,
   189.46
  ]
 },
 {
  "input": "But in these cases, even if you don't hit and you always get grays, that's still giving you a lot of information since it's pretty rare to find a word that doesn't have any of these letters.",
  "model": "nmt",
  "translatedText": "De ezekben az esetekben, még ha nem is találsz, és mindig szürkéket kapsz, ez még mindig sok információt ad, mivel elég ritkán találni olyan szót, amelyben nem szerepel ezek a betűk.",
  "time_range": [
   189.46,
   197.64
  ]
 },
 {
  "input": "But even still, that doesn't feel super systematic, because for example, it does nothing to consider the order of the letters.",
  "model": "nmt",
  "translatedText": "De még így sem tűnik túl szisztematikusnak, mert például nem veszi figyelembe a betűk sorrendjét.",
  "time_range": [
   197.64,
   203.52
  ]
 },
 {
  "input": "Why type nails when I could type snail?",
  "model": "nmt",
  "translatedText": "Miért írjak körmöket, ha írhatnám a csigát?",
  "time_range": [
   203.52,
   206.08
  ]
 },
 {
  "input": "Is it better to have that S at the end?",
  "model": "nmt",
  "translatedText": "Jobb, ha az S van a végén?",
  "time_range": [
   206.08,
   207.72
  ]
 },
 {
  "input": "I'm not really sure.",
  "model": "nmt",
  "translatedText": "Nem igazán vagyok benne biztos.",
  "time_range": [
   207.72,
   208.72
  ]
 },
 {
  "input": "Now, a friend of mine said that he liked to open with the word weary, which kind of surprised me because it has some uncommon letters in there like the W and the Y.",
  "model": "nmt",
  "translatedText": "Nos, egy barátom azt mondta, hogy szeretett a fáradt szóval nyitni, ami kicsit meglepett, mert vannak benne szokatlan betűk, például a W és az Y.",
  "time_range": [
   208.72,
   217.16
  ]
 },
 {
  "input": "But who knows, maybe that is a better opener.",
  "model": "nmt",
  "translatedText": "De ki tudja, talán ez jobb nyitás.",
  "time_range": [
   217.16,
   219.4
  ]
 },
 {
  "input": "Is there some kind of quantitative score that we can give to judge the quality of a potential guess?",
  "model": "nmt",
  "translatedText": "Van-e valamilyen mennyiségi pontszám, amelyet megadhatunk a potenciális tipp minőségének megítélésére?",
  "time_range": [
   219.4,
   224.92
  ]
 },
 {
  "input": "Now to set up for the way that we're going to rank possible guesses, let's go back and add a little clarity to how exactly the game is set up.",
  "model": "nmt",
  "translatedText": "Most, hogy beállítsuk, hogyan rangsoroljuk a lehetséges találgatásokat, térjünk vissza, és adjunk hozzá egy kis világosságot a játék pontos beállításához.",
  "time_range": [
   224.92,
   231.8
  ]
 },
 {
  "input": "So there's a list of words that it will allow you to enter that are considered valid guesses that's just about 13,000 words long.",
  "model": "nmt",
  "translatedText": "Tehát van egy listája azoknak a szavaknak, amelyekbe beírhatja, és amelyek érvényesnek számítanak, és amely csak körülbelül 13 000 szóból áll.",
  "time_range": [
   231.8,
   237.92
  ]
 },
 {
  "input": "But when you look at it, there's a lot of really uncommon things, things like a head or Ali and ARG, the kind of words that bring about family arguments in a game of Scrabble.",
  "model": "nmt",
  "translatedText": "De ha ránézünk, sok nagyon szokatlan dolog van, például egy fej vagy Ali és ARG, olyan szavak, amelyek családi vitákat váltanak ki a Scrabble játékban.",
  "time_range": [
   237.92,
   247.04
  ]
 },
 {
  "input": "But the vibe of the game is that the answer is always going to be a decently common word.",
  "model": "nmt",
  "translatedText": "De a játék hangulata az, hogy a válasz mindig egy tisztességesen gyakori szó lesz.",
  "time_range": [
   247.04,
   250.6
  ]
 },
 {
  "input": "And in fact, there's another list of around 2300 words that are the possible answers.",
  "model": "nmt",
  "translatedText": "Valójában van egy másik lista, amely körülbelül 2300 szóból áll, amelyek a lehetséges válaszok.",
  "time_range": [
   250.6,
   256.08
  ]
 },
 {
  "input": "And this is a human curated list, I think specifically by the game creator's girlfriend, which is kind of fun.",
  "model": "nmt",
  "translatedText": "És ez egy emberi összeállítású lista, szerintem kifejezetten a játék készítőjének barátnője, ami egyfajta móka.",
  "time_range": [
   256.08,
   261.8
  ]
 },
 {
  "input": "But what I would like to do, our challenge for this project is to see if we can write a program solving Wordle that doesn't incorporate previous knowledge about this list.",
  "model": "nmt",
  "translatedText": "De amit szeretnék csinálni, a kihívásunk ebben a projektben az, hogy megtudjuk, tudunk-e olyan Wordle-t megoldó programot írni, amely nem tartalmazza a listával kapcsolatos korábbi ismereteket.",
  "time_range": [
   261.8,
   270.72
  ]
 },
 {
  "input": "For one thing, there's plenty of pretty common five letter words that you won't find in that list.",
  "model": "nmt",
  "translatedText": "Egyrészt rengeteg elég gyakori ötbetűs szó van, amelyeket nem találsz a listában.",
  "time_range": [
   270.72,
   275.56
  ]
 },
 {
  "input": "So it would be better to write a program that's a little more resilient and would play Wordle against anyone, not just what happens to be the official website.",
  "model": "nmt",
  "translatedText": "Ezért jobb lenne egy kicsit ellenállóbb programot írni, és bárki ellen kijátszana a Wordle-t, nem csak a hivatalos webhely ellen.",
  "time_range": [
   275.56,
   281.96
  ]
 },
 {
  "input": "And also the reason that we know what this list of possible answers is, is because it's visible in the source code.",
  "model": "nmt",
  "translatedText": "És az oka annak, hogy tudjuk, mi ez a lehetséges válaszok listája, az az, hogy ez látható a forráskódban.",
  "time_range": [
   281.96,
   287.44
  ]
 },
 {
  "input": "But the way that it's visible in the source code is in the specific order in which answers come up from day to day.",
  "model": "nmt",
  "translatedText": "De az a mód, ahogyan ez látható a forráskódban, abban a konkrét sorrendben történik, ahogy a válaszok napról napra megjelennek.",
  "time_range": [
   287.44,
   292.84
  ]
 },
 {
  "input": "So you could always just look up what tomorrow's answer will be.",
  "model": "nmt",
  "translatedText": "Így mindig csak utánanézhet, mi lesz holnap a válasz.",
  "time_range": [
   292.84,
   296.4
  ]
 },
 {
  "input": "So clearly, there's some sense in which using the list is cheating.",
  "model": "nmt",
  "translatedText": "Nyilvánvaló, hogy a lista használata csalásnak minősül.",
  "time_range": [
   296.4,
   299.14
  ]
 },
 {
  "input": "And what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data like relative word frequencies in general to capture this intuition of having a preference for more common words.",
  "model": "nmt",
  "translatedText": "És ami érdekesebbé teszi a rejtvényt és gazdagabb információelméleti leckét, az az, hogy ehelyett néhány univerzálisabb adatot használunk, például általában a relatív szógyakoriságokat, hogy megragadjuk ezt az intuíciót, hogy a gyakoribb szavakat preferáljuk.",
  "time_range": [
   299.14,
   311.64
  ]
 },
 {
  "input": "So of these 13,000 possibilities, how should we choose the opening guess?",
  "model": "nmt",
  "translatedText": "Tehát ebből a 13 000 lehetőségből hogyan válasszuk ki a nyitó tippet?",
  "time_range": [
   311.64,
   316.56
  ]
 },
 {
  "input": "For example, if my friend proposes weary, how should we analyze its quality?",
  "model": "nmt",
  "translatedText": "Például, ha a barátom fáradtságot javasol, hogyan elemezzük a minőségét?",
  "time_range": [
   316.56,
   319.96
  ]
 },
 {
  "input": "Well, the reason he said he likes that unlikely W is that he likes the long shot nature of just how good it feels if you do hit that W.",
  "model": "nmt",
  "translatedText": "Nos, azért mondta, hogy szereti ezt a valószínűtlen W-t, mert szereti a hosszú távú természetét, hogy milyen jó érzés, ha eltalálja azt a W-t.",
  "time_range": [
   319.96,
   327.88
  ]
 },
 {
  "input": "For example, if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern.",
  "model": "nmt",
  "translatedText": "Például, ha az első feltárt minta valami ilyesmi volt, akkor kiderül, hogy ebben az óriási lexikonban csak 58 szó van, amely megfelel ennek a mintának.",
  "time_range": [
   327.88,
   336.08
  ]
 },
 {
  "input": "So that's a huge reduction from 13,000.",
  "model": "nmt",
  "translatedText": "Tehát ez óriási csökkenés 13 000-hez képest.",
  "time_range": [
   336.08,
   338.9
  ]
 },
 {
  "input": "But the flip side of that, of course, is that it's very uncommon to get a pattern like this.",
  "model": "nmt",
  "translatedText": "De ennek persze az a másik oldala, hogy nagyon ritka az ilyen minta.",
  "time_range": [
   338.9,
   343.36
  ]
 },
 {
  "input": "Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000.",
  "model": "nmt",
  "translatedText": "Pontosabban, ha minden szó egyenlő valószínűséggel lenne a válasz, akkor ennek a mintának a valószínűsége 58 osztva körülbelül 13 000-rel.",
  "time_range": [
   343.36,
   351.68
  ]
 },
 {
  "input": "Of course, they're not equally likely to be answers.",
  "model": "nmt",
  "translatedText": "Természetesen nem egyforma valószínűséggel lesznek válaszok.",
  "time_range": [
   351.68,
   353.88
  ]
 },
 {
  "input": "Most of these are very obscure and even questionable words.",
  "model": "nmt",
  "translatedText": "Ezek többsége nagyon homályos, sőt megkérdőjelezhető szavak.",
  "time_range": [
   353.88,
   356.68
  ]
 },
 {
  "input": "But at least for our first pass at all of this, let's assume that they're all equally likely and then refine that a bit later.",
  "model": "nmt",
  "translatedText": "De legalább az első lépésünknél tegyük fel, hogy mindegyik egyformán valószínű, majd finomítsunk egy kicsit később.",
  "time_range": [
   356.68,
   362.04
  ]
 },
 {
  "input": "The point is the pattern with a lot of information is by its very nature unlikely to occur.",
  "model": "nmt",
  "translatedText": "A lényeg az, hogy a sok információt tartalmazó minta természeténél fogva nem valószínű, hogy előfordul.",
  "time_range": [
   362.04,
   367.36
  ]
 },
 {
  "input": "In fact, what it means to be informative is that it's unlikely.",
  "model": "nmt",
  "translatedText": "Valójában informatívnak lenni azt jelenti, hogy nem valószínű.",
  "time_range": [
   367.36,
   371.92
  ]
 },
 {
  "input": "A much more probable pattern to see with this opening would be something like this, where of course there's not a W in it.",
  "model": "nmt",
  "translatedText": "Sokkal valószínűbb mintát látni ennél a nyitásnál valami ilyesmi lenne, ahol természetesen nincs benne W.",
  "time_range": [
   371.92,
   378.36
  ]
 },
 {
  "input": "Maybe there's an E, and maybe there's no A, there's no R, there's no Y.",
  "model": "nmt",
  "translatedText": "Lehet, hogy van E, és lehet, hogy nincs A, nincs R, nincs Y.",
  "time_range": [
   378.36,
   382.08
  ]
 },
 {
  "input": "In this case, there are 1400 possible matches.",
  "model": "nmt",
  "translatedText": "Ebben az esetben 1400 egyezés lehetséges.",
  "time_range": [
   382.08,
   384.64
  ]
 },
 {
  "input": "If all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see.",
  "model": "nmt",
  "translatedText": "Ha mindegyik egyforma valószínűségű lenne, akkor körülbelül 11%-os valószínűséggel alakulna ki, hogy ezt a mintát látná.",
  "time_range": [
   384.64,
   390.68
  ]
 },
 {
  "input": "So the most likely outcomes are also the least informative.",
  "model": "nmt",
  "translatedText": "Tehát a legvalószínűbb eredmények a legkevésbé informatívak.",
  "time_range": [
   390.68,
   394.32
  ]
 },
 {
  "input": "To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see.",
  "model": "nmt",
  "translatedText": "Ahhoz, hogy átfogóbb képet kaphasson itt, hadd mutassam meg a valószínűségek teljes eloszlását az esetlegesen látható különböző minták között.",
  "time_range": [
   394.32,
   402.0
  ]
 },
 {
  "input": "So each bar that you're looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3 to the 5th possibilities, and they're organized from left to right, most common to least common.",
  "model": "nmt",
  "translatedText": "Tehát minden megtekintett sáv megfelel egy lehetséges színmintának, amely felfedhető, amelyből 3-5. lehetőség van, és balról jobbra vannak rendezve, a leggyakoribbtól a legkevésbé gyakoriig.",
  "time_range": [
   402.0,
   412.96
  ]
 },
 {
  "input": "So the most common possibility here is that you get all grays.",
  "model": "nmt",
  "translatedText": "Tehát itt a leggyakoribb lehetőség az, hogy minden szürke színt kap.",
  "time_range": [
   412.96,
   416.2
  ]
 },
 {
  "input": "That happens about 14% of the time.",
  "model": "nmt",
  "translatedText": "Ez az esetek 14%-ában történik.",
  "time_range": [
   416.2,
   418.8
  ]
 },
 {
  "input": "And what you're hoping for when you make a guess is that you end up somewhere out in this long tail, like over here where there's only 18 possibilities for what matches this pattern that evidently look like this.",
  "model": "nmt",
  "translatedText": "És abban reménykedsz, amikor tippelsz, hogy valahol kint, ebben a hosszú farokban kötsz ki, például itt, ahol csak 18 lehetőség van arra, hogy mi illik ehhez a mintázathoz, ami nyilvánvalóan így néz ki.",
  "time_range": [
   418.8,
   429.92
  ]
 },
 {
  "input": "Or if we venture a little farther to the left, you know, maybe we go all the way over here.",
  "model": "nmt",
  "translatedText": "Vagy ha kicsit messzebbre merészkedünk balra, tudod, talán egészen idáig megyünk.",
  "time_range": [
   429.92,
   434.08
  ]
 },
 {
  "input": "Okay, here's a good puzzle for you.",
  "model": "nmt",
  "translatedText": "Oké, itt van egy jó rejtvény a számodra.",
  "time_range": [
   434.08,
   436.56
  ]
 },
 {
  "input": "What are the three words in the English language that start with a W, end with a Y, and have an R somewhere in them?",
  "model": "nmt",
  "translatedText": "Mi az a három szó az angol nyelvben, amelyek W-vel kezdődnek, Y-ra végződnek, és van bennük valahol R betű?",
  "time_range": [
   436.56,
   442.04
  ]
 },
 {
  "input": "Turns out, the answers are, let's see, wordy, wormy, and wryly.",
  "model": "nmt",
  "translatedText": "Kiderült, hogy a válaszok, lássuk, bőbeszédűek, férgesek és fanyarok.",
  "time_range": [
   442.04,
   447.56
  ]
 },
 {
  "input": "So to judge how good this word is overall, we want some kind of measure of the expected amount of information that you're going to get from this distribution.",
  "model": "nmt",
  "translatedText": "Tehát annak megítéléséhez, hogy mennyire jó ez a szó összességében, szeretnénk valamilyen mérőszámot a várható információmennyiségről, amelyet ebből a terjesztésből kapni fog.",
  "time_range": [
   447.56,
   456.36
  ]
 },
 {
  "input": "If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score.",
  "model": "nmt",
  "translatedText": "Ha végigmegyünk az egyes mintákon, és megszorozzuk annak valószínűségét, hogy bekövetkezik valami, ami azt méri, hogy mennyire informatív, az talán objektív pontszámot adhat nekünk.",
  "time_range": [
   456.36,
   466.0
  ]
 },
 {
  "input": "Now your first instinct for what that something should be might be the number of matches.",
  "model": "nmt",
  "translatedText": "Most az első megérzése, hogy mi legyen ennek a valaminek, a mérkőzések száma lehet.",
  "time_range": [
   466.0,
   470.28
  ]
 },
 {
  "input": "You want a lower average number of matches.",
  "model": "nmt",
  "translatedText": "Alacsonyabb átlagos mérkőzésszámot szeretne.",
  "time_range": [
   470.28,
   472.96
  ]
 },
 {
  "input": "But instead I'd like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they're actually the answer.",
  "model": "nmt",
  "translatedText": "De ehelyett egy univerzálisabb mérést szeretnék használni, amelyet gyakran az információnak tulajdonítunk, és egy olyant, amely rugalmasabb lesz, ha mind a 13 000 szóhoz különböző valószínűséget rendelünk ahhoz, hogy valóban ezek a válaszok-e vagy sem.",
  "time_range": [
   472.96,
   490.6
  ]
 },
 {
  "input": "The standard unit of information is the bit, which has a little bit of a funny formula, but it's really intuitive if we just look at examples.",
  "model": "nmt",
  "translatedText": "Az információ szabványos egysége a bit, aminek van egy kicsit vicces képlete, de nagyon intuitív, ha csak példákat nézünk.",
  "time_range": [
   490.6,
   497.8
  ]
 },
 {
  "input": "If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information.",
  "model": "nmt",
  "translatedText": "Ha van olyan megfigyelése, amely felére csökkenti a lehetőségek terét, akkor azt mondjuk, hogy egy kis információval rendelkezik.",
  "time_range": [
   497.8,
   504.2
  ]
 },
 {
  "input": "In our example, the space of possibilities is all possible words, and it turns out about Half of the five letter words have an S, a little less than that, but about half.",
  "model": "nmt",
  "translatedText": "Példánkban a lehetőségek tere az összes lehetséges szó, és ez kb. Az ötbetűs szavak felében van S, ennél valamivel kevesebb, de kb.",
  "time_range": [
   504.2,
   511.56
  ]
 },
 {
  "input": "So that observation would give you one bit of information.",
  "model": "nmt",
  "translatedText": "Tehát ez a megfigyelés egy kis információval szolgálna.",
  "time_range": [
   511.56,
   515.2
  ]
 },
 {
  "input": "If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information.",
  "model": "nmt",
  "translatedText": "Ha ehelyett egy új tény négyszeresére vágja le a lehetőségek terét, akkor azt mondjuk, hogy két bitnyi információval rendelkezik.",
  "time_range": [
   515.2,
   522.0
  ]
 },
 {
  "input": "For example, it turns out about a quarter of these words have a T.",
  "model": "nmt",
  "translatedText": "Például kiderül, hogy ezeknek a szavaknak körülbelül egynegyedében van T.",
  "time_range": [
   522.0,
   525.12
  ]
 },
 {
  "input": "If the observation cuts that space by a factor of eight, we say it's three bits of information, and so on and so forth.",
  "model": "nmt",
  "translatedText": "Ha a megfigyelés ezt a helyet nyolcszorosára csökkenti, akkor azt mondjuk, hogy ez három bit információ, és így tovább, és így tovább.",
  "time_range": [
   525.12,
   530.92
  ]
 },
 {
  "input": "Four bits cuts it into a 16th, five bits cuts it into a 32nd.",
  "model": "nmt",
  "translatedText": "Négy bit 16-osra, öt bit 32-esre vágja.",
  "time_range": [
   530.92,
   535.0
  ]
 },
 {
  "input": "So now you might want to pause and ask yourself, what is the formula for information for the number of bits in terms of the probability of an occurrence?",
  "model": "nmt",
  "translatedText": "Tehát most érdemes szünetet tartani, és feltenni magának a kérdést, hogy mi a képlet a bitszám információhoz az előfordulás valószínűsége szempontjából?",
  "time_range": [
   535.0,
   544.52
  ]
 },
 {
  "input": "What we're saying here is that when you take one half to the number of bits, that's the same thing as the probability, which is the same thing as saying two to the power of the number of bits is one over the probability, which rearranges further to saying the information is the log base two of one divided by the probability.",
  "model": "nmt",
  "translatedText": "Itt azt mondjuk, hogy amikor a bitek számának egy felét veszünk, az ugyanaz, mint a valószínűség, ami ugyanaz, mintha azt mondanánk, hogy a bitek számának hatványára kettő eggyel meghaladja a valószínűséget, ami átrendezi tovább, és azt mondja, hogy az információ az egy naplóalap kettő osztva a valószínűséggel.",
  "time_range": [
   544.52,
   559.68
  ]
 },
 {
  "input": "And sometimes you see this with one more rearrangement still, where the information is the negative log base two of the probability.",
  "model": "nmt",
  "translatedText": "És néha ezt még egy átrendezéssel látja, ahol az információ a valószínűség negatív logaritmusa.",
  "time_range": [
   559.68,
   565.68
  ]
 },
 {
  "input": "Expressed like this, it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you've cut down your possibilities in half.",
  "model": "nmt",
  "translatedText": "Így kifejezve kissé furcsának tűnhet az avatatlanok számára, de valójában csak az a nagyon intuitív ötlet, hogy megkérdezzük, hányszor vágtad félbe a lehetőségeidet.",
  "time_range": [
   565.68,
   575.12
  ]
 },
 {
  "input": "Now if you're wondering, you know, I thought we were just playing a fun word game, why are logarithms entering the picture?",
  "model": "nmt",
  "translatedText": "Ha kíváncsi vagy, azt hittem, csak egy szórakoztató szójátékot játszunk, miért lépnek be a képbe a logaritmusok?",
  "time_range": [
   575.12,
   579.92
  ]
 },
 {
  "input": "One reason this is a nicer unit is it's just a lot easier to talk about very unlikely events, much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.",
  "model": "nmt",
  "translatedText": "Az egyik oka ennek a szebb egységnek, mert sokkal könnyebb nagyon valószínűtlen eseményekről beszélni, sokkal könnyebb azt mondani, hogy egy megfigyelésnek 20 bitnyi információja van, mint azt mondani, hogy az ilyen és ehhez hasonló előfordulásának valószínűsége 0.",
  "time_range": [
   579.92,
   592.7851851851852
  ]
 },
 {
  "input": "0000095.",
  "model": "nmt",
  "translatedText": "0000095.",
  "time_range": [
   592.7851851851852,
   593.48
  ]
 },
 {
  "input": "But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that information adds together.",
  "model": "nmt",
  "translatedText": "De egy lényegesebb oka annak, hogy ez a logaritmikus kifejezés nagyon hasznos adaléknak bizonyult a valószínűségelmélethez, az az információ összeadásának módja.",
  "time_range": [
   593.48,
   602.0
  ]
 },
 {
  "input": "For example, if one observation gives you two bits of information, cutting your space down by four, and then a second observation like your second guess in Wordle gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information.",
  "model": "nmt",
  "translatedText": "Például, ha az egyik megfigyelés két bit információt ad, ami néggyel csökkenti a teret, majd egy második megfigyelés, mint a Wordle második sejtése, további három bit információt ad, további nyolcszoros faktorral csökkentve, kettő együtt öt bit információt ad.",
  "time_range": [
   602.0,
   617.36
  ]
 },
 {
  "input": "In the same way that probabilities like to multiply, information likes to add.",
  "model": "nmt",
  "translatedText": "Ugyanúgy, ahogy a valószínűségek szeretnek szaporodni, az információ szeret összeadni.",
  "time_range": [
   617.36,
   621.2
  ]
 },
 {
  "input": "So as soon as we're in the realm of something like an expected value, where we're adding a bunch of numbers up, the logs make it a lot nicer to deal with.",
  "model": "nmt",
  "translatedText": "Tehát amint egy várható értékhez hasonló birodalmába kerülünk, ahol egy csomó számot adunk össze, a naplók sokkal jobban kezelik.",
  "time_range": [
   621.2,
   628.66
  ]
 },
 {
  "input": "Let's go back to our distribution for Weary and add another little tracker on here, showing us how much information there is for each pattern.",
  "model": "nmt",
  "translatedText": "Térjünk vissza a Weary disztribúciójához, és adjunk hozzá még egy kis nyomkövetőt, amely megmutatja, mennyi információ van az egyes mintákhoz.",
  "time_range": [
   628.66,
   635.56
  ]
 },
 {
  "input": "The main thing I want you to notice is that the higher the probability as we get to those more likely patterns, the lower the information, the fewer bits you gain.",
  "model": "nmt",
  "translatedText": "A legfontosabb dolog, amit észre akarok venni, az az, hogy minél nagyobb a valószínűsége a valószínűbb minták elérésének, minél alacsonyabb az információ, annál kevesebb bitet nyer.",
  "time_range": [
   635.56,
   643.5
  ]
 },
 {
  "input": "The way we measure the quality of this guess will be to take the expected value of this information, where we go through each pattern, we say how probable is it, and then we multiply that by how many bits of information do we get.",
  "model": "nmt",
  "translatedText": "Ennek a találgatásnak a minőségét úgy mérjük, hogy felvesszük ennek az információnak a várható értékét, ahol végigmegyünk az egyes mintákon, megmondjuk, hogy mekkora a valószínűsége, majd ezt megszorozzuk azzal, hogy hány bittel kapunk információt.",
  "time_range": [
   643.5,
   654.94
  ]
 },
 {
  "input": "And in the example of Weary, that turns out to be 4.",
  "model": "nmt",
  "translatedText": "És Weary példájában ez a 4. 9 bites.",
  "time_range": [
   654.94,
   658.1073684210526
  ]
 },
 {
  "input": "9 bits.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   658.1073684210526,
   658.48
  ]
 },
 {
  "input": "So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times.",
  "model": "nmt",
  "translatedText": "Tehát átlagosan az ebből a nyitó tippből származó információ olyan jó, mintha körülbelül ötször kettévágná a lehetőségek terét.",
  "time_range": [
   658.48,
   665.66
  ]
 },
 {
  "input": "By contrast, an example of a guess with a higher expected information value would be something like Slate.",
  "model": "nmt",
  "translatedText": "Ezzel szemben a magasabb várható információértékkel rendelkező találgatás például a Slate.",
  "time_range": [
   665.66,
   673.22
  ]
 },
 {
  "input": "In this case you'll notice the distribution looks a lot flatter.",
  "model": "nmt",
  "translatedText": "Ebben az esetben észre fogja venni, hogy az elosztás sokkal laposabbnak tűnik.",
  "time_range": [
   673.22,
   676.18
  ]
 },
 {
  "input": "In particular, the most probable occurrence of all grays only has about a 6% chance of occurring, so at minimum you're getting evidently 3.",
  "model": "nmt",
  "translatedText": "Konkrétan az összes szürke legvalószínűbb előfordulásának csak körülbelül 6% az esélye az előfordulásra, tehát legalább 3-at kapsz.",
  "time_range": [
   676.18,
   684.4350000000001
  ]
 },
 {
  "input": "9 bits of information.",
  "model": "nmt",
  "translatedText": "9 bites információ.",
  "time_range": [
   684.4350000000001,
   685.94
  ]
 },
 {
  "input": "But that's a minimum, more typically you'd get something better than that.",
  "model": "nmt",
  "translatedText": "De ez a minimum, jellemzőbb, hogy ennél jobbat kapsz.",
  "time_range": [
   685.94,
   689.14
  ]
 },
 {
  "input": "And it turns out when you crunch the numbers on this one and add up all the relevant terms, the average information is about 5.",
  "model": "nmt",
  "translatedText": "És kiderül, hogy ha összetörjük a számokat, és összeadjuk az összes releváns kifejezést, az átlagos információ körülbelül 5.",
  "time_range": [
   689.14,
   696.3331428571428
  ]
 },
 {
  "input": "8.",
  "model": "nmt",
  "translatedText": "8.",
  "time_range": [
   696.3331428571428,
   696.42
  ]
 },
 {
  "input": "So in contrast with Weary, your space of possibilities will be about half as big after this first guess, on average.",
  "model": "nmt",
  "translatedText": "Tehát Weary-vel ellentétben a lehetőségek tere átlagosan körülbelül feleakkora lesz az első találgatás után.",
  "time_range": [
   696.42,
   703.94
  ]
 },
 {
  "input": "There's actually a fun story about the name for this expected value of information quantity.",
  "model": "nmt",
  "translatedText": "Valójában van egy szórakoztató történet az információmennyiség várható értékének elnevezéséről.",
  "time_range": [
   703.94,
   709.54
  ]
 },
 {
  "input": "Information theory was developed by Claude Shannon, who was working at Bell Labs in the 1940s, but he was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, very prominent in math and physics and the beginnings of what was becoming computer science.",
  "model": "nmt",
  "translatedText": "Az információelméletet Claude Shannon dolgozta ki, aki az 1940-es években a Bell Labs-nál dolgozott, de néhány még publikálásra váró ötletéről beszélt John von Neumann-nal, aki akkoriban ez a nagyon prominens szellemi óriás volt. a matematikában és a fizikában, valamint az informatikává váló kezdetek kezdetén.",
  "time_range": [
   709.54,
   724.18
  ]
 },
 {
  "input": "And when he mentioned that he didn't really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, well you should call it entropy, and for two reasons.",
  "model": "nmt",
  "translatedText": "És amikor megemlítette, hogy nem igazán van jó neve ennek az információmennyiség várható értékének, Neumann állítólag azt mondta, szóval a történet úgy megy, hogy nevezzük entrópiának, és két okból.",
  "time_range": [
   724.18,
   734.72
  ]
 },
 {
  "input": "In the first place, your uncertainty function has been used in statistical mechanics under that name, so it already has a name, and in the second place, and more important, nobody knows what entropy really is, so in a debate you'll always have the advantage.",
  "model": "nmt",
  "translatedText": "Először is, a bizonytalansági függvényt ezen a néven használták a statisztikai mechanikában, tehát már van neve, másodszor, ami még fontosabb, senki sem tudja, mi is az entrópia valójában, ezért a vitákban mindig előnye van.",
  "time_range": [
   734.72,
   746.94
  ]
 },
 {
  "input": "So if the name seems a little bit mysterious, and if this story is to be believed, that's kind of by design.",
  "model": "nmt",
  "translatedText": "Tehát ha a név egy kicsit titokzatosnak tűnik, és ha hinni lehet ennek a történetnek, akkor ez valamiféle terv.",
  "time_range": [
   746.94,
   753.42
  ]
 },
 {
  "input": "Also if you're wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory, and for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess.",
  "model": "nmt",
  "translatedText": "Valamint ha kíváncsiak vagytok a termodinamika fizika azon második törvényével való kapcsolatára, biztosan van összefüggés, de Shannon eredetileg csak a tiszta valószínűségelmélettel foglalkozott, és a mi céljainkra, amikor a szóentrópia, csak azt szeretném, ha egy adott találgatás várható információs értékére gondolna.",
  "time_range": [
   753.42,
   770.82
  ]
 },
 {
  "input": "You can think of entropy as measuring two things simultaneously.",
  "model": "nmt",
  "translatedText": "Az entrópiát úgy képzelheti el, hogy két dolgot mér egyszerre.",
  "time_range": [
   770.82,
   774.38
  ]
 },
 {
  "input": "The first one is how flat is the distribution.",
  "model": "nmt",
  "translatedText": "Az első az, hogy mennyire lapos az eloszlás.",
  "time_range": [
   774.38,
   777.42
  ]
 },
 {
  "input": "The closer a distribution is to uniform, the higher that entropy will be.",
  "model": "nmt",
  "translatedText": "Minél közelebb van egy eloszlás az egyenleteshez, annál nagyobb lesz az entrópia.",
  "time_range": [
   777.42,
   781.7
  ]
 },
 {
  "input": "In our case, where there are 3 to the 5th total patterns, for a uniform distribution, observing any one of them would have information log base 2 of 3 to the 5th, which happens to be 7.",
  "model": "nmt",
  "translatedText": "Esetünkben, ahol 3-tól 5-ig összesen mintázat van, az egyenletes eloszlás érdekében bármelyiket megfigyelve a 2-es információs naplóbázis 3-tól az 5-ig terjed, ami történetesen 7.",
  "time_range": [
   781.7,
   791.8586363636365
  ]
 },
 {
  "input": "92, so that is the absolute maximum that you could possibly have for this entropy.",
  "model": "nmt",
  "translatedText": "92, tehát ez az abszolút maximum, amit ennél az entrópiánál kaphat.",
  "time_range": [
   791.8586363636365,
   797.86
  ]
 },
 {
  "input": "But entropy is also kind of a measure of how many possibilities there are in the first place.",
  "model": "nmt",
  "translatedText": "De az entrópia egyfajta mérőszáma is annak, hogy hány lehetőség van az első helyen.",
  "time_range": [
   797.86,
   802.9
  ]
 },
 {
  "input": "For example, if you happen to have some word where there's only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be 4 bits.",
  "model": "nmt",
  "translatedText": "Például, ha van egy olyan szó, ahol csak 16 lehetséges minta van, és mindegyik egyforma valószínűséggel, akkor ez az entrópia, ez a várt információ 4 bites lenne.",
  "time_range": [
   802.9,
   812.76
  ]
 },
 {
  "input": "But if you have another word where there's 64 possible patterns that could come up, and they're all equally likely, then the entropy would work out to be 6 bits.",
  "model": "nmt",
  "translatedText": "De ha van egy másik szó, ahol 64 lehetséges minta jöhet szóba, és mindegyik egyformán valószínű, akkor az entrópia 6 bitesnek bizonyulna.",
  "time_range": [
   812.76,
   821.0
  ]
 },
 {
  "input": "So if you see some distribution out in the wild that has an entropy of 6 bits, it's sort of like it's saying there's as much variation and uncertainty in what's about to happen as if there were 64 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "Tehát ha látunk valami eloszlást a természetben, amelynek entrópiája 6 bites, az olyan, mintha azt mondaná, annyi eltérés és bizonytalanság van abban, hogy mi fog történni, mintha 64 egyformán valószínű kimenetel lenne.",
  "time_range": [
   821.0,
   834.4
  ]
 },
 {
  "input": "For my first pass at the Wurtelebot, I basically had it just do this.",
  "model": "nmt",
  "translatedText": "A Wurtelebotnál az első bérletemnél alapvetően ezt kellett csinálnom.",
  "time_range": [
   834.4,
   838.36
  ]
 },
 {
  "input": "It goes through all of the possible guesses you could have, all 13,000 words, computes the entropy for each one, or more specifically, the entropy of the distribution across all patterns you might see, for each one, and picks the highest, since that's the one that's likely to chop down your space of possibilities as much as possible.",
  "model": "nmt",
  "translatedText": "Végigmegy az összes lehetséges találgatáson, mind a 13 000 szón, mindegyikre kiszámítja az entrópiát, pontosabban az eloszlás entrópiáját az összes látható minta között, mindegyikre, és kiválasztja a legmagasabbat, mivel ez az, amely valószínűleg a lehető legnagyobb mértékben lecsökkenti a lehetőségek tárházát.",
  "time_range": [
   838.36,
   857.2
  ]
 },
 {
  "input": "And even though I've only been talking about the first guess here, it does the same thing for the next few guesses.",
  "model": "nmt",
  "translatedText": "És bár itt csak az első találgatásról beszéltem, a következő néhány találgatásnál ugyanezt teszi.",
  "time_range": [
   857.2,
   861.68
  ]
 },
 {
  "input": "For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words.",
  "model": "nmt",
  "translatedText": "Például, miután az első találgatáson lát valamilyen mintát, amely kevesebb szóra korlátozza, az alapján, hogy mi egyezik ezzel, ugyanazt a játékot játssza el azzal a kisebb szókészlettel.",
  "time_range": [
   861.68,
   872.3
  ]
 },
 {
  "input": "For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words, you search through all 13,000 possibilities, and you find the one that maximizes that entropy.",
  "model": "nmt",
  "translatedText": "A javasolt második tipphez megvizsgálja az összes mintázat eloszlását, amely a szűkebb szókészletből származhat, átkutatja mind a 13 000 lehetőséget, és megtalálja azt, amely maximalizálja ezt az entrópiát.",
  "time_range": [
   872.3,
   885.48
  ]
 },
 {
  "input": "To show you how this works in action, let me just pull up a little variant of Wurtele that I wrote that shows the highlights of this analysis in the margins.",
  "model": "nmt",
  "translatedText": "Hogy megmutassam, hogyan működik ez a gyakorlatban, hadd húzzak fel egy kis változatot a Wurtele-ről, amit írtam, és amely a margókon mutatja be ennek az elemzésnek a legfontosabb pontjait.",
  "time_range": [
   885.48,
   894.46
  ]
 },
 {
  "input": "After doing all its entropy calculations, on the right here it's showing us which ones have the highest expected information.",
  "model": "nmt",
  "translatedText": "Miután elvégezte az összes entrópiaszámítást, itt a jobb oldalon megmutatja, hogy melyek rendelkeznek a legmagasabb elvárt információval.",
  "time_range": [
   894.46,
   900.34
  ]
 },
 {
  "input": "Turns out the top answer, at least at the moment, we'll refine this later, is Tares, which means, um, of course, a vetch, the most common vetch.",
  "model": "nmt",
  "translatedText": "Kiderült, hogy a legjobb válasz, legalábbis jelenleg, ezt később finomítjuk, a Tares, ami azt jelenti, hm, persze, a bükkönyt, a leggyakoribb bükkönyt.",
  "time_range": [
   900.34,
   911.14
  ]
 },
 {
  "input": "Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had, but then on the right of the word here it's showing us how much actual information we got, given this particular pattern.",
  "model": "nmt",
  "translatedText": "Minden alkalommal, amikor tippelünk, lehet, hogy figyelmen kívül hagyom az ajánlásait, és inkább a palat választom, mert szeretem a palat, láthatjuk, hogy mennyi várt információja volt, de akkor a szó jobb oldalán látható, hogy mennyit. aktuális információkat kaptunk, tekintettel erre a konkrét mintára.",
  "time_range": [
   911.14,
   924.98
  ]
 },
 {
  "input": "So here it looks like we were a little unlucky, we were expected to get 5.",
  "model": "nmt",
  "translatedText": "Szóval itt úgy néz ki, hogy kicsit balszerencsénk volt, 5-öt vártak ránk.",
  "time_range": [
   924.98,
   927.9320879120878
  ]
 },
 {
  "input": "8, but we happened to get something with less than that.",
  "model": "nmt",
  "translatedText": "8, de véletlenül kaptunk valamit ennél kevesebbel.",
  "time_range": [
   927.9320879120878,
   930.66
  ]
 },
 {
  "input": "And then on the left side here it's showing us all of the different possible words given where we are now.",
  "model": "nmt",
  "translatedText": "És akkor itt a bal oldalon az összes lehetséges szót mutatja, a jelenlegi helyzet alapján.",
  "time_range": [
   930.66,
   935.86
  ]
 },
 {
  "input": "The blue bars are telling us how likely it thinks each word is, so at the moment it's assuming each word is equally likely to occur, but we'll refine that in a moment.",
  "model": "nmt",
  "translatedText": "A kék sávok azt mutatják, hogy mennyire valószínűnek tartja az egyes szavakat, ezért jelenleg azt feltételezi, hogy mindegyik szó előfordulásának valószínűsége egyenlő, de ezt egy pillanat alatt finomítjuk.",
  "time_range": [
   935.86,
   944.14
  ]
 },
 {
  "input": "And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it's a uniform distribution, is just a needlessly complicated way to count the number of possibilities.",
  "model": "nmt",
  "translatedText": "És akkor ez a bizonytalanságmérés megmondja ennek az eloszlásnak az entrópiáját a lehetséges szavak között, ami jelenleg, mivel egységes eloszlásról van szó, csak egy szükségtelenül bonyolult módszer a lehetőségek számának megszámlálására.",
  "time_range": [
   944.14,
   955.94
  ]
 },
 {
  "input": "For example, if we were to take 2 to the power of 13.",
  "model": "nmt",
  "translatedText": "Például, ha 2-t 13 hatványára vennénk.",
  "time_range": [
   955.94,
   959.3436363636363
  ]
 },
 {
  "input": "66, that should be around the 13,000 possibilities.",
  "model": "nmt",
  "translatedText": "66, ennek körülbelül a 13 000 lehetőségnek kell lennie.",
  "time_range": [
   959.3436363636363,
   962.7
  ]
 },
 {
  "input": "I'm a little bit off here, but only because I'm not showing all the decimal places.",
  "model": "nmt",
  "translatedText": "Kicsit elkanyarodok itt, de csak azért, mert nem mutatok minden tizedesjegyet.",
  "time_range": [
   962.7,
   966.78
  ]
 },
 {
  "input": "At the moment that might feel redundant and like it's overly complicating things, but you'll see why it's useful to have both numbers in a minute.",
  "model": "nmt",
  "translatedText": "Pillanatnyilag ez feleslegesnek tűnhet, és túlságosan bonyolítja a dolgokat, de látni fogod, miért hasznos, ha mindkét szám egy perc alatt elérhető.",
  "time_range": [
   966.78,
   972.78
  ]
 },
 {
  "input": "So here it looks like it's suggesting the highest entropy for our second guess is Ramen, which again just really doesn't feel like a word.",
  "model": "nmt",
  "translatedText": "Tehát itt úgy tűnik, hogy második tippünk szerint a legmagasabb entrópiát a Ramen jelenti, ami megint csak nem tűnik szónak.",
  "time_range": [
   972.78,
   979.7
  ]
 },
 {
  "input": "So to take the moral high ground here, I'm going to go ahead and type in Rains.",
  "model": "nmt",
  "translatedText": "Tehát, hogy itt az erkölcsi magaslatot megtegyem, megyek előre, és beírom, hogy Rains.",
  "time_range": [
   979.7,
   985.66
  ]
 },
 {
  "input": "And again it looks like we were a little unlucky.",
  "model": "nmt",
  "translatedText": "És megint úgy tűnik, hogy egy kicsit szerencsétlenek voltunk.",
  "time_range": [
   985.66,
   987.54
  ]
 },
 {
  "input": "We were expecting 4.",
  "model": "nmt",
  "translatedText": "4-re számítottunk.",
  "time_range": [
   987.54,
   988.8729230769231
  ]
 },
 {
  "input": "3 bits and we only got 3.",
  "model": "nmt",
  "translatedText": "3 bit és csak 3-at kaptunk.",
  "time_range": [
   988.8729230769231,
   990.5566153846153
  ]
 },
 {
  "input": "39 bits of information.",
  "model": "nmt",
  "translatedText": "39 bites információ.",
  "time_range": [
   990.5566153846153,
   992.1
  ]
 },
 {
  "input": "So that takes us down to 55 possibilities.",
  "model": "nmt",
  "translatedText": "Ez 55 lehetőségre vezet le minket.",
  "time_range": [
   992.1,
   995.06
  ]
 },
 {
  "input": "And here maybe I'll just actually go with what it's suggesting, which is combo, whatever that means.",
  "model": "nmt",
  "translatedText": "És itt talán csak azt fogom folytatni, amit sugall, ami a kombinált, bármit is jelentsen ez.",
  "time_range": [
   995.06,
   1000.2
  ]
 },
 {
  "input": "And okay, this is actually a good chance for a puzzle.",
  "model": "nmt",
  "translatedText": "És oké, ez egy jó lehetőség egy rejtvényre.",
  "time_range": [
   1000.2,
   1003.3
  ]
 },
 {
  "input": "It's telling us this pattern gives us 4.",
  "model": "nmt",
  "translatedText": "Azt mondja nekünk, hogy ez a minta 4-et ad.",
  "time_range": [
   1003.3,
   1005.718
  ]
 },
 {
  "input": "7 bits of information.",
  "model": "nmt",
  "translatedText": "7 bit információ.",
  "time_range": [
   1005.718,
   1007.02
  ]
 },
 {
  "input": "But over on the left, before we see that pattern, there were 5.",
  "model": "nmt",
  "translatedText": "De a bal oldalon, mielőtt láttuk ezt a mintát, 5 volt.",
  "time_range": [
   1007.02,
   1010.9909523809524
  ]
 },
 {
  "input": "78 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "78 bites bizonytalanság.",
  "time_range": [
   1010.9909523809524,
   1012.4
  ]
 },
 {
  "input": "So as a quiz for you, what does that mean about the number of remaining possibilities?",
  "model": "nmt",
  "translatedText": "Tehát kvízként, mit jelent ez a fennmaradó lehetőségek számáról?",
  "time_range": [
   1012.4,
   1016.86
  ]
 },
 {
  "input": "Well, it means that we're reduced down to one bit of uncertainty, which is the same thing as saying that there's two possible answers.",
  "model": "nmt",
  "translatedText": "Nos, ez azt jelenti, hogy egy kis bizonytalanságra csökkentünk, ami ugyanaz, mintha azt mondanánk, hogy két lehetséges válasz létezik.",
  "time_range": [
   1016.86,
   1024.7
  ]
 },
 {
  "input": "It's a 50-50 choice.",
  "model": "nmt",
  "translatedText": "50-50 közötti választás.",
  "time_range": [
   1024.7,
   1026.52
  ]
 },
 {
  "input": "And from here, because you and I know which words are more common, we know that the answer should be abyss.",
  "model": "nmt",
  "translatedText": "És innentől kezdve, mivel te és én tudjuk, hogy melyik szavak gyakoribbak, tudjuk, hogy a válasznak mélységben kell lennie.",
  "time_range": [
   1026.52,
   1031.22
  ]
 },
 {
  "input": "But as it's written right now, the program doesn't know that.",
  "model": "nmt",
  "translatedText": "De ahogy most írják, a program ezt nem tudja.",
  "time_range": [
   1031.22,
   1033.54
  ]
 },
 {
  "input": "So it just keeps going, trying to gain as much information as it can, until it's only one possibility left, and then it guesses it.",
  "model": "nmt",
  "translatedText": "Tehát csak megy, próbál annyi információt szerezni, amennyit csak tud, amíg már csak egy lehetőség marad, aztán kitalálja.",
  "time_range": [
   1033.54,
   1040.36
  ]
 },
 {
  "input": "So obviously we need a better endgame strategy.",
  "model": "nmt",
  "translatedText": "Tehát nyilvánvalóan jobb végjáték-stratégiára van szükségünk.",
  "time_range": [
   1040.36,
   1042.7
  ]
 },
 {
  "input": "But let's say we call this version one of our wordle solver, and then we go and run some simulations to see how it does.",
  "model": "nmt",
  "translatedText": "De tegyük fel, hogy ezt a verziót az egyik szómegoldónknak nevezzük, majd futunk néhány szimulációt, hogy megnézzük, hogyan működik.",
  "time_range": [
   1042.7,
   1050.74
  ]
 },
 {
  "input": "So the way this is working is it's playing every possible wordle game.",
  "model": "nmt",
  "translatedText": "Tehát ez úgy működik, hogy minden lehetséges szójátékot lejátsz.",
  "time_range": [
   1050.74,
   1054.24
  ]
 },
 {
  "input": "It's going through all of those 2315 words that are the actual wordle answers.",
  "model": "nmt",
  "translatedText": "Végigmegy azon a 2315 szón, amelyek a tényleges szóbeli válaszok.",
  "time_range": [
   1054.24,
   1058.78
  ]
 },
 {
  "input": "It's basically using that as a testing set.",
  "model": "nmt",
  "translatedText": "Alapvetően ezt tesztkészletként használja.",
  "time_range": [
   1058.78,
   1061.34
  ]
 },
 {
  "input": "And with this naive method of not considering how common a word is, and just trying to maximize the information at each step along the way, until it gets down to one and only one choice.",
  "model": "nmt",
  "translatedText": "És ezzel a naiv módszerrel, hogy nem veszi figyelembe, mennyire gyakori egy szó, és csak próbálja maximalizálni az információt az út minden lépésében, amíg el nem jut az egyetlen választásig.",
  "time_range": [
   1061.34,
   1070.48
  ]
 },
 {
  "input": "By the end of the simulation, the average score works out to be about 4.",
  "model": "nmt",
  "translatedText": "A szimuláció végére az átlagos pontszám körülbelül 4 lesz.",
  "time_range": [
   1070.48,
   1074.9127027027027
  ]
 },
 {
  "input": "124.",
  "model": "nmt",
  "translatedText": "124.",
  "time_range": [
   1074.9127027027027,
   1075.1
  ]
 },
 {
  "input": "Which is not bad, to be honest, I kind of expected to do worse.",
  "model": "nmt",
  "translatedText": "Ami nem rossz, hogy őszinte legyek, valahogy rosszabbra számítottam.",
  "time_range": [
   1075.1,
   1079.78
  ]
 },
 {
  "input": "But the people who play wordle will tell you that they can usually get it in 4.",
  "model": "nmt",
  "translatedText": "De azok, akik wordle-t játszanak, azt mondják, hogy általában 4-ben is megkapják.",
  "time_range": [
   1079.78,
   1083.04
  ]
 },
 {
  "input": "The real challenge is to get as many in 3 as you can.",
  "model": "nmt",
  "translatedText": "Az igazi kihívás az, hogy minél többet szerezz be 3-ba.",
  "time_range": [
   1083.04,
   1085.26
  ]
 },
 {
  "input": "It's a pretty big jump between the score of 4 and the score of 3.",
  "model": "nmt",
  "translatedText": "Elég nagy ugrás a 4-es és a 3-as pontszám között.",
  "time_range": [
   1085.26,
   1088.92
  ]
 },
 {
  "input": "The obvious low hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that.",
  "model": "nmt",
  "translatedText": "A nyilvánvaló, alacsonyan lógó gyümölcs itt az, hogy valahogyan bele kell foglalni, hogy egy szó gyakori-e vagy sem, és pontosan hogyan tesszük ezt.",
  "time_range": [
   1088.92,
   1103.16
  ]
 },
 {
  "input": "The way I approached it is to get a list of the relative frequencies for all of the words in the English language.",
  "model": "nmt",
  "translatedText": "Úgy közelítettem meg, hogy az összes angol nyelvű szó relatív gyakoriságáról kapok listát.",
  "time_range": [
   1103.16,
   1108.56
  ]
 },
 {
  "input": "And I just used Mathematica's word frequency data function, which itself pulls from the Google Books English Ngram public dataset.",
  "model": "nmt",
  "translatedText": "És csak a Mathematica szófrekvenciás adatfüggvényét használtam, amely maga a Google Books angol Ngram nyilvános adatkészletéből származik.",
  "time_range": [
   1108.56,
   1115.52
  ]
 },
 {
  "input": "And it's kind of fun to look at, for example if we sort it from the most common words to the least common words.",
  "model": "nmt",
  "translatedText": "És szórakoztató nézni, például ha a leggyakoribb szavaktól a legkevésbé gyakori szavakig rendezzük.",
  "time_range": [
   1115.52,
   1120.12
  ]
 },
 {
  "input": "Evidently these are the most common, 5 letter words in the English language.",
  "model": "nmt",
  "translatedText": "Nyilvánvalóan ezek a leggyakoribb, 5 betűből álló szavak az angol nyelvben.",
  "time_range": [
   1120.12,
   1123.74
  ]
 },
 {
  "input": "Or rather, these is the 8th most common.",
  "model": "nmt",
  "translatedText": "Illetve ez a 8. leggyakoribb.",
  "time_range": [
   1123.74,
   1126.48
  ]
 },
 {
  "input": "First is which, after which there's there and there.",
  "model": "nmt",
  "translatedText": "Először melyik, utána ott és ott.",
  "time_range": [
   1126.48,
   1129.44
  ]
 },
 {
  "input": "First itself is not first, but 9th, and it makes sense that these other words could come about more often, where those after first are after, where, and those being just a little bit less common.",
  "model": "nmt",
  "translatedText": "Az első önmagában nem az első, hanem a 9. , és logikus, hogy ezek a többi szó gyakrabban fordulhat elő, ahol az első utániak az után következnek, hol, és azok, amelyek egy kicsit ritkábban fordulnak elő.",
  "time_range": [
   1129.44,
   1139.0
  ]
 },
 {
  "input": "Now, in using this data to model how likely each of these words is to be the final answer, it shouldn't just be proportional to the frequency.",
  "model": "nmt",
  "translatedText": "Ha ezeket az adatokat használjuk annak modellezésére, hogy ezeknek a szavaknak a valószínűsége a végső válasz, nem csak a gyakorisággal kell arányosnak lennie.",
  "time_range": [
   1139.0,
   1147.02
  ]
 },
 {
  "input": "For example, which is given a score of 0.",
  "model": "nmt",
  "translatedText": "Például ami 0 pontot kap.",
  "time_range": [
   1147.02,
   1149.5967441860466
  ]
 },
 {
  "input": "002 in this dataset, whereas the word braid is in some sense about 1000 times less likely.",
  "model": "nmt",
  "translatedText": "002 ebben az adatkészletben, míg a fonat szó bizonyos értelemben körülbelül 1000-szer kevésbé valószínű.",
  "time_range": [
   1149.5967441860466,
   1155.2
  ]
 },
 {
  "input": "But both of these are common enough words that they're almost certainly worth considering.",
  "model": "nmt",
  "translatedText": "De mindkettő elég gyakori szó ahhoz, hogy szinte biztosan megfontolandó.",
  "time_range": [
   1155.2,
   1159.4
  ]
 },
 {
  "input": "So we want more of a binary cutoff.",
  "model": "nmt",
  "translatedText": "Tehát inkább bináris levágást akarunk.",
  "time_range": [
   1159.4,
   1161.9
  ]
 },
 {
  "input": "The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it's either 0 or it's 1, but there's a smoothing in between for that region of uncertainty.",
  "model": "nmt",
  "translatedText": "Úgy jártam el, hogy elképzelem, hogy ezt az egész soros szólistát egy x tengelyre rendezem, majd alkalmazom a szigmoid függvényt, ami a szokásos módja annak, hogy olyan függvényt készítsünk, amelynek kimenete alapvetően bináris. vagy 0, vagy 1, de van egy simítás a bizonytalansági régió között.",
  "time_range": [
   1161.9,
   1178.5
  ]
 },
 {
  "input": "So essentially, the probability that I'm assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis.",
  "model": "nmt",
  "translatedText": "Tehát lényegében annak a valószínűsége, hogy minden szót hozzárendelek a végső listában való szerepléshez, a fenti szigmoid függvény értéke lesz, bárhol is legyen az x tengelyen.",
  "time_range": [
   1178.5,
   1189.54
  ]
 },
 {
  "input": "Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from 1 to 0, and where we situate them left to right determines the cutoff.",
  "model": "nmt",
  "translatedText": "Ez nyilvánvalóan néhány paramétertől függ, például az, hogy az x tengelyen milyen széles szóközt töltenek ki ezek a szavak, meghatározza, hogy milyen fokozatosan vagy meredeken zuhanunk le 1-ről 0-ra, és hogy hol helyezzük el őket balról jobbra, az határozza meg a levágást.",
  "time_range": [
   1189.54,
   1203.16
  ]
 },
 {
  "input": "To be honest, the way I did this was just licking my finger and sticking it into the wind.",
  "model": "nmt",
  "translatedText": "Őszintén szólva, ahogy ezt csináltam, csak megnyaltam az ujjamat, és beledugtam a szélbe.",
  "time_range": [
   1203.16,
   1207.34
  ]
 },
 {
  "input": "I looked through the sorted list and tried to find a window where when I looked at it I figured about half of these words are more likely than not to be the final answer, and used that as the cutoff.",
  "model": "nmt",
  "translatedText": "Átnéztem a rendezett listán, és megpróbáltam találni egy ablakot, ahol amikor ránéztem, arra jutottam, hogy ezeknek a szavaknak körülbelül a fele valószínűbb, mint hogy ne legyen a végső válasz, és ezt használtam zárójelként.",
  "time_range": [
   1207.34,
   1217.68
  ]
 },
 {
  "input": "Once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement.",
  "model": "nmt",
  "translatedText": "Ha ilyen eloszlást kapunk a szavak között, akkor egy újabb helyzetet kapunk, ahol az entrópia válik igazán hasznos méréssé.",
  "time_range": [
   1217.68,
   1224.46
  ]
 },
 {
  "input": "For example, let's say we were playing a game and we start with my old openers, which were a feather and nails, and we end up with a situation where there's four possible words that match it.",
  "model": "nmt",
  "translatedText": "Tegyük fel például, hogy játszunk egy játékot, és a régi nyitóimmal kezdjük, amelyek egy toll és szögek voltak, és egy olyan helyzethez jutunk, ahol négy lehetséges szó egyezik.",
  "time_range": [
   1224.46,
   1233.76
  ]
 },
 {
  "input": "And let's say we consider them all equally likely.",
  "model": "nmt",
  "translatedText": "És tegyük fel, hogy mindegyiket egyformán valószínűnek tartjuk.",
  "time_range": [
   1233.76,
   1236.44
  ]
 },
 {
  "input": "Let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Hadd kérdezzem meg, mi ennek az eloszlásnak az entrópiája?",
  "time_range": [
   1236.44,
   1240.0
  ]
 },
 {
  "input": "Well, the information associated with each one of these possibilities is going to be the log base 2 of 4, since each one is 1 and 4, and that's 2.",
  "model": "nmt",
  "translatedText": "Nos, az ezekhez a lehetőségekhez tartozó információ a 2-es naplóalap 4 lesz, mivel mindegyik 1 és 4, és ez 2.",
  "time_range": [
   1240.0,
   1250.8
  ]
 },
 {
  "input": "Two bits of information, four possibilities.",
  "model": "nmt",
  "translatedText": "Két bit információ, négy lehetőség.",
  "time_range": [
   1250.8,
   1252.78
  ]
 },
 {
  "input": "All very well and good.",
  "model": "nmt",
  "translatedText": "Minden nagyon jó és jó.",
  "time_range": [
   1252.78,
   1254.36
  ]
 },
 {
  "input": "But what if I told you that actually there's more than four matches?",
  "model": "nmt",
  "translatedText": "De mi lenne, ha azt mondanám, hogy valójában négynél több meccs van?",
  "time_range": [
   1254.36,
   1258.32
  ]
 },
 {
  "input": "In reality, when we look through the full word list, there are 16 words that match it.",
  "model": "nmt",
  "translatedText": "A valóságban, ha végignézzük a teljes szólistát, 16 szó van, ami megfelel.",
  "time_range": [
   1258.32,
   1262.6
  ]
 },
 {
  "input": "But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like 1 in 1000 because they're really obscure.",
  "model": "nmt",
  "translatedText": "De tegyük fel, hogy a modellünk nagyon alacsony valószínűséggel teszi azt a másik 12 szót a végső válasznak, valami 1 az 1000-hez, mert ezek valóban homályosak.",
  "time_range": [
   1262.6,
   1271.44
  ]
 },
 {
  "input": "Now let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Most pedig hadd kérdezzem meg, mi ennek az eloszlásnak az entrópiája?",
  "time_range": [
   1271.44,
   1275.48
  ]
 },
 {
  "input": "If entropy was purely measuring the number of matches here, then you might expect it to be something like the log base 2 of 16, which would be 4, two more bits of uncertainty than we had before.",
  "model": "nmt",
  "translatedText": "Ha az entrópia pusztán az egyezések számát mérné itt, akkor azt várhatnánk, hogy valami olyasmi lesz, mint a 16-os 2-es log-alap, ami 4, két bittel több bizonytalanság, mint korábban.",
  "time_range": [
   1275.48,
   1286.2
  ]
 },
 {
  "input": "But of course the actual uncertainty is not really that different from what we had before.",
  "model": "nmt",
  "translatedText": "De természetesen a tényleges bizonytalanság nem igazán különbözik a korábbiaktól.",
  "time_range": [
   1286.2,
   1290.32
  ]
 },
 {
  "input": "Just because there's these 12 really obscure words doesn't mean that it would be all that more surprising to learn that the final answer is charm, for example.",
  "model": "nmt",
  "translatedText": "Csak azért, mert ott van ez a 12 nagyon homályos szó, még nem jelenti azt, hogy még meglepőbb lenne megtudni, hogy a végső válasz például a báj.",
  "time_range": [
   1290.32,
   1298.2
  ]
 },
 {
  "input": "So when you actually do the calculation here, and you add up the probability of each occurrence times the corresponding information, what you get is 2.",
  "model": "nmt",
  "translatedText": "Tehát amikor itt elvégzi a számítást, és összeadja az egyes előfordulások valószínűségét a megfelelő információ szorzatával, akkor 2-t kap.",
  "time_range": [
   1298.2,
   1305.5147540983605
  ]
 },
 {
  "input": "11 bits.",
  "model": "nmt",
  "translatedText": "11 bites.",
  "time_range": [
   1305.5147540983605,
   1305.96
  ]
 },
 {
  "input": "I'm just saying, it's basically two bits, basically those four possibilities, but there's a little more uncertainty because of all of those highly unlikely events, though if you did learn them you'd get a ton of information from it.",
  "model": "nmt",
  "translatedText": "Csak azt mondom, hogy ez alapvetően két bit, alapvetően ez a négy lehetőség, de egy kicsit több a bizonytalanság a rendkívül valószínűtlen események miatt, bár ha megismernéd őket, rengeteg információhoz jutna.",
  "time_range": [
   1305.96,
   1317.12
  ]
 },
 {
  "input": "So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson.",
  "model": "nmt",
  "translatedText": "Tehát a kicsinyítés része annak, ami miatt a Wordle olyan szép példa egy információelméleti leckére.",
  "time_range": [
   1317.12,
   1321.8
  ]
 },
 {
  "input": "We have these two distinct feeling applications for entropy.",
  "model": "nmt",
  "translatedText": "Az entrópiának ez a két eltérő érzésalkalmazása van.",
  "time_range": [
   1321.8,
   1325.28
  ]
 },
 {
  "input": "The first one telling us what's the expected information we'll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words that we have possible.",
  "model": "nmt",
  "translatedText": "Az első azt mondja meg, hogy mi a várt információ, amelyet egy adott sejtésből kapunk, a második pedig azt mondja, hogy mérhetjük-e az összes lehetséges szó fennmaradó bizonytalanságát.",
  "time_range": [
   1325.28,
   1336.48
  ]
 },
 {
  "input": "And I should emphasize, in that first case where we're looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation.",
  "model": "nmt",
  "translatedText": "És hangsúlyoznom kell, hogy abban az első esetben, amikor a feltételezés várható információját nézzük, ha a szavak egyenlőtlen súlyozása van, az befolyásolja az entrópiaszámítást.",
  "time_range": [
   1336.48,
   1345.0
  ]
 },
 {
  "input": "For example, let me pull up that same case we were looking at earlier of the distribution associated with Weary, but this time using a non-uniform distribution across all possible words.",
  "model": "nmt",
  "translatedText": "Például hadd húzzam fel ugyanazt az esetet, amelyet korábban megvizsgáltunk a Weary-hez kapcsolódó eloszlásról, de ezúttal nem egységes eloszlást használva az összes szóban.",
  "time_range": [
   1345.0,
   1354.56
  ]
 },
 {
  "input": "So let me see if I can find a part here that illustrates it pretty well.",
  "model": "nmt",
  "translatedText": "Szóval hadd lássam, találok-e itt olyan részt, ami elég jól illusztrálja.",
  "time_range": [
   1354.56,
   1359.36
  ]
 },
 {
  "input": "Okay, here this is pretty good.",
  "model": "nmt",
  "translatedText": "Oké, ez itt nagyon jó.",
  "time_range": [
   1359.36,
   1362.48
  ]
 },
 {
  "input": "Here we have two adjacent patterns that are about equally likely, but one of them we're told has 32 possible words that match it.",
  "model": "nmt",
  "translatedText": "Itt van két szomszédos mintánk, amelyek körülbelül egyformán valószínűek, de az egyiknek 32 lehetséges szója van, amelyek megfelelnek.",
  "time_range": [
   1362.48,
   1369.48
  ]
 },
 {
  "input": "And if we check what they are, these are those 32, which are all just very unlikely words as you scan your eyes over them.",
  "model": "nmt",
  "translatedText": "És ha megnézzük, hogy mik ezek, ez az a 32, amelyek mind csak nagyon valószínűtlen szavak, ahogy végignézed rajtuk a szemed.",
  "time_range": [
   1369.48,
   1375.6
  ]
 },
 {
  "input": "It's hard to find any that feel like plausible answers, maybe yells, but if we look at the neighboring pattern in the distribution, which is considered just about as likely, we're told that it only has 8 possible matches, so a quarter as many matches, but it's about as likely.",
  "model": "nmt",
  "translatedText": "Nehéz találni olyanokat, amelyek elfogadható válasznak tűnnek, esetleg kiabálásnak, de ha megnézzük a szomszédos mintát a disztribúcióban, amelyet nagyjából ugyanolyan valószínűnek tartanak, azt mondják, hogy csak 8 lehetséges egyezése van, tehát egy negyede sok meccs, de nagyjából ennyi a valószínűsége.",
  "time_range": [
   1375.6,
   1389.92
  ]
 },
 {
  "input": "And when we pull up those matches, we can see why.",
  "model": "nmt",
  "translatedText": "És amikor felhúzzuk ezeket a meccseket, láthatjuk, miért.",
  "time_range": [
   1389.92,
   1392.52
  ]
 },
 {
  "input": "Some of these are actual plausible answers, like ring, or wrath, or raps.",
  "model": "nmt",
  "translatedText": "Ezek közül néhány ténylegesen elfogadható válasz, például csengetés, harag vagy rap.",
  "time_range": [
   1392.52,
   1397.84
  ]
 },
 {
  "input": "To illustrate how we incorporate all that, let me pull up version 2 of the Wordlebot here, and there are two or three main differences from the first one that we saw.",
  "model": "nmt",
  "translatedText": "Annak szemléltetésére, hogyan építjük be mindezt, hadd húzzam ide a Wordlebot 2. verzióját, és két-három fő különbség van az elsőhöz képest, amit láttunk.",
  "time_range": [
   1397.84,
   1405.96
  ]
 },
 {
  "input": "First off, like I just said, the way that we're computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer.",
  "model": "nmt",
  "translatedText": "Először is, ahogy az imént mondtam, az a mód, ahogyan ezeket az entrópiákat, az információ várható értékeit kiszámítjuk, most a minták finomabb eloszlását használja, amely magában foglalja annak valószínűségét, hogy egy adott szó valóban a válasz.",
  "time_range": [
   1405.96,
   1419.3
  ]
 },
 {
  "input": "As it happens, tears is still number 1, though the ones following are a bit different.",
  "model": "nmt",
  "translatedText": "Megtörténik, hogy a könnyek továbbra is az 1. helyen állnak, bár a következő egy kicsit más.",
  "time_range": [
   1419.3,
   1424.16
  ]
 },
 {
  "input": "Second, when it ranks its top picks, it's now going to keep a model of the probability that each word is the actual answer, and it'll incorporate that into its decision, which is easier to see once we have a few guesses on the table.",
  "model": "nmt",
  "translatedText": "Másodszor, amikor rangsorolja a legjobb választásokat, most modellt fog tartani annak valószínűségére vonatkozóan, hogy minden szó a tényleges válasz, és ezt beépíti a döntésébe, ami könnyebben belátható, ha van néhány tippünk a asztal.",
  "time_range": [
   1424.16,
   1435.52
  ]
 },
 {
  "input": "Again, ignoring its recommendation because we can't let machines rule our lives.",
  "model": "nmt",
  "translatedText": "Ismét figyelmen kívül hagyjuk az ajánlást, mert nem hagyhatjuk, hogy a gépek irányítsák életünket.",
  "time_range": [
   1435.52,
   1441.12
  ]
 },
 {
  "input": "And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches.",
  "model": "nmt",
  "translatedText": "És azt hiszem, meg kell említenem egy másik dolgot, ami itt a bal oldalon van, hogy a bizonytalansági érték, a bitek száma már nem csak redundáns a lehetséges egyezések számával.",
  "time_range": [
   1441.12,
   1450.08
  ]
 },
 {
  "input": "Now if we pull it up and calculate 2 to the 8.",
  "model": "nmt",
  "translatedText": "Ha most felhúzzuk és kiszámoljuk a 2-t a 8-hoz.",
  "time_range": [
   1450.08,
   1453.4894117647057
  ]
 },
 {
  "input": "02, which is a little above 256, I guess 259, what it's saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "02, ami valamivel 256 felett van, azt hiszem, 259, amit mond, annak ellenére, hogy összesen 526 szó van, amely valójában megfelel ennek a mintának, a bizonytalanság mértéke inkább hasonlít ahhoz, ami akkor lenne, ha 259 ugyanolyan valószínűséggel lenne. eredmények.",
  "time_range": [
   1453.4894117647057,
   1469.76
  ]
 },
 {
  "input": "You can think of it like this.",
  "model": "nmt",
  "translatedText": "Ezt így is el lehet képzelni.",
  "time_range": [
   1469.76,
   1471.1
  ]
 },
 {
  "input": "It knows borx is not the answer, same with yorts and zorl and zorus, so it's a little less uncertain than it was in the previous case.",
  "model": "nmt",
  "translatedText": "Tudja, hogy nem a borx a megoldás, ugyanúgy, mint a yorts, a zorl és a zorus, így egy kicsit kevésbé bizonytalan, mint az előző esetben.",
  "time_range": [
   1471.1,
   1477.84
  ]
 },
 {
  "input": "This number of bits will be smaller.",
  "model": "nmt",
  "translatedText": "Ez a bitszám kisebb lesz.",
  "time_range": [
   1477.84,
   1480.22
  ]
 },
 {
  "input": "And if I keep playing the game, I'm refining this down with a couple guesses that are apropos of what I would like to explain here.",
  "model": "nmt",
  "translatedText": "És ha folytatom a játékot, finomítok ezen néhány találgatással, amelyek megfelelnek annak, amit itt el szeretnék magyarázni.",
  "time_range": [
   1480.22,
   1488.68
  ]
 },
 {
  "input": "By the fourth guess, if you look over at its top picks, you can see it's no longer just maximizing the entropy.",
  "model": "nmt",
  "translatedText": "A negyedik tippre, ha megnézzük a legjobb választásokat, láthatjuk, hogy már nem csak az entrópia maximalizálásáról van szó.",
  "time_range": [
   1488.68,
   1493.8
  ]
 },
 {
  "input": "So at this point, there's technically seven possibilities, but the only ones with a meaningful chance are dorms and words.",
  "model": "nmt",
  "translatedText": "Tehát ezen a ponton technikailag hét lehetőség van, de csak a kollégiumoknak és a szavaknak van értelme.",
  "time_range": [
   1493.8,
   1500.78
  ]
 },
 {
  "input": "And you can see it ranks choosing both of those above all of these other values, that strictly speaking would give more information.",
  "model": "nmt",
  "translatedText": "És láthatja, hogy mindkettőt választva a többi érték fölé kerül, ami szigorúan véve több információt adna.",
  "time_range": [
   1500.78,
   1507.56
  ]
 },
 {
  "input": "The very first time I did this, I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect.",
  "model": "nmt",
  "translatedText": "A legelső alkalommal, amikor ezt megtettem, csak összeadtam ezt a két számot, hogy megmérjem az egyes találgatások minőségét, ami valójában jobban működött, mint gondolnád.",
  "time_range": [
   1507.56,
   1514.58
  ]
 },
 {
  "input": "But it really didn't feel systematic, and I'm sure there's other approaches people could take but here's the one I landed on.",
  "model": "nmt",
  "translatedText": "De tényleg nem tűnt szisztematikusnak, és biztos vagyok benne, hogy az emberek más megközelítéseket is alkalmazhatnak, de ez az, amelyre ráakadtam.",
  "time_range": [
   1514.58,
   1519.88
  ]
 },
 {
  "input": "If we're considering the prospect of a next guess, like in this case words, what we really care about is the expected score of our game if we do that.",
  "model": "nmt",
  "translatedText": "Ha egy következő tippelés lehetőségét vesszük fontolóra, mint ebben az esetben a szavak, akkor igazán érdekel a játékunk várható pontszáma, ha ezt tesszük.",
  "time_range": [
   1519.88,
   1528.44
  ]
 },
 {
  "input": "And to calculate that expected score, we say what's the probability that words is the actual answer, which at the moment it describes 58% to.",
  "model": "nmt",
  "translatedText": "És a várható pontszám kiszámításához megmondjuk, hogy mekkora a valószínűsége annak, hogy a szavak jelentik a tényleges választ, amely pillanatnyilag 58%-át írja le.",
  "time_range": [
   1528.44,
   1536.08
  ]
 },
 {
  "input": "We say with a 58% chance, our score in this game would be 4.",
  "model": "nmt",
  "translatedText": "Azt mondjuk, 58%-os eséllyel 4 lenne a pontszámunk ebben a játékban.",
  "time_range": [
   1536.08,
   1540.4
  ]
 },
 {
  "input": "And then with the probability of 1 minus that 58%, our score will be more than that 4.",
  "model": "nmt",
  "translatedText": "És akkor 1 mínusz 58% valószínűséggel a pontszámunk több lesz, mint a 4.",
  "time_range": [
   1540.4,
   1546.24
  ]
 },
 {
  "input": "How much more we don't know, but we can estimate it based on how much uncertainty there's likely to be once we get to that point.",
  "model": "nmt",
  "translatedText": "Hogy mennyit, azt még nem tudjuk, de meg tudjuk becsülni az alapján, hogy mennyi bizonytalanság várható, ha eljutunk odáig.",
  "time_range": [
   1546.24,
   1552.92
  ]
 },
 {
  "input": "Specifically, at the moment there's 1.",
  "model": "nmt",
  "translatedText": "Pontosabban, jelenleg 1 db van.",
  "time_range": [
   1552.92,
   1555.2277966101697
  ]
 },
 {
  "input": "44 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "44 bit bizonytalanság.",
  "time_range": [
   1555.2277966101697,
   1556.6
  ]
 },
 {
  "input": "If we guess words, it's telling us the expected information we'll get is 1.",
  "model": "nmt",
  "translatedText": "Ha szavakat tippelünk, az azt jelenti, hogy a várt információ 1.",
  "time_range": [
   1556.6,
   1561.1313580246913
  ]
 },
 {
  "input": "27 bits.",
  "model": "nmt",
  "translatedText": "27 bites.",
  "time_range": [
   1561.1313580246913,
   1561.56
  ]
 },
 {
  "input": "So if we guess words, this difference represents how much uncertainty we're likely to be left with after that happens.",
  "model": "nmt",
  "translatedText": "Tehát ha kitaláljuk a szavakat, ez a különbség azt mutatja, hogy mennyi bizonytalanság marad ránk, miután ez megtörténik.",
  "time_range": [
   1561.56,
   1568.28
  ]
 },
 {
  "input": "What we need is some kind of function, which I'm calling f here, that associates this uncertainty with an expected score.",
  "model": "nmt",
  "translatedText": "Szükségünk van valamiféle függvényre, amelyet itt f-nek nevezek, és amely ezt a bizonytalanságot egy várható pontszámmal társítja.",
  "time_range": [
   1568.28,
   1573.88
  ]
 },
 {
  "input": "And the way it went about this was to just plot a bunch of the data from previous games based on version 1 of the bot to say hey what was the actual score after various points with certain very measurable amounts of uncertainty.",
  "model": "nmt",
  "translatedText": "És úgy ment ez a dolog, hogy a bot 1. verziója alapján csak egy csomó adatot ábrázoltak a korábbi játékokból, hogy kimondják, mi volt a tényleges pontszám különböző pontok után bizonyos nagyon mérhető bizonytalanság mellett.",
  "time_range": [
   1573.88,
   1587.04
  ]
 },
 {
  "input": "For example, these data points here that are sitting above a value that's around like 8.",
  "model": "nmt",
  "translatedText": "Például ezek az adatpontok itt, amelyek egy 8 körüli érték felett vannak.",
  "time_range": [
   1587.04,
   1591.0736363636363
  ]
 },
 {
  "input": "7 or so are saying for some games after a point at which there were 8.",
  "model": "nmt",
  "translatedText": "Néhány meccsre körülbelül 7 mondható egy olyan pont után, amikor 8 volt.",
  "time_range": [
   1591.0736363636363,
   1595.4260674157304
  ]
 },
 {
  "input": "7 bits of uncertainty, it took two guesses to get the final answer.",
  "model": "nmt",
  "translatedText": "7 bites bizonytalanság, két találgatás kellett a végső válaszhoz.",
  "time_range": [
   1595.4260674157304,
   1599.34
  ]
 },
 {
  "input": "For other games it took three guesses, for other games it took four guesses.",
  "model": "nmt",
  "translatedText": "Más játékoknál három, más játékoknál négy tipp kellett.",
  "time_range": [
   1599.34,
   1603.18
  ]
 },
 {
  "input": "If we shift over to the left here, all the points over zero are saying whenever there's zero bits of uncertainty, which is to say there's only one possibility, then the number of guesses required is always just one, which is reassuring.",
  "model": "nmt",
  "translatedText": "Ha itt átváltunk balra, a nulla feletti összes pont azt mondja, ha nulla bitnyi bizonytalanság van, vagyis csak egy lehetőség van, akkor a szükséges találgatások száma mindig csak egy, ami megnyugtató.",
  "time_range": [
   1603.18,
   1615.0
  ]
 },
 {
  "input": "Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess, sometimes it required two more guesses.",
  "model": "nmt",
  "translatedText": "Valahányszor volt egy kis bizonytalanság, ami azt jelenti, hogy lényegében csak két lehetőségre volt szükség, akkor néha még egy, néha két további találgatás kellett.",
  "time_range": [
   1615.0,
   1623.94
  ]
 },
 {
  "input": "And so on and so forth here.",
  "model": "nmt",
  "translatedText": "És így tovább és így tovább itt.",
  "time_range": [
   1623.94,
   1625.98
  ]
 },
 {
  "input": "Maybe a slightly easier way to visualize this data is to bucket it together and take averages.",
  "model": "nmt",
  "translatedText": "Talán egy kicsit egyszerűbb módja ezeknek az adatoknak az, ha összegyűjtjük és átlagokat veszünk.",
  "time_range": [
   1625.98,
   1631.02
  ]
 },
 {
  "input": "For example this bar here saying among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.",
  "model": "nmt",
  "translatedText": "Például ez a sáv itt azt mondja, hogy azon pontok között, ahol volt egy kis bizonytalanságunk, átlagosan körülbelül 1 volt az új tippek száma.",
  "time_range": [
   1631.02,
   1642.3082758620692
  ]
 },
 {
  "input": "5.",
  "model": "nmt",
  "translatedText": "5.",
  "time_range": [
   1642.3082758620692,
   1642.42
  ]
 },
 {
  "input": "And the bar over here saying among all of the different games where at some point the uncertainty was a little above four bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward.",
  "model": "nmt",
  "translatedText": "És az itteni sáv azt mondja, hogy a különböző játékok között valamikor a bizonytalanság valamivel négy bit felett volt, ami olyan, mintha 16 különböző lehetőségre szűkítené, akkor átlagosan kicsivel több, mint két találgatás szükséges ettől a ponttól. előre.",
  "time_range": [
   1642.42,
   1656.24
  ]
 },
 {
  "input": "And from here I just did a regression to fit a function that seemed reasonable to this.",
  "model": "nmt",
  "translatedText": "És innen csak egy regressziót végeztem, hogy illeszkedjek egy ehhez ésszerűnek tűnő függvényhez.",
  "time_range": [
   1656.24,
   1660.08
  ]
 },
 {
  "input": "And remember the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be.",
  "model": "nmt",
  "translatedText": "És ne feledje, hogy ennek az egésznek az a lényege, hogy számszerűsítsük azt az intuíciót, hogy minél több információt nyerünk egy szóból, annál alacsonyabb lesz az elvárt pontszám.",
  "time_range": [
   1660.08,
   1669.72
  ]
 },
 {
  "input": "So with this as version 2.",
  "model": "nmt",
  "translatedText": "Tehát ezzel a 2-es verzióval.",
  "time_range": [
   1669.72,
   1671.0438636363638
  ]
 },
 {
  "input": "0, if we go back and we run the same set of simulations, having it play against all 2315 possible wordle answers, how does it do?",
  "model": "nmt",
  "translatedText": "0, ha visszamegyünk, és ugyanazt a szimulációkészletet futtatjuk, ha mind a 2315 szóbeli válasz ellen játszik, hogyan működik?",
  "time_range": [
   1671.0438636363638,
   1679.82
  ]
 },
 {
  "input": "Well in contrast to our first version it's definitely better, which is reassuring.",
  "model": "nmt",
  "translatedText": "Nos, az első verziónkkal ellentétben határozottan jobb, ami megnyugtató.",
  "time_range": [
   1679.82,
   1684.06
  ]
 },
 {
  "input": "All said and done the average is around 3.",
  "model": "nmt",
  "translatedText": "Az átlag 3 körül van.",
  "time_range": [
   1684.06,
   1686.284367816092
  ]
 },
 {
  "input": "6, although unlike the first version there are a couple times that it loses and requires more than six in this circumstance.",
  "model": "nmt",
  "translatedText": "6, bár az első verziótól eltérően van néhány alkalom, amikor elveszíti, és ebben az esetben hatnál többet igényel.",
  "time_range": [
   1686.284367816092,
   1692.82
  ]
 },
 {
  "input": "Presumably because there's times when it's making that tradeoff to actually go for the goal rather than maximizing information.",
  "model": "nmt",
  "translatedText": "Feltehetően azért, mert vannak esetek, amikor kompromisszumot kell kötni, hogy ténylegesen a célt szolgálják, ahelyett, hogy maximalizálnák az információt.",
  "time_range": [
   1692.82,
   1698.98
  ]
 },
 {
  "input": "So can we do better than 3.",
  "model": "nmt",
  "translatedText": "Tehát tudunk jobbat csinálni, mint a 3.",
  "time_range": [
   1698.98,
   1702.022962962963
  ]
 },
 {
  "input": "6?",
  "model": "nmt",
  "translatedText": "6?",
  "time_range": [
   1702.022962962963,
   1702.14
  ]
 },
 {
  "input": "We definitely can.",
  "model": "nmt",
  "translatedText": "Biztosan tudunk.",
  "time_range": [
   1702.14,
   1703.26
  ]
 },
 {
  "input": "Now I said at the start that it's most fun to try not incorporating the true list of wordle answers into the way that it builds its model.",
  "model": "nmt",
  "translatedText": "Most már az elején azt mondtam, hogy az a legszórakoztatóbb, ha megpróbáljuk nem a szóbeli válaszok valódi listáját beépíteni a modell felépítésébe.",
  "time_range": [
   1703.26,
   1709.98
  ]
 },
 {
  "input": "But if we do incorporate it, the best performance I could get was around 3.",
  "model": "nmt",
  "translatedText": "De ha beépítjük, a legjobb teljesítmény, amit elérhettem, 3 körül volt.",
  "time_range": [
   1709.98,
   1715.0431578947369
  ]
 },
 {
  "input": "43.",
  "model": "nmt",
  "translatedText": "43.",
  "time_range": [
   1715.0431578947369,
   1715.18
  ]
 },
 {
  "input": "So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.",
  "model": "nmt",
  "translatedText": "Tehát ha megpróbálunk kifinomultabb lenni annál, mint hogy pusztán a szógyakorisági adatokat használjuk a korábbi eloszlás kiválasztásához, akkor ez a 3.",
  "time_range": [
   1715.18,
   1720.9576470588236
  ]
 },
 {
  "input": "43 probably gives a max at how good we could get with that, or at least how good I could get with that.",
  "model": "nmt",
  "translatedText": "A 43 valószínűleg maximumot ad arra, hogy ezzel mennyire lehetünk jók, vagy legalábbis én milyen jót tudok ezzel elérni.",
  "time_range": [
   1720.9576470588236,
   1726.36
  ]
 },
 {
  "input": "That best performance essentially just uses the ideas that I've been talking about here, but it goes a little farther, like it does a search for the expected information two steps forward rather than just one.",
  "model": "nmt",
  "translatedText": "Ez a legjobb teljesítmény lényegében csak azokat az ötleteket használja fel, amelyekről itt beszéltem, de egy kicsit messzebbre megy, például két lépéssel előre keresi a várt információkat, nem pedig csak egyet.",
  "time_range": [
   1726.36,
   1735.66
  ]
 },
 {
  "input": "Originally I was planning on talking more about that, but I realize we've actually gone quite long as it is.",
  "model": "nmt",
  "translatedText": "Eredetileg azt terveztem, hogy többet fogok beszélni erről, de rájöttem, hogy valójában elég régen mentünk.",
  "time_range": [
   1735.66,
   1740.58
  ]
 },
 {
  "input": "The one thing I'll say is after doing this two-step search and then running a couple sample simulations in the top candidates, so far for me at least it's looking like Crane is the best opener.",
  "model": "nmt",
  "translatedText": "Az egyetlen dolog, amit elmondok, miután elvégeztem ezt a kétlépcsős keresést, majd lefuttattam néhány minta szimulációt a legjobb jelöltekben, legalábbis eddig számomra úgy tűnik, hogy a Crane a legjobb nyitó.",
  "time_range": [
   1740.58,
   1749.5
  ]
 },
 {
  "input": "Who would have guessed?",
  "model": "nmt",
  "translatedText": "Ki sejtette volna?",
  "time_range": [
   1749.5,
   1751.08
  ]
 },
 {
  "input": "Also if you use the true wordle list to determine your space of possibilities, then the uncertainty you start with is a little over 11 bits.",
  "model": "nmt",
  "translatedText": "Ha a valódi szólistát használja a lehetőségek meghatározásához, akkor a kezdeti bizonytalanság valamivel több, mint 11 bit.",
  "time_range": [
   1751.08,
   1758.16
  ]
 },
 {
  "input": "And it turns out, just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits.",
  "model": "nmt",
  "translatedText": "És kiderült, pusztán egy brute force keresésből, az első két találgatás után a maximálisan elvárható információ 10 bit körül van.",
  "time_range": [
   1758.16,
   1766.58
  ]
 },
 {
  "input": "Which suggests that best case scenario, after your first two guesses, with perfectly optimal play, you'll be left with around one bit of uncertainty.",
  "model": "nmt",
  "translatedText": "Ez azt sugallja, hogy a legjobb esetben az első két találgatás után, tökéletesen optimális játék mellett, körülbelül egy kis bizonytalanság marad.",
  "time_range": [
   1766.58,
   1775.22
  ]
 },
 {
  "input": "Which is the same as being down to two possible guesses.",
  "model": "nmt",
  "translatedText": "Ez ugyanaz, mintha két lehetséges találgatásra támaszkodnánk.",
  "time_range": [
   1775.22,
   1777.4
  ]
 },
 {
  "input": "So I think it's fair and probably pretty conservative to say that you could never possibly write an algorithm that gets this average as low as 3, because with the words available to you, there's simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.",
  "model": "nmt",
  "translatedText": "Szóval szerintem tisztességes és valószínűleg meglehetősen konzervatív azt állítani, hogy soha nem tudna olyan algoritmust írni, amelynél ez az átlag 3-ra csökkenne, mert a rendelkezésünkre álló szavakkal egyszerűen nincs helye elegendő információhoz két lépés után.",
  "time_range": [
   1777.4,
   1790.46
  ]
 }
]