[
 {
  "input": "The game Wurdle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.",
  "translatedText": "A Wurdle című játék az elmúlt egy-két hónapban eléggé elterjedt, és mivel sosem hagyok ki egy matematikaórai lehetőséget, úgy gondoltam, hogy ez a játék nagyon jó központi példát szolgáltat az információelméletről, és különösen az entrópia nevű témáról szóló órán.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 12.66
 },
 {
  "input": "You see, like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.",
  "translatedText": "Tudod, mint sok embert, engem is beszippantott a rejtvény, és mint sok programozót, engem is beszippantott, hogy olyan algoritmust írjak, amely a lehető legoptimálisabban játssza a játékot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 13.92,
  "end": 22.74
 },
 {
  "input": "And what I thought I'd do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy.",
  "translatedText": "Arra gondoltam, hogy itt most átbeszélném veletek, hogy hogyan dolgoztam ezen, és elmagyaráznám a matematikát is, ami ebbe belekerült, mivel az egész algoritmus az entrópia gondolatára épül.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.18,
  "end": 31.08
 },
 {
  "input": "First things first, in case you haven't heard of it, what is Wurdle?",
  "translatedText": "Először is, ha még nem hallottál róla, mi az a Wurdle?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 38.7,
  "end": 41.64
 },
 {
  "input": "And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we're going with this, which is to develop a little algorithm that will basically play the game for us.",
  "translatedText": "És hogy két legyet üssünk egy csapásra, miközben a játékszabályokon végigmegyünk, hadd nézzem meg, hogy hova is megyünk ezzel, ami egy kis algoritmus kifejlesztése, amely alapvetően a játékot játssza helyettünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 42.04,
  "end": 51.04
 },
 {
  "input": "Though I haven't done today's Wurdle, this is February 4th, and we'll see how the bot does.",
  "translatedText": "Bár a mai Wurdle-t még nem csináltam meg, ez február 4-e, és majd meglátjuk, hogyan teljesít a bot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 51.36,
  "end": 55.1
 },
 {
  "input": "The goal of Wurdle is to guess a mystery five letter word, and you're given six different chances to guess.",
  "translatedText": "A Wurdle célja, hogy kitalálj egy rejtélyes ötbetűs szót, és hat különböző esélyt kapsz a kitalálásra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 55.48,
  "end": 60.34
 },
 {
  "input": "For example, my Wurdle bot suggests that I start with the guess crane.",
  "translatedText": "A Wurdle botom például azt javasolja, hogy a kitaláló daruval kezdjem.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 60.84,
  "end": 64.38
 },
 {
  "input": "Each time that you make a guess, you get some information about how close your guess is to the true answer.",
  "translatedText": "Minden egyes alkalommal, amikor kitalálsz valamit, információt kapsz arról, hogy a tipped mennyire van közel a valódi válaszhoz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 65.18,
  "end": 70.22
 },
 {
  "input": "Here the grey box is telling me there's no C in the actual answer.",
  "translatedText": "Itt a szürke doboz azt mondja, hogy nincs C a tényleges válaszban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 70.92,
  "end": 74.1
 },
 {
  "input": "The yellow box is telling me there is an R, but it's not in that position.",
  "translatedText": "A sárga doboz azt mondja, hogy van egy R, de nincs abban a pozícióban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 74.52,
  "end": 77.84
 },
 {
  "input": "The green box is telling me that the secret word does have an A, and it's in the third position.",
  "translatedText": "A zöld doboz azt mondja, hogy a titkos szónak van egy A betűje, és a harmadik helyen áll.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 78.24,
  "end": 82.24
 },
 {
  "input": "And then there's no N and there's no E.",
  "translatedText": "És akkor nincs N és nincs E.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 82.72,
  "end": 84.58
 },
 {
  "input": "So let me just go in and tell the Wurdle bot that information.",
  "translatedText": "Szóval hadd menjek be és mondjam el ezt az információt a Wurdle botnak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 85.2,
  "end": 87.34
 },
 {
  "input": "We started with crane, we got grey, yellow, green, grey, grey.",
  "translatedText": "Daruval kezdtük, szürke, sárga, zöld, szürke, szürke, szürke.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.34,
  "end": 90.32
 },
 {
  "input": "Don't worry about all the data that it's showing right now, I'll explain that in due time.",
  "translatedText": "Ne aggódj az összes adat miatt, amit most mutat, majd időben elmagyarázom.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 91.42,
  "end": 94.94
 },
 {
  "input": "But its top suggestion for our second pick is shtick.",
  "translatedText": "De a második választásunk első számú javaslata a shtick.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 95.46,
  "end": 98.82
 },
 {
  "input": "And your guess does have to be an actual five letter word, but as you'll see, it's pretty liberal with what it will actually let you guess.",
  "translatedText": "És a találgatásodnak egy tényleges ötbetűs szónak kell lennie, de mint látni fogod, elég liberális, hogy mit enged kitalálni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 99.56,
  "end": 105.4
 },
 {
  "input": "In this case, we try shtick.",
  "translatedText": "Ebben az esetben megpróbáljuk a shtick-et.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 106.2,
  "end": 107.44
 },
 {
  "input": "And alright, things are looking pretty good.",
  "translatedText": "És rendben, a dolgok elég jól néznek ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 108.78,
  "end": 110.18
 },
 {
  "input": "We hit the S and the H, so we know the first three letters, we know that there's an R.",
  "translatedText": "Eltaláltuk az S-t és a H-t, tehát ismerjük az első három betűt, tudjuk, hogy van egy R.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 110.26,
  "end": 113.98
 },
 {
  "input": "And so it's going to be like S-H-A something R, or S-H-A R something.",
  "translatedText": "És így ez olyan lesz, mint S-H-A valami R, vagy S-H-A R valami.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 113.98,
  "end": 118.7
 },
 {
  "input": "And it looks like the Wurdle bot knows that it's down to just two possibilities, either shard or sharp.",
  "translatedText": "És úgy tűnik, hogy a Wurdle bot tudja, hogy csak két lehetőség van, vagy szilánk vagy éles.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 119.62,
  "end": 124.24
 },
 {
  "input": "That's kind of a tossup between them at this point, so I guess probably just because it's alphabetical it goes with shard.",
  "translatedText": "Ez egyfajta feldobás közöttük ezen a ponton, így azt hiszem, valószínűleg csak azért, mert ábécé sorrendben megy a shard.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 125.1,
  "end": 130.08
 },
 {
  "input": "Which hooray, is the actual answer, so we got it in three.",
  "translatedText": "Ami hurrá, ez a tényleges válasz, tehát háromban kaptuk meg.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.22,
  "end": 133.78
 },
 {
  "input": "If you're wondering if that's any good, the way I heard one person phrase it is that with Wurdle, four is par and three is birdie.",
  "translatedText": "Ha kíváncsi vagy, hogy ez jó-e, akkor úgy hallottam, hogy egy ember úgy fogalmazott, hogy Wurdle-nál négy a par és három a birdie.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 134.6,
  "end": 140.36
 },
 {
  "input": "Which I think is a pretty apt analogy.",
  "translatedText": "Ami szerintem elég találó hasonlat.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 140.68,
  "end": 142.48
 },
 {
  "input": "You have to be consistently on your game to be getting four, but it's certainly not crazy.",
  "translatedText": "Ahhoz, hogy négyet kapj, következetesen kell játszanod, de ez egyáltalán nem őrültség.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 142.48,
  "end": 147.02
 },
 {
  "input": "But when you get it in three, it just feels great.",
  "translatedText": "De amikor háromban kapod meg, az egyszerűen nagyszerű érzés.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 147.18,
  "end": 149.92
 },
 {
  "input": "So if you're down for it, what I'd like to do here is just talk through my thought process from the beginning for how I approach the Wurdle bot.",
  "translatedText": "Szóval, ha benne vagy, akkor azt szeretném, hogy beszéljünk a gondolatmenetemről a kezdetektől fogva, hogy hogyan közelítem meg a Wurdle botot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.88,
  "end": 155.96
 },
 {
  "input": "And like I said, really it's an excuse for an information theory lesson.",
  "translatedText": "És mint mondtam, ez valójában csak egy ürügy egy információelméleti leckére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 156.48,
  "end": 159.44
 },
 {
  "input": "The main goal is to explain what is information and what is entropy.",
  "translatedText": "A fő cél az, hogy elmagyarázzuk, mi az információ és mi az entrópia.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 159.74,
  "end": 162.82
 },
 {
  "input": "My first thought in approaching this was to take a look at the relative frequencies of different letters in the English language.",
  "translatedText": "Az első gondolatom az volt, hogy megnézzem a különböző betűk relatív gyakoriságát az angol nyelvben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 168.22,
  "end": 173.72
 },
 {
  "input": "So I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters?",
  "translatedText": "Ezért arra gondoltam, hogy van-e olyan nyitó tipp vagy tipppár, ami sok ilyen gyakori betűt eltalál?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 174.38,
  "end": 179.26
 },
 {
  "input": "And one that I was pretty fond of was doing other followed by nails.",
  "translatedText": "És az egyik, amit nagyon szerettem, az volt, hogy mást csináltam, amit a körmök követtek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.96,
  "end": 183.0
 },
 {
  "input": "The thought is that if you hit a letter, you know, you get a green or a yellow, that always feels good, it feels like you're getting information.",
  "translatedText": "Az a gondolat, hogy ha eltalálsz egy betűt, tudod, kapsz egy zöldet vagy egy sárgát, az mindig jó érzés, úgy érzed, hogy információt kapsz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 183.76,
  "end": 188.84
 },
 {
  "input": "But in these cases, even if you don't hit and you always get grays, that's still giving you a lot of information, since it's pretty rare to find a word that doesn't have any of these letters.",
  "translatedText": "De ezekben az esetekben, még ha nem is találsz, és mindig szürke betűket kapsz, ez akkor is sok információt ad, hiszen elég ritka az olyan szó, amelyben nem szerepelnek ezek a betűk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 189.34,
  "end": 197.4
 },
 {
  "input": "But even still, that doesn't feel super systematic, because for example, it does nothing to consider the order of the letters.",
  "translatedText": "De még ez sem tűnik szuper szisztematikusnak, mert például nem veszi figyelembe a betűk sorrendjét.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 198.14,
  "end": 203.2
 },
 {
  "input": "Why type nails when I could type snail?",
  "translatedText": "Miért írnék körmöket, ha írhatnék csigát is?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 203.56,
  "end": 205.3
 },
 {
  "input": "Is it better to have that S at the end?",
  "translatedText": "Jobb, ha az S betű a végén van?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 206.08,
  "end": 207.5
 },
 {
  "input": "I'm not really sure.",
  "translatedText": "Nem vagyok benne biztos.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 207.82,
  "end": 208.68
 },
 {
  "input": "Now, a friend of mine said that he liked to open with the word weary, which kind of surprised me because it has some uncommon letters in there like the W and the Y.",
  "translatedText": "Egy barátom azt mondta, hogy a fáradtság szóval szereti nyitni, ami meglepett, mert van benne néhány szokatlan betű, mint a W és az Y.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 209.24,
  "end": 216.54
 },
 {
  "input": "But who knows, maybe that is a better opener.",
  "translatedText": "De ki tudja, lehet, hogy ez egy jobb nyitány.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 217.12,
  "end": 219.0
 },
 {
  "input": "Is there some kind of quantitative score that we can give to judge the quality of a potential guess?",
  "translatedText": "Van valamilyen mennyiségi pontszám, amelyet megadhatunk a lehetséges tippek minőségének megítélésére?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 219.32,
  "end": 224.32
 },
 {
  "input": "Now to set up for the way that we're going to rank possible guesses, let's go back and add a little clarity to how exactly the game is set up.",
  "translatedText": "Most, hogy felkészüljünk arra, hogy hogyan fogjuk rangsorolni a lehetséges tippeket, menjünk vissza, és tisztázzuk egy kicsit, hogy pontosan hogyan is épül fel a játék.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 225.34,
  "end": 231.42
 },
 {
  "input": "So there's a list of words that it will allow you to enter that are considered valid guesses that's just about 13,000 words long.",
  "translatedText": "Tehát van egy lista a szavakról, amelyeket meg lehet adni, és amelyek érvényes találgatásnak számítanak, és amely körülbelül 13 000 szó hosszú.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 231.42,
  "end": 237.88
 },
 {
  "input": "But when you look at it, there's a lot of really uncommon things, things like a head or Ali and ARG, the kind of words that bring about family arguments in a game of Scrabble.",
  "translatedText": "De ha megnézed, egy csomó igazán szokatlan dolog van benne, olyanok, mint a fej vagy Ali és az ARG, olyan szavak, amelyek családi vitákat váltanak ki egy Scrabble-játékban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 238.32,
  "end": 246.44
 },
 {
  "input": "But the vibe of the game is that the answer is always going to be a decently common word.",
  "translatedText": "De a játék hangulata az, hogy a válasz mindig egy tisztességesen gyakori szó lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 246.96,
  "end": 250.54
 },
 {
  "input": "And in fact, there's another list of around 2300 words that are the possible answers.",
  "translatedText": "És valójában van egy másik lista, amely körülbelül 2300 szót tartalmaz, amelyek a lehetséges válaszok.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 250.96,
  "end": 255.36
 },
 {
  "input": "And this is a human curated list, I think specifically by the game creators girlfriend, which is kind of fun.",
  "translatedText": "És ez egy ember által összeállított lista, azt hiszem, kifejezetten a játékkészítők barátnője által, ami elég szórakoztató.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 255.94,
  "end": 261.16
 },
 {
  "input": "But what I would like to do, our challenge for this project is to see if we can write a program solving wordle that doesn't incorporate previous knowledge about this list.",
  "translatedText": "De amit szeretnék tenni, a kihívásunk a projektben az, hogy megnézzük, tudunk-e olyan wordle-t megoldó programot írni, amely nem foglalja magában a listáról való korábbi tudást.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 261.82,
  "end": 270.18
 },
 {
  "input": "For one thing, there's plenty of pretty common five letter words that you won't find in that list.",
  "translatedText": "Először is, rengeteg olyan gyakori ötbetűs szó van, amelyet nem találsz meg ezen a listán.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.72,
  "end": 274.64
 },
 {
  "input": "So it would be better to write a program that's a little more resilient and would play wordle against anyone, not just what happens to be the official website.",
  "translatedText": "Szóval jobb lenne egy olyan programot írni, ami egy kicsit rugalmasabb, és bárki ellen játszana wordle-t, nem csak ami történetesen a hivatalos honlapon van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 274.94,
  "end": 281.46
 },
 {
  "input": "And also, the reason that we know what this list of possible answers is, is because it's visible in the source code.",
  "translatedText": "És azért tudjuk, hogy mi ez a lehetséges válaszok listája, mert látható a forráskódban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.92,
  "end": 287.0
 },
 {
  "input": "But the way that it's visible in the source code is in the specific order in which answers come up from day to day, that you could always just look up what tomorrow's answer will be.",
  "translatedText": "De a forráskódban látható, hogy a válaszok napról-napra meghatározott sorrendben jelennek meg, hogy mindig megnézheted, mi lesz a holnapi válasz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 287.0,
  "end": 295.84
 },
 {
  "input": "So clearly, there's some sense in which using the list is cheating.",
  "translatedText": "Tehát nyilvánvaló, hogy a lista használata bizonyos értelemben csalásnak minősül.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 296.42,
  "end": 298.88
 },
 {
  "input": "And what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data like relative word frequencies in general to capture this intuition of having a preference for more common words.",
  "translatedText": "Érdekesebb rejtvényt és gazdagabb információelméleti leckét adna, ha ehelyett olyan univerzálisabb adatokat használnánk, mint például a relatív szófrekvenciák, hogy megragadjuk ezt az intuíciót, miszerint a gyakrabban használt szavakat előnyben részesítjük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 299.1,
  "end": 310.44
 },
 {
  "input": "So of these 13,000 possibilities, how should we choose the opening guess?",
  "translatedText": "Tehát ebből a 13 000 lehetőségből hogyan válasszuk ki a nyitó tippet?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 311.6,
  "end": 315.9
 },
 {
  "input": "For example, if my friend proposes weary, how should we analyze its quality?",
  "translatedText": "Ha például a barátom fáradtságot javasol, hogyan elemezzük annak minőségét?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 316.4,
  "end": 319.78
 },
 {
  "input": "Well, the reason he said he likes that unlikely W is that he likes the long shot nature of just how good it feels if you do hit that W.",
  "translatedText": "Nos, azért mondta, hogy szereti ezt a valószínűtlen W-t, mert szereti, hogy mennyire jó érzés, ha sikerül eltalálnod azt a W-t.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 320.52,
  "end": 327.34
 },
 {
  "input": "For example, if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern.",
  "translatedText": "Ha például az első felfedezett minta valami ilyesmi, akkor kiderül, hogy ebben a hatalmas lexikonban csak 58 olyan szó van, amely megfelel ennek a mintának.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 327.92,
  "end": 335.6
 },
 {
  "input": "So that's a huge reduction from 13,000.",
  "translatedText": "Ez tehát hatalmas csökkenés a 13 000-hez képest.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 336.06,
  "end": 338.4
 },
 {
  "input": "But the flip side of that, of course, is that it's very uncommon to get a pattern like this.",
  "translatedText": "De ennek persze az a másik oldala, hogy nagyon ritka az ilyen minta.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 338.78,
  "end": 343.02
 },
 {
  "input": "Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000.",
  "translatedText": "Pontosabban, ha minden szó egyforma valószínűséggel lenne a válasz, akkor a minta eltalálásának valószínűsége 58 osztva körülbelül 13 000-rel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 343.02,
  "end": 351.04
 },
 {
  "input": "Of course, they're not equally likely to be answers.",
  "translatedText": "Természetesen nem egyformán valószínű, hogy ezek a válaszok.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 351.58,
  "end": 353.6
 },
 {
  "input": "Most of these are very obscure and even questionable words.",
  "translatedText": "Ezek többsége nagyon homályos, sőt megkérdőjelezhető szavak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 353.72,
  "end": 356.22
 },
 {
  "input": "But at least for our first pass at all of this, let's assume that they're all equally likely and then refine that a bit later.",
  "translatedText": "De legalábbis az első körben feltételezzük, hogy mindegyik egyformán valószínű, és ezt később finomítsuk egy kicsit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 356.6,
  "end": 361.6
 },
 {
  "input": "The point is, the pattern with a lot of information is, by its very nature, unlikely to occur.",
  "translatedText": "A lényeg az, hogy a sok információval rendelkező minta természeténél fogva nem valószínű, hogy előfordul.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.02,
  "end": 366.72
 },
 {
  "input": "In fact, what it means to be informative is that it's unlikely.",
  "translatedText": "Valójában azt jelenti, hogy informatív, hogy valószínűtlen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 367.28,
  "end": 370.8
 },
 {
  "input": "A much more probable pattern to see with this opening would be something like this, where, of course, there's not a W in it.",
  "translatedText": "Sokkal valószínűbb, hogy valami ilyesmit látnánk ezzel a nyitással, ahol persze nincs benne W.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 371.72,
  "end": 378.12
 },
 {
  "input": "Maybe there's an E, and maybe there's no A, there's no R, there's no Y.",
  "translatedText": "Talán van egy E, és talán nincs A, nincs R, nincs Y.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 378.24,
  "end": 381.4
 },
 {
  "input": "In this case, there are 1400 possible matches.",
  "translatedText": "Ebben az esetben 1400 lehetséges találat van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 382.08,
  "end": 384.56
 },
 {
  "input": "If all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see.",
  "translatedText": "Ha mindegyik egyformán valószínű lenne, akkor körülbelül 11%-os valószínűséggel ez a mintázat lenne látható.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.08,
  "end": 390.6
 },
 {
  "input": "So the most likely outcomes are also the least informative.",
  "translatedText": "Tehát a legvalószínűbb eredmények egyben a legkevésbé informatívak is.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 390.9,
  "end": 393.34
 },
 {
  "input": "To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see.",
  "translatedText": "Hogy átfogó képet kapjunk, hadd mutassam meg a valószínűségek teljes eloszlását az összes különböző mintára, amit láthatunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 394.24,
  "end": 401.14
 },
 {
  "input": "So each bar that you're looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3 to the 5th possibilities, and they're organized from left to right, most common to least common.",
  "translatedText": "Tehát minden egyes sáv, amelyet nézel, megfelel a színek egy lehetséges mintázatának, amely feltárulhat, és amelyből 3-tól az 5. lehetőségig van, és balról jobbra vannak elrendezve, a leggyakoribbtól a legkevésbé gyakoriig.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 401.74,
  "end": 412.34
 },
 {
  "input": "So the most common possibility here is that you get all grays.",
  "translatedText": "Tehát a leggyakoribb lehetőség itt az, hogy minden szürke lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 412.92,
  "end": 416.0
 },
 {
  "input": "That happens about 14% of the time.",
  "translatedText": "Ez az esetek körülbelül 14%-ában fordul elő.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 416.1,
  "end": 418.12
 },
 {
  "input": "And what you're hoping for when you make a guess is that you end up somewhere out in this long tail, like over here, where there's only 18 possibilities for what matches this pattern, that evidently look like this.",
  "translatedText": "És azt reméljük, hogy amikor tippelünk, akkor valahol a hosszú farokban kötünk ki, például itt, ahol csak 18 lehetőség van arra, hogy mi felel meg ennek a mintának, ami nyilvánvalóan így néz ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.58,
  "end": 429.14
 },
 {
  "input": "Or if we venture a little farther to the left, you know, maybe we go all the way over here.",
  "translatedText": "Vagy ha egy kicsit balra merészkedünk, tudod, talán egészen idáig megyünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 429.92,
  "end": 433.8
 },
 {
  "input": "Okay, here's a good puzzle for you.",
  "translatedText": "Oké, itt egy jó kis rejtvény.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 434.94,
  "end": 436.18
 },
 {
  "input": "What are the three words in the English language that start with a W, end with a Y, and have an R somewhere in them?",
  "translatedText": "Melyik az a három szó az angol nyelvben, amely W-vel kezdődik, Y-nal végződik és valahol van benne egy R?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 436.54,
  "end": 442.0
 },
 {
  "input": "Turns out, the answers are, let's see, wordy, wormy, and wryly.",
  "translatedText": "Kiderült, hogy a válaszok, lássuk csak, szókimondó, kukacos és kukacos.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 442.48,
  "end": 446.8
 },
 {
  "input": "So to judge how good this word is overall, we want some kind of measure of the expected amount of information that you're going to get from this distribution.",
  "translatedText": "Tehát annak megítéléséhez, hogy mennyire jó ez a szó összességében, szükségünk van valamilyen mérőszámra, amely a várható információmennyiséget méri, amelyet ebből az eloszlásból kapunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 447.5,
  "end": 455.74
 },
 {
  "input": "If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score.",
  "translatedText": "Ha végigmegyünk minden egyes mintán, és megszorozzuk az előfordulási valószínűségét valamivel, ami azt méri, hogy mennyire informatív, akkor talán kaphatunk egy objektív pontszámot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 455.74,
  "end": 464.72
 },
 {
  "input": "Now your first instinct for what that something should be might be the number of matches.",
  "translatedText": "Most az első megérzésed, hogy mi legyen ez a valami, lehet, hogy a mérkőzések száma.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 465.96,
  "end": 469.84
 },
 {
  "input": "You want a lower average number of matches.",
  "translatedText": "Alacsonyabb átlagos mérkőzésszámot szeretne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 470.16,
  "end": 472.4
 },
 {
  "input": "But instead I'd like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they're actually the answer.",
  "translatedText": "Ehelyett azonban egy univerzálisabb mérőszámot szeretnék használni, amelyet gyakran tulajdonítunk az információnak, és amely rugalmasabb lesz, ha egyszer mind a 13 000 szóhoz különböző valószínűséggel rendeljük hozzá, hogy valóban a válasz-e vagy sem.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 472.8,
  "end": 484.26
 },
 {
  "input": "The standard unit of information is the bit, which has a little bit of a funny formula, but is really intuitive if we just look at examples.",
  "translatedText": "Az információ szabványos egysége a bit, amelynek egy kicsit furcsa képlete van, de igazán intuitív, ha csak példákat nézünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 490.32,
  "end": 496.98
 },
 {
  "input": "If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information.",
  "translatedText": "Ha van egy olyan megfigyelésünk, amely a lehetőségek terét a felére csökkenti, akkor azt mondjuk, hogy egy bit információval rendelkezik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 497.78,
  "end": 503.5
 },
 {
  "input": "In our example, the space of possibilities is all possible words, and it turns out about half of the five letter words have an S, a little less than that, but about half.",
  "translatedText": "A példánkban a lehetőségek tere az összes lehetséges szó, és kiderül, hogy az ötbetűs szavak körülbelül felében van egy S, kicsit kevesebb, de körülbelül a felében.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 504.18,
  "end": 511.26
 },
 {
  "input": "So that observation would give you one bit of information.",
  "translatedText": "Ez a megfigyelés tehát egy kis információt adna.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 511.78,
  "end": 514.32
 },
 {
  "input": "If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information.",
  "translatedText": "Ha ehelyett egy új tény négyszeresére csökkenti a lehetőségek számát, akkor azt mondjuk, hogy két bit információval rendelkezik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 514.88,
  "end": 521.5
 },
 {
  "input": "For example, it turns out about a quarter of these words have a T.",
  "translatedText": "Kiderült például, hogy ezeknek a szavaknak körülbelül egynegyedében van egy T betű.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.98,
  "end": 524.46
 },
 {
  "input": "If the observation cuts that space by a factor of eight, we say it's three bits of information, and so on and so forth.",
  "translatedText": "Ha a megfigyelés nyolcszorosára csökkenti ezt a helyet, akkor azt mondjuk, hogy ez három bit információ, és így tovább, és így tovább.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 525.02,
  "end": 530.72
 },
 {
  "input": "Four bits cuts it into a sixteenth, five bits cuts it into a thirty second.",
  "translatedText": "Négy bitből tizenhatod, öt bitből harminc másodperc lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 530.9,
  "end": 533.88
 },
 {
  "input": "So now's when you might want to take a moment and pause and ask for yourself, what is the formula for information for the number of bits in terms of the probability of an occurrence?",
  "translatedText": "Tehát most érdemes egy pillanatra megállni és megkérdezni magunktól, hogy mi a bitek számának információs képlete az előfordulás valószínűségének szempontjából?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 534.96,
  "end": 542.98
 },
 {
  "input": "Well, what we're saying here is basically that when you take one half to the number of bits, that's the same thing as the probability, which is the same thing as saying two to the power of the number of bits is one over the probability, which rearranges further to saying the information is the log base two of one divided by the probability.",
  "translatedText": "Nos, itt alapvetően azt mondjuk, hogy ha a bitek számának felét vesszük, akkor az ugyanaz, mint a valószínűség, ami ugyanaz, mintha azt mondanánk, hogy a bitek számának kétszeres hatványa egy a valószínűség felett, ami azt jelenti, hogy az információ az egynek a logaritmusa osztva a valószínűséggel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 543.92,
  "end": 558.92
 },
 {
  "input": "And sometimes you see this with one more rearrangement still where the information is the negative log base two of the probability.",
  "translatedText": "És néha ezt még egy átrendeződéssel is láthatjuk, ahol az információ a valószínűség negatív logaritmusának kettes bázisa.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 559.62,
  "end": 564.9
 },
 {
  "input": "Expressed like this, it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you've cut down your possibilities in half.",
  "translatedText": "Így kifejezve kicsit furcsának tűnhet a beavatatlanok számára, de valójában ez csak az a nagyon intuitív gondolat, hogy megkérdezzük, hányszor vágtuk felére a lehetőségeinket.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 565.66,
  "end": 574.08
 },
 {
  "input": "Now if you're wondering, you know, I thought we were just playing a fun word game, why are logarithms entering the picture?",
  "translatedText": "Ha most azon tűnődsz, tudod, azt hittem, hogy csak egy vicces szójátékot játszunk, miért kerülnek a képbe a logaritmusok?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 575.18,
  "end": 579.3
 },
 {
  "input": "One reason this is a nicer unit is it's just a lot easier to talk about very unlikely events, much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.0000095.",
  "translatedText": "Az egyik ok, amiért ez egy szebb egység, hogy sokkal könnyebb nagyon valószínűtlen eseményekről beszélni, sokkal könnyebb azt mondani, hogy egy megfigyelés 20 bit információval rendelkezik, mint azt, hogy az ilyen és ehhez hasonló események bekövetkezésének valószínűsége 0,0000095.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 579.78,
  "end": 592.94
 },
 {
  "input": "But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that information adds together.",
  "translatedText": "De egy sokkal lényegesebb ok, amiért ez a logaritmikus kifejezés nagyon hasznos kiegészítésnek bizonyult a valószínűségelmélethez, az az információ összeadásának módja.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 593.3,
  "end": 601.46
 },
 {
  "input": "For example, if one observation gives you two bits of information, cutting your space down by four, and then a second observation like your second guess in Wordle gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information.",
  "translatedText": "Például, ha egy megfigyelés két bit információt ad, ami négyszeresére csökkenti a helyet, majd egy második megfigyelés, például a Wordle-ben a második találgatásod további három bit információt ad, ami még nyolcszorosára csökkenti a helyet, akkor a kettő együtt öt bit információt ad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 602.06,
  "end": 616.74
 },
 {
  "input": "In the same way that probabilities like to multiply, information likes to add.",
  "translatedText": "Ahogy a valószínűségek szeretnek szorozni, úgy az információ is szeret összeadni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.16,
  "end": 621.02
 },
 {
  "input": "So as soon as we're in the realm of something like an expected value, where we're adding a bunch of numbers up, the logs make it a lot nicer to deal with.",
  "translatedText": "Tehát amint olyan dolgok birodalmába kerülünk, mint például egy várható érték, ahol egy csomó számot adunk össze, a naplók sokkal könnyebben kezelhetővé teszik a dolgot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 621.96,
  "end": 627.98
 },
 {
  "input": "Let's go back to our distribution for weary and add another little tracker on here, showing us how much information there is for each pattern.",
  "translatedText": "Menjünk vissza a fáradt eloszlásunkhoz, és adjunk hozzá egy másik kis nyomkövetőt, amely megmutatja, hogy mennyi információ van az egyes mintákhoz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 628.48,
  "end": 634.94
 },
 {
  "input": "The main thing I want you to notice is that the higher the probability as we get to those more likely patterns, the lower the information, the fewer bits you gain.",
  "translatedText": "A legfontosabb dolog, amit szeretném, ha észrevennétek, hogy minél nagyobb a valószínűség, ahogy eljutunk ezekhez a valószínűbb mintákhoz, annál kisebb az információ, annál kevesebb bitet kaptok.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 635.58,
  "end": 642.78
 },
 {
  "input": "The way we measure the quality of this guess will be to take the expected value of this information.",
  "translatedText": "Ennek a találgatásnak a minőségét úgy mérjük, hogy az információ várható értékét vesszük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 643.5,
  "end": 648.02
 },
 {
  "input": "When we go through each pattern, we say how probable is it and then we multiply that by how many bits of information do we get.",
  "translatedText": "Amikor végigmegyünk minden egyes mintán, megmondjuk, hogy mennyire valószínű, majd ezt megszorozzuk azzal, hogy hány bit információt kapunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 648.42,
  "end": 654.06
 },
 {
  "input": "And in the example of weary, that turns out to be 4.9 bits.",
  "translatedText": "A weary példájában ez 4,9 bit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 654.71,
  "end": 658.12
 },
 {
  "input": "So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times.",
  "translatedText": "Tehát átlagosan az ebből a nyitó tippből származó információ olyan jó, mintha a lehetőségek körét körülbelül ötször felére csökkentenéd.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 658.56,
  "end": 665.48
 },
 {
  "input": "By contrast, an example of a guess with a higher expected information value would be something like slate.",
  "translatedText": "Ezzel szemben a magasabb várható információértékkel rendelkező találgatásra példa lehet például a pala.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 665.96,
  "end": 671.64
 },
 {
  "input": "In this case, you'll notice the distribution looks a lot flatter.",
  "translatedText": "Ebben az esetben észreveheti, hogy az eloszlás sokkal laposabbnak tűnik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 673.12,
  "end": 675.62
 },
 {
  "input": "In particular, the most probable occurrence of all grays only has about a 6% chance of occurring, so at minimum you're getting evidently 3.9 bits of information.",
  "translatedText": "Különösen az összes szürke szín legvalószínűbb előfordulásának csak körülbelül 6% az esélye, így legalább 3,9 bitnyi információt kapunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 675.94,
  "end": 685.26
 },
 {
  "input": "But that's a minimum, more typically you'd get something better than that.",
  "translatedText": "De ez a minimum, ennél jellemzőbb, hogy ennél jobbat kapunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.92,
  "end": 688.56
 },
 {
  "input": "And it turns out when you crunch the numbers on this one and add up all the relevant terms, the average information is about 5.8.",
  "translatedText": "És kiderül, hogy ha összeszámoljuk a számokat, és összeadjuk az összes releváns kifejezést, az átlagos információ körülbelül 5,8.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 689.1,
  "end": 695.9
 },
 {
  "input": "So in contrast with weary, your space of possibilities will be about half as big after this first guess, on average.",
  "translatedText": "Tehát a fáradtakkal ellentétben a lehetőségek tere átlagosan fele akkora lesz az első találgatás után.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 697.36,
  "end": 703.54
 },
 {
  "input": "There's actually a fun story about the name for this expected value of information quantity.",
  "translatedText": "Az információmennyiség várható értékének elnevezéséhez valójában egy vicces történet fűződik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 704.42,
  "end": 708.3
 },
 {
  "input": "You see, information theory was developed by Claude Shannon, who was working at Bell Labs in the 1940s, but he was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, very prominent in math and physics and the beginnings of what was becoming computer science.",
  "translatedText": "Az információelméletet Claude Shannon dolgozta ki, aki az 1940-es években a Bell Labs-nél dolgozott, de néhány, még publikálásra váró ötletéről John von Neumann-nal beszélgetett, aki a kor szellemi óriása volt, aki a matematika és a fizika, valamint az informatika kezdeteinek kezdeteinél nagyon kiemelkedő volt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.3,
  "end": 723.56
 },
 {
  "input": "And when he mentioned that he didn't really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, well, you should call it entropy, and for two reasons.",
  "translatedText": "És amikor megemlítette, hogy nincs igazán jó neve erre az információmennyiség várható értékére, von Neumann állítólag azt mondta - így szól a történet -, nos, akkor nevezzük entrópiának, mégpedig két okból.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 724.1,
  "end": 734.2
 },
 {
  "input": "In the first place, your uncertainty function has been used in statistical mechanics under that name, so it already has a name, and in the second place, and more important, nobody knows what entropy really is, so in a debate you'll always have the advantage.",
  "translatedText": "Először is, a bizonytalansági függvényedet már használták a statisztikai mechanikában ezen a néven, tehát már van neve, másodszor pedig, ami még fontosabb, senki sem tudja, mi is az entrópia valójában, így egy vitában mindig te leszel előnyben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 734.54,
  "end": 746.76
 },
 {
  "input": "So if the name seems a little bit mysterious, and if this story is to be believed, that's kind of by design.",
  "translatedText": "Ha tehát a név egy kicsit titokzatosnak tűnik, és ha hinni lehet ennek a történetnek, akkor ez egyfajta szándékos.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 747.7,
  "end": 752.46
 },
 {
  "input": "Also if you're wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory, and for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess.",
  "translatedText": "Ha a fizikából a termodinamika második törvényével való kapcsolatára kíváncsiak, akkor határozottan van kapcsolat, de eredetileg Shannon csak a tiszta valószínűségelmélettel foglalkozott, és a mi céljainkra, amikor az entrópia szót használom, azt akarom, hogy egy adott találgatás várható információértékére gondoljanak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 753.28,
  "end": 769.58
 },
 {
  "input": "You can think of entropy as measuring two things simultaneously.",
  "translatedText": "Az entrópiára úgy is gondolhatunk, mint két dolog egyidejű mérésére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 770.7,
  "end": 773.78
 },
 {
  "input": "The first one is how flat is the distribution?",
  "translatedText": "Az első az, hogy mennyire lapos az eloszlás?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 774.24,
  "end": 776.78
 },
 {
  "input": "The closer a distribution is to uniform, the higher that entropy will be.",
  "translatedText": "Minél közelebb van egy eloszlás az egyenleteshez, annál nagyobb lesz az entrópia.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 777.32,
  "end": 781.12
 },
 {
  "input": "In our case, where there are 3 to the 5th total patterns, for a uniform distribution, observing any one of them would have information log base 2 of 3 to the 5th, which happens to be 7.92, so that is the absolute maximum that you could possibly have for this entropy.",
  "translatedText": "A mi esetünkben, ahol összesen 3-5 minta van, egy egyenletes eloszlás esetén bármelyik megfigyelése a 3-5 logaritmusának 2-es bázisát jelentené, ami történetesen 7,92, tehát ez az abszolút maximum, amit az entrópia esetében kaphatunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 781.58,
  "end": 797.3
 },
 {
  "input": "But entropy is also kind of a measure of how many possibilities there are in the first place.",
  "translatedText": "De az entrópia egyfajta mérőszáma annak is, hogy egyáltalán hány lehetőség van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 797.84,
  "end": 802.08
 },
 {
  "input": "For example, if you happen to have some word where there's only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be 4 bits.",
  "translatedText": "Ha például van egy olyan szó, amelyben csak 16 lehetséges minta van, és mindegyik egyformán valószínű, akkor ez az entrópia, ez a várható információ 4 bit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 802.32,
  "end": 812.18
 },
 {
  "input": "But if you have another word where there's 64 possible patterns that could come up, and they're all equally likely, then the entropy would work out to be 6 bits.",
  "translatedText": "De ha van egy másik szó, ahol 64 lehetséges minta jöhet létre, és mindegyik egyformán valószínű, akkor az entrópia 6 bit lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 812.58,
  "end": 820.48
 },
 {
  "input": "So if you see some distribution out in the wild that has an entropy of 6 bits, it's sort of like it's saying there's as much variation and uncertainty in what's about to happen as if there were 64 equally likely outcomes.",
  "translatedText": "Ha tehát a természetben olyan eloszlást látunk, amelynek entrópiája 6 bit, az olyan, mintha azt mondaná, hogy ugyanannyi variáció és bizonytalanság van abban, ami történni fog, mintha 64 egyformán valószínű kimenetel lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 821.5,
  "end": 833.5
 },
 {
  "input": "For my first pass at the Wurtelebot, I basically had it just do this.",
  "translatedText": "A Wurtelebot első átadásakor alapvetően csak ezt csináltam vele.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 834.36,
  "end": 837.96
 },
 {
  "input": "It goes through all of the different possible guesses that you could have, all 13,000 words, it computes the entropy for each one, or more specifically, the entropy of the distribution across all patterns that you might see for each one, and then it picks the highest, since that's the one that's likely to chop down your space of possibilities as much as possible.",
  "translatedText": "Végigmegy az összes lehetséges találgatáson, mind a 13 000 szón, kiszámítja mindegyiknek az entrópiáját, pontosabban az összes lehetséges minta eloszlásának entrópiáját, és kiválasztja a legmagasabbat, mivel ez az, amelyik a lehető legjobban lecsökkenti a lehetőségek számát.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 837.96,
  "end": 856.14
 },
 {
  "input": "And even though I've only been talking about the first guess here, it does the same thing for the next few guesses.",
  "translatedText": "És bár itt csak az első tippről beszéltem, ugyanezt teszi a következő tippeknél is.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 857.14,
  "end": 861.1
 },
 {
  "input": "For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words.",
  "translatedText": "Például miután az első találgatáson meglát valamilyen mintát, ami a lehetséges szavak kisebb számára korlátozná a lehetséges szavak számát az alapján, hogy mi egyezik ezzel, csak ugyanazt a játékot játssza a szavak kisebb halmaza tekintetében.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 861.56,
  "end": 871.8
 },
 {
  "input": "For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words, you search through all 13,000 possibilities, and you find the one that maximizes that entropy.",
  "translatedText": "A javasolt második találgatáshoz megnézzük az összes olyan minta eloszlását, amely a szavak szűkebb halmazából előfordulhat, átnézzük mind a 13 000 lehetőséget, és megtaláljuk azt, amelyik maximalizálja az entrópiát.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 872.26,
  "end": 883.84
 },
 {
  "input": "To show you how this works in action, let me just pull up a little variant of Wurtele that I wrote that shows the highlights of this analysis in the margins.",
  "translatedText": "Hogy megmutassam, hogyan működik ez a gyakorlatban, hadd mutassam meg Wurtele egy kis változatát, amit én írtam, és amely a margón mutatja az elemzés legfontosabb elemeit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 885.42,
  "end": 892.18
 },
 {
  "input": "So after doing all its entropy calculations, on the right here it's showing us which ones have the highest expected information.",
  "translatedText": "Tehát miután elvégezte az entrópia számításokat, itt jobbra megmutatja, hogy melyek azok, amelyek a legnagyobb várható információval rendelkeznek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 893.68,
  "end": 899.66
 },
 {
  "input": "Turns out the top answer, at least at the moment, we'll refine this later, is Tares, which means, um, of course, a vetch, the most common vetch.",
  "translatedText": "Kiderült, hogy a legjobb válasz, legalábbis jelenleg, ezt majd később pontosítjuk, a Tares, ami azt jelenti, hogy, öhm, persze, bükköny, a leggyakoribb bükköny.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 900.28,
  "end": 910.58
 },
 {
  "input": "Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had, but then on the right of the word here it's showing us how much actual information we got given this particular pattern.",
  "translatedText": "Minden egyes alkalommal, amikor itt tippelünk, ahol talán figyelmen kívül hagyom az ajánlásait, és a pala mellett döntök, mert szeretem a pala-t, láthatjuk, hogy mennyi várható információ volt, de aztán itt a szó jobb oldalán megmutatja, hogy mennyi tényleges információt kaptunk az adott mintát tekintve.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 911.04,
  "end": 924.42
 },
 {
  "input": "So here it looks like we were a little unlucky, we were expected to get 5.8, but we happened to get something with less than that.",
  "translatedText": "Szóval itt úgy néz ki, hogy egy kicsit pechesek voltunk, 5,8-as értéket vártunk, de történetesen ennél kevesebbel kaptunk valamit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 925.0,
  "end": 930.12
 },
 {
  "input": "And then on the left side here it's showing us all of the different possible words given where we are now.",
  "translatedText": "A bal oldalon pedig megmutatja az összes lehetséges szót, tekintve, hogy hol vagyunk most.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 930.6,
  "end": 935.02
 },
 {
  "input": "The blue bars are telling us how likely it thinks each word is, so at the moment it's assuming each word is equally likely to occur, but we'll refine that in a moment.",
  "translatedText": "A kék sávok azt mutatják, hogy az egyes szavak milyen valószínűséggel fordulnak elő, tehát jelenleg azt feltételezi, hogy minden szó egyforma valószínűséggel fordul elő, de ezt mindjárt finomítjuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 935.8,
  "end": 943.36
 },
 {
  "input": "And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it's a uniform distribution, is just a needlessly complicated way to count the number of possibilities.",
  "translatedText": "Ez a bizonytalansági mérés pedig a lehetséges szavak eloszlásának entrópiáját mutatja meg, ami jelenleg, mivel ez egy egyenletes eloszlás, csak egy szükségtelenül bonyolult módja a lehetőségek számának megszámlálására.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 944.06,
  "end": 955.96
 },
 {
  "input": "For example, if we were to take 2 to the power of 13.66, that should be around the 13,000 possibilities.",
  "translatedText": "Ha például a 2-t 13,66 hatványára emelnénk, akkor ez a 13 000 lehetőség körül lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 956.56,
  "end": 962.18
 },
 {
  "input": "Um, a little bit off here, but only because I'm not showing all the decimal places.",
  "translatedText": "Um, itt egy kicsit eltértem, de csak azért, mert nem mutatom az összes tizedesjegyet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 962.9,
  "end": 966.14
 },
 {
  "input": "At the moment that might feel redundant and like it's overly complicating things, but you'll see why it's useful to have both numbers in a minute.",
  "translatedText": "Jelenleg úgy tűnhet, hogy ez felesleges és túlságosan bonyolítja a dolgokat, de egy perc múlva látni fogod, miért hasznos, ha mindkét szám megvan.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 966.72,
  "end": 972.34
 },
 {
  "input": "So here it looks like it's suggesting the highest entropy for our second guess is Raman, which again just really doesn't feel like a word.",
  "translatedText": "Tehát itt úgy tűnik, hogy a második tippünkhöz a legmagasabb entrópiát a Raman jelöli, ami megint csak nem igazán tűnik szónak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 972.76,
  "end": 979.4
 },
 {
  "input": "So to take the moral high ground here I'm going to go ahead and type in Rains.",
  "translatedText": "Szóval, hogy erkölcsileg magasra tegyem a lécet, megyek előre és beírom Rains-t.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 979.98,
  "end": 984.06
 },
 {
  "input": "And again it looks like we were a little unlucky.",
  "translatedText": "És megint úgy tűnik, hogy egy kicsit pechesek voltunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 985.44,
  "end": 987.34
 },
 {
  "input": "We were expecting 4.3 bits and we only got 3.39 bits of information.",
  "translatedText": "Mi 4,3 bitet vártunk, és csak 3,39 bit információt kaptunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 987.52,
  "end": 991.36
 },
 {
  "input": "So that takes us down to 55 possibilities.",
  "translatedText": "Így már csak 55 lehetőségünk van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 991.94,
  "end": 993.94
 },
 {
  "input": "And here maybe I'll just actually go with what it's suggesting, which is combo, whatever that means.",
  "translatedText": "És itt talán tényleg csak azt fogom követni, amit sugall, ami a kombó, bármit is jelentsen ez.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 994.9,
  "end": 999.44
 },
 {
  "input": "And, okay, this is actually a good chance for a puzzle.",
  "translatedText": "És, oké, ez tulajdonképpen egy jó lehetőség egy rejtvényre.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1000.04,
  "end": 1002.92
 },
 {
  "input": "It's telling us this pattern gives us 4.7 bits of information.",
  "translatedText": "Azt mondja nekünk, hogy ez a minta 4,7 bit információt ad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1002.92,
  "end": 1006.38
 },
 {
  "input": "But over on the left, before we see that pattern, there were 5.78 bits of uncertainty.",
  "translatedText": "De a bal oldalon, mielőtt ezt a mintát látnánk, 5,78 bit bizonytalanság volt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1007.06,
  "end": 1011.72
 },
 {
  "input": "So as a quiz for you, what does that mean about the number of remaining possibilities?",
  "translatedText": "Tehát kvízkérdésként: mit jelent ez a fennmaradó lehetőségek számával kapcsolatban?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1012.42,
  "end": 1016.34
 },
 {
  "input": "Well it means that we're reduced down to 1 bit of uncertainty, which is the same thing as saying that there's 2 possible answers.",
  "translatedText": "Nos, ez azt jelenti, hogy 1 bizonytalansági tényezőre redukálódunk, ami ugyanaz, mintha azt mondanánk, hogy 2 lehetséges válasz van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1018.04,
  "end": 1024.54
 },
 {
  "input": "It's a 50-50 choice.",
  "translatedText": "Ez egy 50-50%-os választás.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1024.7,
  "end": 1025.7
 },
 {
  "input": "And from here, because you and I know which words are more common, we know that the answer should be abyss.",
  "translatedText": "És innen, mivel te és én tudjuk, hogy melyik szó a leggyakoribb, tudjuk, hogy a válasznak a mélységnek kell lennie.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1026.5,
  "end": 1030.64
 },
 {
  "input": "But as it's written right now, the program doesn't know that.",
  "translatedText": "De ahogyan most meg van írva, a program ezt nem tudja.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1031.18,
  "end": 1033.28
 },
 {
  "input": "So it just keeps going, trying to gain as much information as it can, until it's only one possibility left, and then it guesses it.",
  "translatedText": "Tehát csak megy tovább, megpróbál annyi információt szerezni, amennyit csak tud, amíg csak egy lehetőség marad, és akkor kitalálja azt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1033.54,
  "end": 1039.86
 },
 {
  "input": "So obviously we need a better endgame strategy, but let's say we call this version 1 of our wordle solver, and then we go and run some simulations to see how it does.",
  "translatedText": "Tehát nyilvánvalóan szükségünk van egy jobb végjáték-stratégiára, de mondjuk, hogy a wordle megoldónk 1. verziójának nevezzük el, majd lefuttatunk néhány szimulációt, hogy megnézzük, hogyan teljesít.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1040.38,
  "end": 1048.26
 },
 {
  "input": "So the way this is working is it's playing every possible wordle game.",
  "translatedText": "Tehát ez úgy működik, hogy minden lehetséges wordle játékot lejátszik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1050.36,
  "end": 1054.12
 },
 {
  "input": "It's going through all of those 2315 words that are the actual wordle answers.",
  "translatedText": "Végigmegy mindazon a 2315 szón, amelyek a tényleges wordle válaszok.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1054.24,
  "end": 1058.54
 },
 {
  "input": "It's basically using that as a testing set.",
  "translatedText": "Alapvetően ezt használja tesztkészletként.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1058.54,
  "end": 1060.58
 },
 {
  "input": "And with this naive method of not considering how common a word is, and just trying to maximize the information at each step along the way, until it gets down to one and only one choice.",
  "translatedText": "És ezzel a naiv módszerrel, amely nem veszi figyelembe, hogy egy szó mennyire gyakori, és csak megpróbálja maximalizálni az információt minden egyes lépésnél az út mentén, amíg le nem jut egy és csak egy választásig.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1061.36,
  "end": 1069.82
 },
 {
  "input": "By the end of the simulation, the average score works out to be about 4.124.",
  "translatedText": "A szimuláció végére az átlagos pontszám 4,124 körül alakul.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1070.36,
  "end": 1074.3
 },
 {
  "input": "Which is not bad, to be honest, I kind of expect it to do worse.",
  "translatedText": "Ami nem rossz, hogy őszinte legyek, én valahogy rosszabbra számítottam.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1075.32,
  "end": 1079.24
 },
 {
  "input": "But the people who play wordle will tell you that they can usually get it in 4.",
  "translatedText": "De azok, akik wordle-t játszanak, azt fogják mondani, hogy általában 4-ben is meg tudják csinálni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1079.66,
  "end": 1082.6
 },
 {
  "input": "The real challenge is to get as many in 3 as you can.",
  "translatedText": "Az igazi kihívás az, hogy minél többet szerezz 3-ban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1082.86,
  "end": 1085.38
 },
 {
  "input": "It's a pretty big jump between the score of 4 and the score of 3.",
  "translatedText": "Elég nagy ugrás a 4-es és a 3-as pontszám között.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1085.38,
  "end": 1088.08
 },
 {
  "input": "The obvious low-hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that.",
  "translatedText": "A nyilvánvalóan alacsonyan lógó gyümölcs itt az, hogy valahogy beépítsük, hogy egy szó gyakori-e vagy sem, és pontosan hogyan is csináljuk ezt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1088.86,
  "end": 1094.98
 },
 {
  "input": "The way I approached it is to get a list of the relative frequencies for all of the words in the English language, and I just used Mathematica's word frequency data function, which itself pulls from the Google Books English Ngram public dataset.",
  "translatedText": "Én úgy közelítettem meg a dolgot, hogy az angol nyelv összes szavának relatív gyakoriságát tartalmazó listát kaptam, és csak a Mathematica szógyakorisági adatfüggvényét használtam, amely maga is a Google Books English Ngram nyilvános adatkészletéből származik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1102.8,
  "end": 1114.86
 },
 {
  "input": "And it's kind of fun to look at, for example if we sort it from the most common words to the least common words.",
  "translatedText": "És elég szórakoztató megnézni, például ha a leggyakoribb szavaktól a legkevésbé gyakori szavakig rendezzük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1115.46,
  "end": 1119.96
 },
 {
  "input": "Evidently these are the most common, 5-letter words in the English language.",
  "translatedText": "Nyilvánvalóan ezek a leggyakoribb, 5 betűs szavak az angol nyelvben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1120.12,
  "end": 1123.08
 },
 {
  "input": "Or rather, these is the 8th most common.",
  "translatedText": "Vagy inkább ezek a 8. leggyakoribbak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1123.7,
  "end": 1125.84
 },
 {
  "input": "First is which, after which there's there and there.",
  "translatedText": "Az első az, ami, utána pedig az ott és az ott.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1126.28,
  "end": 1128.88
 },
 {
  "input": "First itself is not first, but 9th, and it makes sense that these other words could come about more often, where those after first are after, where, and those being just a little bit less common.",
  "translatedText": "Maga az első nem első, hanem 9., és van értelme, hogy ezek a többi szó gyakrabban fordulhat elő, ahol az első után az után, ahol, és azok csak egy kicsit ritkábban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1129.26,
  "end": 1138.58
 },
 {
  "input": "Now, in using this data to model how likely each of these words is to be the final answer, it shouldn't just be proportional to the frequency, because for example which is given a score of 0.002 in this dataset, whereas the word braid is in some sense about 1000 times less likely.",
  "translatedText": "Most, amikor ezeket az adatokat arra használjuk, hogy modellezzük, hogy az egyes szavak milyen valószínűséggel lesznek a végső válasz, nem csak a gyakorisággal kell arányosnak lennie, mert például a ami 0,002 pontot kap ebben az adathalmazban, míg a fonás szó bizonyos értelemben 1000-szer kisebb valószínűségű.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1139.16,
  "end": 1155.06
 },
 {
  "input": "But both of these are common enough words that they're almost certainly worth considering, so we want more of a binary cutoff.",
  "translatedText": "De mindkettő elég gyakori szó ahhoz, hogy szinte biztos, hogy érdemes figyelembe venni őket, ezért inkább bináris elválasztást szeretnénk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1155.56,
  "end": 1161.0
 },
 {
  "input": "The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it's either 0 or it's 1, but there's a smoothing in between for that region of uncertainty.",
  "translatedText": "Úgy jártam el, hogy elképzeltem, hogy veszem ezt az egész szavak rendezett listáját, majd elrendezem az x-tengelyen, és alkalmazom a szigmoid függvényt, ami a szokásos módja annak, hogy egy olyan függvényt kapjunk, amelynek kimenete alapvetően bináris, vagy 0, vagy 1, de van egy simítás a bizonytalansági tartományban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1161.86,
  "end": 1178.26
 },
 {
  "input": "So essentially, the probability that I'm assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis.",
  "translatedText": "Tehát lényegében az a valószínűség, amit az egyes szavakhoz rendelek, hogy a végső listán szerepeljenek, a szigmoid függvény értéke lesz, bárhol is helyezkedik el az x-tengelyen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1179.16,
  "end": 1188.44
 },
 {
  "input": "Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from 1 to 0, and where we situate them left to right determines the cutoff.",
  "translatedText": "Ez nyilvánvalóan függ néhány paramétertől, például attól, hogy az x-tengelyen milyen széles teret töltenek ki ezek a szavak, meghatározza, hogy mennyire fokozatosan vagy meredeken csökkenünk 1-től 0-ig, és hogy hol helyezzük el őket balról jobbra, meghatározza a határértéket.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1189.52,
  "end": 1202.14
 },
 {
  "input": "And to be honest the way I did this was kind of just licking my finger and sticking it into the wind.",
  "translatedText": "És hogy őszinte legyek, én ezt úgy csináltam, hogy megnyaltam az ujjam, és beledugtam a szélbe.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1202.98,
  "end": 1206.92
 },
 {
  "input": "I looked through the sorted list and tried to find a window where when I looked at it I figured about half of these words are more likely than not to be the final answer, and used that as the cutoff.",
  "translatedText": "Végignéztem a rendezett listát, és megpróbáltam megtalálni azt az ablakot, ahol, amikor ránéztem, úgy gondoltam, hogy ezeknek a szavaknak körülbelül a fele valószínűbb, mint hogy nem a végső válasz, és ezt használtam határértékként.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1207.14,
  "end": 1216.12
 },
 {
  "input": "Now once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement.",
  "translatedText": "Ha már van egy ilyen eloszlásunk a szavak között, akkor egy újabb helyzetet kapunk, ahol az entrópia igazán hasznos mérőeszközzé válik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1217.1,
  "end": 1223.86
 },
 {
  "input": "For example, let's say we were playing a game and we start with my old openers, which were other and nails, and we end up with a situation where there's four possible words that match it.",
  "translatedText": "Mondjuk, mondjuk, játszottunk egy játékot, és a régi nyitószavaimmal kezdünk, amelyek a más és a szögek voltak, és olyan helyzetbe kerülünk, ahol négy lehetséges szó is van, ami illik rá.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1224.5,
  "end": 1233.24
 },
 {
  "input": "And let's say we consider them all equally likely, let me ask you, what is the entropy of this distribution?",
  "translatedText": "És tegyük fel, hogy mindegyiket egyformán valószínűnek tartjuk, hadd kérdezzem meg, mekkora ennek az eloszlásnak az entrópiája?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1233.56,
  "end": 1238.88
 },
 {
  "input": "Well, the information associated with each one of these possibilities is going to be the log base 2 of 4, since each one is 1 and 4, and that's 2.",
  "translatedText": "Nos, a fenti lehetőségek mindegyikéhez tartozó információ a 4 logaritmikus bázisának 2-es bázisa lesz, mivel mindegyik 1 és 4, és ez 2.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1241.08,
  "end": 1250.26
 },
 {
  "input": "2 bits of information, 4 possibilities.",
  "translatedText": "2 bit információ, 4 lehetőség.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1250.64,
  "end": 1252.46
 },
 {
  "input": "All very well and good.",
  "translatedText": "Ez mind nagyon szép és jó.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1252.76,
  "end": 1253.58
 },
 {
  "input": "But what if I told you that actually there's more than 4 matches?",
  "translatedText": "De mi van, ha azt mondom, hogy valójában több mint 4 mérkőzés van?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1254.3,
  "end": 1257.8
 },
 {
  "input": "In reality, when we look through the full word list, there are 16 words that match it.",
  "translatedText": "A valóságban, ha végignézzük a teljes szólistát, 16 olyan szó van, amely megfelel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1258.26,
  "end": 1262.46
 },
 {
  "input": "But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like 1 in 1000 because they're really obscure.",
  "translatedText": "De tegyük fel, hogy a modellünk nagyon alacsony valószínűséggel teszi fel, hogy a másik 12 szó valóban a végső válasz lesz, körülbelül 1 az 1000-hez, mert ezek nagyon homályosak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1262.58,
  "end": 1270.76
 },
 {
  "input": "Now let me ask you, what is the entropy of this distribution?",
  "translatedText": "Most hadd kérdezzem meg, mekkora ennek az eloszlásnak az entrópiája?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1271.5,
  "end": 1274.26
 },
 {
  "input": "If entropy was purely measuring the number of matches here, then you might expect it to be something like the log base 2 of 16, which would be 4, two more bits of uncertainty than we had before.",
  "translatedText": "Ha az entrópia pusztán az egyezések számát mérné, akkor azt várhatnánk, hogy ez valami olyasmi, mint a 16 logbázis 2, ami 4, azaz kettővel több bit bizonytalanságot jelentene, mint korábban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1275.42,
  "end": 1285.7
 },
 {
  "input": "But of course the actual uncertainty is not really that different from what we had before.",
  "translatedText": "De természetesen a tényleges bizonytalanság nem sokban különbözik attól, ami korábban volt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1286.18,
  "end": 1289.86
 },
 {
  "input": "Just because there's these 12 really obscure words doesn't mean that it would be all that more surprising to learn that the final answer is charm, for example.",
  "translatedText": "Csak azért, mert van ez a 12 igazán homályos szó, még nem jelenti azt, hogy még meglepőbb lenne, ha megtudnánk, hogy a végső válasz például a báj.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1290.16,
  "end": 1297.36
 },
 {
  "input": "So when you actually do the calculation here and you add up the probability of each occurrence times the corresponding information, what you get is 2.11 bits.",
  "translatedText": "Ha tehát ténylegesen elvégezzük a számítást, és összeadjuk az egyes előfordulások valószínűségét és a megfelelő információt, akkor 2,11 bitet kapunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1298.18,
  "end": 1306.02
 },
 {
  "input": "Just saying, it's basically two bits, basically those four possibilities, but there's a little more uncertainty because of all of those highly unlikely events, though if you did learn them you'd get a ton of information from it.",
  "translatedText": "Csak azt mondom, hogy ez alapvetően két bit, alapvetően ez a négy lehetőség, de van egy kicsit több bizonytalanság a sok nagyon valószínűtlen esemény miatt, bár ha megtudnád őket, akkor rengeteg információt kapnál belőle.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1306.02,
  "end": 1316.5
 },
 {
  "input": "So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson.",
  "translatedText": "Szóval, ha kicsinyítünk, ez az, ami a Wordle-t olyan szép példává teszi egy információelméleti lecke számára.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1317.16,
  "end": 1321.4
 },
 {
  "input": "We have these two distinct feeling applications for entropy.",
  "translatedText": "Az entrópiának ez a két különböző érzésű alkalmazása van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1321.6,
  "end": 1324.64
 },
 {
  "input": "The first one telling us what's the expected information we'll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words we have possible.",
  "translatedText": "Az első azt mondja meg, hogy mi a várható információ, amit egy adott tippből kapunk, a második pedig azt, hogy meg tudjuk-e mérni a fennmaradó bizonytalanságot az összes lehetséges szó közül.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1325.16,
  "end": 1335.46
 },
 {
  "input": "And I should emphasize, in that first case where we're looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation.",
  "translatedText": "És hangsúlyoznom kell, hogy ebben az első esetben, amikor egy találgatás várható információját nézzük, ha a szavak súlyozása egyenlőtlen, az hatással van az entrópia számítására.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1336.46,
  "end": 1344.54
 },
 {
  "input": "For example, let me pull up that same case we were looking at earlier of the distribution associated with Weary, but this time using a non-uniform distribution across all possible words.",
  "translatedText": "Hadd vegyem például elő ugyanazt az esetet, amit korábban a Weary szóhoz kapcsolódó eloszlásról néztünk, de ezúttal nem egyenletes eloszlást használunk az összes lehetséges szóra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1344.98,
  "end": 1353.72
 },
 {
  "input": "So let me see if I can find a part here that illustrates it pretty well.",
  "translatedText": "Hadd nézzem, hátha találok itt egy részt, amely elég jól illusztrálja ezt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1354.5,
  "end": 1358.28
 },
 {
  "input": "Okay, here, this is pretty good.",
  "translatedText": "Oké, itt van, ez elég jó.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1360.94,
  "end": 1362.36
 },
 {
  "input": "Here we have two adjacent patterns that are about equally likely, but one of them we're told has 32 possible words that match it.",
  "translatedText": "Itt van két szomszédos minta, amelyek nagyjából egyforma valószínűségűek, de az egyiknek 32 lehetséges szó felel meg.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1362.36,
  "end": 1369.1
 },
 {
  "input": "And if we check what they are, these are those 32, which are all just very unlikely words as you scan your eyes over them.",
  "translatedText": "És ha megnézzük, hogy mik ezek, ez az a 32, amelyek mind csak nagyon valószínűtlen szavak, ahogy végigpásztázzuk a szemünket rajtuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1369.28,
  "end": 1375.6
 },
 {
  "input": "It's hard to find any that feel like plausible answers, maybe yells, but if we look at the neighboring pattern in the distribution, which is considered just about as likely, we're told that it only has 8 possible matches.",
  "translatedText": "Nehéz olyanokat találni, amelyek hihető válasznak tűnnek, esetleg kiabálnak, de ha megnézzük a szomszédos mintát az eloszlásban, amelyet éppen olyan valószínűnek tartanak, akkor azt mondják, hogy csak 8 lehetséges egyezése van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1375.84,
  "end": 1386.66
 },
 {
  "input": "So a quarter as many matches, but it's about as likely.",
  "translatedText": "Tehát negyedannyi meccs, de nagyjából ugyanannyi a valószínűsége.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1386.88,
  "end": 1389.52
 },
 {
  "input": "And when we pull up those matches, we can see why.",
  "translatedText": "És amikor elővesszük ezeket a mérkőzéseket, láthatjuk, hogy miért.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1389.86,
  "end": 1392.14
 },
 {
  "input": "Some of these are actual plausible answers like ring or wrath or raps.",
  "translatedText": "Ezek közül néhány valóban hihető válasz, mint a gyűrű, a harag vagy a rap.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1392.5,
  "end": 1396.3
 },
 {
  "input": "To illustrate how we incorporate all that, let me pull up version two of the Wordlebot here.",
  "translatedText": "Annak illusztrálására, hogy mindezt hogyan építjük be, hadd mutassam be a Wordlebot második verzióját.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1397.9,
  "end": 1402.3
 },
 {
  "input": "And there are two or three main differences from the first one that we saw.",
  "translatedText": "És van két-három fő különbség az elsőhöz képest, amit láttunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1402.56,
  "end": 1405.28
 },
 {
  "input": "First off, like I just said, the way that we're computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer.",
  "translatedText": "Először is, ahogy az imént említettem, az a mód, ahogyan ezeket az entrópiákat, az információ várható értékeit kiszámítjuk, most a mintákon belüli finomabb eloszlásokat használja, amelyek magukban foglalják annak valószínűségét, hogy egy adott szó valóban a válasz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1405.86,
  "end": 1418.24
 },
 {
  "input": "As it happens, tears is still number one, though the ones following are a bit different.",
  "translatedText": "Történetesen a könnyek még mindig az első helyen állnak, bár az utánuk következők kicsit másképp néznek ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1418.88,
  "end": 1423.82
 },
 {
  "input": "Second, when it ranks its top picks, it's now going to keep a model of the probability that each word is the actual answer, and it'll incorporate that into its decision, which is easier to see once we have a few guesses on the table.",
  "translatedText": "Másodszor, amikor rangsorolja a legjobb választásokat, akkor mostantól egy modellt fog vezetni arról a valószínűségről, hogy az egyes szavak a tényleges válaszok, és ezt beépíti a döntésébe, ami könnyebben látható, ha már van néhány találgatás az asztalon.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1424.36,
  "end": 1435.08
 },
 {
  "input": "Again, ignoring its recommendation because we can't let machines rule our lives.",
  "translatedText": "Ismét figyelmen kívül hagyva az ajánlását, mert nem hagyhatjuk, hogy gépek irányítsák az életünket.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1435.86,
  "end": 1439.78
 },
 {
  "input": "And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches.",
  "translatedText": "És azt hiszem, meg kell említenem egy másik dolgot, ami itt más, a bal oldalon, hogy a bizonytalansági érték, a bitek száma, már nem csak a lehetséges egyezések számának redundanciája.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1441.14,
  "end": 1449.64
 },
 {
  "input": "Now if we pull it up and calculate 2 to the 8.02, which would be a little above 256, I guess 259, what it's saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes.",
  "translatedText": "Ha most felhúzzuk és kiszámítjuk a 2-t a 8,02-hez, ami egy kicsit több mint 256, azt hiszem 259, akkor azt mondja, hogy bár összesen 526 szó van, ami ténylegesen megfelel ennek a mintának, a bizonytalanság mértéke inkább hasonlít ahhoz, ami akkor lenne, ha 259 egyformán valószínű kimenetel lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1450.08,
  "end": 1468.98
 },
 {
  "input": "You can think of it like this.",
  "translatedText": "Gondolhatod ezt így is.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1469.72,
  "end": 1470.74
 },
 {
  "input": "It knows borks is not the answer, same with yorts and zorl and zorus.",
  "translatedText": "Tudja, hogy a borks nem a válasz, ugyanúgy, mint a yorts, a zorl és a zorus.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1471.02,
  "end": 1474.66
 },
 {
  "input": "So it's a little less uncertain than it was in the previous case.",
  "translatedText": "Tehát ez egy kicsit kevésbé bizonytalan, mint az előző esetben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1474.66,
  "end": 1477.68
 },
 {
  "input": "This number of bits will be smaller.",
  "translatedText": "Ez a bitek száma kisebb lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1477.82,
  "end": 1479.28
 },
 {
  "input": "And if I keep playing the game, I'm refining this down with a couple guesses that are apropos of what I would like to explain here.",
  "translatedText": "És ha tovább játszom a játékot, akkor ezt finomítom le egy pár találgatással, ami apropója annak, amit itt szeretnék elmagyarázni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1480.22,
  "end": 1486.54
 },
 {
  "input": "By the fourth guess, if you look over at its top picks, you can see it's no longer just maximizing the entropy.",
  "translatedText": "A negyedik tippnél, ha megnézzük a legjobb tippjeit, láthatjuk, hogy már nem csak az entrópiát maximalizálja.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1488.36,
  "end": 1493.76
 },
 {
  "input": "So at this point, there's technically seven possibilities, but the only ones with a meaningful chance are dorms and words.",
  "translatedText": "Tehát jelenleg technikailag hét lehetőség van, de az egyetlenek, amelyeknek érdemi esélye van, a kollégiumok és a szavak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1494.46,
  "end": 1500.3
 },
 {
  "input": "And you can see it ranks choosing both of those above all of these other values that strictly speaking would give more information.",
  "translatedText": "És láthatod, hogy mindkettőt az összes többi érték fölé helyezi, amelyek szigorúan véve több információt adnának.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1500.3,
  "end": 1506.72
 },
 {
  "input": "The very first time I did this, I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect.",
  "translatedText": "Az első alkalommal, amikor ezt csináltam, csak összeadtam ezt a két számot, hogy mérjem az egyes tippek minőségét, ami jobban működött, mint ahogy azt gyanítanád.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1507.24,
  "end": 1513.9
 },
 {
  "input": "But it really didn't feel systematic.",
  "translatedText": "De tényleg nem éreztem szisztematikusnak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1514.3,
  "end": 1515.9
 },
 {
  "input": "And I'm sure there's other approaches people could take.",
  "translatedText": "És biztos vagyok benne, hogy az emberek más megközelítéseket is alkalmazhatnának.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1516.1,
  "end": 1517.88
 },
 {
  "input": "But here's the one I landed on.",
  "translatedText": "De itt van az, amelyikre rátaláltam.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1517.9,
  "end": 1519.34
 },
 {
  "input": "If we're considering the prospect of a next guess, like in this case words, what we really care about is the expected score of our game if we do that.",
  "translatedText": "Ha a következő tippelés lehetőségét mérlegeljük, mint ebben az esetben a szavakat, akkor az érdekel minket, hogy milyen várható pontszámot érünk el, ha ezt tesszük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1519.76,
  "end": 1527.9
 },
 {
  "input": "And to calculate that expected score, we say what's the probability that words is the actual answer, which at the moment it describes 58% to.",
  "translatedText": "És hogy kiszámítsuk ezt a várható pontszámot, azt mondjuk, hogy mi a valószínűsége annak, hogy a szavak a tényleges válasz, ami jelenleg 58% -ra írja le.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1528.23,
  "end": 1535.9
 },
 {
  "input": "We say with a 58% chance, our score in this game would be four.",
  "translatedText": "Azt mondjuk, hogy 58%-os eséllyel a mi pontszámunk ebben a játékban négy lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1536.04,
  "end": 1539.54
 },
 {
  "input": "And then with the probability of one minus that 58%, our score will be more than that four.",
  "translatedText": "És akkor az egy mínusz 58%-os valószínűséggel a pontszámunk több lesz, mint a négy.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1540.32,
  "end": 1545.64
 },
 {
  "input": "How much more we don't know, but we can estimate it based on how much uncertainty there's likely to be once we get to that point.",
  "translatedText": "Hogy mennyivel több, azt nem tudjuk, de meg tudjuk becsülni az alapján, hogy mennyi bizonytalanság valószínűsíthető, ha egyszer eljutunk odáig.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1546.22,
  "end": 1552.46
 },
 {
  "input": "Specifically, at the moment, there's 1.44 bits of uncertainty.",
  "translatedText": "Pontosabban, jelenleg 1,44 bit bizonytalanság van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1552.96,
  "end": 1555.94
 },
 {
  "input": "If we guess words, it's telling us the expected information we'll get is 1.27 bits.",
  "translatedText": "Ha szavakat tippelünk, akkor azt mondja, hogy a várható információ, amit kapunk, 1,27 bit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1556.44,
  "end": 1561.12
 },
 {
  "input": "So if we guess words, this difference represents how much uncertainty we're likely to be left with after that happens.",
  "translatedText": "Ha tehát szavakat találgatunk, akkor ez a különbség azt jelzi, hogy mekkora bizonytalanságot hagyunk magunk után, miután ez megtörtént.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1561.62,
  "end": 1567.66
 },
 {
  "input": "What we need is some kind of function, which I'm calling f here, that associates this uncertainty with an expected score.",
  "translatedText": "Szükségünk van valamilyen függvényre, amit itt f-nek nevezek, amely ezt a bizonytalanságot egy várható pontszámhoz társítja.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1568.26,
  "end": 1573.74
 },
 {
  "input": "And the way it went about this was to just plot a bunch of the data from previous games based on version one of the bot to say, hey, what was the actual score after various points with certain very measurable amounts of uncertainty?",
  "translatedText": "És a mód, ahogyan ezt csinálta, az volt, hogy a bot első verziója alapján egy csomó adatot ábrázolt a korábbi játékokból, hogy megmondja, hé, mi volt a tényleges pontszám különböző pontok után, bizonyos nagyon jól mérhető bizonytalansággal?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1574.24,
  "end": 1586.32
 },
 {
  "input": "For example, these data points here that are sitting above a value that's around like 8.7 or so are saying for some games, after a point at which there were 8.7 bits of uncertainty, it took two guesses to get the final answer.",
  "translatedText": "Például ezek az adatpontok itt, amelyek egy 8,7 körüli érték felett vannak, azt jelentik, hogy néhány játék esetében egy olyan pont után, ahol 8,7 bit bizonytalanság volt, két találgatásra volt szükség a végső válaszhoz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1587.02,
  "end": 1598.96
 },
 {
  "input": "For other games, it took three guesses.",
  "translatedText": "Más játékok esetében három találgatásra volt szükség.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1599.32,
  "end": 1600.66
 },
 {
  "input": "For other games, it took four guesses.",
  "translatedText": "Más játékoknál négy találgatás kellett.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1600.82,
  "end": 1602.24
 },
 {
  "input": "If we shift over to the left here, all the points over zero are saying whenever there's zero bits of uncertainty, which is to say there's only one possibility, then the number of guesses required is always just one, which is reassuring.",
  "translatedText": "Ha itt balra toljuk, a nulla feletti pontok azt mondják, hogy amikor nulla bit bizonytalanság van, vagyis csak egy lehetőség van, akkor a szükséges találgatások száma mindig csak egy, ami megnyugtató.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1603.14,
  "end": 1614.26
 },
 {
  "input": "Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess, sometimes it required two more guesses, and so on and so forth here.",
  "translatedText": "Amikor csak egy kis bizonytalanság volt, vagyis lényegében csak két lehetőség volt, akkor néha még egy találgatásra volt szükség, néha még két találgatásra, és így tovább, és így tovább.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1614.78,
  "end": 1625.24
 },
 {
  "input": "Maybe a slightly easier way to visualize this data is to bucket it together and take averages.",
  "translatedText": "Talán egy kicsit egyszerűbb módja az adatok megjelenítésének, ha összevonjuk őket, és átlagokat veszünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1625.74,
  "end": 1630.22
 },
 {
  "input": "For example, this bar here is saying among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.5.",
  "translatedText": "Például ez a sáv itt azt mutatja, hogy az összes olyan pont közül, ahol egy kis bizonytalanság volt, átlagosan körülbelül 1,5 új találgatásra volt szükség.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1631.0,
  "end": 1639.96
 },
 {
  "input": "And the bar over here is saying among all of the different games where at some point the uncertainty was a little above four bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward.",
  "translatedText": "A sáv itt azt mutatja, hogy az összes olyan játék közül, ahol a bizonytalanság valamikor valamivel több mint négy bit volt, ami azt jelenti, hogy 16 különböző lehetőségre szűkítettük le a kört, átlagosan valamivel több mint két találgatásra van szükség attól a ponttól kezdve.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1642.14,
  "end": 1655.38
 },
 {
  "input": "And from here I just did a regression to fit a function that seemed reasonable to this.",
  "translatedText": "És innen csak egy regressziót csináltam, hogy illeszkedjen egy olyan függvényhez, amely ésszerűnek tűnt ehhez.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1656.06,
  "end": 1659.46
 },
 {
  "input": "And remember, the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be.",
  "translatedText": "És ne feledjük, hogy mindez azért van, hogy számszerűsíteni tudjuk azt az intuíciót, hogy minél több információt nyerünk egy szóból, annál alacsonyabb lesz a várható pontszám.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1659.98,
  "end": 1668.96
 },
 {
  "input": "So, with this as version 2.0, if we go back and run the same set of simulations, having it play against all 2315 possible wordle answers, how does it do?",
  "translatedText": "Tehát, ezzel a 2.0-s verzióval, ha visszamegyünk, és lefuttatjuk ugyanazt a szimulációt, és mind a 2315 lehetséges wordle-válasz ellen játszunk, hogyan teljesít?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1669.68,
  "end": 1679.24
 },
 {
  "input": "Well in contrast to our first version, it's definitely better, which is reassuring.",
  "translatedText": "Nos, az első verzióhoz képest határozottan jobb, ami megnyugtató.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1680.28,
  "end": 1683.42
 },
 {
  "input": "All said and done, the average is around 3.6.",
  "translatedText": "Mindent összevetve, az átlag 3,6 körül van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1684.02,
  "end": 1686.18
 },
 {
  "input": "Although unlike the first version, there are a couple times that it loses, and requires more than six in this circumstance.",
  "translatedText": "Bár az első változattal ellentétben van egy párszor, hogy veszít, és hatnál többet igényel ebben a helyzetben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1686.54,
  "end": 1692.12
 },
 {
  "input": "Presumably because there's times when it's making that tradeoff to actually go for the goal rather than maximizing information.",
  "translatedText": "Feltehetően azért, mert van, amikor az információ maximalizálása helyett inkább a cél elérése érdekében kell kompromisszumot kötni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1692.64,
  "end": 1697.94
 },
 {
  "input": "So can we do better than 3.6?",
  "translatedText": "Szóval, tudunk-e jobbat nyújtani 3,6-nál?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1699.04,
  "end": 1701.0
 },
 {
  "input": "We definitely can.",
  "translatedText": "Határozottan megtehetjük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1702.08,
  "end": 1702.92
 },
 {
  "input": "Now, I said at the start that it's most fun to try not incorporating the true list of wordle answers into the way that it builds its model.",
  "translatedText": "Nos, az elején azt mondtam, hogy a legszórakoztatóbb, ha megpróbáljuk nem beépíteni a wordle válaszok valódi listáját abba, ahogyan a modelljét felépíti.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1703.28,
  "end": 1709.36
 },
 {
  "input": "But if we do incorporate it, the best performance I could get was around 3.43.",
  "translatedText": "De ha mégis beépítjük, a legjobb teljesítmény, amit kaptam, 3,43 körül volt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1709.88,
  "end": 1714.18
 },
 {
  "input": "So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.43 probably gives a max at how good we could get with that, or at least how good I could get with that.",
  "translatedText": "Tehát ha megpróbálunk kifinomultabbak lenni annál, minthogy csak a szógyakorisági adatokat használjuk az előzetes eloszlás kiválasztásához, akkor ez a 3,43 valószínűleg megadja a maximumot arra, hogy milyen jót tudnánk elérni ezzel, vagy legalábbis, hogy én milyen jót tudnék elérni ezzel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1715.16,
  "end": 1725.74
 },
 {
  "input": "That best performance essentially just uses the ideas that I've been talking about here, but it goes a little farther, like it does a search for the expected information two steps forward rather than just one.",
  "translatedText": "Ez a legjobb teljesítmény lényegében csak azokat az ötleteket használja, amelyekről itt beszéltem, de egy kicsit tovább megy, például a várt információ keresése két lépéssel előre, nem pedig csak eggyel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1726.24,
  "end": 1735.12
 },
 {
  "input": "Originally I was planning on talking more about that, but I realize we've actually gone quite long as it is.",
  "translatedText": "Eredetileg azt terveztem, hogy többet beszélek erről, de rájöttem, hogy már így is elég hosszúra nyúltunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1735.62,
  "end": 1740.22
 },
 {
  "input": "The one thing I'll say is after doing this two-step search and then running a couple sample simulations in the top candidates, so far for me at least, it's looking like Crane is the best opener.",
  "translatedText": "Az egyetlen dolog, amit mondhatok, hogy miután elvégeztem ezt a kétlépcsős keresést, majd lefuttattam néhány mintaszimulációt a csúcsjelölteknél, eddig legalábbis számomra úgy tűnik, hogy Crane a legjobb nyitó.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1740.58,
  "end": 1749.1
 },
 {
  "input": "Who would have guessed?",
  "translatedText": "Ki gondolta volna?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1749.1,
  "end": 1750.06
 },
 {
  "input": "Also if you use the true wordle list to determine your space of possibilities, then the uncertainty you start with is a little over 11 bits.",
  "translatedText": "Ha a valódi wordle-listát használod a lehetőségek körének meghatározásához, akkor a bizonytalanság, amivel indulsz, valamivel több mint 11 bit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1750.92,
  "end": 1757.82
 },
 {
  "input": "And it turns out just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits.",
  "translatedText": "És kiderül, hogy a nyers erővel végzett keresés alapján az első két találgatás után a maximális várható információ 10 bit körül van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1758.3,
  "end": 1765.88
 },
 {
  "input": "Which suggests that best case scenario, after your first two guesses, with perfectly optimal play, you'll be left with around one bit of uncertainty.",
  "translatedText": "Ami azt sugallja, hogy a legjobb esetben az első két találgatás után, tökéletesen optimális játék mellett, körülbelül egy bitnyi bizonytalanság marad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1766.5,
  "end": 1774.56
 },
 {
  "input": "Which is the same as being down to two possible guesses.",
  "translatedText": "Ami ugyanaz, mintha csak két lehetséges tipp lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1774.8,
  "end": 1777.32
 },
 {
  "input": "But I think it's fair and probably pretty conservative to say that you could never possibly write an algorithm that gets this average as low as three, because with the words available to you, there's simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.",
  "translatedText": "De azt hiszem, tisztességes és valószínűleg elég konzervatív azt mondani, hogy soha nem lehet olyan algoritmust írni, amely ezt az átlagot háromra csökkenti, mert a rendelkezésre álló szavakkal egyszerűen nincs elég hely ahhoz, hogy két lépés után elegendő információt kapjunk ahhoz, hogy a harmadik résben minden egyes alkalommal garantálni tudjuk a választ.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1777.74,
  "end": 1793.36
 }
]