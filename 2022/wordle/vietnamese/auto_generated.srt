1
00:00:00,000 --> 00:00:03,302
Trò chơi Wurdle đã lan truyền khá rộng rãi trong một hoặc hai tháng qua

2
00:00:03,302 --> 00:00:06,605
và không bao giờ người ta bỏ qua cơ hội học toán, tôi chợt nhận ra rằng

3
00:00:06,605 --> 00:00:09,862
trò chơi này là một ví dụ trung tâm rất hay trong bài học về lý thuyết

4
00:00:09,862 --> 00:00:13,120
thông tin và đặc biệt là trò chơi này. một chủ đề được gọi là entropy.

5
00:00:13,120 --> 00:00:16,480
Bạn thấy đấy, giống như nhiều người, tôi bị cuốn hút vào câu đố, và

6
00:00:16,480 --> 00:00:19,938
giống như nhiều lập trình viên, tôi cũng bị cuốn hút vào việc cố gắng

7
00:00:19,938 --> 00:00:23,200
viết một thuật toán để chơi trò chơi một cách tối ưu nhất có thể.

8
00:00:23,200 --> 00:00:26,129
Và điều tôi nghĩ tôi sẽ làm ở đây chỉ là trao đổi với bạn một số

9
00:00:26,129 --> 00:00:28,969
quy trình của tôi trong đó và giải thích một số phép toán liên

10
00:00:28,969 --> 00:00:32,080
quan đến nó, vì toàn bộ thuật toán tập trung vào ý tưởng về entropy.

11
00:00:32,080 --> 00:00:42,180
Trước hết, trong trường hợp bạn chưa từng nghe đến nó, Wurdle là gì?

12
00:00:42,180 --> 00:00:45,151
Và để một mũi tên trúng hai con chim ở đây trong khi chúng ta đi qua các

13
00:00:45,151 --> 00:00:48,245
quy tắc của trò chơi, hãy để tôi xem trước chúng ta sẽ đi đâu với điều này,

14
00:00:48,245 --> 00:00:51,380
đó là phát triển một thuật toán nhỏ về cơ bản sẽ chơi trò chơi cho chúng ta.

15
00:00:51,380 --> 00:00:53,585
Mặc dù tôi chưa thực hiện Wurdle của ngày hôm nay nhưng đây là

16
00:00:53,585 --> 00:00:55,860
ngày 4 tháng 2 và chúng ta sẽ xem con bot hoạt động như thế nào.

17
00:00:55,860 --> 00:00:58,333
Mục tiêu của Wurdle là đoán một từ có năm chữ

18
00:00:58,333 --> 00:01:00,860
cái bí ẩn và bạn có sáu cơ hội đoán khác nhau.

19
00:01:00,860 --> 00:01:05,240
Ví dụ: bot Wurdle của tôi gợi ý rằng tôi nên bắt đầu với cần cẩu đoán.

20
00:01:05,240 --> 00:01:07,990
Mỗi lần bạn đoán, bạn sẽ nhận được một số thông tin về

21
00:01:07,990 --> 00:01:10,940
mức độ gần đúng của suy đoán của bạn với câu trả lời đúng.

22
00:01:10,940 --> 00:01:14,540
Ở đây, hộp màu xám cho tôi biết rằng không có chữ C trong câu trả lời thực tế.

23
00:01:14,540 --> 00:01:18,340
Ô màu vàng cho tôi biết có chữ R, nhưng nó không ở vị trí đó.

24
00:01:18,340 --> 00:01:22,820
Ô màu xanh lá cây cho tôi biết từ bí mật có chữ A và nó ở vị trí thứ ba.

25
00:01:22,820 --> 00:01:24,300
Và rồi không có N và không có E.

26
00:01:24,300 --> 00:01:27,420
Vì vậy, hãy để tôi vào và nói với bot Wurdle thông tin đó.

27
00:01:27,420 --> 00:01:31,500
Chúng tôi bắt đầu với cần cẩu, chúng tôi có màu xám, vàng, xanh lá cây, xám, xám.

28
00:01:31,500 --> 00:01:33,411
Đừng lo lắng về tất cả dữ liệu mà nó đang hiển thị ngay

29
00:01:33,411 --> 00:01:35,460
bây giờ, tôi sẽ giải thích điều đó vào thời điểm thích hợp.

30
00:01:35,460 --> 00:01:39,700
Nhưng gợi ý hàng đầu cho lựa chọn thứ hai của chúng tôi thật tồi tệ.

31
00:01:39,700 --> 00:01:42,678
Và dự đoán của bạn thực sự phải là một từ có năm chữ cái, nhưng như

32
00:01:42,678 --> 00:01:45,700
bạn sẽ thấy, nó khá tự do với những gì nó thực sự cho phép bạn đoán.

33
00:01:45,700 --> 00:01:48,860
Trong trường hợp này, chúng tôi thử shtick.

34
00:01:48,860 --> 00:01:50,260
Và được rồi, mọi thứ có vẻ khá tốt.

35
00:01:50,260 --> 00:01:52,375
Chúng ta nhấn chữ S và chữ H, nên chúng ta biết

36
00:01:52,375 --> 00:01:54,580
ba chữ cái đầu tiên, chúng ta biết rằng có chữ R.

37
00:01:54,580 --> 00:01:59,740
Và vì vậy nó sẽ giống như SHA gì đó R, hoặc SHA R gì đó.

38
00:01:59,740 --> 00:02:05,220
Và có vẻ như bot Wurdle biết rằng chỉ có hai khả năng, mảnh vỡ hoặc sắc nét.

39
00:02:05,220 --> 00:02:08,138
Vào thời điểm này, có một sự xung đột giữa chúng, vì vậy tôi đoán có lẽ

40
00:02:08,138 --> 00:02:11,260
chỉ vì nó được sắp xếp theo thứ tự bảng chữ cái nên nó đi kèm với phân đoạn.

41
00:02:11,260 --> 00:02:13,000
Hoan hô, là câu trả lời thực tế.

42
00:02:13,000 --> 00:02:14,660
Vì vậy, chúng tôi đã nhận được nó trong ba.

43
00:02:14,660 --> 00:02:17,764
Nếu bạn đang thắc mắc liệu điều đó có tốt không, thì theo cách

44
00:02:17,764 --> 00:02:20,820
tôi nghe một người nói thì Wurdle bốn là par và ba là birdie.

45
00:02:20,820 --> 00:02:22,960
Mà tôi nghĩ là một sự tương tự khá thích hợp.

46
00:02:22,960 --> 00:02:25,177
Bạn phải kiên trì trong trò chơi của mình để đạt được

47
00:02:25,177 --> 00:02:27,560
bốn điểm, nhưng điều đó chắc chắn không điên rồ chút nào.

48
00:02:27,560 --> 00:02:30,000
Nhưng khi bạn nhận được nó trong ba, nó sẽ cảm thấy tuyệt vời.

49
00:02:30,000 --> 00:02:33,253
Vì vậy, nếu bạn không hài lòng, điều tôi muốn làm ở đây chỉ là nói về

50
00:02:33,253 --> 00:02:36,600
quá trình suy nghĩ của tôi ngay từ đầu về cách tôi tiếp cận bot Wurdle.

51
00:02:36,600 --> 00:02:39,800
Và như tôi đã nói, thực ra đó chỉ là cái cớ để học lý thuyết thông tin.

52
00:02:39,800 --> 00:02:43,160
Mục tiêu chính là giải thích thông tin là gì và entropy là gì.

53
00:02:43,160 --> 00:02:48,402
Suy nghĩ đầu tiên của tôi khi tiếp cận vấn đề này là xem xét

54
00:02:48,402 --> 00:02:53,560
tần số tương đối của các chữ cái khác nhau trong tiếng Anh.

55
00:02:53,560 --> 00:02:56,711
Vì vậy, tôi nghĩ, được thôi, có một lần đoán mở đầu hoặc một cặp

56
00:02:56,711 --> 00:02:59,960
đoán mở đầu nào chạm được nhiều chữ cái thường gặp nhất này không?

57
00:02:59,960 --> 00:03:03,780
Và một việc mà tôi khá thích là làm những việc khác sau đó là làm móng.

58
00:03:03,780 --> 00:03:05,803
Ý nghĩ là nếu bạn nhấn vào một chữ cái, bạn biết đấy, bạn sẽ nhận

59
00:03:05,803 --> 00:03:07,980
được màu xanh lá cây hoặc màu vàng, điều đó luôn tạo cảm giác dễ chịu.

60
00:03:07,980 --> 00:03:09,460
Có cảm giác như bạn đang nhận được thông tin.

61
00:03:09,460 --> 00:03:12,077
Nhưng trong những trường hợp này, ngay cả khi bạn không đánh và

62
00:03:12,077 --> 00:03:14,736
luôn có màu xám, điều đó vẫn cung cấp cho bạn nhiều thông tin vì

63
00:03:14,736 --> 00:03:17,640
rất hiếm khi tìm thấy một từ không có bất kỳ chữ cái nào trong số này.

64
00:03:17,640 --> 00:03:20,602
Nhưng dù vậy, điều đó vẫn không mang lại cảm giác siêu hệ thống,

65
00:03:20,602 --> 00:03:23,520
vì chẳng hạn, nó không liên quan gì đến thứ tự của các chữ cái.

66
00:03:23,520 --> 00:03:26,080
Tại sao phải gõ móng tay khi tôi có thể gõ ốc?

67
00:03:26,080 --> 00:03:27,720
Có chữ S ở cuối thì tốt hơn phải không?

68
00:03:27,720 --> 00:03:28,720
Tôi không thực sự chắc chắn.

69
00:03:28,720 --> 00:03:32,859
Một người bạn của tôi nói rằng anh ấy thích mở đầu bằng từ mệt mỏi, điều này

70
00:03:32,859 --> 00:03:37,160
làm tôi khá ngạc nhiên vì trong đó có một số chữ cái không phổ biến như W và Y.

71
00:03:37,160 --> 00:03:39,400
Nhưng ai biết được, có lẽ đó là cách mở đầu tốt hơn.

72
00:03:39,400 --> 00:03:42,184
Có loại điểm định lượng nào đó mà chúng ta có thể đưa ra

73
00:03:42,184 --> 00:03:44,920
để đánh giá chất lượng của một dự đoán tiềm năng không?

74
00:03:44,920 --> 00:03:48,407
Bây giờ để thiết lập cách chúng ta sắp xếp các dự đoán có thể xảy ra, hãy

75
00:03:48,407 --> 00:03:51,800
quay lại và thêm một chút rõ ràng về cách thiết lập chính xác trò chơi.

76
00:03:51,800 --> 00:03:54,860
Vì vậy, có một danh sách các từ mà nó sẽ cho phép bạn nhập

77
00:03:54,860 --> 00:03:57,920
được coi là những từ đoán hợp lệ chỉ dài khoảng 13.000 từ.

78
00:03:57,920 --> 00:04:02,351
Nhưng khi bạn nhìn vào nó, có rất nhiều thứ thực sự không phổ biến, những thứ như cái

79
00:04:02,351 --> 00:04:06,524
đầu hay Ali và ARG, những loại từ gây ra tranh cãi trong gia đình trong trò chơi

80
00:04:06,524 --> 00:04:07,040
Scrabble.

81
00:04:07,040 --> 00:04:10,600
Nhưng điều thú vị của trò chơi là câu trả lời luôn là một từ khá phổ biến.

82
00:04:10,600 --> 00:04:16,080
Và trên thực tế, có một danh sách khác khoảng 2300 từ có thể là câu trả lời.

83
00:04:16,080 --> 00:04:18,918
Và đây là danh sách do con người tuyển chọn, tôi nghĩ cụ thể là do

84
00:04:18,918 --> 00:04:21,800
bạn gái của người sáng tạo trò chơi thực hiện, điều này khá thú vị.

85
00:04:21,800 --> 00:04:24,712
Nhưng điều tôi muốn làm, thách thức của chúng tôi đối với dự án

86
00:04:24,712 --> 00:04:27,761
này là xem liệu chúng tôi có thể viết một chương trình giải Wordle

87
00:04:27,761 --> 00:04:30,720
mà không kết hợp kiến thức trước đây về danh sách này hay không.

88
00:04:30,720 --> 00:04:33,187
Có một điều, có rất nhiều từ có năm chữ cái khá phổ

89
00:04:33,187 --> 00:04:35,560
biến mà bạn sẽ không tìm thấy trong danh sách đó.

90
00:04:35,560 --> 00:04:38,839
Vì vậy, sẽ tốt hơn nếu viết một chương trình linh hoạt hơn một chút và có thể chơi

91
00:04:38,839 --> 00:04:41,960
Wordle với bất kỳ ai, chứ không chỉ những gì xảy ra trên trang web chính thức.

92
00:04:41,960 --> 00:04:44,618
Và lý do mà chúng tôi biết danh sách các câu trả

93
00:04:44,618 --> 00:04:47,440
lời có thể có này là vì nó hiển thị trong mã nguồn.

94
00:04:47,440 --> 00:04:50,166
Nhưng cách nó hiển thị trong mã nguồn lại theo thứ

95
00:04:50,166 --> 00:04:52,840
tự cụ thể mà các câu trả lời xuất hiện hàng ngày.

96
00:04:52,840 --> 00:04:56,400
Vì vậy, bạn luôn có thể tra cứu xem câu trả lời của ngày mai sẽ là gì.

97
00:04:56,400 --> 00:04:59,140
Vì vậy, rõ ràng là việc sử dụng danh sách là gian lận.

98
00:04:59,140 --> 00:05:03,306
Và điều tạo nên một câu đố thú vị hơn và một bài học lý thuyết thông tin phong

99
00:05:03,306 --> 00:05:07,367
phú hơn là thay vào đó hãy sử dụng một số dữ liệu phổ quát hơn như tần số từ

100
00:05:07,367 --> 00:05:11,640
tương đối nói chung để nắm bắt trực giác về việc ưa thích những từ phổ biến hơn.

101
00:05:11,640 --> 00:05:16,560
Vậy trong 13.000 khả năng này, chúng ta nên chọn dự đoán mở đầu như thế nào?

102
00:05:16,560 --> 00:05:18,311
Ví dụ, nếu bạn tôi đề xuất một cách mệt mỏi, chúng

103
00:05:18,311 --> 00:05:19,960
ta nên phân tích chất lượng của nó như thế nào?

104
00:05:19,960 --> 00:05:23,749
Chà, lý do anh ấy nói rằng anh ấy thích chữ W không chắc chắn đó là vì anh ấy

105
00:05:23,749 --> 00:05:27,880
thích bản chất bắn xa của cảm giác tuyệt vời như thế nào nếu bạn đánh được chữ W đó.

106
00:05:27,880 --> 00:05:31,847
Ví dụ: nếu mẫu đầu tiên được tiết lộ giống như thế này, thì

107
00:05:31,847 --> 00:05:36,080
hóa ra chỉ có 58 từ trong từ điển khổng lồ này khớp với mẫu đó.

108
00:05:36,080 --> 00:05:38,900
Vì vậy, đó là một mức giảm rất lớn từ 13.000.

109
00:05:38,900 --> 00:05:43,320
Nhưng mặt trái của điều đó, tất nhiên, là rất hiếm khi có được một mẫu như thế này.

110
00:05:43,320 --> 00:05:47,500
Cụ thể, nếu mỗi từ có khả năng là câu trả lời như nhau thì

111
00:05:47,500 --> 00:05:51,680
xác suất đạt được mẫu này sẽ là 58 chia cho khoảng 13.000.

112
00:05:51,680 --> 00:05:53,880
Tất nhiên, chúng không có khả năng là câu trả lời như nhau.

113
00:05:53,880 --> 00:05:56,680
Hầu hết trong số này là những từ rất mơ hồ và thậm chí có vấn đề.

114
00:05:56,680 --> 00:05:59,360
Nhưng ít nhất trong lần đầu tiên chúng ta vượt qua tất cả những điều này, hãy giả sử

115
00:05:59,360 --> 00:06:02,040
rằng chúng đều có khả năng xảy ra như nhau và sau đó tinh chỉnh điều đó một lát sau.

116
00:06:02,040 --> 00:06:07,360
Vấn đề là mô hình có nhiều thông tin về bản chất khó có thể xảy ra.

117
00:06:07,360 --> 00:06:11,320
Trên thực tế, ý nghĩa của việc cung cấp nhiều thông tin là điều đó khó có thể xảy ra.

118
00:06:11,320 --> 00:06:14,869
Một mô hình có nhiều khả năng xảy ra hơn với phần mở đầu này

119
00:06:14,869 --> 00:06:18,360
sẽ giống như thế này, tất nhiên là không có chữ W trong đó.

120
00:06:18,360 --> 00:06:22,080
Có thể có chữ E, và có thể không có chữ A, không có chữ R, không có chữ Y.

121
00:06:22,080 --> 00:06:24,640
Trong trường hợp này, có 1400 kết quả phù hợp.

122
00:06:24,640 --> 00:06:27,597
Nếu tất cả đều có khả năng như nhau thì có xác

123
00:06:27,597 --> 00:06:30,680
suất khoảng 11% rằng đây là mô hình bạn sẽ thấy.

124
00:06:30,680 --> 00:06:34,320
Vì vậy, những kết quả có thể xảy ra nhất cũng có ít thông tin nhất.

125
00:06:34,320 --> 00:06:38,160
Để có cái nhìn toàn diện hơn ở đây, hãy để tôi chỉ cho bạn sự phân bổ

126
00:06:38,160 --> 00:06:42,000
đầy đủ các xác suất trên tất cả các mẫu khác nhau mà bạn có thể thấy.

127
00:06:42,000 --> 00:06:45,672
Vì vậy, mỗi thanh bạn đang xem tương ứng với một mẫu màu có thể

128
00:06:45,672 --> 00:06:49,344
được tiết lộ, trong đó có từ 3 đến khả năng thứ 5 và chúng được

129
00:06:49,344 --> 00:06:52,960
sắp xếp từ trái sang phải, phổ biến nhất đến ít phổ biến nhất.

130
00:06:52,960 --> 00:06:56,200
Vì vậy, khả năng phổ biến nhất ở đây là bạn có toàn màu xám.

131
00:06:56,200 --> 00:06:58,800
Điều đó xảy ra khoảng 14% thời gian.

132
00:06:58,800 --> 00:07:02,469
Và điều bạn hy vọng khi bạn đoán là bạn sẽ kết thúc ở một nơi nào

133
00:07:02,469 --> 00:07:06,194
đó trong cái đuôi dài này, giống như ở đây, nơi chỉ có 18 khả năng

134
00:07:06,194 --> 00:07:09,920
cho những gì phù hợp với mô hình này mà rõ ràng trông như thế này.

135
00:07:09,920 --> 00:07:12,000
Hoặc nếu chúng ta mạo hiểm xa hơn một chút về phía bên trái,

136
00:07:12,000 --> 00:07:14,080
bạn biết đấy, có thể chúng ta sẽ đi hết quãng đường tới đây.

137
00:07:14,080 --> 00:07:16,560
Được rồi, đây là một câu đố hay dành cho bạn.

138
00:07:16,560 --> 00:07:19,383
Ba từ trong tiếng Anh bắt đầu bằng chữ W, kết thúc

139
00:07:19,383 --> 00:07:22,040
bằng chữ Y và có chữ R ở đâu đó trong đó là gì?

140
00:07:22,040 --> 00:07:27,560
Hóa ra, câu trả lời là, hãy xem, dài dòng, sâu sắc và gượng gạo.

141
00:07:27,560 --> 00:07:31,640
Vì vậy, để đánh giá mức độ tốt của từ này nói chung, chúng tôi muốn có một số

142
00:07:31,640 --> 00:07:35,720
thước đo về lượng thông tin mong đợi mà bạn sẽ nhận được từ sự phân phối này.

143
00:07:35,720 --> 00:07:40,676
Nếu chúng ta xem xét từng mẫu và nhân xác suất xảy ra của nó với thứ gì đó để đo

144
00:07:40,676 --> 00:07:46,000
lường mức độ thông tin của nó, thì điều đó có thể cho chúng ta một điểm số khách quan.

145
00:07:46,000 --> 00:07:50,280
Bây giờ, bản năng đầu tiên của bạn về điều gì đó có thể là số lượng trận đấu.

146
00:07:50,280 --> 00:07:52,960
Bạn muốn số lượng trận đấu trung bình thấp hơn.

147
00:07:52,960 --> 00:07:56,630
Nhưng thay vào đó, tôi muốn sử dụng một phép đo phổ quát hơn mà chúng ta thường gán

148
00:07:56,630 --> 00:08:00,431
cho thông tin, và một phép đo sẽ linh hoạt hơn khi chúng ta gán một xác suất khác nhau

149
00:08:00,431 --> 00:08:04,320
cho mỗi từ trong số 13.000 từ này để xem liệu chúng có thực sự là câu trả lời hay không.

150
00:08:04,320 --> 00:08:11,060
Đơn vị thông tin tiêu chuẩn là bit, có công thức hơi buồn cười,

151
00:08:11,060 --> 00:08:17,800
nhưng nó thực sự trực quan nếu chúng ta chỉ nhìn vào các ví dụ.

152
00:08:17,800 --> 00:08:21,080
Nếu bạn có một quan sát làm giảm một nửa không gian khả năng

153
00:08:21,080 --> 00:08:24,200
của bạn, thì chúng tôi nói rằng nó có một chút thông tin.

154
00:08:24,200 --> 00:08:26,614
Trong ví dụ của chúng tôi, không gian của các khả năng là tất

155
00:08:26,614 --> 00:08:29,028
cả các từ có thể, và hóa ra khoảng Một nửa trong số các từ có

156
00:08:29,028 --> 00:08:31,560
năm chữ cái có chữ S, ít hơn thế một chút, nhưng khoảng một nửa.

157
00:08:31,560 --> 00:08:35,200
Vì vậy, quan sát đó sẽ cung cấp cho bạn một chút thông tin.

158
00:08:35,200 --> 00:08:38,600
Thay vào đó, nếu một sự kiện mới cắt giảm không gian khả năng

159
00:08:38,600 --> 00:08:42,000
đó đi bốn lần, thì chúng ta nói rằng nó có hai bit thông tin.

160
00:08:42,000 --> 00:08:45,120
Ví dụ, hóa ra khoảng một phần tư những từ này có chữ T.

161
00:08:45,120 --> 00:08:50,920
Nếu sự quan sát cắt không gian đó đi tám lần, chúng ta nói đó là ba bit thông tin, v.v.

162
00:08:50,920 --> 00:08:55,000
Bốn bit cắt nó thành phần 16, năm bit cắt nó thành phần 32.

163
00:08:55,000 --> 00:08:59,933
Vì vậy, bây giờ bạn có thể muốn tạm dừng và tự hỏi, công

164
00:08:59,933 --> 00:09:04,520
thức thông tin về số bit theo xác suất xảy ra là gì?

165
00:09:04,520 --> 00:09:09,404
Điều chúng tôi đang nói ở đây là khi bạn lấy một nửa số bit, thì nó bằng với

166
00:09:09,404 --> 00:09:14,288
xác suất, cũng giống như nói hai lũy thừa của số bit bằng một trên xác suất,

167
00:09:14,288 --> 00:09:19,680
tức là sắp xếp lại để nói rằng thông tin là log cơ số hai của một chia cho xác suất.

168
00:09:19,680 --> 00:09:22,789
Và đôi khi bạn thấy điều này với một sự sắp xếp lại nữa,

169
00:09:22,789 --> 00:09:25,680
trong đó thông tin là log âm cơ số hai của xác suất.

170
00:09:25,680 --> 00:09:28,696
Diễn đạt như thế này, nó có thể trông hơi kỳ lạ đối với những

171
00:09:28,696 --> 00:09:31,713
người chưa quen, nhưng thực sự đó chỉ là một ý tưởng rất trực

172
00:09:31,713 --> 00:09:35,120
quan khi hỏi bạn đã cắt giảm một nửa khả năng của mình bao nhiêu lần.

173
00:09:35,120 --> 00:09:37,567
Bây giờ nếu bạn đang thắc mắc, bạn biết đấy, tôi nghĩ chúng ta chỉ đang chơi

174
00:09:37,567 --> 00:09:39,920
một trò chơi chữ vui nhộn, tại sao logarit lại xuất hiện trong bức tranh?

175
00:09:39,920 --> 00:09:44,386
Một lý do khiến đây là một đơn vị đẹp hơn là vì nó dễ dàng hơn rất nhiều khi nói về

176
00:09:44,386 --> 00:09:48,853
những sự kiện rất khó xảy ra, dễ dàng hơn nhiều khi nói rằng một quan sát có 20 bit

177
00:09:48,853 --> 00:09:53,480
thông tin so với việc nói rằng xác suất xảy ra điều đó và điều đó xảy ra là 0.0000095.

178
00:09:53,480 --> 00:09:57,766
Nhưng một lý do thực chất hơn khiến biểu thức logarit này hóa ra lại là một sự bổ

179
00:09:57,766 --> 00:10:02,000
sung rất hữu ích cho lý thuyết xác suất là cách các thông tin cộng lại với nhau.

180
00:10:02,000 --> 00:10:05,789
Ví dụ: nếu một quan sát cung cấp cho bạn hai bit thông tin, cắt giảm không

181
00:10:05,789 --> 00:10:09,578
gian của bạn xuống còn bốn, và sau đó quan sát thứ hai như dự đoán thứ hai

182
00:10:09,578 --> 00:10:13,418
của bạn trong Wordle sẽ cung cấp cho bạn ba bit thông tin khác, cắt nhỏ hơn

183
00:10:13,418 --> 00:10:17,360
nữa theo hệ số tám khác, thì cả hai cùng nhau cung cấp cho bạn năm thông tin.

184
00:10:17,360 --> 00:10:21,200
Cũng giống như cách xác suất muốn nhân lên, thông tin cũng thích cộng thêm.

185
00:10:21,200 --> 00:10:24,973
Vì vậy, ngay khi chúng ta ở trong phạm vi của một thứ gì đó giống như giá trị kỳ vọng,

186
00:10:24,973 --> 00:10:28,660
nơi chúng ta cộng một loạt các số, nhật ký sẽ giúp việc xử lý dễ dàng hơn rất nhiều.

187
00:10:28,660 --> 00:10:32,179
Hãy quay lại bản phân phối của chúng tôi cho Weary và thêm một công cụ theo

188
00:10:32,179 --> 00:10:35,560
dõi nhỏ khác vào đây, cho chúng tôi biết lượng thông tin có cho mỗi mẫu.

189
00:10:35,560 --> 00:10:39,403
Điều chính mà tôi muốn bạn chú ý là xác suất chúng ta đạt được những mẫu có

190
00:10:39,403 --> 00:10:43,500
nhiều khả năng đó càng cao thì thông tin càng thấp thì bạn thu được càng ít bit.

191
00:10:43,500 --> 00:10:47,298
Cách chúng tôi đo lường chất lượng của dự đoán này là lấy giá trị kỳ vọng của thông tin

192
00:10:47,298 --> 00:10:51,054
này, trong đó chúng tôi xem xét từng mẫu, chúng tôi cho biết khả năng xảy ra của nó là

193
00:10:51,054 --> 00:10:54,940
bao nhiêu và sau đó chúng tôi nhân giá trị đó với số lượng thông tin chúng tôi nhận được.

194
00:10:54,940 --> 00:10:58,480
Và trong ví dụ của Weary, kết quả là 4.9 bit.

195
00:10:58,480 --> 00:11:02,095
Vì vậy, trung bình, thông tin bạn nhận được từ lần đoán mở đầu này cũng

196
00:11:02,095 --> 00:11:05,660
tốt như việc cắt đôi không gian khả năng của bạn trong khoảng năm lần.

197
00:11:05,660 --> 00:11:09,208
Ngược lại, một ví dụ về phỏng đoán có giá trị

198
00:11:09,208 --> 00:11:13,220
thông tin được mong đợi cao hơn sẽ giống như Slate.

199
00:11:13,220 --> 00:11:16,180
Trong trường hợp này bạn sẽ nhận thấy sự phân bố trông phẳng hơn rất nhiều.

200
00:11:16,180 --> 00:11:21,091
Đặc biệt, khả năng xuất hiện nhiều nhất của tất cả các màu xám chỉ có khoảng

201
00:11:21,091 --> 00:11:25,940
6% khả năng xảy ra, vì vậy rõ ràng bạn nhận được ít nhất 3.9 bit thông tin.

202
00:11:25,940 --> 00:11:29,140
Nhưng đó chỉ là mức tối thiểu, thông thường bạn sẽ nhận được thứ gì đó tốt hơn thế.

203
00:11:29,140 --> 00:11:32,780
Và hóa ra là khi bạn tính toán các con số trên đây và cộng tất cả

204
00:11:32,780 --> 00:11:36,420
các số hạng có liên quan, thông tin trung bình là khoảng 5. số 8.

205
00:11:36,420 --> 00:11:40,307
Vì vậy, trái ngược với Weary, trung bình không gian khả năng

206
00:11:40,307 --> 00:11:43,940
của bạn sẽ lớn khoảng một nửa sau lần đoán đầu tiên này.

207
00:11:43,940 --> 00:11:49,540
Thực sự có một câu chuyện thú vị về tên của giá trị kỳ vọng của lượng thông tin này.

208
00:11:49,540 --> 00:11:53,083
Lý thuyết thông tin được phát triển bởi Claude Shannon, người đang làm việc

209
00:11:53,083 --> 00:11:56,766
tại Bell Labs vào những năm 1940, nhưng ông ấy đang nói về một số ý tưởng chưa

210
00:11:56,766 --> 00:12:00,450
được công bố của mình với John von Neumann, một trí tuệ khổng lồ vào thời điểm

211
00:12:00,450 --> 00:12:04,180
đó, rất nổi bật. trong toán học và vật lý và sự khởi đầu của khoa học máy tính.

212
00:12:04,180 --> 00:12:07,627
Và khi anh ấy đề cập rằng anh ấy thực sự không có một cái tên hay cho

213
00:12:07,627 --> 00:12:11,223
giá trị kỳ vọng của lượng thông tin này, von Neumann được cho là đã nói,

214
00:12:11,223 --> 00:12:14,720
vì vậy câu chuyện diễn ra, bạn nên gọi nó là entropy, và vì hai lý do.

215
00:12:14,720 --> 00:12:18,708
Đầu tiên, hàm bất định của bạn đã được sử dụng trong cơ học thống kê dưới cái

216
00:12:18,708 --> 00:12:22,542
tên đó, nên nó đã có tên rồi, và thứ hai, và quan trọng hơn, không ai biết

217
00:12:22,542 --> 00:12:26,940
entropy thực sự là gì, vì vậy trong một cuộc tranh luận, bạn sẽ luôn luôn có lợi thế.

218
00:12:26,940 --> 00:12:30,112
Vì vậy, nếu cái tên có vẻ hơi bí ẩn và nếu câu

219
00:12:30,112 --> 00:12:33,420
chuyện này được tin tưởng thì đó là do thiết kế.

220
00:12:33,420 --> 00:12:36,808
Ngoài ra, nếu bạn đang thắc mắc về mối quan hệ của nó với tất cả các định

221
00:12:36,808 --> 00:12:40,242
luật thứ hai của nhiệt động lực học trong vật lý, thì chắc chắn có một mối

222
00:12:40,242 --> 00:12:43,585
liên hệ, nhưng về nguồn gốc của nó, Shannon chỉ xử lý lý thuyết xác suất

223
00:12:43,585 --> 00:12:46,973
thuần túy, và vì mục đích của chúng ta ở đây, khi tôi sử dụng từ entropy,

224
00:12:46,973 --> 00:12:50,820
tôi chỉ muốn bạn nghĩ đến giá trị thông tin mong đợi của một lần phỏng đoán cụ thể.

225
00:12:50,820 --> 00:12:54,380
Bạn có thể coi entropy như việc đo hai thứ cùng một lúc.

226
00:12:54,380 --> 00:12:57,420
Đầu tiên là mức độ phân phối bằng phẳng như thế nào.

227
00:12:57,420 --> 00:13:01,700
Sự phân bố càng gần đều thì entropy càng cao.

228
00:13:01,700 --> 00:13:07,168
Trong trường hợp của chúng tôi, khi có tổng số từ 3 đến 5 mẫu, để phân bố đồng đều, việc

229
00:13:07,168 --> 00:13:12,391
quan sát bất kỳ mẫu nào trong số chúng sẽ có nhật ký thông tin cơ sở 2 của 3 đến mẫu

230
00:13:12,391 --> 00:13:17,860
thứ 5, tức là 7.92, vậy đó là mức tối đa tuyệt đối mà bạn có thể có đối với entropy này.

231
00:13:17,860 --> 00:13:22,900
Nhưng entropy cũng là thước đo xem có bao nhiêu khả năng xảy ra ngay từ đầu.

232
00:13:22,900 --> 00:13:27,860
Ví dụ: nếu bạn tình cờ có một từ nào đó trong đó chỉ có 16 mẫu có thể và mỗi mẫu

233
00:13:27,860 --> 00:13:32,760
đều có khả năng như nhau, thì entropy này, thông tin mong đợi này, sẽ là 4 bit.

234
00:13:32,760 --> 00:13:36,880
Nhưng nếu bạn có một từ khác trong đó có 64 mẫu có thể xuất hiện và

235
00:13:36,880 --> 00:13:41,000
chúng đều có khả năng như nhau, thì entropy sẽ có kết quả là 6 bit.

236
00:13:41,000 --> 00:13:45,527
Vì vậy, nếu bạn thấy một số phân phối ngoài tự nhiên có entropy 6 bit, thì

237
00:13:45,527 --> 00:13:50,114
điều đó giống như nói rằng có nhiều biến thể và sự không chắc chắn về những

238
00:13:50,114 --> 00:13:54,400
gì sắp xảy ra giống như thể có 64 kết quả có khả năng xảy ra như nhau.

239
00:13:54,400 --> 00:13:58,360
Trong lần đầu tiên tôi vượt qua Wurtelebot, về cơ bản tôi chỉ cần làm điều này.

240
00:13:58,360 --> 00:14:03,070
Nó xem xét tất cả những phỏng đoán có thể có mà bạn có thể có, tất cả 13.000

241
00:14:03,070 --> 00:14:07,902
từ, tính toán entropy cho mỗi từ, hay cụ thể hơn là entropy của phân phối trên

242
00:14:07,902 --> 00:14:12,673
tất cả các mẫu mà bạn có thể thấy, cho mỗi mẫu và chọn mức cao nhất, vì đó là

243
00:14:12,673 --> 00:14:17,200
thứ có khả năng cắt giảm không gian khả năng của bạn càng nhiều càng tốt.

244
00:14:17,200 --> 00:14:19,353
Và mặc dù tôi chỉ nói về lần đoán đầu tiên ở đây,

245
00:14:19,353 --> 00:14:21,680
nhưng những lần đoán tiếp theo cũng diễn ra tương tự.

246
00:14:21,680 --> 00:14:25,187
Ví dụ: sau khi bạn thấy một số mẫu trong lần đoán đầu tiên đó, điều này

247
00:14:25,187 --> 00:14:28,695
sẽ hạn chế bạn ở số lượng từ có thể có ít hơn dựa trên những gì phù hợp

248
00:14:28,695 --> 00:14:32,300
với từ đó, bạn chỉ cần chơi cùng một trò chơi đối với nhóm từ nhỏ hơn đó.

249
00:14:32,300 --> 00:14:36,693
Đối với lần đoán thứ hai được đề xuất, bạn xem xét sự phân bố của tất

250
00:14:36,693 --> 00:14:40,961
cả các mẫu có thể xảy ra từ tập hợp từ hạn chế hơn đó, bạn tìm kiếm

251
00:14:40,961 --> 00:14:45,480
trong tất cả 13.000 khả năng và bạn tìm thấy mẫu tối đa hóa entropy đó.

252
00:14:45,480 --> 00:14:49,722
Để cho bạn thấy điều này hoạt động như thế nào trong thực tế, hãy để tôi đưa ra một biến

253
00:14:49,722 --> 00:14:53,869
thể nhỏ của Wurtele mà tôi đã viết cho thấy những điểm nổi bật của phân tích này ở bên

254
00:14:53,869 --> 00:14:54,060
lề.

255
00:14:54,060 --> 00:14:57,112
Sau khi thực hiện tất cả các phép tính entropy, ở bên phải nó sẽ hiển

256
00:14:57,112 --> 00:15:00,340
thị cho chúng ta những thông tin nào có thông tin được mong đợi cao nhất.

257
00:15:00,340 --> 00:15:05,674
Hóa ra câu trả lời hàng đầu, ít nhất là tại thời điểm này, chúng ta sẽ tinh chỉnh

258
00:15:05,674 --> 00:15:11,140
lại sau, là Tares, có nghĩa là, ừm, tất nhiên, đậu tằm, loại đậu tằm phổ biến nhất.

259
00:15:11,140 --> 00:15:14,620
Mỗi lần chúng ta đoán ở đây, có lẽ tôi sẽ bỏ qua các đề xuất của nó và chọn phương

260
00:15:14,620 --> 00:15:18,101
tiện chặn, bởi vì tôi thích phương tiện chặn, chúng ta có thể thấy nó có bao nhiêu

261
00:15:18,101 --> 00:15:21,457
thông tin được mong đợi, nhưng ở bên phải của từ ở đây, nó cho chúng ta thấy có

262
00:15:21,457 --> 00:15:24,980
bao nhiêu thông tin thông tin thực tế chúng tôi nhận được, dựa trên mẫu cụ thể này.

263
00:15:24,980 --> 00:15:27,720
Vì vậy ở đây có vẻ như chúng ta đã hơi xui xẻo một chút, chúng ta đã

264
00:15:27,720 --> 00:15:30,660
mong đợi nhận được 5.8, nhưng chúng tôi tình cờ nhận được thứ ít hơn thế.

265
00:15:30,660 --> 00:15:33,283
Và ở phía bên trái, nó hiển thị cho chúng ta tất cả các

266
00:15:33,283 --> 00:15:35,860
từ khác nhau có thể có ở vị trí hiện tại của chúng ta.

267
00:15:35,860 --> 00:15:38,634
Các thanh màu xanh lam cho chúng ta biết khả năng nó nghĩ mỗi từ

268
00:15:38,634 --> 00:15:41,408
là bao nhiêu, vì vậy hiện tại nó đang giả định mỗi từ đều có khả

269
00:15:41,408 --> 00:15:44,140
năng xảy ra như nhau, nhưng chúng ta sẽ tinh chỉnh điều đó sau.

270
00:15:44,140 --> 00:15:48,073
Và sau đó, phép đo độ không đảm bảo này cho chúng ta biết entropy

271
00:15:48,073 --> 00:15:52,006
của phân bố này trên các từ có thể, mà hiện tại, vì nó là phân bố

272
00:15:52,006 --> 00:15:55,940
đều, chỉ là một cách phức tạp không cần thiết để đếm số khả năng.

273
00:15:55,940 --> 00:16:02,700
Ví dụ: nếu chúng ta lấy 2 lũy thừa của 13.66, tức là có khoảng 13.000 khả năng.

274
00:16:02,700 --> 00:16:06,780
Ở đây tôi hơi sai một chút, nhưng chỉ vì tôi không hiển thị tất cả các chữ số thập phân.

275
00:16:06,780 --> 00:16:09,816
Hiện tại, điều này có thể khiến bạn cảm thấy dư thừa và có vẻ như mọi thứ quá phức

276
00:16:09,816 --> 00:16:12,780
tạp, nhưng bạn sẽ thấy tại sao việc có cả hai con số trong một phút lại hữu ích.

277
00:16:12,780 --> 00:16:16,191
Vì vậy, ở đây có vẻ như nó gợi ý entropy cao nhất cho lần đoán thứ hai

278
00:16:16,191 --> 00:16:19,700
của chúng ta là Ramen, một lần nữa nó thực sự không giống một từ nào cả.

279
00:16:19,700 --> 00:16:25,660
Vì vậy, để nâng cao nền tảng đạo đức ở đây, tôi sẽ tiếp tục và gõ Rains.

280
00:16:25,660 --> 00:16:27,540
Và một lần nữa có vẻ như chúng tôi hơi kém may mắn.

281
00:16:27,540 --> 00:16:32,100
Chúng tôi đã mong đợi 4.3 bit và chúng tôi chỉ có 3.39 bit thông tin.

282
00:16:32,100 --> 00:16:35,060
Vì vậy, điều đó đưa chúng ta xuống còn 55 khả năng.

283
00:16:35,060 --> 00:16:37,509
Và ở đây có lẽ tôi sẽ thực sự làm theo những gì nó

284
00:16:37,509 --> 00:16:40,200
gợi ý, đó là sự kết hợp, bất kể điều đó có nghĩa là gì.

285
00:16:40,200 --> 00:16:43,300
Và được rồi, đây thực sự là một cơ hội tốt để giải câu đố.

286
00:16:43,300 --> 00:16:47,020
Nó cho chúng ta biết mẫu này cho chúng ta 4.7 bit thông tin.

287
00:16:47,020 --> 00:16:52,400
Nhưng ở bên trái, trước khi chúng ta nhìn thấy mẫu đó, có 5.78 bit không chắc chắn.

288
00:16:52,400 --> 00:16:56,860
Vì vậy, như một câu đố dành cho bạn, điều đó có ý nghĩa gì về số khả năng còn lại?

289
00:16:56,860 --> 00:17:00,860
Chà, điều đó có nghĩa là chúng ta giảm xuống còn một chút không chắc chắn,

290
00:17:00,860 --> 00:17:04,700
điều này cũng giống như việc nói rằng có hai câu trả lời có thể xảy ra.

291
00:17:04,700 --> 00:17:06,520
Đó là sự lựa chọn 50-50.

292
00:17:06,520 --> 00:17:08,957
Và từ đây, bởi vì bạn và tôi biết những từ nào phổ biến

293
00:17:08,957 --> 00:17:11,220
hơn, chúng ta biết rằng câu trả lời sẽ là vực thẳm.

294
00:17:11,220 --> 00:17:13,540
Nhưng như nó được viết bây giờ, chương trình không biết điều đó.

295
00:17:13,540 --> 00:17:16,827
Vì vậy, nó cứ tiếp tục, cố gắng thu thập càng nhiều thông tin càng

296
00:17:16,827 --> 00:17:20,360
tốt, cho đến khi chỉ còn một khả năng duy nhất, và rồi nó đoán điều đó.

297
00:17:20,360 --> 00:17:22,700
Vì vậy, rõ ràng là chúng ta cần một chiến lược tàn cuộc tốt hơn.

298
00:17:22,700 --> 00:17:26,720
Nhưng giả sử chúng tôi gọi phiên bản này là một trong những trình giải wordle của

299
00:17:26,720 --> 00:17:30,740
chúng tôi, sau đó chúng tôi chạy một số mô phỏng để xem nó hoạt động như thế nào.

300
00:17:30,740 --> 00:17:34,240
Vì vậy, cách thức hoạt động của nó là chơi mọi trò chơi chữ có thể.

301
00:17:34,240 --> 00:17:38,780
Nó sẽ trải qua tất cả 2315 từ đó là câu trả lời từng từ thực tế.

302
00:17:38,780 --> 00:17:41,340
Về cơ bản nó sử dụng nó như một bộ thử nghiệm.

303
00:17:41,340 --> 00:17:44,386
Và với phương pháp ngây thơ này là không xem xét mức độ phổ biến

304
00:17:44,386 --> 00:17:47,386
của một từ mà chỉ cố gắng tối đa hóa thông tin ở mỗi bước trong

305
00:17:47,386 --> 00:17:50,480
quá trình thực hiện, cho đến khi chỉ còn một và chỉ một lựa chọn.

306
00:17:50,480 --> 00:17:55,100
Khi kết thúc mô phỏng, điểm trung bình là khoảng 4.124.

307
00:17:55,100 --> 00:17:59,780
Điều đó không tệ, thành thật mà nói, tôi đã dự kiến sẽ làm tệ hơn.

308
00:17:59,780 --> 00:18:03,040
Nhưng những người chơi wordle sẽ nói với bạn rằng họ thường có thể chơi được trong 4.

309
00:18:03,040 --> 00:18:05,260
Thử thách thực sự là lấy được càng nhiều phần 3 càng tốt.

310
00:18:05,260 --> 00:18:08,920
Đó là một bước nhảy khá lớn giữa điểm 4 và điểm 3.

311
00:18:08,920 --> 00:18:16,040
Điểm mấu chốt rõ ràng ở đây là bằng cách nào đó kết hợp xem một từ có

312
00:18:16,040 --> 00:18:23,160
phổ biến hay không và chính xác thì chúng ta làm điều đó như thế nào.

313
00:18:23,160 --> 00:18:28,560
Cách tôi tiếp cận là lấy danh sách tần số tương đối của tất cả các từ trong tiếng Anh.

314
00:18:28,560 --> 00:18:32,112
Và tôi vừa sử dụng chức năng dữ liệu tần số từ của Mathematica, chức năng

315
00:18:32,112 --> 00:18:35,520
này được lấy từ tập dữ liệu công khai Ngram tiếng Anh của Google Sách.

316
00:18:35,520 --> 00:18:37,800
Và thật thú vị khi xem xét, ví dụ như nếu chúng ta sắp xếp

317
00:18:37,800 --> 00:18:40,120
nó từ những từ phổ biến nhất đến những từ ít phổ biến nhất.

318
00:18:40,120 --> 00:18:43,740
Rõ ràng đây là những từ có 5 chữ cái phổ biến nhất trong tiếng Anh.

319
00:18:43,740 --> 00:18:46,480
Hay đúng hơn, đây là điều phổ biến thứ 8.

320
00:18:46,480 --> 00:18:49,440
Đầu tiên là cái nào, sau đó có đó và có đó.

321
00:18:49,440 --> 00:18:52,626
Bản thân thứ nhất không phải là thứ nhất mà là thứ 9, và điều hợp lý là

322
00:18:52,626 --> 00:18:55,769
những từ khác này có thể xuất hiện thường xuyên hơn, trong đó những từ

323
00:18:55,769 --> 00:18:59,000
đứng sau đầu tiên là sau, ở đâu và những từ đó ít phổ biến hơn một chút.

324
00:18:59,000 --> 00:19:02,851
Bây giờ, khi sử dụng dữ liệu này để mô hình hóa khả năng mỗi từ này

325
00:19:02,851 --> 00:19:06,760
là câu trả lời cuối cùng, nó không nên chỉ tỷ lệ thuận với tần suất.

326
00:19:06,760 --> 00:19:11,043
Ví dụ: được cho điểm 0.002 trong tập dữ liệu này, trong khi từ bện

327
00:19:11,043 --> 00:19:15,200
theo một nghĩa nào đó ít có khả năng xảy ra hơn khoảng 1000 lần.

328
00:19:15,200 --> 00:19:19,400
Nhưng cả hai đều là những từ phổ biến đến mức chúng gần như chắc chắn đáng được xem xét.

329
00:19:19,400 --> 00:19:21,900
Vì vậy, chúng tôi muốn có nhiều điểm cắt nhị phân hơn.

330
00:19:21,900 --> 00:19:25,902
Cách tôi thực hiện là tưởng tượng lấy toàn bộ danh sách các từ được

331
00:19:25,902 --> 00:19:30,141
sắp xếp này, sau đó sắp xếp nó theo trục x, sau đó áp dụng hàm sigmoid,

332
00:19:30,141 --> 00:19:34,261
đây là cách tiêu chuẩn để có một hàm có đầu ra về cơ bản là nhị phân,

333
00:19:34,261 --> 00:19:38,500
đó là 0 hoặc 1, nhưng có sự làm mịn ở giữa cho vùng không chắc chắn đó.

334
00:19:38,500 --> 00:19:43,950
Vì vậy, về cơ bản, xác suất mà tôi gán cho mỗi từ để nằm trong danh sách cuối

335
00:19:43,950 --> 00:19:49,540
cùng sẽ là giá trị của hàm sigmoid ở trên bất kỳ vị trí nào nó nằm trên trục x.

336
00:19:49,540 --> 00:19:54,165
Bây giờ, rõ ràng điều này phụ thuộc vào một số tham số, chẳng hạn như độ rộng của khoảng

337
00:19:54,165 --> 00:19:58,530
trắng trên trục x mà những từ đó điền vào sẽ xác định mức độ chúng ta giảm dần hoặc

338
00:19:58,530 --> 00:20:03,000
dốc từ 1 xuống 0 và vị trí chúng ta đặt chúng từ trái sang phải sẽ xác định điểm cắt.

339
00:20:03,000 --> 00:20:07,340
Thành thật mà nói, cách tôi làm điều này chỉ là liếm ngón tay và đưa nó theo chiều gió.

340
00:20:07,340 --> 00:20:10,678
Tôi xem qua danh sách đã sắp xếp và cố gắng tìm một cửa sổ mà

341
00:20:10,678 --> 00:20:14,071
khi nhìn vào nó, tôi nhận ra khoảng một nửa số từ này có nhiều

342
00:20:14,071 --> 00:20:17,680
khả năng là câu trả lời cuối cùng và sử dụng nó làm điểm giới hạn.

343
00:20:17,680 --> 00:20:20,954
Khi chúng ta có sự phân bố như thế này trên các từ, nó sẽ cho chúng ta

344
00:20:20,954 --> 00:20:24,460
một tình huống khác trong đó entropy trở thành phép đo thực sự hữu ích này.

345
00:20:24,460 --> 00:20:27,473
Ví dụ: giả sử chúng ta đang chơi một trò chơi và chúng ta bắt đầu với

346
00:20:27,473 --> 00:20:30,616
những từ mở đầu cũ của tôi, đó là một chiếc lông vũ và những chiếc đinh,

347
00:20:30,616 --> 00:20:33,760
và chúng ta kết thúc với một tình huống có thể có bốn từ phù hợp với nó.

348
00:20:33,760 --> 00:20:36,440
Và giả sử chúng ta coi chúng đều có khả năng xảy ra như nhau.

349
00:20:36,440 --> 00:20:40,000
Hãy để tôi hỏi bạn, entropy của phân phối này là gì?

350
00:20:40,000 --> 00:20:45,156
Chà, thông tin liên quan đến từng khả năng này sẽ là

351
00:20:45,156 --> 00:20:50,800
log cơ số 2 của 4, vì mỗi khả năng là 1 và 4, và đó là 2.

352
00:20:50,800 --> 00:20:52,780
Hai thông tin, bốn khả năng.

353
00:20:52,780 --> 00:20:54,360
Tất cả đều rất tốt và tốt.

354
00:20:54,360 --> 00:20:58,320
Nhưng điều gì sẽ xảy ra nếu tôi nói với bạn rằng thực sự có nhiều hơn bốn trận đấu?

355
00:20:58,320 --> 00:21:02,600
Trên thực tế, khi chúng ta xem qua danh sách từ đầy đủ, có 16 từ phù hợp với nó.

356
00:21:02,600 --> 00:21:06,964
Nhưng giả sử mô hình của chúng tôi đặt ra xác suất rất thấp cho 12 từ còn lại

357
00:21:06,964 --> 00:21:11,440
thực sự là câu trả lời cuối cùng, khoảng 1 trên 1000 vì chúng thực sự khó hiểu.

358
00:21:11,440 --> 00:21:15,480
Bây giờ hãy để tôi hỏi bạn, entropy của phân phối này là gì?

359
00:21:15,480 --> 00:21:19,053
Nếu entropy chỉ đơn thuần là đo số lượng kết quả trùng khớp ở

360
00:21:19,053 --> 00:21:22,626
đây, thì bạn có thể mong đợi nó giống như log cơ số 2 của 16,

361
00:21:22,626 --> 00:21:26,200
tức là 4, nhiều hơn hai bit không chắc chắn so với trước đây.

362
00:21:26,200 --> 00:21:28,260
Nhưng tất nhiên, sự không chắc chắn thực tế không thực

363
00:21:28,260 --> 00:21:30,320
sự khác biệt so với những gì chúng ta đã có trước đây.

364
00:21:30,320 --> 00:21:34,347
Chỉ vì có 12 từ thực sự khó hiểu này không có nghĩa là sẽ ngạc nhiên

365
00:21:34,347 --> 00:21:38,200
hơn khi biết rằng câu trả lời cuối cùng là sự quyến rũ chẳng hạn.

366
00:21:38,200 --> 00:21:42,106
Vì vậy, khi bạn thực sự thực hiện phép tính ở đây và cộng xác suất của mỗi

367
00:21:42,106 --> 00:21:45,960
lần xuất hiện với thông tin tương ứng, kết quả bạn nhận được là 2.11 bit.

368
00:21:45,960 --> 00:21:49,760
Tôi chỉ đang nói, về cơ bản nó là hai bit, về cơ bản là bốn khả năng đó, nhưng

369
00:21:49,760 --> 00:21:53,367
có một chút không chắc chắn hơn vì tất cả những sự kiện rất khó xảy ra đó,

370
00:21:53,367 --> 00:21:57,120
mặc dù nếu bạn đã tìm hiểu chúng, bạn sẽ nhận được rất nhiều thông tin từ nó.

371
00:21:57,120 --> 00:21:59,352
Vì vậy, thu nhỏ, đây là một phần lý do khiến Wordle

372
00:21:59,352 --> 00:22:01,800
trở thành một ví dụ hay cho bài học lý thuyết thông tin.

373
00:22:01,800 --> 00:22:05,280
Chúng ta có hai ứng dụng cảm nhận riêng biệt về entropy.

374
00:22:05,280 --> 00:22:08,910
Câu đầu tiên cho chúng ta biết thông tin mong đợi mà chúng ta sẽ nhận được từ một

375
00:22:08,910 --> 00:22:12,540
lần phỏng đoán nhất định và câu thứ hai cho chúng ta biết liệu chúng ta có thể đo

376
00:22:12,540 --> 00:22:16,480
lường độ không chắc chắn còn lại trong số tất cả các từ mà chúng ta có thể có hay không.

377
00:22:16,480 --> 00:22:19,214
Và tôi nên nhấn mạnh, trong trường hợp đầu tiên khi chúng ta xem xét

378
00:22:19,214 --> 00:22:22,027
thông tin dự kiến của một lần đoán, một khi chúng ta có trọng số không

379
00:22:22,027 --> 00:22:25,000
bằng nhau đối với các từ, điều đó sẽ ảnh hưởng đến việc tính toán entropy.

380
00:22:25,000 --> 00:22:28,083
Ví dụ: hãy để tôi đưa ra trường hợp tương tự mà chúng ta đã

381
00:22:28,083 --> 00:22:31,219
xem xét trước đó về phân phối liên quan đến Weary, nhưng lần

382
00:22:31,219 --> 00:22:34,560
này sử dụng phân phối không đồng nhất trên tất cả các từ có thể.

383
00:22:34,560 --> 00:22:39,360
Vì vậy, hãy để tôi xem liệu tôi có thể tìm thấy một phần ở đây minh họa nó khá tốt không.

384
00:22:39,360 --> 00:22:42,480
Được rồi, ở đây khá tốt.

385
00:22:42,480 --> 00:22:46,084
Ở đây chúng ta có hai mẫu liền kề có khả năng xảy ra như nhau, nhưng

386
00:22:46,084 --> 00:22:49,480
một trong số chúng được cho biết có 32 từ có thể phù hợp với nó.

387
00:22:49,480 --> 00:22:52,468
Và nếu chúng ta kiểm tra xem chúng là gì, thì đây là 32 từ đó,

388
00:22:52,468 --> 00:22:55,600
tất cả chỉ là những từ rất khó xảy ra khi bạn quét mắt qua chúng.

389
00:22:55,600 --> 00:22:59,272
Thật khó để tìm thấy bất kỳ câu trả lời hợp lý nào, có thể là đáng ngạc nhiên,

390
00:22:59,272 --> 00:23:02,806
nhưng nếu chúng ta nhìn vào mô hình lân cận trong phân phối, được coi là có

391
00:23:02,806 --> 00:23:06,340
khả năng xảy ra, chúng ta được biết rằng nó chỉ có 8 kết quả phù hợp có thể

392
00:23:06,340 --> 00:23:09,920
xảy ra, tức là một phần tư nhiều trận đấu, nhưng gần như có khả năng xảy ra.

393
00:23:09,920 --> 00:23:12,520
Và khi chúng tôi xem những trận đấu đó, chúng tôi có thể hiểu tại sao.

394
00:23:12,520 --> 00:23:15,231
Một số trong số này là những câu trả lời thực sự hợp

395
00:23:15,231 --> 00:23:17,840
lý, như tiếng chuông, cơn thịnh nộ hoặc tiếng rap.

396
00:23:17,840 --> 00:23:20,560
Để minh họa cách chúng tôi kết hợp tất cả những điều đó, hãy để

397
00:23:20,560 --> 00:23:23,154
tôi đưa ra phiên bản 2 của Wordlebot ở đây và có hai hoặc ba

398
00:23:23,154 --> 00:23:25,960
điểm khác biệt chính so với phiên bản đầu tiên mà chúng tôi thấy.

399
00:23:25,960 --> 00:23:30,445
Trước hết, như tôi vừa nói, cách chúng ta tính toán những entropy này, những

400
00:23:30,445 --> 00:23:34,814
giá trị thông tin kỳ vọng này, hiện đang sử dụng những phân bố tinh tế hơn

401
00:23:34,814 --> 00:23:39,300
trên các mẫu kết hợp xác suất mà một từ nhất định thực sự sẽ là câu trả lời.

402
00:23:39,300 --> 00:23:44,160
Thực tế thì nước mắt vẫn là số 1, dù những nước mắt sau có hơi khác một chút.

403
00:23:44,160 --> 00:23:47,879
Thứ hai, khi xếp hạng các lựa chọn hàng đầu, nó sẽ giữ một mô hình về xác

404
00:23:47,879 --> 00:23:51,549
suất mà mỗi từ là câu trả lời thực sự và nó sẽ kết hợp điều đó vào quyết

405
00:23:51,549 --> 00:23:55,520
định của mình, điều này sẽ dễ thấy hơn khi chúng ta có một vài dự đoán về bàn.

406
00:23:55,520 --> 00:23:58,292
Một lần nữa, bỏ qua khuyến nghị của nó vì chúng ta

407
00:23:58,292 --> 00:24:01,120
không thể để máy móc điều khiển cuộc sống của mình.

408
00:24:01,120 --> 00:24:05,626
Và tôi cho rằng tôi nên đề cập đến một điều khác ở đây là ở bên trái, giá trị không

409
00:24:05,626 --> 00:24:10,080
chắc chắn đó, số bit đó, không còn dư thừa với số lượng kết quả phù hợp có thể có.

410
00:24:10,080 --> 00:24:16,640
Bây giờ nếu chúng ta kéo nó lên và tính từ 2 đến 8.02, cao hơn 256 một chút, tôi đoán là

411
00:24:16,640 --> 00:24:22,978
259, điều nó nói là mặc dù có tổng cộng 526 từ thực sự khớp với mẫu này, mức độ không

412
00:24:22,978 --> 00:24:29,391
chắc chắn của nó gần giống với mức độ sẽ xảy ra nếu có 259 từ có khả năng như nhau kết

413
00:24:29,391 --> 00:24:29,760
quả.

414
00:24:29,760 --> 00:24:31,100
Bạn có thể nghĩ về nó như thế này.

415
00:24:31,100 --> 00:24:34,470
Nó biết borx không phải là câu trả lời, tương tự với yorts, zorl và

416
00:24:34,470 --> 00:24:37,840
zorus, vì vậy nó ít chắc chắn hơn một chút so với trường hợp trước.

417
00:24:37,840 --> 00:24:40,220
Số bit này sẽ nhỏ hơn.

418
00:24:40,220 --> 00:24:44,450
Và nếu tôi tiếp tục chơi trò chơi, tôi sẽ tinh chỉnh điều này bằng

419
00:24:44,450 --> 00:24:48,680
một vài phỏng đoán phù hợp với những gì tôi muốn giải thích ở đây.

420
00:24:48,680 --> 00:24:51,179
Đến lần đoán thứ tư, nếu bạn nhìn qua những lựa chọn hàng đầu

421
00:24:51,179 --> 00:24:53,800
của nó, bạn có thể thấy nó không còn chỉ tối đa hóa entropy nữa.

422
00:24:53,800 --> 00:24:57,212
Vì vậy, tại thời điểm này, về mặt kỹ thuật có bảy khả năng, nhưng

423
00:24:57,212 --> 00:25:00,780
những khả năng duy nhất có cơ hội có ý nghĩa là ký túc xá và từ ngữ.

424
00:25:00,780 --> 00:25:04,145
Và bạn có thể thấy nó xếp hạng việc chọn cả hai giá trị đó lên trên

425
00:25:04,145 --> 00:25:07,560
tất cả các giá trị khác, nói đúng ra thì sẽ cung cấp thêm thông tin.

426
00:25:07,560 --> 00:25:11,048
Lần đầu tiên tôi làm điều này, tôi chỉ cộng hai con số này để đo lường chất lượng

427
00:25:11,048 --> 00:25:14,580
của mỗi lần đoán, và chúng thực sự hoạt động tốt hơn những gì bạn có thể nghi ngờ.

428
00:25:14,580 --> 00:25:17,164
Nhưng nó thực sự có vẻ không mang tính hệ thống và tôi chắc chắn rằng có những

429
00:25:17,164 --> 00:25:19,880
cách tiếp cận khác mà mọi người có thể thực hiện nhưng đây là cách tôi đã áp dụng.

430
00:25:19,880 --> 00:25:22,775
Nếu chúng ta đang xem xét khả năng xảy ra lần đoán tiếp theo, chẳng

431
00:25:22,775 --> 00:25:25,586
hạn như trong trường hợp này là từ ngữ, thì điều chúng ta thực sự

432
00:25:25,586 --> 00:25:28,440
quan tâm là điểm số kỳ vọng của trò chơi nếu chúng ta làm điều đó.

433
00:25:28,440 --> 00:25:32,096
Và để tính số điểm mong đợi đó, chúng tôi nói xác suất mà các từ

434
00:25:32,096 --> 00:25:35,640
đó là câu trả lời thực sự là bao nhiêu, hiện tại nó mô tả 58%.

435
00:25:35,640 --> 00:25:40,400
Chúng tôi nói với 58% cơ hội, điểm của chúng tôi trong trò chơi này sẽ là 4.

436
00:25:40,400 --> 00:25:46,240
Và khi đó với xác suất 1 trừ 58% đó thì điểm của chúng ta sẽ lớn hơn 4 đó.

437
00:25:46,240 --> 00:25:49,536
Chúng tôi không biết còn bao nhiêu nữa, nhưng chúng tôi có thể ước tính nó

438
00:25:49,536 --> 00:25:52,920
dựa trên mức độ không chắc chắn có thể xảy ra khi chúng tôi đạt đến điểm đó.

439
00:25:52,920 --> 00:25:56,600
Cụ thể hiện tại có 1.44 bit không chắc chắn.

440
00:25:56,600 --> 00:25:58,917
Nếu chúng ta đoán các từ, nó sẽ cho chúng ta biết

441
00:25:58,917 --> 00:26:01,560
thông tin mong đợi mà chúng ta sẽ nhận được là 1.27 bit.

442
00:26:01,560 --> 00:26:04,791
Vì vậy, nếu chúng ta đoán từ, sự khác biệt này thể hiện mức độ

443
00:26:04,791 --> 00:26:08,280
không chắc chắn mà chúng ta có thể gặp phải sau khi điều đó xảy ra.

444
00:26:08,280 --> 00:26:11,008
Cái chúng ta cần là một loại hàm nào đó, mà tôi gọi là f

445
00:26:11,008 --> 00:26:13,880
ở đây, liên kết sự không chắc chắn này với điểm số kỳ vọng.

446
00:26:13,880 --> 00:26:18,246
Và cách nó diễn ra là chỉ vẽ một loạt dữ liệu từ các trò chơi trước dựa

447
00:26:18,246 --> 00:26:22,673
trên phiên bản 1 của bot để cho biết điểm thực tế sau các điểm khác nhau

448
00:26:22,673 --> 00:26:27,040
với mức độ không chắc chắn nhất định có thể đo lường được là bao nhiêu.

449
00:26:27,040 --> 00:26:31,199
Ví dụ: những điểm dữ liệu ở đây nằm trên một giá trị khoảng 8. Khoảng

450
00:26:31,199 --> 00:26:35,299
7 là nói cho một số trò chơi sau một thời điểm có 8. Có 7 điểm không

451
00:26:35,299 --> 00:26:39,340
chắc chắn, phải mất hai lần đoán mới có được câu trả lời cuối cùng.

452
00:26:39,340 --> 00:26:41,240
Đối với các trò chơi khác, phải mất ba lần đoán,

453
00:26:41,240 --> 00:26:43,180
đối với các trò chơi khác, phải mất bốn lần đoán.

454
00:26:43,180 --> 00:26:46,996
Nếu chúng ta chuyển sang bên trái ở đây, tất cả các điểm trên 0 đều cho

455
00:26:46,996 --> 00:26:50,812
biết bất cứ khi nào không có chút gì không chắc chắn, tức là chỉ có một

456
00:26:50,812 --> 00:26:55,000
khả năng, thì số lần dự đoán cần thiết luôn chỉ là một, điều này thật yên tâm.

457
00:26:55,000 --> 00:26:59,444
Bất cứ khi nào có một chút không chắc chắn, nghĩa là về cơ bản chỉ có hai khả năng xảy

458
00:26:59,444 --> 00:27:03,940
ra, thì đôi khi cần phải đoán thêm một lần nữa, đôi khi cần phải đoán thêm hai lần nữa.

459
00:27:03,940 --> 00:27:05,980
Và vân vân và vân vân ở đây.

460
00:27:05,980 --> 00:27:08,408
Có lẽ cách dễ dàng hơn một chút để hình dung dữ liệu

461
00:27:08,408 --> 00:27:11,020
này là gộp chúng lại với nhau và lấy giá trị trung bình.

462
00:27:11,020 --> 00:27:16,531
Ví dụ: thanh này ở đây cho biết trong số tất cả các điểm mà chúng tôi có

463
00:27:16,531 --> 00:27:22,420
một chút không chắc chắn, trung bình số lần đoán mới cần thiết là khoảng 1.5.

464
00:27:22,420 --> 00:27:26,831
Và thanh ở đây nói về tất cả các trò chơi khác nhau mà tại một thời điểm nào đó độ

465
00:27:26,831 --> 00:27:31,509
không chắc chắn cao hơn 4 bit một chút, giống như thu hẹp nó xuống còn 16 khả năng khác

466
00:27:31,509 --> 00:27:36,240
nhau, sau đó trung bình nó yêu cầu nhiều hơn hai lần đoán kể từ thời điểm đó phía trước.

467
00:27:36,240 --> 00:27:38,243
Và từ đây tôi mới thực hiện một phép hồi quy để

468
00:27:38,243 --> 00:27:40,080
khớp với một hàm có vẻ hợp lý với điều này.

469
00:27:40,080 --> 00:27:43,385
Và hãy nhớ rằng mục đích chung của việc thực hiện bất kỳ điều nào trong

470
00:27:43,385 --> 00:27:46,690
số đó là để chúng ta có thể định lượng trực giác này rằng chúng ta càng

471
00:27:46,690 --> 00:27:49,720
thu được nhiều thông tin từ một từ thì điểm kỳ vọng sẽ càng thấp.

472
00:27:49,720 --> 00:27:54,890
Vì vậy, với phiên bản này là 2.0, nếu chúng ta quay lại và chạy cùng một bộ mô phỏng,

473
00:27:54,890 --> 00:27:59,820
để nó đấu với tất cả 2315 câu trả lời từ có thể có, thì nó hoạt động như thế nào?

474
00:27:59,820 --> 00:28:02,008
Ngược lại với phiên bản đầu tiên của chúng tôi,

475
00:28:02,008 --> 00:28:04,060
nó chắc chắn tốt hơn, điều này thật yên tâm.

476
00:28:04,060 --> 00:28:08,385
Tất cả đã nói và làm trung bình là khoảng 3.6, mặc dù không giống như phiên bản

477
00:28:08,385 --> 00:28:12,820
đầu tiên, có một vài lần nó bị mất và yêu cầu nhiều hơn sáu trong trường hợp này.

478
00:28:12,820 --> 00:28:15,813
Có lẽ bởi vì đôi khi nó thực hiện sự đánh đổi đó để

479
00:28:15,813 --> 00:28:18,980
thực sự đạt được mục tiêu hơn là tối đa hóa thông tin.

480
00:28:18,980 --> 00:28:22,140
Vậy chúng ta có thể làm tốt hơn 3.6?

481
00:28:22,140 --> 00:28:23,260
Chúng tôi chắc chắn có thể.

482
00:28:23,260 --> 00:28:26,663
Bây giờ tôi đã nói ngay từ đầu rằng sẽ thú vị nhất khi thử không kết hợp danh

483
00:28:26,663 --> 00:28:29,980
sách các câu trả lời từng từ thực sự vào cách nó xây dựng mô hình của mình.

484
00:28:29,980 --> 00:28:35,180
Nhưng nếu chúng tôi kết hợp nó, hiệu suất tốt nhất tôi có thể đạt được là khoảng 3.43.

485
00:28:35,180 --> 00:28:38,807
Vì vậy, nếu chúng ta cố gắng phức tạp hơn việc chỉ sử dụng dữ liệu tần số từ để chọn

486
00:28:38,807 --> 00:28:42,519
phân phối trước này, thì phân phối 3 này. 43 có lẽ cho biết mức độ tối đa mà chúng tôi

487
00:28:42,519 --> 00:28:46,360
có thể đạt được với điều đó, hoặc ít nhất là tôi có thể đạt được điều đó tốt đến mức nào.

488
00:28:46,360 --> 00:28:49,444
Hiệu suất tốt nhất đó về cơ bản chỉ sử dụng những ý tưởng mà tôi đã

489
00:28:49,444 --> 00:28:52,529
nói ở đây, nhưng nó còn đi xa hơn một chút, giống như việc tìm kiếm

490
00:28:52,529 --> 00:28:55,660
thông tin được mong đợi về phía trước hai bước thay vì chỉ một bước.

491
00:28:55,660 --> 00:28:58,072
Ban đầu tôi định nói nhiều hơn về vấn đề đó, nhưng

492
00:28:58,072 --> 00:29:00,580
tôi nhận ra rằng chúng ta thực sự đã đi khá lâu rồi.

493
00:29:00,580 --> 00:29:03,596
Một điều tôi sẽ nói là sau khi thực hiện tìm kiếm hai bước này và sau

494
00:29:03,596 --> 00:29:06,569
đó chạy một vài mô phỏng mẫu trong các ứng cử viên hàng đầu, đối với

495
00:29:06,569 --> 00:29:09,500
tôi, ít nhất cho đến nay, có vẻ như Crane là người mở màn tốt nhất.

496
00:29:09,500 --> 00:29:11,080
Ai có thể đoán được?

497
00:29:11,080 --> 00:29:14,566
Ngoài ra, nếu bạn sử dụng danh sách từ thực sự để xác định không gian khả năng

498
00:29:14,566 --> 00:29:17,920
của mình, thì độ không chắc chắn mà bạn bắt đầu sẽ lớn hơn 11 bit một chút.

499
00:29:17,920 --> 00:29:22,076
Và hóa ra, chỉ từ một cuộc tìm kiếm thô bạo, thông tin mong

500
00:29:22,076 --> 00:29:26,580
đợi tối đa có thể có sau hai lần đoán đầu tiên là khoảng 10 bit.

501
00:29:26,580 --> 00:29:30,900
Điều này gợi ý rằng trong trường hợp tốt nhất, sau hai lần đoán đầu tiên của

502
00:29:30,900 --> 00:29:35,220
bạn, với lối chơi hoàn toàn tối ưu, bạn sẽ còn lại một chút không chắc chắn.

503
00:29:35,220 --> 00:29:37,400
Điều này cũng giống như việc có hai khả năng phỏng đoán.

504
00:29:37,400 --> 00:29:41,557
Vì vậy, tôi nghĩ thật công bằng và có lẽ khá thận trọng khi nói rằng bạn không

505
00:29:41,557 --> 00:29:45,610
bao giờ có thể viết một thuật toán đạt mức trung bình thấp nhất là 3, bởi vì

506
00:29:45,610 --> 00:29:49,662
với số từ có sẵn cho bạn, đơn giản là không có đủ chỗ để có đủ thông tin chỉ

507
00:29:49,662 --> 00:29:53,820
sau hai bước. có thể đảm bảo câu trả lời ở ô thứ ba mọi lúc mà không thất bại.

