1
00:00:00,000 --> 00:00:03,137
Wurdle というゲームは、ここ 1 ～

2
00:00:03,137 --> 00:00:05,561
2 か月でかなり話題になりました。

3
00:00:05,561 --> 00:00:08,413
数学の授業の 機会を見逃す人はいません。

4
00:00:08,413 --> 00:00:11,693
このゲームは、情報理 論、特にエントロピーとし

5
00:00:11,693 --> 00:00:13,120
て知られるトピック。

6
00:00:13,120 --> 00:00:16,064
多くの人と同じように、私もパズルに夢中になりました。

7
00:00:16,064 --> 00:00:19,349
また、 多くのプログラマーと同じように、私もゲームを可能な

8
00:00:19,349 --> 00:00:22,633
限り最適 にプレイするアルゴリズムを作成することに夢中にな

9
00:00:22,633 --> 00:00:23,200
りました。

10
00:00:23,200 --> 00:00:26,194
ここで私がやろうと思ったのは、アルゴリズム全体がこのエン

11
00:00:26,194 --> 00:00:29,188
トロピーの考え方に中心を置いているため、そのプロセスの一

12
00:00:29,188 --> 00:00:32,080
部を話し、それに使用された数学の一部を説明することです。

13
00:00:32,080 --> 00:00:37,130
まず最初に、Wurdle について聞いたことがない場

14
00:00:37,130 --> 00:00:42,180
合のために説明します。Wurdle とは何ですか?

15
00:00:42,180 --> 00:00:44,433
そして、ここでゲームのルールを確認しながら一石二

16
00:00:44,433 --> 00:00:46,686
鳥にするために、 今後の展開についてもプレビュー

17
00:00:46,686 --> 00:00:48,375
させていただきます。これは、基本的

18
00:00:48,375 --> 00:00:50,628
にゲームをプレイするための小さなアルゴリズムを開

19
00:00:50,628 --> 00:00:51,380
発することです。

20
00:00:51,380 --> 00:00:53,436
私は今日の Wurdle を実行していませんが、これは

21
00:00:53,436 --> 00:00:54,905
2 月 4 日なので、ボットがどのように

22
00:00:54,905 --> 00:00:55,860
動作するか見てみましょう。

23
00:00:55,860 --> 00:00:58,456
Wurdle の目的は、謎の 5 文字の単語を推測す

24
00:00:58,456 --> 00:01:00,860
ることであり、推測する機会が 6 回与えられます。

25
00:01:00,860 --> 00:01:02,990
たとえば、Wurdle ボットは、推

26
00:01:02,990 --> 00:01:05,240
測クレーンから始めることを提案します。

27
00:01:05,240 --> 00:01:08,156
推測するたびに、その推測が真の答えにどの程

28
00:01:08,156 --> 00:01:10,940
度近づいているかに関する情報が得られます。

29
00:01:10,940 --> 00:01:12,788
ここで灰色のボックスは、実際の答えに

30
00:01:12,788 --> 00:01:14,540
C が存在しないことを示しています。

31
00:01:14,540 --> 00:01:16,440
黄色のボックスは R があることを示

32
00:01:16,440 --> 00:01:18,340
していますが、その位置にありません。

33
00:01:18,340 --> 00:01:20,627
緑色のボックスは、秘密の単語に A があり、そ

34
00:01:20,627 --> 00:01:22,820
れが 3 番目の位置にあることを示しています。

35
00:01:22,820 --> 00:01:24,300
そして、NもEもありません。

36
00:01:24,300 --> 00:01:25,951
それでは、早速入って、Wurdle

37
00:01:25,951 --> 00:01:27,420
ボットにその情報を伝えましょう。

38
00:01:27,420 --> 00:01:29,394
クレーンから始まり、灰色、黄色

39
00:01:29,394 --> 00:01:31,500
、緑色、灰色、灰色になりました。

40
00:01:31,500 --> 00:01:33,439
現在表示されているすべてのデータについては心配し

41
00:01:33,439 --> 00:01:35,460
ないでください。それについては、やがて説明します。

42
00:01:35,460 --> 00:01:39,700
しかし、2番目に選ぶ一番の提案は「クソ」です。

43
00:01:39,700 --> 00:01:42,756
推測は実際の 5 文字の単語である必要がありますが、

44
00:01:42,756 --> 00:01:45,700
ご覧のとおり、実際に推測できる内容はかなり自由です。

45
00:01:45,700 --> 00:01:48,860
この場合、shtick を試します。

46
00:01:48,860 --> 00:01:50,260
さて、状況はかなり良いようです。

47
00:01:50,260 --> 00:01:52,192
S と H を押すと、最初の 3

48
00:01:52,192 --> 00:01:54,580
文字がわかり、R があることがわかります。

49
00:01:54,580 --> 00:01:57,160
そして、それは SHA 何か R 、または

50
00:01:57,160 --> 00:01:59,740
SHA R 何かのようなものになるでしょう。

51
00:01:59,740 --> 00:02:02,594
そして、Wurdle ボットは、シャードかシャー

52
00:02:02,594 --> 00:02:05,220
プの 2 つの可能性だけを知っているようです。

53
00:02:05,220 --> 00:02:07,171
現時点ではどちらを選択するか迷っているよう

54
00:02:07,171 --> 00:02:09,122
なものなので、おそらく アルファベット順と

55
00:02:09,122 --> 00:02:11,260
いうだけでシャードに当てはまるのだと思います。

56
00:02:11,260 --> 00:02:13,000
実際の答えはどれでしょう。

57
00:02:13,000 --> 00:02:14,660
それで、3つで解決しました。

58
00:02:14,660 --> 00:02:16,684
それがいいのかどうか疑問に思っているなら、私が

59
00:02:16,684 --> 00:02:18,708
聞いたある人のフレーズで は、ワールドルでは

60
00:02:18,708 --> 00:02:20,820
4 つがパー、3 つがバーディだということです。

61
00:02:20,820 --> 00:02:22,960
これは非常に適切な例えだと思います。

62
00:02:22,960 --> 00:02:25,214
4 つを獲得するには、一貫してゲームに取り組む必要

63
00:02:25,214 --> 00:02:27,560
がありますが、それは確かにクレイジーではありません。

64
00:02:27,560 --> 00:02:30,000
しかし、3つになると、本当に素晴らしい気分になります。

65
00:02:30,000 --> 00:02:32,145
それで、もしあなたがそれに興味がないなら、私がここで

66
00:02:32,145 --> 00:02:34,290
やりたいことは、Wurdle ボットへのアプローチ方

67
00:02:34,290 --> 00:02:36,600
法についての私の思考プロセスを最初から説明することです。

68
00:02:36,600 --> 00:02:38,154
先ほども言いましたが、実際には、こ

69
00:02:38,154 --> 00:02:39,800
れは情報理論のレッスンの言い訳です。

70
00:02:39,800 --> 00:02:41,429
主な目標は、情報とは何か、エント

71
00:02:41,429 --> 00:02:43,160
ロピーとは何かを説明することです。

72
00:02:43,160 --> 00:02:48,545
これに取り組むにあたって私が最初に考えたのは、英語におけ

73
00:02:48,545 --> 00:02:53,560
るさまざまな文字の相対的な頻度を調べてみることでした。

74
00:02:53,560 --> 00:02:55,693
そこで私は、これらの最も頻繁に使用される文

75
00:02:55,693 --> 00:02:57,826
字の多くに当てはまる 冒頭の推測または冒頭

76
00:02:57,826 --> 00:02:59,960
の推測のペアはあるだろうか、と考えました。

77
00:02:59,960 --> 00:03:01,821
そして、私がとても気に入っていたのは、

78
00:03:01,821 --> 00:03:03,780
ネイルに続いて他のことをすることでした。

79
00:03:03,780 --> 00:03:05,990
文字を打つと、緑か黄色が出ると、いつで

80
00:03:05,990 --> 00:03:07,980
も気分が良くなる、という考え方です。

81
00:03:07,980 --> 00:03:09,460
情報が入ってくる感じです。

82
00:03:09,460 --> 00:03:12,280
ただし、このような場合、たとえヒットせず、常にグレーが表示

83
00:03:12,280 --> 00:03:15,007
されたとしても、これらの文字を含まない単語を見つけること

84
00:03:15,007 --> 00:03:17,640
は非常にまれであるため、それでも多くの情報が得られます。

85
00:03:17,640 --> 00:03:20,752
しかし、それでも、これはあまり体系的とは思えません 。

86
00:03:20,752 --> 00:03:23,520
たとえば、文字の順序は考慮されていないからです。

87
00:03:23,520 --> 00:03:24,800
カタツムリを入力できるのに、なぜ

88
00:03:24,800 --> 00:03:26,080
ネイルを入力するのでしょうか?

89
00:03:26,080 --> 00:03:27,720
最後にSがついたほうがいいでしょうか？

90
00:03:27,720 --> 00:03:28,720
よくわかりません。

91
00:03:28,720 --> 00:03:31,533
さて、私の友人は、「疲れた」という単語で始めるのが

92
00:03:31,533 --> 00:03:34,009
好きだと言いました。それ には、W や Y

93
00:03:34,009 --> 00:03:37,160
などの珍しい文字が含まれているので、ちょっと驚きました。

94
00:03:37,160 --> 00:03:38,243
しかし、おそらくそれはより良い

95
00:03:38,243 --> 00:03:39,400
オープナーであるかもしれません。

96
00:03:39,400 --> 00:03:42,216
潜在的な推測の質を判断するために与えることができ

97
00:03:42,216 --> 00:03:44,920
る、ある種の定量的なスコアはあるのでしょうか?

98
00:03:44,920 --> 00:03:47,179
ここで、考えられる推測をランク付けする方法を

99
00:03:47,179 --> 00:03:49,438
準備するために、戻って 、ゲームがどのように

100
00:03:49,438 --> 00:03:51,800
正確に設定されているかを少し明確にしましょう。

101
00:03:51,800 --> 00:03:54,982
つまり、有効な推測として入力できる単語のリストがあ

102
00:03:54,982 --> 00:03:57,920
り、その長さはわずか約 13,000 単語です。

103
00:03:57,920 --> 00:04:01,720
しかし、よく見てみると、本当に珍しいものがたくさんあります。

104
00:04:01,720 --> 00:04:04,126
頭やアリ、A RG など、スクラブル

105
00:04:04,126 --> 00:04:07,040
ゲームで家族の口論を引き起こすような言葉です。

106
00:04:07,040 --> 00:04:08,820
しかし、ゲームの雰囲気は、答えが常にか

107
00:04:08,820 --> 00:04:10,600
なり一般的な単語になるということです。

108
00:04:10,600 --> 00:04:13,066
そして実際、答えとして考えられる約

109
00:04:13,066 --> 00:04:16,080
2300 語のリストがもう 1 つあります。

110
00:04:16,080 --> 00:04:17,925
これは人間が厳選したリストで、特にゲーム

111
00:04:17,925 --> 00:04:19,770
クリエイターのガールフ レンドによるもの

112
00:04:19,770 --> 00:04:21,800
だと思いますが、これはちょっと楽しいですね。

113
00:04:21,800 --> 00:04:24,704
しかし、私がやりたいのは、このプロジェクトの課題は、この

114
00:04:24,704 --> 00:04:27,608
リストに関する事前の知識を組み 込まずに Wordle

115
00:04:27,608 --> 00:04:30,720
を解決するプログラムを作成できるかどうかを確認することです。

116
00:04:30,720 --> 00:04:33,255
まず、このリストには載っていない、よく使わ

117
00:04:33,255 --> 00:04:35,560
れる 5 文字の単語がたくさんあります。

118
00:04:35,560 --> 00:04:37,723
したがって、もう少し回復力があり、公式 Web

119
00:04:37,723 --> 00:04:39,706
サイトだけでなく、誰と でも Wordle

120
00:04:39,706 --> 00:04:41,960
を対戦できるプログラムを作成する方がよいでしょう。

121
00:04:41,960 --> 00:04:44,700
また、この考えられる答えのリストが何であるかを私たちが知って

122
00:04:44,700 --> 00:04:47,440
いる理由は、それがソース コードに表示されているからです。

123
00:04:47,440 --> 00:04:50,197
ただし、ソース コード内でそれが表示されるのは

124
00:04:50,197 --> 00:04:52,840
、その日その日で得られる答えの特定の順序です。

125
00:04:52,840 --> 00:04:56,400
したがって、いつでも明日の答えを調べることができます。

126
00:04:56,400 --> 00:04:57,730
したがって、リストの使用には不正行

127
00:04:57,730 --> 00:04:59,140
為である意味があることは明らかです。

128
00:04:59,140 --> 00:05:02,265
そして、より興味深いパズルとより豊かな情報理論の

129
00:05:02,265 --> 00:05:05,390
レッスンを実現す るのは、代わりに一般的な単語の

130
00:05:05,390 --> 00:05:07,603
相対頻度などのより普遍的なデータ

131
00:05:07,603 --> 00:05:10,728
を使用して、より一般的な単語を好むという直感を捉

132
00:05:10,728 --> 00:05:11,640
えることです。

133
00:05:11,640 --> 00:05:14,049
では、これら 13,000 の可能性の中から、冒

134
00:05:14,049 --> 00:05:16,560
頭の推測をどのように選択すればよいのでしょうか?

135
00:05:16,560 --> 00:05:18,220
たとえば、友人が疲れたプロポーズをした場合

136
00:05:18,220 --> 00:05:19,960
、その質をどのように分析すべきでしょうか?

137
00:05:19,960 --> 00:05:21,744
まあ、彼がその可能性の低い W

138
00:05:21,744 --> 00:05:23,975
が好きだと言ったのは、その W が当た

139
00:05:23,975 --> 00:05:26,541
ったらどれだけ気持ちいいかというロングショット

140
00:05:26,541 --> 00:05:27,880
の性質が好きだからです。

141
00:05:27,880 --> 00:05:30,577
たとえば、最初に明らかにされたパターンが次のような

142
00:05:30,577 --> 00:05:33,274
ものであった場合、この巨大 な辞書にはそのパターン

143
00:05:33,274 --> 00:05:36,080
に一致する単語が 58 語しかないことがわかります。

144
00:05:36,080 --> 00:05:38,900
13,000からは大幅な削減です。

145
00:05:38,900 --> 00:05:41,062
しかし、もちろんその裏返しとして、このようなパ

146
00:05:41,062 --> 00:05:43,320
ターンが発生するのは非常に珍しいということです。

147
00:05:43,320 --> 00:05:46,106
具体的には、各単語が答えとなる可能性が等しい

148
00:05:46,106 --> 00:05:49,020
場合、このパターンにヒ ットする確率は、58

149
00:05:49,020 --> 00:05:51,680
を約 13,000 で割った値になります。

150
00:05:51,680 --> 00:05:53,880
もちろん、それらが同じように答えられるわけではありません。

151
00:05:53,880 --> 00:05:56,680
これらのほとんどは非常に曖昧で、疑わしい単語ですらあります。

152
00:05:56,680 --> 00:05:58,437
しかし、少なくともこのすべての最初のパス

153
00:05:58,437 --> 00:06:00,194
では、それらはすべて 同じ可能性であると

154
00:06:00,194 --> 00:06:02,040
仮定し、後でそれを少し改良してみましょう。

155
00:06:02,040 --> 00:06:04,635
重要なのは、情報量が多いパターンはその性

156
00:06:04,635 --> 00:06:07,360
質上、発生する可能性が低いということです。

157
00:06:07,360 --> 00:06:09,283
実際のところ、有益であるということ

158
00:06:09,283 --> 00:06:11,320
は、その可能性は低いということです。

159
00:06:11,320 --> 00:06:14,970
このオープニングで見られる可能性の高いパターンは、次の

160
00:06:14,970 --> 00:06:18,360
ようなものです。もちろん、中には W がありません。

161
00:06:18,360 --> 00:06:20,220
E があるかもしれないし、A も

162
00:06:20,220 --> 00:06:22,080
R も Y もないかもしれません。

163
00:06:22,080 --> 00:06:24,640
この場合、一致する可能性は 1400 通りあります。

164
00:06:24,640 --> 00:06:27,737
すべてが同じ確率である場合、このパター

165
00:06:27,737 --> 00:06:30,680
ンになる確率は約 11% になります。

166
00:06:30,680 --> 00:06:32,448
したがって、最も可能性の高い結果は

167
00:06:32,448 --> 00:06:34,320
、最も情報が少ないものでもあります。

168
00:06:34,320 --> 00:06:38,160
ここでより全体的な視点を得るために、表示される可能性のあるさ

169
00:06:38,160 --> 00:06:42,000
まざまなパターンすべてにわたる確率の完全な分布を示します。

170
00:06:42,000 --> 00:06:44,663
したがって、あなたが見ている各バーは、明らかにされる

171
00:06:44,663 --> 00:06:47,326
可能性のある色のパ ターンに対応しており、そのうち

172
00:06:47,326 --> 00:06:49,374
3 ～ 5 番目の可能性があり、最も一

173
00:06:49,374 --> 00:06:52,038
般的なものから最も一般的ではないものの順に左から右に

174
00:06:52,038 --> 00:06:52,960
編成されています。

175
00:06:52,960 --> 00:06:54,580
したがって、ここで最も一般的な可能

176
00:06:54,580 --> 00:06:56,200
性は、すべてが灰色になることです。

177
00:06:56,200 --> 00:06:58,800
それは約 14% の確率で起こります。

178
00:06:58,800 --> 00:07:01,520
そして、推測するときに期待しているのは、このロ

179
00:07:01,520 --> 00:07:04,241
ングテールのどこ かに行き着くということです。

180
00:07:04,241 --> 00:07:06,844
たとえば、このパターンに一致する可 能性が

181
00:07:06,844 --> 00:07:09,920
18 個しかなく、明らかに次のように見える場所です。

182
00:07:09,920 --> 00:07:12,000
あるいは、もう少し左に行けば、おそ

183
00:07:12,000 --> 00:07:14,080
らくここまで行けるかもしれません。

184
00:07:14,080 --> 00:07:16,560
さて、あなたに良いパズルをご紹介します。

185
00:07:16,560 --> 00:07:19,236
W で始まり Y で終わり、どこかに R

186
00:07:19,236 --> 00:07:22,040
が含まれる英語の 3 つの単語は何ですか?

187
00:07:22,040 --> 00:07:24,716
結局のところ、その答えは、くどい

188
00:07:24,716 --> 00:07:27,560
、虫食い、そして皮肉なものだった。

189
00:07:27,560 --> 00:07:30,200
したがって、この単語が全体的にどの程度優れて

190
00:07:30,200 --> 00:07:32,840
いるかを判断するには、こ の分布から得られる

191
00:07:32,840 --> 00:07:35,720
と予想される情報量を示す何らかの尺度が必要です。

192
00:07:35,720 --> 00:07:39,097
各パターンを調べて、その発生確率と、そのパター

193
00:07:39,097 --> 00:07:42,475
ンがどれだけ有益かを測定 するものを掛け合わせ

194
00:07:42,475 --> 00:07:46,000
ると、客観的なスコアが得られる可能性があります。

195
00:07:46,000 --> 00:07:48,085
さて、それが何であるべきかについて最初

196
00:07:48,085 --> 00:07:50,280
に直感するのは、一致の数かもしれません。

197
00:07:50,280 --> 00:07:52,960
平均一致数を減らしたいと考えています。

198
00:07:52,960 --> 00:07:55,178
しかし、その代わりに、私たちが情報に帰することが多

199
00:07:55,178 --> 00:07:57,220
い、より普遍的な尺度を使用したいと 思います。

200
00:07:57,220 --> 00:07:59,438
また、これらの 13,000 語のそれぞれに、それ

201
00:07:59,438 --> 00:08:01,657
らが実際に答えであるかど うかについて異なる確率を

202
00:08:01,657 --> 00:08:04,320
割り当てると、より柔軟になる尺度を使用したいと考えています。

203
00:08:04,320 --> 00:08:11,319
情報の標準単位はビットです。これには少し面白い公式が

204
00:08:11,319 --> 00:08:17,800
ありますが、例を見るだけであれば非常に直感的です。

205
00:08:17,800 --> 00:08:21,065
あなたの可能性の空間を半分に減らすような観察があ

206
00:08:21,065 --> 00:08:24,200
る場合、それは少しの情報を持っていると言います。

207
00:08:24,200 --> 00:08:26,589
この例では、可能性の空間はすべての可能性のある単語

208
00:08:26,589 --> 00:08:28,501
であり、5 文字の単語の約 半分に S

209
00:08:28,501 --> 00:08:30,890
があり、それより少し少ないですが、約半分であること

210
00:08:30,890 --> 00:08:31,560
がわかります。

211
00:08:31,560 --> 00:08:33,380
したがって、この観察により、ちょ

212
00:08:33,380 --> 00:08:35,200
っとした情報が得られるでしょう。

213
00:08:35,200 --> 00:08:37,503
代わりに、新しい事実がその可能性の空間を

214
00:08:37,503 --> 00:08:39,806
4 分の 1 に切り 詰める場合、それは

215
00:08:39,806 --> 00:08:42,000
2 ビットの情報を持っていると言います。

216
00:08:42,000 --> 00:08:43,560
たとえば、これらの単語の約 4 分の 1

217
00:08:43,560 --> 00:08:45,120
に T が含まれていることがわかりました。

218
00:08:45,120 --> 00:08:48,079
観測によりその空間が 8 分の 1 に削減された

219
00:08:48,079 --> 00:08:50,920
場合、それは 3 ビットの情報であると言います。

220
00:08:50,920 --> 00:08:53,057
4 ビットでは 16 ビットに分割され、5

221
00:08:53,057 --> 00:08:55,000
ビットでは 32 ビットに分割されます。

222
00:08:55,000 --> 00:08:59,760
そこで、ここで少し立ち止まって、発生確率の観点からビット数を

223
00:08:59,760 --> 00:09:04,520
表す情報の公式は何なのかを自問してみてはいかがでしょうか。

224
00:09:04,520 --> 00:09:07,502
ここで私たちが言いたいのは、ビット数の半分を取る

225
00:09:07,502 --> 00:09:09,614
とき、それは 確率と同じことです。

226
00:09:09,614 --> 00:09:12,224
これは、ビット数の 2 乗が確率より 1

227
00:09:12,224 --> 00:09:14,460
大きいと言っているのと同じことです。

228
00:09:14,460 --> 00:09:17,443
さらに整理すると、情報 は 2 を底とする 1

229
00:09:17,443 --> 00:09:19,680
を確率で割った対数であると言えます。

230
00:09:19,680 --> 00:09:22,734
そして、さらにもう 1 つ再配置すると、この情報が確率

231
00:09:22,734 --> 00:09:25,680
の 2 を底とする負の対数であることが時々わかります。

232
00:09:25,680 --> 00:09:28,864
このように表現すると、初心者にとっては少し奇妙に見える

233
00:09:28,864 --> 00:09:32,049
かもしれませんが、実際には、自分の可能性を何回半減させ

234
00:09:32,049 --> 00:09:35,120
たかを尋ねるという非常に直感的なアイデアにすぎません。

235
00:09:35,120 --> 00:09:36,668
さて、疑問に思っている方は、私たちは単に

236
00:09:36,668 --> 00:09:38,216
楽しい言葉遊びをして いるだけだと思った

237
00:09:38,216 --> 00:09:39,920
のですが、なぜ対数が登場するのでしょうか?

238
00:09:39,920 --> 00:09:41,981
これがより優れた単元である理由の 1

239
00:09:41,981 --> 00:09:44,476
つは、非常に起こりそうもない出来事について話

240
00:09:44,476 --> 00:09:47,296
すのがはるかに簡単であり、これこれが発生する確率が

241
00:09:47,296 --> 00:09:49,574
0 であると言うよりも、観測 値に 20

242
00:09:49,574 --> 00:09:52,612
ビットの情報があると言う方がはるかに簡単であるためです。

243
00:09:52,612 --> 00:09:53,480
0000095。

244
00:09:53,480 --> 00:09:56,273
しかし、この対数表現が確率論への非常に有

245
00:09:56,273 --> 00:09:59,066
用な追加であることが 判明したより実質的

246
00:09:59,066 --> 00:10:02,000
な理由は、情報が加算される方法にあります。

247
00:10:02,000 --> 00:10:03,880
たとえば、1 つの観測結果から 2

248
00:10:03,880 --> 00:10:05,866
ビットの情報が得られ、スペースが 4

249
00:10:05,866 --> 00:10:08,164
ビット減り、その後、Wordle での 2

250
00:10:08,164 --> 00:10:11,090
番目の推測のような 2 番目 の観測により、さらに 3

251
00:10:11,090 --> 00:10:13,598
ビットの情報が得られ、さらに 8 分の 1 に

252
00:10:13,598 --> 00:10:16,001
削減された場合、 2 つを組み合わせると 5

253
00:10:16,001 --> 00:10:17,360
ビットの情報が得られます。

254
00:10:17,360 --> 00:10:21,200
確率が増加するのと同じように、情報は追加されるのを好みます。

255
00:10:21,200 --> 00:10:25,003
したがって、大量の数値を加算する期待値のような領域

256
00:10:25,003 --> 00:10:28,660
に入るとすぐに、ログのおかげで扱いやすくなります。

257
00:10:28,660 --> 00:10:30,960
Weary のディストリビューションに戻り、こ

258
00:10:30,960 --> 00:10:33,260
こに別の小さなトラッカ ーを追加して、各パター

259
00:10:33,260 --> 00:10:35,560
ンにどれだけの情報があるかを示してみましょう。

260
00:10:35,560 --> 00:10:38,206
ここで注目していただきたいのは、可能性の高いパタ

261
00:10:38,206 --> 00:10:40,853
ーンに到達する確率が高く なるほど、情報が少なく

262
00:10:40,853 --> 00:10:43,500
なり、得られるビットも少なくなるということです。

263
00:10:43,500 --> 00:10:47,454
この推測の質を測定する方法は、この情報の期待値を取得す

264
00:10:47,454 --> 00:10:51,267
ることです。各パターンを調べて、その確率がどれくらい

265
00:10:51,267 --> 00:10:54,940
かを示し、それを取得した情報のビット数で乗算します。

266
00:10:54,940 --> 00:10:56,710
そして、Weary の例では、それは

267
00:10:56,710 --> 00:10:58,480
4 であることがわかります。9ビット。

268
00:10:58,480 --> 00:11:00,835
したがって、平均すると、この冒頭の推測から

269
00:11:00,835 --> 00:11:03,079
得られる情報は、可能性 の空間を約 5

270
00:11:03,079 --> 00:11:05,660
回半分に切り分けるのと同じくらい優れています。

271
00:11:05,660 --> 00:11:09,629
対照的に、情報の期待値がより高い推測の例

272
00:11:09,629 --> 00:11:13,220
としては、Slate などがあります。

273
00:11:13,220 --> 00:11:16,180
この場合、分布がかなり平坦になっていることがわかります。

274
00:11:16,180 --> 00:11:19,716
特に、最も可能性の高いすべての灰色の発生確率は約

275
00:11:19,716 --> 00:11:22,969
6% しかないため、少 なくとも明らかに 3

276
00:11:22,969 --> 00:11:25,940
が得られることになります。9ビットの情報。

277
00:11:25,940 --> 00:11:27,540
しかし、これは最低限のことであり、通常は

278
00:11:27,540 --> 00:11:29,140
それよりも優れたものが得られるでしょう。

279
00:11:29,140 --> 00:11:32,711
この数字を計算して関連するすべての用語を合計すると

280
00:11:32,711 --> 00:11:36,420
、平均的な情報は約 5 であることがわかります。8.

281
00:11:36,420 --> 00:11:40,330
したがって、Weary とは対照的に、この最初の推

282
00:11:40,330 --> 00:11:43,940
測の後、可能性の空間は平均して約半分になります。

283
00:11:43,940 --> 00:11:49,540
実は、この情報量の期待値の名前については面白い話があります。

284
00:11:49,540 --> 00:11:52,410
情報理論は、1940 年代にベル研究所で働いていたクロード

285
00:11:52,410 --> 00:11:54,802
シャノンによって 開発されましたが、彼はまだ発表さ

286
00:11:54,802 --> 00:11:56,907
れていないアイデアのいくつかについて、当時

287
00:11:56,907 --> 00:11:58,821
の知的巨人で非常に著名なジョン フォン

288
00:11:58,821 --> 00:12:00,639
ノイマンと話し合っていました。数学と

289
00:12:00,639 --> 00:12:03,031
物理学、そしてコンピューターサイエンスになりつつあ

290
00:12:03,031 --> 00:12:04,180
ったものの始まりでした。

291
00:12:04,180 --> 00:12:07,814
そして、フォン・ノイマンは、この情報量の期待値にあまり良い

292
00:12:07,814 --> 00:12:11,327
名前がないと述べたとき、おそらく、それをエントロピーと呼

293
00:12:11,327 --> 00:12:14,720
ぶべきだ、と話は進みますが、その理由は 2 つあります。

294
00:12:14,720 --> 00:12:17,692
まず第一に、不確実性関数はその名前で統計力学で使用され

295
00:12:17,692 --> 00:12:19,894
ているため、すでに名 前が付いています。

296
00:12:19,894 --> 00:12:22,976
そして第二に、そしてさらに重要なことに、エントロピーが

297
00:12:22,976 --> 00:12:24,738
実際に何であるか誰も知りません。

298
00:12:24,738 --> 00:12:26,940
したがって、議論では常に利点があります。

299
00:12:26,940 --> 00:12:30,243
したがって、名前が少し謎めいているように見えても、

300
00:12:30,243 --> 00:12:33,420
この話を信じられるとしても、それは一種の仕様です。

301
00:12:33,420 --> 00:12:36,998
また、物理学の熱力学第 2 法則すべてとの関係について疑

302
00:12:36,998 --> 00:12:40,454
問に思っているなら、間違いなく関連性がありますが、その

303
00:12:40,454 --> 00:12:44,032
起源において、シャノンは純粋な確率論を扱っていただけであ

304
00:12:44,032 --> 00:12:47,488
り、ここでの目的のために、単語のエントロピーについては

305
00:12:47,488 --> 00:12:50,820
、特定の推測の期待される情報値を考えてほしいだけです。

306
00:12:50,820 --> 00:12:52,600
エントロピーは、2 つのものを同時

307
00:12:52,600 --> 00:12:54,380
に測定すると考えることができます。

308
00:12:54,380 --> 00:12:57,420
1 つ目は、分布がどの程度平坦であるかです。

309
00:12:57,420 --> 00:13:01,700
分布が均一に近づくほど、エントロピーは高くなります。

310
00:13:01,700 --> 00:13:04,697
私たちの場合、一様分布の場合、合計 3 から

311
00:13:04,697 --> 00:13:07,694
5 までのパターンがあり、それらのいずれかを

312
00:13:07,694 --> 00:13:10,952
観察すると、情報ログの底が 3 から 5 までの

313
00:13:10,952 --> 00:13:13,950
2 になり、これはたまたま 7 になり ます。

314
00:13:13,950 --> 00:13:17,860
92 なので、これがこのエントロピーの絶対最大値になります。

315
00:13:17,860 --> 00:13:20,494
しかし、エントロピーは、そもそもどれだけの可

316
00:13:20,494 --> 00:13:22,900
能性があるかを示す一種の尺度でもあります。

317
00:13:22,900 --> 00:13:25,157
たとえば、考えられるパターンが 16

318
00:13:25,157 --> 00:13:27,889
個しかなく、それぞれの可能性が等しい単語がた

319
00:13:27,889 --> 00:13:31,453
またまあった場合、このエントロピー、つまり期待される情報は

320
00:13:31,453 --> 00:13:32,760
4 ビットになります。

321
00:13:32,760 --> 00:13:35,425
しかし、64 個の考えられるパターンがあり、

322
00:13:35,425 --> 00:13:38,091
それらがすべて同じ確率で ある別の単語がある

323
00:13:38,091 --> 00:13:41,000
場合、エントロピーは 6 ビットになるでしょう。

324
00:13:41,000 --> 00:13:44,252
したがって、6 ビットのエントロピーを持つ分布を実

325
00:13:44,252 --> 00:13:47,634
際に目にした場合、 それは、同じ確率の結果が 64

326
00:13:47,634 --> 00:13:50,106
個存在するのと同じくらい、これから起

327
00:13:50,106 --> 00:13:53,359
こることには大きな変動と不確実性があると言っている

328
00:13:53,359 --> 00:13:54,400
ようなものです。

329
00:13:54,400 --> 00:13:56,380
Wurtelebot での最初のパス

330
00:13:56,380 --> 00:13:58,360
では、基本的にこれを行うだけでした。

331
00:13:58,360 --> 00:14:01,858
考えられるすべての推測 (13,000 語すべて)

332
00:14:01,858 --> 00:14:05,626
を調べ、各単語のエ ントロピー、より具体的には、表示され

333
00:14:05,626 --> 00:14:07,914
る可能性のあるすべてのパターンに

334
00:14:07,914 --> 00:14:11,682
わたる分布のエントロピーを単語ごとに計算し、最も高いもの

335
00:14:11,682 --> 00:14:15,450
を選択します 。それはあなたの可能性の空間を可能な限り切

336
00:14:15,450 --> 00:14:17,200
り詰める可能性があります。

337
00:14:17,200 --> 00:14:19,533
ここでは最初の推測についてのみ話しましたが、次の

338
00:14:19,533 --> 00:14:21,680
いくつかの推測についても同じことが起こります。

339
00:14:21,680 --> 00:14:24,307
たとえば、最初の推測について何らかのパターンがあ

340
00:14:24,307 --> 00:14:26,935
り、それに一致す るものに基づいて候補となる単語

341
00:14:26,935 --> 00:14:28,905
の数が制限されることがわかったら、

342
00:14:28,905 --> 00:14:31,533
その小さな単語のセットに関して同じゲームをプレイ

343
00:14:31,533 --> 00:14:32,300
するだけです。

344
00:14:32,300 --> 00:14:35,530
提案された 2 番目の推測では、より限定された単語

345
00:14:35,530 --> 00:14:38,760
のセットから発生す る可能性のあるすべてのパターン

346
00:14:38,760 --> 00:14:41,215
の分布を調べ、13,000 の可能性

347
00:14:41,215 --> 00:14:44,446
すべてを検索し、そのエントロピーを最大化するパター

348
00:14:44,446 --> 00:14:45,480
ンを見つけます。

349
00:14:45,480 --> 00:14:48,262
これが実際にどのように機能するかを示すために、余

350
00:14:48,262 --> 00:14:50,929
白にこの分析のハイライトを 示す、私が書いた

351
00:14:50,929 --> 00:14:54,060
Wurtele の小さな変形版を取り出してみましょう。

352
00:14:54,060 --> 00:14:57,336
すべてのエントロピー計算を行った後、右側には、

353
00:14:57,336 --> 00:15:00,340
期待される情報が最も高いものを示しています。

354
00:15:00,340 --> 00:15:03,940
少なくとも現時点でのトップの答えは、後ほど詳し

355
00:15:03,940 --> 00:15:06,757
く説明しますが、Tar es です。

356
00:15:06,757 --> 00:15:11,140
つまり、もちろん、レンゲ、最も一般的なレンゲのことです。

357
00:15:11,140 --> 00:15:13,869
ここで推測するたびに、私はスレートが好きなので、推奨事項

358
00:15:13,869 --> 00:15:16,598
を無視してスレ ートを使用することになるのですが、そこに

359
00:15:16,598 --> 00:15:18,157
どれだけの期待情報が含まれてい

360
00:15:18,157 --> 00:15:20,886
るかがわかりますが、ここの単語の右側には、どれだけの情報

361
00:15:20,886 --> 00:15:22,543
が含まれている かが表示されます。

362
00:15:22,543 --> 00:15:24,980
この特定のパターンを考慮して、実際に得られた情報。

363
00:15:24,980 --> 00:15:26,675
つまり、ここでは少し不運だったようです。

364
00:15:26,675 --> 00:15:28,371
5 を獲得することが期待されていました。

365
00:15:28,371 --> 00:15:30,660
8 ですが 、たまたまそれ以下のものが入手できました。

366
00:15:30,660 --> 00:15:33,378
そして左側には、私たちが今いる場所で考えられ

367
00:15:33,378 --> 00:15:35,860
るさまざまな単語がすべて表示されています。

368
00:15:35,860 --> 00:15:38,620
青いバーは各単語がどの程度の確率で考えられるかを示

369
00:15:38,620 --> 00:15:41,380
しているため、現時点では 各単語が出現する可能性が

370
00:15:41,380 --> 00:15:44,140
等しいと仮定していますが、これはすぐに修正します。

371
00:15:44,140 --> 00:15:47,027
そして、この不確実性の測定により、考えられる単

372
00:15:47,027 --> 00:15:50,291
語全体にわたるこ の分布のエントロピーがわかります。

373
00:15:50,291 --> 00:15:53,178
これは、現時点では一様分布で あるため、可能性

374
00:15:53,178 --> 00:15:55,940
の数を数える不必要に複雑な方法にすぎません。

375
00:15:55,940 --> 00:15:58,897
たとえば、2 の 13 乗を取るとします。

376
00:15:58,897 --> 00:16:02,700
66、それは約 13,000 の可能性があるはずです。

377
00:16:02,700 --> 00:16:04,740
ここでは少しずれていますが、それは小数点

378
00:16:04,740 --> 00:16:06,780
以下の桁をすべて表示していないためです。

379
00:16:06,780 --> 00:16:08,723
現時点では、それは冗長で、物事が過度に複雑であ

380
00:16:08,723 --> 00:16:10,667
るように感じるかもしれま せんが、両方の数値を

381
00:16:10,667 --> 00:16:12,780
取得することがなぜ便利であるかはすぐにわかります。

382
00:16:12,780 --> 00:16:15,057
したがって、ここでは、2 番目の推測で最もエントロピ

383
00:16:15,057 --> 00:16:17,334
ーが高いのはラーメンである ことを示唆しているように

384
00:16:17,334 --> 00:16:19,700
見えますが、これも本当に言葉のようには感じられません。

385
00:16:19,700 --> 00:16:23,327
そこで、ここで道徳的な立場を強調するために、先に進んで

386
00:16:23,327 --> 00:16:25,660
Rains と入力することにします。

387
00:16:25,660 --> 00:16:27,540
そしてまた少し不運だったようです。

388
00:16:27,540 --> 00:16:30,315
私たちは4を期待していました。3 ビットありますが、3

389
00:16:30,315 --> 00:16:32,100
つしかありません。39ビットの情報。

390
00:16:32,100 --> 00:16:35,060
つまり、55 の可能性が考えられます。

391
00:16:35,060 --> 00:16:37,673
そしてここでは、それが何を意味するにせよ、実際にそれが示唆

392
00:16:37,673 --> 00:16:40,200
しているもの、つまりコンボに従うことになるかもしれません。

393
00:16:40,200 --> 00:16:43,300
さて、これは実際、パズルを解く良い機会です。

394
00:16:43,300 --> 00:16:46,118
このパターンでは 4 が得られることがわかります。

395
00:16:46,118 --> 00:16:47,020
7ビットの情報。

396
00:16:47,020 --> 00:16:49,772
しかし、左側では、そのパターンが見える前に

397
00:16:49,772 --> 00:16:52,400
5 つありました。78 ビットの不確実性。

398
00:16:52,400 --> 00:16:54,572
それで、あなたへのクイズですが、残りの

399
00:16:54,572 --> 00:16:56,860
可能性の数については何を意味しますか?

400
00:16:56,860 --> 00:17:00,400
これは、不確実性が 1 つまで減少したことを意味します。

401
00:17:00,400 --> 00:17:02,423
これは 、考えられる答えが 2

402
00:17:02,423 --> 00:17:04,700
つあると言っているのと同じことです。

403
00:17:04,700 --> 00:17:06,520
それは五分五分の選択だ。

404
00:17:06,520 --> 00:17:08,912
ここからは、あなたも私もどちらの単語がより一般的である

405
00:17:08,912 --> 00:17:11,220
かを知っているので、答えは深淵であることがわかります。

406
00:17:11,220 --> 00:17:12,344
しかし、現時点で書かれているよう

407
00:17:12,344 --> 00:17:13,540
に、プログラムはそれを知りません。

408
00:17:13,540 --> 00:17:17,007
したがって、可能性が 1 つだけ残されるまで、できるだけ多

409
00:17:17,007 --> 00:17:20,360
くの情報を取得しようと試み続け、その後、それを推測します。

410
00:17:20,360 --> 00:17:22,700
したがって、明らかに、より良い終盤戦略が必要です。

411
00:17:22,700 --> 00:17:25,380
しかし、このバージョンを Wordle ソルバーの

412
00:17:25,380 --> 00:17:28,060
1 つと呼び、それがどのよ うに機能するかを確認する

413
00:17:28,060 --> 00:17:30,740
ためにいくつかのシミュレーションを実行するとします。

414
00:17:30,740 --> 00:17:32,456
つまり、これがどのように機能しているかというと、考え

415
00:17:32,456 --> 00:17:34,240
られるすべての単語ゲームを実行しているということです。

416
00:17:34,240 --> 00:17:36,716
実際の Wordle の回答である

417
00:17:36,716 --> 00:17:38,780
2315 語すべてを調べます。

418
00:17:38,780 --> 00:17:41,340
基本的にはそれをテストセットとして使用します。

419
00:17:41,340 --> 00:17:44,674
そして、単語がどれだけ一般的であるかを考慮せず、ただ

420
00:17:44,674 --> 00:17:47,639
1 つの選択肢に行き 着くまで、途中の各ステップ

421
00:17:47,639 --> 00:17:50,480
で情報を最大化しようとするこの単純な方法です。

422
00:17:50,480 --> 00:17:53,519
シミュレーションが終了するまでに、平均スコアは約

423
00:17:53,519 --> 00:17:55,100
4 になります。124.

424
00:17:55,100 --> 00:17:57,388
それは悪いことではありませんが、正直に言うと

425
00:17:57,388 --> 00:17:59,780
、私はもっと悪いことをすると予想していました。

426
00:17:59,780 --> 00:18:01,806
しかし、ワードルをプレイしている人は、通常は

427
00:18:01,806 --> 00:18:03,040
4 で取得できると言います。

428
00:18:03,040 --> 00:18:05,260
本当の課題は、3 つをできるだけ多く獲得することです。

429
00:18:05,260 --> 00:18:08,920
スコア 4 とスコア 3 の間ではかなり大きな差があります。

430
00:18:08,920 --> 00:18:13,592
ここでの明らかに簡単な成果は、単語が一般的

431
00:18:13,592 --> 00:18:18,487
かどうかを何らかの方法 で組み込むことです。

432
00:18:18,487 --> 00:18:23,160
また、それを具体的にどのように行うかです。

433
00:18:23,160 --> 00:18:25,920
私がこれにアプローチした方法は、英語のすべて

434
00:18:25,920 --> 00:18:28,560
の単語の相対頻度のリストを取得することです。

435
00:18:28,560 --> 00:18:29,811
そして、Mathematica

436
00:18:29,811 --> 00:18:31,218
の単語頻度データ関数を使用しました。

437
00:18:31,218 --> 00:18:33,564
この関数自体は、Go ogle Books English

438
00:18:33,564 --> 00:18:35,520
Ngram 公開データセットから取得したものです。

439
00:18:35,520 --> 00:18:37,866
たとえば、最も一般的な単語から最も一般的ではない

440
00:18:37,866 --> 00:18:40,120
単語まで並べ替えると、見ていてとても楽しいです。

441
00:18:40,120 --> 00:18:43,740
明らかに、これらは英語で最も一般的な 5 文字の単語です。

442
00:18:43,740 --> 00:18:46,480
というか、これらは8番目に多いものです。

443
00:18:46,480 --> 00:18:49,440
最初にどれがあり、その後にあそことあそこがあります。

444
00:18:49,440 --> 00:18:51,448
first 自体は first ではなく 9th

445
00:18:51,448 --> 00:18:53,778
であり、これらの他の単語がよ り頻繁に出現する可能性がある

446
00:18:53,778 --> 00:18:56,027
ことは理にかなっていますが、first の後の単語 は

447
00:18:56,027 --> 00:18:58,357
after、where、そしてそれらの単語は少しだけ一般的

448
00:18:58,357 --> 00:18:59,000
ではありません。

449
00:18:59,000 --> 00:19:01,548
さて、このデータを使用して、これらの各単語が

450
00:19:01,548 --> 00:19:04,096
最終的な答えとなる可能 性をモデル化する場合

451
00:19:04,096 --> 00:19:06,760
、単に頻度に比例するだけであってはなりません。

452
00:19:06,760 --> 00:19:08,646
たとえば、スコア 0 が与えられます。

453
00:19:08,646 --> 00:19:11,029
このデータセットでは 002 が使用されますが

454
00:19:11,029 --> 00:19:13,809
、braid という単語はある意味で約 1000 分の

455
00:19:13,809 --> 00:19:15,200
1 の可能性が低くなります。

456
00:19:15,200 --> 00:19:17,300
しかし、これらは両方とも十分に一般的な単語で

457
00:19:17,300 --> 00:19:19,400
あるため、ほぼ確実に検討する価値があります。

458
00:19:19,400 --> 00:19:20,650
したがって、バイナリのカットオフ

459
00:19:20,650 --> 00:19:21,900
をさらに強化する必要があります。

460
00:19:21,900 --> 00:19:25,147
私がこれに取り組んだ方法は、このソートされた単語のリス

461
00:19:25,147 --> 00:19:28,395
ト全体を取得し、 それを X 軸上に配置し、シグモイド

462
00:19:28,395 --> 00:19:30,440
関数を適用することです。これは、

463
00:19:30,440 --> 00:19:34,049
出力が基本的にバイナリである関数を作成する標準的な方法です。

464
00:19:34,049 --> 00:19:37,297
0 か 1 のどちらかですが、その不確実性の領域の間で

465
00:19:37,297 --> 00:19:38,500
平滑化が行われます。

466
00:19:38,500 --> 00:19:42,180
つまり、基本的に、最終リストに含まれる各単

467
00:19:42,180 --> 00:19:45,860
語に割り当てる確率は 、x 軸上のどこに位

468
00:19:45,860 --> 00:19:49,540
置する上記のシグモイド関数の値になります。

469
00:19:49,540 --> 00:19:52,145
これは明らかにいくつかのパラメータに依存します。

470
00:19:52,145 --> 00:19:54,099
たとえば、これらの単語が占める x

471
00:19:54,099 --> 00:19:56,378
軸上のスペースの幅によって、1 から 0

472
00:19:56,378 --> 00:19:58,549
への降下がどの程度徐々にまたは急激に変

473
00:19:58,549 --> 00:20:01,154
化するかが決まり、単語を左から右のどこに配置する

474
00:20:01,154 --> 00:20:03,000
かによってカットオフが決まります。

475
00:20:03,000 --> 00:20:05,170
正直に言うと、私がこれを行った方法は

476
00:20:05,170 --> 00:20:07,340
、指をなめて風に突き刺すだけでした。

477
00:20:07,340 --> 00:20:10,826
私はソートされたリストを調べて、これらの単語の約半分が最

478
00:20:10,826 --> 00:20:14,313
終的な答えになる可能性が高いと判断できる範囲を見つけよう

479
00:20:14,313 --> 00:20:17,680
としました。そして、それをカットオフとして使用しました。

480
00:20:17,680 --> 00:20:21,205
単語全体でこのような分布が得られると、エントロピー

481
00:20:21,205 --> 00:20:24,460
が非常に有用な測定値となる別の状況が得られます。

482
00:20:24,460 --> 00:20:27,644
たとえば、ゲームをプレイしていて、羽と爪だった古

483
00:20:27,644 --> 00:20:30,829
いオープナーから始めて、それに一致する可能性のあ

484
00:20:30,829 --> 00:20:33,760
る単語が 4 つある状況に行き着いたとします。

485
00:20:33,760 --> 00:20:36,440
そして、それらはすべて同じ可能性であると考えてみましょう。

486
00:20:36,440 --> 00:20:40,000
この分布のエントロピーはいくらですか?

487
00:20:40,000 --> 00:20:43,502
さて、これらの可能性のそれぞれに関連付けられた情

488
00:20:43,502 --> 00:20:46,859
報は、それぞれが 1 と 4 であり、それが

489
00:20:46,859 --> 00:20:50,800
2 であるため、4 の底を 2 とする対数になります。

490
00:20:50,800 --> 00:20:52,780
2 ビットの情報、4 つの可能性。

491
00:20:52,780 --> 00:20:54,360
すべてとても順調です。

492
00:20:54,360 --> 00:20:56,340
しかし、実際には 4 つ以上の試合が

493
00:20:56,340 --> 00:20:58,320
あると言ったらどうなるでしょうか?

494
00:20:58,320 --> 00:21:01,586
実際、完全な単語リストに目を通すと、それに一致する単語が

495
00:21:01,586 --> 00:21:02,600
16 個あります。

496
00:21:02,600 --> 00:21:04,866
しかし、私たちのモデルでは、他の 12

497
00:21:04,866 --> 00:21:07,133
単語が実際に最終的な答えになる確率は非

498
00:21:07,133 --> 00:21:10,080
常に低く、非常に曖昧であるため、1000 分の 1

499
00:21:10,080 --> 00:21:11,440
程度であると仮定します。

500
00:21:11,440 --> 00:21:15,480
さて、この分布のエントロピーはいくらでしょうか?

501
00:21:15,480 --> 00:21:18,160
ここでエントロピーが純粋に一致の数を測定している場

502
00:21:18,160 --> 00:21:20,840
合、それは 16 の底 2 の対数のようなものにな

503
00:21:20,840 --> 00:21:23,198
ると予想されるかもしれません。こ れは 4

504
00:21:23,198 --> 00:21:26,200
となり、以前よりも 2 ビット多くの不確実性が生じます。

505
00:21:26,200 --> 00:21:28,193
しかし、もちろん、実際の不確実

506
00:21:28,193 --> 00:21:30,320
性は以前とそれほど変わりません。

507
00:21:30,320 --> 00:21:32,095
これらの本当にあいまいな 12

508
00:21:32,095 --> 00:21:34,315
の単語があるからといって、たとえば、最

509
00:21:34,315 --> 00:21:36,868
終的な答えが魅力であると知っても、それほど驚く

510
00:21:36,868 --> 00:21:38,200
べきことではありません。

511
00:21:38,200 --> 00:21:42,016
したがって、ここで実際に計算を実行し、各発生の確率と対応す

512
00:21:42,016 --> 00:21:45,196
る情報を合計すると、得られる値は 2 になります。

513
00:21:45,196 --> 00:21:45,960
11ビット。

514
00:21:45,960 --> 00:21:48,824
私が言いたいのは、基本的には 2 つのビット、基本的には

515
00:21:48,824 --> 00:21:51,589
4 つの可能性で すが、これらの非常にありそうもない出来

516
00:21:51,589 --> 00:21:54,058
事がすべてあるため、もう少し不確実性 があります。

517
00:21:54,058 --> 00:21:56,823
ただし、それらを学べば、そこから大量の情報が得られるでし

518
00:21:56,823 --> 00:21:57,120
ょう。

519
00:21:57,120 --> 00:21:59,553
ズームアウトすると、これが Wordle が情報理

520
00:21:59,553 --> 00:22:01,800
論のレッスンに最適な例となる理由の 1 つです。

521
00:22:01,800 --> 00:22:03,366
エントロピーについては、これら 2

522
00:22:03,366 --> 00:22:05,280
つの異なる感覚のアプリケーションがあります。

523
00:22:05,280 --> 00:22:09,061
1 つ目は、与えられた推測から得られる期待情報は何

524
00:22:09,061 --> 00:22:12,843
かを示し、2 つ目は、考えられるすべての単語の中で

525
00:22:12,843 --> 00:22:16,480
残っている不確実性を測定できるかどうかを示します。

526
00:22:16,480 --> 00:22:19,284
そして、強調しておきたいのは、推測の期待情報を調べる

527
00:22:19,284 --> 00:22:22,088
最初のケースでは、単語の重 み付けが不均等になると、

528
00:22:22,088 --> 00:22:25,000
それがエントロピーの計算に影響を与えるということです。

529
00:22:25,000 --> 00:22:28,223
たとえば、Weary に関連する分布について以前に検討し

530
00:22:28,223 --> 00:22:30,446
たのと同じケースを取り出してみましょう。

531
00:22:30,446 --> 00:22:33,559
ただし、今回はす べての可能な単語にわたって不均一な分布

532
00:22:33,559 --> 00:22:34,560
を使用しています。

533
00:22:34,560 --> 00:22:36,898
それでは、それをうまく説明している部分

534
00:22:36,898 --> 00:22:39,360
がここに見つかるかどうか見てみましょう。

535
00:22:39,360 --> 00:22:42,480
さて、これはかなり良いです。

536
00:22:42,480 --> 00:22:44,813
ここでは、ほぼ同じ確率の 2 つの隣接するパターン

537
00:22:44,813 --> 00:22:47,146
がありますが、そのうちの 1 つは、それに一致する

538
00:22:47,146 --> 00:22:49,480
可能性のある単語が 32 個あると言われています。

539
00:22:49,480 --> 00:22:51,714
それらが何であるかを確認してみると、これらは

540
00:22:51,714 --> 00:22:53,754
32 個であり、 目をざっと眺めると、どれ

541
00:22:53,754 --> 00:22:55,600
も非常にありそうもない単語ばかりです。

542
00:22:55,600 --> 00:22:58,464
もっともらしい答え、おそらく叫び声のようなものを見つ

543
00:22:58,464 --> 00:23:01,328
けるのは難し いですが、ほぼ同じ確率であると考えられ

544
00:23:01,328 --> 00:23:04,412
る分布内の隣接するパターン を見ると、一致する可能性は

545
00:23:04,412 --> 00:23:07,056
8 つしかないと言われているため、4 分の 1

546
00:23:07,056 --> 00:23:09,920
は多くの試合がありますが、その可能性はほぼ同じです。

547
00:23:09,920 --> 00:23:12,520
それらの一致を調べてみると、その理由がわかります。

548
00:23:12,520 --> 00:23:15,111
これらの中には、リング、怒り、ラップな

549
00:23:15,111 --> 00:23:17,840
ど、実際にもっともらしい答えもあります。

550
00:23:17,840 --> 00:23:20,608
これらすべてをどのように組み込むかを説明するために、ここで

551
00:23:20,608 --> 00:23:23,191
Wordlebot のバージ ョン 2 を取り上げます。

552
00:23:23,191 --> 00:23:25,960
最初に見たものとの主な違いが 2 つまたは 3 つあります。

553
00:23:25,960 --> 00:23:29,295
まず、先ほど述べたように、これらのエントロピー、

554
00:23:29,295 --> 00:23:32,630
つまり情報の期待 値を計算する方法では、特定の単

555
00:23:32,630 --> 00:23:34,992
語が実際に答えとなる確率を組み込

556
00:23:34,992 --> 00:23:38,327
んだ、パターン全体にわたるより洗練された分布を使

557
00:23:38,327 --> 00:23:39,300
用しています。

558
00:23:39,300 --> 00:23:41,667
偶然にも、涙が依然としてナンバー 1

559
00:23:41,667 --> 00:23:44,160
ですが、それに続くものは少し異なります。

560
00:23:44,160 --> 00:23:48,000
第 2 に、上位の候補をランク付けするときに、

561
00:23:48,000 --> 00:23:51,840
各単語が実際の答えである確率のモデルを保持し、

562
00:23:51,840 --> 00:23:55,520
それを決定に組み込むようになります。テーブル。

563
00:23:55,520 --> 00:23:58,320
繰り返しますが、私たちは機械に生活を支配させ

564
00:23:58,320 --> 00:24:01,120
ることはできないので、その推奨を無視します。

565
00:24:01,120 --> 00:24:04,106
そして、ここでもう 1 つ異なる点があることを言及する

566
00:24:04,106 --> 00:24:07,093
必要があると思います。左側 は、不確実性の値、ビット数

567
00:24:07,093 --> 00:24:10,080
が、一致の可能性の数と重複するだけではなくなりました。

568
00:24:10,080 --> 00:24:13,496
これを引き上げて、2 対 8 を計算するとします。

569
00:24:13,496 --> 00:24:17,323
02、これは 256 を少し上回 る、おそらく 259

570
00:24:17,323 --> 00:24:20,603
です。これが言いたいのは、実際にこのパターンに

571
00:24:20,603 --> 00:24:24,430
一致する単語が合計 526 個あるとしても、その不確実性

572
00:24:24,430 --> 00:24:26,616
の量は、同 じ可能性の 259

573
00:24:26,616 --> 00:24:29,760
個があった場合の値に近いということです。結果。

574
00:24:29,760 --> 00:24:31,100
このように考えることができます。

575
00:24:31,100 --> 00:24:33,908
yorts、zorl、zorus の場合と同様に、borx

576
00:24:33,908 --> 00:24:36,155
が答えではな いことがわかっているため、前のケー

577
00:24:36,155 --> 00:24:37,840
スよりも不確実性が少し低くなります。

578
00:24:37,840 --> 00:24:40,220
このビット数は小さくなります。

579
00:24:40,220 --> 00:24:44,529
そして、ゲームをプレイし続けると、ここで説明したいこ

580
00:24:44,529 --> 00:24:48,680
とと適切ないくつかの推測を加えてこれを洗練させます。

581
00:24:48,680 --> 00:24:51,286
4 番目の推測では、その上位の候補を見てみると、もはや

582
00:24:51,286 --> 00:24:53,800
エントロピーを最大化するだけではないことがわかります。

583
00:24:53,800 --> 00:24:57,355
つまり、現時点では技術的には 7 つの可能性がありま

584
00:24:57,355 --> 00:25:00,780
すが、意味のあるチャンスがあるのは寮と言葉だけです。

585
00:25:00,780 --> 00:25:02,970
そして、これらの両方を選択すると、厳密に言

586
00:25:02,970 --> 00:25:05,160
えば、より多くの情報が 得られる他の値より

587
00:25:05,160 --> 00:25:07,560
も上位にランク付けされていることがわかります。

588
00:25:07,560 --> 00:25:09,598
初めてこれを行ったとき、これら 2

589
00:25:09,598 --> 00:25:12,202
つの数値を合計して各推測の 質を測定しました。

590
00:25:12,202 --> 00:25:14,580
実際、これは予想以上にうまく機能しました。

591
00:25:14,580 --> 00:25:16,683
しかし、それは実際には体系的とは思えませんでした。

592
00:25:16,683 --> 00:25:18,449
他のアプロー チもあるとは思いますが、私が

593
00:25:18,449 --> 00:25:19,880
たどり着いたアプローチはこれです。

594
00:25:19,880 --> 00:25:22,733
この場合の単語のように、次の推測の見通しを

595
00:25:22,733 --> 00:25:25,586
考慮している場合、本 当に関心があるのは、

596
00:25:25,586 --> 00:25:28,440
それを行った場合のゲームの予想スコアです。

597
00:25:28,440 --> 00:25:30,766
そして、その期待スコアを計算するために、単

598
00:25:30,766 --> 00:25:33,424
語が実際の答えである確 率はいくらかを言います。

599
00:25:33,424 --> 00:25:35,640
現時点では 58% と説明されています。

600
00:25:35,640 --> 00:25:40,400
58% の確率で、このゲームのスコアは 4 になるでしょう。

601
00:25:40,400 --> 00:25:44,395
そして、1 から 58% を引いた確率で、スコアは

602
00:25:44,395 --> 00:25:46,240
4 より大きくなります。

603
00:25:46,240 --> 00:25:48,431
それ以上はわかりませんが、その時点に到達し

604
00:25:48,431 --> 00:25:50,623
たときにどの程度の不確 実性が存在する可能

605
00:25:50,623 --> 00:25:52,920
性があるかに基づいて推定することはできます。

606
00:25:52,920 --> 00:25:56,600
具体的には、現時点では 1 です。44 ビットの不確実性。

607
00:25:56,600 --> 00:25:59,016
単語を推測すると、得られる期待情報が

608
00:25:59,016 --> 00:26:01,560
1 であることがわかります。27ビット。

609
00:26:01,560 --> 00:26:04,976
したがって、言葉を推測した場合、この違いは、それが起こった

610
00:26:04,976 --> 00:26:08,280
後にどの程度の不確実性が残る可能性があるかを表しています。

611
00:26:08,280 --> 00:26:11,180
必要なのは、この不確実性を期待されるスコアに関連付ける、

612
00:26:11,180 --> 00:26:13,880
ある種の関数 (ここでは f と呼んでいます) です。

613
00:26:13,880 --> 00:26:16,954
そして、これを行う方法は、ボットのバージョン 1

614
00:26:16,954 --> 00:26:20,152
に基づいて以前のゲー ムからの大量のデータをプロット

615
00:26:20,152 --> 00:26:22,735
して、特定の非常に測定可能な量の不確実性

616
00:26:22,735 --> 00:26:25,933
を伴うさまざまなポイント後の実際のスコアが何であるか

617
00:26:25,933 --> 00:26:27,040
を示すことでした。

618
00:26:27,040 --> 00:26:29,454
たとえば、これらのデータ ポイントは、8

619
00:26:29,454 --> 00:26:31,293
程度の値よりも上にあります。8

620
00:26:31,293 --> 00:26:34,741
人だった時点以降、いくつかの試合では7人ほどが発言している。

621
00:26:34,741 --> 00:26:37,845
7 ビットの不確 実性があり、最終的な答えを得るには

622
00:26:37,845 --> 00:26:39,340
2 回の推測が必要でした。

623
00:26:39,340 --> 00:26:41,932
他のゲームでは 3 回の推測が必要で、他のゲームでは

624
00:26:41,932 --> 00:26:43,180
4 回の推測が必要でした。

625
00:26:43,180 --> 00:26:46,037
ここで左にシフトすると、ゼロを超えるすべての

626
00:26:46,037 --> 00:26:49,025
点は、不確実性が ゼロの場合、つまり可能性が

627
00:26:49,025 --> 00:26:51,882
1 つしかない場合、必要な推測の 数は常に

628
00:26:51,882 --> 00:26:55,000
1 つだけであり、安心できることを示しています。

629
00:26:55,000 --> 00:26:57,880
少しでも不確実性がある場合、つまり、本質的に可能性が 2

630
00:26:57,880 --> 00:27:00,165
つ だけであることを意味する場合、さらに 1

631
00:27:00,165 --> 00:27:02,350
つの推測が必要な 場合もあれば、さらに 2

632
00:27:02,350 --> 00:27:03,940
つの推測が必要な場合もあります。

633
00:27:03,940 --> 00:27:05,980
などなど。

634
00:27:05,980 --> 00:27:08,444
このデータを視覚化するもう少し簡単な方法は、

635
00:27:08,444 --> 00:27:11,020
データをまとめて平均を取ることかもしれません。

636
00:27:11,020 --> 00:27:14,820
たとえば、このバーは、少し不確実性があったすべ

637
00:27:14,820 --> 00:27:19,446
てのポイントのうち、 必要な新しい推測の数は平均して約

638
00:27:19,446 --> 00:27:22,420
1 であることを示しています。5.

639
00:27:22,420 --> 00:27:25,184
そして、ここのバーは、さまざまなゲームすべての中で

640
00:27:25,184 --> 00:27:27,948
、ある時点で 不確実性が 4 ビットをわずかに上回

641
00:27:27,948 --> 00:27:30,380
っていたことを示していま す。これは、16

642
00:27:30,380 --> 00:27:32,923
の異なる可能性に絞り込むようなもので、その時

643
00:27:32,923 --> 00:27:36,240
点から平均して 2 つを少し超える推測が必要ですフォワード。

644
00:27:36,240 --> 00:27:38,160
ここからは、これに合理的と思われる関数

645
00:27:38,160 --> 00:27:40,080
を当てはめるために回帰を実行しました。

646
00:27:40,080 --> 00:27:43,221
そして、そのいずれかを行うことの要点は、単語から得られる情

647
00:27:43,221 --> 00:27:44,954
報が多ければ多いほど、期待され

648
00:27:44,954 --> 00:27:48,095
るスコアが低くなるという直感を定量化できるようにするためで

649
00:27:48,095 --> 00:27:49,720
あることを忘れないでください。

650
00:27:49,720 --> 00:27:52,306
ということで、これをバージョン2とします。

651
00:27:52,306 --> 00:27:55,509
0、戻って同じシミュレーション セットを実行し、2

652
00:27:55,509 --> 00:27:58,834
315 個の単語の答えすべてに対して実行すると、どうな

653
00:27:58,834 --> 00:27:59,820
るでしょうか?

654
00:27:59,820 --> 00:28:01,940
最初のバージョンと比べると明らかに

655
00:28:01,940 --> 00:28:04,060
良くなっているので、安心できます。

656
00:28:04,060 --> 00:28:06,282
全体的に見て平均は 3 程度です。

657
00:28:06,282 --> 00:28:08,636
ただし、最初のバージョンとは異なり

658
00:28:08,636 --> 00:28:11,512
、この状況では失われ、6 つ以上が必要になる

659
00:28:11,512 --> 00:28:12,820
ことが数回あります。

660
00:28:12,820 --> 00:28:15,952
おそらく、情報を最大化するのではなく、実際に目標を達成する

661
00:28:15,952 --> 00:28:18,980
ためにトレードオフが発生する場合があるからだと思われます。

662
00:28:18,980 --> 00:28:22,140
では、3よりもうまくできるでしょうか。6?

663
00:28:22,140 --> 00:28:23,260
間違いなくできます。

664
00:28:23,260 --> 00:28:26,744
さて、冒頭で、Wordle の回答の真のリストをモデル

665
00:28:26,744 --> 00:28:29,980
の構築方法に組み入れないのが最も楽しいと言いました。

666
00:28:29,980 --> 00:28:32,519
しかし、それを組み込んだ場合、得られる最高

667
00:28:32,519 --> 00:28:35,180
のパフォーマンスは 3 程度でした。43.

668
00:28:35,180 --> 00:28:37,975
したがって、この事前分布を選択するために単語頻度データを使用

669
00:28:37,975 --> 00:28:39,745
するだけではなく、より洗練されたもの

670
00:28:39,745 --> 00:28:41,794
にしようとすると、この 3.おそらく 43

671
00:28:41,794 --> 00:28:43,285
が、これでどれだけうまくできる

672
00:28:43,285 --> 00:28:46,080
か、少なくともどれくらいうまくできるかという最大値を示してい

673
00:28:46,080 --> 00:28:46,360
ます。

674
00:28:46,360 --> 00:28:48,685
その最高のパフォーマンスは、基本的には私がここ

675
00:28:48,685 --> 00:28:51,010
で話してきたア イデアを使用しているだけですが

676
00:28:51,010 --> 00:28:53,132
、期待される情報を 1 歩では なく 2

677
00:28:53,132 --> 00:28:55,660
歩前進して検索するなど、さらに一歩進んだものです。

678
00:28:55,660 --> 00:28:58,170
当初はそれについてもっと話すつもりでしたが、実際

679
00:28:58,170 --> 00:29:00,580
にはかなり長くなってしまったことに気づきました。

680
00:29:00,580 --> 00:29:02,788
私が言えるのは、この 2 段階の検索を行った後、上位

681
00:29:02,788 --> 00:29:04,997
候補でいくつかのサ ンプル シミュレーションを実行し

682
00:29:04,997 --> 00:29:07,291
た結果、少なくとも私にとって今のとこ ろ、Crane

683
00:29:07,291 --> 00:29:09,500
が最良のオープナーであるように見えるということです。

684
00:29:09,500 --> 00:29:11,080
誰が予想したでしょうか？

685
00:29:11,080 --> 00:29:13,360
また、真の Wordle リストを使用して可

686
00:29:13,360 --> 00:29:15,743
能性の空間を決定する場 合、最初の不確実性は

687
00:29:15,743 --> 00:29:17,920
11 ビットをわずかに超える値になります。

688
00:29:17,920 --> 00:29:22,399
そして、総当たり検索から、最初の 2 つの推測の後に予想さ

689
00:29:22,399 --> 00:29:26,580
れる最大情報は約 10 ビットであることがわかりました。

690
00:29:26,580 --> 00:29:29,048
これは、最良のシナリオでは、最初の 2

691
00:29:29,048 --> 00:29:32,257
つの推測の後、完全に最適なプレ イを行った場合、約

692
00:29:32,257 --> 00:29:35,220
1 ビットの不確実性が残ることを示唆しています。

693
00:29:35,220 --> 00:29:37,400
これは、可能な推測が 2 つに絞られるのと同じです。

694
00:29:37,400 --> 00:29:40,617
したがって、この平均を 3 という低い値にするアルゴリズム

695
00:29:40,617 --> 00:29:43,834
を作成することは 不可能である、と言うのは公平であり、おそ

696
00:29:43,834 --> 00:29:45,720
らくかなり保守的だと思います。な

697
00:29:45,720 --> 00:29:47,939
ぜなら、利用可能な単語では、たった 2

698
00:29:47,939 --> 00:29:51,046
つのステップで十分な情報を取得す る余地がないからです。

699
00:29:51,046 --> 00:29:53,820
毎回必ず 3 番目のスロットの答えを保証できます。

