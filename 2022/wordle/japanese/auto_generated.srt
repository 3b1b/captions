1
00:00:00,000 --> 00:00:03,027
Wurdle というゲームは、ここ 1 ～ 

2
00:00:03,027 --> 00:00:05,366
2 か月でかなり話題になりました。

3
00:00:05,366 --> 00:00:08,118
数学の授業の 機会を見逃す人はいません。

4
00:00:08,118 --> 00:00:11,283
このゲームは、情報理 論、特にエントロピーとし

5
00:00:11,283 --> 00:00:12,660
て知られるトピック。

6
00:00:13,920 --> 00:00:16,496
多くの人と同じように、私もパズルに夢中になりました。

7
00:00:16,496 --> 00:00:19,370
また、 多くのプログラマーと同じように、私もゲームを可能な

8
00:00:19,370 --> 00:00:22,244
限り最適 にプレイするアルゴリズムを作成することに夢中にな

9
00:00:22,244 --> 00:00:22,740
りました。

10
00:00:23,180 --> 00:00:25,843
ここで私がやろうと思ったのは、アルゴリズム全体がこのエン 

11
00:00:25,843 --> 00:00:28,507
トロピーの考え方に中心を置いているため、そのプロセスの一 

12
00:00:28,507 --> 00:00:31,080
部を話し、それに使用された数学の一部を説明することです。

13
00:00:38,700 --> 00:00:40,170
まず最初に、Wurdle について聞いたことがない場

14
00:00:40,170 --> 00:00:41,640
合のために説明します。Wurdle とは何ですか? 

15
00:00:42,040 --> 00:00:44,244
そして、ここでゲームのルールを確認しながら一石二

16
00:00:44,244 --> 00:00:46,448
鳥にするために、 今後の展開についてもプレビュー

17
00:00:46,448 --> 00:00:48,101
させていただきます。これは、基本的 

18
00:00:48,101 --> 00:00:50,305
にゲームをプレイするための小さなアルゴリズムを開

19
00:00:50,305 --> 00:00:51,040
発することです。

20
00:00:51,360 --> 00:00:53,076
私は今日の Wurdle を実行していませんが、これは 

21
00:00:53,076 --> 00:00:54,302
2 月 4 日なので、ボットがどのように

22
00:00:54,302 --> 00:00:55,100
動作するか見てみましょう。

23
00:00:55,480 --> 00:00:58,003
Wurdle の目的は、謎の 5 文字の単語を推測す 

24
00:00:58,003 --> 00:01:00,340
ることであり、推測する機会が 6 回与えられます。

25
00:01:00,840 --> 00:01:02,562
たとえば、Wurdle ボットは、推

26
00:01:02,562 --> 00:01:04,379
測クレーンから始めることを提案します。

27
00:01:05,180 --> 00:01:07,758
推測するたびに、その推測が真の答えにどの程 

28
00:01:07,758 --> 00:01:10,220
度近づいているかに関する情報が得られます。

29
00:01:10,920 --> 00:01:12,552
ここで灰色のボックスは、実際の答えに 

30
00:01:12,552 --> 00:01:14,100
C が存在しないことを示しています。

31
00:01:14,520 --> 00:01:16,180
黄色のボックスは R があることを示

32
00:01:16,180 --> 00:01:17,840
していますが、その位置にありません。

33
00:01:18,240 --> 00:01:20,282
緑色のボックスは、秘密の単語に A があり、そ 

34
00:01:20,282 --> 00:01:22,240
れが 3 番目の位置にあることを示しています。

35
00:01:22,720 --> 00:01:24,580
そして、NもEもありません。

36
00:01:25,200 --> 00:01:26,332
それでは、早速入って、Wurdle 

37
00:01:26,332 --> 00:01:27,340
ボットにその情報を伝えましょう。

38
00:01:27,340 --> 00:01:28,781
クレーンから始まり、灰色、黄色

39
00:01:28,781 --> 00:01:30,320
、緑色、灰色、灰色になりました。

40
00:01:31,420 --> 00:01:33,144
現在表示されているすべてのデータについては心配し

41
00:01:33,144 --> 00:01:34,940
ないでください。それについては、やがて説明します。

42
00:01:35,460 --> 00:01:38,820
しかし、2番目に選ぶ一番の提案は「クソ」です。

43
00:01:39,560 --> 00:01:42,535
推測は実際の 5 文字の単語である必要がありますが、 

44
00:01:42,535 --> 00:01:45,400
ご覧のとおり、実際に推測できる内容はかなり自由です。

45
00:01:46,200 --> 00:01:47,440
この場合、shtick を試します。

46
00:01:48,780 --> 00:01:50,180
さて、状況はかなり良いようです。

47
00:01:50,260 --> 00:01:51,924
S と H を押すと、最初の 3 

48
00:01:51,924 --> 00:01:53,980
文字がわかり、R があることがわかります。

49
00:01:53,980 --> 00:01:56,340
そして、それは SHA 何か R 、または 

50
00:01:56,340 --> 00:01:58,700
SHA R 何かのようなものになるでしょう。

51
00:01:59,620 --> 00:02:02,026
そして、Wurdle ボットは、シャードかシャー 

52
00:02:02,026 --> 00:02:04,240
プの 2 つの可能性だけを知っているようです。

53
00:02:05,100 --> 00:02:06,708
現時点ではどちらを選択するか迷っているよう

54
00:02:06,708 --> 00:02:08,317
なものなので、おそらく アルファベット順と

55
00:02:08,317 --> 00:02:10,080
いうだけでシャードに当てはまるのだと思います。

56
00:02:11,220 --> 00:02:12,860
実際の答えはどれでしょう。

57
00:02:12,960 --> 00:02:13,780
それで、3つで解決しました。

58
00:02:14,600 --> 00:02:16,492
それがいいのかどうか疑問に思っているなら、私が

59
00:02:16,492 --> 00:02:18,385
聞いたある人のフレーズで は、ワールドルでは 

60
00:02:18,385 --> 00:02:20,360
4 つがパー、3 つがバーディだということです。

61
00:02:20,680 --> 00:02:22,480
これは非常に適切な例えだと思います。

62
00:02:22,480 --> 00:02:24,705
4 つを獲得するには、一貫してゲームに取り組む必要

63
00:02:24,705 --> 00:02:27,020
がありますが、それは確かにクレイジーではありません。

64
00:02:27,180 --> 00:02:29,920
しかし、3つになると、本当に素晴らしい気分になります。

65
00:02:30,880 --> 00:02:32,531
それで、もしあなたがそれに興味がないなら、私がここで

66
00:02:32,531 --> 00:02:34,182
やりたいことは、Wurdle ボットへのアプローチ方

67
00:02:34,182 --> 00:02:35,960
法についての私の思考プロセスを最初から説明することです。

68
00:02:36,480 --> 00:02:37,917
先ほども言いましたが、実際には、こ

69
00:02:37,917 --> 00:02:39,440
れは情報理論のレッスンの言い訳です。

70
00:02:39,740 --> 00:02:41,233
主な目標は、情報とは何か、エント

71
00:02:41,233 --> 00:02:42,820
ロピーとは何かを説明することです。

72
00:02:48,220 --> 00:02:51,068
これに取り組むにあたって私が最初に考えたのは、英語におけ 

73
00:02:51,068 --> 00:02:53,720
るさまざまな文字の相対的な頻度を調べてみることでした。

74
00:02:54,380 --> 00:02:56,006
そこで私は、これらの最も頻繁に使用される文

75
00:02:56,006 --> 00:02:57,633
字の多くに当てはまる 冒頭の推測または冒頭

76
00:02:57,633 --> 00:02:59,260
の推測のペアはあるだろうか、と考えました。

77
00:02:59,960 --> 00:03:01,441
そして、私がとても気に入っていたのは、

78
00:03:01,441 --> 00:03:03,000
ネイルに続いて他のことをすることでした。

79
00:03:03,760 --> 00:03:05,738
文字を打つと、緑か黄色が出ると、いつで 

80
00:03:05,738 --> 00:03:07,520
も気分が良くなる、という考え方です。

81
00:03:07,520 --> 00:03:08,840
情報が入ってくる感じです。

82
00:03:09,340 --> 00:03:12,119
ただし、このような場合、たとえヒットせず、常にグレーが表示 

83
00:03:12,119 --> 00:03:14,805
されたとしても、これらの文字を含まない単語を見つけること 

84
00:03:14,805 --> 00:03:17,400
は非常にまれであるため、それでも多くの情報が得られます。

85
00:03:18,140 --> 00:03:20,818
しかし、それでも、これはあまり体系的とは思えません 。

86
00:03:20,818 --> 00:03:23,200
たとえば、文字の順序は考慮されていないからです。

87
00:03:23,560 --> 00:03:24,430
カタツムリを入力できるのに、なぜ

88
00:03:24,430 --> 00:03:25,300
ネイルを入力するのでしょうか? 

89
00:03:26,080 --> 00:03:27,500
最後にSがついたほうがいいでしょうか？

90
00:03:27,820 --> 00:03:28,680
よくわかりません。

91
00:03:29,240 --> 00:03:31,673
さて、私の友人は、「疲れた」という単語で始めるのが

92
00:03:31,673 --> 00:03:33,814
好きだと言いました。それ には、W や Y 

93
00:03:33,814 --> 00:03:36,540
などの珍しい文字が含まれているので、ちょっと驚きました。

94
00:03:37,120 --> 00:03:38,029
しかし、おそらくそれはより良い

95
00:03:38,029 --> 00:03:39,000
オープナーであるかもしれません。

96
00:03:39,320 --> 00:03:41,871
潜在的な推測の質を判断するために与えることができ 

97
00:03:41,871 --> 00:03:44,320
る、ある種の定量的なスコアはあるのでしょうか? 

98
00:03:45,340 --> 00:03:47,336
ここで、考えられる推測をランク付けする方法を

99
00:03:47,336 --> 00:03:49,332
準備するために、戻って 、ゲームがどのように

100
00:03:49,332 --> 00:03:51,420
正確に設定されているかを少し明確にしましょう。

101
00:03:51,420 --> 00:03:54,779
つまり、有効な推測として入力できる単語のリストがあ 

102
00:03:54,779 --> 00:03:57,880
り、その長さはわずか約 13,000 単語です。

103
00:03:58,320 --> 00:04:01,703
しかし、よく見てみると、本当に珍しいものがたくさんあります。

104
00:04:01,703 --> 00:04:03,846
頭やアリ、A RG など、スクラブル 

105
00:04:03,846 --> 00:04:06,440
ゲームで家族の口論を引き起こすような言葉です。

106
00:04:06,960 --> 00:04:08,750
しかし、ゲームの雰囲気は、答えが常にか

107
00:04:08,750 --> 00:04:10,540
なり一般的な単語になるということです。

108
00:04:10,960 --> 00:04:12,940
そして実際、答えとして考えられる約 

109
00:04:12,940 --> 00:04:15,360
2300 語のリストがもう 1 つあります。

110
00:04:15,940 --> 00:04:17,623
これは人間が厳選したリストで、特にゲーム

111
00:04:17,623 --> 00:04:19,307
クリエイターのガールフ レンドによるもの

112
00:04:19,307 --> 00:04:21,160
だと思いますが、これはちょっと楽しいですね。

113
00:04:21,820 --> 00:04:24,541
しかし、私がやりたいのは、このプロジェクトの課題は、この

114
00:04:24,541 --> 00:04:27,263
リストに関する事前の知識を組み 込まずに Wordle 

115
00:04:27,263 --> 00:04:30,180
を解決するプログラムを作成できるかどうかを確認することです。

116
00:04:30,720 --> 00:04:32,773
まず、このリストには載っていない、よく使わ 

117
00:04:32,773 --> 00:04:34,640
れる 5 文字の単語がたくさんあります。

118
00:04:34,940 --> 00:04:37,143
したがって、もう少し回復力があり、公式 Web 

119
00:04:37,143 --> 00:04:39,164
サイトだけでなく、誰と でも Wordle 

120
00:04:39,164 --> 00:04:41,460
を対戦できるプログラムを作成する方がよいでしょう。

121
00:04:41,920 --> 00:04:44,460
また、この考えられる答えのリストが何であるかを私たちが知って

122
00:04:44,460 --> 00:04:47,000
 いる理由は、それがソース コードに表示されているからです。

123
00:04:47,000 --> 00:04:50,196
ただし、ソース コード内でそれが表示されるのは 

124
00:04:50,196 --> 00:04:53,260
、その日その日で得られる答えの特定の順序です。

125
00:04:53,260 --> 00:04:55,840
したがって、いつでも明日の答えを調べることができます。

126
00:04:56,420 --> 00:04:57,614
したがって、リストの使用には不正行

127
00:04:57,614 --> 00:04:58,880
為である意味があることは明らかです。

128
00:04:59,100 --> 00:05:01,935
そして、より興味深いパズルとより豊かな情報理論の

129
00:05:01,935 --> 00:05:04,770
レッスンを実現す るのは、代わりに一般的な単語の

130
00:05:04,770 --> 00:05:06,778
相対頻度などのより普遍的なデータ 

131
00:05:06,778 --> 00:05:09,613
を使用して、より一般的な単語を好むという直感を捉

132
00:05:09,613 --> 00:05:10,440
えることです。

133
00:05:11,600 --> 00:05:13,706
では、これら 13,000 の可能性の中から、冒

134
00:05:13,706 --> 00:05:15,900
頭の推測をどのように選択すればよいのでしょうか? 

135
00:05:16,400 --> 00:05:18,050
たとえば、友人が疲れたプロポーズをした場合

136
00:05:18,050 --> 00:05:19,780
、その質をどのように分析すべきでしょうか? 

137
00:05:20,520 --> 00:05:22,056
まあ、彼がその可能性の低い W 

138
00:05:22,056 --> 00:05:23,978
が好きだと言ったのは、その W が当た 

139
00:05:23,978 --> 00:05:26,187
ったらどれだけ気持ちいいかというロングショット

140
00:05:26,187 --> 00:05:27,340
の性質が好きだからです。

141
00:05:27,920 --> 00:05:30,446
たとえば、最初に明らかにされたパターンが次のような

142
00:05:30,446 --> 00:05:32,972
ものであった場合、この巨大 な辞書にはそのパターン

143
00:05:32,972 --> 00:05:35,600
に一致する単語が 58 語しかないことがわかります。

144
00:05:36,060 --> 00:05:38,400
13,000からは大幅な削減です。

145
00:05:38,780 --> 00:05:40,854
しかし、もちろんその裏返しとして、このようなパ

146
00:05:40,854 --> 00:05:43,020
ターンが発生するのは非常に珍しいということです。

147
00:05:43,020 --> 00:05:45,693
具体的には、各単語が答えとなる可能性が等しい

148
00:05:45,693 --> 00:05:48,488
場合、このパターンにヒ ットする確率は、58 

149
00:05:48,488 --> 00:05:51,040
を約 13,000 で割った値になります。

150
00:05:51,580 --> 00:05:53,600
もちろん、それらが同じように答えられるわけではありません。

151
00:05:53,720 --> 00:05:56,220
これらのほとんどは非常に曖昧で、疑わしい単語ですらあります。

152
00:05:56,600 --> 00:05:58,239
しかし、少なくともこのすべての最初のパス

153
00:05:58,239 --> 00:05:59,878
では、それらはすべて 同じ可能性であると

154
00:05:59,878 --> 00:06:01,600
仮定し、後でそれを少し改良してみましょう。

155
00:06:02,020 --> 00:06:04,312
重要なのは、情報量が多いパターンはその性

156
00:06:04,312 --> 00:06:06,720
質上、発生する可能性が低いということです。

157
00:06:07,280 --> 00:06:08,989
実際のところ、有益であるということ

158
00:06:08,989 --> 00:06:10,800
は、その可能性は低いということです。

159
00:06:11,719 --> 00:06:15,038
このオープニングで見られる可能性の高いパターンは、次の 

160
00:06:15,038 --> 00:06:18,120
ようなものです。もちろん、中には W がありません。

161
00:06:18,240 --> 00:06:19,820
E があるかもしれないし、A も 

162
00:06:19,820 --> 00:06:21,400
R も Y もないかもしれません。

163
00:06:22,080 --> 00:06:24,560
この場合、一致する可能性は 1400 通りあります。

164
00:06:25,080 --> 00:06:27,910
すべてが同じ確率である場合、このパター 

165
00:06:27,910 --> 00:06:30,600
ンになる確率は約 11% になります。

166
00:06:30,900 --> 00:06:32,085
したがって、最も可能性の高い結果は

167
00:06:32,085 --> 00:06:33,340
、最も情報が少ないものでもあります。

168
00:06:34,240 --> 00:06:37,690
ここでより全体的な視点を得るために、表示される可能性のあるさ

169
00:06:37,690 --> 00:06:41,140
 まざまなパターンすべてにわたる確率の完全な分布を示します。

170
00:06:41,740 --> 00:06:44,315
したがって、あなたが見ている各バーは、明らかにされる

171
00:06:44,315 --> 00:06:46,891
可能性のある色のパ ターンに対応しており、そのうち 

172
00:06:46,891 --> 00:06:48,872
3 ～ 5 番目の可能性があり、最も一 

173
00:06:48,872 --> 00:06:51,448
般的なものから最も一般的ではないものの順に左から右に

174
00:06:51,448 --> 00:06:52,340
編成されています。

175
00:06:52,920 --> 00:06:54,460
したがって、ここで最も一般的な可能

176
00:06:54,460 --> 00:06:56,000
性は、すべてが灰色になることです。

177
00:06:56,100 --> 00:06:58,120
それは約 14% の確率で起こります。

178
00:06:58,580 --> 00:07:01,163
そして、推測するときに期待しているのは、このロ

179
00:07:01,163 --> 00:07:03,747
ングテールのどこ かに行き着くということです。

180
00:07:03,747 --> 00:07:06,219
たとえば、このパターンに一致する可 能性が 

181
00:07:06,219 --> 00:07:09,140
18 個しかなく、明らかに次のように見える場所です。

182
00:07:09,920 --> 00:07:11,860
あるいは、もう少し左に行けば、おそ

183
00:07:11,860 --> 00:07:13,800
らくここまで行けるかもしれません。

184
00:07:14,940 --> 00:07:16,180
さて、あなたに良いパズルをご紹介します。

185
00:07:16,540 --> 00:07:19,206
W で始まり Y で終わり、どこかに R 

186
00:07:19,206 --> 00:07:22,000
が含まれる英語の 3 つの単語は何ですか? 

187
00:07:22,480 --> 00:07:24,574
結局のところ、その答えは、くどい

188
00:07:24,574 --> 00:07:26,800
、虫食い、そして皮肉なものだった。

189
00:07:27,500 --> 00:07:30,165
したがって、この単語が全体的にどの程度優れて

190
00:07:30,165 --> 00:07:32,831
いるかを判断するには、こ の分布から得られる

191
00:07:32,831 --> 00:07:35,740
と予想される情報量を示す何らかの尺度が必要です。

192
00:07:35,740 --> 00:07:38,690
各パターンを調べて、その発生確率と、そのパター

193
00:07:38,690 --> 00:07:41,641
ンがどれだけ有益かを測定 するものを掛け合わせ

194
00:07:41,641 --> 00:07:44,720
ると、客観的なスコアが得られる可能性があります。

195
00:07:45,960 --> 00:07:47,850
さて、それが何であるべきかについて最初

196
00:07:47,850 --> 00:07:49,840
に直感するのは、一致の数かもしれません。

197
00:07:50,160 --> 00:07:52,400
平均一致数を減らしたいと考えています。

198
00:07:52,800 --> 00:07:55,038
しかし、その代わりに、私たちが情報に帰することが多

199
00:07:55,038 --> 00:07:57,097
い、より普遍的な尺度を使用したいと 思います。

200
00:07:57,097 --> 00:07:59,335
また、これらの 13,000 語のそれぞれに、それ

201
00:07:59,335 --> 00:08:01,574
らが実際に答えであるかど うかについて異なる確率を

202
00:08:01,574 --> 00:08:04,260
割り当てると、より柔軟になる尺度を使用したいと考えています。

203
00:08:10,320 --> 00:08:13,778
情報の標準単位はビットです。これには少し面白い公式が 

204
00:08:13,778 --> 00:08:16,980
ありますが、例を見るだけであれば非常に直感的です。

205
00:08:17,780 --> 00:08:20,698
あなたの可能性の空間を半分に減らすような観察があ 

206
00:08:20,698 --> 00:08:23,500
る場合、それは少しの情報を持っていると言います。

207
00:08:24,180 --> 00:08:26,478
この例では、可能性の空間はすべての可能性のある単語

208
00:08:26,478 --> 00:08:28,317
であり、5 文字の単語の約 半分に S 

209
00:08:28,317 --> 00:08:30,616
があり、それより少し少ないですが、約半分であること

210
00:08:30,616 --> 00:08:31,260
がわかります。

211
00:08:31,780 --> 00:08:33,049
したがって、この観察により、ちょ

212
00:08:33,049 --> 00:08:34,320
っとした情報が得られるでしょう。

213
00:08:34,880 --> 00:08:37,122
代わりに、新しい事実がその可能性の空間を 

214
00:08:37,122 --> 00:08:39,364
4 分の 1 に切り 詰める場合、それは 

215
00:08:39,364 --> 00:08:41,500
2 ビットの情報を持っていると言います。

216
00:08:41,980 --> 00:08:43,220
たとえば、これらの単語の約 4 分の 1 

217
00:08:43,220 --> 00:08:44,460
に T が含まれていることがわかりました。

218
00:08:45,020 --> 00:08:47,928
観測によりその空間が 8 分の 1 に削減された 

219
00:08:47,928 --> 00:08:50,720
場合、それは 3 ビットの情報であると言います。

220
00:08:50,900 --> 00:08:53,079
4 ビットでは 16 ビットに分割され、5 

221
00:08:53,079 --> 00:08:55,060
ビットでは 32 ビットに分割されます。

222
00:08:55,060 --> 00:08:59,020
そこで、ここで少し立ち止まって、発生確率の観点からビット数を

223
00:08:59,020 --> 00:09:02,980
 表す情報の公式は何なのかを自問してみてはいかがでしょうか。

224
00:09:03,920 --> 00:09:06,870
ここで私たちが言いたいのは、ビット数の半分を取る

225
00:09:06,870 --> 00:09:08,960
とき、それは 確率と同じことです。

226
00:09:08,960 --> 00:09:11,542
これは、ビット数の 2 乗が確率より 1 

227
00:09:11,542 --> 00:09:13,756
大きいと言っているのと同じことです。

228
00:09:13,756 --> 00:09:16,706
さらに整理すると、情報 は 2 を底とする 1 

229
00:09:16,706 --> 00:09:18,920
を確率で割った対数であると言えます。

230
00:09:19,620 --> 00:09:22,308
そして、さらにもう 1 つ再配置すると、この情報が確率 

231
00:09:22,308 --> 00:09:24,900
の 2 を底とする負の対数であることが時々わかります。

232
00:09:25,660 --> 00:09:28,500
このように表現すると、初心者にとっては少し奇妙に見える 

233
00:09:28,500 --> 00:09:31,340
かもしれませんが、実際には、自分の可能性を何回半減させ 

234
00:09:31,340 --> 00:09:34,080
たかを尋ねるという非常に直感的なアイデアにすぎません。

235
00:09:35,180 --> 00:09:36,509
さて、疑問に思っている方は、私たちは単に

236
00:09:36,509 --> 00:09:37,838
楽しい言葉遊びをして いるだけだと思った

237
00:09:37,838 --> 00:09:39,300
のですが、なぜ対数が登場するのでしょうか? 

238
00:09:39,780 --> 00:09:41,780
これがより優れた単元である理由の 1 

239
00:09:41,780 --> 00:09:44,201
つは、非常に起こりそうもない出来事について話 

240
00:09:44,201 --> 00:09:46,939
すのがはるかに簡単であり、これこれが発生する確率が 

241
00:09:46,939 --> 00:09:49,149
0 であると言うよりも、観測 値に 20 

242
00:09:49,149 --> 00:09:52,097
ビットの情報があると言う方がはるかに簡単であるためです。

243
00:09:52,097 --> 00:09:52,940
0000095。

244
00:09:53,300 --> 00:09:55,975
しかし、この対数表現が確率論への非常に有

245
00:09:55,975 --> 00:09:58,650
用な追加であることが 判明したより実質的

246
00:09:58,650 --> 00:10:01,460
な理由は、情報が加算される方法にあります。

247
00:10:02,060 --> 00:10:03,857
たとえば、1 つの観測結果から 2 

248
00:10:03,857 --> 00:10:05,754
ビットの情報が得られ、スペースが 4 

249
00:10:05,754 --> 00:10:07,951
ビット減り、その後、Wordle での 2 

250
00:10:07,951 --> 00:10:10,748
番目の推測のような 2 番目 の観測により、さらに 3 

251
00:10:10,748 --> 00:10:13,144
ビットの情報が得られ、さらに 8 分の 1 に 

252
00:10:13,144 --> 00:10:15,441
削減された場合、 2 つを組み合わせると 5 

253
00:10:15,441 --> 00:10:16,740
ビットの情報が得られます。

254
00:10:17,160 --> 00:10:21,020
確率が増加するのと同じように、情報は追加されるのを好みます。

255
00:10:21,960 --> 00:10:25,029
したがって、大量の数値を加算する期待値のような領域 

256
00:10:25,029 --> 00:10:27,980
に入るとすぐに、ログのおかげで扱いやすくなります。

257
00:10:28,480 --> 00:10:30,633
Weary のディストリビューションに戻り、こ

258
00:10:30,633 --> 00:10:32,786
こに別の小さなトラッカ ーを追加して、各パター

259
00:10:32,786 --> 00:10:34,940
ンにどれだけの情報があるかを示してみましょう。

260
00:10:35,580 --> 00:10:37,980
ここで注目していただきたいのは、可能性の高いパタ

261
00:10:37,980 --> 00:10:40,380
ーンに到達する確率が高く なるほど、情報が少なく

262
00:10:40,380 --> 00:10:42,780
なり、得られるビットも少なくなるということです。

263
00:10:43,500 --> 00:10:47,150
この推測の質を測定する方法は、この情報の期待値を取得す 

264
00:10:47,150 --> 00:10:50,670
ることです。各パターンを調べて、その確率がどれくらい 

265
00:10:50,670 --> 00:10:54,060
かを示し、それを取得した情報のビット数で乗算します。

266
00:10:54,710 --> 00:10:56,415
そして、Weary の例では、それは 

267
00:10:56,415 --> 00:10:58,120
4 であることがわかります。9ビット。

268
00:10:58,560 --> 00:11:00,830
したがって、平均すると、この冒頭の推測から

269
00:11:00,830 --> 00:11:02,993
得られる情報は、可能性 の空間を約 5 

270
00:11:02,993 --> 00:11:05,480
回半分に切り分けるのと同じくらい優れています。

271
00:11:05,960 --> 00:11:08,942
対照的に、情報の期待値がより高い推測の例 

272
00:11:08,942 --> 00:11:11,640
としては、Slate などがあります。

273
00:11:13,120 --> 00:11:15,620
この場合、分布がかなり平坦になっていることがわかります。

274
00:11:15,940 --> 00:11:19,316
特に、最も可能性の高いすべての灰色の発生確率は約 

275
00:11:19,316 --> 00:11:22,423
6% しかないため、少 なくとも明らかに 3 

276
00:11:22,423 --> 00:11:25,260
が得られることになります。9ビットの情報。

277
00:11:25,920 --> 00:11:27,240
しかし、これは最低限のことであり、通常は

278
00:11:27,240 --> 00:11:28,560
それよりも優れたものが得られるでしょう。

279
00:11:29,100 --> 00:11:32,435
この数字を計算して関連するすべての用語を合計すると 

280
00:11:32,435 --> 00:11:35,900
、平均的な情報は約 5 であることがわかります。8. 

281
00:11:37,360 --> 00:11:40,573
したがって、Weary とは対照的に、この最初の推 

282
00:11:40,573 --> 00:11:43,540
測の後、可能性の空間は平均して約半分になります。

283
00:11:44,420 --> 00:11:49,120
実は、この情報量の期待値の名前については面白い話があります。

284
00:11:49,200 --> 00:11:52,015
情報理論は、1940 年代にベル研究所で働いていたクロード 

285
00:11:52,015 --> 00:11:54,362
シャノンによって 開発されましたが、彼はまだ発表さ

286
00:11:54,362 --> 00:11:56,426
れていないアイデアのいくつかについて、当時 

287
00:11:56,426 --> 00:11:58,304
の知的巨人で非常に著名なジョン フォン 

288
00:11:58,304 --> 00:12:00,087
ノイマンと話し合っていました。数学と 

289
00:12:00,087 --> 00:12:02,433
物理学、そしてコンピューターサイエンスになりつつあ

290
00:12:02,433 --> 00:12:03,560
ったものの始まりでした。

291
00:12:04,100 --> 00:12:07,582
そして、フォン・ノイマンは、この情報量の期待値にあまり良い 

292
00:12:07,582 --> 00:12:10,949
名前がないと述べたとき、おそらく、それをエントロピーと呼 

293
00:12:10,949 --> 00:12:14,200
ぶべきだ、と話は進みますが、その理由は 2 つあります。

294
00:12:14,540 --> 00:12:17,512
まず第一に、不確実性関数はその名前で統計力学で使用され

295
00:12:17,512 --> 00:12:19,714
ているため、すでに名 前が付いています。

296
00:12:19,714 --> 00:12:22,796
そして第二に、そしてさらに重要なことに、エントロピーが 

297
00:12:22,796 --> 00:12:24,558
実際に何であるか誰も知りません。

298
00:12:24,558 --> 00:12:26,760
したがって、議論では常に利点があります。

299
00:12:27,700 --> 00:12:30,126
したがって、名前が少し謎めいているように見えても、 

300
00:12:30,126 --> 00:12:32,460
この話を信じられるとしても、それは一種の仕様です。

301
00:12:33,280 --> 00:12:36,632
また、物理学の熱力学第 2 法則すべてとの関係について疑 

302
00:12:36,632 --> 00:12:39,869
問に思っているなら、間違いなく関連性がありますが、その 

303
00:12:39,869 --> 00:12:43,221
起源において、シャノンは純粋な確率論を扱っていただけであ 

304
00:12:43,221 --> 00:12:46,458
り、ここでの目的のために、単語のエントロピーについては 

305
00:12:46,458 --> 00:12:49,580
、特定の推測の期待される情報値を考えてほしいだけです。

306
00:12:50,700 --> 00:12:52,240
エントロピーは、2 つのものを同時

307
00:12:52,240 --> 00:12:53,780
に測定すると考えることができます。

308
00:12:54,240 --> 00:12:56,780
1 つ目は、分布がどの程度平坦であるかです。

309
00:12:57,320 --> 00:13:01,120
分布が均一に近づくほど、エントロピーは高くなります。

310
00:13:01,580 --> 00:13:04,495
私たちの場合、一様分布の場合、合計 3 から 

311
00:13:04,495 --> 00:13:07,411
5 までのパターンがあり、それらのいずれかを 

312
00:13:07,411 --> 00:13:10,580
観察すると、情報ログの底が 3 から 5 までの 

313
00:13:10,580 --> 00:13:13,496
2 になり、これはたまたま 7 になり ます。

314
00:13:13,496 --> 00:13:17,300
92 なので、これがこのエントロピーの絶対最大値になります。

315
00:13:17,840 --> 00:13:20,056
しかし、エントロピーは、そもそもどれだけの可 

316
00:13:20,056 --> 00:13:22,080
能性があるかを示す一種の尺度でもあります。

317
00:13:22,320 --> 00:13:24,577
たとえば、考えられるパターンが 16 

318
00:13:24,577 --> 00:13:27,309
個しかなく、それぞれの可能性が等しい単語がた 

319
00:13:27,309 --> 00:13:30,873
またまあった場合、このエントロピー、つまり期待される情報は 

320
00:13:30,873 --> 00:13:32,180
4 ビットになります。

321
00:13:32,579 --> 00:13:35,135
しかし、64 個の考えられるパターンがあり、

322
00:13:35,135 --> 00:13:37,691
それらがすべて同じ確率で ある別の単語がある

323
00:13:37,691 --> 00:13:40,480
場合、エントロピーは 6 ビットになるでしょう。

324
00:13:41,500 --> 00:13:44,412
したがって、6 ビットのエントロピーを持つ分布を実

325
00:13:44,412 --> 00:13:47,441
際に目にした場合、 それは、同じ確率の結果が 64 

326
00:13:47,441 --> 00:13:49,655
個存在するのと同じくらい、これから起 

327
00:13:49,655 --> 00:13:52,567
こることには大きな変動と不確実性があると言っている

328
00:13:52,567 --> 00:13:53,500
ようなものです。

329
00:13:54,360 --> 00:13:56,840
Wurtelebot での最初のパス

330
00:13:56,840 --> 00:13:59,320
では、基本的にこれを行うだけでした。

331
00:13:59,320 --> 00:14:02,443
考えられるすべての推測 (13,000 語すべて) 

332
00:14:02,443 --> 00:14:05,807
を調べ、各単語のエ ントロピー、より具体的には、表示され

333
00:14:05,807 --> 00:14:07,850
る可能性のあるすべてのパターンに 

334
00:14:07,850 --> 00:14:11,214
わたる分布のエントロピーを単語ごとに計算し、最も高いもの

335
00:14:11,214 --> 00:14:14,578
を選択します 。それはあなたの可能性の空間を可能な限り切

336
00:14:14,578 --> 00:14:16,140
り詰める可能性があります。

337
00:14:17,140 --> 00:14:19,202
ここでは最初の推測についてのみ話しましたが、次の 

338
00:14:19,202 --> 00:14:21,100
いくつかの推測についても同じことが起こります。

339
00:14:21,560 --> 00:14:24,093
たとえば、最初の推測について何らかのパターンがあ

340
00:14:24,093 --> 00:14:26,627
り、それに一致す るものに基づいて候補となる単語

341
00:14:26,627 --> 00:14:28,527
の数が制限されることがわかったら、 

342
00:14:28,527 --> 00:14:31,061
その小さな単語のセットに関して同じゲームをプレイ

343
00:14:31,061 --> 00:14:31,800
するだけです。

344
00:14:32,260 --> 00:14:35,098
提案された 2 番目の推測では、より限定された単語

345
00:14:35,098 --> 00:14:37,936
のセットから発生す る可能性のあるすべてのパターン

346
00:14:37,936 --> 00:14:40,093
の分布を調べ、13,000 の可能性 

347
00:14:40,093 --> 00:14:42,931
すべてを検索し、そのエントロピーを最大化するパター

348
00:14:42,931 --> 00:14:43,840
ンを見つけます。

349
00:14:45,420 --> 00:14:48,228
これが実際にどのように機能するかを示すために、余

350
00:14:48,228 --> 00:14:50,920
白にこの分析のハイライトを 示す、私が書いた 

351
00:14:50,920 --> 00:14:54,080
Wurtele の小さな変形版を取り出してみましょう。

352
00:14:54,080 --> 00:14:56,991
すべてのエントロピー計算を行った後、右側には、 

353
00:14:56,991 --> 00:14:59,660
期待される情報が最も高いものを示しています。

354
00:15:00,280 --> 00:15:03,713
少なくとも現時点でのトップの答えは、後ほど詳し

355
00:15:03,713 --> 00:15:06,400
く説明しますが、Tar es です。

356
00:15:06,400 --> 00:15:10,580
つまり、もちろん、レンゲ、最も一般的なレンゲのことです。

357
00:15:11,040 --> 00:15:13,678
ここで推測するたびに、私はスレートが好きなので、推奨事項

358
00:15:13,678 --> 00:15:16,316
を無視してスレ ートを使用することになるのですが、そこに

359
00:15:16,316 --> 00:15:17,824
どれだけの期待情報が含まれてい 

360
00:15:17,824 --> 00:15:20,462
るかがわかりますが、ここの単語の右側には、どれだけの情報

361
00:15:20,462 --> 00:15:22,064
が含まれている かが表示されます。

362
00:15:22,064 --> 00:15:24,420
この特定のパターンを考慮して、実際に得られた情報。

363
00:15:25,000 --> 00:15:26,528
つまり、ここでは少し不運だったようです。

364
00:15:26,528 --> 00:15:28,056
5 を獲得することが期待されていました。

365
00:15:28,056 --> 00:15:30,120
8 ですが 、たまたまそれ以下のものが入手できました。

366
00:15:30,600 --> 00:15:32,910
そして左側には、私たちが今いる場所で考えられ 

367
00:15:32,910 --> 00:15:35,020
るさまざまな単語がすべて表示されています。

368
00:15:35,800 --> 00:15:38,319
青いバーは各単語がどの程度の確率で考えられるかを示

369
00:15:38,319 --> 00:15:40,839
しているため、現時点では 各単語が出現する可能性が

370
00:15:40,839 --> 00:15:43,360
等しいと仮定していますが、これはすぐに修正します。

371
00:15:44,060 --> 00:15:46,971
そして、この不確実性の測定により、考えられる単

372
00:15:46,971 --> 00:15:50,263
語全体にわたるこ の分布のエントロピーがわかります。

373
00:15:50,263 --> 00:15:53,174
これは、現時点では一様分布で あるため、可能性

374
00:15:53,174 --> 00:15:55,960
の数を数える不必要に複雑な方法にすぎません。

375
00:15:56,560 --> 00:15:59,018
たとえば、2 の 13 乗を取るとします。

376
00:15:59,018 --> 00:16:02,180
66、それは約 13,000 の可能性があるはずです。

377
00:16:02,900 --> 00:16:04,520
ここでは少しずれていますが、それは小数点

378
00:16:04,520 --> 00:16:06,140
以下の桁をすべて表示していないためです。

379
00:16:06,720 --> 00:16:08,540
現時点では、それは冗長で、物事が過度に複雑であ

380
00:16:08,540 --> 00:16:10,361
るように感じるかもしれま せんが、両方の数値を

381
00:16:10,361 --> 00:16:12,340
取得することがなぜ便利であるかはすぐにわかります。

382
00:16:12,760 --> 00:16:14,945
したがって、ここでは、2 番目の推測で最もエントロピ

383
00:16:14,945 --> 00:16:17,130
ーが高いのはラーメンである ことを示唆しているように

384
00:16:17,130 --> 00:16:19,400
見えますが、これも本当に言葉のようには感じられません。

385
00:16:19,980 --> 00:16:22,463
そこで、ここで道徳的な立場を強調するために、先に進んで 

386
00:16:22,463 --> 00:16:24,060
Rains と入力することにします。

387
00:16:25,440 --> 00:16:27,340
そしてまた少し不運だったようです。

388
00:16:27,520 --> 00:16:29,857
私たちは4を期待していました。3 ビットありますが、3 

389
00:16:29,857 --> 00:16:31,360
つしかありません。39ビットの情報。

390
00:16:31,940 --> 00:16:33,940
つまり、55 の可能性が考えられます。

391
00:16:34,900 --> 00:16:37,208
そしてここでは、それが何を意味するにせよ、実際にそれが示唆 

392
00:16:37,208 --> 00:16:39,440
しているもの、つまりコンボに従うことになるかもしれません。

393
00:16:40,040 --> 00:16:42,920
さて、これは実際、パズルを解く良い機会です。

394
00:16:42,920 --> 00:16:45,541
このパターンでは 4 が得られることがわかります。

395
00:16:45,541 --> 00:16:46,380
7ビットの情報。

396
00:16:47,060 --> 00:16:49,444
しかし、左側では、そのパターンが見える前に 

397
00:16:49,444 --> 00:16:51,720
5 つありました。78 ビットの不確実性。

398
00:16:52,420 --> 00:16:54,329
それで、あなたへのクイズですが、残りの

399
00:16:54,329 --> 00:16:56,340
可能性の数については何を意味しますか? 

400
00:16:58,040 --> 00:17:00,975
これは、不確実性が 1 つまで減少したことを意味します。

401
00:17:00,975 --> 00:17:02,652
これは 、考えられる答えが 2 

402
00:17:02,652 --> 00:17:04,540
つあると言っているのと同じことです。

403
00:17:04,700 --> 00:17:05,700
それは五分五分の選択だ。

404
00:17:06,500 --> 00:17:08,607
ここからは、あなたも私もどちらの単語がより一般的である 

405
00:17:08,607 --> 00:17:10,640
かを知っているので、答えは深淵であることがわかります。

406
00:17:11,180 --> 00:17:12,198
しかし、現時点で書かれているよう

407
00:17:12,198 --> 00:17:13,280
に、プログラムはそれを知りません。

408
00:17:13,540 --> 00:17:16,753
したがって、可能性が 1 つだけ残されるまで、できるだけ多 

409
00:17:16,753 --> 00:17:19,859
くの情報を取得しようと試み続け、その後、それを推測します。

410
00:17:20,380 --> 00:17:22,339
したがって、明らかに、より良い終盤戦略が必要です。

411
00:17:22,599 --> 00:17:24,486
しかし、このバージョンを Wordle ソルバーの 

412
00:17:24,486 --> 00:17:26,373
1 つと呼び、それがどのよ うに機能するかを確認する

413
00:17:26,373 --> 00:17:28,260
ためにいくつかのシミュレーションを実行するとします。

414
00:17:30,360 --> 00:17:32,204
つまり、これがどのように機能しているかというと、考え

415
00:17:32,204 --> 00:17:34,120
られるすべての単語ゲームを実行しているということです。

416
00:17:34,240 --> 00:17:36,585
実際の Wordle の回答である 

417
00:17:36,585 --> 00:17:38,540
2315 語すべてを調べます。

418
00:17:38,540 --> 00:17:40,580
基本的にはそれをテストセットとして使用します。

419
00:17:41,360 --> 00:17:44,446
そして、単語がどれだけ一般的であるかを考慮せず、ただ 

420
00:17:44,446 --> 00:17:47,190
1 つの選択肢に行き 着くまで、途中の各ステップ

421
00:17:47,190 --> 00:17:49,820
で情報を最大化しようとするこの単純な方法です。

422
00:17:50,360 --> 00:17:52,952
シミュレーションが終了するまでに、平均スコアは約 

423
00:17:52,952 --> 00:17:54,300
4 になります。124. 

424
00:17:55,319 --> 00:17:57,236
それは悪いことではありませんが、正直に言うと

425
00:17:57,236 --> 00:17:59,240
、私はもっと悪いことをすると予想していました。

426
00:17:59,660 --> 00:18:01,487
しかし、ワードルをプレイしている人は、通常は 

427
00:18:01,487 --> 00:18:02,600
4 で取得できると言います。

428
00:18:02,860 --> 00:18:05,380
本当の課題は、3 つをできるだけ多く獲得することです。

429
00:18:05,380 --> 00:18:08,080
スコア 4 とスコア 3 の間ではかなり大きな差があります。

430
00:18:08,860 --> 00:18:10,868
ここでの明らかに簡単な成果は、単語が一般的

431
00:18:10,868 --> 00:18:12,971
かどうかを何らかの方法 で組み込むことです。

432
00:18:12,971 --> 00:18:14,980
また、それを具体的にどのように行うかです。

433
00:18:22,800 --> 00:18:25,396
私がこれにアプローチした方法は、英語のすべて 

434
00:18:25,396 --> 00:18:27,880
の単語の相対頻度のリストを取得することです。

435
00:18:28,220 --> 00:18:29,413
そして、Mathematica 

436
00:18:29,413 --> 00:18:30,756
の単語頻度データ関数を使用しました。

437
00:18:30,756 --> 00:18:32,994
この関数自体は、Go ogle Books English 

438
00:18:32,994 --> 00:18:34,860
Ngram 公開データセットから取得したものです。

439
00:18:35,460 --> 00:18:37,755
たとえば、最も一般的な単語から最も一般的ではない 

440
00:18:37,755 --> 00:18:39,960
単語まで並べ替えると、見ていてとても楽しいです。

441
00:18:40,120 --> 00:18:43,080
明らかに、これらは英語で最も一般的な 5 文字の単語です。

442
00:18:43,700 --> 00:18:45,840
というか、これらは8番目に多いものです。

443
00:18:46,280 --> 00:18:48,880
最初にどれがあり、その後にあそことあそこがあります。

444
00:18:49,260 --> 00:18:51,217
first 自体は first ではなく 9th 

445
00:18:51,217 --> 00:18:53,489
であり、これらの他の単語がよ り頻繁に出現する可能性がある

446
00:18:53,489 --> 00:18:55,682
ことは理にかなっていますが、first の後の単語 は 

447
00:18:55,682 --> 00:18:57,953
after、where、そしてそれらの単語は少しだけ一般的

448
00:18:57,953 --> 00:18:58,580
ではありません。

449
00:18:59,160 --> 00:19:01,688
さて、このデータを使用して、これらの各単語が

450
00:19:01,688 --> 00:19:04,216
最終的な答えとなる可能 性をモデル化する場合

451
00:19:04,216 --> 00:19:06,860
、単に頻度に比例するだけであってはなりません。

452
00:19:06,860 --> 00:19:08,692
たとえば、スコア 0 が与えられます。

453
00:19:08,692 --> 00:19:11,008
このデータセットでは 002 が使用されますが 

454
00:19:11,008 --> 00:19:13,709
、braid という単語はある意味で約 1000 分の 

455
00:19:13,709 --> 00:19:15,060
1 の可能性が低くなります。

456
00:19:15,560 --> 00:19:17,199
しかし、これらは両方とも十分に一般的な単語で

457
00:19:17,199 --> 00:19:18,840
あるため、ほぼ確実に検討する価値があります。

458
00:19:19,340 --> 00:19:20,170
したがって、バイナリのカットオフ

459
00:19:20,170 --> 00:19:21,000
をさらに強化する必要があります。

460
00:19:21,860 --> 00:19:25,068
私がこれに取り組んだ方法は、このソートされた単語のリス

461
00:19:25,068 --> 00:19:28,277
ト全体を取得し、 それを X 軸上に配置し、シグモイド

462
00:19:28,277 --> 00:19:30,297
関数を適用することです。これは、 

463
00:19:30,297 --> 00:19:33,862
出力が基本的にバイナリである関数を作成する標準的な方法です。

464
00:19:33,862 --> 00:19:37,071
0 か 1 のどちらかですが、その不確実性の領域の間で

465
00:19:37,071 --> 00:19:38,260
平滑化が行われます。

466
00:19:39,160 --> 00:19:42,253
つまり、基本的に、最終リストに含まれる各単

467
00:19:42,253 --> 00:19:45,346
語に割り当てる確率は 、x 軸上のどこに位

468
00:19:45,346 --> 00:19:48,440
置する上記のシグモイド関数の値になります。

469
00:19:49,520 --> 00:19:52,175
これは明らかにいくつかのパラメータに依存します。

470
00:19:52,175 --> 00:19:54,167
たとえば、これらの単語が占める x 

471
00:19:54,167 --> 00:19:56,490
軸上のスペースの幅によって、1 から 0 

472
00:19:56,490 --> 00:19:58,703
への降下がどの程度徐々にまたは急激に変 

473
00:19:58,703 --> 00:20:01,359
化するかが決まり、単語を左から右のどこに配置する

474
00:20:01,359 --> 00:20:03,240
かによってカットオフが決まります。

475
00:20:03,240 --> 00:20:05,080
正直に言うと、私がこれを行った方法は

476
00:20:05,080 --> 00:20:06,920
、指をなめて風に突き刺すだけでした。

477
00:20:07,140 --> 00:20:10,552
私はソートされたリストを調べて、これらの単語の約半分が最 

478
00:20:10,552 --> 00:20:13,965
終的な答えになる可能性が高いと判断できる範囲を見つけよう 

479
00:20:13,965 --> 00:20:17,260
としました。そして、それをカットオフとして使用しました。

480
00:20:17,260 --> 00:20:20,692
単語全体でこのような分布が得られると、エントロピー 

481
00:20:20,692 --> 00:20:23,860
が非常に有用な測定値となる別の状況が得られます。

482
00:20:24,500 --> 00:20:27,493
たとえば、ゲームをプレイしていて、羽と爪だった古 

483
00:20:27,493 --> 00:20:30,486
いオープナーから始めて、それに一致する可能性のあ 

484
00:20:30,486 --> 00:20:33,240
る単語が 4 つある状況に行き着いたとします。

485
00:20:33,560 --> 00:20:35,620
そして、それらはすべて同じ可能性であると考えてみましょう。

486
00:20:36,220 --> 00:20:38,880
この分布のエントロピーはいくらですか? 

487
00:20:41,080 --> 00:20:43,985
さて、これらの可能性のそれぞれに関連付けられた情

488
00:20:43,985 --> 00:20:46,770
報は、それぞれが 1 と 4 であり、それが 

489
00:20:46,770 --> 00:20:50,040
2 であるため、4 の底を 2 とする対数になります。

490
00:20:50,040 --> 00:20:52,460
2 ビットの情報、4 つの可能性。

491
00:20:52,760 --> 00:20:53,580
すべてとても順調です。

492
00:20:54,300 --> 00:20:56,050
しかし、実際には 4 つ以上の試合が

493
00:20:56,050 --> 00:20:57,800
あると言ったらどうなるでしょうか? 

494
00:20:58,260 --> 00:21:01,465
実際、完全な単語リストに目を通すと、それに一致する単語が 

495
00:21:01,465 --> 00:21:02,460
16 個あります。

496
00:21:02,580 --> 00:21:04,677
しかし、私たちのモデルでは、他の 12 

497
00:21:04,677 --> 00:21:06,774
単語が実際に最終的な答えになる確率は非 

498
00:21:06,774 --> 00:21:09,501
常に低く、非常に曖昧であるため、1000 分の 1 

499
00:21:09,501 --> 00:21:10,760
程度であると仮定します。

500
00:21:11,500 --> 00:21:14,260
さて、この分布のエントロピーはいくらでしょうか? 

501
00:21:15,420 --> 00:21:17,990
ここでエントロピーが純粋に一致の数を測定している場

502
00:21:17,990 --> 00:21:20,560
合、それは 16 の底 2 の対数のようなものにな

503
00:21:20,560 --> 00:21:22,821
ると予想されるかもしれません。こ れは 4 

504
00:21:22,821 --> 00:21:25,700
となり、以前よりも 2 ビット多くの不確実性が生じます。

505
00:21:26,180 --> 00:21:27,960
しかし、もちろん、実際の不確実

506
00:21:27,960 --> 00:21:29,860
性は以前とそれほど変わりません。

507
00:21:30,160 --> 00:21:31,782
これらの本当にあいまいな 12 

508
00:21:31,782 --> 00:21:33,810
の単語があるからといって、たとえば、最 

509
00:21:33,810 --> 00:21:36,143
終的な答えが魅力であると知っても、それほど驚く

510
00:21:36,143 --> 00:21:37,360
べきことではありません。

511
00:21:38,180 --> 00:21:41,809
したがって、ここで実際に計算を実行し、各発生の確率と対応す 

512
00:21:41,809 --> 00:21:44,834
る情報を合計すると、得られる値は 2 になります。

513
00:21:44,834 --> 00:21:45,560
11ビット。

514
00:21:45,560 --> 00:21:48,367
私が言いたいのは、基本的には 2 つのビット、基本的には 

515
00:21:48,367 --> 00:21:51,078
4 つの可能性で すが、これらの非常にありそうもない出来

516
00:21:51,078 --> 00:21:53,498
事がすべてあるため、もう少し不確実性 があります。

517
00:21:53,498 --> 00:21:56,209
ただし、それらを学べば、そこから大量の情報が得られるでし

518
00:21:56,209 --> 00:21:56,500
ょう。

519
00:21:57,160 --> 00:21:59,364
ズームアウトすると、これが Wordle が情報理 

520
00:21:59,364 --> 00:22:01,400
論のレッスンに最適な例となる理由の 1 つです。

521
00:22:01,600 --> 00:22:02,968
エントロピーについては、これら 2 

522
00:22:02,968 --> 00:22:04,640
つの異なる感覚のアプリケーションがあります。

523
00:22:05,160 --> 00:22:08,637
1 つ目は、与えられた推測から得られる期待情報は何 

524
00:22:08,637 --> 00:22:12,115
かを示し、2 つ目は、考えられるすべての単語の中で 

525
00:22:12,115 --> 00:22:15,460
残っている不確実性を測定できるかどうかを示します。

526
00:22:16,460 --> 00:22:19,119
そして、強調しておきたいのは、推測の期待情報を調べる

527
00:22:19,119 --> 00:22:21,778
最初のケースでは、単語の重 み付けが不均等になると、

528
00:22:21,778 --> 00:22:24,540
それがエントロピーの計算に影響を与えるということです。

529
00:22:24,980 --> 00:22:27,927
たとえば、Weary に関連する分布について以前に検討し 

530
00:22:27,927 --> 00:22:29,959
たのと同じケースを取り出してみましょう。

531
00:22:29,959 --> 00:22:32,805
ただし、今回はす べての可能な単語にわたって不均一な分布

532
00:22:32,805 --> 00:22:33,720
を使用しています。

533
00:22:34,500 --> 00:22:36,341
それでは、それをうまく説明している部分

534
00:22:36,341 --> 00:22:38,280
がここに見つかるかどうか見てみましょう。

535
00:22:40,940 --> 00:22:42,360
さて、これはかなり良いです。

536
00:22:42,360 --> 00:22:44,606
ここでは、ほぼ同じ確率の 2 つの隣接するパターン

537
00:22:44,606 --> 00:22:46,853
がありますが、そのうちの 1 つは、それに一致する

538
00:22:46,853 --> 00:22:49,100
可能性のある単語が 32 個あると言われています。

539
00:22:49,280 --> 00:22:51,587
それらが何であるかを確認してみると、これらは 

540
00:22:51,587 --> 00:22:53,693
32 個であり、 目をざっと眺めると、どれ

541
00:22:53,693 --> 00:22:55,600
も非常にありそうもない単語ばかりです。

542
00:22:55,840 --> 00:22:58,576
もっともらしい答え、おそらく叫び声のようなものを見つ

543
00:22:58,576 --> 00:23:01,312
けるのは難し いですが、ほぼ同じ確率であると考えられ

544
00:23:01,312 --> 00:23:04,258
る分布内の隣接するパターン を見ると、一致する可能性は 

545
00:23:04,258 --> 00:23:06,783
8 つしかないと言われているため、4 分の 1 

546
00:23:06,783 --> 00:23:09,520
は多くの試合がありますが、その可能性はほぼ同じです。

547
00:23:09,860 --> 00:23:12,140
それらの一致を調べてみると、その理由がわかります。

548
00:23:12,500 --> 00:23:14,351
これらの中には、リング、怒り、ラップな

549
00:23:14,351 --> 00:23:16,300
ど、実際にもっともらしい答えもあります。

550
00:23:17,900 --> 00:23:20,415
これらすべてをどのように組み込むかを説明するために、ここで 

551
00:23:20,415 --> 00:23:22,764
Wordlebot のバージ ョン 2 を取り上げます。

552
00:23:22,764 --> 00:23:25,280
最初に見たものとの主な違いが 2 つまたは 3 つあります。

553
00:23:25,860 --> 00:23:28,955
まず、先ほど述べたように、これらのエントロピー、

554
00:23:28,955 --> 00:23:32,050
つまり情報の期待 値を計算する方法では、特定の単

555
00:23:32,050 --> 00:23:34,242
語が実際に答えとなる確率を組み込 

556
00:23:34,242 --> 00:23:37,337
んだ、パターン全体にわたるより洗練された分布を使

557
00:23:37,337 --> 00:23:38,240
用しています。

558
00:23:38,879 --> 00:23:41,286
偶然にも、涙が依然としてナンバー 1 

559
00:23:41,286 --> 00:23:43,820
ですが、それに続くものは少し異なります。

560
00:23:44,360 --> 00:23:47,983
第 2 に、上位の候補をランク付けするときに、 

561
00:23:47,983 --> 00:23:51,607
各単語が実際の答えである確率のモデルを保持し、 

562
00:23:51,607 --> 00:23:55,080
それを決定に組み込むようになります。テーブル。

563
00:23:55,860 --> 00:23:57,820
繰り返しますが、私たちは機械に生活を支配させ

564
00:23:57,820 --> 00:23:59,780
ることはできないので、その推奨を無視します。

565
00:24:01,140 --> 00:24:03,973
そして、ここでもう 1 つ異なる点があることを言及する

566
00:24:03,973 --> 00:24:06,806
必要があると思います。左側 は、不確実性の値、ビット数

567
00:24:06,806 --> 00:24:09,640
が、一致の可能性の数と重複するだけではなくなりました。

568
00:24:10,080 --> 00:24:13,361
これを引き上げて、2 対 8 を計算するとします。

569
00:24:13,361 --> 00:24:17,036
02、これは 256 を少し上回 る、おそらく 259 

570
00:24:17,036 --> 00:24:20,186
です。これが言いたいのは、実際にこのパターンに 

571
00:24:20,186 --> 00:24:23,861
一致する単語が合計 526 個あるとしても、その不確実性

572
00:24:23,861 --> 00:24:25,961
の量は、同 じ可能性の 259 

573
00:24:25,961 --> 00:24:28,980
個があった場合の値に近いということです。結果。

574
00:24:29,720 --> 00:24:30,740
このように考えることができます。

575
00:24:31,020 --> 00:24:33,795
yorts、zorl、zorus の場合と同様に、borx 

576
00:24:33,795 --> 00:24:36,014
が答えではな いことがわかっているため、前のケー

577
00:24:36,014 --> 00:24:37,680
スよりも不確実性が少し低くなります。

578
00:24:37,820 --> 00:24:39,280
このビット数は小さくなります。

579
00:24:40,220 --> 00:24:43,439
そして、ゲームをプレイし続けると、ここで説明したいこ 

580
00:24:43,439 --> 00:24:46,540
とと適切ないくつかの推測を加えてこれを洗練させます。

581
00:24:48,360 --> 00:24:51,109
4 番目の推測では、その上位の候補を見てみると、もはや 

582
00:24:51,109 --> 00:24:53,760
エントロピーを最大化するだけではないことがわかります。

583
00:24:54,460 --> 00:24:57,435
つまり、現時点では技術的には 7 つの可能性がありま 

584
00:24:57,435 --> 00:25:00,300
すが、意味のあるチャンスがあるのは寮と言葉だけです。

585
00:25:00,300 --> 00:25:02,374
そして、これらの両方を選択すると、厳密に言

586
00:25:02,374 --> 00:25:04,448
えば、より多くの情報が 得られる他の値より

587
00:25:04,448 --> 00:25:06,720
も上位にランク付けされていることがわかります。

588
00:25:07,240 --> 00:25:09,173
初めてこれを行ったとき、これら 2 

589
00:25:09,173 --> 00:25:11,644
つの数値を合計して各推測の 質を測定しました。

590
00:25:11,644 --> 00:25:13,900
実際、これは予想以上にうまく機能しました。

591
00:25:14,300 --> 00:25:16,300
しかし、それは実際には体系的とは思えませんでした。

592
00:25:16,300 --> 00:25:17,980
他のアプロー チもあるとは思いますが、私が

593
00:25:17,980 --> 00:25:19,340
たどり着いたアプローチはこれです。

594
00:25:19,760 --> 00:25:22,473
この場合の単語のように、次の推測の見通しを

595
00:25:22,473 --> 00:25:25,186
考慮している場合、本 当に関心があるのは、

596
00:25:25,186 --> 00:25:27,900
それを行った場合のゲームの予想スコアです。

597
00:25:28,230 --> 00:25:30,708
そして、その期待スコアを計算するために、単

598
00:25:30,708 --> 00:25:33,540
語が実際の答えである確 率はいくらかを言います。

599
00:25:33,540 --> 00:25:35,900
現時点では 58% と説明されています。

600
00:25:36,040 --> 00:25:39,540
58% の確率で、このゲームのスコアは 4 になるでしょう。

601
00:25:40,320 --> 00:25:43,960
そして、1 から 58% を引いた確率で、スコアは 

602
00:25:43,960 --> 00:25:45,640
4 より大きくなります。

603
00:25:46,220 --> 00:25:48,267
それ以上はわかりませんが、その時点に到達し

604
00:25:48,267 --> 00:25:50,315
たときにどの程度の不確 実性が存在する可能

605
00:25:50,315 --> 00:25:52,460
性があるかに基づいて推定することはできます。

606
00:25:52,960 --> 00:25:55,940
具体的には、現時点では 1 です。44 ビットの不確実性。

607
00:25:56,440 --> 00:25:58,719
単語を推測すると、得られる期待情報が 

608
00:25:58,719 --> 00:26:01,120
1 であることがわかります。27ビット。

609
00:26:01,620 --> 00:26:04,691
したがって、言葉を推測した場合、この違いは、それが起こった 

610
00:26:04,691 --> 00:26:07,660
後にどの程度の不確実性が残る可能性があるかを表しています。

611
00:26:08,260 --> 00:26:11,097
必要なのは、この不確実性を期待されるスコアに関連付ける、 

612
00:26:11,097 --> 00:26:13,740
ある種の関数 (ここでは f と呼んでいます) です。

613
00:26:14,240 --> 00:26:17,062
そして、これを行う方法は、ボットのバージョン 1 

614
00:26:17,062 --> 00:26:19,997
に基づいて以前のゲー ムからの大量のデータをプロット

615
00:26:19,997 --> 00:26:22,368
して、特定の非常に測定可能な量の不確実性 

616
00:26:22,368 --> 00:26:25,303
を伴うさまざまなポイント後の実際のスコアが何であるか

617
00:26:25,303 --> 00:26:26,320
を示すことでした。

618
00:26:27,020 --> 00:26:29,363
たとえば、これらのデータ ポイントは、8 

619
00:26:29,363 --> 00:26:31,148
程度の値よりも上にあります。8 

620
00:26:31,148 --> 00:26:34,496
人だった時点以降、いくつかの試合では7人ほどが発言している。

621
00:26:34,496 --> 00:26:37,509
7 ビットの不確 実性があり、最終的な答えを得るには 

622
00:26:37,509 --> 00:26:38,960
2 回の推測が必要でした。

623
00:26:39,320 --> 00:26:41,291
他のゲームでは 3 回の推測が必要で、他のゲームでは 

624
00:26:41,291 --> 00:26:42,240
4 回の推測が必要でした。

625
00:26:43,140 --> 00:26:45,828
ここで左にシフトすると、ゼロを超えるすべての

626
00:26:45,828 --> 00:26:48,638
点は、不確実性が ゼロの場合、つまり可能性が 

627
00:26:48,638 --> 00:26:51,327
1 つしかない場合、必要な推測の 数は常に 

628
00:26:51,327 --> 00:26:54,260
1 つだけであり、安心できることを示しています。

629
00:26:54,780 --> 00:26:57,435
少しでも不確実性がある場合、つまり、本質的に可能性が 2 

630
00:26:57,435 --> 00:26:59,540
つ だけであることを意味する場合、さらに 1 

631
00:26:59,540 --> 00:27:01,555
つの推測が必要な 場合もあれば、さらに 2 

632
00:27:01,555 --> 00:27:03,020
つの推測が必要な場合もあります。

633
00:27:03,080 --> 00:27:05,240
などなど。

634
00:27:05,740 --> 00:27:07,930
このデータを視覚化するもう少し簡単な方法は、

635
00:27:07,930 --> 00:27:10,220
データをまとめて平均を取ることかもしれません。

636
00:27:11,000 --> 00:27:13,986
たとえば、このバーは、少し不確実性があったすべ

637
00:27:13,986 --> 00:27:17,622
てのポイントのうち、 必要な新しい推測の数は平均して約 

638
00:27:17,622 --> 00:27:19,960
1 であることを示しています。5. 

639
00:27:22,140 --> 00:27:24,788
そして、ここのバーは、さまざまなゲームすべての中で

640
00:27:24,788 --> 00:27:27,436
、ある時点で 不確実性が 4 ビットをわずかに上回

641
00:27:27,436 --> 00:27:29,766
っていたことを示していま す。これは、16 

642
00:27:29,766 --> 00:27:32,202
の異なる可能性に絞り込むようなもので、その時 

643
00:27:32,202 --> 00:27:35,380
点から平均して 2 つを少し超える推測が必要ですフォワード。

644
00:27:36,060 --> 00:27:37,760
ここからは、これに合理的と思われる関数

645
00:27:37,760 --> 00:27:39,460
を当てはめるために回帰を実行しました。

646
00:27:39,980 --> 00:27:42,906
そして、そのいずれかを行うことの要点は、単語から得られる情

647
00:27:42,906 --> 00:27:44,520
報が多ければ多いほど、期待され 

648
00:27:44,520 --> 00:27:47,446
るスコアが低くなるという直感を定量化できるようにするためで

649
00:27:47,446 --> 00:27:48,960
あることを忘れないでください。

650
00:27:49,680 --> 00:27:52,128
ということで、これをバージョン2とします。

651
00:27:52,128 --> 00:27:55,159
0、戻って同じシミュレーション セットを実行し、2 

652
00:27:55,159 --> 00:27:58,307
315 個の単語の答えすべてに対して実行すると、どうな

653
00:27:58,307 --> 00:27:59,240
るでしょうか? 

654
00:28:00,280 --> 00:28:01,850
最初のバージョンと比べると明らかに

655
00:28:01,850 --> 00:28:03,420
良くなっているので、安心できます。

656
00:28:04,020 --> 00:28:06,075
全体的に見て平均は 3 程度です。

657
00:28:06,075 --> 00:28:08,251
ただし、最初のバージョンとは異なり 

658
00:28:08,251 --> 00:28:10,911
、この状況では失われ、6 つ以上が必要になる

659
00:28:10,911 --> 00:28:12,120
ことが数回あります。

660
00:28:12,639 --> 00:28:15,334
おそらく、情報を最大化するのではなく、実際に目標を達成する 

661
00:28:15,334 --> 00:28:17,940
ためにトレードオフが発生する場合があるからだと思われます。

662
00:28:19,040 --> 00:28:21,000
では、3よりもうまくできるでしょうか。6? 

663
00:28:22,080 --> 00:28:22,920
間違いなくできます。

664
00:28:23,280 --> 00:28:26,432
さて、冒頭で、Wordle の回答の真のリストをモデル 

665
00:28:26,432 --> 00:28:29,360
の構築方法に組み入れないのが最も楽しいと言いました。

666
00:28:29,880 --> 00:28:31,980
しかし、それを組み込んだ場合、得られる最高

667
00:28:31,980 --> 00:28:34,180
のパフォーマンスは 3 程度でした。43. 

668
00:28:35,160 --> 00:28:37,805
したがって、この事前分布を選択するために単語頻度データを使用

669
00:28:37,805 --> 00:28:39,480
するだけではなく、より洗練されたもの 

670
00:28:39,480 --> 00:28:41,419
にしようとすると、この 3.おそらく 43 

671
00:28:41,419 --> 00:28:42,830
が、これでどれだけうまくできる 

672
00:28:42,830 --> 00:28:45,475
か、少なくともどれくらいうまくできるかという最大値を示してい

673
00:28:45,475 --> 00:28:45,740
ます。

674
00:28:46,240 --> 00:28:48,460
その最高のパフォーマンスは、基本的には私がここ

675
00:28:48,460 --> 00:28:50,679
で話してきたア イデアを使用しているだけですが

676
00:28:50,679 --> 00:28:52,706
、期待される情報を 1 歩では なく 2 

677
00:28:52,706 --> 00:28:55,120
歩前進して検索するなど、さらに一歩進んだものです。

678
00:28:55,620 --> 00:28:57,966
当初はそれについてもっと話すつもりでしたが、実際 

679
00:28:57,966 --> 00:29:00,220
にはかなり長くなってしまったことに気づきました。

680
00:29:00,580 --> 00:29:02,689
私が言えるのは、この 2 段階の検索を行った後、上位

681
00:29:02,689 --> 00:29:04,799
候補でいくつかのサ ンプル シミュレーションを実行し

682
00:29:04,799 --> 00:29:06,990
た結果、少なくとも私にとって今のとこ ろ、Crane 

683
00:29:06,990 --> 00:29:09,100
が最良のオープナーであるように見えるということです。

684
00:29:09,100 --> 00:29:10,060
誰が予想したでしょうか？

685
00:29:10,920 --> 00:29:13,220
また、真の Wordle リストを使用して可

686
00:29:13,220 --> 00:29:15,624
能性の空間を決定する場 合、最初の不確実性は 

687
00:29:15,624 --> 00:29:17,820
11 ビットをわずかに超える値になります。

688
00:29:18,300 --> 00:29:22,220
そして、総当たり検索から、最初の 2 つの推測の後に予想さ 

689
00:29:22,220 --> 00:29:25,880
れる最大情報は約 10 ビットであることがわかりました。

690
00:29:26,500 --> 00:29:28,802
これは、最良のシナリオでは、最初の 2 

691
00:29:28,802 --> 00:29:31,796
つの推測の後、完全に最適なプレ イを行った場合、約 

692
00:29:31,796 --> 00:29:34,560
1 ビットの不確実性が残ることを示唆しています。

693
00:29:34,800 --> 00:29:37,960
これは、可能な推測が 2 つに絞られるのと同じです。

694
00:29:37,960 --> 00:29:40,977
したがって、この平均を 3 という低い値にするアルゴリズム

695
00:29:40,977 --> 00:29:43,995
を作成することは 不可能である、と言うのは公平であり、おそ

696
00:29:43,995 --> 00:29:45,764
らくかなり保守的だと思います。な 

697
00:29:45,764 --> 00:29:47,845
ぜなら、利用可能な単語では、たった 2 

698
00:29:47,845 --> 00:29:50,758
つのステップで十分な情報を取得す る余地がないからです。

699
00:29:50,758 --> 00:29:53,360
毎回必ず 3 番目のスロットの答えを保証できます。

