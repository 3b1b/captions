1
00:00:00,000 --> 00:00:03,311
Permainan Wurdle telah menjadi sangat viral dalam satu atau dua bulan terakhir,

2
00:00:03,311 --> 00:00:06,622
dan tidak ada seorangpun yang melewatkan kesempatan untuk pelajaran matematika,

3
00:00:06,622 --> 00:00:10,057
menurut saya permainan ini menjadi contoh sentral yang sangat baik dalam pelajaran

4
00:00:10,057 --> 00:00:13,120
tentang teori informasi, dan khususnya topik yang dikenal sebagai entropi.

5
00:00:13,120 --> 00:00:16,547
Anda tahu, seperti kebanyakan orang, saya terjebak dalam teka-teki,

6
00:00:16,547 --> 00:00:19,873
dan seperti kebanyakan programmer, saya juga terjebak dalam upaya

7
00:00:19,873 --> 00:00:23,200
menulis algoritma yang akan memainkan permainan seoptimal mungkin.

8
00:00:23,200 --> 00:00:26,148
Dan apa yang saya pikir akan saya lakukan di sini hanyalah membicarakan dengan Anda

9
00:00:26,148 --> 00:00:29,026
beberapa proses saya di dalamnya, dan menjelaskan beberapa perhitungan matematika

10
00:00:29,026 --> 00:00:32,080
yang masuk ke dalamnya, karena keseluruhan algoritma berpusat pada gagasan entropi ini.

11
00:00:32,080 --> 00:00:42,180
Hal pertama yang pertama, jika Anda belum pernah mendengarnya, apa itu Wurdle?

12
00:00:42,180 --> 00:00:45,199
Dan untuk membunuh dua burung dengan satu batu di sini sementara kita membahas aturan

13
00:00:45,199 --> 00:00:47,868
permainannya, izinkan saya juga melihat ke mana tujuan kita dengan hal ini,

14
00:00:47,868 --> 00:00:50,993
yaitu mengembangkan algoritma kecil yang pada dasarnya akan memainkan permainan tersebut

15
00:00:50,993 --> 00:00:51,380
untuk kita.

16
00:00:51,380 --> 00:00:53,966
Meskipun saya belum melakukan Wurdle hari ini, ini tanggal 4 Februari,

17
00:00:53,966 --> 00:00:55,860
dan kita akan melihat bagaimana botnya melakukannya.

18
00:00:55,860 --> 00:00:58,431
Tujuan Wurdle adalah menebak kata misteri lima huruf,

19
00:00:58,431 --> 00:01:00,860
dan Anda diberi enam peluang berbeda untuk menebak.

20
00:01:00,860 --> 00:01:05,240
Misalnya, bot Wurdle saya menyarankan agar saya memulai dengan tebakan derek.

21
00:01:05,240 --> 00:01:07,866
Setiap kali Anda menebak, Anda mendapatkan informasi

22
00:01:07,866 --> 00:01:10,940
tentang seberapa dekat tebakan Anda dengan jawaban sebenarnya.

23
00:01:10,940 --> 00:01:14,540
Di sini kotak abu-abu memberi tahu saya bahwa tidak ada C pada jawaban sebenarnya.

24
00:01:14,540 --> 00:01:18,340
Kotak kuning memberitahu saya ada huruf R, tapi posisinya tidak seperti itu.

25
00:01:18,340 --> 00:01:21,613
Kotak hijau memberitahu saya bahwa kata rahasianya memang memiliki nilai A,

26
00:01:21,613 --> 00:01:22,820
dan berada di posisi ketiga.

27
00:01:22,820 --> 00:01:24,300
Dan kemudian tidak ada N dan tidak ada E.

28
00:01:24,300 --> 00:01:27,420
Jadi izinkan saya masuk dan memberi tahu bot Wurdle informasi itu.

29
00:01:27,420 --> 00:01:31,500
Kami mulai dengan crane, kami mendapat warna abu-abu, kuning, hijau, abu-abu, abu-abu.

30
00:01:31,500 --> 00:01:33,930
Jangan khawatir tentang semua data yang ditampilkan saat ini,

31
00:01:33,930 --> 00:01:35,460
saya akan menjelaskannya pada waktunya.

32
00:01:35,460 --> 00:01:39,700
Tapi saran utamanya untuk pilihan kedua kami adalah buruk.

33
00:01:39,700 --> 00:01:42,241
Dan tebakan Anda memang harus berupa kata yang terdiri dari lima huruf,

34
00:01:42,241 --> 00:01:45,311
tetapi seperti yang akan Anda lihat, tebakannya cukup liberal karena memungkinkan Anda

35
00:01:45,311 --> 00:01:45,700
menebaknya.

36
00:01:45,700 --> 00:01:48,860
Dalam hal ini, kami mencoba shtick.

37
00:01:48,860 --> 00:01:50,260
Dan baiklah, semuanya terlihat cukup bagus.

38
00:01:50,260 --> 00:01:54,740
Kita tekan S dan H, jadi kita tahu tiga huruf pertama, kita tahu ada R.

39
00:01:54,740 --> 00:01:59,740
Jadi itu akan menjadi seperti SHA sesuatu R, atau SHA R sesuatu.

40
00:01:59,740 --> 00:02:03,777
Dan sepertinya bot Wurdle mengetahui bahwa hanya ada dua kemungkinan,

41
00:02:03,777 --> 00:02:05,220
yaitu pecahan atau tajam.

42
00:02:05,220 --> 00:02:07,581
Saat ini ada semacam perselisihan di antara mereka,

43
00:02:07,581 --> 00:02:11,260
jadi saya kira mungkin hanya karena sesuai abjad, maka itu sesuai dengan pecahan.

44
00:02:11,260 --> 00:02:13,000
Yang mana hore, itulah jawaban sebenarnya.

45
00:02:13,000 --> 00:02:14,660
Jadi kami mendapatkannya dalam tiga.

46
00:02:14,660 --> 00:02:17,762
Jika Anda bertanya-tanya apakah itu bagus, saya mendengar satu orang

47
00:02:17,762 --> 00:02:20,820
berkata bahwa dengan Wurdle empat adalah par dan tiga adalah birdie.

48
00:02:20,820 --> 00:02:22,960
Yang menurut saya merupakan analogi yang cukup tepat.

49
00:02:22,960 --> 00:02:26,273
Anda harus konsisten dalam permainan Anda untuk mendapatkan empat,

50
00:02:26,273 --> 00:02:27,560
tapi itu jelas tidak gila.

51
00:02:27,560 --> 00:02:30,000
Tapi ketika Anda mendapatkannya dalam tiga, rasanya luar biasa.

52
00:02:30,000 --> 00:02:33,149
Jadi jika Anda menginginkannya, yang ingin saya lakukan di sini hanyalah

53
00:02:33,149 --> 00:02:36,600
membahas proses pemikiran saya dari awal tentang cara saya mendekati bot Wurdle.

54
00:02:36,600 --> 00:02:39,800
Dan seperti yang saya katakan, ini sebenarnya alasan untuk pelajaran teori informasi.

55
00:02:39,800 --> 00:02:48,560
Tujuan utamanya adalah menjelaskan apa itu informasi dan apa itu entropi.

56
00:02:48,560 --> 00:02:50,998
Pikiran pertama saya dalam melakukan pendekatan ini adalah

57
00:02:50,998 --> 00:02:53,560
melihat frekuensi relatif berbagai huruf dalam bahasa Inggris.

58
00:02:53,560 --> 00:02:56,525
Jadi saya berpikir, oke, apakah ada tebakan pembuka atau

59
00:02:56,525 --> 00:02:59,960
tebakan pembuka yang banyak mengenai huruf yang paling sering ini?

60
00:02:59,960 --> 00:03:01,972
Dan salah satu hal yang sangat saya sukai adalah

61
00:03:01,972 --> 00:03:03,780
melakukan hal lain yang diikuti dengan paku.

62
00:03:03,780 --> 00:03:05,725
Pemikirannya adalah jika Anda menekan sebuah huruf, Anda tahu,

63
00:03:05,725 --> 00:03:07,980
Anda mendapatkan warna hijau atau kuning, itu selalu terasa menyenangkan.

64
00:03:07,980 --> 00:03:09,460
Rasanya seperti Anda mendapatkan informasi.

65
00:03:09,460 --> 00:03:12,199
Namun dalam kasus ini, bahkan jika Anda tidak memukul dan Anda selalu

66
00:03:12,199 --> 00:03:14,822
mendapatkan warna abu-abu, itu tetap memberi Anda banyak informasi

67
00:03:14,822 --> 00:03:17,640
karena sangat jarang menemukan kata yang tidak memiliki huruf-huruf ini.

68
00:03:17,640 --> 00:03:20,837
Namun tetap saja, hal tersebut tidak terasa super sistematis,

69
00:03:20,837 --> 00:03:23,520
karena misalnya, tidak memperhitungkan urutan huruf.

70
00:03:23,520 --> 00:03:26,080
Mengapa mengetik paku ketika saya bisa mengetik siput?

71
00:03:26,080 --> 00:03:27,720
Apakah lebih baik memiliki S di akhir?

72
00:03:27,720 --> 00:03:28,720
Saya tidak begitu yakin.

73
00:03:28,720 --> 00:03:32,652
Sekarang, seorang teman saya mengatakan bahwa dia suka membuka dengan kata letih,

74
00:03:32,652 --> 00:03:36,872
yang membuat saya terkejut karena ada beberapa huruf yang tidak biasa di sana seperti W

75
00:03:36,872 --> 00:03:37,160
dan Y.

76
00:03:37,160 --> 00:03:39,400
Tapi siapa tahu, mungkin itu pembuka yang lebih baik.

77
00:03:39,400 --> 00:03:44,920
Adakah skor kuantitatif yang bisa kita berikan untuk menilai kualitas tebakan potensial?

78
00:03:44,920 --> 00:03:47,998
Sekarang untuk mempersiapkan cara kita menentukan peringkat kemungkinan tebakan,

79
00:03:47,998 --> 00:03:50,279
mari kita kembali dan menambahkan sedikit kejelasan tentang

80
00:03:50,279 --> 00:03:51,800
bagaimana tepatnya permainan ini diatur.

81
00:03:51,800 --> 00:03:54,761
Jadi ada daftar kata yang dapat Anda masukkan yang dianggap

82
00:03:54,761 --> 00:03:57,920
sebagai tebakan valid yang panjangnya hanya sekitar 13.000 kata.

83
00:03:57,920 --> 00:04:01,399
Tapi kalau dilihat-lihat, ada banyak hal yang sangat tidak biasa,

84
00:04:01,399 --> 00:04:06,038
seperti kepala atau Ali dan ARG, kata-kata yang menimbulkan pertengkaran keluarga dalam

85
00:04:06,038 --> 00:04:07,040
permainan Scrabble.

86
00:04:07,040 --> 00:04:10,600
Namun inti dari permainan ini adalah bahwa jawabannya akan selalu berupa kata yang umum.

87
00:04:10,600 --> 00:04:13,367
Dan faktanya, ada daftar lain yang berisi sekitar

88
00:04:13,367 --> 00:04:16,080
2.300 kata yang merupakan kemungkinan jawabannya.

89
00:04:16,080 --> 00:04:18,368
Dan ini adalah daftar yang dikurasi oleh manusia,

90
00:04:18,368 --> 00:04:21,800
menurut saya khususnya oleh pacar pembuat game, dan itu cukup menyenangkan.

91
00:04:21,800 --> 00:04:24,650
Tapi yang ingin saya lakukan, tantangan kita untuk proyek ini

92
00:04:24,650 --> 00:04:27,455
adalah melihat apakah kita bisa menulis program penyelesaian

93
00:04:27,455 --> 00:04:30,720
Wordle yang tidak memasukkan pengetahuan sebelumnya tentang daftar ini.

94
00:04:30,720 --> 00:04:33,209
Untuk satu hal, ada banyak kata lima huruf yang cukup

95
00:04:33,209 --> 00:04:35,560
umum yang tidak akan Anda temukan dalam daftar itu.

96
00:04:35,560 --> 00:04:38,835
Jadi akan lebih baik untuk menulis sebuah program yang sedikit lebih tangguh dan dapat

97
00:04:38,835 --> 00:04:41,960
memainkan Wordle melawan siapa pun, bukan hanya apa yang terjadi di situs resminya.

98
00:04:41,960 --> 00:04:44,932
Dan juga alasan kita mengetahui daftar kemungkinan jawaban ini,

99
00:04:44,932 --> 00:04:47,440
adalah karena daftar tersebut terlihat di kode sumber.

100
00:04:47,440 --> 00:04:50,198
Namun tampilannya di kode sumber sesuai dengan

101
00:04:50,198 --> 00:04:52,840
urutan jawaban yang muncul dari hari ke hari.

102
00:04:52,840 --> 00:04:56,400
Jadi, Anda selalu bisa mencari tahu apa jawaban besok.

103
00:04:56,400 --> 00:04:59,140
Jelas sekali, ada kesan bahwa menggunakan daftar itu curang.

104
00:04:59,140 --> 00:05:02,342
Dan apa yang menjadikan teka-teki ini lebih menarik dan pelajaran teori

105
00:05:02,342 --> 00:05:05,501
informasi yang lebih kaya adalah dengan menggunakan beberapa data yang

106
00:05:05,501 --> 00:05:08,392
lebih universal seperti frekuensi kata relatif secara umum untuk

107
00:05:08,392 --> 00:05:11,640
menangkap intuisi mengenai preferensi terhadap kata-kata yang lebih umum.

108
00:05:11,640 --> 00:05:16,560
Jadi dari 13.000 kemungkinan ini, bagaimana sebaiknya kita memilih tebakan pembuka?

109
00:05:16,560 --> 00:05:19,960
Misalnya, jika teman saya melamar dengan letih, bagaimana kita menganalisis kualitasnya?

110
00:05:19,960 --> 00:05:22,585
Nah, alasan dia mengatakan dia menyukai W yang tidak mungkin

111
00:05:22,585 --> 00:05:25,340
itu adalah karena dia menyukai sifat pukulan jarak jauh tentang

112
00:05:25,340 --> 00:05:27,880
betapa nikmatnya rasanya jika Anda berhasil mencapai W itu.

113
00:05:27,880 --> 00:05:31,327
Misalnya, jika pola pertama yang terungkap kira-kira seperti ini,

114
00:05:31,327 --> 00:05:35,348
maka ternyata hanya ada 58 kata dalam leksikon raksasa ini yang cocok dengan

115
00:05:35,348 --> 00:05:36,080
pola tersebut.

116
00:05:36,080 --> 00:05:38,900
Jadi itu pengurangan yang sangat besar dari 13.000.

117
00:05:38,900 --> 00:05:43,360
Namun sisi sebaliknya tentu saja sangat jarang mendapatkan pola seperti ini.

118
00:05:43,360 --> 00:05:48,010
Secara khusus, jika setiap kata mempunyai kemungkinan yang sama untuk menjadi jawabannya,

119
00:05:48,010 --> 00:05:51,680
kemungkinan untuk mendapatkan pola ini adalah 58 dibagi sekitar 13.000.

120
00:05:51,680 --> 00:05:53,880
Tentu saja, kemungkinan jawaban tersebut tidak sama.

121
00:05:53,880 --> 00:05:56,680
Kebanyakan dari kata-kata ini sangat tidak jelas dan bahkan dipertanyakan.

122
00:05:56,680 --> 00:05:58,734
Tapi setidaknya untuk langkah pertama kita dalam semua hal ini,

123
00:05:58,734 --> 00:06:01,269
mari kita asumsikan bahwa semuanya memiliki kemungkinan yang sama dan kemudian

124
00:06:01,269 --> 00:06:02,040
menyempurnakannya nanti.

125
00:06:02,040 --> 00:06:07,360
Intinya adalah pola dengan banyak informasi pada dasarnya tidak mungkin terjadi.

126
00:06:07,360 --> 00:06:11,920
Faktanya, yang dimaksud dengan informatif adalah bahwa hal itu tidak mungkin.

127
00:06:11,920 --> 00:06:15,849
Pola yang lebih mungkin terlihat pada pembukaan ini adalah seperti ini,

128
00:06:15,849 --> 00:06:18,360
yang tentu saja tidak ada huruf W di dalamnya.

129
00:06:18,360 --> 00:06:22,080
Mungkin ada E, dan mungkin tidak ada A, tidak ada R, tidak ada Y.

130
00:06:22,080 --> 00:06:24,640
Dalam hal ini, ada 1400 kemungkinan kecocokan.

131
00:06:24,640 --> 00:06:27,864
Jika semua memiliki kemungkinan yang sama, maka kemungkinannya

132
00:06:27,864 --> 00:06:30,680
sekitar 11% bahwa ini adalah pola yang akan Anda lihat.

133
00:06:30,680 --> 00:06:34,320
Jadi hasil yang paling mungkin juga paling tidak informatif.

134
00:06:34,320 --> 00:06:36,803
Untuk mendapatkan gambaran yang lebih global di sini,

135
00:06:36,803 --> 00:06:40,528
izinkan saya menunjukkan kepada Anda distribusi penuh probabilitas di semua pola

136
00:06:40,528 --> 00:06:42,000
berbeda yang mungkin Anda lihat.

137
00:06:42,000 --> 00:06:45,551
Jadi tiap batang yang Anda lihat sesuai dengan kemungkinan pola warna

138
00:06:45,551 --> 00:06:48,951
yang dapat ditampilkan, yang mana terdapat 3 hingga 5 kemungkinan,

139
00:06:48,951 --> 00:06:52,960
dan disusun dari kiri ke kanan, yang paling umum hingga yang paling tidak umum.

140
00:06:52,960 --> 00:06:56,200
Jadi kemungkinan paling umum di sini adalah Anda mendapatkan warna abu-abu.

141
00:06:56,200 --> 00:06:58,800
Itu terjadi sekitar 14% dari seluruh kasus.

142
00:06:58,800 --> 00:07:02,451
Dan yang Anda harapkan saat menebak adalah Anda berakhir di suatu

143
00:07:02,451 --> 00:07:06,047
tempat di ekor panjang ini, seperti di sini di mana hanya ada 18

144
00:07:06,047 --> 00:07:09,920
kemungkinan yang cocok dengan pola yang ternyata terlihat seperti ini.

145
00:07:09,920 --> 00:07:14,080
Atau jika kita melangkah lebih jauh ke kiri, mungkin kita akan terus ke sini.

146
00:07:14,080 --> 00:07:16,560
Oke, ini teka-teki yang bagus untuk Anda.

147
00:07:16,560 --> 00:07:19,101
Apa tiga kata dalam bahasa Inggris yang dimulai dengan huruf W,

148
00:07:19,101 --> 00:07:22,040
diakhiri dengan huruf Y, dan memiliki huruf R di suatu tempat di dalamnya?

149
00:07:22,040 --> 00:07:27,560
Ternyata jawabannya adalah, mari kita lihat, bertele-tele, cacingan, dan masam.

150
00:07:27,560 --> 00:07:31,183
Jadi untuk menilai seberapa bagus kata ini secara keseluruhan,

151
00:07:31,183 --> 00:07:36,360
kami ingin mengukur perkiraan jumlah informasi yang akan Anda peroleh dari distribusi ini.

152
00:07:36,360 --> 00:07:39,503
Jika kita menelusuri setiap pola dan mengalikan kemungkinan

153
00:07:39,503 --> 00:07:43,432
terjadinya dengan sesuatu yang mengukur seberapa informatif pola tersebut,

154
00:07:43,432 --> 00:07:46,000
hal itu mungkin dapat memberi kita skor objektif.

155
00:07:46,000 --> 00:07:47,991
Sekarang insting pertama Anda tentang apa yang

156
00:07:47,991 --> 00:07:50,280
seharusnya terjadi mungkin adalah jumlah pertandingan.

157
00:07:50,280 --> 00:07:52,960
Anda menginginkan jumlah rata-rata kecocokan yang lebih rendah.

158
00:07:52,960 --> 00:07:57,286
Namun saya ingin menggunakan pengukuran yang lebih universal yang sering kita

159
00:07:57,286 --> 00:08:01,724
anggap berasal dari informasi, dan pengukuran yang akan lebih fleksibel setelah

160
00:08:01,724 --> 00:08:06,328
kita menetapkan probabilitas berbeda untuk masing-masing dari 13.000 kata tersebut

161
00:08:06,328 --> 00:08:10,600
untuk mengetahui apakah kata-kata tersebut benar-benar jawabannya atau tidak.

162
00:08:10,600 --> 00:08:14,745
Satuan standar informasi adalah bit, yang memiliki rumus yang sedikit lucu,

163
00:08:14,745 --> 00:08:17,800
namun sangat intuitif jika kita hanya melihat contohnya.

164
00:08:17,800 --> 00:08:21,070
Jika Anda mempunyai pengamatan yang membagi dua kemungkinan yang ada,

165
00:08:21,070 --> 00:08:24,200
kami katakan bahwa pengamatan tersebut mempunyai sedikit informasi.

166
00:08:24,200 --> 00:08:26,866
Dalam contoh kita, ruang kemungkinannya adalah semua kemungkinan kata,

167
00:08:26,866 --> 00:08:29,494
dan ternyata sekitar setengah dari lima huruf kata mempunyai huruf S,

168
00:08:29,494 --> 00:08:31,560
sedikit lebih kecil dari itu, tapi sekitar setengahnya.

169
00:08:31,560 --> 00:08:35,200
Sehingga pengamatan itu akan memberi Anda sedikit informasi.

170
00:08:35,200 --> 00:08:39,298
Jika suatu fakta baru memperkecil ruang kemungkinan tersebut sebanyak empat kali lipat,

171
00:08:39,298 --> 00:08:42,000
kita katakan bahwa fakta tersebut mempunyai dua informasi.

172
00:08:42,000 --> 00:08:45,120
Misalnya, ternyata sekitar seperempat dari kata-kata ini memiliki huruf T.

173
00:08:45,120 --> 00:08:47,897
Jika observasi memotong ruang tersebut sebanyak delapan kali lipat,

174
00:08:47,897 --> 00:08:50,920
kita katakan itu adalah tiga bit informasi, dan seterusnya dan seterusnya.

175
00:08:50,920 --> 00:08:55,000
Empat bit memotongnya menjadi 16, lima bit memotongnya menjadi 32.

176
00:08:55,000 --> 00:08:59,760
Jadi sekarang Anda mungkin ingin berhenti sejenak dan bertanya pada diri sendiri,

177
00:08:59,760 --> 00:09:04,520
apa rumus informasi jumlah bit dalam kaitannya dengan probabilitas suatu kejadian?

178
00:09:04,520 --> 00:09:08,310
Apa yang ingin kami katakan di sini adalah ketika Anda mengambil setengah dari jumlah

179
00:09:08,310 --> 00:09:12,144
bit, itu sama dengan probabilitas, yang sama dengan mengatakan dua pangkat dari jumlah

180
00:09:12,144 --> 00:09:16,022
bit adalah satu di atas probabilitas, yaitu menyusun ulang lebih jauh dengan mengatakan

181
00:09:16,022 --> 00:09:19,680
bahwa informasi tersebut adalah basis log dua dari satu dibagi dengan probabilitas.

182
00:09:19,680 --> 00:09:22,680
Dan kadang-kadang Anda melihat ini dengan satu penataan ulang lagi,

183
00:09:22,680 --> 00:09:25,680
di mana informasinya adalah log negatif basis dua dari probabilitas.

184
00:09:25,680 --> 00:09:29,668
Jika diungkapkan seperti ini, hal ini mungkin terlihat sedikit aneh bagi yang belum tahu,

185
00:09:29,668 --> 00:09:32,815
namun sebenarnya ini hanyalah gagasan intuitif untuk menanyakan berapa

186
00:09:32,815 --> 00:09:35,120
kali Anda telah mengurangi separuh kemungkinan Anda.

187
00:09:35,120 --> 00:09:37,583
Sekarang jika Anda bertanya-tanya, Anda tahu, saya pikir kita hanya memainkan

188
00:09:37,583 --> 00:09:39,920
permainan kata yang menyenangkan, mengapa logaritma masuk ke dalam gambar?

189
00:09:39,920 --> 00:09:43,298
Salah satu alasan unit ini lebih bagus adalah karena lebih mudah untuk

190
00:09:43,298 --> 00:09:46,057
membicarakan peristiwa yang sangat tidak mungkin terjadi,

191
00:09:46,057 --> 00:09:49,340
lebih mudah untuk mengatakan bahwa suatu pengamatan mempunyai 20 bit

192
00:09:49,340 --> 00:09:53,480
informasi daripada mengatakan bahwa probabilitas kejadian ini dan itu adalah 0.0000095.

193
00:09:53,480 --> 00:09:57,456
Namun alasan yang lebih substantif mengapa ekspresi logaritmik ini ternyata menjadi

194
00:09:57,456 --> 00:10:01,432
tambahan yang sangat berguna bagi teori probabilitas adalah cara informasi tersebut

195
00:10:01,432 --> 00:10:02,000
dijumlahkan.

196
00:10:02,000 --> 00:10:05,032
Misalnya, jika satu observasi memberi Anda dua bit informasi,

197
00:10:05,032 --> 00:10:08,652
mengurangi ruang Anda menjadi empat, dan kemudian observasi kedua seperti

198
00:10:08,652 --> 00:10:11,930
tebakan kedua Anda di Wordle memberi Anda tiga bit informasi lagi,

199
00:10:11,930 --> 00:10:14,914
mengurangi Anda lebih jauh lagi sebanyak delapan kali lipat,

200
00:10:14,914 --> 00:10:17,360
maka dua bersama-sama memberi Anda lima informasi.

201
00:10:17,360 --> 00:10:21,200
Sama seperti probabilitas yang berlipat ganda, informasi juga suka bertambah.

202
00:10:21,200 --> 00:10:24,390
Jadi segera setelah kita berada di bidang nilai yang diharapkan,

203
00:10:24,390 --> 00:10:28,660
di mana kita menambahkan banyak angka, log akan membuatnya lebih mudah untuk ditangani.

204
00:10:28,660 --> 00:10:32,325
Mari kita kembali ke distribusi Weary dan menambahkan pelacak kecil lainnya di sini,

205
00:10:32,325 --> 00:10:35,560
menunjukkan kepada kita berapa banyak informasi yang ada untuk setiap pola.

206
00:10:35,560 --> 00:10:38,306
Hal utama yang saya ingin Anda perhatikan adalah semakin tinggi

207
00:10:38,306 --> 00:10:40,624
kemungkinan kita mendapatkan pola yang lebih mungkin,

208
00:10:40,624 --> 00:10:43,500
semakin rendah informasinya, semakin sedikit bit yang Anda peroleh.

209
00:10:43,500 --> 00:10:47,373
Cara kita mengukur kualitas tebakan ini adalah dengan mengambil nilai yang diharapkan

210
00:10:47,373 --> 00:10:49,895
dari informasi tersebut, dengan menelusuri setiap pola,

211
00:10:49,895 --> 00:10:53,678
kita tentukan seberapa besar kemungkinannya, lalu kita kalikan dengan berapa banyak

212
00:10:53,678 --> 00:10:54,940
informasi yang kita peroleh.

213
00:10:54,940 --> 00:10:58,480
Dan dalam contoh Weary, ternyata menjadi 4.9 bit.

214
00:10:58,480 --> 00:11:02,070
Jadi rata-rata, informasi yang Anda dapatkan dari tebakan pembuka ini sama baiknya

215
00:11:02,070 --> 00:11:05,660
dengan memotong ruang kemungkinan Anda menjadi setengahnya sekitar lima kali lipat.

216
00:11:05,660 --> 00:11:09,440
Sebaliknya, contoh tebakan dengan nilai informasi

217
00:11:09,440 --> 00:11:13,220
yang diharapkan lebih tinggi adalah seperti Slate.

218
00:11:13,220 --> 00:11:16,180
Dalam hal ini Anda akan melihat distribusinya terlihat lebih datar.

219
00:11:16,180 --> 00:11:20,971
Secara khusus, kemunculan semua warna abu-abu yang paling mungkin hanya memiliki

220
00:11:20,971 --> 00:11:25,940
peluang sekitar 6% untuk muncul, jadi setidaknya Anda mendapatkan 3.9 bit informasi.

221
00:11:25,940 --> 00:11:29,140
Tapi itu jumlah minimum, biasanya Anda akan mendapatkan sesuatu yang lebih baik dari itu.

222
00:11:29,140 --> 00:11:32,753
Dan ternyata ketika Anda menghitung angka-angka ini dan menjumlahkan

223
00:11:32,753 --> 00:11:36,420
semua istilah yang relevan, rata-rata informasinya adalah sekitar 5.8.

224
00:11:36,420 --> 00:11:40,148
Jadi berbeda dengan Weary, rata-rata ruang kemungkinan Anda

225
00:11:40,148 --> 00:11:43,940
akan menjadi sekitar setengahnya setelah tebakan pertama ini.

226
00:11:43,940 --> 00:11:49,540
Sebenarnya ada cerita menarik tentang nama nilai kuantitas informasi yang diharapkan ini.

227
00:11:49,540 --> 00:11:51,680
Teori informasi dikembangkan oleh Claude Shannon,

228
00:11:51,680 --> 00:11:55,361
yang bekerja di Bell Labs pada tahun 1940-an, tetapi dia membicarakan beberapa idenya

229
00:11:55,361 --> 00:11:57,544
yang belum dipublikasikan dengan John von Neumann,

230
00:11:57,544 --> 00:12:00,455
yang merupakan raksasa intelektual pada saat itu, sangat terkemuka.

231
00:12:00,455 --> 00:12:04,180
dalam matematika dan fisika dan permulaan dari apa yang kemudian menjadi ilmu komputer.

232
00:12:04,180 --> 00:12:07,585
Dan ketika dia menyebutkan bahwa dia tidak benar-benar memiliki nama yang

233
00:12:07,585 --> 00:12:11,498
bagus untuk nilai yang diharapkan dari kuantitas informasi ini, von Neumann berkata,

234
00:12:11,498 --> 00:12:14,720
jadi ceritanya, Anda harus menyebutnya entropi, dan karena dua alasan.

235
00:12:14,720 --> 00:12:18,793
Pertama, fungsi ketidakpastian Anda telah digunakan dalam mekanika statistik dengan nama

236
00:12:18,793 --> 00:12:22,225
tersebut, sehingga sudah memiliki nama, dan kedua, dan yang lebih penting,

237
00:12:22,225 --> 00:12:26,024
tidak ada yang tahu apa sebenarnya entropi, jadi dalam perdebatan Anda akan selalu

238
00:12:26,024 --> 00:12:26,940
memiliki keuntungan.

239
00:12:26,940 --> 00:12:32,085
Jadi jika namanya tampak sedikit misterius, dan jika cerita ini dapat dipercaya,

240
00:12:32,085 --> 00:12:33,420
itu memang disengaja.

241
00:12:33,420 --> 00:12:36,718
Juga jika Anda bertanya-tanya tentang hubungannya dengan semua hukum

242
00:12:36,718 --> 00:12:39,395
kedua termodinamika dari fisika, pasti ada hubungannya,

243
00:12:39,395 --> 00:12:43,076
tetapi pada awalnya Shannon hanya berurusan dengan teori probabilitas murni,

244
00:12:43,076 --> 00:12:46,661
dan untuk tujuan kita di sini, ketika saya menggunakan teori kata entropi,

245
00:12:46,661 --> 00:12:50,820
saya hanya ingin Anda memikirkan nilai informasi yang diharapkan dari tebakan tertentu.

246
00:12:50,820 --> 00:12:54,380
Anda dapat menganggap entropi sebagai mengukur dua hal secara bersamaan.

247
00:12:54,380 --> 00:12:57,420
Yang pertama adalah seberapa datar distribusinya.

248
00:12:57,420 --> 00:13:01,700
Semakin dekat suatu distribusi ke seragam, semakin tinggi entropinya.

249
00:13:01,700 --> 00:13:06,341
Dalam kasus kita, jika terdapat 3 hingga 5 pola total, untuk distribusi seragam,

250
00:13:06,341 --> 00:13:10,582
mengamati salah satu dari pola tersebut akan memiliki basis log informasi

251
00:13:10,582 --> 00:13:13,447
2 dari 3 hingga 5, yang kebetulan berjumlah 7.92,

252
00:13:13,447 --> 00:13:17,860
jadi itulah nilai maksimum mutlak yang mungkin Anda miliki untuk entropi ini.

253
00:13:17,860 --> 00:13:22,900
Namun entropi juga merupakan ukuran seberapa banyak kemungkinan yang ada.

254
00:13:22,900 --> 00:13:27,103
Misalnya, jika Anda memiliki suatu kata yang hanya memiliki 16 kemungkinan pola,

255
00:13:27,103 --> 00:13:30,269
dan setiap pola memiliki kemungkinan yang sama, entropi ini,

256
00:13:30,269 --> 00:13:32,760
informasi yang diharapkan, akan berjumlah 4 bit.

257
00:13:32,760 --> 00:13:36,930
Namun jika Anda memiliki kata lain yang memiliki 64 kemungkinan pola yang muncul,

258
00:13:36,930 --> 00:13:41,000
dan semuanya memiliki kemungkinan yang sama, maka entropinya akan menjadi 6 bit.

259
00:13:41,000 --> 00:13:45,653
Jadi, jika Anda melihat suatu distribusi di alam liar yang memiliki entropi 6 bit,

260
00:13:45,653 --> 00:13:49,970
hal ini seperti menyatakan bahwa ada banyak variasi dan ketidakpastian dalam

261
00:13:49,970 --> 00:13:54,400
apa yang akan terjadi, seolah-olah ada 64 kemungkinan hasil yang sama besarnya.

262
00:13:54,400 --> 00:13:58,360
Untuk pass pertama saya di Wurtelebot, pada dasarnya saya menyuruhnya melakukan ini saja.

263
00:13:58,360 --> 00:14:02,517
Ia menelusuri semua kemungkinan tebakan yang Anda miliki, seluruh 13.000 kata,

264
00:14:02,517 --> 00:14:06,148
menghitung entropi untuk masing-masing kata, atau lebih khusus lagi,

265
00:14:06,148 --> 00:14:10,569
entropi distribusi di semua pola yang mungkin Anda lihat, untuk masing-masing kata,

266
00:14:10,569 --> 00:14:15,094
dan memilih yang tertinggi, karena itulah salah satu yang kemungkinan akan mengurangi

267
00:14:15,094 --> 00:14:17,200
ruang kemungkinan Anda sebanyak mungkin.

268
00:14:17,200 --> 00:14:19,553
Dan meskipun saya hanya membicarakan tebakan pertama di sini,

269
00:14:19,553 --> 00:14:21,680
hal yang sama berlaku untuk beberapa tebakan berikutnya.

270
00:14:21,680 --> 00:14:24,808
Misalnya, setelah Anda melihat beberapa pola pada tebakan pertama tersebut,

271
00:14:24,808 --> 00:14:28,019
yang akan membatasi Anda pada kemungkinan kata yang lebih sedikit berdasarkan

272
00:14:28,019 --> 00:14:31,435
kecocokannya, Anda cukup memainkan permainan yang sama terhadap kumpulan kata yang

273
00:14:31,435 --> 00:14:32,300
lebih kecil tersebut.

274
00:14:32,300 --> 00:14:36,485
Untuk usulan tebakan kedua, Anda melihat distribusi semua pola yang dapat

275
00:14:36,485 --> 00:14:39,710
terjadi dari kumpulan kata yang lebih terbatas tersebut,

276
00:14:39,710 --> 00:14:43,726
Anda menelusuri 13.000 kemungkinan, dan Anda menemukan salah satu yang

277
00:14:43,726 --> 00:14:45,480
memaksimalkan entropi tersebut.

278
00:14:45,480 --> 00:14:48,357
Untuk menunjukkan kepada Anda cara kerjanya, izinkan saya

279
00:14:48,357 --> 00:14:51,135
menampilkan sedikit varian Wurtele yang saya tulis yang

280
00:14:51,135 --> 00:14:54,460
menunjukkan hal-hal penting dari analisis ini di bagian pinggirnya.

281
00:14:54,460 --> 00:14:56,505
Setelah melakukan semua perhitungan entropinya,

282
00:14:56,505 --> 00:15:00,340
di sini ia menunjukkan kepada kita mana yang memiliki informasi yang diharapkan tertinggi.

283
00:15:00,340 --> 00:15:05,916
Ternyata jawaban teratas, setidaknya untuk saat ini, akan kita perbaiki nanti,

284
00:15:05,916 --> 00:15:11,140
adalah Taras, yang artinya, um, tentu saja, vetch, vetch yang paling umum.

285
00:15:11,140 --> 00:15:13,618
Tiap kali kita membuat tebakan di sini, mungkin saya mengabaikan

286
00:15:13,618 --> 00:15:15,829
rekomendasinya dan memilih slate, karena saya suka slate,

287
00:15:15,829 --> 00:15:18,384
kita bisa melihat berapa banyak informasi yang diharapkan darinya,

288
00:15:18,384 --> 00:15:20,976
tapi kemudian di sebelah kanan kata ini, ia menunjukkan kepada kita

289
00:15:20,976 --> 00:15:23,988
seberapa banyak informasi yang diharapkan. informasi aktual yang kami peroleh,

290
00:15:23,988 --> 00:15:24,980
mengingat pola khusus ini.

291
00:15:24,980 --> 00:15:27,035
Jadi di sini sepertinya kami sedikit kurang beruntung,

292
00:15:27,035 --> 00:15:29,875
kami diharapkan mendapat nilai 5.8, tapi kebetulan kami mendapatkan sesuatu

293
00:15:29,875 --> 00:15:30,660
yang kurang dari itu.

294
00:15:30,660 --> 00:15:33,196
Dan kemudian di sisi kiri ini menunjukkan kepada kita semua

295
00:15:33,196 --> 00:15:35,860
kemungkinan kata yang berbeda berdasarkan posisi kita sekarang.

296
00:15:35,860 --> 00:15:39,064
Bilah biru memberi tahu kita seberapa besar kemungkinannya untuk memikirkan setiap kata,

297
00:15:39,064 --> 00:15:41,728
sehingga saat ini diasumsikan bahwa setiap kata memiliki kemungkinan yang

298
00:15:41,728 --> 00:15:44,140
sama untuk muncul, namun kami akan menyempurnakannya sebentar lagi.

299
00:15:44,140 --> 00:15:47,840
Dan kemudian pengukuran ketidakpastian ini memberi tahu kita entropi dari

300
00:15:47,840 --> 00:15:52,290
distribusi ini di seluruh kemungkinan kata, yang saat ini, karena distribusinya seragam,

301
00:15:52,290 --> 00:15:55,940
hanyalah cara rumit yang tidak perlu untuk menghitung jumlah kemungkinan.

302
00:15:55,940 --> 00:16:02,700
Misalnya, jika kita ingin 2 dipangkatkan 13.66, itu seharusnya sekitar 13.000 kemungkinan.

303
00:16:02,700 --> 00:16:04,910
Saya sedikit melenceng di sini, tetapi hanya karena

304
00:16:04,910 --> 00:16:06,780
saya tidak menampilkan semua tempat desimal.

305
00:16:06,780 --> 00:16:09,569
Saat ini hal itu mungkin terasa berlebihan dan sepertinya terlalu rumit,

306
00:16:09,569 --> 00:16:12,780
tetapi Anda akan mengerti mengapa ada gunanya memiliki kedua angka dalam satu menit.

307
00:16:12,780 --> 00:16:17,058
Jadi di sini sepertinya entropi tertinggi untuk tebakan kedua kita adalah Ramen,

308
00:16:17,058 --> 00:16:19,700
yang sekali lagi tidak terasa seperti sebuah kata.

309
00:16:19,700 --> 00:16:23,166
Jadi untuk mengambil landasan moral yang tinggi di sini,

310
00:16:23,166 --> 00:16:25,660
saya akan melanjutkan dan mengetik Rains.

311
00:16:25,660 --> 00:16:27,540
Dan sekali lagi sepertinya kami sedikit kurang beruntung.

312
00:16:27,540 --> 00:16:32,100
Kami mengharapkan 4.3 bit dan kami hanya mendapat 3.39 bit informasi.

313
00:16:32,100 --> 00:16:35,060
Jadi itu membawa kita ke 55 kemungkinan.

314
00:16:35,060 --> 00:16:38,597
Dan di sini mungkin saya akan mengikuti apa yang disarankannya,

315
00:16:38,597 --> 00:16:40,200
yaitu kombo, apa pun artinya.

316
00:16:40,200 --> 00:16:43,300
Dan oke, ini sebenarnya kesempatan bagus untuk membuat teka-teki.

317
00:16:43,300 --> 00:16:47,020
Ini memberi tahu kita bahwa pola ini memberi kita 4.7 bit informasi.

318
00:16:47,020 --> 00:16:52,400
Tapi di sebelah kiri, sebelum kita melihat pola itu, ada 5.78 bit ketidakpastian.

319
00:16:52,400 --> 00:16:56,860
Jadi sebagai kuis untuk Anda, apa maksudnya dengan jumlah kemungkinan yang tersisa?

320
00:16:56,860 --> 00:17:00,563
Artinya, kita hanya dihadapkan pada sedikit ketidakpastian,

321
00:17:00,563 --> 00:17:04,700
yang sama saja dengan mengatakan bahwa ada dua kemungkinan jawaban.

322
00:17:04,700 --> 00:17:06,520
Itu adalah pilihan 50-50.

323
00:17:06,520 --> 00:17:09,323
Dan dari sini, karena Anda dan saya tahu kata mana yang lebih umum,

324
00:17:09,323 --> 00:17:11,220
kita tahu bahwa jawabannya pasti sangat buruk.

325
00:17:11,220 --> 00:17:13,540
Namun seperti yang tertulis sekarang, program tersebut tidak mengetahui hal itu.

326
00:17:13,540 --> 00:17:17,385
Jadi ia terus berjalan, berusaha mendapatkan informasi sebanyak-banyaknya,

327
00:17:17,385 --> 00:17:20,360
hingga hanya tersisa satu kemungkinan, lalu ia menebaknya.

328
00:17:20,360 --> 00:17:22,700
Jadi jelas kita memerlukan strategi akhir yang lebih baik.

329
00:17:22,700 --> 00:17:26,720
Tapi katakanlah kita menyebut versi ini sebagai salah satu pemecah kata-kata kita,

330
00:17:26,720 --> 00:17:30,740
dan kemudian kita menjalankan beberapa simulasi untuk melihat bagaimana kinerjanya.

331
00:17:30,740 --> 00:17:34,240
Jadi cara kerjanya adalah dengan memainkan setiap permainan kata yang memungkinkan.

332
00:17:34,240 --> 00:17:38,780
Itu melewati 2.315 kata yang merupakan jawaban kata yang sebenarnya.

333
00:17:38,780 --> 00:17:41,340
Ini pada dasarnya menggunakannya sebagai set pengujian.

334
00:17:41,340 --> 00:17:45,699
Dan dengan metode naif ini dengan tidak mempertimbangkan seberapa umum suatu kata,

335
00:17:45,699 --> 00:17:48,904
dan hanya mencoba memaksimalkan informasi di setiap langkah,

336
00:17:48,904 --> 00:17:50,480
hingga hanya ada satu pilihan.

337
00:17:50,480 --> 00:17:55,100
Pada akhir simulasi, skor rata-rata menjadi sekitar 4.124.

338
00:17:55,100 --> 00:17:59,780
Itu tidak buruk, sejujurnya, saya berharap untuk melakukan yang lebih buruk.

339
00:17:59,780 --> 00:18:01,424
Tetapi orang-orang yang bermain wordle akan memberitahu

340
00:18:01,424 --> 00:18:03,040
Anda bahwa mereka biasanya bisa mendapatkannya dalam 4.

341
00:18:03,040 --> 00:18:05,260
Tantangan sebenarnya adalah mendapatkan sebanyak 3 buah sebanyak yang Anda bisa.

342
00:18:05,260 --> 00:18:08,920
Ini merupakan lompatan yang cukup besar antara skor 4 dan skor 3.

343
00:18:08,920 --> 00:18:16,195
Hal yang jelas terlihat di sini adalah dengan memasukkan apakah suatu

344
00:18:16,195 --> 00:18:23,160
kata itu umum atau tidak, dan bagaimana tepatnya kita melakukannya.

345
00:18:23,160 --> 00:18:25,860
Cara saya mendekatinya adalah dengan mendapatkan daftar

346
00:18:25,860 --> 00:18:28,560
frekuensi relatif untuk semua kata dalam bahasa Inggris.

347
00:18:28,560 --> 00:18:32,015
Dan saya baru saja menggunakan fungsi data frekuensi kata Mathematica,

348
00:18:32,015 --> 00:18:35,520
yang diambil dari kumpulan data publik Google Buku Bahasa Inggris Ngram.

349
00:18:35,520 --> 00:18:37,959
Dan itu menyenangkan untuk dilihat, misalnya jika kita mengurutkannya

350
00:18:37,959 --> 00:18:40,120
dari kata yang paling umum hingga kata yang paling tidak umum.

351
00:18:40,120 --> 00:18:43,740
Rupanya ini adalah kata 5 huruf yang paling umum dalam bahasa Inggris.

352
00:18:43,740 --> 00:18:46,480
Atau lebih tepatnya, ini adalah yang paling umum ke-8.

353
00:18:46,480 --> 00:18:49,440
Pertama yang mana, setelah itu ada disana dan disana.

354
00:18:49,440 --> 00:18:51,962
Yang pertama bukanlah yang pertama, melainkan yang ke-9,

355
00:18:51,962 --> 00:18:54,618
dan masuk akal jika kata-kata lain ini muncul lebih sering,

356
00:18:54,618 --> 00:18:57,096
jika kata setelah yang pertama adalah setelah, di mana,

357
00:18:57,096 --> 00:18:59,000
dan kata-kata tersebut menjadi kurang umum.

358
00:18:59,000 --> 00:19:01,673
Sekarang, dalam menggunakan data ini untuk memodelkan seberapa

359
00:19:01,673 --> 00:19:04,389
besar kemungkinan masing-masing kata ini menjadi jawaban akhir,

360
00:19:04,389 --> 00:19:07,020
data tersebut tidak boleh hanya sebanding dengan frekuensinya.

361
00:19:07,020 --> 00:19:10,152
Misal yang diberi skor 0.002 dalam kumpulan data ini,

362
00:19:10,152 --> 00:19:15,200
sedangkan kata jalinan dalam beberapa hal kemungkinannya sekitar 1000 kali lebih kecil.

363
00:19:15,200 --> 00:19:17,257
Namun keduanya adalah kata-kata yang cukup umum

364
00:19:17,257 --> 00:19:19,400
sehingga hampir pasti layak untuk dipertimbangkan.

365
00:19:19,400 --> 00:19:21,900
Jadi kami ingin lebih banyak pemutusan biner.

366
00:19:21,900 --> 00:19:25,863
Cara saya melakukannya adalah dengan membayangkan mengambil seluruh daftar kata yang

367
00:19:25,863 --> 00:19:28,381
diurutkan ini, dan kemudian menyusunnya pada sumbu x,

368
00:19:28,381 --> 00:19:32,578
dan kemudian menerapkan fungsi sigmoid, yang merupakan cara standar untuk memiliki fungsi

369
00:19:32,578 --> 00:19:35,329
yang keluarannya pada dasarnya biner, itu's baik 0 atau 1,

370
00:19:35,329 --> 00:19:38,500
namun terdapat kelancaran di antara wilayah ketidakpastian tersebut.

371
00:19:38,500 --> 00:19:43,894
Jadi pada dasarnya, probabilitas yang saya tetapkan untuk setiap kata untuk berada di

372
00:19:43,894 --> 00:19:49,540
daftar akhir akan menjadi nilai fungsi sigmoid di atas di mana pun ia berada pada sumbu x.

373
00:19:49,540 --> 00:19:52,234
Tentu saja hal ini bergantung pada beberapa parameter,

374
00:19:52,234 --> 00:19:55,615
misalnya seberapa lebar spasi pada sumbu x kata-kata tersebut terisi

375
00:19:55,615 --> 00:19:58,897
menentukan seberapa bertahap atau tajamnya kita turun dari 1 ke 0,

376
00:19:58,897 --> 00:20:03,160
dan di mana kita menempatkan kata-kata tersebut dari kiri ke kanan menentukan batasnya.

377
00:20:03,160 --> 00:20:07,340
Sejujurnya, caraku melakukan ini hanyalah menjilat jariku dan menempelkannya ke angin.

378
00:20:07,340 --> 00:20:10,818
Saya melihat daftar yang diurutkan dan mencoba menemukan jendela di mana

379
00:20:10,818 --> 00:20:14,201
ketika saya melihatnya, saya pikir sekitar setengah dari kata-kata ini

380
00:20:14,201 --> 00:20:17,680
lebih mungkin menjadi jawaban akhir, dan menggunakannya sebagai batasnya.

381
00:20:17,680 --> 00:20:20,618
Setelah kita mendapatkan distribusi seperti ini di seluruh kata,

382
00:20:20,618 --> 00:20:24,460
ini memberi kita situasi lain di mana entropi menjadi pengukuran yang sangat berguna.

383
00:20:24,460 --> 00:20:27,514
Sebagai contoh, katakanlah kita sedang bermain game dan kita mulai

384
00:20:27,514 --> 00:20:29,657
dengan pembuka lama saya, yaitu bulu dan paku,

385
00:20:29,657 --> 00:20:33,760
dan kita berakhir dengan situasi di mana ada empat kemungkinan kata yang cocok dengan itu.

386
00:20:33,760 --> 00:20:36,440
Dan katakanlah kita menganggap semuanya memiliki kemungkinan yang sama.

387
00:20:36,440 --> 00:20:40,000
Izinkan saya bertanya, berapa entropi distribusi ini?

388
00:20:40,000 --> 00:20:45,542
Nah, informasi yang terkait dengan masing-masing kemungkinan ini akan menjadi

389
00:20:45,542 --> 00:20:50,800
basis log 2 dari 4, karena masing-masing adalah 1 dan 4, dan itu adalah 2.

390
00:20:50,800 --> 00:20:52,780
Dua informasi, empat kemungkinan.

391
00:20:52,780 --> 00:20:54,360
Semuanya sangat baik dan bagus.

392
00:20:54,360 --> 00:20:58,320
Tapi bagaimana jika saya bilang sebenarnya ada lebih dari empat pertandingan?

393
00:20:58,320 --> 00:21:02,600
Kenyataannya, jika kita melihat daftar kata selengkapnya, ada 16 kata yang cocok.

394
00:21:02,600 --> 00:21:07,020
Namun misalkan model kita memberikan probabilitas yang sangat rendah pada 12 kata lainnya

395
00:21:07,020 --> 00:21:11,440
untuk menjadi jawaban akhir, sekitar 1 dalam 1000 karena kata tersebut sangat tidak jelas.

396
00:21:11,440 --> 00:21:15,480
Sekarang izinkan saya bertanya, berapa entropi distribusi ini?

397
00:21:15,480 --> 00:21:18,463
Jika entropi hanya mengukur jumlah kecocokan di sini,

398
00:21:18,463 --> 00:21:22,166
Anda mungkin mengharapkannya menjadi basis log 2 dari 16, yaitu 4,

399
00:21:22,166 --> 00:21:26,200
dua bit ketidakpastian lebih banyak daripada yang kita miliki sebelumnya.

400
00:21:26,200 --> 00:21:28,318
Namun tentu saja ketidakpastian yang sebenarnya tidak

401
00:21:28,318 --> 00:21:30,320
jauh berbeda dengan apa yang kita alami sebelumnya.

402
00:21:30,320 --> 00:21:34,337
Hanya karena ada 12 kata yang sangat tidak jelas ini tidak berarti akan lebih

403
00:21:34,337 --> 00:21:38,200
mengejutkan jika mengetahui bahwa jawaban akhirnya adalah pesona, misalnya.

404
00:21:38,200 --> 00:21:40,758
Jadi ketika Anda benar-benar melakukan perhitungan di sini,

405
00:21:40,758 --> 00:21:44,467
dan Anda menjumlahkan probabilitas setiap kejadian dikalikan dengan informasi terkait,

406
00:21:44,467 --> 00:21:45,960
yang Anda dapatkan adalah 2.11 bit.

407
00:21:45,960 --> 00:21:49,636
Maksud saya, pada dasarnya ada dua bagian, pada dasarnya empat kemungkinan tersebut,

408
00:21:49,636 --> 00:21:53,140
namun ada sedikit ketidakpastian karena semua kejadian yang sangat tidak mungkin

409
00:21:53,140 --> 00:21:56,773
tersebut, meskipun jika Anda mempelajarinya, Anda akan mendapatkan banyak informasi

410
00:21:56,773 --> 00:21:57,120
darinya.

411
00:21:57,120 --> 00:21:59,418
Jadi jika diperkecil, inilah bagian yang membuat Wordle

412
00:21:59,418 --> 00:22:01,800
menjadi contoh yang bagus untuk pelajaran teori informasi.

413
00:22:01,800 --> 00:22:05,280
Kami memiliki dua penerapan perasaan yang berbeda untuk entropi.

414
00:22:05,280 --> 00:22:08,997
Yang pertama memberi tahu kita informasi apa yang diharapkan yang akan kita

415
00:22:08,997 --> 00:22:12,860
peroleh dari tebakan tertentu, dan yang kedua mengatakan bisakah kita mengukur

416
00:22:12,860 --> 00:22:16,480
ketidakpastian yang tersisa di antara semua kata yang mungkin kita miliki.

417
00:22:16,480 --> 00:22:19,147
Dan saya harus menekankan, dalam kasus pertama ketika kita melihat

418
00:22:19,147 --> 00:22:21,018
informasi yang diharapkan dari sebuah tebakan,

419
00:22:21,018 --> 00:22:23,526
setelah kita memiliki bobot yang tidak sama pada kata-katanya,

420
00:22:23,526 --> 00:22:25,000
itu mempengaruhi perhitungan entropi.

421
00:22:25,000 --> 00:22:28,216
Sebagai contoh, izinkan saya mengambil kasus yang sama yang kita lihat

422
00:22:28,216 --> 00:22:30,799
sebelumnya tentang distribusi yang terkait dengan Weary,

423
00:22:30,799 --> 00:22:34,560
namun kali ini menggunakan distribusi yang tidak seragam di semua kemungkinan kata.

424
00:22:34,560 --> 00:22:36,937
Jadi izinkan saya melihat apakah saya dapat menemukan

425
00:22:36,937 --> 00:22:39,360
bagian di sini yang menggambarkannya dengan cukup baik.

426
00:22:39,360 --> 00:22:42,480
Oke, ini cukup bagus.

427
00:22:42,480 --> 00:22:46,075
Di sini kita memiliki dua pola berdekatan yang kemungkinannya hampir sama,

428
00:22:46,075 --> 00:22:49,480
namun salah satu pola tersebut memiliki 32 kemungkinan kata yang cocok.

429
00:22:49,480 --> 00:22:52,012
Dan jika kita periksa apa itu, ini adalah 32 kata tersebut,

430
00:22:52,012 --> 00:22:55,600
yang semuanya merupakan kata-kata yang sangat tidak mungkin ketika Anda mengamatinya.

431
00:22:55,600 --> 00:22:59,256
Sulit untuk menemukan jawaban yang terasa masuk akal, mungkin teriakan,

432
00:22:59,256 --> 00:23:02,150
tetapi jika kita melihat pola tetangga dalam distribusi,

433
00:23:02,150 --> 00:23:06,619
yang dianggap sama mungkinnya, kita diberitahu bahwa hanya ada 8 kemungkinan kecocokan,

434
00:23:06,619 --> 00:23:09,920
jadi seperempatnya banyak pertandingan, tapi kemungkinannya sama.

435
00:23:09,920 --> 00:23:12,520
Dan saat kami menghentikan pertandingan tersebut, kami dapat mengetahui alasannya.

436
00:23:12,520 --> 00:23:16,102
Beberapa di antaranya adalah jawaban yang benar-benar masuk akal,

437
00:23:16,102 --> 00:23:17,840
seperti dering, murka, atau rap.

438
00:23:17,840 --> 00:23:20,575
Untuk mengilustrasikan bagaimana kami menggabungkan semua itu,

439
00:23:20,575 --> 00:23:22,833
izinkan saya menampilkan Wordlebot versi 2 di sini,

440
00:23:22,833 --> 00:23:25,960
dan ada dua atau tiga perbedaan utama dari yang pertama yang kami lihat.

441
00:23:25,960 --> 00:23:30,128
Pertama, seperti yang baru saja saya katakan, cara kita menghitung entropi ini,

442
00:23:30,128 --> 00:23:34,349
nilai informasi yang diharapkan, kini menggunakan distribusi yang lebih halus di

443
00:23:34,349 --> 00:23:38,726
seluruh pola yang menggabungkan probabilitas bahwa suatu kata tertentu akan menjadi

444
00:23:38,726 --> 00:23:39,300
jawabannya.

445
00:23:39,300 --> 00:23:44,160
Ternyata, air mata tetaplah nomor 1, meski air mata berikut ini sedikit berbeda.

446
00:23:44,160 --> 00:23:46,510
Kedua, ketika ia memberi peringkat pada pilihan teratasnya,

447
00:23:46,510 --> 00:23:49,291
sekarang ia akan menyimpan model probabilitas bahwa setiap kata adalah

448
00:23:49,291 --> 00:23:51,994
jawaban sebenarnya, dan ia akan memasukkannya ke dalam keputusannya,

449
00:23:51,994 --> 00:23:55,520
yang lebih mudah dilihat setelah kita mempunyai beberapa tebakan pada kata tersebut. meja.

450
00:23:55,520 --> 00:23:58,320
Sekali lagi, abaikan rekomendasinya karena kita

451
00:23:58,320 --> 00:24:01,120
tidak bisa membiarkan mesin mengatur hidup kita.

452
00:24:01,120 --> 00:24:05,102
Dan saya kira saya harus menyebutkan hal lain yang berbeda di sebelah kiri,

453
00:24:05,102 --> 00:24:09,556
bahwa nilai ketidakpastian, jumlah bit, tidak lagi mubazir dengan jumlah kemungkinan

454
00:24:09,556 --> 00:24:10,080
kecocokan.

455
00:24:10,080 --> 00:24:15,797
Sekarang jika kita menariknya dan menghitung 2 sampai 8.02, yang sedikit di atas 256,

456
00:24:15,797 --> 00:24:20,518
saya rasa 259, maksudnya adalah meskipun ada 526 kata yang benar-benar

457
00:24:20,518 --> 00:24:25,571
cocok dengan pola ini, jumlah ketidakpastiannya lebih mirip dengan apa yang

458
00:24:25,571 --> 00:24:29,760
akan terjadi jika ada 259 kata yang sama kemungkinannya. hasil.

459
00:24:29,760 --> 00:24:31,100
Anda bisa memikirkannya seperti ini.

460
00:24:31,100 --> 00:24:34,345
Ia mengetahui bahwa borx bukanlah jawabannya, sama halnya dengan yorts, zorl,

461
00:24:34,345 --> 00:24:37,840
dan zorus, jadi ketidakpastiannya tidak terlalu besar dibandingkan kasus sebelumnya.

462
00:24:37,840 --> 00:24:40,220
Jumlah bit ini akan lebih kecil.

463
00:24:40,220 --> 00:24:44,256
Dan jika saya terus memainkan permainan ini, saya akan menyempurnakannya

464
00:24:44,256 --> 00:24:48,680
dengan beberapa tebakan yang sesuai dengan apa yang ingin saya jelaskan di sini.

465
00:24:48,680 --> 00:24:51,080
Pada tebakan keempat, jika Anda melihat pilihan teratasnya,

466
00:24:51,080 --> 00:24:53,800
Anda dapat melihat bahwa ini tidak lagi hanya memaksimalkan entropi.

467
00:24:53,800 --> 00:24:56,468
Jadi saat ini, secara teknis ada tujuh kemungkinan,

468
00:24:56,468 --> 00:25:00,780
tapi satu-satunya peluang yang memiliki peluang berarti adalah asrama dan kata-kata.

469
00:25:00,780 --> 00:25:04,256
Dan Anda dapat melihat peringkatnya dengan memilih kedua nilai tersebut di atas

470
00:25:04,256 --> 00:25:07,560
semua nilai lainnya, yang sebenarnya akan memberikan lebih banyak informasi.

471
00:25:07,560 --> 00:25:11,237
Pertama kali saya melakukan ini, saya hanya menjumlahkan kedua angka ini untuk mengukur

472
00:25:11,237 --> 00:25:14,580
kualitas setiap tebakan, yang sebenarnya bekerja lebih baik dari yang Anda duga.

473
00:25:14,580 --> 00:25:17,210
Namun hal ini terasa tidak sistematis, dan saya yakin ada pendekatan

474
00:25:17,210 --> 00:25:19,880
lain yang bisa diambil orang, namun inilah pendekatan yang saya pilih.

475
00:25:19,880 --> 00:25:22,466
Jika kita mempertimbangkan prospek tebakan berikutnya,

476
00:25:22,466 --> 00:25:25,382
seperti dalam hal ini, yang benar-benar kita pedulikan adalah

477
00:25:25,382 --> 00:25:28,440
skor yang diharapkan dari permainan kita jika kita melakukan itu.

478
00:25:28,440 --> 00:25:32,142
Dan untuk menghitung skor yang diharapkan, kami mengatakan berapa probabilitas

479
00:25:32,142 --> 00:25:36,080
bahwa kata-kata tersebut adalah jawaban sebenarnya, yang saat ini menggambarkan 58%.

480
00:25:36,080 --> 00:25:40,400
Kami katakan dengan peluang 58%, skor kami dalam permainan ini adalah 4.

481
00:25:40,400 --> 00:25:46,240
Dan kemudian dengan probabilitas 1 dikurangi 58% itu, skor kita akan lebih dari 4 itu.

482
00:25:46,240 --> 00:25:49,617
Berapa banyak lagi yang belum kita ketahui, namun kita dapat memperkirakannya berdasarkan

483
00:25:49,617 --> 00:25:52,920
seberapa besar ketidakpastian yang mungkin terjadi setelah kita mencapai titik tersebut.

484
00:25:52,920 --> 00:25:56,600
Secara khusus, saat ini ada 1.44 bit ketidakpastian.

485
00:25:56,600 --> 00:25:58,898
Jika kita menebak kata-kata, itu memberi tahu kita bahwa

486
00:25:58,898 --> 00:26:01,560
informasi yang diharapkan yang akan kita dapatkan adalah 1.27 bit.

487
00:26:01,560 --> 00:26:04,992
Jadi jika kita menebak-nebak, perbedaan ini menunjukkan seberapa besar

488
00:26:04,992 --> 00:26:08,280
ketidakpastian yang mungkin kita alami setelah hal tersebut terjadi.

489
00:26:08,280 --> 00:26:11,101
Yang kita butuhkan adalah suatu fungsi, yang saya sebut f di sini,

490
00:26:11,101 --> 00:26:13,880
yang menghubungkan ketidakpastian ini dengan skor yang diharapkan.

491
00:26:13,880 --> 00:26:18,225
Dan caranya adalah dengan memplot sekumpulan data dari game sebelumnya

492
00:26:18,225 --> 00:26:22,632
berdasarkan versi 1 bot untuk mengatakan berapa skor sebenarnya setelah

493
00:26:22,632 --> 00:26:27,040
berbagai poin dengan jumlah ketidakpastian tertentu yang sangat terukur.

494
00:26:27,040 --> 00:26:31,197
Misalnya, titik data di sini yang berada di atas nilai sekitar 8.7 atau

495
00:26:31,197 --> 00:26:35,297
lebih dikatakan untuk beberapa permainan setelah titik di mana ada 8.7

496
00:26:35,297 --> 00:26:39,340
bit ketidakpastian, butuh dua tebakan untuk mendapatkan jawaban akhir.

497
00:26:39,340 --> 00:26:41,260
Untuk permainan lainnya membutuhkan tiga kali tebakan,

498
00:26:41,260 --> 00:26:43,180
untuk permainan lainnya membutuhkan empat kali tebakan.

499
00:26:43,180 --> 00:26:46,929
Jika kita menggeser ke kiri di sini, semua titik di atas nol menyatakan

500
00:26:46,929 --> 00:26:51,302
kapan pun tidak ada sedikit pun ketidakpastian, artinya hanya ada satu kemungkinan,

501
00:26:51,302 --> 00:26:55,000
maka jumlah tebakan yang diperlukan selalu hanya satu, yang meyakinkan.

502
00:26:55,000 --> 00:26:59,713
Kapan pun ada sedikit ketidakpastian, artinya pada dasarnya hanya ada dua kemungkinan,

503
00:26:59,713 --> 00:27:03,940
terkadang diperlukan satu tebakan lagi, terkadang diperlukan dua tebakan lagi.

504
00:27:03,940 --> 00:27:05,980
Dan seterusnya dan seterusnya di sini.

505
00:27:05,980 --> 00:27:08,402
Mungkin cara yang sedikit lebih mudah untuk memvisualisasikan

506
00:27:08,402 --> 00:27:11,020
data ini adalah dengan menggabungkannya dan mengambil rata-ratanya.

507
00:27:11,020 --> 00:27:16,923
Misalnya bilah di sini menyatakan di antara semua titik di mana kita mempunyai sedikit

508
00:27:16,923 --> 00:27:22,420
ketidakpastian, rata-rata jumlah tebakan baru yang diperlukan adalah sekitar 1.5.

509
00:27:22,420 --> 00:27:25,950
Dan batasan di sini mengatakan di antara semua permainan yang berbeda

510
00:27:25,950 --> 00:27:29,632
di mana pada titik tertentu ketidakpastiannya sedikit di atas empat bit,

511
00:27:29,632 --> 00:27:32,709
yang seperti mempersempitnya menjadi 16 kemungkinan berbeda,

512
00:27:32,709 --> 00:27:36,240
maka rata-rata memerlukan lebih dari dua tebakan dari titik itu. maju.

513
00:27:36,240 --> 00:27:38,071
Dan dari sini saya baru saja melakukan regresi agar

514
00:27:38,071 --> 00:27:40,080
sesuai dengan fungsi yang tampaknya masuk akal untuk ini.

515
00:27:40,080 --> 00:27:43,344
Dan ingat, inti dari melakukan semua itu adalah agar kita dapat

516
00:27:43,344 --> 00:27:47,628
mengukur intuisi bahwa semakin banyak informasi yang kita peroleh dari sebuah kata,

517
00:27:47,628 --> 00:27:49,720
semakin rendah pula skor yang diharapkan.

518
00:27:49,720 --> 00:27:54,770
Jadi dengan ini sebagai versi 2.0, jika kita kembali dan menjalankan rangkaian simulasi

519
00:27:54,770 --> 00:27:59,820
yang sama, memainkannya melawan semua 2315 kemungkinan jawaban, bagaimana cara kerjanya?

520
00:27:59,820 --> 00:28:04,060
Berbeda dengan versi pertama kami, ini pasti lebih baik, dan itu meyakinkan.

521
00:28:04,060 --> 00:28:07,043
Semua dikatakan dan dilakukan rata-ratanya adalah sekitar 3.6,

522
00:28:07,043 --> 00:28:09,978
meskipun tidak seperti versi pertama, ada beberapa kali versi

523
00:28:09,978 --> 00:28:12,820
ini kalah dan membutuhkan lebih dari enam dalam keadaan ini.

524
00:28:12,820 --> 00:28:15,874
Mungkin karena ada kalanya kita melakukan pengorbanan untuk

525
00:28:15,874 --> 00:28:18,980
benar-benar mencapai tujuan daripada memaksimalkan informasi.

526
00:28:18,980 --> 00:28:22,140
Jadi bisakah kita melakukan lebih baik dari 3.6?

527
00:28:22,140 --> 00:28:23,260
Kami pasti bisa.

528
00:28:23,260 --> 00:28:26,555
Sekarang saya katakan di awal bahwa paling menyenangkan adalah mencoba tidak

529
00:28:26,555 --> 00:28:29,980
memasukkan daftar jawaban kata yang sebenarnya ke dalam cara membangun modelnya.

530
00:28:29,980 --> 00:28:32,771
Namun jika kami menggabungkannya, performa terbaik

531
00:28:32,771 --> 00:28:35,180
yang bisa saya dapatkan adalah sekitar 3.43.

532
00:28:35,180 --> 00:28:37,906
Jadi jika kita mencoba menjadi lebih canggih dari sekedar menggunakan

533
00:28:37,906 --> 00:28:40,127
data frekuensi kata untuk memilih distribusi sebelumnya,

534
00:28:40,127 --> 00:28:42,970
ini 3.43 mungkin memberi gambaran maksimal seberapa bagus yang bisa kita

535
00:28:42,970 --> 00:28:46,360
dapatkan dengan itu, atau setidaknya seberapa bagus yang bisa saya dapatkan dengan itu.

536
00:28:46,360 --> 00:28:49,514
Performa terbaik tersebut pada dasarnya hanya menggunakan ide-ide yang telah

537
00:28:49,514 --> 00:28:51,440
saya bicarakan di sini, namun lebih jauh lagi,

538
00:28:51,440 --> 00:28:54,635
seperti melakukan penelusuran informasi yang diharapkan dua langkah ke depan,

539
00:28:54,635 --> 00:28:55,660
bukan hanya satu langkah.

540
00:28:55,660 --> 00:28:58,154
Awalnya saya berencana untuk membicarakan lebih banyak tentang hal itu,

541
00:28:58,154 --> 00:29:00,580
tetapi saya menyadari bahwa kita sebenarnya sudah berjalan cukup lama.

542
00:29:00,580 --> 00:29:03,498
Satu hal yang akan saya katakan adalah setelah melakukan pencarian dua

543
00:29:03,498 --> 00:29:06,992
langkah ini dan kemudian menjalankan beberapa contoh simulasi pada kandidat teratas,

544
00:29:06,992 --> 00:29:09,500
sejauh ini bagi saya setidaknya Crane adalah pembuka terbaik.

545
00:29:09,500 --> 00:29:11,080
Siapa sangka?

546
00:29:11,080 --> 00:29:14,488
Juga jika Anda menggunakan daftar kata yang sebenarnya untuk menentukan ruang

547
00:29:14,488 --> 00:29:18,160
kemungkinan Anda, maka ketidakpastian yang Anda mulai adalah sedikit di atas 11 bit.

548
00:29:18,160 --> 00:29:21,198
Dan ternyata, hanya dari pencarian brute force,

549
00:29:21,198 --> 00:29:26,580
informasi maksimal yang diharapkan setelah dua tebakan pertama adalah sekitar 10 bit.

550
00:29:26,580 --> 00:29:30,927
Hal ini menunjukkan bahwa skenario terbaik, setelah dua tebakan pertama Anda,

551
00:29:30,927 --> 00:29:35,220
dengan permainan optimal sempurna, Anda akan memiliki sedikit ketidakpastian.

552
00:29:35,220 --> 00:29:37,400
Yang sama dengan membuat dua kemungkinan tebakan.

553
00:29:37,400 --> 00:29:40,039
Jadi menurut saya adil dan mungkin cukup konservatif untuk mengatakan bahwa

554
00:29:40,039 --> 00:29:42,992
Anda tidak akan pernah bisa menulis algoritma yang mendapatkan rata-rata serendah 3,

555
00:29:42,992 --> 00:29:44,728
karena dengan kata-kata yang tersedia untuk Anda,

556
00:29:44,728 --> 00:29:47,264
tidak ada ruang untuk mendapatkan informasi yang cukup setelah hanya dua

557
00:29:47,264 --> 00:29:49,869
langkah yang harus dilakukan. mampu menjamin jawaban di slot ketiga setiap

558
00:29:49,869 --> 00:29:50,460
saat tanpa gagal.

