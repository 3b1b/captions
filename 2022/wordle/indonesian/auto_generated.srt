1
00:00:00,000 --> 00:00:03,311
Permainan Wurdle telah menjadi sangat viral dalam satu atau dua bulan terakhir,

2
00:00:03,311 --> 00:00:06,622
dan tidak ada seorangpun yang melewatkan kesempatan untuk pelajaran matematika,

3
00:00:06,622 --> 00:00:10,057
menurut saya permainan ini menjadi contoh sentral yang sangat baik dalam pelajaran

4
00:00:10,057 --> 00:00:13,120
tentang teori informasi, dan khususnya topik yang dikenal sebagai entropi.

5
00:00:13,120 --> 00:00:16,547
Anda tahu, seperti kebanyakan orang, saya terjebak dalam teka-teki,

6
00:00:16,547 --> 00:00:19,873
dan seperti kebanyakan programmer, saya juga terjebak dalam upaya

7
00:00:19,873 --> 00:00:23,200
menulis algoritma yang akan memainkan permainan seoptimal mungkin.

8
00:00:23,200 --> 00:00:26,148
Dan apa yang saya pikir akan saya lakukan di sini hanyalah membicarakan dengan Anda

9
00:00:26,148 --> 00:00:29,026
beberapa proses saya di dalamnya, dan menjelaskan beberapa perhitungan matematika

10
00:00:29,026 --> 00:00:32,080
yang masuk ke dalamnya, karena keseluruhan algoritma berpusat pada gagasan entropi ini.

11
00:00:32,080 --> 00:00:42,180
Hal pertama yang pertama, jika Anda belum pernah mendengarnya, apa itu Wurdle?

12
00:00:42,180 --> 00:00:45,199
Dan untuk membunuh dua burung dengan satu batu di sini sementara kita membahas aturan

13
00:00:45,199 --> 00:00:48,079
permainannya, izinkan saya juga melihat ke mana tujuan kita dengan hal ini, yaitu

14
00:00:48,079 --> 00:00:51,204
mengembangkan algoritma kecil yang pada dasarnya akan memainkan permainan tersebut untuk

15
00:00:51,204 --> 00:00:51,380
kita.

16
00:00:51,380 --> 00:00:53,601
Meskipun saya belum melakukan Wurdle hari ini, ini tanggal 4

17
00:00:53,601 --> 00:00:55,860
Februari, dan kita akan melihat bagaimana botnya melakukannya.

18
00:00:55,860 --> 00:00:58,431
Tujuan Wurdle adalah menebak kata misteri lima huruf,

19
00:00:58,431 --> 00:01:00,860
dan Anda diberi enam peluang berbeda untuk menebak.

20
00:01:00,860 --> 00:01:05,240
Misalnya, bot Wurdle saya menyarankan agar saya memulai dengan tebakan derek.

21
00:01:05,240 --> 00:01:07,866
Setiap kali Anda menebak, Anda mendapatkan informasi

22
00:01:07,866 --> 00:01:10,940
tentang seberapa dekat tebakan Anda dengan jawaban sebenarnya.

23
00:01:10,940 --> 00:01:14,540
Di sini kotak abu-abu memberi tahu saya bahwa tidak ada C pada jawaban sebenarnya.

24
00:01:14,540 --> 00:01:18,340
Kotak kuning memberitahu saya ada huruf R, tapi posisinya tidak seperti itu.

25
00:01:18,340 --> 00:01:20,536
Kotak hijau memberitahu saya bahwa kata rahasianya

26
00:01:20,536 --> 00:01:22,820
memang memiliki nilai A, dan berada di posisi ketiga.

27
00:01:22,820 --> 00:01:24,300
Dan kemudian tidak ada N dan tidak ada E.

28
00:01:24,300 --> 00:01:27,420
Jadi izinkan saya masuk dan memberi tahu bot Wurdle informasi itu.

29
00:01:27,420 --> 00:01:31,500
Kami mulai dengan crane, kami mendapat warna abu-abu, kuning, hijau, abu-abu, abu-abu.

30
00:01:31,500 --> 00:01:33,538
Jangan khawatir tentang semua data yang ditampilkan

31
00:01:33,538 --> 00:01:35,460
saat ini, saya akan menjelaskannya pada waktunya.

32
00:01:35,460 --> 00:01:39,700
Tapi saran utamanya untuk pilihan kedua kami adalah buruk.

33
00:01:39,700 --> 00:01:42,770
Dan tebakan Anda memang harus berupa kata yang terdiri dari lima huruf, tetapi seperti

34
00:01:42,770 --> 00:01:45,700
yang akan Anda lihat, tebakannya cukup liberal karena memungkinkan Anda menebaknya.

35
00:01:45,700 --> 00:01:48,860
Dalam hal ini, kami mencoba shtick.

36
00:01:48,860 --> 00:01:50,260
Dan baiklah, semuanya terlihat cukup bagus.

37
00:01:50,260 --> 00:01:54,740
Kita tekan S dan H, jadi kita tahu tiga huruf pertama, kita tahu ada R.

38
00:01:54,740 --> 00:01:59,740
Jadi itu akan menjadi seperti SHA sesuatu R, atau SHA R sesuatu.

39
00:01:59,740 --> 00:02:02,566
Dan sepertinya bot Wurdle mengetahui bahwa hanya

40
00:02:02,566 --> 00:02:05,220
ada dua kemungkinan, yaitu pecahan atau tajam.

41
00:02:05,220 --> 00:02:08,262
Saat ini ada semacam perselisihan di antara mereka, jadi saya kira

42
00:02:08,262 --> 00:02:11,260
mungkin hanya karena sesuai abjad, maka itu sesuai dengan pecahan.

43
00:02:11,260 --> 00:02:13,000
Yang mana hore, itulah jawaban sebenarnya.

44
00:02:13,000 --> 00:02:14,660
Jadi kami mendapatkannya dalam tiga.

45
00:02:14,660 --> 00:02:17,762
Jika Anda bertanya-tanya apakah itu bagus, saya mendengar satu orang

46
00:02:17,762 --> 00:02:20,820
berkata bahwa dengan Wurdle empat adalah par dan tiga adalah birdie.

47
00:02:20,820 --> 00:02:22,960
Yang menurut saya merupakan analogi yang cukup tepat.

48
00:02:22,960 --> 00:02:25,334
Anda harus konsisten dalam permainan Anda untuk

49
00:02:25,334 --> 00:02:27,560
mendapatkan empat, tapi itu jelas tidak gila.

50
00:02:27,560 --> 00:02:30,000
Tapi ketika Anda mendapatkannya dalam tiga, rasanya luar biasa.

51
00:02:30,000 --> 00:02:33,149
Jadi jika Anda menginginkannya, yang ingin saya lakukan di sini hanyalah

52
00:02:33,149 --> 00:02:36,600
membahas proses pemikiran saya dari awal tentang cara saya mendekati bot Wurdle.

53
00:02:36,600 --> 00:02:39,800
Dan seperti yang saya katakan, ini sebenarnya alasan untuk pelajaran teori informasi.

54
00:02:39,800 --> 00:02:48,560
Tujuan utamanya adalah menjelaskan apa itu informasi dan apa itu entropi.

55
00:02:48,560 --> 00:02:50,998
Pikiran pertama saya dalam melakukan pendekatan ini adalah

56
00:02:50,998 --> 00:02:53,560
melihat frekuensi relatif berbagai huruf dalam bahasa Inggris.

57
00:02:53,560 --> 00:02:56,525
Jadi saya berpikir, oke, apakah ada tebakan pembuka atau

58
00:02:56,525 --> 00:02:59,960
tebakan pembuka yang banyak mengenai huruf yang paling sering ini?

59
00:02:59,960 --> 00:03:01,972
Dan salah satu hal yang sangat saya sukai adalah

60
00:03:01,972 --> 00:03:03,780
melakukan hal lain yang diikuti dengan paku.

61
00:03:03,780 --> 00:03:05,880
Pemikirannya adalah jika Anda menekan sebuah huruf, Anda tahu, Anda

62
00:03:05,880 --> 00:03:07,980
mendapatkan warna hijau atau kuning, itu selalu terasa menyenangkan.

63
00:03:07,980 --> 00:03:09,460
Rasanya seperti Anda mendapatkan informasi.

64
00:03:09,460 --> 00:03:12,199
Namun dalam kasus ini, bahkan jika Anda tidak memukul dan Anda selalu

65
00:03:12,199 --> 00:03:14,822
mendapatkan warna abu-abu, itu tetap memberi Anda banyak informasi

66
00:03:14,822 --> 00:03:17,640
karena sangat jarang menemukan kata yang tidak memiliki huruf-huruf ini.

67
00:03:17,640 --> 00:03:20,837
Namun tetap saja, hal tersebut tidak terasa super sistematis,

68
00:03:20,837 --> 00:03:23,520
karena misalnya, tidak memperhitungkan urutan huruf.

69
00:03:23,520 --> 00:03:26,080
Mengapa mengetik paku ketika saya bisa mengetik siput?

70
00:03:26,080 --> 00:03:27,720
Apakah lebih baik memiliki S di akhir?

71
00:03:27,720 --> 00:03:28,720
Saya tidak begitu yakin.

72
00:03:28,720 --> 00:03:32,892
Sekarang, seorang teman saya mengatakan bahwa dia suka membuka dengan kata letih, yang

73
00:03:32,892 --> 00:03:37,160
membuat saya terkejut karena ada beberapa huruf yang tidak biasa di sana seperti W dan Y.

74
00:03:37,160 --> 00:03:39,400
Tapi siapa tahu, mungkin itu pembuka yang lebih baik.

75
00:03:39,400 --> 00:03:44,920
Adakah skor kuantitatif yang bisa kita berikan untuk menilai kualitas tebakan potensial?

76
00:03:44,920 --> 00:03:47,200
Sekarang untuk mempersiapkan cara kita menentukan peringkat

77
00:03:47,200 --> 00:03:49,595
kemungkinan tebakan, mari kita kembali dan menambahkan sedikit

78
00:03:49,595 --> 00:03:51,800
kejelasan tentang bagaimana tepatnya permainan ini diatur.

79
00:03:51,800 --> 00:03:54,761
Jadi ada daftar kata yang dapat Anda masukkan yang dianggap

80
00:03:54,761 --> 00:03:57,920
sebagai tebakan valid yang panjangnya hanya sekitar 13.000 kata.

81
00:03:57,920 --> 00:04:02,453
Tapi kalau dilihat-lihat, ada banyak hal yang sangat tidak biasa, seperti kepala atau

82
00:04:02,453 --> 00:04:07,040
Ali dan ARG, kata-kata yang menimbulkan pertengkaran keluarga dalam permainan Scrabble.

83
00:04:07,040 --> 00:04:10,600
Namun inti dari permainan ini adalah bahwa jawabannya akan selalu berupa kata yang umum.

84
00:04:10,600 --> 00:04:13,367
Dan faktanya, ada daftar lain yang berisi sekitar

85
00:04:13,367 --> 00:04:16,080
2.300 kata yang merupakan kemungkinan jawabannya.

86
00:04:16,080 --> 00:04:18,962
Dan ini adalah daftar yang dikurasi oleh manusia, menurut saya

87
00:04:18,962 --> 00:04:21,800
khususnya oleh pacar pembuat game, dan itu cukup menyenangkan.

88
00:04:21,800 --> 00:04:24,650
Tapi yang ingin saya lakukan, tantangan kita untuk proyek ini

89
00:04:24,650 --> 00:04:27,455
adalah melihat apakah kita bisa menulis program penyelesaian

90
00:04:27,455 --> 00:04:30,720
Wordle yang tidak memasukkan pengetahuan sebelumnya tentang daftar ini.

91
00:04:30,720 --> 00:04:33,209
Untuk satu hal, ada banyak kata lima huruf yang cukup

92
00:04:33,209 --> 00:04:35,560
umum yang tidak akan Anda temukan dalam daftar itu.

93
00:04:35,560 --> 00:04:38,835
Jadi akan lebih baik untuk menulis sebuah program yang sedikit lebih tangguh dan dapat

94
00:04:38,835 --> 00:04:41,960
memainkan Wordle melawan siapa pun, bukan hanya apa yang terjadi di situs resminya.

95
00:04:41,960 --> 00:04:44,700
Dan juga alasan kita mengetahui daftar kemungkinan jawaban

96
00:04:44,700 --> 00:04:47,440
ini, adalah karena daftar tersebut terlihat di kode sumber.

97
00:04:47,440 --> 00:04:50,198
Namun tampilannya di kode sumber sesuai dengan

98
00:04:50,198 --> 00:04:52,840
urutan jawaban yang muncul dari hari ke hari.

99
00:04:52,840 --> 00:04:56,400
Jadi, Anda selalu bisa mencari tahu apa jawaban besok.

100
00:04:56,400 --> 00:04:59,140
Jelas sekali, ada kesan bahwa menggunakan daftar itu curang.

101
00:04:59,140 --> 00:05:02,342
Dan apa yang menjadikan teka-teki ini lebih menarik dan pelajaran teori

102
00:05:02,342 --> 00:05:05,501
informasi yang lebih kaya adalah dengan menggunakan beberapa data yang

103
00:05:05,501 --> 00:05:08,392
lebih universal seperti frekuensi kata relatif secara umum untuk

104
00:05:08,392 --> 00:05:11,640
menangkap intuisi mengenai preferensi terhadap kata-kata yang lebih umum.

105
00:05:11,640 --> 00:05:16,560
Jadi dari 13.000 kemungkinan ini, bagaimana sebaiknya kita memilih tebakan pembuka?

106
00:05:16,560 --> 00:05:19,960
Misalnya, jika teman saya melamar dengan letih, bagaimana kita menganalisis kualitasnya?

107
00:05:19,960 --> 00:05:22,585
Nah, alasan dia mengatakan dia menyukai W yang tidak mungkin

108
00:05:22,585 --> 00:05:25,340
itu adalah karena dia menyukai sifat pukulan jarak jauh tentang

109
00:05:25,340 --> 00:05:27,880
betapa nikmatnya rasanya jika Anda berhasil mencapai W itu.

110
00:05:27,880 --> 00:05:32,058
Misalnya, jika pola pertama yang terungkap kira-kira seperti ini, maka ternyata

111
00:05:32,058 --> 00:05:36,080
hanya ada 58 kata dalam leksikon raksasa ini yang cocok dengan pola tersebut.

112
00:05:36,080 --> 00:05:38,900
Jadi itu pengurangan yang sangat besar dari 13.000.

113
00:05:38,900 --> 00:05:43,360
Namun sisi sebaliknya tentu saja sangat jarang mendapatkan pola seperti ini.

114
00:05:43,360 --> 00:05:47,390
Secara khusus, jika setiap kata mempunyai kemungkinan yang sama untuk menjadi

115
00:05:47,390 --> 00:05:51,680
jawabannya, kemungkinan untuk mendapatkan pola ini adalah 58 dibagi sekitar 13.000.

116
00:05:51,680 --> 00:05:53,880
Tentu saja, kemungkinan jawaban tersebut tidak sama.

117
00:05:53,880 --> 00:05:56,680
Kebanyakan dari kata-kata ini sangat tidak jelas dan bahkan dipertanyakan.

118
00:05:56,680 --> 00:05:59,376
Tapi setidaknya untuk langkah pertama kita dalam semua hal ini, mari kita asumsikan

119
00:05:59,376 --> 00:06:02,040
bahwa semuanya memiliki kemungkinan yang sama dan kemudian menyempurnakannya nanti.

120
00:06:02,040 --> 00:06:07,360
Intinya adalah pola dengan banyak informasi pada dasarnya tidak mungkin terjadi.

121
00:06:07,360 --> 00:06:11,920
Faktanya, yang dimaksud dengan informatif adalah bahwa hal itu tidak mungkin.

122
00:06:11,920 --> 00:06:15,140
Pola yang lebih mungkin terlihat pada pembukaan ini adalah

123
00:06:15,140 --> 00:06:18,360
seperti ini, yang tentu saja tidak ada huruf W di dalamnya.

124
00:06:18,360 --> 00:06:22,080
Mungkin ada E, dan mungkin tidak ada A, tidak ada R, tidak ada Y.

125
00:06:22,080 --> 00:06:24,640
Dalam hal ini, ada 1400 kemungkinan kecocokan.

126
00:06:24,640 --> 00:06:27,864
Jika semua memiliki kemungkinan yang sama, maka kemungkinannya

127
00:06:27,864 --> 00:06:30,680
sekitar 11% bahwa ini adalah pola yang akan Anda lihat.

128
00:06:30,680 --> 00:06:34,320
Jadi hasil yang paling mungkin juga paling tidak informatif.

129
00:06:34,320 --> 00:06:38,274
Untuk mendapatkan gambaran yang lebih global di sini, izinkan saya menunjukkan kepada

130
00:06:38,274 --> 00:06:42,000
Anda distribusi penuh probabilitas di semua pola berbeda yang mungkin Anda lihat.

131
00:06:42,000 --> 00:06:45,551
Jadi tiap batang yang Anda lihat sesuai dengan kemungkinan pola warna

132
00:06:45,551 --> 00:06:49,154
yang dapat ditampilkan, yang mana terdapat 3 hingga 5 kemungkinan, dan

133
00:06:49,154 --> 00:06:52,960
disusun dari kiri ke kanan, yang paling umum hingga yang paling tidak umum.

134
00:06:52,960 --> 00:06:56,200
Jadi kemungkinan paling umum di sini adalah Anda mendapatkan warna abu-abu.

135
00:06:56,200 --> 00:06:58,800
Itu terjadi sekitar 14% dari seluruh kasus.

136
00:06:58,800 --> 00:07:02,451
Dan yang Anda harapkan saat menebak adalah Anda berakhir di suatu

137
00:07:02,451 --> 00:07:06,047
tempat di ekor panjang ini, seperti di sini di mana hanya ada 18

138
00:07:06,047 --> 00:07:09,920
kemungkinan yang cocok dengan pola yang ternyata terlihat seperti ini.

139
00:07:09,920 --> 00:07:14,080
Atau jika kita melangkah lebih jauh ke kiri, mungkin kita akan terus ke sini.

140
00:07:14,080 --> 00:07:16,560
Oke, ini teka-teki yang bagus untuk Anda.

141
00:07:16,560 --> 00:07:19,458
Apa tiga kata dalam bahasa Inggris yang dimulai dengan huruf W, diakhiri

142
00:07:19,458 --> 00:07:22,040
dengan huruf Y, dan memiliki huruf R di suatu tempat di dalamnya?

143
00:07:22,040 --> 00:07:27,560
Ternyata jawabannya adalah, mari kita lihat, bertele-tele, cacingan, dan masam.

144
00:07:27,560 --> 00:07:31,816
Jadi untuk menilai seberapa bagus kata ini secara keseluruhan, kami ingin

145
00:07:31,816 --> 00:07:36,360
mengukur perkiraan jumlah informasi yang akan Anda peroleh dari distribusi ini.

146
00:07:36,360 --> 00:07:39,503
Jika kita menelusuri setiap pola dan mengalikan kemungkinan

147
00:07:39,503 --> 00:07:42,646
terjadinya dengan sesuatu yang mengukur seberapa informatif

148
00:07:42,646 --> 00:07:46,000
pola tersebut, hal itu mungkin dapat memberi kita skor objektif.

149
00:07:46,000 --> 00:07:47,991
Sekarang insting pertama Anda tentang apa yang

150
00:07:47,991 --> 00:07:50,280
seharusnya terjadi mungkin adalah jumlah pertandingan.

151
00:07:50,280 --> 00:07:52,960
Anda menginginkan jumlah rata-rata kecocokan yang lebih rendah.

152
00:07:52,960 --> 00:07:57,286
Namun saya ingin menggunakan pengukuran yang lebih universal yang sering kita

153
00:07:57,286 --> 00:08:01,724
anggap berasal dari informasi, dan pengukuran yang akan lebih fleksibel setelah

154
00:08:01,724 --> 00:08:06,328
kita menetapkan probabilitas berbeda untuk masing-masing dari 13.000 kata tersebut

155
00:08:06,328 --> 00:08:10,600
untuk mengetahui apakah kata-kata tersebut benar-benar jawabannya atau tidak.

156
00:08:10,600 --> 00:08:13,981
Satuan standar informasi adalah bit, yang memiliki rumus yang

157
00:08:13,981 --> 00:08:17,800
sedikit lucu, namun sangat intuitif jika kita hanya melihat contohnya.

158
00:08:17,800 --> 00:08:21,070
Jika Anda mempunyai pengamatan yang membagi dua kemungkinan yang ada,

159
00:08:21,070 --> 00:08:24,200
kami katakan bahwa pengamatan tersebut mempunyai sedikit informasi.

160
00:08:24,200 --> 00:08:26,640
Dalam contoh kita, ruang kemungkinannya adalah semua kemungkinan

161
00:08:26,640 --> 00:08:29,156
kata, dan ternyata sekitar setengah dari lima huruf kata mempunyai

162
00:08:29,156 --> 00:08:31,560
huruf S, sedikit lebih kecil dari itu, tapi sekitar setengahnya.

163
00:08:31,560 --> 00:08:35,200
Sehingga pengamatan itu akan memberi Anda sedikit informasi.

164
00:08:35,200 --> 00:08:38,460
Jika suatu fakta baru memperkecil ruang kemungkinan tersebut sebanyak

165
00:08:38,460 --> 00:08:42,000
empat kali lipat, kita katakan bahwa fakta tersebut mempunyai dua informasi.

166
00:08:42,000 --> 00:08:45,120
Misalnya, ternyata sekitar seperempat dari kata-kata ini memiliki huruf T.

167
00:08:45,120 --> 00:08:48,101
Jika observasi memotong ruang tersebut sebanyak delapan kali lipat, kita

168
00:08:48,101 --> 00:08:50,920
katakan itu adalah tiga bit informasi, dan seterusnya dan seterusnya.

169
00:08:50,920 --> 00:08:55,000
Empat bit memotongnya menjadi 16, lima bit memotongnya menjadi 32.

170
00:08:55,000 --> 00:08:59,760
Jadi sekarang Anda mungkin ingin berhenti sejenak dan bertanya pada diri sendiri,

171
00:08:59,760 --> 00:09:04,520
apa rumus informasi jumlah bit dalam kaitannya dengan probabilitas suatu kejadian?

172
00:09:04,520 --> 00:09:08,310
Apa yang ingin kami katakan di sini adalah ketika Anda mengambil setengah dari jumlah

173
00:09:08,310 --> 00:09:12,144
bit, itu sama dengan probabilitas, yang sama dengan mengatakan dua pangkat dari jumlah

174
00:09:12,144 --> 00:09:16,022
bit adalah satu di atas probabilitas, yaitu menyusun ulang lebih jauh dengan mengatakan

175
00:09:16,022 --> 00:09:19,680
bahwa informasi tersebut adalah basis log dua dari satu dibagi dengan probabilitas.

176
00:09:19,680 --> 00:09:22,680
Dan kadang-kadang Anda melihat ini dengan satu penataan ulang lagi,

177
00:09:22,680 --> 00:09:25,680
di mana informasinya adalah log negatif basis dua dari probabilitas.

178
00:09:25,680 --> 00:09:28,915
Jika diungkapkan seperti ini, hal ini mungkin terlihat sedikit aneh bagi

179
00:09:28,915 --> 00:09:32,017
yang belum tahu, namun sebenarnya ini hanyalah gagasan intuitif untuk

180
00:09:32,017 --> 00:09:35,120
menanyakan berapa kali Anda telah mengurangi separuh kemungkinan Anda.

181
00:09:35,120 --> 00:09:37,583
Sekarang jika Anda bertanya-tanya, Anda tahu, saya pikir kita hanya memainkan

182
00:09:37,583 --> 00:09:39,920
permainan kata yang menyenangkan, mengapa logaritma masuk ke dalam gambar?

183
00:09:39,920 --> 00:09:43,217
Salah satu alasan unit ini lebih bagus adalah karena lebih mudah untuk

184
00:09:43,217 --> 00:09:46,468
membicarakan peristiwa yang sangat tidak mungkin terjadi, lebih mudah

185
00:09:46,468 --> 00:09:49,580
untuk mengatakan bahwa suatu pengamatan mempunyai 20 bit informasi

186
00:09:49,580 --> 00:09:52,785
daripada mengatakan bahwa probabilitas kejadian ini dan itu adalah 0.

187
00:09:52,785 --> 00:09:53,480
0000095.

188
00:09:53,480 --> 00:09:57,456
Namun alasan yang lebih substantif mengapa ekspresi logaritmik ini ternyata menjadi

189
00:09:57,456 --> 00:10:01,432
tambahan yang sangat berguna bagi teori probabilitas adalah cara informasi tersebut

190
00:10:01,432 --> 00:10:02,000
dijumlahkan.

191
00:10:02,000 --> 00:10:05,864
Misalnya, jika satu observasi memberi Anda dua bit informasi, mengurangi ruang

192
00:10:05,864 --> 00:10:09,728
Anda menjadi empat, dan kemudian observasi kedua seperti tebakan kedua Anda di

193
00:10:09,728 --> 00:10:13,495
Wordle memberi Anda tiga bit informasi lagi, mengurangi Anda lebih jauh lagi

194
00:10:13,495 --> 00:10:17,360
sebanyak delapan kali lipat, maka dua bersama-sama memberi Anda lima informasi.

195
00:10:17,360 --> 00:10:21,200
Sama seperti probabilitas yang berlipat ganda, informasi juga suka bertambah.

196
00:10:21,200 --> 00:10:25,028
Jadi segera setelah kita berada di bidang nilai yang diharapkan, di mana kita

197
00:10:25,028 --> 00:10:28,660
menambahkan banyak angka, log akan membuatnya lebih mudah untuk ditangani.

198
00:10:28,660 --> 00:10:32,066
Mari kita kembali ke distribusi Weary dan menambahkan pelacak kecil lainnya di

199
00:10:32,066 --> 00:10:35,560
sini, menunjukkan kepada kita berapa banyak informasi yang ada untuk setiap pola.

200
00:10:35,560 --> 00:10:38,306
Hal utama yang saya ingin Anda perhatikan adalah semakin tinggi

201
00:10:38,306 --> 00:10:40,967
kemungkinan kita mendapatkan pola yang lebih mungkin, semakin

202
00:10:40,967 --> 00:10:43,500
rendah informasinya, semakin sedikit bit yang Anda peroleh.

203
00:10:43,500 --> 00:10:47,373
Cara kita mengukur kualitas tebakan ini adalah dengan mengambil nilai yang diharapkan

204
00:10:47,373 --> 00:10:51,201
dari informasi tersebut, dengan menelusuri setiap pola, kita tentukan seberapa besar

205
00:10:51,201 --> 00:10:54,940
kemungkinannya, lalu kita kalikan dengan berapa banyak informasi yang kita peroleh.

206
00:10:54,940 --> 00:10:58,107
Dan dalam contoh Weary, ternyata menjadi 4.

207
00:10:58,107 --> 00:10:58,480
9 bit.

208
00:10:58,480 --> 00:11:02,070
Jadi rata-rata, informasi yang Anda dapatkan dari tebakan pembuka ini sama baiknya

209
00:11:02,070 --> 00:11:05,660
dengan memotong ruang kemungkinan Anda menjadi setengahnya sekitar lima kali lipat.

210
00:11:05,660 --> 00:11:09,440
Sebaliknya, contoh tebakan dengan nilai informasi

211
00:11:09,440 --> 00:11:13,220
yang diharapkan lebih tinggi adalah seperti Slate.

212
00:11:13,220 --> 00:11:16,180
Dalam hal ini Anda akan melihat distribusinya terlihat lebih datar.

213
00:11:16,180 --> 00:11:20,168
Secara khusus, kemunculan semua warna abu-abu yang paling mungkin hanya

214
00:11:20,168 --> 00:11:24,435
memiliki peluang sekitar 6% untuk muncul, jadi setidaknya Anda mendapatkan 3.

215
00:11:24,435 --> 00:11:25,940
9 bit informasi.

216
00:11:25,940 --> 00:11:29,140
Tapi itu jumlah minimum, biasanya Anda akan mendapatkan sesuatu yang lebih baik dari itu.

217
00:11:29,140 --> 00:11:32,762
Dan ternyata ketika Anda menghitung angka-angka ini dan menjumlahkan

218
00:11:32,762 --> 00:11:36,333
semua istilah yang relevan, rata-rata informasinya adalah sekitar 5.

219
00:11:36,333 --> 00:11:36,420
8.

220
00:11:36,420 --> 00:11:40,148
Jadi berbeda dengan Weary, rata-rata ruang kemungkinan Anda

221
00:11:40,148 --> 00:11:43,940
akan menjadi sekitar setengahnya setelah tebakan pertama ini.

222
00:11:43,940 --> 00:11:49,540
Sebenarnya ada cerita menarik tentang nama nilai kuantitas informasi yang diharapkan ini.

223
00:11:49,540 --> 00:11:53,264
Teori informasi dikembangkan oleh Claude Shannon, yang bekerja di Bell Labs pada tahun

224
00:11:53,264 --> 00:11:56,988
1940-an, tetapi dia membicarakan beberapa idenya yang belum dipublikasikan dengan John

225
00:11:56,988 --> 00:12:00,712
von Neumann, yang merupakan raksasa intelektual pada saat itu, sangat terkemuka. dalam

226
00:12:00,712 --> 00:12:04,180
matematika dan fisika dan permulaan dari apa yang kemudian menjadi ilmu komputer.

227
00:12:04,180 --> 00:12:07,585
Dan ketika dia menyebutkan bahwa dia tidak benar-benar memiliki nama yang

228
00:12:07,585 --> 00:12:11,083
bagus untuk nilai yang diharapkan dari kuantitas informasi ini, von Neumann

229
00:12:11,083 --> 00:12:14,720
berkata, jadi ceritanya, Anda harus menyebutnya entropi, dan karena dua alasan.

230
00:12:14,720 --> 00:12:18,793
Pertama, fungsi ketidakpastian Anda telah digunakan dalam mekanika statistik dengan nama

231
00:12:18,793 --> 00:12:22,912
tersebut, sehingga sudah memiliki nama, dan kedua, dan yang lebih penting, tidak ada yang

232
00:12:22,912 --> 00:12:26,940
tahu apa sebenarnya entropi, jadi dalam perdebatan Anda akan selalu memiliki keuntungan.

233
00:12:26,940 --> 00:12:30,307
Jadi jika namanya tampak sedikit misterius, dan jika

234
00:12:30,307 --> 00:12:33,420
cerita ini dapat dipercaya, itu memang disengaja.

235
00:12:33,420 --> 00:12:36,718
Juga jika Anda bertanya-tanya tentang hubungannya dengan semua hukum

236
00:12:36,718 --> 00:12:39,968
kedua termodinamika dari fisika, pasti ada hubungannya, tetapi pada

237
00:12:39,968 --> 00:12:43,267
awalnya Shannon hanya berurusan dengan teori probabilitas murni, dan

238
00:12:43,267 --> 00:12:46,661
untuk tujuan kita di sini, ketika saya menggunakan teori kata entropi,

239
00:12:46,661 --> 00:12:50,820
saya hanya ingin Anda memikirkan nilai informasi yang diharapkan dari tebakan tertentu.

240
00:12:50,820 --> 00:12:54,380
Anda dapat menganggap entropi sebagai mengukur dua hal secara bersamaan.

241
00:12:54,380 --> 00:12:57,420
Yang pertama adalah seberapa datar distribusinya.

242
00:12:57,420 --> 00:13:01,700
Semakin dekat suatu distribusi ke seragam, semakin tinggi entropinya.

243
00:13:01,700 --> 00:13:05,338
Dalam kasus kita, jika terdapat 3 hingga 5 pola total, untuk distribusi

244
00:13:05,338 --> 00:13:08,826
seragam, mengamati salah satu dari pola tersebut akan memiliki basis

245
00:13:08,826 --> 00:13:11,858
log informasi 2 dari 3 hingga 5, yang kebetulan berjumlah 7.

246
00:13:11,858 --> 00:13:17,860
92, jadi itulah nilai maksimum mutlak yang mungkin Anda miliki untuk entropi ini.

247
00:13:17,860 --> 00:13:22,900
Namun entropi juga merupakan ukuran seberapa banyak kemungkinan yang ada.

248
00:13:22,900 --> 00:13:26,169
Misalnya, jika Anda memiliki suatu kata yang hanya memiliki 16

249
00:13:26,169 --> 00:13:29,283
kemungkinan pola, dan setiap pola memiliki kemungkinan yang

250
00:13:29,283 --> 00:13:32,760
sama, entropi ini, informasi yang diharapkan, akan berjumlah 4 bit.

251
00:13:32,760 --> 00:13:36,930
Namun jika Anda memiliki kata lain yang memiliki 64 kemungkinan pola yang muncul,

252
00:13:36,930 --> 00:13:41,000
dan semuanya memiliki kemungkinan yang sama, maka entropinya akan menjadi 6 bit.

253
00:13:41,000 --> 00:13:45,373
Jadi, jika Anda melihat suatu distribusi di alam liar yang memiliki entropi 6

254
00:13:45,373 --> 00:13:49,634
bit, hal ini seperti menyatakan bahwa ada banyak variasi dan ketidakpastian

255
00:13:49,634 --> 00:13:54,400
dalam apa yang akan terjadi, seolah-olah ada 64 kemungkinan hasil yang sama besarnya.

256
00:13:54,400 --> 00:13:58,360
Untuk pass pertama saya di Wurtelebot, pada dasarnya saya menyuruhnya melakukan ini saja.

257
00:13:58,360 --> 00:14:03,096
Ia menelusuri semua kemungkinan tebakan yang Anda miliki, seluruh 13.000 kata, menghitung

258
00:14:03,096 --> 00:14:07,622
entropi untuk masing-masing kata, atau lebih khusus lagi, entropi distribusi di semua

259
00:14:07,622 --> 00:14:12,042
pola yang mungkin Anda lihat, untuk masing-masing kata, dan memilih yang tertinggi,

260
00:14:12,042 --> 00:14:16,778
karena itulah salah satu yang kemungkinan akan mengurangi ruang kemungkinan Anda sebanyak

261
00:14:16,778 --> 00:14:17,200
mungkin.

262
00:14:17,200 --> 00:14:19,326
Dan meskipun saya hanya membicarakan tebakan pertama di

263
00:14:19,326 --> 00:14:21,680
sini, hal yang sama berlaku untuk beberapa tebakan berikutnya.

264
00:14:21,680 --> 00:14:25,220
Misalnya, setelah Anda melihat beberapa pola pada tebakan pertama tersebut, yang akan

265
00:14:25,220 --> 00:14:28,801
membatasi Anda pada kemungkinan kata yang lebih sedikit berdasarkan kecocokannya, Anda

266
00:14:28,801 --> 00:14:32,300
cukup memainkan permainan yang sama terhadap kumpulan kata yang lebih kecil tersebut.

267
00:14:32,300 --> 00:14:36,485
Untuk usulan tebakan kedua, Anda melihat distribusi semua pola yang dapat

268
00:14:36,485 --> 00:14:41,011
terjadi dari kumpulan kata yang lebih terbatas tersebut, Anda menelusuri 13.000

269
00:14:41,011 --> 00:14:45,480
kemungkinan, dan Anda menemukan salah satu yang memaksimalkan entropi tersebut.

270
00:14:45,480 --> 00:14:48,357
Untuk menunjukkan kepada Anda cara kerjanya, izinkan saya

271
00:14:48,357 --> 00:14:51,135
menampilkan sedikit varian Wurtele yang saya tulis yang

272
00:14:51,135 --> 00:14:54,460
menunjukkan hal-hal penting dari analisis ini di bagian pinggirnya.

273
00:14:54,460 --> 00:14:57,485
Setelah melakukan semua perhitungan entropinya, di sini ia menunjukkan

274
00:14:57,485 --> 00:15:00,340
kepada kita mana yang memiliki informasi yang diharapkan tertinggi.

275
00:15:00,340 --> 00:15:05,916
Ternyata jawaban teratas, setidaknya untuk saat ini, akan kita perbaiki nanti,

276
00:15:05,916 --> 00:15:11,140
adalah Taras, yang artinya, um, tentu saja, vetch, vetch yang paling umum.

277
00:15:11,140 --> 00:15:13,618
Tiap kali kita membuat tebakan di sini, mungkin saya mengabaikan

278
00:15:13,618 --> 00:15:16,210
rekomendasinya dan memilih slate, karena saya suka slate, kita bisa

279
00:15:16,210 --> 00:15:18,917
melihat berapa banyak informasi yang diharapkan darinya, tapi kemudian

280
00:15:18,917 --> 00:15:21,586
di sebelah kanan kata ini, ia menunjukkan kepada kita seberapa banyak

281
00:15:21,586 --> 00:15:24,980
informasi yang diharapkan. informasi aktual yang kami peroleh, mengingat pola khusus ini.

282
00:15:24,980 --> 00:15:27,932
Jadi di sini sepertinya kami sedikit kurang beruntung, kami diharapkan mendapat nilai 5.

283
00:15:27,932 --> 00:15:30,660
8, tapi kebetulan kami mendapatkan sesuatu yang kurang dari itu.

284
00:15:30,660 --> 00:15:33,196
Dan kemudian di sisi kiri ini menunjukkan kepada kita semua

285
00:15:33,196 --> 00:15:35,860
kemungkinan kata yang berbeda berdasarkan posisi kita sekarang.

286
00:15:35,860 --> 00:15:38,596
Bilah biru memberi tahu kita seberapa besar kemungkinannya untuk memikirkan

287
00:15:38,596 --> 00:15:41,116
setiap kata, sehingga saat ini diasumsikan bahwa setiap kata memiliki

288
00:15:41,116 --> 00:15:44,140
kemungkinan yang sama untuk muncul, namun kami akan menyempurnakannya sebentar lagi.

289
00:15:44,140 --> 00:15:47,840
Dan kemudian pengukuran ketidakpastian ini memberi tahu kita entropi dari

290
00:15:47,840 --> 00:15:51,840
distribusi ini di seluruh kemungkinan kata, yang saat ini, karena distribusinya

291
00:15:51,840 --> 00:15:55,940
seragam, hanyalah cara rumit yang tidak perlu untuk menghitung jumlah kemungkinan.

292
00:15:55,940 --> 00:15:59,343
Misalnya, jika kita ingin 2 dipangkatkan 13.

293
00:15:59,343 --> 00:16:02,700
66, itu seharusnya sekitar 13.000 kemungkinan.

294
00:16:02,700 --> 00:16:04,910
Saya sedikit melenceng di sini, tetapi hanya karena

295
00:16:04,910 --> 00:16:06,780
saya tidak menampilkan semua tempat desimal.

296
00:16:06,780 --> 00:16:09,837
Saat ini hal itu mungkin terasa berlebihan dan sepertinya terlalu rumit, tetapi

297
00:16:09,837 --> 00:16:12,780
Anda akan mengerti mengapa ada gunanya memiliki kedua angka dalam satu menit.

298
00:16:12,780 --> 00:16:16,319
Jadi di sini sepertinya entropi tertinggi untuk tebakan kedua kita

299
00:16:16,319 --> 00:16:19,700
adalah Ramen, yang sekali lagi tidak terasa seperti sebuah kata.

300
00:16:19,700 --> 00:16:22,619
Jadi untuk mengambil landasan moral yang tinggi

301
00:16:22,619 --> 00:16:25,660
di sini, saya akan melanjutkan dan mengetik Rains.

302
00:16:25,660 --> 00:16:27,540
Dan sekali lagi sepertinya kami sedikit kurang beruntung.

303
00:16:27,540 --> 00:16:28,872
Kami mengharapkan 4.

304
00:16:28,872 --> 00:16:30,556
3 bit dan kami hanya mendapat 3.

305
00:16:30,556 --> 00:16:32,100
39 bit informasi.

306
00:16:32,100 --> 00:16:35,060
Jadi itu membawa kita ke 55 kemungkinan.

307
00:16:35,060 --> 00:16:37,768
Dan di sini mungkin saya akan mengikuti apa yang

308
00:16:37,768 --> 00:16:40,200
disarankannya, yaitu kombo, apa pun artinya.

309
00:16:40,200 --> 00:16:43,300
Dan oke, ini sebenarnya kesempatan bagus untuk membuat teka-teki.

310
00:16:43,300 --> 00:16:45,718
Ini memberi tahu kita bahwa pola ini memberi kita 4.

311
00:16:45,718 --> 00:16:47,020
7 bit informasi.

312
00:16:47,020 --> 00:16:50,990
Tapi di sebelah kiri, sebelum kita melihat pola itu, ada 5.

313
00:16:50,990 --> 00:16:52,400
78 bit ketidakpastian.

314
00:16:52,400 --> 00:16:56,860
Jadi sebagai kuis untuk Anda, apa maksudnya dengan jumlah kemungkinan yang tersisa?

315
00:16:56,860 --> 00:17:00,872
Artinya, kita hanya dihadapkan pada sedikit ketidakpastian, yang

316
00:17:00,872 --> 00:17:04,700
sama saja dengan mengatakan bahwa ada dua kemungkinan jawaban.

317
00:17:04,700 --> 00:17:06,520
Itu adalah pilihan 50-50.

318
00:17:06,520 --> 00:17:08,828
Dan dari sini, karena Anda dan saya tahu kata mana yang

319
00:17:08,828 --> 00:17:11,220
lebih umum, kita tahu bahwa jawabannya pasti sangat buruk.

320
00:17:11,220 --> 00:17:13,540
Namun seperti yang tertulis sekarang, program tersebut tidak mengetahui hal itu.

321
00:17:13,540 --> 00:17:17,385
Jadi ia terus berjalan, berusaha mendapatkan informasi sebanyak-banyaknya,

322
00:17:17,385 --> 00:17:20,360
hingga hanya tersisa satu kemungkinan, lalu ia menebaknya.

323
00:17:20,360 --> 00:17:22,700
Jadi jelas kita memerlukan strategi akhir yang lebih baik.

324
00:17:22,700 --> 00:17:26,720
Tapi katakanlah kita menyebut versi ini sebagai salah satu pemecah kata-kata kita,

325
00:17:26,720 --> 00:17:30,740
dan kemudian kita menjalankan beberapa simulasi untuk melihat bagaimana kinerjanya.

326
00:17:30,740 --> 00:17:34,240
Jadi cara kerjanya adalah dengan memainkan setiap permainan kata yang memungkinkan.

327
00:17:34,240 --> 00:17:38,780
Itu melewati 2.315 kata yang merupakan jawaban kata yang sebenarnya.

328
00:17:38,780 --> 00:17:41,340
Ini pada dasarnya menggunakannya sebagai set pengujian.

329
00:17:41,340 --> 00:17:45,910
Dan dengan metode naif ini dengan tidak mempertimbangkan seberapa umum suatu kata, dan

330
00:17:45,910 --> 00:17:50,480
hanya mencoba memaksimalkan informasi di setiap langkah, hingga hanya ada satu pilihan.

331
00:17:50,480 --> 00:17:54,912
Pada akhir simulasi, skor rata-rata menjadi sekitar 4.

332
00:17:54,912 --> 00:17:55,100
124.

333
00:17:55,100 --> 00:17:59,780
Itu tidak buruk, sejujurnya, saya berharap untuk melakukan yang lebih buruk.

334
00:17:59,780 --> 00:18:01,424
Tetapi orang-orang yang bermain wordle akan memberitahu

335
00:18:01,424 --> 00:18:03,040
Anda bahwa mereka biasanya bisa mendapatkannya dalam 4.

336
00:18:03,040 --> 00:18:05,260
Tantangan sebenarnya adalah mendapatkan sebanyak 3 buah sebanyak yang Anda bisa.

337
00:18:05,260 --> 00:18:08,920
Ini merupakan lompatan yang cukup besar antara skor 4 dan skor 3.

338
00:18:08,920 --> 00:18:16,195
Hal yang jelas terlihat di sini adalah dengan memasukkan apakah suatu

339
00:18:16,195 --> 00:18:23,160
kata itu umum atau tidak, dan bagaimana tepatnya kita melakukannya.

340
00:18:23,160 --> 00:18:25,860
Cara saya mendekatinya adalah dengan mendapatkan daftar

341
00:18:25,860 --> 00:18:28,560
frekuensi relatif untuk semua kata dalam bahasa Inggris.

342
00:18:28,560 --> 00:18:32,015
Dan saya baru saja menggunakan fungsi data frekuensi kata Mathematica,

343
00:18:32,015 --> 00:18:35,520
yang diambil dari kumpulan data publik Google Buku Bahasa Inggris Ngram.

344
00:18:35,520 --> 00:18:37,959
Dan itu menyenangkan untuk dilihat, misalnya jika kita mengurutkannya

345
00:18:37,959 --> 00:18:40,120
dari kata yang paling umum hingga kata yang paling tidak umum.

346
00:18:40,120 --> 00:18:43,740
Rupanya ini adalah kata 5 huruf yang paling umum dalam bahasa Inggris.

347
00:18:43,740 --> 00:18:46,480
Atau lebih tepatnya, ini adalah yang paling umum ke-8.

348
00:18:46,480 --> 00:18:49,440
Pertama yang mana, setelah itu ada disana dan disana.

349
00:18:49,440 --> 00:18:52,626
Yang pertama bukanlah yang pertama, melainkan yang ke-9, dan masuk akal

350
00:18:52,626 --> 00:18:55,636
jika kata-kata lain ini muncul lebih sering, jika kata setelah yang

351
00:18:55,636 --> 00:18:59,000
pertama adalah setelah, di mana, dan kata-kata tersebut menjadi kurang umum.

352
00:18:59,000 --> 00:19:01,673
Sekarang, dalam menggunakan data ini untuk memodelkan seberapa

353
00:19:01,673 --> 00:19:04,389
besar kemungkinan masing-masing kata ini menjadi jawaban akhir,

354
00:19:04,389 --> 00:19:07,020
data tersebut tidak boleh hanya sebanding dengan frekuensinya.

355
00:19:07,020 --> 00:19:09,596
Misal yang diberi skor 0.

356
00:19:09,596 --> 00:19:12,398
002 dalam kumpulan data ini, sedangkan kata jalinan dalam

357
00:19:12,398 --> 00:19:15,200
beberapa hal kemungkinannya sekitar 1000 kali lebih kecil.

358
00:19:15,200 --> 00:19:17,257
Namun keduanya adalah kata-kata yang cukup umum

359
00:19:17,257 --> 00:19:19,400
sehingga hampir pasti layak untuk dipertimbangkan.

360
00:19:19,400 --> 00:19:21,900
Jadi kami ingin lebih banyak pemutusan biner.

361
00:19:21,900 --> 00:19:25,863
Cara saya melakukannya adalah dengan membayangkan mengambil seluruh daftar kata yang

362
00:19:25,863 --> 00:19:29,826
diurutkan ini, dan kemudian menyusunnya pada sumbu x, dan kemudian menerapkan fungsi

363
00:19:29,826 --> 00:19:34,023
sigmoid, yang merupakan cara standar untuk memiliki fungsi yang keluarannya pada dasarnya

364
00:19:34,023 --> 00:19:38,080
biner, itu's baik 0 atau 1, namun terdapat kelancaran di antara wilayah ketidakpastian

365
00:19:38,080 --> 00:19:38,500
tersebut.

366
00:19:38,500 --> 00:19:43,894
Jadi pada dasarnya, probabilitas yang saya tetapkan untuk setiap kata untuk berada di

367
00:19:43,894 --> 00:19:49,540
daftar akhir akan menjadi nilai fungsi sigmoid di atas di mana pun ia berada pada sumbu x.

368
00:19:49,540 --> 00:19:53,116
Tentu saja hal ini bergantung pada beberapa parameter, misalnya seberapa

369
00:19:53,116 --> 00:19:56,594
lebar spasi pada sumbu x kata-kata tersebut terisi menentukan seberapa

370
00:19:56,594 --> 00:19:59,730
bertahap atau tajamnya kita turun dari 1 ke 0, dan di mana kita

371
00:19:59,730 --> 00:20:03,160
menempatkan kata-kata tersebut dari kiri ke kanan menentukan batasnya.

372
00:20:03,160 --> 00:20:07,340
Sejujurnya, caraku melakukan ini hanyalah menjilat jariku dan menempelkannya ke angin.

373
00:20:07,340 --> 00:20:10,818
Saya melihat daftar yang diurutkan dan mencoba menemukan jendela di mana

374
00:20:10,818 --> 00:20:14,201
ketika saya melihatnya, saya pikir sekitar setengah dari kata-kata ini

375
00:20:14,201 --> 00:20:17,680
lebih mungkin menjadi jawaban akhir, dan menggunakannya sebagai batasnya.

376
00:20:17,680 --> 00:20:21,160
Setelah kita mendapatkan distribusi seperti ini di seluruh kata, ini memberi

377
00:20:21,160 --> 00:20:24,460
kita situasi lain di mana entropi menjadi pengukuran yang sangat berguna.

378
00:20:24,460 --> 00:20:27,514
Sebagai contoh, katakanlah kita sedang bermain game dan kita mulai

379
00:20:27,514 --> 00:20:30,477
dengan pembuka lama saya, yaitu bulu dan paku, dan kita berakhir

380
00:20:30,477 --> 00:20:33,760
dengan situasi di mana ada empat kemungkinan kata yang cocok dengan itu.

381
00:20:33,760 --> 00:20:36,440
Dan katakanlah kita menganggap semuanya memiliki kemungkinan yang sama.

382
00:20:36,440 --> 00:20:40,000
Izinkan saya bertanya, berapa entropi distribusi ini?

383
00:20:40,000 --> 00:20:45,542
Nah, informasi yang terkait dengan masing-masing kemungkinan ini akan menjadi

384
00:20:45,542 --> 00:20:50,800
basis log 2 dari 4, karena masing-masing adalah 1 dan 4, dan itu adalah 2.

385
00:20:50,800 --> 00:20:52,780
Dua informasi, empat kemungkinan.

386
00:20:52,780 --> 00:20:54,360
Semuanya sangat baik dan bagus.

387
00:20:54,360 --> 00:20:58,320
Tapi bagaimana jika saya bilang sebenarnya ada lebih dari empat pertandingan?

388
00:20:58,320 --> 00:21:02,600
Kenyataannya, jika kita melihat daftar kata selengkapnya, ada 16 kata yang cocok.

389
00:21:02,600 --> 00:21:07,020
Namun misalkan model kita memberikan probabilitas yang sangat rendah pada 12 kata lainnya

390
00:21:07,020 --> 00:21:11,440
untuk menjadi jawaban akhir, sekitar 1 dalam 1000 karena kata tersebut sangat tidak jelas.

391
00:21:11,440 --> 00:21:15,480
Sekarang izinkan saya bertanya, berapa entropi distribusi ini?

392
00:21:15,480 --> 00:21:19,182
Jika entropi hanya mengukur jumlah kecocokan di sini, Anda mungkin

393
00:21:19,182 --> 00:21:22,608
mengharapkannya menjadi basis log 2 dari 16, yaitu 4, dua bit

394
00:21:22,608 --> 00:21:26,200
ketidakpastian lebih banyak daripada yang kita miliki sebelumnya.

395
00:21:26,200 --> 00:21:28,318
Namun tentu saja ketidakpastian yang sebenarnya tidak

396
00:21:28,318 --> 00:21:30,320
jauh berbeda dengan apa yang kita alami sebelumnya.

397
00:21:30,320 --> 00:21:34,337
Hanya karena ada 12 kata yang sangat tidak jelas ini tidak berarti akan lebih

398
00:21:34,337 --> 00:21:38,200
mengejutkan jika mengetahui bahwa jawaban akhirnya adalah pesona, misalnya.

399
00:21:38,200 --> 00:21:41,627
Jadi ketika Anda benar-benar melakukan perhitungan di sini, dan Anda menjumlahkan

400
00:21:41,627 --> 00:21:45,138
probabilitas setiap kejadian dikalikan dengan informasi terkait, yang Anda dapatkan

401
00:21:45,138 --> 00:21:45,514
adalah 2.

402
00:21:45,514 --> 00:21:45,960
11 bit.

403
00:21:45,960 --> 00:21:49,636
Maksud saya, pada dasarnya ada dua bagian, pada dasarnya empat kemungkinan tersebut,

404
00:21:49,636 --> 00:21:53,140
namun ada sedikit ketidakpastian karena semua kejadian yang sangat tidak mungkin

405
00:21:53,140 --> 00:21:56,773
tersebut, meskipun jika Anda mempelajarinya, Anda akan mendapatkan banyak informasi

406
00:21:56,773 --> 00:21:57,120
darinya.

407
00:21:57,120 --> 00:21:59,418
Jadi jika diperkecil, inilah bagian yang membuat Wordle

408
00:21:59,418 --> 00:22:01,800
menjadi contoh yang bagus untuk pelajaran teori informasi.

409
00:22:01,800 --> 00:22:05,280
Kami memiliki dua penerapan perasaan yang berbeda untuk entropi.

410
00:22:05,280 --> 00:22:08,997
Yang pertama memberi tahu kita informasi apa yang diharapkan yang akan kita

411
00:22:08,997 --> 00:22:12,860
peroleh dari tebakan tertentu, dan yang kedua mengatakan bisakah kita mengukur

412
00:22:12,860 --> 00:22:16,480
ketidakpastian yang tersisa di antara semua kata yang mungkin kita miliki.

413
00:22:16,480 --> 00:22:19,147
Dan saya harus menekankan, dalam kasus pertama ketika kita melihat

414
00:22:19,147 --> 00:22:21,894
informasi yang diharapkan dari sebuah tebakan, setelah kita memiliki

415
00:22:21,894 --> 00:22:25,000
bobot yang tidak sama pada kata-katanya, itu mempengaruhi perhitungan entropi.

416
00:22:25,000 --> 00:22:28,216
Sebagai contoh, izinkan saya mengambil kasus yang sama yang kita lihat

417
00:22:28,216 --> 00:22:31,297
sebelumnya tentang distribusi yang terkait dengan Weary, namun kali

418
00:22:31,297 --> 00:22:34,560
ini menggunakan distribusi yang tidak seragam di semua kemungkinan kata.

419
00:22:34,560 --> 00:22:36,937
Jadi izinkan saya melihat apakah saya dapat menemukan

420
00:22:36,937 --> 00:22:39,360
bagian di sini yang menggambarkannya dengan cukup baik.

421
00:22:39,360 --> 00:22:42,480
Oke, ini cukup bagus.

422
00:22:42,480 --> 00:22:46,075
Di sini kita memiliki dua pola berdekatan yang kemungkinannya hampir sama,

423
00:22:46,075 --> 00:22:49,480
namun salah satu pola tersebut memiliki 32 kemungkinan kata yang cocok.

424
00:22:49,480 --> 00:22:52,603
Dan jika kita periksa apa itu, ini adalah 32 kata tersebut, yang semuanya

425
00:22:52,603 --> 00:22:55,600
merupakan kata-kata yang sangat tidak mungkin ketika Anda mengamatinya.

426
00:22:55,600 --> 00:22:59,256
Sulit untuk menemukan jawaban yang terasa masuk akal, mungkin teriakan,

427
00:22:59,256 --> 00:23:02,861
tetapi jika kita melihat pola tetangga dalam distribusi, yang dianggap

428
00:23:02,861 --> 00:23:06,619
sama mungkinnya, kita diberitahu bahwa hanya ada 8 kemungkinan kecocokan,

429
00:23:06,619 --> 00:23:09,920
jadi seperempatnya banyak pertandingan, tapi kemungkinannya sama.

430
00:23:09,920 --> 00:23:12,520
Dan saat kami menghentikan pertandingan tersebut, kami dapat mengetahui alasannya.

431
00:23:12,520 --> 00:23:15,451
Beberapa di antaranya adalah jawaban yang benar-benar

432
00:23:15,451 --> 00:23:17,840
masuk akal, seperti dering, murka, atau rap.

433
00:23:17,840 --> 00:23:20,575
Untuk mengilustrasikan bagaimana kami menggabungkan semua itu,

434
00:23:20,575 --> 00:23:23,180
izinkan saya menampilkan Wordlebot versi 2 di sini, dan ada

435
00:23:23,180 --> 00:23:25,960
dua atau tiga perbedaan utama dari yang pertama yang kami lihat.

436
00:23:25,960 --> 00:23:30,441
Pertama, seperti yang baru saja saya katakan, cara kita menghitung entropi ini, nilai

437
00:23:30,441 --> 00:23:34,766
informasi yang diharapkan, kini menggunakan distribusi yang lebih halus di seluruh

438
00:23:34,766 --> 00:23:39,300
pola yang menggabungkan probabilitas bahwa suatu kata tertentu akan menjadi jawabannya.

439
00:23:39,300 --> 00:23:44,160
Ternyata, air mata tetaplah nomor 1, meski air mata berikut ini sedikit berbeda.

440
00:23:44,160 --> 00:23:46,980
Kedua, ketika ia memberi peringkat pada pilihan teratasnya, sekarang ia

441
00:23:46,980 --> 00:23:49,604
akan menyimpan model probabilitas bahwa setiap kata adalah jawaban

442
00:23:49,604 --> 00:23:52,425
sebenarnya, dan ia akan memasukkannya ke dalam keputusannya, yang lebih

443
00:23:52,425 --> 00:23:55,520
mudah dilihat setelah kita mempunyai beberapa tebakan pada kata tersebut. meja.

444
00:23:55,520 --> 00:23:58,320
Sekali lagi, abaikan rekomendasinya karena kita

445
00:23:58,320 --> 00:24:01,120
tidak bisa membiarkan mesin mengatur hidup kita.

446
00:24:01,120 --> 00:24:05,416
Dan saya kira saya harus menyebutkan hal lain yang berbeda di sebelah kiri, bahwa

447
00:24:05,416 --> 00:24:10,080
nilai ketidakpastian, jumlah bit, tidak lagi mubazir dengan jumlah kemungkinan kecocokan.

448
00:24:10,080 --> 00:24:13,489
Sekarang jika kita menariknya dan menghitung 2 sampai 8.

449
00:24:13,489 --> 00:24:18,845
02, yang sedikit di atas 256, saya rasa 259, maksudnya adalah meskipun ada 526

450
00:24:18,845 --> 00:24:24,404
kata yang benar-benar cocok dengan pola ini, jumlah ketidakpastiannya lebih mirip

451
00:24:24,404 --> 00:24:29,760
dengan apa yang akan terjadi jika ada 259 kata yang sama kemungkinannya. hasil.

452
00:24:29,760 --> 00:24:31,100
Anda bisa memikirkannya seperti ini.

453
00:24:31,100 --> 00:24:34,511
Ia mengetahui bahwa borx bukanlah jawabannya, sama halnya dengan yorts, zorl, dan

454
00:24:34,511 --> 00:24:37,840
zorus, jadi ketidakpastiannya tidak terlalu besar dibandingkan kasus sebelumnya.

455
00:24:37,840 --> 00:24:40,220
Jumlah bit ini akan lebih kecil.

456
00:24:40,220 --> 00:24:44,256
Dan jika saya terus memainkan permainan ini, saya akan menyempurnakannya

457
00:24:44,256 --> 00:24:48,680
dengan beberapa tebakan yang sesuai dengan apa yang ingin saya jelaskan di sini.

458
00:24:48,680 --> 00:24:51,280
Pada tebakan keempat, jika Anda melihat pilihan teratasnya, Anda

459
00:24:51,280 --> 00:24:53,800
dapat melihat bahwa ini tidak lagi hanya memaksimalkan entropi.

460
00:24:53,800 --> 00:24:57,392
Jadi saat ini, secara teknis ada tujuh kemungkinan, tapi satu-satunya

461
00:24:57,392 --> 00:25:00,780
peluang yang memiliki peluang berarti adalah asrama dan kata-kata.

462
00:25:00,780 --> 00:25:04,256
Dan Anda dapat melihat peringkatnya dengan memilih kedua nilai tersebut di atas

463
00:25:04,256 --> 00:25:07,560
semua nilai lainnya, yang sebenarnya akan memberikan lebih banyak informasi.

464
00:25:07,560 --> 00:25:11,237
Pertama kali saya melakukan ini, saya hanya menjumlahkan kedua angka ini untuk mengukur

465
00:25:11,237 --> 00:25:14,580
kualitas setiap tebakan, yang sebenarnya bekerja lebih baik dari yang Anda duga.

466
00:25:14,580 --> 00:25:17,210
Namun hal ini terasa tidak sistematis, dan saya yakin ada pendekatan

467
00:25:17,210 --> 00:25:19,880
lain yang bisa diambil orang, namun inilah pendekatan yang saya pilih.

468
00:25:19,880 --> 00:25:22,843
Jika kita mempertimbangkan prospek tebakan berikutnya, seperti

469
00:25:22,843 --> 00:25:25,618
dalam hal ini, yang benar-benar kita pedulikan adalah skor

470
00:25:25,618 --> 00:25:28,440
yang diharapkan dari permainan kita jika kita melakukan itu.

471
00:25:28,440 --> 00:25:32,142
Dan untuk menghitung skor yang diharapkan, kami mengatakan berapa probabilitas

472
00:25:32,142 --> 00:25:36,080
bahwa kata-kata tersebut adalah jawaban sebenarnya, yang saat ini menggambarkan 58%.

473
00:25:36,080 --> 00:25:40,400
Kami katakan dengan peluang 58%, skor kami dalam permainan ini adalah 4.

474
00:25:40,400 --> 00:25:46,240
Dan kemudian dengan probabilitas 1 dikurangi 58% itu, skor kita akan lebih dari 4 itu.

475
00:25:46,240 --> 00:25:49,617
Berapa banyak lagi yang belum kita ketahui, namun kita dapat memperkirakannya berdasarkan

476
00:25:49,617 --> 00:25:52,920
seberapa besar ketidakpastian yang mungkin terjadi setelah kita mencapai titik tersebut.

477
00:25:52,920 --> 00:25:55,227
Secara khusus, saat ini ada 1.

478
00:25:55,227 --> 00:25:56,600
44 bit ketidakpastian.

479
00:25:56,600 --> 00:25:58,826
Jika kita menebak kata-kata, itu memberi tahu kita bahwa

480
00:25:58,826 --> 00:26:01,131
informasi yang diharapkan yang akan kita dapatkan adalah 1.

481
00:26:01,131 --> 00:26:01,560
27 bit.

482
00:26:01,560 --> 00:26:04,992
Jadi jika kita menebak-nebak, perbedaan ini menunjukkan seberapa besar

483
00:26:04,992 --> 00:26:08,280
ketidakpastian yang mungkin kita alami setelah hal tersebut terjadi.

484
00:26:08,280 --> 00:26:11,101
Yang kita butuhkan adalah suatu fungsi, yang saya sebut f di sini,

485
00:26:11,101 --> 00:26:13,880
yang menghubungkan ketidakpastian ini dengan skor yang diharapkan.

486
00:26:13,880 --> 00:26:18,225
Dan caranya adalah dengan memplot sekumpulan data dari game sebelumnya

487
00:26:18,225 --> 00:26:22,632
berdasarkan versi 1 bot untuk mengatakan berapa skor sebenarnya setelah

488
00:26:22,632 --> 00:26:27,040
berbagai poin dengan jumlah ketidakpastian tertentu yang sangat terukur.

489
00:26:27,040 --> 00:26:31,073
Misalnya, titik data di sini yang berada di atas nilai sekitar 8.

490
00:26:31,073 --> 00:26:35,426
7 atau lebih dikatakan untuk beberapa permainan setelah titik di mana ada 8.

491
00:26:35,426 --> 00:26:39,340
7 bit ketidakpastian, butuh dua tebakan untuk mendapatkan jawaban akhir.

492
00:26:39,340 --> 00:26:41,260
Untuk permainan lainnya membutuhkan tiga kali tebakan,

493
00:26:41,260 --> 00:26:43,180
untuk permainan lainnya membutuhkan empat kali tebakan.

494
00:26:43,180 --> 00:26:46,929
Jika kita menggeser ke kiri di sini, semua titik di atas nol menyatakan

495
00:26:46,929 --> 00:26:50,626
kapan pun tidak ada sedikit pun ketidakpastian, artinya hanya ada satu

496
00:26:50,626 --> 00:26:55,000
kemungkinan, maka jumlah tebakan yang diperlukan selalu hanya satu, yang meyakinkan.

497
00:26:55,000 --> 00:26:59,713
Kapan pun ada sedikit ketidakpastian, artinya pada dasarnya hanya ada dua kemungkinan,

498
00:26:59,713 --> 00:27:03,940
terkadang diperlukan satu tebakan lagi, terkadang diperlukan dua tebakan lagi.

499
00:27:03,940 --> 00:27:05,980
Dan seterusnya dan seterusnya di sini.

500
00:27:05,980 --> 00:27:08,402
Mungkin cara yang sedikit lebih mudah untuk memvisualisasikan

501
00:27:08,402 --> 00:27:11,020
data ini adalah dengan menggabungkannya dan mengambil rata-ratanya.

502
00:27:11,020 --> 00:27:16,392
Misalnya bilah di sini menyatakan di antara semua titik di mana kita mempunyai

503
00:27:16,392 --> 00:27:22,308
sedikit ketidakpastian, rata-rata jumlah tebakan baru yang diperlukan adalah sekitar 1.

504
00:27:22,308 --> 00:27:22,420
5.

505
00:27:22,420 --> 00:27:25,950
Dan batasan di sini mengatakan di antara semua permainan yang berbeda

506
00:27:25,950 --> 00:27:29,380
di mana pada titik tertentu ketidakpastiannya sedikit di atas empat

507
00:27:29,380 --> 00:27:32,709
bit, yang seperti mempersempitnya menjadi 16 kemungkinan berbeda,

508
00:27:32,709 --> 00:27:36,240
maka rata-rata memerlukan lebih dari dua tebakan dari titik itu. maju.

509
00:27:36,240 --> 00:27:38,071
Dan dari sini saya baru saja melakukan regresi agar

510
00:27:38,071 --> 00:27:40,080
sesuai dengan fungsi yang tampaknya masuk akal untuk ini.

511
00:27:40,080 --> 00:27:43,344
Dan ingat, inti dari melakukan semua itu adalah agar kita dapat

512
00:27:43,344 --> 00:27:46,710
mengukur intuisi bahwa semakin banyak informasi yang kita peroleh

513
00:27:46,710 --> 00:27:49,720
dari sebuah kata, semakin rendah pula skor yang diharapkan.

514
00:27:49,720 --> 00:27:51,043
Jadi dengan ini sebagai versi 2.

515
00:27:51,043 --> 00:27:55,127
0, jika kita kembali dan menjalankan rangkaian simulasi yang sama,

516
00:27:55,127 --> 00:27:59,820
memainkannya melawan semua 2315 kemungkinan jawaban, bagaimana cara kerjanya?

517
00:27:59,820 --> 00:28:04,060
Berbeda dengan versi pertama kami, ini pasti lebih baik, dan itu meyakinkan.

518
00:28:04,060 --> 00:28:06,284
Semua dikatakan dan dilakukan rata-ratanya adalah sekitar 3.

519
00:28:06,284 --> 00:28:09,369
6, meskipun tidak seperti versi pertama, ada beberapa kali

520
00:28:09,369 --> 00:28:12,820
versi ini kalah dan membutuhkan lebih dari enam dalam keadaan ini.

521
00:28:12,820 --> 00:28:15,874
Mungkin karena ada kalanya kita melakukan pengorbanan untuk

522
00:28:15,874 --> 00:28:18,980
benar-benar mencapai tujuan daripada memaksimalkan informasi.

523
00:28:18,980 --> 00:28:22,022
Jadi bisakah kita melakukan lebih baik dari 3.

524
00:28:22,022 --> 00:28:22,140
6?

525
00:28:22,140 --> 00:28:23,260
Kami pasti bisa.

526
00:28:23,260 --> 00:28:26,555
Sekarang saya katakan di awal bahwa paling menyenangkan adalah mencoba tidak

527
00:28:26,555 --> 00:28:29,980
memasukkan daftar jawaban kata yang sebenarnya ke dalam cara membangun modelnya.

528
00:28:29,980 --> 00:28:32,786
Namun jika kami menggabungkannya, performa terbaik

529
00:28:32,786 --> 00:28:35,043
yang bisa saya dapatkan adalah sekitar 3.

530
00:28:35,043 --> 00:28:35,180
43.

531
00:28:35,180 --> 00:28:38,220
Jadi jika kita mencoba menjadi lebih canggih dari sekedar menggunakan

532
00:28:38,220 --> 00:28:40,957
data frekuensi kata untuk memilih distribusi sebelumnya, ini 3.

533
00:28:40,957 --> 00:28:43,623
43 mungkin memberi gambaran maksimal seberapa bagus yang bisa kita dapatkan

534
00:28:43,623 --> 00:28:46,360
dengan itu, atau setidaknya seberapa bagus yang bisa saya dapatkan dengan itu.

535
00:28:46,360 --> 00:28:49,514
Performa terbaik tersebut pada dasarnya hanya menggunakan ide-ide yang telah

536
00:28:49,514 --> 00:28:52,669
saya bicarakan di sini, namun lebih jauh lagi, seperti melakukan penelusuran

537
00:28:52,669 --> 00:28:55,660
informasi yang diharapkan dua langkah ke depan, bukan hanya satu langkah.

538
00:28:55,660 --> 00:28:58,154
Awalnya saya berencana untuk membicarakan lebih banyak tentang hal itu,

539
00:28:58,154 --> 00:29:00,580
tetapi saya menyadari bahwa kita sebenarnya sudah berjalan cukup lama.

540
00:29:00,580 --> 00:29:03,498
Satu hal yang akan saya katakan adalah setelah melakukan pencarian dua

541
00:29:03,498 --> 00:29:06,622
langkah ini dan kemudian menjalankan beberapa contoh simulasi pada kandidat

542
00:29:06,622 --> 00:29:09,500
teratas, sejauh ini bagi saya setidaknya Crane adalah pembuka terbaik.

543
00:29:09,500 --> 00:29:11,080
Siapa sangka?

544
00:29:11,080 --> 00:29:14,488
Juga jika Anda menggunakan daftar kata yang sebenarnya untuk menentukan ruang

545
00:29:14,488 --> 00:29:18,160
kemungkinan Anda, maka ketidakpastian yang Anda mulai adalah sedikit di atas 11 bit.

546
00:29:18,160 --> 00:29:22,401
Dan ternyata, hanya dari pencarian brute force, informasi maksimal

547
00:29:22,401 --> 00:29:26,580
yang diharapkan setelah dua tebakan pertama adalah sekitar 10 bit.

548
00:29:26,580 --> 00:29:30,927
Hal ini menunjukkan bahwa skenario terbaik, setelah dua tebakan pertama Anda,

549
00:29:30,927 --> 00:29:35,220
dengan permainan optimal sempurna, Anda akan memiliki sedikit ketidakpastian.

550
00:29:35,220 --> 00:29:37,400
Yang sama dengan membuat dua kemungkinan tebakan.

551
00:29:37,400 --> 00:29:40,039
Jadi menurut saya adil dan mungkin cukup konservatif untuk mengatakan bahwa

552
00:29:40,039 --> 00:29:42,575
Anda tidak akan pernah bisa menulis algoritma yang mendapatkan rata-rata

553
00:29:42,575 --> 00:29:45,076
serendah 3, karena dengan kata-kata yang tersedia untuk Anda, tidak ada

554
00:29:45,076 --> 00:29:47,716
ruang untuk mendapatkan informasi yang cukup setelah hanya dua langkah yang

555
00:29:47,716 --> 00:29:50,460
harus dilakukan. mampu menjamin jawaban di slot ketiga setiap saat tanpa gagal.

