[
 {
  "input": "The game Wurdle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.",
  "model": "nmt",
  "translatedText": "Permainan Wurdle telah menjadi sangat viral dalam satu atau dua bulan terakhir, dan tidak ada seorangpun yang melewatkan kesempatan untuk pelajaran matematika, menurut saya permainan ini menjadi contoh sentral yang sangat baik dalam pelajaran tentang teori informasi, dan khususnya topik yang dikenal sebagai entropi.",
  "time_range": [
   0.0,
   12.66
  ],
  "n_reviews": 0
 },
 {
  "input": "You see, like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.",
  "model": "nmt",
  "translatedText": "Anda tahu, seperti kebanyakan orang, saya terjebak dalam teka-teki, dan seperti kebanyakan programmer, saya juga terjebak dalam upaya menulis algoritma yang akan memainkan permainan seoptimal mungkin.",
  "time_range": [
   13.92,
   22.74
  ],
  "n_reviews": 0
 },
 {
  "input": "And what I thought I'd do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy.",
  "model": "nmt",
  "translatedText": "Dan apa yang saya pikir akan saya lakukan di sini hanyalah membicarakan dengan Anda beberapa proses saya di dalamnya, dan menjelaskan beberapa perhitungan matematika yang masuk ke dalamnya, karena keseluruhan algoritma berpusat pada gagasan entropi ini.",
  "time_range": [
   23.18,
   31.08
  ],
  "n_reviews": 0
 },
 {
  "input": "First things first, in case you haven't heard of it, what is Wurdle?",
  "model": "nmt",
  "translatedText": "Hal pertama yang pertama, jika Anda belum pernah mendengarnya, apa itu Wurdle?",
  "time_range": [
   38.7,
   41.64
  ],
  "n_reviews": 0
 },
 {
  "input": "And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we're going with this, which is to develop a little algorithm that will basically play the game for us.",
  "model": "nmt",
  "translatedText": "Dan untuk membunuh dua burung dengan satu batu di sini sementara kita membahas aturan permainannya, izinkan saya juga melihat ke mana tujuan kita dengan hal ini, yaitu mengembangkan algoritma kecil yang pada dasarnya akan memainkan permainan tersebut untuk kita.",
  "time_range": [
   42.04,
   51.04
  ],
  "n_reviews": 0
 },
 {
  "input": "Though I haven't done today's Wurdle, this is February 4th, and we'll see how the bot does.",
  "model": "nmt",
  "translatedText": "Meskipun saya belum melakukan Wurdle hari ini, ini tanggal 4 Februari, dan kita akan melihat bagaimana botnya melakukannya.",
  "time_range": [
   51.36,
   55.1
  ],
  "n_reviews": 0
 },
 {
  "input": "The goal of Wurdle is to guess a mystery five letter word, and you're given six different chances to guess.",
  "model": "nmt",
  "translatedText": "Tujuan Wurdle adalah menebak kata misteri lima huruf, dan Anda diberi enam peluang berbeda untuk menebak.",
  "time_range": [
   55.48,
   60.34
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, my Wurdle bot suggests that I start with the guess crane.",
  "model": "nmt",
  "translatedText": "Misalnya, bot Wurdle saya menyarankan agar saya memulai dengan tebakan derek.",
  "time_range": [
   60.84,
   64.38
  ],
  "n_reviews": 0
 },
 {
  "input": "Each time that you make a guess, you get some information about how close your guess is to the true answer.",
  "model": "nmt",
  "translatedText": "Setiap kali Anda menebak, Anda mendapatkan informasi tentang seberapa dekat tebakan Anda dengan jawaban sebenarnya.",
  "time_range": [
   65.18,
   70.22
  ],
  "n_reviews": 0
 },
 {
  "input": "Here the grey box is telling me there's no C in the actual answer.",
  "model": "nmt",
  "translatedText": "Di sini kotak abu-abu memberi tahu saya bahwa tidak ada C pada jawaban sebenarnya.",
  "time_range": [
   70.92,
   74.1
  ],
  "n_reviews": 0
 },
 {
  "input": "The yellow box is telling me there is an R, but it's not in that position.",
  "model": "nmt",
  "translatedText": "Kotak kuning memberitahu saya ada huruf R, tapi posisinya tidak seperti itu.",
  "time_range": [
   74.52,
   77.84
  ],
  "n_reviews": 0
 },
 {
  "input": "The green box is telling me that the secret word does have an A, and it's in the third position.",
  "model": "nmt",
  "translatedText": "Kotak hijau memberitahu saya bahwa kata rahasianya memang memiliki nilai A, dan berada di posisi ketiga.",
  "time_range": [
   78.24,
   82.24
  ],
  "n_reviews": 0
 },
 {
  "input": "And then there's no N and there's no E.",
  "model": "nmt",
  "translatedText": "Dan kemudian tidak ada N dan tidak ada E.",
  "time_range": [
   82.72,
   84.58
  ],
  "n_reviews": 0
 },
 {
  "input": "So let me just go in and tell the Wurdle bot that information.",
  "model": "nmt",
  "translatedText": "Jadi izinkan saya masuk dan memberi tahu bot Wurdle informasi itu.",
  "time_range": [
   85.2,
   87.34
  ],
  "n_reviews": 0
 },
 {
  "input": "We started with crane, we got grey, yellow, green, grey, grey.",
  "model": "nmt",
  "translatedText": "Kami mulai dengan crane, kami mendapat warna abu-abu, kuning, hijau, abu-abu, abu-abu.",
  "time_range": [
   87.34,
   90.32
  ],
  "n_reviews": 0
 },
 {
  "input": "Don't worry about all the data that it's showing right now, I'll explain that in due time.",
  "model": "nmt",
  "translatedText": "Jangan khawatir tentang semua data yang ditampilkan saat ini, saya akan menjelaskannya pada waktunya.",
  "time_range": [
   91.42,
   94.94
  ],
  "n_reviews": 0
 },
 {
  "input": "But its top suggestion for our second pick is shtick.",
  "model": "nmt",
  "translatedText": "Tapi saran utamanya untuk pilihan kedua kami adalah buruk.",
  "time_range": [
   95.46,
   98.82
  ],
  "n_reviews": 0
 },
 {
  "input": "And your guess does have to be an actual five letter word, but as you'll see, it's pretty liberal with what it will actually let you guess.",
  "model": "nmt",
  "translatedText": "Dan tebakan Anda memang harus berupa kata yang terdiri dari lima huruf, tetapi seperti yang akan Anda lihat, tebakannya cukup liberal karena memungkinkan Anda menebaknya.",
  "time_range": [
   99.56,
   105.4
  ],
  "n_reviews": 0
 },
 {
  "input": "In this case, we try shtick.",
  "model": "nmt",
  "translatedText": "Dalam hal ini, kami mencoba shtick.",
  "time_range": [
   106.2,
   107.44
  ],
  "n_reviews": 0
 },
 {
  "input": "And alright, things are looking pretty good.",
  "model": "nmt",
  "translatedText": "Dan baiklah, semuanya terlihat cukup bagus.",
  "time_range": [
   108.78,
   110.18
  ],
  "n_reviews": 0
 },
 {
  "input": "We hit the S and the H, so we know the first three letters, we know that there's an R.",
  "model": "nmt",
  "translatedText": "Kita tekan S dan H, jadi kita tahu tiga huruf pertama, kita tahu ada R.",
  "time_range": [
   110.26,
   113.98
  ],
  "n_reviews": 0
 },
 {
  "input": "And so it's going to be like S-H-A something R, or S-H-A R something.",
  "model": "nmt",
  "translatedText": "Jadi itu akan menjadi seperti SHA sesuatu R, atau SHA R sesuatu.",
  "time_range": [
   113.98,
   118.7
  ],
  "n_reviews": 0
 },
 {
  "input": "And it looks like the Wurdle bot knows that it's down to just two possibilities, either shard or sharp.",
  "model": "nmt",
  "translatedText": "Dan sepertinya bot Wurdle mengetahui bahwa hanya ada dua kemungkinan, yaitu pecahan atau tajam.",
  "time_range": [
   119.62,
   124.24
  ],
  "n_reviews": 0
 },
 {
  "input": "That's kind of a toss up between them at this point, so I guess probably just because it's alphabetical it goes with shard.",
  "model": "nmt",
  "translatedText": "Saat ini ada semacam perselisihan di antara mereka, jadi saya kira mungkin hanya karena sesuai abjad, maka itu sesuai dengan pecahan.",
  "time_range": [
   125.1,
   130.08
  ],
  "n_reviews": 0
 },
 {
  "input": "Which hooray, is the actual answer.",
  "model": "nmt",
  "translatedText": "Yang mana hore, itulah jawaban sebenarnya.",
  "time_range": [
   131.22,
   132.86
  ],
  "n_reviews": 0
 },
 {
  "input": "So we got it in three.",
  "model": "nmt",
  "translatedText": "Jadi kami mendapatkannya dalam tiga.",
  "time_range": [
   132.96,
   133.78
  ],
  "n_reviews": 0
 },
 {
  "input": "If you're wondering if that's any good, the way I heard one person phrase it is that with Wurdle four is par and three is birdie.",
  "model": "nmt",
  "translatedText": "Jika Anda bertanya-tanya apakah itu bagus, saya mendengar satu orang berkata bahwa dengan Wurdle empat adalah par dan tiga adalah birdie.",
  "time_range": [
   134.6,
   140.36
  ],
  "n_reviews": 0
 },
 {
  "input": "Which I think is a pretty apt analogy.",
  "model": "nmt",
  "translatedText": "Yang menurut saya merupakan analogi yang cukup tepat.",
  "time_range": [
   140.68,
   142.48
  ],
  "n_reviews": 0
 },
 {
  "input": "You have to be consistently on your game to be getting four, but it's certainly not crazy.",
  "model": "nmt",
  "translatedText": "Anda harus konsisten dalam permainan Anda untuk mendapatkan empat, tapi itu jelas tidak gila.",
  "time_range": [
   142.48,
   147.02
  ],
  "n_reviews": 0
 },
 {
  "input": "But when you get it in three, it just feels great.",
  "model": "nmt",
  "translatedText": "Tapi ketika Anda mendapatkannya dalam tiga, rasanya luar biasa.",
  "time_range": [
   147.18,
   149.92
  ],
  "n_reviews": 0
 },
 {
  "input": "So if you're down for it, what I'd like to do here is just talk through my thought process from the beginning for how I approach the Wurdle bot.",
  "model": "nmt",
  "translatedText": "Jadi jika Anda menginginkannya, yang ingin saya lakukan di sini hanyalah membahas proses pemikiran saya dari awal tentang cara saya mendekati bot Wurdle.",
  "time_range": [
   150.88,
   155.96
  ],
  "n_reviews": 0
 },
 {
  "input": "And like I said, really it's an excuse for an information theory lesson.",
  "model": "nmt",
  "translatedText": "Dan seperti yang saya katakan, ini sebenarnya alasan untuk pelajaran teori informasi.",
  "time_range": [
   156.48,
   159.44
  ],
  "n_reviews": 0
 },
 {
  "input": "The main goal is to explain what is information and what is entropy.",
  "model": "nmt",
  "translatedText": "Tujuan utamanya adalah menjelaskan apa itu informasi dan apa itu entropi.",
  "time_range": [
   159.74,
   162.82
  ],
  "n_reviews": 0
 },
 {
  "input": "My first thought in approaching this was to take a look at the relative frequencies of different letters in the English language.",
  "model": "nmt",
  "translatedText": "Pikiran pertama saya dalam melakukan pendekatan ini adalah melihat frekuensi relatif berbagai huruf dalam bahasa Inggris.",
  "time_range": [
   168.22,
   173.72
  ],
  "n_reviews": 0
 },
 {
  "input": "So I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters?",
  "model": "nmt",
  "translatedText": "Jadi saya berpikir, oke, apakah ada tebakan pembuka atau tebakan pembuka yang banyak mengenai huruf yang paling sering ini?",
  "time_range": [
   174.38,
   179.26
  ],
  "n_reviews": 0
 },
 {
  "input": "And one that I was pretty fond of was doing other followed by nails.",
  "model": "nmt",
  "translatedText": "Dan salah satu hal yang sangat saya sukai adalah melakukan hal lain yang diikuti dengan paku.",
  "time_range": [
   179.96,
   183.0
  ],
  "n_reviews": 0
 },
 {
  "input": "The thought is that if you hit a letter, you know, you get a green or a yellow, that always feels good.",
  "model": "nmt",
  "translatedText": "Pemikirannya adalah jika Anda menekan sebuah huruf, Anda tahu, Anda mendapatkan warna hijau atau kuning, itu selalu terasa menyenangkan.",
  "time_range": [
   183.76,
   187.52
  ],
  "n_reviews": 0
 },
 {
  "input": "It feels like you're getting information.",
  "model": "nmt",
  "translatedText": "Rasanya seperti Anda mendapatkan informasi.",
  "time_range": [
   187.52,
   188.84
  ],
  "n_reviews": 0
 },
 {
  "input": "But in these cases, even if you don't hit and you always get grays, that's still giving you a lot of information since it's pretty rare to find a word that doesn't have any of these letters.",
  "model": "nmt",
  "translatedText": "Namun dalam kasus ini, bahkan jika Anda tidak memukul dan Anda selalu mendapatkan warna abu-abu, itu tetap memberi Anda banyak informasi karena sangat jarang menemukan kata yang tidak memiliki huruf-huruf ini.",
  "time_range": [
   189.34,
   197.4
  ],
  "n_reviews": 0
 },
 {
  "input": "But even still, that doesn't feel super systematic, because for example, it does nothing to consider the order of the letters.",
  "model": "nmt",
  "translatedText": "Namun tetap saja, hal tersebut tidak terasa super sistematis, karena misalnya, tidak memperhitungkan urutan huruf.",
  "time_range": [
   198.14,
   203.2
  ],
  "n_reviews": 0
 },
 {
  "input": "Why type nails when I could type snail?",
  "model": "nmt",
  "translatedText": "Mengapa mengetik paku ketika saya bisa mengetik siput?",
  "time_range": [
   203.56,
   205.3
  ],
  "n_reviews": 0
 },
 {
  "input": "Is it better to have that S at the end?",
  "model": "nmt",
  "translatedText": "Apakah lebih baik memiliki S di akhir?",
  "time_range": [
   206.08,
   207.5
  ],
  "n_reviews": 0
 },
 {
  "input": "I'm not really sure.",
  "model": "nmt",
  "translatedText": "Saya tidak begitu yakin.",
  "time_range": [
   207.82,
   208.68
  ],
  "n_reviews": 0
 },
 {
  "input": "Now, a friend of mine said that he liked to open with the word weary, which kind of surprised me because it has some uncommon letters in there like the W and the Y.",
  "model": "nmt",
  "translatedText": "Sekarang, seorang teman saya mengatakan bahwa dia suka membuka dengan kata letih, yang membuat saya terkejut karena ada beberapa huruf yang tidak biasa di sana seperti W dan Y.",
  "time_range": [
   209.24,
   216.54
  ],
  "n_reviews": 0
 },
 {
  "input": "But who knows, maybe that is a better opener.",
  "model": "nmt",
  "translatedText": "Tapi siapa tahu, mungkin itu pembuka yang lebih baik.",
  "time_range": [
   217.12,
   219.0
  ],
  "n_reviews": 0
 },
 {
  "input": "Is there some kind of quantitative score that we can give to judge the quality of a potential guess?",
  "model": "nmt",
  "translatedText": "Adakah skor kuantitatif yang bisa kita berikan untuk menilai kualitas tebakan potensial?",
  "time_range": [
   219.32,
   224.32
  ],
  "n_reviews": 0
 },
 {
  "input": "Now to set up for the way that we're going to rank possible guesses, let's go back and add a little clarity to how exactly the game is set up.",
  "model": "nmt",
  "translatedText": "Sekarang untuk mempersiapkan cara kita menentukan peringkat kemungkinan tebakan, mari kita kembali dan menambahkan sedikit kejelasan tentang bagaimana tepatnya permainan ini diatur.",
  "time_range": [
   225.34,
   231.42
  ],
  "n_reviews": 0
 },
 {
  "input": "So there's a list of words that it will allow you to enter that are considered valid guesses that's just about 13,000 words long.",
  "model": "nmt",
  "translatedText": "Jadi ada daftar kata yang dapat Anda masukkan yang dianggap sebagai tebakan valid yang panjangnya hanya sekitar 13.000 kata.",
  "time_range": [
   231.42,
   237.88
  ],
  "n_reviews": 0
 },
 {
  "input": "But when you look at it, there's a lot of really uncommon things, things like a head or Ali and ARG, the kind of words that bring about family arguments in a game of Scrabble.",
  "model": "nmt",
  "translatedText": "Tapi kalau dilihat-lihat, ada banyak hal yang sangat tidak biasa, seperti kepala atau Ali dan ARG, kata-kata yang menimbulkan pertengkaran keluarga dalam permainan Scrabble.",
  "time_range": [
   238.32,
   246.44
  ],
  "n_reviews": 0
 },
 {
  "input": "But the vibe of the game is that the answer is always going to be a decently common word.",
  "model": "nmt",
  "translatedText": "Namun inti dari permainan ini adalah bahwa jawabannya akan selalu berupa kata yang umum.",
  "time_range": [
   246.96,
   250.54
  ],
  "n_reviews": 0
 },
 {
  "input": "And in fact, there's another list of around 2300 words that are the possible answers.",
  "model": "nmt",
  "translatedText": "Dan faktanya, ada daftar lain yang berisi sekitar 2.300 kata yang merupakan kemungkinan jawabannya.",
  "time_range": [
   250.96,
   255.36
  ],
  "n_reviews": 0
 },
 {
  "input": "And this is a human curated list, I think specifically by the game creator's girlfriend, which is kind of fun.",
  "model": "nmt",
  "translatedText": "Dan ini adalah daftar yang dikurasi oleh manusia, menurut saya khususnya oleh pacar pembuat game, dan itu cukup menyenangkan.",
  "time_range": [
   255.94,
   261.16
  ],
  "n_reviews": 0
 },
 {
  "input": "But what I would like to do, our challenge for this project is to see if we can write a program solving Wordle that doesn't incorporate previous knowledge about this list.",
  "model": "nmt",
  "translatedText": "Tapi yang ingin saya lakukan, tantangan kita untuk proyek ini adalah melihat apakah kita bisa menulis program penyelesaian Wordle yang tidak memasukkan pengetahuan sebelumnya tentang daftar ini.",
  "time_range": [
   261.82,
   270.18
  ],
  "n_reviews": 0
 },
 {
  "input": "For one thing, there's plenty of pretty common five letter words that you won't find in that list.",
  "model": "nmt",
  "translatedText": "Untuk satu hal, ada banyak kata lima huruf yang cukup umum yang tidak akan Anda temukan dalam daftar itu.",
  "time_range": [
   270.72,
   274.64
  ],
  "n_reviews": 0
 },
 {
  "input": "So it would be better to write a program that's a little more resilient and would play Wordle against anyone, not just what happens to be the official website.",
  "model": "nmt",
  "translatedText": "Jadi akan lebih baik untuk menulis sebuah program yang sedikit lebih tangguh dan dapat memainkan Wordle melawan siapa pun, bukan hanya apa yang terjadi di situs resminya.",
  "time_range": [
   274.94,
   281.46
  ],
  "n_reviews": 0
 },
 {
  "input": "And also the reason that we know what this list of possible answers is, is because it's visible in the source code.",
  "model": "nmt",
  "translatedText": "Dan juga alasan kita mengetahui daftar kemungkinan jawaban ini, adalah karena daftar tersebut terlihat di kode sumber.",
  "time_range": [
   281.92,
   287.0
  ],
  "n_reviews": 0
 },
 {
  "input": "But the way that it's visible in the source code is in the specific order in which answers come up from day to day.",
  "model": "nmt",
  "translatedText": "Namun tampilannya di kode sumber sesuai dengan urutan jawaban yang muncul dari hari ke hari.",
  "time_range": [
   287.0,
   293.26
  ],
  "n_reviews": 0
 },
 {
  "input": "So you could always just look up what tomorrow's answer will be.",
  "model": "nmt",
  "translatedText": "Jadi, Anda selalu bisa mencari tahu apa jawaban besok.",
  "time_range": [
   293.26,
   295.84
  ],
  "n_reviews": 0
 },
 {
  "input": "So clearly, there's some sense in which using the list is cheating.",
  "model": "nmt",
  "translatedText": "Jelas sekali, ada kesan bahwa menggunakan daftar itu curang.",
  "time_range": [
   296.42,
   298.88
  ],
  "n_reviews": 0
 },
 {
  "input": "And what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data like relative word frequencies in general to capture this intuition of having a preference for more common words.",
  "model": "nmt",
  "translatedText": "Dan apa yang menjadikan teka-teki ini lebih menarik dan pelajaran teori informasi yang lebih kaya adalah dengan menggunakan beberapa data yang lebih universal seperti frekuensi kata relatif secara umum untuk menangkap intuisi mengenai preferensi terhadap kata-kata yang lebih umum.",
  "time_range": [
   299.1,
   310.44
  ],
  "n_reviews": 0
 },
 {
  "input": "So of these 13,000 possibilities, how should we choose the opening guess?",
  "model": "nmt",
  "translatedText": "Jadi dari 13.000 kemungkinan ini, bagaimana sebaiknya kita memilih tebakan pembuka?",
  "time_range": [
   311.6,
   315.9
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if my friend proposes weary, how should we analyze its quality?",
  "model": "nmt",
  "translatedText": "Misalnya, jika teman saya melamar dengan letih, bagaimana kita menganalisis kualitasnya?",
  "time_range": [
   316.4,
   319.78
  ],
  "n_reviews": 0
 },
 {
  "input": "Well, the reason he said he likes that unlikely W is that he likes the long shot nature of just how good it feels if you do hit that W.",
  "model": "nmt",
  "translatedText": "Nah, alasan dia mengatakan dia menyukai W yang tidak mungkin itu adalah karena dia menyukai sifat pukulan jarak jauh tentang betapa nikmatnya rasanya jika Anda berhasil mencapai W itu.",
  "time_range": [
   320.52,
   327.34
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern.",
  "model": "nmt",
  "translatedText": "Misalnya, jika pola pertama yang terungkap kira-kira seperti ini, maka ternyata hanya ada 58 kata dalam leksikon raksasa ini yang cocok dengan pola tersebut.",
  "time_range": [
   327.92,
   335.6
  ],
  "n_reviews": 0
 },
 {
  "input": "So that's a huge reduction from 13,000.",
  "model": "nmt",
  "translatedText": "Jadi itu pengurangan yang sangat besar dari 13.000.",
  "time_range": [
   336.06,
   338.4
  ],
  "n_reviews": 0
 },
 {
  "input": "But the flip side of that, of course, is that it's very uncommon to get a pattern like this.",
  "model": "nmt",
  "translatedText": "Namun sisi sebaliknya tentu saja sangat jarang mendapatkan pola seperti ini.",
  "time_range": [
   338.78,
   343.02
  ],
  "n_reviews": 0
 },
 {
  "input": "Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000.",
  "model": "nmt",
  "translatedText": "Secara khusus, jika setiap kata mempunyai kemungkinan yang sama untuk menjadi jawabannya, kemungkinan untuk mendapatkan pola ini adalah 58 dibagi sekitar 13.000.",
  "time_range": [
   343.02,
   351.04
  ],
  "n_reviews": 0
 },
 {
  "input": "Of course, they're not equally likely to be answers.",
  "model": "nmt",
  "translatedText": "Tentu saja, kemungkinan jawaban tersebut tidak sama.",
  "time_range": [
   351.58,
   353.6
  ],
  "n_reviews": 0
 },
 {
  "input": "Most of these are very obscure and even questionable words.",
  "model": "nmt",
  "translatedText": "Kebanyakan dari kata-kata ini sangat tidak jelas dan bahkan dipertanyakan.",
  "time_range": [
   353.72,
   356.22
  ],
  "n_reviews": 0
 },
 {
  "input": "But at least for our first pass at all of this, let's assume that they're all equally likely and then refine that a bit later.",
  "model": "nmt",
  "translatedText": "Tapi setidaknya untuk langkah pertama kita dalam semua hal ini, mari kita asumsikan bahwa semuanya memiliki kemungkinan yang sama dan kemudian menyempurnakannya nanti.",
  "time_range": [
   356.6,
   361.6
  ],
  "n_reviews": 0
 },
 {
  "input": "The point is the pattern with a lot of information is by its very nature unlikely to occur.",
  "model": "nmt",
  "translatedText": "Intinya adalah pola dengan banyak informasi pada dasarnya tidak mungkin terjadi.",
  "time_range": [
   362.02,
   366.72
  ],
  "n_reviews": 0
 },
 {
  "input": "In fact, what it means to be informative is that it's unlikely.",
  "model": "nmt",
  "translatedText": "Faktanya, yang dimaksud dengan informatif adalah bahwa hal itu tidak mungkin.",
  "time_range": [
   367.28,
   370.8
  ],
  "n_reviews": 0
 },
 {
  "input": "A much more probable pattern to see with this opening would be something like this, where of course there's not a W in it.",
  "model": "nmt",
  "translatedText": "Pola yang lebih mungkin terlihat pada pembukaan ini adalah seperti ini, yang tentu saja tidak ada huruf W di dalamnya.",
  "time_range": [
   371.71999999999997,
   378.12
  ],
  "n_reviews": 0
 },
 {
  "input": "Maybe there's an E, and maybe there's no A, there's no R, there's no Y.",
  "model": "nmt",
  "translatedText": "Mungkin ada E, dan mungkin tidak ada A, tidak ada R, tidak ada Y.",
  "time_range": [
   378.24,
   381.4
  ],
  "n_reviews": 0
 },
 {
  "input": "In this case, there are 1400 possible matches.",
  "model": "nmt",
  "translatedText": "Dalam hal ini, ada 1400 kemungkinan kecocokan.",
  "time_range": [
   382.08,
   384.56
  ],
  "n_reviews": 0
 },
 {
  "input": "If all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see.",
  "model": "nmt",
  "translatedText": "Jika semua memiliki kemungkinan yang sama, maka kemungkinannya sekitar 11% bahwa ini adalah pola yang akan Anda lihat.",
  "time_range": [
   385.08,
   390.6
  ],
  "n_reviews": 0
 },
 {
  "input": "So the most likely outcomes are also the least informative.",
  "model": "nmt",
  "translatedText": "Jadi hasil yang paling mungkin juga paling tidak informatif.",
  "time_range": [
   390.9,
   393.34
  ],
  "n_reviews": 0
 },
 {
  "input": "To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see.",
  "model": "nmt",
  "translatedText": "Untuk mendapatkan gambaran yang lebih global di sini, izinkan saya menunjukkan kepada Anda distribusi penuh probabilitas di semua pola berbeda yang mungkin Anda lihat.",
  "time_range": [
   394.24,
   401.14
  ],
  "n_reviews": 0
 },
 {
  "input": "So each bar that you're looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3 to the 5th possibilities, and they're organized from left to right, most common to least common.",
  "model": "nmt",
  "translatedText": "Jadi tiap batang yang Anda lihat sesuai dengan kemungkinan pola warna yang dapat ditampilkan, yang mana terdapat 3 hingga 5 kemungkinan, dan disusun dari kiri ke kanan, yang paling umum hingga yang paling tidak umum.",
  "time_range": [
   401.74,
   412.34
  ],
  "n_reviews": 0
 },
 {
  "input": "So the most common possibility here is that you get all grays.",
  "model": "nmt",
  "translatedText": "Jadi kemungkinan paling umum di sini adalah Anda mendapatkan warna abu-abu.",
  "time_range": [
   412.92,
   416.0
  ],
  "n_reviews": 0
 },
 {
  "input": "That happens about 14% of the time.",
  "model": "nmt",
  "translatedText": "Itu terjadi sekitar 14% dari seluruh kasus.",
  "time_range": [
   416.1,
   418.12
  ],
  "n_reviews": 0
 },
 {
  "input": "And what you're hoping for when you make a guess is that you end up somewhere out in this long tail, like over here where there's only 18 possibilities for what matches this pattern that evidently look like this.",
  "model": "nmt",
  "translatedText": "Dan yang Anda harapkan saat menebak adalah Anda berakhir di suatu tempat di ekor panjang ini, seperti di sini di mana hanya ada 18 kemungkinan yang cocok dengan pola yang ternyata terlihat seperti ini.",
  "time_range": [
   418.58,
   429.14
  ],
  "n_reviews": 0
 },
 {
  "input": "Or if we venture a little farther to the left, you know, maybe we go all the way over here.",
  "model": "nmt",
  "translatedText": "Atau jika kita melangkah lebih jauh ke kiri, mungkin kita akan terus ke sini.",
  "time_range": [
   429.92,
   433.8
  ],
  "n_reviews": 0
 },
 {
  "input": "Okay, here's a good puzzle for you.",
  "model": "nmt",
  "translatedText": "Oke, ini teka-teki yang bagus untuk Anda.",
  "time_range": [
   434.94,
   436.18
  ],
  "n_reviews": 0
 },
 {
  "input": "What are the three words in the English language that start with a W, end with a Y, and have an R somewhere in them?",
  "model": "nmt",
  "translatedText": "Apa tiga kata dalam bahasa Inggris yang dimulai dengan huruf W, diakhiri dengan huruf Y, dan memiliki huruf R di suatu tempat di dalamnya?",
  "time_range": [
   436.54,
   442.0
  ],
  "n_reviews": 0
 },
 {
  "input": "Turns out, the answers are, let's see, wordy, wormy, and wryly.",
  "model": "nmt",
  "translatedText": "Ternyata jawabannya adalah, mari kita lihat, bertele-tele, cacingan, dan masam.",
  "time_range": [
   442.48,
   446.8
  ],
  "n_reviews": 0
 },
 {
  "input": "So to judge how good this word is overall, we want some kind of measure of the expected amount of information that you're going to get from this distribution.",
  "model": "nmt",
  "translatedText": "Jadi untuk menilai seberapa bagus kata ini secara keseluruhan, kami ingin mengukur perkiraan jumlah informasi yang akan Anda peroleh dari distribusi ini.",
  "time_range": [
   447.5,
   455.74
  ],
  "n_reviews": 0
 },
 {
  "input": "If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score.",
  "model": "nmt",
  "translatedText": "Jika kita menelusuri setiap pola dan mengalikan kemungkinan terjadinya dengan sesuatu yang mengukur seberapa informatif pola tersebut, hal itu mungkin dapat memberi kita skor objektif.",
  "time_range": [
   455.74,
   464.72
  ],
  "n_reviews": 0
 },
 {
  "input": "Now your first instinct for what that something should be might be the number of matches.",
  "model": "nmt",
  "translatedText": "Sekarang insting pertama Anda tentang apa yang seharusnya terjadi mungkin adalah jumlah pertandingan.",
  "time_range": [
   465.96,
   469.84
  ],
  "n_reviews": 0
 },
 {
  "input": "You want a lower average number of matches.",
  "model": "nmt",
  "translatedText": "Anda menginginkan jumlah rata-rata kecocokan yang lebih rendah.",
  "time_range": [
   470.16,
   472.4
  ],
  "n_reviews": 0
 },
 {
  "input": "But instead I'd like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they're actually the answer.",
  "model": "nmt",
  "translatedText": "Namun saya ingin menggunakan pengukuran yang lebih universal yang sering kita anggap berasal dari informasi, dan pengukuran yang akan lebih fleksibel setelah kita menetapkan probabilitas berbeda untuk masing-masing dari 13.000 kata tersebut untuk mengetahui apakah kata-kata tersebut benar-benar jawabannya atau tidak.",
  "time_range": [
   472.8,
   484.26
  ],
  "n_reviews": 0
 },
 {
  "input": "The standard unit of information is the bit, which has a little bit of a funny formula, but it's really intuitive if we just look at examples.",
  "model": "nmt",
  "translatedText": "Satuan standar informasi adalah bit, yang memiliki rumus yang sedikit lucu, namun sangat intuitif jika kita hanya melihat contohnya.",
  "time_range": [
   490.32,
   496.98
  ],
  "n_reviews": 0
 },
 {
  "input": "If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information.",
  "model": "nmt",
  "translatedText": "Jika Anda mempunyai pengamatan yang membagi dua kemungkinan yang ada, kami katakan bahwa pengamatan tersebut mempunyai sedikit informasi.",
  "time_range": [
   497.78,
   503.5
  ],
  "n_reviews": 0
 },
 {
  "input": "In our example, the space of possibilities is all possible words, and it turns out about Half of the five letter words have an S, a little less than that, but about half.",
  "model": "nmt",
  "translatedText": "Dalam contoh kita, ruang kemungkinannya adalah semua kemungkinan kata, dan ternyata sekitar setengah dari lima huruf kata mempunyai huruf S, sedikit lebih kecil dari itu, tapi sekitar setengahnya.",
  "time_range": [
   504.18,
   511.26
  ],
  "n_reviews": 0
 },
 {
  "input": "So that observation would give you one bit of information.",
  "model": "nmt",
  "translatedText": "Sehingga pengamatan itu akan memberi Anda sedikit informasi.",
  "time_range": [
   511.78,
   514.32
  ],
  "n_reviews": 0
 },
 {
  "input": "If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information.",
  "model": "nmt",
  "translatedText": "Jika suatu fakta baru memperkecil ruang kemungkinan tersebut sebanyak empat kali lipat, kita katakan bahwa fakta tersebut mempunyai dua informasi.",
  "time_range": [
   514.88,
   521.5
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, it turns out about a quarter of these words have a T.",
  "model": "nmt",
  "translatedText": "Misalnya, ternyata sekitar seperempat dari kata-kata ini memiliki huruf T.",
  "time_range": [
   521.98,
   524.46
  ],
  "n_reviews": 0
 },
 {
  "input": "If the observation cuts that space by a factor of eight, we say it's three bits of information, and so on and so forth.",
  "model": "nmt",
  "translatedText": "Jika observasi memotong ruang tersebut sebanyak delapan kali lipat, kita katakan itu adalah tiga bit informasi, dan seterusnya dan seterusnya.",
  "time_range": [
   525.02,
   530.72
  ],
  "n_reviews": 0
 },
 {
  "input": "Four bits cuts it into a 16th, five bits cuts it into a 32nd.",
  "model": "nmt",
  "translatedText": "Empat bit memotongnya menjadi 16, lima bit memotongnya menjadi 32.",
  "time_range": [
   530.9,
   535.06
  ],
  "n_reviews": 0
 },
 {
  "input": "So now you might want to pause and ask yourself, what is the formula for information for the number of bits in terms of the probability of an occurrence?",
  "model": "nmt",
  "translatedText": "Jadi sekarang Anda mungkin ingin berhenti sejenak dan bertanya pada diri sendiri, apa rumus informasi jumlah bit dalam kaitannya dengan probabilitas suatu kejadian?",
  "time_range": [
   535.06,
   542.66
  ],
  "n_reviews": 0
 },
 {
  "input": "What we're saying here is that when you take one half to the number of bits, that's the same thing as the probability, which is the same thing as saying two to the power of the number of bits is one over the probability, which rearranges further to saying the information is the log base two of one divided by the probability.",
  "model": "nmt",
  "translatedText": "Apa yang ingin kami katakan di sini adalah ketika Anda mengambil setengah dari jumlah bit, itu sama dengan probabilitas, yang sama dengan mengatakan dua pangkat dari jumlah bit adalah satu di atas probabilitas, yaitu menyusun ulang lebih jauh dengan mengatakan bahwa informasi tersebut adalah basis log dua dari satu dibagi dengan probabilitas.",
  "time_range": [
   542.66,
   558.92
  ],
  "n_reviews": 0
 },
 {
  "input": "And sometimes you see this with one more rearrangement still, where the information is the negative log base two of the probability.",
  "model": "nmt",
  "translatedText": "Dan kadang-kadang Anda melihat ini dengan satu penataan ulang lagi, di mana informasinya adalah log negatif basis dua dari probabilitas.",
  "time_range": [
   559.62,
   564.9
  ],
  "n_reviews": 0
 },
 {
  "input": "Expressed like this, it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you've cut down your possibilities in half.",
  "model": "nmt",
  "translatedText": "Jika diungkapkan seperti ini, hal ini mungkin terlihat sedikit aneh bagi yang belum tahu, namun sebenarnya ini hanyalah gagasan intuitif untuk menanyakan berapa kali Anda telah mengurangi separuh kemungkinan Anda.",
  "time_range": [
   565.66,
   574.08
  ],
  "n_reviews": 0
 },
 {
  "input": "Now if you're wondering, you know, I thought we were just playing a fun word game, why are logarithms entering the picture?",
  "model": "nmt",
  "translatedText": "Sekarang jika Anda bertanya-tanya, Anda tahu, saya pikir kita hanya memainkan permainan kata yang menyenangkan, mengapa logaritma masuk ke dalam gambar?",
  "time_range": [
   575.18,
   579.3
  ],
  "n_reviews": 0
 },
 {
  "input": "One reason this is a nicer unit is it's just a lot easier to talk about very unlikely events, much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.0000095.",
  "model": "nmt",
  "translatedText": "Salah satu alasan unit ini lebih bagus adalah karena lebih mudah untuk membicarakan peristiwa yang sangat tidak mungkin terjadi, lebih mudah untuk mengatakan bahwa suatu pengamatan mempunyai 20 bit informasi daripada mengatakan bahwa probabilitas kejadian ini dan itu adalah 0.0000095.",
  "time_range": [
   579.78,
   592.94
  ],
  "n_reviews": 0
 },
 {
  "input": "But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that information adds together.",
  "model": "nmt",
  "translatedText": "Namun alasan yang lebih substantif mengapa ekspresi logaritmik ini ternyata menjadi tambahan yang sangat berguna bagi teori probabilitas adalah cara informasi tersebut dijumlahkan.",
  "time_range": [
   593.3,
   601.46
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if one observation gives you two bits of information, cutting your space down by four, and then a second observation like your second guess in Wordle gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information.",
  "model": "nmt",
  "translatedText": "Misalnya, jika satu observasi memberi Anda dua bit informasi, mengurangi ruang Anda menjadi empat, dan kemudian observasi kedua seperti tebakan kedua Anda di Wordle memberi Anda tiga bit informasi lagi, mengurangi Anda lebih jauh lagi sebanyak delapan kali lipat, maka dua bersama-sama memberi Anda lima informasi.",
  "time_range": [
   602.06,
   616.74
  ],
  "n_reviews": 0
 },
 {
  "input": "In the same way that probabilities like to multiply, information likes to add.",
  "model": "nmt",
  "translatedText": "Sama seperti probabilitas yang berlipat ganda, informasi juga suka bertambah.",
  "time_range": [
   617.16,
   621.02
  ],
  "n_reviews": 0
 },
 {
  "input": "So as soon as we're in the realm of something like an expected value, where we're adding a bunch of numbers up, the logs make it a lot nicer to deal with.",
  "model": "nmt",
  "translatedText": "Jadi segera setelah kita berada di bidang nilai yang diharapkan, di mana kita menambahkan banyak angka, log akan membuatnya lebih mudah untuk ditangani.",
  "time_range": [
   621.96,
   627.98
  ],
  "n_reviews": 0
 },
 {
  "input": "Let's go back to our distribution for Weary and add another little tracker on here, showing us how much information there is for each pattern.",
  "model": "nmt",
  "translatedText": "Mari kita kembali ke distribusi Weary dan menambahkan pelacak kecil lainnya di sini, menunjukkan kepada kita berapa banyak informasi yang ada untuk setiap pola.",
  "time_range": [
   628.48,
   634.94
  ],
  "n_reviews": 0
 },
 {
  "input": "The main thing I want you to notice is that the higher the probability as we get to those more likely patterns, the lower the information, the fewer bits you gain.",
  "model": "nmt",
  "translatedText": "Hal utama yang saya ingin Anda perhatikan adalah semakin tinggi kemungkinan kita mendapatkan pola yang lebih mungkin, semakin rendah informasinya, semakin sedikit bit yang Anda peroleh.",
  "time_range": [
   635.58,
   642.78
  ],
  "n_reviews": 0
 },
 {
  "input": "The way we measure the quality of this guess will be to take the expected value of this information, where we go through each pattern, we say how probable is it, and then we multiply that by how many bits of information do we get.",
  "model": "nmt",
  "translatedText": "Cara kita mengukur kualitas tebakan ini adalah dengan mengambil nilai yang diharapkan dari informasi tersebut, dengan menelusuri setiap pola, kita tentukan seberapa besar kemungkinannya, lalu kita kalikan dengan berapa banyak informasi yang kita peroleh.",
  "time_range": [
   643.5,
   654.06
  ],
  "n_reviews": 0
 },
 {
  "input": "And in the example of Weary, that turns out to be 4.9 bits.",
  "model": "nmt",
  "translatedText": "Dan dalam contoh Weary, ternyata menjadi 4.9 bit.",
  "time_range": [
   654.71,
   658.12
  ],
  "n_reviews": 0
 },
 {
  "input": "So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times.",
  "model": "nmt",
  "translatedText": "Jadi rata-rata, informasi yang Anda dapatkan dari tebakan pembuka ini sama baiknya dengan memotong ruang kemungkinan Anda menjadi setengahnya sekitar lima kali lipat.",
  "time_range": [
   658.56,
   665.48
  ],
  "n_reviews": 0
 },
 {
  "input": "By contrast, an example of a guess with a higher expected information value would be something like Slate.",
  "model": "nmt",
  "translatedText": "Sebaliknya, contoh tebakan dengan nilai informasi yang diharapkan lebih tinggi adalah seperti Slate.",
  "time_range": [
   665.96,
   671.64
  ],
  "n_reviews": 0
 },
 {
  "input": "In this case you'll notice the distribution looks a lot flatter.",
  "model": "nmt",
  "translatedText": "Dalam hal ini Anda akan melihat distribusinya terlihat lebih datar.",
  "time_range": [
   673.12,
   675.62
  ],
  "n_reviews": 0
 },
 {
  "input": "In particular, the most probable occurrence of all grays only has about a 6% chance of occurring, so at minimum you're getting evidently 3.9 bits of information.",
  "model": "nmt",
  "translatedText": "Secara khusus, kemunculan semua warna abu-abu yang paling mungkin hanya memiliki peluang sekitar 6% untuk muncul, jadi setidaknya Anda mendapatkan 3.9 bit informasi.",
  "time_range": [
   675.94,
   685.26
  ],
  "n_reviews": 0
 },
 {
  "input": "But that's a minimum, more typically you'd get something better than that.",
  "model": "nmt",
  "translatedText": "Tapi itu jumlah minimum, biasanya Anda akan mendapatkan sesuatu yang lebih baik dari itu.",
  "time_range": [
   685.92,
   688.56
  ],
  "n_reviews": 0
 },
 {
  "input": "And it turns out when you crunch the numbers on this one and add up all the relevant terms, the average information is about 5.8.",
  "model": "nmt",
  "translatedText": "Dan ternyata ketika Anda menghitung angka-angka ini dan menjumlahkan semua istilah yang relevan, rata-rata informasinya adalah sekitar 5.8.",
  "time_range": [
   689.1,
   695.9
  ],
  "n_reviews": 0
 },
 {
  "input": "So in contrast with Weary, your space of possibilities will be about half as big after this first guess, on average.",
  "model": "nmt",
  "translatedText": "Jadi berbeda dengan Weary, rata-rata ruang kemungkinan Anda akan menjadi sekitar setengahnya setelah tebakan pertama ini.",
  "time_range": [
   697.36,
   703.54
  ],
  "n_reviews": 0
 },
 {
  "input": "There's actually a fun story about the name for this expected value of information quantity.",
  "model": "nmt",
  "translatedText": "Sebenarnya ada cerita menarik tentang nama nilai kuantitas informasi yang diharapkan ini.",
  "time_range": [
   704.42,
   709.12
  ],
  "n_reviews": 0
 },
 {
  "input": "Information theory was developed by Claude Shannon, who was working at Bell Labs in the 1940s, but he was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, very prominent in math and physics and the beginnings of what was becoming computer science.",
  "model": "nmt",
  "translatedText": "Teori informasi dikembangkan oleh Claude Shannon, yang bekerja di Bell Labs pada tahun 1940-an, tetapi dia membicarakan beberapa idenya yang belum dipublikasikan dengan John von Neumann, yang merupakan raksasa intelektual pada saat itu, sangat terkemuka. dalam matematika dan fisika dan permulaan dari apa yang kemudian menjadi ilmu komputer.",
  "time_range": [
   709.2,
   723.56
  ],
  "n_reviews": 0
 },
 {
  "input": "And when he mentioned that he didn't really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, well you should call it entropy, and for two reasons.",
  "model": "nmt",
  "translatedText": "Dan ketika dia menyebutkan bahwa dia tidak benar-benar memiliki nama yang bagus untuk nilai yang diharapkan dari kuantitas informasi ini, von Neumann berkata, jadi ceritanya, Anda harus menyebutnya entropi, dan karena dua alasan.",
  "time_range": [
   724.1,
   734.2
  ],
  "n_reviews": 0
 },
 {
  "input": "In the first place, your uncertainty function has been used in statistical mechanics under that name, so it already has a name, and in the second place, and more important, nobody knows what entropy really is, so in a debate you'll always have the advantage.",
  "model": "nmt",
  "translatedText": "Pertama, fungsi ketidakpastian Anda telah digunakan dalam mekanika statistik dengan nama tersebut, sehingga sudah memiliki nama, dan kedua, dan yang lebih penting, tidak ada yang tahu apa sebenarnya entropi, jadi dalam perdebatan Anda akan selalu memiliki keuntungan.",
  "time_range": [
   734.54,
   746.76
  ],
  "n_reviews": 0
 },
 {
  "input": "So if the name seems a little bit mysterious, and if this story is to be believed, that's kind of by design.",
  "model": "nmt",
  "translatedText": "Jadi jika namanya tampak sedikit misterius, dan jika cerita ini dapat dipercaya, itu memang disengaja.",
  "time_range": [
   747.7,
   752.46
  ],
  "n_reviews": 0
 },
 {
  "input": "Also if you're wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory, and for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess.",
  "model": "nmt",
  "translatedText": "Juga jika Anda bertanya-tanya tentang hubungannya dengan semua hukum kedua termodinamika dari fisika, pasti ada hubungannya, tetapi pada awalnya Shannon hanya berurusan dengan teori probabilitas murni, dan untuk tujuan kita di sini, ketika saya menggunakan teori kata entropi, saya hanya ingin Anda memikirkan nilai informasi yang diharapkan dari tebakan tertentu.",
  "time_range": [
   753.28,
   769.58
  ],
  "n_reviews": 0
 },
 {
  "input": "You can think of entropy as measuring two things simultaneously.",
  "model": "nmt",
  "translatedText": "Anda dapat menganggap entropi sebagai mengukur dua hal secara bersamaan.",
  "time_range": [
   770.7,
   773.78
  ],
  "n_reviews": 0
 },
 {
  "input": "The first one is how flat is the distribution.",
  "model": "nmt",
  "translatedText": "Yang pertama adalah seberapa datar distribusinya.",
  "time_range": [
   774.24,
   776.78
  ],
  "n_reviews": 0
 },
 {
  "input": "The closer a distribution is to uniform, the higher that entropy will be.",
  "model": "nmt",
  "translatedText": "Semakin dekat suatu distribusi ke seragam, semakin tinggi entropinya.",
  "time_range": [
   777.32,
   781.12
  ],
  "n_reviews": 0
 },
 {
  "input": "In our case, where there are 3 to the 5th total patterns, for a uniform distribution, observing any one of them would have information log base 2 of 3 to the 5th, which happens to be 7.92, so that is the absolute maximum that you could possibly have for this entropy.",
  "model": "nmt",
  "translatedText": "Dalam kasus kita, jika terdapat 3 hingga 5 pola total, untuk distribusi seragam, mengamati salah satu dari pola tersebut akan memiliki basis log informasi 2 dari 3 hingga 5, yang kebetulan berjumlah 7.92, jadi itulah nilai maksimum mutlak yang mungkin Anda miliki untuk entropi ini.",
  "time_range": [
   781.58,
   797.3
  ],
  "n_reviews": 0
 },
 {
  "input": "But entropy is also kind of a measure of how many possibilities there are in the first place.",
  "model": "nmt",
  "translatedText": "Namun entropi juga merupakan ukuran seberapa banyak kemungkinan yang ada.",
  "time_range": [
   797.84,
   802.08
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if you happen to have some word where there's only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be 4 bits.",
  "model": "nmt",
  "translatedText": "Misalnya, jika Anda memiliki suatu kata yang hanya memiliki 16 kemungkinan pola, dan setiap pola memiliki kemungkinan yang sama, entropi ini, informasi yang diharapkan, akan berjumlah 4 bit.",
  "time_range": [
   802.32,
   812.18
  ],
  "n_reviews": 0
 },
 {
  "input": "But if you have another word where there's 64 possible patterns that could come up, and they're all equally likely, then the entropy would work out to be 6 bits.",
  "model": "nmt",
  "translatedText": "Namun jika Anda memiliki kata lain yang memiliki 64 kemungkinan pola yang muncul, dan semuanya memiliki kemungkinan yang sama, maka entropinya akan menjadi 6 bit.",
  "time_range": [
   812.5799999999999,
   820.48
  ],
  "n_reviews": 0
 },
 {
  "input": "So if you see some distribution out in the wild that has an entropy of 6 bits, it's sort of like it's saying there's as much variation and uncertainty in what's about to happen as if there were 64 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "Jadi, jika Anda melihat suatu distribusi di alam liar yang memiliki entropi 6 bit, hal ini seperti menyatakan bahwa ada banyak variasi dan ketidakpastian dalam apa yang akan terjadi, seolah-olah ada 64 kemungkinan hasil yang sama besarnya.",
  "time_range": [
   821.5,
   833.5
  ],
  "n_reviews": 0
 },
 {
  "input": "For my first pass at the Wurtelebot, I basically had it just do this.",
  "model": "nmt",
  "translatedText": "Untuk pass pertama saya di Wurtelebot, pada dasarnya saya menyuruhnya melakukan ini saja.",
  "time_range": [
   834.36,
   839.32
  ],
  "n_reviews": 0
 },
 {
  "input": "It goes through all of the possible guesses you could have, all 13,000 words, computes the entropy for each one, or more specifically, the entropy of the distribution across all patterns you might see, for each one, and picks the highest, since that's the one that's likely to chop down your space of possibilities as much as possible.",
  "model": "nmt",
  "translatedText": "Ia menelusuri semua kemungkinan tebakan yang Anda miliki, seluruh 13.000 kata, menghitung entropi untuk masing-masing kata, atau lebih khusus lagi, entropi distribusi di semua pola yang mungkin Anda lihat, untuk masing-masing kata, dan memilih yang tertinggi, karena itulah salah satu yang kemungkinan akan mengurangi ruang kemungkinan Anda sebanyak mungkin.",
  "time_range": [
   839.32,
   856.14
  ],
  "n_reviews": 0
 },
 {
  "input": "And even though I've only been talking about the first guess here, it does the same thing for the next few guesses.",
  "model": "nmt",
  "translatedText": "Dan meskipun saya hanya membicarakan tebakan pertama di sini, hal yang sama berlaku untuk beberapa tebakan berikutnya.",
  "time_range": [
   857.14,
   861.1
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words.",
  "model": "nmt",
  "translatedText": "Misalnya, setelah Anda melihat beberapa pola pada tebakan pertama tersebut, yang akan membatasi Anda pada kemungkinan kata yang lebih sedikit berdasarkan kecocokannya, Anda cukup memainkan permainan yang sama terhadap kumpulan kata yang lebih kecil tersebut.",
  "time_range": [
   861.56,
   871.8
  ],
  "n_reviews": 0
 },
 {
  "input": "For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words, you search through all 13,000 possibilities, and you find the one that maximizes that entropy.",
  "model": "nmt",
  "translatedText": "Untuk usulan tebakan kedua, Anda melihat distribusi semua pola yang dapat terjadi dari kumpulan kata yang lebih terbatas tersebut, Anda menelusuri 13.000 kemungkinan, dan Anda menemukan salah satu yang memaksimalkan entropi tersebut.",
  "time_range": [
   872.26,
   883.84
  ],
  "n_reviews": 0
 },
 {
  "input": "To show you how this works in action, let me just pull up a little variant of Wurtele that I wrote that shows the highlights of this analysis in the margins.",
  "model": "nmt",
  "translatedText": "Untuk menunjukkan kepada Anda cara kerjanya, izinkan saya menampilkan sedikit varian Wurtele yang saya tulis yang menunjukkan hal-hal penting dari analisis ini di bagian pinggirnya.",
  "time_range": [
   885.42,
   894.08
  ],
  "n_reviews": 0
 },
 {
  "input": "After doing all its entropy calculations, on the right here it's showing us which ones have the highest expected information.",
  "model": "nmt",
  "translatedText": "Setelah melakukan semua perhitungan entropinya, di sini ia menunjukkan kepada kita mana yang memiliki informasi yang diharapkan tertinggi.",
  "time_range": [
   894.08,
   899.66
  ],
  "n_reviews": 0
 },
 {
  "input": "Turns out the top answer, at least at the moment, we'll refine this later, is Tares, which means, um, of course, a vetch, the most common vetch.",
  "model": "nmt",
  "translatedText": "Ternyata jawaban teratas, setidaknya untuk saat ini, akan kita perbaiki nanti, adalah Taras, yang artinya, um, tentu saja, vetch, vetch yang paling umum.",
  "time_range": [
   900.28,
   910.58
  ],
  "n_reviews": 0
 },
 {
  "input": "Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had, but then on the right of the word here it's showing us how much actual information we got, given this particular pattern.",
  "model": "nmt",
  "translatedText": "Tiap kali kita membuat tebakan di sini, mungkin saya mengabaikan rekomendasinya dan memilih slate, karena saya suka slate, kita bisa melihat berapa banyak informasi yang diharapkan darinya, tapi kemudian di sebelah kanan kata ini, ia menunjukkan kepada kita seberapa banyak informasi yang diharapkan. informasi aktual yang kami peroleh, mengingat pola khusus ini.",
  "time_range": [
   911.04,
   924.42
  ],
  "n_reviews": 0
 },
 {
  "input": "So here it looks like we were a little unlucky, we were expected to get 5.8, but we happened to get something with less than that.",
  "model": "nmt",
  "translatedText": "Jadi di sini sepertinya kami sedikit kurang beruntung, kami diharapkan mendapat nilai 5.8, tapi kebetulan kami mendapatkan sesuatu yang kurang dari itu.",
  "time_range": [
   925.0,
   930.12
  ],
  "n_reviews": 0
 },
 {
  "input": "And then on the left side here it's showing us all of the different possible words given where we are now.",
  "model": "nmt",
  "translatedText": "Dan kemudian di sisi kiri ini menunjukkan kepada kita semua kemungkinan kata yang berbeda berdasarkan posisi kita sekarang.",
  "time_range": [
   930.6,
   935.02
  ],
  "n_reviews": 0
 },
 {
  "input": "The blue bars are telling us how likely it thinks each word is, so at the moment it's assuming each word is equally likely to occur, but we'll refine that in a moment.",
  "model": "nmt",
  "translatedText": "Bilah biru memberi tahu kita seberapa besar kemungkinannya untuk memikirkan setiap kata, sehingga saat ini diasumsikan bahwa setiap kata memiliki kemungkinan yang sama untuk muncul, namun kami akan menyempurnakannya sebentar lagi.",
  "time_range": [
   935.8,
   943.36
  ],
  "n_reviews": 0
 },
 {
  "input": "And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it's a uniform distribution, is just a needlessly complicated way to count the number of possibilities.",
  "model": "nmt",
  "translatedText": "Dan kemudian pengukuran ketidakpastian ini memberi tahu kita entropi dari distribusi ini di seluruh kemungkinan kata, yang saat ini, karena distribusinya seragam, hanyalah cara rumit yang tidak perlu untuk menghitung jumlah kemungkinan.",
  "time_range": [
   944.06,
   955.96
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if we were to take 2 to the power of 13.66, that should be around the 13,000 possibilities.",
  "model": "nmt",
  "translatedText": "Misalnya, jika kita ingin 2 dipangkatkan 13.66, itu seharusnya sekitar 13.000 kemungkinan.",
  "time_range": [
   956.56,
   962.18
  ],
  "n_reviews": 0
 },
 {
  "input": "I'm a little bit off here, but only because I'm not showing all the decimal places.",
  "model": "nmt",
  "translatedText": "Saya sedikit melenceng di sini, tetapi hanya karena saya tidak menampilkan semua tempat desimal.",
  "time_range": [
   962.9,
   966.14
  ],
  "n_reviews": 0
 },
 {
  "input": "At the moment that might feel redundant and like it's overly complicating things, but you'll see why it's useful to have both numbers in a minute.",
  "model": "nmt",
  "translatedText": "Saat ini hal itu mungkin terasa berlebihan dan sepertinya terlalu rumit, tetapi Anda akan mengerti mengapa ada gunanya memiliki kedua angka dalam satu menit.",
  "time_range": [
   966.72,
   972.34
  ],
  "n_reviews": 0
 },
 {
  "input": "So here it looks like it's suggesting the highest entropy for our second guess is Ramen, which again just really doesn't feel like a word.",
  "model": "nmt",
  "translatedText": "Jadi di sini sepertinya entropi tertinggi untuk tebakan kedua kita adalah Ramen, yang sekali lagi tidak terasa seperti sebuah kata.",
  "time_range": [
   972.76,
   979.4
  ],
  "n_reviews": 0
 },
 {
  "input": "So to take the moral high ground here, I'm going to go ahead and type in Rains.",
  "model": "nmt",
  "translatedText": "Jadi untuk mengambil landasan moral yang tinggi di sini, saya akan melanjutkan dan mengetik Rains.",
  "time_range": [
   979.98,
   984.06
  ],
  "n_reviews": 0
 },
 {
  "input": "And again it looks like we were a little unlucky.",
  "model": "nmt",
  "translatedText": "Dan sekali lagi sepertinya kami sedikit kurang beruntung.",
  "time_range": [
   985.44,
   987.34
  ],
  "n_reviews": 0
 },
 {
  "input": "We were expecting 4.3 bits and we only got 3.39 bits of information.",
  "model": "nmt",
  "translatedText": "Kami mengharapkan 4.3 bit dan kami hanya mendapat 3.39 bit informasi.",
  "time_range": [
   987.52,
   991.36
  ],
  "n_reviews": 0
 },
 {
  "input": "So that takes us down to 55 possibilities.",
  "model": "nmt",
  "translatedText": "Jadi itu membawa kita ke 55 kemungkinan.",
  "time_range": [
   991.94,
   993.94
  ],
  "n_reviews": 0
 },
 {
  "input": "And here maybe I'll just actually go with what it's suggesting, which is combo, whatever that means.",
  "model": "nmt",
  "translatedText": "Dan di sini mungkin saya akan mengikuti apa yang disarankannya, yaitu kombo, apa pun artinya.",
  "time_range": [
   994.9,
   999.44
  ],
  "n_reviews": 0
 },
 {
  "input": "And okay, this is actually a good chance for a puzzle.",
  "model": "nmt",
  "translatedText": "Dan oke, ini sebenarnya kesempatan bagus untuk membuat teka-teki.",
  "time_range": [
   1000.04,
   1002.92
  ],
  "n_reviews": 0
 },
 {
  "input": "It's telling us this pattern gives us 4.7 bits of information.",
  "model": "nmt",
  "translatedText": "Ini memberi tahu kita bahwa pola ini memberi kita 4.7 bit informasi.",
  "time_range": [
   1002.92,
   1006.38
  ],
  "n_reviews": 0
 },
 {
  "input": "But over on the left, before we see that pattern, there were 5.78 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "Tapi di sebelah kiri, sebelum kita melihat pola itu, ada 5.78 bit ketidakpastian.",
  "time_range": [
   1007.06,
   1011.72
  ],
  "n_reviews": 0
 },
 {
  "input": "So as a quiz for you, what does that mean about the number of remaining possibilities?",
  "model": "nmt",
  "translatedText": "Jadi sebagai kuis untuk Anda, apa maksudnya dengan jumlah kemungkinan yang tersisa?",
  "time_range": [
   1012.42,
   1016.34
  ],
  "n_reviews": 0
 },
 {
  "input": "Well, it means that we're reduced down to one bit of uncertainty, which is the same thing as saying that there's two possible answers.",
  "model": "nmt",
  "translatedText": "Artinya, kita hanya dihadapkan pada sedikit ketidakpastian, yang sama saja dengan mengatakan bahwa ada dua kemungkinan jawaban.",
  "time_range": [
   1018.04,
   1024.54
  ],
  "n_reviews": 0
 },
 {
  "input": "It's a 50-50 choice.",
  "model": "nmt",
  "translatedText": "Itu adalah pilihan 50-50.",
  "time_range": [
   1024.7,
   1025.7
  ],
  "n_reviews": 0
 },
 {
  "input": "And from here, because you and I know which words are more common, we know that the answer should be abyss.",
  "model": "nmt",
  "translatedText": "Dan dari sini, karena Anda dan saya tahu kata mana yang lebih umum, kita tahu bahwa jawabannya pasti sangat buruk.",
  "time_range": [
   1026.5,
   1030.64
  ],
  "n_reviews": 0
 },
 {
  "input": "But as it's written right now, the program doesn't know that.",
  "model": "nmt",
  "translatedText": "Namun seperti yang tertulis sekarang, program tersebut tidak mengetahui hal itu.",
  "time_range": [
   1031.18,
   1033.28
  ],
  "n_reviews": 0
 },
 {
  "input": "So it just keeps going, trying to gain as much information as it can, until it's only one possibility left, and then it guesses it.",
  "model": "nmt",
  "translatedText": "Jadi ia terus berjalan, berusaha mendapatkan informasi sebanyak-banyaknya, hingga hanya tersisa satu kemungkinan, lalu ia menebaknya.",
  "time_range": [
   1033.54,
   1039.86
  ],
  "n_reviews": 0
 },
 {
  "input": "So obviously we need a better endgame strategy.",
  "model": "nmt",
  "translatedText": "Jadi jelas kita memerlukan strategi akhir yang lebih baik.",
  "time_range": [
   1040.38,
   1042.34
  ],
  "n_reviews": 0
 },
 {
  "input": "But let's say we call this version one of our wordle solver, and then we go and run some simulations to see how it does.",
  "model": "nmt",
  "translatedText": "Tapi katakanlah kita menyebut versi ini sebagai salah satu pemecah kata-kata kita, dan kemudian kita menjalankan beberapa simulasi untuk melihat bagaimana kinerjanya.",
  "time_range": [
   1042.6,
   1048.26
  ],
  "n_reviews": 0
 },
 {
  "input": "So the way this is working is it's playing every possible wordle game.",
  "model": "nmt",
  "translatedText": "Jadi cara kerjanya adalah dengan memainkan setiap permainan kata yang memungkinkan.",
  "time_range": [
   1050.36,
   1054.12
  ],
  "n_reviews": 0
 },
 {
  "input": "It's going through all of those 2315 words that are the actual wordle answers.",
  "model": "nmt",
  "translatedText": "Itu melewati 2.315 kata yang merupakan jawaban kata yang sebenarnya.",
  "time_range": [
   1054.24,
   1058.54
  ],
  "n_reviews": 0
 },
 {
  "input": "It's basically using that as a testing set.",
  "model": "nmt",
  "translatedText": "Ini pada dasarnya menggunakannya sebagai set pengujian.",
  "time_range": [
   1058.54,
   1060.58
  ],
  "n_reviews": 0
 },
 {
  "input": "And with this naive method of not considering how common a word is, and just trying to maximize the information at each step along the way, until it gets down to one and only one choice.",
  "model": "nmt",
  "translatedText": "Dan dengan metode naif ini dengan tidak mempertimbangkan seberapa umum suatu kata, dan hanya mencoba memaksimalkan informasi di setiap langkah, hingga hanya ada satu pilihan.",
  "time_range": [
   1061.36,
   1069.82
  ],
  "n_reviews": 0
 },
 {
  "input": "By the end of the simulation, the average score works out to be about 4.124.",
  "model": "nmt",
  "translatedText": "Pada akhir simulasi, skor rata-rata menjadi sekitar 4.124.",
  "time_range": [
   1070.36,
   1074.3
  ],
  "n_reviews": 0
 },
 {
  "input": "Which is not bad, to be honest, I kind of expected to do worse.",
  "model": "nmt",
  "translatedText": "Itu tidak buruk, sejujurnya, saya berharap untuk melakukan yang lebih buruk.",
  "time_range": [
   1075.3199999999997,
   1079.24
  ],
  "n_reviews": 0
 },
 {
  "input": "But the people who play wordle will tell you that they can usually get it in 4.",
  "model": "nmt",
  "translatedText": "Tetapi orang-orang yang bermain wordle akan memberitahu Anda bahwa mereka biasanya bisa mendapatkannya dalam 4.",
  "time_range": [
   1079.66,
   1082.6
  ],
  "n_reviews": 0
 },
 {
  "input": "The real challenge is to get as many in 3 as you can.",
  "model": "nmt",
  "translatedText": "Tantangan sebenarnya adalah mendapatkan sebanyak 3 buah sebanyak yang Anda bisa.",
  "time_range": [
   1082.86,
   1085.38
  ],
  "n_reviews": 0
 },
 {
  "input": "It's a pretty big jump between the score of 4 and the score of 3.",
  "model": "nmt",
  "translatedText": "Ini merupakan lompatan yang cukup besar antara skor 4 dan skor 3.",
  "time_range": [
   1085.38,
   1088.08
  ],
  "n_reviews": 0
 },
 {
  "input": "The obvious low hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that.",
  "model": "nmt",
  "translatedText": "Hal yang jelas terlihat di sini adalah dengan memasukkan apakah suatu kata itu umum atau tidak, dan bagaimana tepatnya kita melakukannya.",
  "time_range": [
   1088.86,
   1094.98
  ],
  "n_reviews": 0
 },
 {
  "input": "The way I approached it is to get a list of the relative frequencies for all of the words in the English language.",
  "model": "nmt",
  "translatedText": "Cara saya mendekatinya adalah dengan mendapatkan daftar frekuensi relatif untuk semua kata dalam bahasa Inggris.",
  "time_range": [
   1102.8,
   1107.88
  ],
  "n_reviews": 0
 },
 {
  "input": "And I just used Mathematica's word frequency data function, which itself pulls from the Google Books English Ngram public dataset.",
  "model": "nmt",
  "translatedText": "Dan saya baru saja menggunakan fungsi data frekuensi kata Mathematica, yang diambil dari kumpulan data publik Google Buku Bahasa Inggris Ngram.",
  "time_range": [
   1108.22,
   1114.86
  ],
  "n_reviews": 0
 },
 {
  "input": "And it's kind of fun to look at, for example if we sort it from the most common words to the least common words.",
  "model": "nmt",
  "translatedText": "Dan itu menyenangkan untuk dilihat, misalnya jika kita mengurutkannya dari kata yang paling umum hingga kata yang paling tidak umum.",
  "time_range": [
   1115.46,
   1119.96
  ],
  "n_reviews": 0
 },
 {
  "input": "Evidently these are the most common, 5 letter words in the English language.",
  "model": "nmt",
  "translatedText": "Rupanya ini adalah kata 5 huruf yang paling umum dalam bahasa Inggris.",
  "time_range": [
   1120.12,
   1123.08
  ],
  "n_reviews": 0
 },
 {
  "input": "Or rather, these is the 8th most common.",
  "model": "nmt",
  "translatedText": "Atau lebih tepatnya, ini adalah yang paling umum ke-8.",
  "time_range": [
   1123.7,
   1125.84
  ],
  "n_reviews": 0
 },
 {
  "input": "First is which, after which there's there and there.",
  "model": "nmt",
  "translatedText": "Pertama yang mana, setelah itu ada disana dan disana.",
  "time_range": [
   1126.28,
   1128.88
  ],
  "n_reviews": 0
 },
 {
  "input": "First itself is not first, but 9th, and it makes sense that these other words could come about more often, where those after first are after, where, and those being just a little bit less common.",
  "model": "nmt",
  "translatedText": "Yang pertama bukanlah yang pertama, melainkan yang ke-9, dan masuk akal jika kata-kata lain ini muncul lebih sering, jika kata setelah yang pertama adalah setelah, di mana, dan kata-kata tersebut menjadi kurang umum.",
  "time_range": [
   1129.26,
   1138.58
  ],
  "n_reviews": 0
 },
 {
  "input": "Now, in using this data to model how likely each of these words is to be the final answer, it shouldn't just be proportional to the frequency.",
  "model": "nmt",
  "translatedText": "Sekarang, dalam menggunakan data ini untuk memodelkan seberapa besar kemungkinan masing-masing kata ini menjadi jawaban akhir, data tersebut tidak boleh hanya sebanding dengan frekuensinya.",
  "time_range": [
   1139.16,
   1146.86
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, which is given a score of 0.002 in this dataset, whereas the word braid is in some sense about 1000 times less likely.",
  "model": "nmt",
  "translatedText": "Misal yang diberi skor 0.002 dalam kumpulan data ini, sedangkan kata jalinan dalam beberapa hal kemungkinannya sekitar 1000 kali lebih kecil.",
  "time_range": [
   1146.86,
   1155.06
  ],
  "n_reviews": 0
 },
 {
  "input": "But both of these are common enough words that they're almost certainly worth considering.",
  "model": "nmt",
  "translatedText": "Namun keduanya adalah kata-kata yang cukup umum sehingga hampir pasti layak untuk dipertimbangkan.",
  "time_range": [
   1155.56,
   1158.84
  ],
  "n_reviews": 0
 },
 {
  "input": "So we want more of a binary cutoff.",
  "model": "nmt",
  "translatedText": "Jadi kami ingin lebih banyak pemutusan biner.",
  "time_range": [
   1159.34,
   1161.0
  ],
  "n_reviews": 0
 },
 {
  "input": "The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it's either 0 or it's 1, but there's a smoothing in between for that region of uncertainty.",
  "model": "nmt",
  "translatedText": "Cara saya melakukannya adalah dengan membayangkan mengambil seluruh daftar kata yang diurutkan ini, dan kemudian menyusunnya pada sumbu x, dan kemudian menerapkan fungsi sigmoid, yang merupakan cara standar untuk memiliki fungsi yang keluarannya pada dasarnya biner, itu's baik 0 atau 1, namun terdapat kelancaran di antara wilayah ketidakpastian tersebut.",
  "time_range": [
   1161.86,
   1178.26
  ],
  "n_reviews": 0
 },
 {
  "input": "So essentially, the probability that I'm assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis.",
  "model": "nmt",
  "translatedText": "Jadi pada dasarnya, probabilitas yang saya tetapkan untuk setiap kata untuk berada di daftar akhir akan menjadi nilai fungsi sigmoid di atas di mana pun ia berada pada sumbu x.",
  "time_range": [
   1179.16,
   1188.44
  ],
  "n_reviews": 0
 },
 {
  "input": "Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from 1 to 0, and where we situate them left to right determines the cutoff.",
  "model": "nmt",
  "translatedText": "Tentu saja hal ini bergantung pada beberapa parameter, misalnya seberapa lebar spasi pada sumbu x kata-kata tersebut terisi menentukan seberapa bertahap atau tajamnya kita turun dari 1 ke 0, dan di mana kita menempatkan kata-kata tersebut dari kiri ke kanan menentukan batasnya.",
  "time_range": [
   1189.52,
   1203.24
  ],
  "n_reviews": 0
 },
 {
  "input": "To be honest, the way I did this was just licking my finger and sticking it into the wind.",
  "model": "nmt",
  "translatedText": "Sejujurnya, caraku melakukan ini hanyalah menjilat jariku dan menempelkannya ke angin.",
  "time_range": [
   1203.24,
   1206.92
  ],
  "n_reviews": 0
 },
 {
  "input": "I looked through the sorted list and tried to find a window where when I looked at it I figured about half of these words are more likely than not to be the final answer, and used that as the cutoff.",
  "model": "nmt",
  "translatedText": "Saya melihat daftar yang diurutkan dan mencoba menemukan jendela di mana ketika saya melihatnya, saya pikir sekitar setengah dari kata-kata ini lebih mungkin menjadi jawaban akhir, dan menggunakannya sebagai batasnya.",
  "time_range": [
   1207.14,
   1217.26
  ],
  "n_reviews": 0
 },
 {
  "input": "Once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement.",
  "model": "nmt",
  "translatedText": "Setelah kita mendapatkan distribusi seperti ini di seluruh kata, ini memberi kita situasi lain di mana entropi menjadi pengukuran yang sangat berguna.",
  "time_range": [
   1217.26,
   1223.86
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, let's say we were playing a game and we start with my old openers, which were a feather and nails, and we end up with a situation where there's four possible words that match it.",
  "model": "nmt",
  "translatedText": "Sebagai contoh, katakanlah kita sedang bermain game dan kita mulai dengan pembuka lama saya, yaitu bulu dan paku, dan kita berakhir dengan situasi di mana ada empat kemungkinan kata yang cocok dengan itu.",
  "time_range": [
   1224.5,
   1233.24
  ],
  "n_reviews": 0
 },
 {
  "input": "And let's say we consider them all equally likely.",
  "model": "nmt",
  "translatedText": "Dan katakanlah kita menganggap semuanya memiliki kemungkinan yang sama.",
  "time_range": [
   1233.56,
   1235.62
  ],
  "n_reviews": 0
 },
 {
  "input": "Let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Izinkan saya bertanya, berapa entropi distribusi ini?",
  "time_range": [
   1236.22,
   1238.88
  ],
  "n_reviews": 0
 },
 {
  "input": "Well, the information associated with each one of these possibilities is going to be the log base 2 of 4, since each one is 1 and 4, and that's 2.",
  "model": "nmt",
  "translatedText": "Nah, informasi yang terkait dengan masing-masing kemungkinan ini akan menjadi basis log 2 dari 4, karena masing-masing adalah 1 dan 4, dan itu adalah 2.",
  "time_range": [
   1241.08,
   1250.04
  ],
  "n_reviews": 0
 },
 {
  "input": "Two bits of information, four possibilities.",
  "model": "nmt",
  "translatedText": "Dua informasi, empat kemungkinan.",
  "time_range": [
   1250.04,
   1252.46
  ],
  "n_reviews": 0
 },
 {
  "input": "All very well and good.",
  "model": "nmt",
  "translatedText": "Semuanya sangat baik dan bagus.",
  "time_range": [
   1252.76,
   1253.58
  ],
  "n_reviews": 0
 },
 {
  "input": "But what if I told you that actually there's more than four matches?",
  "model": "nmt",
  "translatedText": "Tapi bagaimana jika saya bilang sebenarnya ada lebih dari empat pertandingan?",
  "time_range": [
   1254.3,
   1257.8
  ],
  "n_reviews": 0
 },
 {
  "input": "In reality, when we look through the full word list, there are 16 words that match it.",
  "model": "nmt",
  "translatedText": "Kenyataannya, jika kita melihat daftar kata selengkapnya, ada 16 kata yang cocok.",
  "time_range": [
   1258.26,
   1262.46
  ],
  "n_reviews": 0
 },
 {
  "input": "But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like 1 in 1000 because they're really obscure.",
  "model": "nmt",
  "translatedText": "Namun misalkan model kita memberikan probabilitas yang sangat rendah pada 12 kata lainnya untuk menjadi jawaban akhir, sekitar 1 dalam 1000 karena kata tersebut sangat tidak jelas.",
  "time_range": [
   1262.58,
   1270.76
  ],
  "n_reviews": 0
 },
 {
  "input": "Now let me ask you, what is the entropy of this distribution?",
  "model": "nmt",
  "translatedText": "Sekarang izinkan saya bertanya, berapa entropi distribusi ini?",
  "time_range": [
   1271.5,
   1274.26
  ],
  "n_reviews": 0
 },
 {
  "input": "If entropy was purely measuring the number of matches here, then you might expect it to be something like the log base 2 of 16, which would be 4, two more bits of uncertainty than we had before.",
  "model": "nmt",
  "translatedText": "Jika entropi hanya mengukur jumlah kecocokan di sini, Anda mungkin mengharapkannya menjadi basis log 2 dari 16, yaitu 4, dua bit ketidakpastian lebih banyak daripada yang kita miliki sebelumnya.",
  "time_range": [
   1275.42,
   1285.7
  ],
  "n_reviews": 0
 },
 {
  "input": "But of course the actual uncertainty is not really that different from what we had before.",
  "model": "nmt",
  "translatedText": "Namun tentu saja ketidakpastian yang sebenarnya tidak jauh berbeda dengan apa yang kita alami sebelumnya.",
  "time_range": [
   1286.18,
   1289.86
  ],
  "n_reviews": 0
 },
 {
  "input": "Just because there's these 12 really obscure words doesn't mean that it would be all that more surprising to learn that the final answer is charm, for example.",
  "model": "nmt",
  "translatedText": "Hanya karena ada 12 kata yang sangat tidak jelas ini tidak berarti akan lebih mengejutkan jika mengetahui bahwa jawaban akhirnya adalah pesona, misalnya.",
  "time_range": [
   1290.16,
   1297.36
  ],
  "n_reviews": 0
 },
 {
  "input": "So when you actually do the calculation here, and you add up the probability of each occurrence times the corresponding information, what you get is 2.11 bits.",
  "model": "nmt",
  "translatedText": "Jadi ketika Anda benar-benar melakukan perhitungan di sini, dan Anda menjumlahkan probabilitas setiap kejadian dikalikan dengan informasi terkait, yang Anda dapatkan adalah 2.11 bit.",
  "time_range": [
   1298.18,
   1305.56
  ],
  "n_reviews": 0
 },
 {
  "input": "I'm just saying, it's basically two bits, basically those four possibilities, but there's a little more uncertainty because of all of those highly unlikely events, though if you did learn them you'd get a ton of information from it.",
  "model": "nmt",
  "translatedText": "Maksud saya, pada dasarnya ada dua bagian, pada dasarnya empat kemungkinan tersebut, namun ada sedikit ketidakpastian karena semua kejadian yang sangat tidak mungkin tersebut, meskipun jika Anda mempelajarinya, Anda akan mendapatkan banyak informasi darinya.",
  "time_range": [
   1305.56,
   1316.5
  ],
  "n_reviews": 0
 },
 {
  "input": "So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson.",
  "model": "nmt",
  "translatedText": "Jadi jika diperkecil, inilah bagian yang membuat Wordle menjadi contoh yang bagus untuk pelajaran teori informasi.",
  "time_range": [
   1317.16,
   1321.4
  ],
  "n_reviews": 0
 },
 {
  "input": "We have these two distinct feeling applications for entropy.",
  "model": "nmt",
  "translatedText": "Kami memiliki dua penerapan perasaan yang berbeda untuk entropi.",
  "time_range": [
   1321.6,
   1324.64
  ],
  "n_reviews": 0
 },
 {
  "input": "The first one telling us what's the expected information we'll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words that we have possible.",
  "model": "nmt",
  "translatedText": "Yang pertama memberi tahu kita informasi apa yang diharapkan yang akan kita peroleh dari tebakan tertentu, dan yang kedua mengatakan bisakah kita mengukur ketidakpastian yang tersisa di antara semua kata yang mungkin kita miliki.",
  "time_range": [
   1325.16,
   1335.46
  ],
  "n_reviews": 0
 },
 {
  "input": "And I should emphasize, in that first case where we're looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation.",
  "model": "nmt",
  "translatedText": "Dan saya harus menekankan, dalam kasus pertama ketika kita melihat informasi yang diharapkan dari sebuah tebakan, setelah kita memiliki bobot yang tidak sama pada kata-katanya, itu mempengaruhi perhitungan entropi.",
  "time_range": [
   1336.46,
   1344.54
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, let me pull up that same case we were looking at earlier of the distribution associated with Weary, but this time using a non-uniform distribution across all possible words.",
  "model": "nmt",
  "translatedText": "Sebagai contoh, izinkan saya mengambil kasus yang sama yang kita lihat sebelumnya tentang distribusi yang terkait dengan Weary, namun kali ini menggunakan distribusi yang tidak seragam di semua kemungkinan kata.",
  "time_range": [
   1344.98,
   1353.72
  ],
  "n_reviews": 0
 },
 {
  "input": "So let me see if I can find a part here that illustrates it pretty well.",
  "model": "nmt",
  "translatedText": "Jadi izinkan saya melihat apakah saya dapat menemukan bagian di sini yang menggambarkannya dengan cukup baik.",
  "time_range": [
   1354.5,
   1358.28
  ],
  "n_reviews": 0
 },
 {
  "input": "Okay, here this is pretty good.",
  "model": "nmt",
  "translatedText": "Oke, ini cukup bagus.",
  "time_range": [
   1360.94,
   1362.36
  ],
  "n_reviews": 0
 },
 {
  "input": "Here we have two adjacent patterns that are about equally likely, but one of them we're told has 32 possible words that match it.",
  "model": "nmt",
  "translatedText": "Di sini kita memiliki dua pola berdekatan yang kemungkinannya hampir sama, namun salah satu pola tersebut memiliki 32 kemungkinan kata yang cocok.",
  "time_range": [
   1362.36,
   1369.1
  ],
  "n_reviews": 0
 },
 {
  "input": "And if we check what they are, these are those 32, which are all just very unlikely words as you scan your eyes over them.",
  "model": "nmt",
  "translatedText": "Dan jika kita periksa apa itu, ini adalah 32 kata tersebut, yang semuanya merupakan kata-kata yang sangat tidak mungkin ketika Anda mengamatinya.",
  "time_range": [
   1369.28,
   1375.6
  ],
  "n_reviews": 0
 },
 {
  "input": "It's hard to find any that feel like plausible answers, maybe yells, but if we look at the neighboring pattern in the distribution, which is considered just about as likely, we're told that it only has 8 possible matches, so a quarter as many matches, but it's about as likely.",
  "model": "nmt",
  "translatedText": "Sulit untuk menemukan jawaban yang terasa masuk akal, mungkin teriakan, tetapi jika kita melihat pola tetangga dalam distribusi, yang dianggap sama mungkinnya, kita diberitahu bahwa hanya ada 8 kemungkinan kecocokan, jadi seperempatnya banyak pertandingan, tapi kemungkinannya sama.",
  "time_range": [
   1375.84,
   1389.52
  ],
  "n_reviews": 0
 },
 {
  "input": "And when we pull up those matches, we can see why.",
  "model": "nmt",
  "translatedText": "Dan saat kami menghentikan pertandingan tersebut, kami dapat mengetahui alasannya.",
  "time_range": [
   1389.86,
   1392.14
  ],
  "n_reviews": 0
 },
 {
  "input": "Some of these are actual plausible answers, like ring, or wrath, or raps.",
  "model": "nmt",
  "translatedText": "Beberapa di antaranya adalah jawaban yang benar-benar masuk akal, seperti dering, murka, atau rap.",
  "time_range": [
   1392.5,
   1396.3
  ],
  "n_reviews": 0
 },
 {
  "input": "To illustrate how we incorporate all that, let me pull up version 2 of the Wordlebot here, and there are two or three main differences from the first one that we saw.",
  "model": "nmt",
  "translatedText": "Untuk mengilustrasikan bagaimana kami menggabungkan semua itu, izinkan saya menampilkan Wordlebot versi 2 di sini, dan ada dua atau tiga perbedaan utama dari yang pertama yang kami lihat.",
  "time_range": [
   1397.9,
   1405.28
  ],
  "n_reviews": 0
 },
 {
  "input": "First off, like I just said, the way that we're computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer.",
  "model": "nmt",
  "translatedText": "Pertama, seperti yang baru saja saya katakan, cara kita menghitung entropi ini, nilai informasi yang diharapkan, kini menggunakan distribusi yang lebih halus di seluruh pola yang menggabungkan probabilitas bahwa suatu kata tertentu akan menjadi jawabannya.",
  "time_range": [
   1405.86,
   1418.24
  ],
  "n_reviews": 0
 },
 {
  "input": "As it happens, tears is still number 1, though the ones following are a bit different.",
  "model": "nmt",
  "translatedText": "Ternyata, air mata tetaplah nomor 1, meski air mata berikut ini sedikit berbeda.",
  "time_range": [
   1418.8799999999999,
   1423.82
  ],
  "n_reviews": 0
 },
 {
  "input": "Second, when it ranks its top picks, it's now going to keep a model of the probability that each word is the actual answer, and it'll incorporate that into its decision, which is easier to see once we have a few guesses on the table.",
  "model": "nmt",
  "translatedText": "Kedua, ketika ia memberi peringkat pada pilihan teratasnya, sekarang ia akan menyimpan model probabilitas bahwa setiap kata adalah jawaban sebenarnya, dan ia akan memasukkannya ke dalam keputusannya, yang lebih mudah dilihat setelah kita mempunyai beberapa tebakan pada kata tersebut. meja.",
  "time_range": [
   1424.36,
   1435.08
  ],
  "n_reviews": 0
 },
 {
  "input": "Again, ignoring its recommendation because we can't let machines rule our lives.",
  "model": "nmt",
  "translatedText": "Sekali lagi, abaikan rekomendasinya karena kita tidak bisa membiarkan mesin mengatur hidup kita.",
  "time_range": [
   1435.86,
   1439.78
  ],
  "n_reviews": 0
 },
 {
  "input": "And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches.",
  "model": "nmt",
  "translatedText": "Dan saya kira saya harus menyebutkan hal lain yang berbeda di sebelah kiri, bahwa nilai ketidakpastian, jumlah bit, tidak lagi mubazir dengan jumlah kemungkinan kecocokan.",
  "time_range": [
   1441.14,
   1449.64
  ],
  "n_reviews": 0
 },
 {
  "input": "Now if we pull it up and calculate 2 to the 8.02, which is a little above 256, I guess 259, what it's saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes.",
  "model": "nmt",
  "translatedText": "Sekarang jika kita menariknya dan menghitung 2 sampai 8.02, yang sedikit di atas 256, saya rasa 259, maksudnya adalah meskipun ada 526 kata yang benar-benar cocok dengan pola ini, jumlah ketidakpastiannya lebih mirip dengan apa yang akan terjadi jika ada 259 kata yang sama kemungkinannya. hasil.",
  "time_range": [
   1450.08,
   1468.98
  ],
  "n_reviews": 0
 },
 {
  "input": "You can think of it like this.",
  "model": "nmt",
  "translatedText": "Anda bisa memikirkannya seperti ini.",
  "time_range": [
   1469.72,
   1470.74
  ],
  "n_reviews": 0
 },
 {
  "input": "It knows borx is not the answer, same with yorts and zorl and zorus, so it's a little less uncertain than it was in the previous case.",
  "model": "nmt",
  "translatedText": "Ia mengetahui bahwa borx bukanlah jawabannya, sama halnya dengan yorts, zorl, dan zorus, jadi ketidakpastiannya tidak terlalu besar dibandingkan kasus sebelumnya.",
  "time_range": [
   1471.02,
   1477.68
  ],
  "n_reviews": 0
 },
 {
  "input": "This number of bits will be smaller.",
  "model": "nmt",
  "translatedText": "Jumlah bit ini akan lebih kecil.",
  "time_range": [
   1477.82,
   1479.28
  ],
  "n_reviews": 0
 },
 {
  "input": "And if I keep playing the game, I'm refining this down with a couple guesses that are apropos of what I would like to explain here.",
  "model": "nmt",
  "translatedText": "Dan jika saya terus memainkan permainan ini, saya akan menyempurnakannya dengan beberapa tebakan yang sesuai dengan apa yang ingin saya jelaskan di sini.",
  "time_range": [
   1480.22,
   1486.54
  ],
  "n_reviews": 0
 },
 {
  "input": "By the fourth guess, if you look over at its top picks, you can see it's no longer just maximizing the entropy.",
  "model": "nmt",
  "translatedText": "Pada tebakan keempat, jika Anda melihat pilihan teratasnya, Anda dapat melihat bahwa ini tidak lagi hanya memaksimalkan entropi.",
  "time_range": [
   1488.36,
   1493.76
  ],
  "n_reviews": 0
 },
 {
  "input": "So at this point, there's technically seven possibilities, but the only ones with a meaningful chance are dorms and words.",
  "model": "nmt",
  "translatedText": "Jadi saat ini, secara teknis ada tujuh kemungkinan, tapi satu-satunya peluang yang memiliki peluang berarti adalah asrama dan kata-kata.",
  "time_range": [
   1494.46,
   1500.3
  ],
  "n_reviews": 0
 },
 {
  "input": "And you can see it ranks choosing both of those above all of these other values, that strictly speaking would give more information.",
  "model": "nmt",
  "translatedText": "Dan Anda dapat melihat peringkatnya dengan memilih kedua nilai tersebut di atas semua nilai lainnya, yang sebenarnya akan memberikan lebih banyak informasi.",
  "time_range": [
   1500.3,
   1506.72
  ],
  "n_reviews": 0
 },
 {
  "input": "The very first time I did this, I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect.",
  "model": "nmt",
  "translatedText": "Pertama kali saya melakukan ini, saya hanya menjumlahkan kedua angka ini untuk mengukur kualitas setiap tebakan, yang sebenarnya bekerja lebih baik dari yang Anda duga.",
  "time_range": [
   1507.24,
   1513.9
  ],
  "n_reviews": 0
 },
 {
  "input": "But it really didn't feel systematic, and I'm sure there's other approaches people could take but here's the one I landed on.",
  "model": "nmt",
  "translatedText": "Namun hal ini terasa tidak sistematis, dan saya yakin ada pendekatan lain yang bisa diambil orang, namun inilah pendekatan yang saya pilih.",
  "time_range": [
   1514.3,
   1519.34
  ],
  "n_reviews": 0
 },
 {
  "input": "If we're considering the prospect of a next guess, like in this case words, what we really care about is the expected score of our game if we do that.",
  "model": "nmt",
  "translatedText": "Jika kita mempertimbangkan prospek tebakan berikutnya, seperti dalam hal ini, yang benar-benar kita pedulikan adalah skor yang diharapkan dari permainan kita jika kita melakukan itu.",
  "time_range": [
   1519.76,
   1527.9
  ],
  "n_reviews": 0
 },
 {
  "input": "And to calculate that expected score, we say what's the probability that words is the actual answer, which at the moment it describes 58% to.",
  "model": "nmt",
  "translatedText": "Dan untuk menghitung skor yang diharapkan, kami mengatakan berapa probabilitas bahwa kata-kata tersebut adalah jawaban sebenarnya, yang saat ini menggambarkan 58%.",
  "time_range": [
   1528.23,
   1535.9
  ],
  "n_reviews": 0
 },
 {
  "input": "We say with a 58% chance, our score in this game would be 4.",
  "model": "nmt",
  "translatedText": "Kami katakan dengan peluang 58%, skor kami dalam permainan ini adalah 4.",
  "time_range": [
   1536.04,
   1539.54
  ],
  "n_reviews": 0
 },
 {
  "input": "And then with the probability of 1 minus that 58%, our score will be more than that 4.",
  "model": "nmt",
  "translatedText": "Dan kemudian dengan probabilitas 1 dikurangi 58% itu, skor kita akan lebih dari 4 itu.",
  "time_range": [
   1540.32,
   1545.64
  ],
  "n_reviews": 0
 },
 {
  "input": "How much more we don't know, but we can estimate it based on how much uncertainty there's likely to be once we get to that point.",
  "model": "nmt",
  "translatedText": "Berapa banyak lagi yang belum kita ketahui, namun kita dapat memperkirakannya berdasarkan seberapa besar ketidakpastian yang mungkin terjadi setelah kita mencapai titik tersebut.",
  "time_range": [
   1546.22,
   1552.46
  ],
  "n_reviews": 0
 },
 {
  "input": "Specifically, at the moment there's 1.44 bits of uncertainty.",
  "model": "nmt",
  "translatedText": "Secara khusus, saat ini ada 1.44 bit ketidakpastian.",
  "time_range": [
   1552.96,
   1555.94
  ],
  "n_reviews": 0
 },
 {
  "input": "If we guess words, it's telling us the expected information we'll get is 1.27 bits.",
  "model": "nmt",
  "translatedText": "Jika kita menebak kata-kata, itu memberi tahu kita bahwa informasi yang diharapkan yang akan kita dapatkan adalah 1.27 bit.",
  "time_range": [
   1556.44,
   1561.12
  ],
  "n_reviews": 0
 },
 {
  "input": "So if we guess words, this difference represents how much uncertainty we're likely to be left with after that happens.",
  "model": "nmt",
  "translatedText": "Jadi jika kita menebak-nebak, perbedaan ini menunjukkan seberapa besar ketidakpastian yang mungkin kita alami setelah hal tersebut terjadi.",
  "time_range": [
   1561.62,
   1567.66
  ],
  "n_reviews": 0
 },
 {
  "input": "What we need is some kind of function, which I'm calling f here, that associates this uncertainty with an expected score.",
  "model": "nmt",
  "translatedText": "Yang kita butuhkan adalah suatu fungsi, yang saya sebut f di sini, yang menghubungkan ketidakpastian ini dengan skor yang diharapkan.",
  "time_range": [
   1568.26,
   1573.74
  ],
  "n_reviews": 0
 },
 {
  "input": "And the way it went about this was to just plot a bunch of the data from previous games based on version 1 of the bot to say hey what was the actual score after various points with certain very measurable amounts of uncertainty.",
  "model": "nmt",
  "translatedText": "Dan caranya adalah dengan memplot sekumpulan data dari game sebelumnya berdasarkan versi 1 bot untuk mengatakan berapa skor sebenarnya setelah berbagai poin dengan jumlah ketidakpastian tertentu yang sangat terukur.",
  "time_range": [
   1574.24,
   1586.32
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, these data points here that are sitting above a value that's around like 8.7 or so are saying for some games after a point at which there were 8.7 bits of uncertainty, it took two guesses to get the final answer.",
  "model": "nmt",
  "translatedText": "Misalnya, titik data di sini yang berada di atas nilai sekitar 8.7 atau lebih dikatakan untuk beberapa permainan setelah titik di mana ada 8.7 bit ketidakpastian, butuh dua tebakan untuk mendapatkan jawaban akhir.",
  "time_range": [
   1587.02,
   1598.96
  ],
  "n_reviews": 0
 },
 {
  "input": "For other games it took three guesses, for other games it took four guesses.",
  "model": "nmt",
  "translatedText": "Untuk permainan lainnya membutuhkan tiga kali tebakan, untuk permainan lainnya membutuhkan empat kali tebakan.",
  "time_range": [
   1599.32,
   1602.24
  ],
  "n_reviews": 0
 },
 {
  "input": "If we shift over to the left here, all the points over zero are saying whenever there's zero bits of uncertainty, which is to say there's only one possibility, then the number of guesses required is always just one, which is reassuring.",
  "model": "nmt",
  "translatedText": "Jika kita menggeser ke kiri di sini, semua titik di atas nol menyatakan kapan pun tidak ada sedikit pun ketidakpastian, artinya hanya ada satu kemungkinan, maka jumlah tebakan yang diperlukan selalu hanya satu, yang meyakinkan.",
  "time_range": [
   1603.14,
   1614.26
  ],
  "n_reviews": 0
 },
 {
  "input": "Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess, sometimes it required two more guesses.",
  "model": "nmt",
  "translatedText": "Kapan pun ada sedikit ketidakpastian, artinya pada dasarnya hanya ada dua kemungkinan, terkadang diperlukan satu tebakan lagi, terkadang diperlukan dua tebakan lagi.",
  "time_range": [
   1614.78,
   1623.02
  ],
  "n_reviews": 0
 },
 {
  "input": "And so on and so forth here.",
  "model": "nmt",
  "translatedText": "Dan seterusnya dan seterusnya di sini.",
  "time_range": [
   1623.08,
   1625.24
  ],
  "n_reviews": 0
 },
 {
  "input": "Maybe a slightly easier way to visualize this data is to bucket it together and take averages.",
  "model": "nmt",
  "translatedText": "Mungkin cara yang sedikit lebih mudah untuk memvisualisasikan data ini adalah dengan menggabungkannya dan mengambil rata-ratanya.",
  "time_range": [
   1625.74,
   1630.22
  ],
  "n_reviews": 0
 },
 {
  "input": "For example this bar here saying among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.5.",
  "model": "nmt",
  "translatedText": "Misalnya bilah di sini menyatakan di antara semua titik di mana kita mempunyai sedikit ketidakpastian, rata-rata jumlah tebakan baru yang diperlukan adalah sekitar 1.5.",
  "time_range": [
   1631.0,
   1639.96
  ],
  "n_reviews": 0
 },
 {
  "input": "And the bar over here saying among all of the different games where at some point the uncertainty was a little above four bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward.",
  "model": "nmt",
  "translatedText": "Dan batasan di sini mengatakan di antara semua permainan yang berbeda di mana pada titik tertentu ketidakpastiannya sedikit di atas empat bit, yang seperti mempersempitnya menjadi 16 kemungkinan berbeda, maka rata-rata memerlukan lebih dari dua tebakan dari titik itu. maju.",
  "time_range": [
   1642.14,
   1655.38
  ],
  "n_reviews": 0
 },
 {
  "input": "And from here I just did a regression to fit a function that seemed reasonable to this.",
  "model": "nmt",
  "translatedText": "Dan dari sini saya baru saja melakukan regresi agar sesuai dengan fungsi yang tampaknya masuk akal untuk ini.",
  "time_range": [
   1656.06,
   1659.46
  ],
  "n_reviews": 0
 },
 {
  "input": "And remember the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be.",
  "model": "nmt",
  "translatedText": "Dan ingat, inti dari melakukan semua itu adalah agar kita dapat mengukur intuisi bahwa semakin banyak informasi yang kita peroleh dari sebuah kata, semakin rendah pula skor yang diharapkan.",
  "time_range": [
   1659.98,
   1668.96
  ],
  "n_reviews": 0
 },
 {
  "input": "So with this as version 2.0, if we go back and we run the same set of simulations, having it play against all 2315 possible wordle answers, how does it do?",
  "model": "nmt",
  "translatedText": "Jadi dengan ini sebagai versi 2.0, jika kita kembali dan menjalankan rangkaian simulasi yang sama, memainkannya melawan semua 2315 kemungkinan jawaban, bagaimana cara kerjanya?",
  "time_range": [
   1669.68,
   1679.24
  ],
  "n_reviews": 0
 },
 {
  "input": "Well in contrast to our first version it's definitely better, which is reassuring.",
  "model": "nmt",
  "translatedText": "Berbeda dengan versi pertama kami, ini pasti lebih baik, dan itu meyakinkan.",
  "time_range": [
   1680.28,
   1683.42
  ],
  "n_reviews": 0
 },
 {
  "input": "All said and done the average is around 3.6, although unlike the first version there are a couple times that it loses and requires more than six in this circumstance.",
  "model": "nmt",
  "translatedText": "Semua dikatakan dan dilakukan rata-ratanya adalah sekitar 3.6, meskipun tidak seperti versi pertama, ada beberapa kali versi ini kalah dan membutuhkan lebih dari enam dalam keadaan ini.",
  "time_range": [
   1684.02,
   1692.12
  ],
  "n_reviews": 0
 },
 {
  "input": "Presumably because there's times when it's making that tradeoff to actually go for the goal rather than maximizing information.",
  "model": "nmt",
  "translatedText": "Mungkin karena ada kalanya kita melakukan pengorbanan untuk benar-benar mencapai tujuan daripada memaksimalkan informasi.",
  "time_range": [
   1692.6399999999999,
   1697.94
  ],
  "n_reviews": 0
 },
 {
  "input": "So can we do better than 3.6?",
  "model": "nmt",
  "translatedText": "Jadi bisakah kita melakukan lebih baik dari 3.6?",
  "time_range": [
   1699.04,
   1701.0
  ],
  "n_reviews": 0
 },
 {
  "input": "We definitely can.",
  "model": "nmt",
  "translatedText": "Kami pasti bisa.",
  "time_range": [
   1702.08,
   1702.92
  ],
  "n_reviews": 0
 },
 {
  "input": "Now I said at the start that it's most fun to try not incorporating the true list of wordle answers into the way that it builds its model.",
  "model": "nmt",
  "translatedText": "Sekarang saya katakan di awal bahwa paling menyenangkan adalah mencoba tidak memasukkan daftar jawaban kata yang sebenarnya ke dalam cara membangun modelnya.",
  "time_range": [
   1703.28,
   1709.36
  ],
  "n_reviews": 0
 },
 {
  "input": "But if we do incorporate it, the best performance I could get was around 3.43.",
  "model": "nmt",
  "translatedText": "Namun jika kami menggabungkannya, performa terbaik yang bisa saya dapatkan adalah sekitar 3.43.",
  "time_range": [
   1709.88,
   1714.18
  ],
  "n_reviews": 0
 },
 {
  "input": "So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.43 probably gives a max at how good we could get with that, or at least how good I could get with that.",
  "model": "nmt",
  "translatedText": "Jadi jika kita mencoba menjadi lebih canggih dari sekedar menggunakan data frekuensi kata untuk memilih distribusi sebelumnya, ini 3.43 mungkin memberi gambaran maksimal seberapa bagus yang bisa kita dapatkan dengan itu, atau setidaknya seberapa bagus yang bisa saya dapatkan dengan itu.",
  "time_range": [
   1715.16,
   1725.74
  ],
  "n_reviews": 0
 },
 {
  "input": "That best performance essentially just uses the ideas that I've been talking about here, but it goes a little farther, like it does a search for the expected information two steps forward rather than just one.",
  "model": "nmt",
  "translatedText": "Performa terbaik tersebut pada dasarnya hanya menggunakan ide-ide yang telah saya bicarakan di sini, namun lebih jauh lagi, seperti melakukan penelusuran informasi yang diharapkan dua langkah ke depan, bukan hanya satu langkah.",
  "time_range": [
   1726.24,
   1735.12
  ],
  "n_reviews": 0
 },
 {
  "input": "Originally I was planning on talking more about that, but I realize we've actually gone quite long as it is.",
  "model": "nmt",
  "translatedText": "Awalnya saya berencana untuk membicarakan lebih banyak tentang hal itu, tetapi saya menyadari bahwa kita sebenarnya sudah berjalan cukup lama.",
  "time_range": [
   1735.62,
   1740.22
  ],
  "n_reviews": 0
 },
 {
  "input": "The one thing I'll say is after doing this two-step search and then running a couple sample simulations in the top candidates, so far for me at least it's looking like Crane is the best opener.",
  "model": "nmt",
  "translatedText": "Satu hal yang akan saya katakan adalah setelah melakukan pencarian dua langkah ini dan kemudian menjalankan beberapa contoh simulasi pada kandidat teratas, sejauh ini bagi saya setidaknya Crane adalah pembuka terbaik.",
  "time_range": [
   1740.58,
   1749.1
  ],
  "n_reviews": 0
 },
 {
  "input": "Who would have guessed?",
  "model": "nmt",
  "translatedText": "Siapa sangka?",
  "time_range": [
   1749.1,
   1750.06
  ],
  "n_reviews": 0
 },
 {
  "input": "Also if you use the true wordle list to determine your space of possibilities, then the uncertainty you start with is a little over 11 bits.",
  "model": "nmt",
  "translatedText": "Juga jika Anda menggunakan daftar kata yang sebenarnya untuk menentukan ruang kemungkinan Anda, maka ketidakpastian yang Anda mulai adalah sedikit di atas 11 bit.",
  "time_range": [
   1750.92,
   1757.82
  ],
  "n_reviews": 0
 },
 {
  "input": "And it turns out, just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits.",
  "model": "nmt",
  "translatedText": "Dan ternyata, hanya dari pencarian brute force, informasi maksimal yang diharapkan setelah dua tebakan pertama adalah sekitar 10 bit.",
  "time_range": [
   1758.3,
   1765.88
  ],
  "n_reviews": 0
 },
 {
  "input": "Which suggests that best case scenario, after your first two guesses, with perfectly optimal play, you'll be left with around one bit of uncertainty.",
  "model": "nmt",
  "translatedText": "Hal ini menunjukkan bahwa skenario terbaik, setelah dua tebakan pertama Anda, dengan permainan optimal sempurna, Anda akan memiliki sedikit ketidakpastian.",
  "time_range": [
   1766.5,
   1774.56
  ],
  "n_reviews": 0
 },
 {
  "input": "Which is the same as being down to two possible guesses.",
  "model": "nmt",
  "translatedText": "Yang sama dengan membuat dua kemungkinan tebakan.",
  "time_range": [
   1774.8,
   1777.96
  ],
  "n_reviews": 0
 },
 {
  "input": "So I think it's fair and probably pretty conservative to say that you could never possibly write an algorithm that gets this average as low as 3, because with the words available to you, there's simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.",
  "model": "nmt",
  "translatedText": "Jadi menurut saya adil dan mungkin cukup konservatif untuk mengatakan bahwa Anda tidak akan pernah bisa menulis algoritma yang mendapatkan rata-rata serendah 3, karena dengan kata-kata yang tersedia untuk Anda, tidak ada ruang untuk mendapatkan informasi yang cukup setelah hanya dua langkah yang harus dilakukan. mampu menjamin jawaban di slot ketiga setiap saat tanpa gagal.",
  "time_range": [
   1777.96,
   1793.36
  ],
  "n_reviews": 0
 }
]