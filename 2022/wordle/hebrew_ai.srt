1
00:00:00,000 --> 00:00:04,040
המשחק Wurdle הפך די ויראלי בחודש-חודשיים האחרונים, ואף

2
00:00:04,040 --> 00:00:07,880
פעם לא יתעלם מהזדמנות לשיעור מתמטיקה, עולה בדעתי

3
00:00:07,880 --> 00:00:12,120
שהמשחק הזה מהווה דוגמה מרכזית טובה מאוד בשיעור

4
00:00:12,120 --> 00:00:13,120
על תורת המידע, ובפרט נושא המכונה אנטרופיה.

5
00:00:13,120 --> 00:00:17,120
אתה מבין, כמו הרבה אנשים קצת נשאבתי לתוך

6
00:00:17,120 --> 00:00:21,200
הפאזל, וכמו הרבה מתכנתים גם נשאבתי לנסות לכתוב

7
00:00:21,200 --> 00:00:23,200
אלגוריתם שישחק את המשחק הכי אופטימלי שהוא יכול.

8
00:00:23,200 --> 00:00:26,400
ומה שחשבתי לעשות כאן זה פשוט לדבר איתך על

9
00:00:26,400 --> 00:00:29,980
חלק מהתהליך שלי בזה, ולהסביר חלק מהמתמטיקה שנכנסה לזה,

10
00:00:29,980 --> 00:00:32,080
מכיוון שכל האלגוריתם מתרכז ברעיון הזה של אנטרופיה.

11
00:00:32,080 --> 00:00:42,180
דבר ראשון, למקרה שלא שמעתם על זה, מה זה וורדל?

12
00:00:42,180 --> 00:00:45,380
וכדי להרוג כאן שתי ציפורים במכה אחת בזמן שאנחנו עוברים על

13
00:00:45,380 --> 00:00:48,980
כללי המשחק, הרשו לי גם לראות מקדימה לאן אנחנו הולכים עם

14
00:00:48,980 --> 00:00:51,380
זה, כלומר לפתח אלגוריתם קטן שבעצם ישחק את המשחק עבורנו.

15
00:00:51,380 --> 00:00:54,860
למרות שלא עשיתי את הוורדל של היום,

16
00:00:54,860 --> 00:00:55,860
זה 4 בפברואר, ונראה איך הבוט יצליח.

17
00:00:55,860 --> 00:00:59,580
המטרה של Wurdle היא לנחש מילה מסתורית של

18
00:00:59,580 --> 00:01:00,860
חמש אותיות, וניתנות לך שש הזדמנויות שונות לנחש.

19
00:01:00,860 --> 00:01:05,240
לדוגמה, בוט הוורדל שלי מציע שאתחיל עם מנוף הניחוש.

20
00:01:05,240 --> 00:01:09,300
בכל פעם שאתה מנחש, אתה מקבל מידע

21
00:01:09,300 --> 00:01:10,940
על כמה קרוב הניחוש שלך לתשובה האמיתית.

22
00:01:10,940 --> 00:01:14,540
כאן התיבה האפורה אומרת לי שאין C בתשובה האמיתית.

23
00:01:14,540 --> 00:01:18,340
הקופסה הצהובה אומרת לי שיש R, אבל היא לא במצב הזה.

24
00:01:18,340 --> 00:01:21,820
התיבה הירוקה אומרת לי שלמילה הסודית

25
00:01:21,820 --> 00:01:22,820
יש א&#39;, והיא נמצאת במיקום השלישי.

26
00:01:22,820 --> 00:01:24,300
ואז אין N ואין E.

27
00:01:24,300 --> 00:01:27,420
אז תן לי פשוט להיכנס ולספר לבוט הוורדל את המידע הזה.

28
00:01:27,420 --> 00:01:31,500
התחלנו עם מנוף, קיבלנו אפור, צהוב, ירוק, אפור, אפור.

29
00:01:31,500 --> 00:01:35,460
אל תדאג לגבי כל הנתונים שהוא מציג עכשיו, אני אסביר את זה בבוא העת.

30
00:01:35,460 --> 00:01:39,700
אבל ההצעה העיקרית שלה לבחירה השנייה שלנו היא shtick.

31
00:01:39,700 --> 00:01:43,500
והניחוש שלך חייב להיות מילה אמיתית של חמש אותיות, אבל כפי

32
00:01:43,500 --> 00:01:45,700
שתראה, זה די ליברלי עם מה שהוא בעצם יאפשר לך לנחש.

33
00:01:45,700 --> 00:01:48,860
במקרה זה, אנו מנסים shtick.

34
00:01:48,860 --> 00:01:50,260
ובסדר, הדברים נראים די טוב.

35
00:01:50,260 --> 00:01:54,580
פגענו ב-S וב-H, אז אנחנו יודעים את שלוש האותיות הראשונות, אנחנו יודעים שיש R.

36
00:01:54,740 --> 00:01:59,740
וכך זה יהיה כמו ש.א. משהו R, או ש.א.ר משהו.

37
00:01:59,740 --> 00:02:03,200
ונראה שהבוט של Wurdle יודע שזה תלוי

38
00:02:03,200 --> 00:02:05,220
רק בשתי אפשרויות, או רסיס או חד.

39
00:02:05,220 --> 00:02:08,620
זה סוג של הטלה ביניהם בשלב זה, אז אני מניח

40
00:02:08,620 --> 00:02:11,260
שכנראה רק בגלל שהוא אלפביתי זה הולך עם רסיס.

41
00:02:11,260 --> 00:02:13,000
איזה הידד, היא התשובה האמיתית.

42
00:02:13,000 --> 00:02:14,660
אז קיבלנו את זה בשלושה.

43
00:02:14,660 --> 00:02:17,740
אם אתה תוהה אם זה טוב, איך ששמעתי ביטוי של אדם

44
00:02:17,740 --> 00:02:20,820
אחד זה שעם Wurdle ארבע הוא ערך ושלוש הוא ציפורי.

45
00:02:20,820 --> 00:02:22,960
שלדעתי היא אנלוגיה די הולמת.

46
00:02:22,960 --> 00:02:27,560
אתה צריך להיות בעקביות במשחק שלך כדי להשיג ארבע, אבל זה בהחלט לא מטורף.

47
00:02:27,560 --> 00:02:30,000
אבל כשאתה מקבל את זה בשלוש, זה פשוט מרגיש נהדר.

48
00:02:30,000 --> 00:02:33,800
אז אם אתה רוצה לעשות את זה, מה שאני רוצה לעשות כאן זה

49
00:02:33,800 --> 00:02:36,600
פשוט לדבר על תהליך החשיבה שלי מההתחלה איך אני ניגש לבוט Wurdle.

50
00:02:36,600 --> 00:02:39,800
וכמו שאמרתי, באמת שזה תירוץ לשיעור תורת מידע.

51
00:02:39,800 --> 00:02:43,160
המטרה העיקרית היא להסביר מהו מידע ומהי אנטרופיה.

52
00:02:48,560 --> 00:02:52,080
המחשבה הראשונה שלי בגישה לזה הייתה להסתכל על

53
00:02:52,080 --> 00:02:53,560
התדרים היחסיים של אותיות שונות בשפה האנגלית.

54
00:02:53,560 --> 00:02:57,800
אז חשבתי, אוקיי, האם יש ניחוש פתיחה או

55
00:02:57,800 --> 00:02:59,960
צמד ניחושים פתיחה שפוגע בהרבה מהאותיות השכיחות ביותר?

56
00:02:59,960 --> 00:03:03,780
ואחד שדי אהבתי היה לעשות אחר ואחריו ציפורניים.

57
00:03:03,780 --> 00:03:06,980
המחשבה היא שאם אתה מכה באות, אתה יודע, אתה

58
00:03:06,980 --> 00:03:07,980
מקבל ירוק או צהוב, זה תמיד מרגיש טוב.

59
00:03:07,980 --> 00:03:09,460
זה מרגיש כאילו אתה מקבל מידע.

60
00:03:09,460 --> 00:03:13,140
אבל במקרים אלה, גם אם אתה לא מכה ואתה תמיד

61
00:03:13,140 --> 00:03:16,640
מקבל אפור, זה עדיין נותן לך מידע רב מכיוון שזה

62
00:03:16,640 --> 00:03:17,640
די נדיר למצוא מילה שאין בה אף אחת מהאותיות הללו.

63
00:03:17,640 --> 00:03:21,840
אבל אפילו עדיין, זה לא מרגיש סופר שיטתי, כי

64
00:03:21,840 --> 00:03:23,520
למשל, זה לא עושה כלום כדי להתחשב בסדר האותיות.

65
00:03:23,520 --> 00:03:26,080
למה להקליד ציפורניים כשאני יכול להקליד חילזון?

66
00:03:26,080 --> 00:03:27,720
האם עדיף לקבל את ה-S הזה בסוף?

67
00:03:27,720 --> 00:03:28,720
אני לא ממש בטוח.

68
00:03:28,720 --> 00:03:33,500
עכשיו, חבר שלי אמר שהוא אהב לפתוח במילה עייף, מה שדי הפתיע

69
00:03:33,500 --> 00:03:37,160
אותי כי יש בה כמה אותיות לא שכיחות כמו ה-W וה-Y.

70
00:03:37,160 --> 00:03:39,400
אבל מי יודע, אולי זו פתיחה טובה יותר.

71
00:03:39,400 --> 00:03:43,920
האם יש איזשהו ציון כמותי שאנחנו יכולים לתת

72
00:03:43,920 --> 00:03:44,920
כדי לשפוט את האיכות של ניחוש פוטנציאלי?

73
00:03:44,920 --> 00:03:48,640
עכשיו כדי להגדיר את הדרך שבה אנחנו הולכים לדרג ניחושים

74
00:03:48,640 --> 00:03:51,800
אפשריים, בואו נחזור ונוסיף קצת בהירות כיצד בדיוק המשחק מוגדר.

75
00:03:51,800 --> 00:03:55,880
אז יש רשימה של מילים שזה יאפשר לך

76
00:03:55,880 --> 00:03:57,920
להזין שנחשבות לניחושים תקפים שאורכה רק כ-13,000 מילים.

77
00:03:57,920 --> 00:04:01,560
אבל כשמסתכלים על זה, יש הרבה דברים ממש לא שכיחים, דברים כמו

78
00:04:01,560 --> 00:04:07,040
ראש או עלי ו-ARG, מסוג המילים שמביאות לוויכוחים משפחתיים במשחק של Scrabble.

79
00:04:07,040 --> 00:04:10,600
אבל האווירה של המשחק היא שהתשובה תמיד תהיה מילה נפוצה בהחלט.

80
00:04:10,600 --> 00:04:16,080
ולמעשה, יש עוד רשימה של כ-2300 מילים שהן התשובות האפשריות.

81
00:04:16,080 --> 00:04:20,320
וזו רשימה שנאספה על ידי אדם, אני חושב במיוחד

82
00:04:20,320 --> 00:04:21,800
על ידי חברתו של יוצר המשחק, וזה די כיף.

83
00:04:21,800 --> 00:04:25,560
אבל מה שהייתי רוצה לעשות, האתגר שלנו עבור הפרויקט הזה הוא לראות אם

84
00:04:25,560 --> 00:04:30,720
נוכל לכתוב תוכנית לפתרון Wordle שאינה משלבת ידע קודם על רשימה זו.

85
00:04:30,720 --> 00:04:34,560
ראשית, יש הרבה מילים נפוצות למדי של

86
00:04:34,560 --> 00:04:35,560
חמש אותיות שלא תמצאו ברשימה הזו.

87
00:04:35,560 --> 00:04:38,360
אז עדיף לכתוב תוכנית שהיא קצת יותר עמידה ותשחק וורדל

88
00:04:38,360 --> 00:04:41,960
נגד כל אחד, לא רק מה שבמקרה הוא האתר הרשמי.

89
00:04:41,960 --> 00:04:45,900
וגם הסיבה שאנחנו יודעים מהי רשימה זו של

90
00:04:45,900 --> 00:04:47,440
תשובות אפשריות, היא בגלל שהיא גלויה בקוד המקור.

91
00:04:47,440 --> 00:04:51,620
אבל האופן שבו זה נראה בקוד המקור הוא

92
00:04:51,620 --> 00:04:52,840
בסדר הספציפי שבו התשובות עולות מיום ליום.

93
00:04:52,840 --> 00:04:56,400
אז אתה תמיד יכול פשוט לחפש מה תהיה התשובה של מחר.

94
00:04:56,400 --> 00:04:59,140
אז ברור, יש מובן מסוים שהשימוש ברשימה הוא רמאות.

95
00:04:59,140 --> 00:05:02,900
ומה שעושה חידה מעניינת יותר ושיעור תיאוריית מידע עשיר יותר הוא להשתמש

96
00:05:02,900 --> 00:05:07,640
במקום בכמה נתונים אוניברסליים יותר כמו תדרים יחסיים של מילים באופן

97
00:05:07,640 --> 00:05:11,640
כללי כדי ללכוד את האינטואיציה הזו של העדפה למילים נפוצות יותר.

98
00:05:11,640 --> 00:05:16,560
אז מבין 13,000 האפשרויות הללו, איך עלינו לבחור את ניחוש הפתיחה?

99
00:05:16,560 --> 00:05:19,960
לדוגמה, אם חבר שלי מציע נישואים עייפים, כיצד עלינו לנתח את איכותו?

100
00:05:19,960 --> 00:05:25,040
ובכן, הסיבה שהוא אמר שהוא אוהב את ה-W הלא סביר הזה היא שהוא אוהב

101
00:05:25,040 --> 00:05:27,880
את אופי ה-long shot של כמה טוב זה מרגיש אם תפגע ב-W הזה.

102
00:05:27,880 --> 00:05:31,400
לדוגמה, אם הדפוס הראשון שנחשף היה משהו כזה, אז מסתבר שיש

103
00:05:31,400 --> 00:05:36,080
רק 58 מילים בלקסיקון הענק הזה שתואמות את הדפוס הזה.

104
00:05:36,080 --> 00:05:38,900
אז זה הפחתה עצומה מ-13,000.

105
00:05:38,900 --> 00:05:43,320
אבל הצד השני של זה, כמובן, הוא שזה מאוד נדיר לקבל דפוס כזה.

106
00:05:43,360 --> 00:05:47,600
באופן ספציפי, אם כל מילה הייתה בעלת סבירות שווה להיות

107
00:05:47,600 --> 00:05:51,680
התשובה, ההסתברות לפגיעה בתבנית זו תהיה 58 חלקי בערך 13,000.

108
00:05:51,680 --> 00:05:53,880
כמובן, לא סביר להניח שהם יהיו תשובות.

109
00:05:53,880 --> 00:05:56,680
רוב אלו הן מילים מאוד לא ברורות ואפילו מפוקפקות.

110
00:05:56,680 --> 00:05:59,560
אבל לפחות עבור המעבר הראשון שלנו בכל זה, בואו נניח שכולן

111
00:05:59,560 --> 00:06:02,040
סבירות באותה מידה ואז נחדד את זה קצת מאוחר יותר.

112
00:06:02,040 --> 00:06:07,360
הנקודה היא שהדפוס עם הרבה מידע מעצם טבעו לא סביר שיתרחש.

113
00:06:07,360 --> 00:06:11,320
למעשה, המשמעות של להיות אינפורמטיבי הוא שזה לא סביר.

114
00:06:11,920 --> 00:06:16,720
דפוס הרבה יותר סביר לראות עם הפתיחה הזו

115
00:06:16,720 --> 00:06:18,360
יהיה משהו כזה, שבו כמובן אין בו W.

116
00:06:18,360 --> 00:06:22,080
אולי יש E, ואולי אין A, אין R, אין Y.

117
00:06:22,080 --> 00:06:24,640
במקרה זה, יש 1400 התאמות אפשריות.

118
00:06:24,640 --> 00:06:29,600
אם כולם היו סבירים באותה מידה, מסתבר שהסתברות

119
00:06:29,600 --> 00:06:30,680
של כ-11% היא זו הדפוס שהיית רואה.

120
00:06:30,680 --> 00:06:34,320
אז התוצאות הסבירות ביותר הן גם הפחות אינפורמטיביות.

121
00:06:34,320 --> 00:06:38,440
כדי לקבל תצוגה גלובלית יותר כאן, הרשו לי להראות לכם את ההתפלגות

122
00:06:38,440 --> 00:06:42,000
המלאה של ההסתברויות על פני כל הדפוסים השונים שאתם עשויים לראות.

123
00:06:42,000 --> 00:06:46,000
אז כל פס שאתה מסתכל עליו מתאים לתבנית אפשרית של

124
00:06:46,000 --> 00:06:50,500
צבעים שאפשר לחשוף, מתוכם יש 3 עד 5 אפשרויות,

125
00:06:50,500 --> 00:06:52,960
והם מאורגנים משמאל לימין, הנפוצים ביותר עד הפחות נפוצים.

126
00:06:52,960 --> 00:06:56,200
אז האפשרות הנפוצה ביותר כאן היא שאתה מקבל את כל האפורים.

127
00:06:56,200 --> 00:06:58,800
זה קורה בערך 14% מהמקרים.

128
00:06:58,800 --> 00:07:02,040
ומה שאתה מייחל לו כשאתה מנחש זה שאתה בסופו של

129
00:07:02,040 --> 00:07:06,360
דבר איפשהו בזנב הארוך הזה, כמו כאן, שם יש רק

130
00:07:06,360 --> 00:07:09,920
18 אפשרויות למה שתואם את הדפוס הזה שכנראה נראה כך.

131
00:07:09,920 --> 00:07:14,080
או אם נצא קצת יותר שמאלה, אתה יודע, אולי נלך עד לכאן.

132
00:07:14,080 --> 00:07:16,560
אוקיי, הנה חידה טובה בשבילך.

133
00:07:16,560 --> 00:07:20,600
מהן שלוש המילים בשפה האנגלית שמתחילות ב-W,

134
00:07:20,600 --> 00:07:22,040
מסתיימות ב-Y, ויש בהן R איפשהו?

135
00:07:22,040 --> 00:07:27,560
מסתבר שהתשובות הן, בוא נראה, מלאות מילים, תולעות ומתפתלות.

136
00:07:27,560 --> 00:07:32,720
אז כדי לשפוט עד כמה המילה הזו טובה בסך הכל, אנחנו

137
00:07:32,720 --> 00:07:35,720
רוצים איזושהי מידה של כמות המידע הצפויה שתקבלו מההפצה הזו.

138
00:07:36,360 --> 00:07:41,080
אם נעבור על כל דפוס ונכפיל את ההסתברות שלו להתרחש פעמים משהו

139
00:07:41,080 --> 00:07:46,000
שמודד כמה הוא אינפורמטיבי, זה יכול אולי לתת לנו ציון אובייקטיבי.

140
00:07:46,000 --> 00:07:50,280
עכשיו האינסטינקט הראשון שלך לגבי מה המשהו הזה צריך להיות עשוי להיות מספר ההתאמות.

141
00:07:50,280 --> 00:07:52,960
אתה רוצה מספר ממוצע נמוך יותר של התאמות.

142
00:07:52,960 --> 00:07:57,400
אבל במקום זאת, הייתי רוצה להשתמש במדידה אוניברסלית יותר שלעתים קרובות אנו

143
00:07:57,400 --> 00:08:01,040
מייחסים למידע, וכזו שתהיה גמישה יותר ברגע שתוקצו לנו הסתברות שונה

144
00:08:01,040 --> 00:08:04,320
לכל אחת מ-13,000 המילים הללו אם הן באמת התשובה או לא.

145
00:08:10,600 --> 00:08:14,760
יחידת המידע הסטנדרטית היא ה-bit, שיש לה נוסחה קצת מצחיקה,

146
00:08:14,760 --> 00:08:17,800
אבל היא ממש אינטואיטיבית אם רק נסתכל על דוגמאות.

147
00:08:17,800 --> 00:08:21,880
אם יש לך תצפית שחותכת את מרחב האפשרויות שלך

148
00:08:21,880 --> 00:08:24,200
לחצי, אנו אומרים שיש לה פיסת מידע אחת.

149
00:08:24,200 --> 00:08:27,680
בדוגמה שלנו, מרחב האפשרויות הוא כל המילים האפשריות, ומסתבר שבערך למחצית

150
00:08:27,760 --> 00:08:31,560
ממילות חמש האותיות יש S, קצת פחות מזה, אבל בערך חצי.

151
00:08:31,560 --> 00:08:35,200
אז התצפית הזו תיתן לך קצת מידע.

152
00:08:35,200 --> 00:08:39,640
אם במקום זאת עובדה חדשה מקצצת את מרחב האפשרויות הזה

153
00:08:39,640 --> 00:08:42,000
בפקטור של ארבע, אנו אומרים שיש לה שתי פיסות מידע.

154
00:08:42,000 --> 00:08:45,120
לדוגמה, מסתבר שלכרבע מהמילים הללו יש T.

155
00:08:45,120 --> 00:08:49,720
אם התצפית חותכת את החלל הזה בפקטור של שמונה, אנחנו

156
00:08:49,720 --> 00:08:50,920
אומרים שזה שלוש פיסות מידע, וכן הלאה וכן הלאה.

157
00:08:50,920 --> 00:08:55,000
ארבעה ביטים חותכים אותו ל-16, חמישה ביטים חותכים אותו ל-32.

158
00:08:55,000 --> 00:09:00,160
אז עכשיו אולי תרצו לעצור ולשאול את עצמכם, מהי

159
00:09:00,160 --> 00:09:04,520
הנוסחה למידע עבור מספר הביטים מבחינת ההסתברות להתרחשות?

160
00:09:04,520 --> 00:09:07,920
מה שאנחנו אומרים כאן הוא שכאשר אתה לוקח חצי אחד למספר

161
00:09:07,920 --> 00:09:11,680
הסיביות, זה אותו דבר כמו ההסתברות, שזה אותו דבר כמו לומר

162
00:09:11,680 --> 00:09:16,200
שניים בחזקת מספר הסיביות הוא אחד מעל ההסתברות, אשר מסדר מחדש

163
00:09:16,200 --> 00:09:19,680
בהמשך לומר שהמידע הוא בסיס היומן שניים מתוך אחד חלקי ההסתברות.

164
00:09:19,680 --> 00:09:23,200
ולפעמים אתה רואה את זה עם עוד סידור מחדש אחד,

165
00:09:23,200 --> 00:09:25,680
כאשר המידע הוא בסיס היומן השלילי שני של ההסתברות.

166
00:09:25,680 --> 00:09:29,120
בביטוי כך, זה יכול להיראות קצת מוזר למי שלא

167
00:09:29,120 --> 00:09:33,400
יודע מה, אבל זה באמת רק הרעיון האינטואיטיבי של

168
00:09:33,400 --> 00:09:35,120
לשאול כמה פעמים צמצמת את האפשרויות שלך בחצי.

169
00:09:35,120 --> 00:09:37,840
עכשיו אם אתה תוהה, אתה יודע, חשבתי שאנחנו סתם

170
00:09:37,840 --> 00:09:39,920
משחקים משחק מילים מהנה, למה לוגריתמים נכנסים לתמונה?

171
00:09:39,920 --> 00:09:43,920
אחת הסיבות לכך שזו יחידה נחמדה יותר היא שפשוט הרבה יותר קל לדבר

172
00:09:43,920 --> 00:09:48,120
על אירועים מאוד לא סבירים, הרבה יותר קל לומר שלתצפית יש 20

173
00:09:48,120 --> 00:09:53,480
סיביות מידע מאשר לומר שההסתברות להתרחשות כאלה ואחרים היא 0. 0000095.

174
00:09:53,480 --> 00:09:57,360
אבל סיבה מהותית יותר לכך שהביטוי הלוגריתמי הזה התברר כתוספת

175
00:09:57,360 --> 00:10:02,000
שימושית מאוד לתורת ההסתברות היא הדרך שבה מידע מתחבר.

176
00:10:02,000 --> 00:10:05,560
לדוגמה, אם תצפית אחת נותנת לך שתי פיסות מידע, מקצצת את

177
00:10:05,560 --> 00:10:10,120
השטח שלך בארבע, ואז תצפית שנייה כמו הניחוש השני שלך

178
00:10:10,120 --> 00:10:14,480
ב-Wordle נותנת לך עוד שלוש פיסות מידע, ומצמצמת אותך עוד יותר

179
00:10:14,480 --> 00:10:17,360
בפקטור של שמונה, שניים ביחד נותנים לך חמש פיסות מידע.

180
00:10:17,360 --> 00:10:21,200
באותו אופן שבו הסתברויות אוהבות להכפיל, מידע אוהב להוסיף.

181
00:10:21,200 --> 00:10:24,920
אז ברגע שאנחנו נמצאים בתחום של משהו כמו ערך צפוי, שבו אנחנו מוסיפים

182
00:10:24,920 --> 00:10:28,660
חבורה של מספרים, היומנים הופכים את זה להרבה יותר נחמד להתמודד איתו.

183
00:10:28,660 --> 00:10:32,600
בואו נחזור להפצה שלנו עבור Weary ונוסיף עוד עוקב

184
00:10:32,600 --> 00:10:35,560
קטן כאן, שמראה לנו כמה מידע יש לכל דפוס.

185
00:10:35,560 --> 00:10:38,760
הדבר העיקרי שאני רוצה שתשים לב הוא שככל שההסתברות גבוהה יותר כשנגיע

186
00:10:38,760 --> 00:10:43,500
לדפוסים הסבירים האלה, כך המידע נמוך יותר, כך אתה מרוויח פחות ביטים.

187
00:10:43,500 --> 00:10:47,360
הדרך שבה אנו מודדים את האיכות של הניחוש הזה תהיה לקחת את

188
00:10:47,360 --> 00:10:51,620
הערך הצפוי של המידע הזה, שם אנחנו עוברים על כל דפוס, אנחנו

189
00:10:51,620 --> 00:10:54,940
אומרים כמה זה סביר, ואז נכפיל את זה בכמה סיביות מידע נקבל.

190
00:10:54,940 --> 00:10:58,480
ובדוגמה של Weary, מסתבר שזה 4. 9 ביטים.

191
00:10:58,480 --> 00:11:02,800
אז בממוצע, המידע שאתה מקבל מניחוש הפתיחה הזה טוב כמו

192
00:11:02,800 --> 00:11:05,660
לחתוך את מרחב האפשרויות שלך לחצי בערך חמש פעמים.

193
00:11:05,660 --> 00:11:10,260
לעומת זאת, דוגמה לניחוש עם ערך מידע

194
00:11:10,260 --> 00:11:13,220
צפוי גבוה יותר תהיה משהו כמו Slate.

195
00:11:13,220 --> 00:11:16,180
במקרה זה תבחין שההפצה נראית הרבה יותר שטוחה.

196
00:11:16,180 --> 00:11:20,780
בפרט, להתרחשות הסבירה ביותר של כל האפורים יש רק סיכוי של כ-6%

197
00:11:20,780 --> 00:11:25,940
להתרחש, כך שלפחות אתה מקבל כנראה 3. 9 סיביות מידע.

198
00:11:25,940 --> 00:11:29,140
אבל זה מינימום, בדרך כלל תקבל משהו יותר טוב מזה.

199
00:11:29,140 --> 00:11:33,380
ומסתבר שכאשר אתה מכתש את המספרים על זה ומחבר את

200
00:11:33,380 --> 00:11:36,420
כל המונחים הרלוונטיים, המידע הממוצע הוא בערך 5. 8.

201
00:11:36,420 --> 00:11:42,140
אז בניגוד ל-Weary, מרחב האפשרויות שלך יהיה גדול

202
00:11:42,140 --> 00:11:43,940
בערך בחצי לאחר הניחוש הראשון הזה, בממוצע.

203
00:11:43,940 --> 00:11:49,540
למעשה יש סיפור מהנה על השם של הערך הצפוי הזה של כמות מידע.

204
00:11:49,540 --> 00:11:52,580
תורת המידע פותחה על ידי קלוד שאנון, שעבד ב-Bell Labs בשנות

205
00:11:52,580 --> 00:11:57,620
ה-40, אבל הוא דיבר על כמה מהרעיונות שלו שטרם פורסמו

206
00:11:57,620 --> 00:12:01,500
עם ג&#39;ון פון נוימן, שהיה הענק האינטלקטואלי הזה של אותה תקופה,

207
00:12:01,500 --> 00:12:04,180
בולט מאוד. במתמטיקה ובפיזיקה ותחילתו של מה שהפך למדעי המחשב.

208
00:12:04,180 --> 00:12:07,260
וכשהזכיר שאין לו שם טוב לערך הצפוי הזה של

209
00:12:07,260 --> 00:12:12,540
כמות מידע, כביכול פון נוימן אמר, אז הסיפור

210
00:12:12,540 --> 00:12:14,720
אומר, ובכן כדאי לקרוא לזה אנטרופיה, ומשתי סיבות.

211
00:12:14,720 --> 00:12:18,400
מלכתחילה, פונקציית אי הוודאות שלך שימשה במכניקה סטטיסטית תחת השם הזה, אז

212
00:12:18,400 --> 00:12:23,100
כבר יש לה שם, ובמקום השני, ויותר חשוב, אף אחד לא

213
00:12:23,100 --> 00:12:26,940
יודע מהי באמת אנטרופיה, אז בוויכוח אתה תמיד יש את היתרון.

214
00:12:26,940 --> 00:12:31,420
אז אם השם נראה קצת מסתורי, ואם אפשר

215
00:12:31,420 --> 00:12:33,420
להאמין לסיפור הזה, זה סוג של תכנון.

216
00:12:33,420 --> 00:12:36,740
כמו כן, אם אתה תוהה לגבי הקשר שלו לכל החומר

217
00:12:36,740 --> 00:12:40,820
השני של החוק השני של התרמודינמיקה מהפיזיקה, בהחלט יש

218
00:12:40,820 --> 00:12:44,780
קשר, אבל במקורותיו שאנון עסק רק בתורת ההסתברות הטהורה, ולמטרותינו

219
00:12:44,780 --> 00:12:49,340
כאן, כשאני משתמש ב- אנטרופיה של מילים, אני רק

220
00:12:49,340 --> 00:12:50,820
רוצה שתחשוב על ערך המידע הצפוי של ניחוש מסוים.

221
00:12:50,820 --> 00:12:54,380
אתה יכול לחשוב על אנטרופיה כמדידת שני דברים בו זמנית.

222
00:12:54,380 --> 00:12:57,420
הראשון הוא עד כמה שטוחה ההתפלגות.

223
00:12:57,420 --> 00:13:01,700
ככל שהתפלגות קרובה יותר לאחידות, כך האנטרופיה תהיה גבוהה יותר.

224
00:13:01,700 --> 00:13:06,340
במקרה שלנו, כאשר יש 3 עד ה-5 דפוסים הכוללים, עבור התפלגות אחידה, צפייה בכל

225
00:13:06,340 --> 00:13:11,340
אחד מהם תהיה בסיס יומן מידע 2 מתוך 3 עד ה-5, שהוא במקרה

226
00:13:11,340 --> 00:13:17,860
7. 92, אז זה המקסימום המוחלט שיכול להיות לך עבור האנטרופיה הזו.

227
00:13:17,860 --> 00:13:21,900
אבל אנטרופיה היא גם סוג של

228
00:13:21,900 --> 00:13:22,900
מדד לכמה אפשרויות יש מלכתחילה.

229
00:13:22,900 --> 00:13:26,980
לדוגמה, אם במקרה יש לך מילה כלשהי שבה יש רק 16 דפוסים אפשריים,

230
00:13:26,980 --> 00:13:32,760
וכל אחת מהן בסבירות שווה, האנטרופיה הזו, המידע הצפוי הזה, תהיה 4 סיביות.

231
00:13:32,760 --> 00:13:36,880
אבל אם יש לך מילה אחרת שבה יש 64 דפוסים אפשריים שיכולים

232
00:13:36,880 --> 00:13:41,000
להופיע, וכולם סבירים באותה מידה, אז האנטרופיה תסתבר להיות 6 סיביות.

233
00:13:41,000 --> 00:13:45,800
אז אם אתה רואה איזושהי התפלגות בטבע שיש לה אנטרופיה של

234
00:13:45,800 --> 00:13:50,000
6 ביטים, זה בערך כאילו זה אומר שיש שונות וחוסר ודאות

235
00:13:50,000 --> 00:13:54,400
במה שעומד לקרות כאילו היו 64 תוצאות סבירות באותה מידה.

236
00:13:54,400 --> 00:13:58,360
עבור המעבר הראשון שלי ב-Wurtelebot, בעצם הייתי צריך לעשות את זה.

237
00:13:58,360 --> 00:14:03,560
הוא עובר על כל הניחושים האפשריים שיכולים להיות לך, כל 13,000 המילים, מחשב

238
00:14:03,560 --> 00:14:08,580
את האנטרופיה עבור כל אחת, או ליתר דיוק, את האנטרופיה של ההתפלגות

239
00:14:08,580 --> 00:14:13,040
על פני כל הדפוסים שאתה עשוי לראות, עבור כל אחת, ובוחר את הגבוהה

240
00:14:13,040 --> 00:14:17,200
ביותר, מכיוון שזהו זה שצפוי לקצץ את מרחב האפשרויות שלך ככל האפשר.

241
00:14:17,200 --> 00:14:20,120
ולמרות שדיברתי רק על הניחוש הראשון כאן, זה

242
00:14:20,120 --> 00:14:21,680
עושה את אותו הדבר עבור הניחושים הבאים.

243
00:14:21,680 --> 00:14:25,100
לדוגמה, לאחר שתראה דפוס כלשהו בניחוש הראשון הזה, שיגביל אותך למספר

244
00:14:25,100 --> 00:14:29,300
קטן יותר של מילים אפשריות בהתבסס על מה שמתאים לזה, אתה

245
00:14:29,300 --> 00:14:32,300
פשוט משחק באותו משחק ביחס לאותה קבוצה קטנה יותר של מילים.

246
00:14:32,300 --> 00:14:36,500
לניחוש שני מוצע, אתה מסתכל על ההתפלגות של כל הדפוסים

247
00:14:36,500 --> 00:14:41,540
שיכולים להתרחש מאותה קבוצה מוגבלת יותר של מילים, אתה מחפש

248
00:14:41,540 --> 00:14:45,480
בכל 13,000 האפשרויות, ומוצא את זו שממקסמת את האנטרופיה הזו.

249
00:14:45,480 --> 00:14:48,980
כדי להראות לכם איך זה עובד בפעולה, הרשו לי רק להעלות גרסה

250
00:14:48,980 --> 00:14:54,060
קטנה של Wurtele שכתבתי שמראה את הדגשים של הניתוח הזה בשוליים.

251
00:14:54,460 --> 00:14:57,820
לאחר ביצוע כל חישובי האנטרופיה שלו, מימין כאן הוא מראה

252
00:14:57,820 --> 00:15:00,340
לנו למי מהם יש את המידע הצפוי הגבוה ביותר.

253
00:15:00,340 --> 00:15:04,940
מסתבר שהתשובה העליונה, לפחות כרגע, נחדד את זה בהמשך,

254
00:15:04,940 --> 00:15:11,140
היא טארס, שפירושו, אממ, כמובן, בקיה, הקיבה הנפוצה ביותר.

255
00:15:11,140 --> 00:15:14,180
בכל פעם שאנחנו מנחשים כאן, איפה אולי אני קצת מתעלם מההמלצות שלו

256
00:15:14,180 --> 00:15:19,220
והולך עם צפחה, כי אני אוהב צפחה, אנחנו יכולים לראות כמה

257
00:15:19,220 --> 00:15:23,300
מידע צפוי היה לו, אבל אז בצד ימין של המילה כאן

258
00:15:23,340 --> 00:15:24,980
זה מראה לנו כמה מידע אמיתי שקיבלנו, בהתחשב בדפוס הספציפי הזה.

259
00:15:24,980 --> 00:15:28,660
אז כאן זה נראה כאילו היה לנו קצת חסר מזל, היה צפוי לנו לקבל 5. 8, אבל

260
00:15:28,660 --> 00:15:30,660
במקרה קיבלנו משהו עם פחות מזה.

261
00:15:30,660 --> 00:15:34,020
ואז בצד שמאל כאן זה מראה לכולנו את

262
00:15:34,020 --> 00:15:35,860
המילים האפשריות השונות שבהן אנחנו נמצאים עכשיו.

263
00:15:35,860 --> 00:15:39,820
הפסים הכחולים אומרים לנו עד כמה הוא חושב שכל מילה היא, אז כרגע זה

264
00:15:39,820 --> 00:15:44,140
מניח שכל מילה בסבירות שווה להתרחש, אבל אנחנו נחדד את זה בעוד רגע.

265
00:15:44,140 --> 00:15:48,580
ואז מדידת אי הוודאות הזו אומרת לנו את האנטרופיה של

266
00:15:48,580 --> 00:15:53,220
ההתפלגות הזו על פני המילים האפשריות, שכרגע, מכיוון שזו התפלגות

267
00:15:53,300 --> 00:15:55,940
אחידה, היא רק דרך מסובכת מיותרת לספור את מספר האפשרויות.

268
00:15:55,940 --> 00:16:01,700
לדוגמה, אם היינו לוקחים 2 בחזקת 13. 66, זה אמור

269
00:16:01,700 --> 00:16:02,700
להיות בסביבות 13,000 האפשרויות.

270
00:16:02,700 --> 00:16:06,780
אני קצת בחוץ כאן, אבל רק בגלל שאני לא מראה את כל האותיות העשרוניות.

271
00:16:06,780 --> 00:16:10,260
כרגע זה עשוי להרגיש מיותר וכאילו זה מסבך דברים מדי, אבל

272
00:16:10,260 --> 00:16:12,780
אתה תראה למה זה שימושי להחזיק את שני המספרים תוך דקה.

273
00:16:12,780 --> 00:16:16,780
אז כאן זה נראה כאילו זה מרמז על האנטרופיה הגבוהה ביותר עבור

274
00:16:16,780 --> 00:16:19,700
הניחוש השני שלנו הוא ראמן, ששוב ממש לא מרגיש כמו מילה.

275
00:16:19,700 --> 00:16:25,660
אז כדי לקחת את הרמה המוסרית כאן, אני מתכוון להמשיך ולהקליד את Rains.

276
00:16:25,660 --> 00:16:27,540
ושוב זה נראה כאילו היה לנו קצת חסר מזל.

277
00:16:27,540 --> 00:16:32,100
ציפינו ל-4. 3 ביטים וקיבלנו רק 3. 39 סיביות מידע.

278
00:16:32,100 --> 00:16:35,060
אז זה מוריד אותנו ל-55 אפשרויות.

279
00:16:35,060 --> 00:16:38,860
וכאן אולי אני פשוט אלך עם מה שזה

280
00:16:38,860 --> 00:16:40,200
מציע, שזה שילוב, מה שזה לא אומר.

281
00:16:40,200 --> 00:16:43,300
ובסדר, זו בעצם הזדמנות טובה לפאזל.

282
00:16:43,300 --> 00:16:47,020
זה אומר לנו שהדפוס הזה נותן לנו 4. 7 סיביות מידע.

283
00:16:47,020 --> 00:16:52,400
אבל בצד שמאל, לפני שאנחנו רואים את הדפוס הזה, היו 5. 78 פיסות של אי ודאות.

284
00:16:52,400 --> 00:16:56,860
אז בתור חידון בשבילך, מה זה אומר לגבי מספר האפשרויות שנותרו?

285
00:16:56,860 --> 00:17:02,280
ובכן, זה אומר שאנחנו מצטמצמים לחלק אחד של אי ודאות,

286
00:17:02,280 --> 00:17:04,700
וזה אותו דבר כמו לומר שיש שתי תשובות אפשריות.

287
00:17:04,700 --> 00:17:06,520
זו בחירה של 50-50.

288
00:17:06,520 --> 00:17:09,860
ומכאן, בגלל שאתה ואני יודעים אילו מילים נפוצות

289
00:17:09,860 --> 00:17:11,220
יותר, אנחנו יודעים שהתשובה צריכה להיות תהום.

290
00:17:11,220 --> 00:17:13,540
אבל כמו שזה נכתב עכשיו, התוכנית לא יודעת את זה.

291
00:17:13,540 --> 00:17:17,560
אז זה פשוט ממשיך, מנסה להשיג כמה שיותר מידע, עד

292
00:17:17,560 --> 00:17:20,360
שנותרה רק אפשרות אחת, ואז הוא מנחש את זה.

293
00:17:20,360 --> 00:17:22,700
אז ברור שאנחנו צריכים אסטרטגיית סוף משחק טובה יותר.

294
00:17:22,700 --> 00:17:26,540
אבל נניח שאנחנו קוראים לגרסה הזו אחת מפותרי המילים שלנו, ואז

295
00:17:26,540 --> 00:17:30,740
אנחנו הולכים ומריצים כמה סימולציות כדי לראות איך זה עובד.

296
00:17:30,740 --> 00:17:34,240
אז הדרך שבה זה עובד היא שהוא משחק בכל משחק מילים אפשרי.

297
00:17:34,240 --> 00:17:38,780
זה עובר על כל 2315 המילים האלה שהן התשובות המילוליות בפועל.

298
00:17:38,780 --> 00:17:41,340
זה בעצם משתמש בזה כמערכת בדיקות.

299
00:17:41,340 --> 00:17:45,820
ועם השיטה הנאיבית הזו של לא להתחשב עד כמה מילה נפוצה, ורק לנסות

300
00:17:45,820 --> 00:17:50,480
למקסם את המידע בכל שלב בדרך, עד שהוא מגיע לבחירה אחת ויחידה.

301
00:17:50,480 --> 00:17:55,100
בסוף הסימולציה, הציון הממוצע מתברר כ-4. 124.

302
00:17:55,100 --> 00:17:59,780
וזה לא רע, למען האמת, די ציפיתי לעשות יותר גרוע.

303
00:17:59,780 --> 00:18:03,040
אבל האנשים שמנגנים wordle יגידו לך שבדרך כלל הם יכולים להשיג את זה ב-4.

304
00:18:03,040 --> 00:18:05,260
האתגר האמיתי הוא להשיג כמה שיותר ב-3.

305
00:18:05,260 --> 00:18:08,920
זה קפיצה די גדולה בין הציון 4 לציון 3.

306
00:18:08,920 --> 00:18:13,300
הפרי התלוי הנמוך כאן הוא איכשהו לשלב האם מילה

307
00:18:13,300 --> 00:18:23,160
נפוצה או לא, ואיך בדיוק אנחנו עושים את זה.

308
00:18:23,160 --> 00:18:26,860
הדרך שבה ניגשתי היא לקבל רשימה של

309
00:18:26,860 --> 00:18:28,560
התדרים היחסיים של כל המילים בשפה האנגלית.

310
00:18:28,560 --> 00:18:32,560
והרגע השתמשתי בפונקציית נתוני תדירות המילים של Mathematica, שבעצמה

311
00:18:32,560 --> 00:18:35,520
שואבת ממאגר הנתונים הציבורי של Google Books English Ngram.

312
00:18:35,520 --> 00:18:38,680
וזה די כיף להסתכל עליו, למשל אם נמיין

313
00:18:38,680 --> 00:18:40,120
את זה מהמילים הנפוצות ביותר למילים הפחות נפוצות.

314
00:18:40,120 --> 00:18:43,740
ברור שאלו הן המילים הנפוצות ביותר, 5 אותיות בשפה האנגלית.

315
00:18:43,740 --> 00:18:46,480
או ליתר דיוק, אלו הם ה-8 הנפוצים ביותר.

316
00:18:46,480 --> 00:18:49,440
ראשון זה איזה, אחרי זה יש שם ושם.

317
00:18:49,440 --> 00:18:53,020
הראשון עצמו הוא לא הראשון, אלא התשיעי, והגיוני שהמילים האחרות

318
00:18:53,020 --> 00:18:57,840
הללו יכולות להופיע לעתים קרובות יותר, כאשר אלה שאחרי

319
00:18:57,840 --> 00:18:59,000
הראשונים הם אחרי, איפה, ואלו רק קצת פחות נפוצות.

320
00:18:59,000 --> 00:19:04,400
כעת, בשימוש בנתונים האלה כדי להדגים את הסבירות שכל אחת מהמילים

321
00:19:04,400 --> 00:19:06,760
הללו תהיה התשובה הסופית, היא לא צריכה להיות רק פרופורציונלית לתדירות.

322
00:19:07,020 --> 00:19:12,560
למשל, שניתן לו ציון 0. 002 במערך הנתונים הזה, בעוד

323
00:19:12,560 --> 00:19:15,200
שהמילה צמה היא בסבירות מסוימת פי 1000 פחות.

324
00:19:15,200 --> 00:19:19,400
אבל שתיהן מילים מספיק נפוצות שכדאי לשקול אותן.

325
00:19:19,400 --> 00:19:21,900
אז אנחנו רוצים יותר חתך בינארי.

326
00:19:21,900 --> 00:19:26,520
הדרך שבה הלכתי היא לדמיין לקחת את כל הרשימה הממוינת הזו של מילים,

327
00:19:26,520 --> 00:19:31,060
ואז לסדר אותה על ציר x, ואז להחיל את הפונקציה הסיגמואידית, שהיא

328
00:19:31,060 --> 00:19:35,540
הדרך הסטנדרטית לקבל פונקציה שהפלט שלה הוא בעצם בינארי, זה או 0

329
00:19:35,540 --> 00:19:38,500
או שזה 1, אבל יש החלקה ביניהם לאזור זה של אי ודאות.

330
00:19:38,500 --> 00:19:43,900
אז בעצם, ההסתברות שאני מקצה לכל מילה להימצאות ברשימה הסופית תהיה הערך

331
00:19:43,900 --> 00:19:49,540
של הפונקציה הסיגמואידית למעלה בכל מקום שבו היא ממוקמת על ציר ה-x.

332
00:19:49,540 --> 00:19:53,940
עכשיו ברור שזה תלוי בכמה פרמטרים, למשל כמה רחב הרווח בציר ה-x

333
00:19:53,940 --> 00:19:59,660
ממלאות המילים האלה קובע באיזו הדרגתית או תלולה אנחנו יורדים מ-1

334
00:19:59,660 --> 00:20:03,000
ל-0, והמקום שבו אנחנו ממקמים אותן משמאל לימין קובע את החתך.

335
00:20:03,160 --> 00:20:07,340
למען האמת, הדרך שעשיתי את זה הייתה פשוט ללקק את האצבע שלי ולהכניס אותה לרוח.

336
00:20:07,340 --> 00:20:10,800
עיינתי ברשימה הממוינת וניסיתי למצוא חלון שבו כשהסתכלתי

337
00:20:10,800 --> 00:20:15,280
עליו הבנתי שכמחצית מהמילים האלה צפויות יותר מאשר

338
00:20:15,280 --> 00:20:17,680
לא להיות התשובה הסופית, והשתמשתי בזה בתור החתך.

339
00:20:17,680 --> 00:20:21,840
ברגע שיש לנו התפלגות כזו בין המילים, זה נותן לנו

340
00:20:21,840 --> 00:20:24,460
מצב נוסף שבו האנטרופיה הופכת למדידה ממש שימושית זו.

341
00:20:24,460 --> 00:20:28,480
לדוגמה, נניח ששיחקנו משחק ונתחיל עם הפותחים הישנים

342
00:20:28,480 --> 00:20:32,480
שלי, שהיו נוצה ומסמרים, ובסופו של דבר יש

343
00:20:32,480 --> 00:20:33,760
מצב שיש ארבע מילים אפשריות שמתאימות לזה.

344
00:20:33,760 --> 00:20:36,440
ונניח שאנו רואים בכולם סבירים באותה מידה.

345
00:20:36,440 --> 00:20:40,000
הרשו לי לשאול אתכם, מהי האנטרופיה של התפלגות זו?

346
00:20:40,000 --> 00:20:45,920
ובכן, המידע הקשור לכל אחת מהאפשרויות הללו יהיה בסיס היומן 2

347
00:20:45,920 --> 00:20:50,800
מתוך 4, מכיוון שכל אחד מהם הוא 1 ו-4, וזה 2.

348
00:20:50,800 --> 00:20:52,780
שתי פיסות מידע, ארבע אפשרויות.

349
00:20:52,780 --> 00:20:54,360
הכל טוב מאוד וטוב.

350
00:20:54,360 --> 00:20:58,320
אבל מה אם אגיד לך שבעצם יש יותר מארבע גפרורים?

351
00:20:58,320 --> 00:21:02,600
במציאות, כשאנחנו מסתכלים ברשימת המילים המלאה, יש 16 מילים שמתאימות לה.

352
00:21:02,600 --> 00:21:07,260
אבל נניח שהמודל שלנו שם סבירות ממש נמוכה ל-12 המילים האחרות האלה להיות

353
00:21:07,260 --> 00:21:11,440
למעשה התשובה הסופית, משהו כמו 1 ל-1000 כי הן ממש לא ברורות.

354
00:21:11,440 --> 00:21:15,480
עכשיו הרשו לי לשאול אתכם, מהי האנטרופיה של התפלגות זו?

355
00:21:15,480 --> 00:21:19,600
אם האנטרופיה מדדה אך ורק את מספר ההתאמות כאן, אז אתה עשוי

356
00:21:19,600 --> 00:21:24,760
לצפות שזה יהיה משהו כמו בסיס היומן 2 מתוך 16, שיהיה

357
00:21:24,760 --> 00:21:26,200
4, שתי פיסות יותר של אי ודאות ממה שהיה לנו קודם.

358
00:21:26,200 --> 00:21:30,320
אבל כמובן שאי הוודאות בפועל לא באמת שונה ממה שהיה לנו קודם.

359
00:21:30,320 --> 00:21:33,840
רק בגלל שיש את 12 המילים המעורפלות האלה לא אומר שזה

360
00:21:33,840 --> 00:21:38,200
יהיה כל כך מפתיע ללמוד שהתשובה הסופית היא קסם, למשל.

361
00:21:38,200 --> 00:21:42,080
אז כאשר אתה באמת עושה את החישוב כאן, ואתה מחבר את ההסתברות של

362
00:21:42,080 --> 00:21:45,960
כל התרחשות כפול המידע המתאים, מה שאתה מקבל הוא 2. 11 ביטים.

363
00:21:45,960 --> 00:21:50,280
אני רק אומר, זה בעצם שני ביטים, בעצם ארבע האפשרויות האלה,

364
00:21:50,280 --> 00:21:54,240
אבל יש קצת יותר אי ודאות בגלל כל האירועים הבלתי סבירים

365
00:21:54,240 --> 00:21:57,120
האלה, אם כי אם תלמד אותם היית מקבל מזה המון מידע.

366
00:21:57,120 --> 00:22:00,800
אז בהתקרבות, זה חלק ממה שהופך את Wordle

367
00:22:00,800 --> 00:22:01,800
לדוגמא כל כך נחמדה לשיעור תורת מידע.

368
00:22:01,800 --> 00:22:05,280
יש לנו את שני יישומי ההרגשה המובהקים הללו עבור אנטרופיה.

369
00:22:05,280 --> 00:22:09,640
הראשון אומר לנו מה המידע הצפוי שנקבל מניחוש

370
00:22:09,640 --> 00:22:14,560
נתון, והשני אומר האם נוכל למדוד את

371
00:22:14,560 --> 00:22:16,480
אי הוודאות שנותרה בין כל המילים האפשריות.

372
00:22:16,480 --> 00:22:19,800
ואני צריך להדגיש, במקרה הראשון שבו אנחנו מסתכלים על המידע הצפוי של ניחוש,

373
00:22:19,800 --> 00:22:25,000
ברגע שיש לנו שקלול לא שווה למילים, זה משפיע על חישוב האנטרופיה.

374
00:22:25,000 --> 00:22:28,600
לדוגמה, הרשו לי להעלות את אותו מקרה שבדקנו קודם

375
00:22:28,600 --> 00:22:33,560
לכן של התפלגות הקשורה ל-Weary, אבל הפעם באמצעות

376
00:22:33,560 --> 00:22:34,560
התפלגות לא אחידה על פני כל המילים האפשריות.

377
00:22:34,560 --> 00:22:39,360
אז תן לי לראות אם אני יכול למצוא כאן חלק שממחיש את זה די טוב.

378
00:22:39,360 --> 00:22:42,480
אוקיי, כאן זה די טוב.

379
00:22:42,480 --> 00:22:46,360
כאן יש לנו שני דפוסים צמודים שסבירים בערך באותה מידה, אבל

380
00:22:46,360 --> 00:22:49,480
לאחד מהם נאמר לנו יש 32 מילים אפשריות שתואמות לה.

381
00:22:49,480 --> 00:22:54,080
ואם נבדוק מה הם, אלה 32 אלה, שכולן פשוט מילים

382
00:22:54,080 --> 00:22:55,600
מאוד לא סבירות כשאתה סורק את העיניים שלך מעליהן.

383
00:22:55,600 --> 00:23:00,400
קשה למצוא כאלה שמרגישות כמו תשובות סבירות, אולי צעקות,

384
00:23:00,400 --> 00:23:04,440
אבל אם נסתכל על התבנית השכנה בהתפלגות, שנחשבת כסבירה

385
00:23:04,440 --> 00:23:08,920
בערך, נאמר לנו שיש לה רק 8 התאמות אפשריות,

386
00:23:08,920 --> 00:23:09,920
אז רבע התאמות רבות, אבל זה סביר בערך.

387
00:23:09,920 --> 00:23:12,520
וכשאנחנו מוציאים את הגפרורים האלה, אנחנו יכולים לראות למה.

388
00:23:12,520 --> 00:23:17,840
חלק מהן תשובות סבירות ממש, כמו צלצול, או זעם, או ראפ.

389
00:23:17,840 --> 00:23:22,000
כדי להמחיש כיצד אנו משלבים את כל זה, הרשו לי להעלות כאן את

390
00:23:22,000 --> 00:23:25,960
גרסה 2 של ה-Wordlebot, ויש שניים או שלושה הבדלים עיקריים מהראשון שראינו.

391
00:23:25,960 --> 00:23:29,460
ראשית, כמו שאמרתי זה עתה, הדרך שבה אנו מחשבים את האנטרופיות

392
00:23:29,460 --> 00:23:34,800
הללו, הערכים הצפויים של המידע, משתמשת כעת בהתפלגות המעודנות יותר על

393
00:23:34,800 --> 00:23:39,300
פני הדפוסים שמשלבת את ההסתברות שמילה נתונה תהיה למעשה התשובה.

394
00:23:39,300 --> 00:23:44,160
כפי שזה קורה, הדמעות עדיין מספר 1, אם כי אלה שאחריו קצת שונים.

395
00:23:44,160 --> 00:23:47,920
שנית, כאשר היא תדרג את הבחירות המובילות שלה, היא עתידה לשמור מודל

396
00:23:47,920 --> 00:23:52,600
של ההסתברות שכל מילה היא התשובה האמיתית, והיא תשלב זאת בהחלטה שלה,

397
00:23:52,600 --> 00:23:55,520
שקל יותר לראות אותה ברגע שיש לנו כמה ניחושים על שולחן.

398
00:23:55,520 --> 00:24:01,120
שוב, מתעלמים מהמלצתו כי אנחנו לא יכולים לתת למכונות לשלוט בחיינו.

399
00:24:01,120 --> 00:24:05,160
ואני מניח שעלי להזכיר עוד דבר שונה כאן משמאל, שערך אי הוודאות,

400
00:24:05,160 --> 00:24:10,080
מספר הביטים הזה, כבר לא רק מיותר עם מספר ההתאמות האפשריות.

401
00:24:10,080 --> 00:24:16,520
עכשיו אם נמשוך אותו למעלה ונחשב 2 ל-8. 02, שזה קצת מעל 256, אני

402
00:24:16,520 --> 00:24:22,640
מניח 259, מה שזה אומר זה למרות שיש 526 מילים

403
00:24:22,640 --> 00:24:26,400
בסך הכל שמתאימות לדפוס הזה, כמות אי הוודאות שיש לה דומה

404
00:24:26,400 --> 00:24:29,760
יותר למה שהיא הייתה אם היו 259 בסבירות שווה תוצאות.

405
00:24:29,760 --> 00:24:31,100
אתה יכול לחשוב על זה ככה.

406
00:24:31,100 --> 00:24:35,560
הוא יודע שבורקס הוא לא התשובה, אותו דבר עם יורט וזורל

407
00:24:35,560 --> 00:24:37,840
וזרוס, אז זה קצת פחות לא ודאי ממה שהיה במקרה הקודם.

408
00:24:37,840 --> 00:24:40,220
מספר ביטים זה יהיה קטן יותר.

409
00:24:40,220 --> 00:24:44,040
ואם אני ממשיך לשחק את המשחק, אני מחדד את זה

410
00:24:44,040 --> 00:24:48,680
עם כמה ניחושים שהם בהתאם למה שהייתי רוצה להסביר כאן.

411
00:24:48,680 --> 00:24:52,520
לפי הניחוש הרביעי, אם תסתכלו על הבחירות המובילות שלה,

412
00:24:52,520 --> 00:24:53,800
תוכלו לראות שזה כבר לא רק ממקסם את האנטרופיה.

413
00:24:53,800 --> 00:24:58,480
אז בשלב זה, מבחינה טכנית יש שבע אפשרויות,

414
00:24:58,480 --> 00:25:00,780
אבל היחידות עם סיכוי משמעותי הן מעונות ומילים.

415
00:25:00,780 --> 00:25:04,760
ואתה יכול לראות את הבחירה בשני אלה מעל כל

416
00:25:04,760 --> 00:25:07,560
הערכים האחרים האלה, שבאופן קפדני ייתן יותר מידע.

417
00:25:07,560 --> 00:25:11,200
בפעם הראשונה שעשיתי את זה, פשוט הוספתי את שני המספרים האלה כדי למדוד

418
00:25:11,200 --> 00:25:14,580
את האיכות של כל ניחוש, שלמעשה עבד טוב יותר ממה שאתה עשוי לחשוד.

419
00:25:14,580 --> 00:25:17,600
אבל זה ממש לא הרגיש שיטתי, ואני בטוח שיש עוד

420
00:25:17,600 --> 00:25:19,880
גישות שאנשים יכולים לנקוט אבל הנה זו שנחתתי עליה.

421
00:25:19,880 --> 00:25:24,200
אם אנחנו שוקלים את הסיכוי לניחוש הבא, כמו במקרה הזה מילים, מה שבאמת

422
00:25:24,200 --> 00:25:28,440
אכפת לנו הוא הציון הצפוי של המשחק שלנו אם נעשה את זה.

423
00:25:28,440 --> 00:25:32,880
וכדי לחשב את הציון הצפוי הזה, אנחנו אומרים מה ההסתברות

424
00:25:32,880 --> 00:25:35,640
שמילים הן התשובה בפועל, שכרגע היא מתארת לה 58%.

425
00:25:36,080 --> 00:25:40,400
אנחנו אומרים שעם סיכוי של 58%, הציון שלנו במשחק הזה יהיה 4.

426
00:25:40,400 --> 00:25:46,240
ואז עם הסתברות של 1 פחות 58%, הציון שלנו יהיה יותר מ-4.

427
00:25:46,240 --> 00:25:50,640
כמה עוד אנחנו לא יודעים, אבל אנחנו יכולים להעריך את זה

428
00:25:50,640 --> 00:25:52,920
על סמך כמה אי ודאות צפויה להיות ברגע שנגיע לנקודה הזו.

429
00:25:52,920 --> 00:25:56,600
ספציפית, כרגע יש 1. 44 פיסות של אי ודאות.

430
00:25:56,600 --> 00:26:01,560
אם ננחש מילים, זה אומר לנו שהמידע הצפוי שנקבל הוא 1. 27 ביטים.

431
00:26:01,560 --> 00:26:06,280
אז אם ננחש מילים, ההבדל הזה מייצג כמה

432
00:26:06,280 --> 00:26:08,280
חוסר ודאות סביר שנישאר עם אחרי שזה יקרה.

433
00:26:08,280 --> 00:26:12,500
מה שאנחנו צריכים זה איזושהי פונקציה, שאני קורא לה

434
00:26:12,500 --> 00:26:13,880
כאן, שקושרת את אי הוודאות הזו עם ציון צפוי.

435
00:26:13,880 --> 00:26:18,040
והדרך שבה זה התנהל הייתה פשוט לשרטט חבורה של נתונים ממשחקים קודמים

436
00:26:18,040 --> 00:26:23,920
המבוססים על גרסה 1 של הבוט כדי לומר היי מה היה הציון

437
00:26:23,920 --> 00:26:27,040
בפועל אחרי נקודות שונות עם כמויות מסוימות מאוד מדידות של אי ודאות.

438
00:26:27,040 --> 00:26:31,120
לדוגמה, נקודות הנתונים האלה כאן שנמצאות מעל ערך שהוא בערך כמו 8. 7

439
00:26:31,120 --> 00:26:36,840
בערך אומרים על כמה משחקים אחרי נקודה שבה היו 8. 7 פיסות של

440
00:26:36,840 --> 00:26:39,340
אי ודאות, נדרשו שני ניחושים כדי לקבל את התשובה הסופית.

441
00:26:39,340 --> 00:26:43,180
למשחקים אחרים נדרשו שלושה ניחושים, למשחקים אחרים נדרשו ארבעה ניחושים.

442
00:26:43,180 --> 00:26:46,920
אם נעבור שמאלה כאן, כל הנקודות מעל האפס אומרות בכל פעם

443
00:26:46,920 --> 00:26:51,620
שיש אפס פיסות של אי ודאות, כלומר יש רק אפשרות אחת,

444
00:26:51,620 --> 00:26:55,000
אז מספר הניחושים הנדרש הוא תמיד רק אחד, וזה מרגיע.

445
00:26:55,000 --> 00:26:59,020
בכל פעם שהייתה קצת אי ודאות, כלומר זה היה

446
00:26:59,020 --> 00:27:02,360
בעצם רק בשתי אפשרויות, אז לפעמים זה דרש עוד

447
00:27:02,360 --> 00:27:03,940
ניחוש אחד, לפעמים זה דרש שני ניחושים נוספים.

448
00:27:03,940 --> 00:27:05,980
וכן הלאה וכן הלאה כאן.

449
00:27:05,980 --> 00:27:11,020
אולי דרך קצת יותר קלה לדמיין את הנתונים האלה היא לרכז אותם יחד ולקחת ממוצעים.

450
00:27:11,020 --> 00:27:15,940
לדוגמה, הסרגל הזה אומר שבין כל הנקודות שבהן היה לנו קצת

451
00:27:15,940 --> 00:27:22,420
אי ודאות, בממוצע מספר הניחושים החדשים הנדרשים היה בערך 1. 5.

452
00:27:22,420 --> 00:27:25,920
והסרגל כאן אומר בין כל המשחקים השונים שבו בשלב

453
00:27:25,920 --> 00:27:30,480
מסוים חוסר הוודאות היה קצת מעל ארבע ביטים, שזה

454
00:27:30,480 --> 00:27:35,120
כמו לצמצם אותו ל-16 אפשרויות שונות, אז בממוצע זה

455
00:27:35,120 --> 00:27:36,240
דורש קצת יותר משני ניחושים מאותה נקודה קָדִימָה.

456
00:27:36,240 --> 00:27:40,080
ומכאן פשוט עשיתי רגרסיה כדי להתאים לפונקציה שנראתה סבירה לזה.

457
00:27:40,080 --> 00:27:44,160
ותזכרו שכל העניין בעשיית כל זה הוא כדי שנוכל לכמת את האינטואיציה

458
00:27:44,160 --> 00:27:49,720
הזו שככל שנשיג יותר מידע ממילה, כך הציון הצפוי יהיה נמוך יותר.

459
00:27:49,720 --> 00:27:54,380
אז עם זה כגרסה 2. 0, אם נחזור אחורה ונריץ את אותה סט של

460
00:27:54,380 --> 00:27:59,820
סימולציות, כשזה ישחק מול כל 2315 תשובות המילה האפשריות, איך זה מסתדר?

461
00:27:59,820 --> 00:28:04,060
ובכן בניגוד לגרסה הראשונה שלנו זה בהחלט טוב יותר, וזה מרגיע.

462
00:28:04,060 --> 00:28:08,780
הכל אמר ועשה הממוצע הוא בסביבות 3. 6, אם כי בניגוד לגרסה הראשונה

463
00:28:08,780 --> 00:28:12,820
יש כמה פעמים שהיא מפסידה ודורשת יותר משש בנסיבות אלה.

464
00:28:12,820 --> 00:28:15,980
ככל הנראה בגלל שיש מקרים שבהם זה עושה את

465
00:28:15,980 --> 00:28:18,980
הפשרה הזו ללכת על המטרה במקום למקסם את המידע.

466
00:28:18,980 --> 00:28:22,140
אז אנחנו יכולים לעשות יותר טוב מ-3. 6?

467
00:28:22,140 --> 00:28:23,260
אנחנו בהחלט יכולים.

468
00:28:23,260 --> 00:28:27,120
עכשיו אמרתי בהתחלה שהכי כיף לנסות לא לשלב את הרשימה האמיתית

469
00:28:27,120 --> 00:28:29,980
של תשובות מילוליות בדרך שבה היא בונה את המודל שלה.

470
00:28:29,980 --> 00:28:35,180
אבל אם נשלב את זה, הביצועים הטובים ביותר שיכולתי לקבל היו בסביבות 3. 43.

471
00:28:35,180 --> 00:28:39,520
אז אם ננסה להיות מתוחכמים יותר מסתם שימוש בנתוני תדירות מילים כדי לבחור את ההפצה

472
00:28:39,520 --> 00:28:44,220
הקודמת הזו, זה 3. 43 כנראה נותן מקסימום כמה טוב יכולנו להגיע

473
00:28:44,220 --> 00:28:46,360
עם זה, או לפחות כמה טוב יכולתי להגיע עם זה.

474
00:28:46,360 --> 00:28:50,240
הביצועים הטובים ביותר האלה בעצם רק משתמשים ברעיונות שדיברתי עליהם

475
00:28:50,240 --> 00:28:53,400
כאן, אבל זה הולך קצת יותר רחוק, כאילו הוא מחפש

476
00:28:53,400 --> 00:28:55,660
את המידע הצפוי שני צעדים קדימה ולא רק אחד.

477
00:28:55,660 --> 00:28:58,720
במקור תכננתי לדבר על זה יותר, אבל אני

478
00:28:58,720 --> 00:29:00,580
מבין שלמעשה עברנו די הרבה זמן כמו שזה.

479
00:29:00,580 --> 00:29:03,520
הדבר היחיד שאני אגיד הוא לאחר ביצוע חיפוש דו-שלבי זה

480
00:29:03,520 --> 00:29:07,720
ולאחר מכן הפעלת כמה סימולציות לדוגמא במועמדים המובילים, עד כה

481
00:29:07,720 --> 00:29:09,500
עבורי לפחות זה נראה כאילו קריין הוא הפותח הטוב ביותר.

482
00:29:09,500 --> 00:29:11,080
מי היה מנחש?

483
00:29:11,080 --> 00:29:15,680
כמו כן, אם אתה משתמש ברשימת המילים האמיתית כדי לקבוע את מרחב האפשרויות

484
00:29:15,680 --> 00:29:17,920
שלך, אז אי הוודאות שאתה מתחיל איתה היא קצת יותר מ-11 ביטים.

485
00:29:18,160 --> 00:29:22,760
ומסתבר, רק מחיפוש כוח גס, המידע המקסימלי האפשרי הצפוי

486
00:29:22,760 --> 00:29:26,580
לאחר שני הניחושים הראשונים הוא בסביבות 10 ביטים.

487
00:29:26,580 --> 00:29:31,720
מה שמרמז על התרחיש הטוב ביותר, לאחר שני הניחושים הראשונים שלך,

488
00:29:31,720 --> 00:29:35,220
עם משחק אופטימלי לחלוטין, תישאר עם קצת אי ודאות אחת.

489
00:29:35,220 --> 00:29:37,400
וזה אותו דבר כמו לרדת לשני ניחושים אפשריים.

490
00:29:37,400 --> 00:29:41,440
אז אני חושב שזה הוגן וכנראה די שמרני לומר שלעולם לא תוכל

491
00:29:41,440 --> 00:29:45,620
לכתוב אלגוריתם שמקבל את הממוצע הזה נמוך כמו 3, כי עם

492
00:29:45,620 --> 00:29:50,460
המילים הזמינות לך, פשוט אין מקום לקבל מספיק מידע לאחר שני שלבים

493
00:29:50,460 --> 00:29:53,820
בלבד. מסוגל להבטיח את התשובה במשבצת השלישית בכל פעם בלי להיכשל.

