1
00:00:00,000 --> 00:00:04,354
لقد انتشرت لعبة Wurdle بشكل كبير في الشهر أو الشهرين الماضيين، ولم يغفل أحد

2
00:00:04,354 --> 00:00:08,708
أبدًا فرصة لدرس الرياضيات، ويخطر لي أن هذه اللعبة تمثل مثالًا مركزيًا جيدًا

3
00:00:08,708 --> 00:00:13,120
جدًا في درس حول نظرية المعلومات، وعلى وجه الخصوص موضوع يعرف باسم الانتروبيا.

4
00:00:13,120 --> 00:00:18,069
كما ترى، مثل الكثير من الأشخاص، انغمست في اللغز، ومثل الكثير من المبرمجين، انغمست

5
00:00:18,069 --> 00:00:23,200
أيضًا في محاولة كتابة خوارزمية من شأنها أن تلعب اللعبة على النحو الأمثل قدر الإمكان.

6
00:00:23,200 --> 00:00:26,290
وما اعتقدت أنني سأفعله هنا هو مجرد التحدث معكم عن بعض العمليات

7
00:00:26,290 --> 00:00:29,185
التي قمت بها في ذلك، وشرح بعض العمليات الحسابية التي أجريت

8
00:00:29,185 --> 00:00:32,080
عليها، حيث أن الخوارزمية بأكملها تركز على فكرة الإنتروبيا.

9
00:00:32,080 --> 00:00:42,180
أول الأشياء أولاً، في حالة أنك لم تسمع بها، ما هو Wurdle؟

10
00:00:42,180 --> 00:00:46,867
ولقتل عصفورين بحجر واحد هنا بينما نراجع قواعد اللعبة، اسمحوا لي أيضًا أن أستعرض

11
00:00:46,867 --> 00:00:51,380
إلى أين نتجه بهذا، وهو تطوير خوارزمية صغيرة ستلعب اللعبة أساسًا بالنسبة لنا.

12
00:00:51,380 --> 00:00:53,574
على الرغم من أنني لم أقم بـWurdle اليوم، إلا أن

13
00:00:53,574 --> 00:00:55,860
هذا هو الرابع من فبراير، وسنرى كيف سيعمل الروبوت.

14
00:00:55,860 --> 00:01:00,860
هدف Wurdle هو تخمين كلمة غامضة مكونة من خمسة أحرف، ويتم منحك ست فرص مختلفة للتخمين.

15
00:01:00,860 --> 00:01:05,240
على سبيل المثال، يقترح روبوت Wurdle الخاص بي أن أبدأ برافعة التخمين.

16
00:01:05,240 --> 00:01:08,488
في كل مرة تقوم فيها بالتخمين، تحصل على بعض المعلومات

17
00:01:08,488 --> 00:01:10,940
حول مدى قرب تخمينك من الإجابة الحقيقية.

18
00:01:10,940 --> 00:01:14,540
هنا يخبرني المربع الرمادي أنه لا يوجد حرف C في الإجابة الفعلية.

19
00:01:14,540 --> 00:01:18,340
يخبرني المربع الأصفر بوجود حرف R، لكنه ليس في هذا الموضع.

20
00:01:18,340 --> 00:01:22,820
يخبرني الصندوق الأخضر أن الكلمة السرية بها حرف A، وهي في المركز الثالث.

21
00:01:22,820 --> 00:01:24,300
ومن ثم لا يوجد N ولا يوجد E.

22
00:01:24,300 --> 00:01:27,420
لذلك اسمحوا لي أن أدخل وأخبر روبوت Wurdle بهذه المعلومات.

23
00:01:27,420 --> 00:01:31,500
لقد بدأنا بالرافعة، وحصلنا على اللون الرمادي والأصفر والأخضر والرمادي والرمادي.

24
00:01:31,500 --> 00:01:35,460
لا تقلق بشأن جميع البيانات التي تظهرها الآن، سأشرح ذلك في الوقت المناسب.

25
00:01:35,460 --> 00:01:39,700
لكن أهم اقتراح لاختيارنا الثاني هو أسلوب هزلي.

26
00:01:39,700 --> 00:01:42,700
ويجب أن يكون تخمينك عبارة عن كلمة فعلية مكونة من خمسة أحرف، ولكن

27
00:01:42,700 --> 00:01:45,700
كما سترى، فهي متحررة جدًا فيما يتعلق بما ستتيح لك تخمينه بالفعل.

28
00:01:45,700 --> 00:01:48,860
في هذه الحالة، نحاول shtick.

29
00:01:48,860 --> 00:01:50,260
حسنًا، تبدو الأمور جيدة جدًا.

30
00:01:50,260 --> 00:01:54,580
نضغط على S وH، حتى نعرف الأحرف الثلاثة الأولى، ونعلم أن هناك حرف R.

31
00:01:54,580 --> 00:01:59,740
وبالتالي سيكون مثل SHA شيء R، أو SHA R شيء ما.

32
00:01:59,740 --> 00:02:05,220
ويبدو أن روبوت Wurdle يعرف أن الأمر يرجع إلى احتمالين فقط، إما شظية أو حادة.

33
00:02:05,220 --> 00:02:08,211
هذا نوع من التقلب بينهما في هذه المرحلة، لذلك أعتقد

34
00:02:08,211 --> 00:02:11,260
أنه ربما فقط لأنه ترتيب أبجدي فإنه يتناسب مع القشرة.

35
00:02:11,260 --> 00:02:13,000
يا للهول، هذا هو الجواب الفعلي.

36
00:02:13,000 --> 00:02:14,660
لذلك حصلنا عليه في ثلاثة.

37
00:02:14,660 --> 00:02:17,740
إذا كنت تتساءل عما إذا كان هذا أمرًا جيدًا، فالطريقة التي سمعت

38
00:02:17,740 --> 00:02:20,820
بها عبارة شخص واحد هي أنه مع Wurdle أربعة متساوية وثلاثة طائر.

39
00:02:20,820 --> 00:02:22,960
والذي أعتقد أنه تشبيه مناسب جدًا.

40
00:02:22,960 --> 00:02:25,383
يجب أن تكون في مستوى لعبتك باستمرار حتى تحصل على

41
00:02:25,383 --> 00:02:27,560
المركز الرابع، لكن هذا بالتأكيد ليس جنونًا.

42
00:02:27,560 --> 00:02:30,000
ولكن عندما تحصل عليه في ثلاثة، فإنه يشعر بالارتياح.

43
00:02:30,000 --> 00:02:33,222
لذا، إذا كنت ترغب في ذلك، ما أود القيام به هنا هو مجرد التحدث

44
00:02:33,222 --> 00:02:36,600
خلال عملية تفكيري منذ البداية حول كيفية التعامل مع روبوت Wurdle.

45
00:02:36,600 --> 00:02:39,800
وكما قلت، إنه حقًا عذر لدرس نظرية المعلومات.

46
00:02:39,800 --> 00:02:43,160
الهدف الرئيسي هو شرح ما هي المعلومات وما هو الإنتروبيا.

47
00:02:43,160 --> 00:02:48,224
كانت فكرتي الأولى في التعامل مع هذا الأمر هي إلقاء نظرة

48
00:02:48,224 --> 00:02:53,560
على التكرارات النسبية للحروف المختلفة في اللغة الإنجليزية.

49
00:02:53,560 --> 00:02:56,872
لذا فكرت، حسنًا، هل هناك تخمين افتتاحي أو زوج من التخمينات

50
00:02:56,872 --> 00:02:59,960
الافتتاحية يصل إلى الكثير من هذه الحروف الأكثر شيوعًا؟

51
00:02:59,960 --> 00:03:03,780
وكان أحد الأشياء التي كنت مغرمًا بها هو القيام بأشياء أخرى متبوعة بالأظافر.

52
00:03:03,780 --> 00:03:07,980
الفكرة هي أنه إذا ضربت حرفًا، فستحصل على اللون الأخضر أو الأصفر، وهذا شعور جيد دائمًا.

53
00:03:07,980 --> 00:03:09,460
يبدو الأمر وكأنك تحصل على معلومات.

54
00:03:09,460 --> 00:03:13,550
لكن في هذه الحالات، حتى لو لم تضرب وظهرت لك علامات رمادية دائمًا، فلا يزال هذا يوفر لك

55
00:03:13,550 --> 00:03:17,640
الكثير من المعلومات لأنه من النادر جدًا العثور على كلمة لا تحتوي على أي من هذه الأحرف.

56
00:03:17,640 --> 00:03:20,437
لكن حتى مع ذلك، لا يبدو هذا منهجيًا للغاية، لأنه

57
00:03:20,437 --> 00:03:23,520
على سبيل المثال، لا يفعل شيئًا للنظر في ترتيب الحروف.

58
00:03:23,520 --> 00:03:26,080
لماذا أكتب الأظافر عندما أستطيع كتابة الحلزون؟

59
00:03:26,080 --> 00:03:27,720
هل من الأفضل أن يكون لديك S في النهاية؟

60
00:03:27,720 --> 00:03:28,720
أنا غير متأكد.

61
00:03:28,720 --> 00:03:32,817
الآن، قال أحد أصدقائي إنه يحب أن يبدأ بكلمة &quot;ضجر&quot;، الأمر

62
00:03:32,817 --> 00:03:37,160
الذي فاجأني نوعًا ما لأنها تحتوي على بعض الحروف غير المألوفة مثل W وY.

63
00:03:37,160 --> 00:03:39,400
لكن من يدري، ربما تكون هذه افتتاحية أفضل.

64
00:03:39,400 --> 00:03:44,920
هل هناك نوع من الدرجة الكمية التي يمكننا تقديمها للحكم على جودة التخمين المحتمل؟

65
00:03:44,920 --> 00:03:48,360
الآن، للإعداد للطريقة التي سنقوم بها بترتيب التخمينات المحتملة،

66
00:03:48,360 --> 00:03:51,800
دعنا نعود ونضيف القليل من الوضوح حول كيفية إعداد اللعبة بالضبط.

67
00:03:51,800 --> 00:03:54,977
لذا، هناك قائمة بالكلمات التي سيسمح لك بإدخالها والتي

68
00:03:54,977 --> 00:03:57,920
تعتبر تخمينات صحيحة ويبلغ طولها حوالي 13000 كلمة.

69
00:03:57,920 --> 00:04:02,217
لكن عندما تنظر إليها، هناك الكثير من الأشياء غير المألوفة حقًا، أشياء مثل &quot;رأس&quot;

70
00:04:02,217 --> 00:04:05,368
أو &quot;علي&quot; و&quot;ARG&quot;، نوع الكلمات التي تثير جدالات

71
00:04:05,368 --> 00:04:07,040
عائلية في لعبة &quot;سكرابل&quot;.

72
00:04:07,040 --> 00:04:10,600
لكن أجواء اللعبة هي أن الإجابة ستكون دائمًا كلمة شائعة بشكل لائق.

73
00:04:10,600 --> 00:04:16,080
وفي الواقع، هناك قائمة أخرى تضم حوالي 2300 كلمة تمثل الإجابات المحتملة.

74
00:04:16,080 --> 00:04:19,000
وهذه قائمة منسقة بشريًا، وأعتقد على وجه التحديد

75
00:04:19,000 --> 00:04:21,800
من قبل صديقة صانع اللعبة، وهي ممتعة نوعًا ما.

76
00:04:21,800 --> 00:04:26,289
لكن ما أود أن أفعله، التحدي الذي يواجهنا في هذا المشروع هو معرفة ما إذا كان

77
00:04:26,289 --> 00:04:30,720
بإمكاننا كتابة برنامج لحل Wordle لا يتضمن المعرفة السابقة حول هذه القائمة.

78
00:04:30,720 --> 00:04:33,294
لسبب واحد، هناك الكثير من الكلمات الشائعة المكونة

79
00:04:33,294 --> 00:04:35,560
من خمسة أحرف والتي لن تجدها في تلك القائمة.

80
00:04:35,560 --> 00:04:38,874
لذلك سيكون من الأفضل كتابة برنامج أكثر مرونة ويمكنه تشغيل

81
00:04:38,874 --> 00:04:41,960
Wordle ضد أي شخص، وليس فقط ما يحدث أنه الموقع الرسمي.

82
00:04:41,960 --> 00:04:47,440
وأيضًا السبب وراء معرفتنا لقائمة الإجابات المحتملة هذه هو أنها مرئية في الكود المصدري.

83
00:04:47,440 --> 00:04:50,058
لكن الطريقة التي تظهر بها في الكود المصدري تكون

84
00:04:50,058 --> 00:04:52,840
بالترتيب المحدد الذي تظهر به الإجابات من يوم لآخر.

85
00:04:52,840 --> 00:04:56,400
لذلك يمكنك دائمًا البحث عن إجابة الغد.

86
00:04:56,400 --> 00:04:59,140
لذا فمن الواضح أن هناك بعض المعنى الذي يعتبر فيه استخدام القائمة غشًا.

87
00:04:59,140 --> 00:05:03,209
وما يجعل اللغز أكثر إثارة للاهتمام ودرسًا أكثر ثراءً لنظرية المعلومات

88
00:05:03,209 --> 00:05:07,279
هو بدلاً من ذلك استخدام بعض البيانات الأكثر عالمية مثل ترددات الكلمات

89
00:05:07,279 --> 00:05:11,640
النسبية بشكل عام لالتقاط هذا الحدس المتمثل في تفضيل الكلمات الأكثر شيوعًا.

90
00:05:11,640 --> 00:05:16,560
إذن، من بين هذه الاحتمالات الـ 13000، كيف يجب أن نختار التخمين الافتتاحي؟

91
00:05:16,560 --> 00:05:19,960
على سبيل المثال، إذا تقدم صديقي بطلب مرهق، فكيف ينبغي لنا أن نحلل جودته؟

92
00:05:19,960 --> 00:05:23,955
حسنًا، السبب الذي جعله يحب ذلك W غير المحتمل هو أنه يحب

93
00:05:23,955 --> 00:05:27,880
طبيعة اللقطة الطويلة لمدى الشعور الجيد إذا ضربت ذلك W.

94
00:05:27,880 --> 00:05:31,861
على سبيل المثال، إذا كان النمط الأول الذي تم الكشف عنه شيئًا كهذا،

95
00:05:31,861 --> 00:05:36,080
فسيتبين أن هناك 58 كلمة فقط في هذا المعجم العملاق تتطابق مع هذا النمط.

96
00:05:36,080 --> 00:05:38,900
وهذا تخفيض كبير من 13000.

97
00:05:38,900 --> 00:05:43,320
لكن الجانب الآخر من ذلك، بالطبع، هو أنه من غير المألوف أن نحصل على نمط كهذا.

98
00:05:43,320 --> 00:05:47,292
على وجه التحديد، إذا كان من المرجح أن تكون كل كلمة هي الإجابة بشكل

99
00:05:47,292 --> 00:05:51,680
متساوٍ، فإن احتمال الوصول إلى هذا النمط سيكون 58 مقسومًا على حوالي 13000.

100
00:05:51,680 --> 00:05:53,880
وبطبيعة الحال، ليس من المرجح أن تكون الإجابات متساوية.

101
00:05:53,880 --> 00:05:56,680
معظم هذه الكلمات غامضة للغاية وحتى مشكوك فيها.

102
00:05:56,680 --> 00:05:59,463
لكن على الأقل بالنسبة لمرورنا الأول في كل هذا، لنفترض

103
00:05:59,463 --> 00:06:02,040
أن جميعهم متساوون في الاحتمال ثم نحسن ذلك لاحقًا.

104
00:06:02,040 --> 00:06:04,815
النقطة المهمة هي أن النمط الذي يحتوي على الكثير

105
00:06:04,815 --> 00:06:07,360
من المعلومات من غير المرجح أن يحدث بطبيعته.

106
00:06:07,360 --> 00:06:11,320
في الواقع، ما يعنيه أن تكون غنيًا بالمعلومات هو أنه أمر غير محتمل.

107
00:06:11,320 --> 00:06:15,004
النمط الأكثر احتمالاً الذي يمكن رؤيته مع هذه الافتتاحية

108
00:06:15,004 --> 00:06:18,360
سيكون شيئًا مثل هذا، حيث لا يوجد بالطبع حرف W فيه.

109
00:06:18,360 --> 00:06:22,080
ربما يوجد حرف E، وربما لا يوجد A، ولا يوجد R، ولا يوجد Y.

110
00:06:22,080 --> 00:06:24,640
في هذه الحالة، هناك 1400 تطابق محتمل.

111
00:06:24,640 --> 00:06:27,568
إذا كانت جميعها متساوية في الاحتمال، فمن المرجح

112
00:06:27,568 --> 00:06:30,680
أن يكون هذا هو النمط الذي ستراه بنسبة 11% تقريبًا.

113
00:06:30,680 --> 00:06:34,320
وبالتالي فإن النتائج الأكثر ترجيحًا هي أيضًا الأقل إفادة.

114
00:06:34,320 --> 00:06:38,285
للحصول على رؤية أكثر عمومية هنا، اسمحوا لي أن أعرض لكم التوزيع

115
00:06:38,285 --> 00:06:42,000
الكامل للاحتمالات عبر جميع الأنماط المختلفة التي قد تراها.

116
00:06:42,000 --> 00:06:45,673
لذا فإن كل شريط تنظر إليه يتوافق مع نمط محتمل من الألوان التي

117
00:06:45,673 --> 00:06:49,227
يمكن الكشف عنها، والتي يوجد منها 3 إلى الاحتمال الخامس، وهي

118
00:06:49,227 --> 00:06:52,960
منظمة من اليسار إلى اليمين، من الأكثر شيوعًا إلى الأقل شيوعًا.

119
00:06:52,960 --> 00:06:56,200
لذا فإن الاحتمال الأكثر شيوعًا هنا هو أن تحصل على كل الألوان الرمادية.

120
00:06:56,200 --> 00:06:58,800
ويحدث ذلك في حوالي 14% من الحالات.

121
00:06:58,800 --> 00:07:04,078
وما تأمله عندما تقوم بالتخمين هو أن ينتهي بك الأمر في مكان ما في هذا الذيل

122
00:07:04,078 --> 00:07:09,920
الطويل، مثل هنا حيث يوجد 18 احتمالًا فقط لما يطابق هذا النمط الذي يبدو بوضوح هكذا.

123
00:07:09,920 --> 00:07:14,080
أو إذا غامرنا بالتحرك إلى اليسار قليلاً، كما تعلمون، ربما نقطع كل الطريق هنا.

124
00:07:14,080 --> 00:07:16,560
حسنًا، إليك لغزًا جيدًا لك.

125
00:07:16,560 --> 00:07:22,040
ما هي الكلمات الثلاث في اللغة الإنجليزية التي تبدأ بحرف W، وتنتهي بحرف Y، وفيها حرف R؟

126
00:07:22,040 --> 00:07:27,560
اتضح أن الإجابات هي، دعونا نرى، كلامية، ودودة، وساخرة.

127
00:07:27,560 --> 00:07:31,704
لذا، للحكم على مدى جودة هذه الكلمة بشكل عام، نريد نوعًا من قياس

128
00:07:31,704 --> 00:07:35,720
الكمية المتوقعة من المعلومات التي ستحصل عليها من هذا التوزيع.

129
00:07:35,720 --> 00:07:40,752
إذا مررنا بكل نمط وضربنا احتمالية حدوثه في شيء

130
00:07:40,752 --> 00:07:46,000
يقيس مدى معلوماته، فقد يمنحنا ذلك نتيجة موضوعية.

131
00:07:46,000 --> 00:07:50,280
الآن قد تكون غريزتك الأولى بشأن ما يجب أن يكون عليه هذا الشيء هي عدد التطابقات.

132
00:07:50,280 --> 00:07:52,960
تريد متوسطًا أقل لعدد المطابقات.

133
00:07:52,960 --> 00:07:56,902
لكن بدلاً من ذلك، أود استخدام مقياس أكثر شمولاً ننسبه غالبًا إلى المعلومات،

134
00:07:56,902 --> 00:08:00,740
والذي سيكون أكثر مرونة بمجرد أن يكون لدينا احتمالية مختلفة مخصصة لكل كلمة

135
00:08:00,740 --> 00:08:04,320
من هذه الكلمات الـ 13000 لمعرفة ما إذا كانت هي الإجابة بالفعل أم لا.

136
00:08:04,320 --> 00:08:10,717
الوحدة القياسية للمعلومات هي البت، والتي تحتوي على صيغة

137
00:08:10,717 --> 00:08:17,800
مضحكة إلى حد ما، لكنها بديهية حقًا إذا نظرنا فقط إلى الأمثلة.

138
00:08:17,800 --> 00:08:20,874
إذا كانت لديك ملاحظة تختصر مساحة الاحتمالات لديك

139
00:08:20,874 --> 00:08:24,200
إلى النصف، نقول إنها تحتوي على بت واحد من المعلومات.

140
00:08:24,200 --> 00:08:27,728
في مثالنا، مساحة الاحتمالات هي كل الكلمات الممكنة، وتبين أن حوالي نصف

141
00:08:27,728 --> 00:08:31,560
الكلمات المكونة من خمسة أحرف بها حرف S، أقل من ذلك بقليل، ولكن حوالي النصف.

142
00:08:31,560 --> 00:08:35,200
لذا فإن هذه الملاحظة ستمنحك معلومة واحدة.

143
00:08:35,200 --> 00:08:38,546
وبدلاً من ذلك، إذا أدت حقيقة جديدة إلى تقليص مساحة الاحتمالات

144
00:08:38,546 --> 00:08:42,000
هذه إلى أربعة أضعاف، فسنقول إنها تحتوي على قطعتين من المعلومات.

145
00:08:42,000 --> 00:08:45,120
على سبيل المثال، تبين أن حوالي ربع هذه الكلمات تحتوي على حرف T.

146
00:08:45,120 --> 00:08:48,049
إذا قطعت الملاحظة هذا الفضاء بمقدار ثمانية أضعاف،

147
00:08:48,049 --> 00:08:50,920
نقول إنها ثلاث أجزاء من المعلومات، وهكذا دواليك.

148
00:08:50,920 --> 00:08:55,000
أربع بتات تقطعه إلى 16، وخمس بتات تقطعه إلى 32.

149
00:08:55,000 --> 00:08:59,664
والآن قد ترغب في التوقف مؤقتًا وتسأل نفسك، ما هي

150
00:08:59,664 --> 00:09:04,520
صيغة المعلومات لعدد البتات من حيث احتمال حدوث ذلك؟

151
00:09:04,520 --> 00:09:09,618
ما نقوله هنا هو أنه عندما تأخذ نصفًا لعدد البتات، فهذا هو نفس الاحتمال، وهو

152
00:09:09,618 --> 00:09:14,380
نفس قول أن اثنين أس عدد البتات يساوي واحدًا على الاحتمال، وهو ما يُعاد

153
00:09:14,380 --> 00:09:19,680
ترتيبها أيضًا لقول أن المعلومات هي سجل واحد للأساس اثنين مقسومًا على الاحتمال.

154
00:09:19,680 --> 00:09:22,709
وفي بعض الأحيان ترى ذلك مع عملية إعادة ترتيب أخرى،

155
00:09:22,709 --> 00:09:25,680
حيث تكون المعلومات هي سالب الاحتمال للأساس اثنين.

156
00:09:25,680 --> 00:09:28,974
إذا تم التعبير عنها بهذه الطريقة، فقد تبدو غريبة بعض الشيء بالنسبة

157
00:09:28,974 --> 00:09:32,022
للمبتدئين، ولكنها في الحقيقة مجرد فكرة بديهية للغاية تتمثل في

158
00:09:32,022 --> 00:09:35,120
السؤال عن عدد المرات التي قمت فيها بتخفيض إمكانياتك إلى النصف.

159
00:09:35,120 --> 00:09:37,542
الآن إذا كنت تتساءل، كما تعلمون، اعتقدت أننا كنا نلعب

160
00:09:37,542 --> 00:09:39,920
لعبة كلمات ممتعة، لماذا تدخل اللوغاريتمات في الصورة؟

161
00:09:39,920 --> 00:09:44,482
أحد الأسباب التي تجعل هذه الوحدة أجمل هو أنه من الأسهل كثيرًا التحدث عن

162
00:09:44,482 --> 00:09:48,981
أحداث غير محتملة للغاية، ومن الأسهل كثيرًا القول إن الملاحظة تحتوي على

163
00:09:48,981 --> 00:09:53,480
20 بت من المعلومات مقارنة بالقول إن احتمال حدوث كذا وكذا هو 0.0000095.

164
00:09:53,480 --> 00:09:57,708
لكن السبب الأكثر أهمية وراء تحول هذا التعبير اللوغاريتمي إلى إضافة

165
00:09:57,708 --> 00:10:02,000
مفيدة جدًا لنظرية الاحتمال هو الطريقة التي تجمع بها المعلومات معًا.

166
00:10:02,000 --> 00:10:06,835
على سبيل المثال، إذا أعطتك ملاحظة واحدة قطعتين من المعلومات، مما يقلل المساحة بمقدار

167
00:10:06,835 --> 00:10:11,784
أربعة، ثم ملاحظة ثانية مثل تخمينك الثاني في Wordle تعطيك ثلاث أجزاء أخرى من المعلومات،

168
00:10:11,784 --> 00:10:16,734
مما يقلل من المساحة بمقدار عامل آخر قدره ثمانية، فإن اثنان معًا يزودانك بخمسة أجزاء من

169
00:10:16,734 --> 00:10:17,360
المعلومات.

170
00:10:17,360 --> 00:10:21,200
بنفس الطريقة التي تحب بها الاحتمالات أن تتضاعف، تحب المعلومات أن تضيف.

171
00:10:21,200 --> 00:10:25,102
لذلك بمجرد أن نكون في عالم شيء مثل القيمة المتوقعة، حيث نقوم بإضافة

172
00:10:25,102 --> 00:10:28,660
مجموعة من الأرقام، فإن السجلات تجعل التعامل معها أفضل كثيرًا.

173
00:10:28,660 --> 00:10:32,110
دعنا نعود إلى توزيعتنا لـ Weary ونضيف أداة تعقب صغيرة

174
00:10:32,110 --> 00:10:35,560
أخرى هنا، لتوضح لنا مقدار المعلومات المتوفرة لكل نمط.

175
00:10:35,560 --> 00:10:39,530
الشيء الرئيسي الذي أريدك أن تلاحظه هو أنه كلما زادت احتمالية وصولنا إلى تلك

176
00:10:39,530 --> 00:10:43,500
الأنماط الأكثر احتمالية، كلما انخفضت المعلومات، وقل عدد البتات التي تكسبها.

177
00:10:43,500 --> 00:10:49,154
الطريقة التي نقيس بها جودة هذا التخمين هي أخذ القيمة المتوقعة لهذه المعلومات، حيث نمر

178
00:10:49,154 --> 00:10:54,940
عبر كل نمط، ونقول مدى احتمالية ذلك، ثم نضرب ذلك في عدد أجزاء المعلومات التي نحصل عليها.

179
00:10:54,940 --> 00:10:58,480
وفي مثال Weary، تبين أن الرقم 4.9 بت.

180
00:10:58,480 --> 00:11:02,172
لذا، في المتوسط، فإن المعلومات التي تحصل عليها من هذا التخمين الافتتاحي

181
00:11:02,172 --> 00:11:05,660
جيدة مثل تقليص مساحة الاحتمالات الخاصة بك إلى النصف حوالي خمس مرات.

182
00:11:05,660 --> 00:11:13,220
على النقيض من ذلك، مثال على التخمين ذو قيمة معلومات متوقعة أعلى سيكون مثل Slate.

183
00:11:13,220 --> 00:11:16,180
في هذه الحالة ستلاحظ أن التوزيع يبدو أكثر تملقًا.

184
00:11:16,180 --> 00:11:21,099
على وجه الخصوص، فإن احتمال حدوث جميع درجات الرمادي هو 6% فقط،

185
00:11:21,099 --> 00:11:25,940
لذا فمن الواضح أنك تحصل على 3% على الأقل. 9 بت من المعلومات.

186
00:11:25,940 --> 00:11:29,140
ولكن هذا هو الحد الأدنى، وعادة ما تحصل على شيء أفضل من ذلك.

187
00:11:29,140 --> 00:11:32,868
واتضح أنه عندما تقوم بجمع الأرقام الموجودة في هذا الرقم وإضافة

188
00:11:32,868 --> 00:11:36,420
جميع المصطلحات ذات الصلة، فإن متوسط المعلومات هو حوالي 5.8.

189
00:11:36,420 --> 00:11:40,111
لذا، على النقيض من Weary، فإن مساحة الاحتمالات الخاصة

190
00:11:40,111 --> 00:11:43,940
بك ستكون حوالي النصف بعد هذا التخمين الأول، في المتوسط.

191
00:11:43,940 --> 00:11:49,540
هناك في الواقع قصة ممتعة حول اسم هذه القيمة المتوقعة لكمية المعلومات.

192
00:11:49,540 --> 00:11:54,475
تم تطوير نظرية المعلومات على يد كلود شانون، الذي كان يعمل في مختبرات بيل في الأربعينيات،

193
00:11:54,475 --> 00:11:59,300
لكنه كان يتحدث عن بعض أفكاره التي لم تُنشر بعد مع جون فون نيومان، الذي كان هذا العملاق

194
00:11:59,300 --> 00:12:04,180
الفكري في ذلك الوقت، بارزًا جدًا في الرياضيات والفيزياء وبدايات ما أصبح علوم الكمبيوتر.

195
00:12:04,180 --> 00:12:09,192
وعندما ذكر أنه ليس لديه حقًا اسم جيد لهذه القيمة المتوقعة لكمية المعلومات، من

196
00:12:09,192 --> 00:12:14,720
المفترض أن فون نيومان قال، وفقًا للقصة، حسنًا، يجب أن تسميها الإنتروبيا، وذلك لسببين.

197
00:12:14,720 --> 00:12:18,737
في المقام الأول، تم استخدام دالة عدم اليقين في الميكانيكا الإحصائية تحت

198
00:12:18,737 --> 00:12:22,755
هذا الاسم، لذا فهي تحمل اسمًا بالفعل، وفي المقام الثاني، والأهم من ذلك،

199
00:12:22,755 --> 00:12:26,940
لا أحد يعرف ما هي الإنتروبيا حقًا، لذلك في أي نقاش ستظل دائمًا لدينا ميزة.

200
00:12:26,940 --> 00:12:30,047
لذا، إذا كان الاسم يبدو غامضًا بعض الشيء، وإذا

201
00:12:30,047 --> 00:12:33,420
كان لهذه القصة أن تصدق، فهذا نوعاً ما حسب التصميم.

202
00:12:33,420 --> 00:12:37,924
وأيضًا إذا كنت تتساءل عن علاقتها بكل ما يتعلق بالقانون الثاني للديناميكا

203
00:12:37,924 --> 00:12:42,305
الحرارية من الفيزياء، فمن المؤكد أن هناك صلة، ولكن في أصولها كان شانون

204
00:12:42,305 --> 00:12:46,500
يتعامل فقط مع نظرية الاحتمالات البحتة، ولأغراضنا هنا، عندما استخدمت

205
00:12:46,500 --> 00:12:50,820
الإنتروبيا، أريدك فقط أن تفكر في قيمة المعلومات المتوقعة لتخمين معين.

206
00:12:50,820 --> 00:12:54,380
يمكنك التفكير في الإنتروبيا على أنها قياس شيئين في وقت واحد.

207
00:12:54,380 --> 00:12:57,420
الأول هو مدى ثبات التوزيع.

208
00:12:57,420 --> 00:13:01,700
كلما كان التوزيع أقرب إلى الانتظام، كلما زادت الإنتروبيا.

209
00:13:01,700 --> 00:13:07,010
في حالتنا، حيث يوجد 3 إلى 5 أنماط إجمالية، للتوزيع الموحد، فإن مراقبة

210
00:13:07,010 --> 00:13:12,397
أي واحد منها سيكون له قاعدة سجل معلومات 2 من 3 إلى 5، وهو ما يصادف أنه

211
00:13:12,397 --> 00:13:17,860
7.92، هذا هو الحد الأقصى المطلق الذي يمكن أن تحصل عليه لهذه الإنتروبيا.

212
00:13:17,860 --> 00:13:22,900
لكن الإنتروبيا هي أيضًا نوع من مقياس لعدد الاحتمالات الموجودة في المقام الأول.

213
00:13:22,900 --> 00:13:27,864
على سبيل المثال، إذا كان لديك كلمة حيث يوجد فقط 16 نمطًا ممكنًا، وكل نمط

214
00:13:27,864 --> 00:13:32,760
محتمل متساوٍ، فإن هذه الإنتروبيا، هذه المعلومات المتوقعة، ستكون 4 بتات.

215
00:13:32,760 --> 00:13:37,050
لكن إذا كانت لديك كلمة أخرى حيث يمكن أن تظهر 64 نمطًا محتملاً،

216
00:13:37,050 --> 00:13:41,000
وجميعها متساوية في الاحتمال، فإن الإنتروبيا ستكون 6 بتات.

217
00:13:41,000 --> 00:13:45,554
لذا، إذا رأيت بعض التوزيعات في الطبيعة والتي تحتوي على إنتروبيا تبلغ

218
00:13:45,554 --> 00:13:50,175
6 بتات، فهذا يشبه القول بأن هناك قدرًا كبيرًا من الاختلاف وعدم اليقين

219
00:13:50,175 --> 00:13:54,400
فيما هو على وشك الحدوث كما لو كان هناك 64 نتيجة محتملة متساوية.

220
00:13:54,400 --> 00:13:58,360
في أول تمريرة لي في Wurtelebot، طلبت مني فعل هذا فقط.

221
00:13:58,360 --> 00:14:03,070
إنه يمر بجميع التخمينات المحتملة التي يمكن أن تكون لديك، كل الكلمات البالغ

222
00:14:03,070 --> 00:14:07,654
عددها 13000 كلمة، ويحسب الإنتروبيا لكل واحدة منها، أو بشكل أكثر تحديدًا،

223
00:14:07,654 --> 00:14:12,301
إنتروبيا التوزيع عبر جميع الأنماط التي قد تراها، لكل واحد، ويختار الأعلى،

224
00:14:12,301 --> 00:14:17,200
نظرًا لأن ذلك الذي من المحتمل أن يقلل مساحة الاحتمالات الخاصة بك قدر الإمكان.

225
00:14:17,200 --> 00:14:19,440
وعلى الرغم من أنني كنت أتحدث فقط عن التخمين الأول هنا،

226
00:14:19,440 --> 00:14:21,680
فإنه يفعل نفس الشيء بالنسبة للتخمينات القليلة التالية.

227
00:14:21,680 --> 00:14:25,151
على سبيل المثال، بعد أن ترى بعض الأنماط في هذا التخمين الأول، والتي

228
00:14:25,151 --> 00:14:28,725
من شأنها أن تقيدك بعدد أقل من الكلمات المحتملة بناءً على ما يتطابق مع

229
00:14:28,725 --> 00:14:32,300
ذلك، فإنك تلعب نفس اللعبة فيما يتعلق بتلك المجموعة الأصغر من الكلمات.

230
00:14:32,300 --> 00:14:36,628
للحصول على تخمين ثانٍ مقترح، تنظر إلى توزيع جميع الأنماط التي يمكن

231
00:14:36,628 --> 00:14:40,828
أن تحدث من تلك المجموعة الأكثر تقييدًا من الكلمات، وتبحث في جميع

232
00:14:40,828 --> 00:14:45,480
الاحتمالات البالغ عددها 13000، وتجد الخيار الذي يزيد من هذه الإنتروبيا.

233
00:14:45,480 --> 00:14:49,678
لكي أوضح لك كيف يتم ذلك عمليًا، اسمحوا لي أن أعرض نسخة صغيرة من كتاب

234
00:14:49,678 --> 00:14:54,060
Wurtele الذي كتبته والذي يوضح النقاط البارزة في هذا التحليل في الهوامش.

235
00:14:54,060 --> 00:14:57,268
بعد إجراء جميع حسابات الإنتروبيا، تظهر لنا على

236
00:14:57,268 --> 00:15:00,340
اليمين أي منها لديه أعلى المعلومات المتوقعة.

237
00:15:00,340 --> 00:15:05,662
اتضح أن الإجابة الرئيسية، على الأقل في الوقت الحالي، وسنقوم بتحسينها

238
00:15:05,662 --> 00:15:11,140
لاحقًا، هي الزوان، والتي تعني، بالطبع، البيقية، البيقية الأكثر شيوعًا.

239
00:15:11,140 --> 00:15:14,675
في كل مرة نقوم بالتخمين هنا، حيث ربما أتجاهل توصياتها نوعًا ما وأختار

240
00:15:14,675 --> 00:15:18,060
القائمة، لأنني أحب القائمة، يمكننا أن نرى مقدار المعلومات المتوقعة

241
00:15:18,060 --> 00:15:21,393
التي تحتوي عليها، ولكن بعد ذلك على يمين الكلمة هنا تظهر لنا مقدار

242
00:15:21,393 --> 00:15:24,980
المعلومات المعلومات الفعلية التي حصلنا عليها، في ضوء هذا النمط بالذات.

243
00:15:24,980 --> 00:15:27,769
لذا يبدو هنا أننا لم نكن محظوظين بعض الشيء، حيث كان من

244
00:15:27,769 --> 00:15:30,660
المتوقع أن نحصل على 5.8، لكننا حصلنا على شيء أقل من ذلك.

245
00:15:30,660 --> 00:15:33,316
ثم على الجانب الأيسر هنا يظهر لنا جميع الكلمات

246
00:15:33,316 --> 00:15:35,860
المختلفة الممكنة بالنظر إلى ما نحن فيه الآن.

247
00:15:35,860 --> 00:15:40,108
تخبرنا الأشرطة الزرقاء بمدى احتمالية التفكير في كل كلمة، لذلك في الوقت الحالي

248
00:15:40,108 --> 00:15:44,140
يفترض أن كل كلمة من المرجح أن تحدث بشكل متساوٍ، ولكننا سنحسن ذلك في لحظة.

249
00:15:44,140 --> 00:15:50,040
ومن ثم يخبرنا قياس عدم اليقين هذا بإنتروبيا هذا التوزيع عبر الكلمات المحتملة، والتي في

250
00:15:50,040 --> 00:15:55,940
الوقت الحالي، نظرًا لأنه توزيع موحد، هي مجرد طريقة معقدة بلا داع لحساب عدد الاحتمالات.

251
00:15:55,940 --> 00:16:02,700
على سبيل المثال، إذا أخذنا 2 أس 13.66، ينبغي أن يكون حوالي 13000 الاحتمالات.

252
00:16:02,700 --> 00:16:06,780
أنا متوقف قليلاً هنا، ولكن فقط لأنني لا أعرض جميع المنازل العشرية.

253
00:16:06,780 --> 00:16:09,821
في الوقت الحالي، قد يبدو هذا زائدًا عن الحاجة ويؤدي إلى تعقيد الأمور بشكل

254
00:16:09,821 --> 00:16:12,780
مفرط، ولكنك سترى لماذا من المفيد الحصول على كلا الرقمين في دقيقة واحدة.

255
00:16:12,780 --> 00:16:16,207
لذا يبدو هنا أنه يشير إلى أن أعلى إنتروبيا لتخميننا

256
00:16:16,207 --> 00:16:19,700
الثاني هي رامين، والتي مرة أخرى لا تبدو وكأنها كلمة.

257
00:16:19,700 --> 00:16:25,660
لذا، لكي أتخذ موقفًا أخلاقيًا عاليًا هنا، سأمضي قدمًا وأكتب Rains.

258
00:16:25,660 --> 00:16:27,540
ومرة أخرى يبدو أننا لم نكن محظوظين بعض الشيء.

259
00:16:27,540 --> 00:16:32,100
كنا نتوقع 4.3 بتات وحصلنا على 3 فقط. 39 بت من المعلومات.

260
00:16:32,100 --> 00:16:35,060
وهذا ينقلنا إلى 55 احتمالًا.

261
00:16:35,060 --> 00:16:40,200
وهنا ربما سأوافق على ما يقترحه، وهو السرد، مهما كان معنى ذلك.

262
00:16:40,200 --> 00:16:43,300
حسنًا، هذه في الواقع فرصة جيدة لحل اللغز.

263
00:16:43,300 --> 00:16:47,020
إنه يخبرنا أن هذا النمط يعطينا 4.7 بت من المعلومات.

264
00:16:47,020 --> 00:16:52,400
لكن على اليسار، قبل أن نرى هذا النمط، كان هناك 5.78 بت من عدم اليقين.

265
00:16:52,400 --> 00:16:56,860
لذا، كاختبار لك، ماذا يعني ذلك بالنسبة لعدد الاحتمالات المتبقية؟

266
00:16:56,860 --> 00:17:00,585
حسنًا، هذا يعني أننا قد اختزلنا إلى جزء واحد من

267
00:17:00,585 --> 00:17:04,700
عدم اليقين، وهو نفس القول بأن هناك إجابتين محتملتين.

268
00:17:04,700 --> 00:17:06,520
إنه خيار 50-50.

269
00:17:06,520 --> 00:17:09,046
ومن هنا، ولأنني وأنت نعرف أي الكلمات أكثر شيوعاً،

270
00:17:09,046 --> 00:17:11,220
فإننا نعلم أن الإجابة يجب أن تكون الهاوية.

271
00:17:11,220 --> 00:17:13,540
ولكن كما هو مكتوب الآن، فإن البرنامج لا يعرف ذلك.

272
00:17:13,540 --> 00:17:16,916
لذلك فهو يستمر في محاولة الحصول على أكبر قدر ممكن

273
00:17:16,916 --> 00:17:20,360
من المعلومات، حتى يتبقى احتمال واحد فقط، ثم يخمنه.

274
00:17:20,360 --> 00:17:22,700
لذا من الواضح أننا بحاجة إلى استراتيجية أفضل لنهاية اللعبة.

275
00:17:22,700 --> 00:17:26,685
لكن لنفترض أننا نطلق على هذا الإصدار أحد برامج حل الكلمات

276
00:17:26,685 --> 00:17:30,740
لدينا، ثم نبدأ ونجري بعض عمليات المحاكاة لنرى كيف يتم ذلك.

277
00:17:30,740 --> 00:17:34,240
لذا فإن الطريقة التي يعمل بها هذا الأمر هي لعب كل لعبة كلمات ممكنة.

278
00:17:34,240 --> 00:17:38,780
إنها تمر بكل تلك الكلمات البالغ عددها 2315 والتي تمثل الإجابات الفعلية.

279
00:17:38,780 --> 00:17:41,340
إنها تستخدم ذلك بشكل أساسي كمجموعة اختبار.

280
00:17:41,340 --> 00:17:45,974
ومع هذه الطريقة الساذجة المتمثلة في عدم مراعاة مدى شيوع الكلمة، ومحاولة

281
00:17:45,974 --> 00:17:50,480
تعظيم المعلومات في كل خطوة على طول الطريق، حتى تصل إلى خيار واحد فقط.

282
00:17:50,480 --> 00:17:55,100
وبحلول نهاية المحاكاة، يبلغ متوسط الدرجات حوالي 4.124.

283
00:17:55,100 --> 00:17:59,780
وهذا ليس سيئًا، لأكون صادقًا، كنت أتوقع نوعًا ما أن أفعل ما هو أسوأ.

284
00:17:59,780 --> 00:18:03,040
لكن الأشخاص الذين يلعبون لعبة Wordle سيخبرونك أنه يمكنهم عادةً الحصول عليها خلال 4.

285
00:18:03,040 --> 00:18:05,260
التحدي الحقيقي هو الحصول على أكبر عدد ممكن من 3.

286
00:18:05,260 --> 00:18:08,920
إنها قفزة كبيرة جدًا بين النتيجة 4 والنتيجة 3.

287
00:18:08,920 --> 00:18:16,659
إن الفاكهة المعلقة الواضحة هنا هي دمج ما إذا كانت

288
00:18:16,659 --> 00:18:23,160
الكلمة شائعة أم لا، وكيف نفعل ذلك بالضبط.

289
00:18:23,160 --> 00:18:25,834
الطريقة التي تعاملت بها مع الأمر هي الحصول على قائمة

290
00:18:25,834 --> 00:18:28,560
بالتكرارات النسبية لجميع الكلمات في اللغة الإنجليزية.

291
00:18:28,560 --> 00:18:32,114
وقد استخدمت للتو وظيفة بيانات تردد الكلمات الخاصة بـ Mathematica، والتي

292
00:18:32,114 --> 00:18:35,520
تستمد نفسها من مجموعة البيانات العامة لـ Google Books English Ngram.

293
00:18:35,520 --> 00:18:37,906
ومن الممتع النظر إليه، على سبيل المثال، إذا قمنا بفرزه

294
00:18:37,906 --> 00:18:40,120
من الكلمات الأكثر شيوعًا إلى الكلمات الأقل شيوعًا.

295
00:18:40,120 --> 00:18:43,740
من الواضح أن هذه هي الكلمات الأكثر شيوعًا والمكونة من 5 أحرف في اللغة الإنجليزية.

296
00:18:43,740 --> 00:18:46,480
أو بالأحرى، هذه هي المرتبة الثامنة الأكثر شيوعًا.

297
00:18:46,480 --> 00:18:49,440
الأول هو الذي، وبعد ذلك هناك وهناك.

298
00:18:49,440 --> 00:18:54,220
الأول في حد ذاته ليس الأول، بل التاسع، ومن المنطقي أن هذه الكلمات الأخرى يمكن أن تأتي في

299
00:18:54,220 --> 00:18:59,000
كثير من الأحيان، حيث تكون تلك الكلمات التي تأتي بعد الأول، وأين، وتلك أقل شيوعًا قليلاً.

300
00:18:59,000 --> 00:19:02,772
الآن، عند استخدام هذه البيانات لنمذجة مدى احتمالية أن تكون كل كلمة من

301
00:19:02,772 --> 00:19:06,760
هذه الكلمات هي الإجابة النهائية، لا ينبغي أن تكون متناسبة مع التكرار فقط.

302
00:19:06,760 --> 00:19:11,017
على سبيل المثال، الذي يعطى درجة 0.002 في مجموعة البيانات

303
00:19:11,017 --> 00:19:15,200
هذه، في حين أن كلمة جديلة أقل احتمالًا بحوالي 1000 مرة.

304
00:19:15,200 --> 00:19:19,400
لكن كلتا هاتين الكلمتين شائعتان بدرجة كافية ومن المؤكد أنهما تستحقان أخذهما في الاعتبار.

305
00:19:19,400 --> 00:19:21,900
لذلك نريد المزيد من القطع الثنائي.

306
00:19:21,900 --> 00:19:25,759
الطريقة التي اتبعتها في ذلك هي تخيل أخذ هذه القائمة الكاملة من

307
00:19:25,759 --> 00:19:29,863
الكلمات، ثم ترتيبها على المحور السيني، ثم تطبيق الدالة السيني، وهي

308
00:19:29,863 --> 00:19:33,844
الطريقة القياسية للحصول على دالة يكون ناتجها ثنائيًا بشكل أساسي،

309
00:19:33,844 --> 00:19:38,500
إنها إما 0 أو 1، ولكن هناك تجانس بينهما بالنسبة لتلك المنطقة من عدم اليقين.

310
00:19:38,500 --> 00:19:43,682
لذلك، بشكل أساسي، فإن الاحتمال الذي أقوم بتعيينه لكل كلمة لوجودها في

311
00:19:43,682 --> 00:19:49,540
القائمة النهائية سيكون قيمة الدالة السيني أعلاه أينما كانت على المحور السيني.

312
00:19:49,540 --> 00:19:53,828
من الواضح الآن أن هذا يعتمد على بعض المعلمات، على سبيل المثال مدى اتساع

313
00:19:53,828 --> 00:19:58,414
المساحة على المحور السيني التي تملأها تلك الكلمات يحدد مدى انخفاضنا تدريجيًا

314
00:19:58,414 --> 00:20:03,000
أو حادًا من 1 إلى 0، والمكان الذي نضعهم فيه من اليسار إلى اليمين يحدد القطع.

315
00:20:03,000 --> 00:20:07,340
لأكون صادقًا، الطريقة التي فعلت بها ذلك كانت مجرد لعق إصبعي ووضعه في مهب الريح.

316
00:20:07,340 --> 00:20:12,480
لقد بحثت في القائمة التي تم فرزها وحاولت العثور على نافذة حيث عندما نظرت إليها، اكتشفت

317
00:20:12,480 --> 00:20:17,680
أن حوالي نصف هذه الكلمات من المرجح أن لا تكون الإجابة النهائية، واستخدمت ذلك كنقطة قطع.

318
00:20:17,680 --> 00:20:21,188
بمجرد أن يكون لدينا توزيع مثل هذا عبر الكلمات، فهذا يعطينا

319
00:20:21,188 --> 00:20:24,460
موقفًا آخر تصبح فيه الإنتروبيا هذا القياس المفيد حقًا.

320
00:20:24,460 --> 00:20:29,081
على سبيل المثال، لنفترض أننا كنا نلعب لعبة وبدأنا بافتتاحيتي القديمة، والتي كانت

321
00:20:29,081 --> 00:20:33,760
عبارة عن ريشة ومسامير، وانتهى بنا الأمر بموقف حيث توجد أربع كلمات محتملة تطابقها.

322
00:20:33,760 --> 00:20:36,440
ولنفترض أننا نعتبرها كلها محتملة على قدم المساواة.

323
00:20:36,440 --> 00:20:40,000
دعني أسألك، ما هي إنتروبيا هذا التوزيع؟

324
00:20:40,000 --> 00:20:45,065
حسنًا، المعلومات المرتبطة بكل واحد من هذه الاحتمالات

325
00:20:45,065 --> 00:20:50,800
ستكون السجل ذو الأساس 2 من 4، حيث أن كل واحد هو 1 و4، أي 2.

326
00:20:50,800 --> 00:20:52,780
قطعتان من المعلومات، وأربعة احتمالات.

327
00:20:52,780 --> 00:20:54,360
كل شيء جيد جدا وجيد.

328
00:20:54,360 --> 00:20:58,320
ولكن ماذا لو أخبرتك أن هناك بالفعل أكثر من أربع مباريات؟

329
00:20:58,320 --> 00:21:02,600
في الواقع، عندما ننظر إلى قائمة الكلمات الكاملة، نجد أن هناك 16 كلمة تطابقها.

330
00:21:02,600 --> 00:21:07,052
لكن لنفترض أن نموذجنا يضع احتمالًا منخفضًا حقًا لتلك الكلمات الـ 12

331
00:21:07,052 --> 00:21:11,440
الأخرى لتكون الإجابة النهائية، شيء مثل 1 في 1000 لأنها غامضة حقًا.

332
00:21:11,440 --> 00:21:15,480
والآن دعني أسألك، ما هي إنتروبيا هذا التوزيع؟

333
00:21:15,480 --> 00:21:20,773
إذا كانت الإنتروبيا تقيس فقط عدد التطابقات هنا، فقد تتوقع أن تكون شيئًا مثل سجل

334
00:21:20,773 --> 00:21:26,200
الأساس 2 لـ 16، والذي سيكون 4، أي قطعتين من عدم اليقين أكثر مما كان لدينا من قبل.

335
00:21:26,200 --> 00:21:30,320
لكن بطبيعة الحال، فإن عدم اليقين الفعلي لا يختلف كثيرًا عما كان لدينا من قبل.

336
00:21:30,320 --> 00:21:34,075
فقط لأن هناك هذه الكلمات الـ 12 الغامضة لا يعني أنه سيكون من

337
00:21:34,075 --> 00:21:38,200
المثير للدهشة معرفة أن الإجابة النهائية هي السحر، على سبيل المثال.

338
00:21:38,200 --> 00:21:41,839
لذلك عندما تقوم بالحساب هنا، وتضيف احتمالية كل تكرار

339
00:21:41,839 --> 00:21:45,960
مضروبًا في المعلومات المقابلة، فإن ما تحصل عليه هو 2.11 بت.

340
00:21:45,960 --> 00:21:49,714
أنا فقط أقول، إنها في الأساس جزأين، أساسًا تلك الاحتمالات الأربعة، ولكن

341
00:21:49,714 --> 00:21:53,469
هناك القليل من عدم اليقين بسبب كل تلك الأحداث غير المحتملة إلى حد كبير،

342
00:21:53,469 --> 00:21:57,120
على الرغم من أنك إذا تعلمتها، فسوف تحصل على الكثير من المعلومات منها.

343
00:21:57,120 --> 00:22:01,800
لذا، فإن التصغير هو جزء مما يجعل Wordle مثالًا رائعًا لدرس نظرية المعلومات.

344
00:22:01,800 --> 00:22:05,280
لدينا هذين التطبيقين المتميزين للشعور بالإنتروبيا.

345
00:22:05,280 --> 00:22:10,649
الأول يخبرنا ما هي المعلومات المتوقعة التي سنحصل عليها من تخمين معين،

346
00:22:10,649 --> 00:22:16,480
والثاني يقول هل يمكننا قياس عدم اليقين المتبقي بين جميع الكلمات التي لدينا.

347
00:22:16,480 --> 00:22:20,922
ويجب أن أؤكد، في تلك الحالة الأولى التي ننظر فيها إلى المعلومات المتوقعة من التخمين،

348
00:22:20,922 --> 00:22:25,000
بمجرد أن يكون لدينا وزن غير متساوٍ للكلمات، فإن ذلك يؤثر على حساب الإنتروبيا.

349
00:22:25,000 --> 00:22:29,693
على سبيل المثال، اسمحوا لي أن أذكر نفس الحالة التي كنا ننظر إليها سابقًا للتوزيع

350
00:22:29,693 --> 00:22:34,560
المرتبط بـ Weary، ولكن هذه المرة باستخدام توزيع غير منتظم عبر جميع الكلمات الممكنة.

351
00:22:34,560 --> 00:22:39,360
لذلك اسمحوا لي أن أرى ما إذا كان بإمكاني العثور على جزء هنا يوضح ذلك بشكل جيد.

352
00:22:39,360 --> 00:22:42,480
حسنًا، هنا هذا جيد جدًا.

353
00:22:42,480 --> 00:22:45,881
لدينا هنا نمطان متجاوران متساويان في الاحتمال، ولكن

354
00:22:45,881 --> 00:22:49,480
قيل لنا أن أحدهما يحتوي على 32 كلمة محتملة تتطابق معه.

355
00:22:49,480 --> 00:22:52,621
وإذا تحققنا من ماهيتها، فهذه هي تلك الكلمات الـ 32، والتي

356
00:22:52,621 --> 00:22:55,600
كلها مجرد كلمات غير محتملة للغاية عندما تفحصها بعينيك.

357
00:22:55,600 --> 00:23:00,255
من الصعب العثور على أي إجابات تبدو وكأنها إجابات معقولة، وربما صيحات، ولكن إذا

358
00:23:00,255 --> 00:23:05,028
نظرنا إلى النمط المجاور في التوزيع، والذي يعتبر محتملًا تقريبًا، فقد قيل لنا أنه

359
00:23:05,028 --> 00:23:09,920
يحتوي على 8 تطابقات محتملة فقط، أي ربع العديد من المباريات، ولكن الأمر على الأرجح.

360
00:23:09,920 --> 00:23:12,520
وعندما نسحب تلك الثقاب، يمكننا أن نرى السبب.

361
00:23:12,520 --> 00:23:17,840
بعض هذه الإجابات هي إجابات معقولة بالفعل، مثل الخاتم، أو الغضب، أو موسيقى الراب.

362
00:23:17,840 --> 00:23:21,928
لتوضيح كيفية دمج كل ذلك، اسمحوا لي أن أعرض الإصدار 2 من Wordlebot هنا،

363
00:23:21,928 --> 00:23:25,960
وهناك اختلافان أو ثلاثة اختلافات رئيسية عن الإصدار الأول الذي رأيناه.

364
00:23:25,960 --> 00:23:30,478
أولاً، كما قلت للتو، الطريقة التي نحسب بها هذه الإنتروبيا، هذه

365
00:23:30,478 --> 00:23:34,709
القيم المتوقعة للمعلومات، تستخدم الآن توزيعات أكثر دقة عبر

366
00:23:34,709 --> 00:23:39,300
الأنماط التي تتضمن احتمال أن تكون كلمة معينة هي الإجابة بالفعل.

367
00:23:39,300 --> 00:23:44,160
كما يحدث، لا تزال الدموع هي رقم 1، على الرغم من أن الدموع التالية مختلفة بعض الشيء.

368
00:23:44,160 --> 00:23:48,024
ثانيًا، عندما يقوم بتصنيف أفضل اختياراته، فإنه سيحتفظ الآن بنموذج

369
00:23:48,024 --> 00:23:51,830
لاحتمال أن تكون كل كلمة هي الإجابة الفعلية، وسيدمج ذلك في قراره،

370
00:23:51,830 --> 00:23:55,520
وهو ما يسهل رؤيته بمجرد أن يكون لدينا بعض التخمينات على طاولة.

371
00:23:55,520 --> 00:24:01,120
مرة أخرى، تجاهل توصيتها لأننا لا نستطيع السماح للآلات بالتحكم في حياتنا.

372
00:24:01,120 --> 00:24:05,425
وأفترض أنني يجب أن أذكر شيئًا آخر مختلفًا هنا على اليسار، وهو أن قيمة عدم

373
00:24:05,425 --> 00:24:10,080
اليقين، وعدد البتات هذا، لم تعد مجرد زائدة عن الحاجة مع عدد التطابقات المحتملة.

374
00:24:10,080 --> 00:24:16,542
الآن إذا سحبناها للأعلى وحسابنا 2 إلى 8.02، وهو أعلى قليلاً من 256، أعتقد 259، ما يقوله

375
00:24:16,542 --> 00:24:22,710
هو أنه على الرغم من وجود 526 كلمة إجمالية تتطابق فعليًا مع هذا النمط، فإن مقدار عدم

376
00:24:22,710 --> 00:24:29,099
اليقين الموجود فيه أقرب إلى ما سيكون عليه لو كان هناك 259 كلمة محتملة على قدم المساواة

377
00:24:29,099 --> 00:24:29,760
النتائج.

378
00:24:29,760 --> 00:24:31,100
يمكنك التفكير في الأمر على هذا النحو.

379
00:24:31,100 --> 00:24:34,498
إنه يعرف أن البورق ليس هو الحل، كما هو الحال مع yorts وzorl

380
00:24:34,498 --> 00:24:37,840
وzorus، لذا فهو أقل غموضًا مما كان عليه في الحالة السابقة.

381
00:24:37,840 --> 00:24:40,220
سيكون هذا العدد من البتات أصغر.

382
00:24:40,220 --> 00:24:44,532
وإذا واصلت لعب اللعبة، فسوف أقوم بتحسين ذلك من خلال

383
00:24:44,532 --> 00:24:48,680
بعض التخمينات التي تتناسب مع ما أود أن أشرحه هنا.

384
00:24:48,680 --> 00:24:51,390
من خلال التخمين الرابع، إذا نظرت إلى أفضل اختياراتها،

385
00:24:51,390 --> 00:24:53,800
يمكنك أن ترى أنها لم تعد مجرد تعظيم الإنتروبيا.

386
00:24:53,800 --> 00:24:57,078
إذن في هذه المرحلة، هناك سبعة احتمالات من الناحية الفنية، لكن

387
00:24:57,078 --> 00:25:00,780
الاحتمالات الوحيدة التي لديها فرصة ذات معنى هي مساكن الطلبة والكلمات.

388
00:25:00,780 --> 00:25:04,080
ويمكنك أن ترى أن اختيار كلتا القيمتين فوق كل هذه القيم

389
00:25:04,080 --> 00:25:07,560
الأخرى، بالمعنى الدقيق للكلمة، سيعطي المزيد من المعلومات.

390
00:25:07,560 --> 00:25:11,187
في المرة الأولى التي قمت فيها بذلك، قمت فقط بجمع هذين الرقمين

391
00:25:11,187 --> 00:25:14,580
لقياس جودة كل تخمين، والذي كان في الواقع أفضل مما قد تظن.

392
00:25:14,580 --> 00:25:17,230
لكن الأمر لم يكن منهجيًا حقًا، وأنا متأكد من أن هناك طرقًا

393
00:25:17,230 --> 00:25:19,880
أخرى يمكن للناس اتباعها ولكن هذا هو النهج الذي توصلت إليه.

394
00:25:19,880 --> 00:25:24,189
إذا كنا نفكر في احتمالية التخمين التالي، كما هو الحال في الكلمات في هذه

395
00:25:24,189 --> 00:25:28,440
الحالة، فإن ما نهتم به حقًا هو النتيجة المتوقعة للعبتنا إذا فعلنا ذلك.

396
00:25:28,440 --> 00:25:31,913
ولحساب تلك النتيجة المتوقعة، نقول ما هو احتمال أن تكون

397
00:25:31,913 --> 00:25:35,640
الكلمات هي الإجابة الفعلية، والتي تصف في الوقت الحالي 58%.

398
00:25:35,640 --> 00:25:40,400
نقول باحتمال 58% أن نتيجتنا في هذه المباراة ستكون 4.

399
00:25:40,400 --> 00:25:46,240
وبعد ذلك، مع احتمال 1 ناقص 58%، ستكون درجاتنا أكثر من 4.

400
00:25:46,240 --> 00:25:49,478
لا نعرف كم من ذلك، ولكن يمكننا تقديره بناءً على

401
00:25:49,478 --> 00:25:52,920
مقدار عدم اليقين المحتمل عندما نصل إلى هذه النقطة.

402
00:25:52,920 --> 00:25:56,600
على وجه التحديد، في هذه اللحظة هناك 1.44 بت من عدم اليقين.

403
00:25:56,600 --> 00:26:01,560
إذا خمننا الكلمات، فهذا يخبرنا أن المعلومات المتوقعة التي سنحصل عليها هي 1.27 بت.

404
00:26:01,560 --> 00:26:04,985
لذا، إذا خمننا الكلمات، فإن هذا الاختلاف يمثل مقدار

405
00:26:04,985 --> 00:26:08,280
عدم اليقين الذي من المحتمل أن نتركه بعد حدوث ذلك.

406
00:26:08,280 --> 00:26:11,199
ما نحتاجه هو نوع من الوظائف، والتي أسميها f هنا،

407
00:26:11,199 --> 00:26:13,880
والتي تربط عدم اليقين هذا بالنتيجة المتوقعة.

408
00:26:13,880 --> 00:26:18,073
وكانت الطريقة التي تم بها تحقيق ذلك هي رسم مجموعة من البيانات من

409
00:26:18,073 --> 00:26:22,588
الألعاب السابقة استنادًا إلى الإصدار 1 من الروبوت لنقول ما هي النتيجة

410
00:26:22,588 --> 00:26:27,040
الفعلية بعد نقاط مختلفة مع قدر معين من عدم اليقين يمكن قياسه للغاية.

411
00:26:27,040 --> 00:26:31,035
على سبيل المثال، نقاط البيانات هذه الموجودة هنا أعلى قيمة تقارب

412
00:26:31,035 --> 00:26:34,907
8.7 أو نحو ذلك يقال لبعض الألعاب بعد النقطة التي كان فيها 8.7

413
00:26:34,907 --> 00:26:39,340
أجزاء من عدم اليقين، استغرق الأمر تخمينين للحصول على الإجابة النهائية.

414
00:26:39,340 --> 00:26:41,241
بالنسبة للألعاب الأخرى، استغرق الأمر ثلاثة تخمينات،

415
00:26:41,241 --> 00:26:43,180
وبالنسبة للألعاب الأخرى، استغرق الأمر أربعة تخمينات.

416
00:26:43,180 --> 00:26:47,043
إذا انتقلنا إلى اليسار هنا، فإن جميع النقاط فوق الصفر تشير إلى أنه

417
00:26:47,043 --> 00:26:51,136
عندما يكون هناك صفر من عدم اليقين، وهو ما يعني أن هناك احتمالًا واحدًا

418
00:26:51,136 --> 00:26:55,000
فقط، فإن عدد التخمينات المطلوبة هو دائمًا واحد فقط، وهو أمر مطمئن.

419
00:26:55,000 --> 00:26:59,573
كلما كان هناك قدر واحد من عدم اليقين، مما يعني أن الأمر كان في الأساس يرجع إلى احتمالين

420
00:26:59,573 --> 00:27:03,940
فقط، كان الأمر يتطلب أحيانًا تخمينًا إضافيًا، وأحيانًا يتطلب الأمر تخمينين إضافيين.

421
00:27:03,940 --> 00:27:05,980
وهكذا دواليك هنا.

422
00:27:05,980 --> 00:27:11,020
ربما تكون الطريقة الأسهل قليلًا لتصور هذه البيانات هي تجميعها معًا وأخذ المتوسطات.

423
00:27:11,020 --> 00:27:16,648
على سبيل المثال، يشير هذا الشريط هنا إلى أنه من بين جميع النقاط التي كان لدينا

424
00:27:16,648 --> 00:27:22,420
فيها قدر واحد من عدم اليقين، كان متوسط عدد التخمينات الجديدة المطلوبة حوالي 1.5.

425
00:27:22,420 --> 00:27:26,828
والشريط هنا يقول من بين جميع الألعاب المختلفة حيث كانت نسبة عدم اليقين في

426
00:27:26,828 --> 00:27:31,593
مرحلة ما أعلى بقليل من أربعة بتات، وهو ما يشبه تضييقها إلى 16 احتمالًا مختلفًا،

427
00:27:31,593 --> 00:27:36,240
ثم في المتوسط يتطلب الأمر ما يزيد قليلاً عن تخمينين من تلك النقطة إلى الأمام.

428
00:27:36,240 --> 00:27:40,080
ومن هنا قمت للتو بالانحدار ليناسب الوظيفة التي بدت معقولة لهذا الغرض.

429
00:27:40,080 --> 00:27:44,900
وتذكر أن الهدف الأساسي من القيام بأي من ذلك هو أن نتمكن من قياس هذا الحدس، وهو

430
00:27:44,900 --> 00:27:49,720
أنه كلما زادت المعلومات التي نكتسبها من كلمة ما، كلما انخفضت النتيجة المتوقعة.

431
00:27:49,720 --> 00:27:54,615
لذا، مع هذا الإصدار 2.0، إذا عدنا وقمنا بتشغيل نفس مجموعة عمليات المحاكاة، حيث

432
00:27:54,615 --> 00:27:59,820
قمنا بتشغيلها مقابل جميع الإجابات اللفظية المحتملة البالغ عددها 2315، كيف سيتم ذلك؟

433
00:27:59,820 --> 00:28:04,060
حسنًا، على النقيض من نسختنا الأولى، فهي بالتأكيد أفضل، وهو أمر مطمئن.

434
00:28:04,060 --> 00:28:08,636
كل ما قيل وفعل هو المتوسط حوالي 3.6، على الرغم من أنه على عكس الإصدار

435
00:28:08,636 --> 00:28:12,820
الأول هناك عدة مرات يخسر فيها ويتطلب أكثر من ستة في هذه الظروف.

436
00:28:12,820 --> 00:28:16,018
من المفترض أنه هناك أوقات يتم فيها إجراء هذه المقايضة

437
00:28:16,018 --> 00:28:18,980
للوصول فعليًا إلى الهدف بدلاً من تعظيم المعلومات.

438
00:28:18,980 --> 00:28:22,140
فهل يمكننا أن نفعل ما هو أفضل من 3.

439
00:28:22,140 --> 00:28:23,260
6؟ يمكننا بالتأكيد.

440
00:28:23,260 --> 00:28:26,676
لقد قلت في البداية أنه من الممتع جدًا محاولة عدم دمج القائمة

441
00:28:26,676 --> 00:28:29,980
الحقيقية للإجابات اللفظية في الطريقة التي يبني بها نموذجه.

442
00:28:29,980 --> 00:28:35,180
ولكن إذا قمنا بدمجها، فإن أفضل أداء يمكن أن أحصل عليه كان حوالي 3.43.

443
00:28:35,180 --> 00:28:38,685
لذا، إذا حاولنا أن نكون أكثر تعقيدًا من مجرد استخدام بيانات تكرار الكلمات

444
00:28:38,685 --> 00:28:42,333
لاختيار هذا التوزيع المسبق، فهذا 3.43 ربما يعطي الحد الأقصى لمدى الجودة التي

445
00:28:42,333 --> 00:28:46,360
يمكننا تحقيقها من خلال ذلك، أو على الأقل مدى الجودة التي يمكن أن نحققها من خلال ذلك.

446
00:28:46,360 --> 00:28:50,896
يستخدم هذا الأداء الأفضل بشكل أساسي الأفكار التي كنت أتحدث عنها هنا، ولكنه يذهب

447
00:28:50,896 --> 00:28:55,660
أبعد قليلاً، مثل البحث عن المعلومات المتوقعة خطوتين للأمام بدلاً من خطوة واحدة فقط.

448
00:28:55,660 --> 00:29:00,580
في الأصل كنت أخطط للحديث أكثر عن ذلك، لكنني أدركت أننا قد قطعنا وقتًا طويلاً بالفعل.

449
00:29:00,580 --> 00:29:04,911
الشيء الوحيد الذي سأقوله هو بعد إجراء هذا البحث المكون من خطوتين ثم تشغيل بعض نماذج

450
00:29:04,911 --> 00:29:09,500
المحاكاة في أفضل المرشحين، حتى الآن بالنسبة لي على الأقل يبدو أن Crane هو أفضل افتتاحية.

451
00:29:09,500 --> 00:29:11,080
من كان سيخمن؟

452
00:29:11,080 --> 00:29:14,710
وأيضًا إذا كنت تستخدم قائمة الكلمات الحقيقية لتحديد مساحة الاحتمالات

453
00:29:14,710 --> 00:29:17,920
الخاصة بك، فإن عدم اليقين الذي تبدأ به يزيد قليلاً عن 11 بت.

454
00:29:17,920 --> 00:29:22,100
وقد اتضح، من خلال بحث القوة الغاشمة فقط، أن الحد الأقصى

455
00:29:22,100 --> 00:29:26,580
الممكن للمعلومات المتوقعة بعد أول تخمينين هو حوالي 10 بتات.

456
00:29:26,580 --> 00:29:30,694
وهو ما يشير إلى أفضل سيناريو، بعد أول تخمينين، مع

457
00:29:30,694 --> 00:29:35,220
اللعب الأمثل تمامًا، سيتبقى لديك القليل من عدم اليقين.

458
00:29:35,220 --> 00:29:37,400
وهو نفس الأمر الذي يرجع إلى اثنين من التخمينات المحتملة.

459
00:29:37,400 --> 00:29:41,610
لذلك أعتقد أنه من العدل وربما المحافظ جدًا أن نقول إنه لا يمكنك أبدًا

460
00:29:41,610 --> 00:29:45,880
كتابة خوارزمية تحصل على هذا المتوسط منخفضًا يصل إلى 3، لأنه مع الكلمات

461
00:29:45,880 --> 00:29:50,030
المتاحة لك، ببساطة ليس هناك مجال للحصول على معلومات كافية بعد خطوتين

462
00:29:50,030 --> 00:29:53,820
فقط قادر على ضمان الإجابة في الفتحة الثالثة في كل مرة دون فشل.

