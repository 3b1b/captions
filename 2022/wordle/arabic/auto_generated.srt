1
00:00:00,000 --> 00:00:04,201
لقد انتشرت لعبة Wurdle بشكل كبير في الشهر أو الشهرين الماضيين، ولم يغفل أحد 

2
00:00:04,201 --> 00:00:08,403
أبدًا فرصة لدرس الرياضيات، ويخطر لي أن هذه اللعبة تمثل مثالًا مركزيًا جيدًا 

3
00:00:08,403 --> 00:00:12,660
جدًا في درس حول نظرية المعلومات، وعلى وجه الخصوص موضوع يعرف باسم الانتروبيا. 

4
00:00:13,920 --> 00:00:18,250
كما ترى، مثل الكثير من الأشخاص، انغمست في اللغز، ومثل الكثير من المبرمجين، انغمست 

5
00:00:18,250 --> 00:00:22,740
أيضًا في محاولة كتابة خوارزمية من شأنها أن تلعب اللعبة على النحو الأمثل قدر الإمكان. 

6
00:00:23,180 --> 00:00:25,929
وما اعتقدت أنني سأفعله هنا هو مجرد التحدث معكم عن بعض العمليات 

7
00:00:25,929 --> 00:00:28,504
التي قمت بها في ذلك، وشرح بعض العمليات الحسابية التي أجريت 

8
00:00:28,504 --> 00:00:31,080
عليها، حيث أن الخوارزمية بأكملها تركز على فكرة الإنتروبيا. 

9
00:00:38,700 --> 00:00:41,640
أول الأشياء أولاً، في حالة أنك لم تسمع بها، ما هو Wurdle؟ 

10
00:00:42,040 --> 00:00:46,625
ولقتل عصفورين بحجر واحد هنا بينما نراجع قواعد اللعبة، اسمحوا لي أيضًا أن أستعرض 

11
00:00:46,625 --> 00:00:51,040
إلى أين نتجه بهذا، وهو تطوير خوارزمية صغيرة ستلعب اللعبة أساسًا بالنسبة لنا. 

12
00:00:51,360 --> 00:00:53,191
على الرغم من أنني لم أقم بـWurdle اليوم، إلا أن 

13
00:00:53,191 --> 00:00:55,100
هذا هو الرابع من فبراير، وسنرى كيف سيعمل الروبوت. 

14
00:00:55,480 --> 00:01:00,340
هدف Wurdle هو تخمين كلمة غامضة مكونة من خمسة أحرف، ويتم منحك ست فرص مختلفة للتخمين. 

15
00:01:00,840 --> 00:01:04,379
على سبيل المثال، يقترح روبوت Wurdle الخاص بي أن أبدأ برافعة التخمين. 

16
00:01:05,180 --> 00:01:08,052
في كل مرة تقوم فيها بالتخمين، تحصل على بعض المعلومات 

17
00:01:08,052 --> 00:01:10,220
حول مدى قرب تخمينك من الإجابة الحقيقية. 

18
00:01:10,920 --> 00:01:14,100
هنا يخبرني المربع الرمادي أنه لا يوجد حرف C في الإجابة الفعلية. 

19
00:01:14,520 --> 00:01:17,840
يخبرني المربع الأصفر بوجود حرف R، لكنه ليس في هذا الموضع. 

20
00:01:18,240 --> 00:01:22,240
يخبرني الصندوق الأخضر أن الكلمة السرية بها حرف A، وهي في المركز الثالث. 

21
00:01:22,720 --> 00:01:24,580
ومن ثم لا يوجد N ولا يوجد E. 

22
00:01:25,200 --> 00:01:27,340
لذلك اسمحوا لي أن أدخل وأخبر روبوت Wurdle بهذه المعلومات. 

23
00:01:27,340 --> 00:01:30,320
لقد بدأنا بالرافعة، وحصلنا على اللون الرمادي والأصفر والأخضر والرمادي والرمادي. 

24
00:01:31,420 --> 00:01:34,940
لا تقلق بشأن جميع البيانات التي تظهرها الآن، سأشرح ذلك في الوقت المناسب. 

25
00:01:35,460 --> 00:01:38,820
لكن أهم اقتراح لاختيارنا الثاني هو أسلوب هزلي. 

26
00:01:39,560 --> 00:01:42,480
ويجب أن يكون تخمينك عبارة عن كلمة فعلية مكونة من خمسة أحرف، ولكن 

27
00:01:42,480 --> 00:01:45,400
كما سترى، فهي متحررة جدًا فيما يتعلق بما ستتيح لك تخمينه بالفعل. 

28
00:01:46,200 --> 00:01:47,440
في هذه الحالة، نحاول shtick. 

29
00:01:48,780 --> 00:01:50,180
حسنًا، تبدو الأمور جيدة جدًا. 

30
00:01:50,260 --> 00:01:53,980
نضغط على S وH، حتى نعرف الأحرف الثلاثة الأولى، ونعلم أن هناك حرف R. 

31
00:01:53,980 --> 00:01:58,700
وبالتالي سيكون مثل SHA شيء R، أو SHA R شيء ما. 

32
00:01:59,620 --> 00:02:04,240
ويبدو أن روبوت Wurdle يعرف أن الأمر يرجع إلى احتمالين فقط، إما شظية أو حادة. 

33
00:02:05,100 --> 00:02:07,566
هذا نوع من التقلب بينهما في هذه المرحلة، لذلك أعتقد 

34
00:02:07,566 --> 00:02:10,080
أنه ربما فقط لأنه ترتيب أبجدي فإنه يتناسب مع القشرة. 

35
00:02:11,220 --> 00:02:12,860
يا للهول، هذا هو الجواب الفعلي. 

36
00:02:12,960 --> 00:02:13,780
لذلك حصلنا عليه في ثلاثة. 

37
00:02:14,600 --> 00:02:17,480
إذا كنت تتساءل عما إذا كان هذا أمرًا جيدًا، فالطريقة التي سمعت 

38
00:02:17,480 --> 00:02:20,360
بها عبارة شخص واحد هي أنه مع Wurdle أربعة متساوية وثلاثة طائر. 

39
00:02:20,680 --> 00:02:22,480
والذي أعتقد أنه تشبيه مناسب جدًا. 

40
00:02:22,480 --> 00:02:24,872
يجب أن تكون في مستوى لعبتك باستمرار حتى تحصل على 

41
00:02:24,872 --> 00:02:27,020
المركز الرابع، لكن هذا بالتأكيد ليس جنونًا. 

42
00:02:27,180 --> 00:02:29,920
ولكن عندما تحصل عليه في ثلاثة، فإنه يشعر بالارتياح. 

43
00:02:30,880 --> 00:02:33,360
لذا، إذا كنت ترغب في ذلك، ما أود القيام به هنا هو مجرد التحدث 

44
00:02:33,360 --> 00:02:35,960
خلال عملية تفكيري منذ البداية حول كيفية التعامل مع روبوت Wurdle. 

45
00:02:36,480 --> 00:02:39,440
وكما قلت، إنه حقًا عذر لدرس نظرية المعلومات. 

46
00:02:39,740 --> 00:02:42,820
الهدف الرئيسي هو شرح ما هي المعلومات وما هو الإنتروبيا. 

47
00:02:48,220 --> 00:02:50,898
كانت فكرتي الأولى في التعامل مع هذا الأمر هي إلقاء نظرة 

48
00:02:50,898 --> 00:02:53,720
على التكرارات النسبية للحروف المختلفة في اللغة الإنجليزية. 

49
00:02:54,380 --> 00:02:56,905
لذا فكرت، حسنًا، هل هناك تخمين افتتاحي أو زوج من التخمينات 

50
00:02:56,905 --> 00:02:59,260
الافتتاحية يصل إلى الكثير من هذه الحروف الأكثر شيوعًا؟ 

51
00:02:59,960 --> 00:03:03,000
وكان أحد الأشياء التي كنت مغرمًا بها هو القيام بأشياء أخرى متبوعة بالأظافر. 

52
00:03:03,760 --> 00:03:07,520
الفكرة هي أنه إذا ضربت حرفًا، فستحصل على اللون الأخضر أو الأصفر، وهذا شعور جيد دائمًا. 

53
00:03:07,520 --> 00:03:08,840
يبدو الأمر وكأنك تحصل على معلومات. 

54
00:03:09,340 --> 00:03:13,370
لكن في هذه الحالات، حتى لو لم تضرب وظهرت لك علامات رمادية دائمًا، فلا يزال هذا يوفر لك 

55
00:03:13,370 --> 00:03:17,400
الكثير من المعلومات لأنه من النادر جدًا العثور على كلمة لا تحتوي على أي من هذه الأحرف. 

56
00:03:18,140 --> 00:03:20,547
لكن حتى مع ذلك، لا يبدو هذا منهجيًا للغاية، لأنه 

57
00:03:20,547 --> 00:03:23,200
على سبيل المثال، لا يفعل شيئًا للنظر في ترتيب الحروف. 

58
00:03:23,560 --> 00:03:25,300
لماذا أكتب الأظافر عندما أستطيع كتابة الحلزون؟ 

59
00:03:26,080 --> 00:03:27,500
هل من الأفضل أن يكون لديك S في النهاية؟ 

60
00:03:27,820 --> 00:03:28,680
أنا غير متأكد. 

61
00:03:29,240 --> 00:03:32,784
الآن، قال أحد أصدقائي إنه يحب أن يبدأ بكلمة &quot;ضجر&quot;، الأمر 

62
00:03:32,784 --> 00:03:36,540
الذي فاجأني نوعًا ما لأنها تحتوي على بعض الحروف غير المألوفة مثل W وY. 

63
00:03:37,120 --> 00:03:39,000
لكن من يدري، ربما تكون هذه افتتاحية أفضل. 

64
00:03:39,320 --> 00:03:44,320
هل هناك نوع من الدرجة الكمية التي يمكننا تقديمها للحكم على جودة التخمين المحتمل؟ 

65
00:03:45,340 --> 00:03:48,380
الآن، للإعداد للطريقة التي سنقوم بها بترتيب التخمينات المحتملة، 

66
00:03:48,380 --> 00:03:51,420
دعنا نعود ونضيف القليل من الوضوح حول كيفية إعداد اللعبة بالضبط. 

67
00:03:51,420 --> 00:03:54,774
لذا، هناك قائمة بالكلمات التي سيسمح لك بإدخالها والتي 

68
00:03:54,774 --> 00:03:57,880
تعتبر تخمينات صحيحة ويبلغ طولها حوالي 13000 كلمة. 

69
00:03:58,320 --> 00:04:02,146
لكن عندما تنظر إليها، هناك الكثير من الأشياء غير المألوفة حقًا، أشياء مثل &quot;رأس&quot; 

70
00:04:02,146 --> 00:04:04,952
أو &quot;علي&quot; و&quot;ARG&quot;، نوع الكلمات التي تثير جدالات 

71
00:04:04,952 --> 00:04:06,440
عائلية في لعبة &quot;سكرابل&quot;. 

72
00:04:06,960 --> 00:04:10,540
لكن أجواء اللعبة هي أن الإجابة ستكون دائمًا كلمة شائعة بشكل لائق. 

73
00:04:10,960 --> 00:04:15,360
وفي الواقع، هناك قائمة أخرى تضم حوالي 2300 كلمة تمثل الإجابات المحتملة. 

74
00:04:15,940 --> 00:04:18,605
وهذه قائمة منسقة بشريًا، وأعتقد على وجه التحديد 

75
00:04:18,605 --> 00:04:21,160
من قبل صديقة صانع اللعبة، وهي ممتعة نوعًا ما. 

76
00:04:21,820 --> 00:04:26,027
لكن ما أود أن أفعله، التحدي الذي يواجهنا في هذا المشروع هو معرفة ما إذا كان 

77
00:04:26,027 --> 00:04:30,180
بإمكاننا كتابة برنامج لحل Wordle لا يتضمن المعرفة السابقة حول هذه القائمة. 

78
00:04:30,720 --> 00:04:32,805
لسبب واحد، هناك الكثير من الكلمات الشائعة المكونة 

79
00:04:32,805 --> 00:04:34,640
من خمسة أحرف والتي لن تجدها في تلك القائمة. 

80
00:04:34,940 --> 00:04:38,316
لذلك سيكون من الأفضل كتابة برنامج أكثر مرونة ويمكنه تشغيل 

81
00:04:38,316 --> 00:04:41,460
Wordle ضد أي شخص، وليس فقط ما يحدث أنه الموقع الرسمي. 

82
00:04:41,920 --> 00:04:47,000
وأيضًا السبب وراء معرفتنا لقائمة الإجابات المحتملة هذه هو أنها مرئية في الكود المصدري. 

83
00:04:47,000 --> 00:04:50,035
لكن الطريقة التي تظهر بها في الكود المصدري تكون 

84
00:04:50,035 --> 00:04:53,260
بالترتيب المحدد الذي تظهر به الإجابات من يوم لآخر. 

85
00:04:53,260 --> 00:04:55,840
لذلك يمكنك دائمًا البحث عن إجابة الغد. 

86
00:04:56,420 --> 00:04:58,880
لذا فمن الواضح أن هناك بعض المعنى الذي يعتبر فيه استخدام القائمة غشًا. 

87
00:04:59,100 --> 00:05:02,792
وما يجعل اللغز أكثر إثارة للاهتمام ودرسًا أكثر ثراءً لنظرية المعلومات 

88
00:05:02,792 --> 00:05:06,484
هو بدلاً من ذلك استخدام بعض البيانات الأكثر عالمية مثل ترددات الكلمات 

89
00:05:06,484 --> 00:05:10,440
النسبية بشكل عام لالتقاط هذا الحدس المتمثل في تفضيل الكلمات الأكثر شيوعًا. 

90
00:05:11,600 --> 00:05:15,900
إذن، من بين هذه الاحتمالات الـ 13000، كيف يجب أن نختار التخمين الافتتاحي؟ 

91
00:05:16,400 --> 00:05:19,780
على سبيل المثال، إذا تقدم صديقي بطلب مرهق، فكيف ينبغي لنا أن نحلل جودته؟ 

92
00:05:20,520 --> 00:05:23,960
حسنًا، السبب الذي جعله يحب ذلك W غير المحتمل هو أنه يحب 

93
00:05:23,960 --> 00:05:27,340
طبيعة اللقطة الطويلة لمدى الشعور الجيد إذا ضربت ذلك W. 

94
00:05:27,920 --> 00:05:31,648
على سبيل المثال، إذا كان النمط الأول الذي تم الكشف عنه شيئًا كهذا، 

95
00:05:31,648 --> 00:05:35,600
فسيتبين أن هناك 58 كلمة فقط في هذا المعجم العملاق تتطابق مع هذا النمط. 

96
00:05:36,060 --> 00:05:38,400
وهذا تخفيض كبير من 13000. 

97
00:05:38,780 --> 00:05:43,020
لكن الجانب الآخر من ذلك، بالطبع، هو أنه من غير المألوف أن نحصل على نمط كهذا. 

98
00:05:43,020 --> 00:05:46,830
على وجه التحديد، إذا كان من المرجح أن تكون كل كلمة هي الإجابة بشكل 

99
00:05:46,830 --> 00:05:51,040
متساوٍ، فإن احتمال الوصول إلى هذا النمط سيكون 58 مقسومًا على حوالي 13000. 

100
00:05:51,580 --> 00:05:53,600
وبطبيعة الحال، ليس من المرجح أن تكون الإجابات متساوية. 

101
00:05:53,720 --> 00:05:56,220
معظم هذه الكلمات غامضة للغاية وحتى مشكوك فيها. 

102
00:05:56,600 --> 00:05:59,196
لكن على الأقل بالنسبة لمرورنا الأول في كل هذا، لنفترض 

103
00:05:59,196 --> 00:06:01,600
أن جميعهم متساوون في الاحتمال ثم نحسن ذلك لاحقًا. 

104
00:06:02,020 --> 00:06:04,472
النقطة المهمة هي أن النمط الذي يحتوي على الكثير 

105
00:06:04,472 --> 00:06:06,720
من المعلومات من غير المرجح أن يحدث بطبيعته. 

106
00:06:07,280 --> 00:06:10,800
في الواقع، ما يعنيه أن تكون غنيًا بالمعلومات هو أنه أمر غير محتمل. 

107
00:06:11,719 --> 00:06:15,069
النمط الأكثر احتمالاً الذي يمكن رؤيته مع هذه الافتتاحية 

108
00:06:15,069 --> 00:06:18,120
سيكون شيئًا مثل هذا، حيث لا يوجد بالطبع حرف W فيه. 

109
00:06:18,240 --> 00:06:21,400
ربما يوجد حرف E، وربما لا يوجد A، ولا يوجد R، ولا يوجد Y. 

110
00:06:22,080 --> 00:06:24,560
في هذه الحالة، هناك 1400 تطابق محتمل. 

111
00:06:25,080 --> 00:06:27,756
إذا كانت جميعها متساوية في الاحتمال، فمن المرجح 

112
00:06:27,756 --> 00:06:30,600
أن يكون هذا هو النمط الذي ستراه بنسبة 11% تقريبًا. 

113
00:06:30,900 --> 00:06:33,340
وبالتالي فإن النتائج الأكثر ترجيحًا هي أيضًا الأقل إفادة. 

114
00:06:34,240 --> 00:06:37,803
للحصول على رؤية أكثر عمومية هنا، اسمحوا لي أن أعرض لكم التوزيع 

115
00:06:37,803 --> 00:06:41,140
الكامل للاحتمالات عبر جميع الأنماط المختلفة التي قد تراها. 

116
00:06:41,740 --> 00:06:45,292
لذا فإن كل شريط تنظر إليه يتوافق مع نمط محتمل من الألوان التي 

117
00:06:45,292 --> 00:06:48,730
يمكن الكشف عنها، والتي يوجد منها 3 إلى الاحتمال الخامس، وهي 

118
00:06:48,730 --> 00:06:52,340
منظمة من اليسار إلى اليمين، من الأكثر شيوعًا إلى الأقل شيوعًا. 

119
00:06:52,920 --> 00:06:56,000
لذا فإن الاحتمال الأكثر شيوعًا هنا هو أن تحصل على كل الألوان الرمادية. 

120
00:06:56,100 --> 00:06:58,120
ويحدث ذلك في حوالي 14% من الحالات. 

121
00:06:58,580 --> 00:07:03,592
وما تأمله عندما تقوم بالتخمين هو أن ينتهي بك الأمر في مكان ما في هذا الذيل 

122
00:07:03,592 --> 00:07:09,140
الطويل، مثل هنا حيث يوجد 18 احتمالًا فقط لما يطابق هذا النمط الذي يبدو بوضوح هكذا. 

123
00:07:09,920 --> 00:07:13,800
أو إذا غامرنا بالتحرك إلى اليسار قليلاً، كما تعلمون، ربما نقطع كل الطريق هنا. 

124
00:07:14,940 --> 00:07:16,180
حسنًا، إليك لغزًا جيدًا لك. 

125
00:07:16,540 --> 00:07:22,000
ما هي الكلمات الثلاث في اللغة الإنجليزية التي تبدأ بحرف W، وتنتهي بحرف Y، وفيها حرف R؟ 

126
00:07:22,480 --> 00:07:26,800
اتضح أن الإجابات هي، دعونا نرى، كلامية، ودودة، وساخرة. 

127
00:07:27,500 --> 00:07:31,685
لذا، للحكم على مدى جودة هذه الكلمة بشكل عام، نريد نوعًا من قياس 

128
00:07:31,685 --> 00:07:35,740
الكمية المتوقعة من المعلومات التي ستحصل عليها من هذا التوزيع. 

129
00:07:35,740 --> 00:07:40,136
إذا مررنا بكل نمط وضربنا احتمالية حدوثه في شيء 

130
00:07:40,136 --> 00:07:44,720
يقيس مدى معلوماته، فقد يمنحنا ذلك نتيجة موضوعية. 

131
00:07:45,960 --> 00:07:49,840
الآن قد تكون غريزتك الأولى بشأن ما يجب أن يكون عليه هذا الشيء هي عدد التطابقات. 

132
00:07:50,160 --> 00:07:52,400
تريد متوسطًا أقل لعدد المطابقات. 

133
00:07:52,800 --> 00:07:56,776
لكن بدلاً من ذلك، أود استخدام مقياس أكثر شمولاً ننسبه غالبًا إلى المعلومات، 

134
00:07:56,776 --> 00:08:00,649
والذي سيكون أكثر مرونة بمجرد أن يكون لدينا احتمالية مختلفة مخصصة لكل كلمة 

135
00:08:00,649 --> 00:08:04,260
من هذه الكلمات الـ 13000 لمعرفة ما إذا كانت هي الإجابة بالفعل أم لا. 

136
00:08:10,320 --> 00:08:13,480
الوحدة القياسية للمعلومات هي البت، والتي تحتوي على صيغة 

137
00:08:13,480 --> 00:08:16,980
مضحكة إلى حد ما، لكنها بديهية حقًا إذا نظرنا فقط إلى الأمثلة. 

138
00:08:17,780 --> 00:08:20,527
إذا كانت لديك ملاحظة تختصر مساحة الاحتمالات لديك 

139
00:08:20,527 --> 00:08:23,500
إلى النصف، نقول إنها تحتوي على بت واحد من المعلومات. 

140
00:08:24,180 --> 00:08:27,574
في مثالنا، مساحة الاحتمالات هي كل الكلمات الممكنة، وتبين أن حوالي نصف 

141
00:08:27,574 --> 00:08:31,260
الكلمات المكونة من خمسة أحرف بها حرف S، أقل من ذلك بقليل، ولكن حوالي النصف. 

142
00:08:31,780 --> 00:08:34,320
لذا فإن هذه الملاحظة ستمنحك معلومة واحدة. 

143
00:08:34,880 --> 00:08:38,137
وبدلاً من ذلك، إذا أدت حقيقة جديدة إلى تقليص مساحة الاحتمالات 

144
00:08:38,137 --> 00:08:41,500
هذه إلى أربعة أضعاف، فسنقول إنها تحتوي على قطعتين من المعلومات. 

145
00:08:41,980 --> 00:08:44,460
على سبيل المثال، تبين أن حوالي ربع هذه الكلمات تحتوي على حرف T. 

146
00:08:45,020 --> 00:08:47,898
إذا قطعت الملاحظة هذا الفضاء بمقدار ثمانية أضعاف، 

147
00:08:47,898 --> 00:08:50,720
نقول إنها ثلاث أجزاء من المعلومات، وهكذا دواليك. 

148
00:08:50,900 --> 00:08:55,060
أربع بتات تقطعه إلى 16، وخمس بتات تقطعه إلى 32. 

149
00:08:55,060 --> 00:08:58,940
والآن قد ترغب في التوقف مؤقتًا وتسأل نفسك، ما هي 

150
00:08:58,940 --> 00:09:02,980
صيغة المعلومات لعدد البتات من حيث احتمال حدوث ذلك؟ 

151
00:09:03,920 --> 00:09:08,964
ما نقوله هنا هو أنه عندما تأخذ نصفًا لعدد البتات، فهذا هو نفس الاحتمال، وهو 

152
00:09:08,964 --> 00:09:13,676
نفس قول أن اثنين أس عدد البتات يساوي واحدًا على الاحتمال، وهو ما يُعاد 

153
00:09:13,676 --> 00:09:18,920
ترتيبها أيضًا لقول أن المعلومات هي سجل واحد للأساس اثنين مقسومًا على الاحتمال. 

154
00:09:19,620 --> 00:09:22,286
وفي بعض الأحيان ترى ذلك مع عملية إعادة ترتيب أخرى، 

155
00:09:22,286 --> 00:09:24,900
حيث تكون المعلومات هي سالب الاحتمال للأساس اثنين. 

156
00:09:25,660 --> 00:09:28,598
إذا تم التعبير عنها بهذه الطريقة، فقد تبدو غريبة بعض الشيء بالنسبة 

157
00:09:28,598 --> 00:09:31,317
للمبتدئين، ولكنها في الحقيقة مجرد فكرة بديهية للغاية تتمثل في 

158
00:09:31,317 --> 00:09:34,080
السؤال عن عدد المرات التي قمت فيها بتخفيض إمكانياتك إلى النصف. 

159
00:09:35,180 --> 00:09:37,259
الآن إذا كنت تتساءل، كما تعلمون، اعتقدت أننا كنا نلعب 

160
00:09:37,259 --> 00:09:39,300
لعبة كلمات ممتعة، لماذا تدخل اللوغاريتمات في الصورة؟ 

161
00:09:39,780 --> 00:09:44,207
أحد الأسباب التي تجعل هذه الوحدة أجمل هو أنه من الأسهل كثيرًا التحدث عن 

162
00:09:44,207 --> 00:09:48,573
أحداث غير محتملة للغاية، ومن الأسهل كثيرًا القول إن الملاحظة تحتوي على 

163
00:09:48,573 --> 00:09:52,940
20 بت من المعلومات مقارنة بالقول إن احتمال حدوث كذا وكذا هو 0.0000095. 

164
00:09:53,300 --> 00:09:57,349
لكن السبب الأكثر أهمية وراء تحول هذا التعبير اللوغاريتمي إلى إضافة 

165
00:09:57,349 --> 00:10:01,460
مفيدة جدًا لنظرية الاحتمال هو الطريقة التي تجمع بها المعلومات معًا. 

166
00:10:02,060 --> 00:10:06,681
على سبيل المثال، إذا أعطتك ملاحظة واحدة قطعتين من المعلومات، مما يقلل المساحة بمقدار 

167
00:10:06,681 --> 00:10:11,411
أربعة، ثم ملاحظة ثانية مثل تخمينك الثاني في Wordle تعطيك ثلاث أجزاء أخرى من المعلومات، 

168
00:10:11,411 --> 00:10:16,141
مما يقلل من المساحة بمقدار عامل آخر قدره ثمانية، فإن اثنان معًا يزودانك بخمسة أجزاء من 

169
00:10:16,141 --> 00:10:16,740
المعلومات. 

170
00:10:17,160 --> 00:10:21,020
بنفس الطريقة التي تحب بها الاحتمالات أن تتضاعف، تحب المعلومات أن تضيف. 

171
00:10:21,960 --> 00:10:25,108
لذلك بمجرد أن نكون في عالم شيء مثل القيمة المتوقعة، حيث نقوم بإضافة 

172
00:10:25,108 --> 00:10:27,980
مجموعة من الأرقام، فإن السجلات تجعل التعامل معها أفضل كثيرًا. 

173
00:10:28,480 --> 00:10:31,710
دعنا نعود إلى توزيعتنا لـ Weary ونضيف أداة تعقب صغيرة 

174
00:10:31,710 --> 00:10:34,940
أخرى هنا، لتوضح لنا مقدار المعلومات المتوفرة لكل نمط. 

175
00:10:35,580 --> 00:10:39,180
الشيء الرئيسي الذي أريدك أن تلاحظه هو أنه كلما زادت احتمالية وصولنا إلى تلك 

176
00:10:39,180 --> 00:10:42,780
الأنماط الأكثر احتمالية، كلما انخفضت المعلومات، وقل عدد البتات التي تكسبها. 

177
00:10:43,500 --> 00:10:48,719
الطريقة التي نقيس بها جودة هذا التخمين هي أخذ القيمة المتوقعة لهذه المعلومات، حيث نمر 

178
00:10:48,719 --> 00:10:54,060
عبر كل نمط، ونقول مدى احتمالية ذلك، ثم نضرب ذلك في عدد أجزاء المعلومات التي نحصل عليها. 

179
00:10:54,710 --> 00:10:58,120
وفي مثال Weary، تبين أن الرقم 4.9 بت. 

180
00:10:58,560 --> 00:11:02,118
لذا، في المتوسط، فإن المعلومات التي تحصل عليها من هذا التخمين الافتتاحي 

181
00:11:02,118 --> 00:11:05,480
جيدة مثل تقليص مساحة الاحتمالات الخاصة بك إلى النصف حوالي خمس مرات. 

182
00:11:05,960 --> 00:11:11,640
على النقيض من ذلك، مثال على التخمين ذو قيمة معلومات متوقعة أعلى سيكون مثل Slate. 

183
00:11:13,120 --> 00:11:15,620
في هذه الحالة ستلاحظ أن التوزيع يبدو أكثر تملقًا. 

184
00:11:15,940 --> 00:11:20,637
على وجه الخصوص، فإن احتمال حدوث جميع درجات الرمادي هو 6% فقط، 

185
00:11:20,637 --> 00:11:25,260
لذا فمن الواضح أنك تحصل على 3% على الأقل. 9 بت من المعلومات. 

186
00:11:25,920 --> 00:11:28,560
ولكن هذا هو الحد الأدنى، وعادة ما تحصل على شيء أفضل من ذلك. 

187
00:11:29,100 --> 00:11:32,582
واتضح أنه عندما تقوم بجمع الأرقام الموجودة في هذا الرقم وإضافة 

188
00:11:32,582 --> 00:11:35,900
جميع المصطلحات ذات الصلة، فإن متوسط المعلومات هو حوالي 5.8. 

189
00:11:37,360 --> 00:11:40,393
لذا، على النقيض من Weary، فإن مساحة الاحتمالات الخاصة 

190
00:11:40,393 --> 00:11:43,540
بك ستكون حوالي النصف بعد هذا التخمين الأول، في المتوسط. 

191
00:11:44,420 --> 00:11:49,120
هناك في الواقع قصة ممتعة حول اسم هذه القيمة المتوقعة لكمية المعلومات. 

192
00:11:49,200 --> 00:11:54,041
تم تطوير نظرية المعلومات على يد كلود شانون، الذي كان يعمل في مختبرات بيل في الأربعينيات، 

193
00:11:54,041 --> 00:11:58,773
لكنه كان يتحدث عن بعض أفكاره التي لم تُنشر بعد مع جون فون نيومان، الذي كان هذا العملاق 

194
00:11:58,773 --> 00:12:03,560
الفكري في ذلك الوقت، بارزًا جدًا في الرياضيات والفيزياء وبدايات ما أصبح علوم الكمبيوتر. 

195
00:12:04,100 --> 00:12:08,903
وعندما ذكر أنه ليس لديه حقًا اسم جيد لهذه القيمة المتوقعة لكمية المعلومات، من 

196
00:12:08,903 --> 00:12:14,200
المفترض أن فون نيومان قال، وفقًا للقصة، حسنًا، يجب أن تسميها الإنتروبيا، وذلك لسببين. 

197
00:12:14,540 --> 00:12:18,557
في المقام الأول، تم استخدام دالة عدم اليقين في الميكانيكا الإحصائية تحت 

198
00:12:18,557 --> 00:12:22,575
هذا الاسم، لذا فهي تحمل اسمًا بالفعل، وفي المقام الثاني، والأهم من ذلك، 

199
00:12:22,575 --> 00:12:26,760
لا أحد يعرف ما هي الإنتروبيا حقًا، لذلك في أي نقاش ستظل دائمًا لدينا ميزة. 

200
00:12:27,700 --> 00:12:29,982
لذا، إذا كان الاسم يبدو غامضًا بعض الشيء، وإذا 

201
00:12:29,982 --> 00:12:32,460
كان لهذه القصة أن تصدق، فهذا نوعاً ما حسب التصميم. 

202
00:12:33,280 --> 00:12:37,499
وأيضًا إذا كنت تتساءل عن علاقتها بكل ما يتعلق بالقانون الثاني للديناميكا 

203
00:12:37,499 --> 00:12:41,603
الحرارية من الفيزياء، فمن المؤكد أن هناك صلة، ولكن في أصولها كان شانون 

204
00:12:41,603 --> 00:12:45,533
يتعامل فقط مع نظرية الاحتمالات البحتة، ولأغراضنا هنا، عندما استخدمت 

205
00:12:45,533 --> 00:12:49,580
الإنتروبيا، أريدك فقط أن تفكر في قيمة المعلومات المتوقعة لتخمين معين. 

206
00:12:50,700 --> 00:12:53,780
يمكنك التفكير في الإنتروبيا على أنها قياس شيئين في وقت واحد. 

207
00:12:54,240 --> 00:12:56,780
الأول هو مدى ثبات التوزيع. 

208
00:12:57,320 --> 00:13:01,120
كلما كان التوزيع أقرب إلى الانتظام، كلما زادت الإنتروبيا. 

209
00:13:01,580 --> 00:13:06,746
في حالتنا، حيث يوجد 3 إلى 5 أنماط إجمالية، للتوزيع الموحد، فإن مراقبة 

210
00:13:06,746 --> 00:13:11,986
أي واحد منها سيكون له قاعدة سجل معلومات 2 من 3 إلى 5، وهو ما يصادف أنه 

211
00:13:11,986 --> 00:13:17,300
7.92، هذا هو الحد الأقصى المطلق الذي يمكن أن تحصل عليه لهذه الإنتروبيا. 

212
00:13:17,840 --> 00:13:22,080
لكن الإنتروبيا هي أيضًا نوع من مقياس لعدد الاحتمالات الموجودة في المقام الأول. 

213
00:13:22,320 --> 00:13:27,284
على سبيل المثال، إذا كان لديك كلمة حيث يوجد فقط 16 نمطًا ممكنًا، وكل نمط 

214
00:13:27,284 --> 00:13:32,180
محتمل متساوٍ، فإن هذه الإنتروبيا، هذه المعلومات المتوقعة، ستكون 4 بتات. 

215
00:13:32,579 --> 00:13:36,693
لكن إذا كانت لديك كلمة أخرى حيث يمكن أن تظهر 64 نمطًا محتملاً، 

216
00:13:36,693 --> 00:13:40,480
وجميعها متساوية في الاحتمال، فإن الإنتروبيا ستكون 6 بتات. 

217
00:13:41,500 --> 00:13:45,578
لذا، إذا رأيت بعض التوزيعات في الطبيعة والتي تحتوي على إنتروبيا تبلغ 

218
00:13:45,578 --> 00:13:49,716
6 بتات، فهذا يشبه القول بأن هناك قدرًا كبيرًا من الاختلاف وعدم اليقين 

219
00:13:49,716 --> 00:13:53,500
فيما هو على وشك الحدوث كما لو كان هناك 64 نتيجة محتملة متساوية. 

220
00:13:54,360 --> 00:13:59,320
في أول تمريرة لي في Wurtelebot، طلبت مني فعل هذا فقط. 

221
00:13:59,320 --> 00:14:03,525
إنه يمر بجميع التخمينات المحتملة التي يمكن أن تكون لديك، كل الكلمات البالغ 

222
00:14:03,525 --> 00:14:07,617
عددها 13000 كلمة، ويحسب الإنتروبيا لكل واحدة منها، أو بشكل أكثر تحديدًا، 

223
00:14:07,617 --> 00:14:11,766
إنتروبيا التوزيع عبر جميع الأنماط التي قد تراها، لكل واحد، ويختار الأعلى، 

224
00:14:11,766 --> 00:14:16,140
نظرًا لأن ذلك الذي من المحتمل أن يقلل مساحة الاحتمالات الخاصة بك قدر الإمكان. 

225
00:14:17,140 --> 00:14:19,120
وعلى الرغم من أنني كنت أتحدث فقط عن التخمين الأول هنا، 

226
00:14:19,120 --> 00:14:21,100
فإنه يفعل نفس الشيء بالنسبة للتخمينات القليلة التالية. 

227
00:14:21,560 --> 00:14:24,907
على سبيل المثال، بعد أن ترى بعض الأنماط في هذا التخمين الأول، والتي 

228
00:14:24,907 --> 00:14:28,353
من شأنها أن تقيدك بعدد أقل من الكلمات المحتملة بناءً على ما يتطابق مع 

229
00:14:28,353 --> 00:14:31,800
ذلك، فإنك تلعب نفس اللعبة فيما يتعلق بتلك المجموعة الأصغر من الكلمات. 

230
00:14:32,260 --> 00:14:36,063
للحصول على تخمين ثانٍ مقترح، تنظر إلى توزيع جميع الأنماط التي يمكن 

231
00:14:36,063 --> 00:14:39,752
أن تحدث من تلك المجموعة الأكثر تقييدًا من الكلمات، وتبحث في جميع 

232
00:14:39,752 --> 00:14:43,840
الاحتمالات البالغ عددها 13000، وتجد الخيار الذي يزيد من هذه الإنتروبيا. 

233
00:14:45,420 --> 00:14:49,657
لكي أوضح لك كيف يتم ذلك عمليًا، اسمحوا لي أن أعرض نسخة صغيرة من كتاب 

234
00:14:49,657 --> 00:14:54,080
Wurtele الذي كتبته والذي يوضح النقاط البارزة في هذا التحليل في الهوامش. 

235
00:14:54,080 --> 00:14:56,930
بعد إجراء جميع حسابات الإنتروبيا، تظهر لنا على 

236
00:14:56,930 --> 00:14:59,660
اليمين أي منها لديه أعلى المعلومات المتوقعة. 

237
00:15:00,280 --> 00:15:05,356
اتضح أن الإجابة الرئيسية، على الأقل في الوقت الحالي، وسنقوم بتحسينها 

238
00:15:05,356 --> 00:15:10,580
لاحقًا، هي الزوان، والتي تعني، بالطبع، البيقية، البيقية الأكثر شيوعًا. 

239
00:15:11,040 --> 00:15:14,458
في كل مرة نقوم بالتخمين هنا، حيث ربما أتجاهل توصياتها نوعًا ما وأختار 

240
00:15:14,458 --> 00:15:17,730
القائمة، لأنني أحب القائمة، يمكننا أن نرى مقدار المعلومات المتوقعة 

241
00:15:17,730 --> 00:15:20,952
التي تحتوي عليها، ولكن بعد ذلك على يمين الكلمة هنا تظهر لنا مقدار 

242
00:15:20,952 --> 00:15:24,420
المعلومات المعلومات الفعلية التي حصلنا عليها، في ضوء هذا النمط بالذات. 

243
00:15:25,000 --> 00:15:27,514
لذا يبدو هنا أننا لم نكن محظوظين بعض الشيء، حيث كان من 

244
00:15:27,514 --> 00:15:30,120
المتوقع أن نحصل على 5.8، لكننا حصلنا على شيء أقل من ذلك. 

245
00:15:30,600 --> 00:15:32,858
ثم على الجانب الأيسر هنا يظهر لنا جميع الكلمات 

246
00:15:32,858 --> 00:15:35,020
المختلفة الممكنة بالنظر إلى ما نحن فيه الآن. 

247
00:15:35,800 --> 00:15:39,679
تخبرنا الأشرطة الزرقاء بمدى احتمالية التفكير في كل كلمة، لذلك في الوقت الحالي 

248
00:15:39,679 --> 00:15:43,360
يفترض أن كل كلمة من المرجح أن تحدث بشكل متساوٍ، ولكننا سنحسن ذلك في لحظة. 

249
00:15:44,060 --> 00:15:50,010
ومن ثم يخبرنا قياس عدم اليقين هذا بإنتروبيا هذا التوزيع عبر الكلمات المحتملة، والتي في 

250
00:15:50,010 --> 00:15:55,960
الوقت الحالي، نظرًا لأنه توزيع موحد، هي مجرد طريقة معقدة بلا داع لحساب عدد الاحتمالات. 

251
00:15:56,560 --> 00:16:02,180
على سبيل المثال، إذا أخذنا 2 أس 13.66، ينبغي أن يكون حوالي 13000 الاحتمالات. 

252
00:16:02,900 --> 00:16:06,140
أنا متوقف قليلاً هنا، ولكن فقط لأنني لا أعرض جميع المنازل العشرية. 

253
00:16:06,720 --> 00:16:09,568
في الوقت الحالي، قد يبدو هذا زائدًا عن الحاجة ويؤدي إلى تعقيد الأمور بشكل 

254
00:16:09,568 --> 00:16:12,340
مفرط، ولكنك سترى لماذا من المفيد الحصول على كلا الرقمين في دقيقة واحدة. 

255
00:16:12,760 --> 00:16:16,048
لذا يبدو هنا أنه يشير إلى أن أعلى إنتروبيا لتخميننا 

256
00:16:16,048 --> 00:16:19,400
الثاني هي رامين، والتي مرة أخرى لا تبدو وكأنها كلمة. 

257
00:16:19,980 --> 00:16:24,060
لذا، لكي أتخذ موقفًا أخلاقيًا عاليًا هنا، سأمضي قدمًا وأكتب Rains. 

258
00:16:25,440 --> 00:16:27,340
ومرة أخرى يبدو أننا لم نكن محظوظين بعض الشيء. 

259
00:16:27,520 --> 00:16:31,360
كنا نتوقع 4.3 بتات وحصلنا على 3 فقط. 39 بت من المعلومات. 

260
00:16:31,940 --> 00:16:33,940
وهذا ينقلنا إلى 55 احتمالًا. 

261
00:16:34,900 --> 00:16:39,440
وهنا ربما سأوافق على ما يقترحه، وهو السرد، مهما كان معنى ذلك. 

262
00:16:40,040 --> 00:16:42,920
حسنًا، هذه في الواقع فرصة جيدة لحل اللغز. 

263
00:16:42,920 --> 00:16:46,380
إنه يخبرنا أن هذا النمط يعطينا 4.7 بت من المعلومات. 

264
00:16:47,060 --> 00:16:51,720
لكن على اليسار، قبل أن نرى هذا النمط، كان هناك 5.78 بت من عدم اليقين. 

265
00:16:52,420 --> 00:16:56,340
لذا، كاختبار لك، ماذا يعني ذلك بالنسبة لعدد الاحتمالات المتبقية؟ 

266
00:16:58,040 --> 00:17:01,129
حسنًا، هذا يعني أننا قد اختزلنا إلى جزء واحد من 

267
00:17:01,129 --> 00:17:04,540
عدم اليقين، وهو نفس القول بأن هناك إجابتين محتملتين. 

268
00:17:04,700 --> 00:17:05,700
إنه خيار 50-50. 

269
00:17:06,500 --> 00:17:08,725
ومن هنا، ولأنني وأنت نعرف أي الكلمات أكثر شيوعاً، 

270
00:17:08,725 --> 00:17:10,640
فإننا نعلم أن الإجابة يجب أن تكون الهاوية. 

271
00:17:11,180 --> 00:17:13,280
ولكن كما هو مكتوب الآن، فإن البرنامج لا يعرف ذلك. 

272
00:17:13,540 --> 00:17:16,668
لذلك فهو يستمر في محاولة الحصول على أكبر قدر ممكن 

273
00:17:16,668 --> 00:17:19,859
من المعلومات، حتى يتبقى احتمال واحد فقط، ثم يخمنه. 

274
00:17:20,380 --> 00:17:22,339
لذا من الواضح أننا بحاجة إلى استراتيجية أفضل لنهاية اللعبة. 

275
00:17:22,599 --> 00:17:25,405
لكن لنفترض أننا نطلق على هذا الإصدار أحد برامج حل الكلمات 

276
00:17:25,405 --> 00:17:28,260
لدينا، ثم نبدأ ونجري بعض عمليات المحاكاة لنرى كيف يتم ذلك. 

277
00:17:30,360 --> 00:17:34,120
لذا فإن الطريقة التي يعمل بها هذا الأمر هي لعب كل لعبة كلمات ممكنة. 

278
00:17:34,240 --> 00:17:38,540
إنها تمر بكل تلك الكلمات البالغ عددها 2315 والتي تمثل الإجابات الفعلية. 

279
00:17:38,540 --> 00:17:40,580
إنها تستخدم ذلك بشكل أساسي كمجموعة اختبار. 

280
00:17:41,360 --> 00:17:45,649
ومع هذه الطريقة الساذجة المتمثلة في عدم مراعاة مدى شيوع الكلمة، ومحاولة 

281
00:17:45,649 --> 00:17:49,820
تعظيم المعلومات في كل خطوة على طول الطريق، حتى تصل إلى خيار واحد فقط. 

282
00:17:50,360 --> 00:17:54,300
وبحلول نهاية المحاكاة، يبلغ متوسط الدرجات حوالي 4.124. 

283
00:17:55,319 --> 00:17:59,240
وهذا ليس سيئًا، لأكون صادقًا، كنت أتوقع نوعًا ما أن أفعل ما هو أسوأ. 

284
00:17:59,660 --> 00:18:02,600
لكن الأشخاص الذين يلعبون لعبة Wordle سيخبرونك أنه يمكنهم عادةً الحصول عليها خلال 4. 

285
00:18:02,860 --> 00:18:05,380
التحدي الحقيقي هو الحصول على أكبر عدد ممكن من 3. 

286
00:18:05,380 --> 00:18:08,080
إنها قفزة كبيرة جدًا بين النتيجة 4 والنتيجة 3. 

287
00:18:08,860 --> 00:18:12,186
إن الفاكهة المعلقة الواضحة هنا هي دمج ما إذا كانت 

288
00:18:12,186 --> 00:18:14,980
الكلمة شائعة أم لا، وكيف نفعل ذلك بالضبط. 

289
00:18:22,800 --> 00:18:25,316
الطريقة التي تعاملت بها مع الأمر هي الحصول على قائمة 

290
00:18:25,316 --> 00:18:27,880
بالتكرارات النسبية لجميع الكلمات في اللغة الإنجليزية. 

291
00:18:28,220 --> 00:18:31,610
وقد استخدمت للتو وظيفة بيانات تردد الكلمات الخاصة بـ Mathematica، والتي 

292
00:18:31,610 --> 00:18:34,860
تستمد نفسها من مجموعة البيانات العامة لـ Google Books English Ngram. 

293
00:18:35,460 --> 00:18:37,794
ومن الممتع النظر إليه، على سبيل المثال، إذا قمنا بفرزه 

294
00:18:37,794 --> 00:18:39,960
من الكلمات الأكثر شيوعًا إلى الكلمات الأقل شيوعًا. 

295
00:18:40,120 --> 00:18:43,080
من الواضح أن هذه هي الكلمات الأكثر شيوعًا والمكونة من 5 أحرف في اللغة الإنجليزية. 

296
00:18:43,700 --> 00:18:45,840
أو بالأحرى، هذه هي المرتبة الثامنة الأكثر شيوعًا. 

297
00:18:46,280 --> 00:18:48,880
الأول هو الذي، وبعد ذلك هناك وهناك. 

298
00:18:49,260 --> 00:18:53,920
الأول في حد ذاته ليس الأول، بل التاسع، ومن المنطقي أن هذه الكلمات الأخرى يمكن أن تأتي في 

299
00:18:53,920 --> 00:18:58,580
كثير من الأحيان، حيث تكون تلك الكلمات التي تأتي بعد الأول، وأين، وتلك أقل شيوعًا قليلاً. 

300
00:18:59,160 --> 00:19:02,903
الآن، عند استخدام هذه البيانات لنمذجة مدى احتمالية أن تكون كل كلمة من 

301
00:19:02,903 --> 00:19:06,860
هذه الكلمات هي الإجابة النهائية، لا ينبغي أن تكون متناسبة مع التكرار فقط. 

302
00:19:06,860 --> 00:19:10,996
على سبيل المثال، الذي يعطى درجة 0.002 في مجموعة البيانات 

303
00:19:10,996 --> 00:19:15,060
هذه، في حين أن كلمة جديلة أقل احتمالًا بحوالي 1000 مرة. 

304
00:19:15,560 --> 00:19:18,840
لكن كلتا هاتين الكلمتين شائعتان بدرجة كافية ومن المؤكد أنهما تستحقان أخذهما في الاعتبار. 

305
00:19:19,340 --> 00:19:21,000
لذلك نريد المزيد من القطع الثنائي. 

306
00:19:21,860 --> 00:19:25,672
الطريقة التي اتبعتها في ذلك هي تخيل أخذ هذه القائمة الكاملة من 

307
00:19:25,672 --> 00:19:29,727
الكلمات، ثم ترتيبها على المحور السيني، ثم تطبيق الدالة السيني، وهي 

308
00:19:29,727 --> 00:19:33,660
الطريقة القياسية للحصول على دالة يكون ناتجها ثنائيًا بشكل أساسي، 

309
00:19:33,660 --> 00:19:38,260
إنها إما 0 أو 1، ولكن هناك تجانس بينهما بالنسبة لتلك المنطقة من عدم اليقين. 

310
00:19:39,160 --> 00:19:43,515
لذلك، بشكل أساسي، فإن الاحتمال الذي أقوم بتعيينه لكل كلمة لوجودها في 

311
00:19:43,515 --> 00:19:48,440
القائمة النهائية سيكون قيمة الدالة السيني أعلاه أينما كانت على المحور السيني. 

312
00:19:49,520 --> 00:19:53,890
من الواضح الآن أن هذا يعتمد على بعض المعلمات، على سبيل المثال مدى اتساع 

313
00:19:53,890 --> 00:19:58,565
المساحة على المحور السيني التي تملأها تلك الكلمات يحدد مدى انخفاضنا تدريجيًا 

314
00:19:58,565 --> 00:20:03,240
أو حادًا من 1 إلى 0، والمكان الذي نضعهم فيه من اليسار إلى اليمين يحدد القطع. 

315
00:20:03,240 --> 00:20:06,920
لأكون صادقًا، الطريقة التي فعلت بها ذلك كانت مجرد لعق إصبعي ووضعه في مهب الريح. 

316
00:20:07,140 --> 00:20:12,171
لقد بحثت في القائمة التي تم فرزها وحاولت العثور على نافذة حيث عندما نظرت إليها، اكتشفت 

317
00:20:12,171 --> 00:20:17,260
أن حوالي نصف هذه الكلمات من المرجح أن لا تكون الإجابة النهائية، واستخدمت ذلك كنقطة قطع. 

318
00:20:17,260 --> 00:20:20,675
بمجرد أن يكون لدينا توزيع مثل هذا عبر الكلمات، فهذا يعطينا 

319
00:20:20,675 --> 00:20:23,860
موقفًا آخر تصبح فيه الإنتروبيا هذا القياس المفيد حقًا. 

320
00:20:24,500 --> 00:20:28,843
على سبيل المثال، لنفترض أننا كنا نلعب لعبة وبدأنا بافتتاحيتي القديمة، والتي كانت 

321
00:20:28,843 --> 00:20:33,240
عبارة عن ريشة ومسامير، وانتهى بنا الأمر بموقف حيث توجد أربع كلمات محتملة تطابقها. 

322
00:20:33,560 --> 00:20:35,620
ولنفترض أننا نعتبرها كلها محتملة على قدم المساواة. 

323
00:20:36,220 --> 00:20:38,880
دعني أسألك، ما هي إنتروبيا هذا التوزيع؟ 

324
00:20:41,080 --> 00:20:45,282
حسنًا، المعلومات المرتبطة بكل واحد من هذه الاحتمالات 

325
00:20:45,282 --> 00:20:50,040
ستكون السجل ذو الأساس 2 من 4، حيث أن كل واحد هو 1 و4، أي 2. 

326
00:20:50,040 --> 00:20:52,460
قطعتان من المعلومات، وأربعة احتمالات. 

327
00:20:52,760 --> 00:20:53,580
كل شيء جيد جدا وجيد. 

328
00:20:54,300 --> 00:20:57,800
ولكن ماذا لو أخبرتك أن هناك بالفعل أكثر من أربع مباريات؟ 

329
00:20:58,260 --> 00:21:02,460
في الواقع، عندما ننظر إلى قائمة الكلمات الكاملة، نجد أن هناك 16 كلمة تطابقها. 

330
00:21:02,580 --> 00:21:06,700
لكن لنفترض أن نموذجنا يضع احتمالًا منخفضًا حقًا لتلك الكلمات الـ 12 

331
00:21:06,700 --> 00:21:10,760
الأخرى لتكون الإجابة النهائية، شيء مثل 1 في 1000 لأنها غامضة حقًا. 

332
00:21:11,500 --> 00:21:14,260
والآن دعني أسألك، ما هي إنتروبيا هذا التوزيع؟ 

333
00:21:15,420 --> 00:21:20,496
إذا كانت الإنتروبيا تقيس فقط عدد التطابقات هنا، فقد تتوقع أن تكون شيئًا مثل سجل 

334
00:21:20,496 --> 00:21:25,700
الأساس 2 لـ 16، والذي سيكون 4، أي قطعتين من عدم اليقين أكثر مما كان لدينا من قبل. 

335
00:21:26,180 --> 00:21:29,860
لكن بطبيعة الحال، فإن عدم اليقين الفعلي لا يختلف كثيرًا عما كان لدينا من قبل. 

336
00:21:30,160 --> 00:21:33,591
فقط لأن هناك هذه الكلمات الـ 12 الغامضة لا يعني أنه سيكون من 

337
00:21:33,591 --> 00:21:37,360
المثير للدهشة معرفة أن الإجابة النهائية هي السحر، على سبيل المثال. 

338
00:21:38,180 --> 00:21:41,641
لذلك عندما تقوم بالحساب هنا، وتضيف احتمالية كل تكرار 

339
00:21:41,641 --> 00:21:45,560
مضروبًا في المعلومات المقابلة، فإن ما تحصل عليه هو 2.11 بت. 

340
00:21:45,560 --> 00:21:49,240
أنا فقط أقول، إنها في الأساس جزأين، أساسًا تلك الاحتمالات الأربعة، ولكن 

341
00:21:49,240 --> 00:21:52,921
هناك القليل من عدم اليقين بسبب كل تلك الأحداث غير المحتملة إلى حد كبير، 

342
00:21:52,921 --> 00:21:56,500
على الرغم من أنك إذا تعلمتها، فسوف تحصل على الكثير من المعلومات منها. 

343
00:21:57,160 --> 00:22:01,400
لذا، فإن التصغير هو جزء مما يجعل Wordle مثالًا رائعًا لدرس نظرية المعلومات. 

344
00:22:01,600 --> 00:22:04,640
لدينا هذين التطبيقين المتميزين للشعور بالإنتروبيا. 

345
00:22:05,160 --> 00:22:10,098
الأول يخبرنا ما هي المعلومات المتوقعة التي سنحصل عليها من تخمين معين، 

346
00:22:10,098 --> 00:22:15,460
والثاني يقول هل يمكننا قياس عدم اليقين المتبقي بين جميع الكلمات التي لدينا. 

347
00:22:16,460 --> 00:22:20,673
ويجب أن أؤكد، في تلك الحالة الأولى التي ننظر فيها إلى المعلومات المتوقعة من التخمين، 

348
00:22:20,673 --> 00:22:24,540
بمجرد أن يكون لدينا وزن غير متساوٍ للكلمات، فإن ذلك يؤثر على حساب الإنتروبيا. 

349
00:22:24,980 --> 00:22:29,270
على سبيل المثال، اسمحوا لي أن أذكر نفس الحالة التي كنا ننظر إليها سابقًا للتوزيع 

350
00:22:29,270 --> 00:22:33,720
المرتبط بـ Weary، ولكن هذه المرة باستخدام توزيع غير منتظم عبر جميع الكلمات الممكنة. 

351
00:22:34,500 --> 00:22:38,280
لذلك اسمحوا لي أن أرى ما إذا كان بإمكاني العثور على جزء هنا يوضح ذلك بشكل جيد. 

352
00:22:40,940 --> 00:22:42,360
حسنًا، هنا هذا جيد جدًا. 

353
00:22:42,360 --> 00:22:45,635
لدينا هنا نمطان متجاوران متساويان في الاحتمال، ولكن 

354
00:22:45,635 --> 00:22:49,100
قيل لنا أن أحدهما يحتوي على 32 كلمة محتملة تتطابق معه. 

355
00:22:49,280 --> 00:22:52,523
وإذا تحققنا من ماهيتها، فهذه هي تلك الكلمات الـ 32، والتي 

356
00:22:52,523 --> 00:22:55,600
كلها مجرد كلمات غير محتملة للغاية عندما تفحصها بعينيك. 

357
00:22:55,840 --> 00:23:00,287
من الصعب العثور على أي إجابات تبدو وكأنها إجابات معقولة، وربما صيحات، ولكن إذا 

358
00:23:00,287 --> 00:23:04,847
نظرنا إلى النمط المجاور في التوزيع، والذي يعتبر محتملًا تقريبًا، فقد قيل لنا أنه 

359
00:23:04,847 --> 00:23:09,520
يحتوي على 8 تطابقات محتملة فقط، أي ربع العديد من المباريات، ولكن الأمر على الأرجح. 

360
00:23:09,860 --> 00:23:12,140
وعندما نسحب تلك الثقاب، يمكننا أن نرى السبب. 

361
00:23:12,500 --> 00:23:16,300
بعض هذه الإجابات هي إجابات معقولة بالفعل، مثل الخاتم، أو الغضب، أو موسيقى الراب. 

362
00:23:17,900 --> 00:23:21,616
لتوضيح كيفية دمج كل ذلك، اسمحوا لي أن أعرض الإصدار 2 من Wordlebot هنا، 

363
00:23:21,616 --> 00:23:25,280
وهناك اختلافان أو ثلاثة اختلافات رئيسية عن الإصدار الأول الذي رأيناه. 

364
00:23:25,860 --> 00:23:30,053
أولاً، كما قلت للتو، الطريقة التي نحسب بها هذه الإنتروبيا، هذه 

365
00:23:30,053 --> 00:23:33,980
القيم المتوقعة للمعلومات، تستخدم الآن توزيعات أكثر دقة عبر 

366
00:23:33,980 --> 00:23:38,240
الأنماط التي تتضمن احتمال أن تكون كلمة معينة هي الإجابة بالفعل. 

367
00:23:38,879 --> 00:23:43,820
كما يحدث، لا تزال الدموع هي رقم 1، على الرغم من أن الدموع التالية مختلفة بعض الشيء. 

368
00:23:44,360 --> 00:23:48,007
ثانيًا، عندما يقوم بتصنيف أفضل اختياراته، فإنه سيحتفظ الآن بنموذج 

369
00:23:48,007 --> 00:23:51,598
لاحتمال أن تكون كل كلمة هي الإجابة الفعلية، وسيدمج ذلك في قراره، 

370
00:23:51,598 --> 00:23:55,080
وهو ما يسهل رؤيته بمجرد أن يكون لدينا بعض التخمينات على طاولة. 

371
00:23:55,860 --> 00:23:59,780
مرة أخرى، تجاهل توصيتها لأننا لا نستطيع السماح للآلات بالتحكم في حياتنا. 

372
00:24:01,140 --> 00:24:05,224
وأفترض أنني يجب أن أذكر شيئًا آخر مختلفًا هنا على اليسار، وهو أن قيمة عدم 

373
00:24:05,224 --> 00:24:09,640
اليقين، وعدد البتات هذا، لم تعد مجرد زائدة عن الحاجة مع عدد التطابقات المحتملة. 

374
00:24:10,080 --> 00:24:16,285
الآن إذا سحبناها للأعلى وحسابنا 2 إلى 8.02، وهو أعلى قليلاً من 256، أعتقد 259، ما يقوله 

375
00:24:16,285 --> 00:24:22,209
هو أنه على الرغم من وجود 526 كلمة إجمالية تتطابق فعليًا مع هذا النمط، فإن مقدار عدم 

376
00:24:22,209 --> 00:24:28,345
اليقين الموجود فيه أقرب إلى ما سيكون عليه لو كان هناك 259 كلمة محتملة على قدم المساواة 

377
00:24:28,345 --> 00:24:28,980
النتائج. 

378
00:24:29,720 --> 00:24:30,740
يمكنك التفكير في الأمر على هذا النحو. 

379
00:24:31,020 --> 00:24:34,377
إنه يعرف أن البورق ليس هو الحل، كما هو الحال مع yorts وzorl 

380
00:24:34,377 --> 00:24:37,680
وzorus، لذا فهو أقل غموضًا مما كان عليه في الحالة السابقة. 

381
00:24:37,820 --> 00:24:39,280
سيكون هذا العدد من البتات أصغر. 

382
00:24:40,220 --> 00:24:43,441
وإذا واصلت لعب اللعبة، فسوف أقوم بتحسين ذلك من خلال 

383
00:24:43,441 --> 00:24:46,540
بعض التخمينات التي تتناسب مع ما أود أن أشرحه هنا. 

384
00:24:48,360 --> 00:24:51,218
من خلال التخمين الرابع، إذا نظرت إلى أفضل اختياراتها، 

385
00:24:51,218 --> 00:24:53,760
يمكنك أن ترى أنها لم تعد مجرد تعظيم الإنتروبيا. 

386
00:24:54,460 --> 00:24:57,203
إذن في هذه المرحلة، هناك سبعة احتمالات من الناحية الفنية، لكن 

387
00:24:57,203 --> 00:25:00,300
الاحتمالات الوحيدة التي لديها فرصة ذات معنى هي مساكن الطلبة والكلمات. 

388
00:25:00,300 --> 00:25:03,424
ويمكنك أن ترى أن اختيار كلتا القيمتين فوق كل هذه القيم 

389
00:25:03,424 --> 00:25:06,720
الأخرى، بالمعنى الدقيق للكلمة، سيعطي المزيد من المعلومات. 

390
00:25:07,240 --> 00:25:10,681
في المرة الأولى التي قمت فيها بذلك، قمت فقط بجمع هذين الرقمين 

391
00:25:10,681 --> 00:25:13,900
لقياس جودة كل تخمين، والذي كان في الواقع أفضل مما قد تظن. 

392
00:25:14,300 --> 00:25:16,820
لكن الأمر لم يكن منهجيًا حقًا، وأنا متأكد من أن هناك طرقًا 

393
00:25:16,820 --> 00:25:19,340
أخرى يمكن للناس اتباعها ولكن هذا هو النهج الذي توصلت إليه. 

394
00:25:19,760 --> 00:25:23,858
إذا كنا نفكر في احتمالية التخمين التالي، كما هو الحال في الكلمات في هذه 

395
00:25:23,858 --> 00:25:27,900
الحالة، فإن ما نهتم به حقًا هو النتيجة المتوقعة للعبتنا إذا فعلنا ذلك. 

396
00:25:28,230 --> 00:25:31,930
ولحساب تلك النتيجة المتوقعة، نقول ما هو احتمال أن تكون 

397
00:25:31,930 --> 00:25:35,900
الكلمات هي الإجابة الفعلية، والتي تصف في الوقت الحالي 58%. 

398
00:25:36,040 --> 00:25:39,540
نقول باحتمال 58% أن نتيجتنا في هذه المباراة ستكون 4. 

399
00:25:40,320 --> 00:25:45,640
وبعد ذلك، مع احتمال 1 ناقص 58%، ستكون درجاتنا أكثر من 4. 

400
00:25:46,220 --> 00:25:49,245
لا نعرف كم من ذلك، ولكن يمكننا تقديره بناءً على 

401
00:25:49,245 --> 00:25:52,460
مقدار عدم اليقين المحتمل عندما نصل إلى هذه النقطة. 

402
00:25:52,960 --> 00:25:55,940
على وجه التحديد، في هذه اللحظة هناك 1.44 بت من عدم اليقين. 

403
00:25:56,440 --> 00:26:01,120
إذا خمننا الكلمات، فهذا يخبرنا أن المعلومات المتوقعة التي سنحصل عليها هي 1.27 بت. 

404
00:26:01,620 --> 00:26:04,699
لذا، إذا خمننا الكلمات، فإن هذا الاختلاف يمثل مقدار 

405
00:26:04,699 --> 00:26:07,660
عدم اليقين الذي من المحتمل أن نتركه بعد حدوث ذلك. 

406
00:26:08,260 --> 00:26:11,116
ما نحتاجه هو نوع من الوظائف، والتي أسميها f هنا، 

407
00:26:11,116 --> 00:26:13,740
والتي تربط عدم اليقين هذا بالنتيجة المتوقعة. 

408
00:26:14,240 --> 00:26:18,089
وكانت الطريقة التي تم بها تحقيق ذلك هي رسم مجموعة من البيانات من 

409
00:26:18,089 --> 00:26:22,234
الألعاب السابقة استنادًا إلى الإصدار 1 من الروبوت لنقول ما هي النتيجة 

410
00:26:22,234 --> 00:26:26,320
الفعلية بعد نقاط مختلفة مع قدر معين من عدم اليقين يمكن قياسه للغاية. 

411
00:26:27,020 --> 00:26:30,898
على سبيل المثال، نقاط البيانات هذه الموجودة هنا أعلى قيمة تقارب 

412
00:26:30,898 --> 00:26:34,656
8.7 أو نحو ذلك يقال لبعض الألعاب بعد النقطة التي كان فيها 8.7 

413
00:26:34,656 --> 00:26:38,960
أجزاء من عدم اليقين، استغرق الأمر تخمينين للحصول على الإجابة النهائية. 

414
00:26:39,320 --> 00:26:40,766
بالنسبة للألعاب الأخرى، استغرق الأمر ثلاثة تخمينات، 

415
00:26:40,766 --> 00:26:42,240
وبالنسبة للألعاب الأخرى، استغرق الأمر أربعة تخمينات. 

416
00:26:43,140 --> 00:26:46,774
إذا انتقلنا إلى اليسار هنا، فإن جميع النقاط فوق الصفر تشير إلى أنه 

417
00:26:46,774 --> 00:26:50,625
عندما يكون هناك صفر من عدم اليقين، وهو ما يعني أن هناك احتمالًا واحدًا 

418
00:26:50,625 --> 00:26:54,260
فقط، فإن عدد التخمينات المطلوبة هو دائمًا واحد فقط، وهو أمر مطمئن. 

419
00:26:54,780 --> 00:26:58,995
كلما كان هناك قدر واحد من عدم اليقين، مما يعني أن الأمر كان في الأساس يرجع إلى احتمالين 

420
00:26:58,995 --> 00:27:03,020
فقط، كان الأمر يتطلب أحيانًا تخمينًا إضافيًا، وأحيانًا يتطلب الأمر تخمينين إضافيين. 

421
00:27:03,080 --> 00:27:05,240
وهكذا دواليك هنا. 

422
00:27:05,740 --> 00:27:10,220
ربما تكون الطريقة الأسهل قليلًا لتصور هذه البيانات هي تجميعها معًا وأخذ المتوسطات. 

423
00:27:11,000 --> 00:27:15,424
على سبيل المثال، يشير هذا الشريط هنا إلى أنه من بين جميع النقاط التي كان لدينا 

424
00:27:15,424 --> 00:27:19,960
فيها قدر واحد من عدم اليقين، كان متوسط عدد التخمينات الجديدة المطلوبة حوالي 1.5. 

425
00:27:22,140 --> 00:27:26,363
والشريط هنا يقول من بين جميع الألعاب المختلفة حيث كانت نسبة عدم اليقين في 

426
00:27:26,363 --> 00:27:30,928
مرحلة ما أعلى بقليل من أربعة بتات، وهو ما يشبه تضييقها إلى 16 احتمالًا مختلفًا، 

427
00:27:30,928 --> 00:27:35,380
ثم في المتوسط يتطلب الأمر ما يزيد قليلاً عن تخمينين من تلك النقطة إلى الأمام. 

428
00:27:36,060 --> 00:27:39,460
ومن هنا قمت للتو بالانحدار ليناسب الوظيفة التي بدت معقولة لهذا الغرض. 

429
00:27:39,980 --> 00:27:44,470
وتذكر أن الهدف الأساسي من القيام بأي من ذلك هو أن نتمكن من قياس هذا الحدس، وهو 

430
00:27:44,470 --> 00:27:48,960
أنه كلما زادت المعلومات التي نكتسبها من كلمة ما، كلما انخفضت النتيجة المتوقعة. 

431
00:27:49,680 --> 00:27:54,313
لذا، مع هذا الإصدار 2.0، إذا عدنا وقمنا بتشغيل نفس مجموعة عمليات المحاكاة، حيث 

432
00:27:54,313 --> 00:27:59,240
قمنا بتشغيلها مقابل جميع الإجابات اللفظية المحتملة البالغ عددها 2315، كيف سيتم ذلك؟ 

433
00:28:00,280 --> 00:28:03,420
حسنًا، على النقيض من نسختنا الأولى، فهي بالتأكيد أفضل، وهو أمر مطمئن. 

434
00:28:04,020 --> 00:28:08,251
كل ما قيل وفعل هو المتوسط حوالي 3.6، على الرغم من أنه على عكس الإصدار 

435
00:28:08,251 --> 00:28:12,120
الأول هناك عدة مرات يخسر فيها ويتطلب أكثر من ستة في هذه الظروف. 

436
00:28:12,639 --> 00:28:15,391
من المفترض أنه هناك أوقات يتم فيها إجراء هذه المقايضة 

437
00:28:15,391 --> 00:28:17,940
للوصول فعليًا إلى الهدف بدلاً من تعظيم المعلومات. 

438
00:28:19,040 --> 00:28:21,000
فهل يمكننا أن نفعل ما هو أفضل من 3. 

439
00:28:22,080 --> 00:28:22,920
6؟ يمكننا بالتأكيد. 

440
00:28:23,280 --> 00:28:26,370
لقد قلت في البداية أنه من الممتع جدًا محاولة عدم دمج القائمة 

441
00:28:26,370 --> 00:28:29,360
الحقيقية للإجابات اللفظية في الطريقة التي يبني بها نموذجه. 

442
00:28:29,880 --> 00:28:34,180
ولكن إذا قمنا بدمجها، فإن أفضل أداء يمكن أن أحصل عليه كان حوالي 3.43. 

443
00:28:35,160 --> 00:28:38,477
لذا، إذا حاولنا أن نكون أكثر تعقيدًا من مجرد استخدام بيانات تكرار الكلمات 

444
00:28:38,477 --> 00:28:41,929
لاختيار هذا التوزيع المسبق، فهذا 3.43 ربما يعطي الحد الأقصى لمدى الجودة التي 

445
00:28:41,929 --> 00:28:45,740
يمكننا تحقيقها من خلال ذلك، أو على الأقل مدى الجودة التي يمكن أن نحققها من خلال ذلك. 

446
00:28:46,240 --> 00:28:50,571
يستخدم هذا الأداء الأفضل بشكل أساسي الأفكار التي كنت أتحدث عنها هنا، ولكنه يذهب 

447
00:28:50,571 --> 00:28:55,120
أبعد قليلاً، مثل البحث عن المعلومات المتوقعة خطوتين للأمام بدلاً من خطوة واحدة فقط. 

448
00:28:55,620 --> 00:29:00,220
في الأصل كنت أخطط للحديث أكثر عن ذلك، لكنني أدركت أننا قد قطعنا وقتًا طويلاً بالفعل. 

449
00:29:00,580 --> 00:29:04,716
الشيء الوحيد الذي سأقوله هو بعد إجراء هذا البحث المكون من خطوتين ثم تشغيل بعض نماذج 

450
00:29:04,716 --> 00:29:09,100
المحاكاة في أفضل المرشحين، حتى الآن بالنسبة لي على الأقل يبدو أن Crane هو أفضل افتتاحية. 

451
00:29:09,100 --> 00:29:10,060
من كان سيخمن؟ 

452
00:29:10,920 --> 00:29:14,582
وأيضًا إذا كنت تستخدم قائمة الكلمات الحقيقية لتحديد مساحة الاحتمالات 

453
00:29:14,582 --> 00:29:17,820
الخاصة بك، فإن عدم اليقين الذي تبدأ به يزيد قليلاً عن 11 بت. 

454
00:29:18,300 --> 00:29:21,959
وقد اتضح، من خلال بحث القوة الغاشمة فقط، أن الحد الأقصى 

455
00:29:21,959 --> 00:29:25,880
الممكن للمعلومات المتوقعة بعد أول تخمينين هو حوالي 10 بتات. 

456
00:29:26,500 --> 00:29:30,338
وهو ما يشير إلى أفضل سيناريو، بعد أول تخمينين، مع 

457
00:29:30,338 --> 00:29:34,560
اللعب الأمثل تمامًا، سيتبقى لديك القليل من عدم اليقين. 

458
00:29:34,800 --> 00:29:37,960
وهو نفس الأمر الذي يرجع إلى اثنين من التخمينات المحتملة. 

459
00:29:37,960 --> 00:29:41,908
لذلك أعتقد أنه من العدل وربما المحافظ جدًا أن نقول إنه لا يمكنك أبدًا 

460
00:29:41,908 --> 00:29:45,913
كتابة خوارزمية تحصل على هذا المتوسط منخفضًا يصل إلى 3، لأنه مع الكلمات 

461
00:29:45,913 --> 00:29:49,806
المتاحة لك، ببساطة ليس هناك مجال للحصول على معلومات كافية بعد خطوتين 

462
00:29:49,806 --> 00:29:53,360
فقط قادر على ضمان الإجابة في الفتحة الثالثة في كل مرة دون فشل. 

