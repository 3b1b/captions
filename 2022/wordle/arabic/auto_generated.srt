1
00:00:00,000 --> 00:00:04,040
لقد انتشرت لعبة Wurdle بشكل كبير في الشهر أو الشهرين

2
00:00:04,040 --> 00:00:07,880
الماضيين، ولم يغفل أحد أبدًا فرصة لدرس الرياضيات، ويخطر لي

3
00:00:07,880 --> 00:00:12,120
أن هذه اللعبة تمثل مثالًا مركزيًا جيدًا جدًا في درس

4
00:00:12,120 --> 00:00:13,120
حول نظرية المعلومات، وعلى وجه الخصوص موضوع يعرف باسم الانتروبيا.

5
00:00:13,120 --> 00:00:17,120
كما ترى، مثل الكثير من الأشخاص، انغمست في اللغز، ومثل

6
00:00:17,120 --> 00:00:21,200
الكثير من المبرمجين، انغمست أيضًا في محاولة كتابة خوارزمية من

7
00:00:21,200 --> 00:00:23,200
شأنها أن تلعب اللعبة على النحو الأمثل قدر الإمكان.

8
00:00:23,200 --> 00:00:26,400
وما اعتقدت أنني سأفعله هنا هو مجرد التحدث معكم عن بعض

9
00:00:26,400 --> 00:00:29,980
العمليات التي قمت بها في ذلك، وشرح بعض العمليات الحسابية التي

10
00:00:29,980 --> 00:00:32,080
أجريت عليها، حيث أن الخوارزمية بأكملها تركز على فكرة الإنتروبيا.

11
00:00:32,080 --> 00:00:42,180
أول الأشياء أولاً، في حالة أنك لم تسمع بها، ما هو Wurdle؟

12
00:00:42,180 --> 00:00:45,380
ولقتل عصفورين بحجر واحد هنا بينما نراجع قواعد اللعبة،

13
00:00:45,380 --> 00:00:48,980
اسمحوا لي أيضًا أن أستعرض إلى أين نتجه بهذا،

14
00:00:48,980 --> 00:00:51,380
وهو تطوير خوارزمية صغيرة ستلعب اللعبة لنا بشكل أساسي.

15
00:00:51,380 --> 00:00:54,860
على الرغم من أنني لم أقم بـWurdle اليوم، إلا أن

16
00:00:54,860 --> 00:00:55,860
هذا هو الرابع من فبراير، وسنرى كيف سيعمل الروبوت.

17
00:00:55,860 --> 00:00:59,580
هدف Wurdle هو تخمين كلمة غامضة مكونة من

18
00:00:59,580 --> 00:01:00,860
خمسة أحرف، ويتم منحك ست فرص مختلفة للتخمين.

19
00:01:00,860 --> 00:01:05,240
على سبيل المثال، يقترح روبوت Wurdle الخاص بي أن أبدأ برافعة التخمين.

20
00:01:05,240 --> 00:01:09,300
في كل مرة تقوم فيها بالتخمين، تحصل على بعض

21
00:01:09,300 --> 00:01:10,940
المعلومات حول مدى قرب تخمينك من الإجابة الحقيقية.

22
00:01:10,940 --> 00:01:14,540
هنا يخبرني المربع الرمادي أنه لا يوجد حرف C في الإجابة الفعلية.

23
00:01:14,540 --> 00:01:18,340
يخبرني المربع الأصفر بوجود حرف R، لكنه ليس في هذا الموضع.

24
00:01:18,340 --> 00:01:21,820
يخبرني الصندوق الأخضر أن الكلمة السرية بها

25
00:01:21,820 --> 00:01:22,820
حرف A، وهي في المركز الثالث.

26
00:01:22,820 --> 00:01:24,300
ومن ثم لا يوجد N ولا يوجد E.

27
00:01:24,300 --> 00:01:27,420
لذلك اسمحوا لي أن أدخل وأخبر روبوت Wurdle بهذه المعلومات.

28
00:01:27,420 --> 00:01:31,500
لقد بدأنا بالرافعة، وحصلنا على اللون الرمادي والأصفر والأخضر والرمادي والرمادي.

29
00:01:31,500 --> 00:01:35,460
لا تقلق بشأن جميع البيانات التي تظهرها الآن، سأشرح ذلك في الوقت المناسب.

30
00:01:35,460 --> 00:01:39,700
لكن أهم اقتراح لاختيارنا الثاني هو أسلوب هزلي.

31
00:01:39,700 --> 00:01:43,500
ويجب أن يكون تخمينك عبارة عن كلمة فعلية مكونة من خمسة أحرف، ولكن

32
00:01:43,500 --> 00:01:45,700
كما سترى، فهي متحررة جدًا فيما يتعلق بما ستتيح لك تخمينه بالفعل.

33
00:01:45,700 --> 00:01:48,860
في هذه الحالة، نحاول shtick.

34
00:01:48,860 --> 00:01:50,260
حسنًا، تبدو الأمور جيدة جدًا.

35
00:01:50,260 --> 00:01:54,580
نضغط على S وH، حتى نعرف الأحرف الثلاثة الأولى، ونعلم أن هناك حرف R.

36
00:01:54,740 --> 00:01:59,740
وبالتالي سيكون مثل SHA شيء R، أو SHA R شيء ما.

37
00:01:59,740 --> 00:02:03,200
ويبدو أن روبوت Wurdle يعرف أن الأمر يرجع

38
00:02:03,200 --> 00:02:05,220
إلى احتمالين فقط، إما شظية أو حادة.

39
00:02:05,220 --> 00:02:08,620
هذا نوع من التقلب بينهما في هذه المرحلة، لذلك أعتقد

40
00:02:08,620 --> 00:02:11,260
أنه ربما فقط لأنه ترتيب أبجدي فإنه يتناسب مع القشرة.

41
00:02:11,260 --> 00:02:13,000
يا للهول، هذا هو الجواب الفعلي.

42
00:02:13,000 --> 00:02:14,660
لذلك حصلنا عليه في ثلاثة.

43
00:02:14,660 --> 00:02:17,740
إذا كنت تتساءل عما إذا كان هذا أمرًا جيدًا، فالطريقة التي سمعت

44
00:02:17,740 --> 00:02:20,820
بها عبارة شخص واحد هي أنه مع Wurdle أربعة متساوية وثلاثة طائر.

45
00:02:20,820 --> 00:02:22,960
والذي أعتقد أنه تشبيه مناسب جدًا.

46
00:02:22,960 --> 00:02:27,560
يجب أن تكون في مستوى لعبتك باستمرار حتى تحصل على المركز الرابع، لكن هذا بالتأكيد ليس جنونًا.

47
00:02:27,560 --> 00:02:30,000
ولكن عندما تحصل عليه في ثلاثة، فإنه يشعر بالارتياح.

48
00:02:30,000 --> 00:02:33,800
لذا، إذا كنت ترغب في ذلك، ما أود القيام به هنا هو مجرد

49
00:02:33,800 --> 00:02:36,600
التحدث خلال عملية تفكيري منذ البداية حول كيفية التعامل مع روبوت Wurdle.

50
00:02:36,600 --> 00:02:39,800
وكما قلت، إنه حقًا عذر لدرس نظرية المعلومات.

51
00:02:39,800 --> 00:02:43,160
الهدف الرئيسي هو شرح ما هي المعلومات وما هو الإنتروبيا.

52
00:02:48,560 --> 00:02:52,080
كانت فكرتي الأولى في التعامل مع هذا الأمر هي إلقاء

53
00:02:52,080 --> 00:02:53,560
نظرة على التكرارات النسبية للحروف المختلفة في اللغة الإنجليزية.

54
00:02:53,560 --> 00:02:57,800
لذا فكرت، حسنًا، هل هناك تخمين افتتاحي أو زوج من

55
00:02:57,800 --> 00:02:59,960
التخمينات الافتتاحية يصل إلى الكثير من هذه الحروف الأكثر شيوعًا؟

56
00:02:59,960 --> 00:03:03,780
وكان أحد الأشياء التي كنت مغرمًا بها هو القيام بأشياء أخرى متبوعة بالأظافر.

57
00:03:03,780 --> 00:03:06,980
الفكرة هي أنه إذا ضربت حرفًا، فستحصل على

58
00:03:06,980 --> 00:03:07,980
اللون الأخضر أو الأصفر، وهذا شعور جيد دائمًا.

59
00:03:07,980 --> 00:03:09,460
يبدو الأمر وكأنك تحصل على معلومات.

60
00:03:09,460 --> 00:03:13,140
لكن في هذه الحالات، حتى لو لم تضرب وظهرت لك علامات رمادية

61
00:03:13,140 --> 00:03:16,640
دائمًا، فلا يزال هذا يوفر لك الكثير من المعلومات لأنه من النادر

62
00:03:16,640 --> 00:03:17,640
جدًا العثور على كلمة لا تحتوي على أي من هذه الأحرف.

63
00:03:17,640 --> 00:03:21,840
لكن حتى مع ذلك، لا يبدو هذا منهجيًا للغاية، لأنه

64
00:03:21,840 --> 00:03:23,520
على سبيل المثال، لا يفعل شيئًا للنظر في ترتيب الحروف.

65
00:03:23,520 --> 00:03:26,080
لماذا أكتب الأظافر عندما أستطيع كتابة الحلزون؟

66
00:03:26,080 --> 00:03:27,720
هل من الأفضل أن يكون لديك S في النهاية؟

67
00:03:27,720 --> 00:03:28,720
أنا غير متأكد.

68
00:03:28,720 --> 00:03:33,500
الآن، قال أحد أصدقائي إنه يحب أن يبدأ بكلمة &quot;ضجر&quot;، وهو ما فاجأني

69
00:03:33,500 --> 00:03:37,160
نوعًا ما لأنها تحتوي على بعض الحروف غير المألوفة مثل حرف W وY.

70
00:03:37,160 --> 00:03:39,400
لكن من يدري، ربما تكون هذه افتتاحية أفضل.

71
00:03:39,400 --> 00:03:43,920
هل هناك نوع من الدرجة الكمية التي

72
00:03:43,920 --> 00:03:44,920
يمكننا تقديمها للحكم على جودة التخمين المحتمل؟

73
00:03:44,920 --> 00:03:48,640
الآن، للإعداد للطريقة التي سنقوم بها بترتيب التخمينات المحتملة، دعنا

74
00:03:48,640 --> 00:03:51,800
نعود ونضيف القليل من الوضوح حول كيفية إعداد اللعبة بالضبط.

75
00:03:51,800 --> 00:03:55,880
لذا، هناك قائمة بالكلمات التي سيسمح لك بإدخالها والتي

76
00:03:55,880 --> 00:03:57,920
تعتبر تخمينات صحيحة ويبلغ طولها حوالي 13000 كلمة.

77
00:03:57,920 --> 00:04:01,560
لكن عندما تنظر إليها، هناك الكثير من الأشياء غير المألوفة حقًا، أشياء مثل

78
00:04:01,560 --> 00:04:07,040
&quot;رأس&quot; أو &quot;علي&quot; و&quot;ARG&quot;، نوع الكلمات التي تثير جدالات عائلية في لعبة &quot;سكرابل&quot;.

79
00:04:07,040 --> 00:04:10,600
لكن أجواء اللعبة هي أن الإجابة ستكون دائمًا كلمة شائعة بشكل لائق.

80
00:04:10,600 --> 00:04:16,080
وفي الواقع، هناك قائمة أخرى تضم حوالي 2300 كلمة تمثل الإجابات المحتملة.

81
00:04:16,080 --> 00:04:20,320
وهذه قائمة منسقة بشريًا، وأعتقد على وجه التحديد من

82
00:04:20,320 --> 00:04:21,800
قبل صديقة صانع اللعبة، وهي ممتعة نوعًا ما.

83
00:04:21,800 --> 00:04:25,560
لكن ما أود أن أفعله، التحدي الذي يواجهنا في هذا المشروع هو معرفة ما

84
00:04:25,560 --> 00:04:30,720
إذا كان بإمكاننا كتابة برنامج لحل Wordle لا يتضمن المعرفة السابقة حول هذه القائمة.

85
00:04:30,720 --> 00:04:34,560
لسبب واحد، هناك الكثير من الكلمات الشائعة المكونة من

86
00:04:34,560 --> 00:04:35,560
خمسة أحرف والتي لن تجدها في تلك القائمة.

87
00:04:35,560 --> 00:04:38,360
لذلك سيكون من الأفضل كتابة برنامج أكثر مرونة ويمكنه تشغيل Wordle

88
00:04:38,360 --> 00:04:41,960
ضد أي شخص، وليس فقط ما يحدث أنه الموقع الرسمي.

89
00:04:41,960 --> 00:04:45,900
وأيضًا السبب وراء معرفتنا لقائمة الإجابات المحتملة

90
00:04:45,900 --> 00:04:47,440
هذه هو أنها مرئية في الكود المصدري.

91
00:04:47,440 --> 00:04:51,620
لكن الطريقة التي تظهر بها في الكود المصدري تكون

92
00:04:51,620 --> 00:04:52,840
بالترتيب المحدد الذي تظهر به الإجابات من يوم لآخر.

93
00:04:52,840 --> 00:04:56,400
لذلك يمكنك دائمًا البحث عن إجابة الغد.

94
00:04:56,400 --> 00:04:59,140
لذا فمن الواضح أن هناك بعض المعنى الذي يعتبر فيه استخدام القائمة غشًا.

95
00:04:59,140 --> 00:05:02,900
وما يجعل اللغز أكثر إثارة للاهتمام ودرسًا أكثر ثراءً لنظرية المعلومات هو

96
00:05:02,900 --> 00:05:07,640
بدلاً من ذلك استخدام بعض البيانات الأكثر عالمية مثل ترددات الكلمات النسبية

97
00:05:07,640 --> 00:05:11,640
بشكل عام لالتقاط هذا الحدس المتمثل في تفضيل الكلمات الأكثر شيوعًا.

98
00:05:11,640 --> 00:05:16,560
إذن، من بين هذه الاحتمالات الـ 13000، كيف يجب أن نختار التخمين الافتتاحي؟

99
00:05:16,560 --> 00:05:19,960
على سبيل المثال، إذا تقدم صديقي بطلب مرهق، فكيف ينبغي لنا أن نحلل جودته؟

100
00:05:19,960 --> 00:05:25,040
حسنًا، السبب الذي جعله يحب ذلك W غير المحتمل هو أنه

101
00:05:25,040 --> 00:05:27,880
يحب طبيعة اللقطة الطويلة لمدى الشعور الجيد إذا ضربت ذلك W.

102
00:05:27,880 --> 00:05:31,400
على سبيل المثال، إذا كان النمط الأول الذي تم الكشف عنه شيئًا كهذا، فسيتبين

103
00:05:31,400 --> 00:05:36,080
أن هناك 58 كلمة فقط في هذا المعجم العملاق تتطابق مع هذا النمط.

104
00:05:36,080 --> 00:05:38,900
وهذا تخفيض كبير من 13000.

105
00:05:38,900 --> 00:05:43,320
لكن الجانب الآخر من ذلك، بالطبع، هو أنه من غير المألوف أن نحصل على نمط كهذا.

106
00:05:43,360 --> 00:05:47,600
على وجه التحديد، إذا كان من المرجح أن تكون كل كلمة هي الإجابة بشكل

107
00:05:47,600 --> 00:05:51,680
متساوٍ، فإن احتمال الوصول إلى هذا النمط سيكون 58 مقسومًا على حوالي 13000.

108
00:05:51,680 --> 00:05:53,880
وبطبيعة الحال، ليس من المرجح أن تكون الإجابات متساوية.

109
00:05:53,880 --> 00:05:56,680
معظم هذه الكلمات غامضة للغاية وحتى مشكوك فيها.

110
00:05:56,680 --> 00:05:59,560
لكن على الأقل بالنسبة لمرورنا الأول في كل هذا، لنفترض

111
00:05:59,560 --> 00:06:02,040
أن جميعهم متساوون في الاحتمال ثم نحسن ذلك لاحقًا.

112
00:06:02,040 --> 00:06:07,360
النقطة المهمة هي أن النمط الذي يحتوي على الكثير من المعلومات من غير المرجح أن يحدث بطبيعته.

113
00:06:07,360 --> 00:06:11,320
في الواقع، ما يعنيه أن تكون غنيًا بالمعلومات هو أنه أمر غير محتمل.

114
00:06:11,920 --> 00:06:16,720
النمط الأكثر احتمالاً الذي يمكن رؤيته مع هذه الافتتاحية سيكون

115
00:06:16,720 --> 00:06:18,360
شيئًا مثل هذا، حيث لا يوجد بالطبع حرف W فيه.

116
00:06:18,360 --> 00:06:22,080
ربما يوجد حرف E، وربما لا يوجد A، ولا يوجد R، ولا يوجد Y.

117
00:06:22,080 --> 00:06:24,640
في هذه الحالة، هناك 1400 تطابق محتمل.

118
00:06:24,640 --> 00:06:29,600
إذا كانت جميعها متساوية في الاحتمال، فمن المرجح أن

119
00:06:29,600 --> 00:06:30,680
يكون هذا هو النمط الذي ستراه بنسبة 11% تقريبًا.

120
00:06:30,680 --> 00:06:34,320
وبالتالي فإن النتائج الأكثر ترجيحًا هي أيضًا الأقل إفادة.

121
00:06:34,320 --> 00:06:38,440
للحصول على رؤية أكثر عمومية هنا، اسمحوا لي أن أعرض لكم

122
00:06:38,440 --> 00:06:42,000
التوزيع الكامل للاحتمالات عبر جميع الأنماط المختلفة التي قد تراها.

123
00:06:42,000 --> 00:06:46,000
لذا فإن كل شريط تنظر إليه يتوافق مع نمط محتمل من الألوان

124
00:06:46,000 --> 00:06:50,500
التي يمكن الكشف عنها، والتي يوجد منها 3 إلى الاحتمال الخامس، وهي

125
00:06:50,500 --> 00:06:52,960
منظمة من اليسار إلى اليمين، من الأكثر شيوعًا إلى الأقل شيوعًا.

126
00:06:52,960 --> 00:06:56,200
لذا فإن الاحتمال الأكثر شيوعًا هنا هو أن تحصل على كل الألوان الرمادية.

127
00:06:56,200 --> 00:06:58,800
ويحدث ذلك في حوالي 14% من الحالات.

128
00:06:58,800 --> 00:07:02,040
وما تأمله عندما تقوم بالتخمين هو أن ينتهي بك الأمر في

129
00:07:02,040 --> 00:07:06,360
مكان ما في هذا الذيل الطويل، مثل هنا حيث يوجد 18

130
00:07:06,360 --> 00:07:09,920
احتمالًا فقط لما يطابق هذا النمط الذي يبدو بوضوح هكذا.

131
00:07:09,920 --> 00:07:14,080
أو إذا غامرنا بالتحرك إلى اليسار قليلاً، كما تعلمون، ربما نقطع كل الطريق هنا.

132
00:07:14,080 --> 00:07:16,560
حسنًا، إليك لغزًا جيدًا لك.

133
00:07:16,560 --> 00:07:20,600
ما هي الكلمات الثلاث في اللغة الإنجليزية التي تبدأ

134
00:07:20,600 --> 00:07:22,040
بحرف W، وتنتهي بحرف Y، وفيها حرف R؟

135
00:07:22,040 --> 00:07:27,560
اتضح أن الإجابات هي، دعونا نرى، كلامية، ودودة، وساخرة.

136
00:07:27,560 --> 00:07:32,720
لذا، للحكم على مدى جودة هذه الكلمة بشكل عام، نريد نوعًا من

137
00:07:32,720 --> 00:07:35,720
قياس الكمية المتوقعة من المعلومات التي ستحصل عليها من هذا التوزيع.

138
00:07:36,360 --> 00:07:41,080
إذا مررنا بكل نمط وضربنا احتمالية حدوثه في شيء

139
00:07:41,080 --> 00:07:46,000
يقيس مدى معلوماته، فقد يمنحنا ذلك نتيجة موضوعية.

140
00:07:46,000 --> 00:07:50,280
الآن قد تكون غريزتك الأولى بشأن ما يجب أن يكون عليه هذا الشيء هي عدد التطابقات.

141
00:07:50,280 --> 00:07:52,960
تريد متوسطًا أقل لعدد المطابقات.

142
00:07:52,960 --> 00:07:57,400
لكن بدلاً من ذلك، أود استخدام مقياس أكثر شمولاً ننسبه غالبًا إلى المعلومات، والذي

143
00:07:57,400 --> 00:08:01,040
سيكون أكثر مرونة بمجرد أن يكون لدينا احتمالية مختلفة مخصصة لكل كلمة من

144
00:08:01,040 --> 00:08:04,320
هذه الكلمات الـ 13000 لمعرفة ما إذا كانت هي الإجابة بالفعل أم لا.

145
00:08:10,600 --> 00:08:14,760
الوحدة القياسية للمعلومات هي البت، والتي تحتوي على صيغة مضحكة إلى

146
00:08:14,760 --> 00:08:17,800
حد ما، لكنها بديهية حقًا إذا نظرنا فقط إلى الأمثلة.

147
00:08:17,800 --> 00:08:21,880
إذا كانت لديك ملاحظة تختصر مساحة الاحتمالات لديك إلى

148
00:08:21,880 --> 00:08:24,200
النصف، نقول إنها تحتوي على بت واحد من المعلومات.

149
00:08:24,200 --> 00:08:27,680
في مثالنا، مساحة الاحتمالات هي كل الكلمات الممكنة، وتبين أن حوالي نصف الكلمات المكونة

150
00:08:27,760 --> 00:08:31,560
من خمسة أحرف بها حرف S، أقل من ذلك بقليل، ولكن حوالي النصف.

151
00:08:31,560 --> 00:08:35,200
لذا فإن هذه الملاحظة ستمنحك معلومة واحدة.

152
00:08:35,200 --> 00:08:39,640
وبدلاً من ذلك، إذا أدت حقيقة جديدة إلى تقليص مساحة الاحتمالات

153
00:08:39,640 --> 00:08:42,000
هذه إلى أربعة أضعاف، فسنقول إنها تحتوي على قطعتين من المعلومات.

154
00:08:42,000 --> 00:08:45,120
على سبيل المثال، تبين أن حوالي ربع هذه الكلمات تحتوي على حرف T.

155
00:08:45,120 --> 00:08:49,720
إذا قطعت الملاحظة هذا الفضاء بمقدار ثمانية أضعاف،

156
00:08:49,720 --> 00:08:50,920
نقول إنها ثلاث أجزاء من المعلومات، وهكذا دواليك.

157
00:08:50,920 --> 00:08:55,000
أربع بتات تقطعه إلى 16، وخمس بتات تقطعه إلى 32.

158
00:08:55,000 --> 00:09:00,160
والآن قد ترغب في التوقف مؤقتًا وتسأل نفسك، ما هي

159
00:09:00,160 --> 00:09:04,520
صيغة المعلومات لعدد البتات من حيث احتمال حدوث ذلك؟

160
00:09:04,520 --> 00:09:07,920
ما نقوله هنا هو أنه عندما تأخذ نصفًا لعدد البتات، فهذا

161
00:09:07,920 --> 00:09:11,680
هو نفس الاحتمال، وهو نفس قول أن اثنين أس عدد

162
00:09:11,680 --> 00:09:16,200
البتات يساوي واحدًا على الاحتمال، وهو ما يُعاد ترتيبها أيضًا لقول

163
00:09:16,200 --> 00:09:19,680
أن المعلومات هي سجل واحد للأساس اثنين مقسومًا على الاحتمال.

164
00:09:19,680 --> 00:09:23,200
وفي بعض الأحيان ترى ذلك مع عملية إعادة ترتيب

165
00:09:23,200 --> 00:09:25,680
أخرى، حيث تكون المعلومات هي سالب الاحتمال للأساس اثنين.

166
00:09:25,680 --> 00:09:29,120
إذا تم التعبير عنها بهذه الطريقة، فقد تبدو غريبة بعض الشيء

167
00:09:29,120 --> 00:09:33,400
بالنسبة للمبتدئين، ولكنها في الحقيقة مجرد فكرة بديهية للغاية تتمثل في

168
00:09:33,400 --> 00:09:35,120
السؤال عن عدد المرات التي قمت فيها بتخفيض إمكانياتك إلى النصف.

169
00:09:35,120 --> 00:09:37,840
الآن إذا كنت تتساءل، كما تعلمون، اعتقدت أننا كنا

170
00:09:37,840 --> 00:09:39,920
نلعب لعبة كلمات ممتعة، لماذا تدخل اللوغاريتمات في الصورة؟

171
00:09:39,920 --> 00:09:43,920
أحد الأسباب التي تجعل هذه الوحدة أجمل هو أنه من الأسهل كثيرًا التحدث عن

172
00:09:43,920 --> 00:09:48,120
أحداث غير محتملة جدًا، ومن الأسهل كثيرًا القول إن الملاحظة تحتوي على 20 بت

173
00:09:48,120 --> 00:09:53,480
من المعلومات مقارنة بالقول إن احتمال حدوث كذا وكذا هو 0. 0000095.

174
00:09:53,480 --> 00:09:57,360
لكن السبب الأكثر أهمية وراء تحول هذا التعبير اللوغاريتمي إلى إضافة

175
00:09:57,360 --> 00:10:02,000
مفيدة جدًا لنظرية الاحتمال هو الطريقة التي تجمع بها المعلومات معًا.

176
00:10:02,000 --> 00:10:05,560
على سبيل المثال، إذا أعطتك ملاحظة واحدة قطعتين من المعلومات، مما يقلل

177
00:10:05,560 --> 00:10:10,120
المساحة بمقدار أربعة، ثم ملاحظة ثانية مثل تخمينك الثاني في Wordle

178
00:10:10,120 --> 00:10:14,480
تعطيك ثلاث أجزاء أخرى من المعلومات، مما يقلل من المساحة بمقدار عامل

179
00:10:14,480 --> 00:10:17,360
آخر قدره ثمانية، فإن اثنان معًا يزودانك بخمسة أجزاء من المعلومات.

180
00:10:17,360 --> 00:10:21,200
بنفس الطريقة التي تحب بها الاحتمالات أن تتضاعف، تحب المعلومات أن تضيف.

181
00:10:21,200 --> 00:10:24,920
لذلك بمجرد أن نكون في عالم شيء مثل القيمة المتوقعة، حيث نقوم

182
00:10:24,920 --> 00:10:28,660
بإضافة مجموعة من الأرقام، فإن السجلات تجعل التعامل معها أفضل كثيرًا.

183
00:10:28,660 --> 00:10:32,600
دعنا نعود إلى توزيعتنا لـ Weary ونضيف أداة تعقب صغيرة

184
00:10:32,600 --> 00:10:35,560
أخرى هنا، لتوضح لنا مقدار المعلومات المتوفرة لكل نمط.

185
00:10:35,560 --> 00:10:38,760
الشيء الرئيسي الذي أريدك أن تلاحظه هو أنه كلما زادت احتمالية وصولنا إلى

186
00:10:38,760 --> 00:10:43,500
تلك الأنماط الأكثر احتمالية، كلما انخفضت المعلومات، وقل عدد البتات التي تكسبها.

187
00:10:43,500 --> 00:10:47,360
الطريقة التي نقيس بها جودة هذا التخمين هي أخذ القيمة المتوقعة

188
00:10:47,360 --> 00:10:51,620
لهذه المعلومات، حيث نمر عبر كل نمط، ونقول مدى احتمالية ذلك،

189
00:10:51,620 --> 00:10:54,940
ثم نضرب ذلك في عدد أجزاء المعلومات التي نحصل عليها.

190
00:10:54,940 --> 00:10:58,480
وفي مثال Weary، تبين أن الرقم 4. 9 بت.

191
00:10:58,480 --> 00:11:02,800
لذا، في المتوسط، فإن المعلومات التي تحصل عليها من هذا التخمين الافتتاحي

192
00:11:02,800 --> 00:11:05,660
جيدة مثل تقليص مساحة الاحتمالات الخاصة بك إلى النصف حوالي خمس مرات.

193
00:11:05,660 --> 00:11:10,260
على النقيض من ذلك، مثال على التخمين ذو

194
00:11:10,260 --> 00:11:13,220
قيمة معلومات متوقعة أعلى سيكون مثل Slate.

195
00:11:13,220 --> 00:11:16,180
في هذه الحالة ستلاحظ أن التوزيع يبدو أكثر تملقًا.

196
00:11:16,180 --> 00:11:20,780
على وجه الخصوص، فإن احتمال حدوث جميع درجات الرمادي هو 6% فقط، لذا

197
00:11:20,780 --> 00:11:25,940
فمن الواضح أنك تحصل على 3% على الأقل. 9 بت من المعلومات.

198
00:11:25,940 --> 00:11:29,140
ولكن هذا هو الحد الأدنى، وعادة ما تحصل على شيء أفضل من ذلك.

199
00:11:29,140 --> 00:11:33,380
واتضح أنه عندما تقوم بجمع الأرقام الموجودة في هذا الرقم وإضافة

200
00:11:33,380 --> 00:11:36,420
جميع المصطلحات ذات الصلة، فإن متوسط المعلومات هو حوالي 5. 8.

201
00:11:36,420 --> 00:11:42,140
لذا، على النقيض من Weary، فإن مساحة الاحتمالات الخاصة بك

202
00:11:42,140 --> 00:11:43,940
ستكون حوالي النصف بعد هذا التخمين الأول، في المتوسط.

203
00:11:43,940 --> 00:11:49,540
هناك في الواقع قصة ممتعة حول اسم هذه القيمة المتوقعة لكمية المعلومات.

204
00:11:49,540 --> 00:11:52,580
تم تطوير نظرية المعلومات على يد كلود شانون، الذي كان يعمل في

205
00:11:52,580 --> 00:11:57,620
مختبرات بيل في الأربعينيات، لكنه كان يتحدث عن بعض أفكاره التي لم

206
00:11:57,620 --> 00:12:01,500
تُنشر بعد مع جون فون نيومان، الذي كان هذا العملاق الفكري في

207
00:12:01,500 --> 00:12:04,180
ذلك الوقت، بارزًا جدًا في الرياضيات والفيزياء وبدايات ما أصبح علوم الكمبيوتر.

208
00:12:04,180 --> 00:12:07,260
وعندما ذكر أنه ليس لديه حقًا اسم جيد لهذه القيمة

209
00:12:07,260 --> 00:12:12,540
المتوقعة لكمية المعلومات، من المفترض أن فون نيومان قال،

210
00:12:12,540 --> 00:12:14,720
وفقًا للقصة، حسنًا، يجب أن تسميها الإنتروبيا، وذلك لسببين.

211
00:12:14,720 --> 00:12:18,400
في المقام الأول، تم استخدام دالة عدم اليقين في الميكانيكا الإحصائية تحت هذا الاسم،

212
00:12:18,400 --> 00:12:23,100
لذا فهي تحمل اسمًا بالفعل، وفي المقام الثاني، والأهم من ذلك، لا أحد

213
00:12:23,100 --> 00:12:26,940
يعرف ما هي الإنتروبيا حقًا، لذلك في أي نقاش ستظل دائمًا لدينا ميزة.

214
00:12:26,940 --> 00:12:31,420
لذا، إذا كان الاسم يبدو غامضًا بعض الشيء، وإذا كان

215
00:12:31,420 --> 00:12:33,420
لهذه القصة أن تصدق، فهذا نوعاً ما حسب التصميم.

216
00:12:33,420 --> 00:12:36,740
وأيضًا إذا كنت تتساءل عن علاقتها بكل ما يتعلق بالقانون

217
00:12:36,740 --> 00:12:40,820
الثاني للديناميكا الحرارية من الفيزياء، فمن المؤكد أن هناك

218
00:12:40,820 --> 00:12:44,780
صلة، ولكن في أصولها كان شانون يتعامل فقط مع

219
00:12:44,780 --> 00:12:49,340
نظرية الاحتمالات البحتة، ولأغراضنا هنا، عندما استخدمت الإنتروبيا، أريدك

220
00:12:49,340 --> 00:12:50,820
فقط أن تفكر في قيمة المعلومات المتوقعة لتخمين معين.

221
00:12:50,820 --> 00:12:54,380
يمكنك التفكير في الإنتروبيا على أنها قياس شيئين في وقت واحد.

222
00:12:54,380 --> 00:12:57,420
الأول هو مدى ثبات التوزيع.

223
00:12:57,420 --> 00:13:01,700
كلما كان التوزيع أقرب إلى الانتظام، كلما زادت الإنتروبيا.

224
00:13:01,700 --> 00:13:06,340
في حالتنا، حيث يوجد 3 إلى 5 أنماط إجمالية، للتوزيع الموحد، فإن مراقبة أي واحد

225
00:13:06,340 --> 00:13:11,340
منها سيكون له قاعدة سجل معلومات 2 من 3 إلى 5، وهو ما يصادف أنه

226
00:13:11,340 --> 00:13:17,860
7. 92، هذا هو الحد الأقصى المطلق الذي يمكن أن تحصل عليه لهذه الإنتروبيا.

227
00:13:17,860 --> 00:13:21,900
لكن الإنتروبيا هي أيضًا نوع من مقياس

228
00:13:21,900 --> 00:13:22,900
لعدد الاحتمالات الموجودة في المقام الأول.

229
00:13:22,900 --> 00:13:26,980
على سبيل المثال، إذا كان لديك كلمة حيث يوجد فقط 16 نمطًا ممكنًا،

230
00:13:26,980 --> 00:13:32,760
وكل نمط محتمل متساوٍ، فإن هذه الإنتروبيا، هذه المعلومات المتوقعة، ستكون 4 بتات.

231
00:13:32,760 --> 00:13:36,880
لكن إذا كانت لديك كلمة أخرى حيث يمكن أن تظهر 64

232
00:13:36,880 --> 00:13:41,000
نمطًا محتملاً، وجميعها متساوية في الاحتمال، فإن الإنتروبيا ستكون 6 بتات.

233
00:13:41,000 --> 00:13:45,800
لذا، إذا رأيت بعض التوزيعات في الطبيعة والتي تحتوي على إنتروبيا تبلغ 6

234
00:13:45,800 --> 00:13:50,000
بتات، فهذا يشبه القول بأن هناك قدرًا كبيرًا من الاختلاف وعدم اليقين فيما

235
00:13:50,000 --> 00:13:54,400
هو على وشك الحدوث كما لو كان هناك 64 نتيجة محتملة متساوية.

236
00:13:54,400 --> 00:13:58,360
في أول تمريرة لي في Wurtelebot، طلبت مني فعل هذا فقط.

237
00:13:58,360 --> 00:14:03,560
إنه يمر بجميع التخمينات المحتملة التي يمكن أن تكون لديك، كل الكلمات البالغ

238
00:14:03,560 --> 00:14:08,580
عددها 13000 كلمة، ويحسب الإنتروبيا لكل واحدة منها، أو بشكل أكثر تحديدًا، إنتروبيا

239
00:14:08,580 --> 00:14:13,040
التوزيع عبر جميع الأنماط التي قد تراها، لكل واحد، ويختار الأعلى، نظرًا لأن

240
00:14:13,040 --> 00:14:17,200
ذلك الذي من المحتمل أن يقلل مساحة الاحتمالات الخاصة بك قدر الإمكان.

241
00:14:17,200 --> 00:14:20,120
وعلى الرغم من أنني كنت أتحدث فقط عن التخمين الأول

242
00:14:20,120 --> 00:14:21,680
هنا، فإنه يفعل نفس الشيء بالنسبة للتخمينات القليلة التالية.

243
00:14:21,680 --> 00:14:25,100
على سبيل المثال، بعد أن ترى بعض الأنماط في هذا التخمين الأول، والتي

244
00:14:25,100 --> 00:14:29,300
من شأنها أن تقيدك بعدد أقل من الكلمات المحتملة بناءً على ما يتطابق

245
00:14:29,300 --> 00:14:32,300
مع ذلك، فإنك تلعب نفس اللعبة فيما يتعلق بتلك المجموعة الأصغر من الكلمات.

246
00:14:32,300 --> 00:14:36,500
للحصول على تخمين ثانٍ مقترح، تنظر إلى توزيع جميع الأنماط التي يمكن

247
00:14:36,500 --> 00:14:41,540
أن تحدث من تلك المجموعة الأكثر تقييدًا من الكلمات، وتبحث في جميع

248
00:14:41,540 --> 00:14:45,480
الاحتمالات البالغ عددها 13000، وتجد الخيار الذي يزيد من هذه الإنتروبيا.

249
00:14:45,480 --> 00:14:48,980
لكي أوضح لك كيف يتم ذلك عمليًا، اسمحوا لي أن أعرض نسخة صغيرة من

250
00:14:48,980 --> 00:14:54,060
كتاب Wurtele الذي كتبته والذي يوضح النقاط البارزة في هذا التحليل في الهوامش.

251
00:14:54,460 --> 00:14:57,820
بعد إجراء جميع حسابات الإنتروبيا، تظهر لنا على

252
00:14:57,820 --> 00:15:00,340
اليمين أي منها لديه أعلى المعلومات المتوقعة.

253
00:15:00,340 --> 00:15:04,940
اتضح أن الإجابة الرئيسية، على الأقل في الوقت الحالي، وسنقوم بتحسينها

254
00:15:04,940 --> 00:15:11,140
لاحقًا، هي الزوان، والتي تعني، بالطبع، البيقية، البيقية الأكثر شيوعًا.

255
00:15:11,140 --> 00:15:14,180
في كل مرة نقوم بالتخمين هنا، حيث ربما أتجاهل توصياتها نوعًا ما

256
00:15:14,180 --> 00:15:19,220
وأختار القائمة، لأنني أحب القائمة، يمكننا أن نرى مقدار المعلومات المتوقعة التي

257
00:15:19,220 --> 00:15:23,300
تحتوي عليها، ولكن بعد ذلك على يمين الكلمة هنا تظهر لنا مقدار

258
00:15:23,340 --> 00:15:24,980
المعلومات المعلومات الفعلية التي حصلنا عليها، في ضوء هذا النمط بالذات.

259
00:15:24,980 --> 00:15:28,660
لذا يبدو هنا أننا لم نكن محظوظين بعض الشيء، حيث كان من المتوقع أن نحصل على 5. 8، لكننا

260
00:15:28,660 --> 00:15:30,660
حصلنا على شيء أقل من ذلك.

261
00:15:30,660 --> 00:15:34,020
ثم على الجانب الأيسر هنا يظهر لنا جميع الكلمات

262
00:15:34,020 --> 00:15:35,860
المختلفة الممكنة بالنظر إلى ما نحن فيه الآن.

263
00:15:35,860 --> 00:15:39,820
تخبرنا الأشرطة الزرقاء بمدى احتمالية التفكير في كل كلمة، لذلك في الوقت الحالي يفترض

264
00:15:39,820 --> 00:15:44,140
أن كل كلمة من المرجح أن تحدث بشكل متساوٍ، ولكننا سنحسن ذلك في لحظة.

265
00:15:44,140 --> 00:15:48,580
ومن ثم يخبرنا قياس عدم اليقين هذا بإنتروبيا هذا التوزيع

266
00:15:48,580 --> 00:15:53,220
عبر الكلمات المحتملة، والتي في الوقت الحالي، نظرًا لأنه توزيع

267
00:15:53,300 --> 00:15:55,940
موحد، هي مجرد طريقة معقدة بلا داع لحساب عدد الاحتمالات.

268
00:15:55,940 --> 00:16:01,700
على سبيل المثال، إذا أخذنا 2 أس 13. 66، ينبغي أن

269
00:16:01,700 --> 00:16:02,700
يكون حوالي 13000 الاحتمالات.

270
00:16:02,700 --> 00:16:06,780
أنا متوقف قليلاً هنا، ولكن فقط لأنني لا أعرض جميع المنازل العشرية.

271
00:16:06,780 --> 00:16:10,260
في الوقت الحالي، قد يبدو هذا زائدًا عن الحاجة ويؤدي إلى تعقيد الأمور بشكل

272
00:16:10,260 --> 00:16:12,780
مفرط، ولكنك سترى لماذا من المفيد الحصول على كلا الرقمين في دقيقة واحدة.

273
00:16:12,780 --> 00:16:16,780
لذا يبدو هنا أنه يشير إلى أن أعلى إنتروبيا لتخميننا

274
00:16:16,780 --> 00:16:19,700
الثاني هي رامين، والتي مرة أخرى لا تبدو وكأنها كلمة.

275
00:16:19,700 --> 00:16:25,660
لذا، لكي أتخذ موقفًا أخلاقيًا عاليًا هنا، سأمضي قدمًا وأكتب Rains.

276
00:16:25,660 --> 00:16:27,540
ومرة أخرى يبدو أننا لم نكن محظوظين بعض الشيء.

277
00:16:27,540 --> 00:16:32,100
كنا نتوقع 4. 3 بتات وحصلنا على 3 فقط. 39 بت من المعلومات.

278
00:16:32,100 --> 00:16:35,060
وهذا ينقلنا إلى 55 احتمالًا.

279
00:16:35,060 --> 00:16:38,860
وهنا ربما سأوافق على ما يقترحه،

280
00:16:38,860 --> 00:16:40,200
وهو السرد، مهما كان معنى ذلك.

281
00:16:40,200 --> 00:16:43,300
حسنًا، هذه في الواقع فرصة جيدة لحل اللغز.

282
00:16:43,300 --> 00:16:47,020
إنه يخبرنا أن هذا النمط يعطينا 4. 7 بت من المعلومات.

283
00:16:47,020 --> 00:16:52,400
لكن على اليسار، قبل أن نرى هذا النمط، كان هناك 5. 78 بت من عدم اليقين.

284
00:16:52,400 --> 00:16:56,860
لذا، كاختبار لك، ماذا يعني ذلك بالنسبة لعدد الاحتمالات المتبقية؟

285
00:16:56,860 --> 00:17:02,280
حسنًا، هذا يعني أننا قد اختزلنا إلى جزء واحد من

286
00:17:02,280 --> 00:17:04,700
عدم اليقين، وهو نفس القول بأن هناك إجابتين محتملتين.

287
00:17:04,700 --> 00:17:06,520
إنه خيار 50-50.

288
00:17:06,520 --> 00:17:09,860
ومن هنا، ولأنني وأنت نعرف أي الكلمات أكثر شيوعاً،

289
00:17:09,860 --> 00:17:11,220
فإننا نعلم أن الإجابة يجب أن تكون الهاوية.

290
00:17:11,220 --> 00:17:13,540
ولكن كما هو مكتوب الآن، فإن البرنامج لا يعرف ذلك.

291
00:17:13,540 --> 00:17:17,560
لذلك فهو يستمر في محاولة الحصول على أكبر قدر ممكن

292
00:17:17,560 --> 00:17:20,360
من المعلومات، حتى يتبقى احتمال واحد فقط، ثم يخمنه.

293
00:17:20,360 --> 00:17:22,700
لذا من الواضح أننا بحاجة إلى استراتيجية أفضل لنهاية اللعبة.

294
00:17:22,700 --> 00:17:26,540
لكن لنفترض أننا نطلق على هذا الإصدار أحد برامج حل الكلمات

295
00:17:26,540 --> 00:17:30,740
لدينا، ثم نبدأ ونجري بعض عمليات المحاكاة لنرى كيف يتم ذلك.

296
00:17:30,740 --> 00:17:34,240
لذا فإن الطريقة التي يعمل بها هذا الأمر هي لعب كل لعبة كلمات ممكنة.

297
00:17:34,240 --> 00:17:38,780
إنها تمر بكل تلك الكلمات البالغ عددها 2315 والتي تمثل الإجابات الفعلية.

298
00:17:38,780 --> 00:17:41,340
إنها تستخدم ذلك بشكل أساسي كمجموعة اختبار.

299
00:17:41,340 --> 00:17:45,820
ومع هذه الطريقة الساذجة المتمثلة في عدم مراعاة مدى شيوع الكلمة، ومحاولة تعظيم

300
00:17:45,820 --> 00:17:50,480
المعلومات في كل خطوة على طول الطريق، حتى تصل إلى خيار واحد فقط.

301
00:17:50,480 --> 00:17:55,100
وبحلول نهاية المحاكاة، يبلغ متوسط الدرجات حوالي 4. 124.

302
00:17:55,100 --> 00:17:59,780
وهذا ليس سيئًا، لأكون صادقًا، كنت أتوقع نوعًا ما أن أفعل ما هو أسوأ.

303
00:17:59,780 --> 00:18:03,040
لكن الأشخاص الذين يلعبون لعبة Wordle سيخبرونك أنه يمكنهم عادةً الحصول عليها خلال 4.

304
00:18:03,040 --> 00:18:05,260
التحدي الحقيقي هو الحصول على أكبر عدد ممكن من 3.

305
00:18:05,260 --> 00:18:08,920
إنها قفزة كبيرة جدًا بين النتيجة 4 والنتيجة 3.

306
00:18:08,920 --> 00:18:13,300
إن الفاكهة المعلقة الواضحة هنا هي دمج ما إذا

307
00:18:13,300 --> 00:18:23,160
كانت الكلمة شائعة أم لا، وكيف نفعل ذلك بالضبط.

308
00:18:23,160 --> 00:18:26,860
الطريقة التي تعاملت بها مع الأمر هي الحصول على

309
00:18:26,860 --> 00:18:28,560
قائمة بالتكرارات النسبية لجميع الكلمات في اللغة الإنجليزية.

310
00:18:28,560 --> 00:18:32,560
وقد استخدمت للتو وظيفة بيانات تردد الكلمات الخاصة بـ Mathematica، والتي

311
00:18:32,560 --> 00:18:35,520
تستمد نفسها من مجموعة البيانات العامة لـ Google Books English Ngram.

312
00:18:35,520 --> 00:18:38,680
ومن الممتع النظر إليه، على سبيل المثال، إذا قمنا

313
00:18:38,680 --> 00:18:40,120
بفرزه من الكلمات الأكثر شيوعًا إلى الكلمات الأقل شيوعًا.

314
00:18:40,120 --> 00:18:43,740
من الواضح أن هذه هي الكلمات الأكثر شيوعًا والمكونة من 5 أحرف في اللغة الإنجليزية.

315
00:18:43,740 --> 00:18:46,480
أو بالأحرى، هذه هي المرتبة الثامنة الأكثر شيوعًا.

316
00:18:46,480 --> 00:18:49,440
الأول هو الذي، وبعد ذلك هناك وهناك.

317
00:18:49,440 --> 00:18:53,020
الأول في حد ذاته ليس الأول، بل التاسع، ومن المنطقي أن هذه

318
00:18:53,020 --> 00:18:57,840
الكلمات الأخرى يمكن أن تأتي في كثير من الأحيان، حيث تكون

319
00:18:57,840 --> 00:18:59,000
تلك الكلمات التي تأتي بعد الأول، وأين، وتلك أقل شيوعًا قليلاً.

320
00:18:59,000 --> 00:19:04,400
الآن، عند استخدام هذه البيانات لنمذجة مدى احتمالية أن تكون كل كلمة من

321
00:19:04,400 --> 00:19:06,760
هذه الكلمات هي الإجابة النهائية، لا ينبغي أن تكون متناسبة مع التكرار فقط.

322
00:19:07,020 --> 00:19:12,560
على سبيل المثال، الذي يعطى درجة 0. 002 في مجموعة البيانات هذه، في

323
00:19:12,560 --> 00:19:15,200
حين أن كلمة جديلة أقل احتمالًا بحوالي 1000 مرة.

324
00:19:15,200 --> 00:19:19,400
لكن كلتا هاتين الكلمتين شائعتان بدرجة كافية ومن المؤكد أنهما تستحقان أخذهما في الاعتبار.

325
00:19:19,400 --> 00:19:21,900
لذلك نريد المزيد من القطع الثنائي.

326
00:19:21,900 --> 00:19:26,520
الطريقة التي اتبعتها في ذلك هي تخيل أخذ هذه القائمة الكاملة من

327
00:19:26,520 --> 00:19:31,060
الكلمات، ثم ترتيبها على المحور السيني، ثم تطبيق الدالة السيني، وهي الطريقة

328
00:19:31,060 --> 00:19:35,540
القياسية للحصول على دالة يكون ناتجها ثنائيًا بشكل أساسي، إنها إما 0

329
00:19:35,540 --> 00:19:38,500
أو 1، ولكن هناك تجانس بينهما بالنسبة لتلك المنطقة من عدم اليقين.

330
00:19:38,500 --> 00:19:43,900
لذلك، بشكل أساسي، فإن الاحتمال الذي أقوم بتعيينه لكل كلمة لوجودها في

331
00:19:43,900 --> 00:19:49,540
القائمة النهائية سيكون قيمة الدالة السيني أعلاه أينما كانت على المحور السيني.

332
00:19:49,540 --> 00:19:53,940
من الواضح الآن أن هذا يعتمد على بعض المعلمات، على سبيل المثال مدى اتساع

333
00:19:53,940 --> 00:19:59,660
المساحة على المحور السيني التي تملأها تلك الكلمات يحدد مدى انخفاضنا تدريجيًا أو حادًا

334
00:19:59,660 --> 00:20:03,000
من 1 إلى 0، والمكان الذي نضعهم فيه من اليسار إلى اليمين يحدد القطع.

335
00:20:03,160 --> 00:20:07,340
لأكون صادقًا، الطريقة التي فعلت بها ذلك كانت مجرد لعق إصبعي ووضعه في مهب الريح.

336
00:20:07,340 --> 00:20:10,800
لقد بحثت في القائمة التي تم فرزها وحاولت العثور على نافذة

337
00:20:10,800 --> 00:20:15,280
حيث عندما نظرت إليها، اكتشفت أن حوالي نصف هذه الكلمات من

338
00:20:15,280 --> 00:20:17,680
المرجح أن لا تكون الإجابة النهائية، واستخدمت ذلك كنقطة قطع.

339
00:20:17,680 --> 00:20:21,840
بمجرد أن يكون لدينا توزيع مثل هذا عبر الكلمات، فهذا

340
00:20:21,840 --> 00:20:24,460
يعطينا موقفًا آخر تصبح فيه الإنتروبيا هذا القياس المفيد حقًا.

341
00:20:24,460 --> 00:20:28,480
على سبيل المثال، لنفترض أننا كنا نلعب لعبة وبدأنا

342
00:20:28,480 --> 00:20:32,480
بافتتاحيتي القديمة، والتي كانت عبارة عن ريشة ومسامير، وانتهى

343
00:20:32,480 --> 00:20:33,760
بنا الأمر بموقف حيث توجد أربع كلمات محتملة تطابقها.

344
00:20:33,760 --> 00:20:36,440
ولنفترض أننا نعتبرها كلها محتملة على قدم المساواة.

345
00:20:36,440 --> 00:20:40,000
دعني أسألك، ما هي إنتروبيا هذا التوزيع؟

346
00:20:40,000 --> 00:20:45,920
حسنًا، المعلومات المرتبطة بكل واحد من هذه الاحتمالات ستكون السجل ذو الأساس

347
00:20:45,920 --> 00:20:50,800
2 من 4، حيث أن كل واحد هو 1 و4، أي 2.

348
00:20:50,800 --> 00:20:52,780
قطعتان من المعلومات، وأربعة احتمالات.

349
00:20:52,780 --> 00:20:54,360
كل شيء جيد جدا وجيد.

350
00:20:54,360 --> 00:20:58,320
ولكن ماذا لو أخبرتك أن هناك بالفعل أكثر من أربع مباريات؟

351
00:20:58,320 --> 00:21:02,600
في الواقع، عندما ننظر إلى قائمة الكلمات الكاملة، نجد أن هناك 16 كلمة تطابقها.

352
00:21:02,600 --> 00:21:07,260
لكن لنفترض أن نموذجنا يضع احتمالًا منخفضًا حقًا لتلك الكلمات الـ 12

353
00:21:07,260 --> 00:21:11,440
الأخرى لتكون الإجابة النهائية، شيء مثل 1 في 1000 لأنها غامضة حقًا.

354
00:21:11,440 --> 00:21:15,480
والآن دعني أسألك، ما هي إنتروبيا هذا التوزيع؟

355
00:21:15,480 --> 00:21:19,600
إذا كانت الإنتروبيا تقيس فقط عدد التطابقات هنا، فقد تتوقع أن

356
00:21:19,600 --> 00:21:24,760
تكون شيئًا مثل سجل الأساس 2 لـ 16، والذي سيكون 4،

357
00:21:24,760 --> 00:21:26,200
أي قطعتين من عدم اليقين أكثر مما كان لدينا من قبل.

358
00:21:26,200 --> 00:21:30,320
لكن بطبيعة الحال، فإن عدم اليقين الفعلي لا يختلف كثيرًا عما كان لدينا من قبل.

359
00:21:30,320 --> 00:21:33,840
فقط لأن هناك هذه الكلمات الـ 12 الغامضة لا يعني أنه سيكون

360
00:21:33,840 --> 00:21:38,200
من المثير للدهشة معرفة أن الإجابة النهائية هي السحر، على سبيل المثال.

361
00:21:38,200 --> 00:21:42,080
لذلك عندما تقوم بالحساب هنا، وتضيف احتمالية كل تكرار مضروبًا في

362
00:21:42,080 --> 00:21:45,960
المعلومات المقابلة، فإن ما تحصل عليه هو 2. 11 بت.

363
00:21:45,960 --> 00:21:50,280
أنا فقط أقول، إنها في الأساس جزأين، أساسًا تلك الاحتمالات الأربعة، ولكن هناك

364
00:21:50,280 --> 00:21:54,240
القليل من عدم اليقين بسبب كل تلك الأحداث غير المحتملة إلى حد كبير،

365
00:21:54,240 --> 00:21:57,120
على الرغم من أنك إذا تعلمتها، فسوف تحصل على الكثير من المعلومات منها.

366
00:21:57,120 --> 00:22:00,800
لذا، فإن التصغير هو جزء مما يجعل

367
00:22:00,800 --> 00:22:01,800
Wordle مثالًا رائعًا لدرس نظرية المعلومات.

368
00:22:01,800 --> 00:22:05,280
لدينا هذين التطبيقين المتميزين للشعور بالإنتروبيا.

369
00:22:05,280 --> 00:22:09,640
الأول يخبرنا ما هي المعلومات المتوقعة التي سنحصل عليها

370
00:22:09,640 --> 00:22:14,560
من تخمين معين، والثاني يقول هل يمكننا قياس

371
00:22:14,560 --> 00:22:16,480
عدم اليقين المتبقي بين جميع الكلمات التي لدينا.

372
00:22:16,480 --> 00:22:19,800
ويجب أن أؤكد، في تلك الحالة الأولى التي ننظر فيها إلى المعلومات المتوقعة من التخمين،

373
00:22:19,800 --> 00:22:25,000
بمجرد أن يكون لدينا وزن غير متساوٍ للكلمات، فإن ذلك يؤثر على حساب الإنتروبيا.

374
00:22:25,000 --> 00:22:28,600
على سبيل المثال، اسمحوا لي أن أذكر نفس الحالة التي

375
00:22:28,600 --> 00:22:33,560
كنا ننظر إليها سابقًا للتوزيع المرتبط بـ Weary، ولكن هذه

376
00:22:33,560 --> 00:22:34,560
المرة باستخدام توزيع غير منتظم عبر جميع الكلمات الممكنة.

377
00:22:34,560 --> 00:22:39,360
لذلك اسمحوا لي أن أرى ما إذا كان بإمكاني العثور على جزء هنا يوضح ذلك بشكل جيد.

378
00:22:39,360 --> 00:22:42,480
حسنًا، هنا هذا جيد جدًا.

379
00:22:42,480 --> 00:22:46,360
لدينا هنا نمطان متجاوران متساويان في الاحتمال، ولكن قيل لنا

380
00:22:46,360 --> 00:22:49,480
أن أحدهما يحتوي على 32 كلمة محتملة تتطابق معه.

381
00:22:49,480 --> 00:22:54,080
وإذا تحققنا من ماهيتها، فهذه هي تلك الكلمات الـ 32،

382
00:22:54,080 --> 00:22:55,600
والتي كلها مجرد كلمات غير محتملة للغاية عندما تفحصها بعينيك.

383
00:22:55,600 --> 00:23:00,400
من الصعب العثور على أي إجابات تبدو وكأنها إجابات معقولة، وربما

384
00:23:00,400 --> 00:23:04,440
صيحات، ولكن إذا نظرنا إلى النمط المجاور في التوزيع، والذي يعتبر

385
00:23:04,440 --> 00:23:08,920
محتملًا تقريبًا، فقد قيل لنا أنه يحتوي على 8 تطابقات محتملة

386
00:23:08,920 --> 00:23:09,920
فقط، أي ربع العديد من المباريات، ولكن الأمر على الأرجح.

387
00:23:09,920 --> 00:23:12,520
وعندما نسحب تلك الثقاب، يمكننا أن نرى السبب.

388
00:23:12,520 --> 00:23:17,840
بعض هذه الإجابات هي إجابات معقولة بالفعل، مثل الخاتم، أو الغضب، أو موسيقى الراب.

389
00:23:17,840 --> 00:23:22,000
لتوضيح كيفية دمج كل ذلك، اسمحوا لي أن أعرض الإصدار 2 من Wordlebot

390
00:23:22,000 --> 00:23:25,960
هنا، وهناك اختلافان أو ثلاثة اختلافات رئيسية عن الإصدار الأول الذي رأيناه.

391
00:23:25,960 --> 00:23:29,460
أولاً، كما قلت للتو، الطريقة التي نحسب بها هذه الإنتروبيا، هذه

392
00:23:29,460 --> 00:23:34,800
القيم المتوقعة للمعلومات، تستخدم الآن توزيعات أكثر دقة عبر الأنماط

393
00:23:34,800 --> 00:23:39,300
التي تتضمن احتمال أن تكون كلمة معينة هي الإجابة بالفعل.

394
00:23:39,300 --> 00:23:44,160
كما يحدث، لا تزال الدموع هي رقم 1، على الرغم من أن الدموع التالية مختلفة بعض الشيء.

395
00:23:44,160 --> 00:23:47,920
ثانيًا، عندما يقوم بتصنيف أفضل اختياراته، فإنه سيحتفظ الآن بنموذج لاحتمال أن

396
00:23:47,920 --> 00:23:52,600
تكون كل كلمة هي الإجابة الفعلية، وسيدمج ذلك في قراره، وهو

397
00:23:52,600 --> 00:23:55,520
ما يسهل رؤيته بمجرد أن يكون لدينا بعض التخمينات على طاولة.

398
00:23:55,520 --> 00:24:01,120
مرة أخرى، تجاهل توصيتها لأننا لا نستطيع السماح للآلات بالتحكم في حياتنا.

399
00:24:01,120 --> 00:24:05,160
وأفترض أنني يجب أن أذكر شيئًا آخر مختلفًا هنا على اليسار، وهو أن قيمة عدم

400
00:24:05,160 --> 00:24:10,080
اليقين، وعدد البتات هذا، لم تعد مجرد زائدة عن الحاجة مع عدد التطابقات المحتملة.

401
00:24:10,080 --> 00:24:16,520
الآن إذا سحبناها للأعلى وحسابنا 2 إلى 8. 02، وهو أعلى قليلاً من 256، أعتقد

402
00:24:16,520 --> 00:24:22,640
259، ما يقوله هو أنه على الرغم من وجود 526 كلمة إجمالية تتطابق

403
00:24:22,640 --> 00:24:26,400
فعليًا مع هذا النمط، فإن مقدار عدم اليقين الموجود فيه أقرب إلى ما

404
00:24:26,400 --> 00:24:29,760
سيكون عليه لو كان هناك 259 كلمة محتملة على قدم المساواة النتائج.

405
00:24:29,760 --> 00:24:31,100
يمكنك التفكير في الأمر على هذا النحو.

406
00:24:31,100 --> 00:24:35,560
إنه يعرف أن البورق ليس هو الحل، كما هو الحال مع yorts

407
00:24:35,560 --> 00:24:37,840
وzorl وzorus، لذا فهو أقل غموضًا مما كان عليه في الحالة السابقة.

408
00:24:37,840 --> 00:24:40,220
سيكون هذا العدد من البتات أصغر.

409
00:24:40,220 --> 00:24:44,040
وإذا واصلت لعب اللعبة، فسوف أقوم بتحسين ذلك من خلال

410
00:24:44,040 --> 00:24:48,680
بعض التخمينات التي تتناسب مع ما أود أن أشرحه هنا.

411
00:24:48,680 --> 00:24:52,520
من خلال التخمين الرابع، إذا نظرت إلى أفضل اختياراتها،

412
00:24:52,520 --> 00:24:53,800
يمكنك أن ترى أنها لم تعد مجرد تعظيم الإنتروبيا.

413
00:24:53,800 --> 00:24:58,480
إذن في هذه المرحلة، هناك سبعة احتمالات من الناحية الفنية، لكن

414
00:24:58,480 --> 00:25:00,780
الاحتمالات الوحيدة التي لديها فرصة ذات معنى هي مساكن الطلبة والكلمات.

415
00:25:00,780 --> 00:25:04,760
ويمكنك أن ترى أن اختيار كلتا القيمتين فوق كل هذه

416
00:25:04,760 --> 00:25:07,560
القيم الأخرى، بالمعنى الدقيق للكلمة، سيعطي المزيد من المعلومات.

417
00:25:07,560 --> 00:25:11,200
في المرة الأولى التي قمت فيها بذلك، قمت فقط بجمع هذين الرقمين

418
00:25:11,200 --> 00:25:14,580
لقياس جودة كل تخمين، والذي كان في الواقع أفضل مما قد تظن.

419
00:25:14,580 --> 00:25:17,600
لكن الأمر لم يكن منهجيًا حقًا، وأنا متأكد من أن هناك طرقًا

420
00:25:17,600 --> 00:25:19,880
أخرى يمكن للناس اتباعها ولكن هذا هو النهج الذي توصلت إليه.

421
00:25:19,880 --> 00:25:24,200
إذا كنا نفكر في احتمالية التخمين التالي، كما هو الحال في الكلمات في هذه

422
00:25:24,200 --> 00:25:28,440
الحالة، فإن ما نهتم به حقًا هو النتيجة المتوقعة للعبتنا إذا فعلنا ذلك.

423
00:25:28,440 --> 00:25:32,880
ولحساب تلك النتيجة المتوقعة، نقول ما هو احتمال أن تكون

424
00:25:32,880 --> 00:25:35,640
الكلمات هي الإجابة الفعلية، والتي تصف في الوقت الحالي 58%.

425
00:25:36,080 --> 00:25:40,400
نقول باحتمال 58% أن نتيجتنا في هذه المباراة ستكون 4.

426
00:25:40,400 --> 00:25:46,240
وبعد ذلك، مع احتمال 1 ناقص 58%، ستكون درجاتنا أكثر من 4.

427
00:25:46,240 --> 00:25:50,640
لا نعرف كم من ذلك، ولكن يمكننا تقديره بناءً على

428
00:25:50,640 --> 00:25:52,920
مقدار عدم اليقين المحتمل عندما نصل إلى هذه النقطة.

429
00:25:52,920 --> 00:25:56,600
على وجه التحديد، في هذه اللحظة هناك 1. 44 بت من عدم اليقين.

430
00:25:56,600 --> 00:26:01,560
إذا خمننا الكلمات، فهذا يخبرنا أن المعلومات المتوقعة التي سنحصل عليها هي 1. 27 بت.

431
00:26:01,560 --> 00:26:06,280
لذا، إذا خمننا الكلمات، فإن هذا الاختلاف يمثل مقدار عدم

432
00:26:06,280 --> 00:26:08,280
اليقين الذي من المحتمل أن نتركه بعد حدوث ذلك.

433
00:26:08,280 --> 00:26:12,500
ما نحتاجه هو نوع من الوظائف، والتي أسميها f

434
00:26:12,500 --> 00:26:13,880
هنا، والتي تربط عدم اليقين هذا بالنتيجة المتوقعة.

435
00:26:13,880 --> 00:26:18,040
وكانت الطريقة التي تم بها تحقيق ذلك هي رسم مجموعة من البيانات من

436
00:26:18,040 --> 00:26:23,920
الألعاب السابقة استنادًا إلى الإصدار 1 من الروبوت لنقول ما هي النتيجة الفعلية

437
00:26:23,920 --> 00:26:27,040
بعد نقاط مختلفة مع قدر معين من عدم اليقين يمكن قياسه للغاية.

438
00:26:27,040 --> 00:26:31,120
على سبيل المثال، نقاط البيانات هذه الموجودة هنا أعلى قيمة تقارب 8. 7

439
00:26:31,120 --> 00:26:36,840
أو نحو ذلك يقال لبعض الألعاب بعد النقطة التي كان فيها 8. 7 أجزاء من

440
00:26:36,840 --> 00:26:39,340
عدم اليقين، استغرق الأمر تخمينين للحصول على الإجابة النهائية.

441
00:26:39,340 --> 00:26:43,180
بالنسبة للألعاب الأخرى، استغرق الأمر ثلاثة تخمينات، وبالنسبة للألعاب الأخرى، استغرق الأمر أربعة تخمينات.

442
00:26:43,180 --> 00:26:46,920
إذا انتقلنا إلى اليسار هنا، فإن جميع النقاط فوق الصفر تشير إلى أنه

443
00:26:46,920 --> 00:26:51,620
عندما يكون هناك صفر من عدم اليقين، وهو ما يعني أن هناك احتمالًا

444
00:26:51,620 --> 00:26:55,000
واحدًا فقط، فإن عدد التخمينات المطلوبة هو دائمًا واحد فقط، وهو أمر مطمئن.

445
00:26:55,000 --> 00:26:59,020
كلما كان هناك قدر واحد من عدم اليقين، مما يعني

446
00:26:59,020 --> 00:27:02,360
أن الأمر كان في الأساس يرجع إلى احتمالين فقط، كان

447
00:27:02,360 --> 00:27:03,940
الأمر يتطلب أحيانًا تخمينًا إضافيًا، وأحيانًا يتطلب الأمر تخمينين إضافيين.

448
00:27:03,940 --> 00:27:05,980
وهكذا دواليك هنا.

449
00:27:05,980 --> 00:27:11,020
ربما تكون الطريقة الأسهل قليلًا لتصور هذه البيانات هي تجميعها معًا وأخذ المتوسطات.

450
00:27:11,020 --> 00:27:15,940
على سبيل المثال، يشير هذا الشريط هنا إلى أنه من بين جميع النقاط التي كان لدينا

451
00:27:15,940 --> 00:27:22,420
فيها قدر واحد من عدم اليقين، كان متوسط عدد التخمينات الجديدة المطلوبة حوالي 1. 5.

452
00:27:22,420 --> 00:27:25,920
والشريط هنا يقول من بين جميع الألعاب المختلفة حيث كانت نسبة

453
00:27:25,920 --> 00:27:30,480
عدم اليقين في مرحلة ما أعلى بقليل من أربعة بتات، وهو

454
00:27:30,480 --> 00:27:35,120
ما يشبه تضييقها إلى 16 احتمالًا مختلفًا، ثم في المتوسط يتطلب

455
00:27:35,120 --> 00:27:36,240
الأمر ما يزيد قليلاً عن تخمينين من تلك النقطة إلى الأمام.

456
00:27:36,240 --> 00:27:40,080
ومن هنا قمت للتو بالانحدار ليناسب الوظيفة التي بدت معقولة لهذا الغرض.

457
00:27:40,080 --> 00:27:44,160
وتذكر أن الهدف الأساسي من القيام بأي من ذلك هو أن نتمكن من قياس هذا

458
00:27:44,160 --> 00:27:49,720
الحدس، وهو أنه كلما زادت المعلومات التي نكتسبها من كلمة ما، كلما انخفضت النتيجة المتوقعة.

459
00:27:49,720 --> 00:27:54,380
لذلك مع هذا الإصدار 2. 0، إذا عدنا إلى الوراء وقمنا بإجراء نفس مجموعة عمليات المحاكاة،

460
00:27:54,380 --> 00:27:59,820
حيث قمنا بتشغيلها مقابل جميع الإجابات الممكنة البالغ عددها 2315 كلمة، فكيف سيحدث ذلك؟

461
00:27:59,820 --> 00:28:04,060
حسنًا، على النقيض من نسختنا الأولى، فهي بالتأكيد أفضل، وهو أمر مطمئن.

462
00:28:04,060 --> 00:28:08,780
كل ما قيل وفعل المتوسط هو حوالي 3. 6، على الرغم من أنه على عكس

463
00:28:08,780 --> 00:28:12,820
الإصدار الأول هناك عدة مرات يخسرها ويتطلب أكثر من ستة في هذه الظروف.

464
00:28:12,820 --> 00:28:15,980
من المفترض أنه هناك أوقات يتم فيها إجراء هذه

465
00:28:15,980 --> 00:28:18,980
المقايضة للوصول فعليًا إلى الهدف بدلاً من تعظيم المعلومات.

466
00:28:18,980 --> 00:28:22,140
فهل يمكننا أن نفعل ما هو أفضل من 3. 6؟

467
00:28:22,140 --> 00:28:23,260
يمكننا بالتأكيد.

468
00:28:23,260 --> 00:28:27,120
لقد قلت في البداية أنه من الممتع جدًا محاولة عدم دمج

469
00:28:27,120 --> 00:28:29,980
القائمة الحقيقية للإجابات اللفظية في الطريقة التي يبني بها نموذجه.

470
00:28:29,980 --> 00:28:35,180
ولكن إذا قمنا بدمجها، فإن أفضل أداء يمكن أن أحصل عليه كان حوالي 3. 43.

471
00:28:35,180 --> 00:28:39,520
لذا، إذا حاولنا أن نكون أكثر تعقيدًا من مجرد استخدام بيانات تكرار الكلمات لاختيار هذا

472
00:28:39,520 --> 00:28:44,220
التوزيع المسبق، فهذا 3. 43 ربما يعطي الحد الأقصى لمدى الجودة التي يمكننا تحقيقها من

473
00:28:44,220 --> 00:28:46,360
خلال ذلك، أو على الأقل مدى الجودة التي يمكن أن نحققها من خلال ذلك.

474
00:28:46,360 --> 00:28:50,240
يستخدم هذا الأداء الأفضل بشكل أساسي الأفكار التي كنت أتحدث

475
00:28:50,240 --> 00:28:53,400
عنها هنا، ولكنه يذهب أبعد قليلاً، مثل البحث عن

476
00:28:53,400 --> 00:28:55,660
المعلومات المتوقعة خطوتين للأمام بدلاً من خطوة واحدة فقط.

477
00:28:55,660 --> 00:28:58,720
في الأصل كنت أخطط للحديث أكثر عن ذلك،

478
00:28:58,720 --> 00:29:00,580
لكنني أدركت أننا قد قطعنا وقتًا طويلاً بالفعل.

479
00:29:00,580 --> 00:29:03,520
الشيء الوحيد الذي سأقوله هو بعد إجراء هذا البحث المكون من

480
00:29:03,520 --> 00:29:07,720
خطوتين ثم تشغيل بعض نماذج المحاكاة في أفضل المرشحين، حتى الآن

481
00:29:07,720 --> 00:29:09,500
بالنسبة لي على الأقل يبدو أن Crane هو أفضل افتتاحية.

482
00:29:09,500 --> 00:29:11,080
من كان سيخمن؟

483
00:29:11,080 --> 00:29:15,680
وأيضًا إذا كنت تستخدم قائمة الكلمات الحقيقية لتحديد مساحة الاحتمالات الخاصة بك،

484
00:29:15,680 --> 00:29:17,920
فإن عدم اليقين الذي تبدأ به يزيد قليلاً عن 11 بت.

485
00:29:18,160 --> 00:29:22,760
وقد اتضح، من خلال بحث القوة الغاشمة فقط، أن الحد الأقصى

486
00:29:22,760 --> 00:29:26,580
الممكن للمعلومات المتوقعة بعد أول تخمينين هو حوالي 10 بتات.

487
00:29:26,580 --> 00:29:31,720
وهو ما يشير إلى أفضل سيناريو، بعد أول تخمينين، مع

488
00:29:31,720 --> 00:29:35,220
اللعب الأمثل تمامًا، سيتبقى لديك القليل من عدم اليقين.

489
00:29:35,220 --> 00:29:37,400
وهو نفس الأمر الذي يرجع إلى اثنين من التخمينات المحتملة.

490
00:29:37,400 --> 00:29:41,440
لذلك أعتقد أنه من العدل وربما المحافظ جدًا أن نقول إنه لا يمكنك

491
00:29:41,440 --> 00:29:45,620
أبدًا كتابة خوارزمية تحصل على هذا المتوسط منخفضًا يصل إلى 3، لأنه مع

492
00:29:45,620 --> 00:29:50,460
الكلمات المتاحة لك، ببساطة ليس هناك مجال للحصول على معلومات كافية بعد خطوتين

493
00:29:50,460 --> 00:29:53,820
فقط قادر على ضمان الإجابة في الفتحة الثالثة في كل مرة دون فشل.

