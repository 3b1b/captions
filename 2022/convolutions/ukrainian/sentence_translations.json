[
 {
  "input": "Suppose I give you two different lists of numbers, or maybe two different functions, and I ask you to think of all the ways you might combine those two lists to get a new list of numbers, or combine the two functions to get a new function.",
  "translatedText": "Припустімо, я даю вам два різні списки чисел або, можливо, дві різні функції, і я прошу вас подумати про всі способи, якими ви можете поєднати ці два списки, щоб отримати новий список чисел, або поєднати дві функції, щоб отримати нову функцію.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 11.32
 },
 {
  "input": "Maybe one simple way that comes to mind is to simply add them together term by term.",
  "translatedText": "Можливо, один простий спосіб, який спадає на думку, це просто скласти їх разом термін за терміном.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.12,
  "end": 16.76
 },
 {
  "input": "Likewise with the functions, you can add all the corresponding outputs.",
  "translatedText": "Так само з функціями ви можете додати всі відповідні виходи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 17.16,
  "end": 19.92
 },
 {
  "input": "In a similar vein, you could also multiply the two lists term by term and do the same thing with the functions.",
  "translatedText": "У подібному ключі ви також можете помножити два списки термін за терміном і зробити те саме з функціями.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.54,
  "end": 25.68
 },
 {
  "input": "But there's another kind of combination just as fundamental as both of those, but a lot less commonly discussed, known as a convolution.",
  "translatedText": "Але є ще один вид комбінації, такий же фундаментальний, як обидва, але набагато рідше обговорюваний, відомий як згортка.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.36,
  "end": 33.5
 },
 {
  "input": "But unlike the previous two cases, it's not something that's merely inherited from an operation you can do to numbers.",
  "translatedText": "Але на відміну від попередніх двох випадків, це не те, що просто успадковано від операції, яку ви можете виконати з числами.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.08,
  "end": 39.82
 },
 {
  "input": "It's something genuinely new for the context of lists of numbers or combining functions.",
  "translatedText": "Це щось справді нове для контексту списків чисел або комбінування функцій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.98,
  "end": 44.7
 },
 {
  "input": "They show up all over the place, they are ubiquitous in image processing, it's a core construct in the theory of probability, they're used a lot in solving differential equations, and one context where you've almost certainly seen it, if not by this name, is multiplying two polynomials together.",
  "translatedText": "Вони з’являються скрізь, вони всюдисущі в обробці зображень, це основна конструкція в теорії ймовірності, вони часто використовуються під час розв’язування диференціальних рівнянь, і в одному контексті ви майже напевно це бачили, якщо ні під цією назвою множить два поліноми разом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 45.32,
  "end": 60.24
 },
 {
  "input": "As someone in the business of visual explanations, this is an especially great topic, because the formulaic definition in isolation and without context can look kind of intimidating, but if we take the time to really unpack what it's saying, and before that actually motivate why you would want something like this, it's an incredibly beautiful operation.",
  "translatedText": "Для тих, хто займається візуальними поясненнями, це особливо чудова тема, тому що шаблонне визначення в ізоляції та без контексту може виглядати дещо лякаюче, але якщо ми приділимо час, щоб справді розгадати, що воно говорить, а перед тим фактично мотивувати, чому ви б хотіли щось подібне, це неймовірно красива операція.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 60.74,
  "end": 78.32
 },
 {
  "input": "And I have to admit, I actually learned a little something while putting together the visuals for this project.",
  "translatedText": "І я повинен визнати, що я дійсно дещо навчився, збираючи візуальні елементи для цього проекту.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.96,
  "end": 83.54
 },
 {
  "input": "In the case of convolving two different functions, I was trying to think of different ways you might picture what that could mean, and with one of them I had a little bit of an aha moment for why it is that normal distributions play the role that they do in probability, why it's such a natural shape for a function.",
  "translatedText": "У випадку згортання двох різних функцій я намагався придумати різні способи, якими можна уявити, що це може означати, і з одним із них у мене виник невеликий момент, чому нормальні розподіли відіграють таку роль. вони ймовірно, чому це така природна форма для функції.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 83.54,
  "end": 98.52
 },
 {
  "input": "But I'm getting ahead of myself, there's a lot of setup for that one.",
  "translatedText": "Але я забігаю вперед, там багато налаштувань для цього.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.02,
  "end": 101.52
 },
 {
  "input": "In this video, our primary focus is just going to be on the discrete case, and in particular building up to a very unexpected but very clever algorithm for computing these.",
  "translatedText": "У цьому відео наша основна увага буде зосереджена лише на дискретному випадку, і, зокрема, на розробці дуже несподіваного, але дуже розумного алгоритму для їх обчислення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 101.84,
  "end": 110.26
 },
 {
  "input": "And I'll pull out the discussion for the continuous case into a second part.",
  "translatedText": "І я витягну обговорення безперервного випадку в другу частину.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.26,
  "end": 114.48
 },
 {
  "input": "It's very tempting to open up with the image processing examples, since they're visually the most intriguing, but there are a couple bits of finickiness that make the image processing case less representative of convolutions overall, so instead let's kick things off with probability, and in particular one of the simplest examples that I'm sure everyone here has thought about at some point in their life, which is rolling a pair of dice and figuring out the chances of seeing various different sums.",
  "translatedText": "Дуже спокусливо розпочати приклади обробки зображень, оскільки вони візуально найбільш інтригуючі, але є кілька тонкощів, які роблять процес обробки зображень менш репрезентативним для звивин, тому замість цього давайте почнемо з ймовірності, і, зокрема, один із найпростіших прикладів, про який, я впевнений, кожен тут думав колись у своєму житті, а це кидання пари кубиків і визначення шансів побачити різні суми.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.58,
  "end": 141.5
 },
 {
  "input": "And you might say, not a problem, not a problem.",
  "translatedText": "І ви можете сказати, не проблема, не проблема.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.46,
  "end": 144.46
 },
 {
  "input": "Each of your two dice has six different possible outcomes, which gives us a total of 36 distinct possible pairs of outcomes, and if we just look through them all we can count up how many pairs have a given sum.",
  "translatedText": "Кожен із ваших двох кубиків має шість різних можливих результатів, що дає нам загалом 36 різних можливих пар результатів, і якщо ми просто переглянемо їх усі, то зможемо порахувати, скільки пар мають певну суму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.68,
  "end": 155.86
 },
 {
  "input": "And arranging all the pairs in a grid like this, one pretty nice thing is that all of the pairs that have a constant sum are visible along one of these different diagonals.",
  "translatedText": "І якщо розташувати всі пари в подібній сітці, то одна дуже приємна річ полягає в тому, що всі пари, які мають постійну суму, видно вздовж однієї з цих різних діагоналей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.6,
  "end": 165.44
 },
 {
  "input": "So simply counting how many exist on each of those diagonals will tell you how likely you are to see a particular sum.",
  "translatedText": "Тож простий підрахунок кількості на кожній із цих діагоналей покаже вам, наскільки ймовірно ви побачите певну суму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.44,
  "end": 172.12
 },
 {
  "input": "And I'd say, very good, very good, but can you think of any other ways that you might visualize the same question?",
  "translatedText": "І я б сказав, дуже добре, дуже добре, але чи можете ви придумати якісь інші способи візуалізації того самого питання?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.22,
  "end": 178.66
 },
 {
  "input": "Other images that can come to mind to think of all the distinct pairs that have a given sum?",
  "translatedText": "Інші образи, які можуть прийти в голову, щоб подумати про всі різні пари, які мають задану суму?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.3,
  "end": 184.06
 },
 {
  "input": "And maybe one of you raises your hand and says, yeah, I've got one.",
  "translatedText": "І, можливо, хтось із вас підніме руку і скаже: «Так, у мене є».",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 184.86,
  "end": 187.98
 },
 {
  "input": "Let's say you picture these two different sets of possibilities each in a row, but you flip around that second row.",
  "translatedText": "Скажімо, ви уявляєте ці два різні набори можливостей кожен у рядку, але ви гортаєте другий рядок.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 188.28,
  "end": 193.76
 },
 {
  "input": "That way all of the different pairs which add up to seven line up vertically like this.",
  "translatedText": "Таким чином усі різні пари, які в сумі становлять сім, вишиковуються вертикально таким чином.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.76,
  "end": 198.76
 },
 {
  "input": "And if we slide that bottom row all the way to the right, then the unique pair that adds up to two, the snake eyes, are the only ones that align.",
  "translatedText": "І якщо ми зсунемо цей нижній рядок до кінця вправо, тоді унікальна пара, яка в сумі додає два, очі змії, будуть єдиними, які вирівнюються.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.36,
  "end": 206.28
 },
 {
  "input": "And if I schlunk that over one unit to the right, the pairs which align are the two different pairs that add up to three.",
  "translatedText": "І якщо я переставлю це на одну одиницю праворуч, пари, які вирівнюються, є двома різними парами, які в сумі дають три.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.62,
  "end": 212.08
 },
 {
  "input": "And in general, different offset values of this lower array, which remember I had to flip around first, reveal all the distinct pairs that have a given sum.",
  "translatedText": "І загалом, різні значення зміщення цього нижнього масиву, які пам’ятають, що я мав спочатку перевернути, виявляють усі різні пари, які мають задану суму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.88,
  "end": 221.46
 },
 {
  "input": "As far as probability questions go, this still isn't especially interesting, because all we're doing is counting how many outcomes there are in each of these categories.",
  "translatedText": "Що стосується ймовірнісних питань, це все ще не особливо цікаво, тому що все, що ми робимо, це підраховуємо, скільки результатів є в кожній із цих категорій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.82,
  "end": 232.64
 },
 {
  "input": "But that is with the implicit assumption that there's an equal chance for each of these faces to come up.",
  "translatedText": "Але це з неявним припущенням, що для кожного з цих облич є однакові шанси з’явитися.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.12
 },
 {
  "input": "But what if I told you I have a special set of dice that's not uniform?",
  "translatedText": "Але що, якби я сказав вам, що у мене є спеціальний набір неоднорідних кубиків?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.36,
  "end": 241.62
 },
 {
  "input": "Maybe the blue die has its own set of numbers describing the probabilities for each face coming up, and the red die has its own unique distinct set of numbers.",
  "translatedText": "Можливо, блакитний кубик має свій власний набір чисел, що описує ймовірності для кожної грані, що випадає, а червоний кубик має свій унікальний набір чисел.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 242.06,
  "end": 249.76
 },
 {
  "input": "In that case, if you wanted to figure out, say, the probability of seeing a two, you would multiply the probability that the blue die is a one times the probability that the red die is a one.",
  "translatedText": "У такому випадку, якби ви хотіли обчислити, скажімо, ймовірність побачити двійку, ви б помножили ймовірність того, що синій кубик дорівнює одиниці, на ймовірність того, що червоний кубик дорівнює одиниці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.3,
  "end": 259.86
 },
 {
  "input": "And for the chances of seeing a three, you look at the two distinct pairs where that's possible, and again, multiply the corresponding probabilities, and then add those two products together.",
  "translatedText": "І щоб отримати шанси побачити трійку, ви дивитеся на дві різні пари, де це можливо, і знову множите відповідні ймовірності, а потім додаєте ці два добутки разом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 260.28,
  "end": 269.68
 },
 {
  "input": "Similarly, the chances of seeing a four involves multiplying together three different pairs of possibilities and adding them all together.",
  "translatedText": "Подібним чином шанси побачити четвірку включають множення разом трьох різних пар можливостей і додавання їх усіх разом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 270.1,
  "end": 276.82
 },
 {
  "input": "And in the spirit of setting up some formulas, let's name these top probabilities a1, a2, a3, and so on, and name the bottom ones b1, b2, b3, and so on.",
  "translatedText": "І в дусі створення деяких формул давайте назвемо ці найвищі ймовірності a1, a2, a3 і так далі, а нижні — b1, b2, b3 і так далі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.82,
  "end": 285.96
 },
 {
  "input": "And in general, this process, where we're taking two different arrays of numbers, flipping the second one around, and then lining them up at various different offset values, taking a bunch of pairwise products and adding them up, that's one of the fundamental ways to think about what a convolution is.",
  "translatedText": "І загалом, цей процес, коли ми беремо два різні масиви чисел, повертаємо другий, а потім шикуємо їх за різними значеннями зміщення, беремо купу попарних добутків і додаємо їх, це один із основні способи уявлення про те, що таке згортка.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.4,
  "end": 301.62
 },
 {
  "input": "So just to spell it out a little more exactly, through this process, we just generated probabilities for seeing two, three, four, on and on up to 12, and we got them by mixing together one list of values, a, and another list of values, b.",
  "translatedText": "Щоб сформулювати це трохи точніше, за допомогою цього процесу ми просто згенерували ймовірності для того, щоб побачити два, три, чотири, і далі до 12, і ми отримали їх, змішавши разом один список значень, a та інший список значень, б.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.86,
  "end": 316.98
 },
 {
  "input": "In the lingo, we'd say the convolution of those two sequences gives us this new sequence, the new sequence of 11 values, each of which looks like some sum of pairwise products.",
  "translatedText": "На жаргоні ми б сказали, що згортка цих двох послідовностей дає нам цю нову послідовність, нову послідовність з 11 значень, кожне з яких виглядає як деяка сума попарних добутків.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.44,
  "end": 327.34
 },
 {
  "input": "If you prefer, another way you could think about the same operation is to first create a table of all the pairwise products, and then add up along all these diagonals.",
  "translatedText": "Якщо ви віддаєте перевагу, інший спосіб, яким ви можете подумати про ту саму операцію, це спочатку створити таблицю всіх попарних добутків, а потім підсумувати всі ці діагоналі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.34,
  "end": 336.98
 },
 {
  "input": "Again, that's a way of mixing together these two sequences of numbers to get us a new sequence of 11 numbers.",
  "translatedText": "Знову ж таки, це спосіб змішування цих двох послідовностей чисел, щоб отримати нову послідовність з 11 чисел.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 337.46,
  "end": 342.76
 },
 {
  "input": "It's the same operation as the sliding windows thought, just another perspective.",
  "translatedText": "Це та сама операція, що і розсувні вікна, просто інша перспектива.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 343.24,
  "end": 346.46
 },
 {
  "input": "Putting a little notation to it, here's how you might see it written down.",
  "translatedText": "Додавши до цього невеликі позначки, ось як ви можете це побачити.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.14,
  "end": 349.8
 },
 {
  "input": "The convolution of a and b, denoted with this little asterisk, is a new list, and the nth element of that list looks like a sum, and that sum goes over all different pairs of indices, i and j, so that the sum of those indices is equal to n.",
  "translatedText": "Згортка a і b, позначена цією маленькою зірочкою, є новим списком, і n-й елемент цього списку виглядає як сума, і ця сума охоплює всі різні пари індексів, i і j, так що сума ці індекси дорівнюють n.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 350.22,
  "end": 364.86
 },
 {
  "input": "It's kind of a mouthful, but for example, if n was 6, the pairs we're going over are 1 and 5, 2 and 4, 3 and 3, 4 and 2, 5 and 1, all the different pairs that add up to 6.",
  "translatedText": "Це наче ковток, але, наприклад, якщо n дорівнює 6, то пари, які ми розглядаємо, це 1 і 5, 2 і 4, 3 і 3, 4 і 2, 5 і 1, усі різні пари, які складаються до 6.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.28,
  "end": 375.8
 },
 {
  "input": "But honestly, however you write it down, the notation is secondary in importance to the visual you might hold in your head for the process.",
  "translatedText": "Але чесно кажучи, як би ви це не записали, нотація має другорядне значення порівняно з візуалом, який ви можете тримати в голові під час процесу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 376.62,
  "end": 382.34
 },
 {
  "input": "Here, maybe it helps to do a super simple example, where I might ask you what's the convolution of the list 1, 2, 3, with the list 4, 5, 6.",
  "translatedText": "Тут, можливо, допоможе зробити дуже простий приклад, де я можу запитати вас, яка згортка списку 1, 2, 3 зі списком 4, 5, 6.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.28,
  "end": 390.78
 },
 {
  "input": "You might picture taking both of these lists, flipping around that second one, and then starting with its lid all the way over to the left.",
  "translatedText": "Ви можете собі уявити, як ви берете обидва ці списки, гортаєте другий, а потім починаєте з його кришки до кінця ліворуч.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.48,
  "end": 397.68
 },
 {
  "input": "Then the pair of values which align are 1 and 4, multiply them together, and that gives us our first term of our output.",
  "translatedText": "Тоді пара значень, які вирівнюються, це 1 і 4, перемножуємо їх разом, і це дає нам перший член нашого результату.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.18,
  "end": 403.54
 },
 {
  "input": "Slide that bottom array one unit to the right, the pairs which align are 1 and 5, and 2 and 4, multiply those pairs, add them together, and that gives us 13, the next entry in our output.",
  "translatedText": "Посуньте цей нижній масив на одну одиницю вправо, пари, які вирівнюються, це 1 і 5, а також 2 і 4, помножте ці пари, додайте їх разом, і це дасть нам 13, наступний запис у наших виводах.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.96,
  "end": 414.46
 },
 {
  "input": "Slide things over once more, and we'll take 1 times 6, plus 2 times 5, plus 3 times 4, which happens to be 28.",
  "translatedText": "Пересуньте все ще раз, і ми візьмемо 1 помножити на 6, плюс 2 помножити на 5, плюс 3 помножити на 4, що дорівнює 28.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.96,
  "end": 421.56
 },
 {
  "input": "One more slide, and we get 2 times 6, plus 3 times 5, and that gives us 27, and finally the last term will look like 3 times 6.",
  "translatedText": "Ще один слайд, і ми отримаємо 2 помножити на 6 плюс 3 помножити на 5, і це дає нам 27, і нарешті останній член виглядатиме як 3 помножити на 6.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.02,
  "end": 430.12
 },
 {
  "input": "If you'd like, you can pull up whatever your favorite programming language is, and your favorite library that includes various numerical operations, and you can confirm I'm not lying to you.",
  "translatedText": "Якщо ви хочете, ви можете вибрати будь-яку вашу улюблену мову програмування та вашу улюблену бібліотеку, яка містить різноманітні числові операції, і ви можете підтвердити, що я вам не брешу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.66,
  "end": 438.98
 },
 {
  "input": "If you take the convolution of 1, 2, 3, against 4, 5, 6, this is indeed the result that you'll get.",
  "translatedText": "Якщо ви візьмете згортку 1, 2, 3 проти 4, 5, 6, це справді результат, який ви отримаєте.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.98,
  "end": 444.48
 },
 {
  "input": "We've seen one case where this is a natural and desirable operation, adding up to probability distributions, and another common example would be a moving average.",
  "translatedText": "Ми бачили один випадок, коли це природна і бажана операція, що додає до розподілу ймовірностей, і іншим поширеним прикладом було б ковзне середнє.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.92,
  "end": 453.66
 },
 {
  "input": "Imagine you have some long list of numbers, and you take another smaller list of numbers that all add up to 1.",
  "translatedText": "Уявіть, що у вас є довгий список чисел, і ви берете ще один менший список чисел, які в сумі дають 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.08,
  "end": 459.76
 },
 {
  "input": "In this case, I just have a little list of 5 values, and they're all equal to 1 5th.",
  "translatedText": "У цьому випадку я маю невеликий список із 5 значень, і всі вони дорівнюють 15-му.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.1,
  "end": 464.06
 },
 {
  "input": "Then if we do this sliding window convolution process, and kind of close our eyes and sweep under the rug what happens at the very beginning of it, once our smaller list of values entirely overlaps with the bigger one, think about what each term in this convolution really means.",
  "translatedText": "Тоді, якщо ми зробимо цей процес згортання ковзного вікна, закриємо очі та заховаємо те, що відбувається на самому початку, як тільки наш менший список значень повністю збігається з більшим, подумайте про те, що означає кожен термін у цьому згортка насправді означає.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.06,
  "end": 478.7
 },
 {
  "input": "At each iteration, what you're doing is multiplying each of the values from your data by 1 5th, and adding them all together, which is to say you're taking an average of your data inside this little window.",
  "translatedText": "На кожній ітерації ви множите кожне значення з ваших даних на 15 і додаєте їх усі разом, що означає, що ви берете середнє значення своїх даних у цьому маленькому вікні.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.4,
  "end": 490.52
 },
 {
  "input": "Overall, the process gives you a smoothed out version of the original data, and you could modify this starting with a different little list of numbers, and as long as that little list all adds up to 1, you can still interpret it as a moving average.",
  "translatedText": "Загалом, процес дає вам згладжену версію вихідних даних, і ви можете змінити це, починаючи з іншого невеликого списку чисел, і доки цей невеликий список у сумі дорівнює 1, ви все одно можете інтерпретувати це як рухливий середній.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.1,
  "end": 502.72
 },
 {
  "input": "In the example shown here, that moving average would be giving more weight towards the central value.",
  "translatedText": "У наведеному тут прикладі ковзне середнє надає більшу вагу центральному значенню.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 503.4,
  "end": 507.76
 },
 {
  "input": "This also results in a smoothed out version of the data.",
  "translatedText": "Це також призводить до згладженої версії даних.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.42,
  "end": 510.8
 },
 {
  "input": "If you do kind of a two-dimensional analog of this, it gives you a fun algorithm for blurring a given image.",
  "translatedText": "Якщо ви зробите такий собі двовимірний аналог, ви отримаєте цікавий алгоритм для розмивання певного зображення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.14,
  "end": 518.72
 },
 {
  "input": "And I should say the animations I'm about to show are modified from something I originally made for part of a set of lectures I did with the Julia Lab at MIT for a certain OpenCourseWare class that included an image processing unit.",
  "translatedText": "І я повинен сказати, що анімації, які я збираюся показати, змінені з того, що я спочатку створив для частини серії лекцій, які я проводив у Julia Lab в MIT для певного класу OpenCourseWare, який включав блок обробки зображень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.72,
  "end": 531.08
 },
 {
  "input": "There we did a little bit more to dive into the code behind all of this, so if you're curious I'll leave you some links.",
  "translatedText": "Там ми зробили трохи більше, щоб зануритися в код, що стоїть за всім цим, тому, якщо вам цікаво, я залишу вам кілька посилань.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.56,
  "end": 536.28
 },
 {
  "input": "But focusing back on this blurring example, what's going on is I've got this little 3x3 grid of values that's marching along our original image, and if we zoom in, each one of those values is 1 9th, and what I'm doing at each iteration is multiplying each of those values by the corresponding pixel that it sits on top of.",
  "translatedText": "Але повернемося до цього прикладу розмиття. Що відбувається, я маю маленьку сітку значень 3x3, яка рухається вздовж нашого оригінального зображення, і якщо ми збільшимо масштаб, кожне з цих значень буде 19-м, і що я роблю на кожній ітерації кожне з цих значень множиться на відповідний піксель, над яким воно знаходиться.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.62,
  "end": 553.62
 },
 {
  "input": "And of course in computer science we think of colors as little vectors of three values, representing the red, green, and blue components.",
  "translatedText": "І, звичайно, в інформатиці ми розглядаємо кольори як маленькі вектори трьох значень, що представляють червоний, зелений і синій компоненти.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.9,
  "end": 560.2
 },
 {
  "input": "When I multiply all these little values by 1 9th and I add them together, it gives us an average along each color channel, and the corresponding pixel for the image on the right is defined to be that sum.",
  "translatedText": "Коли я множу всі ці маленькі значення на 19 і додаю їх разом, це дає нам середнє значення по кожному колірному каналу, і відповідний піксель для зображення праворуч визначається як ця сума.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.56,
  "end": 571.2
 },
 {
  "input": "The overall effect, as we do this for every single pixel on the image, is that each one kind of bleeds into all of its neighbors, which gives us a blurrier version than the original.",
  "translatedText": "Загальний ефект, оскільки ми робимо це для кожного окремого пікселя на зображенні, полягає в тому, що кожен піксель перетікає в усіх своїх сусідів, що дає нам більш розмиту версію, ніж оригінальна.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.94,
  "end": 580.86
 },
 {
  "input": "In the lingo we'd say that the image on the right is a convolution of our original image with a little grid of values.",
  "translatedText": "На жаргоні ми б сказали, що зображення праворуч є згорткою нашого оригінального зображення з невеликою сіткою значень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 581.72,
  "end": 587.74
 },
 {
  "input": "Or more technically maybe I should say that it's the convolution with a 180 degree rotated version of that little grid of values.",
  "translatedText": "Або більш технічно, можливо, я повинен сказати, що це згортка з поверненою на 180 градусів версією цієї маленької сітки значень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.14,
  "end": 594.4
 },
 {
  "input": "Not that it matters when the grid is symmetric, but it's just worth keeping in mind that the definition of a convolution, as inherited from the pure math context, should always invite you to think about flipping around that second array.",
  "translatedText": "Не те, щоб це мало значення, коли сітка є симетричною, але просто варто пам’ятати, що визначення згортки, успадковане з чистого математичного контексту, має завжди спонукати вас подумати про гортання цього другого масиву.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.62,
  "end": 605.24
 },
 {
  "input": "If we modify this slightly we can get a much more elegant blurring effect by choosing a different grid of values.",
  "translatedText": "Якщо ми трохи змінимо це, ми зможемо отримати набагато елегантніший ефект розмиття, вибравши іншу сітку значень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 605.96,
  "end": 611.1
 },
 {
  "input": "In this case I have a little 5x5 grid, but the distinction is not so much its size.",
  "translatedText": "У цьому випадку у мене невелика сітка 5x5, але відмінність полягає не стільки в її розмірі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.44,
  "end": 615.78
 },
 {
  "input": "If we zoom in we notice that the value in the middle is a lot bigger than the value towards the edges, and where this is coming from is they're all sampled from a bell curve, known as a Gaussian distribution.",
  "translatedText": "Якщо ми збільшимо масштаб, то помітимо, що значення в середині набагато більше, ніж значення до країв, і це відбувається з того, що всі вони взяті з дзвоноподібної кривої, відомої як розподіл Гауса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.98,
  "end": 625.94
 },
 {
  "input": "That way when we multiply all of these values by the corresponding pixel that they're sitting on top of, we're giving a lot more weight to that central pixel and much less towards the ones out at the edge.",
  "translatedText": "Таким чином, коли ми множимо всі ці значення на відповідний піксель, над яким вони сидять, ми надаємо набагато більшої ваги цьому центральному пікселю, а тим, що знаходяться на краю, набагато менше.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 626.8,
  "end": 636.38
 },
 {
  "input": "And just as before the corresponding pixel on the right is defined to be this sum.",
  "translatedText": "І так само, як і раніше, відповідний піксель праворуч визначається як ця сума.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.8,
  "end": 640.56
 },
 {
  "input": "As we do this process for every single pixel it gives a blurring effect which much more authentically simulates the notion of putting your lens out of focus or something like that.",
  "translatedText": "Оскільки ми виконуємо цей процес для кожного окремого пікселя, це дає ефект розмиття, який набагато достовірніше імітує поняття розміщення вашого об’єктива поза фокусом або щось подібне.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.32,
  "end": 649.72
 },
 {
  "input": "But blurring is far from the only thing that you can do with this idea.",
  "translatedText": "Але розмиття - далеко не єдине, що ви можете зробити з цією ідеєю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.36
 },
 {
  "input": "For instance take a look at this little grid of values, which involves some positive numbers on the left and some negative numbers on the right, which I'll color with blue and red respectively.",
  "translatedText": "Подивіться, наприклад, на цю невелику сітку значень, яка містить кілька додатних чисел ліворуч і кілька від’ємних чисел праворуч, які я розфарбую синім і червоним кольором відповідно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.8,
  "end": 662.9
 },
 {
  "input": "Take a moment to see if you can predict and understand what effect this will have on the final image.",
  "translatedText": "Знайдіть хвилинку, щоб перевірити, чи можете ви передбачити та зрозуміти, який вплив це матиме на кінцеве зображення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.64,
  "end": 668.48
 },
 {
  "input": "So in this case I'll just be thinking of the image as grayscale instead of colored, so each of the pixels is just represented by one number instead of three.",
  "translatedText": "Тож у цьому випадку я буду думати про зображення як у градаціях сірого, а не як кольорове, тому кожен піксель буде представлено лише одним числом, а не трьома.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.72,
  "end": 678.12
 },
 {
  "input": "And one thing worth noticing is that as we do this convolution it's possible to get negative values.",
  "translatedText": "І одна річ, яку варто зауважити, це те, що коли ми виконуємо цю згортку, можна отримати від’ємні значення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 678.44,
  "end": 683.06
 },
 {
  "input": "For example at this point here if we zoom in the left half of our little grid sits entirely on top of black pixels, which would have a value of zero, but the right half of negative values all sit on top of white pixels, which would have a value of one.",
  "translatedText": "Наприклад, у цій точці тут, якщо ми збільшимо ліву половину нашої маленької сітки, вона буде повністю розташована поверх чорних пікселів, які матимуть нульове значення, але права половина від’ємних значень буде розташована поверх білих пікселів, що буде мають значення одиниці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.06,
  "end": 695.46
 },
 {
  "input": "So when we multiply corresponding terms and add them together the results will be very negative, and the way I'm displaying this with the image on the right is to color negative values red and positive values blue.",
  "translatedText": "Отже, коли ми перемножуємо відповідні члени та додаємо їх разом, результати будуть дуже негативними, і я відображаю це на зображенні праворуч — це фарбую від’ємні значення в червоний колір, а додатні — у синій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 696.18,
  "end": 706.36
 },
 {
  "input": "Another thing to notice is that when you're on a patch that's all the same color everything goes to zero since the sum of the values in our little grid is zero.",
  "translatedText": "Ще одна річ, яку слід зауважити, це те, що коли ви перебуваєте на патчі, який має один колір, усе стає нульовим, оскільки сума значень у нашій маленькій сітці дорівнює нулю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 714.08
 },
 {
  "input": "This is very different from the previous two examples where the sum of our little grid was one, which let us interpret it as a moving average and hence a blur.",
  "translatedText": "Це дуже відрізняється від двох попередніх прикладів, де сума нашої маленької сітки була одиницею, що дозволило нам інтерпретувати її як ковзне середнє і, отже, розмиття.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 715.18,
  "end": 722.18
 },
 {
  "input": "All in all this little process basically detects wherever there's variation in the pixel value as you move from left to right, and so it gives you a kind of way to pick up on all the vertical edges from your image.",
  "translatedText": "Загалом, цей маленький процес виявляє будь-які коливання значення пікселів під час руху зліва направо, і тому він дає вам своєрідний спосіб виявити всі вертикальні краї вашого зображення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.64,
  "end": 733.92
 },
 {
  "input": "And similarly if we rotated that grid around so that it varies as you move from the top to the bottom this will be picking up on all the horizontal edges, which in the case of our little pie creature image does result in some pretty demonic eyes.",
  "translatedText": "І так само, якщо ми обертаємо цю сітку так, щоб вона змінювалася, коли ви рухаєтеся від верху до низу, це буде підбиратися на всіх горизонтальних краях, що у випадку з нашим маленьким зображенням пиріжкової істоти призведе до гарних демонічних очей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 736.5,
  "end": 749.34
 },
 {
  "input": "This smaller grid by the way is often called a kernel, and the beauty here is how just by choosing a different kernel you can get different image processing effects, not just blurring your edge detection but also things like sharpening.",
  "translatedText": "Цю меншу сітку, до речі, часто називають ядром, і принадність тут полягає в тому, що просто вибравши інше ядро, ви можете отримати різні ефекти обробки зображень, не лише розмиваючи виявлення країв, але й такі речі, як збільшення різкості.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 750.4,
  "end": 760.84
 },
 {
  "input": "For those of you who have heard of a convolutional neural network the idea there is to use data to figure out what the kernels should be in the first place as determined by whatever the neural network wants to detect.",
  "translatedText": "Для тих із вас, хто чув про згорточну нейронну мережу, ідея полягає в тому, щоб використовувати дані, щоб з’ясувати, якими мають бути ядра в першу чергу, як це визначається тим, що нейронна мережа хоче виявити.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 760.84,
  "end": 771.48
 },
 {
  "input": "Another thing I should maybe bring up is the length of the output.",
  "translatedText": "Інша річ, яку я, можливо, повинен згадати, це довжина виводу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 772.76,
  "end": 775.52
 },
 {
  "input": "For something like the moving average example you might only want to think about the terms when both of the windows fully align with each other, or in the image processing example maybe you want the final output to have the same size as the original.",
  "translatedText": "Для чогось на кшталт прикладу ковзного середнього ви можете думати лише про терміни, коли обидва вікна повністю вирівнюються одне з одним, або у прикладі обробки зображення, можливо, ви хочете, щоб кінцевий результат мав такий самий розмір, як і оригінал.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 775.82,
  "end": 787.28
 },
 {
  "input": "Now convolutions as a pure math operation always produce an array that's bigger than the two arrays that you started with, at least assuming one of them doesn't have a length of one.",
  "translatedText": "Тепер згортки як чиста математична операція завжди створюють масив, більший за два масиви, з яких ви почали, принаймні припускаючи, що один із них не має довжини одиниці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.28,
  "end": 796.18
 },
 {
  "input": "Just know that in certain computer science contexts you often want to deliberately truncate that output.",
  "translatedText": "Просто знайте, що в певних контекстах інформатики ви часто хочете навмисно скоротити цей вихід.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.72,
  "end": 801.52
 },
 {
  "input": "Another thing worth highlighting is that in the computer science context this notion of flipping around that kernel before you let it march across the original often feels really weird and just uncalled for, but again note that that's what's inherited from the pure math context where like we saw with the probabilities it's an incredibly natural thing to do.",
  "translatedText": "Ще одна річ, яку варто підкреслити, полягає в тому, що в контексті інформатики це поняття гортати ядро перед тим, як ви дасте йому пройти через оригінал, часто здається дуже дивним і просто непотрібним, але знову зауважте, що це те, що успадковано від чистого математичного контексту, де, як ми бачив з ймовірністю, що це неймовірно природна річ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 804.72,
  "end": 822.44
 },
 {
  "input": "And actually I can show you one more pure math example where even the programmers should care about this one because it opens the doors for a much faster algorithm to compute all of these.",
  "translatedText": "І фактично я можу показати вам ще один чистий математичний приклад, про який навіть програмісти повинні піклуватися, тому що він відкриває двері для набагато швидшого алгоритму для обчислення всього цього.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 823.02,
  "end": 832.02
 },
 {
  "input": "To set up what I mean by faster here let me go back and pull up some python again and I'm going to create two different relatively big arrays.",
  "translatedText": "Щоб налаштувати те, що я маю на увазі під швидшим тут, дозвольте мені повернутися і знову витягнути якийсь пітон, і я збираюся створити два різні відносно великі масиви.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.62,
  "end": 839.78
 },
 {
  "input": "Each one will have a hundred thousand random elements in it and I'm going to assess the runtime of the convolve function from the numpy library.",
  "translatedText": "У кожному з них буде сто тисяч випадкових елементів, і я збираюся оцінити час виконання функції convolve з бібліотеки numpy.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.94,
  "end": 847.54
 },
 {
  "input": "And in this case it runs it for multiple different iterations, tries to find an average, and it looks like on this computer at least it averages at 4.87 seconds.",
  "translatedText": "І в цьому випадку він запускає його для кількох різних ітерацій, намагається знайти середнє значення, і виглядає, що на цьому комп’ютері принаймні середнє значення становить 4.87 секунд.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 848.18,
  "end": 856.52
 },
 {
  "input": "By contrast if I use a different function from the scipy library called fftconvolve which is the same thing just implemented differently that only takes 4.3 milliseconds on average, so three orders of magnitude improvement.",
  "translatedText": "На відміну від цього, якщо я використовую іншу функцію з бібліотеки scipy під назвою fftconvolve, яка є тією самою, лише реалізованою по-іншому, що займає лише 4.У середньому 3 мілісекунди, тобто покращення на три порядки.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 856.96,
  "end": 870.16
 },
 {
  "input": "And again even though it flies under a different name it's giving the same output that the other convolve function does, it's just doing something to go about it in a cleverer way.",
  "translatedText": "І знову ж таки, незважаючи на те, що він літає під іншою назвою, він видає той самий результат, що й інша функція convolve, але він просто робить щось, щоб зробити це більш розумним способом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.16,
  "end": 879.12
 },
 {
  "input": "Remember how with the probability example I said another way you could think about the convolution was to create this table of all the pairwise products and then add up those pairwise products along the diagonals.",
  "translatedText": "Пам’ятайте, як у прикладі ймовірності я сказав, що ще один спосіб, яким ви можете думати про згортку, це створити цю таблицю всіх попарних добутків, а потім додати ці попарні добутки вздовж діагоналей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.2,
  "end": 892.68
 },
 {
  "input": "There's of course nothing specific to probability anytime you're convolving two different lists of numbers you can think about it this way.",
  "translatedText": "Звичайно, немає нічого конкретного щодо ймовірності, коли ви складаєте два різні списки чисел, ви можете думати про це таким чином.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.66,
  "end": 899.04
 },
 {
  "input": "Create this kind of multiplication table with all pairwise products and then each sum along the diagonal corresponds to one of your final outputs.",
  "translatedText": "Створіть таку таблицю множення з усіма попарними продуктами, а потім кожна сума по діагоналі відповідає одному з ваших кінцевих результатів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 899.04,
  "end": 906.46
 },
 {
  "input": "One context where this view is especially natural is when you multiply together two polynomials.",
  "translatedText": "Один контекст, де цей погляд особливо природний, це коли ви множите разом два поліноми.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 912.8
 },
 {
  "input": "For example let me take the little grid we already have and replace the top terms with 1, 2x, and 3x squared and replace the other terms with 4, 5x, and 6x squared.",
  "translatedText": "Наприклад, дозвольте мені взяти маленьку сітку, яку ми вже маємо, і замінити верхні члени на 1, 2x і 3x у квадраті, а інші члени на 4, 5x і 6x у квадраті.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 913.3,
  "end": 923.6
 },
 {
  "input": "Now think about what it means when we're creating all of these different pairwise products between the two lists.",
  "translatedText": "А тепер подумайте, що це означає, коли ми створюємо всі ці різні попарні продукти між двома списками.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.0,
  "end": 928.84
 },
 {
  "input": "What you're doing is essentially expanding out the full product of the two polynomials I have written down and then when you add up along the diagonal that corresponds to collecting all like terms which is pretty neat expanding a polynomial and collecting like terms is exactly the same process as a convolution.",
  "translatedText": "Те, що ви робите, по суті, розширюєте повний добуток двох поліномів, які я записав, а потім, коли ви додаєте вздовж діагоналі, яка відповідає збору всіх подібних доданків, що є досить акуратним, розширюючи поліном і збираючи подібні доданки, це точно той самий процес, що й згортка.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 929.04,
  "end": 946.44
 },
 {
  "input": "But this allows us to do something that's pretty cool because think about what we're saying here.",
  "translatedText": "Але це дозволяє нам робити щось дуже круте, тому що подумайте про те, що ми тут говоримо.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 947.74,
  "end": 952.34
 },
 {
  "input": "We're saying if you take two different functions and you multiply them together which is a simple pointwise operation that's the same thing as if you had first extracted the coefficients from each one of those assuming they're polynomials and then taken a convolution of those two lists of coefficients.",
  "translatedText": "Ми говоримо, що якщо ви берете дві різні функції та перемножуєте їх разом, що є простою поточковою операцією, це те ж саме, що якби ви спочатку витягли коефіцієнти з кожної з них, припускаючи, що вони є поліномами, а потім зробили згортку цих два списки коефіцієнтів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 952.34,
  "end": 968.84
 },
 {
  "input": "What makes that so interesting is that convolutions feel in principle a lot more complicated than simple multiplication and I don't just mean conceptually they're harder to think about I mean computationally it requires more steps to perform a convolution than it does to perform a pointwise product of two different lists.",
  "translatedText": "Що робить це таким цікавим, так це те, що згортки в принципі здаються набагато складнішими, ніж просте множення, і я маю на увазі не просто концептуально, що про них важче думати, я маю на увазі, що з обчислювальної точки зору для виконання згортки потрібно більше кроків, ніж для виконання поточковий добуток двох різних списків.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 969.62,
  "end": 985.76
 },
 {
  "input": "For example let's say I gave you two really big polynomials say each one with a hundred different coefficients then if the way you multiply them was to expand out this product you know filling in this entire 100 by 100 grid of pairwise products that would require you to perform 10,000 different products and then when you're collecting all the like terms along the diagonals that's another set of around 10,000 operations.",
  "translatedText": "Наприклад, скажімо, я дав вам два справді великі поліноми, скажімо, кожен із сотнею різних коефіцієнтів, тоді, якби ви їх помножили, щоб розширити цей добуток, який ви знаєте, заповнивши всю цю сітку 100 на 100 попарних добутків, що вимагатиме від вас виконайте 10 000 різних продуктів, а потім, коли ви збираєте всі подібні терміни вздовж діагоналей, це ще один набір приблизно з 10 000 операцій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.32,
  "end": 1009.86
 },
 {
  "input": "More generally in the lingo we'd say the algorithm is O of n squared meaning for two lists of size n the way that the number of operations scales is in proportion to the square of n.",
  "translatedText": "У більш загальному жаргоні ми б сказали, що алгоритм є O з n у квадраті, що означає для двох списків розміром n таким чином, що кількість масштабів операцій пропорційна квадрату n.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1010.7,
  "end": 1021.14
 },
 {
  "input": "On the other hand if I think of two polynomials in terms of their outputs for example sampling their values at some handful of inputs then multiplying them only requires as many operations as the number of samples since again it's a pointwise operation and with polynomials you only need finitely many samples to be able to recover the coefficients.",
  "translatedText": "З іншого боку, якщо я думаю про два поліноми в термінах їхніх виходів, наприклад, вибірка їхніх значень на кількох вхідних даних, тоді їх множення потребує лише стільки операцій, скільки вибірок, оскільки це знову ж таки поточкова операція, а з поліномами вам потрібно лише кінцеву кількість вибірок, щоб мати можливість відновити коефіцієнти.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1021.82,
  "end": 1040.54
 },
 {
  "input": "For example two outputs are enough to uniquely specify a linear polynomial.",
  "translatedText": "Наприклад, двох виходів достатньо, щоб однозначно визначити лінійний поліном.",
  "n_reviews": 0,
  "start": 1040.54,
  "end": 1045.06
 },
 {
  "input": "Three outputs would be enough to uniquely specify a quadratic polynomial.",
  "translatedText": "Трьох вихідних даних було б достатньо, щоб однозначно визначити квадратичний поліном.",
  "n_reviews": 0,
  "start": 1045.66,
  "end": 1049.4
 },
 {
  "input": "And in general if you know n distinct outputs that's enough to uniquely specify a polynomial that has n different coefficients.",
  "translatedText": "І взагалі, якщо ви знаєте n різних виходів, цього достатньо, щоб однозначно вказати поліном, який має n різних коефіцієнтів.",
  "n_reviews": 0,
  "start": 1049.64,
  "end": 1056.74
 },
 {
  "input": "Or if you prefer we could phrase this in the language of systems of equations.",
  "translatedText": "Або, якщо хочете, ми могли б сформулювати це мовою систем рівнянь.",
  "n_reviews": 0,
  "start": 1057.44,
  "end": 1060.72
 },
 {
  "input": "Imagine I tell you I have some polynomial but I don't tell you what the coefficients are, those are a mystery to you.",
  "translatedText": "Уявіть, що я кажу вам, що у мене є якийсь поліном, але я не кажу вам, які це коефіцієнти, це для вас загадка.",
  "n_reviews": 0,
  "start": 1061.2,
  "end": 1066.52
 },
 {
  "input": "In our example you might think of this as the product that we're trying to figure out.",
  "translatedText": "У нашому прикладі ви можете подумати про це як про продукт, який ми намагаємося з’ясувати.",
  "n_reviews": 0,
  "start": 1066.7,
  "end": 1070.18
 },
 {
  "input": "Then suppose I say I'll just tell you what the outputs of this polynomial would be if you inputted various different inputs like 0, 1, 2, 3, on and on, and I give you enough so that you have as many equations as you have unknowns.",
  "translatedText": "Тоді припустімо, я кажу, що я просто скажу вам, якими були б результати цього полінома, якби ви ввели різні вхідні дані, такі як 0, 1, 2, 3, і далі, і я дам вам достатньо, щоб у вас було стільки рівнянь, скільки у вас є невідомі.",
  "n_reviews": 0,
  "start": 1070.18,
  "end": 1083.46
 },
 {
  "input": "It even happens to be a linear system of equations, so that's nice.",
  "translatedText": "Це навіть лінійна система рівнянь, так що це добре.",
  "n_reviews": 0,
  "start": 1084.14,
  "end": 1087.34
 },
 {
  "input": "And in principle at least, this should be enough to recover the coefficients.",
  "translatedText": "Принаймні в принципі цього має бути достатньо для відновлення коефіцієнтів.",
  "n_reviews": 0,
  "start": 1087.78,
  "end": 1090.9
 },
 {
  "input": "So the rough algorithm outline then would be whenever you want to convolve two lists of numbers you treat them like they're coefficients of two polynomials.",
  "translatedText": "Таким чином, приблизний нарис алгоритму буде такий: щоразу, коли ви хочете згорнути два списки чисел, ви розглядаєте їх як коефіцієнти двох поліномів.",
  "n_reviews": 0,
  "start": 1091.74,
  "end": 1099.0
 },
 {
  "input": "You sample those polynomials at enough outputs, multiply those samples point-wise, and then solve the system to recover the coefficients as a sneaky backdoor way to find the convolution.",
  "translatedText": "Ви відбираєте ці поліноми з достатньою кількістю виходів, множите ці зразки поточково, а потім розв’язуєте систему, щоб відновити коефіцієнти як прихований бекдорний спосіб знайти згортку.",
  "n_reviews": 0,
  "start": 1099.42,
  "end": 1110.56
 },
 {
  "input": "And as I've stated it so far at least, some of you could rightfully complain \"Grant, that is an idiotic plan\".",
  "translatedText": "І як я вже казав, принаймні, дехто з вас міг би справедливо скаржитися: «Гранте, це ідіотський план».",
  "n_reviews": 0,
  "start": 1111.42,
  "end": 1117.34
 },
 {
  "input": "Because for one thing just calculating all these samples for one of the polynomials we know already takes on the order of n squared operations, not to mention solving that system is certainly going to be computationally as difficult as just doing the convolution in the first place.",
  "translatedText": "Тому що, з одного боку, просто обчислення всіх цих зразків для одного з поліномів, які ми знаємо, уже займає порядок n квадратних операцій, не кажучи вже про те, що розв’язування цієї системи, безперечно, буде обчислювально таким же складним, як просто виконання згортки.",
  "n_reviews": 0,
  "start": 1117.58,
  "end": 1132.1
 },
 {
  "input": "So, like, sure we have this connection between multiplication and convolutions, but all of the complexity happens in translating from one viewpoint to the other.",
  "translatedText": "Отже, звичайно, у нас є зв’язок між множенням і згортками, але вся складність виникає при перекладі з однієї точки зору на іншу.",
  "n_reviews": 0,
  "start": 1132.6,
  "end": 1140.48
 },
 {
  "input": "But there is a trick, and those of you who know about Fourier transforms and the FFT algorithm might see where this is going.",
  "translatedText": "Але є хитрість, і ті з вас, хто знає про перетворення Фур’є та алгоритм БПФ, можуть зрозуміти, куди це йде.",
  "n_reviews": 0,
  "start": 1141.6,
  "end": 1147.74
 },
 {
  "input": "If you're unfamiliar with these topics, what I'm about to say might seem completely out of the blue.",
  "translatedText": "Якщо ви не знайомі з цими темами, те, що я збираюся сказати, може здатися абсолютно несподіваним.",
  "n_reviews": 0,
  "start": 1147.74,
  "end": 1152.18
 },
 {
  "input": "Just know that there are certain paths you could have walked in math that make this more of an expected step.",
  "translatedText": "Просто знайте, що є певні шляхи, якими ви могли б пройти в математиці, які роблять цей крок більш очікуваним.",
  "n_reviews": 0,
  "start": 1152.26,
  "end": 1156.86
 },
 {
  "input": "Basically the idea is that we have a freedom of choice here.",
  "translatedText": "В основному ідея полягає в тому, що ми маємо тут свободу вибору.",
  "n_reviews": 0,
  "start": 1157.72,
  "end": 1160.36
 },
 {
  "input": "If instead of evaluating at some arbitrary set of inputs like 0, 1, 2, 3, on and on, you choose to evaluate on a very specially selected set of complex numbers.",
  "translatedText": "Якщо замість довільного набору вхідних даних, таких як 0, 1, 2, 3, і далі, ви обираєте обчислення спеціально вибраного набору комплексних чисел.",
  "n_reviews": 0,
  "start": 1160.54,
  "end": 1169.7
 },
 {
  "input": "Specifically the ones that sit evenly spaced on the unit circle, what are known as the roots of unity.",
  "translatedText": "Зокрема ті, які рівномірно розташовані на одиничному колі, відомі як корені єдності.",
  "n_reviews": 0,
  "start": 1170.24,
  "end": 1174.84
 },
 {
  "input": "This gives us a friendlier system.",
  "translatedText": "Це дає нам більш дружню систему.",
  "n_reviews": 0,
  "start": 1175.2,
  "end": 1176.88
 },
 {
  "input": "The basic idea is that by finding a number where taking its powers falls into this cycling pattern, it means that the system we generate is going to have a lot of redundancy in the different terms that you're calculating, and by being clever about how you leverage that redundancy, you can save yourself a lot of work.",
  "translatedText": "Основна ідея полягає в тому, що, знайшовши число, у якому відбір його потужностей потрапляє в цей циклічний шаблон, це означає, що система, яку ми створюємо, матиме багато надлишкових у різних термінах, які ви обчислюєте, і якщо ми розумно розберемося, як Ви використовуєте цю надмірність, ви можете заощадити собі багато роботи.",
  "n_reviews": 0,
  "start": 1178.36,
  "end": 1194.46
 },
 {
  "input": "This set of outputs that I've written has a special name, it's called the discrete Fourier transform of the coefficients.",
  "translatedText": "Цей набір результатів, який я написав, має спеціальну назву, він називається дискретним перетворенням Фур’є коефіцієнтів.",
  "n_reviews": 0,
  "start": 1196.02,
  "end": 1202.28
 },
 {
  "input": "And if you want to learn more I actually did another lecture for that same Julia MIT class all about discrete Fourier transforms.",
  "translatedText": "І якщо ви хочете дізнатися більше, я прочитав ще одну лекцію для того самого класу Джулії в Массачусетському технологічному інституті про дискретні перетворення Фур’є.",
  "n_reviews": 0,
  "start": 1202.5,
  "end": 1209.14
 },
 {
  "input": "And there's also a really excellent video on the channel reducible talking about the fast Fourier transform, which is an algorithm for computing these more quickly.",
  "translatedText": "Також на каналі reducible є справді чудове відео, де розповідається про швидке перетворення Фур’є, яке є алгоритмом для швидшого обчислення.",
  "n_reviews": 0,
  "start": 1209.22,
  "end": 1217.12
 },
 {
  "input": "Also Veritasium recently did a really good video on FFT's, so you've got lots of options.",
  "translatedText": "Крім того, Veritasium нещодавно зняв дуже гарне відео про ШПФ, тому у вас є багато варіантів.",
  "n_reviews": 0,
  "start": 1217.48,
  "end": 1221.76
 },
 {
  "input": "And that fast algorithm really is the point for us.",
  "translatedText": "І цей швидкий алгоритм справді є головним для нас.",
  "n_reviews": 0,
  "start": 1222.26,
  "end": 1224.66
 },
 {
  "input": "Again because of all this redundancy there exists a method to go from the coefficients to all of these outputs, where instead of doing on the order of n squared operations, you do on the order of n times the log of n operations, which is much much better as you scale to big lists.",
  "translatedText": "Знову ж таки, через усю цю надлишковість існує метод переходу від коефіцієнтів до всіх цих виходів, де замість виконання операцій порядку n квадратів, ви виконуєте порядок порядку n помножених на log n операцій, що є набагато набагато краще, якщо ви масштабуєте великі списки.",
  "n_reviews": 0,
  "start": 1225.12,
  "end": 1239.2
 },
 {
  "input": "And importantly this fft algorithm goes both ways.",
  "translatedText": "І що важливо, цей алгоритм FFT працює в обох напрямках.",
  "n_reviews": 0,
  "start": 1239.66,
  "end": 1242.54
 },
 {
  "input": "It also lets you go from the outputs to the coefficients.",
  "translatedText": "Це також дозволяє переходити від результатів до коефіцієнтів.",
  "n_reviews": 0,
  "start": 1242.7,
  "end": 1245.48
 },
 {
  "input": "So bringing it all together, let's look back at our algorithm outline.",
  "translatedText": "Отже, об’єднавши все це, давайте поглянемо на схему нашого алгоритму.",
  "n_reviews": 0,
  "start": 1246.22,
  "end": 1249.06
 },
 {
  "input": "Now we can say whenever you're given two long lists of numbers and you want to take their convolution, first compute the fast Fourier transform of each one of them, which in the back of your mind you can just think of as treating them like they're the coefficients of a polynomial and evaluating it at a very specially selected set of points.",
  "translatedText": "Тепер ми можемо сказати, що коли вам дають два довгі списки чисел і ви хочете взяти їх згортку, спочатку обчисліть швидке перетворення Фур’є кожного з них, що в глибині вашої свідомості ви можете просто подумати як трактувати їх як вони є коефіцієнтами полінома та оцінюють його за дуже спеціально вибраним набором точок.",
  "n_reviews": 0,
  "start": 1249.42,
  "end": 1266.38
 },
 {
  "input": "Then multiply together the two results that you just got point-wise, which is nice and fast, and then do an inverse fast Fourier transform, and what that gives you is the sneaky backdoor way to compute the convolution that we were looking for.",
  "translatedText": "Потім помножте два результати, які ви щойно отримали, по точках, що добре та швидко, а потім виконайте зворотне швидке перетворення Фур’є, і ви отримаєте прихований бекдорний спосіб обчислення згортки, який ми шукали.",
  "n_reviews": 0,
  "start": 1266.9,
  "end": 1278.9
 },
 {
  "input": "But this time it only involves O of n log n operations.",
  "translatedText": "Але цього разу він включає лише O з n log n операцій.",
  "n_reviews": 0,
  "start": 1279.04,
  "end": 1282.24
 },
 {
  "input": "That's really cool to me!",
  "translatedText": "Для мене це дуже круто!",
  "n_reviews": 0,
  "start": 1283.14,
  "end": 1284.74
 },
 {
  "input": "This very specific context where convolutions show up, multiplying two polynomials, opens the doors for an algorithm that's relevant everywhere else where convolutions might come up.",
  "translatedText": "Цей дуже специфічний контекст, де згортки з’являються, множачи два поліноми, відкриває двері для алгоритму, який актуальний скрізь, де можуть з’являтися згортки.",
  "n_reviews": 0,
  "start": 1285.12,
  "end": 1294.1
 },
 {
  "input": "If you want to add probability distributions, do some large image processing, whatever it might be.",
  "translatedText": "Якщо ви хочете додати розподіли ймовірностей, виконайте велику обробку зображень, якою б вона не була.",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1299.0
 },
 {
  "input": "And I just think that's such a good example of why you should be excited when you see some operation or concept in math show up in a lot of seemingly unrelated areas.",
  "translatedText": "І я вважаю, що це такий гарний приклад того, чому ви повинні радіти, коли бачите, що якась операція чи концепція в математиці з’являється в багатьох, здавалося б, непов’язаних областях.",
  "n_reviews": 0,
  "start": 1299.22,
  "end": 1307.48
 },
 {
  "input": "If you want a little homework here's something that's fun to think about.",
  "translatedText": "Якщо ви хочете трохи домашнього завдання, ось щось, про що цікаво подумати.",
  "n_reviews": 0,
  "start": 1308.48,
  "end": 1311.5
 },
 {
  "input": "Explain why when you multiply two different numbers, just ordinary multiplication the way we all learn in elementary school, what you're doing is basically a convolution between the digits of those numbers.",
  "translatedText": "Поясніть, чому коли ви множите два різні числа, просто звичайне множення, як ми всі вчимося в початковій школі, те, що ви робите, є згорткою між цифрами цих чисел.",
  "n_reviews": 0,
  "start": 1311.72,
  "end": 1321.98
 },
 {
  "input": "There are some added steps with carries and the like, but the core step is a convolution.",
  "translatedText": "Є деякі додаткові кроки з переносом тощо, але основним кроком є згортка.",
  "n_reviews": 0,
  "start": 1322.5,
  "end": 1326.46
 },
 {
  "input": "In light of the existence of a fast algorithm, what that means is if you have two very large integers, then there exists a way to find their product that's faster than the method we learn in elementary school.",
  "translatedText": "У світлі існування швидкого алгоритму це означає, що якщо у вас є два дуже великі цілі числа, то існує спосіб знайти їхній продукт, який є швидшим, ніж метод, який ми вивчаємо в початковій школі.",
  "n_reviews": 0,
  "start": 1327.28,
  "end": 1337.88
 },
 {
  "input": "That instead of requiring O of n squared operations only requires O of n log n, which doesn't even feel like it should be possible.",
  "translatedText": "Що замість O з n квадратичних операцій вимагає лише O з n log n, що навіть не здається можливим.",
  "n_reviews": 0,
  "start": 1338.14,
  "end": 1344.92
 },
 {
  "input": "The catch is that before this is actually useful in practice, your numbers would have to be absolutely monstrous.",
  "translatedText": "Заковика в тому, що перш ніж це дійсно стане корисним на практиці, ваші цифри повинні бути абсолютно жахливими.",
  "n_reviews": 0,
  "start": 1345.38,
  "end": 1350.84
 },
 {
  "input": "But still, it's cool that such an algorithm exists.",
  "translatedText": "Але все одно круто, що такий алгоритм існує.",
  "n_reviews": 0,
  "start": 1351.22,
  "end": 1353.86
 },
 {
  "input": "Next up we'll turn our attention to the continuous case with a special focus on probability distributions.",
  "translatedText": "Далі ми звернемо нашу увагу на неперервний випадок з особливим акцентом на розподілі ймовірностей.",
  "n_reviews": 0,
  "start": 1355.16,
  "end": 1359.64
 }
]