[
 {
  "input": "Suppose I give you two different lists of numbers, or maybe two different functions, and I ask you to think of all the ways you might combine those two lists to get a new list of numbers, or combine the two functions to get a new function. ",
  "translatedText": "假设我给你两个不同的数字列表，或者可能是两个不同的函数，并且 我要求你思考可以组合这两个列表以获得新的数字列表，或者组合 这两个函数以获得新函数的所有方法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 11.32
 },
 {
  "input": "Maybe one simple way that comes to mind is to simply add them together term by term. ",
  "translatedText": "也许想到的一种简单方法就是 简单地将它们逐个添加在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.12,
  "end": 16.76
 },
 {
  "input": "Likewise with the functions, you can add all the corresponding outputs. ",
  "translatedText": "与功能类似，您可以添加所有 相应的输出。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 17.16,
  "end": 19.92
 },
 {
  "input": "In a similar vein, you could also multiply the two lists term by term and do the same thing with the functions. ",
  "translatedText": "同样，您也可以将两个列表逐项相乘，并 对函数执行相同的操作。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.54,
  "end": 25.68
 },
 {
  "input": "But there's another kind of combination just as fundamental as both of those, but a lot less commonly discussed, known as a convolution. ",
  "translatedText": "但还有另一种组合与这两 种组合一样基本，但很少被讨论，称为卷积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.36,
  "end": 33.5
 },
 {
  "input": "But unlike the previous two cases, it's not something that's merely inherited from an operation you can do to numbers. ",
  "translatedText": "但与前两种情况不同的是，它不仅仅是从对数字执行 的操作继承的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.08,
  "end": 39.82
 },
 {
  "input": "It's something genuinely new for the context of lists of numbers or combining functions. ",
  "translatedText": "对于数字列表或组合函数的上下文来说，这是真 正的新事物。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.98,
  "end": 44.7
 },
 {
  "input": "They show up all over the place, they are ubiquitous in image processing, it's a core construct in the theory of probability, they're used a lot in solving differential equations, and one context where you've almost certainly seen it, if not by this name, is multiplying two polynomials together. ",
  "translatedText": "它们无处不在，它们在图像处理中无处不在，它 是概率论的核心构造，它们在求解微分方程中被大量使用，并 且您几乎肯定在其中见过它（如果没有的话）顾名思义，就 是将两个多项式相乘。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 45.32,
  "end": 60.24
 },
 {
  "input": "As someone in the business of visual explanations, this is an especially great topic, because the formulaic definition in isolation and without context can look kind of intimidating, but if we take the time to really unpack what it's saying, and before that actually motivate why you would want something like this, it's an incredibly beautiful operation. ",
  "translatedText": "作为从事视觉解释行业的人，这是一个特别 好的主题，因为孤立且没有上下文的公式化定义可能看起来有点令 人生畏，但如果我们花时间真正解开它所说的内容，并在此之前真 正激发为什么你会想要这样的东西，这是一个非常漂亮的操作。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 60.74,
  "end": 78.32
 },
 {
  "input": "And I have to admit, I actually learned a little something while putting together the visuals for this project. ",
  "translatedText": "我必须承认，在为这个项目制作视觉效果时，我实际上学到了一些 东西。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.96,
  "end": 83.54
 },
 {
  "input": "In the case of convolving two different functions, I was trying to think of different ways you might picture what that could mean, and with one of them I had a little bit of an aha moment for why it is that normal distributions play the role that they do in probability, why it's such a natural shape for a function. ",
  "translatedText": "在卷积两个不同函数的情况下，我试图想出不同的方 式来描述这可能意味着什么，对于其中一个，我有点恍然大 悟，为什么正态分布起着这样的作用：它们以概率的形式出 现，为什么它是函数的自然形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 83.54,
  "end": 98.52
 },
 {
  "input": "But I'm getting ahead of myself, there's a lot of setup for that one. ",
  "translatedText": "但我有点超前了，有 很多设置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.02,
  "end": 101.52
 },
 {
  "input": "In this video, our primary focus is just going to be on the discrete case, and in particular building up to a very unexpected but very clever algorithm for computing these. ",
  "translatedText": "在本视频中，我们的主要重点将放在离散情况上 ，特别是构建一个非常出乎意料但非常聪明的算法来计算这些情况 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 101.84,
  "end": 110.26
 },
 {
  "input": "And I'll pull out the discussion for the continuous case into a second part. ",
  "translatedText": "我将对连续案例的讨论拉到第二部分。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.26,
  "end": 114.48
 },
 {
  "input": "It's very tempting to open up with the image processing examples, since they're visually the most intriguing, but there are a couple bits of finickiness that make the image processing case less representative of convolutions overall, so instead let's kick things off with probability, and in particular one of the simplest examples that I'm sure everyone here has thought about at some point in their life, which is rolling a pair of dice and figuring out the chances of seeing various different sums. ",
  "translatedText": "很容易打开图像处理示例，因为它们在视觉上是最有趣的 ，但是有一些挑剔之处使得图像处理案例不太能代表卷 积的整体情况，所以让我们从概率开始，特别是最简单的 例子之一，我相信这里的每个人都在他们生活中的某个 时刻考虑过，那就是掷一对骰子并计算出看到各种不同总 和的机会。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.58,
  "end": 141.5
 },
 {
  "input": "And you might say, not a problem, not a problem. ",
  "translatedText": "你可能会说，不是问题，不是问题。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.46,
  "end": 144.46
 },
 {
  "input": "Each of your two dice has six different possible outcomes, which gives us a total of 36 distinct possible pairs of outcomes, and if we just look through them all we can count up how many pairs have a given sum. ",
  "translatedText": "两个骰子中的每一个 都有 6 种不同的可能结果，这给了我们总共 36 种不同的可能结 果对，如果我们只查看它们，我们可以计算出有多少对具有给定的总和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.68,
  "end": 155.86
 },
 {
  "input": "And arranging all the pairs in a grid like this, one pretty nice thing is that all of the pairs that have a constant sum are visible along one of these different diagonals. ",
  "translatedText": "将所有对排列在这样的网格中，一件非常好的事情是，所有具有恒 定总和的对都沿着这些不同的对角线之一可见。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.6,
  "end": 165.44
 },
 {
  "input": "So simply counting how many exist on each of those diagonals will tell you how likely you are to see a particular sum. ",
  "translatedText": "因此，只需计算每 个对角线上有多少个就可以告诉您看到特定总和的可能性有多大。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.44,
  "end": 172.12
 },
 {
  "input": "And I'd say, very good, very good, but can you think of any other ways that you might visualize the same question? ",
  "translatedText": "我想说，非常好，非常好，但是您能想到任何其他方式来形象化同 一问题吗？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.22,
  "end": 178.66
 },
 {
  "input": "Other images that can come to mind to think of all the distinct pairs that have a given sum? ",
  "translatedText": "可以想到其他图像来思考具有给定总和的所有不同对 吗？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.3,
  "end": 184.06
 },
 {
  "input": "And maybe one of you raises your hand and says, yeah, I've got one. ",
  "translatedText": "也许你们中的一个人举起手说，是的，我有一个。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 184.86,
  "end": 187.98
 },
 {
  "input": "Let's say you picture these two different sets of possibilities each in a row, but you flip around that second row. ",
  "translatedText": "假设您连续想 象这两组不同的可能性，但您翻转了第二行。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 188.28,
  "end": 193.76
 },
 {
  "input": "That way all of the different pairs which add up to seven line up vertically like this. ",
  "translatedText": "这样， 所有不同的对加起来就是七对，像这样垂直排列。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.76,
  "end": 198.76
 },
 {
  "input": "And if we slide that bottom row all the way to the right, then the unique pair that adds up to two, the snake eyes, are the only ones that align. ",
  "translatedText": "如果我们将底 行一直滑动到右侧，那么加起来为两个的独特的一对，即蛇眼 ，是唯一对齐的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.36,
  "end": 206.28
 },
 {
  "input": "And if I schlunk that over one unit to the right, the pairs which align are the two different pairs that add up to three. ",
  "translatedText": "如果我将其放在右侧的一个单位上，则对齐的 对是两对不同的，加起来为三对。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.62,
  "end": 212.08
 },
 {
  "input": "And in general, different offset values of this lower array, which remember I had to flip around first, reveal all the distinct pairs that have a given sum. ",
  "translatedText": "一般来说，这个较低数组的 不同偏移值（记住我必须首先翻转）显示具有给定总和的所有 不同对。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.88,
  "end": 221.46
 },
 {
  "input": "As far as probability questions go, this still isn't especially interesting, because all we're doing is counting how many outcomes there are in each of these categories. ",
  "translatedText": "就概率问题而言，这仍然不是特别有趣，因 为我们所做的只是计算每个类别中有多少个结果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.82,
  "end": 232.64
 },
 {
  "input": "But that is with the implicit assumption that there's an equal chance for each of these faces to come up. ",
  "translatedText": "但这是基于一个隐含的假设，即这些面孔出现的机会均 等。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.12
 },
 {
  "input": "But what if I told you I have a special set of dice that's not uniform? ",
  "translatedText": "但如果我告诉你我有一套不统一的特殊骰子怎么办？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.36,
  "end": 241.62
 },
 {
  "input": "Maybe the blue die has its own set of numbers describing the probabilities for each face coming up, and the red die has its own unique distinct set of numbers. ",
  "translatedText": "也许 蓝色骰子有自己的一组数字来描述每张面出现的概率，而红 色骰子有自己独特的一组数字。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 242.06,
  "end": 249.76
 },
 {
  "input": "In that case, if you wanted to figure out, say, the probability of seeing a two, you would multiply the probability that the blue die is a one times the probability that the red die is a one. ",
  "translatedText": "在这种情况下，如果您想计 算出看到 2 的概率，您可以将蓝色骰子为 1 的概率 乘以红色骰子为 1 的概率。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.3,
  "end": 259.86
 },
 {
  "input": "And for the chances of seeing a three, you look at the two distinct pairs where that's possible, and again, multiply the corresponding probabilities, and then add those two products together. ",
  "translatedText": "对于看到 3 的机会，您可 以在可能的情况下查看两个不同的对，然后再次乘以相应的概 率，然后将这两个乘积加在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 260.28,
  "end": 269.68
 },
 {
  "input": "Similarly, the chances of seeing a four involves multiplying together three different pairs of possibilities and adding them all together. ",
  "translatedText": "类似地，看到四的机会 涉及将三对不同的可能性相乘并将它们全部加在一起 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 270.1,
  "end": 276.82
 },
 {
  "input": "And in the spirit of setting up some formulas, let's name these top probabilities a1, a2, a3, and so on, and name the bottom ones b1, b2, b3, and so on. ",
  "translatedText": "本着建立一些公式的精神，让我们将这些最高概率命名为 a1、a2、a3 等，并将最低概率命名为 b1、b2、b3 等。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.82,
  "end": 285.96
 },
 {
  "input": "And in general, this process, where we're taking two different arrays of numbers, flipping the second one around, and then lining them up at various different offset values, taking a bunch of pairwise products and adding them up, that's one of the fundamental ways to think about what a convolution is. ",
  "translatedText": "一般来说，在这个过 程中，我们获取两个不同的数字数组，翻转第二个数组，然 后将它们排列在各种不同的偏移值处，获取一堆成对的乘积并 将它们相加，这就是其中之一思考什么是卷积的基本方法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.4,
  "end": 301.62
 },
 {
  "input": "So just to spell it out a little more exactly, through this process, we just generated probabilities for seeing two, three, four, on and on up to 12, and we got them by mixing together one list of values, a, and another list of values, b. ",
  "translatedText": "因此，为了更准确地说明这一点，通过这个过程，我们只是生成了看到两个、三 个、四个、一直到 12 的概率，并且我们通过将一个值列表 a 和另一 个值混合在一起来获得它们值列表，b。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.86,
  "end": 316.98
 },
 {
  "input": "In the lingo, we'd say the convolution of those two sequences gives us this new sequence, the new sequence of 11 values, each of which looks like some sum of pairwise products. ",
  "translatedText": "用行话来说，我们会说这两个序列 的卷积给出了这个新序列，即 11 个值的新序列，每个值看起来都 像是成对乘积的总和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.44,
  "end": 327.34
 },
 {
  "input": "If you prefer, another way you could think about the same operation is to first create a table of all the pairwise products, and then add up along all these diagonals. ",
  "translatedText": "如果您愿意，您可以考虑相同操作的另一种 方法是首先创建所有成对产品的表，然后沿着所有这些对角线相 加。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.34,
  "end": 336.98
 },
 {
  "input": "Again, that's a way of mixing together these two sequences of numbers to get us a new sequence of 11 numbers. ",
  "translatedText": "同样，这是一种将这两个数字序列混合在一起以获得 11 个数字的 新序列的方法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 337.46,
  "end": 342.76
 },
 {
  "input": "It's the same operation as the sliding windows thought, just another perspective. ",
  "translatedText": "和滑动窗想的操作是一样的，只是换个角度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 343.24,
  "end": 346.46
 },
 {
  "input": "Putting a little notation to it, here's how you might see it written down. ",
  "translatedText": "对其进行一些注释，您可能会看到这样的写法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.14,
  "end": 349.8
 },
 {
  "input": "The convolution of a and b, denoted with this little asterisk, is a new list, and the nth element of that list looks like a sum, and that sum goes over all different pairs of indices, i and j, so that the sum of those indices is equal to n. ",
  "translatedText": "a 和 b 的卷 积（用这个小星号表示）是一个新列表，该列表的第 n 个元素看起 来像一个和，并且该和遍历所有不同的索引对 i 和 j，因此这些索 引等于 n。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 350.22,
  "end": 364.86
 },
 {
  "input": "It's kind of a mouthful, but for example, if n was 6, the pairs we're going over are 1 and 5, 2 and 4, 3 and 3, 4 and 2, 5 and 1, all the different pairs that add up to 6. ",
  "translatedText": "这有点拗口，但是例如，如果 n 是 6，我们要检查的对是 1 和 5、2 和 4、3 和 3、4 和 2、5 和 1，所有不同的对加起来至 6。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.28,
  "end": 375.8
 },
 {
  "input": "But honestly, however you write it down, the notation is secondary in importance to the visual you might hold in your head for the process. ",
  "translatedText": "但老实说，无论你怎么写，符号的重要性都比你头脑中 的视觉效果要重要。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 376.62,
  "end": 382.34
 },
 {
  "input": "Here, maybe it helps to do a super simple example, where I might ask you what's the convolution of the list 1, 2, 3, with the list 4, 5, 6. ",
  "translatedText": "在这里，也许做一个超级简单的例子会有所帮助，我可 能会问你列表 1, 2, 3 与列表 4, 5, 6 的卷积是多少。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.28,
  "end": 390.78
 },
 {
  "input": "You might picture taking both of these lists, flipping around that second one, and then starting with its lid all the way over to the left. ",
  "translatedText": "您可能会想 象将这两个列表都拿出来，翻转第二个列表，然后从其盖子开 始一直向左移动。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.48,
  "end": 397.68
 },
 {
  "input": "Then the pair of values which align are 1 and 4, multiply them together, and that gives us our first term of our output. ",
  "translatedText": "然后对齐的一对值是 1 和 4，将它们 相乘，这就是我们输出的第一项。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.18,
  "end": 403.54
 },
 {
  "input": "Slide that bottom array one unit to the right, the pairs which align are 1 and 5, and 2 and 4, multiply those pairs, add them together, and that gives us 13, the next entry in our output. ",
  "translatedText": "将底部数组向右滑动一个单位，对 齐的对是 1 和 5、2 和 4，将这些对相乘，将它们加在一起，得到 13，即输出中的下一个条目。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.96,
  "end": 414.46
 },
 {
  "input": "Slide things over once more, and we'll take 1 times 6, plus 2 times 5, plus 3 times 4, which happens to be 28. ",
  "translatedText": "再把东西滑过来，我们需要 1 乘以 6，加上 2 乘以 5，再加上 3 乘以 4，正好是 28。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.96,
  "end": 421.56
 },
 {
  "input": "One more slide, and we get 2 times 6, plus 3 times 5, and that gives us 27, and finally the last term will look like 3 times 6. ",
  "translatedText": "再一张幻灯片，我们得到 2 乘 以 6，加上 3 乘以 5，得到 27，最后一项看起来像 3 乘以 6。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.02,
  "end": 430.12
 },
 {
  "input": "If you'd like, you can pull up whatever your favorite programming language is, and your favorite library that includes various numerical operations, and you can confirm I'm not lying to you. ",
  "translatedText": "如果您愿意，您可以调出您最喜欢的编程语言，以及您最喜 欢的包含各种数值运算的库，并且您可以确认我没有骗您。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.66,
  "end": 438.98
 },
 {
  "input": "If you take the convolution of 1, 2, 3, against 4, 5, 6, this is indeed the result that you'll get. ",
  "translatedText": "如果将 1、2、3 与 4、5、6 进行卷积，这确实是您将得到的结果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.98,
  "end": 444.48
 },
 {
  "input": "We've seen one case where this is a natural and desirable operation, adding up to probability distributions, and another common example would be a moving average. ",
  "translatedText": "我们已经见过一种情况，这是一种自然且理想的操作，加起来就是概 率分布，另一个常见的例子是移动平均线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.92,
  "end": 453.66
 },
 {
  "input": "Imagine you have some long list of numbers, and you take another smaller list of numbers that all add up to 1. ",
  "translatedText": "想象一下，您有一个很长的数字 列表，然后您又取了另一个较小的数字列表，这些数字的总和为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.08,
  "end": 459.76
 },
 {
  "input": "In this case, I just have a little list of 5 values, and they're all equal to 1 5th. ",
  "translatedText": "在本例中，我只有一 个包含 5 个值的小列表，它们都等于 1 5th。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.1,
  "end": 464.06
 },
 {
  "input": "Then if we do this sliding window convolution process, and kind of close our eyes and sweep under the rug what happens at the very beginning of it, once our smaller list of values entirely overlaps with the bigger one, think about what each term in this convolution really means. ",
  "translatedText": "然后，如果我们进行这 个滑动窗口卷积过程，然后闭上眼睛，扫视一开始发生的情 况，一旦我们较小的值列表与较大的值列表完全重叠，请考 虑其中的每一项卷积的真正含义是。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.06,
  "end": 478.7
 },
 {
  "input": "At each iteration, what you're doing is multiplying each of the values from your data by 1 5th, and adding them all together, which is to say you're taking an average of your data inside this little window. ",
  "translatedText": "在每次迭代中，您所做的是 将数据中的每个值乘以 1 五分之一，然后将它们全部加在一起 ，也就是说，您在这个小窗口内取数据的平均值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.4,
  "end": 490.52
 },
 {
  "input": "Overall, the process gives you a smoothed out version of the original data, and you could modify this starting with a different little list of numbers, and as long as that little list all adds up to 1, you can still interpret it as a moving average. ",
  "translatedText": "总体而言，该过 程为您提供了原始数据的平滑版本，您可以从不同的小数字列 表开始修改它，只要该小列表加起来为 1，您仍然可以将其 解释为移动平均的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.1,
  "end": 502.72
 },
 {
  "input": "In the example shown here, that moving average would be giving more weight towards the central value. ",
  "translatedText": "在此所示的示例中，移动平均线将给予 中心值更多的权重。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 503.4,
  "end": 507.76
 },
 {
  "input": "This also results in a smoothed out version of the data. ",
  "translatedText": "这也会产生数据的平滑版本。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.42,
  "end": 510.8
 },
 {
  "input": "If you do kind of a two-dimensional analog of this, it gives you a fun algorithm for blurring a given image. ",
  "translatedText": "如果你对此进行二维模拟，它会给你一个有趣的算法来模糊给定 的图像。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.14,
  "end": 518.72
 },
 {
  "input": "And I should say the animations I'm about to show are modified from something I originally made for part of a set of lectures I did with the Julia Lab at MIT for a certain OpenCourseWare class that included an image processing unit. ",
  "translatedText": "我应该说，我即将展示的动画是根据我最初为我与麻省理工学院的 Jul ia 实验室一起为某个包含图像处理单元的 OpenCourseWare 课 程所做的一组讲座的一部分而制作的动画进行了修改。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.72,
  "end": 531.08
 },
 {
  "input": "There we did a little bit more to dive into the code behind all of this, so if you're curious I'll leave you some links. ",
  "translatedText": "在那里，我们做了更多的工作 来深入研究所有这些背后的代码，所以如果您好奇，我会给您留下一些链接。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.56,
  "end": 536.28
 },
 {
  "input": "But focusing back on this blurring example, what's going on is I've got this little 3x3 grid of values that's marching along our original image, and if we zoom in, each one of those values is 1 9th, and what I'm doing at each iteration is multiplying each of those values by the corresponding pixel that it sits on top of. ",
  "translatedText": "但回 到这个模糊的例子，发生的事情是我得到了这个小的 3x3 值网格，它沿着我们的原始图像行进，如果我们放大，这些值中的 每一个都是 1 9th，而我正在做的在每次迭代中，将每个 值乘以它所在的相应像素。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.62,
  "end": 553.62
 },
 {
  "input": "And of course in computer science we think of colors as little vectors of three values, representing the red, green, and blue components. ",
  "translatedText": "当然，在计算机科学中，我们将 颜色视为三个值的小向量，代表红色、绿色和蓝色分量。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.9,
  "end": 560.2
 },
 {
  "input": "When I multiply all these little values by 1 9th and I add them together, it gives us an average along each color channel, and the corresponding pixel for the image on the right is defined to be that sum. ",
  "translatedText": "当我将所有这些小值乘以 1 9 并将它们加在一起时，它会给 出每个颜色通道的平均值，并且右侧图像的相应像素被定义为该总 和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.56,
  "end": 571.2
 },
 {
  "input": "The overall effect, as we do this for every single pixel on the image, is that each one kind of bleeds into all of its neighbors, which gives us a blurrier version than the original. ",
  "translatedText": "当我们对图像上的每个像素执行此操作时，总体效果是每种像素都 会渗透到其所有邻居中，这给我们提供了比原始版本更模糊的版本。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.94,
  "end": 580.86
 },
 {
  "input": "In the lingo we'd say that the image on the right is a convolution of our original image with a little grid of values. ",
  "translatedText": "用行话来说，我们会说右侧的图像是原始图像与一些值网 格的卷积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 581.72,
  "end": 587.74
 },
 {
  "input": "Or more technically maybe I should say that it's the convolution with a 180 degree rotated version of that little grid of values. ",
  "translatedText": "或者从技术上讲，也许我应该说它是与那个小值网 格的 180 度旋转版本的卷积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.14,
  "end": 594.4
 },
 {
  "input": "Not that it matters when the grid is symmetric, but it's just worth keeping in mind that the definition of a convolution, as inherited from the pure math context, should always invite you to think about flipping around that second array. ",
  "translatedText": "当网格对称时并不重 要，但值得记住的是，从纯数学上下文继承的卷 积定义应该始终邀请您考虑翻转第二个数组。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.62,
  "end": 605.24
 },
 {
  "input": "If we modify this slightly we can get a much more elegant blurring effect by choosing a different grid of values. ",
  "translatedText": "如果我们稍微修改一下，我们可以通过选择不同的值网格来获得更优雅的模 糊效果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 605.96,
  "end": 611.1
 },
 {
  "input": "In this case I have a little 5x5 grid, but the distinction is not so much its size. ",
  "translatedText": "在本例中，我有一个 5x5 的小网格，但区别并不在于它的大小。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.44,
  "end": 615.78
 },
 {
  "input": "If we zoom in we notice that the value in the middle is a lot bigger than the value towards the edges, and where this is coming from is they're all sampled from a bell curve, known as a Gaussian distribution. ",
  "translatedText": "如果我们放大，我们会注意到中间的值比边缘的值大得多 ，这是因为它们都是从钟形曲线（称为高斯分布）中采 样的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.98,
  "end": 625.94
 },
 {
  "input": "That way when we multiply all of these values by the corresponding pixel that they're sitting on top of, we're giving a lot more weight to that central pixel and much less towards the ones out at the edge. ",
  "translatedText": "这样，当我们将所有这些值乘以它们所在的相应像素 时，我们就会为中心像素赋予更多权重，而为边缘像素赋 予更少权重。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 626.8,
  "end": 636.38
 },
 {
  "input": "And just as before the corresponding pixel on the right is defined to be this sum. ",
  "translatedText": "正如之前一样，右侧对应的像素被定义为这个总 和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.8,
  "end": 640.56
 },
 {
  "input": "As we do this process for every single pixel it gives a blurring effect which much more authentically simulates the notion of putting your lens out of focus or something like that. ",
  "translatedText": "当我们对每个像素执行此过程时，它会产生模糊 效果，更真实地模拟镜头失焦或类似情况的概念。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.32,
  "end": 649.72
 },
 {
  "input": "But blurring is far from the only thing that you can do with this idea. ",
  "translatedText": "但模糊远不是你可以用这个想法做的唯一事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.36
 },
 {
  "input": "For instance take a look at this little grid of values, which involves some positive numbers on the left and some negative numbers on the right, which I'll color with blue and red respectively. ",
  "translatedText": "例如，看一下这 个小值网格，其中左侧有一些正数，右侧有一些负 数，我将分别用蓝色和红色着色。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.8,
  "end": 662.9
 },
 {
  "input": "Take a moment to see if you can predict and understand what effect this will have on the final image. ",
  "translatedText": "花点时间看看您是否 可以预测并理解这将对最终图像产生什么影响。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.64,
  "end": 668.48
 },
 {
  "input": "So in this case I'll just be thinking of the image as grayscale instead of colored, so each of the pixels is just represented by one number instead of three. ",
  "translatedText": "因此，在这种情况下 ，我只会将图像视为灰度而不是彩色，因此每个像素仅由一个数字而 不是三个数字表示。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.72,
  "end": 678.12
 },
 {
  "input": "And one thing worth noticing is that as we do this convolution it's possible to get negative values. ",
  "translatedText": "值得注意的一件事是，当我们进行卷积时 ，可能会得到负值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 678.44,
  "end": 683.06
 },
 {
  "input": "For example at this point here if we zoom in the left half of our little grid sits entirely on top of black pixels, which would have a value of zero, but the right half of negative values all sit on top of white pixels, which would have a value of one. ",
  "translatedText": "例如，此时，如果我们放大小网格的 左半部分，则完全位于黑色像素的顶部，其值为零，但负 值的右半部分全部位于白色像素的顶部，这将值为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.06,
  "end": 695.46
 },
 {
  "input": "So when we multiply corresponding terms and add them together the results will be very negative, and the way I'm displaying this with the image on the right is to color negative values red and positive values blue. ",
  "translatedText": "因此，当我们将相应项相乘并将它们加在一起时，结果将非常负 ，而我用右侧图像显示此结果的方式是将负值涂成红色，将正值 涂成蓝色。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 696.18,
  "end": 706.36
 },
 {
  "input": "Another thing to notice is that when you're on a patch that's all the same color everything goes to zero since the sum of the values in our little grid is zero. ",
  "translatedText": "另一件需要注意的事情是，当你在一个颜色相同的补丁上时， 所有的东西都会变为零，因为我们的小网格中的值的总和为零。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 714.08
 },
 {
  "input": "This is very different from the previous two examples where the sum of our little grid was one, which let us interpret it as a moving average and hence a blur. ",
  "translatedText": "这与前两个 示例非常不同，前两个示例中我们的小网格的总和为 1，这让我们将 其解释为移动平均值，因此是模糊的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 715.18,
  "end": 722.18
 },
 {
  "input": "All in all this little process basically detects wherever there's variation in the pixel value as you move from left to right, and so it gives you a kind of way to pick up on all the vertical edges from your image. ",
  "translatedText": "总而言之，这个小过程基本 上可以检测当您从左向右移动时像素值存在变化的地方，因 此它为您提供了一种从图像中拾取所有垂直边缘的方法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.64,
  "end": 733.92
 },
 {
  "input": "And similarly if we rotated that grid around so that it varies as you move from the top to the bottom this will be picking up on all the horizontal edges, which in the case of our little pie creature image does result in some pretty demonic eyes. ",
  "translatedText": "同样，如果我们旋转该网格，使其随着您从顶部移动到底部而变 化，这将在所有水平边缘上出现，在我们的小馅饼生物图像的情 况下，这确实会导致一些漂亮的恶魔眼睛。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 736.5,
  "end": 749.34
 },
 {
  "input": "This smaller grid by the way is often called a kernel, and the beauty here is how just by choosing a different kernel you can get different image processing effects, not just blurring your edge detection but also things like sharpening. ",
  "translatedText": "顺便说一句，这个较 小的网格通常称为内核，这里的美妙之处在于，通过选择不同的内核，您 可以获得不同的图像处理效果，不仅模糊边缘检测，还可以实现锐化等 效果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 750.4,
  "end": 760.84
 },
 {
  "input": "For those of you who have heard of a convolutional neural network the idea there is to use data to figure out what the kernels should be in the first place as determined by whatever the neural network wants to detect. ",
  "translatedText": "对于那些听说过卷积神经网络的人来说，其想法是 使用数据来确定内核首先应该是什么，这取决于神经网络 想要检测的内容。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 760.84,
  "end": 771.48
 },
 {
  "input": "Another thing I should maybe bring up is the length of the output. ",
  "translatedText": "我应该提出的另一件事是输出的长度 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 772.76,
  "end": 775.52
 },
 {
  "input": "For something like the moving average example you might only want to think about the terms when both of the windows fully align with each other, or in the image processing example maybe you want the final output to have the same size as the original. ",
  "translatedText": "对于像移动平均这样的示例，您可能只想考虑两个窗口 彼此完全对齐时的术语，或者在图像处理示例中，您可能希 望最终输出具有与原始大小相同的大小。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 775.82,
  "end": 787.28
 },
 {
  "input": "Now convolutions as a pure math operation always produce an array that's bigger than the two arrays that you started with, at least assuming one of them doesn't have a length of one. ",
  "translatedText": "现在，卷积作为一 种纯数学运算总是会产生一个比您开始使用的两个数组更大的数组 ，至少假设其中一个数组的长度不为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.28,
  "end": 796.18
 },
 {
  "input": "Just know that in certain computer science contexts you often want to deliberately truncate that output. ",
  "translatedText": "只需知道，在某些 计算机科学环境中，您经常想要故意截断该输出。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.72,
  "end": 801.52
 },
 {
  "input": "Another thing worth highlighting is that in the computer science context this notion of flipping around that kernel before you let it march across the original often feels really weird and just uncalled for, but again note that that's what's inherited from the pure math context where like we saw with the probabilities it's an incredibly natural thing to do. ",
  "translatedText": "另一件值得强调的事情是，在计算机科学背景下，在让它跨越 原始内核之前翻转该内核的概念通常感觉非常奇怪并且没有必 要，但再次注意，这是从纯数学背景继承的，就像我们一样从 可能性来看，这是一件非常自然的事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 804.72,
  "end": 822.44
 },
 {
  "input": "And actually I can show you one more pure math example where even the programmers should care about this one because it opens the doors for a much faster algorithm to compute all of these. ",
  "translatedText": "实际上，我可以向您 展示另一个纯数学示例，即使是程序员也应该关心这个示例，因 为它为更快的算法来计算所有这些打开了大门。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 823.02,
  "end": 832.02
 },
 {
  "input": "To set up what I mean by faster here let me go back and pull up some python again and I'm going to create two different relatively big arrays. ",
  "translatedText": "为了设置我所说的更 快的意思，让我返回并再次拉起一些 python，我将创建两个不同的相 对较大的数组。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.62,
  "end": 839.78
 },
 {
  "input": "Each one will have a hundred thousand random elements in it and I'm going to assess the runtime of the convolve function from the numpy library. ",
  "translatedText": "每个都有十万个随机元素，我将评估 numpy 库中卷积函数的运行时间。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.94,
  "end": 847.54
 },
 {
  "input": "And in this case it runs it for multiple different iterations, tries to find an average, and it looks like on this computer at least it averages at 4.87 seconds. ",
  "translatedText": "在本例中， 它运行多次不同的迭代，尝试找到平均值，在这台计算机上 看起来至少平均值为 4。87秒。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 848.18,
  "end": 856.52
 },
 {
  "input": "By contrast if I use a different function from the scipy library called fftconvolve which is the same thing just implemented differently that only takes 4.3 milliseconds on average, so three orders of magnitude improvement. ",
  "translatedText": "相比之下，如果我使用 scipy 库中名为 fftconvolve 的不同函数，它是相同的函数，只是实现方式不同 ，只需要 4 个函数。平均为 3 毫秒，提高了三个数量级。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 856.96,
  "end": 870.16
 },
 {
  "input": "And again even though it flies under a different name it's giving the same output that the other convolve function does, it's just doing something to go about it in a cleverer way. ",
  "translatedText": "同样，即使它以不同的名称运行，它也提供与其他卷积 函数相同的输出，它只是以更聪明的方式做一些事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.16,
  "end": 879.12
 },
 {
  "input": "Remember how with the probability example I said another way you could think about the convolution was to create this table of all the pairwise products and then add up those pairwise products along the diagonals. ",
  "translatedText": "还记得我在概率示例中说过的另一种思考卷积的方法是 创建所有成对乘积的表，然后沿对角线将这些成对乘 积相加。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.2,
  "end": 892.68
 },
 {
  "input": "There's of course nothing specific to probability anytime you're convolving two different lists of numbers you can think about it this way. ",
  "translatedText": "当然，当你将两个不同的数字列表进行卷积时，概 率没有什么特定的，你可以这样思考。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.66,
  "end": 899.04
 },
 {
  "input": "Create this kind of multiplication table with all pairwise products and then each sum along the diagonal corresponds to one of your final outputs. ",
  "translatedText": "使用所有成对乘积创建 这种乘法表，然后沿对角线的每个和对应于您的最终输出 之一。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 899.04,
  "end": 906.46
 },
 {
  "input": "One context where this view is especially natural is when you multiply together two polynomials. ",
  "translatedText": "这种观点特别自然的一种情况是当您将两个多项式 相乘时。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 912.8
 },
 {
  "input": "For example let me take the little grid we already have and replace the top terms with 1, 2x, and 3x squared and replace the other terms with 4, 5x, and 6x squared. ",
  "translatedText": "例如，让我使用已有的小网格，将顶部项替换为 1、2x 和 3x 平方，并将其他项替换为 4、5x 和 6x 平方。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 913.3,
  "end": 923.6
 },
 {
  "input": "Now think about what it means when we're creating all of these different pairwise products between the two lists. ",
  "translatedText": "现在考虑一下当我们在两个列表之间创建所有这些不同的成对乘积时意味 着什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.0,
  "end": 928.84
 },
 {
  "input": "What you're doing is essentially expanding out the full product of the two polynomials I have written down and then when you add up along the diagonal that corresponds to collecting all like terms which is pretty neat expanding a polynomial and collecting like terms is exactly the same process as a convolution. ",
  "translatedText": "你所做的本质上是展开我写下的两个多项式的 完整乘积，然后当你沿着对应于收集所有相似项的对角 线相加时，这非常整齐地展开多项式并收集相似项正 是与卷积相同的过程。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 929.04,
  "end": 946.44
 },
 {
  "input": "But this allows us to do something that's pretty cool because think about what we're saying here. ",
  "translatedText": "但这使我们能够做一些非常酷的事情， 因为想想我们在这里所说的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 947.74,
  "end": 952.34
 },
 {
  "input": "We're saying if you take two different functions and you multiply them together which is a simple pointwise operation that's the same thing as if you had first extracted the coefficients from each one of those assuming they're polynomials and then taken a convolution of those two lists of coefficients. ",
  "translatedText": "我们的意思是，如果你采用两个不同的 函数并将它们相乘，这是一个简单的逐点运算，这与你首先从 每个函数中提取系数（假设它们是多项式）然后对这些函数进行 卷积是一样的两个系数列表。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 952.34,
  "end": 968.84
 },
 {
  "input": "What makes that so interesting is that convolutions feel in principle a lot more complicated than simple multiplication and I don't just mean conceptually they're harder to think about I mean computationally it requires more steps to perform a convolution than it does to perform a pointwise product of two different lists. ",
  "translatedText": "有趣的是，卷积在原则上感觉 比简单的乘法复杂得多，我不仅仅意味着在概念上它们 更难思考，我的意思是在计算上它需要更多的步骤来执行 卷积而不是执行两个不同列表的逐点乘积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 969.62,
  "end": 985.76
 },
 {
  "input": "For example, let's say I gave you two really big polynomials, say each one with a hundred different coefficients. Then if the way you multiply them was to expand out this product, you know, filling in this entire 100 by 100 grid of pairwise products, that would require you to perform 10,000 different products. And then, when you're collecting all the like terms along the diagonals, that's another set of around 10,000 operations. ",
  "translatedText": "例如，假设我 给了你两个非常大的多项式，每个多项式都有一百个不同的系数，那么如果 你将它们相乘的方式是展开这个乘积，你知道填充整个 100 x 1 00 的成对乘积网格，这需要你执行 10,000 种不同的产品， 然后当您沿着对角线收集所有相似项时，这是另一组大约 10,000 次操作。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.32,
  "end": 1009.86
 },
 {
  "input": "More generally in the lingo we'd say the algorithm is O of n squared meaning for two lists of size n the way that the number of operations scales is in proportion to the square of n. ",
  "translatedText": "更一般地说，在行话中，我们会说该算法是 O of n 平 方，这意味着对于两个大小为 n 的列表，操作数量与 n 的平方成正比 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1010.7,
  "end": 1021.14
 },
 {
  "input": "On the other hand if I think of two polynomials in terms of their outputs for example sampling their values at some handful of inputs then multiplying them only requires as many operations as the number of samples since again it's a pointwise operation and with polynomials you only need finitely many samples to be able to recover the coefficients. ",
  "translatedText": "另一方面，如果我根据输出来考虑两个多项式，例如在一些输入处对它们的值进行采样，那么将它们相乘只需要与样本数一样多的运算，因为这又是一个逐点运算，并且对于多项式，您只需要有限多个样本能够恢复系数。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1021.82,
  "end": 1040.54
 },
 {
  "input": "For example two outputs are enough to uniquely specify a linear polynomial.",
  "translatedText": "例如，两个输出足以唯一地指定线性多项式。",
  "n_reviews": 0,
  "start": 1040.54,
  "end": 1045.06
 },
 {
  "input": "Three outputs would be enough to uniquely specify a quadratic polynomial.",
  "translatedText": "三个输出足以唯一地指定二次多项式。",
  "n_reviews": 0,
  "start": 1045.66,
  "end": 1049.4
 },
 {
  "input": "And in general if you know n distinct outputs that's enough to uniquely specify a polynomial that has n different coefficients.",
  "translatedText": "一般来说，如果您知道 n 个不同的输出，就足以唯一地指定具有 n 个不同系数的多项式。",
  "n_reviews": 0,
  "start": 1049.64,
  "end": 1056.74
 },
 {
  "input": "Or if you prefer we could phrase this in the language of systems of equations.",
  "translatedText": "或者，如果您愿意，我们可以用方程组的语言来表达它。",
  "n_reviews": 0,
  "start": 1057.44,
  "end": 1060.72
 },
 {
  "input": "Imagine I tell you I have some polynomial but I don't tell you what the coefficients are, those are a mystery to you.",
  "translatedText": "想象一下，我告诉你我有一些多项式，但我没有告诉你系数是什么，这些对你来说是个谜。",
  "n_reviews": 0,
  "start": 1061.2,
  "end": 1066.52
 },
 {
  "input": "In our example you might think of this as the product that we're trying to figure out.",
  "translatedText": "在我们的示例中，您可能会认为这是我们正在尝试找出的产品。",
  "n_reviews": 0,
  "start": 1066.7,
  "end": 1070.18
 },
 {
  "input": "Then suppose I say I'll just tell you what the outputs of this polynomial would be if you inputted various different inputs like 0, 1, 2, 3, on and on, and I give you enough so that you have as many equations as you have unknowns.",
  "translatedText": "然后假设我说，如果您输入各种不同的输入（例如 0、1、2、3 等等），我会告诉您该多项式的输出是什么，并且我给您足够的信息，以便您有尽可能多的方程你有未知数。",
  "n_reviews": 0,
  "start": 1070.18,
  "end": 1083.46
 },
 {
  "input": "It even happens to be a linear system of equations, so that's nice.",
  "translatedText": "它甚至恰好是一个线性方程组，所以这很好。",
  "n_reviews": 0,
  "start": 1084.14,
  "end": 1087.34
 },
 {
  "input": "And in principle at least, this should be enough to recover the coefficients.",
  "translatedText": "至少原则上，这应该足以恢复系数。",
  "n_reviews": 0,
  "start": 1087.78,
  "end": 1090.9
 },
 {
  "input": "So the rough algorithm outline then would be whenever you want to convolve two lists of numbers you treat them like they're coefficients of two polynomials.",
  "translatedText": "因此，粗略的算法概述是，每当您想要对两个数字列表进行卷积时，您都将它们视为两个多项式的系数。",
  "n_reviews": 0,
  "start": 1091.74,
  "end": 1099.0
 },
 {
  "input": "You sample those polynomials at enough outputs, multiply those samples point-wise, and then solve the system to recover the coefficients as a sneaky backdoor way to find the convolution.",
  "translatedText": "您以足够的输出对这些多项式进行采样，将这些样本逐点相乘，然后求解系统以恢复系数，作为找到卷积的一种偷偷摸摸的后门方法。",
  "n_reviews": 0,
  "start": 1099.42,
  "end": 1110.56
 },
 {
  "input": "And as I've stated it so far at least, some of you could rightfully complain \"Grant, that is an idiotic plan\".",
  "translatedText": "至少到目前为止我已经说过了，你们中的一些人可以合理地抱怨“格兰特，这是一个愚蠢的计划”。",
  "n_reviews": 0,
  "start": 1111.42,
  "end": 1117.34
 },
 {
  "input": "Because for one thing just calculating all these samples for one of the polynomials we know already takes on the order of n squared operations, not to mention solving that system is certainly going to be computationally as difficult as just doing the convolution in the first place.",
  "translatedText": "因为首先，仅计算我们已知的多项式之一的所有这些样本就已经进行了 n 次方运算，更不用说解决该系统在计算上肯定会像首先进行卷积一样困难。",
  "n_reviews": 0,
  "start": 1117.58,
  "end": 1132.1
 },
 {
  "input": "So, like, sure we have this connection between multiplication and convolutions, but all of the complexity happens in translating from one viewpoint to the other.",
  "translatedText": "所以，就像，乘法和卷积之间肯定有这种联系，但所有的复杂性都发生在从一个观点到另一个观点的转换中。",
  "n_reviews": 0,
  "start": 1132.6,
  "end": 1140.48
 },
 {
  "input": "But there is a trick, and those of you who know about Fourier transforms and the FFT algorithm might see where this is going.",
  "translatedText": "但有一个技巧，那些了解傅立叶变换和 FFT 算法的人可能会明白这是怎么回事。",
  "n_reviews": 0,
  "start": 1141.6,
  "end": 1147.74
 },
 {
  "input": "If you're unfamiliar with these topics, what I'm about to say might seem completely out of the blue.",
  "translatedText": "如果您不熟悉这些主题，那么我接下来要说的内容可能看起来完全出乎意料。",
  "n_reviews": 0,
  "start": 1147.74,
  "end": 1152.18
 },
 {
  "input": "Just know that there are certain paths you could have walked in math that make this more of an expected step.",
  "translatedText": "只要知道，在数学中你可以走一些特定的道路，这使得这更像是一个预期的步骤。",
  "n_reviews": 0,
  "start": 1152.26,
  "end": 1156.86
 },
 {
  "input": "Basically the idea is that we have a freedom of choice here.",
  "translatedText": "基本上，我们的想法是我们在这里有选择的自由。",
  "n_reviews": 0,
  "start": 1157.72,
  "end": 1160.36
 },
 {
  "input": "If instead of evaluating at some arbitrary set of inputs like 0, 1, 2, 3, on and on, you choose to evaluate on a very specially selected set of complex numbers.",
  "translatedText": "如果您选择对一组非常特别选择的复数进行评估，而不是对任意一组输入（如 0、1、2、3 等等）进行评估。",
  "n_reviews": 0,
  "start": 1160.54,
  "end": 1169.7
 },
 {
  "input": "Specifically the ones that sit evenly spaced on the unit circle, what are known as the roots of unity.",
  "translatedText": "特别是那些均匀分布在单位圆上的，即所谓的单位根。",
  "n_reviews": 0,
  "start": 1170.24,
  "end": 1174.84
 },
 {
  "input": "This gives us a friendlier system.",
  "translatedText": "这为我们提供了一个更友好的系统。",
  "n_reviews": 0,
  "start": 1175.2,
  "end": 1176.88
 },
 {
  "input": "The basic idea is that by finding a number where taking its powers falls into this cycling pattern, it means that the system we generate is going to have a lot of redundancy in the different terms that you're calculating, and by being clever about how you leverage that redundancy, you can save yourself a lot of work.",
  "translatedText": "基本思想是，通过找到一个数字，使其幂落入这种循环模式，这意味着我们生成的系统将在您计算的不同项中具有大量冗余，并且通过聪明地了解如何计算利用这种冗余，您可以节省大量工作。",
  "n_reviews": 0,
  "start": 1178.36,
  "end": 1194.46
 },
 {
  "input": "This set of outputs that I've written has a special name, it's called the discrete Fourier transform of the coefficients.",
  "translatedText": "我编写的这组输出有一个特殊的名称，称为系数的离散傅立叶变换。",
  "n_reviews": 0,
  "start": 1196.02,
  "end": 1202.28
 },
 {
  "input": "And if you want to learn more I actually did another lecture for that same Julia MIT class all about discrete Fourier transforms.",
  "translatedText": "如果你想了解更多，我实际上为 Julia 麻省理工学院的同一个课程做了另一场关于离散傅里叶变换的讲座。",
  "n_reviews": 0,
  "start": 1202.5,
  "end": 1209.14
 },
 {
  "input": "And there's also a really excellent video on the channel reducible talking about the fast Fourier transform, which is an algorithm for computing these more quickly.",
  "translatedText": "在频道 reducible 上还有一个非常棒的视频，讨论了快速傅立叶变换，这是一种可以更快地计算这些变换的算法。",
  "n_reviews": 0,
  "start": 1209.22,
  "end": 1217.12
 },
 {
  "input": "Also Veritasium recently did a really good video on FFT's, so you've got lots of options.",
  "translatedText": "另外，Veritasium 最近制作了一个关于 FFT 的非常好的视频，因此您有很多选择。",
  "n_reviews": 0,
  "start": 1217.48,
  "end": 1221.76
 },
 {
  "input": "And that fast algorithm really is the point for us.",
  "translatedText": "这种快速算法确实是我们的重点。",
  "n_reviews": 0,
  "start": 1222.26,
  "end": 1224.66
 },
 {
  "input": "Again because of all this redundancy there exists a method to go from the coefficients to all of these outputs, where instead of doing on the order of n squared operations, you do on the order of n times the log of n operations, which is much much better as you scale to big lists.",
  "translatedText": "同样，由于所有这些冗余，存在一种从系数到所有这些输出的方法，其中不是按 n 平方运算的顺序进行，而是按 n 乘以 n 运算的对数的顺序进行，这要多得多当你扩展到大列表时会更好。",
  "n_reviews": 0,
  "start": 1225.12,
  "end": 1239.2
 },
 {
  "input": "And importantly this fft algorithm goes both ways.",
  "translatedText": "重要的是，这种 fft 算法是双向的。",
  "n_reviews": 0,
  "start": 1239.66,
  "end": 1242.54
 },
 {
  "input": "It also lets you go from the outputs to the coefficients.",
  "translatedText": "它还可以让您从输出转到系数。",
  "n_reviews": 0,
  "start": 1242.7,
  "end": 1245.48
 },
 {
  "input": "So bringing it all together, let's look back at our algorithm outline.",
  "translatedText": "因此，将所有内容放在一起，让我们回顾一下我们的算法大纲。",
  "n_reviews": 0,
  "start": 1246.22,
  "end": 1249.06
 },
 {
  "input": "Now we can say whenever you're given two long lists of numbers and you want to take their convolution, first compute the fast Fourier transform of each one of them, which in the back of your mind you can just think of as treating them like they're the coefficients of a polynomial and evaluating it at a very specially selected set of points.",
  "translatedText": "现在我们可以说，每当你给定两个一长串数字并且你想要对它们进行卷积时，首先计算它们每个的快速傅立叶变换，在你的脑海中你可以认为将它们视为它们是多项式的系数，并在一组非常特别选择的点上对其进行评估。",
  "n_reviews": 0,
  "start": 1249.42,
  "end": 1266.38
 },
 {
  "input": "Then multiply together the two results that you just got point-wise, which is nice and fast, and then do an inverse fast Fourier transform, and what that gives you is the sneaky backdoor way to compute the convolution that we were looking for.",
  "translatedText": "然后将刚刚获得的两个结果逐点相乘，这既好又快，然后进行快速傅立叶逆变换，这给了您计算我们正在寻找的卷积的偷偷摸摸的后门方法。",
  "n_reviews": 0,
  "start": 1266.9,
  "end": 1278.9
 },
 {
  "input": "But this time it only involves O of n log n operations.",
  "translatedText": "但这次只涉及 O of n log n 操作。",
  "n_reviews": 0,
  "start": 1279.04,
  "end": 1282.24
 },
 {
  "input": "That's really cool to me!",
  "translatedText": "这对我来说真的很酷！",
  "n_reviews": 0,
  "start": 1283.14,
  "end": 1284.74
 },
 {
  "input": "This very specific context where convolutions show up, multiplying two polynomials, opens the doors for an algorithm that's relevant everywhere else where convolutions might come up.",
  "translatedText": "卷积出现的这种非常具体的上下文，将两个多项式相乘，为一种与其他可能出现卷积的地方相关的算法打开了大门。",
  "n_reviews": 0,
  "start": 1285.12,
  "end": 1294.1
 },
 {
  "input": "If you want to add probability distributions, do some large image processing, whatever it might be.",
  "translatedText": "如果您想添加概率分布，请进行一些大型图像处理，无论它是什么。",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1299.0
 },
 {
  "input": "And I just think that's such a good example of why you should be excited when you see some operation or concept in math show up in a lot of seemingly unrelated areas.",
  "translatedText": "我只是认为这是一个很好的例子，说明为什么当你看到数学中的某些运算或概念出现在许多看似不相关的领域时，你应该感到兴奋。",
  "n_reviews": 0,
  "start": 1299.22,
  "end": 1307.48
 },
 {
  "input": "If you want a little homework here's something that's fun to think about.",
  "translatedText": "如果你想要做一点作业，这里有一些值得思考的有趣的事情。",
  "n_reviews": 0,
  "start": 1308.48,
  "end": 1311.5
 },
 {
  "input": "Explain why when you multiply two different numbers, just ordinary multiplication the way we all learn in elementary school, what you're doing is basically a convolution between the digits of those numbers.",
  "translatedText": "解释为什么当你将两个不同的数字相乘时，只是我们在小学学习的普通乘法，你所做的基本上是这些数字的数字之间的卷积。",
  "n_reviews": 0,
  "start": 1311.72,
  "end": 1321.98
 },
 {
  "input": "There are some added steps with carries and the like, but the core step is a convolution.",
  "translatedText": "增加了一些进位等步骤，但核心步骤是卷积。",
  "n_reviews": 0,
  "start": 1322.5,
  "end": 1326.46
 },
 {
  "input": "In light of the existence of a fast algorithm, what that means is if you have two very large integers, then there exists a way to find their product that's faster than the method we learn in elementary school.",
  "translatedText": "鉴于快速算法的存在，这意味着如果你有两个非常大的整数，那么存在一种比我们在小学学到的方法更快的方法来找到它们的乘积。",
  "n_reviews": 0,
  "start": 1327.28,
  "end": 1337.88
 },
 {
  "input": "That instead of requiring O of n squared operations only requires O of n log n, which doesn't even feel like it should be possible.",
  "translatedText": "这不需要 O of n 平方运算，只需要 O of n log n，这甚至感觉不可能。",
  "n_reviews": 0,
  "start": 1338.14,
  "end": 1344.92
 },
 {
  "input": "The catch is that before this is actually useful in practice, your numbers would have to be absolutely monstrous.",
  "translatedText": "问题是，在这在实践中真正有用之前，你的数字必须绝对是巨大的。",
  "n_reviews": 0,
  "start": 1345.38,
  "end": 1350.84
 },
 {
  "input": "But still, it's cool that such an algorithm exists.",
  "translatedText": "不过，这样的算法存在还是很酷的。",
  "n_reviews": 0,
  "start": 1351.22,
  "end": 1353.86
 },
 {
  "input": "Next up we'll turn our attention to the continuous case with a special focus on probability distributions.",
  "translatedText": "接下来，我们将把注意力转向连续情况，特别关注概率分布。",
  "n_reviews": 0,
  "start": 1355.16,
  "end": 1359.64
 }
]