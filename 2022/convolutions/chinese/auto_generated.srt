1
00:00:00,000 --> 00:00:03,379
假设有两个不同的数组 或两个不同的函数 

2
00:00:03,379 --> 00:00:07,265
让你想出各种运算方式 来把两个数组组合在一起 

3
00:00:07,265 --> 00:00:11,320
得到新数组 或者把两个函数组合起来  得到新函数

4
00:00:12,120 --> 00:00:16,760
最简单的方法可能就是 一个个地把他们加起来

5
00:00:17,160 --> 00:00:19,920
同样 对函数来说则是把结果对应相加

6
00:00:20,540 --> 00:00:25,680
类似的 你也可以把两个数组中的数逐个相乘 对函数也是如此

7
00:00:26,360 --> 00:00:30,822
但有其实另一种组合方式 和之前提过的方式一样基础 

8
00:00:30,822 --> 00:00:33,500
但讨论得不多 它被称作“卷积”

9
00:00:34,080 --> 00:00:39,820
但和前面两种组合方式不同的是 它并非来源于某种数字运算

10
00:00:39,980 --> 00:00:44,700
而是一种用来组合数组和函数的新方法

11
00:00:45,320 --> 00:00:49,423
这一方法随处可见 在数字图像处理中尤为明显 

12
00:00:49,423 --> 00:00:54,644
它是概率论中的一个核心结构 在求解微分方程时被大量使用 

13
00:00:54,644 --> 00:01:00,240
而在多项式相乘的情形中  你一定见过它 只是可能不叫这个名字

14
00:01:00,740 --> 00:01:06,050
对一个用可视化方式传播知识的人来说 这是一个非常好的选题 

15
00:01:06,050 --> 00:01:10,628
因为光看没有上下文的公式化定义 卷积是会有点唬人 

16
00:01:10,628 --> 00:01:15,939
但是如果我告诉你卷积好处都有啥 再给你好好剖析下它的定义 

17
00:01:15,939 --> 00:01:18,320
你就会发现这个运算十分美妙

18
00:01:18,960 --> 00:01:21,536
不得不承认 在制作这期视频的过程中 

19
00:01:21,536 --> 00:01:23,540
我自己也切实地学到了一些知识

20
00:01:23,540 --> 00:01:26,467
在讲到对两个函数进行卷积的例子时 

21
00:01:26,467 --> 00:01:31,632
我在思考用不同的方式将其可视化 其中一个方式 让我豁然开朗 

22
00:01:31,632 --> 00:01:35,937
我一下子明白了  为何正态分布在概率论中如此重要 

23
00:01:35,937 --> 00:01:38,520
它的函数图像的形状为何如此自然

24
00:01:39,020 --> 00:01:41,520
扯远了 在讲这个之前还有很多准备工作要做

25
00:01:41,840 --> 00:01:45,936
在这个视频中我们主要关注离散的卷积 

26
00:01:45,936 --> 00:01:50,260
 逐步构建出一种让人拍案叫绝的计算方法

27
00:01:50,260 --> 00:01:54,480
而连续的卷积我们则放在下期视频里来讨论

28
00:01:58,580 --> 00:02:02,456
虽然用数字图像处理的例子作为开篇听起来很不错 

29
00:02:02,456 --> 00:02:07,006
毕竟它在可视方面是最能引起人兴趣的 但在一些细微之处 

30
00:02:07,006 --> 00:02:10,039
图像处理的例子不太能展现卷积的全貌 

31
00:02:10,039 --> 00:02:14,590
所以我们还是从概率论开始吧 有这么一个最最简单的例子 

32
00:02:14,590 --> 00:02:18,466
相信各位观众或早或晚都曾听过 就是掷两枚骰子 

33
00:02:18,466 --> 00:02:21,500
计算两枚骰子的各个点数和的出现的概率

34
00:02:22,460 --> 00:02:24,460
你可能会说 就这

35
00:02:24,680 --> 00:02:27,992
每个骰子都有 6 种不同的结果 

36
00:02:27,992 --> 00:02:32,961
总共就是六六三十六种配对可能 我们一个个数一遍 

37
00:02:32,961 --> 00:02:35,860
就可以数出每个和有多少种组合

38
00:02:36,600 --> 00:02:41,440
把所有的组合这样填在表格里 有个很妙的事情是 

39
00:02:41,440 --> 00:02:45,440
相同点数和的组合 都排在同一条对角线上

40
00:02:45,440 --> 00:02:48,689
所以只要数出对角线上面有多少个组合 

41
00:02:48,689 --> 00:02:52,120
就可以知道 出现某个点数和的概率是多少

42
00:02:53,220 --> 00:02:58,660
我会说：还不赖  但你能换一种方式展现这个问题吗

43
00:02:59,300 --> 00:03:04,060
有没有想到其它 数出某个加和的所有点数组合方式的画面

44
00:03:04,860 --> 00:03:07,980
可能有聪明的观众想说「我有想法了」

45
00:03:08,280 --> 00:03:13,760
把两枚骰子的所有可能结果 分别放到一行 然后把第二行翻转

46
00:03:13,760 --> 00:03:18,760
这样所有点数和为 7 的组合 就会这样纵向对齐

47
00:03:19,360 --> 00:03:22,474
如果我们把下面这行往左滑到头 那么 

48
00:03:22,474 --> 00:03:26,280
加和为2的唯一一组结果 就是唯一对齐的情况了

49
00:03:26,620 --> 00:03:32,080
如果我在往右推一个单位 就会出现两对和为 3 的组合

50
00:03:32,880 --> 00:03:36,072
总的来说 红色数组的不同偏移量 

51
00:03:36,072 --> 00:03:41,460
（别忘了下面这行是翻转过的） 对应了两个骰子的点数加和

52
00:03:44,820 --> 00:03:48,357
到目前为止 这个概率问题还不算太有趣 

53
00:03:48,357 --> 00:03:52,640
因为我们只是数出了 每种点数和有多少种组合方式

54
00:03:52,980 --> 00:03:58,120
但这里面其实隐藏了一个假设 就是骰子的每面向上的概率是相同的

55
00:03:58,360 --> 00:04:01,620
如果我现在改用非标的骰子

56
00:04:02,060 --> 00:04:06,362
用一个数组来描述蓝骰子每面向上的概率 

57
00:04:06,362 --> 00:04:09,760
同样地 红骰子也有这样一个数组

58
00:04:10,300 --> 00:04:14,248
这样如果你想算出和为 2 的出现概率 

59
00:04:14,248 --> 00:04:19,860
就要用蓝骰子出现 1 的概率 乘红骰子出现 1 的概率

60
00:04:20,279 --> 00:04:25,407
如果要计算和为 3 的概率 则需要把对应组合里 

61
00:04:25,407 --> 00:04:29,680
点数出现的概率分别相乘 然后再把乘积相加

62
00:04:30,100 --> 00:04:32,660
类似地 要计算和为 4 的情况 

63
00:04:32,660 --> 00:04:36,820
就要把三个不同组合里点数的出现概率相乘 再把他们相加

64
00:04:36,820 --> 00:04:41,157
秉着要把它公式化的精神 我们把上面那行的概率记为 a₁ 

65
00:04:41,157 --> 00:04:45,805
a₂ a₃... 把下面一行的概率记为 b₁ b₂ b₃..

66
00:04:45,805 --> 00:04:45,960
.

67
00:04:46,400 --> 00:04:49,538
拿出两列不同的数组{\fsp-29}、 

68
00:04:49,538 --> 00:04:52,519
把第二组翻转过来{\fsp-29}、 

69
00:04:52,519 --> 00:04:56,285
然后用不同偏移值把它们对齐{\fsp-29}、 

70
00:04:56,285 --> 00:04:59,737
得到一组乘积之后再把他们加起来 这整个过程 

71
00:04:59,737 --> 00:05:01,620
便是卷积最基本的思考方式

72
00:05:04,860 --> 00:05:09,382
说得更精确一些 我们通过这个过程 生成了点数和为 

73
00:05:09,382 --> 00:05:12,638
2 3 4 ... 12 的概率  

74
00:05:12,638 --> 00:05:16,980
这个过程通过某种运算将 A 和 B 数组的值交汇

75
00:05:17,440 --> 00:05:21,760
说得专业一点就是 两组数的卷积生成了新的这组数 

76
00:05:21,760 --> 00:05:26,619
新的数列包含 11 个值 每个值都是两数组中若干数对之

77
00:05:26,619 --> 00:05:27,340
积的加和

78
00:05:27,340 --> 00:05:31,789
另一种思考卷积的方式是 列一个表格 

79
00:05:31,789 --> 00:05:36,980
计算各个组合的乘积 然后沿着各个对角线相加

80
00:05:37,460 --> 00:05:42,760
就把两组数混合了起来 得到了一组 11 个数

81
00:05:43,240 --> 00:05:46,460
这个做法和滑动数列类似 只是换了一种思考方式

82
00:05:47,140 --> 00:05:49,800
用上一些符号就可以写成这样

83
00:05:50,220 --> 00:05:54,170
A 和 B 的卷积的符号是「*」 

84
00:05:54,170 --> 00:05:59,050
其结果是一个列表 它的第 n 项定义为  

85
00:05:59,050 --> 00:06:04,860
把下标 i j 之和为 n 的诸元素的乘积累加起来

86
00:06:05,280 --> 00:06:07,707
这可能有点啰嗦 但我还是要举个例子 如果 

87
00:06:07,707 --> 00:06:09,788
n=6 i 和 j 的组合 (i, 

88
00:06:09,788 --> 00:06:12,563
j) 就是 (1, 5) (2, 4) (3, 

89
00:06:12,563 --> 00:06:15,800
3) (4, 2) (5, 1) 这些组合加起来都是 6

90
00:06:16,620 --> 00:06:22,340
但是老实说 不管你怎么写 符号在脑中留下的印象都不会太深

91
00:06:23,280 --> 00:06:27,446
这有一个超简单的例子可能会有所帮助 我要问你 数组 (1, 

92
00:06:27,446 --> 00:06:30,780
2, 3) 和 (4, 5, 6) 的卷积是什么

93
00:06:31,480 --> 00:06:34,314
你就可以想象这两个数组并排放着 

94
00:06:34,314 --> 00:06:37,680
翻转第二个 然后把它（尾部）滑到最左边

95
00:06:38,180 --> 00:06:40,946
这时候对齐的就只有 1 和 4 

96
00:06:40,946 --> 00:06:43,540
把它们乘在一起得到输出的第一项

97
00:06:43,960 --> 00:06:49,034
把第二个数组往右滑一个单位 对齐的就会有 1 和 5、2 

98
00:06:49,034 --> 00:06:54,109
和 4 把这两对相乘  然后把乘积加在一起就得到了下一项 

99
00:06:54,109 --> 00:06:54,460
13

100
00:06:54,960 --> 00:06:59,856
再滑一下 就可以得到 1×6+2×5+3×4 

101
00:06:59,856 --> 00:07:01,560
算出来就是 28

102
00:07:02,020 --> 00:07:07,174
再滑一下 就得到了 2×6+3×5=27 

103
00:07:07,174 --> 00:07:10,120
最后再滑一下就是 3×6

104
00:07:10,660 --> 00:07:16,963
你可以用自己最喜欢的编程语言 和数值计算库跑一下 

105
00:07:16,963 --> 00:07:18,980
就知道我没骗你了

106
00:07:18,980 --> 00:07:21,867
如果计算 (1, 2, 3) 和 (4, 

107
00:07:21,867 --> 00:07:24,480
5, 6) 的卷积 你就会得到这个结果

108
00:07:25,920 --> 00:07:28,822
我们已经在求和得出概率分布的例子中 

109
00:07:28,822 --> 00:07:33,660
看到了这个运算是多么的自然和美妙 而另一个常见例子是滑动平均

110
00:07:34,080 --> 00:07:39,760
假设有一个长数组 和另一个所有数之和为 1 的短数组

111
00:07:40,100 --> 00:07:44,060
这里就让短数组只有五个值好了 且每个值都等于 1/5

112
00:07:44,060 --> 00:07:48,796
接下来 如果我们重复这个滑动窗口卷积的过程 

113
00:07:48,796 --> 00:07:52,887
（最开始窗口出界的问题你就当没看见） 

114
00:07:52,887 --> 00:07:58,700
当短数组和长数组完全重叠时 思考下卷积的每项代表着什么

115
00:07:59,400 --> 00:08:05,054
每次迭代的时候 你实际上是 在把数据里的每个数乘上 1/5 

116
00:08:05,054 --> 00:08:10,520
然后将它们加起来 也就是说 你在求这个小窗口里数据的平均值

117
00:08:11,100 --> 00:08:14,864
总的来说 这个过程给了你一个原数据的平滑版本 

118
00:08:14,864 --> 00:08:18,464
你可以修改它  使其从一个不同的短数组开始 

119
00:08:18,464 --> 00:08:22,720
只要短数组之和还是 1 你就仍可以把它解释为滑动平均

120
00:08:23,400 --> 00:08:27,760
在这个例子中 滑动平均会给中间值更大的权重

121
00:08:28,420 --> 00:08:30,800
其结果也是原数据的平滑版本

122
00:08:33,140 --> 00:08:35,930
如果你在二维上进行类似的操作 就

123
00:08:35,930 --> 00:08:38,720
会得到一个把图片变模糊的有趣方法

124
00:08:38,720 --> 00:08:42,561
我应该指出 我接下来将要展示的动画 是由我和 

125
00:08:42,561 --> 00:08:45,568
Julia Lab 在麻省理工做的 

126
00:08:45,568 --> 00:08:48,240
一系列公开课里的内容修改而来的 

127
00:08:48,240 --> 00:08:51,080
其中就包含了一节图像处理相关的内容

128
00:08:51,560 --> 00:08:54,273
那个视频里对图像处理背后的代码讲解得更为深入 

129
00:08:54,273 --> 00:08:56,280
你感兴趣的话 可以看看评论区的链接

130
00:08:56,620 --> 00:09:02,076
讲回到模糊图片的这个例子上 我们在做的事是 用一个 

131
00:09:02,076 --> 00:09:07,533
3×3 的网格沿着原图像移动 放大后  每个数都是 

132
00:09:07,533 --> 00:09:13,620
1/9 在每次迭代的时候 将这些数值乘以它底下对应的像素值

133
00:09:13,900 --> 00:09:17,860
当然在计算机科学中 我们把颜色当成三维向量 

134
00:09:17,860 --> 00:09:20,200
三个分量分别代表红、绿、蓝

135
00:09:20,560 --> 00:09:24,468
把每个向量都乘以 1/9 然后求和 

136
00:09:24,468 --> 00:09:29,680
就得到了每个颜色通道的平均值 那么右图中对应的像

137
00:09:29,680 --> 00:09:31,200
素就是这个加和

138
00:09:31,940 --> 00:09:34,969
对每个像素都这么计算 得到的效果是 

139
00:09:34,969 --> 00:09:38,167
每个像素都混杂了一部分到相邻的像素中 

140
00:09:38,167 --> 00:09:40,860
这就得到了一个比原图更模糊的版本

141
00:09:41,720 --> 00:09:47,740
用术语来说 右图就是原图和小网格的卷积

142
00:09:48,140 --> 00:09:54,400
严格上讲 应该是 和旋转 180 度的网格的卷积

143
00:09:54,620 --> 00:09:59,045
当然这在网格对称时没什么分别 但还是值得注意一下 

144
00:09:59,045 --> 00:10:03,824
卷积的定义是从纯数学语境继承下来的 你要牢记这个定义 

145
00:10:03,824 --> 00:10:05,240
把第二个数组翻转

146
00:10:05,960 --> 00:10:08,530
如果我们稍微修改一下这个例子 我们可以通过选择

147
00:10:08,530 --> 00:10:11,100
给网格赋予不同的数值 来得到更为美观的模糊效果

148
00:10:11,440 --> 00:10:15,780
这个例子中 有一个 5×5 网格 但是其大小不是主要的不同

149
00:10:15,980 --> 00:10:21,131
如果放大 我们可以看到中间的值 比边上的值大很多 究其根源 

150
00:10:21,131 --> 00:10:25,940
 这些值都从一个钟形曲线中采样得来 这个曲线叫做高斯分布

151
00:10:26,800 --> 00:10:31,057
这样 当我们将这些数乘以 它们下面对应的像素时 

152
00:10:31,057 --> 00:10:36,380
我们把更多的权重给了中间像素 而只把很少的权重给了边上的像素

153
00:10:36,800 --> 00:10:40,560
和之前一样 右图中对应的像素就是这个加和

154
00:10:41,320 --> 00:10:44,424
随着我们对每个像素都重复这个过程 

155
00:10:44,424 --> 00:10:49,720
我们得到了一个模糊效果 它更真实地模拟了镜头失焦之类的场景

156
00:10:49,900 --> 00:10:53,360
但是这个方法能做到的事情 远远不止模糊图片

157
00:10:53,800 --> 00:10:58,740
比如这个数值网格 正数在左 负数在右 

158
00:10:58,740 --> 00:11:02,900
我们来把它们分别填充为蓝色和红色

159
00:11:03,640 --> 00:11:08,480
思考一下 看看你能否预测并理解 这个网格会如何影响最终图像

160
00:11:10,720 --> 00:11:14,067
这里只把图像考虑为灰度图而不是彩色图 

161
00:11:14,067 --> 00:11:18,120
这样每个像素就可以只用一个数来表示 而不是三个

162
00:11:18,440 --> 00:11:23,060
值得一提的是 计算卷积的过程中 是有可能得到负值的

163
00:11:23,060 --> 00:11:28,498
比如这里 放大可以看见 网格左半边都在黑色像素上 

164
00:11:28,498 --> 00:11:33,937
所以会得到 0 而网格右半边的负值都在白色像素上 

165
00:11:33,937 --> 00:11:35,460
所以会得到 1

166
00:11:36,180 --> 00:11:40,405
所以把对应项相乘再把结果相加 会得到负数值 

167
00:11:40,405 --> 00:11:44,823
我在右图中表示这点的方法 是把负数填充为红色 

168
00:11:44,823 --> 00:11:46,360
把正数填充为蓝色

169
00:11:46,880 --> 00:11:50,392
另外需要注意 当所有小块都是同一颜色时 

170
00:11:50,392 --> 00:11:54,080
结果是 0 这是因为网格中所有值相加为 0

171
00:11:55,180 --> 00:11:58,680
这和之前的两个例子大为不同 因为之前的例子里网格里数值的

172
00:11:58,680 --> 00:12:02,180
加和为 1 我们可以将其考虑为滑动平均 也就是模糊了图像

173
00:12:03,640 --> 00:12:09,673
总而言之 这个过程是在 检测像素值从左到右是否有变化 

174
00:12:09,673 --> 00:12:13,920
所以它可以判别出图像中的所有竖向的边界

175
00:12:16,500 --> 00:12:21,293
用同样的逻辑 如果我们旋转这个网格 使得它从上到下变化 

176
00:12:21,293 --> 00:12:25,231
那么它就可以判别出图像中的所有横向的边界   

177
00:12:25,231 --> 00:12:29,340
在这个例子中  它把 π 酱的眼睛变得像个大反派

178
00:12:30,400 --> 00:12:33,927
顺便一提 这个小网格一般叫做“核” 巧妙之处在于 

179
00:12:33,927 --> 00:12:37,736
 仅仅通过选择不同的核 就可以产生不同的图像处理效果 

180
00:12:37,736 --> 00:12:40,840
不只是模糊化边缘检测  图像的锐化也是可以的

181
00:12:40,840 --> 00:12:46,357
如果你听说过卷积神经网络的话 它的思路就是用数据来算出 

182
00:12:46,357 --> 00:12:51,480
应该选取什么样的核 这取决于想用神经网络来检测的目标

183
00:12:52,760 --> 00:12:55,520
另一个应该提一嘴的事情是输出的长度

184
00:12:55,820 --> 00:12:59,640
对滑动平均之类的情况  可能只需要考虑取样窗

185
00:12:59,640 --> 00:13:03,807
口完全对应的情况就好了 或者在图像处理的应用中 

186
00:13:03,807 --> 00:13:07,280
可能你想要保持输出图像的尺寸和原图像相同

187
00:13:07,280 --> 00:13:12,620
其实 纯数学过程上的卷积 产生的数组总是比两个初始数组更长 

188
00:13:12,620 --> 00:13:16,180
至少在数组长度都大于 1 的时候是这样的

189
00:13:16,720 --> 00:13:21,520
你只需知道在某些计算机科学的背景下 你需要刻意截掉一些输出值

190
00:13:24,720 --> 00:13:28,657
另外值得一提的是 在计算机科学的语境下 

191
00:13:28,657 --> 00:13:34,367
将核翻转后再遍历原数组 经常感觉非常奇怪且没必要 但是  

192
00:13:34,367 --> 00:13:37,714
这一样是从纯数学背景中继承而来的 

193
00:13:37,714 --> 00:13:42,440
而就像在概率的例子中所见的 这个翻转再正常不过了

194
00:13:43,020 --> 00:13:46,246
其实 我还可以再展示一个纯数学的例子 

195
00:13:46,246 --> 00:13:50,661
即使是纯程序员也应该关心此例 因为它引入了一个计算卷

196
00:13:50,661 --> 00:13:52,020
积时快得多的算法

197
00:13:52,620 --> 00:13:55,819
为了解释我说的快得多是什么意思 我来掏出 

198
00:13:55,819 --> 00:13:59,780
Python 再写点东西 这次我会建两个不同的长数组

199
00:13:59,940 --> 00:14:02,375
每个中会有 100,000 个随机元素 监测一下 

200
00:14:02,375 --> 00:14:04,909
NumPy 库中 convolve 函数的运行时间 

201
00:14:04,909 --> 00:14:07,540
{\pos(1045, 1060)}{\fs40}卷积

202
00:14:08,180 --> 00:14:12,094
在这个案例中 它输出的是多次迭代中的平均用时 

203
00:14:12,094 --> 00:14:16,520
至少在这台计算机上  看起来平均用时是 4.87 秒

204
00:14:16,960 --> 00:14:19,103
然而 如果我改用 SciPy 库中的 

205
00:14:19,103 --> 00:14:22,149
fftconvolve 函数 {\pos(1310, 

206
00:14:22,149 --> 00:14:25,534
1060)}{\fs40}快速傅里叶变换卷积 它们功能一样 

207
00:14:25,534 --> 00:14:28,693
 只是实现方法不一样 这次计算平均只用了 4.3 毫秒 

208
00:14:28,693 --> 00:14:30,160
这可是 3 个数量级的优化

209
00:14:30,160 --> 00:14:33,027
再强调一下 即使它们的名字不同 

210
00:14:33,027 --> 00:14:36,611
但它和另一个卷积函数给出的输出是相同的 

211
00:14:36,611 --> 00:14:39,120
只是用了某种更巧妙的计算方法

212
00:14:42,200 --> 00:14:47,528
还记得刚才那个概率论的例子吗 我提到了另一种考虑卷积的方式 

213
00:14:47,528 --> 00:14:52,680
就是建立这个表格来计算各组合的乘积 然后沿着每条对角线求和

214
00:14:53,660 --> 00:14:56,066
当然 这办法不只在概率论里用得上 

215
00:14:56,066 --> 00:14:59,040
只要是要求两个数组的卷积时 你都能这么思考

216
00:14:59,040 --> 00:15:04,127
先建一个表格来计算组合乘积 再沿每条对角线求和 

217
00:15:04,127 --> 00:15:06,460
就对应着每一个输出结果

218
00:15:07,600 --> 00:15:12,800
有一种情况会让这种视角显得非常自然 就是当将两个多项式相乘时

219
00:15:13,300 --> 00:15:18,169
比如用这个我们已经有的网格 将上方的项替换为 1, 

220
00:15:18,169 --> 00:15:23,600
2x 和 3x² 将左侧的项替换为 4, 5x 和 6x²

221
00:15:24,000 --> 00:15:28,840
然后来思考一下 这些组合的乘积意味着什么

222
00:15:29,040 --> 00:15:34,981
其实本质上你在做一个多项式展开 即求两个多项式的全乘积 

223
00:15:34,981 --> 00:15:40,710
当你沿对角线求和 其实就是在合并同类项 非常简洁优雅 

224
00:15:40,710 --> 00:15:46,440
扩展多项式然后合并同类项 其实和卷积的过程是一模一样的

225
00:15:47,740 --> 00:15:52,340
基于此我们可以做些更棒的事情 稍微回想一下我们在做的事情

226
00:15:52,340 --> 00:15:56,182
我们是将两个不同的函数 进行相乘 

227
00:15:56,182 --> 00:16:00,703
也就是进行一个简单的逐点运算 这相当于 

228
00:16:00,703 --> 00:16:05,223
假设他们为多项式 首先提取多项式的系数 

229
00:16:05,223 --> 00:16:08,840
然后对这些系数组成的数组进行卷积

230
00:16:09,620 --> 00:16:15,206
非常有意思的是 卷积看起来要比直接相乘复杂那么一点儿 

231
00:16:15,206 --> 00:16:20,586
我不光是说它在概念上更难理解 我的意思是相比较对两个

232
00:16:20,586 --> 00:16:25,760
数组进行逐点乘积来说 卷积需要更多的步骤来执行计算

233
00:16:26,320 --> 00:16:30,600
打个比方 我这有俩很长很长的多项式 每个有 

234
00:16:30,600 --> 00:16:35,269
100 个项和相应的系数 如果你通过相乘系数的办

235
00:16:35,269 --> 00:16:39,938
法来展开多项式 你就要填满这个 100×100 

236
00:16:39,938 --> 00:16:44,607
的数组乘积网格 这意味着你得先做一万次乘法运算 

237
00:16:44,607 --> 00:16:49,860
然后当沿着对角线合并同类项时 你得再执行大约一万次操作

238
00:16:50,700 --> 00:16:55,831
更专业一点 我们可以说这是 O(N²) 的算法 意思是说 

239
00:16:55,831 --> 00:17:01,140
 两个含 N 个数的数组 需要执行操作的次数与 N² 成正比

240
00:17:01,820 --> 00:17:05,603
然而 如果我只考虑多项式的函数输出值 

241
00:17:05,603 --> 00:17:09,188
比如只对少数几个输入值进行采样计算 

242
00:17:09,188 --> 00:17:12,972
那么乘法运算的执行次数就等于样本数量 

243
00:17:12,972 --> 00:17:17,552
因为这也是一个逐点操作 并且说回多项式的情况 

244
00:17:17,552 --> 00:17:20,540
只需有限的样本量就足以重现系数

245
00:17:20,540 --> 00:17:25,060
比如 两个函数输出值就能确定一个唯一的线性多项式

246
00:17:25,660 --> 00:17:29,400
三个函数输出值就能确定一个唯一的二次多项式

247
00:17:29,640 --> 00:17:33,449
而且一般来说 如果你知道 N 个函数输出值 

248
00:17:33,449 --> 00:17:36,740
就足以确定一个唯一的 N-1 次多项式

249
00:17:37,440 --> 00:17:40,720
或者我们也可以用方程组的形式来表述

250
00:17:41,200 --> 00:17:45,042
假设我有一些多项式 但是我不告诉你它们的系数是什么 

251
00:17:45,042 --> 00:17:46,520
它们对你来说是未知的

252
00:17:46,700 --> 00:17:50,180
在我们的例子里 你可能会认为这其实就是我们要求出的乘积

253
00:17:50,180 --> 00:17:53,818
如果假设 我只告诉你这个多项式的输出值 

254
00:17:53,818 --> 00:17:58,548
假如你指定了不同的输入值如 0 1 2 3 ... 

255
00:17:58,548 --> 00:18:03,460
等等 并且我给你提供 与未知系数的个数相同数量的方程式

256
00:18:04,140 --> 00:18:07,340
简直太棒了 它甚至恰好是一个线性方程组

257
00:18:07,780 --> 00:18:10,900
原则上 这已经足够用来恢复系数了

258
00:18:11,740 --> 00:18:16,277
所以粗略的算法大纲为 当需要对两个数组进行卷积时 

259
00:18:16,277 --> 00:18:19,000
可以把它们视为两个多项式的系数

260
00:18:19,420 --> 00:18:25,658
对这些多项式的输出值尽可能多地采样 对这些样本逐点相乘 

261
00:18:25,658 --> 00:18:30,560
然后求解并恢复出系数 这就是为卷积找了个捷径

262
00:18:31,420 --> 00:18:35,120
目前为止 正如我所说的那样 有些同学可能会抱怨说 

263
00:18:35,120 --> 00:18:37,340
 Grant  这点子可太蠢了

264
00:18:37,580 --> 00:18:42,356
因为一方面 只是计算其中一个已知多项式的所有样本 

265
00:18:42,356 --> 00:18:46,559
算法的时间复杂度就已经到了 O(N²) 了 

266
00:18:46,559 --> 00:18:52,100
更别说要对整个系统进行计算了 那和一开始就做卷积没有啥区别

267
00:18:52,600 --> 00:18:56,540
是的 在函数相乘和做卷积之间存在着联系 

268
00:18:56,540 --> 00:19:00,480
但是所有的复杂性都发生在视角转化的过程中

269
00:19:01,600 --> 00:19:04,996
当然 这里有一个技巧 有些同学如果了解傅里叶变换和 

270
00:19:04,996 --> 00:19:07,740
FFT 算法的话 可能已经看懂这是咋回事了

271
00:19:07,740 --> 00:19:09,896
但如果你对这些话题不熟悉的话 接下

272
00:19:09,896 --> 00:19:12,180
来要讲的东西可能会让你有点摸不着头脑

273
00:19:12,260 --> 00:19:14,383
现在你只需要知道 存在某种数学方法 

274
00:19:14,383 --> 00:19:16,860
一旦了解了以后  很多事情就变得顺理成章了

275
00:19:17,720 --> 00:19:20,360
基本思路就是这里我们有一些自由的选择

276
00:19:20,540 --> 00:19:24,929
如果不像原来那样 输入任意数字集合如 0 1 

277
00:19:24,929 --> 00:19:29,700
2 3 等等来计算 而是替换为输入特定的复数来求解

278
00:19:30,240 --> 00:19:34,840
尤其是在单位圆上均匀分布的那些 所谓的单位根的话

279
00:19:35,200 --> 00:19:36,880
我们就得到了一个更友好的系统

280
00:19:38,360 --> 00:19:44,473
基本思路就是 找到一个取幂时输出总在单位圆上循环的数就行了 

281
00:19:44,473 --> 00:19:50,180
于是 我们生成的系统 在计算的不同项中会出现很多的冗余 

282
00:19:50,180 --> 00:19:54,460
巧妙地利用这些冗余 可以帮我们省下很多功夫

283
00:19:56,020 --> 00:20:02,280
这个输出集合有一个特定名字 叫作系数的离散傅里叶变换

284
00:20:02,500 --> 00:20:05,608
如果你想了解更多 我还在同一门 Julia 

285
00:20:05,608 --> 00:20:09,140
MIT 课程上过另一堂课 都是关于离散傅里叶变换的

286
00:20:09,220 --> 00:20:12,323
Reducible 频道也有一期很棒的视频 

287
00:20:12,323 --> 00:20:14,721
介绍了快速傅里叶变换 (FFT) 

288
00:20:14,721 --> 00:20:17,120
这种算法可以让以上这些计算变得更快

289
00:20:17,480 --> 00:20:19,887
真理元素最近也做了一支关于 FFT 

290
00:20:19,887 --> 00:20:21,760
的优质视频 总有一期能满足你

291
00:20:22,260 --> 00:20:24,660
而这种快速算法确实是我们的重点

292
00:20:25,120 --> 00:20:29,343
再强调一下 多亏了这些冗余 我们才能更快速地把系数  

293
00:20:29,343 --> 00:20:33,724
转换到这些输出点 原来需要复杂度为 O(N²) 的操作 

294
00:20:33,724 --> 00:20:37,479
现在只需 O(N log N) 输入数组越大  

295
00:20:37,479 --> 00:20:39,200
这个方法的优势就越明显

296
00:20:39,660 --> 00:20:42,540
更重要的是 FFT 还可以反过来用

297
00:20:42,700 --> 00:20:45,480
你也可以从输出对应到系数

298
00:20:46,220 --> 00:20:49,060
有了以上的知识 我们来回顾一下我们的算法大纲

299
00:20:49,420 --> 00:20:54,009
只要我们有两个长数组 想要计算它们的卷积的话 

300
00:20:54,009 --> 00:20:58,797
首先分别计算它们的快速傅里叶变换 在你的脑海中 

301
00:20:58,797 --> 00:21:02,389
你可以把这些数看作是 多项式的系数 

302
00:21:02,389 --> 00:21:06,380
再将他们作为一系列具有特殊性质的点来处理

303
00:21:06,900 --> 00:21:11,370
然后将两个结果逐点相乘 这还挺容易的 

304
00:21:11,370 --> 00:21:17,252
然后做一个快速傅里叶逆变换  我们就得到了一个计算

305
00:21:17,252 --> 00:21:18,900
卷积的取巧方法

306
00:21:19,040 --> 00:21:22,240
但是这回 它的复杂度仅为 O(N log N)

307
00:21:23,140 --> 00:21:24,740
太神奇了

308
00:21:25,120 --> 00:21:29,430
尽管用到卷积的情景仅仅是多项式相乘 但它引出了 

309
00:21:29,430 --> 00:21:34,100
FFT 任何使用卷积的地方 都能看到 FFT 的身影

310
00:21:34,180 --> 00:21:39,000
比如 在一些大型图像处理中 添加一些概率分布之类的东西

311
00:21:39,220 --> 00:21:43,350
这有力地证明了 一个值得我们兴奋的情形在于   

312
00:21:43,350 --> 00:21:47,480
看似无关的几个领域  出现了相同的数学运算或概念

313
00:21:48,480 --> 00:21:51,500
想要课后练习的话 我留一道思考题

314
00:21:51,720 --> 00:21:54,698
请解释：当你将两个不同的数字相乘时 

315
00:21:54,698 --> 00:21:57,677
就是我们在小学都学过的普通乘法那种 

316
00:21:57,677 --> 00:22:01,980
为什么你所做的事 大体相当于求“两数各个数位”的卷积

317
00:22:02,500 --> 00:22:06,460
会用到进位之类的额外步骤 不过核心步骤还是卷积

318
00:22:07,280 --> 00:22:10,813
而由于这个快速算法的存在 这就意味着如果你要

319
00:22:10,813 --> 00:22:15,310
乘两个非常大的整数 那么就有这么一种找到它们乘积的办法 

320
00:22:15,310 --> 00:22:17,880
要比我们在小学时学的方法要快得多

321
00:22:18,140 --> 00:22:21,451
复杂度从 O(N²) 一下降到了 O(N 

322
00:22:21,451 --> 00:22:24,920
log N) 有一种这本来没理由做得到的感觉

323
00:22:25,380 --> 00:22:30,840
要注意的是 要让这件事变得值得 你的两个乘数必须大得可怕

324
00:22:31,220 --> 00:22:33,860
不管怎样这种算法存在的本身就非常美妙

325
00:22:35,160 --> 00:22:37,616
下一期 我们要把目光转向连续卷积 

326
00:22:37,616 --> 00:22:39,640
并且会特别讨论概率分布的情况

