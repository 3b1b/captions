[
 {
  "input": "Last week I put up this video about solving the game Wordle, or at least trying to solve it, using information theory. ",
  "translatedText": "هفته گذشته این ویدیو را در مورد حل بازی Wordle یا حداقل تلاش برای حل آن با استفاده از تئوری اطلاعات قرار دادم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.18
 },
 {
  "input": "And I wanted to add a quick, what should we call this, an addendum? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 6.58,
  "end": 9.78
 },
 {
  "input": "A confession? ",
  "translatedText": "و من می خواستم سریع اضافه کنم، اسمش را چه بگذاریم، یک الحاقیه، یک اعتراف، اساساً فقط می خواهم جایی را توضیح دهم که در آن اشتباه کردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.08,
  "end": 10.66
 },
 {
  "input": "Basically I just want to explain a place where I made a mistake. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.02,
  "end": 13.9
 },
 {
  "input": "It turns out there was a very slight bug in the code that I was running to recreate Wordle and then run all of the algorithms to solve it and test their performance. ",
  "translatedText": "به نظر می رسد یک اشکال بسیار جزئی در کد وجود دارد که من برای ایجاد مجدد Wordle و سپس اجرای همه الگوریتم ها برای حل آن و آزمایش عملکرد آنها اجرا می کردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.46,
  "end": 22.0
 },
 {
  "input": "And it's one of those bugs that affects a very small percentage of cases, so it was easy to miss, and it has only a very slight effect that for the most part doesn't really matter. ",
  "translatedText": "و این یکی از آن اشکالاتی است که درصد بسیار کمی از موارد را تحت تأثیر قرار می دهد، بنابراین به راحتی می توان آن را از دست داد، و فقط یک تأثیر بسیار جزئی دارد که در بیشتر موارد واقعاً مهم نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.6,
  "end": 30.5
 },
 {
  "input": "Basically it had to do with how you assign a color to a guess that has multiple different letters in it. ",
  "translatedText": "اساساً به نحوه اختصاص یک رنگ به حدسی که دارای چندین حروف مختلف است مربوط می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.22,
  "end": 36.36
 },
 {
  "input": "For example, if you guess speed and the true answer is abide, how should you color those two e's from the guess? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 36.52,
  "end": 42.12
 },
 {
  "input": "Well the way that it works with the Wordle conventions is that the first e would be colored yellow, and the second one would be colored gray. ",
  "translatedText": "به عنوان مثال، اگر سرعت را حدس بزنید و پاسخ واقعی رعایت شود، چگونه باید آن دو e را از حدس بزنید؟ روشی که با قراردادهای Wordle کار می‌کند این است که اولین e زرد و دومی خاکستری خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.06,
  "end": 49.08
 },
 {
  "input": "You might think of that first one as matching up with something from the true answer, and the grayness is telling you there is no second e. ",
  "translatedText": "ممکن است فکر کنید که اولین مورد با چیزی از پاسخ واقعی مطابقت دارد، و خاکستری بودن به شما می گوید که e دومی وجود ندارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 49.6,
  "end": 55.52
 },
 {
  "input": "By contrast, if the answer was something like erase, both of those e's would be colored yellow, telling you that there is a first e in a different location, and there's a second e also in a different location. ",
  "translatedText": "در مقابل، اگر پاسخ چیزی شبیه پاک کردن بود، هر دو e به رنگ زرد خواهند بود و به شما می‌گویند که یک e اول در مکان دیگری وجود دارد، و یک e دوم نیز در مکان دیگری وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.52,
  "end": 66.78
 },
 {
  "input": "Similarly if one of the e's hits and it's green, then that second one would be gray in the case where the true answer has no second e, but it would be yellow in the case where there is a second e and it's just in a different location. ",
  "translatedText": "به طور مشابه اگر یکی از e ها برخورد کند و سبز باشد، آن دومی خاکستری خواهد بود در صورتی که پاسخ واقعی e دومی نداشته باشد، اما در صورتی که یک e دوم وجود داشته باشد و فقط در یک متفاوت باشد، زرد خواهد بود. محل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.3,
  "end": 80.04
 },
 {
  "input": "Long story short, somewhere along the way I accidentally introduced behavior that differs from these conventions slightly. ",
  "translatedText": "به طور خلاصه، جایی در طول مسیر من به طور تصادفی رفتاری را معرفی کردم که کمی با این قراردادها متفاوت است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.7,
  "end": 86.4
 },
 {
  "input": "Honestly it was really dumb. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.1,
  "end": 88.54
 },
 {
  "input": "Basically at some point in the middle of the project I wanted to speed up some of the computations, and I was trying a little trick for how it computed the value for this pattern between any given pair of words, and you know I just didn't really think it through and it introduced this slight change. ",
  "translatedText": "راستش واقعا احمقانه بود اساساً در نقطه‌ای در میانه‌ی پروژه، می‌خواستم برخی از محاسبات را تسریع کنم، و سعی می‌کردم یک ترفند کوچک برای اینکه چگونه مقدار این الگو را بین هر جفت کلمه محاسبه کند، و می‌دانید که من این کار را نکردم. واقعاً به آن فکر کنید و این تغییر جزئی را ایجاد کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.88,
  "end": 102.72
 },
 {
  "input": "The ironic part is that in the end the actual way to make things fastest is to pre-compute all those patterns so that everything is just a lookup, and so it wouldn't matter how long it takes to do each one, especially if you're writing hard to read buggy code to make it happen. ",
  "translatedText": "قسمت طعنه آمیز این است که در نهایت راه واقعی برای سریع‌ترین کار این است که همه آن الگوها را از قبل محاسبه کنید تا همه چیز فقط یک جستجو باشد، و بنابراین مهم نیست که چقدر طول می‌کشد تا هر کدام را انجام دهید، به خصوص اگر خواندن کدهای باگ سخت می نویسم تا این اتفاق بیفتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.22,
  "end": 115.84
 },
 {
  "input": "You know, you live and you learn. ",
  "translatedText": "می دانید، زندگی می کنید و یاد می گیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.4,
  "end": 117.24
 },
 {
  "input": "As far as how this affects the actual video, I mean very little of substance really changes. ",
  "translatedText": "تا آنجا که این موضوع بر روی ویدیوی واقعی تأثیر می‌گذارد، منظور من از تغییرات بسیار اندکی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.04,
  "end": 122.34
 },
 {
  "input": "Of course the main lessons about what is information, what is entropy, all that stays the same. ",
  "translatedText": "البته درس های اصلی در مورد اینکه اطلاعات چیست، آنتروپی چیست، همه چیز ثابت می ماند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.66,
  "end": 126.56
 },
 {
  "input": "Every now and then if I'm showing on screen some distribution associated with a given word, that distribution might actually be a little bit off because some of the buckets associated with various patterns should include either more or fewer true answers. ",
  "translatedText": "هرازگاهی اگر توزیعی مرتبط با یک کلمه معین را روی صفحه نمایش بدهم، آن توزیع ممکن است در واقع کمی کم باشد زیرا برخی از سطل های مرتبط با الگوهای مختلف باید شامل پاسخ های بیشتر یا کمتر واقعی باشند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.86,
  "end": 140.32
 },
 {
  "input": "Even then it doesn't really come up because it was very rare that I would be showing a word that had multiple letters that also hit this edge case. ",
  "translatedText": "حتی در آن زمان هم واقعاً مطرح نمی‌شود، زیرا بسیار نادر بود که کلمه‌ای را نشان دهم که دارای حروف متعددی باشد که به این حاشیه نیز برخورد کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.84,
  "end": 146.96
 },
 {
  "input": "But one of the very few things of substance that does change and that arguably does matter a fair bit was the final conclusion around how if we want to find the optimal possible score for the wordle answer list, what opening guess does such an algorithm use? ",
  "translatedText": "اما یکی از معدود چیزهای ماهوی که تغییر می کند و مسلماً کمی اهمیت دارد، نتیجه گیری نهایی درباره این بود که چگونه اگر بخواهیم نمره بهینه ممکن را برای لیست پاسخ wordle پیدا کنیم، چنین الگوریتمی از چه حدس اولیه استفاده می کند؟ در ویدیو من گفتم بهترین عملکردی که می‌توانم پیدا کنم از باز کردن کلمه جرثقیل حاصل شد، که فقط از این نظر درست بود که الگوریتم‌ها بازی بسیار کمی متفاوتی را انجام می‌دادند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.68,
  "end": 162.46
 },
 {
  "input": "In the video I said the best performance that I could find came from opening with the word crane, which was true only in the sense that the algorithms were playing a very slightly different game. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.08,
  "end": 172.56
 },
 {
  "input": "After fixing it and rerunning it all, there is a different answer for what the theoretically optimal first guess is for this particular list. ",
  "translatedText": "پس از رفع آن و اجرای مجدد همه، پاسخ متفاوتی برای اینکه حدس اول از لحاظ نظری برای این لیست خاص چیست، وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.16,
  "end": 180.16
 },
 {
  "input": "And look, I know that you know that the point of the video is not to find some technically optimal answer to some random online game. ",
  "translatedText": "و ببینید، من می‌دانم که می‌دانید هدف ویدیو یافتن پاسخ فنی بهینه برای یک بازی آنلاین تصادفی نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.0,
  "end": 189.1
 },
 {
  "input": "The point of the video is to shamelessly hop on the bandwagon of an internet trend to sneak attack people with an information theory lesson. ",
  "translatedText": "هدف این ویدیو این است که بی‌شرمانه روی یک گرایش اینترنتی سوار شوید تا با درس تئوری اطلاعات به مردم حمله کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.46,
  "end": 195.9
 },
 {
  "input": "And that's all good, I stand by that part. ",
  "translatedText": "و این همه خوب است، من روی آن قسمت ایستاده ام. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.32,
  "end": 198.0
 },
 {
  "input": "But I know how the internet works, and for a lot of people the one main takeaway was what is the best opener for the game wordle. ",
  "translatedText": "اما من می‌دانم اینترنت چگونه کار می‌کند، و برای بسیاری از مردم یک نکته اصلی این بود که بهترین بازکننده برای wordle بازی چیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 204.6
 },
 {
  "input": "And I get it, I walked into that because I put it in the thumbnail, but presumably you can forgive me if I want to add a little correction here. ",
  "translatedText": "و متوجه شدم، چون آن را در تصویر کوچک قرار دادم وارد آن شدم، اما احتمالاً اگر بخواهم اصلاح کوچکی در اینجا اضافه کنم، می توانید مرا ببخشید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.28,
  "end": 211.86
 },
 {
  "input": "And a more meaningful reason to circle back to all this actually is that I never really talked about what went into that final analysis. ",
  "translatedText": "و یک دلیل معنادارتر برای بازگشت به همه اینها در واقع این است که من هرگز واقعاً در مورد آنچه در آن تحلیل نهایی آمده صحبت نکردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.98,
  "end": 218.34
 },
 {
  "input": "And it's interesting as a sublesson in its own right, so it's worth doing here. ",
  "translatedText": "و در نوع خود به عنوان یک درس فرعی جالب است، بنابراین ارزش انجام آن را در اینجا دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.84,
  "end": 222.42
 },
 {
  "input": "Now if you'll recall, most of our time last video was spent on the challenge of trying to write an algorithm to solve wordle that did not use the official list of all possible answers. ",
  "translatedText": "حالا اگر به خاطر داشته باشید، بیشتر وقت ویدیوی قبلی ما صرف چالش نوشتن الگوریتمی برای حل wordle شد که از لیست رسمی همه پاسخ‌های ممکن استفاده نمی‌کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.14,
  "end": 232.46
 },
 {
  "input": "To my taste, that feels a bit like overfitting to a test set, and what's more fun is building something that's resilient. ",
  "translatedText": "به سلیقه من، این احساس کمی شبیه به تناسب بیش از حد برای یک مجموعه آزمایشی است، و جالب‌تر ساختن چیزی است که انعطاف‌پذیر باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.48
 },
 {
  "input": "This is why we went through the whole process of looking at relative word frequencies in the English language to come up with some notion of how likely each one would be to be included as a final answer. ",
  "translatedText": "به همین دلیل است که ما کل فرآیند بررسی فراوانی های نسبی کلمات در زبان انگلیسی را طی کردیم تا به تصوری مبنی بر اینکه چقدر احتمال دارد هر یک به عنوان پاسخ نهایی گنجانده شود، برسیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.9,
  "end": 248.76
 },
 {
  "input": "However, for what we're doing here, where we're just trying to find an absolute best performance period, I am incorporating that official list and just shamelessly overfitting to the test set, which is to say we know with certainty whether a word is included or not, and we can assign a uniform probability to each one. ",
  "translatedText": "با این حال، برای کاری که ما در اینجا انجام می دهیم، جایی که ما فقط سعی می کنیم بهترین دوره عملکرد مطلق را پیدا کنیم، من آن لیست رسمی را وارد می کنم و به طرز بی شرمانه ای بیش از حد به مجموعه تست تطبیق داده می شود، یعنی می گوییم ما با اطمینان می دانیم که آیا یک کلمه گنجانده شده است یا خیر، و ما می توانیم یک احتمال یکسان را به هر یک اختصاص دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.4,
  "end": 265.46
 },
 {
  "input": "If you'll remember, the first step in all of this was to say for a particular opening guess, maybe something like my old favorite, crane, how likely is it that you would see each of the possible patterns? ",
  "translatedText": "اگر به خاطر داشته باشید، اولین قدم در همه این‌ها این بود که برای حدس اولیه‌ای خاص بگوییم، شاید چیزی شبیه مورد علاقه قدیمی من، جرثقیل، چقدر احتمال دارد که هر یک از الگوهای ممکن را ببینید؟ و در این زمینه، جایی که ما بی‌شرمانه بیش از حد به فهرست پاسخ‌های wordle تناسب داریم، تنها چیزی که شامل شمارش این است که چه تعداد از پاسخ‌های ممکن به هر یک از این الگوها می‌دهند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 266.44,
  "end": 276.18
 },
 {
  "input": "And in this context, where we are shamelessly overfitting to the wordle answer list, all that involves is counting how many of the possible answers give each one of these patterns. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.68,
  "end": 285.34
 },
 {
  "input": "And then of course most of our time was spent on this kind of funny looking formula to quantify the amount of information that you would get from this guess that basically involves going through each one of those buckets and saying how much information would you gain that has this log expression that is a fanciful way of saying how many times would you cut your space of possibilities in half if you observed a given pattern. ",
  "translatedText": "و البته بیشتر وقت ما صرف این نوع فرمول خنده‌دار می‌شود تا مقدار اطلاعاتی را که از این حدس به دست می‌آورید را کمی کنیم که اساساً شامل مرور هر یک از آن سطل‌ها و گفتن اینکه چقدر اطلاعات به دست می‌آورید، می‌شود. این عبارت لاگ که روشی خیال انگیز برای گفتن است که اگر یک الگوی مشخص را مشاهده کنید، چند بار فضای احتمالات خود را نصف می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.98,
  "end": 306.84
 },
 {
  "input": "We take a weighted average of all of those and it gives us a measure of how much we expect to learn from this first guess. ",
  "translatedText": "ما میانگین وزنی همه آنها را می گیریم و به ما اندازه گیری می کند که چقدر انتظار داریم از این حدس اول یاد بگیریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.6,
  "end": 313.18
 },
 {
  "input": "In a moment we'll go deeper than this, but if you simply search through all 13,000 different words that you could start with and you ask which one has the highest expected information, it turns out the best possible answer is soar, which doesn't really look like a real word, but I guess it's an obsolete term for a baby hawk. ",
  "translatedText": "در یک لحظه ما عمیق تر از این خواهیم شد، اما اگر شما به سادگی در تمام 13000 کلمه مختلف که می توانید با آنها شروع کنید جستجو کنید و بپرسید کدام یک بالاترین اطلاعات مورد انتظار را دارد، معلوم می شود که بهترین پاسخ ممکن اوج گرفتن است، که اینطور نیست. واقعاً شبیه یک کلمه واقعی به نظر می رسد، اما من حدس می زنم این یک اصطلاح منسوخ برای بچه شاهین است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.56,
  "end": 333.0
 },
 {
  "input": "The top 15 openers by this metric happen to look like this, but these are not necessarily the best opening guesses because they're only looking one step in with the heuristic of expected information to try to estimate what the true score will be. ",
  "translatedText": "15 بازکننده برتر بر اساس این معیار اتفاقاً به این شکل هستند، اما اینها لزوماً بهترین حدس‌های آغازین نیستند، زیرا آنها فقط یک مرحله را با اطلاعات اکتشافی اطلاعات مورد انتظار دنبال می‌کنند تا سعی کنند امتیاز واقعی را تخمین بزنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.04,
  "end": 347.54
 },
 {
  "input": "But there's few enough patterns that we can do an exhaustive search two steps in. ",
  "translatedText": "اما الگوهای کمی وجود دارد که بتوانیم در دو مرحله جستجوی جامع انجام دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.92,
  "end": 351.68
 },
 {
  "input": "For example, let's say you opened with soar and the pattern you happen to see was the most likely one, all grays, then you can run identical analysis from that point. ",
  "translatedText": "به عنوان مثال، فرض کنید شما با اوج گرفتن باز شدید و الگویی که مشاهده کردید محتمل ترین الگویی بود که تماما خاکستری بود، سپس می توانید تحلیل یکسانی را از آن نقطه انجام دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 352.16,
  "end": 360.8
 },
 {
  "input": "For a given proposed second guess, something like kitty, what's the distribution across all patterns in that restricted case where we're restricted only to the words that would produce all grays for soar, and then we measure the flatness of that distribution using this expected information formula, and we do that for all 13,000 possible words that we could use as a second guess. ",
  "translatedText": "برای یک حدس دوم پیشنهادی، چیزی شبیه به جلف، توزیع در همه الگوها در آن مورد محدود چگونه است که ما فقط به کلماتی محدود می‌شویم که تمام خاکستری‌ها را برای اوج گرفتن ایجاد می‌کنند، و سپس صافی آن توزیع را با استفاده از این مورد انتظار می‌سنجیم. فرمول اطلاعات، و ما این کار را برای تمام 13000 کلمه ممکن که می توانیم به عنوان حدس دوم استفاده کنیم، انجام می دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 361.32,
  "end": 381.42
 },
 {
  "input": "Doing this we can find the optimal second guess in that scenario and the amount of information we were expected to get from it, and if we wash rinse and repeat and do this for all of the different possible patterns that you might see, we get a full map of all the best possible second guesses together with the expected information of each. ",
  "translatedText": "با انجام این کار، می‌توانیم حدس دوم بهینه را در آن سناریو و مقدار اطلاعاتی که انتظار می‌رفت از آن به دست آوریم، پیدا کنیم، و اگر بشوییم، آبکشی کنیم و تکرار کنیم و این کار را برای همه الگوهای مختلف ممکن که ممکن است مشاهده کنید، به دست می‌آوریم. نقشه کامل تمام بهترین حدس های ممکن به همراه اطلاعات مورد انتظار هر کدام. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.12,
  "end": 399.2
 },
 {
  "input": "From there, if you take a weighted average of all those second step values, weighted according to how likely you are to fall into that bucket, it gives you a measure of how much information you're likely to gain from the guess soar after the second step. ",
  "translatedText": "از آنجا، اگر میانگین وزنی تمام مقادیر مرحله دوم را در نظر بگیرید، وزن آن بر اساس میزان احتمال افتادن در آن سطل، به شما اندازه‌گیری می‌کند که احتمالاً چه مقدار اطلاعات از این حدس پس از اوج گرفتن به دست خواهید آورد. مرحله دوم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.18,
  "end": 416.8
 },
 {
  "input": "When we use this two-step metric as our new means of ranking, the list gets shaken up a bit. ",
  "translatedText": "وقتی از این معیار دو مرحله‌ای به عنوان ابزار جدید رتبه‌بندی استفاده می‌کنیم، فهرست کمی متزلزل می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.38,
  "end": 421.78
 },
 {
  "input": "Soar is no longer first place, it falls back to 14th, and instead what rises to the top is slain. ",
  "translatedText": "اوج گرفتن دیگر جایگاه اول نیست، به رده چهاردهم سقوط می کند و در عوض آنچه به اوج می رسد کشته می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.08,
  "end": 427.66
 },
 {
  "input": "Again, doesn't feel very real, and it looks like it is a British term for a spade that's used for cutting turf. ",
  "translatedText": "باز هم، خیلی واقعی به نظر نمی رسد، و به نظر می رسد که یک اصطلاح انگلیسی برای بیل است که برای بریدن چمن استفاده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.64,
  "end": 436.38
 },
 {
  "input": "Alright, but as you can see it is a really tight race among all of these top contenders for who gains the most information after those two steps. ",
  "translatedText": "بسیار خوب، اما همانطور که می بینید، رقابت بسیار سختی در بین همه این مدعیان برتر برای اینکه چه کسی بعد از این دو مرحله بیشترین اطلاعات را به دست آورد، است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.2,
  "end": 445.0
 },
 {
  "input": "And even still, these are not necessarily the best opening guesses, because information is just the heuristic, it's not telling us the actual score if you actually play the game. ",
  "translatedText": "و حتی هنوز، اینها لزوماً بهترین حدس‌های آغازین نیستند، زیرا اطلاعات فقط اکتشافی است، اگر واقعاً بازی را انجام می‌دهید، امتیاز واقعی را به ما نمی‌گوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.7,
  "end": 454.0
 },
 {
  "input": "What I did is I ran the simulation of playing all 2315 possible wordle games with all possible answers on the top 250 from this list. ",
  "translatedText": "کاری که من انجام دادم این بود که شبیه سازی انجام تمام 2315 بازی wordle ممکن را با تمام پاسخ های ممکن در 250 مورد برتر از این لیست اجرا کردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.58,
  "end": 464.62
 },
 {
  "input": "And by doing this, seeing how they actually perform, the one that ends up very marginally with the best possible score turns out to be Salé, which is an alternate spelling for Salé, which is a light medieval helmet. ",
  "translatedText": "و با انجام این کار، با دیدن عملکرد واقعی آنها، یکی که در نهایت با بهترین امتیاز ممکن به پایان می رسد Salé است، که املای جایگزین Salé است، که یک کلاه ایمنی سبک قرون وسطایی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.46,
  "end": 485.98
 },
 {
  "input": "Alright, if that feels a little bit too fake for you, which it does for me, you'll be happy to know that Trace and Crate give almost identical performance. ",
  "translatedText": "بسیار خوب، اگر برای شما کمی بیش از حد جعلی به نظر می رسد، که برای من انجام می شود، خوشحال خواهید شد که بدانید Trace و Crate عملکرد تقریباً یکسانی دارند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.98,
  "end": 495.78
 },
 {
  "input": "Each of them has the benefit of obviously being a real word, so there is one day when you get it right on the first guess, since both are actual wordle answers. ",
  "translatedText": "هر یک از آنها این مزیت را دارند که آشکارا یک کلمه واقعی هستند، بنابراین یک روز وجود دارد که با اولین حدس آن را درست متوجه می شوید، زیرا هر دو پاسخ واقعی کلمه هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 496.3,
  "end": 504.06
 },
 {
  "input": "This move from sorting based on the best two-step entropies to sorting based on the lowest average score also shakes up the list, but not nearly as much. ",
  "translatedText": "این حرکت از مرتب‌سازی بر اساس بهترین آنتروپی‌های دو مرحله‌ای به مرتب‌سازی بر اساس کمترین میانگین امتیاز نیز فهرست را تکان می‌دهد، اما نه به اندازه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.02,
  "end": 512.46
 },
 {
  "input": "For example, Salé was previously third place before it bubbles to the top, and Crate and Trace were both fourth and fifth. ",
  "translatedText": "به عنوان مثال، Salé قبلاً در جایگاه سوم قرار داشت و قبل از اینکه به اوج برسد، Crate و Trace هر دو چهارم و پنجم بودند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.66,
  "end": 519.08
 },
 {
  "input": "If you're curious, you can get slightly better performance from here by doing a little brute forcing. ",
  "translatedText": "اگر کنجکاو هستید، می توانید از اینجا با انجام کمی اجبار بی رحمانه عملکرد کمی بهتر داشته باشید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.64,
  "end": 523.72
 },
 {
  "input": "There's a very nice blog post by Jonathan Olson, if you're curious about this, where he also lets you explore what the optimal following guesses are for a few of the starting words based on these optimal algorithms. ",
  "translatedText": "یک پست وبلاگ بسیار زیبا توسط جاناتان اولسون وجود دارد، اگر در مورد آن کنجکاو هستید، که در آن او همچنین به شما اجازه می‌دهد تا بررسی کنید که حدس‌های بهینه زیر برای چند کلمه آغازین بر اساس این الگوریتم‌های بهینه چیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.1,
  "end": 533.66
 },
 {
  "input": "Stepping back from all this though, I'm told by some people that it quote ruins the game to overanalyze it like this and try to find an optimal opening guess. ",
  "translatedText": "با این حال، از همه اینها عقب نشینی می کنم، برخی از افراد به من می گویند که این نقل قول بازی را خراب می کند تا آن را اینگونه بیش از حد تحلیل کنم و سعی کنم حدس بهینه افتتاحیه را پیدا کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.18,
  "end": 543.6
 },
 {
  "input": "You know, it feels kind of dirty if you use that opening guess after learning it, and it feels inefficient if you don't. ",
  "translatedText": "می دانید، اگر پس از یادگیری آن حدس اولیه را به کار ببرید، به نوعی کثیف به نظر می رسد، و اگر این کار را نکنید، احساس ناکارآمدی می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.26,
  "end": 549.66
 },
 {
  "input": "But the thing is, I don't actually think this is the best opener for a human playing the game. ",
  "translatedText": "اما موضوع این است که من واقعاً فکر نمی‌کنم این بهترین بازکننده برای یک انسان در حال بازی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.8,
  "end": 554.4
 },
 {
  "input": "For one thing, you would need to know what the optimal second guess is for each one of the patterns that you see. ",
  "translatedText": "برای یک چیز، باید بدانید که حدس دوم بهینه برای هر یک از الگوهایی که می بینید چیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.88,
  "end": 559.68
 },
 {
  "input": "And more importantly, all of this is in a setting where we are absurdly overfit to the official wordle answer list. ",
  "translatedText": "و مهمتر از آن، همه اینها در شرایطی است که ما به طرز عجیبی در لیست رسمی پاسخ wordle قرار داریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.26,
  "end": 566.36
 },
 {
  "input": "The moment that, say, the New York Times chooses to change what that list is under the hood, all of this would go out the window. ",
  "translatedText": "لحظه ای که مثلاً نیویورک تایمز انتخاب می کند فهرست زیر را تغییر دهد، همه اینها از پنجره بیرون می روند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.58,
  "end": 572.88
 },
 {
  "input": "The way that we humans play the game is just very different from what any of these algorithms are doing. ",
  "translatedText": "روشی که ما انسان ها بازی می کنیم با آنچه هر یک از این الگوریتم ها انجام می دهند بسیار متفاوت است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.58,
  "end": 577.68
 },
 {
  "input": "We don't have the word list memorized, we're not doing exhaustive searches, we get intuition from things like what are the vowels and how are they placed. ",
  "translatedText": "ما فهرست کلمات را حفظ نشده‌ایم، جستجوی جامع انجام نمی‌دهیم، از چیزهایی مانند اینکه حروف صدادار چیست و چگونه قرار می‌گیرند، شهود دریافت می‌کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.02,
  "end": 585.08
 },
 {
  "input": "I would actually be most happy if those of you watching this video promptly forgot what happens to be the technically best opening guess, and instead came out remembering things like how do you quantify information, or the fact that you should look out for when a greedy algorithm falls short of the globally best performance that you would get from a deeper search. ",
  "translatedText": "در واقع بسیار خوشحال خواهم شد اگر کسانی از شما که این ویدیو را تماشا می‌کنند، فوراً فراموش کنند که چه چیزی از نظر فنی بهترین حدس افتتاحیه است، و در عوض چیزهایی را به خاطر بسپارید، مانند اینکه چگونه اطلاعات را کمیت می‌کنید، یا این واقعیت را که باید به هنگام یک حریص مراقب باشید. الگوریتم از بهترین عملکرد جهانی که از جستجوی عمیق تر بدست می آورید، کوتاه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 585.64,
  "end": 603.1
 },
 {
  "input": "For my taste at least, the joy of writing algorithms to try to play games actually has very little bearing on how I like to play those games as a human. ",
  "translatedText": "حداقل برای سلیقه من، لذت نوشتن الگوریتم‌ها برای انجام بازی‌ها در واقع تأثیر بسیار کمی بر نحوه انجام آن بازی‌ها به عنوان یک انسان دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.7,
  "end": 610.76
 },
 {
  "input": "The point of writing algorithms for all this is not to affect the way that we play the game, it's still just a fun word game. ",
  "translatedText": "هدف از نوشتن الگوریتم برای همه اینها این نیست که بر نحوه بازی ما تأثیر بگذارد، هنوز هم فقط یک بازی سرگرم کننده با کلمات است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.3,
  "end": 616.78
 },
 {
  "input": "It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere. ",
  "translatedText": "این برای تقویت عضلات خود برای نوشتن الگوریتم ها در زمینه های معنادارتر در جاهای دیگر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.1,
  "end": 620.72
 }
]