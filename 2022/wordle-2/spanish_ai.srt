1
00:00:00,000 --> 00:00:04,800
La semana pasada publiqué este vídeo sobre cómo resolver el juego Wordle, o al menos intentar resolverlo, utilizando la

2
00:00:04,800 --> 00:00:09,920
teoría de la información. Y quería agregar algo rápido, cómo deberíamos llamarlo, un apéndice, una

3
00:00:09,920 --> 00:00:14,240
confesión. Básicamente, solo quiero explicar un lugar en el que cometí un error.

4
00:00:14,240 --> 00:00:18,880
Resulta que había un error muy leve en el código que estaba ejecutando para recrear Wordle

5
00:00:18,880 --> 00:00:23,040
y luego ejecutar todos los algoritmos para resolverlo y probar su rendimiento. Y es uno de esos

6
00:00:23,040 --> 00:00:27,760
errores que afecta a un porcentaje muy pequeño de casos, por lo que era fácil pasarlo por alto, y

7
00:00:27,760 --> 00:00:32,080
tiene sólo un efecto muy leve que en su mayor parte realmente no importa. Básicamente tenía que ver con

8
00:00:32,080 --> 00:00:36,880
cómo se asigna un color a una suposición que tiene varias letras diferentes. Por ejemplo, si

9
00:00:36,880 --> 00:00:42,080
adivinas la velocidad y la respuesta verdadera es respetar, ¿cómo deberías colorear esas dos e de la suposición?

10
00:00:42,800 --> 00:00:46,640
Bueno, la forma en que funciona con las convenciones de Wordle es que la primera e sería de color

11
00:00:46,640 --> 00:00:51,120
amarillo y la segunda sería de color gris. Podrías pensar que la primera coincide con algo de

12
00:00:51,120 --> 00:00:56,000
la respuesta verdadera, y el tono gris te dice que no hay una segunda e.

13
00:00:56,000 --> 00:01:01,200
Por el contrario, si la respuesta fuera algo así como borrar, ambas e se colorearían de amarillo, lo que

14
00:01:01,200 --> 00:01:05,920
indicaría que hay una primera e en una ubicación diferente y que hay una segunda e también en

15
00:01:05,920 --> 00:01:10,960
una ubicación diferente. De manera similar, si una de las e acierta y es verde, entonces esa segunda sería gris

16
00:01:10,960 --> 00:01:17,280
en el caso en que la respuesta verdadera no tenga una segunda e, pero sería amarilla en el caso en que

17
00:01:17,280 --> 00:01:21,920
haya una segunda e y esté simplemente en una dirección diferente. ubicación. En pocas palabras, en algún

18
00:01:21,920 --> 00:01:26,240
momento introduje accidentalmente un comportamiento que difiere ligeramente de estas convenciones.

19
00:01:26,960 --> 00:01:31,680
Sinceramente, fue realmente tonto. Básicamente, en algún momento a mitad del proyecto quería acelerar algunos de

20
00:01:31,680 --> 00:01:35,840
los cálculos, y estaba probando un pequeño truco sobre cómo calcular el valor de este patrón

21
00:01:35,840 --> 00:01:40,640
entre cualquier par de palabras determinado, y ya sabes, simplemente lo hice. Realmente no lo

22
00:01:40,640 --> 00:01:45,600
pensé bien e introdujo este ligero cambio. La parte irónica es que, al final, la forma real

23
00:01:45,600 --> 00:01:50,080
de hacer las cosas más rápidas es precalcular todos esos patrones para que todo sea solo una búsqueda, por

24
00:01:50,080 --> 00:01:54,000
lo que no importaría cuánto tiempo lleve hacer cada uno, especialmente si Estamos escribiendo código con errores difíciles

25
00:01:54,000 --> 00:01:59,040
de leer para que esto suceda. Ya sabes, vives y aprendes. En cuanto a cómo esto afecta

26
00:01:59,040 --> 00:02:03,760
el video real, quiero decir que realmente hay muy pocos cambios sustanciales. Por supuesto, las principales lecciones sobre

27
00:02:03,760 --> 00:02:08,160
qué es información y qué es entropía, todo eso sigue igual. De vez en cuando, si muestro

28
00:02:08,160 --> 00:02:13,360
en pantalla alguna distribución asociada con una palabra determinada, esa distribución podría en realidad estar un

29
00:02:13,360 --> 00:02:18,000
poco fuera de lugar porque algunos de los grupos asociados con varios patrones deberían incluir

30
00:02:18,000 --> 00:02:22,960
más o menos respuestas verdaderas. Incluso entonces, realmente no aparece porque era muy raro que mostrara

31
00:02:22,960 --> 00:02:28,400
una palabra que tuviera varias letras que también llegaran a este caso límite. Pero una

32
00:02:28,400 --> 00:02:33,680
de las pocas cosas sustanciales que sí cambia y que posiblemente sí importa bastante fue la conclusión

33
00:02:33,680 --> 00:02:40,240
final sobre cómo, si queremos encontrar la puntuación óptima posible para la lista de respuestas de

34
00:02:40,240 --> 00:02:45,120
Wordle, ¿qué suposición inicial utiliza dicho algoritmo? En el vídeo dije que el mejor rendimiento que

35
00:02:45,120 --> 00:02:50,160
pude encontrar provino de abrir con la palabra grúa, lo cual era cierto sólo en el sentido de

36
00:02:50,160 --> 00:02:55,120
que los algoritmos estaban jugando un juego ligeramente diferente. Después de arreglarlo y volver a ejecutarlo todo,

37
00:02:55,120 --> 00:03:00,000
hay una respuesta diferente sobre cuál es la primera suposición teóricamente óptima para esta lista en particular.

38
00:03:00,800 --> 00:03:06,560
Y mira, sé que sabes que el objetivo del vídeo no es encontrar una respuesta técnicamente

39
00:03:06,560 --> 00:03:11,760
óptima a algún juego aleatorio en línea. El objetivo del vídeo es subirse descaradamente al tren de una

40
00:03:11,760 --> 00:03:16,240
tendencia de Internet para atacar furtivamente a las personas con una lección de teoría de la información.

41
00:03:16,240 --> 00:03:20,160
Y eso está bien, mantengo esa parte. Pero sé cómo funciona Internet y, para mucha gente,

42
00:03:20,160 --> 00:03:26,160
la principal conclusión fue cuál es el mejor comienzo para el juego. Y lo entiendo, entré

43
00:03:26,160 --> 00:03:30,480
en eso porque lo puse en la miniatura, pero probablemente me puedan perdonar si quiero agregar

44
00:03:30,480 --> 00:03:35,120
una pequeña corrección aquí. Y una razón más significativa para volver a todo esto es que

45
00:03:35,120 --> 00:03:39,440
en realidad nunca hablé sobre lo que entró en ese análisis final. Y es interesante como sublección

46
00:03:39,440 --> 00:03:44,560
en sí misma, por lo que vale la pena estudiarla aquí. Ahora bien, si recuerdas, dedicamos la mayor

47
00:03:44,560 --> 00:03:49,120
parte del tiempo del último video al desafío de intentar escribir un algoritmo para resolver palabras que

48
00:03:49,120 --> 00:03:54,320
no utilizaban la lista oficial de todas las respuestas posibles. Para mi gusto, eso se siente un poco como

49
00:03:54,320 --> 00:03:59,280
sobreadaptarse a un equipo de prueba, y lo que es más divertido es construir algo que sea resistente. Es por eso

50
00:03:59,280 --> 00:04:03,920
que pasamos por todo el proceso de observar las frecuencias relativas de palabras en el idioma inglés

51
00:04:03,920 --> 00:04:09,120
para tener una idea de la probabilidad de que cada una se incluyera como respuesta final.

52
00:04:09,120 --> 00:04:13,680
Sin embargo, para lo que estamos haciendo aquí, donde simplemente intentamos encontrar el mejor período de

53
00:04:13,680 --> 00:04:19,120
rendimiento absoluto, estoy incorporando esa lista oficial y simplemente sobreajustándola descaradamente al conjunto de prueba, es

54
00:04:19,120 --> 00:04:23,520
decir, sabemos con certeza si una palabra está incluido o no, y podemos asignar una

55
00:04:23,520 --> 00:04:28,560
probabilidad uniforme a cada uno. Si recuerdas, el primer paso en todo esto fue decir, para

56
00:04:28,560 --> 00:04:34,080
una suposición de apertura particular, tal vez algo como mi viejo favorito, crane, ¿qué probabilidad hay de

57
00:04:34,080 --> 00:04:38,560
que veas cada uno de los patrones posibles? Y en este contexto, donde nos estamos sobreajustando descaradamente

58
00:04:38,560 --> 00:04:43,440
a la lista de respuestas de Wordle, lo único que implica es contar cuántas de las posibles respuestas

59
00:04:43,440 --> 00:04:48,240
dan cada uno de estos patrones. Y luego, por supuesto, pasamos la mayor parte de nuestro

60
00:04:48,240 --> 00:04:53,040
tiempo en este tipo de fórmula de aspecto divertido para cuantificar la cantidad de información que

61
00:04:53,040 --> 00:04:57,520
obtendríamos de esta suposición que básicamente implica revisar cada uno de esos depósitos y decir cuánta

62
00:04:57,520 --> 00:05:02,720
información obtendríamos con eso. Esta expresión logarítmica es una forma imaginativa de decir cuántas veces reducirías

63
00:05:02,720 --> 00:05:08,160
tu espacio de posibilidades a la mitad si observaras un patrón determinado. Tomamos un promedio ponderado

64
00:05:08,160 --> 00:05:12,800
de todos ellos y nos da una medida de cuánto esperamos aprender de esta primera suposición.

65
00:05:12,800 --> 00:05:17,920
En un momento profundizaremos más, pero si simplemente buscas entre las 13.000 palabras diferentes con las

66
00:05:17,920 --> 00:05:22,880
que podrías empezar y preguntas cuál tiene la mayor información esperada, resulta que la mejor respuesta

67
00:05:22,880 --> 00:05:28,400
posible es volar, que no Realmente no parece una palabra real, pero supongo que es un término

68
00:05:28,400 --> 00:05:36,640
obsoleto para referirse a una cría de halcón. Los 15 mejores abridores según esta métrica se

69
00:05:36,640 --> 00:05:41,680
ven así, pero estas no son necesariamente las mejores conjeturas de apertura porque solo están buscando un

70
00:05:41,680 --> 00:05:46,960
paso adelante con la heurística de la información esperada para tratar de estimar cuál será el puntaje

71
00:05:46,960 --> 00:05:52,000
real. Pero hay pocos patrones suficientes como para que podamos hacer una búsqueda exhaustiva en dos pasos.

72
00:05:52,000 --> 00:05:56,640
Por ejemplo, digamos que abrió con Soar y el patrón que vio fue el más probable,

73
00:05:56,640 --> 00:06:02,240
todos grises, entonces puede ejecutar un análisis idéntico desde ese punto. Para una segunda suposición dada,

74
00:06:02,240 --> 00:06:07,360
algo así como kitty, ¿cuál es la distribución en todos los patrones en ese caso restringido en

75
00:06:07,360 --> 00:06:11,920
el que estamos restringidos solo a las palabras que producirían todos los grises para soar, y

76
00:06:11,920 --> 00:06:17,440
luego medimos la planitud de esa distribución usando esta expectativa? fórmula de información, y lo hacemos para

77
00:06:17,440 --> 00:06:23,680
las 13.000 palabras posibles que podríamos usar como una segunda suposición. Al hacer esto, podemos encontrar la

78
00:06:23,680 --> 00:06:28,080
segunda suposición óptima en ese escenario y la cantidad de información que se esperaba que obtuviéramos de

79
00:06:28,640 --> 00:06:32,880
él, y si lavamos, enjuagamos y repetimos y hacemos esto para todos los diferentes patrones posibles que

80
00:06:32,880 --> 00:06:37,680
puedan ver, obtenemos una mapa completo de todas las mejores segundas conjeturas posibles junto con la información

81
00:06:37,680 --> 00:06:46,640
esperada de cada una. A partir de ahí, si tomas un promedio ponderado de todos esos valores del

82
00:06:46,640 --> 00:06:51,760
segundo paso, ponderados de acuerdo con la probabilidad de que caigas en ese grupo, te dará una medida

83
00:06:51,760 --> 00:06:57,440
de cuánta información es probable que obtengas de la suposición que se dispara después del segundo paso. Cuando utilizamos

84
00:06:57,440 --> 00:07:02,400
esta métrica de dos pasos como nuestra nueva forma de clasificación, la lista cambia un poco. Soar ya

85
00:07:02,400 --> 00:07:09,040
no ocupa el primer lugar, vuelve a caer al puesto 14 y, en cambio, lo que llega a la cima muere. Nuevamente, no

86
00:07:09,040 --> 00:07:16,000
parece muy real y parece que es un término británico para una pala que se usa para cortar césped.

87
00:07:16,000 --> 00:07:22,320
Muy bien, pero como puedes ver, es una carrera muy reñida entre todos estos principales contendientes por quién obtiene

88
00:07:22,320 --> 00:07:27,600
la mayor cantidad de información después de esos dos pasos. Y aún así, estas no son necesariamente

89
00:07:27,600 --> 00:07:32,000
las mejores conjeturas iniciales, porque la información es sólo heurística, no nos dice la puntuación

90
00:07:32,000 --> 00:07:37,120
real si realmente juegas el juego. Lo que hice fue ejecutar la simulación de jugar todos

91
00:07:37,120 --> 00:07:44,400
los 2315 juegos de palabras posibles con todas las respuestas posibles entre los 250 primeros de esta lista.

92
00:07:46,160 --> 00:07:51,120
Y al hacer esto, viendo cómo se desempeñan realmente, el que termina muy marginalmente con

93
00:07:51,120 --> 00:08:03,280
la mejor puntuación posible resulta ser Salé, que es una ortografía alternativa de Salé, que

94
00:08:04,240 --> 00:08:10,080
es un casco medieval ligero. Muy bien, si eso te parece demasiado falso, como a

95
00:08:10,080 --> 00:08:15,760
mí me parece, te alegrará saber que Trace y Crate ofrecen un rendimiento casi idéntico.

96
00:08:16,240 --> 00:08:21,040
Cada una de ellas tiene la ventaja de ser obviamente una palabra real, por lo que hay un día en

97
00:08:21,040 --> 00:08:26,480
que aciertas en la primera suposición, ya que ambas son respuestas reales. Este paso de ordenar según las

98
00:08:26,480 --> 00:08:31,200
mejores entropías de dos pasos a ordenar según la puntuación promedio más baja también cambia la lista,

99
00:08:31,200 --> 00:08:36,000
pero no tanto. Por ejemplo, Salé ocupaba anteriormente el tercer lugar antes de llegar a la

100
00:08:36,000 --> 00:08:41,200
cima, y Crate y Trace fueron cuarto y quinto. Si tiene curiosidad, puede obtener un rendimiento

101
00:08:41,200 --> 00:08:45,120
ligeramente mejor desde aquí aplicando un poco de fuerza bruta. Hay una muy buena publicación de

102
00:08:45,120 --> 00:08:49,600
blog de Jonathan Olson, si tiene curiosidad sobre esto, donde también le permite explorar cuáles son

103
00:08:49,600 --> 00:08:53,600
las siguientes conjeturas óptimas para algunas de las palabras iniciales basadas en estos algoritmos óptimos.

104
00:08:55,040 --> 00:08:59,040
Sin embargo, dejando atrás todo esto, algunas personas me han dicho que, entre otras cosas, arruina el

105
00:08:59,040 --> 00:09:03,920
juego analizarlo en exceso de esta manera y tratar de encontrar una suposición de apertura óptima.

106
00:09:03,920 --> 00:09:07,680
Ya sabes, se siente un poco sucio si usas esa suposición inicial después de aprenderla, y se

107
00:09:07,680 --> 00:09:12,400
siente ineficaz si no lo haces. Pero la cuestión es que en realidad no creo que este sea el

108
00:09:12,400 --> 00:09:16,880
mejor abridor para un humano que juega. Por un lado, necesitaría saber cuál es la segunda estimación

109
00:09:16,880 --> 00:09:22,160
óptima para cada uno de los patrones que ve. Y lo que es más importante, todo esto ocurre

110
00:09:22,160 --> 00:09:27,440
en un entorno en el que estamos absurdamente sobreajustados a la lista oficial de respuestas del mundo. En el momento en que,

111
00:09:27,440 --> 00:09:32,240
digamos, el New York Times decida cambiar lo que hay bajo el capó de esa lista, todo esto se iría

112
00:09:32,240 --> 00:09:36,720
por la ventana. La forma en que los humanos jugamos es muy diferente de lo que hacen cualquiera

113
00:09:36,720 --> 00:09:41,440
de estos algoritmos. No tenemos memorizada la lista de palabras, no hacemos búsquedas

114
00:09:41,440 --> 00:09:45,520
exhaustivas, intuimos cosas como cuáles son las vocales y cómo se colocan.

115
00:09:45,520 --> 00:09:50,080
De hecho, sería muy feliz si aquellos de ustedes que ven este video olvidaran rápidamente cuál

116
00:09:50,080 --> 00:09:54,880
es la mejor suposición de apertura técnicamente y en su lugar recordaran cosas como cómo se

117
00:09:54,880 --> 00:09:59,440
cuantifica la información o el hecho de que se debe tener cuidado cuando un codicioso El

118
00:09:59,440 --> 00:10:02,960
algoritmo no alcanza el mejor rendimiento global que se obtendría con una búsqueda más profunda.

119
00:10:03,520 --> 00:10:07,920
Al menos para mi gusto, el placer de escribir algoritmos para intentar jugar juegos en realidad tiene muy poco que

120
00:10:07,920 --> 00:10:12,800
ver con cómo me gusta jugar esos juegos como ser humano. El objetivo de escribir algoritmos para todo

121
00:10:12,800 --> 00:10:17,280
esto no es afectar la forma en que jugamos, sigue siendo solo un divertido juego de palabras. Se

122
00:10:17,280 --> 00:10:22,160
trata de perfeccionar nuestros músculos para escribir algoritmos en contextos más significativos en otros lugares.

123
00:10:37,920 --> 00:10:38,420
you

