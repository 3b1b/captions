[
 {
  "input": "Last week I put up this video about solving the game Wordle, or at least trying to solve it, using information theory. ",
  "translatedText": "पिछले सप्ताह मैंने गेम वर्डले को हल करने के बारे में, या कम से कम सूचना सिद्धांत का उपयोग करके इसे हल करने का प्रयास करने के बारे में यह वीडियो डाला था। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.18
 },
 {
  "input": "And I wanted to add a quick, what should we call this, an addendum? ",
  "translatedText": "और मैं एक त्वरित जोड़ना चाहता था, हमें इसे क्या कहना चाहिए, एक परिशिष्ट? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 6.58,
  "end": 9.78
 },
 {
  "input": "A confession? ",
  "translatedText": "स्वीकारोक्ति? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.08,
  "end": 10.66
 },
 {
  "input": "Basically I just want to explain a place where I made a mistake. ",
  "translatedText": "मूलतः मैं बस उस स्थान की व्याख्या करना चाहता हूँ जहाँ मुझसे गलती हुई। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.02,
  "end": 13.9
 },
 {
  "input": "It turns out there was a very slight bug in the code that I was running to recreate Wordle and then run all of the algorithms to solve it and test their performance. ",
  "translatedText": "यह पता चला कि कोड में एक बहुत ही मामूली बग था जिसे मैं वर्डले को फिर से बनाने के लिए चला रहा था और फिर इसे हल करने और उनके प्रदर्शन का परीक्षण करने के लिए सभी एल्गोरिदम चला रहा था। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.46,
  "end": 22.0
 },
 {
  "input": "And it's one of those bugs that affects a very small percentage of cases, so it was easy to miss, and it has only a very slight effect that for the most part doesn't really matter. ",
  "translatedText": "और यह उन बगों में से एक है जो बहुत कम प्रतिशत मामलों को प्रभावित करता है, इसलिए इसे छोड़ना आसान था, और इसका केवल बहुत ही मामूली प्रभाव होता है जिससे अधिकांश भाग में वास्तव में कोई फर्क नहीं पड़ता।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.6,
  "end": 30.5
 },
 {
  "input": "Basically it had to do with how you assign a color to a guess that has multiple different letters in it. ",
  "translatedText": "मूल रूप से इसका संबंध इस बात से था कि आप एक अनुमान के लिए एक रंग कैसे निर्दिष्ट करते हैं जिसमें कई अलग-अलग अक्षर हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.22,
  "end": 36.36
 },
 {
  "input": "For example, if you guess speed and the true answer is abide, how should you color those two e's from the guess? ",
  "translatedText": "उदाहरण के लिए, यदि आप गति का अनुमान लगाते हैं और सही उत्तर एबाइड है, तो आपको अनुमान से उन दो ई को कैसे रंगना चाहिए? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 36.52,
  "end": 42.12
 },
 {
  "input": "Well the way that it works with the Wordle conventions is that the first e would be colored yellow, and the second one would be colored gray. ",
  "translatedText": "खैर जिस तरह से यह वर्डले सम्मेलनों के साथ काम करता है वह यह है कि पहला ई पीले रंग का होगा, और दूसरा ग्रे रंग का होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.06,
  "end": 49.08
 },
 {
  "input": "You might think of that first one as matching up with something from the true answer, and the grayness is telling you there is no second e. ",
  "translatedText": "हो सकता है कि आप उस पहले वाले को सही उत्तर से मेल खाने वाली चीज़ के रूप में सोचें, और अस्पष्टता आपको बता रही है कि कोई दूसरा ई नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 49.6,
  "end": 55.52
 },
 {
  "input": "By contrast, if the answer was something like erase, both of those e's would be colored yellow, telling you that there is a first e in a different location, and there's a second e also in a different location. ",
  "translatedText": "इसके विपरीत, यदि उत्तर मिटाने जैसा कुछ था, तो उन दोनों ई को पीले रंग में रंग दिया जाएगा, जो आपको बताएगा कि एक अलग स्थान पर पहला ई है, और एक अलग स्थान पर दूसरा ई भी है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.52,
  "end": 66.78
 },
 {
  "input": "Similarly if one of the e's hits and it's green, then that second one would be gray in the case where the true answer has no second e, but it would be yellow in the case where there is a second e and it's just in a different location. ",
  "translatedText": "इसी प्रकार यदि ई में से एक हिट होता है और वह हरा है, तो वह दूसरा ई उस स्थिति में ग्रे होगा जहां सही उत्तर में कोई दूसरा ई नहीं है, लेकिन यह उस स्थिति में पीला होगा जहां दूसरा ई है और यह बिल्कुल अलग है जगह।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.3,
  "end": 80.04
 },
 {
  "input": "Long story short, somewhere along the way I accidentally introduced behavior that differs from these conventions slightly. ",
  "translatedText": "लंबी कहानी संक्षेप में, रास्ते में कहीं मैंने गलती से ऐसा व्यवहार पेश किया जो इन परंपराओं से थोड़ा अलग है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.7,
  "end": 86.4
 },
 {
  "input": "Honestly it was really dumb. ",
  "translatedText": "सच कहूँ तो यह वास्तव में मूर्खतापूर्ण था।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.1,
  "end": 88.54
 },
 {
  "input": "Basically at some point in the middle of the project I wanted to speed up some of the computations, and I was trying a little trick for how it computed the value for this pattern between any given pair of words, and you know I just didn't really think it through and it introduced this slight change. ",
  "translatedText": "मूल रूप से प्रोजेक्ट के बीच में किसी बिंदु पर मैं कुछ गणनाओं को तेज़ करना चाहता था, और मैं एक छोटी सी तरकीब आज़मा रहा था कि यह शब्दों की किसी भी जोड़ी के बीच इस पैटर्न के लिए मूल्य की गणना कैसे करता है, और आप जानते हैं कि मैंने बस ऐसा किया।' वास्तव में इस पर विचार करें और इसने यह मामूली बदलाव लाया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.88,
  "end": 102.72
 },
 {
  "input": "The ironic part is that in the end the actual way to make things fastest is to pre-compute all those patterns so that everything is just a lookup, and so it wouldn't matter how long it takes to do each one, especially if you're writing hard to read buggy code to make it happen. ",
  "translatedText": "विडंबनापूर्ण बात यह है कि अंत में चीजों को तेजी से करने का वास्तविक तरीका उन सभी पैटर्न की पूर्व-गणना करना है ताकि सब कुछ सिर्फ एक लुकअप हो, और इससे कोई फर्क नहीं पड़ता कि प्रत्येक को करने में कितना समय लगता है, खासकर यदि आप इसे साकार करने के लिए बग्गी कोड को पढ़ने के लिए कड़ी मेहनत कर रहे हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.22,
  "end": 115.84
 },
 {
  "input": "You know, you live and you learn. ",
  "translatedText": "आप जानते हैं, आप जीते हैं और आप सीखते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.4,
  "end": 117.24
 },
 {
  "input": "As far as how this affects the actual video, I mean very little of substance really changes. ",
  "translatedText": "जहां तक इसका वास्तविक वीडियो पर प्रभाव पड़ता है, मेरा मतलब है कि वास्तव में बहुत कम सामग्री में परिवर्तन होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.04,
  "end": 122.34
 },
 {
  "input": "Of course the main lessons about what is information, what is entropy, all that stays the same. ",
  "translatedText": "बेशक जानकारी क्या है, एन्ट्रॉपी क्या है, इसके बारे में मुख्य सबक वही रहता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.66,
  "end": 126.56
 },
 {
  "input": "Every now and then if I'm showing on screen some distribution associated with a given word, that distribution might actually be a little bit off because some of the buckets associated with various patterns should include either more or fewer true answers. ",
  "translatedText": "समय-समय पर अगर मैं स्क्रीन पर किसी दिए गए शब्द से जुड़ा कुछ वितरण दिखा रहा हूं, तो वह वितरण वास्तव में थोड़ा हटकर हो सकता है क्योंकि विभिन्न पैटर्न से जुड़े कुछ बकेट में या तो अधिक या कम सही उत्तर शामिल होने चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.86,
  "end": 140.32
 },
 {
  "input": "Even then it doesn't really come up because it was very rare that I would be showing a word that had multiple letters that also hit this edge case. ",
  "translatedText": "फिर भी यह वास्तव में सामने नहीं आता क्योंकि यह बहुत दुर्लभ था कि मैं एक शब्द दिखा रहा होता जिसमें कई अक्षर होते जो इस किनारे के मामले में भी आते।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.84,
  "end": 146.96
 },
 {
  "input": "But one of the very few things of substance that does change and that arguably does matter a fair bit was the final conclusion around how if we want to find the optimal possible score for the wordle answer list, what opening guess does such an algorithm use? ",
  "translatedText": "लेकिन पदार्थ की बहुत कम चीजों में से एक जो बदलती है और जो निश्चित रूप से काफी हद तक मायने रखती है, वह अंतिम निष्कर्ष था कि अगर हम शब्द उत्तर सूची के लिए इष्टतम संभावित स्कोर ढूंढना चाहते हैं, तो इस तरह के एल्गोरिदम का उपयोग किस शुरुआती अनुमान से होता है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.68,
  "end": 162.46
 },
 {
  "input": "In the video I said the best performance that I could find came from opening with the word crane, which was true only in the sense that the algorithms were playing a very slightly different game. ",
  "translatedText": "वीडियो में मैंने कहा कि सबसे अच्छा प्रदर्शन जो मुझे मिला वह क्रेन शब्द के साथ शुरुआत से आया, जो केवल इस अर्थ में सच था कि एल्गोरिदम बहुत थोड़ा अलग गेम खेल रहे थे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.08,
  "end": 172.56
 },
 {
  "input": "After fixing it and rerunning it all, there is a different answer for what the theoretically optimal first guess is for this particular list. ",
  "translatedText": "इसे ठीक करने और इसे फिर से चलाने के बाद, इस विशेष सूची के लिए सैद्धांतिक रूप से इष्टतम पहला अनुमान क्या है, इसका एक अलग उत्तर है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.16,
  "end": 180.16
 },
 {
  "input": "And look, I know that you know that the point of the video is not to find some technically optimal answer to some random online game. ",
  "translatedText": "और देखिए, मुझे पता है कि आप जानते हैं कि वीडियो का उद्देश्य किसी यादृच्छिक ऑनलाइन गेम के लिए तकनीकी रूप से इष्टतम उत्तर ढूंढना नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.0,
  "end": 189.1
 },
 {
  "input": "The point of the video is to shamelessly hop on the bandwagon of an internet trend to sneak attack people with an information theory lesson. ",
  "translatedText": "वीडियो का उद्देश्य सूचना सिद्धांत पाठ के साथ लोगों पर चुपचाप हमला करने के लिए एक इंटरनेट प्रवृत्ति के बैंडवैगन पर बेशर्मी से कूदना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.46,
  "end": 195.9
 },
 {
  "input": "And that's all good, I stand by that part. ",
  "translatedText": "और यह सब अच्छा है, मैं उस हिस्से पर कायम हूं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.32,
  "end": 198.0
 },
 {
  "input": "But I know how the internet works, and for a lot of people the one main takeaway was what is the best opener for the game wordle. ",
  "translatedText": "लेकिन मैं जानता हूं कि इंटरनेट कैसे काम करता है, और बहुत से लोगों के लिए मुख्य बात यह थी कि गेम वर्डले के लिए सबसे अच्छा ओपनर क्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 204.6
 },
 {
  "input": "And I get it, I walked into that because I put it in the thumbnail, but presumably you can forgive me if I want to add a little correction here. ",
  "translatedText": "और मैं समझ गया, मैं उसमें चला गया क्योंकि मैंने इसे थंबनेल में रखा था, लेकिन संभवतः आप मुझे क्षमा कर सकते हैं यदि मैं यहां थोड़ा सुधार जोड़ना चाहता हूं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.28,
  "end": 211.86
 },
 {
  "input": "And a more meaningful reason to circle back to all this actually is that I never really talked about what went into that final analysis. ",
  "translatedText": "और वास्तव में इन सब पर वापस जाने का एक अधिक सार्थक कारण यह है कि मैंने वास्तव में उस अंतिम विश्लेषण में क्या हुआ, इसके बारे में कभी बात नहीं की।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.98,
  "end": 218.34
 },
 {
  "input": "And it's interesting as a sublesson in its own right, so it's worth doing here. ",
  "translatedText": "और यह अपने आप में एक उप-पाठ के रूप में दिलचस्प है, इसलिए इसे यहां करना उचित है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.84,
  "end": 222.42
 },
 {
  "input": "Now if you'll recall, most of our time last video was spent on the challenge of trying to write an algorithm to solve wordle that did not use the official list of all possible answers. ",
  "translatedText": "अब यदि आप याद करेंगे, तो पिछले वीडियो में हमारा अधिकांश समय वर्डले को हल करने के लिए एक एल्गोरिदम लिखने की चुनौती पर व्यतीत हुआ था, जिसमें सभी संभावित उत्तरों की आधिकारिक सूची का उपयोग नहीं किया गया था।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.14,
  "end": 232.46
 },
 {
  "input": "To my taste, that feels a bit like overfitting to a test set, and what's more fun is building something that's resilient. ",
  "translatedText": "मेरी पसंद के अनुसार, यह एक परीक्षण सेट के लिए कुछ हद तक ओवरफिटिंग जैसा लगता है, और इससे भी अधिक मजेदार बात यह है कि कुछ ऐसा बनाना जो लचीला हो।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.48
 },
 {
  "input": "This is why we went through the whole process of looking at relative word frequencies in the English language to come up with some notion of how likely each one would be to be included as a final answer. ",
  "translatedText": "यही कारण है कि हम अंग्रेजी भाषा में सापेक्ष शब्द आवृत्तियों को देखने की पूरी प्रक्रिया से गुजरे ताकि यह पता चल सके कि प्रत्येक को अंतिम उत्तर के रूप में शामिल किए जाने की कितनी संभावना होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.9,
  "end": 248.76
 },
 {
  "input": "However, for what we're doing here, where we're just trying to find an absolute best performance period, I am incorporating that official list and just shamelessly overfitting to the test set, which is to say we know with certainty whether a word is included or not, and we can assign a uniform probability to each one. ",
  "translatedText": "हालाँकि, हम यहाँ क्या कर रहे हैं, जहाँ हम केवल सर्वश्रेष्ठ प्रदर्शन अवधि खोजने की कोशिश कर रहे हैं, मैं उस आधिकारिक सूची को शामिल कर रहा हूँ और परीक्षण सेट पर बेशर्मी से ओवरफ़िट कर रहा हूँ, जिसका अर्थ है कि हम निश्चित रूप से जानते हैं कि एक शब्द भी है या नहीं शामिल है या नहीं, और हम प्रत्येक को एक समान संभावना निर्दिष्ट कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.4,
  "end": 265.46
 },
 {
  "input": "If you'll remember, the first step in all of this was to say for a particular opening guess, maybe something like my old favorite, crane, how likely is it that you would see each of the possible patterns? ",
  "translatedText": "यदि आपको याद होगा, तो इस सब में पहला कदम एक विशेष शुरुआती अनुमान के लिए यह कहना था, शायद मेरे पुराने पसंदीदा, क्रेन जैसा कुछ, इसकी कितनी संभावना है कि आप प्रत्येक संभावित पैटर्न देखेंगे? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 266.44,
  "end": 276.18
 },
 {
  "input": "And in this context, where we are shamelessly overfitting to the wordle answer list, all that involves is counting how many of the possible answers give each one of these patterns. ",
  "translatedText": "और इस संदर्भ में, जहां हम बेशर्मी से शब्दों की उत्तर सूची को ओवरफिट कर रहे हैं, इसमें केवल यह गिनना शामिल है कि कितने संभावित उत्तर इनमें से प्रत्येक पैटर्न को देते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.68,
  "end": 285.34
 },
 {
  "input": "And then of course most of our time was spent on this kind of funny looking formula to quantify the amount of information that you would get from this guess that basically involves going through each one of those buckets and saying how much information would you gain that has this log expression that is a fanciful way of saying how many times would you cut your space of possibilities in half if you observed a given pattern. ",
  "translatedText": "और फिर निश्चित रूप से हमारा अधिकांश समय इस तरह के अजीब दिखने वाले फॉर्मूले पर खर्च किया गया ताकि आप इस अनुमान से प्राप्त होने वाली जानकारी की मात्रा निर्धारित कर सकें, जिसमें मूल रूप से उन सभी बाल्टियों से गुजरना और यह बताना शामिल है कि आप कितनी जानकारी प्राप्त करेंगे।यह लॉग अभिव्यक्ति यह कहने का एक काल्पनिक तरीका है कि यदि आप किसी दिए गए पैटर्न को देखते हैं तो आप कितनी बार संभावनाओं के स्थान को आधा कर देंगे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.98,
  "end": 306.84
 },
 {
  "input": "We take a weighted average of all of those and it gives us a measure of how much we expect to learn from this first guess. ",
  "translatedText": "हम उन सभी का एक भारित औसत लेते हैं और यह हमें माप देता है कि हम इस पहले अनुमान से कितना सीखने की उम्मीद करते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.6,
  "end": 313.18
 },
 {
  "input": "In a moment we'll go deeper than this, but if you simply search through all 13,000 different words that you could start with and you ask which one has the highest expected information, it turns out the best possible answer is soar, which doesn't really look like a real word, but I guess it's an obsolete term for a baby hawk. ",
  "translatedText": "एक क्षण में हम इससे अधिक गहराई में जाएंगे, लेकिन यदि आप सभी 13,000 अलग-अलग शब्दों को खोजते हैं, जिनसे आप शुरुआत कर सकते हैं और आप पूछते हैं कि किसमें सबसे अधिक अपेक्षित जानकारी है, तो यह पता चलता है कि सबसे अच्छा संभव उत्तर ऊंची उड़ान है, जो नहीं है।यह वास्तव में एक वास्तविक शब्द जैसा दिखता है, लेकिन मुझे लगता है कि यह बाज़ के बच्चे के लिए एक अप्रचलित शब्द है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.56,
  "end": 333.0
 },
 {
  "input": "The top 15 openers by this metric happen to look like this, but these are not necessarily the best opening guesses because they're only looking one step in with the heuristic of expected information to try to estimate what the true score will be. ",
  "translatedText": "इस मीट्रिक के अनुसार शीर्ष 15 सलामी बल्लेबाज इस तरह दिखते हैं, लेकिन ये जरूरी नहीं कि सबसे अच्छे शुरुआती अनुमान हों क्योंकि वे अपेक्षित जानकारी के अनुमान के साथ केवल एक कदम देख रहे हैं ताकि यह अनुमान लगाया जा सके कि वास्तविक स्कोर क्या होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.04,
  "end": 347.54
 },
 {
  "input": "But there's few enough patterns that we can do an exhaustive search two steps in. ",
  "translatedText": "लेकिन ऐसे कुछ पर्याप्त पैटर्न हैं जिनके आधार पर हम दो चरणों में विस्तृत खोज कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.92,
  "end": 351.68
 },
 {
  "input": "For example, let's say you opened with soar and the pattern you happen to see was the most likely one, all grays, then you can run identical analysis from that point. ",
  "translatedText": "उदाहरण के लिए, मान लें कि आपने उछाल के साथ शुरुआत की और जो पैटर्न आपने देखा वह सबसे संभावित था, सभी ग्रे, तो आप उस बिंदु से समान विश्लेषण चला सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 352.16,
  "end": 360.8
 },
 {
  "input": "For a given proposed second guess, something like kitty, what's the distribution across all patterns in that restricted case where we're restricted only to the words that would produce all grays for soar, and then we measure the flatness of that distribution using this expected information formula, and we do that for all 13,000 possible words that we could use as a second guess. ",
  "translatedText": "दिए गए प्रस्तावित दूसरे अनुमान के लिए, किटी जैसा कुछ, उस प्रतिबंधित मामले में सभी पैटर्न में वितरण क्या है जहां हम केवल उन शब्दों तक ही सीमित हैं जो ऊंची उड़ान के लिए सभी ग्रे उत्पन्न करेंगे, और फिर हम इस अपेक्षित का उपयोग करके उस वितरण की समतलता को मापते हैं सूचना सूत्र, और हम ऐसा सभी 13,000 संभावित शब्दों के लिए करते हैं जिन्हें हम दूसरे अनुमान के रूप में उपयोग कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 361.32,
  "end": 381.42
 },
 {
  "input": "Doing this we can find the optimal second guess in that scenario and the amount of information we were expected to get from it, and if we wash rinse and repeat and do this for all of the different possible patterns that you might see, we get a full map of all the best possible second guesses together with the expected information of each. ",
  "translatedText": "ऐसा करने से हम उस परिदृश्य में इष्टतम दूसरा अनुमान पा सकते हैं और उससे हमें कितनी जानकारी मिलने की उम्मीद थी, और यदि हम धोते हैं, कुल्ला करते हैं और दोहराते हैं और सभी अलग-अलग संभावित पैटर्न के लिए ऐसा करते हैं जो आप देख सकते हैं, तो हमें एक मिलता है प्रत्येक की अपेक्षित जानकारी के साथ सभी सर्वोत्तम संभव दूसरे अनुमानों का पूरा नक्शा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.12,
  "end": 399.2
 },
 {
  "input": "From there, if you take a weighted average of all those second step values, weighted according to how likely you are to fall into that bucket, it gives you a measure of how much information you're likely to gain from the guess soar after the second step. ",
  "translatedText": "वहां से, यदि आप उन सभी दूसरे चरण के मूल्यों का भारित औसत लेते हैं, जो कि आपके उस बाल्टी में गिरने की कितनी संभावना के अनुसार भारित होता है, तो यह आपको एक माप देता है कि अनुमान के बाद आपको कितनी जानकारी प्राप्त होने की संभावना है दूसरा कदम।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.18,
  "end": 416.8
 },
 {
  "input": "When we use this two-step metric as our new means of ranking, the list gets shaken up a bit. ",
  "translatedText": "जब हम रैंकिंग के अपने नए साधन के रूप में इस दो-चरणीय मीट्रिक का उपयोग करते हैं, तो सूची थोड़ी हिल जाती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.38,
  "end": 421.78
 },
 {
  "input": "Soar is no longer first place, it falls back to 14th, and instead what rises to the top is slain. ",
  "translatedText": "सोअर अब पहले स्थान पर नहीं है, यह वापस 14वें स्थान पर आ जाता है, और इसके बजाय जो शीर्ष पर पहुंचता है वह मारा जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.08,
  "end": 427.66
 },
 {
  "input": "Again, doesn't feel very real, and it looks like it is a British term for a spade that's used for cutting turf. ",
  "translatedText": "फिर, यह बहुत वास्तविक नहीं लगता है, और ऐसा लगता है कि यह कुदाल के लिए एक ब्रिटिश शब्द है जिसका उपयोग टर्फ काटने के लिए किया जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.64,
  "end": 436.38
 },
 {
  "input": "Alright, but as you can see it is a really tight race among all of these top contenders for who gains the most information after those two steps. ",
  "translatedText": "ठीक है, लेकिन जैसा कि आप देख सकते हैं, इन सभी शीर्ष दावेदारों के बीच यह वास्तव में एक कड़ी दौड़ है कि उन दो चरणों के बाद सबसे अधिक जानकारी कौन प्राप्त करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.2,
  "end": 445.0
 },
 {
  "input": "And even still, these are not necessarily the best opening guesses, because information is just the heuristic, it's not telling us the actual score if you actually play the game. ",
  "translatedText": "और फिर भी, ये जरूरी नहीं कि सबसे अच्छे शुरुआती अनुमान हों, क्योंकि जानकारी केवल अनुमान है, यदि आप वास्तव में गेम खेलते हैं तो यह हमें वास्तविक स्कोर नहीं बता रही है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.7,
  "end": 454.0
 },
 {
  "input": "What I did is I ran the simulation of playing all 2315 possible wordle games with all possible answers on the top 250 from this list. ",
  "translatedText": "मैंने जो किया वह यह है कि मैंने इस सूची से शीर्ष 250 पर सभी संभावित उत्तरों के साथ सभी 2315 संभावित वर्डल गेम खेलने का अनुकरण चलाया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.58,
  "end": 464.62
 },
 {
  "input": "And by doing this, seeing how they actually perform, the one that ends up very marginally with the best possible score turns out to be Salé, which is an alternate spelling for Salé, which is a light medieval helmet. ",
  "translatedText": "और ऐसा करने से, यह देखते हुए कि वे वास्तव में कैसा प्रदर्शन करते हैं, जो सर्वोत्तम संभव स्कोर के साथ बहुत मामूली रूप से समाप्त होता है, वह साले बन जाता है, जो सैले के लिए एक वैकल्पिक वर्तनी है, जो एक हल्का मध्ययुगीन हेलमेट है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.46,
  "end": 485.98
 },
 {
  "input": "Alright, if that feels a little bit too fake for you, which it does for me, you'll be happy to know that Trace and Crate give almost identical performance. ",
  "translatedText": "ठीक है, अगर यह आपको थोड़ा-बहुत नकली लगता है, जैसा कि मुझे लगता है, तो आपको यह जानकर खुशी होगी कि ट्रेस और क्रेट लगभग समान प्रदर्शन देते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.98,
  "end": 495.78
 },
 {
  "input": "Each of them has the benefit of obviously being a real word, so there is one day when you get it right on the first guess, since both are actual wordle answers. ",
  "translatedText": "उनमें से प्रत्येक के पास स्पष्ट रूप से एक वास्तविक शब्द होने का लाभ है, इसलिए एक दिन ऐसा आता है जब आप इसे पहले अनुमान पर सही पाते हैं, क्योंकि दोनों वास्तविक शब्द उत्तर हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 496.3,
  "end": 504.06
 },
 {
  "input": "This move from sorting based on the best two-step entropies to sorting based on the lowest average score also shakes up the list, but not nearly as much. ",
  "translatedText": "सर्वोत्तम दो-चरणीय एन्ट्रॉपी के आधार पर छँटाई से लेकर न्यूनतम औसत स्कोर के आधार पर छँटाई करने का यह कदम भी सूची को हिलाता है, लेकिन उतना नहीं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.02,
  "end": 512.46
 },
 {
  "input": "For example, Salé was previously third place before it bubbles to the top, and Crate and Trace were both fourth and fifth. ",
  "translatedText": "उदाहरण के लिए, शीर्ष पर पहुंचने से पहले साले तीसरे स्थान पर था, और क्रेट और ट्रेस दोनों चौथे और पांचवें स्थान पर थे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.66,
  "end": 519.08
 },
 {
  "input": "If you're curious, you can get slightly better performance from here by doing a little brute forcing. ",
  "translatedText": "यदि आप उत्सुक हैं, तो आप थोड़ी सी जबरदस्ती करके यहां से थोड़ा बेहतर प्रदर्शन प्राप्त कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.64,
  "end": 523.72
 },
 {
  "input": "There's a very nice blog post by Jonathan Olson, if you're curious about this, where he also lets you explore what the optimal following guesses are for a few of the starting words based on these optimal algorithms. ",
  "translatedText": "यदि आप इसके बारे में उत्सुक हैं, तो जोनाथन ओल्सन का एक बहुत अच्छा ब्लॉग पोस्ट है, जहां वह आपको यह भी पता लगाने की सुविधा देता है कि इन इष्टतम एल्गोरिदम के आधार पर कुछ शुरुआती शब्दों के लिए इष्टतम निम्नलिखित अनुमान क्या हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.1,
  "end": 533.66
 },
 {
  "input": "Stepping back from all this though, I'm told by some people that it quote ruins the game to overanalyze it like this and try to find an optimal opening guess. ",
  "translatedText": "हालाँकि, इस सब से पीछे हटते हुए, मुझे कुछ लोगों ने बताया है कि इस तरह से इसका अत्यधिक विश्लेषण करने और एक इष्टतम शुरुआती अनुमान खोजने की कोशिश करने से यह खेल को बर्बाद कर देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.18,
  "end": 543.6
 },
 {
  "input": "You know, it feels kind of dirty if you use that opening guess after learning it, and it feels inefficient if you don't. ",
  "translatedText": "आप जानते हैं, यदि आप इसे सीखने के बाद शुरुआती अनुमान का उपयोग करते हैं तो यह गंदा लगता है, और यदि आप ऐसा नहीं करते हैं तो यह अप्रभावी लगता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.26,
  "end": 549.66
 },
 {
  "input": "But the thing is, I don't actually think this is the best opener for a human playing the game. ",
  "translatedText": "लेकिन बात यह है कि, मैं वास्तव में नहीं सोचता कि गेम खेलने वाले इंसान के लिए यह सबसे अच्छा ओपनर है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.8,
  "end": 554.4
 },
 {
  "input": "For one thing, you would need to know what the optimal second guess is for each one of the patterns that you see. ",
  "translatedText": "एक बात के लिए, आपको यह जानना होगा कि आपके द्वारा देखे जाने वाले प्रत्येक पैटर्न के लिए इष्टतम दूसरा अनुमान क्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.88,
  "end": 559.68
 },
 {
  "input": "And more importantly, all of this is in a setting where we are absurdly overfit to the official wordle answer list. ",
  "translatedText": "और इससे भी महत्वपूर्ण बात यह है कि यह सब एक ऐसी सेटिंग में है जहां हम आधिकारिक वर्डले उत्तर सूची में हास्यास्पद रूप से ओवरफिट हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.26,
  "end": 566.36
 },
 {
  "input": "The moment that, say, the New York Times chooses to change what that list is under the hood, all of this would go out the window. ",
  "translatedText": "जिस क्षण, मान लीजिए, न्यूयॉर्क टाइम्स उस सूची को बदलने का विकल्प चुनता है जो हुड के नीचे है, यह सब खिड़की से बाहर चला जाएगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.58,
  "end": 572.88
 },
 {
  "input": "The way that we humans play the game is just very different from what any of these algorithms are doing. ",
  "translatedText": "जिस तरह से हम इंसान गेम खेलते हैं वह इनमें से किसी भी एल्गोरिदम के खेलने से बिल्कुल अलग है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.58,
  "end": 577.68
 },
 {
  "input": "We don't have the word list memorized, we're not doing exhaustive searches, we get intuition from things like what are the vowels and how are they placed. ",
  "translatedText": "हमारे पास शब्दों की सूची याद नहीं है, हम विस्तृत खोज नहीं कर रहे हैं, हमें स्वर क्या हैं और उन्हें कैसे रखा जाता है जैसी चीजों से अंतर्ज्ञान मिलता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.02,
  "end": 585.08
 },
 {
  "input": "I would actually be most happy if those of you watching this video promptly forgot what happens to be the technically best opening guess, and instead came out remembering things like how do you quantify information, or the fact that you should look out for when a greedy algorithm falls short of the globally best performance that you would get from a deeper search. ",
  "translatedText": "मुझे वास्तव में सबसे अधिक खुशी होगी यदि आप में से जो लोग इस वीडियो को देख रहे हैं वे तुरंत भूल जाएं कि तकनीकी रूप से सबसे अच्छा प्रारंभिक अनुमान क्या होता है, और इसके बजाय वे चीजों को याद करते हुए सामने आते हैं जैसे कि आप जानकारी को कैसे मापते हैं, या तथ्य यह है कि आपको लालची होने पर ध्यान देना चाहिए एल्गोरिदम विश्व स्तर पर सर्वोत्तम प्रदर्शन से कम है जो आपको गहन खोज से मिलेगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 585.64,
  "end": 603.1
 },
 {
  "input": "For my taste at least, the joy of writing algorithms to try to play games actually has very little bearing on how I like to play those games as a human. ",
  "translatedText": "कम से कम मेरे स्वाद के लिए, गेम खेलने की कोशिश करने के लिए एल्गोरिदम लिखने की खुशी वास्तव में इस बात पर बहुत कम असर डालती है कि मैं एक इंसान के रूप में उन गेम को कैसे खेलना पसंद करता हूं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.7,
  "end": 610.76
 },
 {
  "input": "The point of writing algorithms for all this is not to affect the way that we play the game, it's still just a fun word game. ",
  "translatedText": "इन सबके लिए एल्गोरिदम लिखने का उद्देश्य हमारे गेम खेलने के तरीके को प्रभावित करना नहीं है, यह अभी भी एक मजेदार शब्द गेम है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.3,
  "end": 616.78
 },
 {
  "input": "It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere. ",
  "translatedText": "यह कहीं और अधिक सार्थक संदर्भों में एल्गोरिदम लिखने के लिए हमारी मांसपेशियों को निखारने के लिए है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.1,
  "end": 620.72
 }
]