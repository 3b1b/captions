[
 {
  "input": "Last week I put up this video about solving the game Wordle, or at least trying to solve it, using information theory. ",
  "translatedText": "La semana pasada publiqué este vídeo sobre cómo resolver el juego Wordle, o al menos intentar resolverlo, utilizando la teoría de la información. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.18
 },
 {
  "input": "And I wanted to add a quick, what should we call this, an addendum? ",
  "translatedText": "Y quería agregar un rápido, ¿cómo deberíamos llamarlo? ¿Un apéndice? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 6.58,
  "end": 9.78
 },
 {
  "input": "A confession? ",
  "translatedText": "¿Una confesión? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.08,
  "end": 10.66
 },
 {
  "input": "Basically I just want to explain a place where I made a mistake. ",
  "translatedText": "Básicamente sólo quiero explicar un lugar en el que cometí un error. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.02,
  "end": 13.9
 },
 {
  "input": "It turns out there was a very slight bug in the code that I was running to recreate Wordle and then run all of the algorithms to solve it and test their performance. ",
  "translatedText": "Resulta que había un error muy leve en el código que estaba ejecutando para recrear Wordle y luego ejecutar todos los algoritmos para resolverlo y probar su rendimiento. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.46,
  "end": 22.0
 },
 {
  "input": "And it's one of those bugs that affects a very small percentage of cases, so it was easy to miss, and it has only a very slight effect that for the most part doesn't really matter. ",
  "translatedText": "Y es uno de esos errores que afecta a un porcentaje muy pequeño de casos, por lo que era fácil pasarlo por alto, y tiene sólo un efecto muy leve que en su mayor parte realmente no importa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.6,
  "end": 30.5
 },
 {
  "input": "Basically it had to do with how you assign a color to a guess that has multiple different letters in it. ",
  "translatedText": "Básicamente tenía que ver con cómo se asigna un color a una suposición que tiene varias letras diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.22,
  "end": 36.36
 },
 {
  "input": "For example, if you guess speed and the true answer is abide, how should you color those two e's from the guess? ",
  "translatedText": "Por ejemplo, si adivinas la velocidad y la respuesta verdadera es respetar, ¿cómo deberías colorear esas dos e de la suposición? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 36.52,
  "end": 42.12
 },
 {
  "input": "Well the way that it works with the Wordle conventions is that the first e would be colored yellow, and the second one would be colored gray. ",
  "translatedText": "Bueno, la forma en que funciona con las convenciones de Wordle es que la primera e sería de color amarillo y la segunda sería de color gris. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.06,
  "end": 49.08
 },
 {
  "input": "You might think of that first one as matching up with something from the true answer, and the grayness is telling you there is no second e. ",
  "translatedText": "Podrías pensar que la primera coincide con algo de la respuesta verdadera, y el tono gris te dice que no hay una segunda e. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 49.6,
  "end": 55.52
 },
 {
  "input": "By contrast, if the answer was something like erase, both of those e's would be colored yellow, telling you that there is a first e in a different location, and there's a second e also in a different location. ",
  "translatedText": "Por el contrario, si la respuesta fuera algo así como borrar, ambas e se colorearían de amarillo, lo que indicaría que hay una primera e en una ubicación diferente y que hay una segunda e también en una ubicación diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.52,
  "end": 66.78
 },
 {
  "input": "Similarly if one of the e's hits and it's green, then that second one would be gray in the case where the true answer has no second e, but it would be yellow in the case where there is a second e and it's just in a different location. ",
  "translatedText": "De manera similar, si una de las e acierta y es verde, entonces esa segunda sería gris en el caso en que la respuesta verdadera no tenga una segunda e, pero sería amarilla en el caso en que haya una segunda e y esté simplemente en una dirección diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.3,
  "end": 80.04
 },
 {
  "input": "Long story short, somewhere along the way I accidentally introduced behavior that differs from these conventions slightly. ",
  "translatedText": "ubicación. En pocas palabras, en algún momento introduje accidentalmente un comportamiento que difiere ligeramente de estas convenciones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.7,
  "end": 86.4
 },
 {
  "input": "Honestly it was really dumb. ",
  "translatedText": "Sinceramente, fue realmente tonto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.1,
  "end": 88.54
 },
 {
  "input": "Basically at some point in the middle of the project I wanted to speed up some of the computations, and I was trying a little trick for how it computed the value for this pattern between any given pair of words, and you know I just didn't really think it through and it introduced this slight change. ",
  "translatedText": "Básicamente, en algún momento a mitad del proyecto quería acelerar algunos de los cálculos, y estaba probando un pequeño truco sobre cómo calcular el valor de este patrón entre cualquier par de palabras determinado, y ya sabes, simplemente lo hice. Realmente no lo pensé bien e introdujo este ligero cambio. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.88,
  "end": 102.72
 },
 {
  "input": "The ironic part is that in the end the actual way to make things fastest is to pre-compute all those patterns so that everything is just a lookup, and so it wouldn't matter how long it takes to do each one, especially if you're writing hard to read buggy code to make it happen. ",
  "translatedText": "La parte irónica es que, al final, la forma real de hacer las cosas más rápidas es precalcular todos esos patrones para que todo sea solo una búsqueda, por lo que no importaría cuánto tiempo lleve hacer cada uno, especialmente si Estamos escribiendo código con errores difíciles de leer para que esto suceda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.22,
  "end": 115.84
 },
 {
  "input": "You know, you live and you learn. ",
  "translatedText": "Ya sabes, vives y aprendes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.4,
  "end": 117.24
 },
 {
  "input": "As far as how this affects the actual video, I mean very little of substance really changes. ",
  "translatedText": "En cuanto a cómo esto afecta el video real, quiero decir que realmente hay muy pocos cambios sustanciales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.04,
  "end": 122.34
 },
 {
  "input": "Of course the main lessons about what is information, what is entropy, all that stays the same. ",
  "translatedText": "Por supuesto, las principales lecciones sobre qué es información y qué es entropía, todo eso sigue igual. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.66,
  "end": 126.56
 },
 {
  "input": "Every now and then if I'm showing on screen some distribution associated with a given word, that distribution might actually be a little bit off because some of the buckets associated with various patterns should include either more or fewer true answers. ",
  "translatedText": "De vez en cuando, si muestro en pantalla alguna distribución asociada con una palabra determinada, esa distribución podría en realidad estar un poco fuera de lugar porque algunos de los grupos asociados con varios patrones deberían incluir más o menos respuestas verdaderas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.86,
  "end": 140.32
 },
 {
  "input": "Even then it doesn't really come up because it was very rare that I would be showing a word that had multiple letters that also hit this edge case. ",
  "translatedText": "Incluso entonces, realmente no aparece porque era muy raro que mostrara una palabra que tuviera varias letras que también llegaran a este caso límite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.84,
  "end": 146.96
 },
 {
  "input": "But one of the very few things of substance that does change and that arguably does matter a fair bit was the final conclusion around how if we want to find the optimal possible score for the wordle answer list, what opening guess does such an algorithm use? ",
  "translatedText": "Pero una de las pocas cosas sustanciales que sí cambia y que posiblemente sí importa bastante fue la conclusión final sobre cómo, si queremos encontrar la puntuación óptima posible para la lista de respuestas de Wordle, ¿qué suposición inicial utiliza dicho algoritmo? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.68,
  "end": 162.46
 },
 {
  "input": "In the video I said the best performance that I could find came from opening with the word crane, which was true only in the sense that the algorithms were playing a very slightly different game. ",
  "translatedText": "En el vídeo dije que el mejor rendimiento que pude encontrar provino de abrir con la palabra grúa, lo cual era cierto sólo en el sentido de que los algoritmos estaban jugando un juego ligeramente diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.08,
  "end": 172.56
 },
 {
  "input": "After fixing it and rerunning it all, there is a different answer for what the theoretically optimal first guess is for this particular list. ",
  "translatedText": "Después de arreglarlo y volver a ejecutarlo todo, hay una respuesta diferente sobre cuál es la primera suposición teóricamente óptima para esta lista en particular. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.16,
  "end": 180.16
 },
 {
  "input": "And look, I know that you know that the point of the video is not to find some technically optimal answer to some random online game. ",
  "translatedText": "Y mira, sé que sabes que el objetivo del vídeo no es encontrar una respuesta técnicamente óptima a algún juego aleatorio en línea. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.0,
  "end": 189.1
 },
 {
  "input": "The point of the video is to shamelessly hop on the bandwagon of an internet trend to sneak attack people with an information theory lesson. ",
  "translatedText": "El objetivo del vídeo es subirse descaradamente al tren de una tendencia de Internet para atacar furtivamente a las personas con una lección de teoría de la información. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.46,
  "end": 195.9
 },
 {
  "input": "And that's all good, I stand by that part. ",
  "translatedText": "Y eso está bien, mantengo esa parte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.32,
  "end": 198.0
 },
 {
  "input": "But I know how the internet works, and for a lot of people the one main takeaway was what is the best opener for the game wordle. ",
  "translatedText": "Pero sé cómo funciona Internet y, para mucha gente, la principal conclusión fue cuál es el mejor comienzo para el juego. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 204.6
 },
 {
  "input": "And I get it, I walked into that because I put it in the thumbnail, but presumably you can forgive me if I want to add a little correction here. ",
  "translatedText": "Y lo entiendo, entré en eso porque lo puse en la miniatura, pero probablemente me puedan perdonar si quiero agregar una pequeña corrección aquí. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.28,
  "end": 211.86
 },
 {
  "input": "And a more meaningful reason to circle back to all this actually is that I never really talked about what went into that final analysis. ",
  "translatedText": "Y una razón más significativa para volver a todo esto es que en realidad nunca hablé sobre lo que entró en ese análisis final. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.98,
  "end": 218.34
 },
 {
  "input": "And it's interesting as a sublesson in its own right, so it's worth doing here. ",
  "translatedText": "Y es interesante como sublección en sí misma, por lo que vale la pena estudiarla aquí. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.84,
  "end": 222.42
 },
 {
  "input": "Now if you'll recall, most of our time last video was spent on the challenge of trying to write an algorithm to solve wordle that did not use the official list of all possible answers. ",
  "translatedText": "Ahora bien, si recuerdas, dedicamos la mayor parte del tiempo del último video al desafío de intentar escribir un algoritmo para resolver palabras que no utilizaban la lista oficial de todas las respuestas posibles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.14,
  "end": 232.46
 },
 {
  "input": "To my taste, that feels a bit like overfitting to a test set, and what's more fun is building something that's resilient. ",
  "translatedText": "Para mi gusto, eso se siente un poco como sobreadaptarse a un equipo de prueba, y lo que es más divertido es construir algo que sea resistente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.48
 },
 {
  "input": "This is why we went through the whole process of looking at relative word frequencies in the English language to come up with some notion of how likely each one would be to be included as a final answer. ",
  "translatedText": "Es por eso que pasamos por todo el proceso de observar las frecuencias relativas de palabras en el idioma inglés para tener una idea de la probabilidad de que cada una se incluyera como respuesta final. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.9,
  "end": 248.76
 },
 {
  "input": "However, for what we're doing here, where we're just trying to find an absolute best performance period, I am incorporating that official list and just shamelessly overfitting to the test set, which is to say we know with certainty whether a word is included or not, and we can assign a uniform probability to each one. ",
  "translatedText": "Sin embargo, para lo que estamos haciendo aquí, donde simplemente intentamos encontrar el mejor período de rendimiento absoluto, estoy incorporando esa lista oficial y simplemente sobreajustándola descaradamente al conjunto de prueba, es decir, sabemos con certeza si una palabra está incluido o no, y podemos asignar una probabilidad uniforme a cada uno. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.4,
  "end": 265.46
 },
 {
  "input": "If you'll remember, the first step in all of this was to say for a particular opening guess, maybe something like my old favorite, crane, how likely is it that you would see each of the possible patterns? ",
  "translatedText": "Si recuerdas, el primer paso en todo esto fue decir, para una suposición de apertura particular, tal vez algo como mi viejo favorito, crane, ¿qué probabilidad hay de que veas cada uno de los patrones posibles? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 266.44,
  "end": 276.18
 },
 {
  "input": "And in this context, where we are shamelessly overfitting to the wordle answer list, all that involves is counting how many of the possible answers give each one of these patterns. ",
  "translatedText": "Y en este contexto, donde nos estamos sobreajustando descaradamente a la lista de respuestas de Wordle, lo único que implica es contar cuántas de las posibles respuestas dan cada uno de estos patrones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.68,
  "end": 285.34
 },
 {
  "input": "And then of course most of our time was spent on this kind of funny looking formula to quantify the amount of information that you would get from this guess that basically involves going through each one of those buckets and saying how much information would you gain that has this log expression that is a fanciful way of saying how many times would you cut your space of possibilities in half if you observed a given pattern. ",
  "translatedText": "Y luego, por supuesto, pasamos la mayor parte de nuestro tiempo en este tipo de fórmula de aspecto divertido para cuantificar la cantidad de información que obtendríamos de esta suposición que básicamente implica revisar cada uno de esos depósitos y decir cuánta información obtendríamos con eso. Esta expresión logarítmica es una forma imaginativa de decir cuántas veces reducirías tu espacio de posibilidades a la mitad si observaras un patrón determinado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.98,
  "end": 306.84
 },
 {
  "input": "We take a weighted average of all of those and it gives us a measure of how much we expect to learn from this first guess. ",
  "translatedText": "Tomamos un promedio ponderado de todos ellos y nos da una medida de cuánto esperamos aprender de esta primera suposición. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.6,
  "end": 313.18
 },
 {
  "input": "In a moment we'll go deeper than this, but if you simply search through all 13,000 different words that you could start with and you ask which one has the highest expected information, it turns out the best possible answer is soar, which doesn't really look like a real word, but I guess it's an obsolete term for a baby hawk. ",
  "translatedText": "En un momento profundizaremos más, pero si simplemente buscas entre las 13.000 palabras diferentes con las que podrías empezar y preguntas cuál tiene la mayor información esperada, resulta que la mejor respuesta posible es volar, que no Realmente no parece una palabra real, pero supongo que es un término obsoleto para referirse a una cría de halcón. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.56,
  "end": 333.0
 },
 {
  "input": "The top 15 openers by this metric happen to look like this, but these are not necessarily the best opening guesses because they're only looking one step in with the heuristic of expected information to try to estimate what the true score will be. ",
  "translatedText": "Los 15 mejores abridores según esta métrica se ven así, pero estas no son necesariamente las mejores conjeturas de apertura porque solo están buscando un paso adelante con la heurística de la información esperada para tratar de estimar cuál será el puntaje real. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.04,
  "end": 347.54
 },
 {
  "input": "But there's few enough patterns that we can do an exhaustive search two steps in. ",
  "translatedText": "Pero hay pocos patrones suficientes como para que podamos hacer una búsqueda exhaustiva en dos pasos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.92,
  "end": 351.68
 },
 {
  "input": "For example, let's say you opened with soar and the pattern you happen to see was the most likely one, all grays, then you can run identical analysis from that point. ",
  "translatedText": "Por ejemplo, digamos que abrió con Soar y el patrón que vio fue el más probable, todos grises, entonces puede ejecutar un análisis idéntico desde ese punto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 352.16,
  "end": 360.8
 },
 {
  "input": "For a given proposed second guess, something like kitty, what's the distribution across all patterns in that restricted case where we're restricted only to the words that would produce all grays for soar, and then we measure the flatness of that distribution using this expected information formula, and we do that for all 13,000 possible words that we could use as a second guess. ",
  "translatedText": "Para una segunda suposición dada, algo así como kitty, ¿cuál es la distribución en todos los patrones en ese caso restringido en el que estamos restringidos solo a las palabras que producirían todos los grises para soar, y luego medimos la planitud de esa distribución usando esta expectativa? fórmula de información, y lo hacemos para las 13.000 palabras posibles que podríamos usar como una segunda suposición. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 361.32,
  "end": 381.42
 },
 {
  "input": "Doing this we can find the optimal second guess in that scenario and the amount of information we were expected to get from it, and if we wash rinse and repeat and do this for all of the different possible patterns that you might see, we get a full map of all the best possible second guesses together with the expected information of each. ",
  "translatedText": "Al hacer esto, podemos encontrar la segunda suposición óptima en ese escenario y la cantidad de información que se esperaba que obtuviéramos de él, y si lavamos, enjuagamos y repetimos y hacemos esto para todos los diferentes patrones posibles que puedan ver, obtenemos una mapa completo de todas las mejores segundas conjeturas posibles junto con la información esperada de cada una. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.12,
  "end": 399.2
 },
 {
  "input": "From there, if you take a weighted average of all those second step values, weighted according to how likely you are to fall into that bucket, it gives you a measure of how much information you're likely to gain from the guess soar after the second step. ",
  "translatedText": "A partir de ahí, si tomas un promedio ponderado de todos esos valores del segundo paso, ponderados de acuerdo con la probabilidad de que caigas en ese grupo, te dará una medida de cuánta información es probable que obtengas de la suposición que se dispara después del segundo paso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.18,
  "end": 416.8
 },
 {
  "input": "When we use this two-step metric as our new means of ranking, the list gets shaken up a bit. ",
  "translatedText": "Cuando utilizamos esta métrica de dos pasos como nuestra nueva forma de clasificación, la lista cambia un poco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.38,
  "end": 421.78
 },
 {
  "input": "Soar is no longer first place, it falls back to 14th, and instead what rises to the top is slain. ",
  "translatedText": "Soar ya no ocupa el primer lugar, vuelve a caer al puesto 14 y, en cambio, lo que llega a la cima muere. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.08,
  "end": 427.66
 },
 {
  "input": "Again, doesn't feel very real, and it looks like it is a British term for a spade that's used for cutting turf. ",
  "translatedText": "Nuevamente, no parece muy real y parece que es un término británico para una pala que se usa para cortar césped. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.64,
  "end": 436.38
 },
 {
  "input": "Alright, but as you can see it is a really tight race among all of these top contenders for who gains the most information after those two steps. ",
  "translatedText": "Muy bien, pero como puedes ver, es una carrera muy reñida entre todos estos principales contendientes por quién obtiene la mayor cantidad de información después de esos dos pasos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.2,
  "end": 445.0
 },
 {
  "input": "And even still, these are not necessarily the best opening guesses, because information is just the heuristic, it's not telling us the actual score if you actually play the game. ",
  "translatedText": "Y aún así, estas no son necesariamente las mejores conjeturas iniciales, porque la información es sólo heurística, no nos dice la puntuación real si realmente juegas el juego. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.7,
  "end": 454.0
 },
 {
  "input": "What I did is I ran the simulation of playing all 2315 possible wordle games with all possible answers on the top 250 from this list. ",
  "translatedText": "Lo que hice fue ejecutar la simulación de jugar todos los 2315 juegos de palabras posibles con todas las respuestas posibles entre los 250 primeros de esta lista. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.58,
  "end": 464.62
 },
 {
  "input": "And by doing this, seeing how they actually perform, the one that ends up very marginally with the best possible score turns out to be Salé, which is an alternate spelling for Salé, which is a light medieval helmet. ",
  "translatedText": "Y al hacer esto, viendo cómo se desempeñan realmente, el que termina muy marginalmente con la mejor puntuación posible resulta ser Salé, que es una ortografía alternativa de Salé, que es un casco medieval ligero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.46,
  "end": 485.98
 },
 {
  "input": "Alright, if that feels a little bit too fake for you, which it does for me, you'll be happy to know that Trace and Crate give almost identical performance. ",
  "translatedText": "Muy bien, si eso te parece demasiado falso, como a mí me parece, te alegrará saber que Trace y Crate ofrecen un rendimiento casi idéntico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.98,
  "end": 495.78
 },
 {
  "input": "Each of them has the benefit of obviously being a real word, so there is one day when you get it right on the first guess, since both are actual wordle answers. ",
  "translatedText": "Cada una de ellas tiene la ventaja de ser obviamente una palabra real, por lo que hay un día en que aciertas en la primera suposición, ya que ambas son respuestas reales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 496.3,
  "end": 504.06
 },
 {
  "input": "This move from sorting based on the best two-step entropies to sorting based on the lowest average score also shakes up the list, but not nearly as much. ",
  "translatedText": "Este paso de ordenar según las mejores entropías de dos pasos a ordenar según la puntuación promedio más baja también cambia la lista, pero no tanto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.02,
  "end": 512.46
 },
 {
  "input": "For example, Salé was previously third place before it bubbles to the top, and Crate and Trace were both fourth and fifth. ",
  "translatedText": "Por ejemplo, Salé ocupaba anteriormente el tercer lugar antes de llegar a la cima, y Crate y Trace fueron cuarto y quinto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.66,
  "end": 519.08
 },
 {
  "input": "If you're curious, you can get slightly better performance from here by doing a little brute forcing. ",
  "translatedText": "Si tiene curiosidad, puede obtener un rendimiento ligeramente mejor desde aquí aplicando un poco de fuerza bruta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.64,
  "end": 523.72
 },
 {
  "input": "There's a very nice blog post by Jonathan Olson, if you're curious about this, where he also lets you explore what the optimal following guesses are for a few of the starting words based on these optimal algorithms. ",
  "translatedText": "Hay una muy buena publicación de blog de Jonathan Olson, si tiene curiosidad sobre esto, donde también le permite explorar cuáles son las siguientes conjeturas óptimas para algunas de las palabras iniciales basadas en estos algoritmos óptimos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.1,
  "end": 533.66
 },
 {
  "input": "Stepping back from all this though, I'm told by some people that it quote ruins the game to overanalyze it like this and try to find an optimal opening guess. ",
  "translatedText": "Sin embargo, dejando atrás todo esto, algunas personas me han dicho que, entre otras cosas, arruina el juego analizarlo en exceso de esta manera y tratar de encontrar una suposición de apertura óptima. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.18,
  "end": 543.6
 },
 {
  "input": "You know, it feels kind of dirty if you use that opening guess after learning it, and it feels inefficient if you don't. ",
  "translatedText": "Ya sabes, se siente un poco sucio si usas esa suposición inicial después de aprenderla, y se siente ineficaz si no lo haces. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.26,
  "end": 549.66
 },
 {
  "input": "But the thing is, I don't actually think this is the best opener for a human playing the game. ",
  "translatedText": "Pero la cuestión es que en realidad no creo que este sea el mejor abridor para un humano que juega. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.8,
  "end": 554.4
 },
 {
  "input": "For one thing, you would need to know what the optimal second guess is for each one of the patterns that you see. ",
  "translatedText": "Por un lado, necesitaría saber cuál es la segunda estimación óptima para cada uno de los patrones que ve. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.88,
  "end": 559.68
 },
 {
  "input": "And more importantly, all of this is in a setting where we are absurdly overfit to the official wordle answer list. ",
  "translatedText": "Y lo que es más importante, todo esto ocurre en un entorno en el que estamos absurdamente sobreajustados a la lista oficial de respuestas del mundo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.26,
  "end": 566.36
 },
 {
  "input": "The moment that, say, the New York Times chooses to change what that list is under the hood, all of this would go out the window. ",
  "translatedText": "En el momento en que, digamos, el New York Times decida cambiar lo que hay bajo el capó de esa lista, todo esto se iría por la ventana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.58,
  "end": 572.88
 },
 {
  "input": "The way that we humans play the game is just very different from what any of these algorithms are doing. ",
  "translatedText": "La forma en que los humanos jugamos es muy diferente de lo que hacen cualquiera de estos algoritmos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.58,
  "end": 577.68
 },
 {
  "input": "We don't have the word list memorized, we're not doing exhaustive searches, we get intuition from things like what are the vowels and how are they placed. ",
  "translatedText": "No tenemos memorizada la lista de palabras, no hacemos búsquedas exhaustivas, intuimos cosas como cuáles son las vocales y cómo se colocan. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.02,
  "end": 585.08
 },
 {
  "input": "I would actually be most happy if those of you watching this video promptly forgot what happens to be the technically best opening guess, and instead came out remembering things like how do you quantify information, or the fact that you should look out for when a greedy algorithm falls short of the globally best performance that you would get from a deeper search. ",
  "translatedText": "De hecho, sería muy feliz si aquellos de ustedes que ven este video olvidaran rápidamente cuál es la mejor suposición de apertura técnicamente y en su lugar recordaran cosas como cómo se cuantifica la información o el hecho de que se debe tener cuidado cuando un codicioso El algoritmo no alcanza el mejor rendimiento global que se obtendría con una búsqueda más profunda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 585.64,
  "end": 603.1
 },
 {
  "input": "For my taste at least, the joy of writing algorithms to try to play games actually has very little bearing on how I like to play those games as a human. ",
  "translatedText": "Al menos para mi gusto, el placer de escribir algoritmos para intentar jugar juegos en realidad tiene muy poco que ver con cómo me gusta jugar esos juegos como ser humano. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.7,
  "end": 610.76
 },
 {
  "input": "The point of writing algorithms for all this is not to affect the way that we play the game, it's still just a fun word game. ",
  "translatedText": "El objetivo de escribir algoritmos para todo esto no es afectar la forma en que jugamos, sigue siendo solo un divertido juego de palabras. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.3,
  "end": 616.78
 },
 {
  "input": "It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere. ",
  "translatedText": "Se trata de perfeccionar nuestros músculos para escribir algoritmos en contextos más significativos en otros lugares. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.1,
  "end": 620.72
 }
]