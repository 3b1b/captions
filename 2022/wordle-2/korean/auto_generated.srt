1
00:00:00,000 --> 00:00:06,180
지난 주에 저는 정보 이론을 사용하여 Wordle 게임을 해결하는 방법, 또는 적어도 해결해 보는 방법에 대한 영상을 올렸습니다. 

2
00:00:06,580 --> 00:00:09,780
그리고 저는 이것을 간단히 덧붙이고 싶었습니다. 이것을 부록이라 불러야 할까요? 

3
00:00:10,080 --> 00:00:10,660
고백? 

4
00:00:11,020 --> 00:00:13,900
기본적으로 저는 단지 제가 실수한 부분을 설명하고 싶을 뿐입니다. 

5
00:00:14,460 --> 00:00:22,000
Wordle을 다시 만들고 모든 알고리즘을 실행하여 문제를 해결하고 성능을 테스트하기 위해 실행한 코드에 아주 작은 버그가 있는 것으로 나타났습니다. 

6
00:00:22,600 --> 00:00:30,500
그리고 이는 매우 적은 비율의 사례에 영향을 미치는 버그 중 하나이므로 놓치기 쉬웠고 대부분의 경우 실제로 중요하지 않은 아주 작은 영향만 미쳤습니다. 

7
00:00:31,220 --> 00:00:36,360
기본적으로 이는 여러 개의 서로 다른 문자가 포함된 추측에 색상을 할당하는 방법과 관련이 있습니다. 

8
00:00:36,520 --> 00:00:42,120
예를 들어, 속도를 추측했는데 정답이 &#39;준수&#39;라면 추측에서 나온 두 e에 어떤 색을 칠해야 할까요? 

9
00:00:43,060 --> 00:00:49,080
Wordle 규칙에 따라 작동하는 방식은 첫 번째 e가 노란색으로 표시되고 두 번째 e가 회색으로 표시된다는 것입니다. 

10
00:00:49,600 --> 00:00:55,520
당신은 그 첫 번째 것이 참 답의 어떤 것과 일치하는 것으로 생각할 수도 있고, 회색조는 두 번째 e가 없다는 것을 의미합니다. 

11
00:00:55,520 --> 00:01:06,780
대조적으로, 대답이 지우기와 같은 것이라면 두 e는 모두 노란색으로 표시되어 첫 번째 e가 다른 위치에 있고 두 번째 e도 다른 위치에 있음을 나타냅니다. 

12
00:01:07,300 --> 00:01:13,540
마찬가지로 e 중 하나가 히트하고 녹색인 경우 실제 답에 두 번째 e가 없는 경우 두 

13
00:01:13,540 --> 00:01:20,040
번째 e는 회색이 되지만 두 번째 e가 있고 다른 위치에 있는 경우에는 노란색이 됩니다. 

14
00:01:20,700 --> 00:01:29,700
위치. 간단히 말해서, 어딘가에서 실수로 이러한 규칙과 약간 다른 동작을 도입했습니다. 

15
00:01:29,700 --> 00:01:30,140
솔직히 정말 멍청했어요. 

16
00:01:30,140 --> 00:01:36,648
기본적으로 프로젝트 중간 어느 시점에서 나는 일부 계산 속도를 높이고 싶었고 주어진 단어 쌍 사이에서 이 패턴의 값을 계산하는 

17
00:01:36,648 --> 00:01:43,340
방법에 대한 약간의 트릭을 시도하고 있었지만 방금 그렇게 하지 않았습니다. 실제로 깊이 생각하지 않고 약간의 변화를 도입했습니다. 

18
00:01:43,340 --> 00:01:49,590
아이러니한 부분은 결국 작업을 가장 빠르게 만드는 실제 방법은 모든 패턴을 미리 계산하여 모든 것이 조회일 뿐이므로 각 작업을 

19
00:01:49,590 --> 00:01:55,840
수행하는 데 시간이 얼마나 걸리는지는 중요하지 않다는 것입니다. 특히 버그가 있는 코드를 읽기 위해 열심히 작성하고 있습니다. 

20
00:01:56,400 --> 00:01:57,240
아시다시피, 당신은 살고 배웁니다. 

21
00:01:58,040 --> 00:02:02,340
이것이 실제 비디오에 어떤 영향을 미치는지에 관해서는 실제로 변경되는 내용이 거의 없다는 것을 의미합니다. 

22
00:02:02,660 --> 00:02:06,560
물론 정보가 무엇인지, 엔트로피가 무엇인지에 대한 주요 교훈은 모두 동일합니다. 

23
00:02:06,860 --> 00:02:13,659
때때로 특정 단어와 관련된 일부 분포를 화면에 표시하는 경우 다양한 패턴과 관련된 일부 

24
00:02:13,659 --> 00:02:20,320
버킷에는 실제 답변이 더 많거나 적으므로 해당 분포가 실제로 약간 다를 수 있습니다. 

25
00:02:20,840 --> 00:02:26,960
그럼에도 불구하고 이 극단적인 경우에 부딪히는 여러 글자가 있는 단어를 표시하는 경우는 매우 드물기 때문에 실제로 나타나지 않습니다. 

26
00:02:27,680 --> 00:02:34,952
그러나 변하는 몇 안 되는 본질적인 것 중 하나는 틀림없이 상당히 중요한 것 중 하나는 단어 답변 목록에 대해 

27
00:02:34,952 --> 00:02:42,460
가능한 최적의 점수를 찾고자 하는 경우 그러한 알고리즘이 어떤 시작 추측을 사용하는지에 대한 최종 결론이었습니다. 

28
00:02:43,080 --> 00:02:48,563
비디오에서 나는 내가 찾을 수 있는 최고의 성능은 크레인이라는 단어로 시작하는 것에서 나왔다고 말했는데, 

29
00:02:48,563 --> 00:02:52,560
이는 알고리즘이 아주 약간 다른 게임을 하고 있다는 점에서만 사실이었습니다. 

30
00:02:53,160 --> 00:03:00,160
문제를 수정하고 모두 다시 실행한 후에는 이 특정 목록에 대한 이론적으로 최적의 첫 번째 추측이 무엇인지에 대한 다른 대답이 있습니다. 

31
00:03:01,000 --> 00:03:09,100
그리고 보세요, 이 비디오의 요점이 임의의 온라인 게임에 대한 기술적으로 최적의 답을 찾는 것이 아니라는 것을 알고 있습니다. 

32
00:03:09,460 --> 00:03:15,900
영상의 요점은 뻔뻔하게도 인터넷 트렌드에 편승하여 정보 이론 수업을 통해 사람들을 몰래 공격하는 것입니다. 

33
00:03:16,320 --> 00:03:18,000
그리고 그것은 모두 좋습니다. 나는 그 부분을 지지합니다. 

34
00:03:18,200 --> 00:03:23,866
하지만 저는 인터넷이 어떻게 작동하는지 알고 있으며, 많은 사람들이 가장 중요하게 생각하는 점은 게임 단어를 위한 최고의 시작 방법이 무엇인지였습니다. 

35
00:03:23,866 --> 00:03:24,600
그리고 알겠습니다. 

36
00:03:25,280 --> 00:03:31,860
미리보기 이미지에 넣었기 때문에 그 부분에 들어갔습니다. 하지만 여기에 약간의 수정 사항을 추가하고 싶다면 용서해 주실 수 있을 것입니다. 

37
00:03:31,980 --> 00:03:38,340
그리고 실제로 이 모든 것을 다시 언급해야 하는 더 의미 있는 이유는 제가 최종 분석에 무엇이 포함되었는지에 대해 실제로 이야기한 적이 없다는 것입니다. 

38
00:03:38,840 --> 00:03:42,420
그리고 그것은 그 자체로 하위 레슨으로서 흥미롭기 때문에 여기서 해볼 가치가 있습니다. 

39
00:03:43,140 --> 00:03:52,460
기억하시겠지만, 지난 비디오의 대부분의 시간은 가능한 모든 답의 공식 목록을 사용하지 않은 단어를 해결하기 위한 알고리즘을 작성하는 데 소비되었습니다. 

40
00:03:52,980 --> 00:03:58,480
내 취향에는 테스트 세트에 과적합된 것 같은 느낌이 들며, 더 재미있는 것은 탄력적인 것을 구축하는 것입니다. 

41
00:03:58,900 --> 00:04:08,760
이것이 우리가 영어의 상대적인 단어 빈도를 살펴보는 전체 과정을 거쳐 각 단어가 최종 답변에 포함될 가능성에 대한 개념을 찾아낸 이유입니다. 

42
00:04:09,400 --> 00:04:20,759
그러나 우리가 여기서 하고 있는 일, 즉 절대적인 최고 성능 기간을 찾으려는 경우에는 공식 목록을 통합하고 뻔뻔스럽게 테스트 세트에 과대적합하고 있습니다. 

43
00:04:20,759 --> 00:04:25,460
포함 여부에 따라 각 항목에 균일한 확률을 할당할 수 있습니다. 

44
00:04:26,440 --> 00:04:31,310
기억하신다면, 이 모든 것의 첫 번째 단계는 특정한 시작 추측, 아마도 제가 가장 좋아하는 

45
00:04:31,310 --> 00:04:36,180
크레인과 같은 것에 대해 가능한 각 패턴을 볼 가능성이 얼마나 되는지 말하는 것이었습니다. 

46
00:04:36,680 --> 00:04:41,010
그리고 우리가 단어 답변 목록에 뻔뻔스럽게 과대적합하는 이러한 맥락에서 관련된 모든 

47
00:04:41,010 --> 00:04:45,340
것은 이러한 패턴 각각에 대해 가능한 답변 중 얼마나 많은 수를 계산하는 것입니다. 

48
00:04:45,980 --> 00:04:53,125
그리고 물론 우리 시간의 대부분은 기본적으로 각 버킷을 통과하여 얻을 수 있는 정보의 양을 말하는 이 추측에서 

49
00:04:53,125 --> 00:04:59,233
얻을 수 있는 정보의 양을 정량화하기 위해 이런 종류의 재미있어 보이는 공식에 소비되었습니다. 

50
00:04:59,233 --> 00:05:06,840
주어진 패턴을 관찰하면 가능성의 공간을 몇 번이나 절반으로 줄일 것인지를 표현하는 기발한 방법인 이 로그 표현입니다. 

51
00:05:07,600 --> 00:05:13,180
우리는 이들 모두의 가중 평균을 취하여 이 첫 번째 추측에서 얼마나 많은 것을 배울 수 있을지 측정합니다. 

52
00:05:13,560 --> 00:05:23,394
잠시 후에 우리는 이것보다 더 깊이 들어갈 것입니다. 그러나 시작할 수 있는 13,000개의 다른 단어를 모두 검색하고 어떤 단어가 가장 기대되는 정보를 

53
00:05:23,394 --> 00:05:33,000
가지고 있는지 묻는다면 가능한 최선의 대답은 솟아오르는 것입니다. 실제로는 실제 단어처럼 보이지 않지만 아기 매를 지칭하는 구식 용어인 것 같습니다. 

54
00:05:34,040 --> 00:05:40,730
이 지표에 따른 상위 15개 오프너는 다음과 같이 보이지만 실제 점수가 무엇인지 추정하기 위해 예상 

55
00:05:40,730 --> 00:05:47,540
정보의 휴리스틱을 사용하여 한 단계만 보고 있기 때문에 이것이 반드시 최고의 오프닝 추측은 아닙니다. 

56
00:05:47,920 --> 00:05:51,680
하지만 두 단계로 철저한 검색을 수행할 수 있을 만큼 충분한 패턴이 없습니다. 

57
00:05:52,160 --> 00:06:00,800
예를 들어, soar로 열었고 우연히 발견한 패턴이 가장 가능성이 높은 패턴인 모두 회색이었다고 가정하고 해당 지점에서 동일한 분석을 실행할 수 있습니다. 

58
00:06:01,320 --> 00:06:10,875
Kitty와 같이 제안된 두 번째 추측에 대해, soar에 대한 모든 회색을 생성하는 단어로만 제한되는 제한된 경우의 모든 패턴에 대한 분포는 무엇입니까? 

59
00:06:10,875 --> 00:06:17,356
그런 다음 예상되는 이 값을 사용하여 해당 분포의 평탄도를 측정합니다. 두 번째 추측으로 사용할 수 있는 

60
00:06:17,356 --> 00:06:21,420
13,000개의 가능한 단어 모두에 대해 정보 공식을 적용합니다. 

61
00:06:22,120 --> 00:06:29,159
이를 통해 우리는 해당 시나리오에서 최적의 두 번째 추측과 그로부터 얻을 것으로 예상되는 정보의 양을 찾을 수 있습니다. 

62
00:06:29,159 --> 00:06:34,852
그리고 볼 수 있는 모든 가능한 패턴에 대해 헹구고 반복하여 이 작업을 수행하면 다음을 얻습니다. 

63
00:06:34,852 --> 00:06:39,200
가능한 최선의 두 번째 추측이 모두 포함된 전체 지도와 각각의 예상 정보. 

64
00:06:43,180 --> 00:06:50,188
거기에서 모든 두 번째 단계 값의 가중 평균을 취하고 해당 버킷에 빠질 가능성에 따라 가중치를 

65
00:06:50,188 --> 00:06:56,800
적용하면 추측이 치솟은 후 얻을 수 있는 정보의 양을 측정할 수 있습니다. 두번째 단계. 

66
00:06:57,380 --> 00:07:01,780
이 2단계 측정항목을 순위를 정하는 새로운 수단으로 사용하면 목록이 약간 흔들립니다. 

67
00:07:02,080 --> 00:07:07,660
Soar는 더 이상 1위가 아니며 14위로 다시 떨어지며, 대신 정상에 오른 것은 죽임을 당합니다. 

68
00:07:08,640 --> 00:07:17,200
다시 말하지만, 그다지 현실감이 없으며 잔디를 자르는 데 사용되는 삽을 가리키는 영국 용어인 것 같습니다. 좋습니다. 

69
00:07:17,200 --> 00:07:25,000
하지만 보시다시피 이 두 단계 후에 누가 가장 많은 정보를 얻을 수 있는지에 대한 모든 최고 경쟁자 사이에서는 정말 치열한 경쟁이 벌어지고 있습니다. 

70
00:07:25,700 --> 00:07:34,000
그럼에도 불구하고 이것이 반드시 최선의 시작 추측은 아닙니다. 정보는 경험적일 뿐이고 실제로 게임을 플레이할 경우 실제 점수를 알려주는 것은 아니기 때문입니다. 

71
00:07:34,580 --> 00:07:44,620
내가 한 일은 이 목록의 상위 250개에 대한 모든 가능한 답을 가지고 2315개의 가능한 단어 게임을 모두 플레이하는 시뮬레이션을 실행한 것입니다. 

72
00:07:46,460 --> 00:07:59,815
그리고 이렇게 함으로써, 그들이 실제로 어떻게 수행하는지를 보면, 가능한 최고의 점수로 아주 미미하게 끝나는 것은 Salé로 밝혀졌습니다. 

73
00:07:59,815 --> 00:08:05,980
이는 가벼운 중세 헬멧인 Salé의 대체 철자인 Salé입니다. 

74
00:08:06,980 --> 00:08:16,360
좋아요, 저처럼 그것이 여러분에게 너무 가짜라고 느껴지신다면 Trace와 Crate가 거의 동일한 성능을 제공한다는 사실을 알게 되어 기뻐하실 것입니다. 

75
00:08:16,360 --> 00:08:24,060
각각은 분명히 실제 단어라는 이점이 있으므로 둘 다 실제 단어 답변이기 때문에 첫 번째 추측에서 정답을 얻을 날이 있습니다. 

76
00:08:25,020 --> 00:08:32,460
최고의 2단계 엔트로피를 기반으로 한 정렬에서 가장 낮은 평균 점수를 기반으로 한 정렬로의 이동도 목록을 뒤흔들지만 그다지 많지는 않습니다. 

77
00:08:32,659 --> 00:08:39,080
예를 들어, Salé는 상위권에 오르기 전 이전에 3위였으며 Crate와 Trace는 모두 4위와 5위였습니다. 

78
00:08:39,640 --> 00:08:43,720
궁금하다면 여기에서 약간의 무차별 대입을 수행하여 약간 더 나은 성능을 얻을 수 있습니다. 

79
00:08:44,100 --> 00:08:48,696
Jonathan Olson이 작성한 매우 멋진 블로그 게시물이 있습니다. 여기에서 최적의 

80
00:08:48,696 --> 00:08:53,660
알고리즘을 기반으로 몇 가지 시작 단어에 대한 최적의 다음 추측이 무엇인지 탐색할 수 있습니다. 

81
00:08:55,180 --> 00:09:02,940
하지만 이 모든 것에서 물러나서, 일부 사람들은 게임을 이렇게 과도하게 분석하고 최적의 오프닝 추측을 찾으려고 노력하는 것이 게임을 망친다고 말했습니다. 

82
00:09:02,940 --> 00:09:09,660
아시다시피, 학습한 후 시작 추측을 사용하면 좀 더러운 느낌이 들고, 그렇지 않으면 비효율적인 느낌이 듭니다. 

83
00:09:09,800 --> 00:09:14,100
하지만 문제는 이것이 인간이 게임을 플레이하기 위한 최고의 오프너라고 생각하지 않는다는 것입니다. 

84
00:09:14,100 --> 00:09:19,680
우선, 표시된 각 패턴에 대한 최적의 두 번째 추측이 무엇인지 알아야 합니다. 

85
00:09:20,260 --> 00:09:26,360
그리고 더 중요한 것은 이 모든 것이 공식 단어 답변 목록에 터무니없이 과적합된 환경에 있다는 것입니다. 

86
00:09:26,580 --> 00:09:32,880
예를 들어 New York Times가 그 목록의 내용을 변경하기로 결정하는 순간 이 모든 것이 창 밖으로 사라질 것입니다. 

87
00:09:33,580 --> 00:09:37,680
우리 인간이 게임을 플레이하는 방식은 이러한 알고리즘이 수행하는 방식과 매우 다릅니다. 

88
00:09:38,020 --> 00:09:45,080
우리는 단어 목록을 기억하지 않고 철저한 검색을 수행하지 않으며 모음이 무엇인지, 모음이 어떻게 배치되는지와 같은 직관을 얻습니다. 

89
00:09:45,640 --> 00:09:54,532
이 비디오를 시청하는 분들이 기술적으로 가장 좋은 오프닝 추측이 무엇인지 즉시 잊어버리고 대신 정보를 수량화하는 방법이나 욕심이 많을 때 조심해야 

90
00:09:54,532 --> 00:10:03,100
하는 사실 등을 기억해 주신다면 실제로 가장 기쁠 것입니다. 알고리즘은 더 깊은 검색에서 얻을 수 있는 세계 최고의 성능에 미치지 못합니다. 

91
00:10:03,700 --> 00:10:10,760
적어도 내 취향에 따르면, 게임을 하기 위해 알고리즘을 작성하는 즐거움은 실제로 내가 인간으로서 그 게임을 즐기는 방식에 거의 영향을 미치지 않습니다. 

92
00:10:11,300 --> 00:10:16,780
이 모든 것에 대한 알고리즘을 작성하는 목적은 우리가 게임을 하는 방식에 영향을 미치는 것이 아니라 여전히 재미있는 단어 게임일 뿐입니다. 

93
00:10:17,100 --> 00:10:20,720
다른 곳에서 보다 의미 있는 맥락에서 알고리즘을 작성하기 위해 근육을 단련하는 것입니다. 

