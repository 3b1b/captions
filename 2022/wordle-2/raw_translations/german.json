[
 {
  "input": "Last week I put up this video about solving the game Wordle, or at least trying to solve it, using information theory.",
  "model": "nmt",
  "translatedText": "Letzte Woche habe ich dieses Video über die Lösung des Spiels Wordle oder zumindest den Versuch, es mithilfe der Informationstheorie zu lösen, veröffentlicht.",
  "time_range": [
   0.0,
   6.15032967032967
  ]
 },
 {
  "input": "And I wanted to add a quick, what should we call this, an addendum?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   6.15032967032967,
   9.92
  ]
 },
 {
  "input": "A confession?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   9.92,
   10.602105263157895
  ]
 },
 {
  "input": "Basically I just want to explain a place where I made a mistake.",
  "model": "nmt",
  "translatedText": "Und ich wollte kurz etwas hinzufügen, wie soll man das nennen, einen Nachtrag, ein Geständnis, im Grunde möchte ich nur eine Stelle erklären, an der ich einen Fehler gemacht habe.",
  "time_range": [
   10.602105263157895,
   14.24
  ]
 },
 {
  "input": "It turns out there was a very slight bug in the code that I was running to recreate Wordle and then run all of the algorithms to solve it and test their performance.",
  "model": "nmt",
  "translatedText": "Es stellte sich heraus, dass es einen sehr kleinen Fehler im Code gab, den ich ausführte, um Wordle neu zu erstellen und dann alle Algorithmen auszuführen, um das Problem zu beheben und ihre Leistung zu testen.",
  "time_range": [
   14.24,
   22.034285714285716
  ]
 },
 {
  "input": "And it's one of those bugs that affects a very small percentage of cases, so it was easy to miss, and it has only a very slight effect that for the most part doesn't really matter.",
  "model": "nmt",
  "translatedText": "Und es handelt sich um einen dieser Fehler, der nur einen sehr kleinen Prozentsatz der Fälle betrifft, daher war er leicht zu übersehen und hat nur eine sehr geringe Auswirkung, die in den meisten Fällen nicht wirklich ins Gewicht fällt.",
  "time_range": [
   22.034285714285716,
   30.95090909090909
  ]
 },
 {
  "input": "Basically it had to do with how you assign a color to a guess that has multiple different letters in it.",
  "model": "nmt",
  "translatedText": "Im Grunde ging es darum, wie man einer Vermutung, die mehrere verschiedene Buchstaben enthält, eine Farbe zuordnet.",
  "time_range": [
   30.95090909090909,
   36.20903225806452
  ]
 },
 {
  "input": "For example, if you guess speed and the true answer is abide, how should you color those two e's from the guess?",
  "model": "nmt",
  "translatedText": "Wenn Sie beispielsweise Geschwindigkeit schätzen und die wahre Antwort „Verbleiben“ lautet, wie sollten Sie dann die beiden „e“ aus der Schätzung färben?",
  "time_range": [
   36.20903225806452,
   42.8
  ]
 },
 {
  "input": "Well the way that it works with the Wordle conventions is that the first e would be colored yellow, and the second one would be colored gray.",
  "model": "nmt",
  "translatedText": "Nun, die Art und Weise, wie es mit den Wordle-Konventionen funktioniert, ist, dass das erste e gelb und das zweite grau gefärbt wäre.",
  "time_range": [
   42.8,
   48.85690721649485
  ]
 },
 {
  "input": "You might think of that first one as matching up with something from the true answer, and the grayness is telling you there is no second e.",
  "model": "nmt",
  "translatedText": "Sie denken vielleicht, dass das erste e mit etwas aus der wahren Antwort übereinstimmt, und die Grauheit sagt Ihnen, dass es kein zweites e gibt.",
  "time_range": [
   48.85690721649485,
   56.0
  ]
 },
 {
  "input": "By contrast, if the answer was something like erase, both of those e's would be colored yellow, telling you that there is a first e in a different location, and there's a second e also in a different location.",
  "model": "nmt",
  "translatedText": "Wenn die Antwort dagegen so etwas wie „löschen“ wäre, würden beide E gelb gefärbt sein, was darauf hinweist, dass sich ein erstes E an einer anderen Stelle und ein zweites E ebenfalls an einer anderen Stelle befindet.",
  "time_range": [
   56.0,
   66.88510638297873
  ]
 },
 {
  "input": "Similarly if one of the e's hits and it's green, then that second one would be gray in the case where the true answer has no second e, but it would be yellow in the case where there is a second e and it's just in a different location.",
  "model": "nmt",
  "translatedText": "Ähnlich verhält es sich, wenn eines der E&#39;s trifft und es grün ist, dann wäre das zweite grau, wenn die wahre Antwort kein zweites E hat, aber es wäre gelb, wenn es ein zweites E gibt und es nur in einem anderen ist Standort.",
  "time_range": [
   66.88510638297873,
   80.06400000000001
  ]
 },
 {
  "input": "Long story short, somewhere along the way I accidentally introduced behavior that differs from these conventions slightly.",
  "model": "nmt",
  "translatedText": "Um es kurz zu machen: Irgendwann habe ich versehentlich ein Verhalten eingeführt, das leicht von diesen Konventionen abweicht.",
  "time_range": [
   80.06400000000001,
   86.96
  ]
 },
 {
  "input": "Honestly it was really dumb.",
  "model": "nmt",
  "translatedText": "Ehrlich gesagt war es wirklich dumm.",
  "time_range": [
   86.96,
   88.34521739130435
  ]
 },
 {
  "input": "Basically at some point in the middle of the project I wanted to speed up some of the computations, and I was trying a little trick for how it computed the value for this pattern between any given pair of words, and you know I just didn't really think it through and it introduced this slight change.",
  "model": "nmt",
  "translatedText": "Im Grunde wollte ich irgendwann in der Mitte des Projekts einige Berechnungen beschleunigen, und ich habe einen kleinen Trick ausprobiert, wie der Wert für dieses Muster zwischen einem bestimmten Wortpaar berechnet werden soll, und Sie wissen, ich habe es einfach nicht geschafft. Ich habe nicht wirklich darüber nachgedacht und es hat diese kleine Änderung eingeführt.",
  "time_range": [
   88.34521739130435,
   102.8898969072165
  ]
 },
 {
  "input": "The ironic part is that in the end the actual way to make things fastest is to pre-compute all those patterns so that everything is just a lookup, and so it wouldn't matter how long it takes to do each one, especially if you're writing hard to read buggy code to make it happen.",
  "model": "nmt",
  "translatedText": "Das Ironische daran ist, dass der eigentliche Weg, die Dinge am Ende schneller zu machen, darin besteht, alle diese Muster vorab zu berechnen, so dass alles nur eine Suche ist und es keine Rolle spielt, wie lange es dauert, jedes einzelne zu erledigen, vor allem, wenn Sie es tun Ich schreibe schwer lesbaren, fehlerhaften Code, um dies zu ermöglichen.",
  "time_range": [
   102.8898969072165,
   115.89
  ]
 },
 {
  "input": "You know, you live and you learn.",
  "model": "nmt",
  "translatedText": "Weißt du, du lebst und lernst.",
  "time_range": [
   115.89,
   117.6225
  ]
 },
 {
  "input": "As far as how this affects the actual video, I mean very little of substance really changes.",
  "model": "nmt",
  "translatedText": "Was die Auswirkungen auf das eigentliche Video angeht, meine ich, dass sich inhaltlich kaum etwas ändert.",
  "time_range": [
   117.6225,
   122.15422680412374
  ]
 },
 {
  "input": "Of course the main lessons about what is information, what is entropy, all that stays the same.",
  "model": "nmt",
  "translatedText": "Natürlich bleiben die wichtigsten Lehren darüber, was Information ist, was Entropie ist, alles gleich.",
  "time_range": [
   122.15422680412374,
   126.58526315789473
  ]
 },
 {
  "input": "Every now and then if I'm showing on screen some distribution associated with a given word, that distribution might actually be a little bit off because some of the buckets associated with various patterns should include either more or fewer true answers.",
  "model": "nmt",
  "translatedText": "Hin und wieder, wenn ich auf dem Bildschirm eine mit einem bestimmten Wort verbundene Verteilung zeige, kann es sein, dass diese Verteilung tatsächlich ein wenig abweicht, da einige der mit verschiedenen Mustern verknüpften Buckets entweder mehr oder weniger wahre Antworten enthalten sollten.",
  "time_range": [
   126.58526315789473,
   139.74127659574467
  ]
 },
 {
  "input": "Even then it doesn't really come up because it was very rare that I would be showing a word that had multiple letters that also hit this edge case.",
  "model": "nmt",
  "translatedText": "Selbst dann taucht es nicht wirklich auf, da es sehr selten vorkam, dass ich ein Wort mit mehreren Buchstaben anzeigte, die auch diesen Randfall trafen.",
  "time_range": [
   139.74127659574467,
   147.77666666666667
  ]
 },
 {
  "input": "But one of the very few things of substance that does change and that arguably does matter a fair bit was the final conclusion around how if we want to find the optimal possible score for the wordle answer list, what opening guess does such an algorithm use?",
  "model": "nmt",
  "translatedText": "Aber eines der wenigen inhaltlichen Dinge, die sich ändern und die wohl ziemlich wichtig sind, war die abschließende Schlussfolgerung darüber, welche Eröffnungsschätzung ein solcher Algorithmus verwendet, wenn wir die optimale mögliche Punktzahl für die Wordle-Antwortliste finden wollen.",
  "time_range": [
   147.77666666666667,
   162.60129032258067
  ]
 },
 {
  "input": "In the video I said the best performance that I could find came from opening with the word crane, which was true only in the sense that the algorithms were playing a very slightly different game.",
  "model": "nmt",
  "translatedText": "Im Video habe ich gesagt, dass die beste Leistung, die ich finden konnte, durch das Öffnen mit dem Wort „Kranich“ erzielt wurde, was nur in dem Sinne stimmte, dass die Algorithmen ein ganz etwas anderes Spiel spielten.",
  "time_range": [
   162.60129032258067,
   172.89306122448983
  ]
 },
 {
  "input": "After fixing it and rerunning it all, there is a different answer for what the theoretically optimal first guess is for this particular list.",
  "model": "nmt",
  "translatedText": "Nachdem das Problem behoben und alles erneut ausgeführt wurde, gibt es eine andere Antwort auf die Frage, was die theoretisch optimale erste Vermutung für diese bestimmte Liste ist.",
  "time_range": [
   172.89306122448983,
   180.8
  ]
 },
 {
  "input": "And look, I know that you know that the point of the video is not to find some technically optimal answer to some random online game.",
  "model": "nmt",
  "translatedText": "Und ich weiß, dass Sie wissen, dass der Zweck des Videos nicht darin besteht, eine technisch optimale Antwort auf ein beliebiges Online-Spiel zu finden.",
  "time_range": [
   180.8,
   188.85247311827953
  ]
 },
 {
  "input": "The point of the video is to shamelessly hop on the bandwagon of an internet trend to sneak attack people with an information theory lesson.",
  "model": "nmt",
  "translatedText": "Der Sinn des Videos besteht darin, schamlos auf den Zug eines Internettrends aufzuspringen, um Menschen mit einer Informationstheorie-Lektion heimlich anzugreifen.",
  "time_range": [
   188.85247311827953,
   196.24
  ]
 },
 {
  "input": "And that's all good, I stand by that part.",
  "model": "nmt",
  "translatedText": "Und das ist alles gut, ich stehe zu diesem Teil.",
  "time_range": [
   196.24,
   197.96817204301072
  ]
 },
 {
  "input": "But I know how the internet works, and for a lot of people the one main takeaway was what is the best opener for the game wordle.",
  "model": "nmt",
  "translatedText": "Aber ich weiß, wie das Internet funktioniert, und für viele Leute war die wichtigste Erkenntnis, was der beste Opener für die Welt des Spiels ist.",
  "time_range": [
   197.96817204301072,
   204.7660606060606
  ]
 },
 {
  "input": "And I get it, I walked into that because I put it in the thumbnail, but presumably you can forgive me if I want to add a little correction here.",
  "model": "nmt",
  "translatedText": "Und ich verstehe, ich bin darauf reingegangen, weil ich es in die Miniaturansicht eingefügt habe, aber Sie können mir vermutlich verzeihen, wenn ich hier eine kleine Korrektur hinzufügen möchte.",
  "time_range": [
   204.7660606060606,
   211.65333333333334
  ]
 },
 {
  "input": "And a more meaningful reason to circle back to all this actually is that I never really talked about what went into that final analysis.",
  "model": "nmt",
  "translatedText": "Und ein bedeutsamerer Grund, noch einmal auf all das zurückzukommen, ist, dass ich nie wirklich darüber gesprochen habe, was in diese abschließende Analyse eingeflossen ist.",
  "time_range": [
   211.65333333333334,
   218.4430769230769
  ]
 },
 {
  "input": "And it's interesting as a sublesson in its own right, so it's worth doing here.",
  "model": "nmt",
  "translatedText": "Und als eigenständige Unterlektion ist es interessant, es lohnt sich also, es hier zu machen.",
  "time_range": [
   218.4430769230769,
   222.64703296703297
  ]
 },
 {
  "input": "Now if you'll recall, most of our time last video was spent on the challenge of trying to write an algorithm to solve wordle that did not use the official list of all possible answers.",
  "model": "nmt",
  "translatedText": "Wenn Sie sich erinnern, haben wir im letzten Video die meiste Zeit mit der Herausforderung verbracht, einen Algorithmus zur Lösung von Wörtern zu schreiben, der nicht die offizielle Liste aller möglichen Antworten verwendet.",
  "time_range": [
   222.64703296703297,
   232.36301075268818
  ]
 },
 {
  "input": "To my taste, that feels a bit like overfitting to a test set, and what's more fun is building something that's resilient.",
  "model": "nmt",
  "translatedText": "Meiner Meinung nach fühlt sich das ein bisschen wie eine Überanpassung an ein Testset an, und was noch mehr Spaß macht, ist, etwas zu bauen, das belastbar ist.",
  "time_range": [
   232.36301075268818,
   238.6663917525773
  ]
 },
 {
  "input": "This is why we went through the whole process of looking at relative word frequencies in the English language to come up with some notion of how likely each one would be to be included as a final answer.",
  "model": "nmt",
  "translatedText": "Aus diesem Grund haben wir den gesamten Prozess der Betrachtung der relativen Worthäufigkeiten in der englischen Sprache durchlaufen, um eine Vorstellung davon zu bekommen, wie wahrscheinlich es ist, dass jedes einzelne Wort in die endgültige Antwort aufgenommen wird.",
  "time_range": [
   238.6663917525773,
   249.12
  ]
 },
 {
  "input": "However, for what we're doing here, where we're just trying to find an absolute best performance period, I am incorporating that official list and just shamelessly overfitting to the test set, which is to say we know with certainty whether a word is included or not, and we can assign a uniform probability to each one.",
  "model": "nmt",
  "translatedText": "Für das, was wir hier tun, wo wir lediglich versuchen, eine absolut beste Leistungsperiode zu finden, beziehe ich diese offizielle Liste ein und passe sie einfach schamlos an den Testsatz an, das heißt, wir wissen mit Sicherheit, ob ein Wort enthalten ist oder nicht, und wir können jedem eine einheitliche Wahrscheinlichkeit zuweisen.",
  "time_range": [
   249.12,
   265.29545454545456
  ]
 },
 {
  "input": "If you'll remember, the first step in all of this was to say for a particular opening guess, maybe something like my old favorite, crane, how likely is it that you would see each of the possible patterns?",
  "model": "nmt",
  "translatedText": "Wenn Sie sich erinnern, bestand der erste Schritt bei all dem darin, für eine bestimmte Eröffnungsschätzung, vielleicht so etwas wie meinen alten Favoriten, den Kranich, zu fragen, wie wahrscheinlich es ist, dass Sie jedes der möglichen Muster sehen würden?",
  "time_range": [
   265.29545454545456,
   276.2444943820225
  ]
 },
 {
  "input": "And in this context, where we are shamelessly overfitting to the wordle answer list, all that involves is counting how many of the possible answers give each one of these patterns.",
  "model": "nmt",
  "translatedText": "Und in diesem Zusammenhang, in dem wir uns schamlos an die Antwortliste der Welt anpassen, müssen wir nur zählen, wie viele der möglichen Antworten jedes dieser Muster ergeben.",
  "time_range": [
   276.2444943820225,
   285.3502040816327
  ]
 },
 {
  "input": "And then of course most of our time was spent on this kind of funny looking formula to quantify the amount of information that you would get from this guess that basically involves going through each one of those buckets and saying how much information would you gain that has this log expression that is a fanciful way of saying how many times would you cut your space of possibilities in half if you observed a given pattern.",
  "model": "nmt",
  "translatedText": "Und dann haben wir natürlich die meiste Zeit mit dieser komisch aussehenden Formel verbracht, um die Menge an Informationen zu quantifizieren, die Sie aus dieser Vermutung erhalten würden. Dabei geht es im Wesentlichen darum, jeden einzelnen dieser Eimer durchzugehen und zu sagen, wie viele Informationen Sie daraus gewinnen würden Dieser logarithmische Ausdruck ist eine fantasievolle Art auszudrücken, wie oft Sie Ihren Raum an Möglichkeiten halbieren würden, wenn Sie ein bestimmtes Muster beobachten würden.",
  "time_range": [
   285.3502040816327,
   307.0604255319149
  ]
 },
 {
  "input": "We take a weighted average of all of those and it gives us a measure of how much we expect to learn from this first guess.",
  "model": "nmt",
  "translatedText": "Wir bilden einen gewichteten Durchschnitt aller Werte und er gibt uns einen Maßstab dafür, wie viel wir aus dieser ersten Vermutung lernen können.",
  "time_range": [
   307.0604255319149,
   313.06122448979596
  ]
 },
 {
  "input": "In a moment we'll go deeper than this, but if you simply search through all 13,000 different words that you could start with and you ask which one has the highest expected information, it turns out the best possible answer is soar, which doesn't really look like a real word, but I guess it's an obsolete term for a baby hawk.",
  "model": "nmt",
  "translatedText": "Wir gehen gleich noch tiefer darauf ein, aber wenn Sie einfach alle 13. 000 verschiedenen Wörter durchsuchen, mit denen Sie beginnen könnten, und fragen, welches die höchsten erwarteten Informationen enthält, stellt sich heraus, dass die bestmögliche Antwort soar ist, was nicht der Fall ist. Es sieht nicht wirklich wie ein echtes Wort aus, aber ich vermute, dass es ein veralteter Begriff für einen Babyfalken ist.",
  "time_range": [
   313.06122448979596,
   332.8862222222223
  ]
 },
 {
  "input": "The top 15 openers by this metric happen to look like this, but these are not necessarily the best opening guesses because they're only looking one step in with the heuristic of expected information to try to estimate what the true score will be.",
  "model": "nmt",
  "translatedText": "Die Top-15-Eröffnungsspieler nach dieser Kennzahl sehen zufällig so aus, aber das sind nicht unbedingt die besten Eröffnungsschätzungen, da sie nur einen Schritt in der Heuristik der erwarteten Informationen betrachten, um zu versuchen, die tatsächliche Punktzahl abzuschätzen.",
  "time_range": [
   332.8862222222223,
   347.36090909090905
  ]
 },
 {
  "input": "But there's few enough patterns that we can do an exhaustive search two steps in.",
  "model": "nmt",
  "translatedText": "Aber es gibt nur wenige Muster, die es uns ermöglichen würden, in zwei Schritten eine umfassende Suche durchzuführen.",
  "time_range": [
   347.36090909090905,
   352.0
  ]
 },
 {
  "input": "For example, let's say you opened with soar and the pattern you happen to see was the most likely one, all grays, then you can run identical analysis from that point.",
  "model": "nmt",
  "translatedText": "Nehmen wir zum Beispiel an, Sie haben mit „Soar“ geöffnet und das Muster, das Sie zufällig sehen, ist das wahrscheinlichste, nämlich nur Grautöne, dann können Sie von diesem Punkt aus eine identische Analyse durchführen.",
  "time_range": [
   352.0,
   360.9036363636364
  ]
 },
 {
  "input": "For a given proposed second guess, something like kitty, what's the distribution across all patterns in that restricted case where we're restricted only to the words that would produce all grays for soar, and then we measure the flatness of that distribution using this expected information formula, and we do that for all 13,000 possible words that we could use as a second guess.",
  "model": "nmt",
  "translatedText": "Wie ist für eine gegebene vorgeschlagene zweite Schätzung, etwa „kitty“, die Verteilung über alle Muster in diesem eingeschränkten Fall, in dem wir uns nur auf die Wörter beschränken, die alle Grautöne für „soar“ erzeugen würden, und dann messen wir die Flachheit dieser Verteilung anhand dieses Erwartungswerts? Informationsformel, und das machen wir für alle 13. 000 möglichen Wörter, die wir als zweite Vermutung verwenden könnten.",
  "time_range": [
   360.9036363636364,
   381.49600000000004
  ]
 },
 {
  "input": "Doing this we can find the optimal second guess in that scenario and the amount of information we were expected to get from it, and if we wash rinse and repeat and do this for all of the different possible patterns that you might see, we get a full map of all the best possible second guesses together with the expected information of each.",
  "model": "nmt",
  "translatedText": "Auf diese Weise können wir die optimale zweite Schätzung in diesem Szenario und die Menge an Informationen finden, die wir daraus erhalten sollten. Wenn wir dies für alle möglichen Muster wiederholen, die Sie möglicherweise sehen, erhalten wir eine vollständige Karte aller bestmöglichen zweiten Vermutungen zusammen mit den erwarteten Informationen zu jeder.",
  "time_range": [
   381.49600000000004,
   400.2933333333334
  ]
 },
 {
  "input": "From there, if you take a weighted average of all those second step values, weighted according to how likely you are to fall into that bucket, it gives you a measure of how much information you're likely to gain from the guess soar after the second step.",
  "model": "nmt",
  "translatedText": "Wenn Sie von dort aus einen gewichteten Durchschnitt aller dieser Werte des zweiten Schritts nehmen, der danach gewichtet wird, wie wahrscheinlich es ist, dass Sie in diesen Bereich fallen, erhalten Sie ein Maß dafür, wie viele Informationen Sie wahrscheinlich aus dem Schätzanstieg nach dem Ergebnis gewinnen werden zweiter Schritt.",
  "time_range": [
   400.2933333333334,
   417.13130434782613
  ]
 },
 {
  "input": "When we use this two-step metric as our new means of ranking, the list gets shaken up a bit.",
  "model": "nmt",
  "translatedText": "Wenn wir diese zweistufige Metrik als neues Ranking-Mittel verwenden, gerät die Liste etwas durcheinander.",
  "time_range": [
   417.13130434782613,
   421.9778723404255
  ]
 },
 {
  "input": "Soar is no longer first place, it falls back to 14th, and instead what rises to the top is slain.",
  "model": "nmt",
  "translatedText": "Soar steht nicht mehr an erster Stelle, sondern fällt auf den 14. Platz zurück, und stattdessen wird getötet, was an die Spitze gelangt.",
  "time_range": [
   421.9778723404255,
   428.5507368421053
  ]
 },
 {
  "input": "Again, doesn't feel very real, and it looks like it is a British term for a spade that's used for cutting turf.",
  "model": "nmt",
  "translatedText": "Auch hier fühlt es sich nicht sehr real an und es sieht so aus, als wäre es ein britischer Begriff für einen Spaten, der zum Schneiden von Rasen verwendet wird.",
  "time_range": [
   428.5507368421053,
   436.2633333333334
  ]
 },
 {
  "input": "Alright, but as you can see it is a really tight race among all of these top contenders for who gains the most information after those two steps.",
  "model": "nmt",
  "translatedText": "Okay, aber wie Sie sehen, ist es ein wirklich enges Rennen zwischen all diesen Top-Anwärtern darum, wer nach diesen beiden Schritten die meisten Informationen erhält.",
  "time_range": [
   436.2633333333334,
   445.24085106382984
  ]
 },
 {
  "input": "And even still, these are not necessarily the best opening guesses, because information is just the heuristic, it's not telling us the actual score if you actually play the game.",
  "model": "nmt",
  "translatedText": "Und dennoch sind dies nicht unbedingt die besten Eröffnungstipps, da es sich bei den Informationen nur um heuristische Elemente handelt, die uns nicht das tatsächliche Ergebnis verraten, wenn Sie das Spiel tatsächlich spielen.",
  "time_range": [
   445.24085106382984,
   454.4436363636364
  ]
 },
 {
  "input": "What I did is I ran the simulation of playing all 2315 possible wordle games with all possible answers on the top 250 from this list.",
  "model": "nmt",
  "translatedText": "Ich habe die Simulation durchgeführt, bei der alle 2315 möglichen Weltspiele mit allen möglichen Antworten auf die 250 besten aus dieser Liste gespielt wurden.",
  "time_range": [
   454.4436363636364,
   466.16
  ]
 },
 {
  "input": "And by doing this, seeing how they actually perform, the one that ends up very marginally with the best possible score turns out to be Salé, which is an alternate spelling for Salé, which is a light medieval helmet.",
  "model": "nmt",
  "translatedText": "Und wenn man so vorgeht, stellt sich heraus, dass Salé, eine alternative Schreibweise für Salé, was ein leichter mittelalterlicher Helm ist, derjenige ist, der ganz knapp die bestmögliche Punktzahl erzielt.",
  "time_range": [
   466.16,
   486.413023255814
  ]
 },
 {
  "input": "Alright, if that feels a little bit too fake for you, which it does for me, you'll be happy to know that Trace and Crate give almost identical performance.",
  "model": "nmt",
  "translatedText": "Okay, wenn Ihnen das ein bisschen zu aufgesetzt vorkommt, was bei mir der Fall ist, werden Sie froh sein zu erfahren, dass Trace und Crate eine fast identische Leistung erbringen.",
  "time_range": [
   486.413023255814,
   496.24
  ]
 },
 {
  "input": "Each of them has the benefit of obviously being a real word, so there is one day when you get it right on the first guess, since both are actual wordle answers.",
  "model": "nmt",
  "translatedText": "Jeder von ihnen hat den Vorteil, dass es sich offensichtlich um ein echtes Wort handelt. Es gibt also einen Tag, an dem man beim ersten Raten richtig liegt, da es sich bei beiden um echte Wortantworten handelt.",
  "time_range": [
   496.24,
   504.628085106383
  ]
 },
 {
  "input": "This move from sorting based on the best two-step entropies to sorting based on the lowest average score also shakes up the list, but not nearly as much.",
  "model": "nmt",
  "translatedText": "Dieser Wechsel von der Sortierung nach den besten zweistufigen Entropien hin zur Sortierung nach dem niedrigsten Durchschnittswert bringt auch die Liste durcheinander, aber nicht annähernd so sehr.",
  "time_range": [
   504.628085106383,
   512.3478260869565
  ]
 },
 {
  "input": "For example, Salé was previously third place before it bubbles to the top, and Crate and Trace were both fourth and fifth.",
  "model": "nmt",
  "translatedText": "Salé lag zum Beispiel zuvor auf dem dritten Platz, bevor es an die Spitze sprudelte, und Crate und Trace belegten jeweils den vierten und fünften Platz.",
  "time_range": [
   512.3478260869565,
   518.9142857142858
  ]
 },
 {
  "input": "If you're curious, you can get slightly better performance from here by doing a little brute forcing.",
  "model": "nmt",
  "translatedText": "Wenn Sie neugierig sind, können Sie von hier aus eine etwas bessere Leistung erzielen, indem Sie ein wenig Brute-Force anwenden.",
  "time_range": [
   518.9142857142858,
   523.7290322580645
  ]
 },
 {
  "input": "There's a very nice blog post by Jonathan Olson, if you're curious about this, where he also lets you explore what the optimal following guesses are for a few of the starting words based on these optimal algorithms.",
  "model": "nmt",
  "translatedText": "Wenn Sie neugierig sind, gibt es einen sehr schönen Blogbeitrag von Jonathan Olson, in dem er Sie auch erkunden lässt, was die optimalen Folgeschätzungen für einige der Startwörter sind, die auf diesen optimalen Algorithmen basieren.",
  "time_range": [
   523.7290322580645,
   535.04
  ]
 },
 {
  "input": "Stepping back from all this though, I'm told by some people that it quote ruins the game to overanalyze it like this and try to find an optimal opening guess.",
  "model": "nmt",
  "translatedText": "Abgesehen davon sagen mir einige Leute, dass es das Spiel ruiniert, wenn man es so überanalysiert und versucht, einen optimalen Eröffnungstipp zu finden.",
  "time_range": [
   535.04,
   543.92
  ]
 },
 {
  "input": "You know, it feels kind of dirty if you use that opening guess after learning it, and it feels inefficient if you don't.",
  "model": "nmt",
  "translatedText": "Wissen Sie, es fühlt sich irgendwie schmutzig an, wenn Sie diese Eröffnungsschätzung verwenden, nachdem Sie sie gelernt haben, und es fühlt sich ineffizient an, wenn Sie dies nicht tun.",
  "time_range": [
   543.92,
   549.5183157894737
  ]
 },
 {
  "input": "But the thing is, I don't actually think this is the best opener for a human playing the game.",
  "model": "nmt",
  "translatedText": "Aber die Sache ist die, ich glaube nicht, dass dies der beste Eröffnungssatz für einen Menschen ist, der das Spiel spielt.",
  "time_range": [
   549.5183157894737,
   554.1422222222221
  ]
 },
 {
  "input": "For one thing, you would need to know what the optimal second guess is for each one of the patterns that you see.",
  "model": "nmt",
  "translatedText": "Zum einen müssten Sie wissen, was die optimale zweite Schätzung für jedes der Muster ist, die Sie sehen.",
  "time_range": [
   554.1422222222221,
   559.9200000000001
  ]
 },
 {
  "input": "And more importantly, all of this is in a setting where we are absurdly overfit to the official wordle answer list.",
  "model": "nmt",
  "translatedText": "Und was noch wichtiger ist: All dies geschieht in einem Umfeld, in dem wir der offiziellen Antwortliste der Welt auf absurde Weise zu nahe kommen.",
  "time_range": [
   559.9200000000001,
   566.4314606741573
  ]
 },
 {
  "input": "The moment that, say, the New York Times chooses to change what that list is under the hood, all of this would go out the window.",
  "model": "nmt",
  "translatedText": "In dem Moment, in dem, sagen wir, die New York Times beschließt, den Inhalt dieser Liste zu ändern, würde das alles aus dem Fenster verschwinden.",
  "time_range": [
   566.4314606741573,
   572.8865979381444
  ]
 },
 {
  "input": "The way that we humans play the game is just very different from what any of these algorithms are doing.",
  "model": "nmt",
  "translatedText": "Die Art und Weise, wie wir Menschen das Spiel spielen, unterscheidet sich einfach stark von dem, was jeder dieser Algorithmen tut.",
  "time_range": [
   572.8865979381444,
   577.7033333333334
  ]
 },
 {
  "input": "We don't have the word list memorized, we're not doing exhaustive searches, we get intuition from things like what are the vowels and how are they placed.",
  "model": "nmt",
  "translatedText": "Wir haben die Wortliste nicht auswendig gelernt, wir führen keine erschöpfenden Suchen durch, wir bekommen eine Intuition aus Dingen wie dem, was die Vokale sind und wie sie platziert werden.",
  "time_range": [
   577.7033333333334,
   585.52
  ]
 },
 {
  "input": "I would actually be most happy if those of you watching this video promptly forgot what happens to be the technically best opening guess, and instead came out remembering things like how do you quantify information, or the fact that you should look out for when a greedy algorithm falls short of the globally best performance that you would get from a deeper search.",
  "model": "nmt",
  "translatedText": "Eigentlich würde ich mich sehr freuen, wenn diejenigen unter Ihnen, die sich dieses Video ansehen, sofort vergessen würden, was die technisch beste Eröffnungsschätzung ist, und sich stattdessen an Dinge erinnern würden, wie zum Beispiel, wie man Informationen quantifiziert, oder daran, worauf man achten sollte, wenn man gierig ist Der Algorithmus erreicht nicht die weltweit beste Leistung, die Sie mit einer tieferen Suche erzielen würden.",
  "time_range": [
   585.52,
   603.52
  ]
 },
 {
  "input": "For my taste at least, the joy of writing algorithms to try to play games actually has very little bearing on how I like to play those games as a human.",
  "model": "nmt",
  "translatedText": "Zumindest für meinen Geschmack hat die Freude, Algorithmen zu schreiben, um Spiele zu spielen, kaum einen Einfluss darauf, wie ich diese Spiele als Mensch gerne spiele.",
  "time_range": [
   603.52,
   610.9507368421052
  ]
 },
 {
  "input": "The point of writing algorithms for all this is not to affect the way that we play the game, it's still just a fun word game.",
  "model": "nmt",
  "translatedText": "Der Sinn des Schreibens von Algorithmen für all das besteht nicht darin, die Art und Weise zu beeinflussen, wie wir das Spiel spielen, es ist immer noch nur ein lustiges Wortspiel.",
  "time_range": [
   610.9507368421052,
   617.0391397849463
  ]
 },
 {
  "input": "It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere.",
  "model": "nmt",
  "translatedText": "Es geht darum, unsere Muskeln zu stärken, um Algorithmen anderswo in sinnvolleren Kontexten zu schreiben.",
  "time_range": [
   617.0391397849463,
   637.92
  ]
 }
]