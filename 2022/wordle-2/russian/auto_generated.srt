1
00:00:00,000 --> 00:00:03,085
На прошлой неделе я разместил это видео о решении игры Wordle или,

2
00:00:03,085 --> 00:00:06,216
по крайней мере, о попытке ее решения, используя теорию информации.

3
00:00:06,216 --> 00:00:09,920
И я хотел добавить небольшое, как бы это назвать, дополнение?

4
00:00:09,920 --> 00:00:10,685
Признание?

5
00:00:10,685 --> 00:00:14,240
По сути, я просто хочу объяснить место, где я допустил ошибку.

6
00:00:14,240 --> 00:00:17,186
Оказывается, в коде, который я использовал, чтобы воссоздать Wordle,

7
00:00:17,186 --> 00:00:20,817
а затем запустить все алгоритмы для ее устранения и проверить их производительность,

8
00:00:20,817 --> 00:00:22,055
была очень небольшая ошибка.

9
00:00:22,055 --> 00:00:25,476
И это одна из тех ошибок, которая затрагивает очень небольшой процент случаев,

10
00:00:25,476 --> 00:00:28,724
поэтому ее легко пропустить, и она имеет лишь очень незначительный эффект,

11
00:00:28,724 --> 00:00:30,976
который по большей части не имеет особого значения.

12
00:00:30,976 --> 00:00:34,393
По сути, это было связано с тем, как вы назначаете цвет предположению,

13
00:00:34,393 --> 00:00:36,223
в котором есть несколько разных букв.

14
00:00:36,223 --> 00:00:39,109
Например, если вы угадали скорость и правильный ответ — «соблюдать»,

15
00:00:39,109 --> 00:00:42,080
как вам следует раскрасить эти две буквы «е», исходя из предположения?

16
00:00:42,080 --> 00:00:47,650
Что ж, в соответствии с соглашениями Wordle первая буква e будет окрашена в желтый цвет,

17
00:00:47,650 --> 00:00:48,902
а вторая — в серый.

18
00:00:48,902 --> 00:00:53,444
Вы можете подумать, что первый ответ соответствует чему-то из истинного ответа,

19
00:00:53,444 --> 00:00:56,000
а серый цвет говорит вам, что второго e нет.

20
00:00:56,000 --> 00:00:59,087
Напротив, если бы ответом было что-то вроде «стирание»,

21
00:00:59,087 --> 00:01:02,229
обе эти «е» были бы окрашены в желтый цвет, сообщая вам,

22
00:01:02,229 --> 00:01:06,970
что первая «е» находится в другом месте, а вторая «е» также находится в другом месте.

23
00:01:06,970 --> 00:01:10,627
Аналогично, если один из символов e соответствует зеленому цвету,

24
00:01:10,627 --> 00:01:14,782
то второй будет серым в том случае, если у истинного ответа нет второго e,

25
00:01:14,782 --> 00:01:19,326
но он будет желтым в случае, когда есть второй e, но он находится в другом месте.

26
00:01:19,326 --> 00:01:20,102
расположение.

27
00:01:20,102 --> 00:01:23,466
Короче говоря, где-то по пути я случайно ввел поведение,

28
00:01:23,466 --> 00:01:26,240
которое немного отличается от этих соглашений.

29
00:01:26,240 --> 00:01:28,416
Честно говоря, это было очень глупо.

30
00:01:28,416 --> 00:01:32,060
По сути, в какой-то момент в середине проекта я захотел ускорить некоторые

31
00:01:32,060 --> 00:01:35,510
вычисления и попробовал небольшой трюк, позволяющий вычислить значение

32
00:01:35,510 --> 00:01:39,689
этого шаблона между любой заданной парой слов, и вы знаете, я просто не сделал этого.

33
00:01:39,689 --> 00:01:42,944
Я действительно не продумал это, и это внесло небольшое изменение.

34
00:01:42,944 --> 00:01:44,876
Ирония заключается в том, что, в конце концов,

35
00:01:44,876 --> 00:01:48,165
реальный способ ускорить работу — это предварительно вычислить все эти шаблоны,

36
00:01:48,165 --> 00:01:50,426
чтобы все было просто поиском, и не имело бы значения,

37
00:01:50,426 --> 00:01:52,851
сколько времени потребуется для выполнения каждого из них,

38
00:01:52,851 --> 00:01:55,934
особенно если вы пишем трудночитаемый код с ошибками, чтобы это произошло.

39
00:01:55,934 --> 00:01:57,665
Знаешь, ты живешь и учишься.

40
00:01:57,665 --> 00:01:59,947
Что касается того, как это влияет на реальное видео,

41
00:01:59,947 --> 00:02:02,186
я имею в виду, что на самом деле мало что меняется.

42
00:02:02,186 --> 00:02:04,739
Конечно, основные уроки о том, что такое информация,

43
00:02:04,739 --> 00:02:06,617
что такое энтропия, остаются прежними.

44
00:02:06,617 --> 00:02:09,903
Время от времени, если я показываю на экране некоторое распределение,

45
00:02:09,903 --> 00:02:13,189
связанное с данным словом, это распределение на самом деле может быть

46
00:02:13,189 --> 00:02:15,677
немного неправильным, потому что некоторые сегменты,

47
00:02:15,677 --> 00:02:19,808
связанные с различными шаблонами, должны включать больше или меньше правильных ответов.

48
00:02:19,808 --> 00:02:23,995
Даже тогда это на самом деле не возникает, потому что очень редко я показывал слово,

49
00:02:23,995 --> 00:02:27,789
состоящее из нескольких букв, которые также попадали в этот крайний регистр.

50
00:02:27,789 --> 00:02:32,006
Но одна из очень немногих существенных вещей, которая действительно меняется и,

51
00:02:32,006 --> 00:02:35,801
возможно, имеет немалое значение, — это окончательный вывод о том, как,

52
00:02:35,801 --> 00:02:39,649
если мы хотим найти оптимально возможный балл для списка ответов Wordle,

53
00:02:39,649 --> 00:02:42,654
какое начальное предположение использует такой алгоритм?

54
00:02:42,654 --> 00:02:46,379
В видео я сказал, что лучшая производительность, которую я смог найти,

55
00:02:46,379 --> 00:02:50,629
была получена при открытии со словом кран, что было правдой только в том смысле,

56
00:02:50,629 --> 00:02:52,937
что алгоритмы играли в немного другую игру.

57
00:02:52,937 --> 00:02:56,369
После исправления и повторного запуска всего этого появляется другой ответ на вопрос,

58
00:02:56,369 --> 00:02:59,960
какое теоретически оптимальное первое предположение является для этого конкретного списка.

59
00:02:59,960 --> 00:03:00,000


60
00:03:00,000 --> 00:03:03,759
И послушайте, я знаю, что вы знаете, что цель видео не в том,

61
00:03:03,759 --> 00:03:08,913
чтобы найти какой-то технически оптимальный ответ на какую-то случайную онлайн-игру.

62
00:03:08,913 --> 00:03:12,169
Смысл видео в том, чтобы беззастенчиво вскочить на подножку

63
00:03:12,169 --> 00:03:16,240
интернет-тренда и тайно атаковать людей с помощью урока теории информации.

64
00:03:16,240 --> 00:03:18,014
И это все хорошо, я поддерживаю эту часть.

65
00:03:18,014 --> 00:03:22,612
Но я знаю, как работает Интернет, и для многих людей главным выводом было то,

66
00:03:22,612 --> 00:03:24,793
как лучше всего начать игру в слова.

67
00:03:24,793 --> 00:03:28,094
И я понимаю, я вошел в это, потому что поместил это в миниатюру, но,

68
00:03:28,094 --> 00:03:31,731
вероятно, вы простите меня, если я захочу добавить сюда небольшую поправку.

69
00:03:31,731 --> 00:03:35,160
И более весомая причина вернуться ко всему этому на самом деле заключается в том,

70
00:03:35,160 --> 00:03:38,464
что я никогда особо не говорил о том, что входило в этот окончательный анализ.

71
00:03:38,464 --> 00:03:42,688
И как подурок он интересен сам по себе, поэтому его стоит пройти здесь.

72
00:03:42,688 --> 00:03:45,875
Если вы помните, большая часть нашего времени в прошлом видео

73
00:03:45,875 --> 00:03:48,857
была потрачена на попытку написать алгоритм решения слов,

74
00:03:48,857 --> 00:03:52,404
который не использовал бы официальный список всех возможных ответов.

75
00:03:52,404 --> 00:03:55,850
На мой вкус, это немного похоже на переоснащение тестового набора,

76
00:03:55,850 --> 00:03:58,678
и что еще интереснее, это создавать что-то устойчивое.

77
00:03:58,678 --> 00:04:03,240
Вот почему мы прошли весь процесс изучения относительной частоты слов в английском языке,

78
00:04:03,240 --> 00:04:06,281
чтобы прийти к некоторому выводу о том, насколько вероятно,

79
00:04:06,281 --> 00:04:09,120
что каждое из них будет включено в окончательный ответ.

80
00:04:09,120 --> 00:04:12,997
Однако для того, что мы здесь делаем, когда мы просто пытаемся найти абсолютно

81
00:04:12,997 --> 00:04:16,777
лучший период производительности, я включаю этот официальный список и просто

82
00:04:16,777 --> 00:04:20,508
бесстыдно подгоняю его к тестовому набору, то есть мы с уверенностью знаем,

83
00:04:20,508 --> 00:04:24,729
является ли слово включен он или нет, и мы можем присвоить каждому из них равномерную

84
00:04:24,729 --> 00:04:25,368
вероятность.

85
00:04:25,368 --> 00:04:28,960
Если вы помните, первым шагом во всем этом было сказать для конкретного

86
00:04:28,960 --> 00:04:33,101
начального предположения, может быть, что-то вроде моего старого любимого журавля,

87
00:04:33,101 --> 00:04:36,295
насколько вероятно, что вы увидите каждую из возможных моделей?

88
00:04:36,295 --> 00:04:40,517
И в этом контексте, когда мы бессовестно подгоняем список ответов под слова, все,

89
00:04:40,517 --> 00:04:44,893
что для этого нужно, — это подсчитать, сколько возможных ответов дает каждый из этих

90
00:04:44,893 --> 00:04:45,408
шаблонов.

91
00:04:45,408 --> 00:04:48,992
И потом, конечно, большая часть нашего времени была потрачена на такого рода забавно

92
00:04:48,992 --> 00:04:51,691
выглядящую формулу для количественной оценки объема информации,

93
00:04:51,691 --> 00:04:54,305
которую вы получите из этого предположения, которое, по сути,

94
00:04:54,305 --> 00:04:57,299
включает в себя просмотр каждого из этих сегментов и определение того,

95
00:04:57,299 --> 00:05:00,167
сколько информации вы получите, если это логарифмическое выражение,

96
00:05:00,167 --> 00:05:02,360
представляющее собой причудливый способ определить,

97
00:05:02,360 --> 00:05:05,270
во сколько раз вы сократили бы свое пространство возможностей вдвое,

98
00:05:05,270 --> 00:05:07,083
если бы наблюдали заданную закономерность.

99
00:05:07,083 --> 00:05:09,401
Мы берем средневзвешенное значение всех этих показателей,

100
00:05:09,401 --> 00:05:12,558
и это дает нам представление о том, сколько мы ожидаем узнать из этого первого

101
00:05:12,558 --> 00:05:13,158
предположения.

102
00:05:13,158 --> 00:05:17,045
Через мгновение мы углубимся в это, но если вы просто проведете поиск по

103
00:05:17,045 --> 00:05:20,773
всем 13 000 различных слов, с которых вы могли бы начать, и спросите,

104
00:05:20,773 --> 00:05:23,968
какое из них имеет наиболее ожидаемую информацию, окажется,

105
00:05:23,968 --> 00:05:27,269
что лучший возможный ответ — «парить», что не так уж и важно.

106
00:05:27,269 --> 00:05:30,465
На самом деле это слово не похоже на настоящее, но я думаю,

107
00:05:30,465 --> 00:05:32,967
это устаревший термин для обозначения ястреба.

108
00:05:32,967 --> 00:05:36,175
Топ-15 первых игроков по этому показателю выглядят так,

109
00:05:36,175 --> 00:05:39,268
но это не обязательно лучшие начальные предположения,

110
00:05:39,268 --> 00:05:44,136
потому что они делают лишь один шаг вперед с помощью эвристики ожидаемой информации,

111
00:05:44,136 --> 00:05:47,458
чтобы попытаться оценить, каков будет истинный результат.

112
00:05:47,458 --> 00:05:52,000
Но шаблонов достаточно мало, чтобы мы могли провести исчерпывающий поиск за два шага.

113
00:05:52,000 --> 00:05:56,131
Например, предположим, что вы открылись с взлетом и фигура, которую вы увидели,

114
00:05:56,131 --> 00:06:00,571
была наиболее вероятной, все серые, тогда вы можете провести идентичный анализ с этой

115
00:06:00,571 --> 00:06:00,933
точки.

116
00:06:00,933 --> 00:06:04,172
Для данного предложенного второго предположения, например «котенок»,

117
00:06:04,172 --> 00:06:07,269
каково распределение по всем шаблонам в этом ограниченном случае,

118
00:06:07,269 --> 00:06:10,884
когда мы ограничены только словами, которые дают все серые цвета для взлета,

119
00:06:10,884 --> 00:06:13,465
а затем мы измеряем равномерность этого распределения,

120
00:06:13,465 --> 00:06:16,141
используя это ожидаемое значение информационную формулу,

121
00:06:16,141 --> 00:06:18,394
и мы делаем это для всех 13 000 возможных слов,

122
00:06:18,394 --> 00:06:21,538
которые мы могли бы использовать в качестве второго предположения.

123
00:06:21,538 --> 00:06:25,514
Сделав это, мы можем найти оптимальное второе предположение в этом сценарии

124
00:06:25,514 --> 00:06:29,594
и объем информации, которую мы ожидали получить от него, и если мы промываем,

125
00:06:29,594 --> 00:06:33,151
промываем, повторяем и проделываем это для всех возможных шаблонов,

126
00:06:33,151 --> 00:06:37,127
которые вы можете увидеть, мы получим полная карта всех наилучших возможных

127
00:06:37,127 --> 00:06:40,422
вторых догадок вместе с ожидаемой информацией о каждой из них.

128
00:06:40,422 --> 00:06:45,264
Отсюда, если вы возьмете средневзвешенное значение всех этих значений второго шага,

129
00:06:45,264 --> 00:06:50,221
взвешенное в зависимости от того, насколько вероятно, что вы попадете в этот сегмент,

130
00:06:50,221 --> 00:06:53,506
это даст вам меру того, сколько информации вы, вероятно,

131
00:06:53,506 --> 00:06:57,137
получите от резкого увеличения предположений после второй шаг.

132
00:06:57,137 --> 00:07:00,721
Когда мы используем эту двухэтапную метрику в качестве нового средства ранжирования,

133
00:07:00,721 --> 00:07:01,986
список немного встряхивается.

134
00:07:01,986 --> 00:07:05,427
Соар больше не занимает первое место, он опускается на 14-е место,

135
00:07:05,427 --> 00:07:08,560
а вместо этого то, что поднимается на вершину, уничтожается.

136
00:07:08,560 --> 00:07:11,691
Опять же, это выглядит не очень реалистично и похоже,

137
00:07:11,691 --> 00:07:16,386
что это британский термин, обозначающий лопату, используемую для стрижки газона.

138
00:07:16,386 --> 00:07:20,729
Хорошо, но, как вы можете видеть, между всеми этими главными претендентами идет

139
00:07:20,729 --> 00:07:25,290
очень напряженная гонка за то, кто получит больше информации после этих двух шагов.

140
00:07:25,290 --> 00:07:28,779
И даже несмотря на это, это не обязательно лучшие начальные предположения,

141
00:07:28,779 --> 00:07:31,106
потому что информация — это всего лишь эвристика,

142
00:07:31,106 --> 00:07:34,503
она не сообщает нам реальный счет, если вы действительно играете в игру.

143
00:07:34,503 --> 00:07:39,532
Я запустил симуляцию игры во все 2315 возможных словесных игр

144
00:07:39,532 --> 00:07:44,400
со всеми возможными ответами из 250 лучших из этого списка.

145
00:07:44,400 --> 00:07:50,084
И, сделав это, наблюдая, как они на самом деле работают, тот,

146
00:07:50,084 --> 00:07:57,419
который в конечном итоге набирает максимально возможный балл, оказывается Сале,

147
00:07:57,419 --> 00:08:04,662
что является альтернативным написанием Сале, который представляет собой легкий

148
00:08:04,662 --> 00:08:06,496
средневековый шлем.

149
00:08:06,496 --> 00:08:10,564
Хорошо, если вам это кажется слишком фальшивым, как мне кажется,

150
00:08:10,564 --> 00:08:15,760
вы будете рады узнать, что Trace и Crate дают почти одинаковую производительность.

151
00:08:15,760 --> 00:08:18,684
Преимущество каждого из них заключается в том, что это, очевидно,

152
00:08:18,684 --> 00:08:22,229
настоящее слово, поэтому наступит день, когда вы угадаете его с первой догадки,

153
00:08:22,229 --> 00:08:24,666
поскольку оба являются настоящими словесными ответами.

154
00:08:24,666 --> 00:08:28,495
Переход от сортировки на основе лучших двухшаговых энтропий к сортировке на

155
00:08:28,495 --> 00:08:32,425
основе наименьшего среднего балла также встряхивает список, но не так сильно.

156
00:08:32,425 --> 00:08:36,708
Например, Сале раньше занимал третье место, прежде чем поднялся на вершину,

157
00:08:36,708 --> 00:08:38,963
а Crate и Trace были четвертым и пятым.

158
00:08:38,963 --> 00:08:42,454
Если вам интересно, вы можете добиться немного большей производительности,

159
00:08:42,454 --> 00:08:43,758
выполнив небольшой перебор.

160
00:08:43,758 --> 00:08:47,100
Если вам интересно, есть очень хорошая запись в блоге Джонатана Олсона,

161
00:08:47,100 --> 00:08:50,396
где он также позволяет вам изучить оптимальные следующие предположения

162
00:08:50,396 --> 00:08:53,600
для нескольких начальных слов на основе этих оптимальных алгоритмов.

163
00:08:53,600 --> 00:08:57,021
Однако, отступив от всего этого, некоторые люди говорят мне,

164
00:08:57,021 --> 00:09:00,554
что если чрезмерно анализировать игру таким образом и пытаться

165
00:09:00,554 --> 00:09:03,920
найти оптимальное начальное предположение, это портит игру.

166
00:09:03,920 --> 00:09:07,035
Знаете, это кажется грязным, если вы используете эту вступительную догадку после того,

167
00:09:07,035 --> 00:09:09,577
как вы ее выучили, и кажется неэффективным, если вы этого не сделаете.

168
00:09:09,577 --> 00:09:13,352
Но дело в том, что я на самом деле не думаю, что это лучший дебют для человека,

169
00:09:13,352 --> 00:09:14,201
играющего в игру.

170
00:09:14,201 --> 00:09:18,931
Во-первых, вам нужно знать, какова оптимальная вторая догадка для каждого из шаблонов,

171
00:09:18,931 --> 00:09:19,964
которые вы видите.

172
00:09:19,964 --> 00:09:22,803
И что еще более важно, все это происходит в обстановке,

173
00:09:22,803 --> 00:09:26,453
когда мы абсурдно подстраиваемся под официальный список ответов Wordle.

174
00:09:26,453 --> 00:09:29,900
В тот момент, когда, скажем, New York Times решит изменить то,

175
00:09:29,900 --> 00:09:32,964
что находится в этом списке, все это улетучится в окно.

176
00:09:32,964 --> 00:09:35,942
То, как мы, люди, играем в игру, сильно отличается от того,

177
00:09:35,942 --> 00:09:37,779
что делает любой из этих алгоритмов.

178
00:09:37,779 --> 00:09:40,987
Мы не запоминаем список слов, не проводим исчерпывающий поиск,

179
00:09:40,987 --> 00:09:45,520
мы получаем интуицию из таких вещей, как, например, какие гласные и как они расположены.

180
00:09:45,520 --> 00:09:48,867
На самом деле я был бы очень рад, если бы те из вас, кто смотрит это видео,

181
00:09:48,867 --> 00:09:52,037
быстро забыли, что является технически лучшим начальным предположением,

182
00:09:52,037 --> 00:09:54,151
и вместо этого вспомнили бы такие вещи, как то,

183
00:09:54,151 --> 00:09:57,366
как вы оцениваете информацию или тот факт, что вам следует остерегаться,

184
00:09:57,366 --> 00:10:00,405
когда жадный Алгоритм не достигает лучшей в мире производительности,

185
00:10:00,405 --> 00:10:02,960
которую можно было бы получить при более глубоком поиске.

186
00:10:02,960 --> 00:10:07,000
По крайней мере, на мой вкус, радость от написания алгоритмов для игр на самом

187
00:10:07,000 --> 00:10:10,988
деле очень мало влияет на то, как мне нравится играть в эти игры как человек.

188
00:10:10,988 --> 00:10:14,209
Смысл написания алгоритмов для всего этого не в том, чтобы повлиять на то,

189
00:10:14,209 --> 00:10:17,044
как мы играем в игру, это все равно просто забавная игра в слова.

190
00:10:17,044 --> 00:10:19,880
Это оттачивание наших мускулов для написания алгоритмов

191
00:10:19,880 --> 00:10:22,160
в более значимых контекстах в других местах.

