1
00:00:00,000 --> 00:00:03,085
На прошлой неделе я разместил это видео о решении игры Wordle или,

2
00:00:03,085 --> 00:00:06,216
по крайней мере, о попытке ее решения, используя теорию информации.

3
00:00:06,216 --> 00:00:09,920
И я хотел добавить небольшое, как бы это назвать, дополнение?

4
00:00:09,920 --> 00:00:10,685
Признание?

5
00:00:10,685 --> 00:00:14,240
По сути, я просто хочу объяснить место, где я допустил ошибку.

6
00:00:14,240 --> 00:00:16,845
Оказывается, в коде, который я использовал, чтобы воссоздать

7
00:00:16,845 --> 00:00:19,407
Wordle, а затем запустить все алгоритмы для ее устранения и

8
00:00:19,407 --> 00:00:22,055
проверить их производительность, была очень небольшая ошибка.

9
00:00:22,055 --> 00:00:25,087
И это одна из тех ошибок, которая затрагивает очень небольшой процент

10
00:00:25,087 --> 00:00:27,728
случаев, поэтому ее легко пропустить, и она имеет лишь очень

11
00:00:27,728 --> 00:00:30,976
незначительный эффект, который по большей части не имеет особого значения.

12
00:00:30,976 --> 00:00:33,671
По сути, это было связано с тем, как вы назначаете цвет

13
00:00:33,671 --> 00:00:36,223
предположению, в котором есть несколько разных букв.

14
00:00:36,223 --> 00:00:39,109
Например, если вы угадали скорость и правильный ответ — «соблюдать»,

15
00:00:39,109 --> 00:00:42,080
как вам следует раскрасить эти две буквы «е», исходя из предположения?

16
00:00:42,080 --> 00:00:45,272
Что ж, в соответствии с соглашениями Wordle первая

17
00:00:45,272 --> 00:00:48,902
буква e будет окрашена в желтый цвет, а вторая — в серый.

18
00:00:48,902 --> 00:00:52,422
Вы можете подумать, что первый ответ соответствует чему-то из

19
00:00:52,422 --> 00:00:56,000
истинного ответа, а серый цвет говорит вам, что второго e нет.

20
00:00:56,000 --> 00:00:59,528
Напротив, если бы ответом было что-то вроде «стирание», обе эти

21
00:00:59,528 --> 00:01:03,056
«е» были бы окрашены в желтый цвет, сообщая вам, что первая «е»

22
00:01:03,056 --> 00:01:06,970
находится в другом месте, а вторая «е» также находится в другом месте.

23
00:01:06,970 --> 00:01:11,181
Аналогично, если один из символов e соответствует зеленому цвету, то второй

24
00:01:11,181 --> 00:01:15,447
будет серым в том случае, если у истинного ответа нет второго e, но он будет

25
00:01:15,447 --> 00:01:20,102
желтым в случае, когда есть второй e, но он находится в другом месте. расположение.

26
00:01:20,102 --> 00:01:23,466
Короче говоря, где-то по пути я случайно ввел поведение,

27
00:01:23,466 --> 00:01:26,240
которое немного отличается от этих соглашений.

28
00:01:26,240 --> 00:01:28,416
Честно говоря, это было очень глупо.

29
00:01:28,416 --> 00:01:32,060
По сути, в какой-то момент в середине проекта я захотел ускорить некоторые

30
00:01:32,060 --> 00:01:35,510
вычисления и попробовал небольшой трюк, позволяющий вычислить значение

31
00:01:35,510 --> 00:01:39,008
этого шаблона между любой заданной парой слов, и вы знаете, я просто не

32
00:01:39,008 --> 00:01:42,944
сделал этого. Я действительно не продумал это, и это внесло небольшое изменение.

33
00:01:42,944 --> 00:01:46,192
Ирония заключается в том, что, в конце концов, реальный способ ускорить работу

34
00:01:46,192 --> 00:01:49,439
— это предварительно вычислить все эти шаблоны, чтобы все было просто поиском,

35
00:01:49,439 --> 00:01:52,645
и не имело бы значения, сколько времени потребуется для выполнения каждого из

36
00:01:52,645 --> 00:01:55,934
них, особенно если вы пишем трудночитаемый код с ошибками, чтобы это произошло.

37
00:01:55,934 --> 00:01:57,665
Знаешь, ты живешь и учишься.

38
00:01:57,665 --> 00:01:59,947
Что касается того, как это влияет на реальное видео,

39
00:01:59,947 --> 00:02:02,186
я имею в виду, что на самом деле мало что меняется.

40
00:02:02,186 --> 00:02:04,739
Конечно, основные уроки о том, что такое информация,

41
00:02:04,739 --> 00:02:06,617
что такое энтропия, остаются прежними.

42
00:02:06,617 --> 00:02:09,903
Время от времени, если я показываю на экране некоторое распределение,

43
00:02:09,903 --> 00:02:13,189
связанное с данным словом, это распределение на самом деле может быть

44
00:02:13,189 --> 00:02:16,240
немного неправильным, потому что некоторые сегменты, связанные с

45
00:02:16,240 --> 00:02:19,808
различными шаблонами, должны включать больше или меньше правильных ответов.

46
00:02:19,808 --> 00:02:23,651
Даже тогда это на самом деле не возникает, потому что очень редко я показывал

47
00:02:23,651 --> 00:02:27,789
слово, состоящее из нескольких букв, которые также попадали в этот крайний регистр.

48
00:02:27,789 --> 00:02:31,373
Но одна из очень немногих существенных вещей, которая действительно

49
00:02:31,373 --> 00:02:35,169
меняется и, возможно, имеет немалое значение, — это окончательный вывод

50
00:02:35,169 --> 00:02:38,806
о том, как, если мы хотим найти оптимально возможный балл для списка

51
00:02:38,806 --> 00:02:42,654
ответов Wordle, какое начальное предположение использует такой алгоритм?

52
00:02:42,654 --> 00:02:46,012
В видео я сказал, что лучшая производительность, которую я смог

53
00:02:46,012 --> 00:02:49,527
найти, была получена при открытии со словом кран, что было правдой

54
00:02:49,527 --> 00:02:52,937
только в том смысле, что алгоритмы играли в немного другую игру.

55
00:02:52,937 --> 00:02:56,369
После исправления и повторного запуска всего этого появляется другой ответ на вопрос,

56
00:02:56,369 --> 00:02:59,680
какое теоретически оптимальное первое предположение является для этого конкретного

57
00:02:59,680 --> 00:03:00,000
списка.

58
00:03:00,000 --> 00:03:04,487
И послушайте, я знаю, что вы знаете, что цель видео не в том, чтобы найти

59
00:03:04,487 --> 00:03:08,913
какой-то технически оптимальный ответ на какую-то случайную онлайн-игру.

60
00:03:08,913 --> 00:03:12,169
Смысл видео в том, чтобы беззастенчиво вскочить на подножку

61
00:03:12,169 --> 00:03:16,240
интернет-тренда и тайно атаковать людей с помощью урока теории информации.

62
00:03:16,240 --> 00:03:18,014
И это все хорошо, я поддерживаю эту часть.

63
00:03:18,014 --> 00:03:21,138
Но я знаю, как работает Интернет, и для многих людей

64
00:03:21,138 --> 00:03:24,793
главным выводом было то, как лучше всего начать игру в слова.

65
00:03:24,793 --> 00:03:28,094
И я понимаю, я вошел в это, потому что поместил это в миниатюру, но,

66
00:03:28,094 --> 00:03:31,731
вероятно, вы простите меня, если я захочу добавить сюда небольшую поправку.

67
00:03:31,731 --> 00:03:35,160
И более весомая причина вернуться ко всему этому на самом деле заключается в том,

68
00:03:35,160 --> 00:03:38,464
что я никогда особо не говорил о том, что входило в этот окончательный анализ.

69
00:03:38,464 --> 00:03:42,688
И как подурок он интересен сам по себе, поэтому его стоит пройти здесь.

70
00:03:42,688 --> 00:03:45,875
Если вы помните, большая часть нашего времени в прошлом видео

71
00:03:45,875 --> 00:03:49,268
была потрачена на попытку написать алгоритм решения слов, который

72
00:03:49,268 --> 00:03:52,404
не использовал бы официальный список всех возможных ответов.

73
00:03:52,404 --> 00:03:55,438
На мой вкус, это немного похоже на переоснащение тестового

74
00:03:55,438 --> 00:03:58,678
набора, и что еще интереснее, это создавать что-то устойчивое.

75
00:03:58,678 --> 00:04:02,226
Вот почему мы прошли весь процесс изучения относительной частоты слов

76
00:04:02,226 --> 00:04:05,774
в английском языке, чтобы прийти к некоторому выводу о том, насколько

77
00:04:05,774 --> 00:04:09,120
вероятно, что каждое из них будет включено в окончательный ответ.

78
00:04:09,120 --> 00:04:12,997
Однако для того, что мы здесь делаем, когда мы просто пытаемся найти абсолютно

79
00:04:12,997 --> 00:04:16,777
лучший период производительности, я включаю этот официальный список и просто

80
00:04:16,777 --> 00:04:20,950
бесстыдно подгоняю его к тестовому набору, то есть мы с уверенностью знаем, является

81
00:04:20,950 --> 00:04:25,368
ли слово включен он или нет, и мы можем присвоить каждому из них равномерную вероятность.

82
00:04:25,368 --> 00:04:28,960
Если вы помните, первым шагом во всем этом было сказать для конкретного

83
00:04:28,960 --> 00:04:32,652
начального предположения, может быть, что-то вроде моего старого любимого

84
00:04:32,652 --> 00:04:36,295
журавля, насколько вероятно, что вы увидите каждую из возможных моделей?

85
00:04:36,295 --> 00:04:40,722
И в этом контексте, когда мы бессовестно подгоняем список ответов под слова, все, что

86
00:04:40,722 --> 00:04:44,893
для этого нужно, — это подсчитать, сколько возможных ответов дает каждый из этих

87
00:04:44,893 --> 00:04:45,408
шаблонов.

88
00:04:45,408 --> 00:04:48,992
И потом, конечно, большая часть нашего времени была потрачена на такого рода забавно

89
00:04:48,992 --> 00:04:52,534
выглядящую формулу для количественной оценки объема информации, которую вы получите

90
00:04:52,534 --> 00:04:56,034
из этого предположения, которое, по сути, включает в себя просмотр каждого из этих

91
00:04:56,034 --> 00:04:59,703
сегментов и определение того, сколько информации вы получите, если это логарифмическое

92
00:04:59,703 --> 00:05:03,119
выражение, представляющее собой причудливый способ определить, во сколько раз вы

93
00:05:03,119 --> 00:05:06,408
сократили бы свое пространство возможностей вдвое, если бы наблюдали заданную

94
00:05:06,408 --> 00:05:07,083
закономерность.

95
00:05:07,083 --> 00:05:10,000
Мы берем средневзвешенное значение всех этих показателей, и это дает нам

96
00:05:10,000 --> 00:05:13,158
представление о том, сколько мы ожидаем узнать из этого первого предположения.

97
00:05:13,158 --> 00:05:17,045
Через мгновение мы углубимся в это, но если вы просто проведете поиск по

98
00:05:17,045 --> 00:05:21,092
всем 13 000 различных слов, с которых вы могли бы начать, и спросите, какое

99
00:05:21,092 --> 00:05:25,086
из них имеет наиболее ожидаемую информацию, окажется, что лучший возможный

100
00:05:25,086 --> 00:05:29,080
ответ — «парить», что не так уж и важно. На самом деле это слово не похоже

101
00:05:29,080 --> 00:05:32,967
на настоящее, но я думаю, это устаревший термин для обозначения ястреба.

102
00:05:32,967 --> 00:05:37,836
Топ-15 первых игроков по этому показателю выглядят так, но это не обязательно лучшие

103
00:05:37,836 --> 00:05:42,876
начальные предположения, потому что они делают лишь один шаг вперед с помощью эвристики

104
00:05:42,876 --> 00:05:47,458
ожидаемой информации, чтобы попытаться оценить, каков будет истинный результат.

105
00:05:47,458 --> 00:05:52,000
Но шаблонов достаточно мало, чтобы мы могли провести исчерпывающий поиск за два шага.

106
00:05:52,000 --> 00:05:56,389
Например, предположим, что вы открылись с взлетом и фигура, которую вы увидели, была

107
00:05:56,389 --> 00:06:00,933
наиболее вероятной, все серые, тогда вы можете провести идентичный анализ с этой точки.

108
00:06:00,933 --> 00:06:05,157
Для данного предложенного второго предположения, например «котенок», каково распределение

109
00:06:05,157 --> 00:06:09,335
по всем шаблонам в этом ограниченном случае, когда мы ограничены только словами, которые

110
00:06:09,335 --> 00:06:13,465
дают все серые цвета для взлета, а затем мы измеряем равномерность этого распределения,

111
00:06:13,465 --> 00:06:17,455
используя это ожидаемое значение информационную формулу, и мы делаем это для всех 13

112
00:06:17,455 --> 00:06:21,538
000 возможных слов, которые мы могли бы использовать в качестве второго предположения.

113
00:06:21,538 --> 00:06:25,514
Сделав это, мы можем найти оптимальное второе предположение в этом сценарии

114
00:06:25,514 --> 00:06:29,019
и объем информации, которую мы ожидали получить от него, и если мы

115
00:06:29,019 --> 00:06:32,628
промываем, промываем, повторяем и проделываем это для всех возможных

116
00:06:32,628 --> 00:06:36,604
шаблонов, которые вы можете увидеть, мы получим полная карта всех наилучших

117
00:06:36,604 --> 00:06:40,422
возможных вторых догадок вместе с ожидаемой информацией о каждой из них.

118
00:06:40,422 --> 00:06:44,457
Отсюда, если вы возьмете средневзвешенное значение всех этих значений

119
00:06:44,457 --> 00:06:48,607
второго шага, взвешенное в зависимости от того, насколько вероятно, что

120
00:06:48,607 --> 00:06:52,699
вы попадете в этот сегмент, это даст вам меру того, сколько информации

121
00:06:52,699 --> 00:06:57,137
вы, вероятно, получите от резкого увеличения предположений после второй шаг.

122
00:06:57,137 --> 00:06:59,456
Когда мы используем эту двухэтапную метрику в качестве

123
00:06:59,456 --> 00:07:01,986
нового средства ранжирования, список немного встряхивается.

124
00:07:01,986 --> 00:07:05,427
Соар больше не занимает первое место, он опускается на 14-е место,

125
00:07:05,427 --> 00:07:08,560
а вместо этого то, что поднимается на вершину, уничтожается.

126
00:07:08,560 --> 00:07:12,155
Опять же, это выглядит не очень реалистично и похоже, что это

127
00:07:12,155 --> 00:07:16,386
британский термин, обозначающий лопату, используемую для стрижки газона.

128
00:07:16,386 --> 00:07:20,729
Хорошо, но, как вы можете видеть, между всеми этими главными претендентами идет

129
00:07:20,729 --> 00:07:25,290
очень напряженная гонка за то, кто получит больше информации после этих двух шагов.

130
00:07:25,290 --> 00:07:28,081
И даже несмотря на это, это не обязательно лучшие начальные

131
00:07:28,081 --> 00:07:31,106
предположения, потому что информация — это всего лишь эвристика,

132
00:07:31,106 --> 00:07:34,503
она не сообщает нам реальный счет, если вы действительно играете в игру.

133
00:07:34,503 --> 00:07:39,532
Я запустил симуляцию игры во все 2315 возможных словесных игр

134
00:07:39,532 --> 00:07:44,400
со всеми возможными ответами из 250 лучших из этого списка.

135
00:07:44,400 --> 00:07:51,826
И, сделав это, наблюдая, как они на самом деле работают, тот, который в конечном

136
00:07:51,826 --> 00:07:58,611
итоге набирает максимально возможный балл, оказывается Сале, что является

137
00:07:58,611 --> 00:08:06,496
альтернативным написанием Сале, который представляет собой легкий средневековый шлем.

138
00:08:06,496 --> 00:08:11,190
Хорошо, если вам это кажется слишком фальшивым, как мне кажется, вы будете

139
00:08:11,190 --> 00:08:15,760
рады узнать, что Trace и Crate дают почти одинаковую производительность.

140
00:08:15,760 --> 00:08:18,684
Преимущество каждого из них заключается в том, что это, очевидно,

141
00:08:18,684 --> 00:08:21,520
настоящее слово, поэтому наступит день, когда вы угадаете его с

142
00:08:21,520 --> 00:08:24,666
первой догадки, поскольку оба являются настоящими словесными ответами.

143
00:08:24,666 --> 00:08:28,495
Переход от сортировки на основе лучших двухшаговых энтропий к сортировке на

144
00:08:28,495 --> 00:08:32,425
основе наименьшего среднего балла также встряхивает список, но не так сильно.

145
00:08:32,425 --> 00:08:35,525
Например, Сале раньше занимал третье место, прежде чем

146
00:08:35,525 --> 00:08:38,963
поднялся на вершину, а Crate и Trace были четвертым и пятым.

147
00:08:38,963 --> 00:08:41,151
Если вам интересно, вы можете добиться немного

148
00:08:41,151 --> 00:08:43,758
большей производительности, выполнив небольшой перебор.

149
00:08:43,758 --> 00:08:47,100
Если вам интересно, есть очень хорошая запись в блоге Джонатана Олсона,

150
00:08:47,100 --> 00:08:50,396
где он также позволяет вам изучить оптимальные следующие предположения

151
00:08:50,396 --> 00:08:53,600
для нескольких начальных слов на основе этих оптимальных алгоритмов.

152
00:08:53,600 --> 00:08:57,021
Однако, отступив от всего этого, некоторые люди говорят мне,

153
00:08:57,021 --> 00:09:00,554
что если чрезмерно анализировать игру таким образом и пытаться

154
00:09:00,554 --> 00:09:03,920
найти оптимальное начальное предположение, это портит игру.

155
00:09:03,920 --> 00:09:06,820
Знаете, это кажется грязным, если вы используете эту вступительную догадку после

156
00:09:06,820 --> 00:09:09,577
того, как вы ее выучили, и кажется неэффективным, если вы этого не сделаете.

157
00:09:09,577 --> 00:09:11,889
Но дело в том, что я на самом деле не думаю, что

158
00:09:11,889 --> 00:09:14,201
это лучший дебют для человека, играющего в игру.

159
00:09:14,201 --> 00:09:17,137
Во-первых, вам нужно знать, какова оптимальная вторая

160
00:09:17,137 --> 00:09:19,964
догадка для каждого из шаблонов, которые вы видите.

161
00:09:19,964 --> 00:09:23,259
И что еще более важно, все это происходит в обстановке, когда мы

162
00:09:23,259 --> 00:09:26,453
абсурдно подстраиваемся под официальный список ответов Wordle.

163
00:09:26,453 --> 00:09:29,681
В тот момент, когда, скажем, New York Times решит изменить

164
00:09:29,681 --> 00:09:32,964
то, что находится в этом списке, все это улетучится в окно.

165
00:09:32,964 --> 00:09:35,495
То, как мы, люди, играем в игру, сильно отличается

166
00:09:35,495 --> 00:09:37,779
от того, что делает любой из этих алгоритмов.

167
00:09:37,779 --> 00:09:41,598
Мы не запоминаем список слов, не проводим исчерпывающий поиск, мы получаем

168
00:09:41,598 --> 00:09:45,520
интуицию из таких вещей, как, например, какие гласные и как они расположены.

169
00:09:45,520 --> 00:09:48,867
На самом деле я был бы очень рад, если бы те из вас, кто смотрит это видео,

170
00:09:48,867 --> 00:09:52,434
быстро забыли, что является технически лучшим начальным предположением, и вместо

171
00:09:52,434 --> 00:09:55,781
этого вспомнили бы такие вещи, как то, как вы оцениваете информацию или тот

172
00:09:55,781 --> 00:09:59,216
факт, что вам следует остерегаться, когда жадный Алгоритм не достигает лучшей

173
00:09:59,216 --> 00:10:02,960
в мире производительности, которую можно было бы получить при более глубоком поиске.

174
00:10:02,960 --> 00:10:07,000
По крайней мере, на мой вкус, радость от написания алгоритмов для игр на самом

175
00:10:07,000 --> 00:10:10,988
деле очень мало влияет на то, как мне нравится играть в эти игры как человек.

176
00:10:10,988 --> 00:10:14,038
Смысл написания алгоритмов для всего этого не в том, чтобы повлиять на

177
00:10:14,038 --> 00:10:17,044
то, как мы играем в игру, это все равно просто забавная игра в слова.

178
00:10:17,044 --> 00:10:19,880
Это оттачивание наших мускулов для написания алгоритмов

179
00:10:19,880 --> 00:10:22,160
в более значимых контекстах в других местах.

