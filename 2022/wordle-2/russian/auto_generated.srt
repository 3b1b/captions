1
00:00:00,000 --> 00:00:03,067
На прошлой неделе я разместил это видео о решении игры Wordle или, 

2
00:00:03,067 --> 00:00:06,180
по крайней мере, о попытке ее решения, используя теорию информации. 

3
00:00:06,580 --> 00:00:09,780
И я хотел добавить небольшое, как бы это назвать, дополнение? 

4
00:00:10,080 --> 00:00:10,660
Признание? 

5
00:00:11,020 --> 00:00:13,900
По сути, я просто хочу объяснить место, где я допустил ошибку. 

6
00:00:14,460 --> 00:00:17,302
Оказывается, в коде, который я использовал, чтобы воссоздать Wordle, 

7
00:00:17,302 --> 00:00:20,805
а затем запустить все алгоритмы для ее устранения и проверить их производительность, 

8
00:00:20,805 --> 00:00:22,000
была очень небольшая ошибка. 

9
00:00:22,600 --> 00:00:25,629
И это одна из тех ошибок, которая затрагивает очень небольшой процент случаев, 

10
00:00:25,629 --> 00:00:28,505
поэтому ее легко пропустить, и она имеет лишь очень незначительный эффект, 

11
00:00:28,505 --> 00:00:30,500
который по большей части не имеет особого значения. 

12
00:00:31,220 --> 00:00:34,568
По сути, это было связано с тем, как вы назначаете цвет предположению, 

13
00:00:34,568 --> 00:00:36,360
в котором есть несколько разных букв. 

14
00:00:36,520 --> 00:00:39,280
Например, если вы угадали скорость и правильный ответ — «соблюдать», 

15
00:00:39,280 --> 00:00:42,120
как вам следует раскрасить эти две буквы «е», исходя из предположения? 

16
00:00:43,060 --> 00:00:47,975
Что ж, в соответствии с соглашениями Wordle первая буква e будет окрашена в желтый цвет, 

17
00:00:47,975 --> 00:00:49,080
а вторая — в серый. 

18
00:00:49,600 --> 00:00:53,388
Вы можете подумать, что первый ответ соответствует чему-то из истинного ответа, 

19
00:00:53,388 --> 00:00:55,520
а серый цвет говорит вам, что второго e нет. 

20
00:00:55,520 --> 00:00:58,688
Напротив, если бы ответом было что-то вроде «стирание», 

21
00:00:58,688 --> 00:01:01,913
обе эти «е» были бы окрашены в желтый цвет, сообщая вам, 

22
00:01:01,913 --> 00:01:06,780
что первая «е» находится в другом месте, а вторая «е» также находится в другом месте. 

23
00:01:07,300 --> 00:01:10,847
Аналогично, если один из символов e соответствует зеленому цвету, 

24
00:01:10,847 --> 00:01:14,879
то второй будет серым в том случае, если у истинного ответа нет второго e, 

25
00:01:14,879 --> 00:01:19,287
но он будет желтым в случае, когда есть второй e, но он находится в другом месте. 

26
00:01:19,287 --> 00:01:20,040
расположение. 

27
00:01:20,700 --> 00:01:25,632
Короче говоря, где-то по пути я случайно ввел поведение, 

28
00:01:25,632 --> 00:01:29,700
которое немного отличается от этих соглашений. 

29
00:01:29,700 --> 00:01:30,140
Честно говоря, это было очень глупо. 

30
00:01:30,140 --> 00:01:33,451
По сути, в какой-то момент в середине проекта я захотел ускорить некоторые 

31
00:01:33,451 --> 00:01:36,585
вычисления и попробовал небольшой трюк, позволяющий вычислить значение 

32
00:01:36,585 --> 00:01:40,382
этого шаблона между любой заданной парой слов, и вы знаете, я просто не сделал этого. 

33
00:01:40,382 --> 00:01:43,340
Я действительно не продумал это, и это внесло небольшое изменение. 

34
00:01:43,340 --> 00:01:45,199
Ирония заключается в том, что, в конце концов, 

35
00:01:45,199 --> 00:01:48,363
реальный способ ускорить работу — это предварительно вычислить все эти шаблоны, 

36
00:01:48,363 --> 00:01:50,539
чтобы все было просто поиском, и не имело бы значения, 

37
00:01:50,539 --> 00:01:52,873
сколько времени потребуется для выполнения каждого из них, 

38
00:01:52,873 --> 00:01:55,840
особенно если вы пишем трудночитаемый код с ошибками, чтобы это произошло. 

39
00:01:56,400 --> 00:01:57,240
Знаешь, ты живешь и учишься. 

40
00:01:58,040 --> 00:02:00,210
Что касается того, как это влияет на реальное видео, 

41
00:02:00,210 --> 00:02:02,340
я имею в виду, что на самом деле мало что меняется. 

42
00:02:02,660 --> 00:02:04,906
Конечно, основные уроки о том, что такое информация, 

43
00:02:04,906 --> 00:02:06,560
что такое энтропия, остаются прежними. 

44
00:02:06,860 --> 00:02:10,213
Время от времени, если я показываю на экране некоторое распределение, 

45
00:02:10,213 --> 00:02:13,566
связанное с данным словом, это распределение на самом деле может быть 

46
00:02:13,566 --> 00:02:16,104
немного неправильным, потому что некоторые сегменты, 

47
00:02:16,104 --> 00:02:20,320
связанные с различными шаблонами, должны включать больше или меньше правильных ответов. 

48
00:02:20,840 --> 00:02:24,051
Даже тогда это на самом деле не возникает, потому что очень редко я показывал слово, 

49
00:02:24,051 --> 00:02:26,960
состоящее из нескольких букв, которые также попадали в этот крайний регистр. 

50
00:02:27,680 --> 00:02:31,872
Но одна из очень немногих существенных вещей, которая действительно меняется и, 

51
00:02:31,872 --> 00:02:35,646
возможно, имеет немалое значение, — это окончательный вывод о том, как, 

52
00:02:35,646 --> 00:02:39,472
если мы хотим найти оптимально возможный балл для списка ответов Wordle, 

53
00:02:39,472 --> 00:02:42,460
какое начальное предположение использует такой алгоритм? 

54
00:02:43,080 --> 00:02:46,514
В видео я сказал, что лучшая производительность, которую я смог найти, 

55
00:02:46,514 --> 00:02:50,431
была получена при открытии со словом кран, что было правдой только в том смысле, 

56
00:02:50,431 --> 00:02:52,560
что алгоритмы играли в немного другую игру. 

57
00:02:53,160 --> 00:02:56,561
После исправления и повторного запуска всего этого появляется другой ответ на вопрос, 

58
00:02:56,561 --> 00:03:00,120
какое теоретически оптимальное первое предположение является для этого конкретного списка.

59
00:03:00,120 --> 00:03:00,160
 

60
00:03:01,000 --> 00:03:04,416
И послушайте, я знаю, что вы знаете, что цель видео не в том, 

61
00:03:04,416 --> 00:03:09,100
чтобы найти какой-то технически оптимальный ответ на какую-то случайную онлайн-игру. 

62
00:03:09,460 --> 00:03:12,322
Смысл видео в том, чтобы беззастенчиво вскочить на подножку 

63
00:03:12,322 --> 00:03:15,900
интернет-тренда и тайно атаковать людей с помощью урока теории информации. 

64
00:03:16,320 --> 00:03:18,000
И это все хорошо, я поддерживаю эту часть. 

65
00:03:18,200 --> 00:03:22,540
Но я знаю, как работает Интернет, и для многих людей главным выводом было то, 

66
00:03:22,540 --> 00:03:24,600
как лучше всего начать игру в слова. 

67
00:03:25,280 --> 00:03:28,411
И я понимаю, я вошел в это, потому что поместил это в миниатюру, но, 

68
00:03:28,411 --> 00:03:31,860
вероятно, вы простите меня, если я захочу добавить сюда небольшую поправку. 

69
00:03:31,980 --> 00:03:35,219
И более весомая причина вернуться ко всему этому на самом деле заключается в том, 

70
00:03:35,219 --> 00:03:38,340
что я никогда особо не говорил о том, что входило в этот окончательный анализ. 

71
00:03:38,840 --> 00:03:42,420
И как подурок он интересен сам по себе, поэтому его стоит пройти здесь. 

72
00:03:43,140 --> 00:03:46,197
Если вы помните, большая часть нашего времени в прошлом видео 

73
00:03:46,197 --> 00:03:49,057
была потрачена на попытку написать алгоритм решения слов, 

74
00:03:49,057 --> 00:03:52,460
который не использовал бы официальный список всех возможных ответов. 

75
00:03:52,980 --> 00:03:56,000
На мой вкус, это немного похоже на переоснащение тестового набора, 

76
00:03:56,000 --> 00:03:58,480
и что еще интереснее, это создавать что-то устойчивое. 

77
00:03:58,900 --> 00:04:03,207
Вот почему мы прошли весь процесс изучения относительной частоты слов в английском языке, 

78
00:04:03,207 --> 00:04:06,079
чтобы прийти к некоторому выводу о том, насколько вероятно, 

79
00:04:06,079 --> 00:04:08,760
что каждое из них будет включено в окончательный ответ. 

80
00:04:09,400 --> 00:04:13,233
Однако для того, что мы здесь делаем, когда мы просто пытаемся найти абсолютно 

81
00:04:13,233 --> 00:04:16,969
лучший период производительности, я включаю этот официальный список и просто 

82
00:04:16,969 --> 00:04:20,656
бесстыдно подгоняю его к тестовому набору, то есть мы с уверенностью знаем, 

83
00:04:20,656 --> 00:04:24,829
является ли слово включен он или нет, и мы можем присвоить каждому из них равномерную 

84
00:04:24,829 --> 00:04:25,460
вероятность. 

85
00:04:26,440 --> 00:04:29,642
Если вы помните, первым шагом во всем этом было сказать для конкретного 

86
00:04:29,642 --> 00:04:33,333
начального предположения, может быть, что-то вроде моего старого любимого журавля, 

87
00:04:33,333 --> 00:04:36,180
насколько вероятно, что вы увидите каждую из возможных моделей? 

88
00:04:36,680 --> 00:04:40,691
И в этом контексте, когда мы бессовестно подгоняем список ответов под слова, все, 

89
00:04:40,691 --> 00:04:44,850
что для этого нужно, — это подсчитать, сколько возможных ответов дает каждый из этих 

90
00:04:44,850 --> 00:04:45,340
шаблонов. 

91
00:04:45,980 --> 00:04:49,429
И потом, конечно, большая часть нашего времени была потрачена на такого рода забавно 

92
00:04:49,429 --> 00:04:52,026
выглядящую формулу для количественной оценки объема информации, 

93
00:04:52,026 --> 00:04:54,543
которую вы получите из этого предположения, которое, по сути, 

94
00:04:54,543 --> 00:04:57,424
включает в себя просмотр каждого из этих сегментов и определение того, 

95
00:04:57,424 --> 00:05:00,184
сколько информации вы получите, если это логарифмическое выражение, 

96
00:05:00,184 --> 00:05:02,294
представляющее собой причудливый способ определить, 

97
00:05:02,294 --> 00:05:05,094
во сколько раз вы сократили бы свое пространство возможностей вдвое, 

98
00:05:05,094 --> 00:05:06,840
если бы наблюдали заданную закономерность. 

99
00:05:07,600 --> 00:05:09,729
Мы берем средневзвешенное значение всех этих показателей, 

100
00:05:09,729 --> 00:05:12,629
и это дает нам представление о том, сколько мы ожидаем узнать из этого первого 

101
00:05:12,629 --> 00:05:13,180
предположения. 

102
00:05:13,560 --> 00:05:17,374
Через мгновение мы углубимся в это, но если вы просто проведете поиск по 

103
00:05:17,374 --> 00:05:21,032
всем 13 000 различных слов, с которых вы могли бы начать, и спросите, 

104
00:05:21,032 --> 00:05:24,168
какое из них имеет наиболее ожидаемую информацию, окажется, 

105
00:05:24,168 --> 00:05:27,408
что лучший возможный ответ — «парить», что не так уж и важно. 

106
00:05:27,408 --> 00:05:30,543
На самом деле это слово не похоже на настоящее, но я думаю, 

107
00:05:30,543 --> 00:05:33,000
это устаревший термин для обозначения ястреба. 

108
00:05:34,040 --> 00:05:37,028
Топ-15 первых игроков по этому показателю выглядят так, 

109
00:05:37,028 --> 00:05:39,909
но это не обязательно лучшие начальные предположения, 

110
00:05:39,909 --> 00:05:44,445
потому что они делают лишь один шаг вперед с помощью эвристики ожидаемой информации, 

111
00:05:44,445 --> 00:05:47,540
чтобы попытаться оценить, каков будет истинный результат. 

112
00:05:47,920 --> 00:05:51,680
Но шаблонов достаточно мало, чтобы мы могли провести исчерпывающий поиск за два шага. 

113
00:05:52,160 --> 00:05:56,155
Например, предположим, что вы открылись с взлетом и фигура, которую вы увидели, 

114
00:05:56,155 --> 00:06:00,450
была наиболее вероятной, все серые, тогда вы можете провести идентичный анализ с этой 

115
00:06:00,450 --> 00:06:00,800
точки. 

116
00:06:01,320 --> 00:06:04,479
Для данного предложенного второго предположения, например «котенок», 

117
00:06:04,479 --> 00:06:07,501
каково распределение по всем шаблонам в этом ограниченном случае, 

118
00:06:07,501 --> 00:06:11,026
когда мы ограничены только словами, которые дают все серые цвета для взлета, 

119
00:06:11,026 --> 00:06:13,544
а затем мы измеряем равномерность этого распределения, 

120
00:06:13,544 --> 00:06:16,154
используя это ожидаемое значение информационную формулу, 

121
00:06:16,154 --> 00:06:18,352
и мы делаем это для всех 13 000 возможных слов, 

122
00:06:18,352 --> 00:06:21,420
которые мы могли бы использовать в качестве второго предположения. 

123
00:06:22,120 --> 00:06:25,715
Сделав это, мы можем найти оптимальное второе предположение в этом сценарии 

124
00:06:25,715 --> 00:06:29,406
и объем информации, которую мы ожидали получить от него, и если мы промываем, 

125
00:06:29,406 --> 00:06:32,623
промываем, повторяем и проделываем это для всех возможных шаблонов, 

126
00:06:32,623 --> 00:06:36,219
которые вы можете увидеть, мы получим полная карта всех наилучших возможных 

127
00:06:36,219 --> 00:06:39,200
вторых догадок вместе с ожидаемой информацией о каждой из них. 

128
00:06:43,180 --> 00:06:47,125
Отсюда, если вы возьмете средневзвешенное значение всех этих значений второго шага, 

129
00:06:47,125 --> 00:06:51,164
взвешенное в зависимости от того, насколько вероятно, что вы попадете в этот сегмент, 

130
00:06:51,164 --> 00:06:53,841
это даст вам меру того, сколько информации вы, вероятно, 

131
00:06:53,841 --> 00:06:56,800
получите от резкого увеличения предположений после второй шаг. 

132
00:06:57,380 --> 00:07:00,632
Когда мы используем эту двухэтапную метрику в качестве нового средства ранжирования, 

133
00:07:00,632 --> 00:07:01,780
список немного встряхивается. 

134
00:07:02,080 --> 00:07:05,000
Соар больше не занимает первое место, он опускается на 14-е место, 

135
00:07:05,000 --> 00:07:07,660
а вместо этого то, что поднимается на вершину, уничтожается. 

136
00:07:08,640 --> 00:07:12,063
Опять же, это выглядит не очень реалистично и похоже, 

137
00:07:12,063 --> 00:07:17,200
что это британский термин, обозначающий лопату, используемую для стрижки газона. 

138
00:07:17,200 --> 00:07:21,004
Хорошо, но, как вы можете видеть, между всеми этими главными претендентами идет 

139
00:07:21,004 --> 00:07:25,000
очень напряженная гонка за то, кто получит больше информации после этих двух шагов. 

140
00:07:25,700 --> 00:07:28,843
И даже несмотря на это, это не обязательно лучшие начальные предположения, 

141
00:07:28,843 --> 00:07:30,939
потому что информация — это всего лишь эвристика, 

142
00:07:30,939 --> 00:07:34,000
она не сообщает нам реальный счет, если вы действительно играете в игру. 

143
00:07:34,580 --> 00:07:39,682
Я запустил симуляцию игры во все 2315 возможных словесных игр 

144
00:07:39,682 --> 00:07:44,620
со всеми возможными ответами из 250 лучших из этого списка. 

145
00:07:46,460 --> 00:07:51,481
И, сделав это, наблюдая, как они на самом деле работают, тот, 

146
00:07:51,481 --> 00:07:57,961
который в конечном итоге набирает максимально возможный балл, оказывается Сале, 

147
00:07:57,961 --> 00:08:04,360
что является альтернативным написанием Сале, который представляет собой легкий 

148
00:08:04,360 --> 00:08:05,980
средневековый шлем. 

149
00:08:06,980 --> 00:08:11,099
Хорошо, если вам это кажется слишком фальшивым, как мне кажется, 

150
00:08:11,099 --> 00:08:16,360
вы будете рады узнать, что Trace и Crate дают почти одинаковую производительность. 

151
00:08:16,360 --> 00:08:18,888
Преимущество каждого из них заключается в том, что это, очевидно, 

152
00:08:18,888 --> 00:08:21,953
настоящее слово, поэтому наступит день, когда вы угадаете его с первой догадки, 

153
00:08:21,953 --> 00:08:24,060
поскольку оба являются настоящими словесными ответами. 

154
00:08:25,020 --> 00:08:28,691
Переход от сортировки на основе лучших двухшаговых энтропий к сортировке на 

155
00:08:28,691 --> 00:08:32,460
основе наименьшего среднего балла также встряхивает список, но не так сильно. 

156
00:08:32,659 --> 00:08:36,866
Например, Сале раньше занимал третье место, прежде чем поднялся на вершину, 

157
00:08:36,866 --> 00:08:39,080
а Crate и Trace были четвертым и пятым. 

158
00:08:39,640 --> 00:08:42,610
Если вам интересно, вы можете добиться немного большей производительности, 

159
00:08:42,610 --> 00:08:43,720
выполнив небольшой перебор. 

160
00:08:44,100 --> 00:08:47,346
Если вам интересно, есть очень хорошая запись в блоге Джонатана Олсона, 

161
00:08:47,346 --> 00:08:50,548
где он также позволяет вам изучить оптимальные следующие предположения 

162
00:08:50,548 --> 00:08:53,660
для нескольких начальных слов на основе этих оптимальных алгоритмов. 

163
00:08:55,180 --> 00:08:57,752
Однако, отступив от всего этого, некоторые люди говорят мне, 

164
00:08:57,752 --> 00:09:00,409
что если чрезмерно анализировать игру таким образом и пытаться 

165
00:09:00,409 --> 00:09:02,940
найти оптимальное начальное предположение, это портит игру. 

166
00:09:02,940 --> 00:09:06,640
Знаете, это кажется грязным, если вы используете эту вступительную догадку после того, 

167
00:09:06,640 --> 00:09:09,660
как вы ее выучили, и кажется неэффективным, если вы этого не сделаете. 

168
00:09:09,800 --> 00:09:13,310
Но дело в том, что я на самом деле не думаю, что это лучший дебют для человека, 

169
00:09:13,310 --> 00:09:14,100
играющего в игру. 

170
00:09:14,100 --> 00:09:18,679
Во-первых, вам нужно знать, какова оптимальная вторая догадка для каждого из шаблонов, 

171
00:09:18,679 --> 00:09:19,680
которые вы видите. 

172
00:09:20,260 --> 00:09:22,928
И что еще более важно, все это происходит в обстановке, 

173
00:09:22,928 --> 00:09:26,360
когда мы абсурдно подстраиваемся под официальный список ответов Wordle. 

174
00:09:26,580 --> 00:09:29,915
В тот момент, когда, скажем, New York Times решит изменить то, 

175
00:09:29,915 --> 00:09:32,880
что находится в этом списке, все это улетучится в окно. 

176
00:09:33,580 --> 00:09:36,116
То, как мы, люди, играем в игру, сильно отличается от того, 

177
00:09:36,116 --> 00:09:37,680
что делает любой из этих алгоритмов. 

178
00:09:38,020 --> 00:09:40,946
Мы не запоминаем список слов, не проводим исчерпывающий поиск, 

179
00:09:40,946 --> 00:09:45,080
мы получаем интуицию из таких вещей, как, например, какие гласные и как они расположены. 

180
00:09:45,640 --> 00:09:48,990
На самом деле я был бы очень рад, если бы те из вас, кто смотрит это видео, 

181
00:09:48,990 --> 00:09:52,165
быстро забыли, что является технически лучшим начальным предположением, 

182
00:09:52,165 --> 00:09:54,281
и вместо этого вспомнили бы такие вещи, как то, 

183
00:09:54,281 --> 00:09:57,500
как вы оцениваете информацию или тот факт, что вам следует остерегаться, 

184
00:09:57,500 --> 00:10:00,542
когда жадный Алгоритм не достигает лучшей в мире производительности, 

185
00:10:00,542 --> 00:10:03,100
которую можно было бы получить при более глубоком поиске. 

186
00:10:03,700 --> 00:10:07,252
По крайней мере, на мой вкус, радость от написания алгоритмов для игр на самом 

187
00:10:07,252 --> 00:10:10,760
деле очень мало влияет на то, как мне нравится играть в эти игры как человек. 

188
00:10:11,300 --> 00:10:14,214
Смысл написания алгоритмов для всего этого не в том, чтобы повлиять на то, 

189
00:10:14,214 --> 00:10:16,780
как мы играем в игру, это все равно просто забавная игра в слова. 

190
00:10:17,100 --> 00:10:19,107
Это оттачивание наших мускулов для написания алгоритмов 

191
00:10:19,107 --> 00:10:20,720
в более значимых контекстах в других местах. 

