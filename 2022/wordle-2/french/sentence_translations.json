[
 {
  "input": "Last week I put up this video about solving the game Wordle, or at least trying to solve it, using information theory. ",
  "translatedText": "La semaine dernière, j'ai mis en ligne cette vidéo sur la résolution du jeu Wordle, ou du moins sur la tentative de le résoudre, en utilisant la théorie de l'information. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.18
 },
 {
  "input": "And I wanted to add a quick, what should we call this, an addendum? ",
  "translatedText": "Et je voulais ajouter un rapide, comment devrions-nous appeler cela, un addendum ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 6.58,
  "end": 9.78
 },
 {
  "input": "A confession? ",
  "translatedText": "Une confession? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.08,
  "end": 10.66
 },
 {
  "input": "Basically I just want to explain a place where I made a mistake. ",
  "translatedText": "En gros, je veux juste expliquer un endroit où j'ai commis une erreur. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.02,
  "end": 13.9
 },
 {
  "input": "It turns out there was a very slight bug in the code that I was running to recreate Wordle and then run all of the algorithms to solve it and test their performance. ",
  "translatedText": "Il s'avère qu'il y avait un très léger bug dans le code que j'exécutais pour recréer Wordle, puis exécuter tous les algorithmes pour le résoudre et tester leurs performances. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.46,
  "end": 22.0
 },
 {
  "input": "And it's one of those bugs that affects a very small percentage of cases, so it was easy to miss, and it has only a very slight effect that for the most part doesn't really matter. ",
  "translatedText": "Et c'est un de ces bugs qui affectent un très petit pourcentage de cas, donc il était facile de le rater, et il n'a qu'un très léger effet qui, pour la plupart, n'a pas vraiment d'importance. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.6,
  "end": 30.5
 },
 {
  "input": "Basically it had to do with how you assign a color to a guess that has multiple different letters in it. ",
  "translatedText": "Fondamentalement, cela concernait la façon dont vous attribuiez une couleur à une supposition contenant plusieurs lettres différentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.22,
  "end": 36.36
 },
 {
  "input": "For example, if you guess speed and the true answer is abide, how should you color those two e's from the guess? ",
  "translatedText": "Par exemple, si vous devinez la vitesse et que la vraie réponse est respecter, comment devriez-vous colorier ces deux e à partir de la supposition ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 36.52,
  "end": 42.12
 },
 {
  "input": "Well the way that it works with the Wordle conventions is that the first e would be colored yellow, and the second one would be colored gray. ",
  "translatedText": "Eh bien, la façon dont cela fonctionne avec les conventions Wordle est que le premier e serait de couleur jaune et le second serait de couleur grise. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.06,
  "end": 49.08
 },
 {
  "input": "You might think of that first one as matching up with something from the true answer, and the grayness is telling you there is no second e. ",
  "translatedText": "Vous pourriez penser que le premier correspond à quelque chose de la vraie réponse, et le gris vous indique qu'il n'y a pas de deuxième e. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 49.6,
  "end": 55.52
 },
 {
  "input": "By contrast, if the answer was something like erase, both of those e's would be colored yellow, telling you that there is a first e in a different location, and there's a second e also in a different location. ",
  "translatedText": "En revanche, si la réponse était quelque chose comme effacer, ces deux e seraient de couleur jaune, vous indiquant qu'il y a un premier e à un endroit différent, et qu'il y a un deuxième e également à un endroit différent. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.52,
  "end": 66.78
 },
 {
  "input": "Similarly if one of the e's hits and it's green, then that second one would be gray in the case where the true answer has no second e, but it would be yellow in the case where there is a second e and it's just in a different location. ",
  "translatedText": "De même, si l'un des e arrive et qu'il est vert, alors ce deuxième sera gris dans le cas où la vraie réponse n'a pas de deuxième e, mais il sera jaune dans le cas où il y a un deuxième e et il est juste dans un autre e. emplacement. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.3,
  "end": 80.04
 },
 {
  "input": "Long story short, somewhere along the way I accidentally introduced behavior that differs from these conventions slightly. ",
  "translatedText": "Pour faire court, quelque part en cours de route, j'ai accidentellement introduit un comportement qui diffère légèrement de ces conventions. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.7,
  "end": 86.4
 },
 {
  "input": "Honestly it was really dumb. ",
  "translatedText": "Honnêtement, c'était vraiment stupide. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.1,
  "end": 88.54
 },
 {
  "input": "Basically at some point in the middle of the project I wanted to speed up some of the computations, and I was trying a little trick for how it computed the value for this pattern between any given pair of words, and you know I just didn't really think it through and it introduced this slight change. ",
  "translatedText": "Fondamentalement, à un moment donné au milieu du projet, je voulais accélérer certains calculs, et j'essayais une petite astuce pour calculer la valeur de ce modèle entre une paire de mots donnée, et vous savez, je l'ai juste fait. Je n’y ai pas vraiment réfléchi et cela a introduit ce léger changement. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.88,
  "end": 102.72
 },
 {
  "input": "The ironic part is that in the end the actual way to make things fastest is to pre-compute all those patterns so that everything is just a lookup, and so it wouldn't matter how long it takes to do each one, especially if you're writing hard to read buggy code to make it happen. ",
  "translatedText": "L'ironie est qu'en fin de compte, la véritable manière d'accélérer les choses est de pré-calculer tous ces modèles afin que tout ne soit qu'une recherche, et donc le temps qu'il faut pour faire chacun d'eux n'a pas d'importance, surtout si vous J'écris du code bogué pour que cela se produise. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.22,
  "end": 115.84
 },
 {
  "input": "You know, you live and you learn. ",
  "translatedText": "Vous savez, vous vivez et vous apprenez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.4,
  "end": 117.24
 },
 {
  "input": "As far as how this affects the actual video, I mean very little of substance really changes. ",
  "translatedText": "En ce qui concerne la façon dont cela affecte la vidéo elle-même, je veux dire que très peu de choses changent réellement. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.04,
  "end": 122.34
 },
 {
  "input": "Of course the main lessons about what is information, what is entropy, all that stays the same. ",
  "translatedText": "Bien sûr, les principales leçons sur ce qu’est l’information, ce qu’est l’entropie, tout cela reste le même. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.66,
  "end": 126.56
 },
 {
  "input": "Every now and then if I'm showing on screen some distribution associated with a given word, that distribution might actually be a little bit off because some of the buckets associated with various patterns should include either more or fewer true answers. ",
  "translatedText": "De temps en temps, si j'affiche à l'écran une distribution associée à un mot donné, cette distribution peut en fait être un peu erronée car certains des compartiments associés à divers modèles devraient inclure plus ou moins de vraies réponses. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.86,
  "end": 140.32
 },
 {
  "input": "Even then it doesn't really come up because it was very rare that I would be showing a word that had multiple letters that also hit this edge case. ",
  "translatedText": "Même dans ce cas, cela n'apparaît pas vraiment car il était très rare que je montre un mot comportant plusieurs lettres qui touchaient également ce cas limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.84,
  "end": 146.96
 },
 {
  "input": "But one of the very few things of substance that does change and that arguably does matter a fair bit was the final conclusion around how if we want to find the optimal possible score for the wordle answer list, what opening guess does such an algorithm use? ",
  "translatedText": "Mais l'une des très rares choses de fond qui change et qui compte sans doute assez peu est la conclusion finale sur la façon dont si nous voulons trouver le score optimal possible pour la liste de réponses de mots, quelle hypothèse d'ouverture un tel algorithme utilise-t-il ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.68,
  "end": 162.46
 },
 {
  "input": "In the video I said the best performance that I could find came from opening with the word crane, which was true only in the sense that the algorithms were playing a very slightly different game. ",
  "translatedText": "Dans la vidéo, j'ai dit que la meilleure performance que j'avais pu trouver provenait d'une ouverture avec le mot grue, ce qui n'était vrai que dans le sens où les algorithmes jouaient à un jeu très légèrement différent. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.08,
  "end": 172.56
 },
 {
  "input": "After fixing it and rerunning it all, there is a different answer for what the theoretically optimal first guess is for this particular list. ",
  "translatedText": "Après avoir corrigé le problème et réexécuté le tout, il existe une réponse différente quant à la première estimation théoriquement optimale pour cette liste particulière. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.16,
  "end": 180.16
 },
 {
  "input": "And look, I know that you know that the point of the video is not to find some technically optimal answer to some random online game. ",
  "translatedText": "Et écoutez, je sais que vous savez que le but de la vidéo n’est pas de trouver une réponse techniquement optimale à un jeu en ligne aléatoire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.0,
  "end": 189.1
 },
 {
  "input": "The point of the video is to shamelessly hop on the bandwagon of an internet trend to sneak attack people with an information theory lesson. ",
  "translatedText": "Le but de la vidéo est de suivre sans vergogne le mouvement d’Internet pour attaquer sournoisement les gens avec une leçon de théorie de l’information. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.46,
  "end": 195.9
 },
 {
  "input": "And that's all good, I stand by that part. ",
  "translatedText": "Et tout va bien, je maintiens cette partie. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.32,
  "end": 198.0
 },
 {
  "input": "But I know how the internet works, and for a lot of people the one main takeaway was what is the best opener for the game wordle. ",
  "translatedText": "Mais je sais comment fonctionne Internet, et pour beaucoup de gens, le principal point à retenir était de savoir quelle est la meilleure introduction au mot de jeu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 198.2,
  "end": 204.6
 },
 {
  "input": "And I get it, I walked into that because I put it in the thumbnail, but presumably you can forgive me if I want to add a little correction here. ",
  "translatedText": "Et je comprends, je suis entré là-dedans parce que je l'ai mis dans la vignette, mais vous pouvez probablement me pardonner si je veux ajouter une petite correction ici. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.28,
  "end": 211.86
 },
 {
  "input": "And a more meaningful reason to circle back to all this actually is that I never really talked about what went into that final analysis. ",
  "translatedText": "Et une raison plus significative de revenir sur tout cela est que je n’ai jamais vraiment parlé de ce qui est entré dans cette analyse finale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.98,
  "end": 218.34
 },
 {
  "input": "And it's interesting as a sublesson in its own right, so it's worth doing here. ",
  "translatedText": "Et c'est intéressant en tant que sous-leçon en soi, donc ça vaut la peine de le faire ici. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.84,
  "end": 222.42
 },
 {
  "input": "Now if you'll recall, most of our time last video was spent on the challenge of trying to write an algorithm to solve wordle that did not use the official list of all possible answers. ",
  "translatedText": "Maintenant, si vous vous en souvenez bien, la plupart de notre temps dans la dernière vidéo a été consacré au défi consistant à essayer d'écrire un algorithme pour résoudre des mots qui n'utilisait pas la liste officielle de toutes les réponses possibles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.14,
  "end": 232.46
 },
 {
  "input": "To my taste, that feels a bit like overfitting to a test set, and what's more fun is building something that's resilient. ",
  "translatedText": "À mon goût, cela ressemble un peu à un surajustement d'un ensemble de test, et ce qui est plus amusant, c'est de construire quelque chose de résilient. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.98,
  "end": 238.48
 },
 {
  "input": "This is why we went through the whole process of looking at relative word frequencies in the English language to come up with some notion of how likely each one would be to be included as a final answer. ",
  "translatedText": "C'est pourquoi nous avons suivi tout le processus d'examen des fréquences relatives des mots dans la langue anglaise pour arriver à une idée de la probabilité que chacun d'entre eux soit inclus comme réponse finale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.9,
  "end": 248.76
 },
 {
  "input": "However, for what we're doing here, where we're just trying to find an absolute best performance period, I am incorporating that official list and just shamelessly overfitting to the test set, which is to say we know with certainty whether a word is included or not, and we can assign a uniform probability to each one. ",
  "translatedText": "Cependant, pour ce que nous faisons ici, où nous essayons simplement de trouver une période de performance optimale absolue, j'incorpore cette liste officielle et je surajuste sans vergogne l'ensemble de tests, c'est-à-dire que nous savons avec certitude si un mot est inclus ou non, et nous pouvons attribuer une probabilité uniforme à chacun. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.4,
  "end": 265.46
 },
 {
  "input": "If you'll remember, the first step in all of this was to say for a particular opening guess, maybe something like my old favorite, crane, how likely is it that you would see each of the possible patterns? ",
  "translatedText": "Si vous vous en souvenez bien, la première étape dans tout cela était de dire, pour une supposition d'ouverture particulière, peut-être quelque chose comme mon ancien favori, la grue, quelle est la probabilité que vous voyiez chacun des modèles possibles ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 266.44,
  "end": 276.18
 },
 {
  "input": "And in this context, where we are shamelessly overfitting to the wordle answer list, all that involves is counting how many of the possible answers give each one of these patterns. ",
  "translatedText": "Et dans ce contexte, où nous surajustons sans vergogne la liste de réponses par mots, tout ce que cela implique est de compter combien de réponses possibles donnent chacun de ces modèles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 276.68,
  "end": 285.34
 },
 {
  "input": "And then of course most of our time was spent on this kind of funny looking formula to quantify the amount of information that you would get from this guess that basically involves going through each one of those buckets and saying how much information would you gain that has this log expression that is a fanciful way of saying how many times would you cut your space of possibilities in half if you observed a given pattern. ",
  "translatedText": "Et bien sûr, la plupart de notre temps a été consacré à ce genre de formule amusante pour quantifier la quantité d'informations que vous obtiendriez de cette supposition, ce qui implique essentiellement de parcourir chacun de ces compartiments et de dire quelle quantité d'informations vous obtiendriez. cette expression de journal qui est une manière fantaisiste de dire combien de fois réduiriez-vous votre espace des possibilités de moitié si vous observiez un modèle donné. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.98,
  "end": 306.84
 },
 {
  "input": "We take a weighted average of all of those and it gives us a measure of how much we expect to learn from this first guess. ",
  "translatedText": "Nous prenons une moyenne pondérée de tous ces éléments et cela nous donne une mesure de ce que nous espérons apprendre de cette première estimation. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.6,
  "end": 313.18
 },
 {
  "input": "In a moment we'll go deeper than this, but if you simply search through all 13,000 different words that you could start with and you ask which one has the highest expected information, it turns out the best possible answer is soar, which doesn't really look like a real word, but I guess it's an obsolete term for a baby hawk. ",
  "translatedText": "Dans un instant, nous irons plus loin que cela, mais si vous recherchez simplement parmi les 13 000 mots différents avec lesquels vous pourriez commencer et que vous demandez lequel contient les informations attendues les plus élevées, il s'avère que la meilleure réponse possible est planer, ce qui n'est pas le cas. Cela ne ressemble pas vraiment à un vrai mot, mais je suppose que c'est un terme obsolète pour désigner un bébé faucon. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.56,
  "end": 333.0
 },
 {
  "input": "The top 15 openers by this metric happen to look like this, but these are not necessarily the best opening guesses because they're only looking one step in with the heuristic of expected information to try to estimate what the true score will be. ",
  "translatedText": "Les 15 premiers ouvreurs selon cette métrique ressemblent à ceci, mais ce ne sont pas nécessairement les meilleures suppositions d'ouverture car ils ne regardent qu'une étape dans l'heuristique des informations attendues pour essayer d'estimer quel sera le véritable score. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.04,
  "end": 347.54
 },
 {
  "input": "But there's few enough patterns that we can do an exhaustive search two steps in. ",
  "translatedText": "Mais il existe suffisamment de modèles pour que nous puissions effectuer une recherche exhaustive en deux étapes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.92,
  "end": 351.68
 },
 {
  "input": "For example, let's say you opened with soar and the pattern you happen to see was the most likely one, all grays, then you can run identical analysis from that point. ",
  "translatedText": "Par exemple, disons que vous avez ouvert avec Soar et que le motif que vous voyez est le plus probable, entièrement gris, vous pouvez alors exécuter une analyse identique à partir de ce point. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 352.16,
  "end": 360.8
 },
 {
  "input": "For a given proposed second guess, something like kitty, what's the distribution across all patterns in that restricted case where we're restricted only to the words that would produce all grays for soar, and then we measure the flatness of that distribution using this expected information formula, and we do that for all 13,000 possible words that we could use as a second guess. ",
  "translatedText": "Pour une seconde proposition donnée, quelque chose comme Kitty, quelle est la distribution entre tous les modèles dans ce cas restreint où nous sommes limités uniquement aux mots qui produiraient tous les gris pour monter en flèche, puis nous mesurons la planéité de cette distribution en utilisant cette valeur attendue. formule d'information, et nous le faisons pour les 13 000 mots possibles que nous pourrions utiliser comme seconde hypothèse. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 361.32,
  "end": 381.42
 },
 {
  "input": "Doing this we can find the optimal second guess in that scenario and the amount of information we were expected to get from it, and if we wash rinse and repeat and do this for all of the different possible patterns that you might see, we get a full map of all the best possible second guesses together with the expected information of each. ",
  "translatedText": "En faisant cela, nous pouvons trouver la seconde estimation optimale dans ce scénario et la quantité d'informations que nous étions censés en tirer, et si nous lavons, rinçons et répétons et faisons cela pour tous les différents modèles possibles que vous pourriez voir, nous obtenons un carte complète de toutes les meilleures secondes hypothèses possibles ainsi que les informations attendues de chacune. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.12,
  "end": 399.2
 },
 {
  "input": "From there, if you take a weighted average of all those second step values, weighted according to how likely you are to fall into that bucket, it gives you a measure of how much information you're likely to gain from the guess soar after the second step. ",
  "translatedText": "À partir de là, si vous faites une moyenne pondérée de toutes ces valeurs de deuxième étape, pondérée en fonction de la probabilité que vous tombiez dans ce seau, cela vous donne une mesure de la quantité d'informations que vous êtes susceptible d'obtenir de la montée en flèche des suppositions après le deuxième étape. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.18,
  "end": 416.8
 },
 {
  "input": "When we use this two-step metric as our new means of ranking, the list gets shaken up a bit. ",
  "translatedText": "Lorsque nous utilisons cette métrique en deux étapes comme nouveau moyen de classement, la liste est un peu bouleversée. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.38,
  "end": 421.78
 },
 {
  "input": "Soar is no longer first place, it falls back to 14th, and instead what rises to the top is slain. ",
  "translatedText": "Soar n'est plus la première place, il retombe à la 14ème place, et à la place, ce qui monte au sommet est tué. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.08,
  "end": 427.66
 },
 {
  "input": "Again, doesn't feel very real, and it looks like it is a British term for a spade that's used for cutting turf. ",
  "translatedText": "Encore une fois, cela ne semble pas très réel, et il semble que ce soit un terme britannique désignant une pelle utilisée pour couper le gazon. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.64,
  "end": 436.38
 },
 {
  "input": "Alright, but as you can see it is a really tight race among all of these top contenders for who gains the most information after those two steps. ",
  "translatedText": "D'accord, mais comme vous pouvez le constater, la course est très serrée entre tous ces principaux prétendants pour savoir qui obtient le plus d'informations après ces deux étapes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.2,
  "end": 445.0
 },
 {
  "input": "And even still, these are not necessarily the best opening guesses, because information is just the heuristic, it's not telling us the actual score if you actually play the game. ",
  "translatedText": "Et même quand même, ce ne sont pas nécessairement les meilleures hypothèses de départ, car l’information n’est qu’une heuristique, elle ne nous indique pas le score réel si vous jouez réellement au jeu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.7,
  "end": 454.0
 },
 {
  "input": "What I did is I ran the simulation of playing all 2315 possible wordle games with all possible answers on the top 250 from this list. ",
  "translatedText": "Ce que j'ai fait, c'est que j'ai exécuté la simulation consistant à jouer à tous les 2315 jeux de mots possibles avec toutes les réponses possibles parmi les 250 premières de cette liste. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.58,
  "end": 464.62
 },
 {
  "input": "And by doing this, seeing how they actually perform, the one that ends up very marginally with the best possible score turns out to be Salé, which is an alternate spelling for Salé, which is a light medieval helmet. ",
  "translatedText": "Et en faisant cela, en voyant comment ils se comportent réellement, celui qui obtient très marginalement le meilleur score possible s'avère être Salé, qui est une orthographe alternative pour Salé, qui est un casque médiéval léger. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.46,
  "end": 485.98
 },
 {
  "input": "Alright, if that feels a little bit too fake for you, which it does for me, you'll be happy to know that Trace and Crate give almost identical performance. ",
  "translatedText": "Très bien, si cela vous semble un peu trop faux, ce qui est le cas pour moi, vous serez heureux de savoir que Trace et Crate offrent des performances presque identiques. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.98,
  "end": 495.78
 },
 {
  "input": "Each of them has the benefit of obviously being a real word, so there is one day when you get it right on the first guess, since both are actual wordle answers. ",
  "translatedText": "Chacun d’eux a l’avantage d’être évidemment un vrai mot, il y a donc un jour où vous réussissez dès la première hypothèse, puisque les deux sont de véritables réponses de mots. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 496.3,
  "end": 504.06
 },
 {
  "input": "This move from sorting based on the best two-step entropies to sorting based on the lowest average score also shakes up the list, but not nearly as much. ",
  "translatedText": "Ce passage d’un tri basé sur les meilleures entropies en deux étapes à un tri basé sur le score moyen le plus bas bouleverse également la liste, mais pas autant. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.02,
  "end": 512.46
 },
 {
  "input": "For example, Salé was previously third place before it bubbles to the top, and Crate and Trace were both fourth and fifth. ",
  "translatedText": "Par exemple, Salé occupait auparavant la troisième place avant d'atteindre le sommet, et Crate et Trace étaient tous deux quatrième et cinquième. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.66,
  "end": 519.08
 },
 {
  "input": "If you're curious, you can get slightly better performance from here by doing a little brute forcing. ",
  "translatedText": "Si vous êtes curieux, vous pouvez obtenir des performances légèrement meilleures à partir d'ici en effectuant un petit forçage brutal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.64,
  "end": 523.72
 },
 {
  "input": "There's a very nice blog post by Jonathan Olson, if you're curious about this, where he also lets you explore what the optimal following guesses are for a few of the starting words based on these optimal algorithms. ",
  "translatedText": "Il existe un très bel article de blog de Jonathan Olson, si vous êtes curieux à ce sujet, dans lequel il vous permet également d'explorer quelles sont les suppositions suivantes optimales pour quelques-uns des mots de départ basés sur ces algorithmes optimaux. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.1,
  "end": 533.66
 },
 {
  "input": "Stepping back from all this though, I'm told by some people that it quote ruins the game to overanalyze it like this and try to find an optimal opening guess. ",
  "translatedText": "En prenant du recul par rapport à tout cela, certaines personnes me disent que cela ruine le jeu de le suranalyser comme ça et d'essayer de trouver une supposition d'ouverture optimale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.18,
  "end": 543.6
 },
 {
  "input": "You know, it feels kind of dirty if you use that opening guess after learning it, and it feels inefficient if you don't. ",
  "translatedText": "Vous savez, cela semble un peu sale si vous utilisez cette supposition d'ouverture après l'avoir apprise, et cela semble inefficace si vous ne le faites pas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.26,
  "end": 549.66
 },
 {
  "input": "But the thing is, I don't actually think this is the best opener for a human playing the game. ",
  "translatedText": "Mais le fait est que je ne pense pas vraiment que ce soit la meilleure ouverture pour un humain jouant à ce jeu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 549.8,
  "end": 554.4
 },
 {
  "input": "For one thing, you would need to know what the optimal second guess is for each one of the patterns that you see. ",
  "translatedText": "D’une part, vous auriez besoin de savoir quelle est la seconde estimation optimale pour chacun des modèles que vous voyez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.88,
  "end": 559.68
 },
 {
  "input": "And more importantly, all of this is in a setting where we are absurdly overfit to the official wordle answer list. ",
  "translatedText": "Et plus important encore, tout cela se déroule dans un contexte où nous sommes absurdement suradaptés à la liste de réponses officielle des mots. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.26,
  "end": 566.36
 },
 {
  "input": "The moment that, say, the New York Times chooses to change what that list is under the hood, all of this would go out the window. ",
  "translatedText": "Au moment où, disons, le New York Times choisit de modifier le contenu de cette liste, tout cela disparaîtrait par la fenêtre. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.58,
  "end": 572.88
 },
 {
  "input": "The way that we humans play the game is just very different from what any of these algorithms are doing. ",
  "translatedText": "La façon dont nous, les humains, jouons au jeu est tout simplement très différente de ce que font n’importe lequel de ces algorithmes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.58,
  "end": 577.68
 },
 {
  "input": "We don't have the word list memorized, we're not doing exhaustive searches, we get intuition from things like what are the vowels and how are they placed. ",
  "translatedText": "Nous n'avons pas mémorisé la liste de mots, nous ne faisons pas de recherches exhaustives, nous obtenons des intuitions à partir de choses comme quelles sont les voyelles et comment sont-elles placées. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.02,
  "end": 585.08
 },
 {
  "input": "I would actually be most happy if those of you watching this video promptly forgot what happens to be the technically best opening guess, and instead came out remembering things like how do you quantify information, or the fact that you should look out for when a greedy algorithm falls short of the globally best performance that you would get from a deeper search. ",
  "translatedText": "Je serais en fait très heureux si ceux d'entre vous qui regardent cette vidéo oubliaient rapidement ce qui se trouve être techniquement la meilleure hypothèse d'ouverture, et se souvenaient plutôt de choses comme la façon de quantifier les informations, ou le fait que vous devriez faire attention lorsqu'un gourmand L’algorithme n’atteint pas les meilleures performances mondiales que vous obtiendriez d’une recherche plus approfondie. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 585.64,
  "end": 603.1
 },
 {
  "input": "For my taste at least, the joy of writing algorithms to try to play games actually has very little bearing on how I like to play those games as a human. ",
  "translatedText": "À mon goût du moins, la joie d’écrire des algorithmes pour essayer de jouer à des jeux a en réalité très peu d’impact sur la façon dont j’aime jouer à ces jeux en tant qu’humain. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.7,
  "end": 610.76
 },
 {
  "input": "The point of writing algorithms for all this is not to affect the way that we play the game, it's still just a fun word game. ",
  "translatedText": "Le but d’écrire des algorithmes pour tout cela n’est pas d’affecter la façon dont nous jouons au jeu, c’est juste un jeu de mots amusant. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.3,
  "end": 616.78
 },
 {
  "input": "It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere. ",
  "translatedText": "Il s’agit de perfectionner nos muscles pour écrire des algorithmes dans des contextes plus significatifs ailleurs. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.1,
  "end": 620.72
 }
]