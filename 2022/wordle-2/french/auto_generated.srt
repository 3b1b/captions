1
00:00:00,000 --> 00:00:03,038
La semaine dernière, j'ai mis en ligne cette vidéo sur la résolution du jeu Wordle, 

2
00:00:03,038 --> 00:00:06,145
ou du moins sur la tentative de le résoudre, en utilisant la théorie de l'information.

3
00:00:06,145 --> 00:00:06,180
 

4
00:00:06,580 --> 00:00:09,780
Et je voulais ajouter un rapide, comment devrions-nous appeler cela, un addendum ? 

5
00:00:10,080 --> 00:00:10,660
Une confession? 

6
00:00:11,020 --> 00:00:13,900
En gros, je veux juste expliquer un endroit où j'ai commis une erreur. 

7
00:00:14,460 --> 00:00:17,040
Il s'avère qu'il y avait un très léger bug dans le code 

8
00:00:17,040 --> 00:00:19,459
que j'exécutais pour recréer Wordle, puis exécuter tous 

9
00:00:19,459 --> 00:00:22,000
les algorithmes pour le résoudre et tester leurs performances. 

10
00:00:22,600 --> 00:00:25,432
Et c'est un de ces bugs qui affectent un très petit pourcentage de cas, 

11
00:00:25,432 --> 00:00:28,413
donc il était facile de le rater, et il n'a qu'un très léger effet qui, 

12
00:00:28,413 --> 00:00:30,500
pour la plupart, n'a pas vraiment d'importance. 

13
00:00:31,220 --> 00:00:33,809
Fondamentalement, cela concernait la façon dont vous attribuiez une 

14
00:00:33,809 --> 00:00:36,360
couleur à une supposition contenant plusieurs lettres différentes. 

15
00:00:36,520 --> 00:00:39,489
Par exemple, si vous devinez la vitesse et que la vraie réponse est respecter, 

16
00:00:39,489 --> 00:00:42,120
comment devriez-vous colorier ces deux e à partir de la supposition ? 

17
00:00:43,060 --> 00:00:46,070
Eh bien, la façon dont cela fonctionne avec les conventions Wordle est que 

18
00:00:46,070 --> 00:00:49,080
le premier e serait de couleur jaune et le second serait de couleur grise. 

19
00:00:49,600 --> 00:00:52,982
Vous pourriez penser que le premier correspond à quelque chose de la vraie réponse, 

20
00:00:52,982 --> 00:00:55,520
et le gris vous indique qu'il n'y a pas de deuxième e. 

21
00:00:55,520 --> 00:00:58,542
En revanche, si la réponse était quelque chose comme effacer, 

22
00:00:58,542 --> 00:01:02,344
ces deux e seraient de couleur jaune, vous indiquant qu'il y a un premier 

23
00:01:02,344 --> 00:01:06,731
e à un endroit différent, et qu'il y a un deuxième e également à un endroit différent.

24
00:01:06,731 --> 00:01:06,780
 

25
00:01:07,300 --> 00:01:10,264
De même, si l'un des e arrive et qu'il est vert, 

26
00:01:10,264 --> 00:01:14,788
alors ce deuxième sera gris dans le cas où la vraie réponse n'a pas de deuxième e, 

27
00:01:14,788 --> 00:01:19,364
mais il sera jaune dans le cas où il y a un deuxième e et il est juste dans un autre e. 

28
00:01:19,364 --> 00:01:20,040
emplacement. 

29
00:01:20,700 --> 00:01:23,803
Pour faire court, quelque part en cours de route, 

30
00:01:23,803 --> 00:01:28,458
j'ai accidentellement introduit un comportement qui diffère légèrement 

31
00:01:28,458 --> 00:01:29,700
de ces conventions. 

32
00:01:29,700 --> 00:01:30,140
Honnêtement, c'était vraiment stupide. 

33
00:01:30,140 --> 00:01:32,543
Fondamentalement, à un moment donné au milieu du projet, 

34
00:01:32,543 --> 00:01:35,917
je voulais accélérer certains calculs, et j'essayais une petite astuce pour 

35
00:01:35,917 --> 00:01:39,249
calculer la valeur de ce modèle entre une paire de mots donnée, et vous savez, 

36
00:01:39,249 --> 00:01:42,580
je l'ai juste fait. Je n’y ai pas vraiment réfléchi et cela a introduit ce 

37
00:01:42,580 --> 00:01:43,340
léger changement. 

38
00:01:43,340 --> 00:01:46,483
L'ironie est qu'en fin de compte, la véritable manière d'accélérer les 

39
00:01:46,483 --> 00:01:49,817
choses est de pré-calculer tous ces modèles afin que tout ne soit qu'une recherche, 

40
00:01:49,817 --> 00:01:53,226
et donc le temps qu'il faut pour faire chacun d'eux n'a pas d'importance, 

41
00:01:53,226 --> 00:01:55,840
surtout si vous J'écris du code bogué pour que cela se produise. 

42
00:01:56,400 --> 00:01:57,240
Vous savez, vous vivez et vous apprenez. 

43
00:01:58,040 --> 00:02:00,347
En ce qui concerne la façon dont cela affecte la vidéo elle-même, 

44
00:02:00,347 --> 00:02:02,340
je veux dire que très peu de choses changent réellement. 

45
00:02:02,660 --> 00:02:04,878
Bien sûr, les principales leçons sur ce qu’est l’information, 

46
00:02:04,878 --> 00:02:06,560
ce qu’est l’entropie, tout cela reste le même. 

47
00:02:06,860 --> 00:02:11,382
De temps en temps, si j'affiche à l'écran une distribution associée à un mot 

48
00:02:11,382 --> 00:02:16,170
donné, cette distribution peut en fait être un peu erronée car certains des compartiments 

49
00:02:16,170 --> 00:02:20,320
associés à divers modèles devraient inclure plus ou moins de vraies réponses. 

50
00:02:20,840 --> 00:02:23,862
Même dans ce cas, cela n'apparaît pas vraiment car il était très rare que je 

51
00:02:23,862 --> 00:02:26,960
montre un mot comportant plusieurs lettres qui touchaient également ce cas limite. 

52
00:02:27,680 --> 00:02:31,310
Mais l'une des très rares choses de fond qui change et qui compte 

53
00:02:31,310 --> 00:02:35,044
sans doute assez peu est la conclusion finale sur la façon dont si nous 

54
00:02:35,044 --> 00:02:39,037
voulons trouver le score optimal possible pour la liste de réponses de mots, 

55
00:02:39,037 --> 00:02:42,460
quelle hypothèse d'ouverture un tel algorithme utilise-t-il ? 

56
00:02:43,080 --> 00:02:46,120
Dans la vidéo, j'ai dit que la meilleure performance que j'avais pu 

57
00:02:46,120 --> 00:02:48,360
trouver provenait d'une ouverture avec le mot grue, 

58
00:02:48,360 --> 00:02:51,480
ce qui n'était vrai que dans le sens où les algorithmes jouaient à un jeu 

59
00:02:51,480 --> 00:02:52,560
très légèrement différent. 

60
00:02:53,160 --> 00:02:55,357
Après avoir corrigé le problème et réexécuté le tout, 

61
00:02:55,357 --> 00:02:58,898
il existe une réponse différente quant à la première estimation théoriquement optimale 

62
00:02:58,898 --> 00:03:00,160
pour cette liste particulière. 

63
00:03:01,000 --> 00:03:05,021
Et écoutez, je sais que vous savez que le but de la vidéo n’est pas de 

64
00:03:05,021 --> 00:03:09,100
trouver une réponse techniquement optimale à un jeu en ligne aléatoire. 

65
00:03:09,460 --> 00:03:12,680
Le but de la vidéo est de suivre sans vergogne le mouvement d’Internet pour 

66
00:03:12,680 --> 00:03:15,900
attaquer sournoisement les gens avec une leçon de théorie de l’information. 

67
00:03:16,320 --> 00:03:18,000
Et tout va bien, je maintiens cette partie. 

68
00:03:18,200 --> 00:03:20,837
Mais je sais comment fonctionne Internet, et pour beaucoup de gens, 

69
00:03:20,837 --> 00:03:24,018
le principal point à retenir était de savoir quelle est la meilleure introduction 

70
00:03:24,018 --> 00:03:24,600
au mot de jeu. 

71
00:03:25,280 --> 00:03:28,494
Et je comprends, je suis entré là-dedans parce que je l'ai mis dans la vignette, 

72
00:03:28,494 --> 00:03:31,860
mais vous pouvez probablement me pardonner si je veux ajouter une petite correction ici. 

73
00:03:31,980 --> 00:03:35,048
Et une raison plus significative de revenir sur tout cela est que je 

74
00:03:35,048 --> 00:03:38,340
n’ai jamais vraiment parlé de ce qui est entré dans cette analyse finale. 

75
00:03:38,840 --> 00:03:40,950
Et c'est intéressant en tant que sous-leçon en soi, 

76
00:03:40,950 --> 00:03:42,420
donc ça vaut la peine de le faire ici. 

77
00:03:43,140 --> 00:03:46,176
Maintenant, si vous vous en souvenez bien, la plupart de notre temps dans la dernière 

78
00:03:46,176 --> 00:03:49,070
vidéo a été consacré au défi consistant à essayer d'écrire un algorithme pour 

79
00:03:49,070 --> 00:03:52,071
résoudre des mots qui n'utilisait pas la liste officielle de toutes les réponses 

80
00:03:52,071 --> 00:03:52,460
possibles. 

81
00:03:52,980 --> 00:03:55,730
À mon goût, cela ressemble un peu à un surajustement d'un ensemble de test, 

82
00:03:55,730 --> 00:03:58,480
et ce qui est plus amusant, c'est de construire quelque chose de résilient. 

83
00:03:58,900 --> 00:04:01,970
C'est pourquoi nous avons suivi tout le processus d'examen des 

84
00:04:01,970 --> 00:04:05,343
fréquences relatives des mots dans la langue anglaise pour arriver à une idée 

85
00:04:05,343 --> 00:04:08,760
de la probabilité que chacun d'entre eux soit inclus comme réponse finale. 

86
00:04:09,400 --> 00:04:13,178
Cependant, pour ce que nous faisons ici, où nous essayons simplement de trouver une 

87
00:04:13,178 --> 00:04:17,047
période de performance optimale absolue, j'incorpore cette liste officielle et je 

88
00:04:17,047 --> 00:04:19,251
surajuste sans vergogne l'ensemble de tests, 

89
00:04:19,251 --> 00:04:22,715
c'est-à-dire que nous savons avec certitude si un mot est inclus ou non, 

90
00:04:22,715 --> 00:04:25,460
et nous pouvons attribuer une probabilité uniforme à chacun. 

91
00:04:26,440 --> 00:04:29,388
Si vous vous en souvenez bien, la première étape dans tout cela était de dire, 

92
00:04:29,388 --> 00:04:31,291
pour une supposition d'ouverture particulière, 

93
00:04:31,291 --> 00:04:33,455
peut-être quelque chose comme mon ancien favori, la grue, 

94
00:04:33,455 --> 00:04:36,180
quelle est la probabilité que vous voyiez chacun des modèles possibles ? 

95
00:04:36,680 --> 00:04:40,641
Et dans ce contexte, où nous surajustons sans vergogne la liste de réponses par mots, 

96
00:04:40,641 --> 00:04:43,451
tout ce que cela implique est de compter combien de réponses 

97
00:04:43,451 --> 00:04:45,340
possibles donnent chacun de ces modèles. 

98
00:04:45,980 --> 00:04:49,628
Et bien sûr, la plupart de notre temps a été consacré à ce genre de formule amusante 

99
00:04:49,628 --> 00:04:53,491
pour quantifier la quantité d'informations que vous obtiendriez de cette supposition, 

100
00:04:53,491 --> 00:04:56,882
ce qui implique essentiellement de parcourir chacun de ces compartiments et de 

101
00:04:56,882 --> 00:04:59,371
dire quelle quantité d'informations vous obtiendriez. 

102
00:04:59,371 --> 00:05:02,762
cette expression de journal qui est une manière fantaisiste de dire combien de 

103
00:05:02,762 --> 00:05:06,239
fois réduiriez-vous votre espace des possibilités de moitié si vous observiez un 

104
00:05:06,239 --> 00:05:06,840
modèle donné. 

105
00:05:07,600 --> 00:05:10,371
Nous prenons une moyenne pondérée de tous ces éléments et cela nous donne 

106
00:05:10,371 --> 00:05:13,180
une mesure de ce que nous espérons apprendre de cette première estimation. 

107
00:05:13,560 --> 00:05:15,633
Dans un instant, nous irons plus loin que cela, 

108
00:05:15,633 --> 00:05:19,392
mais si vous recherchez simplement parmi les 13 000 mots différents avec lesquels vous 

109
00:05:19,392 --> 00:05:23,150
pourriez commencer et que vous demandez lequel contient les informations attendues les 

110
00:05:23,150 --> 00:05:26,390
plus élevées, il s'avère que la meilleure réponse possible est planer, 

111
00:05:26,390 --> 00:05:29,630
ce qui n'est pas le cas. Cela ne ressemble pas vraiment à un vrai mot, 

112
00:05:29,630 --> 00:05:33,000
mais je suppose que c'est un terme obsolète pour désigner un bébé faucon. 

113
00:05:34,040 --> 00:05:37,112
Les 15 premiers ouvreurs selon cette métrique ressemblent à ceci, 

114
00:05:37,112 --> 00:05:40,790
mais ce ne sont pas nécessairement les meilleures suppositions d'ouverture 

115
00:05:40,790 --> 00:05:44,421
car ils ne regardent qu'une étape dans l'heuristique des informations 

116
00:05:44,421 --> 00:05:47,540
attendues pour essayer d'estimer quel sera le véritable score. 

117
00:05:47,920 --> 00:05:49,668
Mais il existe suffisamment de modèles pour que nous 

118
00:05:49,668 --> 00:05:51,680
puissions effectuer une recherche exhaustive en deux étapes. 

119
00:05:52,160 --> 00:05:54,890
Par exemple, disons que vous avez ouvert avec Soar et que le 

120
00:05:54,890 --> 00:05:57,621
motif que vous voyez est le plus probable, entièrement gris, 

121
00:05:57,621 --> 00:06:00,800
vous pouvez alors exécuter une analyse identique à partir de ce point. 

122
00:06:01,320 --> 00:06:04,166
Pour une seconde proposition donnée, quelque chose comme Kitty, 

123
00:06:04,166 --> 00:06:07,501
quelle est la distribution entre tous les modèles dans ce cas restreint où 

124
00:06:07,501 --> 00:06:10,880
nous sommes limités uniquement aux mots qui produiraient tous les gris pour 

125
00:06:10,880 --> 00:06:14,171
monter en flèche, puis nous mesurons la planéité de cette distribution en 

126
00:06:14,171 --> 00:06:16,839
utilisant cette valeur attendue. formule d'information, 

127
00:06:16,839 --> 00:06:20,308
et nous le faisons pour les 13 000 mots possibles que nous pourrions utiliser 

128
00:06:20,308 --> 00:06:21,420
comme seconde hypothèse. 

129
00:06:22,120 --> 00:06:25,693
En faisant cela, nous pouvons trouver la seconde estimation optimale dans ce scénario 

130
00:06:25,693 --> 00:06:29,267
et la quantité d'informations que nous étions censés en tirer, et si nous lavons, 

131
00:06:29,267 --> 00:06:32,717
rinçons et répétons et faisons cela pour tous les différents modèles possibles que 

132
00:06:32,717 --> 00:06:36,290
vous pourriez voir, nous obtenons un carte complète de toutes les meilleures secondes 

133
00:06:36,290 --> 00:06:39,200
hypothèses possibles ainsi que les informations attendues de chacune. 

134
00:06:43,180 --> 00:06:46,740
À partir de là, si vous faites une moyenne pondérée de toutes ces valeurs de deuxième 

135
00:06:46,740 --> 00:06:49,927
étape, pondérée en fonction de la probabilité que vous tombiez dans ce seau, 

136
00:06:49,927 --> 00:06:53,529
cela vous donne une mesure de la quantité d'informations que vous êtes susceptible 

137
00:06:53,529 --> 00:06:56,800
d'obtenir de la montée en flèche des suppositions après le deuxième étape. 

138
00:06:57,380 --> 00:07:00,580
Lorsque nous utilisons cette métrique en deux étapes comme nouveau moyen de classement, 

139
00:07:00,580 --> 00:07:01,780
la liste est un peu bouleversée. 

140
00:07:02,080 --> 00:07:05,379
Soar n'est plus la première place, il retombe à la 14ème place, 

141
00:07:05,379 --> 00:07:07,660
et à la place, ce qui monte au sommet est tué. 

142
00:07:08,640 --> 00:07:11,433
Encore une fois, cela ne semble pas très réel, 

143
00:07:11,433 --> 00:07:15,892
et il semble que ce soit un terme britannique désignant une pelle utilisée 

144
00:07:15,892 --> 00:07:17,200
pour couper le gazon. 

145
00:07:17,200 --> 00:07:19,304
D'accord, mais comme vous pouvez le constater, 

146
00:07:19,304 --> 00:07:21,946
la course est très serrée entre tous ces principaux prétendants 

147
00:07:21,946 --> 00:07:25,000
pour savoir qui obtient le plus d'informations après ces deux étapes. 

148
00:07:25,700 --> 00:07:29,257
Et même quand même, ce ne sont pas nécessairement les meilleures hypothèses de départ, 

149
00:07:29,257 --> 00:07:31,914
car l’information n’est qu’une heuristique, elle ne nous indique 

150
00:07:31,914 --> 00:07:34,000
pas le score réel si vous jouez réellement au jeu. 

151
00:07:34,580 --> 00:07:37,943
Ce que j'ai fait, c'est que j'ai exécuté la simulation 

152
00:07:37,943 --> 00:07:41,106
consistant à jouer à tous les 2315 jeux de mots possibles avec 

153
00:07:41,106 --> 00:07:44,620
toutes les réponses possibles parmi les 250 premières de cette liste. 

154
00:07:46,460 --> 00:07:52,084
Et en faisant cela, en voyant comment ils se comportent réellement, 

155
00:07:52,084 --> 00:07:59,280
celui qui obtient très marginalement le meilleur score possible s'avère être Salé, 

156
00:07:59,280 --> 00:08:05,980
qui est une orthographe alternative pour Salé, qui est un casque médiéval léger. 

157
00:08:06,980 --> 00:08:11,228
Très bien, si cela vous semble un peu trop faux, ce qui est le cas pour moi, 

158
00:08:11,228 --> 00:08:15,697
vous serez heureux de savoir que Trace et Crate offrent des performances presque 

159
00:08:15,697 --> 00:08:16,360
identiques. 

160
00:08:16,360 --> 00:08:18,839
Chacun d’eux a l’avantage d’être évidemment un vrai mot, 

161
00:08:18,839 --> 00:08:21,710
il y a donc un jour où vous réussissez dès la première hypothèse, 

162
00:08:21,710 --> 00:08:24,060
puisque les deux sont de véritables réponses de mots. 

163
00:08:25,020 --> 00:08:28,831
Ce passage d’un tri basé sur les meilleures entropies en deux étapes à un tri basé 

164
00:08:28,831 --> 00:08:32,460
sur le score moyen le plus bas bouleverse également la liste, mais pas autant. 

165
00:08:32,659 --> 00:08:36,512
Par exemple, Salé occupait auparavant la troisième place avant d'atteindre le sommet, 

166
00:08:36,512 --> 00:08:39,080
et Crate et Trace étaient tous deux quatrième et cinquième. 

167
00:08:39,640 --> 00:08:41,694
Si vous êtes curieux, vous pouvez obtenir des performances légèrement 

168
00:08:41,694 --> 00:08:43,720
meilleures à partir d'ici en effectuant un petit forçage brutal. 

169
00:08:44,100 --> 00:08:47,346
Il existe un très bel article de blog de Jonathan Olson, si vous êtes curieux à ce sujet, 

170
00:08:47,346 --> 00:08:50,304
dans lequel il vous permet également d'explorer quelles sont les suppositions 

171
00:08:50,304 --> 00:08:53,299
suivantes optimales pour quelques-uns des mots de départ basés sur ces algorithmes 

172
00:08:53,299 --> 00:08:53,660
optimaux. 

173
00:08:55,180 --> 00:08:57,780
En prenant du recul par rapport à tout cela, certaines personnes 

174
00:08:57,780 --> 00:09:00,260
me disent que cela ruine le jeu de le suranalyser comme ça et 

175
00:09:00,260 --> 00:09:02,940
d'essayer de trouver une supposition d'ouverture optimale. 

176
00:09:02,940 --> 00:09:06,461
Vous savez, cela semble un peu sale si vous utilisez cette supposition d'ouverture 

177
00:09:06,461 --> 00:09:09,660
après l'avoir apprise, et cela semble inefficace si vous ne le faites pas. 

178
00:09:09,800 --> 00:09:12,007
Mais le fait est que je ne pense pas vraiment que ce soit 

179
00:09:12,007 --> 00:09:14,100
la meilleure ouverture pour un humain jouant à ce jeu. 

180
00:09:14,100 --> 00:09:16,958
D’une part, vous auriez besoin de savoir quelle est la seconde 

181
00:09:16,958 --> 00:09:19,680
estimation optimale pour chacun des modèles que vous voyez. 

182
00:09:20,260 --> 00:09:23,268
Et plus important encore, tout cela se déroule dans un contexte où nous 

183
00:09:23,268 --> 00:09:26,360
sommes absurdement suradaptés à la liste de réponses officielle des mots. 

184
00:09:26,580 --> 00:09:30,895
Au moment où, disons, le New York Times choisit de modifier le contenu de cette liste, 

185
00:09:30,895 --> 00:09:32,880
tout cela disparaîtrait par la fenêtre. 

186
00:09:33,580 --> 00:09:35,614
La façon dont nous, les humains, jouons au jeu est tout simplement 

187
00:09:35,614 --> 00:09:37,680
très différente de ce que font n’importe lequel de ces algorithmes. 

188
00:09:38,020 --> 00:09:39,665
Nous n'avons pas mémorisé la liste de mots, 

189
00:09:39,665 --> 00:09:41,275
nous ne faisons pas de recherches exhaustives, 

190
00:09:41,275 --> 00:09:43,572
nous obtenons des intuitions à partir de choses comme quelles sont 

191
00:09:43,572 --> 00:09:45,080
les voyelles et comment sont-elles placées. 

192
00:09:45,640 --> 00:09:48,828
Je serais en fait très heureux si ceux d'entre vous qui regardent cette vidéo 

193
00:09:48,828 --> 00:09:51,978
oubliaient rapidement ce qui se trouve être techniquement la meilleure hypothèse 

194
00:09:51,978 --> 00:09:55,283
d'ouverture, et se souvenaient plutôt de choses comme la façon de quantifier les 

195
00:09:55,283 --> 00:09:58,433
informations, ou le fait que vous devriez faire attention lorsqu'un gourmand 

196
00:09:58,433 --> 00:10:01,777
L’algorithme n’atteint pas les meilleures performances mondiales que vous obtiendriez 

197
00:10:01,777 --> 00:10:03,100
d’une recherche plus approfondie. 

198
00:10:03,700 --> 00:10:07,210
À mon goût du moins, la joie d’écrire des algorithmes pour essayer de jouer à des jeux a 

199
00:10:07,210 --> 00:10:10,760
en réalité très peu d’impact sur la façon dont j’aime jouer à ces jeux en tant qu’humain. 

200
00:10:11,300 --> 00:10:14,000
Le but d’écrire des algorithmes pour tout cela n’est pas d’affecter 

201
00:10:14,000 --> 00:10:16,780
la façon dont nous jouons au jeu, c’est juste un jeu de mots amusant. 

202
00:10:17,100 --> 00:10:18,831
Il s’agit de perfectionner nos muscles pour écrire des 

203
00:10:18,831 --> 00:10:20,720
algorithmes dans des contextes plus significatifs ailleurs. 

