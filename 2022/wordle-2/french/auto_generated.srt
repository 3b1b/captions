1
00:00:00,000 --> 00:00:04,800
La semaine dernière, j&#39;ai mis en ligne cette vidéo sur la résolution du jeu Wordle, ou du moins sur la tentative de le résoudre,

2
00:00:04,800 --> 00:00:09,920
en utilisant la théorie de l&#39;information. Et je voulais ajouter un rapide, comment devrions-nous appeler cela, un addendum,

3
00:00:09,920 --> 00:00:14,240
une confession, en gros, je veux juste expliquer un endroit où j&#39;ai fait une erreur.

4
00:00:14,240 --> 00:00:18,880
Il s&#39;avère qu&#39;il y avait un très léger bug dans le code que j&#39;exécutais pour recréer Wordle,

5
00:00:18,880 --> 00:00:23,040
puis exécuter tous les algorithmes pour le résoudre et tester leurs performances. Et c&#39;est un de ces

6
00:00:23,040 --> 00:00:27,760
bugs qui affectent un très petit pourcentage de cas, donc il était facile de le rater, et il

7
00:00:27,760 --> 00:00:32,080
n&#39;a qu&#39;un très léger effet qui, pour la plupart, n&#39;a pas vraiment d&#39;importance. Fondamentalement, cela concernait la

8
00:00:32,080 --> 00:00:36,880
façon dont vous attribuiez une couleur à une supposition contenant plusieurs lettres différentes. Par exemple, si vous

9
00:00:36,880 --> 00:00:42,080
devinez la vitesse et que la vraie réponse est respecter, comment devriez-vous colorier ces deux e à partir de la supposition ?

10
00:00:42,800 --> 00:00:46,640
Eh bien, la façon dont cela fonctionne avec les conventions Wordle est que le premier e serait de couleur

11
00:00:46,640 --> 00:00:51,120
jaune et le second serait de couleur grise. Vous pourriez penser que le premier correspond à quelque

12
00:00:51,120 --> 00:00:56,000
chose de la vraie réponse, et le gris vous indique qu&#39;il n&#39;y a pas de deuxième e.

13
00:00:56,000 --> 00:01:01,200
En revanche, si la réponse était quelque chose comme effacer, ces deux e seraient de couleur jaune, vous indiquant

14
00:01:01,200 --> 00:01:05,920
qu&#39;il y a un premier e à un endroit différent, et qu&#39;il y a un deuxième e également à

15
00:01:05,920 --> 00:01:10,960
un endroit différent. De même, si l&#39;un des e arrive et qu&#39;il est vert, alors ce deuxième sera gris dans le

16
00:01:10,960 --> 00:01:17,280
cas où la vraie réponse n&#39;a pas de deuxième e, mais il sera jaune dans le cas où il y a

17
00:01:17,280 --> 00:01:21,920
un deuxième e et il est juste dans un autre e. emplacement. Pour faire court, quelque part en

18
00:01:21,920 --> 00:01:26,240
cours de route, j&#39;ai accidentellement introduit un comportement qui diffère légèrement de ces conventions.

19
00:01:26,960 --> 00:01:31,680
Honnêtement, c&#39;était vraiment stupide. Fondamentalement, à un moment donné au milieu du projet, je voulais accélérer

20
00:01:31,680 --> 00:01:35,840
certains calculs, et j&#39;essayais une petite astuce pour calculer la valeur de ce modèle entre une paire

21
00:01:35,840 --> 00:01:40,640
de mots donnée, et vous savez, je l&#39;ai juste fait. Je n’y ai pas vraiment réfléchi

22
00:01:40,640 --> 00:01:45,600
et cela a introduit ce léger changement. L&#39;ironie est qu&#39;en fin de compte, la véritable manière d&#39;accélérer

23
00:01:45,600 --> 00:01:50,080
les choses est de pré-calculer tous ces modèles afin que tout ne soit qu&#39;une recherche, et donc

24
00:01:50,080 --> 00:01:54,000
le temps qu&#39;il faut pour faire chacun d&#39;eux n&#39;a pas d&#39;importance, surtout si vous J&#39;écris du code

25
00:01:54,000 --> 00:01:59,040
bogué pour que cela se produise. Vous savez, vous vivez et vous apprenez. En ce qui concerne la façon dont

26
00:01:59,040 --> 00:02:03,760
cela affecte la vidéo elle-même, je veux dire que très peu de choses changent réellement. Bien sûr, les principales leçons sur

27
00:02:03,760 --> 00:02:08,160
ce qu’est l’information, ce qu’est l’entropie, tout cela reste le même. De temps en temps, si j&#39;affiche

28
00:02:08,160 --> 00:02:13,360
à l&#39;écran une distribution associée à un mot donné, cette distribution peut en fait être

29
00:02:13,360 --> 00:02:18,000
un peu erronée car certains des compartiments associés à divers modèles devraient inclure plus

30
00:02:18,000 --> 00:02:22,960
ou moins de vraies réponses. Même dans ce cas, cela n&#39;apparaît pas vraiment car il était très

31
00:02:22,960 --> 00:02:28,400
rare que je montre un mot comportant plusieurs lettres qui touchaient également ce cas limite. Mais l&#39;une des

32
00:02:28,400 --> 00:02:33,680
très rares choses de fond qui change et qui compte sans doute assez peu est la conclusion finale

33
00:02:33,680 --> 00:02:40,240
sur la façon dont si nous voulons trouver le score optimal possible pour la liste de réponses de mots,

34
00:02:40,240 --> 00:02:45,120
quelle hypothèse d&#39;ouverture un tel algorithme utilise-t-il ? Dans la vidéo, j&#39;ai dit que la meilleure performance que

35
00:02:45,120 --> 00:02:50,160
j&#39;avais pu trouver provenait d&#39;une ouverture avec le mot grue, ce qui n&#39;était vrai que dans le sens

36
00:02:50,160 --> 00:02:55,120
où les algorithmes jouaient à un jeu très légèrement différent. Après avoir corrigé le problème et réexécuté le

37
00:02:55,120 --> 00:03:00,000
tout, il existe une réponse différente quant à la première estimation théoriquement optimale pour cette liste particulière.

38
00:03:00,800 --> 00:03:06,560
Et écoutez, je sais que vous savez que le but de la vidéo n’est pas de trouver une réponse

39
00:03:06,560 --> 00:03:11,760
techniquement optimale à un jeu en ligne aléatoire. Le but de la vidéo est de suivre sans

40
00:03:11,760 --> 00:03:16,240
vergogne le mouvement d’Internet pour attaquer sournoisement les gens avec une leçon de théorie de l’information.

41
00:03:16,240 --> 00:03:20,160
Et tout va bien, je maintiens cette partie. Mais je sais comment fonctionne Internet, et pour beaucoup de gens, le

42
00:03:20,160 --> 00:03:26,160
principal point à retenir était de savoir quelle est la meilleure introduction au mot de jeu. Et je comprends, je suis

43
00:03:26,160 --> 00:03:30,480
entré là-dedans parce que je l&#39;ai mis dans la vignette, mais vous pouvez probablement me pardonner si je veux ajouter

44
00:03:30,480 --> 00:03:35,120
une petite correction ici. Et une raison plus significative de revenir sur tout cela est que je

45
00:03:35,120 --> 00:03:39,440
n’ai jamais vraiment parlé de ce qui est entré dans cette analyse finale. Et c&#39;est intéressant en tant

46
00:03:39,440 --> 00:03:44,560
que sous-leçon en soi, donc ça vaut la peine de le faire ici. Maintenant, si vous vous en souvenez bien, la

47
00:03:44,560 --> 00:03:49,120
plupart de notre temps dans la dernière vidéo a été consacré au défi consistant à essayer d&#39;écrire un algorithme pour résoudre

48
00:03:49,120 --> 00:03:54,320
des mots qui n&#39;utilisait pas la liste officielle de toutes les réponses possibles. À mon goût, cela ressemble un peu à un

49
00:03:54,320 --> 00:03:59,280
surajustement d&#39;un ensemble de test, et ce qui est plus amusant, c&#39;est de construire quelque chose de résilient. C&#39;est pourquoi nous

50
00:03:59,280 --> 00:04:03,920
avons suivi tout le processus d&#39;examen des fréquences relatives des mots dans la langue anglaise pour

51
00:04:03,920 --> 00:04:09,120
arriver à une idée de la probabilité que chacun d&#39;entre eux soit inclus comme réponse finale.

52
00:04:09,120 --> 00:04:13,680
Cependant, pour ce que nous faisons ici, où nous essayons simplement de trouver une période de

53
00:04:13,680 --> 00:04:19,120
performance optimale absolue, j&#39;incorpore cette liste officielle et je surajuste sans vergogne l&#39;ensemble de tests, c&#39;est-à-dire

54
00:04:19,120 --> 00:04:23,520
que nous savons avec certitude si un mot est inclus ou non, et nous pouvons attribuer

55
00:04:23,520 --> 00:04:28,560
une probabilité uniforme à chacun. Si vous vous en souvenez bien, la première étape dans tout cela était

56
00:04:28,560 --> 00:04:34,080
de dire, pour une supposition d&#39;ouverture particulière, peut-être quelque chose comme mon ancien favori, la grue, quelle est la

57
00:04:34,080 --> 00:04:38,560
probabilité que vous voyiez chacun des modèles possibles ? Et dans ce contexte, où nous surajustons sans vergogne

58
00:04:38,560 --> 00:04:43,440
la liste de réponses par mots, tout ce que cela implique est de compter combien de réponses

59
00:04:43,440 --> 00:04:48,240
possibles donnent chacun de ces modèles. Et bien sûr, la plupart de notre temps a été

60
00:04:48,240 --> 00:04:53,040
consacré à ce genre de formule amusante pour quantifier la quantité d&#39;informations que vous obtiendriez de cette

61
00:04:53,040 --> 00:04:57,520
supposition, ce qui implique essentiellement de parcourir chacun de ces compartiments et de dire quelle quantité d&#39;informations

62
00:04:57,520 --> 00:05:02,720
vous obtiendriez. cette expression de journal qui est une manière fantaisiste de dire combien de fois

63
00:05:02,720 --> 00:05:08,160
réduiriez-vous votre espace des possibilités de moitié si vous observiez un modèle donné. Nous prenons une moyenne pondérée

64
00:05:08,160 --> 00:05:12,800
de tous ces éléments et cela nous donne une mesure de ce que nous espérons apprendre de cette première

65
00:05:12,800 --> 00:05:17,920
estimation. Dans un instant, nous irons plus loin que cela, mais si vous recherchez simplement parmi les 13 000 mots différents avec

66
00:05:17,920 --> 00:05:22,880
lesquels vous pourriez commencer et que vous demandez lequel contient les informations attendues les plus élevées, il s&#39;avère que la meilleure

67
00:05:22,880 --> 00:05:28,400
réponse possible est planer, ce qui n&#39;est pas le cas. Cela ne ressemble pas vraiment à un vrai mot, mais je

68
00:05:28,400 --> 00:05:36,640
suppose que c&#39;est un terme obsolète pour désigner un bébé faucon. Les 15 premiers ouvreurs selon cette métrique ressemblent

69
00:05:36,640 --> 00:05:41,680
à ceci, mais ce ne sont pas nécessairement les meilleures suppositions d&#39;ouverture car ils ne

70
00:05:41,680 --> 00:05:46,960
regardent qu&#39;une étape dans l&#39;heuristique des informations attendues pour essayer d&#39;estimer quel sera le véritable

71
00:05:46,960 --> 00:05:52,000
score. Mais il existe suffisamment de modèles pour que nous puissions effectuer une recherche exhaustive en deux étapes.

72
00:05:52,000 --> 00:05:56,640
Par exemple, disons que vous avez ouvert avec Soar et que le motif que vous voyez est le plus probable,

73
00:05:56,640 --> 00:06:02,240
entièrement gris, vous pouvez alors exécuter une analyse identique à partir de ce point. Pour une seconde proposition donnée,

74
00:06:02,240 --> 00:06:07,360
quelque chose comme Kitty, quelle est la distribution entre tous les modèles dans ce cas restreint où

75
00:06:07,360 --> 00:06:11,920
nous sommes limités uniquement aux mots qui produiraient tous les gris pour monter en flèche, puis nous mesurons

76
00:06:11,920 --> 00:06:17,440
la planéité de cette distribution en utilisant cette valeur attendue. formule d&#39;information, et nous le faisons pour les

77
00:06:17,440 --> 00:06:23,680
13 000 mots possibles que nous pourrions utiliser comme seconde hypothèse. En faisant cela, nous pouvons trouver

78
00:06:23,680 --> 00:06:28,080
la seconde estimation optimale dans ce scénario et la quantité d&#39;informations que nous étions censés en tirer,

79
00:06:28,640 --> 00:06:32,880
et si nous lavons, rinçons et répétons et faisons cela pour tous les différents modèles possibles que vous

80
00:06:32,880 --> 00:06:37,680
pourriez voir, nous obtenons un carte complète de toutes les meilleures secondes hypothèses possibles ainsi que les

81
00:06:37,680 --> 00:06:46,640
informations attendues de chacune. À partir de là, si vous faites une moyenne pondérée de toutes ces valeurs de

82
00:06:46,640 --> 00:06:51,760
deuxième étape, pondérée en fonction de la probabilité que vous tombiez dans ce seau, cela vous donne une mesure de

83
00:06:51,760 --> 00:06:57,440
la quantité d&#39;informations que vous êtes susceptible d&#39;obtenir de la montée en flèche des suppositions après le deuxième étape. Lorsque nous

84
00:06:57,440 --> 00:07:02,400
utilisons cette métrique en deux étapes comme nouveau moyen de classement, la liste est un peu bouleversée. Soar n&#39;est

85
00:07:02,400 --> 00:07:09,040
plus la première place, il retombe à la 14ème place, et à la place, ce qui monte au sommet est tué. Encore une

86
00:07:09,040 --> 00:07:16,000
fois, cela ne semble pas très réel, et il semble que ce soit un terme britannique désignant une pelle utilisée pour couper le gazon.

87
00:07:16,000 --> 00:07:22,320
D&#39;accord, mais comme vous pouvez le constater, la course est très serrée entre tous ces principaux prétendants pour

88
00:07:22,320 --> 00:07:27,600
savoir qui obtient le plus d&#39;informations après ces deux étapes. Et même quand même, ce ne sont pas

89
00:07:27,600 --> 00:07:32,000
nécessairement les meilleures hypothèses de départ, car l’information n’est qu’une heuristique, elle ne nous indique pas le

90
00:07:32,000 --> 00:07:37,120
score réel si vous jouez réellement au jeu. Ce que j&#39;ai fait, c&#39;est que j&#39;ai exécuté la simulation consistant à

91
00:07:37,120 --> 00:07:44,400
jouer à tous les 2315 jeux de mots possibles avec toutes les réponses possibles parmi les 250 premières de cette liste.

92
00:07:46,160 --> 00:07:51,120
Et en faisant cela, en voyant comment ils se comportent réellement, celui qui obtient très marginalement

93
00:07:51,120 --> 00:08:03,280
le meilleur score possible s&#39;avère être Salé, qui est une orthographe alternative pour Salé, qui

94
00:08:04,240 --> 00:08:10,080
est un casque médiéval léger. Très bien, si cela vous semble un peu trop faux, ce qui

95
00:08:10,080 --> 00:08:15,760
est le cas pour moi, vous serez heureux de savoir que Trace et Crate offrent des performances presque identiques.

96
00:08:16,240 --> 00:08:21,040
Chacun d’eux a l’avantage d’être évidemment un vrai mot, il y a donc un jour où vous réussissez dès

97
00:08:21,040 --> 00:08:26,480
la première hypothèse, puisque les deux sont de véritables réponses de mots. Ce passage d’un tri basé sur les

98
00:08:26,480 --> 00:08:31,200
meilleures entropies en deux étapes à un tri basé sur le score moyen le plus bas bouleverse également la

99
00:08:31,200 --> 00:08:36,000
liste, mais pas autant. Par exemple, Salé occupait auparavant la troisième place avant d&#39;atteindre le sommet, et

100
00:08:36,000 --> 00:08:41,200
Crate et Trace étaient tous deux quatrième et cinquième. Si vous êtes curieux, vous pouvez obtenir des performances

101
00:08:41,200 --> 00:08:45,120
légèrement meilleures à partir d&#39;ici en effectuant un petit forçage brutal. Il existe un très bel article de

102
00:08:45,120 --> 00:08:49,600
blog de Jonathan Olson, si vous êtes curieux à ce sujet, dans lequel il vous permet également d&#39;explorer

103
00:08:49,600 --> 00:08:53,600
quelles sont les suppositions suivantes optimales pour quelques-uns des mots de départ basés sur ces algorithmes optimaux.

104
00:08:55,040 --> 00:08:59,040
En prenant du recul par rapport à tout cela, certaines personnes me disent que cela ruine

105
00:08:59,040 --> 00:09:03,920
le jeu de le suranalyser comme ça et d&#39;essayer de trouver une supposition d&#39;ouverture optimale.

106
00:09:03,920 --> 00:09:07,680
Vous savez, cela semble un peu sale si vous utilisez cette supposition d&#39;ouverture après l&#39;avoir apprise, et cela semble

107
00:09:07,680 --> 00:09:12,400
inefficace si vous ne le faites pas. Mais le fait est que je ne pense pas vraiment que ce soit la meilleure

108
00:09:12,400 --> 00:09:16,880
ouverture pour un humain jouant à ce jeu. D’une part, vous auriez besoin de savoir quelle est la seconde

109
00:09:16,880 --> 00:09:22,160
estimation optimale pour chacun des modèles que vous voyez. Et plus important encore, tout cela se déroule dans

110
00:09:22,160 --> 00:09:27,440
un contexte où nous sommes absurdement suradaptés à la liste de réponses officielle des mots. Au moment où, disons,

111
00:09:27,440 --> 00:09:32,240
le New York Times choisit de modifier le contenu de cette liste, tout cela disparaîtrait par

112
00:09:32,240 --> 00:09:36,720
la fenêtre. La façon dont nous, les humains, jouons au jeu est tout simplement très différente de ce que font n’importe

113
00:09:36,720 --> 00:09:41,440
lequel de ces algorithmes. Nous n&#39;avons pas mémorisé la liste de mots, nous ne faisons pas de recherches exhaustives,

114
00:09:41,440 --> 00:09:45,520
nous obtenons des intuitions à partir de choses comme quelles sont les voyelles et comment sont-elles placées.

115
00:09:45,520 --> 00:09:50,080
Je serais en fait très heureux si ceux d&#39;entre vous qui regardent cette vidéo oubliaient rapidement

116
00:09:50,080 --> 00:09:54,880
ce qui se trouve être techniquement la meilleure hypothèse d&#39;ouverture, et se souvenaient plutôt de choses

117
00:09:54,880 --> 00:09:59,440
comme la façon de quantifier les informations, ou le fait que vous devriez faire attention lorsqu&#39;un

118
00:09:59,440 --> 00:10:02,960
gourmand L’algorithme n’atteint pas les meilleures performances mondiales que vous obtiendriez d’une recherche plus approfondie.

119
00:10:03,520 --> 00:10:07,920
À mon goût du moins, la joie d’écrire des algorithmes pour essayer de jouer à des jeux a en réalité très peu

120
00:10:07,920 --> 00:10:12,800
d’impact sur la façon dont j’aime jouer à ces jeux en tant qu’humain. Le but d’écrire des algorithmes pour tout cela

121
00:10:12,800 --> 00:10:17,280
n’est pas d’affecter la façon dont nous jouons au jeu, c’est juste un jeu de mots amusant. Il

122
00:10:17,280 --> 00:10:22,160
s’agit de perfectionner nos muscles pour écrire des algorithmes dans des contextes plus significatifs ailleurs.

123
00:10:37,920 --> 00:10:38,420
you

