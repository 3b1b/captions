1
00:00:00,000 --> 00:00:03,055
La semaine dernière, j&#39;ai mis en ligne cette vidéo sur la résolution du jeu Wordle,

2
00:00:03,055 --> 00:00:05,556
ou du moins sur la tentative de le résoudre, en utilisant la théorie de

3
00:00:05,556 --> 00:00:06,216
l&#39;information.

4
00:00:06,216 --> 00:00:09,920
Et je voulais ajouter un rapide, comment devrions-nous appeler cela, un addendum ?

5
00:00:09,920 --> 00:00:10,685
Une confession?

6
00:00:10,685 --> 00:00:14,240
En gros, je veux juste expliquer un endroit où j&#39;ai commis une erreur.

7
00:00:14,240 --> 00:00:16,914
Il s&#39;avère qu&#39;il y avait un très léger bug dans le code

8
00:00:16,914 --> 00:00:19,422
que j&#39;exécutais pour recréer Wordle, puis exécuter tous

9
00:00:19,422 --> 00:00:22,055
les algorithmes pour le résoudre et tester leurs performances.

10
00:00:22,055 --> 00:00:25,043
Et c&#39;est un de ces bugs qui affectent un très petit pourcentage de

11
00:00:25,043 --> 00:00:27,904
cas, donc il était facile de le rater, et il n&#39;a qu&#39;un très

12
00:00:27,904 --> 00:00:30,976
léger effet qui, pour la plupart, n&#39;a pas vraiment d&#39;importance.

13
00:00:30,976 --> 00:00:33,619
Fondamentalement, cela concernait la façon dont vous attribuiez une

14
00:00:33,619 --> 00:00:36,223
couleur à une supposition contenant plusieurs lettres différentes.

15
00:00:36,223 --> 00:00:39,328
Par exemple, si vous devinez la vitesse et que la vraie réponse est respecter,

16
00:00:39,328 --> 00:00:42,080
comment devriez-vous colorier ces deux e à partir de la supposition ?

17
00:00:42,080 --> 00:00:45,491
Eh bien, la façon dont cela fonctionne avec les conventions Wordle est que

18
00:00:45,491 --> 00:00:48,902
le premier e serait de couleur jaune et le second serait de couleur grise.

19
00:00:48,902 --> 00:00:52,523
Vous pourriez penser que le premier correspond à quelque chose de la vraie

20
00:00:52,523 --> 00:00:56,000
réponse, et le gris vous indique qu&#39;il n&#39;y a pas de deuxième e.

21
00:00:56,000 --> 00:00:59,466
En revanche, si la réponse était quelque chose comme effacer, ces deux e

22
00:00:59,466 --> 00:01:02,980
seraient de couleur jaune, vous indiquant qu&#39;il y a un premier e à un

23
00:01:02,980 --> 00:01:06,970
endroit différent, et qu&#39;il y a un deuxième e également à un endroit différent.

24
00:01:06,970 --> 00:01:11,258
De même, si l&#39;un des e arrive et qu&#39;il est vert, alors ce deuxième sera

25
00:01:11,258 --> 00:01:15,706
gris dans le cas où la vraie réponse n&#39;a pas de deuxième e, mais il sera jaune

26
00:01:15,706 --> 00:01:20,102
dans le cas où il y a un deuxième e et il est juste dans un autre e. emplacement.

27
00:01:20,102 --> 00:01:23,319
Pour faire court, quelque part en cours de route, j&#39;ai accidentellement

28
00:01:23,319 --> 00:01:26,240
introduit un comportement qui diffère légèrement de ces conventions.

29
00:01:26,240 --> 00:01:28,416
Honnêtement, c&#39;était vraiment stupide.

30
00:01:28,416 --> 00:01:32,036
Fondamentalement, à un moment donné au milieu du projet, je voulais accélérer

31
00:01:32,036 --> 00:01:35,657
certains calculs, et j&#39;essayais une petite astuce pour calculer la valeur

32
00:01:35,657 --> 00:01:39,277
de ce modèle entre une paire de mots donnée, et vous savez, je l&#39;ai juste

33
00:01:39,277 --> 00:01:42,944
fait. Je n’y ai pas vraiment réfléchi et cela a introduit ce léger changement.

34
00:01:42,944 --> 00:01:46,211
L&#39;ironie est qu&#39;en fin de compte, la véritable manière d&#39;accélérer les

35
00:01:46,211 --> 00:01:49,242
choses est de pré-calculer tous ces modèles afin que tout ne soit qu&#39;une

36
00:01:49,242 --> 00:01:52,509
recherche, et donc le temps qu&#39;il faut pour faire chacun d&#39;eux n&#39;a pas

37
00:01:52,509 --> 00:01:55,934
d&#39;importance, surtout si vous J&#39;écris du code bogué pour que cela se produise.

38
00:01:55,934 --> 00:01:57,665
Vous savez, vous vivez et vous apprenez.

39
00:01:57,665 --> 00:02:00,091
En ce qui concerne la façon dont cela affecte la vidéo elle-même,

40
00:02:00,091 --> 00:02:02,186
je veux dire que très peu de choses changent réellement.

41
00:02:02,186 --> 00:02:04,097
Bien sûr, les principales leçons sur ce qu’est

42
00:02:04,097 --> 00:02:06,617
l’information, ce qu’est l’entropie, tout cela reste le même.

43
00:02:06,617 --> 00:02:11,049
De temps en temps, si j&#39;affiche à l&#39;écran une distribution associée à un mot

44
00:02:11,049 --> 00:02:15,741
donné, cette distribution peut en fait être un peu erronée car certains des compartiments

45
00:02:15,741 --> 00:02:19,808
associés à divers modèles devraient inclure plus ou moins de vraies réponses.

46
00:02:19,808 --> 00:02:23,750
Même dans ce cas, cela n&#39;apparaît pas vraiment car il était très rare que je

47
00:02:23,750 --> 00:02:27,789
montre un mot comportant plusieurs lettres qui touchaient également ce cas limite.

48
00:02:27,789 --> 00:02:31,440
Mais l&#39;une des très rares choses de fond qui change et qui compte

49
00:02:31,440 --> 00:02:35,195
sans doute assez peu est la conclusion finale sur la façon dont si nous

50
00:02:35,195 --> 00:02:38,898
voulons trouver le score optimal possible pour la liste de réponses de

51
00:02:38,898 --> 00:02:42,654
mots, quelle hypothèse d&#39;ouverture un tel algorithme utilise-t-il ?

52
00:02:42,654 --> 00:02:45,951
Dans la vidéo, j&#39;ai dit que la meilleure performance que j&#39;avais pu

53
00:02:45,951 --> 00:02:49,423
trouver provenait d&#39;une ouverture avec le mot grue, ce qui n&#39;était vrai

54
00:02:49,423 --> 00:02:52,937
que dans le sens où les algorithmes jouaient à un jeu très légèrement différent.

55
00:02:52,937 --> 00:02:56,509
Après avoir corrigé le problème et réexécuté le tout, il existe une réponse différente

56
00:02:56,509 --> 00:03:00,000
quant à la première estimation théoriquement optimale pour cette liste particulière.

57
00:03:00,000 --> 00:03:04,425
Et écoutez, je sais que vous savez que le but de la vidéo n’est pas de

58
00:03:04,425 --> 00:03:08,913
trouver une réponse techniquement optimale à un jeu en ligne aléatoire.

59
00:03:08,913 --> 00:03:12,576
Le but de la vidéo est de suivre sans vergogne le mouvement d’Internet pour

60
00:03:12,576 --> 00:03:16,240
attaquer sournoisement les gens avec une leçon de théorie de l’information.

61
00:03:16,240 --> 00:03:18,014
Et tout va bien, je maintiens cette partie.

62
00:03:18,014 --> 00:03:21,342
Mais je sais comment fonctionne Internet, et pour beaucoup de gens, le principal

63
00:03:21,342 --> 00:03:24,793
point à retenir était de savoir quelle est la meilleure introduction au mot de jeu.

64
00:03:24,793 --> 00:03:28,182
Et je comprends, je suis entré là-dedans parce que je l&#39;ai mis dans la vignette,

65
00:03:28,182 --> 00:03:31,731
mais vous pouvez probablement me pardonner si je veux ajouter une petite correction ici.

66
00:03:31,731 --> 00:03:34,980
Et une raison plus significative de revenir sur tout cela est que je

67
00:03:34,980 --> 00:03:38,464
n’ai jamais vraiment parlé de ce qui est entré dans cette analyse finale.

68
00:03:38,464 --> 00:03:40,598
Et c&#39;est intéressant en tant que sous-leçon

69
00:03:40,598 --> 00:03:42,688
en soi, donc ça vaut la peine de le faire ici.

70
00:03:42,688 --> 00:03:45,853
Maintenant, si vous vous en souvenez bien, la plupart de notre temps dans la dernière

71
00:03:45,853 --> 00:03:48,871
vidéo a été consacré au défi consistant à essayer d&#39;écrire un algorithme pour

72
00:03:48,871 --> 00:03:51,999
résoudre des mots qui n&#39;utilisait pas la liste officielle de toutes les réponses

73
00:03:51,999 --> 00:03:52,404
possibles.

74
00:03:52,404 --> 00:03:55,541
À mon goût, cela ressemble un peu à un surajustement d&#39;un ensemble de test,

75
00:03:55,541 --> 00:03:58,678
et ce qui est plus amusant, c&#39;est de construire quelque chose de résilient.

76
00:03:58,678 --> 00:04:01,930
C&#39;est pourquoi nous avons suivi tout le processus d&#39;examen des

77
00:04:01,930 --> 00:04:05,502
fréquences relatives des mots dans la langue anglaise pour arriver à une idée

78
00:04:05,502 --> 00:04:09,120
de la probabilité que chacun d&#39;entre eux soit inclus comme réponse finale.

79
00:04:09,120 --> 00:04:12,943
Cependant, pour ce que nous faisons ici, où nous essayons simplement de trouver une

80
00:04:12,943 --> 00:04:16,857
période de performance optimale absolue, j&#39;incorpore cette liste officielle et je

81
00:04:16,857 --> 00:04:20,816
surajuste sans vergogne l&#39;ensemble de tests, c&#39;est-à-dire que nous savons avec

82
00:04:20,816 --> 00:04:24,912
certitude si un mot est inclus ou non, et nous pouvons attribuer une probabilité uniforme

83
00:04:24,912 --> 00:04:25,368
à chacun.

84
00:04:25,368 --> 00:04:29,052
Si vous vous en souvenez bien, la première étape dans tout cela était de dire, pour une

85
00:04:29,052 --> 00:04:32,527
supposition d&#39;ouverture particulière, peut-être quelque chose comme mon ancien

86
00:04:32,527 --> 00:04:36,295
favori, la grue, quelle est la probabilité que vous voyiez chacun des modèles possibles ?

87
00:04:36,295 --> 00:04:39,397
Et dans ce contexte, où nous surajustons sans vergogne la liste

88
00:04:39,397 --> 00:04:42,451
de réponses par mots, tout ce que cela implique est de compter

89
00:04:42,451 --> 00:04:45,408
combien de réponses possibles donnent chacun de ces modèles.

90
00:04:45,408 --> 00:04:49,198
Et bien sûr, la plupart de notre temps a été consacré à ce genre de formule amusante

91
00:04:49,198 --> 00:04:52,633
pour quantifier la quantité d&#39;informations que vous obtiendriez de cette

92
00:04:52,633 --> 00:04:56,468
supposition, ce qui implique essentiellement de parcourir chacun de ces compartiments

93
00:04:56,468 --> 00:05:00,081
et de dire quelle quantité d&#39;informations vous obtiendriez. cette expression

94
00:05:00,081 --> 00:05:03,738
de journal qui est une manière fantaisiste de dire combien de fois réduiriez-vous

95
00:05:03,738 --> 00:05:07,083
votre espace des possibilités de moitié si vous observiez un modèle donné.

96
00:05:07,083 --> 00:05:10,100
Nous prenons une moyenne pondérée de tous ces éléments et cela nous donne

97
00:05:10,100 --> 00:05:13,158
une mesure de ce que nous espérons apprendre de cette première estimation.

98
00:05:13,158 --> 00:05:17,076
Dans un instant, nous irons plus loin que cela, mais si vous recherchez simplement parmi

99
00:05:17,076 --> 00:05:20,862
les 13 000 mots différents avec lesquels vous pourriez commencer et que vous demandez

100
00:05:20,862 --> 00:05:24,515
lequel contient les informations attendues les plus élevées, il s&#39;avère que la

101
00:05:24,515 --> 00:05:28,477
meilleure réponse possible est planer, ce qui n&#39;est pas le cas. Cela ne ressemble pas

102
00:05:28,477 --> 00:05:32,395
vraiment à un vrai mot, mais je suppose que c&#39;est un terme obsolète pour désigner un

103
00:05:32,395 --> 00:05:32,967
bébé faucon.

104
00:05:32,967 --> 00:05:36,515
Les 15 premiers ouvreurs selon cette métrique ressemblent à ceci, mais

105
00:05:36,515 --> 00:05:40,213
ce ne sont pas nécessairement les meilleures suppositions d&#39;ouverture

106
00:05:40,213 --> 00:05:44,110
car ils ne regardent qu&#39;une étape dans l&#39;heuristique des informations

107
00:05:44,110 --> 00:05:47,458
attendues pour essayer d&#39;estimer quel sera le véritable score.

108
00:05:47,458 --> 00:05:49,569
Mais il existe suffisamment de modèles pour que nous

109
00:05:49,569 --> 00:05:52,000
puissions effectuer une recherche exhaustive en deux étapes.

110
00:05:52,000 --> 00:05:54,823
Par exemple, disons que vous avez ouvert avec Soar et que le

111
00:05:54,823 --> 00:05:57,878
motif que vous voyez est le plus probable, entièrement gris, vous

112
00:05:57,878 --> 00:06:00,933
pouvez alors exécuter une analyse identique à partir de ce point.

113
00:06:00,933 --> 00:06:04,352
Pour une seconde proposition donnée, quelque chose comme Kitty, quelle est

114
00:06:04,352 --> 00:06:07,817
la distribution entre tous les modèles dans ce cas restreint où nous sommes

115
00:06:07,817 --> 00:06:11,190
limités uniquement aux mots qui produiraient tous les gris pour monter en

116
00:06:11,190 --> 00:06:14,563
flèche, puis nous mesurons la planéité de cette distribution en utilisant

117
00:06:14,563 --> 00:06:17,937
cette valeur attendue. formule d&#39;information, et nous le faisons pour

118
00:06:17,937 --> 00:06:21,538
les 13 000 mots possibles que nous pourrions utiliser comme seconde hypothèse.

119
00:06:21,538 --> 00:06:25,490
En faisant cela, nous pouvons trouver la seconde estimation optimale dans ce scénario

120
00:06:25,490 --> 00:06:29,074
et la quantité d&#39;informations que nous étions censés en tirer, et si nous

121
00:06:29,074 --> 00:06:32,611
lavons, rinçons et répétons et faisons cela pour tous les différents modèles

122
00:06:32,611 --> 00:06:36,287
possibles que vous pourriez voir, nous obtenons un carte complète de toutes les

123
00:06:36,287 --> 00:06:40,422
meilleures secondes hypothèses possibles ainsi que les informations attendues de chacune.

124
00:06:40,422 --> 00:06:44,792
À partir de là, si vous faites une moyenne pondérée de toutes ces valeurs de deuxième

125
00:06:44,792 --> 00:06:48,958
étape, pondérée en fonction de la probabilité que vous tombiez dans ce seau, cela

126
00:06:48,958 --> 00:06:53,124
vous donne une mesure de la quantité d&#39;informations que vous êtes susceptible

127
00:06:53,124 --> 00:06:57,137
d&#39;obtenir de la montée en flèche des suppositions après le deuxième étape.

128
00:06:57,137 --> 00:06:59,502
Lorsque nous utilisons cette métrique en deux étapes comme

129
00:06:59,502 --> 00:07:01,986
nouveau moyen de classement, la liste est un peu bouleversée.

130
00:07:01,986 --> 00:07:05,130
Soar n&#39;est plus la première place, il retombe à la

131
00:07:05,130 --> 00:07:08,560
14ème place, et à la place, ce qui monte au sommet est tué.

132
00:07:08,560 --> 00:07:12,473
Encore une fois, cela ne semble pas très réel, et il semble que ce soit

133
00:07:12,473 --> 00:07:16,386
un terme britannique désignant une pelle utilisée pour couper le gazon.

134
00:07:16,386 --> 00:07:19,260
D&#39;accord, mais comme vous pouvez le constater, la course

135
00:07:19,260 --> 00:07:22,369
est très serrée entre tous ces principaux prétendants pour savoir

136
00:07:22,369 --> 00:07:25,290
qui obtient le plus d&#39;informations après ces deux étapes.

137
00:07:25,290 --> 00:07:28,240
Et même quand même, ce ne sont pas nécessairement les meilleures

138
00:07:28,240 --> 00:07:31,235
hypothèses de départ, car l’information n’est qu’une heuristique,

139
00:07:31,235 --> 00:07:34,503
elle ne nous indique pas le score réel si vous jouez réellement au jeu.

140
00:07:34,503 --> 00:07:37,818
Ce que j&#39;ai fait, c&#39;est que j&#39;ai exécuté la simulation

141
00:07:37,818 --> 00:07:40,936
consistant à jouer à tous les 2315 jeux de mots possibles avec

142
00:07:40,936 --> 00:07:44,400
toutes les réponses possibles parmi les 250 premières de cette liste.

143
00:07:44,400 --> 00:07:51,703
Et en faisant cela, en voyant comment ils se comportent réellement, celui qui

144
00:07:51,703 --> 00:07:58,912
obtient très marginalement le meilleur score possible s&#39;avère être Salé,

145
00:07:58,912 --> 00:08:06,496
qui est une orthographe alternative pour Salé, qui est un casque médiéval léger.

146
00:08:06,496 --> 00:08:10,964
Très bien, si cela vous semble un peu trop faux, ce qui est le cas pour moi, vous

147
00:08:10,964 --> 00:08:15,760
serez heureux de savoir que Trace et Crate offrent des performances presque identiques.

148
00:08:15,760 --> 00:08:20,037
Chacun d’eux a l’avantage d’être évidemment un vrai mot, il y a donc un jour où vous

149
00:08:20,037 --> 00:08:24,364
réussissez dès la première hypothèse, puisque les deux sont de véritables réponses de

150
00:08:24,364 --> 00:08:24,666
mots.

151
00:08:24,666 --> 00:08:28,641
Ce passage d’un tri basé sur les meilleures entropies en deux étapes à un tri basé

152
00:08:28,641 --> 00:08:32,425
sur le score moyen le plus bas bouleverse également la liste, mais pas autant.

153
00:08:32,425 --> 00:08:35,868
Par exemple, Salé occupait auparavant la troisième place avant d&#39;atteindre

154
00:08:35,868 --> 00:08:38,963
le sommet, et Crate et Trace étaient tous deux quatrième et cinquième.

155
00:08:38,963 --> 00:08:41,378
Si vous êtes curieux, vous pouvez obtenir des performances légèrement

156
00:08:41,378 --> 00:08:43,758
meilleures à partir d&#39;ici en effectuant un petit forçage brutal.

157
00:08:43,758 --> 00:08:47,100
Il existe un très bel article de blog de Jonathan Olson, si vous êtes curieux à ce sujet,

158
00:08:47,100 --> 00:08:50,146
dans lequel il vous permet également d&#39;explorer quelles sont les suppositions

159
00:08:50,146 --> 00:08:53,228
suivantes optimales pour quelques-uns des mots de départ basés sur ces algorithmes

160
00:08:53,228 --> 00:08:53,600
optimaux.

161
00:08:53,600 --> 00:08:57,057
En prenant du recul par rapport à tout cela, certaines personnes

162
00:08:57,057 --> 00:09:00,355
me disent que cela ruine le jeu de le suranalyser comme ça et

163
00:09:00,355 --> 00:09:03,920
d&#39;essayer de trouver une supposition d&#39;ouverture optimale.

164
00:09:03,920 --> 00:09:06,885
Vous savez, cela semble un peu sale si vous utilisez cette supposition d&#39;ouverture

165
00:09:06,885 --> 00:09:09,577
après l&#39;avoir apprise, et cela semble inefficace si vous ne le faites pas.

166
00:09:09,577 --> 00:09:11,951
Mais le fait est que je ne pense pas vraiment que ce soit

167
00:09:11,951 --> 00:09:14,201
la meilleure ouverture pour un humain jouant à ce jeu.

168
00:09:14,201 --> 00:09:17,153
D’une part, vous auriez besoin de savoir quelle est la seconde

169
00:09:17,153 --> 00:09:19,964
estimation optimale pour chacun des modèles que vous voyez.

170
00:09:19,964 --> 00:09:23,164
Et plus important encore, tout cela se déroule dans un contexte où nous

171
00:09:23,164 --> 00:09:26,453
sommes absurdement suradaptés à la liste de réponses officielle des mots.

172
00:09:26,453 --> 00:09:29,683
Au moment où, disons, le New York Times choisit de modifier le

173
00:09:29,683 --> 00:09:32,964
contenu de cette liste, tout cela disparaîtrait par la fenêtre.

174
00:09:32,964 --> 00:09:35,353
La façon dont nous, les humains, jouons au jeu est tout simplement

175
00:09:35,353 --> 00:09:37,779
très différente de ce que font n’importe lequel de ces algorithmes.

176
00:09:37,779 --> 00:09:40,334
Nous n&#39;avons pas mémorisé la liste de mots, nous ne faisons pas

177
00:09:40,334 --> 00:09:42,889
de recherches exhaustives, nous obtenons des intuitions à partir de

178
00:09:42,889 --> 00:09:45,520
choses comme quelles sont les voyelles et comment sont-elles placées.

179
00:09:45,520 --> 00:09:48,705
Je serais en fait très heureux si ceux d&#39;entre vous qui regardent cette vidéo

180
00:09:48,705 --> 00:09:51,851
oubliaient rapidement ce qui se trouve être techniquement la meilleure hypothèse

181
00:09:51,851 --> 00:09:55,152
d&#39;ouverture, et se souvenaient plutôt de choses comme la façon de quantifier les

182
00:09:55,152 --> 00:09:58,298
informations, ou le fait que vous devriez faire attention lorsqu&#39;un gourmand

183
00:09:58,298 --> 00:10:01,639
L’algorithme n’atteint pas les meilleures performances mondiales que vous obtiendriez

184
00:10:01,639 --> 00:10:02,960
d’une recherche plus approfondie.

185
00:10:02,960 --> 00:10:06,952
À mon goût du moins, la joie d’écrire des algorithmes pour essayer de jouer à des jeux a

186
00:10:06,952 --> 00:10:10,988
en réalité très peu d’impact sur la façon dont j’aime jouer à ces jeux en tant qu’humain.

187
00:10:10,988 --> 00:10:13,972
Le but d’écrire des algorithmes pour tout cela n’est pas d’affecter

188
00:10:13,972 --> 00:10:17,044
la façon dont nous jouons au jeu, c’est juste un jeu de mots amusant.

189
00:10:17,044 --> 00:10:19,490
Il s’agit de perfectionner nos muscles pour écrire des

190
00:10:19,490 --> 00:10:22,160
algorithmes dans des contextes plus significatifs ailleurs.

