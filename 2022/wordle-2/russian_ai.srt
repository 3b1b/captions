1
00:00:00,000 --> 00:00:04,800
На прошлой неделе я разместил это видео о решении игры Wordle или, по крайней мере, о попытке ее

2
00:00:04,800 --> 00:00:09,920
решения, используя теорию информации. И я хотел добавить небольшое, как бы это назвать, дополнение,

3
00:00:09,920 --> 00:00:14,240
признание, по сути, я просто хочу объяснить место, где я допустил ошибку.

4
00:00:14,240 --> 00:00:18,880
Оказывается, в коде, который я использовал, чтобы воссоздать Wordle, а затем запустить все алгоритмы для

5
00:00:18,880 --> 00:00:23,040
ее устранения и проверить их производительность, была очень небольшая ошибка. И это одна из

6
00:00:23,040 --> 00:00:27,760
тех ошибок, которая затрагивает очень небольшой процент случаев, поэтому ее легко пропустить, и она имеет лишь

7
00:00:27,760 --> 00:00:32,080
очень незначительный эффект, который по большей части не имеет особого значения. По сути, это было связано

8
00:00:32,080 --> 00:00:36,880
с тем, как вы назначаете цвет предположению, в котором есть несколько разных букв. Например, если вы

9
00:00:36,880 --> 00:00:42,080
угадали скорость и правильный ответ — «соблюдать», как вам следует раскрасить эти две буквы «е», исходя из предположения?

10
00:00:42,800 --> 00:00:46,640
Что ж, в соответствии с соглашениями Wordle первая буква e будет окрашена в желтый

11
00:00:46,640 --> 00:00:51,120
цвет, а вторая — в серый. Вы можете подумать, что первый ответ соответствует

12
00:00:51,120 --> 00:00:56,000
чему-то из истинного ответа, а серый цвет говорит вам, что второго e нет.

13
00:00:56,000 --> 00:01:01,200
Напротив, если бы ответом было что-то вроде «стирание», обе эти «е» были бы окрашены в желтый

14
00:01:01,200 --> 00:01:05,920
цвет, сообщая вам, что первая «е» находится в другом месте, а вторая «е» также находится в

15
00:01:05,920 --> 00:01:10,960
другом месте. Аналогично, если один из символов e соответствует зеленому цвету, то второй будет серым в

16
00:01:10,960 --> 00:01:17,280
том случае, если у истинного ответа нет второго e, но он будет желтым в случае, когда есть

17
00:01:17,280 --> 00:01:21,920
второй e, но он находится в другом месте. расположение. Короче говоря, где-то по пути

18
00:01:21,920 --> 00:01:26,240
я случайно ввел поведение, которое немного отличается от этих соглашений.

19
00:01:26,960 --> 00:01:31,680
Честно говоря, это было очень глупо. По сути, в какой-то момент в середине проекта я захотел ускорить

20
00:01:31,680 --> 00:01:35,840
некоторые вычисления и попробовал небольшой трюк, позволяющий вычислить значение этого шаблона между любой заданной

21
00:01:35,840 --> 00:01:40,640
парой слов, и вы знаете, я просто не сделал этого. Я действительно не продумал

22
00:01:40,640 --> 00:01:45,600
это, и это внесло небольшое изменение. Ирония заключается в том, что, в конце концов, реальный

23
00:01:45,600 --> 00:01:50,080
способ ускорить работу — это предварительно вычислить все эти шаблоны, чтобы все было просто поиском, и не

24
00:01:50,080 --> 00:01:54,000
имело бы значения, сколько времени потребуется для выполнения каждого из них, особенно если вы пишем трудночитаемый

25
00:01:54,000 --> 00:01:59,040
код с ошибками, чтобы это произошло. Знаешь, ты живешь и учишься. Что касается того, как это влияет

26
00:01:59,040 --> 00:02:03,760
на реальное видео, я имею в виду, что на самом деле мало что меняется. Конечно, основные уроки о том,

27
00:02:03,760 --> 00:02:08,160
что такое информация, что такое энтропия, остаются прежними. Время от времени, если я показываю

28
00:02:08,160 --> 00:02:13,360
на экране некоторое распределение, связанное с данным словом, это распределение на самом деле может

29
00:02:13,360 --> 00:02:18,000
быть немного неправильным, потому что некоторые сегменты, связанные с различными шаблонами, должны включать больше

30
00:02:18,000 --> 00:02:22,960
или меньше правильных ответов. Даже тогда это на самом деле не возникает, потому что очень

31
00:02:22,960 --> 00:02:28,400
редко я показывал слово, состоящее из нескольких букв, которые также попадали в этот крайний регистр. Но одна

32
00:02:28,400 --> 00:02:33,680
из очень немногих существенных вещей, которая действительно меняется и, возможно, имеет немалое значение, — это

33
00:02:33,680 --> 00:02:40,240
окончательный вывод о том, как, если мы хотим найти оптимально возможный балл для списка ответов

34
00:02:40,240 --> 00:02:45,120
Wordle, какое начальное предположение использует такой алгоритм? В видео я сказал, что лучшая производительность, которую

35
00:02:45,120 --> 00:02:50,160
я смог найти, была получена при открытии со словом кран, что было правдой только в том

36
00:02:50,160 --> 00:02:55,120
смысле, что алгоритмы играли в немного другую игру. После исправления и повторного запуска всего этого

37
00:02:55,120 --> 00:03:00,000
появляется другой ответ на вопрос, какое теоретически оптимальное первое предположение является для этого конкретного списка.

38
00:03:00,800 --> 00:03:06,560
И послушайте, я знаю, что вы знаете, что цель видео не в том, чтобы найти какой-то

39
00:03:06,560 --> 00:03:11,760
технически оптимальный ответ на какую-то случайную онлайн-игру. Смысл видео в том, чтобы беззастенчиво вскочить

40
00:03:11,760 --> 00:03:16,240
на подножку интернет-тренда и тайно атаковать людей с помощью урока теории информации.

41
00:03:16,240 --> 00:03:20,160
И это все хорошо, я поддерживаю эту часть. Но я знаю, как работает Интернет, и для многих

42
00:03:20,160 --> 00:03:26,160
людей главным выводом было то, как лучше всего начать игру в слова. И я понимаю, я

43
00:03:26,160 --> 00:03:30,480
вошел в это, потому что поместил это в миниатюру, но, вероятно, вы простите меня, если я захочу

44
00:03:30,480 --> 00:03:35,120
добавить сюда небольшую поправку. И более весомая причина вернуться ко всему этому на самом деле заключается в том,

45
00:03:35,120 --> 00:03:39,440
что я никогда особо не говорил о том, что входило в этот окончательный анализ. И как подурок он

46
00:03:39,440 --> 00:03:44,560
интересен сам по себе, поэтому его стоит пройти здесь. Если вы помните, большая часть нашего

47
00:03:44,560 --> 00:03:49,120
времени в прошлом видео была потрачена на попытку написать алгоритм решения слов, который

48
00:03:49,120 --> 00:03:54,320
не использовал бы официальный список всех возможных ответов. На мой вкус, это немного похоже

49
00:03:54,320 --> 00:03:59,280
на переоснащение тестового набора, и что еще интереснее, это создавать что-то устойчивое. Вот почему

50
00:03:59,280 --> 00:04:03,920
мы прошли весь процесс изучения относительной частоты слов в английском языке, чтобы прийти к некоторому

51
00:04:03,920 --> 00:04:09,120
выводу о том, насколько вероятно, что каждое из них будет включено в окончательный ответ.

52
00:04:09,120 --> 00:04:13,680
Однако для того, что мы здесь делаем, когда мы просто пытаемся найти абсолютно лучший период производительности,

53
00:04:13,680 --> 00:04:19,120
я включаю этот официальный список и просто бесстыдно подгоняю его к тестовому набору, то есть

54
00:04:19,120 --> 00:04:23,520
мы с уверенностью знаем, является ли слово включен он или нет, и мы можем присвоить

55
00:04:23,520 --> 00:04:28,560
каждому из них равномерную вероятность. Если вы помните, первым шагом во всем этом было сказать

56
00:04:28,560 --> 00:04:34,080
для конкретного начального предположения, может быть, что-то вроде моего старого любимого журавля, насколько вероятно,

57
00:04:34,080 --> 00:04:38,560
что вы увидите каждую из возможных моделей? И в этом контексте, когда мы бессовестно подгоняем

58
00:04:38,560 --> 00:04:43,440
список ответов под слова, все, что для этого нужно, — это подсчитать, сколько возможных ответов

59
00:04:43,440 --> 00:04:48,240
дает каждый из этих шаблонов. И потом, конечно, большая часть нашего времени была потрачена на

60
00:04:48,240 --> 00:04:53,040
такого рода забавно выглядящую формулу для количественной оценки объема информации, которую вы получите из этого

61
00:04:53,040 --> 00:04:57,520
предположения, которое, по сути, включает в себя просмотр каждого из этих сегментов и определение того, сколько

62
00:04:57,520 --> 00:05:02,720
информации вы получите, если это логарифмическое выражение, представляющее собой причудливый способ определить, во сколько раз

63
00:05:02,720 --> 00:05:08,160
вы сократили бы свое пространство возможностей вдвое, если бы наблюдали заданную закономерность. Мы берем средневзвешенное значение

64
00:05:08,160 --> 00:05:12,800
всех этих показателей, и это дает нам представление о том, сколько мы ожидаем узнать из этого первого предположения.

65
00:05:12,800 --> 00:05:17,920
Через мгновение мы углубимся в это, но если вы просто проведете поиск по всем 13 000 различных слов,

66
00:05:17,920 --> 00:05:22,880
с которых вы могли бы начать, и спросите, какое из них имеет наиболее ожидаемую информацию, окажется, что лучший

67
00:05:22,880 --> 00:05:28,400
возможный ответ — «парить», что не так уж и важно. На самом деле это слово не похоже на настоящее,

68
00:05:28,400 --> 00:05:36,640
но я думаю, это устаревший термин для обозначения ястреба. Топ-15 первых игроков по этому показателю выглядят

69
00:05:36,640 --> 00:05:41,680
так, но это не обязательно лучшие начальные предположения, потому что они делают лишь один

70
00:05:41,680 --> 00:05:46,960
шаг вперед с помощью эвристики ожидаемой информации, чтобы попытаться оценить, каков будет истинный

71
00:05:46,960 --> 00:05:52,000
результат. Но шаблонов достаточно мало, чтобы мы могли провести исчерпывающий поиск за два шага.

72
00:05:52,000 --> 00:05:56,640
Например, предположим, что вы открылись с взлетом и фигура, которую вы увидели, была наиболее вероятной,

73
00:05:56,640 --> 00:06:02,240
все серые, тогда вы можете провести идентичный анализ с этой точки. Для данного предложенного второго

74
00:06:02,240 --> 00:06:07,360
предположения, например «котенок», каково распределение по всем шаблонам в этом ограниченном случае, когда мы ограничены только

75
00:06:07,360 --> 00:06:11,920
словами, которые дают все серые цвета для взлета, а затем мы измеряем равномерность этого распределения,

76
00:06:11,920 --> 00:06:17,440
используя это ожидаемое значение информационную формулу, и мы делаем это для всех 13 000 возможных

77
00:06:17,440 --> 00:06:23,680
слов, которые мы могли бы использовать в качестве второго предположения. Сделав это, мы можем найти оптимальное

78
00:06:23,680 --> 00:06:28,080
второе предположение в этом сценарии и объем информации, которую мы ожидали получить от него, и

79
00:06:28,640 --> 00:06:32,880
если мы промываем, промываем, повторяем и проделываем это для всех возможных шаблонов, которые вы

80
00:06:32,880 --> 00:06:37,680
можете увидеть, мы получим полная карта всех наилучших возможных вторых догадок вместе с ожидаемой информацией

81
00:06:37,680 --> 00:06:46,640
о каждой из них. Отсюда, если вы возьмете средневзвешенное значение всех этих значений второго шага,

82
00:06:46,640 --> 00:06:51,760
взвешенное в зависимости от того, насколько вероятно, что вы попадете в этот сегмент, это даст вам

83
00:06:51,760 --> 00:06:57,440
меру того, сколько информации вы, вероятно, получите от резкого увеличения предположений после второй шаг. Когда

84
00:06:57,440 --> 00:07:02,400
мы используем эту двухэтапную метрику в качестве нового средства ранжирования, список немного встряхивается. Соар больше

85
00:07:02,400 --> 00:07:09,040
не занимает первое место, он опускается на 14-е место, а вместо этого то, что поднимается на вершину, уничтожается. Опять же,

86
00:07:09,040 --> 00:07:16,000
это выглядит не очень реалистично и похоже, что это британский термин, обозначающий лопату, используемую для стрижки газона.

87
00:07:16,000 --> 00:07:22,320
Хорошо, но, как вы можете видеть, между всеми этими главными претендентами идет очень напряженная гонка за

88
00:07:22,320 --> 00:07:27,600
то, кто получит больше информации после этих двух шагов. И даже несмотря на это, это не обязательно

89
00:07:27,600 --> 00:07:32,000
лучшие начальные предположения, потому что информация — это всего лишь эвристика, она не сообщает нам реальный

90
00:07:32,000 --> 00:07:37,120
счет, если вы действительно играете в игру. Я запустил симуляцию игры во все 2315

91
00:07:37,120 --> 00:07:44,400
возможных словесных игр со всеми возможными ответами из 250 лучших из этого списка.

92
00:07:46,160 --> 00:07:51,120
И, сделав это, наблюдая, как они на самом деле работают, тот, который в конечном

93
00:07:51,120 --> 00:08:03,280
итоге набирает максимально возможный балл, оказывается Сале, что является альтернативным написанием Сале, который

94
00:08:04,240 --> 00:08:10,080
представляет собой легкий средневековый шлем. Хорошо, если вам это кажется слишком фальшивым, как мне

95
00:08:10,080 --> 00:08:15,760
кажется, вы будете рады узнать, что Trace и Crate дают почти одинаковую производительность.

96
00:08:16,240 --> 00:08:21,040
Преимущество каждого из них заключается в том, что это, очевидно, настоящее слово, поэтому наступит день, когда вы

97
00:08:21,040 --> 00:08:26,480
угадаете его с первой догадки, поскольку оба являются настоящими словесными ответами. Переход от сортировки на основе

98
00:08:26,480 --> 00:08:31,200
лучших двухшаговых энтропий к сортировке на основе наименьшего среднего балла также встряхивает список, но

99
00:08:31,200 --> 00:08:36,000
не так сильно. Например, Сале раньше занимал третье место, прежде чем поднялся на вершину,

100
00:08:36,000 --> 00:08:41,200
а Crate и Trace были четвертым и пятым. Если вам интересно, вы можете

101
00:08:41,200 --> 00:08:45,120
добиться немного большей производительности, выполнив небольшой перебор. Если вам интересно, есть очень

102
00:08:45,120 --> 00:08:49,600
хорошая запись в блоге Джонатана Олсона, где он также позволяет вам изучить

103
00:08:49,600 --> 00:08:53,600
оптимальные следующие предположения для нескольких начальных слов на основе этих оптимальных алгоритмов.

104
00:08:55,040 --> 00:08:59,040
Однако, отступив от всего этого, некоторые люди говорят мне, что если чрезмерно анализировать

105
00:08:59,040 --> 00:09:03,920
игру таким образом и пытаться найти оптимальное начальное предположение, это портит игру.

106
00:09:03,920 --> 00:09:07,680
Знаете, это кажется грязным, если вы используете эту вступительную догадку после того, как вы ее выучили, и кажется

107
00:09:07,680 --> 00:09:12,400
неэффективным, если вы этого не сделаете. Но дело в том, что я на самом деле не думаю, что это

108
00:09:12,400 --> 00:09:16,880
лучший дебют для человека, играющего в игру. Во-первых, вам нужно знать, какова оптимальная вторая догадка

109
00:09:16,880 --> 00:09:22,160
для каждого из шаблонов, которые вы видите. И что еще более важно, все это

110
00:09:22,160 --> 00:09:27,440
происходит в обстановке, когда мы абсурдно подстраиваемся под официальный список ответов Wordle. В тот момент, когда,

111
00:09:27,440 --> 00:09:32,240
скажем, New York Times решит изменить то, что находится в этом списке, все это улетучится

112
00:09:32,240 --> 00:09:36,720
в окно. То, как мы, люди, играем в игру, сильно отличается от того, что делает любой

113
00:09:36,720 --> 00:09:41,440
из этих алгоритмов. Мы не запоминаем список слов, не проводим исчерпывающий поиск, мы получаем

114
00:09:41,440 --> 00:09:45,520
интуицию из таких вещей, как, например, какие гласные и как они расположены.

115
00:09:45,520 --> 00:09:50,080
На самом деле я был бы очень рад, если бы те из вас, кто смотрит это

116
00:09:50,080 --> 00:09:54,880
видео, быстро забыли, что является технически лучшим начальным предположением, и вместо этого вспомнили бы такие вещи,

117
00:09:54,880 --> 00:09:59,440
как то, как вы оцениваете информацию или тот факт, что вам следует остерегаться, когда жадный Алгоритм

118
00:09:59,440 --> 00:10:02,960
не достигает лучшей в мире производительности, которую можно было бы получить при более глубоком поиске.

119
00:10:03,520 --> 00:10:07,920
По крайней мере, на мой вкус, радость от написания алгоритмов для игр на самом деле очень мало влияет

120
00:10:07,920 --> 00:10:12,800
на то, как мне нравится играть в эти игры как человек. Смысл написания алгоритмов для всего этого не в

121
00:10:12,800 --> 00:10:17,280
том, чтобы повлиять на то, как мы играем в игру, это все равно просто забавная игра в слова. Это

122
00:10:17,280 --> 00:10:22,160
оттачивание наших мускулов для написания алгоритмов в более значимых контекстах в других местах.

123
00:10:37,920 --> 00:10:38,420
you

