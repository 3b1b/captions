[
 {
  "input": "The months ahead of you hold within them a lot of hard work, some neat examples, some not-so-neat examples, beautiful connections to physics, not-so-beautiful piles of formulas to memorize, plenty of moments of getting stuck and banging your head into a wall, a few nice aha moments sprinkled in as well, and some genuinely lovely graphical intuition to help guide you through it all. ",
  "translatedText": "ماه‌های پیش روی شما کار سخت زیادی را در خود دارند، چند مثال منظم، چند مثال نه چندان منظم، پیوندهای زیبا با فیزیک، انبوهی از فرمول‌های نه چندان زیبا برای به خاطر سپردن، لحظات زیادی گیر افتادن و کوبیدن سر خود را به دیوار، چند لحظه خوب آها پاشیده نیز، و برخی از شهود گرافیکی واقعا دوست داشتنی برای کمک به شما در تمام آن راهنمایی کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.74,
  "end": 27.24
 },
 {
  "input": "But if the course ahead of you is anything like my first introduction to calculus, or any of the first courses I've seen in the years since, there's one topic you will not see, but which I believe stands to greatly accelerate your learning. ",
  "translatedText": "اما اگر دوره پیش روی شما چیزی شبیه به اولین مقدمه من برای حساب دیفرانسیل و انتگرال، یا هر یک از اولین دوره هایی است که در سال های بعد دیده ام، موضوعی وجود دارد که نخواهید دید، اما معتقدم که یادگیری شما را بسیار تسریع می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.63,
  "end": 39.4
 },
 {
  "input": "You see, almost all of the visual intuitions from that first year are based on graphs. ",
  "translatedText": "ببینید، تقریباً تمام شهودات بصری آن سال اول بر اساس نمودارها است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 40.28,
  "end": 44.62
 },
 {
  "input": "The derivative is the slope of a graph, the integral is a certain area under that graph. ",
  "translatedText": "مشتق شیب یک گراف است، انتگرال یک ناحیه معین زیر آن نمودار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 45.08,
  "end": 49.66
 },
 {
  "input": "But as you generalize calculus beyond functions whose inputs and outputs are simply numbers, it's not always possible to graph the function you're analyzing. ",
  "translatedText": "اما از آنجایی که حساب دیفرانسیل و انتگرال را فراتر از توابعی تعمیم می دهید که ورودی و خروجی آنها صرفاً اعداد هستند، همیشه نمی توان تابعی را که تجزیه و تحلیل می کنید نمودار کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.2,
  "end": 58.02
 },
 {
  "input": "So if all your intuitions for the fundamental ideas, like derivatives, are rooted too rigidly in graphs, it can make for a very tall and largely unnecessary conceptual hurdle between you and the more quote-unquote advanced topics, like multivariable calculus and complex analysis, differential geometry. ",
  "translatedText": "بنابراین، اگر تمام شهودات شما برای ایده‌های بنیادی، مانند مشتقات، بیش از حد سفت و سخت در نمودارها ریشه داشته باشد، می‌تواند مانع مفهومی بسیار بلند و تا حد زیادی غیرضروری بین شما و موضوعات پیشرفته‌تر، مانند محاسبات چند متغیره و تحلیل پیچیده ایجاد کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 60.68,
  "end": 77.58
 },
 {
  "input": "What I want to share with you is a way to think about derivatives, which I'll refer to as the transformational view that generalizes more seamlessly into some of those more general contexts where calculus comes up. ",
  "translatedText": "هندسه دیفرانسیل چیزی که می‌خواهم با شما به اشتراک بگذارم راهی برای اندیشیدن درباره مشتقات است، که از آن به عنوان دیدگاه دگرگونی یاد می‌کنم که به طور یکپارچه‌تر به برخی از آن زمینه‌های کلی‌تر تعمیم می‌یابد که در آن حساب دیفرانسیل و انتگرال مطرح می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.84,
  "end": 89.64
 },
 {
  "input": "And then we'll use this alternate view to analyze a fun puzzle about repeated fractions. ",
  "translatedText": "و سپس از این نمای جایگزین برای تجزیه و تحلیل یک پازل سرگرم کننده در مورد کسرهای تکراری استفاده خواهیم کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 94.86
 },
 {
  "input": "But first off, I just want to make sure we're all on the same page about what the standard visual is. ",
  "translatedText": "اما در ابتدا، من فقط می‌خواهم مطمئن شوم که همه ما در مورد اینکه استاندارد بصری چیست در یک صفحه هستیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 95.46,
  "end": 99.66
 },
 {
  "input": "If you were to graph a function, which simply takes real numbers as inputs and outputs, one of the first things you learn in a calculus course is that the derivative gives you the slope of this graph, where what we mean by that is that the derivative of the function is a new function which for every input x returns that slope. ",
  "translatedText": "اگر بخواهید یک تابع را رسم کنید که به سادگی اعداد واقعی را به عنوان ورودی و خروجی می گیرد، یکی از اولین چیزهایی که در درس حسابان یاد می گیرید این است که مشتق شیب این نمودار را به شما می دهد، جایی که منظور ما از آن این است که مشتق تابع تابع جدیدی است که برای هر ورودی x آن شیب را برمی گرداند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 100.06,
  "end": 118.24
 },
 {
  "input": "Now I'd encourage you not to think of this derivative as slope idea as being the definition of a derivative. ",
  "translatedText": "حالا من شما را تشویق می کنم که این مشتق را به عنوان یک ایده شیب به عنوان تعریف مشتق تصور نکنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.52,
  "end": 124.44
 },
 {
  "input": "Instead think of it as being more fundamentally about how sensitive the function is to tiny little nudges around the input. ",
  "translatedText": "در عوض به این فکر کنید که اساساً در مورد حساسیت عملکرد به تکان‌های کوچک اطراف ورودی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 125.0,
  "end": 130.42
 },
 {
  "input": "And the slope is just one way to think about that sensitivity relevant only to this particular way of viewing functions. ",
  "translatedText": "و شیب فقط یک راه برای فکر کردن در مورد حساسیت مربوط به این روش خاص مشاهده توابع است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.02,
  "end": 136.9
 },
 {
  "input": "I have not just another video, but a full series on this topic if it's something you want to learn more about. ",
  "translatedText": "من نه فقط یک ویدیوی دیگر، بلکه یک سری کامل در مورد این موضوع دارم، اگر می خواهید درباره آن بیشتر بدانید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.34,
  "end": 142.12
 },
 {
  "input": "Now the basic idea behind the alternate visual for the derivative is to think of this function as mapping all of the input points on the number line to their corresponding outputs on a different number line. ",
  "translatedText": "اکنون ایده اصلی پشت تصویر جایگزین برای مشتق این است که این تابع را به عنوان نگاشت تمام نقاط ورودی روی خط اعداد به خروجی های متناظر آنها در یک خط عددی متفاوت در نظر بگیریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.6,
  "end": 152.82
 },
 {
  "input": "In this context, what the derivative gives you is a measure of how much the input space gets stretched or squished in various regions. ",
  "translatedText": "در این زمینه، آنچه مشتق به شما می‌دهد، اندازه‌گیری است که فضای ورودی در مناطق مختلف چقدر کشیده یا فشرده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.4,
  "end": 160.22
 },
 {
  "input": "That is, if you were to zoom in around a specific input and take a look at some evenly spaced points around it, the derivative of the function of that input will tell you how spread out or contracted those points become after the mapping. ",
  "translatedText": "یعنی اگر بخواهید در اطراف یک ورودی خاص بزرگنمایی کنید و به چند نقطه با فاصله مساوی در اطراف آن نگاهی بیندازید، مشتق تابع آن ورودی به شما می گوید که این نقاط پس از نقشه برداری چقدر پراکنده یا منقبض می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.86,
  "end": 176.6
 },
 {
  "input": "Here, a specific example helps. ",
  "translatedText": "در اینجا، یک مثال خاص کمک می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.94,
  "end": 179.4
 },
 {
  "input": "Take the function x2, it maps 1 to 1, 2 to 4, 3 to 9, and so on. ",
  "translatedText": "تابع x2 را بگیرید، 1 به 1، 2 به 4، 3 به 9 و غیره را نگاشت می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.74,
  "end": 185.92
 },
 {
  "input": "You can also see how it acts on all of the points in between. ",
  "translatedText": "همچنین می توانید نحوه عملکرد آن را در تمام نقاط بین این دو مشاهده کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.48,
  "end": 189.22
 },
 {
  "input": "If you zoom in on a little cluster of points around the input 1, and see where they land around the relevant output, you'd notice that they tend to get stretched out. ",
  "translatedText": "اگر روی مجموعه کوچکی از نقاط در اطراف ورودی 1 بزرگنمایی کنید و ببینید که آنها در اطراف خروجی مربوطه کجا قرار می گیرند، متوجه خواهید شد که آنها تمایل به کشیده شدن دارند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 192.72,
  "end": 204.9
 },
 {
  "input": "In fact, it roughly looks like stretching out by a factor of 2. ",
  "translatedText": "در واقع، تقریباً به نظر می رسد که با ضریب 2 کشیده شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.76,
  "end": 209.02
 },
 {
  "input": "The closer you zoom in, the more this local behavior looks just like multiplying by a factor of 2. ",
  "translatedText": "هر چه نزدیکتر بزرگنمایی کنید، این رفتار محلی بیشتر شبیه ضرب در ضریب 2 به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 209.66,
  "end": 209.02
 },
 {
  "input": "This is what it means for the derivative of x2 at the input x equals 1 to be 2. ",
  "translatedText": "این همان معنایی است که مشتق x2 در ورودی x برابر 1 به 2 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 209.66,
  "end": 221.82
 },
 {
  "input": "It's what that fact looks like in the context of transformations. ",
  "translatedText": "این همان چیزی است که آن واقعیت در زمینه تحولات به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.34,
  "end": 225.4
 },
 {
  "input": "If you looked at a neighborhood of points around the input 3, they would get stretched out by a factor of 6. ",
  "translatedText": "اگر به محله ای از نقاط در اطراف ورودی 3 نگاه کنید، آنها به ضریب 6 کشیده می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 226.46,
  "end": 232.16
 },
 {
  "input": "This is what it means for the derivative of this function at the input 3 to equal 6. ",
  "translatedText": "این همان معنایی است که مشتق این تابع در ورودی 3 برابر با 6 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.74,
  "end": 237.44
 },
 {
  "input": "Around the input 1 fourth, a small region tends to get contracted by a factor of 1 half, and that's what it looks like for a derivative to be smaller than 1. ",
  "translatedText": "در اطراف ورودی 1 چهارم، یک ناحیه کوچک به ضریب 1 نصف منقبض می شود، و این چیزی است که برای یک مشتق کوچکتر از 1 به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.98,
  "end": 248.36
 },
 {
  "input": "The input 0 is interesting. ",
  "translatedText": "ورودی 0 جالب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.72,
  "end": 252.6
 },
 {
  "input": "Zooming in by a factor of 10, it doesn't really look like a constant stretching or squishing. ",
  "translatedText": "با زوم کردن ضریب 10، واقعاً شبیه کشش یا له شدن مداوم به نظر نمی رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.12,
  "end": 257.96
 },
 {
  "input": "For one thing, all of the outputs end up on the right positive side of things. ",
  "translatedText": "برای یک چیز، تمام خروجی ها به سمت مثبت درست چیزها ختم می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.38,
  "end": 261.68
 },
 {
  "input": "As you zoom in closer and closer, by 100x, or by 1000x, it looks more and more like a small neighborhood of points around 0 just gets collapsed into 0 itself. ",
  "translatedText": "وقتی نزدیک‌تر و نزدیک‌تر، 100 برابر یا 1000 برابر بزرگ‌نمایی می‌کنید، بیشتر و بیشتر شبیه همسایگی کوچکی از نقاط اطراف 0 به نظر می‌رسد که به خودی خود 0 جمع می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.32,
  "end": 277.74
 },
 {
  "input": "This is what it looks like for the derivative to be 0. ",
  "translatedText": "این چیزی است که برای مشتق 0 به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.74,
  "end": 279.96
 },
 {
  "input": "The local behavior looks more and more like multiplying the whole number line by 0. ",
  "translatedText": "رفتار محلی بیشتر و بیشتر شبیه ضرب خط اعداد کامل در 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.5,
  "end": 285.02
 },
 {
  "input": "It doesn't have to completely collapse everything to a point at a particular zoom level, instead it's a matter of what the limiting behavior is as you zoom in closer and closer. ",
  "translatedText": "لازم نیست همه چیز را به طور کامل تا نقطه ای در یک سطح بزرگنمایی خاص جمع کند، در عوض این موضوع مهم است که وقتی نزدیک و نزدیکتر زوم می کنید، رفتار محدود کننده چیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.68,
  "end": 293.84
 },
 {
  "input": "It's also instructive to take a look at the negative inputs here. ",
  "translatedText": "نگاهی به ورودی های منفی در اینجا نیز آموزنده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 295.28,
  "end": 298.96
 },
 {
  "input": "Things start to feel a little cramped since they collide with where all the positive input values go, and this is one of the downsides of thinking of functions as transformations. ",
  "translatedText": "چیزها کمی تنگ به نظر می رسند زیرا با جایی که همه مقادیر ورودی مثبت می روند برخورد می کنند، و این یکی از جنبه های منفی اندیشیدن به توابع به عنوان تبدیل است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.7,
  "end": 308.78
 },
 {
  "input": "But for derivatives, we only really care about the local behavior anyway, what happens in a small range around a given input. ",
  "translatedText": "اما برای مشتقات، ما واقعاً به رفتار محلی اهمیت می‌دهیم، آنچه در یک محدوده کوچک در اطراف یک ورودی مشخص اتفاق می‌افتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 309.4,
  "end": 315.64
 },
 {
  "input": "Here, notice that the inputs in a little neighborhood around, say, negative 2, they don't just get stretched out, they also get flipped around. ",
  "translatedText": "در اینجا، توجه کنید که ورودی‌های یک همسایگی کوچک در اطراف، مثلاً منفی 2، نه تنها کشیده می‌شوند، بلکه به اطراف نیز برمی‌گردند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.5,
  "end": 324.1
 },
 {
  "input": "Specifically, the action on such a neighborhood looks more and more like multiplying by negative 4 the closer you zoom in. ",
  "translatedText": "به طور خاص، عمل در چنین محله ای بیشتر و بیشتر شبیه ضرب در منفی 4 به نظر می رسد که هر چه نزدیکتر بزرگنمایی کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 324.68,
  "end": 331.82
 },
 {
  "input": "This is what it looks like for the derivative of a function to be negative. ",
  "translatedText": "این چیزی است که به نظر می رسد برای مشتق یک تابع منفی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.32,
  "end": 335.6
 },
 {
  "input": "I think you get the point, this is all well and good, but let's see how this is useful in solving a problem. ",
  "translatedText": "فکر می‌کنم متوجه موضوع شده‌اید، همه اینها خوب و خوب است، اما بیایید ببینیم که چگونه در حل یک مشکل مفید است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.46,
  "end": 343.66
 },
 {
  "input": "A friend of mine recently asked me a pretty fun question about the infinite fraction 1 plus 1 divided by 1 plus 1 divided by 1 plus 1 divided by 1, and clearly you watch math videos online, so maybe you've seen this before, but my friend's question actually cuts to something you might not have thought about before, relevant to the view of derivatives that we're looking at here. ",
  "translatedText": "یکی از دوستانم اخیراً یک سؤال جالب در مورد کسر نامتناهی 1 بعلاوه 1 تقسیم بر 1 به علاوه 1 تقسیم بر 1 به علاوه 1 تقسیم بر 1 از من پرسید و واضح است که شما ویدیوهای ریاضی را آنلاین تماشا می کنید ، بنابراین شاید قبلاً این را دیده باشید ، اما سوال دوست من در واقع به چیزی مربوط می شود که ممکن است قبلاً به آن فکر نکرده باشید، مربوط به دیدگاه مشتقاتی است که ما در اینجا به آن نگاه می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.26,
  "end": 364.22
 },
 {
  "input": "The typical way you might evaluate an expression like this is to set it equal to x, and then notice that there's a copy of the full fraction inside itself. ",
  "translatedText": "روش معمولی که می‌توانید عبارتی مانند این را ارزیابی کنید این است که آن را برابر با x قرار دهید و سپس متوجه شوید که یک کپی از کسر کامل درون خودش وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.02,
  "end": 373.64
 },
 {
  "input": "So you can replace that copy with another x, and then just solve for x. ",
  "translatedText": "بنابراین می توانید آن کپی را با x دیگری جایگزین کنید و سپس فقط x را حل کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.7,
  "end": 378.78
 },
 {
  "input": "That is, what you want is to find a fixed point of the function 1 plus 1 divided by x. ",
  "translatedText": "یعنی چیزی که می خواهید پیدا کردن یک نقطه ثابت از تابع 1 به اضافه 1 تقسیم بر x است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.44,
  "end": 384.58
 },
 {
  "input": "But here's the thing, there are actually two solutions for x, two special numbers where 1 plus 1 divided by that number gives you back the same thing. ",
  "translatedText": "اما نکته اینجاست، در واقع دو راه حل برای x وجود دارد، دو عدد خاص که 1 به اضافه 1 تقسیم بر آن عدد همان چیزی را به شما برمی گرداند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.16,
  "end": 396.38
 },
 {
  "input": "One is the golden ratio, phi, around 1.618, and the other is negative 0.618, which happens to be negative 1 divided by phi. ",
  "translatedText": "یکی نسبت طلایی، فی، حدود 1 است. 618 و دیگری منفی 0 است. 618 که اتفاقاً منفی 1 تقسیم بر فی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.94,
  "end": 406.54
 },
 {
  "input": "I like to call this other number phi's little brother, since just about any property that phi has, this number also has. ",
  "translatedText": "من دوست دارم این شماره دیگر را برادر کوچک فی صدا کنم، زیرا تقریباً هر ملکی که فی داشته باشد، این شماره نیز دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.96,
  "end": 412.9
 },
 {
  "input": "And this raises the question, would it be valid to say that the infinite fraction we saw is somehow also equal to phi's little brother, negative 0.618? ",
  "translatedText": "و این سؤال را ایجاد می کند که آیا درست است که بگوییم کسر نامتناهی که دیدیم به نوعی برابر با برادر کوچک فی، منفی 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 413.56,
  "end": 423.6
 },
 {
  "input": "Maybe you initially say, obviously not, everything on the left hand side is positive, so how could it possibly equal a negative number? ",
  "translatedText": "618؟ شاید در ابتدا بگویید، بدیهی است که نه، همه چیز در سمت چپ مثبت است، پس چگونه ممکن است با یک عدد منفی برابر شود؟ خوب، ابتدا باید منظورمان از عبارتی مانند این را روشن کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.52,
  "end": 431.26
 },
 {
  "input": "Well, first we should be clear about what we actually mean by an expression like this. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.5,
  "end": 437.1
 },
 {
  "input": "One way you could think about it, and it's not the only way, there's freedom for choice here, is to imagine starting with some constant, like 1, and then repeatedly applying the function 1 plus 1 divided by x, and then asking, what is this approach as you keep going? ",
  "translatedText": "یکی از راه‌هایی که می‌توانید درباره آن فکر کنید، و این تنها راه نیست، در اینجا آزادی انتخاب وجود دارد، این است که تصور کنید با مقداری ثابت شروع کنید، مانند 1، و سپس به طور مکرر تابع 1 به اضافه 1 تقسیم بر x را اعمال کنید، و سپس بپرسید که چه چیزی آیا این رویکرد همچنان ادامه دارد؟ منظورم این است که قطعاً از نظر نمادین چیزی که دریافت می‌کنید بیشتر و بیشتر شبیه کسر نامتناهی ما است، بنابراین شاید اگر می‌خواهید با عددی برابر شوید، باید بپرسید که این سری از اعداد به چه چیزی نزدیک می‌شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.78,
  "end": 453.26
 },
 {
  "input": "I mean, certainly symbolically what you get looks more and more like our infinite fraction, so maybe if you wanted to equal a number, you should ask what this series of numbers approaches. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.04,
  "end": 463.42
 },
 {
  "input": "And if that's your view of things, maybe you start off with a negative number, so it's not so crazy for the whole expression to end up negative. ",
  "translatedText": "و اگر این دیدگاه شما نسبت به چیزها است، شاید با یک عدد منفی شروع کنید، بنابراین خیلی دیوانه کننده نیست که کل عبارت منفی شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.12,
  "end": 471.3
 },
 {
  "input": "After all, if you start with negative 1 divided by phi, then applying this function, 1 plus 1 over x, you get back the same number, negative 1 divided by phi. ",
  "translatedText": "به هر حال، اگر با منفی 1 تقسیم بر فی شروع کنید، سپس با اعمال این تابع، 1 به اضافه 1 بر x، همان عدد را برمی‌گردانید، منفی 1 تقسیم بر فی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.74,
  "end": 482.02
 },
 {
  "input": "So no matter how many times you apply it, you're staying fixed at this value. ",
  "translatedText": "بنابراین مهم نیست که چند بار آن را اعمال کنید، در این مقدار ثابت می‌مانید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.2,
  "end": 485.74
 },
 {
  "input": "But even then, there is one reason you should probably view phi as the favorite brother in this pair. ",
  "translatedText": "اما حتی پس از آن، یک دلیل وجود دارد که احتمالاً باید فی را به عنوان برادر مورد علاقه در این جفت نگاه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.82,
  "end": 493.42
 },
 {
  "input": "Here, try this, pull up a calculator of some kind, then start with any random number, and plug it into this function, 1 plus 1 divided by x, and plug that number into 1 plus 1 over x, and again, and again, and again, and again. ",
  "translatedText": "در اینجا، این را امتحان کنید، یک نوع ماشین حساب را بردارید، سپس با هر عدد تصادفی شروع کنید، و آن را به این تابع، 1 به علاوه 1 تقسیم بر x وصل کنید، و آن عدد را به 1 به علاوه 1 روی x و دوباره و دوباره وصل کنید. ، و دوباره و دوباره. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.02,
  "end": 508.04
 },
 {
  "input": "No matter what constant you start with, you eventually end up at 1.618. ",
  "translatedText": "مهم نیست که با چه ثابتی شروع کنید، در نهایت به عدد 1 می رسید. 618. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.48,
  "end": 513.16
 },
 {
  "input": "Even if you start with a negative number, even one that's really close to phi's little brother, eventually it shies away from that value and jumps back over to phi. ",
  "translatedText": "حتی اگر با یک عدد منفی شروع کنید، حتی عددی که واقعاً به برادر کوچک فی نزدیک است، در نهایت از آن مقدار دور می شود و دوباره به ph می پرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.8,
  "end": 523.4
 },
 {
  "input": "So, what's going on here? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.82,
  "end": 532.46
 },
 {
  "input": "Why is one of these fixed points favored above the other one? ",
  "translatedText": "خب، اینجا چه خبر است؟ چرا یکی از این نقاط ثابت بالاتر از دیگری ترجیح داده می شود؟ شاید قبلاً می‌توانید ببینید که چگونه درک تحولی مشتقات برای درک این تنظیم مفید است، اما به خاطر داشتن نقطه تضاد، می‌خواهم به شما نشان دهم که چگونه مشکلی مانند این اغلب با استفاده از نمودارها آموزش داده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 532.8,
  "end": 535.92
 },
 {
  "input": "Maybe you can already see how the transformational understanding of derivatives is helpful for understanding this setup, but for the sake of having a point of contrast, I want to show you how a problem like this is often taught using graphs. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.72,
  "end": 547.08
 },
 {
  "input": "If you were to plug in some random input to this function, the y value tells you the corresponding output, right? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 547.92,
  "end": 554.04
 },
 {
  "input": "So to plug that output back into the function, you might first move horizontally until you hit the line y equals x, and that's going to give you a position where the x value corresponds to your previous y value, right? ",
  "translatedText": "اگر بخواهید یک ورودی تصادفی را به این تابع وصل کنید، مقدار y خروجی مربوطه را به شما می گوید، درست است؟ بنابراین برای وصل کردن آن خروجی به تابع، ممکن است ابتدا به صورت افقی حرکت کنید تا زمانی که خط y برابر با x شود، و این به شما موقعیتی می دهد که در آن مقدار x با مقدار y قبلی شما مطابقت دارد، درست است؟ پس از آنجا، می‌توانید به صورت عمودی حرکت کنید تا ببینید این مقدار x جدید چه خروجی دارد، و سپس تکرار می‌کنید، به صورت افقی به خط y برابر با x حرکت می‌کنید تا نقطه‌ای را پیدا کنید که مقدار x آن همان خروجی است که دریافت کردید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.04,
  "end": 568.24
 },
 {
  "input": "So then from there, you can move vertically to see what output this new x value has, and then you repeat, you move horizontally to the line y equals x to find a point whose x value is the same as the output you just got, and then you move vertically to apply the function again. ",
  "translatedText": "و سپس به صورت عمودی حرکت می کنید تا عملکرد را دوباره اعمال کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 568.92,
  "end": 584.76
 },
 {
  "input": "Personally, I think this is an awkward way to think about repeatedly applying a function, don't you? ",
  "translatedText": "من شخصاً فکر می‌کنم این روشی ناخوشایند برای فکر کردن به اعمال مکرر یک تابع است، اینطور نیست؟ منظورم این است که منطقی است، اما باید مکث کرد و به آن فکر کرد تا به یاد بیاوری که خطوط را به کدام سمت بکشی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 585.88,
  "end": 590.78
 },
 {
  "input": "I mean, it makes sense, but you have to pause and think about it to remember which way to draw the lines. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.3,
  "end": 596.54
 },
 {
  "input": "And you can, if you want, think through what conditions make this spiderweb process narrow in on a fixed point, versus propagating away from it. ",
  "translatedText": "و اگر بخواهید می‌توانید به این فکر کنید که چه شرایطی باعث می‌شود این فرآیند تار عنکبوتی در یک نقطه ثابت در مقابل انتشار از آن تنگ شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 597.12,
  "end": 605.28
 },
 {
  "input": "In fact, go ahead, pause right now and try to think it through as an exercise. ",
  "translatedText": "در واقع، همین الان مکث کنید و سعی کنید به آن به عنوان یک تمرین فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 605.86,
  "end": 608.9
 },
 {
  "input": "It has to do with slopes. ",
  "translatedText": "به شیب ها مربوط می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 609.24,
  "end": 610.46
 },
 {
  "input": "Or if you want to skip the exercise for something that I think gives a much more satisfying understanding, think about how this function acts as a transformation. ",
  "translatedText": "یا اگر می‌خواهید تمرین را برای چیزی که فکر می‌کنم درک بسیار رضایت‌بخش‌تری ارائه می‌دهد صرف‌نظر کنید، به این فکر کنید که چگونه این تابع به عنوان یک تبدیل عمل می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.02,
  "end": 619.62
 },
 {
  "input": "So I'm going to start here by drawing a bunch of arrows to indicate where the various sampled input points will go. ",
  "translatedText": "بنابراین من می‌خواهم از اینجا با رسم یک دسته فلش شروع کنم تا مشخص کنم نقاط ورودی نمونه‌برداری‌شده مختلف کجا خواهند رفت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.28,
  "end": 627.74
 },
 {
  "input": "And side note, don't you think this gives a neat emergent pattern? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 628.32,
  "end": 631.44
 },
 {
  "input": "I wasn't expecting this, but it was cool to see it pop up when animating. ",
  "translatedText": "و نکته جانبی، آیا فکر نمی کنید که این یک الگوی نوظهور منظم به دست می دهد؟ من انتظار چنین چیزی را نداشتم، اما دیدن آن در هنگام انیمیشن بسیار جالب بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 631.82,
  "end": 635.02
 },
 {
  "input": "The action of 1 divided by x gives this nice emergent circle, and then we're just shifting things over by one. ",
  "translatedText": "عمل 1 تقسیم بر x این دایره ظاهری زیبا را به دست می دهد، و سپس ما فقط چیزها را به یک تغییر می دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 635.02,
  "end": 641.28
 },
 {
  "input": "Anyway, I want you to think about what it means to repeatedly apply some function, like 1 plus 1 over x, in this context. ",
  "translatedText": "به هر حال، می‌خواهم در مورد اعمال مکرر برخی از تابع‌ها، مانند 1 به علاوه 1 بر x، در این زمینه فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.04,
  "end": 648.72
 },
 {
  "input": "Well, after letting it map all the inputs to the outputs, you could consider those as the new inputs, and then just apply the same process again, and then again, and do it however many times you want. ",
  "translatedText": "خوب، پس از اینکه اجازه دادید همه ورودی‌ها را به خروجی‌ها نگاشت، می‌توانید آن‌ها را به‌عنوان ورودی‌های جدید در نظر بگیرید، و سپس دوباره همان فرآیند را اعمال کنید، و سپس دوباره، و هر چند بار که می‌خواهید این کار را انجام دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 650.24,
  "end": 661.52
 },
 {
  "input": "Notice in animating this with a few dots representing the sample points, it doesn't take many iterations at all before all of those dots kind of clump in around 1.618. ",
  "translatedText": "توجه داشته باشید که در متحرک سازی این با چند نقطه نشان دهنده نقاط نمونه، قبل از اینکه همه آن نقطه ها به نوعی در حدود 1 جمع شوند، تکرارهای زیادی لازم نیست. 618. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.58,
  "end": 672.0
 },
 {
  "input": "Now remember, we know that 1.618 and its little brother, negative 0.618 on and on, stay fixed in place during each iteration of this process. ",
  "translatedText": "اکنون به یاد داشته باشید، ما می دانیم که 1.618 و برادر کوچکش منفی 0.618 و در طول هر تکرار این فرآیند در جای خود ثابت بمانید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 674.62,
  "end": 683.86
 },
 {
  "input": "But zoom in on a neighborhood around phi. ",
  "translatedText": "اما روی یک محله اطراف فی زوم کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.86,
  "end": 687.48
 },
 {
  "input": "During the map, points in that region get contracted around phi, meaning that the function 1 plus 1 over x has a derivative with a magnitude less than 1 at this input. ",
  "translatedText": "در طول نقشه، نقاط آن منطقه حول ph منقبض می شوند، به این معنی که تابع 1 به علاوه 1 روی x دارای مشتقی با قدر کمتر از 1 در این ورودی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.48,
  "end": 701.12
 },
 {
  "input": "In fact, this derivative works out to be around negative 0.38. ",
  "translatedText": "در واقع، این مشتق تقریباً منفی 0 است. 38. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 701.88,
  "end": 705.2
 },
 {
  "input": "So what that means is that each repeated application scrunches the neighborhood around this number smaller and smaller, like a gravitational pull towards phi. ",
  "translatedText": "بنابراین معنای آن این است که هر برنامه تکراری، اطراف این عدد را کوچکتر و کوچکتر می کند، مانند یک کشش گرانشی به سمت فی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.12,
  "end": 714.4
 },
 {
  "input": "So now, tell me what you think happens in the neighborhood of phi's little brother. ",
  "translatedText": "خب حالا به من بگو که فکر می کنی در همسایگی برادر کوچک فی چه اتفاقی می افتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 714.96,
  "end": 718.62
 },
 {
  "input": "Over there, the derivative has a magnitude larger than 1, so points near the fixed point are repelled away from it. ",
  "translatedText": "در آنجا، مشتق دارای قدر بزرگتر از 1 است، بنابراین نقاط نزدیک به نقطه ثابت از آن دفع می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.32,
  "end": 728.92
 },
 {
  "input": "And when you work it out, you can see that they get stretched by more than a factor of 2 in each iteration. ",
  "translatedText": "و هنگامی که آن را انجام می دهید، می بینید که در هر تکرار بیش از ضریب 2 کشیده می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.52,
  "end": 733.8
 },
 {
  "input": "They also get flipped around because the derivative is negative here, but the salient fact for the sake of stability is just the magnitude. ",
  "translatedText": "آنها همچنین تغییر می کنند زیرا مشتق در اینجا منفی است، اما واقعیت برجسته به خاطر ثبات فقط بزرگی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.42,
  "end": 740.84
 },
 {
  "input": "Mathematicians would call this right value a stable fixed point, and the left one is an unstable fixed point. ",
  "translatedText": "ریاضیدانان این مقدار راست را یک نقطه ثابت پایدار می نامند و سمت چپ را یک نقطه ثابت ناپایدار می نامند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.44,
  "end": 749.36
 },
 {
  "input": "Everything is considered stable if when you perturb it just a little bit, it tends to come back towards where it started, rather than going away from it. ",
  "translatedText": "همه چیز پایدار در نظر گرفته می شود اگر وقتی کمی آن را آشفته می کنید، به جای دور شدن از آن، تمایل دارد به همان جایی که شروع شده برگردد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 750.0,
  "end": 757.1
 },
 {
  "input": "So what we're seeing is a very useful little fact, that the stability of a fixed point is determined by whether or not the magnitude of its derivative is bigger or smaller than 1. ",
  "translatedText": "بنابراین آنچه می بینیم یک واقعیت کوچک بسیار مفید است، اینکه پایداری یک نقطه ثابت با بزرگتر یا کوچکتر بودن مقدار مشتق آن از 1 تعیین می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.18,
  "end": 767.3
 },
 {
  "input": "This explains why phi always shows up in the numerical play, where you're just hitting enter on your calculator over and over, but phi's little brother never does. ",
  "translatedText": "این توضیح می‌دهد که چرا ph همیشه در نمایش عددی نشان داده می‌شود، جایی که شما فقط اینتر را بارها و بارها روی ماشین حساب خود فشار می‌دهید، اما برادر کوچک فی هرگز این کار را نمی‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.3,
  "end": 775.8
 },
 {
  "input": "Whether or not you want to consider phi's little brother a valid value of the infinite fraction is up to you. ",
  "translatedText": "اینکه آیا می خواهید برادر کوچک فی را یک مقدار معتبر از کسر نامتناهی در نظر بگیرید یا نه، به شما بستگی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.46,
  "end": 782.88
 },
 {
  "input": "Everything we just showed suggests that if you think of this expression as representing a limiting process, then because every possible seed value other than phi's little brother gives you a series converging to phi, it does feel silly to put them on equal footing with each other. ",
  "translatedText": "همه چیزهایی که اخیرا نشان دادیم نشان می‌دهد که اگر فکر می‌کنید این عبارت نشان‌دهنده یک فرآیند محدودکننده است، پس چون هر مقدار احتمالی بذر غیر از برادر کوچک فی به شما یک سری همگرا با ph می‌دهد، احمقانه است که آن‌ها را در موقعیتی برابر با یکدیگر قرار دهید. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.26,
  "end": 797.74
 },
 {
  "input": "But maybe you don't think of it as a limit, maybe the kind of math you're doing lends itself to treating this as a purely algebraic object, like the solutions of a polynomial, which simply has multiple values. ",
  "translatedText": "اما شاید شما آن را به عنوان یک حد در نظر نگیرید، شاید نوع ریاضی که انجام می‌دهید باعث شود که آن را به عنوان یک شیء جبری صرف در نظر بگیرید، مانند راه‌حل‌های یک چند جمله‌ای، که به سادگی دارای مقادیر متعدد است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.26,
  "end": 809.22
 },
 {
  "input": "Anyway, that's beside the point, and my point here is not that viewing derivatives as this change in density is somehow better than the graphical intuition on the whole. ",
  "translatedText": "به هر حال، این در کنار موضوع است، و منظور من در اینجا این نیست که مشاهده مشتقات به عنوان این تغییر در چگالی به نحوی بهتر از شهود گرافیکی در کل است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 810.34,
  "end": 818.78
 },
 {
  "input": "In fact, picturing an entire function this way can be kind of clunky and impractical as compared to graphs. ",
  "translatedText": "در واقع، تصویر کردن کل یک تابع به این روش می‌تواند در مقایسه با نمودارها، به نوعی سخت و غیرعملی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.6,
  "end": 824.76
 },
 {
  "input": "My point is that it deserves more of a mention in most of the introductory calculus courses, because it can help make a student's understanding of the derivative a little more flexible. ",
  "translatedText": "منظور من این است که در بیشتر دروس مقدماتی حساب دیفرانسیل و انتگرال باید بیشتر به آن اشاره شود، زیرا می تواند به درک دانش آموز از مشتق کمی انعطاف پذیرتر کمک کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.34,
  "end": 833.94
 },
 {
  "input": "Like I mentioned, the real reason I'd recommend you carry this perspective with you as you learn new topics is not so much for what it does with your understanding of single variable calculus, it's for what comes after. ",
  "translatedText": "همانطور که اشاره کردم، دلیل واقعی که توصیه می‌کنم این دیدگاه را با خود همراه داشته باشید، در حین یادگیری موضوعات جدید، به دلیل درک شما از حساب تک متغیری نیست، بلکه به خاطر چیزهایی است که بعد از آن می‌آید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 834.9,
  "end": 845.0
 }
]