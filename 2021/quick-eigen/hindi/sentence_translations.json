[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices.",
  "translatedText": "यह उन लोगों के लिए एक वीडियो है जो पहले से ही जानते हैं कि eigenvalues और eigenvectors क्या हैं, और जो 2x2 मैट्रिक्स के मामले में उनकी गणना करने के त्वरित तरीके का आनंद ले सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you're unfamiliar with eigenvalues, go ahead and take a look at this video here, which is actually meant to introduce them.",
  "translatedText": "यदि आप स्वदेशी मूल्यों से अपरिचित हैं, तो आगे बढ़ें और यहां इस वीडियो को देखें, जो वास्तव में उन्हें पेश करने के लिए है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if all you want to do is see the trick, but if possible I'd like you to rediscover it for yourself.",
  "translatedText": "यदि आप केवल ट्रिक देखना चाहते हैं तो आप आगे बढ़ सकते हैं, लेकिन यदि संभव हो तो मैं चाहूंगा कि आप इसे स्वयं पुनः खोजें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 20.1
 },
 {
  "input": "So for that, let's lay out a little background.",
  "translatedText": "तो इसके लिए, आइए हम थोड़ी पृष्ठभूमि बता दें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.58,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale that vector by some constant, we call it an eigenvector of the transformation, and we call the relevant scaling factor the corresponding eigenvalue, often denoted with the letter lambda.",
  "translatedText": "एक त्वरित अनुस्मारक के रूप में, यदि किसी दिए गए वेक्टर पर रैखिक परिवर्तन का प्रभाव उस वेक्टर को कुछ स्थिरांक द्वारा स्केल करना है, तो हम इसे परिवर्तन का आइगेनवेक्टर कहते हैं, और हम संबंधित स्केलिंग कारक को संबंधित आइगेनवैल्यू कहते हैं, जिसे अक्सर लैम्ब्डा अक्षर से दर्शाया जाता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation, and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix A minus lambda times the identity must send some non-zero vector, namely the corresponding eigenvector, to the zero vector, which in turn means that the determinant of this modified matrix must be zero.",
  "translatedText": "जब आप इसे एक समीकरण के रूप में लिखते हैं, और आप इसे थोड़ा सा पुनर्व्यवस्थित करते हैं, तो आप देखते हैं कि यदि संख्या लैम्ब्डा मैट्रिक्स A का आइगेनवैल्यू है, तो मैट्रिक्स A माइनस लैम्ब्डा गुणे पहचान को शून्य वेक्टर पर कुछ गैर-शून्य वेक्टर, अर्थात् संबंधित आइगेनवेक्टर भेजना चाहिए, जिसका अर्थ है कि इस संशोधित मैट्रिक्स का निर्धारक शून्य होना चाहिए।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that's all a little bit of a mouthful to say, but again, I'm assuming that all of this is review for any of you watching.",
  "translatedText": "ठीक है, यह सब कहने के लिए थोड़ी-सी बात है, लेकिन फिर भी, मैं यह मान रहा हूं कि यह सब आपमें से जो भी देख रहा है उसके लिए समीक्षा है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals, and then solve for the determinant is equal to zero.",
  "translatedText": "अतः आइगेन वैल्यू की गणना करने का सामान्य तरीका, जैसा कि मैं पहले करता था और मेरा मानना है कि अधिकांश छात्रों को इसे करने के लिए यही सिखाया जाता है, विकर्णों से अज्ञात मान लैम्ब्डा घटाना है, और फिर निर्धारक को शून्य के बराबर मान के लिए हल करना है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few extra steps to expand out and simplify to get a clean quadratic polynomial, what's known as the characteristic polynomial of the matrix.",
  "translatedText": "ऐसा करने में हमेशा कुछ अतिरिक्त चरणों का पालन करना होता है, ताकि एक स्पष्ट द्विघात बहुपद प्राप्त करने के लिए इसे विस्तारित और सरल किया जा सके, जिसे मैट्रिक्स का अभिलक्षणिक बहुपद कहा जाता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial, so to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification.",
  "translatedText": "आइगेन मान इस बहुपद के मूल हैं, इसलिए उन्हें खोजने के लिए आपको द्विघात सूत्र का प्रयोग करना होगा, जिसके लिए भी आमतौर पर एक या दो और सरलीकरण चरणों की आवश्यकता होती है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 97.36,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn't terrible, but at least for two by two matrices, there is a much more direct way you can get at the answer.",
  "translatedText": "ईमानदारी से कहें तो यह प्रक्रिया बहुत बुरी नहीं है, लेकिन कम से कम दो गुणा दो मैट्रिसेस के लिए उत्तर पाने का एक और अधिक सीधा तरीका है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.76,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there's only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem solving.",
  "translatedText": "और यदि आप इस युक्ति को पुनः खोजना चाहते हैं, तो आपको केवल तीन प्रासंगिक तथ्यों को जानने की आवश्यकता है, जिनमें से प्रत्येक अपने आप में जानने योग्य है और अन्य समस्याओं को सुलझाने में आपकी सहायता कर सकता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number one, the trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "translatedText": "नंबर एक, एक मैट्रिक्स का ट्रेस, जो इन दो विकर्ण प्रविष्टियों का योग है, आइजेन वैल्यू के योग के बराबर है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or, another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries.",
  "translatedText": "अथवा, इसे दूसरे तरीके से कहें तो, जो हमारे उद्देश्यों के लिए अधिक उपयोगी है, वह यह है कि दो आइगेन वैल्यू का माध्य इन दो विकर्ण प्रविष्टियों के माध्य के समान है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number two, the determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues.",
  "translatedText": "संख्या दो, मैट्रिक्स का निर्धारक, हमारा सामान्य ad-bc सूत्र, दो आइगेन मानों के गुणनफल के बराबर होता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction, and that the determinant describes how much an operator scales areas, or volumes, as a whole.",
  "translatedText": "और यह बात आपको कुछ हद तक समझ में आ जाएगी यदि आप समझते हैं कि आइगेन वैल्यू यह बताती है कि ऑपरेटर किसी विशेष दिशा में स्थान को कितना फैलाता है, और निर्धारक यह बताता है कि ऑपरेटर समग्र रूप से क्षेत्र या आयतन को कितना मापता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down.",
  "translatedText": "अब तीसरे तथ्य पर पहुंचने से पहले, ध्यान दें कि आप वास्तव में बहुत कुछ लिखे बिना मैट्रिक्स से इन पहले दो मानों को अनिवार्य रूप से कैसे पढ़ सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example.",
  "translatedText": "इस मैट्रिक्स को एक उदाहरण के रूप में यहाँ लें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away, you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7.",
  "translatedText": "आप सीधे ही जान सकते हैं कि आइजेन वैल्यू का माध्य 8 और 6 के माध्य के समान है, जो कि 7 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well practiced at finding the determinant, which in this case works out to be 48 minus 8.",
  "translatedText": "इसी प्रकार, अधिकांश रैखिक बीजगणित के विद्यार्थी सारणिक ज्ञात करने में काफी अच्छे होते हैं, जो इस मामले में 48 माइनस 8 आता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.58,
  "end": 187.08
 },
 {
  "input": "So right away, you know that the product of the two eigenvalues is 40.",
  "translatedText": "तो तुरंत ही आप जान जाएंगे कि दोनों आइगेन वैल्यू का गुणनफल 40 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 188.24,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see if you can derive what will be our third relevant fact, which is how you can quickly recover two numbers when you know their mean and you know their product.",
  "translatedText": "अब यह देखने के लिए एक क्षण लें कि क्या आप यह पता लगा सकते हैं कि हमारा तीसरा प्रासंगिक तथ्य क्या होगा, यानी आप दो संख्याओं को कैसे तुरंत पुनर्प्राप्त कर सकते हैं जब आप उनका माध्य जानते हैं और आप उनका उत्पाद जानते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example.",
  "translatedText": "यहां, आइए इस उदाहरण पर ध्यान केंद्रित करें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know that the two values are evenly spaced around the number 7, so they look like 7 plus or minus something, let's call that something d for distance.",
  "translatedText": "आप जानते हैं कि दोनों मान संख्या 7 के चारों ओर समान दूरी पर हैं, इसलिए वे 7 प्लस या माइनस कुछ की तरह दिखते हैं, आइए दूरी के लिए इसे कुछ डी कहते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40.",
  "translatedText": "आप यह भी जानते हैं कि इन दोनों संख्याओं का गुणनफल 40 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares.",
  "translatedText": "अब d खोजने के लिए, ध्यान दें कि यह उत्पाद वास्तव में अच्छी तरह से फैलता है, यह वर्गों के अंतर के रूप में काम करता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can find d.",
  "translatedText": "तो वहां से, आप d पा सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.56,
  "end": 226.86
 },
 {
  "input": "d squared is 7 squared minus 40, or 9, which means that d itself is 3.",
  "translatedText": "d वर्ग = 7 वर्ग - 40, या 9, जिसका अर्थ है कि d स्वयं 3 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 228.2,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10.",
  "translatedText": "दूसरे शब्दों में, इस विशिष्ट उदाहरण के लिए दो मान 4 और 10 बनते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn't want to think through this each time, so let's wrap up what we just did in a general formula.",
  "translatedText": "लेकिन हमारा लक्ष्य एक त्वरित तरकीब है, और आप हर बार इसके बारे में सोचना नहीं चाहेंगे, इसलिए हमने जो किया, उसे एक सामान्य सूत्र में समेटते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean m and product p, the distance squared is always going to be m squared minus p.",
  "translatedText": "किसी भी माध्य m और गुणनफल p के लिए, दूरी का वर्ग हमेशा m वर्ग - p होगा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m plus or minus the square root of m squared minus p.",
  "translatedText": "इससे तीसरा महत्वपूर्ण तथ्य सामने आता है, जो यह है कि जब दो संख्याओं का माध्य m और गुणनफल p होता है, तो आप उन दो संख्याओं को m प्लस या माइनस m वर्ग का वर्गमूल माइनस p के रूप में लिख सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 257.56,
  "end": 268.46
 },
 {
  "input": "This is decently fast to re-derive on the fly if you ever forget it, and it's essentially just a rephrasing of the difference of squares formula.",
  "translatedText": "यदि आप इसे कभी भूल जाते हैं तो इसे तुरंत पुनः प्राप्त करना काफी तेज है, और यह मूलतः वर्गों के अंतर के सूत्र का ही पुनर्लेखन है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.1,
  "end": 277.08
 },
 {
  "input": "But even still, it's a fact that's worth memorizing so it's at the tip of your fingers.",
  "translatedText": "लेकिन फिर भी, यह एक ऐसा तथ्य है जिसे याद रखना जरूरी है ताकि यह आपकी उंगलियों पर रहे।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel A Capella Science wrote us a nice quick jingle to make it a little bit more memorable.",
  "translatedText": "वास्तव में, चैनल ए कैपेला साइंस से मेरे मित्र टिम ने इसे थोड़ा और यादगार बनाने के लिए हमें एक अच्छा त्वरित जिंगल लिखा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "Let me show you how this works, say for the matrix 3 1 4 1.",
  "translatedText": "मैं आपको बताता हूँ कि यह कैसे काम करता है, जैसे मैट्रिक्स 3 1 4 1 के लिए।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head.",
  "translatedText": "आप सूत्र को ध्यान में रखकर शुरुआत करें, हो सकता है कि यह सब अपने दिमाग में बता दें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values for m and p as you go.",
  "translatedText": "लेकिन जब आप इसे लिखते हैं, तो आप m और p के लिए उचित मान भरते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2, so the thing you start writing is 2 plus or minus the square root of 2 squared minus.",
  "translatedText": "अतः इस उदाहरण में, आइजेन वैल्यू का माध्य 3 और 1 के माध्य के समान है, जो कि 2 है, इसलिए आप जो लिखना शुरू करेंगे वह 2 प्लस या माइनस 2 का वर्गमूल माइनस होगा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.34,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3 times 1 minus 1 times 4, or negative 1, so that's the final thing you fill in, which means the eigenvalues are 2 plus or minus the square root of 5.",
  "translatedText": "फिर आइजेन वैल्यू का गुणनफल निर्धारक होता है, जो इस उदाहरण में 3 गुणा 1 घटा 1 गुणा 4, या ऋणात्मक 1 है, इसलिए यह अंतिम चीज है जिसे आप भरते हैं, जिसका अर्थ है कि आइजेन वैल्यू 2 प्लस या माइनस 5 का वर्गमूल है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.54,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer.",
  "translatedText": "आप पहचान सकते हैं कि यह वही मैट्रिक्स है जिसका उपयोग मैं शुरुआत में कर रहा था, लेकिन ध्यान दें कि हम सीधे तौर पर कितना अधिक उत्तर प्राप्त कर सकते हैं। ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one.",
  "translatedText": "यहाँ, एक और प्रयास करें. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5.",
  "translatedText": "इस बार, आइजेन वैल्यू का माध्य 2 और 8 के माध्य के समान है, जो 5 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula, but this time writing 5 in place of m.",
  "translatedText": "तो फिर, आप सूत्र लिखना शुरू करते हैं, लेकिन इस बार m के स्थान पर 5 लिखते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2 times 8 minus 7 times 1, or 9.",
  "translatedText": "और फिर निर्धारक 2*8 - 7*1, या 9 है। ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 plus or minus the square root of 16, which simplifies even further as 9 and 1.",
  "translatedText": "तो इस उदाहरण में, eigenvalues 5 ± sqrt(16) जैसा दिखता है, जो 9 और 1 के रूप में और भी सरल हो जाता है। ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while you're staring at the matrix?",
  "translatedText": "क्या आप समझ रहे हैं कि मेरा क्या मतलब है कि आप मूलतः मैट्रिक्स को देखते हुए ही आइगेनवैल्यू लिखना शुरू कर सकते हैं?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It's typically just the tiniest bit of simplification at the end.",
  "translatedText": "यह आमतौर पर अंत में किया गया एक छोटा सा सरलीकरण होता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I've found myself using this trick a lot when I'm sketching quick notes related to linear algebra and want to use small matrices as examples.",
  "translatedText": "ईमानदारी से कहूं तो, जब मैं रैखिक बीजगणित से संबंधित त्वरित नोट्स बना रहा होता हूं और उदाहरण के रूप में छोटे मैट्रिसेस का उपयोग करना चाहता हूं, तो मैं इस ट्रिक का अक्सर उपयोग करता हूं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I've been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realize it's just very handy if students can read out the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation.",
  "translatedText": "मैं मैट्रिक्स एक्सपोनेंट्स के बारे में एक वीडियो पर काम कर रहा हूं, जहां आइगेनवैल्यू अक्सर आते हैं, और मुझे लगता है कि यह बहुत उपयोगी है अगर छात्र किसी अलग गणना में उलझकर मुख्य विचार को खोए बिना छोटे उदाहरणों से आइगेनवैल्यू को पढ़ सकें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which comes up a lot in quantum mechanics.",
  "translatedText": "एक अन्य रोचक उदाहरण के रूप में, तीन अलग-अलग मैट्रिसेस के इस सेट पर नजर डालें, जो क्वांटम यांत्रिकी में अक्सर आता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 409.74,
  "end": 415.46
 },
 {
  "input": "They're known as the Pauli spin matrices.",
  "translatedText": "इन्हें पाउली स्पिन मैट्रिसेस के नाम से जाना जाता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 415.76,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you'll know that the eigenvalues of matrices are highly relevant to the physics that they describe.",
  "translatedText": "यदि आप क्वांटम यांत्रिकी जानते हैं, तो आपको पता होगा कि मैट्रिसेस के आइगेनवैल्यू उस भौतिकी के लिए अत्यधिक प्रासंगिक हैं जिसका वे वर्णन करते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.6,
  "end": 424.42
 },
 {
  "input": "And if you don't know quantum mechanics, let this just be a little glimpse of how these computations are actually very relevant to real applications.",
  "translatedText": "और यदि आप क्वांटम यांत्रिकी नहीं जानते, तो यह एक छोटी सी झलक मात्र है कि कैसे ये गणनाएं वास्तविक अनुप्रयोगों के लिए बहुत प्रासंगिक हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.22,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal entries in all three cases is zero.",
  "translatedText": "तीनों मामलों में विकर्ण प्रविष्टियों का माध्य शून्य है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 432.54,
  "end": 435.88
 },
 {
  "input": "So the mean of the eigenvalues in all of these cases is zero, which makes our formula look especially simple.",
  "translatedText": "अतः इन सभी मामलों में आइजेन वैल्यू का माध्य शून्य है, जिससे हमारा सूत्र विशेष रूप से सरल प्रतीत होता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 437.56,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices?",
  "translatedText": "इन आव्यूहों के निर्धारक, eigenvalues के उत्पादों के बारे में क्या? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it's 0, minus 1, or negative 1.",
  "translatedText": "पहले के लिए यह 0, माइनस 1, या नेगेटिव 1 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.7,
  "end": 452.56
 },
 {
  "input": "The second one also looks like 0, minus 1, but it takes a moment more to see because of the complex numbers.",
  "translatedText": "दूसरा भी 0, माइनस 1 जैसा दिखता है, लेकिन जटिल संख्याओं के कारण इसे देखने में कुछ क्षण अधिक लगता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.2,
  "end": 458.2
 },
 {
  "input": "And the final one looks like negative 1, minus 0.",
  "translatedText": "और अंतिम नकारात्मक 1 घटा 0 जैसा दिखता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be plus and minus 1.",
  "translatedText": "इसलिए सभी मामलों में, eigenvalues प्लस और माइनस 1 को सरल बनाते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don't need a formula to find two values if you know that they're evenly spaced around 0 and their product is negative 1.",
  "translatedText": "हालाँकि इस मामले में, आपको वास्तव में दो मान खोजने के लिए किसी सूत्र की आवश्यकता नहीं है यदि आप जानते हैं कि वे 0 के आसपास समान दूरी पर हैं और उनका उत्पाद नकारात्मक 1 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you're curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y, or z direction.",
  "translatedText": "यदि आप उत्सुक हैं, तो क्वांटम यांत्रिकी के संदर्भ में, ये मैट्रिसेस उन प्रेक्षणों का वर्णन करते हैं जो आप x, y, या z दिशा में किसी कण के घूर्णन के बारे में कर सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.12
 },
 {
  "input": "And the fact that their eigenvalues are plus and minus 1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between.",
  "translatedText": "और यह तथ्य कि उनके आइगेन वैल्यू प्लस और माइनस 1 हैं, इस विचार से मेल खाता है कि स्पिन के लिए जो मूल्य आप देखेंगे वह या तो पूरी तरह से एक दिशा में होगा या पूरी तरह से दूसरी दिशा में होगा, इसके विपरीत कुछ लगातार बीच में होता रहता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.56,
  "end": 497.02
 },
 {
  "input": "Maybe you'd wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions.",
  "translatedText": "शायद आप सोच रहे होंगे कि यह वास्तव में कैसे काम करता है, या आप तीन आयामों में स्पिन का वर्णन करने के लिए जटिल संख्याओं वाले 2x2 मैट्रिसेस का उपयोग क्यों करेंगे।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "Those would be fair questions, just outside the scope of what I want to talk about here.",
  "translatedText": "ये उचित प्रश्न होंगे, लेकिन मैं यहां जिस विषय पर बात करना चाहता हूं उसके दायरे से बाहर हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know, it's funny, I wrote this section because I wanted some case where you have 2x2 matrices that aren't just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that.",
  "translatedText": "आप जानते हैं, यह अजीब बात है, मैंने यह अनुभाग इसलिए लिखा क्योंकि मैं कुछ ऐसा मामला चाहता था जहां आपके पास 2x2 मैट्रिसेस हों जो केवल खिलौना उदाहरण या होमवर्क समस्याएं न हों, जहां वे वास्तव में व्यवहार में आते हैं, और क्वांटम यांत्रिकी इसके लिए बहुत अच्छी है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "The thing is, after I made it, I realized that the whole example kind of undercuts the point that I'm trying to make.",
  "translatedText": "बात यह है कि इसे बनाने के बाद मुझे एहसास हुआ कि यह पूरा उदाहरण उस बिंदु को कमजोर कर रहा है जिसे मैं बताने की कोशिश कर रहा था।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it's essentially just as fast.",
  "translatedText": "इन विशिष्ट मैट्रिसेस के लिए, जब आप पारंपरिक विधि, अर्थात् अभिलक्षणिक बहुपद वाली विधि का उपयोग करते हैं, तो यह मूलतः उतनी ही तेज होती है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 528.74,
  "end": 536.1
 },
 {
  "input": "It might actually be faster.",
  "translatedText": "यह वास्तव में अधिक तेज़ हो सकता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 536.22,
  "end": 537.64
 },
 {
  "input": "I mean, take a look at the first one.",
  "translatedText": "मेरा मतलब है, पहले वाले पर एक नज़र डालें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.24,
  "end": 539.4
 },
 {
  "input": "The relevant determinant directly gives you a characteristic polynomial of lambda squared minus 1, and clearly that has roots of plus and minus 1.",
  "translatedText": "प्रासंगिक निर्धारक आपको सीधे लैम्ब्डा स्क्वायर माइनस 1 का अभिलक्षणिक बहुपद देता है, और स्पष्ट रूप से इसके धनात्मक और ऋणात्मक 1 के मूल हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.68,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda squared minus 1.",
  "translatedText": "जब आप दूसरा मैट्रिक्स करते हैं तो वही उत्तर होता है, लैम्ब्डा का वर्ग शून्य से एक होता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it's already a diagonal matrix, so those diagonal entries are the eigenvalues.",
  "translatedText": "और जहां तक अंतिम मैट्रिक्स का प्रश्न है, किसी भी गणना, पारंपरिक या अन्य, के बारे में भूल जाइए, यह पहले से ही एक विकर्ण मैट्रिक्स है, इसलिए ये विकर्ण प्रविष्टियां आइगेन वैल्यू हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause.",
  "translatedText": "हालाँकि, यह उदाहरण हमारे उद्देश्य से पूरी तरह लुप्त नहीं हुआ है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speedup is in the more general case, where you take a linear combination of these three matrices and then try to compute the eigenvalues.",
  "translatedText": "जहां आप वास्तव में गति में वृद्धि महसूस करेंगे वह अधिक सामान्य स्थिति में है, जहां आप इन तीन मैट्रिसेस का एक रैखिक संयोजन लेते हैं और फिर आइगेन वैल्यू की गणना करने का प्रयास करते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third.",
  "translatedText": "आप इसे पहले वाले का गुना, दूसरे का जोड़ b का गुना, तीसरे का गुना c के रूप में लिख सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates a, b, c.",
  "translatedText": "क्वांटम यांत्रिकी में, यह निर्देशांक a, b, c वाले एक सदिश की सामान्य दिशा में स्पिन अवलोकन का वर्णन करेगा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume that this vector is normalized, meaning a squared plus b squared plus c squared is equal to 1.",
  "translatedText": "अधिक विशेष रूप से, आपको यह मान लेना चाहिए कि यह वेक्टर सामान्यीकृत है, जिसका अर्थ है कि एक वर्ग जमा बी वर्ग जमा सी वर्ग एक के बराबर है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it's immediate to see that the mean of the eigenvalues is still 0.",
  "translatedText": "जब आप इस नए मैट्रिक्स को देखते हैं, तो यह तुरंत पता चलता है कि आइजेन वैल्यू का माध्य अभी भी 0 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.6,
  "end": 604.1
 },
 {
  "input": "And you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still negative 1.",
  "translatedText": "और आप एक क्षण के लिए रुककर यह पुष्टि भी कर सकते हैं कि उन आइगेनवैल्यू का गुणनफल अभी भी ऋणात्मक 1 है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 604.6,
  "end": 610.9
 },
 {
  "input": "And then from there, concluding what the eigenvalues must be.",
  "translatedText": "और फिर वहां से यह निष्कर्ष निकालना कि आइगेन वैल्यू क्या होनी चाहिए।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 613.26,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head.",
  "translatedText": "और इस बार, विशेषता बहुपद दृष्टिकोण तुलनात्मक रूप से बहुत अधिक बोझिल होगा, निश्चित रूप से आपके दिमाग में इसे करना कठिन होगा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean product formula is not fundamentally different from finding roots of the characteristic polynomial.",
  "translatedText": "स्पष्ट रूप से कहें तो, माध्य गुणनफल सूत्र का उपयोग करना, अभिलक्षणिक बहुपद के मूल ज्ञात करने से मौलिक रूप से भिन्न नहीं है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 625.08,
  "end": 630.96
 },
 {
  "input": "I mean, it can't be, they're solving the same problem.",
  "translatedText": "मेरा मतलब है, ऐसा नहीं हो सकता, वे एक ही समस्या का समाधान कर रहे हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 631.34,
  "end": 633.44
 },
 {
  "input": "One way to think about this actually is that the mean product formula is a nice way to solve quadratics in general.",
  "translatedText": "इस बारे में सोचने का एक तरीका यह है कि माध्य गुणनफल सूत्र सामान्यतः द्विघात समीकरण को हल करने का एक अच्छा तरीका है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.16,
  "end": 639.02
 },
 {
  "input": "And some viewers of the channel may recognize this.",
  "translatedText": "और चैनल के कुछ दर्शक इसे पहचान सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 639.6,
  "end": 641.66
 },
 {
  "input": "Think about it, when you're trying to find the roots of a quadratic, given the coefficients, that's another situation where you know the sum of two values, and you also know their product, but you're trying to recover the original two values.",
  "translatedText": "इसके बारे में सोचें, जब आप दिए गए गुणांकों के साथ किसी द्विघात समीकरण के मूल ज्ञात करने का प्रयास कर रहे हैं, तो यह एक अन्य स्थिति है, जहां आप दो मानों का योग जानते हैं, और आपको उनका गुणनफल भी पता है, लेकिन आप मूल दो मानों को पुनः प्राप्त करने का प्रयास कर रहे हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized, so that this leading coefficient is 1, then the mean of the roots will be negative 1 half times this linear coefficient, which is negative 1 times the sum of those roots.",
  "translatedText": "विशेष रूप से, यदि बहुपद को सामान्यीकृत किया जाता है ताकि यह अग्रणी गुणांक एक हो, तो मूलों का माध्य इस रैखिक गुणांक का आधा गुना ऋणात्मक होगा, जो उन मूलों के योग का एक गुना ऋणात्मक है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "With the example on the screen, that makes the mean 5.",
  "translatedText": "स्क्रीन पर दिखाए गए उदाहरण से, माध्य 5 हो जाता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it's just the constant term, no adjustments needed.",
  "translatedText": "और मूलों का गुणनफल और भी आसान है, यह एक स्थिर पद है, इसमें किसी समायोजन की आवश्यकता नहीं है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula, and that gives you the roots.",
  "translatedText": "तो वहां से, आप माध्य गुणनफल सूत्र लागू करेंगे, और इससे आपको मूल प्राप्त होंगे।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "And on the one hand, you could think of this as a lighter weight version of the traditional quadratic formula.",
  "translatedText": "और एक ओर, आप इसे पारंपरिक द्विघात सूत्र के हल्के संस्करण के रूप में सोच सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is not just that it's fewer symbols to memorize, it's that each one of them carries more meaning with it.",
  "translatedText": "लेकिन वास्तविक लाभ सिर्फ यह नहीं है कि इसमें याद रखने के लिए कम प्रतीक हैं, बल्कि यह है कि उनमें से प्रत्येक अपने साथ अधिक अर्थ रखता है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "I mean, the whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "translatedText": "मेरा मतलब है, इस आइगेनवैल्यू युक्ति का पूरा मुद्दा यह है कि चूंकि आप मैट्रिक्स को देखकर सीधे माध्य और गुणनफल को पढ़ सकते हैं, इसलिए आपको अभिलक्षणिक बहुपद स्थापित करने के मध्यवर्ती चरण से गुजरने की आवश्यकता नहीं है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like.",
  "translatedText": "बहुपद कैसा दिखता है, इसके बारे में स्पष्ट रूप से सोचे बिना आप सीधे जड़ों को लिखने के लिए आगे बढ़ सकते हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that, we need a version of the quadratic formula where the terms carry some kind of meaning.",
  "translatedText": "लेकिन ऐसा करने के लिए, हमें द्विघात सूत्र के एक ऐसे संस्करण की आवश्यकता है जिसमें पदों का कोई न कोई अर्थ हो।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize this is a very specific trick for a very specific audience, but it's something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them.",
  "translatedText": "मैं जानता हूं कि यह एक बहुत ही विशिष्ट तरकीब है, जो विशेष दर्शकों के लिए है, लेकिन काश मुझे यह कॉलेज में पता होती, इसलिए यदि आप ऐसे किसी छात्र को जानते हैं, जो इससे लाभान्वित हो सकता है, तो इसे उनके साथ साझा करने पर विचार करें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it's not just one more thing that you memorize, but that the framing reinforces some other nice facts that are worth knowing, like how the trace and the determinant are related to eigenvalues.",
  "translatedText": "उम्मीद यह है कि यह सिर्फ एक और चीज नहीं है जिसे आप याद करते हैं, बल्कि यह कि फ्रेमिंग कुछ अन्य अच्छे तथ्यों को पुष्ट करती है जो जानने लायक हैं, जैसे कि ट्रेस और निर्धारक आइगेनवैल्यू से कैसे संबंधित हैं।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and then think hard about the meaning of each of these coefficients.",
  "translatedText": "वैसे, यदि आप इन तथ्यों को सिद्ध करना चाहते हैं, तो एक क्षण रुककर सामान्य मैट्रिक्स के लिए अभिलक्षणिक बहुपद का विस्तार करें, और फिर इनमें से प्रत्येक गुणांक के अर्थ के बारे में गहराई से सोचें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim for ensuring that this mean product formula will stay stuck in all of our heads for at least a few months.",
  "translatedText": "टिम को बहुत-बहुत धन्यवाद, जिन्होंने यह सुनिश्चित किया कि यह उत्पाद फार्मूला कम से कम कुछ महीनों तक हम सभी के दिमाग में रहेगा।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don't know about alcappella science, please do check it out.",
  "translatedText": "यदि आप अल्काप्पेला विज्ञान के बारे में नहीं जानते हैं, तो कृपया इसे अवश्य देखें।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "The molecular shape of you in particular is one of the greatest things on the internet.",
  "translatedText": "विशेषकर आपका आणविक आकार इंटरनेट पर सबसे महान चीजों में से एक है।",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]