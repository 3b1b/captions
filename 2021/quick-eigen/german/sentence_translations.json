[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices. ",
  "translatedText": "Dieses Video richtet sich an alle, die bereits wissen, was Eigenwerte und Eigenvektoren sind, und die vielleicht Lust haben, sie im Fall von 2x2-Matrizen schnell zu berechnen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you’re unfamiliar with eigenvalues, take a look at this video which introduces them. ",
  "translatedText": "Wenn du mit Eigenwerten nicht vertraut bist, schau dir dieses Video an, in dem sie erklärt werden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if you just want to see the trick, but if possible I’d like you to rediscover it for yourself, so for that let’s lay down a little background. ",
  "translatedText": "Wenn du nur den Trick sehen willst, kannst du weiterspringen, aber wenn möglich, möchte ich, dass du ihn selbst wiederentdeckst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale it by some constant, we call it an \"eigenvector\" of the transformation, and we call the relevant scaling factor the corresponding \"eigenvalue,\" often denoted with the letter lambda. ",
  "translatedText": "Zur Erinnerung: Wenn die Wirkung einer linearen Transformation auf einen bestimmten Vektor darin besteht, ihn um eine Konstante zu skalieren, nennen wir ihn einen \"Eigenvektor\" der Transformation und den entsprechenden Skalierungsfaktor den entsprechenden \"Eigenwert\", der oft mit dem Buchstaben Lambda bezeichnet wird.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix (A minus lambda times the identity) must send some nonzero vector, namely the corresponding eigenvector, to the zero vector, which in turn means the determinant of this modified matrix must be 0. ",
  "translatedText": "Wenn du das als Gleichung aufschreibst und ein bisschen umordnest, siehst du, dass, wenn die Zahl lambda ein Eigenwert einer Matrix A ist, die Matrix (A minus lambda mal die Identität) einen Nicht-Null-Vektor, nämlich den entsprechenden Eigenvektor, zum Nullvektor schicken muss, was wiederum bedeutet, dass die Determinante dieser veränderten Matrix 0 sein muss.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful to say, but again, I’m assuming all of this is review for anyone watching. ",
  "translatedText": "Okay, das ist alles ein bisschen viel gesagt, aber ich gehe davon aus, dass das alles für jeden, der zuschaut, eine Zusammenfassung ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it, and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals and then solve for when the determinant equals 0. ",
  "translatedText": "Die übliche Art, Eigenwerte zu berechnen, wie ich es früher gemacht habe und wie ich glaube, dass es den meisten Schülern beigebracht wird, ist, den unbekannten Wert Lambda von den Diagonalen abzuziehen und dann zu lösen, wenn die Determinante gleich 0 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few steps to expand out and simplify to get a clean quadratic polynomial, what's known as the “characteristic polynomial” of the matrix. ",
  "translatedText": "Dies erfordert immer einige Schritte zur Erweiterung und Vereinfachung, um ein reines quadratisches Polynom zu erhalten, das so genannte \"charakteristische Polynom\" der Matrix.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial. ",
  "translatedText": "Die Eigenwerte sind die Wurzeln dieses Polynoms.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 97.36,
  "end": 99.9
 },
 {
  "input": "So to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification. ",
  "translatedText": "Um sie zu finden, musst du also die quadratische Formel anwenden, die wiederum in der Regel ein oder zwei weitere Schritte der Vereinfachung erfordert.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 100.1,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn’t terrible. ",
  "translatedText": "Ehrlich gesagt, ist der Prozess nicht schrecklich.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.76,
  "end": 109.5
 },
 {
  "input": "But at least for 2x2 matrices, there’s a much more direct way to get at this answer. ",
  "translatedText": "Aber zumindest für 2x2-Matrizen gibt es einen viel direkteren Weg, um zu dieser Antwort zu kommen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 109.58,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there are only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem-solving. ",
  "translatedText": "Und wenn du diesen Trick wiederentdecken willst, gibt es nur drei relevante Fakten, die du wissen musst, von denen jeder für sich genommen wissenswert ist und dir bei anderen Problemlösungen helfen kann.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number 1: The trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues. ",
  "translatedText": "Nummer 1: Die Spur einer Matrix, die die Summe der beiden diagonalen Einträge ist, ist gleich der Summe der Eigenwerte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries. ",
  "translatedText": "Eine andere, für unsere Zwecke nützlichere Formulierung ist, dass der Mittelwert der beiden Eigenwerte gleich dem Mittelwert dieser beiden Diagonaleinträge ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number 2: The determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues. ",
  "translatedText": "Nummer 2: Die Determinante einer Matrix, unsere übliche ad-bc-Formel, ist gleich dem Produkt der beiden Eigenwerte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction and that the determinant describes how much an operator scales areas (or volumes) as a whole. ",
  "translatedText": "Das macht Sinn, wenn du verstehst, dass Eigenwerte beschreiben, wie stark ein Operator den Raum in eine bestimmte Richtung dehnt, und dass die Determinante beschreibt, wie stark ein Operator Flächen (oder Volumina) als Ganzes skaliert.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down. ",
  "translatedText": "Bevor wir nun zum dritten Fakt kommen, solltest du beachten, dass du die ersten beiden Werte aus der Matrix ablesen kannst, ohne viel aufzuschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example. ",
  "translatedText": "Nimm diese Matrix hier als Beispiel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7. ",
  "translatedText": "Du kannst sofort erkennen, dass der Mittelwert der Eigenwerte derselbe ist wie der Mittelwert von 8 und 6, also 7.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well-practiced at finding the determinant, which in this case works out to be 48 - 8 So right away you know that the product of our two eigenvalues is 40. ",
  "translatedText": "Die meisten Schülerinnen und Schüler, die lineare Algebra studieren, sind ziemlich geübt darin, die Determinante zu bestimmen, die in diesem Fall 48 - 8 beträgt. Du weißt also sofort, dass das Produkt unserer beiden Eigenwerte 40 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.58,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see how you can derive what will be our third relevant fact, which is how to recover two numbers when you know their mean and you know their product. ",
  "translatedText": "Nimm dir jetzt einen Moment Zeit, um zu sehen, wie du die dritte wichtige Tatsache ableiten kannst, nämlich wie du zwei Zahlen wiederherstellen kannst, wenn du ihren Mittelwert und ihr Produkt kennst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example. ",
  "translatedText": "Konzentrieren wir uns auf dieses Beispiel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know the two values are evenly spaced around 7, so they look like 7 plus or minus something; let’s call that something \"d\" for distance. ",
  "translatedText": "Du weißt, dass die beiden Werte gleichmäßig um 7 herum angeordnet sind, also sehen sie aus wie 7 plus oder minus etwas; nennen wir dieses Etwas \"d\" für Abstand.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40. ",
  "translatedText": "Du weißt auch, dass das Produkt dieser beiden Zahlen 40 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares. ",
  "translatedText": "Um nun d zu finden, beachte, dass sich dieses Produkt wirklich schön ausdehnt, es ergibt sich eine Differenz von Quadraten.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can directly find d: d^2 is 7^2 - 40, or 9, which means d itself is 3. ",
  "translatedText": "Von dort aus kannst du also direkt d finden: d^2 ist 7^2 - 40 oder 9, was bedeutet, dass d selbst 3 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.56,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10. ",
  "translatedText": "Mit anderen Worten: Die beiden Werte für dieses sehr spezielle Beispiel sind 4 und 10.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t want to think this through each time, so let’s wrap up what we just did in a general formula. ",
  "translatedText": "Aber unser Ziel ist ein schneller Trick, und du willst das nicht jedes Mal neu durchdenken, also lass uns das, was wir gerade gemacht haben, in eine allgemeine Formel packen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean, m and product, p, the distance squared is always going to be m^2 - p. ",
  "translatedText": "Für jeden Mittelwert m und jedes Produkt p ist der Abstand zum Quadrat immer m^2 - p.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly if you ever forget it, and it’s essentially just a rephrasing of the difference of squares formula. ",
  "translatedText": "Daraus ergibt sich die dritte wichtige Tatsache: Wenn zwei Zahlen einen Mittelwert m und ein Produkt p haben, kannst du diese beiden Zahlen als m ± sqrt(m^2 - p) schreiben. Dies ist schnell wieder abrufbar, wenn du es einmal vergessen hast, und ist im Grunde nur eine Umformulierung der Formel für die Differenz der Quadrate.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 257.56,
  "end": 277.08
 },
 {
  "input": "But even still it’s a fact worth memorizing so that you have it at the tip of your fingers. ",
  "translatedText": "Aber es lohnt sich trotzdem, diese Tatsache auswendig zu lernen, damit du sie immer parat hast.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel acapellascience wrote us a quick jingle to make it a little more memorable. ",
  "translatedText": "Mein Freund Tim vom Kanal acapellascience hat uns sogar einen kurzen Jingle geschrieben, um ihn ein bisschen einprägsamer zu machen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "m plus or minus squaaaare root of me squared minus p (ping!) Let me show you how this works, say for the matrix [[3,1], [4,1]]. ",
  "translatedText": "m plus oder minus Quadratwurzel aus mir zum Quadrat minus p (ping!) Ich zeige dir mal, wie das funktioniert, zum Beispiel für die Matrix [[3,1], [4,1]].",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head. ",
  "translatedText": "Du fängst damit an, dir die Formel ins Gedächtnis zu rufen und sie vielleicht in deinem Kopf aufzuschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values of m and p as you go. ",
  "translatedText": "Aber wenn du es aufschreibst, trägst du die entsprechenden Werte für m und p nach und nach ein.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2. ",
  "translatedText": "In diesem Beispiel ist der Mittelwert der Eigenwerte also derselbe wie der Mittelwert von 3 und 1, also 2.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.34,
  "end": 317.74
 },
 {
  "input": "So the thing you start writing is 2 ± sqrt(2^2 - …). ",
  "translatedText": "Das, was du zu schreiben beginnst, ist also 2 ± sqrt(2^2 - ...).",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 318.3,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3*1 - 1*4, or -1. ",
  "translatedText": "Dann ist das Produkt der Eigenwerte die Determinante, die in diesem Beispiel 3*1 - 1*4 oder -1 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.54,
  "end": 332.14
 },
 {
  "input": "So that’s the final thing you fill in. ",
  "translatedText": "Das ist also der letzte Punkt, den du ausfüllst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 332.38,
  "end": 334.48
 },
 {
  "input": "This means the eigenvalues are 2±sqrt(5). ",
  "translatedText": "Das bedeutet, dass die Eigenwerte 2±sqrt(5) sind.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 334.88,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer. ",
  "translatedText": "Du erkennst vielleicht, dass es sich um dieselbe Matrix handelt, die ich am Anfang verwendet habe, aber merke dir, wie viel direkter wir die Antwort bekommen können.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one. ",
  "translatedText": "Hier, versuch eine andere.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5. ",
  "translatedText": "Dieses Mal ist der Mittelwert der Eigenwerte derselbe wie der Mittelwert von 2 und 8, nämlich 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula but this time writing 5 in place of m [song]. ",
  "translatedText": "Also fängst du wieder an, die Formel aufzuschreiben, aber dieses Mal schreibst du 5 anstelle von m [Lied].",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2*8 - 7*1, or 9. ",
  "translatedText": "Und dann ist die Determinante 2*8 - 7*1, also 9.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which simplifies even further as 9 and 1. ",
  "translatedText": "In diesem Beispiel sehen die Eigenwerte also wie 5 ± sqrt(16) aus, was sich noch weiter zu 9 und 1 vereinfacht.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while staring at the matrix? ",
  "translatedText": "Verstehst du, was ich damit meine, dass du einfach anfangen kannst, die Eigenwerte aufzuschreiben, während du auf die Matrix starrst?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It’s typically just the tiniest bit of simplifying at the end. ",
  "translatedText": "Normalerweise ist es nur eine kleine Vereinfachung am Ende.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I’ve found myself using this trick a lot when I’m sketching quick notes related to linear algebra and want to use small matrices as examples. ",
  "translatedText": "Ehrlich gesagt, verwende ich diesen Trick oft, wenn ich schnelle Notizen zur linearen Algebra skizziere und kleine Matrizen als Beispiele verwenden möchte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I’ve been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realized it’s just very handy if students can read off the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation. ",
  "translatedText": "Ich habe an einem Video über Matrixexponenten gearbeitet, in dem Eigenwerte häufig vorkommen, und mir ist klar geworden, dass es sehr praktisch ist, wenn die Schüler die Eigenwerte von kleinen Beispielen ablesen können, ohne den roten Faden zu verlieren, weil sie sich in einer anderen Berechnung verzetteln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which come up a lot in quantum mechanics, they're known as the Pauli spin matrices. ",
  "translatedText": "Ein weiteres unterhaltsames Beispiel sind die drei verschiedenen Matrizen, die in der Quantenmechanik häufig vorkommen, die sogenannten Pauli-Spin-Matrizen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 409.74,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you’ll know that the eigenvalues of matrices are highly relevant to the physics they describe, and if you don’t know quantum mechanics, let this just be a little glimpse of how these computations are actually relevant to real applications. ",
  "translatedText": "Wenn du dich mit Quantenmechanik auskennst, weißt du, dass die Eigenwerte von Matrizen für die Physik, die sie beschreiben, von großer Bedeutung sind. Wenn du dich nicht mit Quantenmechanik auskennst, soll dies nur ein kleiner Einblick sein, wie diese Berechnungen tatsächlich für reale Anwendungen relevant sind.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.6,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal in all three cases is 0, so the mean of the eigenvalues in all cases is 0, which makes our formula look especially simple. ",
  "translatedText": "Der Mittelwert der Diagonalen ist in allen drei Fällen 0, also ist auch der Mittelwert der Eigenwerte in allen Fällen 0, was unsere Formel besonders einfach aussehen lässt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 432.54,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices? ",
  "translatedText": "Was ist mit den Produkten der Eigenwerte, den Determinanten dieser Matrizen?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1. ",
  "translatedText": "Bei der ersten ist es 0 - 1 oder -1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.7,
  "end": 453.4
 },
 {
  "input": "The second also looks like 0 - 1, but it takes a moment more to see because of the complex numbers. ",
  "translatedText": "Die zweite sieht auch wie 0 - 1 aus, aber es dauert einen Moment länger, um sie zu erkennen, weil es sich um komplexe Zahlen handelt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.4,
  "end": 458.2
 },
 {
  "input": "And the final one looks like -1 - 0. ",
  "translatedText": "Und das Ergebnis sieht aus wie -1 - 0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be ±1. ",
  "translatedText": "In allen Fällen vereinfachen sich die Eigenwerte also auf ±1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don’t need the formula to find two values if you know theyr'e evenly spaced around 0 and their product is -1. ",
  "translatedText": "Aber in diesem Fall brauchst du die Formel nicht, um zwei Werte zu finden, wenn du weißt, dass sie gleichmäßig um 0 herum angeordnet sind und ihr Produkt -1 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you’re curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y or z directions. ",
  "translatedText": "Wenn du neugierig bist: Im Kontext der Quantenmechanik beschreiben diese Matrizen Beobachtungen, die du über den Spin eines Teilchens in x-, y- oder z-Richtung machen kannst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.76
 },
 {
  "input": "The fact that their eigenvalues are ±1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between. ",
  "translatedText": "Die Tatsache, dass ihre Eigenwerte ±1 sind, entspricht der Vorstellung, dass die Werte für den Spin, die du beobachten würdest, entweder ganz in der einen oder ganz in der anderen Richtung liegen würden, im Gegensatz zu etwas, das kontinuierlich dazwischen liegt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.76,
  "end": 497.02
 },
 {
  "input": "Maybe you’d wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions. ",
  "translatedText": "Vielleicht fragst du dich, wie genau das funktioniert oder warum man 2x2 Matrizen mit komplexen Zahlen verwendet, um den Spin in drei Dimensionen zu beschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "And those would be fair questions, just outside the scope of what I want to talk about here. ",
  "translatedText": "Und das sind berechtigte Fragen, die den Rahmen dessen, worüber ich hier sprechen möchte, sprengen würden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know it’s funny, I wrote this section because I wanted some case where you have 2x2 matrices that are not just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that. ",
  "translatedText": "Weißt du, es ist witzig, ich habe diesen Abschnitt geschrieben, weil ich einen Fall haben wollte, in dem du 2x2-Matrizen hast, die nicht nur ein Spielzeug oder eine Hausaufgabe sind, sondern tatsächlich in der Praxis vorkommen, und dafür ist die Quantenmechanik hervorragend geeignet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "But the thing is after I made it I realized that the whole example kind of undercuts the point I’m trying to make. ",
  "translatedText": "Aber nachdem ich es gemacht habe, habe ich gemerkt, dass das ganze Beispiel den Punkt, den ich zu machen versuche, irgendwie untergräbt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; it might actually faster. ",
  "translatedText": "Wenn du für diese speziellen Matrizen die traditionelle Methode mit charakteristischen Polynomen verwendest, ist sie im Grunde genauso schnell, vielleicht sogar schneller.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 528.74,
  "end": 537.64
 },
 {
  "input": "I mean, take a look a the first one: The relevant determinant directly gives you a characteristic polynomial of lambda^2 - 1, and clearly, that has roots of plus and minus 1. ",
  "translatedText": "Ich meine, schau dir die erste an: Die entsprechende Determinante gibt dir direkt ein charakteristisches Polynom von lambda^2 - 1, und das hat eindeutig Wurzeln von plus und minus 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.24,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda^2 - 1. ",
  "translatedText": "Die gleiche Antwort erhältst du, wenn du die zweite Matrix, lambda^2 - 1, verwendest.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it’s already a diagonal matrix, so those diagonal entries are the eigenvalues! ",
  "translatedText": "Und was die letzte Matrix angeht, vergiss die traditionellen Berechnungen. Sie ist bereits eine Diagonalmatrix, also sind die diagonalen Einträge die Eigenwerte!",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause. ",
  "translatedText": "Das Beispiel ist jedoch nicht völlig verloren.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speed up is in the more general case where you take a linear combination of these three matrices and then try to compute the eigenvalues. ",
  "translatedText": "Der eigentliche Geschwindigkeitsvorteil ergibt sich in dem allgemeineren Fall, in dem du eine Linearkombination dieser drei Matrizen nimmst und dann versuchst, die Eigenwerte zu berechnen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third. ",
  "translatedText": "Du könntest das so schreiben: a mal das erste, plus b mal das zweite, plus c mal das dritte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates [a, b, c]. ",
  "translatedText": "In der Quantenmechanik würde dies Spin-Beobachtungen in einer allgemeinen Richtung eines Vektors mit den Koordinaten [a, b, c] beschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume this vector is normalized, meaning a^2 + b^2 + c^2 = 1. ",
  "translatedText": "Genauer gesagt solltest du davon ausgehen, dass dieser Vektor normalisiert ist, also a^2 + b^2 + c^2 = 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it’s immediate to see that the mean of the eigenvalues is still zero, and you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still -1, and then from there concluding what the eigenvalues must be. ",
  "translatedText": "Wenn du dir diese neue Matrix ansiehst, siehst du sofort, dass der Mittelwert der Eigenwerte immer noch Null ist. Du könntest auch kurz innehalten, um dir zu vergewissern, dass das Produkt dieser Eigenwerte immer noch -1 ist, und dann daraus schließen, was die Eigenwerte sein müssen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.6,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head. ",
  "translatedText": "Und dieses Mal wäre der charakteristische Polynom-Ansatz im Vergleich dazu viel umständlicher und definitiv schwieriger im Kopf zu erledigen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean-product formula is not fundamentally different from finding roots of the characteristic polynomial; I mean, it can't be, they're solving the same problem. ",
  "translatedText": "Um das klarzustellen: Die Formel für das mittlere Produkt unterscheidet sich nicht grundlegend von der Suche nach den Wurzeln des charakteristischen Polynoms; das kann nicht sein, denn sie lösen dasselbe Problem.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 625.08,
  "end": 633.44
 },
 {
  "input": "One way to think about this, actually, is that the mean-product formula is a nice way to solve quadratic in general (and some viewers of the channel may recognize this). ",
  "translatedText": "Eine Möglichkeit, darüber nachzudenken, ist, dass die Mittelwert-Produkt-Formel ein guter Weg ist, um quadratische Aufgaben zu lösen (und einige Zuschauer des Kanals werden das vielleicht erkennen).",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.16,
  "end": 641.66
 },
 {
  "input": "This about it: When you’re trying to find the roots of a quadratic given its coefficients, that's another situation where you know the sum of two values, and you also know their product, but you’re trying to recover the original two values. ",
  "translatedText": "So sieht es aus: Wenn du versuchst, die Wurzeln einer Quadratwurzel anhand ihrer Koeffizienten zu finden, ist das eine weitere Situation, in der du die Summe von zwei Werten kennst und auch ihr Produkt, aber du versuchst, die ursprünglichen zwei Werte wiederherzustellen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized so that this leading coefficient is 1, then the mean of the roots will be -½ times this linear coefficient, which is -1 times the sum of those roots. ",
  "translatedText": "Wenn das Polynom so normalisiert wird, dass der führende Koeffizient 1 ist, ist der Mittelwert der Wurzeln das -½-fache dieses linearen Koeffizienten, also das -1-fache der Summe dieser Wurzeln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "For the example on the screen that makes the mean 5. ",
  "translatedText": "Für das Beispiel auf dem Bildschirm ergibt das den Mittelwert 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it’s just the constant term no adjustments needed. ",
  "translatedText": "Und das Produkt der Wurzeln ist sogar noch einfacher, es ist nur der konstante Begriff, keine Anpassungen nötig.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula and that gives you the roots. ",
  "translatedText": "Von dort aus wendest du also die Formel für das mittlere Produkt an und erhältst so die Wurzeln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "On the one hand, you could think of this as a lighter-weight version of the traditional quadratic formula. ",
  "translatedText": "Einerseits kannst du dir das als eine leichtere Version der traditionellen quadratischen Formel vorstellen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is that it's fewer symbols to memorize, it's that each one of them carries more meaning with it. ",
  "translatedText": "Aber der eigentliche Vorteil ist, dass man sich weniger Symbole merken muss, sondern dass jedes einzelne von ihnen mehr Bedeutung mit sich bringt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "The whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial. ",
  "translatedText": "Der Sinn dieses Eigenwerttricks besteht darin, dass du den Mittelwert und das Produkt direkt aus der Matrix ablesen kannst, ohne den Zwischenschritt des charakteristischen Polynoms zu machen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like. ",
  "translatedText": "Du kannst direkt mit dem Aufschreiben der Wurzeln beginnen, ohne dir vorher Gedanken darüber zu machen, wie das Polynom aussieht.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that we need a version of the quadratic formula where the terms carry some kind of meaning. ",
  "translatedText": "Aber dafür brauchen wir eine Version der quadratischen Formel, in der die Begriffe eine Bedeutung haben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize that this is a very specific trick, for a very specific audience, but it’s something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them. ",
  "translatedText": "Mir ist klar, dass dies ein sehr spezieller Trick für ein sehr spezielles Publikum ist, aber ich wünschte, ich hätte ihn schon in der Schule gekannt. Wenn du also Schüler kennst, die davon profitieren könnten, solltest du ihn mit ihnen teilen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it’s not just one more thing to memorize, but that the framing reinforces some other nice facts worth knowing, like how the trace and determinant relate to eigenvalues. ",
  "translatedText": "Die Hoffnung ist, dass es nicht nur eine weitere Sache ist, die man auswendig lernen muss, sondern dass der Rahmen einige andere schöne Fakten verstärkt, die man wissen sollte, z.B. wie die Spur und die Determinante mit den Eigenwerten zusammenhängen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and think hard about the meaning of each of these coefficients. ",
  "translatedText": "Wenn du diese Fakten beweisen willst, nimm dir übrigens einen Moment Zeit, um das charakteristische Polynom für eine allgemeine Matrix zu erweitern, und denke gründlich über die Bedeutung der einzelnen Koeffizienten nach.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim, for ensuring that this mean-product formula will stay stuck in all of our heads for at least a few months. ",
  "translatedText": "Vielen Dank an Tim, dass er dafür gesorgt hat, dass diese fiese Produktformel für mindestens ein paar Monate in unseren Köpfen hängen bleibt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don’t know about acapellascience, please do check it out. ",
  "translatedText": "Wenn du acapellascience noch nicht kennst, solltest du es dir unbedingt ansehen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "\"The Molecular Shape of You\", in particular, is one of the greatest things on the internet. ",
  "translatedText": "Vor allem \"The Molecular Shape of You\" ist eine der besten Sachen im Internet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]