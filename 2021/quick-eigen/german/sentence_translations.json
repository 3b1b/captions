[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices. ",
  "translatedText": "Dies ist ein Video für alle, die bereits wissen, was Eigenwerte und Eigenvektoren sind, und denen es Spaß machen könnte, diese im Fall von 2x2-Matrizen schnell zu berechnen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you’re unfamiliar with eigenvalues, take a look at this video which introduces them. ",
  "translatedText": "Wenn Sie mit Eigenwerten nicht vertraut sind, schauen Sie sich dieses Video hier an, das eigentlich dazu gedacht ist, sie vorzustellen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if you just want to see the trick, but if possible I’d like you to rediscover it for yourself, so for that let’s lay down a little background. ",
  "translatedText": "Sie können weitermachen, wenn Sie den Trick nur sehen möchten, aber wenn möglich, möchte ich, dass Sie ihn selbst wiederentdecken. Lassen Sie uns dazu einen kleinen Hintergrund erläutern. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.68,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale it by some constant, we call it an \"eigenvector\" of the transformation, and we call the relevant scaling factor the corresponding \"eigenvalue,\" often denoted with the letter lambda. ",
  "translatedText": "Zur Erinnerung: Wenn die Wirkung einer linearen Transformation auf einen gegebenen Vektor darin besteht, diesen Vektor um eine Konstante zu skalieren, nennen wir ihn einen Eigenvektor der Transformation und den entsprechenden Skalierungsfaktor nennen wir den entsprechenden Eigenwert, der oft mit dem Buchstaben bezeichnet wird Lambda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix (A minus lambda times the identity) must send some nonzero vector, namely the corresponding eigenvector, to the zero vector, which in turn means the determinant of this modified matrix must be 0. ",
  "translatedText": "Wenn Sie dies als Gleichung schreiben und ein wenig umordnen, sehen Sie, dass, wenn die Zahl Lambda ein Eigenwert einer Matrix A ist, die Matrix A minus Lambda mal der Identität einen Vektor ungleich Null senden muss, nämlich den entsprechenden Eigenvektor zum Nullvektor, was wiederum bedeutet, dass die Determinante dieser modifizierten Matrix Null sein muss. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful to say, but again, I’m assuming all of this is review for anyone watching. ",
  "translatedText": "Okay, das ist alles etwas übertrieben, aber ich gehe auch hier davon aus, dass dies alles eine Rezension für jeden von euch ist, der zuschaut. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it, and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals and then solve for when the determinant equals 0. ",
  "translatedText": "Die übliche Art und Weise, Eigenwerte zu berechnen, wie ich es früher gemacht habe und wie ich glaube, wie es den meisten Schülern beigebracht wird, besteht darin, den unbekannten Wert Lambda von den Diagonalen zu subtrahieren und dann aufzulösen, wann die Determinante gleich Null ist . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few steps to expand out and simplify to get a clean quadratic polynomial, what's known as the “characteristic polynomial” of the matrix. ",
  "translatedText": "Dies erfordert immer ein paar zusätzliche Schritte zur Erweiterung und Vereinfachung, um ein sauberes quadratisches Polynom zu erhalten, das sogenannte charakteristische Polynom der Matrix. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial. ",
  "translatedText": "Die Eigenwerte sind die Wurzeln dieses Polynoms. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.36,
  "end": 99.9
 },
 {
  "input": "So to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification. ",
  "translatedText": "Um sie zu finden, muss man also die quadratische Formel anwenden, die wiederum normalerweise ein oder zwei weitere Vereinfachungsschritte erfordert. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 100.1,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn’t terrible. ",
  "translatedText": "Ehrlich gesagt ist der Prozess nicht schrecklich. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.76,
  "end": 109.5
 },
 {
  "input": "But at least for 2x2 matrices, there’s a much more direct way to get at this answer. ",
  "translatedText": "Aber zumindest für 2x2-Matrizen gibt es einen viel direkteren Weg, zu dieser Antwort zu gelangen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 109.58,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there are only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem-solving. ",
  "translatedText": "Und wenn Sie diesen Trick wiederentdecken möchten, müssen Sie nur drei relevante Fakten kennen, die jeweils für sich wissenswert sind und Ihnen bei der Lösung anderer Probleme helfen können. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number 1: The trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues. ",
  "translatedText": "Erstens ist die Spur einer Matrix, die die Summe dieser beiden Diagonaleinträge ist, gleich der Summe der Eigenwerte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries. ",
  "translatedText": "Oder anders ausgedrückt, was für unsere Zwecke nützlicher ist: Der Mittelwert der beiden Eigenwerte ist derselbe wie der Mittelwert dieser beiden diagonalen Einträge. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number 2: The determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues. ",
  "translatedText": "Zweitens ist die Determinante einer Matrix, unsere übliche ad-bc-Formel, gleich dem Produkt der beiden Eigenwerte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction and that the determinant describes how much an operator scales areas (or volumes) as a whole. ",
  "translatedText": "Und das sollte einigermaßen Sinn machen, wenn man versteht, dass Eigenwerte beschreiben, wie stark ein Operator den Raum in eine bestimmte Richtung ausdehnt, und dass die Determinante beschreibt, wie stark ein Operator Flächen oder Volumina als Ganzes skaliert. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down. ",
  "translatedText": "Bevor wir nun zur dritten Tatsache kommen, beachten Sie, dass Sie diese ersten beiden Werte im Wesentlichen aus der Matrix ablesen können, ohne wirklich viel aufzuschreiben. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example. ",
  "translatedText": "Nehmen Sie diese Matrix hier als Beispiel. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7. ",
  "translatedText": "Sie können sofort erkennen, dass der Mittelwert der Eigenwerte derselbe ist wie der Mittelwert von 8 und 6, also 7. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well-practiced at finding the determinant, which in this case works out to be 48 - 8 So right away you know that the product of our two eigenvalues is 40. ",
  "translatedText": "Ebenso sind die meisten Studenten der linearen Algebra ziemlich geübt darin, die Determinante zu finden, die sich in diesem Fall als 48 minus 8 ergibt. Sie wissen also sofort, dass das Produkt der beiden Eigenwerte 40 ist. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.58,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see how you can derive what will be our third relevant fact, which is how to recover two numbers when you know their mean and you know their product. ",
  "translatedText": "Nehmen Sie sich nun einen Moment Zeit, um zu sehen, ob Sie unsere dritte relevante Tatsache ableiten können, nämlich wie Sie zwei Zahlen schnell wiederherstellen können, wenn Sie ihren Mittelwert und ihr Produkt kennen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example. ",
  "translatedText": "Konzentrieren wir uns hier auf dieses Beispiel. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know the two values are evenly spaced around 7, so they look like 7 plus or minus something; let’s call that something \"d\" for distance. ",
  "translatedText": "Sie wissen, dass die beiden Werte gleichmäßig um die Zahl 7 verteilt sind, also wie 7 plus oder minus etwas aussehen, nennen wir das etwas d für Distanz. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40. ",
  "translatedText": "Sie wissen auch, dass das Produkt dieser beiden Zahlen 40 ist. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares. ",
  "translatedText": "Um nun d zu finden, beachten Sie, dass sich dieses Produkt sehr gut ausdehnt, es ergibt sich als Differenz von Quadraten. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can directly find d: d^2 is 7^2 - 40, or 9, which means d itself is 3. ",
  "translatedText": "Von dort aus können Sie also direkt d finden. d zum Quadrat ist 7 zum Quadrat minus 40 oder 9, was bedeutet, dass d selbst 3 ist. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.56,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10. ",
  "translatedText": "Mit anderen Worten: Die beiden Werte für dieses sehr spezielle Beispiel betragen 4 und 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t want to think this through each time, so let’s wrap up what we just did in a general formula. ",
  "translatedText": "Aber unser Ziel ist ein schneller Trick, und Sie möchten nicht jedes Mal darüber nachdenken, also fassen wir das, was wir gerade gemacht haben, in einer allgemeinen Formel zusammen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean, m and product, p, the distance squared is always going to be m^2 - p. ",
  "translatedText": "Für jeden Mittelwert m und jedes Produkt p ist das Distanzquadrat immer m zum Quadrat minus p. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly if you ever forget it, and it’s essentially just a rephrasing of the difference of squares formula. ",
  "translatedText": "Dies ergibt die dritte wichtige Tatsache: Wenn zwei Zahlen einen Mittelwert m und ein Produkt p haben, können Sie diese beiden Zahlen als m plus oder minus der Quadratwurzel von m zum Quadrat minus p schreiben. Dies lässt sich ziemlich schnell im Handumdrehen wieder herleiten, falls Sie es jemals vergessen, und es handelt sich im Wesentlichen nur um eine Umformulierung der Formel für die Differenz der Quadrate. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.56,
  "end": 277.08
 },
 {
  "input": "But even still it’s a fact worth memorizing so that you have it at the tip of your fingers. ",
  "translatedText": "Dennoch ist es eine Tatsache, die es wert ist, im Gedächtnis zu bleiben, sodass Sie sie immer zur Hand haben. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel acapellascience wrote us a quick jingle to make it a little more memorable. ",
  "translatedText": "Tatsächlich hat uns mein Freund Tim vom Sender A Capella Science einen netten kurzen Jingle geschrieben, um es ein bisschen unvergesslicher zu machen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "m plus or minus squaaaare root of me squared minus p (ping!) Let me show you how this works, say for the matrix [[3,1], [4,1]]. ",
  "translatedText": "Lassen Sie mich Ihnen zeigen, wie das funktioniert, beispielsweise für die Matrix 3, 1, 4, 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head. ",
  "translatedText": "Sie beginnen damit, dass Sie sich die Formel ins Gedächtnis rufen und vielleicht alles in Ihrem Kopf formulieren. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values of m and p as you go. ",
  "translatedText": "Aber wenn Sie es aufschreiben, geben Sie nach und nach die entsprechenden Werte für m und p ein. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2. ",
  "translatedText": "In diesem Beispiel ist der Mittelwert der Eigenwerte also derselbe wie der Mittelwert von 3 und 1, also 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 312.34,
  "end": 317.74
 },
 {
  "input": "So the thing you start writing is 2 ± sqrt(2^2 - …). ",
  "translatedText": "Sie beginnen also mit dem Schreiben von 2 ± sqrt(2^2 - …). ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.3,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3*1 - 1*4, or -1. ",
  "translatedText": "Dann ist das Produkt der Eigenwerte die Determinante, die in diesem Beispiel 3*1 - 1*4 oder -1 beträgt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.54,
  "end": 332.14
 },
 {
  "input": "So that’s the final thing you fill in. ",
  "translatedText": "Das ist also das Letzte, was Sie ausfüllen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.38,
  "end": 334.48
 },
 {
  "input": "This means the eigenvalues are 2±sqrt(5). ",
  "translatedText": "Das bedeutet, dass die Eigenwerte 2±sqrt(5) sind. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.88,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer. ",
  "translatedText": "Sie erkennen vielleicht, dass es sich hierbei um dieselbe Matrix handelt, die ich zu Beginn verwendet habe, aber beachten Sie, wie viel direkter wir zur Antwort gelangen können. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one. ",
  "translatedText": "Hier, versuchen Sie es mit einem anderen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5. ",
  "translatedText": "Diesmal ist der Mittelwert der Eigenwerte derselbe wie der Mittelwert von 2 und 8, also 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula but this time writing 5 in place of m [song]. ",
  "translatedText": "Also fängst du wieder an, die Formel aufzuschreiben, aber dieses Mal schreibst du 5 anstelle von m [Lied]. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2*8 - 7*1, or 9. ",
  "translatedText": "Und dann ist die Determinante 2*8 - 7*1 oder 9. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which simplifies even further as 9 and 1. ",
  "translatedText": "In diesem Beispiel sehen die Eigenwerte also wie 5 ± sqrt(16) aus, was sich noch weiter vereinfacht als 9 und 1 ergibt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while staring at the matrix? ",
  "translatedText": "Verstehen Sie, was ich damit meine, dass Sie im Grunde mit dem Aufschreiben der Eigenwerte beginnen können, während Sie auf die Matrix starren? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It’s typically just the tiniest bit of simplifying at the end. ",
  "translatedText": "Normalerweise handelt es sich am Ende nur um die kleinste Vereinfachung. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I’ve found myself using this trick a lot when I’m sketching quick notes related to linear algebra and want to use small matrices as examples. ",
  "translatedText": "Ehrlich gesagt habe ich diesen Trick häufig verwendet, wenn ich kurze Notizen zur linearen Algebra skizziere und kleine Matrizen als Beispiele verwenden möchte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I’ve been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realized it’s just very handy if students can read off the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation. ",
  "translatedText": "Ich habe an einem Video über Matrixexponenten gearbeitet, in dem Eigenwerte häufig auftauchen, und mir ist klar geworden, dass es einfach sehr praktisch ist, wenn Schüler die Eigenwerte aus kleinen Beispielen herauslesen können, ohne den Hauptgedankenweg zu verlieren, indem sie sich in einem anderen verzetteln Berechnung. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which come up a lot in quantum mechanics, they're known as the Pauli spin matrices. ",
  "translatedText": "Schauen Sie sich als weiteres unterhaltsames Beispiel diesen Satz aus drei verschiedenen Matrizen an, der in der Quantenmechanik häufig vorkommt. Sie sind als Pauli-Spinmatrizen bekannt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.74,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you’ll know that the eigenvalues of matrices are highly relevant to the physics they describe, and if you don’t know quantum mechanics, let this just be a little glimpse of how these computations are actually relevant to real applications. ",
  "translatedText": "Wenn Sie sich mit der Quantenmechanik auskennen, wissen Sie, dass die Eigenwerte von Matrizen für die von ihnen beschriebene Physik von großer Bedeutung sind. Und wenn Sie sich mit Quantenmechanik nicht auskennen, geben Sie mir hier einen kleinen Einblick in die große Bedeutung dieser Berechnungen für reale Anwendungen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.6,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal in all three cases is 0, so the mean of the eigenvalues in all cases is 0, which makes our formula look especially simple. ",
  "translatedText": "Der Mittelwert der diagonalen Einträge ist in allen drei Fällen Null. Der Mittelwert der Eigenwerte ist also in all diesen Fällen Null, was unsere Formel besonders einfach erscheinen lässt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.54,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices? ",
  "translatedText": "Was ist mit den Produkten der Eigenwerte, den Determinanten dieser Matrizen? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1. ",
  "translatedText": "Für die erste ist es 0 minus 1 oder minus 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.7,
  "end": 453.4
 },
 {
  "input": "The second also looks like 0 - 1, but it takes a moment more to see because of the complex numbers. ",
  "translatedText": "Das zweite sieht ebenfalls aus wie 0 minus 1, aber aufgrund der komplexen Zahlen dauert es einen Moment länger, bis man es erkennt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.4,
  "end": 458.2
 },
 {
  "input": "And the final one looks like -1 - 0. ",
  "translatedText": "Und das letzte sieht aus wie minus 1 minus 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be ±1. ",
  "translatedText": "In allen Fällen betragen die Eigenwerte also vereinfacht plus und minus 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don’t need the formula to find two values if you know theyr'e evenly spaced around 0 and their product is -1. ",
  "translatedText": "Allerdings benötigen Sie in diesem Fall wirklich keine Formel, um zwei Werte zu finden, wenn Sie wissen, dass sie gleichmäßig um 0 herum liegen und ihr Produkt negativ 1 ist. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you’re curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y or z directions. ",
  "translatedText": "Wenn Sie neugierig sind: Im Kontext der Quantenmechanik beschreiben diese Matrizen Beobachtungen, die Sie möglicherweise über den Spin eines Teilchens in x-, y- oder z-Richtung machen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.76
 },
 {
  "input": "The fact that their eigenvalues are ±1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between. ",
  "translatedText": "Und die Tatsache, dass ihre Eigenwerte plus und minus 1 sind, entspricht der Vorstellung, dass die Werte für den Spin, die Sie beobachten würden, entweder vollständig in eine Richtung oder vollständig in eine andere Richtung verlaufen würden, im Gegensatz zu etwas, das kontinuierlich dazwischen liegt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.76,
  "end": 497.02
 },
 {
  "input": "Maybe you’d wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions. ",
  "translatedText": "Vielleicht fragen Sie sich, wie das genau funktioniert oder warum Sie 2x2-Matrizen mit komplexen Zahlen verwenden, um den Spin in drei Dimensionen zu beschreiben. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "And those would be fair questions, just outside the scope of what I want to talk about here. ",
  "translatedText": "Und das wären berechtigte Fragen, die knapp außerhalb des Rahmens dessen liegen, worüber ich hier sprechen möchte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know it’s funny, I wrote this section because I wanted some case where you have 2x2 matrices that are not just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that. ",
  "translatedText": "Wissen Sie, es ist lustig, ich habe diesen Abschnitt geschrieben, weil ich einen Fall haben wollte, in dem es 2x2-Matrizen gibt, die nicht nur Spielzeugbeispiele oder Hausaufgaben sind, sondern solche, bei denen sie tatsächlich in der Praxis auftauchen, und die Quantenmechanik ist dafür großartig. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "But the thing is after I made it I realized that the whole example kind of undercuts the point I’m trying to make. ",
  "translatedText": "Aber die Sache ist die: Nachdem ich es gemacht hatte, wurde mir klar, dass das ganze Beispiel den Punkt, den ich ansprechen wollte, irgendwie untergräbt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; it might actually faster. ",
  "translatedText": "Für diese speziellen Matrizen ist die herkömmliche Methode mit charakteristischen Polynomen im Wesentlichen genauso schnell. Es könnte tatsächlich schneller sein. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.74,
  "end": 537.64
 },
 {
  "input": "I mean, take a look a the first one: The relevant determinant directly gives you a characteristic polynomial of lambda^2 - 1, and clearly, that has roots of plus and minus 1. ",
  "translatedText": "Ich meine, schauen Sie sich das erste an. Die relevante Determinante liefert direkt ein charakteristisches Polynom vom Lambda-Quadrat minus eins, und das hat offensichtlich Wurzeln von plus und minus eins. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.24,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda^2 - 1. ",
  "translatedText": "Dieselbe Antwort, wenn Sie die zweite Matrix erstellen, Lambda-Quadrat minus eins. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it’s already a diagonal matrix, so those diagonal entries are the eigenvalues! ",
  "translatedText": "Und was die letzte Matrix betrifft, vergessen Sie jegliche Berechnungen, ob traditionell oder nicht, sie ist bereits eine Diagonalmatrix, also sind diese Diagonaleinträge die Eigenwerte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause. ",
  "translatedText": "Allerdings geht das Beispiel für unsere Sache nicht völlig verloren. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speed up is in the more general case where you take a linear combination of these three matrices and then try to compute the eigenvalues. ",
  "translatedText": "Sie werden die Beschleunigung tatsächlich im allgemeineren Fall spüren, wenn Sie eine lineare Kombination dieser drei Matrizen nehmen und dann versuchen, die Eigenwerte zu berechnen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third. ",
  "translatedText": "Sie könnten dies schreiben als a mal das erste, plus b mal das zweite, plus c mal das dritte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates [a, b, c]. ",
  "translatedText": "In der Quantenmechanik würde dies Spinbeobachtungen in einer allgemeinen Richtung eines Vektors mit den Koordinaten a, b, c beschreiben. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume this vector is normalized, meaning a^2 + b^2 + c^2 = 1. ",
  "translatedText": "Genauer gesagt sollten Sie davon ausgehen, dass dieser Vektor normalisiert ist, was bedeutet, dass a zum Quadrat plus b zum Quadrat plus c zum Quadrat gleich eins ist. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it’s immediate to see that the mean of the eigenvalues is still zero, and you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still -1, and then from there concluding what the eigenvalues must be. ",
  "translatedText": "Wenn Sie sich diese neue Matrix ansehen, sehen Sie sofort, dass der Mittelwert der Eigenwerte immer noch Null ist, und Sie können auch gerne einen kurzen Moment innehalten, um zu bestätigen, dass das Produkt dieser Eigenwerte immer noch negativ Eins ist. Und dann daraus schließen, was die Eigenwerte sein müssen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.6,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head. ",
  "translatedText": "Und dieses Mal wäre der charakteristische Polynomansatz im Vergleich dazu viel umständlicher und definitiv schwieriger im Kopf umzusetzen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean-product formula is not fundamentally different from finding roots of the characteristic polynomial; I mean, it can't be, they're solving the same problem. ",
  "translatedText": "Um es klarzustellen: Die Verwendung der Mittelwertproduktformel unterscheidet sich nicht vom Finden von Wurzeln des charakteristischen Polynoms. Ich meine, das kann nicht sein, sie lösen das gleiche Problem. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.08,
  "end": 633.44
 },
 {
  "input": "One way to think about this, actually, is that the mean-product formula is a nice way to solve quadratic in general (and some viewers of the channel may recognize this). ",
  "translatedText": "Eine Möglichkeit, darüber nachzudenken, besteht tatsächlich darin, dass die mittlere Produktformel eine gute Möglichkeit ist, quadratische Gleichungen im Allgemeinen zu lösen, und einige Zuschauer des Kanals werden dies möglicherweise erkennen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.16,
  "end": 641.66
 },
 {
  "input": "This about it: When you’re trying to find the roots of a quadratic given its coefficients, that's another situation where you know the sum of two values, and you also know their product, but you’re trying to recover the original two values. ",
  "translatedText": "Denk darüber nach. Wenn Sie versuchen, die Wurzeln eines Quadrats anhand der Koeffizienten zu finden, ist das eine weitere Situation, in der Sie die Summe zweier Werte und auch deren Produkt kennen, aber versuchen, die beiden ursprünglichen Werte wiederherzustellen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized so that this leading coefficient is 1, then the mean of the roots will be -½ times this linear coefficient, which is -1 times the sum of those roots. ",
  "translatedText": "Wenn das Polynom insbesondere so normalisiert wird, dass dieser führende Koeffizient Eins ist, dann ist der Mittelwert der Wurzeln negativ und halb so groß wie dieser lineare Koeffizient, der wiederum negativ ist und die Summe dieser Wurzeln beträgt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "For the example on the screen that makes the mean 5. ",
  "translatedText": "Für das Beispiel auf dem Bildschirm ergibt das einen Mittelwert von fünf. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it’s just the constant term no adjustments needed. ",
  "translatedText": "Und das Produkt der Wurzeln ist noch einfacher, es ist nur der konstante Term, es sind keine Anpassungen erforderlich. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula and that gives you the roots. ",
  "translatedText": "Von dort aus würden Sie also die mittlere Produktformel anwenden, und das ergibt die Wurzeln. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "On the one hand, you could think of this as a lighter-weight version of the traditional quadratic formula. ",
  "translatedText": "Und einerseits könnte man sich das als eine leichtere Version der traditionellen quadratischen Formel vorstellen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is that it's fewer symbols to memorize, it's that each one of them carries more meaning with it. ",
  "translatedText": "Der eigentliche Vorteil besteht jedoch nicht nur darin, dass man sich weniger Symbole merken muss, sondern auch darin, dass jedes einzelne Symbol eine größere Bedeutung hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "The whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial. ",
  "translatedText": "Ich meine, der springende Punkt bei diesem Eigenwerttrick ist, dass Sie den Zwischenschritt der Einrichtung des charakteristischen Polynoms nicht durchlaufen müssen, da Sie den Mittelwert und das Produkt direkt aus der Betrachtung der Matrix ablesen können. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like. ",
  "translatedText": "Sie können direkt mit dem Aufschreiben der Wurzeln beginnen, ohne jemals explizit darüber nachzudenken, wie das Polynom aussieht. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that we need a version of the quadratic formula where the terms carry some kind of meaning. ",
  "translatedText": "Dazu benötigen wir jedoch eine Version der quadratischen Formel, bei der die Begriffe eine bestimmte Bedeutung haben. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize that this is a very specific trick, for a very specific audience, but it’s something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them. ",
  "translatedText": "Mir ist klar, dass dies ein sehr spezieller Trick für ein ganz bestimmtes Publikum ist, aber ich wünschte, ich wüsste das im College. Wenn Sie also Studenten kennen, die davon profitieren könnten, sollten Sie darüber nachdenken, es mit ihnen zu teilen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it’s not just one more thing to memorize, but that the framing reinforces some other nice facts worth knowing, like how the trace and determinant relate to eigenvalues. ",
  "translatedText": "Die Hoffnung besteht darin, dass es sich nicht nur um eine weitere Sache handelt, die Sie sich merken, sondern dass die Rahmung einige andere nette Fakten unterstreicht, die es zu wissen gilt, etwa wie die Spur und die Determinante mit Eigenwerten zusammenhängen. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and think hard about the meaning of each of these coefficients. ",
  "translatedText": "Wenn Sie diese Tatsachen übrigens beweisen möchten, nehmen Sie sich einen Moment Zeit, um das charakteristische Polynom für eine allgemeine Matrix zu entwickeln, und denken Sie dann gründlich über die Bedeutung jedes dieser Koeffizienten nach. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim, for ensuring that this mean-product formula will stay stuck in all of our heads for at least a few months. ",
  "translatedText": "Vielen Dank an Tim, der dafür gesorgt hat, dass diese gemeine Produktformel mindestens ein paar Monate lang in unseren Köpfen hängen bleibt. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don’t know about acapellascience, please do check it out. ",
  "translatedText": "Wenn Sie nichts über die Alcappella-Wissenschaft wissen, schauen Sie sich das bitte an. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "\"The Molecular Shape of You\", in particular, is one of the greatest things on the internet. ",
  "translatedText": "Insbesondere Ihre molekulare Form ist eines der großartigsten Dinge im Internet. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]