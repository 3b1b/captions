[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices.",
  "translatedText": "Dieses Video richtet sich an alle, die bereits wissen, was Eigenwerte und Eigenvektoren sind, und die vielleicht Lust haben, sie im Fall von 2x2-Matrizen schnell zu berechnen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you're unfamiliar with eigenvalues, go ahead and take a look at this video here, which is actually meant to introduce them.",
  "translatedText": "Wenn du mit Eigenwerten nicht vertraut bist, schau dir dieses Video an, in dem sie erklärt werden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if all you want to do is see the trick, but if possible I'd like you to rediscover it for yourself.",
  "translatedText": "Wenn du nur den Trick sehen willst, kannst du ihn überspringen, aber wenn möglich, möchte ich, dass du ihn selbst wiederentdeckst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 20.1
 },
 {
  "input": "So for that, let's lay out a little background.",
  "translatedText": "Dafür brauchen wir ein paar Hintergrundinformationen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.58,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale that vector by some constant, we call it an eigenvector of the transformation, and we call the relevant scaling factor the corresponding eigenvalue, often denoted with the letter lambda.",
  "translatedText": "Zur Erinnerung: Wenn die Auswirkung einer linearen Transformation auf einen bestimmten Vektor darin besteht, diesen Vektor um eine Konstante zu skalieren, nennen wir ihn einen Eigenvektor der Transformation und den entsprechenden Skalierungsfaktor den entsprechenden Eigenwert, der oft mit dem Buchstaben Lambda bezeichnet wird.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation, and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix A minus lambda times the identity must send some non-zero vector, namely the corresponding eigenvector, to the zero vector, which in turn means that the determinant of this modified matrix must be zero.",
  "translatedText": "Wenn du das als Gleichung aufschreibst und ein bisschen umordnest, siehst du, dass, wenn die Zahl lambda ein Eigenwert einer Matrix A ist, die Matrix A minus lambda mal die Identität einen Nicht-Null-Vektor, nämlich den entsprechenden Eigenvektor, zum Nullvektor schicken muss, was wiederum bedeutet, dass die Determinante dieser veränderten Matrix Null sein muss.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that's all a little bit of a mouthful to say, but again, I'm assuming that all of this is review for any of you watching.",
  "translatedText": "Okay, das ist alles ein bisschen viel gesagt, aber ich gehe davon aus, dass das alles für jeden, der zuschaut, eine Zusammenfassung ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals, and then solve for the determinant is equal to zero.",
  "translatedText": "Die übliche Art, Eigenwerte zu berechnen, wie ich es früher gemacht habe und wie es meiner Meinung nach den meisten Schülern beigebracht wird, ist also, den unbekannten Wert Lambda von den Diagonalen abzuziehen und dann zu lösen, dass die Determinante gleich Null ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few extra steps to expand out and simplify to get a clean quadratic polynomial, what's known as the characteristic polynomial of the matrix.",
  "translatedText": "Dies erfordert immer ein paar zusätzliche Schritte zur Erweiterung und Vereinfachung, um ein reines quadratisches Polynom zu erhalten, das so genannte charakteristische Polynom der Matrix.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial, so to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification.",
  "translatedText": "Die Eigenwerte sind die Wurzeln dieses Polynoms. Um sie zu finden, musst du also die quadratische Formel anwenden, die wiederum in der Regel ein oder zwei weitere Schritte der Vereinfachung erfordert.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 97.36,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn't terrible, but at least for two by two matrices, there is a much more direct way you can get at the answer.",
  "translatedText": "Ehrlich gesagt ist das Verfahren nicht schlecht, aber zumindest für zwei mal zwei Matrizen gibt es einen viel direkteren Weg, um an die Antwort zu kommen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.76,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there's only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem solving.",
  "translatedText": "Und wenn du diesen Trick wiederentdecken willst, gibt es nur drei relevante Fakten, die du wissen musst. Jeder davon ist für sich genommen wissenswert und kann dir bei anderen Problemlösungen helfen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number one, the trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "translatedText": "Nummer eins, die Spur einer Matrix, die die Summe dieser beiden diagonalen Einträge ist, ist gleich der Summe der Eigenwerte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or, another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries.",
  "translatedText": "Eine andere, für unsere Zwecke nützlichere Formulierung ist, dass der Mittelwert der beiden Eigenwerte gleich dem Mittelwert dieser beiden Diagonaleinträge ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number two, the determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues.",
  "translatedText": "Nummer zwei: Die Determinante einer Matrix, unsere übliche ad-bc-Formel, ist gleich dem Produkt der beiden Eigenwerte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction, and that the determinant describes how much an operator scales areas, or volumes, as a whole.",
  "translatedText": "Das macht Sinn, wenn du verstehst, dass Eigenwerte beschreiben, wie stark ein Operator den Raum in eine bestimmte Richtung dehnt, und dass die Determinante beschreibt, wie stark ein Operator Flächen oder Volumina als Ganzes skaliert.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down.",
  "translatedText": "Bevor wir nun zum dritten Fakt kommen, solltest du beachten, dass du die ersten beiden Werte aus der Matrix ablesen kannst, ohne viel aufzuschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example.",
  "translatedText": "Nimm diese Matrix hier als Beispiel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away, you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7.",
  "translatedText": "Du kannst sofort erkennen, dass der Mittelwert der Eigenwerte derselbe ist wie der Mittelwert von 8 und 6, also 7.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well practiced at finding the determinant, which in this case works out to be 48 minus 8.",
  "translatedText": "Ebenso sind die meisten Schüler der linearen Algebra ziemlich gut darin geübt, die Determinante zu bestimmen, die in diesem Fall 48 minus 8 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.58,
  "end": 187.08
 },
 {
  "input": "So right away, you know that the product of the two eigenvalues is 40.",
  "translatedText": "Du weißt also sofort, dass das Produkt der beiden Eigenwerte 40 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 188.24,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see if you can derive what will be our third relevant fact, which is how you can quickly recover two numbers when you know their mean and you know their product.",
  "translatedText": "Nimm dir jetzt einen Moment Zeit, um zu sehen, wie du die dritte wichtige Tatsache ableiten kannst, nämlich wie du zwei Zahlen wiederherstellen kannst, wenn du ihren Mittelwert und ihr Produkt kennst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example.",
  "translatedText": "Konzentrieren wir uns auf dieses Beispiel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know that the two values are evenly spaced around the number 7, so they look like 7 plus or minus something, let's call that something d for distance.",
  "translatedText": "Du weißt, dass die beiden Werte gleichmäßig um 7 herum angeordnet sind, also sehen sie aus wie 7 plus oder minus etwas; nennen wir dieses Etwas \"d\" für Abstand.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40.",
  "translatedText": "Du weißt auch, dass das Produkt dieser beiden Zahlen 40 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares.",
  "translatedText": "Um nun d zu finden, beachte, dass sich dieses Produkt wirklich schön ausdehnt, es ergibt sich eine Differenz von Quadraten.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can find d.",
  "translatedText": "Von dort aus kannst du also d finden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.56,
  "end": 226.86
 },
 {
  "input": "d squared is 7 squared minus 40, or 9, which means that d itself is 3.",
  "translatedText": "d zum Quadrat ist 7 zum Quadrat minus 40, also 9, was bedeutet, dass d selbst 3 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 228.2,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10.",
  "translatedText": "Mit anderen Worten: Die beiden Werte für dieses sehr spezielle Beispiel sind 4 und 10.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn't want to think through this each time, so let's wrap up what we just did in a general formula.",
  "translatedText": "Aber unser Ziel ist ein schneller Trick und du möchtest nicht jedes Mal neu darüber nachdenken, also lass uns das, was wir gerade gemacht haben, in eine allgemeine Formel packen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean m and product p, the distance squared is always going to be m squared minus p.",
  "translatedText": "Für jeden Mittelwert m und jedes Produkt p ist der Abstand zum Quadrat immer m zum Quadrat minus p.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m plus or minus the square root of m squared minus p.",
  "translatedText": "Daraus ergibt sich die dritte wichtige Tatsache: Wenn zwei Zahlen einen Mittelwert m und ein Produkt p haben, kannst du diese beiden Zahlen als m plus oder minus die Quadratwurzel aus m zum Quadrat minus p schreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 257.56,
  "end": 268.46
 },
 {
  "input": "This is decently fast to re-derive on the fly if you ever forget it, and it's essentially just a rephrasing of the difference of squares formula.",
  "translatedText": "Das ist ziemlich schnell wieder abrufbar, wenn du es mal vergessen hast, und es ist im Grunde nur eine Umformulierung der Formel für die Differenz der Quadrate.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.1,
  "end": 277.08
 },
 {
  "input": "But even still, it's a fact that's worth memorizing so it's at the tip of your fingers.",
  "translatedText": "Trotzdem lohnt es sich, diese Tatsache auswendig zu lernen, damit du sie schnell zur Hand hast.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel A Capella Science wrote us a nice quick jingle to make it a little bit more memorable.",
  "translatedText": "Mein Freund Tim vom Kanal acapellascience hat uns sogar einen kurzen Jingle geschrieben, um ihn ein bisschen einprägsamer zu machen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "Let me show you how this works, say for the matrix 3 1 4 1.",
  "translatedText": "Ich zeige dir, wie das funktioniert, zum Beispiel für die Matrix 3 1 4 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head.",
  "translatedText": "Du fängst damit an, dir die Formel ins Gedächtnis zu rufen und sie vielleicht in deinem Kopf aufzuschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values for m and p as you go.",
  "translatedText": "Aber wenn du es aufschreibst, trägst du die entsprechenden Werte für m und p nach und nach ein.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2, so the thing you start writing is 2 plus or minus the square root of 2 squared minus.",
  "translatedText": "In diesem Beispiel ist der Mittelwert der Eigenwerte derselbe wie der Mittelwert von 3 und 1, also 2. Du schreibst also 2 plus oder minus die Quadratwurzel von 2 zum Quadrat.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.34,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3 times 1 minus 1 times 4, or negative 1, so that's the final thing you fill in, which means the eigenvalues are 2 plus or minus the square root of 5.",
  "translatedText": "Das Produkt der Eigenwerte ist die Determinante, die in diesem Beispiel 3 mal 1 minus 1 mal 4, also negativ 1, ist. Das heißt, die Eigenwerte sind 2 plus oder minus der Quadratwurzel aus 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.54,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer.",
  "translatedText": "Du erkennst vielleicht, dass es sich um dieselbe Matrix handelt, die ich am Anfang verwendet habe, aber merke dir, wie viel direkter wir die Antwort bekommen können.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one.",
  "translatedText": "Hier, versuch eine andere.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5.",
  "translatedText": "Dieses Mal ist der Mittelwert der Eigenwerte derselbe wie der Mittelwert von 2 und 8, nämlich 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula, but this time writing 5 in place of m.",
  "translatedText": "Also schreibst du wieder die Formel auf, aber diesmal schreibst du 5 anstelle von m.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2 times 8 minus 7 times 1, or 9.",
  "translatedText": "Und dann ist die Determinante 2*8 - 7*1, also 9.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 plus or minus the square root of 16, which simplifies even further as 9 and 1.",
  "translatedText": "In diesem Beispiel sehen die Eigenwerte also wie 5 ± sqrt(16) aus, was sich noch weiter zu 9 und 1 vereinfacht.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while you're staring at the matrix?",
  "translatedText": "Verstehst du, was ich damit meine, dass du einfach anfangen kannst, die Eigenwerte aufzuschreiben, während du auf die Matrix starrst?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It's typically just the tiniest bit of simplification at the end.",
  "translatedText": "Normalerweise ist es nur eine kleine Vereinfachung am Ende.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I've found myself using this trick a lot when I'm sketching quick notes related to linear algebra and want to use small matrices as examples.",
  "translatedText": "Ehrlich gesagt, verwende ich diesen Trick oft, wenn ich kurze Notizen zur linearen Algebra skizziere und kleine Matrizen als Beispiele verwenden möchte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I've been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realize it's just very handy if students can read out the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation.",
  "translatedText": "Ich habe an einem Video über Matrixexponenten gearbeitet, in dem die Eigenwerte häufig auftauchen, und ich habe festgestellt, dass es sehr praktisch ist, wenn die Schüler die Eigenwerte aus kleinen Beispielen herauslesen können, ohne den roten Faden zu verlieren, weil sie sich in einer anderen Berechnung verzetteln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which comes up a lot in quantum mechanics.",
  "translatedText": "Ein weiteres unterhaltsames Beispiel ist dieser Satz von drei verschiedenen Matrizen, der in der Quantenmechanik häufig vorkommt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 409.74,
  "end": 415.46
 },
 {
  "input": "They're known as the Pauli spin matrices.",
  "translatedText": "Sie sind bekannt als die Pauli-Spin-Matrizen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 415.76,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you'll know that the eigenvalues of matrices are highly relevant to the physics that they describe.",
  "translatedText": "Wenn du dich mit Quantenmechanik auskennst, weißt du, dass die Eigenwerte von Matrizen für die Physik, die sie beschreiben, von großer Bedeutung sind.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.6,
  "end": 424.42
 },
 {
  "input": "And if you don't know quantum mechanics, let this just be a little glimpse of how these computations are actually very relevant to real applications.",
  "translatedText": "Und falls du dich nicht mit Quantenmechanik auskennst, hier ein kleiner Einblick, wie wichtig diese Berechnungen für reale Anwendungen sind.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.22,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal entries in all three cases is zero.",
  "translatedText": "Der Mittelwert der diagonalen Einträge ist in allen drei Fällen Null.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 432.54,
  "end": 435.88
 },
 {
  "input": "So the mean of the eigenvalues in all of these cases is zero, which makes our formula look especially simple.",
  "translatedText": "Der Mittelwert der Eigenwerte ist also in all diesen Fällen Null, was unsere Formel besonders einfach aussehen lässt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 437.56,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices?",
  "translatedText": "Was ist mit den Produkten der Eigenwerte, den Determinanten dieser Matrizen?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it's 0, minus 1, or negative 1.",
  "translatedText": "Bei der ersten ist es 0, minus 1 oder negative 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.7,
  "end": 452.56
 },
 {
  "input": "The second one also looks like 0, minus 1, but it takes a moment more to see because of the complex numbers.",
  "translatedText": "Die zweite sieht auch wie 0 minus 1 aus, aber wegen der komplexen Zahlen dauert es einen Moment länger, bis man sie sieht.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.2,
  "end": 458.2
 },
 {
  "input": "And the final one looks like negative 1, minus 0.",
  "translatedText": "Und das Ergebnis sieht aus wie -1 - 0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be plus and minus 1.",
  "translatedText": "In allen Fällen vereinfachen sich die Eigenwerte also auf ±1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don't need a formula to find two values if you know that they're evenly spaced around 0 and their product is negative 1.",
  "translatedText": "Aber in diesem Fall brauchst du die Formel nicht, um zwei Werte zu finden, wenn du weißt, dass sie gleichmäßig um 0 herum angeordnet sind und ihr Produkt -1 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you're curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y, or z direction.",
  "translatedText": "Falls du neugierig bist: Im Kontext der Quantenmechanik beschreiben diese Matrizen Beobachtungen, die du über den Spin eines Teilchens in x-, y- oder z-Richtung machen kannst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.12
 },
 {
  "input": "And the fact that their eigenvalues are plus and minus 1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between.",
  "translatedText": "Und die Tatsache, dass ihre Eigenwerte plus und minus 1 sind, entspricht der Vorstellung, dass die Werte für den Spin, die du beobachten würdest, entweder ganz in die eine oder ganz in die andere Richtung gehen würden, im Gegensatz zu etwas, das ständig dazwischen liegt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.56,
  "end": 497.02
 },
 {
  "input": "Maybe you'd wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions.",
  "translatedText": "Vielleicht fragst du dich, wie genau das funktioniert oder warum man 2x2 Matrizen mit komplexen Zahlen verwendet, um den Spin in drei Dimensionen zu beschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "Those would be fair questions, just outside the scope of what I want to talk about here.",
  "translatedText": "Das sind berechtigte Fragen, die den Rahmen dessen, worüber ich hier sprechen möchte, sprengen würden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know, it's funny, I wrote this section because I wanted some case where you have 2x2 matrices that aren't just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that.",
  "translatedText": "Weißt du, es ist witzig, ich habe diesen Abschnitt geschrieben, weil ich einen Fall haben wollte, in dem du 2x2-Matrizen hast, die nicht nur Spielzeugbeispiele oder Hausaufgaben sind, sondern in der Praxis vorkommen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "The thing is, after I made it, I realized that the whole example kind of undercuts the point that I'm trying to make.",
  "translatedText": "Nachdem ich es gemacht habe, habe ich gemerkt, dass das ganze Beispiel irgendwie den Punkt untergräbt, den ich eigentlich machen wollte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it's essentially just as fast.",
  "translatedText": "Wenn du für diese speziellen Matrizen die traditionelle Methode mit charakteristischen Polynomen verwendest, ist sie im Grunde genauso schnell.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 528.74,
  "end": 536.1
 },
 {
  "input": "It might actually be faster.",
  "translatedText": "Es könnte sogar schneller sein.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 536.22,
  "end": 537.64
 },
 {
  "input": "I mean, take a look at the first one.",
  "translatedText": "Ich meine, schau dir das erste an.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.24,
  "end": 539.4
 },
 {
  "input": "The relevant determinant directly gives you a characteristic polynomial of lambda squared minus 1, and clearly that has roots of plus and minus 1.",
  "translatedText": "Die entsprechende Determinante gibt dir direkt ein charakteristisches Polynom von Lambda Quadrat minus 1, und das hat eindeutig Wurzeln von plus und minus 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.68,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda squared minus 1.",
  "translatedText": "Die gleiche Antwort erhältst du, wenn du die zweite Matrix, lambda^2 - 1, verwendest.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it's already a diagonal matrix, so those diagonal entries are the eigenvalues.",
  "translatedText": "Und was die letzte Matrix angeht, vergiss die traditionellen Berechnungen. Sie ist bereits eine Diagonalmatrix, also sind die diagonalen Einträge die Eigenwerte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause.",
  "translatedText": "Das Beispiel ist jedoch nicht völlig verloren.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speedup is in the more general case, where you take a linear combination of these three matrices and then try to compute the eigenvalues.",
  "translatedText": "Im allgemeineren Fall, in dem du eine Linearkombination dieser drei Matrizen nimmst und dann versuchst, die Eigenwerte zu berechnen, wirst du den Geschwindigkeitszuwachs tatsächlich spüren.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third.",
  "translatedText": "Du könntest das so schreiben: a mal das erste, plus b mal das zweite, plus c mal das dritte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates a, b, c.",
  "translatedText": "In der Quantenmechanik würde dies Spin-Beobachtungen in einer allgemeinen Richtung eines Vektors mit den Koordinaten a, b, c beschreiben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume that this vector is normalized, meaning a squared plus b squared plus c squared is equal to 1.",
  "translatedText": "Genauer gesagt solltest du davon ausgehen, dass dieser Vektor normalisiert ist, also a^2 + b^2 + c^2 = 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it's immediate to see that the mean of the eigenvalues is still 0.",
  "translatedText": "Wenn du dir diese neue Matrix ansiehst, siehst du sofort, dass der Mittelwert der Eigenwerte immer noch 0 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.6,
  "end": 604.1
 },
 {
  "input": "And you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still negative 1.",
  "translatedText": "Du könntest auch einen kurzen Moment innehalten, um dir zu vergewissern, dass das Produkt dieser Eigenwerte immer noch negativ 1 ist.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 604.6,
  "end": 610.9
 },
 {
  "input": "And then from there, concluding what the eigenvalues must be.",
  "translatedText": "Und dann schlussfolgern wir daraus, wie hoch die Eigenwerte sein müssen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 613.26,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head.",
  "translatedText": "Und dieses Mal wäre der charakteristische Polynom-Ansatz im Vergleich dazu viel umständlicher und definitiv schwieriger im Kopf zu erledigen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean product formula is not fundamentally different from finding roots of the characteristic polynomial.",
  "translatedText": "Um das klarzustellen: Die Formel für das mittlere Produkt unterscheidet sich nicht grundlegend von der Suche nach Wurzeln aus dem charakteristischen Polynom.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 625.08,
  "end": 630.96
 },
 {
  "input": "I mean, it can't be, they're solving the same problem.",
  "translatedText": "Ich meine, das kann nicht sein, sie lösen das gleiche Problem.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 631.34,
  "end": 633.44
 },
 {
  "input": "One way to think about this actually is that the mean product formula is a nice way to solve quadratics in general.",
  "translatedText": "Eine Möglichkeit, darüber nachzudenken, ist, dass die Formel für das mittlere Produkt eine gute Möglichkeit ist, Quadratzahlen im Allgemeinen zu lösen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.16,
  "end": 639.02
 },
 {
  "input": "And some viewers of the channel may recognize this.",
  "translatedText": "Und einige Zuschauer des Senders werden das vielleicht erkennen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 639.6,
  "end": 641.66
 },
 {
  "input": "Think about it, when you're trying to find the roots of a quadratic, given the coefficients, that's another situation where you know the sum of two values, and you also know their product, but you're trying to recover the original two values.",
  "translatedText": "Wenn du versuchst, die Wurzeln einer Quadratwurzel mit den Koeffizienten zu finden, ist das eine weitere Situation, in der du die Summe von zwei Werten kennst und auch ihr Produkt, aber du versuchst, die ursprünglichen zwei Werte zu finden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized, so that this leading coefficient is 1, then the mean of the roots will be negative 1 half times this linear coefficient, which is negative 1 times the sum of those roots.",
  "translatedText": "Wenn das Polynom so normalisiert wird, dass der führende Koeffizient 1 ist, ist der Mittelwert der Wurzeln das -½-fache dieses linearen Koeffizienten, also das -1-fache der Summe dieser Wurzeln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "With the example on the screen, that makes the mean 5.",
  "translatedText": "Bei dem Beispiel auf dem Bildschirm ist der Mittelwert also 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it's just the constant term, no adjustments needed.",
  "translatedText": "Und das Produkt der Wurzeln ist sogar noch einfacher, es ist nur der konstante Term, keine Anpassungen sind nötig.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula, and that gives you the roots.",
  "translatedText": "Von dort aus wendest du also die Formel für das mittlere Produkt an, und das ergibt die Wurzeln.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "And on the one hand, you could think of this as a lighter weight version of the traditional quadratic formula.",
  "translatedText": "Einerseits könnte man dies als eine leichtere Version der traditionellen quadratischen Formel betrachten.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is not just that it's fewer symbols to memorize, it's that each one of them carries more meaning with it.",
  "translatedText": "Aber der eigentliche Vorteil ist, dass man sich weniger Symbole merken muss, sondern dass jedes einzelne von ihnen mehr Bedeutung mit sich bringt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "I mean, the whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "translatedText": "Der Sinn dieses Eigenwerttricks besteht darin, dass du den Mittelwert und das Produkt direkt aus der Matrix ablesen kannst und nicht erst das charakteristische Polynom aufstellen musst.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like.",
  "translatedText": "Du kannst direkt mit dem Aufschreiben der Wurzeln beginnen, ohne dir vorher Gedanken darüber zu machen, wie das Polynom aussieht.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that, we need a version of the quadratic formula where the terms carry some kind of meaning.",
  "translatedText": "Aber dafür brauchen wir eine Version der quadratischen Formel, in der die Begriffe eine Bedeutung haben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize this is a very specific trick for a very specific audience, but it's something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them.",
  "translatedText": "Ich weiß, dass dies ein sehr spezieller Trick für ein sehr spezielles Publikum ist, aber ich wünschte, ich hätte ihn schon in der Schule gekannt. Wenn du also Schüler kennst, die davon profitieren könnten, solltest du ihn mit ihnen teilen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it's not just one more thing that you memorize, but that the framing reinforces some other nice facts that are worth knowing, like how the trace and the determinant are related to eigenvalues.",
  "translatedText": "Die Hoffnung ist, dass es nicht nur eine weitere Sache ist, die man auswendig lernen muss, sondern dass der Rahmen einige andere schöne Fakten verstärkt, die man wissen sollte, z.B. wie die Spur und die Determinante mit den Eigenwerten zusammenhängen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and then think hard about the meaning of each of these coefficients.",
  "translatedText": "Wenn du diese Fakten beweisen willst, nimm dir übrigens einen Moment Zeit, um das charakteristische Polynom für eine allgemeine Matrix zu erweitern, und denke dann gründlich über die Bedeutung der einzelnen Koeffizienten nach.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim for ensuring that this mean product formula will stay stuck in all of our heads for at least a few months.",
  "translatedText": "Vielen Dank an Tim, der dafür gesorgt hat, dass diese fiese Produktformel für mindestens ein paar Monate in unseren Köpfen hängen bleibt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don't know about alcappella science, please do check it out.",
  "translatedText": "Wenn du die Alcappella-Wissenschaft noch nicht kennst, solltest du sie unbedingt kennenlernen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "The molecular shape of you in particular is one of the greatest things on the internet.",
  "translatedText": "Vor allem die molekulare Form von dir ist eine der tollsten Sachen im Internet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]