[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices. ",
  "translatedText": "Это видео для всех, кто уже знает, что такое собственные значения и собственные векторы, и кому может понравиться быстрый способ их вычисления в случае матриц 2x2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you’re unfamiliar with eigenvalues, take a look at this video which introduces them. ",
  "translatedText": "Если вы не знакомы с собственными значениями, посмотрите это видео, которое на самом деле предназначено для ознакомления с ними. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if you just want to see the trick, but if possible I’d like you to rediscover it for yourself, so for that let’s lay down a little background. ",
  "translatedText": "Вы можете пропустить это, если все, что вам нужно, это увидеть трюк, но, если возможно, я бы хотел, чтобы вы открыли его для себя заново. Итак, давайте изложим небольшую предысторию. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.68,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale it by some constant, we call it an \"eigenvector\" of the transformation, and we call the relevant scaling factor the corresponding \"eigenvalue,\" often denoted with the letter lambda. ",
  "translatedText": "Напомним, что если результатом линейного преобразования данного вектора является масштабирование этого вектора на некоторую константу, мы называем его собственным вектором преобразования, а соответствующий коэффициент масштабирования называем соответствующим собственным значением, часто обозначаемым буквой лямбда. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix (A minus lambda times the identity) must send some nonzero vector, namely the corresponding eigenvector, to the zero vector, which in turn means the determinant of this modified matrix must be 0. ",
  "translatedText": "Когда вы запишите это в виде уравнения и немного перестроите, вы увидите, что если число лямбда является собственным значением матрицы A, то матрица A минус лямбда, умноженная на единицу, должна отправить некоторый ненулевой вектор, а именно соответствующий собственный вектор нулевому вектору, что, в свою очередь, означает, что определитель этой модифицированной матрицы должен быть равен нулю. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful to say, but again, I’m assuming all of this is review for anyone watching. ",
  "translatedText": "Ладно, это все слишком громко сказано, но опять же, я предполагаю, что все это обзор для любого из вас, кто смотрит. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it, and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals and then solve for when the determinant equals 0. ",
  "translatedText": "Итак, обычный способ вычисления собственных значений, как я это делал и как, по моему мнению, учат это делать большинство студентов, состоит в том, чтобы вычесть неизвестное значение лямбда из диагоналей, а затем определить, когда определитель равен нулю. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few steps to expand out and simplify to get a clean quadratic polynomial, what's known as the “characteristic polynomial” of the matrix. ",
  "translatedText": "Для этого всегда необходимо выполнить несколько шагов по расширению и упрощению, чтобы получить чистый квадратичный полином, так называемый «характеристический полином» матрицы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial. ",
  "translatedText": "Собственные значения являются корнями этого многочлена. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.36,
  "end": 99.9
 },
 {
  "input": "So to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification. ",
  "translatedText": "Поэтому, чтобы их найти, вам придется применить квадратичную формулу, которая сама по себе обычно требует еще одного или двух шагов упрощения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 100.1,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn’t terrible. ",
  "translatedText": "Честно говоря, процесс не так уж и страшен. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.76,
  "end": 109.5
 },
 {
  "input": "But at least for 2x2 matrices, there’s a much more direct way to get at this answer. ",
  "translatedText": "Но, по крайней мере, для матриц 2x2 есть гораздо более прямой способ получить ответ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 109.58,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there are only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem-solving. ",
  "translatedText": "И если вы хотите заново открыть для себя этот трюк, вам нужно знать всего три важных факта, каждый из которых стоит знать сам по себе и может помочь вам в решении других проблем. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number 1: The trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues. ",
  "translatedText": "Во-первых, след матрицы, который представляет собой сумму этих двух диагональных элементов, равен сумме собственных значений. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries. ",
  "translatedText": "Или другой способ сформулировать это, более полезный для наших целей: среднее значение двух собственных значений совпадает со средним значением этих двух диагональных элементов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number 2: The determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues. ",
  "translatedText": "Номер два, определитель матрицы, наша обычная формула ad-bc, равен произведению двух собственных значений. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction and that the determinant describes how much an operator scales areas (or volumes) as a whole. ",
  "translatedText": "И это должно иметь смысл, если вы понимаете, что собственные значения описывают, насколько оператор растягивает пространство в определенном направлении, а определитель описывает, насколько оператор масштабирует площади или объемы в целом. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down. ",
  "translatedText": "Теперь, прежде чем перейти к третьему факту, обратите внимание, как вы можете прочитать эти первые два значения из матрицы, практически не записывая их. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example. ",
  "translatedText": "Возьмите эту матрицу в качестве примера. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7. ",
  "translatedText": "Вы сразу можете знать, что среднее значение собственных значений совпадает со средним значением 8 и 6, которое равно 7. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well-practiced at finding the determinant, which in this case works out to be 48 - 8 So right away you know that the product of our two eigenvalues is 40. ",
  "translatedText": "Точно так же большинство студентов, изучающих линейную алгебру, довольно хорошо умеют находить определитель, который в данном случае равен 48 минус 8. Итак, вы сразу знаете, что произведение двух собственных значений равно 40. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.58,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see how you can derive what will be our third relevant fact, which is how to recover two numbers when you know their mean and you know their product. ",
  "translatedText": "Теперь найдите время и посмотрите, сможете ли вы вывести наш третий важный факт, а именно, как вы можете быстро восстановить два числа, если вы знаете их среднее значение и их произведение. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example. ",
  "translatedText": "Давайте сосредоточимся на этом примере. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know the two values are evenly spaced around 7, so they look like 7 plus or minus something; let’s call that something \"d\" for distance. ",
  "translatedText": "Вы знаете, что два значения равномерно распределены вокруг числа 7, поэтому они выглядят как 7 плюс-минус что-то, назовем это чем-то d, обозначающим расстояние. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40. ",
  "translatedText": "Вы также знаете, что произведение этих двух чисел равно 40. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares. ",
  "translatedText": "Теперь, чтобы найти d, обратите внимание, что это произведение очень хорошо расширяется, оно получается как разность квадратов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can directly find d: d^2 is 7^2 - 40, or 9, which means d itself is 3. ",
  "translatedText": "Таким образом, оттуда вы можете напрямую найти d. d в квадрате равно 7 в квадрате минус 40 или 9, что означает, что d само по себе равно 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.56,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10. ",
  "translatedText": "Другими словами, два значения для этого очень конкретного примера — 4 и 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t want to think this through each time, so let’s wrap up what we just did in a general formula. ",
  "translatedText": "Но наша цель — быстрый трюк, и вам не захочется обдумывать это каждый раз, поэтому давайте обернем то, что мы только что сделали, в общую формулу. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean, m and product, p, the distance squared is always going to be m^2 - p. ",
  "translatedText": "Для любого среднего значения m и произведения p квадрат расстояния всегда будет равен m в квадрате минус p. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly if you ever forget it, and it’s essentially just a rephrasing of the difference of squares formula. ",
  "translatedText": "Это дает третий ключевой факт: когда два числа имеют среднее значение m и произведение p, вы можете записать эти два числа как m плюс или минус квадратный корень из m в квадрате минус p. Это достаточно быстро пересчитать на лету, если вы когда-нибудь забудете об этом, и, по сути, это просто перефразирование формулы разности квадратов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.56,
  "end": 277.08
 },
 {
  "input": "But even still it’s a fact worth memorizing so that you have it at the tip of your fingers. ",
  "translatedText": "Но тем не менее, это факт, который стоит запомнить, чтобы он был на кончиках ваших пальцев. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel acapellascience wrote us a quick jingle to make it a little more memorable. ",
  "translatedText": "На самом деле, мой друг Тим с канала A Capella Science написал нам симпатичный джингл, чтобы сделать его немного более запоминающимся. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "m plus or minus squaaaare root of me squared minus p (ping!) Let me show you how this works, say for the matrix [[3,1], [4,1]]. ",
  "translatedText": "Позвольте мне показать вам, как это работает, скажем, для матрицы 3, 1, 4, 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head. ",
  "translatedText": "Вы начинаете с того, что вспоминаете формулу, возможно, проговаривая ее в уме. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values of m and p as you go. ",
  "translatedText": "Но когда вы записываете это, вы по ходу дела вводите соответствующие значения m и p. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2. ",
  "translatedText": "Итак, в этом примере среднее значение собственных значений совпадает со средним значением 3 и 1, что равно 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 312.34,
  "end": 317.74
 },
 {
  "input": "So the thing you start writing is 2 ± sqrt(2^2 - …). ",
  "translatedText": "Итак, вы начинаете писать 2 ± sqrt(2^2 - …). ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.3,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3*1 - 1*4, or -1. ",
  "translatedText": "Тогда произведение собственных значений является определителем, который в этом примере равен 3*1 - 1*4 или -1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.54,
  "end": 332.14
 },
 {
  "input": "So that’s the final thing you fill in. ",
  "translatedText": "Итак, это последнее, что вы заполняете. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.38,
  "end": 334.48
 },
 {
  "input": "This means the eigenvalues are 2±sqrt(5). ",
  "translatedText": "Это означает, что собственные значения равны 2±sqrt(5). ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.88,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer. ",
  "translatedText": "Возможно, вы заметили, что это та же самая матрица, которую я использовал вначале, но обратите внимание, насколько точнее мы можем получить ответ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one. ",
  "translatedText": "Вот, попробуй еще один. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5. ",
  "translatedText": "На этот раз среднее значение собственных значений совпадает со средним значением 2 и 8, то есть 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula but this time writing 5 in place of m [song]. ",
  "translatedText": "Итак, вы снова начинаете записывать формулу, но на этот раз вместо m [песня] пишете 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2*8 - 7*1, or 9. ",
  "translatedText": "И тогда определитель 2*8 - 7*1, или 9. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which simplifies even further as 9 and 1. ",
  "translatedText": "Итак, в этом примере собственные значения выглядят как 5 ± sqrt(16), что еще больше упрощается до 9 и 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while staring at the matrix? ",
  "translatedText": "Вы понимаете, что я имею в виду, когда говорю о том, как можно начать записывать собственные значения, глядя на матрицу? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It’s typically just the tiniest bit of simplifying at the end. ",
  "translatedText": "Обычно это лишь малейшее упрощение в конце. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I’ve found myself using this trick a lot when I’m sketching quick notes related to linear algebra and want to use small matrices as examples. ",
  "translatedText": "Честно говоря, я часто использую этот трюк, когда делаю быстрые заметки, связанные с линейной алгеброй, и хочу использовать небольшие матрицы в качестве примеров. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I’ve been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realized it’s just very handy if students can read off the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation. ",
  "translatedText": "Я работал над видео о показателях матрицы, где часто всплывают собственные значения, и понимаю, что это очень удобно, если студенты могут считывать собственные значения из небольших примеров, не теряя при этом основную линию мысли, увязая в другом. расчет. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which come up a lot in quantum mechanics, they're known as the Pauli spin matrices. ",
  "translatedText": "В качестве еще одного забавного примера рассмотрим набор из трех разных матриц, которые часто встречаются в квантовой механике. Они известны как спиновые матрицы Паули. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.74,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you’ll know that the eigenvalues of matrices are highly relevant to the physics they describe, and if you don’t know quantum mechanics, let this just be a little glimpse of how these computations are actually relevant to real applications. ",
  "translatedText": "Если вы знакомы с квантовой механикой, вы знаете, что собственные значения матриц очень важны для описываемой ими физики. И если вы не знаете квантовую механику, пусть это будет лишь кратким представлением о том, насколько эти вычисления на самом деле очень важны для реальных приложений. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.6,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal in all three cases is 0, so the mean of the eigenvalues in all cases is 0, which makes our formula look especially simple. ",
  "translatedText": "Среднее значение диагональных элементов во всех трех случаях равно нулю. Таким образом, среднее значение собственных значений во всех этих случаях равно нулю, что делает нашу формулу особенно простой. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.54,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices? ",
  "translatedText": "А как насчет произведений собственных значений, определителей этих матриц? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1. ",
  "translatedText": "Для первого это 0 минус 1 или минус 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.7,
  "end": 453.4
 },
 {
  "input": "The second also looks like 0 - 1, but it takes a moment more to see because of the complex numbers. ",
  "translatedText": "Второе тоже выглядит как 0 минус 1, но на его рассмотрение требуется больше времени из-за комплексных чисел. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.4,
  "end": 458.2
 },
 {
  "input": "And the final one looks like -1 - 0. ",
  "translatedText": "И последний выглядит как минус 1 минус 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be ±1. ",
  "translatedText": "Таким образом, во всех случаях собственные значения упрощаются до плюса и минус 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don’t need the formula to find two values if you know theyr'e evenly spaced around 0 and their product is -1. ",
  "translatedText": "Хотя в этом случае вам действительно не нужна формула для нахождения двух значений, если вы знаете, что они равномерно расположены вокруг 0, а их произведение отрицательно 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you’re curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y or z directions. ",
  "translatedText": "Если вам интересно, в контексте квантовой механики эти матрицы описывают наблюдения, которые вы можете сделать относительно вращения частицы в направлении x, y или z. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.76
 },
 {
  "input": "The fact that their eigenvalues are ±1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between. ",
  "translatedText": "И тот факт, что их собственные значения равны плюс и минус 1, соответствует идее, что наблюдаемые вами значения вращения будут либо полностью в одном направлении, либо полностью в другом, а не в чем-то постоянно колеблющемся между ними. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.76,
  "end": 497.02
 },
 {
  "input": "Maybe you’d wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions. ",
  "translatedText": "Возможно, вам будет интересно, как именно это работает или зачем использовать матрицы 2x2 с комплексными числами для описания вращения в трех измерениях. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "And those would be fair questions, just outside the scope of what I want to talk about here. ",
  "translatedText": "И это были бы справедливые вопросы, выходящие за рамки того, о чем я хочу здесь поговорить. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know it’s funny, I wrote this section because I wanted some case where you have 2x2 matrices that are not just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that. ",
  "translatedText": "Знаете, это забавно, я написал этот раздел, потому что мне нужен был случай, когда у вас есть матрицы 2x2, которые не являются просто игрушечными примерами или домашними задачами, а такими, в которых они действительно возникают на практике, и квантовая механика отлично подходит для этого. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "But the thing is after I made it I realized that the whole example kind of undercuts the point I’m trying to make. ",
  "translatedText": "Но дело в том, что после того, как я это сделал, я понял, что весь этот пример как бы подрывает ту мысль, которую я пытаюсь донести. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; it might actually faster. ",
  "translatedText": "Для этих конкретных матриц, когда вы используете традиционный метод с характеристическими полиномами, он по сути столь же быстр. Возможно, на самом деле это будет быстрее. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.74,
  "end": 537.64
 },
 {
  "input": "I mean, take a look a the first one: The relevant determinant directly gives you a characteristic polynomial of lambda^2 - 1, and clearly, that has roots of plus and minus 1. ",
  "translatedText": "Я имею в виду, взгляните на первый. Соответствующий определитель напрямую дает вам характеристический многочлен лямбда в квадрате минус один, который, очевидно, имеет корни плюс и минус один. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.24,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda^2 - 1. ",
  "translatedText": "Тот же ответ, когда вы делаете вторую матрицу, лямбда в квадрате минус один. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it’s already a diagonal matrix, so those diagonal entries are the eigenvalues! ",
  "translatedText": "А что касается последней матрицы, забудьте о каких-либо вычислениях, традиционных или иных, это уже диагональная матрица, поэтому эти диагональные элементы являются собственными значениями. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause. ",
  "translatedText": "Однако этот пример не полностью потерян для нашего дела. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speed up is in the more general case where you take a linear combination of these three matrices and then try to compute the eigenvalues. ",
  "translatedText": "На самом деле вы почувствуете ускорение в более общем случае, когда вы берете линейную комбинацию этих трех матриц, а затем пытаетесь вычислить собственные значения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third. ",
  "translatedText": "Вы можете записать это как a, умноженное на первое, плюс b, умноженное на второе, плюс c, умноженное на третье. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates [a, b, c]. ",
  "translatedText": "В квантовой механике это описывало бы наблюдения спина в общем направлении вектора с координатами a, b, c. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume this vector is normalized, meaning a^2 + b^2 + c^2 = 1. ",
  "translatedText": "Точнее, вы должны предположить, что этот вектор нормализован, то есть квадрат плюс b в квадрате плюс с в квадрате равны единице. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it’s immediate to see that the mean of the eigenvalues is still zero, and you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still -1, and then from there concluding what the eigenvalues must be. ",
  "translatedText": "Когда вы посмотрите на эту новую матрицу, сразу увидите, что среднее значение собственных значений по-прежнему равно нулю, и вам также может понравиться сделать короткую паузу, чтобы убедиться, что произведение этих собственных значений по-прежнему отрицательно. А затем сделать вывод, какими должны быть собственные значения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.6,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head. ",
  "translatedText": "И на этот раз характеристический полиномиальный подход будет намного более громоздким, и его определенно сложнее будет реализовать в уме. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean-product formula is not fundamentally different from finding roots of the characteristic polynomial; I mean, it can't be, they're solving the same problem. ",
  "translatedText": "Чтобы внести ясность, использование формулы среднего произведения не отличается от поиска корней характеристического многочлена. Я имею в виду, этого не может быть, они решают одну и ту же проблему. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.08,
  "end": 633.44
 },
 {
  "input": "One way to think about this, actually, is that the mean-product formula is a nice way to solve quadratic in general (and some viewers of the channel may recognize this). ",
  "translatedText": "На самом деле можно подумать об этом так: формула среднего произведения — это хороший способ решения квадратичных уравнений в целом, и некоторые зрители канала могут это признать. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.16,
  "end": 641.66
 },
 {
  "input": "This about it: When you’re trying to find the roots of a quadratic given its coefficients, that's another situation where you know the sum of two values, and you also know their product, but you’re trying to recover the original two values. ",
  "translatedText": "Думаю об этом. Когда вы пытаетесь найти корни квадратного числа по коэффициентам, это другая ситуация, когда вы знаете сумму двух значений, а также их произведение, но вы пытаетесь восстановить исходные два значения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized so that this leading coefficient is 1, then the mean of the roots will be -½ times this linear coefficient, which is -1 times the sum of those roots. ",
  "translatedText": "В частности, если полином нормализован так, что главный коэффициент равен единице, то среднее значение корней будет отрицательным в половину этого линейного коэффициента, который является отрицательным в один раз суммы этих корней. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "For the example on the screen that makes the mean 5. ",
  "translatedText": "Для примера на экране это означает пять. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it’s just the constant term no adjustments needed. ",
  "translatedText": "А произведение корней еще проще, это просто постоянный член, никаких корректировок не требуется. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula and that gives you the roots. ",
  "translatedText": "Отсюда вы можете применить формулу среднего продукта, и это даст вам корни. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "On the one hand, you could think of this as a lighter-weight version of the traditional quadratic formula. ",
  "translatedText": "И с одной стороны, вы можете думать об этом как об облегченной версии традиционной квадратичной формулы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is that it's fewer symbols to memorize, it's that each one of them carries more meaning with it. ",
  "translatedText": "Но настоящее преимущество не только в том, что нужно запоминать меньше символов, но и в том, что каждый из них несет в себе больше смысла. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "The whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial. ",
  "translatedText": "Я имею в виду, что весь смысл этого трюка с собственными значениями заключается в том, что, поскольку вы можете считать среднее значение и произведение непосредственно, глядя на матрицу, вам не нужно проходить промежуточный шаг по настройке характеристического полинома. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like. ",
  "translatedText": "Вы можете сразу перейти к записи корней, даже не задумываясь явно о том, как выглядит полином. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that we need a version of the quadratic formula where the terms carry some kind of meaning. ",
  "translatedText": "Но для этого нам нужна версия квадратной формулы, в которой члены несут какой-то смысл. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize that this is a very specific trick, for a very specific audience, but it’s something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them. ",
  "translatedText": "Я понимаю, что это очень специфический трюк для очень специфической аудитории, но мне хотелось бы знать об этом в колледже, поэтому, если вы знаете студентов, которым это может быть полезно, подумайте о том, чтобы поделиться им с ними. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it’s not just one more thing to memorize, but that the framing reinforces some other nice facts worth knowing, like how the trace and determinant relate to eigenvalues. ",
  "translatedText": "Мы надеемся, что это не просто еще одна вещь, которую вы запомните, но и то, что формулировка подкрепит некоторые другие интересные факты, которые стоит знать, например, как след и определитель связаны с собственными значениями. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and think hard about the meaning of each of these coefficients. ",
  "translatedText": "Кстати, если вы хотите доказать эти факты, найдите время, чтобы разложить характеристический полином для общей матрицы, а затем хорошенько подумайте о значении каждого из этих коэффициентов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim, for ensuring that this mean-product formula will stay stuck in all of our heads for at least a few months. ",
  "translatedText": "Большое спасибо Тиму за то, что эта формула среднего продукта застряла в наших головах как минимум на несколько месяцев. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don’t know about acapellascience, please do check it out. ",
  "translatedText": "Если вы не знаете о науке об алькапелле, пожалуйста, ознакомьтесь с ней. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "\"The Molecular Shape of You\", in particular, is one of the greatest things on the internet. ",
  "translatedText": "Ваша молекулярная форма — одна из величайших вещей в Интернете. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]