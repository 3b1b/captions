[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices.",
  "translatedText": "این یک ویدیو برای کسانی است که از قبل می دانند مقادیر ویژه و بردارهای ویژه چیست و ممکن است از روشی سریع برای محاسبه آنها در مورد ماتریس های 2x2 لذت ببرند. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you're unfamiliar with eigenvalues, go ahead and take a look at this video here, which is actually meant to introduce them.",
  "translatedText": "اگر با مقادیر ویژه آشنا نیستید، ادامه دهید و به این ویدیو در اینجا نگاهی بیندازید، که در واقع برای معرفی آنها است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if all you want to do is see the trick, but if possible I'd like you to rediscover it for yourself.",
  "translatedText": "اگر تنها کاری که می‌خواهید این است که این ترفند را ببینید، می‌توانید جلوتر بروید، اما در صورت امکان، می‌خواهم خودتان آن را دوباره کشف کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 20.1
 },
 {
  "input": "So for that, let's lay out a little background.",
  "translatedText": "بنابراین برای آن، بیایید یک پس‌زمینه کوچک بسازیم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.58,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale that vector by some constant, we call it an eigenvector of the transformation, and we call the relevant scaling factor the corresponding eigenvalue, often denoted with the letter lambda.",
  "translatedText": "به عنوان یک یادآوری سریع، اگر تأثیر یک تبدیل خطی روی یک بردار معین، مقیاس آن بردار را با مقداری ثابت باشد، آن را بردار ویژه تبدیل می‌نامیم و ضریب مقیاس‌گذاری مربوطه را مقدار ویژه مربوطه می‌نامیم که اغلب با حرف نشان داده می‌شود. لامبدا",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation, and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix A minus lambda times the identity must send some non-zero vector, namely the corresponding eigenvector, to the zero vector, which in turn means that the determinant of this modified matrix must be zero.",
  "translatedText": "وقتی این را به عنوان یک معادله می نویسید، و کمی دوباره ترتیب می دهید، چیزی که می بینید این است که اگر عدد لامبدا یک مقدار ویژه از ماتریس A باشد، ماتریس A منهای لامبدا ضربدر هویت باید مقداری بردار غیر صفر بفرستد. بردار ویژه مربوطه، به بردار صفر، که به نوبه خود به این معنی است که تعیین کننده این ماتریس اصلاح شده باید صفر باشد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that's all a little bit of a mouthful to say, but again, I'm assuming that all of this is review for any of you watching.",
  "translatedText": "بسیار خوب، همه اینها برای گفتن کمی سخت است، اما دوباره، من فرض می کنم که همه اینها برای هر یک از شما که تماشا می کنید، مرور است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals, and then solve for the determinant is equal to zero.",
  "translatedText": "بنابراین، روش معمول برای محاسبه مقادیر ویژه، نحوه انجام آن و اینکه چگونه به اکثر دانش‌آموزان آموزش داده می‌شود که آن را انجام دهند، این است که مقدار مجهول لامبدا را از قطرها کم می‌کنیم، و سپس تعیین‌کننده را با صفر حل می‌کنیم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few extra steps to expand out and simplify to get a clean quadratic polynomial, what's known as the characteristic polynomial of the matrix.",
  "translatedText": "انجام این کار همیشه مستلزم چند گام اضافی برای گسترش و ساده سازی برای بدست آوردن یک چند جمله ای درجه دوم تمیز است، چیزی که به عنوان چند جمله ای مشخصه ماتریس شناخته می شود.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial, so to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification.",
  "translatedText": "مقادیر ویژه ریشه های این چند جمله ای هستند، بنابراین برای یافتن آنها باید فرمول درجه دوم را اعمال کنید، که خود معمولاً به یک یا دو مرحله دیگر ساده سازی نیاز دارد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 97.36,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn't terrible, but at least for two by two matrices, there is a much more direct way you can get at the answer.",
  "translatedText": "راستش را بخواهید، این روند وحشتناک نیست، اما حداقل برای دو در دو ماتریس، راه بسیار مستقیم تری وجود دارد که می توانید به پاسخ آن برسید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.76,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there's only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem solving.",
  "translatedText": "و اگر می‌خواهید این ترفند را دوباره کشف کنید، تنها سه واقعیت مرتبط وجود دارد که باید بدانید، که هر یک به تنهایی ارزش دانستن دارند و می‌توانند به شما در حل مشکلات دیگر کمک کنند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number one, the trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "translatedText": "شماره یک، اثر یک ماتریس، که مجموع این دو ورودی مورب است، برابر با مجموع مقادیر ویژه است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or, another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries.",
  "translatedText": "یا راه دیگری برای بیان آن که برای اهداف ما مفیدتر است، این است که میانگین دو مقدار ویژه با میانگین این دو ورودی مورب یکسان باشد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number two, the determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues.",
  "translatedText": "شماره دو، تعیین کننده یک ماتریس، فرمول ad-bc معمول ما، برابر است با حاصلضرب دو مقدار ویژه.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction, and that the determinant describes how much an operator scales areas, or volumes, as a whole.",
  "translatedText": "و اگر بفهمید که مقادیر ویژه توصیف می‌کنند که یک عملگر چقدر فضا را در یک جهت خاص امتداد می‌دهد، و اینکه تعیین‌کننده توصیف می‌کند که یک عملگر چقدر مناطق یا حجم‌ها را در کل مقیاس می‌کند، منطقی است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down.",
  "translatedText": "اکنون قبل از رسیدن به واقعیت سوم، توجه کنید که چگونه می توانید اساساً این دو مقدار اول را بدون نوشتن چیزهای زیادی از ماتریس بخوانید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example.",
  "translatedText": "این ماتریس را در اینجا به عنوان مثال در نظر بگیرید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away, you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7.",
  "translatedText": "بلافاصله می توانید بدانید که میانگین مقادیر ویژه همان میانگین 8 و 6 است که 7 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well practiced at finding the determinant, which in this case works out to be 48 minus 8.",
  "translatedText": "به همین ترتیب، اکثر دانش‌آموزان جبر خطی در یافتن دترمینان بسیار خوب تمرین می‌کنند، که در این مورد 48 منهای 8 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.58,
  "end": 187.08
 },
 {
  "input": "So right away, you know that the product of the two eigenvalues is 40.",
  "translatedText": "بنابراین فوراً می دانید که حاصل ضرب دو مقدار ویژه 40 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 188.24,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see if you can derive what will be our third relevant fact, which is how you can quickly recover two numbers when you know their mean and you know their product.",
  "translatedText": "حالا یک لحظه وقت بگذارید و ببینید آیا می توانید سومین واقعیت مرتبط ما را استخراج کنید، یعنی چگونه می توانید به سرعت دو عدد را هنگامی که میانگین آنها را می دانید و محصول آنها را می دانید بازیابی کنید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example.",
  "translatedText": "در اینجا، بیایید روی این مثال تمرکز کنیم. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know that the two values are evenly spaced around the number 7, so they look like 7 plus or minus something, let's call that something d for distance.",
  "translatedText": "می دانید که این دو مقدار در اطراف عدد 7 به طور مساوی فاصله دارند، بنابراین آنها مانند 7 به علاوه یا منهای چیزی به نظر می رسند، بیایید آن را چیزی d برای فاصله بنامیم. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40.",
  "translatedText": "همچنین می دانید که حاصل ضرب این دو عدد 40 است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares.",
  "translatedText": "اکنون برای پیدا کردن d، توجه کنید که این محصول واقعاً خوب منبسط می شود، به عنوان اختلاف مربع عمل می کند. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can find d.",
  "translatedText": "بنابراین از آنجا، شما می توانید d را پیدا کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.56,
  "end": 226.86
 },
 {
  "input": "d squared is 7 squared minus 40, or 9, which means that d itself is 3.",
  "translatedText": "d مجذور 7 مجذور منهای 40 یا 9 است، یعنی d خود 3 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 228.2,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10.",
  "translatedText": "به عبارت دیگر، دو مقدار برای این مثال بسیار خاص 4 و 10 است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn't want to think through this each time, so let's wrap up what we just did in a general formula.",
  "translatedText": "اما هدف ما یک ترفند سریع است، و شما نمی خواهید هر بار به این موضوع فکر کنید، بنابراین بیایید آنچه را که انجام دادیم در یک فرمول کلی جمع بندی کنیم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean m and product p, the distance squared is always going to be m squared minus p.",
  "translatedText": "برای هر میانگین m و حاصلضرب p، فاصله مجذور همیشه m مجذور منهای p خواهد بود.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m plus or minus the square root of m squared minus p.",
  "translatedText": "این سومین واقعیت کلیدی را نشان می دهد، و آن این است که وقتی دو عدد دارای میانگین m و حاصلضرب p هستند، می توانید آن دو عدد را به عنوان m بعلاوه یا منهای جذر m مجذور منهای p بنویسید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 257.56,
  "end": 268.46
 },
 {
  "input": "This is decently fast to re-derive on the fly if you ever forget it, and it's essentially just a rephrasing of the difference of squares formula.",
  "translatedText": "اگر زمانی آن را فراموش کردید، می‌توان آن را سریع دوباره به‌دست آورد، و اساساً فقط بیان مجدد تفاوت فرمول مربع‌ها است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.1,
  "end": 277.08
 },
 {
  "input": "But even still, it's a fact that's worth memorizing so it's at the tip of your fingers.",
  "translatedText": "اما با این حال، این واقعیتی است که ارزش به خاطر سپردن دارد، بنابراین در نوک انگشتان شما قرار دارد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel A Capella Science wrote us a nice quick jingle to make it a little bit more memorable.",
  "translatedText": "در واقع، دوست من تیم از کانال A Capella Science یک صدای جرنگ سریع زیبا برای ما نوشت تا کمی خاطره انگیزتر شود. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "Let me show you how this works, say for the matrix 3 1 4 1.",
  "translatedText": "اجازه دهید به شما نشان دهم که چگونه این کار می کند، مثلاً برای ماتریس 3 1 4 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head.",
  "translatedText": "شما با یادآوری فرمول شروع می کنید، شاید همه آن را در ذهن خود بیان کنید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values for m and p as you go.",
  "translatedText": "اما وقتی آن را یادداشت می‌کنید، مقادیر مناسب m و p را در حین حرکت پر می‌کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2, so the thing you start writing is 2 plus or minus the square root of 2 squared minus.",
  "translatedText": "بنابراین در این مثال، میانگین مقادیر ویژه همان میانگین 3 و 1 است که 2 است، بنابراین چیزی که شروع به نوشتن می کنید 2 به علاوه یا منهای جذر 2 مجذور منهای است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.34,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3 times 1 minus 1 times 4, or negative 1, so that's the final thing you fill in, which means the eigenvalues are 2 plus or minus the square root of 5.",
  "translatedText": "سپس حاصل ضرب مقادیر ویژه تعیین کننده است، که در این مثال 3 ضربدر 1 منهای 1 ضربدر 4 یا منفی 1 است، بنابراین آخرین چیزی است که شما پر می کنید، به این معنی که مقادیر ویژه 2 به علاوه یا منهای جذر 5 هستند. .",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.54,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer.",
  "translatedText": "ممکن است متوجه شوید که این همان ماتریسی است که من در ابتدا استفاده می‌کردم، اما توجه کنید که چقدر مستقیم‌تر می‌توانیم پاسخ را دریافت کنیم. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one.",
  "translatedText": "در اینجا، یکی دیگر را امتحان کنید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5.",
  "translatedText": "این بار میانگین مقادیر ویژه با میانگین 2 و 8 برابر است که برابر با 5 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula, but this time writing 5 in place of m.",
  "translatedText": "بنابراین دوباره شروع به نوشتن فرمول می کنید، اما این بار به جای m عدد 5 را می نویسید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2 times 8 minus 7 times 1, or 9.",
  "translatedText": "",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 plus or minus the square root of 16, which simplifies even further as 9 and 1.",
  "translatedText": "بنابراین در این مثال، مقادیر ویژه مانند 5 به علاوه یا منهای جذر 16 به نظر می رسند، که حتی بیشتر به عنوان 9 و 1 ساده می شود. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while you're staring at the matrix?",
  "translatedText": "متوجه منظور من از این هستید که چگونه می توانید در حالی که به ماتریس خیره شده اید، اساساً شروع به نوشتن مقادیر ویژه کنید؟",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It's typically just the tiniest bit of simplification at the end.",
  "translatedText": "معمولاً در پایان فقط کوچکترین ساده سازی است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I've found myself using this trick a lot when I'm sketching quick notes related to linear algebra and want to use small matrices as examples.",
  "translatedText": "راستش را بخواهید، وقتی یادداشت‌های سریع مربوط به جبر خطی را ترسیم می‌کنم و می‌خواهم از ماتریس‌های کوچک به عنوان مثال استفاده کنم، بسیار از این ترفند استفاده می‌کنم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I've been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realize it's just very handy if students can read out the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation.",
  "translatedText": "من روی یک ویدیو درباره نماهای ماتریس کار کرده ام، که در آن مقادیر ویژه زیاد ظاهر می شوند، و متوجه می شوم که بسیار مفید است اگر دانش آموزان بتوانند مقادیر ویژه را از نمونه های کوچک بخوانند بدون اینکه خط فکری اصلی را با گرفتار شدن در یک چیز متفاوت از دست بدهند. محاسبه",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which comes up a lot in quantum mechanics.",
  "translatedText": "به عنوان یک مثال جالب دیگر، به مجموعه ای از سه ماتریس مختلف که در مکانیک کوانتومی بسیار به چشم می خورد، نگاهی بیندازید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 409.74,
  "end": 415.46
 },
 {
  "input": "They're known as the Pauli spin matrices.",
  "translatedText": "آنها به عنوان ماتریس اسپین پاولی شناخته می شوند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 415.76,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you'll know that the eigenvalues of matrices are highly relevant to the physics that they describe.",
  "translatedText": "اگر مکانیک کوانتومی را بلد باشید، می‌دانید که مقادیر ویژه ماتریس‌ها بسیار مرتبط با فیزیکی است که آن‌ها توصیف می‌کنند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.6,
  "end": 424.42
 },
 {
  "input": "And if you don't know quantum mechanics, let this just be a little glimpse of how these computations are actually very relevant to real applications.",
  "translatedText": "و اگر مکانیک کوانتومی را نمی‌دانید، اجازه دهید این تنها نگاهی اجمالی به چگونگی ارتباط این محاسبات با کاربردهای واقعی باشد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.22,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal entries in all three cases is zero.",
  "translatedText": "میانگین ورودی های مورب در هر سه حالت صفر است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 432.54,
  "end": 435.88
 },
 {
  "input": "So the mean of the eigenvalues in all of these cases is zero, which makes our formula look especially simple.",
  "translatedText": "بنابراین میانگین مقادیر ویژه در همه این موارد صفر است که فرمول ما را بسیار ساده می کند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 437.56,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices?",
  "translatedText": "در مورد محصولات مقادیر ویژه، تعیین کننده های این ماتریس ها چطور؟ برای اولی 0 منهای 1 یا منفی 1 است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it's 0, minus 1, or negative 1.",
  "translatedText": "برای اولی 0، منهای 1 یا منفی 1 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.7,
  "end": 452.56
 },
 {
  "input": "The second one also looks like 0, minus 1, but it takes a moment more to see because of the complex numbers.",
  "translatedText": "دومی نیز مانند 0، منهای 1 به نظر می رسد، اما به دلیل اعداد مختلط، دیدن آن یک لحظه بیشتر طول می کشد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.2,
  "end": 458.2
 },
 {
  "input": "And the final one looks like negative 1, minus 0.",
  "translatedText": "و آخرین به نظر منفی 1 منهای 0 است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be plus and minus 1.",
  "translatedText": "بنابراین در همه موارد، مقادیر ویژه به صورت مثبت و منهای 1 ساده می شوند. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don't need a formula to find two values if you know that they're evenly spaced around 0 and their product is negative 1.",
  "translatedText": "اگر چه در این مورد، اگر بدانید که دو مقدار به طور مساوی در فاصله 0 قرار دارند و حاصلضرب آنها منفی 1 است، واقعاً به فرمولی برای یافتن دو مقدار نیاز ندارید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you're curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y, or z direction.",
  "translatedText": "اگر کنجکاو هستید، در زمینه مکانیک کوانتومی، این ماتریس ها مشاهداتی را که ممکن است در مورد اسپین یک ذره در جهت x، y یا z انجام دهید، توصیف می کنند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.12
 },
 {
  "input": "And the fact that their eigenvalues are plus and minus 1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between.",
  "translatedText": "و این واقعیت که مقادیر ویژه آنها به اضافه و منهای 1 است، با این ایده مطابقت دارد که مقادیر اسپینی که مشاهده می کنید کاملاً در یک جهت یا کاملاً در جهت دیگر خواهد بود، برخلاف چیزی که به طور مداوم در این بین قرار دارد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.56,
  "end": 497.02
 },
 {
  "input": "Maybe you'd wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions.",
  "translatedText": "شاید تعجب کنید که این دقیقا چگونه کار می کند، یا چرا از ماتریس های 2x2 که دارای اعداد مختلط هستند برای توصیف اسپین در سه بعدی استفاده می کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "Those would be fair questions, just outside the scope of what I want to talk about here.",
  "translatedText": "اینها سؤالات منصفانه ای خواهند بود، فقط خارج از محدوده چیزی که من می خواهم در مورد آن صحبت کنم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know, it's funny, I wrote this section because I wanted some case where you have 2x2 matrices that aren't just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that.",
  "translatedText": "می دانید، خنده دار است، من این بخش را نوشتم زیرا می خواستم موردی داشته باشید که در آن شما ماتریس های 2x2 داشته باشید که فقط نمونه های اسباب بازی یا مسائل تکلیف نیستند، مواردی که در عمل به وجود می آیند، و مکانیک کوانتومی برای آن عالی است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "The thing is, after I made it, I realized that the whole example kind of undercuts the point that I'm trying to make.",
  "translatedText": "مسئله این است که بعد از اینکه آن را ساختم، متوجه شدم که کل مثال به نوعی نقطه ضعفی را که من می‌خواهم بیان کنم، کاهش می‌دهد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it's essentially just as fast.",
  "translatedText": "برای این ماتریس های خاص، وقتی از روش سنتی استفاده می کنید، روشی که چند جمله ای های مشخصه دارد، اساساً به همان سرعت است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 528.74,
  "end": 536.1
 },
 {
  "input": "It might actually be faster.",
  "translatedText": "ممکن است در واقع سریعتر باشد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 536.22,
  "end": 537.64
 },
 {
  "input": "I mean, take a look at the first one.",
  "translatedText": "منظورم این است که اولی را نگاه کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.24,
  "end": 539.4
 },
 {
  "input": "The relevant determinant directly gives you a characteristic polynomial of lambda squared minus 1, and clearly that has roots of plus and minus 1.",
  "translatedText": "تعیین کننده مربوطه مستقیماً یک چند جمله ای مشخصه از لامبدا مربع منهای 1 را به شما می دهد و به وضوح دارای ریشه های مثبت و منفی 1 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.68,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda squared minus 1.",
  "translatedText": "هنگامی که ماتریس دوم را انجام می دهید، همان پاسخ، مربع لامبدا منهای یک. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it's already a diagonal matrix, so those diagonal entries are the eigenvalues.",
  "translatedText": "و در مورد آخرین ماتریس، انجام هر گونه محاسبات، سنتی یا غیر آن را فراموش کنید، در حال حاضر یک ماتریس مورب است، بنابراین آن ورودی های مورب مقادیر ویژه هستند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause.",
  "translatedText": "با این حال، مثال به طور کامل برای ما گم نشده است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speedup is in the more general case, where you take a linear combination of these three matrices and then try to compute the eigenvalues.",
  "translatedText": "جایی که شما واقعاً افزایش سرعت را احساس خواهید کرد در حالت کلی تر است، جایی که ترکیبی خطی از این سه ماتریس را می گیرید و سپس سعی می کنید مقادیر ویژه را محاسبه کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third.",
  "translatedText": "ممکن است این را به صورت ضربدر اولی، به اضافه b ضربدر دوم، به علاوه c ضربدر سوم بنویسید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates a, b, c.",
  "translatedText": "در مکانیک کوانتومی، این مشاهدات اسپین را در جهت کلی یک بردار با مختصات a، b، c توصیف می‌کند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume that this vector is normalized, meaning a squared plus b squared plus c squared is equal to 1.",
  "translatedText": "به طور خاص، شما باید فرض کنید که این بردار نرمال شده است، به این معنی که مجذور بعلاوه b مجذور مجذور c برابر با یک است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it's immediate to see that the mean of the eigenvalues is still 0.",
  "translatedText": "وقتی به این ماتریس جدید نگاه می کنید، بلافاصله متوجه می شوید که میانگین مقادیر ویژه هنوز 0 است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.6,
  "end": 604.1
 },
 {
  "input": "And you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still negative 1.",
  "translatedText": "و همچنین ممکن است از مکث کوتاهی برای تأیید اینکه حاصلضرب آن مقادیر ویژه هنوز منفی 1 است لذت ببرید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 604.6,
  "end": 610.9
 },
 {
  "input": "And then from there, concluding what the eigenvalues must be.",
  "translatedText": "و سپس از آنجا، نتیجه گیری که مقادیر ویژه باید چه باشند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 613.26,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head.",
  "translatedText": "و این بار، روش چند جمله‌ای مشخصه در مقایسه با آن بسیار دست و پا گیرتر خواهد بود، قطعاً انجام آن در ذهن شما دشوارتر است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean product formula is not fundamentally different from finding roots of the characteristic polynomial.",
  "translatedText": "برای روشن بودن، استفاده از فرمول حاصل از میانگین تفاوت اساسی با یافتن ریشه های چند جمله ای مشخصه ندارد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 625.08,
  "end": 630.96
 },
 {
  "input": "I mean, it can't be, they're solving the same problem.",
  "translatedText": "یعنی نمی شود، همین مشکل را حل می کنند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 631.34,
  "end": 633.44
 },
 {
  "input": "One way to think about this actually is that the mean product formula is a nice way to solve quadratics in general.",
  "translatedText": "یک راه برای فکر کردن در مورد این در واقع این است که فرمول محصول میانگین یک راه خوب برای حل درجه دوم به طور کلی است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.16,
  "end": 639.02
 },
 {
  "input": "And some viewers of the channel may recognize this.",
  "translatedText": "و برخی از بینندگان کانال ممکن است این را تشخیص دهند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 639.6,
  "end": 641.66
 },
 {
  "input": "Think about it, when you're trying to find the roots of a quadratic, given the coefficients, that's another situation where you know the sum of two values, and you also know their product, but you're trying to recover the original two values.",
  "translatedText": "در مورد آن فکر کنید، وقتی می خواهید ریشه های یک درجه دوم را با توجه به ضرایب پیدا کنید، این موقعیت دیگری است که مجموع دو مقدار را می دانید، و همچنین حاصلضرب آنها را می دانید، اما سعی می کنید دو مقدار اصلی را بازیابی کنید. ارزش های.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized, so that this leading coefficient is 1, then the mean of the roots will be negative 1 half times this linear coefficient, which is negative 1 times the sum of those roots.",
  "translatedText": "به طور خاص، اگر چند جمله ای نرمال شود به طوری که این ضریب پیشرو یک باشد، میانگین ریشه ها یک نیم برابر این ضریب خطی منفی خواهد بود که یک برابر مجموع آن ریشه ها منفی است. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "With the example on the screen, that makes the mean 5.",
  "translatedText": "با مثال روی صفحه، این میانگین را 5 می کند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it's just the constant term, no adjustments needed.",
  "translatedText": "و محصول ریشه ها حتی ساده تر است، فقط یک مدت ثابت است، نیازی به تنظیمات نیست.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula, and that gives you the roots.",
  "translatedText": "بنابراین، از آنجا، فرمول میانگین محصول را اعمال می کنید، و این به شما ریشه می دهد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "And on the one hand, you could think of this as a lighter weight version of the traditional quadratic formula.",
  "translatedText": "و از یک طرف، می توانید این را به عنوان یک نسخه سبک تر از فرمول سنتی درجه دوم در نظر بگیرید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is not just that it's fewer symbols to memorize, it's that each one of them carries more meaning with it.",
  "translatedText": "اما مزیت واقعی فقط این نیست که نمادهای کمتری برای به خاطر سپردن است، بلکه این است که هر یک از آنها معنای بیشتری را با خود حمل می کند. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "I mean, the whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "translatedText": "منظورم این است که تمام هدف این ترفند ارزش ویژه این است که چون می‌توانید میانگین و محصول را مستقیماً از نگاه کردن به ماتریس بخوانید، نیازی نیست که مرحله میانی تنظیم چند جمله‌ای مشخصه را طی کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like.",
  "translatedText": "می‌توانید مستقیماً به نوشتن ریشه‌ها بپردازید، بدون اینکه به صراحت در مورد ظاهر چند جمله‌ای فکر کنید. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that, we need a version of the quadratic formula where the terms carry some kind of meaning.",
  "translatedText": "اما برای انجام این کار، ما به نسخه‌ای از فرمول درجه دوم نیاز داریم که در آن اصطلاحات دارای نوعی معنا باشند.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize this is a very specific trick for a very specific audience, but it's something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them.",
  "translatedText": "من متوجه هستم که این یک ترفند بسیار خاص برای یک مخاطب بسیار خاص است، اما چیزی است که آرزو می‌کردم در دانشگاه می‌دانستم، بنابراین اگر دانش‌آموزانی را می‌شناسید که ممکن است از این موضوع سود ببرند، آن را با آنها به اشتراک بگذارید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it's not just one more thing that you memorize, but that the framing reinforces some other nice facts that are worth knowing, like how the trace and the determinant are related to eigenvalues.",
  "translatedText": "امید این است که این فقط یک چیز دیگر نیست که به خاطر بسپارید، بلکه کادربندی برخی حقایق خوب دیگر را که ارزش دانستن دارند، مانند نحوه ارتباط ردیابی و تعیین کننده با مقادیر ویژه، تقویت کند. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and then think hard about the meaning of each of these coefficients.",
  "translatedText": "اگر می خواهید آن حقایق را ثابت کنید، به هر حال، یک لحظه وقت بگذارید و چند جمله ای مشخصه را برای یک ماتریس کلی گسترش دهید، و سپس در مورد معنای هر یک از این ضرایب خوب فکر کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim for ensuring that this mean product formula will stay stuck in all of our heads for at least a few months.",
  "translatedText": "با تشکر فراوان از تیم برای اطمینان از اینکه این فرمول محصول متوسط حداقل برای چند ماه در ذهن همه ما گیر کرده است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don't know about alcappella science, please do check it out.",
  "translatedText": "اگر در مورد علم آلکاپلا اطلاعاتی ندارید، لطفاً آن را بررسی کنید.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "The molecular shape of you in particular is one of the greatest things on the internet.",
  "translatedText": "شکل مولکولی شما به طور خاص یکی از بهترین چیزها در اینترنت است.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]