[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices.",
  "translatedText": "هذا مقطع فيديو لأي شخص يعرف بالفعل ما هي القيم الذاتية والمتجهات الذاتية، ومن قد يستمتع بطريقة سريعة لحسابها في حالة المصفوفات 2x2. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you're unfamiliar with eigenvalues, go ahead and take a look at this video here, which is actually meant to introduce them.",
  "translatedText": "إذا لم تكن على دراية بالقيم الذاتية، فاستمر وألق نظرة على هذا الفيديو هنا، والذي يهدف في الواقع إلى التعريف بها. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if all you want to do is see the trick, but if possible I'd like you to rediscover it for yourself.",
  "translatedText": "يمكنك التخطي للأمام إذا كان كل ما تريد فعله هو رؤية الخدعة، ولكن إذا أمكن، أود منك إعادة اكتشافها بنفسك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 14.68,
  "end": 20.1
 },
 {
  "input": "So for that, let's lay out a little background.",
  "translatedText": "لذلك، دعونا نضع خلفية صغيرة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.58,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale that vector by some constant, we call it an eigenvector of the transformation, and we call the relevant scaling factor the corresponding eigenvalue, often denoted with the letter lambda.",
  "translatedText": "كتذكير سريع، إذا كان تأثير تحويل خطي على متجه معين هو قياس هذا المتجه بواسطة ثابت ما، فإننا نسميه ناقلًا ذاتيًا للتحويل، ونسمي عامل القياس ذي الصلة القيمة الذاتية المقابلة، والتي غالبًا ما يُشار إليها بالحرف لامدا.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation, and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix A minus lambda times the identity must send some non-zero vector, namely the corresponding eigenvector, to the zero vector, which in turn means that the determinant of this modified matrix must be zero.",
  "translatedText": "عندما تكتب هذا كمعادلة، وتعيد الترتيب قليلاً، ما تراه هو أنه إذا كان عدد لامدا هو قيمة ذاتية لمصفوفة A، فإن المصفوفة A ناقص لامدا مضروبة في الهوية يجب أن ترسل متجهًا غير صفري، وهو المتجه الذاتي المقابل للمتجه الصفري، والذي بدوره يعني أن محدد هذه المصفوفة المعدلة يجب أن يكون صفرًا.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that's all a little bit of a mouthful to say, but again, I'm assuming that all of this is review for any of you watching.",
  "translatedText": "حسنًا، هذا أمر مبالغ فيه بعض الشيء، لكن مرة أخرى، أفترض أن كل هذا عبارة عن مراجعة لأي منكم يشاهده. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals, and then solve for the determinant is equal to zero.",
  "translatedText": "لذا، فإن الطريقة المعتادة لحساب القيم الذاتية، والتي اعتدت أن أفعلها والتي أعتقد أن معظم الطلاب تعلموا كيفية تنفيذها، هي طرح القيمة المجهولة لامدا من الأقطار، ثم إيجاد قيمة المحدد يساوي صفر.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few extra steps to expand out and simplify to get a clean quadratic polynomial, what's known as the characteristic polynomial of the matrix.",
  "translatedText": "يتضمن القيام بذلك دائمًا بضع خطوات إضافية للتوسيع والتبسيط للحصول على كثيرة الحدود من الدرجة الثانية، وهو ما يُعرف باسم كثيرة الحدود المميزة للمصفوفة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial, so to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification.",
  "translatedText": "القيم الذاتية هي جذور كثيرة الحدود، لذلك للعثور عليها عليك تطبيق الصيغة التربيعية، والتي تتطلب في حد ذاتها عادةً خطوة أو خطوتين إضافيتين من التبسيط.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 97.36,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn't terrible, but at least for two by two matrices, there is a much more direct way you can get at the answer.",
  "translatedText": "بصراحة، العملية ليست فظيعة، ولكن على الأقل بالنسبة لمصفوفتين في مصفوفتين، هناك طريقة أكثر مباشرة يمكنك من خلالها الحصول على الإجابة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.76,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there's only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem solving.",
  "translatedText": "وإذا كنت تريد إعادة اكتشاف هذه الخدعة، فهناك ثلاث حقائق ذات صلة فقط تحتاج إلى معرفتها، كل واحدة منها تستحق المعرفة في حد ذاتها ويمكن أن تساعدك في حل المشكلات الأخرى.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number one, the trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "translatedText": "رقم واحد، أثر المصفوفة، وهو مجموع هذين المدخلين القطريين، يساوي مجموع القيم الذاتية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or, another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries.",
  "translatedText": "أو هناك طريقة أخرى لصياغة الأمر، أكثر فائدة لأغراضنا، وهي أن متوسط القيمتين الذاتيتين هو نفس متوسط هذين الإدخالين القطريين.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number two, the determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues.",
  "translatedText": "رقم اثنين، محدد المصفوفة، صيغتنا المعتادة ad-bc، يساوي حاصل ضرب القيمتين الذاتيتين.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction, and that the determinant describes how much an operator scales areas, or volumes, as a whole.",
  "translatedText": "وينبغي أن يكون هذا منطقيًا نوعًا ما إذا فهمت أن القيم الذاتية تصف مدى قيام العامل بتمديد المساحة في اتجاه معين، وأن المحدد يصف مقدار قيام العامل بقياس المساحات أو الأحجام ككل.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down.",
  "translatedText": "الآن قبل الوصول إلى الحقيقة الثالثة، لاحظ كيف يمكنك قراءة هاتين القيمتين الأوليين من المصفوفة دون كتابة الكثير. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example.",
  "translatedText": "خذ هذه المصفوفة هنا كمثال. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away, you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7.",
  "translatedText": "على الفور، يمكنك معرفة أن متوسط القيم الذاتية هو نفس متوسط 8 و 6، وهو 7.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well practiced at finding the determinant, which in this case works out to be 48 minus 8.",
  "translatedText": "وبالمثل، فإن معظم طلاب الجبر الخطي ماهرون جيدًا في إيجاد المحدد، والذي في هذه الحالة يساوي 48 ناقص 8.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 179.58,
  "end": 187.08
 },
 {
  "input": "So right away, you know that the product of the two eigenvalues is 40.",
  "translatedText": "إذن، ستعرف على الفور أن حاصل ضرب القيمتين الذاتيتين هو 40.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 188.24,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see if you can derive what will be our third relevant fact, which is how you can quickly recover two numbers when you know their mean and you know their product.",
  "translatedText": "توقف الآن للحظة لترى ما إذا كان بإمكانك استخلاص الحقيقة الثالثة ذات الصلة، وهي كيف يمكنك استرداد رقمين بسرعة عندما تعرف متوسطهما وتعرف حاصل ضربهما. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example.",
  "translatedText": "وهنا، دعونا نركز على هذا المثال. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know that the two values are evenly spaced around the number 7, so they look like 7 plus or minus something, let's call that something d for distance.",
  "translatedText": "أنت تعلم أن القيمتين متباعدتان بالتساوي حول الرقم 7، لذا فإنهما تبدوان مثل 7 زائد أو ناقص شيء ما، دعنا نسمي ذلك شيئًا d للمسافة. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40.",
  "translatedText": "وتعلم أيضًا أن حاصل ضرب هذين الرقمين هو 40. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares.",
  "translatedText": "الآن لإيجاد d، لاحظ أن هذا المنتج يتمدد بشكل جيد للغاية، فهو يمثل فرقًا بين المربعات. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can find d.",
  "translatedText": "ومن هناك يمكنك أن تجد د.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.56,
  "end": 226.86
 },
 {
  "input": "d squared is 7 squared minus 40, or 9, which means that d itself is 3.",
  "translatedText": "د تربيع هو 7 تربيع ناقص 40، أو 9، مما يعني أن د نفسه يساوي 3.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 228.2,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10.",
  "translatedText": "بمعنى آخر، القيمتان لهذا المثال المحدد للغاية هما 4 و10. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn't want to think through this each time, so let's wrap up what we just did in a general formula.",
  "translatedText": "لكن هدفنا هو خدعة سريعة، ولن ترغب في التفكير في هذا في كل مرة، لذلك دعونا نلخص ما فعلناه للتو في صيغة عامة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean m and product p, the distance squared is always going to be m squared minus p.",
  "translatedText": "بالنسبة لأي متوسط m وحاصل p، فإن مربع المسافة سيكون دائمًا m مربعًا ناقص p.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m plus or minus the square root of m squared minus p.",
  "translatedText": "وهذا يعطي الحقيقة الرئيسية الثالثة، وهي أنه عندما يكون لعددين متوسط m وحاصل ضرب p، يمكنك كتابة هذين الرقمين على صورة m زائد أو ناقص الجذر التربيعي لـ m تربيع ناقص p.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 257.56,
  "end": 268.46
 },
 {
  "input": "This is decently fast to re-derive on the fly if you ever forget it, and it's essentially just a rephrasing of the difference of squares formula.",
  "translatedText": "يعد هذا أمرًا سريعًا جدًا لإعادة اشتقاقه بسرعة إذا نسيته، وهو في الأساس مجرد إعادة صياغة لصيغة الفرق بين المربعات.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.1,
  "end": 277.08
 },
 {
  "input": "But even still, it's a fact that's worth memorizing so it's at the tip of your fingers.",
  "translatedText": "ولكن حتى مع ذلك، إنها حقيقة تستحق الحفظ، لذا فهي على أطراف أصابعك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel A Capella Science wrote us a nice quick jingle to make it a little bit more memorable.",
  "translatedText": "في الواقع، كتب لنا صديقي تيم من قناة A Capella Science أغنية سريعة لطيفة لجعلها لا تُنسى. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "Let me show you how this works, say for the matrix 3 1 4 1.",
  "translatedText": "دعني أوضح لك كيف يتم ذلك، مثلًا للمصفوفة 3 1 4 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head.",
  "translatedText": "عليك أن تبدأ بتذكر الصيغة، وربما تذكرها كلها في رأسك. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values for m and p as you go.",
  "translatedText": "ولكن عند كتابتها، فإنك تقوم بملء القيم المناسبة لـ m وp أثناء تقدمك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2, so the thing you start writing is 2 plus or minus the square root of 2 squared minus.",
  "translatedText": "إذن في هذا المثال، متوسط القيم الذاتية هو نفس متوسط 3 و1، وهو 2، لذا فإن الشيء الذي تبدأ كتابته هو 2 زائد أو ناقص الجذر التربيعي لـ 2 تربيع ناقص.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.34,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3 times 1 minus 1 times 4, or negative 1, so that's the final thing you fill in, which means the eigenvalues are 2 plus or minus the square root of 5.",
  "translatedText": "ثم يكون حاصل ضرب القيم الذاتية هو المحدد، وهو في هذا المثال 3 في 1 ناقص 1 في 4، أو سالب 1، لذا فإن هذا هو آخر شيء تقوم بملئه، وهو ما يعني أن القيم الذاتية هي 2 زائد أو ناقص الجذر التربيعي لـ 5 .",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.54,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer.",
  "translatedText": "ربما تدرك أن هذه هي نفس المصفوفة التي كنت أستخدمها في البداية، لكن لاحظ مدى قدرتنا على الحصول على الإجابة بشكل مباشر. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one.",
  "translatedText": "هنا، حاول واحدة أخرى. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5.",
  "translatedText": "هذه المرة، متوسط القيم الذاتية هو نفس متوسط 2 و8، وهو 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula, but this time writing 5 in place of m.",
  "translatedText": "لذا، مرة أخرى، تبدأ في كتابة الصيغة، ولكن هذه المرة تكتب 5 بدلاً من m.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2 times 8 minus 7 times 1, or 9.",
  "translatedText": "ثم المحدد هو 2*8 - 7*1، أو 9. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 plus or minus the square root of 16, which simplifies even further as 9 and 1.",
  "translatedText": "لذا في هذا المثال، تبدو القيم الذاتية مثل 5 ± sqrt(16)، والتي يمكن تبسيطها بشكل أكبر إلى 9 و1. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while you're staring at the matrix?",
  "translatedText": "هل ترى ما أعنيه حول كيف يمكنك البدء في كتابة القيم الذاتية أثناء التحديق في المصفوفة؟",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It's typically just the tiniest bit of simplification at the end.",
  "translatedText": "عادةً ما يكون هذا مجرد جزء صغير من التبسيط في النهاية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I've found myself using this trick a lot when I'm sketching quick notes related to linear algebra and want to use small matrices as examples.",
  "translatedText": "بصراحة، وجدت نفسي أستخدم هذه الخدعة كثيرًا عندما أقوم برسم ملاحظات سريعة تتعلق بالجبر الخطي وأريد استخدام المصفوفات الصغيرة كأمثلة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I've been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realize it's just very handy if students can read out the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation.",
  "translatedText": "لقد كنت أعمل على مقطع فيديو حول أسس المصفوفات، حيث تظهر القيم الذاتية كثيرًا، وأدرك أنه من المفيد جدًا أن يتمكن الطلاب من قراءة القيم الذاتية من أمثلة صغيرة دون فقدان خط التفكير الرئيسي من خلال التورط في مشكلة مختلفة عملية حسابية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which comes up a lot in quantum mechanics.",
  "translatedText": "كمثال ممتع آخر، ألقِ نظرة على هذه المجموعة المكونة من ثلاث مصفوفات مختلفة، والتي تظهر كثيرًا في ميكانيكا الكم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 409.74,
  "end": 415.46
 },
 {
  "input": "They're known as the Pauli spin matrices.",
  "translatedText": "تُعرف باسم مصفوفات باولي المغزلية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 415.76,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you'll know that the eigenvalues of matrices are highly relevant to the physics that they describe.",
  "translatedText": "إذا كنت تعرف ميكانيكا الكم، فستعرف أن القيم الذاتية للمصفوفات وثيقة الصلة بالفيزياء التي تصفها.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 418.6,
  "end": 424.42
 },
 {
  "input": "And if you don't know quantum mechanics, let this just be a little glimpse of how these computations are actually very relevant to real applications.",
  "translatedText": "وإذا كنت لا تعرف ميكانيكا الكم، فلتكن هذه مجرد لمحة بسيطة عن مدى أهمية هذه الحسابات في الواقع للتطبيقات الحقيقية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.22,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal entries in all three cases is zero.",
  "translatedText": "متوسط الإدخالات القطرية في الحالات الثلاث هو صفر.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 432.54,
  "end": 435.88
 },
 {
  "input": "So the mean of the eigenvalues in all of these cases is zero, which makes our formula look especially simple.",
  "translatedText": "إذن متوسط القيم الذاتية في كل هذه الحالات هو صفر، وهو ما يجعل الصيغة تبدو بسيطة بشكل خاص.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 437.56,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices?",
  "translatedText": "ماذا عن حاصل ضرب القيم الذاتية ومحددات هذه المصفوفات؟ ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it's 0, minus 1, or negative 1.",
  "translatedText": "بالنسبة للرقم الأول، فهو 0 أو ناقص 1 أو سالب 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.7,
  "end": 452.56
 },
 {
  "input": "The second one also looks like 0, minus 1, but it takes a moment more to see because of the complex numbers.",
  "translatedText": "والرقم الثاني يبدو أيضًا مثل 0، ناقص 1، لكن الأمر يستغرق لحظة أكثر لرؤيته بسبب الأعداد المركبة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.2,
  "end": 458.2
 },
 {
  "input": "And the final one looks like negative 1, minus 0.",
  "translatedText": "والشكل الأخير يشبه سالب 1 ناقص 0. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be plus and minus 1.",
  "translatedText": "لذا، في جميع الحالات، يتم تبسيط القيم الذاتية لتكون زائد وناقص 1. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don't need a formula to find two values if you know that they're evenly spaced around 0 and their product is negative 1.",
  "translatedText": "على الرغم من أنك في هذه الحالة لا تحتاج حقًا إلى صيغة للعثور على قيمتين إذا كنت تعلم أنهما متباعدتان بشكل متساوٍ حول 0 وحاصل ضربهما هو سالب 1. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you're curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y, or z direction.",
  "translatedText": "إذا كنت فضوليًا، في سياق ميكانيكا الكم، تصف هذه المصفوفات الملاحظات التي قد تقوم بها حول دوران الجسيم في اتجاه x أو y أو z.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.12
 },
 {
  "input": "And the fact that their eigenvalues are plus and minus 1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between.",
  "translatedText": "وحقيقة أن القيم الذاتية لها زائد وناقص 1 تتوافق مع فكرة أن قيم الدوران التي ستلاحظها ستكون إما بالكامل في اتجاه واحد أو بالكامل في اتجاه آخر، على عكس شيء يتراوح بشكل مستمر بينهما.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 483.56,
  "end": 497.02
 },
 {
  "input": "Maybe you'd wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions.",
  "translatedText": "ربما تتساءل كيف يعمل هذا بالضبط، أو لماذا تستخدم مصفوفات 2x2 التي تحتوي على أرقام معقدة لوصف الدوران في ثلاثة أبعاد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "Those would be fair questions, just outside the scope of what I want to talk about here.",
  "translatedText": "ستكون هذه أسئلة عادلة، ولكنها خارج نطاق ما أريد أن أتحدث عنه هنا.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know, it's funny, I wrote this section because I wanted some case where you have 2x2 matrices that aren't just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that.",
  "translatedText": "كما تعلمون، إنه أمر مضحك، لقد كتبت هذا القسم لأنني أردت بعض الحالات التي يكون لديك فيها مصفوفات 2x2 ليست مجرد أمثلة على الألعاب أو واجبات منزلية، تلك التي تظهر بالفعل في الممارسة العملية، وميكانيكا الكم رائعة لذلك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "The thing is, after I made it, I realized that the whole example kind of undercuts the point that I'm trying to make.",
  "translatedText": "الأمر هو أنني بعد أن قمت بذلك، أدركت أن المثال برمته يقوض النقطة التي أحاول توضيحها.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it's essentially just as fast.",
  "translatedText": "بالنسبة لهذه المصفوفات المحددة، عندما تستخدم الطريقة التقليدية، الطريقة ذات متعددات الحدود المميزة، فهي في الأساس بنفس السرعة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 528.74,
  "end": 536.1
 },
 {
  "input": "It might actually be faster.",
  "translatedText": "قد يكون في الواقع أسرع.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 536.22,
  "end": 537.64
 },
 {
  "input": "I mean, take a look at the first one.",
  "translatedText": "أعني، إلقاء نظرة على أول واحد.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.24,
  "end": 539.4
 },
 {
  "input": "The relevant determinant directly gives you a characteristic polynomial of lambda squared minus 1, and clearly that has roots of plus and minus 1.",
  "translatedText": "يمنحك المحدد ذو الصلة بشكل مباشر متعددة الحدود المميزة لامدا تربيع ناقص 1، ومن الواضح أن جذورها زائد وناقص 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.68,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda squared minus 1.",
  "translatedText": "نفس الإجابة عند استخدام المصفوفة الثانية، لامدا تربيع ناقص واحد. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it's already a diagonal matrix, so those diagonal entries are the eigenvalues.",
  "translatedText": "أما بالنسبة للمصفوفة الأخيرة، فلا داعي لإجراء أي حسابات، تقليدية أو غير ذلك، فهي بالفعل مصفوفة قطرية، لذا فإن تلك المدخلات القطرية هي القيم الذاتية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause.",
  "translatedText": "ومع ذلك، فإن المثال لم يضيع تماما لقضيتنا. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speedup is in the more general case, where you take a linear combination of these three matrices and then try to compute the eigenvalues.",
  "translatedText": "المكان الذي ستشعر فيه فعليًا بالتسارع هو في الحالة الأكثر عمومية، حيث تأخذ مجموعة خطية من هذه المصفوفات الثلاثة ثم تحاول حساب القيم الذاتية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third.",
  "translatedText": "يمكنك كتابة ذلك على صورة a مضروبًا في الأول، بالإضافة إلى b مضروبًا في الثاني، بالإضافة إلى c مضروبًا في الثالث. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates a, b, c.",
  "translatedText": "في ميكانيكا الكم، هذا من شأنه أن يصف ملاحظات الدوران في الاتجاه العام لمتجه بإحداثيات a، b، c.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume that this vector is normalized, meaning a squared plus b squared plus c squared is equal to 1.",
  "translatedText": "وبشكل أكثر تحديدًا، يجب أن تفترض أن هذا المتجه تم تسويته، مما يعني أن تربيع زائد ب تربيع زائد ج تربيع يساوي واحدًا. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it's immediate to see that the mean of the eigenvalues is still 0.",
  "translatedText": "عندما تنظر إلى هذه المصفوفة الجديدة، فمن الفوري أن ترى أن متوسط القيم الذاتية لا يزال 0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.6,
  "end": 604.1
 },
 {
  "input": "And you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still negative 1.",
  "translatedText": "وقد تستمتع أيضًا بالتوقف مؤقتًا للحظة قصيرة للتأكد من أن حاصل ضرب تلك القيم الذاتية لا يزال سالبًا 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 604.6,
  "end": 610.9
 },
 {
  "input": "And then from there, concluding what the eigenvalues must be.",
  "translatedText": "وبعد ذلك، نستنتج ما يجب أن تكون عليه القيم الذاتية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 613.26,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head.",
  "translatedText": "وهذه المرة، سيكون النهج متعدد الحدود المميز أكثر تعقيدًا بكثير، وبالتأكيد أصعب في التنفيذ في رأسك. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean product formula is not fundamentally different from finding roots of the characteristic polynomial.",
  "translatedText": "لكي نكون واضحين، فإن استخدام صيغة حاصل الضرب المتوسط لا يختلف جوهريًا عن إيجاد جذور كثيرة الحدود المميزة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 625.08,
  "end": 630.96
 },
 {
  "input": "I mean, it can't be, they're solving the same problem.",
  "translatedText": "أعني، لا يمكن أن يكون الأمر كذلك، إنهم يحلون نفس المشكلة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 631.34,
  "end": 633.44
 },
 {
  "input": "One way to think about this actually is that the mean product formula is a nice way to solve quadratics in general.",
  "translatedText": "إحدى طرق التفكير في هذا الأمر هي أن صيغة حاصل الضرب المتوسط هي طريقة رائعة لحل المعادلات التربيعية بشكل عام.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.16,
  "end": 639.02
 },
 {
  "input": "And some viewers of the channel may recognize this.",
  "translatedText": "وقد يتعرف بعض مشاهدي القناة على ذلك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 639.6,
  "end": 641.66
 },
 {
  "input": "Think about it, when you're trying to find the roots of a quadratic, given the coefficients, that's another situation where you know the sum of two values, and you also know their product, but you're trying to recover the original two values.",
  "translatedText": "فكر في الأمر، عندما تحاول العثور على جذور معادلة تربيعية، بمعرفة المعاملات، فهذا موقف آخر حيث تعرف مجموع قيمتين، وتعرف أيضًا حاصل ضربهما، لكنك تحاول استرداد القيمتين الأصليتين قيم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized, so that this leading coefficient is 1, then the mean of the roots will be negative 1 half times this linear coefficient, which is negative 1 times the sum of those roots.",
  "translatedText": "على وجه التحديد، إذا تمت تسوية كثيرة الحدود بحيث يكون هذا المعامل الرئيسي واحدًا، فإن متوسط الجذور سيكون سالب نصف مضروبًا في هذا المعامل الخطي، وهو ما يساوي سالبًا واحدًا في مجموع تلك الجذور. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "With the example on the screen, that makes the mean 5.",
  "translatedText": "في المثال الذي يظهر على الشاشة، هذا يجعل المتوسط 5.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it's just the constant term, no adjustments needed.",
  "translatedText": "وحاصل ضرب الجذور أسهل، فهو مجرد حد ثابت، ولا حاجة لأي تعديلات.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula, and that gives you the roots.",
  "translatedText": "ومن هنا، يمكنك تطبيق صيغة حاصل الضرب المتوسط، وهذا يمنحك الجذور.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "And on the one hand, you could think of this as a lighter weight version of the traditional quadratic formula.",
  "translatedText": "ومن ناحية، يمكنك اعتبارها نسخة أخف وزنًا من الصيغة التربيعية التقليدية.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is not just that it's fewer symbols to memorize, it's that each one of them carries more meaning with it.",
  "translatedText": "لكن الميزة الحقيقية ليست فقط أن عدد الرموز التي يجب حفظها أقل، بل أن كل واحد منها يحمل معنى أكبر معه. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "I mean, the whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "translatedText": "أعني أن المغزى الأساسي من خدعة القيمة الذاتية هو أنه نظرًا لأنه يمكنك قراءة المتوسط وحاصل الضرب مباشرةً من خلال النظر إلى المصفوفة، فلن تحتاج إلى المرور بالخطوة المتوسطة لإعداد كثيرة الحدود المميزة.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like.",
  "translatedText": "يمكنك الانتقال مباشرة إلى كتابة الجذور دون التفكير بشكل صريح في شكل كثيرة الحدود. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that, we need a version of the quadratic formula where the terms carry some kind of meaning.",
  "translatedText": "لكن للقيام بذلك، نحتاج إلى نسخة من الصيغة التربيعية تحمل فيها الحدود نوعًا ما من المعنى.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize this is a very specific trick for a very specific audience, but it's something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them.",
  "translatedText": "أدرك أن هذه خدعة محددة جدًا لجمهور محدد جدًا، ولكن هذا شيء أتمنى لو كنت أعرفه في الكلية، لذلك إذا كنت تعرف أي طلاب قد يستفيدون من هذا، ففكر في مشاركته معهم.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it's not just one more thing that you memorize, but that the framing reinforces some other nice facts that are worth knowing, like how the trace and the determinant are related to eigenvalues.",
  "translatedText": "الأمل هو أنه ليس مجرد شيء آخر تحفظه، ولكن أن الإطار يعزز بعض الحقائق اللطيفة الأخرى التي تستحق المعرفة، مثل كيفية ارتباط التتبع والمحدد بالقيم الذاتية. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and then think hard about the meaning of each of these coefficients.",
  "translatedText": "إذا كنت تريد إثبات هذه الحقائق، فبالمناسبة، خذ لحظة لتوسيع متعددة الحدود المميزة لمصفوفة عامة، ثم فكر مليًا في معنى كل من هذه المعاملات.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim for ensuring that this mean product formula will stay stuck in all of our heads for at least a few months.",
  "translatedText": "شكرًا جزيلاً لتيم على ضمان بقاء تركيبة المنتج المتوسطة هذه عالقة في رؤوسنا جميعًا لبضعة أشهر على الأقل.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don't know about alcappella science, please do check it out.",
  "translatedText": "إذا كنت لا تعرف عن علم الكابيلا، يرجى التحقق من ذلك.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "The molecular shape of you in particular is one of the greatest things on the internet.",
  "translatedText": "يعد الشكل الجزيئي لك على وجه الخصوص أحد أعظم الأشياء على الإنترنت.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]