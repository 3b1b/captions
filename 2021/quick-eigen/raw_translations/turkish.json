[
 {
  "input": "Intro 00:00:01,989 --> 00:00:06,060 3   the trick, but if possible I’d like you to rediscover it for yourself, so for that 00:00:23,349 --> 00:00:28,550 8  often denoted with the letter lambda.",
  "model": "nmt",
  "translatedText": "Bu, özdeğerlerin ve özvektörlerin ne olduğunu zaten bilen ve bunları 2x2 matrisler durumunda hızlı bir şekilde hesaplamanın keyfini çıkarabilecek herkes için bir videodur. Özdeğerlere aşina değilseniz, devam edin ve buradaki videoya bir göz atın; bu video aslında onları tanıtmayı amaçlamaktadır. Tek yapmak istediğiniz hileyi görmekse ileri atlayabilirsiniz, ancak mümkünse bunu kendi başınıza yeniden keşfetmenizi isterim. Bunun için biraz arka plan hazırlayalım. Kısa bir hatırlatma olarak, belirli bir vektör üzerindeki doğrusal dönüşümün etkisi, bu vektörü bir sabitle ölçeklendirmekse, buna dönüşümün özvektörü adını veririz ve ilgili ölçeklendirme faktörüne karşılık gelen özdeğer adını veririz ve genellikle şu harfle gösterilir: lambda. Bunu bir denklem olarak yazdığınızda ve biraz yeniden düzenlediğinizde, eğer lambda sayısı bir A matrisinin özdeğeriyse, o zaman A matrisi eksi lambda çarpı özdeşliğin sıfırdan farklı bir vektör göndermesi gerektiğini görürsünüz."
 },
 {
  "input": "When you write this as an equation and you rearrange 00:00:47,320 --> 00:00:53,190 12  of this modified matrix must be 0.",
  "model": "nmt",
  "translatedText": "karşılık gelen özvektörün sıfır vektörüne oranı, bu da bu değiştirilmiş matrisin determinantının sıfır olması gerektiği anlamına gelir. Tamam, bunları söylemek biraz fazla ama yine de tüm bunların izleyenleriniz için bir inceleme olduğunu varsayıyorum. Dolayısıyla, özdeğerleri hesaplamanın genel yolu, benim bunu nasıl yaptığım ve çoğu öğrenciye bunu nasıl yapmayı öğrettiğine inandığım, bilinmeyen lambda değerini köşegenlerden çıkarmak ve sonra determinantın sıfıra eşit olduğu zamanı bulmaktır."
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful 00:01:09,960 --> 00:01:12,829 00:01:12,829 --> 00:01:17,939 17  equals 0.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Doing this always involves a few steps to 00:01:32,630 --> 00:01:38,069 21  more steps of simplification.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Honestly, the process isn’t terrible.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But 00:01:52,710 --> 00:01:57,049 25   the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Or another 00:02:14,700 --> 00:02:18,959 30 31  of make sense if you understand that eigenvalues describe how much an operator stretches space 00:02:37,720 --> 00:02:42,189 35  much down.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Take this matrix here as an example.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Straight away you can know that the mean of 00:02:55,970 --> 00:03:02,420 39  is 40.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Now take a moment to see how you can derive 00:03:17,079 --> 00:03:21,860 43  let’s call that something \"d\" for distance.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "You also know that the product of these two 00:03:40,239 --> 00:03:45,480 47  specific example work out to be 4 and 10.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t 00:04:06,239 --> 00:04:12,610 51  you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly 00:04:34,490 --> 00:04:39,360 56  wrote us a quick jingle to make it a little more memorable.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "m plus or minus squaaaare root of me squared 00:04:53,880 --> 00:04:59,069 61  p as you go.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean 00:05:19,030 --> 00:05:26,780 65  might recognize that this is the same matrix I was using at the beginning, but notice how 00:05:47,370 --> 00:05:52,190 69  is 2*8 - 7*1, or 9.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which 00:06:19,590 --> 00:06:23,800 73  a lot when I’m sketching quick notes related to linear algebra and want to use small matrices 00:06:37,039 --> 00:06:41,800 77  a different calculation.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "As another fun example, take a look at this 00:06:54,190 --> 00:06:59,419 81  mechanics, let this just be a little glimpse of how these computations are actually relevant 00:07:12,639 --> 00:07:19,990 85  the determinants of these matrices?",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "The second 00:07:36,430 --> 00:07:42,310 89  know theyr'e evenly spaced around 0 and their product is -1.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "If you’re curious, in the context of quantum 00:07:59,759 --> 00:08:04,470 94  or entirely in another, as opposed to something continuously ranging in between.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Maybe you’d 00:08:20,680 --> 00:08:26,259 98  because I wanted some case where you have 2x2 matrices that are not just toy examples 00:08:38,970 --> 00:08:43,880 102  use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; 00:08:58,700 --> 00:09:03,390 106  for the last matrix, forget about doing any computations, traditional or otherwise, it’s 00:09:20,940 --> 00:09:23,510 00:09:23,510 --> 00:09:28,850 111   one, plus b times the second, plus c times the third.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "In quantum mechanics, this would 00:09:47,360 --> 00:09:53,240 116  still zero, and you might also enjoy pausing for a brief moment to confirm that the product 00:10:13,560 --> 00:10:18,710 120   is not fundamentally different from finding roots of the characteristic polynomial; I 00:10:33,110 --> 00:10:37,160 125  the roots of a quadratic given its coefficients, that's another situation where you know the 00:10:50,950 --> 00:10:54,820 129  linear coefficient, which is -1 times the sum of those roots.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "For the example on the 00:11:12,820 --> 00:11:17,610 133  a lighter-weight version of the traditional quadratic formula.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But the real advantage 00:11:34,200 --> 00:11:37,370 137  you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "00:11:49,930 --> 00:11:54,339 141  for a very specific audience, but it’s something I wish I knew in college, so if you happen 00:12:08,240 --> 00:12:10,330 00:12:10,330 --> 00:12:15,140 146  take a moment to expand out the characteristic polynomial for a general matrix, and think 00:12:32,449 --> 00:12:36,420 150  in particular, is one of the greatest things on the internet.",
  "model": "nmt",
  "translatedText": ""
 }
]