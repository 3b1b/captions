[
 {
  "input": "Intro 00:00:01,989 --> 00:00:06,060 3   the trick, but if possible I’d like you to rediscover it for yourself, so for that 00:00:23,349 --> 00:00:28,550 8  often denoted with the letter lambda.",
  "model": "nmt",
  "translatedText": "यह उन लोगों के लिए एक वीडियो है जो पहले से ही जानते हैं कि eigenvalues और eigenvectors क्या हैं, और जो 2x2 मैट्रिक्स के मामले में उनकी गणना करने के त्वरित तरीके का आनंद ले सकते हैं। यदि आप स्वदेशी मूल्यों से अपरिचित हैं, तो आगे बढ़ें और यहां इस वीडियो को देखें, जो वास्तव में उन्हें पेश करने के लिए है। यदि आप सिर्फ ट्रिक देखना चाहते हैं तो आप आगे बढ़ सकते हैं, लेकिन यदि संभव हो तो मैं चाहूंगा कि आप इसे अपने लिए फिर से खोजें। तो उसके लिए, आइए एक छोटी सी पृष्ठभूमि बताएं। एक त्वरित अनुस्मारक के रूप में, यदि किसी दिए गए वेक्टर पर एक रैखिक परिवर्तन का प्रभाव उस वेक्टर को कुछ स्थिरांक द्वारा स्केल करना है, तो हम इसे परिवर्तन का एक आइजनवेक्टर कहते हैं, और हम संबंधित स्केलिंग कारक को संबंधित आइगेनवैल्यू कहते हैं, जिसे अक्सर अक्षर से दर्शाया जाता है। लैम्ब्डा."
 },
 {
  "input": "When you write this as an equation and you rearrange 00:00:47,320 --> 00:00:53,190 12  of this modified matrix must be 0.",
  "model": "nmt",
  "translatedText": "जब आप इसे एक समीकरण के रूप में लिखते हैं, और आप थोड़ा पुनर्व्यवस्थित करते हैं, तो आप जो देखते हैं वह यह है कि यदि संख्या लैम्ब्डा मैट्रिक्स ए का एक आइगेनवैल्यू है, तो मैट्रिक्स ए माइनस लैम्ब्डा बार पहचान को कुछ गैर-शून्य वेक्टर भेजना होगा, अर्थात् संबंधित eigenvector, शून्य वेक्टर के लिए, जिसका अर्थ है कि इस संशोधित मैट्रिक्स का निर्धारक शून्य होना चाहिए। ठीक है, यह सब कहने के लिए थोड़ी-सी बात है, लेकिन फिर भी, मैं यह मान रहा हूं कि यह सब आपमें से जो भी देख रहा है उसके लिए समीक्षा है। तो, आइगेनवैल्यू की गणना करने का सामान्य तरीका, मैं इसे कैसे करता था और मेरा मानना है कि अधिकांश छात्रों को इसे कैसे करना सिखाया जाता है, विकर्णों से अज्ञात मान लैम्ब्डा को घटाना है, और फिर तब हल करना है जब निर्धारक शून्य के बराबर हो."
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful 00:01:09,960 --> 00:01:12,829 00:01:12,829 --> 00:01:17,939 17  equals 0.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Doing this always involves a few steps to 00:01:32,630 --> 00:01:38,069 21  more steps of simplification.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Honestly, the process isn’t terrible.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But 00:01:52,710 --> 00:01:57,049 25   the sum of these two diagonal entries, is equal to the sum of the eigenvalues.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Or another 00:02:14,700 --> 00:02:18,959 30 31  of make sense if you understand that eigenvalues describe how much an operator stretches space 00:02:37,720 --> 00:02:42,189 35  much down.",
  "model": "nmt",
  "translatedText": "ऐसा करने में हमेशा एक स्वच्छ द्विघात बहुपद प्राप्त करने के लिए विस्तार करने और सरल बनाने के लिए कुछ अतिरिक्त कदम शामिल होते हैं, जिसे मैट्रिक्स के विशिष्ट बहुपद के रूप में जाना जाता है। eigenvalues इस बहुपद की जड़ें हैं, इसलिए उन्हें खोजने के लिए आपको द्विघात सूत्र लागू करना होगा, जिसके लिए आमतौर पर सरलीकरण के एक या दो और चरणों की आवश्यकता होती है। ईमानदारी से कहें तो, प्रक्रिया भयानक नहीं है, लेकिन कम से कम 2x2 मैट्रिक्स के लिए, एक अधिक सीधा तरीका है जिससे आप उत्तर प्राप्त कर सकते हैं। और यदि आप इस ट्रिक को फिर से खोजना चाहते हैं, तो केवल तीन प्रासंगिक तथ्य हैं जिन्हें आपको जानना आवश्यक है, जिनमें से प्रत्येक अपने आप में जानने लायक है और अन्य समस्याओं को सुलझाने में आपकी मदद कर सकता है। नंबर एक, एक मैट्रिक्स का निशान, जो इन दो विकर्ण प्रविष्टियों का योग है, eigenvalues के योग के बराबर है। या इसे वाक्यांशित करने का एक और तरीका, जो हमारे उद्देश्यों के लिए अधिक उपयोगी है, वह यह है कि दो eigenvalues का माध्य इन दो विकर्ण प्रविष्टियों के माध्य के समान है। संख्या दो, एक मैट्रिक्स का निर्धारक, हमारा सामान्य विज्ञापन-बीसी सूत्र, दो eigenvalues के उत्पाद के बराबर है। और यह एक तरह से समझ में आना चाहिए यदि आप समझते हैं कि eigenvalues वर्णन करता है कि एक ऑपरेटर किसी विशेष दिशा में अंतरिक्ष को कितना फैलाता है, और यह कि निर्धारक वर्णन करता है कि एक ऑपरेटर समग्र रूप से क्षेत्रों, या वॉल्यूम को कितना मापता है। अब तीसरे तथ्य पर पहुंचने से पहले, ध्यान दें कि आप वास्तव में बहुत कुछ लिखे बिना मैट्रिक्स से इन पहले दो मानों को अनिवार्य रूप से कैसे पढ़ सकते हैं। इस मैट्रिक्स को एक उदाहरण के रूप में यहाँ लें। तुरंत, आप जान सकते हैं कि आइगेनवैल्यू का माध्य 8 और 6 के माध्य के समान है, जो 7 है। इसी तरह, अधिकांश रैखिक बीजगणित के छात्रों को सारणिक खोजने का बहुत अच्छा अभ्यास है, जो इस मामले में 48 घटा 8 होता है। तो तुरंत, आप जान गए कि दोनों eigenvalues का गुणनफल 40 है। अब यह देखने के लिए एक क्षण लें कि क्या आप यह पता लगा सकते हैं कि हमारा तीसरा प्रासंगिक तथ्य क्या होगा, यानी आप दो संख्याओं को कैसे तुरंत पुनर्प्राप्त कर सकते हैं जब आप उनका माध्य जानते हैं और आप उनका उत्पाद जानते हैं। यहां, आइए इस उदाहरण पर ध्यान केंद्रित करें। आप जानते हैं कि दोनों मान संख्या 7 के चारों ओर समान दूरी पर हैं, इसलिए वे 7 प्लस या माइनस कुछ की तरह दिखते हैं, आइए दूरी के लिए इसे कुछ डी कहते हैं। आप यह भी जानते हैं कि इन दोनों संख्याओं का गुणनफल 40 है। अब d खोजने के लिए, ध्यान दें कि यह उत्पाद वास्तव में अच्छी तरह से फैलता है, यह वर्गों के अंतर के रूप में काम करता है। तो वहां से, आप सीधे डी ढूंढ सकते हैं। d का वर्ग 7 वर्ग घटा 40, या 9 है, जिसका अर्थ है कि d स्वयं 3 है। दूसरे शब्दों में, इस विशिष्ट उदाहरण के लिए दो मान 4 और 10 बनते हैं। लेकिन हमारा लक्ष्य एक त्वरित चाल है, और आप हर बार इसके बारे में सोचना नहीं चाहेंगे, तो आइए हमने जो किया उसे एक सामान्य सूत्र में समाप्त करें। किसी भी माध्य m और गुणनफल p के लिए, दूरी का वर्ग सदैव m वर्ग शून्य से p होगा। यह तीसरा मुख्य तथ्य देता है, जो यह है कि जब दो संख्याओं का माध्य m और गुणनफल p होता है, तो आप उन दो संख्याओं को m जोड़ या m वर्ग के वर्गमूल को घटा p के रूप में लिख सकते हैं। यदि आप कभी भी इसे भूल जाते हैं तो इसे तुरंत पुनः प्राप्त करना शालीनता से तेज़ है, और यह मूल रूप से वर्गों के अंतर के फार्मूले का एक पुनर्लेखन मात्र है। लेकिन फिर भी, यह एक तथ्य है जो याद रखने लायक है इसलिए यह आपकी उंगलियों पर है। वास्तव में, चैनल ए कैपेला साइंस से मेरे मित्र टिम ने इसे थोड़ा और यादगार बनाने के लिए हमें एक अच्छा त्वरित जिंगल लिखा। आइए मैं आपको दिखाता हूं कि यह कैसे काम करता है, मान लीजिए मैट्रिक्स 3, 1, 4, 1 के लिए। आप सूत्र को ध्यान में रखकर शुरुआत करें, हो सकता है कि यह सब अपने दिमाग में बता दें। लेकिन जब आप इसे लिखते हैं, तो आप आगे बढ़ते हुए एम और पी के लिए उचित मान भरते हैं। तो इस उदाहरण में, eigenvalues का माध्य 3 और 1 के माध्य के समान है, जो कि 2 है, इसलिए आप जो लिखना शुरू करते हैं वह 2 प्लस या माइनस 2 वर्ग का वर्गमूल है, फिर eigenvalues का उत्पाद निर्धारक है, जो इस उदाहरण में 3 गुना 1 माइनस 1 गुना 4, या नकारात्मक 1 है, इसलिए यह अंतिम चीज है जिसे आप भरते हैं, जिसका अर्थ है कि आइगेनवैल्यू 2 प्लस या माइनस 5 का वर्गमूल है। आप पहचान सकते हैं कि यह वही मैट्रिक्स है जिसका मैं शुरुआत में उपयोग कर रहा था, लेकिन ध्यान दें कि हम सीधे तौर पर कितना अधिक उत्तर प्राप्त कर सकते हैं। यहाँ, एक और प्रयास करें."
 },
 {
  "input": "Take this matrix here as an example.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Straight away you can know that the mean of 00:02:55,970 --> 00:03:02,420 39  is 40.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Now take a moment to see how you can derive 00:03:17,079 --> 00:03:21,860 43  let’s call that something \"d\" for distance.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "You also know that the product of these two 00:03:40,239 --> 00:03:45,480 47  specific example work out to be 4 and 10.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t 00:04:06,239 --> 00:04:12,610 51  you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly 00:04:34,490 --> 00:04:39,360 56  wrote us a quick jingle to make it a little more memorable.",
  "model": "nmt",
  "translatedText": "इस बार, eigenvalues का माध्य 2 और 8 के माध्य के समान है, जो कि 5 है। तो फिर, आप सूत्र लिखना शुरू करते हैं, लेकिन इस बार m के स्थान पर 5 लिखते हैं, और फिर सारणिक 2 गुना 8 घटा 7 गुना 1, या 9 होता है। तो इस उदाहरण में, आइजनवैल्यू 16 के वर्गमूल को 5 प्लस या माइनस जैसा दिखता है, जो 9 और 1 के रूप में और भी सरल हो जाता है। आप देख रहे हैं कि मेरा मतलब क्या है कि जब आप मैट्रिक्स को देख रहे हों तो आप मूल रूप से आइगेनवैल्यू को कैसे लिखना शुरू कर सकते हैं?"
 },
 {
  "input": "m plus or minus squaaaare root of me squared 00:04:53,880 --> 00:04:59,069 61  p as you go.",
  "model": "nmt",
  "translatedText": "यह आम तौर पर अंत में सरलीकरण का सबसे छोटा सा हिस्सा है। ईमानदारी से कहूं तो, जब मैं रैखिक बीजगणित से संबंधित त्वरित नोट्स बना रहा होता हूं और उदाहरण के रूप में छोटे मैट्रिक्स का उपयोग करना चाहता हूं तो मैंने खुद को इस ट्रिक का भरपूर उपयोग करते हुए पाया है। मैं मैट्रिक्स प्रतिपादकों के बारे में एक वीडियो पर काम कर रहा हूं, जहां आइगेनवैल्यू बहुत अधिक आते हैं, और मुझे एहसास हुआ कि यह बहुत आसान है अगर छात्र किसी अलग विचार में फंसकर विचार की मुख्य पंक्ति को खोए बिना छोटे उदाहरणों से आइगेनवैल्यू पढ़ सकते हैं। गणना। एक और मज़ेदार उदाहरण के रूप में, तीन अलग-अलग मैट्रिक्स के इस सेट पर एक नज़र डालें, जो क्वांटम यांत्रिकी में बहुत अधिक आता है। उन्हें पाउली स्पिन मैट्रिसेस के रूप में जाना जाता है। यदि आप क्वांटम यांत्रिकी को जानते हैं, तो आप जानेंगे कि आव्यूहों के स्वदेशी मान उनके द्वारा वर्णित भौतिकी के लिए अत्यधिक प्रासंगिक हैं। और यदि आप क्वांटम यांत्रिकी नहीं जानते हैं, तो आइए एक छोटी सी झलक देखें कि ये संगणनाएँ वास्तव में वास्तविक अनुप्रयोगों के लिए कितनी प्रासंगिक हैं। तीनों मामलों में विकर्ण प्रविष्टियों का माध्य शून्य है। तो इन सभी मामलों में eigenvalues का माध्य शून्य है, जो हमारे सूत्र को विशेष रूप से सरल बनाता है। इन आव्यूहों के निर्धारक, eigenvalues के उत्पादों के बारे में क्या?"
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean 00:05:19,030 --> 00:05:26,780 65  might recognize that this is the same matrix I was using at the beginning, but notice how 00:05:47,370 --> 00:05:52,190 69  is 2*8 - 7*1, or 9.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which 00:06:19,590 --> 00:06:23,800 73  a lot when I’m sketching quick notes related to linear algebra and want to use small matrices 00:06:37,039 --> 00:06:41,800 77  a different calculation.",
  "model": "nmt",
  "translatedText": "पहले वाले के लिए, यह 0 शून्य से 1, या नकारात्मक 1 है। दूसरा भी 0 घटा 1 जैसा दिखता है, लेकिन जटिल संख्याओं के कारण इसे देखने में एक क्षण अधिक लगता है। और अंतिम नकारात्मक 1 घटा 0 जैसा दिखता है। इसलिए सभी मामलों में, eigenvalues प्लस और माइनस 1 को सरल बनाते हैं। हालाँकि इस मामले में, आपको वास्तव में दो मान खोजने के लिए किसी सूत्र की आवश्यकता नहीं है यदि आप जानते हैं कि वे 0 के आसपास समान दूरी पर हैं और उनका उत्पाद नकारात्मक 1 है। यदि आप उत्सुक हैं, तो क्वांटम यांत्रिकी के संदर्भ में, ये मैट्रिक्स उन टिप्पणियों का वर्णन करते हैं जो आप x, y, या z दिशा में एक कण के घूमने के बारे में कर सकते हैं। और तथ्य यह है कि उनके eigenvalues प्लस और माइनस 1 हैं, इस विचार से मेल खाते हैं कि स्पिन के लिए मान जो आप देखेंगे वह या तो पूरी तरह से एक दिशा में या पूरी तरह से दूसरे में होगा, बीच में लगातार कुछ के विपरीत। शायद आपको आश्चर्य होगा कि यह वास्तव में कैसे काम करता है, या आप 2x2 मैट्रिक्स का उपयोग क्यों करेंगे जिनमें तीन आयामों में स्पिन का वर्णन करने के लिए जटिल संख्याएं हैं। और ये उचित प्रश्न होंगे, मैं यहां जिस बारे में बात करना चाहता हूं उसके दायरे से बिल्कुल बाहर। आप जानते हैं, यह मज़ेदार है, मैंने यह खंड इसलिए लिखा क्योंकि मैं कुछ ऐसा मामला चाहता था जहां आपके पास 2x2 मैट्रिक्स हों जो केवल खिलौनों के उदाहरण या होमवर्क की समस्याएं नहीं हैं, जहां वे वास्तव में अभ्यास में आते हैं, और क्वांटम यांत्रिकी इसके लिए बहुत अच्छा है। लेकिन बात यह है कि, इसे बनाने के बाद, मुझे एहसास हुआ कि पूरा उदाहरण उस बिंदु को कम कर देता है जो मैं कहने की कोशिश कर रहा हूं। इन विशिष्ट मैट्रिक्स के लिए, जब आप पारंपरिक विधि का उपयोग करते हैं, विशेषता बहुपद वाली, तो यह अनिवार्य रूप से उतनी ही तेज़ होती है। यह वास्तव में तेज़ हो सकता है."
 },
 {
  "input": "As another fun example, take a look at this 00:06:54,190 --> 00:06:59,419 81  mechanics, let this just be a little glimpse of how these computations are actually relevant 00:07:12,639 --> 00:07:19,990 85  the determinants of these matrices?",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "The second 00:07:36,430 --> 00:07:42,310 89  know theyr'e evenly spaced around 0 and their product is -1.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "If you’re curious, in the context of quantum 00:07:59,759 --> 00:08:04,470 94  or entirely in another, as opposed to something continuously ranging in between.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Maybe you’d 00:08:20,680 --> 00:08:26,259 98  because I wanted some case where you have 2x2 matrices that are not just toy examples 00:08:38,970 --> 00:08:43,880 102  use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; 00:08:58,700 --> 00:09:03,390 106  for the last matrix, forget about doing any computations, traditional or otherwise, it’s 00:09:20,940 --> 00:09:23,510 00:09:23,510 --> 00:09:28,850 111   one, plus b times the second, plus c times the third.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "In quantum mechanics, this would 00:09:47,360 --> 00:09:53,240 116  still zero, and you might also enjoy pausing for a brief moment to confirm that the product 00:10:13,560 --> 00:10:18,710 120   is not fundamentally different from finding roots of the characteristic polynomial; I 00:10:33,110 --> 00:10:37,160 125  the roots of a quadratic given its coefficients, that's another situation where you know the 00:10:50,950 --> 00:10:54,820 129  linear coefficient, which is -1 times the sum of those roots.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "For the example on the 00:11:12,820 --> 00:11:17,610 133  a lighter-weight version of the traditional quadratic formula.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "But the real advantage 00:11:34,200 --> 00:11:37,370 137  you don't need to go through the intermediate step of setting up the characteristic polynomial.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "00:11:49,930 --> 00:11:54,339 141  for a very specific audience, but it’s something I wish I knew in college, so if you happen 00:12:08,240 --> 00:12:10,330 00:12:10,330 --> 00:12:15,140 146  take a moment to expand out the characteristic polynomial for a general matrix, and think 00:12:32,449 --> 00:12:36,420 150  in particular, is one of the greatest things on the internet.",
  "model": "nmt",
  "translatedText": ""
 }
]