[
 {
  "input": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, and who might enjoy a quick way to compute them in the case of 2x2 matrices. ",
  "translatedText": "Este es un vídeo para cualquiera que ya sepa qué son los valores propios y los vectores propios, y que pueda disfrutar de una forma rápida de calcularlos en el caso de matrices de 2x2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 7.56
 },
 {
  "input": "If you’re unfamiliar with eigenvalues, take a look at this video which introduces them. ",
  "translatedText": "Si no está familiarizado con los valores propios, continúe y mire este video aquí, que en realidad está destinado a presentarlos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 8.58,
  "end": 13.7
 },
 {
  "input": "You can skip ahead if you just want to see the trick, but if possible I’d like you to rediscover it for yourself, so for that let’s lay down a little background. ",
  "translatedText": "Puedes saltar adelante si todo lo que quieres hacer es ver el truco, pero si es posible, me gustaría que lo redescubras por ti mismo. Entonces, para eso, expongamos un poco de contexto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.68,
  "end": 22.38
 },
 {
  "input": "As a quick reminder, if the effect of a linear transformation on a given vector is to scale it by some constant, we call it an \"eigenvector\" of the transformation, and we call the relevant scaling factor the corresponding \"eigenvalue,\" often denoted with the letter lambda. ",
  "translatedText": "Como recordatorio rápido, si el efecto de una transformación lineal en un vector dado es escalar ese vector mediante alguna constante, lo llamamos vector propio de la transformación, y llamamos al factor de escala relevante el valor propio correspondiente, a menudo denotado con la letra lambda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.26,
  "end": 38.6
 },
 {
  "input": "When you write this as an equation and you rearrange a little bit, what you see is that if the number lambda is an eigenvalue of a matrix A, then the matrix (A minus lambda times the identity) must send some nonzero vector, namely the corresponding eigenvector, to the zero vector, which in turn means the determinant of this modified matrix must be 0. ",
  "translatedText": "Cuando escribes esto como una ecuación y lo reorganizas un poco, lo que ves es que si el número lambda es un valor propio de una matriz A, entonces la matriz A menos lambda multiplicada por la identidad debe enviar algún vector distinto de cero, es decir el vector propio correspondiente, al vector cero, lo que a su vez significa que el determinante de esta matriz modificada debe ser cero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.84,
  "end": 64.58
 },
 {
  "input": "Okay, that’s all a little bit of a mouthful to say, but again, I’m assuming all of this is review for anyone watching. ",
  "translatedText": "Bien, eso es un poco complicado de decir, pero nuevamente, supongo que todo esto es una revisión para cualquiera de los que estén mirando. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 66.12,
  "end": 71.54
 },
 {
  "input": "So, the usual way to compute eigenvalues, how I used to do it, and how I believe most students are taught to carry it out, is to subtract the unknown value lambda off the diagonals and then solve for when the determinant equals 0. ",
  "translatedText": "Entonces, la forma habitual de calcular valores propios, cómo solía hacerlo y cómo creo que a la mayoría de los estudiantes se les enseña a hacerlo, es restar el valor desconocido lambda de las diagonales y luego resolver cuándo el determinante es igual a cero. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.82,
  "end": 85.86
 },
 {
  "input": "Doing this always involves a few steps to expand out and simplify to get a clean quadratic polynomial, what's known as the “characteristic polynomial” of the matrix. ",
  "translatedText": "Hacer esto siempre implica algunos pasos para expandir y simplificar para obtener un polinomio cuadrático limpio, lo que se conoce como el &quot;polinomio característico&quot; de la matriz. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.76,
  "end": 96.46
 },
 {
  "input": "The eigenvalues are the roots of this polynomial. ",
  "translatedText": "Los valores propios son las raíces de este polinomio. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.36,
  "end": 99.9
 },
 {
  "input": "So to find them you have to apply the quadratic formula, which itself typically requires one or two more steps of simplification. ",
  "translatedText": "Entonces, para encontrarlos hay que aplicar la fórmula cuadrática, que normalmente requiere uno o dos pasos más de simplificación. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 100.1,
  "end": 106.54
 },
 {
  "input": "Honestly, the process isn’t terrible. ",
  "translatedText": "Honestamente, el proceso no es terrible. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.76,
  "end": 109.5
 },
 {
  "input": "But at least for 2x2 matrices, there’s a much more direct way to get at this answer. ",
  "translatedText": "Pero al menos para matrices de 2x2, hay una forma mucho más directa de llegar a esta respuesta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 109.58,
  "end": 114.68
 },
 {
  "input": "And if you want to rediscover this trick, there are only three relevant facts you need to know, each of which is worth knowing in its own right and can help you with other problem-solving. ",
  "translatedText": "Y si desea redescubrir este truco, solo hay tres hechos relevantes que necesita saber, cada uno de los cuales vale la pena conocer por derecho propio y puede ayudarlo a resolver otros problemas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.4,
  "end": 122.9
 },
 {
  "input": "Number 1: The trace of a matrix, which is the sum of these two diagonal entries, is equal to the sum of the eigenvalues. ",
  "translatedText": "Número uno, la traza de una matriz, que es la suma de estas dos entradas diagonales, es igual a la suma de los valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 123.82,
  "end": 130.92
 },
 {
  "input": "Or another way to phrase it, more useful for our purposes, is that the mean of the two eigenvalues is the same as the mean of these two diagonal entries. ",
  "translatedText": "U otra forma de expresarlo, más útil para nuestros propósitos, es que la media de los dos valores propios es la misma que la media de estas dos entradas diagonales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.7,
  "end": 139.46
 },
 {
  "input": "Number 2: The determinant of a matrix, our usual ad-bc formula, is equal to the product of the two eigenvalues. ",
  "translatedText": "Número dos, el determinante de una matriz, nuestra fórmula ad-bc habitual, es igual al producto de los dos valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.0,
  "end": 148.96
 },
 {
  "input": "And this should kind of make sense if you understand that eigenvalues describe how much an operator stretches space in a particular direction and that the determinant describes how much an operator scales areas (or volumes) as a whole. ",
  "translatedText": "Y esto debería tener sentido si se entiende que los valores propios describen cuánto un operador estira el espacio en una dirección particular, y que el determinante describe cuánto un operador escala áreas o volúmenes en su conjunto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.06,
  "end": 161.76
 },
 {
  "input": "Now before getting to the third fact, notice how you can essentially read these first two values out of the matrix without really writing much down. ",
  "translatedText": "Ahora, antes de llegar al tercer hecho, observe cómo básicamente puede leer estos dos primeros valores de la matriz sin escribir mucho. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 162.8,
  "end": 169.16
 },
 {
  "input": "Take this matrix here as an example. ",
  "translatedText": "Tome esta matriz aquí como ejemplo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.76,
  "end": 171.32
 },
 {
  "input": "Straight away you can know that the mean of the eigenvalues is the same as the mean of 8 and 6, which is 7. ",
  "translatedText": "De inmediato, puedes saber que la media de los valores propios es la misma que la media de 8 y 6, que es 7. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.82,
  "end": 177.82
 },
 {
  "input": "Likewise, most linear algebra students are pretty well-practiced at finding the determinant, which in this case works out to be 48 - 8 So right away you know that the product of our two eigenvalues is 40. ",
  "translatedText": "Del mismo modo, la mayoría de los estudiantes de álgebra lineal tienen bastante práctica en encontrar el determinante, que en este caso resulta ser 48 menos 8. De inmediato sabes que el producto de los dos valores propios es 40. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.58,
  "end": 191.7
 },
 {
  "input": "Now take a moment to see how you can derive what will be our third relevant fact, which is how to recover two numbers when you know their mean and you know their product. ",
  "translatedText": "Ahora tómate un momento para ver si puedes derivar cuál será nuestro tercer hecho relevante, que es cómo puedes recuperar rápidamente dos números cuando conoces su media y conoces su producto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 192.78,
  "end": 201.56
 },
 {
  "input": "Here, let's focus on this example. ",
  "translatedText": "Aquí, centrémonos en este ejemplo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.46,
  "end": 203.72
 },
 {
  "input": "You know the two values are evenly spaced around 7, so they look like 7 plus or minus something; let’s call that something \"d\" for distance. ",
  "translatedText": "Sabes que los dos valores están espaciados uniformemente alrededor del número 7, por lo que parecen 7 más o menos algo, llamémoslo d para la distancia. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.2,
  "end": 212.78
 },
 {
  "input": "You also know that the product of these two numbers is 40. ",
  "translatedText": "También sabes que el producto de estos dos números es 40. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.56,
  "end": 216.38
 },
 {
  "input": "Now to find d, notice that this product expands really nicely, it works out as a difference of squares. ",
  "translatedText": "Ahora, para encontrar d, observa que este producto se expande muy bien, resulta como una diferencia de cuadrados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.6,
  "end": 223.7
 },
 {
  "input": "So from there, you can directly find d: d^2 is 7^2 - 40, or 9, which means d itself is 3. ",
  "translatedText": "Entonces, desde allí, puedes encontrar directamente d. d al cuadrado es 7 al cuadrado menos 40, o 9, lo que significa que d en sí es 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.56,
  "end": 233.4
 },
 {
  "input": "In other words, the two values for this very specific example work out to be 4 and 10. ",
  "translatedText": "En otras palabras, los dos valores para este ejemplo muy específico resultan ser 4 y 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.38,
  "end": 241.1
 },
 {
  "input": "But our goal is a quick trick, and you wouldn’t want to think this through each time, so let’s wrap up what we just did in a general formula. ",
  "translatedText": "Pero nuestro objetivo es un truco rápido y no querrás pensar en esto cada vez, así que resumamos lo que acabamos de hacer en una fórmula general. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 241.68,
  "end": 248.12
 },
 {
  "input": "For any mean, m and product, p, the distance squared is always going to be m^2 - p. ",
  "translatedText": "Para cualquier media m y producto p, la distancia al cuadrado siempre será m al cuadrado menos p. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.64,
  "end": 255.68
 },
 {
  "input": "This gives the third key fact, which is that when two numbers have a mean m and a product p, you can write those two numbers as m ± sqrt(m^2 - p) This is decently fast to rederive on the fly if you ever forget it, and it’s essentially just a rephrasing of the difference of squares formula. ",
  "translatedText": "Esto nos da el tercer hecho clave, que es que cuando dos números tienen una media m y un producto p, puedes escribir esos dos números como m más o menos la raíz cuadrada de m al cuadrado menos p. Esto es bastante rápido para volver a derivar sobre la marcha si alguna vez lo olvidas, y es esencialmente solo una reformulación de la fórmula de diferencia de cuadrados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.56,
  "end": 277.08
 },
 {
  "input": "But even still it’s a fact worth memorizing so that you have it at the tip of your fingers. ",
  "translatedText": "Pero aún así, es un hecho que vale la pena memorizar y que está al alcance de tu mano. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.86,
  "end": 281.22
 },
 {
  "input": "In fact, my friend Tim from the channel acapellascience wrote us a quick jingle to make it a little more memorable. ",
  "translatedText": "De hecho, mi amigo Tim del canal A Capella Science nos escribió un lindo jingle rápido para hacerlo un poco más memorable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.22,
  "end": 287.16
 },
 {
  "input": "m plus or minus squaaaare root of me squared minus p (ping!) Let me show you how this works, say for the matrix [[3,1], [4,1]]. ",
  "translatedText": "Déjame mostrarte cómo funciona esto, digamos para la matriz 3, 1, 4, 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.9,
  "end": 297.62
 },
 {
  "input": "You start by bringing to mind the formula, maybe stating it all in your head. ",
  "translatedText": "Empiece por recordar la fórmula, tal vez expresándolo todo en su cabeza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.1,
  "end": 301.82
 },
 {
  "input": "But when you write it down, you fill in the appropriate values of m and p as you go. ",
  "translatedText": "Pero cuando lo escribes, completas los valores apropiados de myp a medida que avanzas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.2,
  "end": 311.62
 },
 {
  "input": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, which is 2. ",
  "translatedText": "Entonces, en este ejemplo, la media de los valores propios es la misma que la media de 3 y 1, que es 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 312.34,
  "end": 317.74
 },
 {
  "input": "So the thing you start writing is 2 ± sqrt(2^2 - …). ",
  "translatedText": "Entonces, lo que empiezas a escribir es 2 ± sqrt(2^2 -…). ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.3,
  "end": 322.7
 },
 {
  "input": "Then the product of the eigenvalues is the determinant, which in this example is 3*1 - 1*4, or -1. ",
  "translatedText": "Entonces el producto de los valores propios es el determinante, que en este ejemplo es 3*1 - 1*4, o -1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.54,
  "end": 332.14
 },
 {
  "input": "So that’s the final thing you fill in. ",
  "translatedText": "Entonces eso es lo último que debes completar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.38,
  "end": 334.48
 },
 {
  "input": "This means the eigenvalues are 2±sqrt(5). ",
  "translatedText": "Esto significa que los valores propios son 2±sqrt(5). ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.88,
  "end": 338.76
 },
 {
  "input": "You might recognize that this is the same matrix I was using at the beginning, but notice how much more directly we can get at the answer. ",
  "translatedText": "Quizás reconozcas que esta es la misma matriz que estaba usando al principio, pero observa cuánto más directamente podemos llegar a la respuesta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.3,
  "end": 346.5
 },
 {
  "input": "Here, try another one. ",
  "translatedText": "Toma, prueba con otro. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.14,
  "end": 349.18
 },
 {
  "input": "This time the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5. ",
  "translatedText": "Esta vez, la media de los valores propios es la misma que la media de 2 y 8, que es 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.44,
  "end": 354.48
 },
 {
  "input": "So again, you start writing out the formula but this time writing 5 in place of m [song]. ",
  "translatedText": "Entonces, nuevamente, comienzas a escribir la fórmula, pero esta vez escribes 5 en lugar de m [canción]. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.1,
  "end": 359.22
 },
 {
  "input": "And then the determinant is 2*8 - 7*1, or 9. ",
  "translatedText": "Y luego el determinante es 2*8 - 7*1, o 9. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.98,
  "end": 368.3
 },
 {
  "input": "So in this example, the eigenvalues look like 5 ± sqrt(16), which simplifies even further as 9 and 1. ",
  "translatedText": "Entonces, en este ejemplo, los valores propios se ven como 5 ± sqrt(16), lo que se simplifica aún más como 9 y 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 369.52,
  "end": 378.24
 },
 {
  "input": "You see what I mean about how you can basically just start writing down the eigenvalues while staring at the matrix? ",
  "translatedText": "¿Ves lo que quiero decir acerca de cómo básicamente puedes comenzar a escribir los valores propios mientras miras la matriz? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.42,
  "end": 384.62
 },
 {
  "input": "It’s typically just the tiniest bit of simplifying at the end. ",
  "translatedText": "Por lo general, al final es sólo una mínima simplificación. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.28,
  "end": 388.16
 },
 {
  "input": "Honestly, I’ve found myself using this trick a lot when I’m sketching quick notes related to linear algebra and want to use small matrices as examples. ",
  "translatedText": "Honestamente, me he encontrado usando mucho este truco cuando estoy dibujando notas rápidas relacionadas con el álgebra lineal y quiero usar matrices pequeñas como ejemplos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.06,
  "end": 395.72
 },
 {
  "input": "I’ve been working on a video about matrix exponents, where eigenvalues pop up a lot, and I realized it’s just very handy if students can read off the eigenvalues from small examples without losing the main line of thought by getting bogged down in a different calculation. ",
  "translatedText": "He estado trabajando en un vídeo sobre exponentes matriciales, donde los valores propios aparecen con frecuencia, y me doy cuenta de que es muy útil si los estudiantes pueden leer los valores propios de ejemplos pequeños sin perder la línea principal de pensamiento al atascarse en un tema diferente. cálculo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.18,
  "end": 408.62
 },
 {
  "input": "As another fun example, take a look at this set of three different matrices, which come up a lot in quantum mechanics, they're known as the Pauli spin matrices. ",
  "translatedText": "Como otro ejemplo divertido, eche un vistazo a este conjunto de tres matrices diferentes, que aparece mucho en la mecánica cuántica. Se conocen como matrices de espín de Pauli. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.74,
  "end": 417.52
 },
 {
  "input": "If you know quantum mechanics, you’ll know that the eigenvalues of matrices are highly relevant to the physics they describe, and if you don’t know quantum mechanics, let this just be a little glimpse of how these computations are actually relevant to real applications. ",
  "translatedText": "Si conoces la mecánica cuántica, sabrás que los valores propios de las matrices son muy relevantes para la física que describen. Y si no conoce la mecánica cuántica, esto le permitirá echar un vistazo a cómo estos cálculos son realmente muy relevantes para aplicaciones reales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.6,
  "end": 431.22
 },
 {
  "input": "The mean of the diagonal in all three cases is 0, so the mean of the eigenvalues in all cases is 0, which makes our formula look especially simple. ",
  "translatedText": "La media de las entradas diagonales en los tres casos es cero. Entonces, la media de los valores propios en todos estos casos es cero, lo que hace que nuestra fórmula parezca especialmente simple. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.54,
  "end": 443.06
 },
 {
  "input": "What about the products of the eigenvalues, the determinants of these matrices? ",
  "translatedText": "¿Qué pasa con los productos de los valores propios, los determinantes de estas matrices? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.38,
  "end": 448.8
 },
 {
  "input": "For the first one, it’s 0 - 1 or -1. ",
  "translatedText": "Para el primero, es 0 menos 1 o 1 negativo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.7,
  "end": 453.4
 },
 {
  "input": "The second also looks like 0 - 1, but it takes a moment more to see because of the complex numbers. ",
  "translatedText": "El segundo también parece 0 menos 1, pero lleva un momento más verlo debido a los números complejos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.4,
  "end": 458.2
 },
 {
  "input": "And the final one looks like -1 - 0. ",
  "translatedText": "Y el final parece menos 1 menos 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.84,
  "end": 461.36
 },
 {
  "input": "So in all cases, the eigenvalues simplify to be ±1. ",
  "translatedText": "Entonces, en todos los casos, los valores propios se simplifican para ser más y menos 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.06,
  "end": 465.92
 },
 {
  "input": "Although in this case, you really don’t need the formula to find two values if you know theyr'e evenly spaced around 0 and their product is -1. ",
  "translatedText": "Aunque en este caso, realmente no necesitas una fórmula para encontrar dos valores si sabes que están espaciados uniformemente alrededor de 0 y su producto es negativo 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.72,
  "end": 473.28
 },
 {
  "input": "If you’re curious, in the context of quantum mechanics, these matrices describe observations you might make about a particle's spin in the x, y or z directions. ",
  "translatedText": "Si tiene curiosidad, en el contexto de la mecánica cuántica, estas matrices describen observaciones que podría hacer sobre el giro de una partícula en la dirección x, y o z. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.64,
  "end": 483.76
 },
 {
  "input": "The fact that their eigenvalues are ±1 corresponds with the idea that the values for the spin that you would observe would be either entirely in one direction or entirely in another, as opposed to something continuously ranging in between. ",
  "translatedText": "Y el hecho de que sus valores propios sean más y menos 1 corresponde con la idea de que los valores del giro que se observarían estarían completamente en una dirección o completamente en otra, en contraposición a algo que varía continuamente en el medio. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.76,
  "end": 497.02
 },
 {
  "input": "Maybe you’d wonder how exactly this works, or why you would use 2x2 matrices that have complex numbers to describe spin in three dimensions. ",
  "translatedText": "Tal vez te preguntes cómo funciona esto exactamente, o por qué usarías matrices de 2x2 que tienen números complejos para describir el giro en tres dimensiones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.32,
  "end": 505.52
 },
 {
  "input": "And those would be fair questions, just outside the scope of what I want to talk about here. ",
  "translatedText": "Y esas serían preguntas justas, que están fuera del alcance de lo que quiero hablar aquí. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.1,
  "end": 509.76
 },
 {
  "input": "You know it’s funny, I wrote this section because I wanted some case where you have 2x2 matrices that are not just toy examples or homework problems, ones where they actually come up in practice, and quantum mechanics is great for that. ",
  "translatedText": "Sabes, es gracioso, escribí esta sección porque quería algún caso en el que tengas matrices de 2x2 que no sean solo ejemplos de juguete o problemas de tarea, sino que realmente surjan en la práctica, y la mecánica cuántica es excelente para eso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.48,
  "end": 521.7
 },
 {
  "input": "But the thing is after I made it I realized that the whole example kind of undercuts the point I’m trying to make. ",
  "translatedText": "Pero la cuestión es que, después de hacerlo, me di cuenta de que todo el ejemplo socava el punto que estoy tratando de exponer. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.7,
  "end": 528.24
 },
 {
  "input": "For these specific matrices, when you use the traditional method, the one with characteristic polynomials, it’s essentially just as fast; it might actually faster. ",
  "translatedText": "Para estas matrices específicas, cuando se utiliza el método tradicional, el que tiene polinomios característicos, es esencialmente igual de rápido. De hecho, podría ser más rápido. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.74,
  "end": 537.64
 },
 {
  "input": "I mean, take a look a the first one: The relevant determinant directly gives you a characteristic polynomial of lambda^2 - 1, and clearly, that has roots of plus and minus 1. ",
  "translatedText": "Quiero decir, eche un vistazo al primero. El determinante relevante te da directamente un polinomio característico de lambda al cuadrado menos uno, y claramente tiene raíces de más y menos uno. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.24,
  "end": 548.2
 },
 {
  "input": "Same answer when you do the second matrix, lambda^2 - 1. ",
  "translatedText": "La misma respuesta cuando haces la segunda matriz, lambda al cuadrado menos uno. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.84,
  "end": 551.76
 },
 {
  "input": "And as for the last matrix, forget about doing any computations, traditional or otherwise, it’s already a diagonal matrix, so those diagonal entries are the eigenvalues! ",
  "translatedText": "Y en cuanto a la última matriz, olvídese de hacer cálculos, tradicionales o no, ya es una matriz diagonal, por lo que esas entradas diagonales son los valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.88,
  "end": 562.74
 },
 {
  "input": "However, the example is not totally lost to our cause. ",
  "translatedText": "Sin embargo, el ejemplo no está totalmente perdido para nuestra causa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 564.3,
  "end": 566.92
 },
 {
  "input": "Where you will actually feel the speed up is in the more general case where you take a linear combination of these three matrices and then try to compute the eigenvalues. ",
  "translatedText": "Donde realmente sentirás la aceleración es en el caso más general, donde tomas una combinación lineal de estas tres matrices y luego intentas calcular los valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 567.38,
  "end": 576.06
 },
 {
  "input": "You might write this as a times the first one, plus b times the second, plus c times the third. ",
  "translatedText": "Podrías escribir esto como a multiplicado por el primero, más b multiplicado por el segundo, más c multiplicado por el tercero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.82,
  "end": 582.42
 },
 {
  "input": "In quantum mechanics, this would describe spin observations in a general direction of a vector with coordinates [a, b, c]. ",
  "translatedText": "En mecánica cuántica, esto describiría observaciones de espín en una dirección general de un vector con coordenadas a, b, c. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 583.02,
  "end": 589.28
 },
 {
  "input": "More specifically, you should assume this vector is normalized, meaning a^2 + b^2 + c^2 = 1. ",
  "translatedText": "Más específicamente, debes asumir que este vector está normalizado, lo que significa que a al cuadrado más b al cuadrado más c al cuadrado es igual a uno. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 597.7
 },
 {
  "input": "When you look at this new matrix, it’s immediate to see that the mean of the eigenvalues is still zero, and you might also enjoy pausing for a brief moment to confirm that the product of those eigenvalues is still -1, and then from there concluding what the eigenvalues must be. ",
  "translatedText": "Cuando observa esta nueva matriz, es inmediato ver que la media de los valores propios sigue siendo cero, y también puede disfrutar haciendo una breve pausa para confirmar que el producto de esos valores propios sigue siendo uno negativo. Y luego a partir de ahí, concluir cuáles deben ser los valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.6,
  "end": 615.92
 },
 {
  "input": "And this time, the characteristic polynomial approach would be by comparison a lot more cumbersome, definitely harder to do in your head. ",
  "translatedText": "Y esta vez, el enfoque polinomial característico sería, en comparación, mucho más engorroso, definitivamente más difícil de hacer en tu cabeza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.22,
  "end": 623.58
 },
 {
  "input": "To be clear, using the mean-product formula is not fundamentally different from finding roots of the characteristic polynomial; I mean, it can't be, they're solving the same problem. ",
  "translatedText": "Para ser claros, usar la fórmula del producto medio no es diferente de encontrar raíces del polinomio característico. O sea, no puede ser, están solucionando el mismo problema. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.08,
  "end": 633.44
 },
 {
  "input": "One way to think about this, actually, is that the mean-product formula is a nice way to solve quadratic in general (and some viewers of the channel may recognize this). ",
  "translatedText": "En realidad, una forma de pensar en esto es que la fórmula del producto medio es una buena manera de resolver cuadráticas en general, y algunos espectadores del canal pueden reconocerlo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.16,
  "end": 641.66
 },
 {
  "input": "This about it: When you’re trying to find the roots of a quadratic given its coefficients, that's another situation where you know the sum of two values, and you also know their product, but you’re trying to recover the original two values. ",
  "translatedText": "Piénsalo. Cuando intentas encontrar las raíces de una cuadrática, dados los coeficientes, esa es otra situación en la que conoces la suma de dos valores y también conoces su producto, pero estás tratando de recuperar los dos valores originales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.54,
  "end": 654.1
 },
 {
  "input": "Specifically, if the polynomial is normalized so that this leading coefficient is 1, then the mean of the roots will be -½ times this linear coefficient, which is -1 times the sum of those roots. ",
  "translatedText": "Específicamente, si el polinomio se normaliza para que este coeficiente principal sea uno, entonces la media de las raíces será negativa la mitad de este coeficiente lineal, que es negativa una vez la suma de esas raíces. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 655.56,
  "end": 666.88
 },
 {
  "input": "For the example on the screen that makes the mean 5. ",
  "translatedText": "Para el ejemplo en la pantalla, eso hace que la media sea cinco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.02,
  "end": 670.18
 },
 {
  "input": "And the product of the roots is even easier, it’s just the constant term no adjustments needed. ",
  "translatedText": "Y el producto de las raíces es aún más fácil, es sólo el término constante, no se necesitan ajustes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.98,
  "end": 676.52
 },
 {
  "input": "So from there, you would apply the mean product formula and that gives you the roots. ",
  "translatedText": "Entonces, a partir de ahí, aplicarías la fórmula del producto medio, y eso te dará las raíces. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.34,
  "end": 680.9
 },
 {
  "input": "On the one hand, you could think of this as a lighter-weight version of the traditional quadratic formula. ",
  "translatedText": "Y, por un lado, se podría considerar esto como una versión más ligera de la fórmula cuadrática tradicional. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.14,
  "end": 690.22
 },
 {
  "input": "But the real advantage is that it's fewer symbols to memorize, it's that each one of them carries more meaning with it. ",
  "translatedText": "Pero la verdadera ventaja no es sólo que hay menos símbolos que memorizar, sino que cada uno de ellos tiene más significado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 690.96,
  "end": 696.44
 },
 {
  "input": "The whole point of this eigenvalue trick is that because you can read out the mean and product directly from looking at the matrix, you don't need to go through the intermediate step of setting up the characteristic polynomial. ",
  "translatedText": "Quiero decir, el objetivo de este truco de valores propios es que, como puedes leer la media y el producto directamente mirando la matriz, no necesitas pasar por el paso intermedio de configurar el polinomio característico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 696.94,
  "end": 708.0
 },
 {
  "input": "You can jump straight to writing down the roots without ever explicitly thinking about what the polynomial looks like. ",
  "translatedText": "Puedes pasar directamente a escribir las raíces sin pensar explícitamente en cómo se ve el polinomio. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.42,
  "end": 713.64
 },
 {
  "input": "But to do that we need a version of the quadratic formula where the terms carry some kind of meaning. ",
  "translatedText": "Pero para hacer eso, necesitamos una versión de la fórmula cuadrática donde los términos tengan algún tipo de significado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.84,
  "end": 718.82
 },
 {
  "input": "I realize that this is a very specific trick, for a very specific audience, but it’s something I wish I knew in college, so if you happen to know any students who might benefit from this, consider sharing it with them. ",
  "translatedText": "Me doy cuenta de que este es un truco muy específico para una audiencia muy específica, pero es algo que desearía saber en la universidad, así que si conoces a algún estudiante que pueda beneficiarse de esto, considera compartirlo con ellos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 729.7
 },
 {
  "input": "The hope is that it’s not just one more thing to memorize, but that the framing reinforces some other nice facts worth knowing, like how the trace and determinant relate to eigenvalues. ",
  "translatedText": "La esperanza es que no sea solo una cosa más que memorizas, sino que el encuadre refuerce algunos otros hechos interesantes que vale la pena conocer, como cómo la traza y el determinante se relacionan con los valores propios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.28,
  "end": 739.82
 },
 {
  "input": "If you want to prove those facts, by the way, take a moment to expand out the characteristic polynomial for a general matrix, and think hard about the meaning of each of these coefficients. ",
  "translatedText": "Por cierto, si quieres probar esos hechos, tómate un momento para expandir el polinomio característico de una matriz general y luego piensa detenidamente en el significado de cada uno de estos coeficientes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.56,
  "end": 749.62
 },
 {
  "input": "Many thanks to Tim, for ensuring that this mean-product formula will stay stuck in all of our heads for at least a few months. ",
  "translatedText": "Muchas gracias a Tim por garantizar que la fórmula de este producto permanezca atrapada en nuestras cabezas durante al menos unos meses. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 752.4,
  "end": 757.94
 },
 {
  "input": "If you don’t know about acapellascience, please do check it out. ",
  "translatedText": "Si no conoce la ciencia de la alcappella, compruébela. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 761.7,
  "end": 766.0
 },
 {
  "input": "\"The Molecular Shape of You\", in particular, is one of the greatest things on the internet. ",
  "translatedText": "Tu forma molecular en particular es una de las mejores cosas de Internet. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.28,
  "end": 769.58
 }
]