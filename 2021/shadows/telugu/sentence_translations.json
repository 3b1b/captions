[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "translatedText": "ఒక క్షణంలో నేను ఒక క్యూబ్ యొక్క నీడతో కూడిన ఒక నిర్దిష్టమైన మంచి పజిల్ గురించి మీకు చెప్పబోతున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "translatedText": "కానీ మనం దానిని పొందే ముందు, ఈ వీడియో యొక్క పాయింట్ ఖచ్చితంగా పజిల్ పర్ సే కాదని నేను చెప్పాలి, ఇది రెండు విభిన్నమైన సమస్య-పరిష్కార శైలుల గురించి, ఈ సమస్యను మనం పరిష్కరించగల రెండు రకాలుగా ప్రతిబింబిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "translatedText": "వాస్తవానికి, ఆలిస్ మరియు బాబ్ అనే ఇద్దరు విద్యార్థులను ఊహించడం ద్వారా ఆ రెండు విభిన్న శైలులను ఆంత్రోపోమోర్ఫిజ్ చేద్దాం, అవి ఒక్కొక్కటి విధానాలను కలిగి ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "translatedText": "కాబట్టి బాబ్ నిజంగా గణనను ఇష్టపడే విద్యార్థిగా ఉంటాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "translatedText": "అతను వివరాలను త్రవ్వి, అతని ముందు ఉన్న కాంక్రీట్ పరిస్థితిని చాలా ఖచ్చితమైన వీక్షణను పొందగలిగే క్షణం వచ్చిన వెంటనే, అతను చాలా సంతోషిస్తాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "translatedText": "మరోవైపు, ఆలిస్ గణనలను వాయిదా వేయడానికి ఎక్కువ మొగ్గు చూపుతుంది, ఆమెకు వాటిని ఎలా చేయాలో తెలియకపోవటం లేదా వ్యక్తిగతంగా చేయకూడదనుకోవడం వలన కాదు, కానీ ఆమె ఆ రకమైన ఉన్నత-స్థాయి సాధారణ అవలోకనాన్ని పొందడానికి ఇష్టపడుతుంది. ఆమె వ్యవహరించే సమస్య, దాని సాధారణ ఆకృతి, ఆమె గణనలను తీయడానికి ముందు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "translatedText": "ఆమె తన ముందు కూర్చున్న నిర్దిష్ట ప్రశ్నను మాత్రమే కాకుండా, మీరు దానిని సాధారణీకరించగల విశాలమైన మార్గాన్ని కూడా అర్థం చేసుకుంటే, మరియు ప్రత్యేకించి మరింత సాధారణ వీక్షణ మరింత వేగవంతమైన మరియు సొగసైన గణనలకు దారితీసినట్లయితే, ఆమె చాలా సంతోషిస్తుంది. వాటిని అమలు చేయడానికి కూర్చోండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "translatedText": "ఇప్పుడు వారిద్దరూ ఎదుర్కోబోతున్న పజిల్ ఏమిటంటే, ఒక క్యూబ్ యొక్క నీడ కోసం సగటు ప్రాంతాన్ని కనుగొనడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "translatedText": "కాబట్టి నేను ఇక్కడ కూర్చున్న క్యూబ్ రకం అంతరిక్షంలో ఉంటే, దాని నీడ యొక్క ప్రాంతాన్ని ప్రభావితం చేసే కొన్ని అంశాలు ఉన్నాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "translatedText": "ఒక స్పష్టమైన క్యూబ్ పరిమాణం, చిన్న క్యూబ్, చిన్న నీడ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "translatedText": "కానీ అది వేర్వేరు ధోరణుల వద్ద కూర్చున్నట్లయితే, ఆ దిశలు వేర్వేరు ప్రాంతాలతో విభిన్న ప్రత్యేక నీడలకు అనుగుణంగా ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "translatedText": "మరియు ఇక్కడ సగటును కనుగొనండి అని నేను చెప్పినప్పుడు, నా ఉద్దేశ్యం ఏమిటంటే క్యూబ్ యొక్క నిర్దిష్ట పరిమాణం కోసం సాధ్యమయ్యే అన్ని ధోరణులపై సగటు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "translatedText": "మీలో ఉన్న తెలివిగలవారు కాంతి మూలం ఎక్కడ ఉందో కూడా చాలా ముఖ్యమైనదని సూచించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "translatedText": "కాంతి మూలం చాలా తక్కువగా ఉంటే, క్యూబ్‌కు దగ్గరగా ఉంటే, అప్పుడు నీడ పెద్దదిగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "translatedText": "మరియు కాంతి మూలం ఒకవిధంగా పక్కకు పక్కకు ఉంచబడి ఉంటే, ఇది నీడను వక్రీకరిస్తుంది మరియు దానికి చాలా భిన్నమైన ఆకారాన్ని ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "translatedText": "ఆ కాంతి స్థానానికి అకౌంటింగ్ దాని స్వంత హక్కులో చాలా ఆసక్తికరంగా ఉంటుంది, కానీ పజిల్ తగినంత కష్టంగా ఉంటుంది, కాబట్టి కనీసం మొదట్లో, మనం చేయగలిగిన సులభమైన పనిని చేద్దాం మరియు కాంతి నేరుగా క్యూబ్ పైన మరియు చాలా దూరంగా ఉందని చెప్పండి. దూరంగా, ప్రభావవంతంగా అనంతంగా, కాబట్టి మేము పరిగణిస్తున్నది ఫ్లాట్ ప్రొజెక్షన్, అంటే మీరు ఏదైనా కోఆర్డినేట్‌లు, x, y, z, స్పేస్‌లో చూస్తే, ఫ్లాట్ ప్రొజెక్షన్ x, y, 0 అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "translatedText": "కాబట్టి మన బేరింగ్‌లను పొందడానికి, క్యూబ్ నేరుగా పైకి, దాని రెండు ముఖాలు భూమికి సమాంతరంగా ఉంటే ఆలోచించడం చాలా సులభమైన పరిస్థితి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "translatedText": "అలాంటప్పుడు, ఈ ఫ్లాట్ ప్రొజెక్షన్ షాడో కేవలం ఒక చతురస్రం, మరియు క్యూబ్ యొక్క సైడ్ లెంగ్త్‌లు s అని చెప్పినట్లయితే, ఆ నీడ వైశాల్యం s స్క్వేర్డ్ అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "translatedText": "ఇంకా చెప్పాలంటే, నేను ఈ యానిమేషన్‌లపై లేబుల్‌ను కలిగి ఉన్నట్లయితే, ఇక్కడ కింద ఉన్నటువంటి క్యూబ్‌కు 1 వైపు పొడవు ఉందని నేను ఊహిస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "translatedText": "ఇప్పుడు అన్ని విన్యాసాల్లో మరొక ప్రత్యేక సందర్భం ఏమిటంటే, దీర్ఘ వికర్ణం కాంతి దిశకు సమాంతరంగా ఉంటే ఆలోచించడం సరదాగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "translatedText": "అలాంటప్పుడు, నీడ వాస్తవానికి సాధారణ షడ్భుజిలా కనిపిస్తుంది మరియు మేము కొన్ని నిమిషాల్లో అభివృద్ధి చేసే కొన్ని పద్ధతులను మీరు ఉపయోగిస్తే, ఆ నీడ వైశాల్యం ఖచ్చితంగా 3 రెట్లు వైశాల్యం యొక్క వర్గమూలం అని మీరు లెక్కించవచ్చు. చతురస్రాకార ముఖాలలో ఒకటి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "translatedText": "అయితే, చాలా తరచుగా, అసలు నీడ ఒక చతురస్రం లేదా షడ్భుజి వలె సాధారణమైనది కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "translatedText": "ఈ క్యూబ్ కోసం ఓరియంటేషన్ గురించి ఆలోచించడం కొంత కష్టం ఆధారంగా ఆకారం గురించి ఆలోచించడం కొంత కష్టం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "translatedText": "ఇంతకు ముందు, నేను సాధారణంగా సాధ్యమయ్యే అన్ని ధోరణులపై సగటున ఈ పదబంధాన్ని విసిరాను, కానీ మీరు సరిగ్గా అడగవచ్చు, దాని అర్థం ఏమిటి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "translatedText": "కనీసం దాన్ని ధృవీకరించడానికి మీరు ఏ ప్రయోగం చేస్తారనే కోణంలో అయినా మనలో చాలా మందికి దీని అర్థం కావాలనే దాని గురించి స్పష్టమైన అనుభూతి ఉందని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "translatedText": "మీరు ఈ క్యూబ్‌ను డైలాగా గాలిలో విసిరి, ఏదైనా ఏకపక్ష పాయింట్ వద్ద గడ్డకట్టడం, ఆ స్థానం నుండి నీడ యొక్క ప్రాంతాన్ని రికార్డ్ చేయడం, ఆపై పునరావృతం చేయడం వంటివి మీరు ఊహించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "translatedText": "మీరు దీన్ని చాలాసార్లు చేసినట్లయితే, మీరు మీ నమూనా యొక్క సగటును తీసుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "translatedText": "మేము పొందాలనుకునే సంఖ్య, ఇక్కడ నిజమైన సగటు, మీరు మరింత ఎక్కువ టాస్‌లు చేస్తున్నప్పుడు, అనంతమైన అనేకాన్ని చేరుకునేటప్పుడు ఆ ప్రయోగాత్మక సగటు ఏదయినా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "translatedText": "ఇప్పటికీ, మీలో ఉన్న స్టిక్కర్లు నిజంగా ప్రశ్నకు సమాధానం ఇవ్వలేదని ఫిర్యాదు చేయవచ్చు, ఎందుకంటే మేము యాదృచ్ఛిక టాస్‌ను ఎలా నిర్వచిస్తున్నాము అనే సమస్యను ఇది తెరుస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "translatedText": "దీనికి సమాధానమివ్వడానికి సరైన మార్గం, ఇది మరింత లాంఛనప్రాయంగా ఉండాలనుకుంటే, గణిత శాస్త్రజ్ఞులు వాస్తవానికి ఫాన్సీ పేరును ఇచ్చిన అన్ని ధోరణుల స్థలాన్ని వివరించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "translatedText": "వారు దీనిని SO3 అని పిలుస్తారు, సాధారణంగా 3x3 మాత్రికల నిర్దిష్ట కుటుంబం పరంగా నిర్వచించబడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "translatedText": "మరియు మేము సమాధానం చెప్పాలనుకుంటున్న ప్రశ్న ఏమిటంటే, ఈ మొత్తం స్థలానికి మనం ఏ సంభావ్యత పంపిణీని ఉంచుతున్నాము?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "translatedText": "అటువంటి సంభావ్యత పంపిణీని బాగా నిర్వచించినప్పుడు మాత్రమే మనం సగటుతో కూడిన ప్రశ్నకు సమాధానం ఇవ్వగలము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "translatedText": "మీరు అలాంటి విషయాలకు కట్టుబడి ఉన్నట్లయితే, వీడియో చివరి వరకు మీరు ఆ ప్రశ్నను ఆపివేయాలని నేను కోరుకుంటున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "translatedText": "పంపిణీని నిజంగా నిర్వచించకుండా యాదృచ్ఛిక టాస్‌ల సమూహాన్ని పునరావృతం చేసే మరింత హ్యూరిస్టిక్, ప్రయోగాత్మక ఆలోచనతో మేము ఎంత దూరం పొందగలమో మీరు ఆశ్చర్యపోతారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "translatedText": "మేము ఆలిస్ మరియు బాబ్ యొక్క పరిష్కారాలను చూసిన తర్వాత, వారిలో ప్రతి ఒక్కరు తమ మార్గంలో ఈ పంపిణీని ఎలా నిర్వచించారు అని అడగడం చాలా ఆసక్తికరంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "translatedText": "మరియు గుర్తుంచుకోండి, ఇది క్యూబ్ షాడోస్ గురించి పాఠం కాదు, కానీ సమస్య పరిష్కారం గురించి పాఠం, మేము పజిల్‌కు తీసుకురాగల రెండు విభిన్న మనస్తత్వాల లెన్స్ ద్వారా చెప్పబడింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "translatedText": "మరియు సమస్య పరిష్కారానికి సంబంధించిన ఏదైనా పాఠం వలె, ఇక్కడ లక్ష్యం మేము వీలైనంత త్వరగా సమాధానాన్ని పొందడం కాదు, కానీ మీరే సమాధానాన్ని కనుగొన్నట్లు మీరు భావిస్తారని ఆశిస్తున్నాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "translatedText": "కాబట్టి మీకు ఏదైనా ఆలోచన ఉందని మీకు అనిపించినప్పుడు ఏదైనా పాయింట్ ఉంటే, పాజ్ చేయడానికి మరియు దాని గురించి ఆలోచించడానికి ప్రయత్నించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "translatedText": "మొదటి దశగా, మరియు ఇది ఏదైనా నిర్దిష్ట సమస్య పరిష్కార శైలుల నుండి నిజంగా స్వతంత్రంగా ఉంటుంది, మీరు ఎప్పుడైనా కష్టమైన ప్రశ్నను కనుగొన్నప్పుడు, మీరు చేయగలిగిన మంచి విషయం ఏమిటంటే, మీరు చేసే సమస్యకు అత్యంత సరళమైన, చిన్నవిషయం కాని వేరియంట్ ఏమిటి పరిష్కరించడానికి ప్రయత్నించగలరా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "translatedText": "కాబట్టి మా విషయంలో, మీరు చెప్పేది ఏమిటంటే, సరే, అన్ని ధోరణులపై సగటు గురించి మరచిపోదాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about.",
  "translatedText": "అది ఆలోచించడం గమ్మత్తైన విషయం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "translatedText": "మరియు క్యూబ్ యొక్క అన్ని విభిన్న ముఖాల గురించి కూడా మర్చిపోదాం, ఎందుకంటే అవి అతివ్యాప్తి చెందుతాయి మరియు దాని గురించి ఆలోచించడం కూడా గమ్మత్తైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "translatedText": "ఒక నిర్దిష్ట ముఖం మరియు ఒక నిర్దిష్ట ధోరణి కోసం, మేము ఈ నీడ యొక్క వైశాల్యాన్ని లెక్కించగలమా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "translatedText": "మరోసారి, మీరు మీ బేరింగ్‌లను కొన్ని ప్రత్యేక సందర్భాలలో పొందాలనుకుంటే, ఆ ముఖం భూమికి సమాంతరంగా ఉన్నప్పుడు చాలా సులభం, ఆ సందర్భంలో నీడ యొక్క ప్రాంతం ముఖం యొక్క వైశాల్యంతో సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "translatedText": "మరియు మరోవైపు, మనం ఆ ముఖాన్ని 90 డిగ్రీలు వంచి ఉంటే, అప్పుడు దాని నీడ సరళ రేఖగా ఉంటుంది మరియు దాని వైశాల్యం సున్నా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "translatedText": "కాబట్టి బాబ్ దీనిని చూస్తాడు మరియు అతను ఆ నీడకు అసలు ఫార్ములా కావాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "translatedText": "మరియు అతను దాని గురించి ఆలోచించే విధానం ఆ ముఖం యొక్క సాధారణ వెక్టార్‌ను లంబంగా పరిగణించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "translatedText": "మరియు సంబంధితంగా అనిపించేది ఏమిటంటే, ఆ సాధారణ వెక్టర్ నిలువుతో చేసే కోణం, కాంతి ఎక్కడ నుండి వస్తున్నది, దానిని మనం తీటా అని పిలుస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "translatedText": "ఇప్పుడు, మనం ఇప్పుడే చూసిన రెండు ప్రత్యేక సందర్భాల నుండి, తీటా సున్నాకి సమానం అయినప్పుడు, ఆ నీడ యొక్క వైశాల్యం ఆకారపు వైశాల్యంతో సమానంగా ఉంటుందని, చతురస్రం వైపు పొడవులు ఉంటే s స్క్వేర్ చేయబడుతుందని మనకు తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "translatedText": "మరియు తీటా 90 డిగ్రీలకు సమానం అయితే, ఆ నీడ వైశాల్యం సున్నా.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "translatedText": "మరియు త్రికోణమితి ఏదో ఒకవిధంగా సంబంధితంగా ఉంటుందని ఊహించడం చాలా కష్టం కాదు, కాబట్టి వారి ట్రిగ్ ఫంక్షన్‌లతో సౌకర్యవంతమైన ఎవరైనా సరైన ఫార్ములా ఏమిటో అంచనా వేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "translatedText": "కానీ బాబ్ దాని కంటే ఎక్కువ వివరాల ఆధారితమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "translatedText": "కేవలం ఎండ్ పాయింట్స్ ఆధారంగా అంచనా వేయకుండా, ఆ ప్రాంతం ఎలా ఉండాలో సరిగ్గా నిరూపించాలన్నారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "translatedText": "మరియు మీరు దాని గురించి ఆలోచించే విధానం ఇలాంటిదే కావచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "translatedText": "మనం నిలువుగా అలాగే మన సాధారణ వెక్టర్ గుండా వెళ్ళే విమానాన్ని పరిగణలోకి తీసుకుంటే, ఆ విమానంలో లేదా ఆ ప్లేన్‌కి సమాంతరంగా ఉన్న మన ఆకృతిలోని వివిధ ముక్కలన్నింటినీ పరిగణనలోకి తీసుకుంటే, మన దృష్టిని రెండింటిపై కేంద్రీకరించవచ్చు- సమస్య యొక్క డైమెన్షనల్ వేరియంట్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "translatedText": "మనం ఆ స్లైస్‌లలో ఒకదానిని చూస్తే, సాధారణ వెక్టార్, వర్టికల్ నుండి ఒక యాంగిల్ తీటాని కలిగి ఉంటే, దాని ఛాయ ఇలా కనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "translatedText": "మరియు మనం ఇక్కడ ఎడమ వైపుకు నిలువు గీతను గీసినట్లయితే, మనకు ఒక లంబ త్రిభుజం ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "translatedText": "మరియు ఇక్కడ నుండి మనం కొంచెం యాంగిల్ ఛేజింగ్ చేయవచ్చు, ఇక్కడ ఆ యాంగిల్ తీటా మిగిలిన రేఖాచిత్రం గురించి ఏమి సూచిస్తుందో మనం అనుసరిస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "translatedText": "మరియు దీని అర్థం ఈ త్రిభుజంలో దిగువ లంబ కోణం ఖచ్చితంగా తీటా.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "translatedText": "కాబట్టి, ముక్క యొక్క అసలు పరిమాణంతో పోల్చి చూస్తే, ఈ నీడ యొక్క పరిమాణాన్ని మనం అర్థం చేసుకోవాలనుకున్నప్పుడు, ఆ కోణం యొక్క కొసైన్, తీటా, ఇది హైపోటెన్యూస్‌పై ప్రక్కనే గుర్తుంచుకుంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "translatedText": "ఇది అక్షరాలా నీడ పరిమాణం మరియు స్లైస్ పరిమాణం మధ్య నిష్పత్తి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "translatedText": "కాబట్టి, స్లైస్ ఈ దిశలో స్క్విష్ చేయబడే అంశం ఖచ్చితంగా తీటా యొక్క కొసైన్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "translatedText": "మరియు మన వీక్షణను మొత్తం చతురస్రానికి విస్తరింపజేస్తే, ఆ దిశలో ఉన్న అన్ని స్లైస్‌లు ఒకే కారకం ద్వారా స్కేల్ చేయబడతాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "translatedText": "కానీ మరొక దిశలో, ఆ స్లైస్‌కు లంబంగా, సాగదీయడం లేదా స్క్విషింగ్ చేయడం లేదు, ఎందుకంటే ముఖం ఆ వైపుకు అస్సలు వంగి ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "translatedText": "కాబట్టి మొత్తంగా, మన ద్విమితీయ ముఖం యొక్క టూ-డైమెన్షనల్ షాడో కూడా తీటా యొక్క కొసైన్ యొక్క ఈ కారకం ద్వారా తగ్గించబడాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "translatedText": "కోణం 0° మరియు 90° ఉన్న సందర్భంలో మీరు అకారణంగా ఊహిస్తున్న దానితో ఇది వరుసలో ఉంటుంది, కానీ అది ఎందుకు నిజమో చూడటం భరోసానిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "translatedText": "మరియు వాస్తవానికి, ఇప్పటివరకు చెప్పినట్లుగా, ఇది చాలా సరైనది కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "translatedText": "మేము వ్రాసిన సూత్రంలో ఒక చిన్న సమస్య ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "translatedText": "తీటా 90° కంటే పెద్దగా ఉన్న సందర్భంలో, కొసైన్ వాస్తవానికి ప్రతికూలంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "translatedText": "అయితే, మేము నీడను ప్రతికూల ప్రాంతాన్ని కలిగి ఉండాలని పరిగణించకూడదు, కనీసం ఇలాంటి సమస్యలో కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this.",
  "translatedText": "కాబట్టి మీరు దీన్ని పరిష్కరించగల రెండు విభిన్న మార్గాలు ఉన్నాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "translatedText": "సానుకూల z కాంపోనెంట్‌ని కలిగి ఉన్న సాధారణ వెక్టార్‌ను మాత్రమే మేము ఎప్పుడైనా పరిగణించాలనుకుంటున్నామని మీరు చెప్పవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "translatedText": "లేదా, మరింత సరళంగా, మనం చెప్పగలం, ఆ కొసైన్ యొక్క సంపూర్ణ విలువను తీసుకోండి మరియు అది మాకు చెల్లుబాటు అయ్యే ఫార్ములాను ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "translatedText": "కాబట్టి బాబ్ సంతోషంగా ఉన్నాడు, ఎందుకంటే అతను నీడ యొక్క ప్రాంతాన్ని వివరించే ఖచ్చితమైన సూత్రాన్ని కలిగి ఉన్నాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "translatedText": "కానీ ఆలిస్ దాని గురించి కొంచెం భిన్నంగా ఆలోచించడం ప్రారంభిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "translatedText": "ఆమె చెప్పింది, సరే, మేము కొంత ఆకృతిని పొందాము, ఆపై మేము దానిని ఏదో ఒక విధంగా 3D స్పేస్‌లో ఉంచే విధమైన భ్రమణాన్ని వర్తింపజేస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.06,
  "end": 560.52
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "translatedText": "ఆపై మేము ఫ్లాట్ ప్రొజెక్షన్‌ని వర్తింపజేస్తాము, అది తిరిగి రెండు డైమెన్షనల్ స్పేస్‌లోకి వస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.78,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "translatedText": "మరియు ఈ రెండూ లీనియర్ ట్రాన్స్‌ఫార్మేషన్‌లు కావడం ఆమెకు ప్రత్యేకంగా నిలుస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "translatedText": "అంటే సూత్రప్రాయంగా మీరు వాటిలో ప్రతి ఒక్కటి మాతృకతో వివరించవచ్చు మరియు మొత్తం పరివర్తన ఆ రెండు మాత్రికల ఉత్పత్తి వలె కనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "translatedText": "ఆలిస్ తనకు ఇష్టమైన సబ్జెక్ట్‌లలో ఒకటైన లీనియర్ ఆల్జీబ్రా నుండి తెలుసుకునేది ఏమిటంటే, మీరు కొంత ఆకారాన్ని తీసుకొని దాని వైశాల్యాన్ని పరిగణనలోకి తీసుకుంటే, మీరు కొంత సరళ పరివర్తనను వర్తింపజేస్తే, ఆ అవుట్‌పుట్ యొక్క వైశాల్యం ఆకారం యొక్క అసలు వైశాల్యం కంటే కొంత స్థిరంగా కనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "translatedText": "మరింత ప్రత్యేకంగా, ఆ స్థిరాంకానికి మనకు ఒక పేరు ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation.",
  "translatedText": "ఇది పరివర్తన యొక్క నిర్ణయాధికారి అంటారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "translatedText": "మీరు లీనియర్ ఆల్జీబ్రాతో అంత సౌకర్యంగా లేకుంటే, మేము మరింత స్పష్టమైన వివరణను అందించవచ్చు మరియు మీరు అసలు ఆకారాన్ని ఏదో ఒక దిశలో ఏకరీతిగా సాగదీస్తే, అవుట్‌పుట్ కూడా ఏదో ఒక దిశలో ఏకరీతిగా సాగుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "translatedText": "కాబట్టి వాటిలో ప్రతి ప్రాంతం ఒకదానికొకటి నిష్పత్తిలో స్కేల్ చేయాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "translatedText": "ఇప్పుడు సూత్రప్రాయంగా, ఆలిస్ ఈ నిర్ణాయకాన్ని గణించగలదు, కానీ అది నిజంగా ఆమె శైలి కాదు, కనీసం వెంటనే అలా చేయకూడదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "translatedText": "బదులుగా, ఆమె వ్రాసిన విషయం ఏమిటంటే, మన అసలు ఆకారం మరియు దాని నీడ మధ్య ఈ అనుపాత స్థిరాంకం అసలు ఆకారంపై ఎలా ఆధారపడదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "translatedText": "మేము ఈ పిల్లి రూపురేఖల నీడ గురించి లేదా మరేదైనా గురించి మాట్లాడవచ్చు మరియు దాని పరిమాణం నిజంగా పట్టింపు లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "translatedText": "ఆ అనుపాత స్థిరాంకాన్ని ప్రభావితం చేసే ఏకైక విషయం ఏమిటంటే, మనం ఏ పరివర్తనను వర్తింపజేస్తున్నామో, ఈ సందర్భంలో మనం దానిని ఆకారానికి వర్తింపజేసే భ్రమణంపై ఆధారపడి ఉండే కొంత అంశంగా వ్రాయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "translatedText": "మన మనస్సులో, బాబ్ యొక్క గణన కారణంగా, ఆ అంశం ఎలా ఉంటుందో మనకు తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "translatedText": "మీకు తెలుసా, ఇది సాధారణ వెక్టార్ మరియు నిలువు మధ్య కోణం యొక్క కొసైన్ యొక్క సంపూర్ణ విలువ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "translatedText": "కానీ ఆలిస్ ప్రస్తుతం చెబుతోంది, అవును, అవును, అవును, నేను కోరుకున్నప్పుడు నేను దాని గురించి ఆలోచించగలను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "translatedText": "కానీ మేము ఏమైనప్పటికీ అన్ని విభిన్న ధోరణులపై సగటున ఉన్నామని ఆమెకు తెలుసు, అయినప్పటికీ నిర్దిష్ట ధోరణికి సంబంధించిన ఏదైనా నిర్దిష్ట సూత్రం ఆ సగటులో కొట్టుకుపోవచ్చని ఆమె కొంత ఆశను కలిగి ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "translatedText": "ఇప్పుడు దీన్ని చూడటం సులభం, సరే, ఆలిస్ నిజంగా ఏమీ చేయడం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "translatedText": "వాస్తవానికి నీడ యొక్క ప్రాంతం అసలు ఆకారం యొక్క ప్రాంతానికి అనులోమానుపాతంలో ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "translatedText": "అవి రెండూ రెండు డైమెన్షనల్ పరిమాణాలు, అవి రెండూ రెండు డైమెన్షనల్ విషయాల వలె స్కేల్ చేయాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 675.62,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "translatedText": "కానీ గుర్తుంచుకోండి, మనం దగ్గరి కాంతి మూలాన్ని కలిగి ఉన్న కఠినమైన కేసుతో వ్యవహరిస్తున్నట్లయితే ఇది అస్సలు నిజం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear.",
  "translatedText": "ఆ సందర్భంలో, ప్రొజెక్షన్ సరళంగా ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "translatedText": "ఉదాహరణకు, నేను ఈ పిల్లిని తిప్పితే దాని తోక కాంతి మూలానికి చాలా దగ్గరగా ఉంటుంది, నేను అసలు ఆకారాన్ని x-దిశలో ఏకరీతిగా సాగదీస్తే, 1 కారకంతో చెప్పండి.5, ఇది అంతిమ నీడపై చాలా అసమాన ప్రభావాన్ని కలిగి ఉండవచ్చు, ఎందుకంటే ఇది నిజంగా కాంతికి దగ్గరగా ఉన్నందున తోక చాలా అసమానంగా ఎగిరిపోతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "translatedText": "మళ్ళీ, ఆలిస్ సమస్య యొక్క ఏ లక్షణాలు వాస్తవానికి సంబంధించినవి అనే దాని కోసం ఒక కన్ను వేసి ఉంచుతుంది, ఎందుకంటే ఆమె విషయాలను ఎంతవరకు సాధారణీకరించగలదో తెలుసుకోవడానికి ఇది సహాయపడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "translatedText": "మనం చతురస్రాకారపు ముఖం గురించి ఆలోచిస్తున్నామనే వాస్తవం ముఖ్యమా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really.",
  "translatedText": "నిజంగా కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "translatedText": "పరివర్తన సరళమైనది అనే వాస్తవం ముఖ్యమా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely.",
  "translatedText": "అవును ఖచ్చితంగా.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "translatedText": "ఆలిస్ కూడా ఇలాంటి ఆకారానికి సగటు నీడ గురించి ఇదే విధమైన ఆలోచనా విధానాన్ని వర్తింపజేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "translatedText": "మన చతురస్రాకార ముఖానికి వర్తించే కొన్ని భ్రమణాల శ్రేణిని కలిగి ఉన్నారని చెప్పండి మరియు వాటిని R1, R2, R3 మరియు ఇంకా పిలుద్దాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.02,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "translatedText": "ఆ సందర్భాలలో ప్రతి ఒక్కదానిలో నీడ యొక్క వైశాల్యం చతురస్రం యొక్క వైశాల్యానికి కొంత కారకం రెట్లు కనిపిస్తుంది మరియు ఆ కారకం భ్రమణంపై ఆధారపడి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 739.72,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "translatedText": "కాబట్టి మనం ప్రస్తుతం చూస్తున్న భ్రమణాల నమూనాలో ఆ నీడ కోసం అనుభావిక సగటును తీసుకుంటే, ఆ నీడ ప్రాంతాలన్నింటినీ జోడించి, ఆపై మన వద్ద ఉన్న మొత్తం సంఖ్యతో భాగించడం అనేది కనిపించే విధానం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "translatedText": "ఇప్పుడు, సరళత కారణంగా, అసలు చతురస్రంలోని ఈ ప్రాంతం అన్నింటి నుండి క్లీన్‌గా కారకం చేయగలదు మరియు అది ఎడమ వైపున ముగుస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "translatedText": "ఇది మేము వెతుకుతున్న ఖచ్చితమైన సగటు కాదు, ఇది భ్రమణాల నమూనా యొక్క అనుభావిక సగటు, కానీ సూత్రప్రాయంగా మనం వెతుకుతున్నది మా నమూనా యొక్క పరిమాణం అనంతానికి చేరుకోవడంతో ఇది చేరుకుంటుంది మరియు అన్ని నమూనా పరిమాణంపై ఆధారపడిన భాగాలు ఆ ప్రాంతానికి దూరంగా శుభ్రంగా కూర్చుంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.2,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "translatedText": "కాబట్టి పరిమితిలో ఇది ఏమైనప్పటికీ, అది కొంత సంఖ్య మాత్రమే అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "translatedText": "గణించడం రాయల్ నొప్పి కావచ్చు, దాని గురించి మాకు ఇంకా ఖచ్చితంగా తెలియదు, కానీ ఆలిస్ పేర్కొన్న విషయం ఏమిటంటే ఇది మనం చూస్తున్న నిర్దిష్ట 2D విషయం యొక్క పరిమాణం మరియు ఆకృతితో సంబంధం లేకుండా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "translatedText": "ఇది సార్వత్రిక అనుపాత స్థిరాంకం, మరియు ఆ సార్వత్రికత ఏదో ఒకవిధంగా అది ఎలా ఉండాలో అంచనా వేయడానికి మరింత సొగసైన మార్గాన్ని ఇస్తుంది అని ఆమె ఆశ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.72,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "translatedText": "ఇప్పుడు బాబ్ ఈ స్థిరాంకాన్ని ఇక్కడ మరియు ఇప్పుడు గణించడానికి ఆసక్తిగా ఉంటాడు మరియు కొన్ని నిమిషాల్లో అతను దీన్ని ఎలా చేస్తాడో నేను మీకు చూపిస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "translatedText": "కానీ అంతకంటే ముందు నేను ఆలిస్ ప్రపంచంలో మరికొంత కాలం ఉండాలనుకుంటున్నాను, ఎందుకంటే ఇక్కడే విషయాలు నిజంగా సరదాగా ప్రారంభమవుతాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "translatedText": "వివరాల్లోకి ప్రవేశించే ముందు ప్రశ్న యొక్క మొత్తం నిర్మాణాన్ని అర్థం చేసుకోవాలనే ఆమె కోరికతో, క్యూబ్ యొక్క నీడ యొక్క వైశాల్యం దాని వ్యక్తిగత ముఖాల వైశాల్యానికి ఎలా సంబంధం కలిగి ఉంటుంది అనే దాని గురించి ఆమె ఇప్పుడు ఆసక్తిగా ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "translatedText": "ఇప్పుడు మనం ఒక నిర్దిష్ట ముఖం యొక్క సగటు వైశాల్యం గురించి ఏదైనా చెప్పగలిగితే, అది మొత్తంగా క్యూబ్ యొక్క సగటు వైశాల్యం గురించి ఏమైనా చెబుతుందా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "translatedText": "ఉదాహరణకు, మేము చెప్పగలిగే ఒక సాధారణ విషయం ఏమిటంటే, ఆ ప్రాంతం అన్ని ముఖాల్లోని ప్రాంతాల మొత్తం కంటే ఖచ్చితంగా తక్కువగా ఉంటుంది, ఎందుకంటే ఆ నీడల మధ్య అర్థవంతమైన అతివ్యాప్తి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "translatedText": "కానీ ఆ అతివ్యాప్తి గురించి ఎలా ఆలోచించాలో పూర్తిగా స్పష్టంగా తెలియదు, ఎందుకంటే మనం కేవలం రెండు ప్రత్యేక ముఖాలపై దృష్టి పెడితే, కొన్ని ఓరియంటేషన్లలో అవి అతివ్యాప్తి చెందవు, కానీ ఇతర ధోరణులలో అవి కొన్ని అతివ్యాప్తి మరియు నిర్దిష్ట ఆకృతిని కలిగి ఉంటాయి మరియు ఆ అతివ్యాప్తి యొక్క ప్రాంతం గురించి ఆలోచించడం కొంచెం గమ్మత్తైనదిగా అనిపిస్తుంది, భూమిపై మనం వివిధ ధోరణులన్నింటిలో సగటున ఎలా చూస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.64,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "translatedText": "కానీ ఆలిస్ ఈ మొత్తం సమస్య గురించి మూడు తెలివైన అంతర్దృష్టులను కలిగి ఉంది మరియు వాటిలో ఇది మొదటిది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "translatedText": "ఆమె చెప్పింది, వాస్తవానికి, మనం ఒక జత ముఖాల గురించి కాకుండా మొత్తం క్యూబ్ గురించి ఆలోచిస్తే, ఇచ్చిన ఓరియంటేషన్ కోసం నీడ యొక్క వైశాల్యం అన్ని ముఖాల వైశాల్యాల మొత్తంలో సరిగ్గా సగం ఉంటుందని మేము నిర్ధారించగలము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "translatedText": "అకారణంగా మీరు వారిలో సగం మంది కాంతిలో స్నానం చేశారని మరియు వారిలో సగం మంది లేరని మీరు ఊహించవచ్చు, కానీ ఆమె దానిని సమర్థించే మార్గం ఇక్కడ ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "translatedText": "ఒక నిర్దిష్ట కాంతి కిరణం కోసం, అవి ఆకాశం నుండి వెళ్లి చివరికి నీడలో ఒక బిందువును తాకుతాయని ఆమె చెప్పింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 895.82,
  "end": 901.4
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "translatedText": "ఆ కిరణం సరిగ్గా రెండు పాయింట్ల వద్ద క్యూబ్ గుండా వెళుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 902.04,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "translatedText": "అది ప్రవేశించినప్పుడు ఒక క్షణం మరియు అది నిష్క్రమించినప్పుడు ఒక క్షణం ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "translatedText": "కాబట్టి ఆ నీడలోని ప్రతి బిందువు దాని పైన ఉన్న రెండు ముఖాలకు అనుగుణంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "translatedText": "సరే, సరే, ఆ కాంతి పుంజం చతురస్రాల్లో ఒకదాని అంచు గుండా వెళితే అది నిజం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "translatedText": "ఇది ఎన్ని ముఖాలను దాటుతోంది అనే దానిపై కొంచెం సందిగ్ధత ఉంది, కానీ అవి నీడ లోపల సున్నా ప్రాంతాన్ని కలిగి ఉంటాయి, కాబట్టి మేము ప్రాంతాన్ని గణించడానికి ప్రయత్నిస్తున్నట్లయితే వాటిని విస్మరించడం సురక్షితం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 919.6,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "translatedText": "ఆలిస్ నొక్కినప్పుడు మరియు ఇది ఎందుకు నిజమో ఆమె సమర్థించవలసి వస్తే, సమస్య ఎలా సాధారణీకరించబడుతుందో అర్థం చేసుకోవడానికి ముఖ్యమైనది, ఆమె కుంభాకార ఆలోచనకు విజ్ఞప్తి చేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "translatedText": "కుంభాకారం అనేది ఆ లక్షణాలలో ఒకటి, ఇక్కడ మనలో చాలా మందికి దాని అర్థం ఏమిటో అర్థం చేసుకోవచ్చు, మీకు తెలుసా, ఇది కేవలం ఉబ్బిన ఆకారాలు, అవి ఎప్పుడూ లోపలికి వెళ్లవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "translatedText": "కానీ గణిత శాస్త్రజ్ఞులు వాస్తవ రుజువులకు సహాయపడే దానిని అధికారికీకరించడానికి చాలా తెలివైన మార్గాన్ని కలిగి ఉన్నారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "translatedText": "ఆ సెట్ లోపల ఏదైనా రెండు బిందువులను కలిపే రేఖ పూర్తిగా సెట్‌లోనే ఉంటే ఆ సమితి కుంభాకారంగా ఉంటుందని వారు అంటున్నారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "translatedText": "కాబట్టి చతురస్రం కుంభాకారంగా ఉంటుంది, ఎందుకంటే మీరు ఆ చతురస్రం లోపల రెండు పాయింట్లను ఎక్కడ ఉంచినా, వాటిని కలిపే రేఖ పూర్తిగా చతురస్రం లోపల ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "translatedText": "కానీ గుర్తు పై లాంటిది కుంభాకారంగా ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 970.28,
  "end": 972.72
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "translatedText": "నేను రెండు వేర్వేరు పాయింట్‌లను సులభంగా కనుగొనగలను, తద్వారా వాటిని కనెక్ట్ చేసే పంక్తి సెట్ వెలుపల గరిష్ట స్థాయికి చేరుకోవాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 972.84,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "translatedText": "కుంభాకార పదంలోని అక్షరాలు ఏవీ కుంభాకారంగా లేవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "translatedText": "మీరు రెండు పాయింట్లను కనుగొనవచ్చు, తద్వారా వాటిని కనెక్ట్ చేసే లైన్ సెట్ వెలుపలికి వెళ్లాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "translatedText": "ఈ ఆకారం యొక్క ఆలోచనను అధికారికీకరించడానికి ఇది నిజంగా తెలివైన మార్గం, ఎందుకంటే అది ఏ సమయంలోనైనా లోపలికి చొచ్చుకుపోతుంది, మీరు ఈ ప్రతిరూప పంక్తులను కనుగొనవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 987.46,
  "end": 995.54
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "translatedText": "మా క్యూబ్, అది కుంభాకారంగా ఉన్నందున, మొదటి ప్రవేశ బిందువు మరియు నిష్క్రమణ చివరి బిందువు మధ్య, అది కుంభాకార నిర్వచనం ప్రకారం పూర్తిగా క్యూబ్ లోపల ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "translatedText": "కానీ మేము డోనట్ వంటి కొన్ని ఇతర కుంభాకార ఆకారంతో వ్యవహరిస్తుంటే, మీరు ప్రవేశించే కాంతి కిరణాన్ని కనుగొనవచ్చు, ఆపై నిష్క్రమిస్తుంది, ఆపై ప్రవేశిస్తుంది, ఆపై మళ్లీ నిష్క్రమిస్తుంది, కాబట్టి మీకు రెండు నుండి ఒకటి శుభ్రంగా ఉండదు. నీడల నుండి కవర్ చేయండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "translatedText": "దానిలోని అన్ని విభిన్న భాగాల నీడలు, మీరు దీన్ని ముఖాల సమూహంలో కవర్ చేస్తే, ఖచ్చితంగా నీడ వైశాల్యం కంటే రెండు రెట్లు ఎక్కువ ఉండవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "translatedText": "కాబట్టి, ఇది మొదటి కీలక అంతర్దృష్టి, ముఖ ఛాయలు క్యూబ్ షాడోను రెట్టింపుగా కవర్ చేస్తాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "translatedText": "మరియు తదుపరిది కొంచెం సింబాలిక్‌గా ఉంటుంది, కాబట్టి స్క్రీన్‌పై చోటు కల్పించడానికి మన సంజ్ఞామానాన్ని కొద్దిగా సంక్షిప్తీకరించడం ద్వారా పనులను ప్రారంభిద్దాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "translatedText": "క్యూబ్ యొక్క నీడ యొక్క వైశాల్యాన్ని వ్రాయడానికి బదులుగా, నేను క్యూబ్ యొక్క s అని వ్రాయబోతున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "translatedText": "మరియు అదేవిధంగా, ఒక నిర్దిష్ట ముఖం యొక్క నీడ యొక్క ప్రాంతానికి బదులుగా, నేను f యొక్క s వ్రాయబోతున్నాను, ఇక్కడ ఆ సబ్‌స్క్రిప్ట్ j నేను ఏ ముఖం గురించి మాట్లాడుతున్నానో సూచిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "translatedText": "అయితే, మనం నిజంగా క్యూబ్‌కు వర్తించే నిర్దిష్ట భ్రమణ నీడ గురించి మాట్లాడాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "translatedText": "కాబట్టి నేను దీనిని క్యూబ్‌కి వర్తింపజేసిన కొంత భ్రమణ s అని వ్రాయవచ్చు మరియు అదే విధంగా కుడి వైపున, ఇది ఇచ్చిన ముఖాలలో ఒకదానికి వర్తించే అదే భ్రమణపు నీడ యొక్క ప్రాంతం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "translatedText": "చేతిలో ఉన్న మరింత కాంపాక్ట్ సంజ్ఞామానంతో, అనేక విభిన్న భ్రమణాలలో ఈ నీడ ప్రాంతం యొక్క సగటు, r1, r2, r3 మొదలైన వాటి యొక్క కొంత నమూనా గురించి ఆలోచిద్దాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "translatedText": "మళ్ళీ, ఆ సగటు ఆ నీడ ప్రాంతాలన్నింటినీ జోడించి, ఆపై వాటిని n ద్వారా విభజించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "translatedText": "మరియు సూత్రప్రాయంగా, మనం పెద్ద మరియు పెద్ద నమూనాల కోసం దీనిని పరిశీలిస్తే, అనంతం వద్దకు వెళ్లనివ్వండి, అది క్యూబ్ యొక్క నీడ యొక్క సగటు వైశాల్యాన్ని ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "translatedText": "మీలో కొందరు ఆలోచిస్తూ ఉండవచ్చు, అవును, ఇది మాకు తెలుసు, మీరు దీన్ని ఇప్పటికే చెప్పారు, కానీ క్యూబ్ యొక్క నిర్దిష్ట భ్రమణానికి నీడ ప్రాంతాన్ని మొత్తంగా ఎందుకు వ్యక్తీకరించాలో అర్థం చేసుకోవడానికి దీన్ని వ్రాయడం ప్రయోజనకరంగా ఉంటుంది. దాని ముఖాలన్నింటిలో, లేదా కనీసం దానికి సగం రెట్లు, అది ఎందుకు ప్రయోజనకరం?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us?",
  "translatedText": "ఇది మన కోసం ఏమి చేయబోతోంది?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "translatedText": "సరే, క్యూబ్ యొక్క ఈ భ్రమణాలలో ప్రతి ఒక్కదానికి, అన్ని ముఖాలకు వర్తించే అదే భ్రమణంలో మనం ఆ నీడను మొత్తంగా విడగొట్టవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "translatedText": "మరియు ఇది ఇలా గ్రిడ్‌గా వ్రాయబడినప్పుడు, మనం ఆలిస్ యొక్క రెండవ అంతర్దృష్టిని పొందవచ్చు, అంటే మొత్తం గురించి మనం ఆలోచిస్తున్న విధానాన్ని వరుసగా వరుసల నుండి నిలువు వరుసకు బదులుగా కాలమ్‌కు మార్చడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "translatedText": "ఉదాహరణకు, మేము మొదటి నిలువు వరుసపై మాత్రమే దృష్టిని కేంద్రీకరిస్తే, అది మనకు చెప్పేది ఏమిటంటే, అనేక విభిన్న ధోరణులలో మొదటి ముఖం యొక్క నీడ యొక్క వైశాల్యాన్ని జోడించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "translatedText": "కాబట్టి మనం ఆ మొత్తాన్ని తీసుకొని దానిని మన నమూనా పరిమాణంతో భాగిస్తే, అది ఈ ముఖం యొక్క నీడ యొక్క వైశాల్యానికి అనుభావిక సగటును ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "translatedText": "కాబట్టి మనం పెద్ద మరియు పెద్ద నమూనాలను తీసుకుంటే, ఆ పరిమాణాన్ని అనంతానికి వెళ్లనివ్వండి, ఇది చదరపు సగటు నీడ ప్రాంతాన్ని చేరుకుంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "translatedText": "అదేవిధంగా, రెండవ నిలువు వరుస క్యూబ్ యొక్క రెండవ ముఖం యొక్క సగటు వైశాల్యాన్ని తెలియజేస్తున్నట్లు భావించవచ్చు, ఇది వాస్తవానికి అదే సంఖ్యగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "translatedText": "మరియు ఏదైనా ఇతర కాలమ్ కోసం అదే ఒప్పందం, ఇది ఒక నిర్దిష్ట ముఖం కోసం సగటు ప్రాంతాన్ని మాకు తెలియజేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "translatedText": "కాబట్టి అది మన మొత్తం వ్యక్తీకరణ గురించి చాలా భిన్నమైన ఆలోచనను ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "translatedText": "అన్ని విభిన్న ధోరణుల వద్ద క్యూబ్‌ల ప్రాంతాలను జోడించు అని చెప్పడానికి బదులుగా, మేము కేవలం ఆరు వేర్వేరు ముఖాల కోసం సగటు నీడలను జోడించి, మొత్తం సగంతో భాగించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "translatedText": "ఇక్కడ ఎడమ వైపున ఉన్న పదం ముందుగా అడ్డు వరుసలను జోడించడం గురించి ఆలోచిస్తోంది మరియు కుడి వైపున ఉన్న పదం ముందుగా నిలువు వరుసలను జోడించడం గురించి ఆలోచిస్తోంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "translatedText": "సంక్షిప్తంగా, ముఖ ఛాయల సగటు మొత్తం ముఖ ఛాయల సగటు మొత్తం సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "translatedText": "బహుశా ఆ స్వాప్ సాధారణమైనదిగా అనిపించవచ్చు, బహుశా అలా చేయకపోవచ్చు, కానీ మేము ఇప్పుడే తీసుకున్న దశకు కంటికి కనిపించే దానికంటే కొంచెం ఎక్కువ ఉందని నేను మీకు చెప్పగలను, కానీ మేము దానిని తర్వాత పొందుతాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "translatedText": "మరియు గుర్తుంచుకోండి, నిర్దిష్ట ముఖం యొక్క సగటు ప్రాంతం ఆ ముఖం యొక్క వైశాల్యానికి కొంత సార్వత్రిక అనుపాత స్థిరాంకం వలె కనిపిస్తుందని మాకు తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "translatedText": "కాబట్టి మేము దీనిని క్యూబ్ యొక్క అన్ని ముఖాల్లో జోడిస్తున్నట్లయితే, ఇది క్యూబ్ యొక్క ఉపరితల వైశాల్యానికి కొన్ని స్థిరమైన సార్లు సమానం అని మనం భావించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting.",
  "translatedText": "మరియు అది చాలా ఆసక్తికరంగా ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "translatedText": "ఈ క్యూబ్ యొక్క నీడ యొక్క సగటు వైశాల్యం దాని ఉపరితల వైశాల్యానికి అనులోమానుపాతంలో ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "translatedText": "కానీ అదే సమయంలో, మీరు ఫిర్యాదు చేయవచ్చు, బాగా ఆలిస్ ఇక్కడ చిహ్నాల సమూహాన్ని చుట్టుముడుతోంది, ఎందుకంటే ఆ అనుపాత స్థిరాంకం ఏమిటో మనకు తెలియకపోతే వీటిలో ఏదీ ముఖ్యమైనది కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious.",
  "translatedText": "నా ఉద్దేశ్యం, ఇది దాదాపు స్పష్టంగా కనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "translatedText": "ఉదాహరణకు, సగటు నీడ ప్రాంతం ఉపరితల వైశాల్యానికి అనులోమానుపాతంలో ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "translatedText": "అవి రెండూ రెండు డైమెన్షనల్ పరిమాణాలు, కాబట్టి అవి ఒకదానితో ఒకటి లాక్‌స్టెప్‌లో స్కేల్ చేయాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious.",
  "translatedText": "నా ఉద్దేశ్యం, ఇది స్పష్టంగా లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "translatedText": "అన్నింటికంటే, దగ్గరి కాంతి మూలం కోసం, ఇది నిజం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "translatedText": "అలాగే, మేము గ్రిడ్ కాలమ్‌ని నిలువు వరుసల వారీగా జోడించిన ఈ వ్యాపారం మొదట కనిపించే దానికంటే కొంచెం ఎక్కువ సూక్ష్మంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "translatedText": "వీటన్నింటికీ అంతర్లీనంగా ఒక నిగూఢమైన, దాగి ఉన్న ఊహ ఉంది, అన్ని ఓరియంటేషన్ల స్థలంలో ఏ సంభావ్యత పంపిణీని తీసుకుంటారు అనే ప్రశ్నను మళ్లీ సందర్శించాలని మేము ఎంచుకున్నప్పుడు ఇది ప్రత్యేక ప్రాముఖ్యతను కలిగి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "translatedText": "కానీ అన్నింటికంటే, ఇది స్పష్టంగా కనిపించకపోవడానికి కారణం ఏమిటంటే, ఇక్కడ ఈ ఫలితం యొక్క ప్రాముఖ్యత కేవలం ఈ రెండు విలువలు అనుపాతంలో ఉండటం మాత్రమే కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "translatedText": "ఏ కుంభాకార ఘనపదార్థాలకైనా సారూప్యమైన వాస్తవం నిజమైనది మరియు ముఖ్యంగా, ఆలిస్ ఇప్పటివరకు నిర్మించిన దాని యొక్క వాస్తవ కంటెంట్ ఏమిటంటే, వాటన్నింటిలో అదే అనుపాత స్థిరాంకం ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "translatedText": "ఇప్పుడు మీరు దాని గురించి నిజంగా ఆలోచిస్తే, మీలో కొందరు ఆలిస్ ఇక్కడి నుండి పనులను పూర్తి చేయగల విధానాన్ని అంచనా వేయగలరు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful.",
  "translatedText": "ఇది నిజంగా సంతోషకరమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1295.42
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "translatedText": "నిజాయితీగా ఈ అంశాన్ని కవర్ చేయడానికి ఇది నా ప్రధాన కారణం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1295.6,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "translatedText": "కానీ మనం దానిలోకి ప్రవేశించే ముందు, ఆమె ఏమి తప్పించుకుంటుందో అనే వివరాలను మనం త్రవ్వితే తప్ప, ఆమె ఫలితాన్ని తక్కువగా అంచనా వేయడం సులభం అని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "translatedText": "కాబట్టి మన దృష్టిని తిరిగి బాబ్ ప్రపంచంలోకి మళ్లించడానికి కొంత సమయం తీసుకుందాం, ఎందుకంటే ఆలిస్ ఇవన్నీ చేస్తున్నప్పుడు, అతను కొన్ని గణనలు చేయడంలో బిజీగా ఉన్నాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "translatedText": "వాస్తవానికి, అతను పని చేస్తున్నది ఏమిటంటే, ఆలిస్ ఇంకా గుర్తించాల్సిన వాటిని సరిగ్గా కనుగొనడం, అంటే చతురస్రం యొక్క నీడ యొక్క వైశాల్యం కోసం అతను కనుగొన్న సూత్రాన్ని ఎలా తీసుకోవాలి మరియు దాని సగటును కనుగొనే ప్రయత్నంలో సహజమైన తదుపరి దశను తీసుకోవడం. చతురస్రం యొక్క నీడ సాధ్యమయ్యే అన్ని ధోరణులపై సగటున ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "translatedText": "కాబట్టి బాబ్ ప్రారంభించే విధానం ఏమిటంటే, అతను ఈ స్క్వేర్ కోసం సాధ్యమయ్యే అన్ని విభిన్న ధోరణుల గురించి ఆలోచిస్తుంటే, ఆ చతురస్రం ఈ అన్ని ధోరణులలో కలిగి ఉండే విభిన్న సాధారణ వెక్టర్స్ ఏవి అని అడగడం, ఎందుకంటే దాని నీడ గురించి ప్రతిదీ సాధారణ స్థాయికి వస్తుంది. వెక్టర్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "translatedText": "సాధ్యమయ్యే అన్ని సాధారణ వెక్టార్‌లు గోళం యొక్క ఉపరితలం నుండి గుర్తించడాన్ని చూడటం చాలా కష్టం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1352.32
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "translatedText": "ఇది యూనిట్ సాధారణ వెక్టార్ అని మనం ఊహిస్తే, అది వ్యాసార్థం 1తో కూడిన గోళం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.32,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "translatedText": "ఇంకా, ఈ గోళంలోని ప్రతి బిందువు మరేదైనా సంభవించే అవకాశం ఉందని బాబ్ పేర్కొన్నాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "translatedText": "మన సంభావ్యత ఆ విధంగా ఏకరీతిగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1363.98
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "translatedText": "ఒక దిశ కంటే మరొక దిశను ఇష్టపడటానికి ఎటువంటి కారణం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1364.02,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "translatedText": "కానీ నిరంతర సంభావ్యత సందర్భంలో, ఒక నిర్దిష్ట వ్యక్తిగత పాయింట్ యొక్క సంభావ్యత గురించి మాట్లాడటం చాలా సహాయకారిగా ఉండదు, ఎందుకంటే గోళంపై పాయింట్ల యొక్క లెక్కించలేని అనంతంలో, అది సున్నా మరియు పనికిరానిది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "translatedText": "కాబట్టి బదులుగా, ఈ ఏకరూపతను పదబంధం చేయడానికి మరింత ఖచ్చితమైన మార్గం ఏమిటంటే, మన సాధారణ వెక్టర్ గోళంలోని ఏదైనా పాచ్‌లో ఆ ప్రాంతానికి అనులోమానుపాతంలో ఉండే సంభావ్యతను చెప్పడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "translatedText": "మరింత ప్రత్యేకంగా, ఇది గోళం యొక్క మొత్తం ఉపరితల వైశాల్యంతో విభజించబడిన చిన్న పాచ్ యొక్క వైశాల్యానికి సమానంగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "translatedText": "అది నిజమైతే, మేము ఏ ప్రాంతం యొక్క ప్యాచ్‌ని పరిశీలిస్తున్నామో, గోళంపై ఏకరీతి పంపిణీ అంటే అదే.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "translatedText": "ఇప్పుడు స్పష్టంగా చెప్పాలంటే, గోళంపై ఉన్న పాయింట్లు 3D స్పేస్‌లోని ఓరియంటేషన్‌ల మాదిరిగానే ఉండవు, ఎందుకంటే ఈ స్క్వేర్ ఏ సాధారణ వెక్టర్‌ను కలిగి ఉంటుందో మీకు తెలిసినప్పటికీ, అది మనకు మరొక స్థాయి స్వేచ్ఛను ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1411.7
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "translatedText": "చతురస్రాన్ని ఆ సాధారణ వెక్టర్ చుట్టూ తిప్పవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.9,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "translatedText": "కానీ బాబ్ వాస్తవానికి ఆ అదనపు స్వేచ్ఛ గురించి పట్టించుకోనవసరం లేదు, ఎందుకంటే ఆ సందర్భాలలో అన్నింటికీ, నీడ యొక్క ప్రాంతం ఒకే విధంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1422.0
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "translatedText": "ఇది సాధారణ వెక్టర్ మరియు నిలువు మధ్య కోణం యొక్క కొసైన్‌పై మాత్రమే ఆధారపడి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.36,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat.",
  "translatedText": "ఏ రకంగా చక్కగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1427.84
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "translatedText": "ఆ నీడలన్నీ నిజంగా భిన్నమైన ఆకారాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1428.0,
  "end": 1430.06
 },
 {
  "input": "They're not the same.",
  "translatedText": "అవి ఒకేలా ఉండవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.16,
  "end": 1430.9
 },
 {
  "input": "But the area of each of them will be the same.",
  "translatedText": "కానీ వాటిలో ప్రతి ప్రాంతం ఒకే విధంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.2,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "translatedText": "దీనర్థం ఏమిటంటే, బాబ్ ఈ సగటు నీడ ప్రాంతాన్ని సాధ్యమయ్యే అన్ని ధోరణులపై కోరుకున్నప్పుడు, అతను నిజంగా తెలుసుకోవలసినది తీటా యొక్క కొసైన్ యొక్క ఈ సంపూర్ణ విలువ యొక్క అన్ని విభిన్న సాధారణ వెక్టర్‌ల కోసం, గోళంలోని అన్ని విభిన్న సాధ్యమైన పాయింట్ల సగటు విలువ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this?",
  "translatedText": "కాబట్టి, మీరు ఇలాంటి సగటును ఎలా గణిస్తారు?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "translatedText": "సరే, మనం ఏదో ఒక రకమైన వివిక్త పిక్సలేటెడ్ ప్రపంచంలో నివసించినట్లయితే, ఆ సాధారణ వెక్టర్ కలిగి ఉండే పరిమిత సంఖ్యలో సాధ్యమయ్యే కోణాల తీటా మాత్రమే ఉంటే, సగటు చాలా సరళంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "translatedText": "మీరు చేసేది ఏమిటంటే, తీటా యొక్క ఏదైనా నిర్దిష్ట విలువపై ల్యాండింగ్ సంభావ్యతను కనుగొనడం, ఇది ఆ కోణంతో సాధారణ వెక్టర్‌లు ఎంత గోళాన్ని తయారు చేస్తాయో మాకు తెలియజేస్తుంది, ఆపై మీరు దానిని మనం సగటును తీసుకోవాలనుకుంటున్న అంశంతో గుణించాలి. యొక్క, నీడ యొక్క ప్రాంతం కోసం ఈ సూత్రం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "translatedText": "ఆపై మీరు 0 నుండి 180 డిగ్రీల వరకు లేదా pi రేడియన్‌ల వరకు ఉన్న తీటా యొక్క విభిన్న సాధ్యమైన విలువలన్నింటిపైగా జోడించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "translatedText": "వాస్తవానికి, వాస్తవానికి, తీటా యొక్క సాధ్యమైన విలువల యొక్క నిరంతరాయంగా ఉంది, ఈ లెక్కించలేని అనంతం మరియు తీటా యొక్క ఏదైనా నిర్దిష్ట నిర్దిష్ట విలువపై ల్యాండింగ్ సంభావ్యత వాస్తవానికి 0 అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "translatedText": "కాబట్టి దురదృష్టవశాత్తూ ఇలాంటి మొత్తానికి నిజంగా అర్థం లేదు, లేదా అది అర్థవంతంగా ఉంటే, అనంతమైన అనేక సున్నాలను జోడించడం వల్ల మనకు 0 ఇవ్వాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "translatedText": "బదులుగా మనం చేసేదానికి సంక్షిప్త సమాధానం ఏమిటంటే, మనం సమగ్రతను గణిస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "translatedText": "మరియు నేను మీతో సమం చేస్తాను, ఇక్కడ చాలా కష్టమైన భాగం ఏమిటంటే, ప్రస్తుతం చూస్తున్న మీలో నుండి నేను ఏ నేపథ్యాన్ని ఊహించాలనుకుంటున్నానో నాకు పూర్తిగా తెలియదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "translatedText": "బహుశా మీరు కాలిక్యులస్‌తో చాలా సౌకర్యంగా ఉన్నారు మరియు నేను ఇక్కడ పాయింట్‌ను చెప్పాల్సిన అవసరం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "translatedText": "బహుశా ఇది మీకు కాలిక్యులస్ గురించి తెలియకపోయి ఉండవచ్చు మరియు నేను అలాంటి సమగ్రాలను విసిరివేయకూడదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "translatedText": "లేదా మీరు కొంతకాలం క్రితం కాలిక్యులస్ క్లాస్ తీసుకున్నారేమో కానీ మీకు కొంచెం రిఫ్రెషర్ కావాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "translatedText": "నేను దీన్ని కాలిక్యులస్ పాఠం వలె సెటప్ చేసే ఎంపికతో వెళ్లబోతున్నాను, ఎందుకంటే నిజాయితీగా చెప్పాలంటే, మీరు ఇంటిగ్రల్స్‌తో చాలా సౌకర్యంగా ఉన్నప్పటికీ, వాటిని సెటప్ చేయడం అనేది ఒక రకమైన లోపానికి గురయ్యే ప్రక్రియ మరియు తిరిగి కాల్ చేయడం అంతర్లీన నిర్వచనం ప్రకారం, ప్రక్రియలో మిమ్మల్ని మీరు తనిఖీ చేసుకోవడానికి ఒక మంచి మార్గం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "translatedText": "కాలిక్యులస్ ఉనికిలో ఉండక ముందు మనం జీవించి ఉంటే మరియు ఇంటిగ్రల్స్ ఒక విషయం కాదు, మరియు మేము ఈ ప్రశ్నకు సుమారుగా సమాధానం చెప్పాలనుకుంటే, మేము దాని గురించి వెళ్ళడానికి ఒక మార్గం θ కోసం విలువల నమూనా 0 నుండి వరకు ఉంటుంది. 180°.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "translatedText": "మేము వాటిని ప్రతిదానికీ, కొంత డెల్టా θ మధ్య ఏదో ఒక విధమైన వ్యత్యాసంతో సమానంగా ఖాళీగా ఉన్నట్లు భావించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "translatedText": "మరియు అది మా నమూనాలో 1 అయినప్పటికీ, θ యొక్క నిర్దిష్ట విలువ సంభవించే సంభావ్యత గురించి అడగడం సహాయకరంగా ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "translatedText": "ఆ సంభావ్యత ఇప్పటికీ 0గా ఉంటుంది మరియు అది సహాయం చేయదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "translatedText": "డెల్టా θ వెడల్పుతో అక్షాంశం యొక్క ఈ చిన్న బ్యాండ్‌లో మా నమూనా నుండి రెండు వేర్వేరు విలువల మధ్య పడే సంభావ్యతను అడగడానికి సహాయకరంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "translatedText": "ఈ గోళం పొడవునా పంపిణీ ఏకరీతిగా ఉండాలనే మా ఊహ ఆధారంగా, ఆ సంభావ్యత ఈ బ్యాండ్ యొక్క వైశాల్యాన్ని తెలుసుకోవడం ద్వారా వస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "translatedText": "మరింత ప్రత్యేకంగా, ఆ బ్యాండ్‌లో యాదృచ్ఛికంగా ఎంచుకున్న వెక్టర్ ల్యాండ్ అయ్యే అవకాశాలు గోళం యొక్క మొత్తం ఉపరితల వైశాల్యంతో భాగించబడిన వైశాల్యం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "translatedText": "ఆ ప్రాంతాన్ని గుర్తించడానికి, ముందుగా ఆ బ్యాండ్ యొక్క వ్యాసార్థం గురించి ఆలోచిద్దాం, ఇది మన గోళం యొక్క వ్యాసార్థం 1 అయితే, ఖచ్చితంగా 1 కంటే చిన్నదిగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "translatedText": "వాస్తవానికి, మనం ఇక్కడ తగిన చిన్న లంబ త్రిభుజాన్ని గీస్తే, ఆ చిన్న వ్యాసార్థం, బ్యాండ్ పైభాగంలో చెప్పుకుందాం, మన కోణం యొక్క సైన్, θ యొక్క సైన్ ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "translatedText": "దీనర్థం బ్యాండ్ చుట్టుకొలత ఆ కోణం యొక్క సైన్ కంటే 2π రెట్లు ఉండాలి, ఆపై బ్యాండ్ యొక్క వైశాల్యం చుట్టుకొలత దాని మందం కంటే తక్కువ డెల్టా θ ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "translatedText": "లేదా బదులుగా, మా బ్యాండ్ యొక్క ప్రాంతం సుమారుగా ఈ పరిమాణంలో ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "translatedText": "ముఖ్యమైనది ఏమిటంటే, θ యొక్క మరిన్ని విలువల యొక్క సూక్ష్మ నమూనా కోసం, ఆ ఉజ్జాయింపు యొక్క ఖచ్చితత్వం మెరుగ్గా మరియు మెరుగ్గా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "translatedText": "ఇప్పుడు గుర్తుంచుకోండి, మేము ఈ ప్రాంతాన్ని కోరుకునే కారణం ఆ బ్యాండ్‌లో పడే సంభావ్యతను తెలుసుకోవడమే, ఇది గోళం యొక్క ఉపరితల వైశాల్యంతో భాగించబడిన ఈ ప్రాంతం, దాని వ్యాసార్థం స్క్వేర్డ్‌కు 4π రెట్లు ఎక్కువ అని మనకు తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "translatedText": "ఇది మేము ఇప్పుడు సెటప్ చేస్తున్న దానితో సమానమైన సమగ్రంతో మీరు గణించగల విలువ, కానీ ప్రస్తుతానికి మేము దానిని ప్రామాణికమైన ప్రసిద్ధ ఫార్ములాగా తీసుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "translatedText": "మరియు ఈ సంభావ్యత మనకు వాస్తవానికి కావలసిన దిశలో ఒక మెట్టు మాత్రమే, ఇది చదరపు నీడకు సగటు ప్రాంతం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "translatedText": "దాన్ని పొందడానికి, మేము ఈ సంభావ్యతను సంబంధిత నీడ ప్రాంతం కంటే గుణిస్తాము, ఇది మేము ఇప్పటివరకు చాలాసార్లు చూసిన cosθ వ్యక్తీకరణ యొక్క ఈ సంపూర్ణ విలువ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "translatedText": "మరియు ఈ సగటు కోసం మా అంచనా ఇప్పుడు వివిధ బ్యాండ్‌లన్నింటిలో, మేము తీసుకున్న θ యొక్క విభిన్న నమూనాలన్నింటిలో ఈ వ్యక్తీకరణను జోడించడం వరకు వస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "translatedText": "ఇది ఇక్కడే, బాబ్ తన మూలకంలో పూర్తిగా ఉన్నప్పుడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "translatedText": "మేము చాలా నిర్దిష్టమైనదాన్ని వివరించే చాలా ఖచ్చితమైన సూత్రాలను కలిగి ఉన్నాము, వాస్తవానికి నిజమైన సమాధానం కోసం మా మార్గంలో త్రవ్వడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "translatedText": "మరలా, ఇది చాలా వివరంగా అనిపిస్తే, మీరు ఆ వాస్తవాన్ని అభినందించాలని నేను కోరుకుంటున్నాను, తద్వారా ఆలిస్ వీటన్నింటిని ఎలాగైనా నివారించగలిగినప్పుడు అది ఎంత అద్భుతంగా ఉందో మీరు అభినందించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "translatedText": "ఏది ఏమైనప్పటికీ, మన వ్యక్తీకరణను తిరిగి చూస్తే, θపై ఆధారపడని అన్ని నిబంధనలను కారకాలుగా మార్చడం వంటి విషయాలను కొంచెం క్లీన్ చేద్దాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "translatedText": "మరియు మనం 2πని 4πతో భాగించడాన్ని 1 సగానికి సులభతరం చేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "translatedText": "మరియు దానిని కాలిక్యులస్‌కి కొంచెం సారూప్యంగా చేయడానికి, ఇంటిగ్రల్స్‌తో, ఇక్కడ మొత్తం లోపల ఉన్న ప్రధాన నిబంధనలను మార్చుకుంటాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "translatedText": "ఇప్పుడు మన దగ్గర ఉన్నది, ఈ మొత్తం మన ప్రశ్నకు సుమారుగా సమాధానం ఇవ్వబడుతుంది, ఇది దాదాపుగా సమగ్రమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "translatedText": "మొత్తానికి సిగ్మాను వ్రాయడానికి బదులుగా, మేము 0 నుండి πకి వెళ్తున్నామని చూపిస్తూ, ఈ రకమైన పొడుగుచేసిన లైబ్నిజియన్ s అనే సమగ్ర చిహ్నాన్ని వ్రాస్తాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "translatedText": "మరియు దశల పరిమాణాన్ని δθ, కాంక్రీట్ పరిమిత మొత్తంగా వివరించే బదులు, మేము దానిని dθగా వర్ణిస్తాము, ఇది ఒక రకమైన పరిమితి తీసుకోబడుతుందనే వాస్తవాన్ని సూచిస్తుందని నేను భావించాలనుకుంటున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "translatedText": "ఆ సమగ్రత అంటే, నిర్వచనం ప్రకారం, సూక్ష్మమైన మరియు సూక్ష్మమైన ఉపవిభాగాల కోసం దిగువన ఉన్న మొత్తమేదైనా, θ కోసం మనం తీసుకునే మరింత దట్టమైన నమూనాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "translatedText": "మరియు ఈ సమయంలో, మీలో కాలిక్యులస్ తెలిసిన వారి కోసం, మీరు దీన్ని బాబ్ నోట్‌బుక్‌లో వ్రాసి ఉంచినట్లు మీరు దీన్ని ఎలా నిర్వహిస్తారు అనే వివరాలను నేను వ్రాస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "translatedText": "ఇది సాధారణ యాంటీ-డెరివేటివ్ అంశాలు, కానీ ఒక నిర్దిష్ట ట్రిగ్ గుర్తింపును తీసుకురావడం ఒక ముఖ్య దశ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "translatedText": "చివరికి, బాబ్ దీన్ని చేసిన తర్వాత కనుగొన్నది ఏమిటంటే, ఒక చతురస్రం యొక్క నీడ యొక్క సగటు వైశాల్యం ఖచ్చితంగా ఆ చతురస్రంలోని సగం వైశాల్యం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "translatedText": "ఇది మిస్టరీ స్థిరాంకం, ఇది ఆలిస్‌కి ఇంకా తెలియదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "translatedText": "బాబ్ ఆమె భుజం మీదుగా చూస్తూ, ఆమె చేసిన పనిని చూస్తే, అతను ఇప్పుడే సమస్యను ముగించగలడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "translatedText": "అతను ఇప్పుడే కనుగొన్న స్థిరాంకాన్ని ప్లగ్ చేస్తాడు మరియు చివరి సమాధానం అతనికి తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "translatedText": "ఇప్పుడు, చివరగా, వీటన్నిటి నేపథ్యంతో, ఆలిస్ తుది పరిష్కారాన్ని చేపట్టడానికి ఏమి చేస్తుంది?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "translatedText": "ఆమె కనుగొన్న ఫలితాలను సాధారణీకరించడానికి నిజంగా ఇష్టపడే వ్యక్తిగా నేను ఆమెను పరిచయం చేసాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "translatedText": "మరియు సాధారణంగా ఆ సాధారణీకరణలు ఆసక్తికరమైన ఫుట్‌నోట్‌లుగా ముగుస్తాయి, అవి నిర్దిష్ట సమస్యలను పరిష్కరించడానికి నిజంగా పదార్థం కావు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "translatedText": "కానీ సాధారణీకరణ ఆమెను పరిమాణాత్మక ఫలితానికి ఆకర్షిస్తున్న సందర్భం ఇది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "translatedText": "గుర్తుంచుకోండి, ఆమె ఇప్పటివరకు కనుగొన్న దానిలోని పదార్ధం ఏమిటంటే, మీరు ఏదైనా కుంభాకార ఘనాన్ని చూస్తే, దాని నీడ యొక్క సగటు వైశాల్యం దాని ఉపరితల వైశాల్యానికి అనులోమానుపాతంలో ఉంటుంది మరియు విమర్శనాత్మకంగా, ఇది అన్నింటిలో ఒకే నిష్పత్తిలో స్థిరంగా ఉంటుంది ఈ ఘనపదార్థాల.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "translatedText": "కాబట్టి ఆలిస్ చేయాల్సిందల్లా కేవలం ఒక కుంభాకార ఘనాన్ని కనుగొనడమే, అక్కడ ఆమెకు దాని నీడ యొక్క సగటు ప్రాంతం ఇప్పటికే తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going.",
  "translatedText": "మరియు ఇది ఎక్కడికి వెళుతుందో మీలో కొందరు చూడవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "translatedText": "మనకు అందుబాటులో ఉన్న అత్యంత సుష్ట ఘనపదార్థం గోళం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "translatedText": "ఆ గోళం యొక్క దిశ ఎలా ఉన్నా, దాని నీడ, ఫ్లాట్ ప్రొజెక్షన్ నీడ, ఎల్లప్పుడూ πr² వైశాల్యంతో ఒక వృత్తం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "translatedText": "కాబట్టి ముఖ్యంగా, అది దాని సగటు నీడ ప్రాంతం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "translatedText": "మరియు ఒక గోళం యొక్క ఉపరితల వైశాల్యం, నేను ముందు చెప్పినట్లుగా, సరిగ్గా 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "translatedText": "మార్గం ద్వారా, నేను ఆ ఉపరితల వైశాల్య సూత్రం గురించి మరియు కాలిక్యులస్ ఉనికికి వేల సంవత్సరాల ముందు ఆర్కిమెడిస్ దానిని ఎలా నిరూపించాడు అనే దాని గురించి మాట్లాడే వీడియోను రూపొందించాను, కాబట్టి దాన్ని కనుగొనడానికి మీకు సమగ్రతలు అవసరం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "translatedText": "ఆలిస్ చేసిన మాయాజాలం ఏమిటంటే, గోళం యొక్క నీడ దాని ఉపరితల వైశాల్యం సరిగ్గా 1⁄4 విస్తీర్ణం కలిగి ఉంటుంది, మరియు ఏదైనా కుంభాకార ఘనం కోసం మరింత సాధారణ వాస్తవాన్ని నిర్ధారించడానికి ఆమె ఈ అకారణంగా నిర్దిష్ట వాస్తవాన్ని తీసుకోగలదు. అక్కడ, దాని నీడ మరియు ఉపరితల వైశాల్యం ఒక నిర్దిష్ట కోణంలో ఒకే విధంగా ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "translatedText": "కాబట్టి దానితో, ఆమె వెళ్లి ఒక క్యూబ్ గురించి నిర్దిష్ట ప్రశ్న యొక్క వివరాలను పూరించవచ్చు మరియు దాని సగటు నీడ వైశాల్యం దాని ఉపరితల వైశాల్యం 6s² కంటే 1⁄4 రెట్లు ఉంటుందని చెప్పవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "translatedText": "కానీ మీరు ఆలోచించడం వల్ల మీరు నిద్రపోతారనేది మరింత గుర్తుండిపోయే వాస్తవం ఏమిటంటే, మేము ఒక క్యూబ్ గురించి మాట్లాడుతున్నాము అనేది నిజంగా పట్టింపు లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "translatedText": "ఇప్పుడు, అదంతా చాలా అందంగా ఉంది, కానీ మీలో కొందరు ఇది నిజంగా చెల్లుబాటు అయ్యే వాదన కాదని ఫిర్యాదు చేయవచ్చు, ఎందుకంటే గోళాలకు చదునైన ముఖాలు లేవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "translatedText": "ఆలిస్ యొక్క వాదన ఏదైనా కుంభాకార ఘనానికి సాధారణీకరిస్తుంది అని నేను చెప్పినప్పుడు, వాస్తవానికి మనం వాదనను పరిశీలిస్తే, అది ఖచ్చితంగా పరిమిత సంఖ్యలో ఫ్లాట్ ముఖాల ఉపయోగంపై ఆధారపడి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "translatedText": "ఉదాహరణకు, మేము దానిని డోడెకాహెడ్రాన్‌కు మ్యాప్ చేస్తుంటే, ఆ డోడెకాహెడ్రాన్ యొక్క నిర్దిష్ట నీడ యొక్క వైశాల్యం దాని అన్ని ముఖాల నీడల ప్రాంతాల మొత్తానికి సరిగ్గా 1⁄2 రెట్లు ఉన్నట్లు చెప్పడం ద్వారా మీరు ప్రారంభిస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "translatedText": "మరోసారి, మీరు ఆ తీర్మానాన్ని రూపొందించడానికి కుంభాకార వాదనతో కలిపిన నిర్దిష్ట కాంతి కిరణాన్ని ఉపయోగించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "translatedText": "మరియు గుర్తుంచుకోండి, ఆ నీడ ప్రాంతాన్ని మొత్తంగా వ్యక్తీకరించడం వల్ల కలిగే ప్రయోజనం ఏమిటంటే, మనం వేర్వేరు భ్రమణాల సమూహానికి సగటున కావాలనుకున్నప్పుడు, ఆ మొత్తాన్ని పెద్ద గ్రిడ్‌గా వర్ణించవచ్చు, ఇక్కడ మనం కాలమ్ వారీగా వెళ్లి సగటు ప్రాంతాన్ని పరిగణించవచ్చు. ప్రతి ముఖం యొక్క నీడ కోసం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "translatedText": "ఇంకా, ఒక క్లిష్టమైన వాస్తవం ఏమిటంటే, ఏదైనా 2D వస్తువు యొక్క సగటు నీడ, ఒక ఫ్లాట్ 2D వస్తువు, ముఖ్యమైనది, కొంత సార్వత్రిక అనుపాత స్థిరాంకం దాని వైశాల్యానికి సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "translatedText": "ప్రాముఖ్యత ఏమిటంటే ఆ స్థిరాంకం ఆకారంపైనే ఆధారపడి ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "translatedText": "అది ఒక చతురస్రం కావచ్చు, లేదా పిల్లి కావచ్చు లేదా మన డోడెకాహెడ్రాన్ యొక్క పెంటగోనల్ ముఖాలు ఏమైనా కావచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "translatedText": "కాబట్టి, పరిమిత సంఖ్యలో చదునైన ముఖాలు లేని గోళానికి దీన్ని త్వరగా తీసుకెళ్లిన తర్వాత, మీరు ఫిర్యాదు చేయడం సరైనదే.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "translatedText": "కానీ అదృష్టవశాత్తూ, ఇది పూరించడానికి చాలా సులభమైన వివరాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "translatedText": "మీరు చేయగలిగేది ఏమిటంటే, ఒక గోళాన్ని వరుసగా అంచనా వేసే విభిన్న పాలిహెడ్రా క్రమాన్ని ఊహించుకోండి, ఆ కోణంలో వారి ముఖాలు గోళం యొక్క నిజమైన ఉపరితలం చుట్టూ గట్టిగా మరియు గట్టిగా కౌగిలించుకుంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "translatedText": "ఆ ఉజ్జాయింపులలో ప్రతి ఒక్కదానికి, ఈ సార్వత్రిక అనుపాత స్థిరాంకంతో దాని సగటు నీడ దాని ఉపరితల వైశాల్యానికి అనులోమానుపాతంలో ఉంటుందని మనం ఒకే నిర్ధారణకు రావచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "translatedText": "కాబట్టి, మనం సరే అని చెబితే, ప్రతి అడుగు వద్ద సగటు నీడ వైశాల్యం మరియు ప్రతి అడుగు వద్ద ఉన్న ఉపరితల వైశాల్యం మధ్య నిష్పత్తి యొక్క పరిమితిని తీసుకుందాం, సరే, ఆ నిష్పత్తి ఎప్పుడూ మారదు కాబట్టి, ఇది ఎల్లప్పుడూ ఈ స్థిరాంకానికి సమానంగా ఉంటుంది. పరిమితి, అది కూడా స్థిరంగా సమానం కానుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "translatedText": "కానీ మరోవైపు, వారి నిర్వచనం ప్రకారం, పరిమితిలో, వాటి సగటు నీడ వైశాల్యం వృత్తాకారంగా ఉండాలి, ఇది πr², మరియు ఉపరితల ప్రాంతాల పరిమితి గోళం యొక్క ఉపరితల వైశాల్యం, 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "translatedText": "కాబట్టి మేము అంతర్ దృష్టిని సూచించే ముగింపును నిజంగా పొందుతాము, కానీ, ఇక్కడ ఆలిస్ వాదనలో చాలా సాధారణం, మేము ఆ అంతర్ దృష్టిని ఎలా సమర్థిస్తాము అనే విషయంలో కొంచెం సున్నితంగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "translatedText": "ఆలిస్ మరియు బాబ్‌ల యొక్క ఈ వ్యత్యాసాన్ని ఒక వాల్యూ జడ్జిమెంట్ లాగా చూడటం చాలా సులభం, నేను చెబుతున్నట్లుగా, ఆలిస్ ఎంత తెలివిగా వ్యవహరించిందో చూడండి, బాబ్ చేయాల్సిన అన్ని గణనలను ఆమె తెలివిగా తప్పించింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "translatedText": "కానీ అది చాలా, ఉమ్, తప్పుదారి పట్టించే ముగింపు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "translatedText": "నిజానికి గణితాన్ని చేస్తున్న అనుభూతికి భిన్నంగా గణితానికి సంబంధించిన జనాదరణకు భిన్నమైన మార్గం ఉందని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "translatedText": "వివేకవంతమైన రుజువులను చూపడంలో ఈ పక్షపాతం ఉంది, మీరు లెక్కలు చేయకుండా ఉండేందుకు మిమ్మల్ని అనుమతించే కొన్ని తెలివైన తెలివైన అంతర్దృష్టితో వాదనలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "translatedText": "నేను ఈ విషయంలో చాలా దోషిగా ఉన్నాను కాబట్టి నేను ప్రొజెక్ట్ చేయగలను, కానీ ఇక్కడ స్క్రీన్‌కి అవతలి వైపు కూర్చొని నేను మీకు చెప్పగలిగేది ఏమిటంటే, బాబ్ కంటే ఆలిస్ విధానం గురించి వీడియో చేయడం చాలా ఆకర్షణీయంగా అనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "translatedText": "ఒక విషయం ఏమిటంటే, ఆలిస్ యొక్క విధానంలో, తార్కికం యొక్క లైన్ సరదాగా ఉంటుంది, ఇందులో ఈ మంచి ఆహా క్షణాలు ఉన్నాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "translatedText": "కానీ, ముఖ్యంగా, మీరు దానిని వివరించే విధానం చాలా విస్తృతమైన గణిత నేపథ్యాలకు ఎక్కువ లేదా తక్కువగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "translatedText": "బాబ్ యొక్క విధానం గురించి వీడియో చేయడం చాలా తక్కువ ఆకర్షణీయంగా ఉంది, ఎందుకంటే గణనలు అంత చెడ్డవి కావు, నా ఉద్దేశ్యం, అవి నిజాయితీగా లేవు, కానీ ఆచరణాత్మక వాస్తవికత ఏమిటంటే, విభిన్న గణితశాస్త్రాన్ని బట్టి దానిని వివరించడానికి తగిన వేగం చాలా భిన్నంగా కనిపిస్తుంది. ప్రేక్షకులలో నేపథ్యాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "translatedText": "కాబట్టి, మీరు ప్రస్తుతం దీన్ని చూస్తున్నారు, ఆన్‌లైన్‌లో గణిత వీడియోలను స్పష్టంగా వినియోగిస్తారు మరియు అలా చేయడం వల్ల ఈ పక్షపాతం గురించి తెలుసుకోవడం విలువైనదని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "translatedText": "సమస్య పరిష్కారంపై నిజమైన పాఠాన్ని కలిగి ఉండటమే లక్ష్యం అయితే, వివేక ప్రూఫ్‌లపై ఎక్కువ దృష్టి పెట్టడం అనేది అసహజంగా ఉండే ప్రమాదం ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "translatedText": "ఉదాహరణకు, మేము ఇక్కడ ఛాలెంజ్ మోడ్‌ను ప్రారంభించి, దగ్గరి కాంతి వనరుతో కేసు గురించి అడగాలని అనుకుందాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "translatedText": "నాకు తెలిసినట్లుగా, ఇక్కడ ఆలిస్‌కి సారూప్యమైన పరిష్కారం లేదు, ఇక్కడ మీరు గోళం వంటి ఒకే ఆకారంతో సంబంధం కలిగి ఉంటారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "translatedText": "మరింత ఉత్పాదకమైన వార్మప్ చేయాలంటే బాబ్ యొక్క విధానం యొక్క కాలిక్యులస్ అయి ఉండేది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "translatedText": "మరియు మీరు ఈ సమస్య యొక్క చరిత్రను పరిశీలిస్తే, ఇది 1832లో కౌచీచే నిరూపించబడింది మరియు మేము అతని చేతితో వ్రాసిన గమనికలను పరిశీలిస్తే, అవి ఆలిస్ యొక్క పని కంటే బాబ్ యొక్క పనిని పోలి ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "translatedText": "ఇక్కడ 11వ పేజీ ఎగువన, మీరు మరియు నేను మధ్యలో సెటప్ చేసిన అదే సమగ్రతను మీరు చూడవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "translatedText": "మరోవైపు, కాగితం యొక్క మొత్తం ఫ్రేమింగ్ ఒక సాధారణ వాస్తవాన్ని కనుగొనడం, క్యూబ్ కేసు వంటి నిర్దిష్టమైనది కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "translatedText": "కాబట్టి ఈ రెండు మనస్తత్వాలలో ఏది కొత్త గణితాన్ని కనుగొనే చర్యతో పరస్పర సంబంధం కలిగి ఉంటుంది అనే ప్రశ్నను మనం అడుగుతున్నట్లయితే, సరైన సమాధానం దాదాపు ఖచ్చితంగా రెండింటి కలయికగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "translatedText": "కానీ మీరు గణనలలోకి ప్రవేశించడానికి ఆసక్తిగా ఉన్న మిశ్రమం యొక్క భాగానికి చాలా మంది వ్యక్తులు తగినంత బరువును సంతకం చేయరని నేను సూచిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "translatedText": "మరియు నేను రూపొందించే వీడియోలు దానికి దోహదం చేసే ప్రమాదం ఉందని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "translatedText": "నేను గణిత శాస్త్రజ్ఞుడు అలెక్స్ కొంటోరోవిచ్‌తో కలిసి చేసిన పోడ్‌కాస్ట్‌లో, మీరు కొత్త తరగతితో నిమగ్నమయ్యే విద్యార్థి అయినా, లేదా కొత్త రంగంలో నిమగ్నమై ఉన్న పరిశోధనా గణిత శాస్త్రజ్ఞుడైనా, అంతర్ దృష్టిని పెంపొందించడానికి గణనలపై డ్రిల్లింగ్ చేయడం యొక్క తరచుగా తక్కువగా అంచనా వేయబడని ప్రాముఖ్యత గురించి మాట్లాడాడు. చదువు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "translatedText": "ఒక శ్రోత నిజానికి నిర్దిష్ట విభాగం ఎలాంటి అభిప్రాయాన్ని కలిగించిందో హైలైట్ చేయడానికి వ్రాసాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "translatedText": "వారు పిహెచ్‌డి విద్యార్థి మరియు వారి గణిత సామర్థ్యాలు మసకబారడం ప్రారంభిస్తున్నాయని తమను తాము ఆందోళన చెందుతున్నట్లు వివరిస్తున్నారు, ఇది వారు పెద్దవయ్యారని మరియు తక్కువ పదునుగా మారడానికి కారణమని పేర్కొన్నారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "translatedText": "కానీ ఒక అభ్యాసం చేస్తున్న గణిత శాస్త్రజ్ఞుడు క్రొత్తదాన్ని నేర్చుకోవడానికి వందలాది నిర్దిష్ట ఉదాహరణలను చేయడం యొక్క ప్రాముఖ్యత గురించి మాట్లాడటం వింటుంది, స్పష్టంగా అది వారి దృక్పథాన్ని మార్చింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "translatedText": "వారి స్వంత మాటలలో, దీనిని గుర్తించడం వారి దృక్పథాన్ని మరియు వారి ఫలితాలను పూర్తిగా మార్చింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "translatedText": "మరియు మీరు చరిత్ర ద్వారా ప్రసిద్ధ గణిత శాస్త్రజ్ఞులను పరిశీలిస్తే, న్యూటన్, ఆయిలర్, గాస్, వీళ్లందరినీ చూస్తే, వారంతా దుర్భరమైన లెక్కలు చేయడానికి ఈ అంతులేని సహనం కలిగి ఉంటారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "translatedText": "గణనలను నివారించే అంతర్దృష్టులను చూపడానికి పక్షపాతంతో వ్యవహరించడం యొక్క వ్యంగ్యం ఏమిటంటే, ఆ అంతర్దృష్టులను మొదట కనుగొనడానికి ప్రజలు తరచుగా అంతర్ దృష్టికి శిక్షణ ఇచ్చే విధానం కుప్పలు మరియు గణనలను చేయడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "translatedText": "ఇక్కడ ఆలిస్ మనస్తత్వం లేకుండా ఖచ్చితంగా ఏదో మిస్ అవుతుందని చెప్పబడింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "translatedText": "నా ఉద్దేశ్యం, దాని గురించి ఆలోచించండి, మనం ఒక క్యూబ్ కోసం ఈ సమస్యను పరిష్కరిస్తే ఎంత బాధగా ఉంటుందో, మరియు అడవిని చూడటానికి మరియు ఇది చాలా సాధారణ వాస్తవం అని అర్థం చేసుకోవడానికి చెట్ల నుండి బయటకి అడుగు పెట్టలేదు, ఇది చాలా పెద్ద కుటుంబానికి వర్తిస్తుంది. ఆకారాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "translatedText": "మరియు గణితమంటే కేవలం మీకు ఎదురయ్యే ప్రశ్నలకు సమాధానమివ్వడమే కాదు, కొత్త ఆలోచనలు మరియు నిర్మాణాలను పరిచయం చేయడమే అని మీరు భావిస్తే, ఇక్కడ ఆలిస్ యొక్క విధానం గురించి ఒక ఆహ్లాదకరమైన సైడ్ నోట్ ఏమిటంటే ఇది కుంభాకార ఆలోచనను లెక్కించడానికి ఒక ఆహ్లాదకరమైన మార్గాన్ని సూచిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "translatedText": "కేవలం అవును-కాదు అని సమాధానం ఇవ్వకుండా, అది కుంభాకారంగా ఉందా, కాదా, మనం దానికి ఒక సంఖ్యను ఉంచవచ్చు, కొంత ఘనపు నీడ యొక్క సగటు వైశాల్యాన్ని పరిగణించండి, దానిని 4తో గుణించి, ఉపరితల వైశాల్యంతో భాగించండి , మరియు ఆ సంఖ్య 1 అయితే, మీరు ఒక కుంభాకార ఘనతను కలిగి ఉంటారు, కానీ అది 1 కంటే తక్కువ ఉంటే, అది కుంభాకారం కానిది మరియు 1కి ఎంత దగ్గరగా ఉందో అది కుంభాకారంగా ఉండటానికి ఎంత దగ్గరగా ఉందో మీకు తెలియజేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "translatedText": "అలాగే, ఇక్కడ ఆలిస్ సొల్యూషన్ గురించిన ఒక మంచి విషయం ఏమిటంటే, గణిత శాస్త్రజ్ఞులు కొన్నిసార్లు సాధారణతతో మరియు సంగ్రహణతో విచిత్రమైన వ్యామోహం లాగా ఎందుకు కనిపిస్తారో వివరించడంలో సహాయపడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "translatedText": "సాధారణీకరించడం మరియు సంగ్రహించడం అనేది ఒక నిర్దిష్ట కేసును పరిష్కరించడానికి మీకు సహాయపడే మరిన్ని ఉదాహరణలు, మీరు అదే మోహాన్ని మరింత ఎక్కువగా స్వీకరించడం ప్రారంభిస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "translatedText": "మరియు ఇంతవరకు దాని ద్వారా నిలిచిపోయిన మీలో ఉన్న దృఢమైన వీక్షకుల కోసం చివరి ఆలోచనగా, మా పజిల్ యొక్క ఆవరణ గురించి ఇప్పటికీ ఒక సమాధానం లేని ప్రశ్న ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "translatedText": "యాదృచ్ఛిక ధోరణిని ఎంచుకోవడం అంటే ఏమిటి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "translatedText": "ఇప్పుడు అది ఒక వెర్రి ప్రశ్నగా అనిపిస్తే, దాని అర్థం ఏమిటో మాకు తెలుసు, బెర్ట్రాండ్ యొక్క పారడాక్స్ అని పిలువబడే సంభావ్యత నుండి తికమక పెట్టే సమస్యపై నేను నంబర్‌ఫైల్‌తో చేసిన వీడియోను చూడమని మిమ్మల్ని ప్రోత్సహిస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "translatedText": "మీరు దీన్ని వీక్షించిన తర్వాత, మరియు ఇక్కడ జరుగుతున్న కొన్ని సూక్ష్మ నైపుణ్యాలను మీరు అభినందిస్తే, ఆలిస్ మరియు బాబ్ ఈ ప్రశ్నకు పరోక్షంగా ఎక్కడ సమాధానమిచ్చారో ఆలోచించడం మీ కోసం హోంవర్క్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "translatedText": "బాబ్ కేసు సాపేక్షంగా సూటిగా ఉంటుంది, అయితే ఆలిస్ అన్ని ఓరియంటేషన్ల స్థలంపై నిర్దిష్ట పంపిణీని లాక్ చేసే పాయింట్, ఇది స్పష్టంగా లేదు, వాస్తవానికి ఇది చాలా సూక్ష్మమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2381.7
 }
]