[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "model": "nmt",
  "translatedText": "Tra poco vi parlerò di un certo enigma davvero carino che coinvolge l'ombra di un cubo.",
  "time_range": [
   0.0,
   4.3
  ]
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "model": "nmt",
  "translatedText": "Ma prima di arrivare a questo, dovrei dire che il punto di questo video non è esattamente il puzzle in sé, ma riguarda due distinti stili di risoluzione dei problemi che si riflettono in due modi diversi in cui possiamo affrontare questo problema.",
  "time_range": [
   5.0,
   15.24
  ]
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "model": "nmt",
  "translatedText": "Infatti, antropomorfizziamo questi due stili diversi immaginando due studenti, Alice e Bob, che incarnano ciascuno degli approcci.",
  "time_range": [
   15.78,
   22.7
  ]
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "model": "nmt",
  "translatedText": "Quindi Bob sarà il tipo di studente che ama davvero il calcolo.",
  "time_range": [
   23.5,
   26.98
  ]
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "model": "nmt",
  "translatedText": "Non appena c'è un momento in cui riesce a scavare nei dettagli e ad avere una visione molto concreta della situazione concreta che ha di fronte, è lì che è più contento.",
  "time_range": [
   26.98,
   34.34
  ]
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "model": "nmt",
  "translatedText": "Alice, invece, è più portata a procrastinare i calcoli, non perché non sappia farli o non voglia farlo di per sé, ma preferisce avere una bella panoramica generale di alto livello del genere del problema che sta affrontando, la forma generale che ha, prima di approfondire i calcoli stessi.",
  "time_range": [
   35.12,
   51.36
  ]
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "model": "nmt",
  "translatedText": "È molto contenta se capisce non solo la domanda specifica che le sta di fronte, ma anche il modo più ampio possibile di generalizzarla, e soprattutto se la visione più generale può prestarsi a calcoli più rapidi ed eleganti, una volta che lo fa effettivamente. sedersi per eseguirli.",
  "time_range": [
   52.16,
   66.94
  ]
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "model": "nmt",
  "translatedText": "Ora il puzzle che dovranno affrontare entrambi sarà trovare l'area media dell'ombra di un cubo.",
  "time_range": [
   73.02,
   79.14
  ]
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "model": "nmt",
  "translatedText": "Quindi, se ho un cubo seduto qui sospeso nello spazio, ci sono alcune cose che influenzano l'area della sua ombra.",
  "time_range": [
   79.9,
   85.46
  ]
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "model": "nmt",
  "translatedText": "Uno ovvio sarebbe la dimensione del cubo, cubo più piccolo, ombra più piccola.",
  "time_range": [
   85.46,
   89.26
  ]
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "model": "nmt",
  "translatedText": "Ma anche se si trova con orientamenti diversi, tali orientamenti corrispondono a ombre particolari diverse con aree diverse.",
  "time_range": [
   89.88,
   96.16
  ]
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "model": "nmt",
  "translatedText": "E quando dico di trovare la media qui, intendo la media su tutti i possibili orientamenti per una particolare dimensione del cubo.",
  "time_range": [
   96.78,
   103.1
  ]
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "model": "nmt",
  "translatedText": "I più astuti tra voi potrebbero sottolineare che è molto importante anche dove si trova la fonte di luce.",
  "time_range": [
   104.42,
   108.1
  ]
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "model": "nmt",
  "translatedText": "Se la fonte di luce fosse molto bassa, vicina al cubo stesso, l'ombra risulterà più grande.",
  "time_range": [
   108.36,
   112.66
  ]
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "model": "nmt",
  "translatedText": "E se la fonte di luce fosse posizionata lateralmente, ciò potrebbe distorcere l'ombra e darle una forma molto diversa.",
  "time_range": [
   112.66,
   118.56
  ]
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "model": "nmt",
  "translatedText": "Tenere conto della posizione della luce è di per sé molto interessante, ma il puzzle è già abbastanza difficile così com'è, quindi almeno inizialmente, facciamo la cosa più semplice che possiamo e diciamo che la luce è direttamente sopra il cubo e molto lontana di distanza, effettivamente infinitamente lontano, quindi tutto ciò che stiamo considerando è una proiezione piatta, nel senso che se guardi qualsiasi coordinata, x, y, z, nello spazio, la proiezione piatta sarebbe x, y, 0.",
  "time_range": [
   119.26,
   141.7
  ]
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "model": "nmt",
  "translatedText": "Quindi, tanto per orientarci, la situazione più semplice a cui pensare sarebbe se il cubo fosse dritto verso l'alto, con due facce parallele al suolo.",
  "time_range": [
   142.48,
   149.28
  ]
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "model": "nmt",
  "translatedText": "In tal caso, l'ombra di proiezione piatta è semplicemente un quadrato, e se diciamo che le lunghezze dei lati del cubo sono s, allora l'area di quell'ombra è s al quadrato.",
  "time_range": [
   149.92,
   157.9
  ]
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "model": "nmt",
  "translatedText": "E comunque, ogni volta che ho un'etichetta su queste animazioni, come quella qui sotto, presumo che il cubo in questione abbia una lunghezza del lato pari a 1.",
  "time_range": [
   158.74,
   165.46
  ]
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "model": "nmt",
  "translatedText": "Ora, un altro caso speciale tra tutti gli orientamenti a cui è divertente pensare è se la lunga diagonale è parallela alla direzione della luce.",
  "time_range": [
   166.24,
   173.04
  ]
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "model": "nmt",
  "translatedText": "In tal caso, l'ombra appare effettivamente come un esagono regolare e, se si utilizzano alcuni dei metodi che svilupperemo tra qualche minuto, è possibile calcolare che l'area di quell'ombra è esattamente la radice quadrata di 3 volte l'area di una delle facce quadrate.",
  "time_range": [
   173.6,
   185.82
  ]
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "model": "nmt",
  "translatedText": "Ma ovviamente, molto spesso, l'ombra reale non sarà così regolare come un quadrato o un esagono.",
  "time_range": [
   186.66,
   191.2
  ]
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "model": "nmt",
  "translatedText": "È un po' più difficile pensare alla forma in base ad un po' più difficile pensare all'orientamento di questo cubo.",
  "time_range": [
   191.66,
   196.24
  ]
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "model": "nmt",
  "translatedText": "In precedenza, ho buttato lì con nonchalance questa frase di media su tutti gli orientamenti possibili, ma potresti giustamente chiederti, cosa dovrebbe significare esattamente?",
  "time_range": [
   197.06,
   205.3
  ]
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "model": "nmt",
  "translatedText": "Penso che molti di noi abbiano una sensazione intuitiva di ciò che vogliamo che significhi, almeno nel senso di quale esperimento faresti per verificarlo.",
  "time_range": [
   206.16,
   212.86
  ]
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "model": "nmt",
  "translatedText": "Potresti immaginare di lanciare questo cubo in aria come una tintura, congelarlo in un punto arbitrario, registrare l'area dell'ombra da quella posizione e poi ripetere.",
  "time_range": [
   213.06,
   222.44
  ]
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "model": "nmt",
  "translatedText": "Se lo fai molte volte, ancora e ancora, puoi prendere la media del tuo campione.",
  "time_range": [
   223.64000000000001,
   228.38
  ]
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "model": "nmt",
  "translatedText": "Il numero a cui vogliamo arrivare, la vera media qui, dovrebbe essere qualunque cosa la media sperimentale si avvicini man mano che fai sempre più lanci, avvicinandoti a un numero infinito.",
  "time_range": [
   229.22,
   237.94
  ]
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "model": "nmt",
  "translatedText": "Nonostante ciò, i più pignoli tra voi potrebbero lamentarsi che non risponde realmente alla domanda, perché lascia aperta la questione di come definiamo un lancio casuale.",
  "time_range": [
   240.44,
   247.8
  ]
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "model": "nmt",
  "translatedText": "Il modo corretto di rispondere a questa domanda, se vogliamo che sia più formale, sarebbe innanzitutto descrivere lo spazio di tutti gli orientamenti possibili, a cui i matematici hanno dato un nome di fantasia.",
  "time_range": [
   248.3,
   257.54
  ]
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "model": "nmt",
  "translatedText": "Lo chiamano SO3, tipicamente definito in termini di una certa famiglia di matrici 3x3.",
  "time_range": [
   257.64,
   262.44
  ]
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "model": "nmt",
  "translatedText": "E la domanda a cui vogliamo rispondere è: quale distribuzione di probabilità stiamo applicando all'intero spazio?",
  "time_range": [
   263.1,
   268.76
  ]
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "model": "nmt",
  "translatedText": "È solo quando tale distribuzione di probabilità è ben definita che possiamo rispondere a una domanda che coinvolge una media.",
  "time_range": [
   269.1,
   274.5
  ]
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "model": "nmt",
  "translatedText": "Se sei un pignolo in questo genere di cose, voglio che tu sospenda questa domanda fino alla fine del video.",
  "time_range": [
   275.8,
   280.82
  ]
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "model": "nmt",
  "translatedText": "Rimarrai sorpreso da quanto lontano possiamo arrivare con l'idea più euristica e sperimentale di ripetere semplicemente una serie di lanci casuali senza definire realmente la distribuzione.",
  "time_range": [
   280.98,
   288.58
  ]
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "model": "nmt",
  "translatedText": "Una volta viste le soluzioni di Alice e Bob, è in realtà molto interessante chiedersi come esattamente ognuno di loro abbia definito questa distribuzione nel proprio percorso.",
  "time_range": [
   289.28,
   296.48
  ]
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "model": "nmt",
  "translatedText": "E ricorda, questa non vuole essere una lezione sulle ombre dei cubi di per sé, ma una lezione sulla risoluzione dei problemi, raccontata attraverso la lente di due diverse mentalità che potremmo portare nel puzzle.",
  "time_range": [
   297.92,
   307.1
  ]
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "model": "nmt",
  "translatedText": "E come in ogni lezione sulla risoluzione dei problemi, l'obiettivo qui non è arrivare alla risposta il più rapidamente possibile, ma sperare che tu ti senta come se avessi trovato la risposta da solo.",
  "time_range": [
   307.86,
   315.72
  ]
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "model": "nmt",
  "translatedText": "Quindi, se mai arriva il momento in cui senti che potresti avere un'idea, concediti la libertà di fermarti e provare a rifletterci.",
  "time_range": [
   316.02,
   320.82
  ]
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "model": "nmt",
  "translatedText": "Come primo passo, e questo è davvero indipendente da qualsiasi particolare stile di risoluzione dei problemi, ogni volta che trovi una domanda difficile, una buona cosa che puoi fare è chiedere, qual è la variante più semplice possibile e non banale del problema che stai cercando può provare a risolvere?",
  "time_range": [
   325.42,
   338.54
  ]
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "model": "nmt",
  "translatedText": "Quindi nel nostro caso, quello che potresti dire è, okay, dimentichiamoci della media su tutti gli orientamenti.",
  "time_range": [
   339.56,
   344.0
  ]
 },
 {
  "input": "That's a tricky thing to think about.",
  "model": "nmt",
  "translatedText": "È una cosa difficile a cui pensare.",
  "time_range": [
   344.12,
   345.42
  ]
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "model": "nmt",
  "translatedText": "E dimentichiamoci anche di tutte le diverse facce del cubo, perché si sovrappongono, e anche questo è complicato da pensare.",
  "time_range": [
   345.68,
   350.86
  ]
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "model": "nmt",
  "translatedText": "Solo per una faccia particolare e per un orientamento particolare, possiamo calcolare l'area di quest'ombra?",
  "time_range": [
   351.34,
   356.9
  ]
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "model": "nmt",
  "translatedText": "Ancora una volta, se vuoi orientarti in alcuni casi particolari, il più semplice è quando quella faccia è parallela al suolo, nel qual caso l'area dell'ombra è la stessa dell'area del viso.",
  "time_range": [
   357.66,
   366.68
  ]
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "model": "nmt",
  "translatedText": "E d'altra parte, se inclinassimo quella faccia di 90 gradi, la sua ombra sarà una linea retta e avrà un'area pari a zero.",
  "time_range": [
   367.18,
   373.44
  ]
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "model": "nmt",
  "translatedText": "Quindi Bob guarda questo e vuole una vera formula per quell'ombra.",
  "time_range": [
   374.3,
   377.42
  ]
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "model": "nmt",
  "translatedText": "E il modo in cui potrebbe pensarci è considerare il vettore normale perpendicolare a quella faccia.",
  "time_range": [
   377.9,
   382.7
  ]
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "model": "nmt",
  "translatedText": "E ciò che sembra rilevante è l'angolo che quel vettore normale forma con la verticale, con la direzione da cui proviene la luce, che potremmo chiamare theta.",
  "time_range": [
   383.18,
   390.08
  ]
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "model": "nmt",
  "translatedText": "Ora, dai due casi speciali che abbiamo appena visto, sappiamo che quando theta è uguale a zero, l'area di quell'ombra è uguale all'area della forma stessa, che è s quadrata se il quadrato ha lati di lunghezza s.",
  "time_range": [
   391.2,
   401.56
  ]
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "model": "nmt",
  "translatedText": "E se theta è uguale a 90 gradi, allora l'area di quell'ombra è zero.",
  "time_range": [
   402.2,
   405.8
  ]
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "model": "nmt",
  "translatedText": "E probabilmente non è troppo difficile indovinare che la trigonometria sarà in qualche modo rilevante, quindi chiunque sia a suo agio con le proprie funzioni trigonometriche potrebbe probabilmente azzardare un'ipotesi su quale sia la formula giusta.",
  "time_range": [
   406.24,
   414.62
  ]
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "model": "nmt",
  "translatedText": "Ma Bob è più attento ai dettagli di così.",
  "time_range": [
   414.62,
   417.12
  ]
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "model": "nmt",
  "translatedText": "Vuole dimostrare adeguatamente quale dovrebbe essere quell'area, piuttosto che fare semplicemente ipotesi basate sui punti finali.",
  "time_range": [
   417.4,
   422.02
  ]
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "model": "nmt",
  "translatedText": "E il modo in cui potresti pensarci potrebbe essere qualcosa del genere.",
  "time_range": [
   422.82,
   424.74
  ]
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "model": "nmt",
  "translatedText": "Se consideriamo il piano che passa per la verticale così come il nostro vettore normale, e poi consideriamo tutte le diverse sezioni della nostra forma che si trovano in quel piano, o parallele a quel piano, allora possiamo focalizzare la nostra attenzione su due- variante dimensionale del problema.",
  "time_range": [
   424.98,
   439.04
  ]
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "model": "nmt",
  "translatedText": "Se guardiamo solo una di quelle fette, che ha un vettore normale, un angolo theta lontano dalla verticale, la sua ombra potrebbe assomigliare a questa.",
  "time_range": [
   439.32,
   446.78
  ]
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "model": "nmt",
  "translatedText": "E se tracciamo una linea verticale qui in alto a sinistra, abbiamo un triangolo rettangolo.",
  "time_range": [
   447.46,
   451.02
  ]
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "model": "nmt",
  "translatedText": "E da qui possiamo fare un po' di ricerca degli angoli, dove seguiamo ciò che l'angolo theta implica riguardo al resto del diagramma.",
  "time_range": [
   451.6,
   457.52
  ]
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "model": "nmt",
  "translatedText": "E questo significa che l'angolo inferiore retto in questo triangolo è esattamente theta.",
  "time_range": [
   458.58,
   462.36
  ]
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "model": "nmt",
  "translatedText": "Quindi, quando vogliamo capire la dimensione di quest'ombra rispetto alla dimensione originale del pezzo, possiamo pensare al coseno di quell'angolo, theta, che ricorda l'adiacente sopra l'ipotenusa.",
  "time_range": [
   463.48,
   474.58
  ]
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "model": "nmt",
  "translatedText": "È letteralmente il rapporto tra la dimensione dell'ombra e la dimensione della fetta.",
  "time_range": [
   474.7,
   478.18
  ]
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "model": "nmt",
  "translatedText": "Quindi, il fattore per cui la fetta viene schiacciata in questa direzione è esattamente il coseno di theta.",
  "time_range": [
   478.9,
   484.52
  ]
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "model": "nmt",
  "translatedText": "E se allarghiamo la visione all'intero quadrato, tutte le fette in quella direzione verranno ridimensionate dello stesso fattore.",
  "time_range": [
   485.14,
   490.18
  ]
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "model": "nmt",
  "translatedText": "Ma nell'altra direzione, in quella perpendicolare a quella fetta, non c'è né stiramento né schiacciamento, perché il viso non è affatto inclinato in quella direzione.",
  "time_range": [
   490.38,
   498.12
  ]
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "model": "nmt",
  "translatedText": "Quindi, nel complesso, anche l'ombra bidimensionale del nostro volto bidimensionale dovrebbe essere ridimensionata di questo fattore coseno di theta.",
  "time_range": [
   498.12,
   505.7
  ]
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "model": "nmt",
  "translatedText": "Si allinea con ciò che potresti indovinare intuitivamente, dato il caso in cui l'angolo è 0° e il caso in cui è 90°, ma è rassicurante vedere perché è vero.",
  "time_range": [
   506.26,
   513.38
  ]
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "model": "nmt",
  "translatedText": "E in realtà, come affermato finora, ciò non è del tutto corretto.",
  "time_range": [
   514.96,
   518.32
  ]
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "model": "nmt",
  "translatedText": "C'è un piccolo problema con la formula che abbiamo scritto.",
  "time_range": [
   518.52,
   520.8
  ]
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "model": "nmt",
  "translatedText": "Nel caso in cui theta sia maggiore di 90°, il coseno risulterà effettivamente negativo.",
  "time_range": [
   521.34,
   526.24
  ]
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "model": "nmt",
  "translatedText": "Ma ovviamente non vogliamo considerare l'ombra come un'area negativa, almeno non in un problema come questo.",
  "time_range": [
   526.24,
   531.4
  ]
 },
 {
  "input": "So there's two different ways you could solve this.",
  "model": "nmt",
  "translatedText": "Quindi ci sono due modi diversi per risolvere questo problema.",
  "time_range": [
   531.86,
   533.3
  ]
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "model": "nmt",
  "translatedText": "Si potrebbe dire che vogliamo considerare solo il vettore normale che punta verso l'alto, che ha una componente z positiva.",
  "time_range": [
   533.38,
   538.34
  ]
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "model": "nmt",
  "translatedText": "O, più semplicemente, potremmo dire, prendiamo il valore assoluto di quel coseno e questo ci dà una formula valida.",
  "time_range": [
   538.84,
   544.72
  ]
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "model": "nmt",
  "translatedText": "Quindi Bob è felice perché ha una formula precisa che descrive l'area dell'ombra.",
  "time_range": [
   546.98,
   550.86
  ]
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "model": "nmt",
  "translatedText": "Ma Alice inizia a pensarci in modo leggermente diverso.",
  "time_range": [
   551.5,
   554.06
  ]
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "model": "nmt",
  "translatedText": "Dice, okay, abbiamo una forma e poi applichiamo una rotazione che la situa in qualche modo nello spazio 3D.",
  "time_range": [
   554.06,
   560.52
  ]
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "model": "nmt",
  "translatedText": "E poi applichiamo una proiezione piatta che la riporta nello spazio bidimensionale.",
  "time_range": [
   560.78,
   564.66
  ]
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "model": "nmt",
  "translatedText": "E ciò che la colpisce è che entrambe sono trasformazioni lineari.",
  "time_range": [
   565.08,
   568.34
  ]
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "model": "nmt",
  "translatedText": "Ciò significa che in linea di principio potresti descrivere ciascuno di essi con una matrice e che la trasformazione complessiva assomiglierebbe al prodotto di queste due matrici.",
  "time_range": [
   569.06,
   576.2
  ]
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "model": "nmt",
  "translatedText": "Ciò che Alice sa da una delle sue materie preferite, l'algebra lineare, è che se prendi una forma e ne consideri l'area, quindi applichi una trasformazione lineare, l'area di quel risultato assomiglia a una moltiplicazione costante dell'area originale della forma.",
  "time_range": [
   577.0,
   590.32
  ]
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "model": "nmt",
  "translatedText": "Più specificamente, abbiamo un nome per quella costante.",
  "time_range": [
   590.9,
   592.78
  ]
 },
 {
  "input": "It's called the determinant of the transformation.",
  "model": "nmt",
  "translatedText": "Si chiama determinante della trasformazione.",
  "time_range": [
   592.86,
   594.96
  ]
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "model": "nmt",
  "translatedText": "Se non sei molto a tuo agio con l'algebra lineare, potremmo fornire una descrizione molto più intuitiva e dire che se allunghi uniformemente la forma originale in una certa direzione, anche l'output verrà allungato uniformemente in una certa direzione.",
  "time_range": [
   596.26,
   607.56
  ]
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "model": "nmt",
  "translatedText": "Quindi l'area di ciascuno di essi dovrebbe ridimensionarsi in proporzione l'una all'altra.",
  "time_range": [
   607.56,
   611.4
  ]
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "model": "nmt",
  "translatedText": "Ora, in linea di principio, Alice potrebbe calcolare questo determinante, ma non è proprio nel suo stile farlo, almeno non immediatamente.",
  "time_range": [
   612.16,
   618.32
  ]
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "model": "nmt",
  "translatedText": "Invece, quello che scrive è come questa costante di proporzionalità tra la nostra forma originale e la sua ombra non dipenda dalla forma originale.",
  "time_range": [
   618.88,
   627.1
  ]
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "model": "nmt",
  "translatedText": "Potremmo parlare dell'ombra del contorno di questo gatto, o di qualsiasi altra cosa, e la sua dimensione non ha molta importanza.",
  "time_range": [
   627.26,
   632.64
  ]
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "model": "nmt",
  "translatedText": "L'unica cosa che influenza la costante di proporzionalità è la trasformazione che stiamo applicando, il che in questo contesto significa che potremmo scriverla come un fattore che dipende dalla rotazione applicata alla forma.",
  "time_range": [
   632.64,
   643.14
  ]
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "model": "nmt",
  "translatedText": "Nel profondo della nostra mente, grazie al calcolo di Bob, sappiamo a cosa assomiglia quel fattore.",
  "time_range": [
   644.5,
   648.22
  ]
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "model": "nmt",
  "translatedText": "Sai, è il valore assoluto del coseno dell'angolo tra il vettore normale e la verticale.",
  "time_range": [
   648.36,
   652.5
  ]
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "model": "nmt",
  "translatedText": "Ma Alice in questo momento sta solo dicendo, sì, sì, sì, posso pensarci alla fine quando voglio.",
  "time_range": [
   653.16,
   656.82
  ]
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "model": "nmt",
  "translatedText": "Ma sa che stiamo comunque per calcolare la media su tutti i diversi orientamenti, anche se nutre qualche speranza che qualsiasi formula specifica su un orientamento specifico possa essere spazzata via in quella media.",
  "time_range": [
   657.04,
   666.8
  ]
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "model": "nmt",
  "translatedText": "Ora è facile guardare questo e dire, okay, beh, allora Alice non sta davvero facendo nulla.",
  "time_range": [
   668.22,
   671.64
  ]
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "model": "nmt",
  "translatedText": "Naturalmente l'area dell'ombra è proporzionale all'area della forma originale.",
  "time_range": [
   671.78,
   675.44
  ]
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "model": "nmt",
  "translatedText": "Sono entrambe quantità bidimensionali, dovrebbero entrambe scalare come cose bidimensionali.",
  "time_range": [
   675.62,
   679.64
  ]
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "model": "nmt",
  "translatedText": "Ma tieni presente che questo non sarebbe affatto vero se avessimo a che fare con il caso più difficile che ha una fonte di luce più vicina.",
  "time_range": [
   680.2,
   685.68
  ]
 },
 {
  "input": "In that case, the projection is not linear.",
  "model": "nmt",
  "translatedText": "In tal caso la proiezione non è lineare.",
  "time_range": [
   685.84,
   687.98
  ]
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "model": "nmt",
  "translatedText": "Ad esempio, se ruoto questo gatto in modo che la sua coda finisca abbastanza vicino alla sorgente luminosa, allora se allungo la forma originale in modo uniforme nella direzione x, diciamo di un fattore 1.5, potrebbe avere un effetto molto sproporzionato sull'ombra finale, perché la coda si gonfia in modo molto sproporzionato quando si avvicina molto alla luce.",
  "time_range": [
   687.98,
   706.2
  ]
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "model": "nmt",
  "translatedText": "Ancora una volta, Alice tiene d'occhio quali proprietà del problema sono effettivamente rilevanti, perché questo la aiuta a sapere quanto può generalizzare le cose.",
  "time_range": [
   706.88,
   713.44
  ]
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "model": "nmt",
  "translatedText": "Ha importanza il fatto che stiamo pensando a una faccia quadrata e non a qualche altra forma?",
  "time_range": [
   713.96,
   717.26
  ]
 },
 {
  "input": "No, not really.",
  "model": "nmt",
  "translatedText": "No, non proprio.",
  "time_range": [
   717.26,
   718.64
  ]
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "model": "nmt",
  "translatedText": "Il fatto che la trasformazione sia lineare ha importanza?",
  "time_range": [
   718.78,
   721.32
  ]
 },
 {
  "input": "Yes, absolutely.",
  "model": "nmt",
  "translatedText": "Si assolutamente.",
  "time_range": [
   721.82,
   722.84
  ]
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "model": "nmt",
  "translatedText": "Alice può anche applicare un modo simile di pensare all'ombra media per qualsiasi forma come questa.",
  "time_range": [
   726.56,
   731.76
  ]
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "model": "nmt",
  "translatedText": "Supponiamo di avere una sequenza di rotazioni da applicare alla nostra faccia quadrata e chiamiamole R1, R2, R3 e così via.",
  "time_range": [
   732.02,
   739.56
  ]
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "model": "nmt",
  "translatedText": "Quindi l'area dell'ombra in ognuno di questi casi assomiglia ad un fattore moltiplicato per l'area del quadrato, e quel fattore dipende dalla rotazione.",
  "time_range": [
   739.72,
   747.3
  ]
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "model": "nmt",
  "translatedText": "Quindi se prendiamo una media empirica per quell'ombra nel campione di rotazioni che stiamo osservando adesso, il risultato è sommare tutte quelle aree d'ombra e poi dividerle per il numero totale che abbiamo.",
  "time_range": [
   748.06,
   758.32
  ]
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "model": "nmt",
  "translatedText": "Ora, a causa della linearità, quest'area del quadrato originale può essere chiaramente esclusa da tutto ciò e finisce a sinistra.",
  "time_range": [
   758.9,
   766.46
  ]
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "model": "nmt",
  "translatedText": "Questa non è la media esatta che stiamo cercando, è solo una media empirica di un campione di rotazioni, ma in linea di principio ciò che stiamo cercando è ciò che si avvicina quando la dimensione del nostro campione si avvicina all'infinito, e tutto il le parti che dipendono dalla dimensione del campione si trovano perfettamente lontane dall'area stessa.",
  "time_range": [
   767.2,
   783.04
  ]
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "model": "nmt",
  "translatedText": "Quindi qualunque cosa si avvicini al limite, sarà semplicemente un numero.",
  "time_range": [
   783.58,
   786.46
  ]
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "model": "nmt",
  "translatedText": "Potrebbe essere una faticaccia calcolarlo, non ne siamo ancora sicuri, ma la cosa che Alice nota è che è indipendente dalla dimensione e dalla forma della particolare cosa 2D che stiamo guardando.",
  "time_range": [
   786.82,
   795.66
  ]
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "model": "nmt",
  "translatedText": "È una costante di proporzionalità universale, e la sua speranza è che quell'universalità si presti in qualche modo a un modo più elegante per dedurre cosa deve essere.",
  "time_range": [
   795.72,
   804.94
  ]
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "model": "nmt",
  "translatedText": "Ora Bob sarebbe ansioso di calcolare questa costante qui e ora, e tra pochi minuti ti mostrerò come lo fa.",
  "time_range": [
   806.26,
   811.72
  ]
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "model": "nmt",
  "translatedText": "Ma prima voglio restare ancora un po' nel mondo di Alice, perché è qui che le cose iniziano a diventare davvero divertenti.",
  "time_range": [
   812.04,
   816.96
  ]
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "model": "nmt",
  "translatedText": "Nel suo desiderio di comprendere la struttura complessiva della domanda prima di immergersi nei dettagli, ora è curiosa di sapere come l'area dell'ombra del cubo si relaziona con l'area delle sue singole facce.",
  "time_range": [
   820.08,
   831.1
  ]
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "model": "nmt",
  "translatedText": "Ora, se possiamo dire qualcosa sull'area media di una particolare faccia, questo ci dice qualcosa sull'area media del cubo nel suo insieme?",
  "time_range": [
   831.62,
   838.4
  ]
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "model": "nmt",
  "translatedText": "Ad esempio, una cosa semplice che potremmo dire è che quell'area è decisamente inferiore alla somma delle aree di tutti i volti, perché c'è una quantità significativa di sovrapposizione tra quelle ombre.",
  "time_range": [
   839.1,
   848.92
  ]
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "model": "nmt",
  "translatedText": "Ma non è del tutto chiaro come pensare a tale sovrapposizione, perché se focalizziamo la nostra attenzione solo su due facce particolari, in alcuni orientamenti non si sovrappongono affatto, ma in altri orientamenti hanno qualche sovrapposizione, e la forma specifica e l’area di quella sovrapposizione sembra un po’ difficile da pensare, tanto meno come sulla Terra potremmo mediarla su tutti i diversi orientamenti.",
  "time_range": [
   849.64,
   869.82
  ]
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "model": "nmt",
  "translatedText": "Ma Alice ha circa tre intuizioni intelligenti riguardo all'intero problema, e questa è la prima.",
  "time_range": [
   870.66,
   875.46
  ]
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "model": "nmt",
  "translatedText": "Dice che, in realtà, se pensiamo all'intero cubo, non solo a un paio di facce, possiamo concludere che l'area dell'ombra per un dato orientamento è esattamente la metà della somma delle aree di tutte le facce.",
  "time_range": [
   875.88,
   888.18
  ]
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "model": "nmt",
  "translatedText": "Intuitivamente si può forse intuire che metà di loro sono immersi nella luce e l'altra metà no, ma ecco come lei lo giustifica.",
  "time_range": [
   889.58,
   895.66
  ]
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "model": "nmt",
  "translatedText": "Dice che un particolare raggio di luce partirebbe dal cielo e alla fine colpirebbe un punto nell'ombra.",
  "time_range": [
   895.82,
   901.4
  ]
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "model": "nmt",
  "translatedText": "Quel raggio passa attraverso il cubo esattamente in due punti.",
  "time_range": [
   902.04,
   904.86
  ]
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "model": "nmt",
  "translatedText": "C'è un momento in cui entra e un momento in cui esce.",
  "time_range": [
   905.12,
   907.6
  ]
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "model": "nmt",
  "translatedText": "Quindi ogni punto in quell'ombra corrisponde esattamente a due facce sopra di essa.",
  "time_range": [
   907.6,
   913.78
  ]
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "model": "nmt",
  "translatedText": "Bene, ok, non è esattamente vero se quel raggio di luce passa attraverso il bordo di uno dei quadrati.",
  "time_range": [
   914.46,
   919.22
  ]
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "model": "nmt",
  "translatedText": "C'è un po' di ambiguità su quante facce sta passando, ma quelle rappresentano un'area pari a zero all'interno dell'ombra, quindi possiamo tranquillamente ignorarle se la cosa che stiamo cercando di fare è calcolare l'area.",
  "time_range": [
   919.6,
   929.04
  ]
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "model": "nmt",
  "translatedText": "Se Alice viene pressata e ha bisogno di giustificare il motivo per cui questo è esattamente vero, il che è importante per capire come il problema potrebbe generalizzarsi, può fare appello all’idea di convessità.",
  "time_range": [
   931.02,
   940.82
  ]
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "model": "nmt",
  "translatedText": "La convessità è una di quelle proprietà per cui molti di noi hanno un senso intuitivo di cosa dovrebbe significare, sai, sono forme che sporgono e basta, senza mai intaccarsi verso l'interno.",
  "time_range": [
   941.42,
   948.58
  ]
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "model": "nmt",
  "translatedText": "Ma i matematici hanno un modo piuttosto intelligente di formalizzarlo, utile per dimostrazioni concrete.",
  "time_range": [
   949.14,
   953.02
  ]
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "model": "nmt",
  "translatedText": "Dicono che un insieme è convesso se la linea che collega due punti qualsiasi all'interno di quell'insieme è interamente contenuta nell'insieme stesso.",
  "time_range": [
   953.68,
   961.66
  ]
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "model": "nmt",
  "translatedText": "Quindi un quadrato è convesso perché non importa dove si mettono due punti all'interno del quadrato, la linea che li collega è interamente contenuta all'interno del quadrato.",
  "time_range": [
   961.66,
   969.66
  ]
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "model": "nmt",
  "translatedText": "Ma qualcosa come il simbolo pi greco non è convesso.",
  "time_range": [
   970.28,
   972.72
  ]
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "model": "nmt",
  "translatedText": "Posso facilmente trovare due punti diversi in modo che la linea che li collega debba raggiungere il picco all'esterno dell'insieme stesso.",
  "time_range": [
   972.84,
   978.32
  ]
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "model": "nmt",
  "translatedText": "Nessuna delle lettere nella parola convessa è essa stessa convessa.",
  "time_range": [
   978.94,
   982.6
  ]
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "model": "nmt",
  "translatedText": "Puoi trovare due punti in modo che la linea che li collega debba passare all'esterno dell'insieme.",
  "time_range": [
   982.7,
   987.02
  ]
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "model": "nmt",
  "translatedText": "È un modo davvero intelligente per formalizzare l'idea di una forma che sporge solo verso l'esterno, perché ogni volta che si incastra verso l'interno, puoi trovare queste linee di controesempio.",
  "time_range": [
   987.46,
   996.16
  ]
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "model": "nmt",
  "translatedText": "Il nostro cubo, poiché è convesso, tra il primo punto di entrata e l'ultimo punto di uscita, deve rimanere interamente all'interno del cubo per definizione di convessità.",
  "time_range": [
   996.38,
   1005.18
  ]
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "model": "nmt",
  "translatedText": "Ma se avessimo a che fare con qualche altra forma non convessa, come una ciambella, potremmo trovare un raggio di luce che entra, poi esce, poi entra, poi esce di nuovo, quindi non avremmo un rapporto due a uno pulito coprirsi dall'ombra.",
  "time_range": [
   1005.74,
   1016.16
  ]
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "model": "nmt",
  "translatedText": "Le ombre di tutte le sue diverse parti, se dovessi coprirle con un gruppo di volti, non sarebbero esattamente il doppio dell'area dell'ombra stessa.",
  "time_range": [
   1016.6,
   1024.08
  ]
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "model": "nmt",
  "translatedText": "Quindi, questa è la prima intuizione chiave, le ombre del viso coprono due volte l'ombra del cubo.",
  "time_range": [
   1024.76,
   1028.26
  ]
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "model": "nmt",
  "translatedText": "E il successivo è un po' più simbolico, quindi iniziamo abbreviando un po' la nostra notazione per fare spazio sullo schermo.",
  "time_range": [
   1028.88,
   1034.66
  ]
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "model": "nmt",
  "translatedText": "Invece di scrivere l'area dell'ombra del cubo, scriverò solo s del cubo.",
  "time_range": [
   1035.36,
   1039.68
  ]
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "model": "nmt",
  "translatedText": "E allo stesso modo, invece dell'area dell'ombra di un volto particolare, scriverò semplicemente s di f, dove il pedice j indica di quale volto sto parlando.",
  "time_range": [
   1040.32,
   1048.42
  ]
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "model": "nmt",
  "translatedText": "Ma ovviamente dovremmo parlare dell'ombra di una particolare rotazione applicata al cubo.",
  "time_range": [
   1048.42,
   1053.62
  ]
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "model": "nmt",
  "translatedText": "Quindi potrei scriverlo come s di una certa rotazione applicata al cubo, e allo stesso modo a destra, è l'area dell'ombra di quella stessa rotazione applicata a una data delle facce.",
  "time_range": [
   1054.1,
   1063.26
  ]
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "model": "nmt",
  "translatedText": "Con la notazione più compatta a portata di mano, pensiamo alla media di questa area d'ombra attraverso molte rotazioni diverse, qualche campione di r1, r2, r3 e così via.",
  "time_range": [
   1063.76,
   1073.7
  ]
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "model": "nmt",
  "translatedText": "Ancora una volta, la media implica semplicemente la somma di tutte quelle aree d'ombra e la loro divisione per n.",
  "time_range": [
   1074.12,
   1079.22
  ]
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "model": "nmt",
  "translatedText": "E in linea di principio, se dovessimo considerarlo per campioni sempre più grandi, lasciamo che n si avvicini all'infinito, questo ci darebbe l'area media dell'ombra del cubo.",
  "time_range": [
   1079.94,
   1087.36
  ]
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "model": "nmt",
  "translatedText": "Alcuni di voi potrebbero pensare, sì, lo sappiamo, lo avete già detto, ma è utile scriverlo in modo da poter capire perché esprime l'area d'ombra per una particolare rotazione del cubo come somma su tutte le sue facce, o almeno la metà di quella somma, perché è vantaggioso?",
  "time_range": [
   1088.26,
   1103.42
  ]
 },
 {
  "input": "What is it going to do for us?",
  "model": "nmt",
  "translatedText": "Cosa farà per noi?",
  "time_range": [
   1103.6,
   1104.76
  ]
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "model": "nmt",
  "translatedText": "Bene, scriviamolo e basta, dove per ciascuna di queste rotazioni del cubo, potremmo scomporre l'ombra come somma della stessa rotazione applicata a tutte le facce.",
  "time_range": [
   1105.56,
   1113.9
  ]
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "model": "nmt",
  "translatedText": "E quando è scritto come una griglia come questa, possiamo arrivare alla seconda intuizione di Alice, che è cambiare il modo in cui pensiamo alla somma da riga per riga a colonna per colonna.",
  "time_range": [
   1114.54,
   1123.72
  ]
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "model": "nmt",
  "translatedText": "Ad esempio, se focalizziamo la nostra attenzione solo sulla prima colonna, ciò che ci dice è di sommare l'area dell'ombra della prima faccia attraverso molti orientamenti diversi.",
  "time_range": [
   1125.84,
   1135.08
  ]
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "model": "nmt",
  "translatedText": "Quindi, se prendessimo quella somma e la dividessimo per la dimensione del nostro campione, otterremmo una media empirica per l'area dell'ombra di questa faccia.",
  "time_range": [
   1135.64,
   1142.94
  ]
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "model": "nmt",
  "translatedText": "Quindi, se prendiamo campioni sempre più grandi, lasciando che la dimensione arrivi all'infinito, questo si avvicinerà all'area d'ombra media di un quadrato.",
  "time_range": [
   1143.8,
   1150.24
  ]
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "model": "nmt",
  "translatedText": "Allo stesso modo, si può pensare che la seconda colonna ci indichi l'area media della seconda faccia del cubo, che ovviamente dovrebbe essere lo stesso numero.",
  "time_range": [
   1152.12,
   1159.78
  ]
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "model": "nmt",
  "translatedText": "E lo stesso vale per qualsiasi altra colonna, ci dice l'area media per un volto particolare.",
  "time_range": [
   1160.44,
   1164.36
  ]
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "model": "nmt",
  "translatedText": "Questo ci dà un modo molto diverso di pensare alla nostra intera espressione.",
  "time_range": [
   1164.98,
   1168.04
  ]
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "model": "nmt",
  "translatedText": "Invece di dire sommare le aree dei cubi in tutti i diversi orientamenti, potremmo dire semplicemente sommare le ombre medie delle sei diverse facce e dividere il totale per metà.",
  "time_range": [
   1168.38,
   1177.56
  ]
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "model": "nmt",
  "translatedText": "Il termine a sinistra qui sta pensando prima di sommare le righe, mentre il termine a destra sta pensando prima di sommare le colonne.",
  "time_range": [
   1178.04,
   1183.76
  ]
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "model": "nmt",
  "translatedText": "In breve, la media della somma delle ombre del viso è uguale alla somma della media delle ombre del viso.",
  "time_range": [
   1184.6799999999998,
   1191.14
  ]
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "model": "nmt",
  "translatedText": "Forse lo scambio sembra semplice, forse no, ma posso dirti che in realtà c'è qualcosa in più di quanto sembri nel passo che abbiamo appena fatto, ma ci arriveremo più tardi.",
  "time_range": [
   1192.14,
   1199.7
  ]
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "model": "nmt",
  "translatedText": "E ricorda, sappiamo che l'area media di un viso particolare assomiglia a una costante di proporzionalità universale moltiplicata per l'area di quel viso.",
  "time_range": [
   1200.78,
   1208.22
  ]
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "model": "nmt",
  "translatedText": "Quindi se lo sommiamo su tutte le facce del cubo, potremmo pensarlo come uguale ad alcune volte costanti l'area della superficie del cubo.",
  "time_range": [
   1208.8,
   1215.2
  ]
 },
 {
  "input": "And that's pretty interesting.",
  "model": "nmt",
  "translatedText": "E questo è piuttosto interessante.",
  "time_range": [
   1215.92,
   1216.76
  ]
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "model": "nmt",
  "translatedText": "L'area media dell'ombra di questo cubo sarà proporzionale alla sua superficie.",
  "time_range": [
   1216.98,
   1221.48
  ]
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "model": "nmt",
  "translatedText": "Ma allo stesso tempo potresti lamentarti, beh Alice sta solo spingendo in giro un mucchio di simboli, perché niente di tutto questo ha importanza se non sappiamo qual è la costante di proporzionalità.",
  "time_range": [
   1222.68,
   1231.08
  ]
 },
 {
  "input": "I mean, it almost seems obvious.",
  "model": "nmt",
  "translatedText": "Voglio dire, sembra quasi ovvio.",
  "time_range": [
   1231.66,
   1233.38
  ]
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "model": "nmt",
  "translatedText": "Ad esempio, ovviamente l'area d'ombra media dovrebbe essere proporzionale alla superficie.",
  "time_range": [
   1233.64,
   1237.62
  ]
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "model": "nmt",
  "translatedText": "Sono entrambe quantità bidimensionali, quindi dovrebbero scalare di pari passo l'una con l'altra.",
  "time_range": [
   1237.88,
   1242.26
  ]
 },
 {
  "input": "I mean, it's not obvious.",
  "model": "nmt",
  "translatedText": "Voglio dire, non è ovvio.",
  "time_range": [
   1243.08,
   1244.38
  ]
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "model": "nmt",
  "translatedText": "Dopotutto, per una fonte di luce più vicina, semplicemente non sarebbe vero.",
  "time_range": [
   1244.64,
   1247.28
  ]
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "model": "nmt",
  "translatedText": "Inoltre, questa attività in cui abbiamo sommato la griglia colonna per colonna rispetto a riga per riga è un po' più sfumata di quanto potrebbe sembrare a prima vista.",
  "time_range": [
   1248.12,
   1254.7
  ]
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "model": "nmt",
  "translatedText": "Alla base di tutto ciò c’è un presupposto sottile e nascosto, che assume un significato speciale quando scegliamo di rivisitare la questione di quale distribuzione di probabilità viene adottata nello spazio di tutti gli orientamenti.",
  "time_range": [
   1255.22,
   1266.3
  ]
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "model": "nmt",
  "translatedText": "Ma più di ogni altra cosa, la ragione per cui non è ovvia è che il significato di questo risultato qui non è semplicemente che questi due valori sono proporzionali.",
  "time_range": [
   1267.3,
   1275.36
  ]
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "model": "nmt",
  "translatedText": "È che un fatto analogo vale per qualsiasi solido convesso e, soprattutto, il contenuto effettivo di ciò che Alice ha costruito finora è che ci sarà la stessa costante di proporzionalità in tutti loro.",
  "time_range": [
   1276.14,
   1287.92
  ]
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "model": "nmt",
  "translatedText": "Ora, se riflettete davvero su questo, alcuni di voi potrebbero essere in grado di prevedere il modo in cui Alice sarà in grado di finire le cose da qui.",
  "time_range": [
   1289.28,
   1294.18
  ]
 },
 {
  "input": "It's really delightful.",
  "model": "nmt",
  "translatedText": "È davvero delizioso.",
  "time_range": [
   1294.18,
   1295.42
  ]
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "model": "nmt",
  "translatedText": "Onestamente è il motivo principale per cui ho trattato questo argomento.",
  "time_range": [
   1295.6,
   1297.94
  ]
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "model": "nmt",
  "translatedText": "Ma prima di addentrarci nel merito, penso che sia facile sottovalutare il suo risultato a meno che non approfondiamo nei dettagli ciò che riesce a evitare.",
  "time_range": [
   1298.24,
   1306.14
  ]
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "model": "nmt",
  "translatedText": "Quindi prendiamoci un momento per riportare la nostra attenzione al mondo di Bob, perché mentre Alice faceva tutto questo, lui era impegnato a fare alcuni calcoli.",
  "time_range": [
   1306.86,
   1314.4
  ]
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "model": "nmt",
  "translatedText": "In effetti, ciò su cui sta lavorando è trovare esattamente ciò che Alice deve ancora capire, ovvero come prendere la formula che ha trovato per l'area dell'ombra di un quadrato e fare il naturale passo successivo di cercare di trovare la media di quella l'ombra del quadrato mediata su tutti gli orientamenti possibili.",
  "time_range": [
   1314.98,
   1329.98
  ]
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "model": "nmt",
  "translatedText": "Quindi il modo in cui Bob inizia, se sta pensando a tutti i diversi orientamenti possibili per questo quadrato, è chiedersi quali sono tutti i diversi vettori normali che quel quadrato può avere in tutti questi orientamenti, perché tutto ciò che riguarda la sua ombra si riduce a quella normale vettore.",
  "time_range": [
   1334.62,
   1347.24
  ]
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "model": "nmt",
  "translatedText": "Non è troppo difficile vedere che tutti questi possibili vettori normali tracciano la superficie di una sfera.",
  "time_range": [
   1347.8,
   1352.32
  ]
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "model": "nmt",
  "translatedText": "Se assumiamo che sia un vettore normale unitario, è una sfera con raggio 1.",
  "time_range": [
   1352.32,
   1355.56
  ]
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "model": "nmt",
  "translatedText": "Inoltre, Bob ritiene che ogni punto di questa sfera dovrebbe avere la stessa probabilità di verificarsi di qualsiasi altro.",
  "time_range": [
   1356.42,
   1361.58
  ]
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "model": "nmt",
  "translatedText": "Le nostre probabilità dovrebbero essere uniformi in questo modo.",
  "time_range": [
   1362.0,
   1363.98
  ]
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "model": "nmt",
  "translatedText": "Non c'è motivo di preferire una direzione rispetto ad un'altra.",
  "time_range": [
   1364.02,
   1366.32
  ]
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "model": "nmt",
  "translatedText": "Ma nel contesto delle probabilità continue, non è molto utile parlare della probabilità di un particolare punto individuale, perché nell'infinità innumerevole di punti sulla sfera, sarebbe zero e inutile.",
  "time_range": [
   1367.12,
   1377.44
  ]
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "model": "nmt",
  "translatedText": "Quindi, invece, il modo più preciso per esprimere questa uniformità sarebbe dire che la probabilità che il nostro vettore normale arrivi in un dato pezzo di area sulla sfera dovrebbe essere proporzionale a quell'area stessa.",
  "time_range": [
   1377.44,
   1389.44
  ]
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "model": "nmt",
  "translatedText": "Più specificamente, dovrebbe essere uguale all'area di quella piccola zona divisa per la superficie totale della sfera.",
  "time_range": [
   1389.96,
   1395.12
  ]
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "model": "nmt",
  "translatedText": "Se questo è vero, non importa quale porzione di area stiamo considerando, questo è ciò che intendiamo per distribuzione uniforme sulla sfera.",
  "time_range": [
   1395.68,
   1401.06
  ]
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "model": "nmt",
  "translatedText": "Ora, per essere chiari, i punti sulla sfera non sono la stessa cosa degli orientamenti nello spazio 3D, perché anche se sai quale vettore normale avrà questo quadrato, questo ci lascia con un altro grado di libertà.",
  "time_range": [
   1402.0,
   1411.7
  ]
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "model": "nmt",
  "translatedText": "Il quadrato potrebbe essere ruotato attorno a quel vettore normale.",
  "time_range": [
   1411.9,
   1414.16
  ]
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "model": "nmt",
  "translatedText": "Ma in realtà Bob non deve preoccuparsi di quel grado di libertà extra, perché in tutti questi casi l'area dell'ombra è la stessa.",
  "time_range": [
   1414.96,
   1422.0
  ]
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "model": "nmt",
  "translatedText": "Dipende solo dal coseno dell'angolo tra quel vettore normale e la verticale.",
  "time_range": [
   1422.36,
   1426.46
  ]
 },
 {
  "input": "Which is kind of neat.",
  "model": "nmt",
  "translatedText": "Il che è piuttosto carino.",
  "time_range": [
   1427.18,
   1427.84
  ]
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "model": "nmt",
  "translatedText": "Tutte quelle ombre hanno forme veramente diverse.",
  "time_range": [
   1428.0,
   1430.06
  ]
 },
 {
  "input": "They're not the same.",
  "model": "nmt",
  "translatedText": "Non sono la stessa cosa.",
  "time_range": [
   1430.16,
   1430.9
  ]
 },
 {
  "input": "But the area of each of them will be the same.",
  "model": "nmt",
  "translatedText": "Ma l'area di ciascuno di essi sarà la stessa.",
  "time_range": [
   1431.2,
   1433.54
  ]
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "model": "nmt",
  "translatedText": "Ciò significa che quando Bob vuole quest'area d'ombra media su tutti i possibili orientamenti, tutto ciò che ha veramente bisogno di sapere è il valore medio di questo valore assoluto del coseno di theta per tutti i diversi possibili vettori normali, tutti i diversi possibili punti sulla sfera.",
  "time_range": [
   1434.72,
   1448.44
  ]
 },
 {
  "input": "So, how do you compute an average like this?",
  "model": "nmt",
  "translatedText": "Quindi, come si calcola una media come questa?",
  "time_range": [
   1449.12,
   1451.32
  ]
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "model": "nmt",
  "translatedText": "Ebbene, se vivessimo in una sorta di mondo pixelato discreto, dove c'è solo un numero finito di possibili angoli theta che quel vettore normale potrebbe avere, la media sarebbe piuttosto semplice.",
  "time_range": [
   1452.54,
   1461.44
  ]
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "model": "nmt",
  "translatedText": "Quello che fai è trovare la probabilità di arrivare a un qualsiasi valore particolare di theta, che ci dirà qualcosa come quanta parte della sfera compongono i vettori normali con quell'angolo, e poi moltiplicarla per la cosa che vogliamo prendere in media di, questa formula per l'area dell'ombra.",
  "time_range": [
   1461.44,
   1475.94
  ]
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "model": "nmt",
  "translatedText": "E poi lo sommeresti su tutti i diversi possibili valori di theta, che vanno da 0 a 180 gradi, o pi radianti.",
  "time_range": [
   1476.86,
   1484.02
  ]
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "model": "nmt",
  "translatedText": "Ma ovviamente, in realtà, esiste un continuum di possibili valori di theta, questo infinito innumerevole, e la probabilità di arrivare a qualsiasi valore particolare di theta sarà effettivamente 0.",
  "time_range": [
   1485.06,
   1495.98
  ]
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "model": "nmt",
  "translatedText": "E quindi una somma come questa sfortunatamente non ha alcun senso, o se avesse senso, sommando infiniti zeri dovrebbe darci semplicemente uno 0.",
  "time_range": [
   1496.68,
   1504.16
  ]
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "model": "nmt",
  "translatedText": "La risposta breve a ciò che facciamo invece è che calcoliamo un integrale.",
  "time_range": [
   1505.8,
   1508.88
  ]
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "model": "nmt",
  "translatedText": "E sarò sincero con te, la parte difficile qui è che non sono del tutto sicuro di quale background dovrei supporre da quelli di voi che guardano in questo momento.",
  "time_range": [
   1509.66,
   1515.26
  ]
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "model": "nmt",
  "translatedText": "Forse è vero che ti senti abbastanza a tuo agio con il calcolo infinitesimale e non hai bisogno che io insista su questo punto qui.",
  "time_range": [
   1515.64,
   1519.8
  ]
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "model": "nmt",
  "translatedText": "Forse è il caso che tu non abbia familiarità con il calcolo infinitesimale e non dovrei buttare giù integrali del genere.",
  "time_range": [
   1519.8,
   1525.9
  ]
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "model": "nmt",
  "translatedText": "O forse hai seguito un corso di calcolo qualche tempo fa ma hai bisogno di un po' di ripasso.",
  "time_range": [
   1525.9,
   1529.44
  ]
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "model": "nmt",
  "translatedText": "Utilizzerò l'opzione di impostarlo come se fosse una lezione di calcolo, perché a dire il vero, anche quando sei abbastanza a tuo agio con gli integrali, impostarli può essere una specie di processo soggetto a errori e richiamare alla definizione sottostante è un buon modo per controllarti durante il processo.",
  "time_range": [
   1529.82,
   1543.04
  ]
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "model": "nmt",
  "translatedText": "Se vivessimo in un'epoca in cui non esisteva il calcolo infinitesimale e gli integrali non esistevano, e volessimo fornire una risposta approssimativa a questa domanda, un modo in cui potremmo farlo è prendere un campione di valori per θ che varia da 0 fino a 180°.",
  "time_range": [
   1543.78,
   1556.52
  ]
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "model": "nmt",
  "translatedText": "Potremmo pensarli come distanziati uniformemente con una sorta di differenza tra ciascuno di essi, un delta θ.",
  "time_range": [
   1557.18,
   1562.04
  ]
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "model": "nmt",
  "translatedText": "E resta il fatto che sarebbe inutile chiedere quale sia la probabilità che si verifichi un particolare valore di θ, anche se è 1 nel nostro campione.",
  "time_range": [
   1562.62,
   1569.24
  ]
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "model": "nmt",
  "translatedText": "Quella probabilità sarebbe ancora 0 e non sarebbe utile.",
  "time_range": [
   1569.66,
   1572.36
  ]
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "model": "nmt",
  "translatedText": "Ma ciò che è utile chiedersi è la probabilità di cadere tra due valori diversi del nostro campione, in questa piccola fascia di latitudine con un'ampiezza di delta θ.",
  "time_range": [
   1572.36,
   1582.02
  ]
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "model": "nmt",
  "translatedText": "Partendo dal presupposto che la distribuzione lungo questa sfera dovrebbe essere uniforme, la probabilità si riduce alla conoscenza dell'area di questa fascia.",
  "time_range": [
   1582.4,
   1589.56
  ]
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "model": "nmt",
  "translatedText": "Più specificamente, le probabilità che un vettore scelto casualmente si trovi in quella banda dovrebbero essere pari a quell'area divisa per la superficie totale della sfera.",
  "time_range": [
   1590.02,
   1596.72
  ]
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "model": "nmt",
  "translatedText": "Per calcolare quell'area, pensiamo prima al raggio di quella fascia, che, se il raggio della nostra sfera è 1, sarà sicuramente inferiore a 1.",
  "time_range": [
   1596.72,
   1605.28
  ]
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "model": "nmt",
  "translatedText": "E infatti, se disegniamo qui il piccolo triangolo rettangolo appropriato, puoi vedere che quel piccolo raggio, diciamo solo in cima alla fascia, dovrebbe essere il seno del nostro angolo, il seno di θ.",
  "time_range": [
   1605.9,
   1614.78
  ]
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "model": "nmt",
  "translatedText": "Ciò significa che la circonferenza della fascia dovrebbe essere 2π volte il seno di quell'angolo, e quindi l'area della fascia dovrebbe essere quella circonferenza moltiplicata per il suo spessore, quel piccolo delta θ.",
  "time_range": [
   1615.52,
   1625.52
  ]
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "model": "nmt",
  "translatedText": "O meglio, l'area della nostra fascia è all'incirca questa quantità.",
  "time_range": [
   1625.52,
   1629.08
  ]
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "model": "nmt",
  "translatedText": "Ciò che è importante è che per un campione più fine con molti più valori di θ, la precisione di tale approssimazione diventerebbe sempre migliore.",
  "time_range": [
   1629.54,
   1636.32
  ]
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "model": "nmt",
  "translatedText": "Ora ricorda, il motivo per cui volevamo quest'area è conoscere la probabilità di cadere in quella fascia, che è quest'area divisa per l'area della superficie della sfera, che sappiamo essere 4π volte il suo raggio al quadrato.",
  "time_range": [
   1637.54,
   1648.08
  ]
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "model": "nmt",
  "translatedText": "Questo è un valore che potresti anche calcolare con un integrale simile a quello che stiamo impostando ora, ma per ora possiamo darlo per scontato, come una formula standard ben nota.",
  "time_range": [
   1648.66,
   1656.08
  ]
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "model": "nmt",
  "translatedText": "E questa probabilità stessa è solo un trampolino di lancio nella direzione di ciò che realmente vogliamo, che è l'area media dell'ombra di un quadrato.",
  "time_range": [
   1656.84,
   1663.32
  ]
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "model": "nmt",
  "translatedText": "Per ottenere ciò, moltiplicheremo questa probabilità per la corrispondente area d'ombra, che è questo valore assoluto dell'espressione cosθ che abbiamo visto molte volte fino a questo punto.",
  "time_range": [
   1664.24,
   1673.02
  ]
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "model": "nmt",
  "translatedText": "E la nostra stima per questa media ora si ridurrebbe alla somma di questa espressione su tutte le diverse bande, tutti i diversi campioni di θ che abbiamo preso.",
  "time_range": [
   1673.5,
   1681.7
  ]
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "model": "nmt",
  "translatedText": "Questo qui, tra l'altro, è quando Bob è totalmente nel suo elemento.",
  "time_range": [
   1683.44,
   1686.36
  ]
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "model": "nmt",
  "translatedText": "Abbiamo un sacco di formule esatte che descrivono qualcosa di molto concreto, che in realtà scavano nel nostro cammino verso una risposta reale.",
  "time_range": [
   1686.58,
   1691.86
  ]
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "model": "nmt",
  "translatedText": "E ancora, se ti sembrano tanti dettagli, voglio che tu apprezzi questo fatto, così che tu possa apprezzare quanto sia magico quando Alice riesce in qualche modo a evitare tutto questo.",
  "time_range": [
   1692.52,
   1701.92
  ]
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "model": "nmt",
  "translatedText": "Comunque, guardando indietro alla nostra espressione, facciamo un po' di pulizia, ad esempio eliminando tutti i termini che non dipendono da θ stesso.",
  "time_range": [
   1702.8799999999999,
   1709.0
  ]
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "model": "nmt",
  "translatedText": "E possiamo semplificare che 2π diviso 4π sia semplicemente 1 metà.",
  "time_range": [
   1709.72,
   1713.48
  ]
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "model": "nmt",
  "translatedText": "E per renderlo un po' più analogo al calcolo infinitesimale, con gli integrali, lasciami semplicemente scambiare qui i termini principali all'interno della somma.",
  "time_range": [
   1714.54,
   1719.46
  ]
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "model": "nmt",
  "translatedText": "Ciò che abbiamo ora, questa somma che si avvicinerà alla risposta alla nostra domanda, è quasi ciò che è un integrale.",
  "time_range": [
   1719.96,
   1726.04
  ]
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "model": "nmt",
  "translatedText": "Invece di scrivere il sigma per la somma, scriviamo il simbolo integrale, questo tipo di Leibniziane allungate, che ci mostrano che stiamo andando da 0 a π.",
  "time_range": [
   1726.48,
   1733.98
  ]
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "model": "nmt",
  "translatedText": "E invece di descrivere la dimensione del passo come δθ, una quantità finita concreta, la descriviamo invece come dθ, che mi piace pensare che segnali il fatto che viene preso un qualche tipo di limite.",
  "time_range": [
   1734.72,
   1745.16
  ]
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "model": "nmt",
  "translatedText": "Ciò che quell'integrale significa, per definizione, è qualunque cosa la somma sul fondo si avvicini a suddivisioni sempre più fini, campioni più densi che potremmo prendere per θ stesso.",
  "time_range": [
   1746.08,
   1757.1
  ]
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "model": "nmt",
  "translatedText": "E a questo punto, per quelli di voi che conoscono l'analisi infinitesimale, scriverò semplicemente i dettagli di come lo realizzereste effettivamente, poiché potreste vederlo scritto nel taccuino di Bob.",
  "time_range": [
   1759.04,
   1766.62
  ]
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "model": "nmt",
  "translatedText": "È la solita roba anti-derivativa, ma l'unico passo fondamentale è introdurre una certa identità trigonometrica.",
  "time_range": [
   1767.16,
   1772.16
  ]
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "model": "nmt",
  "translatedText": "Alla fine, ciò che Bob scopre dopo aver fatto ciò è il fatto sorprendentemente chiaro che l'area media dell'ombra di un quadrato è esattamente la metà dell'area di quel quadrato.",
  "time_range": [
   1773.06,
   1783.52
  ]
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "model": "nmt",
  "translatedText": "Questa è la costante misteriosa, che Alice ancora non conosce.",
  "time_range": [
   1784.58,
   1787.56
  ]
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "model": "nmt",
  "translatedText": "Se Bob guardasse alle sue spalle e vedesse il lavoro che ha svolto, potrebbe risolvere il problema in questo momento.",
  "time_range": [
   1788.12,
   1792.78
  ]
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "model": "nmt",
  "translatedText": "Inserisce la costante che ha appena trovato e conosce la risposta finale.",
  "time_range": [
   1793.0,
   1796.16
  ]
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "model": "nmt",
  "translatedText": "E ora, finalmente, con tutto questo sullo sfondo, cosa fa Alice per realizzare la soluzione finale?",
  "time_range": [
   1800.22,
   1806.2
  ]
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "model": "nmt",
  "translatedText": "L'ho presentata come una persona a cui piace davvero generalizzare i risultati che trova.",
  "time_range": [
   1806.86,
   1810.26
  ]
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "model": "nmt",
  "translatedText": "E di solito queste generalizzazioni finiscono per diventare note a piè di pagina interessanti che non sono realmente utili per risolvere problemi particolari.",
  "time_range": [
   1810.84,
   1816.68
  ]
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "model": "nmt",
  "translatedText": "Ma questo è un caso in cui la generalizzazione stessa la porta a un risultato quantitativo.",
  "time_range": [
   1817.18,
   1821.76
  ]
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "model": "nmt",
  "translatedText": "Ricorda, la sostanza di ciò che ha scoperto finora è che se guardi un solido convesso, allora l'area media della sua ombra sarà proporzionale alla sua area superficiale e, soprattutto, sarà la stessa costante di proporzionalità in tutti gli oggetti. di questi solidi.",
  "time_range": [
   1821.76,
   1836.5
  ]
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "model": "nmt",
  "translatedText": "Quindi tutto ciò che Alice deve fare è trovare un singolo solido convesso là fuori di cui conosce già l'area media della sua ombra.",
  "time_range": [
   1837.1,
   1844.46
  ]
 },
 {
  "input": "And some of you may see where this is going.",
  "model": "nmt",
  "translatedText": "E alcuni di voi potrebbero vedere dove sta andando.",
  "time_range": [
   1845.16,
   1846.84
  ]
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "model": "nmt",
  "translatedText": "Il solido più simmetrico a nostra disposizione è una sfera.",
  "time_range": [
   1846.84,
   1850.06
  ]
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "model": "nmt",
  "translatedText": "Non importa quale sia l'orientamento di quella sfera, la sua ombra, l'ombra di proiezione piatta, è sempre un cerchio con un'area πr².",
  "time_range": [
   1850.52,
   1858.02
  ]
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "model": "nmt",
  "translatedText": "Quindi, in particolare, questa è la sua area d'ombra media.",
  "time_range": [
   1858.62,
   1861.04
  ]
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "model": "nmt",
  "translatedText": "E la superficie di una sfera, come ho detto prima, è esattamente 4πr².",
  "time_range": [
   1861.78,
   1866.32
  ]
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "model": "nmt",
  "translatedText": "A proposito, ho realizzato un video in cui si parla di quella formula dell'area superficiale e di come Archimede l'ha dimostrata migliaia di anni prima che esistesse il calcolo infinitesimale, quindi non sono necessari gli integrali per trovarlo.",
  "time_range": [
   1867.1,
   1876.34
  ]
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "model": "nmt",
  "translatedText": "La magia di ciò che Alice ha fatto è che può prendere questo fatto apparentemente specifico, che l'ombra di una sfera ha un'area esattamente 1/4 della sua superficie, e usarlo per concludere un fatto molto più generale, che per qualsiasi solido convesso là fuori, la sua ombra e la sua superficie sono legate allo stesso modo, in un certo senso.",
  "time_range": [
   1876.34,
   1893.58
  ]
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "model": "nmt",
  "translatedText": "Quindi, può andare a compilare i dettagli della domanda particolare su un cubo e dire che la sua area d'ombra media sarà 1⁄4 volte la sua superficie, 6s².",
  "time_range": [
   1894.64,
   1903.62
  ]
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "model": "nmt",
  "translatedText": "Ma il fatto molto più memorabile a cui andrai a dormire pensando è che non aveva alcuna importanza il fatto che stessimo parlando di un cubo.",
  "time_range": [
   1903.62,
   1910.8
  ]
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "model": "nmt",
  "translatedText": "Ora, è tutto molto carino, ma alcuni di voi potrebbero lamentarsi che questo non è un argomento valido, perché le sfere non hanno facce piatte.",
  "time_range": [
   1912.52,
   1919.38
  ]
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "model": "nmt",
  "translatedText": "Quando ho detto che l'argomentazione di Alice si generalizza a qualsiasi solido convesso, se guardiamo effettivamente l'argomentazione stessa, dipende sicuramente dall'uso di un numero finito di facce piane.",
  "time_range": [
   1920.1,
   1928.94
  ]
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "model": "nmt",
  "translatedText": "Ad esempio, se lo mappassimo su un dodecaedro, inizieremmo dicendo che l'area di una particolare ombra di quel dodecaedro assomiglia esattamente a 1/2 volte la somma delle aree delle ombre di tutte le sue facce.",
  "time_range": [
   1928.94,
   1940.44
  ]
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "model": "nmt",
  "translatedText": "Ancora una volta, potresti usare un certo raggio di luce mescolato con un argomento convessità per trarre questa conclusione.",
  "time_range": [
   1941.0,
   1945.44
  ]
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "model": "nmt",
  "translatedText": "E ricorda, il vantaggio di esprimere quell'area d'ombra come somma è che quando vogliamo calcolare la media su un gruppo di rotazioni diverse, possiamo descrivere quella somma come una grande griglia, dove possiamo poi andare colonna per colonna e considerare l'area media per l'ombra di ogni volto.",
  "time_range": [
   1946.28,
   1960.82
  ]
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "model": "nmt",
  "translatedText": "Inoltre, un fatto critico è stata la conclusione di molto prima, che l'ombra media per qualsiasi oggetto 2D, un oggetto 2D piatto, che è importante, sarà uguale ad una costante di proporzionalità universale moltiplicata per la sua area.",
  "time_range": [
   1961.46,
   1972.72
  ]
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "model": "nmt",
  "translatedText": "Il significato era che quella costante non dipendeva dalla forma stessa.",
  "time_range": [
   1973.26,
   1976.12
  ]
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "model": "nmt",
  "translatedText": "Potrebbe essere stato un quadrato, o un gatto, o le facce pentagonali del nostro dodecaedro, qualunque cosa.",
  "time_range": [
   1976.22,
   1981.84
  ]
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "model": "nmt",
  "translatedText": "Quindi, dopo aver portato frettolosamente questo concetto su una sfera che non ha un numero finito di facce piane, avresti ragione a lamentarti.",
  "time_range": [
   1982.28,
   1988.26
  ]
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "model": "nmt",
  "translatedText": "Ma fortunatamente, è un dettaglio abbastanza semplice da inserire.",
  "time_range": [
   1988.9,
   1991.24
  ]
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "model": "nmt",
  "translatedText": "Quello che si può fare è immaginare una sequenza di diversi poliedri che si avvicinano successivamente ad una sfera, nel senso che le loro facce si abbracciano sempre più strettamente attorno alla superficie vera e propria della sfera.",
  "time_range": [
   1991.64,
   2001.16
  ]
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "model": "nmt",
  "translatedText": "Per ciascuna di queste approssimazioni, possiamo trarre la stessa conclusione, che la sua ombra media sarà proporzionale alla sua superficie con questa costante di proporzionalità universale.",
  "time_range": [
   2001.6799999999998,
   2010.78
  ]
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "model": "nmt",
  "translatedText": "Quindi, se diciamo, ok, prendiamo il limite del rapporto tra l'area d'ombra media ad ogni passaggio e l'area della superficie ad ogni passaggio, beh, poiché quel rapporto non cambia mai, è sempre uguale a questa costante, quindi in il limite, sarà anche uguale a quella costante.",
  "time_range": [
   2011.2,
   2024.62
  ]
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "model": "nmt",
  "translatedText": "Ma d'altra parte, per loro definizione, al limite, la loro area d'ombra media dovrebbe essere quella di un cerchio, che è πr², e il limite delle aree superficiali sarebbe la superficie della sfera, 4πr².",
  "time_range": [
   2024.62,
   2036.98
  ]
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "model": "nmt",
  "translatedText": "Quindi arriviamo davvero alla conclusione che l'intuizione suggerisce, ma, come è così comune con l'argomentazione di Alice qui, dobbiamo essere un po' delicati nel modo in cui giustifichiamo tale intuizione.",
  "time_range": [
   2037.66,
   2047.0
  ]
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "model": "nmt",
  "translatedText": "È facile che questo contrasto tra Alice e Bob venga percepito come un giudizio di valore, come se stessi dicendo, guarda quanto è riuscita ad essere intelligente Alice, ha perspicacemente evitato tutti quei calcoli che Bob doveva fare.",
  "time_range": [
   2052.2,
   2063.56
  ]
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "model": "nmt",
  "translatedText": "Ma questa sarebbe una conclusione davvero fuorviante.",
  "time_range": [
   2063.88,
   2067.9
  ]
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "model": "nmt",
  "translatedText": "Penso che ci sia un motivo importante per cui la divulgazione della matematica differisce dalla sensazione di fare effettivamente matematica.",
  "time_range": [
   2068.56,
   2074.08
  ]
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "model": "nmt",
  "translatedText": "C'è questa tendenza a mostrare le dimostrazioni, gli argomenti con una certa intuizione acuta che ti consente di evitare di fare calcoli.",
  "time_range": [
   2074.08,
   2080.78
  ]
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "model": "nmt",
  "translatedText": "Potrei semplicemente proiettare, dato che sono molto colpevole di questo, ma quello che posso dirti, seduto qui dall'altra parte dello schermo, è che è molto più attraente realizzare un video sull'approccio di Alice rispetto a quello di Bob.",
  "time_range": [
   2081.24,
   2092.3
  ]
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "model": "nmt",
  "translatedText": "Per prima cosa, nell'approccio di Alice, il ragionamento è divertente, ha questi bei momenti aha.",
  "time_range": [
   2092.46,
   2097.12
  ]
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "model": "nmt",
  "translatedText": "Ma anche, cosa fondamentale, il modo in cui lo spieghi è più o meno lo stesso per una gamma molto ampia di contesti matematici.",
  "time_range": [
   2097.12,
   2103.9
  ]
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "model": "nmt",
  "translatedText": "È molto meno allettante fare un video sull'approccio di Bob, non perché i calcoli siano poi così pessimi, voglio dire, onestamente non lo sono, ma la realtà pragmatica è che il ritmo appropriato per spiegarlo sembra molto diverso a seconda dei diversi metodi matematici background del pubblico.",
  "time_range": [
   2104.64,
   2118.86
  ]
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "model": "nmt",
  "translatedText": "Quindi, tu, guardando questo in questo momento, chiaramente consumi video di matematica online, e penso che nel farlo valga la pena essere consapevoli di questo pregiudizio.",
  "time_range": [
   2119.82,
   2126.62
  ]
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "model": "nmt",
  "translatedText": "Se l’obiettivo è quello di impartire una vera lezione sulla risoluzione dei problemi, concentrarsi troppo sulle dimostrazioni astute corre il rischio di risultare in malafede.",
  "time_range": [
   2126.62,
   2134.52
  ]
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "model": "nmt",
  "translatedText": "Ad esempio, supponiamo di dover passare alla modalità sfida e chiedere informazioni sul caso con una fonte di luce più vicina.",
  "time_range": [
   2135.84,
   2141.02
  ]
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "model": "nmt",
  "translatedText": "Per quanto ne so, non esiste una soluzione altrettanto intelligente di quella di Alice qui, in cui puoi semplicemente relazionarti a una singola forma come una sfera.",
  "time_range": [
   2141.7,
   2148.16
  ]
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "model": "nmt",
  "translatedText": "Il riscaldamento molto più produttivo da fare sarebbe stato il calcolo dell'approccio di Bob.",
  "time_range": [
   2148.86,
   2153.3
  ]
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "model": "nmt",
  "translatedText": "E se si guarda alla storia di questo problema, è stato dimostrato da Cauchy nel 1832, e se scrutiamo i suoi appunti scritti a mano, sembrano molto più simili al lavoro di Bob che al lavoro di Alice.",
  "time_range": [
   2153.88,
   2164.48
  ]
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "model": "nmt",
  "translatedText": "Proprio qui, all'inizio di pagina 11, puoi vedere cos'è essenzialmente lo stesso integrale che tu ed io abbiamo impostato nel mezzo.",
  "time_range": [
   2164.9,
   2170.4
  ]
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "model": "nmt",
  "translatedText": "D'altra parte, l'intera struttura dell'articolo mira a trovare un fatto generale, non qualcosa di specifico come il caso di un cubo.",
  "time_range": [
   2171.3,
   2177.24
  ]
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "model": "nmt",
  "translatedText": "Quindi, se ci chiedessimo quale di queste due mentalità sia correlata all’atto di scoprire nuova matematica, la risposta giusta dovrebbe quasi certamente essere una miscela di entrambe.",
  "time_range": [
   2177.24,
   2186.4
  ]
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "model": "nmt",
  "translatedText": "Ma suggerirei che molte persone non diano abbastanza peso alla parte di quella miscela in cui sei ansioso di tuffarti nei calcoli.",
  "time_range": [
   2187.22,
   2194.18
  ]
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "model": "nmt",
  "translatedText": "E penso che ci sia il rischio che i video che realizzo possano contribuire a questo.",
  "time_range": [
   2194.72,
   2198.16
  ]
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "model": "nmt",
  "translatedText": "Nel podcast che ho fatto con il matematico Alex Kontorovich, ha parlato dell'importanza, spesso sottovalutata, di esercitarsi semplicemente sui calcoli per sviluppare l'intuizione, sia che tu sia uno studente impegnato in una nuova classe, o un matematico ricercatore praticante impegnato in un nuovo campo di studio.",
  "time_range": [
   2198.9599999999996,
   2214.32
  ]
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "model": "nmt",
  "translatedText": "Un ascoltatore in realtà ha scritto per evidenziare l'impressione fatta da quella particolare sezione.",
  "time_range": [
   2214.8,
   2219.04
  ]
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "model": "nmt",
  "translatedText": "Sono studenti di dottorato e si descrivono preoccupati che le loro capacità matematiche stiano iniziando a svanire, cosa che attribuiscono al fatto di diventare più vecchi e meno acuti.",
  "time_range": [
   2219.18,
   2227.64
  ]
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "model": "nmt",
  "translatedText": "Ma sentire un matematico praticante parlare dell’importanza di fare centinaia di esempi concreti per imparare qualcosa di nuovo, evidentemente, ha cambiato la loro prospettiva.",
  "time_range": [
   2227.64,
   2236.32
  ]
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "model": "nmt",
  "translatedText": "Secondo le loro stesse parole, il riconoscimento di ciò ha completamente rimodellato la loro prospettiva e i loro risultati.",
  "time_range": [
   2236.9,
   2241.16
  ]
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "model": "nmt",
  "translatedText": "E se guardi i famosi matematici della storia, Newton, Eulero, Gauss, tutti loro, hanno tutti questa pazienza apparentemente infinita nel fare calcoli noiosi.",
  "time_range": [
   2242.02,
   2250.58
  ]
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "model": "nmt",
  "translatedText": "L’ironia di essere prevenuti nel mostrare intuizioni che ci permettono di evitare calcoli è che il modo in cui le persone spesso allenano le intuizioni per trovare quelle intuizioni in primo luogo è facendo pile e pile di calcoli.",
  "time_range": [
   2250.58,
   2262.72
  ]
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "model": "nmt",
  "translatedText": "Detto questo, sicuramente mancherebbe qualcosa senza la mentalità di Alice qui.",
  "time_range": [
   2264.72,
   2269.42
  ]
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "model": "nmt",
  "translatedText": "Voglio dire, pensaci, quanto sarebbe triste se risolvessimo questo problema per un cubo, e non uscissimo mai dagli alberi per vedere la foresta e capire che questo è un fatto generalissimo, si applica a una grande famiglia di forme.",
  "time_range": [
   2269.98,
   2280.32
  ]
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "model": "nmt",
  "translatedText": "E se consideri che la matematica non consiste solo nel rispondere alle domande che ti vengono poste, ma nell'introdurre nuove idee e costrutti, una nota divertente sull'approccio di Alice è che suggerisce un modo divertente per quantificare l'idea di convessità.",
  "time_range": [
   2281.14,
   2294.82
  ]
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "model": "nmt",
  "translatedText": "Invece di avere semplicemente una risposta sì-no, è convesso o no, potremmo assegnargli un numero dicendo: considera l'area media dell'ombra di un solido, moltiplicala per 4, dividila per la superficie , e se quel numero è 1, hai un solido convesso, ma se è inferiore a 1, è non convesso, e quanto è vicino a 1 ti dice quanto è vicino a essere convesso.",
  "time_range": [
   2295.36,
   2316.46
  ]
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "model": "nmt",
  "translatedText": "Inoltre, uno degli aspetti positivi della soluzione Alice è che aiuta a spiegare il motivo per cui i matematici hanno quella che a volte può sembrare una bizzarra infatuazione per la generalità e l'astrazione.",
  "time_range": [
   2317.1,
   2328.36
  ]
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "model": "nmt",
  "translatedText": "Più esempi vedi in cui generalizzare e astrarre ti aiutano effettivamente a risolvere un caso specifico, più inizi ad adottare la stessa infatuazione.",
  "time_range": [
   2328.36,
   2337.36
  ]
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "model": "nmt",
  "translatedText": "E come pensiero finale per gli spettatori accaniti tra voi che sono riusciti a resistere fino a questo punto, c'è ancora una domanda senza risposta sulla premessa stessa del nostro puzzle.",
  "time_range": [
   2339.24,
   2347.0
  ]
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "model": "nmt",
  "translatedText": "Cosa significa esattamente scegliere un orientamento casuale?",
  "time_range": [
   2347.76,
   2350.94
  ]
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "model": "nmt",
  "translatedText": "Ora, se ti sembra una domanda sciocca, perché ovviamente sappiamo cosa dovrebbe significare, ti incoraggio a guardare un video che ho appena fatto con Numberphile su un enigma della probabilità noto come paradosso di Bertrand.",
  "time_range": [
   2350.94,
   2360.78
  ]
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "model": "nmt",
  "translatedText": "Dopo averlo guardato, e se apprezzi alcune delle sfumature in gioco qui, il tuo compito è riflettere su dove esattamente Alice e Bob rispondono implicitamente a questa domanda.",
  "time_range": [
   2361.58,
   2370.42
  ]
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "model": "nmt",
  "translatedText": "Il caso di Bob è relativamente semplice, ma il punto in cui Alice fissa una distribuzione specifica nello spazio di tutti gli orientamenti, beh, non è affatto ovvio, in realtà è molto sottile.",
  "time_range": [
   2370.42,
   2381.7
  ]
 }
]