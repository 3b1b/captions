[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "translatedText": "",
  "from_community_srt": "잠시 후, 큐브의 그림자와 관련된 정말 멋진 문제에 대해 말하겠습니다.",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "translatedText": "",
  "from_community_srt": "하지만 우리가 그것에 대해 알기 전에, 이 영상의 요점은 정확히 \"문제\"에 관한 영상이 아니라 우리가 이 문제를 해결할 수 있는 두 가지의 다른 문제 해결 방법에 관한 영상입니다. 실제로 두 학생,",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "translatedText": "",
  "from_community_srt": "Alice와 Bob이 각각의 접근 방식을 구현한다고 상상하여 두 가지 다른 방식을 가정해 보겠습니다.",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "translatedText": "",
  "from_community_srt": "Bob은 계산을 아주 좋아하는 학생입니다.",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "translatedText": "",
  "from_community_srt": "그는 디테일을 파헤치고 그 구체적인 상황에 대한 매우 구체적인 관점을 얻을 수 있는 순간이 있는 순간을 가장 기뻐합니다.",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice on the other hand is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has before she digs into the computations themselves.",
  "translatedText": "",
  "from_community_srt": "반면에 Alice는 계산을 미루는 경향이 있습니다. 이는 그녀가 계산을 하는 방법을 모르거나 하고싶지 않기 때문이 아닙니다. 그러나 그녀는 계산 자체를 하기 전에 자신이 다루고 있는 문제의 종류, 문제의 일반적인 형태에 대한 높은 수준의 일반적인 윤곽을 얻는 것을 선호합니다.",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "translatedText": "",
  "from_community_srt": "그녀는 자신의 앞에 놓인 구체적인 질문뿐만 아니라 이것을 일반화 할 수 있는 가장 넓은 방법을 이해한다면 매우 기뻐합니다. 그리고, 특히 더 일반적인 방법이 더 빠르고 우아한 계산을 할 수 있다면, 그녀는 실제로 그 계산들을 수행합니다.",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "translatedText": "",
  "from_community_srt": "이제 두 사람이 마주하게 될 문제는 큐브의 그림자에 대한 평균 면적을 찾는 것입니다. 큐브가 이 공간에서 맴돌고 있다면,",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "translatedText": "",
  "from_community_srt": "그림자의 면적에 영향을 미치는 몇가지 것들이 있습니다. 그림자의 면적에 영향을 미치는 몇가지 것들이 있습니다.",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "translatedText": "",
  "from_community_srt": "한 가지 확실한 것은 큐브의 크기입니다. 큐브가 작아질수록,",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "translatedText": "",
  "from_community_srt": "그림자도 작아집니다. 하지만 만약 큐브가 다른 방향으로 놓여있다면, 그 방향들은 다른 면적의 다른 특정한 그림자들에 대응합니다.",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "translatedText": "",
  "from_community_srt": "여기에서 평균을 찾으라는 말은 큐브의 특정 크기에 대해 가능한 모든 방향에 대한 평균을 의미합니다.",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "translatedText": "",
  "from_community_srt": "여러분 중 눈치좋은 사람들은 광원이 어디에 있는지도 매우 중요하다는 것을 지적할 수 있습니다.",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "translatedText": "",
  "from_community_srt": "만약 광원이 큐브 가까이에 매우 낮게 있다면 그림자는 더 커지게 되고, 만약 광원이 옆으로 약간 떨어져 있다면,",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "translatedText": "",
  "from_community_srt": "이것은 그림자를 왜곡시키고 매우 다른 모양을 만들 수 있습니다.",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "translatedText": "",
  "from_community_srt": "그 빛 위치를 설명하는 것은 그 자체로 매우 흥미롭습니다. 하지만 퍼즐은 그 자체로도 충분히 어렵기 때문에, 적어도 처음에 우리가 할 수 있는 가장 쉬운 일을 해봅시다. 그리고 빛이 큐브 바로 위에 있고 정말로 멀리 있다고 말해두죠. 사실상 무한히 멀리 있어서 우리가 고려하고 있는 것은 평면 사영입니다. (사영: 도형을 한 평면에 옮긴 느낌이라고 생각하면 된다.) 즉, 공간의 좌표(𝒙, 𝒚, 𝒛)를 보면 평면 사영은 (𝒙, 𝒚, 0)이 됩니다.",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So, just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "translatedText": "",
  "from_community_srt": "따라서 우리가 방향을 파악하기 위해 가장 쉽게 생각할 수 있는 상황은 큐브의 두 면이 지면과 평행하게 세워져 있는 경우입니다.",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s².",
  "translatedText": "",
  "from_community_srt": "이 경우, 이 평평한 사영된 그림자는 단순히 정사각형이고, 큐브의 옆면 길이가 𝒔라고 하면, 그 그림자의 넓이는 𝒔²입니다.",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "translatedText": "",
  "from_community_srt": "그리고 여기 아래에 있는 것과 같은 애니메이션에 숫자를 적을 때마다 저는 관련된 큐브의 옆면 길이가 1이라고 가정할 것입니다.",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now, another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "translatedText": "",
  "from_community_srt": "생각하기에 재미있는 방향 중 또 다른 특별한 경우는 긴 대각선이 빛의 방향과 평행한 경우입니다.",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "translatedText": "",
  "from_community_srt": "이 경우 그림자는 실제로 정육각형처럼 보입니다. 그리고 몇 분 안에 우리가 개발할 방법들을 사용한다면, 여러분은 그 그림자의 면적이 정사각형 면 넓이의 √3 이라는 것을 계산할 수 있습니다.",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "translatedText": "",
  "from_community_srt": "하지만 보통의 실제 그림자는 정사각형이나 육각형처럼 규칙적이지는 않을 것입니다.",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape, based on some harder to think about orientation for this cube.",
  "translatedText": "",
  "from_community_srt": "이 큐브에 경우 \"생각하기 어려운 방향을 기반\"으로 하는 \"생각하기 어려운 모양\"입니다.",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "translatedText": "",
  "from_community_srt": "아까, 저는 무심코 모든 가능한 방향들에 대해 평균을 내는 말을 했고, 여러분은 그것이 정확히 무엇을 의미하는지 물어볼 수 있을 것 같습니다.",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "translatedText": "",
  "from_community_srt": "전 우리 중 많은 사람들이 그것이 무엇을 의미하는지 직감적으로 느끼고 있다고 생각합니다.",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air, like a die, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "translatedText": "",
  "from_community_srt": "적어도 그것을 검증하기 위해 어떤 실험을 할 것인가에 대해서는 말이죠. 여러분은 이 큐브를 주사위처럼 공중에 던지고, 임의의 지점에서 얼리고,",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times, over and over, you can take the mean of your sample.",
  "translatedText": "",
  "from_community_srt": "그 위치에서 그림자의 면적을 기록하고, 반복하는 것을 상상할 수 있습니다.",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "translatedText": "",
  "from_community_srt": "이 과정을 여러 번 반복하면 표본의 평균을 구할 수 있습니다. 우리가 얻고자 하는 수, 여기에서 실제 평균은 무한히 많이 던질수록 실험 평균이 접근하는 값이어야 합니다.",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "translatedText": "",
  "from_community_srt": "그럼에도 불구하고, 여러분 중 깐깐한 사람들은 불평할 수 있습니다. 그것은 우리가 어떻게 \"랜덤 던지기\"를 정의하는지 또 다른 문제를 만들기 때문입니다.",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "translatedText": "",
  "from_community_srt": "이에 대한 적절한 답변 방법은, 만약 우리가 더 형식적이기를 원한다면, 먼저 모든 가능한 방향의 공간을 설명하는 것입니다.",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "translatedText": "",
  "from_community_srt": "수학자들이 실제로 멋진 이름을 지어준 것이죠. 그들은 이를 𝑺𝑶(3)라고 부르며, 일반적으로 3x3 행렬의 특정 족으로 정의됩니다.",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "translatedText": "",
  "from_community_srt": "그리고 우리가 답하고자 하는 질문은 \"이 공간 전체에 어떤 확률 분포를 두고 있는가?\" 입니다.",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined, that we can answer a question involving an average.",
  "translatedText": "",
  "from_community_srt": "이러한 확률 분포가 잘 정의된 경우에만 평균과 관련된 질문에 답할 수 있습니다.",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "translatedText": "",
  "from_community_srt": "만약 당신이 그런 것에 대해 까다로우신다면, \\n 그 질문을 영상이 끝날 때까지 미루어 주셨으면 합니다.",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "translatedText": "",
  "from_community_srt": "실제로 분포를 정의하지 않고 무작위로 던지기만 하는, 보다 경험적인 실험 아이디어를 가지고 얼마나 멀리 갈 수 있는지 알면 놀랄 것입니다.",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "translatedText": "",
  "from_community_srt": "일단 Alice와 Bob의 해답을 보게 되면, 그들 각각이 어떻게 이 분포를 정의했는지 물어보는 것은 매우 흥미로운 일입니다.",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "translatedText": "",
  "from_community_srt": "그리고 기억하세요, 이것은 큐브의 그림자에 대한 교훈 그 자체가 아니라 우리가 문제에서 얻올 수 있는 다른 두 가지 사고방식의 관점을 통해 말하는, \"문제 해결\"에 대한 교훈입니다.",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "translatedText": "",
  "from_community_srt": "그리고 문제 해결에 대한 교훈과 마찬가지로, 여기서의 목표는 우리가 할 수 있는 한 빨리 정답에 도달하는 것이 아닌 여러분이 스스로 답을 찾았다고 느끼기를 바랍니다.",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "translatedText": "",
  "from_community_srt": "그러니 만약 여러분이 아이디어가 있다고 느낀다면, 잠시 멈추고 여러분이 다시 생각해 볼 수 있는 시간을 주세요.",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving style, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "translatedText": "",
  "from_community_srt": "첫 번째 단계로, 이것은 어떤 특정한 문제 해결 방식과는 완전히 독립적입니다. 여러분이 어려운 질문을 발견할 때마다, 여러분이 할 수 있는 좋은 일은 \"내가 해결하려고 시도할 수 있는 가장 단순하지만 중대한 문제의 변형은 무엇일까?\" 라고 묻는 것입니다.",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "translatedText": "",
  "from_community_srt": "우리의 경우, 여러분이 말할 수 있는 것은 \"좋아, 모든 방향에서 평균화하는 것을 잊자.\" 입니다.",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about.",
  "translatedText": "",
  "from_community_srt": "그것은 생각하기 어려운 문제입니다.",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "translatedText": "",
  "from_community_srt": "그리고 큐브의 모든 다른 면들은 잊어버리도록 합시다. 왜냐하면 그것들은 겹치고 생각하기도 어렵기 때문입니다.",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "translatedText": "",
  "from_community_srt": "하나의 특정한 면과 하나의 특정한 방향에 대해, 우리는 이 그림자의 면적을 계산할 수 있을까요? 다시 한 번,",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "translatedText": "",
  "from_community_srt": "몇 가지 특별한 경우 중 가장 쉬운 방향은 면이 지면과 평행할 때입니다. 이 경우 그림자 면적은 면의 면적과 동일합니다.",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "translatedText": "",
  "from_community_srt": "그리고 반대로 그 면을 90도 기울이면 그림자는 직선이 되고 면적은 0이 됩니다.",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "translatedText": "",
  "from_community_srt": "Bob은 이것을 보고 그림자에 대한 실제 공식을 원했습니다.",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "translatedText": "",
  "from_community_srt": "그리고 그가 생각할 수 있는 것은 그 면으로부터 수직인 법선 벡터를 고려하는 것입니다. (법선 벡터:",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "translatedText": "",
  "from_community_srt": "한 평면의 수직인 벡터) 관련있어 보이는 것은 법선 벡터가 빛이 오는 방향과 수직을 따라 만드는 각도인데, 그 각도를 θ라고 부를 수 있습니다.",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "translatedText": "",
  "from_community_srt": "우리가 방금 살펴본 두 가지 특별한 경우로부터, 우리는 θ가 0일 때 그 그림자의 넓이는 모양 자체의 넓이와 같다는 것을 압니다.",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "translatedText": "",
  "from_community_srt": "정사각형의 길이가 𝒔인 경우 넓이는 𝒔²입니다. 만약 θ가 90도 이면 그림자의 면적은 0입니다.",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "translatedText": "",
  "from_community_srt": "그리고 삼각법이 어떻게든 관련이 있을 것이라고 추측하는 것은 그리 어렵지 않을 것입니다. 그래서 삼각함수에 익숙한 사람이라면 올바른 공식이무엇인지에 대한 추측을 할 수 있을 것입니다.",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "translatedText": "",
  "from_community_srt": "하지만 Bob은 그것보다 더 세밀합니다.",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "translatedText": "",
  "from_community_srt": "단순히 결과만 보고 추측하는 것이 아니라 그 면적이 무엇인지 제대로 증명하고 싶은 것입니다.",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "translatedText": "",
  "from_community_srt": "어떻게 보면,",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "translatedText": "",
  "from_community_srt": "이런 생각일 수 있습니다. 만약 우리가 법선 벡터같이 수직을 통과하는 평면을 고려한다면, 그리고 그 평면 안에 있거나, 그 평면과 평행한 형태의 모든 다른 조각들을 고려한다면, 우리는 문제의 2차원 변형에 집중할 수 있습니다.",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "translatedText": "",
  "from_community_srt": "만약 우리가 그 조각들 중 하나를 본다면, 수직에서 떨어진 θ각의 법선 벡터를 가지고 있고, 그것의 그림자는 이렇게 보일지도 모릅니다.",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "translatedText": "",
  "from_community_srt": "그리고 여기서 왼쪽에 수직선을 그으면, 우리는 직각삼각형을 얻게 됩니다.",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "translatedText": "",
  "from_community_srt": "여기서부터 우리는 약간의 각도를 추적을 할 수 있습니다. θ가 그림의 나머지 부분에 대해 동위각인걸 암시합니다.",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "translatedText": "",
  "from_community_srt": "이것은 이 삼각형의 오른쪽 아래 각도가 정확히 θ라는 것을 의미합니다.",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "translatedText": "",
  "from_community_srt": "따라서 우리가 이 그림자의 크기를 원래의 크기와 비교하여 이해하고 싶을 때, 우리는 그 각도의 \"이웃변/빗변\" 인 \"cos(θ)\"를 생각할 수 있습니다.",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "translatedText": "",
  "from_community_srt": "말 그대로 그림자의 크기와 조각의 크기 사이의 비율입니다.",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "translatedText": "",
  "from_community_srt": "따라서 조각들이 이 방향으로 뭉개지는 요인은 정확히 cos(θ)입니다.",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "translatedText": "",
  "from_community_srt": "그리고 우리가 전체 정사각형으로 시야를 넓히면, 그 방향으로의 모든 조각들은 동일한 요소로 조정됩니다.",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "translatedText": "",
  "from_community_srt": "그러나 그 조각에 수직인 다른 방향에서는 면이 그 방향으로 전혀 기울어지지 않기 때문에 늘어나거나 뭉개지지 않습니다.",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "translatedText": "",
  "from_community_srt": "그래서 전체적으로 2차원 면의 2차원 그림자 또한 cos(θ)에 의해 축소되어야 합니다.",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "translatedText": "",
  "from_community_srt": "각도가 0도인 경우와 90도인 경우를 볼 때 추측할 수 있는 내용과 일치하고 그것이 사실인 이유를 확인하면 안심이 됩니다.",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "translatedText": "",
  "from_community_srt": "사실, 지금까지 말했듯이 이것은 꽤 정확하지 않습니다.",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "translatedText": "",
  "from_community_srt": "우리가 만든 공식에 작은 문제가 있습니다.",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "translatedText": "",
  "from_community_srt": "θ가 90도 이상일 경우 코사인이 음으로 나오겠지만 당연히 그림자가 음의 면적을 갖는다고 생각하지는 않습니다. 적어도 이런 문제에서는요.",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "translatedText": "",
  "from_community_srt": "따라서 이 문제를 해결할 수 있는 두 가지 방법이 있습니다. 위로 향하는 법선 벡터, 즉 양수의 z 성분을 갖는 벡터만 고려하려고 한다고 할 수 있습니다.",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "translatedText": "",
  "from_community_srt": "좀 더 간단하게 말해서 코사인의 절대값을 구하면 유효한 공식을 얻을 수 있습니다.",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "translatedText": "",
  "from_community_srt": "따라서 Bob은 그림자 면적을 설명하는 정확한 공식을 가지고 있기 때문에 행복할 겁니다.",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "translatedText": "",
  "from_community_srt": "하지만 Alice는 조금 다르게 생각하기 시작합니다. 그녀가 \"좋아,",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way, and then we apply a flat projection that shoves that back into two-dimensional space.",
  "translatedText": "",
  "from_community_srt": "우리는 어떤 모양를 가지고 있어.\" 라고 말합니다. 그리고 우리는 어떤 식으로든 3차원 공간에 위치시키는 회전을 적용한 다음, 그것을 다시 2차원 공간으로 밀어넣는 평면 사영을 적용합니다.",
  "n_reviews": 0,
  "start": 554.06,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "translatedText": "",
  "from_community_srt": "그리고 그녀에게 눈에 띈 것은 이 두 가지가 모두 선형 변환이라는 것입니다. 즉, 각각의 행렬을 하나의 행렬로 설명할 수 있으며, 전체 변환은 두 행렬의 곱처럼 보입니다.",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "translatedText": "",
  "from_community_srt": "Alice가 가장 좋아하는 과목 중 하나인 선형대수학에서 알고 있는 것은 어떤 형태를 취하고 그 면적을 고려한다면 선형 변환을 적용하면 그 결과의 면적은 원래 형태의 면적에 일정하게 곱한 것과 같다는 것입니다.",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "translatedText": "",
  "from_community_srt": "좀 더 구체적으로 말하면,",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation.",
  "translatedText": "",
  "from_community_srt": "변환의 행렬식(determinant)이라고 불리는 상수가 있습니다.",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "translatedText": "",
  "from_community_srt": "만약 여러분이 선형대수와 친하지 않다면, 훨씬 더 직관적인 설명을 할 수 있습니다. 그리고 만약 여러분이 원래의 모양을 어떤 방향으로 균일하게 늘린다면, 결과도 균일하게 어떤 방향으로 늘어날 것이라고 말할 수 있습니다.",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "translatedText": "",
  "from_community_srt": "따라서 각각의 면적은 서로 비례하여 확장되어야 합니다.",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now, in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "translatedText": "",
  "from_community_srt": "이제 Alice는 이 행렬식을 계산할 수 있습니다. 하지만 그것은 그녀가 원하는 방식이 아닙니다.",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "translatedText": "",
  "from_community_srt": "적어도 바로 계산하는 걸 말이죠. 대신 그녀가 기록하는 것은 우리의 원래 모양과, 그림자 사이의 비례 상수가 원래 모양에 의존하지 않는 방법입니다.",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "translatedText": "",
  "from_community_srt": "우리는 이 고양이의 그림자 또는 다른 것에 대해 이야기할 수 있으며 그 크기는 실제로 중요하지 않습니다.",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "translatedText": "",
  "from_community_srt": "비례 상수에 영향을 미치는 유일한 것은 우리가 적용하는 변환입니다. 그것은 모양에 적용되는 회전에 따라 달라지는 몇 가지 요소입니다.",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "translatedText": "",
  "from_community_srt": "Bob의 계산 덕분에 우리는 그 요소가 어떻게 보이는지 알고 있습니다.",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "translatedText": "",
  "from_community_srt": "법선 벡터와 수직선 사이의 각도의 코사인 절대값입니다.",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "translatedText": "",
  "from_community_srt": "하지만 지금 Alice는 \"ㅇㅇ 난 내가 원할 때 저걸 사용할 수 있어.\" 라고 말하고 있습니다.",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "translatedText": "",
  "from_community_srt": "그러나 그녀는, 우리가 어쨌든 모든 다른 방향에 대해 평균을 내고 있다는 것을 알고 있으므로 특정 방향에 대한 특정 공식이 그 평균에서 다 풀린다는 희망을 가지고 있습니다.",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well, Alice isn't really doing anything then.",
  "translatedText": "",
  "from_community_srt": "우리는 이걸 보면서 \"ㅇㅋ, Alice는 정말 아무것도 안 하고 있구나!\" 라고 쉽게 말할 거 같습니다.",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "translatedText": "",
  "from_community_srt": "물론 그림자의 면적은 원래 모양에 비례합니다, 둘 다 2차원 양이죠.",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 675.62,
  "end": 677.28
 },
 {
  "input": "They should both scale like two-dimensional things.",
  "translatedText": "",
  "from_community_srt": "둘 다 2차원적인 것 처럼 커져야 합니다.",
  "n_reviews": 0,
  "start": 677.38,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "translatedText": "",
  "from_community_srt": "하지만 만약 우리가 더 가까운 광원을 가진 더 어려운 경우를 다룬다면 이것은 전혀 사실이 아닐 것입니다.",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear.",
  "translatedText": "",
  "from_community_srt": "이 경우 사영은 선형이 아닙니다.",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow because the tail gets very disproportionately blown up as it gets really close to the light.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 제가 이 고양이를 회전시켜서 꼬리가 광원에 꽤 가까이 오도록 한 다음, 𝒙 방향으로 1.5배 정도 균일하게 원래 모양을 늘리면, 그 비율에 따라 매우 불균형한 영향을 미칠 수 있습니다. 왜냐하면 꼬리는 빛에 매우 가까이 다가갈수록 매우 불균형적으로 부풀어 오르기 때문입니다.",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant because that helps her know how much she can generalize things.",
  "translatedText": "",
  "from_community_srt": "다시 말하지만, Alice는 어떤 문제의 특성이 실제로 관련이 있는지 \"주시\"하고 있습니다. 이는 그녀가 사물을 얼마나 일반화 할 수 있는지를 알 수 있도록 도와주기 때문입니다.",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "translatedText": "",
  "from_community_srt": "우리가 다른 모양이 아닌 정사각형 면적에 대해 생각하고 있다는 사실이 중요한가요?",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "translatedText": "",
  "from_community_srt": "그건 아니죠. 변환이 선형이라는 사실이 중요한가요?",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely.",
  "translatedText": "",
  "from_community_srt": "네, 당근이죠.",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "translatedText": "",
  "from_community_srt": "Alice는 이와 같은 모든 모양의 평균 그림자에 대해서도 유사한 사고 방식을 적용할 수 있습니다.",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face.",
  "translatedText": "",
  "from_community_srt": "정사각형 면에 적용할 일련의 회전이 있다고 가정하고 \\n 𝑹₁, 𝑹₂, 𝑹₃ 등이라고 해보죠.",
  "n_reviews": 0,
  "start": 732.02,
  "end": 736.0
 },
 {
  "input": "And let's call them R1, R2, R3, and so on.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 736.58,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square.",
  "translatedText": "",
  "from_community_srt": "ㅊㄷ 그런 다음 각각의 경우에 그림자의 면적은 정사각형의 면적을 곱한 계수처럼 보이며 그 계수는 회전에 따라 다릅니다.",
  "n_reviews": 0,
  "start": 739.72,
  "end": 745.42
 },
 {
  "input": "And that factor depends on the rotation.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 745.42,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "translatedText": "",
  "from_community_srt": "따라서 우리가 지금 보고 있는 회전 표본에서 해당 그림자에 대한 평균을 취하고, 우리가 구하는건 해당 그림자 면적을 모두 더한 다음 우리가 가진 총 개수로 나누는 것입니다.",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "translatedText": "",
  "from_community_srt": "선형성 때문에, 원래 사각형의 이 면적은 한번에 묶을 수 있습니다.",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations.",
  "translatedText": "",
  "from_community_srt": "이것은 우리가 찾고 있는 정확한 평균이 아니라 회전 표본의 실증적인 평균일 뿐입니다.",
  "n_reviews": 0,
  "start": 767.2,
  "end": 772.2
 },
 {
  "input": "But in principle what we're looking for is what this approaches as the size of our sample approaches infinity.",
  "translatedText": "",
  "from_community_srt": "그러나 원칙적으로 우리가 찾고 있는 것은 표본의 양이 무한대로 갈수록 그 값이 어디로 수렴하는지 입니다.",
  "n_reviews": 0,
  "start": 772.2,
  "end": 777.64
 },
 {
  "input": "And all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "translatedText": "",
  "from_community_srt": "그리고 표본에 있는 모든 부분은 면적 자체랑 깔끔하게 떨어져 있습니다.",
  "n_reviews": 0,
  "start": 777.98,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "translatedText": "",
  "from_community_srt": "그래서 이것이 어디로 접근하든,",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "translatedText": "",
  "from_community_srt": "그 극한은 단지 어떤 숫자일 것입니다. 계산을 하는 것은 매우 어려울 수 있습니다. 아직 확실하지는 않지만 Alice가 주목하는 것은 우리가 보고 있는 특정한 2차원의 크기와 모양과는 무관하다는 것입니다.",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 795.72,
  "end": 798.0
 },
 {
  "input": "And her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "translatedText": "",
  "from_community_srt": "그것은 보편적인 비례 상수이고, 그녀의 희망은 그 보편성이 그것이 무엇인지 추론할 수 있는 더 우아한 방법에 어떻게 구실을 하는 것입니다.",
  "n_reviews": 0,
  "start": 798.46,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "translatedText": "",
  "from_community_srt": "이제 Bob은 지금 바로 이 상수를 계산하는 걸 원할 겁니다. 잠시 후에 Bob이 어떻게 계산하는지 보여드리겠습니다.",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "translatedText": "",
  "from_community_srt": "하지만 그 전에, 저는 \"Alice의 세계\"에 조금 더 머물겠습니다. 왜냐하면 여기서부터 모든 것이 정말 재미있어지기 시작하니까요.",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "translatedText": "",
  "from_community_srt": "세부 사항으로 넘어가기 전에 질문의 전체적인 구조를 이해하고자 하는 그녀의 바람으로, 그녀는 이제 큐브의 그림자 면적과 개별 면의 면적과 어떻게 연관되어 있는지에 대해 궁금해합니다.",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "translatedText": "",
  "from_community_srt": "우리가 특정 면의 평균 면적에 대해 말할 수 있다면, 큐브 전체의 평균 면적에 대해 알 수 있을까요?",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 우리가 간단히 말할 수 있는 것은 그 면적이 모든 면의 면적 합보다 적다는 것입니다. 왜냐하면 그 그림자 사이에는 겹침이 있기 때문입니다.",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all.",
  "translatedText": "",
  "from_community_srt": "하지만 그 겹침에 대해 어떻게 생각해야 할지 완전히 명확하지 않습니다.",
  "n_reviews": 0,
  "start": 849.64,
  "end": 858.38
 },
 {
  "input": "But in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "translatedText": "",
  "from_community_srt": "왜냐하면 우리가 두 개의 특정한 면적에만 집중한다면 어떤 방향에서는 전혀 겹치지 않지만 다른 방향에서는 겹침이 있기 때문입니다. 그 겹치는 부분의 구체적인 모양과 면적은 생각하기에 조금 까다로워 보입니다. 하물며 우리가 어떻게 모든 다른 방향에서 평균을 맞출지는 더더욱요.",
  "n_reviews": 0,
  "start": 858.46,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "translatedText": "",
  "from_community_srt": "하지만 Alice는 이 모든 문제에 관한 약 세 가지의 영리한 통찰력을 가지고 있는데, 다음이 그 중 첫 번째입니다.",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "translatedText": "",
  "from_community_srt": "그녀는 \"사실, 우리가 한 쌍의 면적이 아닌 전체 큐브에 대해 생각한다면, 우리는 주어진 방향에 대한 그림자 면적이 정확히 모든 면의 면적 합계의 1/2이라는 결론을 내릴 수 있어.\" 라고 말합니다.",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "translatedText": "",
  "from_community_srt": "직관적으로, 당신은 그들 중 절반이 빛을 받고, 그 중 절반이 아니라는 것을 추측 할 수 있습니다. 하지만 그녀가 정당화하는 방법은 이렇습니다.",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light that would go from the sky and eventually hit a point in the shadow, that ray passes through the cube at exactly two points.",
  "translatedText": "",
  "from_community_srt": "그녀는 특정 광선의 경우, 하늘에서 가다가 결국 그림자의 한 지점에 부딪히게 되고, 그 광선은 정확히 두 지점에서 큐브를 통과하게 된다고 말합니다.",
  "n_reviews": 0,
  "start": 895.82,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "translatedText": "",
  "from_community_srt": "빛의 들어가는 때와 나가는 때가 있습니다.",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "translatedText": "",
  "from_community_srt": "그래서 그림자의 모든 점은 정확히 그 위에 있는 두 개의 면과 일치합니다.",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "translatedText": "",
  "from_community_srt": "흐음... 네, 그건 정확히 사실이 아니에요.",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing.",
  "translatedText": "",
  "from_community_srt": "만약 그 광선이 정사각형의 모서리를 통과하게 된다면, 그 광선이 얼마나 많은 면을이 통과하는지 약간의 애매모호함이 있습니다.",
  "n_reviews": 0,
  "start": 919.6,
  "end": 922.32
 },
 {
  "input": "But those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "translatedText": "",
  "from_community_srt": "하지만 그림자의 안쪽 면적이 0이기 때문에 우리가 면적을 계산하는 것이라면 그 애매함을 무시해도 괜찮습니다.",
  "n_reviews": 0,
  "start": 922.72,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "translatedText": "",
  "from_community_srt": "만약 Alice가 왜 이것이 사실인지, 그리고 문제가 어떻게 일반화될 수 있는지를 이해하는 데 중요한 이유를 정당화할 필요가 있다고 압박 받는다면 그녀는 볼록성을 호소 할 겁니다.",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "translatedText": "",
  "from_community_srt": "볼록성은 우리 중 많은 사람들이 그것이 무엇을 의미해야 하는지에 대한 직관적인 감각을 가지고 있는 특성들 중 하나입니다. 보시다시피, 저건 그냥 튀어나온(볼록) 모양이에요, 절대 안쪽으로 들어가지 않죠.",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "translatedText": "",
  "from_community_srt": "수학자들은 증명에 도움이 되는 꽤 영리한 공식화 방법을 가지고 있습니다.",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "translatedText": "",
  "from_community_srt": "집합 내부의 두 점을 연결하는 선이 집합 자체에 완전히 포함되어 있으면 집합이 \"볼록\"하다고 말합니다.",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So, a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "translatedText": "",
  "from_community_srt": "그래서 정사각형은 볼록합니다. 왜냐하면 그 정사각형 안에 두 점을 어디에 두든, 그것들을 연결하는 선은 정사각형 안에 완전히 포함되기 때문입니다.",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex, I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "translatedText": "",
  "from_community_srt": "하지만 π 같은 것은 볼록하지 않습니다. 전 쉽게 집합에 삐져나온 두 점이 연결된 선을 찾을 수 있습니다.",
  "n_reviews": 0,
  "start": 970.28,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "translatedText": "",
  "from_community_srt": "\"convex\"라는 단어의 어떤 글자도 볼록하지 않습니다.",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "translatedText": "",
  "from_community_srt": "당신은 두 점을 연결하는 선이 집합 밖을 지나가는 두 점을 찾을 수 있습니다.",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out.",
  "translatedText": "",
  "from_community_srt": "이건 튀어나온 모양에 대한 아이디어를 공식화하는 정말 영리한 방법입니다.",
  "n_reviews": 0,
  "start": 987.46,
  "end": 991.42
 },
 {
  "input": "Because anytime that it dents inward, you can find these counterexample lines.",
  "translatedText": "",
  "from_community_srt": "왜냐하면 안쪽으로 움푹 들어간 부분이 있을 때마다 이러한 반례적인 선을 찾을 수 있기 때문입니다.",
  "n_reviews": 0,
  "start": 991.42,
  "end": 995.54
 },
 {
  "input": "Or, our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "translatedText": "",
  "from_community_srt": "우리의 큐브는 볼록하기 때문에, 첫 번째 입구와 마지막 출구 사이가 볼록성의 정의에 의해 정육면체 안에 완전히 있어야 합니다.",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "translatedText": "",
  "from_community_srt": "하지만 만약 우리가 도넛처럼 볼록하지 않은 다른 모양을 다루고 있다면, 여러분은 한번 더 들어오고 나가는 광선을 발견할 수 있습니다. 그러므로 당신은 깔끔한 2대1의 그림자를 얻지 못합니다.",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "translatedText": "",
  "from_community_srt": "다른 모든 부분의 그림자를 여러 면으로 덮는다면 그림자 자체의 면적이 정확히 두 배는 아닐 것입니다.",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "translatedText": "",
  "from_community_srt": "이것이 첫 번째 핵심 통찰입니다. 그 면의 그림자가 큐브의 그림자를 이중으로 덮습니다.",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "translatedText": "",
  "from_community_srt": "그리고 다음은 조금 더 상징적이기 때문에, 화면에 공간을 만들기 위해 우리의 표기법을 조금 줄여서 시작해보도록 하겠습니다.",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "translatedText": "",
  "from_community_srt": "Area(Shadow(Cube))을 S(Cube)로 쓰겠습니다.",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "translatedText": "",
  "from_community_srt": "그리고 Area(Shadow(a particular face))을 S(F_j)로 쓰겠습니다. 여기서 첨자 j는 제가 말하는 면의 위치를 나타냅니다.",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "translatedText": "",
  "from_community_srt": "하지만 물론 우리는 큐브에 적용된 특정 회전의 그림자에 대해 이야기해야 하므로, 큐브에 적용된 \"회전의 S\"로 써도 좋습니다. 그리고 오른쪽도 마찬가지로 주어진 면 중 하나에 적용된, 동일한 회전의 그림자 면적입니다.",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "translatedText": "",
  "from_community_srt": "보다 간결한 표기법을 사용하여 다양한 회전; R1, R2, R3 등의 일부 샘플에서 이 그림자 면적의 평균에 대해 생각해 보겠습니다.",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "translatedText": "",
  "from_community_srt": "다시 말씀드리지만, 그 평균은 모든 그림자 면적을 합한 다음 n으로 나누는 것입니다.",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "translatedText": "",
  "from_community_srt": "원칙적으로 우리가 이것을 더 많고많은 샘플에 대해 n이 무한대에 접근하게 된다면, 그것은 큐브의 그림자 면적의 평균이 될 것입니다.",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "translatedText": "",
  "from_community_srt": "여러분 중 일부는 \"ㅇㅇ, 우린 이걸 이미 알고 있어, 너가 그전에 말했잖아.\" 라고 생각할 겁니다. 그러나 큐브의 특정 회전에 대한 그림자 면적을 모든 면의 합계로 표현하거나, 적어도 합계의 1/2로 표현하는 이유를 이해할 수 있도록 작성하는 것이 좋습니다. 왜 이것이 좋을까요?",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us?",
  "translatedText": "",
  "from_community_srt": "그게 우리에게 무슨 도움이 될까요? 그냥...",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "translatedText": "",
  "from_community_srt": "일단 한번 적어보죠. 큐브의 각 회전마다 그림자를 모든 면에 적용되는 동일한 회전의 합으로 분해할 수 있는 부분을요.",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "translatedText": "",
  "from_community_srt": "이렇게 격자로 쓰여질 때, Alice의 두 번째 통찰을 얻을 수 있습니다. 즉, 합계에 대해 생각하는 방식을 행(가로 줄)에서 열(세로 줄)로 바꾸는 것입니다.",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 우리가 첫 번째 열에만 주의를 집중했다면, 그것은 많은 다른 방향에서 첫 번째 면의 그림자 면적을 더하라는 것을 말해줍니다.",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "translatedText": "",
  "from_community_srt": "따라서 그 합계를 표본 개수로 나누면 이 면의 그림자 면적에 대한 평균이 나옵니다.",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "translatedText": "",
  "from_community_srt": "그래서 만약 우리가 점점 더 큰 샘플을 가지고 그 개수를 무한대로 둔다면, 이것은 정사각형의 평균 그림자 면적에 접근할 것입니다.",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "translatedText": "",
  "from_community_srt": "마찬가지로, 두 번째 열은 큐브의 두 번째 면에 대한 평균 면적을 알려주는 것으로 생각할 수 있으며, 이 면적의 수는 물론 같아야 합니다.",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "translatedText": "",
  "from_community_srt": "다른 열에도 마찬가지입니다. 특정 면의 평균 면적을 알려줍니다.",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "translatedText": "",
  "from_community_srt": "그래서 그것은 우리에게 전체의 표현에 대해 매우 다른 사고 방식을 제공합니다.",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "translatedText": "",
  "from_community_srt": "모든 다른 방향에서 큐브의 면적을 합친다고 말하는 대신, 우리는 단지 여섯 개의 다른 면에 대한 평균 그림자를 더하고 합계에 1/2을 곱한다고 말할 수 있습니다.",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "translatedText": "",
  "from_community_srt": "왼쪽의 용어는 먼저 행을 추가하는 것에 대해 생각하고 있으며 오른쪽의 용어는 먼저 열을 추가하는 것에 대해 생각하고 있습니다.",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "translatedText": "",
  "from_community_srt": "즉, 면의 그림자의 합의 평균은 면의 그림자의 평균의 합과 같습니다.",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "translatedText": "",
  "from_community_srt": "어쩌면 교환이 단순 해 보일 수도 그러지 않을 수도 있지만, 우리가 방금 한 행동에는 실제로 그 이상의 것이 있다는 것을 말씀드릴 수 있습니다. 하지만 그건 나중에 얘기하죠.",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "translatedText": "",
  "from_community_srt": "그리고 우리는 특정 면의 평균 면적이, 비례 상수가 그 면적을 곱한 것처럼 보인다는 걸 알고 있습니다.",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "translatedText": "",
  "from_community_srt": "그래서 만약 우리가 이것을 큐브의 모든 면에 걸쳐서 합친다면, 우리는 이것을 큐브의 표면적의 일정 배와 동일하다고 생각할 수 있습니다.",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "translatedText": "",
  "from_community_srt": "흥미로운 점은, 이 큐브의 그림자의 평균 면적이 그것의 표면적에 비례한다는 것입니다.",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "translatedText": "",
  "from_community_srt": "하지만 동시에, 여러분은 불평할지도 모릅니다. \"Alice는 단지 수많은 기호들을 막 쓰고 있어요!! 어차피 우리가 그 비례 상수가 뭔지 모른다면 이 모든 것이 중요하지 않잖아요!!\"",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "translatedText": "",
  "from_community_srt": "제 말은 거의 분명한 것처럼 보인다는 거죠. 물론,",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "translatedText": "",
  "from_community_srt": "평균 그림자 면적은 표면적에 비례해야 하고, 둘 다 2차원 크기이므로, 서로 보조를 맞춰야 합니다. 하지만 그건 분명하지 않죠.",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious.",
  "translatedText": "",
  "from_community_srt": "결국,",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "translatedText": "",
  "from_community_srt": "더 가까운 광원이라면 그것은 사실이 아닐 것입니다.",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "translatedText": "",
  "from_community_srt": "그리고 우리가 한 열씩, 한 행씩 식을 더하는 이 일은 처음보다 미묘한 차이가 있고,",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "translatedText": "",
  "from_community_srt": "우리가 모든 방향에서 어떤 확률분포를 취하는지 다시 생각하기로 할 때, 어떤 특별한 의미가 있는 미묘한 차이를 보입니다.",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "translatedText": "",
  "from_community_srt": "하지만 무엇보다도, 이것이 분명하지 않은 이유는 이 결과의 의미가, 이 두 값이랑 비례한 것이 아니기 때문입니다.",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "translatedText": "",
  "from_community_srt": "그것은 어떤 볼록 다면체에 대해서도 유사한 사실일 것이고, 결정적으로 Alice가 지금까지 해왔던 것은, 모든 것이 동일한 비례 상수가 적용된다는 것입니다.",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "translatedText": "",
  "from_community_srt": "만약 여러분이 그것에 대해 정말 곰곰이 생각한다면, 여러분 중 일부는 Alice가 여기서 어떻게 이 문제를 끝낼 수 있을지 예측할 수 있을 것입니다.",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful, it's honestly my main reason for covering this topic.",
  "translatedText": "",
  "from_community_srt": "정말 기분이 좋네요, 이것이 솔직히 제가 이 주제를 다루게 된 이유입니다.",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "translatedText": "",
  "from_community_srt": "하지만 우리가 그것에 대해 이야기하기 전에, 그녀가 피하려고 하는 것이 무엇인지에 대한 세부 사항을 파고들지 않는 한, 그녀의 결과를 과소평가할 것 같습니다.",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "translatedText": "",
  "from_community_srt": "그럼 잠시 Bob의 세계로 돌아가보죠. Alice가 이 모든 것을 하는 동안, 그는 몇 가지 계산을 하느라 바빴으니까요.",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "translatedText": "",
  "from_community_srt": "사실, 그가 연구한 것은 Alice가 아직 알아내지 못한 것, 즉 정사각형의 그림자 면적에 대해 찾은 공식을 찾는 것입니다. 그리고 가능한 모든 방향에서 그 정사각형의 그림자의 평균을 구하는 자연스러운 다음 단계를 밟는 것입니다.",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "translatedText": "",
  "from_community_srt": "Bob 방식에서, 만약 Bob이 이 정사각형의 가능한 모든 방향에 대해 생각하고 있다면, 그 정사각형이 이 모든 방향에서 가질 수 있는 모든 다른 법선 벡터는 무엇인지 물어보는 것입니다. 왜냐하면 그림자에 대한 모든 것은 법선 벡터로 설명되기 때문입니다.",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere, if we assume it's a unit normal vector, it's a sphere with radius 1.",
  "translatedText": "",
  "from_community_srt": "모든 가능한 법선 벡터가 구의 표면을 추적하는 것을 보는 것은 그리 어렵지 않습니다. 법선 벡터를 단위 벡터라고 가정하면 반지름이 1인 구가 됩니다.",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "translatedText": "",
  "from_community_srt": "게다가 Bob은 구의 각 점이 다른 점들과 마찬가지로 존재할 가능성이 있어야 하며, 우리의 확률이 균일해야 한다고 생각합니다.",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way, there's no reason to prefer one direction over another.",
  "translatedText": "",
  "from_community_srt": "한 방향을 다른 방향보다 선호할 이유가 없습니다.",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "translatedText": "",
  "from_community_srt": "하지만 연속적인 확률의 맥락에서, 특정 점의 대해 가능성을 말하는 것은 그다지 도움이 되지 않습니다. 왜냐하면 셀 수 없는 구 위에 무한개의 점들은 0이고 도움이 되지 않기 때문입니다.",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "translatedText": "",
  "from_community_srt": "그래서 이 균일성을 표현하는 더 정확한 방법은, 법선 벡터가 구의 주어진 면적에 있을 확률이 그 면적 자체에 비례하는 것입니다.",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "translatedText": "",
  "from_community_srt": "좀 더 구체적으로 말하면, 그것은 작은 조각의 면적을 구의 총 표면적으로 나눈 것과 같아야 합니다.",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "translatedText": "",
  "from_community_srt": "만약 그것이 사실이라면, 우리가 어떤 부분을 고려하고 있든지 간에, 그것이 우리가 말하는 구면의 균일한 분포입니다.",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom, the square could be rotated about that normal vector.",
  "translatedText": "",
  "from_community_srt": "확실히 하자면, 구면의 점들은 3차원 공간의 방향과 같지 않습니다. 왜냐하면 정사각형이 어떤 법선 벡터를 가질지 안다고 해도 우리에게 다른 자유도를 남기니까요. 정사각형은 법선 벡터를 중심으로 회전할 수 있습니다. (자유도:",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same, it's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "translatedText": "",
  "from_community_srt": "값에는 영향이 없지만 변화를 줄 수 있는 원소 수) 하지만 Bob은 그 추가적인 자유도에 대해 신경 쓸 필요가 없습니다. 왜냐하면 그림자의 면적은 모두 같기 때문입니다.",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat, all those shadows are genuinely different shapes, they're not the same, but the area of each of them will be the same.",
  "translatedText": "",
  "from_community_srt": "그림자는 수직선과 법선 벡터의 cos(θ) 에만 의존하는데, 꽤 깔끔하죠. 이 모든 그림자들은 정말로 다른 모양이고, 똑같지 않습니다. 하지만 각각의 면적은 같을 것입니다.",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "translatedText": "",
  "from_community_srt": "이것은 Bob이 모든 가능한 방향에서 이 평균 그림자 면적을 원할 때, 그가 정말로 알아야 하는 것은 모든 가능한 법선 벡터, 구에서 모든 가능한 점들에 대한 |cos(θ)|의 평균값입니다.",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "translatedText": "",
  "from_community_srt": "그렇다면 이러한 평균을 어떻게 계산할 수 있을까요? 만약 우리가 법선 벡터가 가질 수 있는 가능한 각의 수가 한정되어 있는, 픽셀로 나눠진 세계라면 평균은 매우 간단할 것입니다.",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "translatedText": "",
  "from_community_srt": "여러분이 찾아야 하는 것은 θ가 어떤 특정 값에 있을 확률을 구하는 것입니다. 이것은 구가 그 각도로 얼마나 많은 법선 벡터를 구성하는지 알려줍니다. 그리고 그 각도에 대해 우리가 얻고자 하는 공식에 그림자의 면적에 대한 공식을 곱하는 것입니다.",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "translatedText": "",
  "from_community_srt": "그리고 0° ~ 180° 또는 π라디안 구간에서 θ의 모든 가능한 값에 더하면 됩니다.",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "translatedText": "",
  "from_community_srt": "(π rad = 180°) 하지만 현실에는 셀 수 없는 무한한 θ의 가능한 값의 연속체가 존재하며, θ가 특정 값에 있을 확률은 실제로 0이 될 것입니다.",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "translatedText": "",
  "from_community_srt": "그래서 불행하게도 이와 같은 합은 말이 안됩니다. 만약 된더라도, 0을 무한히 더해도 그저 0 입니다.",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "translatedText": "",
  "from_community_srt": "대신 우리가 하는 일의 간단한 대답은 적분을 하는 것입니다.",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "translatedText": "",
  "from_community_srt": "솔직히 말씀드리자면, 제가 여기서 가장 어려운 것은 지금 이걸 보는 여러분을 어떻게 가정해야 할지 잘 모르겠다는 것입니다.",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "translatedText": "",
  "from_community_srt": "아마 여러분이 미적분학에 꽤 익숙해서 제가 요점을 굳이 말 안해도 된다는거죠.",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "translatedText": "",
  "from_community_srt": "또는 미적분학에 익숙하지 않은 경우에 제가 적분만을 그렇게 표시해서는 안 될 것 같아요. 또는 여러분이...",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you, you know, you took a calculus class a while ago, but you need a little bit of a refresher.",
  "translatedText": "",
  "from_community_srt": "만약... 흠.. 얼마 전에 미적분 수업을 들으셨는데, 조금은 복습이 필요할 수도 있고요.",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "translatedText": "",
  "from_community_srt": "저는 그냥 미적분학 수업인 것처럼 하겠습니다. 왜냐하면 솔직히 말하면, 여러분이 적분에 익숙해도 적분하는 것은 오류가 발생하기 쉬운 과정이 될 수 있고, 그 과정에서 자신을 점검하는 좋은 방법이 될 수 있기 때문입니다.",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for theta that ranges from 0 up to 180 degrees.",
  "translatedText": "",
  "from_community_srt": "만약 우리가 미적분학이 존재하기 전의 시대에 살았고 적분이 존재하지 않을 때 우리가 이 질문에 대한 해답을 찾고 싶다면, 우리가 할 수 있는 한 가지 방법은 0° ~ 180°까지의 θ 값의 샘플을 쓰는 것입니다.",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta theta.",
  "translatedText": "",
  "from_community_srt": "우리는 각들이 일정한 간격을 두고 있다고 생각할 수 있습니다. Δθ 처럼요.",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of theta occurring, even if it's 1 in our sample.",
  "translatedText": "",
  "from_community_srt": "그리고 우리의 샘플에서 θ의 특정 값이 발생할 확률에 대해 묻는 것은 여전히 도움이 되지 않습니다. 그 확률은 여전히 0일 것이고,",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "translatedText": "",
  "from_community_srt": "도움이 되지 않을 것입니다.",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta theta.",
  "translatedText": "",
  "from_community_srt": "하지만 도움이 되는것은, 작은 길이인 Δθ가 우리의 샘플에 다른 두 값 사이에 있을 확률입니다.",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "translatedText": "",
  "from_community_srt": "구를 따라 분포가 균일하다는 우리의 가정에 따르면, 그 확률은 이 띠의 면적을 알아야 하는 것으로 이르게 됩니다.",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "translatedText": "",
  "from_community_srt": "더 구체적으로, 무작위로 선택된 벡터가 그 띠에 있을 확률은 그 면적을 구의 총 표면적으로 나눈 값이어야 합니다.",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "translatedText": "",
  "from_community_srt": "그 면적을 알아내기 위해 먼저 그 띠의 반지름을 생각해 봅시다. 만약 구의 반지름이 1이라면, 띠의 반지름은 분명히 1보다 작을 것입니다.",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of theta.",
  "translatedText": "",
  "from_community_srt": "그리고 여기에 적절한 작은 직각삼각형을 그려보면, 띠 위 쪽 부분을 sin(θ)라고 할 수 있습니다.",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2 pi times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta theta.",
  "translatedText": "",
  "from_community_srt": "즉, 띠의 둘레는 2π sin(θ) 입니다. 그리고 띠의 면적은 둘레에 두께를 곱한 2π sin(θ) Δθ 입니다.",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "translatedText": "",
  "from_community_srt": "우리 밴드의 면적은 대략 이 정도입니다.",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of theta, the accuracy of that approximation would get better and better.",
  "translatedText": "",
  "from_community_srt": "중요한 것은 θ를 더 미세하게 할 수록 근사치의 정확도가 점점 더 향상된다는 것입니다.",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4 pi times its radius squared.",
  "translatedText": "",
  "from_community_srt": "우리가 이 면적을 원했던 이유는 이 면적이 {4π ⨉ 반지름²}인 구의 표면적으로 나눈 띠에 있을 확률을 알기 위해서 입니다.",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "translatedText": "",
  "from_community_srt": "이 값은 현재 설정 중인 것과 유사한 적분으로 계산할 수도 있지만, 지금은 잘 알려진 공식으로 쓸 수 있습니다.",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "translatedText": "",
  "from_community_srt": "그리고 이 확률 자체는 우리가 실제로 원하는 방향으로의 디딤돌인데, 이것은 바로 정사각형의 그림자에 대한 평균 면적입니다.",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosine theta expression we've seen many times up to this point.",
  "translatedText": "",
  "from_community_srt": "이를 위해 우리는 이 확률에 해당하는 그림자 면적을 곱할 것입니다. 이는 지금까지 여러 번 봤던 |cos(θ)| 입니다.",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of theta that we've taken.",
  "translatedText": "",
  "from_community_srt": "그리고 이 평균에 대한 우리의 예측은 우리가 얻은 θ의 모든 다른 샘플과 다른 띠들로 이루어진 이 공식을 더하는 것으로 이르게 됩니다.",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "translatedText": "",
  "from_community_srt": "이건 바로 Bob이 가장 편하게 느끼는 상황입니다.",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "translatedText": "",
  "from_community_srt": "우리는 매우 구체적인 것들을 설명하는 정확한 공식들을 많이 가지고 있습니다. 우리가 진짜 답을 찾기 위해서 말이죠.",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "translatedText": "",
  "from_community_srt": "그리고 다시 말씀드리지만, 만약 여러분이 이 과정들을 이해하셨으면 합니다. 그래야 Alice가 이 모든 과정을 어떻게 피했는지 얼마나 신비로운지 알 수 있을 겁니다.",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on theta itself.",
  "translatedText": "",
  "from_community_srt": "어쨌든, 우리의 공식을 다시 보면, θ랑 관련없는 기호들을 뽑아내고, 식을 조금 정리해보도록 하겠습니다.",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2 pi divided by 4 pi to simply be 1 half.",
  "translatedText": "",
  "from_community_srt": "그리고 우리는 2π/4π을 단순하게 1/2으로 만들 수 있습니다.",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "translatedText": "",
  "from_community_srt": "미적분학에서 적분과 조금 더 유사하게 만들기 위해, 여기 합 안에 있는 주요 식들을 교환 하겠습니다.",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "translatedText": "",
  "from_community_srt": "우리가 지금 가지고 있는 것; 우리의 질문에 대한 답은 거의 적분입니다.",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to pi.",
  "translatedText": "",
  "from_community_srt": "Σ 대신에 적분 기호를 쓰고, 이렇게 길쭉한 라이프니츠 S (적분 기호)는 우리가 0에서 π로 가는 것을 보여줍니다.",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as delta theta, a concrete finite amount, we instead describe it as d theta, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "translatedText": "",
  "from_community_srt": "간격 크기를 Δθ로 표현하는 대신 \"dθ\"라고 표현하겠습니다. 저는 이것을 어떤 극한 값이 있다고 알려주는 신호로 생각하겠습니다.",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions.",
  "translatedText": "",
  "from_community_srt": "그 적분이 의미하는 바는, 정의상, 밑에 있는 합이 더 미세하게 접근할수록,",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1753.58
 },
 {
  "input": "More dense samples that we might take for theta itself.",
  "translatedText": "",
  "from_community_srt": "우리는 더 밀도 높은 샘플을 얻을 수 있는 겁니다.",
  "n_reviews": 0,
  "start": 1753.58,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "translatedText": "",
  "from_community_srt": "이 시점에서, 미적분을 아시는 분들을 위해, 제가 Bob의 노트에 적는 것처럼 이 계산을 어떻게 수행할지에 대한 자세한 사항을 적어보겠습니다.",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "translatedText": "",
  "from_community_srt": "이것은 일반적인 부정적분이지만, 여기서 중요한 한 단계는 삼각함수 항등식을 쓰는 것입니다.",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "translatedText": "",
  "from_community_srt": "결국, Bob 이걸 계산한 후에 발견한 것은 정사각형의 그림자의 평균 면적이 정확히 그 정사각형의 면적의 1/2이라는 놀랍도록 깔끔한 사실입니다.",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "translatedText": "",
  "from_community_srt": "이것은 Alice가 아직 모르는 미스터리한 상수입니다.",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "translatedText": "",
  "from_community_srt": "만약 Bob이 그녀의 어깨 너머로 그녀가 한 일을 본다면, 그는 지금 당장 그 문제를 끝낼 수 있을 거예요.",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "translatedText": "",
  "from_community_srt": "그는 방금 찾은 상수를 대입하고 드디어 최종 답을 알게 됩니다.",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "translatedText": "",
  "from_community_srt": "그리고 이제, 드디어!!! 이 모든 것을 배경으로 내버려 둔 Alice는 최종 해결책을 얻기 위해 무엇을 할까요?",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "translatedText": "",
  "from_community_srt": "저는 그녀를 자신이 발견한 결과를 일반화하는 것을 정말 좋아하는 사람이라고 소개했었습니다.",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "translatedText": "",
  "from_community_srt": "그리고 보통 그러한 일반화는 특정한 문제를 해결하는 데 별로 중요하지 않은 흥미로운 각주로 끝나게 됩니다.",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "translatedText": "",
  "from_community_srt": "하지만 이 문제는 일반화 자체가 그녀를 의미있는 결과로 이끄는 경우입니다. 기억하세요.",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area.",
  "translatedText": "",
  "from_community_srt": "그녀가 지금까지 발견한 것은, 여러분이 어떤 볼록한 다면체를 본다면, 그것의 그림자의 평균 면적은 그것의 표면적에 비례한다는 것입니다.",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1831.68
 },
 {
  "input": "And critically, it'll be the same proportionality constant across all of these solids.",
  "translatedText": "",
  "from_community_srt": "그리고 중요한 것은, 이 모든 다면체의 비례 상수가 같다는 것입니다.",
  "n_reviews": 0,
  "start": 1832.18,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "translatedText": "",
  "from_community_srt": "그래서 Alice가 해야 할 일은 그림자의 평균 면적을 이미 알고 있는 볼록 다면체를 찾는 것입니다.",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going.",
  "translatedText": "",
  "from_community_srt": "그리고 여러분 중 일부는 뭘 찾을지 알 것이고,",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "translatedText": "",
  "from_community_srt": "우리가 이용할 수 있는 대칭적인 다면체는 구입니다.",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of pi r squared.",
  "translatedText": "",
  "from_community_srt": "그 구의 방향이 어떻든 간에, 그것의 평평한 사영 그림자는 항상 원의 넓이인 πr² 입니다.",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "translatedText": "",
  "from_community_srt": "그것은 그림자의 평균 면적입니다.",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4 pi r squared.",
  "translatedText": "",
  "from_community_srt": "그리고 구의 표면적은, 제가 전에 언급했듯이, 정확히 4πr^2 입니다.",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "translatedText": "",
  "from_community_srt": "저는 표면적 공식에 대한, 그리고 미적분이 존재하기 수천년 전에 아르키메데스가 그것을 어떻게 증명했는 지 비디오를 만들었습니다.",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact that the shadow of a sphere has an area exactly 1 fourth its surface area and use it to conclude a much more general fact that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "translatedText": "",
  "from_community_srt": "따라서 저걸 구하는 것에 적분이 필요하지 않습니다. Alice가 한 마법은 구체로 보이는 이 사실을 받아들이고, 구의 그림자가 정확히 표면적의 1/4을 가지고 있다는 것을 결론지을 수 있다는 것입니다. 그리고 그 그림자와 표면적은 어떤 의미에서는 어느 다면체라도 같은 방식으로 연관되어 있다는 사실로 결론지을 수 있습니다.",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube and say that its average shadow area will be 1 fourth times its surface area, 6 s squared.",
  "translatedText": "",
  "from_community_srt": "그래서 그녀는 큐브에 대한 특정 질문의 세부 사항을 맞추고 평균 그림자 면적이 큐브의 표면적인 6s^2의 1/4가 될 것이라고 말할 수 있습니다.",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "translatedText": "",
  "from_community_srt": "하지만 그녀가 잠을 자면서도 생각할 훨씬 더 기억에 남는 사실은 우리가 큐브에 대해 이야기하고 있는 것이 전혀 중요하지 않다는 것입니다.",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument because spheres don't have flat faces.",
  "translatedText": "",
  "from_community_srt": "자, 이 모든 과정이 매우 아름답지만, 여러분 중 일부는 이것이 타당한 주장이 아니라고 불평할 수 있습니다. 왜냐하면 구체는 평평한 면이 아니기 때문입니다.",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "translatedText": "",
  "from_community_srt": "제가 Alice의 주장이 어떤 볼록한 다면체로 일반화된다고 말했을 때 실제로 우리가 그 주장 자체를 본다면, 그것은 분명히 한정된 수의 평평한 면에만 사용할 수 있습니다.",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1 half times the sum of the areas of the shadows of all its faces.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 만약 우리가 그것을 12면체에 적용한다면, 당신은 그 12면체의 특정한 그림자의 면적이 모든 면의 그림자 면적의 합계의 정확히 1/2처럼 보인다고 말할 것입니다.",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "translatedText": "",
  "from_community_srt": "다시 당신은 그 결론을 도출하기 위해 볼록성과 연관된 특정 광선을 사용할 수 있습니다.",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid where we can then go column by column and consider the average area for the shadow of each face.",
  "translatedText": "",
  "from_community_srt": "그림자를 여러 회전의 평균의 합으로 표현할 때 그 합을 큰 행렬로 설명할 수 있다는 점을 기억합시다. 여기서 한 열씩 이동하여 각 면의 그림자에 대한 평균 면적을 고려할 수 있습니다.",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "translatedText": "",
  "from_community_srt": "또한 중요한 사실은 2D 물체(중요한)에 대한 평균 그림자는 면적에 일정한 비례 상수를 곱한 것과 같다는 훨씬 이전의 결론이었습니다.",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "translatedText": "",
  "from_community_srt": "중요한 점은 그 상수가 모양 자체에 관련이 없다는 것입니다.",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "translatedText": "",
  "from_community_srt": "뭐가 됐든 정사각형이나 고양이, 또는 12면체의 오각형 면일 수도 있습니다.",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "Though, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "translatedText": "",
  "from_community_srt": "그래서 이것을 급하게 평평한 면의 수가 있지 않은 구에 적용하고, 여러분은 불평할 수도 있습니다.",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "translatedText": "",
  "from_community_srt": "하지만 다행히, 그것은 이해하기 쉬운 사항입니다.",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "translatedText": "",
  "from_community_srt": "여러분이 할 수 있는 것은 연속적으로 구에 근접하는 다른 다면체들의 순서를 상상하는 것입니다. 그들의 면이 구체의 표면 주변을 점점 더 껴안는다는 의미에서 말이죠.",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "translatedText": "",
  "from_community_srt": "각각의 근사치에 대해, 우리는 그것의 평균 그림자가 이 비례 상수로 그것의 표면적에 비례한다는 동일한 결론을 도출할 수 있습니다.",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "translatedText": "",
  "from_community_srt": "그러고 나면 우리는 \"ㅇㅋ, 각 단계의 평균 그림자 면적과 각 단계의 표면적 사이의 비율을 극한으로 취하자...\" 라고 말할 겁니다. 음, 그 비율은 절대 변하지 않기 때문에, 항상 이 상수와 같습니다. 그리고 극한에서도 그 상수와 같을 것입니다.",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "translatedText": "",
  "from_community_srt": "반면에 정의에 의해, 극한에서 평균 그림자 면적은 그 원인 πr²이고, 극한에서 표면적은 구의 표면인 4πr²입니다.",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "translatedText": "",
  "from_community_srt": "그래서 우리는 직관적으로 결론을 얻습니다. 하지만 Alice의 이 주장과 마찬가지로, 우리는 그 직관을 어떻게 정당화 할 수 있는지 조금 더 섬세해야 합니다.",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "translatedText": "",
  "from_community_srt": "Alice와 Bob의 이 차이가 가치 판단처럼 다가오기는 쉽습니다. 마치 제가 \"Alice가 얼마나 영리한지 보세요! 그녀는 통찰력 있게 Bob이 했던 계산을 안 했다고요!.\" 라고 말하는 것 처럼요.",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "translatedText": "",
  "from_community_srt": "하지만 그건 아주... 잘못된 결론이에요.",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "translatedText": "",
  "from_community_srt": "전 수학의 대중화와 실제로 수학을 하는 느낌이 다른 중요한 뭔가가 있다고 생각합니다.",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "translatedText": "",
  "from_community_srt": "계산을 안해도 되는 몇 가지 영리한 통찰력이 말만 번지르르한 증명을 보여준다는 편견이 있습니다.",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "translatedText": "",
  "from_community_srt": "저는 이 영상을 계획하면서 죄책감을 느꼈지만, 여기 화면 반대편에 있는 여러분에게 말할 수 있는 것은 Bob의 접근 방식보다 Alice의 접근 방식에 대한 영상을 만드는 것이 훨씬 더 매력적이라고 느낀다는 것입니다.",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "translatedText": "",
  "from_community_srt": "우선 첫째로, Alice의 추론 방식이 재미있다는 것입니다. Alice 방식에는 \"ㅇㅎ\" 하는 순간들이 있습니다.",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "translatedText": "",
  "from_community_srt": "하지만 결정적으로, 당신이 그것을 설명하는 방법은 매우 넓은 범위의 수학적 배경에서 거의 같습니다.",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "translatedText": "",
  "from_community_srt": "Bob의 접근법에 대한 영상을 찍는 것은 덜 매력적이지만, 계산을 하는게 나쁘기 때문은 아닙니다. 제 말은, 솔직히 계산은 매력적이지 않습니다. 하지만 계산을 설명하는 적절한 속도는 여러분들의 다른 수학적 배경에 따라 매우 다르게 보이는 것이 실용주의적인 현실입니다.",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "translatedText": "",
  "from_community_srt": "지금 보시는 것과 같이 여러분은 온라인으로 수학 영상을 소비하고 있습니다. 그리고 저는 여러분이 이러한 편견을 인식할 필요가 있다고 생각합니다.",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "translatedText": "",
  "from_community_srt": "문제 해결에 대한 진정한 교훈을 얻는 것이 목표라면, 매끄러운 증명에 너무 집중하면 정직하지 못할 위험이 있습니다.",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 만약 우리가 여기서 도전적인 태도가 되서 더 가까운 광원을 가진 경우에 대해 물어본다고 가정해 보겠습니다.",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "translatedText": "",
  "from_community_srt": "제가 아는 한 에서는 구와 원이 관련 돼있다고 보는 Alice와 비슷할 매끄러운 해결책은 없습니다.",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "translatedText": "",
  "from_community_srt": "훨씬 더 생산적인 워밍업은 Bob의 접근법인 미적분이었을 것입니다.",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "translatedText": "",
  "from_community_srt": "이 문제의 역사를 살펴보면, 이것은 1832년에 코시에 의해 증명되었습니다. 그리고 우리가 그의 손으로 쓴 노트를 훑어보면, Alice의 방식보단 Bob의 방식과 훨씬 더 비슷해 보입니다.",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "translatedText": "",
  "from_community_srt": "여기 11페이지 상단에서 여러분과 제가 중간에 설정한 것과 본질적으로 같은 것이 무엇인지 보실 수 있습니다.",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "translatedText": "",
  "from_community_srt": "반면에, 논문의 전체 프레임은 큐브의 경우처럼 특정한 것이 아닌 일반적인 사실을 찾는 것입니다.",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "translatedText": "",
  "from_community_srt": "그래서 만약 우리가 이 두 가지 마음가짐이 새로운 수학을 발견하는 행위와 관련이 있는지를 묻는다면, 정답은 거의 확실히 두 가지 모두의 혼합이어야 할 것입니다.",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "translatedText": "",
  "from_community_srt": "하지만 저는 많은 사람들이 계산에 열중하는 부분에 가중치를 두지 않는 것을 제안합니다.",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "translatedText": "",
  "from_community_srt": "그리고 제가 만든 영상들이 그 제안을 기여한다고 생각합니다.",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "translatedText": "",
  "from_community_srt": "제가 수학자 Alex Kontorovich와 함께 했던 팟캐스트에서 그는 직관을 쌓기 위한 계산 훈련의 중요성이 종종 과소평가되고 있다고 말했습니다. 새로운 수업에 참여하는 학생이든, 새로운 학문 분야에 참여하는 실습 연구 수학자든 말이죠.",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "translatedText": "",
  "from_community_srt": "어떤 청취자가 실제로 그 부분이 어떤 인상을 주었는지 강조하기 위해 글을 썼습니다. 그들은 박사과정 학생이고,",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "translatedText": "",
  "from_community_srt": "그들의 수학적 능력이 점점 퇴색하기 시작하는 것을 걱정한다고 설명했습니다. 그들은 나이가 들고 덜 예리해진 탓으로 돌렸습니다.",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "translatedText": "",
  "from_community_srt": "하지만 실제 수학자가 새로운 것을 배우기 위해, 수백 가지의 구체적인 예시를 수행하는 것의 중요성에 대해 이야기하는 것을 들은 것은, 분명히 그들의 관점을 바꾸었습니다.",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "translatedText": "",
  "from_community_srt": "다시 말해, 이것을 인식하는 것은 그들의 전망과 결과를 완전히 바꾸어 놓았습니다.",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, you know, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "translatedText": "",
  "from_community_srt": "역사에서 뉴턴, 오일러, 가우스 등.. 모든 유명한 수학자들을 보면 지루한 계산을 하는 데 무한한 인내심을 가지고 있습니다.",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "translatedText": "",
  "from_community_srt": "계산을 피할 수 있는 통찰을 보여주기 위해 편향되는 아이러니는, 사람들이 종종 그 통찰을 찾기 위해 직관력을 훈련시키는 방법은, 산더미처럼 쌓여있는 계산이라는 것입니다.",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "translatedText": "",
  "from_community_srt": "Alice의 사고방식이 없었다면 분명 뭔가가 없었을 겁니다.",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "translatedText": "",
  "from_community_srt": "제 말은 우리가 큐브에서만 이 문제를 해결한다면 얼마나 슬플까 생각해보세요. 그리고 우리가 숲을 보기 위해 나무 쪽으로 나가지도 않고, 숲을 매우 일반적인 사실이라고 이해한다면요.",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "translatedText": "",
  "from_community_srt": "만약 수학이 단순히 여러분에게 제기되는 질문에 답하는 것이 아니라 새로운 아이디어와 구조를 도입하는 것이라는 점을 생각한다면, Alice의 접근 방식에 대한 한 가지 재미있는 점은 볼록성의 아이디어를 정량화하는 재미있는 방법을 제안한다는 것입니다.",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by four, divide it by the surface area, and if that number is one, you've got a convex solid, but if it's less than one, it's non-convex, and how close it is to one tells you how close it is to being convex.",
  "translatedText": "",
  "from_community_srt": "단순히 예/아니오로 대답하는 대신, 볼록한지 않은지에 대해서 우리는 다음과 같이 숫자를 쓰면서 말할 수 있습니다. 어떤 다면체의 그림자의 평균 면적에 4를 곱하고 표면적으로 나누면 볼록한 다면체가 됩니다. 하지만 1보다 작으면 볼록하지 않고, 1에 얼마나 가까운지는 볼록에 얼마나 가까운지 알 수 있습니다.",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "translatedText": "",
  "from_community_srt": "또한, Alice 해법의 좋은 점 중 하나는 왜 수학자들이 때때로 일반성과 추상화에 대한 특이한 열광을 가지는 이유를 설명하는 데 도움이 된다는 것입니다.",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "translatedText": "",
  "from_community_srt": "일반화와 추상화가 실제로 특정 사례를 해결하는 데 도움이 되는 예를 더 많이 볼수록 여러분도 동일한 열광을 받아들이기 시작합니다.",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who've stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "translatedText": "",
  "from_community_srt": "그리고 마지막으로, 여기까지 버텨온 여러분 중 충실한 시청자에게는 우리 퍼즐의 바로 그 전제에 대해 아직 풀리지 않은 질문이 하나 있습니다.",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "translatedText": "",
  "from_community_srt": "무작위로 방향을 선택한다는 것이 정확히 무엇을 뜻할까요? 그게 바보 같은 질문으로 느껴진다면,",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "translatedText": "",
  "from_community_srt": "물론 우리는 그것이 무엇을 의미하는지 알고 있습니다. 제가 방금 Numberphile과 함께 풀었던 \"Bertrand's Paradox\"라는 수수께끼의 영상을 보시길 권하고 싶습니다.",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answered this question.",
  "translatedText": "",
  "from_community_srt": "여러분이 그것을 본 후에, 그리고 여러분이 거기서 진행되는 뉘앙스의 일부분을 본다면, 여러분의 숙제는 Alice와 Bob 이 질문에 대한 대답을 되돌아보는 것입니다.",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations is not at all obvious.",
  "translatedText": "",
  "from_community_srt": "Bob의 경우는 비교적 간단하지만 Alice가 모든 방향의 공간에 대한 특정 분포를 고정하는 지점은... 글쎄, 그것은 전혀 분명하지 않고,",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2380.5
 },
 {
  "input": "It's actually very subtle.",
  "translatedText": "",
  "from_community_srt": "매우 미묘합니다.",
  "n_reviews": 0,
  "start": 2380.64,
  "end": 2381.7
 },
 {
  "input": ".",
  "translatedText": "",
  "n_reviews": 0,
  "start": 2400.42,
  "end": 2381.7
 }
]