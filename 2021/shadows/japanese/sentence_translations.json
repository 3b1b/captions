[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "translatedText": "すぐに、立方体の影を使ったとても素晴らしいパズルについてお話します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "translatedText": "しかし、本題に入る前に、このビデオのポイントはパズルそのものではなく、この問題に取り組むための 2 つの 異なる方法で反映される 2 つの異なる問題解決スタイルについてであることを言っておかなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "translatedText": "実際に、それぞれのアプローチを体現する 2 人の生徒、アリスとボブを想像して、これら 2 つの異なるスタイルを擬人化してみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "translatedText": "つまり、ボブは計算が大好きな生徒になるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "translatedText": "詳細を掘り下げて、目の前の具体的な状況を非常に具体的に把握できる瞬間が来ると、それが彼にとって最も嬉しいことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "translatedText": "一方、アリスは計算を先延ばしにする傾向があり、その方法がわからないから、 または計算自体をしたくないからではなく、そのような種類の優れた高レベル の一般的な概要を取得することを好みます。 彼女は計算そのものを掘り下げる 前に、彼女が取り組んでいる問題の概要とその全体的な形状を理解しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "translatedText": "彼女は、目の前にある特定の質問だけでなく、それを一般化できる最も広範な方法 も理解できれば、特に、実際に理解した後、より一般的な見方がより迅速かつエ レガントな計算に役立つ場合に、最も満足します。 座ってそれらを実行します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "translatedText": "さて、二人が直面するパズルは、立方体の影の平均面積を見つけることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "translatedText": "したがって、ここに宇宙に浮かんでいるような立方体がある場合、その影の領域に影響を与えるものがいくつかあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "translatedText": "明らかな点としては、立方体のサイズ、立方体が小さくなり、影が小さくなることが挙げられます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "translatedText": "しかし、それが異なる方向に座っている場合も、それらの方向は異なる領域の異なる特定の影に対応します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "translatedText": "ここで平均を求めると言うとき、私が意味するのは、特定のサイズの立方体について考えられるすべての向きの平均です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "translatedText": "賢明な人は、光源がどこにあるかも非常に重要であると指摘するかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "translatedText": "光源が非常に低く、立方体自体に近い場合、影はより大きくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "translatedText": "また、光源が横方向にずれて配置されていると、影が歪み、まったく異なる形状になる可能性があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "translatedText": "ライトの位置を説明することは、それ自体で非常に興味深いものですが、パズルはそのままで も十分に難しいので、少なくとも最初は、できる限り簡単なことを実行して、ライトが立方体 の真上で非常に遠いところにあるとします。 つまり、空間内の任意の座標 x、y、z を見 ると、平面投影は x、y、0 になるという意味で、考慮しているのは平面投影だけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "translatedText": "したがって、方位を把握するために、立方体が真っ直ぐ上にあり、その 2 つの面が地面と平行である場合を考えるのが最も簡単な状況になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "translatedText": "その場合、この平面投影の影は単なる正方形であり、立方体の辺の長さを s とすれば、その影の面積は s の 2 乗になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "translatedText": "ちなみに、ここにあるアニメーションのように、これらのアニメーションにラベルを付けるときは、関連する立方体の辺の長さが 1 であると仮定します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "translatedText": "さて、すべての方向の中で考えるのが楽しいもう 1 つの特殊なケースは、長い対角線が光の方向と平行であるかどうかです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "translatedText": "この場合、影は実際には正六角形のように見えます。 そして、数分で開発するいくつかの方法を使用す ると、その影の面積が正確に、影の面積の 3 倍の平方根であると計算できます。 四角い面の一つ。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "translatedText": "しかし、もちろん、多くの場合、実際の影は正方形や六角形ほど規則的ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "translatedText": "この立方体の向きを考えるのは難しいため、形状を考えるのはさらに難しくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "translatedText": "先ほど、私は考えられるすべての方向を平均するというこのフレーズを何気なく投げかけましたが、それは一体何を意味するのでしょうか? と疑問に思う方もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "translatedText": "私たちの多くは、少なくともそれを検証するためにどのような実験を行うかという意味では、それが何を意味したいのかについて直感的に感じていると思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "translatedText": "この立方体を染料のように空中に投げ、任意の点で固定し、その位置か ら影の領域を記録し、それを繰り返すことを想像するかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "translatedText": "これを何度も何度も繰り返すと、サンプルの平均値を求めることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "translatedText": "ここで得たい数値、つまり真の平均値は、トスを重ねるにつれて実験平均値が近づき、無限に近づく数値である必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "translatedText": "それでも、こだわる人は、それは質問の本当の答えではないと不満を言うかもしれません。 なぜなら、ランダムなトスをどのように定義するかという問題が未解決のままだからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "translatedText": "これに答えるための適切な方法は、もしそれをより形式的にしたいのであれば、最初にすべての可能な方向の空間を記述することでしょう。 これは実際に数学者が派手な名前を付けたものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "translatedText": "彼らはこれを SO3 と呼び、通常は 3x3 行列の特定のファミリーに関して定義されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "translatedText": "そして、私たちが答えたい質問は、この空間全体にどのような確率分布を適用するのかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "translatedText": "このような確率分布が明確に定義されている場合にのみ、平均を含む質問に答えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "translatedText": "もしあなたがそのようなことにこだわる人なら、ビデオが終わるまでその質問は控えてほしい。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "translatedText": "実際に分布を定義せずにランダムな投げを繰り返すという、よりヒューリスティックで実験的なアイデアでどこまで達成できるかに驚かれるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "translatedText": "アリスとボブの解決策を見ると、彼らが途中でこの分布をどのように正確に定義したかを尋ねるのは実際非常に興味深いです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "translatedText": "そして、これは立方体の影そのものについてのレッスンを意図しているのではなく、パズルにもたらす可能性のある 2 つの異なる考え方のレンズを通して語られる、問題解決についてのレッスンであることを忘れないでください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "translatedText": "そして、問題解決に関する他のレッスンと同様に、ここでの目標はできるだけ早く答えに 到達することではなく、できれば自分で答えを見つけたように感じてもらうことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "translatedText": "したがって、何かアイデアがあるかもしれないと感じたときは、立ち止まってじっくり考えてみてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "translatedText": "最初のステップとして、これは特定の問題解決スタイルとはまったく関係ありません。 難しい質問を見つけたときはいつでも 、自分が考えている問題の最も単純で自明ではない変形は何であるかを尋ねることが良いことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "translatedText": "解決してみませんか？ したがって、私たちの場合、すべての方向の平均を計算することは忘れましょう、と言うかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about.",
  "translatedText": "それは考えるのが難しいことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "translatedText": "そして、立方体のさまざまな面についても忘れましょう。 それらは重なり合っており、これも考えるのが難しいからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "translatedText": "1 つの特定の顔と 1 つの特定の方向だけについて、この影の面積を計算できますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "translatedText": "もう一度言いますが、いくつかの特殊なケースで方向を把握したい場合、最も簡単なのは 、顔が地面と平行である場合です。 この場合、影の面積は顔の面積と同じになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "translatedText": "一方、その面を 90 度傾けた場合、その影は直線になり、その面積はゼロになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "translatedText": "そこでボブはこれを見て、その影の実際の式を知りたいと考えました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "translatedText": "そして、彼がそれを考える方法は、その面に垂直な法線ベクトルを考慮することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "translatedText": "そして関連していると思われるのは、その法線ベクトルが垂直方向、つまり光が来る方向となす角度であり、これをシータと呼ぶこともあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "translatedText": "さて、先ほど見てきた 2 つの特殊なケースから、theta が 0 に等しいとき、その影の面積は形 状自体の面積と同じであり、正方形の辺の長さが s の場合、s の 2 乗であることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "translatedText": "そして、シータが 90 度に等しい場合、その影の面積はゼロになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "translatedText": "そして、三角関数が何らかの形で関連することを推測するのはおそらくそれほど難しくないため、 三角関数に慣れている人なら、おそらく正しい公式が何であるか推測する危険があるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "translatedText": "しかし、ボブはそれよりも細部にこだわる人です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "translatedText": "エンドポイントに基づいて推測するのではなく、その領域がどうあるべきかを適切に証明したいと考えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "translatedText": "そして、それについて考える方法は次のようなものかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "translatedText": "垂直ベクトルと法線ベクトルを通過する平面を考慮し、その平面内 またはその平面に平行な形状のさまざまなスライスをすべて考慮す ると、次の 2 つに注意を集中できます。 問題の次元の変化。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "translatedText": "垂直方向から角度θだけ離れた法線ベクトルを持つスライス の 1 つだけを見ると、その影は次のようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "translatedText": "ここで左に垂直線を引くと、直角三角形が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "translatedText": "そして、ここから、角度の追跡を少し行うことができます。 そこでは、その角度シータが図の残りの部分について何を意味するかを追跡します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "translatedText": "これは、この三角形の直下角が正確にシータであることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "translatedText": "したがって、ピースの元のサイズと比較してこの影のサイズを理解したい場合は、その角度の余弦で あるシータについて考えることができます。 これは、斜辺を超えて隣接する角度を覚えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "translatedText": "文字通り、影のサイズとスライスのサイズの比率です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "translatedText": "したがって、スライスがこの方向に押しつぶされる要因は、まさにシータのコサインです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "translatedText": "そして、視野を正方形全体に広げると、その方向のすべてのスライスが同じ係数で拡大縮小されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "translatedText": "しかし、他の方向、つまりそのスライスに垂直な方向では、顔はその方向に まったく傾いていないため、伸びたり潰されたりすることはありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "translatedText": "したがって、全体として、2 次元の顔の 2 次元の影も、このシータの余弦係数によって縮小される必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "translatedText": "これは、角度が 0° の場合と 90° の場合を考えると、直感的に推測 できるものと一致しますが、なぜそれが真実であるかを知ると安心します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "translatedText": "そして実際には、これまで述べてきたように、これはまったく正しくありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "translatedText": "私たちが書いた式には小さな問題があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "translatedText": "シータが 90° より大きい場合、コサインは実際には負になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "translatedText": "しかしもちろん、少なくともこのような問題では、影にマイナスの領域があるとは考えたくありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this.",
  "translatedText": "したがって、これを解決するには 2 つの異なる方法があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "translatedText": "上向きの法線ベクトル、つまり正の z 成分を持つ法線ベクトルのみを考慮する必要があると言えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "translatedText": "あるいは、もっと単純に、コサインの絶対値を取 得するだけで、有効な式が得られると言えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "translatedText": "ボブは影の領域を説明する正確な式を持っているので満足しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "translatedText": "しかし、アリスは少し違うことを考え始めます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "translatedText": "彼女は、「分かった、ある程度の形状ができたので、それを何らかの方法で 3D 空間に配置する回転を適用します」と言いました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.06,
  "end": 560.52
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "translatedText": "次に、それを 2 次元空間に押し戻す平面投影を適用します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.78,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "translatedText": "そして、彼女にとって注目に値するのは、これらが両方とも線形変換であるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "translatedText": "つまり、原理的には、それぞれを行列で記述することができ、全体の 変換はこれら 2 つの行列の積のように見えるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "translatedText": "アリスが好きな科目の 1 つである線形代数から知っていることは、 ある形状を取得し、その面積を考慮し、線形変換を適用すると、その 出力の面積は元の形状の面積の定数倍に見えるということです。 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "translatedText": "より具体的には、その定数に名前があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation.",
  "translatedText": "それを変化の決定要因と呼びます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "translatedText": "線形代数にあまり慣れていない場合は、もっと直観的に説明 して、元の形状をある方向に均一に引き伸ばすと、出力も ある方向に均一に引き伸ばされると言うことができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "translatedText": "したがって、それぞれの面積は互いに比例して拡大する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "translatedText": "原理的には、アリスはこの行列式を計算できますが、それを実行するのは実際 には彼女のスタイルではありません、少なくとも直ちに実行しないのです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "translatedText": "代わりに、彼女が書き留めているのは、私たちの元の形状と その影の間の比例定数が元の形状に依存しないことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "translatedText": "この猫の輪郭の影やその他のことについて話している可能性があり、そのサイズは実際には重要ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "translatedText": "その比例定数に影響を与える唯一のことは、どのような変換を適用しているかということです。 つまり、この文脈で は、形状に適用されている回転に依存する何らかの要素としてそれを書き留めることができることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "translatedText": "ボブの計算のおかげで、私たちはその要素がどのようなものかを頭では知っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "translatedText": "ご存知のとおり、これは法線ベクトルと垂直線の間の角度の余弦の絶対値です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "translatedText": "でもアリスは今、そう、そう、そう、それについてはそのうち考えたいときに考えられるよ、と言っているだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "translatedText": "しかし、彼女は、いずれにせよ、さまざまな方向性すべてについて平均をとろうとしていることを知っていますが 、特定の方向性に関する特定の公式がその平均値の中で洗い流されるかもしれないという希望を抱いています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "translatedText": "これを見て、アリスは実際には何もしていない、と言うのは簡単です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "translatedText": "もちろん、影の面積は元の形状の面積に比例します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "translatedText": "これらは両方とも 2 次元の量であり、どちらも 2 次元のもののようにスケールする必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 675.62,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "translatedText": "ただし、光源が近い、より難しいケースを扱う場合、これはまったく当てはまらないことを覚えておいてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear.",
  "translatedText": "その場合、投影は線形ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "translatedText": "たとえば、この猫の尻尾が光源にかなり近づくように回転させた場合、元の形 状を x 方向に均一に (たとえば 1 倍) 引き伸ばすとします。5 、光に非常に近づくと尾が非常に不均衡に吹き飛ばされるため 、究極の影に非常に不均衡な影響を与える可能性があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "translatedText": "繰り返しますが、アリスは、問題のどの特性が実際に関連しているかに注意を払っ ています。 それは、物事をどの程度一般化できるかを知るのに役立つからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "translatedText": "他の形ではなく四角い顔について考えているという事実は重要なのでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really.",
  "translatedText": "いいえ、そうではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "translatedText": "変換が線形であるという事実は重要ですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely.",
  "translatedText": "そのとおり。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "translatedText": "アリスは、このような任意の形状の平均影についても同様の考え方を適用できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "translatedText": "正方形の面に適用する一連の回転があるとします。 それらを R1、R2、R3 などと呼びます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.02,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "translatedText": "これらのそれぞれの場合の影の面積は、正方形の面積に何らかの 係数を掛けたもののように見え、その係数は回転に依存します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 739.72,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "translatedText": "したがって、現在調べている回転のサンプル全体でその影の経験的平均を取る場合、その 計算方法は、それらの影の領域をすべて合計し、得られる合計数で割ることになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "translatedText": "さて、直線性のおかげで、元の正方形のこの領域はすべての 要素からきれいに考慮され、最終的には左側になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "translatedText": "これは私たちが探している正確な平均ではなく、回転のサンプルの単なる経験的平均です。 しかし原則とし て、私たちが探しているのは、サンプルのサイズが無限に近づくにつれて、これがどのように近づくかとい うことです。 サンプルのサイズに依存する部分は、その領域自体からきれいに離れた場所に配置されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.2,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "translatedText": "したがって、これが限界に近づいたとしても、それは単なる数値になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "translatedText": "計算するのは大変な苦痛かもしれませんが、それについてはまだわかりませんが、アリスが指摘している のは、それは私たちが見ている特定の 2D もののサイズや形状とは無関係であるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "translatedText": "これは普遍的な比例定数であり、彼女の希望は、その普遍性が何らかの形で、そ れが何であるべきかを推測するためのよりエレガントな方法に役立つことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.72,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "translatedText": "さて、ボブは今ここでこの定数を計算したいと考えていま す。 数分後に、彼がどのように計算するかを説明します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "translatedText": "でもその前に、もう少しアリスの世界に留まりたいと思っ ています。 ここからが本当に楽しくなり始めるからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "translatedText": "詳細に入る前に質問の全体的な構造を理解したいという彼女は、立方体の影の 面積が個々の面の面積とどのように関係しているかに興味を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "translatedText": "さて、特定の面の平均面積について何か言えるとしたら、そ れは立方体全体の平均面積について何か言えるでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "translatedText": "たとえば、簡単に言えることは、これらの影の間にはかなりの重なりがあるた め、その面積はすべての面の面積の合計よりも確実に小さいということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "translatedText": "しかし、その重なりについてどのように考えるかは完全には明らかでは ありません。 なぜなら、2 つの特定の面だけに注意を集中すると、 向きによってはまったく重なりませんが、別の向きではいくらかの重 なりがあり、特定の形状とその重なり合う領域について考えるのは少 し難しいように思えます。 ましてや、さまざまな方向すべてにわたっ てそれを平均する方法など、考えるのが少し難しいように思えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.64,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "translatedText": "しかし、アリスはこの問題全体を通じて 3 つほど賢明な洞察を持っており、これはその最初の 1 つです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "translatedText": "実際、一対の面だけでなく立方体全体について考えると、特定の向きの影の面積はすべて の面の面積の合計のちょうど半分であると結論付けることができると彼女は言います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "translatedText": "直感的には、彼らの半分は光を浴びていて、半分はそうでないことが推測で きるかもしれませんが、彼女はそれを正当化する方法を以下に示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "translatedText": "彼女によると、特定の光線については、空から光が届き、最終的には影の中の点に当たるとのことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 895.82,
  "end": 901.4
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "translatedText": "その光線は立方体のちょうど 2 点を通過します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 902.04,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "translatedText": "入る瞬間と出る瞬間があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "translatedText": "したがって、その影のすべての点は、その上の 2 つの面に正確に対応します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "translatedText": "そうですね、その光線がたまたま正方形の 1 つの端を通過した場合、それは正確には当てはまりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "translatedText": "通過する面の数については多少のあいまいさがありますが、それらは影の内側の領域を占める ものではないため、領域を計算することを目的としている場合は無視しても問題ありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 919.6,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "translatedText": "アリスが迫られ、なぜこれが正しいのかを正当化する必要があ る場合、これは問題がどのように一般化するかを理解するた めに重要であり、凸性のアイデアに訴えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "translatedText": "凸面とは、私たちの多くがその意味を直観的に理解している特性の 1 つ です。 凸面とは、内側にへこむことはなく、ただ膨らむ形状のことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "translatedText": "しかし、数学者は実際の証明に役立つ、それを形式化する非常に賢い方法を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "translatedText": "彼らは、その集合内の任意の 2 点を結ぶ線がその集合自体の中に完全に含まれる場合、その集合は凸であると言います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "translatedText": "したがって、正方形は凸面です。 なぜなら、その正方形内のどこに 2 つ の点を置いても、それらを結ぶ線が完全に正方形の中に含まれるからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "translatedText": "しかし、記号 pi のようなものは凸ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 970.28,
  "end": 972.72
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "translatedText": "2 つの異なる点を簡単に見つけることができるため、それらを接続する線はセット自体の外側に頂点を持つ必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 972.84,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "translatedText": "convex という単語の文字はどれもそれ自体が凸ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "translatedText": "2 つの点を見つけると、それらを結ぶ線がセットの外側を通過する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "translatedText": "これは、膨らむだけの形状というアイデアを形式化する非常に賢い方法です。 なぜなら、形 状が内側にへこむときはいつでも、これらの反例の線を見つけることができるからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 987.46,
  "end": 995.54
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "translatedText": "私たちの立方体は凸状であるため、最初の入口点と最後の出口点の間では 、凸性の定義により完全に立方体の内側に留まらなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "translatedText": "しかし、ドーナツのような他の非凸形状を扱っている場合、光 線が入っては出て、入ってまた出ていくことになるため、きれ いな 2 対 1 は得られません。 影からカバーします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "translatedText": "さまざまな部分すべての影は、これを多数の面でカバーし た場合、影自体の面積の正確に 2 倍にはなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "translatedText": "これが最初の重要な洞察です。 顔のシャドウがキューブのシャドウを二重に覆っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "translatedText": "次はもう少し象徴的なものなので、画面上のスペースを確保するために表記を少し省略することから始めましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "translatedText": "立方体の影の領域を書く代わりに、立方体の s だけを書きます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "translatedText": "同様に、特定の顔の影の領域の代わりに、f の s を書きます。 ここ で、下付き文字 j は、どの顔について話しているのかを示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "translatedText": "しかし、もちろん、実際には立方体に適用される特定の回転の影について話すべきです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "translatedText": "したがって、これを立方体に適用された回転の s として書くことができます。 同様 に、右側では、指定された面の 1 つに同じ回転が適用された影の領域になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "translatedText": "よりコンパクトな表記法を使用して、r1、r2、r3 などのいくつかのサンプル について、さまざまな回転にわたるこの影の領域の平均について考えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "translatedText": "繰り返しますが、この平均には、これらの影の領域をすべて加算して、それを n で割るだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "translatedText": "そして原理的には、これをより大きなサンプルについて調べる場合、 n を無限大に近づけると、立方体の影の平均面積が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "translatedText": "皆さんの中には、「はい、それはわかっています、すでに言ったことです」と思う人もいるかも しれませんが、立方体の特定の回転の影の領域を合計として表現する理由を理解できるよう、 書き出してみると有益です。 面全体、または少なくともその合計の 2 分の 1 倍であるの に、なぜそれが有益なのでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us?",
  "translatedText": "それは私たちに何をもたらすのでしょうか？ さて、それを書き出してみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "translatedText": "立方体のこれらの回転ごとに、 すべての面に適用される同じ回転の合計として影を分解できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "translatedText": "そして、このようにグリッドとして書くと、アリスの 2 番目の洞察にたどり着くことができます。 それは、合計についての考え方を行ごとに考える方法から列ごとに考える方法に変えることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "translatedText": "たとえば、最初の列だけに注目すると、最初の面の影の面積 をさまざまな方向にわたって合計することがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "translatedText": "したがって、その合計をサンプルのサイズで割ると 、この顔の影の面積の経験的平均が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "translatedText": "したがって、サンプルをどんどん大きくして、そのサイズを 無限大にすると、正方形の平均的な影の領域に近づきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "translatedText": "同様に、2 番目の列は、立方体の 2 番目の面の平均面積を示すものと 考えることができます。 もちろん、これは同じ数値である必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "translatedText": "他の列でも同様で、特定の面の平均面積がわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "translatedText": "そのため、表現全体について非常に異なる考え方が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "translatedText": "すべての異なる向きの立方体の面積を合計すると言う代わりに、6 つの異なる面の平均影を合計し、合計を半分で割ると言えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "translatedText": "ここで、左側の項は最初に行を加算することを考えており 、右側の項は最初に列を加算することを考えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "translatedText": "つまり、顔影の合計の平均は、顔影の平均の合計と同じである。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "translatedText": "この交換は簡単そうに見えるかもしれませんし、そうでもないかもしれま せん。 しかし、私たちが今行ったステップには、実際には目に見える以上 のことが少しだけあると言えます。 それについては後ほど説明します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "translatedText": "そして、特定の顔の平均面積は、その顔の面積の普遍的な比例定数 倍のように見えることを知っていることを覚えておいてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "translatedText": "したがって、これを立方体のすべての面にわたって合計すると、こ れは立方体の表面積の定数倍に等しいと考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting.",
  "translatedText": "そしてそれはとても興味深いことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "translatedText": "この立方体の影の平均面積は、その表面積に比例します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "translatedText": "しかし同時に、アリスはここでたくさんの記号を押し広げているだ けだと不満を言うかもしれません。 なぜなら、その比例定数が何 であるかが分からなければ、これは何も重要ではないからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious.",
  "translatedText": "つまり、それはほとんど明らかなようです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "translatedText": "もちろん、平均的な影の面積は表面積に比例するはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "translatedText": "これらは両方とも 2 次元の量であるため、互いに同期してスケールする必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious.",
  "translatedText": "つまり、それは明らかではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "translatedText": "結局のところ、光源が近い場合、それは当てはまりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "translatedText": "また、グリッドを列ごとに、行ごとに合計するこ のビジネスは、一見したよりも少し微妙です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "translatedText": "これらすべての根底には微妙な隠れた仮定があり、すべての方 向の空間にわたってどのような確率分布が取られているかとい う問題を再検討する場合、これは特別な重要性を持ちます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "translatedText": "しかし、何よりも、それが自明ではない理由は、ここ でのこの結果の重要性は、単にこれら 2 つの値が 比例しているということではないということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "translatedText": "それは、同様の事実があらゆる凸立体にも当てはまるということであり、 そして重要なことに、アリスがこれまでに構築してきたものの実際の内 容は、すべての凸立体にわたって同じ比例定数になるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "translatedText": "さて、それをよく考えてみると、アリスがここからどうや って終わらせるかを予測できる人もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful.",
  "translatedText": "本当に嬉しいです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1295.42
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "translatedText": "正直に言うと、それが私がこのトピックを取り上げる主な理由です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1295.6,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "translatedText": "しかし、本題に入る前に、彼女が回避できたことの詳細を掘り下 げない限り、彼女の結果を過小評価するのは簡単だと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "translatedText": "それでは、少しの間、ボブの世界に注意を戻してみ ましょう。 アリスがこれらすべてを行っている間、 いくつかの計算を行うのに忙しかったからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "translatedText": "実際、彼が取り組んでいるのは、アリスがまだ理解していないことを正確に見つ けることです。 それは、正方形の影の面積について彼が見つけた公式をどのよ うに取得するかであり、その平均を見つけようとする自然な次のステップを実 行する方法です。 正方形の影は、考えられるすべての方向で平均化されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "translatedText": "したがって、ボブがこの正方形の考えられるさまざまな方向をすべて考えている場合、ボブ はまず、その正方形がこれらすべての方向で取り得るさまざまな法線ベクトルは何であるか を尋ねます。 なぜなら、その影に関するすべてはその法線に帰着するからです。 ベクター。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "translatedText": "これらすべての可能な法線ベクトルが球の表面をトレースしていることを確認するのは、それほど難しくありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1352.32
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "translatedText": "これを単位法線ベクトルと仮定すると、半径 1 の球になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.32,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "translatedText": "さらに、ボブは、この球体の各点が他の点と同様に発生する可能性があると考えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "translatedText": "このようにして、確率は均一になるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1363.98
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "translatedText": "ある方向を別の方向よりも好む理由はありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1364.02,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "translatedText": "しかし、連続確率の文脈では、特定の個々の点の可能性について話すことはあまり役に 立ちません。 球上の数え切れない無限の点では、それはゼロで役に立たないからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "translatedText": "したがって、代わりに、この均一性をより正確に表現する 方法は、法線ベクトルが球上の特定の領域に着地する確率 がその領域自体に比例するはずであると言うことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "translatedText": "より具体的には、その小さなパッチの面積を球の総表面積で割った値に等しくなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "translatedText": "それが本当であれば、どの領域のパッチを考慮しているとしても、それが球上の均一な分布を意味することになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "translatedText": "ここで明確にしておきますが、球上の点は 3D 空間の方向と同じものではありません。 この 正方形の法線ベクトルがわかっていたとしても、それによって別の自由度が残されるからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1411.7
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "translatedText": "正方形はその法線ベクトルを中心に回転できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.9,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "translatedText": "しかし、ボブは実際にはその余分な自由度を気にする必要はありません。 なぜなら、これらすべての場合において、影の領域は同じだからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1422.0
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "translatedText": "それは法線ベクトルと垂直線の間の角度の余弦にのみ依存します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.36,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat.",
  "translatedText": "それはちょっと素敵ですね。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1427.84
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "translatedText": "それらの影はすべて、まったく異なる形をしています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1428.0,
  "end": 1430.06
 },
 {
  "input": "They're not the same.",
  "translatedText": "それらは同じではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.16,
  "end": 1430.9
 },
 {
  "input": "But the area of each of them will be the same.",
  "translatedText": "しかし、それぞれの面積は同じになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.2,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "translatedText": "これが意味するのは、ボブが考えられるすべての方向にわたってこの平均シャドウ領域を必要と する場合、彼が実際に知る必要があるのは、考えられるすべての異なる法線ベクトル、球面上の すべての異なる点についてのシータのコサインの絶対値の平均値だけであるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this?",
  "translatedText": "では、このような平均値はどうやって計算するのでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "translatedText": "私たちが、ある種の離散的なピクセル化された世界に住んでいて、その法線ベクトル が取り得る角度シータの数が有限数しかない場合、平均は非常に単純になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "translatedText": "あなたが行うことは、シータの特定の値に到達する確率を見つけることです。 これにより、その角度の法線ベクトルが球のどの部分を構成するかなどがわ かります。 次に、平均を求めたい値を掛けます。 の、この影の面積の公式。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "translatedText": "次に、0 から 180 度、つまり pi ラジアンまでのさまざまなシータ値をすべて合計します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "translatedText": "しかし、もちろん、実際には、シータの可能な値の連続体、この数え切れない無 限が存在し、シータの特定の値に到達する確率は実際には 0 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "translatedText": "したがって、このような合計は、残念ながらまったく意味がありません。 あるいは、 意味があるとしても、無限に多くのゼロを加算すると、0 が得られるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "translatedText": "代わりに何を行うかについての簡単な答えは、積分を計算することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "translatedText": "私もあなたと同じ意見ですが、ここで難しいのは、今見ている人たちから私がどのような背景を想定すべきか完全にわからないということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "translatedText": "おそらく、あなたは微積分にかなり慣れており、私がここで要点を詳しく説明する必要はないかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "translatedText": "おそらく、あなたは微積分に慣れていないのかもしれませんし、積分をそのように投げ捨てるべきではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "translatedText": "あるいは、少し前に微積分のクラスを受講したものの、少し復習が必要な場合もあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "translatedText": "微積分のレッスンであるかのようにこれを設定するオプションを使用します。 正直に言うと、積分にかな り慣れている場合でも、積分を設定するのは一種のエラーが発生しやすいプロセスであり、コールバック するためです。 基礎となる定義を確認することは、プロセス中に自分自身をチェックする良い方法です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "translatedText": "微積分が存在せず、積分が存在しなかった時代に私たちが住んでいて、この質問に対する答えを近似したい場合、それに取 り組む 1 つの方法は、0 から 2000 までの範囲の θ の値のサンプルを取得することです。 180°。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "translatedText": "それらは等間隔に配置されており、それぞれの間に何らかの差、デルタ θ があると考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "translatedText": "そして、たとえそれがサンプル内で 1 であったとしても、θ の特定の値が発生する確率について尋ねることは役に立たないということは依然として当てはまります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "translatedText": "その確率は依然として 0 であり、役に立ちません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "translatedText": "しかし、尋ねると役立つのは、幅がデルタ θ のこの小さな緯度 帯において、サンプルの 2 つの異なる値の間に入る確率です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "translatedText": "この球に沿った分布は均一であるはずであるという仮定に基づいて、その確率はこのバンドの面積を知ることになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "translatedText": "より具体的には、ランダムに選択されたベクトルがそのバンドに到達する確率は、その面積を球の総表面積で割った値になるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "translatedText": "その領域を把握するために、まずそのバンドの半径を考えてみましょう。 球の半径が 1 の場合、この半径は間違いなく 1 より小さくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "translatedText": "実際、ここで適切な小さな直角三角形を描くと、その小さな半径、たとえばバ ンドの上部が、角度の正弦、つまり θ の正弦であることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "translatedText": "これは、バンドの円周がその角度の正弦の 2π 倍である必要があり、バンドの面積はそ の円周とその厚さの積、つまり小さなデルタ θ である必要があることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "translatedText": "というか、うちのバンドの面積は大体これくらいです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "translatedText": "重要なことは、より多くの θ の値のより細かいサンプルでは、その近似の精度がますます良くなるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "translatedText": "ここで、この領域が必要な理由は、その帯域に該当する確率を知るためであることを思い出してください。 こ れは、この領域を球の表面積で割ったもので、半径の 2 乗の 4π 倍であることがわかっています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "translatedText": "これは、現在設定しているものと同様の積分を使用して計算することもできる値ですが、今 のところは、標準的なよく知られた公式として、所与の値として考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "translatedText": "そして、この確率自体は、私たちが実際に望むもの、つまり 正方形の影の平均面積への単なる足がかりにすぎません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "translatedText": "これを得るには、この確率に対応する影の領域を乗算します。 こ れは、これまで何度も見てきた cosθ 式の絶対値です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "translatedText": "そして、この平均の推定値は、さまざまなバンドすべて、つまり取得した θ のさまざまなサンプルすべてにわたってこの式を合計することになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "translatedText": "ちなみに、これはボブが完全に本領を発揮しているときです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "translatedText": "非常に具体的なものを説明する正確な公式がたくさんあり、実際に本当の答えに至るまでの過程を掘り下げています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "translatedText": "繰り返しになりますが、細かい点が多いように感じられる場合は、その事実を理解していただき、アリス がこれらすべてをなんとか回避することがどれほど魔法であるかを理解していただきたいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "translatedText": "とにかく、式を振り返って、θ 自体に依存しない項を すべて因数分解するなど、少し整理してみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "translatedText": "そして、2π を 4π で割った値を単純化して、単純に 1/2 にすることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "translatedText": "そして、積分を使った微積分にもう少し似せるために、ここで和の中の主な項を入れ替えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "translatedText": "私たちが今得ているもの、つまり私たちの質問に対する答えに近似するこの合計は、積分とほぼ同じです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "translatedText": "和を表すシグマを書く代わりに、このような細長いライプニツィアン s のような積分記号を書き、0 から π へ向かうことを示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "translatedText": "そして、ステップ サイズを具体的な有限量である δθ として記述する代わりに、代わりに dθ と して記述します。 これは、ある種の制限が取られているという事実を示していると考えたいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "translatedText": "定義上、その積分が意味するものは、θ 自体に対して取得する可能性のある、より細 かい細分化、より高密度のサンプルに対して、底部の合計が近づくことを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "translatedText": "ここで、微積分を知っている人のために、ボブのノートに書かれているの と同じように、実際にこれを実行する方法の詳細を書き留めておきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "translatedText": "これはよくあるアンチ派生的なものですが、重要なステップの 1 つは、特定の Trig アイデンティティを導入することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "translatedText": "結局、ボブがこれを行った後に発見したのは、正方形の影の平均面積がまさにその正方形の面積の 2 分の 1 であるという、驚くほど明確な事実です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "translatedText": "これはアリスがまだ知らない謎の定数です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "translatedText": "ボブが彼女の肩越しに彼女の仕事を見ていたら、今すぐに問題を解決できるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "translatedText": "彼は見つけたばかりの定数を代入すると、最終的な答えがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "translatedText": "そしてついに、これらすべてを背景に、アリスは最終的な解決策を実行するために何をしますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "translatedText": "私は彼女を、自分が見つけた結果を一般化するのが本当に好きな人だと紹介しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "translatedText": "そして通常、こうした一般化は、特定の問題を解決するための実際には重要ではない、興味深い脚注として終わります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "translatedText": "しかし、これは一般化自体が彼女を定量的な結果に導くケースです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "translatedText": "覚えておいてください、彼女がこれまでに発見したことの本質は、凸状の固体 を見ると、その影の平均面積はその表面積に比例し、重要なことに、それはす べての固体にわたって同じ比例定数になるということです。 これらの固体の。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "translatedText": "したがって、アリスがしなければならないことは、その影の平均面積がすでにわかっている凸面固体を 1 つだけ見つけることだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going.",
  "translatedText": "そして、皆さんの中には、これがどうなるか分かる人もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "translatedText": "私たちが利用できる最も対称的な固体は球です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "translatedText": "その球の向きが何であれ、その影、つまり平面投影の影は常に πr² の面積を持つ円です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "translatedText": "特に、これは平均的な影の領域です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "translatedText": "そして、前に述べたように、球の表面積は正確に 4πr² です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "translatedText": "ちなみに、その表面積の公式と、微積分が存在する何千年も前にアルキメデスがそれを証明した方法 について説明するビデオを作成しました。 そのため、それを見つけるのに積分は必要ありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "translatedText": "アリスがやったことの魔法は、球の影の面積がその表面積のちょうど 1/4 であるという、この一見具体的な事実を彼女が取り込み、それ を使って、より一般的な事実、つまりどんな凸面の固体についても、外では、その影と表面積は、ある意味では同じように関係しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "translatedText": "それで、彼女は立方体に関する特定の質問の詳細を入力し、平均的な影の面積が表面積の 1/4 倍 (6 平方メートル) になると言うことができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "translatedText": "しかし、もっと忘れられない事実は、あなたが考えながら眠りにつくことになるでしょう、それは、私たちが立方体について話していることが実際にはまったく重要ではなかったということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "translatedText": "これはとてもきれいなことですが、球には平らな面がないので、これは実際には有効な議論ではないと不満を言う人もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "translatedText": "アリスの議論はあらゆる凸立体に一般化すると言いましたが、実際に議論自体を見てみると、それは間違いなく有限数の平面の使用に依存しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "translatedText": "たとえば、これを 12 面体にマッピングする場合、その 12 面体の特定の影の面積が、そのすべての面の影の面積の合計のちょうど 1/2 倍に見えると言うことから始めるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "translatedText": "もう一度言いますが、凸性の議論と混合した特定の光線を使用して、その結論を引き出すことができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "translatedText": "影の領域を合計として表現する利点は、さまざまな回転の束を平均したい場合、その合計を大きなグリッドとして記述 することができ、そこで列ごとに移動して平均領域を考慮できることを覚えておいてください。 それぞれの顔の影に。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "translatedText": "また、重要な事実は、2D オブジェクト、つまり重要な平らな 2D オブジェクトの 平均影は、普遍的な比例定数とその面積の積に等しいという、かなり以前の結論でした。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "translatedText": "重要なのは、その定数が形状自体に依存しないということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "translatedText": "それは正方形、猫、または十二面体の五角形の面など、何でもかまいません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "translatedText": "したがって、これを有限数の平面を持たない球体に急いで持ち込んだ後、文句を言うのは当然でしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "translatedText": "しかし幸いなことに、詳細を入力するのは非常に簡単です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "translatedText": "あなたができることは、それらの面が球の本物の表面の周りにますますきつく抱きついているという意味で、連続的に球に近似する一連の異なる多面体を想像することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "translatedText": "これらの近似のそれぞれについて、この普遍的な比例定数により、平均的な影はその表面積に比例するという同じ結論を導くことができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "translatedText": "それで、「よし、各ステップの平均影の面積と各ステップの表面積の比率の限界を考えましょう」と言った場合、そ の比率は決して変わらないので、常にこの定数に等しくなります。 制限に達すると、その定数にも等しくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "translatedText": "しかしその一方で、その定義によれば、その極限では、平均影の面積は円の陰面積、つまり πr² になるはずであり、表面積の限界は球の表面積、4πr² になるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "translatedText": "したがって、私たちは直感が示唆する結論を本当に得ますが、ここでのアリスの議論によくある ことですが、その直感をどのように正当化するかについては少し慎重になる必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "translatedText": "アリスとボブのこの対比は、価値判断のように思われがちで、まるでアリスがいかに賢いのか、彼女は ボブがしなければならなかったすべての計算を洞察力をもって回避した、と言っているかのようです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "translatedText": "しかし、それは非常に、うーん、見当違いの結論になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "translatedText": "数学の普及と実際に数学をやっている感覚とは異なる重要な点があると思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "translatedText": "巧妙な証明や、計算を避けることができる賢い鋭い洞察を伴う議論を示すことへの偏見があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "translatedText": "私はこれについて非常に罪悪感を持っているので、ただ投影しているだけかもしれませんが、ここでスクリーンの反対側に座っている私が言 えることは、ボブのアプローチよりもアリスのアプローチについてのビデオを作成する方がはるかに魅力的に感じられるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "translatedText": "まず、アリスのアプローチでは推理が楽しく、なるほどと思う瞬間がたくさんあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "translatedText": "しかし、重要なことに、それを説明する方法は、非常に幅広い数学的背景に対して多かれ少なかれ同じです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "translatedText": "ボブのアプローチについてビデオを作るのはあまり魅力的ではありません。 計算がそれほどひどいからではありません。 つまり、正直に言ってそ うではありませんが、現実的な現実として、それを説明する適切なペースは、異なる数学に応じて大きく異なるように見えます。 聴衆の背景。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "translatedText": "つまり、今これを見ているあなたは、明らかに数学ビデオをオンラインで消費しています。 そうする際には、このバイアスを認識する価値があると思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "translatedText": "目的が問題解決に関する真のレッスンを受けることである場合、巧妙な証明に焦点を当てすぎると不誠実になる危険があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "translatedText": "たとえば、ここでチャレンジ モードにステップアップし、光源が近い場合について質問するとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "translatedText": "私の知る限り、アリスの場合と同様に、球体のような単一の形状に関連付けることができる、同様に巧妙な解決策はありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "translatedText": "もっと生産的なウォームアップを行うべきだったのは、ボブのアプローチの計算だったでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "translatedText": "そして、この問題の歴史を見ると、それは 1832 年にコーシーによって証明されており、彼の手書きのメモを調べてみると、アリスの作品よりもボブの作品によく似ていることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "translatedText": "ここ 11 ページの一番上に、あなたと私が真ん中で設定した積分と本質的に同じものがあることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "translatedText": "一方、論文全体の構成は、立方体の場合のような特定のものではなく、一般的な事実を見つけることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "translatedText": "したがって、これら 2 つの考え方のどちらが新しい数学を発見する行為と相関するのかという質問をする場合、正しい答えはほぼ確実に両方を組み合わせたものになるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "translatedText": "しかし、多くの人は、計算に熱心に取り組みたいそのブレンドの部分に十分な重点を置いていないことをお勧めします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "translatedText": "そして、私が作成したビデオがそれに貢献する可能性があるリスクがあると思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "translatedText": "私が数学者のアレックス・コントロヴィッチと行ったポッドキャストの中で、彼は、新しい授業に取り組む学生であろうと、新しい分野に取り 組む現役の研究数学者であろうと、直観力を養うために単に計算をドリルすることの過小評価されがちな重要性について話しました。 勉強。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "translatedText": "リスナーは実際に、その特定のセクションがどのような印象を与えたかを強調するために書き込みを行いました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "translatedText": "彼らは博士課程の学生で、自分の数学的能力が衰え始めているのではないかと心配していると語っており、その原因は加齢と鋭敏さのせいだと考えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "translatedText": "しかし、何か新しいことを学ぶために何百もの具体例を行うことの重要性について現役の数学者が語るのを聞いて、明らかに彼らの見方が変わりました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "translatedText": "彼ら自身の言葉によれば、これを認識することで、彼らの見通しと結果は完全に変わりました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "translatedText": "そして、ニュートン、オイラー、ガウスなど、歴史上の有名な数学者たちを見てみると、彼らは皆、退屈な計算を行うのに無限とも思える忍耐力を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "translatedText": "計算を回避できる洞察を示したいという偏見があるのは皮肉なことに、人々がそもそもそのような洞察を見つけるための直観を訓練する方法は、山ほどの計算を繰り返すことによって行われることが多いということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "translatedText": "そうは言っても、ここでアリスの考え方がなければ間違いなく何かが欠けているでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "translatedText": "つまり、考えてください。 立方体についてこの問題を解決し、森を見るために木の外に出ず、これが超一般的な事実であり、大家族に当てはまることを理解できなかったら、どれほど悲しいでしょう。 形。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "translatedText": "そして、数学は単に提示された質問に答えることではなく、新しいアイデアや構造を導入することであると考えると、ここでのアリスのアプローチに関する楽しい余談は、凸性のアイデアを定量化する楽しい方法を提案していることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "translatedText": "単に「はい」か「いいえ」で答えるのではなく、「凸面か凸面か、そうではないか」という数字を当てはめることができます。 「ある固体の影の平均面積を考慮し、それを 4 倍し、それを表面積で割ります」と言えます。 、その数値が 1 の場合は凸ソリッドですが、1 未満の場合は非凸ソリッドであり、1 にどれだけ近いかによって凸ソリッドにどれだけ近いかがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "translatedText": "また、ここでのアリスの解決策の優れた点の 1 つは、数学者が一般性や抽象化に対して時として奇妙な熱狂のように見える理由を説明するのに役立つことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "translatedText": "一般化と抽象化が実際に特定のケースを解決するのに役立つ例をたくさん見れば見るほど、同じことに夢中になり始めます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "translatedText": "そして、ここまで見守ってきた熱心な視聴者の皆さんへの最後の考えとして、私たちのパズルのまさに前提に関して、まだ答えられていない疑問が 1 つあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "translatedText": "ランダムな方向を選択するとは、具体的には何を意味しますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "translatedText": "もちろん、それが何を意味するのかはわかっていますが、それが愚かな質問のように感じられる場合は、ベルトランのパラドックスとして知られる確率からの難題について Numberphile と共同で行ったビデオをご覧になることをお勧めします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "translatedText": "これを見て、ここでの微妙なニュアンスが理解できたなら、アリスとボブがこの質問に対して正確にどこで暗黙的に答えているかを考えることが宿題になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "translatedText": "ボブの場合は比較的単純ですが、アリスがすべての方向の空間上で特定の分布をロックダウンする時点は、まったく明らかではなく、実際には非常に微妙です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2381.7
 }
]