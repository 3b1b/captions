[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube. ",
  "translatedText": "कुछ ही देर में मैं आपको घन की छाया से जुड़ी एक बहुत अच्छी पहेली के बारे में बताने जा रहा हूँ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem. ",
  "translatedText": "लेकिन इससे पहले कि हम उस पर पहुँचें, मुझे यह कहना चाहिए कि इस वीडियो का मुद्दा वास्तव में पहेली नहीं है, यह दो अलग-अलग समस्या-समाधान शैलियों के बारे में है जो दो अलग-अलग तरीकों से परिलक्षित होती हैं जिससे हम इस समस्या से निपट सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches. ",
  "translatedText": "वास्तव में, आइए दो छात्रों, ऐलिस और बॉब की कल्पना करके उन दो अलग-अलग शैलियों का मानवरूपीकरण करें, जो प्रत्येक दृष्टिकोण को मूर्त रूप देते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation. ",
  "translatedText": "तो बॉब उस तरह का छात्र होगा जिसे वास्तव में गणना पसंद है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased. ",
  "translatedText": "जैसे ही वह क्षण आता है जब वह विवरणों को खंगाल सकता है और अपने सामने की ठोस स्थिति का एक बहुत ही ठोस दृश्य प्राप्त कर सकता है, वहीं वह सबसे अधिक प्रसन्न होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves. ",
  "translatedText": "दूसरी ओर, ऐलिस गणनाओं में देरी करने के लिए अधिक इच्छुक है, इसलिए नहीं कि वह नहीं जानती कि उन्हें कैसे करना है या नहीं करना चाहती है, बल्कि वह इस तरह का एक अच्छा उच्च-स्तरीय सामान्य अवलोकन प्राप्त करना पसंद करती है।वह जिस समस्या से निपट रही है, उसका सामान्य आकार क्या है, इससे पहले कि वह स्वयं गणनाओं में तल्लीन हो जाए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out. ",
  "translatedText": "वह सबसे अधिक प्रसन्न होती है अगर वह न केवल उसके सामने बैठे विशिष्ट प्रश्न को समझती है, बल्कि सबसे व्यापक संभव तरीके से भी समझती है जिससे आप इसे सामान्यीकृत कर सकते हैं, और विशेष रूप से यदि अधिक सामान्य दृष्टिकोण खुद को अधिक तेज़ और सुरुचिपूर्ण गणनाओं के लिए उधार दे सकता है, एक बार जब वह वास्तव में ऐसा कर लेती है उन्हें पूरा करने के लिए बैठ जाओ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube. ",
  "translatedText": "अब इन दोनों के सामने जो पहेली आने वाली है वह है एक घन की छाया का औसत क्षेत्रफल ज्ञात करना।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow. ",
  "translatedText": "तो अगर मेरे पास अंतरिक्ष में मंडराता हुआ एक घन जैसा बैठा है, तो कुछ चीजें हैं जो इसकी छाया के क्षेत्र को प्रभावित करती हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow. ",
  "translatedText": "एक स्पष्ट बात यह होगी कि घन का आकार, छोटा घन, छोटी छाया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas. ",
  "translatedText": "लेकिन अगर यह अलग-अलग अभिविन्यासों पर बैठा है, तो वे अभिविन्यास अलग-अलग क्षेत्रों के साथ अलग-अलग विशेष छायाओं के अनुरूप होते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube. ",
  "translatedText": "और जब मैं कहता हूं कि यहां औसत ज्ञात करो, तो मेरा मतलब घन के एक विशेष आकार के लिए सभी संभावित झुकावों पर औसत है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is. ",
  "translatedText": "आपमें से जो चतुर लोग होंगे वे यह बता सकते हैं कि यह भी बहुत मायने रखता है कि प्रकाश स्रोत कहां है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger. ",
  "translatedText": "यदि प्रकाश स्रोत बहुत कम, घन के करीब होता, तो छाया बड़ी हो जाती।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape. ",
  "translatedText": "और यदि प्रकाश स्रोत पार्श्व में किनारे की ओर स्थित हो, तो यह छाया को विकृत कर सकता है और इसे एक बहुत अलग आकार दे सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0. ",
  "translatedText": "उस प्रकाश की स्थिति का हिसाब-किताब करना अपने आप में बेहद दिलचस्प है, लेकिन पहेली काफी कठिन है, इसलिए कम से कम शुरुआत में, आइए सबसे आसान काम करें और कहें कि प्रकाश सीधे घन के ऊपर है और वास्तव में बहुत दूर है दूर, प्रभावी रूप से असीम रूप से दूर, ताकि हम जिस पर विचार कर रहे हैं वह एक सपाट प्रक्षेपण है, इस अर्थ में कि यदि आप अंतरिक्ष में किसी भी निर्देशांक, x, y, z को देखते हैं, तो सपाट प्रक्षेपण x, y, 0 होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground. ",
  "translatedText": "तो बस अपना रुख जानने के लिए, सोचने की सबसे आसान स्थिति यह होगी कि यदि घन सीधा है, और उसके दो चेहरे जमीन के समानांतर हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared. ",
  "translatedText": "उस स्थिति में, यह सपाट प्रक्षेपण छाया बस एक वर्ग है, और यदि हम कहते हैं कि घन की भुजाओं की लंबाई s है, तो उस छाया का क्षेत्र s वर्ग है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1. ",
  "translatedText": "और वैसे, जब भी मैं इन एनिमेशनों पर एक लेबल लगाऊंगा, जैसा कि यहां नीचे दिया गया है, तो मैं मान लूंगा कि संबंधित क्यूब की भुजा की लंबाई 1 है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light. ",
  "translatedText": "अब सभी झुकावों के बीच एक और विशेष मामला जिसके बारे में सोचना मजेदार है वह यह है कि क्या लंबा विकर्ण प्रकाश की दिशा के समानांतर है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces. ",
  "translatedText": "उस स्थिति में, छाया वास्तव में एक नियमित षट्भुज की तरह दिखती है, और यदि आप कुछ तरीकों का उपयोग करते हैं जिन्हें हम कुछ मिनटों में विकसित करेंगे, तो आप गणना कर सकते हैं कि उस छाया का क्षेत्र बिल्कुल उस क्षेत्र के 3 गुना के वर्गमूल के बराबर है।चौकोर चेहरों में से एक. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon. ",
  "translatedText": "लेकिन निश्चित रूप से, अधिक बार, वास्तविक छाया एक वर्ग या षट्भुज जितनी नियमित नहीं होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube. ",
  "translatedText": "इस घन के अभिविन्यास के आधार पर आकार के बारे में सोचना कुछ कठिन है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean? ",
  "translatedText": "इससे पहले, मैंने लापरवाही से सभी संभावित झुकावों पर औसत के इस वाक्यांश को खारिज कर दिया था, लेकिन आप ठीक ही पूछ सकते हैं कि वास्तव में इसका क्या मतलब है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it. ",
  "translatedText": "मुझे लगता है कि हममें से बहुतों को इसका सहज ज्ञान है कि हम इसका क्या मतलब निकालना चाहते हैं, कम से कम इस अर्थ में कि आप इसे सत्यापित करने के लिए कौन सा प्रयोग करेंगे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating. ",
  "translatedText": "आप इस घन को डाई की तरह हवा में उछालने, इसे किसी मनमाने बिंदु पर जमा देने, उस स्थिति से छाया के क्षेत्र को रिकॉर्ड करने और फिर दोहराने की कल्पना कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample. ",
  "translatedText": "यदि आप ऐसा बार-बार करते हैं, तो आप अपने नमूने का माध्य निकाल सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many. ",
  "translatedText": "जिस संख्या को हम प्राप्त करना चाहते हैं, यहां वास्तविक औसत, वह होना चाहिए जो प्रयोगात्मक माध्य के करीब पहुंचता है क्योंकि आप अधिक से अधिक टॉस करते हैं, अनंत तक पहुंचते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss. ",
  "translatedText": "फिर भी, आप में से कुछ लोग शिकायत कर सकते हैं कि यह वास्तव में प्रश्न का उत्तर नहीं देता है, क्योंकि यह इस मुद्दे को खुला छोड़ देता है कि हम यादृच्छिक टॉस को कैसे परिभाषित कर रहे हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name. ",
  "translatedText": "इसका उत्तर देने का उचित तरीका, यदि हम इसे अधिक औपचारिक बनाना चाहते हैं, तो पहले सभी संभावित अभिविन्यासों के स्थान का वर्णन करना होगा, जिन्हें गणितज्ञों ने वास्तव में एक फैंसी नाम दिया है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices. ",
  "translatedText": "वे इसे SO3 कहते हैं, जिसे आम तौर पर 3x3 मैट्रिक्स के एक निश्चित परिवार के संदर्भ में परिभाषित किया जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space? ",
  "translatedText": "और जिस प्रश्न का हम उत्तर देना चाहते हैं वह यह है कि हम इस संपूर्ण स्थान पर कौन सा संभाव्यता वितरण रख रहे हैं? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average. ",
  "translatedText": "ऐसा केवल तभी होता है जब ऐसा संभाव्यता वितरण अच्छी तरह से परिभाषित होता है कि हम औसत से जुड़े प्रश्न का उत्तर दे सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video. ",
  "translatedText": "यदि आप इस तरह की चीज़ के पक्षधर हैं, तो मैं चाहता हूँ कि आप वीडियो के अंत तक उस प्रश्न को रोक कर रखें।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution. ",
  "translatedText": "आपको यह देखकर आश्चर्य होगा कि वितरण को वास्तव में परिभाषित किए बिना यादृच्छिक उछालों के एक समूह को दोहराने के अधिक अनुमानवादी, प्रयोगात्मक विचार से हम कितनी दूर तक पहुँच सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way. ",
  "translatedText": "एक बार जब हम ऐलिस और बॉब के समाधान देखते हैं, तो यह पूछना वास्तव में बहुत दिलचस्प होता है कि उनमें से प्रत्येक ने अपने तरीके से इस वितरण को कैसे परिभाषित किया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle. ",
  "translatedText": "और याद रखें, इसका मतलब घन छाया के बारे में एक पाठ नहीं है, बल्कि समस्या समाधान के बारे में एक पाठ है, जिसे दो अलग-अलग मानसिकताओं के लेंस के माध्यम से बताया गया है जिसे हम पहेली में ला सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself. ",
  "translatedText": "और समस्या समाधान पर किसी भी पाठ की तरह, यहां लक्ष्य जितनी जल्दी हो सके उत्तर तक पहुंचना नहीं है, बल्कि उम्मीद है कि आपको यह महसूस होगा कि आपको उत्तर स्वयं मिल गया है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through. ",
  "translatedText": "इसलिए यदि कभी ऐसा समय आए जब आपको लगे कि आपके पास कोई विचार हो सकता है, तो अपने आप को रुकने की स्वतंत्रता दें और उस पर विचार करने का प्रयास करें।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve? ",
  "translatedText": "पहले कदम के रूप में, और यह वास्तव में किसी विशेष समस्या समाधान शैली से स्वतंत्र है, बस जब भी आपको कोई कठिन प्रश्न मिले, तो एक अच्छी बात जो आप कर सकते हैं वह यह है कि आप पूछ सकते हैं कि समस्या का सबसे सरल, गैर-तुच्छ संस्करण क्या है।हल करने का प्रयास कर सकते हैं? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations. ",
  "translatedText": "तो हमारे मामले में, आप जो कह सकते हैं वह यह है, ठीक है, आइए सभी झुकावों के औसत के बारे में भूल जाएं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about. ",
  "translatedText": "इसके बारे में सोचना एक मुश्किल बात है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about. ",
  "translatedText": "और चलो घन के सभी अलग-अलग चेहरों के बारे में भी भूल जाएं, क्योंकि वे ओवरलैप होते हैं, और इसके बारे में सोचना भी मुश्किल है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow? ",
  "translatedText": "केवल एक विशेष चेहरे और एक विशेष अभिविन्यास के लिए, क्या हम इस छाया के क्षेत्र की गणना कर सकते हैं? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face. ",
  "translatedText": "एक बार फिर, यदि आप कुछ विशेष मामलों के बारे में जानना चाहते हैं, तो सबसे आसान वह है जब वह चेहरा जमीन के समानांतर हो, उस स्थिति में छाया का क्षेत्र चेहरे के क्षेत्र के समान होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero. ",
  "translatedText": "वहीं, अगर हम उस चेहरे को 90 डिग्री तक झुकाएं तो उसकी छाया एक सीधी रेखा होगी और उसका क्षेत्रफल शून्य होगा. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow. ",
  "translatedText": "तो बॉब इसे देखता है, और वह उस छाया के लिए एक वास्तविक सूत्र चाहता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face. ",
  "translatedText": "और जिस तरह से वह इसके बारे में सोच सकता है वह उस चेहरे के लंबवत सामान्य वेक्टर पर विचार करना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta. ",
  "translatedText": "और जो प्रासंगिक लगता है वह वह कोण है जो सामान्य वेक्टर ऊर्ध्वाधर के साथ बनाता है, उस दिशा के साथ जहां से प्रकाश आ रहा है, जिसे हम थीटा कह सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s. ",
  "translatedText": "अब, जिन दो विशेष मामलों को हमने अभी देखा, उनसे हम जानते हैं कि जब थीटा शून्य के बराबर होता है, तो उस छाया का क्षेत्र स्वयं आकृति के क्षेत्र के समान होता है, जो कि वर्ग है यदि वर्ग की भुजाओं की लंबाई s है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero. ",
  "translatedText": "और यदि थीटा 90 डिग्री के बराबर है, तो उस छाया का क्षेत्रफल शून्य है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is. ",
  "translatedText": "और शायद यह अनुमान लगाना बहुत मुश्किल नहीं है कि त्रिकोणमिति किसी भी तरह प्रासंगिक होगी, इसलिए उनके ट्रिगर कार्यों के साथ सहज कोई भी व्यक्ति शायद यह अनुमान लगाने में जोखिम उठा सकता है कि सही सूत्र क्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that. ",
  "translatedText": "लेकिन बॉब उससे कहीं अधिक विस्तार-उन्मुख है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints. ",
  "translatedText": "वह अंतिम बिंदुओं के आधार पर केवल अनुमान लगाने के बजाय, ठीक से साबित करना चाहता है कि वह क्षेत्र क्या होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this. ",
  "translatedText": "और जिस तरह से आप इसके बारे में सोच सकते हैं वह कुछ इस तरह हो सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem. ",
  "translatedText": "यदि हम अपने सामान्य वेक्टर के साथ-साथ ऊर्ध्वाधर से गुजरने वाले विमान पर विचार करते हैं, और फिर हम अपने आकार के सभी अलग-अलग स्लाइसों पर विचार करते हैं जो उस विमान में हैं, या उस विमान के समानांतर हैं, तो हम अपना ध्यान दो पर केंद्रित कर सकते हैं- समस्या का आयामी संस्करण. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this. ",
  "translatedText": "यदि हम केवल उन स्लाइसों में से एक को देखें, जिसमें एक सामान्य वेक्टर है, ऊर्ध्वाधर से एक कोण थीटा दूर, तो इसकी छाया कुछ इस तरह दिख सकती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle. ",
  "translatedText": "और यदि हम यहां बाईं ओर एक ऊर्ध्वाधर रेखा खींचते हैं, तो हमें एक समकोण त्रिभुज मिलता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram. ",
  "translatedText": "और यहां से हम कोणों का थोड़ा पीछा कर सकते हैं, जहां हम उस कोण थीटा का बाकी आरेख के बारे में क्या अर्थ निकालते हैं, इसका अनुसरण करते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta. ",
  "translatedText": "और इसका मतलब यह है कि इस त्रिभुज में निचला समकोण बिल्कुल थीटा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse. ",
  "translatedText": "इसलिए, जब हम टुकड़े के मूल आकार की तुलना में इस छाया के आकार को समझना चाहते हैं, तो हम उस कोण के कोसाइन, थीटा के बारे में सोच सकते हैं, जो कर्ण के ऊपर आसन्न को याद करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice. ",
  "translatedText": "यह वस्तुतः छाया के आकार और स्लाइस के आकार के बीच का अनुपात है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta. ",
  "translatedText": "तो, वह कारक जिसके द्वारा टुकड़ा इस दिशा में दब जाता है, बिल्कुल थीटा की कोज्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor. ",
  "translatedText": "और यदि हम अपने दृष्टिकोण को पूरे वर्ग तक विस्तृत करते हैं, तो उस दिशा के सभी स्लाइस एक ही कारक से मापे जाते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction. ",
  "translatedText": "लेकिन दूसरी दिशा में, उस टुकड़े के लंबवत एक हिस्से में, कोई खिंचाव या सिकुड़न नहीं है, क्योंकि चेहरा उस दिशा में बिल्कुल भी झुका हुआ नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta. ",
  "translatedText": "तो कुल मिलाकर, हमारे द्वि-आयामी चेहरे की द्वि-आयामी छाया को थीटा के कोसाइन के इस कारक द्वारा कम किया जाना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true. ",
  "translatedText": "यह उस स्थिति के अनुरूप है जिसका आप सहज ज्ञान से अनुमान लगा सकते हैं, उस स्थिति को देखते हुए जहां कोण 0° है और वह स्थिति जहां यह 90° है, लेकिन यह देखना आश्वस्त करने वाला है कि यह सच क्यों है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct. ",
  "translatedText": "और वास्तव में, जैसा कि अब तक कहा गया है, यह बिल्कुल सही नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written. ",
  "translatedText": "हमने जो सूत्र लिखा है उसमें एक छोटी सी समस्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative. ",
  "translatedText": "ऐसे मामले में जहां थीटा 90° से बड़ा है, कोसाइन वास्तव में नकारात्मक निकलेगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this. ",
  "translatedText": "लेकिन निस्संदेह, हम छाया को नकारात्मक क्षेत्र नहीं मानना चाहते, कम से कम इस तरह की समस्या में तो नहीं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this. ",
  "translatedText": "तो आप इसे दो अलग-अलग तरीकों से हल कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component. ",
  "translatedText": "आप कह सकते हैं कि हम केवल उस सामान्य वेक्टर पर विचार करना चाहते हैं जो ऊपर की ओर इशारा कर रहा है, जिसमें एक सकारात्मक z घटक है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula. ",
  "translatedText": "या, अधिक सरलता से, हम कह सकते हैं, बस उस कोसाइन का पूर्ण मान लें, और यह हमें एक वैध सूत्र देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow. ",
  "translatedText": "इसलिए बॉब खुश है क्योंकि उसके पास छाया के क्षेत्र का वर्णन करने वाला एक सटीक सूत्र है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently. ",
  "translatedText": "लेकिन ऐलिस इसके बारे में थोड़ा अलग ढंग से सोचने लगती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way. ",
  "translatedText": "वह कहती है, ठीक है, हमें कुछ आकार मिल गया है, और फिर हम एक घुमाव लागू करते हैं जो इसे किसी तरह से 3डी स्पेस में स्थित कर देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.06,
  "end": 560.52
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space. ",
  "translatedText": "और फिर हम एक सपाट प्रक्षेपण लागू करते हैं जो उसे वापस दो-आयामी स्थान में धकेल देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.78,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations. ",
  "translatedText": "और जो बात उनके सामने स्पष्ट है वह यह है कि ये दोनों रैखिक परिवर्तन हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices. ",
  "translatedText": "इसका मतलब है कि सिद्धांत रूप में आप उनमें से प्रत्येक का एक मैट्रिक्स के साथ वर्णन कर सकते हैं, और समग्र परिवर्तन उन दो मैट्रिक्स के उत्पाद की तरह दिखेगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape. ",
  "translatedText": "ऐलिस अपने पसंदीदा विषयों में से एक, रैखिक बीजगणित से जो जानती है, वह यह है कि यदि आप कोई आकार लेते हैं और आप उसके क्षेत्र पर विचार करते हैं, फिर आप कुछ रैखिक परिवर्तन लागू करते हैं, तो उस आउटपुट का क्षेत्र आकार के मूल क्षेत्र से कुछ स्थिर गुना जैसा दिखता है।. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant. ",
  "translatedText": "अधिक विशेष रूप से, हमारे पास उस स्थिरांक के लिए एक नाम है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation. ",
  "translatedText": "इसे परिवर्तन का निर्धारक कहा जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction. ",
  "translatedText": "यदि आप रैखिक बीजगणित के साथ इतने सहज नहीं हैं, तो हम अधिक सहज विवरण दे सकते हैं और कह सकते हैं, यदि आप मूल आकार को किसी दिशा में समान रूप से फैलाते हैं, तो आउटपुट भी समान रूप से किसी दिशा में खिंच जाएगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other. ",
  "translatedText": "इसलिए उनमें से प्रत्येक का क्षेत्रफल एक-दूसरे के अनुपात में होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately. ",
  "translatedText": "अब सैद्धांतिक रूप से, ऐलिस इस निर्धारक की गणना कर सकती है, लेकिन वास्तव में ऐसा करना उसकी शैली नहीं है, कम से कम तुरंत ऐसा न करना।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape. ",
  "translatedText": "इसके बजाय, जो बात वह लिखती है वह यह है कि हमारे मूल आकार और उसकी छाया के बीच स्थिर आनुपातिकता मूल आकार पर निर्भर नहीं करती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter. ",
  "translatedText": "हम इस बिल्ली की रूपरेखा की छाया या किसी अन्य चीज़ के बारे में बात कर सकते हैं, और इसका आकार वास्तव में कोई मायने नहीं रखता।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape. ",
  "translatedText": "आनुपातिकता स्थिरांक को प्रभावित करने वाली एकमात्र चीज यह है कि हम कौन सा परिवर्तन लागू कर रहे हैं, जिसका इस संदर्भ में मतलब है कि हम इसे कुछ कारक के रूप में लिख सकते हैं जो आकार पर लागू होने वाले घूर्णन पर निर्भर करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like. ",
  "translatedText": "हमारे दिमाग में, बॉब की गणना के कारण, हम जानते हैं कि वह कारक कैसा दिखता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical. ",
  "translatedText": "आप जानते हैं, यह सामान्य वेक्टर और ऊर्ध्वाधर के बीच के कोण की कोज्या का पूर्ण मान है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to. ",
  "translatedText": "लेकिन ऐलिस अभी बस यही कह रही है, हाँ, हाँ, हाँ, मैं अंततः इसके बारे में तब सोच सकती हूँ जब मैं चाहूँ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average. ",
  "translatedText": "लेकिन वह जानती है कि हम वैसे भी सभी अलग-अलग झुकावों पर औसत करने वाले हैं, हालांकि उसे कुछ उम्मीद है कि किसी विशिष्ट अभिविन्यास के बारे में कोई भी विशिष्ट सूत्र उस औसत में धुल सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then. ",
  "translatedText": "अब इसे देखना और कहना आसान है, ठीक है, ऐलिस वास्तव में कुछ नहीं कर रही है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape. ",
  "translatedText": "निःसंदेह छाया का क्षेत्रफल मूल आकृति के क्षेत्रफल के समानुपाती होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things. ",
  "translatedText": "वे दोनों द्वि-आयामी मात्राएँ हैं, उन दोनों को द्वि-आयामी चीज़ों की तरह स्केल करना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 675.62,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source. ",
  "translatedText": "लेकिन ध्यान रखें, यह बिल्कुल भी सच नहीं होगा यदि हम एक कठिन मामले से निपट रहे हैं जिसका प्रकाश स्रोत करीब है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear. ",
  "translatedText": "उस स्थिति में, प्रक्षेपण रैखिक नहीं है. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light. ",
  "translatedText": "उदाहरण के लिए, यदि मैं इस बिल्ली को घुमाता हूं ताकि इसकी पूंछ प्रकाश स्रोत के काफी करीब हो जाए, तो यदि मैं मूल आकार को एक्स-दिशा में समान रूप से फैलाता हूं, मान लीजिए 1 के कारक से।5, इसका अंतिम छाया पर बहुत असंगत प्रभाव हो सकता है, क्योंकि जैसे ही यह प्रकाश के करीब आता है, पूंछ बहुत असंगत रूप से फूल जाती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things. ",
  "translatedText": "फिर, ऐलिस इस बात पर नज़र रख रही है कि समस्या के कौन से गुण वास्तव में प्रासंगिक हैं, क्योंकि इससे उसे यह जानने में मदद मिलती है कि वह चीजों को कितना सामान्य बना सकती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter? ",
  "translatedText": "क्या यह तथ्य मायने रखता है कि हम चौकोर चेहरे के बारे में सोच रहे हैं न कि किसी अन्य आकार के बारे में? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really. ",
  "translatedText": "नहीं वाकई में नहीं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter? ",
  "translatedText": "क्या यह तथ्य कि परिवर्तन रैखिक है, कोई मायने नहीं रखता? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely. ",
  "translatedText": "हां बिल्कुल।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this. ",
  "translatedText": "ऐलिस भी इस तरह की किसी भी आकृति के लिए औसत छाया के बारे में सोचने का एक समान तरीका लागू कर सकती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on. ",
  "translatedText": "मान लें कि हमारे पास घुमावों का कुछ क्रम है जिसे हम अपने वर्गाकार चेहरे पर लागू करते हैं, और चलिए उन्हें R1, R2, R3 इत्यादि कहते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.02,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation. ",
  "translatedText": "फिर उनमें से प्रत्येक मामले में छाया का क्षेत्र वर्ग के क्षेत्रफल के कुछ कारक गुना जैसा दिखता है, और वह कारक घूर्णन पर निर्भर करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 739.72,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have. ",
  "translatedText": "इसलिए यदि हम उस छाया के लिए उस घूर्णन के नमूने में एक अनुभवजन्य औसत लेते हैं जिसे हम अभी देख रहे हैं, तो यह जिस तरह से दिखता है वह उन सभी छाया क्षेत्रों को जोड़ना है और फिर हमारे पास मौजूद कुल संख्या से विभाजित करना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left. ",
  "translatedText": "अब, रैखिकता के कारण, मूल वर्ग का यह क्षेत्र उन सभी को स्पष्ट रूप से कारक बना सकता है, और यह बाईं ओर समाप्त होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself. ",
  "translatedText": "यह वह सटीक औसत नहीं है जिसकी हम तलाश कर रहे हैं, यह केवल घूर्णन के नमूने का एक अनुभवजन्य माध्य है, लेकिन सिद्धांत रूप में हम जो खोज रहे हैं वह वह है जो हमारे नमूने का आकार अनंत तक पहुंचने के करीब पहुंचता है, और सभी वे भाग जो नमूने के आकार पर निर्भर करते हैं वे क्षेत्र से साफ-सुथरे दूर स्थित होते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.2,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number. ",
  "translatedText": "तो यह सीमा में जो भी पहुंचे, वह बस कुछ संख्या होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at. ",
  "translatedText": "इसकी गणना करना कठिन हो सकता है, हम अभी तक इसके बारे में निश्चित नहीं हैं, लेकिन ऐलिस ने जो बात नोट की है वह यह है कि यह उस विशेष 2डी चीज़ के आकार और आकार से स्वतंत्र है जिसे हम देख रहे हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be. ",
  "translatedText": "यह एक सार्वभौमिक आनुपातिकता स्थिरांक है, और उसकी आशा है कि वह सार्वभौमिकता किसी भी तरह खुद को और अधिक सुंदर तरीके से यह निष्कर्ष निकालने के लिए उधार देती है कि उसे क्या होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.72,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it. ",
  "translatedText": "अब बॉब यहां और अभी इस स्थिरांक की गणना करने के लिए उत्सुक होगा, और कुछ ही मिनटों में मैं आपको दिखाऊंगा कि वह यह कैसे करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun. ",
  "translatedText": "लेकिन उससे पहले मैं ऐलिस की दुनिया में थोड़ा और रुकना चाहता हूं, क्योंकि यहीं से चीजें वास्तव में मजेदार होने लगती हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces. ",
  "translatedText": "विवरण में जाने से पहले प्रश्न की समग्र संरचना को समझने की उसकी इच्छा में, वह अब इस बारे में उत्सुक है कि घन की छाया का क्षेत्र उसके व्यक्तिगत चेहरों के क्षेत्र से कैसे संबंधित है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole? ",
  "translatedText": "अब यदि हम किसी विशेष फलक के औसत क्षेत्रफल के बारे में कुछ कह सकते हैं, तो क्या यह हमें संपूर्ण घन के औसत क्षेत्रफल के बारे में कुछ बताता है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows. ",
  "translatedText": "उदाहरण के लिए, एक साधारण बात जो हम कह सकते हैं वह यह है कि वह क्षेत्र निश्चित रूप से सभी चेहरों के क्षेत्रों के योग से कम है, क्योंकि उन छायाओं के बीच एक सार्थक मात्रा में ओवरलैप है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations. ",
  "translatedText": "लेकिन यह पूरी तरह से स्पष्ट नहीं है कि उस ओवरलैप के बारे में कैसे सोचा जाए, क्योंकि अगर हम अपना ध्यान केवल दो विशेष चेहरों पर केंद्रित करते हैं, तो कुछ अभिविन्यासों में वे बिल्कुल भी ओवरलैप नहीं होते हैं, लेकिन अन्य अभिविन्यासों में उनमें कुछ ओवरलैप होते हैं, और विशिष्ट आकार और उस ओवरलैप के क्षेत्र के बारे में सोचना थोड़ा मुश्किल लगता है, और इस बारे में तो सोचना ही मुश्किल है कि पृथ्वी पर हम सभी अलग-अलग दिशाओं में इसका औसत कैसे निकालेंगे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.64,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them. ",
  "translatedText": "लेकिन ऐलिस के पास इस पूरी समस्या के बारे में तीन चतुर अंतर्दृष्टियाँ हैं, और यह उनमें से पहली है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces. ",
  "translatedText": "वह कहती हैं, वास्तव में, अगर हम पूरे घन के बारे में सोचते हैं, न कि केवल चेहरों की एक जोड़ी के बारे में, तो हम यह निष्कर्ष निकाल सकते हैं कि किसी दिए गए अभिविन्यास के लिए छाया का क्षेत्र सभी चेहरों के क्षेत्रों के योग का आधा हिस्सा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it. ",
  "translatedText": "सहज रूप से आप अनुमान लगा सकते हैं कि उनमें से आधे रोशनी में नहाए हुए हैं और आधे नहीं, लेकिन यहां वह तरीका है जिससे वह इसे उचित ठहराती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow. ",
  "translatedText": "वह कहती हैं कि प्रकाश की एक विशेष किरण के लिए, वे आकाश से जाएंगी और अंततः छाया में एक बिंदु से टकराएंगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 895.82,
  "end": 901.4
 },
 {
  "input": "That ray passes through the cube at exactly two points. ",
  "translatedText": "वह किरण घन से ठीक दो बिंदुओं पर गुजरती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 902.04,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits. ",
  "translatedText": "एक क्षण होता है जब वह प्रवेश करता है और एक क्षण होता है जब वह बाहर निकल जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it. ",
  "translatedText": "तो उस छाया का प्रत्येक बिंदु उसके ठीक ऊपर के दो चेहरों से मेल खाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares. ",
  "translatedText": "ठीक है, ठीक है, यह बिल्कुल सच नहीं है अगर प्रकाश की किरण किसी एक वर्ग के किनारे से गुज़रती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area. ",
  "translatedText": "यह कितने चेहरों से गुजर रहा है, इस पर थोड़ी अस्पष्टता है, लेकिन वे छाया के अंदर शून्य क्षेत्र के लिए जिम्मेदार हैं, इसलिए यदि हम जो करने की कोशिश कर रहे हैं वह क्षेत्र की गणना करना है तो हम उन्हें अनदेखा करना सुरक्षित हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 919.6,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity. ",
  "translatedText": "यदि ऐलिस पर दबाव डाला जाता है और उसे यह बताना होगा कि वास्तव में यह सच क्यों है, जो यह समझने के लिए महत्वपूर्ण है कि समस्या कैसे सामान्य हो सकती है, तो वह उत्तलता के विचार के लिए अपील कर सकती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward. ",
  "translatedText": "उत्तलता उन गुणों में से एक है जहां हममें से बहुत से लोगों के पास इसका क्या अर्थ होना चाहिए, इसकी सहज समझ होती है, आप जानते हैं, यह ऐसी आकृतियाँ हैं जो बस बाहर की ओर उभरी हुई होती हैं, वे कभी भी अंदर की ओर सेंध नहीं लगाती हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs. ",
  "translatedText": "लेकिन गणितज्ञों के पास इसे औपचारिक बनाने का एक बहुत ही चतुर तरीका है जो वास्तविक प्रमाणों के लिए उपयोगी है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself. ",
  "translatedText": "वे कहते हैं कि एक सेट उत्तल होता है यदि उस सेट के अंदर किन्हीं दो बिंदुओं को जोड़ने वाली रेखा पूरी तरह से सेट के भीतर ही समाहित हो।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square. ",
  "translatedText": "तो एक वर्ग उत्तल होता है क्योंकि इससे कोई फर्क नहीं पड़ता कि आप उस वर्ग के अंदर दो बिंदु कहाँ रखते हैं, उन्हें जोड़ने वाली रेखा पूरी तरह से वर्ग के अंदर समाहित होती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex. ",
  "translatedText": "लेकिन प्रतीक पाई जैसा कुछ उत्तल नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 970.28,
  "end": 972.72
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself. ",
  "translatedText": "मैं आसानी से दो अलग-अलग बिंदु ढूंढ सकता हूं ताकि उन्हें जोड़ने वाली रेखा सेट के बाहर ही चरम पर हो।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 972.84,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex. ",
  "translatedText": "उत्तल शब्द का कोई भी अक्षर स्वयं उत्तल नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set. ",
  "translatedText": "आप दो बिंदु पा सकते हैं ताकि उन्हें जोड़ने वाली रेखा को सेट के बाहर से गुजरना पड़े।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines. ",
  "translatedText": "यह किसी आकृति के इस विचार को औपचारिक रूप देने का वास्तव में एक चतुर तरीका है जो केवल बाहर की ओर निकलता है, क्योंकि जब भी यह अंदर की ओर सेंध लगाता है, तो आप इन प्रति-उदाहरण रेखाओं को पा सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 987.46,
  "end": 995.54
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity. ",
  "translatedText": "हमारा घन, क्योंकि यह उत्तल है, प्रवेश के पहले बिंदु और निकास के अंतिम बिंदु के बीच, इसे उत्तलता की परिभाषा के अनुसार पूरी तरह से घन के अंदर रहना होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows. ",
  "translatedText": "लेकिन अगर हम डोनट की तरह किसी अन्य गैर-उत्तल आकार के साथ काम कर रहे होते, तो आपको प्रकाश की एक किरण मिल सकती थी जो प्रवेश करती है, फिर बाहर निकलती है, फिर प्रवेश करती है, फिर बाहर निकलती है, इसलिए आपके पास एक साफ टू-टू-वन नहीं होगा छाया से छिपाओ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself. ",
  "translatedText": "इसके सभी अलग-अलग हिस्सों की परछाइयाँ, यदि आप इसे चेहरों के समूह में ढँक दें, तो इसका क्षेत्रफल छाया के क्षेत्रफल से ठीक दोगुना नहीं होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow. ",
  "translatedText": "तो, यह पहली मुख्य अंतर्दृष्टि है, चेहरे की छाया घन छाया को दोगुना ढक देती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen. ",
  "translatedText": "और अगला थोड़ा अधिक प्रतीकात्मक है, तो आइए स्क्रीन पर जगह बनाने के लिए अपने नोटेशन को थोड़ा संक्षिप्त करके चीजों को शुरू करें।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube. ",
  "translatedText": "घन की छाया का क्षेत्रफल लिखने के बजाय, मैं केवल घन का s लिखने जा रहा हूँ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about. ",
  "translatedText": "और इसी तरह, किसी विशेष चेहरे की छाया के क्षेत्र के बजाय, मैं केवल f का s लिखने जा रहा हूं, जहां वह सबस्क्रिप्ट j इंगित करता है कि मैं किस चेहरे के बारे में बात कर रहा हूं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube. ",
  "translatedText": "लेकिन निःसंदेह, हमें वास्तव में घन पर लागू एक विशेष घुमाव की छाया के बारे में बात करनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces. ",
  "translatedText": "तो मैं इसे घन पर लागू कुछ घुमाव के एस के रूप में लिख सकता हूं, और इसी तरह दाईं ओर, यह किसी दिए गए चेहरे पर लागू उसी घुमाव की छाया का क्षेत्र है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on. ",
  "translatedText": "हाथ में अधिक कॉम्पैक्ट नोटेशन के साथ, आइए कई अलग-अलग घुमावों में इस छाया क्षेत्र के औसत के बारे में सोचें, आर 1, आर 2, आर 3 और इसी तरह के कुछ नमूने।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n. ",
  "translatedText": "पुनः, उस औसत में उन सभी छाया क्षेत्रों को जोड़ना और फिर उन्हें n से विभाजित करना शामिल है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube. ",
  "translatedText": "और सिद्धांत रूप में, अगर हम इसे बड़े और बड़े नमूनों के लिए देखें, तो अनंत तक पहुंचें, इससे हमें घन की छाया का औसत क्षेत्र मिलेगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial? ",
  "translatedText": "आप में से कुछ लोग सोच रहे होंगे, हां, हम यह जानते हैं, आप यह पहले ही कह चुके हैं, लेकिन इसे लिखना फायदेमंद है ताकि हम समझ सकें कि घन के एक विशेष घूर्णन के लिए छाया क्षेत्र को योग के रूप में व्यक्त करना क्यों है इसके सभी पहलुओं में, या कम से कम उस राशि का आधा गुना, यह लाभदायक क्यों है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us? ",
  "translatedText": "यह हमारे लिए क्या करने जा रहा है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces. ",
  "translatedText": "ठीक है, चलो बस इसे लिखें, जहां घन के इन घुमावों में से प्रत्येक के लिए, हम उस छाया को सभी चेहरों पर लागू उसी घुमाव के योग के रूप में तोड़ सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column. ",
  "translatedText": "और जब इसे इस तरह एक ग्रिड के रूप में लिखा जाता है, तो हम ऐलिस की दूसरी अंतर्दृष्टि प्राप्त कर सकते हैं, जो कि जिस तरह से हम योग के बारे में सोच रहे हैं उसे पंक्ति दर पंक्ति में बदलने के बजाय कॉलम दर कॉलम में बदलना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations. ",
  "translatedText": "उदाहरण के लिए, यदि हमने अपना ध्यान केवल पहले कॉलम पर केंद्रित किया है, तो यह हमें जो बता रहा है वह कई अलग-अलग झुकावों में पहले चेहरे की छाया के क्षेत्र को जोड़ना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face. ",
  "translatedText": "इसलिए यदि हम उस राशि को लें और उसे अपने नमूने के आकार से विभाजित करें, तो इससे हमें इस चेहरे की छाया के क्षेत्र के लिए एक अनुभवजन्य औसत प्राप्त होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square. ",
  "translatedText": "इसलिए यदि हम बड़े और बड़े नमूने लेते हैं, तो उस आकार को अनंत तक जाने दें, यह एक वर्ग के औसत छाया क्षेत्र के करीब पहुंच जाएगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number. ",
  "translatedText": "इसी तरह, दूसरे स्तंभ को घन के दूसरे फलक का औसत क्षेत्रफल बताने के रूप में सोचा जा सकता है, जो निश्चित रूप से वही संख्या होनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face. ",
  "translatedText": "और किसी अन्य कॉलम के लिए भी यही सौदा, यह हमें एक विशेष चेहरे के लिए औसत क्षेत्र बता रहा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression. ",
  "translatedText": "तो यह हमें अपनी संपूर्ण अभिव्यक्ति के बारे में सोचने का एक बहुत अलग तरीका देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half. ",
  "translatedText": "यह कहने के बजाय कि सभी अलग-अलग दिशाओं में घनों का क्षेत्रफल जोड़ें, हम कह सकते हैं कि बस छह अलग-अलग चेहरों के लिए औसत छाया जोड़ें और कुल को एक आधे से विभाजित करें।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first. ",
  "translatedText": "यहां बाईं ओर का पद पहले पंक्तियों को जोड़ने के बारे में सोच रहा है, और दाईं ओर का पद पहले कॉलम जोड़ने के बारे में सोच रहा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows. ",
  "translatedText": "संक्षेप में, चेहरे की छायाओं के योग का औसत चेहरे की छायाओं के औसत के योग के समान है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later. ",
  "translatedText": "हो सकता है कि वह अदला-बदली सरल लगे, हो सकता है कि न हो, लेकिन मैं आपको बता सकता हूं कि जो कदम हमने अभी उठाया है, वास्तव में उससे कुछ अधिक है, लेकिन हम उस पर बाद में विचार करेंगे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face. ",
  "translatedText": "और याद रखें, हम जानते हैं कि किसी विशेष चेहरे का औसत क्षेत्रफल उस चेहरे के क्षेत्रफल से गुणा करके कुछ सार्वभौमिक आनुपातिकता स्थिरांक जैसा दिखता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube. ",
  "translatedText": "इसलिए यदि हम इसे घन के सभी सतहों पर जोड़ रहे हैं, तो हम इसे घन के सतह क्षेत्र के कुछ स्थिर समय के बराबर मान सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting. ",
  "translatedText": "और यह काफी दिलचस्प है. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area. ",
  "translatedText": "इस घन की छाया का औसत क्षेत्र इसके सतह क्षेत्र के समानुपाती होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is. ",
  "translatedText": "लेकिन साथ ही, आप शिकायत कर सकते हैं, ठीक है, ऐलिस यहां केवल प्रतीकों का एक समूह बना रही है, क्योंकि इसमें से कोई भी मायने नहीं रखता अगर हम नहीं जानते कि आनुपातिकता स्थिरांक क्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious. ",
  "translatedText": "मेरा मतलब है, यह लगभग स्पष्ट प्रतीत होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area. ",
  "translatedText": "जैसे, निश्चित रूप से औसत छाया क्षेत्र सतह क्षेत्र के समानुपाती होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other. ",
  "translatedText": "वे दोनों द्वि-आयामी मात्राएँ हैं, इसलिए उन्हें एक-दूसरे के साथ तालमेल बिठाना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious. ",
  "translatedText": "मेरा मतलब है, यह स्पष्ट नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true. ",
  "translatedText": "आख़िरकार, एक नज़दीकी प्रकाश स्रोत के लिए, यह सच नहीं होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first. ",
  "translatedText": "और साथ ही, यह व्यवसाय जहां हमने ग्रिड कॉलम को कॉलम दर कॉलम बनाम पंक्ति दर पंक्ति जोड़ा है, वह पहले की तुलना में थोड़ा अधिक सूक्ष्म है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations. ",
  "translatedText": "इस सबके पीछे एक सूक्ष्म, छिपी हुई धारणा है, जो एक विशेष महत्व रखती है जब हम इस सवाल पर फिर से विचार करना चुनते हैं कि सभी अभिविन्यासों के स्थान पर किस संभाव्यता वितरण को लिया जा रहा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional. ",
  "translatedText": "लेकिन किसी भी चीज़ से अधिक, इसका स्पष्ट न होने का कारण यह है कि इस परिणाम का महत्व केवल यह नहीं है कि ये दो मान आनुपातिक हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them. ",
  "translatedText": "यह है कि एक समान तथ्य किसी भी उत्तल ठोस के लिए सच होगा, और, महत्वपूर्ण रूप से, ऐलिस ने अब तक जो भी बनाया है उसकी वास्तविक सामग्री यह है कि यह उन सभी में समान आनुपातिकता स्थिरांक होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here. ",
  "translatedText": "अब यदि आप वास्तव में इस पर विचार करें, तो आप में से कुछ लोग यह अनुमान लगाने में सक्षम हो सकते हैं कि ऐलिस यहां से चीजों को कैसे समाप्त करने में सक्षम है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful. ",
  "translatedText": "यह सचमुच आनंददायक है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1295.42
 },
 {
  "input": "It's honestly my main reason for covering this topic. ",
  "translatedText": "ईमानदारी से कहूं तो इस विषय को कवर करने का यही मेरा मुख्य कारण है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1295.6,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid. ",
  "translatedText": "लेकिन इससे पहले कि हम इसमें उतरें, मुझे लगता है कि उसके परिणाम को कम आंकना आसान है जब तक कि हम इस बात का विवरण नहीं लेते कि वह क्या है जिससे वह बचने का प्रबंधन करती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations. ",
  "translatedText": "तो आइए एक पल रुकें और अपना ध्यान वापस बॉब की दुनिया की ओर मोड़ें, क्योंकि जब ऐलिस यह सब कर रहा है, तो वह कुछ गणनाएँ करने में व्यस्त है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations. ",
  "translatedText": "वास्तव में, वह जिस पर काम कर रहा है, वह वही ढूँढ़ रहा है जो ऐलिस को अभी तक पता नहीं चल पाया है, यानी कि एक वर्ग की छाया के क्षेत्र के लिए उसने जो सूत्र पाया है उसे कैसे लिया जाए और उसका औसत निकालने की कोशिश करने का स्वाभाविक अगला कदम उठाया जाए।वर्ग की छाया सभी संभावित झुकावों पर औसत है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector. ",
  "translatedText": "तो जिस तरह से बॉब शुरू करता है, अगर वह इस वर्ग के लिए सभी अलग-अलग संभावित झुकावों के बारे में सोच रहा है, तो उसे पूछना है, सभी अलग-अलग सामान्य वेक्टर क्या हैं जो उस वर्ग में इन सभी झुकावों में हो सकते हैं, क्योंकि इसकी छाया के बारे में सब कुछ उस सामान्य पर आ जाता है वेक्टर।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere. ",
  "translatedText": "यह देखना बहुत कठिन नहीं है कि वे सभी संभावित सामान्य वैक्टर एक गोले की सतह का पता लगाते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1352.32
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1. ",
  "translatedText": "यदि हम मान लें कि यह एक इकाई सामान्य वेक्टर है, तो यह त्रिज्या 1 वाला एक गोला है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.32,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other. ",
  "translatedText": "और इसके अलावा, बॉब का अनुमान है कि इस क्षेत्र के प्रत्येक बिंदु के घटित होने की संभावना किसी अन्य बिंदु की तरह ही होनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way. ",
  "translatedText": "हमारी संभावनाएँ उस तरह से एक समान होनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1363.98
 },
 {
  "input": "There's no reason to prefer one direction over another. ",
  "translatedText": "एक दिशा को दूसरी दिशा से अधिक प्राथमिकता देने का कोई कारण नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1364.02,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful. ",
  "translatedText": "लेकिन निरंतर संभावनाओं के संदर्भ में, किसी विशेष व्यक्तिगत बिंदु की संभावना के बारे में बात करना बहुत उपयोगी नहीं है, क्योंकि क्षेत्र पर बिंदुओं की अनगिनत अनंतता में, यह शून्य और अनुपयोगी होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself. ",
  "translatedText": "इसलिए इसके बजाय, इस एकरूपता को व्यक्त करने का अधिक सटीक तरीका यह कहना होगा कि गोले पर क्षेत्र के किसी भी पैच में हमारी सामान्य वेक्टर भूमि उस क्षेत्र के समानुपाती होनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere. ",
  "translatedText": "अधिक विशेष रूप से, इसे गोले के कुल सतह क्षेत्र से विभाजित उस छोटे पैच के क्षेत्र के बराबर होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere. ",
  "translatedText": "यदि यह सच है, तो इससे कोई फर्क नहीं पड़ता कि हम क्षेत्र के किस हिस्से पर विचार कर रहे हैं, गोले पर समान वितरण से हमारा मतलब यही है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom. ",
  "translatedText": "अब स्पष्ट होने के लिए, गोले पर बिंदु 3डी अंतरिक्ष में अभिविन्यास के समान नहीं हैं, क्योंकि भले ही आप जानते हों कि इस वर्ग में कौन सा सामान्य वेक्टर होने वाला है, यह हमें स्वतंत्रता की एक और डिग्री के साथ छोड़ देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1411.7
 },
 {
  "input": "The square could be rotated about that normal vector. ",
  "translatedText": "वर्ग को उस सामान्य वेक्टर के चारों ओर घुमाया जा सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.9,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same. ",
  "translatedText": "लेकिन बॉब को वास्तव में स्वतंत्रता की उस अतिरिक्त डिग्री की परवाह नहीं है, क्योंकि उन सभी मामलों में, छाया का क्षेत्र समान है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1422.0
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical. ",
  "translatedText": "यह केवल उस सामान्य वेक्टर और ऊर्ध्वाधर के बीच के कोण की कोज्या पर निर्भर है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.36,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat. ",
  "translatedText": "जो एक तरह से साफ-सुथरा है. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1427.84
 },
 {
  "input": "All those shadows are genuinely different shapes. ",
  "translatedText": "वे सभी छायाएँ वास्तव में अलग-अलग आकृतियाँ हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1428.0,
  "end": 1430.06
 },
 {
  "input": "They're not the same. ",
  "translatedText": "वे एक जैसे नहीं हैं. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.16,
  "end": 1430.9
 },
 {
  "input": "But the area of each of them will be the same. ",
  "translatedText": "लेकिन इनमें से प्रत्येक का क्षेत्रफल एक ही होगा. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.2,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere. ",
  "translatedText": "इसका मतलब यह है कि जब बॉब सभी संभावित झुकावों पर इस औसत छाया क्षेत्र को चाहता है, तो उसे वास्तव में सभी अलग-अलग संभावित सामान्य वैक्टरों, गोले पर सभी अलग-अलग संभावित बिंदुओं के लिए थीटा के कोसाइन के इस निरपेक्ष मूल्य का औसत मूल्य जानने की जरूरत है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this? ",
  "translatedText": "तो, आप इस तरह औसत की गणना कैसे करते हैं? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward. ",
  "translatedText": "ठीक है, अगर हम किसी प्रकार की अलग पिक्सेलयुक्त दुनिया में रहते हैं, जहां उस सामान्य वेक्टर के संभावित कोण थीटा की केवल एक सीमित संख्या है, तो औसत बहुत सीधा होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow. ",
  "translatedText": "आप जो करते हैं वह थीटा के किसी विशेष मान पर उतरने की संभावना का पता लगाते हैं, जो हमें कुछ बताएगा जैसे कि उस कोण के साथ सामान्य वेक्टर कितने गोले बनाते हैं, और फिर आप इसे उस चीज़ से गुणा करते हैं जिसे हम औसत लेना चाहते हैं का, छाया के क्षेत्रफल के लिए यह सूत्र।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians. ",
  "translatedText": "और फिर आप थीटा के विभिन्न संभावित मानों को 0 से 180 डिग्री या पीआई रेडियन तक जोड़ देंगे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0. ",
  "translatedText": "लेकिन निश्चित रूप से, वास्तव में, थीटा के संभावित मूल्यों की एक निरंतरता है, यह बेशुमार अनंतता है, और थीटा के किसी विशिष्ट विशेष मूल्य पर उतरने की संभावना वास्तव में 0 होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0. ",
  "translatedText": "और इसलिए इस तरह के योग का दुर्भाग्य से वास्तव में कोई मतलब नहीं है, या यदि इसका कोई मतलब है, तो अनंत संख्या में शून्य जोड़ने पर हमें केवल 0 मिलना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral. ",
  "translatedText": "इसके बजाय हम जो करते हैं उसका संक्षिप्त उत्तर यह है कि हम एक अभिन्न की गणना करते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now. ",
  "translatedText": "और मैं आपके साथ बराबरी करूंगा, यहां कठिन बात यह है कि मैं पूरी तरह से निश्चित नहीं हूं कि आप में से जो लोग अभी देख रहे हैं, उनसे मुझे किस पृष्ठभूमि का अनुमान लगाना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here. ",
  "translatedText": "शायद यह मामला है कि आप कैलकुलस के साथ काफी सहज हैं और आपको यहां इस मुद्दे पर विस्तार से बताने के लिए मेरी आवश्यकता नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that. ",
  "translatedText": "शायद यह मामला है कि आप कैलकुलस से परिचित नहीं हैं और मुझे इस तरह इंटीग्रल को यूं ही नहीं फेंकना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher. ",
  "translatedText": "या हो सकता है कि आपने कुछ समय पहले कैलकुलस की कक्षा ली हो लेकिन आपको थोड़े से पुनश्चर्या की आवश्यकता हो।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process. ",
  "translatedText": "मैं इसे सेट करने के विकल्प के साथ जा रहा हूं जैसे कि यह एक कैलकुलस पाठ है, क्योंकि ईमानदारी से कहें तो, भले ही आप इंटीग्रल के साथ काफी सहज हों, उन्हें सेट करना एक प्रकार की त्रुटि-प्रवण प्रक्रिया हो सकती है, और वापस कॉल करना अंतर्निहित परिभाषा इस प्रक्रिया में स्वयं को जांचने का एक अच्छा तरीका है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°. ",
  "translatedText": "यदि हम कैलकुलस के अस्तित्व में आने से पहले के समय में रहते थे और इंटीग्रल्स कोई चीज़ नहीं थी, और हम इस प्रश्न का अनुमानित उत्तर चाहते थे, तो एक तरीका यह हो सकता था कि हम θ के लिए मानों का एक नमूना लें जो 0 से लेकर 180°. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ. ",
  "translatedText": "हम उनके बारे में सोच सकते हैं कि वे समान रूप से दूरी पर हैं और प्रत्येक के बीच कुछ प्रकार का अंतर है, कुछ डेल्टा θ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample. ",
  "translatedText": "और यह अभी भी मामला है कि θ के किसी विशेष मान के घटित होने की संभावना के बारे में पूछना अनुपयोगी होगा, भले ही वह हमारे नमूने में 1 हो।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful. ",
  "translatedText": "वह संभावना अभी भी 0 होगी और यह अनुपयोगी होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ. ",
  "translatedText": "लेकिन यह पूछना उपयोगी है कि डेल्टा θ की चौड़ाई वाले अक्षांश के इस छोटे बैंड में, हमारे नमूने से दो अलग-अलग मानों के बीच गिरने की संभावना क्या है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band. ",
  "translatedText": "हमारी धारणा के आधार पर कि इस क्षेत्र में वितरण एक समान होना चाहिए, इस बैंड के क्षेत्र को जानने की संभावना कम हो जाती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere. ",
  "translatedText": "अधिक विशेष रूप से, उस बैंड में बेतरतीब ढंग से चुने गए वेक्टर भूमि की संभावना उस क्षेत्र को गोले के कुल सतह क्षेत्र से विभाजित किया जाना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1. ",
  "translatedText": "उस क्षेत्र का पता लगाने के लिए, आइए पहले उस बैंड की त्रिज्या के बारे में सोचें, जो, यदि हमारे गोले की त्रिज्या 1 है, तो निश्चित रूप से 1 से छोटी होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ. ",
  "translatedText": "और वास्तव में, यदि हम यहां उपयुक्त छोटा समकोण त्रिभुज बनाते हैं, तो आप देख सकते हैं कि वह छोटी त्रिज्या, मान लीजिए कि बैंड के शीर्ष पर, हमारे कोण की ज्या, θ की ज्या होनी चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ. ",
  "translatedText": "इसका मतलब यह है कि बैंड की परिधि उस कोण की ज्या का 2π गुना होनी चाहिए, और फिर बैंड का क्षेत्रफल उस परिधि का उसकी मोटाई का गुना होना चाहिए, वह छोटा डेल्टा θ होना चाहिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity. ",
  "translatedText": "या यों कहें कि हमारे बैंड का क्षेत्रफल लगभग इतनी ही है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better. ",
  "translatedText": "महत्वपूर्ण बात यह है कि θ के कई और मूल्यों के बेहतर नमूने के लिए, उस सन्निकटन की सटीकता बेहतर और बेहतर होती जाएगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared. ",
  "translatedText": "अब याद रखें, हम जिस कारण से यह क्षेत्र चाहते थे, वह उस बैंड में गिरने की संभावना को जानना है, जो कि इस क्षेत्र को गोले के सतह क्षेत्र से विभाजित किया जाता है, जिसे हम इसके वर्ग त्रिज्या का 4π गुना मानते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula. ",
  "translatedText": "यह एक ऐसा मूल्य है जिसकी गणना आप उस अभिन्न अंग के साथ भी कर सकते हैं जिसे हम अभी स्थापित कर रहे हैं, लेकिन अभी हम इसे एक दिए गए, एक मानक प्रसिद्ध सूत्र के रूप में ले सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square. ",
  "translatedText": "और यह संभावना स्वयं उस दिशा में एक कदम है जो हम वास्तव में चाहते हैं, जो एक वर्ग की छाया का औसत क्षेत्र है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point. ",
  "translatedText": "इसे प्राप्त करने के लिए, हम इस संभावना को संबंधित छाया क्षेत्र से गुणा करेंगे, जो कि cosθ अभिव्यक्ति का यह निरपेक्ष मान है जिसे हमने इस बिंदु तक कई बार देखा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken. ",
  "translatedText": "और इस औसत के लिए हमारा अनुमान अब सभी अलग-अलग बैंडों, हमारे द्वारा लिए गए θ के सभी अलग-अलग नमूनों में इस अभिव्यक्ति को जोड़ने पर आएगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element. ",
  "translatedText": "वैसे, यह तब है जब बॉब पूरी तरह से अपने तत्व में है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer. ",
  "translatedText": "हमारे पास बहुत सारे सटीक सूत्र हैं जो किसी ठोस चीज़ का वर्णन करते हैं, वास्तव में एक वास्तविक उत्तर की ओर बढ़ते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this. ",
  "translatedText": "और फिर, अगर यह बहुत अधिक विवरण जैसा लगता है, तो मैं चाहता हूं कि आप उस तथ्य की सराहना करें, ताकि आप सराहना कर सकें कि यह कितना जादुई है जब ऐलिस किसी तरह इस सब से बचने में कामयाब होती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself. ",
  "translatedText": "वैसे भी, अपनी अभिव्यक्ति को देखते हुए, आइए चीजों को थोड़ा साफ करें, जैसे कि उन सभी शर्तों को अलग करना जो θ पर निर्भर नहीं हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half. ",
  "translatedText": "और हम इसे सरल बना सकते हैं कि 2π को 4π से विभाजित करने पर केवल 1 आधा प्राप्त होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here. ",
  "translatedText": "और इसे कैलकुलस के साथ इंटीग्रल के साथ थोड़ा और अधिक अनुरूप बनाने के लिए, मैं यहां योग के अंदर मुख्य शब्दों की अदला-बदली करता हूं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is. ",
  "translatedText": "अब हमारे पास जो है, यह राशि जो हमारे प्रश्न के उत्तर का अनुमान लगाएगी, वह लगभग एक अभिन्न के बराबर है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π. ",
  "translatedText": "योग के लिए सिग्मा लिखने के बजाय, हम अभिन्न प्रतीक लिखते हैं, इस प्रकार का लम्बा लीबनिज़ियन, हमें दिखाता है कि हम 0 से π तक जा रहे हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken. ",
  "translatedText": "और चरण आकार को δθ, एक ठोस परिमित राशि के रूप में वर्णित करने के बजाय, हम इसे dθ के रूप में वर्णित करते हैं, जिसे मैं इस तथ्य के संकेत के रूप में सोचना पसंद करता हूं कि किसी प्रकार की सीमा ली जा रही है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself. ",
  "translatedText": "परिभाषा के अनुसार, उस अभिन्न का मतलब यह है कि नीचे का योग महीन और महीन उपविभाजनों, अधिक सघन नमूनों के लिए जो कुछ भी हो, वह है जिसे हम θ के लिए ही ले सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook. ",
  "translatedText": "और इस बिंदु पर, आप में से उन लोगों के लिए जो कैलकुलस जानते हैं, मैं केवल यह विवरण लिखूंगा कि आप वास्तव में इसे कैसे करेंगे, जैसा कि आप इसे बॉब की नोटबुक में लिखा हुआ देख सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity. ",
  "translatedText": "यह सामान्य विरोधी व्युत्पन्न सामग्री है, लेकिन एक महत्वपूर्ण कदम एक निश्चित ट्रिगर पहचान लाना है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square. ",
  "translatedText": "अंत में, बॉब ने ऐसा करने के बाद जो पाया वह आश्चर्यजनक रूप से स्पष्ट तथ्य है कि एक वर्ग की छाया का औसत क्षेत्र उस वर्ग के क्षेत्रफल का ठीक आधा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know. ",
  "translatedText": "यह रहस्य स्थिरांक है, जिसे ऐलिस अभी तक नहीं जानती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now. ",
  "translatedText": "यदि बॉब उसके कंधे की ओर देखे और उसने जो काम किया है उसे देखे, तो वह समस्या को अभी समाप्त कर सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer. ",
  "translatedText": "वह उस स्थिरांक को प्लग इन करता है जो उसे अभी मिला है, और वह अंतिम उत्तर जानता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution? ",
  "translatedText": "और अब, अंततः, इस सब की पृष्ठभूमि में, ऐलिस अंतिम समाधान को पूरा करने के लिए क्या करती है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds. ",
  "translatedText": "मैंने उसका परिचय ऐसे व्यक्ति के रूप में कराया जो वास्तव में अपने द्वारा प्राप्त परिणामों का सामान्यीकरण करना पसंद करती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems. ",
  "translatedText": "और आमतौर पर वे सामान्यीकरण दिलचस्प फ़ुटनोट के रूप में समाप्त हो जाते हैं जो वास्तव में विशेष समस्याओं को हल करने के लिए उपयोगी नहीं होते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result. ",
  "translatedText": "लेकिन यह एक ऐसा मामला है जहां सामान्यीकरण ही उसे मात्रात्मक परिणाम की ओर खींचता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids. ",
  "translatedText": "याद रखें, उसने अब तक जो पाया है उसका सार यह है कि यदि आप किसी उत्तल ठोस को देखते हैं, तो उसकी छाया का औसत क्षेत्र उसके सतह क्षेत्र के समानुपाती होगा, और गंभीर रूप से, यह सभी में समान आनुपातिकता स्थिरांक होगा इन ठोस पदार्थों का. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow. ",
  "translatedText": "तो ऐलिस को बस वहां एक उत्तल ठोस ढूंढना है जहां वह पहले से ही इसकी छाया का औसत क्षेत्र जानती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going. ",
  "translatedText": "और आप में से कुछ लोग देख सकते हैं कि यह कहां जा रहा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere. ",
  "translatedText": "हमारे लिए उपलब्ध सबसे सममित ठोस एक गोला है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr². ",
  "translatedText": "इससे कोई फर्क नहीं पड़ता कि उस गोले का अभिविन्यास क्या है, उसकी छाया, सपाट प्रक्षेपण छाया, हमेशा πr² के क्षेत्र के साथ एक वृत्त होती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area. ",
  "translatedText": "तो विशेष रूप से, यह इसका औसत छाया क्षेत्र है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr². ",
  "translatedText": "और एक गोले का सतह क्षेत्र, जैसा कि मैंने पहले उल्लेख किया है, बिल्कुल 4πr² है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it. ",
  "translatedText": "वैसे, मैंने उस सतह क्षेत्र सूत्र के बारे में बात करते हुए एक वीडियो बनाया था और कैलकुलस के अस्तित्व में आने से हजारों साल पहले आर्किमिडीज़ ने इसे कैसे साबित किया था, इसलिए आपको इसे खोजने के लिए इंटीग्रल की आवश्यकता नहीं है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense. ",
  "translatedText": "ऐलिस ने जो किया उसका जादू यह है कि वह इस विशिष्ट प्रतीत होने वाले तथ्य को ले सकती है, कि एक गोले की छाया का क्षेत्रफल उसके सतह क्षेत्र का ठीक 1/4 है, और इसका उपयोग एक अधिक सामान्य तथ्य को निष्कर्ष निकालने के लिए किया जाता है, जो कि किसी भी उत्तल ठोस के लिए होता है।वहाँ, इसकी छाया और सतह क्षेत्र एक निश्चित अर्थ में, उसी तरह से संबंधित हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s². ",
  "translatedText": "तो इसके साथ, वह जा सकती है और एक घन के बारे में विशेष प्रश्न का विवरण भर सकती है, और कह सकती है कि इसका औसत छाया क्षेत्र इसके सतह क्षेत्र का 1⁄4 गुना, 6s² होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all. ",
  "translatedText": "लेकिन इससे भी अधिक यादगार तथ्य जिसके बारे में सोचते हुए आप सो जाएंगे, वह यह है कि वास्तव में इससे कोई फर्क नहीं पड़ता कि हम एक घन के बारे में बात कर रहे थे।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces. ",
  "translatedText": "अब, यह सब बहुत सुंदर है, लेकिन आप में से कुछ लोग शिकायत कर सकते हैं कि यह वास्तव में एक वैध तर्क नहीं है, क्योंकि गोले में सपाट सतह नहीं होती है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces. ",
  "translatedText": "जब मैंने कहा कि ऐलिस का तर्क किसी भी उत्तल ठोस को सामान्यीकृत करता है, अगर हम वास्तव में तर्क को देखें, तो यह निश्चित रूप से फ्लैट चेहरों की सीमित संख्या के उपयोग पर निर्भर करता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces. ",
  "translatedText": "उदाहरण के लिए, यदि हम इसे एक डोडेकाहेड्रोन पर मैप कर रहे थे, तो आप यह कहकर शुरू करेंगे कि उस डोडेकाहेड्रोन की एक विशेष छाया का क्षेत्र उसके सभी चेहरों की छाया के क्षेत्रों के योग का ठीक 1⁄2 गुना दिखता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion. ",
  "translatedText": "एक बार फिर, आप उस निष्कर्ष को निकालने के लिए उत्तलता तर्क के साथ मिश्रित प्रकाश की एक निश्चित किरण का उपयोग कर सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face. ",
  "translatedText": "और याद रखें, उस छाया क्षेत्र को योग के रूप में व्यक्त करने का लाभ यह है कि जब हम विभिन्न घुमावों के समूह का औसत निकालना चाहते हैं, तो हम उस योग को एक बड़े ग्रिड के रूप में वर्णित कर सकते हैं, जहां हम कॉलम दर कॉलम जा सकते हैं और औसत क्षेत्र पर विचार कर सकते हैं प्रत्येक चेहरे की छाया के लिए. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area. ",
  "translatedText": "और साथ ही, एक महत्वपूर्ण तथ्य बहुत पहले का निष्कर्ष था, कि किसी भी 2डी वस्तु, एक सपाट 2डी वस्तु के लिए औसत छाया, जो महत्वपूर्ण है, उसके क्षेत्रफल के कुछ सार्वभौमिक आनुपातिक स्थिरांक के बराबर होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself. ",
  "translatedText": "महत्व यह था कि वह स्थिरांक स्वयं आकार पर निर्भर नहीं था।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever. ",
  "translatedText": "यह एक वर्ग, या एक बिल्ली, या हमारे डोडेकाहेड्रोन के पंचकोणीय चेहरे, जो भी हो सकता था।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain. ",
  "translatedText": "इसलिए, इसे जल्दबाजी में एक ऐसे क्षेत्र में ले जाने के बाद, जिसमें सपाट सतहों की सीमित संख्या नहीं है, आपके लिए शिकायत करना सही होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in. ",
  "translatedText": "लेकिन सौभाग्य से, इसे भरना बहुत आसान विवरण है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere. ",
  "translatedText": "आप जो कर सकते हैं वह अलग-अलग पॉलीहेड्रा के अनुक्रम की कल्पना करना है जो क्रमिक रूप से एक गोले का अनुमान लगाता है, इस अर्थ में कि उनके चेहरे गोले की वास्तविक सतह के चारों ओर कसकर और कसकर चिपक जाते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant. ",
  "translatedText": "उनमें से प्रत्येक सन्निकटन के लिए, हम एक ही निष्कर्ष निकाल सकते हैं, कि इसकी औसत छाया इस सार्वभौमिक आनुपातिकता स्थिरांक के साथ इसके सतह क्षेत्र के समानुपाती होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant. ",
  "translatedText": "तो फिर, अगर हम कहते हैं, ठीक है, आइए प्रत्येक चरण पर औसत छाया क्षेत्र और प्रत्येक चरण पर सतह क्षेत्र के बीच अनुपात की सीमा लें, ठीक है, चूंकि वह अनुपात कभी नहीं बदलता है, यह हमेशा इस स्थिरांक के बराबर होता है, फिर में सीमा, यह भी उस स्थिरांक के बराबर होने वाली है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr². ",
  "translatedText": "लेकिन दूसरी ओर, उनकी परिभाषा के अनुसार, सीमा में, उनका औसत छाया क्षेत्र एक वृत्त का होना चाहिए, जो कि πr² है, और सतह क्षेत्रों की सीमा गोले का सतह क्षेत्र, 4πr² होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition. ",
  "translatedText": "इसलिए हम वास्तव में उस निष्कर्ष को प्राप्त करते हैं जो अंतर्ज्ञान सुझाएगा, लेकिन, जैसा कि यहां ऐलिस के तर्क के साथ बहुत आम है, हमें उस अंतर्ज्ञान को उचित ठहराने में थोड़ा नाजुक होना होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do. ",
  "translatedText": "ऐलिस और बॉब के इस विरोधाभास को एक मूल्य निर्णय की तरह सामने लाना आसान है, जैसे कि मैं कह रहा हूं, देखो ऐलिस कितनी चतुर हो गई है, उसने उन सभी गणनाओं को समझदारी से टाल दिया जो बॉब को करनी थी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion. ",
  "translatedText": "लेकिन यह एक बहुत ही गुमराह करने वाला निष्कर्ष होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math. ",
  "translatedText": "मुझे लगता है कि एक महत्वपूर्ण तरीका यह है कि गणित को लोकप्रिय बनाना वास्तव में गणित करने की भावना से भिन्न है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations. ",
  "translatedText": "चालाक सबूत, कुछ चतुर गहरी अंतर्दृष्टि के साथ तर्क दिखाने के प्रति यह पूर्वाग्रह है जो आपको गणना करने से बचने देता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's. ",
  "translatedText": "मैं बस प्रक्षेपण कर सकता हूं, क्योंकि मैं इसके लिए बहुत दोषी हूं, लेकिन यहां स्क्रीन के दूसरी तरफ बैठकर मैं आपको जो बता सकता हूं, वह यह है कि बॉब की तुलना में ऐलिस के दृष्टिकोण के बारे में एक वीडियो बनाना अधिक आकर्षक लगता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments. ",
  "translatedText": "एक बात के लिए, ऐलिस के दृष्टिकोण में, तर्क की रेखा मजेदार है, इसमें ये अच्छे अहा क्षण हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds. ",
  "translatedText": "लेकिन साथ ही, महत्वपूर्ण रूप से, जिस तरह से आप इसे समझाते हैं वह गणितीय पृष्ठभूमि की एक विस्तृत श्रृंखला के लिए कमोबेश एक जैसा है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience. ",
  "translatedText": "बॉब के दृष्टिकोण के बारे में एक वीडियो बनाना बहुत कम आकर्षक है, इसलिए नहीं कि गणनाएं इतनी खराब हैं, मेरा मतलब है, वे ईमानदारी से नहीं हैं, लेकिन व्यावहारिक वास्तविकता यह है कि इसे समझाने की उचित गति अलग-अलग गणितीय के आधार पर बहुत अलग दिखती है दर्शकों में पृष्ठभूमि. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias. ",
  "translatedText": "तो, आप इसे अभी देख रहे हैं, स्पष्ट रूप से ऑनलाइन गणित वीडियो का उपभोग करते हैं, और मुझे लगता है कि ऐसा करने में इस पूर्वाग्रह के बारे में जागरूक होना उचित है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous. ",
  "translatedText": "यदि उद्देश्य समस्या समाधान पर एक वास्तविक सबक है, तो चालाक सबूतों पर बहुत अधिक ध्यान कपटपूर्ण होने का जोखिम रखता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source. ",
  "translatedText": "उदाहरण के लिए, मान लें कि हमें यहां चुनौती मोड में कदम रखना था और नजदीकी प्रकाश स्रोत से मामले के बारे में पूछना था।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere. ",
  "translatedText": "मेरी जानकारी के अनुसार, यहां ऐलिस जैसा कोई आसान समाधान नहीं है, जहां आप केवल एक गोले जैसे एकल आकार से संबंधित हो सकें।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach. ",
  "translatedText": "इससे भी अधिक उत्पादक वार्मअप बॉब के दृष्टिकोण की गणना होगी।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work. ",
  "translatedText": "और यदि आप इस समस्या के इतिहास को देखें, तो इसे 1832 में कॉची द्वारा सिद्ध किया गया था, और यदि हम उनके हस्तलिखित नोट्स को देखें, तो वे ऐलिस के काम की तुलना में बॉब के काम के समान दिखते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle. ",
  "translatedText": "यहीं पृष्ठ 11 के शीर्ष पर, आप देख सकते हैं कि मूलतः वही अभिन्न अंग क्या है जिसे आपने और मैंने बीच में स्थापित किया है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube. ",
  "translatedText": "दूसरी ओर, पेपर की पूरी रूपरेखा एक सामान्य तथ्य को खोजने के लिए है, न कि घन के मामले जैसी किसी विशिष्ट चीज़ को खोजने के लिए।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both. ",
  "translatedText": "इसलिए यदि हम यह प्रश्न पूछ रहे थे कि इन दोनों मानसिकताओं में से कौन सी नई गणित की खोज के कार्य से संबंधित है, तो सही उत्तर लगभग निश्चित रूप से दोनों का मिश्रण होगा।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations. ",
  "translatedText": "लेकिन मैं सुझाव दूंगा कि बहुत से लोग उस मिश्रण के उस हिस्से पर पर्याप्त वजन पर हस्ताक्षर नहीं करते हैं जहां आप गणना में गोता लगाने के लिए उत्सुक हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that. ",
  "translatedText": "और मुझे लगता है कि कुछ जोखिम है कि मेरे द्वारा बनाए गए वीडियो इसमें योगदान दे सकते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study. ",
  "translatedText": "गणितज्ञ एलेक्स कोंटोरोविच के साथ मैंने जो पॉडकास्ट किया, उसमें उन्होंने अंतर्ज्ञान विकसित करने के लिए गणनाओं पर ड्रिलिंग के अक्सर कम महत्व के बारे में बात की, चाहे आप एक नई कक्षा से जुड़े छात्र हों, या एक नए क्षेत्र से जुड़े शोध गणितज्ञ हों।अध्ययन।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made. ",
  "translatedText": "वास्तव में एक श्रोता ने यह उजागर करने के लिए लिखा कि उस विशेष अनुभाग ने क्या प्रभाव डाला।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp. ",
  "translatedText": "वे एक पीएचडी छात्र हैं और खुद को चिंतित बताते हैं कि उनकी गणितीय क्षमताएं फीकी पड़ने लगी हैं, जिसका कारण वे अधिक उम्र और कम तेज होने को मानते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective. ",
  "translatedText": "लेकिन एक अभ्यासरत गणितज्ञ को कुछ नया सीखने के लिए सैकड़ों ठोस उदाहरणों को करने के महत्व के बारे में बात करते हुए सुनना, जाहिर तौर पर इससे उनका दृष्टिकोण बदल गया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results. ",
  "translatedText": "उनके अपने शब्दों में, इसे पहचानने ने उनके दृष्टिकोण और उनके परिणामों को पूरी तरह से बदल दिया।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations. ",
  "translatedText": "और यदि आप इतिहास के प्रसिद्ध गणितज्ञों, न्यूटन, यूलर, गॉस, उन सभी को देखें, तो उन सभी के पास कठिन गणनाएँ करने के लिए असीम धैर्य है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations. ",
  "translatedText": "अंतर्दृष्टि दिखाने के पक्षपाती होने की विडंबना यह है कि हम गणनाओं से बचते हैं, जिस तरह से लोग अक्सर उन अंतर्दृष्टि को खोजने के लिए अंतर्ज्ञान को प्रशिक्षित करते हैं, वह गणनाओं के ढेर लगाने के द्वारा होता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here. ",
  "translatedText": "जो कुछ भी कहा गया है, ऐलिस मानसिकता के बिना यहां निश्चित रूप से कुछ कमी होगी। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes. ",
  "translatedText": "मेरा मतलब है, इसके बारे में सोचें, यह कितना दुखद होगा यदि हमने इस समस्या को एक घन के लिए हल किया, और हम जंगल को देखने और समझने के लिए पेड़ों से बाहर कभी नहीं निकले कि यह एक सुपर सामान्य तथ्य है, यह एक विशाल परिवार पर लागू होता है आकृतियाँ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity. ",
  "translatedText": "और यदि आप मानते हैं कि गणित केवल उन प्रश्नों का उत्तर देने के बारे में नहीं है जो आपके सामने रखे गए हैं, बल्कि नए विचारों और निर्माणों को पेश करने के बारे में है, तो यहां ऐलिस के दृष्टिकोण के बारे में एक मजेदार बात यह है कि यह उत्तलता के विचार को मापने का एक मजेदार तरीका सुझाता है। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex. ",
  "translatedText": "केवल हां-नहीं में उत्तर देने के बजाय, क्या यह उत्तल है, क्या यह नहीं है, हम यह कहकर एक संख्या डाल सकते हैं, किसी ठोस की छाया के औसत क्षेत्र पर विचार करें, इसे 4 से गुणा करें, इसे सतह क्षेत्र से विभाजित करें , और यदि वह संख्या 1 है, तो आपको एक उत्तल ठोस मिला है, लेकिन यदि यह 1 से कम है, तो यह गैर-उत्तल है, और यह 1 के कितना करीब है, यह आपको बताता है कि यह उत्तल होने के कितना करीब है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction. ",
  "translatedText": "साथ ही, यहां ऐलिस समाधान के बारे में एक अच्छी बात यह है कि यह यह समझाने में मदद करता है कि ऐसा क्यों है कि गणितज्ञों के पास कभी-कभी व्यापकता और अमूर्तता के साथ एक विचित्र आकर्षण जैसा दिख सकता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation. ",
  "translatedText": "आप जितने अधिक उदाहरण देखेंगे जहां सामान्यीकरण और अमूर्तीकरण वास्तव में आपको किसी विशिष्ट मामले को सुलझाने में मदद करता है, उतना ही अधिक आप उसी मोह को अपनाना शुरू कर देते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle. ",
  "translatedText": "और आपमें से उन दिग्गज दर्शकों के लिए अंतिम विचार के रूप में, जो अब तक इसमें लगे हुए हैं, हमारी पहेली के मूल आधार के बारे में अभी भी एक अनुत्तरित प्रश्न है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation? ",
  "translatedText": "यादृच्छिक अभिविन्यास चुनने का वास्तव में क्या मतलब है? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox. ",
  "translatedText": "अब अगर यह एक मूर्खतापूर्ण सवाल लगता है, जैसे कि निश्चित रूप से हम जानते हैं कि इसका क्या मतलब होना चाहिए, तो मैं आपको एक वीडियो देखने के लिए प्रोत्साहित करूंगा जो मैंने नंबरफाइल के साथ संभाव्यता की एक पहेली पर किया था जिसे बर्ट्रेंड के विरोधाभास के रूप में जाना जाता है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question. ",
  "translatedText": "इसे देखने के बाद, और यदि आप यहां खेल की कुछ बारीकियों की सराहना करते हैं, तो आपके लिए होमवर्क इस बात पर विचार करना है कि वास्तव में ऐलिस और बॉब इस प्रश्न का स्पष्ट रूप से उत्तर कहां देते हैं।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle. ",
  "translatedText": "बॉब के साथ मामला अपेक्षाकृत सीधा है, लेकिन जिस बिंदु पर ऐलिस सभी अभिविन्यासों के स्थान पर कुछ विशिष्ट वितरण को बंद कर देता है, वह बिल्कुल भी स्पष्ट नहीं है, यह वास्तव में बहुत सूक्ष्म है।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2381.7
 }
]