[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "model": "nmt",
  "translatedText": "Daqui a pouco vou falar sobre um quebra-cabeça muito legal envolvendo a sombra de um cubo.",
  "time_range": [
   0.0,
   4.3
  ]
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "model": "nmt",
  "translatedText": "Mas antes de chegarmos a isso, devo dizer que o objetivo deste vídeo não é exatamente o quebra-cabeça em si, trata-se de dois estilos distintos de resolução de problemas que se refletem em duas maneiras diferentes de resolver esse problema.",
  "time_range": [
   5.0,
   15.24
  ]
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "model": "nmt",
  "translatedText": "Na verdade, vamos antropomorfizar esses dois estilos diferentes imaginando dois alunos, Alice e Bob, que personificam cada uma das abordagens.",
  "time_range": [
   15.78,
   22.7
  ]
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "model": "nmt",
  "translatedText": "Portanto, Bob será o tipo de aluno que realmente adora cálculos.",
  "time_range": [
   23.5,
   26.98
  ]
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "model": "nmt",
  "translatedText": "Assim que chega o momento em que ele consegue se aprofundar nos detalhes e ter uma visão muito concreta da situação concreta que tem pela frente, é aí que ele fica mais satisfeito.",
  "time_range": [
   26.98,
   34.34
  ]
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "model": "nmt",
  "translatedText": "Alice, por outro lado, está mais inclinada a procrastinar os cálculos, não porque ela não saiba como fazê-los ou não queira fazê-los por si só, mas ela prefere obter uma boa visão geral de alto nível do tipo do problema com o qual ela está lidando, a forma geral que ele tem, antes de se aprofundar nos cálculos em si.",
  "time_range": [
   35.12,
   51.36
  ]
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "model": "nmt",
  "translatedText": "Ela ficará mais satisfeita se compreender não apenas a questão específica que está diante dela, mas também a maneira mais ampla possível de generalizá-la, e especialmente se a visão mais geral puder se prestar a cálculos mais rápidos e elegantes, uma vez que ela realmente o faça. sente-se para realizá-los.",
  "time_range": [
   52.16,
   66.94
  ]
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "model": "nmt",
  "translatedText": "Agora, o quebra-cabeça que ambos enfrentarão é encontrar a área média da sombra de um cubo.",
  "time_range": [
   73.02,
   79.14
  ]
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "model": "nmt",
  "translatedText": "Então, se eu tiver um cubo aqui pairando no espaço, há algumas coisas que influenciam a área de sua sombra.",
  "time_range": [
   79.9,
   85.46
  ]
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "model": "nmt",
  "translatedText": "Um óbvio seria o tamanho do cubo, cubo menor, sombra menor.",
  "time_range": [
   85.46,
   89.26
  ]
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "model": "nmt",
  "translatedText": "Mas também se estiver em orientações diferentes, essas orientações correspondem a diferentes sombras específicas com áreas diferentes.",
  "time_range": [
   89.88,
   96.16
  ]
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "model": "nmt",
  "translatedText": "E quando digo para encontrar a média aqui, o que quero dizer é a média de todas as orientações possíveis para um determinado tamanho do cubo.",
  "time_range": [
   96.78,
   103.1
  ]
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "model": "nmt",
  "translatedText": "Os astutos entre vocês podem apontar que também importa muito onde está a fonte de luz.",
  "time_range": [
   104.42,
   108.1
  ]
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "model": "nmt",
  "translatedText": "Se a fonte de luz fosse muito baixa, próxima ao próprio cubo, a sombra acabaria sendo maior.",
  "time_range": [
   108.36,
   112.66
  ]
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "model": "nmt",
  "translatedText": "E se a fonte de luz estiver posicionada lateralmente, isso pode distorcer a sombra e dar-lhe uma forma muito diferente.",
  "time_range": [
   112.66,
   118.56
  ]
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "model": "nmt",
  "translatedText": "Levar em conta a posição da luz é altamente interessante por si só, mas o quebra-cabeça já é bastante difícil, então, pelo menos inicialmente, vamos fazer a coisa mais fácil que pudermos e dizer que a luz está diretamente acima do cubo e muito longe longe, efetivamente infinitamente longe, de modo que tudo o que estamos considerando é uma projeção plana, no sentido de que se você olhar para quaisquer coordenadas, x, y, z, no espaço, a projeção plana seria x, y, 0.",
  "time_range": [
   119.26,
   141.7
  ]
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "model": "nmt",
  "translatedText": "Então, só para nos orientarmos, a situação mais fácil de pensar seria se o cubo estivesse reto, com duas das suas faces paralelas ao solo.",
  "time_range": [
   142.48,
   149.28
  ]
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "model": "nmt",
  "translatedText": "Nesse caso, esta sombra de projeção plana é simplesmente um quadrado, e se dissermos que os comprimentos dos lados do cubo são s, então a área dessa sombra é s ao quadrado.",
  "time_range": [
   149.92,
   157.9
  ]
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "model": "nmt",
  "translatedText": "E, a propósito, sempre que eu tiver um rótulo nessas animações, como esse aqui embaixo, assumirei que o cubo relevante tem comprimento lateral de 1.",
  "time_range": [
   158.74,
   165.46
  ]
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "model": "nmt",
  "translatedText": "Agora, outro caso especial entre todas as orientações que é divertido pensar é se a longa diagonal for paralela à direção da luz.",
  "time_range": [
   166.24,
   173.04
  ]
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "model": "nmt",
  "translatedText": "Nesse caso, a sombra na verdade se parece com um hexágono regular, e se você usar alguns dos métodos que desenvolveremos em alguns minutos, poderá calcular que a área dessa sombra é exatamente a raiz quadrada de 3 vezes a área de uma das faces quadradas.",
  "time_range": [
   173.6,
   185.82
  ]
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "model": "nmt",
  "translatedText": "Mas é claro que, com mais frequência, a sombra real não será tão regular quanto um quadrado ou um hexágono.",
  "time_range": [
   186.66,
   191.2
  ]
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "model": "nmt",
  "translatedText": "É um pouco mais difícil pensar sobre a forma com base em um pouco mais difícil pensar sobre a orientação deste cubo.",
  "time_range": [
   191.66,
   196.24
  ]
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "model": "nmt",
  "translatedText": "Anteriormente, eu casualmente joguei fora esta frase de média de todas as orientações possíveis, mas você poderia perguntar com razão: o que exatamente isso significa?",
  "time_range": [
   197.06,
   205.3
  ]
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "model": "nmt",
  "translatedText": "Acho que muitos de nós temos uma noção intuitiva do que queremos que isso signifique, pelo menos no sentido de qual experimento você faria para verificar isso.",
  "time_range": [
   206.16,
   212.86
  ]
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "model": "nmt",
  "translatedText": "Você pode imaginar jogar este cubo no ar como uma tinta, congelá-lo em algum ponto arbitrário, registrar a área da sombra nessa posição e depois repetir.",
  "time_range": [
   213.06,
   222.44
  ]
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "model": "nmt",
  "translatedText": "Se você fizer isso muitas vezes, poderá calcular a média da sua amostra.",
  "time_range": [
   223.64000000000001,
   228.38
  ]
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "model": "nmt",
  "translatedText": "O número que queremos chegar, a verdadeira média aqui, deve ser o que quer que a média experimental se aproxime à medida que você faz mais e mais lançamentos, aproximando-se de um número infinito.",
  "time_range": [
   229.22,
   237.94
  ]
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "model": "nmt",
  "translatedText": "Mesmo assim, os defensores entre vocês podem reclamar que isso realmente não responde à pergunta, porque deixa em aberto a questão de como estamos definindo um lançamento aleatório.",
  "time_range": [
   240.44,
   247.8
  ]
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "model": "nmt",
  "translatedText": "A maneira adequada de responder a isto, se quisermos que seja mais formal, seria primeiro descrever o espaço de todas as orientações possíveis, ao qual os matemáticos deram um nome sofisticado.",
  "time_range": [
   248.3,
   257.54
  ]
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "model": "nmt",
  "translatedText": "Eles chamam isso de SO3, normalmente definido em termos de uma certa família de matrizes 3x3.",
  "time_range": [
   257.64,
   262.44
  ]
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "model": "nmt",
  "translatedText": "E a questão que queremos responder é: que distribuição de probabilidade estamos a atribuir a todo este espaço?",
  "time_range": [
   263.1,
   268.76
  ]
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "model": "nmt",
  "translatedText": "Somente quando essa distribuição de probabilidade está bem definida é que podemos responder a uma questão que envolve uma média.",
  "time_range": [
   269.1,
   274.5
  ]
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "model": "nmt",
  "translatedText": "Se você é um defensor desse tipo de coisa, quero que adie essa questão até o final do vídeo.",
  "time_range": [
   275.8,
   280.82
  ]
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "model": "nmt",
  "translatedText": "Você ficará surpreso com o quão longe podemos chegar com a ideia mais heurística e experimental de apenas repetir um monte de lançamentos aleatórios sem realmente definir a distribuição.",
  "time_range": [
   280.98,
   288.58
  ]
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "model": "nmt",
  "translatedText": "Uma vez que vemos as soluções de Alice e Bob, é realmente muito interessante perguntar como exatamente cada um deles definiu esta distribuição ao longo do seu caminho.",
  "time_range": [
   289.28,
   296.48
  ]
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "model": "nmt",
  "translatedText": "E lembre-se, esta não pretende ser uma lição sobre sombras de cubos em si, mas uma lição sobre resolução de problemas, contada através das lentes de duas mentalidades diferentes que podemos trazer para o quebra-cabeça.",
  "time_range": [
   297.92,
   307.1
  ]
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "model": "nmt",
  "translatedText": "E como acontece com qualquer lição sobre resolução de problemas, o objetivo aqui não é chegar à resposta o mais rápido possível, mas esperar que você sinta que encontrou a resposta sozinho.",
  "time_range": [
   307.86,
   315.72
  ]
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "model": "nmt",
  "translatedText": "Portanto, se chegar um momento em que você sentir que pode ter uma ideia, dê a si mesmo a liberdade de fazer uma pausa e tentar refletir sobre o assunto.",
  "time_range": [
   316.02,
   320.82
  ]
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "model": "nmt",
  "translatedText": "Como primeiro passo, e isso é realmente independente de qualquer estilo específico de resolução de problemas, sempre que você encontrar uma pergunta difícil, uma coisa boa que você pode fazer é perguntar qual é a variante mais simples e não trivial possível do problema que você pode tentar resolver?",
  "time_range": [
   325.42,
   338.54
  ]
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "model": "nmt",
  "translatedText": "Então, no nosso caso, o que você poderia dizer é, ok, vamos esquecer a média de todas as orientações.",
  "time_range": [
   339.56,
   344.0
  ]
 },
 {
  "input": "That's a tricky thing to think about.",
  "model": "nmt",
  "translatedText": "Isso é uma coisa complicada de se pensar.",
  "time_range": [
   344.12,
   345.42
  ]
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "model": "nmt",
  "translatedText": "E vamos até esquecer todas as diferentes faces do cubo, porque elas se sobrepõem, e isso também é difícil de pensar.",
  "time_range": [
   345.68,
   350.86
  ]
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "model": "nmt",
  "translatedText": "Apenas para uma face específica e uma orientação específica, podemos calcular a área desta sombra?",
  "time_range": [
   351.34,
   356.9
  ]
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "model": "nmt",
  "translatedText": "Mais uma vez, se você quiser se orientar em alguns casos especiais, o mais fácil é quando aquela face está paralela ao solo, caso em que a área da sombra é igual à área da face.",
  "time_range": [
   357.66,
   366.68
  ]
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "model": "nmt",
  "translatedText": "E por outro lado, se inclinarmos essa face 90 graus, então a sua sombra será uma linha reta e terá uma área zero.",
  "time_range": [
   367.18,
   373.44
  ]
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "model": "nmt",
  "translatedText": "Então Bob olha para isso e quer uma fórmula real para essa sombra.",
  "time_range": [
   374.3,
   377.42
  ]
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "model": "nmt",
  "translatedText": "E a maneira como ele pode pensar sobre isso é considerar o vetor normal perpendicular a essa face.",
  "time_range": [
   377.9,
   382.7
  ]
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "model": "nmt",
  "translatedText": "E o que parece relevante é o ângulo que esse vetor normal faz com a vertical, com a direção de onde vem a luz, que poderíamos chamar de teta.",
  "time_range": [
   383.18,
   390.08
  ]
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "model": "nmt",
  "translatedText": "Agora, a partir dos dois casos especiais que acabamos de ver, sabemos que quando teta é igual a zero, a área dessa sombra é igual à área da própria forma, que é s ao quadrado se o quadrado tiver lados de comprimento s.",
  "time_range": [
   391.2,
   401.56
  ]
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "model": "nmt",
  "translatedText": "E se teta for igual a 90 graus, então a área dessa sombra é zero.",
  "time_range": [
   402.2,
   405.8
  ]
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "model": "nmt",
  "translatedText": "E provavelmente não é muito difícil adivinhar que a trigonometria será de alguma forma relevante, então qualquer pessoa confortável com suas funções trigonométricas provavelmente poderia arriscar um palpite sobre qual é a fórmula correta.",
  "time_range": [
   406.24,
   414.62
  ]
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "model": "nmt",
  "translatedText": "Mas Bob é mais detalhista do que isso.",
  "time_range": [
   414.62,
   417.12
  ]
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "model": "nmt",
  "translatedText": "Ele quer provar adequadamente qual deveria ser essa área, em vez de apenas adivinhar com base nos pontos finais.",
  "time_range": [
   417.4,
   422.02
  ]
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "model": "nmt",
  "translatedText": "E a maneira como você pode pensar sobre isso poderia ser algo assim.",
  "time_range": [
   422.82,
   424.74
  ]
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "model": "nmt",
  "translatedText": "Se considerarmos o plano que passa pela vertical, bem como pelo nosso vetor normal, e depois considerarmos todas as diferentes fatias da nossa forma que estão nesse plano, ou paralelas a esse plano, então podemos concentrar a nossa atenção num dois- variante dimensional do problema.",
  "time_range": [
   424.98,
   439.04
  ]
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "model": "nmt",
  "translatedText": "Se olharmos apenas para uma dessas fatias, que tem um vetor normal, a um ângulo teta de distância da vertical, a sua sombra pode ser mais ou menos assim.",
  "time_range": [
   439.32,
   446.78
  ]
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "model": "nmt",
  "translatedText": "E se traçarmos uma linha vertical para a esquerda aqui, teremos um triângulo retângulo.",
  "time_range": [
   447.46,
   451.02
  ]
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "model": "nmt",
  "translatedText": "E a partir daqui podemos fazer um pouco de perseguição de ângulo, onde seguimos o que esse ângulo teta implica sobre o resto do diagrama.",
  "time_range": [
   451.6,
   457.52
  ]
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "model": "nmt",
  "translatedText": "E isto significa que o ângulo reto inferior neste triângulo é precisamente teta.",
  "time_range": [
   458.58,
   462.36
  ]
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "model": "nmt",
  "translatedText": "Então, quando quisermos entender o tamanho dessa sombra em comparação com o tamanho original da peça, podemos pensar no cosseno desse ângulo, teta, que lembra o adjacente sobre a hipotenusa.",
  "time_range": [
   463.48,
   474.58
  ]
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "model": "nmt",
  "translatedText": "É literalmente a relação entre o tamanho da sombra e o tamanho da fatia.",
  "time_range": [
   474.7,
   478.18
  ]
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "model": "nmt",
  "translatedText": "Portanto, o fator pelo qual a fatia é comprimida nesta direção é exatamente o cosseno de teta.",
  "time_range": [
   478.9,
   484.52
  ]
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "model": "nmt",
  "translatedText": "E se ampliarmos a nossa visão para todo o quadrado, todas as fatias nessa direção serão dimensionadas pelo mesmo fator.",
  "time_range": [
   485.14,
   490.18
  ]
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "model": "nmt",
  "translatedText": "Mas na outra direção, naquela perpendicular a esse corte, não há estiramento ou esmagamento, porque a face não está nada inclinada nessa direção.",
  "time_range": [
   490.38,
   498.12
  ]
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "model": "nmt",
  "translatedText": "Portanto, no geral, a sombra bidimensional da nossa face bidimensional também deve ser reduzida por este fator de cosseno de teta.",
  "time_range": [
   498.12,
   505.7
  ]
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "model": "nmt",
  "translatedText": "Isso está de acordo com o que você pode adivinhar intuitivamente, dado o caso em que o ângulo é 0° e o caso em que é 90°, mas é reconfortante ver por que isso é verdade.",
  "time_range": [
   506.26,
   513.38
  ]
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "model": "nmt",
  "translatedText": "E na verdade, como afirmado até agora, isso não é totalmente correto.",
  "time_range": [
   514.96,
   518.32
  ]
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "model": "nmt",
  "translatedText": "Há um pequeno problema com a fórmula que escrevemos.",
  "time_range": [
   518.52,
   520.8
  ]
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "model": "nmt",
  "translatedText": "No caso em que teta é maior que 90°, o cosseno seria na verdade negativo.",
  "time_range": [
   521.34,
   526.24
  ]
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "model": "nmt",
  "translatedText": "Mas é claro que não queremos considerar que a sombra tenha área negativa, pelo menos não num problema como este.",
  "time_range": [
   526.24,
   531.4
  ]
 },
 {
  "input": "So there's two different ways you could solve this.",
  "model": "nmt",
  "translatedText": "Portanto, há duas maneiras diferentes de resolver isso.",
  "time_range": [
   531.86,
   533.3
  ]
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "model": "nmt",
  "translatedText": "Você poderia dizer que só queremos considerar o vetor normal que está apontando para cima, que tem um componente z positivo.",
  "time_range": [
   533.38,
   538.34
  ]
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "model": "nmt",
  "translatedText": "Ou, mais simplesmente, poderíamos dizer, basta pegar no valor absoluto desse cosseno e isso dá-nos uma fórmula válida.",
  "time_range": [
   538.84,
   544.72
  ]
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "model": "nmt",
  "translatedText": "Então Bob está feliz porque tem uma fórmula precisa que descreve a área da sombra.",
  "time_range": [
   546.98,
   550.86
  ]
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "model": "nmt",
  "translatedText": "Mas Alice começa a pensar nisso de forma um pouco diferente.",
  "time_range": [
   551.5,
   554.06
  ]
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "model": "nmt",
  "translatedText": "Ela diz, ok, temos alguma forma, e então aplicamos uma rotação que a situa de alguma forma no espaço 3D.",
  "time_range": [
   554.06,
   560.52
  ]
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "model": "nmt",
  "translatedText": "E então aplicamos uma projeção plana que empurra isso de volta para o espaço bidimensional.",
  "time_range": [
   560.78,
   564.66
  ]
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "model": "nmt",
  "translatedText": "E o que chama a atenção para ela é que ambas são transformações lineares.",
  "time_range": [
   565.08,
   568.34
  ]
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "model": "nmt",
  "translatedText": "Isso significa que, em princípio, você poderia descrever cada uma delas com uma matriz e que a transformação geral seria semelhante ao produto dessas duas matrizes.",
  "time_range": [
   569.06,
   576.2
  ]
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "model": "nmt",
  "translatedText": "O que Alice sabe de um de seus assuntos favoritos, álgebra linear, é que se você pegar alguma forma e considerar sua área, então aplicar alguma transformação linear, então a área dessa saída se parecerá com algumas constantes vezes a área original da forma.",
  "time_range": [
   577.0,
   590.32
  ]
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "model": "nmt",
  "translatedText": "Mais especificamente, temos um nome para essa constante.",
  "time_range": [
   590.9,
   592.78
  ]
 },
 {
  "input": "It's called the determinant of the transformation.",
  "model": "nmt",
  "translatedText": "É chamado de determinante da transformação.",
  "time_range": [
   592.86,
   594.96
  ]
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "model": "nmt",
  "translatedText": "Se você não estiver tão confortável com álgebra linear, poderíamos dar uma descrição muito mais intuitiva e dizer, se você esticar uniformemente a forma original em alguma direção, a saída também será esticada uniformemente em alguma direção.",
  "time_range": [
   596.26,
   607.56
  ]
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "model": "nmt",
  "translatedText": "Portanto, a área de cada um deles deve ser proporcional entre si.",
  "time_range": [
   607.56,
   611.4
  ]
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "model": "nmt",
  "translatedText": "Agora, em princípio, Alice poderia calcular esse determinante, mas não é realmente o estilo dela fazer isso, pelo menos não fazê-lo imediatamente.",
  "time_range": [
   612.16,
   618.32
  ]
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "model": "nmt",
  "translatedText": "Em vez disso, o que ela escreve é como esta constante de proporcionalidade entre a nossa forma original e a sua sombra não depende da forma original.",
  "time_range": [
   618.88,
   627.1
  ]
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "model": "nmt",
  "translatedText": "Poderíamos estar falando sobre a sombra do contorno do gato, ou qualquer outra coisa, e o tamanho realmente não importa.",
  "time_range": [
   627.26,
   632.64
  ]
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "model": "nmt",
  "translatedText": "A única coisa que afeta essa constante de proporcionalidade é a transformação que estamos aplicando, o que neste contexto significa que poderíamos escrevê-la como um fator que depende da rotação aplicada à forma.",
  "time_range": [
   632.64,
   643.14
  ]
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "model": "nmt",
  "translatedText": "No fundo, por causa do cálculo de Bob, sabemos como é esse fator.",
  "time_range": [
   644.5,
   648.22
  ]
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "model": "nmt",
  "translatedText": "Você sabe, é o valor absoluto do cosseno do ângulo entre o vetor normal e a vertical.",
  "time_range": [
   648.36,
   652.5
  ]
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "model": "nmt",
  "translatedText": "Mas Alice agora está apenas dizendo, sim, sim, sim, posso pensar nisso eventualmente quando quiser.",
  "time_range": [
   653.16,
   656.82
  ]
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "model": "nmt",
  "translatedText": "Mas ela sabe que, de qualquer forma, estamos prestes a calcular a média de todas as diferentes orientações, embora tenha alguma esperança de que qualquer fórmula específica sobre uma orientação específica possa ser eliminada nessa média.",
  "time_range": [
   657.04,
   666.8
  ]
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "model": "nmt",
  "translatedText": "Agora é fácil olhar para isso e dizer, ok, bem, Alice não está realmente fazendo nada então.",
  "time_range": [
   668.22,
   671.64
  ]
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "model": "nmt",
  "translatedText": "É claro que a área da sombra é proporcional à área da forma original.",
  "time_range": [
   671.78,
   675.44
  ]
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "model": "nmt",
  "translatedText": "Ambas são quantidades bidimensionais, ambas deveriam ser dimensionadas como coisas bidimensionais.",
  "time_range": [
   675.62,
   679.64
  ]
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "model": "nmt",
  "translatedText": "Mas tenha em mente que isto não seria verdade se estivéssemos lidando com o caso mais difícil, que tem uma fonte de luz mais próxima.",
  "time_range": [
   680.2,
   685.68
  ]
 },
 {
  "input": "In that case, the projection is not linear.",
  "model": "nmt",
  "translatedText": "Nesse caso, a projeção não é linear.",
  "time_range": [
   685.84,
   687.98
  ]
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "model": "nmt",
  "translatedText": "Por exemplo, se eu girar este gato de modo que sua cauda fique bem próxima da fonte de luz, então se eu esticar a forma original uniformemente na direção x, digamos por um fator de 1.5, pode ter um efeito muito desproporcional na sombra final, porque a cauda fica muito desproporcional quando chega muito perto da luz.",
  "time_range": [
   687.98,
   706.2
  ]
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "model": "nmt",
  "translatedText": "Novamente, Alice está atenta a quais propriedades do problema são realmente relevantes, porque isso a ajuda a saber o quanto ela pode generalizar as coisas.",
  "time_range": [
   706.88,
   713.44
  ]
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "model": "nmt",
  "translatedText": "O fato de estarmos pensando em um rosto quadrado e não em algum outro formato importa?",
  "time_range": [
   713.96,
   717.26
  ]
 },
 {
  "input": "No, not really.",
  "model": "nmt",
  "translatedText": "Não, na verdade não.",
  "time_range": [
   717.26,
   718.64
  ]
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "model": "nmt",
  "translatedText": "O fato de a transformação ser linear importa?",
  "time_range": [
   718.78,
   721.32
  ]
 },
 {
  "input": "Yes, absolutely.",
  "model": "nmt",
  "translatedText": "Sim absolutamente.",
  "time_range": [
   721.82,
   722.84
  ]
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "model": "nmt",
  "translatedText": "Alice também pode aplicar uma maneira semelhante de pensar sobre a sombra média para qualquer formato como este.",
  "time_range": [
   726.56,
   731.76
  ]
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "model": "nmt",
  "translatedText": "Digamos que temos alguma sequência de rotações que aplicamos à nossa face quadrada e vamos chamá-las de R1, R2, R3 e assim por diante.",
  "time_range": [
   732.02,
   739.56
  ]
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "model": "nmt",
  "translatedText": "Então a área da sombra em cada um desses casos parece um fator vezes a área do quadrado, e esse fator depende da rotação.",
  "time_range": [
   739.72,
   747.3
  ]
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "model": "nmt",
  "translatedText": "Então, se tomarmos uma média empírica para essa sombra na amostra de rotações que estamos vendo agora, a aparência é somar todas essas áreas de sombra e depois dividir pelo número total que temos.",
  "time_range": [
   748.06,
   758.32
  ]
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "model": "nmt",
  "translatedText": "Agora, por causa da linearidade, esta área do quadrado original pode ser fatorada de forma clara de tudo isso, e termina à esquerda.",
  "time_range": [
   758.9,
   766.46
  ]
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "model": "nmt",
  "translatedText": "Esta não é a média exata que procuramos, é apenas uma média empírica de uma amostra de rotações, mas em princípio o que procuramos é o que isto se aproxima à medida que o tamanho da nossa amostra se aproxima do infinito, e todos os as peças que dependem do tamanho da amostra ficam bem afastadas da própria área.",
  "time_range": [
   767.2,
   783.04
  ]
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "model": "nmt",
  "translatedText": "Então, seja lá o que isso se aproxime do limite, será apenas um número.",
  "time_range": [
   783.58,
   786.46
  ]
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "model": "nmt",
  "translatedText": "Pode ser muito difícil calcular, não temos certeza disso ainda, mas o que Alice observa é que é independente do tamanho e da forma da coisa 2D específica que estamos vendo.",
  "time_range": [
   786.82,
   795.66
  ]
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "model": "nmt",
  "translatedText": "É uma constante de proporcionalidade universal, e a sua esperança é que essa universalidade de alguma forma se preste a uma forma mais elegante de deduzir o que deve ser.",
  "time_range": [
   795.72,
   804.94
  ]
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "model": "nmt",
  "translatedText": "Agora, Bob estaria ansioso para calcular essa constante aqui e agora, e em alguns minutos mostrarei como ele faz isso.",
  "time_range": [
   806.26,
   811.72
  ]
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "model": "nmt",
  "translatedText": "Mas antes disso eu quero ficar um pouco mais no mundo da Alice, porque é aqui que as coisas começam a ficar realmente divertidas.",
  "time_range": [
   812.04,
   816.96
  ]
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "model": "nmt",
  "translatedText": "Em seu desejo de compreender a estrutura geral da questão antes de mergulhar nos detalhes, ela agora está curiosa para saber como a área da sombra do cubo se relaciona com a área de suas faces individuais.",
  "time_range": [
   820.08,
   831.1
  ]
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "model": "nmt",
  "translatedText": "Agora, se pudermos dizer algo sobre a área média de uma face específica, isso nos diz alguma coisa sobre a área média do cubo como um todo?",
  "time_range": [
   831.62,
   838.4
  ]
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "model": "nmt",
  "translatedText": "Por exemplo, uma coisa simples que poderíamos dizer é que essa área é definitivamente menor que a soma das áreas em todas as faces, porque há uma quantidade significativa de sobreposição entre essas sombras.",
  "time_range": [
   839.1,
   848.92
  ]
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "model": "nmt",
  "translatedText": "Mas não está totalmente claro como pensar sobre essa sobreposição, porque se focarmos a nossa atenção apenas em duas faces específicas, em algumas orientações elas não se sobrepõem de todo, mas noutras orientações têm alguma sobreposição, e a forma específica e A área dessa sobreposição parece um pouco complicada de se pensar, muito menos como na Terra faríamos a média disso em todas as diferentes orientações.",
  "time_range": [
   849.64,
   869.82
  ]
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "model": "nmt",
  "translatedText": "Mas Alice tem cerca de três insights inteligentes sobre todo esse problema, e este é o primeiro deles.",
  "time_range": [
   870.66,
   875.46
  ]
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "model": "nmt",
  "translatedText": "Ela diz que, na verdade, se pensarmos no cubo inteiro, e não apenas num par de faces, podemos concluir que a área da sombra para uma determinada orientação é exatamente metade da soma das áreas de todas as faces.",
  "time_range": [
   875.88,
   888.18
  ]
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "model": "nmt",
  "translatedText": "Intuitivamente você pode adivinhar que metade deles está banhada pela luz e a outra metade não, mas aqui está a maneira como ela justifica isso.",
  "time_range": [
   889.58,
   895.66
  ]
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "model": "nmt",
  "translatedText": "Ela diz que para um determinado raio de luz, eles iriam do céu e eventualmente atingiriam um ponto na sombra.",
  "time_range": [
   895.82,
   901.4
  ]
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "model": "nmt",
  "translatedText": "Esse raio passa pelo cubo em exatamente dois pontos.",
  "time_range": [
   902.04,
   904.86
  ]
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "model": "nmt",
  "translatedText": "Há um momento em que entra e um momento em que sai.",
  "time_range": [
   905.12,
   907.6
  ]
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "model": "nmt",
  "translatedText": "Portanto, cada ponto nessa sombra corresponde exatamente a duas faces acima dela.",
  "time_range": [
   907.6,
   913.78
  ]
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "model": "nmt",
  "translatedText": "Bem, tudo bem, isso não é exatamente verdade se aquele feixe de luz passasse pela borda de um dos quadrados.",
  "time_range": [
   914.46,
   919.22
  ]
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "model": "nmt",
  "translatedText": "Há um pouco de ambigüidade sobre quantas faces ele está passando, mas elas representam área zero dentro da sombra, então podemos ignorá-las com segurança se o que estamos tentando fazer é calcular a área.",
  "time_range": [
   919.6,
   929.04
  ]
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "model": "nmt",
  "translatedText": "Se Alice for pressionada e precisar justificar exatamente por que isso é verdade, o que é importante para entender como o problema pode se generalizar, ela poderá apelar para a ideia de convexidade.",
  "time_range": [
   931.02,
   940.82
  ]
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "model": "nmt",
  "translatedText": "A convexidade é uma daquelas propriedades em que muitos de nós temos uma noção intuitiva do que deveria significar, você sabe, são formas que simplesmente se projetam, nunca se amassam para dentro.",
  "time_range": [
   941.42,
   948.58
  ]
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "model": "nmt",
  "translatedText": "Mas os matemáticos têm uma maneira bastante inteligente de formalizar isso, que é útil para provas reais.",
  "time_range": [
   949.14,
   953.02
  ]
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "model": "nmt",
  "translatedText": "Dizem que um conjunto é convexo se a reta que liga quaisquer dois pontos dentro desse conjunto estiver inteiramente contida no próprio conjunto.",
  "time_range": [
   953.68,
   961.66
  ]
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "model": "nmt",
  "translatedText": "Portanto, um quadrado é convexo porque não importa onde você coloque dois pontos dentro desse quadrado, a reta que os conecta estará inteiramente contida dentro do quadrado.",
  "time_range": [
   961.66,
   969.66
  ]
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "model": "nmt",
  "translatedText": "Mas algo como o símbolo pi não é convexo.",
  "time_range": [
   970.28,
   972.72
  ]
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "model": "nmt",
  "translatedText": "Posso facilmente encontrar dois pontos diferentes, de modo que a linha que os conecta tenha um pico fora do próprio conjunto.",
  "time_range": [
   972.84,
   978.32
  ]
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "model": "nmt",
  "translatedText": "Nenhuma das letras da palavra convexa é convexa.",
  "time_range": [
   978.94,
   982.6
  ]
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "model": "nmt",
  "translatedText": "Você pode encontrar dois pontos de modo que a linha que os conecta passe fora do conjunto.",
  "time_range": [
   982.7,
   987.02
  ]
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "model": "nmt",
  "translatedText": "É uma maneira muito inteligente de formalizar essa ideia de uma forma que apenas se projeta para fora, porque sempre que ela se inclina para dentro, você pode encontrar essas linhas de contra-exemplo.",
  "time_range": [
   987.46,
   996.16
  ]
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "model": "nmt",
  "translatedText": "Nosso cubo, por ser convexo, entre o primeiro ponto de entrada e o último ponto de saída, tem que ficar inteiramente dentro do cubo por definição de convexidade.",
  "time_range": [
   996.38,
   1005.18
  ]
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "model": "nmt",
  "translatedText": "Mas se estivéssemos lidando com alguma outra forma não-convexa, como um donut, você poderia encontrar um raio de luz que entra, depois sai, depois entra e sai novamente, então você não teria uma relação dois-para-um limpa. proteger das sombras.",
  "time_range": [
   1005.74,
   1016.16
  ]
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "model": "nmt",
  "translatedText": "As sombras de todas as suas diferentes partes, se você cobrisse isso com um monte de faces, não seriam exatamente duas vezes a área da própria sombra.",
  "time_range": [
   1016.6,
   1024.08
  ]
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "model": "nmt",
  "translatedText": "Então, esse é o primeiro insight importante: as sombras da face cobrem duplamente a sombra do cubo.",
  "time_range": [
   1024.76,
   1028.26
  ]
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "model": "nmt",
  "translatedText": "E o próximo é um pouco mais simbólico, então vamos começar abreviando um pouco nossa notação para liberar espaço na tela.",
  "time_range": [
   1028.88,
   1034.66
  ]
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "model": "nmt",
  "translatedText": "Em vez de escrever a área da sombra do cubo, escreverei apenas s do cubo.",
  "time_range": [
   1035.36,
   1039.68
  ]
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "model": "nmt",
  "translatedText": "E da mesma forma, em vez da área da sombra de uma face específica, vou apenas escrever s de f, onde o subscrito j indica de qual face estou falando.",
  "time_range": [
   1040.32,
   1048.42
  ]
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "model": "nmt",
  "translatedText": "Mas é claro que deveríamos estar falando sobre a sombra de uma rotação específica aplicada ao cubo.",
  "time_range": [
   1048.42,
   1053.62
  ]
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "model": "nmt",
  "translatedText": "Então eu poderia escrever isso como s de alguma rotação aplicada ao cubo, e da mesma forma à direita, é a área da sombra dessa mesma rotação aplicada a uma determinada das faces.",
  "time_range": [
   1054.1,
   1063.26
  ]
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "model": "nmt",
  "translatedText": "Com a notação mais compacta em mãos, vamos pensar na média dessa área de sombra em muitas rotações diferentes, alguma amostra de r1, r2, r3 e assim por diante.",
  "time_range": [
   1063.76,
   1073.7
  ]
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "model": "nmt",
  "translatedText": "Novamente, essa média envolve apenas somar todas essas áreas de sombra e depois dividi-las por n.",
  "time_range": [
   1074.12,
   1079.22
  ]
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "model": "nmt",
  "translatedText": "E, em princípio, se olharmos para amostras cada vez maiores, deixemos que n se aproxime do infinito, o que nos daria a área média da sombra do cubo.",
  "time_range": [
   1079.94,
   1087.36
  ]
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "model": "nmt",
  "translatedText": "Alguns de vocês podem estar pensando, sim, nós sabemos disso, vocês já disseram isso, mas é benéfico escrevê-lo para que possamos entender por que expressar a área de sombra para uma rotação específica do cubo como uma soma em todas as suas faces, ou pelo menos metade dessa soma, por que isso é benéfico?",
  "time_range": [
   1088.26,
   1103.42
  ]
 },
 {
  "input": "What is it going to do for us?",
  "model": "nmt",
  "translatedText": "O que isso fará por nós?",
  "time_range": [
   1103.6,
   1104.76
  ]
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "model": "nmt",
  "translatedText": "Bem, vamos apenas escrever, onde para cada uma dessas rotações do cubo, poderíamos decompor essa sombra como uma soma nessa mesma rotação aplicada em todas as faces.",
  "time_range": [
   1105.56,
   1113.9
  ]
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "model": "nmt",
  "translatedText": "E quando é escrito como uma grade como esta, podemos chegar ao segundo insight de Alice, que é mudar a maneira como pensamos sobre a soma, de linha por linha para coluna por coluna.",
  "time_range": [
   1114.54,
   1123.72
  ]
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "model": "nmt",
  "translatedText": "Por exemplo, se focarmos nossa atenção apenas na primeira coluna, o que ela nos diz é somar a área da sombra da primeira face em muitas orientações diferentes.",
  "time_range": [
   1125.84,
   1135.08
  ]
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "model": "nmt",
  "translatedText": "Então, se pegarmos nesta soma e a dividirmos pelo tamanho da nossa amostra, isso dá-nos uma média empírica para a área da sombra desta face.",
  "time_range": [
   1135.64,
   1142.94
  ]
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "model": "nmt",
  "translatedText": "Portanto, se pegarmos amostras cada vez maiores, deixando esse tamanho ir até o infinito, isso se aproximará da área de sombra média de um quadrado.",
  "time_range": [
   1143.8,
   1150.24
  ]
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "model": "nmt",
  "translatedText": "Da mesma forma, pode-se pensar que a segunda coluna nos informa a área média da segunda face do cubo, que deve, obviamente, ser o mesmo número.",
  "time_range": [
   1152.12,
   1159.78
  ]
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "model": "nmt",
  "translatedText": "E o mesmo acontece com qualquer outra coluna: ela nos diz a área média de um rosto específico.",
  "time_range": [
   1160.44,
   1164.36
  ]
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "model": "nmt",
  "translatedText": "Isso nos dá uma maneira muito diferente de pensar sobre toda a nossa expressão.",
  "time_range": [
   1164.98,
   1168.04
  ]
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "model": "nmt",
  "translatedText": "Em vez de somar as áreas dos cubos em todas as diferentes orientações, poderíamos dizer apenas somar as sombras médias das seis faces diferentes e dividir o total pela metade.",
  "time_range": [
   1168.38,
   1177.56
  ]
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "model": "nmt",
  "translatedText": "O termo à esquerda aqui pensa em somar as linhas primeiro, e o termo à direita pensa em somar as colunas primeiro.",
  "time_range": [
   1178.04,
   1183.76
  ]
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "model": "nmt",
  "translatedText": "Resumindo, a média da soma das sombras das faces é igual à soma da média das sombras das faces.",
  "time_range": [
   1184.6799999999998,
   1191.14
  ]
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "model": "nmt",
  "translatedText": "Talvez essa troca pareça simples, talvez não, mas posso dizer que há um pouco mais do que aparenta no passo que acabamos de dar, mas falaremos disso mais tarde.",
  "time_range": [
   1192.14,
   1199.7
  ]
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "model": "nmt",
  "translatedText": "E lembre-se, sabemos que a área média de uma face específica se parece com uma constante de proporcionalidade universal vezes a área dessa face.",
  "time_range": [
   1200.78,
   1208.22
  ]
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "model": "nmt",
  "translatedText": "Então, se somarmos isso em todas as faces do cubo, poderíamos pensar nisso como igualando uma constante vezes a área da superfície do cubo.",
  "time_range": [
   1208.8,
   1215.2
  ]
 },
 {
  "input": "And that's pretty interesting.",
  "model": "nmt",
  "translatedText": "E isso é muito interessante.",
  "time_range": [
   1215.92,
   1216.76
  ]
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "model": "nmt",
  "translatedText": "A área média da sombra deste cubo será proporcional à sua área de superfície.",
  "time_range": [
   1216.98,
   1221.48
  ]
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "model": "nmt",
  "translatedText": "Mas, ao mesmo tempo, você pode reclamar, bem, Alice está apenas empurrando um monte de símbolos aqui, porque nada disso importa se não soubermos o que é essa constante de proporcionalidade.",
  "time_range": [
   1222.68,
   1231.08
  ]
 },
 {
  "input": "I mean, it almost seems obvious.",
  "model": "nmt",
  "translatedText": "Quero dizer, quase parece óbvio.",
  "time_range": [
   1231.66,
   1233.38
  ]
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "model": "nmt",
  "translatedText": "Tipo, é claro que a área média de sombra deve ser proporcional à área da superfície.",
  "time_range": [
   1233.64,
   1237.62
  ]
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "model": "nmt",
  "translatedText": "Ambas são quantidades bidimensionais, portanto devem ser dimensionadas em sincronia uma com a outra.",
  "time_range": [
   1237.88,
   1242.26
  ]
 },
 {
  "input": "I mean, it's not obvious.",
  "model": "nmt",
  "translatedText": "Quero dizer, não é óbvio.",
  "time_range": [
   1243.08,
   1244.38
  ]
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "model": "nmt",
  "translatedText": "Afinal, para uma fonte de luz mais próxima, isso simplesmente não seria verdade.",
  "time_range": [
   1244.64,
   1247.28
  ]
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "model": "nmt",
  "translatedText": "E também, esse negócio em que somamos a grade coluna por coluna versus linha por linha é um pouco mais matizado do que pode parecer à primeira vista.",
  "time_range": [
   1248.12,
   1254.7
  ]
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "model": "nmt",
  "translatedText": "Há uma suposição sutil e oculta subjacente a tudo isso, que tem um significado especial quando optamos por revisitar a questão de qual distribuição de probabilidade está sendo tomada no espaço de todas as orientações.",
  "time_range": [
   1255.22,
   1266.3
  ]
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "model": "nmt",
  "translatedText": "Mas, mais do que tudo, a razão pela qual não é óbvio é que a importância deste resultado aqui não é apenas o facto de estes dois valores serem proporcionais.",
  "time_range": [
   1267.3,
   1275.36
  ]
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "model": "nmt",
  "translatedText": "É que um facto análogo será válido para quaisquer sólidos convexos e, crucialmente, o conteúdo real do que Alice construiu até agora é que será a mesma constante de proporcionalidade em todos eles.",
  "time_range": [
   1276.14,
   1287.92
  ]
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "model": "nmt",
  "translatedText": "Agora, se vocês realmente refletirem sobre isso, alguns de vocês poderão prever a maneira como Alice será capaz de terminar as coisas a partir daqui.",
  "time_range": [
   1289.28,
   1294.18
  ]
 },
 {
  "input": "It's really delightful.",
  "model": "nmt",
  "translatedText": "É realmente delicioso.",
  "time_range": [
   1294.18,
   1295.42
  ]
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "model": "nmt",
  "translatedText": "Honestamente, é meu principal motivo para cobrir este tópico.",
  "time_range": [
   1295.6,
   1297.94
  ]
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "model": "nmt",
  "translatedText": "Mas antes de entrarmos nisso, acho que é fácil subestimar o resultado dela, a menos que nos aprofundemos nos detalhes do que ela consegue evitar.",
  "time_range": [
   1298.24,
   1306.14
  ]
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "model": "nmt",
  "translatedText": "Então, vamos reservar um momento para voltar nossa atenção para o mundo de Bob, porque enquanto Alice fazia tudo isso, ele estava ocupado fazendo alguns cálculos.",
  "time_range": [
   1306.86,
   1314.4
  ]
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "model": "nmt",
  "translatedText": "Na verdade, o que ele tem trabalhado é descobrir exatamente o que Alice ainda precisa descobrir, que é como pegar a fórmula que ele encontrou para a área da sombra de um quadrado e dar o próximo passo natural de tentar encontrar a média disso. a sombra do quadrado foi calculada em média sobre todas as orientações possíveis.",
  "time_range": [
   1314.98,
   1329.98
  ]
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "model": "nmt",
  "translatedText": "Então, a maneira como Bob começa, se ele está pensando em todas as diferentes orientações possíveis para este quadrado, é perguntar quais são todos os diferentes vetores normais que esse quadrado pode ter em todas essas orientações, porque tudo em sua sombra se resume a essa normal vetor.",
  "time_range": [
   1334.62,
   1347.24
  ]
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "model": "nmt",
  "translatedText": "Não é muito difícil ver que todos esses vetores normais possíveis traçam a superfície de uma esfera.",
  "time_range": [
   1347.8,
   1352.32
  ]
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "model": "nmt",
  "translatedText": "Se assumirmos que é um vetor normal unitário, é uma esfera com raio 1.",
  "time_range": [
   1352.32,
   1355.56
  ]
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "model": "nmt",
  "translatedText": "Além disso, Bob calcula que cada ponto desta esfera deveria ter a mesma probabilidade de ocorrer como qualquer outro.",
  "time_range": [
   1356.42,
   1361.58
  ]
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "model": "nmt",
  "translatedText": "Nossas probabilidades deveriam ser uniformes dessa forma.",
  "time_range": [
   1362.0,
   1363.98
  ]
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "model": "nmt",
  "translatedText": "Não há razão para preferir uma direção a outra.",
  "time_range": [
   1364.02,
   1366.32
  ]
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "model": "nmt",
  "translatedText": "Mas no contexto de probabilidades contínuas, não é muito útil falar sobre a probabilidade de um determinado ponto individual, porque na incontável infinidade de pontos na esfera, isso seria zero e inútil.",
  "time_range": [
   1367.12,
   1377.44
  ]
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "model": "nmt",
  "translatedText": "Então, em vez disso, a maneira mais precisa de expressar esta uniformidade seria dizer que a probabilidade de o nosso vetor normal aterrar em qualquer pedaço de área da esfera deveria ser proporcional a essa própria área.",
  "time_range": [
   1377.44,
   1389.44
  ]
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "model": "nmt",
  "translatedText": "Mais especificamente, deveria ser igual à área daquela pequena mancha dividida pela área total da superfície da esfera.",
  "time_range": [
   1389.96,
   1395.12
  ]
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "model": "nmt",
  "translatedText": "Se isso for verdade, não importa que área da área estejamos considerando, é isso que queremos dizer com distribuição uniforme na esfera.",
  "time_range": [
   1395.68,
   1401.06
  ]
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "model": "nmt",
  "translatedText": "Agora, para ficar claro, pontos na esfera não são a mesma coisa que orientações no espaço 3D, porque mesmo que você saiba qual vetor normal esse quadrado terá, isso nos deixa com outro grau de liberdade.",
  "time_range": [
   1402.0,
   1411.7
  ]
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "model": "nmt",
  "translatedText": "O quadrado poderia ser girado em torno desse vetor normal.",
  "time_range": [
   1411.9,
   1414.16
  ]
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "model": "nmt",
  "translatedText": "Mas Bob não precisa realmente se preocupar com esse grau extra de liberdade, porque em todos esses casos, a área da sombra é a mesma.",
  "time_range": [
   1414.96,
   1422.0
  ]
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "model": "nmt",
  "translatedText": "Depende apenas do cosseno do ângulo entre o vetor normal e a vertical.",
  "time_range": [
   1422.36,
   1426.46
  ]
 },
 {
  "input": "Which is kind of neat.",
  "model": "nmt",
  "translatedText": "O que é legal.",
  "time_range": [
   1427.18,
   1427.84
  ]
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "model": "nmt",
  "translatedText": "Todas essas sombras têm formas genuinamente diferentes.",
  "time_range": [
   1428.0,
   1430.06
  ]
 },
 {
  "input": "They're not the same.",
  "model": "nmt",
  "translatedText": "Eles não são iguais.",
  "time_range": [
   1430.16,
   1430.9
  ]
 },
 {
  "input": "But the area of each of them will be the same.",
  "model": "nmt",
  "translatedText": "Mas a área de cada um deles será a mesma.",
  "time_range": [
   1431.2,
   1433.54
  ]
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "model": "nmt",
  "translatedText": "O que isto significa é que quando Bob deseja esta área de sombra média sobre todas as orientações possíveis, tudo o que ele realmente precisa saber é o valor médio deste valor absoluto do cosseno de teta para todos os diferentes vetores normais possíveis, todos os diferentes pontos possíveis na esfera.",
  "time_range": [
   1434.72,
   1448.44
  ]
 },
 {
  "input": "So, how do you compute an average like this?",
  "model": "nmt",
  "translatedText": "Então, como você calcula uma média como essa?",
  "time_range": [
   1449.12,
   1451.32
  ]
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "model": "nmt",
  "translatedText": "Bem, se vivêssemos em algum tipo de mundo pixelado discreto, onde há apenas um número finito de ângulos teta possíveis que esse vetor normal poderia ter, a média seria bastante direta.",
  "time_range": [
   1452.54,
   1461.44
  ]
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "model": "nmt",
  "translatedText": "O que você faz é encontrar a probabilidade de cair em qualquer valor específico de teta, o que nos dirá algo como quanto da esfera os vetores normais com aquele ângulo compõem, e então você multiplica isso pela coisa que queremos calcular como média de, esta fórmula para a área da sombra.",
  "time_range": [
   1461.44,
   1475.94
  ]
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "model": "nmt",
  "translatedText": "E então você adicionaria isso a todos os diferentes valores possíveis de teta, variando de 0 a 180 graus, ou pi radianos.",
  "time_range": [
   1476.86,
   1484.02
  ]
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "model": "nmt",
  "translatedText": "Mas é claro que, na realidade, existe um continuum de valores possíveis de teta, esse infinito incontável, e a probabilidade de chegar a qualquer valor específico de teta será, na verdade, 0.",
  "time_range": [
   1485.06,
   1495.98
  ]
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "model": "nmt",
  "translatedText": "E, portanto, uma soma como essa, infelizmente, não faz nenhum sentido, ou se faz sentido, somar infinitos zeros deveria nos dar apenas um 0.",
  "time_range": [
   1496.68,
   1504.16
  ]
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "model": "nmt",
  "translatedText": "A resposta curta para o que fazemos é calcular uma integral.",
  "time_range": [
   1505.8,
   1508.88
  ]
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "model": "nmt",
  "translatedText": "E vou ser sincero com vocês, a parte difícil aqui é que não tenho muita certeza de qual histórico devo assumir daqueles que estão assistindo agora.",
  "time_range": [
   1509.66,
   1515.26
  ]
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "model": "nmt",
  "translatedText": "Talvez você se sinta bastante confortável com cálculo e não precise que eu insista nesse assunto aqui.",
  "time_range": [
   1515.64,
   1519.8
  ]
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "model": "nmt",
  "translatedText": "Talvez seja o caso de você não estar familiarizado com cálculo e eu não deveria estar simplesmente jogando integrais assim.",
  "time_range": [
   1519.8,
   1525.9
  ]
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "model": "nmt",
  "translatedText": "Ou talvez você tenha feito uma aula de cálculo há algum tempo, mas precisa de uma atualização.",
  "time_range": [
   1525.9,
   1529.44
  ]
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "model": "nmt",
  "translatedText": "Vou escolher a opção de configurar isso como se fosse uma aula de cálculo, porque, para ser honesto, mesmo quando você está bastante confortável com integrais, configurá-las pode ser um processo sujeito a erros, e ligar de volta à definição subjacente é uma boa maneira de verificar você mesmo no processo.",
  "time_range": [
   1529.82,
   1543.04
  ]
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "model": "nmt",
  "translatedText": "Se vivêssemos em uma época antes da existência do cálculo e as integrais não existissem, e quiséssemos aproximar uma resposta a essa pergunta, uma maneira de fazer isso é pegar uma amostra de valores para θ que varia de 0 a 180°.",
  "time_range": [
   1543.78,
   1556.52
  ]
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "model": "nmt",
  "translatedText": "Poderíamos pensar neles como espaçados uniformemente com algum tipo de diferença entre cada um, algum delta θ.",
  "time_range": [
   1557.18,
   1562.04
  ]
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "model": "nmt",
  "translatedText": "E ainda seria inútil perguntar sobre a probabilidade de ocorrência de um determinado valor de θ, mesmo que seja 1 na nossa amostra.",
  "time_range": [
   1562.62,
   1569.24
  ]
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "model": "nmt",
  "translatedText": "Essa probabilidade ainda seria 0 e seria inútil.",
  "time_range": [
   1569.66,
   1572.36
  ]
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "model": "nmt",
  "translatedText": "Mas o que é útil perguntar é a probabilidade de cair entre dois valores diferentes da nossa amostra, nesta pequena faixa de latitude com largura de delta θ.",
  "time_range": [
   1572.36,
   1582.02
  ]
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "model": "nmt",
  "translatedText": "Com base na nossa suposição de que a distribuição ao longo desta esfera deve ser uniforme, essa probabilidade resume-se a conhecer a área desta banda.",
  "time_range": [
   1582.4,
   1589.56
  ]
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "model": "nmt",
  "translatedText": "Mais especificamente, as chances de um vetor escolhido aleatoriamente pousar naquela banda deveriam ser aquela área dividida pela área total da superfície da esfera.",
  "time_range": [
   1590.02,
   1596.72
  ]
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "model": "nmt",
  "translatedText": "Para descobrir essa área, vamos primeiro pensar no raio dessa banda, que, se o raio da nossa esfera for 1, será definitivamente menor que 1.",
  "time_range": [
   1596.72,
   1605.28
  ]
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "model": "nmt",
  "translatedText": "E de fato, se desenharmos o pequeno triângulo retângulo apropriado aqui, você pode ver que aquele pequeno raio, digamos apenas no topo da banda, deveria ser o seno do nosso ângulo, o seno de θ.",
  "time_range": [
   1605.9,
   1614.78
  ]
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "model": "nmt",
  "translatedText": "Isso significa que a circunferência da banda deve ser 2π vezes o seno desse ângulo, e então a área da banda deve ser essa circunferência vezes sua espessura, aquele pequeno delta θ.",
  "time_range": [
   1615.52,
   1625.52
  ]
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "model": "nmt",
  "translatedText": "Ou melhor, a área da nossa banda é aproximadamente esta quantidade.",
  "time_range": [
   1625.52,
   1629.08
  ]
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "model": "nmt",
  "translatedText": "O que é importante é que, para uma amostra mais precisa com muito mais valores de θ, a precisão dessa aproximação ficaria cada vez melhor.",
  "time_range": [
   1629.54,
   1636.32
  ]
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "model": "nmt",
  "translatedText": "Agora lembre-se, a razão pela qual queríamos esta área é saber a probabilidade de cair nessa banda, que é esta área dividida pela área da superfície da esfera, que sabemos ser 4π vezes o seu raio ao quadrado.",
  "time_range": [
   1637.54,
   1648.08
  ]
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "model": "nmt",
  "translatedText": "Esse é um valor que você também poderia calcular com uma integral semelhante àquela que estamos configurando agora, mas por enquanto podemos tomá-lo como um dado, como uma fórmula padrão bem conhecida.",
  "time_range": [
   1648.66,
   1656.08
  ]
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "model": "nmt",
  "translatedText": "E esta probabilidade em si é apenas um trampolim na direção do que realmente queremos, que é a área média da sombra de um quadrado.",
  "time_range": [
   1656.84,
   1663.32
  ]
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "model": "nmt",
  "translatedText": "Para conseguir isso, multiplicaremos essa probabilidade pela área de sombra correspondente, que é esse valor absoluto da expressão cosθ que vimos muitas vezes até agora.",
  "time_range": [
   1664.24,
   1673.02
  ]
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "model": "nmt",
  "translatedText": "E a nossa estimativa para esta média se resumiria agora à soma desta expressão em todas as diferentes bandas, em todas as diferentes amostras de θ que obtivemos.",
  "time_range": [
   1673.5,
   1681.7
  ]
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "model": "nmt",
  "translatedText": "A propósito, é aqui que Bob está totalmente em seu elemento.",
  "time_range": [
   1683.44,
   1686.36
  ]
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "model": "nmt",
  "translatedText": "Temos muitas fórmulas exatas que descrevem algo muito concreto, na verdade nos aprofundando no caminho para uma resposta real.",
  "time_range": [
   1686.58,
   1691.86
  ]
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "model": "nmt",
  "translatedText": "E, novamente, se parecerem muitos detalhes, quero que vocês apreciem esse fato, para que possam apreciar o quão mágico é quando Alice consegue de alguma forma evitar tudo isso.",
  "time_range": [
   1692.52,
   1701.92
  ]
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "model": "nmt",
  "translatedText": "De qualquer forma, olhando para a nossa expressão, vamos limpar um pouco as coisas, como fatorar todos os termos que não dependem do próprio θ.",
  "time_range": [
   1702.8799999999999,
   1709.0
  ]
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "model": "nmt",
  "translatedText": "E podemos simplificar que 2π dividido por 4π seja simplesmente 1 meio.",
  "time_range": [
   1709.72,
   1713.48
  ]
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "model": "nmt",
  "translatedText": "E para torná-lo um pouco mais análogo ao cálculo, com integrais, deixe-me trocar os termos principais dentro da soma aqui.",
  "time_range": [
   1714.54,
   1719.46
  ]
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "model": "nmt",
  "translatedText": "O que temos agora, esta soma que vai aproximar a resposta à nossa pergunta, é quase o que é uma integral.",
  "time_range": [
   1719.96,
   1726.04
  ]
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "model": "nmt",
  "translatedText": "Em vez de escrever o sigma para soma, escrevemos o símbolo integral, uma espécie de s Leibniziano alongado, mostrando-nos que estamos indo de 0 a π.",
  "time_range": [
   1726.48,
   1733.98
  ]
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "model": "nmt",
  "translatedText": "E em vez de descrever o tamanho do passo como δθ, uma quantidade finita concreta, em vez disso descrevemo-lo como dθ, o que gosto de pensar como um sinal do facto de que algum tipo de limite está a ser tomado.",
  "time_range": [
   1734.72,
   1745.16
  ]
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "model": "nmt",
  "translatedText": "O que essa integral significa, por definição, é qualquer que seja a soma na parte inferior que se aproxime para subdivisões cada vez mais finas, amostras mais densas que poderíamos tomar para o próprio θ.",
  "time_range": [
   1746.08,
   1757.1
  ]
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "model": "nmt",
  "translatedText": "E neste ponto, para aqueles que conhecem cálculo, vou apenas escrever os detalhes de como vocês realmente fariam isso, como vocês podem ver no caderno de Bob.",
  "time_range": [
   1759.04,
   1766.62
  ]
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "model": "nmt",
  "translatedText": "É o material anti-derivativo usual, mas o passo principal é trazer uma certa identidade trigonométrica.",
  "time_range": [
   1767.16,
   1772.16
  ]
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "model": "nmt",
  "translatedText": "No final, o que Bob descobre depois de fazer isso é o fato surpreendentemente claro de que a área média da sombra de um quadrado é precisamente metade da área desse quadrado.",
  "time_range": [
   1773.06,
   1783.52
  ]
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "model": "nmt",
  "translatedText": "Esta é a constante misteriosa, que Alice ainda não conhece.",
  "time_range": [
   1784.58,
   1787.56
  ]
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "model": "nmt",
  "translatedText": "Se Bob olhasse por cima do ombro e visse o trabalho que ela fez, ele poderia resolver o problema agora mesmo.",
  "time_range": [
   1788.12,
   1792.78
  ]
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "model": "nmt",
  "translatedText": "Ele insere a constante que acabou de encontrar e sabe a resposta final.",
  "time_range": [
   1793.0,
   1796.16
  ]
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "model": "nmt",
  "translatedText": "E agora, finalmente, com tudo isso como pano de fundo, o que Alice faz para levar a cabo a solução final?",
  "time_range": [
   1800.22,
   1806.2
  ]
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "model": "nmt",
  "translatedText": "Apresentei-a como alguém que gosta muito de generalizar os resultados que encontra.",
  "time_range": [
   1806.86,
   1810.26
  ]
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "model": "nmt",
  "translatedText": "E normalmente essas generalizações acabam como notas de rodapé interessantes que não são realmente materiais para resolver problemas específicos.",
  "time_range": [
   1810.84,
   1816.68
  ]
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "model": "nmt",
  "translatedText": "Mas este é um caso em que a própria generalização a leva a um resultado quantitativo.",
  "time_range": [
   1817.18,
   1821.76
  ]
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "model": "nmt",
  "translatedText": "Lembre-se, a substância do que ela descobriu até agora é que se você olhar para qualquer sólido convexo, então a área média de sua sombra será proporcional à sua área de superfície e, criticamente, terá a mesma constante de proporcionalidade em todos desses sólidos.",
  "time_range": [
   1821.76,
   1836.5
  ]
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "model": "nmt",
  "translatedText": "Portanto, tudo o que Alice precisa de fazer é encontrar apenas um único sólido convexo onde ela já conhece a área média da sua sombra.",
  "time_range": [
   1837.1,
   1844.46
  ]
 },
 {
  "input": "And some of you may see where this is going.",
  "model": "nmt",
  "translatedText": "E alguns de vocês podem ver onde isso vai dar.",
  "time_range": [
   1845.16,
   1846.84
  ]
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "model": "nmt",
  "translatedText": "O sólido mais simétrico disponível para nós é uma esfera.",
  "time_range": [
   1846.84,
   1850.06
  ]
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "model": "nmt",
  "translatedText": "Não importa qual seja a orientação dessa esfera, sua sombra, a sombra plana da projeção, é sempre um círculo com área de πr².",
  "time_range": [
   1850.52,
   1858.02
  ]
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "model": "nmt",
  "translatedText": "Então, em particular, essa é a área média de sombra.",
  "time_range": [
   1858.62,
   1861.04
  ]
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "model": "nmt",
  "translatedText": "E a área superficial de uma esfera, como mencionei antes, é exatamente 4πr².",
  "time_range": [
   1861.78,
   1866.32
  ]
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "model": "nmt",
  "translatedText": "A propósito, eu fiz um vídeo falando sobre a fórmula da área de superfície e como Arquimedes a provou milhares de anos antes de o cálculo existir, então você não precisa de integrais para encontrá-la.",
  "time_range": [
   1867.1,
   1876.34
  ]
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "model": "nmt",
  "translatedText": "A mágica do que Alice fez é que ela pode pegar esse fato aparentemente específico, de que a sombra de uma esfera tem uma área exatamente igual a 1/4 de sua área superficial, e usá-lo para concluir um fato muito mais geral, que para qualquer sólido convexo lá fora, sua sombra e área de superfície estão relacionadas da mesma forma, em certo sentido.",
  "time_range": [
   1876.34,
   1893.58
  ]
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "model": "nmt",
  "translatedText": "Então, com isso, ela pode preencher os detalhes da questão específica sobre um cubo e dizer que sua área de sombra média será 1⁄4 vezes sua área de superfície, 6s².",
  "time_range": [
   1894.64,
   1903.62
  ]
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "model": "nmt",
  "translatedText": "Mas o fato muito mais memorável que você vai dormir pensando é como realmente não importava que estivéssemos falando de um cubo.",
  "time_range": [
   1903.62,
   1910.8
  ]
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "model": "nmt",
  "translatedText": "Agora, tudo isso é muito bonito, mas alguns de vocês podem reclamar que este não é realmente um argumento válido, porque as esferas não têm faces planas.",
  "time_range": [
   1912.52,
   1919.38
  ]
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "model": "nmt",
  "translatedText": "Quando eu disse que o argumento de Alice generaliza para qualquer sólido convexo, se realmente olharmos para o argumento em si, ele definitivamente depende do uso de um número finito de faces planas.",
  "time_range": [
   1920.1,
   1928.94
  ]
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "model": "nmt",
  "translatedText": "Por exemplo, se o estivéssemos mapeando para um dodecaedro, você começaria dizendo que a área de uma sombra específica desse dodecaedro parece exatamente 1/2 vezes a soma das áreas das sombras de todas as suas faces.",
  "time_range": [
   1928.94,
   1940.44
  ]
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "model": "nmt",
  "translatedText": "Mais uma vez, você poderia usar um certo raio de luz misturado com o argumento da convexidade para chegar a essa conclusão.",
  "time_range": [
   1941.0,
   1945.44
  ]
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "model": "nmt",
  "translatedText": "E lembre-se, o benefício de expressar essa área de sombra como uma soma é que quando queremos calcular a média de várias rotações diferentes, podemos descrever essa soma como uma grande grade, onde podemos ir coluna por coluna e considerar a área média para a sombra de cada rosto.",
  "time_range": [
   1946.28,
   1960.82
  ]
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "model": "nmt",
  "translatedText": "E também, um facto crítico foi a conclusão muito anterior, de que a sombra média para qualquer objecto 2D, um objecto 2D plano, o que é importante, será igual a alguma constante de proporcionalidade universal vezes a sua área.",
  "time_range": [
   1961.46,
   1972.72
  ]
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "model": "nmt",
  "translatedText": "O significado era que essa constante não dependia da forma em si.",
  "time_range": [
   1973.26,
   1976.12
  ]
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "model": "nmt",
  "translatedText": "Poderia ter sido um quadrado, ou um gato, ou as faces pentagonais do nosso dodecaedro, tanto faz.",
  "time_range": [
   1976.22,
   1981.84
  ]
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "model": "nmt",
  "translatedText": "Então, depois de transferir isso às pressas para uma esfera que não tem um número finito de faces planas, você estaria certo em reclamar.",
  "time_range": [
   1982.28,
   1988.26
  ]
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "model": "nmt",
  "translatedText": "Mas, felizmente, é um detalhe muito fácil de preencher.",
  "time_range": [
   1988.9,
   1991.24
  ]
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "model": "nmt",
  "translatedText": "O que você pode fazer é imaginar uma sequência de diferentes poliedros que se aproximam sucessivamente de uma esfera, no sentido de que suas faces se abraçam cada vez mais em torno da superfície genuína da esfera.",
  "time_range": [
   1991.64,
   2001.16
  ]
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "model": "nmt",
  "translatedText": "Para cada uma destas aproximações, podemos tirar a mesma conclusão, que a sua sombra média será proporcional à sua área de superfície com esta constante de proporcionalidade universal.",
  "time_range": [
   2001.6799999999998,
   2010.78
  ]
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "model": "nmt",
  "translatedText": "Então, se dissermos, ok, vamos pegar o limite da razão entre a área de sombra média em cada etapa e a área de superfície em cada etapa, bem, como essa proporção nunca muda, é sempre igual a essa constante, então em o limite, também será igual a essa constante.",
  "time_range": [
   2011.2,
   2024.62
  ]
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "model": "nmt",
  "translatedText": "Mas por outro lado, pela sua definição, no limite, a sua área média de sombra deveria ser a de um círculo, que é πr², e o limite das áreas superficiais seria a área superficial da esfera, 4πr².",
  "time_range": [
   2024.62,
   2036.98
  ]
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "model": "nmt",
  "translatedText": "Portanto, chegamos genuinamente à conclusão que a intuição sugeriria, mas, como é tão comum no argumento de Alice aqui, temos de ser um pouco delicados na forma como justificamos essa intuição.",
  "time_range": [
   2037.66,
   2047.0
  ]
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "model": "nmt",
  "translatedText": "É fácil que esse contraste entre Alice e Bob pareça um julgamento de valor, como se eu estivesse dizendo: veja como Alice conseguiu ser inteligente, ela evitou com perspicácia todos aqueles cálculos que Bob teve que fazer.",
  "time_range": [
   2052.2,
   2063.56
  ]
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "model": "nmt",
  "translatedText": "Mas isso seria uma conclusão muito, hum, equivocada.",
  "time_range": [
   2063.88,
   2067.9
  ]
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "model": "nmt",
  "translatedText": "Acho que há uma maneira importante pela qual a popularização da matemática difere da sensação de realmente fazer matemática.",
  "time_range": [
   2068.56,
   2074.08
  ]
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "model": "nmt",
  "translatedText": "Existe essa tendência de mostrar as provas engenhosas, os argumentos com uma visão inteligente e aguçada que permite evitar fazer cálculos.",
  "time_range": [
   2074.08,
   2080.78
  ]
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "model": "nmt",
  "translatedText": "Eu poderia estar apenas projetando, já que sou muito culpado disso, mas o que posso dizer a vocês, aqui sentados do outro lado da tela, é que parece muito mais atraente fazer um vídeo sobre a abordagem de Alice do que a de Bob.",
  "time_range": [
   2081.24,
   2092.3
  ]
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "model": "nmt",
  "translatedText": "Por um lado, na abordagem de Alice, a linha de raciocínio é divertida, tem momentos agradáveis de aha.",
  "time_range": [
   2092.46,
   2097.12
  ]
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "model": "nmt",
  "translatedText": "Mas também, o que é crucial, a maneira como você explica isso é mais ou menos a mesma para uma ampla gama de formações matemáticas.",
  "time_range": [
   2097.12,
   2103.9
  ]
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "model": "nmt",
  "translatedText": "É muito menos atraente fazer um vídeo sobre a abordagem de Bob, não porque os cálculos sejam tão ruins, quero dizer, honestamente não são, mas a realidade pragmática é que o ritmo apropriado para explicá-lo parece muito diferente dependendo das diferentes matemáticas. origens na plateia.",
  "time_range": [
   2104.64,
   2118.86
  ]
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "model": "nmt",
  "translatedText": "Então, você, que está assistindo isso agora, claramente consome vídeos de matemática online, e acho que ao fazer isso vale a pena estar atento a esse preconceito.",
  "time_range": [
   2119.82,
   2126.62
  ]
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "model": "nmt",
  "translatedText": "Se o objetivo é obter uma lição genuína sobre a resolução de problemas, focar demais nas provas engenhosas corre o risco de ser hipócrita.",
  "time_range": [
   2126.62,
   2134.52
  ]
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "model": "nmt",
  "translatedText": "Por exemplo, digamos que devíamos passar para o modo de desafio aqui e perguntar sobre o caso com uma fonte de luz mais próxima.",
  "time_range": [
   2135.84,
   2141.02
  ]
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "model": "nmt",
  "translatedText": "Que eu saiba, não existe uma solução igualmente engenhosa para Alice aqui, onde você pode apenas se relacionar com uma única forma, como uma esfera.",
  "time_range": [
   2141.7,
   2148.16
  ]
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "model": "nmt",
  "translatedText": "O aquecimento muito mais produtivo a ser feito teria sido o cálculo da abordagem de Bob.",
  "time_range": [
   2148.86,
   2153.3
  ]
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "model": "nmt",
  "translatedText": "E se você olhar para a história deste problema, ele foi provado por Cauchy em 1832, e se examinarmos suas notas manuscritas, elas se parecem muito mais com o trabalho de Bob do que com o trabalho de Alice.",
  "time_range": [
   2153.88,
   2164.48
  ]
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "model": "nmt",
  "translatedText": "Bem aqui no topo da página 11, você pode ver o que é essencialmente a mesma integral que você e eu configuramos no meio.",
  "time_range": [
   2164.9,
   2170.4
  ]
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "model": "nmt",
  "translatedText": "Por outro lado, todo o enquadramento do artigo visa encontrar um fato geral, e não algo específico como o caso de um cubo.",
  "time_range": [
   2171.3,
   2177.24
  ]
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "model": "nmt",
  "translatedText": "Portanto, se estivéssemos perguntando qual dessas duas mentalidades se correlaciona com o ato de descobrir uma nova matemática, a resposta certa quase certamente teria que ser uma mistura de ambas.",
  "time_range": [
   2177.24,
   2186.4
  ]
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "model": "nmt",
  "translatedText": "Mas eu sugeriria que muitas pessoas não atribuem peso suficiente à parte dessa mistura em que você está ansioso para mergulhar nos cálculos.",
  "time_range": [
   2187.22,
   2194.18
  ]
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "model": "nmt",
  "translatedText": "E acho que há algum risco de que os vídeos que faço possam contribuir para isso.",
  "time_range": [
   2194.72,
   2198.16
  ]
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "model": "nmt",
  "translatedText": "No podcast que fiz com o matemático Alex Kontorovich, ele falou sobre a importância muitas vezes subestimada de apenas aprofundar os cálculos para construir a intuição, seja você um estudante engajado em uma nova aula ou um matemático pesquisador praticante engajado em um novo campo de conhecimento. estudar.",
  "time_range": [
   2198.9599999999996,
   2214.32
  ]
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "model": "nmt",
  "translatedText": "Na verdade, um ouvinte escreveu para destacar a impressão que aquela seção específica causou.",
  "time_range": [
   2214.8,
   2219.04
  ]
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "model": "nmt",
  "translatedText": "Eles são estudantes de doutorado e se descrevem preocupados com o fato de suas habilidades matemáticas estarem começando a desaparecer, o que atribuem ao fato de estarem se tornando mais velhos e menos aguçados.",
  "time_range": [
   2219.18,
   2227.64
  ]
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "model": "nmt",
  "translatedText": "Mas ouvir um matemático praticante falar sobre a importância de fazer centenas de exemplos concretos para aprender algo novo, evidentemente que isso mudou a sua perspectiva.",
  "time_range": [
   2227.64,
   2236.32
  ]
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "model": "nmt",
  "translatedText": "Nas suas próprias palavras, reconhecer isto remodelou completamente a sua perspectiva e os seus resultados.",
  "time_range": [
   2236.9,
   2241.16
  ]
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "model": "nmt",
  "translatedText": "E se olharmos para os matemáticos famosos ao longo da história, Newton, Euler, Gauss, todos eles, todos eles têm uma paciência aparentemente infinita para fazer cálculos tediosos.",
  "time_range": [
   2242.02,
   2250.58
  ]
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "model": "nmt",
  "translatedText": "A ironia de ser tendencioso para mostrar insights que nos permitem evitar cálculos é que a forma como as pessoas muitas vezes treinam as intuições para encontrar esses insights é, em primeiro lugar, fazendo pilhas e pilhas de cálculos.",
  "time_range": [
   2250.58,
   2262.72
  ]
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "model": "nmt",
  "translatedText": "Dito isso, algo definitivamente estaria faltando sem a mentalidade de Alice aqui.",
  "time_range": [
   2264.72,
   2269.42
  ]
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "model": "nmt",
  "translatedText": "Quer dizer, pense bem, quão triste seria se resolvêssemos esse problema para um cubo, e nunca saíssemos das árvores para ver a floresta e entendermos que isso é um fato supergeral, se aplica a uma enorme família de formas.",
  "time_range": [
   2269.98,
   2280.32
  ]
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "model": "nmt",
  "translatedText": "E se considerarmos que a matemática não se trata apenas de responder às questões que lhe são colocadas, mas de introduzir novas ideias e construções, uma observação divertida sobre a abordagem de Alice aqui é que ela sugere uma forma divertida de quantificar a ideia de convexidade.",
  "time_range": [
   2281.14,
   2294.82
  ]
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "model": "nmt",
  "translatedText": "Em vez de apenas ter uma resposta sim ou não, é convexo, não é, poderíamos atribuir um número dizendo, considere a área média da sombra de algum sólido, multiplique isso por 4, divida pela área da superfície , e se esse número for 1, você terá um sólido convexo, mas se for menor que 1, não será convexo, e o quão próximo ele está de 1 indica o quão próximo ele está de ser convexo.",
  "time_range": [
   2295.36,
   2316.46
  ]
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "model": "nmt",
  "translatedText": "Além disso, uma das coisas boas sobre a solução de Alice aqui é que ela ajuda a explicar por que os matemáticos têm o que às vezes pode parecer uma paixão bizarra pela generalidade e pela abstração.",
  "time_range": [
   2317.1,
   2328.36
  ]
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "model": "nmt",
  "translatedText": "Quanto mais exemplos você vê onde generalizar e abstrair realmente ajudam a resolver um caso específico, mais você começa a adotar a mesma paixão.",
  "time_range": [
   2328.36,
   2337.36
  ]
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "model": "nmt",
  "translatedText": "E como um pensamento final para os fiéis espectadores entre vocês que conseguiram chegar até aqui, ainda há uma pergunta sem resposta sobre a própria premissa do nosso quebra-cabeça.",
  "time_range": [
   2339.24,
   2347.0
  ]
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "model": "nmt",
  "translatedText": "O que exatamente significa escolher uma orientação aleatória?",
  "time_range": [
   2347.76,
   2350.94
  ]
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "model": "nmt",
  "translatedText": "Agora, se isso parece uma pergunta boba, como é claro que sabemos o que deveria significar, eu encorajo você a assistir a um vídeo que acabei de fazer com Numberphile sobre um enigma de probabilidade conhecido como paradoxo de Bertrand.",
  "time_range": [
   2350.94,
   2360.78
  ]
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "model": "nmt",
  "translatedText": "Depois de assistir, e se você apreciar algumas das nuances em jogo aqui, o dever de casa para você é refletir sobre onde exatamente Alice e Bob respondem implicitamente a essa pergunta.",
  "time_range": [
   2361.58,
   2370.42
  ]
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "model": "nmt",
  "translatedText": "O caso de Bob é relativamente simples, mas o ponto em que Alice fixa alguma distribuição específica no espaço de todas as orientações, bem, não é nada óbvio, na verdade é muito sutil.",
  "time_range": [
   2370.42,
   2381.7
  ]
 }
]