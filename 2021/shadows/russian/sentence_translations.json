[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "translatedText": "Через минуту я расскажу вам об очень интересной головоломке, связанной с тенью куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "translatedText": "Но прежде чем мы перейдем к этому, я должен сказать, что суть этого видео не в головоломке как таковой, а в двух различных стилях решения проблем, которые отражаются в двух разных способах решения этой проблемы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "translatedText": "Фактически, давайте антропоморфизируем эти два разных стиля, представив двух учеников, Алису и Боба, которые воплощают каждый из подходов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "translatedText": "Так что Боб будет из тех учеников, которые действительно любят считать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "translatedText": "Как только наступает момент, когда он может вникнуть в детали и получить очень конкретное представление о конкретной ситуации, стоящей перед ним, это то, чему он больше всего рад.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "translatedText": "Алиса, с другой стороны, более склонна откладывать вычисления не потому, что она не знает, как их делать или не хочет как таковая, а потому, что она предпочитает получить хороший общий обзор высокого уровня такого рода. проблемы, с которой она имеет дело, ее общую форму, прежде чем она углубится в сами вычисления.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "translatedText": "Ей очень приятно, если она понимает не только конкретный вопрос, стоящий перед ней, но и самый широкий способ его обобщения, и особенно если более общий взгляд может привести к более быстрым и элегантным вычислениям, как только она действительно это сделает. сесть и выполнить их.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "translatedText": "Теперь задача, с которой им обоим придется столкнуться, — найти среднюю площадь тени куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "translatedText": "Итак, если у меня есть куб, парящий в пространстве, есть несколько вещей, которые влияют на область его тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "translatedText": "Одним из очевидных вариантов является размер куба: меньший куб, меньшая тень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "translatedText": "Но также, если он расположен в разных ориентациях, эти ориентации соответствуют разным теням с разными областями.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "translatedText": "И когда я говорю «найти здесь среднее», я имею в виду среднее значение по всем возможным ориентациям для куба определенного размера.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "translatedText": "Проницательные из вас могут заметить, что большое значение имеет и то, где находится источник света.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "translatedText": "Если источник света находился очень низко, близко к самому кубу, тень окажется больше.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "translatedText": "А если бы источник света был расположен сбоку, это могло бы исказить тень и придать ей совершенно другую форму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "translatedText": "Учет этого положения источника света сам по себе очень интересен, но головоломка и так достаточно сложна, поэтому, по крайней мере, на начальном этапе давайте сделаем самое простое, что можем, и скажем, что свет находится прямо над кубом и очень далеко. далеко, фактически бесконечно далеко, так что все, что мы рассматриваем, — это плоская проекция в том смысле, что если вы посмотрите на любые координаты x, y, z в пространстве, плоская проекция будет равна x, y, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "translatedText": "Итак, чтобы сориентироваться, проще всего подумать о ситуации, когда куб стоит прямо вверх, а две его грани параллельны земле.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "translatedText": "В этом случае эта плоская тень от проекции представляет собой просто квадрат, и если мы скажем, что длины сторон куба равны s, то площадь этой тени равна s в квадрате.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "translatedText": "И, кстати, каждый раз, когда у меня есть метка для этих анимаций, как здесь, я буду предполагать, что длина стороны соответствующего куба равна 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "translatedText": "Еще один особый случай среди всех ориентаций, о котором интересно подумать: длинная диагональ параллельна направлению света.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "translatedText": "В этом случае тень на самом деле выглядит как правильный шестиугольник, и если вы воспользуетесь некоторыми методами, которые мы разработаем через несколько минут, вы сможете вычислить, что площадь этой тени равна квадратному корню из трехкратной площади одно из квадратных лиц.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "translatedText": "Но, конечно, чаще всего реальная тень будет не такой правильной, как квадрат или шестиугольник.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "translatedText": "Сложнее думать о форме, основываясь на том, что сложнее думать об ориентации этого куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "translatedText": "Ранее я невзначай выкинул эту фразу об усреднении по всем возможным направлениям, но вы справедливо спросите, а что именно это должно означать?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "translatedText": "Я думаю, что у многих из нас есть интуитивное представление о том, что мы хотим, чтобы это значило, по крайней мере, в том смысле, какой эксперимент вы бы провели, чтобы проверить это.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "translatedText": "Вы можете представить, как подбрасываете этот куб в воздух, как краситель, замораживаете его в какой-то произвольной точке, записываете область тени из этого положения, а затем повторяете.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "translatedText": "Если вы проделаете это много-много раз снова и снова, вы сможете получить среднее значение вашей выборки.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "translatedText": "Число, которое мы хотим получить, истинное среднее здесь, должно быть любым, к которому приближается экспериментальное среднее значение по мере того, как вы делаете все больше и больше бросков, приближаясь к бесконечному числу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "translatedText": "Тем не менее, сторонники среди вас могут жаловаться, что это на самом деле не отвечает на вопрос, потому что оставляет открытым вопрос о том, как мы определяем случайный бросок.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "translatedText": "Правильный способ ответить на этот вопрос, если мы хотим, чтобы он был более формальным, — это сначала описать пространство всех возможных ориентаций, которому математики на самом деле дали причудливое название.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "translatedText": "Они называют это SO3 и обычно определяют как определенное семейство матриц 3х3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "translatedText": "И вопрос, на который мы хотим ответить, заключается в том, какое распределение вероятностей мы придаем всему этому пространству?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "translatedText": "Только когда такое распределение вероятностей четко определено, мы можем ответить на вопрос, связанный со средним значением.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "translatedText": "Если вы сторонник подобных вещей, я хочу, чтобы вы воздержались от этого вопроса до конца видео.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "translatedText": "Вы будете удивлены тем, как далеко мы можем зайти с более эвристической, экспериментальной идеей простого повторения группы случайных бросков без реального определения распределения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "translatedText": "Как только мы увидим решения Алисы и Боба, на самом деле будет очень интересно спросить, как именно каждый из них определил это распределение на своем пути.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "translatedText": "И помните, это не урок о тенях куба как таковых, а урок о решении проблем, рассказанный через призму двух разных мировоззрений, которые мы можем применить к головоломке.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "translatedText": "И, как и в любом уроке по решению проблем, цель здесь не в том, чтобы найти ответ как можно быстрее, а в том, чтобы вы почувствовали, что нашли ответ сами.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "translatedText": "Поэтому, если когда-нибудь наступит момент, когда вы почувствуете, что у вас может возникнуть идея, дайте себе свободу сделать паузу и попытаться все обдумать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "translatedText": "В качестве первого шага, и это на самом деле не зависит от каких-либо конкретных стилей решения проблем, каждый раз, когда вы сталкиваетесь с трудным вопросом, вы можете спросить, какой самый простой и нетривиальный вариант проблемы, которую вы решаете. может попробовать решить?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "translatedText": "В нашем случае вы можете сказать: ладно, давайте забудем об усреднении по всем направлениям.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about.",
  "translatedText": "Об этом сложно думать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "translatedText": "И давайте даже забудем обо всех гранях куба, потому что они перекрываются, и об этом тоже сложно думать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "translatedText": "Можем ли мы вычислить площадь этой тени только для одного конкретного лица и одной конкретной ориентации?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "translatedText": "Еще раз, если вы хотите сориентироваться в некоторых особых случаях, проще всего, когда лицо параллельно земле, и в этом случае площадь тени равна площади лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "translatedText": "И с другой стороны, если мы наклоним это лицо на 90 градусов, то его тень будет прямой линией, а ее площадь будет равна нулю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "translatedText": "Итак, Боб смотрит на это и хочет получить реальную формулу этой тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "translatedText": "И он мог бы думать об этом, рассматривая вектор нормали, перпендикулярный этой грани.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "translatedText": "И что имеет значение, так это угол, который этот нормальный вектор образует с вертикалью, с направлением, откуда исходит свет, который мы могли бы назвать тета.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "translatedText": "Теперь из двух особых случаев, которые мы только что рассмотрели, мы знаем, что когда тета равна нулю, площадь этой тени равна площади самой фигуры, которая равна s в квадрате, если длина сторон квадрата s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "translatedText": "А если тэта равна 90 градусам, то площадь этой тени равна нулю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "translatedText": "И, вероятно, не так уж сложно догадаться, что тригонометрия будет каким-то образом актуальна, поэтому любой, кто знаком со своими тригонометрическими функциями, вероятно, может рискнуть предположить, какая формула правильная.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "translatedText": "Но Боб более ориентирован на детали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "translatedText": "Он хочет правильно доказать, какой должна быть эта область, а не просто строить предположения, основанные на конечных точках.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "translatedText": "И то, как вы можете об этом думать, может быть примерно таким.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "translatedText": "Если мы рассмотрим плоскость, проходящую через вертикаль, а также наш вектор нормали, а затем рассмотрим все различные фрагменты нашей фигуры, находящиеся в этой плоскости или параллельные этой плоскости, тогда мы сможем сосредоточить наше внимание на двух- размерный вариант задачи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "translatedText": "Если мы просто посмотрим на один из этих срезов, у которого есть нормальный вектор, угол тета от вертикали, его тень может выглядеть примерно так.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "translatedText": "И если мы проведем здесь вертикальную линию вверх влево, у нас получится прямоугольный треугольник.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "translatedText": "И отсюда мы можем немного погонять за углом, проследив за тем, что означает этот угол тэта в отношении остальной части диаграммы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "translatedText": "А это значит, что нижний правый угол в этом треугольнике равен именно тэте.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "translatedText": "Итак, когда мы хотим понять размер этой тени по сравнению с исходным размером фигуры, мы можем подумать о косинусе этого угла, тэте, который запоминает примыкание к гипотенузе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "translatedText": "Это буквально соотношение между размером тени и размером среза.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "translatedText": "Таким образом, коэффициент, с которым срез сжимается в этом направлении, равен точно косинусу теты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "translatedText": "А если мы расширим обзор на весь квадрат, все срезы в этом направлении масштабируются с одинаковым коэффициентом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "translatedText": "А вот в другую сторону, в ту, которая перпендикулярна этому срезу, растяжения и сжатия нет, потому что лицо вовсе не наклонено в ту сторону.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "translatedText": "Таким образом, в целом двумерную тень нашего двухмерного лица также следует уменьшить на коэффициент косинуса теты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "translatedText": "Это соответствует тому, что вы можете интуитивно догадаться, учитывая случай, когда угол равен 0°, и случай, когда он равен 90°, но приятно понять, почему это правда.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "translatedText": "И на самом деле, как говорилось до сих пор, это не совсем правильно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "translatedText": "Есть небольшая проблема с формулой, которую мы написали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "translatedText": "В случае, когда тэта больше 90°, косинус фактически окажется отрицательным.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "translatedText": "Но, конечно, мы не хотим считать, что тень имеет отрицательную область, по крайней мере, в такой задаче.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this.",
  "translatedText": "Итак, есть два разных способа решить эту проблему.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "translatedText": "Можно сказать, что мы хотим рассматривать только вектор нормали, направленный вверх и имеющий положительную компоненту z.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "translatedText": "Или, проще говоря, мы могли бы сказать: просто возьмите абсолютное значение этого косинуса, и это даст нам действительную формулу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "translatedText": "Итак, Боб счастлив, потому что у него есть точная формула, описывающая площадь тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "translatedText": "Но Алиса начинает думать об этом немного по-другому.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "translatedText": "Она говорит: «Хорошо, у нас есть некоторая форма, а затем мы применяем вращение, которое каким-то образом помещает ее в трехмерное пространство».",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.06,
  "end": 560.52
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "translatedText": "А затем мы применяем плоскую проекцию, которая возвращает это в двухмерное пространство.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.78,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "translatedText": "И что для нее особенно важно, так это то, что оба эти преобразования являются линейными.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "translatedText": "Это означает, что в принципе вы можете описать каждую из них с помощью матрицы, и что общее преобразование будет выглядеть как произведение этих двух матриц.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "translatedText": "Что Алиса знает из одного из своих любимых предметов, линейной алгебры, так это то, что если вы берете некоторую фигуру и считаете ее площадь, затем применяете некоторое линейное преобразование, то площадь этого результата выглядит как некоторое постоянное произведение исходной площади фигуры.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "translatedText": "Точнее, у нас есть имя для этой константы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation.",
  "translatedText": "Это называется определителем трансформации.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "translatedText": "Если вы не очень хорошо разбираетесь в линейной алгебре, мы могли бы дать гораздо более интуитивное описание и сказать, что если вы равномерно растянете исходную форму в некотором направлении, выходные данные также будут равномерно растянуты в некотором направлении.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "translatedText": "Таким образом, площадь каждого из них должна масштабироваться пропорционально друг другу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "translatedText": "В принципе, Алиса могла бы вычислить этот определитель, но это не в ее стиле делать это, по крайней мере, не делать этого немедленно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "translatedText": "Вместо этого она записывает, что константа пропорциональности между нашей исходной формой и ее тенью не зависит от исходной формы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "translatedText": "Мы могли бы говорить о тени этого контура кошки или о чем-то еще, и ее размер не имеет особого значения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "translatedText": "Единственное, что влияет на эту константу пропорциональности, — это то, какое преобразование мы применяем, что в данном контексте означает, что мы можем записать его как некоторый фактор, который зависит от вращения, применяемого к форме.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "translatedText": "В глубине души, благодаря расчетам Боба, мы знаем, как выглядит этот фактор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "translatedText": "Знаете, это абсолютное значение косинуса угла между вектором нормали и вертикалью.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "translatedText": "Но Элис прямо сейчас просто говорит: да, да, да, когда-нибудь я смогу подумать об этом, когда захочу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "translatedText": "Но она знает, что мы в любом случае собираемся усреднить все различные ориентации, хотя и питает некоторую надежду, что любая конкретная формула, касающаяся конкретной ориентации, может быть смыта этим средним значением.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "translatedText": "Теперь легко посмотреть на это и сказать: ладно, тогда Алиса на самом деле ничего не делает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "translatedText": "Конечно, площадь тени пропорциональна площади исходной фигуры.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "translatedText": "Обе они двумерные величины, и обе они должны масштабироваться как двумерные вещи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 675.62,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "translatedText": "Но имейте в виду, что это было бы совсем не так, если бы мы имели дело с более сложным случаем с более близким источником света.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear.",
  "translatedText": "В этом случае проекция не является линейной.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "translatedText": "Например, если я поверну этого кота так, чтобы его хвост оказался достаточно близко к источнику света, то если я равномерно растяну исходную форму в направлении x, скажем, в 1 раз.5, это может оказать очень непропорциональное влияние на конечную тень, потому что хвост очень непропорционально раздувается, когда он приближается к свету.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "translatedText": "Опять же, Алиса следит за тем, какие свойства проблемы действительно актуальны, потому что это помогает ей понять, насколько она может обобщать вещи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "translatedText": "Имеет ли значение тот факт, что мы думаем о квадратном лице, а не о какой-то другой форме?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really.",
  "translatedText": "Нет, не совсем.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "translatedText": "Имеет ли значение тот факт, что преобразование является линейным?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely.",
  "translatedText": "Да, конечно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "translatedText": "Алиса также может применить аналогичный подход к средней тени для любой фигуры, подобной этой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "translatedText": "Допустим, у нас есть некоторая последовательность поворотов, которую мы применяем к нашему квадратному лицу, и назовем их R1, R2, R3 и так далее.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.02,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "translatedText": "Тогда площадь тени в каждом из этих случаев выглядит как некоторый коэффициент, умноженный на площадь квадрата, и этот коэффициент зависит от вращения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 739.72,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "translatedText": "Итак, если мы возьмем эмпирическое среднее значение для этой тени по выборке вращений, которую мы сейчас рассматриваем, это будет выглядеть так: сложить все эти области теней, а затем разделить на общее количество, которое у нас есть.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "translatedText": "Теперь, благодаря линейности, эту область исходного квадрата можно четко вычесть из всего этого, и она окажется слева.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "translatedText": "Это не то точное среднее значение, которое мы ищем, это просто эмпирическое среднее значение выборки вращений, но в принципе мы ищем то, к чему оно приближается, поскольку размер нашей выборки приближается к бесконечности, и все части, которые зависят от размера образца, располагаются на некотором расстоянии от самой области.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.2,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "translatedText": "Итак, к чему бы это ни приближалось в пределе, это будет просто какое-то число.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "translatedText": "Вычислять это может быть очень сложно, мы пока не уверены в этом, но Алиса отмечает, что это не зависит от размера и формы конкретного 2D-объекта, на который мы смотрим.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "translatedText": "Это универсальная константа пропорциональности, и она надеется, что эта универсальность каким-то образом позволит найти более элегантный способ вывода того, какой она должна быть.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.72,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "translatedText": "Теперь Бобу хотелось бы вычислить эту константу здесь и сейчас, и через несколько минут я покажу вам, как он это делает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "translatedText": "Но перед этим я хочу еще немного побыть в мире Алисы, потому что именно здесь все становится по-настоящему весело.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "translatedText": "Желая понять общую структуру вопроса, прежде чем углубляться в детали, ей теперь интересно, как площадь тени куба связана с площадью его отдельных граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "translatedText": "Теперь, если мы можем что-то сказать о средней площади конкретной грани, говорит ли это нам что-нибудь о средней площади куба в целом?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "translatedText": "Например, мы могли бы просто сказать, что эта площадь определенно меньше суммы площадей всех граней, потому что между этими тенями существует значительная степень перекрытия.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "translatedText": "Но не совсем понятно, как относиться к этому перекрытию, потому что, если мы сосредоточим наше внимание только на двух конкретных лицах, в некоторых ориентациях они вообще не перекрываются, а в других ориентациях они имеют некоторое перекрытие, и конкретная форма и Область этого перекрытия кажется немного сложной для размышления, не говоря уже о том, как на Земле мы могли бы усреднить ее по всем различным ориентациям.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.64,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "translatedText": "Но у Алисы есть около трёх умных догадок по всей этой проблеме, и это первая из них.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "translatedText": "По ее словам, на самом деле, если мы подумаем обо всем кубе, а не только о паре граней, мы можем заключить, что площадь тени для данной ориентации равна ровно половине суммы площадей всех граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "translatedText": "Интуитивно вы можете догадаться, что половина из них залиты светом, а половина нет, но вот как она это оправдывает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "translatedText": "Она говорит, что определенный луч света исходит с неба и в конечном итоге попадает в точку в тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 895.82,
  "end": 901.4
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "translatedText": "Этот луч проходит через куб ровно в двух точках.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 902.04,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "translatedText": "Есть один момент, когда он входит, и один момент, когда он выходит.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "translatedText": "Таким образом, каждая точка этой тени соответствует ровно двум граням над ней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "translatedText": "Ну да ладно, это не совсем так, если этот луч света случайно прошел через край одного из квадратов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "translatedText": "Существует небольшая двусмысленность в отношении количества граней, которые он проходит, но они учитывают нулевую площадь внутри тени, поэтому мы можем их игнорировать, если мы пытаемся вычислить площадь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 919.6,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "translatedText": "Если на Алису давят и ей нужно обосновать, почему именно это верно, что важно для понимания того, как проблема может обобщиться, она может обратиться к идее выпуклости.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "translatedText": "Выпуклость — одно из тех свойств, которые многие из нас интуитивно понимают, что это должно означать. Знаете, это формы, которые просто выпирают наружу и никогда не вдавливаются внутрь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "translatedText": "Но у математиков есть довольно хитрый способ формализовать это, который полезен для реальных доказательств.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "translatedText": "Говорят, что множество является выпуклым, если линия, соединяющая любые две точки внутри этого множества, целиком содержится внутри самого множества.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "translatedText": "Итак, квадрат является выпуклым, потому что независимо от того, где вы поместите две точки внутри этого квадрата, линия, соединяющая их, целиком находится внутри квадрата.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "translatedText": "Но что-то вроде символа «пи» не является выпуклым.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 970.28,
  "end": 972.72
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "translatedText": "Я легко могу найти две разные точки, так что линия, соединяющая их, должна выходить за пределы самого множества.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 972.84,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "translatedText": "Ни одна буква в слове «выпуклый» сама по себе не является выпуклой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "translatedText": "Вы можете найти две точки так, что соединяющая их линия должна выходить за пределы множества.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "translatedText": "Это действительно умный способ формализовать идею формы, которая только выпирает, потому что каждый раз, когда она вмятина внутрь, вы можете найти эти линии, противоположные примеру.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 987.46,
  "end": 995.54
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "translatedText": "Наш куб, поскольку он выпуклый, между первой точкой входа и последней точкой выхода, он должен полностью оставаться внутри куба по определению выпуклости.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "translatedText": "Но если бы мы имели дело с какой-то другой невыпуклой формой, например с бубликом, вы могли бы обнаружить луч света, который входит, затем выходит, затем входит, а затем снова выходит, так что у вас не было бы чистого соотношения два к одному. укрыться от тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "translatedText": "Тени всех его частей, если бы вы покрыли это группой лиц, не были бы ровно в два раза больше площади самой тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "translatedText": "Итак, это первое ключевое открытие: тени лица дважды покрывают тень куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "translatedText": "А следующий немного более символичен, поэтому давайте начнем с того, что немного сократим наши обозначения, чтобы освободить место на экране.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "translatedText": "Вместо того, чтобы писать площадь тени куба, я просто напишу s куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "translatedText": "И аналогично, вместо площади тени конкретного лица я просто буду писать s от f, где индекс j указывает, о каком лице я говорю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "translatedText": "Но, конечно, на самом деле мы должны говорить о тени определенного вращения, примененной к кубу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "translatedText": "Поэтому я мог бы записать это как некоторое вращение, примененное к кубу, и аналогично справа это площадь тени того же вращения, примененная к данной одной из граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "translatedText": "Имея под рукой более компактные обозначения, давайте подумаем о среднем значении этой области тени для многих различных вращений, некоторой выборке r1, r2, r3 и так далее.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "translatedText": "Опять же, это среднее значение просто включает в себя сложение всех этих теневых областей и последующее деление их на n.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "translatedText": "И в принципе, если бы мы рассматривали это для все больших и больших выборок, пусть n приближается к бесконечности, что даст нам среднюю площадь тени куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "translatedText": "Некоторые из вас могут подумать: да, мы это знаем, вы уже это говорили, но полезно записать это, чтобы мы могли понять, почему площадь тени для конкретного вращения куба выражается как сумма по всем граням, или хотя бы в полтора раза больше, почему это выгодно?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us?",
  "translatedText": "Что это нам даст?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "translatedText": "Что ж, давайте просто запишем это, где для каждого из этих поворотов куба мы могли бы разбить эту тень как сумму по тому же повороту, примененному ко всем граням.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "translatedText": "И когда это записано в виде такой сетки, мы можем прийти ко второму выводу Алисы, который заключается в том, чтобы изменить способ мышления о сумме с рассмотрения строки за строкой вместо рассмотрения столбца за столбцом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "translatedText": "Например, если мы сосредоточим наше внимание только на первом столбце, он нам скажет сложить площадь тени первого лица во многих различных ориентациях.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "translatedText": "Итак, если мы возьмем эту сумму и разделим ее на размер нашей выборки, это даст нам эмпирическое среднее значение площади тени этого лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "translatedText": "Поэтому, если мы будем брать все большие и большие образцы, стремясь к бесконечности, это приблизится к средней площади тени для квадрата.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "translatedText": "Аналогично, второй столбец можно рассматривать как сообщающий нам среднюю площадь второй грани куба, которая, конечно, должна быть тем же числом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "translatedText": "То же самое и с любым другим столбцом: он сообщает нам среднюю площадь определенного лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "translatedText": "Это дает нам совершенно другой способ мышления обо всем нашем самовыражении.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "translatedText": "Вместо того, чтобы просить сложить площади кубов в разных ориентациях, мы могли бы сказать, просто сложите средние тени для шести разных граней и разделите сумму на половину.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "translatedText": "Термин слева здесь предполагает сначала сложение строк, а термин справа — сначала сложение столбцов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "translatedText": "Короче говоря, среднее значение суммы теней лица равно сумме средних значений теней лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "translatedText": "Возможно, этот обмен кажется простым, а может и нет, но я могу вам сказать, что на самом деле в шаге, который мы только что предприняли, есть нечто большее, чем кажется на первый взгляд, но мы вернемся к этому позже.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "translatedText": "И помните, мы знаем, что средняя площадь конкретного лица выглядит как некая универсальная константа пропорциональности, умноженная на площадь этого лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "translatedText": "Итак, если мы сложим это значение по всем граням куба, мы можем представить это как равное некоторому постоянному умножению на площадь поверхности куба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting.",
  "translatedText": "И это довольно интересно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "translatedText": "Средняя площадь тени этого куба будет пропорциональна площади его поверхности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "translatedText": "Но в то же время вы можете возразить: ну, Алиса просто перебирает здесь кучу символов, потому что все это не имеет значения, если мы не знаем, что такое константа пропорциональности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious.",
  "translatedText": "Я имею в виду, это кажется почти очевидным.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "translatedText": "Мол, конечно, средняя площадь тени должна быть пропорциональна площади поверхности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "translatedText": "Обе они двумерные величины, поэтому они должны масштабироваться синхронно друг с другом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious.",
  "translatedText": "Я имею в виду, это не очевидно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "translatedText": "В конце концов, для более близкого источника света это было бы просто неправдой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "translatedText": "Кроме того, этот бизнес, в котором мы суммировали столбец за столбцом сетки, а не строку за строкой, немного более тонкий, чем может показаться на первый взгляд.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "translatedText": "В основе всего этого лежит тонкое, скрытое предположение, которое имеет особое значение, когда мы решаем вернуться к вопросу о том, какое распределение вероятностей принимается в пространстве всех ориентаций.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "translatedText": "Но более всего причина, по которой это неочевидно, заключается в том, что значение этого результата заключается не только в том, что эти два значения пропорциональны.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "translatedText": "Дело в том, что аналогичный факт будет справедлив для любых выпуклых тел, и, что особенно важно, фактическое содержание того, что Алиса создала до сих пор, заключается в том, что для всех них будет одна и та же константа пропорциональности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "translatedText": "Теперь, если вы действительно поразмыслите над этим, некоторые из вас, возможно, смогут предсказать, как Алиса сможет закончить дело отсюда.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful.",
  "translatedText": "Это действительно восхитительно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1295.42
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "translatedText": "Честно говоря, это моя главная причина затронуть эту тему.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1295.6,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "translatedText": "Но прежде чем мы углубимся в это, я думаю, легко недооценить ее результат, если мы не углубимся в детали того, чего ей удается избежать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "translatedText": "Итак, давайте на минутку снова обратим наше внимание на мир Боба, потому что, пока Алиса всем этим занималась, он был занят некоторыми вычислениями.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "translatedText": "Фактически, он работает над тем, чтобы найти именно то, что Алисе еще предстоит выяснить, а именно, как взять найденную им формулу для площади тени квадрата и сделать следующий естественный шаг, пытаясь найти среднее значение этой площади. тень квадрата усреднялась по всем возможным ориентациям.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "translatedText": "Итак, если Боб думает обо всех возможных ориентациях этого квадрата, он начинает с вопроса: каковы все различные векторы нормалей, которые этот квадрат может иметь во всех этих ориентациях, потому что все, что касается его тени, сводится к этой нормали? вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "translatedText": "Нетрудно увидеть, что все возможные векторы нормалей очерчивают поверхность сферы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1352.32
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "translatedText": "Если предположить, что это единичный вектор нормали, то это сфера радиуса 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.32,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "translatedText": "Более того, Боб полагает, что каждая точка этой сферы должна возникнуть с такой же вероятностью, как и любая другая.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "translatedText": "Таким образом, наши вероятности должны быть однородными.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1363.98
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "translatedText": "Нет причин отдавать предпочтение одному направлению другому.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1364.02,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "translatedText": "Но в контексте непрерывных вероятностей не очень полезно говорить о вероятности конкретной отдельной точки, потому что в неисчислимой бесконечности точек на сфере она была бы равна нулю и бесполезна.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "translatedText": "Вместо этого более точным способом выразить эту однородность было бы сказать, что вероятность того, что наш нормальный вектор приземлится на любом заданном участке области сферы, должна быть пропорциональна самой этой площади.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "translatedText": "Точнее, она должна равняться площади этого небольшого участка, разделенной на общую площадь поверхности сферы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "translatedText": "Если это правда, то независимо от того, какой участок площади мы рассматриваем, именно это мы подразумеваем под равномерным распределением на сфере.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "translatedText": "Теперь, чтобы внести ясность, точки на сфере — это не то же самое, что ориентации в трехмерном пространстве, потому что даже если вы знаете, какой вектор нормали будет иметь этот квадрат, это оставляет нам другую степень свободы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1411.7
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "translatedText": "Квадрат можно было вращать вокруг этого нормального вектора.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.9,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "translatedText": "Но Бобу на самом деле не нужно беспокоиться об этой дополнительной степени свободы, потому что во всех этих случаях площадь тени одинакова.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1422.0
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "translatedText": "Это зависит только от косинуса угла между вектором нормали и вертикалью.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.36,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat.",
  "translatedText": "Что довольно аккуратно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1427.84
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "translatedText": "Все эти тени действительно имеют разную форму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1428.0,
  "end": 1430.06
 },
 {
  "input": "They're not the same.",
  "translatedText": "Они не одинаковы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.16,
  "end": 1430.9
 },
 {
  "input": "But the area of each of them will be the same.",
  "translatedText": "Но площадь каждого из них будет одинаковой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.2,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "translatedText": "Это означает, что когда Бобу нужна эта средняя площадь тени по всем возможным ориентациям, все, что ему действительно нужно знать, — это среднее значение этого абсолютного значения косинуса тета для всех возможных нормальных векторов, всех возможных точек на сфере.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this?",
  "translatedText": "Итак, как вычислить такое среднее значение?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "translatedText": "Что ж, если бы мы жили в каком-то дискретном пиксельном мире, где существует только конечное число возможных углов тета, которые может иметь этот нормальный вектор, среднее значение было бы довольно простым.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "translatedText": "Что вам нужно сделать, так это найти вероятность попадания на любое конкретное значение теты, которое скажет нам что-то вроде того, какую часть сферы составляют нормальные векторы с этим углом, а затем вы умножаете это на то, что мы хотим взять в качестве среднего значения. вот эта формула площади тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "translatedText": "А затем вы должны сложить это со всеми возможными значениями теты в диапазоне от 0 до 180 градусов или пи радиан.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "translatedText": "Но, конечно, в действительности существует континуум возможных значений тэты, эта неисчислимая бесконечность, и вероятность попасть на какое-то конкретное значение тэты на самом деле будет равна 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "translatedText": "И поэтому такая сумма, к сожалению, на самом деле не имеет никакого смысла, а если и имеет смысл, то сложение бесконечного числа нулей должно просто дать нам 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "translatedText": "Короткий ответ на то, что мы делаем вместо этого: мы вычисляем интеграл.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "translatedText": "И я скажу вам, что самое сложное здесь в том, что я не совсем уверен, какой опыт мне следует предположить от тех из вас, кто смотрит прямо сейчас.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "translatedText": "Возможно, дело в том, что вы вполне разбираетесь в исчислении, и вам не нужно, чтобы я подробно останавливался на этом вопросе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "translatedText": "Возможно, вы не знакомы с математическим анализом, и мне не следует просто так выбрасывать интегралы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "translatedText": "Или, может быть, вы недавно посещали занятия по математическому анализу, но вам нужно немного освежить знания.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "translatedText": "Я собираюсь настроить это так, как если бы это был урок исчисления, потому что, честно говоря, даже если вы вполне знакомы с интегралами, их настройка может быть своего рода процессом, подверженным ошибкам, и обратный вызов к основному определению — это хороший способ проверить себя в процессе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "translatedText": "Если бы мы жили во времена, когда еще не существовало исчисления и интегралы не существовали, и мы хотели бы приблизительно ответить на этот вопрос, один из способов сделать это — взять выборку значений θ в диапазоне от 0 до 180°.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "translatedText": "Мы могли бы думать о них как о равномерно расположенных, с некоторой разницей между ними, некоторой дельтой θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "translatedText": "И по-прежнему было бы бесполезно спрашивать о вероятности появления определенного значения θ, даже если в нашей выборке оно равно 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "translatedText": "Эта вероятность все равно будет равна 0, и это будет бесполезно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "translatedText": "Но что полезно спросить, так это вероятность попадания между двумя разными значениями из нашей выборки в этой маленькой полосе широты с шириной дельты θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "translatedText": "Исходя из нашего предположения, что распределение вдоль этой сферы должно быть равномерным, эта вероятность сводится к знанию площади этой полосы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "translatedText": "Точнее, вероятность того, что случайно выбранный вектор попадет в эту полосу, должна быть равна площади, разделенной на общую площадь поверхности сферы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "translatedText": "Чтобы определить эту площадь, давайте сначала подумаем о радиусе этой полосы, который, если радиус нашей сферы равен 1, определенно будет меньше 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "translatedText": "И на самом деле, если мы нарисуем здесь подходящий маленький прямоугольный треугольник, вы увидите, что этот маленький радиус, скажем так, в верхней части полосы, должен быть синусом нашего угла, синусом θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "translatedText": "Это означает, что длина окружности полосы должна быть в 2π раза больше синуса этого угла, а затем площадь полосы должна быть равна этой длине окружности, умноженной на ее толщину, этой маленькой дельте θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "translatedText": "Вернее, площадь нашей полосы примерно такой величины.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "translatedText": "Важно то, что для более точной выборки с большим количеством значений θ точность этого приближения будет становиться все лучше и лучше.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "translatedText": "Теперь помните: причина, по которой нам нужна эта площадь, состоит в том, чтобы знать вероятность попадания в эту полосу, которая равна этой площади, разделенной на площадь поверхности сферы, которая, как мы знаем, равна 4π, умноженному на квадрат ее радиуса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "translatedText": "Это значение также можно вычислить с помощью интеграла, подобного тому, который мы сейчас устанавливаем, но сейчас мы можем принять его как данность, как стандартную известную формулу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "translatedText": "И эта вероятность сама по себе является лишь ступенькой на пути к тому, чего мы на самом деле хотим, а именно к средней площади тени квадрата.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "translatedText": "Чтобы получить это, мы умножим эту вероятность на соответствующую площадь тени, которая представляет собой абсолютное значение выражения cosθ, которое мы видели много раз до этого момента.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "translatedText": "И наша оценка этого среднего теперь сводилась бы к суммированию этого выражения по всем различным диапазонам, всем различным выборкам θ, которые мы взяли.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "translatedText": "Кстати, именно здесь Боб полностью в своей стихии.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "translatedText": "У нас есть множество точных формул, описывающих что-то очень конкретное, и мы действительно углубляемся в путь к реальному ответу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "translatedText": "И опять же, если вам кажется, что это много деталей, я хочу, чтобы вы оценили этот факт, чтобы вы могли оценить, насколько волшебно, когда Алисе удается каким-то образом избежать всего этого.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "translatedText": "В любом случае, оглядываясь назад на наше выражение, давайте немного проясним ситуацию, например, выделим все члены, которые не зависят от самого θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "translatedText": "И мы можем упростить 2π, разделенное на 4π, чтобы оно было просто половиной.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "translatedText": "И чтобы сделать это немного более похожим на исчисление с интегралами, позвольте мне просто поменять местами основные члены внутри суммы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "translatedText": "То, что мы сейчас имеем, эта сумма, которая будет аппроксимировать ответ на наш вопрос, — это почти то же самое, что и интеграл.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "translatedText": "Вместо того, чтобы писать сигму для суммы, мы пишем интегральный символ, своего рода удлиненную букву Лейбница, показывающую нам, что мы идем от 0 к π.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "translatedText": "И вместо того, чтобы описывать размер шага как δθ, конкретную конечную величину, мы описываем его как dθ, что мне нравится думать как сигнал о том, что принят какой-то предел.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "translatedText": "По определению, этот интеграл означает то, что сумма внизу приближается к все более и более мелким подразделениям, более плотным выборкам, которые мы могли бы принять за саму θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "translatedText": "А на этом этапе для тех из вас, кто разбирается в исчислении, я просто запишу подробности того, как вы на самом деле это сделаете, как вы можете увидеть это записанным в блокноте Боба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "translatedText": "Это обычный антипроизводный метод, но единственным ключевым шагом является придание определенной тригонометрической идентичности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "translatedText": "В конце концов, проделав это, Боб обнаруживает удивительно ясный факт: средняя площадь тени квадрата составляет ровно половину площади этого квадрата.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "translatedText": "Это загадочная константа, о которой Алиса еще не знает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "translatedText": "Если бы Боб посмотрел через ее плечо и увидел работу, которую она проделала, он мог бы решить проблему прямо сейчас.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "translatedText": "Он подставляет константу, которую только что нашел, и знает окончательный ответ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "translatedText": "И теперь, наконец, на фоне всего этого, что делает Алиса, чтобы прийти к окончательному решению?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "translatedText": "Я представил ее как человека, который действительно любит обобщать полученные ею результаты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "translatedText": "И обычно эти обобщения заканчиваются интересными сносками, которые на самом деле не являются материалами для решения конкретных проблем.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "translatedText": "Но это тот случай, когда само обобщение влечет ее к количественному результату.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "translatedText": "Помните, суть того, что она обнаружила на данный момент, заключается в том, что если вы посмотрите на любое выпуклое твердое тело, то средняя площадь его тени будет пропорциональна площади его поверхности, и, что особенно важно, это будет одна и та же константа пропорциональности для всех тел. этих твердых веществ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "translatedText": "Итак, все, что нужно сделать Алисе, — это найти хотя бы одно выпуклое тело, средняя площадь тени которого ей уже известна.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going.",
  "translatedText": "И некоторые из вас могут увидеть, к чему это ведет.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "translatedText": "Самым симметричным телом, доступным нам, является сфера.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "translatedText": "Независимо от ориентации этой сферы, ее тень, плоская тень проекции, всегда представляет собой круг площадью πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "translatedText": "В частности, это средняя площадь тени.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "translatedText": "А площадь поверхности сферы, как я уже упоминал, равна ровно 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "translatedText": "Кстати, я сделал видео, рассказывающее об этой формуле площади поверхности и о том, как Архимед доказал ее за тысячи лет до того, как появилось исчисление, поэтому вам не нужны интегралы, чтобы ее найти.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "translatedText": "Волшебство того, что сделала Алиса, заключается в том, что она может взять этот, казалось бы, конкретный факт, что тень сферы имеет площадь ровно 1/4 площади ее поверхности, и использовать его для вывода гораздо более общего факта, что для любого выпуклого твердого тела там, в определенном смысле, его тень и площадь поверхности связаны таким же образом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "translatedText": "Таким образом, она может пойти и подробно ответить на конкретный вопрос о кубе и сказать, что его средняя площадь тени будет в 1/4 раза больше площади его поверхности, 6 с².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "translatedText": "Но гораздо более запоминающийся факт, о котором вы засыпаете, думая о том, что на самом деле не имело значения, что мы вообще говорили о кубе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "translatedText": "Все это очень красиво, но некоторые из вас могут жаловаться, что это не совсем веский аргумент, потому что у сфер нет плоских граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "translatedText": "Когда я сказал, что аргумент Алисы обобщается на любое выпуклое тело, если мы действительно посмотрим на сам аргумент, он определенно зависит от использования конечного числа плоских граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "translatedText": "Например, если бы мы отображали его на додекаэдр, вы бы начали с того, что площадь конкретной тени этого додекаэдра выглядит ровно в 1/2 раза больше суммы площадей теней всех его граней.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "translatedText": "Опять же, чтобы сделать такой вывод, вы могли бы использовать определенный луч света, смешанный с аргументом выпуклости.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "translatedText": "И помните, преимущество выражения этой площади тени в виде суммы заключается в том, что когда мы хотим усреднить несколько различных вращений, мы можем описать эту сумму в виде большой сетки, где мы можем затем пройти столбец за столбцом и рассмотреть среднюю площадь. для тени каждого лица.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "translatedText": "Кроме того, важным фактом был вывод, сделанный гораздо раньше, о том, что средняя тень для любого 2D-объекта, плоского 2D-объекта, что важно, будет равна некоторой универсальной константе пропорциональности, умноженной на его площадь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "translatedText": "Значение заключалось в том, что эта константа не зависела от самой формы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "translatedText": "Это мог быть квадрат, или кошка, или пятиугольные грани нашего додекаэдра, что угодно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "translatedText": "Итак, поспешно перенеся это на сферу, у которой нет конечного числа плоских граней, вы будете правы жаловаться.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "translatedText": "Но, к счастью, заполнить эту деталь довольно легко.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "translatedText": "Что вы можете сделать, так это представить себе последовательность различных многогранников, которые последовательно аппроксимируют сферу в том смысле, что их грани все плотнее и плотнее облегают истинную поверхность сферы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "translatedText": "Для каждого из этих приближений мы можем сделать один и тот же вывод: его средняя тень будет пропорциональна площади его поверхности с этой универсальной константой пропорциональности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "translatedText": "Итак, если мы скажем: хорошо, давайте возьмем предел отношения между средней площадью тени на каждом шаге и площадью поверхности на каждом шаге, ну, поскольку это соотношение никогда не меняется, оно всегда равно этой константе, тогда в предел, он также будет равен этой константе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "translatedText": "Но с другой стороны, по их определению, в пределе их средняя площадь тени должна быть равна площади круга, то есть πr², а пределом площадей поверхности будет площадь поверхности сферы, 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "translatedText": "Таким образом, мы действительно получаем вывод, который подсказывает интуиция, но, как это часто бывает с аргументами Алисы здесь, нам нужно быть немного деликатными в том, как мы оправдываем эту интуицию.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "translatedText": "Этот контраст Алисы и Боба легко воспринимается как оценочное суждение, как будто я говорю: посмотрите, какой умной Алисе удалось быть, она проницательно избегала всех тех вычислений, которые должен был делать Боб.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "translatedText": "Но это было бы очень, хм, ошибочным выводом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "translatedText": "Я думаю, что есть важное отличие популяризации математики от ощущения от реального занятия математикой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "translatedText": "Существует склонность показывать изящные доказательства, аргументы с какой-то умной и проницательной проницательностью, которая позволяет избежать вычислений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "translatedText": "Я мог бы просто проецировать, так как я очень виноват в этом, но что я могу вам сказать, сидя здесь по другую сторону экрана, так это то, что мне кажется гораздо более привлекательным снять видео о подходе Алисы, чем о подходе Боба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "translatedText": "Во-первых, в подходе Алисы ход рассуждений забавный, в нем есть приятные моменты «ага».",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "translatedText": "Но, что особенно важно, то, как вы это объясняете, более или менее одинаково для очень широкого спектра математических знаний.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "translatedText": "Гораздо менее заманчиво снимать видео о подходе Боба не потому, что вычисления настолько плохи, я имею в виду, что, честно говоря, это не так, но прагматическая реальность такова, что подходящий темп для объяснения выглядит очень по-разному в зависимости от различных математических методов. фон в аудитории.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "translatedText": "Итак, вы, смотря это прямо сейчас, явно смотрите онлайн-видео по математике, и я думаю, что при этом стоит осознавать эту предвзятость.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "translatedText": "Если цель состоит в том, чтобы получить настоящий урок по решению проблем, слишком большое внимание к изящным доказательствам может привести к неискренности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "translatedText": "Например, предположим, что мы должны были перейти в режим вызова и спросить о случае с более близким источником света.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "translatedText": "Насколько мне известно, здесь нет такого же гладкого решения, как у Алисы, где вы можете просто относиться к одной форме, например сфере.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "translatedText": "Гораздо более продуктивной разминкой было бы расчет подхода Боба.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "translatedText": "И если вы посмотрите на историю этой проблемы, то увидите, что она была доказана Коши в 1832 году, и если мы покопаемся в его рукописных заметках, то они гораздо больше похожи на работу Боба, чем на работу Алисы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "translatedText": "Прямо здесь, вверху страницы 11, вы можете увидеть, по сути, тот же интеграл, который мы с вами установили посередине.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "translatedText": "С другой стороны, вся цель статьи — найти общий факт, а не что-то конкретное, как в случае с кубом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "translatedText": "Итак, если бы мы задали вопрос, какой из этих двух образов мышления коррелирует с открытием новой математики, правильным ответом почти наверняка было бы сочетание обоих.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "translatedText": "Но я бы посоветовал многим людям не придавать достаточного веса той части смеси, где вы хотите углубиться в расчеты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "translatedText": "И я думаю, что есть некоторый риск, что видео, которые я снимаю, могут способствовать этому.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "translatedText": "В подкасте, который я вел с математиком Алексом Конторовичем, он говорил о часто недооцененной важности простого изучения вычислений для развития интуиции, независимо от того, являетесь ли вы студентом, посещающим новый класс, или практикующим математиком-исследователем, занимающимся новой областью знаний. изучать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "translatedText": "Слушатель фактически написал, чтобы подчеркнуть, какое впечатление произвел этот конкретный раздел.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "translatedText": "Они аспиранты и описывают себя как обеспокоенные тем, что их математические способности начали угасать, что они объясняют тем, что стали старше и менее сообразительными.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "translatedText": "Но услышав, как практикующий математик говорит о важности выполнения сотен конкретных примеров, чтобы узнать что-то новое, очевидно, это изменило их точку зрения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "translatedText": "По их собственным словам, признание этого полностью изменило их мировоззрение и результаты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "translatedText": "И если вы посмотрите на знаменитых математиков в истории, Ньютона, Эйлера, Гаусса, всех их, то они все обладают, казалось бы, бесконечным терпением к выполнению утомительных вычислений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "translatedText": "Ирония в том, что мы склонны показывать идеи, которые позволяют нам избежать вычислений, заключается в том, что люди часто тренируют интуицию, чтобы найти эти идеи, в первую очередь, выполняя кучу вычислений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "translatedText": "Тем не менее, без мышления Алисы здесь чего-то определенно не хватало бы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "translatedText": "Я имею в виду, подумайте, как было бы грустно, если бы мы решили эту задачу для куба и никогда не выходили за пределы деревьев, чтобы увидеть лес и понять, что это суперобщий факт, он применим к огромной семье формы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "translatedText": "И если вы считаете, что математика — это не только ответы на вопросы, которые вам задают, но и введение новых идей и конструкций, одно забавное замечание о подходе Алисы здесь заключается в том, что он предлагает интересный способ количественной оценки идеи выпуклости.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "translatedText": "Вместо того, чтобы просто ответить да-нет, выпукло ли оно, не так ли, мы могли бы дать ему число, сказав: рассмотрим среднюю площадь тени некоторого твердого тела, умножим ее на 4, разделим на площадь поверхности. , и если это число равно 1, у вас есть выпуклое тело, но если оно меньше 1, оно невыпуклое, и то, насколько оно близко к 1, говорит о том, насколько оно близко к выпуклости.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "translatedText": "Кроме того, одна из приятных особенностей решения Алисы заключается в том, что оно помогает объяснить, почему у математиков есть то, что иногда может выглядеть как причудливое увлечение общностью и абстракцией.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "translatedText": "Чем больше вы видите примеров того, как обобщение и абстрагирование действительно помогают вам решить конкретный случай, тем больше вы начинаете испытывать такое же увлечение.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "translatedText": "И в качестве последней мысли для стойких зрителей среди вас, которые дошли до этого момента, остается еще один вопрос без ответа о самой предпосылке нашей головоломки.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "translatedText": "Что именно означает выбор случайной ориентации?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "translatedText": "Теперь, если это кажется глупым вопросом, поскольку мы, конечно, знаем, что это должно означать, я бы посоветовал вам посмотреть видео, которое я только что сделал с Numberphile, о загадке вероятности, известной как парадокс Бертрана.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "translatedText": "После просмотра и если вы цените некоторые нюансы, присутствующие здесь, домашнее задание для вас — поразмыслить над тем, где именно Алиса и Боб неявно отвечают на этот вопрос.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "translatedText": "Случай с Бобом относительно прост, но момент, когда Алиса фиксирует какое-то конкретное распределение в пространстве всех ориентаций, совсем не очевиден, на самом деле он очень тонкий.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2381.7
 }
]