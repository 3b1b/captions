[
 {
  "input": "In a moment I'm going to tell you about a certain really nice puzzle involving the shadow of a cube.",
  "translatedText": "עוד רגע אני הולך לספר לכם על פאזל ממש נחמד שמערב צל של קובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.3
 },
 {
  "input": "But before we get to that, I should say that the point of this video is not exactly the puzzle per se, it's about two distinct problem-solving styles that are reflected in two different ways that we can tackle this problem.",
  "translatedText": "אבל לפני שנגיע לזה, אני צריך לומר שהפואנטה של הסרטון הזה היא לא בדיוק הפאזל כשלעצמו, היא עוסקת בשני סגנונות ברורים לפתרון בעיות שבאים לידי ביטוי בשתי דרכים שונות שבהן נוכל להתמודד עם הבעיה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.0,
  "end": 15.24
 },
 {
  "input": "In fact, let's anthropomorphize those two different styles by imagining two students, Alice and Bob, that embody each one of the approaches.",
  "translatedText": "למעשה, בואו ננסה לאנתרופומורפיזציה את שני הסגנונות השונים על ידי דמיון של שני תלמידים, אליס ובוב, שמגלמים כל אחת מהגישות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 15.78,
  "end": 22.7
 },
 {
  "input": "So Bob will be the kind of student who really loves calculation.",
  "translatedText": "אז בוב יהיה מסוג הסטודנטים שבאמת אוהב חישובים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 23.5,
  "end": 26.98
 },
 {
  "input": "As soon as there's a moment when he can dig into the details and get a very concrete view of the concrete situation in front of him, that's where he's the most pleased.",
  "translatedText": "ברגע שיש רגע שהוא יכול לחפור בפרטים ולקבל מבט מאוד קונקרטי על המצב הקונקרטי שלפניו, שם הוא הכי מרוצה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.34
 },
 {
  "input": "Alice, on the other hand, is more inclined to procrastinate the computations, not because she doesn't know how to do them or doesn't want to per se, but she prefers to get a nice high-level general overview of the kind of problem she's dealing with, the general shape that it has, before she digs into the computations themselves.",
  "translatedText": "אליס, לעומת זאת, נוטה יותר לדחות את החישובים, לא בגלל שהיא לא יודעת לעשות אותם או לא רוצה כשלעצמה, אלא היא מעדיפה לקבל סקירה כללית נחמדה ברמה גבוהה מהסוג של בעיה איתה היא מתמודדת, הצורה הכללית שיש לה, לפני שהיא חופרת בחישובים עצמם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.12,
  "end": 51.36
 },
 {
  "input": "She's most pleased if she understands not just the specific question sitting in front of her, but also the broadest possible way that you could generalize it, and especially if the more general view can lend itself to more swift and elegant computations, once she does actually sit down to carry them out.",
  "translatedText": "היא הכי מרוצה אם היא מבינה לא רק את השאלה הספציפית שעומדת מולה, אלא גם את הדרך הרחבה ביותר שאפשר להכליל אותה, ובמיוחד אם ההשקפה הכללית יותר יכולה להתאים את עצמה לחישובים מהירים ואלגנטיים יותר, ברגע שהיא באמת מבינה אותה. לשבת לבצע אותם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.16,
  "end": 66.94
 },
 {
  "input": "Now the puzzle that both of them are going to be faced with is to find the average area for the shadow of a cube.",
  "translatedText": "כעת הפאזל שעימו יתמודדו שניהם הוא למצוא את השטח הממוצע לצל של קובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.02,
  "end": 79.14
 },
 {
  "input": "So if I have a cube kind of sitting here hovering in space, there are a few things that influence the area of its shadow.",
  "translatedText": "אז אם יש לי קובייה שיושבת כאן ומרחפת בחלל, יש כמה דברים שמשפיעים על אזור הצל שלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.9,
  "end": 85.46
 },
 {
  "input": "One obvious one would be the size of the cube, smaller cube, smaller shadow.",
  "translatedText": "אחד ברור יהיה גודל הקוביה, קובייה קטנה יותר, צל קטן יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.46,
  "end": 89.26
 },
 {
  "input": "But also if it's sitting at different orientations, those orientations correspond to different particular shadows with different areas.",
  "translatedText": "אבל גם אם הוא יושב בכיוונים שונים, האוריינטציות הללו מתאימות לצללים שונים עם אזורים שונים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.88,
  "end": 96.16
 },
 {
  "input": "And when I say find the average here, what I mean is average over all possible orientations for a particular size of the cube.",
  "translatedText": "וכשאני אומר למצוא את הממוצע כאן, מה שאני מתכוון הוא ממוצע על פני כל הכיוונים האפשריים עבור גודל מסוים של הקובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 96.78,
  "end": 103.1
 },
 {
  "input": "The astute among you might point out that it also matters a lot where the light source is.",
  "translatedText": "הנבון שביניכם עשוי לציין שזה גם משנה היכן נמצא מקור האור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.42,
  "end": 108.1
 },
 {
  "input": "If the light source were very low, close to the cube itself, then the shadow ends up larger.",
  "translatedText": "אם מקור האור היה נמוך מאוד, קרוב לקובייה עצמה, אז הצל בסופו של דבר גדול יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.36,
  "end": 112.66
 },
 {
  "input": "And if the light source were kind of positioned laterally off to the side, this can distort the shadow and give it a very different shape.",
  "translatedText": "ואם מקור האור היה סוג של ממוקם לרוחב בצד, זה יכול לעוות את הצל ולתת לו צורה שונה מאוד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.66,
  "end": 118.56
 },
 {
  "input": "Accounting for that light position stands to be highly interesting in its own right, but the puzzle is hard enough as it is, so at least initially, let's do the easiest thing we can and say that the light is directly above the cube and really far away, effectively infinitely far, so that all we're considering is a flat projection, in the sense that if you look at any coordinates, x, y, z, in space, the flat projection would be x, y, 0.",
  "translatedText": "החשבון על מיקום האור הזה נראה מאוד מעניין בפני עצמו, אבל הפאזל מספיק קשה כמו שהוא, אז לפחות בהתחלה, בואו נעשה את הדבר הכי קל שאנחנו יכולים ונאמר שהאור נמצא ישירות מעל הקובייה ובאמת רחוק רחוק, למעשה רחוק לאין ערוך, כך שכל מה שאנו שוקלים הוא היטל שטוח, במובן זה שאם אתה מסתכל על קואורדינטות כלשהן, x, y, z, במרחב, ההשלכה השטוחה תהיה x, y, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.26,
  "end": 141.7
 },
 {
  "input": "So just to get our bearings, the easiest situation to think about would be if the cube is straight up, with two of its faces parallel to the ground.",
  "translatedText": "אז רק כדי להבין, הסיטואציה הקלה ביותר לחשוב עליה תהיה אם הקוביה תהיה ישרה למעלה, כששני פניה מקבילים לקרקע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.48,
  "end": 149.28
 },
 {
  "input": "In that case, this flat projection shadow is simply a square, and if we say the side lengths of the cube are s, then the area of that shadow is s squared.",
  "translatedText": "במקרה כזה, צל ההקרנה השטוח הזה הוא פשוט ריבוע, ואם נגיד שאורכי הצלעות של הקוביה הם s, אז השטח של הצל הוא s בריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 149.92,
  "end": 157.9
 },
 {
  "input": "And by the way, any time that I have a label up on these animations, like the one down here, I'll be assuming that the relevant cube has a side length of 1.",
  "translatedText": "ודרך אגב, בכל פעם שתהיה לי תווית על האנימציות האלה, כמו זו כאן למטה, אני יוצא מנקודת הנחה שלקוביה הרלוונטית יש אורך צד של 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.74,
  "end": 165.46
 },
 {
  "input": "Now another special case among all the orientations that's fun to think about is if the long diagonal is parallel to the direction of the light.",
  "translatedText": "עכשיו מקרה מיוחד נוסף בין כל הכיוונים שכיף לחשוב עליו הוא אם האלכסון הארוך מקביל לכיוון האור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.24,
  "end": 173.04
 },
 {
  "input": "In that case, the shadow actually looks like a regular hexagon, and if you use some of the methods that we will develop in a few minutes, you can compute that the area of that shadow is exactly the square root of 3 times the area of one of the square faces.",
  "translatedText": "במקרה כזה, הצל נראה למעשה כמו משושה רגיל, ואם תשתמש בכמה מהשיטות שנפתח בעוד מספר דקות, תוכל לחשב ששטח הצל הוא בדיוק השורש הריבועי של פי 3 מהשטח של אחד הפרצופים המרובעים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.6,
  "end": 185.82
 },
 {
  "input": "But of course, more often, the actual shadow will be not so regular as a square or a hexagon.",
  "translatedText": "אבל כמובן, לעתים קרובות יותר, הצל בפועל לא יהיה כל כך קבוע כמו ריבוע או משושה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.66,
  "end": 191.2
 },
 {
  "input": "It's some harder to think about shape based on some harder to think about orientation for this cube.",
  "translatedText": "קצת יותר קשה לחשוב על צורה בהתבסס על משהו שקשה יותר לחשוב על הכיוון של הקובייה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.66,
  "end": 196.24
 },
 {
  "input": "Earlier, I casually threw out this phrase of averaging over all possible orientations, but you could rightly ask, what exactly is that supposed to mean?",
  "translatedText": "קודם לכן, זרקתי כלאחר יד את המשפט הזה של ממוצע על כל הכיוונים האפשריים, אבל אתה יכול לשאול בצדק, מה בדיוק זה אמור להביע?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.06,
  "end": 205.3
 },
 {
  "input": "I think a lot of us have an intuitive feel for what we want it to mean, at least in the sense of what experiment would you do to verify it.",
  "translatedText": "אני חושב שלרבים מאיתנו יש תחושה אינטואיטיבית לגבי מה שאנחנו רוצים שזה אומר, לפחות במובן של איזה ניסוי היית עושה כדי לאמת את זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.16,
  "end": 212.86
 },
 {
  "input": "You might imagine tossing this cube in the air like a dye, freezing it at some arbitrary point, recording the area of the shadow from that position, and then repeating.",
  "translatedText": "אתה יכול לדמיין לזרוק את הקובייה הזו באוויר כמו צבע, להקפיא אותה בנקודה שרירותית כלשהי, לתעד את אזור הצל מהמיקום הזה, ואז לחזור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.06,
  "end": 222.44
 },
 {
  "input": "If you do this many many times over and over, you can take the mean of your sample.",
  "translatedText": "אם תעשה זאת פעמים רבות שוב ושוב, תוכל לקחת את הממוצע של המדגם שלך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.64,
  "end": 228.38
 },
 {
  "input": "The number that we want to get at, the true average here, should be whatever that experimental mean approaches as you do more and more tosses, approaching infinitely many.",
  "translatedText": "המספר שאליו אנחנו רוצים להגיע, הממוצע האמיתי כאן, צריך להיות מה שהממוצע הניסיוני הזה מתקרב ככל שאתה עושה יותר ויותר הטלות, שמתקרבות להרבה אינסוף.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.22,
  "end": 237.94
 },
 {
  "input": "Even still, the sticklers among you could complain that doesn't really answer the question, because it leaves open the issue of how we're defining a random toss.",
  "translatedText": "אפילו בכל זאת, הדביקים שביניכם יכולים להתלונן שזה לא ממש עונה על השאלה, כי זה משאיר את הסוגיה פתוחה של איך אנחנו מגדירים הטלה אקראית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.44,
  "end": 247.8
 },
 {
  "input": "The proper way to answer this, if we want it to be more formal, would be to first describe the space of all possible orientations, which mathematicians have actually given a fancy name.",
  "translatedText": "הדרך הנכונה לענות על זה, אם אנחנו רוצים שזה יהיה יותר רשמי, תהיה ראשית לתאר את המרחב של כל האוריינטציות האפשריות, שמתמטיקאים נתנו להם שם מהודר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.3,
  "end": 257.54
 },
 {
  "input": "They call it SO3, typically defined in terms of a certain family of 3x3 matrices.",
  "translatedText": "הם קוראים לזה SO3, המוגדר בדרך כלל במונחים של משפחה מסוימת של מטריצות 3x3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.64,
  "end": 262.44
 },
 {
  "input": "And the question we want to answer is, what probability distribution are we putting to this entire space?",
  "translatedText": "והשאלה שאנו רוצים לענות היא, איזו התפלגות הסתברות אנו שמים לכל המרחב הזה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.1,
  "end": 268.76
 },
 {
  "input": "It's only when such a probability distribution is well-defined that we can answer a question involving an average.",
  "translatedText": "רק כאשר התפלגות הסתברות כזו מוגדרת היטב, נוכל לענות על שאלה הכוללת ממוצע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.1,
  "end": 274.5
 },
 {
  "input": "If you are a stickler for that kind of thing, I want you to hold off on that question until the end of the video.",
  "translatedText": "אם אתה דבק בדברים מהסוג הזה, אני רוצה שתעצור את השאלה הזו עד סוף הסרטון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.8,
  "end": 280.82
 },
 {
  "input": "You'll be surprised at how far we can get with the more heuristic, experimental idea of just repeating a bunch of random tosses without really defining the distribution.",
  "translatedText": "תופתעו לגלות כמה רחוק אנחנו יכולים להגיע עם הרעיון היוריסטי והניסיוני יותר של לחזור על חבורה של הטלות אקראיות מבלי להגדיר את ההתפלגות באמת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.98,
  "end": 288.58
 },
 {
  "input": "Once we see Alice and Bob's solutions, it's actually very interesting to ask how exactly each one of them defined this distribution along their way.",
  "translatedText": "ברגע שאנחנו רואים את הפתרונות של אליס ובוב, זה בעצם מאוד מעניין לשאול איך בדיוק כל אחד מהם הגדיר את ההפצה הזו לאורך דרכו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.28,
  "end": 296.48
 },
 {
  "input": "And remember, this is not meant to be a lesson about cube shadows per se, but a lesson about problem solving, told through the lens of two different mindsets that we might bring to the puzzle.",
  "translatedText": "וזכרו, זה לא אמור להיות שיעור על צללי קוביות כשלעצמם, אלא שיעור על פתרון בעיות, המסופר דרך העדשה של שני היבטי חשיבה שונים שאנו עשויים להביא לפאזל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.92,
  "end": 307.1
 },
 {
  "input": "And as with any lesson on problem solving, the goal here is not to get to the answer as quickly as we can, but hopefully for you to feel like you found the answer yourself.",
  "translatedText": "וכמו בכל שיעור בנושא פתרון בעיות, המטרה כאן היא לא להגיע לתשובה כמה שיותר מהר, אלא בתקווה שתרגישו שמצאתם את התשובה בעצמכם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.86,
  "end": 315.72
 },
 {
  "input": "So if ever there's a point when you feel like you might have an idea, give yourself the freedom to pause and try to think it through.",
  "translatedText": "אז אם אי פעם יש נקודה שבה אתה מרגיש שאולי יש לך רעיון, תן לעצמך את החופש לעצור ולנסות לחשוב עליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.02,
  "end": 320.82
 },
 {
  "input": "As a first step, and this is really independent of any particular problem solving styles, just any time you find a hard question, a good thing that you can do is ask, what's the simplest possible, non-trivial variant of the problem that you can try to solve?",
  "translatedText": "כצעד ראשון, וזה באמת בלתי תלוי בסגנונות ספציפיים של פתרון בעיות, בכל פעם שאתה מוצא שאלה קשה, דבר טוב שאתה יכול לעשות הוא לשאול, מהי הגרסה הפשוטה ביותר האפשרית והלא טריוויאלית של הבעיה שאתה יכול לנסות לפתור?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.42,
  "end": 338.54
 },
 {
  "input": "So in our case, what you might say is, okay, let's forget about averaging over all the orientations.",
  "translatedText": "אז במקרה שלנו, מה שאתה יכול להגיד זה, בסדר, בוא נשכח מממוצע של כל הכיוונים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.56,
  "end": 344.0
 },
 {
  "input": "That's a tricky thing to think about.",
  "translatedText": "זה דבר מסובך לחשוב עליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.12,
  "end": 345.42
 },
 {
  "input": "And let's even forget about all the different faces of the cube, because they overlap, and that's also tricky to think about.",
  "translatedText": "ובואו אפילו נשכח מכל הפנים השונות של הקוביה, כי הם חופפים, וגם על זה קשה לחשוב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.68,
  "end": 350.86
 },
 {
  "input": "Just for one particular face, and one particular orientation, can we compute the area of this shadow?",
  "translatedText": "רק עבור פרצוף אחד מסוים, וכיוון מסוים אחד, האם נוכל לחשב את השטח של הצל הזה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.34,
  "end": 356.9
 },
 {
  "input": "Once more, if you want to get your bearings with some special cases, the easiest is when that face is parallel to the ground, in which case the area of the shadow is the same as the area of the face.",
  "translatedText": "שוב, אם אתה רוצה להתמצא עם כמה מקרים מיוחדים, הכי קל הוא כאשר הפנים האלה מקבילות לקרקע, ובמקרה זה אזור הצל זהה לאזור הפנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.66,
  "end": 366.68
 },
 {
  "input": "And on the other hand, if we were to tilt that face 90 degrees, then its shadow will be a straight line, and it has an area of zero.",
  "translatedText": "ומצד שני, אם היינו מטים את הפרצוף הזה ב-90 מעלות, אז הצל שלו יהיה קו ישר, ויש לו שטח של אפס.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 367.18,
  "end": 373.44
 },
 {
  "input": "So Bob looks at this, and he wants an actual formula for that shadow.",
  "translatedText": "אז בוב מסתכל על זה, והוא רוצה נוסחה אמיתית עבור הצל הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.3,
  "end": 377.42
 },
 {
  "input": "And the way he might think about it is to consider the normal vector perpendicular off of that face.",
  "translatedText": "והדרך שבה הוא עשוי לחשוב על זה היא לשקול את הווקטור הנורמלי הניצב מהפנים הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.9,
  "end": 382.7
 },
 {
  "input": "And what seems relevant is the angle that that normal vector makes with the vertical, with the direction where the light is coming from, which we might call theta.",
  "translatedText": "ומה שנראה רלוונטי הוא הזווית שיוצר אותו וקטור נורמלי עם האנכי, עם הכיוון שממנו מגיע האור, שאותו נוכל לקרוא תטא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.18,
  "end": 390.08
 },
 {
  "input": "Now, from the two special cases we just looked at, we know that when theta is equal to zero, the area of that shadow is the same as the area of the shape itself, which is s squared if the square has side lengths s.",
  "translatedText": "כעת, משני המקרים המיוחדים שראינו זה עתה, אנו יודעים שכאשר תטא שווה לאפס, השטח של הצל הזה זהה לשטח הצורה עצמה, שהוא s בריבוע אם לריבוע יש אורכי צלעות s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.2,
  "end": 401.56
 },
 {
  "input": "And if theta is equal to 90 degrees, then the area of that shadow is zero.",
  "translatedText": "ואם תטא שווה ל-90 מעלות, אז השטח של הצל הזה הוא אפס.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.2,
  "end": 405.8
 },
 {
  "input": "And it's probably not too hard to guess that trigonometry will be somehow relevant, so anyone comfortable with their trig functions could probably hazard a guess as to what the right formula is.",
  "translatedText": "וכנראה שלא קשה מדי לנחש שטריגונומטריה תהיה רלוונטית איכשהו, אז כל מי שנוח עם פונקציות הטריג שלו יכול כנראה להסתכן בניחוש מהי הנוסחה הנכונה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 414.62
 },
 {
  "input": "But Bob is more detail-oriented than that.",
  "translatedText": "אבל בוב מכוון יותר לפרטים מזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.62,
  "end": 417.12
 },
 {
  "input": "He wants to properly prove what that area should be, rather than just making a guess based on the endpoints.",
  "translatedText": "הוא רוצה להוכיח כמו שצריך מה התחום הזה צריך להיות, במקום רק לנחש על סמך נקודות הקצה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.4,
  "end": 422.02
 },
 {
  "input": "And the way you might think about it could be something like this.",
  "translatedText": "והדרך שבה אתה עשוי לחשוב על זה יכול להיות משהו כזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.82,
  "end": 424.74
 },
 {
  "input": "If we consider the plane that passes through the vertical as well as our normal vector, and then we consider all the different slices of our shape that are in that plane, or parallel to that plane, then we can focus our attention on a two-dimensional variant of the problem.",
  "translatedText": "אם ניקח בחשבון את המישור שעובר דרך האנכי כמו גם את הווקטור הרגיל שלנו, ואז ניקח בחשבון את כל הפרוסות השונות של הצורה שלנו שנמצאות במישור הזה, או במקביל למישור הזה, אז נוכל למקד את תשומת הלב שלנו בשני- גרסה ממדית של הבעיה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.98,
  "end": 439.04
 },
 {
  "input": "If we just look at one of those slices, who has a normal vector, an angle theta away from the vertical, its shadow might look something like this.",
  "translatedText": "אם רק נסתכל על אחת הפרוסות האלה, שיש לה וקטור רגיל, במרחק תטא בזווית מהאנכי, הצל שלה עשוי להיראות בערך כך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.32,
  "end": 446.78
 },
 {
  "input": "And if we draw a vertical line up to the left here, we have ourselves a right triangle.",
  "translatedText": "ואם נשרטט כאן קו אנכי שמאלה, יש לנו משולש ישר זווית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.46,
  "end": 451.02
 },
 {
  "input": "And from here we can do a little bit of angle chasing, where we follow around what that angle theta implies about the rest of the diagram.",
  "translatedText": "ומכאן נוכל לעשות מעט רדיפה זווית, כאשר אנו עוקבים אחר מה שזווית תטא מרמזת לגבי שאר התרשים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.6,
  "end": 457.52
 },
 {
  "input": "And this means the lower right angle in this triangle is precisely theta.",
  "translatedText": "וזה אומר שהזווית הימנית התחתונה במשולש הזה היא בדיוק תטא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 458.58,
  "end": 462.36
 },
 {
  "input": "So, when we want to understand the size of this shadow in comparison to the original size of the piece, we can think about the cosine of that angle, theta, which remembers the adjacent over the hypotenuse.",
  "translatedText": "לכן, כאשר אנו רוצים להבין את גודל הצל הזה בהשוואה לגודל המקורי של היצירה, אנו יכולים לחשוב על הקוסינוס של זווית זו, תטא, שזוכרת את הסמוך מעל התחתון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.48,
  "end": 474.58
 },
 {
  "input": "It's literally the ratio between the size of the shadow and the size of the slice.",
  "translatedText": "זה ממש היחס בין גודל הצל לגודל הפרוסה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.7,
  "end": 478.18
 },
 {
  "input": "So, the factor by which the slice gets squished down in this direction is exactly cosine of theta.",
  "translatedText": "אז הגורם שבאמצעותו הפרוסה נמעכת בכיוון הזה הוא בדיוק קוסינוס של תטא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.9,
  "end": 484.52
 },
 {
  "input": "And if we broaden our view to the entire square, all the slices in that direction get scaled by the same factor.",
  "translatedText": "ואם נרחיב את הראייה שלנו לכל הכיכר, כל הפרוסות בכיוון הזה יקבלו קנה מידה באותו גורם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.14,
  "end": 490.18
 },
 {
  "input": "But in the other direction, in the one perpendicular to that slice, there is no stretching or squishing, because the face is not at all tilted in that direction.",
  "translatedText": "אבל בכיוון השני, בזו הניצבת לאותה פרוסה, אין מתיחה או מעיכה, כי הפנים כלל לא נוטים לכיוון הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.38,
  "end": 498.12
 },
 {
  "input": "So overall, the two-dimensional shadow of our two-dimensional face should also be scaled down by this factor of a cosine of theta.",
  "translatedText": "אז בסך הכל, הצל הדו-ממדי של הפנים הדו-מימדי שלנו צריך להיות מופחת גם על ידי הגורם הזה של קוסינוס של תטא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.12,
  "end": 505.7
 },
 {
  "input": "It lines up with what you might intuitively guess, given the case where the angle is 0° and the case where it's 90°, but it's reassuring to see why it's true.",
  "translatedText": "זה תואם את מה שאתה יכול לנחש באופן אינטואיטיבי, בהתחשב במקרה שבו הזווית היא 0° והמקרה שבו היא 90°, אבל זה מרגיע לראות למה זה נכון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.26,
  "end": 513.38
 },
 {
  "input": "And actually, as stated so far, this is not quite correct.",
  "translatedText": "ובעצם, כאמור עד כה, זה לא לגמרי נכון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.96,
  "end": 518.32
 },
 {
  "input": "There is a small problem with the formula that we've written.",
  "translatedText": "יש בעיה קטנה עם הנוסחה שכתבנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.52,
  "end": 520.8
 },
 {
  "input": "In the case where theta is bigger than 90°, the cosine would actually come out to be negative.",
  "translatedText": "במקרה שבו תטא גדול מ-90°, הקוסינוס היה למעשה יוצא שלילי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 521.34,
  "end": 526.24
 },
 {
  "input": "But of course, we don't want to consider the shadow to have negative area, at least not in a problem like this.",
  "translatedText": "אבל כמובן, אנחנו לא רוצים לראות בצל יש אזור שלילי, לפחות לא בבעיה כזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 526.24,
  "end": 531.4
 },
 {
  "input": "So there's two different ways you could solve this.",
  "translatedText": "אז יש שתי דרכים שונות שאתה יכול לפתור את זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.86,
  "end": 533.3
 },
 {
  "input": "You could say we only ever want to consider the normal vector that is pointing up, that has a positive z component.",
  "translatedText": "אפשר לומר שאי פעם נרצה לשקול רק את הווקטור הנורמלי שמצביע כלפי מעלה, שיש לו רכיב z חיובי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.38,
  "end": 538.34
 },
 {
  "input": "Or, more simply, we could say, just take the absolute value of that cosine, and that gives us a valid formula.",
  "translatedText": "או, יותר פשוט, אפשר לומר, פשוט קח את הערך המוחלט של הקוסינוס הזה, וזה נותן לנו נוסחה תקפה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.84,
  "end": 544.72
 },
 {
  "input": "So Bob's happy because he has a precise formula describing the area of the shadow.",
  "translatedText": "אז בוב מאושר כי יש לו נוסחה מדויקת שמתארת את אזור הצל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.98,
  "end": 550.86
 },
 {
  "input": "But Alice starts to think about it a little bit differently.",
  "translatedText": "אבל אליס מתחילה לחשוב על זה קצת אחרת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.5,
  "end": 554.06
 },
 {
  "input": "She says, okay, we've got some shape, and then we apply a rotation that sort of situates it into 3D space in some way.",
  "translatedText": "היא אומרת, בסדר, יש לנו איזושהי צורה, ואז אנחנו מיישמים סיבוב שממקם אותו בחלל תלת-ממדי בדרך כלשהי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 554.06,
  "end": 560.52
 },
 {
  "input": "And then we apply a flat projection that shoves that back into two-dimensional space.",
  "translatedText": "ואז אנחנו מיישמים הקרנה שטוחה שדוחפת את זה בחזרה לחלל דו מימדי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.78,
  "end": 564.66
 },
 {
  "input": "And what stands out to her is that both of these are linear transformations.",
  "translatedText": "ומה שבולט בעיניה הוא ששניהם הם טרנספורמציות ליניאריות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.08,
  "end": 568.34
 },
 {
  "input": "That means that in principle you could describe each one of them with a matrix, and that the overall transformation would look like the product of those two matrices.",
  "translatedText": "זה אומר שבאופן עקרוני אפשר לתאר כל אחד מהם עם מטריצה, ושהטרנספורמציה הכוללת תיראה כמו המכפלה של שתי המטריצות הללו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.06,
  "end": 576.2
 },
 {
  "input": "What Alice knows from one of her favorite subjects, linear algebra, is that if you take some shape and you consider its area, then you apply some linear transformation, then the area of that output looks like some constant times the original area of the shape.",
  "translatedText": "מה שאליס יודעת מאחד הנושאים האהובים עליה, אלגברה לינארית, הוא שאם אתה לוקח צורה כלשהי ואתה מחשיב את השטח שלה, אתה מיישם איזו טרנספורמציה ליניארית, ואז השטח של הפלט הזה נראה כמו כמה קבועים כפול השטח המקורי של הצורה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.0,
  "end": 590.32
 },
 {
  "input": "More specifically, we have a name for that constant.",
  "translatedText": "ליתר דיוק, יש לנו שם לקבוע הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 590.9,
  "end": 592.78
 },
 {
  "input": "It's called the determinant of the transformation.",
  "translatedText": "זה נקרא הקובע של הטרנספורמציה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.86,
  "end": 594.96
 },
 {
  "input": "If you're not so comfortable with linear algebra, we could give a much more intuitive description and say, if you uniformly stretch the original shape in some direction, the output will also uniformly get stretched in some direction.",
  "translatedText": "אם אתה לא כל כך נוח עם אלגברה לינארית, נוכל לתת תיאור הרבה יותר אינטואיטיבי ולומר, אם אתה מותח את הצורה המקורית בצורה אחידה לכיוון כלשהו, גם הפלט יימתח באופן אחיד לכיוון כלשהו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 596.26,
  "end": 607.56
 },
 {
  "input": "So the area of each of them should scale in proportion to each other.",
  "translatedText": "אז השטח של כל אחד מהם צריך להיות בקנה מידה ביחס זה לזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.56,
  "end": 611.4
 },
 {
  "input": "Now in principle, Alice could compute this determinant, but it's not really her style to do that, at least not to do so immediately.",
  "translatedText": "כעת, באופן עקרוני, אליס יכלה לחשב את הקובע הזה, אבל זה לא באמת הסגנון שלה לעשות את זה, לפחות לא לעשות זאת מיד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.16,
  "end": 618.32
 },
 {
  "input": "Instead, the thing that she writes down is how this proportionality constant between our original shape and its shadow does not depend on the original shape.",
  "translatedText": "במקום זאת, הדבר שהיא כותבת הוא כיצד קבוע המידתיות הזה בין הצורה המקורית שלנו והצל שלה אינו תלוי בצורה המקורית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.88,
  "end": 627.1
 },
 {
  "input": "We could be talking about the shadow of this cat outline, or anything else, and the size of it doesn't really matter.",
  "translatedText": "יכול להיות שאנחנו מדברים על הצל של מתאר החתול הזה, או כל דבר אחר, והגודל שלו לא ממש משנה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.26,
  "end": 632.64
 },
 {
  "input": "The only thing affecting that proportionality constant is what transformation we're applying, which in this context means we could write it down as some factor that depends on the rotation being applied to the shape.",
  "translatedText": "הדבר היחיד שמשפיע על קבוע המידתיות הוא איזו טרנספורמציה אנחנו מיישמים, מה שאומר שבהקשר זה נוכל לרשום אותה כגורם כלשהו שתלוי בסיבוב המופעל על הצורה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.64,
  "end": 643.14
 },
 {
  "input": "In the back of our mind, because of Bob's calculation, we know what that factor looks like.",
  "translatedText": "בחלק האחורי של מוחנו, בגלל החישוב של בוב, אנחנו יודעים איך הגורם הזה נראה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.5,
  "end": 648.22
 },
 {
  "input": "You know, it's the absolute value of the cosine of the angle between the normal vector and the vertical.",
  "translatedText": "אתה יודע, זה הערך המוחלט של הקוסינוס של הזווית בין הווקטור הנורמלי לאנך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.36,
  "end": 652.5
 },
 {
  "input": "But Alice right now is just saying, yeah, yeah, yeah, I can think about that eventually when I want to.",
  "translatedText": "אבל אליס כרגע רק אומרת, כן, כן, כן, אני יכולה לחשוב על זה בסופו של דבר כשאני רוצה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.16,
  "end": 656.82
 },
 {
  "input": "But she knows we're about to average over all the different orientations anyway, though she holds out some hope that any specific formula about a specific orientation might get washed away in that average.",
  "translatedText": "אבל היא יודעת שבכל מקרה אנחנו עומדים להגיע לממוצע על כל הכיוונים השונים, אם כי היא מחזיקה בתקווה שכל נוסחה ספציפית לגבי אוריינטציה ספציפית עלולה להישטף בממוצע הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 657.04,
  "end": 666.8
 },
 {
  "input": "Now it's easy to look at this and say, okay, well Alice isn't really doing anything then.",
  "translatedText": "עכשיו קל להסתכל על זה ולהגיד, בסדר, ובכן אליס לא באמת עושה כלום אז.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 668.22,
  "end": 671.64
 },
 {
  "input": "Of course the area of the shadow is proportional to the area of the original shape.",
  "translatedText": "כמובן ששטח הצל פרופורציונלי לשטח הצורה המקורית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.78,
  "end": 675.44
 },
 {
  "input": "They're both two-dimensional quantities, they should both scale like two-dimensional things.",
  "translatedText": "שניהם גדלים דו מימדיים, שניהם צריכים להתאים כמו דברים דו מימדיים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 675.62,
  "end": 679.64
 },
 {
  "input": "But keep in mind, this would not at all be true if we were dealing with the harder case that has a closer light source.",
  "translatedText": "אבל זכור, זה בכלל לא היה נכון אם אנחנו עוסקים במקרה הקשה יותר שיש לו מקור אור קרוב יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.2,
  "end": 685.68
 },
 {
  "input": "In that case, the projection is not linear.",
  "translatedText": "במקרה זה, ההקרנה אינה ליניארית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.84,
  "end": 687.98
 },
 {
  "input": "For example, if I rotate this cat so that its tail ends up quite close to the light source, then if I stretch the original shape uniformly in the x-direction, say by a factor of 1.5, it might have a very disproportionate effect on the ultimate shadow, because the tail gets very disproportionately blown up as it gets really close to the light.",
  "translatedText": "לדוגמה, אם אני מסובב את החתול הזה כך שזנבו יגיע די קרוב למקור האור, אז אם אני מותח את הצורה המקורית בצורה אחידה בכיוון ה-x, נניח בפקטור 1.5, עשויה להיות לו השפעה מאוד לא פרופורציונלית על הצל האולטימטיבי, מכיוון שהזנב מתפוצץ בצורה מאוד לא פרופורציונלית כשהוא מתקרב באמת לאור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 687.98,
  "end": 706.2
 },
 {
  "input": "Again, Alice is keeping an eye out for what properties of the problem are actually relevant, because that helps her know how much she can generalize things.",
  "translatedText": "שוב, אליס שמה עין על אילו מאפיינים של הבעיה רלוונטיים בפועל, כי זה עוזר לה לדעת עד כמה היא יכולה להכליל דברים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 706.88,
  "end": 713.44
 },
 {
  "input": "Does the fact that we're thinking about a square face and not some other shape matter?",
  "translatedText": "האם העובדה שאנחנו חושבים על פנים מרובעות ולא על צורה אחרת חשובה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 713.96,
  "end": 717.26
 },
 {
  "input": "No, not really.",
  "translatedText": "לא לא ממש.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 717.26,
  "end": 718.64
 },
 {
  "input": "Does the fact that the transformation is linear matter?",
  "translatedText": "האם העובדה שהטרנספורמציה היא ליניארית משנה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 718.78,
  "end": 721.32
 },
 {
  "input": "Yes, absolutely.",
  "translatedText": "כן בהחלט.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 721.82,
  "end": 722.84
 },
 {
  "input": "Alice can also apply a similar way of thinking about the average shadow for any shape like this.",
  "translatedText": "אליס יכולה גם ליישם דרך חשיבה דומה לגבי הצל הממוצע עבור כל צורה כזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.56,
  "end": 731.76
 },
 {
  "input": "Say we have some sequence of rotations that we apply to our square face, and let's call them R1, R2, R3, and so on.",
  "translatedText": "נניח שיש לנו איזה רצף של סיבובים שאנו מפעילים על הפנים המרובעות שלנו, ובואו נקרא להם R1, R2, R3 וכו'.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.02,
  "end": 739.56
 },
 {
  "input": "Then the area of the shadow in each one of those cases looks like some factor times the area of the square, and that factor depends on the rotation.",
  "translatedText": "ואז השטח של הצל בכל אחד מהמקרים האלה נראה כמו גורם מסוים כפול שטח הריבוע, והגורם הזה תלוי בסיבוב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 739.72,
  "end": 747.3
 },
 {
  "input": "So if we take an empirical average for that shadow across the sample of rotations we're looking at right now, the way it looks is to add up all of those shadow areas and then divide by the total number that we have.",
  "translatedText": "אז אם ניקח ממוצע אמפירי עבור הצל הזה על פני מדגם הסיבובים שאנו מסתכלים עליו כעת, הדרך שבה הוא נראה הוא לחבר את כל אזורי הצל הללו ואז לחלק במספר הכולל שיש לנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.06,
  "end": 758.32
 },
 {
  "input": "Now, because of the linearity, this area of the original square can cleanly factor out of all of that, and it ends up on the left.",
  "translatedText": "עכשיו, בגלל הליניאריות, השטח הזה של הריבוע המקורי יכול לקחת בחשבון בצורה נקייה את כל זה, והוא מסתיים בצד שמאל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 758.9,
  "end": 766.46
 },
 {
  "input": "This isn't the exact average that we're looking for, it's just an empirical mean of a sample of rotations, but in principle what we're looking for is what this approaches as the size of our sample approaches infinity, and all the parts that depend on the size of the sample sit cleanly away from the area itself.",
  "translatedText": "זה לא הממוצע המדויק שאנחנו מחפשים, זה רק ממוצע אמפירי של מדגם של סיבובים, אבל באופן עקרוני מה שאנחנו מחפשים זה מה זה מתקרב כשגודל המדגם שלנו מתקרב לאינסוף, וכל חלקים התלויים בגודל המדגם יושבים בצורה נקייה הרחק מהאזור עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 767.2,
  "end": 783.04
 },
 {
  "input": "So whatever this approaches in the limit, it's just going to be some number.",
  "translatedText": "אז לא משנה מה זה מתקרב בגבול, זה רק יהיה מספר כלשהו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.58,
  "end": 786.46
 },
 {
  "input": "It might be a royal pain to compute, we're not sure about that yet, but the thing that Alice notes is that it's independent of the size and the shape of the particular 2D thing that we're looking at.",
  "translatedText": "זה יכול להיות כאב מלכותי לחשב, אנחנו לא בטוחים לגבי זה עדיין, אבל הדבר שאליס מציינת הוא שזה לא תלוי בגודל ובצורה של הדבר הדו-ממדי המסוים שאנחנו מסתכלים עליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 786.82,
  "end": 795.66
 },
 {
  "input": "It's a universal proportionality constant, and her hope is that that universality somehow lends itself to a more elegant way to deduce what it must be.",
  "translatedText": "זה קבוע מידתיות אוניברסלי, והתקווה שלה היא שהאוניברסליות הזו מתאימה איכשהו לדרך אלגנטית יותר להסיק מה היא חייבת להיות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.72,
  "end": 804.94
 },
 {
  "input": "Now Bob would be eager to compute this constant here and now, and in a few minutes I'll show you how he does it.",
  "translatedText": "עכשיו בוב היה להוט לחשב את הקבוע הזה כאן ועכשיו, ובעוד כמה דקות אני אראה לך איך הוא עושה את זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.26,
  "end": 811.72
 },
 {
  "input": "But before that I do want to stay in Alice's world for a little bit more, because this is where things start to really get fun.",
  "translatedText": "אבל לפני כן אני כן רוצה להישאר בעולמה של אליס עוד קצת, כי זה המקום שבו הדברים מתחילים להיות ממש כיף.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 812.04,
  "end": 816.96
 },
 {
  "input": "In her desire to understand the overall structure of the question before diving into the details, she's curious now about how the area of the shadow of the cube relates to the area of its individual faces.",
  "translatedText": "מתוך רצונה להבין את המבנה הכללי של השאלה לפני הצלילה לפרטים, היא סקרנית כעת כיצד אזור הצל של הקוביה קשור לאזור פניה האישיים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.08,
  "end": 831.1
 },
 {
  "input": "Now if we can say something about the average area of a particular face, does that tell us anything about the average area of the cube as a whole?",
  "translatedText": "עכשיו אם אנחנו יכולים לומר משהו על השטח הממוצע של פנים מסוימות, האם זה אומר לנו משהו על השטח הממוצע של הקובייה בכללותה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 831.62,
  "end": 838.4
 },
 {
  "input": "For example, a simple thing we could say is that that area is definitely less than the sum of the areas across all the faces, because there's a meaningful amount of overlap between those shadows.",
  "translatedText": "לדוגמה, דבר פשוט שאנחנו יכולים לומר הוא שהאזור הזה הוא בהחלט פחות מסכום השטחים על פני כל הפרצופים, מכיוון שיש כמות משמעותית של חפיפה בין הצללים הללו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.1,
  "end": 848.92
 },
 {
  "input": "But it's not entirely clear how to think about that overlap, because if we focus our attention just on two particular faces, in some orientations they don't overlap at all, but in other orientations they do have some overlap, and the specific shape and area of that overlap seems a little bit tricky to think about, much less how on Earth we would average that across all of the different orientations.",
  "translatedText": "אבל לא לגמרי ברור איך לחשוב על החפיפה הזו, כי אם נמקד את תשומת הלב שלנו רק בשתי פנים מסוימות, בכמה אוריינטציות הם לא חופפים בכלל, אבל בשאר הכיוונים יש להם חפיפה מסוימת, והצורה הספציפית וה אזור החפיפה הזה נראה קצת מסובך לחשוב עליו, הרבה פחות איך בכדור הארץ היינו ממוצעים את זה בכל הכיוונים השונים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.64,
  "end": 869.82
 },
 {
  "input": "But Alice has about three clever insights through this whole problem, and this is the first one of them.",
  "translatedText": "אבל לאליס יש בערך שלוש תובנות חכמות דרך כל הבעיה הזו, וזו הראשונה שבהן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 870.66,
  "end": 875.46
 },
 {
  "input": "She says, actually, if we think about the whole cube, not just a pair of faces, we can conclude that the area of the shadow for a given orientation is exactly one half the sum of the areas of all of the faces.",
  "translatedText": "היא אומרת, למעשה, אם נחשוב על כל הקובייה, לא רק על זוג פרצופים, נוכל להסיק ששטח הצל עבור כיוון נתון הוא בדיוק חצי מסכום השטחים של כל הפרצופים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.88,
  "end": 888.18
 },
 {
  "input": "Intuitively you can maybe guess that half of them are bathed in the light and half of them are not, but here's the way that she justifies it.",
  "translatedText": "באופן אינטואיטיבי אתה יכול אולי לנחש שמחציתם שטופים באור ומחציתם לא, אבל הנה הדרך שבה היא מצדיקה זאת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.58,
  "end": 895.66
 },
 {
  "input": "She says for a particular ray of light, they would go from the sky and eventually hit a point in the shadow.",
  "translatedText": "היא אומרת שעבור קרן אור מסוימת, הם היו יוצאים מהשמים ובסופו של דבר פוגעים בנקודה בצל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 895.82,
  "end": 901.4
 },
 {
  "input": "That ray passes through the cube at exactly two points.",
  "translatedText": "קרן זו עוברת דרך הקובייה בשתי נקודות בדיוק.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 902.04,
  "end": 904.86
 },
 {
  "input": "There's one moment when it enters and one moment when it exits.",
  "translatedText": "יש רגע אחד שבו הוא נכנס ורגע אחד שבו הוא יוצא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 905.12,
  "end": 907.6
 },
 {
  "input": "So every point in that shadow corresponds to exactly two faces above it.",
  "translatedText": "אז כל נקודה בצל מתאימה בדיוק לשני פנים מעליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.6,
  "end": 913.78
 },
 {
  "input": "Well, okay, that's not exactly true if that beam of light happened to go through the edge of one of the squares.",
  "translatedText": "טוב, בסדר, זה לא בדיוק נכון אם קרן האור הזו עברה במקרה דרך קצה אחד הריבועים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.46,
  "end": 919.22
 },
 {
  "input": "There's a little bit of ambiguity on how many faces it's passing, but those account for zero area inside the shadow, so we're safe to ignore them if the thing we're trying to do is compute the area.",
  "translatedText": "יש קצת אי בהירות לגבי כמה פרצופים זה עובר, אבל אלה מהווים שטח אפס בתוך הצל, אז אנחנו בטוחים להתעלם מהם אם הדבר שאנחנו מנסים לעשות הוא לחשב את השטח.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 919.6,
  "end": 929.04
 },
 {
  "input": "If Alice is pressed and she needs to justify why exactly this is true, which is important for understanding how the problem might generalize, she can appeal to the idea of convexity.",
  "translatedText": "אם אליס נלחצת והיא צריכה להצדיק מדוע בדיוק זה נכון, מה שחשוב להבנה כיצד הבעיה עשויה להכליל, היא יכולה לערער על רעיון הקמור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 931.02,
  "end": 940.82
 },
 {
  "input": "Convexity is one of those properties where a lot of us have an intuitive sense for what it should mean, you know, it's shapes that just bulge out, they never dent inward.",
  "translatedText": "קמורות היא אחד מאותם מאפיינים שבהם לרבים מאיתנו יש תחושה אינטואיטיבית למה זה צריך להיות אומר, אתה יודע, אלו צורות שפשוט מתבלטות החוצה, הן אף פעם לא נבלעות פנימה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 941.42,
  "end": 948.58
 },
 {
  "input": "But mathematicians have a pretty clever way of formalizing it that's helpful for actual proofs.",
  "translatedText": "אבל למתמטיקאים יש דרך די חכמה לנסח את זה בצורה מועילה להוכחות ממשיות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.14,
  "end": 953.02
 },
 {
  "input": "They say that a set is convex if the line that connects any two points inside that set is entirely contained within the set itself.",
  "translatedText": "הם אומרים שקבוצה היא קמורה אם הקו שמחבר בין שתי נקודות כלשהן בתוך הסט הזה מוכל כולו בתוך הסט עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.68,
  "end": 961.66
 },
 {
  "input": "So a square is convex because no matter where you put two points inside that square, the line connecting them is entirely contained inside the square.",
  "translatedText": "אז ריבוע הוא קמור כי לא משנה היכן אתה שם שתי נקודות בתוך הריבוע הזה, הקו המחבר ביניהן מוכל כולו בתוך הריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.66,
  "end": 969.66
 },
 {
  "input": "But something like the symbol pi is not convex.",
  "translatedText": "אבל משהו כמו הסמל pi אינו קמור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 970.28,
  "end": 972.72
 },
 {
  "input": "I can easily find two different points so that the line connecting them has to peak outside of the set itself.",
  "translatedText": "אני יכול למצוא בקלות שתי נקודות שונות כך שהקו המחבר אותן צריך להגיע לשיא מחוץ לסט עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 972.84,
  "end": 978.32
 },
 {
  "input": "None of the letters in the word convex are themselves convex.",
  "translatedText": "אף אחת מהאותיות במילה קמור אינה קמורה בעצמה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.94,
  "end": 982.6
 },
 {
  "input": "You can find two points so that the line connecting them has to pass outside of the set.",
  "translatedText": "אתה יכול למצוא שתי נקודות כך שהקו המחבר אותן צריך לעבור מחוץ לסט.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 982.7,
  "end": 987.02
 },
 {
  "input": "It's a really clever way to formalize this idea of a shape that only bulges out, because any time that it dents inward, you can find these counterexample lines.",
  "translatedText": "זו דרך ממש חכמה להמציא את הרעיון הזה של צורה שרק בולטת החוצה, מכיוון שבכל פעם שהיא נקלעת פנימה, אתה יכול למצוא את קווי הדוגמה הנגדית האלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 987.46,
  "end": 995.54
 },
 {
  "input": "Our cube, because it's convex, between the first point of entry and the last point of exit, it has to stay entirely inside the cube by definition of convexity.",
  "translatedText": "הקובייה שלנו, מכיוון שהיא קמורה, בין נקודת הכניסה הראשונה לנקודת היציאה האחרונה, היא חייבת להישאר כולה בתוך הקובייה בהגדרתה של קמור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.1,
  "end": 1005.18
 },
 {
  "input": "But if we were dealing with some other non-convex shape, like a donut, you could find a ray of light that enters, then exits, then enters, then exits again, so you wouldn't have a clean two-to-one cover from the shadows.",
  "translatedText": "אבל אם עסקינן באיזו צורה לא קמורה אחרת, כמו סופגנייה, היית יכול למצוא קרן אור שנכנסת, ואז יוצאת, ואז נכנסת, ואז יוצאת שוב, כדי שלא תהיה לך שניים על אחד נקי. לכסות מהצללים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1005.74,
  "end": 1016.16
 },
 {
  "input": "The shadows of all of its different parts, if you were to cover this in a bunch of faces, would not be precisely two times the area of the shadow itself.",
  "translatedText": "הצללים של כל החלקים השונים שלו, אם הייתם מכסים את זה בחבורה של פרצופים, לא יהיו בדיוק פי שניים מהשטח של הצל עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.6,
  "end": 1024.08
 },
 {
  "input": "So, that's the first key insight, the face shadows double cover the cube shadow.",
  "translatedText": "אז, זו התובנה המרכזית הראשונה, צלליות הפנים מכסות כפולות את הצללית הקובייתית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.76,
  "end": 1028.26
 },
 {
  "input": "And the next one is a little bit more symbolic, so let's start things off by abbreviating our notation a little to make room on the screen.",
  "translatedText": "והבא הוא קצת יותר סמלי, אז בואו נתחיל בקיצור של התווים שלנו קצת כדי לפנות מקום על המסך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.88,
  "end": 1034.66
 },
 {
  "input": "Instead of writing the area of the shadow of the cube, I'm just going to write s of the cube.",
  "translatedText": "במקום לכתוב את אזור הצל של הקוביה, אני פשוט אכתוב את ה-s של הקובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.36,
  "end": 1039.68
 },
 {
  "input": "And similarly, instead of the area of the shadow of a particular face, I'm just going to write s of f, where that subscript j indicates which face I'm talking about.",
  "translatedText": "ובאופן דומה, במקום אזור הצל של פנים מסוימות, אני פשוט אכתוב את s של f, שבו הכתובית j מציינת על איזה פנים אני מדבר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.32,
  "end": 1048.42
 },
 {
  "input": "But of course, we should really be talking about the shadow of a particular rotation applied to the cube.",
  "translatedText": "אבל כמובן, אנחנו צריכים באמת לדבר על הצל של סיבוב מסוים שהופעל על הקובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1048.42,
  "end": 1053.62
 },
 {
  "input": "So I might write this as s of some rotation applied to the cube, and likewise on the right, it's the area of the shadow of that same rotation applied to a given one of the faces.",
  "translatedText": "אז אני יכול לכתוב את זה בתור סיבוב כלשהו שהוחל על הקוביה, וכמו כן בצד ימין, זה האזור של הצל של אותו סיבוב שהוחל על אחד מהפנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1054.1,
  "end": 1063.26
 },
 {
  "input": "With the more compact notation at hand, let's think about the average of this shadow area across many different rotations, some sample of r1, r2, r3, and so on.",
  "translatedText": "עם הסימון הקומפקטי יותר בהישג יד, בואו נחשוב על הממוצע של אזור הצל הזה על פני סיבובים רבים ושונים, מדגם כלשהו של r1, r2, r3 וכן הלאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1063.76,
  "end": 1073.7
 },
 {
  "input": "Again, that average just involves adding up all of those shadow areas and then dividing them by n.",
  "translatedText": "שוב, הממוצע הזה רק כרוך בחיבור של כל אזורי הצל, ואז לחלק אותם ב-n.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1074.12,
  "end": 1079.22
 },
 {
  "input": "And in principle, if we were to look at this for larger and larger samples, let n approach infinity, that would give us the average area of the shadow of the cube.",
  "translatedText": "ובאופן עקרוני, אם היינו מסתכלים על זה עבור דגימות גדולות יותר ויותר, תנו ל-n להתקרב לאינסוף, זה ייתן לנו את השטח הממוצע של הצל של הקובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1079.94,
  "end": 1087.36
 },
 {
  "input": "Some of you might be thinking, yes, we know this, you've said this already, but it's beneficial to write it out so that we can understand why it is that expressing the shadow area for a particular rotation of the cube as a sum across all of its faces, or one half times that sum at least, why is that beneficial?",
  "translatedText": "חלק מכם אולי חושבים, כן, אנחנו יודעים את זה, כבר אמרתם את זה, אבל זה מועיל לכתוב את זה כדי שנוכל להבין למה זה הביטוי של אזור הצל עבור סיבוב מסוים של הקוביה כסכום על פני כל הפנים שלו, או פי חצי מהסכום הזה לפחות, למה זה מועיל?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.26,
  "end": 1103.42
 },
 {
  "input": "What is it going to do for us?",
  "translatedText": "מה זה יעשה לנו?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1103.6,
  "end": 1104.76
 },
 {
  "input": "Well, let's just write it out, where for each one of these rotations of the cube, we could break down that shadow as a sum across that same rotation applied across all of the faces.",
  "translatedText": "ובכן, בוא נכתוב את זה, איפה עבור כל אחד מהסיבובים האלה של הקובייה, נוכל לפרק את הצל הזה כסכום על פני אותו סיבוב שהופעל על פני כל הפרצופים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.56,
  "end": 1113.9
 },
 {
  "input": "And when it's written as a grid like this, we can get to Alice's second insight, which is to shift the way that we're thinking about the sum from going row by row to instead going column by column.",
  "translatedText": "וכשזה כתוב כרשת כזו, אנחנו יכולים להגיע לתובנה השנייה של אליס, שהיא לשנות את הדרך שבה אנחנו חושבים על הסכום ממעבר שורה אחר שורה למקום מעבר טור אחר טור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1114.54,
  "end": 1123.72
 },
 {
  "input": "For example, if we focused our attention just on the first column, what it's telling us is to add up the area of the shadow of the first face across many different orientations.",
  "translatedText": "לדוגמה, אם מיקדנו את תשומת הלב שלנו רק בעמודה הראשונה, מה שזה אומר לנו הוא לחבר את אזור הצל של הפנים הראשון על פני הרבה כיוונים שונים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.84,
  "end": 1135.08
 },
 {
  "input": "So if we were to take that sum and divide it by the size of our sample, that gives us an empirical average for the area of the shadow of this face.",
  "translatedText": "אז אם היינו לוקחים את הסכום הזה ומחלקים אותו בגודל המדגם שלנו, זה נותן לנו ממוצע אמפירי עבור שטח הצל של הפנים הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1135.64,
  "end": 1142.94
 },
 {
  "input": "So if we take larger and larger samples, letting that size go to infinity, this will approach the average shadow area for a square.",
  "translatedText": "אז אם ניקח דגימות גדולות יותר ויותר, נניח לגודל הזה להגיע לאינסוף, זה יתקרב לאזור הצל הממוצע של ריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1143.8,
  "end": 1150.24
 },
 {
  "input": "Likewise, the second column can be thought of as telling us the average area for the second face of the cube, which should of course be the same number.",
  "translatedText": "כמו כן, ניתן לחשוב על העמודה השנייה כמספרת לנו את השטח הממוצע של הפן השני של הקובייה, שאמור להיות כמובן אותו מספר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1152.12,
  "end": 1159.78
 },
 {
  "input": "And same deal for any other column, it's telling us the average area for a particular face.",
  "translatedText": "ואותו עסקה לכל עמוד אחר, הוא אומר לנו את השטח הממוצע לפרצוף מסוים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1160.44,
  "end": 1164.36
 },
 {
  "input": "So that gives us a very different way of thinking about our whole expression.",
  "translatedText": "אז זה נותן לנו דרך שונה מאוד לחשוב על כל הביטוי שלנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1164.98,
  "end": 1168.04
 },
 {
  "input": "Instead of saying add up the areas of the cubes at all the different orientations, we could say just add up the average shadows for the six different faces and divide the total by one half.",
  "translatedText": "במקום לומר הוסף את השטחים של הקוביות בכל הכיוונים השונים, נוכל לומר פשוט הוסף את ממוצע הצללים עבור ששת הפרצופים השונים וחלק את סך הכל בחצי אחד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1168.38,
  "end": 1177.56
 },
 {
  "input": "The term on the left here is thinking about adding up rows first, and the term on the right is thinking about adding up columns first.",
  "translatedText": "המונח משמאל כאן חושב על הוספת שורות תחילה, והמונח מימין חושב על הוספת עמודות תחילה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.04,
  "end": 1183.76
 },
 {
  "input": "In short, the average of the sum of the face shadows is the same as the sum of the average of the face shadows.",
  "translatedText": "בקיצור, הממוצע של סכום צלליות הפנים זהה לסכום הממוצע של צלליות הפנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1184.68,
  "end": 1191.14
 },
 {
  "input": "Maybe that swap seems simple, maybe it doesn't, but I can tell you that there is actually a little bit more than meets the eye to the step that we just took, but we'll get to that later.",
  "translatedText": "אולי ההחלפה הזו נראית פשוטה, אולי היא לא, אבל אני יכול להגיד לך שבעצם יש קצת יותר ממה שנראה לעין לצעד שעשינו זה עתה, אבל נגיע לזה מאוחר יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1192.14,
  "end": 1199.7
 },
 {
  "input": "And remember, we know that the average area for a particular face looks like some universal proportionality constant times the area of that face.",
  "translatedText": "וזכור, אנו יודעים שהשטח הממוצע של פנים מסוימות נראה כמו איזשהו מידתיות אוניברסלית קבועה כפול שטח הפנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.78,
  "end": 1208.22
 },
 {
  "input": "So if we're adding this up across all the faces of the cube, we could think of this as equaling some constant times the surface area of the cube.",
  "translatedText": "אז אם נחבר את זה על פני כל פני הקוביה, נוכל לחשוב על זה כשווה כפולים קבועים משטח הפנים של הקובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1208.8,
  "end": 1215.2
 },
 {
  "input": "And that's pretty interesting.",
  "translatedText": "וזה די מעניין.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.92,
  "end": 1216.76
 },
 {
  "input": "The average area for the shadow of this cube is going to be proportional to its surface area.",
  "translatedText": "השטח הממוצע של הצל של הקובייה הזו יהיה פרופורציונלי לשטח הפנים שלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1216.98,
  "end": 1221.48
 },
 {
  "input": "But at the same time, you might complain, well Alice is just pushing around a bunch of symbols here, because none of this matters if we don't know what that proportionality constant is.",
  "translatedText": "אבל יחד עם זאת, אולי תתלונן, ובכן אליס פשוט דוחפת כאן חבורה של סמלים, כי כל זה לא משנה אם אנחנו לא יודעים מהו קבוע המידתיות הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1222.68,
  "end": 1231.08
 },
 {
  "input": "I mean, it almost seems obvious.",
  "translatedText": "כלומר, זה כמעט נראה מובן מאליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1231.66,
  "end": 1233.38
 },
 {
  "input": "Like, of course the average shadow area should be proportional to the surface area.",
  "translatedText": "כמו, כמובן ששטח הצל הממוצע צריך להיות פרופורציונלי לשטח הפנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.64,
  "end": 1237.62
 },
 {
  "input": "They're both two-dimensional quantities, so they should scale in lockstep with each other.",
  "translatedText": "שניהם כמויות דו-ממדיות, אז הם צריכים להתאים זה לזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.88,
  "end": 1242.26
 },
 {
  "input": "I mean, it's not obvious.",
  "translatedText": "כלומר, זה לא מובן מאליו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1243.08,
  "end": 1244.38
 },
 {
  "input": "After all, for a closer light source, it simply wouldn't be true.",
  "translatedText": "אחרי הכל, עבור מקור אור קרוב יותר, זה פשוט לא יהיה נכון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1244.64,
  "end": 1247.28
 },
 {
  "input": "And also, this business where we added up the grid column by column versus row by row is a little more nuanced than it might look at first.",
  "translatedText": "וגם, העסק הזה שבו הוספנו את הרשת עמודה אחר עמודה לעומת שורה אחר שורה הוא קצת יותר ניואנס ממה שהוא עשוי להיראות בהתחלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.12,
  "end": 1254.7
 },
 {
  "input": "There's a subtle, hidden assumption underlying all of this, which carries a special significance when we choose to revisit the question of what probability distribution is being taken across the space of all orientations.",
  "translatedText": "ישנה הנחה עדינה ונסתרת העומדת בבסיס כל זה, שיש לה משמעות מיוחדת כאשר אנו בוחרים לחזור על השאלה איזו התפלגות הסתברות נלקחת על פני המרחב של כל האוריינטציות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.22,
  "end": 1266.3
 },
 {
  "input": "But more than anything, the reason that it's not obvious is that the significance of this result right here is not merely that these two values are proportional.",
  "translatedText": "אבל יותר מכל, הסיבה שזה לא מובן מאליו היא שהמשמעות של התוצאה הזו כאן היא לא רק ששני הערכים האלה פרופורציונליים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1267.3,
  "end": 1275.36
 },
 {
  "input": "It's that an analogous fact will hold true for any convex solids, and, crucially, the actual content of what Alice has built up so far is that it'll be the same proportionality constant across all of them.",
  "translatedText": "זה שעובדה מקבילה תתקיים לגבי כל מוצק קמור, ובאופן מכריע, התוכן האמיתי של מה שאליס בנתה עד כה הוא שזה יהיה אותו קבוע מידתיות על פני כולם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1276.14,
  "end": 1287.92
 },
 {
  "input": "Now if you really mull over that, some of you may be able to predict the way that Alice is able to finish things off from here.",
  "translatedText": "עכשיו, אם אתה באמת חושב על זה, חלק מכם אולי יוכלו לחזות את הדרך שבה אליס מסוגלת לסיים דברים מכאן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1289.28,
  "end": 1294.18
 },
 {
  "input": "It's really delightful.",
  "translatedText": "זה ממש מענג.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.18,
  "end": 1295.42
 },
 {
  "input": "It's honestly my main reason for covering this topic.",
  "translatedText": "זו באמת הסיבה העיקרית שלי לסקר את הנושא הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1295.6,
  "end": 1297.94
 },
 {
  "input": "But before we get into it, I think it's easy to underappreciate her result unless we dig into the details of what it is that she manages to avoid.",
  "translatedText": "אבל לפני שאנחנו נכנסים לזה, אני חושב שקל לא להעריך את התוצאה שלה, אלא אם כן נחפור בפרטים של מה היא מצליחה להימנע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.24,
  "end": 1306.14
 },
 {
  "input": "So let's take a moment to turn our attention back into Bob's world, because while Alice has been doing all of this, he's been busy doing some computations.",
  "translatedText": "אז בואו ניקח רגע כדי להחזיר את תשומת הלב שלנו לעולמו של בוב, כי בזמן שאליס עשתה את כל זה, הוא היה עסוק בכמה חישובים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1306.86,
  "end": 1314.4
 },
 {
  "input": "In fact, what he's been working on is finding exactly what Alice has yet to figure out, which is how to take the formula that he found for the area of a square's shadow and taking the natural next step of trying to find the average of that square's shadow averaged over all possible orientations.",
  "translatedText": "למעשה, מה שהוא עבד עליו זה למצוא בדיוק את מה שאליס עדיין לא הבינה, כלומר איך לקחת את הנוסחה שהוא מצא עבור שטח הצל של ריבוע ולבצע את הצעד הבא הטבעי של ניסיון למצוא את הממוצע של זה. ממוצע הצל של הריבוע על פני כל הכיוונים האפשריים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1314.98,
  "end": 1329.98
 },
 {
  "input": "So the way Bob starts, if he's thinking about all the different possible orientations for this square, is to ask, what are all the different normal vectors that that square can have in all these orientations, because everything about its shadow comes down to that normal vector.",
  "translatedText": "אז הדרך שבה בוב מתחיל, אם הוא חושב על כל האוריינטציות האפשריות השונות של הריבוע הזה, היא לשאול, מה הם כל הוקטורים הנורמליים השונים שיכולים להיות לריבוע הזה בכל הכיוונים האלה, כי הכל לגבי הצל שלו מגיע לנורמלי הזה וֶקטוֹר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.62,
  "end": 1347.24
 },
 {
  "input": "It's not too hard to see that all those possible normal vectors trace out the surface of a sphere.",
  "translatedText": "זה לא קשה מדי לראות שכל אותם וקטורים נורמליים אפשריים מתחקים אל פני השטח של כדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1347.8,
  "end": 1352.32
 },
 {
  "input": "If we assume it's a unit normal vector, it's a sphere with radius 1.",
  "translatedText": "אם נניח שזה וקטור נורמלי של יחידה, זה כדור עם רדיוס 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.32,
  "end": 1355.56
 },
 {
  "input": "And furthermore, Bob figures that each point of this sphere should be just as likely to occur as any other.",
  "translatedText": "ויתרה מכך, בוב חושב שלכל נקודה בכדור הזה יש סיכוי להתרחש בדיוק כמו כל נקודה אחרת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.42,
  "end": 1361.58
 },
 {
  "input": "Our probabilities should be uniform in that way.",
  "translatedText": "ההסתברויות שלנו צריכות להיות אחידות בצורה כזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.0,
  "end": 1363.98
 },
 {
  "input": "There's no reason to prefer one direction over another.",
  "translatedText": "אין סיבה להעדיף כיוון אחד על פני אחר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1364.02,
  "end": 1366.32
 },
 {
  "input": "But in the context of continuous probabilities, it's not very helpful to talk about the likelihood of a particular individual point, because in the uncountable infinity of points on the sphere, that would be zero and unhelpful.",
  "translatedText": "אבל בהקשר של הסתברויות מתמשכות, זה לא מאוד מועיל לדבר על הסבירות של נקודה בודדת מסוימת, מכיוון שבאינסוף הנקודות הבלתי נספור על הכדור, זה יהיה אפס ולא מועיל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1367.12,
  "end": 1377.44
 },
 {
  "input": "So instead, the more precise way to phrase this uniformity would be to say the probability that our normal vector lands in any given patch of area on the sphere should be proportional to that area itself.",
  "translatedText": "אז במקום זאת, הדרך המדויקת יותר לנסח את האחידות הזו תהיה לומר שההסתברות שהווקטור הרגיל שלנו נוחת בכל חלקה נתונה של שטח על הכדור צריכה להיות פרופורציונלית לאזור עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1377.44,
  "end": 1389.44
 },
 {
  "input": "More specifically, it should equal the area of that little patch divided by the total surface area of the sphere.",
  "translatedText": "ליתר דיוק, זה צריך להיות שווה לשטח של אותו טלאי קטן חלקי שטח הפנים הכולל של הכדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.96,
  "end": 1395.12
 },
 {
  "input": "If that's true, no matter what patch of area we're considering, that's what we mean by a uniform distribution on the sphere.",
  "translatedText": "אם זה נכון, לא משנה איזה חלקת שטח אנחנו שוקלים, לזה אנחנו מתכוונים בפיזור אחיד על הכדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1395.68,
  "end": 1401.06
 },
 {
  "input": "Now to be clear, points on the sphere are not the same thing as orientations in 3D space, because even if you know what normal vector this square is going to have, that leaves us with another degree of freedom.",
  "translatedText": "עכשיו כדי להיות ברור, נקודות על הכדור אינן אותו דבר כמו כיוונים במרחב תלת-ממדי, כי גם אם אתה יודע איזה וקטור נורמלי הולך להיות הריבוע הזה, זה משאיר אותנו עם עוד מידה של חופש.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1402.0,
  "end": 1411.7
 },
 {
  "input": "The square could be rotated about that normal vector.",
  "translatedText": "ניתן היה לסובב את הריבוע סביב אותו וקטור נורמלי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.9,
  "end": 1414.16
 },
 {
  "input": "But Bob doesn't actually have to care about that extra degree of freedom, because in all of those cases, the area of the shadow is the same.",
  "translatedText": "אבל לבוב לא צריך להיות אכפת מהדרגה הנוספת של חופש, כי בכל המקרים האלה, אזור הצל זהה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1414.96,
  "end": 1422.0
 },
 {
  "input": "It's only dependent on the cosine of the angle between that normal vector and the vertical.",
  "translatedText": "זה תלוי רק בקוסינוס של הזווית בין אותו וקטור נורמלי לאנך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.36,
  "end": 1426.46
 },
 {
  "input": "Which is kind of neat.",
  "translatedText": "שזה די מסודר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.18,
  "end": 1427.84
 },
 {
  "input": "All those shadows are genuinely different shapes.",
  "translatedText": "כל הצללים האלה הם באמת צורות שונות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1428.0,
  "end": 1430.06
 },
 {
  "input": "They're not the same.",
  "translatedText": "הם לא אותו דבר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.16,
  "end": 1430.9
 },
 {
  "input": "But the area of each of them will be the same.",
  "translatedText": "אבל השטח של כל אחד מהם יהיה זהה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.2,
  "end": 1433.54
 },
 {
  "input": "What this means is that when Bob wants this average shadow area over all possible orientations, all he really needs to know is the average value of this absolute value of cosine of theta for all different possible normal vectors, all different possible points on the sphere.",
  "translatedText": "המשמעות היא שכאשר בוב רוצה את אזור הצל הממוצע הזה על פני כל הכיוונים האפשריים, כל מה שהוא באמת צריך לדעת הוא הערך הממוצע של הערך המוחלט הזה של הקוסינוס של תטא עבור כל הווקטורים הנורמליים האפשריים השונים, כולם נקודות אפשריות שונות על הכדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1434.72,
  "end": 1448.44
 },
 {
  "input": "So, how do you compute an average like this?",
  "translatedText": "אז איך מחשבים ממוצע כזה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.12,
  "end": 1451.32
 },
 {
  "input": "Well, if we lived in some kind of discrete pixelated world, where there's only a finite number of possible angles theta that that normal vector could have, the average would be pretty straightforward.",
  "translatedText": "ובכן, אם היינו חיים באיזשהו עולם מפוקסל בדיד, שבו יש רק מספר סופי של זוויות אפשריות תטא שיכול להיות לוקטור רגיל, הממוצע היה די פשוט.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.54,
  "end": 1461.44
 },
 {
  "input": "What you do is find the probability of landing on any particular value of theta, which will tell us something like how much of the sphere do normal vectors with that angle make up, and then you multiply it by the thing we want to take the average of, this formula for the area of the shadow.",
  "translatedText": "מה שאתה עושה זה למצוא את ההסתברות לנחיתה על כל ערך מסוים של תטא, מה שיגיד לנו משהו כמו כמה מהכדור מרכיבים וקטורים נורמליים עם הזווית הזו, ואז אתה מכפיל אותו בדבר שאנחנו רוצים לקחת את הממוצע של, נוסחה זו עבור אזור הצל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1461.44,
  "end": 1475.94
 },
 {
  "input": "And then you would add that up over all of the different possible values of theta, ranging from 0 up to 180 degrees, or pi radians.",
  "translatedText": "ואז היית מוסיף את זה על כל הערכים האפשריים השונים של תטא, החל מ-0 עד 180 מעלות, או פאי רדיאנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1476.86,
  "end": 1484.02
 },
 {
  "input": "But of course, in reality, there is a continuum of possible values of theta, this uncountable infinity, and the probability of landing on any specific particular value of theta will actually be 0.",
  "translatedText": "אבל כמובן, במציאות, יש רצף של ערכים אפשריים של תטא, האינסוף הבלתי נספור הזה, וההסתברות לנחיתה על כל ערך מסוים ספציפי של תטא תהיה למעשה 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1485.06,
  "end": 1495.98
 },
 {
  "input": "And so a sum like this unfortunately doesn't really make any sense, or if it does make sense, adding up infinitely many zeros should just give us a 0.",
  "translatedText": "ולכן סכום כזה, למרבה הצער, לא באמת הגיוני, או אם הוא הגיוני, חיבור של אינסוף אפסים אמור לתת לנו 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1496.68,
  "end": 1504.16
 },
 {
  "input": "The short answer for what we do instead is that we compute an integral.",
  "translatedText": "התשובה הקצרה למה שאנחנו עושים במקום היא שאנחנו מחשבים אינטגרל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.8,
  "end": 1508.88
 },
 {
  "input": "And I'll level with you, the hard part here is I'm not entirely sure what background I should be assuming from those of you watching right now.",
  "translatedText": "ואני אשתלב איתך, החלק הקשה כאן הוא שאני לא לגמרי בטוח באיזה רקע אני אמור להניח מאלה מכם שצופים עכשיו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1515.26
 },
 {
  "input": "Maybe it's the case that you're quite comfortable with calculus and you don't need me to belabor the point here.",
  "translatedText": "אולי זה המקרה שאתה די נוח עם חשבון ואתה לא צריך שאני אסביר את הנקודה כאן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1515.64,
  "end": 1519.8
 },
 {
  "input": "Maybe it's the case that you're not familiar with calculus and I shouldn't just be throwing down integrals like that.",
  "translatedText": "אולי זה המקרה שאתה לא מכיר את החשבון ואני לא צריך פשוט לזרוק אינטגרלים ככה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1519.8,
  "end": 1524.78
 },
 {
  "input": "Or maybe you took a calculus class a while ago but you need a little bit of a refresher.",
  "translatedText": "או שאולי למדת שיעור חישוב לפני זמן מה אבל אתה צריך קצת רענון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1524.86,
  "end": 1529.44
 },
 {
  "input": "I'm going to go with the option of setting this up as if it's a calculus lesson, because to be honest, even when you are quite comfortable with integrals, setting them up can be kind of an error-prone process, and calling back to the underlying definition is a good way to sort of check yourself in the process.",
  "translatedText": "אני הולך עם האפשרות להגדיר את זה כאילו זה שיעור חישוב, כי למען האמת, גם כאשר אתה די נוח עם אינטגרלים, הגדרתם יכולה להיות סוג של תהליך מועד לשגיאות, ולהתקשר בחזרה להגדרה הבסיסית היא דרך טובה לבדוק את עצמך בתהליך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1529.82,
  "end": 1543.04
 },
 {
  "input": "If we lived in a time before calculus existed and integrals weren't a thing, and we wanted to approximate an answer to this question, one way we could go about it is to take a sample of values for θ that ranges from 0 up to 180°.",
  "translatedText": "אם חיינו בתקופה שלפני שחישוב היה קיים ואינטגרלים לא היו עניין, ורצינו להעריך תשובה לשאלה זו, דרך אחת שבה נוכל ללכת על זה היא לקחת מדגם של ערכים עבור θ שנעה בין 0 ל- 180°.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1543.78,
  "end": 1556.52
 },
 {
  "input": "We might think of them as evenly spaced with some sort of difference between each one, some delta θ.",
  "translatedText": "אנו עשויים לחשוב עליהם כמרווחים באופן שווה עם איזשהו הבדל בין כל אחד מהם, איזו דלתא θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1557.18,
  "end": 1562.04
 },
 {
  "input": "And it's still the case that it would be unhelpful to ask about the probability of a particular value of θ occurring, even if it's 1 in our sample.",
  "translatedText": "וזה עדיין המצב שלא יעזור לשאול לגבי ההסתברות להתרחשות ערך מסוים של θ, גם אם הוא 1 במדגם שלנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1562.62,
  "end": 1569.24
 },
 {
  "input": "That probability would still be 0 and it would be unhelpful.",
  "translatedText": "ההסתברות הזו עדיין תהיה 0 וזה לא יעזור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1569.66,
  "end": 1572.36
 },
 {
  "input": "But what is helpful to ask is the probability of falling between two different values from our sample, in this little band of latitude with a width of delta θ.",
  "translatedText": "אבל מה שמועיל לשאול הוא ההסתברות ליפול בין שני ערכים שונים מהמדגם שלנו, ברצועת קו הרוחב הקטנה הזו ברוחב דלתא θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1572.36,
  "end": 1582.02
 },
 {
  "input": "Based on our assumption that the distribution along this sphere should be uniform, that probability comes down to knowing the area of this band.",
  "translatedText": "בהתבסס על ההנחה שלנו שההתפלגות לאורך כדור זה צריכה להיות אחידה, הסתברות זו מסתכמת בידיעת השטח של הרצועה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1582.4,
  "end": 1589.56
 },
 {
  "input": "More specifically, the chances that a randomly chosen vector lands in that band should be that area divided by the total surface area of the sphere.",
  "translatedText": "ליתר דיוק, הסיכוי שוקטור שנבחר באקראי ינחת ברצועה זו צריך להיות השטח הזה חלקי שטח הפנים הכולל של הכדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1590.02,
  "end": 1596.72
 },
 {
  "input": "To figure out that area, let's first think of the radius of that band, which, if the radius of our sphere is 1, is definitely going to be smaller than 1.",
  "translatedText": "כדי להבין את השטח הזה, בוא נחשוב תחילה על הרדיוס של הרצועה, שאם הרדיוס של הכדור שלנו הוא 1, הוא בהחלט הולך להיות קטן מ-1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1596.72,
  "end": 1605.28
 },
 {
  "input": "And in fact, if we draw the appropriate little right triangle here, you can see that that little radius, let's just say at the top of the band, should be the sine of our angle, the sine of θ.",
  "translatedText": "ולמעשה, אם נצייר כאן את המשולש הישר-זוויתי הקטן המתאים, אתה יכול לראות שהרדיוס הקטן הזה, נניח בחלק העליון של הרצועה, צריך להיות הסינוס של הזווית שלנו, הסינוס של θ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1605.9,
  "end": 1614.78
 },
 {
  "input": "This means that the circumference of the band should be 2π times the sine of that angle, and then the area of the band should be that circumference times its thickness, that little delta θ.",
  "translatedText": "זה אומר שהיקף הרצועה צריך להיות פי 2π מהסינוס של זווית זו, ואז שטח הרצועה צריך להיות ההיקף הזה כפול העובי שלה, אותה דלתא θ הקטנה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1615.52,
  "end": 1625.52
 },
 {
  "input": "Or rather, the area of our band is approximately this quantity.",
  "translatedText": "או ליתר דיוק, השטח של הלהקה שלנו הוא בערך בכמות הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1625.52,
  "end": 1629.08
 },
 {
  "input": "What's important is that for a finer sample of many more values of θ, the accuracy of that approximation would get better and better.",
  "translatedText": "מה שחשוב הוא שלמדגם עדין יותר של הרבה יותר ערכים של θ, הדיוק של הקירוב הזה ישתפר יותר ויותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1629.54,
  "end": 1636.32
 },
 {
  "input": "Now remember, the reason we wanted this area is to know the probability of falling into that band, which is this area divided by the surface area of the sphere, which we know to be 4π times its radius squared.",
  "translatedText": "עכשיו זכור, הסיבה שרצינו את השטח הזה היא לדעת את ההסתברות ליפול לתוך הרצועה הזו, שהיא השטח הזה חלקי שטח הפנים של הכדור, שאנחנו יודעים שהוא פי 4π מהרדיוס שלו בריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1637.54,
  "end": 1648.08
 },
 {
  "input": "That's a value that you could also compute with an integral similar to the one that we're setting up now, but for now we can take it as a given, as a standard well-known formula.",
  "translatedText": "זה ערך שאפשר לחשב גם עם אינטגרל דומה לזה שאנחנו מגדירים עכשיו, אבל לעת עתה אנחנו יכולים לקחת אותו כנתון, כנוסחה סטנדרטית ידועה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.66,
  "end": 1656.08
 },
 {
  "input": "And this probability itself is just a stepping stone in the direction of what we actually want, which is the average area for the shadow of a square.",
  "translatedText": "וההסתברות הזו כשלעצמה היא רק קפיצה לכיוון מה שאנחנו בעצם רוצים, שהוא השטח הממוצע לצל של ריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1656.84,
  "end": 1663.32
 },
 {
  "input": "To get that, we'll multiply this probability times the corresponding shadow area, which is this absolute value of cosθ expression we've seen many times up to this point.",
  "translatedText": "כדי לקבל זאת, נכפיל את ההסתברות הזו כפול שטח הצל המתאים, שהוא הערך המוחלט הזה של ביטוי cosθ שראינו פעמים רבות עד לנקודה זו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.24,
  "end": 1673.02
 },
 {
  "input": "And our estimate for this average would now come down to adding up this expression across all of the different bands, all of the different samples of θ that we've taken.",
  "translatedText": "וההערכה שלנו לממוצע הזה תסתכם כעת בחיבור הביטוי הזה על פני כל הרצועות השונות, כל הדגימות השונות של θ שלקחנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1673.5,
  "end": 1681.7
 },
 {
  "input": "This right here, by the way, is when Bob is just totally in his element.",
  "translatedText": "זה כאן, דרך אגב, כאשר בוב פשוט לגמרי באלמנט שלו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1683.44,
  "end": 1686.36
 },
 {
  "input": "We've got a lot of exact formulas describing something very concrete, actually digging in on our way to a real answer.",
  "translatedText": "יש לנו הרבה נוסחאות מדויקות שמתארות משהו מאוד קונקרטי, בעצם מתעמקות בדרכנו לתשובה אמיתית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1686.58,
  "end": 1691.86
 },
 {
  "input": "And again, if it feels like a lot of detail, I want you to appreciate that fact, so that you can appreciate just how magical it is when Alice manages to somehow avoid all of this.",
  "translatedText": "ושוב, אם זה מרגיש כמו הרבה פרטים, אני רוצה שתעריכו את העובדה הזו, כדי שתוכלו להעריך עד כמה זה קסום כשאליס מצליחה איכשהו להימנע מכל זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.52,
  "end": 1701.92
 },
 {
  "input": "Anyway, looking back at our expression, let's clean things up a little bit, like factoring out all of the terms that don't depend on θ itself.",
  "translatedText": "בכל מקרה, במבט לאחור על הביטוי שלנו, בוא ננקה קצת את הדברים, כמו למנות את כל המונחים שאינם תלויים ב-θ עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.88,
  "end": 1709.0
 },
 {
  "input": "And we can simplify that 2π divided by 4π to simply be 1 half.",
  "translatedText": "ואנחנו יכולים לפשט את זה ש-2π חלקי 4π פשוט יהיה 1 חצי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1709.72,
  "end": 1713.48
 },
 {
  "input": "And to make it a little more analogous to calculus, with integrals, let me just swap the main terms inside the sum here.",
  "translatedText": "וכדי לעשות את זה קצת יותר אנלוגי לחישוב, עם אינטגרלים, הרשו לי פשוט להחליף כאן את המונחים העיקריים בתוך הסכום.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.54,
  "end": 1719.46
 },
 {
  "input": "What we now have, this sum that's going to approximate the answer to our question, is almost what an integral is.",
  "translatedText": "מה שיש לנו עכשיו, הסכום הזה שעתיד להעריך את התשובה לשאלה שלנו, הוא כמעט מה זה אינטגרל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1719.96,
  "end": 1726.04
 },
 {
  "input": "Instead of writing the sigma for sum, we write the integral symbol, this kind of elongated Leibnizian s, showing us that we're going from 0 to π.",
  "translatedText": "במקום לכתוב את הסיגמה עבור סכום, אנו כותבים את הסמל האינטגרלי, סוג זה של s מוארך של לייבניציאן, שמראה לנו שאנו עוברים מ-0 ל-π.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1726.48,
  "end": 1733.98
 },
 {
  "input": "And instead of describing the step size as δθ, a concrete finite amount, we instead describe it as dθ, which I like to think of as signaling the fact that some kind of limit is being taken.",
  "translatedText": "ובמקום לתאר את גודל הצעד כ-δθ, כמות סופית קונקרטית, במקום זאת אנו מתארים אותו כ-dθ, שאני אוהב לחשוב עליו כאותת לעובדה שננקטת איזושהי מגבלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1734.72,
  "end": 1745.16
 },
 {
  "input": "What that integral means, by definition, is whatever the sum on the bottom approaches for finer and finer subdivisions, more dense samples that we might take for θ itself.",
  "translatedText": "המשמעות של האינטגרל הזה, בהגדרה, היא מה שהסכום בתחתית מתקרב לחלוקות משנה עדינות יותר ויותר, דגימות צפופות יותר שנוכל לקחת עבור θ עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1746.08,
  "end": 1757.1
 },
 {
  "input": "And at this point, for those of you who do know calculus, I'll just write down the details of how you would actually carry this out, as you might see it written down in Bob's notebook.",
  "translatedText": "ובשלב זה, לאלו מכם שכן יודעים חשבון, אני רק ארשום את הפרטים של איך הייתם מבצעים זאת בפועל, כפי שאולי תראו את זה כתוב במחברת של בוב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1759.04,
  "end": 1766.62
 },
 {
  "input": "It's the usual anti-derivative stuff, but the one key step is to bring in a certain trig identity.",
  "translatedText": "זה החומר האנטי-נגזר הרגיל, אבל הצעד המרכזי היחיד הוא להביא זהות טריגית מסוימת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1767.16,
  "end": 1772.16
 },
 {
  "input": "In the end, what Bob finds after doing this is the surprisingly clean fact that the average area for a square's shadow is precisely one half the area of that square.",
  "translatedText": "בסופו של דבר, מה שבוב מגלה לאחר שעשה זאת היא העובדה המפתיעה הנקייה שהשטח הממוצע לצל של ריבוע הוא בדיוק חצי מהשטח של הריבוע הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1773.06,
  "end": 1783.52
 },
 {
  "input": "This is the mystery constant, which Alice doesn't yet know.",
  "translatedText": "זהו קבוע המסתורין, שאליס עדיין לא יודעת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1784.58,
  "end": 1787.56
 },
 {
  "input": "If Bob were to look over her shoulder and see the work that she's done, he could finish out the problem right now.",
  "translatedText": "אם בוב היה מסתכל מעבר לכתפה ורואה את העבודה שהיא עשתה, הוא יכול לסיים את הבעיה כבר עכשיו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1788.12,
  "end": 1792.78
 },
 {
  "input": "He plugs in the constant that he just found, and he knows the final answer.",
  "translatedText": "הוא מחבר את הקבוע שהוא זה עתה מצא, והוא יודע את התשובה הסופית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1793.0,
  "end": 1796.16
 },
 {
  "input": "And now, finally, with all of this as backdrop, what is it that Alice does to carry out the final solution?",
  "translatedText": "ועכשיו, סוף סוף, עם כל זה כרקע, מה זה שאליס עושה כדי לבצע את הפתרון הסופי?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1800.22,
  "end": 1806.2
 },
 {
  "input": "I introduced her as someone who really likes to generalize the results she finds.",
  "translatedText": "הצגתי אותה כמי שמאוד אוהבת להכליל את התוצאות שהיא מוצאת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.86,
  "end": 1810.26
 },
 {
  "input": "And usually those generalizations end up as interesting footnotes that aren't really material for solving particular problems.",
  "translatedText": "ובדרך כלל ההכללות הללו מסתיימות כהערות שוליים מעניינות שאינן באמת מהותיות לפתרון בעיות מסוימות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.84,
  "end": 1816.68
 },
 {
  "input": "But this is a case where the generalization itself draws her to a quantitative result.",
  "translatedText": "אבל זה מקרה שבו ההכללה עצמה מושכת אותה לתוצאה כמותית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1817.18,
  "end": 1821.76
 },
 {
  "input": "Remember, the substance of what she's found so far is that if you look at any convex solid, then the average area for its shadow is going to be proportional to its surface area, and critically, it'll be the same proportionality constant across all of these solids.",
  "translatedText": "זכור, המהות של מה שהיא מצאה עד כה הוא שאם אתה מסתכל על מוצק קמור כלשהו, אז השטח הממוצע של הצל שלו יהיה פרופורציונלי לשטח הפנים שלו, ובאופן קריטי, זה יהיה אותו קבוע מידתיות בכל מהמוצקים הללו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1821.76,
  "end": 1836.5
 },
 {
  "input": "So all Alice needs to do is find just a single convex solid out there where she already knows the average area of its shadow.",
  "translatedText": "אז כל מה שאליס צריכה לעשות הוא למצוא רק מוצק קמור בודד שם בחוץ שבו היא כבר יודעת את השטח הממוצע של הצל שלו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1837.1,
  "end": 1844.46
 },
 {
  "input": "And some of you may see where this is going.",
  "translatedText": "וחלקכם אולי יראו לאן זה הולך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1845.16,
  "end": 1846.84
 },
 {
  "input": "The most symmetric solid available to us is a sphere.",
  "translatedText": "המוצק הכי סימטרי שזמין לנו הוא כדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1846.84,
  "end": 1850.06
 },
 {
  "input": "No matter what the orientation of that sphere, its shadow, the flat projection shadow, is always a circle with an area of πr².",
  "translatedText": "לא משנה מה הכיוון של אותו כדור, הצל שלו, צל ההקרנה השטוח, הוא תמיד עיגול עם שטח של πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1850.52,
  "end": 1858.02
 },
 {
  "input": "So in particular, that's its average shadow area.",
  "translatedText": "אז במיוחד, זה אזור הצל הממוצע שלו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1858.62,
  "end": 1861.04
 },
 {
  "input": "And the surface area of a sphere, like I mentioned before, is exactly 4πr².",
  "translatedText": "ושטח הפנים של כדור, כמו שציינתי קודם, הוא בדיוק 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1861.78,
  "end": 1866.32
 },
 {
  "input": "By the way, I did make a video talking all about that surface area formula and how Archimedes proved it thousands of years before calculus existed, so you don't need integrals to find it.",
  "translatedText": "אגב, עשיתי סרטון שמדבר הכל על נוסחת שטח הפנים הזו וכיצד ארכימדס הוכיח אותה אלפי שנים לפני שחישוב קיים, כך שלא צריך אינטגרלים כדי למצוא אותה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1867.1,
  "end": 1876.34
 },
 {
  "input": "The magic of what Alice has done is that she can take this seemingly specific fact, that the shadow of a sphere has an area exactly 1⁄4 its surface area, and use it to conclude a much more general fact, that for any convex solid out there, its shadow and surface area are related in the same way, in a certain sense.",
  "translatedText": "הקסם של מה שאליס עשתה הוא שהיא יכולה לקחת את העובדה הספציפית לכאורה הזו, שלצל של כדור יש שטח בדיוק של 1⁄4 שטח הפנים שלו, ולהשתמש בו כדי להסיק עובדה הרבה יותר כללית, שלכל מוצק קמור שם בחוץ, הצל ושטח הפנים שלו קשורים באותו אופן, במובן מסוים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1876.34,
  "end": 1893.58
 },
 {
  "input": "So with that, she can go and fill in the details of the particular question about a cube, and say that its average shadow area will be 1⁄4 times its surface area, 6s².",
  "translatedText": "אז עם זה, היא יכולה ללכת ולמלא את הפרטים של השאלה המסוימת על קובייה, ולומר ששטח הצל הממוצע שלה יהיה פי 1⁄4 משטח הפנים שלה, 6s².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1894.64,
  "end": 1903.62
 },
 {
  "input": "But the much more memorable fact that you'll go to sleep thinking about is how it didn't really matter that we were talking about a cube at all.",
  "translatedText": "אבל העובדה הרבה יותר בלתי נשכחת שאתה הולך לישון במחשבה היא איך זה לא ממש משנה שדיברנו על קובייה בכלל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1903.62,
  "end": 1910.8
 },
 {
  "input": "Now, that's all very pretty, but some of you might complain that this isn't really a valid argument, because spheres don't have flat faces.",
  "translatedText": "עכשיו, הכל מאוד יפה, אבל חלק מכם עלולים להתלונן שזה לא באמת טיעון תקף, כי לספירות אין פנים שטוחות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1912.52,
  "end": 1919.38
 },
 {
  "input": "When I said Alice's argument generalizes to any convex solid, if we actually look at the argument itself, it definitely depends on the use of a finite number of flat faces.",
  "translatedText": "כשאמרתי שהטיעון של אליס מכליל לכל מוצק קמור, אם אנחנו באמת מסתכלים על הטיעון עצמו, זה בהחלט תלוי בשימוש במספר סופי של פרצופים שטוחים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1920.1,
  "end": 1928.94
 },
 {
  "input": "For example, if we were mapping it to a dodecahedron, you would start by saying that the area of a particular shadow of that dodecahedron looks like exactly 1⁄2 times the sum of the areas of the shadows of all its faces.",
  "translatedText": "לדוגמה, אם היינו ממפים אותו לדודקהדרון, היית מתחיל בכך שהשטח של צל מסוים של אותו דודקהדרון נראה בדיוק פי 1⁄2 מסכום שטחי הצללים של כל פניו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1928.94,
  "end": 1940.44
 },
 {
  "input": "Once again, you could use a certain ray of light mixed with convexity argument to draw that conclusion.",
  "translatedText": "שוב, אתה יכול להשתמש בקרן אור מסוימת מעורבת בטיעון קמור כדי להסיק את המסקנה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1941.0,
  "end": 1945.44
 },
 {
  "input": "And remember, the benefit of expressing that shadow area as a sum is that when we want to average over a bunch of different rotations, we can describe that sum as a big grid, where we can then go column by column and consider the average area for the shadow of each face.",
  "translatedText": "וזכור, היתרון בביטוי של שטח הצל כסכום הוא שכאשר אנו רוצים לעשות ממוצע על פני חבורה של סיבובים שונים, אנו יכולים לתאר את הסכום הזה כרשת גדולה, שבה נוכל לעבור עמודה אחר עמודה ולהתייחס לשטח הממוצע. עבור הצל של כל פנים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1946.28,
  "end": 1960.82
 },
 {
  "input": "And also, a critical fact was the conclusion from much earlier, that the average shadow for any 2D object, a flat 2D object, which is important, will equal some universal proportionality constant times its area.",
  "translatedText": "וגם, עובדה קריטית הייתה המסקנה הרבה קודם לכן, שהצל הממוצע לכל אובייקט דו-ממדי, אובייקט דו-ממדי שטוח, וזה חשוב, ישתווה לאיזשהו קבוע מידתיות אוניברסלי כפול שטחו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1961.46,
  "end": 1972.72
 },
 {
  "input": "The significance was that that constant didn't depend on the shape itself.",
  "translatedText": "המשמעות הייתה שהקבוע הזה לא היה תלוי בצורה עצמה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1973.26,
  "end": 1976.12
 },
 {
  "input": "It could have been a square, or a cat, or the pentagonal faces of our dodecahedron, whatever.",
  "translatedText": "זה יכול היה להיות ריבוע, או חתול, או הפנים המחומשות של הדודקהדרון שלנו, מה שלא יהיה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1976.22,
  "end": 1980.84
 },
 {
  "input": "So, after hastily carrying this over to a sphere that doesn't have a finite number of flat faces, you would be right to complain.",
  "translatedText": "לכן, לאחר שהעברת זאת בחופזה לכדור שאין לו מספר סופי של פרצופים שטוחים, תצטרכי להתלונן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1980.84,
  "end": 1988.26
 },
 {
  "input": "But luckily, it's a pretty easy detail to fill in.",
  "translatedText": "אבל למרבה המזל, זה פרט די קל למילוי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1988.9,
  "end": 1991.24
 },
 {
  "input": "What you can do is imagine a sequence of different polyhedra that successively approximate a sphere, in the sense that their faces hug tighter and tighter around the genuine surface of the sphere.",
  "translatedText": "מה שאתה יכול לעשות הוא לדמיין רצף של פולי-הדרות שונות שמתקרבות ברציפות לכדור, במובן זה שהפנים שלהן מתחבקות חזק יותר ויותר סביב פני השטח האמיתיים של הכדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1991.64,
  "end": 2001.16
 },
 {
  "input": "For each one of those approximations, we can draw the same conclusion, that its average shadow is going to be proportional to its surface area with this universal proportionality constant.",
  "translatedText": "עבור כל אחת מהקירובים הללו, אנו יכולים להסיק את אותה מסקנה, שהצל הממוצע שלו יהיה פרופורציונלי לשטח הפנים שלו עם קבוע מידתיות אוניברסלי זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2001.68,
  "end": 2010.78
 },
 {
  "input": "So then, if we say, okay, let's take the limit of the ratio between the average shadow area at each step and the surface area at each step, well, since that ratio is never changing, it's always equal to this constant, then in the limit, it's also going to equal that constant.",
  "translatedText": "אז אם נגיד, בסדר, בואו ניקח את הגבול של היחס בין שטח הצל הממוצע בכל צעד ושטח הפנים בכל צעד, ובכן, מכיוון שהיחס הזה לעולם לא משתנה, הוא תמיד שווה לקבוע הזה, אז ב הגבול, הוא גם ישתווה לקבוע הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2011.2,
  "end": 2024.62
 },
 {
  "input": "But on the other hand, by their definition, in the limit, their average shadow area should be that of a circle, which is πr², and the limit of the surface areas would be the surface area of the sphere, 4πr².",
  "translatedText": "אבל מצד שני, לפי הגדרתם, בגבול, שטח הצל הממוצע שלהם צריך להיות של מעגל, שהוא πr², והגבול של שטחי הפנים יהיה שטח הפנים של הכדור, 4πr².",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2024.62,
  "end": 2036.98
 },
 {
  "input": "So we do genuinely get the conclusion that intuition would suggest, but, as is so common with Alice's argument here, we do have to be a little delicate in how we justify that intuition.",
  "translatedText": "אז אנחנו באמת מבינים את המסקנה שהאינטואיציה תציע, אבל, כפי שמקובל כל כך בטיעון של אליס כאן, אנחנו צריכים להיות קצת עדינים איך אנחנו מצדיקים את האינטואיציה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2037.66,
  "end": 2047.0
 },
 {
  "input": "It's easy for this contrast of Alice and Bob to come across like a value judgment, as if I'm saying, look how clever Alice has managed to be, she insightfully avoided all those computations that Bob had to do.",
  "translatedText": "קל לניגוד הזה של אליס ובוב להיראות כמו שיפוט ערכי, כאילו אני אומר, תראה כמה אליס הצליחה להיות חכמה, היא נמנעה בתובנה מכל החישובים האלה שבוב היה צריך לעשות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2052.2,
  "end": 2063.56
 },
 {
  "input": "But that would be a very, um, misguided conclusion.",
  "translatedText": "אבל זו תהיה מסקנה מאוד מוטעית.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2063.88,
  "end": 2067.9
 },
 {
  "input": "I think there's an important way that popularizations of math differ from the feeling of actually doing math.",
  "translatedText": "אני חושב שיש דרך חשובה שהפופולריזציה של מתמטיקה שונה מהתחושה של לעשות מתמטיקה בפועל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2068.56,
  "end": 2074.08
 },
 {
  "input": "There's this bias towards showing the slick proofs, the arguments with some clever keen insight that lets you avoid doing calculations.",
  "translatedText": "יש הטיה זו כלפי הצגת ההוכחות החלקלקות, הטיעונים עם איזו תובנה חדה חכמה המאפשרת לך להימנע מביצוע חישובים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2074.08,
  "end": 2080.78
 },
 {
  "input": "I could just be projecting, since I'm very guilty of this, but what I can tell you, sitting on the other side of the screen here, is that it feels a lot more attractive to make a video about Alice's approach than Bob's.",
  "translatedText": "יכול להיות שאני סתם מקרין, כי אני מאוד אשם בזה, אבל מה שאני יכול להגיד לך, כשאני יושב בצד השני של המסך כאן, זה שזה מרגיש הרבה יותר אטרקטיבי לעשות סרטון על הגישה של אליס מאשר של בוב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2081.24,
  "end": 2092.3
 },
 {
  "input": "For one thing, in Alice's approach, the line of reasoning is fun, it has these nice aha moments.",
  "translatedText": "דבר אחד, בגישה של אליס, קו ההיגיון הוא כיף, יש בו את רגעי האהא הנחמדים האלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2092.46,
  "end": 2097.12
 },
 {
  "input": "But also, crucially, the way that you explain it is more or less the same for a very wide range of mathematical backgrounds.",
  "translatedText": "אבל גם, באופן מכריע, הדרך שבה אתה מסביר את זה זהה פחות או יותר עבור מגוון רחב מאוד של רקעים מתמטיים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2097.12,
  "end": 2103.9
 },
 {
  "input": "It's much less enticing to do a video about Bob's approach, not because the computations are all that bad, I mean, they're honestly not, but the pragmatic reality is that the appropriate pace to explain it looks very different depending on the different mathematical backgrounds in the audience.",
  "translatedText": "זה הרבה פחות מפתה לעשות סרטון על הגישה של בוב, לא בגלל שהחישובים כל כך גרועים, כלומר, הם באמת לא, אבל המציאות הפרגמטית היא שהקצב המתאים להסביר את זה נראה שונה מאוד בהתאם למתמטיקה השונה. רקע בקהל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2104.64,
  "end": 2118.86
 },
 {
  "input": "So, you, watching this right now, clearly consume math videos online, and I think in doing so it's worth being aware of this bias.",
  "translatedText": "אז אתה, צופה בזה עכשיו, צורכת בבירור סרטוני מתמטיקה באינטרנט, ואני חושב שבכך כדאי להיות מודעים להטיה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2119.82,
  "end": 2126.62
 },
 {
  "input": "If the aim is to have a genuine lesson on problem solving, too much focus on the slick proofs runs the risk of being disingenuous.",
  "translatedText": "אם המטרה היא לקבל שיעור אמיתי על פתרון בעיות, התמקדות רבה מדי בהוכחות החלקלקות עלולה להיות לא הגונה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2126.62,
  "end": 2134.52
 },
 {
  "input": "For example, let's say we were to step up to challenge mode here and ask about the case with a closer light source.",
  "translatedText": "לדוגמה, נניח שהיינו עולים למצב אתגר כאן ונשאל על המקרה עם מקור אור קרוב יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2135.84,
  "end": 2141.02
 },
 {
  "input": "To my knowledge, there is not a similarly slick solution to Alice's here, where you can just relate to a single shape like a sphere.",
  "translatedText": "למיטב ידיעתי, אין כאן פתרון חלקלק דומה לזה של אליס, שבו אתה יכול פשוט להתייחס לצורה בודדת כמו כדור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2141.7,
  "end": 2148.16
 },
 {
  "input": "The much more productive warmup to have done would have been the calculus of Bob's approach.",
  "translatedText": "החימום הרבה יותר פרודוקטיבי שהיה צריך לעשות היה החשבון של הגישה של בוב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2148.86,
  "end": 2153.3
 },
 {
  "input": "And if you look at the history of this problem, it was proved by Cauchy in 1832, and if we paw through his handwritten notes, they look a lot more similar to Bob's work than Alice's work.",
  "translatedText": "ואם מסתכלים על ההיסטוריה של הבעיה הזו, היא הוכחה על ידי קאוצ'י בשנת 1832, ואם נעבור על ההערות שלו בכתב ידו, הן נראות הרבה יותר דומות לעבודתו של בוב מאשר לעבודתה של אליס.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2153.88,
  "end": 2164.48
 },
 {
  "input": "Right here at the top of page 11, you can see what is essentially the same integral that you and I set up in the middle.",
  "translatedText": "ממש כאן בראש עמוד 11, אתה יכול לראות מהו בעצם אותו אינטגרל שאתה ואני הגדרנו באמצע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2164.9,
  "end": 2170.4
 },
 {
  "input": "On the other hand, the whole framing of the paper is to find a general fact, not something specific like the case of a cube.",
  "translatedText": "מצד שני, כל המסגור של הנייר הוא למצוא עובדה כללית, לא משהו ספציפי כמו מקרה של קובייה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2171.3,
  "end": 2177.24
 },
 {
  "input": "So if we were asking the question which of these two mindsets correlates with the act of discovering new math, the right answer would almost certainly have to be a blend of both.",
  "translatedText": "אז אם היינו שואלים את השאלה איזה משני הלכי החשיבה הללו מתאם עם פעולת גילוי מתמטיקה חדשה, התשובה הנכונה הייתה כמעט בוודאות צריכה להיות שילוב של שניהם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2177.24,
  "end": 2186.4
 },
 {
  "input": "But I would suggest that many people don't sign enough weight to the part of that blend where you're eager to dive into calculations.",
  "translatedText": "אבל הייתי מציע שאנשים רבים לא יתנו משקל מספיק לחלק של התערובת שבה אתה להוט לצלול לחישובים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2187.22,
  "end": 2194.18
 },
 {
  "input": "And I think there's some risk that the videos I make might contribute to that.",
  "translatedText": "ואני חושב שיש סיכון מסוים שהסרטונים שאני מכין עשויים לתרום לכך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2194.72,
  "end": 2198.16
 },
 {
  "input": "In the podcast I did with the mathematician Alex Kontorovich, he talked about the often underappreciated importance of just drilling on computations to build intuition, whether you're a student engaging with a new class, or a practicing research mathematician engaging with a new field of study.",
  "translatedText": "בפודקאסט שעשיתי עם המתמטיקאי אלכס קונטורוביץ', הוא דיבר על החשיבות הבלתי מוערכת לעתים קרובות של רק לקדוח על חישובים כדי לבנות אינטואיציה, בין אם אתה סטודנט שעוסק בכיתה חדשה, או מתמטיקאי מחקר מתאמן העוסק בתחום חדש של לימוד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2198.96,
  "end": 2214.32
 },
 {
  "input": "A listener actually wrote in to highlight what an impression that particular section made.",
  "translatedText": "מאזין באמת כתב כדי להדגיש איזה רושם עשה הקטע המסוים הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2214.8,
  "end": 2219.04
 },
 {
  "input": "They're a PhD student and describe themselves as being worried that their mathematical abilities were starting to fade, which they attributed to becoming older and less sharp.",
  "translatedText": "הם סטודנטים לדוקטורט ומתארים את עצמם כחוששים שהיכולות המתמטיות שלהם מתחילות לדעוך, מה שהם ייחסו להיות מבוגרים ופחות חדים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2219.18,
  "end": 2227.64
 },
 {
  "input": "But hearing a practicing mathematician talk about the importance of doing hundreds of concrete examples in order to learn something new, evidently that changed their perspective.",
  "translatedText": "אבל לשמוע מתמטיקאי פעיל מדבר על החשיבות של לעשות מאות דוגמאות קונקרטיות כדי ללמוד משהו חדש, כנראה ששינה את נקודת המבט שלהם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2227.64,
  "end": 2236.32
 },
 {
  "input": "In their own words, recognizing this completely reshaped their outlook and their results.",
  "translatedText": "במילים שלהם, ההכרה בכך עיצבה מחדש לחלוטין את השקפתם ואת התוצאות שלהם.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2236.9,
  "end": 2241.16
 },
 {
  "input": "And if you look at the famous mathematicians through history, Newton, Euler, Gauss, all of them, they all have this seemingly infinite patience for doing tedious calculations.",
  "translatedText": "ואם מסתכלים על המתמטיקאים המפורסמים דרך ההיסטוריה, ניוטון, אוילר, גאוס, כולם, לכולם יש את הסבלנות האינסופית לכאורה לעשות חישובים מייגעים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2242.02,
  "end": 2250.58
 },
 {
  "input": "The irony of being biased to show insights that let us avoid calculations is that the way people often train up the intuitions to find those insights in the first place is by doing piles and piles of calculations.",
  "translatedText": "האירוניה בלהיות מוטים להראות תובנות שמאפשרות לנו להימנע מחישובים היא שהדרך שבה אנשים מאמנים לעתים קרובות את האינטואיציות כדי למצוא את התובנות הללו מלכתחילה היא על ידי ערימות על ערימות של חישובים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2250.58,
  "end": 2262.72
 },
 {
  "input": "All that said, something would definitely be missing without the Alice mindset here.",
  "translatedText": "כל זה אמר, משהו בהחלט היה חסר בלי הלך הרוח של אליס כאן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2264.72,
  "end": 2269.42
 },
 {
  "input": "I mean, think about it, how sad would it be if we solved this problem for a cube, and we never stepped outside of the trees to see the forest and understand that this is a super general fact, it applies to a huge family of shapes.",
  "translatedText": "כלומר, תחשוב על זה, כמה עצוב זה יהיה אם נפתור את הבעיה הזו עבור קובייה, ומעולם לא יצאנו מחוץ לעצים כדי לראות את היער ולהבין שזו עובדה סופר כללית, היא חלה על משפחה ענקית של צורות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2269.98,
  "end": 2280.32
 },
 {
  "input": "And if you consider that math is not just about answering the questions that are posed to you, but about introducing new ideas and constructs, one fun side note about Alice's approach here is that it suggests a fun way to quantify the idea of convexity.",
  "translatedText": "ואם אתה מחשיב שמתמטיקה היא לא רק לענות על השאלות שמוצגות לך, אלא על הצגת רעיונות ומבנים חדשים, הערת צד מהנה אחת לגבי הגישה של אליס כאן היא שהיא מציעה דרך מהנה לכמת את רעיון הקמור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2281.14,
  "end": 2294.82
 },
 {
  "input": "Rather than just having a yes-no answer, is it convex, is it not, we could put a number to it by saying, consider the average area of the shadow of some solid, multiply that by 4, divide it by the surface area, and if that number is 1, you've got a convex solid, but if it's less than 1, it's non-convex, and how close it is to 1 tells you how close it is to being convex.",
  "translatedText": "במקום רק לקבל תשובה של כן-לא, האם היא קמורה, נכון, נוכל לשים לזה מספר על ידי אמירה, שקול את השטח הממוצע של הצל של מוצק כלשהו, הכפל את זה ב-4, חלק אותו בשטח הפנים , ואם המספר הזה הוא 1, יש לך מוצק קמור, אבל אם הוא קטן מ-1, הוא לא קמור, וכמה הוא קרוב ל-1 אומר לך כמה הוא קרוב להיות קמור.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2295.36,
  "end": 2316.46
 },
 {
  "input": "Also, one of the nice things about the Alice solution here is that it helps explain why it is that mathematicians have what can sometimes look like a bizarre infatuation with generality and with abstraction.",
  "translatedText": "כמו כן, אחד הדברים היפים בפתרון של אליס כאן הוא שהוא עוזר להסביר מדוע למתמטיקאים יש מה שלפעמים יכול להיראות כמו התאהבות מוזרה בכלליות ובהפשטה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2317.1,
  "end": 2328.36
 },
 {
  "input": "The more examples that you see where generalizing and abstracting actually helps you to solve a specific case, the more you start to adopt the same infatuation.",
  "translatedText": "ככל שתראה יותר דוגמאות שבהן הכללה והפשטה בעצם עוזרות לך לפתור מקרה ספציפי, כך אתה מתחיל לאמץ את אותה התאהבות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2328.36,
  "end": 2337.36
 },
 {
  "input": "And as a final thought for the stalwart viewers among you who have stuck through it this far, there is still one unanswered question about the very premise of our puzzle.",
  "translatedText": "וכמחשבה אחרונה לצופים האיתנים שביניכם שעברו את זה עד כאן, יש עדיין שאלה אחת ללא תשובה לגבי עצם הנחת היסוד של הפאזל שלנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2339.24,
  "end": 2347.0
 },
 {
  "input": "What exactly does it mean to choose a random orientation?",
  "translatedText": "מה זה בדיוק אומר לבחור כיוון אקראי?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2347.76,
  "end": 2350.94
 },
 {
  "input": "Now if that feels like a silly question, like of course we know what it should mean, I would encourage you to watch a video that I just did with Numberphile on a conundrum from probability known as Bertrand's paradox.",
  "translatedText": "עכשיו, אם זו מרגישה כמו שאלה מטופשת, כמו כמובן שאנחנו יודעים מה זה צריך להיות אומר, אני ממליץ לך לצפות בסרטון שעשיתי זה עתה עם Numberphile על חידה מהסתברות המכונה הפרדוקס של ברטרנד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2350.94,
  "end": 2360.78
 },
 {
  "input": "After you watch it, and if you appreciate some of the nuance at play here, homework for you is to reflect on where exactly Alice and Bob implicitly answer to this question.",
  "translatedText": "אחרי שתצפו בו, ואם אתם מעריכים חלק מהניואנסים שמשחקים כאן, שיעורי הבית עבורכם הם לחשוב היכן בדיוק אליס ובוב עונים באופן מרומז לשאלה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2361.58,
  "end": 2370.42
 },
 {
  "input": "The case with Bob is relatively straightforward, but the point at which Alice locks down some specific distribution on the space of all orientations, well it's not at all obvious, it's actually very subtle.",
  "translatedText": "המקרה עם בוב הוא יחסית פשוט, אבל הנקודה שבה אליס נועלת איזו הפצה ספציפית על המרחב של כל האוריינטציות, ובכן, זה בכלל לא ברור, זה למעשה עדין מאוד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2370.42,
  "end": 2381.7
 }
]