[
 {
  "input": "You may have heard the phrase, the unreasonable effectiveness of mathematics in the natural sciences.",
  "translatedText": "자연과학에서 수학의 불합리한 효율성이라는 말을 들어보셨을 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.38
 },
 {
  "input": "This was the title of a paper by the physicist Eugene Wigner, but even more fun than the title is the way that he chooses to open it.",
  "translatedText": "물리학자 유진 위그너(Eugene Wigner)의 논문 제목이었는데, 제목보다 더 재미있는 것은 그가 논문을 펼치는 방식을 택했다는 점이다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.08,
  "end": 11.5
 },
 {
  "input": "The paper begins, quote, There is a story about two friends who were classmates in high school, talking about their jobs.",
  "translatedText": "신문은 다음과 같이 시작합니다. 고등학교 동창이었던 두 친구가 자신의 직업에 대해 이야기하는 이야기입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.64,
  "end": 18.06
 },
 {
  "input": "One of them became a statistician and was working on population trends.",
  "translatedText": "그 중 한 명은 통계학자가 되어 인구 동향을 연구하고 있었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.62,
  "end": 21.66
 },
 {
  "input": "They showed a reprint to their former classmate, and the reprint started, as usual, with the Gaussian distribution.",
  "translatedText": "그들은 이전 동급생에게 재판본을 보여 주었고 재판은 평소와 같이 가우스 분포로 시작되었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.06,
  "end": 26.98
 },
 {
  "input": "The statistician explained to the former classmate the meaning of the symbols for the actual population, the average population, and so on.",
  "translatedText": "통계학자는 같은 반 친구에게 실제인구, 평균인구 등 기호의 의미를 설명했다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.7
 },
 {
  "input": "The classmate was a bit incredulous and was not quite sure whether the statistician was pulling their leg.",
  "translatedText": "동급생은 약간 믿기지 않아 통계학자가 다리를 당기고 있는지 확신하지 못했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.14,
  "end": 39.84
 },
 {
  "input": "How can you know that?",
  "translatedText": "그걸 어떻게 알 수 있나요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 40.22,
  "end": 41.12
 },
 {
  "input": "was the query.",
  "translatedText": "쿼리였습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.26,
  "end": 41.76
 },
 {
  "input": "And what is this symbol over here?",
  "translatedText": "그리고 여기 있는 이 기호는 무엇인가요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.28,
  "end": 43.76
 },
 {
  "input": "Oh, said the statistician, this is pi.",
  "translatedText": "아, 통계학자가 말하길, 이것은 파이입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.38,
  "end": 46.82
 },
 {
  "input": "What is that?",
  "translatedText": "저게 뭐에요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.34,
  "end": 47.9
 },
 {
  "input": "The ratio of the circumference of a circle to its diameter.",
  "translatedText": "원의 지름에 대한 원주 비율입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 48.6,
  "end": 51.08
 },
 {
  "input": "Well, now you're pushing the joke too far, said the classmate.",
  "translatedText": "글쎄, 이제 당신은 농담을 너무 멀리하고 있는 것 같다고 동급생이 말했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.0,
  "end": 54.42
 },
 {
  "input": "Surely the population has nothing to do with the circumference of a circle.",
  "translatedText": "확실히 인구는 원의 둘레와 아무런 관련이 없습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.42,
  "end": 57.96
 },
 {
  "input": "In the paper, Wigner then goes on to talk about the more general phenomenon of concepts and pure math seeming to find applications that extend strangely beyond what their definitions would suggest.",
  "translatedText": "논문에서 Wigner는 정의가 제안하는 것 이상으로 이상하게 확장되는 응용 프로그램을 찾는 것처럼 보이는 개념과 순수 수학의 보다 일반적인 현상에 대해 계속해서 이야기합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.28,
  "end": 68.48
 },
 {
  "input": "But I would like to stay focused on this particular anecdote and the question that the statistician's friend is getting at.",
  "translatedText": "하지만 저는 이 특별한 일화와 통계학자의 친구가 제기하는 질문에 계속 집중하고 싶습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.94,
  "end": 74.76
 },
 {
  "input": "You see, there is a very beautiful and classic proof that explains the pi inside the formula for a normal distribution.",
  "translatedText": "보시다시피, 정규 분포 공식 내부의 파이를 설명하는 매우 아름답고 고전적인 증명이 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 75.24,
  "end": 80.84
 },
 {
  "input": "And despite there being a number of other really great explanations online, see some links in the description, I cannot help but indulge in the pleasure of reanimating it here.",
  "translatedText": "그리고 온라인에 정말 훌륭한 설명이 많이 있음에도 불구하고 설명의 일부 링크를 참조하세요. 여기서 다시 애니메이션화하는 즐거움에 빠져들지 않을 수 없습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.84,
  "end": 89.72
 },
 {
  "input": "For one thing, there is a fun side note that I didn't learn until recently about how you can use this proof to derive the volumes of higher dimensional spheres.",
  "translatedText": "우선, 이 증명을 사용하여 고차원 구의 부피를 유도하는 방법에 대해 최근까지 배우지 못한 재미있는 참고 사항이 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 90.42,
  "end": 97.36
 },
 {
  "input": "But much more importantly than that, what I really want to do is try to go beyond the classic proof.",
  "translatedText": "하지만 그보다 훨씬 더 중요한 것은 제가 정말로 하고 싶은 일은 고전적인 증명을 넘어서려고 노력하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.28,
  "end": 103.0
 },
 {
  "input": "Consider this hypothetical statistician's friend.",
  "translatedText": "이 가상의 통계학자의 친구를 생각해 보십시오.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.56,
  "end": 106.06
 },
 {
  "input": "What I want to ask is, can we find an explanation that would satisfy their disbelief?",
  "translatedText": "내가 묻고 싶은 것은 그들의 불신을 만족시킬 수 있는 설명을 찾을 수 있느냐는 것이다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.38,
  "end": 110.7
 },
 {
  "input": "You see, they're not just asking for some pure math proof about a function that was handed down to them on high.",
  "translatedText": "알다시피, 그들은 단지 높은 곳에서 그들에게 전해졌던 기능에 대한 순수한 수학 증명을 요구하는 것이 아닙니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.84,
  "end": 115.98
 },
 {
  "input": "The friend's incredulity was that circles should have anything to do with population statistics.",
  "translatedText": "그 친구는 서클이 인구 통계와 관련이 있다는 사실을 믿을 수 없었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.54,
  "end": 121.58
 },
 {
  "input": "Until we fully draw that connecting line, we should consider the task incomplete.",
  "translatedText": "연결선을 완전히 그릴 때까지는 작업이 완료되지 않은 것으로 간주해야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.06,
  "end": 126.18
 },
 {
  "input": "Those of you who watched the last video on the central limit theorem will have some of the backdrop here, because there we broke down the formula for a normal distribution, which is also called a Gaussian distribution.",
  "translatedText": "중심 극한 정리에 대한 지난 비디오를 시청한 분들은 여기에 배경이 있을 것입니다. 왜냐하면 거기서 우리가 가우시안 분포라고도 불리는 정규 분포 공식을 분석했기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 127.0,
  "end": 136.68
 },
 {
  "input": "And when you strip away all of the different parameters and the constants, the basic function that describes the bell curve shape is e to the negative x squared.",
  "translatedText": "그리고 다양한 매개변수와 상수를 모두 제거하면 종형 곡선 모양을 설명하는 기본 함수는 e의 음수 x 제곱입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.26,
  "end": 145.28
 },
 {
  "input": "And the reason that pi showed up in the final formula was that the area underneath this curve works out, as you will see in a couple minutes, to be the square root of pi.",
  "translatedText": "그리고 파이가 최종 공식에 나타나는 이유는 이 곡선 아래의 면적이 파이의 제곱근이 되기 때문입니다. 몇 분 후에 보시게 될 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.92,
  "end": 155.34
 },
 {
  "input": "So what that meant for us was that at some point we needed to divide out by that square root of pi to make sure that the area under the curve is one, which is a requirement before you can interpret it as a probability distribution.",
  "translatedText": "따라서 이것이 우리에게 의미하는 바는 어느 시점에서 곡선 아래의 면적이 1이 되도록 하기 위해 파이의 제곱근으로 나누어야 한다는 것입니다. 이는 확률 분포로 해석하기 전에 요구되는 사항입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.34,
  "end": 166.66
 },
 {
  "input": "In the full formula that you would see, say, in a stats book, this gets mixed together with some of the other constants, but in its purest form that pi originates from the area underneath this curve.",
  "translatedText": "예를 들어 통계 책에서 볼 수 있는 전체 공식에서 이는 다른 상수 중 일부와 혼합되지만 가장 순수한 형태에서는 파이가 이 곡선 아래 영역에서 유래합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.24,
  "end": 178.1
 },
 {
  "input": "So step number one for you and me is to explain that area, but I want to emphasize it's not the last step.",
  "translatedText": "따라서 여러분과 저를 위한 첫 번째 단계는 해당 영역을 설명하는 것입니다. 그러나 이것이 마지막 단계는 아니라는 점을 강조하고 싶습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.12,
  "end": 185.06
 },
 {
  "input": "To satisfy the question raised by that hypothetical statistician's friend, we need to go further.",
  "translatedText": "그 가상의 통계학자 친구가 제기한 질문을 만족시키기 위해서는 더 나아가야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 185.38,
  "end": 190.34
 },
 {
  "input": "We need to also answer why is it that this function e to the negative x squared is so special in the first place?",
  "translatedText": "우리는 또한 음의 x 제곱에 대한 이 함수 e가 애초에 그렇게 특별한 이유가 무엇인지 대답해야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.44,
  "end": 195.86
 },
 {
  "input": "I mean, there are lots of different formulas you could write down that would give a shape that, you know, vaguely bulges in the middle and tapers out on either side.",
  "translatedText": "내 말은, 가운데가 막연하게 불룩해지고 양쪽이 점점 가늘어지는 모양을 만드는 공식이 많이 있다는 뜻입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.86,
  "end": 204.1
 },
 {
  "input": "So why is it that this specific function holds such a special place in statistics?",
  "translatedText": "그렇다면 이 특정 함수가 통계에서 그렇게 특별한 위치를 차지하는 이유는 무엇일까요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.64,
  "end": 208.86
 },
 {
  "input": "To phrase our goal another way, can we find a connection between the proof that shows why pi shows up and the central limit theorem, which, as we talked about in the last video, is the thing that explains when you can expect a normal distribution to arise in nature?",
  "translatedText": "우리의 목표를 다른 방식으로 표현하자면, 파이가 나타나는 이유를 보여주는 증명과 지난 비디오에서 이야기했듯이 정규 분포를 기대할 수 있는 시기를 설명하는 중심 극한 정리 사이의 연관성을 찾을 수 있습니까? 자연에서 발생?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 209.74,
  "end": 224.04
 },
 {
  "input": "So with all of that as the goal, first things first, let's dig into the classic and very beautiful proof.",
  "translatedText": "따라서 이 모든 것을 목표로 삼고 가장 먼저 고전적이고 매우 아름다운 증명을 파헤쳐 보겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.7,
  "end": 229.28
 },
 {
  "input": "All right, when you want to find the area underneath a curve, the tool for doing that is an integral.",
  "translatedText": "좋습니다. 곡선 아래의 면적을 찾으려면 이를 수행하는 도구가 필수적입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.76,
  "end": 236.76
 },
 {
  "input": "As a quick reminder for how you might read this notation, you might imagine approximating that area with many different rectangles under the curve, where the height of each such rectangle is the value of the function above that point, in this case, e to the negative x squared for a certain input x, and the width is some little number that we're calling dx.",
  "translatedText": "이 표기법을 읽는 방법에 대한 빠른 알림으로 곡선 아래에 다양한 직사각형이 있는 해당 영역을 근사화하는 것을 상상할 수 있습니다. 여기서 각 직사각형의 높이는 해당 지점 위의 함수 값입니다. 이 경우 e는 특정 입력 x에 대해 음수 x 제곱이고 너비는 dx라고 부르는 작은 숫자입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.26,
  "end": 253.8
 },
 {
  "input": "We need to add up the areas of all these rectangles, for values of x ranging from negative infinity up to infinity, and the use of that notation dx is kind of meant to imply you shouldn't think of any specific width, but instead you ask, as the chosen width for your rectangles gets thinner and thinner, what does this sum of all those areas approach?",
  "translatedText": "음의 무한대에서 무한대까지의 x 값에 대해 모든 직사각형의 면적을 더해야 하며, dx 표기법을 사용하는 것은 특정 너비를 생각해서는 안 된다는 것을 의미하지만 대신 직사각형에 대해 선택한 너비가 점점 더 얇아짐에 따라 모든 영역의 합은 얼마에 가까워지나요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 254.42,
  "end": 271.84
 },
 {
  "input": "Of course, all of that is just notation unless you provide a way to answer that question, and the magic of calculus is that it provides just that, at least usually.",
  "translatedText": "물론, 그 질문에 답할 방법을 제공하지 않는 한 그 모든 것은 단지 표기법일 뿐이며, 미적분학의 마법은 적어도 일반적으로 바로 그것을 제공한다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.38,
  "end": 280.38
 },
 {
  "input": "You see, usually the procedure here would be to find some function whose derivative is equal to the stuff we have on the inside, e to the negative x squared.",
  "translatedText": "보시다시피, 일반적으로 여기서의 절차는 도함수가 우리가 내부에 있는 것과 동일한 함수, 즉 e의 음수 x 제곱을 찾는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.86,
  "end": 288.56
 },
 {
  "input": "In other words, we want to find an antiderivative of that function.",
  "translatedText": "즉, 우리는 해당 함수의 역도함수를 찾고 싶습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.1,
  "end": 291.88
 },
 {
  "input": "The problem is, for this particular function, it is provably not possible to find such an antiderivative.",
  "translatedText": "문제는 이 특정 함수에 대해 그러한 역도함수를 찾는 것이 불가능하다는 것이 입증되었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.56,
  "end": 298.08
 },
 {
  "input": "It's a little weird and beyond the scope of what I want to talk about here, but basically, even though there exists an antiderivative, it is a well-defined function, you cannot express what that antiderivative is using all our usual tools, like polynomial expressions, trig functions, exponentials, or any way to mix them together.",
  "translatedText": "조금 이상하고 여기서 이야기하고 싶은 범위를 벗어나지만 기본적으로 역도함수가 존재하더라도 잘 정의된 함수이므로 다항식과 같은 일반적인 도구를 사용하여 해당 역도함수가 무엇인지 표현할 수 없습니다. 표현식, 삼각 함수, 지수 또는 이들을 혼합하는 모든 방법.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.74,
  "end": 314.66
 },
 {
  "input": "So finding this area requires a bit of cleverness.",
  "translatedText": "따라서 이 영역을 찾으려면 약간의 영리함이 필요합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.26,
  "end": 317.52
 },
 {
  "input": "There needs to be a new trick that we bring to bear.",
  "translatedText": "우리가 감당할 수 있는 새로운 트릭이 필요합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.6,
  "end": 319.46
 },
 {
  "input": "And the first step to this trick is easily the most absurd.",
  "translatedText": "그리고 이 트릭의 첫 번째 단계는 가장 터무니없는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.94,
  "end": 322.38
 },
 {
  "input": "We start by bumping things up one dimension, so that instead of asking for the area under a bell curve, we ask for the volume underneath this kind of bell surface.",
  "translatedText": "우리는 일차원을 높이는 것부터 시작하여 종형 곡선 아래의 면적을 묻는 대신 이런 종류의 종 표면 아래의 부피를 묻습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.6,
  "end": 331.36
 },
 {
  "input": "You could rightly ask, why would you do that?",
  "translatedText": "당신은 당연히 물어볼 수 있습니다. 왜 그렇게 하시겠습니까?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.36,
  "end": 334.34
 },
 {
  "input": "Who ordered another dimension?",
  "translatedText": "누가 다른 차원을 주문했나요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.42,
  "end": 335.58
 },
 {
  "input": "And I'll admit, it's not terribly motivated right now, other than to say, watch what happens when we just try it.",
  "translatedText": "그리고 인정하겠습니다. 지금 당장은 별로 동기가 부여되지 않습니다. 그냥 시도해 보면 어떤 일이 일어나는지 지켜보세요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.32,
  "end": 341.62
 },
 {
  "input": "And in general, with hard problems, it's never a bad idea to try solving cousins of the problem, since that can help you get a little bit of momentum and insight.",
  "translatedText": "그리고 일반적으로 어려운 문제의 경우, 문제의 사촌을 해결하려고 시도하는 것은 결코 나쁜 생각이 아닙니다. 왜냐하면 그렇게 하면 약간의 추진력과 통찰력을 얻는 데 도움이 될 수 있기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.7,
  "end": 348.64
 },
 {
  "input": "To be clear on how this higher dimensional function is defined, it takes in two different inputs, x and y, which we might think of as a point on the xy-plane.",
  "translatedText": "이 고차원 함수가 어떻게 정의되는지 명확히 하기 위해 xy 평면의 한 점으로 생각할 수 있는 두 개의 서로 다른 입력 x와 y를 사용합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.56,
  "end": 357.12
 },
 {
  "input": "And the way to think about it is to consider the distance from that point to the origin, which I'll label as r, and then to plug in that distance to our original bell curve function, we take e to the negative r squared.",
  "translatedText": "이에 대해 생각하는 방법은 해당 지점에서 원점까지의 거리를 고려하는 것입니다. 이를 r로 표시한 다음 해당 거리를 원래 종 곡선 함수에 연결하고 e를 음수 r 제곱으로 가져옵니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.46,
  "end": 368.42
 },
 {
  "input": "You might notice the lines I've drawn on this diagram make a right triangle.",
  "translatedText": "이 다이어그램에 제가 그린 선이 직각 삼각형을 이루는 것을 보실 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 368.42,
  "end": 372.18
 },
 {
  "input": "So by the Pythagorean theorem, x squared plus y squared equals r squared.",
  "translatedText": "따라서 피타고라스 정리에 따르면 x 제곱 더하기 y 제곱은 r 제곱과 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.82,
  "end": 376.14
 },
 {
  "input": "So in the function I have written, where you see x squared plus y squared, you can think in the back of your mind, that's really the square of the distance from the point to the origin.",
  "translatedText": "그래서 제가 작성한 함수에서 x 제곱 더하기 y 제곱을 보면 마음 속으로 생각할 수 있습니다. 그것은 실제로 점에서 원점까지의 거리의 제곱입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 376.8,
  "end": 384.46
 },
 {
  "input": "The main thing to notice here is how this gives our function a kind of circular symmetry, in the sense that all of the inputs that sit on a given circle have the same output.",
  "translatedText": "여기서 주목해야 할 가장 중요한 점은 주어진 원에 있는 모든 입력이 동일한 출력을 갖는다는 의미에서 이것이 우리 함수에 일종의 원형 대칭을 제공하는 방법입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.02,
  "end": 392.98
 },
 {
  "input": "And so when we graph this function in three dimensions, it means it has a rotational symmetry about the z-axis.",
  "translatedText": "따라서 이 함수를 3차원으로 그래프로 표시하면 z축에 대해 회전 대칭이 있다는 의미입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.72,
  "end": 399.38
 },
 {
  "input": "Math tends to reward you when you respect its symmetries, so for our question of computing the volume underneath this surface, what we're going to do is respect that symmetry, and imagine integrating together a bunch of thin little cylinders underneath that surface.",
  "translatedText": "수학은 대칭을 존중할 때 보상을 받는 경향이 있습니다. 따라서 이 표면 아래의 부피를 계산하는 문제에 대해 우리가 할 일은 그 대칭을 존중하고 그 표면 아래에 있는 얇고 작은 원통 묶음을 함께 통합하는 것을 상상하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.48,
  "end": 413.48
 },
 {
  "input": "Here, making this a little more quantitative, let's focus on just one of those cylindrical shells, where its area is going to be the circumference of that shell times the height.",
  "translatedText": "여기에서는 이를 좀 더 정량적으로 설명하면서 원통형 껍질 중 하나에만 초점을 맞춰보겠습니다. 여기서 그 면적은 껍질의 둘레에 높이를 곱한 값이 됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.38,
  "end": 423.1
 },
 {
  "input": "You might imagine it as something like the label on a soup can that we can unwrap into a rectangle.",
  "translatedText": "직사각형으로 풀 수 있는 수프 캔의 라벨과 같은 것으로 상상할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.5,
  "end": 428.1
 },
 {
  "input": "The circumference of the cylinder, which is the top side of that rectangle, is going to be 2 pi times the radius.",
  "translatedText": "직사각형의 위쪽인 원통의 원주는 반지름의 2파이가 됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.82,
  "end": 434.26
 },
 {
  "input": "And then the height of our cylinder, the other side of our rectangle, is the height of the surface at this point, which by definition is the value of our function associated with that radius, which like I said earlier you can think of as e to the negative r squared.",
  "translatedText": "그리고 직사각형의 반대편인 원통의 높이는 이 지점의 표면 높이입니다. 정의에 따르면 이는 반경과 관련된 함수의 값입니다. 앞서 말했듯이 e로 생각할 수 있습니다. 음의 r 제곱을 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 435.16,
  "end": 448.36
 },
 {
  "input": "The real way you want to think about this is to give that cylinder a little bit of thickness, which we'll call dr, so that the volume that it represents is approximately that area we just looked at multiplied by this thickness dr.",
  "translatedText": "이에 대해 생각하고 싶은 실제 방법은 원통에 약간의 두께를 부여하는 것입니다. 이를 dr이라고 부르겠습니다. 그러면 그것이 나타내는 볼륨은 대략 우리가 본 영역에 이 두께 dr을 곱한 값이 됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.38,
  "end": 460.98
 },
 {
  "input": "Our task now is to integrate together, or add together, all of these different cylinders as r ranges between 0 and infinity.",
  "translatedText": "이제 우리의 임무는 r의 범위가 0에서 무한대 사이이므로 이러한 다양한 원통을 모두 통합하거나 더하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.6,
  "end": 468.82
 },
 {
  "input": "Or more precisely, we consider what happens as that thickness gets thinner and thinner, approaching 0, and we add together the volumes of the many many many different thin cylinders that sit underneath that curve.",
  "translatedText": "또는 더 정확하게는 두께가 0에 가까워지고 얇아지면 어떤 일이 발생하는지 고려하고 해당 곡선 아래에 있는 다양한 얇은 원통의 부피를 더합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 469.34,
  "end": 479.12
 },
 {
  "input": "You might think this is just a harder version of what we were looking at earlier, three dimensions should be more complicated than two.",
  "translatedText": "이것이 이전에 살펴본 것보다 더 어려운 버전이라고 생각할 수도 있습니다. 3차원은 2차원보다 더 복잡해야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 481.56,
  "end": 487.86
 },
 {
  "input": "But actually, something very helpful has happened.",
  "translatedText": "그런데 실제로 매우 도움이 되는 일이 일어났습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.56,
  "end": 490.48
 },
 {
  "input": "First let me clean up a little by factoring the pi outside that integral.",
  "translatedText": "먼저 적분 외부의 파이를 인수분해하여 조금 정리하겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.14,
  "end": 494.0
 },
 {
  "input": "Now the stuff inside that integral, having picked up this term 2r, does have an antiderivative.",
  "translatedText": "이제 이 항 2r을 선택한 적분 내부의 내용은 역도함수를 갖습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.56,
  "end": 500.54
 },
 {
  "input": "We can now apply the usual tactics of calculus.",
  "translatedText": "이제 우리는 일반적인 미적분학 전략을 적용할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.74,
  "end": 502.98
 },
 {
  "input": "Specifically, that whole inside expression is the derivative of negative e to the negative r squared.",
  "translatedText": "구체적으로, 그 전체 내부 표현은 음수 e를 음수 r 제곱으로 미분한 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 503.64,
  "end": 509.34
 },
 {
  "input": "And so, those of you comfortable with calculus know what to do from here.",
  "translatedText": "미적분학에 익숙한 분들은 여기서 무엇을 해야 할지 아실 겁니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.16,
  "end": 513.14
 },
 {
  "input": "We take that antiderivative and plug in the upper bound, which is negative infinity squared, and that gives us 0, or speaking a little bit more precisely, if you consider the limit of this expression as the input approaches infinity, the limiting value is 0, and we subtract off the value of that antiderivative at the lower bound, 0, which in this case is negative 1.",
  "translatedText": "역도함수를 취하고 상한을 대입하면 음의 무한대 제곱이 됩니다. 그러면 0이 됩니다. 좀 더 정확하게 말하면 입력이 무한대에 접근할 때 이 표현식의 극한을 고려하면 극한 값은 0입니다. , 하한값 0에서 해당 역도함수의 값을 뺍니다. 이 경우에는 음수 1입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.38,
  "end": 532.5
 },
 {
  "input": "So all in all, the whole integral just works out to be 1, which means all we're left with is that factor out in front, pi.",
  "translatedText": "따라서 전체적으로, 전체 적분은 1이 됩니다. 즉, 우리에게 남은 것은 앞에 있는 인수인 pi뿐이라는 의미입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 532.98,
  "end": 539.0
 },
 {
  "input": "Evidently, the volume underneath this bell surface is pi.",
  "translatedText": "분명히 이 종 표면 아래의 부피는 파이입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.72,
  "end": 542.94
 },
 {
  "input": "And I'll point out in this case, it's not wild that pi shows up, because the surface has this intrinsic circular symmetry.",
  "translatedText": "그리고 이 경우에 제가 지적하고 싶은 것은 표면이 본질적인 원형 대칭을 갖고 있기 때문에 파이가 나타나는 것은 우연이 아니라는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.24,
  "end": 550.0
 },
 {
  "input": "Still, you might wonder, how does that help us?",
  "translatedText": "그래도 그것이 우리에게 어떻게 도움이 되는지 궁금할 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 550.9,
  "end": 553.06
 },
 {
  "input": "As I said, throughout math, if you face a hard problem, solving an adjacent problem can be unexpectedly helpful as a next step.",
  "translatedText": "내가 말했듯이 수학 전반에 걸쳐 어려운 문제에 직면하면 인접한 문제를 해결하는 것이 다음 단계로 예기치 않게 도움이 될 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.56,
  "end": 559.78
 },
 {
  "input": "And in this case, it's helpful not just for building intuition, but we can directly relate the three-dimensional graph to our two-dimensional graph by analyzing the volume in a second, different way.",
  "translatedText": "이 경우 직관력을 키우는 데 도움이 될 뿐만 아니라 두 번째, 다른 방식으로 볼륨을 분석하여 3차원 그래프를 2차원 그래프와 직접 연관시킬 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.78,
  "end": 569.92
 },
 {
  "input": "You see, the more general way to approach volumes underneath surfaces is to think of chopping it up into slices that are all parallel to one of the axes.",
  "translatedText": "표면 아래의 볼륨에 접근하는 보다 일반적인 방법은 볼륨을 축 중 하나와 평행한 조각으로 자르는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.4,
  "end": 578.88
 },
 {
  "input": "For example, all these slices that are parallel to the x-axis.",
  "translatedText": "예를 들어, x축에 평행한 모든 조각이 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.3,
  "end": 582.22
 },
 {
  "input": "For example, this right here is a slice that corresponds to the plane y equals 0.",
  "translatedText": "예를 들어, 여기 있는 것은 y가 0인 평면에 해당하는 슬라이스입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.06,
  "end": 588.34
 },
 {
  "input": "You might notice it looks just like a bell curve, and if we write out the function, this should actually make a lot of sense.",
  "translatedText": "종형 곡선처럼 보인다는 것을 눈치채셨을 것입니다. 함수를 작성해 보면 실제로 많은 의미가 있을 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.34,
  "end": 593.76
 },
 {
  "input": "You could just plug in y equals 0, but to help see what happens with other slices, notice how, thanks to the rules of exponentiation, we could also write our function as e to the negative x squared times e to the negative y squared.",
  "translatedText": "y = 0을 대입하면 되지만, 다른 조각에서 어떤 일이 일어나는지 확인하려면 지수 규칙 덕분에 함수를 e의 음수 x 제곱 곱하기 e의 음수 y 제곱으로 쓸 수도 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 593.98,
  "end": 605.08
 },
 {
  "input": "It factors out nicely.",
  "translatedText": "그것은 잘 고려됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 605.16,
  "end": 606.48
 },
 {
  "input": "On this slice, that e to the negative y squared is just a number, specifically the number 1.",
  "translatedText": "이 조각에서 e의 음수 y 제곱은 단지 숫자, 특히 숫자 1입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.28,
  "end": 612.28
 },
 {
  "input": "So this is the same graph we've seen before, e to the negative x squared, meaning that the area of this slice is exactly the thing that we're looking for.",
  "translatedText": "따라서 이것은 이전에 본 것과 동일한 그래프입니다. e의 -x 제곱은 이 슬라이스의 면적이 정확히 우리가 찾고 있는 것임을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.84,
  "end": 620.08
 },
 {
  "input": "It's the mystery constant, which I'm going to give the name c.",
  "translatedText": "이것은 미스터리 상수입니다. 저는 여기에 c라는 이름을 붙일 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.5,
  "end": 623.22
 },
 {
  "input": "What's nice is there's nothing really special about this particular slice.",
  "translatedText": "좋은 점은 이 특정 조각에는 특별한 것이 없다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.98,
  "end": 627.1
 },
 {
  "input": "If we chose a different slice corresponding to a different y value, it corresponds to multiplying this curve by a different number.",
  "translatedText": "다른 y 값에 해당하는 다른 슬라이스를 선택한 경우 이는 이 곡선에 다른 숫자를 곱하는 것과 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.64,
  "end": 634.08
 },
 {
  "input": "So it's the same basic shape, just scaled down by that number, meaning its area is the same as our mystery constant, just scaled down by some number.",
  "translatedText": "그래서 그것은 동일한 기본 모양이고 그 숫자만큼만 축소되었습니다. 즉, 그 면적은 우리의 미스터리 상수와 동일하며 단지 어떤 숫자만큼만 축소되었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.52,
  "end": 642.54
 },
 {
  "input": "That's pretty cool.",
  "translatedText": "꽤 괜찮은데.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.54,
  "end": 643.72
 },
 {
  "input": "Each one of these slices has the same basic shape, just rescaled in the vertical direction, which, by the way, is not at all true for most two-variable functions.",
  "translatedText": "이러한 조각 각각은 동일한 기본 모양을 가지며 수직 방향으로 크기가 조정되었습니다. 그런데 이는 대부분의 2변수 함수에 전혀 해당되지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 643.98,
  "end": 652.26
 },
 {
  "input": "This is very much dependent on the fact that we were able to factor our function into one part that's just dependent on the y and another part that's just dependent on the x.",
  "translatedText": "이는 함수를 y에만 의존하는 한 부분과 x에만 의존하는 다른 부분으로 분해할 수 있다는 사실에 크게 좌우됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.72,
  "end": 661.2
 },
 {
  "input": "Now, to think about the volume underneath this whole surface, here's another way we could phrase it.",
  "translatedText": "이제 이 전체 표면 아래의 부피에 대해 생각해 보기 위해 이를 표현하는 또 다른 방법이 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.04,
  "end": 666.76
 },
 {
  "input": "We're going to compute another integral that ranges from y equals negative infinity up to infinity, where the term inside that integral tells us the area of each one of those slices.",
  "translatedText": "우리는 y가 음의 무한대에서 무한대까지의 또 다른 적분을 계산할 것입니다. 적분 내부의 항은 각 조각의 면적을 알려줍니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.96,
  "end": 676.14
 },
 {
  "input": "And when we multiply it by a little thickness dy, you might think of it as giving each one of those slices a little bit of volume.",
  "translatedText": "그리고 여기에 약간의 두께 dy를 곱하면 각 조각에 약간의 볼륨을 부여하는 것으로 생각할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 676.78,
  "end": 682.7
 },
 {
  "input": "And remember, that term c sitting in front represents the thing we want to know, which itself is an integral, a suspiciously similar-looking integral.",
  "translatedText": "그리고 기억하세요, 앞에 있는 용어 c는 우리가 알고 싶은 것을 나타내며, 그 자체가 적분이고, 의심스러울 정도로 유사해 보이는 적분입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.18,
  "end": 691.84
 },
 {
  "input": "See, if we take the expression on the top and we factor out that constant c, because it's just a number, it doesn't depend on y, the thing we're left with, the integral we need to compute, is exactly the mystery constant, the thing we don't know.",
  "translatedText": "보세요, 맨 위의 식을 취하고 상수 c를 빼내면 이는 단지 숫자일 뿐이고 y에 의존하지 않기 때문에 우리에게 남은 것, 우리가 계산해야 하는 적분은 정확히 다음과 같습니다. 미스터리 상수, 우리가 모르는 것.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 692.58,
  "end": 704.84
 },
 {
  "input": "So overall, the volume underneath this bell surface works out to be this mystery constant squared.",
  "translatedText": "따라서 전체적으로 이 종 표면 아래의 부피는 이 미스터리 상수의 제곱으로 나타납니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 705.42,
  "end": 711.38
 },
 {
  "input": "Out of context, this might seem very unhelpful, it's just relating one thing we don't know to another thing we don't know, except we've already computed the volume under this surface, we know that it's equal to pi.",
  "translatedText": "문맥상, 이것은 매우 도움이 되지 않는 것처럼 보일 수 있습니다. 이는 우리가 모르는 것과 우리가 모르는 다른 것을 연관시키는 것입니다. 단, 우리는 이 표면 아래의 부피를 이미 계산했고 그것이 pi와 같다는 것을 압니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 712.46,
  "end": 722.3
 },
 {
  "input": "Therefore, the mystery constant we want to know, the area underneath this bell curve, must be the square root of pi.",
  "translatedText": "그러므로 우리가 알고 싶은 미스터리 상수, 즉 이 종형 곡선 아래의 면적은 파이의 제곱근이어야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.06,
  "end": 728.82
 },
 {
  "input": "It's a very pretty argument, but a few things are not entirely satisfying.",
  "translatedText": "매우 그럴듯한 주장이지만 몇 가지 사항은 완전히 만족스럽지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.12,
  "end": 734.16
 },
 {
  "input": "For one thing, it feels a little bit like a trick, something that just happened to work, without offering much of a sense for how you could have rediscovered it yourself.",
  "translatedText": "우선, 그것은 당신이 그것을 어떻게 스스로 재발견할 수 있었는지에 대한 많은 감각을 제공하지 않고 방금 작동했던 일종의 속임수처럼 느껴집니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.86,
  "end": 742.8
 },
 {
  "input": "Also, if we think back to our imagined statistician's friend, it doesn't really answer their question, which was what do circles have to do with population statistics?",
  "translatedText": "또한, 우리가 상상하는 통계학자의 친구를 다시 생각해보면, 그것은 그들의 질문에 실제로 대답하지 않습니다. '원이 인구 통계와 무슨 관련이 있습니까?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.42,
  "end": 751.8
 },
 {
  "input": "Like I said, it's the first step, not the last, and as our next step, let's see if we can unpack why this proof is not quite as wild and arbitrary as you might first think, and how it relates to an explanation for where this function e to the negative x squared is coming from in the first place.",
  "translatedText": "' 내가 말했듯이, 이것은 마지막이 아닌 첫 번째 단계입니다. 다음 단계로서 이 증명이 처음 생각하는 것만큼 거칠고 임의적이지 않은 이유를 풀 수 있는지, 그리고 그것이 어디에 대한 설명과 어떻게 관련되는지 살펴보겠습니다. e의 음수 x 제곱에 대한 이 함수는 처음부터 나옵니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 752.54,
  "end": 766.6
 },
 {
  "input": "John Herschel was this mathematician slash scientist slash inventor who really did all sorts of things throughout the 19th century.",
  "translatedText": "존 허셜(John Herschel)은 19세기 내내 정말 온갖 일을 해낸 수학자 슬래시 과학자 슬래시 발명가였습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 771.66,
  "end": 779.06
 },
 {
  "input": "He made contributions in chemistry, astronomy, photography, botany, he invented the blueprint and named many of the moons in our solar system, and in the midst of all of this, he also offered a very elegant little derivation for the Gaussian distribution in 1850.",
  "translatedText": "그는 화학, 천문학, 사진, 식물학 분야에 공헌을 했으며 청사진을 발명하고 우리 태양계의 많은 위성에 이름을 붙였습니다. 그리고 이 모든 와중에 1850년에 그는 가우스 분포에 대한 매우 우아한 작은 유도도 제공했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.4,
  "end": 793.66
 },
 {
  "input": "The setup is to imagine that you want to describe some kind of probability distribution in two-dimensional space.",
  "translatedText": "설정은 2차원 공간에서 일종의 확률 분포를 설명하고 싶다고 상상하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.0,
  "end": 800.08
 },
 {
  "input": "For instance, maybe you want to model the probability density for hits on a dartboard.",
  "translatedText": "예를 들어, 다트판의 적중 확률 밀도를 모델링하고 싶을 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 800.36,
  "end": 804.5
 },
 {
  "input": "What Herschel showed is that if you want this distribution to satisfy two pretty reasonable seeming properties, your hand is unexpectedly forced, and even if you had never heard of a Gaussian in your life, you would be inexorably drawn to use a function with the shape e to the negative x squared plus y squared.",
  "translatedText": "Herschel이 보여준 것은 이 분포가 매우 합리적으로 보이는 두 가지 속성을 만족시키기를 원한다면 예기치 않게 손이 움직이게 되며, 평생 가우시안에 대해 들어본 적이 없더라도 다음 모양의 함수를 사용하고 싶은 마음이 가차 없이 끌리게 된다는 것입니다. e를 음의 x 제곱에 y 제곱을 더한 값입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.06,
  "end": 820.56
 },
 {
  "input": "You do have one degree of freedom to control the spread of that distribution, and of course there's going to be some constant sitting in front to make sure it's normalized, but the point is that we're forced into this very specific kind of bell curve shape.",
  "translatedText": "해당 분포의 확산을 제어할 수 있는 자유도는 1도이고, 물론 이것이 정규화되었는지 확인하기 위해 계속해서 앞에 앉아 있어야 하지만 요점은 우리가 매우 특정한 종류의 종형 곡선을 강요당한다는 것입니다. 모양.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 821.14,
  "end": 832.62
 },
 {
  "input": "The first of these two properties is that the probability density around each point depends only on its distance from the origin, not on its direction.",
  "translatedText": "이 두 가지 속성 중 첫 번째는 각 점 주변의 확률 밀도가 방향이 아닌 원점으로부터의 거리에만 의존한다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 833.48,
  "end": 842.14
 },
 {
  "input": "So on a dartboard with everybody aiming for the bullseye, this would mean that you could rotate the board and it would make no difference for the distribution.",
  "translatedText": "따라서 모두가 불스아이를 목표로 하는 다트판에서는 보드를 회전할 수 있으며 배포에는 아무런 차이가 없다는 의미입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.8,
  "end": 849.46
 },
 {
  "input": "Mathematically, this means that the function describing your probability distribution, which I'll call f2 since it takes in two inputs x and y, well it can be expressed as some single variable function of the radius r.",
  "translatedText": "수학적으로 이는 확률 분포를 설명하는 함수(두 개의 입력 x와 y를 사용하므로 f2라고 부르겠습니다)가 반경 r의 단일 변수 함수로 표현될 수 있음을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 852.72,
  "end": 864.62
 },
 {
  "input": "And just to spell it out, r is the distance between the point xy and the origin, the square root of x squared plus y squared.",
  "translatedText": "간단히 설명하면, r은 점 xy와 원점 사이의 거리, x 제곱 + y 제곱의 제곱근입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 865.28,
  "end": 871.82
 },
 {
  "input": "Property number two is that the x and y coordinates of each point are independent from each other, which is to say if you learn the x coordinate of a point, it would give you no information about the y coordinate.",
  "translatedText": "두 번째 속성은 각 점의 x 및 y 좌표가 서로 독립적이라는 것입니다. 즉, 점의 x 좌표를 학습하면 y 좌표에 대한 정보가 제공되지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 873.1,
  "end": 883.62
 },
 {
  "input": "The way this looks as an equation is that our function, which describes the probability density around each point on the xy plane, can be factored into two different parts, one of which can be purely written in terms of x, this is the distribution of the x coordinate, I'm giving it the name g, and the other part is purely in terms of y, this would be the distribution for the y coordinate, which I'm temporarily calling h.",
  "translatedText": "이것이 방정식으로 보이는 방식은 xy 평면의 각 점 주위의 확률 밀도를 설명하는 함수가 두 개의 다른 부분으로 인수화될 수 있다는 것입니다. 그 중 하나는 순전히 x로 작성될 수 있습니다. 이것은 다음의 분포입니다. x 좌표는 g라는 이름을 붙이겠습니다. 다른 부분은 순전히 y에 관한 것입니다. 이것은 y 좌표에 대한 분포가 될 것입니다. 임시로 h라고 부르겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 885.1,
  "end": 906.0
 },
 {
  "input": "But if you combine this with the assumption that things are radially symmetric, both of these should be the same distribution.",
  "translatedText": "그러나 이것을 방사형 대칭이라는 가정과 결합하면 둘 다 동일한 분포가 되어야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 906.44,
  "end": 911.8
 },
 {
  "input": "The behavior on each axis should look the same.",
  "translatedText": "각 축의 동작은 동일하게 표시되어야 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 912.1,
  "end": 914.18
 },
 {
  "input": "So we could also write this as g of x times g of y, it's the same function.",
  "translatedText": "따라서 이것을 g(x) 곱하기 g(y)로 쓸 수도 있습니다. 이는 동일한 함수입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.48,
  "end": 918.36
 },
 {
  "input": "And more than that, this function is actually going to be proportional to the one we were just looking at, the one that describes our probability density as a function of the radius, the distance away from the origin.",
  "translatedText": "그리고 그보다 더 중요한 것은 이 함수는 실제로 우리가 방금 보고 있는 함수, 즉 원점으로부터의 거리인 반경의 함수로 확률 밀도를 설명하는 함수에 비례한다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.84,
  "end": 928.26
 },
 {
  "input": "To see this, imagine you were to analyze a point that was on the x axis, a distance r away from the origin.",
  "translatedText": "이를 확인하기 위해 원점에서 거리 r만큼 x축에 있는 점을 분석한다고 가정해 보겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 928.74,
  "end": 933.78
 },
 {
  "input": "Then the two distinct ways to express our function based on the two different properties tells us that f of r has to equal some constant multiplied by g of r.",
  "translatedText": "그러면 두 가지 서로 다른 속성을 기반으로 함수를 표현하는 두 가지 서로 다른 방법은 f(r)가 r(r)의 g를 곱한 상수와 같아야 함을 알려줍니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 934.3,
  "end": 942.98
 },
 {
  "input": "So these functions f and g are basically the same thing, just up to some constant multiple.",
  "translatedText": "따라서 이 함수 f와 g는 기본적으로 동일한 것입니다. 단지 일정한 배수까지만 다를 뿐입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.12,
  "end": 947.5
 },
 {
  "input": "And you know what?",
  "translatedText": "그리고 그거 알아?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 948.9,
  "end": 949.84
 },
 {
  "input": "It would be really nice if we could just assume that that constant was one, so that f and g were literally the same function.",
  "translatedText": "그 상수가 1이라고 가정하여 f와 g가 문자 그대로 동일한 함수라고 가정할 수 있다면 정말 좋을 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.84,
  "end": 956.08
 },
 {
  "input": "And what I'm going to do, which might feel a little bit cheeky, is just assume that that is the case.",
  "translatedText": "그리고 제가 하려고 하는 것은 다소 건방지게 느껴질 수도 있지만, 그것이 사실이라고 가정하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 956.7,
  "end": 961.6
 },
 {
  "input": "What this means is that our answer is going to be a little bit wrong.",
  "translatedText": "이것이 의미하는 바는 우리의 대답이 약간 잘못될 것이라는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.2,
  "end": 964.66
 },
 {
  "input": "The function that we will deduce describing this distribution will be off by some constant factor.",
  "translatedText": "이 분포를 설명하기 위해 우리가 추론할 함수는 일정한 요인에 의해 벗어날 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.88,
  "end": 969.38
 },
 {
  "input": "But that's no big deal, because in the end we can just rescale to make sure the area under the curve is one, like we always do with probability distributions.",
  "translatedText": "하지만 그것은 큰 문제가 아닙니다. 왜냐하면 결국 우리는 항상 확률 분포에서 하는 것처럼 곡선 아래 영역이 1이 되도록 크기를 다시 조정할 수 있기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 969.84,
  "end": 976.96
 },
 {
  "input": "Now, if f and g are the same thing, this gives us a very nice little equation purely in terms of the function f.",
  "translatedText": "이제, 만약 f와 g가 같다면, 이것은 순전히 함수 f의 관점에서 아주 멋진 작은 방정식을 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.52,
  "end": 983.84
 },
 {
  "input": "Remember what this function f is.",
  "translatedText": "이 함수 f가 무엇인지 기억하세요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 984.58,
  "end": 986.2
 },
 {
  "input": "If you have some point in the xy plane, a distance r from the origin, then f of r tells you the relative likelihood of that point showing up in the random process.",
  "translatedText": "xy 평면에 원점으로부터 거리가 r인 어떤 점이 있는 경우 r의 f는 해당 점이 무작위 과정에 나타날 상대적 가능성을 알려줍니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.5,
  "end": 995.26
 },
 {
  "input": "More specifically, it gives the probability density of that point.",
  "translatedText": "보다 구체적으로 말하면 해당 지점의 확률 밀도를 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 995.68,
  "end": 998.68
 },
 {
  "input": "At the outset, this function could have been anything.",
  "translatedText": "처음에는 이 기능이 무엇이든 될 수 있었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 999.16,
  "end": 1001.24
 },
 {
  "input": "But Herschel's two different properties evidently imply something kind of funny about it, which is that if we take the x and y coordinates of that point on the plane and evaluate this function on them separately, taking f of x times f of y, it should give us the same result.",
  "translatedText": "그러나 Herschel의 두 가지 다른 속성은 분명히 그것에 대해 뭔가 재미있는 것을 암시합니다. 즉, 평면에서 해당 점의 x 및 y 좌표를 취하고 이 함수를 별도로 평가하여 f(x) 곱하기 f(y)를 취하면, 우리에게 동일한 결과를 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1001.66,
  "end": 1015.82
 },
 {
  "input": "Or if you prefer, we could expand out the meaning of that distance r as the square root of x squared plus y squared, and this is what our key equation looks like.",
  "translatedText": "또는 원하는 경우 거리 r의 의미를 x 제곱 + y 제곱의 제곱근으로 확장할 수 있으며 이것이 핵심 방정식입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.26,
  "end": 1024.18
 },
 {
  "input": "This kind of equation is what's known in the business as a functional equation.",
  "translatedText": "이런 종류의 방정식은 업계에서 함수 방정식으로 알려져 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1025.0,
  "end": 1028.88
 },
 {
  "input": "We're not solving for an unknown number.",
  "translatedText": "우리는 알 수 없는 숫자를 해결하는 것이 아닙니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.98,
  "end": 1031.04
 },
 {
  "input": "Instead, we're saying that the equation is true for all possible numbers x and y, and the thing we're trying to find is an unknown function.",
  "translatedText": "대신, 우리는 방정식이 가능한 모든 숫자 x와 y에 대해 참이고 우리가 찾으려는 것은 알려지지 않은 함수라고 말하고 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.04,
  "end": 1038.26
 },
 {
  "input": "In the back of your mind, you can think we already know one function that satisfies this property, e to the negative x squared, and as a sanity check you might verify for yourself that it does satisfy that.",
  "translatedText": "마음 속으로 우리는 이 속성을 만족하는 하나의 함수, 즉 e의 음수 x 제곱을 이미 알고 있다고 생각할 수 있으며, 온전한 확인을 통해 해당 함수가 그것을 만족하는지 스스로 확인할 수도 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.48,
  "end": 1050.38
 },
 {
  "input": "Of course, the point is to pretend that you don't know that, and to instead deduce what all of the functions are which satisfy this property.",
  "translatedText": "물론, 요점은 당신이 그것을 모르는 척하고 대신 이 속성을 만족하는 모든 기능이 무엇인지 추론하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1051.0,
  "end": 1057.8
 },
 {
  "input": "In general, functional equations can be quite tricky, but let me show you how you can solve this one.",
  "translatedText": "일반적으로 함수 방정식은 매우 까다로울 수 있지만 이 방정식을 어떻게 해결할 수 있는지 보여 드리겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.42,
  "end": 1063.42
 },
 {
  "input": "First, it's nice to introduce a little helper function that I'll call h of x, which will be defined as our mystery function evaluated at the square root of x.",
  "translatedText": "먼저 x의 제곱근에서 평가되는 미스터리 함수로 정의될 x의 h라고 부르는 작은 도우미 함수를 소개하는 것이 좋습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.08,
  "end": 1071.96
 },
 {
  "input": "Said another way, h of x squared is the same thing as f of x.",
  "translatedText": "다르게 말하면, x의 h 제곱은 x의 f와 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1072.4,
  "end": 1076.02
 },
 {
  "input": "For example, in the back of your mind where you know that e to the negative x squared will happen to be one of the answers, this little helper function h would be e to the negative x.",
  "translatedText": "예를 들어, e의 음수 x 제곱이 답 중 하나가 될 것이라는 것을 알고 있는 마음 한구석에서 이 작은 도우미 함수 h는 음수 x에 대한 e가 될 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1076.7,
  "end": 1085.36
 },
 {
  "input": "But again, we're pretending like we don't know that.",
  "translatedText": "그런데 또 우리는 그걸 모르는 척 하고 있어요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.36,
  "end": 1087.76
 },
 {
  "input": "The reason for doing this is that the key property looks a little bit nicer if we phrase it in terms of this helper function, h.",
  "translatedText": "이렇게 하는 이유는 이 도우미 함수 h의 관점에서 표현하면 핵심 속성이 조금 더 좋아 보이기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.14,
  "end": 1094.26
 },
 {
  "input": "Because now what it's saying is if you take two arbitrary positive numbers and you add them up and evaluate h, it's the same thing as evaluating h on them separately and then multiplying the results.",
  "translatedText": "이제 이것이 말하는 것은 두 개의 임의의 양수를 취하고 이를 더해 h를 평가하는 경우, 이는 h를 개별적으로 평가한 다음 결과를 곱하는 것과 동일하다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1094.64,
  "end": 1104.56
 },
 {
  "input": "In a sense, it turns addition into multiplication.",
  "translatedText": "어떤 의미에서는 덧셈을 곱셈으로 바꾸는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.04,
  "end": 1107.38
 },
 {
  "input": "Some of you might see where this is going, but let's take a moment to walk through why this forces our hand.",
  "translatedText": "여러분 중 일부는 이것이 어디로 가는지 알 수 있지만 이것이 왜 우리 손을 강제하는지 잠시 살펴보겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.06,
  "end": 1112.94
 },
 {
  "input": "As a next step, you might want to pause and convince yourself that if this property is true for the sum of two numbers, this property also must be true if we add up an arbitrary number of inputs.",
  "translatedText": "다음 단계에서는 이 속성이 두 숫자의 합에 대해 true인 경우 임의 개수의 입력을 더해도 이 속성이 true여야 한다는 점을 잠시 멈추고 스스로 확신할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.94,
  "end": 1123.88
 },
 {
  "input": "To get a feel for why this is so constraining, think about plugging in a whole number, something like h of 5.",
  "translatedText": "이것이 왜 그렇게 제한적인지 이해하려면 h/5와 같은 정수를 대입하는 것을 생각해 보세요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.3,
  "end": 1130.52
 },
 {
  "input": "Because you can write 5 as 1 plus 1 plus 1 plus 1 plus 1, this key property means that it must equal h of 1 multiplied by itself 5 times.",
  "translatedText": "5는 1 더하기 1 더하기 1 더하기 1 더하기 1로 쓸 수 있기 때문에 이 핵심 속성은 h에 1을 5번 곱한 것과 같아야 함을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1131.3,
  "end": 1140.18
 },
 {
  "input": "Of course, there's nothing special about 5.",
  "translatedText": "물론 5에는 특별한 것이 없습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1140.76,
  "end": 1142.76
 },
 {
  "input": "I could have chosen any whole number n, and we'd be forced to conclude that the function looks like some number raised to the power n.",
  "translatedText": "나는 임의의 정수 n을 선택할 수 있었고, 우리는 함수가 n의 거듭제곱을 제곱한 어떤 숫자와 같다고 결론을 내리게 될 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.88,
  "end": 1149.62
 },
 {
  "input": "And let's go ahead and give that number a name, like b for the base of our exponential.",
  "translatedText": "그리고 계속해서 그 숫자에 지수의 밑수인 b와 같은 이름을 붙여 봅시다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1150.76,
  "end": 1154.84
 },
 {
  "input": "As a little mini exercise here, see if you can pause and take a moment to convince yourself that the same is true for a rational input, that if you plug in p over q to this function, it must look like this base b raised to the power p over q.",
  "translatedText": "여기서 작은 연습으로, 잠시 멈춰 합리적인 입력에 대해서도 마찬가지라는 것을 스스로 확신할 수 있는지 확인하십시오. p를 q에 연결하면 이 함수는 b를 2진수로 올려놓은 것처럼 보일 것입니다. q에 대한 p의 거듭제곱입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1156.08,
  "end": 1169.06
 },
 {
  "input": "And as a hint, you might want to think about adding that input to itself q different times.",
  "translatedText": "그리고 힌트로, 해당 입력을 여러 번 자체에 추가하는 것에 대해 생각해 볼 수도 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1170.48,
  "end": 1175.2
 },
 {
  "input": "And then because rational numbers are dense in the real number line, if we make one more pretty reasonable assumption that we only care about continuous functions, this is enough to force your hand completely and say that h has to be an exponential function, b to the power x, for all real number inputs x.",
  "translatedText": "그리고 유리수는 실수선에서 밀도가 높기 때문에, 우리가 연속 함수에만 관심이 있다는 꽤 합리적인 가정을 하나 더 한다면, 이것은 당신의 손을 완전히 강요하고 h가 지수 함수, b여야 한다고 말하기에 충분합니다. 모든 실수 입력 x에 대한 거듭제곱 x.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.62,
  "end": 1194.58
 },
 {
  "input": "I guess to be more precise I should say for all positive real inputs.",
  "translatedText": "더 정확하게 말하면 모든 긍정적인 실제 입력에 대해 말해야 할 것 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1195.3,
  "end": 1198.3
 },
 {
  "input": "The way we defined h, it's only taking in positive numbers.",
  "translatedText": "우리가 h를 정의한 방식은 양수만 취하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.3,
  "end": 1201.52
 },
 {
  "input": "Now, as we've gone over before, instead of writing down exponential functions as some base raised to the power x, mathematicians often like to write them as e to the power of some constant c times x.",
  "translatedText": "이제 이전에 살펴본 것처럼 지수 함수를 x 거듭제곱으로 쓰는 대신 수학자들은 종종 이를 상수 c 곱하기 x의 e 거듭제곱으로 쓰는 것을 좋아합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1202.5,
  "end": 1212.78
 },
 {
  "input": "Making the choice to always use e as a base while letting that constant c determine which specific exponential function you're talking about just makes everything much easier any time calculus comes wandering along your path.",
  "translatedText": "항상 e를 기본으로 사용하고 상수 c가 어떤 특정 지수 함수를 결정하도록 선택하면 미적분학이 경로를 따라 방황할 때마다 모든 것이 훨씬 쉬워집니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1213.26,
  "end": 1224.5
 },
 {
  "input": "And so this means that our target function f has to look like e to the power of some constant times x squared.",
  "translatedText": "그리고 이는 우리의 목표 함수 f가 e의 상수 곱하기 x 제곱의 거듭제곱과 같아야 함을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1225.64,
  "end": 1232.48
 },
 {
  "input": "The beauty is that that function is no longer something that was merely handed down to us from on high.",
  "translatedText": "아름다운 점은 그 기능이 더 이상 위에서 단순히 우리에게 물려주는 것이 아니라는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.6,
  "end": 1238.12
 },
 {
  "input": "Instead we started with these two different premises for how we wanted a distribution in two dimensions to behave, and we were drawn to the conclusion that the shape of the expression describing that distribution as a function of the radius away from the origin has to be e to the power of some constant times that radius squared.",
  "translatedText": "대신에 우리는 2차원의 분포가 어떻게 작동하기를 원하는지에 대해 이러한 두 가지 서로 다른 전제로 시작했으며, 원점에서 떨어진 반경의 함수로 해당 분포를 설명하는 표현의 모양은 다음과 같아야 한다는 결론에 도달했습니다. 반경의 제곱에 대한 일정한 시간의 거듭제곱입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.76,
  "end": 1255.16
 },
 {
  "input": "You'll remember I said earlier this answer will be off by a factor of a constant.",
  "translatedText": "앞서 이 답변은 상수 요소에 의해 달라질 것이라고 말한 것을 기억하실 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1256.32,
  "end": 1259.68
 },
 {
  "input": "We need to rescale it to make it a valid probability distribution, and geometrically you might think of that as scaling it so that the volume under the surface is equal to one.",
  "translatedText": "유효한 확률 분포를 만들기 위해 크기를 다시 조정해야 하며 기하학적으로 표면 아래의 부피가 1이 되도록 크기를 조정하는 것으로 생각할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1260.1,
  "end": 1267.86
 },
 {
  "input": "Now you might notice that for positive values of this constant in the exponent c, our function blows up to infinity in all directions, so the volume under that surface would be infinite, meaning it's not possible to renormalize.",
  "translatedText": "이제 지수 c에서 이 상수의 양수 값에 대해 함수가 모든 방향에서 무한대로 커지므로 해당 표면 아래의 볼륨이 무한해지며 다시 정규화가 불가능하다는 것을 알 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.94,
  "end": 1280.72
 },
 {
  "input": "You can't turn it into a probability distribution, and that leaves us with the last constraint, which is that this constant in the exponent has to be a negative number, and the specific value of that number determines the spread of the distribution.",
  "translatedText": "이를 확률 분포로 바꿀 수 없으며, 이는 지수의 이 상수가 음수여야 하고 해당 숫자의 특정 값이 분포의 확산을 결정한다는 마지막 제약 조건을 남깁니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1280.92,
  "end": 1292.56
 },
 {
  "input": "Ten years after Herschel wrote this, James Clerk Maxwell, who's most well known for having written down the fundamental equations for electricity and magnetism, independently stumbled across the same derivation.",
  "translatedText": "허셜이 이 글을 쓴 지 10년 후, 전기와 자기의 기본 방정식을 기록한 것으로 가장 잘 알려진 제임스 클러크 맥스웰(James Clerk Maxwell)이 독립적으로 동일한 유도를 우연히 발견했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.0,
  "end": 1303.92
 },
 {
  "input": "In his case he was doing it in three dimensions, since he was doing statistical mechanics and he was deriving a formula for the distribution for velocities of molecules in a gas.",
  "translatedText": "그의 경우에 그는 통계 역학을 하고 있었고 가스 내 분자 속도 분포에 대한 공식을 도출하고 있었기 때문에 3차원에서 그 일을 하고 있었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1304.22,
  "end": 1312.9
 },
 {
  "input": "But the logic all works out the same.",
  "translatedText": "그러나 논리는 모두 동일하게 작동합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1313.1,
  "end": 1315.1
 },
 {
  "input": "For you and me, if we view this as the defining property of a Gaussian, then it's a little bit less surprising that pi might make an appearance.",
  "translatedText": "여러분과 제가 이것을 가우스의 정의 속성으로 본다면 파이가 나타날 수 있다는 것은 조금 덜 놀라운 일입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1315.88,
  "end": 1323.4
 },
 {
  "input": "After all, circular symmetry was part of this defining property.",
  "translatedText": "결국 원형 대칭은 이 정의 속성의 일부였습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1323.94,
  "end": 1327.48
 },
 {
  "input": "More than that, it makes the clever proof that we saw earlier feel a little bit less out of the blue.",
  "translatedText": "게다가, 우리가 앞서 본 기발한 증명이 조금 덜 갑작스럽게 느껴지게 만듭니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1328.2,
  "end": 1332.74
 },
 {
  "input": "I mean, a key problem-solving principle in math is to use the defining features of your setup.",
  "translatedText": "내 말은, 수학의 핵심 문제 해결 원칙은 설정의 정의 기능을 사용하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.2,
  "end": 1338.02
 },
 {
  "input": "And if you had been primed by this Herschel-Maxwell derivation, where the defining property for a Gaussian is this coincidence of having a distribution that's both radially symmetric and also independent along each axis, then the very first step of our proof, which seemed so strange bumping the problem up one dimension, was really just a way of opening the door to let that defining property make itself visible.",
  "translatedText": "그리고 가우시안의 정의 속성이 방사상 대칭이고 각 축을 따라 독립적인 분포를 갖는 우연의 일치인 이 Herschel-Maxwell 유도에 의해 준비되었다면 우리 증명의 첫 번째 단계는 다음과 같습니다. 이상하게도 문제를 한 차원 위로 끌어올리는 것은 실제로 그 정의 속성 자체가 가시화되도록 문을 여는 방법일 뿐입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.52,
  "end": 1361.18
 },
 {
  "input": "And if you think back, the essence of the proof came down to using that radial symmetry on the one hand, and then also using the ability to factor the function on the other.",
  "translatedText": "그리고 다시 생각해보면, 증명의 본질은 한편으로는 방사형 대칭을 사용하고 다른 한편으로는 함수를 인수분해하는 능력을 사용하는 것이었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.04,
  "end": 1370.64
 },
 {
  "input": "From this standpoint, using both those facts feels less like a trick that happened to work, and more like an inevitable necessity.",
  "translatedText": "이러한 관점에서 볼 때 두 가지 사실을 모두 사용하는 것은 우연히 작동한 속임수라기보다는 불가피한 필수 사항처럼 느껴집니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1371.32,
  "end": 1378.24
 },
 {
  "input": "Nevertheless, thinking once again of our statistician's friend, this is still not entirely satisfying.",
  "translatedText": "그럼에도 불구하고, 우리 통계학자의 친구를 다시 한 번 생각해 보면, 이것은 여전히 완전히 만족스럽지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1380.32,
  "end": 1385.96
 },
 {
  "input": "Using the Herschel-Maxwell derivation, saying this property of a multi-dimensional distribution is what defines a Gaussian, well that presumes that we're already in some kind of multi-dimensional situation in the first place.",
  "translatedText": "Herschel-Maxwell 유도를 사용하여 다차원 분포의 속성이 가우시안을 정의하는 것이라고 말하면, 애초에 우리가 이미 일종의 다차원 상황에 있다고 가정합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1386.38,
  "end": 1397.64
 },
 {
  "input": "Much more commonly, the way that a normal distribution arises in practice doesn't feel spatial or geometric at all.",
  "translatedText": "훨씬 더 일반적으로 실제로 정규 분포가 발생하는 방식은 공간적이거나 기하학적인 느낌이 전혀 없습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1398.12,
  "end": 1404.64
 },
 {
  "input": "It stems from the central limit theorem, which is all about adding together many different independent variables.",
  "translatedText": "이는 다양한 독립 변수를 더하는 중심 극한 정리에서 유래합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1404.88,
  "end": 1410.3
 },
 {
  "input": "So to bring it all home here, what we need to do is explain why the function that's characterized by this Herschel-Maxwell derivation should be the same thing as the function that sits at the heart of the central limit theorem.",
  "translatedText": "따라서 모든 것을 여기로 가져오려면, 우리가 해야 할 일은 왜 이 허셜-맥스웰 유도의 특징이 되는 함수가 중심 극한 정리의 핵심에 있는 함수와 동일해야 하는지 설명하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1410.82,
  "end": 1421.78
 },
 {
  "input": "And at this point, those of you following along are probably going to make fun of me, I think it makes sense to pull this last step out as its own video.",
  "translatedText": "그리고 이 시점에서 따라오시는 분들은 아마 저를 비웃으실 텐데요, 이 마지막 단계를 자체 영상으로 뽑아내는 게 맞을 것 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.52,
  "end": 1429.68
 },
 {
  "input": "Oh, and one final footnote here.",
  "translatedText": "아, 그리고 여기에 마지막 각주가 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.26,
  "end": 1432.18
 },
 {
  "input": "After making a Patreon post about this particular project, one patron, who's a mathematician named Kevin Ega, shared something completely delightful that I had never seen before, which is that if you apply this integration trick in higher dimensions, it lets you derive the formulas for volumes of higher dimensional spheres.",
  "translatedText": "이 특정 프로젝트에 대한 Patreon 게시물을 작성한 후 Kevin Ega라는 수학자 한 후원자는 제가 이전에 본 적이 없는 완전히 즐거운 내용을 공유했습니다. 즉, 이 통합 트릭을 더 높은 차원에 적용하면 공식을 도출할 수 있다는 것입니다. 더 높은 차원의 구체의 볼륨에 대한 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1432.38,
  "end": 1448.78
 },
 {
  "input": "A very fun exercise, I'm leaving the details up on the screen for any viewers who are comfortable with integration by parts.",
  "translatedText": "매우 재미있는 연습입니다. 부분별 통합에 익숙한 시청자를 위해 세부 사항을 화면에 남겨 두었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.26,
  "end": 1454.78
 },
 {
  "input": "Thank you very much to Kevin for sharing that one, and thanks to all patrons, by the way, both for the support of the channel and also for all the feedback you offer on the early drafts of videos.",
  "translatedText": "해당 동영상을 공유해 주신 Kevin에게 진심으로 감사드리며, 채널 지원과 초기 동영상 초안에 대한 모든 피드백에 대해 모든 후원자 분들께 감사드립니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1455.26,
  "end": 1485.1
 }
]