[
 {
  "input": "You may have heard the phrase, the unreasonable effectiveness of mathematics in the natural sciences.",
  "translatedText": "సహజ శాస్త్రాలలో గణితశాస్త్రం యొక్క అసమంజసమైన ప్రభావం అనే పదబంధాన్ని మీరు విని ఉండవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 4.38
 },
 {
  "input": "This was the title of a paper by the physicist Eugene Wigner, but even more fun than the title is the way that he chooses to open it.",
  "translatedText": "ఇది భౌతిక శాస్త్రవేత్త యూజీన్ విగ్నర్ రాసిన కాగితం యొక్క శీర్షిక, కానీ టైటిల్ కంటే మరింత సరదాగా అతను దానిని తెరవడానికి ఎంచుకున్న మార్గం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 5.08,
  "end": 11.5
 },
 {
  "input": "The paper begins, quote, There is a story about two friends who were classmates in high school, talking about their jobs.",
  "translatedText": "పేపర్ ప్రారంభమవుతుంది, కోట్, హైస్కూల్‌లో క్లాస్‌మేట్స్ అయిన ఇద్దరు స్నేహితులు వారి ఉద్యోగాల గురించి మాట్లాడుకోవడం గురించి ఒక కథ ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.64,
  "end": 18.06
 },
 {
  "input": "One of them became a statistician and was working on population trends.",
  "translatedText": "వారిలో ఒకరు గణాంకవేత్త అయ్యారు మరియు జనాభా పోకడలపై పని చేస్తున్నారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.62,
  "end": 21.66
 },
 {
  "input": "They showed a reprint to their former classmate, and the reprint started, as usual, with the Gaussian distribution.",
  "translatedText": "వారు తమ పూర్వ సహవిద్యార్థికి పునఃముద్రణను చూపించారు మరియు పునఃముద్రణ యధావిధిగా, గాస్సియన్ పంపిణీతో ప్రారంభమైంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.06,
  "end": 26.98
 },
 {
  "input": "The statistician explained to the former classmate the meaning of the symbols for the actual population, the average population, and so on.",
  "translatedText": "గణాంక నిపుణుడు మాజీ సహవిద్యార్థికి వాస్తవ జనాభా, సగటు జనాభా మొదలైనవాటికి సంబంధించిన చిహ్నాల అర్థాన్ని వివరించాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.98,
  "end": 34.7
 },
 {
  "input": "The classmate was a bit incredulous and was not quite sure whether the statistician was pulling their leg.",
  "translatedText": "క్లాస్‌మేట్ కొంచెం నమ్మశక్యం కానివాడు మరియు గణాంకవేత్త వారి కాలును లాగుతున్నాడో లేదో ఖచ్చితంగా తెలియదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.14,
  "end": 39.84
 },
 {
  "input": "How can you know that?",
  "translatedText": "అది నీకెలా తెలుసు?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 40.22,
  "end": 41.12
 },
 {
  "input": "was the query.",
  "translatedText": "అనేది ప్రశ్న.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.26,
  "end": 41.76
 },
 {
  "input": "And what is this symbol over here?",
  "translatedText": "మరియు ఇక్కడ ఈ చిహ్నం ఏమిటి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.28,
  "end": 43.76
 },
 {
  "input": "Oh, said the statistician, this is pi.",
  "translatedText": "ఓహ్, ఇది పై అని గణాంకవేత్త చెప్పారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.38,
  "end": 46.82
 },
 {
  "input": "What is that?",
  "translatedText": "అది ఏమిటి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.34,
  "end": 47.9
 },
 {
  "input": "The ratio of the circumference of a circle to its diameter.",
  "translatedText": "వృత్తం యొక్క చుట్టుకొలత దాని వ్యాసానికి నిష్పత్తి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 48.6,
  "end": 51.08
 },
 {
  "input": "Well, now you're pushing the joke too far, said the classmate.",
  "translatedText": "సరే, ఇప్పుడు మీరు జోక్‌ని చాలా దూరం నెట్టివేస్తున్నారు, అన్నాడు క్లాస్‌మేట్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.0,
  "end": 54.42
 },
 {
  "input": "Surely the population has nothing to do with the circumference of a circle.",
  "translatedText": "ఖచ్చితంగా జనాభాకు వృత్తం చుట్టుకొలతతో సంబంధం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.42,
  "end": 57.96
 },
 {
  "input": "In the paper, Wigner then goes on to talk about the more general phenomenon of concepts and pure math seeming to find applications that extend strangely beyond what their definitions would suggest.",
  "translatedText": "పేపర్‌లో, విగ్నర్ భావనల యొక్క మరింత సాధారణ దృగ్విషయం మరియు స్వచ్ఛమైన గణితాన్ని వాటి నిర్వచనాలు సూచించే దానికంటే వింతగా విస్తరించే అప్లికేషన్‌లను కనుగొనడం గురించి మాట్లాడాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.28,
  "end": 68.48
 },
 {
  "input": "But I would like to stay focused on this particular anecdote and the question that the statistician's friend is getting at.",
  "translatedText": "కానీ నేను ఈ ప్రత్యేక వృత్తాంతంపై దృష్టి కేంద్రీకరించాలనుకుంటున్నాను మరియు గణాంకవేత్త యొక్క స్నేహితుడు అడుగుతున్న ప్రశ్న.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.94,
  "end": 74.76
 },
 {
  "input": "You see, there is a very beautiful and classic proof that explains the pi inside the formula for a normal distribution.",
  "translatedText": "మీరు చూడండి, సాధారణ పంపిణీ కోసం ఫార్ములా లోపల పైని వివరించే చాలా అందమైన మరియు క్లాసిక్ రుజువు ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 75.24,
  "end": 80.84
 },
 {
  "input": "And despite there being a number of other really great explanations online, see some links in the description, I cannot help but indulge in the pleasure of reanimating it here.",
  "translatedText": "మరియు ఆన్‌లైన్‌లో చాలా గొప్ప వివరణలు ఉన్నప్పటికీ, వివరణలోని కొన్ని లింక్‌లను చూడండి, నేను ఇక్కడ దాన్ని తిరిగి యానిమేట్ చేయడంలో ఆనందాన్ని పొందకుండా ఉండలేను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 80.84,
  "end": 89.72
 },
 {
  "input": "For one thing, there is a fun side note that I didn't learn until recently about how you can use this proof to derive the volumes of higher dimensional spheres.",
  "translatedText": "ఒక విషయం ఏమిటంటే, హై డైమెన్షనల్ గోళాల వాల్యూమ్‌లను పొందేందుకు మీరు ఈ రుజువును ఎలా ఉపయోగించవచ్చనే దాని గురించి నేను ఇటీవల వరకు నేర్చుకోని సరదా సైడ్ నోట్ ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 90.42,
  "end": 97.36
 },
 {
  "input": "But much more importantly than that, what I really want to do is try to go beyond the classic proof.",
  "translatedText": "కానీ దాని కంటే చాలా ముఖ్యమైనది, నేను నిజంగా చేయాలనుకుంటున్నది క్లాసిక్ ప్రూఫ్‌కు మించి వెళ్ళడానికి ప్రయత్నించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.28,
  "end": 103.0
 },
 {
  "input": "Consider this hypothetical statistician's friend.",
  "translatedText": "ఈ ఊహాత్మక గణాంకవేత్త స్నేహితుడిని పరిగణించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.56,
  "end": 106.06
 },
 {
  "input": "What I want to ask is, can we find an explanation that would satisfy their disbelief?",
  "translatedText": "నేను అడగాలనుకుంటున్నది ఏమిటంటే, వారి అవిశ్వాసాన్ని సంతృప్తిపరిచే వివరణను మనం కనుగొనగలమా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.38,
  "end": 110.7
 },
 {
  "input": "You see, they're not just asking for some pure math proof about a function that was handed down to them on high.",
  "translatedText": "మీరు చూడండి, వారు కేవలం ఒక ఫంక్షన్ గురించి స్వచ్ఛమైన గణిత రుజువు కోసం అడగడం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.84,
  "end": 115.98
 },
 {
  "input": "The friend's incredulity was that circles should have anything to do with population statistics.",
  "translatedText": "సర్కిల్‌లకు జనాభా గణాంకాలతో ఏదైనా సంబంధం ఉండాలని స్నేహితుడి నమ్మశక్యం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.54,
  "end": 121.58
 },
 {
  "input": "Until we fully draw that connecting line, we should consider the task incomplete.",
  "translatedText": "మేము ఆ అనుసంధాన రేఖను పూర్తిగా గీసే వరకు, మేము పనిని అసంపూర్ణంగా పరిగణించాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 122.06,
  "end": 126.18
 },
 {
  "input": "Those of you who watched the last video on the central limit theorem will have some of the backdrop here, because there we broke down the formula for a normal distribution, which is also called a Gaussian distribution.",
  "translatedText": "మీలో సెంట్రల్ లిమిట్ థియరమ్‌పై చివరి వీడియోని చూసిన వారికి ఇక్కడ కొంత బ్యాక్‌డ్రాప్ ఉంటుంది, ఎందుకంటే అక్కడ మేము సాధారణ పంపిణీకి సంబంధించిన ఫార్ములాను విడగొట్టాము, దీనిని గాస్సియన్ డిస్ట్రిబ్యూషన్ అని కూడా పిలుస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 127.0,
  "end": 136.68
 },
 {
  "input": "And when you strip away all of the different parameters and the constants, the basic function that describes the bell curve shape is e to the negative x squared.",
  "translatedText": "మరియు మీరు వివిధ పారామితులు మరియు స్థిరాంకాలన్నింటినీ తీసివేసినప్పుడు, బెల్ కర్వ్ ఆకారాన్ని వివరించే ప్రాథమిక విధి ప్రతికూల x స్క్వేర్డ్‌కు e అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.26,
  "end": 145.28
 },
 {
  "input": "And the reason that pi showed up in the final formula was that the area underneath this curve works out, as you will see in a couple minutes, to be the square root of pi.",
  "translatedText": "మరియు తుది ఫార్ములాలో pi చూపిన కారణం ఏమిటంటే, ఈ వక్రరేఖ కింద ఉన్న ప్రాంతం పని చేస్తుంది, మీరు రెండు నిమిషాల్లో pi యొక్క వర్గమూలంగా చూస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.92,
  "end": 155.34
 },
 {
  "input": "So what that meant for us was that at some point we needed to divide out by that square root of pi to make sure that the area under the curve is one, which is a requirement before you can interpret it as a probability distribution.",
  "translatedText": "కాబట్టి మాకు అర్థం ఏమిటంటే, వక్రరేఖ కింద ఉన్న ప్రాంతం ఒకటి అని నిర్ధారించుకోవడానికి మనం ఏదో ఒక సమయంలో పై యొక్క వర్గమూలంతో విభజించాల్సిన అవసరం ఉంది, మీరు దానిని సంభావ్యత పంపిణీగా అర్థం చేసుకోవడానికి ముందు ఇది అవసరం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.34,
  "end": 166.66
 },
 {
  "input": "In the full formula that you would see, say, in a stats book, this gets mixed together with some of the other constants, but in its purest form that pi originates from the area underneath this curve.",
  "translatedText": "గణాంకాల పుస్తకంలో మీరు చూసే పూర్తి ఫార్ములాలో, ఇది కొన్ని ఇతర స్థిరాంకాలతో కలిపి ఉంటుంది, కానీ దాని స్వచ్ఛమైన రూపంలో పై ఈ వక్రరేఖ కింద ఉన్న ప్రాంతం నుండి ఉద్భవించింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.24,
  "end": 178.1
 },
 {
  "input": "So step number one for you and me is to explain that area, but I want to emphasize it's not the last step.",
  "translatedText": "కాబట్టి మీరు మరియు నా కోసం మొదటి దశ ఆ ప్రాంతాన్ని వివరించడం, కానీ ఇది చివరి దశ కాదని నేను నొక్కి చెప్పాలనుకుంటున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.12,
  "end": 185.06
 },
 {
  "input": "To satisfy the question raised by that hypothetical statistician's friend, we need to go further.",
  "translatedText": "ఆ ఊహాత్మక గణాంకవేత్త స్నేహితుడు లేవనెత్తిన ప్రశ్నను సంతృప్తి పరచడానికి, మనం మరింత ముందుకు వెళ్లాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 185.38,
  "end": 190.34
 },
 {
  "input": "We need to also answer why is it that this function e to the negative x squared is so special in the first place?",
  "translatedText": "ఈ ఫంక్షన్ e నుండి నెగటివ్ x స్క్వేర్డ్ వరకు ఎందుకు చాలా ప్రత్యేకమైనది అనేదానికి కూడా మనం సమాధానం ఇవ్వాలి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.44,
  "end": 195.86
 },
 {
  "input": "I mean, there are lots of different formulas you could write down that would give a shape that, you know, vaguely bulges in the middle and tapers out on either side.",
  "translatedText": "నా ఉద్దేశ్యం, మధ్యలో అస్పష్టంగా ఉబ్బెత్తుగా మరియు ఇరువైపులా కుచించుకుపోయే ఆకృతిని ఇవ్వగల అనేక విభిన్న సూత్రాలు మీరు వ్రాసుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.86,
  "end": 204.1
 },
 {
  "input": "So why is it that this specific function holds such a special place in statistics?",
  "translatedText": "కాబట్టి ఈ నిర్దిష్ట ఫంక్షన్ గణాంకాలలో ఇంత ప్రత్యేక స్థానాన్ని ఎందుకు కలిగి ఉంది?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.64,
  "end": 208.86
 },
 {
  "input": "To phrase our goal another way, can we find a connection between the proof that shows why pi shows up and the central limit theorem, which, as we talked about in the last video, is the thing that explains when you can expect a normal distribution to arise in nature?",
  "translatedText": "మా లక్ష్యాన్ని మరొక విధంగా చెప్పాలంటే, పై ఎందుకు చూపబడుతుందో చూపే రుజువు మరియు సెంట్రల్ లిమిట్ థియరం మధ్య సంబంధాన్ని కనుగొనగలమా, ఇది మేము గత వీడియోలో మాట్లాడినట్లుగా, మీరు సాధారణ పంపిణీని ఎప్పుడు ఆశించవచ్చో వివరించే విషయం ప్రకృతిలో ఉద్భవించాలా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 209.74,
  "end": 224.04
 },
 {
  "input": "So with all of that as the goal, first things first, let's dig into the classic and very beautiful proof.",
  "translatedText": "కాబట్టి వీటన్నింటిని లక్ష్యంగా చేసుకుని, ముందుగా మొదటి విషయాలు, క్లాసిక్ మరియు చాలా అందమైన రుజువుని తీయండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.7,
  "end": 229.28
 },
 {
  "input": "All right, when you want to find the area underneath a curve, the tool for doing that is an integral.",
  "translatedText": "సరే, మీరు వక్రరేఖకు దిగువన ఉన్న ప్రాంతాన్ని కనుగొనాలనుకున్నప్పుడు, దానిని చేయడానికి సాధనం ఒక సమగ్రమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.76,
  "end": 236.76
 },
 {
  "input": "As a quick reminder for how you might read this notation, you might imagine approximating that area with many different rectangles under the curve, where the height of each such rectangle is the value of the function above that point, in this case, e to the negative x squared for a certain input x, and the width is some little number that we're calling dx.",
  "translatedText": "మీరు ఈ సంజ్ఞామానాన్ని ఎలా చదవవచ్చనే దాని కోసం శీఘ్ర రిమైండర్‌గా, మీరు ఆ ప్రాంతాన్ని వక్రరేఖ క్రింద అనేక విభిన్న దీర్ఘచతురస్రాలతో అంచనా వేయవచ్చు, ఇక్కడ అటువంటి ప్రతి దీర్ఘచతురస్రం యొక్క ఎత్తు ఆ పాయింట్ పైన ఉన్న ఫంక్షన్ యొక్క విలువ, ఈ సందర్భంలో, ఇ నిర్దిష్ట ఇన్‌పుట్ x కోసం నెగెటివ్ x స్క్వేర్ చేయబడింది మరియు వెడల్పు అనేది మనం dx అని పిలుస్తున్న కొంత సంఖ్య.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.26,
  "end": 253.8
 },
 {
  "input": "We need to add up the areas of all these rectangles, for values of x ranging from negative infinity up to infinity, and the use of that notation dx is kind of meant to imply you shouldn't think of any specific width, but instead you ask, as the chosen width for your rectangles gets thinner and thinner, what does this sum of all those areas approach?",
  "translatedText": "ప్రతికూల అనంతం నుండి అనంతం వరకు ఉన్న x విలువల కోసం మేము ఈ దీర్ఘచతురస్రాల ప్రాంతాలన్నింటిని జోడించాలి మరియు ఆ సంజ్ఞామానం dx యొక్క ఉపయోగం మీరు నిర్దిష్ట వెడల్పు గురించి ఆలోచించకూడదని సూచించడానికి ఉద్దేశించబడింది, కానీ బదులుగా మీరు మీ దీర్ఘ చతురస్రాల కోసం ఎంచుకున్న వెడల్పు సన్నగా మరియు సన్నగా మారుతున్నందున, ఆ ప్రాంతాలన్నింటిలో ఈ మొత్తం దేనికి చేరుకుంటుంది?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 254.42,
  "end": 271.84
 },
 {
  "input": "Of course, all of that is just notation unless you provide a way to answer that question, and the magic of calculus is that it provides just that, at least usually.",
  "translatedText": "వాస్తవానికి, మీరు ఆ ప్రశ్నకు సమాధానమివ్వడానికి ఒక మార్గాన్ని అందించకపోతే అదంతా కేవలం సంజ్ఞామానం మాత్రమే, మరియు కాలిక్యులస్ యొక్క మాయాజాలం ఏమిటంటే అది కనీసం సాధారణంగా అయినా అది అందిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.38,
  "end": 280.38
 },
 {
  "input": "You see, usually the procedure here would be to find some function whose derivative is equal to the stuff we have on the inside, e to the negative x squared.",
  "translatedText": "మీరు చూస్తారు, సాధారణంగా ఇక్కడ ఉన్న విధానం ఏదైనా ఫంక్షన్‌ని కనుగొనడం, దీని ఉత్పన్నం మనం లోపల ఉన్న అంశాలకు సమానం, ఇ నెగటివ్ x స్క్వేర్డ్‌కు సమానం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.86,
  "end": 288.56
 },
 {
  "input": "In other words, we want to find an antiderivative of that function.",
  "translatedText": "మరో మాటలో చెప్పాలంటే, మేము ఆ ఫంక్షన్ యొక్క యాంటీడెరివేటివ్‌ను కనుగొనాలనుకుంటున్నాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.1,
  "end": 291.88
 },
 {
  "input": "The problem is, for this particular function, it is provably not possible to find such an antiderivative.",
  "translatedText": "సమస్య ఏమిటంటే, ఈ నిర్దిష్ట ఫంక్షన్ కోసం, అటువంటి యాంటీడెరివేటివ్‌ను కనుగొనడం సాధ్యం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.56,
  "end": 298.08
 },
 {
  "input": "It's a little weird and beyond the scope of what I want to talk about here, but basically, even though there exists an antiderivative, it is a well-defined function, you cannot express what that antiderivative is using all our usual tools, like polynomial expressions, trig functions, exponentials, or any way to mix them together.",
  "translatedText": "ఇది కొంచెం అసహజమైనది మరియు నేను ఇక్కడ మాట్లాడాలనుకుంటున్న దాని పరిధికి మించినది, కానీ ప్రాథమికంగా, యాంటీడెరివేటివ్ ఉన్నప్పటికీ, ఇది బాగా నిర్వచించబడిన ఫంక్షన్, బహుపది వంటి మా సాధారణ సాధనాలన్నింటినీ ఆ యాంటీడెరివేటివ్ ఉపయోగిస్తుందో మీరు వ్యక్తపరచలేరు. వ్యక్తీకరణలు, ట్రిగ్ ఫంక్షన్‌లు, ఎక్స్‌పోనెన్షియల్‌లు లేదా వాటిని కలపడానికి ఏదైనా మార్గం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.74,
  "end": 314.66
 },
 {
  "input": "So finding this area requires a bit of cleverness.",
  "translatedText": "కాబట్టి ఈ ప్రాంతాన్ని కనుగొనడానికి కొంచెం తెలివి అవసరం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.26,
  "end": 317.52
 },
 {
  "input": "There needs to be a new trick that we bring to bear.",
  "translatedText": "మేము భరించే కొత్త ట్రిక్ ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.6,
  "end": 319.46
 },
 {
  "input": "And the first step to this trick is easily the most absurd.",
  "translatedText": "మరియు ఈ ట్రిక్కి మొదటి అడుగు సులభంగా అత్యంత అసంబద్ధమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.94,
  "end": 322.38
 },
 {
  "input": "We start by bumping things up one dimension, so that instead of asking for the area under a bell curve, we ask for the volume underneath this kind of bell surface.",
  "translatedText": "మేము ఒక కోణాన్ని పెంచడం ద్వారా ప్రారంభిస్తాము, తద్వారా బెల్ కర్వ్ కింద ఉన్న ప్రాంతాన్ని అడగడానికి బదులుగా, మేము ఈ రకమైన బెల్ ఉపరితలం క్రింద ఉన్న వాల్యూమ్‌ను అడుగుతాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.6,
  "end": 331.36
 },
 {
  "input": "You could rightly ask, why would you do that?",
  "translatedText": "మీరు సరిగ్గా అడగవచ్చు, మీరు ఎందుకు అలా చేస్తారు?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.36,
  "end": 334.34
 },
 {
  "input": "Who ordered another dimension?",
  "translatedText": "మరొక కోణాన్ని ఎవరు ఆదేశించారు?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.42,
  "end": 335.58
 },
 {
  "input": "And I'll admit, it's not terribly motivated right now, other than to say, watch what happens when we just try it.",
  "translatedText": "మరియు నేను ఒప్పుకుంటాను, ఇది ప్రస్తుతం భయంకరంగా ప్రేరేపించబడలేదు, చెప్పడమే కాకుండా, మనం దీన్ని ప్రయత్నించినప్పుడు ఏమి జరుగుతుందో చూడండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.32,
  "end": 341.62
 },
 {
  "input": "And in general, with hard problems, it's never a bad idea to try solving cousins of the problem, since that can help you get a little bit of momentum and insight.",
  "translatedText": "మరియు సాధారణంగా, కఠినమైన సమస్యలతో, సమస్య యొక్క దాయాదులను పరిష్కరించడానికి ప్రయత్నించడం ఎప్పుడూ చెడ్డ ఆలోచన కాదు, ఎందుకంటే ఇది మీకు కొంచెం ఊపందుకోవడం మరియు అంతర్దృష్టిని పొందడంలో సహాయపడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.7,
  "end": 348.64
 },
 {
  "input": "To be clear on how this higher dimensional function is defined, it takes in two different inputs, x and y, which we might think of as a point on the xy-plane.",
  "translatedText": "ఈ అధిక డైమెన్షనల్ ఫంక్షన్ ఎలా నిర్వచించబడుతుందో స్పష్టంగా చెప్పాలంటే, ఇది x మరియు y అనే రెండు వేర్వేరు ఇన్‌పుట్‌లను తీసుకుంటుంది, వీటిని మనం xy-ప్లేన్‌లో పాయింట్‌గా భావించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.56,
  "end": 357.12
 },
 {
  "input": "And the way to think about it is to consider the distance from that point to the origin, which I'll label as r, and then to plug in that distance to our original bell curve function, we take e to the negative r squared.",
  "translatedText": "మరియు దాని గురించి ఆలోచించడానికి మార్గం ఏమిటంటే, ఆ బిందువు నుండి మూలానికి ఉన్న దూరాన్ని పరిగణనలోకి తీసుకోవడం, నేను r అని లేబుల్ చేస్తాను, ఆపై ఆ దూరాన్ని మన అసలు బెల్ కర్వ్ ఫంక్షన్‌కు ప్లగ్ చేయడానికి, మేము eని నెగటివ్ r స్క్వేర్డ్‌కి తీసుకువెళతాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.46,
  "end": 368.42
 },
 {
  "input": "You might notice the lines I've drawn on this diagram make a right triangle.",
  "translatedText": "ఈ రేఖాచిత్రంలో నేను గీసిన పంక్తులు లంబ త్రిభుజంగా మారడాన్ని మీరు గమనించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 368.42,
  "end": 372.18
 },
 {
  "input": "So by the Pythagorean theorem, x squared plus y squared equals r squared.",
  "translatedText": "కాబట్టి పైథాగరియన్ సిద్ధాంతం ప్రకారం, x స్క్వేర్డ్ ప్లస్ y స్క్వేర్డ్ r వర్గానికి సమానం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.82,
  "end": 376.14
 },
 {
  "input": "So in the function I have written, where you see x squared plus y squared, you can think in the back of your mind, that's really the square of the distance from the point to the origin.",
  "translatedText": "కాబట్టి నేను వ్రాసిన ఫంక్షన్‌లో, మీరు ఎక్కడ x స్క్వేర్డ్ ప్లస్ y స్క్వేర్డ్‌ని చూస్తారో, మీరు మీ మనస్సు వెనుక ఆలోచించవచ్చు, అది నిజంగా పాయింట్ నుండి మూలానికి ఉన్న దూరం యొక్క వర్గమే.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 376.8,
  "end": 384.46
 },
 {
  "input": "The main thing to notice here is how this gives our function a kind of circular symmetry, in the sense that all of the inputs that sit on a given circle have the same output.",
  "translatedText": "ఇక్కడ గమనించవలసిన ప్రధాన విషయం ఏమిటంటే, ఇది మన ఫంక్షన్‌కు ఒక రకమైన వృత్తాకార సమరూపతను ఎలా ఇస్తుంది, అంటే ఇచ్చిన సర్కిల్‌పై కూర్చునే అన్ని ఇన్‌పుట్‌లు ఒకే అవుట్‌పుట్‌ను కలిగి ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.02,
  "end": 392.98
 },
 {
  "input": "And so when we graph this function in three dimensions, it means it has a rotational symmetry about the z-axis.",
  "translatedText": "కాబట్టి మనం ఈ ఫంక్షన్‌ను మూడు కోణాలలో గ్రాఫ్ చేసినప్పుడు, ఇది z- అక్షం గురించి భ్రమణ సమరూపతను కలిగి ఉందని అర్థం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.72,
  "end": 399.38
 },
 {
  "input": "Math tends to reward you when you respect its symmetries, so for our question of computing the volume underneath this surface, what we're going to do is respect that symmetry, and imagine integrating together a bunch of thin little cylinders underneath that surface.",
  "translatedText": "గణితం మీరు దాని సమరూపతలను గౌరవించినప్పుడు మీకు బహుమతిని అందజేస్తుంది, కాబట్టి ఈ ఉపరితలం క్రింద వాల్యూమ్‌ను గణించాలనే మా ప్రశ్నకు, మేము చేయబోయేది ఆ సమరూపతను గౌరవించడం మరియు ఆ ఉపరితలం క్రింద సన్నని చిన్న సిలిండర్‌ల సమూహాన్ని ఏకీకృతం చేయడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.48,
  "end": 413.48
 },
 {
  "input": "Here, making this a little more quantitative, let's focus on just one of those cylindrical shells, where its area is going to be the circumference of that shell times the height.",
  "translatedText": "ఇక్కడ, దీన్ని కొంచెం పరిమాణాత్మకంగా చేస్తూ, ఆ స్థూపాకార షెల్‌లలో ఒకదానిపై దృష్టి పెడతాము, ఇక్కడ దాని వైశాల్యం ఆ షెల్ యొక్క చుట్టుకొలత ఎత్తు కంటే ఎక్కువ ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.38,
  "end": 423.1
 },
 {
  "input": "You might imagine it as something like the label on a soup can that we can unwrap into a rectangle.",
  "translatedText": "మేము దీర్ఘచతురస్రాకారంలో విప్పగలిగే సూప్ క్యాన్‌పై ఉన్న లేబుల్ లాగా మీరు దీనిని ఊహించుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.5,
  "end": 428.1
 },
 {
  "input": "The circumference of the cylinder, which is the top side of that rectangle, is going to be 2 pi times the radius.",
  "translatedText": "ఆ దీర్ఘచతురస్రం యొక్క పైభాగంలో ఉన్న సిలిండర్ చుట్టుకొలత, వ్యాసార్థానికి 2 pi రెట్లు ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.82,
  "end": 434.26
 },
 {
  "input": "And then the height of our cylinder, the other side of our rectangle, is the height of the surface at this point, which by definition is the value of our function associated with that radius, which like I said earlier you can think of as e to the negative r squared.",
  "translatedText": "ఆపై మన దీర్ఘచతురస్రం యొక్క మరొక వైపు మా సిలిండర్ యొక్క ఎత్తు, ఈ సమయంలో ఉపరితలం యొక్క ఎత్తు, ఇది నిర్వచనం ప్రకారం ఆ వ్యాసార్థంతో అనుబంధించబడిన మా ఫంక్షన్ యొక్క విలువ, నేను ఇంతకు ముందు చెప్పినట్లుగా మీరు ఇ ప్రతికూల r వర్గానికి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 435.16,
  "end": 448.36
 },
 {
  "input": "The real way you want to think about this is to give that cylinder a little bit of thickness, which we'll call dr, so that the volume that it represents is approximately that area we just looked at multiplied by this thickness dr.",
  "translatedText": "మీరు దీని గురించి ఆలోచించాలనుకునే నిజమైన మార్గం ఏమిటంటే, ఆ సిలిండర్‌కు కొంచెం మందం ఇవ్వడం, దానిని మనం dr అని పిలుస్తాము, తద్వారా అది సూచించే వాల్యూమ్ సుమారుగా మనం చూసే ప్రాంతాన్ని ఈ మందంతో గుణించబడుతుంది dr.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.38,
  "end": 460.98
 },
 {
  "input": "Our task now is to integrate together, or add together, all of these different cylinders as r ranges between 0 and infinity.",
  "translatedText": "ఇప్పుడు మా పని ఏమిటంటే, ఈ విభిన్న సిలిండర్‌లన్నింటినీ 0 మరియు అనంతం మధ్య r పరిధులుగా ఏకీకృతం చేయడం లేదా కలపడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.6,
  "end": 468.82
 },
 {
  "input": "Or more precisely, we consider what happens as that thickness gets thinner and thinner, approaching 0, and we add together the volumes of the many many many different thin cylinders that sit underneath that curve.",
  "translatedText": "లేదా మరింత ఖచ్చితంగా చెప్పాలంటే, ఆ మందం సన్నగా మరియు సన్నగా, 0కి చేరుకునేటప్పుడు ఏమి జరుగుతుందో మేము పరిశీలిస్తాము మరియు ఆ వక్రరేఖ క్రింద కూర్చున్న అనేక అనేక విభిన్న సన్నని సిలిండర్‌ల వాల్యూమ్‌లను మేము కలుపుతాము.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 469.34,
  "end": 479.12
 },
 {
  "input": "You might think this is just a harder version of what we were looking at earlier, three dimensions should be more complicated than two.",
  "translatedText": "ఇది మేము ఇంతకు ముందు చూస్తున్న దాని యొక్క కఠినమైన సంస్కరణ అని మీరు అనుకోవచ్చు, మూడు కోణాలు రెండు కంటే క్లిష్టంగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 481.56,
  "end": 487.86
 },
 {
  "input": "But actually, something very helpful has happened.",
  "translatedText": "కానీ నిజానికి, చాలా ఉపయోగకరమైనది జరిగింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.56,
  "end": 490.48
 },
 {
  "input": "First let me clean up a little by factoring the pi outside that integral.",
  "translatedText": "మొదట ఆ ఇంటిగ్రల్ వెలుపల పైని కారకం చేయడం ద్వారా కొంచెం శుభ్రం చేయనివ్వండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.14,
  "end": 494.0
 },
 {
  "input": "Now the stuff inside that integral, having picked up this term 2r, does have an antiderivative.",
  "translatedText": "ఇప్పుడు ఆ ఇంటిగ్రల్ లోపల ఉన్న అంశాలు, ఈ పదం 2rని ఎంచుకున్నప్పుడు, యాంటీడెరివేటివ్‌ని కలిగి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.56,
  "end": 500.54
 },
 {
  "input": "We can now apply the usual tactics of calculus.",
  "translatedText": "మనం ఇప్పుడు కాలిక్యులస్ యొక్క సాధారణ వ్యూహాలను అన్వయించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.74,
  "end": 502.98
 },
 {
  "input": "Specifically, that whole inside expression is the derivative of negative e to the negative r squared.",
  "translatedText": "ప్రత్యేకించి, ఆ మొత్తం లోపల వ్యక్తీకరణ ప్రతికూల r స్క్వేర్డ్ నుండి ప్రతికూల e నుండి ఉత్పన్నం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 503.64,
  "end": 509.34
 },
 {
  "input": "And so, those of you comfortable with calculus know what to do from here.",
  "translatedText": "కాబట్టి, మీలో కాలిక్యులస్‌తో సౌకర్యంగా ఉన్నవారికి ఇక్కడ నుండి ఏమి చేయాలో తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.16,
  "end": 513.14
 },
 {
  "input": "We take that antiderivative and plug in the upper bound, which is negative infinity squared, and that gives us 0, or speaking a little bit more precisely, if you consider the limit of this expression as the input approaches infinity, the limiting value is 0, and we subtract off the value of that antiderivative at the lower bound, 0, which in this case is negative 1.",
  "translatedText": "మేము ఆ యాంటీడెరివేటివ్‌ని తీసుకుంటాము మరియు ఎగువ బౌండ్‌ను ప్లగ్ ఇన్ చేయండి, ఇది ప్రతికూల అనంతం స్క్వేర్డ్, మరియు అది మాకు 0 ఇస్తుంది లేదా కొంచెం ఖచ్చితంగా మాట్లాడితే, ఇన్‌పుట్ అనంతానికి చేరుకునేటప్పుడు ఈ వ్యక్తీకరణ యొక్క పరిమితిని మీరు పరిగణించినట్లయితే, పరిమితి విలువ 0 , మరియు మేము ఆ యాంటిడెరివేటివ్ విలువను దిగువ బౌండ్ వద్ద తీసివేస్తాము, 0, ఈ సందర్భంలో ప్రతికూలమైనది 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.38,
  "end": 532.5
 },
 {
  "input": "So all in all, the whole integral just works out to be 1, which means all we're left with is that factor out in front, pi.",
  "translatedText": "కాబట్టి మొత్తం మీద, మొత్తం సమగ్రం కేవలం 1గా పని చేస్తుంది, అంటే మనకు మిగిలి ఉన్నది ముందు, పై అనే అంశం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 532.98,
  "end": 539.0
 },
 {
  "input": "Evidently, the volume underneath this bell surface is pi.",
  "translatedText": "స్పష్టంగా, ఈ బెల్ ఉపరితలం క్రింద ఉన్న వాల్యూమ్ pi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.72,
  "end": 542.94
 },
 {
  "input": "And I'll point out in this case, it's not wild that pi shows up, because the surface has this intrinsic circular symmetry.",
  "translatedText": "మరియు నేను ఈ సందర్భంలో ఎత్తి చూపుతాను, పై చూపు కనిపించడం విడ్డూరం కాదు, ఎందుకంటే ఉపరితలం ఈ అంతర్గత వృత్తాకార సమరూపతను కలిగి ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.24,
  "end": 550.0
 },
 {
  "input": "Still, you might wonder, how does that help us?",
  "translatedText": "అయినప్పటికీ, మీరు ఆశ్చర్యపోవచ్చు, అది మనకు ఎలా సహాయం చేస్తుంది?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 550.9,
  "end": 553.06
 },
 {
  "input": "As I said, throughout math, if you face a hard problem, solving an adjacent problem can be unexpectedly helpful as a next step.",
  "translatedText": "నేను చెప్పినట్లుగా, గణితంలో, మీరు కఠినమైన సమస్యను ఎదుర్కొంటే, పక్కనే ఉన్న సమస్యను పరిష్కరించడం తదుపరి దశగా ఊహించని విధంగా సహాయపడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.56,
  "end": 559.78
 },
 {
  "input": "And in this case, it's helpful not just for building intuition, but we can directly relate the three-dimensional graph to our two-dimensional graph by analyzing the volume in a second, different way.",
  "translatedText": "మరియు ఈ సందర్భంలో, ఇది అంతర్ దృష్టిని నిర్మించడానికి మాత్రమే ఉపయోగపడుతుంది, అయితే వాల్యూమ్‌ను రెండవ, భిన్నమైన రీతిలో విశ్లేషించడం ద్వారా త్రిమితీయ గ్రాఫ్‌ను మన ద్విమితీయ గ్రాఫ్‌కు నేరుగా సంబంధం కలిగి ఉండవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.78,
  "end": 569.92
 },
 {
  "input": "You see, the more general way to approach volumes underneath surfaces is to think of chopping it up into slices that are all parallel to one of the axes.",
  "translatedText": "మీరు చూస్తారు, ఉపరితలాల కింద వాల్యూమ్‌లను చేరుకోవడానికి మరింత సాధారణ మార్గం ఏమిటంటే, దానిని అక్షాలలో ఒకదానికి సమాంతరంగా ఉండే ముక్కలుగా కత్తిరించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.4,
  "end": 578.88
 },
 {
  "input": "For example, all these slices that are parallel to the x-axis.",
  "translatedText": "ఉదాహరణకు, x-అక్షానికి సమాంతరంగా ఉండే ఈ స్లైస్‌లన్నీ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.3,
  "end": 582.22
 },
 {
  "input": "For example, this right here is a slice that corresponds to the plane y equals 0.",
  "translatedText": "ఉదాహరణకు, ఇక్కడ ఉన్న స్లైస్ y 0కి సమానం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.06,
  "end": 588.34
 },
 {
  "input": "You might notice it looks just like a bell curve, and if we write out the function, this should actually make a lot of sense.",
  "translatedText": "ఇది బెల్ కర్వ్ లాగా కనిపిస్తుందని మీరు గమనించవచ్చు మరియు మేము ఫంక్షన్‌ను వ్రాస్తే, ఇది వాస్తవానికి చాలా అర్ధవంతం కావాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.34,
  "end": 593.76
 },
 {
  "input": "You could just plug in y equals 0, but to help see what happens with other slices, notice how, thanks to the rules of exponentiation, we could also write our function as e to the negative x squared times e to the negative y squared.",
  "translatedText": "మీరు కేవలం yకి సమానం 0ని ప్లగ్ చేయవచ్చు, కానీ ఇతర స్లైస్‌లతో ఏమి జరుగుతుందో చూడటంలో సహాయపడటానికి, ఎక్స్‌పోనెన్షియేషన్ నియమాలకు ధన్యవాదాలు, మేము మా ఫంక్షన్‌ను e నుండి నెగటివ్ x స్క్వేర్డ్ టైమ్స్ ఇ నుండి నెగెటివ్ y స్క్వేర్డ్‌కి ఎలా వ్రాయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 593.98,
  "end": 605.08
 },
 {
  "input": "It factors out nicely.",
  "translatedText": "ఇది చక్కగా కారణమవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 605.16,
  "end": 606.48
 },
 {
  "input": "On this slice, that e to the negative y squared is just a number, specifically the number 1.",
  "translatedText": "ఈ స్లైస్‌లో, ఆ e నుండి నెగిటివ్ y స్క్వేర్డ్ కేవలం ఒక సంఖ్య, ప్రత్యేకంగా సంఖ్య 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 607.28,
  "end": 612.28
 },
 {
  "input": "So this is the same graph we've seen before, e to the negative x squared, meaning that the area of this slice is exactly the thing that we're looking for.",
  "translatedText": "కాబట్టి ఇది మనం ఇంతకు ముందు చూసిన అదే గ్రాఫ్, ఇ నుండి నెగటివ్ x స్క్వేర్డ్, అంటే ఈ స్లైస్ యొక్క వైశాల్యం ఖచ్చితంగా మనం వెతుకుతున్న విషయం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 612.84,
  "end": 620.08
 },
 {
  "input": "It's the mystery constant, which I'm going to give the name c.",
  "translatedText": "ఇది మిస్టరీ స్థిరాంకం, నేను సి పేరు ఇవ్వబోతున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.5,
  "end": 623.22
 },
 {
  "input": "What's nice is there's nothing really special about this particular slice.",
  "translatedText": "విశేషం ఏమిటంటే, ఈ ప్రత్యేక స్లైస్‌లో ప్రత్యేకంగా ఏమీ లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.98,
  "end": 627.1
 },
 {
  "input": "If we chose a different slice corresponding to a different y value, it corresponds to multiplying this curve by a different number.",
  "translatedText": "మేము వేరొక y విలువకు అనుగుణంగా వేరొక స్లైస్‌ని ఎంచుకుంటే, అది ఈ వక్రతను వేరొక సంఖ్యతో గుణించడానికి అనుగుణంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.64,
  "end": 634.08
 },
 {
  "input": "So it's the same basic shape, just scaled down by that number, meaning its area is the same as our mystery constant, just scaled down by some number.",
  "translatedText": "కనుక ఇది అదే ప్రాథమిక ఆకారం, కేవలం ఆ సంఖ్యతో స్కేల్ చేయబడింది, అంటే దాని ప్రాంతం మన రహస్య స్థిరాంకం వలె ఉంటుంది, కొంత సంఖ్యతో తగ్గించబడింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.52,
  "end": 642.54
 },
 {
  "input": "That's pretty cool.",
  "translatedText": "చాలా బాగుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.54,
  "end": 643.72
 },
 {
  "input": "Each one of these slices has the same basic shape, just rescaled in the vertical direction, which, by the way, is not at all true for most two-variable functions.",
  "translatedText": "ఈ స్లైస్‌లలో ప్రతి ఒక్కటి ఒకే ప్రాథమిక ఆకారాన్ని కలిగి ఉంటుంది, కేవలం నిలువు దిశలో రీస్కేల్ చేయబడింది, ఇది చాలా వరకు రెండు-వేరియబుల్ ఫంక్షన్‌లకు అస్సలు నిజం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 643.98,
  "end": 652.26
 },
 {
  "input": "This is very much dependent on the fact that we were able to factor our function into one part that's just dependent on the y and another part that's just dependent on the x.",
  "translatedText": "ఇది మన ఫంక్షన్‌ని yపై ఆధారపడిన ఒక భాగం మరియు xపై ఆధారపడి ఉండే మరొక భాగం అనే అంశం మీద ఆధారపడి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.72,
  "end": 661.2
 },
 {
  "input": "Now, to think about the volume underneath this whole surface, here's another way we could phrase it.",
  "translatedText": "ఇప్పుడు, ఈ మొత్తం ఉపరితలం క్రింద ఉన్న వాల్యూమ్ గురించి ఆలోచించడానికి, మేము దానిని పదబంధం చేయగల మరొక మార్గం ఇక్కడ ఉంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.04,
  "end": 666.76
 },
 {
  "input": "We're going to compute another integral that ranges from y equals negative infinity up to infinity, where the term inside that integral tells us the area of each one of those slices.",
  "translatedText": "మేము y నుండి అనంతం వరకు ప్రతికూల అనంతం వరకు ఉండే మరొక సమగ్రతను గణించబోతున్నాము, ఇక్కడ ఆ సమగ్రం లోపల ఉన్న పదం ఆ స్లైస్‌లలో ప్రతి ఒక్కదాని వైశాల్యాన్ని తెలియజేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.96,
  "end": 676.14
 },
 {
  "input": "And when we multiply it by a little thickness dy, you might think of it as giving each one of those slices a little bit of volume.",
  "translatedText": "మరియు మేము దానిని కొద్దిగా మందం dyతో గుణించినప్పుడు, ఆ స్లైస్‌లలో ప్రతిదానికి కొద్దిగా వాల్యూమ్‌ను ఇస్తున్నట్లు మీరు భావించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 676.78,
  "end": 682.7
 },
 {
  "input": "And remember, that term c sitting in front represents the thing we want to know, which itself is an integral, a suspiciously similar-looking integral.",
  "translatedText": "మరియు గుర్తుంచుకోండి, ముందు కూర్చున్న సి అనే పదం మనం తెలుసుకోవాలనుకునే విషయాన్ని సూచిస్తుంది, ఇది ఒక సమగ్రమైనది, అనుమానాస్పదంగా సారూప్యమైన సమగ్రమైనది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.18,
  "end": 691.84
 },
 {
  "input": "See, if we take the expression on the top and we factor out that constant c, because it's just a number, it doesn't depend on y, the thing we're left with, the integral we need to compute, is exactly the mystery constant, the thing we don't know.",
  "translatedText": "చూడండి, మనం పైన ఉన్న ఎక్స్‌ప్రెషన్‌ని తీసుకుంటే, ఆ స్థిరమైన cని మనం కారకం చేస్తే, అది కేవలం ఒక సంఖ్య, అది y మీద ఆధారపడి ఉండదు, మనకు మిగిలి ఉన్న విషయం, మనం కంప్యూట్ చేయాల్సిన సమగ్రత, సరిగ్గా రహస్య స్థిరాంకం, మనకు తెలియని విషయం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 692.58,
  "end": 704.84
 },
 {
  "input": "So overall, the volume underneath this bell surface works out to be this mystery constant squared.",
  "translatedText": "కాబట్టి మొత్తంగా, ఈ బెల్ ఉపరితలం క్రింద ఉన్న వాల్యూమ్ ఈ మిస్టరీ స్థిరమైన స్క్వేర్డ్‌గా పనిచేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 705.42,
  "end": 711.38
 },
 {
  "input": "Out of context, this might seem very unhelpful, it's just relating one thing we don't know to another thing we don't know, except we've already computed the volume under this surface, we know that it's equal to pi.",
  "translatedText": "సందర్భానుసారంగా, ఇది చాలా పనికిరానిదిగా అనిపించవచ్చు, ఇది మనకు తెలియని ఒక విషయానికి సంబంధించి మనకు తెలియని మరొక విషయానికి సంబంధించినది, మేము ఈ ఉపరితలం క్రింద వాల్యూమ్‌ను ఇప్పటికే లెక్కించాము తప్ప, ఇది piకి సమానమని మాకు తెలుసు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 712.46,
  "end": 722.3
 },
 {
  "input": "Therefore, the mystery constant we want to know, the area underneath this bell curve, must be the square root of pi.",
  "translatedText": "కాబట్టి, మనం తెలుసుకోవాలనుకునే మిస్టరీ స్థిరాంకం, ఈ బెల్ కర్వ్ కింద ఉన్న ప్రాంతం, పై యొక్క వర్గమూలం అయి ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.06,
  "end": 728.82
 },
 {
  "input": "It's a very pretty argument, but a few things are not entirely satisfying.",
  "translatedText": "ఇది చాలా అందమైన వాదన, కానీ కొన్ని విషయాలు పూర్తిగా సంతృప్తికరంగా లేవు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.12,
  "end": 734.16
 },
 {
  "input": "For one thing, it feels a little bit like a trick, something that just happened to work, without offering much of a sense for how you could have rediscovered it yourself.",
  "translatedText": "ఒక విషయం ఏమిటంటే, ఇది కొంచెం ఉపాయం లాగా అనిపిస్తుంది, ఇప్పుడే పనికి వచ్చినది, మీరే దాన్ని ఎలా తిరిగి కనుగొన్నారనే దాని గురించి ఎక్కువ భావాన్ని అందించకుండా.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.86,
  "end": 742.8
 },
 {
  "input": "Also, if we think back to our imagined statistician's friend, it doesn't really answer their question, which was what do circles have to do with population statistics?",
  "translatedText": "అలాగే, మనం ఊహించిన గణాంకవేత్త స్నేహితుని గురించి ఆలోచిస్తే, అది నిజంగా వారి ప్రశ్నకు సమాధానం ఇవ్వదు, ఇది సర్కిల్‌లకు జనాభా గణాంకాలతో సంబంధం ఏమిటి?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.42,
  "end": 751.8
 },
 {
  "input": "Like I said, it's the first step, not the last, and as our next step, let's see if we can unpack why this proof is not quite as wild and arbitrary as you might first think, and how it relates to an explanation for where this function e to the negative x squared is coming from in the first place.",
  "translatedText": "నేను చెప్పినట్లుగా, ఇది మొదటి అడుగు, చివరిది కాదు, మరియు మా తదుపరి దశగా, ఈ రుజువు మీరు ముందుగా అనుకున్నంత విపరీతంగా మరియు ఏకపక్షంగా ఎందుకు లేదు మరియు ఇది ఎక్కడ వివరణతో సంబంధం కలిగి ఉందో చూద్దాం. ఈ ఫంక్షన్ e నుండి నెగెటివ్ x స్క్వేర్డ్ మొదటి స్థానంలో వస్తోంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 752.54,
  "end": 766.6
 },
 {
  "input": "John Herschel was this mathematician slash scientist slash inventor who really did all sorts of things throughout the 19th century.",
  "translatedText": "జాన్ హెర్షెల్ ఈ గణిత శాస్త్రజ్ఞుడు స్లాష్ సైంటిస్ట్ స్లాష్ ఆవిష్కర్త, అతను నిజంగా 19వ శతాబ్దం అంతటా అన్ని రకాల పనులు చేశాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 771.66,
  "end": 779.06
 },
 {
  "input": "He made contributions in chemistry, astronomy, photography, botany, he invented the blueprint and named many of the moons in our solar system, and in the midst of all of this, he also offered a very elegant little derivation for the Gaussian distribution in 1850.",
  "translatedText": "అతను కెమిస్ట్రీ, ఖగోళ శాస్త్రం, ఫోటోగ్రఫీ, వృక్షశాస్త్రంలో రచనలు చేశాడు, అతను బ్లూప్రింట్‌ను కనుగొన్నాడు మరియు మన సౌర వ్యవస్థలోని అనేక చంద్రులకు పేరు పెట్టాడు మరియు వీటన్నింటి మధ్యలో, అతను 1850లో గాస్సియన్ పంపిణీకి చాలా సొగసైన చిన్న ఉత్పన్నాన్ని అందించాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.4,
  "end": 793.66
 },
 {
  "input": "The setup is to imagine that you want to describe some kind of probability distribution in two-dimensional space.",
  "translatedText": "మీరు ద్విమితీయ స్థలంలో సంభావ్యత పంపిణీని వివరించాలనుకుంటున్నట్లు ఊహించడం సెటప్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 795.0,
  "end": 800.08
 },
 {
  "input": "For instance, maybe you want to model the probability density for hits on a dartboard.",
  "translatedText": "ఉదాహరణకు, మీరు డార్ట్‌బోర్డ్‌లో హిట్‌ల కోసం సంభావ్యత సాంద్రతను మోడల్ చేయాలనుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 800.36,
  "end": 804.5
 },
 {
  "input": "What Herschel showed is that if you want this distribution to satisfy two pretty reasonable seeming properties, your hand is unexpectedly forced, and even if you had never heard of a Gaussian in your life, you would be inexorably drawn to use a function with the shape e to the negative x squared plus y squared.",
  "translatedText": "హెర్షెల్ చూపించినది ఏమిటంటే, ఈ పంపిణీ రెండు అందంగా కనిపించే రెండు లక్షణాలను సంతృప్తి పరచాలని మీరు కోరుకుంటే, మీ చేయి ఊహించని విధంగా బలవంతం చేయబడింది మరియు మీరు మీ జీవితంలో ఎప్పుడూ ఒక గాస్సియన్ గురించి వినకపోయినా, మీరు ఆకృతితో కూడిన ఫంక్షన్‌ను ఉపయోగించేందుకు నిర్దాక్షిణ్యంగా ఆకర్షితులవుతారు. ఇ ప్రతికూల x స్క్వేర్డ్ ప్లస్ y స్క్వేర్డ్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.06,
  "end": 820.56
 },
 {
  "input": "You do have one degree of freedom to control the spread of that distribution, and of course there's going to be some constant sitting in front to make sure it's normalized, but the point is that we're forced into this very specific kind of bell curve shape.",
  "translatedText": "ఆ పంపిణీ యొక్క వ్యాప్తిని నియంత్రించడానికి మీకు ఒక స్థాయి స్వేచ్ఛ ఉంది మరియు అది సాధారణీకరించబడిందని నిర్ధారించుకోవడానికి కొంత స్థిరంగా కూర్చుని ఉంటుంది, అయితే మేము ఈ నిర్దిష్ట రకమైన బెల్ కర్వ్‌లోకి బలవంతం చేయబడతాము. ఆకారం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 821.14,
  "end": 832.62
 },
 {
  "input": "The first of these two properties is that the probability density around each point depends only on its distance from the origin, not on its direction.",
  "translatedText": "ఈ రెండు లక్షణాలలో మొదటిది ఏమిటంటే, ప్రతి బిందువు చుట్టూ సంభావ్యత సాంద్రత దాని దిశపై కాకుండా మూలం నుండి దాని దూరంపై మాత్రమే ఆధారపడి ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 833.48,
  "end": 842.14
 },
 {
  "input": "So on a dartboard with everybody aiming for the bullseye, this would mean that you could rotate the board and it would make no difference for the distribution.",
  "translatedText": "కాబట్టి ప్రతి ఒక్కరూ బుల్‌సీని లక్ష్యంగా చేసుకునే డార్ట్‌బోర్డ్‌లో, మీరు బోర్డ్‌ను తిప్పవచ్చు మరియు పంపిణీకి ఎటువంటి తేడా ఉండదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.8,
  "end": 849.46
 },
 {
  "input": "Mathematically, this means that the function describing your probability distribution, which I'll call f2 since it takes in two inputs x and y, well it can be expressed as some single variable function of the radius r.",
  "translatedText": "గణితశాస్త్రపరంగా, ఇది మీ సంభావ్యత పంపిణీని వివరించే ఫంక్షన్ అని అర్థం, నేను f2 అని పిలుస్తాను ఎందుకంటే ఇది x మరియు y అనే రెండు ఇన్‌పుట్‌లను తీసుకుంటుంది, అలాగే ఇది వ్యాసార్థం r యొక్క కొన్ని సింగిల్ వేరియబుల్ ఫంక్షన్‌గా వ్యక్తీకరించబడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 852.72,
  "end": 864.62
 },
 {
  "input": "And just to spell it out, r is the distance between the point xy and the origin, the square root of x squared plus y squared.",
  "translatedText": "మరియు దానిని ఉచ్చరించడానికి, r అనేది పాయింట్ xy మరియు మూలం మధ్య దూరం, x స్క్వేర్డ్ ప్లస్ y స్క్వేర్డ్ యొక్క వర్గమూలం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 865.28,
  "end": 871.82
 },
 {
  "input": "Property number two is that the x and y coordinates of each point are independent from each other, which is to say if you learn the x coordinate of a point, it would give you no information about the y coordinate.",
  "translatedText": "ఆస్తి సంఖ్య రెండు అంటే ప్రతి బిందువు యొక్క x మరియు y కోఆర్డినేట్‌లు ఒకదానికొకటి స్వతంత్రంగా ఉంటాయి, అంటే మీరు ఒక పాయింట్ యొక్క x కోఆర్డినేట్‌ని నేర్చుకుంటే, అది మీకు y కోఆర్డినేట్ గురించి ఎటువంటి సమాచారం ఇవ్వదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 873.1,
  "end": 883.62
 },
 {
  "input": "The way this looks as an equation is that our function, which describes the probability density around each point on the xy plane, can be factored into two different parts, one of which can be purely written in terms of x, this is the distribution of the x coordinate, I'm giving it the name g, and the other part is purely in terms of y, this would be the distribution for the y coordinate, which I'm temporarily calling h.",
  "translatedText": "ఇది సమీకరణంగా కనిపించే విధానం ఏమిటంటే, xy ప్లేన్‌లోని ప్రతి బిందువు చుట్టూ సంభావ్యత సాంద్రతను వివరించే మా ఫంక్షన్‌ను రెండు వేర్వేరు భాగాలుగా విభజించవచ్చు, వాటిలో ఒకటి పూర్తిగా x పరంగా వ్రాయబడుతుంది, ఇది పంపిణీ x కోఆర్డినేట్, నేను దీనికి g అనే పేరు ఇస్తున్నాను, మరియు ఇతర భాగం పూర్తిగా y పరంగా ఉంటుంది, ఇది y కోఆర్డినేట్ కోసం పంపిణీ అవుతుంది, దీనిని నేను తాత్కాలికంగా h అని పిలుస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 885.1,
  "end": 906.0
 },
 {
  "input": "But if you combine this with the assumption that things are radially symmetric, both of these should be the same distribution.",
  "translatedText": "కానీ మీరు విషయాలు రేడియల్ సిమెట్రిక్ అనే ఊహతో దీన్ని కలిపితే, ఈ రెండూ ఒకే పంపిణీగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 906.44,
  "end": 911.8
 },
 {
  "input": "The behavior on each axis should look the same.",
  "translatedText": "ప్రతి అక్షం మీద ప్రవర్తన ఒకేలా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 912.1,
  "end": 914.18
 },
 {
  "input": "So we could also write this as g of x times g of y, it's the same function.",
  "translatedText": "కాబట్టి మేము y యొక్క x సార్లు g యొక్క g అని కూడా వ్రాయవచ్చు, ఇది అదే ఫంక్షన్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 914.48,
  "end": 918.36
 },
 {
  "input": "And more than that, this function is actually going to be proportional to the one we were just looking at, the one that describes our probability density as a function of the radius, the distance away from the origin.",
  "translatedText": "మరియు అంతకంటే ఎక్కువ, ఈ ఫంక్షన్ వాస్తవానికి మనం చూస్తున్న దానికి అనులోమానుపాతంలో ఉంటుంది, ఇది మన సంభావ్యత సాంద్రతను వ్యాసార్థం యొక్క ఫంక్షన్‌గా వివరిస్తుంది, మూలం నుండి దూరం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.84,
  "end": 928.26
 },
 {
  "input": "To see this, imagine you were to analyze a point that was on the x axis, a distance r away from the origin.",
  "translatedText": "దీన్ని చూడడానికి, మీరు మూలం నుండి r దూరంలో ఉన్న x అక్షం మీద ఉన్న బిందువును విశ్లేషించాలని ఊహించుకోండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 928.74,
  "end": 933.78
 },
 {
  "input": "Then the two distinct ways to express our function based on the two different properties tells us that f of r has to equal some constant multiplied by g of r.",
  "translatedText": "రెండు వేర్వేరు లక్షణాల ఆధారంగా మన పనితీరును వ్యక్తీకరించడానికి రెండు విభిన్న మార్గాలు, r యొక్క f, r యొక్క gతో గుణించబడిన కొంత స్థిరాంకం సమానం అని చెబుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 934.3,
  "end": 942.98
 },
 {
  "input": "So these functions f and g are basically the same thing, just up to some constant multiple.",
  "translatedText": "కాబట్టి ఈ విధులు f మరియు g ప్రాథమికంగా ఒకే విషయం, కొన్ని స్థిరమైన మల్టిపుల్ వరకు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.12,
  "end": 947.5
 },
 {
  "input": "And you know what?",
  "translatedText": "మరియు మీకు తెలుసా?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 948.9,
  "end": 949.84
 },
 {
  "input": "It would be really nice if we could just assume that that constant was one, so that f and g were literally the same function.",
  "translatedText": "ఆ స్థిరాంకం ఒకటి అని మనం ఊహించగలిగితే అది నిజంగా మంచిది, తద్వారా f మరియు g అక్షరాలా ఒకే ఫంక్షన్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 949.84,
  "end": 956.08
 },
 {
  "input": "And what I'm going to do, which might feel a little bit cheeky, is just assume that that is the case.",
  "translatedText": "మరియు నేను ఏమి చేయబోతున్నాను, ఇది కొంచెం చీకెగా అనిపించవచ్చు, అది అదే అని ఊహించుకోండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 956.7,
  "end": 961.6
 },
 {
  "input": "What this means is that our answer is going to be a little bit wrong.",
  "translatedText": "దీని అర్థం ఏమిటంటే, మా సమాధానం కొంచెం తప్పుగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.2,
  "end": 964.66
 },
 {
  "input": "The function that we will deduce describing this distribution will be off by some constant factor.",
  "translatedText": "ఈ డిస్ట్రిబ్యూషన్‌ను వివరించడం ద్వారా మేము తగ్గించే ఫంక్షన్ కొంత స్థిరమైన కారకం ద్వారా నిలిపివేయబడుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.88,
  "end": 969.38
 },
 {
  "input": "But that's no big deal, because in the end we can just rescale to make sure the area under the curve is one, like we always do with probability distributions.",
  "translatedText": "కానీ అది పెద్ద విషయం కాదు, ఎందుకంటే చివరికి మనం ప్రాబబిలిటీ డిస్ట్రిబ్యూషన్‌ల మాదిరిగానే వక్రరేఖ కింద ఉన్న ప్రాంతం ఒకటి అని నిర్ధారించుకోవడానికి రీస్కేల్ చేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 969.84,
  "end": 976.96
 },
 {
  "input": "Now, if f and g are the same thing, this gives us a very nice little equation purely in terms of the function f.",
  "translatedText": "ఇప్పుడు, f మరియు g ఒకే విషయం అయితే, f ఫంక్షన్ పరంగా ఇది చాలా చక్కని చిన్న సమీకరణాన్ని ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.52,
  "end": 983.84
 },
 {
  "input": "Remember what this function f is.",
  "translatedText": "ఈ ఫంక్షన్ f అంటే ఏమిటో గుర్తుంచుకోండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 984.58,
  "end": 986.2
 },
 {
  "input": "If you have some point in the xy plane, a distance r from the origin, then f of r tells you the relative likelihood of that point showing up in the random process.",
  "translatedText": "మీరు xy ప్లేన్‌లో కొంత పాయింట్‌ను కలిగి ఉంటే, మూలం నుండి దూరం r, అప్పుడు r యొక్క f అనేది యాదృచ్ఛిక ప్రక్రియలో ఆ పాయింట్ యొక్క సాపేక్ష సంభావ్యతను మీకు తెలియజేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.5,
  "end": 995.26
 },
 {
  "input": "More specifically, it gives the probability density of that point.",
  "translatedText": "మరింత ప్రత్యేకంగా, ఇది ఆ బిందువు యొక్క సంభావ్యత సాంద్రతను ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 995.68,
  "end": 998.68
 },
 {
  "input": "At the outset, this function could have been anything.",
  "translatedText": "ప్రారంభంలో, ఈ ఫంక్షన్ ఏదైనా కావచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 999.16,
  "end": 1001.24
 },
 {
  "input": "But Herschel's two different properties evidently imply something kind of funny about it, which is that if we take the x and y coordinates of that point on the plane and evaluate this function on them separately, taking f of x times f of y, it should give us the same result.",
  "translatedText": "కానీ హెర్షెల్ యొక్క రెండు విభిన్న లక్షణాలు స్పష్టంగా దాని గురించి ఫన్నీని సూచిస్తాయి, అంటే మనం విమానంలో ఆ బిందువు యొక్క x మరియు y కోఆర్డినేట్‌లను తీసుకొని వాటిపై ఈ ఫంక్షన్‌ను విడిగా అంచనా వేస్తే, y యొక్క x రెట్లు f తీసుకుంటే, అది తప్పక మాకు అదే ఫలితాన్ని ఇవ్వండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1001.66,
  "end": 1015.82
 },
 {
  "input": "Or if you prefer, we could expand out the meaning of that distance r as the square root of x squared plus y squared, and this is what our key equation looks like.",
  "translatedText": "లేదా మీరు కావాలనుకుంటే, మేము ఆ దూరం r యొక్క అర్థాన్ని x స్క్వేర్డ్ ప్లస్ y స్క్వేర్డ్ యొక్క వర్గమూలంగా విస్తరింపజేస్తాము మరియు మా కీలక సమీకరణం ఇలా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1016.26,
  "end": 1024.18
 },
 {
  "input": "This kind of equation is what's known in the business as a functional equation.",
  "translatedText": "ఈ రకమైన సమీకరణాన్ని వ్యాపారంలో ఫంక్షనల్ ఈక్వేషన్‌గా పిలుస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1025.0,
  "end": 1028.88
 },
 {
  "input": "We're not solving for an unknown number.",
  "translatedText": "మేము తెలియని నంబర్ కోసం పరిష్కరించడం లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1028.98,
  "end": 1031.04
 },
 {
  "input": "Instead, we're saying that the equation is true for all possible numbers x and y, and the thing we're trying to find is an unknown function.",
  "translatedText": "బదులుగా, x మరియు y సాధ్యమయ్యే అన్ని సంఖ్యలకు సమీకరణం సరైనదని మేము చెబుతున్నాము మరియు మేము కనుగొనడానికి ప్రయత్నిస్తున్న విషయం తెలియని ఫంక్షన్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.04,
  "end": 1038.26
 },
 {
  "input": "In the back of your mind, you can think we already know one function that satisfies this property, e to the negative x squared, and as a sanity check you might verify for yourself that it does satisfy that.",
  "translatedText": "మీ మనస్సులో, ఈ ఆస్తిని సంతృప్తిపరిచే ఒక ఫంక్షన్ మాకు ఇప్పటికే తెలుసునని మీరు అనుకోవచ్చు, ఇ నెగటివ్ x స్క్వేర్డ్‌కు, మరియు తెలివిని తనిఖీ చేయడం ద్వారా అది సంతృప్తి చెందుతుందని మీరే ధృవీకరించుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.48,
  "end": 1050.38
 },
 {
  "input": "Of course, the point is to pretend that you don't know that, and to instead deduce what all of the functions are which satisfy this property.",
  "translatedText": "అయితే, విషయం ఏమిటంటే, మీకు అది తెలియనట్లు నటించడం మరియు బదులుగా ఈ ఆస్తిని సంతృప్తిపరిచే అన్ని విధులు ఏమిటో తీసివేయడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1051.0,
  "end": 1057.8
 },
 {
  "input": "In general, functional equations can be quite tricky, but let me show you how you can solve this one.",
  "translatedText": "సాధారణంగా, ఫంక్షనల్ సమీకరణాలు చాలా గమ్మత్తైనవిగా ఉంటాయి, కానీ మీరు దీన్ని ఎలా పరిష్కరించవచ్చో నేను మీకు చూపుతాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.42,
  "end": 1063.42
 },
 {
  "input": "First, it's nice to introduce a little helper function that I'll call h of x, which will be defined as our mystery function evaluated at the square root of x.",
  "translatedText": "ముందుగా, నేను x యొక్క h అని పిలుస్తాను, x యొక్క వర్గమూలం వద్ద మూల్యాంకనం చేయబడిన మా మిస్టరీ ఫంక్షన్‌గా నిర్వచించబడే ఒక చిన్న సహాయక ఫంక్షన్‌ను పరిచయం చేయడం చాలా బాగుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.08,
  "end": 1071.96
 },
 {
  "input": "Said another way, h of x squared is the same thing as f of x.",
  "translatedText": "మరో విధంగా చెప్పాలంటే, x స్క్వేర్డ్ యొక్క h అనేది x యొక్క f వలె ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1072.4,
  "end": 1076.02
 },
 {
  "input": "For example, in the back of your mind where you know that e to the negative x squared will happen to be one of the answers, this little helper function h would be e to the negative x.",
  "translatedText": "ఉదాహరణకు, మీ మనస్సు వెనుక భాగంలో e నుండి నెగటివ్ x స్క్వేర్డ్ వరకు ఉన్న సమాధానాలలో ఒకటిగా ఉంటుందని మీకు తెలిసిన చోట, ఈ చిన్న సహాయక ఫంక్షన్ h ప్రతికూల xకి e అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1076.7,
  "end": 1085.36
 },
 {
  "input": "But again, we're pretending like we don't know that.",
  "translatedText": "కానీ మళ్లీ ఆ విషయం తెలియనట్లు నటిస్తున్నాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.36,
  "end": 1087.76
 },
 {
  "input": "The reason for doing this is that the key property looks a little bit nicer if we phrase it in terms of this helper function, h.",
  "translatedText": "దీన్ని చేయడానికి కారణం ఏమిటంటే, ఈ హెల్పర్ ఫంక్షన్ పరంగా మనం దానిని పదబంధం చేస్తే కీ ప్రాపర్టీ కొంచెం చక్కగా కనిపిస్తుంది, h.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1088.14,
  "end": 1094.26
 },
 {
  "input": "Because now what it's saying is if you take two arbitrary positive numbers and you add them up and evaluate h, it's the same thing as evaluating h on them separately and then multiplying the results.",
  "translatedText": "ఎందుకంటే ఇప్పుడు అది చెప్పేది ఏమిటంటే, మీరు రెండు ఏకపక్ష సానుకూల సంఖ్యలను తీసుకుంటే, మీరు వాటిని జోడించి, h మూల్యాంకనం చేస్తే, వాటిపై hని విడిగా మూల్యాంకనం చేసి, ఆపై ఫలితాలను గుణించడం లాంటిదే.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1094.64,
  "end": 1104.56
 },
 {
  "input": "In a sense, it turns addition into multiplication.",
  "translatedText": "ఒక కోణంలో, ఇది కూడికను గుణకారంగా మారుస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1105.04,
  "end": 1107.38
 },
 {
  "input": "Some of you might see where this is going, but let's take a moment to walk through why this forces our hand.",
  "translatedText": "ఇది ఎక్కడికి వెళుతుందో మీలో కొందరు చూడవచ్చు, అయితే ఇది మన చేతిని ఎందుకు బలవంతం చేస్తుందో తెలుసుకుందాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.06,
  "end": 1112.94
 },
 {
  "input": "As a next step, you might want to pause and convince yourself that if this property is true for the sum of two numbers, this property also must be true if we add up an arbitrary number of inputs.",
  "translatedText": "తదుపరి దశగా, మీరు పాజ్ చేసి, రెండు సంఖ్యల మొత్తానికి ఈ ఆస్తి నిజమైతే, మేము ఏకపక్ష ఇన్‌పుట్‌ల సంఖ్యను జోడిస్తే ఈ లక్షణం కూడా తప్పక నిజమని మిమ్మల్ని మీరు ఒప్పించుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.94,
  "end": 1123.88
 },
 {
  "input": "To get a feel for why this is so constraining, think about plugging in a whole number, something like h of 5.",
  "translatedText": "ఇది ఎందుకు అంత నిర్బంధంగా ఉందో అర్థం చేసుకోవడానికి, h 5 వంటి పూర్ణ సంఖ్యను ప్లగ్ చేయడం గురించి ఆలోచించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.3,
  "end": 1130.52
 },
 {
  "input": "Because you can write 5 as 1 plus 1 plus 1 plus 1 plus 1, this key property means that it must equal h of 1 multiplied by itself 5 times.",
  "translatedText": "మీరు 5ని 1 ప్లస్ 1 ప్లస్ 1 ప్లస్ 1 ప్లస్ 1 అని వ్రాయవచ్చు కాబట్టి, ఈ కీ ప్రాపర్టీ అంటే 1 దానితో సమానంగా 5 రెట్లు గుణిస్తే h ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1131.3,
  "end": 1140.18
 },
 {
  "input": "Of course, there's nothing special about 5.",
  "translatedText": "వాస్తవానికి, 5 గురించి ప్రత్యేకంగా ఏమీ లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1140.76,
  "end": 1142.76
 },
 {
  "input": "I could have chosen any whole number n, and we'd be forced to conclude that the function looks like some number raised to the power n.",
  "translatedText": "నేను ఏదైనా పూర్తి సంఖ్య nని ఎంచుకోగలిగాను, మరియు ఫంక్షన్ n పవర్‌కి పెంచబడిన కొంత సంఖ్య లాగా ఉందని మేము నిర్ధారించవలసి వస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.88,
  "end": 1149.62
 },
 {
  "input": "And let's go ahead and give that number a name, like b for the base of our exponential.",
  "translatedText": "మరియు మన ఘాతాంకానికి ఆధారం కోసం b వంటి ఆ సంఖ్యకు ఒక పేరును ఇద్దాం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1150.76,
  "end": 1154.84
 },
 {
  "input": "As a little mini exercise here, see if you can pause and take a moment to convince yourself that the same is true for a rational input, that if you plug in p over q to this function, it must look like this base b raised to the power p over q.",
  "translatedText": "ఇక్కడ ఒక చిన్న చిన్న వ్యాయామంగా, మీరు పాజ్ చేసి, హేతుబద్ధమైన ఇన్‌పుట్‌కి ఇదే నిజమని మిమ్మల్ని మీరు ఒప్పించుకోవడానికి కొంత సమయం వెచ్చించవచ్చో లేదో చూడండి, మీరు ఈ ఫంక్షన్‌కి qపై p ప్లగ్ చేస్తే, అది ఈ బేస్ b లాగా ఉండాలి q పై శక్తి p.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1156.08,
  "end": 1169.06
 },
 {
  "input": "And as a hint, you might want to think about adding that input to itself q different times.",
  "translatedText": "మరియు సూచనగా, మీరు ఆ ఇన్‌పుట్‌ని దానికే q వివిధ సమయాల్లో జోడించడం గురించి ఆలోచించాలనుకోవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1170.48,
  "end": 1175.2
 },
 {
  "input": "And then because rational numbers are dense in the real number line, if we make one more pretty reasonable assumption that we only care about continuous functions, this is enough to force your hand completely and say that h has to be an exponential function, b to the power x, for all real number inputs x.",
  "translatedText": "ఆపై వాస్తవ సంఖ్యా రేఖలో హేతుబద్ధ సంఖ్యలు దట్టంగా ఉన్నందున, మనం నిరంతర ఫంక్షన్‌ల గురించి మాత్రమే శ్రద్ధ వహిస్తాము అని మరొక అందమైన సహేతుకమైన ఊహ చేస్తే, మీ చేతిని పూర్తిగా బలవంతం చేయడానికి మరియు h ఒక ఘాతాంక విధిగా ఉండాలని చెప్పడానికి సరిపోతుంది, b to పవర్ x, అన్ని వాస్తవ సంఖ్య ఇన్‌పుట్‌ల కోసం x.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1178.62,
  "end": 1194.58
 },
 {
  "input": "I guess to be more precise I should say for all positive real inputs.",
  "translatedText": "అన్ని సానుకూల వాస్తవ ఇన్‌పుట్‌ల కోసం నేను మరింత ఖచ్చితంగా చెప్పాలనుకుంటున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1195.3,
  "end": 1198.3
 },
 {
  "input": "The way we defined h, it's only taking in positive numbers.",
  "translatedText": "మేము h ని నిర్వచించిన విధానం, అది సానుకూల సంఖ్యలను మాత్రమే తీసుకుంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.3,
  "end": 1201.52
 },
 {
  "input": "Now, as we've gone over before, instead of writing down exponential functions as some base raised to the power x, mathematicians often like to write them as e to the power of some constant c times x.",
  "translatedText": "ఇప్పుడు, మనం ఇంతకు ముందు చెప్పినట్లుగా, ఎక్స్‌పోనెన్షియల్ ఫంక్షన్‌లను పవర్ xకి కొంత బేస్‌గా వ్రాసే బదులు, గణిత శాస్త్రజ్ఞులు తరచుగా వాటిని కొన్ని స్థిరమైన c సార్లు x యొక్క శక్తికి ఇ అని వ్రాయడానికి ఇష్టపడతారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1202.5,
  "end": 1212.78
 },
 {
  "input": "Making the choice to always use e as a base while letting that constant c determine which specific exponential function you're talking about just makes everything much easier any time calculus comes wandering along your path.",
  "translatedText": "మీరు ఏ నిర్దిష్ట ఎక్స్‌పోనెన్షియల్ ఫంక్షన్ గురించి మాట్లాడుతున్నారో ఆ స్థిరాంకం cని గుర్తించేందుకు వీలు కల్పిస్తూ, ఎల్లప్పుడూ eని బేస్‌గా ఉపయోగించేలా ఎంపిక చేసుకోవడం వల్ల మీ మార్గంలో ఎప్పుడైనా కాలిక్యులస్ తిరుగుతున్నప్పుడు ప్రతిదీ చాలా సులభం అవుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1213.26,
  "end": 1224.5
 },
 {
  "input": "And so this means that our target function f has to look like e to the power of some constant times x squared.",
  "translatedText": "మరియు దీని అర్థం మా లక్ష్యం ఫంక్షన్ f కొన్ని స్థిరమైన సార్లు x స్క్వేర్డ్ యొక్క శక్తికి e లాగా ఉండాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1225.64,
  "end": 1232.48
 },
 {
  "input": "The beauty is that that function is no longer something that was merely handed down to us from on high.",
  "translatedText": "అందం ఏమిటంటే, ఆ ఫంక్షన్ ఇప్పుడు పై నుండి మనకు అప్పగించబడినది కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1233.6,
  "end": 1238.12
 },
 {
  "input": "Instead we started with these two different premises for how we wanted a distribution in two dimensions to behave, and we were drawn to the conclusion that the shape of the expression describing that distribution as a function of the radius away from the origin has to be e to the power of some constant times that radius squared.",
  "translatedText": "బదులుగా మేము రెండు కోణాలలో పంపిణీని ఎలా ప్రవర్తించాలనుకుంటున్నాము అనే దాని కోసం మేము ఈ రెండు విభిన్న ప్రాంగణాలతో ప్రారంభించాము మరియు మూలం నుండి దూరంగా ఉన్న వ్యాసార్థం యొక్క విధిగా పంపిణీని వివరించే వ్యక్తీకరణ యొక్క ఆకృతి e అయి ఉండాలనే నిర్ణయానికి వచ్చాము. వ్యాసార్థం వర్గీకరించబడిన కొన్ని స్థిరమైన సమయాల శక్తికి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.76,
  "end": 1255.16
 },
 {
  "input": "You'll remember I said earlier this answer will be off by a factor of a constant.",
  "translatedText": "ఈ సమాధానం స్థిరమైన కారకం ద్వారా నిలిపివేయబడుతుందని నేను ఇంతకు ముందు చెప్పినట్లు మీకు గుర్తుండే ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1256.32,
  "end": 1259.68
 },
 {
  "input": "We need to rescale it to make it a valid probability distribution, and geometrically you might think of that as scaling it so that the volume under the surface is equal to one.",
  "translatedText": "మేము దానిని చెల్లుబాటు అయ్యే సంభావ్యత పంపిణీగా మార్చడానికి దాన్ని రీస్కేల్ చేయాలి మరియు రేఖాగణితంగా మీరు దానిని స్కేలింగ్‌గా భావించవచ్చు, తద్వారా ఉపరితలం క్రింద ఉన్న వాల్యూమ్ ఒకదానికి సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1260.1,
  "end": 1267.86
 },
 {
  "input": "Now you might notice that for positive values of this constant in the exponent c, our function blows up to infinity in all directions, so the volume under that surface would be infinite, meaning it's not possible to renormalize.",
  "translatedText": "ఇప్పుడు మీరు ఘాతాంకం cలో ఈ స్థిరాంకం యొక్క సానుకూల విలువల కోసం, మా ఫంక్షన్ అన్ని దిశలలో అనంతం వరకు ఎగిసిపడుతుందని మీరు గమనించవచ్చు, కాబట్టి ఆ ఉపరితలం క్రింద ఉన్న వాల్యూమ్ అనంతంగా ఉంటుంది, అంటే రీనార్మలైజ్ చేయడం సాధ్యం కాదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.94,
  "end": 1280.72
 },
 {
  "input": "You can't turn it into a probability distribution, and that leaves us with the last constraint, which is that this constant in the exponent has to be a negative number, and the specific value of that number determines the spread of the distribution.",
  "translatedText": "మీరు దానిని సంభావ్యత పంపిణీగా మార్చలేరు మరియు అది మాకు చివరి పరిమితిని కలిగిస్తుంది, అంటే ఘాతాంకంలోని ఈ స్థిరాంకం ప్రతికూల సంఖ్యగా ఉండాలి మరియు ఆ సంఖ్య యొక్క నిర్దిష్ట విలువ పంపిణీ వ్యాప్తిని నిర్ణయిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1280.92,
  "end": 1292.56
 },
 {
  "input": "Ten years after Herschel wrote this, James Clerk Maxwell, who's most well known for having written down the fundamental equations for electricity and magnetism, independently stumbled across the same derivation.",
  "translatedText": "హెర్షెల్ దీనిని వ్రాసిన పదేళ్ల తర్వాత, విద్యుత్ మరియు అయస్కాంతత్వానికి సంబంధించిన ప్రాథమిక సమీకరణాలను వ్రాసినందుకు ప్రసిద్ధి చెందిన జేమ్స్ క్లర్క్ మాక్స్‌వెల్, స్వతంత్రంగా అదే ఉత్పన్నంలో పొరపాటు పడ్డాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1294.0,
  "end": 1303.92
 },
 {
  "input": "In his case he was doing it in three dimensions, since he was doing statistical mechanics and he was deriving a formula for the distribution for velocities of molecules in a gas.",
  "translatedText": "అతని విషయంలో అతను దానిని మూడు కోణాలలో చేస్తున్నాడు, ఎందుకంటే అతను గణాంక మెకానిక్స్ చేస్తున్నాడు మరియు అతను వాయువులోని అణువుల వేగాల పంపిణీకి సూత్రాన్ని రూపొందించాడు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1304.22,
  "end": 1312.9
 },
 {
  "input": "But the logic all works out the same.",
  "translatedText": "కానీ లాజిక్ అన్నీ ఒకేలా పనిచేస్తాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1313.1,
  "end": 1315.1
 },
 {
  "input": "For you and me, if we view this as the defining property of a Gaussian, then it's a little bit less surprising that pi might make an appearance.",
  "translatedText": "మీకు మరియు నాకు, మేము దీనిని గాస్సియన్ యొక్క నిర్వచించే ఆస్తిగా చూస్తే, పై కనిపించడం కొంచెం తక్కువ ఆశ్చర్యం కలిగిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1315.88,
  "end": 1323.4
 },
 {
  "input": "After all, circular symmetry was part of this defining property.",
  "translatedText": "అన్నింటికంటే, వృత్తాకార సమరూపత ఈ నిర్వచించే ఆస్తిలో భాగం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1323.94,
  "end": 1327.48
 },
 {
  "input": "More than that, it makes the clever proof that we saw earlier feel a little bit less out of the blue.",
  "translatedText": "అంతకు మించి, మనం ఇంతకు ముందు చూసిన తెలివైన రుజువును కొంచెం తక్కువగా అనిపించేలా చేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1328.2,
  "end": 1332.74
 },
 {
  "input": "I mean, a key problem-solving principle in math is to use the defining features of your setup.",
  "translatedText": "నా ఉద్దేశ్యం, గణితంలో కీలకమైన సమస్య-పరిష్కార సూత్రం మీ సెటప్ యొక్క నిర్వచించే లక్షణాలను ఉపయోగించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.2,
  "end": 1338.02
 },
 {
  "input": "And if you had been primed by this Herschel-Maxwell derivation, where the defining property for a Gaussian is this coincidence of having a distribution that's both radially symmetric and also independent along each axis, then the very first step of our proof, which seemed so strange bumping the problem up one dimension, was really just a way of opening the door to let that defining property make itself visible.",
  "translatedText": "మరియు మీరు ఈ హెర్షెల్-మాక్స్‌వెల్ ఉత్పన్నం ద్వారా ప్రైమ్ చేయబడితే, గాస్సియన్‌కి నిర్వచించే ఆస్తి ప్రతి అక్షం పొడవునా రేడియల్‌గా సుష్టంగా మరియు స్వతంత్రంగా ఉండే పంపిణీని కలిగి ఉండటం యాదృచ్చికం, అప్పుడు మా రుజువు యొక్క మొదటి దశ అలా అనిపించింది. సమస్యను ఒక కోణాన్ని పెంచడం విచిత్రం, ఇది నిజంగా ఆ నిర్వచించే ఆస్తి స్వయంగా కనిపించేలా చేయడానికి తలుపు తెరవడానికి ఒక మార్గం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.52,
  "end": 1361.18
 },
 {
  "input": "And if you think back, the essence of the proof came down to using that radial symmetry on the one hand, and then also using the ability to factor the function on the other.",
  "translatedText": "మరియు మీరు తిరిగి ఆలోచిస్తే, రుజువు యొక్క సారాంశం ఒక వైపు ఆ రేడియల్ సమరూపతను ఉపయోగించడం మరియు మరొక వైపు ఫంక్షన్‌ను కారకం చేసే సామర్థ్యాన్ని ఉపయోగించడం వరకు వచ్చింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1362.04,
  "end": 1370.64
 },
 {
  "input": "From this standpoint, using both those facts feels less like a trick that happened to work, and more like an inevitable necessity.",
  "translatedText": "ఈ దృక్కోణం నుండి, ఆ రెండు వాస్తవాలను ఉపయోగించడం పనికి వచ్చిన ఒక ఉపాయం వలె తక్కువ మరియు అనివార్యమైన అవసరం వలె అనిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1371.32,
  "end": 1378.24
 },
 {
  "input": "Nevertheless, thinking once again of our statistician's friend, this is still not entirely satisfying.",
  "translatedText": "అయినప్పటికీ, మన గణాంకవేత్త స్నేహితుడి గురించి మరోసారి ఆలోచిస్తే, ఇది ఇప్పటికీ పూర్తిగా సంతృప్తికరంగా లేదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1380.32,
  "end": 1385.96
 },
 {
  "input": "Using the Herschel-Maxwell derivation, saying this property of a multi-dimensional distribution is what defines a Gaussian, well that presumes that we're already in some kind of multi-dimensional situation in the first place.",
  "translatedText": "హెర్షెల్-మాక్స్‌వెల్ వ్యుత్పత్తిని ఉపయోగించి, బహుళ డైమెన్షనల్ డిస్ట్రిబ్యూషన్ యొక్క ఈ ప్రాపర్టీ అనేది గాస్సియన్‌ను నిర్వచిస్తుంది, అలాగే మనం ఇప్పటికే ఒకరకమైన బహుళ-డైమెన్షనల్ పరిస్థితిలో మొదటి స్థానంలో ఉన్నామని ఊహిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1386.38,
  "end": 1397.64
 },
 {
  "input": "Much more commonly, the way that a normal distribution arises in practice doesn't feel spatial or geometric at all.",
  "translatedText": "చాలా సాధారణంగా, ఆచరణలో సాధారణ పంపిణీ ఏర్పడే విధానం ప్రాదేశికంగా లేదా రేఖాగణితంగా అనిపించదు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1398.12,
  "end": 1404.64
 },
 {
  "input": "It stems from the central limit theorem, which is all about adding together many different independent variables.",
  "translatedText": "ఇది కేంద్ర పరిమితి సిద్ధాంతం నుండి ఉద్భవించింది, ఇది అనేక విభిన్న స్వతంత్ర చరరాశులను కలిపిస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1404.88,
  "end": 1410.3
 },
 {
  "input": "So to bring it all home here, what we need to do is explain why the function that's characterized by this Herschel-Maxwell derivation should be the same thing as the function that sits at the heart of the central limit theorem.",
  "translatedText": "కాబట్టి వాటన్నింటినీ ఇక్కడకు తీసుకురావడానికి, ఈ హెర్షెల్-మాక్స్‌వెల్ ఉత్పన్నం ద్వారా వర్గీకరించబడిన ఫంక్షన్ కేంద్ర పరిమితి సిద్ధాంతం యొక్క గుండె వద్ద ఉన్న ఫంక్షన్‌తో సమానంగా ఎందుకు ఉండాలో మనం వివరించాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1410.82,
  "end": 1421.78
 },
 {
  "input": "And at this point, those of you following along are probably going to make fun of me, I think it makes sense to pull this last step out as its own video.",
  "translatedText": "మరియు ఈ సమయంలో, మీలో అనుసరించే వారు బహుశా నన్ను ఎగతాళి చేయబోతున్నారు, ఈ చివరి దశను దాని స్వంత వీడియోగా లాగడం సమంజసమని నేను భావిస్తున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1422.52,
  "end": 1429.68
 },
 {
  "input": "Oh, and one final footnote here.",
  "translatedText": "ఓహ్, మరియు ఇక్కడ ఒక చివరి ఫుట్‌నోట్.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1430.26,
  "end": 1432.18
 },
 {
  "input": "After making a Patreon post about this particular project, one patron, who's a mathematician named Kevin Ega, shared something completely delightful that I had never seen before, which is that if you apply this integration trick in higher dimensions, it lets you derive the formulas for volumes of higher dimensional spheres.",
  "translatedText": "ఈ నిర్దిష్ట ప్రాజెక్ట్ గురించి పాట్రియన్ పోస్ట్ చేసిన తర్వాత, కెవిన్ ఎగా అనే గణిత శాస్త్రజ్ఞుడైన ఒక పోషకుడు, నేను ఇంతకు ముందెన్నడూ చూడని పూర్తిగా సంతోషకరమైన విషయాన్ని పంచుకున్నాడు, అంటే మీరు ఈ ఇంటిగ్రేషన్ ట్రిక్‌ను ఎక్కువ డైమెన్షన్‌లలో వర్తింపజేస్తే, అది మిమ్మల్ని ఫార్ములాలను పొందేలా చేస్తుంది. అధిక డైమెన్షనల్ గోళాల వాల్యూమ్‌ల కోసం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1432.38,
  "end": 1448.78
 },
 {
  "input": "A very fun exercise, I'm leaving the details up on the screen for any viewers who are comfortable with integration by parts.",
  "translatedText": "చాలా ఆహ్లాదకరమైన వ్యాయామం, భాగాల వారీగా ఇంటిగ్రేషన్‌తో సౌకర్యవంతంగా ఉండే వీక్షకుల కోసం నేను వివరాలను స్క్రీన్‌పై ఉంచుతున్నాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.26,
  "end": 1454.78
 },
 {
  "input": "Thank you very much to Kevin for sharing that one, and thanks to all patrons, by the way, both for the support of the channel and also for all the feedback you offer on the early drafts of videos.",
  "translatedText": "దీన్ని భాగస్వామ్యం చేసినందుకు కెవిన్‌కి చాలా ధన్యవాదాలు, అలాగే, ఛానెల్‌కు మద్దతు ఇచ్చినందుకు మరియు వీడియోల ప్రారంభ చిత్తుప్రతులపై మీరు అందించిన అన్ని అభిప్రాయాలకు కూడా అన్ని పోషకులకు ధన్యవాదాలు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1455.26,
  "end": 1485.1
 }
]