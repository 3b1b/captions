[
 {
  "input": "Let's kick things off with a quiz.",
  "translatedText": "Hadi bir testle konuya başlayalım.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution.",
  "translatedText": "Bu tanıdık çan eğrisi şekliyle normal bir dağılım aldığımı ve bu dağılımdan elde edilen bir rastgele değişken x'im olduğunu varsayalım.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable.",
  "translatedText": "Yani şu anda baktığınız şey o rastgele değişkenin tekrarlanan örnekleri.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values.",
  "translatedText": "Kısa bir hatırlatma olarak, bu eğriyi yorumlama şekliniz, fonksiyonun gerçekte anlamı şudur: Eğer numunenizin belirli bir değer aralığına düşme olasılığını istiyorsanız, bunun negatif bir ile iki arasında sonuçlanma olasılığını söyleyin. Bu, bu değer aralığında bu eğrinin altındaki alana eşit olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means.",
  "translatedText": "Eğrinin aslında anlamı budur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation.",
  "translatedText": "Aynı zamanda normal dağılıma uygun ikinci bir rastgele değişken de ele alacağım, ama belki bu sefer biraz daha yayılmış, biraz daha büyük bir standart sapma.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you.",
  "translatedText": "Ve işte size bir test.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable.",
  "translatedText": "Bu değişkenlerin her ikisini de tekrar tekrar örneklerseniz ve her yinelemede iki sonucu toplarsanız, o zaman bu toplam kendi rastgele değişkeni gibi davranır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at?",
  "translatedText": "Ve soru şu, baktığınız toplamı hangi dağılım tanımlıyor?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape.",
  "translatedText": "Biraz düşünürsünüz, belki bir tahmininiz vardır, belki de ben bilmiyorum bunun başka bir normal dağılım veya farklı şekle sahip bir şey olduğunu düşünürsünüz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough.",
  "translatedText": "Söylemeye gerek yok, tahmin etmek yeterli değil.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do.",
  "translatedText": "Gerçek test, aldığınız cevabı neden aldığınızı açıklayabilmektir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability.",
  "translatedText": "Bu durumda, cevabın neden bu olduğuna dair iliklerinize kadar bu kadar derin bir anlayışa sahipseniz, normal dağılımların neden olasılıkta yaptıkları özel işleve hizmet ettiğini anlama yolunda uzun bir yol kat etmiş olacaksınız.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones.",
  "translatedText": "Uzaklaştırırsak, bu aslında sadece normal dağılıma sahip olanları değil, dağılımlarına bakılmaksızın iki farklı rastgele değişkeni nasıl ekleyeceğinizle ilgili çok daha genel bir ders anlamına gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables.",
  "translatedText": "Bu, söz konusu değişkenlerin temelini oluşturan dağılımlara uyguladığınız özel bir işlem anlamına gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution.",
  "translatedText": "Operasyonun özel bir adı var, buna evrişim denir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem.",
  "translatedText": "Ve bugün sizin ve benim yapacağımız ilk şey, sürekli fonksiyonlar için bir evrişimin neye benzediğini görselleştirmek için iki farklı yolu motive etmek ve oluşturmak ve ardından bu iki farklı görselleştirmenin her birinin, özel bir yaklaşımla, farklı şekillerde nasıl yardımcı olabileceği hakkında konuşmaktır. Merkezi limit teoremine odaklanın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it.",
  "translatedText": "Genel dersi yaptıktan sonra açılış sınavına dönmek ve soruyu yanıtlamanın alışılmadık derecede tatmin edici bir yolunu sunmak istiyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel.",
  "translatedText": "Kısa bir not olarak, aranızdaki düzenli izleyiciler bu kanalda evrişimlerle ilgili bir videonun zaten olduğunu biliyor olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts.",
  "translatedText": "Ancak bunun oldukça farklı bir odağı vardı, biz sadece ayrık vakayı yapıyorduk ve sadece olasılığı değil, bunun çok çeşitli bağlamlarda ortaya çıkma yollarını da göstermek istedim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video.",
  "translatedText": "Biraz tuhaf bir durumdayım çünkü bunun bu video için bir önkoşul olması pek mantıklı değil, ama bence bugün ısınmanın en iyi yolu, esasen o videoda kullanılan örneklerden birini ele almak.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead.",
  "translatedText": "Yani eğer doğrudan oradan geliyorsanız, muhtemelen güvenli bir şekilde ilerleyebilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in.",
  "translatedText": "Aksi halde hemen içeri girelim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers.",
  "translatedText": "Bu açılış sınavı sorusu için, rastgele değişkenlerin her biri, tüm olası gerçek sayılar olan sürekli sonsuz bir değer aralığında bir değer alabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice.",
  "translatedText": "Daha ayrık ve sınırlı bir ortamda, örneğin bir çift ağırlıklı zar atmak gibi bir ortamda ısınırsak çok daha kolay olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration.",
  "translatedText": "Burada, baktığınız animasyon iki ağırlıklı zarı simüle ediyor ve muhtemelen ne olduğunu anlayabilirsiniz, ancak açıkça belirtmek gerekirse, mavi zar daha düşük değerlere eğilimli görünen bir dağılımı takip ediyor, kırmızı kalıbın farklı bir dağılımı var ve her birinden tekrar tekrar örnek alıyorum ve her yinelemede iki değerin toplamını kaydediyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely.",
  "translatedText": "Bunun gibi örnekleri çok ama çok farklı zamanlarda tekrarlamak size nihai dağılım hakkında sezgisel bir fikir verebilir, ancak bugünkü asıl görevimiz bu dağılımı tam olarak hesaplamaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities?",
  "translatedText": "Tüm olasılıklar için 2, 3, 4 veya 5 atmanın kesin olasılığı nedir?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself.",
  "translatedText": "Bu çok zor bir soru değil, aslında durup kendi başınıza çözmeyi denemenizi tavsiye ederim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation.",
  "translatedText": "Bu ısınma bölümündeki ana amaç, temeldeki hesaplamayı görselleştirebileceğiniz iki farklı yoldan geçmek olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid.",
  "translatedText": "Örneğin, bunu düşünmeye başlamanın bir yolu, 36 farklı olası sonucun olması ve bu sonuçları 6x6'lık küçük bir ızgarada düzenleyebilmemizdir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say?",
  "translatedText": "Şimdi size bu belirli sonuçlardan herhangi birini görme olasılığı nedir, diyelim ki mavi 4 ve kırmızı 2 görme olasılığını sorsaydım ne derdiniz?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2.",
  "translatedText": "Mavi 4'ün olasılığının kırmızı 2'nin olasılığıyla çarpımı olması gerektiğini söyleyebiliriz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other.",
  "translatedText": "Ve kalıp rulolarının birbirinden bağımsız olduğunu varsayarsak bu doğru olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent.",
  "translatedText": "Bunun biraz bilgiçlik tasladığını düşünebilirsiniz, tabii ki kalıp atışları birbirinden bağımsız olmalıdır, ancak bu vurgulanmaya değer bir noktadır çünkü buradan itibaren yapacağımız her şey, bu basit örnekten başlayarak şuraya kadar ilerleyecektir: merkezi limit teoremi, rastgele değişkenlerin bağımsız olduğunu varsayar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds.",
  "translatedText": "Gerçek dünyada bu varsayımın gerçekten geçerli olup olmadığına dikkat etmelisiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers.",
  "translatedText": "Şimdi yapacağım şey, tüm olası sonuçları içeren bu tabloyu almak, ancak onu bazı sayılarla doldurmaya başlamak.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution.",
  "translatedText": "Belki mavi zarın tüm olasılıklarının rakamlarını alt tarafa, kırmızı zarın tüm olasılıklarını da sol tarafa koyacağız ve sonra tablonun içindeki her sonucun olasılığının yer aldığı tabloyu dolduracağız. mavi dağılımdan bir sayı ile kırmızı dağılımdan bir sayı arasındaki bir çarpıma benziyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table.",
  "translatedText": "Bunu düşünmenin başka bir yolu da temelde bir çarpım tablosu oluşturuyor olmamızdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot.",
  "translatedText": "Tüm bunları biraz daha görselleştirmek için, bu tür üç boyutlu çizimde bu olasılıkların her birini karenin üzerindeki bir çubuğun yüksekliği olarak çizebiliriz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice.",
  "translatedText": "Bir bakıma bu üç boyutlu çizim, bir çift zarın atılmasıyla ilgili bilmemiz gereken tüm verileri taşıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums?",
  "translatedText": "Ve soru şu: Bilmek istediğimiz şeyi, çeşitli farklı toplamların olasılıklarını nasıl çıkaracağız?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal.",
  "translatedText": "Peki, tüm sonuçları belirli bir toplamla, diyelim altı toplamla vurgularsanız, bunların hepsinin nasıl belirli bir köşegen üzerinde sonuçlandığına dikkat edin.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven.",
  "translatedText": "Toplamın yedi olduğu tüm çiftleri vurgularsam aynı sonuç çıkar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal.",
  "translatedText": "Farklı bir diyagonal boyunca oturuyorlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals.",
  "translatedText": "Her olası toplamın olasılığını hesaplamak için yapmanız gereken, bu köşegenlerden birinde yer alan tüm girdileri toplamaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices.",
  "translatedText": "3 boyutlu çizimi yukarı çekerek, olası toplamların dağılımının bu grafiğin tüm yüksekliklerini bu çapraz dilimlerden biri boyunca birleştirmeye benzediğini söyleyerek daha sonra bununla nereye gideceğimizi daha iyi öngörebiliriz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions.",
  "translatedText": "Sanki tüm olası sonuçlar için bu tam dağılımı almışız ve onu yönlerden birine göre daraltmışız gibi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot.",
  "translatedText": "Ve itiraf etmeliyim ki, bu noktada animasyonlarla biraz eğleniyorum, bunu kalem ve kağıtla yapıyor olsaydınız, üç boyutlu bir çizim yapıyor olurdunuz gibi değil.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun!",
  "translatedText": "Ama eğlenceli!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see.",
  "translatedText": "Bu yönde daralttığınızda aslında aynı dağılımı elde edersiniz ki bunu yapmanız gerektiğini biliyordum ama yine de bunu görmek eğlenceli.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof.",
  "translatedText": "Ayrıca, tüm bunlar biraz eğlenceli ve hatta gereksiz derecede karmaşık görünse de, çapraz dilimler hakkındaki bu sezginin gerçekten tatmin edici bir kanıt olarak daha sonra bize geri döneceğine söz verebilirim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it.",
  "translatedText": "Ancak basit zar olayına biraz daha uzun süre odaklanarak düşünebileceğimiz ikinci yolu burada bulabilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left.",
  "translatedText": "Alttaki dağılımı alın ve yatay olarak çevirin, böylece sağdan sola doğru ilerledikçe zar değerleri artar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask?",
  "translatedText": "Bunu neden yapıyorsunuz diye sorabilirsiniz?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other.",
  "translatedText": "Şimdi hangi zar değeri çiftinin birbiriyle aynı hizada olduğuna dikkat edin.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on.",
  "translatedText": "Şu anki konumuyla 1 ve 6, 2 ve 5, 3 ve 4 vb. var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7.",
  "translatedText": "Toplamı 7'ye ulaşan değer çiftlerinin tamamıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results.",
  "translatedText": "Yani eğer 7 gelme olasılığını düşünmek istiyorsanız, bu hesaplamayı aklınızda tutmanın bir yolu birbiriyle aynı hizada olan tüm olasılık çiftlerini almak, bu çiftleri birbiriyle çarpmak ve sonra hepsini toplamaktır. Sonuçlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product.",
  "translatedText": "Bazılarınız bunu bir tür nokta çarpımı olarak düşünmek isteyebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many.",
  "translatedText": "Ancak bir bütün olarak operasyon yalnızca bir nokta çarpımından değil, birçok noktadan oluşur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5.",
  "translatedText": "Alt dağılımı biraz daha sola kaydırırsak, bu durumda kalıp değerlerinin 1 ve 4, 2 ve 3, 3 ve 2, 4 ve 1, yani tüm Toplamları 5'e eşit olanlar, şimdi nokta çarpımı alırsak, sıralanan olasılık çiftlerini çarpar ve toplarız, bu bize toplam 5 gelme olasılığını verir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way.",
  "translatedText": "Genel olarak, bu bakış açısından bakıldığında, toplamın tam dağılımını hesaplamak, alt dağılımı çeşitli farklı konumlara kaydırmak ve yol boyunca bu nokta çarpımı hesaplamak gibi görünür.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier.",
  "translatedText": "Bu, daha önce incelediğimiz çapraz dilimlerle tamamen aynı işlemdir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation.",
  "translatedText": "Bunlar, temelde yatan aynı operasyonu görselleştirmenin sadece iki farklı yoludur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk.",
  "translatedText": "Ve onu nasıl görselleştirmeyi seçerseniz seçin, iki farklı dağılımı alıp ilgili rastgele değişkenlerin toplamını tanımlayan yeni bir dağılım ortaya koyan bu işleme evrişim denir ve biz bunu genellikle bu yıldız işaretiyle belirtiriz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function.",
  "translatedText": "Aslında bunun hakkında düşünmek istediğiniz yol, özellikle de sürekli durumu hazırlarken, onu iki farklı fonksiyonun birleşimi ve yeni bir fonksiyon ortaya çıkarmak olarak düşünmektir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px.",
  "translatedText": "Örneğin bu durumda ilk dağıtım için fonksiyona px adını verebilirim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability.",
  "translatedText": "Bu, zar için olası bir değeri (3 gibi) alan ve buna karşılık gelen olasılığı ortaya koyan bir fonksiyon olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum.",
  "translatedText": "Benzer şekilde, ikinci dağılımımızın fonksiyonu py olsun ve toplamın dağılımını tanımlayan fonksiyon da px artı y olsun.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py.",
  "translatedText": "Dilde px artı y'nin px ile py arasındaki bir evrişime eşit olduğunu söyleyebilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like.",
  "translatedText": "Ve şimdi düşünmenizi istediğim şey bu operasyonun formülünün nasıl olması gerektiğidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols?",
  "translatedText": "Onu görselleştirmenin iki farklı yolunu gördünüz, ama aslında bunu sembollerle nasıl yazacağız?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4.",
  "translatedText": "Yönünüzü bulmak için, toplamı 4'e ulaşan girdi çiftlerine karşılık gelen tüm farklı ikili çarpımları topladığınız 4'ü takma durumu gibi belirli bir örneği yazmak yararlı olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look.",
  "translatedText": "Daha genel olarak şöyle görünebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y.",
  "translatedText": "Bu yeni fonksiyon, rastgele değişkenleriniz için benim s diyeceğim olası bir toplamı girdi olarak alıyor ve çıktısı, x ve y için bir grup değer çiftinin toplamı gibi görünüyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6.",
  "translatedText": "Her zamanki gibi yazılma şekli dışında, x ve y ile yazmak değil, bunun yerine sadece bu değişkenlerden birine, bu durumda x'e odaklanırız, onun olası tüm değerleri arasında değişmesine izin veririz, bu da burada sadece 1'den 6'ya gitmek anlamına gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s.",
  "translatedText": "Ve y yazmak yerine s eksi x yazarsınız, yani toplamın s olmasını sağlamak için sayı ne olursa olsun.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written.",
  "translatedText": "Şimdi aranızdaki zeki biri formülün yazılış şekliyle ilgili biraz garip bir tuhaflık fark edebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined.",
  "translatedText": "Örneğin, s eşittir 4 gibi belirli bir değeri yerine koyarsanız ve bu toplamı açarsanız, x'in 1'den 6'ya kadar olan tüm olası değerler arasında değişmesine izin verirseniz, bazen karşılık gelen y değeri, bizim tanımladığımız alanın altına düşer. açıkça tanımladık.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2.",
  "translatedText": "Örneğin, 0'ı, eksi 1'i ve eksi 2'yi koyarsınız.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted.",
  "translatedText": "Aslında o kadar da önemli değil, aslında tüm bu değerlerin 0 olduğunu söylersiniz, dolayısıyla sonraki terimlerin tümü sayılmaz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense.",
  "translatedText": "Ve bu bir bakıma mantıklı olmalı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1?",
  "translatedText": "Kırmızı zarın yuvarlanarak eksi 1 olma olasılığı nedir?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0.",
  "translatedText": "Peki, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome.",
  "translatedText": "Bu imkansız bir sonuçtur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers.",
  "translatedText": "Bir sonraki adım olarak dikkatimizi, rastgele değişkeninizin tüm olası gerçek sayılar gibi sonsuz bir sürekliliğin herhangi bir yerinde değerler alabileceği sürekli dağılımlara çevirelim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives.",
  "translatedText": "Belki hava durumu modellemesi yapıyorsunuz ve yarın öğlen sıcaklığını tahmin etmeye çalışıyorsunuz, ya da bazı finansal tahminler yapıyorsunuz ya da belki bir otobüs gelmeden önce tipik bekleme sürelerini modelliyorsunuz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity.",
  "translatedText": "Sürekliliği halletmeniz gereken her türlü şey var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density.",
  "translatedText": "Çizdiğimiz tüm grafiklerde, x değeri hala rastgele değişkenin alabileceği olası bir sayıyı temsil ediyor, ancak y ekseninin yorumlanması biraz farklı çünkü bu artık olasılığı temsil etmiyor, bunun yerine olasılık yoğunluğu denilen şeyin grafiğini çiziyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal.",
  "translatedText": "Bu daha önce konuştuğumuz bir konu, o yüzden konuyu biliyorsun.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range.",
  "translatedText": "Temel olarak, değişkeninizin bir örneğinin belirli bir aralığa düşme olasılığı, o aralıktaki eğrinin altındaki alana benzer.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF.",
  "translatedText": "Bu eğriyi tanımlayan fonksiyona genellikle olasılık yoğunluk fonksiyonu adı verilir; bu, yeterince yaygın bir ifadedir ve sıklıkla PDF kısaltması olarak kullanılır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range.",
  "translatedText": "Ve tüm bunları yazmanın doğru yolu, örneğinizin belirli bir aralığa düşme olasılığının, PDF'nizin o aralıktaki olasılık yoğunluk fonksiyonu integraline benzediğini söylemek olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case.",
  "translatedText": "Genel bir kural olarak, ayrık durumda bir toplam gördüğünüzde, sürekli durumda bir integral kullanırsınız.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example.",
  "translatedText": "Ana örneğimiz için bunun ne anlama geldiğini düşünelim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum.",
  "translatedText": "Diyelim ki elimizde iki farklı rastgele değişken var ama bu sefer her biri sürekli bir dağılım izleyecek ve biz bunların toplamını ve bu toplamı açıklayan yeni dağılımı anlamak istiyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy.",
  "translatedText": "Muhtemelen formülün ne olacağını sadece benzetme yoluyla tahmin edebilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products.",
  "translatedText": "Hatırlayın, az önce yazdığımız formülde, p alt x birinci değişkenin fonksiyonu ve p sub y ikinci değişkenin fonksiyonudur, aralarındaki evrişim, bu değişkenlerin toplamını tanımlayan şeyin kendisi görünür bir grup ikili çarpımı birleştirdiğimiz bir toplam gibi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral.",
  "translatedText": "Sürekli durumdaki ifade gerçekten %100 benzer görünüyor, sadece bu toplamı bir integralle değiştiriyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating.",
  "translatedText": "Bazen öğrenciler evrişimin bu tanımını bağlam dışında gördüklerinde, bu biraz korkutucu görünebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms.",
  "translatedText": "Umarım benzetme bunu açıklığa kavuşturmak için yeterlidir, ancak sürekli doğa ona gerçekten farklı bir tat veriyor ve kendi şartlarında ne anlama geldiğini düşünmek için birkaç dakika ayırmaya değer.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying.",
  "translatedText": "Ve böylece, ifadenin her bir parçasını ve gerçekte ne söylediğini ortaya çıkarmaya yardımcı olacak küçük, etkileşimli bir demo hazırladım.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables.",
  "translatedText": "Örneğin, bu integraldeki ilk terim f(x)'tir ve bu, iki rastgele değişkenden ilkinin yoğunluk fonksiyonunu temsil eder.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything.",
  "translatedText": "Ve bu durumda, bu dağılım için bu tür kama şeklindeki fonksiyonu seçiyorum, ama bu herhangi bir şey olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution.",
  "translatedText": "Benzer şekilde g, ikinci rastgele değişkenin yoğunluk fonksiyonunu temsil ediyor, bunun için bu tür çift yumru şeklindeki dağılımı seçiyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s.",
  "translatedText": "Ve daha önce belirli bir toplamla tüm olası zar değeri çiftlerini incelediğimiz gibi, bu integral hakkında düşünmek istediğiniz şey de, onun yapmak istediği şeyin, x ve y'nin tüm olası değer çiftleri üzerinde yineleme yapmak olduğudur. belirli bir toplamla sınırlı, s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s.",
  "translatedText": "Bunu simetrik olarak yapmak için pek iyi bir gösterime sahip değiliz, dolayısıyla bunu genel olarak yazma şeklimiz değişkenlerden birine yapay bir vurgu yapıyor, bu durumda x, burada x değerinin tüm olası gerçek sayılara yayılmasına izin veriyoruz, Negatif sonsuzdan sonsuza kadar ve g fonksiyonuna koyacağımız şey s eksi x'tir, esasen bu toplamın s olarak sınırlandırıldığından emin olmak için ne olması gerekiyorsa o olur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x.",
  "translatedText": "Demo için g'nin grafiğini doğrudan çizmek yerine, g'nin s eksi x'in grafiğini çizmek istiyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like?",
  "translatedText": "Kendinize şu soruyu sorabilirsiniz: Bu neye benziyor?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally.",
  "translatedText": "Giriş olarak negatif x'i girerseniz grafiğin yatay olarak dönmesi etkisi olur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative.",
  "translatedText": "Ve sonra, bir tür sabit olarak kabul edilen bu s parametresini dahil edersek, bu, s'nin pozitif ya da negatif olmasına bağlı olarak grafiği sola ya da sağa kaydırma etkisine sahip olur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit.",
  "translatedText": "Demoda s, yakalayıp biraz değiştireceğim bir parametredir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs.",
  "translatedText": "Gerçek eğlence, bu iki grafiğin arasındaki çarpım olan integralin tüm içeriğinin grafiğini çizmekten gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph.",
  "translatedText": "Bu, daha önce gördüğümüz ikili çarpımların listesine benzer, ancak bu durumda, tüm ikili çarpımları toplamak yerine, bunları bir araya getirmek istiyoruz, bunu bu çarpım grafiğinin altındaki alan olarak yorumlayabilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area.",
  "translatedText": "Bu s değeri etrafında kaydırdıkça, çarpım grafiğinin şekli değişir ve buna karşılık gelen alan da değişir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter.",
  "translatedText": "Soldaki üç grafiğin tümü için girdinin x olduğunu ve s sayısının da yalnızca bir parametre olduğunu unutmayın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be.",
  "translatedText": "Ancak sağdaki son grafik için, ortaya çıkan evrişimin kendisi için, bu s sayısı bu fonksiyonun girdisidir ve karşılık gelen çıktı, sol alt grafiğin alanı ne olursa olsun, f ve g'nin bu birleşimi arasındaki integral ne olursa olsun olur. olduğu ortaya çıktı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half.",
  "translatedText": "Burada basit bir örnek yaparsak, örneğin iki rastgele değişkenimizin her birinin negatif yarım ve pozitif yarım değerleri arasında tekdüze bir dağılım izlediğini söylersek faydalı olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else.",
  "translatedText": "Yani bu, yoğunluk fonksiyonlarımızın her birinin bu tür bir silindir şapka şekline sahip olduğu gibi görünüyor; burada grafik, negatif yarım ile pozitif yarım arasındaki tüm girdiler için 1'e eşittir ve diğer her yerde 0'a eşittir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like?",
  "translatedText": "Soru her zaman olduğu gibi toplamın dağılımının nasıl olması gerektiğidir?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo.",
  "translatedText": "Demomuzun içinde nasıl göründüğünü size göstereyim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation.",
  "translatedText": "Bu durumda iki grafiğin arasındaki çarpımın yorumlanması oldukça kolaydır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else.",
  "translatedText": "Grafiklerin birbiriyle çakıştığı her yerde 1, diğer her yerde 0'dır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve.",
  "translatedText": "Yani eğer bu parametreyi üstteki grafiklerimiz hiç örtüşmeyecek kadar sola kaydırırsam, çarpım grafiği her yerde 0 olur ve bu, bunun elde edilmesi imkansız bir toplam olduğunu söylemenin bir yoludur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense.",
  "translatedText": "Bu mantıklı olmalı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1.",
  "translatedText": "İki değişkenin her biri yalnızca eksi yarıya kadar düşebilir, dolayısıyla toplam asla eksi 1'in altına inemez.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum.",
  "translatedText": "S'yi sağa kaydırmaya başladığımda ve grafikler birbiriyle örtüştükçe alan, grafikler tamamen örtüşene kadar doğrusal olarak artıyor ve maksimuma ulaşıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape.",
  "translatedText": "Ve bu noktadan sonra tekrar doğrusal olarak azalmaya başlıyor, bu da toplamın dağılımının bu tür bir kama şeklini aldığı anlamına geliyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice.",
  "translatedText": "Ve bunun aslında bir çift zar, yani ağırlıksız zarlar hakkında düşünen herkese biraz tanıdık geldiğini düşünüyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape.",
  "translatedText": "Burada, iki farklı düzgün dağılımlı değişkeni toplarsanız, toplamın dağılımı belirli bir kama şekline sahip olur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again.",
  "translatedText": "Olasılıklar maksimum 7'ye çıkana kadar artar ve sonra tekrar azalır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables.",
  "translatedText": "Bunun çok daha eğlenceli hale geldiği nokta ise, iki eşit dağılımlı değişkenin toplamını istemek yerine, üç farklı eşit dağılımlı değişkeni topladığımızda nasıl görüneceğini soruyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two.",
  "translatedText": "İlk başta, bilmiyorum diyebilirsiniz, iki yerine üç şeyi birleştirmeyi görselleştirmenin yeni bir yoluna ihtiyacımız var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function.",
  "translatedText": "Ama gerçekte burada yapabileceğiniz şey, ilk ikisinin toplamını kendi değişkenleri olarak düşünmek, ki bunun da kama şekli dağılımını takip ettiğini anladık ve sonra bununla silindir şapka fonksiyonu arasında bir evrişim almak.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like.",
  "translatedText": "Demoyu yukarı çektiğimizde bunun neye benzeyeceği görülüyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph.",
  "translatedText": "Bir kez daha, silindir şapka fonksiyonunu gerçekten güzel yapan şey, onunla çarpmanın bir nevi üst grafikteki değerleri filtreleme etkisine sahip olmasıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window.",
  "translatedText": "Alttaki ürün tıpkı üstteki grafiğin kopyası gibi görünüyor ancak belirli bir pencereyle sınırlı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly.",
  "translatedText": "Yine, bunu sola ve sağa kaydırdıkça ve alan büyüyüp küçüldükçe, sonuç ortada maksimuma çıkıyor ancak her iki tarafa doğru daralıyor, ancak bu sefer daha düzgün bir şekilde oluyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph.",
  "translatedText": "Sanki sol üstteki grafiğin hareketli ortalamasını alıyormuşuz gibi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph.",
  "translatedText": "Aslında bu, bir nevi daha fazlasıdır; bu kelimenin tam anlamıyla sol üstteki grafiğin hareketli ortalamasıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further.",
  "translatedText": "Yapmayı düşünebileceğiniz şeylerden biri bunu daha da ileri götürmek olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat.",
  "translatedText": "Başlama şeklimiz iki silindir şapka fonksiyonunu birleştirmekti ve bu kamayı elde ettik, sonra ilk fonksiyonu bu kamayla değiştirdik ve sonra evrişimi aldığımızda üç farklı tekdüze değişkenin toplamını tanımlayan daha düzgün bir şekil elde ettik, ancak bunu yapabilirdik. sadece tekrarla.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables.",
  "translatedText": "Bunu üstteki fonksiyonla değiştirin ve sonra bunu düz dikdörtgen fonksiyonla evriştirin; göreceğimiz sonuç, eşit dağılımlı dört rastgele değişkenin toplamını tanımlamalıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect.",
  "translatedText": "Merkezi limit teoremi hakkındaki videoyu izleyen herhangi biriniz ne bekleyeceğini biliyor olmalı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve.",
  "translatedText": "Bu işlemi defalarca tekrarladığımızda şekil giderek daha çok çan eğrisine benziyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time.",
  "translatedText": "Veya daha kesin olmak gerekirse, standart sapmanın bir olduğundan emin olmak için her yinelemede x eksenini yeniden ölçeklendirmeliyiz, çünkü bu tekrarlanan evrişimin, bir tür tekrarlanan hareketli ortalama sürecinin baskın etkisi, fonksiyonun üzerinde düzleştirilmesidir. zaman.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero.",
  "translatedText": "Yani limitte sıfıra doğru düzleşiyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all?",
  "translatedText": "Ancak yeniden ölçeklendirme, evet evet evet, düzleştiğini biliyorum ama tüm bunların altında yatan gerçek şekil nedir demenin bir yoludur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true.",
  "translatedText": "Olasılığın en havalı gerçeklerinden biri olan merkezi limit teoreminin ifadesi, esasen herhangi bir dağılımla başlayabileceğiniz ve bunun hala doğru olacağıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution.",
  "translatedText": "Belirli bir rastgele değişkenin giderek daha büyük toplamlarını temsil eden bunun gibi tekrarlanan evrişimleri aldığınızda, bu toplamı tanımlayan dağılım, normal bir dağılımdan çok farklı görünmeye başlayabilir, zamanla keyfi bir hale gelene kadar giderek daha fazla düzleşir. normal dağılıma yakındır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution.",
  "translatedText": "Evrişim boyunca tekrarlanan yumuşatma işlemini uyguladığımızda, sanki bir çan eğrisi, gevşek bir ifadeyle, mümkün olan en yumuşak dağılım, tüm olası fonksiyonların uzayında çekici bir sabit nokta gibi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions?",
  "translatedText": "Doğal olarak neden normal dağılımlar olduğunu merak edebilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one?",
  "translatedText": "Neden bu işlev de başka bir işlev değil?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions.",
  "translatedText": "Bu çok iyi bir cevap ve bence cevabı göstermenin en eğlenceli yolu evrişimler için göstereceğimiz son görselleştirmenin ışığında olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals?",
  "translatedText": "Ayrık durumda, iki görselleştirmemizden ilkinin bu tür bir çarpım tablosu oluşturmayı, tüm olası sonuçların olasılıklarını göstermeyi ve köşegenler boyunca toplama yapmayı içerdiğini hatırlıyor musunuz?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case.",
  "translatedText": "Muhtemelen şimdiye kadar tahmin etmişsinizdir, ancak son adımımız bunu sürekli duruma genelleştirmek olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful.",
  "translatedText": "Ve çok güzel ama biraz dikkatli olmalısın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier?",
  "translatedText": "Daha önce sahip olduğumuz f(x) ve g(y) fonksiyonlarını ele alırsak, bu durumda daha önce baktığımız olası çiftler tablosuna benzer ne olabilir?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind.",
  "translatedText": "Bu durumda, değişkenlerin her biri herhangi bir reel sayıyı alabilir, dolayısıyla tüm olası reel sayı çiftlerini düşünmek istiyoruz ve akla xy düzlemi geliyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions.",
  "translatedText": "Her iki dağılımdan da örnekleme yaptığımızda her nokta olası bir sonuca karşılık gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent.",
  "translatedText": "Şimdi, bu sonuçlardan herhangi birinin olasılığı, xy, ya da daha doğrusu bu noktanın etrafındaki olasılık yoğunluğu, yine ikisinin bağımsız olduğu varsayıldığında, f x çarpı g y gibi görünecektir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane.",
  "translatedText": "Dolayısıyla yapılacak doğal bir şey, f(x) çarpı g(y) fonksiyonunun grafiğini iki değişkenli bir fonksiyon olarak çizmek, bu da xy düzleminin üzerinde bir yüzeye benzeyen bir şey verir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph.",
  "translatedText": "Bu örnekte, x değerlerinin değiştiğini gördüğümüz bir açıdan baktığımızda, ilk grafiğimizin şeklini aldığına, ancak başka bir açıdan baktığımızda, y yönündeki değişimi vurguladığımızda, nasıl olduğuna dikkat edin. ikinci grafiğimizin şeklini alır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need.",
  "translatedText": "Bu üç boyutlu grafik ihtiyacımız olan tüm bilgileri kodlamaktadır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome.",
  "translatedText": "Her olası sonuç için tüm olasılık yoğunluklarını gösterir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant.",
  "translatedText": "Ve eğer görüşünüzü yalnızca x artı y'nin belirli bir toplamla sınırlandırıldığı sonuçlarla sınırlamak istiyorsanız, bu, görüşümüzü köşegen bir dilimle, özellikle de x artı y'nin bir sabite eşit olduğu çizgisi üzerindeki bir dilimle sınırlamak gibi görünür.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at.",
  "translatedText": "Bu kısıtlamaya tabi sonuç için tüm olası olasılık yoğunlukları, bu grafiğin altında bir tür dilim gibi görünür ve kısıtladığımız belirli toplamın etrafında değişiklik yaptıkça, baktığımız belirli çapraz dilimin etrafında da değişir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface.",
  "translatedText": "Şimdi tahmin edebileceğiniz şey şu ki, tüm olasılık yoğunluklarını bu dilimlerden biri boyunca birleştirmenin yolu, bunları bir araya getirmenin yolu, bu eğrinin altındaki alan, yani yüzeyin bir dilimi olarak yorumlanabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct.",
  "translatedText": "Ve bu neredeyse doğru.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution.",
  "translatedText": "İkinin karekökü faktörüyle ilgili konuşmamız gereken ince bir ayrıntı var, ancak sabit bir faktöre kadar bu dilimlerin alanları bize evrişimin değerlerini verir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier.",
  "translatedText": "Aslında baktığımız bu dilimlerin tümü, daha önce baktığımız ürün grafiğiyle tamamen aynı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g.",
  "translatedText": "Burada, bu noktayı vurgulamak için, her iki görselleştirmeyi yan yana getireyim ve s'nin değerini yavaş yavaş azaltacağım; bu, solda farklı dilimlere baktığımız anlamına gelir, sağda ise 'bizim' anlamına gelir. g'nin değiştirilmiş grafiği etrafında yeniden kayma.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice.",
  "translatedText": "Sağ alttaki grafiğin şeklinin, yani fonksiyonlar arasındaki çarpımın, tüm noktalarda köşegen dilimin şekliyle nasıl tamamen aynı göründüğüne dikkat edin.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense.",
  "translatedText": "Ve bu mantıklı olmalı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing.",
  "translatedText": "Bunlar aynı şeyi görselleştirmenin iki farklı yoludur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum.",
  "translatedText": "Kelimelere döktüğümüzde çok gibi görünüyor, ancak baktığımız şey, belirli bir toplamdaki girdi çiftlerine karşılık gelen fonksiyonların çıktıları arasındaki tüm olası ürünlerdir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it.",
  "translatedText": "Yine ağız dolusu olacak ama sanırım ne dediğimi anlıyorsunuz ve artık bunu görmenin iki farklı yolu var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation.",
  "translatedText": "Çapraz dilim görselleştirmesinin güzel yanı, bunun simetrik bir işlem olduğunu çok daha net bir şekilde ortaya koymasıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f.",
  "translatedText": "f'nin g ile evrişimi ile g'nin f ile evrişiminin aynı şey olduğu çok daha açıktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape.",
  "translatedText": "Teknik olarak diyagonal dilimler tam olarak aynı şekilde değildir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2.",
  "translatedText": "Aslında 2'nin karekökü kadar uzatılmışlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step.",
  "translatedText": "Bunun temel nedeni, eğer x artı y'nin bir sabite eşit olduğu bu doğrulardan birinde küçük bir adım attığınızı hayal ederseniz, o zaman x değerinizdeki değişimin, buradaki delta x'in, o adımın uzunluğuyla aynı şey olmamasıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2.",
  "translatedText": "Bu adım aslında 2'nin karekökü kadar daha uzundur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices.",
  "translatedText": "Aranızda durup düşünmek isteyen matematik meraklıları için ekrana bir not bırakacağım, ancak sonuç çok basit bir şekilde evrişimimizin çıktılarının teknik olarak bu köşegen dilimlerin alanları olmadığıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2.",
  "translatedText": "Bu alanları 2'nin kareköküne bölmemiz gerekiyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful.",
  "translatedText": "Bir an için tüm bunlardan geriye adım attığımda bunun çok güzel olduğunu düşünüyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables?",
  "translatedText": "Çok basit bir soruyla ya da en azından görünüşte basit bir soruyla başladık: İki rastgele değişkeni nasıl toplarsınız?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions.",
  "translatedText": "Ve sonunda iki farklı fonksiyonun birleştirilmesine yönelik bu çok karmaşık işlemle karşı karşıya kalıyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something?",
  "translatedText": "Bunu anlamanın en az iki güzel yolu var, ama yine de bazılarınız ellerini kaldırıp şöyle diyebilir: Güzel resimler iyidir, güzeldir, ama bunlar gerçekten bir şeyler hesaplamanıza yardımcı oluyor mu?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables.",
  "translatedText": "Örneğin, normal dağılıma sahip iki rastgele değişkenin eklenmesiyle ilgili açılış sınavı sorusunu hâlâ yanıtlamadım.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here.",
  "translatedText": "Peki, bu tür bir soruya yaklaşmanın olağan yolu, eğer bir ödevde ya da buna benzer bir şeyde ortaya çıkarsa, normal dağılım formülünü evrişimin, yani integralin tanımına yerleştirmektir. burada anlatıyordum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat.",
  "translatedText": "Ve bu durumda, görselleştirmeler aslında sadece ifadenin ne söylediğini netleştirmek için orada olacaktır, ancak arka koltukta oturuyorlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself.",
  "translatedText": "Bu durumda integral çok zor değil, analitik yöntemler var ama bu örnekte size görselleştirmelerin, özellikle köşegen dilimlerin, hesaplamada çok daha ön ve merkez rol oynayacağı daha eğlenceli bir yöntem göstermek istiyorum. kendini kanıtlıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself.",
  "translatedText": "Birçoğunuzun bunun kendiniz için nasıl görüneceğini tahmin etmek için biraz zaman ayırmayı gerçekten sevebileceğini düşünüyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of.",
  "translatedText": "İki normal dağılım durumunda bu 3 boyutlu grafiğin nasıl görüneceğini ve hangi özelliklerden yararlanabileceğinizi düşünün.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation.",
  "translatedText": "Ve her iki dağılımın da aynı standart sapmaya sahip olduğu bir durumla başlamanız kesinlikle en kolay yoldur.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video.",
  "translatedText": "Ayrıntıları istediğiniz zaman ve cevabın merkezi limit teoremine nasıl uyduğunu görmek için bir sonraki videoda bana katılın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]