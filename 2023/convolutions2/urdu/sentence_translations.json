[
 {
  "input": "Let's kick things off with a quiz. ",
  "translatedText": "آئیے کوئز کے ساتھ چیزوں کو شروع کریں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution. ",
  "translatedText": "فرض کریں کہ میں اس مانوس گھنٹی وکر کی شکل کے ساتھ ایک عام تقسیم لیتا ہوں، اور میرے پاس ایک بے ترتیب متغیر x ہے جو اس تقسیم سے اخذ کیا گیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable. ",
  "translatedText": "تو جو آپ ابھی دیکھ رہے ہیں وہ اس بے ترتیب متغیر کے بار بار نمونے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values. ",
  "translatedText": "اور ایک فوری یاد دہانی کے طور پر، جس طرح سے آپ اس منحنی خطوط کی تشریح کرتے ہیں، فنکشن کا اصل مطلب کیا ہے، یہ ہے کہ اگر آپ یہ امکان چاہتے ہیں کہ آپ کا نمونہ اقدار کی ایک دی گئی حد کے اندر آتا ہے، تو اس امکان کو کہیں کہ یہ منفی ایک اور دو کے درمیان ختم ہوتا ہے۔، ٹھیک ہے، یہ اقدار کی اس حد میں اس منحنی خطوط کے نیچے رقبہ کے برابر ہوگا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means. ",
  "translatedText": "وکر کا اصل مطلب یہی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation. ",
  "translatedText": "میں ایک دوسرے بے ترتیب متغیر کو بھی کھینچوں گا، ایک عام تقسیم کے بعد، لیکن شاید اس بار تھوڑا سا زیادہ پھیلا ہوا، تھوڑا بڑا معیاری انحراف۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you. ",
  "translatedText": "اور یہاں آپ کے لیے کوئز ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable. ",
  "translatedText": "اگر آپ ان دونوں متغیرات کا بار بار نمونہ لیتے ہیں، اور ہر تکرار میں آپ دو نتائج کو شامل کرتے ہیں، ٹھیک ہے، تو یہ رقم اپنے بے ترتیب متغیر کی طرح برتاؤ کرتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape. ",
  "translatedText": "اور سوال یہ ہے کہ کون سی تقسیم اس رقم کو بیان کرتی ہے جسے آپ دیکھ رہے ہیں؟ آپ تھوڑی دیر کے لیے اس کے بارے میں سوچیں، ہو سکتا ہے آپ کو اندازہ ہو، ہو سکتا ہے آپ سوچیں، میں نہیں جانتا، یہ ایک اور عام تقسیم ہے، یا کچھ اور شکل ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough. ",
  "translatedText": "کہنے کی ضرورت نہیں، اندازہ لگانا کافی نہیں ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do. ",
  "translatedText": "اصل کوئز یہ بتانے کے قابل ہونا ہے کہ آپ کو جواب کیوں ملتا ہے جو آپ کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability. ",
  "translatedText": "اس صورت میں، اگر آپ کے پاس اپنی ہڈیوں کے بصری سطح تک اتنی گہری سمجھ ہے کہ اس کا جواب کیا ہے، تو آپ کو یہ سمجھنے کی طرف بہت لمبا فاصلہ طے کرنا پڑے گا کہ عام تقسیم کیوں اس خاص کام کو انجام دیتی ہے جو وہ امکان میں کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones. ",
  "translatedText": "اگرچہ زوم آؤٹ کرنے کا مطلب یہ ہے کہ یہ ایک بہت زیادہ عام سبق ہے کہ آپ کس طرح دو مختلف بے ترتیب متغیرات کو ان کی تقسیم سے قطع نظر شامل کرتے ہیں، ضروری نہیں کہ صرف عام طور پر تقسیم شدہ متغیر ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables. ",
  "translatedText": "یہ ایک خاص آپریشن کے مترادف ہے جسے آپ ان متغیرات کے تحت تقسیم پر لاگو کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution. ",
  "translatedText": "آپریشن کا ایک خاص نام ہے، اسے کنوولوشن کہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem. ",
  "translatedText": "اور آپ اور میں آج جو بنیادی کام کریں گے وہ یہ ہے کہ یہ تصور کرنے کے لیے دو الگ الگ طریقوں کی حوصلہ افزائی اور تعمیر کرنا ہے کہ مسلسل افعال کے لیے کنولیشن کیسا لگتا ہے، اور پھر اس بارے میں بات کرنا کہ یہ دو مختلف تصورات کس طرح مختلف طریقوں سے مددگار ثابت ہو سکتے ہیں، ایک خاص کے ساتھ۔مرکزی حد نظریہ پر توجہ مرکوز کریں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it. ",
  "translatedText": "عام سبق کرنے کے بعد، میں ابتدائی کوئز پر واپس جانا چاہتا ہوں اور اس کا جواب دینے کے لیے غیر معمولی طور پر تسلی بخش طریقہ پیش کرنا چاہتا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel. ",
  "translatedText": "ایک فوری ضمنی نوٹ کے طور پر، آپ میں سے باقاعدہ ناظرین کو معلوم ہو سکتا ہے کہ اس چینل پر کنوولوشنز کے بارے میں پہلے سے ہی ایک ویڈیو موجود ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts. ",
  "translatedText": "لیکن اس کی توجہ بالکل مختلف تھی، ہم صرف مجرد کیس کر رہے تھے، اور میں نہ صرف امکان ظاہر کرنا چاہتا تھا بلکہ ان طریقوں کو بھی دکھانا چاہتا تھا جو مختلف سیاق و سباق میں سامنے آتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video. ",
  "translatedText": "میں قدرے عجیب و غریب جگہ پر ہوں کیونکہ اس ویڈیو کے لیے اس کا لازمی شرط ہونا واقعی کوئی معنی نہیں رکھتا، لیکن میرے خیال میں آج گرم ہونے کا بہترین طریقہ یہ ہے کہ اس ویڈیو میں استعمال کی گئی مثالوں میں سے ایک کو بنیادی طور پر شامل کیا جائے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead. ",
  "translatedText": "لہذا اگر آپ اس سے سیدھے آ رہے ہیں، تو آپ شاید محفوظ طریقے سے آگے بڑھ سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in. ",
  "translatedText": "بصورت دیگر، آئیے اندر کودیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers. ",
  "translatedText": "اس ابتدائی کوئز سوال کے لیے، ہر ایک بے ترتیب متغیر اقدار کی مسلسل لامحدود رینج میں ایک قدر لے سکتا ہے، تمام ممکنہ حقیقی اعداد۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice. ",
  "translatedText": "یہ بہت آسان ہو جائے گا اگر ہم ایسی ترتیب میں گرم ہو جائیں جو زیادہ مجرد اور محدود ہو، جیسے شاید وزنی نرد کا جوڑا گھومنا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration. ",
  "translatedText": "یہاں، آپ جس اینیمیشن کو دیکھ رہے ہیں وہ دو وزنی ڈائس کی نقل کر رہی ہے، اور آپ شاید بتا سکتے ہیں کہ کیا ہو رہا ہے، لیکن صرف اس کو واضح کرنے کے لیے، نیلی ڈائی ایک ایسی تقسیم کی پیروی کر رہی ہے جو کم اقدار کی طرف متعصب معلوم ہوتی ہے، سرخ die کی ایک الگ تقسیم ہے، اور میں بار بار ہر ایک سے نمونہ لے رہا ہوں اور ہر تکرار پر دو قدروں کا مجموعہ ریکارڈ کر رہا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely. ",
  "translatedText": "اس طرح کے نمونوں کو کئی، کئی بار دہرانے سے آپ کو حتمی تقسیم کا اندازہ ہو سکتا ہے، لیکن آج ہمارا اصل کام اس تقسیم کو درست طریقے سے شمار کرنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities? ",
  "translatedText": "تمام امکانات کے لیے 2، یا 3، یا 4، یا 5، کو آن اور آن کرنے کا قطعی امکان کیا ہے؟ یہ کوئی زیادہ مشکل سوال نہیں ہے، میں درحقیقت آپ کی حوصلہ افزائی کروں گا کہ آپ توقف کریں اور خود ہی اس پر عمل کرنے کی کوشش کریں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation. ",
  "translatedText": "اس وارم اپ سیکشن کا بنیادی مقصد دو الگ الگ طریقوں سے گزرنا ہے جس سے آپ بنیادی حساب کتاب کو تصور کر سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid. ",
  "translatedText": "مثال کے طور پر، ایک طریقہ جس کے بارے میں آپ سوچنا شروع کر سکتے ہیں وہ یہ ہے کہ 36 الگ الگ ممکنہ نتائج ہیں، اور ہم ان نتائج کو 6x6 گرڈ میں ترتیب دے سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say? ",
  "translatedText": "اب اگر میں آپ سے پوچھوں کہ ان مخصوص نتائج میں سے کسی ایک کو دیکھنے کا امکان کیا ہے، کہیے کہ نیلے 4 اور سرخ 2 کو دیکھنے کا امکان، آپ کیا کہیں گے؟ ہم کہہ سکتے ہیں کہ یہ اس نیلے 4 کے امکان کو سرخ 2 کے امکان سے ضرب دینا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other. ",
  "translatedText": "اور یہ فرض کرنا درست ہوگا کہ ڈائی رولز ایک دوسرے سے آزاد ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent. ",
  "translatedText": "آپ کہہ سکتے ہیں کہ یہ ایک قسم کا پیڈینٹک ہے، یقیناً ڈائی رولز کو ایک دوسرے سے آزاد ہونا چاہیے، لیکن یہ ایک نقطہ پر زور دینے کے قابل ہے کیونکہ ہم یہاں سے جو کچھ بھی کرنے جا رہے ہیں، اس سادہ مثال سے لے کر پورے راستے تک۔مرکزی حد نظریہ، فرض کرتا ہے کہ بے ترتیب متغیرات آزاد ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds. ",
  "translatedText": "حقیقی دنیا میں، آپ اس بات پر گہری نظر رکھنا چاہتے ہیں کہ آیا یہ مفروضہ حقیقت میں قائم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers. ",
  "translatedText": "اب میں جو کرنے جا رہا ہوں وہ یہ ہے کہ تمام ممکنہ نتائج کے اس گرڈ کو لے جاؤں، لیکن اسے کچھ نمبروں سے بھرنا شروع کروں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution. ",
  "translatedText": "ہوسکتا ہے کہ ہم نیلے مرنے کے تمام امکانات کے اعداد کو نیچے ڈالیں گے، سرخ مرنے کے تمام امکانات یہاں بائیں جانب ڈالیں گے، اور پھر ہم اس گرڈ کو بھریں گے جہاں گرڈ کے اندر ہر نتیجہ کا امکان نیلی تقسیم سے ایک نمبر اور سرخ تقسیم سے ایک نمبر کے درمیان کچھ مصنوعات کی طرح لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table. ",
  "translatedText": "اس کے بارے میں سوچنے کا دوسرا طریقہ یہ ہے کہ ہم بنیادی طور پر ایک ضرب کی میز بنا رہے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot. ",
  "translatedText": "ان سب کے بارے میں تھوڑا زیادہ بصری ہونے کے لیے، ہم اس طرح کے تین جہتی پلاٹ میں مربع کے اوپر ایک بار کی اونچائی کے طور پر ان میں سے ہر ایک احتمال کو پلاٹ کر سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice. ",
  "translatedText": "کسی لحاظ سے، یہ تین جہتی پلاٹ وہ تمام ڈیٹا رکھتا ہے جو ہمیں ڈائس کے جوڑے کو رول کرنے کے بارے میں جاننے کی ضرورت ہوگی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal. ",
  "translatedText": "اور اس لیے سوال یہ ہے کہ ہم جس چیز کو جاننا چاہتے ہیں اسے کیسے نکالیں گے، مختلف مختلف رقموں کے امکانات؟ ٹھیک ہے، اگر آپ تمام نتائج کو ایک خاص رقم کے ساتھ نمایاں کرتے ہیں، تو چھ کا مجموعہ کہیں، دیکھیں کہ یہ سب ایک مخصوص اخترن پر کیسے ختم ہوتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven. ",
  "translatedText": "ایک ہی ڈیل اگر میں ان تمام جوڑوں کو نمایاں کروں جہاں رقم سات ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal. ",
  "translatedText": "وہ ایک مختلف اخترن کے ساتھ بیٹھتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals. ",
  "translatedText": "لہذا ہر ممکنہ رقم کے امکان کا حساب لگانے کے لیے، آپ یہ کرتے ہیں کہ آپ ان تمام اندراجات کو جوڑتے ہیں جو ان اخترن میں سے کسی ایک پر بیٹھتی ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices. ",
  "translatedText": "3D پلاٹ کو کھینچتے ہوئے، ہم اس بات کی بہتر پیش گوئی کر سکتے ہیں کہ ہم بعد میں یہ کہہ کر کہاں جائیں گے کہ ممکنہ رقوم کی تقسیم اس پلاٹ کی تمام اونچائیوں کو ان ترچھے ٹکڑوں میں سے ایک کے ساتھ ملانے کی طرح دکھائی دیتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions. ",
  "translatedText": "ایسا لگتا ہے کہ ہم نے اس مکمل تقسیم کو تمام ممکنہ نتائج کے لیے لے لیا ہے اور ہم نے اسے کسی ایک سمت میں منہدم کر دیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot. ",
  "translatedText": "اور اقرار میں، میں اس وقت اینیمیشنز کے ساتھ تھوڑا سا مزہ کر رہا ہوں، ایسا نہیں ہے کہ اگر آپ پنسل اور کاغذ کے ساتھ یہ کام کر رہے ہوں، تو آپ کچھ تین جہتی پلاٹ بنا رہے ہوں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun! ",
  "translatedText": "لیکن یہ مزہ ہے! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see. ",
  "translatedText": "جب آپ اسے اس سمت سے گراتے ہیں، تو آپ کو درحقیقت وہی تقسیم ملتی ہے، جو میں جانتا تھا کہ آپ کو ہونا چاہیے، لیکن یہ دیکھنا پھر بھی مزہ آتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof. ",
  "translatedText": "اس کے علاوہ، اگرچہ یہ سب کچھ تھوڑا سا چنچل یا غیر ضروری طور پر پیچیدہ بھی لگ سکتا ہے، میں آپ سے وعدہ کر سکتا ہوں کہ اخترن سلائسس کے بارے میں یہ بصیرت بعد میں ایک حقیقی اطمینان بخش ثبوت کے لیے ہمارے پاس واپس آئے گی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it. ",
  "translatedText": "لیکن سادہ ڈائس کیس پر تھوڑی دیر تک توجہ مرکوز کرتے ہوئے، یہ دوسرا طریقہ ہے جس سے ہم اس کے بارے میں سوچ سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left. ",
  "translatedText": "نیچے کی تقسیم کو لیں اور اسے افقی طور پر پلٹائیں، تاکہ جب آپ دائیں سے بائیں جائیں تو ڈائی ویلیوز بڑھیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other. ",
  "translatedText": "ایسا کیوں کرتے ہیں، آپ پوچھ سکتے ہیں؟ ٹھیک ہے، اب غور کریں کہ ڈائس ویلیو کے کون سے جوڑے ایک دوسرے کے ساتھ ملتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on. ",
  "translatedText": "جیسا کہ یہ ابھی پوزیشن میں ہے، ہمارے پاس 1 اور 6، 2 اور 5، 3 اور 4 وغیرہ ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7. ",
  "translatedText": "یہ تمام اقدار کے جوڑے ہیں جو 7 تک جوڑتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results. ",
  "translatedText": "لہذا اگر آپ 7 کو رول کرنے کے امکان کے بارے میں سوچنا چاہتے ہیں، تو اس حساب کو اپنے ذہن میں رکھنے کا ایک طریقہ یہ ہے کہ تمام امکانات کے جوڑے جو ایک دوسرے کے ساتھ ملتے ہیں، ان جوڑوں کو ایک ساتھ ضرب کریں، اور پھر تمام کو جوڑ دیں۔نتائج. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product. ",
  "translatedText": "آپ میں سے کچھ لوگ اسے ڈاٹ پروڈکٹ کی ایک قسم کے طور پر سوچنا پسند کر سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many. ",
  "translatedText": "لیکن مجموعی طور پر آپریشن صرف ایک ڈاٹ پروڈکٹ نہیں ہے، بلکہ بہت سے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5. ",
  "translatedText": "اگر ہم نیچے کی تقسیم کو تھوڑا سا اور بائیں طرف سلائیڈ کریں، تو اس صورت میں ایسا لگتا ہے کہ ڈائی ویلیوز جو لائن اپ ہیں 1 اور 4، 2 اور 3، 3 اور 2، 4 اور 1، دوسرے لفظوں میں تمام وہ جو 5 تک جوڑتے ہیں، ٹھیک ہے اب اگر ہم ڈاٹ پروڈکٹ لیتے ہیں، تو ہم ان امکانات کے جوڑوں کو ضرب دیتے ہیں جو لائن میں ہوتے ہیں اور ان کو ایک ساتھ جوڑتے ہیں، اس سے ہمیں 5 کا رول کرنے کا کل امکان ملے گا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way. ",
  "translatedText": "عام طور پر، اس نقطہ نظر سے، رقم کی مکمل تقسیم کا حساب لگانا ایسا لگتا ہے کہ نیچے کی تقسیم کو مختلف مختلف پوزیشنوں میں سلائیڈ کرنا اور راستے میں اس ڈاٹ پروڈکٹ کو کمپیوٹنگ کرنا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier. ",
  "translatedText": "یہ بالکل وہی آپریشن ہے جیسا کہ ترچھی سلائسیں ہم پہلے دیکھ رہے تھے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation. ",
  "translatedText": "وہ ایک ہی بنیادی آپریشن کو تصور کرنے کے صرف دو مختلف طریقے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk. ",
  "translatedText": "اور اگرچہ آپ اسے تصور کرنے کا انتخاب کرتے ہیں، یہ عمل جو دو مختلف تقسیموں میں لیتا ہے اور متعلقہ بے ترتیب متغیرات کے مجموعے کو بیان کرتے ہوئے ایک نیا نکالتا ہے، اسے کنوولوشن کہا جاتا ہے، اور ہم اکثر اس کو اس ستارے سے ظاہر کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function. ",
  "translatedText": "واقعی جس طرح سے آپ اس کے بارے میں سوچنا چاہتے ہیں، خاص طور پر جیسا کہ ہم مسلسل کیس کے لیے ترتیب دیتے ہیں، اسے دو مختلف فنکشنز کو یکجا کرنے اور ایک نئے فنکشن کو تھوکنے کے طور پر سوچنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px. ",
  "translatedText": "مثال کے طور پر، اس معاملے میں، شاید میں پہلی تقسیم کے لیے فنکشن کا نام px دیتا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability. ",
  "translatedText": "یہ ایک ایسا فنکشن ہوگا جو ڈائی کے لیے ممکنہ قدر لیتا ہے، جیسے کہ 3، اور یہ متعلقہ امکان کو ختم کر دیتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum. ",
  "translatedText": "اسی طرح، آئیے اپنی دوسری تقسیم کے لیے py کو فنکشن بننے دیں، اور px پلس y کو رقم کی تقسیم کو بیان کرنے والا فنکشن بنائیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py. ",
  "translatedText": "لنگو میں، آپ جو کہیں گے وہ یہ ہے کہ px جمع y px اور py کے درمیان کنولیشن کے برابر ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like. ",
  "translatedText": "اور میں چاہتا ہوں کہ آپ اب اس بارے میں سوچیں کہ اس آپریشن کا فارمولا کیسا ہونا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4. ",
  "translatedText": "آپ نے اسے دیکھنے کے دو مختلف طریقے دیکھے ہیں، لیکن ہم اسے علامتوں میں کیسے لکھتے ہیں؟ اپنے بیرنگ حاصل کرنے کے لیے، ہو سکتا ہے کہ ایک مخصوص مثال لکھنا مددگار ہو، جیسے کہ 4 میں پلگ لگانے کا معاملہ، جہاں آپ ان پٹ کے جوڑے کے مطابق تمام مختلف جوڑے کے مطابق مصنوعات جو کہ 4 تک کا اضافہ کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look. ",
  "translatedText": "اور عام طور پر، یہاں یہ ہے کہ یہ کیسا نظر آتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y. ",
  "translatedText": "یہ نیا فنکشن ان پٹ کے طور پر آپ کے بے ترتیب متغیرات کے لیے ایک ممکنہ رقم لیتا ہے، جسے میں s کہوں گا، اور جو اس سے نکلتا ہے وہ x اور y کے لیے قدروں کے جوڑے کے ایک گروپ پر ایک رقم کی طرح لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6. ",
  "translatedText": "عام طریقہ کے علاوہ اسے x اور y کے ساتھ لکھنا نہیں ہے، بلکہ اس کے بجائے ہم صرف ان متغیرات میں سے ایک پر توجہ مرکوز کرتے ہیں، اس صورت میں x، اسے اپنی تمام ممکنہ قدروں پر رینج کرنے دیتے ہیں، جس کا مطلب یہاں صرف 1 سے 6 تک جانا ہے۔. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s. ",
  "translatedText": "اور y لکھنے کے بجائے، آپ s مائنس x لکھتے ہیں، بنیادی طور پر جو بھی نمبر ہونا چاہیے اس بات کو یقینی بنانے کے لیے کہ رقم s ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written. ",
  "translatedText": "اب آپ میں سے ہوشیار اس فارمولے کے ساتھ تھوڑا سا عجیب و غریب نرالا محسوس کر سکتا ہے جیسا کہ یہ لکھا گیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined. ",
  "translatedText": "مثال کے طور پر، اگر آپ کسی دی گئی ویلیو کو پلگ ان کرتے ہیں جیسے s برابر 4، اور آپ اس رقم کو کھولتے ہیں، x کو 1 سے لے کر 6 تک جانے والی تمام ممکنہ قدروں پر چھوڑ دیتے ہیں، تو بعض اوقات یہ متعلقہ y قدر اس ڈومین سے نیچے گر جاتی ہے جو ہم' واضح طور پر بیان کیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2. ",
  "translatedText": "مثال کے طور پر، آپ 0 اور منفی 1 اور منفی 2 میں پلگ ان کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted. ",
  "translatedText": "یہ حقیقت میں اتنا بڑا سودا نہیں ہے، بنیادی طور پر آپ صرف یہ کہیں گے کہ یہ تمام اقدار 0 ہیں، اس لیے ان تمام بعد کی شرائط کو شمار نہیں کیا جاتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense. ",
  "translatedText": "اور یہ ایک قسم کا احساس ہونا چاہئے. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1? ",
  "translatedText": "ریڈ ڈائی رولز کے منفی 1 بننے کا کیا امکان ہے؟ ٹھیک ہے، یہ 0 ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome. ",
  "translatedText": "یہ ایک ناممکن نتیجہ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers. ",
  "translatedText": "اگلے قدم کے طور پر، آئیے اپنی توجہ مسلسل تقسیم کی طرف مبذول کریں، جہاں آپ کا بے ترتیب متغیر لامحدود تسلسل میں کہیں بھی قدروں کو لے سکتا ہے، جیسے تمام ممکنہ حقیقی اعداد۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives. ",
  "translatedText": "ہوسکتا ہے کہ آپ موسم کی ماڈلنگ کر رہے ہوں اور کل دوپہر کے وقت درجہ حرارت کی پیشن گوئی کرنے کی کوشش کر رہے ہوں، یا آپ کچھ مالی تخمینہ لگا رہے ہوں، یا ہو سکتا ہے کہ آپ بس کے آنے سے پہلے انتظار کے عام اوقات کی ماڈلنگ کر رہے ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity. ",
  "translatedText": "ہر طرح کی چیزیں ہیں جہاں آپ کو تسلسل کو سنبھالنے کی ضرورت ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density. ",
  "translatedText": "ان تمام گرافوں میں جو ہم کھینچتے ہیں، x قدر اب بھی ایک ممکنہ نمبر کی نمائندگی کرتی ہے جسے بے ترتیب متغیر لے سکتا ہے، لیکن y-axis کی تشریح تھوڑی مختلف ہے، کیونکہ اب یہ امکان کی نمائندگی نہیں کرتا، بجائے اس کے کہ وہ چیز جو ہم گرافنگ کر رہے ہیں جسے امکانی کثافت کہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal. ",
  "translatedText": "یہ وہ چیز ہے جس کے بارے میں ہم پہلے بھی بات کر چکے ہیں، لہذا آپ کو معاہدے کا علم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range. ",
  "translatedText": "بنیادی طور پر، اس بات کا امکان کہ آپ کے متغیر کا نمونہ ایک دی گئی حد میں آتا ہے اس حد میں وکر کے نیچے والے علاقے کی طرح لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF. ",
  "translatedText": "اس منحنی خطوط کو بیان کرنے والے فنکشن کو عام طور پر امکانی کثافت کا فنکشن کہا جاتا ہے، یہ کافی عام جملہ ہے کہ اسے اکثر صرف پی ڈی ایف کا مخفف دیا جاتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range. ",
  "translatedText": "اور اس لیے ان سب کو لکھنے کا مناسب طریقہ یہ ہے کہ یہ کہنا کہ آپ کا نمونہ ایک دی گئی رینج میں آنے کا امکان آپ کے پی ڈی ایف کے انٹیگرل کی طرح لگتا ہے، اس حد میں امکانی کثافت کا فنکشن۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case. ",
  "translatedText": "انگوٹھے کے عام اصول کے طور پر، کسی بھی وقت جب آپ مجرد کیس میں کوئی رقم دیکھیں گے، آپ مسلسل کیس میں انٹیگرل استعمال کریں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example. ",
  "translatedText": "تو آئیے اس کے بارے میں سوچتے ہیں کہ ہماری اہم مثال کے لئے اس کا کیا مطلب ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum. ",
  "translatedText": "ہم کہتے ہیں کہ ہمارے پاس دو مختلف بے ترتیب متغیرات ہیں، لیکن اس بار ہر ایک مسلسل تقسیم کی پیروی کرے گا، اور ہم ان کی رقم اور اس رقم کو بیان کرنے والی نئی تقسیم کو سمجھنا چاہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy. ",
  "translatedText": "آپ شاید پہلے ہی اندازہ لگا سکتے ہیں کہ صرف تشبیہ سے فارمولا کیا ہوگا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products. ",
  "translatedText": "یاد رکھیں، اس فارمولے میں جو ہم نے ابھی لکھا ہے، جہاں p sub x پہلے متغیر کا فنکشن ہے اور p sub y دوسرے متغیر کا فنکشن ہے، ان کے درمیان کنولیشن، ان متغیرات کا مجموعہ بیان کرنے والی چیز خود نظر آتی ہے۔ایک رقم کی طرح جہاں ہم جوڑے کے مطابق مصنوعات کا ایک گروپ جوڑتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral. ",
  "translatedText": "مسلسل کیس میں اظہار واقعی 100% مشابہ نظر آتا ہے، یہ صرف اتنا ہے کہ ہم اس رقم کو انٹیگرل کے لیے تبدیل کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating. ",
  "translatedText": "بعض اوقات جب طالب علم سیاق و سباق سے ہٹ کر کنولیشن کی اس تعریف کو دیکھتے ہیں، تو یہ تھوڑا سا خوف زدہ لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms. ",
  "translatedText": "امید ہے کہ مشابہت اسے واضح کرنے کے لیے کافی ہے، لیکن مسلسل فطرت واقعی اسے ایک مختلف ذائقہ فراہم کرتی ہے، اور یہ سوچنے کے لیے چند منٹ لگانے کے قابل ہے کہ اس کا اپنی شرائط پر کیا مطلب ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying. ",
  "translatedText": "اور اس لیے میں نے ایک چھوٹا سا انٹرایکٹو ڈیمو اکٹھا کیا ہے جو اظہار کے ہر حصے کو کھولنے میں مدد کرتا ہے اور یہ کیا کہہ رہا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables. ",
  "translatedText": "مثال کے طور پر، اس انٹیگرل میں پہلی اصطلاح x کا f ہے، جو دو بے ترتیب متغیرات میں سے پہلے کے لیے کثافت کے فنکشن کی نمائندگی کرتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything. ",
  "translatedText": "اور اس معاملے میں میں اس تقسیم کے لیے پچر کے سائز کے فنکشن کا انتخاب کر رہا ہوں، لیکن یہ کچھ بھی ہو سکتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution. ",
  "translatedText": "اسی طرح، جی دوسرے رینڈم متغیر کے لیے کثافت کے فنکشن کی نمائندگی کرتا ہے، جس کے لیے میں اس طرح کی ڈبل گانٹھ کی شکل والی تقسیم کا انتخاب کر رہا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s. ",
  "translatedText": "اور اسی طرح جس طرح اس سے پہلے ہم ایک دی گئی رقم کے ساتھ ڈائس ویلیو کے تمام ممکنہ جوڑوں پر گئے تھے، جس طرح سے آپ اس انٹیگرل کے بارے میں سوچنا چاہتے ہیں وہ یہ ہے کہ یہ جو کرنا چاہتا ہے وہ x اور y کی اقدار کے تمام ممکنہ جوڑوں پر اعادہ کرنا ہے۔دی گئی رقم تک محدود، s۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s. ",
  "translatedText": "اس کو ہم آہنگی کے ساتھ کرنے کے لیے ہمارے پاس واقعی کوئی اچھی علامت نہیں ہے، لہذا اس کے بجائے جس طرح سے ہم اسے عام طور پر لکھتے ہیں اس سے کسی ایک متغیر پر مصنوعی زور دیا جاتا ہے، اس صورت میں x، جہاں ہم اس قدر x کو تمام ممکنہ حقیقی نمبروں پر چھوڑ دیتے ہیں، لامحدودیت تک منفی انفینٹی، اور جس چیز کو ہم فنکشن جی میں لگاتے ہیں وہ ہے s مائنس x، بنیادی طور پر جو کچھ بھی ہونا ہے اس بات کو یقینی بنانے کے لیے کہ یہ رقم s ہونے پر مجبور ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x. ",
  "translatedText": "تو ڈیمو کے لیے، جی کو براہ راست گراف کرنے کے بجائے، میں s مائنس x کا گراف گراف کرنا چاہتا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally. ",
  "translatedText": "آپ اپنے آپ سے پوچھ سکتے ہیں، یہ کیسا لگتا ہے؟ ٹھیک ہے، اگر آپ منفی x کو ان پٹ کے طور پر لگاتے ہیں، تو اس کا اثر گراف کے گرد افقی طور پر پلٹنے کا ہوتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative. ",
  "translatedText": "اور پھر اگر ہم اس پیرامیٹر s میں ڈالتے ہیں، جسے کسی طرح کا مستقل سمجھا جاتا ہے، جس کا اثر گراف کو بائیں یا دائیں منتقل کرنے کا ہوتا ہے، اس پر منحصر ہے کہ s مثبت ہے یا منفی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit. ",
  "translatedText": "ڈیمو میں، s ایک پیرامیٹر ہے جسے میں صرف پکڑوں گا اور تھوڑا سا ادھر ادھر منتقل کروں گا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs. ",
  "translatedText": "اصل مزہ ان دو گرافس کے درمیان انٹیگرل، پروڈکٹ کے پورے مواد کو گراف کرنے سے آتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph. ",
  "translatedText": "یہ جوڑے کے لحاظ سے پروڈکٹس کی فہرست کے مشابہ ہے جو ہم نے پہلے دیکھے تھے، لیکن اس صورت میں، ان تمام جوڑے کے مطابق پروڈکٹس کو شامل کرنے کے بجائے، ہم ان کو ایک ساتھ ضم کرنا چاہتے ہیں، جس کی آپ اس پروڈکٹ گراف کے نیچے والے حصے کے طور پر تشریح کریں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area. ",
  "translatedText": "جیسا کہ میں s کی اس قدر کے ارد گرد منتقل ہوتا ہوں، اس پروڈکٹ گراف کی شکل بدل جاتی ہے، اور اسی طرح متعلقہ علاقہ بھی بدل جاتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter. ",
  "translatedText": "ذہن میں رکھیں، بائیں جانب تینوں گرافس کے لیے، ان پٹ x ہے، اور نمبر s صرف ایک پیرامیٹر ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be. ",
  "translatedText": "لیکن دائیں طرف کے فائنل گراف کے لیے، نتیجے میں آنے والے کنوولوشن کے لیے، یہ نمبر s اس فنکشن کا ان پٹ ہے، اور متعلقہ آؤٹ پٹ وہ ہے جو بھی نیچے بائیں گراف کا رقبہ ہو، چاہے f اور g کے اس امتزاج کے درمیان جو بھی ہو۔نکلا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half. ",
  "translatedText": "یہاں، یہ مددگار ہو سکتا ہے اگر ہم ایک سادہ سی مثال کریں، یہ کہیں کہ ہمارے دو بے ترتیب متغیرات میں سے ہر ایک منفی آدھے اور مثبت نصف کے درمیان یکساں تقسیم کی پیروی کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else. ",
  "translatedText": "تو ایسا لگتا ہے کہ ہمارے کثافت کے افعال میں سے ہر ایک کی ٹاپ ہیٹ کی شکل ہوتی ہے، جہاں گراف منفی ڈیڑھ نصف اور مثبت ڈیڑھ نصف کے درمیان تمام ان پٹ کے لیے 1 کے برابر ہوتا ہے، اور یہ ہر جگہ 0 کے برابر ہوتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like? ",
  "translatedText": "سوال، ہمیشہ کی طرح، یہ ہے کہ رقم کی تقسیم کیسی ہونی چاہیے؟ ٹھیک ہے، میں آپ کو دکھاتا ہوں کہ یہ ہمارے ڈیمو کے اندر کیسا لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation. ",
  "translatedText": "اس صورت میں، دو گراف کے درمیان پروڈکٹ کی واقعی آسان تشریح ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else. ",
  "translatedText": "یہ 1 ہے جہاں بھی گراف ایک دوسرے کے ساتھ اوورلیپ ہوتے ہیں، لیکن ہر جگہ 0۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve. ",
  "translatedText": "لہذا اگر میں اس پیرامیٹر کو بائیں طرف اتنا زیادہ سلائیڈ کرتا ہوں کہ ہمارے اوپری گراف بالکل اوورلیپ نہیں ہوتے ہیں، تو پروڈکٹ گراف ہر جگہ 0 ہے، اور یہ کہنے کا ایک طریقہ ہے کہ یہ حاصل کرنا ایک ناممکن رقم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense. ",
  "translatedText": "اس کا مطلب ہونا چاہئے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1. ",
  "translatedText": "دو متغیرات میں سے ہر ایک صرف منفی ڈیڑھ سے کم ہو سکتا ہے، اس لیے رقم کبھی بھی منفی 1 سے کم نہیں ہو سکتی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum. ",
  "translatedText": "جیسا کہ میں s کو دائیں طرف سلائیڈ کرنا شروع کرتا ہوں اور گراف ایک دوسرے کے ساتھ اوورلیپ ہو جاتے ہیں، رقبہ لکیری طور پر بڑھتا جاتا ہے جب تک کہ گراف مکمل طور پر اوورلیپ نہ ہو جائیں اور یہ زیادہ سے زیادہ حد تک نہ پہنچ جائے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape. ",
  "translatedText": "اور پھر اس نقطہ کے بعد، یہ دوبارہ لکیری طور پر کم ہونا شروع ہو جاتا ہے، جس کا مطلب ہے کہ رقم کی تقسیم اس قسم کی پچر کی شکل اختیار کر لیتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice. ",
  "translatedText": "اور میں تصور کرتا ہوں کہ یہ حقیقت میں کسی ایسے شخص کے لیے کچھ حد تک مانوس محسوس ہوتا ہے جس نے نرد کے جوڑے کے بارے میں سوچا ہو، یعنی بغیر وزن کے نرد۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape. ",
  "translatedText": "وہاں، اگر آپ دو مختلف یکساں طور پر تقسیم شدہ متغیرات کو جوڑتے ہیں، تو رقم کی تقسیم میں ایک خاص پچر کی شکل ہوتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again. ",
  "translatedText": "امکانات اس وقت تک بڑھ جاتے ہیں جب تک کہ وہ 7 پر زیادہ سے زیادہ نہیں ہو جاتے، اور پھر وہ دوبارہ نیچے کم ہو جاتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables. ",
  "translatedText": "جہاں یہ بہت زیادہ مزہ آتا ہے وہ یہ ہے کہ اگر دو یکساں تقسیم شدہ متغیرات کی رقم طلب کرنے کے بجائے، میں آپ سے پوچھتا ہوں کہ اگر ہم تین مختلف یکساں تقسیم شدہ متغیرات کو شامل کریں تو یہ کیسا لگتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two. ",
  "translatedText": "پہلے تو آپ کہہ سکتے ہیں، مجھے نہیں معلوم، ہمیں دو کے بجائے تین چیزوں کو ملا کر تصور کرنے کے لیے کسی نئے طریقے کی ضرورت ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function. ",
  "translatedText": "لیکن واقعی آپ یہاں جو کچھ کر سکتے ہیں وہ یہ ہے کہ پہلے دو کے مجموعے کے بارے میں ان کے اپنے متغیر کے طور پر سوچیں، جس کا ہم نے ابھی اندازہ لگایا ہے کہ اس پچر کی شکل کی تقسیم کے بعد، اور پھر اس اور ٹاپ ہیٹ فنکشن کے درمیان ایک کنولیشن لیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like. ",
  "translatedText": "ڈیمو کو کھینچنا، یہاں یہ ہے کہ وہ کیسا نظر آئے گا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph. ",
  "translatedText": "ایک بار پھر، جو چیز ٹاپ ہیٹ فنکشن کو واقعی اچھا بناتی ہے وہ یہ ہے کہ اس سے ضرب لگانے سے اوپر کے گراف سے اقدار کو فلٹر کرنے کا اثر پڑتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window. ",
  "translatedText": "نیچے کی پروڈکٹ بالکل اوپر والے گراف کی کاپی کی طرح نظر آتی ہے، لیکن ایک مخصوص ونڈو تک محدود ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly. ",
  "translatedText": "ایک بار پھر، جیسا کہ میں اسے بائیں اور دائیں کے ارد گرد سلائیڈ کرتا ہوں، اور رقبہ بڑا اور چھوٹا ہوتا جاتا ہے، نتیجہ درمیان میں زیادہ سے زیادہ نکلتا ہے لیکن دونوں طرف سے باہر نکل جاتا ہے، سوائے اس وقت کے یہ زیادہ آسانی سے کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph. ",
  "translatedText": "یہ اس طرح ہے جیسے ہم اس اوپری بائیں گراف کی حرکت پذیری اوسط لے رہے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph. ",
  "translatedText": "درحقیقت، یہ صرف ایک قسم سے زیادہ نہیں ہے، یہ لفظی طور پر اوپری بائیں گراف کی چلتی اوسط ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further. ",
  "translatedText": "ایک چیز جو آپ سوچ سکتے ہیں کہ اسے اور بھی آگے لے جانا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat. ",
  "translatedText": "جس طرح سے ہم نے شروع کیا وہ دو ٹاپ ہیٹ فنکشنز کو ملا رہا تھا اور ہمیں یہ ویج ملا، پھر ہم نے پہلے فنکشن کو اس ویج سے بدل دیا، اور پھر جب ہم نے کنوولوشن لیا تو ہمیں یہ ہموار شکل ملی جس میں تین الگ الگ یکساں متغیرات کا مجموعہ بیان کیا گیا، لیکن ہم کر سکتے تھے۔صرف دہرائیں. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables. ",
  "translatedText": "اسے سب سے اوپر کے فنکشن کے لیے تبدیل کریں، اور پھر اسے فلیٹ مستطیل فنکشن کے ساتھ جوڑیں، اور جو بھی نتیجہ ہم دیکھتے ہیں اسے چار یکساں طور پر تقسیم شدہ بے ترتیب متغیرات کا مجموعہ بیان کرنا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect. ",
  "translatedText": "آپ میں سے کوئی بھی جس نے مرکزی حد نظریہ کے بارے میں ویڈیو دیکھی ہے اسے معلوم ہونا چاہیے کہ کیا توقع رکھنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve. ",
  "translatedText": "جیسا کہ ہم اس عمل کو بار بار دہراتے ہیں، شکل زیادہ سے زیادہ گھنٹی کی گھنٹی کی طرح دکھائی دیتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time. ",
  "translatedText": "یا زیادہ درست کہنے کے لیے، ہر تکرار پر ہمیں ایکس محور کو دوبارہ اسکیل کرنا چاہیے تاکہ یہ یقینی بنایا جا سکے کہ معیاری انحراف ایک ہے، کیونکہ اس بار بار کنولیشن کا غالب اثر، بار بار چلنے والی اوسط عمل کی قسم، فنکشن کو فلیٹ کرنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero. ",
  "translatedText": "وقت تو حد میں یہ صرف صفر کی طرف چپٹا ہوتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true. ",
  "translatedText": "لیکن ریسکیلنگ کہنے کا ایک طریقہ ہے، ہاں ہاں ہاں، میں جانتا ہوں کہ یہ چاپلوسی ہو جاتا ہے، لیکن اس سب کی اصل شکل کیا ہے؟ مرکزی حد نظریہ کا بیان، احتمال سے بہترین حقائق میں سے ایک، یہ ہے کہ آپ بنیادی طور پر کسی بھی تقسیم کے ساتھ شروع کر سکتے تھے اور یہ اب بھی درست ہوتا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution. ",
  "translatedText": "یہ کہ جب آپ اس طرح بار بار کنولیشنز لیتے ہیں، ایک دیے گئے بے ترتیب متغیر کی بڑی اور بڑی رقوم کی نمائندگی کرتے ہیں، پھر اس رقم کو بیان کرنے والی تقسیم، جو کہ ایک عام تقسیم سے بہت مختلف نظر آنا شروع ہو سکتی ہے، وقت کے ساتھ ساتھ زیادہ سے زیادہ ہموار ہوتی جاتی ہے جب تک کہ یہ من مانی نہ ہو جائے۔عام تقسیم کے قریب۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution. ",
  "translatedText": "یہ ایسا ہی ہے جیسے کہ گھنٹی کا منحنی خطوط، بولنے کے کچھ ڈھیلے انداز میں، ہموار ممکنہ تقسیم، تمام ممکنہ افعال کی جگہ میں ایک پرکشش مقررہ نقطہ ہے، جیسا کہ ہم کنولوشن کے ذریعے بار بار ہموار کرنے کے اس عمل کو لاگو کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one? ",
  "translatedText": "قدرتی طور پر آپ حیران ہوسکتے ہیں، کیوں عام تقسیم؟ یہ فنکشن کیوں اور کوئی دوسرا نہیں؟ یہ ایک بہت اچھا جواب ہے، اور میں سمجھتا ہوں کہ جواب دکھانے کا سب سے پرلطف طریقہ آخری تصور کی روشنی میں ہے جسے ہم کنولیشنز کے لیے دکھائیں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals? ",
  "translatedText": "یاد رکھیں کہ کس طرح مجرد صورت میں، ہماری دو تصورات میں سے پہلی میں اس قسم کی ضرب جدول کی تشکیل، تمام ممکنہ نتائج کے امکانات کو ظاہر کرنا، اور اخترن کے ساتھ اضافہ کرنا شامل ہے؟ آپ نے شاید اب تک اس کا اندازہ لگا لیا ہو گا، لیکن ہمارا آخری مرحلہ اسے مسلسل کیس میں عام کرنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful. ",
  "translatedText": "اور یہ خوبصورت ہے، لیکن آپ کو تھوڑا سا محتاط رہنا ہوگا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier? ",
  "translatedText": "انہی دو فنکشنز کو کھینچتے ہوئے جو ہمارے پاس پہلے تھے، f کا x اور y کا g، اس صورت میں ممکنہ جوڑوں کے گرڈ سے کیا مشابہ ہوگا جسے ہم پہلے دیکھ رہے تھے؟ ٹھیک ہے اس معاملے میں، ہر ایک متغیر کسی بھی حقیقی نمبر کو لے سکتا ہے، لہذا ہم حقیقی اعداد کے تمام ممکنہ جوڑوں کے بارے میں سوچنا چاہتے ہیں، اور xy-plane ذہن میں آتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions. ",
  "translatedText": "جب ہم دونوں تقسیموں سے نمونہ لیتے ہیں تو ہر نقطہ ممکنہ نتیجہ سے مطابقت رکھتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent. ",
  "translatedText": "اب ان نتائج میں سے کسی ایک کا امکان، xy، یا اس نقطہ کے ارد گرد امکانی کثافت، ایک بار پھر، یہ فرض کرتے ہوئے کہ دونوں آزاد ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane. ",
  "translatedText": "تو ایک فطری کام یہ ہے کہ اس فنکشن کو گراف کرنا ہے، y کے x گنا جی، کو دو متغیر فنکشن کے طور پر، جو ایسی چیز دے گا جو xy-plane کے اوپر کی سطح کی طرح نظر آئے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph. ",
  "translatedText": "اس مثال میں دیکھیں کہ اگر ہم اسے ایک زاویے سے دیکھتے ہیں، جہاں ہم x کی قدروں کو بدلتے ہوئے دیکھتے ہیں، تو اس کی شکل ہمارے پہلے گراف کی ہوتی ہے، لیکن اگر ہم اسے کسی دوسرے زاویے سے دیکھیں، y سمت میں تبدیلی پر زور دیتے ہوئے، یہ ہمارے دوسرے گراف کی شکل اختیار کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need. ",
  "translatedText": "یہ تین جہتی گراف ہمیں درکار تمام معلومات کو انکوڈ کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome. ",
  "translatedText": "یہ ہر ممکنہ نتائج کے لیے تمام امکانی کثافت کو ظاہر کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant. ",
  "translatedText": "اور اگر آپ اپنے نقطہ نظر کو صرف ان نتائج تک محدود رکھنا چاہتے ہیں جہاں x جمع y ایک دی گئی رقم کے طور پر محدود ہے، جو ایسا لگتا ہے وہ ہمارے نقطہ نظر کو ایک ترچھے ٹکڑوں تک محدود کر رہا ہے، خاص طور پر x plus y لائن پر ایک ٹکڑا کچھ مستقل کے برابر ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at. ",
  "translatedText": "اس رکاوٹ سے مشروط نتائج کے لیے تمام ممکنہ امکانات کی کثافتیں اس گراف کے نیچے ایک سلائس کی طرح نظر آتی ہیں، اور جیسا کہ ہم اس کے ارد گرد تبدیل ہوتے ہیں کہ ہم کس مخصوص رقم کو روک رہے ہیں، یہ اس کے گرد بدل جاتا ہے کہ ہم کس مخصوص اخترن سلائس کو دیکھ رہے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface. ",
  "translatedText": "اب آپ جس چیز کی پیشین گوئی کر سکتے ہیں وہ یہ ہے کہ ان سلائسوں میں سے کسی ایک کے ساتھ تمام امکانات کی کثافتوں کو یکجا کرنے کا طریقہ، ان کو ایک ساتھ جوڑنے کا طریقہ، اس منحنی خطوط کے نیچے کے علاقے سے تعبیر کیا جا سکتا ہے، جو سطح کا ایک ٹکڑا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct. ",
  "translatedText": "اور یہ تقریباً درست ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution. ",
  "translatedText": "دو کے مربع جڑ کے عنصر کے بارے میں ایک باریک تفصیل ہے جس کے بارے میں ہمیں بات کرنے کی ضرورت ہے، لیکن ایک مستقل عنصر تک، ان ٹکڑوں کے حصے ہمیں کنولیشن کی قدریں دیتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier. ",
  "translatedText": "درحقیقت، یہ تمام سلائسیں جو ہم دیکھ رہے ہیں بالکل وہی ہیں جو پروڈکٹ گراف کی طرح ہے جسے ہم پہلے دیکھ رہے تھے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g. ",
  "translatedText": "یہاں، اس نکتے پر زور دینے کے لیے، میں دونوں تصورات کو ساتھ ساتھ کھینچتا ہوں، اور میں آہستہ آہستہ s کی قدر کو کم کرنے جا رہا ہوں، جس کا مطلب ہے کہ بائیں جانب ہم مختلف سلائسز کو دیکھ رہے ہیں، اور دائیں جانب کا مطلب ہے کہ ہم' جی کے تبدیل شدہ گراف کے گرد دوبارہ منتقل ہو رہا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice. ",
  "translatedText": "نوٹ کریں کہ کس طرح نیچے دائیں طرف گراف کی شکل، فنکشنز کے درمیان پروڈکٹ، بالکل ویسا ہی دکھائی دیتی ہے جیسے اخترن سلائس کی شکل۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense. ",
  "translatedText": "اور یہ احساس ہونا چاہئے. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing. ",
  "translatedText": "وہ ایک ہی چیز کو دیکھنے کے دو الگ الگ طریقے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum. ",
  "translatedText": "جب ہم اسے الفاظ میں ڈالتے ہیں تو یہ بہت زیادہ لگتا ہے، لیکن جو ہم دیکھ رہے ہیں وہ تمام ممکنہ پروڈکٹس ہیں فنکشنز کے آؤٹ پٹس کے درمیان ان پٹ کے جوڑے کے مطابق جو ایک دی گئی رقم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it. ",
  "translatedText": "ایک بار پھر، یہ ایک طرح کی بات ہے، لیکن مجھے لگتا ہے کہ آپ دیکھ رہے ہیں کہ میں کیا کہہ رہا ہوں، اور اب ہمارے پاس اسے دیکھنے کے دو مختلف طریقے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation. ",
  "translatedText": "اخترن سلائس ویژولائزیشن کے بارے میں اچھی بات یہ ہے کہ یہ اس بات کو زیادہ واضح کرتا ہے کہ یہ ایک ہم آہنگ آپریشن ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f. ",
  "translatedText": "یہ بہت زیادہ واضح ہے کہ f g کے ساتھ متصل وہی چیز ہے جیسا کہ g f کے ساتھ متصل ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape. ",
  "translatedText": "تکنیکی طور پر، ترچھی سلائسیں بالکل ایک جیسی نہیں ہوتیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2. ",
  "translatedText": "وہ اصل میں 2 کے مربع جڑ کے فیکٹر کے ذریعہ پھیلائے گئے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step. ",
  "translatedText": "بنیادی وجہ یہ ہے کہ اگر آپ تصور کرتے ہیں کہ ان لائنوں میں سے کسی ایک کے ساتھ کچھ چھوٹا سا قدم اٹھانا ہے جہاں x جمع y ایک مستقل کے برابر ہے، تو آپ کی x ویلیو میں تبدیلی، یہاں ڈیلٹا x، اس قدم کی لمبائی کے برابر نہیں ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2. ",
  "translatedText": "یہ مرحلہ درحقیقت 2 کے مربع جڑ کے عنصر سے لمبا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices. ",
  "translatedText": "میں آپ میں سے حساب کتاب کے شوقین افراد کے لیے اسکرین پر ایک نوٹ چھوڑوں گا جو توقف اور غور کرنا چاہتے ہیں، لیکن نتیجہ یہ ہے کہ ہمارے کنوولوشن کے نتائج تکنیکی طور پر ان ترچھے ٹکڑوں کے حصے نہیں ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2. ",
  "translatedText": "ہمیں ان علاقوں کو 2 کے مربع جڑ سے تقسیم کرنا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful. ",
  "translatedText": "ایک لمحے کے لیے ان سب سے پیچھے ہٹتے ہوئے، مجھے لگتا ہے کہ یہ بہت خوبصورت ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables? ",
  "translatedText": "ہم نے اتنے آسان سوال کے ساتھ شروع کیا، یا کم از کم ایسا بظاہر آسان سوال، آپ دو بے ترتیب متغیرات کو کیسے جوڑتے ہیں؟ اور جو ہم ختم کرتے ہیں وہ دو مختلف افعال کو یکجا کرنے کے لیے یہ بہت پیچیدہ آپریشن ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something? ",
  "translatedText": "ہمارے پاس اسے سمجھنے کے لیے کم از کم دو بہت ہی خوبصورت طریقے ہیں، لیکن پھر بھی، آپ میں سے کچھ لوگ ہاتھ اٹھا کر کہہ رہے ہوں گے، خوبصورت تصویریں سب ٹھیک اور اچھی ہیں، لیکن کیا وہ حقیقت میں آپ کو کسی چیز کا حساب لگانے میں مدد کرتی ہیں؟ مثال کے طور پر، میں نے ابھی تک دو عام طور پر تقسیم شدہ بے ترتیب متغیرات کو شامل کرنے کے بارے میں ابتدائی کوئز سوال کا جواب نہیں دیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here. ",
  "translatedText": "ٹھیک ہے، عام طریقہ جس سے آپ اس قسم کے سوال تک پہنچیں گے، اگر یہ ہوم ورک یا اس طرح کی کسی چیز پر ظاہر ہوتا ہے، تو یہ ہے کہ آپ ایک عام تقسیم کے فارمولے کو کنوولوشن کی تعریف میں پلگ ان کریں گے، جو کہ ہم ہیں' یہاں بیان کر رہا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat. ",
  "translatedText": "اور اس صورت میں، تصورات واقعی صرف یہ واضح کرنے کے لیے ہوں گے کہ اظہار کیا کہہ رہا ہے، لیکن وہ پچھلی سیٹ پر بیٹھتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself. ",
  "translatedText": "اس معاملے میں، انٹیگرل ممنوعہ طور پر مشکل نہیں ہے، تجزیاتی طریقے موجود ہیں، لیکن اس مثال کے لیے، میں آپ کو ایک اور مزے کا طریقہ دکھانا چاہتا ہوں جہاں تصورات، خاص طور پر ترچھی سلائسیں، بہت زیادہ سامنے اور مرکزی کردار ادا کریں گی۔خود ثبوت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself. ",
  "translatedText": "مجھے لگتا ہے کہ آپ میں سے بہت سے لوگ حقیقت میں ایک لمحہ نکال کر یہ اندازہ لگا سکتے ہیں کہ یہ آپ کے لیے کیسا نظر آئے گا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of. ",
  "translatedText": "اس بارے میں سوچیں کہ یہ 3D گراف دو عام تقسیم کے معاملے میں کیسا نظر آئے گا، اور اس میں کون سی خصوصیات ہیں جن سے آپ فائدہ اٹھا سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation. ",
  "translatedText": "اور یہ یقینی طور پر سب سے آسان ہے اگر آپ کسی ایسے معاملے سے شروع کریں جہاں دونوں تقسیموں میں ایک ہی معیاری انحراف ہو۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video. ",
  "translatedText": "جب بھی آپ تفصیلات چاہتے ہیں، اور یہ دیکھنے کے لیے کہ جواب مرکزی حد کے نظریے میں کیسے فٹ بیٹھتا ہے، اگلی ویڈیو میں میرے ساتھ شامل ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]