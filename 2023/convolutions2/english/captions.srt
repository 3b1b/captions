1
00:00:00,000 --> 00:00:01,620
Let's kick things off with a quiz.

2
00:00:02,360 --> 00:00:06,212
Suppose I take a normal distribution with this familiar bell curve shape, 

3
00:00:06,212 --> 00:00:09,700
and I have a random variable x that's drawn from that distribution.

4
00:00:10,520 --> 00:00:14,540
So what you're looking at right now are repeated samples of that random variable.

5
00:00:14,960 --> 00:00:18,451
And as a quick reminder, the way that you interpret this curve, 

6
00:00:18,451 --> 00:00:22,816
what the function actually means, is that if you want the probability that your 

7
00:00:22,816 --> 00:00:27,235
sample falls within a given range of values, say the probability that it ends up 

8
00:00:27,235 --> 00:00:31,654
between negative one and two, well that would equal the area under this curve in 

9
00:00:31,654 --> 00:00:32,800
that range of values.

10
00:00:32,840 --> 00:00:34,700
That's what the curve actually means.

11
00:00:35,260 --> 00:00:39,096
I'll also pull up a second random variable, also following a normal distribution, 

12
00:00:39,096 --> 00:00:42,980
but maybe this time a little more spread out, a slightly bigger standard deviation.

13
00:00:43,280 --> 00:00:44,440
And here's the quiz for you.

14
00:00:44,600 --> 00:00:47,426
If you repeatedly sample both of these variables, 

15
00:00:47,426 --> 00:00:50,253
and at each iteration you add up the two results, 

16
00:00:50,253 --> 00:00:53,420
well then that sum behaves like its own random variable.

17
00:00:53,960 --> 00:00:58,880
And the question is what distribution describes that sum that you're looking at?

18
00:00:59,380 --> 00:01:02,875
You think about it for a little moment, maybe you have a guess, maybe you think, 

19
00:01:02,875 --> 00:01:06,500
I don't know, it's another normal distribution, or something with a different shape.

20
00:01:07,200 --> 00:01:09,120
Needless to say, guessing is not enough.

21
00:01:09,560 --> 00:01:14,260
The real quiz is to be able to explain why you get the answer that you do.

22
00:01:14,800 --> 00:01:19,074
In this case, if you have that deep to your bones visceral level of understanding 

23
00:01:19,074 --> 00:01:23,089
for why the answer is what it is, you'll be a long way towards understanding 

24
00:01:23,089 --> 00:01:27,260
why normal distributions serve the special function that they do in probability.

25
00:01:27,860 --> 00:01:31,293
Zooming out though, this is actually meant to be a much more general 

26
00:01:31,293 --> 00:01:34,130
lesson about how you add two different random variables, 

27
00:01:34,130 --> 00:01:38,360
regardless of their distribution, not necessarily just the normally distributed ones.

28
00:01:39,100 --> 00:01:41,850
This amounts to a special operation that you apply 

29
00:01:41,850 --> 00:01:44,440
to the distributions underlying those variables.

30
00:01:44,660 --> 00:01:47,864
The operation has a special name, it's called a convolution, 

31
00:01:47,864 --> 00:01:51,805
and the primary thing you and I will do today is motivate and build up two 

32
00:01:51,805 --> 00:01:56,166
distinct ways to visualize what a convolution looks like for continuous functions, 

33
00:01:56,166 --> 00:02:00,054
and then to talk about how these two different visualizations can each be 

34
00:02:00,054 --> 00:02:04,100
helpful in different ways, with a special focus on the central limit theorem.

35
00:02:04,880 --> 00:02:08,043
After we do the general lesson, I want to return to the 

36
00:02:08,043 --> 00:02:11,660
opening quiz and offer an unusually satisfying way to answer it.

37
00:02:11,660 --> 00:02:15,447
As a quick side note, regular viewers among you might know there's already a 

38
00:02:15,447 --> 00:02:19,580
video about convolutions on this channel, but that one had a pretty different focus.

39
00:02:19,760 --> 00:02:23,402
We were only doing the discrete case, and I wanted to show not just probability, 

40
00:02:23,402 --> 00:02:26,100
but the ways that it comes up in a wide variety of contexts.

41
00:02:26,780 --> 00:02:31,009
I'm in a slightly awkward spot because it doesn't really make sense for that to be 

42
00:02:31,009 --> 00:02:35,289
a prerequisite to this video, but I think the best way to warm up today is to cover 

43
00:02:35,289 --> 00:02:38,193
essentially one of the same examples used in that video, 

44
00:02:38,193 --> 00:02:42,320
so if you are coming straight from that one, you can probably skip safely ahead, 

45
00:02:42,320 --> 00:02:43,900
otherwise, let's dive right in.

46
00:02:46,860 --> 00:02:50,740
For this opening quiz question, each of the random variables can take on 

47
00:02:50,740 --> 00:02:54,780
a value in a continuous infinite range of values, all possible real numbers.

48
00:02:55,300 --> 00:02:59,550
It'll be a lot easier if we warm up in a setting that's more discrete and finite, 

49
00:02:59,550 --> 00:03:01,780
like maybe rolling a pair of weighted dice.

50
00:03:02,560 --> 00:03:06,415
Here, the animation you're looking at is simulating two weighted dice, 

51
00:03:06,415 --> 00:03:10,759
and you can probably tell what's going on, but just to spell it out explicitly, 

52
00:03:10,759 --> 00:03:15,483
the blue die is following a distribution that seems to be biased towards lower values, 

53
00:03:15,483 --> 00:03:19,501
the red die has a distinct distribution, and I'm repeatedly sampling from 

54
00:03:19,501 --> 00:03:23,140
each one and recording the sum of the two values at each iteration.

55
00:03:23,740 --> 00:03:28,120
Repeating samples like this many many different times can give you a heuristic sense of 

56
00:03:28,120 --> 00:03:32,600
the final distribution, but our real task today is to compute that distribution precisely.

57
00:03:32,600 --> 00:03:35,720
What is the precise probability of rolling a 2, 

58
00:03:35,720 --> 00:03:39,360
or a 3, or a 4, or a 5, on and on for all possibilities?

59
00:03:39,840 --> 00:03:42,074
It's not too hard a question, I'd actually encourage 

60
00:03:42,074 --> 00:03:44,140
you to pause and try working it out for yourself.

61
00:03:44,980 --> 00:03:48,310
The main goal in this warm-up section will be to walk through two 

62
00:03:48,310 --> 00:03:51,640
distinct ways that you could visualize the underlying computation.

63
00:03:52,920 --> 00:03:57,873
For example, one way you could start to think about it is that there are 36 distinct 

64
00:03:57,873 --> 00:04:02,360
possible outcomes, and we could organize those outcomes in a little 6x6 grid.

65
00:04:03,040 --> 00:04:07,883
Now if I was to ask you, what is the probability of seeing any one of these specific 

66
00:04:07,883 --> 00:04:12,500
outcomes, say the probability of seeing a blue 4 and a red 2, what would you say?

67
00:04:13,040 --> 00:04:16,100
We might say it should be the probability of that blue 4 

68
00:04:16,100 --> 00:04:19,429
multiplied by the probability of the red 2, and that would be 

69
00:04:19,429 --> 00:04:23,080
correct assuming that the die rolls are independent from each other.

70
00:04:23,540 --> 00:04:27,342
You might say that's kind of pedantic, of course the die rolls should be independent 

71
00:04:27,342 --> 00:04:31,011
from each other, but it's a point worth emphasizing because everything that we're 

72
00:04:31,011 --> 00:04:34,635
going to do from here moving forward, from this simple example all the way up to 

73
00:04:34,635 --> 00:04:38,080
the central limit theorem, assumes that the random variables are independent.

74
00:04:38,660 --> 00:04:42,720
In the real world, you want to keep a sharp eye out for if this assumption actually holds.

75
00:04:43,640 --> 00:04:46,860
Now what I'm going to do is take this grid of all possible outcomes, 

76
00:04:46,860 --> 00:04:48,820
but start filling it in with some numbers.

77
00:04:49,180 --> 00:04:53,526
Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, 

78
00:04:53,526 --> 00:04:56,472
all the probabilities for the red die over here on the left, 

79
00:04:56,472 --> 00:05:00,819
and then we will fill in the grid where the probability for every outcome inside the grid 

80
00:05:00,819 --> 00:05:05,165
looks like some product between one number from the blue distribution and one number from 

81
00:05:05,165 --> 00:05:06,180
the red distribution.

82
00:05:06,680 --> 00:05:10,340
Another way to think about it is we're basically constructing a multiplication table.

83
00:05:10,700 --> 00:05:14,796
To be a little more visual about all of this, we could plot each one of these 

84
00:05:14,796 --> 00:05:19,417
probabilities as the height of a bar above the square in this sort of three-dimensional 

85
00:05:19,417 --> 00:05:19,680
plot.

86
00:05:20,120 --> 00:05:22,814
In some sense, this three-dimensional plot carries all the 

87
00:05:22,814 --> 00:05:25,600
data that we would need to know about rolling a pair of dice.

88
00:05:25,740 --> 00:05:29,711
And so the question is how do we extract the thing that we want to know, 

89
00:05:29,711 --> 00:05:32,160
the probabilities for various different sums?

90
00:05:33,660 --> 00:05:37,233
Well, if you highlight all of the outcomes with a certain sum, 

91
00:05:37,233 --> 00:05:41,260
say a sum of six, notice how all of those end up on a certain diagonal.

92
00:05:41,740 --> 00:05:44,934
Same deal if I highlight all the pairs where the sum is seven, 

93
00:05:44,934 --> 00:05:46,760
they sit along a different diagonal.

94
00:05:47,240 --> 00:05:50,088
So to compute the probability of each possible sum, 

95
00:05:50,088 --> 00:05:54,800
what you do is you add together all of the entries that sit on one of these diagonals.

96
00:05:58,280 --> 00:06:02,413
Pulling up the 3D plot, we can better foreshadow where we'll go with this 

97
00:06:02,413 --> 00:06:06,657
later by saying that the distribution of possible sums looks like combining 

98
00:06:06,657 --> 00:06:10,400
all of the heights of this plot along one of these diagonal slices.

99
00:06:12,080 --> 00:06:15,398
It's as if we've taken this full distribution for all possible 

100
00:06:15,398 --> 00:06:18,980
outcomes and we've kind of collapsed it along one of the directions.

101
00:06:20,960 --> 00:06:24,140
And admittedly, I'm just having a bit of fun with the animations at this point.

102
00:06:24,140 --> 00:06:26,436
It's not like if you were working this out with pencil 

103
00:06:26,436 --> 00:06:28,900
and paper you would be drawing some three-dimensional plot.

104
00:06:29,320 --> 00:06:31,865
But it's fun when you collapse it on this direction, 

105
00:06:31,865 --> 00:06:35,131
you actually do get the same distribution, which I knew you should, 

106
00:06:35,131 --> 00:06:36,380
but it's still fun to see.

107
00:06:36,960 --> 00:06:40,695
Also, even though all of this might just seem a little bit playful or 

108
00:06:40,695 --> 00:06:44,484
even unnecessarily complicated, I can promise you this intuition about 

109
00:06:44,484 --> 00:06:48,540
diagonal slices will come back to us later for a genuinely satisfying proof.

110
00:06:48,860 --> 00:06:51,897
But staying focused on the simple dice case a little bit longer, 

111
00:06:51,897 --> 00:06:54,280
here's the second way that we could think about it.

112
00:06:54,780 --> 00:06:58,086
Take that bottom distribution and flip it around horizontally 

113
00:06:58,086 --> 00:07:01,340
so that the die values increase as you go from right to left.

114
00:07:02,480 --> 00:07:04,040
Why do this, you might ask?

115
00:07:04,600 --> 00:07:08,480
Well, notice now which of the pairs of dice values line up with each other.

116
00:07:08,860 --> 00:07:14,720
As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on.

117
00:07:14,900 --> 00:07:18,100
It is all of the pairs of values that add up to 7.

118
00:07:18,100 --> 00:07:21,639
So if you want to think about the probability of rolling a 7, 

119
00:07:21,639 --> 00:07:25,920
a way to hold that computation in your mind is to take all of the pairs of 

120
00:07:25,920 --> 00:07:30,202
probabilities that line up with each other, multiply together those pairs, 

121
00:07:30,202 --> 00:07:32,200
and then add up all of the results.

122
00:07:32,940 --> 00:07:35,640
Some of you might like to think of this as a kind of dot product.

123
00:07:36,180 --> 00:07:39,920
But the operation as a whole is not just one dot product, but many.

124
00:07:40,360 --> 00:07:44,475
If we were to slide that bottom distribution a little more to the left, 

125
00:07:44,475 --> 00:07:49,106
so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 

126
00:07:49,106 --> 00:07:53,222
3 and 2, 4 and 1, in other words all the ones that add up to a 5, well, 

127
00:07:53,222 --> 00:07:57,566
now if we take the dot product, we multiply the pairs of probabilities that 

128
00:07:57,566 --> 00:08:02,540
line up and add them together, that would give us the total probability of rolling a 5.

129
00:08:03,200 --> 00:08:06,626
In general, from this point of view, computing the full distribution 

130
00:08:06,626 --> 00:08:10,052
for the sum looks like sliding that bottom distribution into various 

131
00:08:10,052 --> 00:08:13,280
different positions and computing this dot product along the way.

132
00:08:14,600 --> 00:08:19,820
It is precisely the same operation as the diagonal slices we were looking at earlier.

133
00:08:20,380 --> 00:08:23,800
They're just two different ways to visualize the same underlying operation.

134
00:08:27,240 --> 00:08:31,957
And however you choose to visualize it, this operation that takes in two different 

135
00:08:31,957 --> 00:08:36,503
distributions and spits out a new one describing the sum of the relevant random 

136
00:08:36,503 --> 00:08:40,880
variables is called a convolution, and we often denote it with this asterisk.

137
00:08:40,880 --> 00:08:44,896
Really the way you want to think about it, especially as we set up for the continuous 

138
00:08:44,896 --> 00:08:48,819
case, is to think of it as combining two different functions and spitting out a new 

139
00:08:48,819 --> 00:08:49,240
function.

140
00:08:50,320 --> 00:08:53,139
For example, in this case, maybe I give the function 

141
00:08:53,139 --> 00:08:55,480
for the first distribution the name p sub x.

142
00:08:55,820 --> 00:08:59,740
This would be a function that takes in a possible value for the die, 

143
00:08:59,740 --> 00:09:02,980
like a 3, and it spits out the corresponding probability.

144
00:09:04,440 --> 00:09:08,721
Similarly, let's let p sub y be the function for our second distribution, 

145
00:09:08,721 --> 00:09:13,060
and p sub x plus y be the function describing the distribution for the sum.

146
00:09:13,960 --> 00:09:17,455
In the lingo, what you would say is that p sub x plus 

147
00:09:17,455 --> 00:09:21,080
y is equal to a convolution between p sub x and p sub y.

148
00:09:21,680 --> 00:09:23,886
And what I want you to think about now is what 

149
00:09:23,886 --> 00:09:26,140
the formula for this operation should look like.

150
00:09:26,440 --> 00:09:28,450
You've seen two different ways to visualize it, 

151
00:09:28,450 --> 00:09:30,460
but how do we actually write it down in symbols?

152
00:09:30,960 --> 00:09:34,624
To get your bearings, maybe it's helpful to write down a specific example, 

153
00:09:34,624 --> 00:09:38,239
like the case of plugging in a 4, where you add up over all the different 

154
00:09:38,239 --> 00:09:41,660
pairwise products corresponding to pairs of inputs that add up to a 4.

155
00:09:42,460 --> 00:09:44,540
And more generally, here's how it might look.

156
00:09:44,980 --> 00:09:49,730
This new function takes as an input a possible sum for your random variables, 

157
00:09:49,730 --> 00:09:55,089
which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values 

158
00:09:55,089 --> 00:09:55,820
for x and y.

159
00:09:55,820 --> 00:09:59,192
Except the usual way it's written is not to write with x and y, 

160
00:09:59,192 --> 00:10:02,827
but instead we just focus on one of those variables, in this case x, 

161
00:10:02,827 --> 00:10:05,462
letting it range over all of its possible values, 

162
00:10:05,462 --> 00:10:08,360
which here just means going from 1 all the way up to 6.

163
00:10:08,840 --> 00:10:11,651
And instead of writing y, you write s minus x, 

164
00:10:11,651 --> 00:10:15,720
essentially whatever the number has to be to make sure the sum is s.

165
00:10:17,300 --> 00:10:19,583
Now the astute among you might notice a slightly 

166
00:10:19,583 --> 00:10:21,680
weird quirk with the formula as it's written.

167
00:10:22,220 --> 00:10:27,192
For example, if you plug in a given value like s equals 4, and you unpack this sum, 

168
00:10:27,192 --> 00:10:31,158
letting x range over all the possible values going from 1 up to 6, 

169
00:10:31,158 --> 00:10:35,835
then sometimes that corresponding y value drops below the domain of what we've 

170
00:10:35,835 --> 00:10:36,960
explicitly defined.

171
00:10:37,400 --> 00:10:40,540
For example, you plug in 0 and negative 1 and negative 2.

172
00:10:41,200 --> 00:10:42,880
It's not actually that big a deal.

173
00:10:43,000 --> 00:10:45,984
Essentially, you would just say all of these values are 0, 

174
00:10:45,984 --> 00:10:48,160
so all these later terms don't get counted.

175
00:10:48,640 --> 00:10:49,740
And that should kind of make sense.

176
00:10:49,900 --> 00:10:53,280
What is the probability that the red die rolls to become a negative 1?

177
00:10:53,820 --> 00:10:54,820
Well, it's 0.

178
00:10:54,860 --> 00:10:56,400
That is an impossible outcome.

179
00:11:01,040 --> 00:11:05,050
As a next step, let's turn our attention towards continuous distributions, 

180
00:11:05,050 --> 00:11:09,382
where your random variable can take on values anywhere in an infinite continuum, 

181
00:11:09,382 --> 00:11:11,040
like all possible real numbers.

182
00:11:11,520 --> 00:11:14,272
Maybe you're doing weather modeling and trying to predict the 

183
00:11:14,272 --> 00:11:17,557
temperature tomorrow at noon, or you're doing some financial projections, 

184
00:11:17,557 --> 00:11:20,620
or maybe you're modeling the typical wait times before a bus arrives.

185
00:11:20,840 --> 00:11:23,360
There are all sorts of things where you need to handle continuity.

186
00:11:23,900 --> 00:11:27,935
In all the graphs that we draw, the x value still represents a possible number 

187
00:11:27,935 --> 00:11:31,919
that the random variable can take on, but the interpretation of the y-axis is 

188
00:11:31,919 --> 00:11:35,700
a little bit different, because no longer does this represent probability.

189
00:11:36,280 --> 00:11:39,840
Instead, the thing that we're graphing is what's called probability density.

190
00:11:40,320 --> 00:11:43,020
This is something we've talked about before, so you know the deal.

191
00:11:43,440 --> 00:11:47,159
Essentially, the probability that a sample of your variable falls 

192
00:11:47,159 --> 00:11:51,160
within a given range looks like the area under the curve in that range.

193
00:11:51,620 --> 00:11:56,273
The function describing this curve is commonly called a probability density function, 

194
00:11:56,273 --> 00:12:00,440
a common enough phrase that it's frequently just given the abbreviation PDF, 

195
00:12:00,440 --> 00:12:04,390
and so the proper way to write all of this down would be to say that the 

196
00:12:04,390 --> 00:12:08,232
probability that your sample falls within a given range looks like the 

197
00:12:08,232 --> 00:12:12,020
integral of your PDF, the probability density function, in that range.

198
00:12:12,880 --> 00:12:16,986
As a general rule of thumb, anytime that you see a sum in the discrete case, 

199
00:12:16,986 --> 00:12:19,600
you would use an integral in the continuous case.

200
00:12:20,420 --> 00:12:23,300
So let's think about what that means for our main example.

201
00:12:23,860 --> 00:12:26,458
Let's say we have two different random variables, 

202
00:12:26,458 --> 00:12:29,681
but this time each one will follow a continuous distribution, 

203
00:12:29,681 --> 00:12:34,100
and we want to understand their sum and the new distribution that describes that sum.

204
00:12:35,420 --> 00:12:38,920
You can probably already guess what the formula will be just by analogy.

205
00:12:39,400 --> 00:12:42,103
Remember, in the formula that we just wrote down, 

206
00:12:42,103 --> 00:12:45,024
where p sub x is the function for the first variable, 

207
00:12:45,024 --> 00:12:49,512
and p sub y is the function for the second variable, the convolution between them, 

208
00:12:49,512 --> 00:12:52,054
the thing describing a sum of those variables, 

209
00:12:52,054 --> 00:12:55,840
itself looks like a sum where we combine a bunch of pairwise products.

210
00:12:56,480 --> 00:13:00,160
The expression in the continuous case really does look 100% analogous.

211
00:13:00,600 --> 00:13:02,980
It's just that we swap out that sum for an integral.

212
00:13:03,760 --> 00:13:07,131
Sometimes when students see this definition of a convolution out of context, 

213
00:13:07,131 --> 00:13:08,620
it can seem a little intimidating.

214
00:13:09,100 --> 00:13:11,375
Hopefully the analogy is enough to make it clear, 

215
00:13:11,375 --> 00:13:14,380
but the continuous nature really does give it a different flavor, 

216
00:13:14,380 --> 00:13:18,340
and it's worth taking a couple minutes to think through what it means on its own terms.

217
00:13:18,340 --> 00:13:21,657
And so I put together a little interactive demo that helps 

218
00:13:21,657 --> 00:13:25,200
unpack each part of the expression and what it's really saying.

219
00:13:25,800 --> 00:13:28,995
For example, the first term in this integral is f of x, 

220
00:13:28,995 --> 00:13:33,560
which represents the density function for the first of the two random variables.

221
00:13:33,940 --> 00:13:37,749
And in this case, I'm choosing this sort of wedge-shaped function for that distribution, 

222
00:13:37,749 --> 00:13:38,820
but it could be anything.

223
00:13:39,660 --> 00:13:43,462
Similarly, g represents the density function for the second random variable, 

224
00:13:43,462 --> 00:13:46,820
for which I'm choosing this sort of double lump-shaped distribution.

225
00:13:46,820 --> 00:13:52,086
And in the same way that earlier we went over all possible pairs of dice values with a 

226
00:13:52,086 --> 00:13:57,412
given sum, the way you want to think about this integral is that what it wants to do is 

227
00:13:57,412 --> 00:14:02,800
iterate over all possible pairs of values x and y that are constrained to a given sum, s.

228
00:14:03,340 --> 00:14:07,183
We don't really have great notation for doing that symmetrically, 

229
00:14:07,183 --> 00:14:12,018
so instead the way we commonly write it down gives this artificial emphasis to one 

230
00:14:12,018 --> 00:14:16,910
of the variables, in this case x, where we let that value x range over all possible 

231
00:14:16,910 --> 00:14:19,706
real numbers, negative infinity up to infinity, 

232
00:14:19,706 --> 00:14:22,967
and the thing we plug into the function g is s minus x, 

233
00:14:22,967 --> 00:14:27,860
essentially whatever it has to be to make sure that this sum is constrained to be s.

234
00:14:29,380 --> 00:14:34,600
So for the demo, instead of graphing g directly, I want to graph g of s minus x.

235
00:14:35,100 --> 00:14:37,140
You might ask yourself, what does that look like?

236
00:14:37,680 --> 00:14:40,847
Well, if you plug in negative x as the input, that has 

237
00:14:40,847 --> 00:14:43,900
the effect of flipping around the graph horizontally.

238
00:14:44,760 --> 00:14:48,689
And then if we throw in this parameter s, treat it as some kind of constant, 

239
00:14:48,689 --> 00:14:51,956
that has the effect of shifting the graph either left or right, 

240
00:14:51,956 --> 00:14:54,100
depending on if s is positive or negative.

241
00:14:54,640 --> 00:14:58,320
In the demo, s is a parameter that I'll just grab and shift around a little bit.

242
00:14:58,700 --> 00:15:02,324
The real fun comes from graphing the entire contents of the integral, 

243
00:15:02,324 --> 00:15:04,240
the product between these two graphs.

244
00:15:04,780 --> 00:15:08,497
This is analogous to the list of pairwise products that we saw earlier, 

245
00:15:08,497 --> 00:15:12,110
but in this case instead of adding up all of those pairwise products, 

246
00:15:12,110 --> 00:15:16,499
we want to integrate them together, which you would interpret as the area underneath 

247
00:15:16,499 --> 00:15:17,480
this product graph.

248
00:15:18,200 --> 00:15:21,119
As I shift around this value of s, the shape of that 

249
00:15:21,119 --> 00:15:24,260
product graph changes and so does the corresponding area.

250
00:15:26,920 --> 00:15:29,948
Keep in mind for all three graphs on the left, 

251
00:15:29,948 --> 00:15:33,300
the input is x and the number s is just a parameter.

252
00:15:33,300 --> 00:15:37,898
But for the final graph on the right, for the resulting convolution itself, 

253
00:15:37,898 --> 00:15:41,953
this number s is the input to that function, and the corresponding 

254
00:15:41,953 --> 00:15:45,342
output is whatever the area of the lower left graph is, 

255
00:15:45,342 --> 00:15:49,820
whatever the integral between this combination of f and g turns out to be.

256
00:15:53,280 --> 00:15:56,266
Here, it might be helpful if we do a simple example, 

257
00:15:56,266 --> 00:15:59,703
say where each of our two random variables follows a uniform 

258
00:15:59,703 --> 00:16:03,760
distribution between the values negative one half and positive one half.

259
00:16:04,460 --> 00:16:08,533
So what that looks like is that our density functions each have this kind 

260
00:16:08,533 --> 00:16:12,276
of top hat shape, where the graph equals one for all inputs between 

261
00:16:12,276 --> 00:16:16,460
negative one half and positive one half, and it equals zero everywhere else.

262
00:16:17,040 --> 00:16:21,440
The question, as always, is what should the distribution for the sum look like?

263
00:16:21,960 --> 00:16:24,400
Well, let me show you how it looks inside our demo.

264
00:16:25,220 --> 00:16:29,180
In this case, the product between the two graphs has a really easy interpretation.

265
00:16:29,180 --> 00:16:34,060
It is one wherever the graphs overlap with each other, but zero everywhere else.

266
00:16:34,560 --> 00:16:38,513
So if I slide this parameter s far enough to the left that our top 

267
00:16:38,513 --> 00:16:42,763
graphs don't overlap at all, then the product graph is zero everywhere, 

268
00:16:42,763 --> 00:16:46,540
and that's a way of saying this is an impossible sum to achieve.

269
00:16:47,220 --> 00:16:48,060
That should make sense.

270
00:16:48,200 --> 00:16:51,862
Each of the two variables can only get as low as negative one half, 

271
00:16:51,862 --> 00:16:54,340
so the sum could never get below negative one.

272
00:16:54,340 --> 00:16:59,414
As I start to slide s to the right and the graphs overlap with each other, 

273
00:16:59,414 --> 00:17:05,300
the area increases linearly until the graphs overlap entirely and it reaches a maximum.

274
00:17:06,200 --> 00:17:09,613
And then after that point it starts to decrease linearly again, 

275
00:17:09,613 --> 00:17:13,880
which means that the distribution for the sum takes on this kind of wedge shape.

276
00:17:15,339 --> 00:17:18,392
And I imagine this actually feels somewhat familiar for anyone 

277
00:17:18,392 --> 00:17:21,300
who's thought about a pair of dice, that is unweighted dice.

278
00:17:21,859 --> 00:17:26,035
There, if you add up two different uniformly distributed variables, 

279
00:17:26,035 --> 00:17:29,720
then the distribution for the sum has a certain wedge shape.

280
00:17:30,040 --> 00:17:32,338
Probabilities increase until they max out at a 

281
00:17:32,338 --> 00:17:34,540
seven and then they decrease back down again.

282
00:17:36,260 --> 00:17:39,773
Where this gets a lot more fun is if instead of asking for a sum 

283
00:17:39,773 --> 00:17:43,232
of two uniformly distributed variables, I ask you what it looks 

284
00:17:43,232 --> 00:17:46,800
like if we add up three different uniformly distributed variables.

285
00:17:46,800 --> 00:17:49,690
At first you might say, I don't know, we need some new 

286
00:17:49,690 --> 00:17:52,580
way to visualize combining three things instead of two.

287
00:17:53,420 --> 00:17:57,130
But really what you can do here is think about the sum of the first two as 

288
00:17:57,130 --> 00:18:01,335
their own variable, which we just figured out follows this wedge shape distribution, 

289
00:18:01,335 --> 00:18:04,600
and then take a convolution between that and the top hat function.

290
00:18:05,100 --> 00:18:07,360
Pulling up the demo, here's what that would look like.

291
00:18:07,840 --> 00:18:12,112
Once again, what makes the top hat function really nice is that multiplying 

292
00:18:12,112 --> 00:18:16,160
by it sort of has the effect of filtering out values from the top graph.

293
00:18:16,160 --> 00:18:19,949
The product on the bottom looks just like a copy of the top graph, 

294
00:18:19,949 --> 00:18:21,760
but limited to a certain window.

295
00:18:22,620 --> 00:18:26,683
Again, as I slide this around left and right and the area gets bigger and smaller, 

296
00:18:26,683 --> 00:18:29,963
the result maxes out in the middle, but tapers out to either side, 

297
00:18:29,963 --> 00:18:32,020
except this time it does so more smoothly.

298
00:18:32,600 --> 00:18:36,120
It's kind of like we're taking a moving average of that top left graph.

299
00:18:36,940 --> 00:18:39,696
Actually, it's more than just kind of, this literally 

300
00:18:39,696 --> 00:18:41,840
is a moving average of the top left graph.

301
00:18:42,400 --> 00:18:45,000
One thing you might think to do is take this even further.

302
00:18:45,500 --> 00:18:48,960
The way we started was combining two top hat functions and we got this wedge.

303
00:18:49,460 --> 00:18:52,301
Then we replaced the first function with that wedge, 

304
00:18:52,301 --> 00:18:56,911
and then when we took the convolution, we got this smoother shape describing a sum of 

305
00:18:56,911 --> 00:18:58,680
three distinct uniform variables.

306
00:18:59,380 --> 00:19:00,500
But we could just repeat.

307
00:19:01,220 --> 00:19:04,194
Swap that out for the top function and then convolve 

308
00:19:04,194 --> 00:19:06,440
that with the flat rectangular function.

309
00:19:06,440 --> 00:19:09,471
And whatever result we see should describe a sum 

310
00:19:09,471 --> 00:19:12,380
of four uniformly distributed random variables.

311
00:19:13,660 --> 00:19:15,688
Any of you who watched the video about the central 

312
00:19:15,688 --> 00:19:17,320
limit theorem should know what to expect.

313
00:19:17,820 --> 00:19:22,400
As we repeat this process over and over, the shape looks more and more like a bell curve.

314
00:19:22,860 --> 00:19:27,678
Or to be more precise, at each iteration we should rescale the x-axis to make sure that 

315
00:19:27,678 --> 00:19:32,551
the standard deviation is one, because the dominant effect of this repeated convolution, 

316
00:19:32,551 --> 00:19:37,260
the kind of repeated moving average process, is to flatten out the function over time.

317
00:19:37,620 --> 00:19:39,840
So in the limit it just flattens out towards zero.

318
00:19:40,240 --> 00:19:42,587
But rescaling is a way of saying yeah, yeah, yeah, 

319
00:19:42,587 --> 00:19:46,040
I know that it gets flatter, but what's the actual shape underlying it all?

320
00:19:48,060 --> 00:19:52,632
The statement of the central limit theorem, one of the coolest facts from probability, 

321
00:19:52,632 --> 00:19:56,048
is that you could have started with essentially any distribution 

322
00:19:56,048 --> 00:19:57,940
and this still would have been true.

323
00:19:58,540 --> 00:20:01,462
That as you take repeated convolutions like this, 

324
00:20:01,462 --> 00:20:05,203
representing bigger and bigger sums of a given random variable, 

325
00:20:05,203 --> 00:20:09,762
then the distribution describing that sum, which might start off looking very 

326
00:20:09,762 --> 00:20:14,438
different from a normal distribution, over time smooths out more and more until 

327
00:20:14,438 --> 00:20:17,420
it gets arbitrarily close to a normal distribution.

328
00:20:18,080 --> 00:20:21,442
It's as if a bell curve is, in some loose manner of speaking, 

329
00:20:21,442 --> 00:20:25,727
the smoothest possible distribution, an attractive fixed point in the space of 

330
00:20:25,727 --> 00:20:30,012
all possible functions, as we apply this process of repeated smoothing through 

331
00:20:30,012 --> 00:20:30,880
the convolution.

332
00:20:35,400 --> 00:20:38,520
Naturally you might wonder why normal distributions?

333
00:20:38,980 --> 00:20:40,920
Why this function and not some other one?

334
00:20:41,680 --> 00:20:45,420
That's a very good answer, and I think the most fun way to show the answer 

335
00:20:45,420 --> 00:20:49,160
is in the light of the last visualization that we'll show for convolutions.

336
00:20:50,280 --> 00:20:54,029
Remember how in the discrete case the first of our two visualizations 

337
00:20:54,029 --> 00:20:56,814
involved forming this kind of multiplication table, 

338
00:20:56,814 --> 00:21:01,420
showing the probabilities for all possible outcomes and adding up along the diagonals?

339
00:21:02,960 --> 00:21:05,242
You've probably guessed it by now, but our last 

340
00:21:05,242 --> 00:21:07,620
step is to generalize this to the continuous case.

341
00:21:08,560 --> 00:21:10,860
And it is beautiful, but you have to be a little bit careful.

342
00:21:11,980 --> 00:21:15,840
Pulling up the same two functions we had before, f of x and g of y, 

343
00:21:15,840 --> 00:21:20,381
what in this case would be analogous to the grid of possible pairs that we were 

344
00:21:20,381 --> 00:21:21,460
looking at earlier?

345
00:21:22,480 --> 00:21:26,345
Well in this case each of the variables can take on any real number, 

346
00:21:26,345 --> 00:21:30,715
so we want to think about all possible pairs of real numbers and the xy plane 

347
00:21:30,715 --> 00:21:31,500
comes to mind.

348
00:21:32,640 --> 00:21:37,040
Every point corresponds to a possible outcome when we sample from both distributions.

349
00:21:38,140 --> 00:21:41,399
Now the probability of any one of these outcomes xy, 

350
00:21:41,399 --> 00:21:44,659
or rather the probability density around that point, 

351
00:21:44,659 --> 00:21:49,580
will look like f of x times g of y, again assuming that the two are independent.

352
00:21:49,580 --> 00:21:54,961
So a natural thing to do is to graph this function f of x times g of y as a two variable 

353
00:21:54,961 --> 00:21:59,920
function, which would give something that looks like a surface above the xy plane.

354
00:22:00,560 --> 00:22:04,952
Notice in this example how if we look at it from one angle where we see the x values 

355
00:22:04,952 --> 00:22:07,380
changing, it has the shape of our first graph, 

356
00:22:07,380 --> 00:22:11,669
but if we look at it from another angle emphasizing the change in the y direction, 

357
00:22:11,669 --> 00:22:13,840
it takes on the shape of our second graph.

358
00:22:14,220 --> 00:22:17,800
This three-dimensional graph encodes all of the information we need.

359
00:22:17,800 --> 00:22:21,120
It shows all the probability densities for every possible outcome.

360
00:22:21,900 --> 00:22:26,265
And if you want to limit your view just to those outcomes where x plus y is 

361
00:22:26,265 --> 00:22:30,746
constrained to be a given sum, what that looks like is limiting our view to a 

362
00:22:30,746 --> 00:22:35,400
diagonal slice, specifically a slice over the line x plus y equals some constant.

363
00:22:35,980 --> 00:22:40,757
All of the possible probability densities for the outcome subject to this constraint 

364
00:22:40,757 --> 00:22:45,590
look sort of like a slice under this graph, and as we change around what specific sum 

365
00:22:45,590 --> 00:22:50,480
we're constraining to, it shifts around which specific diagonal slice we're looking at.

366
00:22:53,940 --> 00:22:58,340
Now what you might predict is that the way to combine all of the probability 

367
00:22:58,340 --> 00:23:02,511
densities along one of these slices, the way to integrate them together, 

368
00:23:02,511 --> 00:23:07,140
can be interpreted as the area under this curve, which is a slice of the surface.

369
00:23:07,940 --> 00:23:09,420
And that is almost correct.

370
00:23:09,740 --> 00:23:13,309
There's a subtle detail regarding a factor of the square root 

371
00:23:13,309 --> 00:23:16,994
of two that we need to talk about, but up to a constant factor, 

372
00:23:16,994 --> 00:23:20,680
the areas of these slices give us the values of the convolution.

373
00:23:21,500 --> 00:23:24,949
In fact, all of these slices that we're looking at are precisely 

374
00:23:24,949 --> 00:23:28,240
the same as the product graph that we were looking at earlier.

375
00:23:29,440 --> 00:23:34,065
Here, to emphasize this point, let me pull up both visualizations side by side, 

376
00:23:34,065 --> 00:23:36,898
and I'm going to slowly decrease the value of s, 

377
00:23:36,898 --> 00:23:40,310
which on the left means we're looking at different slices, 

378
00:23:40,310 --> 00:23:44,300
and on the right means we're shifting around the modified graph of g.

379
00:23:45,520 --> 00:23:49,455
Notice how at all points the shape of the graph on the bottom right, 

380
00:23:49,455 --> 00:23:53,904
the product between the functions, looks exactly the same as the shape of the 

381
00:23:53,904 --> 00:23:54,760
diagonal slice.

382
00:23:58,440 --> 00:23:59,700
And this should make sense.

383
00:23:59,840 --> 00:24:02,600
They are two distinct ways to visualize the same thing.

384
00:24:03,040 --> 00:24:05,750
It sounds like a lot when we put it into words, 

385
00:24:05,750 --> 00:24:10,833
but what we're looking at are all the possible products between outputs of the functions, 

386
00:24:10,833 --> 00:24:13,940
corresponding to pairs of inputs that have a given sum.

387
00:24:14,760 --> 00:24:18,203
Again, it's kind of a mouthful, but I think you see what I'm saying, 

388
00:24:18,203 --> 00:24:20,450
and we now have two different ways to see it.

389
00:24:31,000 --> 00:24:34,100
The nice thing about the diagonal slice visualization is that 

390
00:24:34,100 --> 00:24:37,100
it makes it much more clear that it's a symmetric operation.

391
00:24:37,100 --> 00:24:43,020
It's much more obvious that f convolved with g is the same thing as g convolved with f.

392
00:24:44,080 --> 00:24:47,580
Technically, the diagonal slices are not exactly the same shape.

393
00:24:47,900 --> 00:24:51,160
They've actually been stretched out by a factor of the square root of 2.

394
00:24:51,880 --> 00:24:56,260
The basic reason is that if you imagine taking some small step along one 

395
00:24:56,260 --> 00:25:01,180
of these lines where x plus y equals a constant, then the change in your x value, 

396
00:25:01,180 --> 00:25:05,200
the delta x here, is not the same thing as the length of that step.

397
00:25:05,200 --> 00:25:08,880
That step is actually longer by a factor of the square root of 2.

398
00:25:09,660 --> 00:25:13,391
I will leave a note up on the screen for the calculus enthusiasts among you 

399
00:25:13,391 --> 00:25:17,172
who want to pause and ponder, but the upshot is very simply that the outputs 

400
00:25:17,172 --> 00:25:21,100
of our convolution are technically not quite the areas of these diagonal slices.

401
00:25:21,600 --> 00:25:24,340
We have to divide those areas by a square root of 2.

402
00:25:26,140 --> 00:25:29,540
Stepping back from all of this for a moment, I just think this is so beautiful.

403
00:25:30,040 --> 00:25:34,400
We started with such a simple question, or at least such a seemingly simple question.

404
00:25:34,400 --> 00:25:36,680
How do you add up two random variables?

405
00:25:37,300 --> 00:25:39,546
And what we end up with is this very intricate 

406
00:25:39,546 --> 00:25:41,840
operation for combining two different functions.

407
00:25:42,680 --> 00:25:45,862
We have at least two very pretty ways to understand it, but still, 

408
00:25:45,862 --> 00:25:48,332
some of you might be raising your hands and saying, 

409
00:25:48,332 --> 00:25:52,560
pretty pictures are all well and good, but do they actually help you calculate something?

410
00:25:53,040 --> 00:25:55,952
For example, I still have not answered the opening quiz 

411
00:25:55,952 --> 00:25:59,280
question about adding two normally distributed random variables.

412
00:25:59,880 --> 00:26:03,516
Well, the ordinary way that you would approach this kind of question, 

413
00:26:03,516 --> 00:26:06,322
if it showed up on a homework or something like that, 

414
00:26:06,322 --> 00:26:09,907
is that you would plug in the formula for a normal distribution into 

415
00:26:09,907 --> 00:26:13,960
the definition of a convolution, the integral that we've been describing here.

416
00:26:15,080 --> 00:26:18,203
And in that case, the visualizations would really just be there to 

417
00:26:18,203 --> 00:26:21,420
clarify what the expression is saying, but they sit in the back seat.

418
00:26:21,920 --> 00:26:24,620
In this case, the integral is not prohibitively difficult.

419
00:26:24,860 --> 00:26:26,280
There are analytical methods.

420
00:26:26,280 --> 00:26:31,277
But for this example, I want to show you a more fun method where the visualizations, 

421
00:26:31,277 --> 00:26:34,923
specifically the diagonal slices, will play a much more front 

422
00:26:34,923 --> 00:26:37,040
and center role in the proof itself.

423
00:26:37,900 --> 00:26:39,986
I think many of you may actually enjoy taking a 

424
00:26:39,986 --> 00:26:42,160
moment to predict how this will look for yourself.

425
00:26:42,680 --> 00:26:47,455
Think about what this 3D graph would look like in the case of two normal distributions, 

426
00:26:47,455 --> 00:26:51,580
and what properties that it has that you might be able to take advantage of.

427
00:26:52,480 --> 00:26:55,035
And it is for sure easiest if you start with the case 

428
00:26:55,035 --> 00:26:57,780
where both distributions have the same standard deviation.

429
00:26:59,080 --> 00:27:02,006
Whenever you want the details, and to see how the answer fits 

430
00:27:02,006 --> 00:27:04,980
into the central limit theorem, come join me in the next video.

