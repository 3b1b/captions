[
 {
  "input": "Let's kick things off with a quiz. ",
  "translatedText": "بیایید کارها را با یک مسابقه شروع کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution. ",
  "translatedText": "فرض کنید من یک توزیع نرمال با این شکل منحنی زنگ آشنا می‌گیرم، و یک متغیر تصادفی x دارم که از آن توزیع گرفته شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable. ",
  "translatedText": "بنابراین آنچه در حال حاضر به آن نگاه می کنید، نمونه های تکراری آن متغیر تصادفی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values. ",
  "translatedText": "و به عنوان یک یادآوری سریع، روشی که شما این منحنی را تفسیر می‌کنید، یعنی تابع در واقع این است که اگر می‌خواهید احتمال اینکه نمونه شما در محدوده معینی از مقادیر قرار می‌گیرد، احتمال آن را بین منفی یک و دو بگویید. خوب، مساحت زیر این منحنی در آن محدوده از مقادیر برابر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means. ",
  "translatedText": "منحنی در واقع به این معنی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation. ",
  "translatedText": "من همچنین یک متغیر تصادفی دوم را انتخاب می‌کنم، همچنین از یک توزیع عادی پیروی می‌کند، اما شاید این بار کمی گسترده‌تر، یک انحراف استاندارد کمی بزرگ‌تر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you. ",
  "translatedText": "و در اینجا مسابقه برای شما است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable. ",
  "translatedText": "اگر به طور مکرر از هر دوی این متغیرها نمونه برداری کنید و در هر تکرار دو نتیجه را جمع کنید، خوب، آن مجموع مانند متغیر تصادفی خودش عمل می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape. ",
  "translatedText": "و سوال این است که چه توزیعی آن مجموع را توصیف می کند که شما به آن نگاه می کنید؟ یک لحظه به آن فکر می‌کنید، شاید حدس می‌زنید، شاید فکر می‌کنید، نمی‌دانم، توزیع عادی دیگری است یا چیزی با شکل دیگری. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough. ",
  "translatedText": "نیازی به گفتن نیست که حدس زدن کافی نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do. ",
  "translatedText": "آزمون واقعی این است که بتوانید توضیح دهید که چرا پاسخی را که می گیرید دریافت می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability. ",
  "translatedText": "در این مورد، اگر شما آن سطح احشایی را تا حد زیادی درک کنید که چرا پاسخ چیست، راه درازی برای درک اینکه چرا توزیع‌های نرمال عملکرد خاصی را انجام می‌دهند، خواهید داشت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones. ",
  "translatedText": "با این حال، با بزرگنمایی، این در واقع یک درس بسیار کلی تر است در مورد اینکه چگونه دو متغیر تصادفی مختلف را بدون توجه به توزیع آنها اضافه می کنید، نه لزوماً آنهایی که به طور معمول توزیع شده اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables. ",
  "translatedText": "این به معنای یک عملیات ویژه است که شما برای توزیع های زیربنایی آن متغیرها اعمال می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution. ",
  "translatedText": "این عملیات یک نام خاص دارد که به آن پیچیدگی می گویند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem. ",
  "translatedText": "و اولین کاری که شما و من امروز انجام خواهیم داد، ایجاد انگیزه و ایجاد دو راه متمایز برای تجسم اینکه یک کانولوشن برای توابع پیوسته چگونه به نظر می رسد، و سپس صحبت در مورد اینکه چگونه این دو تجسم مختلف می توانند هر کدام به طرق مختلف مفید باشند، با یک ویژگی خاص است. بر قضیه حد مرکزی تمرکز کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it. ",
  "translatedText": "بعد از اینکه درس عمومی را انجام دادیم، می‌خواهم به مسابقه آغازین بازگردم و روشی غیرمعمول رضایت‌بخش برای پاسخ دادن به آن ارائه دهم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel. ",
  "translatedText": "به عنوان یک یادداشت جانبی سریع، بینندگان عادی در میان شما ممکن است بدانند که قبلاً ویدیویی در مورد پیچیدگی ها در این کانال وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts. ",
  "translatedText": "اما آن یکی تمرکز کاملاً متفاوتی داشت، ما فقط موارد گسسته را انجام می‌دادیم، و من می‌خواستم نه تنها احتمال، بلکه راه‌هایی را که در زمینه‌های مختلف به وجود می‌آید را نشان دهم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video. ",
  "translatedText": "من در وضعیت کمی ناخوشایند هستم زیرا واقعاً منطقی نیست که این پیش نیاز این ویدیو باشد، اما فکر می کنم بهترین راه برای گرم کردن امروز پوشش دادن یکی از نمونه های مشابه استفاده شده در آن ویدیو است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead. ",
  "translatedText": "بنابراین اگر مستقیماً از آن یکی می‌آیید، احتمالاً می‌توانید با خیال راحت جلو بروید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in. ",
  "translatedText": "در غیر این صورت، بیایید درست شیرجه بزنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers. ",
  "translatedText": "برای این سوال مسابقه ابتدایی، هر یک از متغیرهای تصادفی می‌توانند مقداری را در محدوده بی‌نهایتی از مقادیر، همه اعداد واقعی ممکن، به دست آورند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice. ",
  "translatedText": "اگر در محیطی که گسسته تر و محدودتر است، مانند انداختن یک جفت تاس وزنی، خود را گرم کنیم، بسیار آسان تر خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration. ",
  "translatedText": "در اینجا، انیمیشنی که شما به آن نگاه می‌کنید، دو تاس وزن‌دار را شبیه‌سازی می‌کند، و احتمالاً می‌توانید بگویید که چه اتفاقی می‌افتد، اما فقط برای بیان صریح آن، قالب آبی توزیعی را دنبال می‌کند که به نظر می‌رسد به سمت مقادیر پایین‌تر، قرمز، سوگیری دارد. die توزیع مشخصی دارد، و من به طور مکرر از هر یک نمونه برداری می کنم و مجموع دو مقدار را در هر تکرار ثبت می کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely. ",
  "translatedText": "تکرار نمونه‌هایی از این دست در زمان‌های مختلف می‌تواند به شما یک حس اکتشافی از توزیع نهایی بدهد، اما وظیفه واقعی امروز ما محاسبه دقیق آن توزیع است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities? ",
  "translatedText": "احتمال دقیق چرخاندن 2 یا 3 یا 4 یا 5 برای همه احتمالات چقدر است؟ این سوال خیلی سخت نیست، من در واقع شما را تشویق می کنم که مکث کنید و سعی کنید خودتان آن را حل کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation. ",
  "translatedText": "هدف اصلی در این بخش گرم کردن، پیمودن دو روش متمایز است که بتوانید محاسبات زیربنایی را تجسم کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid. ",
  "translatedText": "برای مثال، یکی از راه‌هایی که می‌توانید درباره آن فکر کنید این است که 36 نتیجه ممکن متمایز وجود دارد، و ما می‌توانیم آن نتایج را در یک شبکه 6×6 سازماندهی کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say? ",
  "translatedText": "حالا اگر بخواهم از شما بپرسم که احتمال دیدن هر یک از این نتایج خاص، مثلاً احتمال دیدن 4 آبی و 2 قرمز چقدر است، چه می گویید؟ ممکن است بگوییم که باید احتمال آن 4 آبی ضرب در احتمال 2 قرمز باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other. ",
  "translatedText": "و این درست است با فرض اینکه دای رول ها مستقل از یکدیگر باشند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent. ",
  "translatedText": "ممکن است بگویید که این یک جور حیرت‌انگیز است، البته دای رول‌ها باید مستقل از یکدیگر باشند، اما این نکته‌ای است که باید بر آن تاکید کرد، زیرا هر کاری که از اینجا به بعد انجام می‌دهیم، از این مثال ساده تا قضیه حد مرکزی، فرض می کند که متغیرهای تصادفی مستقل هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds. ",
  "translatedText": "در دنیای واقعی، شما باید مراقب باشید که آیا این فرض واقعاً صادق است یا خیر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers. ",
  "translatedText": "اکنون کاری که من می خواهم انجام دهم این است که این شبکه از همه نتایج ممکن را انتخاب کنم، اما شروع به پر کردن آن با تعدادی اعداد کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution. ",
  "translatedText": "شاید ما اعداد را برای همه احتمالات رنگ آبی در پایین، همه احتمالات برای رنگ قرمز را در اینجا در سمت چپ قرار دهیم، و سپس شبکه ای را پر می کنیم که احتمال هر نتیجه در داخل شبکه وجود دارد. به نظر می رسد محصولی بین یک عدد از توزیع آبی و یک عدد از توزیع قرمز است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table. ",
  "translatedText": "راه دیگری برای فکر کردن در مورد آن این است که ما اساساً یک جدول ضرب می سازیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot. ",
  "translatedText": "برای اینکه در مورد همه اینها کمی بصری تر باشیم، می توانیم هر یک از این احتمالات را به صورت ارتفاع یک میله بالای مربع در این نوع طرح سه بعدی ترسیم کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice. ",
  "translatedText": "به نوعی، این طرح سه بعدی حاوی تمام داده هایی است که باید در مورد انداختن یک جفت تاس بدانیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal. ",
  "translatedText": "و بنابراین سؤال این است که چگونه چیزی را که می خواهیم بدانیم، احتمالات برای مبالغ مختلف مختلف استخراج کنیم؟ خوب، اگر همه نتایج را با یک مجموع مشخص برجسته کنید، مثلاً مجموع شش را بگویید، توجه کنید که چگونه همه آنها به یک مورب خاص ختم می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven. ",
  "translatedText": "اگر تمام جفت هایی را که مجموع آنها هفت است را برجسته کنم، همین کار را انجام می دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal. ",
  "translatedText": "آنها در امتداد یک مورب متفاوت می نشینند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals. ",
  "translatedText": "بنابراین برای محاسبه احتمال هر مجموع ممکن، کاری که انجام می‌دهید این است که تمام ورودی‌هایی را که روی یکی از این مورب‌ها قرار دارند را با هم جمع می‌کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices. ",
  "translatedText": "با بالا کشیدن نمودار سه بعدی، بهتر می توانیم پیش بینی کنیم که بعداً به کجا خواهیم رسید، با گفتن اینکه توزیع مجموع ممکن به نظر می رسد ترکیب تمام ارتفاعات این نمودار در امتداد یکی از این برش های مورب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions. ",
  "translatedText": "گویی این توزیع کامل را برای همه نتایج ممکن در نظر گرفته ایم و به نوعی آن را در یکی از جهت ها فرو ریخته ایم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot. ",
  "translatedText": "و مسلماً، من در این مرحله فقط با انیمیشن ها کمی سرگرم می شوم، نه اینکه اگر این کار را با مداد و کاغذ انجام می دادید، یک طرح سه بعدی می کشید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun! ",
  "translatedText": "اما سرگرم کننده است! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see. ",
  "translatedText": "وقتی آن را در این جهت فرو می‌کنید، در واقع همان توزیع را دریافت می‌کنید، که می‌دانستم باید آن را داشته باشید، اما هنوز دیدن آن سرگرم‌کننده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof. ",
  "translatedText": "همچنین، اگرچه ممکن است همه اینها کمی بازیگوش یا حتی غیرضروری پیچیده به نظر برسند، می‌توانم به شما قول بدهم که این شهود در مورد برش‌های مورب بعداً برای اثبات واقعاً رضایت‌بخش به ما باز خواهد گشت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it. ",
  "translatedText": "اما اگر کمی بیشتر روی تاس ساده متمرکز بمانیم، راه دومی است که می‌توانیم درباره آن فکر کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left. ",
  "translatedText": "آن توزیع پایین را بگیرید و آن را به صورت افقی بچرخانید، به طوری که با رفتن از راست به چپ، مقادیر قالب افزایش یابد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other. ",
  "translatedText": "شاید بپرسید چرا این کار را می کنید؟ خوب، اکنون توجه کنید که کدام یک از جفت مقادیر تاس با یکدیگر ردیف می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on. ",
  "translatedText": "همانطور که در حال حاضر در موقعیت قرار گرفته است، ما 1 و 6، 2 و 5، 3 و 4 و غیره داریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7. ",
  "translatedText": "این همه جفت مقادیری است که به 7 می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results. ",
  "translatedText": "بنابراین اگر می خواهید در مورد احتمال چرخاندن عدد 7 فکر کنید، راهی برای نگه داشتن این محاسبات در ذهن شما این است که همه جفت احتمالاتی را که با یکدیگر ردیف می شوند را بردارید، آن جفت ها را با هم ضرب کنید و سپس همه را جمع کنید. نتایج. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product. ",
  "translatedText": "برخی از شما ممکن است دوست داشته باشید این را نوعی محصول نقطه‌ای در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many. ",
  "translatedText": "اما این عملیات به طور کلی فقط یک محصول نقطه ای نیست، بلکه بسیاری است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5. ",
  "translatedText": "اگر بخواهیم آن توزیع پایین را کمی بیشتر به سمت چپ بلغزانیم، در این حالت به نظر می رسد که مقادیر دای که ردیف می شوند عبارتند از 1 و 4، 2 و 3، 3 و 2، 4 و 1، به عبارت دیگر همه آنهایی که جمع آنها 5 می شود، حالا اگر حاصل ضرب نقطه ای را در نظر بگیریم، جفت احتمال هایی را که ردیف می شوند ضرب می کنیم و آنها را با هم جمع می کنیم، که احتمال کل 5 را به ما می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way. ",
  "translatedText": "به طور کلی، از این منظر، محاسبه توزیع کامل برای مجموع به نظر می رسد که توزیع پایین را در موقعیت های مختلف مختلف قرار دهید و این محصول نقطه ای را در طول مسیر محاسبه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier. ",
  "translatedText": "این دقیقاً همان عملیات برش های مورب است که قبلاً به آنها نگاه کردیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation. ",
  "translatedText": "آنها فقط دو راه متفاوت برای تجسم عملیات زیربنایی یکسان هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk. ",
  "translatedText": "و هر طور که بخواهید آن را تجسم کنید، این عملیات که دو توزیع مختلف را در بر می گیرد و توزیع جدیدی را بیرون می اندازد و مجموع متغیرهای تصادفی مربوطه را توصیف می کند، پیچیدگی نامیده می شود و ما اغلب آن را با این ستاره نشان می دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function. ",
  "translatedText": "واقعاً روشی که می‌خواهید در مورد آن فکر کنید، مخصوصاً همانطور که ما برای مورد پیوسته تنظیم کرده‌ایم، این است که آن را به عنوان ترکیب دو عملکرد مختلف و تفکیک یک تابع جدید در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px. ",
  "translatedText": "به عنوان مثال، در این مورد، شاید من تابع توزیع اول را px بگذارم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability. ",
  "translatedText": "این تابعی است که مقدار احتمالی دای را می گیرد، مانند 3، و احتمال مربوطه را بیرون می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum. ",
  "translatedText": "به طور مشابه، اجازه دهید py تابع توزیع دوم ما باشد و px بعلاوه y تابعی باشد که توزیع مجموع را توصیف می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py. ",
  "translatedText": "در زبان انگلیسی، آنچه شما می گویید این است که px بعلاوه y برابر است با پیچیدگی بین px و py. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like. ",
  "translatedText": "و آنچه من می خواهم اکنون در مورد آن فکر کنید این است که فرمول این عمل چگونه باید باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4. ",
  "translatedText": "شما دو روش مختلف برای تجسم آن دیده اید، اما چگونه آن را در نمادها یادداشت کنیم؟ برای به دست آوردن بلبرینگ خود، شاید مفید باشد که یک مثال خاص را یادداشت کنید، مانند مورد وصل کردن 4، که در آن همه محصولات جفتی مختلف را که مربوط به جفت ورودی هایی است که مجموعاً 4 می شود، جمع می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look. ",
  "translatedText": "و به طور کلی تر، در اینجا ممکن است به نظر برسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y. ",
  "translatedText": "این تابع جدید یک مجموع ممکن برای متغیرهای تصادفی شما را به عنوان ورودی می گیرد، که من آن را s می نامم، و آنچه را که خروجی می دهد به نظر می رسد مجموع بر روی یک دسته از جفت مقادیر برای x و y است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6. ",
  "translatedText": "به جز روش معمولی که نوشته می‌شود این نیست که با x و y بنویسیم، بلکه ما فقط روی یکی از آن متغیرها تمرکز می‌کنیم، در این مورد x، به آن اجازه می‌دهیم در تمام مقادیر ممکن خود در محدوده باشد، که در اینجا فقط به معنای رفتن از 1 به 6 است. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s. ",
  "translatedText": "و به جای نوشتن y، s منهای x را بنویسید، اساساً هر عددی که باید باشد تا مطمئن شوید که حاصل جمع s است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written. ",
  "translatedText": "اکنون افراد زیرک در میان شما ممکن است متوجه یک ابهام کمی عجیب با فرمول همانطور که نوشته شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined. ",
  "translatedText": "به عنوان مثال، اگر مقدار مشخصی مانند s را به 4 وصل کنید، و این مجموع را باز کنید، و اجازه دهید x در تمام مقادیر ممکن از 1 تا 6 باشد، گاهی اوقات آن مقدار y متناظر از دامنه چیزی که ما داریم پایین می‌آید. به صراحت تعریف شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2. ",
  "translatedText": "به عنوان مثال، شما 0 و منفی 1 و منفی 2 را وصل می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted. ",
  "translatedText": "در واقع موضوع چندان مهمی نیست، اساساً شما فقط می‌گویید همه این مقادیر 0 هستند، بنابراین همه این عبارت‌های بعدی شمارش نمی‌شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense. ",
  "translatedText": "و این باید به نوعی منطقی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1? ",
  "translatedText": "احتمال اینکه قالب قرمز به عدد 1 تبدیل شود چقدر است؟ خوب، 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome. ",
  "translatedText": "این یک نتیجه غیر ممکن است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers. ",
  "translatedText": "به عنوان گام بعدی، بیایید توجه خود را به سمت توزیع‌های پیوسته معطوف کنیم، جایی که متغیر تصادفی شما می‌تواند مقادیری را در هر جایی در یک پیوستار بی‌نهایت، مانند همه اعداد واقعی ممکن، بگیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives. ",
  "translatedText": "شاید در حال انجام مدل‌سازی آب و هوا هستید و سعی می‌کنید دمای فردا ظهر را پیش‌بینی کنید، یا در حال انجام برخی پیش‌بینی‌های مالی هستید، یا شاید در حال مدل‌سازی زمان‌های انتظار معمولی قبل از رسیدن اتوبوس هستید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity. ",
  "translatedText": "همه جور چیزهایی وجود دارد که باید تداوم را مدیریت کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density. ",
  "translatedText": "در تمام نمودارهایی که رسم می کنیم، مقدار x همچنان عدد احتمالی را نشان می دهد که متغیر تصادفی می تواند آن را بگیرد، اما تفسیر محور y کمی متفاوت است، زیرا این دیگر نشان دهنده احتمال نیست، در عوض چیزی که ما نمودار می کنیم چیزی است که چگالی احتمال نامیده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal. ",
  "translatedText": "این چیزی است که قبلاً در مورد آن صحبت کرده ایم، بنابراین شما از معامله مطلع هستید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range. ",
  "translatedText": "اساساً، احتمال اینکه نمونه ای از متغیر شما در یک محدوده معین قرار گیرد، مانند ناحیه زیر منحنی در آن محدوده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF. ",
  "translatedText": "تابعی که این منحنی را توصیف می کند، معمولاً تابع چگالی احتمال نامیده می شود، یک عبارت به اندازه کافی رایج است که اغلب فقط به آن اختصار PDF داده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range. ",
  "translatedText": "و بنابراین راه مناسب برای نوشتن همه اینها این است که بگوییم احتمال اینکه نمونه شما در یک محدوده معین قرار می گیرد مانند انتگرال PDF شما، تابع چگالی احتمال، در آن محدوده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case. ",
  "translatedText": "به عنوان یک قاعده کلی، هر زمان که یک جمع را در حالت گسسته مشاهده کردید، از یک انتگرال در حالت پیوسته استفاده می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example. ",
  "translatedText": "بنابراین بیایید به معنای آن برای مثال اصلی خود فکر کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum. ",
  "translatedText": "فرض کنید دو متغیر تصادفی متفاوت داریم، اما این بار هر کدام یک توزیع پیوسته را دنبال می‌کنند و می‌خواهیم مجموع آنها و توزیع جدیدی را که آن مجموع را توصیف می‌کند، درک کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy. ",
  "translatedText": "احتمالاً از قبل می‌توانید حدس بزنید که فرمول دقیقاً با قیاس چیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products. ",
  "translatedText": "به یاد داشته باشید، در فرمولی که ما نوشتیم، جایی که p sub x تابع متغیر اول و p sub y تابع متغیر دوم است، پیچیدگی بین آنها، چیزی که مجموع آن متغیرها را توصیف می کند، خود به نظر می رسد. مانند یک مجموع که در آن دسته ای از محصولات جفتی را با هم ترکیب می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral. ",
  "translatedText": "عبارت در حالت پیوسته واقعاً 100٪ مشابه به نظر می رسد، فقط این است که ما آن مجموع را با یک انتگرال عوض می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating. ",
  "translatedText": "گاهی اوقات وقتی دانش آموزان این تعریف از پیچیدگی را خارج از چارچوب می بینند، ممکن است کمی ترسناک به نظر برسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms. ",
  "translatedText": "امیدواریم این تشبیه برای روشن کردن آن کافی باشد، اما ماهیت پیوسته واقعاً طعم متفاوتی به آن می‌دهد، و ارزش آن را دارد که چند دقیقه وقت بگذارید و به معنای آن در شرایط خاص فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying. ",
  "translatedText": "و بنابراین من یک نسخه نمایشی تعاملی کوچک را گردآوری کردم که به باز کردن هر بخش از عبارت و آنچه واقعاً می‌گوید کمک می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables. ",
  "translatedText": "به عنوان مثال، اولین جمله در این انتگرال f از x است که نشان دهنده تابع چگالی برای اولین از دو متغیر تصادفی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything. ",
  "translatedText": "و در این مورد من این نوع تابع گوه‌شکل را برای آن توزیع انتخاب می‌کنم، اما می‌تواند هر چیزی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution. ",
  "translatedText": "به طور مشابه، g تابع چگالی دومین متغیر تصادفی را نشان می‌دهد، که من این نوع توزیع توده‌ای شکل را برای آن انتخاب می‌کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s. ",
  "translatedText": "و همانطور که قبلاً همه جفت‌های ممکن مقادیر تاس را با یک مجموع معین بررسی کردیم، روشی که می‌خواهید در مورد این انتگرال فکر کنید این است که کاری که می‌خواهد انجام دهد این است که روی همه جفت‌های ممکن مقادیر x و y تکرار شود. محدود به یک مبلغ معین، s. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s. ",
  "translatedText": "ما واقعاً نماد خوبی برای انجام این کار به صورت متقارن نداریم، بنابراین روشی که معمولاً آن را یادداشت می کنیم، این تأکید مصنوعی را بر یکی از متغیرها می دهد، در این مورد x، جایی که اجازه می دهیم آن مقدار x در همه اعداد واقعی ممکن باشد. بی‌نهایت منفی تا بی‌نهایت، و چیزی که به تابع g وصل می‌کنیم s منهای x است، اساساً هر چیزی که باید باشد تا مطمئن شویم که این مجموع محدود به s است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x. ",
  "translatedText": "بنابراین برای نسخه آزمایشی، به جای اینکه g را مستقیماً نمودار کنم، می خواهم g از s منهای x را نمودار کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally. ",
  "translatedText": "ممکن است از خود بپرسید که چگونه به نظر می رسد؟ خوب، اگر x منفی را به عنوان ورودی وصل کنید، این اثر باعث می‌شود که نمودار به صورت افقی چرخانده شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative. ",
  "translatedText": "و سپس اگر این پارامتر s را که به عنوان نوعی ثابت در نظر گرفته می‌شود، قرار دهیم، بسته به مثبت یا منفی بودن نمودار، نمودار را به چپ یا راست تغییر می‌دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit. ",
  "translatedText": "در نسخه ی نمایشی، s پارامتری است که من فقط آن را می گیرم و کمی آن را جابجا می کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs. ",
  "translatedText": "لذت واقعی از ترسیم نمودار کل محتویات انتگرال حاصل می شود، محصول بین این دو نمودار. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph. ",
  "translatedText": "این مشابه لیستی از محصولات جفتی است که قبلاً دیدیم، اما در این مورد، به جای اینکه همه آن محصولات جفتی را جمع کنیم، می خواهیم آنها را با هم ادغام کنیم، که شما آن را به عنوان ناحیه زیر این نمودار محصول تفسیر می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area. ",
  "translatedText": "همانطور که من حول این مقدار s جابجا می شوم، شکل آن نمودار محصول تغییر می کند، و همچنین ناحیه مربوطه تغییر می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter. ",
  "translatedText": "به خاطر داشته باشید، برای هر سه نمودار سمت چپ، ورودی x است و عدد s فقط یک پارامتر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be. ",
  "translatedText": "اما برای نمودار نهایی در سمت راست، برای خود پیچیدگی حاصل، این عدد s ورودی آن تابع است، و خروجی مربوطه هر چه مساحت نمودار پایین سمت چپ باشد، هر انتگرال بین این ترکیب f و g باشد. معلوم می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half. ",
  "translatedText": "در اینجا، ممکن است مفید باشد اگر یک مثال ساده انجام دهیم، بگوییم که در آن هر یک از دو متغیر تصادفی ما از توزیع یکنواختی بین مقادیر منفی نصف و مثبت نصف پیروی می کنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else. ",
  "translatedText": "بنابراین آنچه به نظر می رسد این است که توابع چگالی ما هر کدام دارای این شکل کلاه بالایی هستند، که در آن نمودار برای همه ورودی های بین یک دوم منفی و یک دوم مثبت برابر با 1 است و در هر جای دیگر برابر با 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like? ",
  "translatedText": "سوال، مثل همیشه، این است که توزیع برای مجموع چگونه باید باشد؟ خوب، اجازه دهید به شما نشان دهم که در نسخه نمایشی ما چگونه به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation. ",
  "translatedText": "در این مورد، محصول بین دو نمودار تفسیر واقعاً آسانی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else. ",
  "translatedText": "هر جا که نمودارها با یکدیگر همپوشانی داشته باشند 1 است، اما در هر جای دیگر 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve. ",
  "translatedText": "بنابراین اگر این پارامتر را به اندازه کافی به سمت چپ بکشم که نمودارهای بالای ما به هیچ وجه با هم تداخل نداشته باشند، نمودار محصول در همه جا 0 است، و این راهی است که بگوییم این یک مجموع غیرممکن است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense. ",
  "translatedText": "این باید منطقی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1. ",
  "translatedText": "هر یک از این دو متغیر فقط می توانند به اندازه یک دوم منفی باشند، بنابراین مجموع هرگز نمی تواند از منفی 1 کمتر شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum. ",
  "translatedText": "همانطور که من شروع به لغزش s به سمت راست می کنم و نمودارها با یکدیگر همپوشانی دارند، مساحت به صورت خطی افزایش می یابد تا زمانی که نمودارها کاملاً همپوشانی داشته باشند و به حداکثر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape. ",
  "translatedText": "و سپس پس از آن نقطه، دوباره شروع به کاهش خطی می کند، به این معنی که توزیع برای مجموع این نوع شکل گوه را به خود می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice. ",
  "translatedText": "و تصور می‌کنم این برای هر کسی که به یک جفت تاس فکر می‌کند، یعنی تاس‌های وزن‌نشده، تا حدودی آشناست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape. ",
  "translatedText": "در آنجا، اگر دو متغیر متفاوت با توزیع یکنواخت را جمع آوری کنید، توزیع حاصل از مجموع شکل گوه ای خاصی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again. ",
  "translatedText": "احتمالات افزایش می‌یابد تا زمانی که در ۷ به حداکثر برسند، و سپس دوباره کاهش می‌یابند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables. ",
  "translatedText": "جایی که این موضوع بسیار جالب‌تر می‌شود این است که به جای درخواست مجموع دو متغیر با توزیع یکنواخت، از شما بپرسم که اگر سه متغیر متفاوت توزیع شده یکنواخت را با هم جمع کنیم، چگونه به نظر می‌رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two. ",
  "translatedText": "در ابتدا ممکن است بگویید، نمی دانم، ما به روش جدیدی برای تجسم ترکیب سه چیز به جای دو چیز نیاز داریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function. ",
  "translatedText": "اما واقعاً کاری که می‌توانید در اینجا انجام دهید این است که در مورد مجموع دو مورد اول به عنوان متغیر خود فکر کنید، که ما به تازگی متوجه شدیم که از توزیع شکل گوه پیروی می‌کند، و سپس یک کانولوشن بین آن و تابع کلاه بالایی در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like. ",
  "translatedText": "با کشیدن نسخه ی نمایشی، در اینجا به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph. ",
  "translatedText": "یک بار دیگر، چیزی که عملکرد کلاه بالایی را واقعاً خوب می کند این است که ضرب در آن به نوعی تأثیر فیلتر کردن مقادیر از نمودار بالایی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window. ",
  "translatedText": "محصول در پایین درست شبیه یک کپی از نمودار بالا است، اما محدود به یک پنجره خاص است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly. ",
  "translatedText": "دوباره، همانطور که من این را در اطراف چپ و راست می‌چرخانم، و ناحیه بزرگ‌تر و کوچک‌تر می‌شود، نتیجه در وسط به حداکثر می‌رسد، اما به هر طرف مخروطی می‌شود، با این تفاوت که این بار این کار را نرم‌تر انجام می‌دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph. ",
  "translatedText": "مثل این است که میانگین متحرک آن نمودار بالا سمت چپ را می گیریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph. ",
  "translatedText": "در واقع، این چیزی بیش از یک نوع ساده است، این به معنای واقعی کلمه میانگین متحرک نمودار بالا سمت چپ است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further. ",
  "translatedText": "یکی از کارهایی که ممکن است فکر کنید انجام دهید این است که این کار را حتی بیشتر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat. ",
  "translatedText": "روشی که ما شروع کردیم ترکیب دو تابع کلاه بالا بود و این گوه را به دست آوردیم، سپس اولین تابع را با آن گوه جایگزین کردیم و سپس وقتی پیچیدگی را گرفتیم به این شکل صاف تر رسیدیم که مجموع سه متغیر یکنواخت مجزا را توصیف می کند، اما می توانیم فقط تکرار کن آن را با تابع بالا عوض کنید، و سپس آن را با تابع مستطیلی مسطح در هم آمیخت، و هر نتیجه ای که می بینیم باید مجموع چهار متغیر تصادفی توزیع شده یکنواخت را توصیف کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect. ",
  "translatedText": "هر یک از شما که ویدیوی قضیه حد مرکزی را تماشا کردید باید بداند که چه انتظاری دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve. ",
  "translatedText": "همانطور که این روند را بارها و بارها تکرار می کنیم، شکل بیشتر و بیشتر شبیه یک منحنی زنگوله به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time. ",
  "translatedText": "یا به عبارت دقیق‌تر، در هر تکرار، باید محور x را تغییر مقیاس دهیم تا مطمئن شویم که انحراف استاندارد یک است، زیرا اثر غالب این پیچش مکرر، نوعی فرآیند میانگین متحرک مکرر، صاف کردن تابع است. زمان. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero. ",
  "translatedText": "بنابراین در حد آن فقط به سمت صفر صاف می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true. ",
  "translatedText": "اما تغییر مقیاس راهی برای گفتن است، بله بله بله، من می دانم که صاف تر می شود، اما شکل واقعی زیربنای همه آن چیست؟ بیان قضیه حد مرکزی، یکی از جالب‌ترین واقعیت‌های احتمال، این است که می‌توانستید اساساً با هر توزیعی شروع کنید و این هنوز هم درست می‌بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution. ",
  "translatedText": "این که همانطور که کانولوشن های مکرر مانند این را در نظر می گیرید، که مجموع بزرگتر و بزرگتر یک متغیر تصادفی معین را نشان می دهد، سپس توزیع توصیف کننده آن مجموع، که ممکن است بسیار متفاوت از توزیع معمولی به نظر برسد، به مرور زمان بیشتر و بیشتر هموار می شود تا زمانی که خودسرانه شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution. ",
  "translatedText": "نزدیک به توزیع نرمال مثل این است که منحنی زنگی، به شیوه‌ای آزاد، صاف‌ترین توزیع ممکن، نقطه ثابت جذابی در فضای همه توابع ممکن است، همانطور که ما این فرآیند هموارسازی مکرر را در کانولوشن اعمال می‌کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one? ",
  "translatedText": "به طور طبیعی ممکن است تعجب کنید، چرا توزیع نرمال؟ چرا این تابع و نه یکی دیگر؟ این پاسخ بسیار خوبی است، و من فکر می کنم سرگرم کننده ترین راه برای نشان دادن پاسخ، در پرتو آخرین تصویرسازی است که برای کانولوشن ها نشان خواهیم داد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals? ",
  "translatedText": "به یاد داشته باشید که چگونه در حالت گسسته، اولین تصویر از دو تجسم ما شامل تشکیل این نوع جدول ضرب، نشان دادن احتمالات برای همه نتایج ممکن، و جمع کردن در امتداد قطرها بود؟ احتمالاً تا به حال آن را حدس زده اید، اما آخرین گام ما تعمیم آن به حالت پیوسته است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful. ",
  "translatedText": "و زیباست اما باید کمی دقت کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier? ",
  "translatedText": "با کشیدن همان دو تابعی که قبلاً داشتیم، f از x و g از y، در این مورد چه چیزی شبیه به شبکه جفت‌های ممکنی است که قبلاً به آن نگاه می‌کردیم؟ خوب در این مورد، هر یک از متغیرها می توانند هر عدد واقعی را بگیرند، بنابراین ما می خواهیم به تمام جفت های ممکن اعداد واقعی فکر کنیم، و صفحه xy به ذهن می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions. ",
  "translatedText": "وقتی از هر دو توزیع نمونه برداری می کنیم، هر نقطه با یک نتیجه ممکن مطابقت دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent. ",
  "translatedText": "حالا احتمال هر یک از این نتایج، xy، یا بهتر است بگوییم چگالی احتمال در اطراف آن نقطه، دوباره مانند f از x ضربدر g از y، با فرض مستقل بودن این دو به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane. ",
  "translatedText": "بنابراین یک کار طبیعی این است که این تابع، f از x ضربدر g از y، را به عنوان یک تابع دو متغیره ترسیم کنیم، که چیزی شبیه به سطحی در بالای صفحه xy به دست می‌دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph. ",
  "translatedText": "در این مثال توجه کنید که چگونه اگر از یک زاویه به آن نگاه کنیم، جایی که مقادیر x را در حال تغییر می بینیم، شکل اولین نمودار ما را دارد، اما اگر از زاویه دیگری به آن نگاه کنیم، با تاکید بر تغییر جهت y، شکل نمودار دوم ما را به خود می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need. ",
  "translatedText": "این نمودار سه بعدی تمام اطلاعات مورد نیاز ما را رمزگذاری می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome. ",
  "translatedText": "تمام چگالی احتمال را برای هر نتیجه ممکن نشان می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant. ",
  "translatedText": "و اگر بخواهید دید خود را فقط به آن دسته از نتایجی محدود کنید که x به علاوه y محدود به یک جمع معین است، آنچه به نظر می‌رسد این است که نمای ما را به یک برش مورب محدود می‌کنیم، به‌ویژه یک برش روی خط x به اضافه y برابر با مقداری ثابت است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at. ",
  "translatedText": "همه چگالی احتمالات ممکن برای نتیجه موضوع این محدودیت به نوعی شبیه یک برش در زیر این نمودار به نظر می‌رسند، و با تغییر در مجموع مشخصی که به آن محدود می‌شویم، حول برش مورب خاصی که به آن نگاه می‌کنیم تغییر می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface. ",
  "translatedText": "اکنون آنچه ممکن است پیش‌بینی کنید این است که روش ترکیب همه چگالی‌های احتمال در امتداد یکی از این برش‌ها، روش ادغام آنها با هم، می‌تواند به عنوان ناحیه زیر این منحنی، که برشی از سطح است، تفسیر شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct. ",
  "translatedText": "و این تقریبا درست است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution. ",
  "translatedText": "جزئیات ظریفی در رابطه با ضریب جذر دو وجود دارد که باید در مورد آن صحبت کنیم، اما تا یک عامل ثابت، مساحت این برش ها مقادیر پیچیدگی را به ما می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier. ",
  "translatedText": "در واقع، تمام این برش هایی که ما به آنها نگاه می کنیم دقیقاً مشابه نمودار محصول است که قبلاً به آن نگاه می کردیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g. ",
  "translatedText": "در اینجا، برای تاکید بر این نکته، اجازه دهید هر دو تجسم را در کنار هم قرار دهم، و به آرامی مقدار s را کاهش می‌دهم، که در سمت چپ به این معنی است که ما به برش‌های مختلف نگاه می‌کنیم، و در سمت راست به معنای ما است. جابجایی مجدد حول نمودار اصلاح شده g. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice. ",
  "translatedText": "توجه کنید که چگونه در تمام نقاط شکل نمودار در سمت راست پایین، حاصل ضرب بین توابع، دقیقاً مشابه شکل برش مورب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense. ",
  "translatedText": "و این باید منطقی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing. ",
  "translatedText": "آنها دو راه متمایز برای تجسم یک چیز هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum. ",
  "translatedText": "هنگامی که آن را در قالب کلمات بیان می کنیم بسیار به نظر می رسد، اما آنچه ما به آن نگاه می کنیم همه محصولات ممکن بین خروجی های توابع مربوط به جفت ورودی هایی است که دارای مجموع معین هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it. ",
  "translatedText": "باز هم به نوعی لقمه‌ای است، اما فکر می‌کنم شما می‌بینید که من چه می‌گویم، و ما اکنون دو راه متفاوت برای دیدن آن داریم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation. ",
  "translatedText": "نکته خوب در مورد تجسم برش مورب این است که بسیار واضح تر می کند که یک عملیات متقارن است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f. ",
  "translatedText": "بسیار واضح تر است که f که با g در هم می پیچد همان چیزی است که g با f در هم می پیچد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape. ",
  "translatedText": "از نظر فنی، برش های مورب دقیقاً یک شکل نیستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2. ",
  "translatedText": "آنها در واقع با ضریب جذر 2 کشیده شده اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step. ",
  "translatedText": "دلیل اصلی این است که اگر تصور کنید یک گام کوچک در امتداد یکی از این خطوط بردارید که در آن x به اضافه y برابر با یک ثابت است، تغییر در مقدار x شما، دلتا x در اینجا، با طول آن مرحله یکسان نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2. ",
  "translatedText": "این مرحله در واقع ضریب جذر 2 طولانی تر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices. ",
  "translatedText": "من برای علاقه مندان به حساب دیفرانسیل و انتگرال در میان شما که می خواهند مکث و تأمل کنند، یادداشتی بر روی صفحه می گذارم، اما نتیجه بسیار ساده است که خروجی های پیچیدگی ما از نظر فنی کاملاً مساحت این برش های مورب نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2. ",
  "translatedText": "باید آن مناطق را بر جذر 2 تقسیم کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful. ",
  "translatedText": "از همه اینها برای یک لحظه عقب نشینی می کنم، فقط فکر می کنم این خیلی زیباست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables? ",
  "translatedText": "ما با یک سوال ساده یا حداقل یک سوال به ظاهر ساده شروع کردیم، چگونه دو متغیر تصادفی را جمع می کنید؟ و چیزی که در نهایت به آن می رسیم این عملیات بسیار پیچیده برای ترکیب دو عملکرد مختلف است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something? ",
  "translatedText": "ما حداقل دو راه بسیار زیبا برای درک آن داریم، اما با این حال، ممکن است برخی از شما دستان خود را بالا ببرید و بگویید، تصاویر زیبا همه خوب و خوب هستند، اما آیا واقعاً به شما کمک می‌کنند چیزی را محاسبه کنید؟ به عنوان مثال، من هنوز به سؤال مسابقه ابتدایی در مورد اضافه کردن دو متغیر تصادفی با توزیع نرمال پاسخ نداده ام. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here. ",
  "translatedText": "خوب، روش معمولی که شما به این نوع سؤال می‌پردازید، اگر در یک تکلیف یا چیزی شبیه به آن نشان داده شود، این است که فرمول توزیع نرمال را به تعریف یک کانولوشن، انتگرال که اینجا توصیف کرده ام و در آن صورت، تجسم‌ها واقعاً برای روشن کردن آنچه بیان می‌گوید وجود دارند، اما آنها در صندلی عقب می‌نشینند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself. ",
  "translatedText": "در این مورد، انتگرال خیلی سخت نیست، روش‌های تحلیلی وجود دارد، اما برای این مثال، می‌خواهم روش سرگرم‌کننده‌تری را به شما نشان دهم که در آن تجسم‌ها، به‌ویژه برش‌های مورب، نقش جلویی و مرکزی بیشتری را در خود اثبات من فکر می‌کنم بسیاری از شما ممکن است واقعاً از وقت گذاشتن برای پیش‌بینی اینکه چگونه برای خودتان به نظر می‌رسد لذت ببرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of. ",
  "translatedText": "به این فکر کنید که این نمودار سه بعدی در مورد دو توزیع معمولی چگونه خواهد بود و چه ویژگی هایی دارد که ممکن است بتوانید از آنها استفاده کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation. ",
  "translatedText": "و اگر با موردی شروع کنید که هر دو توزیع دارای انحراف استاندارد یکسان باشند، مطمئناً ساده‌ترین کار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video. ",
  "translatedText": "هر زمان که جزئیات را خواستید و برای اینکه ببینید پاسخ چگونه در قضیه حد مرکزی قرار می گیرد، در ویدیوی بعدی با من همراه شوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]