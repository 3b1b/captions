[
 {
  "input": "Let's kick things off with a quiz. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values. ",
  "translatedText": "มาเริ่มเรื่องต่างๆ กันด้วยแบบทดสอบ สมมุติว่าผมใช้การกระจายตัวแบบปกติด้วยเส้นโค้งรูประฆังที่คุ้นเคย และผมมีตัวแปรสุ่ม x ที่มาจากการกระจายตัวนั้น สิ่งที่คุณกำลังดูอยู่ตอนนี้คือตัวอย่างซ้ำของตัวแปรสุ่มนั้น และขอเตือนไว้ก่อนว่า วิธีที่คุณตีความเส้นโค้งนี้ ความหมายของฟังก์ชันจริงๆ คือว่า หากคุณต้องการความน่าจะเป็นที่ตัวอย่างของคุณอยู่ในช่วงค่าที่กำหนด ให้บอกว่าความน่าจะเป็นที่มันจะจบลงระหว่างลบ 1 กับ 2 นั่นจะเท่ากับพื้นที่ใต้เส้นโค้งนี้ในช่วงของค่านั้น นั่นคือสิ่งที่เส้นโค้งหมายถึงจริงๆ ผมจะดึงตัวแปรสุ่มตัวที่สองขึ้นมา, ตามการกระจายตัวแบบปกติ แต่บางทีคราวนี้ กระจายมากขึ้นหน่อย, ค่าเบี่ยงเบนมาตรฐานที่ใหญ่กว่าเล็กน้อย และนี่คือแบบทดสอบสำหรับคุณ หากคุณสุ่มตัวอย่างตัวแปรทั้งสองนี้ซ้ำๆ และในการวนซ้ำแต่ละครั้ง คุณบวกผลลัพธ์ทั้งสองเข้าด้วยกัน ผลรวมนั้นจะมีลักษณะเหมือนตัวแปรสุ่มของมันเอง และคำถามคือการกระจายตัวแบบใดที่อธิบายผลรวมที่คุณดูอยู่? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts. ",
  "translatedText": "คุณลองคิดดูสักพัก, บางทีคุณอาจเดาได้, บางทีคุณอาจคิดว่า, ไม่รู้สิ, มันเป็นการกระจายตัวแบบปกติแบบอื่น หรืออะไรสักอย่างที่มีรูปร่างแตกต่างออกไป จำเป็นต้องพูดการเดาไม่เพียงพอ แบบทดสอบที่แท้จริงคือการสามารถอธิบายว่าทำไมคุณถึงได้รับคำตอบเหมือนที่คุณทำ ในกรณีนี้ หากคุณมีระดับความเข้าใจลึกลงไปถึงกระดูกว่าทำไมคำตอบจึงเป็นเช่นนั้น คุณก็จะเข้าใจได้ว่าทำไมการแจกแจงแบบปกติจึงทำหน้าที่พิเศษที่พวกมันทำในความน่าจะเป็น เมื่อซูมออก จริงๆ แล้วนี่เป็นบทเรียนทั่วไปเกี่ยวกับวิธีเพิ่มตัวแปรสุ่มสองตัวที่แตกต่างกันโดยไม่คำนึงถึงการแจกแจงของตัวแปรเหล่านั้น ไม่จำเป็นต้องเป็นเพียงตัวแปรสุ่มแบบปกติเท่านั้น ซึ่งเท่ากับการดำเนินการพิเศษที่คุณใช้กับการแจกแจงที่อยู่ภายใต้ตัวแปรเหล่านั้น การดำเนินการนี้มีชื่อพิเศษ เรียกว่าการบิด และสิ่งหลักที่คุณและฉันจะทำในวันนี้คือกระตุ้นและสร้างวิธีที่แตกต่างกันสองวิธีในการแสดงภาพว่าการบิดงอเป็นอย่างไรสำหรับฟังก์ชันที่ต่อเนื่องกัน และจากนั้นจึงพูดถึงว่าการแสดงภาพทั้งสองแบบที่แตกต่างกันนี้มีประโยชน์ในวิธีที่แตกต่างกันได้อย่างไร โดยมีลักษณะพิเศษ มุ่งเน้นไปที่ทฤษฎีบทขีด จำกัด จุดศูนย์กลาง หลังจากที่เราทำบทเรียนทั่วไปแล้ว ฉันต้องการกลับไปที่แบบทดสอบเปิดและเสนอวิธีตอบคำถามที่น่าพึงพอใจเป็นพิเศษ โปรดทราบว่ามีวิดีโอเกี่ยวกับการพลิกผันในช่องนี้อยู่แล้ว ผู้ชมขาประจำในหมู่คุณอาจทราบว่ามีวิดีโอเกี่ยวกับการพลิกผัน แต่อันนั้นมีการมุ่งเน้นที่แตกต่างออกไปมาก เราทำเฉพาะกรณีที่แยกกันเท่านั้น และฉันต้องการแสดงให้เห็นไม่เพียงแค่ความน่าจะเป็น แต่วิธีที่มันเกิดขึ้นในบริบทที่หลากหลาย ฉันอยู่ในจุดที่น่าอึดอัดใจเล็กน้อยเพราะมันไม่สมเหตุสมผลเลยที่ต้องเป็นข้อกำหนดเบื้องต้นสำหรับวิดีโอนี้ แต่ฉันคิดว่าวิธีที่ดีที่สุดในการอุ่นเครื่องในวันนี้คือการครอบคลุมตัวอย่างหลักตัวใดตัวหนึ่งแบบเดียวกับที่ใช้ในวิดีโอนั้น ดังนั้นหากคุณมาจากจุดนั้นโดยตรง คุณก็สามารถข้ามไปข้างหน้าได้อย่างปลอดภัย ไม่อย่างนั้นก็มาดำดิ่งลงไปเลย สำหรับคำถามตอบคำถามเปิดนี้ ตัวแปรสุ่มแต่ละตัวสามารถรับค่าในช่วงค่าที่ต่อเนื่องไม่สิ้นสุด ซึ่งเป็นจำนวนจริงที่เป็นไปได้ทั้งหมด มันจะง่ายกว่ามากถ้าเราวอร์มร่างกายในสภาพแวดล้อมที่แยกจากกันและมีขอบเขตมากขึ้น เช่น การทอยลูกเต๋าถ่วงน้ำหนักคู่หนึ่ง ตรงนี้ แอนิเมชั่นที่คุณกำลังดูกำลังจำลองลูกเต๋าถ่วงน้ำหนักสองตัว และคุณอาจบอกได้ว่าเกิดอะไรขึ้น แต่เพื่ออธิบายให้ชัดเจน ลูกเต๋าสีน้ำเงินกำลังติดตามการกระจายตัวที่ดูเหมือนว่าจะเอนเอียงไปทางค่าที่ต่ำกว่า สีแดง die มีการแจกแจงที่แตกต่างกัน และฉันก็สุ่มตัวอย่างซ้ำๆ จากแต่ละรายการและบันทึกผลรวมของทั้งสองค่าในการวนซ้ำแต่ละครั้ง การทำซ้ำตัวอย่างหลายๆ ครั้งหลายๆ ครั้งจะทำให้คุณเข้าใจถึงการแจกแจงขั้นสุดท้ายได้ แต่งานที่แท้จริงของเราในปัจจุบันคือคำนวณการแจกแจงอย่างแม่นยำ ความน่าจะเป็นที่แน่นอนของการทอย 2 หรือ 3 หรือ 4 หรือ 5 ไปเรื่อยๆ สำหรับความเป็นไปได้ทั้งหมดคือเท่าไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid. ",
  "translatedText": "เป็นคำถามที่ไม่ยากเกินไป ฉันขอแนะนำให้คุณหยุดและลองทำด้วยตัวเอง เป้าหมายหลักในส่วนอุ่นเครื่องนี้คือการอธิบายสองวิธีที่แตกต่างกันเพื่อให้คุณเห็นภาพการคำนวณพื้นฐาน  ตัวอย่างเช่น วิธีหนึ่งที่คุณสามารถเริ่มคิดได้ก็คือ มีผลลัพธ์ที่เป็นไปได้ที่แตกต่างกัน 36 รายการ และเราสามารถจัดระเบียบผลลัพธ์เหล่านั้นเป็นตารางขนาด 6x6 เล็กๆ น้อยๆ ได้ ทีนี้ หากผมถามคุณว่า อะไรคือความน่าจะเป็นที่จะเห็นผลอันใดอันหนึ่งเหล่านี้ บอกว่าความน่าจะเป็นที่จะเห็นเลข 4 สีน้ำเงิน และ 2 สีแดง คุณจะตอบว่าอะไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2. ",
  "translatedText": "เราอาจบอกว่ามันควรเป็นความน่าจะเป็นของ 4 สีน้ำเงินนั้น คูณด้วยความน่าจะเป็นของสีแดง 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution. ",
  "translatedText": "และนั่นจะถูกต้องหากสมมติว่าลูกกลิ้งแม่พิมพ์มีความเป็นอิสระจากกัน คุณอาจบอกว่านั่นเป็นเรื่องอวดรู้ แน่นอนว่าลูกกลิ้งแม่พิมพ์ควรเป็นอิสระจากกัน แต่ก็เป็นประเด็นที่ควรเน้นย้ำ เพราะทุกสิ่งที่เราจะทำต่อจากนี้ก้าวไปข้างหน้า จากตัวอย่างง่ายๆ นี้ไปจนถึง ทฤษฎีบทขีดจำกัดกลาง ถือว่าตัวแปรสุ่มมีความเป็นอิสระ ในโลกแห่งความเป็นจริง คุณต้องจับตาดูให้ดีว่าสมมติฐานนี้เกิดขึ้นจริงหรือไม่ ทีนี้สิ่งที่ฉันจะทำคือเอาตารางผลลัพธ์ที่เป็นไปได้ทั้งหมดมา แต่เริ่มเติมตัวเลขลงไปก่อน บางทีเราอาจใส่ตัวเลขของความน่าจะเป็นของค่าตายตัวสีน้ำเงินทั้งหมดไว้ด้านล่าง ความน่าจะเป็นของค่าสีแดงตายตรงนี้ทางซ้าย แล้วเราจะเติมลงในตาราง โดยความน่าจะเป็นของทุกผลลัพธ์ภายในตาราง ดูเหมือนผลคูณระหว่างหมายเลขหนึ่งจากการแจกแจงสีน้ำเงินและหนึ่งหมายเลขจากการแจกแจงสีแดง วิธีคิดอีกอย่างคือ เรากำลังสร้างตารางสูตรคูณขึ้นมา เพื่อให้เห็นภาพทั้งหมดนี้มากขึ้น เราสามารถพลอตความน่าจะเป็นแต่ละอันเป็นความสูงของแท่งที่อยู่เหนือสี่เหลี่ยมจัตุรัสในโครงเรื่องสามมิติแบบนี้ ในแง่หนึ่ง โครงเรื่องสามมิตินี้มีข้อมูลทั้งหมดที่เราต้องรู้เกี่ยวกับการทอยลูกเต๋า คำถามคือเราจะดึงสิ่งที่เราอยากรู้ ความน่าจะเป็นของผลรวมต่างๆ ออกมาได้อย่างไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices. ",
  "translatedText": "ทีนี้ หากคุณเน้นผลลัพธ์ทั้งหมดด้วยผลรวมที่แน่นอน เช่น ผลรวมของ 6 สังเกตว่าผลลัพธ์ทั้งหมดนั้นจบลงที่เส้นทแยงมุมใดค่าหนึ่ง ข้อตกลงเดียวกันถ้าฉันเน้นทุกคู่ที่ผลรวมเป็นเจ็ด พวกเขานั่งในแนวทแยงที่แตกต่างกัน เพื่อคำนวณความน่าจะเป็นของแต่ละผลรวมที่เป็นไปได้ สิ่งที่คุณทำคือบวกค่าทั้งหมดที่อยู่บนเส้นทแยงมุมอันใดอันหนึ่งเข้าด้วยกัน เมื่อดึงพล็อต 3 มิติขึ้นมา เราจะสามารถคาดเดาได้ดีขึ้นว่าเราจะไปที่ใดในภายหลัง โดยบอกว่าการกระจายตัวของผลรวมที่เป็นไปได้นั้นดูเหมือนว่าจะรวมความสูงทั้งหมดของโครงเรื่องนี้เข้ากับชิ้นแนวทแยงชิ้นใดชิ้นหนึ่ง เหมือนกับว่าเราหาการกระจายตัวแบบเต็มนี้ สำหรับผลลัพธ์ที่เป็นไปได้ทั้งหมด แล้วเราก็ยุบมันไปตามทิศทางใดทิศทางหนึ่ง และยอมรับว่า ณ จุดนี้ ฉันแค่สนุกนิดหน่อยกับแอนิเมชั่น ไม่ใช่ว่าถ้าคุณทำสิ่งนี้ด้วยดินสอและกระดาษ คุณจะวาดโครงเรื่องสามมิติได้ แต่ก็สนุกดี! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun! ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof. ",
  "translatedText": "เมื่อคุณยุบมันในทิศนี้, คุณจะได้การกระจายตัวแบบเดิม, ซึ่งผมรู้ว่าควรทำ แต่ก็ยังสนุกที่ได้เห็น นอกจากนี้ แม้ว่าทั้งหมดนี้อาจดูเล่นๆ นิดหน่อยหรือซับซ้อนโดยไม่จำเป็น แต่ฉันสัญญากับคุณได้ว่าสัญชาตญาณเกี่ยวกับชิ้นในแนวทแยงจะกลับมาหาเราในภายหลังเพื่อเป็นข้อพิสูจน์ที่น่าพึงพอใจอย่างแท้จริง แต่การจดจ่ออยู่กับกรณีลูกเต๋าธรรมดาอีกสักหน่อย นี่คือวิธีที่สองที่เราสามารถคิดถึงมันได้ ใช้การกระจายด้านล่างแล้วพลิกไปรอบ ๆ ในแนวนอน เพื่อให้ค่าการตายเพิ่มขึ้นเมื่อคุณไปจากขวาไปซ้าย ทำไมทำเช่นนี้คุณอาจถาม? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on. ",
  "translatedText": "สังเกตว่าตอนนี้ค่าลูกเต๋าคู่ใดเรียงกัน ตามที่วางไว้ตอนนี้ เรามี 1 กับ 6, 2 และ 5, 3 และ 4 และอื่นๆ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation. ",
  "translatedText": "มันคือคู่ของค่าทั้งหมดที่รวมกันได้ 7 ดังนั้น หากคุณอยากคิดถึงความน่าจะเป็นที่จะทอยเลข 7 วิธีที่จะจำการคำนวณนั้นไว้ในใจก็คือ นำคู่ความน่าจะเป็นทั้งหมดที่เรียงต่อกัน มาคูณคู่เหล่านั้นเข้าด้วยกัน แล้วบวกทั้งหมด ผลลัพธ์ บางท่านอาจคิดว่านี่เป็นผลคูณดอท แต่การดำเนินการโดยรวมไม่ใช่แค่ดอทโปรดัคตัวเดียว แต่มีหลายตัว หากเราเลื่อนการกระจายด้านล่างไปทางซ้ายอีกหน่อย ดังนั้นในกรณีนี้ ดูเหมือนว่าค่าตายซึ่งเรียงกันเป็น 1 และ 4, 2 และ 3, 3 และ 2, 4 และ 1 หรืออีกนัยหนึ่งคือ ค่าที่รวมกันได้ 5 ทีนี้ ถ้าเราหาดอทโปรดัค เราจะคูณความน่าจะเป็นคู่ที่เรียงกันแล้วบวกเข้าด้วยกัน ซึ่งจะให้ความน่าจะเป็นรวมที่จะได้ 5 โดยทั่วไป จากมุมมองนี้ การคำนวณการกระจายตัวเต็มของผลรวมดูเหมือนเป็นการเลื่อนการกระจายตัวด้านล่างไปยังตำแหน่งต่างๆ และคำนวณดอทโปรดัคนี้ไปพร้อมกัน มันเป็นการดำเนินการแบบเดียวกับชิ้นแนวทแยงที่เราดูก่อนหน้านี้ มันเป็นเพียงสองวิธีที่แตกต่างกันในการแสดงภาพการดำเนินการพื้นฐานเดียวกัน และไม่ว่าคุณจะเลือกเห็นภาพมันอย่างไร การดำเนินการนี้ที่ใช้การแจกแจงสองแบบที่แตกต่างกัน แล้วแยกการแจกแจงใหม่ออกมา โดยอธิบายผลรวมของตัวแปรสุ่มที่เกี่ยวข้อง เรียกว่าการบิด และเรามักจะแสดงด้วยเครื่องหมายดอกจันนี้ วิธีที่คุณต้องการคิดจริงๆ โดยเฉพาะอย่างยิ่งเมื่อเราตั้งค่าสำหรับกรณีต่อเนื่อง คือการคิดว่ามันเป็นการรวมฟังก์ชันที่แตกต่างกันสองฟังก์ชันเข้าด้วยกันและแยกฟังก์ชันใหม่ออกมา ตัวอย่างเช่น ในกรณีนี้ ฉันอาจตั้งชื่อ px ให้กับฟังก์ชันสำหรับการแจกแจงครั้งแรก นี่จะเป็นฟังก์ชันที่รับค่าที่เป็นไปได้สำหรับการตาย เช่น 3 และแยกความน่าจะเป็นที่สอดคล้องกันออกมา ในทำนองเดียวกัน ให้ py เป็นฟังก์ชันสำหรับการแจกแจงครั้งที่สอง และ px บวก y เป็นฟังก์ชันที่อธิบายการกระจายตัวของผลรวม ตามศัพท์แสง คุณจะบอกว่า px บวก y เท่ากับการบิดงอระหว่าง px กับ py และสิ่งที่ผมอยากให้คุณคิดตอนนี้คือสูตรของการดำเนินการนี้ควรเป็นอย่างไร คุณเคยเห็นสองวิธีที่แตกต่างกันในการแสดงภาพ แต่เราจะเขียนมันลงในสัญลักษณ์ได้อย่างไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y. ",
  "translatedText": "เพื่อให้ได้ทิศทาง การเขียนตัวอย่างเฉพาะเจาะจงลงไปอาจเป็นประโยชน์ เช่น กรณีของการเสียบเลข 4 โดยที่คุณบวกค่าผลคูณคู่ต่างๆ ทั้งหมดที่ตรงกับคู่อินพุตที่รวมกันได้เท่ากับ 4 และโดยทั่วไปแล้ว มันอาจจะมีลักษณะดังนี้ ฟังก์ชันใหม่นี้รับผลรวมที่เป็นไปได้สำหรับตัวแปรสุ่มของคุณ ซึ่งผมจะเรียกว่า s และผลลัพธ์ที่ออกมาจะดูเหมือนผลบวกของคู่ค่าต่างๆ ของ x และ y ยกเว้นวิธีปกติที่เขียนไว้ไม่ใช่เขียนด้วย x และ y แต่เราแค่เน้นไปที่ตัวแปรตัวใดตัวหนึ่งแทน ในกรณีนี้คือ x ปล่อยให้มันอยู่ในช่วงค่าที่เป็นไปได้ทั้งหมด ซึ่งในที่นี้หมายถึงไปจาก 1 ถึง 6 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined. ",
  "translatedText": "และแทนที่จะเขียน y, คุณเขียน s ลบ x, จริงๆ แล้วเลขอะไรก็ตาม จะต้องเป็นเพื่อให้แน่ใจว่าผลรวมเป็น s ตอนนี้ผู้มีไหวพริบในหมู่คุณอาจสังเกตเห็นมุมแหลมแปลก ๆ เล็กน้อยกับสูตรตามที่เขียนไว้ ตัวอย่างเช่น หากคุณแทนค่าที่กำหนด เช่น s เท่ากับ 4 และคุณคลายผลรวมนี้ โดยปล่อยให้ x มีช่วงเหนือค่าที่เป็นไปได้ทั้งหมดตั้งแต่ 1 ถึง 6 แล้วบางครั้งค่า y ที่สอดคล้องกันนั้นจะลดลงต่ำกว่าโดเมนของสิ่งที่เรา ได้กำหนดไว้ชัดเจนแล้ว ตัวอย่างเช่น คุณแทนค่า 0 และค่าลบ 1 และค่าลบ 2 มันไม่ใช่เรื่องใหญ่ขนาดนั้น จริงๆ แล้วคุณก็แค่บอกว่าค่าพวกนี้เป็น 0 เทอมหลังๆ พวกนี้จะไม่ถูกนับ และนั่นก็ควรจะสมเหตุสมผล ความน่าจะเป็นที่ลูกเต๋าสีแดงทอยกลายเป็นลบ 1 เป็นเท่าไหร่? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products. ",
  "translatedText": "มันคือ 0 นั่นเป็นผลลัพธ์ที่เป็นไปไม่ได้ ขั้นต่อไป ให้เรามุ่งความสนใจไปที่การแจกแจงแบบต่อเนื่อง โดยที่ตัวแปรสุ่มสามารถรับค่าใดๆ ก็ได้ในความต่อเนื่องไม่สิ้นสุด เช่นเดียวกับจำนวนจริงที่เป็นไปได้ทั้งหมด บางทีคุณอาจกำลังสร้างโมเดลสภาพอากาศและพยายามคาดการณ์อุณหภูมิในวันพรุ่งนี้ตอนเที่ยง หรือกำลังประมาณการทางการเงิน หรือบางทีคุณอาจกำลังสร้างโมเดลเวลารอโดยทั่วไปก่อนที่รถบัสจะมาถึง มีสิ่งต่างๆ มากมายที่คุณต้องจัดการกับความต่อเนื่อง ในกราฟทั้งหมดที่เราวาด ค่า x ยังคงแสดงถึงจำนวนที่เป็นไปได้ที่ตัวแปรสุ่มสามารถใช้ได้ แต่การตีความแกน y นั้นแตกต่างออกไปเล็กน้อย เพราะค่านี้ไม่ได้แสดงถึงความน่าจะเป็นอีกต่อไป แทนที่จะเป็นสิ่งที่ เรากำลังสร้างกราฟที่เรียกว่าความหนาแน่นของความน่าจะเป็น นี่คือสิ่งที่เราเคยพูดถึงมาก่อน ดังนั้นคุณก็รู้ข้อตกลงนี้ โดยพื้นฐานแล้ว ความน่าจะเป็นที่ตัวอย่างตัวแปรของคุณอยู่ในช่วงที่กำหนดจะดูเหมือนพื้นที่ใต้เส้นโค้งในช่วงนั้น ฟังก์ชันที่อธิบายเส้นโค้งนี้มักเรียกว่าฟังก์ชันความหนาแน่นของความน่าจะเป็น ซึ่งเป็นวลีที่ใช้บ่อยจนมักใช้ตัวย่อในรูปแบบ PDF ดังนั้นวิธีที่เหมาะสมในการเขียนทั้งหมดนี้ คือบอกว่าความน่าจะเป็นที่ตัวอย่างของคุณอยู่ในช่วงที่กำหนด ดูเหมือนอินทิกรัลของ PDF ซึ่งเป็นฟังก์ชันความหนาแน่นของความน่าจะเป็น ในช่วงนั้น ตามหลักการทั่วไป ทุกครั้งที่คุณเห็นผลรวมในกรณีที่แยก คุณจะต้องใช้อินทิกรัลในกรณีต่อเนื่อง ลองคิดว่านั่นหมายถึงอะไรสำหรับตัวอย่างหลักของเรา สมมติว่าเรามีตัวแปรสุ่มสองตัวที่แตกต่างกัน แต่คราวนี้แต่ละตัวจะเป็นไปตามการแจกแจงแบบต่อเนื่อง และเราต้องการที่จะเข้าใจผลรวมของตัวแปรเหล่านี้และการแจกแจงใหม่ที่อธิบายผลรวมนั้น คุณอาจเดาได้ว่าสูตรจะเป็นเช่นไรโดยการเปรียบเทียบ จำไว้ว่าในสูตรที่เราเพิ่งเขียนลงไป โดยที่ p sub x เป็นฟังก์ชันสำหรับตัวแปรตัวแรก และ p sub y เป็นฟังก์ชันสำหรับตัวแปรตัวที่สอง การบิดระหว่างพวกมัน สิ่งที่อธิบายผลรวมของตัวแปรเหล่านั้น ในตัวมันเองจะมีลักษณะดังนี้ เหมือนผลรวมที่เรารวมผลิตภัณฑ์จำนวนหนึ่งเข้าด้วยกัน นิพจน์ในกรณีที่ต่อเนื่องดูคล้ายกัน 100% แค่เราสลับผลบวกนั้นกับอินทิกรัล บางครั้งเมื่อนักเรียนเห็นคำจำกัดความของการบิดเบี้ยวนี้นอกบริบท ก็อาจดูน่ากลัวเล็กน้อย หวังว่าการเปรียบเทียบจะเพียงพอที่จะทำให้มันชัดเจน แต่ธรรมชาติที่ต่อเนื่องกันนั้นให้รสชาติที่แตกต่างออกไปจริงๆ และมันก็คุ้มค่าที่จะสละเวลาสองสามนาทีเพื่อพิจารณาว่ามันหมายถึงอะไรตามเงื่อนไขของมันเอง ดังนั้นฉันจึงรวบรวมการสาธิตเชิงโต้ตอบเล็กๆ น้อยๆ ที่ช่วยแยกแต่ละส่วนของสำนวนและสิ่งที่สื่อความหมายจริงๆ ตัวอย่างเช่น เทอมแรกในอินทิกรัลนี้คือ f ของ x ซึ่งแทนฟังก์ชันความหนาแน่นของตัวแปรสุ่มตัวแรกจากสองตัว และในกรณีนี้ ผมจะเลือกฟังก์ชันรูปลิ่มแบบนี้สำหรับการกระจายตัวนั้น, แต่มันจะเป็นอะไรก็ได้ ในทำนองเดียวกัน g แทนฟังก์ชันความหนาแน่นของตัวแปรสุ่มตัวที่สอง ซึ่งฉันเลือกการกระจายตัวแบบก้อนสองชั้นแบบนี้ และในทำนองเดียวกับที่ก่อนหน้านี้ เราพิจารณาคู่ของค่าลูกเต๋าที่เป็นไปได้ทั้งหมดด้วยผลรวมที่กำหนด วิธีที่คุณต้องการคิดเกี่ยวกับอินทิกรัลนี้คือสิ่งที่ต้องการทำคือวนซ้ำคู่ที่เป็นไปได้ทั้งหมดของค่า x และ y ที่ ถูกจำกัดด้วยจำนวนที่กำหนด s เราไม่มีสัญกรณ์ที่ดีนักในการทำแบบนั้นแบบสมมาตร แต่วิธีที่เราเขียนมันลงไปกลับเน้นไปที่ตัวแปรตัวใดตัวหนึ่งแทน ในกรณีนี้คือ x โดยที่เราปล่อยให้ค่า x มีช่วงเป็นจำนวนจริงที่เป็นไปได้ทั้งหมด ลบอนันต์จนถึงอนันต์ และสิ่งที่เราแทนค่าลงในฟังก์ชัน g คือ s ลบ x สิ่งสำคัญที่สุดก็คืออะไรก็ได้เพื่อให้แน่ใจว่าผลรวมนี้จำกัดเป็น s สำหรับการสาธิต, แทนที่จะวาดกราฟ g โดยตรง, ผมอยากจะวาดกราฟ g ของ s ลบ x คุณอาจถามตัวเองว่ามันมีลักษณะอย่างไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter. ",
  "translatedText": "ทีนี้ ถ้าคุณแทนค่าลบ x เป็นอินพุต มันจะมีผลกับการพลิกกราฟในแนวนอน แล้วถ้าเราใส่พารามิเตอร์นี้ s ซึ่งถือเป็นค่าคงที่ชนิดหนึ่งลงไป มันมีผลกับการเลื่อนกราฟไปทางซ้ายหรือขวา ขึ้นอยู่กับว่า s เป็นบวกหรือลบ ในการสาธิต s คือพารามิเตอร์ที่ฉันจะจับและเลื่อนไปมาเล็กน้อย ความสนุกที่แท้จริงมาจากการสร้างกราฟเนื้อหาทั้งหมดของอินทิกรัล ซึ่งเป็นผลคูณระหว่างกราฟทั้งสองนี้ สิ่งนี้คล้ายคลึงกับรายการผลิตภัณฑ์แบบคู่ที่เราเห็นก่อนหน้านี้ แต่ในกรณีนี้ แทนที่จะรวมผลิตภัณฑ์แบบคู่ทั้งหมดเข้าด้วยกัน เราต้องการรวมผลิตภัณฑ์เหล่านั้นเข้าด้วยกัน ซึ่งคุณจะตีความว่าเป็นพื้นที่ใต้กราฟผลิตภัณฑ์นี้ เมื่อฉันเลื่อนค่า s นี้ รูปร่างของกราฟผลิตภัณฑ์นั้นจะเปลี่ยนไป และพื้นที่ที่สอดคล้องกันก็เปลี่ยนเช่นกัน โปรดทราบว่าสำหรับกราฟทั้งสามทางด้านซ้าย ข้อมูลเข้าคือ x และตัวเลข s เป็นเพียงพารามิเตอร์ แต่สำหรับกราฟสุดท้ายทางขวา สำหรับผลลัพธ์ของการโควลูชันเอง ตัวเลข s คือข้อมูลเข้าของฟังก์ชันนั้น และผลลัพธ์ที่สอดคล้องกันคือพื้นที่ของกราฟด้านซ้ายล่างจะเป็นเท่าใด จะเป็นอินทิกรัลระหว่างผลรวมของ f และ g ก็ตาม ปรากฎว่าเป็น ในที่นี้ อาจมีประโยชน์ถ้าเรายกตัวอย่างง่ายๆ สมมติว่าตัวแปรสุ่มสองตัวของเรามีการกระจายตัวแบบสม่ำเสมอระหว่างค่าลบครึ่งหนึ่งและบวกครึ่งหนึ่ง สิ่งที่ดูเหมือนคือว่าฟังก์ชันความหนาแน่นของเราแต่ละอันมีรูปทรงหมวกทรงสูงแบบนี้ โดยกราฟเท่ากับ 1 สำหรับค่าเข้าทั้งหมดระหว่างลบครึ่งหนึ่งกับบวกครึ่งหนึ่ง และส่วนอื่นจะเท่ากับ 0 คำถามเช่นเคยคือการกระจายตัวของผลรวมควรเป็นอย่างไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function. ",
  "translatedText": "ให้ฉันแสดงให้คุณเห็นว่ามันดูเป็นอย่างไรในการสาธิตของเรา ในกรณีนี้ ผลคูณระหว่างกราฟทั้งสองมีการตีความที่ง่ายมาก กราฟซ้อนทับกันเป็น 1 ทุกที่ แต่เป็น 0 ทุกที่ ดังนั้นหากฉันเลื่อนพารามิเตอร์นี้ไปทางซ้ายจนกราฟบนสุดไม่ทับซ้อนกันเลย กราฟผลคูณจะเป็น 0 ทุกที่ และนั่นเป็นวิธีบอกว่านี่เป็นผลรวมที่เป็นไปไม่ได้ นั่นควรจะสมเหตุสมผล ตัวแปรแต่ละตัวในสองตัวนี้จะมีค่าต่ำสุดเท่ากับลบครึ่งหนึ่งเท่านั้น ดังนั้นผลรวมจึงไม่มีทางต่ำกว่าลบ 1 เลย เมื่อฉันเริ่มเลื่อน s ไปทางขวาและกราฟซ้อนทับกัน พื้นที่นั้นจะเพิ่มขึ้นเป็นเส้นตรงจนกระทั่งกราฟเหลื่อมกันทั้งหมดและถึงค่าสูงสุด แล้วหลังจากนั้น มันเริ่มลดลงเป็นเส้นตรงอีกครั้ง ซึ่งหมายความว่าการกระจายตัวของผลรวมจะเป็นรูปทรงลิ่มแบบนี้ และฉันคิดว่านี่ค่อนข้างจะคุ้นเคยสำหรับทุกคนที่คิดถึงลูกเต๋าคู่หนึ่ง ซึ่งก็คือลูกเต๋าไม่ถ่วงน้ำหนัก ที่นั่น หากคุณรวมตัวแปรที่มีการกระจายสม่ำเสมอสองตัวเข้าด้วยกัน การแจกแจงของผลรวมจะมีรูปทรงลิ่มที่แน่นอน ความน่าจะเป็นเพิ่มขึ้นจนกระทั่งสูงสุดที่ 7 จากนั้นจึงลดลงอีกครั้ง สิ่งที่สนุกกว่านี้มากคือ แทนที่จะถามหาผลรวมของตัวแปรที่มีการกระจายสม่ำเสมอสองตัว ฉันจะถามคุณว่าถ้าเรารวมตัวแปรที่มีการกระจายสม่ำเสมอสามตัวที่ต่างกันเข้าด้วยกันจะเป็นอย่างไร ตอนแรกคุณอาจบอกว่า ไม่รู้สิ เราต้องการวิธีใหม่ในการแสดงภาพการรวมสามสิ่งเข้าด้วยกัน แทนที่จะเป็นสองสิ่ง แต่จริงๆ แล้วสิ่งที่คุณทำได้ตรงนี้ คือคิดว่าผลบวกของสองตัวแรกเป็นตัวแปรของมันเอง ซึ่งเราเพิ่งหาได้ตามการกระจายตัวของรูปทรงลิ่ม แล้วหาการบิดระหว่างค่านั้นกับฟังก์ชันหมวกทรงสูง เมื่อดึงการสาธิตขึ้นมา หน้าตาจะเป็นอย่างไร อีกครั้งหนึ่ง สิ่งที่ทำให้ฟังก์ชันหมวกทรงสูงดีจริงๆ คือการคูณด้วยฟังก์ชันดังกล่าวจะส่งผลต่อการกรองค่าออกจากกราฟด้านบน ผลิตภัณฑ์ที่อยู่ด้านล่างมีลักษณะเหมือนกับสำเนาของกราฟด้านบน แต่จำกัดอยู่เพียงบางหน้าต่าง อีกครั้ง เมื่อฉันเลื่อนสิ่งนี้ไปรอบๆ ซ้ายและขวา และพื้นที่จะใหญ่ขึ้นเรื่อยๆ ผลลัพธ์ที่ได้จะออกมาสูงสุดตรงกลาง แต่จะค่อยๆ เรียวออกไปทั้งสองด้าน ยกเว้นคราวนี้มันจะราบรื่นมากขึ้น มันเหมือนกับว่าเรากำลังหาค่าเฉลี่ยเคลื่อนที่ของกราฟซ้ายบนนั่น ที่จริง, มันเป็นมากกว่าแค่แบบนี้, นี่คือค่าเฉลี่ยเคลื่อนที่ของกราฟมุมซ้ายบน สิ่งหนึ่งที่คุณอาจคิดที่จะทำคือทำให้สิ่งนี้ดียิ่งขึ้นไปอีก วิธีที่เราเริ่มต้นคือการรวมฟังก์ชันหมวกทรงสูงสองฟังก์ชันเข้าด้วยกัน และเราได้ลิ่มนี้ จากนั้นเราก็แทนที่ฟังก์ชันแรกด้วยลิ่มนั้น และเมื่อเราทำการบิด เราก็ได้รูปร่างที่นุ่มนวลขึ้นนี้ ซึ่งอธิบายผลรวมของตัวแปรที่เหมือนกันสามตัวที่แตกต่างกัน แต่เราทำได้ แค่ทำซ้ำ สลับมันออกมาเป็นฟังก์ชันบนสุด แล้วหมุนมันด้วยฟังก์ชันสี่เหลี่ยมแบน และผลลัพธ์ใดก็ตามที่เราเห็นควรอธิบายผลรวมของตัวแปรสุ่มที่กระจายสม่ำเสมอสี่ตัว พวกคุณคนใดก็ตามที่ดูวิดีโอเกี่ยวกับทฤษฎีบทขีดจำกัดกลางควรรู้ว่าจะเกิดอะไรขึ้น เมื่อเราทำซ้ำขั้นตอนนี้ซ้ำแล้วซ้ำอีก รูปร่างจะดูเหมือนเส้นโค้งระฆังมากขึ้นเรื่อยๆ หรือเพื่อให้แม่นยำยิ่งขึ้น ในการวนซ้ำแต่ละครั้ง เราควรปรับขนาดแกน x ใหม่เพื่อให้แน่ใจว่าค่าเบี่ยงเบนมาตรฐานเป็นหนึ่ง เพราะผลเด่นของการบิดซ้ำนี้ ซึ่งเป็นกระบวนการของค่าเฉลี่ยเคลื่อนที่ซ้ำๆ คือการทำให้ฟังก์ชันราบเรียบลง เวลา. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all? ",
  "translatedText": "เมื่อถึงขีดจำกัด มันก็จะแบนไปทางศูนย์ แต่การลดขนาดเป็นวิธีหนึ่งในการพูดว่า ใช่ ใช่ ใช่ ฉันรู้ว่ามันดูเรียบขึ้น แต่รูปร่างที่แท้จริงที่เป็นรากฐานของทั้งหมดคืออะไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution. ",
  "translatedText": "ข้อความของทฤษฎีบทขีดจำกัดจุดศูนย์กลาง หนึ่งในข้อเท็จจริงที่เจ๋งที่สุดเกี่ยวกับความน่าจะเป็น คือ คุณสามารถเริ่มต้นด้วยการแจกแจงแบบใดๆ ก็ตาม และนี่ก็ยังคงเป็นจริง ว่าเมื่อคุณทำการโน้มน้าวใจซ้ำๆ แบบนี้ ซึ่งแสดงถึงผลรวมที่มากขึ้นเรื่อยๆ ของตัวแปรสุ่มที่กำหนด แล้วการกระจายที่อธิบายผลรวมนั้น ซึ่งอาจเริ่มดูแตกต่างอย่างมากจากการแจกแจงแบบปกติ เมื่อเวลาผ่านไปจะราบรื่นขึ้นเรื่อยๆ จนกระทั่งมันเป็นไปตามอำเภอใจ ใกล้เคียงกับการกระจายแบบปกติ ราวกับว่าเส้นโค้งระฆังเป็นการกระจายที่ราบรื่นที่สุดเท่าที่จะเป็นไปได้ เป็นจุดคงที่ที่น่าสนใจในปริภูมิของฟังก์ชันที่เป็นไปได้ทั้งหมด ในขณะที่เราใช้กระบวนการทำให้เรียบซ้ำๆ ผ่านการบิด โดยปกติแล้วคุณอาจสงสัยว่า ทำไมจึงต้องแจกแจงแบบปกติ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]