[
 {
  "input": "Let's kick things off with a quiz.",
  "translatedText": "Давайте начнем с викторины.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution.",
  "translatedText": "Предположим, я беру нормальное распределение со знакомой формой колоколообразной кривой и имею случайную величину x, полученную из этого распределения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable.",
  "translatedText": "Итак, то, на что вы сейчас смотрите, — это повторяющиеся выборки этой случайной величины.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values.",
  "translatedText": "И в качестве быстрого напоминания: способ интерпретации этой кривой, то, что на самом деле означает функция, заключается в том, что если вам нужна вероятность того, что ваша выборка попадает в заданный диапазон значений, скажите вероятность того, что она окажется между отрицательными единицей и двумя. , ну, это будет равняться площади под этой кривой в этом диапазоне значений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means.",
  "translatedText": "Вот что на самом деле означает кривая.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation.",
  "translatedText": "Я также возьму вторую случайную величину, также имеющую нормальное распределение, но, возможно, на этот раз с немного большим разбросом, с немного большим стандартным отклонением.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you.",
  "translatedText": "И вот вам викторина.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable.",
  "translatedText": "Если вы неоднократно выбираете обе эти переменные и на каждой итерации суммируете два результата, тогда эта сумма ведет себя как собственная случайная величина.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at?",
  "translatedText": "И вопрос в том, какое распределение описывает ту сумму, на которую вы смотрите?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape.",
  "translatedText": "Вы думаете об этом на мгновение, может быть, у вас есть предположение, может быть, вы думаете: я не знаю, это другое нормальное распределение или что-то другое, имеющее другую форму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough.",
  "translatedText": "Излишне говорить, что гадать недостаточно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do.",
  "translatedText": "Настоящая викторина заключается в том, чтобы суметь объяснить, почему вы получаете именно тот ответ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability.",
  "translatedText": "В этом случае, если у вас есть до мозга костей интуитивное понимание того, почему ответ именно такой, вы будете далеко на пути к пониманию того, почему нормальное распределение выполняет особую функцию, которую оно выполняет в теории вероятности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones.",
  "translatedText": "Однако если уменьшить масштаб, то на самом деле это гораздо более общий урок о том, как складывать две разные случайные величины независимо от их распределения, а не обязательно только нормально распределенных.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables.",
  "translatedText": "Это представляет собой специальную операцию, которую вы применяете к распределениям, лежащим в основе этих переменных.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution.",
  "translatedText": "У операции есть специальное название — свертка.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem.",
  "translatedText": "И главное, что мы с вами сделаем сегодня, — это мотивируем и создадим два различных способа визуализации того, как выглядит свертка для непрерывных функций, а затем поговорим о том, как каждая из этих двух разных визуализаций может быть полезна по-разному, с помощью специального сосредоточьтесь на центральной предельной теореме.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it.",
  "translatedText": "После того, как мы проведем общий урок, я хочу вернуться к вступительному тесту и предложить необычайно приятный способ ответа на него.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel.",
  "translatedText": "В качестве небольшого примечания: постоянные зрители среди вас, возможно, знают, что на этом канале уже есть видео о извилинах.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts.",
  "translatedText": "Но у этого случая была совершенно другая направленность: мы рассматривали только дискретный случай, и я хотел показать не только вероятность, но и способы, которыми она возникает в самых разных контекстах.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video.",
  "translatedText": "Я нахожусь в некоторой неловкой ситуации, потому что на самом деле нет смысла делать это обязательным условием для этого видео, но я думаю, что лучший способ разогреться сегодня - это рассмотреть по существу один из тех же примеров, которые использовались в этом видео.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead.",
  "translatedText": "Так что, если вы идете прямо оттуда, вы, вероятно, можете смело пропустить вперед.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in.",
  "translatedText": "В противном случае, давайте сразу погрузимся.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers.",
  "translatedText": "В этом вступительном вопросе каждая из случайных величин может принимать значение в непрерывном бесконечном диапазоне значений — всех возможных действительных числах.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice.",
  "translatedText": "Будет намного проще, если мы разогреемся в более дискретной и ограниченной обстановке, например, в броске пары взвешенных игральных костей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration.",
  "translatedText": "Здесь анимация, на которую вы смотрите, имитирует два взвешенных кубика, и вы, вероятно, можете сказать, что происходит, но просто чтобы объяснить это явно: синий кубик следует распределению, которое, кажется, смещено в сторону меньших значений, красный die имеет четкое распределение, и я неоднократно беру выборку из каждого из них и записываю сумму двух значений на каждой итерации.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely.",
  "translatedText": "Повторение подобных выборок много-много раз может дать вам эвристическое представление об окончательном распределении, но наша настоящая задача сегодня — точно вычислить это распределение.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities?",
  "translatedText": "Какова точная вероятность выпадения 2, 3, 4 или 5 для всех возможностей?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself.",
  "translatedText": "Это не слишком сложный вопрос, я бы посоветовал вам сделать паузу и попытаться разобраться в нем самостоятельно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation.",
  "translatedText": "Основная цель этого разминочного раздела — рассмотреть два различных способа визуализации лежащих в основе вычислений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid.",
  "translatedText": "Например, вы можете начать думать об этом так: существует 36 различных возможных результатов, и мы можем организовать эти результаты в небольшой сетке 6x6.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say?",
  "translatedText": "Теперь, если бы я спросил вас, какова вероятность увидеть любой из этих конкретных результатов, скажем, вероятность увидеть синюю 4 и красную 2, что бы вы ответили?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2.",
  "translatedText": "Мы могли бы сказать, что это должна быть вероятность синей 4, умноженная на вероятность красной 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other.",
  "translatedText": "И это было бы правильно, если предположить, что броски кубика независимы друг от друга.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent.",
  "translatedText": "Вы можете сказать, что это какой-то педантизм, конечно, броски кубиков должны быть независимы друг от друга, но на этом стоит подчеркнуть, потому что все, что мы собираемся делать дальше, будет двигаться вперед, от этого простого примера до самого конца. центральная предельная теорема предполагает, что случайные величины независимы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds.",
  "translatedText": "В реальном мире вам следует внимательно следить за тем, действительно ли это предположение верно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers.",
  "translatedText": "Теперь я собираюсь взять эту сетку всех возможных результатов и начать заполнять ее числами.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution.",
  "translatedText": "Возможно, мы поместим числа для всех вероятностей выпадения синего кубика внизу, все вероятности для красного кубика здесь, слева, а затем заполним сетку, где вероятность каждого результата внутри сетки выглядит как произведение одного числа из синего распределения и одного числа из красного распределения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table.",
  "translatedText": "Другой способ подумать об этом: по сути, мы строим таблицу умножения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot.",
  "translatedText": "Чтобы сделать все это немного более наглядным, мы могли бы изобразить каждую из этих вероятностей как высоту столбца над квадратом на таком трехмерном графике.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice.",
  "translatedText": "В каком-то смысле этот трехмерный график содержит все данные, которые нам нужно знать о броске игральных костей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums?",
  "translatedText": "Итак, вопрос в том, как нам извлечь то, что мы хотим знать, — вероятности для различных сумм?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal.",
  "translatedText": "Что ж, если вы выделите все результаты с определенной суммой, скажем, шестью, обратите внимание, как все они окажутся на определенной диагонали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven.",
  "translatedText": "То же самое, если я выделю все пары, сумма которых равна семи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal.",
  "translatedText": "Они сидят по другой диагонали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals.",
  "translatedText": "Итак, чтобы вычислить вероятность каждой возможной суммы, вам нужно сложить все элементы, находящиеся на одной из этих диагоналей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices.",
  "translatedText": "Подняв трехмерный график, мы можем лучше предвидеть, куда мы пойдем позже, сказав, что распределение возможных сумм выглядит как объединение всех высот этого графика вдоль одного из этих диагональных срезов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions.",
  "translatedText": "Это как если бы мы взяли это полное распределение для всех возможных исходов и как бы свернули его по одному из направлений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot.",
  "translatedText": "И, признаться, на данный момент я просто немного развлекаюсь с анимацией, а не так, как если бы вы работали с карандашом и бумагой, вы бы рисовали какой-то трехмерный сюжет.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun!",
  "translatedText": "Но это весело!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see.",
  "translatedText": "Когда вы сворачиваете его в этом направлении, вы действительно получаете то же распределение, которое, как я знал, и должно быть, но это все равно интересно видеть.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof.",
  "translatedText": "Кроме того, хотя все это может показаться немного игривым или даже излишне сложным, я могу обещать вам, что это интуитивное представление о диагональных срезах вернется к нам позже для действительно удовлетворительного доказательства.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it.",
  "translatedText": "Но остановившись еще немного на простом случае с игральными костями, вот второй способ, которым мы могли бы об этом подумать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left.",
  "translatedText": "Возьмите это нижнее распределение и переверните его по горизонтали, чтобы значения кубика увеличивались при движении справа налево.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask?",
  "translatedText": "Зачем это делать, спросите вы?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other.",
  "translatedText": "Итак, обратите внимание, какие из пар значений костей совпадают.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on.",
  "translatedText": "В его нынешнем положении у нас есть 1 и 6, 2 и 5, 3 и 4 и так далее.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7.",
  "translatedText": "Это все пары значений, сумма которых равна 7.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results.",
  "translatedText": "Итак, если вы хотите подумать о вероятности выпадения 7, способ сохранить это вычисление в уме — взять все пары вероятностей, которые совпадают друг с другом, перемножить эти пары, а затем сложить все результаты.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product.",
  "translatedText": "Некоторым из вас может понравиться думать об этом как о своего рода точечном продукте.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many.",
  "translatedText": "Но операция в целом — это не одно скалярное произведение, а множество.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5.",
  "translatedText": "Если бы мы сдвинули это нижнее распределение немного левее, то в данном случае это выглядело бы так, как будто выстроились в ряд значения кубиков: 1 и 4, 2 и 3, 3 и 2, 4 и 1, другими словами, все те, которые в сумме дают 5, ну, теперь, если мы возьмем скалярное произведение, мы умножим пары вероятностей, которые выстраиваются в линию, и сложим их вместе, что даст нам общую вероятность выпадения 5.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way.",
  "translatedText": "В общем, с этой точки зрения вычисление полного распределения суммы выглядит как перемещение нижнего распределения в разные позиции и попутное вычисление скалярного произведения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier.",
  "translatedText": "Это точно такая же операция, как и диагональные срезы, которые мы рассматривали ранее.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation.",
  "translatedText": "Это всего лишь два разных способа визуализировать одну и ту же основную операцию.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk.",
  "translatedText": "И как бы вы ни решили это визуализировать, эта операция, которая принимает два разных распределения и выдает новое, описывающее сумму соответствующих случайных величин, называется сверткой, и мы часто обозначаем ее этой звездочкой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function.",
  "translatedText": "На самом деле, вы хотите думать об этом, особенно когда мы рассматриваем непрерывный случай, — это думать об этом как о объединении двух разных функций и создании новой функции.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px.",
  "translatedText": "Например, в этом случае я могу дать функции для первого распределения имя px.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability.",
  "translatedText": "Это будет функция, которая принимает возможное значение кубика, например, 3, и выдает соответствующую вероятность.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum.",
  "translatedText": "Аналогично, пусть py будет функцией нашего второго распределения, а px плюс y будет функцией, описывающей распределение суммы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py.",
  "translatedText": "На жаргоне вы бы сказали, что px плюс y равно свертке между px и py.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like.",
  "translatedText": "И я хочу, чтобы вы сейчас подумали, как должна выглядеть формула этой операции.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols?",
  "translatedText": "Вы видели два разных способа визуализировать это, но как нам на самом деле записать это в символах?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4.",
  "translatedText": "Чтобы сориентироваться, возможно, будет полезно записать конкретный пример, например, случай с подключением 4, где вы суммируете все различные попарные произведения, соответствующие парам входных данных, которые в сумме дают 4.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look.",
  "translatedText": "И вообще, вот как это может выглядеть.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y.",
  "translatedText": "Эта новая функция принимает на вход возможную сумму ваших случайных величин, которую я назову s, и то, что она выводит, выглядит как сумма нескольких пар значений x и y.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6.",
  "translatedText": "За исключением того, что обычно это пишется не с помощью x и y, а вместо этого мы просто фокусируемся на одной из этих переменных, в данном случае x, позволяя ей варьироваться по всем возможным значениям, что здесь просто означает переход от 1 до 6.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s.",
  "translatedText": "И вместо того, чтобы писать y, вы пишете s минус x, по сути, какое бы число ни было, чтобы сумма была равна s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written.",
  "translatedText": "Теперь самые проницательные из вас могут заметить немного странную особенность формулы в том виде, в каком она написана.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined.",
  "translatedText": "Например, если вы подставляете заданное значение, например, s равно 4, и распаковываете эту сумму, позволяя x варьироваться от всех возможных значений от 1 до 6, то иногда соответствующее значение y падает ниже области определения, которую мы они определены явно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2.",
  "translatedText": "Например, вы подставляете 0, отрицательный 1 и отрицательный 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted.",
  "translatedText": "На самом деле это не так уж и важно, по сути, вы бы просто сказали, что все эти значения равны 0, поэтому все эти последующие члены не учитываются.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense.",
  "translatedText": "И это должно иметь смысл.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1?",
  "translatedText": "Какова вероятность того, что на красном кубике выпадет отрицательная единица?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0.",
  "translatedText": "Ну это 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome.",
  "translatedText": "Это невозможный результат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers.",
  "translatedText": "В качестве следующего шага давайте обратим внимание на непрерывные распределения, где ваша случайная величина может принимать значения в любом месте бесконечного континуума, как и все возможные действительные числа.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives.",
  "translatedText": "Возможно, вы моделируете погоду и пытаетесь предсказать температуру завтра в полдень, или делаете финансовые прогнозы, или, может быть, вы моделируете типичное время ожидания до прибытия автобуса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity.",
  "translatedText": "Есть множество вещей, в которых вам нужно обеспечить непрерывность.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density.",
  "translatedText": "На всех графиках, которые мы рисуем, значение x по-прежнему представляет собой возможное число, которое может принимать случайная величина, но интерпретация оси y немного другая, потому что это больше не представляет вероятность, а то, что мы рисуем график, который называется плотностью вероятности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal.",
  "translatedText": "Мы уже говорили об этом раньше, так что вы знаете, в чем дело.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range.",
  "translatedText": "По сути, вероятность того, что выборка вашей переменной попадает в заданный диапазон, выглядит как площадь под кривой в этом диапазоне.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF.",
  "translatedText": "Функцию, описывающую эту кривую, обычно называют функцией плотности вероятности. Это достаточно распространенное словосочетание, поэтому ему часто дают просто сокращение PDF.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range.",
  "translatedText": "Поэтому правильный способ записать все это — сказать, что вероятность того, что ваша выборка попадает в заданный диапазон, выглядит как интеграл вашей PDF, функции плотности вероятности, в этом диапазоне.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case.",
  "translatedText": "Как правило, каждый раз, когда вы видите сумму в дискретном случае, вы должны использовать интеграл в непрерывном случае.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example.",
  "translatedText": "Итак, давайте подумаем, что это значит для нашего основного примера.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum.",
  "translatedText": "Допустим, у нас есть две разные случайные величины, но на этот раз каждая из них будет следовать непрерывному распределению, и мы хотим понять их сумму и новое распределение, которое описывает эту сумму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy.",
  "translatedText": "Вы, наверное, уже догадались, какой будет формула, просто по аналогии.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products.",
  "translatedText": "Помните, в формуле, которую мы только что записали, где p sub x — функция для первой переменной, а p sub y — функция для второй переменной, свертка между ними, то есть вещь, описывающая сумму этих переменных, сама по себе выглядит как сумма, в которой мы объединяем кучу попарных произведений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral.",
  "translatedText": "Выражение в непрерывном случае действительно выглядит на 100% аналогично, просто мы заменяем эту сумму интегралом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating.",
  "translatedText": "Иногда, когда студенты видят это определение свертки вне контекста, оно может показаться немного пугающим.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms.",
  "translatedText": "Надеюсь, аналогии достаточно, чтобы прояснить ситуацию, но непрерывная природа действительно придает ей другой оттенок, и стоит потратить пару минут, чтобы подумать, что это значит на ее собственных условиях.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying.",
  "translatedText": "Поэтому я собрал небольшую интерактивную демонстрацию, которая помогает раскрыть каждую часть выражения и понять, что оно на самом деле означает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables.",
  "translatedText": "Например, первый член в этом интеграле — это f от x, который представляет собой функцию плотности для первой из двух случайных величин.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything.",
  "translatedText": "В данном случае я выбираю для этого распределения клиновидную функцию, но это может быть что угодно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution.",
  "translatedText": "Точно так же g представляет функцию плотности для второй случайной величины, для которой я выбираю такое двойное кусковое распределение.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s.",
  "translatedText": "И точно так же, как ранее мы перебирали все возможные пары значений кубиков с заданной суммой, вы можете думать об этом интеграле так: он хочет перебирать все возможные пары значений x и y, которые ограничено заданной суммой, s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s.",
  "translatedText": "На самом деле у нас нет подходящих обозначений для того, чтобы сделать это симметрично, поэтому вместо этого способ, которым мы обычно это записываем, придает искусственное значение одной из переменных, в данном случае x, где мы позволяем этому значению x варьироваться по всем возможным действительным числам: отрицательная бесконечность до бесконечности, и то, что мы подставляем в функцию g, — это s минус x, по сути, что бы это ни было, чтобы убедиться, что эта сумма ограничена значением s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x.",
  "translatedText": "Итак, для демонстрации вместо непосредственного построения графика g я хочу построить график g от s минус x.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like?",
  "translatedText": "Вы можете спросить себя, как это выглядит?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally.",
  "translatedText": "Что ж, если вы подставите отрицательный x в качестве входных данных, это приведет к перевороту графика по горизонтали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative.",
  "translatedText": "А затем, если мы добавим этот параметр s, рассматриваемый как некую константу, это приведет к сдвигу графика влево или вправо, в зависимости от того, является ли s положительным или отрицательным.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit.",
  "translatedText": "В демо-версии s — это параметр, который я просто возьму и немного поменяю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs.",
  "translatedText": "Настоящее удовольствие доставляет графическое представление всего содержимого интеграла, произведения этих двух графиков.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph.",
  "translatedText": "Это аналогично списку парных продуктов, который мы видели ранее, но в данном случае вместо сложения всех этих парных продуктов мы хотим интегрировать их вместе, что можно интерпретировать как область под этим графиком продуктов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area.",
  "translatedText": "Когда я сдвигаю это значение s, форма графика продукта меняется, как и соответствующая область.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter.",
  "translatedText": "Имейте в виду, что для всех трех графиков слева входными данными являются x, а число s — это всего лишь параметр.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be.",
  "translatedText": "Но для окончательного графика справа, для самой результирующей свертки, это число s является входными данными для этой функции, а соответствующий выходной результат — это любая площадь нижнего левого графика, каким бы ни был интеграл между этой комбинацией f и g. оказывается.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half.",
  "translatedText": "Здесь может быть полезно, если мы приведем простой пример, скажем, где каждая из наших двух случайных величин следует равномерному распределению между значениями отрицательной половины и положительной половины.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else.",
  "translatedText": "Это выглядит так: каждая из наших функций плотности имеет форму цилиндра, где график равен 1 для всех входных данных между отрицательной половиной и положительной половиной, а везде он равен 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like?",
  "translatedText": "Вопрос, как всегда, в том, как должно выглядеть распределение суммы?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo.",
  "translatedText": "Что ж, позвольте мне показать вам, как это выглядит внутри нашей демо-версии.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation.",
  "translatedText": "В этом случае произведение между двумя графиками имеет очень простую интерпретацию.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else.",
  "translatedText": "Оно равно 1 везде, где графики перекрываются друг с другом, и 0 везде.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve.",
  "translatedText": "Итак, если я сдвину этот параметр достаточно далеко влево, чтобы наши верхние графики вообще не перекрывались, то график продукта везде будет равен 0, и это способ сказать, что это недостижимая сумма.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense.",
  "translatedText": "Это должно иметь смысл.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1.",
  "translatedText": "Каждая из двух переменных может быть меньше отрицательной половины, поэтому сумма никогда не может стать ниже отрицательной 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum.",
  "translatedText": "Когда я начинаю сдвигать s вправо и графики перекрываются друг с другом, площадь увеличивается линейно, пока графики полностью не перекроются и не достигнет максимума.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape.",
  "translatedText": "А затем после этой точки она снова начинает линейно уменьшаться, а это означает, что распределение суммы принимает форму клина.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice.",
  "translatedText": "И я полагаю, что это на самом деле кажется знакомым каждому, кто думал о паре игральных костей, то есть о невзвешенных игральных костях.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape.",
  "translatedText": "Там если сложить две разные равномерно распределенные переменные, то распределение суммы имеет определенную форму клина.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again.",
  "translatedText": "Вероятности увеличиваются до тех пор, пока не достигнут максимума 7, а затем снова уменьшаются.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables.",
  "translatedText": "Гораздо интереснее будет, если вместо суммы двух равномерно распределенных переменных я спрошу вас, как это будет выглядеть, если мы сложим три разные равномерно распределенные переменные.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two.",
  "translatedText": "Сначала вы можете сказать: «Я не знаю, нам нужен какой-то новый способ визуализировать объединение трех вещей вместо двух».",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function.",
  "translatedText": "Но на самом деле здесь вы можете подумать о сумме первых двух как об отдельной переменной, которая, как мы только что выяснили, соответствует этому распределению в форме клина, а затем выполнить свертку между ней и функцией цилиндра.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like.",
  "translatedText": "Запускаем демо-версию, вот как это будет выглядеть.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph.",
  "translatedText": "Опять же, что делает функцию цилиндра действительно хорошей, так это то, что умножение на нее приводит к отфильтровыванию значений из верхнего графика.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window.",
  "translatedText": "Продукт внизу выглядит точно так же, как копия верхнего графика, но ограничен определенным окном.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly.",
  "translatedText": "Опять же, когда я перемещаю это влево и вправо, и область становится больше и меньше, результат достигает максимума в середине, но сужается с обеих сторон, за исключением того, что на этот раз это происходит более плавно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph.",
  "translatedText": "Это похоже на то, как будто мы берем скользящее среднее верхнего левого графика.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph.",
  "translatedText": "На самом деле, это нечто большее, это буквально скользящее среднее верхнего левого графика.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further.",
  "translatedText": "Вы можете подумать, что стоит пойти еще дальше.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat.",
  "translatedText": "Мы начали с объединения двух функций цилиндра и получили этот клин, затем мы заменили первую функцию этим клином, а затем, когда мы взяли свертку, мы получили эту более гладкую форму, описывающую сумму трех различных однородных переменных, но мы могли бы просто повтори.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables.",
  "translatedText": "Замените это на верхнюю функцию, а затем сверните ее с плоской прямоугольной функцией, и какой бы результат мы ни увидели, он должен описывать сумму четырех равномерно распределенных случайных величин.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect.",
  "translatedText": "Любой из вас, кто смотрел видео о центральной предельной теореме, должен знать, чего ожидать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve.",
  "translatedText": "По мере того, как мы повторяем этот процесс снова и снова, форма все больше и больше становится похожей на колоколообразную кривую.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time.",
  "translatedText": "Или, если быть более точным, на каждой итерации мы должны масштабировать ось X, чтобы убедиться, что стандартное отклонение равно единице, потому что доминирующим эффектом этой повторяющейся свертки, своего рода повторяющегося процесса скользящего среднего, является выравнивание функции по время.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero.",
  "translatedText": "Таким образом, в пределе оно просто стремится к нулю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all?",
  "translatedText": "Но изменение масштаба — это способ сказать: да, да, я знаю, что оно становится более плоским, но какова реальная форма, лежащая в основе всего этого?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true.",
  "translatedText": "Утверждение центральной предельной теоремы, одного из самых крутых фактов из теории вероятности, заключается в том, что вы могли бы начать практически с любого распределения, и это все равно было бы верно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution.",
  "translatedText": "Когда вы повторяете подобные свертки, представляющие все большие и большие суммы данной случайной величины, тогда распределение, описывающее эту сумму, которое может поначалу сильно отличаться от нормального распределения, со временем все больше и больше сглаживается, пока не станет произвольным. близкое к нормальному распределению.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution.",
  "translatedText": "Это похоже на то, как если бы колоколообразная кривая — это, в некотором смысле, самое гладкое из возможных распределений, притягивающая фиксированная точка в пространстве всех возможных функций, когда мы применяем этот процесс многократного сглаживания посредством свертки.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions?",
  "translatedText": "Естественно, вы можете задаться вопросом, почему нормальное распределение?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one?",
  "translatedText": "Почему именно эта функция, а не какая-то другая?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions.",
  "translatedText": "Это очень хороший ответ, и я думаю, что самый интересный способ показать ответ — это в свете последней визуализации, которую мы покажем для извилин.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals?",
  "translatedText": "Помните, как в дискретном случае первая из двух наших визуализаций включала в себя формирование такого рода таблицы умножения, показывающую вероятности всех возможных исходов и суммирование по диагоналям?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case.",
  "translatedText": "Вы, наверное, уже догадались, но наш последний шаг — обобщить это на непрерывный случай.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful.",
  "translatedText": "И это красиво, но нужно быть немного осторожным.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier?",
  "translatedText": "Если использовать те же две функции, которые у нас были раньше, f от x и g от y, что в этом случае будет аналогом сетки возможных пар, которую мы рассматривали ранее?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind.",
  "translatedText": "Что ж, в этом случае каждая из переменных может принимать любое действительное число, поэтому мы хотим подумать обо всех возможных парах действительных чисел, и на ум приходит плоскость xy.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions.",
  "translatedText": "Каждая точка соответствует возможному результату при выборке из обоих распределений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent.",
  "translatedText": "Теперь вероятность любого из этих результатов, xy, или, скорее, плотность вероятности вокруг этой точки, будет выглядеть как f от x, умноженная на g от y, опять же, при условии, что они независимы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane.",
  "translatedText": "Поэтому естественным будет построить график этой функции f от x, умноженной на g от y, как функции двух переменных, что даст нечто похожее на поверхность над плоскостью xy.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph.",
  "translatedText": "Обратите внимание, что в этом примере, если мы посмотрим на него под одним углом и увидим изменение значений x, он будет иметь форму нашего первого графика, но если мы посмотрим на него под другим углом, подчеркнув изменение в направлении y, он будет иметь форму нашего первого графика. принимает форму нашего второго графика.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need.",
  "translatedText": "Этот трехмерный график кодирует всю необходимую нам информацию.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome.",
  "translatedText": "Он показывает все плотности вероятности для каждого возможного результата.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant.",
  "translatedText": "И если вы хотите ограничить свое представление только теми результатами, где x плюс y ограничено заданной суммой, это выглядит как ограничение нашего представления диагональным срезом, а именно срезом над линией x плюс y, равным некоторой константе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at.",
  "translatedText": "Все возможные плотности вероятности для результата, на который распространяется это ограничение, выглядят как срез под этим графиком, и по мере того, как мы меняем конкретную сумму, которую мы ограничиваем, она смещается вокруг того, какой конкретный диагональный срез мы рассматриваем.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface.",
  "translatedText": "Теперь вы можете предсказать, что способ объединения всех плотностей вероятности вдоль одного из этих срезов, способ их интеграции вместе можно интерпретировать как площадь под этой кривой, которая является срезом поверхности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct.",
  "translatedText": "И это почти правильно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution.",
  "translatedText": "Есть тонкая деталь, касающаяся коэффициента квадратного корня из двух, о котором нам нужно поговорить, но до постоянного коэффициента площади этих срезов дают нам значения свертки.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier.",
  "translatedText": "Фактически, все эти срезы, которые мы рассматриваем, в точности совпадают с графиком продуктов, который мы рассматривали ранее.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g.",
  "translatedText": "Здесь, чтобы подчеркнуть этот момент, позвольте мне расположить обе визуализации рядом и медленно уменьшить значение s, что слева означает, что мы смотрим на разные срезы, а справа означает, что мы повторное перемещение по модифицированному графику g.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice.",
  "translatedText": "Обратите внимание, что форма графика в правом нижнем углу (произведение функций) во всех точках выглядит точно так же, как форма диагонального среза.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense.",
  "translatedText": "И это должно иметь смысл.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing.",
  "translatedText": "Это два разных способа визуализировать одно и то же.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum.",
  "translatedText": "Когда мы выражаем это словами, это звучит как много, но мы рассматриваем все возможные произведения между выходными данными функций, соответствующих парам входных данных, имеющих заданную сумму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it.",
  "translatedText": "Опять же, это своего рода пустословие, но я думаю, вы понимаете, о чем я говорю, и теперь у нас есть два разных взгляда на это.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation.",
  "translatedText": "Визуализация диагональных срезов хороша тем, что она делает гораздо более ясным, что это симметричная операция.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f.",
  "translatedText": "Гораздо более очевидно, что f, свернутая с g, — это то же самое, что g, свернутая с f.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape.",
  "translatedText": "Технически диагональные ломтики не имеют одинаковой формы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2.",
  "translatedText": "На самом деле они были растянуты в квадратный корень из 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step.",
  "translatedText": "Основная причина в том, что если вы представляете, что делаете небольшой шаг по одной из этих линий, где x плюс y равняется константе, то изменение вашего значения x, здесь дельта x, не будет тем же самым, что и длина этого шага.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2.",
  "translatedText": "На самом деле этот шаг длиннее в квадратный корень из 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices.",
  "translatedText": "Я оставлю на экране заметку для энтузиастов исчисления среди вас, которые хотят остановиться и поразмышлять, но результат очень прост: результаты нашей свертки технически не совсем являются областями этих диагональных срезов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2.",
  "translatedText": "Нам нужно разделить эти площади на квадратный корень из 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful.",
  "translatedText": "Отступив на мгновение от всего этого, я просто думаю, что это так прекрасно.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables?",
  "translatedText": "Мы начали с такого простого вопроса, или, по крайней мере, с такого, казалось бы, простого вопроса: как сложить две случайные величины?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions.",
  "translatedText": "И в итоге мы получаем очень сложную операцию по объединению двух разных функций.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something?",
  "translatedText": "У нас есть как минимум два очень красивых способа понять это, но все же некоторые из вас могут поднять руки и сказать: красивые картинки — это хорошо, но помогают ли они на самом деле что-то вычислить?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables.",
  "translatedText": "Например, я до сих пор не ответил на вступительный вопрос о сложении двух нормально распределенных случайных величин.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here.",
  "translatedText": "Что ж, обычный подход к такого рода вопросам, если бы он возник в домашнем задании или что-то в этом роде, заключается в том, что вы подставили бы формулу нормального распределения в определение свертки, интеграла, который мы Я описывал здесь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat.",
  "translatedText": "И в этом случае визуализации на самом деле будут просто для того, чтобы прояснить, о чем говорит выражение, но они сидят на заднем сиденье.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself.",
  "translatedText": "В этом случае интеграл не является непомерно сложным, существуют аналитические методы, но на этом примере я хочу показать вам более интересный метод, в котором визуализация, особенно диагональные срезы, будет играть гораздо более важную роль в доказательство само собой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself.",
  "translatedText": "Я думаю, что многим из вас действительно понравится потратить время на то, чтобы предсказать, как это будет выглядеть для вас самих.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of.",
  "translatedText": "Подумайте, как будет выглядеть этот трехмерный график в случае двух нормальных распределений и какими его свойствами вы могли бы воспользоваться.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation.",
  "translatedText": "И наверняка проще всего начать со случая, когда оба распределения имеют одинаковое стандартное отклонение.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video.",
  "translatedText": "Если вам нужны подробности и посмотреть, как ответ вписывается в центральную предельную теорему, присоединяйтесь ко мне в следующем видео.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]