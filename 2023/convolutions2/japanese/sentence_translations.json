[
 {
  "input": "Let's kick things off with a quiz.",
  "translatedText": "まずはクイズから始めましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.62
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution.",
  "translatedText": "このよく知られた釣鐘曲線形状の正規分布をと り、その分布から抽出された確率変数 x があるとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.36,
  "end": 9.7
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable.",
  "translatedText": "つまり、今見ているのは、その確率変数の繰り返しサンプルです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.52,
  "end": 14.54
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values.",
  "translatedText": "簡単に思い出していただきたいのですが、この曲線を解釈する方法、つまり関数が実際に何 を意味するかというと、サンプルが特定の値の範囲内に収まる確率が必要な場合は、サン プルがマイナス 1 から 2 の間に収まる確率を言います。 そうですね、それはその 値の範囲におけるこの曲線の下の面積に等しくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 14.96,
  "end": 32.8
 },
 {
  "input": "That's what the curve actually means.",
  "translatedText": "それが曲線が実際に意味するものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.84,
  "end": 34.7
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation.",
  "translatedText": "また、2 番目の確率変数も取得します。 これも正規分布に従いますが、 今回はもう少し分散して、標準偏差が少し大きくなるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.26,
  "end": 42.98
 },
 {
  "input": "And here's the quiz for you.",
  "translatedText": "ここでクイズです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.28,
  "end": 44.44
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable.",
  "translatedText": "これらの変数の両方を繰り返しサンプリングし、各反復 で 2 つの結果を合計すると、その合計は独自の確率変数のように動作します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.6,
  "end": 53.42
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at?",
  "translatedText": "そして問題は、あなたが調べているその合計がどのような分布で表されているかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.96,
  "end": 58.88
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape.",
  "translatedText": "少し考えてみると、おそらく推測ができるでしょう。 おそらく、わかりませ んが、これは別の正規分布か、あるいは形状が異なる何かだと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 59.38,
  "end": 66.5
 },
 {
  "input": "Needless to say, guessing is not enough.",
  "translatedText": "言うまでもなく、推測するだけでは十分ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.2,
  "end": 69.12
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do.",
  "translatedText": "本当のクイズは、なぜそのような答えが得られるのかを説明できることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 69.56,
  "end": 74.26
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability.",
  "translatedText": "この場合、答えがなぜそうなるのかを骨の髄まで内臓レベルで理解していれば、正規分布が 確率において果たす特別な機能を果たす理由を理解するのに長い道のりとなるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.8,
  "end": 87.26
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones.",
  "translatedText": "ただし、ズームアウトすると、これは実際には、分布に関係なく 2 つの異なる確率変数を追加する方法について、必ずしも正規分布 のものだけではなく、より一般的なレッスンを目的としています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.86,
  "end": 98.36
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables.",
  "translatedText": "これは、それらの変数の基礎となる分布に適用する特別な操作に相当します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.1,
  "end": 104.44
 },
 {
  "input": "The operation has a special name, it's called a convolution.",
  "translatedText": "この操作には特別な名前があり、畳み込みと呼ばれます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.66,
  "end": 107.52
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem.",
  "translatedText": "そして、あなたと私が今日行う主な仕事は、連続関数の畳み込みがどのように見えるかを視覚化する ための 2 つの異なる方法を動機付けて構築し、これら 2 つの異なる視覚化がそれぞれ異なる 方法でどのように役立つかについて、特別な方法で話すことです。 中心極限定理に焦点を当てます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.52,
  "end": 124.1
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it.",
  "translatedText": "全体的なレッスンを行った後、冒頭のクイズに戻り、いつもと違って満足のいく答え方を提供したいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.88,
  "end": 131.66
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel.",
  "translatedText": "ちょっとした余談ですが、定期的に視聴している方は、このチャンネルに畳み込みに関するビデオがすでに存在していることをご存じかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.66,
  "end": 137.68
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts.",
  "translatedText": "しかし、それはかなり異なる焦点を持っていて、私たちは離散的なケースだけを扱っていました、 そして私は確率だけでなく、それがさまざまな状況でどのように現れるかを示したかったのです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.68,
  "end": 146.1
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video.",
  "translatedText": "それがこのビデオの前提条件になるのはあまり意味がないので、少し厄介な立場にいますが、今日のウォーミングア ップに最適な方法は、本質的にそのビデオで使用されているのと同じ例の 1 つを取り上げることだと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.78,
  "end": 157.54
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead.",
  "translatedText": "したがって、そこからまっすぐに来る場合は、おそらく安全にスキップして先に進むことができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 157.56,
  "end": 161.38
 },
 {
  "input": "Otherwise, let's dive right in.",
  "translatedText": "それ以外の場合は、すぐに始めましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.38,
  "end": 163.9
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers.",
  "translatedText": "この冒頭のクイズの質問では、各確率変数は、連続した無限の値の 範囲内の値 (すべての可能な実数) を取ることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.86,
  "end": 174.78
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice.",
  "translatedText": "加重サイコロを振るような、より離散的で有限な設定 でウォームアップすると、はるかに簡単になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.3,
  "end": 181.78
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration.",
  "translatedText": "ここで、あなたが見ているアニメーションは 2 つの重み付けされたサイコロをシミ ュレートしており、おそらく何が起こっているかがわかるでしょう。 しかし、明確に 説明すると、青いサイコロはより低い値に偏った分布に従っており、赤いサイコロは より低い値に偏っているように見えます。 die には明確な分布があるため、そ れぞれから繰り返しサンプリングし、反復ごとに 2 つの値の合計を記録します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.56,
  "end": 203.14
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely.",
  "translatedText": "このようなサンプルを何度も何度も繰り返すことで、最終的な分布をヒューリスティックに把握 できるようになりますが、今日の私たちの本当の仕事は、その分布を正確に計算することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.74,
  "end": 212.6
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities?",
  "translatedText": "すべての可能性に対して、2、または 3、または 4、または 5 が延々と続く正確な確率はどれくらいですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.6,
  "end": 219.36
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself.",
  "translatedText": "それほど難しい質問ではありません。 実際に、立ち止まって自分で解決してみることをお勧めします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 219.84,
  "end": 224.14
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation.",
  "translatedText": "このウォームアップ セクションの主な目標は、基礎となる計 算を視覚化する 2 つの異なる方法を説明することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.98,
  "end": 231.64
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid.",
  "translatedText": "たとえば、考え始める 1 つの方法は、36 の異なる可能な結果があり 、それらの結果を小さな 6x6 グリッドに整理できるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 232.92,
  "end": 242.36
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say?",
  "translatedText": "さて、これらの特定の結果のいずれかが表示される確率、たとえば青 4 と赤 2 が表示される確率はどれくらいかと尋ねたら、あなたは何と答えますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.04,
  "end": 252.5
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2.",
  "translatedText": "青 4 の確率と赤 2 の確率を乗じたものであるべきだと言えるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 253.04,
  "end": 258.24
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other.",
  "translatedText": "そして、サイコロの目が互いに独立していると仮定すると、それは正しいでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.78,
  "end": 263.08
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent.",
  "translatedText": "それはちょっと衒学的だと言われるかもしれません。 もちろん、サイコロの目 は互いに独立している必要がありますが、この単純な例から最終的な結果に至 るまで、ここから先に行うことはすべて重要であるため、これは強調する価値 のある点です。 中心極限定理では、確率変数が独立していると仮定します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.54,
  "end": 278.08
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds.",
  "translatedText": "現実の世界では、この仮定が実際に当てはまるかどうかを注意深く監視する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.66,
  "end": 282.72
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers.",
  "translatedText": "ここで私がやろうとしていることは、考えられるすべての結果のこの グリッドを取得し、それにいくつかの数字を入力し始めることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.64,
  "end": 288.82
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution.",
  "translatedText": "おそらく、青いサイコロのすべての確率の数字を一番 下に置き、赤いサイコロのすべての確率を左側に置き 、次にグリッドを埋めて、グリッド内のすべての結果 の確率を記入します。 青の分布の 1 つの数値と赤 の分布の 1 つの数値の間の積のように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.18,
  "end": 306.18
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table.",
  "translatedText": "別の考え方としては、基本的には九九を構築しているということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.68,
  "end": 310.34
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot.",
  "translatedText": "これらすべてをもう少し視覚的に理解するには、これらの確率のそれぞれを、この種の 3 次元プロットの正方形の上のバーの高さとしてプロットすることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.7,
  "end": 319.68
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice.",
  "translatedText": "ある意味、この 3 次元プロットには、サイコロを振る際 に知っておく必要があるすべてのデータが含まれています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.12,
  "end": 325.6
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums?",
  "translatedText": "そこで問題は、知りたいこと、つまりさまざまな合 計の確率をどのように抽出するかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.74,
  "end": 332.16
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal.",
  "translatedText": "さて、特定の合計、たとえば 6 の合計ですべての結果を強調表示すると、そ れらすべてが特定の対角線上にどのように配置されるかに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.66,
  "end": 341.26
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven.",
  "translatedText": "合計が 7 であるすべてのペアを強調表示しても、同じ処理になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.74,
  "end": 344.72
 },
 {
  "input": "They sit along a different diagonal.",
  "translatedText": "彼らは異なる対角線に沿って座っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.1,
  "end": 346.76
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals.",
  "translatedText": "したがって、考えられるそれぞれの合計の確率を計算するには、これらの 対角線の 1 つにあるすべてのエントリを合計することになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.24,
  "end": 354.8
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices.",
  "translatedText": "3D プロットを表示すると、考えられる合計の分布が、これらの対角スライス の 1 つに沿ってこのプロットの高さのすべてを組み合わせたもののように 見えると言うことで、後でこれをどこに進めるかをより適切に予測できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.28,
  "end": 370.4
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions.",
  "translatedText": "これは、考えられるすべての結果についてこの完全な分布を取得し 、それを 1 つの方向に沿って折りたたんだようなものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 372.08,
  "end": 378.98
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot.",
  "translatedText": "そして確かに、現時点ではアニメーションを少し楽しんでい るだけで、紙と鉛筆を使ってこれを作成する場合のように 3 次元のプロットを描くようなものではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.96,
  "end": 388.9
 },
 {
  "input": "But it's fun!",
  "translatedText": "でも楽しいですよ！ この方向に折りたたむと、実際には同じ分布が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.32,
  "end": 390.14
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see.",
  "translatedText": "そうすべ きであることはわかっていましたが、それでも見るのは楽しいです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.14,
  "end": 396.38
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof.",
  "translatedText": "また、これらすべてが少しふざけているように見えた り、不必要に複雑に見えたりするかもしれませんが、 斜めのスライスに関するこの直感は、後で本当に満足 のいく証明として戻ってくることを約束できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 396.96,
  "end": 408.54
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it.",
  "translatedText": "しかし、もう少し単純なサイコロのケースに焦点を当てて、こ れについて考えることができる 2 番目の方法を示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.86,
  "end": 414.28
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left.",
  "translatedText": "その一番下の分布を水平方向に反転して、右から左に 行くにつれてサイコロの値が増加するようにします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.78,
  "end": 421.34
 },
 {
  "input": "Why do this, you might ask?",
  "translatedText": "なぜこんなことをするのかと疑問に思うかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 422.48,
  "end": 424.04
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other.",
  "translatedText": "さて、サイコロの値のどのペアが互いに並んでいるかに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.6,
  "end": 428.48
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on.",
  "translatedText": "現在の位置では、1 と 6、2 と 5、3 と 4 などがあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.86,
  "end": 434.72
 },
 {
  "input": "It is all of the pairs of values that add up to 7.",
  "translatedText": "合計すると 7 になるすべての値のペアです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.9,
  "end": 438.1
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results.",
  "translatedText": "したがって、7 が出る確率について考えたい場合、 その計算を頭の中に留めておく方法は、互いに並んで いる確率のペアをすべて取得し、それらのペアを掛け 合わせてから、すべてを合計することです。 結果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 438.1,
  "end": 452.2
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product.",
  "translatedText": "これを一種の内積と考えたい人もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.94,
  "end": 455.64
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many.",
  "translatedText": "しかし、全体としての演算は 1 つのドット積ではなく、多数のドット積になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.18,
  "end": 459.92
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5.",
  "translatedText": "この一番下の分布をもう少し左にスライドすると、この場合、並ん でいるサイコロの値は 1 と 4、2 と 3、3 と 2、4 と 1、つまりすべてのサイコロの値のように見えます。 合計す ると 5 になるものです。 ドット積を計算すると、並んだ確率の ペアを掛け合わせて合計し、5 が出る合計確率が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.36,
  "end": 482.54
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way.",
  "translatedText": "一般に、この観点から見ると、合計の完全な分布を計算する ことは、その最下位の分布をさまざまな異なる位置にスライ ドさせ、途中でこのドット積を計算するように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 483.2,
  "end": 493.28
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier.",
  "translatedText": "これは、先ほど説明した斜めのスライスとまったく同じ操作です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.6,
  "end": 499.82
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation.",
  "translatedText": "これらは、同じ基礎となる操作を視覚化するための 2 つの異なる方法にすぎません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.38,
  "end": 503.8
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk.",
  "translatedText": "どのような視覚化を選択しても、2 つの異なる分布を取り込み、 関連する確率変数の合計を表す新しい分布を吐き出すこの操作は 畳み込みと呼ばれ、多くの場合このアスタリスクで示されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.24,
  "end": 520.88
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function.",
  "translatedText": "実際には、特に継続的なケースを設定する場合、2 つの異なる関数を 組み合わせて新しい関数を吐き出すと考えるのが望ましいでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.88,
  "end": 529.24
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px.",
  "translatedText": "たとえば、この場合、最初のディストリビューションの関数に px という名前を付けるとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.32,
  "end": 535.48
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability.",
  "translatedText": "これは、3 などのサイコロの可能な値を受け取 り、対応する確率を吐き出す関数になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.82,
  "end": 542.98
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum.",
  "translatedText": "同様に、2 番目の分布の関数を py とし、合計の 分布を記述する関数を px と y に加えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.44,
  "end": 553.06
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py.",
  "translatedText": "専門用語では、px + y は px と py の間の畳み込みに等しいと言えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.96,
  "end": 561.08
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like.",
  "translatedText": "ここで考えていただきたいのは、この演算の式がどのようになるべきかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 566.14
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols?",
  "translatedText": "これを視覚化する 2 つの異なる方法を見てきましたが、実際にそれを記号で書き出すにはどうすればよいでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.44,
  "end": 570.46
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4.",
  "translatedText": "状況を把握するには、4 を接続する場合など、合計が 4 になる入力のペアに対応するさまざまなペアごとの積をすべて 合計する、具体的な例を書き留めておくと役立つでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.96,
  "end": 581.66
 },
 {
  "input": "And more generally, here's how it might look.",
  "translatedText": "より一般的には、次のようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.46,
  "end": 584.54
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y.",
  "translatedText": "この新しい関数は、ランダム変数 (s と呼ぶことにします) の可能な合計を入力とし て受け取り、出力されるものは、x と y の一連の値のペアの合計のように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.98,
  "end": 595.82
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6.",
  "translatedText": "ただし、通常の書き方では x と y を使用するのではなく、変数の 1 つ (この場合は x) に焦点を当て、取り得るすべての値の範 囲を指定します。 これは単に 1 から 6 までを意味します。 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.82,
  "end": 608.36
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s.",
  "translatedText": "そして、y を書く代わりに、s から x を引いたものを書きま す。 基本的に、合計が s になるように数値を何でもいいのです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.84,
  "end": 615.72
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written.",
  "translatedText": "ここで、賢明な方は、この式が書かれていると、少し奇妙な癖があることに気づくかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 617.3,
  "end": 621.68
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined.",
  "translatedText": "たとえば、s が 4 に等しいなどの特定の値を入力し、この合計を展開し て、x の範囲を 1 から 6 までのすべての可能な値に設定すると、対 応する y の値が定義域を下回る場合があります。 明示的に定義しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.22,
  "end": 636.96
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2.",
  "translatedText": "たとえば、0、負の 1、および負の 2 を接続します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 637.4,
  "end": 640.54
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted.",
  "translatedText": "これは実際にはそれほど大したことではありません。 本質的には、これらの値が すべて 0 であるため、後の項はすべてカウントされないと言うだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.2,
  "end": 648.16
 },
 {
  "input": "And that should kind of make sense.",
  "translatedText": "そしてそれはある程度意味があるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.64,
  "end": 649.74
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1?",
  "translatedText": "赤いサイコロを振ってマイナス 1 になる確率はいくらですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 649.9,
  "end": 653.28
 },
 {
  "input": "Well, it's 0.",
  "translatedText": "まあ、0ですよ。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 653.82,
  "end": 654.82
 },
 {
  "input": "That is an impossible outcome.",
  "translatedText": "それはありえない結果だ。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.86,
  "end": 656.4
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers.",
  "translatedText": "次のステップとして、連続分布に注目してみましょう。 連続分布では、ランダム変数は、すべての実数と同 様に、無限連続体の任意の値を取ることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.04,
  "end": 671.04
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives.",
  "translatedText": "おそらく、気象モデリングを行って明日の正午の気温を予測しようとしているか もしれません。 あるいは、財務予測を行っているかもしれません。 あるいは、 バスが到着するまでの一般的な待ち時間をモデル化しているかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.52,
  "end": 680.62
 },
 {
  "input": "There are all sorts of things where you need to handle continuity.",
  "translatedText": "継続性を処理する必要があるあらゆる種類のものがあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 680.84,
  "end": 683.36
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density.",
  "translatedText": "私たちが描いたすべてのグラフにおいて、x の値は依然として 確率変数が取り得る数値を表していますが、y 軸の解釈は少 し異なります。 これは、もはや確率を表すのではなく、代わり に、私たちがグラフにしているのは、いわゆる確率密度です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.9,
  "end": 699.84
 },
 {
  "input": "This is something we've talked about before, so you know the deal.",
  "translatedText": "これについては以前にもお話ししたので、ご存知のとおりです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.32,
  "end": 703.02
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range.",
  "translatedText": "基本的に、変数のサンプルが特定の範囲内に収まる確率 は、その範囲内の曲線の下の面積のようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.44,
  "end": 711.16
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF.",
  "translatedText": "この曲線を記述する関数は一般に確率密度関数と呼ばれ、よく使われる言葉 であるため、単に PDF という略語が与えられることもよくあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.62,
  "end": 719.66
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range.",
  "translatedText": "したがって、これらすべてを書き留める適切な方法は、サンプル が特定の範囲内に収まる確率が、その範囲内での PDF の積 分 (確率密度関数) に似ている、ということになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 720.38,
  "end": 732.02
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case.",
  "translatedText": "一般的な経験則として、離散の場合に合計を表示す るときは常に、連続の場合には積分を使用します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.88,
  "end": 739.6
 },
 {
  "input": "So let's think about what that means for our main example.",
  "translatedText": "それでは、それが私たちの主な例で何を意味するのか考えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.42,
  "end": 743.3
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum.",
  "translatedText": "2 つの異なる確率変数があるとします。 ただし、今回はそれぞれが連続分布 に従い、それらの合計とその合計を表す新しい分布を理解したいとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.86,
  "end": 754.1
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy.",
  "translatedText": "おそらく、その式がどのようなものになるかは、すでに類推して推測できるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.42,
  "end": 758.92
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products.",
  "translatedText": "先ほど書き留めた式で、p sub x が最初の変数の関数、p sub y が 2 番目の 変数の関数であることを思い出してください。 それらの間の畳み込み、これらの変数の合計を記述 するもの自体は次のようになります。 多数のペアごとの積を組み合わせた合計のようなものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 759.4,
  "end": 775.84
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral.",
  "translatedText": "連続の場合の式は実際には 100% 類似していま す。 単にその合計を積分に置き換えているだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.48,
  "end": 782.98
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating.",
  "translatedText": "学生が文脈を無視してこの畳み込みの定義を見ると、少し怖く感じることがあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.76,
  "end": 788.62
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms.",
  "translatedText": "このたとえ話だけで十分に理解できると思いますが、継続的な性質が実際に異なる味わいを 与えているため、それ自体が何を意味するのかを数分かけて考えてみる価値はあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 789.1,
  "end": 798.34
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying.",
  "translatedText": "そこで、式の各部分とそれが実際に何を言っているのかを解き明かすのに役立つ、小さなインタラクティブなデモを作成しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.34,
  "end": 805.2
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables.",
  "translatedText": "たとえば、この積分の最初の項は x の f で、こ れは 2 つの確率変数の最初の密度関数を表します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 805.8,
  "end": 813.56
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything.",
  "translatedText": "この場合、その分布に対してこの種のくさび形関数を選択していますが、何でも構いません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.94,
  "end": 818.82
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution.",
  "translatedText": "同様に、 g は 2 番目の確率変数の密度関数 を表し、この種の二重塊状分布を選択しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.66,
  "end": 826.82
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s.",
  "translatedText": "そして、先ほど与えられた合計を持つサイコロの値の可能なすべてのペアを調べた のと同じように、この積分について考えたいのは、次の値 x と y の可能な すべてのペアを反復処理することです。 与えられた合計 s に制約されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.82,
  "end": 842.8
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s.",
  "translatedText": "これを対称的に行うための優れた表記法は実際にはありません。 そのため、代わり に一般的にそれを書き留める方法は、変数の 1 つ (この場合は x) を人 為的に強調し、その値 x の範囲をすべての可能な実数にします。 負の無限大か ら無限大まで、関数 g に代入するのは s から x を引いたもので、本質 的にはこの合計が s に制限されるようにするために必要なものは何でもです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.34,
  "end": 867.86
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x.",
  "translatedText": "したがって、デモでは、g を直接グラフ化する代わりに、s から x を引いたものをグラフ化したいと考えています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.38,
  "end": 874.6
 },
 {
  "input": "You might ask yourself, what does that look like?",
  "translatedText": "それはどのようなものですか? と自問するかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 875.1,
  "end": 877.14
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally.",
  "translatedText": "そうですね、負の x を入力として接続すると、グラフが水平方向に反転する効果があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.68,
  "end": 883.9
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative.",
  "translatedText": "そして、このパラメータ s を投入すると、ある種の定数として扱われ、 s が正か負かに応じてグラフを左または右にシフトする効果があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 884.76,
  "end": 894.1
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit.",
  "translatedText": "デモでは、 s はパラメータであり、これを取得して少し移動します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.64,
  "end": 898.32
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs.",
  "translatedText": "本当の楽しみは、これら 2 つのグラフ間の積である積分の内容全体をグラフ化することから生まれます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 898.7,
  "end": 904.24
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph.",
  "translatedText": "これは、前に見たペアごとの商品のリストに似ていますが、この場合、こ れらのペアごとの商品をすべて合計するのではなく、それらを統合する必 要があります。 これは、この商品グラフの下の領域として解釈されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.78,
  "end": 917.48
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area.",
  "translatedText": "s のこの値を中心にシフトすると、積グラフの形状が変化し、対応する領域も変化します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 918.2,
  "end": 924.26
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter.",
  "translatedText": "左側の 3 つのグラフすべてで、入力は x であり、数値 s は単なるパラメーターであることに注意してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 926.92,
  "end": 933.3
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be.",
  "translatedText": "しかし、右側の最後のグラフ、つまり結果として得られる畳み込み自体の場合、この数値 s はその関数への入力であり、対応する出力は、左下のグラフの面積が何であれ、この f と g の組み合わせの積分が何であれ、対応する出力になります。 であることが判明。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 933.3,
  "end": 949.82
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half.",
  "translatedText": "ここで、2 つの確率変数のそれぞれが値の負の 1/2 と正の 1/2 の間の一様分布に従うという簡単な例を行うと役立つかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.28,
  "end": 963.76
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else.",
  "translatedText": "つまり、密度関数はそれぞれこの種のトップハット形状になっており、グラフは負の 1/2 と正 の 1/2 の間のすべての入力で 1 に等しく、それ以外の場合は 0 に等しくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 964.46,
  "end": 976.46
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like?",
  "translatedText": "いつものように、問題は、合計の分布がどのようになるべきかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 977.04,
  "end": 981.44
 },
 {
  "input": "Well, let me show you how it looks inside our demo.",
  "translatedText": "それでは、デモ内でどのように見えるかを説明しましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 981.96,
  "end": 984.4
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation.",
  "translatedText": "この場合、2 つのグラフ間の積は非常に簡単に解釈できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.22,
  "end": 989.18
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else.",
  "translatedText": "グラフが互いに重なっている場合は 1 ですが、それ以外の場合は 0 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.18,
  "end": 994.06
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve.",
  "translatedText": "したがって、このパラメータを左に十分にスライドさせて、上のグラフがまったく重ならないようにす ると、積のグラフはどこでも 0 になり、これは、この合計が達成不可能であることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 994.56,
  "end": 1006.54
 },
 {
  "input": "That should make sense.",
  "translatedText": "それは理にかなっているはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1007.22,
  "end": 1008.06
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1.",
  "translatedText": "2 つの変数はそれぞれマイナスの 2 分の 1 までしか取り得ないため、合計がマイナス 1 を下回ることはありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1008.2,
  "end": 1014.34
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum.",
  "translatedText": "s を右にスライドし始め、グラフが互いに重なり合うと、グラフ が完全に重なり最大値に達するまで、面積は直線的に増加します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1014.34,
  "end": 1025.3
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape.",
  "translatedText": "そして、その点を過ぎると、再び直線的に減少し始めます。 これは、合計の分布がこの種のくさび形になることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1026.2,
  "end": 1033.88
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice.",
  "translatedText": "そして、これは、サイコロのペア、つまり重みのないサイコロについて考えたことがある人にとっては、実際にいくらか馴染みがあるものだと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.34,
  "end": 1041.3
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape.",
  "translatedText": "そこで、2 つの異なる一様分布変数を合計すると、合計の分布は特定のくさび形になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.86,
  "end": 1049.72
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again.",
  "translatedText": "確率は 7 で最大になるまで増加し、その後再び減少します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1050.04,
  "end": 1054.54
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables.",
  "translatedText": "これがさらに面白くなるのは、2 つの均一に分布した変数の合計を求める代わりに 、3 つの異なる均一に分布した変数を合計するとどうなるかを尋ねる場合です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1056.26,
  "end": 1066.8
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two.",
  "translatedText": "最初は、「わからない、2 つではなく 3 つのものを組み合わせて視覚化する新しい方法が必要だ」と思うかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1066.8,
  "end": 1072.58
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function.",
  "translatedText": "しかし、実際にここでできることは、最初の 2 つの合計を独自の変数として考え、それがこのくさ び形分布に従っていることを理解し、それとトップハット関数の間の畳み込みを計算することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.42,
  "end": 1084.6
 },
 {
  "input": "Pulling up the demo, here's what that would look like.",
  "translatedText": "デモを起動すると、次のようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.1,
  "end": 1087.36
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph.",
  "translatedText": "繰り返しになりますが、トップ ハット関数が非常に優れているのは、トップ ハット関数を乗算すると、上のグラフから値をフィルタリングするような効果があることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1087.84,
  "end": 1096.16
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window.",
  "translatedText": "下の積は上のグラフのコピーと同じように見えますが、特定のウィンドウに限定されています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.16,
  "end": 1101.76
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly.",
  "translatedText": "もう一度、これを左右にスライドさせ、領域が大きくなったり小さくなったりすると、結果は中央で 最大になりますが、どちらかの側に向かって先細になりますが、今回はよりスムーズに動作します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.62,
  "end": 1112.02
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph.",
  "translatedText": "左上のグラフの移動平均を取っているようなものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.6,
  "end": 1116.12
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph.",
  "translatedText": "実際には、これは単なる一種ではなく、文字通り左上のグラフの移動平均です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1116.94,
  "end": 1121.84
 },
 {
  "input": "One thing you might think to do is take this even further.",
  "translatedText": "これをさらに推し進めることも考えられるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.4,
  "end": 1125.0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat.",
  "translatedText": "私たちが始めた方法は、2 つのトップハット関数を組み合わせ てこのウェッジを取得し、次に最初の関数をそのウェッジで置き 換え、畳み込みを行うと、3 つの異なる一様変数の合計を表す このより滑らかな形状が得られました。 ただ繰り返すだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.5,
  "end": 1140.5
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables.",
  "translatedText": "それを一番上の関数と交換し、それを平坦な長方形関数と畳み込みます。 どのよう な結果が得られても、4 つの均一に分布した確率変数の合計を表すはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1141.22,
  "end": 1152.38
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect.",
  "translatedText": "中心極限定理に関するビデオを見た人なら、何を期待するかわかるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1153.66,
  "end": 1157.32
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve.",
  "translatedText": "この作業を何度も繰り返すうちに、形はどんどんベルカーブに近づいていきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.82,
  "end": 1162.4
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time.",
  "translatedText": "より正確に言えば、反復ごとに x 軸を再スケールして、標準偏差が 1 になるよう にする必要があります。 これは、この反復された畳み込み (反復移動平均プロセスの 一種) の主な効果は、関数を全体にわたって平坦化することであるためです。 時間。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1162.86,
  "end": 1177.26
 },
 {
  "input": "So in the limit it just flattens out towards zero.",
  "translatedText": "したがって、制限内ではゼロに向かって平坦になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1177.62,
  "end": 1179.84
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all?",
  "translatedText": "しかし、再スケーリングとは、「はい、はい、平坦になるのはわかって いますが、その根底にある実際の形状は何ですか? 」ということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.24,
  "end": 1186.04
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true.",
  "translatedText": "中心極限定理のステートメントは、確率から得られる最も優れた事実の 1 つであり、 基本的にどのような分布でも開始でき、これは依然として真実であるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1188.06,
  "end": 1197.94
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution.",
  "translatedText": "このように畳み込みを繰り返して、与えられた確率変数の合計がますます大きくなるようにす ると、その合計を表す分布は、最初は正規分布とは大きく異なって見えるかもしれませんが、 時間の経過とともに徐々に滑らかになり、最終的には任意の値になります。 正規分布に近い。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1198.54,
  "end": 1217.42
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution.",
  "translatedText": "畳み込みを通じて平滑化を繰り返すこのプロセスを適用するとき、 釣鐘曲線は、大まかに言えば、可能な限り滑らかな分布、可能なす べての関数の空間における魅力的な固定点であるかのようです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1218.08,
  "end": 1230.88
 },
 {
  "input": "Naturally you might wonder, why normal distributions?",
  "translatedText": "当然、なぜ正規分布なのか疑問に思うかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1235.4,
  "end": 1238.52
 },
 {
  "input": "Why this function and not some other one?",
  "translatedText": "なぜ他の機能ではなくこの機能があるのでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1238.98,
  "end": 1240.92
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions.",
  "translatedText": "これは非常に良い答えです。 その答えを示す最も楽しい方法は、畳み 込みについて示す最後の視覚化に照らして行うことだと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1241.68,
  "end": 1249.16
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals?",
  "translatedText": "離散的なケースで、2 つの視覚化のうちの最初に、この種の乗算 表を作成し、考えられるすべての結果の確率を表示し、対角線に 沿って加算することがどのように含まれたかを覚えていますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1250.28,
  "end": 1261.42
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case.",
  "translatedText": "おそらくもうお気づきかと思いますが、最後のステップはこれを連続ケースに一般化することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1262.96,
  "end": 1267.62
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful.",
  "translatedText": "そしてそれは美しいですが、少し注意する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1268.56,
  "end": 1270.86
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier?",
  "translatedText": "以前と同じ 2 つの関数、x の f と y の g を取り出した場合、 この場合、前に調べた可能なペアのグリッドに類似したものは何でしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1271.98,
  "end": 1281.46
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind.",
  "translatedText": "この場合、各変数は任意の実数を取ることができるため、考えられるすべて の実数のペアについて考えたいと思います。 xy 平面が思い浮かびます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1282.48,
  "end": 1291.5
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions.",
  "translatedText": "すべての点は、両方の分布からサンプリングした場合に考えられる結果に対応します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1292.64,
  "end": 1297.04
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent.",
  "translatedText": "ここで、これらの結果のいずれか 1 つの確率 xy、またはむし ろその点の周りの確率密度は、この 2 つが独立していると仮定 すると、x の f と y の g を掛けたものになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1298.14,
  "end": 1309.58
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane.",
  "translatedText": "したがって、当然のこととして、この関数 (x の f と y の g の積) を 2 変数関数としてグラフ化すると、xy 平面上の表面のように見えるものが得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1309.58,
  "end": 1319.92
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph.",
  "translatedText": "この例では、ある角度から見ると、つまり x 値が変化していることがわか り、最初のグラフの形状になりますが、別の角度から見ると、y 方向の変化 が強調されることに注目してください。 2 番目のグラフの形になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1320.56,
  "end": 1333.84
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need.",
  "translatedText": "この 3 次元グラフには、必要な情報がすべてエンコードされています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1334.22,
  "end": 1337.8
 },
 {
  "input": "It shows all the probability densities for every possible outcome.",
  "translatedText": "これは、考えられるすべての結果のすべての確率密度を示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1337.8,
  "end": 1341.12
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant.",
  "translatedText": "そして、x と y が特定の合計になるように制約される結果のみにビュ ーを制限したい場合は、ビューを対角のスライス、具体的には x と y が何らかの定数に等しい線上のスライスに限定することになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.9,
  "end": 1355.4
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at.",
  "translatedText": "この制約の対象となる結果の可能な確率密度はすべて、このグラフの 下のスライスのように見えます。 制約している特定の合計を中心に変 更すると、注目している特定の対角スライスの周囲にシフトします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1355.98,
  "end": 1370.48
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface.",
  "translatedText": "ここで、これらのスライスの 1 つに沿ってすべての確率密度を結合する方法、 つまりそれらを統合する方法は、この曲線の下の領域 (サーフェスのスライス) として解釈できると予想されるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1373.94,
  "end": 1387.14
 },
 {
  "input": "And that is almost correct.",
  "translatedText": "そしてそれはほぼ正しいです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1387.94,
  "end": 1389.42
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution.",
  "translatedText": "2 の平方根の係数に関しては説明する必要がある微妙な詳細がありますが、 一定の係数までは、これらのスライスの面積から畳み込みの値が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1389.74,
  "end": 1400.68
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier.",
  "translatedText": "実際、私たちが見ているこれらのスライスはすべて 、前に見ていた製品グラフとまったく同じです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1401.5,
  "end": 1408.24
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g.",
  "translatedText": "ここで、この点を強調するために、両方のビジュアライゼーションを並べて表示します。 s の値をゆっくりと減らしていきます。 これは、左側では異なるスライスを見て いることを意味し、右側では、 g の修正されたグラフを中心に再シフトします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1409.44,
  "end": 1424.3
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice.",
  "translatedText": "右下のグラフの形状 (関数間の積) が、あらゆる点で斜めのス ライスの形状とまったく同じに見えることに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1425.52,
  "end": 1434.76
 },
 {
  "input": "And this should make sense.",
  "translatedText": "そして、これには意味があるはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1438.44,
  "end": 1439.7
 },
 {
  "input": "They are two distinct ways to visualize the same thing.",
  "translatedText": "これらは、同じものを視覚化する 2 つの異なる方法です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.84,
  "end": 1442.6
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum.",
  "translatedText": "言葉にすると大変そうに聞こえますが、私たちが注目しているのは、指定 された合計を持つ入力のペアに対応する関数の出力間の可能なすべての 積です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1443.04,
  "end": 1453.94
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it.",
  "translatedText": "繰り返しになりますが、ちょっと口の悪い話ですが、私の言いたいこと がおわかりいただけると思います。 これには 2 つの異なる見方があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1454.76,
  "end": 1460.45
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation.",
  "translatedText": "斜めスライスの視覚化の優れた点は、それが対称的な操作であるこ とがより明確になることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1471.0,
  "end": 1477.1
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f.",
  "translatedText": "f と g を畳み込んだものは、g と f を畳み 込んだものと同じであることがはるかに明白です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1477.1,
  "end": 1483.02
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape.",
  "translatedText": "技術的には、斜めのスライスはまったく同じ形 状ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1484.08,
  "end": 1487.58
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2.",
  "translatedText": "実際には 2 の平方根の係数だけ引き伸ばされています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1487.9,
  "end": 1491.16
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step.",
  "translatedText": "基本的な理由は、x と y が定数に等しいこれらの線の 1 つに沿って小さなステッ プを踏むことを想像すると、x の値の変化、ここではデルタ x はそのステップの長 さと同じではないからです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.88,
  "end": 1505.2
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2.",
  "translatedText": "このステップは実際には 2 の平方根の係数だけ長くなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1505.2,
  "end": 1508.88
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices.",
  "translatedText": "立ち止まって熟考したい微積分愛好家のために画面にメモを残しておきますが、結 論は非常に単純で、畳み込みの出力は技術的にはこれらの対角スライスの領域には まったく及ばないということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1509.66,
  "end": 1521.1
 },
 {
  "input": "We have to divide those areas by a square root of 2.",
  "translatedText": "これらの面積を 2 の平方根で割る必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1521.6,
  "end": 1524.34
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful.",
  "translatedText": "これらすべてから少し離れて、私はこれがとても美しいと思うだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1526.14,
  "end": 1529.54
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables?",
  "translatedText": "私たちは、2 つの確率変数をどのように足し合わせるのかという、非常に単純な質問、少なく とも一見単純な質問から始めました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1530.04,
  "end": 1536.68
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions.",
  "translatedText": "そして最終的に行き着くのは、2 つの異なる関数を組み合 わせるための非常に複雑な操作です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1537.3,
  "end": 1541.84
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something?",
  "translatedText": "それを理解するための非常にきれいな方法が少なくとも 2 つありま す。 しかし、それでも、皆さんの中には手を挙げて、きれいな写真はすべて良いものですが、実際に何かを計算するのに 役立つのでしょうか、と言う人もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1542.68,
  "end": 1552.56
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables.",
  "translatedText": "たとえば、2 つの正規分布確率変数の 追加に関する最初のクイズの質問にはまだ答えていません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1553.04,
  "end": 1559.28
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here.",
  "translatedText": "そうですね、 この種の質問に取り組む通常の方法は、宿題などで出題され た場合、正規分布の公式を畳み込みの定義に組み込むこと です。 ここで説明してきました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1559.88,
  "end": 1573.96
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat.",
  "translatedText": "その場合、ビジュアライゼーションは実際には 表現が何を言っているかを明確にするために存在するだけですが、後部座席に座っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1575.08,
  "end": 1581.42
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself.",
  "translatedText": "この場 合、積分は法外に難しいものではなく、分析手法もありますが、この例では、 視覚化、具体的には斜めのスライスがより中心的な役割を果たす、より楽し い手法を紹介したいと思います。 証明そのもの。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1581.92,
  "end": 1597.04
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself.",
  "translatedText": "皆さんの多くは、これが自分にとっ てどのようになるかを予測するのを実際に楽しんでいると思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1597.9,
  "end": 1602.16
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of.",
  "translatedText": "この 3D グラフが 2 つの正規分布の場合にどのようになるか、また、それがどのような特性を持っていてそ れを利用できるかを考えてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.68,
  "end": 1611.58
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation.",
  "translatedText": "そして、両方の分布が同じ標準偏差を持つ 場合から始めると、確かに最も簡単です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1612.48,
  "end": 1617.78
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video.",
  "translatedText": "詳細が必要な場合や、答えが中心極 限定理にどのように適合するかを確認したい場合は、次のビデオに参加してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1619.08,
  "end": 1624.98
 }
]