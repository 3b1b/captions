[
 {
  "input": "Let's kick things off with a quiz.",
  "translatedText": "让我们从一个测验开始吧。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Suppose I take a normal distribution with this familiar bell curve shape, and I have a random variable x that's drawn from that distribution.",
  "translatedText": "假设我采用具有这种熟悉的钟形曲线形状的 正态分布，并且我有一个从该分布中提取的随机变量 x。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So what you're looking at right now are repeated samples of that random variable.",
  "translatedText": "因此，您现在看到的是该随机变量的重复样本。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And as a quick reminder, the way that you interpret this curve, what the function actually means, is that if you want the probability that your sample falls within a given range of values, say the probability that it ends up between negative one and two, well, that would equal the area under this curve in that range of values.",
  "translatedText": "快速提醒一下，您解释这条曲线的方式，该函数的实际 含义是，如果您想要样本落在给定值范围内的概率，例 如它最终位于负 1 和 2 之间的概率好吧，这将 等于该值范围内该曲线下的面积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That's what the curve actually means.",
  "translatedText": "这就是曲线的实际含义。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "I'll also pull up a second random variable, also following a normal distribution, but maybe this time a little more spread out, a slightly bigger standard deviation.",
  "translatedText": "我还将提取第二个随机变量，也遵循正态分布 ，但这次可能更分散一些，标准差稍大一些。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And here's the quiz for you.",
  "translatedText": "这是给你的测验。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "If you repeatedly sample both of these variables, and in each iteration you add up the two results, well, then that sum behaves like its own random variable.",
  "translatedText": "如果您重复对这两个变量进行采样，并且在每次 迭代中将两个结果相加，那么该总和的行为就像它自己的随机变量一样。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And the question is what distribution describes that sum that you're looking at?",
  "translatedText": "问题是什么分布描述了您正在查看的总和？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You think about it for a little moment, maybe you have a guess, maybe you think, I don't know, it's another normal distribution, or something with a different shape.",
  "translatedText": "你想一下，也许你有一个猜测，也许你认为，我不知道 ，这是另一种正态分布，或者具有不同形状的东西。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Needless to say, guessing is not enough.",
  "translatedText": "不用说，光靠猜测是不够的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The real quiz is to be able to explain why you get the answer that you do.",
  "translatedText": "真正的测验是能够解释为什么你会得到这样的答案。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In this case, if you have that deep to your bones visceral level of understanding for why the answer is what it is, you'll be a long way towards understanding why normal distributions serve the special function that they do in probability.",
  "translatedText": "在这种情况下，如果您对答案为何如此有深入的理解，那么您将在理 解为什么正态分布发挥其概率中的特殊功能方面还有很长的路要走。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Zooming out though, this is actually meant to be a much more general lesson about how you add two different random variables regardless of their distribution, not necessarily just the normally distributed ones.",
  "translatedText": "不过，缩小范围来看，这实际上是一个更一般的课 程，讲述如何添加两个不同的随机变量，无论它们 的分布如何，而不一定只是正态分布的随机变量。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This amounts to a special operation that you apply to the distributions underlying those variables.",
  "translatedText": "这相当于对这些变量的分布应用一种特殊的操作。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The operation has a special name, it's called a convolution.",
  "translatedText": "该操作有一个特殊的名称，称为卷积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And the primary thing you and I will do today is motivate and build up two distinct ways to visualize what a convolution looks like for continuous functions, and then to talk about how these two different visualizations can each be helpful in different ways, with a special focus on the central limit theorem.",
  "translatedText": "你和我今天要做的主要事情是激发并建立两种不同的方法来可视化 连续函数的卷积是什么样子，然后讨论这两种不同的可视化如何以 不同的方式提供帮助，并具有特殊的意义重点关注中心极限定理。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "After we do the general lesson, I want to return to the opening quiz and offer an unusually satisfying way to answer it.",
  "translatedText": "在我们完成一般课程后，我想回到开场测验并提供一种异常令人满意的回答方式。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As a quick side note, regular viewers among you might know there's already a video about convolutions on this channel.",
  "translatedText": "作为一个简短的旁注，你们中的普通观众可能知道这个频道上已经有一个关于卷积的视频。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But that one had a pretty different focus, we were only doing the discrete case, and I wanted to show not just probability but the ways that it comes up in a wide variety of contexts.",
  "translatedText": "但那个有一个完全不同的焦点，我们只做离散的情况，我 不仅想展示概率，还想展示它在各种背景下出现的方式。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "I'm in a slightly awkward spot because it doesn't really make sense for that to be a prerequisite to this video, but I think the best way to warm up today is to cover essentially one of the same examples used in that video.",
  "translatedText": "我处于一个有点尴尬的境地，因为将其作为该视频的先决条件并没有真正意义 ，但我认为今天最好的热身方式是基本上介绍该视频中使用的相同示例之一。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So if you are coming straight from that one, you can probably skip safely ahead.",
  "translatedText": "因此，如果您直接从那一个开始，您可能可以安全地跳过前面。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Otherwise, let's dive right in.",
  "translatedText": "否则，让我们直接开始吧。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For this opening quiz question, each of the random variables can take on a value in a continuous infinite range of values, all possible real numbers.",
  "translatedText": "对于这个开放测验问题，每个随机变量都可以 取连续无限范围内的值，所有可能的实数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It'll be a lot easier if we warm up in a setting that's more discrete and finite, like maybe rolling a pair of weighted dice.",
  "translatedText": "如果我们在一个更加离散和有限的环境中热身 ，比如掷一对加权骰子，事情会容易得多。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Here, the animation you're looking at is simulating two weighted dice, and you can probably tell what's going on, but just to spell it out explicitly, the blue die is following a distribution that seems to be biased towards lower values, the red die has a distinct distribution, and I'm repeatedly sampling from each one and recording the sum of the two values at each iteration.",
  "translatedText": "在这里，您看到的动画正在模拟两个加权骰子，您 可能可以知道发生了什么，但为了明确说明，蓝 色骰子遵循的分布似乎偏向于较低值，红色骰子 die 具有不同的分布，我会重复对每个分布 进行采样，并在每次迭代时记录两个值的总和。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Repeating samples like this many, many different times can give you a heuristic sense of the final distribution, but our real task today is to compute that distribution precisely.",
  "translatedText": "多次重复这样的样本可以让您对最终分布有一个启发式 的感觉，但我们今天的真正任务是精确计算该分布。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "What is the precise probability of rolling a 2, or a 3, or a 4, or a 5, on and on for all possibilities?",
  "translatedText": "对于所有可能性，掷出 2、3、4、5 的精确概率是多少？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's not too hard a question, I'd actually encourage you to pause and try working it out for yourself.",
  "translatedText": "这并不是一个太难的问题，实际上我鼓励您停下来尝试自己解决这个问题。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The main goal in this warm-up section will be to walk through two distinct ways that you could visualize the underlying computation.",
  "translatedText": "本热身部分的主要目标是介绍两种 不同的方式来可视化底层计算。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, one way you could start to think about it is that there are 36 distinct possible outcomes, and we could organize those outcomes in a little 6x6 grid.",
  "translatedText": "例如，您可以开始思考的一种方式是，有 36 种不同的可能 结果，我们可以将这些结果组织在一个 6x6 的小网格中。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Now if I was to ask you, what is the probability of seeing any one of these specific outcomes, say the probability of seeing a blue 4 and a red 2, what would you say?",
  "translatedText": "现在，如果我问你，看到这些特定结果中任何一个的概率是多 少，比如看到蓝色 4 和红色 2 的概率，你会怎么说？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "We might say it should be the probability of that blue 4 multiplied by the probability of the red 2.",
  "translatedText": "我们可能会说它应该是蓝色 4 的概率乘以红色 2 的概率。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And that would be correct assuming that the die rolls are independent from each other.",
  "translatedText": "假设骰子彼此独立，这是正确的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You might say that's kind of pedantic, of course the die rolls should be independent from each other, but it's a point worth emphasizing because everything that we're going to do from here moving forward, from this simple example all the way up to the central limit theorem, assumes that the random variables are independent.",
  "translatedText": "你可能会说这有点迂腐，当然，骰子应该彼此 独立，但这是值得强调的一点，因为我们从 这里开始要做的一切，从这个简单的例子一直 到中心极限定理，假设随机变量是独立的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In the real world, you want to keep a sharp eye out for if this assumption actually holds.",
  "translatedText": "在现实世界中，您需要密切关注这个假设是否确实成立。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Now what I'm going to do is take this grid of all possible outcomes, but start filling it in with some numbers.",
  "translatedText": "现在我要做的就是获取所有可能结果 的网格，但开始用一些数字填充它。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom, all the probabilities for the red die over here on the left, and then we will fill in the grid where the probability for every outcome inside the grid looks like some product between one number from the blue distribution and one number from the red distribution.",
  "translatedText": "也许我们会将蓝色骰子的所有概率的数字放 在底部，将红色骰子的所有概率放在左侧， 然后我们将填写网格，其中网格内每个结果 的概率看起来像是蓝色分布中的一个数字和 红色分布中的一个数字之间的某种乘积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Another way to think about it is we're basically constructing a multiplication table.",
  "translatedText": "另一种思考方式是我们基本上是在构建一个乘法表。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "To be a little more visual about all of this, we could plot each one of these probabilities as the height of a bar above the square in this sort of three-dimensional plot.",
  "translatedText": "为了更直观地了解所有这些，我们可以将这些概率中的 每一个绘制为这种三维图中正方形上方的条形的高度。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In some sense, this three-dimensional plot carries all the data that we would need to know about rolling a pair of dice.",
  "translatedText": "从某种意义上说，这个三维图包含了我 们需要了解的有关掷骰子的所有数据。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And so the question is how do we extract the thing that we want to know, the probabilities for various different sums?",
  "translatedText": "所以问题是我们如何提取我们想知道 的东西，即各种不同总和的概率？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, if you highlight all of the outcomes with a certain sum, say a sum of six, notice how all of those end up on a certain diagonal.",
  "translatedText": "好吧，如果你突出显示具有一定总和的所有结果，比如六 的总和，请注意所有这些结果如何在某个对角线上结束。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Same deal if I highlight all the pairs where the sum is seven.",
  "translatedText": "如果我突出显示所有总和为 7 的对，则同样的交易。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "They sit along a different diagonal.",
  "translatedText": "他们坐在不同的对角线上。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So to compute the probability of each possible sum, what you do is you add together all of the entries that sit on one of these diagonals.",
  "translatedText": "因此，要计算每个可能总和的概率，您要做的 是将位于这些对角线上的所有条目加在一起。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Pulling up the 3D plot, we can better foreshadow where we'll go with this later by saying that the distribution of possible sums looks like combining all of the heights of this plot along one of these diagonal slices.",
  "translatedText": "拉出 3D 图，我们可以通过说可能总和的分布 看起来像是沿着这些对角线切片之一组合该图的 所有高度来更好地预示我们稍后将讨论的内容。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's as if we've taken this full distribution for all possible outcomes and we've kind of collapsed it along one of the directions.",
  "translatedText": "就好像我们已经对所有可能的结果采取了完整的分 布，并且我们已经沿着其中一个方向将其折叠了。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And admittedly, I'm just having a bit of fun with the animations at this point, not like if you were working this out with pencil and paper, you would be drawing some three-dimensional plot.",
  "translatedText": "不可否认，此时我只是对动画感到一 点乐趣，不像你用铅笔和纸来解决这 个问题，你会绘制一些三维情节。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But it's fun!",
  "translatedText": "但这很有趣！",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "When you collapse it on this direction, you actually do get the same distribution, which I knew you should, but it's still fun to see.",
  "translatedText": "当你沿着这个方向折叠它时，你实际上得到了相同的 分布，我知道你应该这样做，但看到它仍然很有趣。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Also, even though all of this might just seem a little bit playful or even unnecessarily complicated, I can promise you this intuition about diagonal slices will come back to us later for a genuinely satisfying proof.",
  "translatedText": "另外，尽管所有这些可能看起来有点有趣 ，甚至不必要地复杂，但我可以向你保证 ，这种关于对角线切片的直觉稍后会返回 给我们，以提供真正令人满意的证明。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But staying focused on the simple dice case a little bit longer, here's the second way that we could think about it.",
  "translatedText": "但是，稍微长时间关注简单的骰子情况 ，这是我们可以考虑的第二种方式。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Take that bottom distribution and flip it around horizontally, so that the die values increase as you go from right to left.",
  "translatedText": "采取底部分布并将其水平翻转，以便 骰子值随着从右到左的移动而增加。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Why do this, you might ask?",
  "translatedText": "您可能会问，为什么要这样做？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, notice now which of the pairs of dice values line up with each other.",
  "translatedText": "好吧，现在请注意哪对骰子的值彼此对齐。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on.",
  "translatedText": "由于它现在的位置，我们有 1 和 6、2 和 5、3 和 4，等等。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It is all of the pairs of values that add up to 7.",
  "translatedText": "它是所有加起来为 7 的值对。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So if you want to think about the probability of rolling a 7, a way to hold that computation in your mind is to take all of the pairs of probabilities that line up with each other, multiply together those pairs, and then add up all of the results.",
  "translatedText": "因此，如果您想考虑掷出 7 的概率 ，将计算牢记在心的一种方法是采用 所有彼此对齐的概率对，将这些概率对 相乘，然后将所有概率相加。 结果。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Some of you might like to think of this as a kind of dot product.",
  "translatedText": "你们中的一些人可能喜欢将其视为一种点积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But the operation as a whole is not just one dot product, but many.",
  "translatedText": "但整个操作不仅仅是一个点积，而是多个点积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "If we were to slide that bottom distribution a little more to the left, so in this case it looks like the die values which line up are 1 and 4, 2 and 3, 3 and 2, 4 and 1, in other words all the ones that add up to a 5, well now if we take the dot product, we multiply the pairs of probabilities that line up and add them together, that would give us the total probability of rolling a 5.",
  "translatedText": "如果我们将该底部分布向左滑动一点，那么在这种情况下， 看起来排列的骰子值是 1 和 4、2 和 3、3 和 2、4 和 1，换句话说，所有那些加起来为 5 的，现在如果我们采用点积，我们将排列成行的概率对相 乘并将它们加在一起，这将得到滚动到 5 的总概率。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In general, from this point of view, computing the full distribution for the sum looks like sliding that bottom distribution into various different positions and computing this dot product along the way.",
  "translatedText": "一般来说，从这个角度来看，计算总和的 完整分布看起来就像将底部分布滑动到 各种不同的位置并一路计算这个点积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It is precisely the same operation as the diagonal slices we were looking at earlier.",
  "translatedText": "这与我们之前看到的对角线切片的操作完全相同。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "They're just two different ways to visualize the same underlying operation.",
  "translatedText": "它们只是可视化同一底层操作的两种不同方式。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And however you choose to visualize it, this operation that takes in two different distributions and spits out a new one, describing the sum of the relevant random variables, is called a convolution, and we often denote it with this asterisk.",
  "translatedText": "无论您选择如何可视化它，这种接受两个不同分 布并输出一个新分布（描述相关随机变量之和） 的操作称为卷积，我们经常用这个星号表示它。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Really the way you want to think about it, especially as we set up for the continuous case, is to think of it as combining two different functions and spitting out a new function.",
  "translatedText": "实际上，您想要考虑它的方式，尤其是当我们为连续情况设 置时，是将其视为组合两个不同的函数并生成一个新函数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, in this case, maybe I give the function for the first distribution the name px.",
  "translatedText": "例如，在本例中，也许我将第一个分布的函数命名为 px。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This would be a function that takes in a possible value for the die, like a 3, and it spits out the corresponding probability.",
  "translatedText": "这将是一个函数，它接收骰子的可能值 （例如 3），并输出相应的概率。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Similarly, let's let py be the function for our second distribution, and px plus y be the function describing the distribution for the sum.",
  "translatedText": "同样，让 py 为第二个分布的函数， px 加 y 为描述总和分布的函数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In the lingo, what you would say is that px plus y is equal to a convolution between px and py.",
  "translatedText": "用行话来说，你会说 px 加 y 等于 px 和 py 之间的卷积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And what I want you to think about now is what the formula for this operation should look like.",
  "translatedText": "我现在想让你思考的是这个运算的公式应该是什么样的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You've seen two different ways to visualize it, but how do we actually write it down in symbols?",
  "translatedText": "您已经看到了两种不同的可视化方式，但我们如何实际用符号将其写下来呢？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "To get your bearings, maybe it's helpful to write down a specific example, like the case of plugging in a 4, where you add up over all the different pairwise products corresponding to pairs of inputs that add up to a 4.",
  "translatedText": "为了了解情况，写下一个具体示例可能会有所帮助 ，例如插入 4 的情况，其中将与加起来为 4 的输入对相对应的所有不同成对乘积相加。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And more generally, here's how it might look.",
  "translatedText": "更一般地说，它可能是这样的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This new function takes as an input a possible sum for your random variables, which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values for x and y.",
  "translatedText": "这个新函数将随机变量的可能总和（我将其称为 s）作为 输入，其输出看起来像是一组 x 和 y 值对的总和。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Except the usual way it's written is not to write with x and y, but instead we just focus on one of those variables, in this case x, letting it range over all of its possible values, which here just means going from 1 to 6.",
  "translatedText": "除了通常的编写方式不是用 x 和 y 来编写之外 ，而是我们只关注其中一个变量，在本例中为 x，让 它涵盖所有可能的值，这意味着从 1 到 6。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And instead of writing y, you write s minus x, essentially whatever the number has to be to make sure the sum is s.",
  "translatedText": "并且不写 y，而是写 s 减去 x，本质 上无论数字必须是什么，以确保总和为 s。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Now the astute among you might notice a slightly weird quirk with the formula as it's written.",
  "translatedText": "现在，精明的人可能会注意到所写的公式有点奇怪。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, if you plug in a given value like s equals 4, and you unpack this sum, letting x range over all the possible values going from 1 up to 6, then sometimes that corresponding y value drops below the domain of what we've explicitly defined.",
  "translatedText": "例如，如果您插入一个给定值，如 s 等于 4，然后解 压该总和，让 x 涵盖从 1 到 6 的所有可能值 ，那么有时相应的 y 值会低于我们的域已明确定义。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, you plug in 0 and negative 1 and negative 2.",
  "translatedText": "例如，插入 0 和负 1 和负 2。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's not actually that big a deal, essentially you would just say all of these values are 0, so all these later terms don't get counted.",
  "translatedText": "实际上这没什么大不了的，本质上你只是说所有这些值 都是 0，所以所有这些后面的项都不会被计算在内。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And that should kind of make sense.",
  "translatedText": "这应该是有道理的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "What is the probability that the red die rolls to become a negative 1?",
  "translatedText": "红色骰子掷出成为负 1 的概率是多少？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, it's 0.",
  "translatedText": "嗯，是 0。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That is an impossible outcome.",
  "translatedText": "这是不可能的结果。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As a next step, let's turn our attention towards continuous distributions, where your random variable can take on values anywhere in an infinite continuum, like all possible real numbers.",
  "translatedText": "下一步，让我们将注意力转向连续分布， 其中随机变量可以在无限连续体中的任何 位置取值，就像所有可能的实数一样。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Maybe you're doing weather modeling and trying to predict the temperature tomorrow at noon, or you're doing some financial projections, or maybe you're modeling the typical wait times before a bus arrives.",
  "translatedText": "也许您正在做天气建模并尝试预测明天中午的温度 ，或者您正在做一些财务预测，或者您可能正在 对公共汽车到达之前的典型等待时间进行建模。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "There are all sorts of things where you need to handle continuity.",
  "translatedText": "有各种各样的事情需要处理连续性。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In all the graphs that we draw, the x value still represents a possible number that the random variable can take on, but the interpretation of the y-axis is a little bit different, because no longer does this represent probability, instead the thing that we're graphing is what's called probability density.",
  "translatedText": "在我们绘制的所有图表中，x值仍然代表随机 变量可以呈现的可能数字，但是y轴的解释 有点不同，因为这不再代表概率，而是代表概 率。 我们绘制的图表就是所谓的概率密度。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This is something we've talked about before, so you know the deal.",
  "translatedText": "这是我们之前讨论过的事情，所以你知道这是怎么回事。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Essentially, the probability that a sample of your variable falls within a given range looks like the area under the curve in that range.",
  "translatedText": "本质上，变量样本落在给定范围内的概 率看起来就像该范围内曲线下的面积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The function describing this curve is commonly called a probability density function, a common enough phrase that it's frequently just given the abbreviation PDF.",
  "translatedText": "描述这条曲线的函数通常称为概率密度函数，这是 一个非常常见的短语，通常只给出缩写 PDF。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And so the proper way to write all of this down would be to say that the probability that your sample falls within a given range looks like the integral of your PDF, the probability density function, in that range.",
  "translatedText": "因此，写下所有这些的正确方法是，样本 落在给定范围内的概率看起来就像 PD F（概率密度函数）在该范围内的积分。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As a general rule of thumb, any time that you see a sum in the discrete case, you would use an integral in the continuous case.",
  "translatedText": "作为一般经验法则，每当您在离散情况下看 到总和时，您都会在连续情况下使用积分。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So let's think about what that means for our main example.",
  "translatedText": "那么让我们考虑一下这对于我们的主要示例意味着什么。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Let's say we have two different random variables, but this time each one will follow a continuous distribution, and we want to understand their sum and the new distribution that describes that sum.",
  "translatedText": "假设我们有两个不同的随机变量，但这一次每个变量都遵循连 续分布，我们想要了解它们的总和以及描述该总和的新分布。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You can probably already guess what the formula will be just by analogy.",
  "translatedText": "通过类比你可能已经猜到公式是什么了。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Remember, in the formula that we just wrote down, where p sub x is the function for the first variable and p sub y is the function for the second variable, the convolution between them, the thing describing a sum of those variables, itself looks like a sum where we combine a bunch of pairwise products.",
  "translatedText": "请记住，在我们刚刚写下的公式中，其中 p sub x 是第一个变量的 函数，p sub y 是第二个变量的函数，它们之间的卷积，即描述这 些变量之和的东西，本身看起来就像我们将一堆成对产品组合起来的总和。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The expression in the continuous case really does look 100% analogous, it's just that we swap out that sum for an integral.",
  "translatedText": "连续情况下的表达式确实看起来 100% 相似，只是我们将该总和替换为积分。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Sometimes when students see this definition of a convolution out of context, it can seem a little intimidating.",
  "translatedText": "有时，当学生断章取义地看到卷积的定义时，它可能看起来有点令人生畏。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Hopefully the analogy is enough to make it clear, but the continuous nature really does give it a different flavor, and it's worth taking a couple minutes to think through what it means on its own terms.",
  "translatedText": "希望这个类比足以让大家清楚，但连续性确实赋予了 它不同的风味，值得花几分钟来思考它本身的含义。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And so I put together a little interactive demo that helps unpack each part of the expression and what it's really saying.",
  "translatedText": "因此，我制作了一个小型交互式演示，有助于解开表达式的每个部分及其真正含义。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, the first term in this integral is f of x, which represents the density function for the first of the two random variables.",
  "translatedText": "例如，该积分中的第一项是 x 的 f， 它表示两个随机变量中第一个的密度函数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And in this case I'm choosing this sort of wedge-shaped function for that distribution, but it could be anything.",
  "translatedText": "在本例中，我为该分布选择这种楔形函数，但它可以是任何东西。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Similarly, g represents the density function for the second random variable, for which I'm choosing this sort of double lump-shaped distribution.",
  "translatedText": "类似地，g 表示第二个随机变量的密度 函数，我为此选择了这种双块状分布。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And in the same way that earlier we went over all possible pairs of dice values with a given sum, the way you want to think about this integral is that what it wants to do is iterate over all possible pairs of values x and y that are constrained to a given sum, s.",
  "translatedText": "就像之前我们遍历给定总和的所有可能的骰子值对一样 ，您想要考虑这个积分的方式是它想要做的是迭代所 有可能的值 x 和 y 对限制为给定总和 s。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "We don't really have great notation for doing that symmetrically, so instead the way we commonly write it down gives this artificial emphasis to one of the variables, in this case x, where we let that value x range over all possible real numbers, negative infinity up to infinity, and the thing we plug into the function g is s minus x, essentially whatever it has to be to make sure that this sum is constrained to be s.",
  "translatedText": "我们实际上没有很好的符号来对称地做到这一点，所以我们 通常写下来的方式人为地强调了其中一个变量，在本例中为 x，我们让该值 x 范围涵盖所有可能的实数，负无穷 大到无穷大，我们插入函数 g 的值是 s 减去 x， 本质上无论它必须是什么，以确保这个总和被限制为 s。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So for the demo, instead of graphing g directly, I want to graph g of s minus x.",
  "translatedText": "因此，对于演示，我不想直接绘制 g 的图形，而是绘制 s 减去 x 的 g 的图形。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You might ask yourself, what does that look like?",
  "translatedText": "你可能会问自己，那是什么样子的？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, if you plug in negative x as the input, that has the effect of flipping around the graph horizontally.",
  "translatedText": "好吧，如果您插入负 x 作为输入，则会产生水平翻转图形的效果。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And then if we throw in this parameter s, treated as some kind of constant, that has the effect of shifting the graph either left or right, depending on if s is positive or negative.",
  "translatedText": "然后，如果我们输入这个参数 s（被视为某种常量），就会产生 向左或向右移动图形的效果，具体取决于 s 是正数还是负数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In the demo, s is a parameter that I'll just grab and shift around a little bit.",
  "translatedText": "在演示中，s 是一个参数，我将抓取它并稍微移动一下。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The real fun comes from graphing the entire contents of the integral, the product between these two graphs.",
  "translatedText": "真正的乐趣来自于绘制积分的全部内容，即这两个图之间的乘积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This is analogous to the list of pairwise products that we saw earlier, but in this case, instead of adding up all of those pairwise products, we want to integrate them together, which you would interpret as the area underneath this product graph.",
  "translatedText": "这类似于我们之前看到的成对乘积列表，但在这种情况 下，我们不是将所有这些成对乘积相加，而是将它们集 成在一起，您可以将其解释为该乘积图下方的区域。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As I shift around this value of s, the shape of that product graph changes, and so does the corresponding area.",
  "translatedText": "当我围绕 s 的值移动时，产品图的形状会发生变化，相应的区域也会发生变化。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Keep in mind, for all three graphs on the left, the input is x, and the number s is just a parameter.",
  "translatedText": "请记住，对于左侧的所有三个图，输入都是 x，数字 s 只是一个参数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But for the final graph on the right, for the resulting convolution itself, this number s is the input to that function, and the corresponding output is whatever the area of the lower left graph is, whatever the integral between this combination of f and g turns out to be.",
  "translatedText": "但对于右边的最终图，对于最终的卷积本身，这个数字 s 是该函数的输入，相应的输出是无论左下图的面积是多 少，无论 f 和 g 的组合之间的积分如何原来是。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Here, it might be helpful if we do a simple example, say where each of our two random variables follows a uniform distribution between the values negative one-half and positive one-half.",
  "translatedText": "在这里，如果我们做一个简单的例子，假设我们的两个随机变量中的每一个 都遵循负二分之一和正二分之一值之间的均匀分布，这可能会有所帮助。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So what that looks like is that our density functions each have this kind of top hat shape, where the graph equals 1 for all inputs between negative one-half and positive one-half, and it equals 0 everywhere else.",
  "translatedText": "所以看起来我们的密度函数都有这种高帽形状，其中对于负二分之一和正 二分之一之间的所有输入，图形都等于 1，而其他地方都等于 0。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The question, as always, is what should the distribution for the sum look like?",
  "translatedText": "与往常一样，问题是总和的分布应该是什么样的？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, let me show you how it looks inside our demo.",
  "translatedText": "好吧，让我向您展示它在我们的演示中的样子。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In this case, the product between the two graphs has a really easy interpretation.",
  "translatedText": "在这种情况下，两个图之间的乘积有一个非常简单的解释。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It is 1 wherever the graphs overlap with each other, but 0 everywhere else.",
  "translatedText": "图形相互重叠的地方为 1，其他地方为 0。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So if I slide this parameter s far enough to the left that our top graphs don't overlap at all, then the product graph is 0 everywhere, and that's a way of saying this is an impossible sum to achieve.",
  "translatedText": "因此，如果我将这个参数向左滑动得足够远，以至于我们的顶部图表根本不 重叠，那么乘积图到处都是 0，这就是说这是一个不可能实现的总和。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That should make sense.",
  "translatedText": "这应该是有道理的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Each of the two variables can only get as low as negative one-half, so the sum could never get below negative 1.",
  "translatedText": "这两个变量中的每一个只能低至负二分之一，因此总和永远不会低于负 1。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As I start to slide s to the right and the graphs overlap with each other, the area increases linearly until the graphs overlap entirely and it reaches a maximum.",
  "translatedText": "当我开始向右滑动 s 并且图形彼此重叠时，面 积线性增加，直到图形完全重叠并达到最大值。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And then after that point, it starts to decrease linearly again, which means that the distribution for the sum takes on this kind of wedge shape.",
  "translatedText": "然后在那之后，它再次开始线性下降，这意味着总和的分布呈现这种楔形。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And I imagine this actually feels somewhat familiar for anyone who's thought about a pair of dice, that is, unweighted dice.",
  "translatedText": "我想对于任何考虑过一对骰子（即未加权骰子）的人来说，这实际上感觉有些熟悉。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "There, if you add up two different uniformly distributed variables, then the distribution for the sum has a certain wedge shape.",
  "translatedText": "在那里，如果将两个不同的均匀分布变量相加，则总和的分布具有一定的楔形形状。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Probabilities increase until they max out at a 7, and then they decrease back down again.",
  "translatedText": "概率会增加，直到达到最大值 7，然后再次减少。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Where this gets a lot more fun is if instead of asking for a sum of two uniformly distributed variables, I ask you what it looks like if we add up three different uniformly distributed variables.",
  "translatedText": "更有趣的是，如果我不要求两个均匀分布变量的总和，而是问 你如果我们将三个不同的均匀分布变量相加会是什么样子。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "At first you might say, I don't know, we need some new way to visualize combining three things instead of two.",
  "translatedText": "一开始你可能会说，我不知道，我们需要一些新的方法来可视化组合三件事而不是两件事。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But really what you can do here is think about the sum of the first two as their own variable, which we just figured out follows this wedge shape distribution, and then take a convolution between that and the top hat function.",
  "translatedText": "但实际上你在这里可以做的是将前两个的总和视为它们自己的变量，我 们刚刚发现它遵循这个楔形分布，然后在它和顶帽函数之间进行卷积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Pulling up the demo, here's what that would look like.",
  "translatedText": "拉出演示，这就是它的样子。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Once again, what makes the top hat function really nice is that multiplying by it sort of has the effect of filtering out values from the top graph.",
  "translatedText": "再次强调，顶帽函数真正出色的地方在于，乘以它可以起到从顶图中过滤掉值的作用。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The product on the bottom looks just like a copy of the top graph, but limited to a certain window.",
  "translatedText": "底部的产品看起来就像顶部图表的副本，但仅限于某个窗口。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Again, as I slide this around left and right, and the area gets bigger and smaller, the result maxes out in the middle but tapers out to either side, except this time it does so more smoothly.",
  "translatedText": "再次，当我左右滑动它时，区域变得越来越大和越来越小，结果在 中间达到最大值，但向两侧逐渐变细，只不过这次它做得更平滑。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's kind of like we're taking a moving average of that top left graph.",
  "translatedText": "这有点像我们正在计算左上角图表的移动平均值。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Actually, it's more than just kind of, this literally is a moving average of the top left graph.",
  "translatedText": "实际上，它不仅仅是一种，这实际上是左上角图的移动平均值。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "One thing you might think to do is take this even further.",
  "translatedText": "您可能想做的一件事就是更进一步。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The way we started was combining two top hat functions and we got this wedge, then we replaced the first function with that wedge, and then when we took the convolution we got this smoother shape describing a sum of three distinct uniform variables, but we could just repeat.",
  "translatedText": "我们开始的方法是组合两个顶帽函数，得到这个楔形 ，然后用该楔形替换第一个函数，然后当我们进行 卷积时，我们得到了这个更平滑的形状，描述了三个 不同的统一变量的总和，但是我们可以只是重复。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Swap that out for the top function, and then convolve that with the flat rectangular function, and whatever result we see should describe a sum of four uniformly distributed random variables.",
  "translatedText": "将其替换为顶部函数，然后将其与平面矩形函数进行卷积，无论 我们看到什么结果都应该描述四个均匀分布随机变量的总和。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Any of you who watched the video about the central limit theorem should know what to expect.",
  "translatedText": "任何看过有关中心极限定理的视频的人都应该知道会发生什么。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "As we repeat this process over and over, the shape looks more and more like a bell curve.",
  "translatedText": "当我们一遍又一遍地重复这个过程时，形状看起来越来越像钟形曲线。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Or to be more precise, at each iteration we should rescale the x-axis to make sure that the standard deviation is one, because the dominant effect of this repeated convolution, the kind of repeated moving average process, is to flatten out the function over time.",
  "translatedText": "或者更准确地说，在每次迭代时，我们应该重新缩放 x 轴以确保标准差为 1，因为这种重复卷积（一种 重复移动平均过程）的主要效果是使函数变平时间。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So in the limit it just flattens out towards zero.",
  "translatedText": "因此，在极限情况下，它会趋于零。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "But rescaling is a way of saying, yeah yeah yeah, I know that it gets flatter, but what's the actual shape underlying it all?",
  "translatedText": "但重新缩放是一种说法，是的，是的，我知道它 会变得更平坦，但它背后的实际形状是什么？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The statement of the central limit theorem, one of the coolest facts from probability, is that you could have started with essentially any distribution and this still would have been true.",
  "translatedText": "中心极限定理是概率中最酷的事实之一，它的陈述是 ，您可以从本质上任何分布开始，这仍然是正确的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That as you take repeated convolutions like this, representing bigger and bigger sums of a given random variable, then the distribution describing that sum, which might start off looking very different from a normal distribution, over time smooths out more and more until it gets arbitrarily close to a normal distribution.",
  "translatedText": "当你像这样重复进行卷积时，表示给定随机变量的总和越来越大， 然后描述该总和的分布（一开始可能看起来与正态分布非常不同） 随着时间的推移变得越来越平滑，直到它变得任意接近正态分布。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's as if a bell curve is, in some loose manner of speaking, the smoothest possible distribution, an attractive fixed point in the space of all possible functions, as we apply this process of repeated smoothing through the convolution.",
  "translatedText": "当我们通过卷积应用这种重复平滑的过程时，用某种 宽松的方式来说，就好像钟形曲线是最平滑的可能 分布，是所有可能函数空间中有吸引力的固定点。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Naturally you might wonder, why normal distributions?",
  "translatedText": "您自然可能想知道，为什么是正态分布？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Why this function and not some other one?",
  "translatedText": "为什么是这个函数而不是其他函数？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That's a very good answer, and I think the most fun way to show the answer is in the light of the last visualization that we'll show for convolutions.",
  "translatedText": "这是一个非常好的答案，我认为展示答案的最有趣的 方式是根据我们将展示的卷积的最后一个可视化。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Remember how in the discrete case, the first of our two visualizations involved forming this kind of multiplication table, showing the probabilities for all possible outcomes, and adding up along the diagonals?",
  "translatedText": "还记得在离散情况下，我们的两个可视化 中的第一个涉及形成这种乘法表，显示所 有可能结果的概率，并沿对角线相加吗？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "You've probably guessed it by now, but our last step is to generalize this to the continuous case.",
  "translatedText": "您现在可能已经猜到了，但我们的最后一步是将其推广到连续情况。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And it is beautiful, but you have to be a little bit careful.",
  "translatedText": "它很漂亮，但你必须要小心一点。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Pulling up the same two functions we had before, f of x and g of y, what in this case would be analogous to the grid of possible pairs that we were looking at earlier?",
  "translatedText": "提取我们之前拥有的两个相同的函数，即 x 的 f 和 y 的 g，在这种情况下，什么类似于我们之前看到的可能对的网格？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well in this case, each of the variables can take on any real number, so we want to think about all possible pairs of real numbers, and the xy-plane comes to mind.",
  "translatedText": "在这种情况下，每个变量都可以采用任何实数，因此我们 想要考虑所有可能的实数对，并且想到了 xy 平面。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Every point corresponds to a possible outcome when we sample from both distributions.",
  "translatedText": "当我们从两个分布中采样时，每个点都对应于一个可能的结果。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Now the probability of any one of these outcomes, xy, or rather the probability density around that point, will look like f of x times g of y, again, assuming that the two are independent.",
  "translatedText": "现在，这些结果中任何一个的概率 xy，或者更确 切地说，该点周围的概率密度，将再次看起来像 x 的 f 乘以 y 的 g，假设两者是独立的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "So a natural thing to do is to graph this function, f of x times g of y, as a two-variable function, which would give something that looks like a surface above the xy-plane.",
  "translatedText": "因此，很自然的做法是将这个函数（x 的 f 乘以 y 的 g）绘 制为二变量函数，这将给出看起来像 xy 平面上方的表面的东西。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Notice in this example how if we look at it from one angle, where we see the x values changing, it has the shape of our first graph, but if we look at it from another angle, emphasizing the change in the y direction, it takes on the shape of our second graph.",
  "translatedText": "请注意，在这个例子中，如果我们从一个角度看它，我们看到 x 值发生变化，它具有我们第一个图形的形状，但如果我们从另一个角 度看它，强调 y 方向的变化，它呈现出我们第二张图的形状。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "This three-dimensional graph encodes all of the information we need.",
  "translatedText": "这个三维图编码了我们需要的所有信息。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It shows all the probability densities for every possible outcome.",
  "translatedText": "它显示了每种可能结果的所有概率密度。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And if you want to limit your view just to those outcomes where x plus y is constrained to be a given sum, what that looks like is limiting our view to a diagonal slice, specifically a slice over the line x plus y equals some constant.",
  "translatedText": "如果您想将您的视图限制为 x 加 y 被限制为给定 总和的结果，那么看起来就像将我们的视图限制为对角线 切片，特别是 x 加 y 线上的切片等于某个常数。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "All of the possible probability densities for the outcome subject to this constraint look sort of like a slice under this graph, and as we change around what specific sum we're constraining to, it shifts around which specific diagonal slice we're looking at.",
  "translatedText": "受此约束影响的结果的所有可能的概率密度看起来有点 像该图下的切片，并且当我们改变要约束的特定总和时 ，它会围绕我们正在查看的特定对角线切片进行移动。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Now what you might predict is that the way to combine all of the probability densities along one of these slices, the way to integrate them together, can be interpreted as the area under this curve, which is a slice of the surface.",
  "translatedText": "现在您可能预测的是，沿着这些切片之一组合所有概率 密度的方法，将它们整合在一起的方法，可以解释为该 曲线下方的面积，即曲面的切片。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And that is almost correct.",
  "translatedText": "这几乎是正确的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "There's a subtle detail regarding a factor of the square root of two that we need to talk about, but up to a constant factor, the areas of these slices give us the values of the convolution.",
  "translatedText": "我们需要讨论关于二的平方根的一个微妙细节，但在常数 因子范围内，这些切片的面积为我们提供了卷积的值。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In fact, all of these slices that we're looking at are precisely the same as the product graph that we were looking at earlier.",
  "translatedText": "事实上，我们正在查看的所有这些切片 与我们之前查看的产品图完全相同。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Here, to emphasize this point, let me pull up both visualizations side by side, and I'm going to slowly decrease the value of s, which on the left means we're looking at different slices, and on the right means we're shifting around the modified graph of g.",
  "translatedText": "在这里，为了强调这一点，让我并排拉出两个可视化，我将慢慢 减小 s 的值，左边意味着我们正在查看不同的切片，右边意 味着我们正在查看不同的切片。 重新围绕 g 的修改图移动。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Notice how at all points the shape of the graph on the bottom right, the product between the functions, looks exactly the same as the shape of the diagonal slice.",
  "translatedText": "请注意，右下角图形的形状（函数之间的乘积）在 所有点上看起来都与对角线切片的形状完全相同。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And this should make sense.",
  "translatedText": "这应该是有道理的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "They are two distinct ways to visualize the same thing.",
  "translatedText": "它们是可视化同一事物的两种不同方式。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It sounds like a lot when we put it into words, but what we're looking at are all the possible products between outputs of the functions corresponding to pairs of inputs that have a given sum.",
  "translatedText": "当我们用文字表达时，听起来好像很多，但我们看到的是与具 有给定总和的输入对相对应的函数的输出之间的所有可能的 乘积。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Again, it's kind of a mouthful, but I think you see what I'm saying, and we now have two different ways to see it.",
  "translatedText": "再说一次，这有点拗口，但我想你明白我在说 什么，而且我们现在有两种不同的方式来看待它。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The nice thing about the diagonal slice visualization is that it makes it much more clear that it's a symmetric operation.",
  "translatedText": "对角线切片可视化的好处在于，它更清楚地表明 这是一个对称操作。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "It's much more obvious that f convolved with g is the same thing as g convolved with f.",
  "translatedText": "更明显的是，f 与 g 的卷积与 g 与 f 的卷积是一样的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Technically, the diagonal slices are not exactly the same shape.",
  "translatedText": "从技术上讲，对角线切片的形状并 不完全相同。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "They've actually been stretched out by a factor of the square root of 2.",
  "translatedText": "它们实际上被拉伸了 2 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "The basic reason is that if you imagine taking some small step along one of these lines where x plus y equals a constant, then the change in your x value, the delta x here, is not the same thing as the length of that step.",
  "translatedText": "基本原因是，如果您想象沿着其中一条线迈出一小步，其中 x 加 y 等于常数，那么 x 值的变化（此处的增量 x ）与该步长不同。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "That step is actually longer by a factor of the square root of 2.",
  "translatedText": "该步骤实际上要长 2 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "I will leave a note up on the screen for the calculus enthusiasts among you who want to pause and ponder, but the upshot is very simply that the outputs of our convolution are technically not quite the areas of these diagonal slices.",
  "translatedText": "我会在屏幕上为那些想要停下来思考的微积分爱好者留下一条注 释，但结果很简单，从技术上讲，我们卷积的输出并不完全是 这些对角线切片的区域。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "We have to divide those areas by a square root of 2.",
  "translatedText": "我们必须将这些面积除以 2 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Stepping back from all of this for a moment, I just think this is so beautiful.",
  "translatedText": "暂时抛开这一切，我只是觉得这太美了。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "We started with such a simple question, or at least such a seemingly simple question, how do you add up two random variables?",
  "translatedText": "我们从一个如此简单的问题开始，或者至少是一个看似简单的问题， 如何将两个随机变量相加？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And what we end up with is this very intricate operation for combining two different functions.",
  "translatedText": "我们最终得到的是组合两个不同函数 的非常复杂的操作。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "We have at least two very pretty ways to understand it, but still, some of you might be raising your hands and saying, pretty pictures are all well and good, but do they actually help you calculate something?",
  "translatedText": "我们至少有两种非常漂亮的方法来理解它 ，但是，你们中的一些人可能会举手说，漂亮的图片都很好，但它们 真的能帮助您计算一些东西吗？",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "For example, I still have not answered the opening quiz question about adding two normally distributed random variables.",
  "translatedText": "例如，我还没有回答关于添加 两个正态分布随机变量的开场测验问题。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Well, the ordinary way that you would approach this kind of question, if it showed up on a homework or something like that, is that you would plug in the formula for a normal distribution into the definition of a convolution, the integral that we've been describing here.",
  "translatedText": "嗯，解决这类 问题的普通方法，如果它出现在家庭作业或类似的东西 上，就是将正态分布的公式代入卷积的定义中，即我们 的积分。 已经在这里描述了。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And in that case, the visualizations would really just be there to clarify what the expression is saying, but they sit in the back seat.",
  "translatedText": "在这种情况下，可视化实际 上只是为了澄清表达式所说的内容，但它们位于后座。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "In this case, the integral is not prohibitively difficult, there are analytical methods, but for this example, I want to show you a more fun method where the visualizations, specifically the diagonal slices, will play a much more front and center role in the proof itself.",
  "translatedText": "在这 种情况下，积分并不是非常困难，有分析方法，但对于这 个例子，我想向您展示一种更有趣的方法，其中可视化， 特别是对角线切片，将在证明本身。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "I think many of you may actually enjoy taking a moment to predict how this will look for yourself.",
  "translatedText": "我想你们中的许多人可能 真的喜欢花点时间来预测一下自己的情况。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Think about what this 3D graph would look like in the case of two normal distributions, and what properties that it has that you might be able to take advantage of.",
  "translatedText": "想想这个 3D 图在两个正态分布的情况下会是什么样子，以及它具有哪 些您可以利用的属性。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "And it is for sure easiest if you start with a case where both distributions have the same standard deviation.",
  "translatedText": "如果从两个分布具有相同标准差 的情况开始，这肯定是最简单的。",
  "model": "google_nmt",
  "n_reviews": 0
 },
 {
  "input": "Whenever you want the details, and to see how the answer fits into the central limit theorem, come join me in the next video.",
  "translatedText": "每当您想要了解详细信息并 了解答案如何符合中心极限定理时，请跟我一起观看下一个视频。",
  "model": "google_nmt",
  "n_reviews": 0
 }
]