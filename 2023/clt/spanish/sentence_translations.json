[
 {
  "input": "This is a Galton board. ",
  "translatedText": "Este es un tablero Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "Tal vez hayas visto uno antes, es una demostración popular de cómo, incluso cuando un solo evento es caótico y aleatorio, con un resultado efectivamente incognoscible, aún es posible hacer afirmaciones precisas sobre un gran número de eventos, es decir, cómo las proporciones relativas porque se distribuyen muchos resultados diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "Más específicamente, el tablero de Galton ilustra una de las distribuciones más destacadas de toda la probabilidad, conocida como distribución normal, más coloquialmente conocida como curva de campana, y también llamada distribución gaussiana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "Hay una función muy específica para describir esta distribución, es muy bonita, hablaremos de ella más adelante, pero ahora solo quiero enfatizar cómo la distribución normal es, como sugiere el nombre, muy común, aparece en muchos de contextos aparentemente no relacionados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "Si tomaras un gran número de personas que pertenecen a un grupo demográfico similar y trazaras sus alturas, esas alturas tenderían a seguir una distribución normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "Si observa una gran franja de números naturales muy grandes y pregunta cuántos factores primos distintos tiene cada uno de esos números, las respuestas seguirán muy de cerca una determinada distribución normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "Nuestro tema de hoy es una de las joyas de la corona de toda la teoría de la probabilidad, es uno de los hechos clave que explica por qué esta distribución es tan común como es, conocido como teorema del límite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "Esta lección está destinada a volver a lo básico, brindándole los fundamentos sobre lo que dice el teorema del límite central, qué son las distribuciones normales y quiero asumir una base mínima. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "Vamos a profundizar bastante en esto, pero después de esto todavía me gustaría profundizar y explicar por qué el teorema es verdadero, por qué la función subyacente a la distribución normal tiene la forma tan específica que tiene, por qué esa fórmula tiene un pi en él y, lo más divertido, por qué esos dos últimos hechos están en realidad más relacionados de lo que sugerirían muchas explicaciones tradicionales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "Esa segunda lección también pretende ser la continuación del vídeo sobre convoluciones que prometí, por lo que aquí hay muchos temas interrelacionados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "Pero ahora, volviendo a los fundamentos, me gustaría comenzar con un modelo demasiado simplificado del tablero de Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "En este modelo asumiremos que cada bola cae directamente sobre una determinada clavija central y que tiene una probabilidad de 50-50 de rebotar hacia la izquierda o hacia la derecha, y pensaremos que cada uno de esos resultados suma uno o restando uno de su posición. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "Una vez que se elige uno de ellos, hacemos la suposición muy poco realista de que aterriza exactamente en el medio de la clavija adyacente debajo de él, donde nuevamente se enfrentará a la misma opción 50-50 de rebotar hacia la izquierda o hacia la derecha. A la derecha. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "Para el que estoy mostrando en pantalla, hay cinco filas diferentes de clavijas, por lo que nuestra pequeña bola que salta hace cinco elecciones aleatorias diferentes entre más uno y menos uno, y podemos pensar que su posición final es básicamente la suma de todas. de esos números diferentes, que en este caso resulta ser uno, y podríamos etiquetar todos los diferentes grupos con la suma que representan. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "Mientras repetimos esto, observamos diferentes sumas posibles para esos cinco números aleatorios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "Y para aquellos de ustedes que se inclinan a quejarse de que este es un modelo muy poco realista para el verdadero tablero Galton, permítanme enfatizar que el objetivo en este momento no es modelar la física con precisión. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "El objetivo es dar un ejemplo sencillo para ilustrar el teorema del límite central y, para ello, por muy idealizado que sea, en realidad nos da un muy buen ejemplo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "Si dejamos caer muchas bolas diferentes, haciendo otra suposición poco realista de que no se influyen entre sí como si todas fueran fantasmas, entonces el número de bolas que caen en cada cubo diferente nos da una idea vaga de la probabilidad de que cada una de ellas caiga. de esos cubos es. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "En este ejemplo, los números son lo suficientemente simples como para que no sea demasiado difícil calcular explícitamente cuál es la probabilidad de caer en cada grupo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "Si quieres pensar en ello detenidamente, encontrarás que te recuerda mucho al triángulo de Pascal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "Pero lo interesante de nuestro teorema es hasta qué punto va más allá de los ejemplos simples. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "Entonces, al menos para comenzar, en lugar de hacer cálculos explícitos, simplemente simulemos cosas ejecutando una gran cantidad de muestras y dejando que la cantidad total de resultados en cada resultado diferente nos dé una idea de cómo se ve esa distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "Como dije, el que está en pantalla tiene cinco filas, por lo que cada suma que estamos considerando incluye solo cinco números. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "La idea básica del teorema del límite central es que si aumentas el tamaño de esa suma, por ejemplo aquí eso significaría aumentar el número de filas de clavijas para que rebote cada bola, entonces la distribución que describe dónde va a llegar esa suma El otoño se parece cada vez más a una curva en forma de campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "Aquí realmente vale la pena tomarse un momento para escribir esa idea general. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "La configuración es que tenemos una variable aleatoria, y eso es básicamente una abreviatura de un proceso aleatorio donde cada resultado de ese proceso está asociado con algún número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "Llamaremos a ese número aleatorio x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "Por ejemplo, cada rebote en la clavija es un proceso aleatorio modelado con dos resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "Esos resultados están asociados con los números uno negativo y uno positivo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "Otro ejemplo de variable aleatoria sería tirar un dado, donde se obtienen seis resultados diferentes, cada uno asociado con un número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "Lo que estamos haciendo es tomar varias muestras diferentes de esa variable y sumarlas todas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "En nuestro tablero de Galton, eso parece dejar que la bola rebote en varias clavijas diferentes en su camino hacia el fondo y, en el caso de un dado, podrías imaginarte lanzando muchos dados diferentes y sumando los resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "La afirmación del teorema del límite central es que a medida que se deja que el tamaño de esa suma crezca cada vez más, entonces la distribución de esa suma, la probabilidad de que caiga en diferentes valores posibles, se parecerá cada vez más a una curva de campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "Eso es todo, esa es la idea general. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "En el transcurso de esta lección, nuestro trabajo es hacer que esa afirmación sea más cuantitativa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "Le pondremos algunos números, le pondremos algunas fórmulas y le mostraremos cómo puede usarlo para hacer predicciones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "Por ejemplo, este es el tipo de pregunta que quiero que puedas responder al final de este video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "Supongamos que lanzaste el dado 100 veces y sumaste los resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "¿Podrías encontrar un rango de valores tal que estés 95% seguro de que la suma estará dentro de ese rango? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "O tal vez debería decir encontrar el rango de valores más pequeño posible para que esto sea cierto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "Lo bueno es que podrás responder esta pregunta si es un dado justo o si es un dado ponderado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "Ahora permítanme decir desde arriba que este teorema tiene tres supuestos diferentes, tres cosas que tienen que ser ciertas antes de que el teorema siga. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "Y en realidad no les diré cuáles son hasta el final del video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "En lugar de eso, quiero que estés atento y veas si puedes notar y tal vez predecir cuáles serán esas tres suposiciones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "Como siguiente paso, para ilustrar mejor cuán general es este teorema, quiero ejecutar un par de simulaciones más centradas en el ejemplo de los dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "Por lo general, si piensas en tirar un dado, piensas que los seis resultados son igualmente probables, pero al teorema en realidad eso no le importa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "Podríamos comenzar con un dado ponderado, algo con una distribución no trivial entre los resultados, y la idea central sigue siendo válida. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "Para la simulación, lo que haré será tomar una distribución como ésta que esté sesgada hacia valores más bajos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "Voy a tomar 10 muestras distintas de esa distribución y luego registraré la suma de esa muestra en el gráfico de abajo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "Luego haré esto muchas veces diferentes, siempre con una suma de tamaño 10, pero mantendré un registro de dónde terminaron esas sumas para darnos una idea de la distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "Y, de hecho, permítanme cambiar la escala de la dirección y para darnos espacio para ejecutar una cantidad aún mayor de muestras. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "Y lo dejaré llegar hasta un par de miles, y mientras lo hace, notarás que la forma que comienza a emerger parece una curva de campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "Tal vez si entrecierras los ojos puedas ver que se inclina un poquito hacia la izquierda, pero es genial que algo tan simétrico surgiera de un punto de partida que era tan asimétrico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "Para ilustrar mejor de qué se trata el teorema del límite central, permítanme ejecutar cuatro de estas simulaciones en paralelo, donde en la parte superior izquierda lo hago, donde solo sumamos dos dados a la vez, en la parte superior derecha Lo estamos haciendo donde sumamos cinco dados a la vez, la parte inferior izquierda es la que acabamos de ver agregando 10 dados a la vez, y luego haremos otro con una suma mayor, 15 a la vez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "Observe cómo en la parte superior izquierda, cuando simplemente estamos sumando dos dados, la distribución resultante no parece realmente una curva de campana, sino que recuerda mucho más a la que comenzamos sesgada hacia la izquierda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "Pero a medida que permitimos más y más dados en cada suma, la forma resultante que aparece en estas distribuciones parece cada vez más simétrica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "Tiene el bulto en el medio y se desvanece hacia la forma de una curva de campana de la cola. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "Y déjame enfatizar nuevamente, puedes comenzar con cualquier distribución diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "Aquí lo ejecutaré de nuevo, pero donde la mayor parte de la probabilidad está ligada a los números 1 y 6, con una probabilidad muy baja para los valores medios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "A pesar de cambiar completamente la distribución para una tirada individual del dado, sigue siendo cierto que surgirá una forma de curva de campana a medida que consideramos las diferentes sumas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "Ilustrar cosas con una simulación como esta es muy divertido y es genial ver cómo emerge el orden del caos, pero también resulta un poco impreciso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "Como en este caso, cuando corté la simulación en 3000 muestras, aunque parece una curva de campana, los diferentes cubos parecen bastante puntiagudos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "Y quizás te preguntes: ¿se supone que debe verse así o es sólo un artefacto de la aleatoriedad en la simulación? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "Y si es así, ¿cuántas muestras necesitamos antes de poder estar seguros de que lo que estamos viendo es representativo de la distribución real? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "En lugar de seguir adelante, seamos un poco más teóricos y mostremos la forma precisa que adoptarán estas distribuciones en el largo plazo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "El caso más sencillo para hacer este cálculo es si tenemos una distribución uniforme, donde cada posible cara del dado tiene la misma probabilidad, 16. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "Por ejemplo, si luego quieres saber qué probabilidades hay de que haya diferentes sumas para un par de dados, es esencialmente un juego de contar, en el que cuentas cuántos pares distintos toman la misma suma, lo cual, en el diagrama que he dibujado, puedes ver. puede pensar convenientemente pasando por todas las diferentes diagonales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "Dado que cada par tiene la misma probabilidad de aparecer, 1 en 36, todo lo que tienes que hacer es contar los tamaños de estos cubos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "Eso nos da una forma definitiva para la distribución que describe una suma de dos dados, y si jugáramos el mismo juego con todos los tripletes posibles, la distribución resultante se vería así. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "Ahora bien, lo que es más desafiante, pero mucho más interesante, es preguntar qué sucede si tenemos una distribución no uniforme para ese único dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "De hecho, hablamos de todo esto en el último video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "Básicamente haces lo mismo, pasas por todos los distintos pares de dados que suman el mismo valor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "Es solo que en lugar de contar esos pares, para cada par multiplicas las dos probabilidades de que aparezca cada cara en particular y luego las sumas todas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "El cálculo que hace esto para todas las sumas posibles tiene un nombre elegante, se llama convolución, pero esencialmente es solo la versión ponderada del juego de contar que cualquiera que haya jugado con un par de dados ya encuentra familiar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "Para nuestros propósitos en esta lección, haré que la computadora calcule todo eso, simplemente le mostrará los resultados y lo invitaré a observar ciertos patrones, pero en el fondo, esto es lo que está sucediendo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "Entonces, para dejar muy claro lo que se representa aquí, si imagina tomar muestras de dos valores diferentes de esa distribución superior, la que describe un solo dado, y sumarlos, entonces la segunda distribución que estoy dibujando representa la probabilidad de que ver varias sumas diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "Del mismo modo, si imagina muestrear tres valores distintos de esa distribución superior y sumarlos, el siguiente gráfico representa las probabilidades de varias sumas diferentes en ese caso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "Entonces, si calculo cómo se ven las distribuciones de estas sumas para sumas cada vez mayores, bueno, ya sabes lo que voy a decir, se parece cada vez más a una curva de campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "Pero antes de llegar a eso, quiero que hagas un par de observaciones simples más. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "Por ejemplo, estas distribuciones parecen estar desplazándose hacia la derecha y también parecen estar más extendidas y un poco más planas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "No se puede describir cuantitativamente el teorema del límite central sin tener en cuenta ambos efectos, lo que a su vez requiere describir la media y la desviación estándar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "Tal vez ya esté familiarizado con ellos, pero quiero hacer suposiciones mínimas aquí y nunca está de más revisarlas, así que repasemos ambas rápidamente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "La media de una distribución, a menudo denotada con la letra griega mu, es una forma de capturar el centro de masa de esa distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "Se calcula como el valor esperado de nuestra variable aleatoria, que es una forma de decir que se analizan todos los diferentes resultados posibles y se multiplica la probabilidad de ese resultado por el valor de la variable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "Si los valores más altos son más probables, esa suma ponderada será mayor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "Si los valores más bajos son más probables, esa suma ponderada será menor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "Un poco más interesante es si desea medir qué tan extendida está esta distribución, porque hay varias formas diferentes de hacerlo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "Uno de ellos se llama varianza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "La idea es observar la diferencia entre cada valor posible y la media, elevar al cuadrado esa diferencia y preguntar por su valor esperado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "La idea es que, ya sea que tu valor esté por debajo o por encima de la media, cuando elevas esa diferencia al cuadrado, obtienes un número positivo, y cuanto mayor es la diferencia, mayor es ese número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "Cuadrarlo así hace que las matemáticas sean mucho más agradables que si hiciéramos algo así como un valor absoluto, pero la desventaja es que es difícil pensar en esto como una distancia en nuestro diagrama porque las unidades están equivocadas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "Algo así como las unidades aquí son unidades cuadradas, mientras que una distancia en nuestro diagrama sería una especie de unidad lineal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "Entonces, otra forma de medir la dispersión es lo que se llama desviación estándar, que es la raíz cuadrada de este valor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "Eso se puede interpretar de manera mucho más razonable como una distancia en nuestro diagrama, y comúnmente se denota con la letra griega sigma, por lo que sabes que m significa media y desviación estándar, pero ambas en griego. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "Volviendo a nuestra secuencia de distribuciones, hablemos de la media y la desviación estándar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "Si llamamos mu a la media de la distribución inicial, que para la ilustrada resulta ser 2.24, espero que no sea muy sorprendente si les digo que la media del siguiente es 2 veces mu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "Es decir, tiras un par de dados y quieres saber el valor esperado de la suma, que es dos veces el valor esperado para un solo dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "De manera similar, el valor esperado para nuestra suma de tamaño 3 es 3 veces mu, y así sucesivamente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "La media simplemente avanza constantemente hacia la derecha, razón por la cual nuestras distribuciones parecen desviarse en esa dirección. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "Un poco más desafiante, pero muy importante, es describir cómo cambia la desviación estándar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "El hecho clave aquí es que si tienes dos variables aleatorias diferentes, entonces la varianza de la suma de esas variables es la misma que simplemente sumar las dos varianzas originales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "Este es uno de esos hechos que puedes calcular simplemente cuando descomprimes todas las definiciones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "Hay un par de buenas intuiciones de por qué esto es cierto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "Mi plan tentativo es simplemente hacer una serie sobre probabilidad y hablar sobre cosas como las intuiciones que subyacen a la varianza y sus primas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "Pero ahora mismo, lo principal que quiero resaltar es que lo que suma es la varianza, no la desviación estándar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "Entonces, críticamente, si tomaras n realizaciones diferentes de la misma variable aleatoria y preguntaras cómo se ve la suma, la varianza de esa suma es n veces la varianza de tu variable original, es decir, la desviación estándar, la raíz cuadrada de todas esto es la raíz cuadrada de n veces la desviación estándar original. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "Por ejemplo, volviendo a nuestra secuencia de distribuciones, si etiquetamos la desviación estándar de nuestra distribución inicial con sigma, entonces la siguiente desviación estándar será la raíz cuadrada de 2 multiplicado por sigma, y después de eso se verá como la raíz cuadrada de 3 veces sigma, y así sucesivamente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "Esto, como dije, es muy importante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "Significa que aunque nuestras distribuciones se están extendiendo, no lo hacen tan rápidamente, solo lo hacen en proporción a la raíz cuadrada del tamaño de la suma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "Mientras nos preparamos para hacer una descripción más cuantitativa del teorema del límite central, la intuición central que quiero que tengas en mente es que básicamente realinearemos todas estas distribuciones para que sus medias se alineen y luego las reescalaremos de manera que que todas las desviaciones estándar serán iguales a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "Y cuando hacemos eso, la forma resultante se acerca cada vez más a una determinada forma universal, descrita con una pequeña y elegante función que desentrañaremos en un momento. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "Y permítanme decir una vez más, la verdadera magia aquí es cómo podríamos haber comenzado con cualquier distribución, describiendo una sola tirada del dado, y si jugamos el mismo juego, considerando cómo se ven las distribuciones para las diferentes sumas, y los realineamos para que las medias se alineen, y los redimensionamos para que las desviaciones estándar sean todas 1, todavía nos acercamos a esa misma forma universal, lo cual es algo alucinante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "Y ahora, amigos míos, probablemente sea un buen momento para entrar finalmente en la fórmula de una distribución normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "Y la forma en que me gustaría hacer esto es básicamente quitar todas las capas y construirlas una pieza a la vez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "La función e a la x, o cualquier cosa a la x, describe el crecimiento exponencial, y si haces que el exponente sea negativo, lo que invierte el gráfico horizontalmente, podrías pensar que describe la caída exponencial. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "Para realizar esta caída en ambas direcciones, podrías hacer algo para asegurarte de que el exponente sea siempre negativo y creciente, como tomar el valor absoluto negativo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "Eso nos daría este tipo de punta afilada incómoda en el medio, pero si en lugar de eso convertimos ese exponente en el cuadrado negativo de x, obtenemos una versión más suave de lo mismo, que decae en ambas direcciones. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "Esto nos da la forma básica de curva de campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "Ahora, si colocas una constante delante de esa x y escalas esa constante hacia arriba y hacia abajo, te permite estirar y aplastar el gráfico horizontalmente, lo que te permite describir curvas de campana estrechas y más anchas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "Y una cosa rápida que me gustaría señalar aquí es que, según las reglas de la exponenciación, a medida que modificamos esa constante c, también puedes pensar en ello como simplemente cambiar la base de la exponenciación. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "Y en ese sentido, el número e no es tan especial para nuestra fórmula. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "Podríamos reemplazarla con cualquier otra constante positiva y obtendrás la misma familia de curvas a medida que modificamos esa constante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "Conviértalo en 2, misma familia de curvas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "Conviértalo en 3, misma familia de curvas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "La razón por la que usamos e es que le da a esa constante un significado muy legible. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "O mejor dicho, si reconfiguramos las cosas un poco para que el exponente parezca menos la mitad de x dividido por una determinada constante, que llamaremos sugerentemente sigma al cuadrado, entonces una vez que convertimos esto en una distribución de probabilidad, esa constante sigma Sea la desviación estándar de esa distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "Y eso es muy lindo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "Pero antes de que podamos interpretar esto como una distribución de probabilidad, necesitamos que el área bajo la curva sea 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "Y la razón es cómo se interpreta la curva. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "A diferencia de las distribuciones discretas, cuando se trata de algo continuo, no se pregunta por la probabilidad de un punto en particular. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "En cambio, pregunta por la probabilidad de que un valor se encuentre entre dos valores diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "Y lo que la curva te dice es que esa probabilidad es igual al área bajo la curva entre esos dos valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "Hay otro video sobre esto, se llaman funciones de densidad de probabilidad. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "El punto principal ahora es que el área bajo toda la curva representa la probabilidad de que algo suceda, que aparezca algún número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "Debería ser 1, por eso queremos que el área debajo de esto sea 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "Tal como está con la forma básica de curva de campana de e elevado a x cuadrado negativo, el área no es 1, en realidad es la raíz cuadrada de pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "¿Yo se, verdad? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "¿Qué hace pi aquí? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "¿Qué tiene esto que ver con los círculos? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "Como dije al principio, me encantaría hablar de eso en el próximo video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "Pero si puedes dedicar tu entusiasmo a nuestros propósitos ahora mismo, todo lo que significa es que debemos dividir esta función por la raíz cuadrada de pi, y nos dará el área que queremos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "Volviendo a las constantes que teníamos antes, 1 mitad y sigma, el efecto es estirar la gráfica en un factor de sigma multiplicado por la raíz cuadrada de 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "Entonces también necesitamos dividir por eso para asegurarnos de que tenga un área de 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "Y combinando esas fracciones, el factor anterior parece 1 dividido por sigma multiplicado por la raíz cuadrada de 2 pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "Ésta, finalmente, es una distribución de probabilidad válida. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "A medida que modificamos ese valor sigma, lo que da como resultado curvas más estrechas y más anchas, esa constante en el frente siempre garantiza que el área sea igual a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "El caso especial en el que sigma es igual a 1 tiene un nombre específico, lo llamamos distribución normal estándar, que juega un papel especialmente importante para usted y para mí en esta lección. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "Y todas las distribuciones normales posibles no solo están parametrizadas con este valor sigma, sino que también restamos otra constante mu de la variable x, y esto básicamente le permite deslizar el gráfico hacia la izquierda y hacia la derecha para que pueda prescribir la media de esta distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "En resumen, tenemos dos parámetros, uno que describe la media, otro que describe la desviación estándar, y todos están unidos en esta gran fórmula que involucra una e y un pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "Ahora que todo eso está sobre la mesa, volvamos a considerar la idea de comenzar con alguna variable aleatoria y preguntarnos cómo son las distribuciones de las sumas de esa variable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "Como ya hemos comentado, cuando aumentas el tamaño de esa suma, la distribución resultante cambiará según una media creciente y lentamente se extenderá según una desviación estándar creciente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "Y poniéndole algunas fórmulas reales, si conocemos la media de nuestra variable aleatoria subyacente, la llamamos mu, y también conocemos su desviación estándar, y la llamamos sigma, entonces la media de la suma en la parte inferior será mu. veces el tamaño de la suma, y la desviación estándar será sigma multiplicado por la raíz cuadrada de ese tamaño. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "Entonces, si queremos afirmar que esto se parece cada vez más a una curva de campana, y que una curva de campana solo se describe mediante dos parámetros diferentes, la media y la desviación estándar, ya sabes qué hacer. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "Podrías introducir esos dos valores en la fórmula, y obtendrás una fórmula muy explícita, aunque algo complicada, para una curva que debería ajustarse estrechamente a nuestra distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "Pero hay otra manera de describirlo que es un poco más elegante y se presta a una imagen muy divertida que podemos desarrollar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "En lugar de centrarnos en la suma de todas estas variables aleatorias, modifiquemos un poco esta expresión, donde lo que haremos será mirar la media que esperamos que tome esa suma y la restaremos para que nuestra nueva expresión tiene una media de 0, y luego veremos la desviación estándar que esperamos de nuestra suma y la dividiremos por eso, lo que básicamente simplemente reescala las unidades para que la desviación estándar de nuestra expresión sea igual a 1. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "Puede parecer una expresión más complicada, pero en realidad tiene un significado muy legible. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "Básicamente, se trata de decir ¿a cuántas desviaciones estándar de la media se encuentra esta suma? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "Por ejemplo, esta barra aquí corresponde a un cierto valor que puedes encontrar cuando tiras 10 dados y los sumas todos, y su posición un poco por encima del negativo 1 te dice que ese valor es un poco menor que una desviación estándar. inferior a la media. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "Además, por cierto, anticipándonos a la animación que estoy tratando de crear aquí, la forma en que estoy representando las cosas en el gráfico inferior es que el área de cada una de estas barras nos indica la probabilidad del valor correspondiente. en lugar de la altura. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "Se podría pensar que el eje y no representa probabilidad sino una especie de densidad de probabilidad. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "La razón de esto es preparar el escenario para que se alinee con la forma en que interpretamos las distribuciones continuas, donde la probabilidad de caer entre un rango de valores es igual a un área bajo una curva entre esos valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "En particular, el área de todas las barras juntas será 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "Ahora, con todo eso en su lugar, divirtámonos un poco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "Permítanme comenzar retrocediendo las cosas para que la distribución en la parte inferior represente una suma relativamente pequeña, como sumar solo tres de esas variables aleatorias. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "Observe lo que sucede cuando cambio la distribución con la que comenzamos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "A medida que cambia, la distribución en la parte inferior cambia completamente de forma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "Depende mucho de con qué empezamos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "Si dejamos que el tamaño de nuestra suma crezca un poco más, digamos hasta 10, y cuando cambio la distribución de x, en gran medida sigue pareciendo una curva de campana, pero puedo encontrar algunas distribuciones que hacen que cambie de forma. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "Por ejemplo, la curva realmente desequilibrada en la que casi toda la probabilidad está en los números 1 o 6 da como resultado este tipo de curva de campana puntiaguda y, si recuerdan, anteriormente mostré esto en forma de simulación. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "Entonces, si se pregunta si ese pico fue un artefacto de la aleatoriedad o refleja la distribución verdadera, resulta que refleja la distribución verdadera. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "En este caso, 10 no es una suma lo suficientemente grande como para que entre en vigor el teorema del límite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "Pero si en lugar de eso dejo que esa suma crezca y considero agregar 50 valores diferentes, lo cual en realidad no es tan grande, entonces no importa cómo cambie la distribución de nuestra variable aleatoria subyacente, esencialmente no tiene ningún efecto en la forma de la gráfica en el abajo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "No importa por dónde empecemos, toda la información y los matices de la distribución de x desaparecen y tendemos hacia esta única forma universal descrita por una función muy elegante para la distribución normal estándar, 1 sobre la raíz cuadrada de 2 pi por e. al negativo x al cuadrado sobre 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "De esto, de esto se trata el teorema del límite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "Casi nada de lo que puedas hacer con esta distribución inicial cambia la forma a la que tendemos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "Ahora bien, es posible que los más teóricos todavía se pregunten: ¿cuál es el teorema real? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "¿Cuál es la afirmación matemática que podemos probar o refutar y que afirmamos aquí? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "Si desea una declaración formal agradable, así es como podría ser. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "Considere este valor, donde estamos sumando n instancias diferentes de nuestra variable aleatoria, pero modificadas y ajustadas para que su media y desviación estándar sean 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "Nuevamente, lo que significa que puedes leerlo como preguntar cuántas desviaciones estándar de la media es la suma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "Entonces, la afirmación real, rigurosa y sin bromas esta vez del teorema del límite central es que si se considera la probabilidad de que este valor se encuentre entre dos números reales dados, a y b, y se considera el límite de esa probabilidad como el tamaño de su suma llega al infinito, entonces ese límite es igual a una determinada integral, que básicamente describe el área bajo una distribución normal estándar entre esos dos valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "Nuevamente, hay tres suposiciones subyacentes que todavía tengo que contarles, pero aparte de esas, con todo su sangriento detalle, este es el teorema del límite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "Todo esto es un poco teórico, por lo que podría ser útil regresar las cosas a la Tierra y volver al ejemplo concreto que mencioné al principio, donde imaginas lanzar un dado 100 veces, y supongamos que es un dado justo. para este ejemplo, y suma los resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "El desafío para usted es encontrar un rango de valores tal que esté 95% seguro de que la suma estará dentro de este rango. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "Para preguntas como esta, existe una regla práctica sobre las distribuciones normales, que es que alrededor del 68% de sus valores estarán dentro de una desviación estándar de la media, el 95% de sus valores, lo que nos importa, estarán dentro de dos desviaciones estándar de la media y la friolera de 99. El 7% de sus valores estarán dentro de tres desviaciones estándar de la media. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "Es una regla general que comúnmente memorizan las personas que hacen muchas probabilidades y estadísticas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "Naturalmente, esto nos da lo que necesitamos para nuestro ejemplo, y permítanme seguir adelante y dibujar cómo se vería esto, donde mostraré la distribución de un dado justo en la parte superior y la distribución de una suma de 100. esos dados en la parte inferior, que a estas alturas, como ya sabes, parece una cierta distribución normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "El primer paso con un problema como este es encontrar la media de su distribución inicial, que en este caso se verá como 1 sexto por 1 más 1 sexto por 2 una y otra vez, y resulta ser 3.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "También necesitamos la desviación estándar, que requiere calcular la varianza, que como sabes implica sumar todos los cuadrados de las diferencias entre los valores y las medias, y resulta ser 2.92, la raíz cuadrada de eso es 1.71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "Esos son los únicos dos números que necesitamos, y los invitaré nuevamente a reflexionar sobre lo mágico que es que esos sean los únicos dos números que necesitamos para comprender completamente la distribución inferior. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "Su media será 100 multiplicado por mu, que es 350, y su desviación estándar será la raíz cuadrada de 100 multiplicado por sigma, es decir, 10 multiplicado por sigma 17.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "Recordando nuestra práctica regla general, buscamos valores a dos desviaciones estándar de la media, y cuando restas 2 sigma de la media terminas con aproximadamente 316, y cuando sumas 2 sigma terminas con 384. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "Y ahí lo tienes, eso nos da la respuesta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "Bien, prometí terminar las cosas en breve, pero mientras estamos en este ejemplo, hay una pregunta más que vale la pena reflexionar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "En lugar de simplemente preguntar sobre la suma de 100 tiradas de dado, digamos que te pedí que dividieras ese número entre 100, lo que básicamente significa que todos los números en nuestro diagrama en la parte inferior se dividen entre 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "Tómate un momento para interpretar lo que todo esto estaría diciendo entonces. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "Básicamente, la expresión te indica el promedio empírico de 100 tiradas de dados diferentes, y ese intervalo que encontramos ahora te indica qué rango esperas ver para ese promedio empírico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "En otras palabras, se podría esperar que sea alrededor de 3.5, ese es el valor esperado para una tirada de dado, pero lo que es mucho menos obvio y lo que el teorema del límite central te permite calcular es qué tan cerca de ese valor esperado te encontrarás razonablemente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "En particular, vale la pena tomarse un momento para reflexionar sobre cuál es la desviación estándar de este promedio empírico y qué le sucede al observar una muestra cada vez mayor de tiradas de dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "Por último, pero probablemente lo más importante, hablemos de los supuestos que se incluyen en este teorema. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "La primera es que todas estas variables que estamos sumando son independientes entre sí. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "El resultado de un proceso no influye en el resultado de ningún otro proceso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "La segunda es que todas estas variables se extraen de la misma distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "Ambas cosas se han asumido implícitamente en nuestro ejemplo de los dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "Hemos estado tratando el resultado de cada tirada de dado como independiente del resultado de todas las demás, y asumimos que cada dado sigue la misma distribución. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "A veces en la literatura verás estos dos supuestos agrupados bajo las iniciales IID para independientes e idénticamente distribuidos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "Una situación en la que estas suposiciones son decididamente falsas sería la junta de Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "Quiero decir, piénsalo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "¿Es cierto que la forma en que una pelota rebota en una de las clavijas es independiente de cómo rebotará en la siguiente clavija? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "Absolutamente no. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "Dependiendo del último rebote, llega con una trayectoria completamente diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "¿Y es cierto que la distribución de posibles resultados de cada clavija es la misma para cada clavija que golpea? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "De nuevo, es casi seguro que no. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "Tal vez golpee una clavija que mira hacia la izquierda, lo que significa que los resultados están muy sesgados en esa dirección, y luego golpee la siguiente que mira hacia la derecha. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "Cuando hice todas esas suposiciones simplificadoras en el ejemplo inicial, no fue solo para que fuera más fácil pensar en esto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "También es que esas suposiciones eran necesarias para que esto fuera realmente un ejemplo del teorema del límite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "Sin embargo, ¿parece ser cierto que para el tablero Galton real, a pesar de violar ambos, se produce una distribución normal? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "Parte de la razón podría ser que existen generalizaciones del teorema más allá del alcance de este video que relajan estos supuestos, especialmente el segundo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "Pero sí quiero advertirle contra el hecho de que muchas veces la gente parece asumir que una variable tiene una distribución normal, incluso cuando no existe una justificación real para hacerlo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "La tercera suposición es, en realidad, bastante sutil. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "Es que la varianza que hemos estado calculando para estas variables es finita. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "Esto nunca fue un problema en el ejemplo de los dados, porque sólo había seis resultados posibles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "Pero en ciertas situaciones en las que tienes un conjunto infinito de resultados, cuando vas a calcular la varianza, la suma termina divergiendo hacia el infinito. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "Éstas pueden ser distribuciones de probabilidad perfectamente válidas y surgen en la práctica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "Pero en esas situaciones, cuando considera agregar muchas instancias diferentes de esa variable y dejar que la suma se acerque al infinito, incluso si se cumplen los dos primeros supuestos, es muy posible que aquello hacia lo que tiende no sea en realidad una distribución normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "Si has entendido todo hasta este punto, ahora tienes una base muy sólida sobre de qué se trata el teorema central del límite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "Y a continuación, me gustaría explicar por qué esta función en particular es hacia lo que tendemos, y por qué tiene un pi, qué tiene que ver con los círculos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]