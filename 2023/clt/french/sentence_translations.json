[
 {
  "input": "This is a Galton board. ",
  "translatedText": "C'est une planche Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "Peut-être en avez-vous déjà vu un auparavant, c'est une démonstration populaire de la façon dont, même lorsqu'un seul événement est chaotique et aléatoire, avec un résultat effectivement inconnaissable, il est toujours possible de faire des déclarations précises sur un grand nombre d'événements, à savoir comment les proportions relatives car de nombreux résultats différents sont distribués. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "Plus précisément, le tableau de Galton illustre l'une des distributions les plus importantes de toute probabilité, connue sous le nom de distribution normale, plus familièrement connue sous le nom de courbe en cloche, et également appelée distribution gaussienne. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "Il y a une fonction très spécifique pour décrire cette distribution, elle est très jolie, nous y reviendrons plus tard, mais pour l'instant je veux juste souligner à quel point la distribution normale est, comme son nom l'indique, très courante, elle apparaît dans beaucoup de contextes apparemment sans rapport. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "Si vous deviez prendre un grand nombre de personnes appartenant à un groupe démographique similaire et tracer leurs tailles, ces tailles ont tendance à suivre une distribution normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "Si vous regardez une large bande de très grands nombres naturels et que vous demandez combien de facteurs premiers distincts possède chacun de ces nombres, les réponses suivront de très près une certaine distribution normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "Notre sujet d'aujourd'hui est l'un des joyaux de toute la théorie des probabilités. C'est l'un des faits clés qui expliquent pourquoi cette distribution est aussi courante qu'elle l'est, connue sous le nom de théorème central limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "Cette leçon est destinée à revenir aux bases, en vous donnant les principes fondamentaux de ce que dit le théorème central limite, ce que sont les distributions normales, et je veux supposer un minimum de connaissances. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "Nous allons approfondir ce sujet, mais après cela, j'aimerais encore approfondir et expliquer pourquoi le théorème est vrai, pourquoi la fonction sous-jacente à la distribution normale a la forme très spécifique qu'elle a, pourquoi cette formule a un pi dedans et, ce qui est le plus amusant, pourquoi ces deux derniers faits sont en réalité plus liés que ne le suggèrent de nombreuses explications traditionnelles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "Cette deuxième leçon est également censée faire suite à la vidéo sur les circonvolutions que j'ai promise, il y a donc beaucoup de sujets interdépendants ici. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "Mais pour le moment, revenons aux fondamentaux, j'aimerais commencer avec un modèle trop simplifié de la carte Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "Dans ce modèle, nous supposerons que chaque balle tombe directement sur un certain piquet central et qu'elle a une probabilité de 50-50 de rebondir vers la gauche ou vers la droite, et nous considérerons chacun de ces résultats comme l'ajout d'un ou d'un autre. en soustrayant un de sa position. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "Une fois que l'un d'entre eux est choisi, nous faisons l'hypothèse hautement irréaliste qu'il atterrit exactement au milieu du piquet adjacent en dessous, où il sera à nouveau confronté au même choix 50-50 de rebondir vers la gauche ou vers la gauche. À droite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "Pour celui que je montre à l'écran, il y a cinq rangées différentes de piquets, donc notre petite balle sautillante fait cinq choix aléatoires différents entre plus un et moins un, et nous pouvons considérer sa position finale comme étant fondamentalement la somme de tous. de ces différents nombres, qui dans ce cas se trouve être un, et nous pourrions étiqueter tous les différents compartiments avec la somme qu'ils représentent. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "En répétant cela, nous examinons différentes sommes possibles pour ces cinq nombres aléatoires. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "Et pour ceux d'entre vous qui ont tendance à se plaindre qu'il s'agit d'un modèle très irréaliste pour le véritable tableau de Galton, permettez-moi de souligner que l'objectif actuel n'est pas de modéliser avec précision la physique. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "Le but est de donner un exemple simple pour illustrer le théorème central limite, et pour cela, aussi idéalisé soit-il, cela nous donne en fait un très bon exemple. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "Si nous laissons tomber de nombreuses balles différentes, en faisant une autre hypothèse irréaliste selon laquelle elles ne s'influencent pas les unes les autres comme si elles étaient toutes des fantômes, alors le nombre de balles qui tombent dans chaque seau différent nous donne une idée vague de la probabilité que chacune d'entre elles tombe. de ces seaux est. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "Dans cet exemple, les chiffres sont suffisamment simples pour qu’il ne soit pas trop difficile de calculer explicitement la probabilité de tomber dans chaque catégorie. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "Si vous voulez bien y réfléchir, vous constaterez que cela rappelle beaucoup le triangle de Pascal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "Mais ce qui est intéressant avec notre théorème, c’est qu’il va au-delà des simples exemples. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "Donc, pour commencer au moins, plutôt que de faire des calculs explicites, simulons simplement les choses en exécutant un grand nombre d'échantillons et en laissant le nombre total de résultats dans chaque résultat différent nous donner une idée de ce à quoi ressemble cette distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "Comme je l'ai dit, celui à l'écran comporte cinq lignes, donc chaque somme que nous envisageons ne comprend que cinq nombres. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "L'idée de base du théorème central limite est que si vous augmentez la taille de cette somme, par exemple ici, cela signifierait augmenter le nombre de rangées de piquets pour que chaque balle rebondisse, alors la distribution qui décrit où cette somme va l’automne ressemble de plus en plus à une courbe en cloche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "Ici, cela vaut la peine de prendre un moment pour écrire cette idée générale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "La configuration est que nous avons une variable aléatoire, et c'est essentiellement un raccourci pour un processus aléatoire où chaque résultat de ce processus est associé à un certain nombre. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "Nous appellerons ce nombre aléatoire x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "Par exemple, chaque rebond sur la cheville est un processus aléatoire modélisé avec deux résultats. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "Ces résultats sont associés aux nombres négatif un et positif. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "Un autre exemple de variable aléatoire serait de lancer un dé, où vous obtenez six résultats différents, chacun associé à un nombre. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "Ce que nous faisons, c'est prendre plusieurs échantillons différents de cette variable et les additionner tous ensemble. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "Sur notre tableau Galton, cela revient à laisser la balle rebondir sur plusieurs piquets différents en descendant vers le bas, et dans le cas d'un dé, vous pourriez imaginer lancer de nombreux dés différents et additionner les résultats. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "L'affirmation du théorème central limite est que plus vous laissez la taille de cette somme devenir de plus en plus grande, alors la distribution de cette somme, sa probabilité de tomber dans différentes valeurs possibles, ressemblera de plus en plus à une courbe en cloche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "Voilà, c'est l'idée générale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "Au cours de cette leçon, notre travail consiste à rendre cette affirmation plus quantitative. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "Nous allons y mettre quelques chiffres, y mettre des formules, montrer comment vous pouvez l'utiliser pour faire des prédictions. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "Par exemple, voici le genre de question à laquelle je souhaite que vous puissiez répondre d'ici la fin de cette vidéo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "Supposons que vous ayez lancé le dé 100 fois et que vous ayez additionné les résultats. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "Pourriez-vous trouver une plage de valeurs telle que vous soyez sûr à 95% que la somme se situera dans cette plage ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "Ou peut-être devrais-je dire trouver la plage de valeurs la plus petite possible pour que cela soit vrai. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "Ce qui est intéressant, c'est que vous serez en mesure de répondre à cette question, s'il s'agit d'un dé équitable ou d'un dé pondéré. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "Maintenant, permettez-moi de dire tout d'abord que ce théorème repose sur trois hypothèses différentes, trois choses qui doivent être vraies avant que le théorème ne suive. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "Et je ne vais en fait pas vous dire de quoi il s’agit avant la toute fin de la vidéo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "Au lieu de cela, je veux que vous gardiez l’œil ouvert et que vous voyiez si vous pouvez remarquer et peut-être prédire quelles seront ces trois hypothèses. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "Dans la prochaine étape, pour mieux illustrer à quel point ce théorème est général, je souhaite exécuter pour vous quelques simulations supplémentaires axées sur l'exemple des dés. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "Habituellement, si vous envisagez de lancer un dé, vous pensez que les six résultats sont également probables, mais le théorème ne s'en soucie pas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "Nous pourrions commencer avec un dé pondéré, quelque chose avec une distribution non triviale entre les résultats, et l’idée centrale est toujours valable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "Pour la simulation, je vais prendre une distribution comme celle-ci qui est orientée vers des valeurs inférieures. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "Je vais prélever 10 échantillons distincts de cette distribution, puis j'enregistrerai la somme de cet échantillon sur le tracé en bas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "Ensuite, je vais faire cela plusieurs fois, toujours avec une somme de taille 10, mais gardez une trace de l'endroit où ces sommes ont abouti pour nous donner une idée de la distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "Et en fait, permettez-moi de redimensionner la direction y pour nous donner la possibilité d'analyser un nombre encore plus grand d'échantillons. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "Et je vais laisser cela aller jusqu'à quelques milliers, et ce faisant, vous remarquerez que la forme qui commence à émerger ressemble à une courbe en cloche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "Peut-être que si vous plissez les yeux, vous pouvez voir que cela s'incline un peu vers la gauche, mais il est intéressant que quelque chose d'aussi symétrique ait émergé d'un point de départ si asymétrique. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "Pour mieux illustrer ce qu'est le théorème central limite, permettez-moi d'exécuter quatre de ces simulations en parallèle, où en haut à gauche je le fais là où nous n'ajoutons que deux dés à la fois, en haut à droite nous' Si nous le faisons en ajoutant cinq dés à la fois, le coin inférieur gauche est celui que nous venons de voir ajouter 10 dés à la fois, puis nous en ferons un autre avec une somme plus importante, 15 à la fois. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "Remarquez qu'en haut à gauche, lorsque nous ajoutons simplement deux dés, la distribution résultante ne ressemble pas vraiment à une courbe en cloche, elle rappelle beaucoup plus celle avec laquelle nous avons commencé, inclinée vers la gauche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "Mais à mesure que nous acceptons de plus en plus de dés dans chaque somme, la forme résultante qui apparaît dans ces distributions semble de plus en plus symétrique. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "Il a une bosse au milieu et s'estompe vers la forme d'une courbe en cloche de la queue. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "Et permettez-moi de souligner encore une fois que vous pouvez commencer avec n'importe quelle distribution différente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "Ici, je vais le relancer, mais où la majeure partie de la probabilité est liée aux nombres 1 et 6, avec une très faible probabilité pour les valeurs moyennes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "Même si la distribution a complètement changé pour un lancer de dé individuel, il arrive toujours qu'une forme de courbe en cloche émerge lorsque l'on considère les différentes sommes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "Illustrer des choses avec une simulation comme celle-ci est très amusant, et c'est plutôt sympa de voir l'ordre émerger du chaos, mais cela semble aussi un peu imprécis. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "Comme dans ce cas, lorsque j'ai coupé la simulation à 3 000 échantillons, même si cela ressemble à une courbe en cloche, les différents compartiments semblent assez pointus. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "Et vous vous demandez peut-être si c’est censé ressembler à cela, ou est-ce simplement un artefact du caractère aléatoire de la simulation ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "Et si c'est le cas, de combien d'échantillons avons-nous besoin avant de pouvoir être sûrs que ce que nous examinons est représentatif de la véritable distribution ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "Au lieu de cela, soyons un peu plus théoriques et montrons la forme précise que prendront ces distributions à long terme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "Le cas le plus simple pour effectuer ce calcul est si nous avons une distribution uniforme, où chaque face possible du dé a une probabilité égale, 1 6ème. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "Par exemple, si vous voulez ensuite connaître la probabilité que des sommes différentes soient obtenues pour une paire de dés, il s'agit essentiellement d'un jeu de comptage, dans lequel vous comptez combien de paires distinctes prennent la même somme, ce qui, dans le diagramme que j'ai dessiné, vous peut facilement y réfléchir en passant par toutes les différentes diagonales. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "Puisque chacune de ces paires a une chance égale d’apparaître, 1 sur 36, tout ce que vous avez à faire est de compter la taille de ces seaux. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "Cela nous donne une forme définitive pour la distribution décrivant une somme de deux dés, et si nous devions jouer au même jeu avec tous les triplets possibles, la distribution résultante ressemblerait à ceci. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "Maintenant, ce qui est plus difficile, mais beaucoup plus intéressant, est de se demander ce qui se passe si nous avons une distribution non uniforme pour cette seule puce. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "En fait, nous en avons parlé dans la dernière vidéo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "Vous faites essentiellement la même chose, vous parcourez toutes les paires de dés distinctes qui totalisent la même valeur. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "C'est juste qu'au lieu de compter ces paires, pour chaque paire, vous multipliez les deux probabilités que chaque face particulière se présente, puis vous les additionnez toutes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "Le calcul qui fait cela pour toutes les sommes possibles a un nom fantaisiste, on l'appelle une convolution, mais il s'agit essentiellement de la version pondérée du jeu de comptage que quiconque a joué avec une paire de dés trouve déjà familier. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "Pour les besoins de cette leçon, je vais demander à l'ordinateur de calculer tout cela, d'afficher simplement les résultats pour vous et de vous inviter à observer certains modèles, mais sous le capot, voici ce qui se passe. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "Donc, juste pour être parfaitement clair sur ce qui est représenté ici, si vous imaginez échantillonner deux valeurs différentes de cette distribution supérieure, celle décrivant un seul dé, et les additionner, alors la deuxième distribution que je dessine représente la probabilité que vous soyez voir différentes sommes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "De même, si vous imaginez échantillonner trois valeurs distinctes de cette distribution supérieure et les additionner, le graphique suivant représente les probabilités de différentes sommes dans ce cas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "Donc si je calcule à quoi ressemblent les distributions de ces sommes pour des sommes de plus en plus grandes, eh bien vous savez ce que je vais dire, cela ressemble de plus en plus à une courbe en cloche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "Mais avant d’en arriver là, j’aimerais que vous fassiez quelques observations plus simples. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "Par exemple, ces distributions semblent errer vers la droite, et elles semblent également s'étaler davantage et être un peu plus plates. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "Vous ne pouvez pas décrire quantitativement le théorème central limite sans prendre en compte ces deux effets, ce qui nécessite à son tour de décrire la moyenne et l’écart type. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "Peut-être que vous les connaissez déjà, mais je souhaite ici faire des hypothèses minimales, et cela ne fait jamais de mal de les examiner, alors passons rapidement en revue les deux. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "La moyenne d'une distribution, souvent désignée par la lettre grecque mu, est un moyen de capturer le centre de masse de cette distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "Elle est calculée comme la valeur attendue de notre variable aléatoire, ce qui est une façon de dire que vous passez en revue tous les différents résultats possibles et que vous multipliez la probabilité de ce résultat par la valeur de la variable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "Si des valeurs plus élevées sont plus probables, cette somme pondérée sera plus importante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "Si des valeurs inférieures sont plus probables, cette somme pondérée sera plus petite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "Un peu plus intéressant est si vous souhaitez mesurer l'étendue de cette distribution, car vous pouvez le faire de plusieurs manières différentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "L’un d’eux s’appelle la variance. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "L'idée est d'examiner la différence entre chaque valeur possible et la moyenne, de mettre cette différence au carré et de demander sa valeur attendue. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "L’idée est que, que votre valeur soit inférieure ou supérieure à la moyenne, lorsque vous mettez cette différence au carré, vous obtenez un nombre positif, et plus la différence est grande, plus ce nombre est grand. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "Le mettre au carré ainsi s'avère rendre les calculs beaucoup plus agréables que si nous faisions quelque chose comme une valeur absolue, mais l'inconvénient est qu'il est difficile de considérer cela comme une distance dans notre diagramme car les unités sont fausses. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "Un peu comme si les unités ici sont des unités carrées, alors qu'une distance dans notre diagramme serait une sorte d'unité linéaire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "Une autre façon de mesurer la propagation est ce qu'on appelle l'écart type, qui est la racine carrée de cette valeur. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "Cela peut être interprété de manière beaucoup plus raisonnable comme une distance sur notre diagramme, et elle est généralement désignée par la lettre grecque sigma, vous connaissez donc m pour la moyenne comme pour l'écart type, mais les deux en grec. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "En repensant à notre séquence de distributions, parlons de la moyenne et de l'écart type. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "Si nous appelons mu la moyenne de la distribution initiale, qui pour celle illustrée se trouve être 2.24, j'espère que ce ne sera pas trop surprenant si je vous dis que la moyenne du prochain est de 2 fois mu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "Autrement dit, vous lancez une paire de dés, vous voulez connaître la valeur attendue de la somme, c'est deux fois la valeur attendue pour un seul dé. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "De même, la valeur attendue pour notre somme de taille 3 est 3 fois mu, et ainsi de suite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "La moyenne progresse régulièrement vers la droite, c'est pourquoi nos distributions semblent dériver dans cette direction. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "Un peu plus difficile, mais très important, consiste à décrire comment l'écart type change. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "Le fait clé ici est que si vous avez deux variables aléatoires différentes, alors la variance de la somme de ces variables est la même que la simple addition des deux variances d'origine. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "C’est l’un de ces faits que vous pouvez simplement calculer lorsque vous décompressez toutes les définitions. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "Il existe quelques bonnes intuitions expliquant pourquoi c'est vrai. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "Mon plan provisoire est simplement de faire une série sur les probabilités et de parler de choses comme les intuitions qui sous-tendent la variance et ses cousins. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "Mais pour l’instant, la principale chose que je veux que vous souligniez est que c’est la variance qui s’ajoute, et non l’écart type qui s’ajoute. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "Donc, de manière critique, si vous deviez prendre n réalisations différentes de la même variable aléatoire et demander à quoi ressemble la somme, la variance de cette somme est n fois la variance de votre variable d'origine, c'est-à-dire l'écart type, la racine carrée de tous. c'est la racine carrée de n fois l'écart type d'origine. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "Par exemple, de retour dans notre séquence de distributions, si nous étiquetons l'écart type de notre distribution initiale avec sigma, alors l'écart type suivant sera la racine carrée de 2 fois sigma, et après cela, il ressemblera à la racine carrée de 3 fois sigma, et ainsi de suite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "Ceci, comme je l'ai dit, est très important. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "Cela signifie que même si nos distributions s'étalent, elles ne s'étalent pas si rapidement, elles ne le font que proportionnellement à la racine carrée de la taille de la somme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "Alors que nous nous préparons à faire une description plus quantitative du théorème central limite, l'intuition fondamentale que je veux que vous gardiez à l'esprit est que nous allons fondamentalement réaligner toutes ces distributions afin que leurs moyennes s'alignent ensemble, puis les redimensionner de manière à ce que que tous les écarts types seront simplement égaux à 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "Et lorsque nous faisons cela, la forme qui en résulte se rapproche de plus en plus d'une certaine forme universelle, décrite par une petite fonction élégante que nous dévoilerons dans un instant. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "Et permettez-moi de le répéter une fois de plus, la vraie magie ici est de savoir comment nous aurions pu commencer avec n'importe quelle distribution, en décrivant un seul lancer de dé, et si nous jouions au même jeu, en considérant à quoi ressemblent les distributions pour les nombreuses sommes différentes, et on les réaligne pour que les moyennes s'alignent, et on les redimensionne pour que les écarts types soient tous égaux à 1, on s'approche toujours de cette même forme universelle, ce qui est un peu ahurissant. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "Et maintenant, mes amis, c’est probablement le moment le plus opportun pour enfin aborder la formule d’une distribution normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "Et la façon dont j'aimerais procéder est de décoller toutes les couches et de les construire une pièce à la fois. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "La fonction e au x, ou quoi que ce soit au x, décrit une croissance exponentielle, et si vous rendez cet exposant négatif, qui tourne horizontalement autour du graphique, vous pourriez le considérer comme décrivant une décroissance exponentielle. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "Pour effectuer cette décroissance dans les deux sens, vous pouvez faire quelque chose pour vous assurer que l'exposant est toujours négatif et croissant, comme prendre la valeur absolue négative. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "Cela nous donnerait ce genre de point pointu et gênant au milieu, mais si à la place vous faites de cet exposant le carré négatif de x, vous obtenez une version plus douce de la même chose, qui se désintègre dans les deux sens. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "Cela nous donne la forme de base de la courbe en cloche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "Maintenant, si vous placez une constante devant ce x et que vous augmentez et diminuez cette constante, cela vous permet d'étirer et d'écraser le graphique horizontalement, vous permettant ainsi de décrire des courbes en cloche étroites et plus larges. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "Et une chose rapide que j'aimerais souligner ici est que, sur la base des règles d'exponentiation, lorsque nous ajustons cette constante c, vous pouvez également y penser comme simplement changer la base de l'exponentiation. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "Et en ce sens, le nombre e n’est pas vraiment spécial pour notre formule. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "Nous pourrions la remplacer par n’importe quelle autre constante positive, et vous obtiendrez la même famille de courbes en modifiant cette constante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "Faites-en 2, même famille de courbes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "Faites-en un 3, même famille de courbes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "La raison pour laquelle nous utilisons e est que cela donne à cette constante une signification très lisible. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "Ou plutôt, si nous reconfigurons un peu les choses pour que l'exposant ressemble à moins une moitié de x divisé par une certaine constante, que nous appellerons de manière suggestive sigma au carré, alors une fois que nous transformerons cela en une distribution de probabilité, ce sigma constant sera être l'écart type de cette distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "Et c'est très sympa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "Mais avant de pouvoir interpréter cela comme une distribution de probabilité, nous avons besoin que l’aire sous la courbe soit égale à 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "Et la raison en est la manière dont la courbe est interprétée. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "Contrairement aux distributions discrètes, lorsqu'il s'agit de quelque chose de continu, vous ne posez pas de questions sur la probabilité d'un point particulier. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "Au lieu de cela, vous demandez la probabilité qu'une valeur se situe entre deux valeurs différentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "Et ce que la courbe vous dit, c'est que cette probabilité est égale à l'aire sous la courbe entre ces deux valeurs. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "Il y a une toute autre vidéo à ce sujet, on les appelle les fonctions de densité de probabilité. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "Le point principal à l’heure actuelle est que l’aire sous la courbe entière représente la probabilité que quelque chose se produise, qu’un certain nombre apparaisse. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "Cela devrait être 1, c'est pourquoi nous voulons que l'aire en dessous soit 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "Dans l'état actuel des choses avec la forme de base de la courbe en cloche de e au carré négatif de x, l'aire n'est pas 1, c'est en fait la racine carrée de pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "N'est-ce pas? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "Que fait Pi ici ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "Qu'est-ce que cela a à voir avec les cercles ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "Comme je l'ai dit au début, j'aimerais parler de tout cela dans la prochaine vidéo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "Mais si vous pouvez vous enthousiasmer pour nos objectifs du moment, cela signifie simplement que nous devons diviser cette fonction par la racine carrée de pi, et cela nous donne l’aire souhaitée. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "En reprenant les constantes que nous avions plus tôt, la moitié 1 et le sigma, l'effet est d'étirer le graphique d'un facteur sigma multiplié par la racine carrée de 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "Nous devons donc également diviser par cela afin de nous assurer qu’il a une aire de 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "Et en combinant ces fractions, le facteur affiché ressemble à 1 divisé par sigma fois la racine carrée de 2 pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "Il s’agit enfin d’une distribution de probabilité valide. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "Au fur et à mesure que nous ajustons cette valeur sigma, ce qui entraîne des courbes plus étroites et plus larges, cette constante à l'avant garantit toujours que l'aire est égale à 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "Le cas particulier où sigma est égal à 1 a un nom spécifique, nous l'appelons la distribution normale standard, qui joue un rôle particulièrement important pour vous et moi dans cette leçon. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "Et toutes les distributions normales possibles sont non seulement paramétrées avec cette valeur sigma, mais nous soustrayons également une autre constante mu de la variable x, ce qui vous permet essentiellement de faire glisser le graphique vers la gauche et la droite afin que vous puissiez prescrire la moyenne de cette distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "En bref, nous avons deux paramètres, l'un décrivant la moyenne, l'autre décrivant l'écart type, et ils sont tous liés ensemble dans cette grande formule impliquant un e et un pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "Maintenant que tout cela est sur la table, revenons à l'idée de commencer avec une variable aléatoire et demandons à quoi ressemblent les distributions des sommes de cette variable. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "Comme nous l'avons déjà vu, lorsque vous augmentez la taille de cette somme, la distribution résultante se déplace selon une moyenne croissante, et elle s'étale lentement selon un écart type croissant. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "Et en appliquant quelques formules réelles, si nous connaissons la moyenne de notre variable aléatoire sous-jacente, nous l'appelons mu, et nous connaissons également son écart type, et nous l'appelons sigma, alors la moyenne de la somme en bas sera mu fois la taille de la somme, et l'écart type sera égal à sigma fois la racine carrée de cette taille. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "Alors maintenant, si nous voulons affirmer que cela ressemble de plus en plus à une courbe en cloche, et qu’une courbe en cloche n’est décrite que par deux paramètres différents, la moyenne et l’écart type, vous savez quoi faire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "Vous pouvez insérer ces deux valeurs dans la formule, et cela vous donne une formule très explicite, bien que compliquée, pour une courbe qui devrait correspondre étroitement à notre distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "Mais il existe une autre façon de le décrire, un peu plus élégante et qui se prête à un visuel très amusant sur lequel nous pouvons construire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "Au lieu de nous concentrer sur la somme de toutes ces variables aléatoires, modifions un peu cette expression, où nous allons regarder la moyenne que nous nous attendons à ce que cette somme prenne, et nous la soustrayons pour que notre nouvelle expression a une moyenne de 0, puis nous allons examiner l'écart type que nous attendons de notre somme et diviser par cela, ce qui redimensionne simplement les unités de sorte que l'écart type de notre expression soit égal à 1. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "Cela peut sembler une expression plus compliquée, mais elle a en réalité une signification très lisible. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "Il s'agit essentiellement de savoir à combien d'écarts types cette somme s'éloigne de la moyenne ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "Par exemple, cette barre correspond ici à une certaine valeur que vous pourriez trouver lorsque vous lancez 10 dés et que vous les additionnez tous, et sa position un peu au-dessus de moins 1 vous indique que cette valeur est un peu inférieure à un écart type. inférieur à la moyenne. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "En outre, en prévision de l'animation que j'essaie de créer ici, la façon dont je représente les choses sur ce tracé inférieur est que l'aire de chacune de ces barres nous indique la probabilité de la valeur correspondante. plutôt que la hauteur. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "Vous pourriez penser que l’axe des y représente non pas une probabilité mais une sorte de densité de probabilité. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "La raison en est de préparer le terrain pour qu'il corresponde à la façon dont nous interprétons les distributions continues, où la probabilité de se situer entre une plage de valeurs est égale à l'aire sous une courbe entre ces valeurs. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "En particulier, l’aire de toutes les barres ensemble sera de 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "Maintenant que tout cela est en place, amusons-nous un peu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "Permettez-moi de commencer par revenir en arrière pour que la distribution en bas représente une somme relativement petite, comme si l'on additionnait seulement trois de ces variables aléatoires. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "Remarquez ce qui se passe lorsque je change la distribution avec laquelle nous commençons. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "Au fur et à mesure qu'elle change, la répartition sur le fond change complètement de forme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "Cela dépend beaucoup de ce avec quoi nous avons commencé. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "Si nous laissons la taille de notre somme augmenter un peu, disons jusqu'à 10, et que je change la distribution pour x, elle ressemble en grande partie à une courbe en cloche, mais je peux trouver des distributions qui la font changer de forme. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "Par exemple, la courbe vraiment déséquilibrée où presque toute la probabilité est dans les nombres 1 ou 6 donne ce genre de courbe en cloche hérissée, et si vous vous en souvenez, plus tôt, je l'ai montré sous la forme d'une simulation. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "Donc, si vous vous demandiez si ces pics étaient un artefact du hasard ou reflétaient la vraie distribution, il s’avère qu’elle reflète la vraie distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "Dans ce cas, 10 n’est pas une somme suffisamment importante pour que le théorème central limite entre en jeu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "Mais si, à la place, je laisse cette somme croître et que j'envisage d'ajouter 50 valeurs différentes, ce qui n'est en fait pas si grand, alors peu importe la façon dont je modifie la distribution de notre variable aléatoire sous-jacente, cela n'a essentiellement aucun effet sur la forme du tracé sur le bas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "Peu importe où nous commençons, toutes les informations et nuances de la distribution de x sont effacées, et nous tendons vers cette forme universelle unique décrite par une fonction très élégante pour la distribution normale standard, 1 sur racine carrée de 2 pi fois e. au carré x négatif sur 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "C’est là l’essence même du théorème central limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "Presque rien de ce que vous pouvez faire pour modifier cette distribution initiale ne change la forme vers laquelle nous tendons. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "Maintenant, les plus théoriques d’entre vous se demandent peut-être encore quel est le véritable théorème ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "Par exemple, quelle est l'affirmation mathématique qui pourrait être prouvée ou réfutée que nous affirmons ici ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "Si vous voulez une belle déclaration formelle, voici comment cela pourrait se dérouler. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "Considérez cette valeur, où nous résumons n instanciations différentes de notre variable aléatoire, mais modifiées et ajustées pour que sa moyenne et son écart type soient égaux à 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "Encore une fois, cela signifie que vous pouvez le lire comme demandant combien d'écarts types par rapport à la moyenne correspond la somme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "Ensuite, l'énoncé rigoureux et sans blague du théorème central limite est que si vous considérez la probabilité que cette valeur se situe entre deux nombres réels donnés, a et b, et que vous considérez la limite de cette probabilité comme la taille de votre somme va à l'infini, alors cette limite est égale à une certaine intégrale, qui décrit essentiellement l'aire sous une distribution normale standard entre ces deux valeurs. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "Encore une fois, il y a trois hypothèses sous-jacentes que je ne vous ai pas encore expliquées, mais à part celles-là, dans tous ses détails sanglants, voici le théorème central limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "Tout cela est un peu théorique, donc il pourrait être utile de ramener les choses sur Terre et de revenir à l'exemple concret que j'ai évoqué au début, où l'on imagine lancer un dé 100 fois, et supposons que c'est un dé équitable. pour cet exemple, et vous additionnez les résultats. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "Le défi pour vous est de trouver une plage de valeurs telle que vous soyez sûr à 95% que la somme se situera dans cette plage. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "Pour des questions comme celle-ci, il existe une règle empirique pratique concernant les distributions normales, à savoir qu'environ 68% de vos valeurs vont se situer dans un écart type de la moyenne, 95% de vos valeurs, ce qui nous intéresse, se situent dans deux écarts types de la moyenne, et un énorme 99.7% de vos valeurs se situeront dans trois écarts types de la moyenne. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "C'est une règle empirique qui est couramment mémorisée par les personnes qui font beaucoup de probabilités et de statistiques. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "Naturellement, cela nous donne ce dont nous avons besoin pour notre exemple, et permettez-moi de dessiner à quoi cela ressemblerait, où je montrerai la distribution pour un dé équitable en haut, et la distribution pour une somme de 100. de tels dés en bas, qui, comme vous le savez, ressemblent maintenant à une certaine distribution normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "La première étape avec un problème comme celui-ci consiste à trouver la moyenne de votre distribution initiale, qui dans ce cas ressemblera à 1 6ème fois 1 plus 1 6ème fois 2 encore et encore, et s'avère être 3.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "Nous avons également besoin de l'écart type, qui nécessite le calcul de la variance, ce qui, comme vous le savez, implique l'addition de tous les carrés des différences entre les valeurs et les moyennes, et cela s'avère être 2.92, la racine carrée de cela est 1.71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "Ce sont les deux seuls chiffres dont nous avons besoin, et je vous invite à nouveau à réfléchir à quel point il est magique que ce soient les deux seuls chiffres dont vous avez besoin pour comprendre complètement la distribution inférieure. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "Sa moyenne sera de 100 fois mu, soit 350, et son écart type sera la racine carrée de 100 fois sigma, donc 10 fois sigma 17.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "En nous souvenant de notre règle empirique pratique, nous recherchons des valeurs à deux écarts types de la moyenne, et lorsque vous soustrayez 2 sigma de la moyenne, vous obtenez environ 316, et lorsque vous ajoutez 2 sigma, vous obtenez 384. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "Et voilà, cela nous donne la réponse. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "D'accord, j'ai promis de conclure sous peu, mais pendant que nous sommes sur cet exemple, il y a encore une question qui mérite que vous y réfléchissiez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "Au lieu de simplement poser des questions sur la somme de 100 lancers de dés, disons que je vous demande de diviser ce nombre par 100, ce qui signifie essentiellement que tous les nombres de notre diagramme en bas sont divisés par 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "Prenez un moment pour interpréter ce que tout cela dirait alors. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "L'expression vous indique essentiellement la moyenne empirique pour 100 lancers de dés différents, et cet intervalle que nous avons trouvé vous indique maintenant quelle plage vous vous attendez à voir pour cette moyenne empirique. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "En d’autres termes, on pourrait s’attendre à ce qu’il soit autour de 3.5, c'est la valeur attendue pour un lancer de dé, mais ce qui est beaucoup moins évident et ce que le théorème central limite vous permet de calculer, c'est à quel point vous vous trouverez raisonnablement proche de cette valeur attendue. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "En particulier, cela vaut la peine de prendre un moment pour réfléchir à l'écart type de cette moyenne empirique et à ce qui lui arrive lorsque vous examinez un échantillon de plus en plus grand de lancers de dés. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "Enfin, mais probablement le plus important, parlons des hypothèses qui sous-tendent ce théorème. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "La première est que toutes ces variables que nous additionnons sont indépendantes les unes des autres. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "Le résultat d’un processus n’influence pas le résultat d’un autre processus. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "La seconde est que toutes ces variables sont issues de la même distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "Ces deux éléments ont été implicitement supposés avec notre exemple de dés. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "Nous avons traité le résultat de chaque lancer de dé comme indépendant du résultat de tous les autres, et nous supposons que chaque dé suit la même distribution. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "Parfois, dans la littérature, vous verrez ces deux hypothèses regroupées sous les initiales IID pour indépendant et identiquement distribué. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "Une situation dans laquelle ces hypothèses ne sont décidément pas vraies serait celle du conseil d’administration de Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "Je veux dire, pensez-y. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "Est-il vrai que la façon dont une balle rebondit sur l'un des piquets est indépendante de la façon dont elle va rebondir sur le piquet suivant ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "Absolument pas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "En fonction du dernier rebond, il arrive avec une trajectoire complètement différente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "Et est-il vrai que la répartition des résultats possibles pour chaque piquet est la même pour chaque piquet touché ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "Encore une fois, ce n’est certainement pas le cas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "Peut-être qu’il touche un point en jetant un coup d’œil vers la gauche, ce qui signifie que les résultats sont extrêmement biaisés dans cette direction, puis qu’il touche le suivant en jetant un coup d’œil à droite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "Lorsque j’ai fait toutes ces hypothèses simplificatrices dans l’exemple d’ouverture, ce n’était pas seulement pour faciliter la réflexion. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "C'est aussi que ces hypothèses étaient nécessaires pour que cela soit réellement un exemple du théorème central limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "Néanmoins, il semble vrai que pour le vrai tableau Galton, malgré la violation de ces deux principes, une distribution normale se produit en quelque sorte ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "Cela pourrait s'expliquer en partie par le fait qu'il existe des généralisations du théorème dépassant le cadre de cette vidéo et qui assouplissent ces hypothèses, en particulier la seconde. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "Mais je tiens à vous mettre en garde contre le fait que les gens semblent souvent supposer qu'une variable est normalement distribuée, même s'il n'y a aucune justification réelle pour le faire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "La troisième hypothèse est en réalité assez subtile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "C'est que la variance que nous avons calculée pour ces variables est finie. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "Cela n’a jamais été un problème pour l’exemple des dés, car il n’y avait que six résultats possibles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "Mais dans certaines situations où vous avez un ensemble infini de résultats, lorsque vous calculez la variance, la somme finit par diverger vers l'infini. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "Il peut s’agir de distributions de probabilité parfaitement valides, et elles apparaissent dans la pratique. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "Mais dans ces situations, lorsque vous envisagez d'ajouter de nombreuses instanciations différentes de cette variable et de laisser cette somme approcher l'infini, même si les deux premières hypothèses sont valables, il est fort possible que la chose vers laquelle vous tendez ne soit pas réellement une distribution normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "Si vous avez tout compris jusqu’à présent, vous disposez désormais d’une base très solide sur ce qu’est le théorème central limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "Et ensuite, j'aimerais expliquer pourquoi cette fonction particulière est la chose vers laquelle nous tendons, et pourquoi elle contient un pi, ce qu'elle a à voir avec les cercles. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]