1
00:00:00,000 --> 00:00:01,260
Это доска Гальтона. 

2
00:00:02,520 --> 00:00:05,937
Возможно, вы видели такое раньше: это популярная демонстрация того, 

3
00:00:05,937 --> 00:00:10,359
что даже когда одно событие хаотично и случайно, с практически неизвестным результатом, 

4
00:00:10,359 --> 00:00:14,028
все еще возможно делать точные утверждения о большом количестве событий, 

5
00:00:14,028 --> 00:00:18,300
а именно, как относительные пропорции для многих различных результатов распределены. 

6
00:00:20,380 --> 00:00:24,399
Более конкретно, доска Гальтона иллюстрирует одно из наиболее ярких распределений 

7
00:00:24,399 --> 00:00:27,390
во всей вероятности, известное как нормальное распределение, 

8
00:00:27,390 --> 00:00:29,841
в просторечии называемое колоколообразной кривой, 

9
00:00:29,841 --> 00:00:31,900
а также называемое распределением Гаусса. 

10
00:00:32,500 --> 00:00:35,291
Для описания этого распределения есть очень специфическая функция, 

11
00:00:35,291 --> 00:00:38,665
она очень красивая, мы займемся этим позже, но сейчас я просто хочу подчеркнуть, 

12
00:00:38,665 --> 00:00:41,873
что нормальное распределение, как следует из названия, очень распространено, 

13
00:00:41,873 --> 00:00:45,040
оно встречается во многих случаях. из, казалось бы, несвязанных контекстов. 

14
00:00:46,020 --> 00:00:48,266
Если вы возьмете большое количество людей, относящихся к одной и 

15
00:00:48,266 --> 00:00:50,373
той же демографической группе, и нанесете на график их рост, 

16
00:00:50,373 --> 00:00:53,000
то этот рост, как правило, будет соответствовать нормальному распределению. 

17
00:00:53,660 --> 00:00:57,660
Если вы посмотрите на большой набор очень больших натуральных чисел и спросите, 

18
00:00:57,660 --> 00:01:00,859
сколько различных простых делителей имеет каждое из этих чисел, 

19
00:01:00,859 --> 00:01:04,959
ответы будут очень точно соответствовать определенному нормальному распределению. 

20
00:01:05,580 --> 00:01:08,863
Наша сегодняшняя тема — одна из жемчужин всей теории вероятностей, 

21
00:01:08,863 --> 00:01:12,147
это один из ключевых фактов, объясняющих, почему это распределение 

22
00:01:12,147 --> 00:01:16,020
настолько распространено, что оно известно как центральная предельная теорема. 

23
00:01:16,640 --> 00:01:19,881
Этот урок предназначен для того, чтобы вернуться к основам, 

24
00:01:19,881 --> 00:01:24,095
дать вам основные сведения о том, что говорит центральная предельная теорема, 

25
00:01:24,095 --> 00:01:28,580
что такое нормальные распределения, и я хочу предположить минимальную предысторию. 

26
00:01:28,580 --> 00:01:32,721
Мы собираемся углубиться в это, но после этого мне все же хотелось бы пойти глубже 

27
00:01:32,721 --> 00:01:35,266
и объяснить, почему теорема верна, почему функция, 

28
00:01:35,266 --> 00:01:39,109
лежащая в основе нормального распределения, имеет очень специфическую форму, 

29
00:01:39,109 --> 00:01:42,752
почему эта формула имеет в нем есть число «пи», и, что самое интересное, 

30
00:01:42,752 --> 00:01:46,394
почему эти два последних факта на самом деле связаны между собой больше, 

31
00:01:46,394 --> 00:01:48,840
чем предполагают многие традиционные объяснения. 

32
00:01:48,840 --> 00:01:51,608
Этот второй урок также должен стать продолжением обещанного мной 

33
00:01:51,608 --> 00:01:54,590
видео по извилистым волосам, так что здесь много взаимосвязанных тем. 

34
00:01:54,590 --> 00:01:58,251
Но сейчас, возвращаясь к основам, я хотел бы начать 

35
00:01:58,251 --> 00:02:01,490
с чрезмерно упрощенной модели доски Гальтона. 

36
00:02:01,490 --> 00:02:04,554
В этой модели мы будем предполагать, что каждый шар падает прямо на 

37
00:02:04,554 --> 00:02:07,664
определенный центральный колышек и что вероятность его отскока влево 

38
00:02:07,664 --> 00:02:10,684
или вправо составляет 50 на 50, и мы будем думать о каждом из этих 

39
00:02:10,684 --> 00:02:14,110
результатов как о добавлении одного или вычитание единицы из своей позиции. 

40
00:02:14,670 --> 00:02:18,912
Как только один из них выбран, мы делаем крайне нереалистичное предположение, 

41
00:02:18,912 --> 00:02:22,719
что он случайно приземлится в середине колышка, примыкающего под ним, 

42
00:02:22,719 --> 00:02:27,070
где он снова столкнется с тем же выбором 50 на 50: отскочить влево или Направо. 

43
00:02:27,430 --> 00:02:30,942
Для того, что я показываю на экране, есть пять разных рядов колышков, 

44
00:02:30,942 --> 00:02:34,706
поэтому наш маленький прыгающий шарик делает пять разных случайных выборов 

45
00:02:34,706 --> 00:02:38,370
между плюс один и минус один, и мы можем думать о его конечном положении 

46
00:02:38,370 --> 00:02:42,485
как о сумме всех из этих разных чисел, которое в данном случае оказывается одним, 

47
00:02:42,485 --> 00:02:46,350
и мы могли бы пометить все разные сегменты суммой, которую они представляют. 

48
00:02:46,350 --> 00:02:51,290
Повторяя это, мы рассматриваем различные возможные суммы этих пяти случайных чисел. 

49
00:02:53,050 --> 00:02:55,250
А для тех из вас, кто склонен жаловаться на то, 

50
00:02:55,250 --> 00:02:58,139
что это крайне нереалистичная модель настоящей платы Гальтона, 

51
00:02:58,139 --> 00:03:01,670
позвольте мне подчеркнуть, что цель сейчас не в точном моделировании физики. 

52
00:03:01,830 --> 00:03:03,858
Цель состоит в том, чтобы дать простой пример, 

53
00:03:03,858 --> 00:03:06,016
иллюстрирующий центральную предельную теорему, и, 

54
00:03:06,016 --> 00:03:08,735
каким бы идеализированным он ни был, на самом деле он дает нам 

55
00:03:08,735 --> 00:03:10,030
действительно хороший пример. 

56
00:03:10,570 --> 00:03:12,469
Если мы позволим упасть множеству разных шаров, 

57
00:03:12,469 --> 00:03:15,595
сделав еще одно нереалистичное предположение, что они не влияют друг на друга, 

58
00:03:15,595 --> 00:03:19,077
как если бы они все были призраками, тогда количество шаров, попадающих в каждое ведро, 

59
00:03:19,077 --> 00:03:22,598
даст нам некоторое неопределенное представление о том, насколько вероятен каждый из них. 

60
00:03:22,598 --> 00:03:23,390
из этих ведер есть. 

61
00:03:23,830 --> 00:03:27,032
В этом примере числа достаточно просты, поэтому нетрудно 

62
00:03:27,032 --> 00:03:30,010
явно вычислить вероятность попадания в каждое ведро. 

63
00:03:30,270 --> 00:03:32,050
Если вы захотите обдумать это, вы обнаружите, 

64
00:03:32,050 --> 00:03:33,830
что это очень напоминает треугольник Паскаля. 

65
00:03:33,950 --> 00:03:38,270
Но самое интересное в нашей теореме то, что она выходит далеко за рамки простых примеров. 

66
00:03:38,670 --> 00:03:41,821
Итак, по крайней мере, для начала, вместо того, чтобы проводить явные вычисления, 

67
00:03:41,821 --> 00:03:44,627
давайте просто смоделируем ситуацию, запустив большое количество выборок 

68
00:03:44,627 --> 00:03:47,394
и позволив общему количеству результатов в каждом отдельном исходе дать 

69
00:03:47,394 --> 00:03:49,970
нам некоторое представление о том, как выглядит это распределение. 

70
00:03:50,450 --> 00:03:53,467
Как я уже сказал, на экране пять строк, поэтому каждая 

71
00:03:53,467 --> 00:03:56,210
рассматриваемая сумма включает только пять чисел. 

72
00:03:56,810 --> 00:03:59,975
Основная идея центральной предельной теоремы заключается в том, 

73
00:03:59,975 --> 00:04:02,794
что если вы увеличите размер этой суммы, например здесь, 

74
00:04:02,794 --> 00:04:06,454
это будет означать увеличение количества рядов колышков для каждого шара, 

75
00:04:06,454 --> 00:04:10,659
от которого отскочит, тогда распределение, которое описывает, куда пойдет эта сумма. 

76
00:04:10,659 --> 00:04:13,330
падение все больше похоже на колоколообразную кривую. 

77
00:04:15,470 --> 00:04:18,350
Здесь действительно стоит потратить время на то, чтобы записать эту общую идею. 

78
00:04:19,269 --> 00:04:22,995
Установка такова, что у нас есть случайная переменная, и это, по сути, 

79
00:04:22,995 --> 00:04:27,245
сокращение для случайного процесса, где каждый результат этого процесса связан с 

80
00:04:27,245 --> 00:04:28,190
некоторым числом. 

81
00:04:28,490 --> 00:04:29,970
Мы назовем это случайное число x. 

82
00:04:29,970 --> 00:04:32,900
Например, каждый отскок от прищепки — это случайный процесс, 

83
00:04:32,900 --> 00:04:34,390
моделируемый с двумя исходами. 

84
00:04:34,850 --> 00:04:37,890
Эти результаты связаны с числами «отрицательный» и «положительный». 

85
00:04:38,530 --> 00:04:41,219
Другим примером случайной величины может быть бросок игральной кости, 

86
00:04:41,219 --> 00:04:43,485
в результате которого у вас есть шесть разных результатов, 

87
00:04:43,485 --> 00:04:44,830
каждый из которых связан с числом. 

88
00:04:45,470 --> 00:04:50,410
Мы берем несколько разных образцов этой переменной и складываем их все вместе. 

89
00:04:50,770 --> 00:04:54,008
На нашей доске Гальтона это выглядит так, будто мяч отскакивает от 

90
00:04:54,008 --> 00:04:58,117
нескольких разных колышков на пути вниз, а в случае с кубиком вы можете представить, 

91
00:04:58,117 --> 00:05:00,970
что бросаете много разных кубиков и суммируете результаты. 

92
00:05:01,430 --> 00:05:04,642
Утверждение центральной предельной теоремы состоит в том, что по мере того, 

93
00:05:04,642 --> 00:05:07,600
как вы позволяете размеру этой суммы становиться все больше и больше, 

94
00:05:07,600 --> 00:05:10,644
распределение этой суммы, вероятность того, что она попадет в различные 

95
00:05:10,644 --> 00:05:14,110
возможные значения, будет все больше и больше напоминать колоколообразную кривую. 

96
00:05:15,430 --> 00:05:17,130
Вот и все, это общая идея. 

97
00:05:17,550 --> 00:05:21,530
В ходе этого урока наша задача — сделать это утверждение более количественным. 

98
00:05:22,070 --> 00:05:24,479
Мы собираемся добавить к нему некоторые цифры, формулы и показать, 

99
00:05:24,479 --> 00:05:26,350
как вы можете использовать его для прогнозирования. 

100
00:05:27,210 --> 00:05:31,570
Например, вот вопрос, на который я хочу, чтобы вы смогли ответить к концу этого видео. 

101
00:05:32,190 --> 00:05:35,890
Предположим, вы бросили игральную кость 100 раз и сложили результаты. 

102
00:05:36,630 --> 00:05:40,391
Можете ли вы найти такой диапазон значений, в котором вы на 95 % уверены, 

103
00:05:40,391 --> 00:05:42,170
что сумма попадет в этот диапазон? 

104
00:05:42,830 --> 00:05:45,661
Или, может быть, мне следует сказать: найдите наименьший возможный диапазон значений, 

105
00:05:45,661 --> 00:05:46,550
в котором это будет верно. 

106
00:05:47,390 --> 00:05:49,983
Самое интересное, что вы сможете ответить на этот вопрос, 

107
00:05:49,983 --> 00:05:52,130
является ли это честным кубиком или взвешенным. 

108
00:05:53,450 --> 00:05:56,654
Теперь позвольте мне сказать вверху, что эта теорема включает в себя три различных 

109
00:05:56,654 --> 00:06:00,130
предположения, три вещи, которые должны быть верными, прежде чем из нее вытекает теорема. 

110
00:06:00,430 --> 00:06:03,790
И я на самом деле не собираюсь рассказывать вам, что это такое, до самого конца видео. 

111
00:06:04,270 --> 00:06:06,630
Вместо этого я хочу, чтобы вы внимательно наблюдали и посмотрели, 

112
00:06:06,630 --> 00:06:09,670
сможете ли вы заметить и, возможно, предсказать, какими будут эти три предположения. 

113
00:06:10,710 --> 00:06:12,875
В качестве следующего шага, чтобы лучше проиллюстрировать, 

114
00:06:12,875 --> 00:06:15,885
насколько общей является эта теорема, я хочу провести для вас еще пару симуляций, 

115
00:06:15,885 --> 00:06:17,390
сосредоточенных на примере игры в кости. 

116
00:06:20,910 --> 00:06:23,870
Обычно, когда вы думаете о броске игральной кости, вы думаете, 

117
00:06:23,870 --> 00:06:27,630
что шесть исходов равновероятны, но на самом деле теорема не заботится об этом. 

118
00:06:27,830 --> 00:06:31,216
Мы могли бы начать с взвешенной кости, чего-то с нетривиальным 

119
00:06:31,216 --> 00:06:34,550
распределением результатов, и основная идея останется в силе. 

120
00:06:35,030 --> 00:06:37,411
Для моделирования я возьму некоторое распределение, 

121
00:06:37,411 --> 00:06:39,930
подобное этому, со сдвигом в сторону меньших значений. 

122
00:06:40,250 --> 00:06:43,968
Я возьму 10 различных выборок из этого распределения, 

123
00:06:43,968 --> 00:06:47,550
а затем запишу сумму этой выборки на графике внизу. 

124
00:06:48,630 --> 00:06:50,696
Затем я собираюсь сделать это много-много раз, 

125
00:06:50,696 --> 00:06:54,567
всегда с суммой размером 10, но отслеживайте, где в конечном итоге оказались эти суммы, 

126
00:06:54,567 --> 00:06:56,590
чтобы дать нам представление о распределении. 

127
00:06:59,970 --> 00:07:02,280
И на самом деле, позвольте мне изменить масштаб по направлению y, 

128
00:07:02,280 --> 00:07:04,730
чтобы дать нам возможность выполнить еще большее количество образцов. 

129
00:07:05,030 --> 00:07:08,484
И я позволю этому увеличиться до пары тысяч, и при этом вы заметите, 

130
00:07:08,484 --> 00:07:12,490
что фигура, которая начинает проявляться, выглядит как колоколообразная кривая. 

131
00:07:12,870 --> 00:07:16,461
Возможно, если вы прищуритесь, вы увидите, что он немного смещается влево, 

132
00:07:16,461 --> 00:07:20,674
но это здорово, что что-то столь симметричное возникло из такой асимметричной отправной 

133
00:07:20,674 --> 00:07:21,010
точки. 

134
00:07:21,470 --> 00:07:24,507
Чтобы лучше проиллюстрировать суть центральной предельной теоремы, 

135
00:07:24,507 --> 00:07:27,408
позвольте мне запустить четыре таких моделирования параллельно: 

136
00:07:27,408 --> 00:07:31,397
в левом верхнем углу я делаю это, когда мы добавляем только две игральные кости за раз, 

137
00:07:31,397 --> 00:07:34,933
а в верхнем правом мы: Мы делаем это, когда мы добавляем пять кубиков за раз, 

138
00:07:34,933 --> 00:07:38,786
нижний левый — это тот, который мы только что видели, добавляя по 10 кубиков за раз, 

139
00:07:38,786 --> 00:07:41,370
а затем мы сделаем еще один с большей суммой, 15 за раз. 

140
00:07:42,250 --> 00:07:45,675
Обратите внимание, что в левом верхнем углу, когда мы просто добавляем два кубика, 

141
00:07:45,675 --> 00:07:48,976
полученное распределение на самом деле не выглядит как колоколообразная кривая, 

142
00:07:48,976 --> 00:07:52,030
оно намного больше напоминает то, с которым мы начали, с перекосом влево. 

143
00:07:52,810 --> 00:07:55,726
Но поскольку мы учитываем все больше и больше кубиков в каждой сумме, 

144
00:07:55,726 --> 00:07:58,101
результирующая форма, возникающая в этих распределениях, 

145
00:07:58,101 --> 00:07:59,810
выглядит все более и более симметричной. 

146
00:07:59,950 --> 00:08:03,890
У него есть выступ посередине, а хвост плавно переходит в колоколообразную форму. 

147
00:08:07,050 --> 00:08:10,490
И еще раз подчеркну: начать можно с любого другого дистрибутива. 

148
00:08:10,490 --> 00:08:14,838
Здесь я запущу его еще раз, но большая часть вероятности связана с числами 1 и 6, 

149
00:08:14,838 --> 00:08:17,490
с очень низкой вероятностью для средних значений. 

150
00:08:18,190 --> 00:08:22,107
Несмотря на полное изменение распределения для отдельного броска игральной кости, 

151
00:08:22,107 --> 00:08:24,639
форма колоколообразной кривой по-прежнему возникает, 

152
00:08:24,639 --> 00:08:26,550
когда мы рассматриваем различные суммы. 

153
00:08:27,270 --> 00:08:31,332
Иллюстрировать вещи с помощью такой симуляции очень весело, и приятно видеть, 

154
00:08:31,332 --> 00:08:35,030
как порядок возникает из хаоса, но это также кажется немного неточным. 

155
00:08:35,390 --> 00:08:38,480
Как в этом случае, когда я отсек симуляцию на 3000 выборках, 

156
00:08:38,480 --> 00:08:42,990
хотя она выглядит как колоколообразная кривая, разные сегменты кажутся довольно резкими. 

157
00:08:42,990 --> 00:08:45,512
И вы можете задаться вопросом, так ли это должно 

158
00:08:45,512 --> 00:08:48,550
выглядеть или это просто артефакт случайности в симуляции? 

159
00:08:49,010 --> 00:08:51,964
И если да, то сколько образцов нам нужно, прежде чем мы сможем быть уверены, 

160
00:08:51,964 --> 00:08:55,110
что то, на что мы смотрим, является репрезентативным для истинного распределения? 

161
00:08:59,190 --> 00:09:02,212
Вместо того, чтобы двигаться вперед, давайте немного больше теоретического и 

162
00:09:02,212 --> 00:09:05,470
покажем точную форму, которую эти распределения примут в долгосрочной перспективе. 

163
00:09:06,130 --> 00:09:10,153
Проще всего выполнить этот расчет, если у нас есть равномерное распределение, 

164
00:09:10,153 --> 00:09:13,970
где каждая возможная грань игральной кости имеет равную вероятность, 1/6. 

165
00:09:13,990 --> 00:09:17,486
Например, если вы затем хотите узнать, насколько вероятны разные суммы для 

166
00:09:17,486 --> 00:09:21,216
пары игральных костей, это, по сути, игра подсчета, в которой вы подсчитываете, 

167
00:09:21,216 --> 00:09:24,526
сколько различных пар составляют одну и ту же сумму, что на диаграмме, 

168
00:09:24,526 --> 00:09:28,490
которую я нарисовал, вы можно удобно обдумать, пройдя через все различные диагонали. 

169
00:09:31,410 --> 00:09:34,869
Поскольку вероятность появления каждой такой пары равна 1 из 36, 

170
00:09:34,869 --> 00:09:37,530
вам остается только посчитать размеры этих ведер. 

171
00:09:38,190 --> 00:09:42,450
Это дает нам окончательную форму распределения, описывающего сумму двух игральных костей, 

172
00:09:42,450 --> 00:09:45,432
и если бы мы играли в ту же игру со всеми возможными тройками, 

173
00:09:45,432 --> 00:09:48,130
полученное распределение выглядело бы следующим образом. 

174
00:09:48,690 --> 00:09:51,880
Теперь, что более сложно, но гораздо интереснее, это спросить, что произойдет, 

175
00:09:51,880 --> 00:09:54,990
если у нас будет неравномерное распределение для этого единственного кубика. 

176
00:09:55,550 --> 00:09:57,970
Обо всём этом мы, собственно, и говорили в прошлом видео. 

177
00:09:58,450 --> 00:10:01,901
По сути, вы делаете то же самое: перебираете все различные пары игральных костей, 

178
00:10:01,901 --> 00:10:03,670
сумма которых дает одно и то же значение. 

179
00:10:03,970 --> 00:10:08,169
Просто вместо того, чтобы считать эти пары, вы для каждой пары умножаете две 

180
00:10:08,169 --> 00:10:12,750
вероятности появления каждого конкретного лица, а затем складываете все это вместе. 

181
00:10:13,290 --> 00:10:17,408
Вычисление, которое делает это для всех возможных сумм, имеет причудливое название, 

182
00:10:17,408 --> 00:10:21,331
оно называется сверткой, но по сути это просто взвешенная версия игры подсчета, 

183
00:10:21,331 --> 00:10:24,470
которая уже знакома любому, кто играл с парой игральных костей. 

184
00:10:25,030 --> 00:10:28,463
Для целей этого урока я попрошу компьютер все это рассчитать, 

185
00:10:28,463 --> 00:10:33,391
просто отобразить вам результаты и предложить вам наблюдать определенные закономерности, 

186
00:10:33,391 --> 00:10:35,330
но под капотом происходит вот что. 

187
00:10:36,650 --> 00:10:40,483
Итак, чтобы внести ясность в то, что здесь представлено, если вы представите, 

188
00:10:40,483 --> 00:10:43,776
что выбираете два разных значения из этого верхнего распределения, 

189
00:10:43,776 --> 00:10:47,904
описывающего одну игральную кость, и суммируете их вместе, то второе распределение, 

190
00:10:47,904 --> 00:10:52,230
которое я рисую, показывает, насколько вероятно, что вы увидеть различные разные суммы. 

191
00:10:52,890 --> 00:10:56,105
Аналогично, если вы представите себе выборку трех различных значений 

192
00:10:56,105 --> 00:10:58,622
из этого верхнего распределения и сложение их вместе, 

193
00:10:58,622 --> 00:11:02,490
следующий график представляет вероятности для различных разных сумм в этом случае. 

194
00:11:03,510 --> 00:11:06,397
Итак, если я вычислю, как будут выглядеть распределения этих сумм 

195
00:11:06,397 --> 00:11:09,546
для все больших и больших сумм, ну, вы знаете, что я собираюсь сказать, 

196
00:11:09,546 --> 00:11:12,390
это все больше и больше будет похоже на колоколообразную кривую. 

197
00:11:13,350 --> 00:11:16,450
Но прежде чем мы перейдем к этому, я хочу, чтобы вы сделали еще пару простых наблюдений. 

198
00:11:17,450 --> 00:11:20,942
Например, кажется, что эти распределения смещаются вправо, 

199
00:11:20,942 --> 00:11:24,790
а также становятся более разбросанными и немного более плоскими. 

200
00:11:25,250 --> 00:11:28,020
Вы не можете описать центральную предельную теорему количественно, 

201
00:11:28,020 --> 00:11:30,626
не принимая во внимание оба этих эффекта, что, в свою очередь, 

202
00:11:30,626 --> 00:11:33,190
требует описания среднего значения и стандартного отклонения. 

203
00:11:33,950 --> 00:11:37,468
Возможно, вы уже знакомы с ними, но я хочу сделать здесь минимальные предположения, 

204
00:11:37,468 --> 00:11:40,610
и обзор никогда не помешает, поэтому давайте быстро рассмотрим оба из них. 

205
00:11:43,410 --> 00:11:47,085
Среднее значение распределения, часто обозначаемое греческой буквой мю, 

206
00:11:47,085 --> 00:11:50,710
представляет собой способ определения центра масс этого распределения. 

207
00:11:51,190 --> 00:11:55,341
Оно рассчитывается как ожидаемое значение нашей случайной величины, 

208
00:11:55,341 --> 00:11:59,004
что означает, что вы перебираете все возможные результаты и 

209
00:11:59,004 --> 00:12:02,850
умножаете вероятность этого результата на значение переменной. 

210
00:12:03,190 --> 00:12:06,410
Если более высокие значения более вероятны, эта взвешенная сумма будет больше. 

211
00:12:06,750 --> 00:12:09,950
Если более низкие значения более вероятны, эта взвешенная сумма будет меньше. 

212
00:12:10,790 --> 00:12:14,708
Немного интереснее, если вы хотите измерить, насколько распространено это распределение, 

213
00:12:14,708 --> 00:12:17,130
потому что есть несколько разных способов сделать это. 

214
00:12:18,530 --> 00:12:20,290
Один из них называется дисперсией. 

215
00:12:20,830 --> 00:12:24,437
Идея состоит в том, чтобы посмотреть разницу между каждым возможным значением и 

216
00:12:24,437 --> 00:12:28,270
средним значением, возвести эту разницу в квадрат и запросить ее ожидаемое значение. 

217
00:12:28,730 --> 00:12:31,345
Идея состоит в том, что независимо от того, находится ли ваше значение 

218
00:12:31,345 --> 00:12:33,776
ниже или выше среднего, когда вы возводите эту разницу в квадрат, 

219
00:12:33,776 --> 00:12:36,650
вы получаете положительное число, и чем больше разница, тем больше это число. 

220
00:12:37,369 --> 00:12:39,992
Возведение в квадрат таким образом делает математические вычисления 

221
00:12:39,992 --> 00:12:43,077
намного более точными, чем если бы мы делали что-то вроде абсолютного значения, 

222
00:12:43,077 --> 00:12:45,700
но недостатком является то, что на нашей диаграмме трудно думать об 

223
00:12:45,700 --> 00:12:48,130
этом как о расстоянии, потому что единицы измерения отключены. 

224
00:12:48,330 --> 00:12:50,290
Вроде как единицы здесь — это квадратные единицы, 

225
00:12:50,290 --> 00:12:53,310
тогда как расстояние на нашей диаграмме будет своего рода линейной единицей. 

226
00:12:53,710 --> 00:12:56,565
Итак, еще один способ измерения разброса — это так называемое стандартное отклонение, 

227
00:12:56,565 --> 00:12:58,690
которое представляет собой квадратный корень из этого значения. 

228
00:12:58,690 --> 00:13:02,558
Гораздо более разумно это можно интерпретировать как расстояние на нашей диаграмме, 

229
00:13:02,558 --> 00:13:05,735
и оно обычно обозначается греческой буквой сигма, поэтому вы знаете, 

230
00:13:05,735 --> 00:13:09,650
что m означает среднее значение и стандартное отклонение, но оба на греческом языке. 

231
00:13:11,870 --> 00:13:14,122
Оглядываясь назад на нашу последовательность распределений, 

232
00:13:14,122 --> 00:13:16,150
давайте поговорим о среднем и стандартном отклонении. 

233
00:13:16,630 --> 00:13:19,569
Если мы назовем среднее значение начального распределения mu, 

234
00:13:19,569 --> 00:13:23,126
которое для иллюстрированного случая равно 2.24, надеюсь, вы не удивитесь, 

235
00:13:23,126 --> 00:13:26,730
если я скажу вам, что среднее значение следующего числа в 2 раза больше му. 

236
00:13:27,130 --> 00:13:30,375
То есть вы бросаете пару игральных костей и хотите узнать ожидаемое значение суммы, 

237
00:13:30,375 --> 00:13:32,810
оно в два раза превышает ожидаемое значение для одного кубика. 

238
00:13:33,850 --> 00:13:37,790
Аналогично, ожидаемое значение нашей суммы размера 3 в 3 раза больше мю, 

239
00:13:37,790 --> 00:13:39,410
и так далее, и тому подобное. 

240
00:13:39,630 --> 00:13:43,059
Среднее значение неуклонно движется вправо, поэтому наши распределения, 

241
00:13:43,059 --> 00:13:44,870
похоже, смещаются в этом направлении. 

242
00:13:45,350 --> 00:13:49,910
Немного сложнее, но очень важно описать, как изменяется стандартное отклонение. 

243
00:13:50,490 --> 00:13:54,618
Ключевым фактом здесь является то, что если у вас есть две разные случайные величины, 

244
00:13:54,618 --> 00:13:57,498
то дисперсия суммы этих переменных такая же, как если бы вы 

245
00:13:57,498 --> 00:13:59,370
просто сложили две исходные дисперсии. 

246
00:13:59,930 --> 00:14:03,630
Это один из тех фактов, которые можно просто вычислить, распаковав все определения. 

247
00:14:03,630 --> 00:14:06,210
Есть пара хороших предположений, почему это правда. 

248
00:14:06,630 --> 00:14:09,998
Мой предварительный план состоит в том, чтобы просто сделать серию о вероятности и 

249
00:14:09,998 --> 00:14:13,530
рассказать о таких вещах, как интуиция, лежащая в основе дисперсии, и ее родственники. 

250
00:14:14,010 --> 00:14:16,992
Но сейчас главное, что я хочу, чтобы вы подчеркнули, это то, 

251
00:14:16,992 --> 00:14:19,730
что добавляется дисперсия, а не стандартное отклонение. 

252
00:14:19,730 --> 00:14:24,116
Итак, что особенно важно, если вы возьмете n различных реализаций одной и той же 

253
00:14:24,116 --> 00:14:26,878
случайной величины и спросите, как выглядит сумма, 

254
00:14:26,878 --> 00:14:30,993
дисперсия этой суммы в n раз превышает дисперсию вашей исходной переменной, 

255
00:14:30,993 --> 00:14:35,650
то есть стандартное отклонение, квадратный корень из всех это квадратный корень из n, 

256
00:14:35,650 --> 00:14:38,250
умноженного на исходное стандартное отклонение. 

257
00:14:39,290 --> 00:14:41,970
Например, вернемся к нашей последовательности распределений, 

258
00:14:41,970 --> 00:14:45,530
если мы обозначим стандартное отклонение нашего начального распределения сигмой, 

259
00:14:45,530 --> 00:14:48,651
то следующее стандартное отклонение будет квадратным корнем из 2 сигм, 

260
00:14:48,651 --> 00:14:52,079
и после этого оно будет выглядеть как квадратный корень из 3 раза сигма и так 

261
00:14:52,079 --> 00:14:53,090
далее и тому подобное. 

262
00:14:53,750 --> 00:14:55,650
Это, как я уже сказал, очень важно. 

263
00:14:56,070 --> 00:14:59,150
Это означает, что хотя наши распределения и распределяются, 

264
00:14:59,150 --> 00:15:03,205
они распространяются не так быстро, а только пропорционально квадратному корню 

265
00:15:03,205 --> 00:15:04,130
из размера суммы. 

266
00:15:04,710 --> 00:15:08,448
Пока мы готовимся к более количественному описанию центральной предельной теоремы, 

267
00:15:08,448 --> 00:15:12,457
основная интуиция, которую я хочу, чтобы вы держали в голове, заключается в том, что мы, 

268
00:15:12,457 --> 00:15:14,574
по сути, перестроим все эти распределения так, 

269
00:15:14,574 --> 00:15:18,538
чтобы их средние значения выровнялись вместе, а затем изменим их масштаб таким образом. 

270
00:15:18,538 --> 00:15:20,610
что все стандартные отклонения будут равны 1. 

271
00:15:21,290 --> 00:15:24,202
И когда мы это делаем, получаемая в результате форма становится все ближе 

272
00:15:24,202 --> 00:15:27,233
и ближе к определенной универсальной форме, описываемой с помощью элегантной 

273
00:15:27,233 --> 00:15:29,870
маленькой функции, которую мы распакуем буквально через мгновение. 

274
00:15:30,470 --> 00:15:33,939
И позвольте мне сказать еще раз: настоящее волшебство заключается в том, 

275
00:15:33,939 --> 00:15:37,979
что мы могли бы начать с любого распределения, описывая один бросок игральной кости, 

276
00:15:37,979 --> 00:15:40,212
и если мы будем играть в ту же игру, учитывая, 

277
00:15:40,212 --> 00:15:44,062
как выглядят распределения для множества разных сумм: и мы перестраиваем их так, 

278
00:15:44,062 --> 00:15:46,771
чтобы средние значения совпадали, и масштабируем их так, 

279
00:15:46,771 --> 00:15:49,005
чтобы все стандартные отклонения были равны 1, 

280
00:15:49,005 --> 00:15:52,950
мы все равно приближаемся к той же универсальной форме, которая просто ошеломляет. 

281
00:15:54,810 --> 00:15:57,749
И сейчас, друзья мои, возможно, самое подходящее время 

282
00:15:57,749 --> 00:16:00,850
наконец разобраться с формулой нормального распределения. 

283
00:16:01,490 --> 00:16:03,318
И то, как я хотел бы это сделать, состоит в том, 

284
00:16:03,318 --> 00:16:05,930
чтобы по сути снять все слои и построить их по одному кусочку за раз. 

285
00:16:06,530 --> 00:16:09,922
Функция e для x или что-то еще для x описывает экспоненциальный рост, 

286
00:16:09,922 --> 00:16:12,345
и если вы сделаете этот показатель отрицательным, 

287
00:16:12,345 --> 00:16:16,028
который переворачивает график по горизонтали, вы можете думать о нем как об 

288
00:16:16,028 --> 00:16:17,870
описании экспоненциального затухания. 

289
00:16:18,510 --> 00:16:20,340
Чтобы сделать это затухание в обоих направлениях, 

290
00:16:20,340 --> 00:16:23,526
вы можете сделать что-нибудь, чтобы показатель степени всегда был отрицательным и рос, 

291
00:16:23,526 --> 00:16:25,430
например, приняв отрицательное абсолютное значение. 

292
00:16:25,930 --> 00:16:28,189
Это дало бы нам неуклюжую острую точку посередине, 

293
00:16:28,189 --> 00:16:31,556
но если вместо этого вы сделаете этот показатель отрицательным квадратом x, 

294
00:16:31,556 --> 00:16:34,082
вы получите более гладкую версию того же самого объекта, 

295
00:16:34,082 --> 00:16:35,810
который затухает в обоих направлениях. 

296
00:16:36,330 --> 00:16:38,190
Это дает нам базовую форму колоколообразной кривой. 

297
00:16:38,650 --> 00:16:41,931
Теперь, если вы поместите константу перед этим x и масштабируете эту константу 

298
00:16:41,931 --> 00:16:45,088
вверх и вниз, это позволит вам растягивать и сжимать график по горизонтали, 

299
00:16:45,088 --> 00:16:48,370
позволяя вам описывать узкие и более широкие кривые нормального распределения. 

300
00:16:49,010 --> 00:16:53,284
И я хотел бы сразу отметить, что, основываясь на правилах возведения в степень, 

301
00:16:53,284 --> 00:16:56,757
когда мы настраиваем константу c, вы также можете думать об этом 

302
00:16:56,757 --> 00:16:59,750
как о простом изменении основания возведения в степень. 

303
00:17:00,150 --> 00:17:03,630
И в этом смысле число e не является чем-то особенным для нашей формулы. 

304
00:17:04,050 --> 00:17:06,948
Мы могли бы заменить ее любой другой положительной константой, 

305
00:17:06,948 --> 00:17:10,490
и вы получите то же самое семейство кривых, когда мы настроим эту константу. 

306
00:17:11,510 --> 00:17:13,109
Пусть это будет 2, одно и то же семейство кривых. 

307
00:17:13,329 --> 00:17:15,069
Пусть это будет цифра 3, одно и то же семейство кривых. 

308
00:17:15,750 --> 00:17:17,763
Причина, по которой мы используем e, заключается в том, 

309
00:17:17,763 --> 00:17:19,490
что это придает константе очень понятный смысл. 

310
00:17:20,109 --> 00:17:22,608
Или, скорее, если мы немного изменим ситуацию так, 

311
00:17:22,608 --> 00:17:26,871
чтобы показатель степени выглядел как отрицательный, равный половине умноженного на х, 

312
00:17:26,871 --> 00:17:30,448
деленного на определенную константу, которую мы назовем квадратом сигмы, 

313
00:17:30,448 --> 00:17:33,437
то как только мы превратим это в распределение вероятностей, 

314
00:17:33,437 --> 00:17:37,210
эта постоянная сигма будет быть стандартным отклонением этого распределения. 

315
00:17:37,810 --> 00:17:38,570
И это очень приятно. 

316
00:17:38,910 --> 00:17:42,184
Но прежде чем мы сможем интерпретировать это как распределение вероятностей, 

317
00:17:42,184 --> 00:17:44,310
нам нужно, чтобы площадь под кривой была равна 1. 

318
00:17:44,830 --> 00:17:46,910
Причина этого в том, как интерпретируется кривая. 

319
00:17:47,370 --> 00:17:51,007
В отличие от дискретных распределений, когда речь идет о чем-то непрерывном, 

320
00:17:51,007 --> 00:17:53,370
вы не спрашиваете о вероятности конкретной точки. 

321
00:17:53,790 --> 00:17:55,856
Вместо этого вы запрашиваете вероятность того, 

322
00:17:55,856 --> 00:17:58,230
что значение попадает между двумя разными значениями. 

323
00:17:58,750 --> 00:18:02,055
И кривая говорит вам, что эта вероятность равна 

324
00:18:02,055 --> 00:18:05,430
площади под кривой между этими двумя значениями. 

325
00:18:06,030 --> 00:18:09,430
Об этом есть совершенно другое видео, они называются функциями плотности вероятности. 

326
00:18:09,830 --> 00:18:14,256
Главное сейчас то, что площадь под всей кривой представляет вероятность того, 

327
00:18:14,256 --> 00:18:17,150
что что-то произойдет, что выпадет какое-то число. 

328
00:18:17,410 --> 00:18:20,630
Это должно быть 1, поэтому мы хотим, чтобы площадь под ним была равна 1. 

329
00:18:21,050 --> 00:18:24,377
В соответствии с базовой формой колоколообразной кривой от e до отрицательного 

330
00:18:24,377 --> 00:18:27,790
квадрата x, площадь не равна 1, на самом деле это квадратный корень из числа Пи. 

331
00:18:28,410 --> 00:18:29,150
Я точно знаю? 

332
00:18:29,270 --> 00:18:30,190
Что здесь делает Пи? 

333
00:18:30,290 --> 00:18:31,470
Какое это имеет отношение к кругам? 

334
00:18:32,010 --> 00:18:35,050
Как я уже сказал в начале, мне бы хотелось поговорить обо всем этом в следующем видео. 

335
00:18:35,330 --> 00:18:38,147
Но если вы можете прямо сейчас потратить свое волнение на наши цели, 

336
00:18:38,147 --> 00:18:41,740
все это означает, что нам нужно разделить эту функцию на квадратный корень из числа пи, 

337
00:18:41,740 --> 00:18:43,170
и это даст нам нужную нам площадь. 

338
00:18:43,610 --> 00:18:47,450
Возвращаясь к константам, которые мы использовали ранее, 1 половине и сигме, 

339
00:18:47,450 --> 00:18:51,790
мы получаем эффект растягивания графика в сигму, умноженную на квадратный корень из 2. 

340
00:18:52,410 --> 00:18:54,636
Поэтому нам также нужно разделить на это значение, 

341
00:18:54,636 --> 00:18:56,470
чтобы убедиться, что его площадь равна 1. 

342
00:18:56,470 --> 00:18:58,965
И, объединив эти дроби, множитель выглядит как 1, 

343
00:18:58,965 --> 00:19:02,110
разделенная на сигму, умноженную на квадратный корень из 2 пи. 

344
00:19:02,910 --> 00:19:05,850
Наконец, это действительное распределение вероятностей. 

345
00:19:06,450 --> 00:19:10,986
Когда мы настраиваем это значение сигмы, что приводит к более узким и широким кривым, 

346
00:19:10,986 --> 00:19:14,310
эта константа спереди всегда гарантирует, что площадь равна 1. 

347
00:19:15,910 --> 00:19:18,744
Особый случай, когда сигма равна 1, имеет особое название, 

348
00:19:18,744 --> 00:19:21,387
мы называем его стандартным нормальным распределением, 

349
00:19:21,387 --> 00:19:24,510
которое играет для нас с вами в этом уроке особенно важную роль. 

350
00:19:25,130 --> 00:19:29,906
И все возможные нормальные распределения не только параметризуются этим значением сигма, 

351
00:19:29,906 --> 00:19:33,501
но мы также вычитаем еще одну константу мю из переменной x, и это, 

352
00:19:33,501 --> 00:19:36,829
по сути, просто позволяет вам сдвигать график влево и вправо, 

353
00:19:36,829 --> 00:19:40,210
чтобы вы могли прописать среднее значение этого распределения. 

354
00:19:40,990 --> 00:19:44,601
Короче говоря, у нас есть два параметра: один описывает среднее значение, 

355
00:19:44,601 --> 00:19:48,262
другой — стандартное отклонение, и все они связаны в одну большую формулу, 

356
00:19:48,262 --> 00:19:49,190
включающую е и пи. 

357
00:19:49,190 --> 00:19:54,314
Теперь, когда все это на столе, давайте еще раз вернемся к идее начать с некоторой 

358
00:19:54,314 --> 00:19:59,810
случайной величины и задаться вопросом, как выглядят распределения сумм этой переменной. 

359
00:20:00,130 --> 00:20:02,739
Как мы уже говорили, когда вы увеличиваете размер этой суммы, 

360
00:20:02,739 --> 00:20:06,064
результирующее распределение будет смещаться в соответствии с растущим средним 

361
00:20:06,064 --> 00:20:09,810
значением и медленно распространяться в соответствии с растущим стандартным отклонением. 

362
00:20:10,330 --> 00:20:12,637
И, применив к этому некоторые реальные формулы, 

363
00:20:12,637 --> 00:20:15,761
если мы знаем среднее значение нашей базовой случайной величины, 

364
00:20:15,761 --> 00:20:19,799
мы называем ее мю, и мы также знаем ее стандартное отклонение и называем ее сигмой, 

365
00:20:19,799 --> 00:20:23,211
тогда среднее значение суммы внизу будет мю. умножить на размер суммы, 

366
00:20:23,211 --> 00:20:26,528
а стандартное отклонение будет равно сигме, умноженной на квадратный 

367
00:20:26,528 --> 00:20:27,730
корень из этого размера. 

368
00:20:28,190 --> 00:20:31,165
Итак, теперь, если мы хотим заявить, что это все больше и больше похоже на 

369
00:20:31,165 --> 00:20:34,179
колоколообразную кривую, а колоколообразная кривая описывается только двумя 

370
00:20:34,179 --> 00:20:37,710
разными параметрами: средним значением и стандартным отклонением, вы знаете, что делать. 

371
00:20:37,930 --> 00:20:40,382
Вы можете подставить эти два значения в формулу, 

372
00:20:40,382 --> 00:20:44,036
и это даст вам весьма явную, хотя и довольно сложную формулу для кривой, 

373
00:20:44,036 --> 00:20:46,990
которая должна точно соответствовать нашему распределению. 

374
00:20:48,390 --> 00:20:51,752
Но есть и другой способ описать это, более элегантный и создающий 

375
00:20:51,752 --> 00:20:54,810
очень забавный визуальный эффект, который мы можем создать. 

376
00:20:55,270 --> 00:20:59,004
Вместо того, чтобы сосредотачиваться на сумме всех этих случайных величин, 

377
00:20:59,004 --> 00:21:03,086
давайте немного изменим это выражение: мы посмотрим на среднее значение, которое, 

378
00:21:03,086 --> 00:21:05,675
как мы ожидаем, примет эта сумма, и вычтем его так, 

379
00:21:05,675 --> 00:21:08,314
чтобы наше новое выражение имеет среднее значение 0, 

380
00:21:08,314 --> 00:21:12,446
а затем мы посмотрим на стандартное отклонение, которое мы ожидаем от нашей суммы, 

381
00:21:12,446 --> 00:21:15,533
и разделим на него, что по сути просто меняет масштаб единиц, 

382
00:21:15,533 --> 00:21:18,770
так что стандартное отклонение нашего выражения будет равно 1. . 

383
00:21:19,350 --> 00:21:21,645
Это выражение может показаться более сложным, 

384
00:21:21,645 --> 00:21:24,090
но на самом деле оно имеет очень читаемый смысл. 

385
00:21:24,450 --> 00:21:26,983
По сути, это вопрос о том, на сколько стандартных 

386
00:21:26,983 --> 00:21:29,670
отклонений от среднего значения находится эта сумма? 

387
00:21:30,750 --> 00:21:33,774
Например, эта полоса здесь соответствует определенному значению, 

388
00:21:33,774 --> 00:21:37,542
которое вы можете найти, когда бросаете 10 игральных костей и суммируете их все, 

389
00:21:37,542 --> 00:21:40,194
и ее положение немного выше отрицательной 1 говорит вам, 

390
00:21:40,194 --> 00:21:43,870
что это значение немного меньше одного стандартного отклонения. ниже среднего. 

391
00:21:45,130 --> 00:21:49,502
Кроме того, кстати, в предвкушении анимации, которую я пытаюсь здесь построить, 

392
00:21:49,502 --> 00:21:53,382
я представляю вещи на нижнем графике так: площадь каждой из этих полос 

393
00:21:53,382 --> 00:21:56,990
говорит нам о вероятности соответствующего значения. а не высота. 

394
00:21:57,230 --> 00:22:00,225
Вы можете подумать, что ось Y представляет собой не вероятность, 

395
00:22:00,225 --> 00:22:01,930
а своего рода плотность вероятности. 

396
00:22:02,270 --> 00:22:06,362
Причина этого в том, чтобы подготовить почву так, чтобы она соответствовала тому, 

397
00:22:06,362 --> 00:22:08,808
как мы интерпретируем непрерывные распределения, 

398
00:22:08,808 --> 00:22:12,651
где вероятность попадания в диапазон значений равна площади под кривой между 

399
00:22:12,651 --> 00:22:13,550
этими значениями. 

400
00:22:13,910 --> 00:22:16,730
В частности, площадь всех столбцов вместе будет равна 1. 

401
00:22:18,230 --> 00:22:20,950
Теперь, когда все это готово, давайте немного повеселимся. 

402
00:22:21,330 --> 00:22:24,848
Позвольте мне начать с отката назад, чтобы распределение внизу представляло собой 

403
00:22:24,848 --> 00:22:28,580
относительно небольшую сумму, как если бы вы сложили вместе только три таких случайных 

404
00:22:28,580 --> 00:22:29,010
величины. 

405
00:22:29,450 --> 00:22:32,430
Обратите внимание, что происходит, когда я меняю дистрибутив, с которого мы начали. 

406
00:22:32,730 --> 00:22:36,290
При его изменении распределение внизу полностью меняет свою форму. 

407
00:22:36,510 --> 00:22:38,770
Это очень зависит от того, с чего мы начали. 

408
00:22:40,350 --> 00:22:43,662
Если мы позволим размеру нашей суммы стать немного больше, скажем, до 10, 

409
00:22:43,662 --> 00:22:46,974
и когда я изменю распределение для x, она в основном останется похожей на 

410
00:22:46,974 --> 00:22:49,929
колоколообразную кривую, но я могу найти некоторые распределения, 

411
00:22:49,929 --> 00:22:51,630
которые заставят ее изменить форму. . 

412
00:22:52,230 --> 00:22:56,406
Например, действительно однобокий вариант, где почти вся вероятность заключена 

413
00:22:56,406 --> 00:23:00,318
в числах 1 или 6, приводит к такой остроконечной колоколообразной кривой, 

414
00:23:00,318 --> 00:23:04,230
и, если вы помните, ранее я фактически показал это в форме моделирования. 

415
00:23:04,230 --> 00:23:07,993
Итак, если вам интересно, была ли эта остроконечность артефактом случайности или 

416
00:23:07,993 --> 00:23:11,850
отражала истинное распределение, оказывается, она отражает истинное распределение. 

417
00:23:12,290 --> 00:23:14,540
В этом случае 10 — недостаточно большая сумма для того, 

418
00:23:14,540 --> 00:23:16,470
чтобы сработала центральная предельная теорема. 

419
00:23:16,470 --> 00:23:20,087
Но если вместо этого я позволю этой сумме расти и рассмотрю возможность 

420
00:23:20,087 --> 00:23:23,655
добавления 50 различных значений, что на самом деле не так уж и много, 

421
00:23:23,655 --> 00:23:27,876
то независимо от того, как я изменю распределение нашей базовой случайной величины, 

422
00:23:27,876 --> 00:23:30,690
это по существу не повлияет на форму графика на нижний. 

423
00:23:31,170 --> 00:23:35,120
Независимо от того, с чего мы начинаем, вся информация и нюансы распределения x 

424
00:23:35,120 --> 00:23:38,478
смываются, и мы склоняемся к этой единственной универсальной форме, 

425
00:23:38,478 --> 00:23:42,527
описываемой очень элегантной функцией для стандартного нормального распределения: 

426
00:23:42,527 --> 00:23:45,144
1 вместо квадратного корня из 2 пи, умноженных на e. 

427
00:23:45,144 --> 00:23:47,070
к отрицательному х в квадрате более 2. 

428
00:23:47,810 --> 00:23:50,810
Вот в этом-то и состоит суть центральной предельной теоремы. 

429
00:23:51,130 --> 00:23:53,752
Почти ничего, что вы можете сделать с этим начальным распределением, 

430
00:23:53,752 --> 00:23:55,310
не меняет форму, к которой мы стремимся. 

431
00:23:59,030 --> 00:24:01,563
Те из вас, кто более склонен к теории, возможно, 

432
00:24:01,563 --> 00:24:04,510
все еще задаются вопросом, какова на самом деле теорема? 

433
00:24:04,810 --> 00:24:07,309
Например, какое математическое утверждение мы здесь утверждаем, 

434
00:24:07,309 --> 00:24:08,910
которое можно доказать или опровергнуть? 

435
00:24:09,030 --> 00:24:11,050
Если вам нужно красивое официальное заявление, вот как это может быть. 

436
00:24:11,050 --> 00:24:15,099
Рассмотрим это значение, где мы суммируем n различных экземпляров нашей случайной 

437
00:24:15,099 --> 00:24:19,445
величины, но изменены и настроены так, что ее среднее значение и стандартное отклонение 

438
00:24:19,445 --> 00:24:19,890
равны 1. 

439
00:24:20,230 --> 00:24:22,790
Опять же, это означает, что вы можете прочитать это как вопрос, 

440
00:24:22,790 --> 00:24:25,350
на сколько стандартных отклонений от среднего составляет сумма. 

441
00:24:25,770 --> 00:24:29,818
Тогда фактическая строгая формулировка центральной предельной теоремы (на этот 

442
00:24:29,818 --> 00:24:32,739
раз без шуток): если вы рассматриваете вероятность того, 

443
00:24:32,739 --> 00:24:36,838
что это значение попадает между двумя заданными действительными числами, a и b, 

444
00:24:36,838 --> 00:24:40,733
и вы рассматриваете предел этой вероятности как размер ваша сумма стремится 

445
00:24:40,733 --> 00:24:44,115
к бесконечности, тогда этот предел равен определенному интегралу, 

446
00:24:44,115 --> 00:24:48,112
который в основном описывает площадь при стандартном нормальном распределении 

447
00:24:48,112 --> 00:24:49,650
между этими двумя значениями. 

448
00:24:51,250 --> 00:24:55,517
Опять же, есть три основных предположения, о которых мне еще предстоит вам рассказать, 

449
00:24:55,517 --> 00:24:59,588
но кроме них, во всех кровавых подробностях, вот это и есть центральная предельная 

450
00:24:59,588 --> 00:25:00,030
теорема. 

451
00:25:04,550 --> 00:25:07,865
Все это немного теоретически, поэтому было бы полезно вернуться на Землю 

452
00:25:07,865 --> 00:25:10,772
и вернуться к конкретному примеру, который я упомянул в начале, 

453
00:25:10,772 --> 00:25:14,541
где вы представляете, что бросаете игральную кость 100 раз, и давайте предположим, 

454
00:25:14,541 --> 00:25:18,130
что это справедливый результат. для этого примера, и вы суммируете результаты. 

455
00:25:18,870 --> 00:25:23,219
Ваша задача — найти такой диапазон значений, в котором вы на 95 % уверены, 

456
00:25:23,219 --> 00:25:25,830
что сумма будет находиться в этом диапазоне. 

457
00:25:27,130 --> 00:25:31,935
Для подобных вопросов существует удобное эмпирическое правило нормального распределения, 

458
00:25:31,935 --> 00:25:36,255
которое гласит, что около 68% ваших значений будут находиться в пределах одного 

459
00:25:36,255 --> 00:25:41,060
стандартного отклонения от среднего значения, а 95% ваших значений, то, что нас волнует, 

460
00:25:41,060 --> 00:25:45,704
попадают в этот диапазон. два стандартных отклонения среднего значения и колоссальные 

461
00:25:45,704 --> 00:25:50,510
99.7% ваших значений будут находиться в пределах трех стандартных отклонений от среднего 

462
00:25:50,510 --> 00:25:51,050
значения. 

463
00:25:51,050 --> 00:25:53,442
Это практическое правило, которое обычно запоминают люди, 

464
00:25:53,442 --> 00:25:55,670
которые много занимаются вероятностями и статистикой. 

465
00:25:55,670 --> 00:25:58,919
Естественно, это дает нам то, что нам нужно для нашего примера, 

466
00:25:58,919 --> 00:26:01,610
и позвольте мне нарисовать, как это будет выглядеть, 

467
00:26:01,610 --> 00:26:06,179
где я покажу распределение для справедливого кубика вверху и распределение для суммы 100. 

468
00:26:06,179 --> 00:26:08,870
такие игральные кости внизу, которые, как вы знаете, 

469
00:26:08,870 --> 00:26:11,510
теперь выглядят как некое нормальное распределение. 

470
00:26:11,510 --> 00:26:15,051
Первый шаг в решении подобной проблемы — найти среднее значение вашего начального 

471
00:26:15,051 --> 00:26:18,593
распределения, которое в данном случае будет выглядеть как 16-е, умноженное на 1, 

472
00:26:18,593 --> 00:26:21,530
плюс 16-е, умноженное на 2, и так далее, и в итоге будет равно 3.5. 

473
00:26:21,530 --> 00:26:25,767
Нам также нужно стандартное отклонение, для которого требуется вычислить дисперсию, 

474
00:26:25,767 --> 00:26:28,995
которая, как вы знаете, включает в себя сложение всех квадратов 

475
00:26:28,995 --> 00:26:33,131
разностей между значениями и средними значениями, и в результате получается 2.92, 

476
00:26:33,131 --> 00:26:35,250
квадратный корень из которого равен 1.71. 

477
00:26:35,250 --> 00:26:39,317
Это единственные два числа, которые нам нужны, и я снова приглашаю вас задуматься о том, 

478
00:26:39,317 --> 00:26:41,830
насколько волшебно то, что это единственные два числа, 

479
00:26:41,830 --> 00:26:44,710
которые вам нужны для полного понимания нижнего распределения. 

480
00:26:44,710 --> 00:26:47,696
Его среднее значение будет в 100 раз мю, что равно 350, 

481
00:26:47,696 --> 00:26:52,070
а его стандартное отклонение будет равно квадратному корню из 100-кратного сигмы, 

482
00:26:52,070 --> 00:26:53,670
то есть 10-кратного сигмы 17. 

483
00:26:53,670 --> 00:26:56,797
1. Помня наше удобное эмпирическое правило, мы ищем значения, 

484
00:26:56,797 --> 00:26:59,924
отстоящие на два стандартных отклонения от среднего значения, 

485
00:26:59,924 --> 00:27:03,858
и когда вы вычитаете 2 сигмы из среднего значения, вы получаете примерно 316, 

486
00:27:03,858 --> 00:27:06,330
а когда вы добавляете 2 сигмы, вы получаете 384. 

487
00:27:07,350 --> 00:27:08,950
И вот, это дает нам ответ. 

488
00:27:11,470 --> 00:27:15,140
Хорошо, я обещал подвести итоги в ближайшее время, но пока мы рассматриваем этот пример, 

489
00:27:15,140 --> 00:27:17,450
есть еще один вопрос, на который стоит потратить время. 

490
00:27:18,250 --> 00:27:21,480
Вместо того, чтобы просто спрашивать о сумме 100 бросков кубика, 

491
00:27:21,480 --> 00:27:24,263
предположим, я попросил вас разделить это число на 100, 

492
00:27:24,263 --> 00:27:28,090
что по сути означает, что все числа на нашей диаграмме внизу делятся на 100. 

493
00:27:28,570 --> 00:27:31,570
Найдите минутку, чтобы интерпретировать, о чем все это говорит тогда. 

494
00:27:32,070 --> 00:27:35,842
По сути, это выражение сообщает вам эмпирическое среднее значение для 100 

495
00:27:35,842 --> 00:27:39,513
различных бросков кубика, и найденный нами интервал теперь говорит вам, 

496
00:27:39,513 --> 00:27:43,490
какой диапазон вы ожидаете увидеть для этого эмпирического среднего значения. 

497
00:27:44,350 --> 00:27:47,195
Другими словами, вы можете ожидать, что оно будет около 3.5, 

498
00:27:47,195 --> 00:27:51,299
это ожидаемое значение для броска кубика, но что гораздо менее очевидно и что позволяет 

499
00:27:51,299 --> 00:27:53,818
вычислить центральная предельная теорема, так это то, 

500
00:27:53,818 --> 00:27:56,570
насколько близко к этому ожидаемому значению вы окажетесь. 

501
00:27:57,590 --> 00:27:59,930
В частности, стоит уделить время размышлениям о том, 

502
00:27:59,930 --> 00:28:03,110
каково стандартное отклонение для этого эмпирического среднего значения 

503
00:28:03,110 --> 00:28:07,085
и что с ним происходит, когда вы смотрите на все большую и большую выборку бросков кубика.

504
00:28:07,085 --> 00:28:07,130
 

505
00:28:12,950 --> 00:28:16,117
И наконец, но, вероятно, самое главное: давайте поговорим о предположениях, 

506
00:28:16,117 --> 00:28:17,410
лежащих в основе этой теоремы. 

507
00:28:18,010 --> 00:28:22,530
Во-первых, все эти переменные, которые мы суммируем, независимы друг от друга. 

508
00:28:22,850 --> 00:28:26,310
Результат одного процесса не влияет на результат любого другого процесса. 

509
00:28:27,250 --> 00:28:30,950
Во-вторых, все эти переменные взяты из одного и того же распределения. 

510
00:28:31,310 --> 00:28:34,390
Оба этих условия неявно предполагались в нашем примере с игральными костями. 

511
00:28:34,790 --> 00:28:38,387
Мы рассматривали результат каждого броска кубика как независимый от результата 

512
00:28:38,387 --> 00:28:42,030
всех остальных и предполагаем, что каждый кубик имеет одинаковое распределение. 

513
00:28:42,850 --> 00:28:45,694
Иногда в литературе вы встретите эти два предположения, 

514
00:28:45,694 --> 00:28:49,910
объединенные инициалами IID, обозначающими независимые и одинаково распределенные. 

515
00:28:50,530 --> 00:28:53,337
Одной из ситуаций, когда эти предположения явно неверны, 

516
00:28:53,337 --> 00:28:55,110
является совет директоров Гальтона. 

517
00:28:55,710 --> 00:28:56,830
Я имею в виду, подумай об этом. 

518
00:28:56,970 --> 00:29:00,131
Действительно ли то, как мяч отскочит от одного из колышков, 

519
00:29:00,131 --> 00:29:03,190
не зависит от того, как он отскочит от следующего колышка? 

520
00:29:03,830 --> 00:29:04,610
Точно нет. 

521
00:29:04,770 --> 00:29:07,870
В зависимости от последнего отскока он движется по совершенно разной траектории. 

522
00:29:08,210 --> 00:29:11,489
И действительно ли распределение возможных результатов для каждой 

523
00:29:11,489 --> 00:29:14,670
привязки одинаково для каждой привязки, к которой она попадает? 

524
00:29:15,190 --> 00:29:16,710
Опять же, почти наверняка нет. 

525
00:29:16,710 --> 00:29:19,468
Может быть, он попадает в одну точку, глядя влево, а это означает, 

526
00:29:19,468 --> 00:29:23,133
что результаты сильно искажаются в этом направлении, а затем попадает в следующую точку, 

527
00:29:23,133 --> 00:29:23,710
глядя вправо. 

528
00:29:25,730 --> 00:29:28,702
Когда я сделал все эти упрощающие предположения в первом примере, 

529
00:29:28,702 --> 00:29:31,630
я делал это не только для того, чтобы об этом было легче думать. 

530
00:29:31,970 --> 00:29:34,236
Кроме того, эти предположения были необходимы для того, 

531
00:29:34,236 --> 00:29:37,070
чтобы это действительно было примером центральной предельной теоремы. 

532
00:29:38,130 --> 00:29:41,055
Тем не менее, похоже, что для реальной доски Гальтона, 

533
00:29:41,055 --> 00:29:45,470
несмотря на нарушение обоих условий, нормальное распределение все-таки получается? 

534
00:29:46,050 --> 00:29:49,728
Частично причина может заключаться в том, что существуют обобщения теоремы, 

535
00:29:49,728 --> 00:29:53,890
выходящие за рамки этого видео, которые ослабляют эти предположения, особенно второе. 

536
00:29:54,490 --> 00:29:58,321
Но я хочу предостеречь вас от того факта, что часто люди предполагают, 

537
00:29:58,321 --> 00:30:03,070
что переменная распределяется нормально, даже если для этого нет реального обоснования. 

538
00:30:04,290 --> 00:30:06,210
Третье предположение на самом деле довольно тонкое. 

539
00:30:06,210 --> 00:30:10,270
Дело в том, что дисперсия, которую мы вычисляли для этих переменных, конечна. 

540
00:30:10,810 --> 00:30:13,107
В примере с игральными костями это никогда не было проблемой, 

541
00:30:13,107 --> 00:30:14,850
поскольку возможных исходов было только шесть. 

542
00:30:15,030 --> 00:30:18,364
Но в некоторых ситуациях, когда у вас есть бесконечный набор результатов, 

543
00:30:18,364 --> 00:30:21,834
когда вы начинаете вычислять дисперсию, сумма в конечном итоге расходится до 

544
00:30:21,834 --> 00:30:22,510
бесконечности. 

545
00:30:23,450 --> 00:30:25,695
Это могут быть совершенно правильные распределения вероятностей, 

546
00:30:25,695 --> 00:30:27,250
и они действительно встречаются на практике. 

547
00:30:27,550 --> 00:30:31,025
Но в таких ситуациях, когда вы рассматриваете возможность добавления множества 

548
00:30:31,025 --> 00:30:34,414
различных экземпляров этой переменной и позволяете этой сумме приближаться к 

549
00:30:34,414 --> 00:30:37,670
бесконечности, даже если первые два предположения верны, весьма вероятно, 

550
00:30:37,670 --> 00:30:41,190
что то, к чему вы склонны, на самом деле не является нормальным распределением. 

551
00:30:42,150 --> 00:30:45,845
Если вы все поняли до этого момента, то теперь у вас есть очень прочная основа в том, 

552
00:30:45,845 --> 00:30:47,650
что такое центральная предельная теорема. 

553
00:30:48,290 --> 00:30:59,828
И далее я хотел бы объяснить, почему именно эта функция является тем, 

554
00:30:59,828 --> 00:31:14,170
к чему мы склонны, и почему в ней есть число «пи», какое отношение она имеет к кругам. 

