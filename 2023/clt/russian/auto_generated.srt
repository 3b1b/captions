1
00:00:00,000 --> 00:00:05,280
Это доска Гальтона. Возможно, вы видели такое раньше: это популярная демонстрация того,

2
00:00:05,280 --> 00:00:10,400
что даже когда одно событие хаотично и случайно, с практически неизвестным

3
00:00:10,400 --> 00:00:14,480
результатом, все еще возможно делать точные утверждения о большом количестве событий,

4
00:00:14,480 --> 00:00:18,320
а именно, как относительные пропорции для многих различных результатов распределены.

5
00:00:20,560 --> 00:00:24,560
Более конкретно, доска Гальтона иллюстрирует одно из наиболее ярких распределений во всей

6
00:00:24,560 --> 00:00:29,840
вероятности, известное как нормальное распределение, в просторечии называемое колоколообразной кривой, а

7
00:00:29,840 --> 00:00:34,480
также называемое распределением Гаусса. Для описания этого распределения есть очень специфическая функция,

8
00:00:34,480 --> 00:00:38,800
она очень красивая, мы займемся этим позже, но сейчас я просто хочу подчеркнуть, что

9
00:00:38,800 --> 00:00:43,200
нормальное распределение, как следует из названия, очень распространено, оно встречается во многих случаях. из,

10
00:00:43,200 --> 00:00:48,480
казалось бы, несвязанных контекстов. Если вы возьмете большое количество людей, относящихся к одной и той же демографической

11
00:00:48,480 --> 00:00:54,240
группе, и нанесете на график их рост, то этот рост, как правило, будет соответствовать нормальному распределению. Если вы

12
00:00:54,240 --> 00:00:59,600
посмотрите на большой набор очень больших натуральных чисел и спросите, сколько различных простых делителей

13
00:00:59,600 --> 00:01:05,280
имеет каждое из этих чисел, ответы будут очень точно соответствовать определенному нормальному распределению.

14
00:01:05,280 --> 00:01:10,240
Наша сегодняшняя тема — одна из жемчужин всей теории вероятностей, это один из ключевых

15
00:01:10,240 --> 00:01:15,600
фактов, объясняющих, почему это распределение настолько распространено, что оно известно как центральная предельная

16
00:01:15,600 --> 00:01:20,240
теорема. Этот урок предназначен для того, чтобы вернуться к основам, дать вам основные сведения о

17
00:01:20,240 --> 00:01:24,160
том, что говорит центральная предельная теорема, что такое нормальные распределения, и я хочу предположить минимальную

18
00:01:24,160 --> 00:01:29,280
предысторию. Мы собираемся углубиться в это, но после этого мне все же хотелось бы пойти глубже

19
00:01:29,280 --> 00:01:34,800
и объяснить, почему теорема верна, почему функция, лежащая в основе нормального распределения, имеет очень специфическую форму, почему

20
00:01:34,800 --> 00:01:41,920
эта формула имеет в нем есть число «пи», и, что самое интересное, почему эти два последних факта

21
00:01:41,920 --> 00:01:47,600
на самом деле связаны между собой больше, чем предполагают многие традиционные объяснения. Этот второй урок

22
00:01:47,600 --> 00:01:52,000
также должен стать продолжением обещанного мной видео по извилистым волосам, так что здесь

23
00:01:52,000 --> 00:01:56,400
много взаимосвязанных тем. Но сейчас, возвращаясь к основам, я хотел бы начать с

24
00:01:56,400 --> 00:02:03,440
чрезмерно упрощенной модели доски Гальтона. В этой модели мы будем предполагать, что каждый шар

25
00:02:03,440 --> 00:02:08,720
падает прямо на определенный центральный колышек и что вероятность его отскока влево или вправо составляет 50 на

26
00:02:08,720 --> 00:02:13,200
50, и мы будем думать о каждом из этих результатов как о добавлении одного или вычитание единицы

27
00:02:13,200 --> 00:02:18,800
из своей позиции. Как только один из них выбран, мы делаем крайне нереалистичное предположение, что

28
00:02:18,800 --> 00:02:23,760
он случайно приземлится в середине колышка, примыкающего под ним, где он снова столкнется с тем

29
00:02:23,760 --> 00:02:28,640
же выбором 50 на 50: отскочить влево или Направо. Для того, что я показываю на

30
00:02:28,640 --> 00:02:33,360
экране, есть пять разных рядов колышков, поэтому наш маленький прыгающий шарик делает пять разных случайных

31
00:02:33,360 --> 00:02:38,480
выборов между плюс один и минус один, и мы можем думать о его конечном положении как

32
00:02:38,480 --> 00:02:43,760
о сумме всех из этих разных чисел, которое в данном случае оказывается одним, и мы

33
00:02:43,760 --> 00:02:48,000
могли бы пометить все разные сегменты суммой, которую они представляют. Повторяя это, мы рассматриваем различные

34
00:02:48,000 --> 00:02:54,400
возможные суммы этих пяти случайных чисел. А для тех из вас, кто склонен

35
00:02:54,400 --> 00:02:59,120
жаловаться на то, что это крайне нереалистичная модель настоящей платы Гальтона, позвольте мне подчеркнуть, что

36
00:02:59,120 --> 00:03:04,480
цель сейчас не в точном моделировании физики. Цель состоит в том, чтобы дать простой пример, иллюстрирующий

37
00:03:04,480 --> 00:03:09,200
центральную предельную теорему, и, каким бы идеализированным он ни был, на самом деле он дает нам

38
00:03:09,200 --> 00:03:14,480
действительно хороший пример. Если мы позволим упасть множеству разных шаров, сделав еще одно нереалистичное предположение, что они не

39
00:03:14,480 --> 00:03:18,960
влияют друг на друга, как если бы они все были призраками, тогда количество шаров, попадающих в каждое

40
00:03:18,960 --> 00:03:23,680
ведро, даст нам некоторое неопределенное представление о том, насколько вероятен каждый из них. из этих ведер есть.

41
00:03:23,680 --> 00:03:27,840
В этом примере числа достаточно просты, поэтому нетрудно явно вычислить

42
00:03:27,840 --> 00:03:31,280
вероятность попадания в каждое ведро. Если вы захотите обдумать это, вы

43
00:03:31,280 --> 00:03:35,840
обнаружите, что это очень напоминает треугольник Паскаля. Но самое интересное в нашей теореме то, что

44
00:03:35,840 --> 00:03:40,800
она выходит далеко за рамки простых примеров. Итак, по крайней мере, для начала, вместо того, чтобы

45
00:03:40,800 --> 00:03:45,360
проводить явные вычисления, давайте просто смоделируем ситуацию, запустив большое количество выборок и позволив общему количеству

46
00:03:45,360 --> 00:03:49,600
результатов в каждом отдельном исходе дать нам некоторое представление о том, как выглядит это распределение.

47
00:03:49,600 --> 00:03:55,440
Как я уже сказал, на экране пять строк, поэтому каждая рассматриваемая сумма включает только пять

48
00:03:55,440 --> 00:04:01,040
чисел. Основная идея центральной предельной теоремы заключается в том, что если вы увеличите размер этой

49
00:04:01,040 --> 00:04:06,480
суммы, например здесь, это будет означать увеличение количества рядов колышков для каждого шара, от которого

50
00:04:06,480 --> 00:04:12,640
отскочит, тогда распределение, которое описывает, куда пойдет эта сумма. падение все больше похоже на колоколообразную

51
00:04:12,640 --> 00:04:19,760
кривую. Здесь действительно стоит потратить время на то, чтобы записать эту общую идею. Установка такова,

52
00:04:19,760 --> 00:04:25,120
что у нас есть случайная переменная, и это, по сути, сокращение для случайного процесса, где

53
00:04:25,120 --> 00:04:30,240
каждый результат этого процесса связан с некоторым числом. Мы назовем это случайное число x. Например,

54
00:04:30,240 --> 00:04:35,200
каждый отскок от прищепки — это случайный процесс, моделируемый с двумя исходами. Эти результаты

55
00:04:35,200 --> 00:04:39,920
связаны с числами «отрицательный» и «положительный». Другим примером случайной величины может быть бросок

56
00:04:39,920 --> 00:04:44,400
игральной кости, в результате которого у вас есть шесть разных результатов, каждый из которых связан с

57
00:04:44,400 --> 00:04:49,760
числом. Мы берем несколько разных образцов этой переменной и складываем их все

58
00:04:49,760 --> 00:04:54,640
вместе. На нашей доске Гальтона это выглядит так, будто мяч отскакивает от нескольких разных колышков

59
00:04:54,640 --> 00:04:59,760
на пути вниз, а в случае с кубиком вы можете представить, что бросаете много разных кубиков

60
00:04:59,840 --> 00:05:04,880
и суммируете результаты. Утверждение центральной предельной теоремы состоит в том, что по мере того, как вы

61
00:05:04,880 --> 00:05:10,400
позволяете размеру этой суммы становиться все больше и больше, распределение этой суммы, вероятность того, что она попадет в

62
00:05:10,400 --> 00:05:16,720
различные возможные значения, будет все больше и больше напоминать колоколообразную кривую. Вот и все, это общая идея.

63
00:05:16,720 --> 00:05:22,080
В ходе этого урока наша задача — сделать это утверждение более количественным. Мы собираемся

64
00:05:22,080 --> 00:05:26,400
добавить к нему некоторые цифры, формулы и показать, как вы можете использовать его для прогнозирования.

65
00:05:27,360 --> 00:05:31,440
Например, вот вопрос, на который я хочу, чтобы вы смогли ответить к концу этого видео.

66
00:05:32,080 --> 00:05:37,840
Предположим, вы бросили игральную кость 100 раз и сложили результаты. Можете ли вы найти такой диапазон

67
00:05:37,840 --> 00:05:43,840
значений, в котором вы на 95 % уверены, что сумма попадет в этот диапазон? Или, может быть, мне следует

68
00:05:43,840 --> 00:05:48,560
сказать: найдите наименьший возможный диапазон значений, в котором это будет верно. Самое интересное, что вы сможете ответить

69
00:05:48,560 --> 00:05:54,480
на этот вопрос, является ли это честным кубиком или взвешенным. Теперь позвольте мне сказать вверху,

70
00:05:54,480 --> 00:05:58,880
что эта теорема включает в себя три различных предположения, три вещи, которые должны быть верными, прежде чем

71
00:05:58,880 --> 00:06:03,040
из нее вытекает теорема. И я на самом деле не собираюсь рассказывать вам, что это такое, до

72
00:06:03,040 --> 00:06:07,200
самого конца видео. Вместо этого я хочу, чтобы вы внимательно наблюдали и посмотрели, сможете ли вы заметить

73
00:06:07,200 --> 00:06:12,480
и, возможно, предсказать, какими будут эти три предположения. В качестве следующего шага, чтобы лучше проиллюстрировать, насколько

74
00:06:12,480 --> 00:06:16,880
общей является эта теорема, я хочу провести для вас еще пару симуляций, сосредоточенных на примере игры в

75
00:06:16,880 --> 00:06:24,880
кости. Обычно, когда вы думаете о броске игральной кости, вы думаете, что шесть исходов равновероятны,

76
00:06:24,880 --> 00:06:29,600
но на самом деле теорема не заботится об этом. Мы могли бы начать с взвешенной

77
00:06:29,600 --> 00:06:34,960
кости, чего-то с нетривиальным распределением результатов, и основная идея останется в силе. Для

78
00:06:34,960 --> 00:06:39,120
моделирования я возьму некоторое распределение, подобное этому, со сдвигом в сторону меньших

79
00:06:39,120 --> 00:06:45,040
значений. Я возьму 10 различных выборок из этого распределения, а затем запишу

80
00:06:45,040 --> 00:06:50,320
сумму этой выборки на графике внизу. Затем я собираюсь сделать это много-много раз, всегда

81
00:06:50,320 --> 00:06:55,360
с суммой размером 10, но отслеживайте, где в конечном итоге оказались эти суммы, чтобы дать

82
00:06:55,360 --> 00:07:03,200
нам представление о распределении. И на самом деле, позвольте мне изменить масштаб по направлению y, чтобы дать нам

83
00:07:03,200 --> 00:07:08,000
возможность выполнить еще большее количество образцов. И я позволю этому увеличиться до пары тысяч, и при этом

84
00:07:08,000 --> 00:07:13,680
вы заметите, что фигура, которая начинает проявляться, выглядит как колоколообразная кривая. Возможно, если вы

85
00:07:13,680 --> 00:07:18,560
прищуритесь, вы увидите, что он немного смещается влево, но это здорово, что что-то столь

86
00:07:18,560 --> 00:07:22,720
симметричное возникло из такой асимметричной отправной точки. Чтобы лучше проиллюстрировать суть центральной предельной теоремы, позвольте

87
00:07:22,720 --> 00:07:27,840
мне запустить четыре таких моделирования параллельно: в левом верхнем углу я делаю это, когда мы добавляем только две

88
00:07:27,840 --> 00:07:32,480
игральные кости за раз, а в верхнем правом мы: Мы делаем это, когда мы добавляем пять кубиков

89
00:07:32,480 --> 00:07:37,200
за раз, нижний левый — это тот, который мы только что видели, добавляя по 10 кубиков за раз,

90
00:07:37,200 --> 00:07:43,440
а затем мы сделаем еще один с большей суммой, 15 за раз. Обратите внимание, что в левом

91
00:07:43,440 --> 00:07:48,160
верхнем углу, когда мы просто добавляем два кубика, полученное распределение на самом деле не выглядит

92
00:07:48,160 --> 00:07:51,920
как колоколообразная кривая, оно намного больше напоминает то, с которым мы начали, с перекосом влево.

93
00:07:52,640 --> 00:07:57,600
Но поскольку мы учитываем все больше и больше кубиков в каждой сумме, результирующая форма, возникающая в этих

94
00:07:57,600 --> 00:08:02,160
распределениях, выглядит все более и более симметричной. У него есть выступ посередине, а хвост плавно

95
00:08:02,160 --> 00:08:10,640
переходит в колоколообразную форму. И еще раз подчеркну: начать можно с любого другого дистрибутива.

96
00:08:10,640 --> 00:08:15,200
Здесь я запущу его еще раз, но большая часть вероятности связана с числами 1 и 6,

97
00:08:15,200 --> 00:08:20,160
с очень низкой вероятностью для средних значений. Несмотря на полное изменение распределения для

98
00:08:20,160 --> 00:08:25,200
отдельного броска игральной кости, форма колоколообразной кривой по-прежнему возникает, когда мы

99
00:08:25,200 --> 00:08:30,400
рассматриваем различные суммы. Иллюстрировать вещи с помощью такой симуляции очень весело, и приятно видеть,

100
00:08:30,400 --> 00:08:35,840
как порядок возникает из хаоса, но это также кажется немного неточным. Как в

101
00:08:35,840 --> 00:08:40,560
этом случае, когда я отсек симуляцию на 3000 выборках, хотя она выглядит как колоколообразная

102
00:08:40,560 --> 00:08:45,520
кривая, разные сегменты кажутся довольно резкими. И вы можете задаться вопросом, так ли это

103
00:08:45,520 --> 00:08:50,560
должно выглядеть или это просто артефакт случайности в симуляции? И если да, то сколько образцов

104
00:08:50,560 --> 00:08:55,040
нам нужно, прежде чем мы сможем быть уверены, что то, на что мы смотрим, является репрезентативным для истинного распределения?

105
00:08:59,120 --> 00:09:03,280
Вместо того, чтобы двигаться вперед, давайте немного больше теоретического и покажем точную форму, которую

106
00:09:03,360 --> 00:09:08,480
эти распределения примут в долгосрочной перспективе. Проще всего выполнить этот расчет, если у нас

107
00:09:08,480 --> 00:09:13,760
есть равномерное распределение, где каждая возможная грань игральной кости имеет равную вероятность, 1/6.

108
00:09:13,760 --> 00:09:17,840
Например, если вы затем хотите узнать, насколько вероятны разные суммы для пары игральных костей, это,

109
00:09:17,840 --> 00:09:23,520
по сути, игра подсчета, в которой вы подсчитываете, сколько различных пар составляют одну и

110
00:09:23,520 --> 00:09:27,120
ту же сумму, что на диаграмме, которую я нарисовал, вы можно удобно обдумать, пройдя

111
00:09:27,120 --> 00:09:34,080
через все различные диагонали. Поскольку вероятность появления каждой такой пары равна 1 из

112
00:09:34,080 --> 00:09:39,600
36, вам остается только посчитать размеры этих ведер. Это дает нам окончательную форму распределения,

113
00:09:39,600 --> 00:09:44,640
описывающего сумму двух игральных костей, и если бы мы играли в ту же игру

114
00:09:44,640 --> 00:09:49,680
со всеми возможными тройками, полученное распределение выглядело бы следующим образом. Теперь, что более сложно, но

115
00:09:49,680 --> 00:09:54,320
гораздо интереснее, это спросить, что произойдет, если у нас будет неравномерное распределение для этого единственного

116
00:09:54,320 --> 00:09:59,680
кубика. Обо всём этом мы, собственно, и говорили в прошлом видео. По сути, вы делаете то же

117
00:09:59,680 --> 00:10:04,480
самое: перебираете все различные пары игральных костей, сумма которых дает одно и то же значение. Просто вместо

118
00:10:04,480 --> 00:10:09,760
того, чтобы считать эти пары, вы для каждой пары умножаете две вероятности появления

119
00:10:09,760 --> 00:10:14,560
каждого конкретного лица, а затем складываете все это вместе. Вычисление, которое делает это для

120
00:10:14,560 --> 00:10:19,280
всех возможных сумм, имеет причудливое название, оно называется сверткой, но по сути это

121
00:10:19,280 --> 00:10:23,680
просто взвешенная версия игры подсчета, которая уже знакома любому, кто играл с парой

122
00:10:23,680 --> 00:10:28,800
игральных костей. Для целей этого урока я попрошу компьютер все это рассчитать, просто

123
00:10:28,800 --> 00:10:33,760
отобразить вам результаты и предложить вам наблюдать определенные закономерности, но под капотом

124
00:10:33,760 --> 00:10:39,760
происходит вот что. Итак, чтобы внести ясность в то, что здесь представлено, если вы

125
00:10:39,760 --> 00:10:44,400
представите, что выбираете два разных значения из этого верхнего распределения, описывающего одну игральную

126
00:10:44,400 --> 00:10:49,920
кость, и суммируете их вместе, то второе распределение, которое я рисую, показывает, насколько вероятно,

127
00:10:49,920 --> 00:10:55,120
что вы увидеть различные разные суммы. Аналогично, если вы представите себе выборку трех различных

128
00:10:55,120 --> 00:10:59,440
значений из этого верхнего распределения и сложение их вместе, следующий график представляет вероятности

129
00:10:59,440 --> 00:11:06,080
для различных разных сумм в этом случае. Итак, если я вычислю, как будут выглядеть распределения этих

130
00:11:06,080 --> 00:11:11,360
сумм для все больших и больших сумм, ну, вы знаете, что я собираюсь сказать, это все больше и больше

131
00:11:11,360 --> 00:11:15,840
будет похоже на колоколообразную кривую. Но прежде чем мы перейдем к этому, я хочу, чтобы вы сделали еще пару

132
00:11:15,840 --> 00:11:21,680
простых наблюдений. Например, кажется, что эти распределения смещаются вправо, а также становятся

133
00:11:21,680 --> 00:11:26,480
более разбросанными и немного более плоскими. Вы не можете описать центральную

134
00:11:26,480 --> 00:11:30,640
предельную теорему количественно, не принимая во внимание оба этих эффекта, что, в свою

135
00:11:30,640 --> 00:11:35,040
очередь, требует описания среднего значения и стандартного отклонения. Возможно, вы уже знакомы с ними,

136
00:11:35,040 --> 00:11:39,200
но я хочу сделать здесь минимальные предположения, и обзор никогда не помешает, поэтому давайте быстро

137
00:11:39,200 --> 00:11:46,320
рассмотрим оба из них. Среднее значение распределения, часто обозначаемое греческой буквой мю,

138
00:11:46,320 --> 00:11:51,840
представляет собой способ определения центра масс этого распределения. Оно рассчитывается как

139
00:11:51,840 --> 00:11:56,880
ожидаемое значение нашей случайной величины, что означает, что вы перебираете

140
00:11:56,880 --> 00:12:02,320
все возможные результаты и умножаете вероятность этого результата на значение переменной.

141
00:12:02,320 --> 00:12:07,200
Если более высокие значения более вероятны, эта взвешенная сумма будет больше. Если более

142
00:12:07,200 --> 00:12:11,680
низкие значения более вероятны, эта взвешенная сумма будет меньше. Немного интереснее, если вы

143
00:12:11,680 --> 00:12:15,520
хотите измерить, насколько распространено это распределение, потому что есть несколько разных

144
00:12:15,520 --> 00:12:21,920
способов сделать это. Один из них называется дисперсией. Идея состоит в том, чтобы

145
00:12:21,920 --> 00:12:27,360
посмотреть разницу между каждым возможным значением и средним значением, возвести эту разницу в квадрат и запросить ее

146
00:12:27,360 --> 00:12:32,480
ожидаемое значение. Идея состоит в том, что независимо от того, находится ли ваше значение ниже или выше среднего, когда

147
00:12:32,480 --> 00:12:36,560
вы возводите эту разницу в квадрат, вы получаете положительное число, и чем больше разница, тем больше это число.

148
00:12:37,360 --> 00:12:41,200
Возведение в квадрат таким образом делает математические вычисления намного более точными, чем если бы мы делали что-то вроде

149
00:12:41,200 --> 00:12:46,560
абсолютного значения, но недостатком является то, что на нашей диаграмме трудно думать об этом как о расстоянии, потому

150
00:12:46,560 --> 00:12:51,280
что единицы измерения отключены. Вроде как единицы здесь — это квадратные единицы, тогда как расстояние на нашей

151
00:12:51,280 --> 00:12:56,480
диаграмме будет своего рода линейной единицей. Итак, еще один способ измерения разброса — это так называемое стандартное отклонение,

152
00:12:56,480 --> 00:13:01,840
которое представляет собой квадратный корень из этого значения. Гораздо более разумно это можно интерпретировать как расстояние на

153
00:13:01,840 --> 00:13:07,040
нашей диаграмме, и оно обычно обозначается греческой буквой сигма, поэтому вы знаете, что m означает среднее значение

154
00:13:07,040 --> 00:13:14,240
и стандартное отклонение, но оба на греческом языке. Оглядываясь назад на нашу последовательность распределений, давайте

155
00:13:14,240 --> 00:13:19,280
поговорим о среднем и стандартном отклонении. Если мы назовем среднее значение начального распределения mu,

156
00:13:19,280 --> 00:13:24,240
которое для иллюстрированного случая равно 2. 24, надеюсь, вы не удивитесь, если я скажу вам, что среднее

157
00:13:24,240 --> 00:13:28,880
значение следующего числа в 2 раза больше му. То есть вы бросаете пару игральных костей и хотите

158
00:13:28,880 --> 00:13:34,160
узнать ожидаемое значение суммы, оно в два раза превышает ожидаемое значение для одного кубика. Аналогично, ожидаемое значение

159
00:13:34,160 --> 00:13:39,840
нашей суммы размера 3 в 3 раза больше мю, и так далее, и тому подобное. Среднее значение

160
00:13:39,840 --> 00:13:44,160
неуклонно движется вправо, поэтому наши распределения, похоже, смещаются в этом

161
00:13:44,160 --> 00:13:48,640
направлении. Немного сложнее, но очень важно описать, как изменяется стандартное

162
00:13:48,640 --> 00:13:53,920
отклонение. Ключевым фактом здесь является то, что если у вас есть две разные случайные

163
00:13:53,920 --> 00:13:58,800
величины, то дисперсия суммы этих переменных такая же, как если бы вы просто сложили две исходные

164
00:13:58,800 --> 00:14:03,920
дисперсии. Это один из тех фактов, которые можно просто вычислить, распаковав все определения.

165
00:14:03,920 --> 00:14:08,400
Есть пара хороших предположений, почему это правда. Мой предварительный план состоит в том, чтобы просто

166
00:14:08,400 --> 00:14:12,720
сделать серию о вероятности и рассказать о таких вещах, как интуиция, лежащая в основе дисперсии, и

167
00:14:12,720 --> 00:14:17,280
ее родственники. Но сейчас главное, что я хочу, чтобы вы подчеркнули, это то,

168
00:14:17,280 --> 00:14:22,080
что добавляется дисперсия, а не стандартное отклонение. Итак, что особенно важно, если вы возьмете

169
00:14:22,080 --> 00:14:27,840
n различных реализаций одной и той же случайной величины и спросите, как выглядит сумма, дисперсия

170
00:14:27,840 --> 00:14:34,000
этой суммы в n раз превышает дисперсию вашей исходной переменной, то есть стандартное отклонение, квадратный

171
00:14:34,000 --> 00:14:39,760
корень из всех это квадратный корень из n, умноженного на исходное стандартное отклонение. Например, вернемся

172
00:14:39,760 --> 00:14:44,160
к нашей последовательности распределений, если мы обозначим стандартное отклонение нашего начального распределения сигмой, то следующее

173
00:14:44,160 --> 00:14:49,680
стандартное отклонение будет квадратным корнем из 2 сигм, и после этого оно будет выглядеть как квадратный

174
00:14:49,680 --> 00:14:54,800
корень из 3 раза сигма и так далее и тому подобное. Это, как я уже

175
00:14:54,800 --> 00:14:59,440
сказал, очень важно. Это означает, что хотя наши распределения и распределяются, они распространяются

176
00:14:59,440 --> 00:15:03,760
не так быстро, а только пропорционально квадратному корню из размера суммы.

177
00:15:03,760 --> 00:15:08,640
Пока мы готовимся к более количественному описанию центральной предельной теоремы, основная интуиция, которую я хочу,

178
00:15:08,640 --> 00:15:13,200
чтобы вы держали в голове, заключается в том, что мы, по сути, перестроим все эти распределения

179
00:15:13,200 --> 00:15:18,480
так, чтобы их средние значения выровнялись вместе, а затем изменим их масштаб таким образом. что

180
00:15:18,480 --> 00:15:23,840
все стандартные отклонения будут равны 1. И когда мы это делаем, получаемая в результате форма становится

181
00:15:23,840 --> 00:15:29,040
все ближе и ближе к определенной универсальной форме, описываемой с помощью элегантной маленькой функции, которую мы распакуем буквально

182
00:15:29,040 --> 00:15:34,240
через мгновение. И позвольте мне сказать еще раз: настоящее волшебство заключается в том, что мы

183
00:15:34,240 --> 00:15:39,200
могли бы начать с любого распределения, описывая один бросок игральной кости, и если мы будем

184
00:15:39,200 --> 00:15:43,760
играть в ту же игру, учитывая, как выглядят распределения для множества разных сумм: и мы

185
00:15:43,760 --> 00:15:47,920
перестраиваем их так, чтобы средние значения совпадали, и масштабируем их так, чтобы все стандартные отклонения

186
00:15:48,480 --> 00:15:52,800
были равны 1, мы все равно приближаемся к той же универсальной форме, которая просто ошеломляет.

187
00:15:55,040 --> 00:16:00,160
И сейчас, друзья мои, возможно, самое подходящее время наконец разобраться с формулой нормального

188
00:16:00,160 --> 00:16:04,800
распределения. И то, как я хотел бы это сделать, состоит в том, чтобы по сути снять все слои и построить их

189
00:16:04,800 --> 00:16:11,280
по одному кусочку за раз. Функция e для x или что-то еще для x описывает экспоненциальный рост,

190
00:16:11,280 --> 00:16:15,520
и если вы сделаете этот показатель отрицательным, который переворачивает график по горизонтали, вы можете

191
00:16:15,520 --> 00:16:20,000
думать о нем как об описании экспоненциального затухания. Чтобы сделать это затухание в обоих

192
00:16:20,000 --> 00:16:23,440
направлениях, вы можете сделать что-нибудь, чтобы показатель степени всегда был отрицательным и рос,

193
00:16:23,440 --> 00:16:28,160
например, приняв отрицательное абсолютное значение. Это дало бы нам неуклюжую острую точку посередине,

194
00:16:28,160 --> 00:16:32,240
но если вместо этого вы сделаете этот показатель отрицательным квадратом x, вы получите

195
00:16:32,240 --> 00:16:36,240
более гладкую версию того же самого объекта, который затухает в обоих направлениях.

196
00:16:36,240 --> 00:16:40,640
Это дает нам базовую форму колоколообразной кривой. Теперь, если вы поместите константу перед этим x и

197
00:16:40,640 --> 00:16:45,440
масштабируете эту константу вверх и вниз, это позволит вам растягивать и сжимать график по горизонтали, позволяя

198
00:16:45,440 --> 00:16:50,160
вам описывать узкие и более широкие кривые нормального распределения. И я хотел бы сразу отметить, что,

199
00:16:50,160 --> 00:16:56,080
основываясь на правилах возведения в степень, когда мы настраиваем константу c, вы также можете думать об

200
00:16:56,080 --> 00:17:01,680
этом как о простом изменении основания возведения в степень. И в этом смысле число e

201
00:17:01,680 --> 00:17:06,960
не является чем-то особенным для нашей формулы. Мы могли бы заменить ее любой другой положительной константой, и

202
00:17:06,960 --> 00:17:12,640
вы получите то же самое семейство кривых, когда мы настроим эту константу. Пусть это будет 2, одно и то же

203
00:17:12,640 --> 00:17:18,240
семейство кривых. Пусть это будет цифра 3, одно и то же семейство кривых. Причина, по которой мы используем e, заключается в том, что это

204
00:17:18,240 --> 00:17:23,280
придает константе очень понятный смысл. Или, скорее, если мы немного изменим ситуацию так, чтобы показатель

205
00:17:23,280 --> 00:17:28,160
степени выглядел как отрицательный, равный половине умноженного на х, деленного на определенную константу,

206
00:17:28,160 --> 00:17:33,520
которую мы назовем квадратом сигмы, то как только мы превратим это в распределение вероятностей,

207
00:17:33,520 --> 00:17:38,880
эта постоянная сигма будет быть стандартным отклонением этого распределения. И это очень приятно. Но

208
00:17:38,880 --> 00:17:43,600
прежде чем мы сможем интерпретировать это как распределение вероятностей, нам нужно, чтобы площадь под кривой была равна

209
00:17:43,600 --> 00:17:48,960
1. Причина этого в том, как интерпретируется кривая. В отличие от дискретных распределений,

210
00:17:48,960 --> 00:17:53,680
когда речь идет о чем-то непрерывном, вы не спрашиваете о вероятности конкретной точки.

211
00:17:53,680 --> 00:17:59,040
Вместо этого вы запрашиваете вероятность того, что значение попадает между двумя разными значениями. И кривая

212
00:17:59,040 --> 00:18:04,880
говорит вам, что эта вероятность равна площади под кривой между этими двумя значениями.

213
00:18:04,880 --> 00:18:09,680
Об этом есть совершенно другое видео, они называются функциями плотности вероятности.

214
00:18:09,680 --> 00:18:15,040
Главное сейчас то, что площадь под всей кривой представляет вероятность того, что что-то

215
00:18:15,040 --> 00:18:19,920
произойдет, что выпадет какое-то число. Это должно быть 1, поэтому мы хотим, чтобы площадь под ним была

216
00:18:19,920 --> 00:18:24,560
равна 1. В соответствии с базовой формой колоколообразной кривой от e до отрицательного квадрата x, площадь не равна

217
00:18:24,560 --> 00:18:30,240
1, на самом деле это квадратный корень из числа Пи. Я точно знаю? Что здесь делает Пи? Какое

218
00:18:30,240 --> 00:18:34,320
это имеет отношение к кругам? Как я уже сказал в начале, мне бы хотелось поговорить обо всем этом в

219
00:18:34,320 --> 00:18:38,640
следующем видео. Но если вы можете прямо сейчас потратить свое волнение на наши цели, все это означает, что нам

220
00:18:38,640 --> 00:18:43,680
нужно разделить эту функцию на квадратный корень из числа пи, и это даст нам нужную нам площадь. Возвращаясь к

221
00:18:43,680 --> 00:18:48,960
константам, которые мы использовали ранее, 1 половине и сигме, мы получаем эффект растягивания графика

222
00:18:48,960 --> 00:18:54,480
в сигму, умноженную на квадратный корень из 2. Поэтому нам также нужно разделить на это значение,

223
00:18:54,480 --> 00:18:58,960
чтобы убедиться, что его площадь равна 1. И, объединив эти дроби, множитель выглядит как 1, разделенная

224
00:18:58,960 --> 00:19:05,200
на сигму, умноженную на квадратный корень из 2 пи. Наконец, это действительное распределение

225
00:19:05,200 --> 00:19:10,880
вероятностей. Когда мы настраиваем это значение сигмы, что приводит к более узким и широким кривым,

226
00:19:10,880 --> 00:19:17,360
эта константа спереди всегда гарантирует, что площадь равна 1. Особый случай, когда сигма равна 1,

227
00:19:17,360 --> 00:19:22,400
имеет особое название, мы называем его стандартным нормальным распределением, которое играет для нас с

228
00:19:22,400 --> 00:19:27,600
вами в этом уроке особенно важную роль. И все возможные нормальные распределения не только параметризуются

229
00:19:27,600 --> 00:19:33,280
этим значением сигма, но мы также вычитаем еще одну константу мю из переменной x,

230
00:19:33,280 --> 00:19:38,080
и это, по сути, просто позволяет вам сдвигать график влево и вправо, чтобы вы могли

231
00:19:38,080 --> 00:19:43,280
прописать среднее значение этого распределения. Короче говоря, у нас есть два параметра: один описывает

232
00:19:43,280 --> 00:19:47,520
среднее значение, другой — стандартное отклонение, и все они связаны в одну большую формулу, включающую

233
00:19:47,520 --> 00:19:54,160
е и пи. Теперь, когда все это на столе, давайте еще раз вернемся к

234
00:19:54,160 --> 00:19:59,200
идее начать с некоторой случайной величины и задаться вопросом, как выглядят распределения сумм этой

235
00:19:59,200 --> 00:20:03,440
переменной. Как мы уже говорили, когда вы увеличиваете размер этой суммы, результирующее распределение

236
00:20:03,440 --> 00:20:08,480
будет смещаться в соответствии с растущим средним значением и медленно распространяться в соответствии с

237
00:20:08,480 --> 00:20:13,360
растущим стандартным отклонением. И, применив к этому некоторые реальные формулы, если мы знаем среднее значение

238
00:20:13,360 --> 00:20:18,240
нашей базовой случайной величины, мы называем ее мю, и мы также знаем ее стандартное отклонение и

239
00:20:18,240 --> 00:20:24,000
называем ее сигмой, тогда среднее значение суммы внизу будет мю. умножить на размер суммы, а стандартное

240
00:20:24,000 --> 00:20:29,600
отклонение будет равно сигме, умноженной на квадратный корень из этого размера. Итак, теперь, если мы хотим

241
00:20:29,600 --> 00:20:34,240
заявить, что это все больше и больше похоже на колоколообразную кривую, а колоколообразная кривая описывается только двумя

242
00:20:34,240 --> 00:20:38,800
разными параметрами: средним значением и стандартным отклонением, вы знаете, что делать. Вы можете подставить эти

243
00:20:38,800 --> 00:20:43,840
два значения в формулу, и это даст вам весьма явную, хотя и

244
00:20:43,840 --> 00:20:46,960
довольно сложную формулу для кривой, которая должна точно соответствовать нашему распределению.

245
00:20:48,480 --> 00:20:52,960
Но есть и другой способ описать это, более элегантный и создающий очень забавный визуальный

246
00:20:52,960 --> 00:20:57,920
эффект, который мы можем создать. Вместо того, чтобы сосредотачиваться на сумме всех этих случайных величин,

247
00:20:57,920 --> 00:21:02,560
давайте немного изменим это выражение: мы посмотрим на среднее значение, которое, как мы ожидаем, примет

248
00:21:02,560 --> 00:21:07,600
эта сумма, и вычтем его так, чтобы наше новое выражение имеет среднее значение 0, а затем

249
00:21:08,160 --> 00:21:12,560
мы посмотрим на стандартное отклонение, которое мы ожидаем от нашей суммы, и разделим на него,

250
00:21:12,560 --> 00:21:17,920
что по сути просто меняет масштаб единиц, так что стандартное отклонение нашего выражения будет равно

251
00:21:17,920 --> 00:21:22,960
1. . Это выражение может показаться более сложным, но на самом деле оно имеет

252
00:21:22,960 --> 00:21:28,800
очень читаемый смысл. По сути, это вопрос о том, на сколько стандартных отклонений от среднего значения находится

253
00:21:28,800 --> 00:21:34,800
эта сумма? Например, эта полоса здесь соответствует определенному значению, которое вы можете найти, когда

254
00:21:34,800 --> 00:21:39,520
бросаете 10 игральных костей и суммируете их все, и ее положение немного выше отрицательной

255
00:21:39,520 --> 00:21:43,760
1 говорит вам, что это значение немного меньше одного стандартного отклонения. ниже среднего.

256
00:21:44,800 --> 00:21:49,680
Кроме того, кстати, в предвкушении анимации, которую я пытаюсь здесь построить, я представляю

257
00:21:49,680 --> 00:21:54,880
вещи на нижнем графике так: площадь каждой из этих полос говорит нам о

258
00:21:54,880 --> 00:21:59,440
вероятности соответствующего значения. а не высота. Вы можете подумать, что ось Y представляет собой

259
00:21:59,440 --> 00:22:04,400
не вероятность, а своего рода плотность вероятности. Причина этого в том, чтобы подготовить почву

260
00:22:04,400 --> 00:22:08,800
так, чтобы она соответствовала тому, как мы интерпретируем непрерывные распределения, где вероятность попадания

261
00:22:08,800 --> 00:22:14,400
в диапазон значений равна площади под кривой между этими значениями. В частности, площадь

262
00:22:14,400 --> 00:22:20,400
всех столбцов вместе будет равна 1. Теперь, когда все это готово, давайте немного

263
00:22:20,400 --> 00:22:24,960
повеселимся. Позвольте мне начать с отката назад, чтобы распределение внизу представляло собой относительно небольшую сумму,

264
00:22:24,960 --> 00:22:30,160
как если бы вы сложили вместе только три таких случайных величины. Обратите внимание, что происходит,

265
00:22:30,160 --> 00:22:35,440
когда я меняю дистрибутив, с которого мы начали. При его изменении распределение внизу полностью меняет

266
00:22:35,440 --> 00:22:42,240
свою форму. Это очень зависит от того, с чего мы начали. Если мы позволим размеру нашей суммы стать

267
00:22:42,240 --> 00:22:47,760
немного больше, скажем, до 10, и когда я изменю распределение для x, она в основном останется

268
00:22:47,760 --> 00:22:52,240
похожей на колоколообразную кривую, но я могу найти некоторые распределения, которые заставят ее изменить форму. . Например,

269
00:22:52,240 --> 00:22:57,600
действительно однобокий вариант, где почти вся вероятность заключена в числах 1 или 6, приводит

270
00:22:57,600 --> 00:23:02,400
к такой остроконечной колоколообразной кривой, и, если вы помните, ранее я фактически показал это

271
00:23:02,400 --> 00:23:07,120
в форме моделирования. Итак, если вам интересно, была ли эта остроконечность артефактом

272
00:23:07,120 --> 00:23:12,160
случайности или отражала истинное распределение, оказывается, она отражает истинное распределение.

273
00:23:12,160 --> 00:23:17,040
В этом случае 10 — недостаточно большая сумма для того, чтобы сработала центральная предельная теорема. Но если вместо

274
00:23:17,040 --> 00:23:22,400
этого я позволю этой сумме расти и рассмотрю возможность добавления 50 различных значений, что на самом деле не

275
00:23:22,960 --> 00:23:28,480
так уж и много, то независимо от того, как я изменю распределение нашей базовой случайной величины, это по

276
00:23:28,480 --> 00:23:33,280
существу не повлияет на форму графика на нижний. Независимо от того, с чего мы начинаем, вся

277
00:23:33,280 --> 00:23:38,640
информация и нюансы распределения x смываются, и мы склоняемся к этой единственной универсальной форме, описываемой очень

278
00:23:38,640 --> 00:23:44,160
элегантной функцией для стандартного нормального распределения: 1 вместо квадратного корня из 2 пи, умноженных на e.

279
00:23:44,160 --> 00:23:49,920
к отрицательному х в квадрате более 2. Вот в этом-то и состоит суть центральной

280
00:23:49,920 --> 00:23:54,480
предельной теоремы. Почти ничего, что вы можете сделать с этим начальным распределением, не меняет форму, к

281
00:23:54,480 --> 00:24:02,960
которой мы стремимся. Те из вас, кто более склонен к теории, возможно, все еще задаются вопросом, какова

282
00:24:02,960 --> 00:24:07,280
на самом деле теорема? Например, какое математическое утверждение мы здесь утверждаем, которое

283
00:24:07,280 --> 00:24:11,440
можно доказать или опровергнуть? Если вам нужно красивое официальное заявление, вот как это может быть.

284
00:24:12,080 --> 00:24:16,720
Рассмотрим это значение, где мы суммируем n различных экземпляров нашей случайной величины, но изменены и

285
00:24:16,720 --> 00:24:21,040
настроены так, что ее среднее значение и стандартное отклонение равны 1. Опять же, это означает, что

286
00:24:21,040 --> 00:24:26,640
вы можете прочитать это как вопрос, на сколько стандартных отклонений от среднего составляет сумма. Тогда фактическая строгая

287
00:24:26,640 --> 00:24:30,880
формулировка центральной предельной теоремы (на этот раз без шуток): если вы рассматриваете вероятность того,

288
00:24:30,880 --> 00:24:37,040
что это значение попадает между двумя заданными действительными числами, a и b, и вы

289
00:24:37,040 --> 00:24:43,520
рассматриваете предел этой вероятности как размер ваша сумма стремится к бесконечности, тогда этот предел

290
00:24:43,520 --> 00:24:48,560
равен определенному интегралу, который в основном описывает площадь при стандартном нормальном распределении между этими

291
00:24:48,560 --> 00:24:55,040
двумя значениями. Опять же, есть три основных предположения, о которых мне еще предстоит вам рассказать,

292
00:24:55,040 --> 00:24:59,760
но кроме них, во всех кровавых подробностях, вот это и есть центральная предельная теорема.

293
00:25:04,720 --> 00:25:08,480
Все это немного теоретически, поэтому было бы полезно вернуться на Землю и вернуться к конкретному

294
00:25:08,480 --> 00:25:12,560
примеру, который я упомянул в начале, где вы представляете, что бросаете игральную кость 100

295
00:25:12,560 --> 00:25:17,520
раз, и давайте предположим, что это справедливый результат. для этого примера, и вы суммируете

296
00:25:17,520 --> 00:25:23,680
результаты. Ваша задача — найти такой диапазон значений, в котором вы на 95 % уверены, что

297
00:25:23,680 --> 00:25:29,040
сумма будет находиться в этом диапазоне. Для подобных вопросов существует удобное эмпирическое правило нормального распределения,

298
00:25:29,040 --> 00:25:34,080
которое гласит, что около 68% ваших значений будут находиться в пределах одного стандартного отклонения

299
00:25:34,080 --> 00:25:39,520
от среднего значения, а 95% ваших значений, то, что нас волнует, попадают в этот диапазон.

300
00:25:39,520 --> 00:25:45,440
два стандартных отклонения среднего значения и колоссальные 99. 7% ваших значений будут находиться в пределах трех

301
00:25:45,440 --> 00:25:49,920
стандартных отклонений от среднего значения. Это практическое правило, которое обычно запоминают люди, которые много

302
00:25:49,920 --> 00:25:55,040
занимаются вероятностями и статистикой. Естественно, это дает нам то, что нам нужно для нашего

303
00:25:55,040 --> 00:25:59,200
примера, и позвольте мне нарисовать, как это будет выглядеть, где я покажу распределение для

304
00:25:59,200 --> 00:26:05,040
справедливого кубика вверху и распределение для суммы 100. такие игральные кости внизу, которые, как

305
00:26:05,040 --> 00:26:09,600
вы знаете, теперь выглядят как некое нормальное распределение. Первый шаг в решении подобной проблемы — найти

306
00:26:09,600 --> 00:26:14,720
среднее значение вашего начального распределения, которое в данном случае будет выглядеть как 16-е, умноженное на 1, плюс 16-е, умноженное

307
00:26:14,720 --> 00:26:20,880
на 2, и так далее, и в итоге будет равно 3. 5. Нам также нужно стандартное отклонение, для

308
00:26:20,880 --> 00:26:25,440
которого требуется вычислить дисперсию, которая, как вы знаете, включает в себя сложение всех квадратов

309
00:26:25,440 --> 00:26:30,800
разностей между значениями и средними значениями, и в результате получается 2. 92, квадратный корень из

310
00:26:30,800 --> 00:26:36,000
которого равен 1. 71. Это единственные два числа, которые нам нужны, и я снова приглашаю вас

311
00:26:36,000 --> 00:26:40,160
задуматься о том, насколько волшебно то, что это единственные два числа, которые вам нужны

312
00:26:40,160 --> 00:26:46,560
для полного понимания нижнего распределения. Его среднее значение будет в 100 раз мю, что равно 350, а

313
00:26:46,560 --> 00:26:53,600
его стандартное отклонение будет равно квадратному корню из 100-кратного сигмы, то есть 10-кратного сигмы 17. 1. Помня наше удобное

314
00:26:53,600 --> 00:26:58,320
эмпирическое правило, мы ищем значения, отстоящие на два стандартных отклонения от среднего значения, и когда вы

315
00:26:58,320 --> 00:27:04,800
вычитаете 2 сигмы из среднего значения, вы получаете примерно 316, а когда вы добавляете 2

316
00:27:04,960 --> 00:27:08,880
сигмы, вы получаете 384. И вот, это дает нам ответ.

317
00:27:11,600 --> 00:27:15,840
Хорошо, я обещал подвести итоги в ближайшее время, но пока мы рассматриваем этот пример, есть еще один

318
00:27:15,840 --> 00:27:21,440
вопрос, на который стоит потратить время. Вместо того, чтобы просто спрашивать о сумме 100 бросков кубика,

319
00:27:21,440 --> 00:27:25,840
предположим, я попросил вас разделить это число на 100, что по сути означает, что все числа на

320
00:27:25,840 --> 00:27:31,120
нашей диаграмме внизу делятся на 100. Найдите минутку, чтобы интерпретировать, о чем все это говорит тогда.

321
00:27:31,120 --> 00:27:36,560
По сути, это выражение сообщает вам эмпирическое среднее значение для 100 различных бросков кубика, и

322
00:27:37,200 --> 00:27:43,040
найденный нами интервал теперь говорит вам, какой диапазон вы ожидаете увидеть для этого эмпирического среднего

323
00:27:43,040 --> 00:27:48,480
значения. Другими словами, вы можете ожидать, что оно будет около 3. 5, это ожидаемое значение для броска

324
00:27:48,480 --> 00:27:53,200
кубика, но что гораздо менее очевидно и что позволяет вычислить центральная предельная теорема, так это

325
00:27:53,200 --> 00:27:58,640
то, насколько близко к этому ожидаемому значению вы окажетесь. В частности, стоит уделить время

326
00:27:58,640 --> 00:28:03,680
размышлениям о том, каково стандартное отклонение для этого эмпирического среднего значения и что с

327
00:28:03,680 --> 00:28:07,040
ним происходит, когда вы смотрите на все большую и большую выборку бросков кубика.

328
00:28:12,960 --> 00:28:17,920
И наконец, но, вероятно, самое главное: давайте поговорим о предположениях, лежащих в основе этой теоремы.

329
00:28:17,920 --> 00:28:22,720
Во-первых, все эти переменные, которые мы суммируем, независимы друг от друга.

330
00:28:22,720 --> 00:28:26,320
Результат одного процесса не влияет на результат любого другого процесса.

331
00:28:27,040 --> 00:28:31,440
Во-вторых, все эти переменные взяты из одного и того же распределения.

332
00:28:31,440 --> 00:28:35,920
Оба этих условия неявно предполагались в нашем примере с игральными костями. Мы рассматривали результат каждого

333
00:28:35,920 --> 00:28:40,400
броска кубика как независимый от результата всех остальных и предполагаем, что каждый

334
00:28:40,400 --> 00:28:45,040
кубик имеет одинаковое распределение. Иногда в литературе вы встретите эти два

335
00:28:45,040 --> 00:28:50,320
предположения, объединенные инициалами IID, обозначающими независимые и одинаково распределенные.

336
00:28:50,320 --> 00:28:55,440
Одной из ситуаций, когда эти предположения явно неверны, является совет директоров Гальтона.

337
00:28:55,440 --> 00:29:00,320
Я имею в виду, подумай об этом. Действительно ли то, как мяч отскочит от одного из колышков, не

338
00:29:00,320 --> 00:29:05,200
зависит от того, как он отскочит от следующего колышка? Точно нет. В зависимости от

339
00:29:05,200 --> 00:29:09,200
последнего отскока он движется по совершенно разной траектории. И действительно ли распределение

340
00:29:09,200 --> 00:29:15,600
возможных результатов для каждой привязки одинаково для каждой привязки, к которой она попадает? Опять же,

341
00:29:15,600 --> 00:29:19,680
почти наверняка нет. Может быть, он попадает в одну точку, глядя влево, а это означает,

342
00:29:19,680 --> 00:29:23,680
что результаты сильно искажаются в этом направлении, а затем попадает в следующую точку, глядя вправо.

343
00:29:25,680 --> 00:29:30,320
Когда я сделал все эти упрощающие предположения в первом примере, я делал это не только для того, чтобы об

344
00:29:30,320 --> 00:29:35,120
этом было легче думать. Кроме того, эти предположения были необходимы для того, чтобы это

345
00:29:35,120 --> 00:29:39,920
действительно было примером центральной предельной теоремы. Тем не менее, похоже, что для

346
00:29:39,920 --> 00:29:45,040
реальной доски Гальтона, несмотря на нарушение обоих условий, нормальное распределение все-таки получается?

347
00:29:45,040 --> 00:29:49,840
Частично причина может заключаться в том, что существуют обобщения теоремы, выходящие за

348
00:29:49,920 --> 00:29:55,120
рамки этого видео, которые ослабляют эти предположения, особенно второе. Но я хочу

349
00:29:55,120 --> 00:29:59,520
предостеречь вас от того факта, что часто люди предполагают, что переменная распределяется

350
00:29:59,520 --> 00:30:05,200
нормально, даже если для этого нет реального обоснования. Третье предположение на самом

351
00:30:05,200 --> 00:30:10,800
деле довольно тонкое. Дело в том, что дисперсия, которую мы вычисляли для этих переменных, конечна.

352
00:30:10,800 --> 00:30:15,120
В примере с игральными костями это никогда не было проблемой, поскольку возможных исходов было только шесть.

353
00:30:15,120 --> 00:30:19,280
Но в некоторых ситуациях, когда у вас есть бесконечный набор результатов, когда вы начинаете вычислять

354
00:30:19,280 --> 00:30:25,200
дисперсию, сумма в конечном итоге расходится до бесконечности. Это могут быть совершенно правильные распределения вероятностей,

355
00:30:25,200 --> 00:30:30,160
и они действительно встречаются на практике. Но в таких ситуациях, когда вы рассматриваете возможность

356
00:30:30,160 --> 00:30:34,720
добавления множества различных экземпляров этой переменной и позволяете этой сумме приближаться к бесконечности, даже если

357
00:30:34,720 --> 00:30:39,520
первые два предположения верны, весьма вероятно, что то, к чему вы склонны, на самом

358
00:30:39,520 --> 00:30:44,320
деле не является нормальным распределением. Если вы все поняли до этого момента, то теперь у

359
00:30:44,320 --> 00:30:48,960
вас есть очень прочная основа в том, что такое центральная предельная теорема. И далее я

360
00:30:48,960 --> 00:30:53,200
хотел бы объяснить, почему именно эта функция является тем, к чему мы склонны,

361
00:30:53,200 --> 00:30:56,640
и почему в ней есть число «пи», какое отношение она имеет к кругам.

