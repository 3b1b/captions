1
00:00:00,000 --> 00:00:01,392
Это доска Гальтона.

2
00:00:01,392 --> 00:00:05,543
Возможно, вы видели такое раньше: это популярная демонстрация того, что даже

3
00:00:05,543 --> 00:00:09,802
когда одно событие хаотично и случайно, с практически неизвестным результатом,

4
00:00:09,802 --> 00:00:13,845
все еще возможно делать точные утверждения о большом количестве событий, а

5
00:00:13,845 --> 00:00:18,320
именно, как относительные пропорции для многих различных результатов распределены.

6
00:00:18,320 --> 00:00:23,069
Более конкретно, доска Гальтона иллюстрирует одно из наиболее ярких распределений

7
00:00:23,069 --> 00:00:27,413
во всей вероятности, известное как нормальное распределение, в просторечии

8
00:00:27,413 --> 00:00:31,930
называемое колоколообразной кривой, а также называемое распределением Гаусса.

9
00:00:31,930 --> 00:00:35,263
Для описания этого распределения есть очень специфическая функция, она очень

10
00:00:35,263 --> 00:00:38,510
красивая, мы займемся этим позже, но сейчас я просто хочу подчеркнуть, что

11
00:00:38,510 --> 00:00:41,670
нормальное распределение, как следует из названия, очень распространено,

12
00:00:41,670 --> 00:00:44,960
оно встречается во многих случаях. из, казалось бы, несвязанных контекстов.

13
00:00:44,960 --> 00:00:47,723
Если вы возьмете большое количество людей, относящихся к одной и

14
00:00:47,723 --> 00:00:50,657
той же демографической группе, и нанесете на график их рост, то этот

15
00:00:50,657 --> 00:00:53,548
рост, как правило, будет соответствовать нормальному распределению.

16
00:00:53,548 --> 00:00:57,182
Если вы посмотрите на большой набор очень больших натуральных чисел и

17
00:00:57,182 --> 00:01:01,023
спросите, сколько различных простых делителей имеет каждое из этих чисел,

18
00:01:01,023 --> 00:01:05,280
ответы будут очень точно соответствовать определенному нормальному распределению.

19
00:01:05,280 --> 00:01:08,865
Наша сегодняшняя тема — одна из жемчужин всей теории вероятностей, это

20
00:01:08,865 --> 00:01:12,550
один из ключевых фактов, объясняющих, почему это распределение настолько

21
00:01:12,550 --> 00:01:16,035
распространено, что оно известно как центральная предельная теорема.

22
00:01:16,035 --> 00:01:18,763
Этот урок предназначен для того, чтобы вернуться к основам, дать вам

23
00:01:18,763 --> 00:01:21,650
основные сведения о том, что говорит центральная предельная теорема, что

24
00:01:21,650 --> 00:01:24,774
такое нормальные распределения, и я хочу предположить минимальную предысторию.

25
00:01:24,774 --> 00:01:29,190
Мы собираемся углубиться в это, но после этого мне все же хотелось бы пойти глубже

26
00:01:29,190 --> 00:01:33,446
и объяснить, почему теорема верна, почему функция, лежащая в основе нормального

27
00:01:33,446 --> 00:01:37,649
распределения, имеет очень специфическую форму, почему эта формула имеет в нем

28
00:01:37,649 --> 00:01:42,012
есть число «пи», и, что самое интересное, почему эти два последних факта на самом

29
00:01:42,012 --> 00:01:46,374
деле связаны между собой больше, чем предполагают многие традиционные объяснения.

30
00:01:46,374 --> 00:01:49,634
Этот второй урок также должен стать продолжением обещанного мной

31
00:01:49,634 --> 00:01:53,144
видео по извилистым волосам, так что здесь много взаимосвязанных тем.

32
00:01:53,144 --> 00:01:56,681
Но сейчас, возвращаясь к основам, я хотел бы начать

33
00:01:56,681 --> 00:01:59,811
с чрезмерно упрощенной модели доски Гальтона.

34
00:01:59,811 --> 00:02:03,334
В этой модели мы будем предполагать, что каждый шар падает прямо на

35
00:02:03,334 --> 00:02:06,910
определенный центральный колышек и что вероятность его отскока влево

36
00:02:06,910 --> 00:02:10,381
или вправо составляет 50 на 50, и мы будем думать о каждом из этих

37
00:02:10,381 --> 00:02:14,320
результатов как о добавлении одного или вычитание единицы из своей позиции.

38
00:02:14,320 --> 00:02:18,651
Как только один из них выбран, мы делаем крайне нереалистичное предположение,

39
00:02:18,651 --> 00:02:22,927
что он случайно приземлится в середине колышка, примыкающего под ним, где он

40
00:02:22,927 --> 00:02:26,981
снова столкнется с тем же выбором 50 на 50: отскочить влево или Направо.

41
00:02:26,981 --> 00:02:31,028
Для того, что я показываю на экране, есть пять разных рядов колышков, поэтому

42
00:02:31,028 --> 00:02:34,816
наш маленький прыгающий шарик делает пять разных случайных выборов между

43
00:02:34,816 --> 00:02:38,604
плюс один и минус один, и мы можем думать о его конечном положении как о

44
00:02:38,604 --> 00:02:42,547
сумме всех из этих разных чисел, которое в данном случае оказывается одним,

45
00:02:42,547 --> 00:02:46,542
и мы могли бы пометить все разные сегменты суммой, которую они представляют.

46
00:02:46,542 --> 00:02:51,749
Повторяя это, мы рассматриваем различные возможные суммы этих пяти случайных чисел.

47
00:02:51,749 --> 00:02:55,117
А для тех из вас, кто склонен жаловаться на то, что это крайне

48
00:02:55,117 --> 00:02:58,432
нереалистичная модель настоящей платы Гальтона, позвольте мне

49
00:02:58,432 --> 00:03:01,800
подчеркнуть, что цель сейчас не в точном моделировании физики.

50
00:03:01,800 --> 00:03:04,576
Цель состоит в том, чтобы дать простой пример, иллюстрирующий

51
00:03:04,576 --> 00:03:07,442
центральную предельную теорему, и, каким бы идеализированным он

52
00:03:07,442 --> 00:03:10,308
ни был, на самом деле он дает нам действительно хороший пример.

53
00:03:10,308 --> 00:03:13,569
Если мы позволим упасть множеству разных шаров, сделав еще одно нереалистичное

54
00:03:13,569 --> 00:03:17,076
предположение, что они не влияют друг на друга, как если бы они все были призраками,

55
00:03:17,076 --> 00:03:20,584
тогда количество шаров, попадающих в каждое ведро, даст нам некоторое неопределенное

56
00:03:20,584 --> 00:03:23,680
представление о том, насколько вероятен каждый из них. из этих ведер есть.

57
00:03:23,680 --> 00:03:26,881
В этом примере числа достаточно просты, поэтому нетрудно

58
00:03:26,881 --> 00:03:29,859
явно вычислить вероятность попадания в каждое ведро.

59
00:03:29,859 --> 00:03:31,922
Если вы захотите обдумать это, вы обнаружите,

60
00:03:31,922 --> 00:03:33,985
что это очень напоминает треугольник Паскаля.

61
00:03:33,985 --> 00:03:38,148
Но самое интересное в нашей теореме то, что она выходит далеко за рамки простых примеров.

62
00:03:38,148 --> 00:03:40,959
Итак, по крайней мере, для начала, вместо того, чтобы проводить явные

63
00:03:40,959 --> 00:03:44,051
вычисления, давайте просто смоделируем ситуацию, запустив большое количество

64
00:03:44,051 --> 00:03:47,062
выборок и позволив общему количеству результатов в каждом отдельном исходе

65
00:03:47,062 --> 00:03:49,953
дать нам некоторое представление о том, как выглядит это распределение.

66
00:03:49,953 --> 00:03:53,242
Как я уже сказал, на экране пять строк, поэтому каждая

67
00:03:53,242 --> 00:03:56,231
рассматриваемая сумма включает только пять чисел.

68
00:03:56,231 --> 00:04:00,716
Основная идея центральной предельной теоремы заключается в том, что если вы увеличите

69
00:04:00,716 --> 00:04:04,991
размер этой суммы, например здесь, это будет означать увеличение количества рядов

70
00:04:04,991 --> 00:04:09,058
колышков для каждого шара, от которого отскочит, тогда распределение, которое

71
00:04:09,058 --> 00:04:13,646
описывает, куда пойдет эта сумма. падение все больше похоже на колоколообразную кривую.

72
00:04:13,646 --> 00:04:19,040
Здесь действительно стоит потратить время на то, чтобы записать эту общую идею.

73
00:04:19,040 --> 00:04:23,728
Установка такова, что у нас есть случайная переменная, и это, по сути, сокращение для

74
00:04:23,728 --> 00:04:28,306
случайного процесса, где каждый результат этого процесса связан с некоторым числом.

75
00:04:28,306 --> 00:04:30,031
Мы назовем это случайное число x.

76
00:04:30,031 --> 00:04:32,509
Например, каждый отскок от прищепки — это случайный

77
00:04:32,509 --> 00:04:34,416
процесс, моделируемый с двумя исходами.

78
00:04:34,416 --> 00:04:38,173
Эти результаты связаны с числами «отрицательный» и «положительный».

79
00:04:38,173 --> 00:04:41,553
Другим примером случайной величины может быть бросок игральной кости, в результате

80
00:04:41,553 --> 00:04:44,851
которого у вас есть шесть разных результатов, каждый из которых связан с числом.

81
00:04:44,851 --> 00:04:50,423
Мы берем несколько разных образцов этой переменной и складываем их все вместе.

82
00:04:50,423 --> 00:04:53,837
На нашей доске Гальтона это выглядит так, будто мяч отскакивает от

83
00:04:53,837 --> 00:04:57,505
нескольких разных колышков на пути вниз, а в случае с кубиком вы можете

84
00:04:57,505 --> 00:05:01,174
представить, что бросаете много разных кубиков и суммируете результаты.

85
00:05:01,174 --> 00:05:04,620
Утверждение центральной предельной теоремы состоит в том, что по мере того,

86
00:05:04,620 --> 00:05:07,795
как вы позволяете размеру этой суммы становиться все больше и больше,

87
00:05:07,795 --> 00:05:11,061
распределение этой суммы, вероятность того, что она попадет в различные

88
00:05:11,061 --> 00:05:14,780
возможные значения, будет все больше и больше напоминать колоколообразную кривую.

89
00:05:14,780 --> 00:05:17,051
Вот и все, это общая идея.

90
00:05:17,051 --> 00:05:21,748
В ходе этого урока наша задача — сделать это утверждение более количественным.

91
00:05:21,748 --> 00:05:23,976
Мы собираемся добавить к нему некоторые цифры, формулы и

92
00:05:23,976 --> 00:05:26,400
показать, как вы можете использовать его для прогнозирования.

93
00:05:26,400 --> 00:05:31,440
Например, вот вопрос, на который я хочу, чтобы вы смогли ответить к концу этого видео.

94
00:05:31,440 --> 00:05:36,327
Предположим, вы бросили игральную кость 100 раз и сложили результаты.

95
00:05:36,327 --> 00:05:39,262
Можете ли вы найти такой диапазон значений, в котором

96
00:05:39,262 --> 00:05:42,251
вы на 95 % уверены, что сумма попадет в этот диапазон?

97
00:05:42,251 --> 00:05:44,559
Или, может быть, мне следует сказать: найдите наименьший

98
00:05:44,559 --> 00:05:46,826
возможный диапазон значений, в котором это будет верно.

99
00:05:46,826 --> 00:05:49,695
Самое интересное, что вы сможете ответить на этот

100
00:05:49,695 --> 00:05:52,909
вопрос, является ли это честным кубиком или взвешенным.

101
00:05:52,909 --> 00:05:56,356
Теперь позвольте мне сказать вверху, что эта теорема включает в себя три различных

102
00:05:56,356 --> 00:06:00,093
предположения, три вещи, которые должны быть верными, прежде чем из нее вытекает теорема.

103
00:06:00,093 --> 00:06:03,836
И я на самом деле не собираюсь рассказывать вам, что это такое, до самого конца видео.

104
00:06:03,836 --> 00:06:06,882
Вместо этого я хочу, чтобы вы внимательно наблюдали и посмотрели, сможете

105
00:06:06,882 --> 00:06:10,051
ли вы заметить и, возможно, предсказать, какими будут эти три предположения.

106
00:06:10,051 --> 00:06:12,513
В качестве следующего шага, чтобы лучше проиллюстрировать,

107
00:06:12,513 --> 00:06:14,933
насколько общей является эта теорема, я хочу провести для

108
00:06:14,933 --> 00:06:17,645
вас еще пару симуляций, сосредоточенных на примере игры в кости.

109
00:06:17,645 --> 00:06:22,844
Обычно, когда вы думаете о броске игральной кости, вы думаете, что шесть

110
00:06:22,844 --> 00:06:27,830
исходов равновероятны, но на самом деле теорема не заботится об этом.

111
00:06:27,830 --> 00:06:31,313
Мы могли бы начать с взвешенной кости, чего-то с нетривиальным

112
00:06:31,313 --> 00:06:34,741
распределением результатов, и основная идея останется в силе.

113
00:06:34,741 --> 00:06:37,272
Для моделирования я возьму некоторое распределение,

114
00:06:37,272 --> 00:06:39,948
подобное этому, со сдвигом в сторону меньших значений.

115
00:06:39,948 --> 00:06:43,887
Я возьму 10 различных выборок из этого распределения,

116
00:06:43,887 --> 00:06:47,680
а затем запишу сумму этой выборки на графике внизу.

117
00:06:47,680 --> 00:06:51,186
Затем я собираюсь сделать это много-много раз, всегда с суммой

118
00:06:51,186 --> 00:06:54,581
размером 10, но отслеживайте, где в конечном итоге оказались

119
00:06:54,581 --> 00:06:57,753
эти суммы, чтобы дать нам представление о распределении.

120
00:06:57,753 --> 00:07:01,188
И на самом деле, позвольте мне изменить масштаб по направлению y,

121
00:07:01,188 --> 00:07:04,832
чтобы дать нам возможность выполнить еще большее количество образцов.

122
00:07:04,832 --> 00:07:08,615
И я позволю этому увеличиться до пары тысяч, и при этом вы заметите, что

123
00:07:08,615 --> 00:07:12,555
фигура, которая начинает проявляться, выглядит как колоколообразная кривая.

124
00:07:12,555 --> 00:07:16,629
Возможно, если вы прищуритесь, вы увидите, что он немного смещается влево, но это

125
00:07:16,629 --> 00:07:21,001
здорово, что что-то столь симметричное возникло из такой асимметричной отправной точки.

126
00:07:21,001 --> 00:07:24,807
Чтобы лучше проиллюстрировать суть центральной предельной теоремы, позвольте мне

127
00:07:24,807 --> 00:07:28,755
запустить четыре таких моделирования параллельно: в левом верхнем углу я делаю это,

128
00:07:28,755 --> 00:07:32,843
когда мы добавляем только две игральные кости за раз, а в верхнем правом мы: Мы делаем

129
00:07:32,843 --> 00:07:36,931
это, когда мы добавляем пять кубиков за раз, нижний левый — это тот, который мы только

130
00:07:36,931 --> 00:07:41,113
что видели, добавляя по 10 кубиков за раз, а затем мы сделаем еще один с большей суммой,

131
00:07:41,113 --> 00:07:41,630
15 за раз.

132
00:07:41,630 --> 00:07:44,886
Обратите внимание, что в левом верхнем углу, когда мы просто добавляем два

133
00:07:44,886 --> 00:07:48,359
кубика, полученное распределение на самом деле не выглядит как колоколообразная

134
00:07:48,359 --> 00:07:51,920
кривая, оно намного больше напоминает то, с которым мы начали, с перекосом влево.

135
00:07:51,920 --> 00:07:55,875
Но поскольку мы учитываем все больше и больше кубиков в каждой сумме, результирующая

136
00:07:55,875 --> 00:07:59,737
форма, возникающая в этих распределениях, выглядит все более и более симметричной.

137
00:07:59,737 --> 00:08:04,582
У него есть выступ посередине, а хвост плавно переходит в колоколообразную форму.

138
00:08:04,582 --> 00:08:10,640
И еще раз подчеркну: начать можно с любого другого дистрибутива.

139
00:08:10,640 --> 00:08:14,120
Здесь я запущу его еще раз, но большая часть вероятности связана

140
00:08:14,120 --> 00:08:17,707
с числами 1 и 6, с очень низкой вероятностью для средних значений.

141
00:08:17,707 --> 00:08:22,241
Несмотря на полное изменение распределения для отдельного броска игральной кости, форма

142
00:08:22,241 --> 00:08:26,723
колоколообразной кривой по-прежнему возникает, когда мы рассматриваем различные суммы.

143
00:08:26,723 --> 00:08:30,660
Иллюстрировать вещи с помощью такой симуляции очень весело, и приятно

144
00:08:30,660 --> 00:08:35,103
видеть, как порядок возникает из хаоса, но это также кажется немного неточным.

145
00:08:35,103 --> 00:08:39,256
Как в этом случае, когда я отсек симуляцию на 3000 выборках, хотя она выглядит

146
00:08:39,256 --> 00:08:42,989
как колоколообразная кривая, разные сегменты кажутся довольно резкими.

147
00:08:42,989 --> 00:08:45,722
И вы можете задаться вопросом, так ли это должно

148
00:08:45,722 --> 00:08:49,013
выглядеть или это просто артефакт случайности в симуляции?

149
00:08:49,013 --> 00:08:51,931
И если да, то сколько образцов нам нужно, прежде чем мы сможем быть уверены,

150
00:08:51,931 --> 00:08:55,040
что то, на что мы смотрим, является репрезентативным для истинного распределения?

151
00:08:55,040 --> 00:09:00,185
Вместо того, чтобы двигаться вперед, давайте немного больше теоретического и

152
00:09:00,185 --> 00:09:05,731
покажем точную форму, которую эти распределения примут в долгосрочной перспективе.

153
00:09:05,731 --> 00:09:09,851
Проще всего выполнить этот расчет, если у нас есть равномерное распределение,

154
00:09:09,851 --> 00:09:13,760
где каждая возможная грань игральной кости имеет равную вероятность, 1/6.

155
00:09:13,760 --> 00:09:17,592
Например, если вы затем хотите узнать, насколько вероятны разные суммы для

156
00:09:17,592 --> 00:09:21,679
пары игральных костей, это, по сути, игра подсчета, в которой вы подсчитываете,

157
00:09:21,679 --> 00:09:25,716
сколько различных пар составляют одну и ту же сумму, что на диаграмме, которую

158
00:09:25,716 --> 00:09:29,650
я нарисовал, вы можно удобно обдумать, пройдя через все различные диагонали.

159
00:09:29,650 --> 00:09:33,590
Поскольку вероятность появления каждой такой пары равна

160
00:09:33,590 --> 00:09:37,741
1 из 36, вам остается только посчитать размеры этих ведер.

161
00:09:37,741 --> 00:09:41,317
Это дает нам окончательную форму распределения, описывающего сумму двух

162
00:09:41,317 --> 00:09:44,844
игральных костей, и если бы мы играли в ту же игру со всеми возможными

163
00:09:44,844 --> 00:09:48,173
тройками, полученное распределение выглядело бы следующим образом.

164
00:09:48,173 --> 00:09:51,636
Теперь, что более сложно, но гораздо интереснее, это спросить, что произойдет,

165
00:09:51,636 --> 00:09:55,011
если у нас будет неравномерное распределение для этого единственного кубика.

166
00:09:55,011 --> 00:09:58,066
Обо всём этом мы, собственно, и говорили в прошлом видео.

167
00:09:58,066 --> 00:10:01,115
По сути, вы делаете то же самое: перебираете все различные пары

168
00:10:01,115 --> 00:10:03,974
игральных костей, сумма которых дает одно и то же значение.

169
00:10:03,974 --> 00:10:08,288
Просто вместо того, чтобы считать эти пары, вы для каждой пары умножаете две

170
00:10:08,288 --> 00:10:12,993
вероятности появления каждого конкретного лица, а затем складываете все это вместе.

171
00:10:12,993 --> 00:10:16,751
Вычисление, которое делает это для всех возможных сумм, имеет причудливое

172
00:10:16,751 --> 00:10:20,559
название, оно называется сверткой, но по сути это просто взвешенная версия

173
00:10:20,559 --> 00:10:24,570
игры подсчета, которая уже знакома любому, кто играл с парой игральных костей.

174
00:10:24,570 --> 00:10:28,208
Для целей этого урока я попрошу компьютер все это рассчитать,

175
00:10:28,208 --> 00:10:31,728
просто отобразить вам результаты и предложить вам наблюдать

176
00:10:31,728 --> 00:10:35,484
определенные закономерности, но под капотом происходит вот что.

177
00:10:35,484 --> 00:10:39,655
Итак, чтобы внести ясность в то, что здесь представлено, если вы представите,

178
00:10:39,655 --> 00:10:43,934
что выбираете два разных значения из этого верхнего распределения, описывающего

179
00:10:43,934 --> 00:10:48,159
одну игральную кость, и суммируете их вместе, то второе распределение, которое

180
00:10:48,159 --> 00:10:52,437
я рисую, показывает, насколько вероятно, что вы увидеть различные разные суммы.

181
00:10:52,437 --> 00:10:56,031
Аналогично, если вы представите себе выборку трех различных значений

182
00:10:56,031 --> 00:10:59,729
из этого верхнего распределения и сложение их вместе, следующий график

183
00:10:59,729 --> 00:11:03,166
представляет вероятности для различных разных сумм в этом случае.

184
00:11:03,166 --> 00:11:06,259
Итак, если я вычислю, как будут выглядеть распределения этих сумм

185
00:11:06,259 --> 00:11:09,212
для все больших и больших сумм, ну, вы знаете, что я собираюсь

186
00:11:09,212 --> 00:11:12,680
сказать, это все больше и больше будет похоже на колоколообразную кривую.

187
00:11:12,680 --> 00:11:16,691
Но прежде чем мы перейдем к этому, я хочу, чтобы вы сделали еще пару простых наблюдений.

188
00:11:16,691 --> 00:11:20,719
Например, кажется, что эти распределения смещаются вправо, а

189
00:11:20,719 --> 00:11:24,880
также становятся более разбросанными и немного более плоскими.

190
00:11:24,880 --> 00:11:27,841
Вы не можете описать центральную предельную теорему количественно,

191
00:11:27,841 --> 00:11:30,625
не принимая во внимание оба этих эффекта, что, в свою очередь,

192
00:11:30,625 --> 00:11:33,366
требует описания среднего значения и стандартного отклонения.

193
00:11:33,366 --> 00:11:37,773
Возможно, вы уже знакомы с ними, но я хочу сделать здесь минимальные предположения,

194
00:11:37,773 --> 00:11:41,708
и обзор никогда не помешает, поэтому давайте быстро рассмотрим оба из них.

195
00:11:41,708 --> 00:11:46,247
Среднее значение распределения, часто обозначаемое греческой буквой мю,

196
00:11:46,247 --> 00:11:50,724
представляет собой способ определения центра масс этого распределения.

197
00:11:50,724 --> 00:11:54,399
Оно рассчитывается как ожидаемое значение нашей случайной

198
00:11:54,399 --> 00:11:58,709
величины, что означает, что вы перебираете все возможные результаты

199
00:11:58,709 --> 00:12:02,828
и умножаете вероятность этого результата на значение переменной.

200
00:12:02,828 --> 00:12:06,742
Если более высокие значения более вероятны, эта взвешенная сумма будет больше.

201
00:12:06,742 --> 00:12:10,440
Если более низкие значения более вероятны, эта взвешенная сумма будет меньше.

202
00:12:10,440 --> 00:12:13,968
Немного интереснее, если вы хотите измерить, насколько распространено

203
00:12:13,968 --> 00:12:17,698
это распределение, потому что есть несколько разных способов сделать это.

204
00:12:17,698 --> 00:12:20,149
Один из них называется дисперсией.

205
00:12:20,149 --> 00:12:24,059
Идея состоит в том, чтобы посмотреть разницу между каждым возможным значением и

206
00:12:24,059 --> 00:12:28,213
средним значением, возвести эту разницу в квадрат и запросить ее ожидаемое значение.

207
00:12:28,213 --> 00:12:30,969
Идея состоит в том, что независимо от того, находится ли ваше значение

208
00:12:30,969 --> 00:12:33,648
ниже или выше среднего, когда вы возводите эту разницу в квадрат, вы

209
00:12:33,648 --> 00:12:36,560
получаете положительное число, и чем больше разница, тем больше это число.

210
00:12:36,560 --> 00:12:39,311
Возведение в квадрат таким образом делает математические вычисления

211
00:12:39,311 --> 00:12:42,142
намного более точными, чем если бы мы делали что-то вроде абсолютного

212
00:12:42,142 --> 00:12:44,893
значения, но недостатком является то, что на нашей диаграмме трудно

213
00:12:44,893 --> 00:12:47,847
думать об этом как о расстоянии, потому что единицы измерения отключены.

214
00:12:47,847 --> 00:12:50,423
Вроде как единицы здесь — это квадратные единицы, тогда как

215
00:12:50,423 --> 00:12:53,299
расстояние на нашей диаграмме будет своего рода линейной единицей.

216
00:12:53,299 --> 00:12:56,203
Итак, еще один способ измерения разброса — это так называемое стандартное

217
00:12:56,203 --> 00:12:59,186
отклонение, которое представляет собой квадратный корень из этого значения.

218
00:12:59,186 --> 00:13:03,280
Гораздо более разумно это можно интерпретировать как расстояние на нашей диаграмме,

219
00:13:03,280 --> 00:13:06,936
и оно обычно обозначается греческой буквой сигма, поэтому вы знаете, что m

220
00:13:06,936 --> 00:13:10,786
означает среднее значение и стандартное отклонение, но оба на греческом языке.

221
00:13:10,786 --> 00:13:13,904
Оглядываясь назад на нашу последовательность распределений,

222
00:13:13,904 --> 00:13:16,710
давайте поговорим о среднем и стандартном отклонении.

223
00:13:16,710 --> 00:13:19,871
Если мы назовем среднее значение начального распределения mu, которое

224
00:13:19,871 --> 00:13:23,122
для иллюстрированного случая равно 2.24, надеюсь, вы не удивитесь, если

225
00:13:23,122 --> 00:13:26,328
я скажу вам, что среднее значение следующего числа в 2 раза больше му.

226
00:13:26,328 --> 00:13:30,092
То есть вы бросаете пару игральных костей и хотите узнать ожидаемое значение

227
00:13:30,092 --> 00:13:33,514
суммы, оно в два раза превышает ожидаемое значение для одного кубика.

228
00:13:33,514 --> 00:13:36,362
Аналогично, ожидаемое значение нашей суммы размера

229
00:13:36,362 --> 00:13:39,265
3 в 3 раза больше мю, и так далее, и тому подобное.

230
00:13:39,265 --> 00:13:42,192
Среднее значение неуклонно движется вправо, поэтому наши

231
00:13:42,192 --> 00:13:44,914
распределения, похоже, смещаются в этом направлении.

232
00:13:44,914 --> 00:13:49,663
Немного сложнее, но очень важно описать, как изменяется стандартное отклонение.

233
00:13:49,663 --> 00:13:52,755
Ключевым фактом здесь является то, что если у вас есть две

234
00:13:52,755 --> 00:13:56,004
разные случайные величины, то дисперсия суммы этих переменных

235
00:13:56,004 --> 00:13:59,357
такая же, как если бы вы просто сложили две исходные дисперсии.

236
00:13:59,357 --> 00:14:03,920
Это один из тех фактов, которые можно просто вычислить, распаковав все определения.

237
00:14:03,920 --> 00:14:06,414
Есть пара хороших предположений, почему это правда.

238
00:14:06,414 --> 00:14:09,848
Мой предварительный план состоит в том, чтобы просто сделать серию о вероятности и

239
00:14:09,848 --> 00:14:13,447
рассказать о таких вещах, как интуиция, лежащая в основе дисперсии, и ее родственники.

240
00:14:13,447 --> 00:14:16,687
Но сейчас главное, что я хочу, чтобы вы подчеркнули, это

241
00:14:16,687 --> 00:14:20,097
то, что добавляется дисперсия, а не стандартное отклонение.

242
00:14:20,097 --> 00:14:24,578
Итак, что особенно важно, если вы возьмете n различных реализаций одной и той же

243
00:14:24,578 --> 00:14:29,004
случайной величины и спросите, как выглядит сумма, дисперсия этой суммы в n раз

244
00:14:29,004 --> 00:14:33,984
превышает дисперсию вашей исходной переменной, то есть стандартное отклонение, квадратный

245
00:14:33,984 --> 00:14:38,354
корень из всех это квадратный корень из n, умноженного на исходное стандартное

246
00:14:38,354 --> 00:14:39,018
отклонение.

247
00:14:39,018 --> 00:14:42,734
Например, вернемся к нашей последовательности распределений, если мы обозначим

248
00:14:42,734 --> 00:14:46,308
стандартное отклонение нашего начального распределения сигмой, то следующее

249
00:14:46,308 --> 00:14:49,883
стандартное отклонение будет квадратным корнем из 2 сигм, и после этого оно

250
00:14:49,883 --> 00:14:53,786
будет выглядеть как квадратный корень из 3 раза сигма и так далее и тому подобное.

251
00:14:53,786 --> 00:14:55,690
Это, как я уже сказал, очень важно.

252
00:14:55,690 --> 00:14:59,995
Это означает, что хотя наши распределения и распределяются, они распространяются

253
00:14:59,995 --> 00:15:04,034
не так быстро, а только пропорционально квадратному корню из размера суммы.

254
00:15:04,034 --> 00:15:07,985
Пока мы готовимся к более количественному описанию центральной предельной теоремы,

255
00:15:07,985 --> 00:15:12,222
основная интуиция, которую я хочу, чтобы вы держали в голове, заключается в том, что мы,

256
00:15:12,222 --> 00:15:16,268
по сути, перестроим все эти распределения так, чтобы их средние значения выровнялись

257
00:15:16,268 --> 00:15:20,409
вместе, а затем изменим их масштаб таким образом. что все стандартные отклонения будут

258
00:15:20,409 --> 00:15:20,838
равны 1.

259
00:15:20,838 --> 00:15:23,949
И когда мы это делаем, получаемая в результате форма становится все ближе

260
00:15:23,949 --> 00:15:27,187
и ближе к определенной универсальной форме, описываемой с помощью элегантной

261
00:15:27,187 --> 00:15:30,004
маленькой функции, которую мы распакуем буквально через мгновение.

262
00:15:30,004 --> 00:15:33,715
И позвольте мне сказать еще раз: настоящее волшебство заключается в том, что

263
00:15:33,715 --> 00:15:37,619
мы могли бы начать с любого распределения, описывая один бросок игральной кости,

264
00:15:37,619 --> 00:15:41,378
и если мы будем играть в ту же игру, учитывая, как выглядят распределения для

265
00:15:41,378 --> 00:15:44,896
множества разных сумм: и мы перестраиваем их так, чтобы средние значения

266
00:15:44,896 --> 00:15:48,655
совпадали, и масштабируем их так, чтобы все стандартные отклонения были равны

267
00:15:48,655 --> 00:15:52,800
1, мы все равно приближаемся к той же универсальной форме, которая просто ошеломляет.

268
00:15:52,800 --> 00:15:56,698
И сейчас, друзья мои, возможно, самое подходящее время

269
00:15:56,698 --> 00:16:00,809
наконец разобраться с формулой нормального распределения.

270
00:16:00,809 --> 00:16:03,504
И то, как я хотел бы это сделать, состоит в том, чтобы по

271
00:16:03,504 --> 00:16:06,339
сути снять все слои и построить их по одному кусочку за раз.

272
00:16:06,339 --> 00:16:10,223
Функция e для x или что-то еще для x описывает экспоненциальный рост, и если

273
00:16:10,223 --> 00:16:14,056
вы сделаете этот показатель отрицательным, который переворачивает график по

274
00:16:14,056 --> 00:16:18,141
горизонтали, вы можете думать о нем как об описании экспоненциального затухания.

275
00:16:18,141 --> 00:16:20,484
Чтобы сделать это затухание в обоих направлениях, вы можете

276
00:16:20,484 --> 00:16:22,670
сделать что-нибудь, чтобы показатель степени всегда был

277
00:16:22,670 --> 00:16:25,520
отрицательным и рос, например, приняв отрицательное абсолютное значение.

278
00:16:25,520 --> 00:16:29,125
Это дало бы нам неуклюжую острую точку посередине, но если вместо этого вы

279
00:16:29,125 --> 00:16:32,490
сделаете этот показатель отрицательным квадратом x, вы получите более

280
00:16:32,490 --> 00:16:36,240
гладкую версию того же самого объекта, который затухает в обоих направлениях.

281
00:16:36,240 --> 00:16:38,293
Это дает нам базовую форму колоколообразной кривой.

282
00:16:38,293 --> 00:16:41,628
Теперь, если вы поместите константу перед этим x и масштабируете эту константу

283
00:16:41,628 --> 00:16:44,837
вверх и вниз, это позволит вам растягивать и сжимать график по горизонтали,

284
00:16:44,837 --> 00:16:48,172
позволяя вам описывать узкие и более широкие кривые нормального распределения.

285
00:16:48,172 --> 00:16:52,143
И я хотел бы сразу отметить, что, основываясь на правилах возведения

286
00:16:52,143 --> 00:16:56,056
в степень, когда мы настраиваем константу c, вы также можете думать

287
00:16:56,056 --> 00:16:59,739
об этом как о простом изменении основания возведения в степень.

288
00:16:59,739 --> 00:17:04,080
И в этом смысле число e не является чем-то особенным для нашей формулы.

289
00:17:04,080 --> 00:17:07,496
Мы могли бы заменить ее любой другой положительной константой, и вы

290
00:17:07,496 --> 00:17:11,113
получите то же самое семейство кривых, когда мы настроим эту константу.

291
00:17:11,113 --> 00:17:13,268
Пусть это будет 2, одно и то же семейство кривых.

292
00:17:13,268 --> 00:17:15,325
Пусть это будет цифра 3, одно и то же семейство кривых.

293
00:17:15,325 --> 00:17:17,473
Причина, по которой мы используем e, заключается в

294
00:17:17,473 --> 00:17:19,705
том, что это придает константе очень понятный смысл.

295
00:17:19,705 --> 00:17:24,032
Или, скорее, если мы немного изменим ситуацию так, чтобы показатель степени выглядел

296
00:17:24,032 --> 00:17:28,614
как отрицательный, равный половине умноженного на х, деленного на определенную константу,

297
00:17:28,614 --> 00:17:32,839
которую мы назовем квадратом сигмы, то как только мы превратим это в распределение

298
00:17:32,839 --> 00:17:36,708
вероятностей, эта постоянная сигма будет быть стандартным отклонением этого

299
00:17:36,708 --> 00:17:37,472
распределения.

300
00:17:37,472 --> 00:17:38,663
И это очень приятно.

301
00:17:38,663 --> 00:17:41,358
Но прежде чем мы сможем интерпретировать это как распределение

302
00:17:41,358 --> 00:17:44,097
вероятностей, нам нужно, чтобы площадь под кривой была равна 1.

303
00:17:44,097 --> 00:17:47,247
Причина этого в том, как интерпретируется кривая.

304
00:17:47,247 --> 00:17:50,488
В отличие от дискретных распределений, когда речь идет о чем-то

305
00:17:50,488 --> 00:17:53,680
непрерывном, вы не спрашиваете о вероятности конкретной точки.

306
00:17:53,680 --> 00:17:56,031
Вместо этого вы запрашиваете вероятность того, что

307
00:17:56,031 --> 00:17:58,336
значение попадает между двумя разными значениями.

308
00:17:58,336 --> 00:18:01,776
И кривая говорит вам, что эта вероятность равна

309
00:18:01,776 --> 00:18:05,288
площади под кривой между этими двумя значениями.

310
00:18:05,288 --> 00:18:09,680
Об этом есть совершенно другое видео, они называются функциями плотности вероятности.

311
00:18:09,680 --> 00:18:13,217
Главное сейчас то, что площадь под всей кривой представляет

312
00:18:13,217 --> 00:18:17,284
вероятность того, что что-то произойдет, что выпадет какое-то число.

313
00:18:17,284 --> 00:18:20,633
Это должно быть 1, поэтому мы хотим, чтобы площадь под ним была равна 1.

314
00:18:20,633 --> 00:18:24,158
В соответствии с базовой формой колоколообразной кривой от e до отрицательного

315
00:18:24,158 --> 00:18:27,772
квадрата x, площадь не равна 1, на самом деле это квадратный корень из числа Пи.

316
00:18:27,772 --> 00:18:28,633
Я точно знаю?

317
00:18:28,633 --> 00:18:29,953
Что здесь делает Пи?

318
00:18:29,953 --> 00:18:31,668
Какое это имеет отношение к кругам?

319
00:18:31,668 --> 00:18:34,848
Как я уже сказал в начале, мне бы хотелось поговорить обо всем этом в следующем видео.

320
00:18:34,848 --> 00:18:37,597
Но если вы можете прямо сейчас потратить свое волнение на наши

321
00:18:37,597 --> 00:18:40,346
цели, все это означает, что нам нужно разделить эту функцию на

322
00:18:40,346 --> 00:18:43,226
квадратный корень из числа пи, и это даст нам нужную нам площадь.

323
00:18:43,226 --> 00:18:47,661
Возвращаясь к константам, которые мы использовали ранее, 1 половине и сигме, мы

324
00:18:47,661 --> 00:18:52,317
получаем эффект растягивания графика в сигму, умноженную на квадратный корень из 2.

325
00:18:52,317 --> 00:18:54,615
Поэтому нам также нужно разделить на это значение,

326
00:18:54,615 --> 00:18:56,507
чтобы убедиться, что его площадь равна 1.

327
00:18:56,507 --> 00:18:59,294
И, объединив эти дроби, множитель выглядит как 1,

328
00:18:59,294 --> 00:19:02,804
разделенная на сигму, умноженную на квадратный корень из 2 пи.

329
00:19:02,804 --> 00:19:06,093
Наконец, это действительное распределение вероятностей.

330
00:19:06,093 --> 00:19:10,290
Когда мы настраиваем это значение сигмы, что приводит к более узким и

331
00:19:10,290 --> 00:19:15,027
широким кривым, эта константа спереди всегда гарантирует, что площадь равна 1.

332
00:19:15,027 --> 00:19:19,874
Особый случай, когда сигма равна 1, имеет особое название, мы называем его стандартным

333
00:19:19,874 --> 00:19:24,665
нормальным распределением, которое играет для нас с вами в этом уроке особенно важную

334
00:19:24,665 --> 00:19:25,000
роль.

335
00:19:25,000 --> 00:19:28,914
И все возможные нормальные распределения не только параметризуются этим

336
00:19:28,914 --> 00:19:32,938
значением сигма, но мы также вычитаем еще одну константу мю из переменной

337
00:19:32,938 --> 00:19:36,852
x, и это, по сути, просто позволяет вам сдвигать график влево и вправо,

338
00:19:36,852 --> 00:19:40,277
чтобы вы могли прописать среднее значение этого распределения.

339
00:19:40,277 --> 00:19:44,675
Короче говоря, у нас есть два параметра: один описывает среднее значение, другой —

340
00:19:44,675 --> 00:19:49,180
стандартное отклонение, и все они связаны в одну большую формулу, включающую е и пи.

341
00:19:49,180 --> 00:19:54,257
Теперь, когда все это на столе, давайте еще раз вернемся к идее начать с некоторой

342
00:19:54,257 --> 00:19:59,701
случайной величины и задаться вопросом, как выглядят распределения сумм этой переменной.

343
00:19:59,701 --> 00:20:03,121
Как мы уже говорили, когда вы увеличиваете размер этой суммы, результирующее

344
00:20:03,121 --> 00:20:06,497
распределение будет смещаться в соответствии с растущим средним значением и

345
00:20:06,497 --> 00:20:09,918
медленно распространяться в соответствии с растущим стандартным отклонением.

346
00:20:09,918 --> 00:20:13,411
И, применив к этому некоторые реальные формулы, если мы знаем среднее

347
00:20:13,411 --> 00:20:17,054
значение нашей базовой случайной величины, мы называем ее мю, и мы также

348
00:20:17,054 --> 00:20:20,448
знаем ее стандартное отклонение и называем ее сигмой, тогда среднее

349
00:20:20,448 --> 00:20:23,991
значение суммы внизу будет мю. умножить на размер суммы, а стандартное

350
00:20:23,991 --> 00:20:27,983
отклонение будет равно сигме, умноженной на квадратный корень из этого размера.

351
00:20:27,983 --> 00:20:30,988
Итак, теперь, если мы хотим заявить, что это все больше и больше похоже на

352
00:20:30,988 --> 00:20:34,033
колоколообразную кривую, а колоколообразная кривая описывается только двумя

353
00:20:34,033 --> 00:20:37,600
разными параметрами: средним значением и стандартным отклонением, вы знаете, что делать.

354
00:20:37,600 --> 00:20:40,702
Вы можете подставить эти два значения в формулу, и это даст

355
00:20:40,702 --> 00:20:43,908
вам весьма явную, хотя и довольно сложную формулу для кривой,

356
00:20:43,908 --> 00:20:46,960
которая должна точно соответствовать нашему распределению.

357
00:20:46,960 --> 00:20:51,142
Но есть и другой способ описать это, более элегантный и создающий

358
00:20:51,142 --> 00:20:54,944
очень забавный визуальный эффект, который мы можем создать.

359
00:20:54,944 --> 00:20:58,722
Вместо того, чтобы сосредотачиваться на сумме всех этих случайных величин,

360
00:20:58,722 --> 00:21:02,853
давайте немного изменим это выражение: мы посмотрим на среднее значение, которое,

361
00:21:02,853 --> 00:21:06,832
как мы ожидаем, примет эта сумма, и вычтем его так, чтобы наше новое выражение

362
00:21:06,832 --> 00:21:10,560
имеет среднее значение 0, а затем мы посмотрим на стандартное отклонение,

363
00:21:10,560 --> 00:21:14,641
которое мы ожидаем от нашей суммы, и разделим на него, что по сути просто меняет

364
00:21:14,641 --> 00:21:18,721
масштаб единиц, так что стандартное отклонение нашего выражения будет равно 1. .

365
00:21:18,721 --> 00:21:21,502
Это выражение может показаться более сложным,

366
00:21:21,502 --> 00:21:24,465
но на самом деле оно имеет очень читаемый смысл.

367
00:21:24,465 --> 00:21:26,948
По сути, это вопрос о том, на сколько стандартных

368
00:21:26,948 --> 00:21:29,580
отклонений от среднего значения находится эта сумма?

369
00:21:29,580 --> 00:21:33,250
Например, эта полоса здесь соответствует определенному значению, которое

370
00:21:33,250 --> 00:21:36,670
вы можете найти, когда бросаете 10 игральных костей и суммируете их

371
00:21:36,670 --> 00:21:40,189
все, и ее положение немного выше отрицательной 1 говорит вам, что это

372
00:21:40,189 --> 00:21:43,760
значение немного меньше одного стандартного отклонения. ниже среднего.

373
00:21:43,760 --> 00:21:48,006
Кроме того, кстати, в предвкушении анимации, которую я пытаюсь здесь

374
00:21:48,006 --> 00:21:52,375
построить, я представляю вещи на нижнем графике так: площадь каждой из

375
00:21:52,375 --> 00:21:57,113
этих полос говорит нам о вероятности соответствующего значения. а не высота.

376
00:21:57,113 --> 00:21:59,512
Вы можете подумать, что ось Y представляет собой не

377
00:21:59,512 --> 00:22:01,818
вероятность, а своего рода плотность вероятности.

378
00:22:01,818 --> 00:22:05,758
Причина этого в том, чтобы подготовить почву так, чтобы она соответствовала

379
00:22:05,758 --> 00:22:09,438
тому, как мы интерпретируем непрерывные распределения, где вероятность

380
00:22:09,438 --> 00:22:13,534
попадания в диапазон значений равна площади под кривой между этими значениями.

381
00:22:13,534 --> 00:22:17,616
В частности, площадь всех столбцов вместе будет равна 1.

382
00:22:17,616 --> 00:22:20,958
Теперь, когда все это готово, давайте немного повеселимся.

383
00:22:20,958 --> 00:22:24,692
Позвольте мне начать с отката назад, чтобы распределение внизу представляло собой

384
00:22:24,692 --> 00:22:28,654
относительно небольшую сумму, как если бы вы сложили вместе только три таких случайных

385
00:22:28,654 --> 00:22:29,109
величины.

386
00:22:29,109 --> 00:22:32,460
Обратите внимание, что происходит, когда я меняю дистрибутив, с которого мы начали.

387
00:22:32,460 --> 00:22:36,732
При его изменении распределение внизу полностью меняет свою форму.

388
00:22:36,732 --> 00:22:39,792
Это очень зависит от того, с чего мы начали.

389
00:22:39,792 --> 00:22:43,877
Если мы позволим размеру нашей суммы стать немного больше, скажем, до 10, и когда я

390
00:22:43,877 --> 00:22:47,817
изменю распределение для x, она в основном останется похожей на колоколообразную

391
00:22:47,817 --> 00:22:52,049
кривую, но я могу найти некоторые распределения, которые заставят ее изменить форму. .

392
00:22:52,049 --> 00:22:56,040
Например, действительно однобокий вариант, где почти вся вероятность заключена

393
00:22:56,040 --> 00:22:59,778
в числах 1 или 6, приводит к такой остроконечной колоколообразной кривой,

394
00:22:59,778 --> 00:23:03,516
и, если вы помните, ранее я фактически показал это в форме моделирования.

395
00:23:03,516 --> 00:23:07,785
Итак, если вам интересно, была ли эта остроконечность артефактом случайности или

396
00:23:07,785 --> 00:23:12,160
отражала истинное распределение, оказывается, она отражает истинное распределение.

397
00:23:12,160 --> 00:23:14,154
В этом случае 10 — недостаточно большая сумма для

398
00:23:14,154 --> 00:23:16,308
того, чтобы сработала центральная предельная теорема.

399
00:23:16,308 --> 00:23:20,021
Но если вместо этого я позволю этой сумме расти и рассмотрю возможность

400
00:23:20,021 --> 00:23:23,683
добавления 50 различных значений, что на самом деле не так уж и много,

401
00:23:23,683 --> 00:23:27,500
то независимо от того, как я изменю распределение нашей базовой случайной

402
00:23:27,500 --> 00:23:30,904
величины, это по существу не повлияет на форму графика на нижний.

403
00:23:30,904 --> 00:23:34,905
Независимо от того, с чего мы начинаем, вся информация и нюансы распределения x

404
00:23:34,905 --> 00:23:38,906
смываются, и мы склоняемся к этой единственной универсальной форме, описываемой

405
00:23:38,906 --> 00:23:42,858
очень элегантной функцией для стандартного нормального распределения: 1 вместо

406
00:23:42,858 --> 00:23:47,009
квадратного корня из 2 пи, умноженных на e. к отрицательному х в квадрате более 2.

407
00:23:47,009 --> 00:23:50,976
Вот в этом-то и состоит суть центральной предельной теоремы.

408
00:23:50,976 --> 00:23:53,453
Почти ничего, что вы можете сделать с этим начальным

409
00:23:53,453 --> 00:23:56,118
распределением, не меняет форму, к которой мы стремимся.

410
00:23:56,118 --> 00:24:00,196
Те из вас, кто более склонен к теории, возможно, все

411
00:24:00,196 --> 00:24:04,274
еще задаются вопросом, какова на самом деле теорема?

412
00:24:04,274 --> 00:24:06,527
Например, какое математическое утверждение мы здесь

413
00:24:06,527 --> 00:24:08,823
утверждаем, которое можно доказать или опровергнуть?

414
00:24:08,823 --> 00:24:11,440
Если вам нужно красивое официальное заявление, вот как это может быть.

415
00:24:11,440 --> 00:24:15,343
Рассмотрим это значение, где мы суммируем n различных экземпляров нашей случайной

416
00:24:15,343 --> 00:24:19,531
величины, но изменены и настроены так, что ее среднее значение и стандартное отклонение

417
00:24:19,531 --> 00:24:19,960
равны 1.

418
00:24:19,960 --> 00:24:22,823
Опять же, это означает, что вы можете прочитать это как вопрос,

419
00:24:22,823 --> 00:24:25,686
на сколько стандартных отклонений от среднего составляет сумма.

420
00:24:25,686 --> 00:24:29,777
Тогда фактическая строгая формулировка центральной предельной теоремы (на этот

421
00:24:29,777 --> 00:24:33,608
раз без шуток): если вы рассматриваете вероятность того, что это значение

422
00:24:33,608 --> 00:24:37,905
попадает между двумя заданными действительными числами, a и b, и вы рассматриваете

423
00:24:37,905 --> 00:24:41,996
предел этой вероятности как размер ваша сумма стремится к бесконечности, тогда

424
00:24:41,996 --> 00:24:46,138
этот предел равен определенному интегралу, который в основном описывает площадь

425
00:24:46,138 --> 00:24:49,814
при стандартном нормальном распределении между этими двумя значениями.

426
00:24:49,814 --> 00:24:54,814
Опять же, есть три основных предположения, о которых мне еще предстоит вам рассказать, но

427
00:24:54,814 --> 00:24:59,760
кроме них, во всех кровавых подробностях, вот это и есть центральная предельная теорема.

428
00:24:59,760 --> 00:25:04,313
Все это немного теоретически, поэтому было бы полезно вернуться на Землю

429
00:25:04,313 --> 00:25:08,741
и вернуться к конкретному примеру, который я упомянул в начале, где вы

430
00:25:08,741 --> 00:25:13,482
представляете, что бросаете игральную кость 100 раз, и давайте предположим,

431
00:25:13,482 --> 00:25:18,409
что это справедливый результат. для этого примера, и вы суммируете результаты.

432
00:25:18,409 --> 00:25:22,346
Ваша задача — найти такой диапазон значений, в котором вы на

433
00:25:22,346 --> 00:25:26,153
95 % уверены, что сумма будет находиться в этом диапазоне.

434
00:25:26,153 --> 00:25:30,334
Для подобных вопросов существует удобное эмпирическое правило нормального распределения,

435
00:25:30,334 --> 00:25:34,092
которое гласит, что около 68% ваших значений будут находиться в пределах одного

436
00:25:34,092 --> 00:25:38,273
стандартного отклонения от среднего значения, а 95% ваших значений, то, что нас волнует,

437
00:25:38,273 --> 00:25:42,313
попадают в этот диапазон. два стандартных отклонения среднего значения и колоссальные

438
00:25:42,313 --> 00:25:46,494
99.7% ваших значений будут находиться в пределах трех стандартных отклонений от среднего

439
00:25:46,494 --> 00:25:46,964
значения.

440
00:25:46,964 --> 00:25:49,470
Это практическое правило, которое обычно запоминают люди,

441
00:25:49,470 --> 00:25:51,803
которые много занимаются вероятностями и статистикой.

442
00:25:51,803 --> 00:25:55,709
Естественно, это дает нам то, что нам нужно для нашего примера, и позвольте

443
00:25:55,709 --> 00:25:59,409
мне нарисовать, как это будет выглядеть, где я покажу распределение для

444
00:25:59,409 --> 00:26:03,264
справедливого кубика вверху и распределение для суммы 100. такие игральные

445
00:26:03,264 --> 00:26:07,838
кости внизу, которые, как вы знаете, теперь выглядят как некое нормальное распределение.

446
00:26:07,838 --> 00:26:11,634
Первый шаг в решении подобной проблемы — найти среднее значение вашего начального

447
00:26:11,634 --> 00:26:15,152
распределения, которое в данном случае будет выглядеть как 16-е, умноженное

448
00:26:15,152 --> 00:26:18,577
на 1, плюс 16-е, умноженное на 2, и так далее, и в итоге будет равно 3.5.

449
00:26:18,577 --> 00:26:21,693
Нам также нужно стандартное отклонение, для которого требуется

450
00:26:21,693 --> 00:26:25,155
вычислить дисперсию, которая, как вы знаете, включает в себя сложение

451
00:26:25,155 --> 00:26:28,469
всех квадратов разностей между значениями и средними значениями, и

452
00:26:28,469 --> 00:26:32,030
в результате получается 2.92, квадратный корень из которого равен 1.71.

453
00:26:32,030 --> 00:26:35,422
Это единственные два числа, которые нам нужны, и я снова приглашаю

454
00:26:35,422 --> 00:26:38,966
вас задуматься о том, насколько волшебно то, что это единственные два

455
00:26:38,966 --> 00:26:42,511
числа, которые вам нужны для полного понимания нижнего распределения.

456
00:26:42,511 --> 00:26:47,515
Его среднее значение будет в 100 раз мю, что равно 350, а его стандартное отклонение

457
00:26:47,515 --> 00:26:52,401
будет равно квадратному корню из 100-кратного сигмы, то есть 10-кратного сигмы 17.

458
00:26:52,401 --> 00:26:56,752
1. Помня наше удобное эмпирическое правило, мы ищем значения, отстоящие на два

459
00:26:56,752 --> 00:27:01,489
стандартных отклонения от среднего значения, и когда вы вычитаете 2 сигмы из среднего

460
00:27:01,489 --> 00:27:06,226
значения, вы получаете примерно 316, а когда вы добавляете 2 сигмы, вы получаете 384.

461
00:27:06,226 --> 00:27:08,880
И вот, это дает нам ответ.

462
00:27:08,880 --> 00:27:13,815
Хорошо, я обещал подвести итоги в ближайшее время, но пока мы рассматриваем

463
00:27:13,815 --> 00:27:18,297
этот пример, есть еще один вопрос, на который стоит потратить время.

464
00:27:18,297 --> 00:27:21,508
Вместо того, чтобы просто спрашивать о сумме 100 бросков кубика,

465
00:27:21,508 --> 00:27:24,868
предположим, я попросил вас разделить это число на 100, что по сути

466
00:27:24,868 --> 00:27:28,080
означает, что все числа на нашей диаграмме внизу делятся на 100.

467
00:27:28,080 --> 00:27:31,467
Найдите минутку, чтобы интерпретировать, о чем все это говорит тогда.

468
00:27:31,467 --> 00:27:35,453
По сути, это выражение сообщает вам эмпирическое среднее значение для 100

469
00:27:35,453 --> 00:27:39,332
различных бросков кубика, и найденный нами интервал теперь говорит вам,

470
00:27:39,332 --> 00:27:43,534
какой диапазон вы ожидаете увидеть для этого эмпирического среднего значения.

471
00:27:43,534 --> 00:27:47,999
Другими словами, вы можете ожидать, что оно будет около 3.5, это ожидаемое значение для

472
00:27:47,999 --> 00:27:52,209
броска кубика, но что гораздо менее очевидно и что позволяет вычислить центральная

473
00:27:52,209 --> 00:27:56,268
предельная теорема, так это то, насколько близко к этому ожидаемому значению вы

474
00:27:56,268 --> 00:27:56,826
окажетесь.

475
00:27:56,826 --> 00:28:00,231
В частности, стоит уделить время размышлениям о том, каково стандартное

476
00:28:00,231 --> 00:28:03,871
отклонение для этого эмпирического среднего значения и что с ним происходит,

477
00:28:03,871 --> 00:28:07,040
когда вы смотрите на все большую и большую выборку бросков кубика.

478
00:28:07,040 --> 00:28:11,920
И наконец, но, вероятно, самое главное: давайте

479
00:28:11,920 --> 00:28:17,920
поговорим о предположениях, лежащих в основе этой теоремы.

480
00:28:17,920 --> 00:28:22,720
Во-первых, все эти переменные, которые мы суммируем, независимы друг от друга.

481
00:28:22,720 --> 00:28:26,320
Результат одного процесса не влияет на результат любого другого процесса.

482
00:28:26,320 --> 00:28:31,440
Во-вторых, все эти переменные взяты из одного и того же распределения.

483
00:28:31,440 --> 00:28:34,457
Оба этих условия неявно предполагались в нашем примере с игральными костями.

484
00:28:34,457 --> 00:28:38,250
Мы рассматривали результат каждого броска кубика как независимый от результата

485
00:28:38,250 --> 00:28:42,091
всех остальных и предполагаем, что каждый кубик имеет одинаковое распределение.

486
00:28:42,091 --> 00:28:46,176
Иногда в литературе вы встретите эти два предположения, объединенные

487
00:28:46,176 --> 00:28:50,320
инициалами IID, обозначающими независимые и одинаково распределенные.

488
00:28:50,320 --> 00:28:52,962
Одной из ситуаций, когда эти предположения явно

489
00:28:52,962 --> 00:28:55,440
неверны, является совет директоров Гальтона.

490
00:28:55,440 --> 00:28:56,741
Я имею в виду, подумай об этом.

491
00:28:56,741 --> 00:29:00,188
Действительно ли то, как мяч отскочит от одного из колышков,

492
00:29:00,188 --> 00:29:03,522
не зависит от того, как он отскочит от следующего колышка?

493
00:29:03,522 --> 00:29:04,335
Точно нет.

494
00:29:04,335 --> 00:29:08,156
В зависимости от последнего отскока он движется по совершенно разной траектории.

495
00:29:08,156 --> 00:29:11,710
И действительно ли распределение возможных результатов для каждой

496
00:29:11,710 --> 00:29:15,156
привязки одинаково для каждой привязки, к которой она попадает?

497
00:29:15,156 --> 00:29:16,631
Опять же, почти наверняка нет.

498
00:29:16,631 --> 00:29:20,031
Может быть, он попадает в одну точку, глядя влево, а это означает, что результаты

499
00:29:20,031 --> 00:29:23,680
сильно искажаются в этом направлении, а затем попадает в следующую точку, глядя вправо.

500
00:29:23,680 --> 00:29:27,723
Когда я сделал все эти упрощающие предположения в первом примере,

501
00:29:27,723 --> 00:29:31,705
я делал это не только для того, чтобы об этом было легче думать.

502
00:29:31,705 --> 00:29:34,580
Кроме того, эти предположения были необходимы для того, чтобы

503
00:29:34,580 --> 00:29:37,547
это действительно было примером центральной предельной теоремы.

504
00:29:37,547 --> 00:29:41,351
Тем не менее, похоже, что для реальной доски Гальтона, несмотря на

505
00:29:41,351 --> 00:29:45,382
нарушение обоих условий, нормальное распределение все-таки получается?

506
00:29:45,382 --> 00:29:49,479
Частично причина может заключаться в том, что существуют обобщения теоремы,

507
00:29:49,479 --> 00:29:54,115
выходящие за рамки этого видео, которые ослабляют эти предположения, особенно второе.

508
00:29:54,115 --> 00:29:58,621
Но я хочу предостеречь вас от того факта, что часто люди предполагают, что

509
00:29:58,621 --> 00:30:03,668
переменная распределяется нормально, даже если для этого нет реального обоснования.

510
00:30:03,668 --> 00:30:06,557
Третье предположение на самом деле довольно тонкое.

511
00:30:06,557 --> 00:30:10,800
Дело в том, что дисперсия, которую мы вычисляли для этих переменных, конечна.

512
00:30:10,800 --> 00:30:12,821
В примере с игральными костями это никогда не было

513
00:30:12,821 --> 00:30:15,120
проблемой, поскольку возможных исходов было только шесть.

514
00:30:15,120 --> 00:30:18,921
Но в некоторых ситуациях, когда у вас есть бесконечный набор результатов, когда вы

515
00:30:18,921 --> 00:30:22,723
начинаете вычислять дисперсию, сумма в конечном итоге расходится до бесконечности.

516
00:30:22,723 --> 00:30:25,021
Это могут быть совершенно правильные распределения

517
00:30:25,021 --> 00:30:27,680
вероятностей, и они действительно встречаются на практике.

518
00:30:27,680 --> 00:30:31,165
Но в таких ситуациях, когда вы рассматриваете возможность добавления множества

519
00:30:31,165 --> 00:30:34,563
различных экземпляров этой переменной и позволяете этой сумме приближаться к

520
00:30:34,563 --> 00:30:38,004
бесконечности, даже если первые два предположения верны, весьма вероятно, что

521
00:30:38,004 --> 00:30:41,358
то, к чему вы склонны, на самом деле не является нормальным распределением.

522
00:30:41,358 --> 00:30:44,648
Если вы все поняли до этого момента, то теперь у вас есть очень

523
00:30:44,648 --> 00:30:47,939
прочная основа в том, что такое центральная предельная теорема.

524
00:30:47,939 --> 00:30:52,206
И далее я хотел бы объяснить, почему именно эта функция является тем, к чему

525
00:30:52,206 --> 00:30:56,640
мы склонны, и почему в ней есть число «пи», какое отношение она имеет к кругам.

