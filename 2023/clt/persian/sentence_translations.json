[
 {
  "input": "This is a Galton board. ",
  "translatedText": "این یک تخته گالتون است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "شاید قبلاً یکی را دیده باشید، این یک نمایش عمومی است که نشان می‌دهد چگونه، حتی زمانی که یک رویداد منفرد بی‌نظم و تصادفی است، با نتیجه‌ای کاملاً غیرقابل دانستن، هنوز هم می‌توان اظهارات دقیقی درباره تعداد زیادی از رویدادها بیان کرد، یعنی اینکه چگونه نسبت‌های نسبی برای بسیاری از نتایج مختلف توزیع شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "به طور خاص، تخته گالتون یکی از برجسته‌ترین توزیع‌ها را به احتمال زیاد نشان می‌دهد که به توزیع نرمال معروف است، که بیشتر به عنوان منحنی زنگی شناخته می‌شود و توزیع گاوسی نیز نامیده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "یک تابع بسیار خاص برای توصیف این توزیع وجود دارد، بسیار زیبا است، بعداً به آن خواهیم پرداخت، اما در حال حاضر فقط می‌خواهم تاکید کنم که توزیع نرمال چگونه است، همانطور که از نام آن پیداست، بسیار رایج است، این توزیع در موارد زیادی نشان داده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "از زمینه های به ظاهر نامرتبط اگر بخواهید تعداد زیادی از افرادی را انتخاب کنید که در یک جمعیت شناسی مشابه می نشینند و ارتفاع آنها را ترسیم می کنند، این ارتفاع ها معمولاً از توزیع نرمال پیروی می کنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "اگر به بخش بزرگی از اعداد طبیعی بسیار بزرگ نگاه کنید و بپرسید که هر یک از آن اعداد چند عامل اول متمایز دارند، پاسخ‌ها با توزیع نرمال مشخصی بسیار دقیق دنبال می‌شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "اکنون موضوع امروز ما یکی از جواهرات تاج در تمام نظریه احتمالات است، این یکی از حقایق کلیدی است که توضیح می دهد چرا این توزیع به همان اندازه رایج است که به عنوان قضیه حد مرکزی شناخته می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "این درس به منظور بازگشت به اصول اولیه است، به شما اصولی را در مورد آنچه که قضیه حد مرکزی می گوید، توزیع های نرمال چیست، و من می خواهم حداقل پیشینه را فرض کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "ما می‌خواهیم عمیق‌تر به آن برویم، اما پس از این، من همچنان می‌خواهم عمیق‌تر بروم و توضیح دهم که چرا قضیه درست است، چرا تابع زیربنایی توزیع نرمال شکل بسیار خاصی دارد که دارد، چرا آن فرمول دارد. یک پی در آن، و جالب‌تر از همه، این که چرا آن دو واقعیت آخر در واقع بیش از آن چیزی که بسیاری از توضیحات سنتی نشان می‌دهند مرتبط هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "آن درس دوم همچنین قرار است دنباله‌روی ویدیوی کانولوشن باشد که قول داده بودم، بنابراین موضوعات مرتبط زیادی در اینجا وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "اما در حال حاضر، به اصول اولیه بازگردیم، می‌خواهم کارها را با یک مدل بسیار ساده‌شده از تخته گالتون شروع کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "در این مدل فرض می‌کنیم که هر توپ مستقیماً روی یک میخ مرکزی خاص می‌افتد و احتمال 50-50 پرش به چپ یا راست دارد، و هر یک از این نتایج را به‌عنوان یک یا اضافه کردن یک یا اضافه می‌کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "کم کردن یکی از موقعیتش هنگامی که یکی از آن‌ها انتخاب می‌شود، این فرض بسیار غیرواقع‌بینانه را می‌کنیم که اتفاقاً در وسط میخ مجاور زیر آن فرود می‌آید، جایی که دوباره با همان انتخاب 50-50 یعنی پرش به چپ یا جهش روبرو می‌شود. به سمت راست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "برای صفحه‌ای که من روی صفحه نشان می‌دهم، پنج ردیف مختلف از گیره‌ها وجود دارد، بنابراین توپ جهنده کوچک ما پنج انتخاب تصادفی مختلف بین بعلاوه یک و منهای یک انجام می‌دهد و می‌توانیم موقعیت نهایی آن را اساساً مجموع همه آنها در نظر بگیریم. از آن اعداد مختلف، که در این مورد یکی است، و ممکن است همه سطل‌های مختلف را با مجموع نشان‌دهنده برچسب‌گذاری کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "همانطور که ما این کار را تکرار می کنیم، به جمع های مختلف ممکن برای آن پنج عدد تصادفی نگاه می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "و برای کسانی از شما که تمایل دارند شکایت کنند که این یک مدل بسیار غیر واقعی برای تخته گالتون واقعی است، اجازه دهید تاکید کنم که هدف در حال حاضر مدل سازی دقیق فیزیک نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "هدف ارائه یک مثال ساده برای نشان دادن قضیه حد مرکزی است، و برای آن، هر چند ممکن است ایده آل باشد، در واقع یک مثال واقعا خوب به ما می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "اگر اجازه دهیم توپ‌های مختلف بیفتند، و فرض غیرواقعی دیگری ایجاد کنیم که گویا همه آنها بر روی یکدیگر تأثیر نمی‌گذارند، آن‌گاه تعداد توپ‌هایی که در هر سطل مختلف می‌افتند، به ما می‌دهد که احتمال هر کدام چقدر است. از آن سطل ها است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "در این مثال، اعداد به اندازه کافی ساده هستند که محاسبه صریح احتمال افتادن در هر سطل چندان سخت نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "اگر بخواهید به آن فکر کنید، آن را بسیار یادآور مثلث پاسکال خواهید یافت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "اما نکته دقیق در مورد قضیه ما این است که چقدر فراتر از مثال های ساده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "بنابراین حداقل برای شروع، به جای محاسبات صریح، بیایید با اجرای تعداد زیادی نمونه، چیزها را شبیه سازی کنیم و اجازه دهیم که تعداد کل نتایج در هر نتیجه متفاوت به ما بفهماند که آن توزیع چگونه به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "همانطور که گفتم، یک روی صفحه دارای پنج ردیف است، بنابراین هر جمعی که ما در نظر می گیریم فقط شامل پنج عدد است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "ایده اصلی قضیه حد مرکزی این است که اگر اندازه آن مجموع را افزایش دهید، برای مثال در اینجا این به معنای افزایش تعداد ردیف‌های میخ‌ها برای هر توپ است که باید به سمت بیرون پرتاب شود، سپس توزیعی که توضیح می‌دهد که این مجموع به کجا می‌رود. پاییز بیشتر و بیشتر شبیه یک منحنی زنگ است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "در اینجا، در واقع ارزش آن را دارد که یک لحظه وقت بگذارید و این ایده کلی را بنویسید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "تنظیمات به این صورت است که ما یک متغیر تصادفی داریم، و این اساسا مختصر یک فرآیند تصادفی است که در آن هر نتیجه آن فرآیند با تعدادی عدد همراه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "ما آن عدد تصادفی را x می نامیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "برای مثال، هر پرش از میخ یک فرآیند تصادفی است که با دو نتیجه مدل شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "این نتایج با اعداد منفی یک و مثبت همراه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "مثال دیگری از یک متغیر تصادفی، چرخاندن قالب است، که در آن شما شش نتیجه متفاوت دارید که هر کدام با یک عدد مرتبط است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "کاری که ما انجام می دهیم این است که چندین نمونه مختلف از آن متغیر گرفته و همه آنها را با هم جمع می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "در تخته گالتون ما، به نظر می رسد که اجازه دهید توپ از چندین میخ مختلف در مسیر پایین به پایین پرش کند، و در مورد یک قالب، ممکن است تصور کنید که تاس های مختلف پرتاب کنید و نتایج را جمع کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "ادعای قضیه حد مرکزی این است که هرچه شما اجازه دهید اندازه آن مجموع بزرگتر و بزرگتر شود، توزیع آن مجموع، چقدر احتمال دارد که در مقادیر ممکن مختلف قرار گیرد، بیشتر و بیشتر شبیه یک منحنی زنگ خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "همین است، ایده کلی همین است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "در طول این درس، وظیفه ما این است که آن بیانیه را کمی بیشتر کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "ما قصد داریم تعدادی اعداد برای آن قرار دهیم، چند فرمول برای آن قرار دهیم، نشان دهیم که چگونه می توانید از آن برای پیش بینی استفاده کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "به عنوان مثال، در اینجا سؤالی است که می خواهم تا پایان این ویدیو بتوانید به آن پاسخ دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "فرض کنید قالب را 100 بار چرخانده اید و نتایج را با هم جمع کرده اید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "آیا می توانید محدوده ای از مقادیر را پیدا کنید که 95٪ مطمئن باشید که مجموع در آن محدوده قرار می گیرد؟ یا شاید باید بگویم کوچکترین محدوده ممکن از مقادیر را پیدا کنید تا این درست باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "نکته دقیق این است که شما قادر خواهید بود به این سوال پاسخ دهید که آیا این یک قالب عادلانه است یا یک قالب وزنی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "حال اجازه دهید در بالا بگویم که این قضیه سه فرض متفاوت دارد که در آن گنجانده شده است، سه چیز که قبل از ادامه قضیه باید درست باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "و من در واقع تا پایان ویدیو به شما نمی گویم آنها چه هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "درعوض از شما می‌خواهم که چشم‌تان را دور نگه دارید و ببینید آیا می‌توانید متوجه شوید و شاید پیش‌بینی کنید که این سه فرض چه خواهند بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "به عنوان گام بعدی، برای نشان دادن بهتر اینکه چقدر این قضیه کلی است، می‌خواهم چند شبیه‌سازی دیگر را با تمرکز بر مثال تاس برای شما اجرا کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "معمولاً اگر به چرخاندن قالب فکر می کنید، شش نتیجه را به یک اندازه محتمل تصور می کنید، اما قضیه در واقع به آن اهمیتی نمی دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "ما می‌توانیم با یک قالب وزن‌دار شروع کنیم، چیزی با توزیع غیر پیش پاافتاده در بین نتایج، و ایده اصلی همچنان پابرجاست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "برای شبیه سازی کاری که من انجام خواهم داد این است که مقداری توزیع مانند این را انتخاب کنم که به سمت مقادیر پایین تر منحرف شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "من 10 نمونه متمایز از آن توزیع را می‌گیرم و سپس مجموع آن نمونه را در نمودار پایین ثبت می‌کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "سپس می‌خواهم این کار را در زمان‌های مختلف انجام دهم، همیشه با مجموع اندازه 10، اما پیگیری کنید که این مبالغ به کجا ختم شده‌اند تا حسی از توزیع به ما بدهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "و در واقع اجازه دهید جهت y را تغییر دهم تا فضایی برای اجرای تعداد بیشتری نمونه به ما بدهم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "و من آن را تا چند هزار نفر ادامه می‌دهم، و همانطور که انجام می‌شود متوجه خواهید شد که شکلی که شروع به ظهور می‌کند شبیه یک منحنی زنگوله است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "شاید اگر چشمانتان را به هم بزنید، بتوانید ببینید که کمی به سمت چپ کج شده است، اما خوب است که چیزی متقارن از نقطه شروعی که بسیار نامتقارن بود، پدیدار شد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "برای توضیح بهتر قضیه حد مرکزی، اجازه دهید چهار تا از این شبیه‌سازی‌ها را به صورت موازی اجرا کنم، جایی که در سمت چپ بالا، من این کار را انجام می‌دهم، جایی که فقط دو تاس را در یک زمان اضافه می‌کنیم، در سمت راست بالا. دوباره این کار را در جایی انجام می‌دهیم که در آن واحد پنج تاس اضافه می‌کنیم، پایین سمت چپ همان تاس است که به تازگی شاهد اضافه کردن 10 تاس در یک زمان بودیم، و سپس یک تاس دیگر با مجموع بزرگ‌تر، هر بار 15 تاس انجام می‌دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "توجه کنید که چگونه در سمت چپ بالا، زمانی که ما فقط دو تاس را اضافه می کنیم، توزیع حاصل واقعاً شبیه یک منحنی زنگ نیست، به نظر می رسد بسیار بیشتر یادآور همان چیزی است که ما با آن به سمت چپ خم شده بودیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "اما از آنجایی که در هر مجموع تعداد تاس‌های بیشتری را مجاز می‌کنیم، شکل حاصل در این توزیع‌ها متقارن‌تر و متقارن‌تر به نظر می‌رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "این توده در وسط است و به شکل منحنی زنگوله ای دم محو می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "و اجازه دهید دوباره تاکید کنم، شما می توانید با هر توزیع متفاوت شروع کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "در اینجا دوباره آن را اجرا می کنم، اما در جایی که بیشتر احتمالات در اعداد 1 و 6 گره خورده است، با احتمال بسیار کم برای مقادیر متوسط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "علیرغم تغییر کامل توزیع برای یک رول انفرادی قالب، هنوز هم با در نظر گرفتن مجموع های مختلف، شکل منحنی زنگ ظاهر می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "به تصویر کشیدن چیزها با شبیه سازی مانند این بسیار سرگرم کننده است، و دیدن نظم از هرج و مرج ظاهر می شود، اما کمی نادقیق نیز به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "مانند این مورد، وقتی شبیه سازی را در 3000 نمونه قطع کردم، حتی اگر به نوعی شبیه یک منحنی زنگی به نظر برسد، سطل های مختلف بسیار سیخ به نظر می رسند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "و ممکن است تعجب کنید، آیا قرار است به این شکل باشد یا این فقط یک مصنوع از تصادفی بودن در شبیه سازی است؟ و اگر چنین است، قبل از اینکه مطمئن شویم چیزی که به آن نگاه می کنیم نماینده توزیع واقعی است، به چند نمونه نیاز داریم؟ به جای حرکت رو به جلو، بیایید کمی بیشتر نظری داشته باشیم و شکل دقیقی را که این توزیع ها در دراز مدت به خود می گیرند نشان دهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "ساده ترین حالت برای انجام این محاسبه این است که توزیع یکنواخت داشته باشیم، که در آن هر وجه ممکن از قالب دارای احتمال مساوی 1 6 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "به عنوان مثال، اگر می‌خواهید بدانید که چقدر احتمال دارد که مجموع‌های مختلف برای یک جفت تاس وجود داشته باشد، در اصل یک بازی شمارش است، که در آن تعداد جفت‌های متمایز را در یک مجموع می‌شمارید، که در نموداری که من ترسیم کردم، شما می توانید به راحتی با عبور از تمام مورب های مختلف به آن فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "از آنجایی که هر یک از این جفت ها شانس یکسانی برای حضور دارند، 1 در 36، تنها کاری که باید انجام دهید این است که اندازه این سطل ها را بشمارید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "این به ما یک شکل قطعی برای توزیع می‌دهد که مجموع دو تاس را توصیف می‌کند، و اگر بخواهیم یک بازی را با تمام سه‌قلوهای ممکن انجام دهیم، توزیع حاصل به این شکل خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "اکنون آنچه چالش برانگیزتر، اما بسیار جالب تر است، این است که بپرسیم اگر توزیع غیریکنواختی برای آن قالب واحد داشته باشیم چه اتفاقی می افتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "ما در واقع در آخرین ویدیو در مورد این موضوع صحبت کردیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "شما اساساً همان کار را انجام می‌دهید، تمام جفت‌های متمایز تاس را که ارزش یکسانی دارند، مرور می‌کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "فقط این است که به جای شمارش آن جفت ها، برای هر جفت، دو احتمال هر صورت خاص را ضرب می کنید و سپس همه آن ها را با هم جمع می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "محاسباتی که این کار را برای تمام مبالغ ممکن انجام می دهد، نامی جذاب دارد، به آن پیچیدگی می گویند، اما اساساً فقط نسخه وزن دار بازی شمارش است که هر کسی که با یک جفت تاس بازی کرده است، قبلاً آن را آشنا می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "برای اهداف ما در این درس، من از کامپیوتر می‌خواهم همه اینها را محاسبه کند، به سادگی نتایج را برای شما نمایش دهد و شما را به مشاهده الگوهای خاصی دعوت کند، اما در زیر کاپوت، این چیزی است که می‌گذرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "بنابراین، برای اینکه در مورد آنچه در اینجا نمایش داده می شود کاملاً واضح باشیم، اگر تصور کنید که دو مقدار متفاوت را از آن توزیع بالا نمونه برداری کنید، مقداری که یک قالب را توصیف می کند، و آنها را با هم جمع می کنید، توزیع دومی که من ترسیم می کنم نشان می دهد که چقدر احتمال دارد مبالغ مختلف را ببینید به همین ترتیب، اگر تصور کنید که سه مقدار متمایز را از آن توزیع بالا نمونه برداری کنید، و آنها را با هم جمع کنید، نمودار بعدی احتمالات را برای مجموع مختلف مختلف در آن مورد نشان می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "بنابراین، اگر من محاسبه کنم که توزیع این مجموع برای مجموع بزرگتر و بزرگتر چگونه است، خوب می دانید که چه چیزی می خواهم بگویم، بیشتر و بیشتر شبیه یک منحنی زنگوله به نظر می رسد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "اما قبل از اینکه به آن بپردازیم، می‌خواهم چند مشاهدات ساده‌تر را انجام دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "به عنوان مثال، به نظر می رسد که این توزیع ها به سمت راست سرگردان هستند، و همچنین به نظر می رسد که گسترش بیشتری پیدا می کنند، و کمی هموارتر می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "شما نمی توانید قضیه حد مرکزی را به صورت کمی بدون در نظر گرفتن هر دوی این اثرات توصیف کنید، که به نوبه خود مستلزم توصیف میانگین و انحراف معیار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "شاید شما قبلاً با آن‌ها آشنا باشید، اما من می‌خواهم در اینجا حداقل فرضیات را بیان کنم، و مرور کردن آن هرگز ضرری ندارد، بنابراین بیایید به سرعت هر دوی آن‌ها را مرور کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "میانگین توزیع، که اغلب با حرف یونانی mu نشان داده می شود، راهی برای گرفتن مرکز جرم برای آن توزیع است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "به عنوان مقدار مورد انتظار متغیر تصادفی ما محاسبه می شود، که راهی برای گفتن شما از طریق تمام نتایج ممکن مختلف است، و احتمال آن نتیجه را در مقدار متغیر ضرب می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "اگر مقادیر بالاتر محتمل تر باشد، آن جمع وزنی بزرگتر خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "اگر مقادیر پایین‌تر محتمل‌تر باشند، آن جمع وزنی کوچک‌تر خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "اگر بخواهید میزان پراکندگی این توزیع را اندازه گیری کنید، کمی جالب تر است، زیرا راه های مختلفی برای انجام آن وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "یکی از آنها واریانس نام دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "ایده این است که به تفاوت بین هر مقدار ممکن و میانگین نگاه کنیم، آن اختلاف را مربع کنیم و مقدار مورد انتظار آن را بخواهیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "ایده این است که چه مقدار شما زیر یا بالاتر از میانگین باشد، وقتی آن اختلاف را مربع می‌کنید، یک عدد مثبت به دست می‌آید و هر چه این اختلاف بزرگ‌تر باشد، آن عدد بزرگ‌تر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "مربع کردن آن به این صورت معلوم می‌شود که ریاضیات را بسیار بهتر از زمانی می‌کند که چیزی شبیه مقدار مطلق انجام می‌دادیم، اما نقطه ضعف آن این است که فکر کردن به این فاصله در نمودار ما سخت است زیرا واحدها خاموش هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "مانند واحدهای اینجا واحدهای مربعی هستند، در حالی که فاصله در نمودار ما نوعی واحد خطی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "بنابراین روش دیگری برای اندازه گیری گسترش چیزی است که انحراف معیار نامیده می شود که جذر این مقدار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "این را می توان بسیار منطقی تر به عنوان فاصله در نمودار ما تفسیر کرد، و معمولاً با حرف یونانی سیگما نشان داده می شود، بنابراین شما m را به معنای میانگین به عنوان انحراف استاندارد می شناسید، اما هر دو را در یونانی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "با نگاهی به توالی توزیع‌هایمان، بیایید در مورد میانگین و انحراف معیار صحبت کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "اگر میانگین توزیع اولیه را mu بنامیم که برای تصویر نشان داده شده 2 است. 24، امیدوارم خیلی تعجب آور نباشد اگر به شما بگویم که میانگین بعدی 2 برابر mu است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "یعنی شما یک جفت تاس می اندازید، می خواهید مقدار مورد انتظار مجموع را بدانید، این دو برابر مقدار مورد انتظار برای یک قالب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "به طور مشابه، مقدار مورد انتظار برای مجموع اندازه 3 ما 3 برابر mu است، و غیره و غیره. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "میانگین فقط به طور پیوسته به سمت راست حرکت می کند، به همین دلیل است که به نظر می رسد توزیع های ما در آن جهت حرکت می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "کمی چالش برانگیزتر، اما بسیار مهم، توصیف چگونگی تغییر انحراف معیار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "واقعیت کلیدی در اینجا این است که اگر دو متغیر تصادفی متفاوت داشته باشید، واریانس مجموع آن متغیرها مانند جمع کردن دو واریانس اصلی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "این یکی از آن حقایقی است که با باز کردن تمام تعاریف می توانید آن را محاسبه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "چند شهود خوب برای اینکه چرا درست است وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "برنامه آزمایشی من این است که در واقع یک سریال در مورد احتمال بسازم و در مورد چیزهایی مانند شهودهای نهفته در واریانس و پسرعموهای آن در آنجا صحبت کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "اما در حال حاضر، اصلی‌ترین چیزی که از شما می‌خواهم برجسته کنید این است که چگونه واریانس است که اضافه می‌کند، این انحراف معیار نیست که اضافه می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "بنابراین، به طور انتقادی، اگر بخواهید n تحقق مختلف از یک متغیر تصادفی یکسان را در نظر بگیرید و بپرسید که مجموع آن چگونه است، واریانس آن مجموع n برابر واریانس متغیر اصلی شما است، یعنی انحراف معیار، جذر همه. این، جذر n برابر انحراف استاندارد اصلی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "به عنوان مثال، در توالی توزیع های خود، اگر انحراف معیار اولیه خود را با سیگما برچسب گذاری کنیم، انحراف استاندارد بعدی جذر 2 برابر سیگما خواهد بود و پس از آن به نظر می رسد مانند جذر 3 برابر سیگما و غیره و غیره. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "این همانطور که گفتم بسیار مهم است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "این بدان معناست که با وجود اینکه توزیع‌های ما در حال پخش شدن هستند، اما آنقدر سریع پخش نمی‌شوند، آنها این کار را فقط به نسبت جذر اندازه مجموع انجام می‌دهند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "همانطور که ما برای توضیح کمی بیشتر از قضیه حد مرکزی آماده می‌شویم، شهود اصلی که می‌خواهم شما در ذهن خود نگه دارید این است که اساساً همه این توزیع‌ها را مجدداً تنظیم می‌کنیم تا ابزارهای آنها در کنار هم قرار گیرند، و سپس آنها را به گونه‌ای تغییر مقیاس دهیم. که تمام انحرافات استاندارد فقط برابر با 1 خواهند بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "و وقتی این کار را انجام می‌دهیم، شکلی که به دست می‌آید به یک شکل جهانی خاص نزدیک‌تر و نزدیک‌تر می‌شود، که با یک عملکرد کوچک زیبا توصیف می‌شود که ما فقط در یک لحظه آن را باز می‌کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "و اجازه دهید یک بار دیگر بگویم، جادوی واقعی اینجاست که چگونه می‌توانستیم با هر توزیعی شروع کنیم، و یک رول از قالب را توصیف کنیم، و اگر همان بازی را انجام دهیم، با توجه به اینکه توزیع‌ها برای مبالغ مختلف چگونه به نظر می‌رسند، و آنها را مجدداً مرتب می کنیم تا ابزارها در یک ردیف قرار گیرند، و آنها را به گونه ای تغییر می دهیم که انحرافات استاندارد همه 1 باشند، ما هنوز به همان شکل جهانی نزدیک می شویم که به نوعی گیج کننده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "و اکنون، دوستان من، احتمالاً زمان خوبی است تا در نهایت وارد فرمول توزیع عادی شویم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "و روشی که من می خواهم این کار را انجام دهم این است که اساساً تمام لایه ها را پوست کنده و آن را یک تکه در یک زمان بسازم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "تابع e نسبت به x، یا هر چیزی نسبت به x، رشد نمایی را توصیف می‌کند، و اگر آن نما را که به صورت افقی در اطراف نمودار چرخش می‌کند، منفی کنید، ممکن است آن را به عنوان توصیف فروپاشی نمایی در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "برای ایجاد این فروپاشی در هر دو جهت، می توانید کاری انجام دهید تا مطمئن شوید که توان همیشه منفی و در حال رشد است، مانند گرفتن قدر مطلق منفی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "این یک نقطه تیز ناخوشایند را در وسط به ما می دهد، اما اگر در عوض آن نما را مربع منفی x قرار دهید، نسخه صاف تری از همان چیز دریافت می کنید که در هر دو جهت تحلیل می رود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "این شکل اصلی منحنی زنگ را به ما می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "حالا اگر یک ثابت را جلوی آن x پرتاب کنید و آن ثابت را بالا و پایین کنید، به شما امکان می دهد نمودار را به صورت افقی کشیده و له کنید و به شما امکان می دهد منحنی های زنگ باریک و گسترده تری را توصیف کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "و نکته‌ای که می‌خواهم در اینجا به آن اشاره کنم این است که بر اساس قواعد توان، همانطور که در اطراف ثابت c می‌چرخیم، می‌توانید آن را به‌عنوان تغییر پایه قدرت در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "و از این نظر، عدد e واقعاً برای فرمول ما خاص نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "ما می‌توانیم آن را با هر ثابت مثبت دیگری جایگزین کنیم، و با تغییر دادن آن ثابت، همان خانواده منحنی‌ها را دریافت خواهید کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "آن را به یک خانواده 2 منحنی تبدیل کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "آن را به یک خانواده 3 منحنی تبدیل کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "دلیل استفاده از e این است که به آن ثابت معنای بسیار خواندنی می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "یا بهتر است بگوییم، اگر چیزها را کمی مجدداً پیکربندی کنیم به طوری که توان به نظر منفی نصف x تقسیم بر ثابت معینی به نظر برسد، که به طور پیشنهادی آن را مجذور سیگما می نامیم، پس از اینکه این را به یک توزیع احتمال تبدیل کنیم، آن سیگما ثابت خواهد شد. انحراف معیار آن توزیع باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "و این خیلی خوب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "اما قبل از اینکه بتوانیم این را به عنوان توزیع احتمال تفسیر کنیم، باید مساحت زیر منحنی 1 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "و دلیل آن نحوه تفسیر منحنی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "برخلاف توزیع‌های گسسته، وقتی صحبت از چیزی پیوسته می‌شود، احتمال یک نقطه خاص را نمی‌پرسید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "در عوض، احتمال قرار گرفتن یک مقدار بین دو مقدار متفاوت را می‌پرسید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "و چیزی که منحنی به شما می گوید این است که این احتمال برابر است با مساحت زیر منحنی بین این دو مقدار. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "یک ویدیوی کاملاً دیگر در مورد این وجود دارد که به آنها توابع چگالی احتمال می گویند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "نکته اصلی در حال حاضر این است که ناحیه زیر کل منحنی نشان دهنده احتمال وقوع چیزی است، که عددی بالا می آید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "این باید 1 باشد، به همین دلیل است که می خواهیم مساحت زیر آن 1 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "همانطور که با شکل منحنی زنگ پایه e به مربع منفی x، مساحت 1 نیست، در واقع جذر pi است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "می دانم، درست است؟ پی اینجا چیکار میکنه؟ این چه ربطی به حلقه ها دارد؟ همانطور که در ابتدا گفتم، دوست دارم در ویدیوی بعدی همه چیز را در مورد آن صحبت کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "اما اگر در حال حاضر بتوانید از هیجان خود برای اهداف ما صرفه‌جویی کنید، معنایش این است که باید این تابع را بر جذر pi تقسیم کنیم و مساحت مورد نظر را به ما می‌دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "با توجه به ثابت‌هایی که قبلاً داشتیم، نیمه 1 و سیگما، اثری که وجود دارد باعث می‌شود که نمودار را با ضریب سیگما ضربدر جذر 2 بکشیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "بنابراین ما نیز باید آن را بر آن تقسیم کنیم تا مطمئن شویم مساحت آن 1 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "و با ترکیب این کسرها، ضریب جلویی به نظر می رسد 1 تقسیم بر سیگما ضربدر جذر 2 پی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "این، در نهایت، یک توزیع احتمال معتبر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "همانطور که مقدار سیگما را تغییر می دهیم و منحنی های باریک تر و گسترده تر را به همراه می آوریم، آن ثابت در جلو همیشه تضمین می کند که مساحت برابر با 1 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "مورد خاصی که سیگما برابر با 1 است، نام خاصی دارد، ما آن را توزیع نرمال استاندارد می نامیم، که نقش ویژه ای برای من و شما در این درس دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "و همه توزیع‌های نرمال ممکن نه تنها با این مقدار سیگما پارامتر می‌شوند، بلکه یک mu ثابت دیگر را نیز از متغیر x کم می‌کنیم، و این اساساً به شما اجازه می‌دهد نمودار را به چپ و راست بکشید تا بتوانید میانگین این توزیع را تجویز کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "بنابراین به طور خلاصه، ما دو پارامتر داریم، یکی میانگین را توصیف می کند، یکی انحراف استاندارد را توصیف می کند، و همه آنها در این فرمول بزرگ که شامل یک e و یک pi است، با هم گره خورده اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "اکنون که همه اینها روی میز است، بیایید دوباره به این ایده نگاه کنیم که با یک متغیر تصادفی شروع کنیم و بپرسیم که توزیع مجموع آن متغیر چگونه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "همانطور که قبلاً گفته‌ایم، وقتی اندازه آن مجموع را افزایش می‌دهید، توزیع حاصل مطابق با میانگین رو به رشد تغییر می‌کند و به آرامی مطابق با یک انحراف استاندارد رو به رشد گسترش می‌یابد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "و با قرار دادن چند فرمول واقعی برای آن، اگر میانگین متغیر تصادفی زیربنایی خود را بدانیم، آن را mu می نامیم، و همچنین انحراف معیار آن را می دانیم، و آن را سیگما می نامیم، آنگاه میانگین برای مجموع در پایین، mu خواهد بود. برابر اندازه مجموع، و انحراف معیار سیگما برابر جذر آن اندازه خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "بنابراین اکنون، اگر بخواهیم ادعا کنیم که این بیشتر و بیشتر شبیه یک منحنی زنگ است، و یک منحنی زنگی فقط با دو پارامتر مختلف، میانگین و انحراف استاندارد توصیف می‌شود، می‌دانید چه باید بکنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "شما می توانید آن دو مقدار را به فرمول متصل کنید، و این فرمول بسیار واضح، البته به نوعی پیچیده، برای منحنی به شما می دهد که باید کاملاً متناسب با توزیع ما باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "اما روش دیگری وجود دارد که می‌توانیم آن را توصیف کنیم که کمی ظریف‌تر است و خود را به تصویری بسیار سرگرم‌کننده می‌دهد که می‌توانیم آن را بسازیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "به جای تمرکز روی مجموع همه این متغیرهای تصادفی، بیایید این عبارت را کمی تغییر دهیم، جایی که ما انجام خواهیم داد این است که به میانگینی که انتظار داریم آن مجموع گرفته شود، نگاه می کنیم و آن را کم می کنیم تا عبارت جدید ما دارای میانگین 0 است، و سپس به انحراف استانداردی که از مجموع خود انتظار داریم نگاه می کنیم و بر آن تقسیم می کنیم، که اساساً فقط واحدها را مجدداً مقیاس می دهد تا انحراف استاندارد عبارت ما برابر با 1 شود. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "ممکن است این عبارت پیچیده‌تر به نظر برسد، اما در واقع معنای بسیار خوانایی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "اساساً بیان می کند که این مجموع چند انحراف معیار از میانگین فاصله دارد؟ برای مثال، این نوار در اینجا با مقدار خاصی مطابقت دارد که ممکن است وقتی 10 تاس می‌اندازید و همه آنها را جمع می‌کنید، پیدا کنید، و موقعیت آن کمی بالاتر از منفی 1 به شما می‌گوید که این مقدار کمی کمتر از یک انحراف استاندارد است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "کمتر از میانگین همچنین، به هر حال، در انتظار انیمیشنی که می‌خواهم در اینجا بسازم، روشی که من چیزها را در آن طرح پایین نشان می‌دهم این است که مساحت هر یک از این نوارها احتمال مقدار مربوطه را به ما می‌گوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "به جای ارتفاع ممکن است فکر کنید که محور y نشان دهنده احتمال نیست، بلکه نوعی چگالی احتمال است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "دلیل این امر این است که مرحله را به گونه ای تنظیم کنیم که با روشی که ما توزیع های پیوسته را تفسیر می کنیم، مطابقت داشته باشد، جایی که احتمال سقوط بین محدوده ای از مقادیر برابر با یک ناحیه زیر منحنی بین آن مقادیر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "به طور خاص، مساحت همه میله ها با هم 1 خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "حالا، با وجود همه اینها، بیایید کمی سرگرم شویم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "اجازه دهید با چرخاندن چیزها به عقب شروع کنم به طوری که توزیع در پایین یک مجموع نسبتاً کوچک را نشان دهد، مانند جمع کردن تنها سه متغیر تصادفی با هم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "توجه کنید که وقتی توزیعی را که با آن شروع می کنیم تغییر می دهم چه اتفاقی می افتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "همانطور که تغییر می کند، توزیع در پایین به طور کامل شکل خود را تغییر می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "این بسیار بستگی به چیزی دارد که ما با آن شروع کرده ایم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "اگر اجازه دهیم اندازه مجموع ما کمی بزرگتر شود، مثلاً به عدد 10 برسیم، و وقتی توزیع را برای x تغییر می‌دهم، تا حد زیادی شبیه یک منحنی زنگ می‌ماند، اما می‌توانم توزیع‌هایی را پیدا کنم که باعث تغییر شکل آن شوند. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "به عنوان مثال، منحنی واقعاً کج که تقریباً تمام احتمالات آن در اعداد 1 یا 6 است منجر به این نوع منحنی زنگ سیخ دار می شود، و اگر به خاطر داشته باشید، قبلاً من در واقع این را در قالب یک شبیه سازی نشان دادم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "بنابراین اگر می‌پرسید که آیا این تیز بودن مصنوع تصادفی است یا توزیع واقعی را منعکس می‌کند، معلوم می‌شود که توزیع واقعی را منعکس می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "در این مورد، 10 مجموع کافی برای اجرای قضیه حد مرکزی نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "اما اگر به جای آن اجازه بدهم که این مجموع رشد کند و 50 مقدار مختلف را اضافه کنم، که در واقع آنقدر بزرگ نیست، مهم نیست که چگونه توزیع را برای متغیر تصادفی زیربنایی خود تغییر می‌دهم، اساساً تأثیری بر شکل نمودار روی نمودار نخواهد داشت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "پایین مهم نیست که از کجا شروع کنیم، تمام اطلاعات و تفاوت های ظریف برای توزیع x از بین می رود، و ما به سمت این شکل جهانی منفرد که با یک تابع بسیار زیبا برای توزیع نرمال استاندارد، 1 روی ریشه مربع از 2 پی ضربدر e میل می کنیم. به منفی x مجذور 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "این دقیقاً در اینجا چیزی است که قضیه حد مرکزی در مورد آن است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "تقریباً هیچ کاری که نمی توانید برای این توزیع اولیه انجام دهید، شکلی را که ما به آن تمایل داریم تغییر می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "اکنون، هر کس در میان شما که دارای تفکر نظری بیشتری است، ممکن است همچنان بپرسید، قضیه واقعی چیست؟ مثلاً، آن گزاره ی ریاضی که در اینجا ادعا می کنیم چیست که می تواند اثبات یا رد شود؟ اگر می خواهید یک بیانیه رسمی خوب داشته باشید، در اینجا نحوه انجام آن آمده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "این مقدار را در نظر بگیرید، جایی که ما n نمونه مختلف از متغیر تصادفی خود را جمع‌بندی می‌کنیم، اما بهینه‌سازی و تنظیم شده است تا میانگین و انحراف استاندارد آن 1 باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "باز هم، به این معنی که می‌توانید آن را به‌عنوان سؤال بخوانید که مجموع چند انحراف استاندارد از میانگین فاصله دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "سپس گزاره دقیق واقعی بدون شوخی-این بار قضیه حد مرکزی این است که اگر احتمال قرار گرفتن این مقدار بین دو عدد واقعی داده شده، a و b را در نظر بگیرید، و حد آن احتمال را به اندازه اندازه در نظر بگیرید. مجموع شما به بی نهایت می رود، سپس آن حد برابر با یک انتگرال مشخص است، که اساساً مساحت را تحت یک توزیع نرمال استاندارد بین آن دو مقدار توصیف می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "باز هم، سه فرض اساسی وجود دارد که من هنوز باید به شما بگویم، اما به غیر از آنها، با تمام جزئیات شدیدش، این درست در اینجا قضیه حد مرکزی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "همه اینها کمی تئوری است، بنابراین ممکن است مفید باشد که همه چیز را به زمین بازگردانیم و به مثال عینی که در ابتدا ذکر کردم برگردیم، جایی که تصور می‌کنید یک قالب را 100 بار می‌چرخانید، و بیایید فرض کنیم که یک قالب عادلانه است. برای این مثال، و شما نتایج را با هم جمع کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "چالش پیش روی شما این است که محدوده ای از مقادیر را پیدا کنید به طوری که 95٪ مطمئن باشید که مجموع در این محدوده قرار می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "برای سؤالاتی مانند این، یک قانون ساده در مورد توزیع های نرمال وجود دارد، این است که حدود 68٪ از مقادیر شما در یک انحراف استاندارد از میانگین قرار می گیرند، 95٪ از مقادیر شما، چیزی که ما به آن اهمیت می دهیم، در آن قرار می گیرند. دو انحراف استاندارد از میانگین و 99 بسیار زیاد. 7٪ از مقادیر شما در سه انحراف استاندارد از میانگین قرار می گیرند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "این یک قانون سرانگشتی است که معمولاً توسط افرادی که احتمالات و آمار زیادی انجام می دهند حفظ می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "طبیعتاً، این به ما چیزی را می‌دهد که برای مثال خود نیاز داریم، و اجازه دهید ادامه دهم و ترسیم کنم که چگونه به نظر می‌رسد، جایی که من توزیع را برای یک عادلانه در بالا نشان می‌دهم، و توزیع را برای مجموع 100 نشان می‌دهم. چنین تاس هایی در پایین، که در حال حاضر همانطور که می دانید به نظر یک توزیع نرمال خاص است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "گام اول با چنین مشکلی این است که میانگین توزیع اولیه خود را بیابید، که در این حالت مانند 1 ششم ضربدر 1 بعلاوه 1 ششم ضربدر 2 بر روی و رو به رو خواهد شد و 3 خواهد بود. 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "ما همچنین به انحراف استاندارد نیاز داریم، که نیاز به محاسبه واریانس دارد، که همانطور که می‌دانید شامل اضافه کردن تمام مربع‌های تفاوت بین مقادیر و میانگین است، و نتیجه آن 2 است. 92، جذر آن برابر 1 می شود. 71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "اینها تنها دو عددی هستند که ما به آن نیاز داریم، و من دوباره از شما دعوت خواهم کرد تا به این فکر کنید که چقدر جادویی است که این دو عدد تنها دو عددی هستند که برای درک کامل توزیع پایین به آنها نیاز دارید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "میانگین آن 100 برابر مو یعنی 350 و انحراف معیار آن جذر 100 برابر سیگما، پس 10 برابر سیگما 17 خواهد بود. 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "با یادآوری قاعده کلی خود، ما به دنبال مقادیری هستیم که دو انحراف استاندارد از میانگین فاصله دارند، و وقتی 2 سیگما را از میانگین کم کنید، در نهایت به 316 می رسید و وقتی 2 سیگما را اضافه می کنید، به 384 می رسید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "و همین که می روی، جواب ما را می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "بسیار خوب، من قول دادم که به زودی همه چیز را جمع بندی کنم، اما در حالی که در حال بررسی این مثال هستیم، یک سوال دیگر وجود دارد که ارزش وقت گذاشتن شما را برای تامل دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "به جای اینکه فقط در مورد مجموع 100 رول قالب بپرسید، فرض کنید از شما خواسته بودم آن عدد را بر 100 تقسیم کنید، که اساساً به این معنی است که تمام اعداد در نمودار ما در پایین بر 100 تقسیم می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "یک لحظه وقت بگذارید و تفسیر کنید که این همه چه می‌گویند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "این عبارت اساساً میانگین تجربی 100 رول قالب مختلف را به شما می گوید، و آن بازه زمانی که ما پیدا کردیم اکنون به شما می گوید که انتظار دارید چه محدوده ای را برای آن میانگین تجربی ببینید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "به عبارت دیگر، ممکن است انتظار داشته باشید که حدود 3 باشد. 5، این مقدار مورد انتظار برای یک رول قالب است، اما چیزی که خیلی کمتر آشکار است و قضیه حد مرکزی به شما اجازه می‌دهد محاسبه کنید این است که چقدر به مقدار مورد انتظار نزدیک می‌شوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "به ویژه، ارزش وقت شما را دارد تا لحظه ای در مورد اینکه انحراف استاندارد برای این میانگین تجربی چقدر است، و وقتی به نمونه بزرگتر و بزرگتری از دای رول ها نگاه می کنید چه اتفاقی برای آن می افتد فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "در نهایت، اما احتمالا مهم‌تر از همه، اجازه دهید در مورد مفروضاتی که در این قضیه وجود دارد صحبت کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "اولین مورد این است که همه این متغیرهایی که جمع می کنیم مستقل از یکدیگر هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "نتیجه یک فرآیند بر نتیجه هیچ فرآیند دیگری تأثیر نمی گذارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "دوم اینکه همه این متغیرها از یک توزیع گرفته شده اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "هر دوی اینها به طور ضمنی با مثال تاس ما فرض شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "ما نتیجه هر رول دای را مستقل از نتیجه همه حلقه‌های دیگر می‌دانیم، و فرض می‌کنیم که هر قالب از توزیع یکسانی پیروی می‌کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "گاهی اوقات در ادبیات، این دو فرض را می بینید که در زیر حروف اول IID برای مستقل و به طور یکسان توزیع شده اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "یکی از شرایطی که این فرضیات به طور قطعی درست نیستند، تابلوی گالتون است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "یعنی بهش فکر کن آیا این طور است که نحوه پرش توپ از یکی از میخ ها مستقل از نحوه پرش توپ از میخ بعدی است؟ قطعا نه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "بسته به آخرین پرش، با یک مسیر کاملا متفاوت وارد می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "و آیا چنین است که توزیع نتایج احتمالی هر میخ برای هر میخ یکسان باشد؟ باز هم، تقریباً مطمئناً نه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "شاید با نگاهی به چپ به یک میخ برخورد کند، به این معنی که نتایج به شدت در آن جهت منحرف شده است، و سپس با نگاهی به سمت راست به میخ بعدی برخورد می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "وقتی تمام آن فرضیات ساده‌کننده را در مثال ابتدایی مطرح کردم، فقط برای این نبود که فکر کردن به آن آسان‌تر شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "همچنین این فرضیات لازم بود تا این در واقع نمونه ای از قضیه حد مرکزی باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "با این وجود، به نظر می رسد درست باشد که برای تخته گالتون واقعی، با وجود نقض هر دوی این موارد، توزیع نرمال به نوعی به وجود می آید؟ بخشی از دلیل ممکن است این باشد که تعمیم هایی از قضیه خارج از محدوده این ویدیو وجود دارد که این فرضیات، به ویژه مورد دوم را تسهیل می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "اما من می‌خواهم به شما در مورد این واقعیت هشدار دهم که بسیاری از اوقات افراد تصور می‌کنند که یک متغیر به طور معمول توزیع شده است، حتی زمانی که هیچ توجیه واقعی برای انجام آن وجود ندارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "فرض سوم در واقع نسبتاً ظریف است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "این است که واریانسی که ما برای این متغیرها محاسبه کرده ایم محدود است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "این هرگز برای مثال تاس مشکلی نبود، زیرا تنها شش نتیجه ممکن وجود داشت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "اما در موقعیت‌های خاصی که مجموعه‌ای از نتایج نامتناهی دارید، وقتی می‌خواهید واریانس را محاسبه کنید، مجموع به بی‌نهایت واگرا می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "اینها می توانند توزیع های احتمالی کاملاً معتبری باشند، و در عمل نیز به وجود می آیند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "اما در آن موقعیت‌ها، وقتی در نظر می‌گیرید نمونه‌های مختلفی از آن متغیر را اضافه کنید و اجازه دهید آن مجموع به بی‌نهایت نزدیک شود، حتی اگر دو فرض اول پابرجا باشند، این احتمال وجود دارد که چیزی که به آن تمایل دارید در واقع یک توزیع عادی نباشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "اگر تا اینجا همه چیز را فهمیده باشید، اکنون یک پایه بسیار قوی در مورد قضیه حد مرکزی دارید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "و در مرحله بعد، می‌خواهم توضیح دهم که چرا این تابع خاص همان چیزی است که ما به سمت آن گرایش داریم، و چرا یک عدد pi در آن وجود دارد، چه ربطی به دایره‌ها دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]