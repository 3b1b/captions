[
 {
  "input": "This is a Galton board. ",
  "translatedText": "ゴルトンボードです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "これは、単一の出来事が混沌としてランダムで、結 果が実質的に不可知である場合でも、多数の出来事について正確 に述べることがどのように可能であるかを示すよく知られたデモ ンストレーションです。さまざまな結果が分散されるためです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "より具体的には、ゴルトン板は、正規分布として知られる、より口語的には釣鐘 曲線として知られ、ガウス分布とも呼ばれる、あらゆる確率の中で最も顕著な 分布の 1 つを示しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "この分布を記述するための非常に特殊な関数があり ます。これは非常に美しいです。後で説明しますが、ここでは、正規分布がその名前が示 すように非常に一般的であり、多くの場所で現れることを強調したいと思います。一見無関 係に見えるコンテキスト。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "同じような人口統計に属する多数の人々を抽出して身長 をプロットした場合、それらの身長は正規分布に従う傾向があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "非常に大き な自然数の大きな部分を見て、それらの数値のそれぞれに個別の素因数がいくつ あるかを尋ねると、答えは特定の正規分布に非常に厳密に従うことになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "さて、今日のトピックは、すべての確率論における至宝の 1 つであり、この分布がなぜこれ ほど一般的であるかを説明する重要な事実の 1 つであり、中心極限定理として知られてい ます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "このレッスンは基本に戻り、中心極限定理が何を言っているのか、正規分布とは何 かについての基礎を説明することを目的としており、最小限の背景を想定したいと思い ます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "私たちはこの問題をかなり深く掘り下げていきますが、この後もさらに深く掘り下げて、なぜ定 理が正しいのか、なぜ正規分布の基礎となる関数がそのような非常に特殊な形式をとるのか、なぜその公 式が次のような形になるのかを説明したいと思います。そして最も興味深いのは、これらの最後の 2 つの事実が、多くの従来の説明が示唆するよりも実際に関連している理由です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "2 番目のレッスンは 、約束したたたみ込みビデオの続編となることも意図しているため、ここには相互に関連するトピッ クがたくさんあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "しかし今は、基本に立ち返って、過度に単純化した Galton ボードのモデルから始めたいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "このモデルでは、各ボールが特定の中央のペ グに直接落ち、50-50 の確率で左または右に跳ね返ると仮定し、それらの結果 のそれぞれを 1 または 1 を加算するものと考えます。その位置から 1 を 減算します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "それらの 1 つが選択されると、その下に隣接するペグの中央に偶然着地するという 非常に非現実的な仮定を立てます。そこでもまた、左にバウンドするか、左にバウンドするかという同じ 50 対 50 の選択に直面することになります。右の方へ。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "私が画面に表示しているものでは、 5 つの異なるペグ列があるため、小さなホッピング ボールはプラス 1 とマイナス 1 の間で 5 つの異なるランダムな選択を行い、最終的な位置は基本的にすべての合計であると考えることがで きます。それらのさまざまな数値 (この場合はたまたま 1 つ) を合計し、さまざまなバケット すべてに、それらが表す合計でラベルを付けることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "これを繰り返しながら、これら 5 つの乱数について考えられるさまざまな合計を調べます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "そして、これは真のゴルトンボードの非常に 非現実的なモデルであると文句を言いたくなる人のために、現時点での目標は物理学を正確にモデ ル化することではないことを強調しておきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "目的は、中心極限定理を説明するために簡単な 例を示すことであり、そのために、これは理想的かもしれませんが、実際には非常に良い例 を提供します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "多くの異なるボールを落下させて、それらがすべて幽霊であるかのように相互に影響を及ぼ さないという非現実的な仮定をさらに立てた場合、それぞれの異なるバケツに落ちるボールの数から、それぞれ のボールがどれくらいの可能性があるかをある程度の大まかに把握できます。それらのバケツの中にあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "この例では、数値が非常に単純であるため、各バケットに該当する確率を明示的 に計算するのはそれほど難しくありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "このことをよく考えてみると、パスカルの 三角形を非常に彷彿とさせることがわかるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "しかし、私たちの定理の素晴らしい点は、それが 単純な例をどれだけ超えているかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "したがって、少なくとも手始めに、明示的な計 算を行うのではなく、多数のサンプルを実行し、さまざまな結果ごとの結果の合計数か らその分布がどのようになるかをある程度把握してシミュレーションしてみましょう 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "先ほども言いましたが、画面上のものには 5 行あるため、検討している各合計には 5 つの数字のみが含ま れています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "中心極限定理の基本的な考え方は、その和のサイズを大きくすると、たと えばここでは、各ボールが跳ね返るペグの列の数が増えることを意味し、その和がど こに行くのかを表す分布は次のようになります。秋はますますベルカーブのように見 えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "ここで、実際に少し時間をとってその一般的なアイデアを書き留める価値があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "設定では 、確率変数があり、これは基本的に、そのプロセスの各結果が何らかの数値に関 連付けられるランダム プロセスの略語です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "その乱数を x と呼びます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "たとえ ば、ペグからの各跳ね返りは、2 つの結果でモデル化されたランダム プロセスです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "これらの結果は、 マイナス 1 とプラス 1 の数値に関連付けられます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "確率変数のもう 1 つの例は、サイコ ロを振ることです。この場合、6 つの異なる結果が得られ、それぞれの結果が数字に関連付けられま す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "私たちがやっていることは、その変数の複数の異なるサンプルを取得し、それらをすべて加算する ことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "ゴルトン ボードでは、これはボールが下に落ちる途中で複数の異なるペグで跳ね返 るように見えます。サイコロの場合は、さまざまなサイコロを振って結果を合計することを想像 するかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "中心極限定理の主張は、和のサイズをどんどん大きくしていく と、その和の分布、つまり、さまざまな可能な値に該当する可能性が、ますます 釣鐘曲線のように見えるようになるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "それがそれです、それが一般的な考え方で す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "このレッスンを通じて、私たちの仕事は、そのステートメントをより定量的にすることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "それに いくつかの数値を入力し、いくつかの式を入力し、それを使用して予測を行う方法を示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "たとえば、このビデオの最後までに答えられるようにしておきたい質問は次のとおりです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "サイコロを 100 回振って結果を合計したとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "合計がその範囲内に収まることが 95% 確実であるような値の範囲を見つけることができますか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "あるいは、これが当てはまるような最小の値の範囲を見つけると言うべきかもしれません。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "素晴らしいのは、それが公平なダイスであるか、重み付けされたダイスであるかに関係なく、この質問に答えることができるということです。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "さて、最初に言っておきま すが、この定理には 3 つの異なる仮定が含まれており、定理が従う前に 3 つのことが真 でなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "そして、実際には、ビデオの最後までそれらが何であるかを説明するつもり はありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "代わりに、常に注目して、これら 3 つの仮定がどのようになるかに気づき、 予測できるかどうかを確認してほしいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "次のステップとして、この定理がどれほど一般的であ るかをよりよく説明するために、サイコロの例に焦点を当てたシミュレーションをさらにいくつか実行したいと思い ます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "通常、サイコロを振ることを考えるとき、6 つの結果が同じ確率であると考 えますが、定理は実際にはそれを気にしません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "重み付けされたダイス、つまり結果全体にわ たって自明ではない分布を持つものから始めることもできますが、中心となるアイデアは依然として有効です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "シミ ュレーションでは、このような、より低い値に偏った分布を取得し ます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "その分布から 10 個の異なるサンプルを取得し、そのサンプルの 合計を下部のプロットに記録します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "次に、これを何度も何度も繰り返します。常に サイズ 10 の合計を使用しますが、分布を把握するために、それらの合計がどこに到 達したかを追跡します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "そして実際に、さらに多くのサンプルを実行する余地を与えるために、y 方 向を再スケールしてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "数千までそのままにしていきます。そうすると、出現し 始める形状がベルカーブのように見えることに気づくでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "おそらく目を細める と、それが少し左に傾いているのがわかるでしょう。しかし、これほど非対称な出発点からこれ ほど対称的なものが現れたのは素晴らしいことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "中心極限定理が何であるかをよりよく説 明するために、これらのシミュレーションを 4 つ並行して実行してみます。左上では、一 度に 2 つのサイコロのみを追加しています。右上では、ここでは、一度に 5 個のサイ コロを追加します。左下は、一度に 10 個のサイコロを追加するものです。次に、一度に 15 個ずつ、より大きな合計で別のサイコロを追加します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "2 つのサイコロを追 加しただけの左上では、結果の分布が実際には鐘曲線のようには見えず 、左に傾いて開始した分布によく似ていることに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "しかし、各合計でより多くのサイコロを許可すると、これらの分布で得られる結果の 形状はますます対称的に見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "中央に塊があり、尾部のベルカーブの形に向か って消えていきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "もう一度強調しておきますが、別のディストリビューションから始めることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "ここでもう一度実行しますが、確率の大部分は 1 と 6 の数値に結びつき、 中間の値の確率は非常に低くなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "サイコロの個々のロールの分布を完全に変 更したにもかかわらず、さまざまな合計を考慮すると釣鐘曲線の形状が現れることに 変わりはありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "このようにシミュレーションを使って物事を説明するのはとても楽しいですし 、混沌から秩序が生まれるのを見るのはなんだか素敵ですが、少し不正確な気もします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "このケースのよ うに、シミュレーションを 3000 サンプルで切り取ると、たとえそれが釣鐘曲線のように見えても、さま ざまなバケットはかなりとがったように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "そして、それはそのように見えるはずだろうか、それともシミュレーショ ンのランダム性による単なるアーチファクトなのでしょうか?と疑問に思うかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "もしそうなら、見ているものが真 の分布を表していると確信できるようになるまでに、どれだけのサンプルが必要になるでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "代わりに、先に進む代わりに、もう少し理論的になり、これらの分布が長期的にどのような 形になるかを正確に示してみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "この計算を行う最も簡単なケースは、サイコロの 考えられる各面が等しい確率 (1 6 分の 1) を持つ一様分布がある場合です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "たとえば、サイコロのペアの合計が異なる可能性がどのくらいかを知りたい場合、これ は本質的に数えゲームであり、同じ合計を持つ異なるペアがいくつあるかを数えます 。私が描いた図では、これを表します。さまざまな対角線をすべて検討することで便 利に考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "このような各ペアが出現する確率は 36 分の 1 と等しいた め、必要なのはこれらのバケットのサイズを数えることだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "これにより、2 つのサイコロ の合計を表す分布の最終的な形状が得られ、可能なすべての 3 つの要素で同じゲー ムをプレイした場合、結果の分布は次のようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "ここで、より困難ですが、よ り興味深いのは、その 1 つのダイの分布が不均一である場合に何が起こるかを問うこ とです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "実はこれについては前回のビデオですべて話しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "本質的に同じことを行い 、合計すると同じ値になるサイコロの異なるペアをすべて調べます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "それらの ペアを数える代わりに、ペアごとに、特定の顔が現れる 2 つの確率を掛 け合わせて、それらをすべて加算するだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "考えられるすべての合計に対して これを行う計算には、畳み込みと呼ばれる派手な名前が付いていますが、本質的には、サイコロで 遊んだことがある人なら誰でもすでにおなじみの、カウンティング ゲームの重み付けバージョンに すぎません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "このレッスンの目的のために、コンピューターにこれらすべてを計算させ、 単に結果を表示して、特定のパターンを観察するように促しますが、内部ではこれが起 こっていることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "ここで何を表しているのかを明確にするために、上の分布 (1 つのダイ を表す分布) から 2 つの異なる値をサンプリングし、それらを加算することを想像すると、私 が描いている 2 番目の分布は、あなたがどのくらいの確率でダイスを表すかを表していることにな ります。さまざまな合計を参照してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "同様に、最上位の分布から 3 つの異なる 値をサンプリングし、それらを加算することを想像すると、次のプロットは、そ の場合のさまざまな合計の確率を表します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "したがって、これらの合計の分布が、合計が 大きくなるにつれてどのようになるかを計算すると、何を言いたいのかわかりますが、ますます釣 鐘曲線のように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "しかし、それに入る前に、もう少し簡単な観察をしていただきたいと 思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "たとえば、これらの分布は右にふらふらしているように見えますが、さらに広 がって、もう少し平坦になりつつあるように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "これらの効果の両方を考 慮せずに中心極限定理を定量的に記述することはできないため、平均 と標準偏差を記述する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "すでにこれらについてはご存知かもしれま せんが、ここでは最小限の仮定を置きたいと思います。復習するのは決して悪いことではないので、両方 について簡単に説明しましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "分布の平均はギリシャ文字の「ムー」で表され ることが多く、その分布の重心を捉える方法です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "これは確率変数 の期待値として計算されます。これは、考えられるさまざまな結果を すべて検討し、その結果の確率と変数の値を乗算することを意味しま す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "値が大きいほど可能性が高い場合、加重合計は大きくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "値が低い ほど可能性が高い場合、加重合計は小さくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "もう少し興味深いのは、 この分布がどの程度広がっているかを測定したい場合です。測定には複数の異な る方法があるためです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "そのうちの 1 つは分散と呼ばれます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "ここでの考え方は、考 えられる各値と平均値の差を調べ、その差を二乗して、その期待値を求める ことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "考え方としては、値が平均より下でも上でも、その差を二乗すると 正の数値が得られ、差が大きいほどその数値も大きくなるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "このように二乗すると、絶対値のようなことを行う場合よりもはるかに優れた計算にな ることがわかりますが、欠点は、単位が異なるため、これを図の距離として考えるの が難しいことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "ここの単位は平方単位であるのに対し、図の距離は一種の線形 単位であるようなものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "したがって、スプレッドを測定する別の方法は、この値の 平方根である標準偏差と呼ばれるものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "これは、図上の距離としてはるかに合理的に 解釈でき、一般にギリシャ文字のシグマで示されるため、平均と標準偏差の m が わかりますが、どちらもギリシャ語です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "一連の分布を振り返って、平均と標 準偏差について話しましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "初期分布の平均を mu と呼ぶと、図示されて いるものではたまたま 2 になります。24、次の平均が mu の 2 倍であると言っても、 それほど驚くべきことではないと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "つまり、サイコロを 1 つ振って、その合計の期待 値を知りたいとします。それは、1 つのサイコロの期待値の 2 倍です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "同様に、サ イズ 3 の合計の期待値は mu の 3 倍などとなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "平均値は 右に向かって着実に進んでおり、それが分布がその方向にずれているように見える 理由です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "もう少し難しいですが、非常に重要なのは、標準偏差がどのように変化するかを説明 することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "ここで重要な事実は、2 つの異なる確率変数がある場合、それらの変 数の合計の分散は、元の 2 つの分散を単純に加算したものと同じになるということ です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "これは、すべての定義を展開するときに計算できる事実の 1 つです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "それが真実である理由については、いくつかの優れた直感があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "私の暫定的な計画は、実際に確率に関 するシリーズを作成し、分散の基礎となる直観やその類似点などについて話す ことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "しかし、ここで私が強調したいのは、追加されるのは分散であって、追加 されるのは標準偏差ではないということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "したがって、重要なことに、同じ確 率変数の n 個の異なる実現を取得し、合計がどのようになるかを尋ねた場 合、その合計の分散は元の変数の分散の n 倍、つまり標準偏差、すべての平 方根を意味します。これは、元の標準偏差の n 倍の平方根です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "たとえば 、一連の分布に戻り、最初の標準偏差にシグマのラベルを付けると 、次の標準偏差はシグマの 2 倍の平方根になり、その後は次の標 準偏差のようになります。シグマの 3 倍など。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "先ほども言いましたが、こ れは非常に重要です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "これは、分布が広がっているとはいえ、それほど急速に広がっているわけ ではなく、合計のサイズの平方根に比例して広がっているだけであることを意味します 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "中心極限定理をより定量的に説明する準備をする際に、頭の中に留めておいていた だきたい中心的な直感は、基本的にこれらの分布すべてを再調整して、平均値が揃う ようにし、次にそれらを再スケーリングするということです。すべての標準偏差が 1 に等しくなるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "それを行うと、結果として得られる形状は、すぐ に開梱するエレガントな小さな関数で記述される特定の普遍的な形状にますます 近づきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "もう一度言わせてください、ここでの本当の魔法は、サイコロの 1 つの ロールを記述して、どのような分布から始めることができたのかということです。同じゲー ムをプレイした場合、多くの異なる合計の分布がどのようになるかを考慮して、そして、平 均値が揃うようにそれらを再調整し、標準偏差がすべて 1 になるように再スケーリング します。それでも同じ普遍的な形状に近づきますが、これはちょっと気が遠くなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "そして皆さん、今はおそらく正規分布の公式をついに理解するのに最高の時期だと思 います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "私がこれを行う方法は、基本的にすべてのレイヤーを剥がして、一度に 1 つずつ 構築することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "x に対する関数 e、または x に対する関数は指数関数的 な増加を表します。その指数を負にすると、グラフが水平方向に反転し、指数関 数的な減衰を表すと考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "これを両方向に減衰させる には、負の絶対値を取るなど、指数が常に負で増加するよう にすることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "これにより、中央にこのようなぎこちない鋭 い点ができてしまいますが、代わりにその指数を x の負の 2 乗にす ると、同じもののより滑らかなバージョンが得られ、両方向に減衰します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "これにより、基本的なベルカーブの形状が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "ここで、その x の前に定数を挿入し、その定数を 上下にスケールすると、グラフを水平方向に伸ばしたり押し込んだりすることができ、狭い鐘形 曲線やより広い鐘形曲線を記述することができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "そして、ここで簡単に指摘しておきたい のは、べき乗のルールに基づいて、定数 c を微調整するときに、それを単純にべき乗の 底を変更するものと考えることもできるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "その意味で、数値 e は私たちの式 にとってそれほど特別なものではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "これを他の正の定数に置き換えることもでき、 その定数を微調整すると、同じ一連の曲線が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "2 つの同じファミリーの曲線に します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "これを 3 つの同じファミリーのカーブにします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "e を使用する理由は、定数に非常に読みやすい 意味を与えるためです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "というか、指数が x の 2 分の 1 を負の 数で割った値を特定の定数で割ったものになるように少し再構成する と、これを確率分布に変換すると、その定数 sigma は次のよ うになります。その分布の標準偏差になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "それはとてもいいことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "ただ し、これを確率分布として解釈する前に、曲線の下の面積が 1 である必要がありま す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "その理由は、曲線がどのように解釈されるかにあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "離散分布とは異なり、 連続的なものに関しては、特定の点の確率については尋ねません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "代わりに、値が 2 つの異なる値の間に入る確率を求めます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "そして、曲線 が示しているのは、その確率がこれら 2 つの値の間の曲線の下の面積に等しいということで す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "これについては別のビデオがあり、確率密度関数と呼ばれています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "ここでの重要な点は、曲線全体の下の領域が何かが起こる確率、つまり何らかの数字が現れ る確率を表しているということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "これは 1 である必要があるため、この下の領域を 1 にし たいのです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "e の負の x の 2 乗に対する基本的な釣鐘曲線の形状をそのままにすると、面積は 1 ではなく、実際には pi の平方根になります。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "私は当然知っている？ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "パイはここで何をしているのですか？ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "これは サークルと何の関係があるのでしょうか？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "最初に言ったように、次のビデオでそれについてすべて話したいと思 います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "しかし、今の目的のために興奮するのを許していただければ、それが意味するのは、 この関数を pi の平方根で割れば、必要な面積が得られるということだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "先ほどの 定数である 1/2 とシグマを元に戻すと、その効果は 2 の平方根のシ グマ倍でグラフを引き伸ばすことになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "したがって、面積が 1 であることを確 認するために、それで割る必要もあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "これらの分数を組み合わせると、前にある係数は、1 をシグ マで割って 2 円周率の平方根を掛けたもののようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "結局のところ、これは有効な確率 分布です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "その値シグマを微調整して曲線を狭くしたり広くしたりすると、前面の定数に よって常に面積が 1 に等しいことが保証されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "シグマが 1 に等しい特殊なケー スには特定の名前があり、それを標準正規分布と呼びます。これは、このレッスンであなた と私にとって特に重要な役割を果たします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "そして、考えられるすべての正規分布は、こ の値 sigma でパラメータ化されるだけでなく、変数 x から別の定数 mu を減算します。これにより、基本的にグラフを左右にスライドさせて、この分布の平 均を規定できるようになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "つまり、2 つのパラメーターがあり、1 つは平均を表 し、もう 1 つは標準偏差を表し、これらはすべて、e と pi を含むこの大きな式で結 び付けられています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "以上のことがすべてわかったので、いくつかの確率変数から始めて、そ の変数の合計の分布がどのようになるかを尋ねるというアイデアをもう一度振り返ってみま しょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "すでに説明したように、合計のサイズを大きくすると、結果の 分布は平均の増加に応じてシフトし、標準偏差の増加に応じてゆっく りと広がります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "実際の数式をいくつか当てはめると、基礎となる確率変数の平 均がわかっていてそれを mu と呼び、その標準偏差もわかっていてそれをシグマ と呼ぶ場合、一番下の合計の平均は mu になります。は合計のサイズに乗算され 、標準偏差はそのサイズの平方根のシグマ倍になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "さて、これがますます釣鐘曲 線のように見え、釣鐘曲線は平均と標準偏差という 2 つの異なるパラメーターによっての み記述されると主張したい場合、どうすればよいかはわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "これら 2 つ の値を式に代入すると、分布に厳密に適合する曲線の、や や複雑ではあるものの、非常に明示的な式が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "しかし、もう少しエレガントで、構築できる非常に楽しいビジュアルに適し た別の表現方法があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "これらすべての確率変数の合計に焦点を当てる代 わりに、この式を少し変更してみましょう。ここで行うことは、その合計が取る と予想される平均を調べ、それを減算して次のようにします。新しい式の平均 は 0 です。次に、合計に期待される標準偏差を調べて、それで割ります。こ れは基本的に、式の標準偏差が 1 になるように単位を再スケールするだけで す。。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "これは複雑な表現のように見えるかもしれませんが、実際には非常に読みやすい 意味を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "これは本質的に、この合計が平均からどれだけ標準偏差離れているかを示しているという ことです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "たとえば、このバーは、10 個のサイコロを振ってそれらをすべて合計した ときに見つかる可能性のある特定の値に対応しており、マイナス 1 より少し上の位 置は、その値が 1 標準偏差より少し小さいことを示しています。平均よりも低い。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "また、ところで、ここまで構築しようとしているアニメーションを見越して、下のプロッ トで物事を表現する方法は、これらのバーのそれぞれの面積が対応する値の確率を示して いるということです。身長というよりも。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "y 軸は確率ではなく、一種の確率密度 を表すと考えることもできます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "この理由は、連続分布を解釈する方法 と一致するように段階を設定するためです。値の範囲内に入る確率は 、それらの値の間の曲線の下の面積に等しくなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "特に、すべて のバーを合わせた面積は 1 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "さて、ここまでがすべて整ったので、少し楽しんでみ ましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "まず、3 つの確率変数のみを加算するなど、下部の分布が比較的小さ な合計を表すように、物事をロールバックしてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "最初のディストリビューシ ョンを変更すると何が起こるかに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "それが変化するにつれて、底部の分布はその形を完 全に変えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "それは私たちが何を始めたかに大きく依存します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "合計のサイズを少し大きくして、 たとえば 10 まで増やすと、x の分布を変更しても、ほとんど釣鐘曲線のよ うに見えますが、形状を変えるいくつかの分布を見つけることができます。。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "たとえ ば、ほぼすべての確率が 1 または 6 の数字に含まれる非常に偏ったものでは、この種のとがった ベル カーブが生成されます。覚えておいていただけると思いますが、以前にこれをシミュレーションの形 で実際に示しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "したがって、そのスパイクがランダム性によるアーチファクトなのか、それとも真の 分布を反映しているのか疑問に思っていたとしたら、それは真の分布を反映していることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "この場合、10 は中心極限定理が適用されるのに十分な合計ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "しかし、代わり にその合計が大きくなるようにし、実際にはそれほど大きくない 50 個の異なる値を 追加することを検討すると、基礎となる確率変数の分布をどのように変更しても、基本的 にプロットの形状には影響しません。底。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "どこから始めても、x の分布に関するすべての 情報とニュアンスは洗い流されてしまい、標準正規分布の非常に洗練された関数 (1 の 2 π の平方根に e を掛けたもの) によって記述されるこの単一の普遍的な形状に向かう傾 向があります。2 の負の x の二乗。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "これが中心極限定理の正 体です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "この初期分布に対してできることはほとんど何もなく、傾向を変えること はできません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "さて、理論に興味のある方は、実際の定理とは何なのか、まだ疑問に思っ ているかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "たとえば、私たちがここで主張している、証明または反証できる数学的ステートメントは何ですか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "きちんとした正式なステートメントが必要な場合は、次のようになります。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "この値を考えてみましょう。確率変数の n 個の異なるインスタンス化を合計していますが、平均と標準偏差が 1 になるように微調整および調整されています。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "繰り返しますが、これは、合 計が平均値からどれだけ標準偏差離れているかを尋ねるものであると解釈できます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "次に、中心極限 定理の実際の厳密な冗談ではないステートメントは、この値が与えられた 2 つの実数 a と b の間に収まる確率を考慮し、その確率の限界を次のサイ ズとみなした場合です。合計が無限大になると、その限界は特定の積分に等しくな ります。これは基本的に、これら 2 つの値の間の標準正規分布に基づく面積 を表します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "もう一度言いますが、まだお話ししていない 3 つの基礎的な仮定があ ります。しかし、それら以外に、その詳細をすべて含めると、これが中心極限定理です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "これらはすべて少し理論的なものなので、物事を現実に戻し、最初に述べた具体 的な例に戻ってみるのが役立つかもしれません。サイコロを 100 回振って 、それが公正なサイコロであると想定してみましょう。この例では、結果を合計 します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "あなたにとっての課題は、合計がこの範囲内に収まることが 95% 確実であ るような値の範囲を見つけることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "このような質問に対しては、正規分布に関する便利な経験則 があります。それは、値の約 68% が平均値の 1 標準偏差以内に収まり、値の 95% は平均値の 1 標準偏差以内に収まる、つまり、私たちが重視している値は 1 標準偏差以内に収まるということ です。平均の標準偏差は 2 つで、なんと 99 です。値の 7% は、平均値の 3 標準 偏差以内に収まります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "これは、確率や統計を頻繁に扱う人がよく覚 えている経験則です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "当然のことながら、これでこの例に必要なものが得られ ます。次に、これがどのようになるかを図に示します。上部に公正なダイアップの分布 と、合計 100 の分布を示します。底にはそのようなサイコロがあり、ご存知の とおり、これは特定の正規分布のように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "このような問題のステップ 1 は、初 期分布の平均を求めることです。この場合、平均値は 1 の 6 倍 1 と 1 の 6 倍 2 を延々と繰り返すと、結果は 3 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "5.また、標準偏差も必要です。これ には分散を計算する必要があります。ご存知のとおり、分散には値と平均の差のす べての二乗を加算する必要があり、結果は 2 になります。92、その平方根は 1になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "71.必要な数字はこれら 2 つだけです。最下位の分布を完全に理解す るために必要な数字が 2 つだけであることがどれほど魔法であるかをもう一度考 えてもらいたいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "その平均はムーの 100 倍、つまり 350 になり、標準偏差は シグマの 100 倍の平方根になるため、シグマの 10 倍は 17 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "1.便利な経験則 を思い出して、平均から 2 標準偏差離れた値を探します。平均から 2 シグマを引くと約 316 になり、2 シグマを加えると 3 84 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "これで答えが得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "さて、すぐに話を終えると約束しましたが、この例を取り上げている間に、時間をかけてじっくり考える 価値のある疑問がもう 1 つあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "単に 100 個のサイコロの出目の合計について尋ねるの ではなく、その数値を 100 で割ってもらったとします。これは基本的に、下の図のすべての数値が 100 で割られることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "このことが何を言っているのか、少し時間をとって解釈してくださ い。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "この式は基本的に、100 個の異なるサイコロの目の経験的平均を示します。そして 、私たちが見つけたその間隔は、その経験的平均がどの範囲であると予想されるかを示しま す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "つまり、3 程度になると予想できます。5、これはサイコロの目の期待値です が、あまり明らかではなく、中心極限定理によって計算できるのは、その期待値にどれだけ 近い値を合理的に見つけることができるかということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "特に、この経験的平均の標 準偏差がどの程度であるか、そしてサイコロの目のより大きなサンプルを 観察すると標準偏差に何が起こるのかを少し考えてみる価値はあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "最後に、おそらく最も重要なことですが、この定理に含まれる仮定について話しましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "1 つ目は、合計するこれらの変数はすべて互いに独立しているということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "1 つのプロセスの結果は、他のプロセスの結果に影響を与えません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "2 つ目は、これらの変数がすべて同じ分布から抽出されていることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "これらは両方とも、サイコロの例では暗黙的に想定されています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "私たちは、各サイコロの出目 を他のすべてのサイコロの出目から独立したものとして扱い、各サイコロが同じ分 布に従うと仮定しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "文献では、これら 2 つの仮定が独立および同一分 散の頭文字 IID としてまとめられているのを目にすることがあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "これらの仮定が明らかに正しくない状況の 1 つは、ゴルトン委員会です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "つまり、考えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "ボールがペグの 1 つで跳ね返る方法は、次のペグで跳ね返る方法とは独立しているということでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "絶対違う。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "最後のバウンド次第で全く違う軌道で入ってきます。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "そして、各ペグから得られる可能性のある結果の分布は、ヒットした各ペグで同じになるのでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "繰り返しますが、ほぼ間違いなくそうではありません。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "おそらく、左に向かって 1 つのペグにぶつかります。つまり、結果がその方向に大きく偏り、その後、右にちらっと見て次のペグにぶつかる可能性があります。 ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "冒頭の例でこれらすべての単純化した仮定を立てたのは、単に考えやすくするためで はありませんでした。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "また、これが実際に中心極限定理の例となるためには、これらの仮 定が必要だったということでもあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "それにもかかわらず、実際の Galton ボー ドでは、これらの両方に違反しているにもかかわらず、ある種の正規分布が生じるのは事実のようで す。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "理由の 1 つは、このビデオの範囲を超えて、これらの仮定、特に 2 番 目の仮定を緩和する定理の一般化があることかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "しかし、実際にそ うする正当な理由がない場合でも、多くの場合、人々は変数が正規分布していると仮定し ているようだという事実に注意していただきたいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "3 番目の仮定は実際に はかなり微妙です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "それは、これらの変数について計算してきた分散が有限であるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "サイコロの例では、考えられる出目は 6 つしかなかったため、これは決して問題になりませんでした。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "しかし、結果のセットが無限である特定の状況では、分散を計算しようとする と、合計が無限大に発散してしまいます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "これらは完全に有効な確率分布であ る可能性があり、実際に発生します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "しかし、そのような状況では、その変数のさ まざまなインスタンスを追加してその合計を無限大に近づけることを検討すると、たと え最初の 2 つの仮定が当てはまったとしても、傾向が実際には正規分布ではない 可能性が非常に高くなります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "ここまでの内容をすべて理解していれば、中心極限定理が 何であるかについての非常に強力な基礎ができたことになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "次に、この特定 の関数がなぜ私たちが好む傾向にあるのか、なぜ円周率が含まれてい るのか、円とどのような関係があるのかを説明したいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]