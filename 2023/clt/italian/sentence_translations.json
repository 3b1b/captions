[
 {
  "input": "This is a Galton board. ",
  "translatedText": "Questa è una tavola Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "Forse ne hai già visto uno, è una dimostrazione popolare di come, anche quando un singolo evento è caotico e casuale, con un risultato effettivamente inconoscibile, è ancora possibile fare affermazioni precise su un gran numero di eventi, vale a dire come le proporzioni relative poiché molti risultati diversi sono distribuiti. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "Più specificamente, la tavola di Galton illustra una delle distribuzioni più importanti di tutta la probabilità, nota come distribuzione normale, più colloquialmente nota come curva a campana e chiamata anche distribuzione gaussiana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "C'è una funzione molto specifica per descrivere questa distribuzione, è molto carina, ne parleremo più avanti, ma per ora voglio solo sottolineare come la distribuzione normale sia, come suggerisce il nome, molto comune, si presenta molto di contesti apparentemente non correlati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "Se dovessi prendere un gran numero di persone che siedono in un gruppo demografico simile e tracciare le loro altezze, tali altezze tenderebbero a seguire una distribuzione normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "Se osservi un’ampia fascia di numeri naturali molto grandi e chiedi quanti fattori primi distinti ha ciascuno di questi numeri, le risposte seguiranno molto da vicino una certa distribuzione normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "Ora, il nostro argomento di oggi è uno dei fiori all'occhiello di tutta la teoria della probabilità, è uno dei fatti chiave che spiega perché questa distribuzione è così comune, conosciuta come teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "Questa lezione ha lo scopo di tornare alle basi, fornendoti i fondamenti su cosa dice il teorema del limite centrale, cosa sono le distribuzioni normali e voglio assumere un background minimo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "Lo approfondiremo, ma dopo vorrei approfondire ancora e spiegare perché il teorema è vero, perché la funzione alla base della distribuzione normale ha la forma molto specifica che ha, perché quella formula ha un pi greco e, cosa più divertente, perché questi ultimi due fatti sono in realtà più correlati di quanto suggerirebbero molte spiegazioni tradizionali. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "La seconda lezione vuole anche essere il seguito del video sulle circonvoluzioni che avevo promesso, quindi qui ci sono molti argomenti correlati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "Ma adesso, tornando ai fondamenti, vorrei iniziare con un modello eccessivamente semplificato della tavola Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "In questo modello assumeremo che ogni pallina cada direttamente su un certo picchetto centrale e che abbia una probabilità 50-50 di rimbalzare a sinistra o a destra, e penseremo a ciascuno di questi risultati come se aggiungesse uno o sottraendo uno dalla sua posizione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "Una volta scelto uno di questi, presupponiamo, altamente irrealistico, che atterri esattamente al centro del piolo adiacente sotto di esso, dove ancora una volta si troverà di fronte alla stessa scelta 50-50 di rimbalzare a sinistra o A destra. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "Per quello che sto mostrando sullo schermo, ci sono cinque diverse file di picchetti, quindi la nostra pallina saltellante fa cinque diverse scelte casuali tra più uno e meno uno, e possiamo pensare alla sua posizione finale come se fosse sostanzialmente la somma di tutti di questi diversi numeri, che in questo caso è uno, e potremmo etichettare tutti i diversi contenitori con la somma che rappresentano. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "Mentre lo ripetiamo, osserviamo diverse possibili somme per questi cinque numeri casuali. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "E per quelli di voi che sono propensi a lamentarsi del fatto che questo è un modello altamente irrealistico per la vera tavola Galton, lasciatemi sottolineare che l'obiettivo in questo momento non è modellare accuratamente la fisica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "L'obiettivo è fornire un semplice esempio per illustrare il teorema del limite centrale e, per quanto idealizzato possa essere, in realtà ci fornisce un ottimo esempio. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "Se lasciamo cadere molte palline diverse, assumendo ancora un'altra ipotesi irrealistica che non si influenzino a vicenda come se fossero tutte fantasmi, allora il numero di palline che cadono in ciascun contenitore diverso ci dà un'idea approssimativa della probabilità che ciascuna di esse cada. di quei secchi è. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "In questo esempio, i numeri sono abbastanza semplici da non essere troppo difficile calcolare esplicitamente qual è la probabilità di cadere in ciascun segmento. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "Se ci pensate bene, troverete che ricorda molto il triangolo di Pascal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "Ma la cosa bella del nostro teorema è quanto va oltre i semplici esempi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "Quindi, almeno per cominciare, invece di fare calcoli espliciti, simuliamo semplicemente le cose eseguendo un gran numero di campioni e lasciando che il numero totale di risultati in ogni risultato diverso ci dia un'idea di come appare quella distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "Come ho detto, quella sullo schermo ha cinque righe, quindi ogni somma che stiamo considerando comprende solo cinque numeri. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "L'idea di base del teorema del limite centrale è che se aumenti la dimensione di quella somma, per esempio in questo caso, ciò significherebbe aumentare il numero di file di pioli su cui ciascuna pallina rimbalza, quindi la distribuzione che descrive dove andrà a finire quella somma l’autunno assomiglia sempre più ad una curva a campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "Ecco, in realtà vale la pena prendersi un momento per scrivere quell'idea generale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "La situazione è che abbiamo una variabile casuale, e questa è fondamentalmente una scorciatoia per un processo casuale in cui ogni risultato di quel processo è associato a un certo numero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "Chiameremo quel numero casuale x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "Ad esempio, ogni rimbalzo dal piolo è un processo casuale modellato con due risultati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "Tali risultati sono associati ai numeri uno negativo e uno positivo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "Un altro esempio di variabile casuale sarebbe il lancio di un dado, in cui si hanno sei risultati diversi, ciascuno associato a un numero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "Quello che stiamo facendo è prendere più campioni diversi di quella variabile e sommarli tutti insieme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "Sulla nostra tavola Galton, sembra che la pallina rimbalzi su più picchetti diversi nel suo percorso verso il fondo e, nel caso di un dado, potresti immaginare di lanciare molti dadi diversi e sommare i risultati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "L’affermazione del teorema del limite centrale è che man mano che si lascia che la dimensione di quella somma diventi sempre più grande, allora la distribuzione di quella somma, la probabilità che ricada in diversi valori possibili, assomiglierà sempre più a una curva a campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "Questo è tutto, questa è l'idea generale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "Nel corso di questa lezione, il nostro compito sarà rendere questa affermazione più quantitativa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "Ci inseriremo alcuni numeri, inseriremo alcune formule, mostreremo come usarlo per fare previsioni. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "Ad esempio, ecco il tipo di domanda a cui voglio che tu possa rispondere entro la fine di questo video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "Supponiamo di aver lanciato il dado 100 volte e di aver sommato i risultati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "Potresti trovare un intervallo di valori tale da essere sicuro al 95% che la somma rientrerà in tale intervallo? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "O forse dovrei dire di trovare l'intervallo di valori più piccolo possibile in modo che ciò sia vero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "La cosa bella è che sarai in grado di rispondere a questa domanda se si tratta di un dado equilibrato o se è un dado ponderato. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "Ora lasciatemi dire all'inizio che questo teorema contiene tre diverse ipotesi, tre cose che devono essere vere prima che il teorema venga seguito. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "E in realtà non ti dirò cosa sono fino alla fine del video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "Voglio invece che tu tenga gli occhi aperti e vedi se riesci a notare e magari prevedere quali saranno questi tre presupposti. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "Come passo successivo, per illustrare meglio quanto sia generale questo teorema, voglio eseguire per te un altro paio di simulazioni incentrate sull'esempio dei dadi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "Di solito se si pensa di lanciare un dado si pensa che i sei risultati siano ugualmente probabili, ma al teorema in realtà questo non interessa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "Potremmo iniziare con un dado ponderato, qualcosa con una distribuzione non banale tra i risultati, e l’idea centrale rimane valida. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "Per la simulazione quello che farò è prendere una distribuzione come questa che è sbilanciata verso valori più bassi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "Prenderò 10 campioni distinti da quella distribuzione e poi registrerò la somma di quel campione sul grafico in basso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "Poi lo farò molte volte diverse, sempre con una somma pari a 10, ma tengo traccia di dove sono finite quelle somme per darci un'idea della distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "E infatti permettetemi di ridimensionare la direzione y per darci spazio per analizzare un numero ancora maggiore di campioni. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "E lo lascerò arrivare fino a un paio di migliaia, e mentre lo fa noterai che la forma che inizia ad emergere sembra una curva a campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "Forse se strizzi gli occhi puoi vedere che si inclina leggermente a sinistra, ma è bello che qualcosa di così simmetrico sia emerso da un punto di partenza che era così asimmetrico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "Per illustrare meglio in cosa consiste il teorema del limite centrale, lasciatemi eseguire quattro di queste simulazioni in parallelo, dove in alto a sinistra lo sto facendo aggiungendo solo due dadi alla volta, in alto a destra &quot; Se lo facciamo aggiungendo cinque dadi alla volta, quello in basso a sinistra è quello che abbiamo appena visto aggiungere 10 dadi alla volta, e poi ne faremo un altro con una somma maggiore, 15 alla volta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "Nota come in alto a sinistra, quando aggiungiamo solo due dadi, la distribuzione risultante non assomiglia davvero a una curva a campana, ricorda molto di più quella inclinata verso sinistra con cui abbiamo iniziato. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "Ma poiché teniamo conto di un numero sempre maggiore di dadi in ciascuna somma, la forma risultante che emerge in queste distribuzioni appare sempre più simmetrica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "Ha la protuberanza al centro e sfuma verso la coda a forma di campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "E vorrei sottolinearlo ancora, puoi iniziare con qualsiasi distribuzione diversa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "Qui lo eseguirò di nuovo, ma dove la maggior parte della probabilità è legata ai numeri 1 e 6, con una probabilità molto bassa per i valori medi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "Nonostante sia cambiata completamente la distribuzione per un singolo lancio di dado, accade comunque che emerga una forma a campana quando consideriamo le diverse somme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "Illustrare le cose con una simulazione come questa è molto divertente, ed è abbastanza carino vedere l'ordine emergere dal caos, ma sembra anche un po' impreciso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "Come in questo caso, quando ho interrotto la simulazione a 3000 campioni, anche se sembra una curva a campana, i diversi contenitori sembrano piuttosto appuntiti. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "E potresti chiederti, dovrebbe apparire in quel modo o è solo un artefatto della casualità nella simulazione? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "E se lo è, di quanti campioni abbiamo bisogno prima di poter essere sicuri che ciò che stiamo osservando sia rappresentativo della distribuzione reale? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "Andando invece avanti, diventiamo un po' più teorici e mostriamo la forma precisa che queste distribuzioni assumeranno nel lungo periodo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "Il caso più semplice per effettuare questo calcolo è se abbiamo una distribuzione uniforme, dove ogni possibile faccia del dado ha la stessa probabilità, 1 6°. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "Ad esempio, se poi vuoi sapere quanto sono probabili somme diverse per una coppia di dadi, è essenzialmente un gioco di conteggio, in cui conti quante coppie distinte danno la stessa somma, che nel diagramma che ho disegnato, tu può comodamente pensare esaminando tutte le diverse diagonali. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "Poiché ciascuna di queste coppie ha la stessa probabilità di apparire, 1 su 36, tutto ciò che devi fare è contare le dimensioni di questi contenitori. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "Questo ci dà una forma definitiva per la distribuzione che descrive la somma di due dadi, e se dovessimo giocare allo stesso gioco con tutte le possibili triplette, la distribuzione risultante sarebbe simile a questa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "Ora, ciò che è più impegnativo, ma molto più interessante, è chiedersi cosa succede se abbiamo una distribuzione non uniforme per quel singolo dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "In realtà ne abbiamo parlato proprio nell'ultimo video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "Fai essenzialmente la stessa cosa, esamini tutte le coppie distinte di dadi che si sommano allo stesso valore. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "È solo che invece di contare quelle coppie, per ciascuna coppia moltiplichi le due probabilità che ogni particolare faccia esca, e poi le sommi tutte insieme. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "Il calcolo che fa questo per tutte le somme possibili ha un nome di fantasia, si chiama convoluzione, ma essenzialmente è solo la versione ponderata del gioco di conteggio che chiunque abbia giocato con una coppia di dadi trova già familiare. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "Per i nostri scopi in questa lezione, farò calcolare tutto al computer, mostrerò semplicemente i risultati e ti inviterò a osservare determinati schemi, ma dietro il cofano, questo è ciò che sta succedendo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "Quindi, giusto per essere chiari su ciò che viene rappresentato qui, se immagini di campionare due valori diversi da quella distribuzione superiore, quella che descrive un singolo dado, e di sommarli insieme, allora la seconda distribuzione che sto disegnando rappresenta la probabilità che tu lo faccia vedere varie somme diverse. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "Allo stesso modo, se immagini di campionare tre valori distinti da quella distribuzione superiore e di sommarli insieme, il grafico successivo rappresenta le probabilità per varie somme diverse in quel caso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "Quindi se calcolo come appaiono le distribuzioni di queste somme per somme sempre più grandi, beh sai cosa dirò, assomiglia sempre di più ad una curva a campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "Ma prima di arrivare a questo, voglio che tu faccia ancora un paio di semplici osservazioni. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "Ad esempio, queste distribuzioni sembrano spostarsi verso destra, e sembrano anche diventare più diffuse e un po' più piatte. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "Non è possibile descrivere quantitativamente il teorema del limite centrale senza tenere conto di entrambi questi effetti, il che a sua volta richiede la descrizione della media e della deviazione standard. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "Forse li hai già familiari, ma qui voglio fare delle ipotesi minime e non fa mai male ripassarle, quindi esaminiamole rapidamente entrambe. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "La media di una distribuzione, spesso indicata con la lettera greca mu, è un modo per catturare il centro di massa di quella distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "Viene calcolato come il valore atteso della nostra variabile casuale, che è un modo per dire che si esaminano tutti i diversi risultati possibili e si moltiplica la probabilità di quel risultato per il valore della variabile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "Se valori più alti sono più probabili, la somma ponderata sarà maggiore. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "Se i valori più bassi sono più probabili, la somma ponderata sarà inferiore. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "Un po' più interessante è se vuoi misurare quanto è estesa questa distribuzione, perché ci sono molti modi diversi per farlo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "Uno di questi è chiamato varianza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "L'idea è quella di guardare la differenza tra ogni possibile valore e la media, elevare al quadrato quella differenza e chiederne il valore atteso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "L'idea è che, indipendentemente dal fatto che il valore sia inferiore o superiore alla media, quando si eleva al quadrato la differenza, si ottiene un numero positivo e maggiore è la differenza, maggiore è il numero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "Elevandolo al quadrato in questo modo risulta che i calcoli sono molto più piacevoli che se facessimo qualcosa come un valore assoluto, ma lo svantaggio è che è difficile pensarla come una distanza nel nostro diagramma perché le unità sono sbagliate. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "Un po' come le unità qui sono unità quadrate, mentre una distanza nel nostro diagramma sarebbe una sorta di unità lineare. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "Quindi un altro modo per misurare lo spread è la cosiddetta deviazione standard, che è la radice quadrata di questo valore. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "Questa può essere interpretata molto più ragionevolmente come una distanza sul nostro diagramma, ed è comunemente indicata con la lettera greca sigma, quindi conosci m sia per media che per deviazione standard, ma entrambe in greco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "Ripensando alla nostra sequenza di distribuzioni, parliamo della media e della deviazione standard. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "Se chiamiamo mu la media della distribuzione iniziale, che per quella illustrata risulta essere 2.24, spero che non sia troppo sorprendente se ti dico che la media del successivo è 2 volte mu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "Cioè, lanci una coppia di dadi, vuoi conoscere il valore atteso della somma, che è il doppio del valore atteso per un singolo dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "Allo stesso modo, il valore atteso per la nostra somma di dimensione 3 è 3 volte mu, e così via. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "La media avanza costantemente verso destra, motivo per cui le nostre distribuzioni sembrano spostarsi in quella direzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "Un po’ più impegnativo, ma molto importante, è descrivere come cambia la deviazione standard. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "Il fatto chiave qui è che se hai due variabili casuali diverse, allora la varianza per la somma di quelle variabili è la stessa che si ottiene semplicemente sommando le due varianze originali. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "Questo è uno di quei fatti che puoi semplicemente calcolare quando scompatta tutte le definizioni. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "Ci sono un paio di belle intuizioni sul perché è vero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "Il mio piano provvisorio è quello di realizzare semplicemente una serie sulla probabilità e parlare di cose come le intuizioni alla base della varianza e dei suoi cugini lì. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "Ma adesso, la cosa principale che voglio che tu evidenzi è che è la varianza che aggiunge, non la deviazione standard che aggiunge. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "Quindi, criticamente, se dovessi prendere n diverse realizzazioni della stessa variabile casuale e chiedere come appare la somma, la varianza di quella somma è n volte la varianza della tua variabile originale, ovvero la deviazione standard, la radice quadrata di tutti questa è la radice quadrata di n volte la deviazione standard originale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "Ad esempio, tornando alla nostra sequenza di distribuzioni, se etichettiamo la deviazione standard di quella iniziale con sigma, la deviazione standard successiva sarà la radice quadrata di 2 volte sigma, e dopo apparirà come la radice quadrata di 3 volte sigma e così via. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "Questo, come ho detto, è molto importante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "Ciò significa che anche se le nostre distribuzioni si stanno diffondendo, non si stanno diffondendo così rapidamente, ma lo fanno solo in proporzione alla radice quadrata della dimensione della somma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "Mentre ci prepariamo a fare una descrizione più quantitativa del teorema del limite centrale, l'intuizione fondamentale che voglio che teniate in testa è che sostanzialmente riallineeremo tutte queste distribuzioni in modo che le loro medie si allineino insieme, e poi le ridimensioneremo in modo che tutte le deviazioni standard saranno uguali a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "E quando lo facciamo, la forma che ne risulta si avvicina sempre di più a una certa forma universale, descritta con una piccola ed elegante funzione che spiegheremo tra poco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "E lasciatemelo dire ancora una volta, la vera magia qui è come avremmo potuto iniziare con qualsiasi distribuzione, descrivendo un singolo lancio di dado, e se giocassimo allo stesso gioco, considerando come appaiono le distribuzioni per le molte somme diverse, e li riallineiamo in modo che le medie siano allineate, e li ridimensioniamo in modo che le deviazioni standard siano tutte 1, ci avviciniamo comunque alla stessa forma universale, il che è piuttosto sbalorditivo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "E ora, amici miei, è probabilmente il momento migliore per entrare finalmente nella formula di una distribuzione normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "E il modo in cui mi piacerebbe farlo è fondamentalmente rimuovere tutti gli strati e costruirli un pezzo alla volta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "La funzione e alla x, o qualsiasi cosa alla x, descrive la crescita esponenziale, e se rendi negativo l'esponente, che gira il grafico orizzontalmente, potresti pensare che descriva il decadimento esponenziale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "Per rendere questo decadimento in entrambe le direzioni, potresti fare qualcosa per assicurarti che l'esponente sia sempre negativo e crescente, come prendere il valore assoluto negativo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "Questo ci darebbe questo strano punto acuto nel mezzo, ma se invece rendiamo quell'esponente il quadrato negativo di x, otterremo una versione più morbida della stessa cosa, che decade in entrambe le direzioni. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "Questo ci dà la forma base della curva a campana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "Ora, se metti una costante davanti a quella x e la ridimensioni su e giù, puoi allungare e schiacciare il grafico orizzontalmente, permettendoti di descrivere curve a campana strette e più larghe. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "E una cosa veloce che vorrei sottolineare qui è che in base alle regole dell'elevamento a potenza, mentre modifichiamo la costante c, potresti anche pensarlo come un semplice cambiamento della base dell'elevamento a potenza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "E in questo senso il numero e non è poi così speciale per la nostra formula. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "Potremmo sostituirla con qualsiasi altra costante positiva, e otterrai la stessa famiglia di curve modificando quella costante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "Rendilo un 2, stessa famiglia di curve. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "Rendilo un 3, stessa famiglia di curve. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "Il motivo per cui usiamo e è che dà a quella costante un significato molto leggibile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "O meglio, se riconfiguriamo un po' le cose in modo che l'esponente appaia negativo una metà x diviso per una certa costante, che chiameremo suggestivamente sigma al quadrato, quindi una volta trasformato questo in una distribuzione di probabilità, quella costante sigma lo farà essere la deviazione standard di quella distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "E questo è molto bello. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "Ma prima di poterlo interpretare come una distribuzione di probabilità, abbiamo bisogno che l’area sotto la curva sia 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "E la ragione di ciò è il modo in cui viene interpretata la curva. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "A differenza delle distribuzioni discrete, quando si tratta di qualcosa di continuo, non ci si chiede quale sia la probabilità di un punto particolare. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "Chiedi invece la probabilità che un valore rientri tra due valori diversi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "E ciò che la curva ti dice è che quella probabilità è uguale all'area sotto la curva tra questi due valori. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "C'è un altro video a riguardo, si chiamano funzioni di densità di probabilità. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "Il punto principale in questo momento è che l'area sotto l'intera curva rappresenta la probabilità che succeda qualcosa, che esca qualche numero. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "Dovrebbe essere 1, motivo per cui vogliamo che l'area sottostante sia 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "Così com'è con la forma base della curva a campana di e alla negativa x al quadrato, l'area non è 1, in realtà è la radice quadrata di pi greco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "Infatti, NO? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "Cosa ci fa pi greco qui? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "Cosa c'entra questo con i cerchi? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "Come ho detto all'inizio, mi piacerebbe parlarne nel prossimo video. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "Ma se adesso puoi risparmiare la tua eccitazione per i nostri scopi, significa solo che dovremmo dividere questa funzione per la radice quadrata di pi greco, e otterremo l'area che vogliamo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "Ritornando alle costanti che avevamo prima, 1 metà e sigma, l'effetto è quello di allungare il grafico di un fattore sigma moltiplicato per la radice quadrata di 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "Quindi dobbiamo anche dividerlo per assicurarci che abbia un'area pari a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "E combinando queste frazioni, il fattore in primo piano sembra 1 diviso per sigma per la radice quadrata di 2 pi greco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "Questa, infine, è una distribuzione di probabilità valida. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "Quando modifichiamo il valore sigma, ottenendo curve più strette e più larghe, la costante nella parte anteriore garantisce sempre che l'area sia uguale a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "Il caso speciale in cui sigma è uguale a 1 ha un nome specifico, lo chiamiamo distribuzione normale standard, che gioca un ruolo particolarmente importante per te e per me in questa lezione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "E tutte le possibili distribuzioni normali non solo sono parametrizzate con questo valore sigma, ma sottraiamo anche un'altra costante mu dalla variabile x, e questo essenzialmente ti permette semplicemente di far scorrere il grafico a sinistra e a destra in modo da poter prescrivere la media di questa distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "Quindi, in breve, abbiamo due parametri, uno che descrive la media, l'altro che descrive la deviazione standard, e sono tutti legati insieme in questa grande formula che coinvolge una e e un pi greco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "Ora che tutto questo è sul tavolo, torniamo a considerare l'idea di iniziare con una variabile casuale e chiederci come appaiono le distribuzioni per le somme di quella variabile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "Come abbiamo già spiegato, quando aumenti la dimensione di quella somma, la distribuzione risultante si sposterà secondo una media crescente e si diffonderà lentamente secondo una deviazione standard crescente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "E inserendo alcune formule reali, se conosciamo la media della nostra variabile casuale sottostante, la chiamiamo mu, e conosciamo anche la sua deviazione standard, e la chiamiamo sigma, allora la media della somma in basso sarà mu volte la dimensione della somma e la deviazione standard sarà sigma per la radice quadrata di quella dimensione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "Quindi ora, se vogliamo affermare che questa assomiglia sempre di più a una curva a campana, e che una curva a campana è descritta solo da due parametri diversi, la media e la deviazione standard, sai cosa fare. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "Potresti inserire questi due valori nella formula e otterresti una formula altamente esplicita, anche se un po' complicata, per una curva che dovrebbe adattarsi perfettamente alla nostra distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "Ma c'è un altro modo in cui possiamo descriverlo, che è un po' più elegante e si presta a una grafica molto divertente su cui possiamo costruire. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "Invece di concentrarci sulla somma di tutte queste variabili casuali, modifichiamo un po' questa espressione, dove quello che faremo è guardare la media che ci aspettiamo che abbia quella somma, e sottrarla in modo che la nostra nuova espressione ha una media pari a 0, quindi esamineremo la deviazione standard che ci aspettiamo dalla nostra somma e la divideremo per quella, che in pratica ridimensiona semplicemente le unità in modo che la deviazione standard della nostra espressione sia uguale a 1 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "Potrebbe sembrare un'espressione più complicata, ma in realtà ha un significato altamente leggibile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "In sostanza dice a quante deviazioni standard dalla media c'è questa somma? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "Ad esempio, questa barra qui corrisponde a un certo valore che potresti trovare quando lanci 10 dadi e li sommi tutti, e la sua posizione leggermente sopra il negativo 1 ti dice che quel valore è leggermente inferiore a una deviazione standard inferiore alla media. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "Inoltre, in previsione dell'animazione che sto cercando di realizzare qui, il modo in cui rappresento le cose sul grafico inferiore è che l'area di ciascuna di queste barre ci dice la probabilità del valore corrispondente piuttosto che l'altezza. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "Potresti pensare che l'asse y non rappresenti la probabilità ma una sorta di densità di probabilità. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "La ragione di ciò è impostare il contesto in modo che si allinei al modo in cui interpretiamo le distribuzioni continue, dove la probabilità di cadere in un intervallo di valori è uguale a un'area sotto una curva tra tali valori. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "In particolare, l'area di tutte le barre insieme sarà 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "Ora, con tutto questo a posto, divertiamoci un po'. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "Vorrei iniziare riportando le cose indietro in modo che la distribuzione sul fondo rappresenti una somma relativamente piccola, come sommare insieme solo tre variabili casuali. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "Nota cosa succede quando cambio la distribuzione con cui iniziamo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "Man mano che cambia, la distribuzione sul fondo cambia completamente forma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "Dipende molto da cosa abbiamo iniziato. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "Se lasciamo che la dimensione della nostra somma diventi un po' più grande, diciamo fino a 10, e mentre cambio la distribuzione per x, rimane in gran parte simile a una curva a campana, ma posso trovare alcune distribuzioni che le fanno cambiare forma . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "Ad esempio, quella davvero asimmetrica in cui quasi tutta la probabilità è nei numeri 1 o 6 risulta in questo tipo di curva a campana appuntita e, se ricordi, in precedenza l'ho mostrata sotto forma di simulazione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "Quindi, se ti stavi chiedendo se quella spigolosità fosse un artefatto della casualità o riflettesse la vera distribuzione, risulta che riflette la vera distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "In questo caso, 10 non è una somma abbastanza grande da far entrare in vigore il teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "Ma se invece lascio crescere quella somma e prendo in considerazione l'aggiunta di 50 valori diversi, che in realtà non è così grande, allora non importa come cambio la distribuzione per la nostra variabile casuale sottostante, essenzialmente non ha alcun effetto sulla forma del grafico sul grafico. metter il fondo a. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "Non importa da dove iniziamo, tutte le informazioni e le sfumature relative alla distribuzione di x vengono spazzate via e tendiamo verso questa singola forma universale descritta da una funzione molto elegante per la distribuzione normale standard, 1 su radice quadrata di 2 pi greco per e al negativo x quadrato su 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "Questo, questo qui è lo scopo del teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "Quasi nulla che tu possa fare per questa distribuzione iniziale cambia la forma verso cui tendiamo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "Ora, quelli tra voi con una mentalità più teorica potrebbero ancora chiedersi: qual è il vero teorema? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "Ad esempio, qual è l'affermazione matematica che stiamo affermando qui che potrebbe essere dimostrata o confutata? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "Se vuoi una bella dichiarazione formale, ecco come potrebbe andare. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "Considera questo valore, dove stiamo sommando n diverse istanze della nostra variabile casuale, ma ottimizzate e ottimizzate in modo che la sua media e deviazione standard siano 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "Ancora una volta, il che significa che puoi leggerlo come se chiedessi quante deviazioni standard dalla media è la somma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "Quindi la vera affermazione rigorosa del teorema del limite centrale, questa volta senza scherzi, è che se si considera la probabilità che questo valore rientri tra due numeri reali dati, a e b, e si considera il limite di tale probabilità come la dimensione di la tua somma va all'infinito, quindi quel limite è uguale a un certo integrale, che sostanzialmente descrive l'area sotto una distribuzione normale standard tra questi due valori. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "Ancora una volta, ci sono tre presupposti di base che devo ancora dirvi, ma a parte questi, in tutti i suoi cruenti dettagli, questo qui è il teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "Tutto ciò è un po' teorico, quindi potrebbe essere utile riportare le cose sulla Terra e tornare all'esempio concreto che ho menzionato all'inizio, dove immagini di lanciare un dado 100 volte e supponiamo che sia un dado giusto per questo esempio e sommi i risultati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "La sfida per te è trovare un intervallo di valori tale da essere sicuro al 95% che la somma rientrerà in questo intervallo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "Per domande come questa, esiste una pratica regola pratica sulle distribuzioni normali, ovvero che circa il 68% dei tuoi valori cadrà entro una deviazione standard della media, il 95% dei tuoi valori, la cosa a cui teniamo, rientra due deviazioni standard della media e un enorme 99. Il 7% dei tuoi valori rientrerà entro tre deviazioni standard dalla media. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "È una regola pratica che viene comunemente memorizzata da persone che fanno molte probabilità e statistiche. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "Naturalmente, questo ci dà ciò di cui abbiamo bisogno per il nostro esempio, e lasciatemi andare avanti e disegnare come sarebbe, dove mostrerò la distribuzione per un dado equo in alto, e la distribuzione per una somma di 100 tali dadi sul fondo, che ormai come sai assomiglia ad una certa distribuzione normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "Il primo passo con un problema come questo è trovare la media della tua distribuzione iniziale, che in questo caso sarà come 1 sesto per 1 più 1 sesto per 2 e così via, e risulta essere 3.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "Abbiamo anche bisogno della deviazione standard, che richiede il calcolo della varianza, che come sai comporta la somma di tutti i quadrati delle differenze tra i valori e le medie, e risulta essere 2.92, la radice quadrata risulta essere 1.71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "Questi sono gli unici due numeri di cui abbiamo bisogno, e ti invito nuovamente a riflettere su quanto sia magico che questi siano gli unici due numeri di cui hai bisogno per comprendere completamente la distribuzione inferiore. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "La sua media sarà 100 volte mu, ovvero 350, e la sua deviazione standard sarà la radice quadrata di 100 volte sigma, quindi 10 volte sigma 17.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "Ricordando la nostra pratica regola empirica, stiamo cercando valori a due deviazioni standard dalla media, e quando sottrai 2 sigma dalla media ti ritrovi con circa 316, e quando aggiungi 2 sigma finisci con 384. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "Ed ecco qua, questo ci dà la risposta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "Ok, ho promesso di concludere le cose a breve, ma mentre siamo su questo esempio c'è un'altra domanda su cui vale la pena riflettere. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "Invece di chiederti semplicemente la somma di 100 lanci di dado, diciamo che ti ho fatto dividere quel numero per 100, il che significa sostanzialmente che tutti i numeri nel nostro diagramma in basso vengono divisi per 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "Prenditi un momento per interpretare cosa direbbe tutto questo allora. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "L'espressione essenzialmente ti dice la media empirica per 100 diversi tiri di dado, e l'intervallo che abbiamo trovato ora ti dice quale intervallo ti aspetti di vedere per quella media empirica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "In altre parole, potresti aspettarti che sia intorno ai 3.5, questo è il valore atteso per un lancio di dado, ma ciò che è molto meno ovvio e che il teorema del limite centrale ti consente di calcolare è quanto vicino a quel valore atteso ti troverai ragionevolmente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "In particolare, vale la pena dedicare del tempo a riflettere su quale sia la deviazione standard per questa media empirica e cosa le succede quando osservi un campione sempre più grande di tiri di dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "Infine, ma probabilmente la cosa più importante, parliamo delle ipotesi che rientrano in questo teorema. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "Il primo è che tutte queste variabili che stiamo sommando sono indipendenti l'una dall'altra. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "L'esito di un processo non influenza l'esito di nessun altro processo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "Il secondo è che tutte queste variabili provengono dalla stessa distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "Entrambi questi valori sono stati implicitamente assunti con il nostro esempio di dadi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "Abbiamo considerato il risultato di ogni lancio di dado come indipendente dal risultato di tutti gli altri e stiamo assumendo che ogni dado segua la stessa distribuzione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "A volte in letteratura si vedono queste due ipotesi raggruppate insieme sotto la sigla IID che significa indipendente e identicamente distribuito. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "Una situazione in cui queste ipotesi decisamente non sono vere sarebbe il consiglio di amministrazione di Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "Voglio dire, pensaci. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "È possibile che il modo in cui una pallina rimbalza su uno dei picchetti sia indipendente da come rimbalzerà sul picchetto successivo? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "Assolutamente no. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "A seconda dell'ultimo rimbalzo, arriverà con una traiettoria completamente diversa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "Ed è vero che la distribuzione dei possibili risultati di ciascun piolo è la stessa per ogni piolo che colpisce? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "Ancora una volta, quasi certamente no. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "Forse colpisce un piolo guardando a sinistra, il che significa che i risultati sono enormemente distorti in quella direzione, e poi colpisce quello successivo guardando a destra. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "Quando ho fatto tutte queste ipotesi semplificatrici nell'esempio di apertura, non è stato solo per rendere più semplice la riflessione. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "È anche che tali presupposti erano necessari affinché questo fosse effettivamente un esempio del teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "Tuttavia, sembra essere vero che per il vero consiglio di Galton, nonostante la violazione di entrambi, si ottiene una distribuzione normale? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "Parte del motivo potrebbe essere che ci sono generalizzazioni del teorema oltre lo scopo di questo video che allentano questi presupposti, specialmente il secondo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "Ma voglio metterti in guardia dal fatto che molte volte le persone sembrano presumere che una variabile sia distribuita normalmente, anche quando non c'è una reale giustificazione per farlo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "La terza ipotesi è in realtà piuttosto sottile. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "Il fatto è che la varianza che abbiamo calcolato per queste variabili è finita. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "Questo non è mai stato un problema per l’esempio dei dadi, perché c’erano solo sei possibili risultati. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "Ma in certe situazioni in cui si hanno una serie infinita di risultati, quando si calcola la varianza, la somma finisce per divergere all'infinito. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "Queste possono essere distribuzioni di probabilità perfettamente valide e si presentano nella pratica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "Ma in quelle situazioni, se consideri l'aggiunta di molte istanze diverse di quella variabile e lasci che la somma si avvicini all'infinito, anche se valgono i primi due presupposti, è molto probabile che ciò a cui tendi non sia effettivamente una distribuzione normale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "Se hai capito tutto fino a questo punto, ora hai delle basi molto solide su ciò che riguarda il teorema del limite centrale. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "E poi vorrei spiegare perché questa particolare funzione è ciò a cui tendiamo, e perché contiene un pi greco, cosa ha a che fare con i cerchi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]