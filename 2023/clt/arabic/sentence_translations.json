[
 {
  "input": "This is a Galton board. ",
  "translatedText": "هذه لوحة جالتون. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "ربما تكون قد رأيت واحدًا من قبل، إنه عرض شائع لكيفية أنه، حتى عندما يكون حدث واحد فوضويًا وعشوائيًا، مع نتيجة غير معروفة فعليًا، لا يزال من الممكن تقديم بيانات دقيقة حول عدد كبير من الأحداث، أي كيفية النسب النسبية للعديد من النتائج المختلفة يتم توزيعها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "وبشكل أكثر تحديدًا، توضح لوحة جالتون أحد أبرز التوزيعات في جميع الاحتمالات، والمعروف باسم التوزيع الطبيعي، والمعروف بالعامية باسم منحنى الجرس، ويسمى أيضًا التوزيع الغوسي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "هناك وظيفة محددة جدًا لوصف هذا التوزيع، إنها جميلة جدًا، وسنتناولها لاحقًا، لكن الآن أريد فقط التأكيد على كيف أن التوزيع الطبيعي، كما يوحي الاسم، شائع جدًا، ويظهر في الكثير من السياقات التي تبدو غير ذات صلة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "إذا كنت ستأخذ عددًا كبيرًا من الأشخاص الذين يجلسون في مجموعة سكانية مماثلة وترسم طولهم، فإن تلك الارتفاعات تميل إلى اتباع التوزيع الطبيعي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "إذا نظرت إلى مجموعة كبيرة من الأعداد الطبيعية الكبيرة جدًا وسألت عن عدد العوامل الأولية المميزة لكل واحد من هذه الأعداد، فإن الإجابات ستتبع بشكل وثيق توزيعًا طبيعيًا معينًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "الآن موضوعنا لهذا اليوم هو أحد جواهر التاج في نظرية الاحتمالات كلها، إنها إحدى الحقائق الأساسية التي تشرح سبب شيوع هذا التوزيع كما هو، والمعروف باسم نظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "يهدف هذا الدرس إلى العودة إلى الأساسيات، مما يوفر لك الأساسيات حول ما تقوله نظرية الحد المركزي، وما هي التوزيعات الطبيعية، وأريد أن أفترض الحد الأدنى من الخلفية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "سنتعمق في الأمر بشكل لائق، ولكن بعد ذلك ما زلت أرغب في التعمق أكثر وشرح سبب صحة النظرية، ولماذا تتمتع الدالة التي يقوم عليها التوزيع الطبيعي بالشكل المحدد للغاية، ولماذا تحتوي هذه الصيغة على هناك نقطة في ذلك، والأكثر متعة، لماذا ترتبط هاتان الحقيقتان الأخيرتان في الواقع أكثر مما قد توحي به الكثير من التفسيرات التقليدية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "يهدف هذا الدرس الثاني أيضًا إلى أن يكون متابعة لفيديو التوليفات الذي وعدت به، لذلك هناك الكثير من المواضيع المترابطة هنا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "لكن الآن، بالعودة إلى الأساسيات، أود أن أبدأ الأمور بنموذج مبسط للغاية للوحة جالتون. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "في هذا النموذج، سنفترض أن كل كرة تسقط مباشرة على وتد مركزي معين وأن احتمال ارتدادها إلى اليسار أو اليمين هو 50-50، وسنفكر في كل من هذه النتائج على أنها إما إضافة واحدة أو اخراج واحد من مكانه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "بمجرد اختيار واحد من هؤلاء، فإننا نفترض افتراضًا غير واقعي إلى حد كبير أنه حدث أن هبط ميتًا في منتصف الوتد المجاور أسفله، حيث سيواجه مرة أخرى نفس الاختيار بنسبة 50-50 للارتداد إلى اليسار أو إلى اليمين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "بالنسبة للكرة التي أعرضها على الشاشة، هناك خمسة صفوف مختلفة من الأوتاد، لذا فإن كرة القفز الصغيرة لدينا تقوم بخمسة اختيارات عشوائية مختلفة بين زائد واحد وسالب واحد، ويمكننا التفكير في موضعها النهائي باعتباره مجموع الكل من هذه الأرقام المختلفة، والتي في هذه الحالة هي رقم واحد، ويمكننا تسمية جميع المجموعات المختلفة بالمجموع الذي تمثله. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "بينما نكرر ذلك، فإننا ننظر إلى مجاميع مختلفة محتملة لهذه الأرقام العشوائية الخمسة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "ولأولئك الذين يميلون إلى الشكوى من أن هذا نموذج غير واقعي إلى حد كبير للوحة جالتون الحقيقية، اسمحوا لي أن أؤكد على أن الهدف الآن ليس صياغة نماذج فيزيائية دقيقة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "الهدف هو إعطاء مثال بسيط لتوضيح نظرية النهاية المركزية، وعلى الرغم من أن هذا قد يكون مثاليًا، إلا أنه في الواقع يعطينا مثالًا جيدًا حقًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "إذا تركنا العديد من الكرات المختلفة تسقط، مع افتراض آخر غير واقعي مفاده أنها لا تؤثر على بعضها البعض كما لو كانت جميعها أشباح، فإن عدد الكرات التي تسقط في كل دلو مختلف يعطينا فكرة فضفاضة عن مدى احتمالية سقوط كل واحدة منها. من تلك الدلاء هو. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "في هذا المثال، الأرقام بسيطة بما يكفي بحيث لا يكون من الصعب جدًا حساب احتمالية الوقوع في كل مجموعة بشكل صريح. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "إذا كنت تريد التفكير في ذلك جيدًا، فستجد أنه يذكرنا جدًا بمثلث باسكال. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "لكن الشيء الرائع في نظريتنا هو مدى تجاوزها للأمثلة البسيطة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "لذا، لنبدأ على الأقل، بدلًا من إجراء حسابات صريحة، دعونا نحاكي الأشياء عن طريق تشغيل عدد كبير من العينات والسماح للعدد الإجمالي للنتائج في كل نتيجة مختلفة بأن يعطينا فكرة عن الشكل الذي يبدو عليه هذا التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "كما قلت، يحتوي الرقم الذي يظهر على الشاشة على خمسة صفوف، لذا فإن كل مجموع نفكر فيه يتضمن خمسة أرقام فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "الفكرة الأساسية لنظرية الحد المركزي هي أنه إذا قمت بزيادة حجم هذا المجموع، على سبيل المثال هنا، فهذا يعني زيادة عدد صفوف الأوتاد لكل كرة لترتد، ثم التوزيع الذي يصف أين سيذهب هذا المجموع يبدو الخريف أكثر فأكثر مثل منحنى الجرس. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "هنا، من المفيد أن نتوقف لحظة لتدوين تلك الفكرة العامة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "الإعداد هو أن لدينا متغير عشوائي، وهذا في الأساس اختصار لعملية عشوائية حيث ترتبط كل نتيجة لتلك العملية برقم ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "سوف نسمي هذا الرقم العشوائي x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "على سبيل المثال، كل ارتداد عن الربط هو عملية عشوائية تم تصميمها بنتيجتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "وترتبط هذه النتائج بالأرقام سالب واحد وموجب واحد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "مثال آخر للمتغير العشوائي هو رمي حجر النرد، حيث يكون لديك ست نتائج مختلفة، كل واحدة منها مرتبطة برقم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "ما نقوم به هو أخذ عدة عينات مختلفة من هذا المتغير وإضافتها جميعًا معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "على لوحة غالتون الخاصة بنا، يبدو ذلك مثل ترك الكرة ترتد عن عدة أوتاد مختلفة في طريقها إلى الأسفل، وفي حالة النرد، قد تتخيل رمي العديد من أحجار النرد المختلفة وجمع النتائج. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "ادعاء نظرية الحد المركزي هو أنه عندما تترك حجم هذا المجموع يكبر فأكبر، فإن توزيع هذا المجموع، ومدى احتمال وقوعه في قيم محتملة مختلفة، سيبدو أكثر فأكثر مثل منحنى الجرس. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "هذا كل شيء، هذه هي الفكرة العامة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "على مدار هذا الدرس، مهمتنا هي جعل هذه العبارة أكثر كمية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "سنقوم بإضافة بعض الأرقام إليها، وسنضع بعض الصيغ لها، ونوضح كيف يمكنك استخدامها لإجراء التنبؤات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "على سبيل المثال، إليك نوع السؤال الذي أريدك أن تكون قادرًا على الإجابة عليه بنهاية هذا الفيديو. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "لنفترض أنك رميت حجر النرد 100 مرة وقمت بجمع النتائج معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "هل يمكنك العثور على نطاق من القيم بحيث تكون متأكدًا بنسبة 95% من أن المجموع سيندرج ضمن هذا النطاق؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "أو ربما يجب أن أقول أوجد أصغر نطاق ممكن من القيم بحيث يكون هذا صحيحًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "الأمر الجيد هو أنك ستكون قادرًا على الإجابة على هذا السؤال سواء كان حجر نرد عادلًا أو حجر نرد مرجح. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "الآن اسمحوا لي أن أقول في الأعلى أن هذه النظرية تحتوي على ثلاثة افتراضات مختلفة، وهي ثلاثة أشياء يجب أن تكون صحيحة قبل أن تتبعها النظرية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "وفي الحقيقة لن أخبركم ما هي حتى نهاية الفيديو. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "بدلاً من ذلك، أريدك أن تراقب وترى ما إذا كان بإمكانك ملاحظة وربما التنبؤ بما ستكون عليه هذه الافتراضات الثلاثة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "كخطوة تالية، لتوضيح مدى عمومية هذه النظرية بشكل أفضل، أريد إجراء بعض عمليات المحاكاة الإضافية لك والتي تركز على مثال النرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "عادةً، إذا كنت تفكر في رمي حجر النرد، فإنك تعتقد أن النتائج الستة محتملة بنفس القدر، لكن النظرية في الواقع لا تهتم بذلك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "يمكننا أن نبدأ بنرد مرجح، وهو شيء ذو توزيع غير تافه عبر النتائج، والفكرة الأساسية لا تزال قائمة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "بالنسبة للمحاكاة، ما سأفعله هو أن أقوم بتوزيع مثل هذا والذي يميل نحو القيم الأقل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "سأقوم بأخذ 10 عينات مميزة من هذا التوزيع ثم سأسجل مجموع تلك العينة على المخطط في الأسفل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "ثم سأفعل ذلك عدة مرات مختلفة، دائمًا بمجموع مقداره 10، لكن تابع أين انتهت هذه المجاميع لتعطينا فكرة عن التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "وفي الواقع اسمحوا لي بإعادة قياس الاتجاه y لمنحنا مساحة لتشغيل عدد أكبر من العينات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "وسأترك الأمر يصل إلى بضعة آلاف، وبينما هو كذلك ستلاحظ أن الشكل الذي يبدأ في الظهور يشبه منحنى الجرس. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "ربما إذا أغمضت عينيك يمكنك أن ترى أنها تنحرف قليلاً إلى اليسار، لكن من الرائع أن شيئًا متماثلًا جدًا ظهر من نقطة بداية كانت غير متماثلة تمامًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "لتوضيح ما تدور حوله نظرية الحد المركزي بشكل أفضل، اسمحوا لي بإجراء أربع من عمليات المحاكاة هذه بالتوازي، حيث أقوم بذلك في الجزء العلوي الأيسر حيث نضيف فقط حجري نرد في المرة الواحدة، وفي الجزء العلوي الأيمن نقوم بذلك. إذا قمنا بذلك حيث نضيف خمسة أحجار نرد في كل مرة، فإن الجزء السفلي الأيسر هو الذي رأيناه للتو نضيف 10 أحجار نرد في المرة الواحدة، ثم سنفعل نردًا آخر بمبلغ أكبر، 15 في المرة الواحدة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "لاحظ كيف أنه في الجزء العلوي الأيسر عندما نضيف فقط حجري نرد، فإن التوزيع الناتج لا يبدو حقًا مثل منحنى الجرس، بل يبدو أكثر تذكيرًا بالمنحنى الذي بدأناه مع الانحراف نحو اليسار. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "ولكن عندما نسمح بوجود المزيد والمزيد من النرد في كل مجموع، فإن الشكل الناتج الذي يظهر في هذه التوزيعات يبدو أكثر تناسقًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "تحتوي على كتلة في المنتصف وتتلاشى باتجاه شكل منحنى الجرس الذيل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "واسمحوا لي أن أؤكد مرة أخرى، يمكنك البدء بأي توزيع مختلف. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "هنا سأقوم بتشغيله مرة أخرى، ولكن حيث أن معظم الاحتمالية مرتبطة بالرقمين 1 و6، مع احتمالية منخفضة جدًا للقيم المتوسطة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "على الرغم من التغيير الكامل للتوزيع لكل لفة فردية للنرد، إلا أنه لا يزال من الممكن أن يظهر شكل منحنى الجرس عندما نأخذ في الاعتبار المجاميع المختلفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "إن توضيح الأشياء بمحاكاة كهذه أمر ممتع للغاية، ومن الرائع رؤية النظام ينشأ من الفوضى، ولكنه يبدو أيضًا غير دقيق بعض الشيء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "كما في هذه الحالة، عندما قطعت المحاكاة عند 3000 عينة، على الرغم من أنها تبدو مثل منحنى الجرس، فإن الدلاء المختلفة تبدو شائكة جدًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "وقد تتساءل، هل من المفترض أن يبدو الأمر بهذه الطريقة، أم أن ذلك مجرد قطعة أثرية من العشوائية في المحاكاة؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "وإذا كان الأمر كذلك، فما عدد العينات التي نحتاجها قبل أن نتمكن من التأكد من أن ما ننظر إليه يمثل التوزيع الحقيقي؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "بدلًا من المضي قدمًا، دعونا نلقي نظرة نظرية أكثر قليلًا ونظهر الشكل الدقيق الذي ستتخذه هذه التوزيعات على المدى الطويل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "أسهل حالة لإجراء هذه العملية الحسابية هي إذا كان لدينا توزيع موحد، حيث يكون لكل وجه محتمل لحجر النرد احتمال متساوٍ، وهو 1 على 6. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "على سبيل المثال، إذا كنت تريد بعد ذلك معرفة مدى احتمال وجود مجاميع مختلفة لزوج من حجر النرد، فهي في الأساس لعبة عد، حيث تقوم بإحصاء عدد الأزواج المميزة التي تأخذ نفس المجموع، والذي في الرسم البياني الذي رسمته، عليك يمكن التفكير فيه بسهولة من خلال المرور عبر جميع الأقطار المختلفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "نظرًا لأن كل زوج لديه فرصة متساوية للظهور، 1 من 36، كل ما عليك فعله هو حساب أحجام هذه الدلاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "وهذا يعطينا شكلاً محددًا للتوزيع الذي يصف مجموع حجري نرد، وإذا لعبنا نفس اللعبة مع كل ثلاثة توائم ممكنة، فسيبدو التوزيع الناتج بهذا الشكل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "الآن الأمر الأكثر تحديًا، ولكن الأكثر إثارة للاهتمام، هو أن نسأل ماذا يحدث إذا كان لدينا توزيع غير منتظم لذلك القالب الفردي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "لقد تحدثنا بالفعل عن كل هذا في الفيديو الأخير. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "أنت تفعل نفس الشيء بشكل أساسي، حيث تقوم بتمرير جميع أزواج النرد المميزة التي تضيف ما يصل إلى نفس القيمة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "الأمر فقط أنه بدلًا من عد تلك الأزواج، لكل زوج تقوم بضرب الاحتمالين لكل وجه محدد، ثم تقوم بجمع كل هؤلاء معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "الحساب الذي يقوم بذلك لجميع المبالغ الممكنة له اسم فاخر، يُطلق عليه اسم الإلتواء، ولكنه في الأساس مجرد نسخة مرجحة من لعبة العد التي يجدها أي شخص يلعب بزوج من النرد مألوفة بالفعل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "ولأغراضنا في هذا الدرس، سأطلب من الكمبيوتر حساب كل ذلك، وببساطة عرض النتائج لك، وأدعوك لمراقبة أنماط معينة، ولكن تحت الغطاء، هذا ما يحدث. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "لذا فقط لكي نكون واضحين تمامًا بشأن ما يتم تمثيله هنا، إذا كنت تتخيل أخذ عينات من قيمتين مختلفتين من هذا التوزيع العلوي، القيمة التي تصف قالبًا واحدًا، وإضافتهما معًا، فإن التوزيع الثاني الذي أرسمه يمثل مدى احتمالية قيامك بذلك رؤية مبالغ مختلفة مختلفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "وبالمثل، إذا تخيلت أخذ عينات من ثلاث قيم مختلفة من هذا التوزيع العلوي، وجمعها معًا، فإن المخطط التالي يمثل احتمالات المجاميع المختلفة في هذه الحالة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "لذا، إذا قمت بحساب كيف تبدو توزيعات هذه المجاميع بالنسبة للمجاميع الأكبر فأكبر، حسنًا، كما تعلمون ما سأقوله، يبدو الأمر مثل منحنى الجرس أكثر فأكثر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "لكن قبل أن نصل إلى ذلك، أريدكم أن تقدموا بعض الملاحظات البسيطة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "على سبيل المثال، يبدو أن هذه التوزيعات تتجه نحو اليمين، ويبدو أيضًا أنها أصبحت أكثر انتشارًا وأكثر استواءً قليلاً. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "لا يمكنك وصف نظرية الحد المركزي كميًا دون الأخذ بعين الاعتبار هذين التأثيرين، الأمر الذي يتطلب بدوره وصف المتوسط والانحراف المعياري. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "ربما تكون على دراية بهذه الأمور بالفعل، ولكني أريد أن أضع الحد الأدنى من الافتراضات هنا، ولا يضر أبدًا مراجعتها، لذلك دعونا نراجعها سريعًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "إن متوسط التوزيع، الذي يُشار إليه غالبًا بالحرف اليوناني mu، هو وسيلة لالتقاط مركز الكتلة لهذا التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "يتم حسابها على أنها القيمة المتوقعة للمتغير العشوائي، وهي طريقة للقول إنك تمر بجميع النتائج المحتملة المختلفة، وتضرب احتمالية تلك النتيجة في قيمة المتغير. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "إذا كانت القيم الأعلى أكثر احتمالا، فإن هذا المبلغ المرجح سيكون أكبر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "إذا كانت القيم الأقل أكثر احتمالا، فسيكون هذا المبلغ المرجح أصغر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "الأمر الأكثر إثارة للاهتمام هو إذا كنت تريد قياس مدى انتشار هذا التوزيع، لأن هناك عدة طرق مختلفة يمكنك القيام بها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "واحد منهم يسمى التباين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "الفكرة هنا هي النظر إلى الفرق بين كل قيمة محتملة والمتوسط، وتربيع هذا الفرق، والسؤال عن قيمته المتوقعة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "الفكرة هي أنه سواء كانت القيمة أقل من المتوسط أو أعلى منه، فعندما تقوم بتربيع هذا الفرق، تحصل على رقم موجب، وكلما زاد الفرق، زاد هذا الرقم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "يبدو أن تربيعها بهذه الطريقة يجعل العمليات الحسابية أفضل بكثير مما لو قمنا بشيء مثل القيمة المطلقة، ولكن الجانب السلبي هو أنه من الصعب التفكير في ذلك كمسافة في مخططنا لأن الوحدات متباعدة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "تشبه الوحدات هنا وحدات مربعة، في حين أن المسافة في الرسم البياني لدينا ستكون نوعًا من الوحدات الخطية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "لذا هناك طريقة أخرى لقياس الانتشار وهي ما يسمى بالانحراف المعياري، وهو الجذر التربيعي لهذه القيمة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "يمكن تفسير ذلك بشكل أكثر منطقية على أنه مسافة في الرسم البياني الخاص بنا، ويُشار إليها عادةً بالحرف اليوناني سيجما، لذا فأنت تعرف m تعني الانحراف المعياري، ولكن كلاهما باللغة اليونانية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "إذا نظرنا إلى الوراء في تسلسل التوزيعات لدينا، دعونا نتحدث عن المتوسط والانحراف المعياري. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "إذا أطلقنا على متوسط التوزيع الأولي mu، والذي بالنسبة للتوزيع الموضح يكون 2.24، آمل ألا يكون مفاجئًا جدًا إذا أخبرتك أن متوسط الرقم التالي هو 2 مرات mu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "أي أنك تقوم برمي زوج من النرد، وتريد معرفة القيمة المتوقعة للمجموع، وهي ضعف القيمة المتوقعة لنرد واحد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "وبالمثل، فإن القيمة المتوقعة لمجموع الحجم 3 لدينا هي 3 مرات مو، وهكذا دواليك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "ويسير المتوسط بثبات نحو اليمين، ولهذا السبب يبدو أن توزيعاتنا تنجرف في هذا الاتجاه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "الأمر الأكثر تحديًا، ولكنه مهم جدًا، هو وصف كيفية تغير الانحراف المعياري. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "الحقيقة الأساسية هنا هي أنه إذا كان لديك متغيرين عشوائيين مختلفين، فإن التباين لمجموع تلك المتغيرات هو نفسه مجرد إضافة التباينين الأصليين معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "هذه واحدة من تلك الحقائق التي يمكنك حسابها فقط عندما تقوم بتفكيك جميع التعريفات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "هناك بعض البديهيات اللطيفة التي توضح سبب صحة هذا الأمر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "خطتي المبدئية هي أن أقوم بعمل سلسلة حول الاحتمالات والتحدث عن أشياء مثل الحدس الكامن وراء التباين وأقربائه هناك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "لكن الآن، الشيء الرئيسي الذي أريدك أن تسلط الضوء عليه هو كيف أن التباين هو الذي يضيف، وليس الانحراف المعياري هو الذي يضيف. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "لذا، بشكل حاسم، إذا كنت ستأخذ n من إدراكات مختلفة لنفس المتغير العشوائي وتسأل كيف يبدو المجموع، فإن تباين هذا المجموع هو n مضروبًا في تباين المتغير الأصلي، مما يعني الانحراف المعياري، الجذر التربيعي للجميع هذا هو الجذر التربيعي لـ n مضروبًا في الانحراف المعياري الأصلي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "على سبيل المثال، بالعودة إلى تسلسل التوزيعات لدينا، إذا قمنا بتسمية الانحراف المعياري للانحراف الأولي بـ سيجما، فإن الانحراف المعياري التالي سيكون الجذر التربيعي لـ 2 في سيجما، وبعد ذلك يبدو مثل الجذر التربيعي لـ 3 مرات سيجما، وهكذا دواليك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "وهذا، كما قلت، مهم جداً. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "هذا يعني أنه على الرغم من أن توزيعاتنا تنتشر، إلا أنها لا تنتشر بهذه السرعة، بل تفعل ذلك فقط بما يتناسب مع الجذر التربيعي لحجم المجموع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "بينما نستعد لتقديم وصف كمي أكثر لنظرية الحد المركزي، فإن الحدس الأساسي الذي أريدك أن تبقيه في رأسك هو أننا سنقوم بشكل أساسي بإعادة تنظيم كل هذه التوزيعات بحيث تصطف وسائلها معًا، ثم نعيد قياسها بحيث أن جميع الانحرافات المعيارية ستكون مساوية لـ 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "وعندما نفعل ذلك، فإن الشكل الناتج يقترب أكثر فأكثر من شكل عالمي معين، موصوف بوظيفة صغيرة أنيقة سنكشف عنها في لحظة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "واسمحوا لي أن أقول مرة أخرى، السحر الحقيقي هنا هو كيف يمكننا البدء بأي توزيع، ووصف رمية واحدة من حجر النرد، وإذا لعبنا نفس اللعبة، مع الأخذ في الاعتبار كيف تبدو التوزيعات للمجاميع العديدة المختلفة، ونعيد تنظيمها بحيث تصطف المتوسطات، ونعيد قياسها بحيث تكون الانحرافات المعيارية كلها 1، وما زلنا نقترب من نفس الشكل العالمي، وهو أمر محير للعقل نوعًا ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "والآن، يا أصدقائي، ربما يكون الوقت مناسبًا مثل أي وقت آخر للدخول أخيرًا في صيغة التوزيع الطبيعي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "والطريقة التي أود القيام بها هي تقشير كل الطبقات وبناءها قطعة واحدة في كل مرة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "تصف الدالة e إلى x، أو أي شيء إلى x، النمو الأسي، وإذا جعلت هذا الأس سالبًا، والذي يتقلب حول الرسم البياني أفقيًا، فقد تفكر في الأمر على أنه يصف الانحطاط الأسي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "لإجراء هذا الاضمحلال في كلا الاتجاهين، يمكنك فعل شيء للتأكد من أن الأس دائمًا سالب ومتزايد، مثل أخذ القيمة المطلقة السالبة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "وهذا من شأنه أن يعطينا هذا النوع من النقطة الحادة الغريبة في المنتصف، ولكن إذا جعلت هذا الأس هو المربع السالب لـ x، فستحصل على نسخة أكثر سلاسة من نفس الشيء، والتي تضمحل في كلا الاتجاهين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "وهذا يعطينا شكل منحنى الجرس الأساسي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "الآن، إذا قمت برمي ثابت أمام ذلك x، وقمت بقياس هذا الثابت لأعلى ولأسفل، فسيسمح لك ذلك بتمديد الرسم البياني وسحقه أفقيًا، مما يسمح لك بوصف منحنيات الجرس الضيقة والأوسع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "والأمر السريع الذي أود الإشارة إليه هنا هو أنه استنادًا إلى قواعد الأسي، أثناء قيامنا بالتعديل حول هذا الثابت c، يمكنك أيضًا التفكير في الأمر على أنه مجرد تغيير لقاعدة الأسي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "وبهذا المعنى، فإن العدد e ليس خاصًا بالصيغة التي لدينا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "يمكننا استبداله بأي ثابت موجب آخر، وستحصل على نفس عائلة المنحنيات عندما نقوم بتعديل هذا الثابت. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "اجعلها 2، نفس عائلة المنحنيات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "اجعلها 3، نفس عائلة المنحنيات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "سبب استخدامنا e هو أنه يعطي هذا الثابت معنى سهل القراءة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "أو بالأحرى، إذا قمنا بإعادة تشكيل الأشياء قليلًا بحيث يبدو الأس سالب نصف مضروبًا في x مقسومًا على ثابت معين، والذي سنسميه بشكل مقترح سيجما تربيع، وبمجرد أن نحول ذلك إلى توزيع احتمالي، فإن سيجما الثابت سوف يكون الانحراف المعياري لهذا التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "وهذا جميل جدا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "لكن قبل أن نتمكن من تفسير ذلك على أنه توزيع احتمالي، نحتاج إلى أن تكون المساحة تحت المنحنى 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "والسبب في ذلك هو كيفية تفسير المنحنى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "على عكس التوزيعات المنفصلة، عندما يتعلق الأمر بشيء مستمر، فإنك لا تسأل عن احتمالية نقطة معينة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "بدلا من ذلك، أنت تسأل عن احتمال أن تقع القيمة بين قيمتين مختلفتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "وما يخبرك به المنحنى هو أن هذا الاحتمال يساوي المساحة الموجودة أسفل المنحنى بين هاتين القيمتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "هناك فيديو آخر كامل حول هذا، يطلق عليهم دوال الكثافة الاحتمالية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "النقطة الأساسية الآن هي أن المساحة الموجودة أسفل المنحنى بأكمله تمثل احتمال حدوث شيء ما، أو ظهور رقم ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "ينبغي أن يكون 1، ولهذا السبب نريد أن تكون المساحة الموجودة تحت هذا 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "كما هو الحال مع شكل منحنى الجرس الأساسي من e إلى سالب x تربيع، فإن المساحة ليست 1، إنها في الواقع الجذر التربيعي لـ pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "أنا أوافق؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "ماذا يفعل بي هنا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "ما علاقة هذا بالدوائر؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "كما قلت في البداية، أود أن أتحدث عن ذلك في الفيديو التالي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "لكن إذا كان بوسعك توفير حماسك لأغراضنا الآن، فكل ما يعنيه ذلك هو أننا يجب أن نقسم هذه الدالة على الجذر التربيعي لـ pi، وهذا يعطينا المساحة التي نريدها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "بالعودة إلى الثوابت التي كانت لدينا سابقًا، النصف 1 وسيجما، فإن التأثير هناك هو تمديد الرسم البياني بعامل سيجما مضروبًا في الجذر التربيعي لـ 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "لذلك نحتاج أيضًا إلى القسمة على ذلك للتأكد من أن مساحته تساوي 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "وبجمع هذه الكسور، يبدو العامل الناتج مثل 1 مقسومًا على سيجما مضروبًا في الجذر التربيعي لـ 2 باي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "وهذا، أخيرًا، توزيع احتمالي صحيح. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "عندما نقوم بتعديل قيمة سيجما، مما يؤدي إلى منحنيات أضيق وأوسع، فإن هذا الثابت في المقدمة يضمن دائمًا أن المساحة تساوي 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "الحالة الخاصة التي يكون فيها سيجما يساوي 1 لها اسم محدد، نسميها التوزيع الطبيعي القياسي، والذي يلعب دورًا مهمًا بشكل خاص بالنسبة لي ولكم في هذا الدرس. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "وجميع التوزيعات العادية الممكنة لا يتم تحديد معلماتها باستخدام قيمة سيجما هذه فحسب، بل نطرح أيضًا ثابتًا آخر mu من المتغير x، وهذا يتيح لك فقط تحريك الرسم البياني إلى اليسار واليمين حتى تتمكن من وصف متوسط هذا التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "باختصار، لدينا معاملان، أحدهما يصف المتوسط، والآخر يصف الانحراف المعياري، وكلهم مرتبطون معًا في هذه الصيغة الكبيرة التي تتضمن e وpi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "الآن بعد أن أصبح كل ذلك مطروحًا على الطاولة، دعونا ننظر مرة أخرى إلى فكرة البدء ببعض المتغيرات العشوائية ونسأل كيف تبدو توزيعات مجاميع هذا المتغير. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "وكما سبق أن تناولنا، عندما تقوم بزيادة حجم هذا المبلغ، فإن التوزيع الناتج سوف يتحول وفقًا لمتوسط متزايد، وينتشر ببطء وفقًا للانحراف المعياري المتزايد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "وبوضع بعض الصيغ الفعلية لها، إذا كنا نعرف متوسط المتغير العشوائي الأساسي، نسميه mu، ونعرف أيضًا انحرافه المعياري، ونسميه sigma، فإن متوسط المجموع في الأسفل سيكون mu أضعاف حجم المجموع، وسيكون الانحراف المعياري هو سيجما ضرب الجذر التربيعي لذلك الحجم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "والآن، إذا أردنا أن ندعي أن هذا يبدو أكثر فأكثر مثل منحنى الجرس، وأن منحنى الجرس يوصف فقط من خلال معلمتين مختلفتين، المتوسط والانحراف المعياري، فأنت تعرف ما يجب فعله. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "يمكنك إدخال هاتين القيمتين في الصيغة، وستمنحك صيغة واضحة للغاية، وإن كانت معقدة نوعًا ما، لمنحنى يجب أن يتناسب بشكل وثيق مع توزيعنا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "ولكن هناك طريقة أخرى يمكننا أن نصفها بأنها أكثر أناقة قليلاً وتضفي طابعًا بصريًا ممتعًا للغاية يمكننا البناء عليه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "بدلاً من التركيز على مجموع كل هذه المتغيرات العشوائية، دعونا نعدل هذا التعبير قليلاً، حيث ما سنفعله هو أننا سننظر إلى المتوسط الذي نتوقع أن يأخذه هذا المجموع، ونطرحه بحيث تعبيرنا الجديد له متوسط قدره 0، ثم سننظر إلى الانحراف المعياري الذي نتوقعه من مجموعنا، ونقسمه على ذلك، والذي يؤدي في الأساس إلى إعادة قياس الوحدات بحيث يصبح الانحراف المعياري للتعبير لدينا يساوي 1 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "قد يبدو هذا تعبيرًا أكثر تعقيدًا، لكنه في الواقع له معنى سهل القراءة للغاية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "إنها تقول في الأساس كم عدد الانحرافات المعيارية بعيدًا عن المتوسط هو هذا المبلغ؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "على سبيل المثال، يتوافق هذا الشريط هنا مع قيمة معينة قد تجدها عند رمي 10 نرد وتجمعها كلها، وموضعه أعلى بقليل من سالب 1 يخبرك أن هذه القيمة أقل قليلاً من انحراف معياري واحد أقل من المتوسط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "وبالمناسبة أيضًا، تحسبًا للرسوم المتحركة التي أحاول إنشاءها هنا، فإن الطريقة التي أمثل بها الأشياء في المخطط السفلي هي أن مساحة كل واحد من هذه الأشرطة تخبرنا باحتمالية القيمة المقابلة بدلا من الارتفاع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "قد تعتقد أن المحور الصادي لا يمثل الاحتمالية بل نوعًا من كثافة الاحتمالية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "والسبب في ذلك هو تهيئة المسرح بحيث يتوافق مع الطريقة التي نفسر بها التوزيعات المستمرة، حيث يكون احتمال الوقوع بين نطاق من القيم يساوي مساحة تحت منحنى بين تلك القيم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "على وجه الخصوص، ستكون مساحة جميع الأشرطة معًا 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "الآن، مع كل ذلك، دعونا نستمتع قليلاً. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "اسمحوا لي أن أبدأ بإعادة الأمور إلى الوراء بحيث يمثل التوزيع في الأسفل مبلغًا صغيرًا نسبيًا، مثل إضافة ثلاثة متغيرات عشوائية فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "لاحظ ما يحدث عندما أقوم بتغيير التوزيع الذي نبدأ به. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "ومع تغيره، يتغير شكل التوزيع الموجود في الأسفل تمامًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "إنه يعتمد بشكل كبير على ما بدأنا به. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "إذا سمحنا لحجم مجموعنا أن يصبح أكبر قليلًا، لنفترض أنه يصل إلى 10، وعندما أقوم بتغيير التوزيع لـ x، فسيظل يبدو إلى حد كبير مثل منحنى الجرس، لكن يمكنني العثور على بعض التوزيعات التي تجعله يغير شكله . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "على سبيل المثال، الشكل غير المتوازن حقًا حيث تكون كل الاحتمالات تقريبًا في الأرقام 1 أو 6 يؤدي إلى هذا النوع من منحنى الجرس الشائك، وإذا كنتم تتذكرون، في وقت سابق لقد عرضت هذا بالفعل في شكل محاكاة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "لذا، إذا كنت تتساءل عما إذا كان هذا الارتفاع نتيجة للعشوائية أو يعكس التوزيع الحقيقي، فقد تبين أنه يعكس التوزيع الحقيقي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "في هذه الحالة، 10 ليس مبلغًا كبيرًا بما يكفي لتطبيق نظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "ولكن إذا تركت هذا المجموع ينمو وفكرت في إضافة 50 قيمة مختلفة، وهي في الواقع ليست كبيرة جدًا، فبغض النظر عن كيفية تغيير التوزيع للمتغير العشوائي الأساسي، فلن يكون له أي تأثير على شكل المخطط على قاع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "بغض النظر عن المكان الذي نبدأ فيه، يتم التخلص من جميع المعلومات والفروق الدقيقة لتوزيع x، ونحن نميل نحو هذا الشكل العالمي الوحيد الموصوف بوظيفة أنيقة للغاية للتوزيع الطبيعي القياسي، 1 على الجذر التربيعي لـ 2 pi في e إلى السالب x تربيع على 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "هذا، هذا هنا هو ما تدور حوله نظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "لا شيء تقريبًا يمكنك فعله لهذا التوزيع الأولي يغير الشكل الذي نميل إليه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "الآن، ربما لا يزال الأشخاص الأكثر تفكيرًا من الناحية النظرية يتساءلون، ما هي النظرية الفعلية؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "مثل، ما هي العبارة الرياضية التي يمكن إثباتها أو دحضها والتي ندعيها هنا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "إذا كنت تريد بيانًا رسميًا لطيفًا، فإليك كيف يمكن أن تسير الأمور. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "خذ بعين الاعتبار هذه القيمة، حيث نقوم بتلخيص عدد n من المثيلات المختلفة لمتغيرنا العشوائي، ولكن تم تعديلها وضبطها بحيث يكون متوسطها وانحرافها المعياري 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "مرة أخرى، هذا يعني أنه يمكنك قراءتها على أنها تسأل عن عدد الانحرافات المعيارية بعيدًا عن المتوسط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "ومن ثم فإن العبارة الفعلية الصارمة التي لا داعي للسخرية هذه المرة لنظرية الحد المركزي هي أنه إذا أخذت في الاعتبار احتمال وقوع هذه القيمة بين رقمين حقيقيين محددين، a وb، واعتبرت حد هذا الاحتمال هو حجم يذهب مجموعك إلى ما لا نهاية، فإن هذا الحد يساوي تكاملًا معينًا، والذي يصف بشكل أساسي المنطقة الواقعة تحت التوزيع الطبيعي القياسي بين هاتين القيمتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "مرة أخرى، هناك ثلاثة افتراضات أساسية لم أخبرك بها بعد، ولكن بخلاف تلك، بكل تفاصيلها الدموية، هذه هنا هي نظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "كل هذا نظري بعض الشيء، لذا قد يكون من المفيد إعادة الأمور إلى الأرض والعودة إلى المثال الملموس الذي ذكرته في البداية، حيث تتخيل رمي حجر النرد 100 مرة، ودعنا نفترض أنها نرد عادل على سبيل المثال، وقمت بإضافة النتائج معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "التحدي الذي يواجهك هو العثور على نطاق من القيم بحيث تكون متأكدًا بنسبة 95% من أن المجموع سيندرج ضمن هذا النطاق. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "بالنسبة لأسئلة كهذه، هناك قاعدة أساسية مفيدة حول التوزيعات العادية، وهي أن حوالي 68% من قيمك سوف تقع ضمن انحراف معياري واحد عن المتوسط، و95% من قيمك، الشيء الذي نهتم به، تقع ضمن انحراف معياري واحد انحرافين معياريين عن المتوسط، و99.7% من القيم الخاصة بك سوف تقع ضمن ثلاثة انحرافات معيارية عن المتوسط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "إنها قاعدة عامة يحفظها عادة الأشخاص الذين يقومون بالكثير من الاحتمالات والإحصائيات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "وبطبيعة الحال، هذا يعطينا ما نحتاجه في مثالنا، واسمحوا لي أن أمضي قدمًا وأرسم كيف سيبدو هذا، حيث سأعرض توزيع القالب العادل في الأعلى، والتوزيع لمجموع 100 مثل هذا النرد الموجود في الأسفل، والذي يبدو الآن، كما تعلم، وكأنه توزيع طبيعي معين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "الخطوة الأولى في مسألة مثل هذه هي إيجاد متوسط التوزيع الأولي، والذي في هذه الحالة سيبدو مثل 1 على 6 في 1 زائد 1 على 6 في 2 وهكذا، ويحصل على 3.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "نحتاج أيضًا إلى الانحراف المعياري، وهو ما يتطلب حساب التباين، والذي كما تعلم يتضمن جمع جميع مربعات الفروق بين القيم والمتوسطات، فيصبح الناتج 2.92، الجذر التربيعي لذلك يساوي 1.71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "هذان هما الرقمان الوحيدان اللذان نحتاجهما، وسأدعوك مرة أخرى للتفكير في مدى روعة أن يكون هذان الرقمان الوحيدان اللذان تحتاجهما لفهم التوزيع السفلي بشكل كامل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "سيكون متوسطه 100 مرة mu، أي 350، وسيكون انحرافه المعياري هو الجذر التربيعي لـ 100 مرة سيجما، أي 10 مرات سيجما 17.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "تذكر قاعدتنا الأساسية، أننا نبحث عن قيم تبعد انحرافين معياريين عن المتوسط، وعندما تطرح 2 سيجما من المتوسط، ينتهي بك الأمر إلى حوالي 316، وعندما تضيف 2 سيجما، ينتهي بك الأمر إلى 384. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "وهنا تذهب، وهذا يعطينا الجواب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "حسنًا، لقد وعدت بإكمال الأمور قريبًا، ولكن أثناء تواجدنا في هذا المثال، هناك سؤال آخر يستحق وقتك للتفكير فيه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "بدلًا من مجرد السؤال عن مجموع 100 لفة نرد، لنفترض أنني قمت بتقسيم هذا الرقم على 100، وهو ما يعني في الأساس أن جميع الأرقام الموجودة في الرسم البياني الخاص بنا في الأسفل سيتم قسمتها على 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "خذ لحظة لتفسير ما سيقوله كل هذا بعد ذلك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "يخبرك التعبير أساسًا بالمتوسط التجريبي لـ 100 لفة مختلفة للقالب، وهذه الفترة التي وجدناها تخبرك الآن بالنطاق الذي تتوقع رؤيته لهذا المتوسط التجريبي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "وبعبارة أخرى، قد تتوقع أن يكون حوالي 3.5، هذه هي القيمة المتوقعة لرمية القالب، ولكن ما هو أقل وضوحًا وما تتيح لك نظرية الحد المركزي حسابه هو مدى قربك من تلك القيمة المتوقعة التي ستجدها بنفسك بشكل معقول. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "على وجه الخصوص، من المفيد أن نتوقف لحظة للتفكير في الانحراف المعياري لهذا المتوسط التجريبي، وما يحدث له عندما تنظر إلى عينة أكبر وأكبر من قوالب القالب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "أخيرًا، وربما الأهم، دعونا نتحدث عن الافتراضات التي تدخل في هذه النظرية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "الأول هو أن كل هذه المتغيرات التي نضيفها مستقلة عن بعضها البعض. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "لا تؤثر نتيجة عملية واحدة على نتيجة أي عملية أخرى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "والثاني هو أن كل هذه المتغيرات مستمدة من نفس التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "تم افتراض كلا الأمرين ضمنيًا في مثال النرد الخاص بنا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "لقد تعاملنا مع نتيجة كل نرد على أنها مستقلة عن نتائج جميع النردات الأخرى، ونفترض أن كل نرد يتبع نفس التوزيع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "في بعض الأحيان، سترى في الأدبيات هذين الافتراضين مجمعين معًا تحت الأحرف الأولى من IID لـ مستقل وموزع بشكل متطابق. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "أحد المواقف التي تكون فيها هذه الافتراضات غير صحيحة بالتأكيد هو مجلس جالتون. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": ". ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "هل الطريقة التي ترتد بها الكرة عن أحد الأوتاد مستقلة عن الطريقة التي سترتد بها الكرة عن الوتد التالي؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "بالطبع لا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "اعتمادًا على الارتداد الأخير، فإنه يأتي بمسار مختلف تمامًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "وهل صحيح أن توزيع النتائج المحتملة لكل ربط هو نفسه بالنسبة لكل ربط يتم الوصول إليه؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "مرة أخرى، يكاد يكون من المؤكد لا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "ربما تضرب وتدًا واحدًا خاطفًا إلى اليسار، مما يعني أن النتائج منحرفة بشكل كبير في هذا الاتجاه، ثم تضرب الوتد التالي الذي يلتفت إلى اليمين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "عندما قدمت كل تلك الافتراضات المبسطة في المثال الافتتاحي، لم يكن ذلك فقط لتسهيل التفكير في هذا الأمر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "إنها أيضًا أن هذه الافتراضات كانت ضرورية ليكون هذا مثالًا لنظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "ومع ذلك، يبدو أنه من الصحيح أنه بالنسبة للوحة جالتون الحقيقية، على الرغم من انتهاك كلا الأمرين، هل يحدث توزيع طبيعي نوعًا ما؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "قد يرجع جزء من السبب إلى وجود تعميمات للنظرية خارج نطاق هذا الفيديو والتي تخفف من هذه الافتراضات، خاصة الافتراض الثاني. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "لكنني أريد أن أحذرك من حقيقة أنه في كثير من الأحيان يبدو أن الناس يفترضون أن المتغير يتم توزيعه بشكل طبيعي، حتى عندما لا يكون هناك مبرر فعلي للقيام بذلك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "الافتراض الثالث هو في الواقع دقيق إلى حد ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "إنه أن التباين الذي قمنا بحسابه لهذه المتغيرات محدود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "لم تكن هذه مشكلة أبدًا بالنسبة لمثال النرد، لأنه كانت هناك ست نتائج محتملة فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "لكن في مواقف معينة حيث يكون لديك مجموعة لا حصر لها من النتائج، عندما تذهب لحساب التباين، ينتهي الأمر بالمجموع إلى التباعد إلى ما لا نهاية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "يمكن أن تكون هذه توزيعات احتمالية صحيحة تمامًا، وهي موجودة بالفعل في الممارسة العملية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "لكن في تلك المواقف، عندما تفكر في إضافة العديد من المثيلات المختلفة لهذا المتغير والسماح لهذا المجموع بالاقتراب من اللانهاية، حتى لو كان الافتراضان الأولان صحيحين، فمن المحتمل جدًا أن الشيء الذي تميل إليه ليس في الواقع توزيعًا طبيعيًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "إذا كنت قد فهمت كل شيء حتى هذه اللحظة، فلديك الآن أساس قوي جدًا لما تدور حوله نظرية الحد المركزي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "وبعد ذلك، أود أن أشرح لماذا هذه الوظيفة بالذات هي الشيء الذي نميل إليه، ولماذا تحتوي على باي، وما علاقتها بالدوائر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]