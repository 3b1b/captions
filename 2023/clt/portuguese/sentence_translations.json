[
 {
  "input": "This is a Galton board. ",
  "translatedText": "Esta é uma placa Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "Talvez você já tenha visto isso antes, é uma demonstração popular de como, mesmo quando um único evento é caótico e aleatório, com um resultado efetivamente incognoscível, ainda é possível fazer afirmações precisas sobre um grande número de eventos, ou seja, como as proporções relativas pois muitos resultados diferentes são distribuídos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "Mais especificamente, o quadro de Galton ilustra uma das distribuições mais proeminentes de todas as probabilidades, conhecida como distribuição normal, mais coloquialmente conhecida como curva em sino, e também chamada de distribuição gaussiana. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "Existe uma função muito específica para descrever essa distribuição, é muito bonita, falaremos dela mais tarde, mas agora só quero enfatizar como a distribuição normal é, como o nome sugere, muito comum, aparece em muitos de contextos aparentemente não relacionados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "Se você pegasse um grande número de pessoas que pertencem a um grupo demográfico semelhante e traçasse suas alturas, essas alturas tenderiam a seguir uma distribuição normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "Se você olhar para uma grande quantidade de números naturais muito grandes e perguntar quantos fatores primos distintos cada um desses números tem, as respostas acompanharão de perto uma certa distribuição normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "Agora, nosso tópico de hoje é uma das joias da coroa de toda a teoria das probabilidades, é um dos principais fatos que explica por que essa distribuição é tão comum como é, conhecida como teorema do limite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "Esta lição pretende voltar ao básico, dando-lhe os fundamentos sobre o que o teorema do limite central diz, o que são distribuições normais, e quero assumir um histórico mínimo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "Vamos nos aprofundar nisso, mas depois disso eu ainda gostaria de me aprofundar e explicar por que o teorema é verdadeiro, por que a função subjacente à distribuição normal tem a forma muito específica que tem, por que essa fórmula tem um pi nele e, o que é mais divertido, por que esses dois últimos fatos estão na verdade mais relacionados do que muitas explicações tradicionais poderiam sugerir. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "Essa segunda lição também pretende ser a continuação do vídeo de convoluções que prometi, portanto, há muitos tópicos inter-relacionados aqui. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "Mas agora, voltando aos fundamentos, gostaria de começar com um modelo excessivamente simplificado do conselho de Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "Neste modelo, assumiremos que cada bola cai diretamente em um determinado pino central e que tem uma probabilidade de 50-50 de quicar para a esquerda ou para a direita, e pensaremos em cada um desses resultados como a adição de um ou subtraindo um de sua posição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "Uma vez escolhido um deles, fazemos a suposição altamente irrealista de que ele cai no meio do pino adjacente abaixo dele, onde novamente ele será confrontado com a mesma escolha de 50-50 de saltar para a esquerda ou Para a direita. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "Para aquela que estou mostrando na tela, há cinco fileiras diferentes de pinos, então nossa bolinha saltitante faz cinco escolhas aleatórias diferentes entre mais um e menos um, e podemos pensar em sua posição final como sendo basicamente a soma de todas desses diferentes números, que neste caso é um, e podemos rotular todos os diferentes baldes com a soma que eles representam. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "Ao repetirmos isso, estamos analisando diferentes somas possíveis para esses cinco números aleatórios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "E para aqueles de vocês que estão inclinados a reclamar que este é um modelo altamente irrealista para o verdadeiro tabuleiro de Galton, deixe-me enfatizar que o objetivo agora não é modelar a física com precisão. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "O objetivo é dar um exemplo simples para ilustrar o teorema do limite central e, para isso, por mais idealizado que seja, na verdade nos dá um exemplo realmente bom. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "Se deixarmos cair muitas bolas diferentes, fazendo ainda outra suposição irreal de que elas não influenciam umas às outras como se fossem todas fantasmas, então o número de bolas que caem em cada balde diferente nos dá uma noção vaga da probabilidade de cada uma delas cair. desses baldes é. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "Neste exemplo, os números são simples o suficiente para que não seja muito difícil calcular explicitamente qual é a probabilidade de cair em cada balde. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "Se você quiser refletir sobre isso, verá que isso lembra muito o triângulo de Pascal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "Mas o que é interessante no nosso teorema é o quão longe ele vai além dos exemplos simples. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "Então, pelo menos para começar, em vez de fazer cálculos explícitos, vamos apenas simular coisas executando um grande número de amostras e deixando que o número total de resultados em cada resultado diferente nos dê alguma noção de como é essa distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "Como eu disse, o que está na tela tem cinco linhas, então cada soma que estamos considerando inclui apenas cinco números. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "A ideia básica do teorema do limite central é que se você aumentar o tamanho dessa soma, por exemplo aqui, isso significaria aumentar o número de fileiras de pinos para cada bola quicar, então a distribuição que descreve para onde essa soma está indo o outono parece cada vez mais uma curva em forma de sino. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "Aqui, vale a pena reservar um momento para anotar essa ideia geral. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "A configuração é que temos uma variável aleatória, e isso é basicamente uma abreviação de um processo aleatório onde cada resultado desse processo está associado a algum número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "Chamaremos esse número aleatório de x. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "Por exemplo, cada rebote da estaca é um processo aleatório modelado com dois resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "Esses resultados estão associados aos números menos um e positivo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "Outro exemplo de variável aleatória seria lançar um dado, onde você tem seis resultados diferentes, cada um associado a um número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "O que estamos fazendo é pegar várias amostras diferentes dessa variável e adicioná-las todas juntas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "No nosso tabuleiro de Galton, isso parece deixar a bola quicar em vários pinos diferentes em seu caminho até o fundo e, no caso de um dado, você pode imaginar lançar muitos dados diferentes e somar os resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "A afirmação do teorema do limite central é que, à medida que deixamos o tamanho dessa soma ficar cada vez maior, a distribuição dessa soma, a probabilidade de cair em diferentes valores possíveis, parecerá cada vez mais com uma curva em forma de sino. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "É isso, essa é a ideia geral. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "Ao longo desta lição, nosso trabalho é tornar essa afirmação mais quantitativa. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "Vamos colocar alguns números, algumas fórmulas, mostrar como você pode usá-lo para fazer previsões. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "Por exemplo, aqui está o tipo de pergunta que quero que você consiga responder até o final deste vídeo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "Suponha que você lançou o dado 100 vezes e somou os resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "Você poderia encontrar um intervalo de valores tal que tenha 95% de certeza de que a soma estará dentro desse intervalo? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "Ou talvez eu deva dizer para encontrar o menor intervalo possível de valores para que isso seja verdade. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "O interessante é que você será capaz de responder a essa pergunta, seja um dado justo ou um dado ponderado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "Agora, deixe-me dizer, no início, que este teorema tem três suposições diferentes, três coisas que precisam ser verdadeiras antes que o teorema seja seguido. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "E na verdade não vou contar o que são até o final do vídeo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "Em vez disso, quero que você fique atento e veja se consegue perceber e talvez prever quais serão essas três suposições. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "Como próximo passo, para ilustrar melhor o quão geral é esse teorema, quero fazer mais algumas simulações para você, focadas no exemplo dos dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "Normalmente, se você pensa em lançar um dado, pensa que os seis resultados são igualmente prováveis, mas o teorema na verdade não se importa com isso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "Poderíamos começar com um dado ponderado, algo com uma distribuição não trivial entre os resultados, e a ideia central ainda se mantém. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "Para a simulação, o que farei é pegar alguma distribuição como esta, que está distorcida para valores mais baixos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "Vou pegar 10 amostras distintas dessa distribuição e depois registrar a soma dessa amostra no gráfico abaixo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "Então farei isso muitas vezes diferentes, sempre com uma soma de tamanho 10, mas acompanhe onde essas somas foram parar para nos dar uma noção da distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "E, na verdade, deixe-me redimensionar a direção y para nos dar espaço para executar um número ainda maior de amostras. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "E vou deixá-lo ir até alguns milhares e, à medida que isso acontece, você notará que a forma que começa a surgir parece uma curva em forma de sino. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "Talvez se você apertar os olhos você possa ver que ele se inclina um pouquinho para a esquerda, mas é legal que algo tão simétrico tenha surgido de um ponto de partida que era tão assimétrico. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "Para ilustrar melhor do que se trata o teorema do limite central, deixe-me executar quatro dessas simulações em paralelo, onde no canto superior esquerdo estou fazendo isso onde estamos apenas adicionando dois dados por vez, no canto superior direito estamos ' estamos fazendo isso adicionando cinco dados de cada vez, o canto inferior esquerdo é aquele que acabamos de ver adicionando 10 dados de cada vez, e então faremos outro com uma soma maior, 15 de cada vez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "Observe como no canto superior esquerdo, quando estamos apenas adicionando dois dados, a distribuição resultante não se parece realmente com uma curva em forma de sino, parece muito mais uma reminiscência daquela com a qual começamos, inclinada para a esquerda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "Mas à medida que permitimos mais e mais dados em cada soma, a forma resultante que surge nestas distribuições parece cada vez mais simétrica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "Ele tem uma protuberância no meio e desbota em direção ao formato de uma curva de sino da cauda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "E deixe-me enfatizar novamente: você pode começar com qualquer distribuição diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "Aqui vou executá-lo novamente, mas onde a maior parte da probabilidade está ligada aos números 1 e 6, com probabilidade muito baixa para os valores médios. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "Apesar de mudar completamente a distribuição para um lançamento individual do dado, ainda acontece que uma forma de curva em sino surgirá à medida que consideramos as diferentes somas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "Ilustrar coisas com uma simulação como essa é muito divertido e é legal ver a ordem emergir do caos, mas também parece um pouco impreciso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "Como neste caso, quando cortei a simulação em 3.000 amostras, mesmo que pareça uma curva em forma de sino, os diferentes intervalos parecem bastante pontiagudos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "E você pode se perguntar: deveria ser assim ou isso é apenas um artefato da aleatoriedade na simulação? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "E se for, de quantas amostras precisamos antes de termos certeza de que o que estamos vendo é representativo da verdadeira distribuição? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "Em vez de seguir em frente, vamos ser um pouco mais teóricos e mostrar a forma precisa que essas distribuições assumirão no longo prazo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "O caso mais fácil de fazer esse cálculo é se tivermos uma distribuição uniforme, onde cada face possível do dado tem probabilidade igual, 1 6º. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "Por exemplo, se você quiser saber qual a probabilidade de somas diferentes para um par de dados, é essencialmente um jogo de contagem, onde você conta quantos pares distintos resultam na mesma soma, o que no diagrama que desenhei, você podemos pensar convenientemente percorrendo todas as diferentes diagonais. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "Como cada par tem chances iguais de aparecer, 1 em 36, tudo o que você precisa fazer é contar o tamanho desses baldes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "Isto dá-nos uma forma definitiva para a distribuição que descreve uma soma de dois dados, e se jogássemos o mesmo jogo com todos os trigémeos possíveis, a distribuição resultante seria assim. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "Agora, o que é mais desafiador, mas muito mais interessante, é perguntar o que acontece se tivermos uma distribuição não uniforme para aquele único dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "Na verdade, falamos sobre isso no último vídeo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "Você faz essencialmente a mesma coisa, passa por todos os pares distintos de dados que somam o mesmo valor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "Acontece que, em vez de contar esses pares, para cada par você multiplica as duas probabilidades de cada face específica surgir e depois soma todas elas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "O cálculo que faz isso para todas as somas possíveis tem um nome chique, é chamado de convolução, mas é essencialmente apenas a versão ponderada do jogo de contagem que qualquer pessoa que já jogou com um par de dados já acha familiar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "Para nossos propósitos nesta lição, farei com que o computador calcule tudo isso, simplesmente mostre os resultados para você e convide você a observar certos padrões, mas nos bastidores é isso que está acontecendo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "Então, só para ficar bem claro sobre o que está sendo representado aqui, se você imaginar a amostragem de dois valores diferentes daquela distribuição superior, aquela que descreve um único dado, e adicioná-los, então a segunda distribuição que estou desenhando representa a probabilidade de você ter veja várias somas diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "Da mesma forma, se você imaginar amostrar três valores distintos dessa distribuição superior e adicioná-los, o próximo gráfico representa as probabilidades de várias somas diferentes nesse caso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "Então, se eu calcular como são as distribuições dessas somas para somas cada vez maiores, bem, você sabe o que vou dizer, parece cada vez mais uma curva em forma de sino. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "Mas antes de chegarmos a isso, quero que você faça mais algumas observações simples. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "Por exemplo, essas distribuições parecem estar vagando para a direita e também parecem estar ficando mais espalhadas e um pouco mais planas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "Não é possível descrever quantitativamente o teorema do limite central sem levar em conta ambos os efeitos, o que, por sua vez, requer a descrição da média e do desvio padrão. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "Talvez você já esteja familiarizado com eles, mas quero fazer suposições mínimas aqui, e nunca é demais revisar, então vamos examinar rapidamente ambos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "A média de uma distribuição, muitas vezes denotada pela letra grega mu, é uma forma de capturar o centro de massa dessa distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "É calculado como o valor esperado da nossa variável aleatória, que é uma forma de dizer que você analisa todos os diferentes resultados possíveis e multiplica a probabilidade desse resultado pelo valor da variável. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "Se valores mais altos forem mais prováveis, essa soma ponderada será maior. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "Se valores mais baixos forem mais prováveis, essa soma ponderada será menor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "Um pouco mais interessante é se você quiser medir o quão espalhada é essa distribuição, porque há várias maneiras diferentes de fazer isso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "Um deles é chamado de variância. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "A ideia é observar a diferença entre cada valor possível e a média, elevar essa diferença ao quadrado e perguntar qual é o seu valor esperado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "A ideia é que, quer o seu valor esteja abaixo ou acima da média, ao elevar ao quadrado essa diferença, você obtém um número positivo, e quanto maior a diferença, maior será o número. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "Elevá-lo ao quadrado desta forma torna a matemática muito mais agradável do que se fizéssemos algo como um valor absoluto, mas a desvantagem é que é difícil pensar nisso como uma distância no nosso diagrama porque as unidades estão erradas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "Mais ou menos como se as unidades aqui fossem unidades quadradas, enquanto a distância no nosso diagrama seria uma espécie de unidade linear. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "Portanto, outra forma de medir o spread é o chamado desvio padrão, que é a raiz quadrada desse valor. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "Isso pode ser interpretado de forma muito mais razoável como uma distância em nosso diagrama, e é comumente denotado pela letra grega sigma, então você conhece m para média e desvio padrão, mas ambos em grego. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "Olhando novamente para a nossa sequência de distribuições, vamos falar sobre a média e o desvio padrão. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "Se chamarmos a média da distribuição inicial de mu, que para a ilustrada passa a ser 2.24, espero que não seja muito surpreendente se eu lhe disser que a média do próximo é 2 vezes mu. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "Ou seja, você lança um par de dados, quer saber o valor esperado da soma, é duas vezes o valor esperado de um único dado. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "Da mesma forma, o valor esperado para a nossa soma do tamanho 3 é 3 vezes mu, e assim por diante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "A média apenas avança continuamente para a direita, razão pela qual as nossas distribuições parecem estar a desviar-se nessa direcção. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "Um pouco mais desafiador, mas muito importante, é descrever como o desvio padrão muda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "O fato principal aqui é que, se você tiver duas variáveis aleatórias diferentes, a variância para a soma dessas variáveis será a mesma que apenas somar as duas variâncias originais. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "Este é um daqueles fatos que você pode calcular quando descompacta todas as definições. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "Existem algumas boas intuições sobre por que isso é verdade. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "Meu plano provisório é apenas fazer uma série sobre probabilidade e falar sobre coisas como intuições subjacentes à variância e seus primos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "Mas agora, a principal coisa que quero destacar é como é a variância que soma, não é o desvio padrão que soma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "Então, criticamente, se você pegasse n realizações diferentes da mesma variável aleatória e perguntasse como é a soma, a variância dessa soma será n vezes a variância da sua variável original, ou seja, o desvio padrão, a raiz quadrada de todas isto é a raiz quadrada de n vezes o desvio padrão original. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "Por exemplo, de volta à nossa sequência de distribuições, se rotularmos o desvio padrão da nossa distribuição inicial com sigma, então o próximo desvio padrão será a raiz quadrada de 2 vezes sigma, e depois disso parecerá a raiz quadrada de 3 vezes sigma e assim por diante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "Isto, como eu disse, é muito importante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "Significa que, embora as nossas distribuições estejam a espalhar-se, não o estão a espalhar tão rapidamente, apenas o fazem em proporção à raiz quadrada do tamanho da soma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "À medida que nos preparamos para fazer uma descrição mais quantitativa do teorema do limite central, a intuição central que quero que você mantenha em mente é que basicamente realinharemos todas essas distribuições para que suas médias se alinhem e depois as redimensionaremos para que que todos os desvios padrão serão iguais a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "E quando fazemos isso, a forma resultante fica cada vez mais próxima de uma certa forma universal, descrita com uma pequena função elegante que iremos descompactar em alguns instantes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "E deixe-me dizer mais uma vez, a verdadeira magia aqui é como poderíamos ter começado com qualquer distribuição, descrevendo um único lançamento do dado, e se jogarmos o mesmo jogo, considerando como são as distribuições para as muitas somas diferentes, e nós os realinhamos para que as médias se alinhem, e os redimensionamos para que os desvios padrão sejam todos 1, ainda nos aproximamos da mesma forma universal, o que é meio incompreensível. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "E agora, meus amigos, é provavelmente um momento tão bom quanto qualquer outro para finalmente entrar na fórmula de uma distribuição normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "E a maneira que eu gostaria de fazer isso é basicamente descascar todas as camadas e construir uma peça de cada vez. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "A função e elevado a x, ou qualquer coisa elevada a x, descreve o crescimento exponencial, e se você tornar esse expoente negativo, que gira horizontalmente no gráfico, você pode pensar nisso como uma descrição do decaimento exponencial. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "Para fazer esse decaimento em ambas as direções, você poderia fazer algo para garantir que o expoente seja sempre negativo e crescente, como calcular o valor absoluto negativo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "Isso nos daria este tipo de ponto agudo estranho no meio, mas se, em vez disso, fizermos desse expoente o quadrado negativo de x, obteremos uma versão mais suave da mesma coisa, que decai em ambas as direções. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "Isso nos dá a forma básica da curva em sino. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "Agora, se você colocar uma constante na frente desse x e dimensionar essa constante para cima e para baixo, isso permitirá esticar e comprimir o gráfico horizontalmente, permitindo descrever curvas em forma de sino estreitas e mais largas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "E uma coisa rápida que gostaria de salientar aqui é que, com base nas regras da exponenciação, à medida que ajustamos a constante c, você também pode pensar nisso como uma simples mudança na base da exponenciação. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "E nesse sentido, o número e não é tão especial para a nossa fórmula. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "Poderíamos substituí-la por qualquer outra constante positiva e você obterá a mesma família de curvas à medida que ajustamos essa constante. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "Faça duas mesmas famílias de curvas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "Faça com que seja uma 3 mesma família de curvas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "A razão pela qual usamos e é que ele dá a essa constante um significado muito legível. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "Ou melhor, se reconfigurarmos as coisas um pouco para que o expoente pareça menos um meio vezes x dividido por uma certa constante, que chamaremos sugestivamente de sigma ao quadrado, então, uma vez que transformarmos isso em uma distribuição de probabilidade, essa constante sigma irá seja o desvio padrão dessa distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "E isso é muito bom. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "Mas antes de podermos interpretar isto como uma distribuição de probabilidade, precisamos que a área sob a curva seja 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "E a razão para isso é como a curva é interpretada. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "Ao contrário das distribuições discretas, quando se trata de algo contínuo, você não pergunta sobre a probabilidade de um determinado ponto. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "Em vez disso, você pergunta a probabilidade de um valor estar entre dois valores diferentes. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "E o que a curva lhe diz é que essa probabilidade é igual à área sob a curva entre esses dois valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "Há um outro vídeo sobre isso, eles são chamados de funções de densidade de probabilidade. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "O ponto principal agora é que a área sob toda a curva representa a probabilidade de que algo aconteça, de que algum número apareça. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "Deveria ser 1, e é por isso que queremos que a área abaixo disso seja 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "Da forma como está a forma básica da curva em sino de e elevado a x negativo ao quadrado, a área não é 1, é na verdade a raiz quadrada de pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "Eu sei direito? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "O que pi está fazendo aqui? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "O que isso tem a ver com círculos? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "Como eu disse no início, adoraria falar sobre isso no próximo vídeo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "Mas se puder poupar o seu entusiasmo para os nossos propósitos agora, tudo o que significa é que devemos dividir esta função pela raiz quadrada de pi, e isso dá-nos a área que queremos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "Voltando às constantes que tínhamos anteriormente, o 1 meio e o sigma, o efeito é esticar o gráfico por um fator de sigma vezes a raiz quadrada de 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "Então também precisamos dividir por isso para ter certeza de que tem uma área de 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "E combinando essas frações, o fator na frente parece 1 dividido por sigma vezes a raiz quadrada de 2 pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "Esta, finalmente, é uma distribuição de probabilidade válida. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "À medida que ajustamos esse valor sigma, resultando em curvas mais estreitas e mais largas, essa constante na frente sempre garante que a área seja igual a 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "O caso especial em que sigma é igual a 1 tem um nome específico, nós o chamamos de distribuição normal padrão, que desempenha um papel especialmente importante para você e para mim nesta lição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "E todas as distribuições normais possíveis não são apenas parametrizadas com este valor sigma, mas também subtraímos outra constante mu da variável x, e isso essencialmente permite deslizar o gráfico para a esquerda e para a direita para que você possa prescrever a média desta distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "Resumindo, temos dois parâmetros, um que descreve a média, outro que descreve o desvio padrão, e todos estão interligados nesta grande fórmula envolvendo um e e um pi. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "Agora que tudo isso está na mesa, vamos relembrar novamente a ideia de começar com alguma variável aleatória e perguntar como são as distribuições das somas dessa variável. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "Como já dissemos, quando você aumenta o tamanho dessa soma, a distribuição resultante mudará de acordo com uma média crescente e se espalhará lentamente de acordo com um desvio padrão crescente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "E colocando algumas fórmulas reais nisso, se conhecermos a média da nossa variável aleatória subjacente, chamamos-lhe mu, e também conhecemos o seu desvio padrão, e chamamos-lhe sigma, então a média da soma na parte inferior será mu. vezes o tamanho da soma, e o desvio padrão será sigma vezes a raiz quadrada desse tamanho. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "Então agora, se quisermos afirmar que isto se parece cada vez mais com uma curva em sino, e uma curva em sino só é descrita por dois parâmetros diferentes, a média e o desvio padrão, você sabe o que fazer. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "Você poderia inserir esses dois valores na fórmula, e isso lhe daria uma fórmula altamente explícita, embora meio complicada, para uma curva que deveria se ajustar perfeitamente à nossa distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "Mas há outra maneira de descrevê-lo que é um pouco mais elegante e se presta a um visual muito divertido que podemos desenvolver. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "Em vez de focar na soma de todas essas variáveis aleatórias, vamos modificar um pouco esta expressão, onde o que faremos é olhar para a média que esperamos que essa soma tenha, e subtraí-la para que nossa nova expressão tem média 0, e então vamos olhar para o desvio padrão que esperamos de nossa soma e dividir por ele, o que basicamente apenas redimensiona as unidades para que o desvio padrão de nossa expressão seja igual a 1 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "Pode parecer uma expressão mais complicada, mas na verdade tem um significado altamente legível. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "Basicamente, está dizendo a quantos desvios padrão da média está essa soma? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "Por exemplo, esta barra aqui corresponde a um certo valor que você pode encontrar quando você joga 10 dados e soma todos eles, e sua posição um pouco acima de 1 negativo indica que esse valor é um pouco menor que um desvio padrão inferior à média. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "Além disso, a propósito, em antecipação à animação que estou tentando construir aqui, a forma como estou representando as coisas naquele gráfico inferior é que a área de cada uma dessas barras está nos dizendo a probabilidade do valor correspondente em vez da altura. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "Você pode pensar no eixo y como representando não uma probabilidade, mas um tipo de densidade de probabilidade. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "A razão para isto é preparar o cenário para que se alinhe com a forma como interpretamos as distribuições contínuas, onde a probabilidade de cair entre um intervalo de valores é igual a uma área sob uma curva entre esses valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "Em particular, a área de todas as barras juntas será 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "Agora, com tudo isso preparado, vamos nos divertir um pouco. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "Deixe-me começar revertendo as coisas para que a distribuição na parte inferior represente uma soma relativamente pequena, como somar apenas três dessas variáveis aleatórias. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "Observe o que acontece quando mudo a distribuição com a qual começamos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "À medida que muda, a distribuição na parte inferior muda completamente de forma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "Depende muito do que começamos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "Se deixarmos o tamanho da nossa soma aumentar um pouco, digamos, indo até 10, e conforme eu mudo a distribuição de x, ela permanece em grande parte parecida com uma curva em forma de sino, mas posso encontrar algumas distribuições que fazem com que ela mude de forma . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "Por exemplo, a curva realmente assimétrica, onde quase toda a probabilidade está nos números 1 ou 6, resulta neste tipo de curva em forma de sino pontiaguda e, se você se lembra, anteriormente eu mostrei isso na forma de uma simulação. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "Então, se você está se perguntando se esse pico é um artefato da aleatoriedade ou reflete a verdadeira distribuição, acontece que ele reflete a verdadeira distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "Neste caso, 10 não é uma soma suficientemente grande para que o teorema do limite central entre em ação. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "Mas se, em vez disso, eu deixar essa soma crescer e considerar adicionar 50 valores diferentes, o que na verdade não é tão grande, então não importa como eu altere a distribuição da nossa variável aleatória subjacente, isso essencialmente não terá nenhum efeito na forma do gráfico no fundo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "Não importa por onde comecemos, todas as informações e nuances da distribuição de x são eliminadas e tendemos para esta forma universal única descrita por uma função muito elegante para a distribuição normal padrão, 1 sobre a raiz quadrada de 2 pi vezes e para o negativo x ao quadrado sobre 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "É disso que trata o teorema do limite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "Quase nada que você possa fazer com essa distribuição inicial muda a forma que tendemos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "Agora, os mais teóricos entre vocês ainda podem estar se perguntando: qual é o teorema real? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "Tipo, qual é a afirmação matemática que poderia ser provada ou refutada que estamos afirmando aqui? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "Se você quiser uma declaração formal agradável, veja como pode ser. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "Considere este valor, onde estamos somando n instanciações diferentes de nossa variável aleatória, mas ajustados e ajustados para que sua média e desvio padrão sejam 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "Novamente, o que significa que você pode ler isso como uma pergunta a quantos desvios padrão da média está a soma. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "Então, a afirmação rigorosa e rigorosa e sem piadas desta vez do teorema do limite central é que se você considerar a probabilidade de que esse valor caia entre dois números reais dados, a e b, e considerar o limite dessa probabilidade como o tamanho de sua soma vai até o infinito, então esse limite é igual a uma certa integral, que basicamente descreve a área sob uma distribuição normal padrão entre esses dois valores. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "Novamente, há três suposições subjacentes que ainda não lhes contei, mas além dessas, em todos os seus detalhes sangrentos, este aqui é o teorema central do limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "Tudo isso é um pouco teórico, então pode ser útil trazer as coisas de volta à Terra e voltar ao exemplo concreto que mencionei no início, onde você imagina jogar um dado 100 vezes, e vamos supor que seja um dado justo. para este exemplo, e você soma os resultados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "O desafio para você é encontrar um intervalo de valores tal que tenha 95% de certeza de que a soma estará dentro desse intervalo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "Para questões como essa, existe uma regra prática sobre distribuições normais, que diz que cerca de 68% dos seus valores ficarão dentro de um desvio padrão da média, 95% dos seus valores, aquilo que nos interessa, ficarão dentro dois desvios padrão da média e impressionantes 99.7% dos seus valores ficarão dentro de três desvios padrão da média. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "É uma regra prática comumente memorizada por pessoas que fazem muitas probabilidades e estatísticas. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "Naturalmente, isso nos dá o que precisamos para o nosso exemplo, e deixe-me prosseguir e desenhar como seria, onde mostrarei a distribuição para um dado justo no topo, e a distribuição para uma soma de 100 esses dados na parte inferior, que agora, como você sabe, parece uma certa distribuição normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "O primeiro passo com um problema como este é encontrar a média de sua distribuição inicial, que neste caso será semelhante a 1 6 vezes 1 mais 1 6 vezes 2 e assim por diante, e resulta em 3.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "Também precisamos do desvio padrão, que requer o cálculo da variância, que, como você sabe, envolve a soma de todos os quadrados das diferenças entre os valores e as médias, e resulta em 2.92, a raiz quadrada disso resulta em 1.71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "Esses são os únicos dois números de que precisamos, e vou convidá-lo novamente a refletir sobre como é mágico que esses sejam os únicos dois números de que você precisa para compreender completamente a distribuição inferior. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "Sua média será 100 vezes mu, que é 350, e seu desvio padrão será a raiz quadrada de 100 vezes sigma, ou seja, 10 vezes sigma 17.1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "Lembrando nossa regra prática, estamos procurando valores a dois desvios padrão da média, e quando você subtrai 2 sigma da média você acaba com cerca de 316, e quando você adiciona 2 sigma você acaba com 384. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "E aí está, isso nos dá a resposta. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "Ok, prometi encerrar as coisas em breve, mas enquanto estamos neste exemplo, há mais uma questão que vale a pena ponderar. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "Em vez de apenas perguntar sobre a soma de 100 lançamentos de dados, digamos que você divida esse número por 100, o que basicamente significa que todos os números em nosso diagrama na parte inferior são divididos por 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "Reserve um momento para interpretar o que tudo isso estaria dizendo então. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "A expressão essencialmente informa a média empírica para 100 lançamentos de dados diferentes, e o intervalo que encontramos agora informa qual intervalo você espera ver para essa média empírica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "Em outras palavras, você pode esperar que seja em torno de 3.5, esse é o valor esperado para uma jogada de dado, mas o que é muito menos óbvio e o que o teorema do limite central permite calcular é o quão próximo desse valor esperado você estará razoavelmente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "Em particular, vale a pena dedicar um momento para refletir sobre qual é o desvio padrão dessa média empírica e o que acontece com ele quando você olha para uma amostra cada vez maior de lançamentos de dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "Por último, mas provavelmente o mais importante, vamos falar sobre as suposições deste teorema. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "A primeira é que todas essas variáveis que estamos somando são independentes umas das outras. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "O resultado de um processo não influencia o resultado de qualquer outro processo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "A segunda é que todas essas variáveis são extraídas da mesma distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "Ambos foram assumidos implicitamente em nosso exemplo dos dados. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "Estamos tratando o resultado de cada lançamento de dado como independente do resultado de todos os outros e estamos assumindo que cada dado segue a mesma distribuição. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "Às vezes, na literatura, você verá essas duas suposições agrupadas sob as iniciais IID para independentes e distribuídas de forma idêntica. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "Uma situação em que estas suposições decididamente não são verdadeiras seria no conselho de Galton. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "quero dizer, pense sobre isso. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "Será que o modo como uma bola rebate em um dos pinos é independente de como ela irá ricochetear no próximo pino? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "Absolutamente não. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "Dependendo do último salto, ele chega com uma trajetória completamente diferente. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "E será que a distribuição dos resultados possíveis de cada pino é a mesma para cada pino atingido? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "Novamente, quase certamente não. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "Talvez acerte um pino olhando para a esquerda, o que significa que os resultados são enormemente distorcidos nessa direção, e depois acerte o próximo, olhando para a direita. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "Quando fiz todas essas suposições simplificadoras no exemplo inicial, não foi apenas para facilitar a reflexão. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "É também que essas suposições eram necessárias para que este fosse realmente um exemplo do teorema central do limite. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "No entanto, parece ser verdade que para o tabuleiro real de Galton, apesar de violar ambos, uma distribuição normal surge? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "Parte da razão pode ser que existem generalizações do teorema além do escopo deste vídeo que relaxam essas suposições, especialmente a segunda. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "Mas quero alertá-lo contra o fato de que muitas vezes as pessoas parecem assumir que uma variável é normalmente distribuída, mesmo quando não há nenhuma justificativa real para fazê-lo. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "A terceira suposição é, na verdade, bastante sutil. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "É que a variância que estamos calculando para essas variáveis é finita. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "Isto nunca foi um problema para o exemplo dos dados, porque havia apenas seis resultados possíveis. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "Mas em certas situações em que você tem um conjunto infinito de resultados, quando você calcula a variância, a soma acaba divergindo para o infinito. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "Estas podem ser distribuições de probabilidade perfeitamente válidas e surgem na prática. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "Mas nessas situações, ao considerar adicionar muitas instanciações diferentes dessa variável e deixar que a soma se aproxime do infinito, mesmo que as duas primeiras suposições sejam válidas, é muito provável que aquilo para o qual você tende não seja realmente uma distribuição normal. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "Se você entendeu tudo até agora, agora você tem uma base muito sólida sobre o que é o teorema do limite central. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "E a seguir, gostaria de explicar por que essa função em particular é aquilo para o qual tendemos, e por que ela contém um pi, o que ela tem a ver com círculos. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]