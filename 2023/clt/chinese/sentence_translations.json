[
 {
  "input": "This is a Galton board. ",
  "translatedText": "这是高尔顿板。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "也许您以前看过一个，这是一个流行的演 示，说明即使单个事件是混乱和随机的，其结果实际 上是不可知的，仍然可以对大量事件做出精确的陈述 ，即相对比例如何对于许多不同的结果是分布的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "更具体地说，高尔顿板说明了所有概率中最突出的 分布之一，称为正态分布，更通俗地称为钟形曲线 ，也称为高斯分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "有一个非常具体的函数来描述这个分 布，它非常漂亮，我们稍后会介绍它，但现在我只想强调正态 分布是如何的，顾名思义，非常常见，它出现在很多地方看似 不相关的上下文。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "如果您要选取大量具有相似人口统计特征的人 并绘制他们的身高，那么这些身高往往遵循正态分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "如果您 查看一大堆非常大的自然数，并询问每个数字有多少 个不同的质因数，答案将非常接近某种正态分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "现在我们今天的主题是所有概率论中的皇冠上的宝石之一，它是 解释为什么这种分布如此普遍的关键事实之一，称为中心极限定 理。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "本课旨在回到基础知识，为您提供有关中心极限定理的 含义、正态分布是什么的基础知识，并且我想假设最少的背 景。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "我们将深入探讨它，但在此之后我仍然想更深入地解释为什么该 定理是正确的，为什么正态分布背后的函数具有它所具有的非常具体 的形式，为什么该公式具有其中有一个 pi，最有趣的是，为什么最 后两个事实实际上比许多传统解释所暗示的更相关。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "第二课也是我 承诺的卷积视频的后续课程，因此这里有很多相互关 联的主题。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "但现在，回到基础知识，我想从一个过于简 化的高尔顿板模型开始。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "在这个模型中，我们假设每个球直 接落到某个中心钉上，并且它有 50-50 的概率向左或向 右弹跳，并且我们将这些结果中的每一个视为添加一个或从其 位置减一。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "一旦选择了其中一个，我们就会做出一个非常不切实际的假设 ，即它恰好落在与其下方相邻的钉子的中间，在那里它将再次面临相同的 50-50 选择：向左弹跳或向左弹跳向右。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "对于我在屏幕上显示的 那个，有五排不同的钉子，因此我们的小跳球在加一和减一之间做 出五种不同的随机选择，我们可以将其最终位置视为基本上是所 有位置的总和这些不同的数字，在本例中恰好是一个，我们可以 用它们代表的总和来标记所有不同的桶。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "当我们重复这一点时，我们 正在研究这五个随机数的不同可能总和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "对于那些倾向于抱怨对于真正 的高尔顿板来说这是一个非常不切实际的模型的人，让我强调一下，现 在的目标不是精确地模拟物理。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "目标是给出一个简单的例子来说明中心 极限定理，为此，尽管这可能是理想化的，但它实际上给了我们一个非 常好的例子。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "如果我们让许多不同的球落下，做出另一个不切实际的假 设，即它们不会像幽灵一样互相影响，那么落入每个不同桶中的球的数 量会让我们对每个球的可能性有一些松散的感觉这些桶中的一个是。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "在此示例中，数字非常简单，因此明确计算落 入每个桶的概率并不难。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "如果你确实想仔细想一下，你会 发现它很容易让人想起帕斯卡三角形。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "但我们的定理的巧妙之处在 于它远远超出了简单的例子。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "因此，至少首先，我们不进行显 式计算，而是通过运行大量样本来模拟事物，并让每个 不同结果中的结果总数让我们对分布的样子有所了解。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "正如我所说，屏幕上的数字有五行，因此我们正在考虑的每个总和仅包含五 个数字。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "中心极限定理的基本思想是，如果增加该总和的 大小，例如这里，这意味着增加每个球反弹的钉子行 数，则描述该总和的分布秋天看起来越来越像钟形曲 线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "在这里，实际上值得花点时间写下这个总体想法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "设置是 我们有一个随机变量，这基本上是随机过程的简写，其中该过 程的每个结果都与某个数字相关联。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "我们将这个随机数称为 x。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "例如 ，每次从挂钩上反弹都是一个随机过程，建模有两个结果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "这些结果 与数字负一和正一相关。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "随机变量的另一个例子是 掷骰子，其中有六个不同的结果，每个结果都与一个数字相关联 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "我们正在做的是获取该变量的多个不同样本并将它们全部加在 一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "在我们的高尔顿棋盘上，这看起来就像让球在向下到达底部的过程中从 多个不同的钉子上反弹，而在骰子的情况下，您可能会想象滚动许多不同的骰 子并将结果相加。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "中心极限定理的主张是，当您让该和的大小 变得越来越大时，该和的分布，即落入不同可能值的可 能性，将看起来越来越像钟形曲线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "就是这样，这就是总体想法 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "在本课中，我们的工作是使该陈述更加量化。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "我们 将在其中添加一些数字，添加一些公式，展示如何使用它来进行预测。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "例如，我希望您能够在本视频结束时回答以下问题。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "假设您掷骰子 100 次，并将结果相加。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "您能否找到一个值范围 ，使得您有 95% 的把握确定总和落在该范围内？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "或者也许我应该说 找到最小可能的值范围以使这是正确的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "有趣的是，无论是公平骰 子还是加权骰子，您都可以回答这个问题。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "现在让我在顶部 说这个定理包含三个不同的假设，在定理成立之前必须满 足三个条件。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "事实上，直到视频最后我才会告诉你它们 是什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "相反，我希望你留意，看看你是否能注意到并预 测这三个假设将会是什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "下一步，为了更好地说明这个 定理的普遍性，我想为您运行更多模拟，重点关注骰子示例 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "通常，如果您想到掷骰子，您会认为六种结果的可能性相同 ，但该定理实际上并不关心这一点。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "我们可以从加权骰子开始， 这种骰子的结果具有非平凡的分布，并且核心思想仍然成立。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "对 于模拟，我要做的就是采用一些像这样偏向较低值的分 布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "我将从该分布中抽取 10 个不同的样本，然后将该样 本的总和记录在底部的图上。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "然后我将多次执行此操作，总和 始终为 10，但要跟踪这些总和的最终结果，以便让我们 了解分布情况。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "事实上，让我重新调整 y 方向，以便为我们提供 运行更多样本的空间。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "我会让它一直到几千，当它这样做时，你 会注意到开始出现的形状看起来像钟形曲线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "也许如果你眯 起眼睛，你会发现它向左倾斜了一点点，但从如此不对称的起点 出现如此对称的东西是很巧妙的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "为了更好地说明中心极限定理 的含义，让我并行运行四个模拟，在左上角，我们一次只添加两个骰 子，在右上角，我们'我们一次添加 5 个骰子，左下角 是我们刚刚看到一次添加 10 个骰子的骰子，然后我们将再做另 一个，每次添加 15 个骰子，其总和更大。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "请注意，当我们仅 添加两个骰子时，在左上角，所得的分布实际上看起来并不像 钟形曲线，它看起来更让人想起我们开始向左倾斜的分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "但是，随着我们在每个总和中允许越来越多的骰子，这些分布中出现的 最终形状看起来越来越对称。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "它的中间有一个肿块，并逐渐向尾部的钟形 曲线形状逐渐消失。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "让我再次强调，您可以从任何不同的发行版开始。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "在这里，我将再次运行它，但大部分概率都与数字 1 和 6 相关，中间值的概率非常低。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "尽管完全改变了单个骰子的 分布，但当我们考虑不同的总和时，钟形曲线形状 仍然会出现。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "用这样的模拟来说明事物非常有趣，而且看到秩序 从混乱中显现出来的感觉很整洁，但也感觉有点不精确。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "就像在本例 中一样，当我在 3000 个样本处停止模拟时，尽管它看起来像钟形曲 线，但不同的桶看起来相当尖峰。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "您可能想知道，它应该看起来像那 样吗？或者这只是模拟中随机性的产物？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "如果是的话，我们需 要多少样本才能确定我们所看到的数据代表了真实的分布？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "相反，让我们更深入地了解一下理论，并展示这些分布从长远 来看将呈现的精确形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "进行此计算的最简单情况是，如果我们有 均匀分布，其中骰子的每个可能的面都具有相等的概率，即 1 6 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "例如，如果您想知道一对骰子的总和不同的可能性有多大，这本质 上是一个计数游戏，您可以在其中计算有多少个不同的骰子对具 有相同的总和，在我绘制的图表中，您可以通过遍历所有不同的对 角线来方便地思考。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "由于每一对出现的机会均等（三十六分之一） ，因此您所要做的就是计算这些桶的大小。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "这为我们提供了描述两 个骰子之和的分布的明确形状，如果我们用所有可能的三元组 玩同一个游戏，得到的分布将如下所示。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "现在更具挑战性， 但更有趣的是，如果我们对单个芯片的分布不均匀，会发生什 么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "我们实际上在上一个视频中讨论了所有这些。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "你本质上做的是同样的 事情，你遍历所有不同的骰子对，它们加起来的值相同。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "只是， 不是计算这些对，而是对于每一对，将每个特定面孔出现的两 个概率相乘，然后将所有这些加在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "对所有可能的总和执 行此操作的计算有一个奇特的名称，称为卷积，但它本质上 只是计数游戏的加权版本，任何玩过一对骰子的人都已经 熟悉了。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "为了本课的目的，我将让计算机计算所有这些，简单地 为您显示结果，并邀请您观察某些模式，但在幕后，这就是正 在发生的事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "因此，为了清楚地了解此处所表示的内容，如 果您想象从顶部分布中采样两个不同的值（描述单个芯片的值 ）并将它们加在一起，那么我绘制的第二个分布代表了您的可 能性看到各种不同的金额。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "同样，如果您想象从顶部分布中 采样三个不同的值，并将它们加在一起，下一个图表示在这 种情况下各种不同总和的概率。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "因此，如果我计算这些和的 分布对于越来越大的和，你知道我要说什么，它看起来越来 越像钟形曲线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "但在我们开始讨论之前，我希望您做一些更简单的 观察。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "例如，这些分布似乎向右漂移，而且它们似乎 变得更加分散，并且更加平坦。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "如果不考虑这两种 影响，就无法定量地描述中心极限定理，而这又 需要描述平均值和标准差。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "也许您已经熟悉这些内容，但 我想在这里做出最少的假设，回顾一下也没什么坏处，所以让我们快速 浏览一下这两个内容。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "分布的均值通常用希腊字母 mu 表示，是捕获该分布质心的一种方法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "它被计算为 随机变量的期望值，这表示您经历了所有不同 的可能结果，并将该结果的概率乘以变量的值 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "如果更高的值更有可能出现，那么加权和就会更大。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "如果较 低值的可能性更大，则加权和将会更小。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "更有趣的是，如果 您想测量这种分布的分布程度，因为您可以通过多种不 同的方式来实现。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "其中之一称为方差。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "其想法是查看每个 可能值与平均值之间的差异，计算差异的平方，并求出其期 望值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "这个想法是，无论您的值低于还是高于平均值，当您对差值 进行平方时，您都会得到一个正数，并且差值越大，该数字就越大。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "事实证明，像这样对它进行平方使得数学比我们做绝对值之类 的事情要好得多，但缺点是很难将其视为图表中的距离，因为 单位不正确。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "有点像这里的单位是平方单位，而我们图中的 距离是一种线性单位。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "因此，衡量传播的另一种方法是所谓的 标准差，它是该值的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "这可以更合理地解释为我们图表上的 距离，并且通常用希腊字母 sigma 表示，因此您知道 m 代表 平均值和标准差，但都是希腊语。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "回顾我们的分布序列，让我们 讨论一下平均值和标准差。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "如果我们将初始分布的均值称为 mu ，如图所示，它恰好是 2。24、如果我告诉你下一个的平均值是 2 倍 mu，希望你不会太惊讶。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "也就是说，你掷一对骰子，你想知 道总和的期望值，它是单个骰子期望值的两倍。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "同样，大 小 3 的总和的期望值是 3 乘以 mu，依此类推。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "均值稳 定地向右移动，这就是为什么我们的分布似乎朝那个方向 漂移。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "更具挑战性但非常重要的是描述标准差如何 变化。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "这里的关键事实是，如果有两个不同的随机变 量，那么这些变量之和的方差与将原始两个方差相加相 同。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "这是您在解压所有定义时可以计算的事实之一。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "对于为什么这是真的，有一些很好的直觉。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "我的暂定计划是制作一系列有 关概率的内容，并讨论诸如方差及其表兄弟背后的直觉之类的 事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "但现在，我想让你强调的主要事情是方差是如何增加 的，而不是标准差是如何增加的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "因此，至关重要的是，如果 您要对同一随机变量采取 n 个不同的实现，并询问其总和，则 该总和的方差是原始变量方差的 n 倍，这意味着标准差，即 所有变量的平方根这是原始标准差 n 倍的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "例如，回 到我们的分布序列中，如果我们用 sigma 标记初始分布 的标准差，那么下一个标准差将是 2 倍 sigma 的平 方根，之后它看起来像3 倍西格玛，依此类推。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "正如我所说，这一 点非常重要。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "这意味着即使我们的分布正在扩散，但它们的扩散 速度并没有那么快，它们只是与总和大小的平方根成比例。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "当我们准备对中心极限定理进行更定量的描述时，我希望您 牢记的核心直觉是，我们基本上将重新调整所有这些分布，使 它们的均值排列在一起，然后重新调整它们的比例，以便所 有标准差都将等于 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "当我们这样做时，产生的形状越来越 接近某种通用形状，用一个优雅的小函数来描述，我们稍后会 解压它。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "让我再说一遍，这里真正的魔力在于我们如何从 任何分布开始，描述骰子的一掷，如果我们玩同一个游戏 ，考虑许多不同总和的分布是什么样的，我们重新调整它 们，使平均值对齐，重新调整它们，使标准差全部为 1 ，我们仍然接近相同的通用形状，这有点令人难以置信。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "我的朋友们，现在可能是最终了解正态分布公式的最佳时 机。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "我想要做到这一点的方法是基本上剥离所有层并一次将 其构建起来。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "函数 e 与 x 的关系，或任何与 x 关系的 函数，描述了指数增长，如果将该指数设为负值（水平翻转图形）， 您可能会认为它描述的是指数衰减。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "为了使这种衰减在两个方 向上，您可以采取一些措施来确保指数始终为负并且不断增 长，例如取负绝对值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "这会给我们带来这种中间尴尬的 尖点，但如果你将该指数设为 x 的负平方，你会 得到同一事物的更平滑版本，它在两个方向上衰减。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "这给了我们基本的钟形曲线形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "现在，如果您在该 x 前面添加一 个常数，并上下缩放该常数，它可以让您水平拉伸和挤压图形，从而 允许您描述狭窄和更宽的钟形曲线。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "我想在这里指出的一件事是 ，根据求幂规则，当我们围绕常数 c 进行调整时，您也 可以将其视为简单地更改求幂的底数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "从这个意义上说，数字 e 对 于我们的公式来说并不是那么特别。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "我们可以用任何其他正常数替换它，当 我们调整该常数时，您将得到相同的曲线族。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "使其成为 2 个相同的曲 线族。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "使其成为 3 个相同的曲线族。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "我们使用 e 的原因是它赋予该常量 非常可读的含义。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "或者更确切地说，如果我们稍微重新配置一下， 使指数看起来像负二分之一 x 除以某个常数（我们建议将其 称为 sigma 平方），那么一旦我们将其转换为概率分布， 该常数 sigma 将是该分布的标准差。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "这非常好。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "但在 我们将其解释为概率分布之前，我们需要曲线下面积为 1 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "其原因在于曲线的解释方式。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "与离散分布不同， 当涉及连续分布时，您不会询问特定点的概率。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "相反，您要求一个值落在两个不同值之间的概率。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "曲线告 诉您的是，概率等于曲线下这两个值之间的面积 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "还有一个关于此的完整其他视频，它们被称为概率密度函数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "现在的要点是，整条曲线下方的面积代表某件事发生、 某个数字出现的概率。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "那应该是 1，这就是为什么我们希望它下面的面 积是 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "由于 e 到负 x 平方的基本钟形曲线形状，面积不是 1，它实际上是 pi 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "我知道，对吧？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "pi 在这里做什么？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "这和 圈子有什么关系？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "就像我在开始时所说的那样，我很乐意在下一个视频中讨论所有这 些内容。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "但如果你现在能不为我们的目的而兴奋，这意味着我们应该用这 个函数除以 pi 的平方根，它就给出了我们想要的面积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "回溯我 们之前的常数，即 1 的一半和 sigma，其效果是将图形拉 伸 sigma 乘以 2 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "所以我们还需要除以它 以确保它的面积为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "将这些分数组合起来，前面的因子看起来就像 1 除以 sigma 乘以 2 pi 的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "最后，这是一个有效的概率 分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "当我们调整该值 sigma 时，会产生更窄和更宽的曲 线，前面的常数始终保证面积等于 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "sigma 等于 1 的 特殊情况有一个特定的名称，我们称之为标准正态分布，它在本课中 对你和我起着特别重要的作用。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "所有可能的正态分布不仅用这个值 sigma 进行参数化，而且我们还从变量 x 中减去 另一个常数 mu，这本质上只是让您左右滑动图形，以便您可 以指定该分布的平均值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "简而言之，我们有两个参数，一个描述平均 值，一个描述标准差，它们都在这个涉及 e 和 pi 的大公式 中联系在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "现在所有这些都已摆在桌面上，让我们再次回顾 一下从某个随机变量开始并询问该变量之和的分布是什么样的想 法。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "正如我们已经讨论过的，当您增加该总和的大小时，所 得分布将根据不断增长的均值而变化，并根据不断增长的标 准差缓慢展开。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "加上一些实际的公式，如果我们知道基础随机变量 的平均值，我们称之为 mu，我们也知道它的标准差，我们称之 为 sigma，那么底部总和的平均值将是 mu乘以总和的大 小，标准差将是西格玛乘以该大小的平方根。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "所以现在，如果我们想 要声称这看起来越来越像钟形曲线，并且钟形曲线仅由两个不同的参 数（均值和标准差）描述，那么您知道该怎么做。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "您可以将这两个 值代入公式中，它会为您提供一个高度明确（尽管有点复 杂）的曲线公式，该曲线应该与我们的分布密切相关。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "但我们可以用另一种方式来描述它，这种方式更优雅，并且适合我们构 建非常有趣的视觉效果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "我们不要关注所有这些随机变量的总和， 而是稍微修改一下这个表达式，我们要做的是查看我们期望该总 和的平均值，然后将其减去，以便我们的新表达式的平均值为 0，然后我们将查看我们期望的总和的标准差，然后除以该值， 这基本上只是重新调整单位，以便我们的表达式的标准差等于 1 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "这可能看起来是一个更复杂的表达，但它实际上具有很 高的可读性。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "本质上是说这个总和与平均值相差多少个标准 差？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "例如，这里的这个条对应于您在掷 10 个骰子并 将它们全部加起来时可能会发现的某个值，并且它的位置略 高于负 1 告诉您该值略小于一个标准差低于平均值。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "另外，顺便说一句，为了预期我要在这里构建的动画，我在 较低的图上表示事物的方式是，每个条形的面积告诉我们 相应值的概率而不是高度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "您可能认为 y 轴代表的不是 概率，而是一种概率密度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "这样做的原因是设置阶段，使其 与我们解释连续分布的方式保持一致，其中落在一系列值 之间的概率等于这些值之间的曲线下的面积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "特别是， 所有条形的面积合计为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "现在，所有这些都已就绪，让我们来玩点乐 趣吧。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "让我首先回滚一些东西，以便底部的分布代表一个相对较小 的总和，就像只将三个这样的随机变量加在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "请注意当我更改 我们开始的分布时会发生什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "随着它的变化，底部的分布完全改变了 它的形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "这很大程度上取决于我们从什么开始。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "如果我们让总和的大小变 大一点，比如说达到 10，当我改变 x 的分布时，它基本 上看起来像钟形曲线，但我可以找到一些分布来改变形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "例如 ，几乎所有概率都在数字 1 或 6 中的真正不平衡曲线会导致这种 尖尖的钟形曲线，如果您还记得的话，早些时候我实际上以模拟的形式展 示了这一点。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "因此，如果您想知道这种尖峰是否是随机性的产 物或反映了真实分布，那么事实证明它反映了真实分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "在这种情况下，10 的总和不足以让中心极限定理发挥作用。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "但是，如果 我让这个总和增长，并且考虑添加 50 个不同的值（实际上并没 有那么大），那么无论我如何更改基础随机变量的分布，它基本上对 图上的图的形状没有影响底部。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "无论我们从哪里开始，x 分布的所有 信息和细微差别都会被冲走，我们倾向于用标准正态分布的一个非常优雅的 函数来描述这个单一的通用形状，即 1 除以 2 pi 乘以 e 的 平方根到 2 的负 x 平方。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "这，这就是中心极限定理的 意义所在。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "你几乎无法对这个初始分布做任何改变我们倾向于 的形状。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "现在，你们中更有理论头脑的人可能仍然想知道，实 际的定理是什么？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "比如，我们在这里声明的可以被证明或反驳 的数学陈述是什么？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "如果您想要一份漂亮的正式声明，可以按以下方式进行。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "考虑这个值，我们对随机变量的 n 个不同实例求和，但进 行了调整，使其平均值和标准差均为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "同样，这意味着您 可以将其理解为询问与平均值相距多少个标准差是总和。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "那么，中心 极限定理的实际严格的严肃陈述是，如果您考虑该值落在 两个给定实数 a 和 b 之间的概率，并且将该概率 的极限视为如果您的总和趋于无穷大，则该极限等于某个积 分，该积分基本上描述了这两个值之间的标准正态分布下 的面积。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "再说一次，我还没有告诉你三个基本假设，但除 此之外，在所有血淋淋的细节中，这就是中心极限定理。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "所有这些都有点理论化，因此将事情带回到现实并回到我在开始时 提到的具体示例可能会有所帮助，其中您想象将骰子滚动 10 0 次，让我们假设这是一个公平的骰子对于本示例，您将结果 相加。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "您面临的挑战是找到一个值范围，以便 95% 确 定总和将落在该范围内。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "对于这样的问题，有一个关于正态分布的 方便的经验法则，即大约 68% 的值将落在平均值的一个标准差范 围内，95% 的值（我们关心的事情）落在平均值的一个标准差范围 内平均值的两个标准差，高达 99。7% 的值将落在平均值的三 个标准差范围内。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "这是进行大量概率和统计分析的人通常会 记住的经验法则。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "当然，这为我们提供了示例所需的内容 ，让我继续画出它的样子，其中我将在顶部显示公平骰子 的分布，以及总和为 100 的分布底部的骰子，现在 你知道它看起来像某种正态分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "解决此类问题的第一步是找到 初始分布的均值，在本例中，该均值看起来像 1 6 次乘以 1 加 1 6 次乘以 2 等等，结果为 3。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "5.我们还需要标准差，这 需要计算方差，正如您所知，这涉及到将值与平均值之 间的差值的所有平方相加，结果为 2。92，平方根 为 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "71.这是我们唯一需要的两个数字，我将再次邀请 您思考一下，这是您完全理解底部分布所需的唯一两个数字 ，这是多么神奇。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "其均值将是 100 倍 mu，即 350，其标准差将是 100 倍 sigma 的平方根，即 10 倍 sigma 17。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "1.记住我们方便 的经验法则，我们正在寻找距平均值两个标准差的值，当你从平均值中减去 2 西格玛时，你最终得到大约 316，当你加上 2 西格玛时，你 最终得到 384。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "就这样，这给了我们答案。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "好的，我答应很快就会结束事情，但是当我们讨论这个例子时，还有一 个问题值得您花时间思考。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "不只是询问 100 次骰子的总和， 假设我让你将该数字除以 100，这基本上意味着底部图表中的 所有数字都除以 100。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "花点时间解释一下这一切到底意味着什么 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "该表达式本质上告诉您 100 个不同骰子的经验平均值 ，而我们发现的区间现在告诉您您期望看到该经验平均值的范围 。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "换句话说，您可能期望它在 3 左右。5，这是掷骰子的期望 值，但不太明显的是中心极限定理让您计算的是您将合理 地发现自己与该期望值的接近程度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "特别是，值得您花 点时间思考这个经验平均值的标准差是多少，以及 当您查看越来越大的骰子样本时它会发生什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "最后，但可能也是最重要的，让我们讨论一下该定理的假设。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "第一个是我们添加的所有这些变量都是相互独立的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "一个过程的结果不会影响任何其他过程的结果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "第二个是所有这些变量都来自相同的分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "我们的骰子示例已隐含地假设了这两者。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "我们一直将每个骰子的 结果视为独立于所有其他骰子的结果，并且我们假设每个骰子 都遵循相同的分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "有时在文献中，您会看到这两个假 设集中在缩写 IID 下，表示独立和同分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "这些假设显然不成立的一种情况是高尔顿板。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "我想说的是，考虑一下。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "球从一个钉子上弹起的方式是否与它从 下一个钉子上弹起的方式无关？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "绝对不。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "根据最后一 次的弹跳，它会以完全不同的轨迹进入。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "每个挂钩的可 能结果分布是否与它所触及的每个挂钩相同？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "再说一 遍，几乎肯定不会。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "也许它击中了一个向左看的钉子，这意味着结果 在那个方向上严重倾斜，然后又击中了向右看的下一个钉子。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "当我在开头的示例中做出所有这些简化假设时，不仅仅是为了让这个 问题更容易思考。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "而且这些假设对于这实际上是中心极限定 理的一个例子也是必要的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "然而，对于真正的高尔顿板来 说，尽管违反了这两个条件，但似乎确实会出现正态分布 ？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "部分原因可能是该定理的概括超出了本视频的范围 ，放松了这些假设，尤其是第二个假设。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "但我确实想 提醒您注意这样一个事实：很多时候人们似乎认为变量是 正态分布的，即使没有实际理由这样做。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "第三个假设实际上 相当微妙。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "我们计算这些变量的方差是有限的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "对于骰子的例子来说，这从来都不是问题，因为只有六种可能的结果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "但在某些情况下，如果你有无限组结果，当你计算方差时 ，总和最终会发散到无穷大。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "这些可能是完全有效的概率分布 ，并且它们确实在实践中出现。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "但在这些情况下，当您考虑 添加该变量的许多不同实例并让总和接近无穷大时， 即使前两个假设成立，您倾向于的东西实际上很可 能不是正态分布。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "如果到目前为止您已经理解了所有内容，那么您 现在对中心极限定理的含义已经有了非常坚实的基础。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "接下来，我 想解释为什么这个特定的函数是我们所倾向于的 ，为什么它有一个 pi，它与圆有什么关系。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]