[
 {
  "input": "This is a Galton board. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 1.26
 },
 {
  "input": "Maybe you've seen one before, it's a popular demonstration of how, even when a single event is chaotic and random, with an effectively unknowable outcome, it's still possible to make precise statements about a large number of events, namely how the relative proportions for many different outcomes are distributed. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.52,
  "end": 18.3
 },
 {
  "input": "More specifically, the Galton board illustrates one of the most prominent distributions in all of probability, known as the normal distribution, more colloquially known as a bell curve, and also called a Gaussian distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.38,
  "end": 31.9
 },
 {
  "input": "There's a very specific function to describe this distribution, it's very pretty, we'll get into it later, but right now I just want to emphasize how the normal distribution is, as the name suggests, very common, it shows up in a lot of seemingly unrelated contexts. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.5,
  "end": 45.04
 },
 {
  "input": "If you were to take a large number of people who sit in a similar demographic and plot their heights, those heights tend to follow a normal distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.02,
  "end": 53.0
 },
 {
  "input": "If you look at a large swath of very big natural numbers and you ask how many distinct prime factors does each one of those numbers have, the answers will very closely track with a certain normal distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.66,
  "end": 64.96
 },
 {
  "input": "Now our topic for today is one of the crown jewels in all of probability theory, it's one of the key facts that explains why this distribution is as common as it is, known as the central limit theorem. ",
  "translatedText": "นี่คือบอร์ด Galton บางทีคุณอาจเคยเห็นมาก่อน มันเป็นการสาธิตที่ได้รับความนิยมว่า แม้ว่าเหตุการณ์เดียวจะวุ่นวายและสุ่มตัวอย่าง โดยให้ผลลัพธ์ที่ไม่อาจทราบได้อย่างมีประสิทธิภาพ แต่ก็ยังเป็นไปได้ที่จะระบุข้อความที่แม่นยำเกี่ยวกับเหตุการณ์จำนวนมาก กล่าวคือ สัดส่วนสัมพัทธ์อย่างไร เพราะผลลัพธ์ที่แตกต่างกันมากมายจะถูกกระจายออกไป โดยเฉพาะอย่างยิ่ง กระดาน Galton แสดงให้เห็นการแจกแจงที่โดดเด่นที่สุดครั้งหนึ่งในความน่าจะเป็นทั้งหมด เรียกว่าการแจกแจงแบบปกติ หรือที่เรียกขานว่าเส้นโค้งระฆัง และเรียกอีกอย่างว่าการแจกแจงแบบเกาส์เซียน มีฟังก์ชันเฉพาะเจาะจงมากในการอธิบายการแจกแจงนี้ มันสวยมาก เราจะพูดถึงมันทีหลัง แต่ตอนนี้ ผมแค่อยากจะเน้นว่าการแจกแจงแบบปกติเป็นอย่างไร ดังที่ชื่อบอก เป็นเรื่องธรรมดามาก มันปรากฏให้เห็นบ่อยมาก จากบริบทที่ดูเหมือนไม่เกี่ยวข้องกัน หากคุณนำคนจำนวนมากที่อยู่ในกลุ่มประชากรใกล้เคียงกันมาวางแผนส่วนสูง ความสูงเหล่านั้นมักจะเป็นไปตามการแจกแจงแบบปกติ หากคุณดูแนวจำนวนมากของจำนวนธรรมชาติขนาดใหญ่ และถามว่าตัวเลขแต่ละตัวมีตัวประกอบเฉพาะที่แตกต่างกันจำนวนเท่าใด คำตอบจะติดตามอย่างใกล้ชิดมากด้วยการแจกแจงแบบปกติที่แน่นอน หัวข้อของเราสำหรับวันนี้คือหนึ่งในอัญมณีมงกุฎในทฤษฎีความน่าจะเป็นทั้งหมด มันเป็นหนึ่งในข้อเท็จจริงสำคัญที่อธิบายว่าทำไมการแจกแจงนี้จึงเป็นเรื่องธรรมดาอย่างที่มันเป็น หรือที่เรียกว่าทฤษฎีบทลิมิตจุดศูนย์กลาง บทเรียนนี้มีจุดมุ่งหมายเพื่อกลับไปสู่พื้นฐาน โดยให้ความรู้พื้นฐานเกี่ยวกับสิ่งที่ทฤษฎีบทขีดจำกัดกลางพูดถึง การแจกแจงแบบปกติคืออะไร และฉันต้องการใช้พื้นฐานขั้นต่ำ เราจะเจาะลึกลงไปพอสมควร แต่หลังจากนี้ ฉันยังอยากลงลึกลงไปอีก และอธิบายว่าเหตุใดทฤษฎีบทจึงเป็นจริง ทำไมฟังก์ชันที่อยู่ใต้การแจกแจงแบบปกติจึงมีรูปแบบเฉพาะเจาะจงมาก ทำไมสูตรถึงมี มีพายอยู่ในนั้น และที่สนุกที่สุดก็คือ เหตุใดข้อเท็จจริงสองข้อสุดท้ายจึงเกี่ยวข้องกันมากกว่าคำอธิบายแบบเดิม ๆ มากมาย บทเรียนที่สองนั้นควรจะเป็นภาคต่อของวิดีโอ Convolutions ที่ฉันสัญญาไว้ จึงมีหัวข้อที่เกี่ยวข้องกันมากมายที่นี่ แต่ตอนนี้ กลับมาที่พื้นฐาน ฉันต้องการเริ่มต้นด้วยโมเดลบอร์ด Galton ที่เรียบง่ายเกินไป ในแบบจำลองนี้ เราจะถือว่าลูกบอลแต่ละลูกตกลงบนหมุดตรงกลาง และมีความน่าจะเป็น 50-50 ที่จะกระดอนไปทางซ้ายหรือไปทางขวา และเราจะคิดว่าผลลัพธ์แต่ละอย่างจะบวกหนึ่งหรือ ลบอันหนึ่งออกจากตำแหน่ง เมื่อเลือกอันใดอันหนึ่งแล้ว เราจะตั้งสมมติฐานที่ไม่สมจริงอย่างยิ่งว่ามันบังเอิญตกลงไปตรงกลางหมุดที่อยู่ติดกันด้านล่าง ซึ่งอีกครั้งที่มันจะต้องเผชิญกับตัวเลือก 50-50 แบบเดิมคือเด้งไปทางซ้ายหรือ ไปทางขวา. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 65.58,
  "end": 76.02
 },
 {
  "input": "This lesson is meant to go back to the basics, giving you the fundamentals on what the central limit theorem is saying, what normal distributions are, and I want to assume minimal background. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.64,
  "end": 85.26
 },
 {
  "input": "We're going to go decently deep into it, but after this I'd still like to go deeper and explain why the theorem is true, why the function underlying the normal distribution has the very specific form that it does, why that formula has a pi in it, and, most fun, why those last two facts are actually more related than a lot of traditional explanations would suggest. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.26,
  "end": 105.56
 },
 {
  "input": "That second lesson is also meant to be the follow-on to the convolutions video that I promised, so there's a lot of interrelated topics here. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.48,
  "end": 113.37
 },
 {
  "input": "But right now, back to the fundamentals, I'd like to kick things off with a overly simplified model of the Galton board. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.57,
  "end": 119.17
 },
 {
  "input": "In this model we will assume that each ball falls directly onto a certain central peg and that it has a 50-50 probability of bouncing to the left or to the right, and we'll think of each of those outcomes as either adding one or subtracting one from its position. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 120.89,
  "end": 134.11
 },
 {
  "input": "Once one of those is chosen, we make the highly unrealistic assumption that it happens to land dead on in the middle of the peg adjacent below it, where again it'll be faced with the same 50-50 choice of bouncing to the left or to the right. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.67,
  "end": 147.07
 },
 {
  "input": "For the one I'm showing on screen, there are five different rows of pegs, so our little hopping ball makes five different random choices between plus one and minus one, and we can think of its final position as basically being the sum of all of those different numbers, which in this case happens to be one, and we might label all of the different buckets with the sum that they represent. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.43,
  "end": 166.35
 },
 {
  "input": "As we repeat this, we're looking at different possible sums for those five random numbers. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.35,
  "end": 171.29
 },
 {
  "input": "And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board, let me emphasize the goal right now is not to accurately model physics. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 173.05,
  "end": 181.67
 },
 {
  "input": "The goal is to give a simple example to illustrate the central limit theorem, and for that, idealized though this might be, it actually gives us a really good example. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 181.83,
  "end": 190.03
 },
 {
  "input": "If we let many different balls fall, making yet another unrealistic assumption that they don't influence each other as if they're all ghosts, then the number of balls that fall into each different bucket gives us some loose sense for how likely each one of those buckets is. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.57,
  "end": 203.39
 },
 {
  "input": "In this example, the numbers are simple enough that it's not too hard to explicitly calculate what the probability is for falling into each bucket. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.83,
  "end": 210.01
 },
 {
  "input": "If you do want to think that through, you'll find it very reminiscent of Pascal's triangle. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.27,
  "end": 213.83
 },
 {
  "input": "But the neat thing about our theorem is how far it goes beyond the simple examples. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 213.95,
  "end": 218.27
 },
 {
  "input": "So to start off at least, rather than making explicit calculations, let's just simulate things by running a large number of samples and letting the total number of results in each different outcome give us some sense for what that distribution looks like. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.67,
  "end": 229.97
 },
 {
  "input": "As I said, the one on screen has five rows, so each sum that we're considering includes only five numbers. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.45,
  "end": 236.21
 },
 {
  "input": "The basic idea of the central limit theorem is that if you increase the size of that sum, for example here that would mean increasing the number of rows of pegs for each ball to bounce off, then the distribution that describes where that sum is going to fall looks more and more like a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.81,
  "end": 253.33
 },
 {
  "input": "Here, it's actually worth taking a moment to write down that general idea. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.47,
  "end": 258.35
 },
 {
  "input": "The setup is that we have a random variable, and that's basically shorthand for a random process where each outcome of that process is associated with some number. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.27,
  "end": 268.19
 },
 {
  "input": "We'll call that random number x. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 268.49,
  "end": 269.97
 },
 {
  "input": "For example, each bounce off the peg is a random process modeled with two outcomes. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.97,
  "end": 274.39
 },
 {
  "input": "Those outcomes are associated with the numbers negative one and positive one. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.85,
  "end": 277.89
 },
 {
  "input": "Another example of a random variable would be rolling a die, where you have six different outcomes, each one associated with a number. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.53,
  "end": 284.83
 },
 {
  "input": "What we're doing is taking multiple different samples of that variable and adding them all together. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.47,
  "end": 290.41
 },
 {
  "input": "On our Galton board, that looks like letting the ball bounce off multiple different pegs on its way down to the bottom, and in the case of a die, you might imagine rolling many different dice and adding up the results. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.77,
  "end": 300.97
 },
 {
  "input": "The claim of the central limit theorem is that as you let the size of that sum get bigger and bigger, then the distribution of that sum, how likely it is to fall into different possible values, will look more and more like a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.43,
  "end": 314.11
 },
 {
  "input": "That's it, that is the general idea. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 315.43,
  "end": 317.13
 },
 {
  "input": "Over the course of this lesson, our job is to make that statement more quantitative. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.55,
  "end": 321.53
 },
 {
  "input": "We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.07,
  "end": 326.35
 },
 {
  "input": "For example, here's the kind of question I want you to be able to answer by the end of this video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.21,
  "end": 331.57
 },
 {
  "input": "Suppose you rolled the die 100 times and you added together the results. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 332.19,
  "end": 335.89
 },
 {
  "input": "Could you find a range of values such that you're 95% sure that the sum will fall within that range? ",
  "translatedText": "สำหรับอันที่ฉันแสดงบนหน้าจอ มีหมุดห้าแถวที่แตกต่างกัน ดังนั้นลูกบอลกระโดดตัวน้อยของเราจึงสุ่มเลือกห้าแบบระหว่างบวกหนึ่งและลบหนึ่ง และเราสามารถนึกถึงตำแหน่งสุดท้ายของมัน โดยพื้นฐานแล้วคือผลรวมของทั้งหมด ของตัวเลขที่แตกต่างกันเหล่านั้น ซึ่งในกรณีนี้จะเป็นตัวเลขเดียว และเราอาจติดป้ายกำกับกลุ่มต่างๆ ทั้งหมดด้วยผลรวมที่ตัวเลขเหล่านั้นเป็นตัวแทน ขณะที่เราทำซ้ำ เรากำลังดูผลรวมที่เป็นไปได้ที่แตกต่างกันของตัวเลขสุ่มห้าตัวนั้น และสำหรับพวกคุณที่มักจะบ่นว่า นี่เป็นโมเดลที่ไม่สมจริงอย่างมากสำหรับบอร์ด Galton ที่แท้จริง ผมขอเน้นย้ำว่าเป้าหมายในตอนนี้ ไม่ใช่การสร้างแบบจำลองทางฟิสิกส์อย่างแม่นยำ เป้าหมายคือยกตัวอย่างง่ายๆ เพื่อแสดงทฤษฎีบทลิมิตจุดศูนย์กลาง และเพื่อให้เป็นไปตามอุดมคติ แม้ว่าจะเป็นเช่นนี้ มันก็ให้ตัวอย่างที่ดีแก่เราจริงๆ หากเราปล่อยให้ลูกบอลหลายลูกตกลงไป โดยตั้งสมมติฐานที่ไม่สมจริงอีกอย่างหนึ่งว่าพวกมันไม่มีอิทธิพลต่อกันราวกับว่าพวกมันเป็นผี จำนวนลูกบอลที่ตกลงไปในถังแต่ละถังก็ทำให้เรารู้สึกหลวม ๆ ว่าลูกบอลแต่ละลูกมีโอกาสแค่ไหน ของถังเหล่านั้นก็คือ ในตัวอย่างนี้ ตัวเลขนั้นง่ายพอที่จะคำนวณได้อย่างชัดเจนว่าความน่าจะเป็นที่จะตกอยู่ในแต่ละกลุ่มนั้นเป็นอย่างไร หากคุณต้องการคิดให้ถี่ถ้วน คุณจะพบว่ามันชวนให้นึกถึงสามเหลี่ยมปาสกาลมาก แต่ข้อดีอย่างหนึ่งของทฤษฎีบทของเราคือว่ามันไปได้ไกลกว่าตัวอย่างง่ายๆ แค่ไหน ดังนั้น เพื่อเริ่มต้นอย่างน้อย แทนที่จะทำการคำนวณที่ชัดเจน เรามาจำลองสิ่งต่างๆ โดยการสุ่มตัวอย่างจำนวนมาก และปล่อยให้จำนวนผลลัพธ์ทั้งหมดในผลลัพธ์ที่แตกต่างกันแต่ละรายการทำให้เราเข้าใจได้ว่าการแจกแจงนั้นเป็นอย่างไร อย่างที่ฉันบอกไปแล้ว แถวบนหน้าจอมีห้าแถว ดังนั้นแต่ละผลรวมที่เรากำลังพิจารณาจึงมีเพียงห้าตัวเลขเท่านั้น แนวคิดพื้นฐานของทฤษฎีบทขีดจำกัดจุดศูนย์กลางคือ หากคุณเพิ่มขนาดของผลรวมนั้น เช่น ในกรณีนี้ นั่นหมายถึงการเพิ่มจำนวนแถวของหมุดเพื่อให้ลูกบอลแต่ละลูกกระดอน การกระจายตัวจะอธิบายว่าผลรวมนั้นจะไปที่ใด ฤดูใบไม้ร่วงดูเหมือนโค้งระฆังมากขึ้นเรื่อยๆ ตรงนี้ จริงๆ แล้วคุ้มค่าที่สละเวลาสักครู่เพื่อเขียนแนวคิดทั่วไปนั้น การตั้งค่าคือเรามีตัวแปรสุ่ม และโดยพื้นฐานแล้วเป็นการจดชวเลขสำหรับกระบวนการสุ่ม โดยที่แต่ละผลลัพธ์ของกระบวนการนั้นเชื่อมโยงกับตัวเลขจำนวนหนึ่ง เราจะเรียกเลขสุ่มนั้นว่า x ตัวอย่างเช่น การกระเด้งออกจากหมุดแต่ละครั้งเป็นกระบวนการสุ่มที่สร้างแบบจำลองด้วยผลลัพธ์สองประการ ผลลัพธ์เหล่านั้นสัมพันธ์กับตัวเลขลบและบวก อีกตัวอย่างหนึ่งของตัวแปรสุ่มคือการทอยลูกเต๋า ซึ่งคุณจะได้ผลลัพธ์ที่แตกต่างกัน 6 รายการ โดยแต่ละผลลัพธ์จะสัมพันธ์กับตัวเลข สิ่งที่เรากำลังทำคือนำตัวอย่างต่างๆ หลายๆ ตัวอย่าง ของตัวแปรนั้นมาบวกเข้าด้วยกัน บนกระดาน Galton ของเรา ดูเหมือนว่าจะปล่อยให้ลูกบอลกระดอนจากหมุดต่างๆ หลายๆ อันระหว่างทางลงไปด้านล่าง และในกรณีของการตาย คุณอาจจินตนาการถึงการทอยลูกเต๋าหลายๆ แบบแล้วบวกผลลัพธ์เข้าด้วยกัน ข้ออ้างของทฤษฎีบทขีดจำกัดจุดศูนย์กลางคือ เมื่อคุณปล่อยให้ขนาดของผลรวมนั้นใหญ่ขึ้นเรื่อยๆ จากนั้นการกระจายตัวของผลรวมนั้น ความน่าจะเป็นที่มันจะตกอยู่ในค่าที่เป็นไปได้ต่างๆ จะมีลักษณะเหมือนเส้นโค้งระฆังมากขึ้นเรื่อยๆ แค่นั้นแหละ นั่นคือความคิดทั่วไป ตลอดบทเรียนนี้ งานของเราคือการทำให้ข้อความนั้นมีปริมาณมากขึ้น เราจะใส่ตัวเลขลงไป ใส่สูตรลงไป แสดงว่าคุณสามารถใช้มันทำนายได้อย่างไร ตัวอย่างเช่น นี่คือคำถามประเภทที่ฉันอยากให้คุณตอบได้ในตอนท้ายของวิดีโอนี้ สมมติว่าคุณทอยลูกเต๋า 100 ครั้งแล้วบวกผลลัพธ์เข้าด้วยกัน คุณสามารถหาช่วงของค่าที่คุณมั่นใจ 95% ว่าผลรวมจะอยู่ในช่วงนั้นได้หรือไม่ หรือบางทีผมควรบอกว่า หาช่วงของค่าที่เล็กที่สุดเท่าที่จะเป็นไปได้ โดยที่นี่คือความจริง สิ่งที่ยอดเยี่ยมคือคุณจะสามารถตอบคำถามนี้ได้ ไม่ว่าจะเป็นแม่พิมพ์ที่ยุติธรรมหรือว่าเป็นแม่พิมพ์แบบถ่วงน้ำหนักก็ตาม ตอนนี้ขอผมบอกอย่างสูงว่าทฤษฎีบทนี้มีสมมติฐานที่แตกต่างกันสามข้อ สามสิ่งที่ต้องเป็นจริงก่อนที่ทฤษฎีบทจะตามมา และฉันจะไม่บอกคุณจริงๆ ว่ามันคืออะไร จนกว่าจะจบวิดีโอ แต่ฉันอยากให้คุณจับตาดูและดูว่าคุณสามารถสังเกตเห็นและอาจคาดเดาได้ว่าสมมติฐานทั้งสามนั้นจะเป็นอย่างไร ขั้นต่อไป เพื่อให้อธิบายได้ดีขึ้นว่าทฤษฎีบทนี้กว้างแค่ไหน ฉันต้องการจำลองสถานการณ์เพิ่มเติมให้คุณเน้นที่ตัวอย่างลูกเต๋า โดยปกติ หากคุณคิดที่จะทอยลูกเต๋า คุณจะคิดว่าผลลัพธ์ทั้ง 6 อย่างมีความน่าจะเป็นพอๆ กัน แต่ทฤษฎีบทไม่ได้สนใจเรื่องนั้นเลย เราอาจเริ่มต้นด้วยการตายแบบถ่วงน้ำหนัก ซึ่งมีการกระจายผลลัพธ์แบบไม่สำคัญ และแนวคิดหลักยังคงอยู่ สำหรับการจำลอง สิ่งที่ฉันจะทำคือหาการกระจายตัวแบบนี้ ซึ่งเบ้ไปทางค่าที่ต่ำกว่า ผมจะเลือกตัวอย่าง 10 ตัวอย่างจากการกระจายตัวนั้น แล้วผมจะบันทึกผลรวมของกลุ่มตัวอย่างนั้นไว้บนแผนภาพด้านล่าง แล้วผมจะทำแบบนี้หลายๆ ครั้ง โดยมีผลรวมเป็น 10 เสมอ แต่คอยดูว่าผลรวมเหล่านั้นจบลงที่ตรงไหน เพื่อให้เราเข้าใจถึงการกระจายตัว ที่จริง ขอผมขยายทิศทาง y ใหม่ เพื่อให้เรามีพื้นที่ตัวอย่างมากกว่านี้ และผมจะปล่อยให้มันไปจนสุดถึงสองพัน และเมื่อเป็นเช่นนี้ คุณจะสังเกตเห็นว่ารูปร่างที่เริ่มโผล่ออกมา ดูเหมือนโค้งระฆัง บางทีถ้าคุณเหล่ตา คุณจะเห็นว่ามันเอียงไปทางซ้ายเล็กน้อย แต่ก็ดีที่มีบางสิ่งที่สมมาตรเกิดขึ้นจากจุดเริ่มต้นที่ไม่สมมาตรมาก เพื่ออธิบายให้ชัดเจนยิ่งขึ้นว่าทฤษฎีบทขีดจำกัดจุดศูนย์กลางคืออะไร ผมขอจำลองสถานการณ์ทั้ง 4 แบบขนานกัน โดยที่ด้านซ้ายบน ผมจะทำโดยที่เราบวกลูกเต๋าครั้งละ 2 ลูกเท่านั้น ส่วนมุมขวาบนคือ กำลังทำโดยที่เราบวกลูกเต๋าครั้งละห้าลูก ด้านซ้ายล่างคืออันที่เราเพิ่งเห็นว่าบวกลูกเต๋าครั้งละ 10 ลูก แล้วเราจะทำอีกลูกหนึ่งด้วยผลรวมที่มากขึ้น ครั้งละ 15 ลูก สังเกตว่าทางด้านซ้ายบนเมื่อเราเพิ่มลูกเต๋าสองลูก ผลลัพธ์ที่ได้จะดูไม่เหมือนเส้นโค้งระฆัง มันดูชวนให้นึกถึงการที่เราเริ่มด้วยการเบ้ไปทางซ้ายมากกว่ามาก แต่เมื่อเราอนุญาตให้มีลูกเต๋ามากขึ้นในแต่ละผลรวม รูปร่างผลลัพธ์ที่เกิดขึ้นในการแจกแจงเหล่านี้จะดูสมมาตรมากขึ้นเรื่อยๆ มีก้อนเนื้ออยู่ตรงกลางและจางไปทางหางเป็นรูปโค้งระฆัง ผมขอย้ำอีกครั้งว่า คุณสามารถเริ่มด้วยการกระจายตัวแบบอื่นก็ได้ ผมจะเรียกใช้อีกครั้ง แต่ความน่าจะเป็นส่วนใหญ่เชื่อมโยงกับตัวเลข 1 และ 6 โดยมีความน่าจะเป็นต่ำมากสำหรับค่ากลาง แม้ว่าการเปลี่ยนแปลงการกระจายตัวของแม่พิมพ์แต่ละม้วนไปโดยสิ้นเชิง แต่ก็ยังเป็นกรณีที่รูปร่างโค้งระฆังจะปรากฏขึ้นเมื่อเราพิจารณาผลรวมที่แตกต่างกัน การแสดงสิ่งต่าง ๆ ด้วยการจำลองแบบนี้สนุกมาก และการที่จะเห็นระเบียบเกิดขึ้นจากความสับสนวุ่นวายก็ดูเรียบร้อยดี แต่ก็ให้ความรู้สึกไม่ชัดเจนเช่นกัน เช่นในกรณีนี้ เมื่อฉันตัดการจำลองที่ตัวอย่าง 3,000 ตัวอย่างออก แม้ว่ามันจะดูเหมือนโค้งระฆัง แต่ถังที่แตกต่างกันก็ดูแหลมคมทีเดียว และคุณอาจสงสัยว่า มันควรจะเป็นแบบนั้น หรือนั่นเป็นเพียงสิ่งประดิษฐ์ของการสุ่มในการจำลอง และถ้าเป็นเช่นนั้น เราต้องการตัวอย่างกี่ตัวอย่างจึงจะแน่ใจได้ว่าสิ่งที่เรากำลังดูอยู่เป็นตัวแทนของการกระจายตัวที่แท้จริง? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.63,
  "end": 342.17
 },
 {
  "input": "Or maybe I should say find the smallest possible range of values such that this is true. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.83,
  "end": 346.55
 },
 {
  "input": "The neat thing is you'll be able to answer this question whether it's a fair die or if it's a weighted die. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 347.39,
  "end": 352.13
 },
 {
  "input": "Now let me say at the top that this theorem has three different assumptions that go into it, three things that have to be true before the theorem follows. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.45,
  "end": 360.13
 },
 {
  "input": "And I'm actually not going to tell you what they are until the very end of the video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.43,
  "end": 363.79
 },
 {
  "input": "Instead I want you to keep your eye out and see if you can notice and maybe predict what those three assumptions are going to be. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.27,
  "end": 369.67
 },
 {
  "input": "As a next step, to better illustrate just how general this theorem is, I want to run a couple more simulations for you focused on the dice example. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.71,
  "end": 377.39
 },
 {
  "input": "Usually if you think of rolling a die you think of the six outcomes as being equally probable, but the theorem actually doesn't care about that. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 380.91,
  "end": 387.63
 },
 {
  "input": "We could start with a weighted die, something with a non-trivial distribution across the outcomes, and the core idea still holds. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 387.83,
  "end": 394.55
 },
 {
  "input": "For the simulation what I'll do is take some distribution like this one that is skewed towards lower values. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.03,
  "end": 399.93
 },
 {
  "input": "I'm going to take 10 distinct samples from that distribution and then I'll record the sum of that sample on the plot on the bottom. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 400.25,
  "end": 407.55
 },
 {
  "input": "Then I'm going to do this many many different times, always with a sum of size 10, but keep track of where those sums ended up to give us a sense of the distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.63,
  "end": 416.59
 },
 {
  "input": "And in fact let me rescale the y direction to give us room to run an even larger number of samples. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 419.97,
  "end": 424.73
 },
 {
  "input": "And I'll let it go all the way up to a couple thousand, and as it does you'll notice that the shape that starts to emerge looks like a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.03,
  "end": 432.49
 },
 {
  "input": "Maybe if you squint your eyes you can see it skews a tiny bit to the left, but it's neat that something so symmetric emerged from a starting point that was so asymmetric. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 432.87,
  "end": 441.01
 },
 {
  "input": "To better illustrate what the central limit theorem is all about, let me run four of these simulations in parallel, where on the upper left I'm doing it where we're only adding two dice at a time, on the upper right we're doing it where we're adding five dice at a time, the lower left is the one that we just saw adding 10 dice at a time, and then we'll do another one with a bigger sum, 15 at a time. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.47,
  "end": 461.37
 },
 {
  "input": "Notice how on the upper left when we're just adding two dice, the resulting distribution doesn't really look like a bell curve, it looks a lot more reminiscent of the one we started with skewed towards the left. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.25,
  "end": 472.03
 },
 {
  "input": "But as we allow for more and more dice in each sum, the resulting shape that comes up in these distributions looks more and more symmetric. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 472.81,
  "end": 479.81
 },
 {
  "input": "It has the lump in the middle and fade towards the tail's shape of a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.95,
  "end": 483.89
 },
 {
  "input": "And let me emphasize again, you can start with any different distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 487.05,
  "end": 490.49
 },
 {
  "input": "Here I'll run it again, but where most of the probability is tied up in the numbers 1 and 6, with very low probability for the mid values. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 490.49,
  "end": 497.49
 },
 {
  "input": "Despite completely changing the distribution for an individual roll of the die, it's still the case that a bell curve shape will emerge as we consider the different sums. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.19,
  "end": 506.55
 },
 {
  "input": "Illustrating things with a simulation like this is very fun, and it's kind of neat to see order emerge from chaos, but it also feels a little imprecise. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.27,
  "end": 515.03
 },
 {
  "input": "Like in this case, when I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve, the different buckets seem pretty spiky. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.39,
  "end": 522.99
 },
 {
  "input": "And you might wonder, is it supposed to look that way, or is that just an artifact of the randomness in the simulation? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 522.99,
  "end": 528.55
 },
 {
  "input": "And if it is, how many samples do we need before we can be sure that what we're looking at is representative of the true distribution? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 529.01,
  "end": 535.11
 },
 {
  "input": "Instead moving forward, let's get a little more theoretical and show the precise shape that these distributions will take on in the long run. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.19,
  "end": 545.47
 },
 {
  "input": "The easiest case to make this calculation is if we have a uniform distribution, where each possible face of the die has an equal probability, 1 6th. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.13,
  "end": 553.97
 },
 {
  "input": "For example, if you then want to know how likely different sums are for a pair of dice, it's essentially a counting game, where you count up how many distinct pairs take on the same sum, which in the diagram I've drawn, you can conveniently think about by going through all of the different diagonals. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.99,
  "end": 568.49
 },
 {
  "input": "Since each such pair has an equal chance of showing up, 1 in 36, all you have to do is count the sizes of these buckets. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.41,
  "end": 577.53
 },
 {
  "input": "That gives us a definitive shape for the distribution describing a sum of two dice, and if we were to play the same game with all possible triplets, the resulting distribution would look like this. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.19,
  "end": 588.13
 },
 {
  "input": "Now what's more challenging, but a lot more interesting, is to ask what happens if we have a non-uniform distribution for that single die. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.69,
  "end": 594.99
 },
 {
  "input": "We actually talked all about this in the last video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.55,
  "end": 597.97
 },
 {
  "input": "You do essentially the same thing, you go through all the distinct pairs of dice which add up to the same value. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.45,
  "end": 603.67
 },
 {
  "input": "It's just that instead of counting those pairs, for each pair you multiply the two probabilities of each particular face coming up, and then you add all those together. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 603.97,
  "end": 612.75
 },
 {
  "input": "The computation that does this for all possible sums has a fancy name, it's called a convolution, but it's essentially just the weighted version of the counting game that anyone who's played with a pair of dice already finds familiar. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 613.29,
  "end": 624.47
 },
 {
  "input": "For our purposes in this lesson, I'll have the computer calculate all that, simply display the results for you, and invite you to observe certain patterns, but under the hood, this is what's going on. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 625.03,
  "end": 635.33
 },
 {
  "input": "So just to be crystal clear on what's being represented here, if you imagine sampling two different values from that top distribution, the one describing a single die, and adding them together, then the second distribution I'm drawing represents how likely you are to see various different sums. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.65,
  "end": 652.23
 },
 {
  "input": "Likewise, if you imagine sampling three distinct values from that top distribution, and adding them together, the next plot represents the probabilities for various different sums in that case. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.89,
  "end": 662.49
 },
 {
  "input": "So if I compute what the distributions for these sums look like for larger and larger sums, well you know what I'm going to say, it looks more and more like a bell curve. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 663.51,
  "end": 672.39
 },
 {
  "input": "But before we get to that, I want you to make a couple more simple observations. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 673.35,
  "end": 676.45
 },
 {
  "input": "For example, these distributions seem to be wandering to the right, and also they seem to be getting more spread out, and a little bit more flat. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.45,
  "end": 684.79
 },
 {
  "input": "You cannot describe the central limit theorem quantitatively without taking into account both of those effects, which in turn requires describing the mean and the standard deviation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.25,
  "end": 693.19
 },
 {
  "input": "Maybe you're already familiar with those, but I want to make minimal assumptions here, and it never hurts to review, so let's quickly go over both of those. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 693.95,
  "end": 700.61
 },
 {
  "input": "The mean of a distribution, often denoted with the Greek letter mu, is a way of capturing the center of mass for that distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 703.41,
  "end": 710.71
 },
 {
  "input": "It's calculated as the expected value of our random variable, which is a way of saying you go through all of the different possible outcomes, and you multiply the probability of that outcome times the value of the variable. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.19,
  "end": 722.85
 },
 {
  "input": "If higher values are more probable, that weighted sum is going to be bigger. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 723.19,
  "end": 726.41
 },
 {
  "input": "If lower values are more probable, that weighted sum is going to be smaller. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 726.75,
  "end": 729.95
 },
 {
  "input": "A little more interesting is if you want to measure how spread out this distribution is, because there's multiple different ways you might do it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 730.79,
  "end": 737.13
 },
 {
  "input": "One of them is called the variance. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 738.53,
  "end": 740.29
 },
 {
  "input": "The idea there is to look at the difference between each possible value and the mean, square that difference, and ask for its expected value. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 740.83,
  "end": 748.27
 },
 {
  "input": "The idea is that whether your value is below or above the mean, when you square that difference, you get a positive number, and the larger the difference, the bigger that number. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 748.73,
  "end": 756.65
 },
 {
  "input": "Squaring it like this turns out to make the math much much nicer than if we did something like an absolute value, but the downside is that it's hard to think about this as a distance in our diagram because the units are off. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 757.37,
  "end": 768.13
 },
 {
  "input": "Kind of like the units here are square units, whereas a distance in our diagram would be a kind of linear unit. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 768.33,
  "end": 773.31
 },
 {
  "input": "So another way to measure spread is what's called the standard deviation, which is the square root of this value. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 773.71,
  "end": 779.19
 },
 {
  "input": "That can be interpreted much more reasonably as a distance on our diagram, and it's commonly denoted with the Greek letter sigma, so you know m for mean as for standard deviation, but both in Greek. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 779.47,
  "end": 789.65
 },
 {
  "input": "Looking back at our sequence of distributions, let's talk about the mean and standard deviation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.87,
  "end": 796.15
 },
 {
  "input": "If we call the mean of the initial distribution mu, which for the one illustrated happens to be 2.24, hopefully it won't be too surprising if I tell you that the mean of the next one is 2 times mu. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.63,
  "end": 806.73
 },
 {
  "input": "That is, you roll a pair of dice, you want to know the expected value of the sum, it's two times the expected value for a single die. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 807.13,
  "end": 812.81
 },
 {
  "input": "Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. ",
  "translatedText": "แทนที่จะก้าวไปข้างหน้า เรามาดูทฤษฎีอีกหน่อยแล้วแสดงรูปร่างที่ชัดเจนที่การแจกแจงเหล่านี้จะเกิดขึ้นในระยะยาว กรณีที่ง่ายที่สุดในการคำนวณนี้คือ ถ้าเรามีการแจกแจงแบบสม่ำเสมอ โดยที่แต่ละหน้าของลูกเต๋าที่เป็นไปได้มีความน่าจะเป็นเท่ากัน คือ 1 ใน 6 ตัวอย่างเช่น หากคุณต้องการทราบว่าลูกเต๋าคู่หนึ่งน่าจะมีผลรวมต่างกันเพียงใด เป็นเกมการนับ โดยคุณจะต้องนับจำนวนคู่ที่แตกต่างกันเพื่อให้ได้ผลรวมเท่ากัน ซึ่งในแผนภาพที่ฉันวาด สามารถคิดได้อย่างสะดวกโดยผ่านเส้นทแยงมุมต่างๆ ทั้งหมด เนื่องจากแต่ละคู่มีโอกาสปรากฏตัวเท่ากัน 1 ใน 36 สิ่งที่คุณต้องทำคือนับขนาดของที่เก็บข้อมูลเหล่านี้ นั่นทำให้เรามีรูปแบบที่ชัดเจนสำหรับการแจกแจงที่อธิบายผลรวมของลูกเต๋าสองลูก และถ้าเราเล่นเกมเดียวกันโดยใช้ลูกแฝดที่เป็นไปได้ทั้งหมด ผลการแจกแจงจะมีลักษณะเช่นนี้ ทีนี้สิ่งที่ท้าทายกว่า แต่น่าสนใจกว่ามาก คือการถามว่าจะเกิดอะไรขึ้น หากเรามีการกระจายตัวไม่เท่ากันสำหรับลูกเต๋าตัวนั้น เราพูดถึงเรื่องนี้ไปแล้วในวิดีโอที่แล้ว โดยพื้นฐานแล้วคุณทำสิ่งเดียวกัน คุณจะต้องผ่านลูกเต๋าคู่ที่แตกต่างกันทั้งหมดซึ่งรวมกันแล้วจะมีค่าเท่ากัน แทนที่จะนับคู่เหล่านั้น สำหรับแต่ละคู่ คุณจะคูณความน่าจะเป็นสองรายการของแต่ละหน้าที่เกิดขึ้น แล้วบวกทั้งหมดเข้าด้วยกัน การคำนวณที่ทำสิ่งนี้กับผลรวมที่เป็นไปได้ทั้งหมดมีชื่อที่แปลกตา เรียกว่าการบิด แต่โดยพื้นฐานแล้วมันเป็นเพียงเกมการนับแบบถ่วงน้ำหนัก ซึ่งใครก็ตามที่เล่นลูกเต๋าคู่หนึ่งจะคุ้นเคยอยู่แล้ว สำหรับจุดประสงค์ของเราในบทเรียนนี้ ฉันจะให้คอมพิวเตอร์คำนวณทั้งหมด เพียงแสดงผลลัพธ์ให้คุณ และเชิญชวนให้คุณสังเกตรูปแบบบางอย่าง แต่เบื้องหลัง นี่คือสิ่งที่เกิดขึ้น เพื่อให้ชัดเจนถึงสิ่งที่แสดงตรงนี้, ถ้าคุณลองสุ่มตัวอย่างค่าที่ต่างกันสองค่า จากการกระจายตัวบน ค่าที่อธิบายลูกเต๋าตัวเดียว แล้วบวกเข้าด้วยกัน, การกระจายตัวที่สอง ที่ผมวาดแสดงว่าคุณมีโอกาสแค่ไหน ดูผลรวมที่แตกต่างกัน ในทำนองเดียวกัน หากคุณลองสุ่มตัวอย่างค่าที่แตกต่างกันสามค่าจากการแจกแจงบนสุดนั้น แล้วบวกเข้าด้วยกัน แผนภาพถัดไปจะแสดงความน่าจะเป็นสำหรับผลรวมต่างๆ ที่แตกต่างกันในกรณีนั้น ดังนั้นหากผมคำนวณว่าการกระจายตัวของผลบวกเหล่านี้ เป็นอย่างไรสำหรับผลรวมที่มากขึ้นเรื่อยๆ คุณก็รู้ว่าผมจะพูดอะไร มันดูเหมือนเส้นโค้งระฆังมากขึ้นเรื่อยๆ แต่ก่อนที่เราจะไปถึงจุดนั้น ฉันอยากให้คุณตั้งข้อสังเกตง่ายๆ อีกสองสามข้อก่อน ตัวอย่างเช่น การแจกแจงเหล่านี้ดูเหมือนจะเคลื่อนไปทางขวา และดูเหมือนว่าจะกระจายออกไปมากขึ้นและแบนขึ้นอีกเล็กน้อย คุณไม่สามารถอธิบายทฤษฎีบทขีดจำกัดจุดศูนย์กลางในเชิงปริมาณได้โดยไม่คำนึงถึงผลกระทบทั้งสองประการ ซึ่งจะต้องอธิบายค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานด้วย บางทีคุณอาจคุ้นเคยกับสิ่งเหล่านั้นแล้ว แต่ฉันต้องการตั้งสมมติฐานเพียงเล็กน้อยที่นี่ และการพิจารณาทบทวนก็ไม่ใช่เรื่องเสียหาย ดังนั้น เรามาดูทั้งสองข้ออย่างรวดเร็วกันดีกว่า ค่าเฉลี่ยของการแจกแจง ซึ่งมักแสดงด้วยอักษรกรีก mu เป็นวิธีจับจุดศูนย์กลางมวลของการแจกแจงนั้น มันคำนวณเป็นค่าคาดหวังของตัวแปรสุ่ม ซึ่งเป็นวิธีบอกว่าคุณดูผลลัพธ์ที่เป็นไปได้ต่างๆ แล้วคุณคูณความน่าจะเป็นของผลลัพธ์นั้นด้วยค่าของตัวแปร หากค่าที่สูงกว่ามีความเป็นไปได้มากกว่า ผลรวมถ่วงน้ำหนักนั้นก็จะมากขึ้น หากค่าที่ต่ำกว่ามีความเป็นไปได้มากกว่า ผลรวมถ่วงน้ำหนักนั้นก็จะน้อยลง สิ่งที่น่าสนใจอีกหน่อยคือถ้าคุณต้องการวัดว่าการกระจายตัวนี้เป็นอย่างไร เพราะมีหลายวิธีที่คุณทำได้ หนึ่งในนั้นเรียกว่าความแปรปรวน แนวคิดคือการดูความแตกต่างระหว่างค่าที่เป็นไปได้แต่ละค่ากับค่าเฉลี่ย จัดกำลังสองส่วนต่างนั้น และถามค่าคาดหวัง แนวคิดก็คือไม่ว่าค่าของคุณจะต่ำกว่าหรือสูงกว่าค่าเฉลี่ย เมื่อคุณยกกำลังสองผลต่างนั้น คุณจะได้จำนวนบวก และยิ่งผลต่างมากเท่าไร ตัวเลขนั้นก็จะยิ่งมากขึ้นเท่านั้น การยกกำลังสองแบบนี้จะทำให้คณิตศาสตร์ดีกว่าการที่เราทำอะไรบางอย่างเช่นค่าสัมบูรณ์ แต่ข้อเสียคือมันยากที่จะคิดว่านี่เป็นระยะทางในแผนภาพของเราเพราะหน่วยไม่อยู่ เหมือนกับหน่วยตรงนี้เป็นหน่วยสี่เหลี่ยม ส่วนระยะทางในแผนภาพจะเป็นหน่วยเชิงเส้น อีกวิธีหนึ่งในการวัดค่าสเปรดคือสิ่งที่เรียกว่าค่าเบี่ยงเบนมาตรฐาน ซึ่งก็คือรากที่สองของค่านี้ นั่นสามารถตีความได้สมเหตุสมผลกว่ามากว่าเป็นระยะทางบนแผนภาพของเรา และโดยทั่วไปเขียนแทนด้วยอักษรกรีก ซิกมา ดังนั้นคุณจึงรู้ว่า m เป็นค่าเฉลี่ยเท่ากับค่าเบี่ยงเบนมาตรฐาน แต่เป็นภาษากรีกทั้งคู่ มองย้อนกลับไปที่ลำดับการแจกแจงของเรา เรามาพูดถึงค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานกัน หากเราเรียกค่าเฉลี่ยของการแจกแจงเริ่มต้น mu ซึ่งสำหรับค่าที่อธิบายไว้จะเป็น 2 24, หวังว่าคงไม่น่าแปลกใจเกินไปหากผมบอกคุณว่าค่าเฉลี่ยของตัวต่อไปคือ 2 คูณมิว นั่นคือคุณทอยลูกเต๋าหนึ่งคู่ และต้องการทราบมูลค่าที่คาดหวังของผลรวม มันเป็นสองเท่าของมูลค่าที่คาดหวังสำหรับการตายครั้งเดียว ในทำนองเดียวกัน ค่าคาดหวังสำหรับผลรวมของขนาด 3 ของเราคือ 3 คูณ mu และเป็นเช่นนี้ไปเรื่อยๆ ค่าเฉลี่ยแค่เคลื่อนไปทางขวาเรื่อยๆ ซึ่งเป็นสาเหตุที่การกระจายตัวของเราดูเหมือนจะเคลื่อนไปในทิศทางนั้น สิ่งที่ท้าทายกว่าเล็กน้อย แต่สำคัญมาก คือการอธิบายว่าค่าเบี่ยงเบนมาตรฐานเปลี่ยนแปลงไปอย่างไร ข้อเท็จจริงที่สำคัญตรงนี้ก็คือ หากคุณมีตัวแปรสุ่มสองตัวที่แตกต่างกัน ความแปรปรวนของผลรวมของตัวแปรเหล่านั้นจะเหมือนกับการบวกค่าความแปรปรวนดั้งเดิมสองตัวเข้าด้วยกัน นี่เป็นหนึ่งในข้อเท็จจริงที่คุณสามารถคำนวณได้เมื่อคุณแกะคำจำกัดความทั้งหมดออก มีสัญชาตญาณดีๆ สองสามข้อว่าทำไมมันถึงเป็นจริง แผนเบื้องต้นของผมคือสร้างซีรีส์เกี่ยวกับความน่าจะเป็น แล้วพูดถึงสิ่งต่างๆ เช่น สัญชาตญาณของความแปรปรวนที่แฝงอยู่ และญาติของมันตรงนั้น แต่ตอนนี้ สิ่งสำคัญที่ผมอยากให้คุณเน้นคือ ความแปรปรวนที่บวก ไม่ใช่ค่าเบี่ยงเบนมาตรฐานที่บวก ดังนั้น ในเชิงวิกฤต หากคุณต้องคำนึงถึงตัวแปรสุ่มตัวเดียวกันที่แตกต่างกัน n ตัว และถามว่าผลรวมเป็นอย่างไร ความแปรปรวนของผลรวมนั้นจะเท่ากับ n คูณความแปรปรวนของตัวแปรเดิมของคุณ ซึ่งหมายถึงค่าเบี่ยงเบนมาตรฐาน รากที่สองของทั้งหมด นี่คือสแควร์รูทของ n คูณค่าเบี่ยงเบนมาตรฐานเดิม ตัวอย่างเช่น ย้อนกลับไปในลำดับการแจกแจง ถ้าเราเขียนค่าเบี่ยงเบนมาตรฐานของค่าเริ่มต้นด้วยซิกมา แล้วค่าเบี่ยงเบนมาตรฐานถัดไปจะเป็นสแควร์รูทของ 2 คูณซิกมา แล้วหลังจากนั้น มันดูเหมือนสแควร์รูทของ 3 คูณซิกมา และอื่นๆ อย่างที่ฉันพูดไปนี้มีความสำคัญมาก หมายความว่าแม้ว่าการกระจายตัวของเราจะกระจายออกไป แต่ก็ไม่ได้กระจายไปเร็วขนาดนั้น แต่กระจายไปตามสัดส่วนของรากที่สองของขนาดของผลรวมเท่านั้น ขณะที่เราเตรียมอธิบายเชิงปริมาณของทฤษฎีบทขีดจำกัดจุดศูนย์กลาง สัญชาตญาณหลักที่อยากให้คุณจำไว้คือว่า โดยพื้นฐานแล้วเราจะจัดการกระจายตัวเหล่านี้ใหม่ เพื่อให้ค่าเฉลี่ยของพวกมันเรียงกัน แล้วจึงปรับสัดส่วนใหม่ ค่าเบี่ยงเบนมาตรฐานทั้งหมดจะเท่ากับ 1 และเมื่อเราทำเช่นนั้น รูปร่างที่ได้ผลลัพธ์จะเข้าใกล้รูปร่างสากลมากขึ้นเรื่อยๆ อธิบายด้วยฟังก์ชันเล็กๆ น้อยๆ อันงดงามที่เราจะแกะออกมาในอีกสักครู่ และขอผมพูดอีกครั้ง ความมหัศจรรย์ที่แท้จริงคือวิธีที่เราสามารถเริ่มต้นด้วยการกระจายใดๆ อธิบายการทอยลูกเต๋าหนึ่งลูก และถ้าเราเล่นเกมเดียวกัน โดยพิจารณาว่าการกระจายตัวของผลรวมต่างๆ มากมายจะเป็นอย่างไร และเราปรับมันใหม่เพื่อให้ค่าเฉลี่ยเรียงกัน และเราปรับมันใหม่ เพื่อให้ค่าเบี่ยงเบนมาตรฐานเป็น 1 ทั้งหมด เรายังคงใช้รูปร่างสากลเหมือนเดิม ซึ่งน่าเหลือเชื่อมาก ทีนี้เพื่อนของผม น่าจะเป็นช่วงเวลาที่ดีพอๆ กับการได้สูตรการกระจายตัวแบบปกติในที่สุด และวิธีที่ผมอยากทำก็คือ ลอกชั้นทั้งหมดออก และสร้างมันขึ้นมาทีละชั้น ฟังก์ชัน e กำลัง x หรืออะไรก็ตามของ x อธิบายการเติบโตแบบเอ็กซ์โปเนนเชียล และถ้าคุณสร้างค่าลบแบบเอ็กซ์โปเนนเชียล ซึ่งพลิกกราฟไปรอบๆ ในแนวนอน คุณอาจคิดว่ามันเป็นการอธิบายการสลายตัวแบบเอ็กซ์โปเนนเชียล หากต้องการสลายตัวในทั้งสองทิศทาง คุณสามารถทำอะไรบางอย่างเพื่อให้แน่ใจว่าเลขชี้กำลังนั้นเป็นลบและเพิ่มขึ้นอยู่เสมอ เช่น หาค่าสัมบูรณ์เป็นลบ นั่นจะทำให้เรามีจุดแหลมแปลกๆ ตรงกลางแบบนี้ แต่ถ้าคุณทำให้เลขชี้กำลังนั้นเป็นกำลังสองของ x แทน คุณจะได้จุดเดียวกันที่ราบรื่นกว่า ซึ่งสลายไปทั้งสองทิศทาง สิ่งนี้ทำให้เรามีรูปทรงโค้งระฆังพื้นฐาน ทีนี้ ถ้าคุณโยนค่าคงที่ไปหน้า x นั้น และคุณปรับขนาดค่าคงที่นั้นขึ้นและลง มันจะช่วยให้คุณสามารถยืดและบีบกราฟในแนวนอน ทำให้คุณสามารถอธิบายเส้นโค้งระฆังที่แคบและกว้างขึ้นได้ และสิ่งสั้นๆ ที่ผมอยากจะชี้ให้เห็นตรงนี้คือว่าตามกฎของการยกกำลัง เมื่อเราปรับแต่งค่าคงที่ c นั้น คุณก็แค่เปลี่ยนฐานของการยกกำลังก็ได้ และในแง่นั้น เลข e ไม่ใช่สิ่งที่พิเศษสำหรับสูตรของเราจริงๆ เราแทนที่มันด้วยค่าคงที่บวกอื่นๆ ได้ แล้วคุณจะได้เส้นโค้งกลุ่มเดียวกันเมื่อเราปรับแต่งค่าคงที่นั้น ทำให้เป็นเส้นโค้ง 2 ตระกูลเดียวกัน ทำให้เป็นเส้นโค้ง 3 ตระกูลเดียวกัน เหตุผลที่เราใช้ e ก็เพราะว่าค่าคงที่นั้นให้ความหมายที่อ่านได้ง่ายมาก หรือถ้าจะพูดให้ง่ายกว่านั้น ถ้าเราปรับค่าใหม่นิดหน่อย เพื่อให้เลขชี้กำลังดูเหมือนลบ ครึ่งคูณ x หารด้วยค่าคงที่ที่แน่นอน ซึ่งเราขอเรียกว่าซิกม่ากำลังสอง แล้วเมื่อเราเปลี่ยนสิ่งนี้เป็นการแจกแจงความน่าจะเป็น ซิกม่าคงที่นั้นจะ เป็นค่าเบี่ยงเบนมาตรฐานของการกระจายตัวนั้น และนั่นเป็นสิ่งที่ดีมาก แต่ก่อนที่เราจะตีความว่ามันเป็นการแจกแจงความน่าจะเป็น เราต้องมีพื้นที่ใต้เส้นโค้งเป็น 1 ก่อน และเหตุผลก็คือวิธีตีความเส้นโค้ง ไม่เหมือนการแจกแจงแบบแยกส่วน เมื่อพูดถึงเรื่องต่อเนื่อง คุณไม่ต้องถามถึงความน่าจะเป็นของจุดใดจุดหนึ่ง แต่คุณถามถึงความน่าจะเป็นที่ค่าหนึ่งจะอยู่ระหว่างค่าที่ต่างกันสองค่าแทน และสิ่งที่เส้นโค้งบอกคุณคือ ความน่าจะเป็นนั้น เท่ากับพื้นที่ใต้เส้นโค้งระหว่างสองค่านั้น มีวิดีโออื่นเกี่ยวกับเรื่องนี้อีก เขาเรียกว่าฟังก์ชันความหนาแน่นของความน่าจะเป็น ประเด็นหลักในตอนนี้คือพื้นที่ใต้เส้นโค้งทั้งหมดแสดงถึงความน่าจะเป็นที่จะมีบางสิ่งเกิดขึ้น โดยมีตัวเลขบางตัวปรากฏขึ้น นั่นควรเป็น 1 ซึ่งเป็นสาเหตุที่เราต้องการให้พื้นที่ข้างใต้นี้เป็น 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.85,
  "end": 819.41
 },
 {
  "input": "The mean just marches steadily on to the right, which is why our distributions seem to be drifting off in that direction. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.63,
  "end": 824.87
 },
 {
  "input": "A little more challenging, but very important, is to describe how the standard deviation changes. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.35,
  "end": 829.91
 },
 {
  "input": "The key fact here is that if you have two different random variables, then the variance for the sum of those variables is the same as just adding together the original two variances. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.49,
  "end": 839.37
 },
 {
  "input": "This is one of those facts that you can just compute when you unpack all the definitions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.93,
  "end": 843.63
 },
 {
  "input": "There are a couple nice intuitions for why it's true. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.63,
  "end": 846.21
 },
 {
  "input": "My tentative plan is to just actually make a series about probability and talk about things like intuitions underlying variance and its cousins there. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 846.63,
  "end": 853.53
 },
 {
  "input": "But right now, the main thing I want you to highlight is how it's the variance that adds, it's not the standard deviation that adds. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 854.01,
  "end": 860.15
 },
 {
  "input": "So, critically, if you were to take n different realizations of the same random variable and ask what the sum looks like, the variance of that sum is n times the variance of your original variable, meaning the standard deviation, the square root of all this, is the square root of n times the original standard deviation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.41,
  "end": 878.25
 },
 {
  "input": "For example, back in our sequence of distributions, if we label the standard deviation of our initial one with sigma, then the next standard deviation is going to be the square root of 2 times sigma, and after that it looks like the square root of 3 times sigma, and so on and so forth. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 879.29,
  "end": 893.09
 },
 {
  "input": "This, like I said, is very important. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 893.75,
  "end": 895.65
 },
 {
  "input": "It means that even though our distributions are getting spread out, they're not spreading out all that quickly, they only do so in proportion to the square root of the size of the sum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 896.07,
  "end": 904.13
 },
 {
  "input": "As we prepare to make a more quantitative description of the central limit theorem, the core intuition I want you to keep in your head is that we'll basically realign all of these distributions so that their means line up together, and then rescale them so that all of the standard deviations are just going to be equal to 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 904.71,
  "end": 920.61
 },
 {
  "input": "And when we do that, the shape that results gets closer and closer to a certain universal shape, described with an elegant little function that we'll unpack in just a moment. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 921.29,
  "end": 929.87
 },
 {
  "input": "And let me say one more time, the real magic here is how we could have started with any distribution, describing a single roll of the die, and if we play the same game, considering what the distributions for the many different sums look like, and we realign them so that the means line up, and we rescale them so that the standard deviations are all 1, we still approach that same universal shape, which is kind of mind-boggling. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.47,
  "end": 952.95
 },
 {
  "input": "And now, my friends, is probably as good a time as any to finally get into the formula for a normal distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 954.81,
  "end": 960.85
 },
 {
  "input": "And the way I'd like to do this is to basically peel back all the layers and build it up one piece at a time. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 961.49,
  "end": 965.93
 },
 {
  "input": "The function e to the x, or anything to the x, describes exponential growth, and if you make that exponent negative, which flips around the graph horizontally, you might think of it as describing exponential decay. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 966.53,
  "end": 977.87
 },
 {
  "input": "To make this decay in both directions, you could do something to make sure the exponent is always negative and growing, like taking the negative absolute value. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.51,
  "end": 985.43
 },
 {
  "input": "That would give us this kind of awkward sharp point in the middle, but if instead you make that exponent the negative square of x, you get a smoother version of the same thing, which decays in both directions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 985.93,
  "end": 995.81
 },
 {
  "input": "This gives us the basic bell curve shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 996.33,
  "end": 998.19
 },
 {
  "input": "Now if you throw a constant in front of that x, and you scale that constant up and down, it lets you stretch and squish the graph horizontally, allowing you to describe narrow and wider bell curves. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 998.65,
  "end": 1008.37
 },
 {
  "input": "And a quick thing I'd like to point out here is that based on the rules of exponentiation, as we tweak around that constant c, you could also think about it as simply changing the base of the exponentiation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1009.01,
  "end": 1019.75
 },
 {
  "input": "And in that sense, the number e is not really all that special for our formula. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1020.15,
  "end": 1023.63
 },
 {
  "input": "We could replace it with any other positive constant, and you'll get the same family of curves as we tweak that constant. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1024.05,
  "end": 1030.49
 },
 {
  "input": "Make it a 2, same family of curves. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1031.51,
  "end": 1033.11
 },
 {
  "input": "Make it a 3, same family of curves. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1033.33,
  "end": 1035.07
 },
 {
  "input": "The reason we use e is that it gives that constant a very readable meaning. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.75,
  "end": 1039.49
 },
 {
  "input": "Or rather, if we reconfigure things a little bit so that the exponent looks like negative one half times x divided by a certain constant, which we'll suggestively call sigma squared, then once we turn this into a probability distribution, that constant sigma will be the standard deviation of that distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1040.11,
  "end": 1057.21
 },
 {
  "input": "And that's very nice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.81,
  "end": 1058.57
 },
 {
  "input": "But before we can interpret this as a probability distribution, we need the area under the curve to be 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1058.91,
  "end": 1064.31
 },
 {
  "input": "And the reason for that is how the curve is interpreted. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1064.83,
  "end": 1066.91
 },
 {
  "input": "Unlike discrete distributions, when it comes to something continuous, you don't ask about the probability of a particular point. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1067.37,
  "end": 1073.37
 },
 {
  "input": "Instead, you ask for the probability that a value falls between two different values. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1073.79,
  "end": 1078.23
 },
 {
  "input": "And what the curve is telling you is that that probability equals the area under the curve between those two values. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1078.75,
  "end": 1085.43
 },
 {
  "input": "There's a whole other video about this, they're called probability density functions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1086.03,
  "end": 1089.43
 },
 {
  "input": "The main point right now is that the area under the entire curve represents the probability that something happens, that some number comes up. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1089.83,
  "end": 1097.15
 },
 {
  "input": "That should be 1, which is why we want the area under this to be 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1097.41,
  "end": 1100.63
 },
 {
  "input": "As it stands with the basic bell curve shape of e to the negative x squared, the area is not 1, it's actually the square root of pi. ",
  "translatedText": "เนื่องจากมันยืนด้วยเส้นโค้งระฆังพื้นฐานของ e กำลังลบ x กำลังสอง พื้นที่จึงไม่ใช่ 1 แต่จริงๆ แล้วมันคือรากที่สองของพาย ฉันรู้ใช่ไหม? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1101.05,
  "end": 1107.79
 },
 {
  "input": "I know, right? ",
  "translatedText": "พีมาทำอะไรที่นี่? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.41,
  "end": 1109.15
 },
 {
  "input": "What is pi doing here? ",
  "translatedText": "เกี่ยวอะไรกับวงกลม? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1109.27,
  "end": 1110.19
 },
 {
  "input": "What does this have to do with circles? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1110.29,
  "end": 1111.47
 },
 {
  "input": "Like I said at the start, I'd love to talk all about that in the next video. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.01,
  "end": 1115.05
 },
 {
  "input": "But if you can spare your excitement for our purposes right now, all it means is that we should divide this function by the square root of pi, and it gives us the area we want. ",
  "translatedText": "อย่างที่ผมบอกไปแล้วตอนต้น ผมอยากจะพูดถึงเรื่องนั้นในวิดีโอหน้า แต่ถ้าคุณเลิกตื่นเต้นกับจุดประสงค์ของเราตอนนี้ได้ นั่นหมายความว่าเราควรหารฟังก์ชันนี้ด้วยสแควร์รูทของพาย และมันจะให้พื้นที่ที่เราต้องการ ลองย้อนกลับไปดูค่าคงที่ที่เรามีก่อนหน้านี้ ครึ่ง 1 และซิกมา ผลลัพธ์ที่ได้คือการยืดกราฟออกด้วยตัวประกอบของซิกมา คูณรากที่สองของ 2 เราต้องหารด้วยค่านั้นเพื่อให้แน่ใจว่ามันมีพื้นที่เป็น 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.33,
  "end": 1123.17
 },
 {
  "input": "Throwing back in the constants we had earlier, the 1 half and the sigma, the effect there is to stretch out the graph by a factor of sigma times the square root of 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1123.61,
  "end": 1131.79
 },
 {
  "input": "So we also need to divide out by that in order to make sure it has an area of 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1132.41,
  "end": 1136.47
 },
 {
  "input": "And combining those fractions, the factor out front looks like 1 divided by sigma times the square root of 2 pi. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1136.47,
  "end": 1142.11
 },
 {
  "input": "This, finally, is a valid probability distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.91,
  "end": 1145.85
 },
 {
  "input": "As we tweak that value sigma, resulting in narrower and wider curves, that constant in the front always guarantees that the area equals 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1146.45,
  "end": 1154.31
 },
 {
  "input": "The special case where sigma equals 1 has a specific name, we call it the standard normal distribution, which plays an especially important role for you and me in this lesson. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1155.91,
  "end": 1164.51
 },
 {
  "input": "And all possible normal distributions are not only parameterized with this value sigma, but we also subtract off another constant mu from the variable x, and this essentially just lets you slide the graph left and right so that you can prescribe the mean of this distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1165.13,
  "end": 1180.21
 },
 {
  "input": "So in short, we have two parameters, one describing the mean, one describing the standard deviation, and they're all tied together in this big formula involving an e and a pi. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1180.99,
  "end": 1189.19
 },
 {
  "input": "Now that all of that is on the table, let's look back again at the idea of starting with some random variable and asking what the distributions for sums of that variable look like. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1189.19,
  "end": 1199.81
 },
 {
  "input": "As we've already gone over, when you increase the size of that sum, the resulting distribution will shift according to a growing mean, and it slowly spreads out according to a growing standard deviation. ",
  "translatedText": "แล้วรวมเศษส่วนพวกนั้น ตัวประกอบข้างหน้าดูเหมือน 1 หารด้วยซิกมา คูณสแควร์รูทของ 2 ไพ ในที่สุด นี่คือการแจกแจงความน่าจะเป็นที่ถูกต้อง ขณะที่เราปรับแต่งค่าซิกมา ซึ่งส่งผลให้เส้นโค้งแคบลงและกว้างขึ้น ค่าคงที่ด้านหน้าจะรับประกันว่าพื้นที่จะเท่ากับ 1 เสมอ กรณีพิเศษที่ซิกมาเท่ากับ 1 มีชื่อเฉพาะ เราเรียกมันว่าการแจกแจงแบบปกติมาตรฐาน ซึ่งมีบทบาทสำคัญอย่างยิ่งสำหรับคุณและฉันในบทเรียนนี้ และการแจกแจงแบบปกติที่เป็นไปได้ทั้งหมดไม่เพียงแต่ถูกตั้งพารามิเตอร์ด้วยค่าซิกมานี้เท่านั้น แต่เรายังลบค่าคงที่ mu ออกจากตัวแปร x ด้วย และนี่แค่ให้คุณเลื่อนกราฟไปทางซ้ายและขวา เพื่อกำหนดค่าเฉลี่ยของการกระจายตัวนี้ได้ สรุปได้ว่า เรามีพารามิเตอร์สองตัว ตัวหนึ่งอธิบายค่าเฉลี่ย ตัวหนึ่งอธิบายค่าเบี่ยงเบนมาตรฐาน และพวกมันทั้งหมดเชื่อมโยงกันในสูตรใหญ่นี้ เกี่ยวข้องกับ e กับ pi ตอนนี้เมื่อทั้งหมดอยู่บนโต๊ะแล้ว ลองย้อนกลับไปดูแนวคิดในการเริ่มต้นด้วยตัวแปรสุ่ม และถามว่าการกระจายตัวของผลบวกของตัวแปรนั้นเป็นอย่างไร เมื่อเราอธิบายไปแล้ว เมื่อคุณเพิ่มขนาดของผลรวมนั้น ผลการแจกแจงที่ได้จะเปลี่ยนไปตามค่าเฉลี่ยที่เพิ่มขึ้น และมันจะค่อยๆ กระจายตามค่าเบี่ยงเบนมาตรฐานที่เพิ่มขึ้น แล้วใส่สูตรจริงลงไป ถ้าเรารู้ค่าเฉลี่ยของตัวแปรสุ่มข้างใต้ เราเรียกมันว่า มิว และเรายังรู้ค่าเบี่ยงเบนมาตรฐานของมันด้วย และเราเรียกมันว่าซิกม่า แล้วค่าเฉลี่ยของผลบวกด้านล่างจะเป็น มิว คูณขนาดของผลรวม และค่าเบี่ยงเบนมาตรฐานจะเป็นซิกม่าคูณรากที่สองของขนาดนั้น ทีนี้ หากเราต้องการอ้างว่านี่ดูเหมือนเส้นโค้งระฆังมากขึ้นเรื่อยๆ และเส้นโค้งระฆังอธิบายด้วยพารามิเตอร์ที่ต่างกันสองตัวเท่านั้น ค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐาน คุณคงรู้ว่าต้องทำอย่างไร คุณสามารถแทนค่าทั้งสองค่านั้นลงในสูตรได้ และมันจะให้สูตรที่ชัดเจนมาก แม้จะซับซ้อน แต่ก็ควรจะพอดีกับการกระจายตัวของเรา แต่มีอีกวิธีหนึ่งที่เราสามารถอธิบายมันได้ ซึ่งดูหรูหรากว่าเล็กน้อยและทำให้เกิดภาพที่สนุกสนานมากที่เราสามารถสร้างขึ้นมาได้ แทนที่จะเน้นไปที่ผลรวมของตัวแปรสุ่มพวกนี้ ลองแก้ไขพจน์นี้กันหน่อย โดยที่เราจะทำคือ เราจะดูค่าเฉลี่ยที่เราคาดหวังว่าผลรวมนั้นจะได้ แล้วเราลบมันออกแล้วจะได้ นิพจน์ใหม่ของเรามีค่าเฉลี่ยเป็น 0 แล้วเราจะดูค่าเบี่ยงเบนมาตรฐานที่เราคาดหวังจากผลรวม แล้วหารด้วยค่านั้น ซึ่งโดยพื้นฐานก็แค่ขยายหน่วยใหม่เพื่อให้ค่าเบี่ยงเบนมาตรฐานของนิพจน์เท่ากับ 1 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1200.13,
  "end": 1209.81
 },
 {
  "input": "And putting some actual formulas to it, if we know the mean of our underlying random variable, we call it mu, and we also know its standard deviation, and we call it sigma, then the mean for the sum on the bottom will be mu times the size of the sum, and the standard deviation will be sigma times the square root of that size. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1210.33,
  "end": 1227.73
 },
 {
  "input": "So now, if we want to claim that this looks more and more like a bell curve, and a bell curve is only described by two different parameters, the mean and the standard deviation, you know what to do. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1228.19,
  "end": 1237.71
 },
 {
  "input": "You could plug those two values into the formula, and it gives you a highly explicit, albeit kind of complicated, formula for a curve that should closely fit our distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.93,
  "end": 1246.99
 },
 {
  "input": "But there's another way we can describe it that's a little more elegant and lends itself to a very fun visual that we can build up to. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.39,
  "end": 1254.81
 },
 {
  "input": "Instead of focusing on the sum of all of these random variables, let's modify this expression a little bit, where what we'll do is we'll look at the mean that we expect that sum to take, and we subtract it off so that our new expression has a mean of 0, and then we're going to look at the standard deviation we expect of our sum, and divide out by that, which basically just rescales the units so that the standard deviation of our expression will equal 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1255.27,
  "end": 1278.77
 },
 {
  "input": "This might seem like a more complicated expression, but it actually has a highly readable meaning. ",
  "translatedText": "นี่อาจดูเหมือนเป็นสำนวนที่ซับซ้อนกว่า แต่จริงๆ แล้วมีความหมายที่สามารถอ่านได้ง่ายมาก มันบอกว่าผลบวกนี้อยู่ห่างจากค่าเฉลี่ยเป็นเท่าใด? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1279.35,
  "end": 1284.09
 },
 {
  "input": "It's essentially saying how many standard deviations away from the mean is this sum? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1284.45,
  "end": 1289.67
 },
 {
  "input": "For example, this bar here corresponds to a certain value that you might find when you roll 10 dice and you add them all up, and its position a little above negative 1 is telling you that that value is a little bit less than one standard deviation lower than the mean. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1290.75,
  "end": 1303.87
 },
 {
  "input": "Also, by the way, in anticipation for the animation I'm trying to build to here, the way I'm representing things on that lower plot is that the area of each one of these bars is telling us the probability of the corresponding value rather than the height. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1305.13,
  "end": 1316.99
 },
 {
  "input": "You might think of the y-axis as representing not probability but a kind of probability density. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1317.23,
  "end": 1321.93
 },
 {
  "input": "The reason for this is to set the stage so that it aligns with the way we interpret continuous distributions, where the probability of falling between a range of values is equal to an area under a curve between those values. ",
  "translatedText": "ตัวอย่างเช่น แถบนี้ตรงกับค่าบางค่าที่คุณอาจพบเมื่อคุณทอยลูกเต๋า 10 ลูกแล้วบวกทั้งหมดเข้าด้วยกัน และตำแหน่งของมันอยู่เหนือลบ 1 เล็กน้อย กำลังบอกคุณว่าค่านั้นน้อยกว่าค่าเบี่ยงเบนมาตรฐานเล็กน้อย ต่ำกว่าค่าเฉลี่ย นอกจากนี้ เพื่อคาดหวังถึงแอนิเมชันที่ฉันกำลังพยายามสร้างที่นี่ วิธีที่ฉันนำเสนอสิ่งต่าง ๆ ในพล็อตด้านล่างก็คือ พื้นที่ของแท่งแต่ละแท่งกำลังบอกเราถึงความน่าจะเป็นของค่าที่สอดคล้องกัน มากกว่าความสูง คุณอาจคิดว่าแกน y ไม่ใช่ความน่าจะเป็น แต่เป็นความหนาแน่นของความน่าจะเป็น เหตุผลก็คือเพื่อกำหนดระยะให้สอดคล้องกับวิธีที่เราตีความการแจกแจงแบบต่อเนื่อง โดยที่ความน่าจะเป็นที่จะตกลงระหว่างช่วงของค่าจะเท่ากับพื้นที่ใต้เส้นโค้งระหว่างค่าเหล่านั้น โดยเฉพาะพื้นที่ของแท่งทั้งหมดรวมกันจะเป็น 1 เอาล่ะ เมื่อรวมทุกอย่างแล้ว มาสนุกกันหน่อยดีกว่า ผมขอเริ่มด้วยการย้อนกลับเพื่อให้การกระจายตัวด้านล่างแสดงถึงผลรวมที่ค่อนข้างน้อย เช่น การรวมตัวแปรสุ่มเพียง 3 ตัวเข้าด้วยกัน สังเกตว่าจะเกิดอะไรขึ้นเมื่อฉันเปลี่ยนการกระจายตัวที่เราเริ่มต้น เมื่อมีการเปลี่ยนแปลง การกระจายตัวที่ด้านล่างจะเปลี่ยนรูปร่างไปโดยสิ้นเชิง มันขึ้นอยู่กับสิ่งที่เราเริ่มต้นด้วย ถ้าเราปล่อยให้ขนาดของผลรวมเพิ่มขึ้นอีกหน่อย เช่น ขึ้นไปถึง 10 และเมื่อฉันเปลี่ยนการกระจายตัวของ x มันจะดูเหมือนโค้งระฆัง แต่ฉันสามารถหาการแจกแจงที่ทำให้รูปร่างเปลี่ยนได้ . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1322.27,
  "end": 1333.55
 },
 {
  "input": "In particular, the area of all the bars together is going to be 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1333.91,
  "end": 1336.73
 },
 {
  "input": "Now, with all of that in place, let's have a little fun. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1338.23,
  "end": 1340.95
 },
 {
  "input": "Let me start by rolling things back so that the distribution on the bottom represents a relatively small sum, like adding together only three such random variables. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1341.33,
  "end": 1349.01
 },
 {
  "input": "Notice what happens as I change the distribution we start with. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1349.45,
  "end": 1352.43
 },
 {
  "input": "As it changes, the distribution on the bottom completely changes its shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1352.73,
  "end": 1356.29
 },
 {
  "input": "It's very dependent on what we started with. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1356.51,
  "end": 1358.77
 },
 {
  "input": "If we let the size of our sum get a little bit bigger, say going up to 10, and as I change the distribution for x, it largely stays looking like a bell curve, but I can find some distributions that get it to change shape. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1360.35,
  "end": 1371.63
 },
 {
  "input": "For example, the really lopsided one where almost all the probability is in the numbers 1 or 6 results in this kind of spiky bell curve, and if you'll recall, earlier on I actually showed this in the form of a simulation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1372.23,
  "end": 1383.51
 },
 {
  "input": "So if you were wondering whether that spikiness was an artifact of the randomness or reflected the true distribution, turns out it reflects the true distribution. ",
  "translatedText": "ตัวอย่างเช่น ค่าที่ไม่สมดุลจริงๆ ซึ่งความน่าจะเป็นเกือบทั้งหมดอยู่ในตัวเลข 1 หรือ 6 ส่งผลให้เกิดเส้นโค้งระฆังแหลมคมแบบนี้ และถ้าคุณจำได้ ก่อนหน้านี้ฉันได้แสดงสิ่งนี้ไว้ในรูปแบบของการจำลองแล้ว ดังนั้น หากคุณสงสัยว่าความแหลมคมนั้นเป็นผลของการสุ่ม หรือสะท้อนถึงการกระจายตัวที่แท้จริง ปรากฎว่ามันสะท้อนถึงการกระจายตัวที่แท้จริง ในกรณีนี้ 10 ไม่ใช่ผลรวมมากพอสำหรับทฤษฎีบทขีดจำกัดจุดศูนย์กลางที่จะนำมาใช้ แต่ถ้าฉันปล่อยให้ผลรวมนั้นเพิ่มขึ้น และฉันพิจารณาบวกค่าที่แตกต่างกัน 50 ค่า ซึ่งจริงๆ แล้วไม่ได้ใหญ่ขนาดนั้น ไม่ว่าฉันจะเปลี่ยนการแจกแจงสำหรับตัวแปรสุ่มที่ซ่อนอยู่อย่างไร ก็จะไม่มีผลกระทบต่อรูปร่างของโครงเรื่องบน ด้านล่าง. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1384.13,
  "end": 1391.85
 },
 {
  "input": "In this case, 10 is not a large enough sum for the central limit theorem to kick in. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1392.29,
  "end": 1396.47
 },
 {
  "input": "But if instead I let that sum grow and I consider adding 50 different values, which is actually not that big, then no matter how I change the distribution for our underlying random variable, it has essentially no effect on the shape of the plot on the bottom. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1396.47,
  "end": 1410.69
 },
 {
  "input": "No matter where we start, all of the information and nuance for the distribution of x gets washed away, and we tend towards this single universal shape described by a very elegant function for the standard normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. ",
  "translatedText": "ไม่ว่าเราจะเริ่มต้นจากจุดไหน ข้อมูลและความแตกต่างเล็กๆ น้อยๆ ทั้งหมดสำหรับการแจกแจงของ x จะถูกล้างออกไป และเรามีแนวโน้มไปทางรูปทรงสากลรูปแบบเดียวนี้ ซึ่งอธิบายได้ด้วยฟังก์ชันที่สวยงามมากสำหรับการแจกแจงแบบปกติมาตรฐาน 1 ส่วนสแควร์รูทของ 2 ไพ คูณ e กำลังลบ x กำลังสองส่วน 2 นี่, นี่ตรงนี้คือสิ่งที่เกี่ยวกับทฤษฎีบทขีดจำกัดจุดศูนย์กลาง แทบจะทำอะไรไม่ได้เลยกับการกระจายตัวครั้งแรกนี้ จะเปลี่ยนรูปร่างที่เรามุ่งไป ทีนี้ ยิ่งคุณมีความคิดทางทฤษฎีมากขึ้นในหมู่พวกคุณแล้ว อาจจะยังสงสัยว่าทฤษฎีบทที่แท้จริงคืออะไร? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1411.17,
  "end": 1427.07
 },
 {
  "input": "This, this right here is what the central limit theorem is all about. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1427.81,
  "end": 1430.81
 },
 {
  "input": "Almost nothing you can do to this initial distribution changes the shape we tend towards. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1431.13,
  "end": 1435.31
 },
 {
  "input": "Now, the more theoretically minded among you might still be wondering, what is the actual theorem? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1439.03,
  "end": 1444.51
 },
 {
  "input": "Like, what's the mathematical statement that could be proved or disproved that we're claiming here? ",
  "translatedText": "เช่น ประโยคทางคณิตศาสตร์อะไรที่สามารถพิสูจน์หรือหักล้าง ที่เราอ้างได้ตรงนี้ได้? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1444.81,
  "end": 1448.91
 },
 {
  "input": "If you want a nice formal statement, here's how it might go. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1449.03,
  "end": 1451.67
 },
 {
  "input": "Consider this value, where we're summing up n different instantiations of our random variable, but tweaked and tuned so that its mean and standard deviation are 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1452.13,
  "end": 1459.89
 },
 {
  "input": "Again, meaning you can read it as asking how many standard deviations away from the mean is the sum. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1460.23,
  "end": 1465.35
 },
 {
  "input": "Then the actual rigorous no-jokes-this-time statement of the central limit theorem is that if you consider the probability that this value falls between two given real numbers, a and b, and you consider the limit of that probability as the size of your sum goes to infinity, then that limit is equal to a certain integral, which basically describes the area under a standard normal distribution between those two values. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1465.77,
  "end": 1489.65
 },
 {
  "input": "Again, there are three underlying assumptions that I have yet to tell you, but other than those, in all of its gory detail, this right here is the central limit theorem. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1491.25,
  "end": 1500.03
 },
 {
  "input": "All of that is a bit theoretical, so it might be helpful to bring things back down to Earth and turn back to the concrete example that I mentioned at the start, where you imagine rolling a die 100 times, and let's assume it's a fair die for this example, and you add together the results. ",
  "translatedText": "หากคุณต้องการข้อความที่เป็นทางการที่ดี ควรทำดังนี้ พิจารณาค่านี้ โดยที่เราสรุปอินสแตนซ์ต่างๆ ของตัวแปรสุ่มของเรา แต่ปรับแต่งและปรับแต่งเพื่อให้ค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานเป็น 1 อีกครั้ง หมายความว่าคุณอ่านได้โดยการถามว่าค่าเบี่ยงเบนมาตรฐานที่ห่างจากค่าเฉลี่ยคือผลรวมเท่าไร จากนั้น ข้อความที่ไม่ตลกในเวลานี้ที่เข้มงวดจริงของทฤษฎีบทขีดจำกัดศูนย์กลางก็คือ ถ้าคุณพิจารณาความน่าจะเป็นที่ค่านี้อยู่ระหว่างจำนวนจริงที่กำหนดสองตัว a และ b และคุณพิจารณาขีดจำกัดของความน่าจะเป็นนั้นเป็นขนาดของ ผลรวมของคุณกลายเป็นอนันต์ แล้วขีดจำกัดนั้นจะเท่ากับอินทิกรัลจำนวนหนึ่ง ซึ่งโดยทั่วไปจะอธิบายพื้นที่ภายใต้การแจกแจงแบบปกติมาตรฐานระหว่างสองค่านั้น ขอย้ำอีกครั้งว่า มีสมมุติฐานอยู่สามข้อที่ผมยังไม่ได้บอกคุณ แต่นอกเหนือจากนั้น ในรายละเอียดอันน่าสยดสยอง นี่คือทฤษฎีบทลิมิตจุดศูนย์กลาง ทั้งหมดนี้เป็นทฤษฎีเล็กน้อย ดังนั้นการนำสิ่งต่างๆ กลับลงมายังโลกอาจเป็นประโยชน์ และย้อนกลับไปสู่ตัวอย่างที่เป็นรูปธรรม ที่ผมพูดถึงในตอนเริ่มต้น โดยที่คุณจินตนาการถึงการกลิ้งลูกเต๋า 100 ครั้ง และสมมติว่ามันเป็นการตายที่ยุติธรรม สำหรับตัวอย่างนี้ และคุณรวมผลลัพธ์เข้าด้วยกัน ความท้าทายสำหรับคุณคือการหาช่วงของค่าโดยที่คุณมั่นใจ 95% ว่าผลรวมจะอยู่ภายในช่วงนี้ สำหรับคำถามแบบนี้ มีกฎง่ายๆ เกี่ยวกับการแจกแจงแบบปกติ ซึ่งก็คือว่า ประมาณ 68% ของค่าจะตกอยู่ภายในค่าเบี่ยงเบนมาตรฐานของค่าเฉลี่ย 95% ของค่าของคุณ สิ่งที่เราสนใจ อยู่ภายในค่าเบี่ยงเบนมาตรฐาน ค่าเบี่ยงเบนมาตรฐานสองค่าของค่าเฉลี่ย และค่ามหาศาลคือ 99 7% ของค่าของคุณจะอยู่ภายในค่าเบี่ยงเบนมาตรฐานสามค่าของค่าเฉลี่ย เป็นกฎทั่วไปที่ผู้คนที่มีความน่าจะเป็นและสถิติจำนวนมากมักจะจดจำไว้ โดยธรรมชาติ นี่ทำให้เราได้สิ่งที่เราต้องการสำหรับตัวอย่างของเรา และขอผมวาดดูว่ามันจะเป็นอย่างไร โดยผมจะแสดงการกระจายตัวของค่าตายตัวที่ด้านบน และการกระจายตัวของผลรวม 100 ลูกเต๋าที่อยู่ด้านล่าง ซึ่งอย่างที่คุณทราบตอนนี้ดูเหมือนเป็นการแจกแจงแบบปกติ ขั้นตอนที่หนึ่งที่มีปัญหาเช่นนี้ คือหาค่าเฉลี่ยของการแจกแจงเริ่มต้น ซึ่งในกรณีนี้จะมีลักษณะเป็น 1 ใน 6 คูณ 1 บวก 1 ใน 6 คูณ 2 เรื่อยๆ และได้ผลออกมาเป็น 3 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1504.55,
  "end": 1518.13
 },
 {
  "input": "The challenge for you is to find a range of values such that you're 95% sure that the sum will fall within this range. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1518.87,
  "end": 1525.83
 },
 {
  "input": "For questions like this, there's a handy rule of thumb about normal distributions, which is that about 68% of your values are going to fall within one standard deviation of the mean, 95% of your values, the thing we care about, fall within two standard deviations of the mean, and a whopping 99.7% of your values will fall within three standard deviations of the mean. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1527.13,
  "end": 1546.97
 },
 {
  "input": "It's a rule of thumb that's commonly memorized by people who do a lot of probability and stats. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1547.45,
  "end": 1551.45
 },
 {
  "input": "Naturally, this gives us what we need for our example, and let me go ahead and draw out what this would look like, where I'll show the distribution for a fair die up at the top, and the distribution for a sum of 100 such dice on the bottom, which by now as you know looks like a certain normal distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1552.49,
  "end": 1567.29
 },
 {
  "input": "Step one with a problem like this is to find the mean of your initial distribution, which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on, and works out to be 3.5. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1567.95,
  "end": 1578.91
 },
 {
  "input": "We also need the standard deviation, which requires calculating the variance, which as you know involves adding all the squares of the differences between the values and the means, and it works out to be 2.92, square root of that comes out to be 1.71. ",
  "translatedText": "เรายังต้องการค่าเบี่ยงเบนมาตรฐาน ซึ่งต้องคำนวณความแปรปรวน ซึ่งอย่างที่คุณทราบคือการบวกกำลังสองทั้งหมดของความแตกต่างระหว่างค่ากับค่าเฉลี่ย และผลลัพธ์ที่ได้คือ 2 92 สแควร์รูทของนั่นออกมาเป็น 1 71. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1579.41,
  "end": 1592.43
 },
 {
  "input": "Those are the only two numbers we need, and I will invite you again to reflect on how magical it is that those are the only two numbers that you need to completely understand the bottom distribution. ",
  "translatedText": "นี่เป็นตัวเลขสองตัวเท่านั้นที่เราต้องการ และผมจะขอเชิญคุณอีกครั้งเพื่อพิจารณาว่ามันมหัศจรรย์แค่ไหนที่มันเป็นตัวเลขเพียงสองตัวเท่านั้นที่คุณต้องเข้าใจการกระจายตัวด้านล่างโดยสมบูรณ์ ค่าเฉลี่ยมันจะเป็น 100 คูณ มิว ซึ่งก็คือ 350 และค่าเบี่ยงเบนมาตรฐานจะเป็น สแควร์รูทของ 100 คูณซิกมา ได้ 10 คูณซิกมา 17 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1592.95,
  "end": 1601.69
 },
 {
  "input": "Its mean will be 100 times mu, which is 350, and its standard deviation will be the square root of 100 times sigma, so 10 times sigma 17.1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1602.43,
  "end": 1612.61
 },
 {
  "input": "Remembering our handy rule of thumb, we're looking for values two standard deviations away from the mean, and when you subtract 2 sigma from the mean you end up with about 316, and when you add 2 sigma you end up with 384. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1613.03,
  "end": 1626.33
 },
 {
  "input": "And there you go, that gives us the answer. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1627.35,
  "end": 1628.95
 },
 {
  "input": "Okay, I promised to wrap things up shortly, but while we're on this example there's one more question that's worth your time to ponder. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1631.47,
  "end": 1637.45
 },
 {
  "input": "Instead of just asking about the sum of 100 die rolls, let's say I had you divide that number by 100, which basically means all the numbers in our diagram in the bottom get divided by 100. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1638.25,
  "end": 1648.09
 },
 {
  "input": "Take a moment to interpret what this all would be saying then. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1648.57,
  "end": 1651.57
 },
 {
  "input": "The expression essentially tells you the empirical average for 100 different die rolls, and that interval we found is now telling you what range you are expecting to see for that empirical average. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1652.07,
  "end": 1663.49
 },
 {
  "input": "In other words, you might expect it to be around 3.5, that's the expected value for a die roll, but what's much less obvious and what the central limit theorem lets you compute is how close to that expected value you'll reasonably find yourself. ",
  "translatedText": "จำกฎง่ายๆ ของเราไว้ เรากำลังหาค่าเบี่ยงเบนมาตรฐาน 2 ค่าห่างจากค่าเฉลี่ย และเมื่อคุณลบ 2 ซิกมาจากค่าเฉลี่ย คุณจะกลายเป็น 316 และเมื่อคุณบวก 2 ซิกมา คุณจะเท่ากับ 384 แล้วคุณก็ไป นั่นให้คำตอบแก่เรา โอเค ฉันสัญญาว่าจะสรุปให้เสร็จสิ้นเร็วๆ นี้ แต่ในขณะที่เราอยู่ในตัวอย่างนี้ มีอีกคำถามหนึ่งที่คุ้มค่าแก่เวลาของคุณในการไตร่ตรอง แทนที่จะถามเกี่ยวกับผลรวมของลูกเต๋า 100 ลูก สมมติว่าฉันให้คุณหารตัวเลขนั้นด้วย 100 ซึ่งโดยทั่วไปหมายความว่าตัวเลขทั้งหมดในแผนภาพด้านล่างจะถูกหารด้วย 100 ใช้เวลาสักครู่เพื่อตีความสิ่งที่จะพูดทั้งหมดนี้ สำนวนนี้จะบอกค่าเฉลี่ยเชิงประจักษ์ของลูกกลิ้งแม่พิมพ์ 100 แบบที่แตกต่างกัน และช่วงที่เราพบนั้นกำลังบอกคุณว่าช่วงใดที่คุณคาดว่าจะเห็นสำหรับค่าเฉลี่ยเชิงประจักษ์นั้น กล่าวอีกนัยหนึ่ง คุณอาจคาดหวังว่ามันจะอยู่ที่ประมาณ 3 5 นั่นคือค่าที่คาดหวังสำหรับม้วนแม่พิมพ์ แต่สิ่งที่ชัดเจนน้อยกว่ามากและทฤษฎีบทขีดจำกัดกลางที่ให้คุณคำนวณได้ก็คือว่าคุณจะพบตัวเองได้ใกล้เคียงกับค่าที่คาดหวังนั้นมากน้อยเพียงใด โดยเฉพาะอย่างยิ่ง คุณควรใช้เวลาไตร่ตรองว่าค่าเบี่ยงเบนมาตรฐานสำหรับค่าเฉลี่ยเชิงประจักษ์นี้คืออะไร และจะเกิดอะไรขึ้นเมื่อคุณดูตัวอย่างแม่พิมพ์ที่ใหญ่ขึ้นเรื่อยๆ สุดท้ายนี้ แต่อาจสำคัญที่สุด เรามาพูดถึงสมมติฐานที่อยู่ในทฤษฎีบทนี้กัน อย่างแรกคือตัวแปรทั้งหมดที่เราบวกกัน มีความเป็นอิสระจากกัน ผลลัพธ์ของกระบวนการหนึ่งไม่ส่งผลต่อผลลัพธ์ของกระบวนการอื่นใด ประการที่สองคือตัวแปรทั้งหมดเหล่านี้มาจากการแจกแจงแบบเดียวกัน ทั้งสองอย่างนี้ได้รับการสมมติโดยปริยายกับตัวอย่างลูกเต๋าของเรา เราถือว่าผลลัพธ์ของทอยแต่ละทอยเป็นอิสระจากผลลัพธ์ของทอยอื่นๆ ทั้งหมด และเราสมมุติว่าแต่ละทอยมีการกระจายตัวแบบเดียวกัน บางครั้งในวรรณกรรม คุณจะเห็นสมมติฐานทั้งสองนี้รวมกันภายใต้ชื่อย่อ IID สำหรับการกระจายที่เป็นอิสระและเหมือนกัน สถานการณ์หนึ่งที่สมมติฐานเหล่านี้ไม่เป็นความจริงอย่างแน่นอนก็คือคณะกรรมการ Galton ฉันหมายถึงลองคิดดู เป็นกรณีที่วิธีที่ลูกบอลกระดอนจากหมุดตัวใดตัวหนึ่งนั้นไม่ขึ้นอยู่กับวิธีที่ลูกบอลจะกระดอนจากหมุดตัวถัดไปหรือไม่ ไม่ได้อย่างแน่นอน. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1664.35,
  "end": 1676.57
 },
 {
  "input": "In particular, it's worth your time to take a moment mulling over what the standard deviation for this empirical average is, and what happens to it as you look at a bigger and bigger sample of die rolls. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1677.59,
  "end": 1687.13
 },
 {
  "input": "Lastly, but probably most importantly, let's talk about the assumptions that go into this theorem. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1692.95,
  "end": 1697.41
 },
 {
  "input": "The first one is that all of these variables that we're adding up are independent from each other. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1698.01,
  "end": 1702.53
 },
 {
  "input": "The outcome of one process doesn't influence the outcome of any other process. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1702.85,
  "end": 1706.31
 },
 {
  "input": "The second is that all of these variables are drawn from the same distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1707.25,
  "end": 1710.95
 },
 {
  "input": "Both of these have been implicitly assumed with our dice example. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1711.31,
  "end": 1714.39
 },
 {
  "input": "We've been treating the outcome of each die roll as independent from the outcome of all the others, and we're assuming that each die follows the same distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1714.79,
  "end": 1722.03
 },
 {
  "input": "Sometimes in the literature you'll see these two assumptions lumped together under the initials IID for independent and identically distributed. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1722.85,
  "end": 1729.91
 },
 {
  "input": "One situation where these assumptions are decidedly not true would be the Galton board. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1730.53,
  "end": 1735.11
 },
 {
  "input": "I mean, think about it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1735.71,
  "end": 1736.83
 },
 {
  "input": "Is it the case that the way a ball bounces off of one of the pegs is independent from how it's going to bounce off the next peg? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1736.97,
  "end": 1743.19
 },
 {
  "input": "Absolutely not. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1743.83,
  "end": 1744.61
 },
 {
  "input": "Depending on the last bounce, it's coming in with a completely different trajectory. ",
  "translatedText": "ขึ้นอยู่กับการตีกลับครั้งสุดท้าย มันเข้ามาด้วยวิถีที่แตกต่างไปจากเดิมอย่างสิ้นเชิง และเป็นกรณีที่การกระจายผลลัพธ์ที่เป็นไปได้ของแต่ละหมุดนั้นเหมือนกันหรือไม่? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1744.77,
  "end": 1747.87
 },
 {
  "input": "And is it the case that the distribution of possible outcomes off of each peg are the same for each peg that it hits? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1748.21,
  "end": 1754.67
 },
 {
  "input": "Again, almost certainly not. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1755.19,
  "end": 1756.71
 },
 {
  "input": "Maybe it hits one peg glancing to the left, meaning the outcomes are hugely skewed in that direction, and then hits the next one glancing to the right. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1756.71,
  "end": 1763.71
 },
 {
  "input": "When I made all those simplifying assumptions in the opening example, it wasn't just to make this easier to think about. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1765.73,
  "end": 1771.63
 },
 {
  "input": "It's also that those assumptions were necessary for this to actually be an example of the central limit theorem. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1771.97,
  "end": 1777.07
 },
 {
  "input": "Nevertheless, it seems to be true that for the real Galton board, despite violating both of these, a normal distribution does kind of come about? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1778.13,
  "end": 1785.47
 },
 {
  "input": "Part of the reason might be that there are generalizations of the theorem beyond the scope of this video that relax these assumptions, especially the second one. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1786.05,
  "end": 1793.89
 },
 {
  "input": "But I do want to caution you against the fact that many times people seem to assume that a variable is normally distributed, even when there's no actual justification to do so. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1794.49,
  "end": 1803.07
 },
 {
  "input": "The third assumption is actually fairly subtle. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1804.29,
  "end": 1806.21
 },
 {
  "input": "It's that the variance we've been computing for these variables is finite. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1806.21,
  "end": 1810.27
 },
 {
  "input": "This was never an issue for the dice example, because there were only six possible outcomes. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1810.81,
  "end": 1814.85
 },
 {
  "input": "But in certain situations where you have an infinite set of outcomes, when you go to compute the variance, the sum ends up diverging off to infinity. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1815.03,
  "end": 1822.51
 },
 {
  "input": "These can be perfectly valid probability distributions, and they do come up in practice. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1823.45,
  "end": 1827.25
 },
 {
  "input": "But in those situations, as you consider adding many different instantiations of that variable and letting that sum approach infinity, even if the first two assumptions hold, it is very much a possibility that the thing you tend towards is not actually a normal distribution. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1827.55,
  "end": 1841.19
 },
 {
  "input": "If you've understood everything up to this point, you now have a very strong foundation in what the central limit theorem is all about. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1842.15,
  "end": 1847.65
 },
 {
  "input": "And next up, I'd like to explain why it is that this particular function is the thing that we tend towards, and why it has a pi in it, what it has to do with circles. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1848.29,
  "end": 1874.17
 }
]