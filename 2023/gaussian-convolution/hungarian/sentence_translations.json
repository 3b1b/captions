[
 {
  "input": "The basic function underlying a normal distribution, aka a Gaussian, is e to the negative x squared.",
  "translatedText": "A normális eloszlás, más néven Gauss eloszlás alapfüggvénye az e negatív x négyzetére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.12
 },
 {
  "input": "But you might wonder, why this function?",
  "translatedText": "De talán elgondolkodik, miért ez a funkció?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 6.64,
  "end": 8.34
 },
 {
  "input": "Of all the expressions we could dream up that give you some symmetric smooth graph with mass concentrated towards the middle, why is it that the theory of probability seems to have a special place in its heart for this particular expression?",
  "translatedText": "Az összes olyan kifejezés közül, amit megálmodhatnánk, amely valamilyen szimmetrikus sima gráfot ad, amelynek tömege a közepe felé koncentrálódik, miért van az, hogy a valószínűségelméletnek úgy tűnik, különleges helye van a szívében ennek a bizonyos kifejezésnek?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 8.72,
  "end": 20.44
 },
 {
  "input": "For the last many videos I've been hinting at an answer to this question, and here we'll finally arrive at something like a satisfying answer.",
  "translatedText": "Az elmúlt sok videóban utaltam a válaszra erre a kérdésre, és itt végre valami kielégítő válaszhoz jutunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 21.38,
  "end": 27.68
 },
 {
  "input": "As a quick refresher on where we are, a couple videos ago we talked about the central limit theorem, which describes how as you add multiple copies of a random variable, for example rolling a weighted die many different times, or letting a ball bounce off of a peg repeatedly, then the distribution describing that sum tends to look approximately like a normal distribution.",
  "translatedText": "Egy gyors felfrissítésként, hogy hol tartunk, néhány videóval ezelőtt beszéltünk a központi határértéktételről, amely leírja, hogy ha egy véletlen változó több példányát adjuk össze, például ha egy súlyozott kockát többször is megdobunk, vagy ha egy labdát többször is hagyunk lepattanni egy csapról, akkor az összeget leíró eloszlás közelítőleg úgy néz ki, mint egy normális eloszlás.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 27.68,
  "end": 47.72
 },
 {
  "input": "What the central limit theorem says is as you make that sum bigger and bigger, under appropriate conditions, that approximation to a normal becomes better and better.",
  "translatedText": "A központi határértéktétel szerint, ahogyan ezt az összeget egyre nagyobbra és nagyobbra növeljük, megfelelő feltételek mellett, a normálishoz való közelítés egyre jobb és jobb lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 48.44,
  "end": 56.22
 },
 {
  "input": "But I never explained why this theorem is actually true.",
  "translatedText": "De soha nem magyaráztam meg, hogy ez a tétel miért igaz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 56.94,
  "end": 60.18
 },
 {
  "input": "We only talked about what it's claiming.",
  "translatedText": "Csak arról beszéltünk, hogy mit állít.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 60.22,
  "end": 61.98
 },
 {
  "input": "In the last video we started talking about the math involved in adding two random variables.",
  "translatedText": "A legutóbbi videóban két véletlen változó összeadásának matematikájáról kezdtünk beszélgetni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 63.08,
  "end": 67.88
 },
 {
  "input": "If you have two random variables, each following some distribution, then to find the distribution describing the sum of those variables, you compute something known as a convolution between the two original functions.",
  "translatedText": "Ha van két véletlen változó, amelyek mindegyike valamilyen eloszlást követ, akkor a két változó összegét leíró eloszlás megtalálásához a két eredeti függvény közötti konvolúciót kell kiszámítani.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 68.26,
  "end": 79.7
 },
 {
  "input": "And we spent a lot of time building up two distinct ways to visualize what this convolution operation really is.",
  "translatedText": "És sok időt töltöttünk azzal, hogy két különböző módot dolgoztunk ki annak vizualizálására, hogy mi is ez a konvolúciós művelet valójában.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 79.88,
  "end": 85.94
 },
 {
  "input": "Today our basic job is to work through a particular example, which is to ask what happens when you add two normally distributed random variables, which, as you know by now, is the same as asking what do you get if you compute a convolution between two Gaussian functions.",
  "translatedText": "Ma az alapvető feladatunk az, hogy egy konkrét példát dolgozzunk fel, ami azt a kérdést teszi fel, hogy mi történik, ha két normális eloszlású véletlen változót összeadunk, ami, mint már tudják, ugyanaz, mintha azt kérdeznénk, hogy mit kapunk, ha két Gauss-függvény konvolúcióját számítjuk ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 85.94,
  "end": 101.78
 },
 {
  "input": "I'd like to share an especially pleasing visual way that you can think about this calculation, which hopefully offers some sense of what makes the e to the negative x squared function special in the first place.",
  "translatedText": "Szeretnék megosztani egy különösen tetszetős vizuális módot, ahogyan gondolkodhatsz erről a számításról, ami remélhetőleg ad némi értelmet annak, hogy mitől különleges az e a negatív x négyzet függvényhez.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 102.52,
  "end": 112.36
 },
 {
  "input": "After we walk through it, we'll talk about how this calculation is one of the steps involved in proving the central limit theorem.",
  "translatedText": "Miután végigvettük, beszélni fogunk arról, hogy ez a számítás a központi határértéktétel bizonyításának egyik lépése.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 112.36,
  "end": 118.24
 },
 {
  "input": "It's the step that answers the question of why a Gaussian and not something else is the central limit.",
  "translatedText": "Ez az a lépés, amely választ ad arra a kérdésre, hogy miért egy Gauss és nem valami más a központi határérték.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 118.32,
  "end": 123.56
 },
 {
  "input": "But first, let's dive in.",
  "translatedText": "De először is, merüljünk bele.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 124.2,
  "end": 125.84
 },
 {
  "input": "The full formula for a Gaussian is more complicated than just e to the negative x squared.",
  "translatedText": "A Gauss teljes képlete bonyolultabb, mint az e negatív x négyzetére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 129.78,
  "end": 134.44
 },
 {
  "input": "The exponent is typically written as negative one half times x divided by sigma squared, where sigma describes the spread of the distribution, specifically the standard deviation.",
  "translatedText": "Az exponens jellemzően úgy írható fel, hogy az x negatív fele osztva a sigma négyzetével, ahol a sigma az eloszlás szórását, pontosabban a szórást írja le.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 134.82,
  "end": 144.2
 },
 {
  "input": "All of this needs to be multiplied by a fraction on the front, which is there to make sure that the area under the curve is one, making it a valid probability distribution.",
  "translatedText": "Mindezt meg kell szorozni az előlapon lévő törttel, amely azért van, hogy a görbe alatti terület egy legyen, és így érvényes valószínűségi eloszlás legyen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 144.68,
  "end": 153.42
 },
 {
  "input": "And if you want to consider distributions that aren't necessarily centered at zero, you would also throw another parameter, mu, into the exponent like this.",
  "translatedText": "Ha pedig olyan eloszlásokat is figyelembe akarsz venni, amelyek nem feltétlenül nullával vannak központosítva, akkor egy másik paramétert, a mu-t is be kell dobnod az exponensbe, így.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 154.02,
  "end": 161.18
 },
 {
  "input": "Although for everything we'll be doing here, we just consider centered distributions.",
  "translatedText": "Bár minden, amit itt csinálni fogunk, csak a központosított eloszlásokat vesszük figyelembe.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 161.54,
  "end": 165.12
 },
 {
  "input": "Now if you look at our central goal for today, which is to compute a convolution between two Gaussian functions, the direct way to do this would be to take the definition of a convolution, this integral expression we built up last video, and then to plug in for each one of the functions involved the formula for a Gaussian.",
  "translatedText": "Ha most megnézzük a mai központi célunkat, ami két Gauss-függvény közötti konvolúció kiszámítása, akkor a közvetlen módja ennek az lenne, hogy fogjuk a konvolúció definícióját, ezt az integrál-kifejezést, amit a múltkori videóban építettünk fel, majd minden egyes érintett függvényhez beillesztjük a Gauss-képletet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 165.8,
  "end": 183.76
 },
 {
  "input": "It's kind of a lot of symbols when you throw it all together, but more than anything, working this out is an exercise in completing the square.",
  "translatedText": "Elég sok szimbólumot tartalmaz, ha összedobod az egészet, de mindennél többet jelent, hogy ennek a kidolgozása a négyzet kitöltésének gyakorlása.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 184.22,
  "end": 190.08
 },
 {
  "input": "And there's nothing wrong with that.",
  "translatedText": "És ezzel nincs is semmi baj.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 190.56,
  "end": 191.58
 },
 {
  "input": "That will get you the answer that you want.",
  "translatedText": "Így megkapja a kívánt választ.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 191.72,
  "end": 193.22
 },
 {
  "input": "But of course, you know me, I'm a sucker for visual intuition, and in this case, there's another way to think about it that I haven't seen written about before that offers a very nice connection to other aspects of this distribution, like the presence of pi and certain ways to derive where it comes from.",
  "translatedText": "De persze, ismersz engem, a vizuális intuíció híve vagyok, és ebben az esetben van egy másik módja is a gondolkodásnak, amiről még nem láttam korábban írni, ami nagyon szép kapcsolatot kínál az eloszlás más aspektusaihoz, mint például a pi jelenléte és bizonyos módjai annak, hogy levezessük, honnan származik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 193.76,
  "end": 207.86
 },
 {
  "input": "And the way I'd like to do this is by first peeling away all of the constants associated with the actual distribution, and just showing the computation for the simplified form, e to the negative x squared.",
  "translatedText": "És ezt úgy szeretném megtenni, hogy először lehámozom a tényleges eloszláshoz kapcsolódó összes állandót, és csak az egyszerűsített forma számítását mutatom be, e negatív x négyzetére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 208.2,
  "end": 217.96
 },
 {
  "input": "The essence of what we want to compute is what the convolution between two copies of this function looks like.",
  "translatedText": "A lényeg, amit ki akarunk számítani, az az, hogy hogyan néz ki a függvény két példánya közötti konvolúció.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 217.96,
  "end": 224.08
 },
 {
  "input": "If you'll remember, in the last video we had two different ways to visualize convolutions, and the one we'll be using here is the second one involving diagonal slices.",
  "translatedText": "Ha emlékeznek, az előző videóban két különböző módon szemléltettük a konvolúciókat, és az itt használt módszer a második, amelyik átlós szeleteket tartalmaz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.46,
  "end": 232.92
 },
 {
  "input": "And as a quick reminder of the way that worked, if you have two different distributions that are described by two different functions, f and g, then every possible pair of values that you might get when you sample from these two distributions can be thought of as individual points on the xy-plane.",
  "translatedText": "Egy gyors emlékeztető, hogy ez hogyan működik: ha van két különböző eloszlásunk, amelyeket két különböző függvény, f és g ír le, akkor minden lehetséges értékpár, amelyet a két eloszlásból történő mintavételezés során kaphatunk, az xy-sík egyes pontjainak tekinthető.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 233.28,
  "end": 249.56
 },
 {
  "input": "And the probability density of landing on one such point, assuming independence, looks like f of x times g of y.",
  "translatedText": "És a valószínűségi sűrűség, hogy egy ilyen pontra érkezünk, függetlenséget feltételezve, úgy néz ki, hogy f x szorozva g y-val.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 250.36,
  "end": 257.52
 },
 {
  "input": "So what we do is we look at a graph of that expression as a two-variable function of x and y, which is a way of showing the distribution of all possible outcomes when we sample from the two different variables.",
  "translatedText": "Tehát azt tesszük, hogy megnézzük a kifejezés grafikonját, mint az x és y kétváltozós függvényét, ami egy módja annak, hogy megmutassuk az összes lehetséges eredmény eloszlását, amikor a két különböző változóból mintát veszünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 258.0,
  "end": 269.62
 },
 {
  "input": "To interpret the convolution of f and g evaluated on some input s, which is a way of saying how likely are you to get a pair of samples that adds up to this sum s, what you do is you look at a slice of this graph over the line x plus y equals s, and you consider the area under that slice.",
  "translatedText": "Az f és g konvolúciójának értelmezéséhez, amelyet valamilyen s bemenetre értékelünk, ami azt jelenti, hogy milyen valószínűséggel kapunk olyan mintapárt, amely összeadja ezt az s összeget, azt kell tennünk, hogy megnézzük a grafikon egy szeletét az x plusz y egyenlő s egyenes felett, és megvizsgáljuk a szelet alatti területet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 270.56,
  "end": 289.3
 },
 {
  "input": "This area is almost, but not quite, the value of the convolution at s.",
  "translatedText": "Ez a terület majdnem, de nem egészen, a konvolúció értéke s-nél.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 291.1,
  "end": 296.32
 },
 {
  "input": "For a mildly technical reason, you need to divide by the square root of 2.",
  "translatedText": "Enyhén technikai okokból osztani kell a 2 négyzetgyökével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 296.8,
  "end": 300.16
 },
 {
  "input": "Still, this area is the key feature to focus on.",
  "translatedText": "Mégis, ez a terület a legfontosabb jellemző, amelyre összpontosítani kell.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 300.84,
  "end": 303.44
 },
 {
  "input": "You can think of it as a way to combine together all the probability densities for all of the outcomes corresponding to a given sum.",
  "translatedText": "Úgy is elképzelhetjük, hogy egy adott összegnek megfelelő összes kimenetel valószínűségi sűrűségét kombináljuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 303.44,
  "end": 311.04
 },
 {
  "input": "In the specific case where these two functions look like e to the negative x squared and e to the negative y squared, the resulting 3D graph has a really nice property that you can exploit.",
  "translatedText": "Abban a konkrét esetben, amikor ez a két függvény úgy néz ki, hogy e a negatív x négyzetére és e a negatív y négyzetére, az így kapott 3D grafikon egy nagyon szép tulajdonsággal rendelkezik, amelyet kihasználhatunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 313.3,
  "end": 323.5
 },
 {
  "input": "It's rotationally symmetric.",
  "translatedText": "Ez forgásszimmetrikus.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 323.72,
  "end": 325.68
 },
 {
  "input": "You can see this by combining the terms and noticing that it's entirely a function of x squared plus y squared, and this term describes the square of the distance between any point on the xy plane and the origin.",
  "translatedText": "Ezt úgy láthatjuk, ha kombináljuk a kifejezéseket, és észrevesszük, hogy ez teljes egészében az x négyzet plusz y négyzet függvénye, és ez a kifejezés az xy-sík bármely pontja és az origó közötti távolság négyzetét írja le.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 326.88,
  "end": 338.46
 },
 {
  "input": "So in other words, the expression is purely a function of the distance from the origin.",
  "translatedText": "Más szóval, a kifejezés pusztán az origótól való távolság függvénye.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 339.2,
  "end": 343.16
 },
 {
  "input": "And by the way, this would not be true for any other distribution.",
  "translatedText": "És egyébként ez nem lenne igaz semmilyen más terjesztésre.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 344.56,
  "end": 347.92
 },
 {
  "input": "It's a property that uniquely characterizes bell curves.",
  "translatedText": "Ez a tulajdonság egyedülállóan jellemzi a haranggörbéket.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.1,
  "end": 351.28
 },
 {
  "input": "So for most other pairs of functions, these diagonal slices will be some complicated shape that's hard to think about, and honestly, calculating the area would just amount to computing the original integral that defines a convolution in the first place.",
  "translatedText": "Tehát a legtöbb más függvénypár esetében ezek az átlós szeletek valami bonyolult alakúak lesznek, amire nehéz gondolni, és őszintén szólva, a terület kiszámítása csak annyit tenne ki, mint az eredeti integrál kiszámítása, ami a konvolúciót egyáltalán meghatározza.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 353.16,
  "end": 365.54
 },
 {
  "input": "So in most cases, the visual intuition doesn't really buy you anything.",
  "translatedText": "Tehát a legtöbb esetben a vizuális intuícióval nem igazán vásárolhatsz semmit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 365.94,
  "end": 369.36
 },
 {
  "input": "But in the case of bell curves, you can leverage that rotational symmetry.",
  "translatedText": "A haranggörbék esetében azonban kihasználhatjuk ezt a forgási szimmetriát.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 370.36,
  "end": 373.92
 },
 {
  "input": "Here, focus on one of these slices over the line x plus y equals s for some value of s.",
  "translatedText": "Itt koncentráljunk az egyik ilyen szeletre az x plusz y egyenlő s egyenes felett, s bizonyos értékére.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 374.8,
  "end": 380.48
 },
 {
  "input": "And remember, the convolution that we're trying to compute is a function of s.",
  "translatedText": "És ne feledjük, hogy a konvolúció, amit megpróbálunk kiszámítani, az s függvénye.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 381.3,
  "end": 385.84
 },
 {
  "input": "The thing that you want is an expression of s that tells you the area under this slice.",
  "translatedText": "Amit keresünk, az az s egy olyan kifejezése, amely megmondja, hogy mekkora terület van a szelet alatt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.84,
  "end": 391.1
 },
 {
  "input": "Well, if you look at that line, it intersects the x-axis at s zero and the y-axis at zero s, and a little bit of Pythagoras will show you that the straight line distance from the origin to this line is s divided by the square root of two.",
  "translatedText": "Nos, ha megnézzük ezt az egyenest, akkor az x-tengelyt s nulla pontnál, az y-tengelyt pedig s nulla pontnál metszi, és egy kis Pitagorasz-ismeret megmutatja, hogy az origótól az egyenes távolsága s osztva kettő négyzetgyökével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 391.7,
  "end": 405.32
 },
 {
  "input": "Now, because of the symmetry, this slice is identical to one that you get rotating 45 degrees where you'd find something parallel to the y-axis the same distance away from the origin.",
  "translatedText": "A szimmetria miatt ez a szelet megegyezik azzal, amit 45 fokos elforgatással kapunk, ahol az y-tengellyel párhuzamosan, az origótól ugyanolyan távolságra találunk valamit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 405.86,
  "end": 416.36
 },
 {
  "input": "The key is that computing this other area of a slice parallel to the y-axis is much, much easier than slices in other directions because it only involves taking an integral with respect to y.",
  "translatedText": "A lényeg az, hogy az y-tengellyel párhuzamos szelet másik területének kiszámítása sokkal, de sokkal egyszerűbb, mint a más irányú szeleteké, mivel csak egy integrál számítása szükséges az y-hez viszonyítva.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 417.64,
  "end": 428.26
 },
 {
  "input": "The value of x on this slice is a constant.",
  "translatedText": "Az x értéke ezen a szeleten egy konstans.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 428.74,
  "end": 431.44
 },
 {
  "input": "Specifically, it would be the constant s divided by the square root of two.",
  "translatedText": "Pontosabban, ez az s állandó osztva kettő négyzetgyökével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 431.62,
  "end": 434.76
 },
 {
  "input": "So when you're computing the integral, finding this area, all of this term here behaves like it was just some number, and you can factor it out.",
  "translatedText": "Tehát amikor kiszámítod az integrált, megtalálod ezt a területet, ez a kifejezés úgy viselkedik, mintha csak egy szám lenne, és ki tudod faktorálni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 434.76,
  "end": 443.38
 },
 {
  "input": "This is the important point.",
  "translatedText": "Ez a fontos pont.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 443.88,
  "end": 444.94
 },
 {
  "input": "All of the stuff that's involving s is now entirely separate from the integrated variable.",
  "translatedText": "Az összes dolog, ami az s-t érinti, már teljesen elkülönül az integrált változótól.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 445.28,
  "end": 450.2
 },
 {
  "input": "This remaining integral is a little bit tricky.",
  "translatedText": "Ez a fennmaradó integrál egy kicsit trükkös.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 450.82,
  "end": 453.0
 },
 {
  "input": "I did a whole video on it, it's actually quite famous.",
  "translatedText": "Csináltam egy egész videót róla, elég híres.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.08,
  "end": 455.2
 },
 {
  "input": "But you almost don't really care.",
  "translatedText": "De szinte nem is érdekel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 455.5,
  "end": 456.9
 },
 {
  "input": "The point is that it's just some number.",
  "translatedText": "A lényeg az, hogy ez csak egy szám.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 457.24,
  "end": 459.0
 },
 {
  "input": "That number happens to be the square root of pi, but what really matters is that it's something with no dependence on s.",
  "translatedText": "Ez a szám történetesen a pí négyzetgyöke, de ami igazán számít, az az, hogy ez a szám nem függ az s-től.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 459.0,
  "end": 465.48
 },
 {
  "input": "And essentially this is our answer.",
  "translatedText": "És lényegében ez a mi válaszunk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 466.88,
  "end": 468.48
 },
 {
  "input": "We were looking for an expression for the area of these slices as a function of s, and now we have it.",
  "translatedText": "Kerestünk egy kifejezést ezeknek a szeleteknek a területére s függvényében, és most megvan.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 468.78,
  "end": 474.28
 },
 {
  "input": "It looks like e to the negative s squared divided by two, scaled by some constant.",
  "translatedText": "Úgy néz ki, hogy e a negatív s négyzete osztva kettővel, valamilyen konstanssal skálázva.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 474.38,
  "end": 478.84
 },
 {
  "input": "In other words, it's also a bell curve, another Gaussian, just stretched out a little bit because of this two in the exponent.",
  "translatedText": "Más szóval, ez is egy haranggörbe, egy másik Gauss-görbe, csak egy kicsit megnyújtva, mert az exponensben ez a kettő van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 479.3,
  "end": 485.62
 },
 {
  "input": "As I said earlier, the convolution evaluated at s is not quite this area.",
  "translatedText": "Mint korábban említettem, az s-nél kiértékelt konvolúció nem egészen ez a terület.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 485.62,
  "end": 490.86
 },
 {
  "input": "Technically it's this area divided by the square root of two.",
  "translatedText": "Technikailag ez a terület osztva kettő négyzetgyökével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 491.34,
  "end": 494.16
 },
 {
  "input": "We talked about it in the last video, but it doesn't really matter because it just gets baked into the constant.",
  "translatedText": "A legutóbbi videóban beszéltünk róla, de ez nem igazán számít, mert ez egyszerűen beépül az állandóba.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 494.8,
  "end": 499.24
 },
 {
  "input": "What really matters is the conclusion that a convolution between two Gaussians is itself another Gaussian.",
  "translatedText": "Ami igazán számít, az a következtetés, hogy két Gauss közötti konvolúció maga is egy másik Gauss.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 499.68,
  "end": 505.68
 },
 {
  "input": "If you were to go back and reintroduce all of the constants for a normal distribution with a mean zero and an arbitrary standard deviation sigma, essentially identical reasoning will lead to the same square root of two factor that shows up in the exponent and out front, and it leads to the conclusion that the convolution between two such normal distributions is another normal distribution with a standard deviation square root of two times sigma.",
  "translatedText": "Ha visszamennénk, és újra bevezetnénk az összes állandót egy olyan normális eloszláshoz, amelynek átlaga nulla és tetszőleges szórású sigma, akkor a lényegében azonos érvelés ugyanahhoz a kettő négyzetgyökös tényezőhöz vezet, amely az exponensben és az előlapon is megjelenik, és ez ahhoz a következtetéshez vezet, hogy két ilyen normális eloszlás konvolúciója egy másik normális eloszlás, amelynek szórásnégyzete kétszeres sigma négyzetgyöke.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 507.56,
  "end": 530.38
 },
 {
  "input": "If you haven't computed a lot of convolutions before, it's worth emphasizing this is a very special result.",
  "translatedText": "Ha még nem számoltál sok konvolúciót, érdemes hangsúlyozni, hogy ez egy nagyon különleges eredmény.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 530.98,
  "end": 536.06
 },
 {
  "input": "Almost always you end up with a completely different kind of function, but here there's a sort of stability to the process.",
  "translatedText": "Majdnem mindig egy teljesen másfajta funkciót kapunk, de itt van egyfajta stabilitása a folyamatnak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 536.38,
  "end": 542.5
 },
 {
  "input": "Also, for those of you who enjoy exercises, I'll leave one up on the screen for how you would handle the case of two different standard deviations.",
  "translatedText": "Azoknak, akik szeretik a feladatokat, hagyok egyet a képernyőn, hogy hogyan kezelnék két különböző standard eltérés esetét.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 543.26,
  "end": 549.44
 },
 {
  "input": "Still, some of you might be raising your hands and saying, what's the big deal?",
  "translatedText": "Mégis, néhányan talán felemelik a kezüket, és azt mondják, mi ebben a nagy ügy?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 550.42,
  "end": 553.94
 },
 {
  "input": "I mean, when you first heard the question, what do you get when you add two normally distributed random variables, you probably even guessed that the answer should be another normally distributed variable.",
  "translatedText": "Úgy értem, amikor először hallottad a kérdést, hogy mit kapsz, ha két normális eloszlású véletlen változót összeadsz, valószínűleg még azt is kitaláltad, hogy a válasznak egy másik normális eloszlású változónak kell lennie.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 554.48,
  "end": 564.32
 },
 {
  "input": "After all, what else is it going to be?",
  "translatedText": "Végül is, mi más lehetne?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 564.76,
  "end": 566.36
 },
 {
  "input": "Normal distributions are supposedly quite common, so why not?",
  "translatedText": "A normális eloszlások állítólag elég gyakoriak, miért ne?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 566.86,
  "end": 570.24
 },
 {
  "input": "You could even say that this should follow from the central limit theorem.",
  "translatedText": "Azt is mondhatnánk, hogy ennek a központi határértéktételből kell következnie.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 570.24,
  "end": 573.34
 },
 {
  "input": "But that would have it all backwards.",
  "translatedText": "De ez az egész fordítva lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 573.86,
  "end": 575.48
 },
 {
  "input": "First of all, the supposed ubiquity of normal distributions is often a little exaggerated, but to the extent that they do come up, it is because of the central limit theorem, but it would be cheating to say the central limit theorem implies this result because this computation we just did is the reason that the function at the heart of the central limit theorem is a Gaussian in the first place, and not some other function.",
  "translatedText": "Először is, a normális eloszlások állítólagos mindenütt jelenléte gyakran kissé túlzó, de amennyiben mégis felbukkannak, az a központi határértéktétel miatt van, de csalás lenne azt mondani, hogy a központi határértéktétel implikálja ezt az eredményt, mert ez a számítás, amit az imént végeztünk, az oka annak, hogy a központi határértéktétel középpontjában álló függvény eleve egy Gauss, és nem valami más függvény.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 576.18,
  "end": 597.06
 },
 {
  "input": "We've talked all about the central limit theorem before, but essentially it says if you repeatedly add copies of a random variable to itself, which mathematically looks like repeatedly computing convolutions against a given distribution, then after appropriate shifting and rescaling, the tendency is always to approach a normal distribution.",
  "translatedText": "A központi határértéktételről már beszéltünk korábban, de lényegében azt mondja, hogy ha egy véletlen változó másolatait ismételten hozzáadjuk önmagához, ami matematikailag úgy néz ki, mintha egy adott eloszlással szemben ismételten konvolúciókat számolnánk, akkor a megfelelő eltolás és átméretezés után a tendencia mindig a normális eloszláshoz közelít.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 597.06,
  "end": 616.5
 },
 {
  "input": "Technically, there's a small assumption the distribution you start with can't have infinite variance, but it's a relatively soft assumption.",
  "translatedText": "Gyakorlatilag van egy kis feltételezés, hogy az eloszlás, amivel indulsz, nem lehet végtelen szórású, de ez egy viszonylag puha feltételezés.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 616.98,
  "end": 623.22
 },
 {
  "input": "The magic is that for a huge category of initial distributions, this process of adding a whole bunch of random variables drawn from that distribution always tends towards this one universal shape, a Gaussian.",
  "translatedText": "A varázslat az, hogy a kezdeti eloszlások hatalmas kategóriája esetében ez a folyamat, amelynek során egy csomó, az adott eloszlásból származó véletlen változót adunk hozzá, mindig egy univerzális alak, a Gauss-alak felé tendál.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 623.22,
  "end": 635.1
 },
 {
  "input": "One common approach to proving this theorem involves two separate steps.",
  "translatedText": "A tétel bizonyításának egyik gyakori megközelítése két külön lépést tartalmaz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 635.82,
  "end": 639.3
 },
 {
  "input": "The first step is to show that for all the different finite variance distributions you might start with, there exists a single universal shape that this process of repeated convolutions tends towards.",
  "translatedText": "Az első lépés az, hogy megmutassuk, hogy az összes különböző véges szórású eloszlásra, amiből kiindulhatunk, létezik egyetlen univerzális alak, amely felé az ismétlődő konvolúciók folyamata tendál.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 639.6,
  "end": 650.0
 },
 {
  "input": "This step is actually pretty technical, it goes a little beyond what I want to talk about here.",
  "translatedText": "Ez a lépés valójában elég technikai jellegű, kicsit túlmutat azon, amiről itt beszélni szeretnék.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 650.0,
  "end": 654.24
 },
 {
  "input": "You often use these objects called moment generating functions that gives you a very abstract argument that there must be some universal shape, but it doesn't make any claim about what that particular shape is, just that everything in this big family is tending towards a single point in the space of distributions.",
  "translatedText": "Gyakran használod ezeket a pillanatgeneráló függvényeknek nevezett objektumokat, amelyek egy nagyon absztrakt érvet adnak arra, hogy kell lennie valamilyen univerzális alakzatnak, de nem állít semmit arról, hogy mi ez a konkrét alakzat, csak azt, hogy ebben a nagy családban minden az eloszlások terének egyetlen pontja felé tendál.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 654.52,
  "end": 669.98
 },
 {
  "input": "So then step number two is what we just showed in this video, prove that the convolution of two Gaussians gives another Gaussian.",
  "translatedText": "A második lépés tehát az, amit az imént mutattunk be a videóban, bizonyítsuk be, hogy két Gauss konvolúciója egy másik Gauss-t ad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 670.62,
  "end": 677.4
 },
 {
  "input": "What that means is that as you apply this process of repeated convolutions, a Gaussian doesn't change, it's a fixed point, so the only thing it can approach is itself, and since it's one member in this big family of distributions, all of which must be tending towards a single universal shape, it must be that universal shape.",
  "translatedText": "Ez azt jelenti, hogy ahogyan ezt az ismétlődő tekercselési folyamatot alkalmazzuk, a Gauss nem változik, ez egy fix pont, így az egyetlen dolog, amit megközelíthet, az önmaga, és mivel ez egy tag ebben a nagy eloszláscsaládban, amelyek mindegyike egyetlen univerzális alak felé tendál, ennek az univerzális alaknak kell lennie.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.4,
  "end": 695.06
 },
 {
  "input": "I mentioned at the start how this calculation, step two, is something that you can do directly, just symbolically with the definitions, but one of the reasons I'm so charmed by a geometric argument that leverages the rotational symmetry of this graph is that it directly connects to a few things that we've talked about on this channel before, for example, the Herschel-Maxwell derivation of a Gaussian, which essentially says that you can view this rotational symmetry as the defining feature of the distribution, that it locks you into this e to the negative x squared form, and also as an added bonus, it connects to the classic proof for why pi shows up in the formula, meaning we now have a direct line between the presence and mystery of that pi and the central limit theorem.",
  "translatedText": "Az elején említettem, hogy ezt a számítást, a második lépést, közvetlenül is megtehetjük, csak szimbolikusan a definíciókkal, de az egyik ok, amiért annyira elbűvöl egy geometriai érv, amely kihasználja a gráf forgási szimmetriáját, az az, hogy közvetlenül kapcsolódik néhány dologhoz, amiről már beszéltünk ezen a csatornán, például a Gauss Herschel-Maxwell levezetéséhez, ami lényegében azt mondja, hogy ezt a forgási szimmetriát az eloszlás meghatározó tulajdonságának tekinthetjük, hogy ez rögzíti az e negatív x négyzet formáját, és egy további bónuszként kapcsolódik a klasszikus bizonyításhoz, hogy miért jelenik meg a pi a képletben, ami azt jelenti, hogy most már van egy közvetlen kapcsolat a pi jelenléte és rejtélye, valamint a központi határértéktétel között.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 695.58,
  "end": 736.5
 },
 {
  "input": "Also, on a recent Patreon post, the channel supporter Daksha Vaid-Quinter brought my attention to a completely different approach I hadn't seen before, which leverages the use of entropy, and again, for the theoretically curious among you, I'll leave some links in the description.",
  "translatedText": "Továbbá, egy nemrégiben közzétett Patreon-posztban a csatorna támogatója, Daksha Vaid-Quinter felhívta a figyelmemet egy teljesen más megközelítésre, amelyet még nem láttam korábban, amely az entrópia használatát használja, és ismét, az elméletileg kíváncsiak számára, hagyok néhány linket a leírásban.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 737.06,
  "end": 749.58
 },
 {
  "input": "By the way, if you want to stay up to date with new videos, and also any other projects that I put out there, like the Summer of Math Exposition, there is a mailing list.",
  "translatedText": "Egyébként, ha naprakész akarsz maradni az új videókkal és minden más projektemmel, például a Matematika Nyári Kiállítással kapcsolatban, van egy levelezőlista.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 750.96,
  "end": 758.4
 },
 {
  "input": "It's relatively new, and I'm pretty sparing about only posting what I think people will enjoy.",
  "translatedText": "Viszonylag új, és elég takarékosan bánok azzal, hogy csak azt teszem közzé, amiről úgy gondolom, hogy az emberek élvezni fogják.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 758.72,
  "end": 762.78
 },
 {
  "input": "Usually I try not to be too promotional at the end of videos these days, but if you are interested in following the work that I do, this is probably one of the most enduring ways to do so.",
  "translatedText": "Általában igyekszem nem túlságosan reklámozni a videók végén, de ha érdekel a munkám követése, akkor valószínűleg ez az egyik legtartósabb módja ennek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 763.22,
  "end": 795.26
 }
]