[
 {
  "input": "The basic function underlying a normal distribution, aka a Gaussian, is e to the negative x squared.",
  "translatedText": "Hàm cơ bản nằm dưới phân phối chuẩn, hay còn gọi là Gaussian, là e mũ âm x bình phương.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.12
 },
 {
  "input": "But you might wonder, why this function?",
  "translatedText": "Nhưng bạn có thể thắc mắc, tại sao lại có hàm này?",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 6.64,
  "end": 8.34
 },
 {
  "input": "Of all the expressions we could dream up that give you some symmetric smooth graph with mass concentrated towards the middle, why is it that the theory of probability seems to have a special place in its heart for this particular expression?",
  "translatedText": "Trong số tất cả các biểu thức mà chúng ta có thể nghĩ ra để cung cấp cho bạn một số đồ thị trơn đối xứng với khối lượng tập trung vào giữa, tại sao lý thuyết xác suất dường như lại có một vị trí đặc biệt cho biểu thức đặc biệt này?",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 8.72,
  "end": 20.44
 },
 {
  "input": "For the last many videos I've been hinting at an answer to this question, and here we'll finally arrive at something like a satisfying answer.",
  "translatedText": "Trong nhiều video gần đây nhất, mình đã gợi ý về câu trả lời cho câu hỏi này và ở đây, cuối cùng chúng ta cũng đã đi đến một câu trả lời thỏa mãn.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 21.38,
  "end": 27.68
 },
 {
  "input": "As a quick refresher on where we are, a couple videos ago we talked about the central limit theorem, which describes how as you add multiple copies of a random variable, for example rolling a weighted die many different times or letting a ball bounce off of a peg repeatedly, then the distribution describing that sum tends to look approximately like a normal distribution.",
  "translatedText": "Để ôn lại nhanh chúng ta đã đi đến đâu, một vài video trước chúng ta đã nói về định lý giới hạn trung tâm, mô tả cách bạn cộng nhiều bản sao của một biến ngẫu nhiên, chẳng hạn như lăn một con súc sắc có trọng số nhiều lần khác nhau hoặc để một quả bóng bật ra khỏi nó. một chốt lặp đi lặp lại thì phân phối mô tả tổng đó có xu hướng trông gần giống phân phối chuẩn.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 27.68,
  "end": 47.72
 },
 {
  "input": "What the central limit theorem says is as you make that sum bigger and bigger, under appropriate conditions, that approximation to a normal becomes better and better.",
  "translatedText": "Định lý giới hạn trung tâm nói rằng khi bạn làm cho tổng đó ngày càng lớn hơn, trong những điều kiện thích hợp, thì giá trị gần đúng với chuẩn đó sẽ ngày càng tốt hơn.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 48.44,
  "end": 56.22
 },
 {
  "input": "But I never explained why this theorem is actually true, we only talked about what it's claiming.",
  "translatedText": "Nhưng mình chưa bao giờ giải thích tại sao định lý này thực sự đúng, chúng ta chỉ nói về điều nó khẳng định.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 56.94,
  "end": 61.98
 },
 {
  "input": "In the last video we started talking about the math involved in adding two random variables.",
  "translatedText": "Trong video trước, chúng ta đã bắt đầu nói về phép toán liên quan đến việc cộng hai biến ngẫu nhiên.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 63.08,
  "end": 67.88
 },
 {
  "input": "If you have two random variables, each following some distribution, then to find the distribution describing the sum of those variables, you compute something known as a convolution between the two original functions.",
  "translatedText": "Nếu bạn có hai biến ngẫu nhiên, mỗi biến tuân theo một phân phối nào đó, thì để tìm phân phối mô tả tổng của các biến đó, bạn tính một thứ gọi là tích chập giữa hai hàm ban đầu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.26,
  "end": 79.7
 },
 {
  "input": "And we spent a lot of time building up two distinct ways to visualize what this convolution operation really is.",
  "translatedText": "Và chúng ta đã dành rất nhiều thời gian để xây dựng hai cách riêng biệt để hình dung phép toán tích chập này thực sự là gì.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 79.88,
  "end": 85.94
 },
 {
  "input": "Today our basic job is to work through a particular example, which is to ask what happens when you add two normally distributed random variables, which as you know by now is the same as asking what do you get if you compute a convolution between two Gaussian functions.",
  "translatedText": "Hôm nay, công việc cơ bản của chúng ta là giải quyết một ví dụ cụ thể, đó là hỏi điều gì sẽ xảy ra khi bạn cộng hai biến ngẫu nhiên có phân phối chuẩn, mà như bạn biết bây giờ cũng giống như hỏi bạn nhận được gì nếu tính tích chập giữa hai hàm Gaussian.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 85.94,
  "end": 101.78
 },
 {
  "input": "I'd like to share an especially pleasing visual way that you can think about this calculation, which hopefully offers some sense of what makes the e to the negative x squared function special in the first place.",
  "translatedText": "Mình muốn chia sẻ một cách trực quan đặc biệt thú vị mà bạn có thể nghĩ về phép tính này, hy vọng mang lại ý nghĩa nào đó về điều gì làm cho hàm e mũ âm x bình phương trở nên đặc biệt ngay từ đầu.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 102.52,
  "end": 112.36
 },
 {
  "input": "After we walk through it, we'll talk about how this calculation is one of the steps involved in proving the central limit theorem.",
  "translatedText": "Sau khi xem qua nó, chúng ta sẽ nói về cách tính toán này là một trong những bước liên quan đến việc chứng minh định lý giới hạn trung tâm.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 112.36,
  "end": 118.24
 },
 {
  "input": "It's the step that answers the question of why a Gaussian and not something else is the central limit.",
  "translatedText": "Đây là bước để trả lời câu hỏi tại sao một Gaussian, không phải cái gì khác mà lại là giới hạn trung tâm.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 118.32,
  "end": 123.56
 },
 {
  "input": "But first, let's dive in.",
  "translatedText": "Nhưng trước tiên, ta hãy đi sâu vào.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 124.2,
  "end": 125.84
 },
 {
  "input": "The full formula for a Gaussian is more complicated than just e to the negative x squared.",
  "translatedText": "Công thức đầy đủ cho một Gaussian phức tạp hơn chỉ là e mũ âm x bình phương.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 129.78,
  "end": 134.44
 },
 {
  "input": "The exponent is typically written as negative one half times x divided by sigma squared, where sigma describes the spread of the distribution, specifically the standard deviation.",
  "translatedText": "Số mũ thường được viết dưới dạng âm một nửa x chia cho bình phương sigma, trong đó sigma mô tả mức độ phân bố, cụ thể là độ lệch chuẩn.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.82,
  "end": 144.2
 },
 {
  "input": "All of this needs to be multiplied by a fraction on the front, which is there to make sure that the area under the curve is one, making it a valid probability distribution.",
  "translatedText": "Tất cả những điều này cần phải được nhân với một phân số ở phía trước, để đảm bảo rằng diện tích dưới đường cong là một, làm cho nó trở thành một phân bố xác suất hợp lệ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.68,
  "end": 153.42
 },
 {
  "input": "And if you want to consider distributions that aren't necessarily centered at zero, you would also throw another parameter, mu, into the exponent like this.",
  "translatedText": "Và nếu bạn muốn xem xét các phân bố không nhất thiết phải tập trung vào số 0, bạn cũng sẽ đưa một tham số khác, mu, vào số mũ như thế này.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 154.02,
  "end": 161.18
 },
 {
  "input": "Although for everything we'll be doing here, we just consider centered distributions.",
  "translatedText": "Mặc dù đối với mọi thứ chúng ta sẽ làm ở đây, chúng ta chỉ xem xét sự phân bố tập trung.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 161.54,
  "end": 165.12
 },
 {
  "input": "Now if you look at our central goal for today, which is to compute a convolution between two Gaussian functions, the direct way to do this would be to take the definition of a convolution, this integral expression we built up last video, and then to plug in for each one of the functions involved the formula for a Gaussian.",
  "translatedText": "Bây giờ nếu bạn nhìn vào mục tiêu chính của chúng ta ngày hôm nay, đó là tính tích chập giữa hai hàm Gauss, cách trực tiếp để làm điều này là lấy định nghĩa của tích chập, biểu thức tích phân mà chúng ta đã xây dựng trong video trước, và sau đó là cắm vào từng hàm liên quan đến công thức của Gaussian.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.8,
  "end": 183.76
 },
 {
  "input": "It's kind of a lot of symbols when you throw it all together, but more than anything, working this out is an exercise in completing the square.",
  "translatedText": "Nó có rất nhiều biểu tượng khi bạn gộp tất cả lại với nhau, nhưng hơn hết, việc giải quyết vấn đề này là một bài tập để hoàn thiện hình vuông.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 184.22,
  "end": 190.08
 },
 {
  "input": "And there's nothing wrong with that.",
  "translatedText": "Và không có gì sai với điều đó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.56,
  "end": 191.58
 },
 {
  "input": "That will get you the answer that you want.",
  "translatedText": "Điều đó sẽ giúp bạn có được câu trả lời mà bạn muốn.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 191.72,
  "end": 193.22
 },
 {
  "input": "But of course, you know me, I'm a sucker for visual intuition, and in this case, there's another way to think about it that I haven't seen written about before, that offers a very nice connection to other aspects of this distribution, like the presence of pi and certain ways to derive where it comes from.",
  "translatedText": "Nhưng tất nhiên, bạn biết tôi mà, tôi là người rất thích trực giác thị giác, và trong trường hợp này, có một cách khác để nghĩ về nó mà tôi chưa từng thấy được viết trước đây, nó mang lại một mối liên hệ rất tốt đẹp với các khía cạnh khác của vấn đề này. phân phối, như sự hiện diện của số pi và một số cách nhất định để tìm ra nguồn gốc của nó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.76,
  "end": 207.86
 },
 {
  "input": "And the way I'd like to do this is by first peeling away all of the constants associated with the actual distribution, and just showing the computation for the simplified form, e to the negative x squared.",
  "translatedText": "Và cách tôi muốn làm điều này trước tiên là loại bỏ tất cả các hằng số liên quan đến phân bố thực tế và chỉ hiển thị phép tính ở dạng đơn giản, e mũ âm x bình phương.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.2,
  "end": 217.96
 },
 {
  "input": "The essence of what we want to compute is what the convolution between two copies of this function looks like.",
  "translatedText": "Bản chất của những gì chúng ta muốn tính toán là sự tích chập giữa hai bản sao của hàm này trông như thế nào.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 217.96,
  "end": 224.08
 },
 {
  "input": "If you'll remember, in the last video we had two different ways to visualize convolutions, and the one we'll be using here is the second one, involving diagonal slices.",
  "translatedText": "Nếu bạn còn nhớ, trong video trước chúng ta đã có hai cách khác nhau để hình dung các phép cuộn và cách chúng ta sẽ sử dụng ở đây là cách thứ hai, liên quan đến các lát cắt chéo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.46,
  "end": 232.92
 },
 {
  "input": "And as a quick reminder of the way that worked, if you have two different distributions that are described by two different functions, f and g, then every possible pair of values that you might get when you sample from these two distributions can be thought of as individual points on the xy-plane.",
  "translatedText": "Và như một lời nhắc nhở nhanh về cách thức hoạt động, nếu bạn có hai phân bố khác nhau được mô tả bởi hai hàm khác nhau, f và g, thì mọi cặp giá trị có thể có mà bạn có thể nhận được khi lấy mẫu từ hai phân bố này đều có thể được nghĩ đến dưới dạng các điểm riêng lẻ trên mặt phẳng xy.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 233.28,
  "end": 249.56
 },
 {
  "input": "And the probability density of landing on one such point, assuming independence, looks like f of x times g of y.",
  "translatedText": "Và mật độ xác suất để hạ cánh trên một điểm như vậy, giả sử tính độc lập, trông giống như f(x nhân g của y).",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.36,
  "end": 257.52
 },
 {
  "input": "So what we do is we look at a graph of that expression as a two-variable function of x and y, which is a way of showing the distribution of all possible outcomes when we sample from the two different variables.",
  "translatedText": "Vì vậy, những gì chúng ta làm là xem biểu đồ của biểu thức đó như một hàm hai biến của x và y, đây là một cách thể hiện sự phân bố của tất cả các kết quả có thể xảy ra khi chúng ta lấy mẫu từ hai biến khác nhau.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.0,
  "end": 269.62
 },
 {
  "input": "To interpret the convolution of f and g evaluated on some input s, which is a way of saying how likely are you to get a pair of samples that adds up to this sum s, what you do is you look at a slice of this graph over the line x plus y equals s, and you consider the area under that slice.",
  "translatedText": "Để giải thích tích chập của f và g được đánh giá trên một số đầu vào s, đó là một cách để nói khả năng bạn nhận được một cặp mẫu có tổng bằng s này, điều bạn làm là nhìn vào một lát cắt của biểu đồ này trên đường x cộng y bằng s, và bạn xét diện tích bên dưới lát cắt đó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 270.56,
  "end": 289.3
 },
 {
  "input": "This area is almost, but not quite, the value of the convolution at s.",
  "translatedText": "Diện tích này gần như, nhưng không hoàn toàn, giá trị của tích chập tại s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.1,
  "end": 296.32
 },
 {
  "input": "For a mildly technical reason, you need to divide by the square root of two.",
  "translatedText": "Vì lý do kỹ thuật nhẹ nhàng, bạn cần chia cho căn bậc hai của 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 296.8,
  "end": 300.16
 },
 {
  "input": "Still, this area is the key feature to focus on.",
  "translatedText": "Tuy nhiên, khu vực này là tính năng chính cần tập trung vào.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.84,
  "end": 303.44
 },
 {
  "input": "You can think of it as a way to combine together all the probability densities for all of the outcomes corresponding to a given sum.",
  "translatedText": "Bạn có thể coi nó như một cách để kết hợp tất cả mật độ xác suất cho tất cả các kết quả tương ứng với một tổng nhất định.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 303.44,
  "end": 311.04
 },
 {
  "input": "In the specific case where these two functions look like e to the negative x squared and e to the negative y squared, the resulting 3D graph has a really nice property that you can exploit.",
  "translatedText": "Trong trường hợp cụ thể khi hai hàm này trông giống như e mũ âm x bình phương và e mũ âm y bình phương, đồ thị 3D thu được có một đặc tính thực sự hay mà bạn có thể khai thác.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.3,
  "end": 323.5
 },
 {
  "input": "It's rotationally symmetric.",
  "translatedText": "Nó đối xứng xoay.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.72,
  "end": 325.68
 },
 {
  "input": "You can see this by combining the terms and noticing that it's entirely a function of x squared plus y squared, and this term describes the square of the distance between any point on the xy plane and the origin.",
  "translatedText": "Bạn có thể thấy điều này bằng cách kết hợp các số hạng và nhận thấy rằng nó hoàn toàn là một hàm của x bình cộng y bình, và số hạng này mô tả bình phương khoảng cách giữa bất kỳ điểm nào trên mặt phẳng xy và gốc tọa độ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 326.88,
  "end": 338.46
 },
 {
  "input": "So in other words, the expression is purely a function of the distance from the origin.",
  "translatedText": "Vì vậy, nói cách khác, biểu thức hoàn toàn là một hàm của khoảng cách từ gốc tọa độ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 339.2,
  "end": 343.16
 },
 {
  "input": "And by the way, this would not be true for any other distribution.",
  "translatedText": "Và nhân tiện, điều này sẽ không đúng với bất kỳ bản phân phối nào khác.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.56,
  "end": 347.92
 },
 {
  "input": "It's a property that uniquely characterizes bell curves.",
  "translatedText": "Đó là một thuộc tính đặc trưng độc đáo cho đường cong hình chuông.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.1,
  "end": 351.28
 },
 {
  "input": "So for most other pairs of functions, these diagonal slices will be some complicated shape that's hard to think about, and honestly calculating the area would just amount to computing the original integral that defines a convolution in the first place.",
  "translatedText": "Vì vậy, đối với hầu hết các cặp hàm khác, những lát cắt chéo này sẽ có một số hình dạng phức tạp khó nghĩ tới, và việc tính diện tích một cách trung thực sẽ chỉ tương đương với việc tính tích phân ban đầu xác định tích chập ngay từ đầu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.16,
  "end": 365.54
 },
 {
  "input": "So in most cases, the visual intuition doesn't really buy you anything.",
  "translatedText": "Vì vậy, trong hầu hết các trường hợp, trực giác trực quan không thực sự mang lại cho bạn bất cứ thứ gì.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.94,
  "end": 369.36
 },
 {
  "input": "But in the case of bell curves, you can leverage that rotational symmetry.",
  "translatedText": "Nhưng trong trường hợp đường cong hình chuông, bạn có thể tận dụng tính đối xứng quay đó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.36,
  "end": 373.92
 },
 {
  "input": "Here, focus on one of these slices over the line x plus y equals s for some value of s.",
  "translatedText": "Ở đây, tập trung vào một trong những lát cắt này trên đường x cộng y bằng s với một số giá trị của s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.8,
  "end": 380.48
 },
 {
  "input": "And remember, the convolution that we're trying to compute is a function of s.",
  "translatedText": "Và hãy nhớ, tích chập mà chúng ta đang tính là một hàm của s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 381.3,
  "end": 385.84
 },
 {
  "input": "The thing that you want is an expression of s that tells you the area under this slice.",
  "translatedText": "Điều bạn muốn là một biểu thức của s cho bạn biết diện tích bên dưới lát cắt này.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.84,
  "end": 391.1
 },
 {
  "input": "Well, if you look at that line, it intersects the x-axis at s zero and the y-axis at zero s.",
  "translatedText": "Vâng, nếu bạn nhìn vào đường thẳng đó, nó cắt trục x tại s 0 và trục y tại 0 s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.7,
  "end": 397.9
 },
 {
  "input": "And a little bit of Pythagoras will show you that the straight line distance from the origin to this line is s divided by the square root of two.",
  "translatedText": "Và một chút về Pythagoras sẽ cho bạn thấy rằng khoảng cách đường thẳng từ gốc tọa độ đến đường thẳng này bằng s chia cho căn bậc hai của 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.32,
  "end": 405.32
 },
 {
  "input": "Now, because of the symmetry, this slice is identical to one that you get rotating 45 degrees, where you'd find something parallel to the y-axis the same distance away from the origin.",
  "translatedText": "Bây giờ, do tính đối xứng, lát cắt này giống hệt với lát cắt mà bạn xoay 45 độ, trong đó bạn sẽ tìm thấy một vật nào đó song song với trục y và có cùng khoảng cách so với gốc tọa độ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 405.86,
  "end": 416.36
 },
 {
  "input": "The key is that computing this other area of a slice parallel to the y-axis is much, much easier than slices in other directions, because it only involves taking an integral with respect to y.",
  "translatedText": "Điều quan trọng là việc tính diện tích khác này của một lát cắt song song với trục y dễ dàng hơn nhiều so với các lát cắt theo các hướng khác, bởi vì nó chỉ liên quan đến việc lấy tích phân theo y.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 417.64,
  "end": 428.26
 },
 {
  "input": "The value of x on this slice is a constant.",
  "translatedText": "Giá trị của x trên lát cắt này là một hằng số.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.74,
  "end": 431.44
 },
 {
  "input": "Specifically, it would be the constant s divided by the square root of two.",
  "translatedText": "Cụ thể, nó sẽ là hằng số s chia cho căn bậc hai của 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 431.62,
  "end": 434.76
 },
 {
  "input": "So when you're computing the integral, finding this area, all of this term here behaves like it was just some number, and you can factor it out.",
  "translatedText": "Vì vậy, khi bạn tính tích phân, tìm diện tích này, tất cả số hạng ở đây hoạt động giống như nó chỉ là một số nào đó, và bạn có thể phân tích nó thành nhân tử.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.76,
  "end": 443.38
 },
 {
  "input": "This is the important point.",
  "translatedText": "Đây là điểm quan trọng.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 443.88,
  "end": 444.94
 },
 {
  "input": "All of the stuff that's involving s is now entirely separate from the integrated variable.",
  "translatedText": "Tất cả những thứ liên quan đến s bây giờ hoàn toàn tách biệt với biến tích hợp.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 445.28,
  "end": 450.2
 },
 {
  "input": "This remaining integral is a little bit tricky.",
  "translatedText": "Tích phân còn lại này hơi phức tạp một chút.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 450.82,
  "end": 453.0
 },
 {
  "input": "I did a whole video on it, it's actually quite famous.",
  "translatedText": "Tôi đã làm cả một video về nó, nó thực sự khá nổi tiếng.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.08,
  "end": 455.2
 },
 {
  "input": "But you almost don't really care.",
  "translatedText": "Nhưng bạn hầu như không thực sự quan tâm.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 455.5,
  "end": 456.9
 },
 {
  "input": "The point is that it's just some number.",
  "translatedText": "Vấn đề là nó chỉ là một số con số.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.24,
  "end": 459.0
 },
 {
  "input": "That number happens to be the square root of pi, but what really matters is that it's something with no dependence on s.",
  "translatedText": "Con số đó tình cờ là căn bậc hai của pi, nhưng điều thực sự quan trọng là nó không phụ thuộc vào s.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 459.0,
  "end": 465.48
 },
 {
  "input": "And essentially, this is our answer.",
  "translatedText": "Và về cơ bản, đây là câu trả lời của chúng tôi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.88,
  "end": 468.48
 },
 {
  "input": "We were looking for an expression for the area of these slices as a function of s, and now we have it.",
  "translatedText": "Chúng tôi đang tìm kiếm một biểu thức cho diện tích của những lát cắt này dưới dạng hàm của s và bây giờ chúng tôi đã có nó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.78,
  "end": 474.28
 },
 {
  "input": "It looks like e to the negative s squared divided by two, scaled by some constant.",
  "translatedText": "Nó trông giống như e mũ âm s bình phương chia cho hai, chia tỷ lệ cho một hằng số nào đó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 474.38,
  "end": 478.84
 },
 {
  "input": "In other words, it's also a bell curve, another Gaussian, just stretched out a little bit because of this two in the exponent.",
  "translatedText": "Nói cách khác, nó cũng là một đường cong hình chuông, một đường cong Gauss khác, chỉ giãn ra một chút vì hai số này trong số mũ.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.3,
  "end": 485.62
 },
 {
  "input": "As I said earlier, the convolution evaluated at s is not quite this area.",
  "translatedText": "Như tôi đã nói trước đó, tích chập được đánh giá tại s không hoàn toàn nằm ở khu vực này.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.62,
  "end": 490.86
 },
 {
  "input": "Technically, it's this area divided by the square root of two.",
  "translatedText": "Về mặt kỹ thuật, đây là diện tích được chia cho căn bậc hai của 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.34,
  "end": 494.16
 },
 {
  "input": "We talked about it in the last video, but it doesn't really matter because it just gets baked into the constant.",
  "translatedText": "Chúng ta đã nói về nó trong video trước, nhưng nó không thực sự quan trọng vì nó chỉ được đưa vào hằng số.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 494.8,
  "end": 499.24
 },
 {
  "input": "What really matters is the conclusion that a convolution between two Gaussians is itself another Gaussian.",
  "translatedText": "Điều thực sự quan trọng là kết luận rằng tích chập giữa hai Gaussian chính là một Gaussian khác.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 499.68,
  "end": 505.68
 },
 {
  "input": "If you were to go back and reintroduce all of the constants for a normal distribution with a mean zero and an arbitrary standard deviation sigma, essentially identical reasoning will lead to the same square root of two factor that shows up in the exponent and out front, and it leads to the conclusion that the convolution between two such normal distributions is another normal distribution with a standard deviation square root of two times sigma.",
  "translatedText": "Nếu bạn quay lại và giới thiệu lại tất cả các hằng số cho phân bố chuẩn với giá trị trung bình bằng 0 và độ lệch chuẩn sigma tùy ý, lý luận về cơ bản giống hệt nhau sẽ dẫn đến cùng một căn bậc hai của hai thừa số xuất hiện ở số mũ và phía trước, và nó dẫn đến kết luận rằng tích chập giữa hai phân phối chuẩn như vậy là một phân phối chuẩn khác có căn bậc hai độ lệch chuẩn là hai lần sigma.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 507.56,
  "end": 530.38
 },
 {
  "input": "If you haven't computed a lot of convolutions before, it's worth emphasizing this is a very special result.",
  "translatedText": "Nếu trước đây bạn chưa tính nhiều phép chập thì cần nhấn mạnh rằng đây là một kết quả rất đặc biệt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.98,
  "end": 536.06
 },
 {
  "input": "Almost always you end up with a completely different kind of function, but here there's a sort of stability to the process.",
  "translatedText": "Hầu như bạn luôn kết thúc với một loại chức năng hoàn toàn khác, nhưng ở đây có một sự ổn định nào đó đối với quy trình.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.38,
  "end": 542.5
 },
 {
  "input": "Also, for those of you who enjoy exercises, I'll leave one up on the screen for how you would handle the case of two different standard deviations.",
  "translatedText": "Ngoài ra, đối với những ai yêu thích các bài tập, tôi sẽ hiển thị một bài trên màn hình để biết cách bạn xử lý trường hợp có hai độ lệch chuẩn khác nhau.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.26,
  "end": 549.44
 },
 {
  "input": "Still, some of you might be raising your hands and saying, what's the big deal?",
  "translatedText": "Tuy nhiên, một số bạn có thể giơ tay và nói, có chuyện gì lớn vậy?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 550.42,
  "end": 553.94
 },
 {
  "input": "I mean, when you first heard the question, what do you get when you add two normally distributed random variables, you probably even guessed that the answer should be another normally distributed variable.",
  "translatedText": "Ý mình là, khi lần đầu tiên bạn nghe câu hỏi, bạn sẽ nhận được gì khi cộng hai biến ngẫu nhiên có phân phối chuẩn, bạn thậm chí có thể đoán rằng câu trả lời phải là một biến có phân phối chuẩn khác.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 554.48,
  "end": 564.32
 },
 {
  "input": "After all, what else is it going to be?",
  "translatedText": "Rốt cuộc thì nó sẽ ra sao nữa đây?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 564.76,
  "end": 566.36
 },
 {
  "input": "Normal distributions are supposedly quite common, so why not?",
  "translatedText": "Phân phối bình thường được cho là khá phổ biến, vậy tại sao không?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 566.86,
  "end": 570.24
 },
 {
  "input": "You could even say that this should follow from the central limit theorem, but that would have it all backwards.",
  "translatedText": "Bạn thậm chí có thể nói rằng điều này sẽ tuân theo định lý giới hạn trung tâm, nhưng điều đó sẽ dẫn đến kết quả ngược lại.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 570.24,
  "end": 575.48
 },
 {
  "input": "First of all, the supposed ubiquity of normal distributions is often a little exaggerated, but to the extent that they do come up, it is because of the central limit theorem, but it would be cheating to say the central limit theorem implies this result because this computation we just did is the reason that the function at the heart of the central limit theorem is a Gaussian in the first place and not some other function.",
  "translatedText": "Trước hết, tính phổ biến được cho là của phân bố chuẩn thường hơi phóng đại, nhưng trong phạm vi mà chúng xuất hiện, đó là do định lý giới hạn trung tâm, nhưng sẽ là gian lận nếu nói rằng định lý giới hạn trung tâm ngụ ý kết quả này bởi vì Phép tính mà chúng ta vừa thực hiện này là lý do vì sao hàm trung tâm của định lý giới hạn trung tâm ngay từ đầu là một hàm Gaussian chứ không phải một hàm nào khác.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.18,
  "end": 597.06
 },
 {
  "input": "We've talked all about the central limit theorem before, but essentially it says if you repeatedly add copies of a random variable to itself, which mathematically looks like repeatedly computing convolutions against a given distribution, then after appropriate shifting and rescaling, the tendency is always to approach a normal distribution.",
  "translatedText": "Chúng ta đã nói tất cả về định lý giới hạn trung tâm trước đây, nhưng về cơ bản nó nói rằng nếu bạn liên tục thêm các bản sao của một biến ngẫu nhiên vào chính nó, về mặt toán học trông giống như tính toán liên tục các tích chập theo một phân bố nhất định, thì sau khi dịch chuyển và thay đổi tỷ lệ thích hợp, xu hướng là luôn tiến tới phân phối chuẩn.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 597.06,
  "end": 616.5
 },
 {
  "input": "Technically there's a small assumption the distribution you start with can't have infinite variance, but it's a relatively soft assumption.",
  "translatedText": "Về mặt kỹ thuật, có một giả định nhỏ rằng phân phối mà bạn bắt đầu không thể có phương sai vô hạn, nhưng đó là một giả định tương đối mềm.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 616.98,
  "end": 623.22
 },
 {
  "input": "The magic is that for a huge category of initial distributions, this process of adding a whole bunch of random variables drawn from that distribution always tends towards this one universal shape, a Gaussian.",
  "translatedText": "Điều kỳ diệu là đối với một danh mục khổng lồ các phân phối ban đầu, quá trình thêm toàn bộ các biến ngẫu nhiên được rút ra từ phân phối đó luôn có xu hướng hướng tới một hình dạng phổ quát này, một Gaussian.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.22,
  "end": 635.1
 },
 {
  "input": "One common approach to proving this theorem involves two separate steps.",
  "translatedText": "Một cách tiếp cận phổ biến để chứng minh định lý này bao gồm hai bước riêng biệt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 635.82,
  "end": 639.3
 },
 {
  "input": "The first step is to show that for all the different finite variance distributions you might start with, there exists a single universal shape that this process of repeated convolutions tends towards.",
  "translatedText": "Bước đầu tiên là chỉ ra rằng đối với tất cả các phân bố phương sai hữu hạn khác nhau mà bạn có thể bắt đầu, tồn tại một hình dạng phổ quát duy nhất mà quá trình tích chập lặp đi lặp lại này hướng tới.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.6,
  "end": 650.0
 },
 {
  "input": "This step is actually pretty technical, it goes a little beyond what I want to talk about here.",
  "translatedText": "Bước này thực sự khá kỹ thuật, nó vượt xa những gì tôi muốn nói ở đây một chút.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 650.0,
  "end": 654.24
 },
 {
  "input": "You often use these objects called moment generating functions that gives you a very abstract argument that there must be some universal shape, but it doesn't make any claim about what that particular shape is, just that everything in this big family is tending towards a single point in the space of distributions.",
  "translatedText": "Bạn thường sử dụng những đối tượng được gọi là hàm tạo mô men này, nó mang lại cho bạn một lập luận rất trừu tượng rằng phải có một hình dạng phổ quát nào đó, nhưng nó không đưa ra bất kỳ khẳng định nào về hình dạng cụ thể đó là gì, chỉ là mọi thứ trong họ lớn này đều có xu hướng hướng tới một một điểm duy nhất trong không gian phân phối.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 654.52,
  "end": 669.98
 },
 {
  "input": "So then step number two is what we just showed in this video, prove that the convolution of two Gaussians gives another Gaussian.",
  "translatedText": "Vậy bước thứ hai là điều chúng ta vừa trình bày trong video này, chứng minh rằng tích chập của hai Gaussian cho một Gaussian khác.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.62,
  "end": 677.4
 },
 {
  "input": "What that means is that as you apply this process of repeated convolutions, a Gaussian doesn't change, it's a fixed point.",
  "translatedText": "Điều đó có nghĩa là khi bạn áp dụng quy trình tích chập lặp đi lặp lại này, một Gaussian không thay đổi, đó là một điểm cố định.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.4,
  "end": 684.06
 },
 {
  "input": "So the only thing it can approach is itself, and since it's one member in this big family of distributions, all of which must be tending towards a single universal shape, it must be that universal shape.",
  "translatedText": "Vì vậy, điều duy nhất nó có thể tiếp cận là chính nó, và vì nó là một thành viên trong đại gia đình phân phối này, tất cả đều phải hướng tới một hình dạng phổ quát duy nhất, nên nó phải là hình dạng phổ quát đó.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.2,
  "end": 695.06
 },
 {
  "input": "I mentioned at the start how this calculation, step two, is something that you can do directly, just symbolically with the definitions, but one of the reasons I'm so charmed by a geometric argument that leverages the rotational symmetry of this graph is that it directly connects to a few things that we've talked about on this channel before.",
  "translatedText": "Tôi đã đề cập ngay từ đầu về cách phép tính này, bước hai, là thứ mà bạn có thể thực hiện trực tiếp, chỉ mang tính biểu tượng với các định nghĩa, nhưng một trong những lý do khiến tôi bị cuốn hút bởi một lập luận hình học thúc đẩy tính đối xứng quay của biểu đồ này là nó kết nối trực tiếp tới một số điều mà chúng ta đã nói trên kênh này trước đây.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 695.58,
  "end": 712.3
 },
 {
  "input": "For example, the Herschel-Maxwell derivation of a Gaussian, which essentially says that you can view this rotational symmetry as the defining feature of the distribution, that it locks you into this e to the negative x squared form, and also as an added bonus it connects to the classic proof for why pi shows up in the formula, meaning we now have a direct line between the presence and mystery of that pi and the central limit theorem.",
  "translatedText": "Ví dụ: đạo hàm Herschel-Maxwell của Gaussian, về cơ bản nói rằng bạn có thể xem sự đối xứng quay này như là đặc điểm xác định của phân bố, nó khóa bạn vào e này ở dạng x bình phương âm và cũng như một phần thưởng bổ sung nó kết nối với bằng chứng cổ điển giải thích tại sao số pi lại xuất hiện trong công thức, nghĩa là giờ đây chúng ta có một đường thẳng giữa sự hiện diện và bí ẩn của số pi đó với định lý giới hạn trung tâm.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 712.4,
  "end": 736.5
 },
 {
  "input": "Also on a recent Patreon post, the channel supporter Daksha Vaid-Quinter brought my attention to a completely different approach I hadn't seen before, which leverages the use of entropy, and again for the theoretically curious among you I'll leave some links in the description.",
  "translatedText": "Cũng trên một bài đăng gần đây trên Patreon, người hỗ trợ kênh Daksha Vaid-Quinter đã khiến tôi chú ý đến một cách tiếp cận hoàn toàn khác mà tôi chưa từng thấy trước đây, cách tiếp cận này thúc đẩy việc sử dụng entropy và một lần nữa đối với những ai tò mò về mặt lý thuyết, tôi sẽ để lại một số liên kết trong phần mô tả.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 737.06,
  "end": 749.58
 },
 {
  "input": "By the way, if you want to stay up to date with new videos and also any other projects that I put out there like the Summer of Math Exposition, there is a mailing list.",
  "translatedText": "Nhân tiện, nếu bạn muốn cập nhật các video mới cũng như bất kỳ dự án nào khác mà tôi đưa ra như Triển lãm Toán học Mùa hè, thì mình có một danh sách gửi thư.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 750.96,
  "end": 758.4
 },
 {
  "input": "It's relatively new and I'm pretty sparing about only posting what I think people will enjoy.",
  "translatedText": "Nó tương đối mới và mình chỉ đăng những gì mình nghĩ mọi người sẽ thích.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 758.72,
  "end": 762.78
 },
 {
  "input": "Usually I try not to be too promotional at the end of videos these days, but if you are interested in following the work that I do, this is probably one of the most enduring ways to do so.",
  "translatedText": "Thông thường, những ngày này mình cố gắng không quảng cáo quá nhiều ở cuối video, nhưng nếu bạn quan tâm đến việc theo dõi công việc mình làm thì đây có lẽ là một trong những cách lâu dài nhất để làm điều đó.",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 763.22,
  "end": 795.26
 }
]