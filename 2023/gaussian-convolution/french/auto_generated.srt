1
00:00:00,000 --> 00:00:03,362
La fonction de base sous-jacente à une distribution normale,

2
00:00:03,362 --> 00:00:06,560
également appelée gaussienne, est e au carré de x négatif.

3
00:00:06,560 --> 00:00:08,660
Mais vous vous demandez peut-être pourquoi cette fonction?

4
00:00:08,660 --> 00:00:12,817
De toutes les expressions que nous pourrions imaginer et qui donnent un graphique lisse

5
00:00:12,817 --> 00:00:17,068
symétrique avec une masse concentrée vers le milieu, pourquoi la théorie des probabilités

6
00:00:17,068 --> 00:00:21,320
semble-t-elle avoir une place particulière en son cœur pour cette expression particulière?

7
00:00:21,320 --> 00:00:24,760
Au cours des dernières vidéos, j'ai fait allusion à une réponse à cette question, et

8
00:00:24,760 --> 00:00:28,160
ici nous arriverons enfin à quelque chose qui ressemble à une réponse satisfaisante.

9
00:00:28,160 --> 00:00:32,113
Pour vous rappeler où nous en sommes, il y a quelques vidéos, nous avons parlé du

10
00:00:32,113 --> 00:00:36,114
théorème central limite, qui décrit comment, lorsque vous ajoutez plusieurs copies

11
00:00:36,114 --> 00:00:40,212
d'une variable aléatoire, par exemple lancer un dé pondéré plusieurs fois ou laisser

12
00:00:40,212 --> 00:00:43,972
une balle rebondir sur un ancrage à plusieurs reprises, alors la distribution

13
00:00:43,972 --> 00:00:47,974
décrivant cette somme a tendance à ressembler approximativement à une distribution

14
00:00:47,974 --> 00:00:48,360
normale.

15
00:00:48,360 --> 00:00:51,349
Ce que dit le théorème central limite, c'est qu'à mesure que

16
00:00:51,349 --> 00:00:54,339
vous augmentez cette somme, dans des conditions appropriées,

17
00:00:54,339 --> 00:00:57,280
cette approximation d'une normale devient de mieux en mieux.

18
00:00:57,280 --> 00:01:00,062
Mais je n’ai jamais expliqué pourquoi ce théorème est

19
00:01:00,062 --> 00:01:03,360
réellement vrai, nous avons seulement parlé de ce qu’il prétend.

20
00:01:03,360 --> 00:01:05,550
Dans la dernière vidéo, nous avons commencé à parler des

21
00:01:05,550 --> 00:01:08,240
mathématiques impliquées dans l'addition de deux variables aléatoires.

22
00:01:08,240 --> 00:01:12,428
Si vous avez deux variables aléatoires, chacune suivant une certaine distribution,

23
00:01:12,428 --> 00:01:16,314
alors pour trouver la distribution décrivant la somme de ces variables, vous

24
00:01:16,314 --> 00:01:20,200
calculez ce qu'on appelle une convolution entre les deux fonctions d'origine.

25
00:01:20,200 --> 00:01:23,498
Et nous avons passé beaucoup de temps à élaborer deux manières distinctes

26
00:01:23,498 --> 00:01:26,440
de visualiser ce qu’est réellement cette opération de convolution.

27
00:01:26,440 --> 00:01:30,448
Aujourd'hui, notre travail de base consiste à travailler sur un exemple particulier, qui

28
00:01:30,448 --> 00:01:34,187
consiste à demander ce qui se passe lorsque vous ajoutez deux variables aléatoires

29
00:01:34,187 --> 00:01:38,105
normalement distribuées, ce qui, comme vous le savez maintenant, revient à demander ce

30
00:01:38,105 --> 00:01:42,069
que vous obtenez si vous calculez une convolution entre deux variables gaussiennes. les

31
00:01:42,069 --> 00:01:42,520
fonctions.

32
00:01:42,520 --> 00:01:45,922
J'aimerais partager une manière visuelle particulièrement agréable

33
00:01:45,922 --> 00:01:49,426
de réfléchir à ce calcul, qui, espérons-le, donne une idée de ce qui

34
00:01:49,426 --> 00:01:52,880
rend le e de la fonction x au carré négatif spécial en premier lieu.

35
00:01:52,880 --> 00:01:55,554
Après l'avoir parcouru, nous expliquerons en quoi ce calcul est

36
00:01:55,554 --> 00:01:58,480
l'une des étapes impliquées dans la preuve du théorème central limite.

37
00:01:58,480 --> 00:02:01,344
C'est l'étape qui répond à la question de savoir pourquoi

38
00:02:01,344 --> 00:02:04,160
une gaussienne et non autre chose est la limite centrale.

39
00:02:04,160 --> 00:02:10,160
Mais d’abord, plongeons-y.

40
00:02:10,160 --> 00:02:12,383
La formule complète d’une gaussienne est plus

41
00:02:12,383 --> 00:02:14,800
compliquée que simplement e au carré négatif de x.

42
00:02:14,800 --> 00:02:19,785
L'exposant est généralement écrit sous la forme moins une moitié de x divisé par sigma

43
00:02:19,785 --> 00:02:24,600
au carré, où sigma décrit l'étendue de la distribution, en particulier l'écart type.

44
00:02:24,600 --> 00:02:29,226
Tout cela doit être multiplié par une fraction sur le devant, qui est là pour garantir

45
00:02:29,226 --> 00:02:33,960
que l'aire sous la courbe est une, ce qui en fait une distribution de probabilité valide.

46
00:02:33,960 --> 00:02:36,493
Et si vous souhaitez considérer des distributions qui ne sont

47
00:02:36,493 --> 00:02:38,905
pas nécessairement centrées sur zéro, vous devez également

48
00:02:38,905 --> 00:02:41,480
ajouter un autre paramètre, mu, dans l'exposant comme celui-ci.

49
00:02:41,480 --> 00:02:43,930
Bien que pour tout ce que nous allons faire ici, nous

50
00:02:43,930 --> 00:02:46,200
considérons uniquement les distributions centrées.

51
00:02:46,200 --> 00:02:49,804
Maintenant, si vous regardez notre objectif principal d'aujourd'hui, qui est

52
00:02:49,804 --> 00:02:53,220
de calculer une convolution entre deux fonctions gaussiennes, la manière

53
00:02:53,220 --> 00:02:56,871
directe d'y parvenir serait de prendre la définition d'une convolution, cette

54
00:02:56,871 --> 00:03:00,429
expression intégrale que nous avons construite dans la dernière vidéo, puis

55
00:03:00,429 --> 00:03:04,080
de branchez pour chacune des fonctions impliquées la formule d'une gaussienne.

56
00:03:04,080 --> 00:03:07,299
Cela fait en quelque sorte beaucoup de symboles lorsque vous mélangez tout cela,

57
00:03:07,299 --> 00:03:10,480
mais plus que tout, travailler sur cela est un exercice pour compléter le carré.

58
00:03:10,480 --> 00:03:11,951
Et il n’y a rien de mal à cela.

59
00:03:11,951 --> 00:03:13,760
Cela vous donnera la réponse que vous souhaitez.

60
00:03:13,760 --> 00:03:17,364
Mais bien sûr, vous me connaissez, je suis un adepte de l'intuition visuelle, et

61
00:03:17,364 --> 00:03:20,702
dans ce cas, il y a une autre façon d'y penser que je n'ai jamais vu écrit

62
00:03:20,702 --> 00:03:24,173
auparavant, qui offre une très belle connexion avec d'autres aspects de cela.

63
00:03:24,173 --> 00:03:28,000
distribution, comme la présence de pi et certaines façons de déterminer d'où il vient.

64
00:03:28,000 --> 00:03:31,463
Et la façon dont j'aimerais procéder est d'abord de supprimer toutes

65
00:03:31,463 --> 00:03:34,826
les constantes associées à la distribution réelle et de simplement

66
00:03:34,826 --> 00:03:38,240
montrer le calcul pour la forme simplifiée, e au carré négatif de x.

67
00:03:38,240 --> 00:03:41,215
L’essence de ce que nous voulons calculer est à quoi

68
00:03:41,215 --> 00:03:44,640
ressemble la convolution entre deux copies de cette fonction.

69
00:03:44,640 --> 00:03:47,411
Si vous vous en souvenez, dans la dernière vidéo, nous avions deux

70
00:03:47,411 --> 00:03:50,141
manières différentes de visualiser les convolutions, et celle que

71
00:03:50,141 --> 00:03:53,120
nous utiliserons ici est la seconde, impliquant des tranches diagonales.

72
00:03:53,120 --> 00:03:57,489
Et pour rappel rapide de la façon dont cela a fonctionné, si vous avez deux distributions

73
00:03:57,489 --> 00:04:01,615
différentes décrites par deux fonctions différentes, f et g, alors toutes les paires

74
00:04:01,615 --> 00:04:05,839
possibles de valeurs que vous pourriez obtenir lorsque vous échantillonnez à partir de

75
00:04:05,839 --> 00:04:10,160
ces deux distributions peuvent être considérées. comme points individuels sur le plan xy.

76
00:04:10,160 --> 00:04:14,022
Et la densité de probabilité d’atterrir sur un de ces points,

77
00:04:14,022 --> 00:04:17,760
en supposant l’indépendance, ressemble à f de x fois g de y.

78
00:04:17,760 --> 00:04:21,811
Nous examinons donc un graphique de cette expression comme une fonction à deux

79
00:04:21,811 --> 00:04:25,966
variables de x et y, ce qui est une façon de montrer la distribution de tous les

80
00:04:25,966 --> 00:04:30,480
résultats possibles lorsque nous échantillonnons à partir de deux variables différentes.

81
00:04:30,480 --> 00:04:35,723
Pour interpréter la convolution de f et g évaluées sur certaines entrées s, ce qui

82
00:04:35,723 --> 00:04:40,524
est une façon de dire quelle est la probabilité que vous obteniez une paire

83
00:04:40,524 --> 00:04:45,388
d'échantillons qui totalisent cette somme s, vous regardez une tranche de ce

84
00:04:45,388 --> 00:04:50,694
graphique sur la ligne x plus y est égal à s, et vous considérez la zone sous cette

85
00:04:50,694 --> 00:04:51,200
tranche.

86
00:04:51,200 --> 00:04:56,640
Cette zone correspond presque, mais pas tout à fait, à la valeur de la convolution à s.

87
00:04:56,640 --> 00:05:00,720
Pour une raison légèrement technique, vous devez diviser par la racine carrée de deux.

88
00:05:00,720 --> 00:05:03,520
Pourtant, ce domaine est l’élément clé sur lequel se concentrer.

89
00:05:03,520 --> 00:05:08,292
Vous pouvez y voir un moyen de combiner toutes les densités de

90
00:05:08,292 --> 00:05:13,520
probabilité pour tous les résultats correspondant à une somme donnée.

91
00:05:13,520 --> 00:05:16,789
Dans le cas spécifique où ces deux fonctions ressemblent à e au

92
00:05:16,789 --> 00:05:19,957
carré de x négatif et à e au carré de y négatif, le graphe 3D

93
00:05:19,957 --> 00:05:23,840
résultant possède une propriété très intéressante que vous pouvez exploiter.

94
00:05:23,840 --> 00:05:27,120
C'est symétrique en rotation.

95
00:05:27,120 --> 00:05:30,667
Vous pouvez le voir en combinant les termes et en remarquant que c'est

96
00:05:30,667 --> 00:05:34,413
entièrement une fonction de x au carré plus y au carré, et ce terme décrit

97
00:05:34,413 --> 00:05:38,160
le carré de la distance entre n'importe quel point du plan xy et l'origine.

98
00:05:38,160 --> 00:05:40,632
En d’autres termes, l’expression est purement

99
00:05:40,632 --> 00:05:43,211
fonction de la distance par rapport à l’origine.

100
00:05:43,211 --> 00:05:47,838
Et d’ailleurs, cela ne serait vrai pour aucune autre distribution.

101
00:05:47,838 --> 00:05:51,998
C'est une propriété qui caractérise de manière unique les courbes en cloche.

102
00:05:51,998 --> 00:05:55,308
Ainsi, pour la plupart des autres paires de fonctions, ces tranches

103
00:05:55,308 --> 00:05:58,715
diagonales auront une forme compliquée à laquelle il est difficile de

104
00:05:58,715 --> 00:06:01,879
penser, et honnêtement, calculer l'aire reviendrait simplement à

105
00:06:01,879 --> 00:06:05,530
calculer l'intégrale d'origine qui définit une convolution en premier lieu.

106
00:06:05,530 --> 00:06:10,160
Ainsi, dans la plupart des cas, l’intuition visuelle ne vous rapporte rien.

107
00:06:10,160 --> 00:06:12,594
Mais dans le cas des courbes en cloche, vous pouvez

108
00:06:12,594 --> 00:06:14,560
tirer parti de cette symétrie de rotation.

109
00:06:14,560 --> 00:06:17,722
Ici, concentrez-vous sur l'une de ces tranches sur la

110
00:06:17,722 --> 00:06:21,120
ligne x plus y est égal à s pour une certaine valeur de s.

111
00:06:21,120 --> 00:06:25,755
Et rappelez-vous, la convolution que nous essayons de calculer est fonction de s.

112
00:06:25,755 --> 00:06:28,292
Ce que vous voulez, c'est une expression de s

113
00:06:28,292 --> 00:06:31,104
qui vous indique la zone située sous cette tranche.

114
00:06:31,104 --> 00:06:34,252
Eh bien, si vous regardez cette ligne, elle coupe

115
00:06:34,252 --> 00:06:37,084
l’axe des x à s zéro et l’axe des y à zéro s.

116
00:06:37,084 --> 00:06:41,232
Et un peu de Pythagore vous montrera que la distance en ligne droite

117
00:06:41,232 --> 00:06:45,680
entre l'origine et cette ligne est s divisée par la racine carrée de deux.

118
00:06:45,680 --> 00:06:49,607
Maintenant, en raison de la symétrie, cette tranche est identique à

119
00:06:49,607 --> 00:06:53,534
celle que vous obtenez en rotation de 45 degrés, où vous trouveriez

120
00:06:53,534 --> 00:06:57,520
quelque chose de parallèle à l'axe y à la même distance de l'origine.

121
00:06:57,520 --> 00:07:00,925
La clé est que calculer cette autre zone d’une tranche parallèle à l’axe

122
00:07:00,925 --> 00:07:04,098
y est beaucoup, beaucoup plus facile que les tranches dans d’autres

123
00:07:04,098 --> 00:07:07,924
directions, car cela implique uniquement de prendre une intégrale par rapport à y.

124
00:07:07,924 --> 00:07:10,564
La valeur de x sur cette tranche est une constante.

125
00:07:10,564 --> 00:07:14,826
Plus précisément, ce serait la constante s divisée par la racine carrée de deux.

126
00:07:14,826 --> 00:07:19,030
Ainsi, lorsque vous calculez l'intégrale et trouvez cette aire, tout ce terme se

127
00:07:19,030 --> 00:07:23,598
comporte ici comme s'il s'agissait simplement d'un nombre, et vous pouvez le factoriser.

128
00:07:23,598 --> 00:07:25,155
C'est le point important.

129
00:07:25,155 --> 00:07:30,133
Tout ce qui implique s est désormais entièrement séparé de la variable intégrée.

130
00:07:30,133 --> 00:07:32,640
Cette intégrale restante est un peu délicate.

131
00:07:32,640 --> 00:07:35,346
J'ai fait une vidéo entière dessus, c'est en fait assez célèbre.

132
00:07:35,346 --> 00:07:36,953
Mais vous ne vous en souciez presque pas vraiment.

133
00:07:36,953 --> 00:07:38,873
Le fait est que ce n'est qu'un chiffre.

134
00:07:38,873 --> 00:07:42,204
Ce nombre se trouve être la racine carrée de pi, mais

135
00:07:42,204 --> 00:07:45,598
ce qui compte vraiment, c'est qu'il ne dépend pas de s.

136
00:07:45,598 --> 00:07:48,040
Et essentiellement, voici notre réponse.

137
00:07:48,040 --> 00:07:50,909
Nous cherchions une expression pour l’aire de ces

138
00:07:50,909 --> 00:07:54,008
tranches en fonction de s, et maintenant nous l’avons.

139
00:07:54,008 --> 00:07:59,034
Cela ressemble à e au carré négatif s divisé par deux, mis à l'échelle par une constante.

140
00:07:59,034 --> 00:08:02,514
En d’autres termes, c’est aussi une courbe en cloche, une autre

141
00:08:02,514 --> 00:08:06,320
gaussienne, juste un peu allongée à cause de ces deux dans l’exposant.

142
00:08:06,320 --> 00:08:10,685
Comme je l'ai dit plus tôt, la convolution évaluée à s n'est pas tout à fait cette zone.

143
00:08:10,685 --> 00:08:13,972
Techniquement, c'est cette surface divisée par la racine carrée de deux.

144
00:08:13,972 --> 00:08:16,581
Nous en avons parlé dans la dernière vidéo, mais cela n'a pas

145
00:08:16,581 --> 00:08:19,527
vraiment d'importance car cela s'intègre simplement dans la constante.

146
00:08:19,527 --> 00:08:22,918
Ce qui compte vraiment, c'est la conclusion selon laquelle une

147
00:08:22,918 --> 00:08:26,685
convolution entre deux gaussiennes est elle-même une autre gaussienne.

148
00:08:26,685 --> 00:08:30,574
Si vous deviez revenir en arrière et réintroduire toutes les constantes d'une

149
00:08:30,574 --> 00:08:34,413
distribution normale avec un zéro moyen et un sigma d'écart type arbitraire,

150
00:08:34,413 --> 00:08:38,251
un raisonnement essentiellement identique conduirait à la même racine carrée

151
00:08:38,251 --> 00:08:42,140
de deux facteurs qui apparaît dans l'exposant et à l'avant, et cela conduit à

152
00:08:42,140 --> 00:08:46,028
la conclusion que la convolution entre deux de ces distributions normales est

153
00:08:46,028 --> 00:08:50,166
une autre distribution normale avec un écart type racine carrée de deux fois sigma.

154
00:08:50,166 --> 00:08:53,040
Si vous n'avez pas calculé beaucoup de convolutions auparavant,

155
00:08:53,040 --> 00:08:55,958
il convient de souligner qu'il s'agit d'un résultat très spécial.

156
00:08:55,958 --> 00:08:59,519
On se retrouve presque toujours avec un type de fonction complètement

157
00:08:59,519 --> 00:09:03,029
différent, mais ici, il y a une sorte de stabilité dans le processus.

158
00:09:03,029 --> 00:09:06,350
De plus, pour ceux d'entre vous qui aiment les exercices, j'en laisserai un à

159
00:09:06,350 --> 00:09:09,756
l'écran expliquant comment vous géreriez le cas de deux écarts types différents.

160
00:09:09,756 --> 00:09:11,958
Pourtant, certains d’entre vous lèvent peut-être

161
00:09:11,958 --> 00:09:13,936
la main et demandent : quel est le problème?

162
00:09:13,936 --> 00:09:16,841
Je veux dire, lorsque vous avez entendu la question pour la première fois,

163
00:09:16,841 --> 00:09:20,249
qu'obtenez-vous lorsque vous ajoutez deux variables aléatoires normalement distribuées,

164
00:09:20,249 --> 00:09:23,425
vous avez probablement même deviné que la réponse devrait être une autre variable

165
00:09:23,425 --> 00:09:24,316
normalement distribuée.

166
00:09:24,316 --> 00:09:26,463
Après tout, qu’est-ce que ça va être d’autre?

167
00:09:26,463 --> 00:09:29,637
Les distributions normales sont censées être assez courantes, alors pourquoi pas?

168
00:09:29,637 --> 00:09:32,615
On pourrait même dire que cela devrait découler du

169
00:09:32,615 --> 00:09:35,768
théorème central limite, mais ce serait tout inverser.

170
00:09:35,768 --> 00:09:39,813
Tout d’abord, l’omniprésence supposée des distributions normales est souvent un peu

171
00:09:39,813 --> 00:09:44,003
exagérée, mais dans la mesure où elles apparaissent, c’est à cause du théorème central

172
00:09:44,003 --> 00:09:48,001
limite, mais il serait tricheur de dire que le théorème central limite implique ce

173
00:09:48,001 --> 00:09:52,095
résultat parce que ce calcul que nous venons de faire est la raison pour laquelle la

174
00:09:52,095 --> 00:09:56,236
fonction au cœur du théorème central limite est en premier lieu une gaussienne et non

175
00:09:56,236 --> 00:09:57,152
une autre fonction.

176
00:09:57,152 --> 00:10:01,005
Nous avons déjà parlé du théorème central limite, mais il dit essentiellement que

177
00:10:01,005 --> 00:10:05,047
si vous ajoutez à plusieurs reprises des copies d'une variable aléatoire à elle-même,

178
00:10:05,047 --> 00:10:08,854
ce qui ressemble mathématiquement à un calcul répété de convolutions par rapport

179
00:10:08,854 --> 00:10:12,379
à une distribution donnée, alors après un décalage et une mise à l'échelle

180
00:10:12,379 --> 00:10:16,280
appropriés, la tendance est toujours pour se rapprocher d'une distribution normale.

181
00:10:16,280 --> 00:10:18,635
Techniquement, il existe une petite hypothèse selon laquelle la

182
00:10:18,635 --> 00:10:20,991
distribution avec laquelle vous commencez ne peut pas avoir une

183
00:10:20,991 --> 00:10:23,309
variance infinie, mais c'est une hypothèse relativement souple.

184
00:10:23,309 --> 00:10:27,136
La magie est que pour une énorme catégorie de distributions initiales, ce

185
00:10:27,136 --> 00:10:30,911
processus d'ajout de tout un tas de variables aléatoires tirées de cette

186
00:10:30,911 --> 00:10:34,996
distribution tend toujours vers cette forme universelle unique, une gaussienne.

187
00:10:34,996 --> 00:10:39,360
Une approche courante pour prouver ce théorème implique deux étapes distinctes.

188
00:10:39,360 --> 00:10:42,966
La première étape consiste à montrer que pour toutes les différentes distributions

189
00:10:42,966 --> 00:10:46,400
de variance finie avec lesquelles vous pourriez commencer, il existe une seule

190
00:10:46,400 --> 00:10:49,659
forme universelle vers laquelle tend ce processus de convolutions répétées.

191
00:10:49,659 --> 00:10:51,904
Cette étape est en fait assez technique, elle va

192
00:10:51,904 --> 00:10:54,150
un peu au-delà de ce dont je souhaite parler ici.

193
00:10:54,150 --> 00:10:57,943
Vous utilisez souvent ces objets appelés fonctions génératrices de moments qui vous

194
00:10:57,943 --> 00:11:01,827
donnent un argument très abstrait selon lequel il doit y avoir une forme universelle,

195
00:11:01,827 --> 00:11:05,801
mais cela ne prétend pas quelle est cette forme particulière, juste que tout dans cette

196
00:11:05,801 --> 00:11:09,369
grande famille tend vers une forme universelle. point unique dans l’espace des

197
00:11:09,369 --> 00:11:10,001
distributions.

198
00:11:10,001 --> 00:11:13,793
Alors la deuxième étape est ce que nous venons de montrer dans cette vidéo,

199
00:11:13,793 --> 00:11:17,485
prouver que la convolution de deux gaussiennes donne une autre gaussienne.

200
00:11:17,485 --> 00:11:20,986
Cela signifie que lorsque vous appliquez ce processus de convolutions

201
00:11:20,986 --> 00:11:23,987
répétées, une gaussienne ne change pas, c'est un point fixe.

202
00:11:23,987 --> 00:11:27,618
Donc la seule chose qu'il peut approcher, c'est lui-même, et comme il s'agit

203
00:11:27,618 --> 00:11:31,061
d'un membre de cette grande famille de distributions, qui doivent toutes

204
00:11:31,061 --> 00:11:34,740
tendre vers une seule forme universelle, ce doit être cette forme universelle.

205
00:11:34,740 --> 00:11:38,206
J'ai mentionné au début que ce calcul, la deuxième étape, est quelque chose

206
00:11:38,206 --> 00:11:41,764
que vous pouvez faire directement, juste symboliquement avec les définitions,

207
00:11:41,764 --> 00:11:45,093
mais l'une des raisons pour lesquelles je suis si charmé par un argument

208
00:11:45,093 --> 00:11:48,651
géométrique qui exploite la symétrie de rotation de ce graphique est que cela

209
00:11:48,651 --> 00:11:52,664
se connecte directement à quelques éléments dont nous avons déjà parlé sur cette chaîne.

210
00:11:52,664 --> 00:11:56,601
Par exemple, la dérivation Herschel-Maxwell d'une gaussienne, qui dit essentiellement

211
00:11:56,601 --> 00:12:00,217
que vous pouvez considérer cette symétrie de rotation comme la caractéristique

212
00:12:00,217 --> 00:12:04,061
déterminante de la distribution, qu'elle vous enferme dans ce e à la forme x carrée

213
00:12:04,061 --> 00:12:08,089
négative, et aussi comme un bonus supplémentaire cela se connecte à la preuve classique

214
00:12:08,089 --> 00:12:11,751
expliquant pourquoi pi apparaît dans la formule, ce qui signifie que nous avons

215
00:12:11,751 --> 00:12:15,642
maintenant une ligne directe entre la présence et le mystère de ce pi et le théorème

216
00:12:15,642 --> 00:12:16,328
central limite.

217
00:12:16,328 --> 00:12:19,612
Également dans un article récent sur Patreon, Daksha Vaid-Quinter, partisan de la

218
00:12:19,612 --> 00:12:23,097
chaîne, a attiré mon attention sur une approche complètement différente que je n'avais

219
00:12:23,097 --> 00:12:26,501
jamais vue auparavant, qui exploite l'utilisation de l'entropie, et encore une fois,

220
00:12:26,501 --> 00:12:30,106
pour les curieux d'entre vous en théorie, je laisserai quelques liens. dans le descriptif.

221
00:12:30,106 --> 00:12:34,187
À propos, si vous souhaitez rester au courant des nouvelles vidéos et de tout autre

222
00:12:34,187 --> 00:12:38,560
projet que je propose comme l'exposition Summer of Math, il existe une liste de diffusion.

223
00:12:38,560 --> 00:12:40,750
C'est relativement nouveau et j'hésite à publier

224
00:12:40,750 --> 00:12:43,120
uniquement ce que je pense que les gens apprécieront.

225
00:12:43,120 --> 00:12:44,598
Habituellement, j'essaie de ne pas être trop promotionnel à la fin des

226
00:12:44,598 --> 00:12:46,118
vidéos ces jours-ci, mais si vous êtes intéressé à suivre le travail que

227
00:12:46,118 --> 00:12:47,680
je fais, c'est probablement l'une des façons les plus durables de le faire.

