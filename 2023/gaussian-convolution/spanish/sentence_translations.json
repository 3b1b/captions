[
 {
  "input": "The basic function underlying a normal distribution, aka a Gaussian, is e to the negative x squared.",
  "model": "nmt",
  "translatedText": "La función básica que subyace a una distribución normal, también conocida como gaussiana, es e elevado a menos x al cuadrado.",
  "time_range": [
   0.0,
   6.12
  ]
 },
 {
  "input": "But you might wonder, why this function?",
  "model": "nmt",
  "translatedText": "Pero quizá te preguntes, ¿por qué esta función?",
  "time_range": [
   6.64,
   8.34
  ]
 },
 {
  "input": "Of all the expressions we could dream up that give you some symmetric smooth graph with mass concentrated towards the middle, why is it that the theory of probability seems to have a special place in its heart for this particular expression?",
  "model": "nmt",
  "translatedText": "De todas las expresiones que podríamos imaginar, que darían una gráfica simétrica, suave y con masa concentrada hacia el centro, ¿por qué la teoría de la probabilidad pareciera tener un lugar especial en su corazón para esta expresión?",
  "time_range": [
   8.72,
   20.44
  ]
 },
 {
  "input": "For the last many videos I've been hinting at an answer to this question, and here we'll finally arrive at something like a satisfying answer.",
  "model": "nmt",
  "translatedText": "Durante los últimos videos he estado insinuando una respuesta a esta pregunta, y aquí llegaremos finalmente a una respuesta más o menos satisfactoria.",
  "time_range": [
   21.38,
   27.68
  ]
 },
 {
  "input": "As a quick refresher on where we are, a couple videos ago we talked about the central limit theorem, which describes how as you add multiple copies of a random variable, for example rolling a weighted die many different times or letting a ball bounce off of a peg repeatedly, then the distribution describing that sum tends to look approximately like a normal distribution.",
  "model": "nmt",
  "translatedText": "Como repaso rápido de dónde estamos, hace un par de videos hablamos sobre el teorema del límite central, que describe cómo al agregar múltiples copias de una variable aleatoria, por ejemplo, lanzar un dado ponderado muchas veces diferentes o dejar que una bola rebote repetidamente por un pasador, la distribución que describe esa suma tiende aproximadamente a una distribución normal.",
  "time_range": [
   27.68,
   47.72
  ]
 },
 {
  "input": "What the central limit theorem says is as you make that sum bigger and bigger, under appropriate conditions, that approximation to a normal becomes better and better.",
  "model": "nmt",
  "translatedText": "Lo que dice el teorema del límite central es que a medida que esa suma aumenta cada vez más, en condiciones apropiadas, la aproximación a una normal se vuelve cada vez mejor.",
  "time_range": [
   48.44,
   56.22
  ]
 },
 {
  "input": "But I never explained why this theorem is actually true, we only talked about what it's claiming.",
  "model": "nmt",
  "translatedText": "Pero nunca expliqué por qué es cierto este teorema, solo hablamos de lo que afirma.",
  "time_range": [
   56.94,
   61.98
  ]
 },
 {
  "input": "In the last video we started talking about the math involved in adding two random variables.",
  "model": "nmt",
  "translatedText": "En el último video comenzamos a hablar sobre las matemáticas detrás de la suma de dos variables aleatorias.",
  "time_range": [
   63.08,
   67.88
  ]
 },
 {
  "input": "If you have two random variables, each following some distribution, then to find the distribution describing the sum of those variables, you compute something known as a convolution between the two original functions.",
  "model": "nmt",
  "translatedText": "Si tenemos dos variables aleatorias, cada una de las cuales sigue una distribución, entonces, para encontrar la distribución que describe la suma de esas variables, calculamos lo que se conoce como convolución entre las dos funciones originales.",
  "time_range": [
   68.26,
   79.7
  ]
 },
 {
  "input": "And we spent a lot of time building up two distinct ways to visualize what this convolution operation really is.",
  "model": "nmt",
  "translatedText": "Y hemos dedicado mucho tiempo a crear dos formas distintas de visualizar lo que esta operación llamada convolución realmente es.",
  "time_range": [
   79.88,
   85.94
  ]
 },
 {
  "input": "Today our basic job is to work through a particular example, which is to ask what happens when you add two normally distributed random variables, which as you know by now is the same as asking what do you get if you compute a convolution between two Gaussian functions.",
  "model": "nmt",
  "translatedText": "Hoy nuestro trabajo básicamente es trabajar en un ejemplo particular, que consiste en preguntarnos qué sucede cuando agregamos dos variables aleatorias distribuidas normalmente, lo cual, como ya sabemos, es lo mismo que preguntarnos qué obtenemos si calculamos una convolución entre dos funciones gaussianas.",
  "time_range": [
   85.94,
   101.78
  ]
 },
 {
  "input": "I'd like to share an especially pleasing visual way that you can think about this calculation, which hopefully offers some sense of what makes the e to the negative x squared function special in the first place.",
  "model": "nmt",
  "translatedText": "Me gustaría compartir una forma de visualizar este cálculo que, con suerte, ofrece una idea de lo que hace que la función e elevado a menos x al cuadrado sea especial para empezar.",
  "time_range": [
   102.52,
   112.36
  ]
 },
 {
  "input": "After we walk through it, we'll talk about how this calculation is one of the steps involved in proving the central limit theorem.",
  "model": "nmt",
  "translatedText": "Después de analizarlo, hablaremos sobre cómo este cálculo es uno de los pasos necesarios para demostrar el teorema del límite central.",
  "time_range": [
   112.36,
   118.24
  ]
 },
 {
  "input": "It's the step that answers the question of why a Gaussian and not something else is the central limit.",
  "model": "nmt",
  "translatedText": "Es el paso que responde a la pregunta de por qué una gaussiana y no otra cosa es el límite central.",
  "time_range": [
   118.32,
   123.56
  ]
 },
 {
  "input": "But first, let's dive in.",
  "model": "nmt",
  "translatedText": "Pero primero, profundicemos.",
  "time_range": [
   124.2,
   125.84
  ]
 },
 {
  "input": "The full formula for a Gaussian is more complicated than just e to the negative x squared.",
  "model": "nmt",
  "translatedText": "La fórmula completa para una gaussiana es más complicada que simplemente e elevado a menos x al cuadrado.",
  "time_range": [
   129.78,
   134.44
  ]
 },
 {
  "input": "The exponent is typically written as negative one half times x divided by sigma squared, where sigma describes the spread of the distribution, specifically the standard deviation.",
  "model": "nmt",
  "translatedText": "El exponente generalmente se escribe como menos la mitad por x dividido por sigma al cuadrado, donde sigma describe la dispersión de la distribución, específicamente la desviación estándar.",
  "time_range": [
   134.82,
   144.2
  ]
 },
 {
  "input": "All of this needs to be multiplied by a fraction on the front, which is there to make sure that the area under the curve is one, making it a valid probability distribution.",
  "model": "nmt",
  "translatedText": "Todo esto debe multiplicarse por una fracción en el frente, que está ahí para garantizar que el área bajo la curva sea uno, lo que la convierte en una distribución de probabilidad válida.",
  "time_range": [
   144.68,
   153.42
  ]
 },
 {
  "input": "And if you want to consider distributions that aren't necessarily centered at zero, you would also throw another parameter, mu, into the exponent like this.",
  "model": "nmt",
  "translatedText": "Y si quieres considerar distribuciones que no están necesariamente centradas en cero, también incluirías otro parámetro, mu, en el exponente como este.",
  "time_range": [
   154.02,
   161.18
  ]
 },
 {
  "input": "Although for everything we'll be doing here, we just consider centered distributions.",
  "model": "nmt",
  "translatedText": "Aunque para todo lo que haremos aquí, solo consideraremos distribuciones centradas.",
  "time_range": [
   161.54,
   165.12
  ]
 },
 {
  "input": "Now if you look at our central goal for today, which is to compute a convolution between two Gaussian functions, the direct way to do this would be to take the definition of a convolution, this integral expression we built up last video, and then to plug in for each one of the functions involved the formula for a Gaussian.",
  "model": "nmt",
  "translatedText": "Ahora, si nos fijamos en nuestro objetivo central de hoy, que es calcular una convolución entre dos funciones gaussianas, la forma directa de hacerlo sería tomar la definición de convolución, esta expresión integral que construimos en el último vídeo, y luego Inserte para cada una de las funciones involucradas la fórmula de una Gaussiana.",
  "time_range": [
   165.79999999999998,
   183.76
  ]
 },
 {
  "input": "It's kind of a lot of symbols when you throw it all together, but more than anything, working this out is an exercise in completing the square.",
  "model": "nmt",
  "translatedText": "Son muchos símbolos cuando los juntas todos, pero más que nada, resolver esto es un ejercicio para completar el cuadrado.",
  "time_range": [
   184.22,
   190.08
  ]
 },
 {
  "input": "And there's nothing wrong with that.",
  "model": "nmt",
  "translatedText": "Y eso no tiene nada de malo.",
  "time_range": [
   190.56,
   191.58
  ]
 },
 {
  "input": "That will get you the answer that you want.",
  "model": "nmt",
  "translatedText": "Eso le dará la respuesta que desea.",
  "time_range": [
   191.72,
   193.22
  ]
 },
 {
  "input": "But of course, you know me, I'm a sucker for visual intuition, and in this case, there's another way to think about it that I haven't seen written about before, that offers a very nice connection to other aspects of this distribution, like the presence of pi and certain ways to derive where it comes from.",
  "model": "nmt",
  "translatedText": "Pero, por supuesto, ya me conoces, soy un fanático de la intuición visual, y en este caso, hay otra forma de pensar en ello sobre la que no he visto escrito antes, que ofrece una muy buena conexión con otros aspectos de esto. distribución, como la presencia de pi y ciertas formas de derivar de dónde viene.",
  "time_range": [
   193.76,
   207.86
  ]
 },
 {
  "input": "And the way I'd like to do this is by first peeling away all of the constants associated with the actual distribution, and just showing the computation for the simplified form, e to the negative x squared.",
  "model": "nmt",
  "translatedText": "Y la forma en que me gustaría hacer esto es primero eliminando todas las constantes asociadas con la distribución real y mostrando simplemente el cálculo para la forma simplificada, e elevado a menos x al cuadrado.",
  "time_range": [
   208.2,
   217.96
  ]
 },
 {
  "input": "The essence of what we want to compute is what the convolution between two copies of this function looks like.",
  "model": "nmt",
  "translatedText": "La esencia de lo que queremos calcular es cómo se ve la convolución entre dos copias de esta función.",
  "time_range": [
   217.96,
   224.08
  ]
 },
 {
  "input": "If you'll remember, in the last video we had two different ways to visualize convolutions, and the one we'll be using here is the second one, involving diagonal slices.",
  "model": "nmt",
  "translatedText": "Si recuerdas, en el último video teníamos dos formas diferentes de visualizar convoluciones, y la que usaremos aquí es la segunda, que involucra cortes diagonales.",
  "time_range": [
   224.46,
   232.92
  ]
 },
 {
  "input": "And as a quick reminder of the way that worked, if you have two different distributions that are described by two different functions, f and g, then every possible pair of values that you might get when you sample from these two distributions can be thought of as individual points on the xy-plane.",
  "model": "nmt",
  "translatedText": "Y como recordatorio rápido de cómo funcionó, si tiene dos distribuciones diferentes que se describen mediante dos funciones diferentes, f y g, entonces puede pensar en cada par posible de valores que pueda obtener al tomar muestras de estas dos distribuciones. como puntos individuales en el plano xy.",
  "time_range": [
   233.28,
   249.56
  ]
 },
 {
  "input": "And the probability density of landing on one such point, assuming independence, looks like f of x times g of y.",
  "model": "nmt",
  "translatedText": "Y la densidad de probabilidad de aterrizar en uno de esos puntos, suponiendo independencia, parece f de x multiplicado por g de y.",
  "time_range": [
   250.36,
   257.52
  ]
 },
 {
  "input": "So what we do is we look at a graph of that expression as a two-variable function of x and y, which is a way of showing the distribution of all possible outcomes when we sample from the two different variables.",
  "model": "nmt",
  "translatedText": "Entonces, lo que hacemos es mirar una gráfica de esa expresión como una función de dos variables de x e y, que es una forma de mostrar la distribución de todos los resultados posibles cuando tomamos muestras de las dos variables diferentes.",
  "time_range": [
   258.0,
   269.62
  ]
 },
 {
  "input": "To interpret the convolution of f and g evaluated on some input s, which is a way of saying how likely are you to get a pair of samples that adds up to this sum s, what you do is you look at a slice of this graph over the line x plus y equals s, and you consider the area under that slice.",
  "model": "nmt",
  "translatedText": "Para interpretar la convolución de f y g evaluada en algunas entradas s, que es una forma de decir qué probabilidad hay de obtener un par de muestras que sumen esta suma s, lo que hay que hacer es mirar una porción de este gráfico. sobre la línea x más y es igual a s, y consideras el área debajo de ese corte.",
  "time_range": [
   270.56,
   289.3
  ]
 },
 {
  "input": "This area is almost, but not quite, the value of the convolution at s.",
  "model": "nmt",
  "translatedText": "Esta área es casi, pero no del todo, el valor de la convolución en s.",
  "time_range": [
   291.1,
   296.32
  ]
 },
 {
  "input": "For a mildly technical reason, you need to divide by the square root of two.",
  "model": "nmt",
  "translatedText": "Por una razón levemente técnica, debes dividir por la raíz cuadrada de dos.",
  "time_range": [
   296.8,
   300.16
  ]
 },
 {
  "input": "Still, this area is the key feature to focus on.",
  "model": "nmt",
  "translatedText": "Aun así, esta área es la característica clave en la que debemos centrarnos.",
  "time_range": [
   300.84,
   303.44
  ]
 },
 {
  "input": "You can think of it as a way to combine together all the probability densities for all of the outcomes corresponding to a given sum.",
  "model": "nmt",
  "translatedText": "Puedes considerarlo como una forma de combinar todas las densidades de probabilidad de todos los resultados correspondientes a una suma determinada.",
  "time_range": [
   303.44,
   311.04
  ]
 },
 {
  "input": "In the specific case where these two functions look like e to the negative x squared and e to the negative y squared, the resulting 3D graph has a really nice property that you can exploit.",
  "model": "nmt",
  "translatedText": "En el caso específico en el que estas dos funciones se parecen a e elevado a menos x cuadrado y e elevado a menos y cuadrado, el gráfico 3D que queda tiene una propiedad realmente interesante que podemos explotar.",
  "time_range": [
   313.3,
   323.5
  ]
 },
 {
  "input": "It's rotationally symmetric.",
  "model": "nmt",
  "translatedText": "Es rotacionalmente simétrico.",
  "time_range": [
   323.72,
   325.68
  ]
 },
 {
  "input": "You can see this by combining the terms and noticing that it's entirely a function of x squared plus y squared, and this term describes the square of the distance between any point on the xy plane and the origin.",
  "model": "nmt",
  "translatedText": "Puedes ver esto combinando los términos y notando que es completamente una función de x al cuadrado más y al cuadrado, y este término describe el cuadrado de la distancia entre cualquier punto en el plano xy y el origen.",
  "time_range": [
   326.88,
   338.46
  ]
 },
 {
  "input": "So in other words, the expression is purely a function of the distance from the origin.",
  "model": "nmt",
  "translatedText": "En otras palabras, la expresión es puramente una función de la distancia desde el origen.",
  "time_range": [
   339.2,
   343.16
  ]
 },
 {
  "input": "And by the way, this would not be true for any other distribution.",
  "model": "nmt",
  "translatedText": "Y, por cierto, esto no ocurriría con ninguna otra distribución.",
  "time_range": [
   344.56,
   347.92
  ]
 },
 {
  "input": "It's a property that uniquely characterizes bell curves.",
  "model": "nmt",
  "translatedText": "Es una propiedad que caracteriza únicamente a las curvas de campana.",
  "time_range": [
   348.1,
   351.28
  ]
 },
 {
  "input": "So for most other pairs of functions, these diagonal slices will be some complicated shape that's hard to think about, and honestly calculating the area would just amount to computing the original integral that defines a convolution in the first place.",
  "model": "nmt",
  "translatedText": "Entonces, para la mayoría de los otros pares de funciones, estos cortes diagonales tendrán una forma complicada en la que es difícil pensar y, sinceramente, calcular el área equivaldría a calcular la integral original que define una convolución en primer lugar.",
  "time_range": [
   353.16,
   365.54
  ]
 },
 {
  "input": "So in most cases, the visual intuition doesn't really buy you anything.",
  "model": "nmt",
  "translatedText": "Entonces, en la mayoría de los casos, la intuición visual realmente no te compra nada.",
  "time_range": [
   365.94,
   369.36
  ]
 },
 {
  "input": "But in the case of bell curves, you can leverage that rotational symmetry.",
  "model": "nmt",
  "translatedText": "Pero en el caso de las curvas de campana, puedes aprovechar esa simetría rotacional.",
  "time_range": [
   370.36,
   373.92
  ]
 },
 {
  "input": "Here, focus on one of these slices over the line x plus y equals s for some value of s.",
  "model": "nmt",
  "translatedText": "Aquí, concéntrate en uno de estos cortes sobre la línea x más y es igual a s para algún valor de s.",
  "time_range": [
   374.8,
   380.48
  ]
 },
 {
  "input": "And remember, the convolution that we're trying to compute is a function of s.",
  "model": "nmt",
  "translatedText": "Y recuerde, la convolución que intentamos calcular es una función de s.",
  "time_range": [
   381.3,
   385.84
  ]
 },
 {
  "input": "The thing that you want is an expression of s that tells you the area under this slice.",
  "model": "nmt",
  "translatedText": "Lo que quieres es una expresión de s que te indique el área debajo de este sector.",
  "time_range": [
   385.84,
   391.1
  ]
 },
 {
  "input": "Well, if you look at that line, it intersects the x-axis at s zero and the y-axis at zero s.",
  "model": "nmt",
  "translatedText": "Bueno, si miras esa línea, corta el eje x en s cero y el eje y en cero s.",
  "time_range": [
   391.7,
   397.9
  ]
 },
 {
  "input": "And a little bit of Pythagoras will show you that the straight line distance from the origin to this line is s divided by the square root of two.",
  "model": "nmt",
  "translatedText": "Y un poco de Pitágoras te mostrará que la distancia en línea recta desde el origen hasta esta línea es s partido por raíz cuadrada de dos.",
  "time_range": [
   398.32,
   405.32
  ]
 },
 {
  "input": "Now, because of the symmetry, this slice is identical to one that you get rotating 45 degrees, where you'd find something parallel to the y-axis the same distance away from the origin.",
  "model": "nmt",
  "translatedText": "Ahora, debido a la simetría, este corte es idéntico a uno que se obtiene girando 45 grados, donde encontrarías algo paralelo al eje y a la misma distancia del origen.",
  "time_range": [
   405.86,
   416.36
  ]
 },
 {
  "input": "The key is that computing this other area of a slice parallel to the y-axis is much, much easier than slices in other directions, because it only involves taking an integral with respect to y.",
  "model": "nmt",
  "translatedText": "La clave es que calcular esta otra área de un corte paralelo al eje y es mucho, mucho más fácil que los cortes en otras direcciones, porque solo implica tomar una integral con respecto a y.",
  "time_range": [
   417.64,
   428.26
  ]
 },
 {
  "input": "The value of x on this slice is a constant.",
  "model": "nmt",
  "translatedText": "El valor de x en este sector es una constante.",
  "time_range": [
   428.74,
   431.44
  ]
 },
 {
  "input": "Specifically, it would be the constant s divided by the square root of two.",
  "model": "nmt",
  "translatedText": "En concreto, sería la constante s dividida por la raíz cuadrada de dos.",
  "time_range": [
   431.62,
   434.76
  ]
 },
 {
  "input": "So when you're computing the integral, finding this area, all of this term here behaves like it was just some number, and you can factor it out.",
  "model": "nmt",
  "translatedText": "Entonces, cuando calculas la integral y encuentras esta área, todo este término aquí se comporta como si fuera solo un número y puedes factorizarlo.",
  "time_range": [
   434.76,
   443.38
  ]
 },
 {
  "input": "This is the important point.",
  "model": "nmt",
  "translatedText": "Este es el punto importante.",
  "time_range": [
   443.88,
   444.94
  ]
 },
 {
  "input": "All of the stuff that's involving s is now entirely separate from the integrated variable.",
  "model": "nmt",
  "translatedText": "Todo lo que involucra s ahora está completamente separado de la variable integrada.",
  "time_range": [
   445.28,
   450.2
  ]
 },
 {
  "input": "This remaining integral is a little bit tricky.",
  "model": "nmt",
  "translatedText": "Esta integral restante es un poco complicada.",
  "time_range": [
   450.82,
   453.0
  ]
 },
 {
  "input": "I did a whole video on it, it's actually quite famous.",
  "model": "nmt",
  "translatedText": "Ya hice un vídeo entero sobre ello, que de hecho es bastante popular.",
  "time_range": [
   453.08,
   455.2
  ]
 },
 {
  "input": "But you almost don't really care.",
  "model": "nmt",
  "translatedText": "Pero apenas importa.",
  "time_range": [
   455.5,
   456.9
  ]
 },
 {
  "input": "The point is that it's just some number.",
  "model": "nmt",
  "translatedText": "El caso es que es sólo un número.",
  "time_range": [
   457.24,
   459.0
  ]
 },
 {
  "input": "That number happens to be the square root of pi, but what really matters is that it's something with no dependence on s.",
  "model": "nmt",
  "translatedText": "Ese número resulta ser la raíz cuadrada de pi, pero lo que realmente importa es que es algo que no depende de s.",
  "time_range": [
   459.0,
   465.48
  ]
 },
 {
  "input": "And essentially, this is our answer.",
  "model": "nmt",
  "translatedText": "Y, en esencia, esta es nuestra respuesta.",
  "time_range": [
   466.88,
   468.48
  ]
 },
 {
  "input": "We were looking for an expression for the area of these slices as a function of s, and now we have it.",
  "model": "nmt",
  "translatedText": "Estábamos buscando una expresión para el área de estos cortes en función de s y ahora la tenemos.",
  "time_range": [
   468.78,
   474.28
  ]
 },
 {
  "input": "It looks like e to the negative s squared divided by two, scaled by some constant.",
  "model": "nmt",
  "translatedText": "Parece e elevado a s negativo al cuadrado dividido por dos, escalado por alguna constante.",
  "time_range": [
   474.38,
   478.84
  ]
 },
 {
  "input": "In other words, it's also a bell curve, another Gaussian, just stretched out a little bit because of this two in the exponent.",
  "model": "nmt",
  "translatedText": "En otras palabras, también es una curva de campana, otra gaussiana, sólo que se alarga un poco debido a estos dos en el exponente.",
  "time_range": [
   479.3,
   485.62
  ]
 },
 {
  "input": "As I said earlier, the convolution evaluated at s is not quite this area.",
  "model": "nmt",
  "translatedText": "Como dije antes, la convolución evaluada en s no es exactamente esta área.",
  "time_range": [
   485.62,
   490.86
  ]
 },
 {
  "input": "Technically, it's this area divided by the square root of two.",
  "model": "nmt",
  "translatedText": "Técnicamente, es esta área dividida por la raíz cuadrada de dos.",
  "time_range": [
   491.34,
   494.16
  ]
 },
 {
  "input": "We talked about it in the last video, but it doesn't really matter because it just gets baked into the constant.",
  "model": "nmt",
  "translatedText": "Hablamos de ello en el último vídeo, pero en realidad no importa porque simplemente se incorpora a la constante.",
  "time_range": [
   494.8,
   499.24
  ]
 },
 {
  "input": "What really matters is the conclusion that a convolution between two Gaussians is itself another Gaussian.",
  "model": "nmt",
  "translatedText": "Lo que realmente importa es la conclusión de que una convolución entre dos gaussianas es en sí misma otra gaussiana.",
  "time_range": [
   499.68,
   505.68
  ]
 },
 {
  "input": "If you were to go back and reintroduce all of the constants for a normal distribution with a mean zero and an arbitrary standard deviation sigma, essentially identical reasoning will lead to the same square root of two factor that shows up in the exponent and out front, and it leads to the conclusion that the convolution between two such normal distributions is another normal distribution with a standard deviation square root of two times sigma.",
  "model": "nmt",
  "translatedText": "Si volviera atrás y reintrodujera todas las constantes para una distribución normal con una media cero y una desviación estándar sigma arbitraria, un razonamiento esencialmente idéntico conducirá a la misma raíz cuadrada de dos factores que aparece en el exponente y al frente, y lleva a la conclusión de que la convolución entre dos de esas distribuciones normales es otra distribución normal con una desviación estándar de raíz cuadrada de dos veces sigma.",
  "time_range": [
   507.56,
   530.38
  ]
 },
 {
  "input": "If you haven't computed a lot of convolutions before, it's worth emphasizing this is a very special result.",
  "model": "nmt",
  "translatedText": "Si no has calculado muchas convoluciones antes, vale la pena enfatizar que este es un resultado muy especial.",
  "time_range": [
   530.98,
   536.06
  ]
 },
 {
  "input": "Almost always you end up with a completely different kind of function, but here there's a sort of stability to the process.",
  "model": "nmt",
  "translatedText": "Casi siempre terminas con un tipo de función completamente distinta, pero aquí hay una especie de estabilidad en el proceso.",
  "time_range": [
   536.38,
   542.5
  ]
 },
 {
  "input": "Also, for those of you who enjoy exercises, I'll leave one up on the screen for how you would handle the case of two different standard deviations.",
  "model": "nmt",
  "translatedText": "Además, para los que les gustan los ejercicios, pondré uno en la pantalla sobre cómo se puede hacer en el caso de dos desviaciones estándar distintas.",
  "time_range": [
   543.26,
   549.44
  ]
 },
 {
  "input": "Still, some of you might be raising your hands and saying, what's the big deal?",
  "model": "nmt",
  "translatedText": "Aun así, es posible que algunos de ustedes levanten la mano y digan: ¿cuál es el problema?",
  "time_range": [
   550.42,
   553.94
  ]
 },
 {
  "input": "I mean, when you first heard the question, what do you get when you add two normally distributed random variables, you probably even guessed that the answer should be another normally distributed variable.",
  "model": "nmt",
  "translatedText": "Quiero decir, cuando escuchaste por primera vez la pregunta, ¿qué obtienes cuando agregas dos variables aleatorias distribuidas normalmente? Probablemente incluso adivinaste que la respuesta debería ser otra variable distribuida normalmente.",
  "time_range": [
   554.48,
   564.32
  ]
 },
 {
  "input": "After all, what else is it going to be?",
  "model": "nmt",
  "translatedText": "Después de todo, ¿qué más va a ser?",
  "time_range": [
   564.76,
   566.36
  ]
 },
 {
  "input": "Normal distributions are supposedly quite common, so why not?",
  "model": "nmt",
  "translatedText": "Se supone que las distribuciones normales son bastante comunes, entonces ¿por qué no?",
  "time_range": [
   566.86,
   570.24
  ]
 },
 {
  "input": "You could even say that this should follow from the central limit theorem, but that would have it all backwards.",
  "model": "nmt",
  "translatedText": "Incluso se podría decir que esto debería derivarse del teorema del límite central, pero eso sería todo al revés.",
  "time_range": [
   570.24,
   575.48
  ]
 },
 {
  "input": "First of all, the supposed ubiquity of normal distributions is often a little exaggerated, but to the extent that they do come up, it is because of the central limit theorem, but it would be cheating to say the central limit theorem implies this result because this computation we just did is the reason that the function at the heart of the central limit theorem is a Gaussian in the first place and not some other function.",
  "model": "nmt",
  "translatedText": "En primer lugar, la supuesta ubicuidad de las distribuciones normales es a menudo un poco exagerada, pero en la medida en que surgen, se debe al teorema del límite central, pero sería un engaño decir que el teorema del límite central implica este resultado porque Este cálculo que acabamos de hacer es la razón por la que la función central del teorema del límite central es gaussiana en primer lugar y no alguna otra función.",
  "time_range": [
   576.18,
   597.06
  ]
 },
 {
  "input": "We've talked all about the central limit theorem before, but essentially it says if you repeatedly add copies of a random variable to itself, which mathematically looks like repeatedly computing convolutions against a given distribution, then after appropriate shifting and rescaling, the tendency is always to approach a normal distribution.",
  "model": "nmt",
  "translatedText": "Ya hemos hablado antes sobre el teorema del límite central, pero en esencia dice que si agregas repetidamente copias de una variable aleatoria a sí misma, lo que matemáticamente parece calcular repetidamente convoluciones contra una distribución dada, luego de un desplazamiento y reescalado apropiados, la tendencia es siempre para acercarse a una distribución normal.",
  "time_range": [
   597.06,
   616.5
  ]
 },
 {
  "input": "Technically there's a small assumption the distribution you start with can't have infinite variance, but it's a relatively soft assumption.",
  "model": "nmt",
  "translatedText": "Técnicamente, existe una pequeña suposición de que la distribución con la que comienzas no puede tener una varianza infinita, pero es una suposición relativamente blanda.",
  "time_range": [
   616.98,
   623.22
  ]
 },
 {
  "input": "The magic is that for a huge category of initial distributions, this process of adding a whole bunch of random variables drawn from that distribution always tends towards this one universal shape, a Gaussian.",
  "model": "nmt",
  "translatedText": "La magia es que para una categoría enorme de distribuciones iniciales, este proceso de agregar un montón de variables aleatorias extraídas de esa distribución siempre tiende hacia esta forma universal, una gaussiana.",
  "time_range": [
   623.22,
   635.1
  ]
 },
 {
  "input": "One common approach to proving this theorem involves two separate steps.",
  "model": "nmt",
  "translatedText": "Un enfoque común para demostrar este teorema implica dos pasos separados.",
  "time_range": [
   635.82,
   639.3
  ]
 },
 {
  "input": "The first step is to show that for all the different finite variance distributions you might start with, there exists a single universal shape that this process of repeated convolutions tends towards.",
  "model": "nmt",
  "translatedText": "El primer paso es mostrar que para todas las diferentes distribuciones de varianza finita con las que se puede comenzar, existe una única forma universal hacia la que tiende este proceso de convoluciones repetidas.",
  "time_range": [
   639.6,
   650.0
  ]
 },
 {
  "input": "This step is actually pretty technical, it goes a little beyond what I want to talk about here.",
  "model": "nmt",
  "translatedText": "En realidad, este paso es bastante técnico y va un poco más allá de lo que quiero hablar aquí.",
  "time_range": [
   650.0,
   654.24
  ]
 },
 {
  "input": "You often use these objects called moment generating functions that gives you a very abstract argument that there must be some universal shape, but it doesn't make any claim about what that particular shape is, just that everything in this big family is tending towards a single point in the space of distributions.",
  "model": "nmt",
  "translatedText": "A menudo se utilizan estos objetos llamados funciones generadoras de momentos, lo que les da un argumento muy abstracto de que debe haber alguna forma universal, pero no afirman cuál es esa forma en particular, solo que todo en esta gran familia tiende hacia una punto único en el espacio de distribuciones.",
  "time_range": [
   654.52,
   669.98
  ]
 },
 {
  "input": "So then step number two is what we just showed in this video, prove that the convolution of two Gaussians gives another Gaussian.",
  "model": "nmt",
  "translatedText": "Entonces, el paso número dos es lo que acabamos de mostrar en este video: demostrar que la convolución de dos gaussianas da otra gaussiana.",
  "time_range": [
   670.62,
   677.4
  ]
 },
 {
  "input": "What that means is that as you apply this process of repeated convolutions, a Gaussian doesn't change, it's a fixed point.",
  "model": "nmt",
  "translatedText": "Lo que eso quiere decir es que al aplicar este proceso de convoluciones repetidas, una gaussiana no cambia, es un punto fijo.",
  "time_range": [
   677.4,
   684.06
  ]
 },
 {
  "input": "So the only thing it can approach is itself, and since it's one member in this big family of distributions, all of which must be tending towards a single universal shape, it must be that universal shape.",
  "model": "nmt",
  "translatedText": "Entonces, lo único a lo que se puede acercar es a sí mismo, y dado que es un miembro de esta gran familia de distribuciones, todas las cuales deben tender hacia una única forma universal, debe ser esa forma universal.",
  "time_range": [
   684.2,
   695.06
  ]
 },
 {
  "input": "I mentioned at the start how this calculation, step two, is something that you can do directly, just symbolically with the definitions, but one of the reasons I'm so charmed by a geometric argument that leverages the rotational symmetry of this graph is that it directly connects to a few things that we've talked about on this channel before.",
  "model": "nmt",
  "translatedText": "Mencioné al principio que este cálculo, paso dos, es algo que puedes hacer directamente, sólo simbólicamente con las definiciones, pero una de las razones por las que estoy tan encantado con un argumento geométrico que aprovecha la simetría rotacional de esta gráfica es que se conecta directamente con algunas cosas de las que hemos hablado antes en este canal.",
  "time_range": [
   695.58,
   712.3
  ]
 },
 {
  "input": "For example, the Herschel-Maxwell derivation of a Gaussian, which essentially says that you can view this rotational symmetry as the defining feature of the distribution, that it locks you into this e to the negative x squared form, and also as an added bonus it connects to the classic proof for why pi shows up in the formula, meaning we now have a direct line between the presence and mystery of that pi and the central limit theorem.",
  "model": "nmt",
  "translatedText": "Por ejemplo, la derivación de Herschel-Maxwell de una gaussiana, que esencialmente dice que puedes ver esta simetría rotacional como la característica definitoria de la distribución, que te encierra en esta e en la forma negativa de x al cuadrado, y también como una ventaja adicional. se conecta con la prueba clásica de por qué pi aparece en la fórmula, lo que significa que ahora tenemos una línea directa entre la presencia y el misterio de ese pi y el teorema del límite central.",
  "time_range": [
   712.4,
   736.5
  ]
 },
 {
  "input": "Also on a recent Patreon post, the channel supporter Daksha Vaid-Quinter brought my attention to a completely different approach I hadn't seen before, which leverages the use of entropy, and again for the theoretically curious among you I'll leave some links in the description.",
  "model": "nmt",
  "translatedText": "También en una publicación reciente de Patreon, Daksha Vaid-Quinter, mecenas del canal, me llamó la atención sobre un enfoque completamente diferente que no había visto antes, que aprovecha el uso de la entropía, y nuevamente, para los curiosos de la teoría, dejaré algunos enlaces en la descripción.",
  "time_range": [
   737.06,
   749.58
  ]
 },
 {
  "input": "By the way, if you want to stay up to date with new videos and also any other projects that I put out there like the Summer of Math Exposition, there is a mailing list.",
  "model": "nmt",
  "translatedText": "Por cierto, si quieres mantenerte al tanto de nuevos vídeos y también de cualquier otro proyecto que publique, como la Exposición de Matemáticas de Verano, tenemos una lista de correos.",
  "time_range": [
   750.96,
   758.4
  ]
 },
 {
  "input": "It's relatively new and I'm pretty sparing about only posting what I think people will enjoy.",
  "model": "nmt",
  "translatedText": "Es relativamente nuevo y soy bastante cauteloso a la hora de publicar solo aquello que creo que la gente va a disfrutar.",
  "time_range": [
   758.72,
   762.78
  ]
 },
 {
  "input": "Usually I try not to be too promotional at the end of videos these days, but if you are interested in following the work that I do, this is probably one of the most enduring ways to do so.",
  "model": "nmt",
  "translatedText": "Por lo general, estos días estoy tratando de no hacer demasiadas promociones al final de los videos, pero si estás interesado en seguir el trabajo que hago, esta es probablemente una de las mejores formas de hacerlo.",
  "time_range": [
   763.22,
   795.26
  ]
 }
]
