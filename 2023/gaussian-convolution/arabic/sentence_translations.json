[
 {
  "input": "The basic function underlying a normal distribution, aka a Gaussian, is e to the negative x squared. ",
  "translatedText": "الوظيفة الأساسية التي يقوم عليها التوزيع الطبيعي، والمعروفة أيضًا باسم Gaussian، هي e إلى سالب x تربيع. ",
  "model": "nmt",
  "time_range": [
   0.0,
   6.5600000000000005
  ]
 },
 {
  "input": "But you might wonder, why this function? ",
  "translatedText": "لكن قد تتساءل لماذا هذه الوظيفة؟ ",
  "model": "nmt",
  "time_range": [
   6.5600000000000005,
   8.66
  ]
 },
 {
  "input": "Of all the expressions we could dream up that give you some symmetric smooth graph with mass concentrated towards the middle, why is it that the theory of probability seems to have a special place in its heart for this particular expression? ",
  "translatedText": "من بين جميع التعبيرات التي يمكن أن نحلم بها والتي تعطيك رسمًا بيانيًا سلسًا متماثلًا مع كتلة مركزة نحو المنتصف، لماذا يبدو أن نظرية الاحتمال لها مكان خاص في قلبها لهذا التعبير بالذات؟ ",
  "model": "nmt",
  "time_range": [
   8.66,
   21.32
  ]
 },
 {
  "input": "For the last many videos I've been hinting at an answer to this question, and here we'll finally arrive at something like a satisfying answer. ",
  "translatedText": "في العديد من مقاطع الفيديو الأخيرة، كنت ألمح إلى إجابة لهذا السؤال، وهنا سنصل أخيرًا إلى شيء يشبه الإجابة المرضية. ",
  "model": "nmt",
  "time_range": [
   21.32,
   28.16
  ]
 },
 {
  "input": "As a quick refresher on where we are, a couple videos ago we talked about the central limit theorem, which describes how as you add multiple copies of a random variable, for example rolling a weighted die many different times or letting a ball bounce off of a peg repeatedly, then the distribution describing that sum tends to look approximately like a normal distribution. ",
  "translatedText": "كتجديد سريع لما وصلنا إليه، تحدثنا قبل عدة مقاطع فيديو عن نظرية الحد المركزي، والتي تصف كيفية إضافة نسخ متعددة من متغير عشوائي، على سبيل المثال رمي حجر النرد الموزون عدة مرات مختلفة أو ترك الكرة ترتد الربط بشكل متكرر، فإن التوزيع الذي يصف هذا المبلغ يميل إلى أن يبدو تقريبًا مثل التوزيع الطبيعي. ",
  "model": "nmt",
  "time_range": [
   28.16,
   48.36
  ]
 },
 {
  "input": "What the central limit theorem says is as you make that sum bigger and bigger, under appropriate conditions, that approximation to a normal becomes better and better. ",
  "translatedText": "ما تقوله نظرية الحد المركزي هو أنه عندما تجعل هذا المجموع أكبر فأكبر، في ظل الظروف المناسبة، فإن التقريب إلى الوضع الطبيعي يصبح أفضل وأفضل. ",
  "model": "nmt",
  "time_range": [
   48.36,
   57.28
  ]
 },
 {
  "input": "But I never explained why this theorem is actually true, we only talked about what it's claiming. ",
  "translatedText": "لكنني لم أشرح أبدًا سبب صحة هذه النظرية، لقد تحدثنا فقط عما تدعيه. ",
  "model": "nmt",
  "time_range": [
   57.28,
   63.36
  ]
 },
 {
  "input": "In the last video we started talking about the math involved in adding two random variables. ",
  "translatedText": "في الفيديو الأخير بدأنا الحديث عن العمليات الحسابية المتعلقة بإضافة متغيرين عشوائيين. ",
  "model": "nmt",
  "time_range": [
   63.36,
   68.24
  ]
 },
 {
  "input": "If you have two random variables, each following some distribution, then to find the distribution describing the sum of those variables, you compute something known as a convolution between the two original functions. ",
  "translatedText": "إذا كان لديك متغيرين عشوائيين، كل منهما يتبع بعض التوزيع، ثم للعثور على التوزيع الذي يصف مجموع تلك المتغيرات، عليك حساب ما يعرف بالالتواء بين الوظيفتين الأصليتين. ",
  "model": "nmt",
  "time_range": [
   68.24,
   80.2
  ]
 },
 {
  "input": "And we spent a lot of time building up two distinct ways to visualize what this convolution operation really is. ",
  "translatedText": "وقد أمضينا الكثير من الوقت في بناء طريقتين مختلفتين لتصور حقيقة عملية التلافي هذه. ",
  "model": "nmt",
  "time_range": [
   80.2,
   86.44
  ]
 },
 {
  "input": "Today our basic job is to work through a particular example, which is to ask what happens when you add two normally distributed random variables, which as you know by now is the same as asking what do you get if you compute a convolution between two Gaussian functions. ",
  "translatedText": "مهمتنا الأساسية اليوم هي العمل من خلال مثال معين، وهو التساؤل عما يحدث عند إضافة متغيرين عشوائيين موزعين بشكل طبيعي، والذي كما تعلم الآن هو نفس السؤال عما ستحصل عليه إذا قمت بحساب الالتواء بين متغيرين غاوسيين المهام. ",
  "model": "nmt",
  "time_range": [
   86.44,
   102.52
  ]
 },
 {
  "input": "I'd like to share an especially pleasing visual way that you can think about this calculation, which hopefully offers some sense of what makes the e to the negative x squared function special in the first place. ",
  "translatedText": "أود أن أشارك طريقة مرئية ممتعة بشكل خاص يمكنك من خلالها التفكير في هذه العملية الحسابية، والتي نأمل أن توفر بعض المعنى لما يجعل الدالة e إلى x السالبة المربعة مميزة في المقام الأول. ",
  "model": "nmt",
  "time_range": [
   102.52,
   112.88
  ]
 },
 {
  "input": "After we walk through it, we'll talk about how this calculation is one of the steps involved in proving the central limit theorem. ",
  "translatedText": "وبعد أن نتناولها، سنتحدث عن كيف أن هذه العملية الحسابية هي إحدى خطوات إثبات نظرية الحد المركزي. ",
  "model": "nmt",
  "time_range": [
   112.88,
   118.48
  ]
 },
 {
  "input": "It's the step that answers the question of why a Gaussian and not something else is the central limit. ",
  "translatedText": "إنها الخطوة التي تجيب على سؤال لماذا يعتبر Gaussian وليس أي شيء آخر هو الحد المركزي. ",
  "model": "nmt",
  "time_range": [
   118.48,
   124.16
  ]
 },
 {
  "input": "But first, let's dive in. ",
  "translatedText": "لكن أولاً، دعونا نتعمق. ",
  "model": "nmt",
  "time_range": [
   124.16,
   125.68
  ]
 },
 {
  "input": "The full formula for a Gaussian is more complicated than just e to the negative x squared. ",
  "translatedText": "الصيغة الكاملة للغاوسي أكثر تعقيدًا من مجرد e إلى سالب x تربيع. ",
  "model": "nmt",
  "time_range": [
   125.68,
   134.8
  ]
 },
 {
  "input": "The exponent is typically written as negative one half times x divided by sigma squared, where sigma describes the spread of the distribution, specifically the standard deviation. ",
  "translatedText": "يتم كتابة الأس عادةً على هيئة سالب نصف × x مقسومًا على مربع سيجما، حيث يصف سيجما انتشار التوزيع، وتحديدًا الانحراف المعياري. ",
  "model": "nmt",
  "time_range": [
   134.8,
   144.6
  ]
 },
 {
  "input": "All of this needs to be multiplied by a fraction on the front, which is there to make sure that the area under the curve is one, making it a valid probability distribution. ",
  "translatedText": "كل هذا يحتاج إلى ضربه في كسر في المقدمة، وهو موجود للتأكد من أن المساحة تحت المنحنى تساوي واحدًا، مما يجعله توزيعًا احتماليًا صحيحًا. ",
  "model": "nmt",
  "time_range": [
   144.6,
   153.96
  ]
 },
 {
  "input": "And if you want to consider distributions that aren't necessarily centered at zero, you would also throw another parameter, mu, into the exponent like this. ",
  "translatedText": "وإذا كنت تريد أن تأخذ في الاعتبار التوزيعات التي لا تتمركز بالضرورة عند الصفر، فيمكنك أيضًا إضافة معلمة أخرى، mu، إلى الأس مثل هذا. ",
  "model": "nmt",
  "time_range": [
   153.96,
   161.48
  ]
 },
 {
  "input": "Although for everything we'll be doing here, we just consider centered distributions. ",
  "translatedText": "على الرغم من أن كل ما سنفعله هنا، فإننا نأخذ في الاعتبار التوزيعات المركزية فقط. ",
  "model": "nmt",
  "time_range": [
   161.48,
   166.2
  ]
 },
 {
  "input": "Now if you look at our central goal for today, which is to compute a convolution between two Gaussian functions, the direct way to do this would be to take the definition of a convolution, this integral expression we built up last video, and then to plug in for each one of the functions involved the formula for a Gaussian. ",
  "translatedText": "الآن إذا نظرت إلى هدفنا المركزي لهذا اليوم، وهو حساب الالتواء بين دالتين غاوسيتين، فإن الطريقة المباشرة للقيام بذلك هي أخذ تعريف الالتفاف، هذا التعبير التكاملي الذي بنيناه في الفيديو الأخير، ثم قم بتوصيل كل واحدة من الوظائف التي تتضمن صيغة Gaussian. ",
  "model": "nmt",
  "time_range": [
   166.2,
   184.08
  ]
 },
 {
  "input": "It's kind of a lot of symbols when you throw it all together, but more than anything, working this out is an exercise in completing the square. ",
  "translatedText": "إنه نوع من الرموز الكثيرة عندما تجمعها كلها معًا، ولكن الأهم من أي شيء آخر، أن حل هذا هو تمرين على إكمال المربع. ",
  "model": "nmt",
  "time_range": [
   184.08,
   190.48
  ]
 },
 {
  "input": "And there's nothing wrong with that. ",
  "translatedText": "ولا حرج في ذلك. ",
  "model": "nmt",
  "time_range": [
   190.48,
   191.97827160493824
  ]
 },
 {
  "input": "That will get you the answer that you want. ",
  "translatedText": "سيعطيك ذلك الإجابة التي تريدها. ",
  "model": "nmt",
  "time_range": [
   191.97827160493824,
   193.76
  ]
 },
 {
  "input": "But of course, you know me, I'm a sucker for visual intuition, and in this case, there's another way to think about it that I haven't seen written about before, that offers a very nice connection to other aspects of this distribution, like the presence of pi and certain ways to derive where it comes from. ",
  "translatedText": "لكن بالطبع، كما تعلمون، أنا مهووس بالحدس البصري، وفي هذه الحالة، هناك طريقة أخرى للتفكير في الأمر لم أرها مكتوبة عنها من قبل، والتي توفر اتصالًا لطيفًا جدًا بجوانب أخرى من هذا التوزيع، مثل وجود pi وطرق معينة لاستخلاص مصدرها. ",
  "model": "nmt",
  "time_range": [
   193.76,
   208.0
  ]
 },
 {
  "input": "And the way I'd like to do this is by first peeling away all of the constants associated with the actual distribution, and just showing the computation for the simplified form, e to the negative x squared. ",
  "translatedText": "والطريقة التي أود القيام بها هي أولاً إزالة كل الثوابت المرتبطة بالتوزيع الفعلي، وإظهار الحساب للشكل المبسط، e إلى سالب x مربع. ",
  "model": "nmt",
  "time_range": [
   208.0,
   218.24
  ]
 },
 {
  "input": "The essence of what we want to compute is what the convolution between two copies of this function looks like. ",
  "translatedText": "جوهر ما نريد حسابه هو الشكل الذي يبدو عليه الالتواء بين نسختين من هذه الوظيفة. ",
  "model": "nmt",
  "time_range": [
   218.24,
   224.64
  ]
 },
 {
  "input": "If you'll remember, in the last video we had two different ways to visualize convolutions, and the one we'll be using here is the second one, involving diagonal slices. ",
  "translatedText": "إذا كنتم تتذكرون، في الفيديو الأخير كان لدينا طريقتان مختلفتان لتصور التلافيف، والطريقة التي سنستخدمها هنا هي الطريقة الثانية، والتي تتضمن شرائح قطرية. ",
  "model": "nmt",
  "time_range": [
   224.64,
   233.12
  ]
 },
 {
  "input": "And as a quick reminder of the way that worked, if you have two different distributions that are described by two different functions, f and g, then every possible pair of values that you might get when you sample from these two distributions can be thought of as individual points on the xy-plane. ",
  "translatedText": "وكتذكير سريع بالطريقة التي نجح بها الأمر، إذا كان لديك توزيعان مختلفان موصوفان بوظيفتين مختلفتين، f وg، فيمكن التفكير في كل زوج ممكن من القيم التي قد تحصل عليها عند أخذ عينة من هذين التوزيعين كنقاط فردية على المستوى xy. ",
  "model": "nmt",
  "time_range": [
   233.12,
   249.44
  ]
 },
 {
  "input": "And the probability density of landing on one such point, assuming independence, looks like f of x times g of y. ",
  "translatedText": "والكثافة الاحتمالية للهبوط على إحدى هذه النقاط، بافتراض الاستقلال، تبدو مثل f لـ x في g لـ y. ",
  "model": "nmt",
  "time_range": [
   249.44,
   257.76
  ]
 },
 {
  "input": "So what we do is we look at a graph of that expression as a two-variable function of x and y, which is a way of showing the distribution of all possible outcomes when we sample from the two different variables. ",
  "translatedText": "إذن ما نفعله هو أننا ننظر إلى الرسم البياني لذلك التعبير باعتباره دالة ذات متغيرين لـ x وy، وهي طريقة لإظهار توزيع جميع النتائج المحتملة عندما نأخذ عينات من المتغيرين المختلفين. ",
  "model": "nmt",
  "time_range": [
   257.76,
   269.6
  ]
 },
 {
  "input": "To interpret the convolution of f and g evaluated on some input s, which is a way of saying how likely are you to get a pair of samples that adds up to this sum s, what you do is you look at a slice of this graph over the line x plus y equals s, and you consider the area under that slice. ",
  "translatedText": "لتفسير التفاف f وg الذي تم تقييمه على بعض المدخلات s، وهي طريقة لتوضيح مدى احتمال حصولك على زوج من العينات التي تضيف ما يصل إلى هذا المجموع s، ما تفعله هو النظر إلى شريحة من هذا الرسم البياني فوق الخط x زائد y يساوي s، وتأخذ في الاعتبار المساحة الموجودة أسفل تلك الشريحة. ",
  "model": "nmt",
  "time_range": [
   269.6,
   289.12
  ]
 },
 {
  "input": "This area is almost, but not quite, the value of the convolution at s. ",
  "translatedText": "هذه المنطقة تقريبًا، ولكن ليس تمامًا، قيمة الالتواء عند s. ",
  "model": "nmt",
  "time_range": [
   289.12,
   296.08
  ]
 },
 {
  "input": "For a mildly technical reason, you need to divide by the square root of two. ",
  "translatedText": "لسبب تقني بسيط، تحتاج إلى القسمة على الجذر التربيعي لاثنين. ",
  "model": "nmt",
  "time_range": [
   296.08,
   300.0
  ]
 },
 {
  "input": "Still, this area is the key feature to focus on. ",
  "translatedText": "ومع ذلك، فإن هذه المنطقة هي الميزة الرئيسية التي يجب التركيز عليها. ",
  "model": "nmt",
  "time_range": [
   300.0,
   303.52
  ]
 },
 {
  "input": "You can think of it as a way to combine together all the probability densities for all of the outcomes corresponding to a given sum. ",
  "translatedText": "يمكنك التفكير في الأمر كطريقة للجمع بين كل كثافات الاحتمالية لجميع النتائج المقابلة لمجموع معين. ",
  "model": "nmt",
  "time_range": [
   303.52,
   310.8
  ]
 },
 {
  "input": "In the specific case where these two functions look like e to the negative x squared and e to the negative y squared, the resulting 3D graph has a really nice property that you can exploit. ",
  "translatedText": "في الحالة المحددة حيث تبدو هاتان الدالتان مثل e إلى سالب x تربيع وe إلى سالب y تربيع، فإن الرسم البياني ثلاثي الأبعاد الناتج له خاصية رائعة حقًا يمكنك استغلالها. ",
  "model": "nmt",
  "time_range": [
   310.8,
   323.84
  ]
 },
 {
  "input": "It's rotationally symmetric. ",
  "translatedText": "انها متناظرة دورانيا. ",
  "model": "nmt",
  "time_range": [
   323.84,
   325.36
  ]
 },
 {
  "input": "You can see this by combining the terms and noticing that it's entirely a function of x squared plus y squared, and this term describes the square of the distance between any point on the xy plane and the origin. ",
  "translatedText": "يمكنك رؤية ذلك من خلال دمج المصطلحات وملاحظة أنها دالة بالكامل لـ x تربيع زائد y تربيع، وهذا المصطلح يصف مربع المسافة بين أي نقطة على المستوى xy ونقطة الأصل. ",
  "model": "nmt",
  "time_range": [
   325.36,
   338.2408
  ]
 },
 {
  "input": "So in other words, the expression is purely a function of the distance from the origin. ",
  "translatedText": "بمعنى آخر، التعبير هو مجرد دالة للبعد عن نقطة الأصل. ",
  "model": "nmt",
  "time_range": [
   338.2408,
   343.316
  ]
 },
 {
  "input": "And by the way, this would not be true for any other distribution. ",
  "translatedText": "وبالمناسبة، هذا لن يكون صحيحا بالنسبة لأي توزيع آخر. ",
  "model": "nmt",
  "time_range": [
   343.316,
   347.872
  ]
 },
 {
  "input": "It's a property that uniquely characterizes bell curves. ",
  "translatedText": "إنها خاصية تميز منحنيات الجرس بشكل فريد. ",
  "model": "nmt",
  "time_range": [
   347.872,
   352.0739240506329
  ]
 },
 {
  "input": "So for most other pairs of functions, these diagonal slices will be some complicated shape that's hard to think about, and honestly calculating the area would just amount to computing the original integral that defines a convolution in the first place. ",
  "translatedText": "لذا بالنسبة لمعظم أزواج الدوال الأخرى، ستكون هذه الشرائح القطرية ذات شكل معقد يصعب التفكير فيه، وحساب المساحة بأمانة سيكون بمثابة حساب التكامل الأصلي الذي يحدد الالتواء في المقام الأول. ",
  "model": "nmt",
  "time_range": [
   352.0739240506329,
   365.58490566037733
  ]
 },
 {
  "input": "So in most cases, the visual intuition doesn't really buy you anything. ",
  "translatedText": "لذلك في معظم الحالات، الحدس البصري لا يشتري لك أي شيء حقًا. ",
  "model": "nmt",
  "time_range": [
   365.58490566037733,
   369.28
  ]
 },
 {
  "input": "But in the case of bell curves, you can leverage that rotational symmetry. ",
  "translatedText": "لكن في حالة منحنيات الجرس، يمكنك الاستفادة من هذا التناظر الدوراني. ",
  "model": "nmt",
  "time_range": [
   369.28,
   373.92
  ]
 },
 {
  "input": "Here, focus on one of these slices over the line x plus y equals s for some value of s. ",
  "translatedText": "هنا، ركز على إحدى هذه الشرائح فوق الخط x زائد y يساوي s لبعض قيم s. ",
  "model": "nmt",
  "time_range": [
   373.92,
   380.32
  ]
 },
 {
  "input": "And remember, the convolution that we're trying to compute is a function of s. ",
  "translatedText": "وتذكر أن الإلتواء الذي نحاول حسابه هو دالة لـ s. ",
  "model": "nmt",
  "time_range": [
   380.32,
   385.78330097087377
  ]
 },
 {
  "input": "The thing that you want is an expression of s that tells you the area under this slice. ",
  "translatedText": "الشيء الذي تريده هو تعبير عن s يخبرك بالمساحة الموجودة أسفل هذه الشريحة. ",
  "model": "nmt",
  "time_range": [
   385.78330097087377,
   391.14666666666665
  ]
 },
 {
  "input": "Well, if you look at that line, it intersects the x-axis at s zero and the y-axis at zero s. ",
  "translatedText": "حسنًا، إذا نظرت إلى هذا الخط، فهو يتقاطع مع المحور x عند s صفر والمحور y عند صفر s. ",
  "model": "nmt",
  "time_range": [
   391.14666666666665,
   397.13882352941175
  ]
 },
 {
  "input": "And a little bit of Pythagoras will show you that the straight line distance from the origin to this line is s divided by the square root of two. ",
  "translatedText": "وقليلًا من فيثاغورس سيوضح لك أن مسافة الخط المستقيم من نقطة الأصل إلى هذا الخط هي s مقسومة على الجذر التربيعي لاثنين. ",
  "model": "nmt",
  "time_range": [
   397.13882352941175,
   405.68
  ]
 },
 {
  "input": "Now, because of the symmetry, this slice is identical to one that you get rotating 45 degrees, where you'd find something parallel to the y-axis the same distance away from the origin. ",
  "translatedText": "الآن، بسبب التماثل، هذه الشريحة مطابقة لشريحة تدور بزاوية 45 درجة، حيث ستجد شيئًا موازيًا للمحور الصادي على نفس المسافة بعيدًا عن نقطة الأصل. ",
  "model": "nmt",
  "time_range": [
   405.68,
   416.32
  ]
 },
 {
  "input": "The key is that computing this other area of a slice parallel to the y-axis is much, much easier than slices in other directions, because it only involves taking an integral with respect to y. ",
  "translatedText": "المفتاح هو أن حساب هذه المساحة الأخرى من الشريحة الموازية للمحور y أسهل بكثير من الشرائح في اتجاهات أخرى، لأنها تتضمن فقط أخذ تكامل فيما يتعلق بـ y. ",
  "model": "nmt",
  "time_range": [
   416.32,
   428.01254901960783
  ]
 },
 {
  "input": "The value of x on this slice is a constant. ",
  "translatedText": "قيمة x على هذه الشريحة ثابتة. ",
  "model": "nmt",
  "time_range": [
   428.01254901960783,
   430.63529411764705
  ]
 },
 {
  "input": "Specifically, it would be the constant s divided by the square root of two. ",
  "translatedText": "على وجه التحديد، سيكون الثابت s مقسومًا على الجذر التربيعي لاثنين. ",
  "model": "nmt",
  "time_range": [
   430.63529411764705,
   434.8917894736842
  ]
 },
 {
  "input": "So when you're computing the integral, finding this area, all of this term here behaves like it was just some number, and you can factor it out. ",
  "translatedText": "لذلك عندما تقوم بحساب التكامل، وإيجاد هذه المنطقة، كل هذا المصطلح هنا يتصرف وكأنه مجرد رقم ما، ويمكنك تحليله. ",
  "model": "nmt",
  "time_range": [
   434.8917894736842,
   443.60842105263157
  ]
 },
 {
  "input": "This is the important point. ",
  "translatedText": "هذه هي النقطة المهمة. ",
  "model": "nmt",
  "time_range": [
   443.60842105263157,
   445.2430769230769
  ]
 },
 {
  "input": "All of the stuff that's involving s is now entirely separate from the integrated variable. ",
  "translatedText": "جميع الأشياء التي تتضمن s أصبحت الآن منفصلة تمامًا عن المتغير المتكامل. ",
  "model": "nmt",
  "time_range": [
   445.2430769230769,
   450.205
  ]
 },
 {
  "input": "This remaining integral is a little bit tricky. ",
  "translatedText": "هذا التكامل المتبقي صعب بعض الشيء. ",
  "model": "nmt",
  "time_range": [
   450.205,
   452.685
  ]
 },
 {
  "input": "I did a whole video on it, it's actually quite famous. ",
  "translatedText": "لقد قمت بعمل فيديو كامل عنها، وهي في الواقع مشهورة جدًا. ",
  "model": "nmt",
  "time_range": [
   452.685,
   455.4004210526316
  ]
 },
 {
  "input": "But you almost don't really care. ",
  "translatedText": "لكنك تقريبًا لا تهتم حقًا. ",
  "model": "nmt",
  "time_range": [
   455.4004210526316,
   457.0037894736842
  ]
 },
 {
  "input": "The point is that it's just some number. ",
  "translatedText": "النقطة المهمة هي أنه مجرد رقم. ",
  "model": "nmt",
  "time_range": [
   457.0037894736842,
   458.96851063829786
  ]
 },
 {
  "input": "That number happens to be the square root of pi, but what really matters is that it's something with no dependence on s. ",
  "translatedText": "يصادف أن هذا الرقم هو الجذر التربيعي لـ pi، لكن ما يهم حقًا هو أنه شيء لا يعتمد على s. ",
  "model": "nmt",
  "time_range": [
   458.96851063829786,
   465.6589473684211
  ]
 },
 {
  "input": "And essentially, this is our answer. ",
  "translatedText": "وهذه هي الإجابة في الأساس. ",
  "model": "nmt",
  "time_range": [
   465.6589473684211,
   468.0892631578947
  ]
 },
 {
  "input": "We were looking for an expression for the area of these slices as a function of s, and now we have it. ",
  "translatedText": "كنا نبحث عن تعبير لمساحة هذه الشرائح كدالة لـ s، والآن حصلنا عليه. ",
  "model": "nmt",
  "time_range": [
   468.0892631578947,
   474.02553191489363
  ]
 },
 {
  "input": "It looks like e to the negative s squared divided by two, scaled by some constant. ",
  "translatedText": "يبدو الأمر مثل e بالنسبة إلى السالب s تربيع مقسومًا على اثنين، ومقاسًا ببعض الثوابت. ",
  "model": "nmt",
  "time_range": [
   474.02553191489363,
   479.0752941176471
  ]
 },
 {
  "input": "In other words, it's also a bell curve, another Gaussian, just stretched out a little bit because of this two in the exponent. ",
  "translatedText": "بمعنى آخر، إنه أيضًا منحنى جرس، منحنى غاوسي آخر، تم تمديده قليلاً بسبب هذين الاثنين في الأس. ",
  "model": "nmt",
  "time_range": [
   479.0752941176471,
   485.68
  ]
 },
 {
  "input": "As I said earlier, the convolution evaluated at s is not quite this area. ",
  "translatedText": "كما قلت سابقًا، فإن الالتواء الذي تم تقييمه عند s ليس في هذه المنطقة تمامًا. ",
  "model": "nmt",
  "time_range": [
   485.68,
   490.7142268041237
  ]
 },
 {
  "input": "Technically, it's this area divided by the square root of two. ",
  "translatedText": "من الناحية الفنية، هذه المنطقة مقسومة على الجذر التربيعي لاثنين. ",
  "model": "nmt",
  "time_range": [
   490.7142268041237,
   494.032
  ]
 },
 {
  "input": "We talked about it in the last video, but it doesn't really matter because it just gets baked into the constant. ",
  "translatedText": "لقد تحدثنا عن ذلك في الفيديو الأخير، لكن هذا لا يهم حقًا لأنه أصبح جزءًا من الثابت. ",
  "model": "nmt",
  "time_range": [
   494.032,
   499.5692307692308
  ]
 },
 {
  "input": "What really matters is the conclusion that a convolution between two Gaussians is itself another Gaussian. ",
  "translatedText": "ما يهم حقًا هو الاستنتاج بأن الالتواء بين اثنين من الجاوسيين هو في حد ذاته جاوسي آخر. ",
  "model": "nmt",
  "time_range": [
   499.5692307692308,
   506.73
  ]
 },
 {
  "input": "If you were to go back and reintroduce all of the constants for a normal distribution with a mean zero and an arbitrary standard deviation sigma, essentially identical reasoning will lead to the same square root of two factor that shows up in the exponent and out front, and it leads to the conclusion that the convolution between two such normal distributions is another normal distribution with a standard deviation square root of two times sigma. ",
  "translatedText": "إذا كنت تريد العودة وإعادة تقديم جميع الثوابت للتوزيع الطبيعي بمتوسط صفر وانحراف معياري عشوائي سيجما، فإن المنطق المتطابق بشكل أساسي سيؤدي إلى نفس الجذر التربيعي لعاملين الذي يظهر في الأس وفي الخارج، ويؤدي إلى استنتاج مفاده أن الالتواء بين توزيعين طبيعيين من هذا القبيل هو توزيع طبيعي آخر مع جذر تربيعي للانحراف المعياري يبلغ مرتين سيجما. ",
  "model": "nmt",
  "time_range": [
   506.73,
   530.23
  ]
 },
 {
  "input": "If you haven't computed a lot of convolutions before, it's worth emphasizing this is a very special result. ",
  "translatedText": "إذا لم تكن قد قمت بحساب الكثير من التلافيفات من قبل، فمن الجدير التأكيد على أن هذه نتيجة خاصة جدًا. ",
  "model": "nmt",
  "time_range": [
   530.23,
   536.0057731958763
  ]
 },
 {
  "input": "Almost always you end up with a completely different kind of function, but here there's a sort of stability to the process. ",
  "translatedText": "غالبًا ما ينتهي بك الأمر إلى نوع مختلف تمامًا من الوظائف، ولكن هنا يوجد نوع من الاستقرار في العملية. ",
  "model": "nmt",
  "time_range": [
   536.0057731958763,
   543.0498969072165
  ]
 },
 {
  "input": "Also, for those of you who enjoy exercises, I'll leave one up on the screen for how you would handle the case of two different standard deviations. ",
  "translatedText": "أيضًا، بالنسبة لأولئك منكم الذين يستمتعون بالتمارين، سأترك واحدًا على الشاشة لكيفية التعامل مع حالة انحرافين معياريين مختلفين. ",
  "model": "nmt",
  "time_range": [
   543.0498969072165,
   549.8263829787234
  ]
 },
 {
  "input": "Still, some of you might be raising your hands and saying, what's the big deal? ",
  "translatedText": "ومع ذلك، قد يرفع البعض منكم أيديكم ويقول، ما هي المشكلة الكبيرة؟ ",
  "model": "nmt",
  "time_range": [
   549.8263829787234,
   554.0098969072164
  ]
 },
 {
  "input": "I mean, when you first heard the question, what do you get when you add two normally distributed random variables, you probably even guessed that the answer should be another normally distributed variable. ",
  "translatedText": "أعني، عندما سمعت السؤال لأول مرة، ما الذي ستحصل عليه عند إضافة متغيرين عشوائيين موزعين بشكل طبيعي، ربما خمنت أن الإجابة يجب أن تكون متغيرًا آخر موزعًا بشكل طبيعي. ",
  "model": "nmt",
  "time_range": [
   554.0098969072164,
   564.3733333333333
  ]
 },
 {
  "input": "After all, what else is it going to be? ",
  "translatedText": "بعد كل شيء، ماذا سيكون؟ ",
  "model": "nmt",
  "time_range": [
   564.3733333333333,
   566.5066666666667
  ]
 },
 {
  "input": "Normal distributions are supposedly quite common, so why not? ",
  "translatedText": "من المفترض أن تكون التوزيعات الطبيعية شائعة جدًا، فلماذا لا؟ ",
  "model": "nmt",
  "time_range": [
   566.5066666666667,
   569.7014432989691
  ]
 },
 {
  "input": "You could even say that this should follow from the central limit theorem, but that would have it all backwards. ",
  "translatedText": "يمكنك حتى القول إن هذا يجب أن ينبع من نظرية الحد المركزي، لكن هذا سيجعل الأمر كله معكوسًا. ",
  "model": "nmt",
  "time_range": [
   569.7014432989691,
   575.8166292134831
  ]
 },
 {
  "input": "First of all, the supposed ubiquity of normal distributions is often a little exaggerated, but to the extent that they do come up, it is because of the central limit theorem, but it would be cheating to say the central limit theorem implies this result because this computation we just did is the reason that the function at the heart of the central limit theorem is a Gaussian in the first place and not some other function. ",
  "translatedText": "بادئ ذي بدء، غالبًا ما يكون التواجد المفترض للتوزيعات الطبيعية في كل مكان مبالغًا فيه بعض الشيء، ولكن إلى الحد الذي تظهر فيه، يكون ذلك بسبب نظرية الحد المركزي، ولكن سيكون من الغش القول بأن نظرية الحد المركزي تتضمن هذه النتيجة لأن هذه العملية الحسابية التي قمنا بها للتو هي السبب في أن الدالة الموجودة في قلب نظرية الحد المركزي هي دالة غاوسية في المقام الأول وليست دالة أخرى. ",
  "model": "nmt",
  "time_range": [
   575.8166292134831,
   597.2338144329897
  ]
 },
 {
  "input": "We've talked all about the central limit theorem before, but essentially it says if you repeatedly add copies of a random variable to itself, which mathematically looks like repeatedly computing convolutions against a given distribution, then after appropriate shifting and rescaling, the tendency is always to approach a normal distribution. ",
  "translatedText": "لقد تحدثنا جميعًا عن نظرية الحد المركزي من قبل، ولكنها تقول بشكل أساسي إذا قمت بإضافة نسخ من متغير عشوائي إلى نفسه بشكل متكرر، والذي يبدو رياضيًا وكأنه يحسب بشكل متكرر التلافيفات مقابل توزيع معين، فبعد التحويل وإعادة القياس المناسبين، يكون الاتجاه دائما للاقتراب من التوزيع الطبيعي. ",
  "model": "nmt",
  "time_range": [
   597.2338144329897,
   616.3144554455446
  ]
 },
 {
  "input": "Technically there's a small assumption the distribution you start with can't have infinite variance, but it's a relatively soft assumption. ",
  "translatedText": "من الناحية الفنية، هناك افتراض صغير بأن التوزيع الذي تبدأ به لا يمكن أن يكون له تباين لا نهائي، ولكنه افتراض بسيط نسبيًا. ",
  "model": "nmt",
  "time_range": [
   616.3144554455446,
   623.4138613861386
  ]
 },
 {
  "input": "The magic is that for a huge category of initial distributions, this process of adding a whole bunch of random variables drawn from that distribution always tends towards this one universal shape, a Gaussian. ",
  "translatedText": "السحر هو أنه بالنسبة لفئة كبيرة من التوزيعات الأولية، فإن عملية إضافة مجموعة كاملة من المتغيرات العشوائية المستمدة من هذا التوزيع تميل دائمًا نحو هذا الشكل العالمي الوحيد، وهو الشكل الغوسي. ",
  "model": "nmt",
  "time_range": [
   623.4138613861386,
   635.0658823529412
  ]
 },
 {
  "input": "One common approach to proving this theorem involves two separate steps. ",
  "translatedText": "أحد الأساليب الشائعة لإثبات هذه النظرية يتضمن خطوتين منفصلتين. ",
  "model": "nmt",
  "time_range": [
   635.0658823529412,
   639.36
  ]
 },
 {
  "input": "The first step is to show that for all the different finite variance distributions you might start with, there exists a single universal shape that this process of repeated convolutions tends towards. ",
  "translatedText": "الخطوة الأولى هي إظهار أنه بالنسبة لجميع توزيعات التباين المحدودة المختلفة التي قد تبدأ بها، يوجد شكل عالمي واحد تميل إليه عملية التلافيف المتكررة. ",
  "model": "nmt",
  "time_range": [
   639.36,
   649.738901098901
  ]
 },
 {
  "input": "This step is actually pretty technical, it goes a little beyond what I want to talk about here. ",
  "translatedText": "هذه الخطوة هي في الواقع تقنية جدًا، وهي تتجاوز قليلاً ما أريد التحدث عنه هنا. ",
  "model": "nmt",
  "time_range": [
   649.738901098901,
   654.2269387755101
  ]
 },
 {
  "input": "You often use these objects called moment generating functions that gives you a very abstract argument that there must be some universal shape, but it doesn't make any claim about what that particular shape is, just that everything in this big family is tending towards a single point in the space of distributions. ",
  "translatedText": "غالبًا ما تستخدم هذه الكائنات التي تسمى وظائف توليد اللحظة والتي تمنحك حجة مجردة للغاية مفادها أنه يجب أن يكون هناك شكل عالمي ما، ولكنها لا تقدم أي ادعاء حول ماهية هذا الشكل المحدد، فقط أن كل شيء في هذه العائلة الكبيرة يميل نحو نقطة واحدة في فضاء التوزيعات ",
  "model": "nmt",
  "time_range": [
   654.2269387755101,
   670.0566666666666
  ]
 },
 {
  "input": "So then step number two is what we just showed in this video, prove that the convolution of two Gaussians gives another Gaussian. ",
  "translatedText": "إذن الخطوة الثانية هي ما أظهرناه للتو في هذا الفيديو، إثبات أن التواء اثنين من الجاوسيين يعطي جاوسيًا آخر. ",
  "model": "nmt",
  "time_range": [
   670.0566666666666,
   677.5066666666668
  ]
 },
 {
  "input": "What that means is that as you apply this process of repeated convolutions, a Gaussian doesn't change, it's a fixed point. ",
  "translatedText": "ما يعنيه ذلك هو أنه عند تطبيق هذه العملية من التلافيف المتكررة، لا يتغير الغاوسي، إنها نقطة ثابتة. ",
  "model": "nmt",
  "time_range": [
   677.5066666666668,
   684.0858333333334
  ]
 },
 {
  "input": "So the only thing it can approach is itself, and since it's one member in this big family of distributions, all of which must be tending towards a single universal shape, it must be that universal shape. ",
  "translatedText": "لذا فإن الشيء الوحيد الذي يمكن أن يقترب منه هو نفسه، وبما أنه عضو واحد في هذه العائلة الكبيرة من التوزيعات، والتي يجب أن تتجه جميعها نحو شكل عالمي واحد، فيجب أن يكون ذلك الشكل العالمي. ",
  "model": "nmt",
  "time_range": [
   684.0858333333334,
   694.8199999999999
  ]
 },
 {
  "input": "I mentioned at the start how this calculation, step two, is something that you can do directly, just symbolically with the definitions, but one of the reasons I'm so charmed by a geometric argument that leverages the rotational symmetry of this graph is that it directly connects to a few things that we've talked about on this channel before. ",
  "translatedText": "لقد ذكرت في البداية كيف أن هذه العملية الحسابية، الخطوة الثانية، هي شيء يمكنك القيام به بشكل مباشر، فقط رمزيًا باستخدام التعريفات، ولكن أحد الأسباب التي تجعلني مفتونًا جدًا بالحجة الهندسية التي تعزز التماثل الدوراني لهذا الرسم البياني هو أنه إنه يتصل مباشرة ببعض الأشياء التي تحدثنا عنها على هذه القناة من قبل. ",
  "model": "nmt",
  "time_range": [
   694.8199999999999,
   712.6778947368422
  ]
 },
 {
  "input": "For example, the Herschel-Maxwell derivation of a Gaussian, which essentially says that you can view this rotational symmetry as the defining feature of the distribution, that it locks you into this e to the negative x squared form, and also as an added bonus it connects to the classic proof for why pi shows up in the formula, meaning we now have a direct line between the presence and mystery of that pi and the central limit theorem. ",
  "translatedText": "على سبيل المثال، اشتقاق هيرشل-ماكسويل من غاوسي، والذي ينص بشكل أساسي على أنه يمكنك عرض هذا التناظر الدوراني باعتباره السمة المميزة للتوزيع، وأنه يحبسك في هذا e إلى النموذج السالب x المربع، وأيضًا كمكافأة إضافية إنه يتصل بالبرهان الكلاسيكي لسبب ظهور pi في الصيغة، مما يعني أن لدينا الآن خطًا مباشرًا بين وجود وغموض pi ونظرية الحد المركزي. ",
  "model": "nmt",
  "time_range": [
   712.6778947368422,
   736.3957894736841
  ]
 },
 {
  "input": "Also on a recent Patreon post, the channel supporter Daksha Vaid-Quinter brought my attention to a completely different approach I hadn't seen before, which leverages the use of entropy, and again for the theoretically curious among you I'll leave some links in the description. ",
  "translatedText": "أيضًا في منشور حديث على Patreon، لفت مؤيد القناة Daksha Vaid-Quinter انتباهي إلى نهج مختلف تمامًا لم أره من قبل، والذي يعزز استخدام الإنتروبيا، ومرة أخرى لأولئك الذين لديهم فضول نظريًا بينكم، سأترك بعض الروابط في الوصف. ",
  "model": "nmt",
  "time_range": [
   736.3957894736841,
   750.1834343434343
  ]
 },
 {
  "input": "By the way, if you want to stay up to date with new videos and also any other projects that I put out there like the Summer of Math Exposition, there is a mailing list. ",
  "translatedText": "بالمناسبة، إذا كنت تريد البقاء على اطلاع بمقاطع الفيديو الجديدة وأيضًا أي مشاريع أخرى أطرحها هناك مثل معرض Summer of Math، فهناك قائمة بريدية. ",
  "model": "nmt",
  "time_range": [
   750.1834343434343,
   758.56
  ]
 },
 {
  "input": "It's relatively new and I'm pretty sparing about only posting what I think people will enjoy. ",
  "translatedText": "إنها جديدة نسبيًا وأنا لا أهتم إلا بنشر ما أعتقد أن الناس سيستمتعون به. ",
  "model": "nmt",
  "time_range": [
   758.56,
   763.12
  ]
 },
 {
  "input": "Usually I try not to be too promotional at the end of videos these days, but if you are interested in following the work that I do, this is probably one of the most enduring ways to do so. ",
  "translatedText": "عادةً ما أحاول ألا أكون ترويجيًا جدًا في نهاية مقاطع الفيديو هذه الأيام، ولكن إذا كنت مهتمًا بمتابعة العمل الذي أقوم به، فمن المحتمل أن تكون هذه إحدى الطرق الأكثر ديمومة للقيام بذلك. ",
  "model": "nmt",
  "time_range": [
   763.12,
   772.4
  ]
 }
]