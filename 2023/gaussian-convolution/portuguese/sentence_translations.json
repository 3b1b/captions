[
 {
  "input": "The basic function underlying a normal distribution, aka a Gaussian, is e to the negative x squared.",
  "model": "nmt",
  "translatedText": "A função básica subjacente a uma distribuição normal, também conhecida como Gaussiana, é e elevado a x negativo ao quadrado.",
  "time_range": [
   0.0,
   6.12
  ]
 },
 {
  "input": "But you might wonder, why this function?",
  "model": "nmt",
  "translatedText": "Mas você pode se perguntar: por que essa função?",
  "time_range": [
   6.64,
   8.34
  ]
 },
 {
  "input": "Of all the expressions we could dream up that give you some symmetric smooth graph with mass concentrated towards the middle, why is it that the theory of probability seems to have a special place in its heart for this particular expression?",
  "model": "nmt",
  "translatedText": "De todas as expressões que poderíamos imaginar que fornecem algum gráfico simétrico e suave com massa concentrada no meio, por que é que a teoria da probabilidade parece ter um lugar especial no seu coração para esta expressão específica?",
  "time_range": [
   8.72,
   20.44
  ]
 },
 {
  "input": "For the last many videos I've been hinting at an answer to this question, and here we'll finally arrive at something like a satisfying answer.",
  "model": "nmt",
  "translatedText": "Nos últimos vídeos tenho sugerido uma resposta para essa pergunta, e aqui finalmente chegaremos a algo parecido com uma resposta satisfatória.",
  "time_range": [
   21.38,
   27.68
  ]
 },
 {
  "input": "As a quick refresher on where we are, a couple videos ago we talked about the central limit theorem, which describes how as you add multiple copies of a random variable, for example rolling a weighted die many different times or letting a ball bounce off of a peg repeatedly, then the distribution describing that sum tends to look approximately like a normal distribution.",
  "model": "nmt",
  "translatedText": "Para relembrar rapidamente onde estamos, alguns vídeos atrás falamos sobre o teorema do limite central, que descreve como você adiciona múltiplas cópias de uma variável aleatória, por exemplo, lançando um dado ponderado muitas vezes diferentes ou deixando uma bola quicar no uma indexação repetidamente, então a distribuição que descreve essa soma tende a se parecer aproximadamente com uma distribuição normal.",
  "time_range": [
   27.68,
   47.72
  ]
 },
 {
  "input": "What the central limit theorem says is as you make that sum bigger and bigger, under appropriate conditions, that approximation to a normal becomes better and better.",
  "model": "nmt",
  "translatedText": "O que o teorema do limite central diz é que à medida que aumentamos essa soma, sob condições apropriadas, essa aproximação a um normal torna-se cada vez melhor.",
  "time_range": [
   48.44,
   56.22
  ]
 },
 {
  "input": "But I never explained why this theorem is actually true, we only talked about what it's claiming.",
  "model": "nmt",
  "translatedText": "Mas nunca expliquei porque é que este teorema é realmente verdadeiro, apenas falámos sobre o que ele afirma.",
  "time_range": [
   56.94,
   61.98
  ]
 },
 {
  "input": "In the last video we started talking about the math involved in adding two random variables.",
  "model": "nmt",
  "translatedText": "No último vídeo começamos a falar sobre a matemática envolvida na adição de duas variáveis aleatórias.",
  "time_range": [
   63.08,
   67.88
  ]
 },
 {
  "input": "If you have two random variables, each following some distribution, then to find the distribution describing the sum of those variables, you compute something known as a convolution between the two original functions.",
  "model": "nmt",
  "translatedText": "Se você tiver duas variáveis aleatórias, cada uma seguindo alguma distribuição, então, para encontrar a distribuição que descreve a soma dessas variáveis, você calcula algo conhecido como convolução entre as duas funções originais.",
  "time_range": [
   68.26,
   79.7
  ]
 },
 {
  "input": "And we spent a lot of time building up two distinct ways to visualize what this convolution operation really is.",
  "model": "nmt",
  "translatedText": "E passamos muito tempo construindo duas maneiras distintas de visualizar o que realmente é essa operação de convolução.",
  "time_range": [
   79.88,
   85.94
  ]
 },
 {
  "input": "Today our basic job is to work through a particular example, which is to ask what happens when you add two normally distributed random variables, which as you know by now is the same as asking what do you get if you compute a convolution between two Gaussian functions.",
  "model": "nmt",
  "translatedText": "Hoje, nosso trabalho básico é trabalhar com um exemplo específico, que é perguntar o que acontece quando você adiciona duas variáveis aleatórias normalmente distribuídas, o que, como você já sabe, é o mesmo que perguntar o que você obtém se calcular uma convolução entre duas variáveis gaussianas. funções.",
  "time_range": [
   85.94,
   101.78
  ]
 },
 {
  "input": "I'd like to share an especially pleasing visual way that you can think about this calculation, which hopefully offers some sense of what makes the e to the negative x squared function special in the first place.",
  "model": "nmt",
  "translatedText": "Eu gostaria de compartilhar uma maneira visual especialmente agradável de pensar sobre esse cálculo, que esperançosamente oferece alguma noção do que torna o e elevado à função x negativo ao quadrado especial em primeiro lugar.",
  "time_range": [
   102.52,
   112.36
  ]
 },
 {
  "input": "After we walk through it, we'll talk about how this calculation is one of the steps involved in proving the central limit theorem.",
  "model": "nmt",
  "translatedText": "Depois de percorrermos isso, falaremos sobre como esse cálculo é uma das etapas envolvidas na prova do teorema do limite central.",
  "time_range": [
   112.36,
   118.24
  ]
 },
 {
  "input": "It's the step that answers the question of why a Gaussian and not something else is the central limit.",
  "model": "nmt",
  "translatedText": "É o passo que responde à questão de por que uma Gaussiana e não outra coisa é o limite central.",
  "time_range": [
   118.32,
   123.56
  ]
 },
 {
  "input": "But first, let's dive in.",
  "model": "nmt",
  "translatedText": "Mas primeiro, vamos mergulhar.",
  "time_range": [
   124.2,
   125.84
  ]
 },
 {
  "input": "The full formula for a Gaussian is more complicated than just e to the negative x squared.",
  "model": "nmt",
  "translatedText": "A fórmula completa para um Gaussiano é mais complicada do que apenas e elevado a x negativo ao quadrado.",
  "time_range": [
   129.78,
   134.44
  ]
 },
 {
  "input": "The exponent is typically written as negative one half times x divided by sigma squared, where sigma describes the spread of the distribution, specifically the standard deviation.",
  "model": "nmt",
  "translatedText": "O expoente é normalmente escrito como menos um meio vezes x dividido por sigma ao quadrado, onde sigma descreve a propagação da distribuição, especificamente o desvio padrão.",
  "time_range": [
   134.82,
   144.2
  ]
 },
 {
  "input": "All of this needs to be multiplied by a fraction on the front, which is there to make sure that the area under the curve is one, making it a valid probability distribution.",
  "model": "nmt",
  "translatedText": "Tudo isso precisa ser multiplicado por uma fração na frente, que existe para garantir que a área sob a curva seja um, tornando-a uma distribuição de probabilidade válida.",
  "time_range": [
   144.68,
   153.42
  ]
 },
 {
  "input": "And if you want to consider distributions that aren't necessarily centered at zero, you would also throw another parameter, mu, into the exponent like this.",
  "model": "nmt",
  "translatedText": "E se você quiser considerar distribuições que não estão necessariamente centradas em zero, você também colocaria outro parâmetro, mu, no expoente como este.",
  "time_range": [
   154.02,
   161.18
  ]
 },
 {
  "input": "Although for everything we'll be doing here, we just consider centered distributions.",
  "model": "nmt",
  "translatedText": "Embora para tudo o que faremos aqui, consideremos apenas distribuições centradas.",
  "time_range": [
   161.54,
   165.12
  ]
 },
 {
  "input": "Now if you look at our central goal for today, which is to compute a convolution between two Gaussian functions, the direct way to do this would be to take the definition of a convolution, this integral expression we built up last video, and then to plug in for each one of the functions involved the formula for a Gaussian.",
  "model": "nmt",
  "translatedText": "Agora, se você olhar para o nosso objetivo central de hoje, que é calcular uma convolução entre duas funções gaussianas, a maneira direta de fazer isso seria pegar a definição de uma convolução, essa expressão integral que construímos no último vídeo, e depois insira para cada uma das funções envolvidas a fórmula de uma Gaussiana.",
  "time_range": [
   165.79999999999998,
   183.76
  ]
 },
 {
  "input": "It's kind of a lot of symbols when you throw it all together, but more than anything, working this out is an exercise in completing the square.",
  "model": "nmt",
  "translatedText": "São muitos símbolos quando você junta tudo, mas mais do que tudo, resolver isso é um exercício para completar o quadrado.",
  "time_range": [
   184.22,
   190.08
  ]
 },
 {
  "input": "And there's nothing wrong with that.",
  "model": "nmt",
  "translatedText": "E não há nada de errado com isso.",
  "time_range": [
   190.56,
   191.58
  ]
 },
 {
  "input": "That will get you the answer that you want.",
  "model": "nmt",
  "translatedText": "Isso lhe dará a resposta que deseja.",
  "time_range": [
   191.72,
   193.22
  ]
 },
 {
  "input": "But of course, you know me, I'm a sucker for visual intuition, and in this case, there's another way to think about it that I haven't seen written about before, that offers a very nice connection to other aspects of this distribution, like the presence of pi and certain ways to derive where it comes from.",
  "model": "nmt",
  "translatedText": "Mas é claro, você me conhece, adoro intuição visual e, neste caso, há outra maneira de pensar sobre isso sobre a qual nunca vi escrito antes, que oferece uma conexão muito boa com outros aspectos deste distribuição, como a presença de pi e certas maneiras de derivar de onde ele vem.",
  "time_range": [
   193.76,
   207.86
  ]
 },
 {
  "input": "And the way I'd like to do this is by first peeling away all of the constants associated with the actual distribution, and just showing the computation for the simplified form, e to the negative x squared.",
  "model": "nmt",
  "translatedText": "E a maneira que eu gostaria de fazer isso é primeiro retirando todas as constantes associadas à distribuição real e apenas mostrando o cálculo para a forma simplificada, e elevado a menos x ao quadrado.",
  "time_range": [
   208.2,
   217.96
  ]
 },
 {
  "input": "The essence of what we want to compute is what the convolution between two copies of this function looks like.",
  "model": "nmt",
  "translatedText": "A essência do que queremos calcular é a aparência da convolução entre duas cópias desta função.",
  "time_range": [
   217.96,
   224.08
  ]
 },
 {
  "input": "If you'll remember, in the last video we had two different ways to visualize convolutions, and the one we'll be using here is the second one, involving diagonal slices.",
  "model": "nmt",
  "translatedText": "Se você se lembra, no último vídeo tivemos duas formas diferentes de visualizar convoluções, e a que usaremos aqui é a segunda, envolvendo fatias diagonais.",
  "time_range": [
   224.46,
   232.92
  ]
 },
 {
  "input": "And as a quick reminder of the way that worked, if you have two different distributions that are described by two different functions, f and g, then every possible pair of values that you might get when you sample from these two distributions can be thought of as individual points on the xy-plane.",
  "model": "nmt",
  "translatedText": "E como um rápido lembrete de como isso funcionou, se você tiver duas distribuições diferentes que são descritas por duas funções diferentes, f e g, então cada par possível de valores que você pode obter ao amostrar essas duas distribuições pode ser pensado em como pontos individuais no plano xy.",
  "time_range": [
   233.28,
   249.56
  ]
 },
 {
  "input": "And the probability density of landing on one such point, assuming independence, looks like f of x times g of y.",
  "model": "nmt",
  "translatedText": "E a densidade de probabilidade de chegar a um desses pontos, assumindo independência, parece f de x vezes g de y.",
  "time_range": [
   250.36,
   257.52
  ]
 },
 {
  "input": "So what we do is we look at a graph of that expression as a two-variable function of x and y, which is a way of showing the distribution of all possible outcomes when we sample from the two different variables.",
  "model": "nmt",
  "translatedText": "Então, o que fazemos é olhar para um gráfico dessa expressão como uma função de duas variáveis de x e y, que é uma forma de mostrar a distribuição de todos os resultados possíveis quando amostramos as duas variáveis diferentes.",
  "time_range": [
   258.0,
   269.62
  ]
 },
 {
  "input": "To interpret the convolution of f and g evaluated on some input s, which is a way of saying how likely are you to get a pair of samples that adds up to this sum s, what you do is you look at a slice of this graph over the line x plus y equals s, and you consider the area under that slice.",
  "model": "nmt",
  "translatedText": "Para interpretar a convolução de f e g avaliada em algumas entradas s, que é uma forma de dizer qual a probabilidade de você obter um par de amostras que somam essa soma s, o que você faz é olhar para uma fatia deste gráfico sobre a linha x mais y é igual a s, e você considera a área sob essa fatia.",
  "time_range": [
   270.56,
   289.3
  ]
 },
 {
  "input": "This area is almost, but not quite, the value of the convolution at s.",
  "model": "nmt",
  "translatedText": "Esta área é quase, mas não exatamente, o valor da convolução em s.",
  "time_range": [
   291.1,
   296.32
  ]
 },
 {
  "input": "For a mildly technical reason, you need to divide by the square root of two.",
  "model": "nmt",
  "translatedText": "Por uma razão levemente técnica, você precisa dividir pela raiz quadrada de dois.",
  "time_range": [
   296.8,
   300.16
  ]
 },
 {
  "input": "Still, this area is the key feature to focus on.",
  "model": "nmt",
  "translatedText": "Ainda assim, esta área é o principal recurso a ser focado.",
  "time_range": [
   300.84,
   303.44
  ]
 },
 {
  "input": "You can think of it as a way to combine together all the probability densities for all of the outcomes corresponding to a given sum.",
  "model": "nmt",
  "translatedText": "Você pode pensar nisso como uma forma de combinar todas as densidades de probabilidade para todos os resultados correspondentes a uma determinada soma.",
  "time_range": [
   303.44,
   311.04
  ]
 },
 {
  "input": "In the specific case where these two functions look like e to the negative x squared and e to the negative y squared, the resulting 3D graph has a really nice property that you can exploit.",
  "model": "nmt",
  "translatedText": "No caso específico em que essas duas funções se parecem com e elevado a x negativo ao quadrado e e elevado a y negativo ao quadrado, o gráfico 3D resultante tem uma propriedade muito boa que você pode explorar.",
  "time_range": [
   313.3,
   323.5
  ]
 },
 {
  "input": "It's rotationally symmetric.",
  "model": "nmt",
  "translatedText": "É rotacionalmente simétrico.",
  "time_range": [
   323.72,
   325.68
  ]
 },
 {
  "input": "You can see this by combining the terms and noticing that it's entirely a function of x squared plus y squared, and this term describes the square of the distance between any point on the xy plane and the origin.",
  "model": "nmt",
  "translatedText": "Você pode ver isso combinando os termos e percebendo que é inteiramente uma função de x ao quadrado mais y ao quadrado, e esse termo descreve o quadrado da distância entre qualquer ponto no plano xy e a origem.",
  "time_range": [
   326.88,
   338.46
  ]
 },
 {
  "input": "So in other words, the expression is purely a function of the distance from the origin.",
  "model": "nmt",
  "translatedText": "Por outras palavras, a expressão é puramente uma função da distância à origem.",
  "time_range": [
   339.2,
   343.16
  ]
 },
 {
  "input": "And by the way, this would not be true for any other distribution.",
  "model": "nmt",
  "translatedText": "E, a propósito, isso não seria verdade para nenhuma outra distribuição.",
  "time_range": [
   344.56,
   347.92
  ]
 },
 {
  "input": "It's a property that uniquely characterizes bell curves.",
  "model": "nmt",
  "translatedText": "É uma propriedade que caracteriza exclusivamente as curvas em sino.",
  "time_range": [
   348.1,
   351.28
  ]
 },
 {
  "input": "So for most other pairs of functions, these diagonal slices will be some complicated shape that's hard to think about, and honestly calculating the area would just amount to computing the original integral that defines a convolution in the first place.",
  "model": "nmt",
  "translatedText": "Portanto, para a maioria dos outros pares de funções, essas fatias diagonais terão uma forma complicada que é difícil de imaginar, e calcular honestamente a área equivaleria apenas a calcular a integral original que define uma convolução em primeiro lugar.",
  "time_range": [
   353.16,
   365.54
  ]
 },
 {
  "input": "So in most cases, the visual intuition doesn't really buy you anything.",
  "model": "nmt",
  "translatedText": "Portanto, na maioria dos casos, a intuição visual não traz nada para você.",
  "time_range": [
   365.94,
   369.36
  ]
 },
 {
  "input": "But in the case of bell curves, you can leverage that rotational symmetry.",
  "model": "nmt",
  "translatedText": "Mas no caso de curvas em forma de sino, você pode aproveitar essa simetria rotacional.",
  "time_range": [
   370.36,
   373.92
  ]
 },
 {
  "input": "Here, focus on one of these slices over the line x plus y equals s for some value of s.",
  "model": "nmt",
  "translatedText": "Aqui, concentre-se em uma dessas fatias sobre a linha x mais y igual a s para algum valor de s.",
  "time_range": [
   374.8,
   380.48
  ]
 },
 {
  "input": "And remember, the convolution that we're trying to compute is a function of s.",
  "model": "nmt",
  "translatedText": "E lembre-se, a convolução que estamos tentando calcular é uma função de s.",
  "time_range": [
   381.3,
   385.84
  ]
 },
 {
  "input": "The thing that you want is an expression of s that tells you the area under this slice.",
  "model": "nmt",
  "translatedText": "O que você deseja é uma expressão de s que indique a área sob esta fatia.",
  "time_range": [
   385.84,
   391.1
  ]
 },
 {
  "input": "Well, if you look at that line, it intersects the x-axis at s zero and the y-axis at zero s.",
  "model": "nmt",
  "translatedText": "Bem, se você olhar para essa reta, ela intercepta o eixo x em s zero e o eixo y em zero s.",
  "time_range": [
   391.7,
   397.9
  ]
 },
 {
  "input": "And a little bit of Pythagoras will show you that the straight line distance from the origin to this line is s divided by the square root of two.",
  "model": "nmt",
  "translatedText": "E um pouco de Pitágoras mostrará que a distância em linha reta da origem até esta reta é s dividido pela raiz quadrada de dois.",
  "time_range": [
   398.32,
   405.32
  ]
 },
 {
  "input": "Now, because of the symmetry, this slice is identical to one that you get rotating 45 degrees, where you'd find something parallel to the y-axis the same distance away from the origin.",
  "model": "nmt",
  "translatedText": "Agora, por causa da simetria, esta fatia é idêntica àquela que você gira 45 graus, onde você encontraria algo paralelo ao eixo y à mesma distância da origem.",
  "time_range": [
   405.86,
   416.36
  ]
 },
 {
  "input": "The key is that computing this other area of a slice parallel to the y-axis is much, much easier than slices in other directions, because it only involves taking an integral with respect to y.",
  "model": "nmt",
  "translatedText": "A chave é que calcular esta outra área de uma fatia paralela ao eixo y é muito, muito mais fácil do que fatias em outras direções, porque envolve apenas fazer uma integral em relação a y.",
  "time_range": [
   417.64,
   428.26
  ]
 },
 {
  "input": "The value of x on this slice is a constant.",
  "model": "nmt",
  "translatedText": "O valor de x nesta fatia é uma constante.",
  "time_range": [
   428.74,
   431.44
  ]
 },
 {
  "input": "Specifically, it would be the constant s divided by the square root of two.",
  "model": "nmt",
  "translatedText": "Especificamente, seria a constante s dividida pela raiz quadrada de dois.",
  "time_range": [
   431.62,
   434.76
  ]
 },
 {
  "input": "So when you're computing the integral, finding this area, all of this term here behaves like it was just some number, and you can factor it out.",
  "model": "nmt",
  "translatedText": "Então quando você está calculando a integral, encontrando essa área, todo esse termo aqui se comporta como se fosse apenas um número, e você pode fatorá-lo.",
  "time_range": [
   434.76,
   443.38
  ]
 },
 {
  "input": "This is the important point.",
  "model": "nmt",
  "translatedText": "Este é o ponto importante.",
  "time_range": [
   443.88,
   444.94
  ]
 },
 {
  "input": "All of the stuff that's involving s is now entirely separate from the integrated variable.",
  "model": "nmt",
  "translatedText": "Todas as coisas que envolvem s agora estão totalmente separadas da variável integrada.",
  "time_range": [
   445.28,
   450.2
  ]
 },
 {
  "input": "This remaining integral is a little bit tricky.",
  "model": "nmt",
  "translatedText": "Esta integral restante é um pouco complicada.",
  "time_range": [
   450.82,
   453.0
  ]
 },
 {
  "input": "I did a whole video on it, it's actually quite famous.",
  "model": "nmt",
  "translatedText": "Eu fiz um vídeo inteiro sobre isso, na verdade é bastante famoso.",
  "time_range": [
   453.08,
   455.2
  ]
 },
 {
  "input": "But you almost don't really care.",
  "model": "nmt",
  "translatedText": "Mas você quase não se importa.",
  "time_range": [
   455.5,
   456.9
  ]
 },
 {
  "input": "The point is that it's just some number.",
  "model": "nmt",
  "translatedText": "A questão é que é apenas um número.",
  "time_range": [
   457.24,
   459.0
  ]
 },
 {
  "input": "That number happens to be the square root of pi, but what really matters is that it's something with no dependence on s.",
  "model": "nmt",
  "translatedText": "Acontece que esse número é a raiz quadrada de pi, mas o que realmente importa é que é algo que não depende de s.",
  "time_range": [
   459.0,
   465.48
  ]
 },
 {
  "input": "And essentially, this is our answer.",
  "model": "nmt",
  "translatedText": "E essencialmente, esta é a nossa resposta.",
  "time_range": [
   466.88,
   468.48
  ]
 },
 {
  "input": "We were looking for an expression for the area of these slices as a function of s, and now we have it.",
  "model": "nmt",
  "translatedText": "Estávamos procurando uma expressão para a área dessas fatias em função de s, e agora a temos.",
  "time_range": [
   468.78,
   474.28
  ]
 },
 {
  "input": "It looks like e to the negative s squared divided by two, scaled by some constant.",
  "model": "nmt",
  "translatedText": "Parece e elevado ao quadrado negativo dividido por dois, dimensionado por alguma constante.",
  "time_range": [
   474.38,
   478.84
  ]
 },
 {
  "input": "In other words, it's also a bell curve, another Gaussian, just stretched out a little bit because of this two in the exponent.",
  "model": "nmt",
  "translatedText": "Em outras palavras, também é uma curva em forma de sino, outra Gaussiana, apenas esticada um pouco por causa deste dois no expoente.",
  "time_range": [
   479.3,
   485.62
  ]
 },
 {
  "input": "As I said earlier, the convolution evaluated at s is not quite this area.",
  "model": "nmt",
  "translatedText": "Como eu disse anteriormente, a convolução avaliada em s não é exatamente esta área.",
  "time_range": [
   485.62,
   490.86
  ]
 },
 {
  "input": "Technically, it's this area divided by the square root of two.",
  "model": "nmt",
  "translatedText": "Tecnicamente, é esta área dividida pela raiz quadrada de dois.",
  "time_range": [
   491.34,
   494.16
  ]
 },
 {
  "input": "We talked about it in the last video, but it doesn't really matter because it just gets baked into the constant.",
  "model": "nmt",
  "translatedText": "Falamos sobre isso no último vídeo, mas isso realmente não importa, porque está incluído na constante.",
  "time_range": [
   494.8,
   499.24
  ]
 },
 {
  "input": "What really matters is the conclusion that a convolution between two Gaussians is itself another Gaussian.",
  "model": "nmt",
  "translatedText": "O que realmente importa é a conclusão de que uma convolução entre duas gaussianas é ela mesma outra gaussiana.",
  "time_range": [
   499.68,
   505.68
  ]
 },
 {
  "input": "If you were to go back and reintroduce all of the constants for a normal distribution with a mean zero and an arbitrary standard deviation sigma, essentially identical reasoning will lead to the same square root of two factor that shows up in the exponent and out front, and it leads to the conclusion that the convolution between two such normal distributions is another normal distribution with a standard deviation square root of two times sigma.",
  "model": "nmt",
  "translatedText": "Se você voltar e reintroduzir todas as constantes para uma distribuição normal com média zero e um desvio padrão sigma arbitrário, um raciocínio essencialmente idêntico levará à mesma raiz quadrada de dois fatores que aparece no expoente e na frente, e leva à conclusão de que a convolução entre duas dessas distribuições normais é outra distribuição normal com um desvio padrão raiz quadrada de dois vezes sigma.",
  "time_range": [
   507.56,
   530.38
  ]
 },
 {
  "input": "If you haven't computed a lot of convolutions before, it's worth emphasizing this is a very special result.",
  "model": "nmt",
  "translatedText": "Se você nunca calculou muitas convoluções antes, vale a pena enfatizar que este é um resultado muito especial.",
  "time_range": [
   530.98,
   536.06
  ]
 },
 {
  "input": "Almost always you end up with a completely different kind of function, but here there's a sort of stability to the process.",
  "model": "nmt",
  "translatedText": "Quase sempre você acaba com um tipo de função completamente diferente, mas aqui há uma espécie de estabilidade no processo.",
  "time_range": [
   536.38,
   542.5
  ]
 },
 {
  "input": "Also, for those of you who enjoy exercises, I'll leave one up on the screen for how you would handle the case of two different standard deviations.",
  "model": "nmt",
  "translatedText": "Além disso, para aqueles que gostam de exercícios, deixarei um na tela sobre como você lidaria com o caso de dois desvios padrão diferentes.",
  "time_range": [
   543.26,
   549.44
  ]
 },
 {
  "input": "Still, some of you might be raising your hands and saying, what's the big deal?",
  "model": "nmt",
  "translatedText": "Ainda assim, alguns de vocês podem estar levantando a mão e dizendo: qual é o problema?",
  "time_range": [
   550.42,
   553.94
  ]
 },
 {
  "input": "I mean, when you first heard the question, what do you get when you add two normally distributed random variables, you probably even guessed that the answer should be another normally distributed variable.",
  "model": "nmt",
  "translatedText": "Quero dizer, quando você ouviu pela primeira vez a pergunta, o que você obtém quando adiciona duas variáveis aleatórias normalmente distribuídas, você provavelmente até adivinhou que a resposta deveria ser outra variável normalmente distribuída.",
  "time_range": [
   554.48,
   564.32
  ]
 },
 {
  "input": "After all, what else is it going to be?",
  "model": "nmt",
  "translatedText": "Afinal, o que mais será?",
  "time_range": [
   564.76,
   566.36
  ]
 },
 {
  "input": "Normal distributions are supposedly quite common, so why not?",
  "model": "nmt",
  "translatedText": "Distribuições normais são supostamente bastante comuns, então por que não?",
  "time_range": [
   566.86,
   570.24
  ]
 },
 {
  "input": "You could even say that this should follow from the central limit theorem, but that would have it all backwards.",
  "model": "nmt",
  "translatedText": "Você poderia até dizer que isso deveria decorrer do teorema do limite central, mas isso significaria tudo ao contrário.",
  "time_range": [
   570.24,
   575.48
  ]
 },
 {
  "input": "First of all, the supposed ubiquity of normal distributions is often a little exaggerated, but to the extent that they do come up, it is because of the central limit theorem, but it would be cheating to say the central limit theorem implies this result because this computation we just did is the reason that the function at the heart of the central limit theorem is a Gaussian in the first place and not some other function.",
  "model": "nmt",
  "translatedText": "Em primeiro lugar, a suposta onipresença das distribuições normais é muitas vezes um pouco exagerada, mas na medida em que elas surgem, é por causa do teorema do limite central, mas seria trapaça dizer que o teorema do limite central implica este resultado porque este cálculo que acabamos de fazer é a razão pela qual a função no cerne do teorema do limite central é uma gaussiana em primeiro lugar e não alguma outra função.",
  "time_range": [
   576.18,
   597.06
  ]
 },
 {
  "input": "We've talked all about the central limit theorem before, but essentially it says if you repeatedly add copies of a random variable to itself, which mathematically looks like repeatedly computing convolutions against a given distribution, then after appropriate shifting and rescaling, the tendency is always to approach a normal distribution.",
  "model": "nmt",
  "translatedText": "Já falamos tudo sobre o teorema do limite central antes, mas essencialmente ele diz que se você adicionar repetidamente cópias de uma variável aleatória a si mesma, o que matematicamente se parece com o cálculo repetido de convoluções em relação a uma determinada distribuição, então, após o deslocamento e o redimensionamento apropriados, a tendência é sempre se aproximando de uma distribuição normal.",
  "time_range": [
   597.06,
   616.5
  ]
 },
 {
  "input": "Technically there's a small assumption the distribution you start with can't have infinite variance, but it's a relatively soft assumption.",
  "model": "nmt",
  "translatedText": "Tecnicamente, há uma pequena suposição de que a distribuição com a qual você começa não pode ter variação infinita, mas é uma suposição relativamente suave.",
  "time_range": [
   616.98,
   623.22
  ]
 },
 {
  "input": "The magic is that for a huge category of initial distributions, this process of adding a whole bunch of random variables drawn from that distribution always tends towards this one universal shape, a Gaussian.",
  "model": "nmt",
  "translatedText": "A mágica é que, para uma enorme categoria de distribuições iniciais, esse processo de adicionar um monte de variáveis aleatórias extraídas dessa distribuição sempre tende para essa forma universal, uma Gaussiana.",
  "time_range": [
   623.22,
   635.1
  ]
 },
 {
  "input": "One common approach to proving this theorem involves two separate steps.",
  "model": "nmt",
  "translatedText": "Uma abordagem comum para provar este teorema envolve duas etapas separadas.",
  "time_range": [
   635.82,
   639.3
  ]
 },
 {
  "input": "The first step is to show that for all the different finite variance distributions you might start with, there exists a single universal shape that this process of repeated convolutions tends towards.",
  "model": "nmt",
  "translatedText": "O primeiro passo é mostrar que, para todas as diferentes distribuições de variância finita com as quais você pode começar, existe uma única forma universal para a qual tende esse processo de convoluções repetidas.",
  "time_range": [
   639.6,
   650.0
  ]
 },
 {
  "input": "This step is actually pretty technical, it goes a little beyond what I want to talk about here.",
  "model": "nmt",
  "translatedText": "Essa etapa na verdade é bem técnica, vai um pouco além do que quero falar aqui.",
  "time_range": [
   650.0,
   654.24
  ]
 },
 {
  "input": "You often use these objects called moment generating functions that gives you a very abstract argument that there must be some universal shape, but it doesn't make any claim about what that particular shape is, just that everything in this big family is tending towards a single point in the space of distributions.",
  "model": "nmt",
  "translatedText": "Você costuma usar esses objetos chamados funções geradoras de momento, que fornecem um argumento muito abstrato de que deve haver alguma forma universal, mas não faz nenhuma afirmação sobre qual é essa forma específica, apenas que tudo nesta grande família tende a uma único ponto no espaço de distribuições.",
  "time_range": [
   654.52,
   669.98
  ]
 },
 {
  "input": "So then step number two is what we just showed in this video, prove that the convolution of two Gaussians gives another Gaussian.",
  "model": "nmt",
  "translatedText": "Então o passo número dois é o que acabamos de mostrar neste vídeo, provar que a convolução de duas Gaussianas dá outra Gaussiana.",
  "time_range": [
   670.62,
   677.4
  ]
 },
 {
  "input": "What that means is that as you apply this process of repeated convolutions, a Gaussian doesn't change, it's a fixed point.",
  "model": "nmt",
  "translatedText": "O que isso significa é que conforme você aplica esse processo de convoluções repetidas, uma Gaussiana não muda, é um ponto fixo.",
  "time_range": [
   677.4,
   684.06
  ]
 },
 {
  "input": "So the only thing it can approach is itself, and since it's one member in this big family of distributions, all of which must be tending towards a single universal shape, it must be that universal shape.",
  "model": "nmt",
  "translatedText": "Portanto, a única coisa que pode aproximar-se é de si próprio, e como é um membro desta grande família de distribuições, todas as quais devem tender para uma única forma universal, deve ser essa forma universal.",
  "time_range": [
   684.2,
   695.06
  ]
 },
 {
  "input": "I mentioned at the start how this calculation, step two, is something that you can do directly, just symbolically with the definitions, but one of the reasons I'm so charmed by a geometric argument that leverages the rotational symmetry of this graph is that it directly connects to a few things that we've talked about on this channel before.",
  "model": "nmt",
  "translatedText": "Mencionei no início como esse cálculo, passo dois, é algo que você pode fazer diretamente, apenas simbolicamente com as definições, mas uma das razões pelas quais estou tão encantado com um argumento geométrico que aproveita a simetria rotacional deste gráfico é que ele se conecta diretamente a algumas coisas sobre as quais falamos neste canal antes.",
  "time_range": [
   695.58,
   712.3
  ]
 },
 {
  "input": "For example, the Herschel-Maxwell derivation of a Gaussian, which essentially says that you can view this rotational symmetry as the defining feature of the distribution, that it locks you into this e to the negative x squared form, and also as an added bonus it connects to the classic proof for why pi shows up in the formula, meaning we now have a direct line between the presence and mystery of that pi and the central limit theorem.",
  "model": "nmt",
  "translatedText": "Por exemplo, a derivação de Herschel-Maxwell de uma Gaussiana, que essencialmente diz que você pode ver esta simetria rotacional como a característica definidora da distribuição, que ela prende você neste e à forma negativa x ao quadrado, e também como um bônus adicional ele se conecta à prova clássica de por que pi aparece na fórmula, o que significa que agora temos uma linha direta entre a presença e o mistério desse pi e o teorema do limite central.",
  "time_range": [
   712.4,
   736.5
  ]
 },
 {
  "input": "Also on a recent Patreon post, the channel supporter Daksha Vaid-Quinter brought my attention to a completely different approach I hadn't seen before, which leverages the use of entropy, and again for the theoretically curious among you I'll leave some links in the description.",
  "model": "nmt",
  "translatedText": "Também em uma postagem recente no Patreon, o apoiador do canal Daksha Vaid-Quinter chamou minha atenção para uma abordagem completamente diferente que eu não tinha visto antes, que aproveita o uso da entropia, e novamente para os teoricamente curiosos entre vocês deixarei alguns links na descrição.",
  "time_range": [
   737.06,
   749.58
  ]
 },
 {
  "input": "By the way, if you want to stay up to date with new videos and also any other projects that I put out there like the Summer of Math Exposition, there is a mailing list.",
  "model": "nmt",
  "translatedText": "Aliás, se você quiser ficar por dentro de novos vídeos e também de quaisquer outros projetos que eu coloquei por aí como o Summer of Math Exposition, existe uma mailing list.",
  "time_range": [
   750.96,
   758.4
  ]
 },
 {
  "input": "It's relatively new and I'm pretty sparing about only posting what I think people will enjoy.",
  "model": "nmt",
  "translatedText": "É relativamente novo e estou economizando em postar apenas o que acho que as pessoas vão gostar.",
  "time_range": [
   758.72,
   762.78
  ]
 },
 {
  "input": "Usually I try not to be too promotional at the end of videos these days, but if you are interested in following the work that I do, this is probably one of the most enduring ways to do so.",
  "model": "nmt",
  "translatedText": "Normalmente tento não ser muito promocional no final dos vídeos hoje em dia, mas se você tiver interesse em acompanhar o trabalho que faço, esta é provavelmente uma das formas mais duradouras de fazê-lo.",
  "time_range": [
   763.22,
   795.26
  ]
 }
]