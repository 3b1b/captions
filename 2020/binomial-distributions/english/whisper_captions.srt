1
00:00:00,000 --> 00:00:02,900
You're buying a product online, and you see three different sellers.

2
00:00:03,460 --> 00:00:06,200
They're all offering that same product at essentially the same price.

3
00:00:06,720 --> 00:00:10,640
One of them has a 100% positive rating, but with only 10 reviews.

4
00:00:11,180 --> 00:00:14,740
Another has a 96% positive rating, with 50 total reviews.

5
00:00:15,220 --> 00:00:19,560
And yet another has a 93% positive rating, but with 200 total reviews.

6
00:00:20,300 --> 00:00:21,360
Which one should you buy from?

7
00:00:28,120 --> 00:00:32,420
I think we all have this instinct that the more data we see, it gives us more confidence

8
00:00:32,420 --> 00:00:33,240
in a given rating.

9
00:00:33,760 --> 00:00:37,620
We're a little suspicious of seeing 100% ratings, since more often than not they come

10
00:00:37,620 --> 00:00:41,640
from a tiny number of reviews, which makes it feel more plausible that things could have

11
00:00:41,640 --> 00:00:43,440
gone another way and given a lower rating.

12
00:00:43,920 --> 00:00:45,840
But how do you make that intuition quantitative?

13
00:00:46,420 --> 00:00:49,980
What's the rational way to reason about the trade-off here between the confidence

14
00:00:49,980 --> 00:00:53,260
gained from more data versus the lower absolute percentage?

15
00:00:54,540 --> 00:00:59,420
This particular example is a slight modification from one that John Cook gave in his excellent

16
00:00:59,420 --> 00:01:02,160
blog post, A Bayesian Review of Amazon Resellers.

17
00:01:02,620 --> 00:01:06,760
For you and me, it's a wonderful excuse to dig into a few core topics in probability

18
00:01:06,760 --> 00:01:07,600
and statistics.

19
00:01:08,320 --> 00:01:11,000
And to really cover these topics properly, it takes time.

20
00:01:11,560 --> 00:01:15,400
So what I'm going to do is break this down into three videos, where in this first one

21
00:01:15,400 --> 00:01:19,860
we'll set up a model for the situation, and start by talking about the binomial distribution.

22
00:01:19,980 --> 00:01:24,820
The second is going to bring in ideas of Bayesian updating, and how to work with probabilities

23
00:01:24,820 --> 00:01:26,380
over continuous values.

24
00:01:27,040 --> 00:01:31,060
And in the third, we'll look at something known as a beta distribution, and pull up

25
00:01:31,060 --> 00:01:35,440
a little python to analyze the data we have, and come to various different answers depending

26
00:01:35,440 --> 00:01:36,980
on what it is you want to optimize.

27
00:01:39,660 --> 00:01:43,380
Now, to throw you a bone before we dive into all the math, let me just show you what one

28
00:01:43,380 --> 00:01:46,240
of the answers turns out to be, since it's delightfully simple.

29
00:01:46,880 --> 00:01:51,880
When you see an online rating, something like this 10 out of 10, you pretend that there

30
00:01:51,880 --> 00:01:55,200
were two more reviews, one that was positive and one that's negative.

31
00:01:55,860 --> 00:02:00,480
In this case, that means you pretend that it's 11 out of 12, which would give 91.7%.

32
00:02:01,500 --> 00:02:06,080
This number is your probability of having a good experience with that seller.

33
00:02:08,140 --> 00:02:12,960
So in the case of 50 reviews, where you have 48 positive and 2 negative, you pretend that

34
00:02:12,960 --> 00:02:19,360
it's 49 positive and 3 negative, which would give you 49 out of 52, or 94.2%.

35
00:02:20,500 --> 00:02:23,840
That's your probability of having a good experience with the second seller.

36
00:02:25,320 --> 00:02:31,600
Playing the same game with our third seller who had 200 reviews, you get 187 out of 202,

37
00:02:32,060 --> 00:02:33,440
or 92.6%.

38
00:02:34,640 --> 00:02:38,660
So according to this rule, it would mean your best bet is to go with seller number 2.

39
00:02:39,300 --> 00:02:45,720
This is something known as Laplace's rule of succession, and to understand what assumptions

40
00:02:45,720 --> 00:02:50,480
are underlying this, and how changing either those assumptions or your underlying goal

41
00:02:50,480 --> 00:02:54,140
can change the choice you make, we really do need to go through all the math.

42
00:02:54,660 --> 00:02:56,360
So without further ado, let's dive in.

43
00:03:00,840 --> 00:03:06,080
Step 1, how exactly are we modeling the situation, and what exactly is it that you want to optimize?

44
00:03:06,700 --> 00:03:11,640
One option is to think of each seller as producing random experiences that are either positive

45
00:03:11,640 --> 00:03:16,500
or negative, and that each seller has some kind of constant underlying probability of

46
00:03:16,500 --> 00:03:21,480
giving a good experience, what we're going to call the success rate, or S for short.

47
00:03:21,900 --> 00:03:24,100
The whole challenge is that we don't know S.

48
00:03:25,640 --> 00:03:30,040
When you see that first rating of 100% with 10 reviews, that doesn't mean the underlying

49
00:03:30,040 --> 00:03:31,120
success rate is 100%.

50
00:03:31,640 --> 00:03:33,920
It could very well be something like 95%.

51
00:03:33,920 --> 00:03:38,960
And just to illustrate, let me run a little simulation, where I choose a random number

52
00:03:38,960 --> 00:03:45,020
between 0 and 1, and if it's less than 0.95, I'll record it as a positive review, otherwise

53
00:03:45,760 --> 00:03:47,660
record it as a negative review.

54
00:03:48,760 --> 00:03:57,560
Now do this 10 times in a row, and then make 10 more, and 10 more, and 10 more, and so

55
00:03:57,560 --> 00:04:02,780
on, to get a sense of what sequences of 10 reviews for a seller with this success rate,

56
00:04:02,780 --> 00:04:05,220
would tend to look like.

57
00:04:05,740 --> 00:04:09,520
Quite a few of those, around 60% actually, give 10 out of 10.

58
00:04:10,020 --> 00:04:14,460
So the data we see seems perfectly plausible if the seller's true success rate was 95%.

59
00:04:15,580 --> 00:04:18,040
Or maybe it's really 90%, or 99%.

60
00:04:18,700 --> 00:04:20,680
The whole challenge is that we just don't know.

61
00:04:21,600 --> 00:04:25,500
As to the goal, let's say you simply want to maximize your probability of having a

62
00:04:25,500 --> 00:04:28,960
positive experience, despite not being sure of this success rate.

63
00:04:29,860 --> 00:04:34,020
So think about this here, we've got many different possible success rates for each

64
00:04:34,020 --> 00:04:39,440
seller, any number from 0 up to 1, and we need to say something about how likely each

65
00:04:39,440 --> 00:04:43,920
one of these success rates is, a kind of probability of probabilities.

66
00:04:45,120 --> 00:04:49,360
Unlike the more gamified examples like coin flips and die tosses and the sort of things

67
00:04:49,360 --> 00:04:54,200
you see in an intro probability class, where you go in assuming a long run frequency, like

68
00:04:54,200 --> 00:05:00,400
1.5 or 1.6, what we have here is uncertainty about the long run frequency itself, which

69
00:05:00,400 --> 00:05:02,040
is a much more potent kind of doubt.

70
00:05:03,160 --> 00:05:07,360
I should also emphasize that this kind of setup is relevant to many many situations

71
00:05:07,360 --> 00:05:11,340
in the real world where you need to make a judgment about a random process from limited

72
00:05:11,340 --> 00:05:11,720
data.

73
00:05:12,860 --> 00:05:17,160
For example, let's say that you're setting up a factory producing cars, and in an initial

74
00:05:17,160 --> 00:05:20,840
test of 100 cars, two of them come out with some kind of problem.

75
00:05:21,400 --> 00:05:26,680
If you plan to spin things up to produce a million cars, what are you willing to confidently

76
00:05:26,680 --> 00:05:30,460
say about how many total cars will have problems that need addressing?

77
00:05:31,240 --> 00:05:36,140
It's not like the test guarantees that the true error rate is 2%, but what exactly does

78
00:05:36,140 --> 00:05:36,660
it say?

79
00:05:38,620 --> 00:05:40,560
As your first challenge, let me ask you this.

80
00:05:40,840 --> 00:05:46,420
If you did magically know the true success rate for a given seller, say it was 95%, how

81
00:05:46,420 --> 00:05:52,240
would you compute the probability of seeing 10 positive reviews and 0 negative reviews,

82
00:05:52,780 --> 00:05:56,200
or 48 and 2, or 186 and 14?

83
00:05:57,120 --> 00:06:02,160
In other words, what's the probability of seeing the data given an assumed success rate?

84
00:06:03,060 --> 00:06:07,840
A moment ago I showed you something like this with a simulation, generating 10 random reviews,

85
00:06:08,360 --> 00:06:12,360
and with a little programming you could just do that many times, building up a histogram

86
00:06:12,360 --> 00:06:15,080
to get some sense of what this distribution looks like.

87
00:06:21,660 --> 00:06:26,520
Likewise, you could simulate sets of 50 reviews, and get some sense for how probable it would

88
00:06:26,520 --> 00:06:29,080
be to see 48 positive and 2 negative.

89
00:06:29,900 --> 00:06:31,580
You see, this is the nice thing about probability.

90
00:06:31,960 --> 00:06:35,480
A little programming can almost always let you cheat a little and see what the answer

91
00:06:35,480 --> 00:06:37,480
is ahead of time by simulating it.

92
00:06:37,840 --> 00:06:42,160
For example, after a few hundred thousand samples of 50 reviews, assuming the success

93
00:06:42,160 --> 00:06:48,160
rate is 95%, it looks like about 26.1% of them would give us this 48 out of 50 review.

94
00:06:49,200 --> 00:06:52,440
Luckily, in this case, an exact formula is not bad at all.

95
00:06:52,980 --> 00:06:56,820
The probability of seeing exactly 48 out of 50 looks like this.

96
00:06:57,740 --> 00:07:03,400
This first term is pronounced 50 choose 48, and it represents the total number of ways

97
00:07:03,400 --> 00:07:08,040
that you could take 50 slots and fill out 48 of them.

98
00:07:09,100 --> 00:07:14,040
For example, maybe you start with 48 good reviews and end with 2 bad reviews, or maybe

99
00:07:14,040 --> 00:07:18,660
you start with 47 good reviews and then it goes bad good bad, and so on.

100
00:07:19,100 --> 00:07:24,100
In principle, if you were to enumerate every possible way of filling 48 out of 50 slots

101
00:07:24,100 --> 00:07:29,600
like this, the total number of these patterns is 50 choose 48, which in this case works

102
00:07:29,600 --> 00:07:31,860
out to be 1225.

103
00:07:32,680 --> 00:07:34,000
What do we multiply by this count?

104
00:07:34,000 --> 00:07:38,680
Well, it's the probability of any one of these patterns, which is the probability of

105
00:07:38,680 --> 00:07:43,440
a single positive review raised to the 48th times the probability of a single negative

106
00:07:43,440 --> 00:07:44,820
review squared.

107
00:07:45,640 --> 00:07:51,120
Crucial is that we assume each review is independent of the last, so we can multiply all the probabilities

108
00:07:51,120 --> 00:07:55,400
together like this, and with the numbers we have, when you evaluate it, it works out to

109
00:07:55,400 --> 00:08:00,220
be 0.261, which matches what we just saw empirically with the simulation.

110
00:08:01,380 --> 00:08:06,720
You could also replace this 48 with some other value, and compute the probability of seeing

111
00:08:06,720 --> 00:08:11,500
any other number of positive reviews, again assuming a given success rate.

112
00:08:14,760 --> 00:08:19,040
What you're looking at right now, by the way, is known in the business as a binomial

113
00:08:19,040 --> 00:08:23,160
distribution, one of the most fundamental distributions in probability.

114
00:08:23,860 --> 00:08:28,080
It comes up whenever you have something like a coin flip, a random event that can go one

115
00:08:28,080 --> 00:08:32,780
of two ways, and you repeat it some number of times, and what you want to know is the

116
00:08:32,780 --> 00:08:35,200
probability of getting various different totals.

117
00:08:36,720 --> 00:08:42,320
For our purposes, this formula gives us the probability of seeing the data given an assumed

118
00:08:42,320 --> 00:08:47,140
success rate, which ultimately we want to somehow use to make judgments about the opposite,

119
00:08:47,680 --> 00:08:50,860
the probability of a success rate given the fixed data we see.

120
00:08:51,320 --> 00:08:53,440
These are related, but definitely distinct.

121
00:08:54,060 --> 00:08:58,860
To get more in that direction, let's play around with this value of s and see what happens

122
00:08:58,860 --> 00:09:02,580
as we change it to different numbers between 0 and 1.

123
00:09:04,560 --> 00:09:08,920
The binomial distribution that it produces kind of looks like this pile that's centered

124
00:09:08,920 --> 00:09:10,860
around whatever s times 50 is.

125
00:09:11,460 --> 00:09:16,400
The value we care about, the probability of seeing 48 out of 50 reviews, is represented

126
00:09:16,400 --> 00:09:18,680
by this highlighted 48th bar.

127
00:09:19,400 --> 00:09:24,600
Let's draw a second plot on the bottom, representing how that value depends on s.

128
00:09:25,480 --> 00:09:30,320
When s is equal to 0.96, that value is as high as it's ever going to get.

129
00:09:30,840 --> 00:09:35,800
And this should kind of make sense, because when you look at that review of 96%, it should

130
00:09:35,800 --> 00:09:39,320
be most likely if the true underlying success rate was 96%.

131
00:09:41,000 --> 00:09:47,420
As s increases, it kind of peters out, going to 0 as s approaches 1, since someone with

132
00:09:47,420 --> 00:09:50,480
a perfect success rate would never have those two negative reviews.

133
00:09:51,420 --> 00:09:54,560
Also, as you move to the left, it approaches 0 pretty quickly.

134
00:09:56,900 --> 00:10:02,940
By the time you get to s equals 0.8, getting 48 out of 50 reviews by chance is exceedingly

135
00:10:02,940 --> 00:10:05,200
rare, it would happen 1 in 1000 times.

136
00:10:06,240 --> 00:10:10,160
This plot we have on the bottom is a great start to getting a more quantitative description

137
00:10:10,160 --> 00:10:13,380
for which values of s feel more or less plausible.

138
00:10:14,200 --> 00:10:18,920
Written down as a formula, what I want you to remember is that as a function of the success

139
00:10:18,920 --> 00:10:24,620
rate s, the curve looks like some constant times s to the number of positive reviews

140
00:10:24,620 --> 00:10:28,080
times 1 minus s to the number of negative reviews.

141
00:10:29,100 --> 00:10:34,220
In principle, if we had more data, like 480 positive reviews and 20 negative reviews,

142
00:10:34,660 --> 00:10:38,900
the resulting plot would still be centered around 0.96, but it would be smaller and more

143
00:10:38,900 --> 00:10:39,480
concentrated.

144
00:10:39,930 --> 00:10:44,220
A good exercise right now would be to see if you could explain why that's the case.

145
00:10:45,480 --> 00:10:49,480
There is a lingering question, though, of what to actually do with these curves.

146
00:10:50,220 --> 00:10:54,220
I mean, our goal is to compute the probability that you have a good experience with this

147
00:10:54,220 --> 00:10:56,020
seller, so what do you do?

148
00:10:57,000 --> 00:11:01,780
Naively, you might think that probability is 96%, since that's where the peak of the

149
00:11:01,780 --> 00:11:05,160
graph is, which in a sense is the most likely success rate.

150
00:11:05,620 --> 00:11:07,860
But think of the example with 10 out of 10 positives.

151
00:11:07,860 --> 00:11:13,260
In that case, the whole binomial formula simplifies to be s to the power 10.

152
00:11:15,080 --> 00:11:19,300
The probability of seeing 10 consecutive good reviews is the probability of seeing one of

153
00:11:19,300 --> 00:11:20,650
them raised to the 10th.

154
00:11:21,320 --> 00:11:26,120
The closer the true success rate is to 1, the higher the probability of seeing a 10

155
00:11:26,120 --> 00:11:26,660
out of 10.

156
00:11:27,220 --> 00:11:30,980
Our plot on the bottom only ever increases as s approaches 1.

157
00:11:32,400 --> 00:11:37,320
But even if s equals 1 is the value that maximizes this probability, surely you wouldn't

158
00:11:37,320 --> 00:11:41,840
feel comfortable saying that you personally have a 100% probability of a good experience

159
00:11:41,840 --> 00:11:42,520
with this seller.

160
00:11:43,460 --> 00:11:47,820
Maybe you think that instead we should look for some kind of center of mass of this graph,

161
00:11:48,180 --> 00:11:50,400
and that would absolutely be on the right track.

162
00:11:51,300 --> 00:11:56,220
First, though, we need to explain how to take this expression for the probability of the

163
00:11:56,220 --> 00:12:01,400
data we're seeing given a value of s, and get the probability for a value of s, the

164
00:12:01,400 --> 00:12:04,880
thing we actually don't know, given the data, the thing we actually know.

165
00:12:05,380 --> 00:12:09,980
And that requires us to talk about Bayes' rule, and also probability density functions.

166
00:12:10,620 --> 00:12:12,360
For those, I'll see you in part 2.

