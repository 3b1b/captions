[
 {
  "input": "I'm assuming that everybody here is coming from part 1.",
  "translatedText": "여기 계신 분들은 모두 1부에서 오신 분들인 것 같아요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 2.56
 },
 {
  "input": "We were talking about Hamming codes, a way to create a block of data where most of the bits carry a meaningful message, while a few others act as a kind of redundancy, in such a way that if any bit gets flipped, either a message bit or a redundancy bit, anything in this block, a receiver is going to be able to identify that there was an error, and how to fix it.",
  "translatedText": "우리는 대부분의 비트가 의미 있는 메시지를 전달하는 반면 다른 비트는 일종의 중복 역할을 하는 데이터 블록을 생성하는 방법인 해밍 코드에 대해 이야기하고 있었습니다. 비트 또는 중복 비트 등 이 블록에 있는 모든 항목을 통해 수신자는 오류가 있음을 식별하고 이를 수정하는 방법을 확인할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.06,
  "end": 21.24
 },
 {
  "input": "The basic idea presented there was how to use multiple parity checks to binary search your way down to the error.",
  "translatedText": "거기에 제시된 기본 아이디어는 다중 패리티 검사를 사용하여 오류까지 이진 검색하는 방법이었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 21.88,
  "end": 27.16
 },
 {
  "input": "In that video the goal was to make Hamming codes feel as hands-on and rediscoverable as possible.",
  "translatedText": "해당 비디오의 목표는 Hamming 코드를 가능한 한 직접 사용하고 재발견할 수 있도록 만드는 것이었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 28.98,
  "end": 34.6
 },
 {
  "input": "But as you start to think about actually implementing this, either in software or hardware, that framing may actually undersell how elegant these codes really are.",
  "translatedText": "그러나 소프트웨어나 하드웨어에서 이를 실제로 구현하는 것에 대해 생각하기 시작하면 해당 프레임은 실제로 이러한 코드가 실제로 얼마나 우아한지 과소평가할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.18,
  "end": 43.46
 },
 {
  "input": "You might think that you need to write an algorithm that keeps track of all the possible error locations and cuts that group in half with each check, but it's actually way, way simpler than that.",
  "translatedText": "가능한 모든 오류 위치를 추적하고 검사할 때마다 해당 그룹을 절반으로 줄이는 알고리즘을 작성해야 한다고 생각할 수도 있지만 실제로는 그보다 훨씬 더 간단합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.92,
  "end": 53.48
 },
 {
  "input": "If you read out the answers to the four parity checks we did in the last video, all as 1s and 0s instead of yeses and nos, it literally spells out the position of the error in binary.",
  "translatedText": "지난 비디오에서 우리가 했던 네 가지 패리티 검사에 대한 답을 모두 예와 아니오 대신 1과 0으로 읽으면 문자 그대로 이진수로 오류 위치를 설명합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.94,
  "end": 64.08
 },
 {
  "input": "For example, the number 7 in binary looks like 0111, essentially saying that it's 4 plus 2 plus 1.",
  "translatedText": "예를 들어, 이진수 7은 0111처럼 보입니다. 이는 본질적으로 4 더하기 2 더하기 1을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 64.78,
  "end": 71.26
 },
 {
  "input": "And notice where the position 7 sits, it does affect the first of our parity groups, and the second, and the third, but not the last.",
  "translatedText": "그리고 위치 7이 어디에 있는지 확인하세요. 이는 패리티 그룹 중 첫 번째, 두 번째, 세 번째에 영향을 주지만 마지막에는 영향을 미치지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.54,
  "end": 81.74
 },
 {
  "input": "So reading the results of those four checks from bottom to top indeed does spell out the position of the error.",
  "translatedText": "따라서 이 네 가지 검사 결과를 아래에서 위로 읽으면 실제로 오류의 위치를 알 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 82.22,
  "end": 87.54
 },
 {
  "input": "There's nothing special about the example 7, this works in general, and this makes the logic for implementing the whole scheme in hardware shockingly simple.",
  "translatedText": "예제 7에는 특별한 것이 없습니다. 이는 일반적으로 작동하며 하드웨어에서 전체 구성표를 구현하는 논리를 놀라울 정도로 단순하게 만듭니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.32,
  "end": 95.82
 },
 {
  "input": "Now if you want to see why this magic happens, take these 16 index labels for our positions, but instead of writing them in base 10, let's write them all in binary, running from 0000 up to 1111.",
  "translatedText": "이제 이 마법이 왜 일어나는지 알고 싶다면 위치에 대한 16개의 인덱스 레이블을 사용하세요. 단, 10진수로 작성하는 대신 0000부터 1111까지 실행되는 이진수로 모두 작성해 보겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.24,
  "end": 109.88
 },
 {
  "input": "As we put these binary labels back into their boxes, let me emphasize that they are distinct from the data that's actually being sent.",
  "translatedText": "이러한 바이너리 레이블을 상자에 다시 넣을 때 실제로 전송되는 데이터와 구별된다는 점을 강조하겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.56,
  "end": 117.8
 },
 {
  "input": "They're nothing more than a conceptual label to help you and me understand where the four parity groups came from.",
  "translatedText": "이는 여러분과 제가 네 개의 패리티 그룹이 어디에서 왔는지 이해하는 데 도움이 되는 개념적 레이블에 지나지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.32,
  "end": 123.5
 },
 {
  "input": "The elegance of having everything we're looking at be described in binary is maybe undercut by the confusion of having everything we're looking at being described in binary.",
  "translatedText": "우리가 보고 있는 모든 것을 이진법으로 기술하는 것의 우아함은 우리가 보고 있는 모든 것을 이진법으로 기술하는 것의 혼란으로 인해 약화될 수도 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.14,
  "end": 132.36
 },
 {
  "input": "It's worth it, though.",
  "translatedText": "그래도 그만한 가치가 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 133.02,
  "end": 134.12
 },
 {
  "input": "Focus your attention just on that last bit of all of these labels, and then highlight the positions where that final bit is a 1.",
  "translatedText": "모든 레이블의 마지막 비트에만 주의를 집중한 다음 마지막 비트가 1인 위치를 강조 표시하세요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 143.22
 },
 {
  "input": "What we get is the first of our four parity groups, which means you can interpret that first check as asking, hey, if there's an error, is the final bit in the position of that error a 1?",
  "translatedText": "우리가 얻는 것은 네 개의 패리티 그룹 중 첫 번째입니다. 즉, 첫 번째 검사를 다음과 같이 묻는 것으로 해석할 수 있습니다. 오류가 있으면 해당 오류 위치의 마지막 비트가 1인가요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.24,
  "end": 155.74
 },
 {
  "input": "Similarly, if you focus on the second to last bit, and highlight all the positions where that's a 1, you get the second parity group from our scheme.",
  "translatedText": "마찬가지로, 마지막 비트에서 두 번째 비트에 초점을 맞추고 해당 비트가 1인 모든 위치를 강조 표시하면 구성표에서 두 번째 패리티 그룹을 얻게 됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.2,
  "end": 166.16
 },
 {
  "input": "In other words, that second check is asking, hey, me again, if there's an error, is the second to last bit of that position a 1?",
  "translatedText": "즉, 두 번째 확인은 '안녕하세요, 다시 한 번 말씀드리지만, 오류가 있는 경우 해당 위치의 마지막에서 두 번째 비트가 1인가요? '라고 묻습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.74,
  "end": 174.5
 },
 {
  "input": "And so on.",
  "translatedText": "등등.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.76,
  "end": 176.9
 },
 {
  "input": "The third parity check covers every position whose third to last bit is turned on, and the last one covers the last eight positions, those ones whose highest order bit is a 1.",
  "translatedText": "세 번째 패리티 검사는 마지막에서 세 번째 비트가 켜져 있는 모든 위치를 다루고, 마지막 패리티 검사는 가장 높은 순서 비트가 1인 마지막 8개 위치를 다룹니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.22,
  "end": 188.74
 },
 {
  "input": "Everything we did earlier is the same as answering these four questions, which in turn is the same as spelling out a position in binary.",
  "translatedText": "이전에 우리가 했던 모든 것은 이 네 가지 질문에 답하는 것과 동일하며, 이는 다시 이진법으로 위치를 철자하는 것과 동일합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.74,
  "end": 197.74
 },
 {
  "input": "I hope this makes two things clearer.",
  "translatedText": "이것이 두 가지를 더 명확하게 해주기를 바랍니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.62,
  "end": 201.48
 },
 {
  "input": "The first is how to systematically generalize to block sizes that are bigger powers of two.",
  "translatedText": "첫 번째는 2의 거듭제곱보다 큰 블록 크기를 체계적으로 일반화하는 방법입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.04,
  "end": 206.46
 },
 {
  "input": "If it takes more bits to describe each position, like six bits to describe 64 spots, then each of those bits gives you one of the parity groups that we need to check.",
  "translatedText": "64개 지점을 설명하는 데 6비트가 필요한 것처럼 각 위치를 설명하는 데 더 많은 비트가 필요한 경우 각 비트는 확인해야 할 패리티 그룹 중 하나를 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 216.68
 },
 {
  "input": "Those of you who watched the chessboard puzzle I did with Matt Parker might find all this exceedingly familiar.",
  "translatedText": "제가 Matt Parker와 함께 했던 체스판 퍼즐을 본 분들이라면 이 모든 것이 매우 익숙할 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.4,
  "end": 223.18
 },
 {
  "input": "It's the same core logic, but solving a different problem, and applied to a 64-squared chessboard.",
  "translatedText": "동일한 핵심 논리이지만 다른 문제를 해결하고 64제곱 체스판에 적용됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.66,
  "end": 228.78
 },
 {
  "input": "The second thing I hope this makes clear is why our parity bits are sitting in the positions that are powers of two, for example 1, 2, 4, and 8.",
  "translatedText": "두 번째로 명확해지기를 바라는 것은 패리티 비트가 1, 2, 4, 8과 같이 2의 거듭제곱 위치에 있는 이유입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.88,
  "end": 237.32
 },
 {
  "input": "These are the positions whose binary representation has just a single bit turned on.",
  "translatedText": "이는 이진 표현이 단일 비트만 켜져 있는 위치입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.0,
  "end": 243.0
 },
 {
  "input": "What that means is each of those parity bits sits inside one and only one of the four parity groups.",
  "translatedText": "이는 각 패리티 비트가 4개의 패리티 그룹 중 하나에만 위치한다는 것을 의미합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.6,
  "end": 249.46
 },
 {
  "input": "You can also see this in larger examples, where no matter how big you get, each parity bit conveniently touches only one of the groups.",
  "translatedText": "얼마나 큰지 상관없이 각 패리티 비트가 그룹 중 하나에만 편리하게 닿는 더 큰 예에서도 이를 볼 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.04,
  "end": 259.34
 },
 {
  "input": "Once you understand that these parity checks that we've focused so much of our time on are nothing more than a clever way to spell out the position of an error in binary, then we can draw a connection with a different way to think about hamming codes, one that is arguably a lot simpler and more elegant, and which can basically be written down with a single line of code.",
  "translatedText": "우리가 많은 시간을 투자해 온 이러한 패리티 검사가 오류의 위치를 바이너리로 설명하는 영리한 방법일 뿐이라는 점을 이해하면 해밍에 대해 생각하는 다른 방식으로 연결을 그릴 수 있습니다. 훨씬 더 간단하고 우아하며 기본적으로 한 줄의 코드로 작성할 수 있는 코드입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.6,
  "end": 283.24
 },
 {
  "input": "It's based on the XOR function.",
  "translatedText": "XOR 함수를 기반으로 합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.66,
  "end": 285.5
 },
 {
  "input": "XOR, for those of you who don't know, stands for exclusive or.",
  "translatedText": "XOR은 모르시는 분들을 위해 설명하자면, Exclusive or의 약자입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.94,
  "end": 290.22
 },
 {
  "input": "When you take the XOR of two bits, it's going to return a 1 if either one of those bits is turned on, but not if both are turned on or off.",
  "translatedText": "두 비트의 XOR을 수행하면 해당 비트 중 하나가 켜져 있으면 1이 반환되지만 둘 다 켜져 있거나 꺼져 있으면 반환되지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.78,
  "end": 299.36
 },
 {
  "input": "Phrased differently, it's the parity of these two bits.",
  "translatedText": "다르게 말하면, 이 두 비트의 패리티입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.1,
  "end": 302.98
 },
 {
  "input": "As a math person, I prefer to think about it as addition mod 2.",
  "translatedText": "수학적인 사람으로서 나는 그것을 추가 모드 2로 생각하는 것을 선호합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 303.54,
  "end": 306.76
 },
 {
  "input": "We also commonly talk about the XOR of two different bit strings, which basically does this component by component.",
  "translatedText": "또한 기본적으로 이 구성 요소를 구성 요소별로 수행하는 두 개의 서로 다른 비트 문자열의 XOR에 대해서도 일반적으로 이야기합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.36,
  "end": 313.44
 },
 {
  "input": "It's like addition, but where you never carry.",
  "translatedText": "그것은 덧셈과 비슷하지만 결코 가지고 다니지 않습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.68,
  "end": 315.72
 },
 {
  "input": "Again, the more mathematically inclined might prefer to think of this as adding two vectors and reducing mod 2.",
  "translatedText": "다시 말하지만, 수학적으로 더 기울어진 사람은 이를 두 개의 벡터를 추가하고 mod 2를 줄이는 것으로 생각하는 것을 선호할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.5,
  "end": 322.48
 },
 {
  "input": "If you open up some Python right now and apply the caret operation between two integers, this is what it's doing but to the bit representations of those numbers under the hood.",
  "translatedText": "지금 당장 Python을 열고 두 정수 사이에 캐럿 연산을 적용하면 이것이 수행되는 작업이지만 내부적으로 해당 숫자의 비트 표현이 수행됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.5,
  "end": 332.94
 },
 {
  "input": "The key point for you and me is that taking the XOR of many different bit strings is effectively a way to compute the parodies of a bunch of separate groups, like so with the columns, all in one fell swoop.",
  "translatedText": "여러분과 저에게 중요한 점은 다양한 비트 문자열의 XOR을 취하는 것이 열의 경우와 같이 여러 개별 그룹의 패러디를 한꺼번에 계산하는 효과적인 방법이라는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.96,
  "end": 347.14
 },
 {
  "input": "This gives us a rather snazzy way to think about the multiple parity checks from our Hamming code algorithm as all being packaged together into one single operation.",
  "translatedText": "이는 해밍 코드 알고리즘의 다중 패리티 검사를 모두 하나의 단일 작업으로 함께 패키지하는 것으로 생각하는 다소 멋진 방법을 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.26,
  "end": 358.78
 },
 {
  "input": "Though at first glance it does look very different.",
  "translatedText": "언뜻 보면 매우 달라 보이지만.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.48,
  "end": 362.18
 },
 {
  "input": "Specifically write down the 16 positions in binary, like we had before, and now highlight the positions where the message bit is turned on to a 1, and then collect these positions into one big column and take the XOR.",
  "translatedText": "이전처럼 16개 위치를 이진수로 구체적으로 기록하고 이제 메시지 비트가 1로 켜진 위치를 강조 표시한 다음 이러한 위치를 하나의 큰 열로 수집하고 XOR을 수행합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.82,
  "end": 377.1
 },
 {
  "input": "You can probably guess that the 4 bits sitting at the bottom as a result are the same as the 4 parity checks we've come to know and love, but take a moment to actually think about why exactly.",
  "translatedText": "결과적으로 맨 아래에 있는 4비트는 우리가 알고 사랑하게 된 4개의 패리티 검사와 동일하다고 추측할 수 있지만 실제로 그 이유가 무엇인지 잠시 생각해 보세요.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.26,
  "end": 389.2
 },
 {
  "input": "This last column, for example, is counting all of the positions whose last bit is a 1, but we're already limited only to the highlighted positions, so it's effectively counting how many highlighted positions came from the first parity group.",
  "translatedText": "예를 들어 이 마지막 열은 마지막 비트가 1인 모든 위치를 계산하지만 이미 강조 표시된 위치로만 제한되어 있으므로 첫 번째 패리티 그룹에서 강조 표시된 위치 수를 효과적으로 계산합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.22,
  "end": 405.76
 },
 {
  "input": "Does that make sense?",
  "translatedText": "말이 돼?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 406.8
 },
 {
  "input": "Likewise, the next column counts how many positions are in the second parity group, the positions whose second to last bit is a 1, and which are also highlighted, and so on.",
  "translatedText": "마찬가지로 다음 열에서는 두 번째 패리티 그룹에 위치가 몇 개 있는지, 마지막 비트에서 두 번째 비트가 1이고 역시 강조 표시된 위치 등을 계산합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.08,
  "end": 420.0
 },
 {
  "input": "It's really just a small shift in perspective on the same thing we've been doing.",
  "translatedText": "이는 우리가 해왔던 동일한 일에 대한 관점의 작은 변화일 뿐입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.26,
  "end": 423.96
 },
 {
  "input": "And so you know where it goes from here.",
  "translatedText": "그래서 여기서부터 어디로 가는지 알 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 427.76,
  "end": 429.6
 },
 {
  "input": "The sender is responsible for toggling some of the special parity bits to make sure the sum works out to be 0000.",
  "translatedText": "보낸 사람은 합계가 0000이 되도록 특수 패리티 비트 중 일부를 전환할 책임이 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.0,
  "end": 436.56
 },
 {
  "input": "Now once we have it like this, this gives us a really nice way to think about why these four resulting bits at the bottom directly spell out the position of an error.",
  "translatedText": "이제 이와 같은 결과가 나오면 하단에 있는 4개의 결과 비트가 오류 위치를 직접적으로 설명하는 이유를 생각할 수 있는 정말 좋은 방법을 제공합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.04,
  "end": 447.58
 },
 {
  "input": "Let's say some bit in this block gets toggled from a 0 to a 1.",
  "translatedText": "이 블록의 일부 비트가 0에서 1로 전환된다고 가정해 보겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.46,
  "end": 451.86
 },
 {
  "input": "What that means is that the position of that bit is now going to be included in the total XOR, which changes the sum from being 0 to instead being this newly included value, the position of the error.",
  "translatedText": "이는 해당 비트의 위치가 이제 전체 XOR에 포함되어 합계가 0에서 새로 포함된 값인 오류 위치로 변경된다는 의미입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.6,
  "end": 463.82
 },
 {
  "input": "Slightly less obviously, the same is true if there's an error that changes a 1 to a 0.",
  "translatedText": "약간 덜 명확하게 말하면 1을 0으로 변경하는 오류가 있는 경우에도 마찬가지입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.46,
  "end": 469.36
 },
 {
  "input": "You see, if you add a bit string together twice, it's the same as not having it there at all, basically because in this world 1 plus 1 equals 0.",
  "translatedText": "알다시피, 비트 문자열을 두 번 더하면 거기에 전혀 없는 것과 같습니다. 기본적으로 이 세상에서는 1 더하기 1이 0이기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.18,
  "end": 477.94
 },
 {
  "input": "So adding a copy of this position to the total sum has the same effect as we're moving it.",
  "translatedText": "따라서 이 위치의 복사본을 총 합계에 추가하면 이동하는 것과 동일한 효과가 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.92,
  "end": 484.3
 },
 {
  "input": "And that effect, again, is that the total result at the bottom here spells out the position of the error.",
  "translatedText": "그리고 그 효과는 여기 하단의 전체 결과가 오류의 위치를 설명한다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.16,
  "end": 490.7
 },
 {
  "input": "To illustrate how elegant this is, let me show that one line of Python code I referenced before, which will capture almost all of the logic on the receiver's end.",
  "translatedText": "이것이 얼마나 우아한지 설명하기 위해 이전에 참조한 Python 코드 한 줄을 보여 드리겠습니다. 이 코드는 수신자 측의 거의 모든 논리를 캡처합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.04,
  "end": 501.44
 },
 {
  "input": "We'll start by creating a random array of 16 1s and 0s to simulate the data block, and I'll give it the name bits, but of course in practice this would be something we're receiving from a sender, and instead of being random it would be carrying 11 data bits together with 5 parity bits.",
  "translatedText": "데이터 블록을 시뮬레이션하기 위해 16개의 1과 0으로 구성된 임의의 배열을 생성하는 것부터 시작하고 여기에 이름 비트를 부여할 것입니다. 무작위이므로 5개의 패리티 비트와 함께 11개의 데이터 비트를 전달합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.08,
  "end": 517.4
 },
 {
  "input": "If I call the function enumerateBits, what it does is pair together each of those bits with a corresponding index, in this case running from 0 up to 15.",
  "translatedText": "enumerateBits 함수를 호출하면 각 비트를 해당 인덱스와 쌍으로 연결합니다. 이 경우에는 0에서 15까지 실행됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.12,
  "end": 527.0
 },
 {
  "input": "So if we then create a list that loops over all of these pairs, pairs that look like i, and then we pull out just the i value, just the index, well it's not that exciting, we just get back those indices 0 through 15.",
  "translatedText": "그래서 우리가 이 모든 쌍, 즉 i처럼 보이는 쌍을 반복하는 목록을 생성하고 i 값만 추출하고 인덱스만 추출하면 그다지 흥미롭지는 않습니다. 0부터 15까지의 인덱스만 다시 가져옵니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.18,
  "end": 541.34
 },
 {
  "input": "But if we add on the condition to only do this if bit, meaning if that bit is a 1 and not a 0, well then it pulls out only the positions where the corresponding bit is turned on.",
  "translatedText": "하지만 만약 비트인 경우에만 이 작업을 수행한다는 조건을 추가하면, 즉 해당 비트가 1이고 0이 아닌 경우 해당 비트가 켜져 있는 위치만 꺼냅니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 541.68,
  "end": 552.66
 },
 {
  "input": "In this case it looks like those positions are 0, 4, 6, 9, etc.",
  "translatedText": "이 경우 해당 위치는 0, 4, 6, 9 등인 것처럼 보입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.38,
  "end": 557.96
 },
 {
  "input": "What we want is to collect together all of those positions, the positions of the bits that are turned on, and then XOR them together.",
  "translatedText": "우리가 원하는 것은 모든 위치, 즉 켜져 있는 비트의 위치를 함께 수집한 다음 함께 XOR하는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.98,
  "end": 567.24
 },
 {
  "input": "To do this in Python, let me first import a couple helpful functions.",
  "translatedText": "Python에서 이 작업을 수행하려면 먼저 몇 가지 유용한 함수를 가져오겠습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.18,
  "end": 573.22
 },
 {
  "input": "That way we can call reduce() on this list, and use the XOR function to reduce it.",
  "translatedText": "그런 식으로 우리는 이 목록에서 Reduce()를 호출하고 XOR 함수를 사용하여 목록을 줄일 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.9,
  "end": 578.7
 },
 {
  "input": "This basically eats its way through the list, taking XORs along the way.",
  "translatedText": "이것은 기본적으로 목록을 통해 XOR을 수행합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.1,
  "end": 582.68
 },
 {
  "input": "If you prefer, you can explicitly write out that XOR function without having to import it from anywhere.",
  "translatedText": "원하는 경우 XOR 함수를 어디에서든 가져올 필요 없이 명시적으로 작성할 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.8,
  "end": 589.44
 },
 {
  "input": "So at the moment it looks like if we do this on our random block of 16 bits, it returns 9, which has the binary representation 1001.",
  "translatedText": "따라서 현재로서는 16비트의 무작위 블록에 대해 이 작업을 수행하면 이진 표현 1001을 갖는 9가 반환되는 것처럼 보입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.94,
  "end": 601.28
 },
 {
  "input": "We won't do it here, but you could write a function where the sender uses that binary representation to set the four parity bits as needed, ultimately getting this block to a state where running this line of code on the full list of bits returns a 0.",
  "translatedText": "여기서는 수행하지 않겠지만 송신자가 이진 표현을 사용하여 필요에 따라 4개의 패리티 비트를 설정하는 함수를 작성할 수 있습니다. 그러면 궁극적으로 이 블록을 전체 비트 목록에서 이 코드 줄을 실행하는 상태가 반환됩니다. 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.98,
  "end": 615.46
 },
 {
  "input": "This would be considered a well-prepared block.",
  "translatedText": "이는 잘 준비된 블록으로 간주됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 616.08,
  "end": 618.2
 },
 {
  "input": "What's cool is that if we toggle any one of the bits in this list, simulating a random error from noise, then if you run this same line of code, it prints out that error.",
  "translatedText": "멋진 점은 이 목록의 비트 중 하나를 전환하여 노이즈로 인한 임의 오류를 시뮬레이션한 다음 동일한 코드 줄을 실행하면 해당 오류가 인쇄된다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 619.88,
  "end": 630.22
 },
 {
  "input": "Isn't that neat?",
  "translatedText": "깔끔하지 않나요?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 630.96,
  "end": 631.52
 },
 {
  "input": "You could get this block from out of the blue, run this single line on it, and it'll automatically spit out the position of an error, or a 0 if there wasn't any.",
  "translatedText": "갑자기 이 블록을 가져와서 이 한 줄을 실행하면 오류 위치가 자동으로 표시되고, 오류가 없으면 0이 표시됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 631.82,
  "end": 641.06
 },
 {
  "input": "And there's nothing special about the size 16 here.",
  "translatedText": "그리고 사이즈 16에는 특별한 것이 없습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.5,
  "end": 645.2
 },
 {
  "input": "The same line of code would work if you had a list of, say, 256 bits.",
  "translatedText": "예를 들어 256비트 목록이 있는 경우 동일한 코드 줄이 작동합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.4,
  "end": 649.86
 },
 {
  "input": "Needless to say, there is more code to write here, like doing the meta parity check to detect 2-bit errors, but the idea is that almost all of the core logic from our scheme comes down to a single XOR reduction.",
  "translatedText": "말할 필요도 없이 여기에 작성해야 할 코드가 더 있습니다. 예를 들어 2비트 오류를 감지하기 위한 메타 패리티 검사를 수행하는 것입니다. 그러나 아이디어는 우리 체계의 거의 모든 핵심 논리가 단일 XOR 감소로 귀결된다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.88,
  "end": 663.76
 },
 {
  "input": "Now, depending on your comfort with binary and XORs and software in general, you may either find this perspective a little bit confusing, or so much more elegant and simple that you're wondering why we didn't just start with it from the get-go.",
  "translatedText": "이제 바이너리, XOR 및 일반적인 소프트웨어에 대한 편안함에 따라 이 관점이 약간 혼란스러울 수도 있고 훨씬 더 우아하고 단순하여 왜 우리가 처음부터 시작하지 않았는지 궁금해할 수도 있습니다. -가다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.12,
  "end": 678.42
 },
 {
  "input": "Loosely speaking, the multiple parity check perspective is easier to think about when implementing Hamming codes in hardware very directly, and the XOR perspective is easiest to think about when doing it in software, from kind of a higher level.",
  "translatedText": "대략적으로 말하면 다중 패리티 검사 관점은 하드웨어에서 해밍 코드를 직접 구현할 때 생각하기가 더 쉽고, XOR 관점은 소프트웨어에서 수행할 때 더 높은 수준에서 생각하기 가장 쉽습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 679.14,
  "end": 690.5
 },
 {
  "input": "The first one is easiest to actually do by hand, and I think it does a better job instilling the core intuition underlying all of this, which is that the information required to locate a single error is related to the log of the size of the block, or in other words, it grows one bit at a time as the block size doubles.",
  "translatedText": "첫 번째는 실제로 손으로 하는 것이 가장 쉽고, 이 모든 것의 기초가 되는 핵심 직관을 심어주는 것이 더 나은 일이라고 생각합니다. 즉, 단일 오류를 찾는 데 필요한 정보는 블록 크기의 로그와 관련이 있다는 것입니다. 즉, 블록 크기가 두 배로 증가함에 따라 한 번에 한 비트씩 증가합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.36,
  "end": 710.0
 },
 {
  "input": "The relevant fact here is that that information directly corresponds to how much redundancy we need.",
  "translatedText": "여기서 관련 사실은 해당 정보가 필요한 중복 정도와 직접적으로 일치한다는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.02,
  "end": 716.06
 },
 {
  "input": "That's really what runs against most people's knee-jerk reaction when they first think about making a message resilient to errors, where usually copying the whole message is the first instinct that comes to mind.",
  "translatedText": "이는 오류에 대해 탄력적인 메시지를 만드는 것에 대해 처음 생각할 때 대부분의 사람들이 무작정 반응하는 것과 반대되는 것입니다. 일반적으로 전체 메시지를 복사하는 것이 가장 먼저 떠오르는 본능입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 716.66,
  "end": 726.54
 },
 {
  "input": "And then, by the way, there is this whole other way that you sometimes see Hamming codes presented, where you multiply the message by one big matrix.",
  "translatedText": "그런데 때로는 해밍 코드가 표시되는 완전히 다른 방식이 있는데, 여기서 메시지에 하나의 큰 행렬을 곱합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 727.5,
  "end": 734.0
 },
 {
  "input": "It's kind of nice because it relates it to the broader family of linear codes, but I think that gives almost no intuition for where it comes from or how it scales.",
  "translatedText": "더 넓은 범위의 선형 코드 제품군과 관련되어 있기 때문에 다소 좋지만, 그것이 어디서 왔는지 또는 어떻게 확장되는지에 대한 직관을 거의 제공하지 않는다고 생각합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.67,
  "end": 743.06
 },
 {
  "input": "And speaking of scaling, you might notice that the efficiency of this scheme only gets better as we increase the block size.",
  "translatedText": "확장에 관해 말하자면, 블록 크기를 늘릴수록 이 체계의 효율성이 더 좋아진다는 것을 알 수 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.2,
  "end": 751.16
 },
 {
  "input": "For example, we saw that with 256 bits, you're using only 3% of that space for redundancy, and it just keeps getting better from there.",
  "translatedText": "예를 들어, 256비트의 경우 중복성을 위해 해당 공간의 3%만 사용하고 그 이후로 점점 더 좋아지는 것을 확인했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.0,
  "end": 762.66
 },
 {
  "input": "As the number of parity bits grows one by one, the block size keeps doubling.",
  "translatedText": "패리티 비트 수가 하나씩 증가함에 따라 블록 크기는 계속 두 배로 늘어납니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 763.3,
  "end": 767.34
 },
 {
  "input": "And if you take that to an extreme, you could have a block with, say, a million bits, where you would quite literally be playing 20 questions with your parity checks, and it uses only 21 parity bits.",
  "translatedText": "그리고 이를 극단적으로 받아들인다면, 예를 들어 백만 비트의 블록을 가질 수 있습니다. 여기서 패리티 검사로 문자 그대로 20개의 질문을 플레이하고 21개의 패리티 비트만 사용하게 됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 769.0,
  "end": 780.02
 },
 {
  "input": "And if you step back to think about looking at a million bits and locating a single error, that genuinely feels crazy.",
  "translatedText": "그리고 한 걸음 물러서서 백만 개의 비트를 살펴보고 단일 오류를 찾는 것에 대해 생각한다면 그것은 정말로 미친 것처럼 느껴집니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 780.74,
  "end": 787.06
 },
 {
  "input": "The problem, of course, is that with a larger block, the probability of seeing more than one or two bit errors goes up, and Hamming codes do not handle anything beyond that.",
  "translatedText": "물론 문제는 블록이 클수록 비트 오류가 1~2개 이상 나올 확률이 높아지고, 해밍 코드는 그 이상은 처리하지 못한다는 점이다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 788.2,
  "end": 797.66
 },
 {
  "input": "So in practice, what you'd want is to find the right size so that the probability of too many bit flips isn't too high.",
  "translatedText": "따라서 실제로 원하는 것은 비트 플립이 너무 많이 발생할 확률이 너무 높지 않도록 올바른 크기를 찾는 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.32,
  "end": 804.3
 },
 {
  "input": "Also, in practice, errors tend to come in little bursts, which would totally ruin a single block, so one common tactic to help spread out a burst of errors across many different blocks is to interlace those blocks, like this, before they're sent out or stored.",
  "translatedText": "또한 실제로 오류는 작은 단위로 발생하는 경향이 있어 단일 블록을 완전히 망칠 수 있습니다. 따라서 여러 블록에 걸쳐 오류를 분산시키는 데 도움이 되는 일반적인 전술 중 하나는 해당 블록이 블록에 포함되기 전에 이와 같이 인터레이스하는 것입니다. 발송 또는 보관됩니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.6,
  "end": 820.98
 },
 {
  "input": "Then again, a lot of this is rendered completely moot by more modern codes, like the much more commonly used Reed-Solomon algorithm, which handles burst errors particularly well, and it can be tuned to be resilient to a larger number of errors per block.",
  "translatedText": "그런 다음 다시 말하지만, 이 중 많은 부분은 버스트 오류를 특히 잘 처리하고 블록당 더 많은 수의 오류에 탄력적으로 조정될 수 있는 훨씬 더 일반적으로 사용되는 Reed-Solomon 알고리즘과 같은 최신 코드에 의해 완전히 논쟁의 여지가 있습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.58,
  "end": 838.82
 },
 {
  "input": "But that's a topic for another time.",
  "translatedText": "그러나 그것은 다른 시간에 다룰 주제입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.36,
  "end": 841.34
 },
 {
  "input": "In his book The Art of Doing Science and Engineering, Hamming is wonderfully candid about just how meandering his discovery of this code was.",
  "translatedText": "Hamming은 자신의 저서 The Art of Doing Science and Engineering에서 자신이 발견한 이 코드가 얼마나 의미심장한 일이었는지 놀랍도록 솔직하게 밝혔습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.5,
  "end": 849.94
 },
 {
  "input": "He first tried all sorts of different schemes involving organizing the bits into parts of a higher dimensional lattice and strange things like this.",
  "translatedText": "그는 먼저 비트를 더 높은 차원의 격자 부분으로 구성하는 것과 이와 같은 이상한 것들을 포함하는 모든 종류의 다양한 계획을 시도했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 850.62,
  "end": 857.78
 },
 {
  "input": "The idea that it might be possible to get parity checks to conspire in a way that spells out the position of an error only came to Hamming when he stepped back after a bunch of other analysis and asked, okay, what is the most efficient I could conceivably be about this?",
  "translatedText": "오류의 위치를 명시하는 방식으로 패리티 검사를 공모하여 음모를 꾸미는 것이 가능할 수도 있다는 생각은 Hamming이 여러 가지 다른 분석을 한 후 한 걸음 물러나서 &quot;알겠습니다. 제가 할 수 있는 가장 효율적인 방법은 무엇입니까? &quot;라고 물었을 때부터였습니다. 아마도 이것에 관한 것입니까?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 858.3,
  "end": 871.52
 },
 {
  "input": "He was also candid about how important it was that parity checks were already on his mind, which would have been way less common back in the 1940s than it is today.",
  "translatedText": "그는 또한 패리티 검사가 이미 그의 마음 속에 있다는 것이 얼마나 중요한지 솔직하게 말했습니다. 1940년대에는 오늘날보다 훨씬 덜 일반적이었을 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 872.62,
  "end": 881.22
 },
 {
  "input": "There are like half a dozen times throughout this book that he references the Louis Pasteur quote, luck favors a prepared mind.",
  "translatedText": "이 책 전체에 걸쳐 그는 루이 파스퇴르의 명언을 여섯 번이나 언급합니다. 행운은 준비된 마음을 선호합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.92,
  "end": 888.22
 },
 {
  "input": "Clever ideas often look deceptively simple in hindsight, which makes them easy to underappreciate.",
  "translatedText": "영리한 아이디어는 돌이켜보면 믿을 수 없을 만큼 단순해 보이는 경우가 많아 과소평가되기 쉽습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.32,
  "end": 894.3
 },
 {
  "input": "Right now my honest hope is that Hamming codes, or at least the possibility of such codes, feels almost obvious to you.",
  "translatedText": "지금 당장은 해밍 코드, 또는 적어도 그러한 코드의 가능성이 여러분에게 거의 명백하게 느껴지기를 진심으로 바랍니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.96,
  "end": 901.3
 },
 {
  "input": "But you shouldn't fool yourself into thinking that they actually are obvious, because they definitely aren't.",
  "translatedText": "하지만 그것들이 실제로 명백하다고 생각하도록 자신을 속여서는 안 됩니다. 왜냐하면 그것들은 확실히 그렇지 않기 때문입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 901.66,
  "end": 906.82
 },
 {
  "input": "Part of the reason that clever ideas look deceptively easy is that we only ever see the final result, cleaning up what was messy, never mentioning all of the wrong turns, underselling just how vast the space of explorable possibilities is at the start of a problem solving process, all of that.",
  "translatedText": "영리한 아이디어가 믿을 수 없을 정도로 쉬워 보이는 이유 중 하나는 우리가 최종 결과만 보고 지저분한 것을 정리하고 모든 잘못된 방향을 언급하지 않고 문제가 시작될 때 탐색 가능한 가능성의 공간이 얼마나 광대한지 과소평가하기 때문입니다. 해결 과정, 그 모든 것.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.88,
  "end": 922.86
 },
 {
  "input": "But this is true in general.",
  "translatedText": "그러나 이것은 일반적으로 사실입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 923.82,
  "end": 924.9
 },
 {
  "input": "I think for some special inventions, there's a second, deeper reason that we underappreciate them.",
  "translatedText": "저는 몇몇 특별한 발명품에 대해 우리가 그것을 과소평가하는 두 번째로 더 깊은 이유가 있다고 생각합니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.9,
  "end": 930.04
 },
 {
  "input": "Thinking of information in terms of bits had only really coalesced into a full theory by 1948, with Claude Shannon's seminal paper on information theory.",
  "translatedText": "정보를 비트 단위로 생각하는 것은 정보 이론에 관한 Claude Shannon의 중요한 논문을 통해 1948년에 비로소 완전한 이론으로 통합되었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.84,
  "end": 938.64
 },
 {
  "input": "This was essentially concurrent with when Hamming developed his algorithm.",
  "translatedText": "이는 Hamming이 자신의 알고리즘을 개발했을 때와 본질적으로 동시에 발생했습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 939.28,
  "end": 942.54
 },
 {
  "input": "This was the same foundational paper that showed, in a certain sense, that efficient error correction is always possible, no matter how high the probability of bit flips, at least in theory.",
  "translatedText": "이것은 적어도 이론적으로는 비트 플립 확률이 아무리 높더라도 어떤 의미에서는 효율적인 오류 수정이 항상 가능하다는 것을 보여주는 동일한 기본 논문이었습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.3,
  "end": 952.9
 },
 {
  "input": "Shannon and Hamming, by the way, shared an office in Bell Labs, despite working on very different things, which hardly seems coincidental here.",
  "translatedText": "그런데 Shannon과 Hamming은 매우 다른 일을 하고 있음에도 불구하고 Bell Labs에서 사무실을 공유했는데, 여기서는 우연이 아닌 것 같습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.7,
  "end": 961.16
 },
 {
  "input": "Fast forward several decades, and these days, many of us are so immersed in thinking about bits and information that it's easy to overlook just how distinct this way of thinking was.",
  "translatedText": "수십 년이 지난 지금, 우리 중 많은 사람들이 비트와 정보에 대한 생각에 너무 몰두하여 이러한 사고 방식이 얼마나 뚜렷한지 간과하기 쉽습니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.38,
  "end": 972.34
 },
 {
  "input": "Ironically, the ideas that most profoundly shape the ways that a future generation thinks will end up looking to that future generation simpler than they really are.",
  "translatedText": "아이러니하게도 미래 세대가 생각하는 방식을 가장 근본적으로 형성하는 아이디어는 결국 미래 세대를 실제보다 더 단순하게 보게 될 것입니다.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 973.1,
  "end": 982.26
 }
]