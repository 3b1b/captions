1
00:00:00,000 --> 00:00:02,560
Ich gehe davon aus, dass hier alle aus Teil 1 kommen.

2
00:00:03,060 --> 00:00:06,592
Wir sprachen über Hamming-Codes, eine Möglichkeit, einen Datenblock zu erstellen, 

3
00:00:06,592 --> 00:00:09,220
bei dem die meisten Bits eine sinnvolle Nachricht enthalten, 

4
00:00:09,220 --> 00:00:12,020
während einige andere als eine Art Redundanz fungieren, so dass, 

5
00:00:12,020 --> 00:00:15,553
wenn ein Bit umgedreht wird, entweder eine Nachricht entsteht Ob ein Bit oder ein 

6
00:00:15,553 --> 00:00:18,655
Redundanzbit, irgendetwas in diesem Block, ein Empfänger kann erkennen, 

7
00:00:18,655 --> 00:00:21,240
dass ein Fehler aufgetreten ist und wie er ihn beheben kann.

8
00:00:21,880 --> 00:00:24,056
Die dort vorgestellte Grundidee bestand darin, 

9
00:00:24,056 --> 00:00:27,160
mithilfe mehrerer Paritätsprüfungen binär bis zum Fehler zu suchen.

10
00:00:28,980 --> 00:00:31,627
In diesem Video bestand das Ziel darin, Hamming-Codes so 

11
00:00:31,627 --> 00:00:34,600
praktisch und wiederentdeckbar wie möglich erscheinen zu lassen.

12
00:00:35,180 --> 00:00:38,591
Aber wenn Sie anfangen, darüber nachzudenken, dies tatsächlich zu implementieren, 

13
00:00:38,591 --> 00:00:40,589
sei es in Software oder Hardware, kann es sein, 

14
00:00:40,589 --> 00:00:43,460
dass dieser Rahmen die Eleganz dieser Codes tatsächlich unterschätzt.

15
00:00:43,920 --> 00:00:47,154
Sie denken vielleicht, dass Sie einen Algorithmus schreiben müssen, 

16
00:00:47,154 --> 00:00:51,149
der alle möglichen Fehlerorte verfolgt und diese Gruppe bei jeder Prüfung halbiert, 

17
00:00:51,149 --> 00:00:53,480
aber in Wirklichkeit ist es viel, viel einfacher.

18
00:00:53,940 --> 00:00:56,440
Wenn Sie die Antworten auf die vier Paritätsprüfungen, 

19
00:00:56,440 --> 00:00:59,714
die wir im letzten Video durchgeführt haben, alle als Einsen und Nullen 

20
00:00:59,714 --> 00:01:03,261
anstelle von Ja und Nein vorlesen, wird die Position des Fehlers buchstäblich 

21
00:01:03,261 --> 00:01:04,080
binär dargestellt.

22
00:01:04,780 --> 00:01:08,074
Beispielsweise sieht die Zahl 7 im Binärformat wie 0111 aus, 

23
00:01:08,074 --> 00:01:11,260
was im Wesentlichen bedeutet, dass sie 4 plus 2 plus 1 ist.

24
00:01:12,540 --> 00:01:15,547
Und beachten Sie, wo sich die Position 7 befindet. 

25
00:01:15,547 --> 00:01:20,442
Sie betrifft zwar die erste unserer Paritätsgruppen und die zweite und die dritte, 

26
00:01:20,442 --> 00:01:21,740
aber nicht die letzte.

27
00:01:22,220 --> 00:01:25,293
Wenn man also die Ergebnisse dieser vier Prüfungen von unten nach oben liest, 

28
00:01:25,293 --> 00:01:27,540
lässt sich tatsächlich die Position des Fehlers erkennen.

29
00:01:28,320 --> 00:01:31,503
An Beispiel 7 gibt es nichts Besonderes, es funktioniert im Allgemeinen, 

30
00:01:31,503 --> 00:01:34,904
und dies macht die Logik zur Implementierung des gesamten Schemas in Hardware 

31
00:01:34,904 --> 00:01:35,820
erschreckend einfach.

32
00:01:37,240 --> 00:01:40,413
Wenn Sie nun sehen möchten, warum diese Magie geschieht, 

33
00:01:40,413 --> 00:01:43,866
nehmen Sie diese 16 Indexbezeichnungen für unsere Positionen, 

34
00:01:43,866 --> 00:01:48,320
aber anstatt sie in Basis 10 zu schreiben, schreiben wir sie alle in Binärform, 

35
00:01:48,320 --> 00:01:49,880
beginnend von 0000 bis 1111.

36
00:01:50,559 --> 00:01:54,427
Während wir diese binären Etiketten wieder in ihre Boxen stecken, möchte ich betonen, 

37
00:01:54,427 --> 00:01:57,800
dass sie sich von den Daten unterscheiden, die tatsächlich gesendet werden.

38
00:01:58,320 --> 00:02:00,478
Sie sind nichts weiter als eine konzeptionelle Bezeichnung, 

39
00:02:00,478 --> 00:02:03,500
die Ihnen und mir helfen soll, zu verstehen, woher die vier Paritätsgruppen stammen.

40
00:02:04,140 --> 00:02:06,894
Die Eleganz, alles, was wir betrachten, binär zu beschreiben, 

41
00:02:06,894 --> 00:02:09,294
wird möglicherweise durch die Verwirrung untergraben, 

42
00:02:09,294 --> 00:02:12,360
die entsteht, wenn alles, was wir betrachten, binär beschrieben wird.

43
00:02:13,020 --> 00:02:14,120
Es lohnt sich jedoch.

44
00:02:14,800 --> 00:02:18,661
Konzentrieren Sie Ihre Aufmerksamkeit nur auf das letzte Bit all dieser 

45
00:02:18,661 --> 00:02:23,220
Bezeichnungen und markieren Sie dann die Stellen, an denen das letzte Bit eine 1 ist.

46
00:02:24,240 --> 00:02:27,912
Was wir bekommen, ist die erste unserer vier Paritätsgruppen, was bedeutet, 

47
00:02:27,912 --> 00:02:31,681
dass Sie diese erste Prüfung so interpretieren können, dass Sie fragen: „Hey, 

48
00:02:31,681 --> 00:02:35,740
wenn es einen Fehler gibt, ist das letzte Bit an der Position dieses Fehlers eine 1?

49
00:02:38,200 --> 00:02:41,771
“ Wenn Sie sich auf das vorletzte Bit konzentrieren und alle Positionen markieren, 

50
00:02:41,771 --> 00:02:44,395
an denen das eine 1 ist, erhalten Sie in ähnlicher Weise die 

51
00:02:44,395 --> 00:02:46,160
zweite Paritätsgruppe aus unserem Schema.

52
00:02:46,740 --> 00:02:50,945
Mit anderen Worten, bei dieser zweiten Prüfung wird gefragt: „Hey, ich noch einmal: 

53
00:02:50,945 --> 00:02:54,500
Wenn ein Fehler vorliegt, ist das vorletzte Bit dieser Position eine 1?

54
00:02:55,760 --> 00:02:56,900
“ Und so weiter.

55
00:02:57,220 --> 00:03:00,172
Die dritte Paritätsprüfung deckt jede Position ab, 

56
00:03:00,172 --> 00:03:04,050
deren drittletztes Bit eingeschaltet ist, und die letzte deckt die 

57
00:03:04,050 --> 00:03:08,740
letzten acht Positionen ab, also diejenigen, deren höchstwertiges Bit eine 1 ist.

58
00:03:09,740 --> 00:03:13,833
Alles, was wir zuvor getan haben, ist dasselbe wie die Beantwortung dieser vier Fragen, 

59
00:03:13,833 --> 00:03:17,740
was wiederum dasselbe ist, als würde man eine Position im Binärsystem buchstabieren.

60
00:03:19,620 --> 00:03:21,480
Ich hoffe, das macht zwei Dinge klarer.

61
00:03:22,040 --> 00:03:25,185
Die erste besteht darin, wie man systematisch auf Blockgrößen verallgemeinert, 

62
00:03:25,185 --> 00:03:26,460
die größere Zweierpotenzen sind.

63
00:03:26,960 --> 00:03:30,000
Wenn zur Beschreibung jeder Position mehr Bits erforderlich sind, 

64
00:03:30,000 --> 00:03:32,718
beispielsweise sechs Bits zur Beschreibung von 64 Stellen, 

65
00:03:32,718 --> 00:03:36,680
dann gibt Ihnen jedes dieser Bits eine der Paritätsgruppen, die wir überprüfen müssen.

66
00:03:38,400 --> 00:03:40,368
Diejenigen von Ihnen, die das Schachbretträtsel gesehen haben, 

67
00:03:40,368 --> 00:03:43,180
das ich mit Matt Parker gemacht habe, werden das alles vielleicht überaus vertraut finden.

68
00:03:43,660 --> 00:03:46,325
Es handelt sich um dieselbe Kernlogik, löst jedoch ein anderes 

69
00:03:46,325 --> 00:03:48,780
Problem und wird auf ein 64-Felder-Schachbrett angewendet.

70
00:03:49,880 --> 00:03:52,195
Als Zweites hoffe ich, dass dadurch klar wird, 

71
00:03:52,195 --> 00:03:55,989
warum unsere Paritätsbits an den Positionen sitzen, die Zweierpotenzen sind, 

72
00:03:55,989 --> 00:03:57,320
zum Beispiel 1, 2, 4 und 8.

73
00:03:58,000 --> 00:04:01,043
Dies sind die Positionen, bei deren binärer Darstellung 

74
00:04:01,043 --> 00:04:03,000
nur ein einzelnes Bit aktiviert ist.

75
00:04:03,600 --> 00:04:06,640
Das bedeutet, dass jedes dieser Paritätsbits innerhalb 

76
00:04:06,640 --> 00:04:09,460
einer und nur einer der vier Paritätsgruppen liegt.

77
00:04:12,040 --> 00:04:14,572
Sie können dies auch an größeren Beispielen sehen, 

78
00:04:14,572 --> 00:04:18,297
bei denen jedes Paritätsbit praktischerweise nur eine der Gruppen berührt, 

79
00:04:18,297 --> 00:04:19,339
egal wie groß es ist.

80
00:04:25,600 --> 00:04:27,815
Sobald Sie verstehen, dass diese Paritätsprüfungen, 

81
00:04:27,815 --> 00:04:29,903
auf die wir uns so viel Zeit konzentriert haben, 

82
00:04:29,903 --> 00:04:32,033
nichts anderes als eine clevere Möglichkeit sind, 

83
00:04:32,033 --> 00:04:34,590
die Position eines Fehlers im Binärsystem zu buchstabieren, 

84
00:04:34,590 --> 00:04:38,212
können wir eine Verbindung zu einer anderen Denkweise über Hamming herstellen Codes, 

85
00:04:38,212 --> 00:04:41,876
die wohl viel einfacher und eleganter sind und im Grunde mit einer einzigen Codezeile 

86
00:04:41,876 --> 00:04:43,240
niedergeschrieben werden können.

87
00:04:43,660 --> 00:04:45,500
Es basiert auf der XOR-Funktion.

88
00:04:46,940 --> 00:04:50,220
XOR steht für diejenigen unter Ihnen, die es nicht wissen, für exklusiv oder.

89
00:04:50,780 --> 00:04:54,675
Wenn Sie die XOR-Verknüpfung zweier Bits verwenden, wird eine 1 zurückgegeben, 

90
00:04:54,675 --> 00:04:57,239
wenn eines dieser Bits aktiviert ist, nicht jedoch, 

91
00:04:57,239 --> 00:04:59,360
wenn beide aktiviert oder deaktiviert sind.

92
00:05:00,100 --> 00:05:02,980
Anders ausgedrückt ist es die Parität dieser beiden Bits.

93
00:05:03,540 --> 00:05:06,760
Als Mathematiker betrachte ich es lieber als Addition Mod 2.

94
00:05:07,360 --> 00:05:10,852
Wir sprechen auch häufig von der XOR-Verknüpfung zweier verschiedener Bitfolgen, 

95
00:05:10,852 --> 00:05:13,440
die dies grundsätzlich Komponente für Komponente durchführt.

96
00:05:13,680 --> 00:05:15,720
Es ist wie eine Ergänzung, die man aber nie trägt.

97
00:05:16,500 --> 00:05:18,612
Auch hier gilt: Wer eher mathematisch veranlagt ist, 

98
00:05:18,612 --> 00:05:21,642
könnte sich dies lieber so vorstellen, als würde man zwei Vektoren addieren 

99
00:05:21,642 --> 00:05:22,480
und Mod 2 reduzieren.

100
00:05:23,500 --> 00:05:28,088
Wenn Sie jetzt etwas Python öffnen und die Caret-Operation zwischen zwei ganzen Zahlen 

101
00:05:28,088 --> 00:05:32,623
anwenden, geschieht Folgendes, außer auf die Bitdarstellungen dieser Zahlen unter der 

102
00:05:32,623 --> 00:05:32,940
Haube.

103
00:05:34,960 --> 00:05:39,037
Der entscheidende Punkt für Sie und mich ist, dass die XOR-Verknüpfung vieler 

104
00:05:39,037 --> 00:05:41,912
verschiedener Bitfolgen effektiv eine Möglichkeit ist, 

105
00:05:41,912 --> 00:05:45,571
die Parodien einer Reihe separater Gruppen, wie etwa bei den Spalten, 

106
00:05:45,571 --> 00:05:47,140
auf einen Schlag zu berechnen.

107
00:05:51,260 --> 00:05:53,911
Dies gibt uns eine ziemlich schicke Möglichkeit, uns vorzustellen, 

108
00:05:53,911 --> 00:05:56,642
dass die mehreren Paritätsprüfungen unseres Hamming-Code-Algorithmus 

109
00:05:56,642 --> 00:05:58,780
alle in einer einzigen Operation zusammengefasst sind.

110
00:05:59,479 --> 00:06:02,180
Obwohl es auf den ersten Blick ganz anders aussieht.

111
00:06:02,820 --> 00:06:07,446
Schreiben Sie konkret die 16 Positionen binär auf, wie wir es zuvor getan haben, 

112
00:06:07,446 --> 00:06:12,301
und markieren Sie nun die Positionen, an denen das Nachrichtenbit auf 1 gesetzt ist, 

113
00:06:12,301 --> 00:06:17,100
und sammeln Sie diese Positionen dann in einer großen Spalte und nehmen Sie das XOR.

114
00:06:19,260 --> 00:06:21,571
Sie können sich wahrscheinlich vorstellen, dass die 4 Bits, 

115
00:06:21,571 --> 00:06:24,653
die sich dadurch unten befinden, die gleichen sind wie die 4 Paritätsprüfungen, 

116
00:06:24,653 --> 00:06:27,774
die wir kennen und lieben gelernt haben, aber nehmen Sie sich einen Moment Zeit, 

117
00:06:27,774 --> 00:06:29,200
um darüber nachzudenken, warum genau.

118
00:06:32,220 --> 00:06:35,830
In dieser letzten Spalte werden beispielsweise alle Positionen gezählt, 

119
00:06:35,830 --> 00:06:39,842
deren letztes Bit eine 1 ist. Da wir uns jedoch bereits auf die hervorgehobenen 

120
00:06:39,842 --> 00:06:44,255
Positionen beschränken, zählt sie effektiv, wie viele hervorgehobene Positionen aus der 

121
00:06:44,255 --> 00:06:45,760
ersten Paritätsgruppe stammen.

122
00:06:46,240 --> 00:06:46,800
Ist das sinnvoll?

123
00:06:49,080 --> 00:06:52,701
Ebenso zählt die nächste Spalte, wie viele Positionen sich in der 

124
00:06:52,701 --> 00:06:55,390
zweiten Paritätsgruppe befinden, die Positionen, 

125
00:06:55,390 --> 00:07:00,000
deren vorletztes Bit eine 1 ist und die ebenfalls hervorgehoben sind, und so weiter.

126
00:07:00,260 --> 00:07:03,164
Es ist wirklich nur ein kleiner Perspektivwechsel in Bezug auf dasselbe, 

127
00:07:03,164 --> 00:07:03,960
was wir getan haben.

128
00:07:07,760 --> 00:07:09,600
Und so wissen Sie, wohin es von hier aus führt.

129
00:07:10,000 --> 00:07:13,728
Der Absender ist dafür verantwortlich, einige der speziellen Paritätsbits umzuschalten, 

130
00:07:13,728 --> 00:07:15,720
um sicherzustellen, dass die Summe 0000 ergibt.

131
00:07:15,720 --> 00:07:21,076
Wenn wir es nun so haben, können wir wirklich gut darüber nachdenken, 

132
00:07:21,076 --> 00:07:27,580
warum diese vier resultierenden Bits unten direkt die Position eines Fehlers angeben.

133
00:07:28,460 --> 00:07:31,860
Nehmen wir an, ein Bit in diesem Block wird von 0 auf 1 umgeschaltet.

134
00:07:32,600 --> 00:07:36,300
Das bedeutet, dass die Position dieses Bits nun in die gesamte 

135
00:07:36,300 --> 00:07:39,942
XOR-Verknüpfung einbezogen wird, wodurch sich die Summe von 0 

136
00:07:39,942 --> 00:07:43,820
in diesen neu einbezogenen Wert, die Position des Fehlers, ändert.

137
00:07:44,460 --> 00:07:46,740
Etwas weniger offensichtlich gilt das Gleiche, 

138
00:07:46,740 --> 00:07:49,360
wenn ein Fehler auftritt, der eine 1 in eine 0 ändert.

139
00:07:50,180 --> 00:07:53,656
Sehen Sie, wenn Sie eine Bitfolge zweimal addieren, ist das dasselbe, 

140
00:07:53,656 --> 00:07:57,580
als ob sie gar nicht vorhanden wäre, denn in dieser Welt ist 1 plus 1 gleich 0.

141
00:07:57,580 --> 00:08:01,251
Das Hinzufügen einer Kopie dieser Position zur Gesamtsumme 

142
00:08:01,251 --> 00:08:04,300
hat also den gleichen Effekt wie das Verschieben.

143
00:08:05,160 --> 00:08:07,752
Und dieser Effekt besteht wiederum darin, dass das 

144
00:08:07,752 --> 00:08:10,700
Gesamtergebnis hier unten die Position des Fehlers angibt.

145
00:08:13,039 --> 00:08:15,749
Um zu veranschaulichen, wie elegant das ist, möchte ich die 

146
00:08:15,749 --> 00:08:18,640
eine Zeile Python-Code zeigen, auf die ich zuvor verwiesen habe 

147
00:08:18,640 --> 00:08:21,440
und die fast die gesamte Logik auf der Empfängerseite erfasst.

148
00:08:22,080 --> 00:08:25,845
Wir beginnen damit, ein zufälliges Array aus 16 Einsen und Nullen zu erstellen, 

149
00:08:25,845 --> 00:08:28,951
um den Datenblock zu simulieren, und ich gebe ihm den Namen Bits, 

150
00:08:28,951 --> 00:08:32,387
aber in der Praxis würden wir das natürlich von einem Absender erhalten, 

151
00:08:32,387 --> 00:08:35,870
und statt dessen Da es zufällig ist, würde es 11 Datenbits zusammen mit 5 

152
00:08:35,870 --> 00:08:37,000
Paritätsbits übertragen.

153
00:08:37,000 --> 00:08:41,744
Wenn ich die Funktion enumerateBits aufrufe, verbindet sie jedes 

154
00:08:41,744 --> 00:08:47,000
dieser Bits mit einem entsprechenden Index, in diesem Fall von 0 bis 15.

155
00:08:48,180 --> 00:08:52,377
Wenn wir dann also eine Liste erstellen, die alle diese Paare durchläuft, 

156
00:08:52,377 --> 00:08:56,972
Paare, die wie i aussehen, und dann nur den i-Wert, nur den Index, herausziehen, 

157
00:08:56,972 --> 00:09:01,340
ist das nicht so aufregend, wir bekommen einfach die Indizes 0 bis 15 zurück.

158
00:09:01,680 --> 00:09:05,063
Aber wenn wir die Bedingung hinzufügen, dies nur zu tun, 

159
00:09:05,063 --> 00:09:09,989
wenn das Bit eine 1 und keine 0 ist, dann werden nur die Positionen herausgezogen, 

160
00:09:09,989 --> 00:09:12,660
an denen das entsprechende Bit aktiviert ist.

161
00:09:13,380 --> 00:09:20,360
In diesem Fall sieht es so aus, als wären diese Positionen 0, 4, 6, 9 usw.

162
00:09:20,720 --> 00:09:24,765
Was wir wollen, ist, alle diese Positionen, die Positionen der eingeschalteten Bits, 

163
00:09:24,765 --> 00:09:27,240
zusammenzufassen und sie dann per XOR zu verknüpfen.

164
00:09:29,180 --> 00:09:33,220
Um dies in Python zu tun, möchte ich zunächst einige hilfreiche Funktionen importieren.

165
00:09:33,900 --> 00:09:36,468
Auf diese Weise können wir Reduce() für diese Liste aufrufen 

166
00:09:36,468 --> 00:09:38,700
und die XOR-Funktion verwenden, um sie zu reduzieren.

167
00:09:39,100 --> 00:09:42,680
Dies frisst sich im Grunde durch die Liste und nimmt dabei auch XORs mit.

168
00:09:44,800 --> 00:09:47,591
Wenn Sie möchten, können Sie diese XOR-Funktion explizit ausschreiben, 

169
00:09:47,591 --> 00:09:49,440
ohne sie von irgendwoher importieren zu müssen.

170
00:09:51,940 --> 00:09:56,815
Im Moment sieht es also so aus, als ob wir, wenn wir dies auf unserem Zufallsblock 

171
00:09:56,815 --> 00:10:01,280
von 16 Bits tun, 9 zurückgeben, was der binären Darstellung 1001 entspricht.

172
00:10:01,980 --> 00:10:04,921
Wir werden es hier nicht tun, aber Sie könnten eine Funktion schreiben, 

173
00:10:04,921 --> 00:10:07,249
bei der der Absender diese binäre Darstellung verwendet, 

174
00:10:07,249 --> 00:10:10,517
um die vier Paritätsbits nach Bedarf zu setzen und diesen Block letztendlich in 

175
00:10:10,517 --> 00:10:14,071
einen Zustand zu bringen, in dem die Ausführung dieser Codezeile auf der vollständigen 

176
00:10:14,071 --> 00:10:15,460
Liste der Bits zurückkehrt eine 0.

177
00:10:16,080 --> 00:10:20,100
Dies würde als gut vorbereiteter Block angesehen werden.

178
00:10:20,100 --> 00:10:23,202
Das Coole ist, dass, wenn wir eines der Bits in dieser Liste 

179
00:10:23,202 --> 00:10:26,711
umschalten und so einen zufälligen Fehler durch Rauschen simulieren, 

180
00:10:26,711 --> 00:10:30,220
dieser Fehler ausgegeben wird, wenn Sie dieselbe Codezeile ausführen.

181
00:10:30,960 --> 00:10:31,520
Ist das nicht nett?

182
00:10:31,820 --> 00:10:34,508
Sie könnten diesen Block aus heiterem Himmel bekommen, 

183
00:10:34,508 --> 00:10:37,588
diese einzelne Zeile darauf ausführen und er würde automatisch 

184
00:10:37,588 --> 00:10:41,060
die Position eines Fehlers ausspucken, oder eine 0, wenn es keinen gab.

185
00:10:42,500 --> 00:10:44,840
Und die Größe 16 ist hier nichts Besonderes.

186
00:10:44,840 --> 00:10:47,298
Die gleiche Codezeile würde funktionieren, wenn 

187
00:10:47,298 --> 00:10:49,860
Sie eine Liste mit beispielsweise 256 Bits hätten.

188
00:10:51,880 --> 00:10:55,413
Es erübrigt sich zu erwähnen, dass hier noch mehr Code geschrieben werden muss, 

189
00:10:55,413 --> 00:10:58,902
etwa die Durchführung der Metaparitätsprüfung zur Erkennung von 2-Bit-Fehlern, 

190
00:10:58,902 --> 00:11:02,611
aber die Idee ist, dass fast die gesamte Kernlogik unseres Schemas auf eine einzige 

191
00:11:02,611 --> 00:11:03,760
XOR-Reduktion hinausläuft.

192
00:11:06,120 --> 00:11:09,195
Nun, je nachdem, wie gut Sie mit Binär- und XOR-Funktionen und Software 

193
00:11:09,195 --> 00:11:12,355
im Allgemeinen vertraut sind, finden Sie diese Perspektive möglicherweise 

194
00:11:12,355 --> 00:11:15,643
etwas verwirrend oder so viel eleganter und einfacher, dass Sie sich fragen, 

195
00:11:15,643 --> 00:11:18,420
warum wir nicht gleich von Anfang an damit begonnen haben -gehen.

196
00:11:19,140 --> 00:11:21,999
Vereinfacht gesagt lässt sich die Perspektive der Mehrfachparitätsprüfung 

197
00:11:21,999 --> 00:11:25,322
leichter in Betracht ziehen, wenn man Hamming-Codes direkt in Hardware implementiert, 

198
00:11:25,322 --> 00:11:28,027
und die XOR-Perspektive lässt sich am einfachsten in Betracht ziehen, 

199
00:11:28,027 --> 00:11:30,500
wenn man sie in Software von einer höheren Ebene aus durchführt.

200
00:11:31,360 --> 00:11:35,013
Die erste Methode lässt sich am einfachsten per Hand ausführen, und ich denke, 

201
00:11:35,013 --> 00:11:38,667
sie eignet sich besser dazu, die dem Ganzen zugrunde liegende Kernintuition zu 

202
00:11:38,667 --> 00:11:42,460
vermitteln, nämlich dass die zum Auffinden eines einzelnen Fehlers erforderlichen 

203
00:11:42,460 --> 00:11:45,790
Informationen mit dem Protokoll der Blockgröße in Zusammenhang stehen , 

204
00:11:45,790 --> 00:11:48,334
oder mit anderen Worten, es wächst um jeweils ein Bit, 

205
00:11:48,334 --> 00:11:50,000
wenn sich die Blockgröße verdoppelt.

206
00:11:51,020 --> 00:11:53,740
Die relevante Tatsache hierbei ist, dass diese Informationen 

207
00:11:53,740 --> 00:11:56,060
direkt mit der benötigten Redundanz korrespondieren.

208
00:11:56,660 --> 00:11:58,909
Das ist es, was den meisten Menschen zuwiderläuft, 

209
00:11:58,909 --> 00:12:02,570
wenn sie zum ersten Mal darüber nachdenken, eine Nachricht fehlersicher zu machen, 

210
00:12:02,570 --> 00:12:06,540
wobei ihnen normalerweise als erstes in den Sinn kommt, die gesamte Nachricht zu kopieren.

211
00:12:07,500 --> 00:12:09,867
Und dann gibt es übrigens noch eine ganz andere Art und Weise, 

212
00:12:09,867 --> 00:12:13,210
wie man manchmal Hamming-Codes präsentiert, bei denen man die Nachricht mit einer großen 

213
00:12:13,210 --> 00:12:14,000
Matrix multipliziert.

214
00:12:14,670 --> 00:12:17,641
Es ist ganz nett, weil es es mit der breiteren Familie der linearen 

215
00:12:17,641 --> 00:12:21,486
Codes in Verbindung bringt, aber ich denke, das vermittelt kaum eine Vorstellung davon, 

216
00:12:21,486 --> 00:12:23,060
woher es kommt oder wie es skaliert.

217
00:12:25,200 --> 00:12:27,492
Apropos Skalierung: Sie werden vielleicht feststellen, 

218
00:12:27,492 --> 00:12:31,160
dass die Effizienz dieses Schemas nur dann besser wird, wenn wir die Blockgröße erhöhen.

219
00:12:35,000 --> 00:12:38,749
Wir haben beispielsweise gesehen, dass Sie bei 256 Bit nur 3 % dieses 

220
00:12:38,749 --> 00:12:42,660
Speicherplatzes für Redundanz nutzen, und von da an wird es immer besser.

221
00:12:43,300 --> 00:12:45,562
Wenn die Anzahl der Paritätsbits nach und nach zunimmt, 

222
00:12:45,562 --> 00:12:47,340
verdoppelt sich die Blockgröße immer weiter.

223
00:12:49,000 --> 00:12:52,703
Und wenn Sie das auf die Spitze treiben, könnten Sie einen Block mit, sagen wir, 

224
00:12:52,703 --> 00:12:56,224
einer Million Bits haben, in dem Sie mit Ihren Paritätsprüfungen im wahrsten 

225
00:12:56,224 --> 00:13:00,020
Sinne des Wortes 20 Fragen abspielen würden, und der nur 21 Paritätsbits verwendet.

226
00:13:00,740 --> 00:13:03,018
Und wenn man einen Schritt zurücktritt und darüber nachdenkt, 

227
00:13:03,018 --> 00:13:05,737
wie man sich eine Million Bits ansieht und einen einzelnen Fehler findet, 

228
00:13:05,737 --> 00:13:07,060
fühlt sich das wirklich verrückt an.

229
00:13:08,199 --> 00:13:11,189
Das Problem besteht natürlich darin, dass mit einem größeren 

230
00:13:11,189 --> 00:13:15,111
Block die Wahrscheinlichkeit steigt, mehr als ein oder zwei Bitfehler zu sehen, 

231
00:13:15,111 --> 00:13:17,660
und Hamming-Codes verarbeiten nichts darüber hinaus.

232
00:13:18,320 --> 00:13:21,094
In der Praxis möchten Sie also die richtige Größe finden, 

233
00:13:21,094 --> 00:13:24,300
damit die Wahrscheinlichkeit zu vieler Bit-Flips nicht zu hoch ist.

234
00:13:26,600 --> 00:13:30,015
Außerdem kommt es in der Praxis dazu, dass Fehler in kleinen Schüben auftauchen, 

235
00:13:30,015 --> 00:13:33,642
die einen einzelnen Block völlig ruinieren würden. Daher besteht eine gängige Taktik, 

236
00:13:33,642 --> 00:13:37,016
um einen Schwall von Fehlern auf viele verschiedene Blöcke zu verteilen, darin, 

237
00:13:37,016 --> 00:13:38,998
diese Blöcke auf diese Weise zu verschachteln, 

238
00:13:38,998 --> 00:13:40,980
bevor sie entstehen versendet oder gespeichert.

239
00:13:45,580 --> 00:13:48,218
Andererseits wird vieles davon durch modernere Codes, 

240
00:13:48,218 --> 00:13:51,296
wie den weitaus häufiger verwendeten Reed-Solomon-Algorithmus, 

241
00:13:51,296 --> 00:13:54,618
völlig hinfällig, der Burst-Fehler besonders gut verarbeitet und so 

242
00:13:54,618 --> 00:13:58,820
abgestimmt werden kann, dass er einer größeren Anzahl von Fehlern pro Block standhält.

243
00:13:59,360 --> 00:14:01,340
Aber das ist ein Thema für ein anderes Mal.

244
00:14:02,500 --> 00:14:06,195
In seinem Buch „The Art of Doing Science and Engineering“ spricht Hamming 

245
00:14:06,195 --> 00:14:09,940
wunderbar offen darüber, wie kompliziert seine Entdeckung dieses Codes war.

246
00:14:10,620 --> 00:14:13,206
Er probierte zunächst alle möglichen unterschiedlichen Schemata aus, 

247
00:14:13,206 --> 00:14:15,755
bei denen es darum ging, die Bits in Teile eines höherdimensionalen 

248
00:14:15,755 --> 00:14:17,780
Gitters zu organisieren, und seltsame Dinge wie diese.

249
00:14:18,300 --> 00:14:21,524
Die Idee, dass es möglich sein könnte, Paritätsprüfungen auf eine Art und Weise 

250
00:14:21,524 --> 00:14:24,869
zusammenzuführen, die die Position eines Fehlers deutlich macht, kam Hamming erst, 

251
00:14:24,869 --> 00:14:28,295
als er nach einer Reihe anderer Analysen einen Schritt zurücktrat und fragte: „Okay, 

252
00:14:28,295 --> 00:14:31,520
was ist das effizienteste, was ich konnte. “ könnte es sein, dass es darum geht?

253
00:14:32,620 --> 00:14:37,510
Er äußerte auch offen, wie wichtig es sei, dass er bereits an Paritätsprüfungen denke, 

254
00:14:37,510 --> 00:14:41,220
die in den 1940er Jahren weitaus seltener gewesen wären als heute.

255
00:14:41,920 --> 00:14:45,023
In diesem Buch verweist er ungefähr ein halbes Dutzend Mal auf das 

256
00:14:45,023 --> 00:14:48,220
Zitat von Louis Pasteur: „Glück begünstigt einen vorbereiteten Geist.

257
00:14:49,320 --> 00:14:51,987
“ Clevere Ideen wirken im Nachhinein oft täuschend einfach, 

258
00:14:51,987 --> 00:14:54,300
was dazu führt, dass sie leicht unterschätzt werden.

259
00:14:54,960 --> 00:14:58,219
Im Moment ist meine ehrliche Hoffnung, dass Hamming-Codes oder zumindest 

260
00:14:58,219 --> 00:15:01,300
die Möglichkeit solcher Codes für Sie fast offensichtlich erscheinen.

261
00:15:01,660 --> 00:15:03,668
Aber Sie sollten sich nicht der Illusion hingeben, 

262
00:15:03,668 --> 00:15:06,820
dass sie tatsächlich offensichtlich sind, denn das ist definitiv nicht der Fall.

263
00:15:07,880 --> 00:15:11,317
Dass kluge Ideen täuschend einfach aussehen, liegt zum Teil daran, 

264
00:15:11,317 --> 00:15:14,549
dass wir immer nur das Endergebnis sehen, das Chaos aufräumen, 

265
00:15:14,549 --> 00:15:17,627
niemals alle falschen Wendungen erwähnen und unterschätzen, 

266
00:15:17,627 --> 00:15:21,423
wie groß der Raum an erforschbaren Möglichkeiten am Anfang eines Problems 

267
00:15:21,423 --> 00:15:22,860
ist Lösungsprozess, all das.

268
00:15:23,820 --> 00:15:24,900
Aber das gilt im Allgemeinen.

269
00:15:24,900 --> 00:15:27,783
Ich denke, dass es bei einigen besonderen Erfindungen einen zweiten, 

270
00:15:27,783 --> 00:15:30,040
tieferen Grund dafür gibt, dass wir sie unterschätzen.

271
00:15:30,840 --> 00:15:33,397
Das Denken von Information in Form von Bits hatte sich erst 

272
00:15:33,397 --> 00:15:35,613
1948 mit Claude Shannons bahnbrechender Arbeit über 

273
00:15:35,613 --> 00:15:38,640
Informationstheorie wirklich zu einer vollständigen Theorie verdichtet.

274
00:15:39,280 --> 00:15:40,962
Dies geschah im Wesentlichen zeitgleich mit der 

275
00:15:40,962 --> 00:15:42,540
Entwicklung seines Algorithmus durch Hamming.

276
00:15:43,300 --> 00:15:46,764
Dabei handelte es sich um dieselbe Grundlagenarbeit, die in gewisser Weise zeigte, 

277
00:15:46,764 --> 00:15:49,853
dass eine effiziente Fehlerkorrektur immer möglich ist, unabhängig davon, 

278
00:15:49,853 --> 00:15:52,900
wie hoch die Wahrscheinlichkeit von Bit-Flips ist, zumindest theoretisch.

279
00:15:53,700 --> 00:15:56,957
Shannon und Hamming teilten sich übrigens ein Büro in den Bell Labs, 

280
00:15:56,957 --> 00:16:01,160
obwohl sie an sehr unterschiedlichen Dingen arbeiteten, was hier kaum zufällig erscheint.

281
00:16:02,380 --> 00:16:07,190
Mehrere Jahrzehnte später sind viele von uns so sehr in das Nachdenken über Bits und 

282
00:16:07,190 --> 00:16:10,076
Informationen vertieft, dass man leicht übersieht, 

283
00:16:10,076 --> 00:16:12,340
wie unterschiedlich diese Denkweise war.

284
00:16:13,100 --> 00:16:15,852
Ironischerweise werden die Ideen, die die Denkweise einer 

285
00:16:15,852 --> 00:16:18,890
zukünftigen Generation am tiefsten prägen, für diese zukünftige 

286
00:16:18,890 --> 00:16:22,260
Generation letztendlich einfacher erscheinen, als sie tatsächlich sind.

