1
00:00:00,000 --> 00:00:02,560
ここにいる皆さんはパート1から来ていると思います。

2
00:00:03,060 --> 00:00:05,127
私たちはハミング コードについて話していました。

3
00:00:05,127 --> 00:00:06,764
 これは、ほとんどのビットが意味のあ 

4
00:00:06,764 --> 00:00:09,005
るメッセージを運ぶデータ ブロックを作成する方法であ

5
00:00:09,005 --> 00:00:10,383
り、他のいくつかのビットは一種 

6
00:00:10,383 --> 00:00:12,623
の冗長性として機能し、ビットが反転した場合、メッセー

7
00:00:12,623 --> 00:00:15,122
ジが送信されるか、メッセージが 送信されるかが決まります。

8
00:00:15,122 --> 00:00:17,707
 ビットや冗長ビットなど、このブロック内のあらゆるものによ 

9
00:00:17,707 --> 00:00:19,947
って、受信機はエラーがあったことと、それを修正する方

10
00:00:19,947 --> 00:00:21,240
法を識別できるようになります。

11
00:00:21,880 --> 00:00:24,564
そこで提示された基本的なアイデアは、複数のパリティ チェッ 

12
00:00:24,564 --> 00:00:27,160
クを使用してエラーに至るまでバイナリ検索を行う方法でした。

13
00:00:28,980 --> 00:00:31,902
このビデオの目標は、ハミング コードをできる限り実 

14
00:00:31,902 --> 00:00:34,600
際に操作でき、再発見できるようにすることでした。

15
00:00:35,180 --> 00:00:37,227
しかし、これをソフトウェアまたはハードウェアで

16
00:00:37,227 --> 00:00:39,364
実際に実装することを考え始めると、その枠組みに 

17
00:00:39,364 --> 00:00:41,412
よって、これらのコードが実際にどれほどエレガン

18
00:00:41,412 --> 00:00:43,460
トであるかが実際に理解できないかもしれません。

19
00:00:43,920 --> 00:00:47,216
考えられるすべてのエラー位置を追跡し、各チェックでそのグル 

20
00:00:47,216 --> 00:00:50,403
ープを半分に分割するアルゴリズムを作成する必要があると思 

21
00:00:50,403 --> 00:00:53,480
うかもしれませんが、実際にはそれよりもはるかに簡単です。

22
00:00:53,940 --> 00:00:56,244
前回のビデオで行った 4 つのパリティ 

23
00:00:56,244 --> 00:00:59,125
チェックの答えを、すべて「はい」と「いいえ」では 

24
00:00:59,125 --> 00:01:02,466
なく「1」と「0」として読み上げると、文字通りエラーの位置

25
00:01:02,466 --> 00:01:04,080
が 2 進数で表示されます。

26
00:01:04,780 --> 00:01:06,904
たとえば、2 進数の 7 は 0111 

27
00:01:06,904 --> 00:01:09,029
のように見え、本質的 には 4 プラス 

28
00:01:09,029 --> 00:01:11,260
2 プラス 1 であることを示しています。

29
00:01:12,540 --> 00:01:15,787
位置 7 がどこに位置するかに注目してください。

30
00:01:15,787 --> 00:01:18,763
 パリティ グループ の最初、2 番目、3 

31
00:01:18,763 --> 00:01:21,740
番目には影響しますが、最後には影響しません。

32
00:01:22,220 --> 00:01:24,990
したがって、これら 4 つのチェックの結果を下か 

33
00:01:24,990 --> 00:01:27,540
ら上に読むと、エラーの位置が明らかになります。

34
00:01:28,320 --> 00:01:30,432
例 7 には特別なことは何もありません。

35
00:01:30,432 --> 00:01:32,228
 これは一般的に機能し、ハードウ 

36
00:01:32,228 --> 00:01:34,658
ェアでスキーム全体を実装するためのロジックが驚

37
00:01:34,658 --> 00:01:35,820
くほど単純になります。

38
00:01:37,240 --> 00:01:40,200
この魔法がなぜ起こるのかを知りたい場合は、これらの 

39
00:01:40,200 --> 00:01:43,389
16 個のインデック ス ラベルを位置に取ってください。

40
00:01:43,389 --> 00:01:46,691
 ただし、それらを 10 進数で書く代わ りに、0000 

41
00:01:46,691 --> 00:01:49,880
から 1111 までのバイナリですべて書いてみましょう。

42
00:01:50,559 --> 00:01:54,319
これらのバイナリ ラベルを箱に戻すときに、実際に送信 

43
00:01:54,319 --> 00:01:57,800
されるデータとは区別されることを強調しておきます。

44
00:01:58,320 --> 00:02:01,009
これらは、4 つのパリティ グループがどこから来たの 

45
00:02:01,009 --> 00:02:03,500
かを理解するのに役立つ概念的なラベルにすぎません。

46
00:02:04,140 --> 00:02:06,880
私たちが見ているものすべてがバイナリで記述されることの

47
00:02:06,880 --> 00:02:09,620
優雅さは、おそらく、私たち が見ているものすべてがバイ

48
00:02:09,620 --> 00:02:12,360
ナリで記述されることの混乱によって損なわれるでしょう。

49
00:02:13,020 --> 00:02:14,120
ただし、それだけの価値はあります。

50
00:02:14,800 --> 00:02:19,095
これらすべてのラベルの最後のビットに注目し、その 

51
00:02:19,095 --> 00:02:23,220
最後のビットが 1 である位置を強調表示します。

52
00:02:24,240 --> 00:02:26,117
得られるのは 4 つのパリティ 

53
00:02:26,117 --> 00:02:28,229
グループの最初のグループです。 つ 

54
00:02:28,229 --> 00:02:31,046
まり、最初のチェックは、エラーがある場合、そのエ

55
00:02:31,046 --> 00:02:33,862
ラーの位置にある 最後のビットは 1 ですか? 

56
00:02:33,862 --> 00:02:35,740
という質問であると解釈できます。

57
00:02:38,200 --> 00:02:40,959
同様に、最後から 2 番目のビットに注目し、それが 

58
00:02:40,959 --> 00:02:43,931
1 であるすべての位置 を強調表示すると、スキームから 

59
00:02:43,931 --> 00:02:46,160
2 番目のパリティ グループが得られます。

60
00:02:46,740 --> 00:02:49,288
言い換えれば、その 2 番目のチェックでは、

61
00:02:49,288 --> 00:02:51,836
エラーがある場合、その 位置の最後から 2 

62
00:02:51,836 --> 00:02:54,500
番目のビットは 1 ですか? と尋ねています。

63
00:02:55,760 --> 00:02:56,900
等々。

64
00:02:57,220 --> 00:02:59,980
3 番目のパリティ チェックは、最後から 3 

65
00:02:59,980 --> 00:03:03,100
番目のビットがオンになっているすべての位置をカバー 

66
00:03:03,100 --> 00:03:05,980
し、最後のパリティ チェックは、最上位ビットが 

67
00:03:05,980 --> 00:03:08,740
1 である最後の 8 つの位置をカバーします。

68
00:03:09,740 --> 00:03:12,210
これまでに行ったことはすべて、これら 4 

69
00:03:12,210 --> 00:03:14,798
つの質問に答えることと同じ であり、これはバ

70
00:03:14,798 --> 00:03:17,740
イナリでポジションを詳しく説明することと同じです。

71
00:03:19,620 --> 00:03:21,480
これにより 2 つのことが明確になると思います。

72
00:03:22,040 --> 00:03:24,420
1 つ目は、2 の累乗より大きいブロック 

73
00:03:24,420 --> 00:03:26,460
サイズに体系的に一般化する方法です。

74
00:03:26,960 --> 00:03:28,736
64 個のスポットを表すのに 6 

75
00:03:28,736 --> 00:03:31,872
ビットなど、各位置を表すのにさらに多くのビットが必要な場合 

76
00:03:31,872 --> 00:03:35,007
、それらの各ビットによって、チェックする必要があるパリティ 

77
00:03:35,007 --> 00:03:36,680
グループの 1 つが得られます。

78
00:03:38,400 --> 00:03:39,946
私がマット・パーカーと一緒にやったチェス盤の

79
00:03:39,946 --> 00:03:41,492
パズルを見たことがある人 なら、これらすべて

80
00:03:41,492 --> 00:03:43,180
に非常に馴染みのあるものに気づくかもしれません。

81
00:03:43,660 --> 00:03:46,336
これは同じコア ロジックですが、別の問題を解 

82
00:03:46,336 --> 00:03:48,780
決し、64 マスのチェス盤に適用されます。

83
00:03:49,880 --> 00:03:52,054
これで明らかになることを望みます 2 

84
00:03:52,054 --> 00:03:54,687
つ目は、パリティ ビットが 2 の累乗の位置 

85
00:03:54,687 --> 00:03:57,320
(たとえば 1、2、4、8) にある理由です。

86
00:03:58,000 --> 00:04:00,500
これらは、バイナリ表現で 1 つのビ

87
00:04:00,500 --> 00:04:03,000
ットだけがオンになっている位置です。

88
00:04:03,600 --> 00:04:05,261
これが意味するのは、これらのパリティ 

89
00:04:05,261 --> 00:04:06,923
ビットはそれぞれ、4 つのパ リティ 

90
00:04:06,923 --> 00:04:09,460
グループのうちの 1 つのみの中に存在するということです。

91
00:04:12,040 --> 00:04:14,210
これは、より大きな例でも見ることができます。

92
00:04:14,210 --> 00:04:16,775
 この例では、どれだけ大きくな っても、各パリティ 

93
00:04:16,775 --> 00:04:19,339
ビットは都合よくグループの 1 つだけに影響します。

94
00:04:25,600 --> 00:04:29,128
私たちが多くの時間を費やしてきたパリティ チェックが、バイ 

95
00:04:29,128 --> 00:04:32,656
ナリでエラーの位置を詳しく説明するための賢い方法にすぎない 

96
00:04:32,656 --> 00:04:36,183
ことを理解すると、ハミングについての別の考え方との関連性を 

97
00:04:36,183 --> 00:04:39,712
引き出すことができます。 コードはおそらくはるかにシンプルで

98
00:04:39,712 --> 00:04:43,240
 洗練されており、基本的には 1 行のコードで記述できます。

99
00:04:43,660 --> 00:04:45,500
これは XOR 関数に基づいています。

100
00:04:46,940 --> 00:04:48,950
知らない人のために説明すると、XOR 

101
00:04:48,950 --> 00:04:50,220
は排他的論理和の略です。

102
00:04:50,780 --> 00:04:53,640
2 つのビットの XOR を計算すると、それらの

103
00:04:53,640 --> 00:04:55,904
ビットのいずれかがオンで あれば 1 

104
00:04:55,904 --> 00:04:59,360
が返されますが、両方がオンまたはオフの場合は返されません。

105
00:05:00,100 --> 00:05:02,980
別の言い方をすると、これはこれら 2 ビットのパリティです。

106
00:05:03,540 --> 00:05:05,150
数学者として、私はこれを加算法 

107
00:05:05,150 --> 00:05:06,760
2 として考えることを好みます。

108
00:05:07,360 --> 00:05:09,589
また、2 つの異なるビット文字列の XOR 

109
00:05:09,589 --> 00:05:12,629
についてもよく話 しますが、これは基本的にコンポーネントごと

110
00:05:12,629 --> 00:05:13,440
に実行されます。

111
00:05:13,680 --> 00:05:15,720
それは足し算のようなものですが、決して持ち歩かない場所です。

112
00:05:16,500 --> 00:05:18,753
繰り返しますが、より数学的な傾向がある人は、これを 

113
00:05:18,753 --> 00:05:20,486
2 つのベクトル を加算し、mod 2 

114
00:05:20,486 --> 00:05:22,480
を減らすものと考えることを好むかもしれません。

115
00:05:23,500 --> 00:05:26,036
今すぐ Python を開いて 2 

116
00:05:26,036 --> 00:05:28,290
つの整数間にキャレット操作を適 

117
00:05:28,290 --> 00:05:31,390
用すると、内部でこれらの数値のビット表現が行

118
00:05:31,390 --> 00:05:32,940
われることになります。

119
00:05:34,960 --> 00:05:38,841
あなたと私にとって重要な点は、多くの異なるビット文字列の 

120
00:05:38,841 --> 00:05:41,786
X OR をとることは、列の場合と同様に、多

121
00:05:41,786 --> 00:05:44,730
数の別々のグループの パロディを一度に計算す

122
00:05:44,730 --> 00:05:47,140
る効果的な方法であるということです。

123
00:05:51,260 --> 00:05:53,766
これにより、ハミング コード アルゴリズムからの複数の

124
00:05:53,766 --> 00:05:55,252
パリティ チェックがすべて 1 

125
00:05:55,252 --> 00:05:57,758
つの操作にパッケージ化されていると考える、かなり気の利

126
00:05:57,758 --> 00:05:58,780
いた方法が得られます。

127
00:05:59,479 --> 00:06:02,180
一見するとかなり違うように見えますが。

128
00:06:02,820 --> 00:06:05,358
具体的には、以前と同様に 16 

129
00:06:05,358 --> 00:06:09,960
個の位置をバイナリで書き留め 、メッセージ ビットが 1 

130
00:06:09,960 --> 00:06:13,768
に変わる位置を強調表示し、これ らの位置を 1 

131
00:06:13,768 --> 00:06:17,100
つの大きな列に集めて XOR をとります。

132
00:06:19,260 --> 00:06:21,025
おそらく、結果として最下位にある 4 

133
00:06:21,025 --> 00:06:23,440
ビットが、私たちがよく知っていて 愛用している 4 

134
00:06:23,440 --> 00:06:26,134
つのパリティ チェックと同じであると推測できるでしょ う。

135
00:06:26,134 --> 00:06:28,549
 しかし、実際になぜなのかを少し時間を取って実際に考

136
00:06:28,549 --> 00:06:29,200
えてください。

137
00:06:32,220 --> 00:06:34,975
たとえば、この最後の列は、最後のビットが 1 

138
00:06:34,975 --> 00:06:38,330
であるすべての位置をカウント していますが、すでに強調表

139
00:06:38,330 --> 00:06:41,326
示された位置のみに制限されているため、事実上、最 

140
00:06:41,326 --> 00:06:44,681
初のパリティ グループからの強調表示された位置の数がカウ

141
00:06:44,681 --> 00:06:45,760
ントされています。

142
00:06:46,240 --> 00:06:46,800
それは理にかなっていますか？

143
00:06:49,080 --> 00:06:52,860
同様に、次の列では、2 番目のパリティ グループに位 

144
00:06:52,860 --> 00:06:56,500
置がいくつあるか、最後から 2 番目のビットが 1 

145
00:06:56,500 --> 00:07:00,000
で、強調表示されている位置などがカウントされます。

146
00:07:00,260 --> 00:07:02,110
それは、私たちがこれまでやってきたことと同

147
00:07:02,110 --> 00:07:03,960
じことについて、視点を少し変えただけです。

148
00:07:07,760 --> 00:07:09,600
ここから先はわかります。

149
00:07:10,000 --> 00:07:12,918
送信者は、合計が 0000 になるように特別なパ 

150
00:07:12,918 --> 00:07:15,720
リティ ビットの一部を切り替える責任があります。

151
00:07:15,720 --> 00:07:19,997
このようにすると、結果として得られる下部の 

152
00:07:19,997 --> 00:07:23,885
4 つのビットが エラーの位置を直接表す

153
00:07:23,885 --> 00:07:27,580
理由を考える非常に良い方法になります。

154
00:07:28,460 --> 00:07:30,060
このブロック内の一部のビットが 

155
00:07:30,060 --> 00:07:31,860
0 から 1 に切り替わるとします。

156
00:07:32,600 --> 00:07:36,383
これが意味するのは、そのビットの位置が合計 XOR に含 

157
00:07:36,383 --> 00:07:40,166
まれることになり、合計が 0 から、代わりにこの新しく含 

158
00:07:40,166 --> 00:07:43,820
まれた値、つまりエラーの位置に変更されるということです。

159
00:07:44,460 --> 00:07:47,012
少しわかりにくいですが、1 を 0 に変更するエ 

160
00:07:47,012 --> 00:07:49,360
ラーが発生した場合も同じことが当てはまります。

161
00:07:50,180 --> 00:07:51,623
ご存知のとおり、ビット列を 2 

162
00:07:51,623 --> 00:07:53,880
回追加すると、ビット列がまったく存在しないのと同 

163
00:07:53,880 --> 00:07:56,226
じになります。 基本的に、この世界では 1 プラス 

164
00:07:56,226 --> 00:07:57,580
1 は 0 に等しいためです。

165
00:07:57,580 --> 00:08:01,100
したがって、この位置のコピーを合計に追加す 

166
00:08:01,100 --> 00:08:04,300
ると、移動するのと同じ効果が得られます。

167
00:08:05,160 --> 00:08:08,036
そして、その効果は、やはり、ここの一番下にある合計結 

168
00:08:08,036 --> 00:08:10,700
果がエラーの位置を詳しく示しているということです。

169
00:08:13,039 --> 00:08:16,076
これがいかに洗練されているかを説明するために、前に参照した 

170
00:08:16,076 --> 00:08:18,201
Python コードの 1 行を示します。

171
00:08:18,201 --> 00:08:20,933
 これにより、受信側のロジックのほぼすべてがキャプチャ

172
00:08:20,933 --> 00:08:21,440
されます。

173
00:08:22,080 --> 00:08:25,063
まず、データ ブロックをシミュレートするために 16 個の 

174
00:08:25,063 --> 00:08:27,948
1 と 0 の ランダムな配列を作成し、それに bits 

175
00:08:27,948 --> 00:08:29,539
という名前を付けますが、もちろ 

176
00:08:29,539 --> 00:08:32,126
ん実際には、これは送信者から受信するものになります。

177
00:08:32,126 --> 00:08:34,911
 ランダムであるため、1 1 個のデータ ビットと 5 

178
00:08:34,911 --> 00:08:37,000
個のパリティ ビットを運ぶことになります。

179
00:08:37,000 --> 00:08:40,333
enumerateBits 関数を呼び出すと、こ

180
00:08:40,333 --> 00:08:44,083
れらの各ビットが対応する インデックス (この場合は 

181
00:08:44,083 --> 00:08:47,000
0 から 15 まで) とペアになります。

182
00:08:48,180 --> 00:08:51,262
したがって、これらすべてのペア (i に似たペア) 

183
00:08:51,262 --> 00:08:53,278
をループするリストを作 成し、i 

184
00:08:53,278 --> 00:08:56,004
の値だけ、インデックスだけを取り出すとします。

185
00:08:56,004 --> 00:08:58,257
 それほど面白いこ とではありません。

186
00:08:58,257 --> 00:09:01,340
 インデックス 0 から 15 が返されるだけです。

187
00:09:01,680 --> 00:09:05,423
しかし、ビットの場合のみ、つまりそのビットが 0 ではなく 

188
00:09:05,423 --> 00:09:09,041
1 である場合にのみこれを実 行するという条件を追加すると

189
00:09:09,041 --> 00:09:12,660
、対応するビットがオンになっている位置のみが抽出されます。

190
00:09:13,380 --> 00:09:17,960
この場合、それらの位置は 0、4、6、9 

191
00:09:17,960 --> 00:09:20,360
などのように見えます。

192
00:09:20,720 --> 00:09:22,893
私たちが望んでいるのは、これらの位置、つま

193
00:09:22,893 --> 00:09:25,894
りオンになっているビ ットの位置をすべて収集し、それらを 

194
00:09:25,894 --> 00:09:27,240
XOR 演算することです。

195
00:09:29,180 --> 00:09:31,148
これを Python で行うには、まず

196
00:09:31,148 --> 00:09:33,220
いくつかの便利な関数をインポートします。

197
00:09:33,900 --> 00:09:36,300
そうすることで、このリストに対してreduce()を呼び

198
00:09:36,300 --> 00:09:38,700
出し、XOR関数を使用してリストを減らすことができます。

199
00:09:39,100 --> 00:09:41,449
これは基本的にリスト全体を処理し、途中で 

200
00:09:41,449 --> 00:09:42,680
XOR を取得します。

201
00:09:44,800 --> 00:09:47,225
必要に応じて、XOR 関数をどこからもインポ 

202
00:09:47,225 --> 00:09:49,440
ートせずに明示的に書き出すことができます。

203
00:09:51,940 --> 00:09:55,285
したがって、現時点では、16 ビットのランダム 

204
00:09:55,285 --> 00:09:58,352
ブロックでこれを実 行すると、バイナリ表現 

205
00:09:58,352 --> 00:10:01,280
1001 を持つ 9 が返されるようです。

206
00:10:01,980 --> 00:10:05,350
ここではそれを行いませんが、送信者がそのバイナリ表現を使用し

207
00:10:05,350 --> 00:10:07,259
て必要に応じて 4 つのパリティ 

208
00:10:07,259 --> 00:10:10,629
ビットを設定し、最終的にこのブロックをビットの完全なリストに

209
00:10:10,629 --> 00:10:13,999
対して このコード行を実行すると返される状態にする関数を作成

210
00:10:13,999 --> 00:10:15,460
することもできます。 0。

211
00:10:16,080 --> 00:10:20,100
これは、十分に準備されたブロックであると考えられます。

212
00:10:20,100 --> 00:10:23,432
素晴らしいのは、このリストのビットのいずれかを切り替え

213
00:10:23,432 --> 00:10:26,764
て、ノイズによるランダムなエ ラーをシミュレートし、同

214
00:10:26,764 --> 00:10:30,220
じコード行を実行すると、そのエラーが出力されることです。

215
00:10:30,960 --> 00:10:31,520
素敵じゃないですか？

216
00:10:31,820 --> 00:10:34,724
このブロックを突然取得し、その上でこの 1 

217
00:10:34,724 --> 00:10:37,760
行を実行すると、エラーの位 置が自動的に出力さ

218
00:10:37,760 --> 00:10:41,060
れ、エラーが存在しない場合は 0 が出力されます。

219
00:10:42,500 --> 00:10:44,840
サイズ 16 については特別なことは何もありません。

220
00:10:44,840 --> 00:10:47,278
たとえば 256 ビットのリストが

221
00:10:47,278 --> 00:10:49,860
ある場合、同じコード行が機能します。

222
00:10:51,880 --> 00:10:54,651
言うまでもなく、2 ビット エラーを検出するためのメタ 

223
00:10:54,651 --> 00:10:57,622
パリティ チェックの実行 など、ここで記述するコードはさらに

224
00:10:57,622 --> 00:10:59,998
ありますが、考え方としては、このスキームのコア 

225
00:10:59,998 --> 00:11:01,879
ロジックのほぼすべてが単一の XOR 

226
00:11:01,879 --> 00:11:03,760
リダクションに帰結するということです。

227
00:11:06,120 --> 00:11:09,117
さて、バイナリ、XOR、およびソフトウェア全般に慣れている

228
00:11:09,117 --> 00:11:12,114
かどうかに応じて、こ の視点が少しわかりにくいと感じるか、

229
00:11:12,114 --> 00:11:14,388
またははるかにエレガントでシンプルなので、 

230
00:11:14,388 --> 00:11:17,386
なぜ最初からこの視点を始めなかったのかと不思議に思うかもし

231
00:11:17,386 --> 00:11:18,420
れません。 -行く。

232
00:11:19,140 --> 00:11:22,448
大まかに言うと、複数のパリティ チェックの観点は、ハミング 

233
00:11:22,448 --> 00:11:25,206
コードを ハードウェアで直接実装する場合に考えやす

234
00:11:25,206 --> 00:11:27,963
く、XOR の観点は、ソフト ウェアで実行する場合

235
00:11:27,963 --> 00:11:30,500
に、より高いレベルから考えるのが最も簡単です。

236
00:11:31,360 --> 00:11:34,427
最初の方法は実際に手作業で行うのが最も簡単で、これら

237
00:11:34,427 --> 00:11:37,494
すべての根底にある核となる 直感を植え付けるのに効果

238
00:11:37,494 --> 00:11:40,797
的だと思います。 つまり、単一のエラーを見つけるのに必 

239
00:11:40,797 --> 00:11:43,865
要な情報はブロックのサイズのログに関連しているという

240
00:11:43,865 --> 00:11:46,814
ことです。 、言い換えれば 、ブロック サイズが 

241
00:11:46,814 --> 00:11:50,000
2 倍になると、一度に 1 ビットずつ大きくなります。

242
00:11:51,020 --> 00:11:53,601
ここで重要な事実は、その情報が必要な冗長 

243
00:11:53,601 --> 00:11:56,060
性の量に直接対応しているということです。

244
00:11:56,660 --> 00:11:59,993
これは、ほとんどの人が最初にメッセージをエラーに強いも 

245
00:11:59,993 --> 00:12:03,326
のにしようと考えたとき、通常はメッセージ全体をコピーす 

246
00:12:03,326 --> 00:12:06,540
ることが最初に頭に浮かぶ本能的な反応に反するものです。

247
00:12:07,500 --> 00:12:08,850
そして、ところで、時々ハミング 

248
00:12:08,850 --> 00:12:10,792
コードが表示されるのを目にすることがあります 

249
00:12:10,792 --> 00:12:12,902
が、これとはまったく別の方法で、メッセージに 1 

250
00:12:12,902 --> 00:12:14,000
つの大きな行列を掛けます。

251
00:12:14,670 --> 00:12:16,701
これは、線形コードのより広範なファミリーに関連

252
00:12:16,701 --> 00:12:18,909
付けられているため、ある意味素晴らしいですが、そ 

253
00:12:18,909 --> 00:12:20,940
れがどこから来たのか、どのようにスケールするの

254
00:12:20,940 --> 00:12:23,060
かについてはほとんど直観が得られないと思います。

255
00:12:25,200 --> 00:12:27,087
スケーリングについて言えば、ブロック 

256
00:12:27,087 --> 00:12:30,067
サイズが増加するにつれ てこのスキームの効率が向上することに

257
00:12:30,067 --> 00:12:31,160
気づくかもしれません。

258
00:12:35,000 --> 00:12:38,330
たとえば、256 ビットでは、冗長性のためにそのスペースの 

259
00:12:38,330 --> 00:12:40,883
3% の みが使用されており、そこからさらに改

260
00:12:40,883 --> 00:12:42,660
善され続けることがわかりました。

261
00:12:43,300 --> 00:12:45,870
パリティ ビットの数が 1 つずつ増加すると、ブロック 

262
00:12:45,870 --> 00:12:47,340
サイズは 2 倍になり続けます。

263
00:12:49,000 --> 00:12:51,515
これを極端に解釈すると、たとえば 100 

264
00:12:51,515 --> 00:12:54,150
万ビットのブロック があり、文字通り 20 

265
00:12:54,150 --> 00:12:56,426
問のパリティ チェックを行うことにな 

266
00:12:56,426 --> 00:13:00,020
り、使用するパリティ ビットは 21 ビットだけになります。

267
00:13:00,740 --> 00:13:04,008
そして、百万ビットを調べて単一のエラーを見つけることを一歩 

268
00:13:04,008 --> 00:13:07,060
下がって考えると、それは本当にクレイジーに感じられます。

269
00:13:08,199 --> 00:13:11,353
もちろん、問題は、ブロックが大きくなると、1 つまたは 

270
00:13:11,353 --> 00:13:14,506
2 つ以上のビット エラーが 発生する確率が高くなり、ハ

271
00:13:14,506 --> 00:13:17,660
ミング コードがそれを超えるものを処理できないことです。

272
00:13:18,320 --> 00:13:21,362
したがって、実際には、ビット フリップが多すぎる可能性が 

273
00:13:21,362 --> 00:13:24,300
高すぎないように、適切なサイズを見つけることが必要です。

274
00:13:26,600 --> 00:13:29,476
また、実際には、エラーは小さなバーストで発生する傾向があり、

275
00:13:29,476 --> 00:13:31,393
単一のブロックを完全に破壊してしまうた 

276
00:13:31,393 --> 00:13:34,269
め、エラーのバーストを多くの異なるブロックに分散させるための

277
00:13:34,269 --> 00:13:36,186
一般的な戦術の 1 つは、ブロックがブ 

278
00:13:36,186 --> 00:13:39,062
ロックされる前に、このようにそれらのブロックをインターレース

279
00:13:39,062 --> 00:13:40,980
することです。 発送または保管されます。

280
00:13:45,580 --> 00:13:48,186
しかし、繰り返しになりますが、この多くは、より一般

281
00:13:48,186 --> 00:13:50,167
的に使用されているリードソロモン ア 

282
00:13:50,167 --> 00:13:52,773
ルゴリズムなど、バースト エラーを特にうまく処理し

283
00:13:52,773 --> 00:13:54,649
、ブロックあたりのより多くのエラー 

284
00:13:54,649 --> 00:13:57,256
に耐性を持つように調整できる、より現代的なコードに

285
00:13:57,256 --> 00:13:58,820
よって完全に無意味になります。

286
00:13:59,360 --> 00:14:01,340
しかし、それはまた別の機会にお話します。

287
00:14:02,500 --> 00:14:04,415
ハミング氏は著書『The Art of Doing 

288
00:14:04,415 --> 00:14:06,256
Science and Engineering』 

289
00:14:06,256 --> 00:14:08,098
の中で、このコードの発見がどれほど曲がりくねったも

290
00:14:08,098 --> 00:14:09,940
のであったかについて、驚くほど率直に語っています。

291
00:14:10,620 --> 00:14:12,933
彼はまず、ビットを高次元の格子の一部に組織

292
00:14:12,933 --> 00:14:15,246
することや、このような 奇妙なことを含む、

293
00:14:15,246 --> 00:14:17,780
あらゆる種類のさまざまなスキームを試しました。

294
00:14:18,300 --> 00:14:20,341
エラーの位置を明らかにする方法でパリティ 

295
00:14:20,341 --> 00:14:22,965
チェックを共謀させること ができるかもしれないという考

296
00:14:22,965 --> 00:14:24,910
えがハミングに思いついたのは、ハミング 

297
00:14:24,910 --> 00:14:27,534
が他の一連の分析を終えて一歩下がって、「わかった、私に

298
00:14:27,534 --> 00:14:30,061
できる最も効 率的なものは何か」と尋ねたときでした。

299
00:14:30,061 --> 00:14:31,520
 おそらくこれについてですか？

300
00:14:32,620 --> 00:14:34,770
彼はまた、パリティ チェックがすでに頭の中にあ

301
00:14:34,770 --> 00:14:37,293
ったことがいかに重要であるかについても率直に 語った。

302
00:14:37,293 --> 00:14:39,443
 1940 年代にはパリティ チェックは現在よ

303
00:14:39,443 --> 00:14:41,220
りもはるかに一般的ではなかったはずだ。

304
00:14:41,920 --> 00:14:45,186
この本の中で、ルイ・パスツールの名言「幸運は準備ができ 

305
00:14:45,186 --> 00:14:48,220
た心に味方する」という言葉が何度も引用されています。

306
00:14:49,320 --> 00:14:51,810
賢いアイデアは、後から考えると一見シンプル

307
00:14:51,810 --> 00:14:54,300
に見えることが多く、過小評価されがちです。

308
00:14:54,960 --> 00:14:57,073
今のところ私の正直な願いは、ハミング符号、あ

309
00:14:57,073 --> 00:14:59,186
るいは少なくともそのよ うな符号の可能性が、

310
00:14:59,186 --> 00:15:01,300
皆さんにとってほぼ明白に感じられることです。

311
00:15:01,660 --> 00:15:04,292
しかし、それらは決して明らかではないので、それら 

312
00:15:04,292 --> 00:15:06,820
が実際には明白であると思い込む必要はありません。

313
00:15:07,880 --> 00:15:10,341
賢いアイデアが一見簡単そうに見える理由の 1 

314
00:15:10,341 --> 00:15:13,337
つは、私たちは最終的な 結果しか見ていないこと、散らかっ

315
00:15:13,337 --> 00:15:15,370
たものを片づけること、間違った方向へ 

316
00:15:15,370 --> 00:15:18,366
の言及がまったくないこと、問題の開始時に探索可能な可能性

317
00:15:18,366 --> 00:15:21,362
の空間がいか に広大であるかを過小評価していることです。

318
00:15:21,362 --> 00:15:22,860
 解決プロセス、そのすべて。

319
00:15:23,820 --> 00:15:24,900
しかし、これは一般的に真実です。

320
00:15:24,900 --> 00:15:27,572
一部の特別な発明については、私たちがそれらを過小評 

321
00:15:27,572 --> 00:15:30,040
価している第二の、より深い理由があると思います。

322
00:15:30,840 --> 00:15:33,200
情報をビットの観点から考えることは、1948 

323
00:15:33,200 --> 00:15:34,842
年までにクロード シャノンによ 

324
00:15:34,842 --> 00:15:37,408
る情報理論に関する独創的な論文によってようやく完全

325
00:15:37,408 --> 00:15:38,640
な理論に統合されました。

326
00:15:39,280 --> 00:15:40,863
これは基本的に、ハミングがアルゴリ

327
00:15:40,863 --> 00:15:42,540
ズムを開発したときと同時進行でした。

328
00:15:43,300 --> 00:15:46,633
これは、ビット反転の確率がどれほど高くても、少な 

329
00:15:46,633 --> 00:15:49,833
くとも理論上は、ある意味、効率的なエラー訂正が 

330
00:15:49,833 --> 00:15:52,900
常に可能であることを示した同じ基礎論文でした。

331
00:15:53,700 --> 00:15:56,122
ちなみに、シャノンとハミングは、まったく異なること

332
00:15:56,122 --> 00:15:58,544
に取り組んでいたにもかかわ らず、ベル研究所でオフ

333
00:15:58,544 --> 00:16:01,160
ィスを共有していましたが、ここでは偶然とは思えません。

334
00:16:02,380 --> 00:16:05,700
数十年が経ち、最近では私たちの多くが断片や情報

335
00:16:05,700 --> 00:16:09,020
について考えることに没 頭しているため、この考

336
00:16:09,020 --> 00:16:12,340
え方がいかに独特であったかを見落としがちです。

337
00:16:13,100 --> 00:16:16,063
皮肉なことに、将来の世代の考え方を最も深く形

338
00:16:16,063 --> 00:16:19,027
作っているアイデアは、最 終的にはその将来の

339
00:16:19,027 --> 00:16:22,260
世代にとって実際よりも単純なものになるでしょう。

