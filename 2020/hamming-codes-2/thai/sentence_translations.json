[
 {
  "input": "I'm assuming that everybody here is coming from part 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 2.56
 },
 {
  "input": "We were talking about Hamming codes, a way to create a block of data where most of the bits carry a meaningful message, while a few others act as a kind of redundancy, in such a way that if any bit gets flipped, either a message bit or a redundancy bit, anything in this block, a receiver is going to be able to identify that there was an error, and how to fix it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.06,
  "end": 21.24
 },
 {
  "input": "The basic idea presented there was how to use multiple parity checks to binary search your way down to the error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 21.88,
  "end": 27.16
 },
 {
  "input": "In that video the goal was to make Hamming codes feel as hands-on and rediscoverable as possible. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 28.98,
  "end": 34.6
 },
 {
  "input": "But as you start to think about actually implementing this, either in software or hardware, that framing may actually undersell how elegant these codes really are. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.18,
  "end": 43.46
 },
 {
  "input": "You might think that you need to write an algorithm that keeps track of all the possible error locations and cuts that group in half with each check, but it's actually way, way simpler than that. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.92,
  "end": 53.48
 },
 {
  "input": "If you read out the answers to the four parity checks we did in the last video, all as 1s and 0s instead of yeses and nos, it literally spells out the position of the error in binary. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.94,
  "end": 64.08
 },
 {
  "input": "For example, the number 7 in binary looks like 0111, essentially saying that it's 4 plus 2 plus 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 64.78,
  "end": 71.26
 },
 {
  "input": "And notice where the position 7 sits, it does affect the first of our parity groups, and the second, and the third, but not the last. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.54,
  "end": 81.74
 },
 {
  "input": "So reading the results of those four checks from bottom to top indeed does spell out the position of the error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 82.22,
  "end": 87.54
 },
 {
  "input": "There's nothing special about the example 7, this works in general, and this makes the logic for implementing the whole scheme in hardware shockingly simple. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.32,
  "end": 95.82
 },
 {
  "input": "Now if you want to see why this magic happens, take these 16 index labels for our positions, but instead of writing them in base 10, let's write them all in binary, running from 0000 up to 1111. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.24,
  "end": 109.88
 },
 {
  "input": "As we put these binary labels back into their boxes, let me emphasize that they are distinct from the data that's actually being sent. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.56,
  "end": 117.8
 },
 {
  "input": "They're nothing more than a conceptual label to help you and me understand where the four parity groups came from. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.32,
  "end": 123.5
 },
 {
  "input": "The elegance of having everything we're looking at be described in binary is maybe undercut by the confusion of having everything we're looking at being described in binary. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.14,
  "end": 132.36
 },
 {
  "input": "It's worth it, though. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 133.02,
  "end": 134.12
 },
 {
  "input": "Focus your attention just on that last bit of all of these labels, and then highlight the positions where that final bit is a 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 143.22
 },
 {
  "input": "What we get is the first of our four parity groups, which means you can interpret that first check as asking, hey, if there's an error, is the final bit in the position of that error a 1? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.24,
  "end": 155.74
 },
 {
  "input": "Similarly, if you focus on the second to last bit, and highlight all the positions where that's a 1, you get the second parity group from our scheme. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.2,
  "end": 166.16
 },
 {
  "input": "In other words, that second check is asking, hey, me again, if there's an error, is the second to last bit of that position a 1? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.74,
  "end": 174.5
 },
 {
  "input": "And so on. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.76,
  "end": 176.9
 },
 {
  "input": "The third parity check covers every position whose third to last bit is turned on, and the last one covers the last eight positions, those ones whose highest order bit is a 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.22,
  "end": 188.74
 },
 {
  "input": "Everything we did earlier is the same as answering these four questions, which in turn is the same as spelling out a position in binary. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.74,
  "end": 197.74
 },
 {
  "input": "I hope this makes two things clearer. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.62,
  "end": 201.48
 },
 {
  "input": "The first is how to systematically generalize to block sizes that are bigger powers of two. ",
  "translatedText": "ฉันเดาว่าทุกคนที่นี่มาจากภาค 1 เรากำลังพูดถึงโค้ด Hamming ซึ่งเป็นวิธีในการสร้างบล็อกข้อมูลที่บิตส่วนใหญ่มีข้อความที่มีความหมาย ในขณะที่บิตอื่นๆ บางส่วนทำหน้าที่เป็นการซ้ำซ้อน ในลักษณะที่ว่าหากบิตใด ๆ พลิกกลับ ข้อความก็อาจเป็นข้อความหนึ่งก็ได้ บิตหรือบิตสำรอง อะไรก็ตามในบล็อกนี้ ผู้รับจะสามารถระบุได้ว่ามีข้อผิดพลาด และวิธีการแก้ไข แนวคิดพื้นฐานที่นำเสนอคือวิธีใช้การตรวจสอบพาริตีหลายรายการเพื่อค้นหาแบบไบนารี่ไปจนถึงข้อผิดพลาด  ในวิดีโอนั้นเป้าหมายคือการทำให้โค้ด Hamming รู้สึกเหมือนได้ลงมือปฏิบัติจริงและสามารถค้นพบใหม่ได้มากที่สุดเท่าที่จะเป็นไปได้ แต่เมื่อคุณเริ่มคิดถึงการนำสิ่งนี้ไปใช้จริง ทั้งในซอฟต์แวร์หรือฮาร์ดแวร์ เฟรมนั้นอาจตอกย้ำว่าโค้ดเหล่านี้สวยงามเพียงใด คุณอาจคิดว่าคุณจำเป็นต้องเขียนอัลกอริทึมที่ติดตามตำแหน่งข้อผิดพลาดที่เป็นไปได้ทั้งหมด และลดกลุ่มนั้นลงครึ่งหนึ่งในการตรวจสอบแต่ละครั้ง แต่จริงๆ แล้วเป็นวิธีที่ง่ายกว่านั้นมาก หากคุณอ่านคำตอบของการตรวจสอบความเท่าเทียมกันทั้งสี่ครั้งที่เราทำในวิดีโอที่แล้ว ทั้งหมดเป็น 1 และ 0 แทนที่จะเป็นใช่และไม่ใช่ มันจะสะกดตำแหน่งของข้อผิดพลาดในรูปแบบไบนารี่ ตัวอย่างเช่น เลข 7 ในไบนารี่ดูเหมือน 0111 โดยพื้นฐานแล้วบอกว่ามันคือ 4 บวก 2 บวก 1 และสังเกตว่าตำแหน่งที่ 7 อยู่ที่ใด มันจะส่งผลต่อกลุ่มพาริตีกลุ่มแรกของเรา และกลุ่มที่สองและกลุ่มที่สาม แต่ไม่ใช่กลุ่มสุดท้าย ดังนั้นการอ่านผลการตรวจสอบทั้งสี่ครั้งจากล่างขึ้นบนจะช่วยระบุตำแหน่งของข้อผิดพลาดได้อย่างแน่นอน  ไม่มีอะไรพิเศษเกี่ยวกับตัวอย่างที่ 7 ซึ่งใช้งานได้โดยทั่วไป และทำให้ตรรกะในการใช้โครงร่างทั้งหมดในฮาร์ดแวร์เป็นเรื่องง่ายอย่างน่าตกใจ ตอนนี้ หากคุณต้องการดูว่าเหตุใดเหตุการณ์มหัศจรรย์นี้จึงเกิดขึ้น ให้นำป้ายกำกับดัชนีทั้ง 16 รายการสำหรับตำแหน่งของเรา แต่แทนที่จะเขียนเป็นฐาน 10 ให้เขียนทั้งหมดในรูปแบบไบนารี่ โดยเริ่มจาก 0000 ถึง 1111 ขณะที่เราใส่ป้ายกำกับไบนารี่เหล่านี้กลับเข้าไปในกล่อง ฉันขอย้ำว่าป้ายเหล่านี้แตกต่างจากข้อมูลที่ถูกส่งจริง สิ่งเหล่านี้เป็นเพียงป้ายกำกับแนวคิดที่จะช่วยให้คุณและฉันเข้าใจว่ากลุ่มความเท่าเทียมกันทั้งสี่มาจากไหน  ความสง่างามของการมีทุกสิ่งที่เรากำลังดูถูกอธิบายในรูปแบบไบนารี่อาจถูกลดทอนลงด้วยความสับสนของการมีทุกสิ่งที่เรากำลังดูถูกอธิบายในรูปแบบไบนารี  มันก็คุ้มค่านะ มุ่งความสนใจของคุณไปที่ส่วนสุดท้ายของป้ายกำกับเหล่านี้ทั้งหมด จากนั้นไฮไลต์ตำแหน่งที่บิตสุดท้ายคือ 1 สิ่งที่เราได้รับคือกลุ่มพาริตีกลุ่มแรกจากสี่กลุ่ม ซึ่งหมายความว่าคุณสามารถตีความการตรวจสอบครั้งแรกเป็นการถามว่า เฮ้ หากมีข้อผิดพลาด บิตสุดท้ายในตำแหน่งของข้อผิดพลาดนั้นเป็น 1 หรือไม่ ในทำนองเดียวกัน หากคุณเน้นที่บิตที่สองถึงบิตสุดท้าย และเน้นตำแหน่งทั้งหมดที่เป็น 1 คุณจะได้กลุ่มแพริตีที่สองจากแผนของเรา กล่าวอีกนัยหนึ่ง การตรวจสอบครั้งที่สองจะถามว่า เฮ้ ฉันอีกครั้ง หากมีข้อผิดพลาด บิตที่สองจากบิตสุดท้ายของตำแหน่งนั้นเป็น 1 หรือไม่ และอื่นๆ การตรวจสอบพาริตี้ครั้งที่สามครอบคลุมทุกตำแหน่งที่เปิดบิตที่สามถึงสุดท้าย และการตรวจสอบสุดท้ายครอบคลุมแปดตำแหน่งสุดท้าย ซึ่งบิตลำดับสูงสุดคือ 1 ทุกสิ่งที่เราทำก่อนหน้านี้เหมือนกับการตอบคำถามสี่ข้อนี้ ซึ่งในทางกลับกันก็เหมือนกับการสะกดตำแหน่งในรูปแบบไบนารี่ ฉันหวังว่านี่จะทำให้สองสิ่งชัดเจนขึ้น ประการแรกคือวิธีการสรุปอย่างเป็นระบบเกี่ยวกับขนาดบล็อกที่มีพลังมากกว่าสอง หากต้องใช้บิตมากกว่าในการอธิบายแต่ละตำแหน่ง เช่น หกบิตเพื่ออธิบาย 64 จุด แต่ละบิตเหล่านั้นจะให้หนึ่งในกลุ่มพาริตีที่เราต้องตรวจสอบ บรรดาผู้ที่ดูปริศนากระดานหมากรุกที่ฉันทำกับแมตต์ ปาร์กเกอร์อาจพบว่าทั้งหมดนี้คุ้นเคยอย่างยิ่ง มันเป็นตรรกะหลักเดียวกัน แต่แก้ปัญหาที่แตกต่าง และนำไปใช้กับกระดานหมากรุกขนาด 64 สี่เหลี่ยม สิ่งที่สองที่ฉันหวังว่าสิ่งนี้จะทำให้ชัดเจนคือเหตุใดแพริตีบิตของเราจึงนั่งอยู่ในตำแหน่งที่เป็นกำลังของสอง เช่น 1, 2, 4 และ 8 ตำแหน่งเหล่านี้คือตำแหน่งที่การแสดงไบนารี่เปิดขึ้นเพียงเล็กน้อย นั่นหมายความว่าแต่ละแพริตีบิตเหล่านั้นอยู่ภายในกลุ่มพาริตีเพียงกลุ่มเดียวจากสี่กลุ่มเท่านั้น  คุณยังสามารถดูสิ่งนี้ได้ในตัวอย่างที่ใหญ่กว่า โดยไม่ว่าคุณจะได้ขนาดใหญ่แค่ไหน แต่ละบิตของพาริตีจะแตะเพียงกลุ่มใดกลุ่มหนึ่งได้อย่างสะดวก เมื่อคุณเข้าใจว่าการตรวจสอบความเท่าเทียมกันเหล่านี้ที่เราทุ่มเทเวลาส่วนใหญ่นั้นไม่มีอะไรมากไปกว่าวิธีที่ชาญฉลาดในการระบุตำแหน่งของข้อผิดพลาดในรูปแบบไบนารี่ จากนั้นเราก็สามารถเชื่อมโยงด้วยวิธีคิดที่แตกต่างออกไปเกี่ยวกับการแฮมมิง รหัส ซึ่งอาจจะเรียบง่ายกว่าและสวยงามกว่ามาก และโดยทั่วไปแล้วสามารถเขียนลงไปได้ด้วยโค้ดเพียงบรรทัดเดียว มันขึ้นอยู่กับฟังก์ชัน XOR XOR สำหรับคนที่ไม่รู้จัก ย่อมาจาก Exclusive or เมื่อคุณรับ XOR ของสองบิต มันจะคืนค่า 1 หากบิตใดบิตหนึ่งนั้นเปิดอยู่ แต่จะไม่ได้ถ้าทั้งสองเปิดหรือปิด หากใช้ถ้อยคำต่างกัน มันคือความเท่าเทียมกันของสองบิตนี้ ในฐานะคนคณิต ฉันชอบคิดว่ามันเป็นการบวก mod 2 โดยทั่วไปเรายังพูดถึง XOR ของสตริงบิตที่แตกต่างกันสองตัว ซึ่งโดยพื้นฐานแล้วจะทำส่วนประกอบนี้ทีละส่วนประกอบ มันเหมือนกับการเติม แต่ที่คุณไม่เคยพกติดตัว ขอย้ำอีกครั้งว่ายิ่งมีความโน้มเอียงทางคณิตศาสตร์มากขึ้นอาจชอบคิดว่านี่เป็นการเพิ่มเวกเตอร์สองตัวและลด mod 2 หากคุณเปิด Python ขึ้นมาตอนนี้และใช้การดำเนินการเครื่องหมายรูปหมวกระหว่างจำนวนเต็มสองตัว นี่คือสิ่งที่มันกำลังทำอยู่ ยกเว้นการแสดงบิตของตัวเลขเหล่านั้นภายใต้ประทุน ประเด็นสำคัญสำหรับคุณและฉันคือการรับ XOR ของสตริงบิตต่างๆ มากมายเป็นวิธีที่มีประสิทธิภาพในการคำนวณการล้อเลียนกลุ่มกลุ่มที่แยกจากกัน เช่นเดียวกับคอลัมน์ ทั้งหมดในคราวเดียว สิ่งนี้ทำให้เรามีวิธีที่ค่อนข้างเก๋ในการคิดเกี่ยวกับการตรวจสอบพาริตีหลายรายการจากอัลกอริธึมโค้ด Hamming ของเรา โดยที่ทั้งหมดนี้ถูกรวมเข้าด้วยกันเป็นการดำเนินการเดียว แม้ว่ามองแวบแรกจะดูแตกต่างออกไปมากก็ตาม เขียนตำแหน่งทั้ง 16 ตำแหน่งในรูปแบบไบนารี่อย่างที่เราเคยมีมาก่อน และตอนนี้เน้นตำแหน่งที่บิตข้อความเปิดเป็น 1 จากนั้นรวบรวมตำแหน่งเหล่านี้เป็นคอลัมน์ขนาดใหญ่คอลัมน์เดียวแล้วรับ XOR คุณอาจเดาได้ว่าผลลัพธ์ 4 บิตที่อยู่ด้านล่างนั้นเหมือนกับการตรวจสอบความเท่าเทียมกัน 4 รายการที่เรารู้จักและชื่นชอบ แต่ใช้เวลาสักครู่เพื่อคิดจริงๆ ว่าเหตุใดจึงเป็นเช่นนั้น ตัวอย่างเช่น คอลัมน์สุดท้ายนี้ กำลังนับตำแหน่งทั้งหมดที่มีบิตสุดท้ายเป็น 1 แต่เราจำกัดไว้เฉพาะตำแหน่งที่ไฮไลต์อยู่แล้ว ดังนั้นจึงเป็นการนับอย่างมีประสิทธิภาพว่าตำแหน่งที่ไฮไลต์กี่ตำแหน่งมาจากกลุ่มแพริตีกลุ่มแรก นั่นสมเหตุสมผลไหม? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.04,
  "end": 206.46
 },
 {
  "input": "If it takes more bits to describe each position, like six bits to describe 64 spots, then each of those bits gives you one of the parity groups that we need to check. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 216.68
 },
 {
  "input": "Those of you who watched the chessboard puzzle I did with Matt Parker might find all this exceedingly familiar. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.4,
  "end": 223.18
 },
 {
  "input": "It's the same core logic, but solving a different problem, and applied to a 64-squared chessboard. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.66,
  "end": 228.78
 },
 {
  "input": "The second thing I hope this makes clear is why our parity bits are sitting in the positions that are powers of two, for example 1, 2, 4, and 8. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.88,
  "end": 237.32
 },
 {
  "input": "These are the positions whose binary representation has just a single bit turned on. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.0,
  "end": 243.0
 },
 {
  "input": "What that means is each of those parity bits sits inside one and only one of the four parity groups. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.6,
  "end": 249.46
 },
 {
  "input": "You can also see this in larger examples, where no matter how big you get, each parity bit conveniently touches only one of the groups. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.04,
  "end": 259.34
 },
 {
  "input": "Once you understand that these parity checks that we've focused so much of our time on are nothing more than a clever way to spell out the position of an error in binary, then we can draw a connection with a different way to think about hamming codes, one that is arguably a lot simpler and more elegant, and which can basically be written down with a single line of code. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.6,
  "end": 283.24
 },
 {
  "input": "It's based on the XOR function. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.66,
  "end": 285.5
 },
 {
  "input": "XOR, for those of you who don't know, stands for exclusive or. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.94,
  "end": 290.22
 },
 {
  "input": "When you take the XOR of two bits, it's going to return a 1 if either one of those bits is turned on, but not if both are turned on or off. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.78,
  "end": 299.36
 },
 {
  "input": "Phrased differently, it's the parity of these two bits. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.1,
  "end": 302.98
 },
 {
  "input": "As a math person, I prefer to think about it as addition mod 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 303.54,
  "end": 306.76
 },
 {
  "input": "We also commonly talk about the XOR of two different bit strings, which basically does this component by component. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.36,
  "end": 313.44
 },
 {
  "input": "It's like addition, but where you never carry. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.68,
  "end": 315.72
 },
 {
  "input": "Again, the more mathematically inclined might prefer to think of this as adding two vectors and reducing mod 2. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.5,
  "end": 322.48
 },
 {
  "input": "If you open up some Python right now and apply the caret operation between two integers, this is what it's doing but to the bit representations of those numbers under the hood. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.5,
  "end": 332.94
 },
 {
  "input": "The key point for you and me is that taking the XOR of many different bit strings is effectively a way to compute the parodies of a bunch of separate groups, like so with the columns, all in one fell swoop. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.96,
  "end": 347.14
 },
 {
  "input": "This gives us a rather snazzy way to think about the multiple parity checks from our Hamming code algorithm as all being packaged together into one single operation. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.26,
  "end": 358.78
 },
 {
  "input": "Though at first glance it does look very different. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.48,
  "end": 362.18
 },
 {
  "input": "Specifically write down the 16 positions in binary, like we had before, and now highlight the positions where the message bit is turned on to a 1, and then collect these positions into one big column and take the XOR. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.82,
  "end": 377.1
 },
 {
  "input": "You can probably guess that the 4 bits sitting at the bottom as a result are the same as the 4 parity checks we've come to know and love, but take a moment to actually think about why exactly. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.26,
  "end": 389.2
 },
 {
  "input": "This last column, for example, is counting all of the positions whose last bit is a 1, but we're already limited only to the highlighted positions, so it's effectively counting how many highlighted positions came from the first parity group. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.22,
  "end": 405.76
 },
 {
  "input": "Does that make sense? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 406.8
 },
 {
  "input": "Likewise, the next column counts how many positions are in the second parity group, the positions whose second to last bit is a 1, and which are also highlighted, and so on. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.08,
  "end": 420.0
 },
 {
  "input": "It's really just a small shift in perspective on the same thing we've been doing. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.26,
  "end": 423.96
 },
 {
  "input": "And so you know where it goes from here. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 427.76,
  "end": 429.6
 },
 {
  "input": "The sender is responsible for toggling some of the special parity bits to make sure the sum works out to be 0000. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.0,
  "end": 436.56
 },
 {
  "input": "Now once we have it like this, this gives us a really nice way to think about why these four resulting bits at the bottom directly spell out the position of an error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.04,
  "end": 447.58
 },
 {
  "input": "Let's say some bit in this block gets toggled from a 0 to a 1. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.46,
  "end": 451.86
 },
 {
  "input": "What that means is that the position of that bit is now going to be included in the total XOR, which changes the sum from being 0 to instead being this newly included value, the position of the error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.6,
  "end": 463.82
 },
 {
  "input": "Slightly less obviously, the same is true if there's an error that changes a 1 to a 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.46,
  "end": 469.36
 },
 {
  "input": "You see, if you add a bit string together twice, it's the same as not having it there at all, basically because in this world 1 plus 1 equals 0. ",
  "translatedText": "ในทำนองเดียวกัน คอลัมน์ถัดไปจะนับจำนวนตำแหน่งที่อยู่ในกลุ่มพาริตีที่สอง ตำแหน่งที่บิตที่สองถึงสุดท้ายคือ 1 และตำแหน่งที่ถูกไฮไลต์ด้วย และอื่นๆ มันเป็นเพียงการเปลี่ยนแปลงเล็กๆ น้อยๆ ในมุมมองต่อสิ่งเดียวกันที่เราทำอยู่ แล้วคุณจะรู้ว่ามันไปจากที่นี่ที่ไหน ผู้ส่งมีหน้าที่รับผิดชอบในการสลับบิตพาริตีพิเศษบางส่วนเพื่อให้แน่ใจว่าผลรวมจะเป็น 0000 ตอนนี้เมื่อเรามีแบบนี้แล้ว นี่ทำให้เรามีวิธีที่ดีที่จะคิดว่าเหตุใดผลลัพธ์สี่บิตที่อยู่ด้านล่างจึงสะกดตำแหน่งของข้อผิดพลาดได้โดยตรง สมมติว่าบางส่วนในบล็อกนี้มีการสลับจาก 0 เป็น 1 ความหมายก็คือตอนนี้ตำแหน่งของบิตนั้นจะถูกรวมไว้ใน XOR ทั้งหมด ซึ่งเปลี่ยนผลรวมจาก 0 เป็นค่าที่รวมใหม่แทน ซึ่งเป็นตำแหน่งของข้อผิดพลาด เห็นได้ชัดว่าน้อยกว่าเล็กน้อย กรณีเดียวกันนี้จะเกิดขึ้นหากมีข้อผิดพลาดที่เปลี่ยน 1 เป็น 0 คุณจะเห็นว่า ถ้าคุณบวกสตริงบิตเข้าด้วยกันสองครั้ง มันก็เหมือนกับการไม่มีมันเลย โดยพื้นฐานแล้ว เพราะในโลกนี้ 1 บวก 1 เท่ากับ 0 ดังนั้นการเพิ่มสำเนาของตำแหน่งนี้เข้ากับผลรวมทั้งหมดจะมีผลเช่นเดียวกับที่เรากำลังย้ายตำแหน่ง  และผลกระทบนั้นอีกครั้ง ก็คือผลลัพธ์รวมที่อยู่ด้านล่างสุดนี้ ระบุตำแหน่งของข้อผิดพลาด เพื่อแสดงให้เห็นว่าสิ่งนี้สวยงามเพียงใด ฉันขอแสดงโค้ด Python หนึ่งบรรทัดที่ฉันอ้างถึงก่อนหน้านี้ ซึ่งจะรวบรวมตรรกะเกือบทั้งหมดในส่วนท้ายของผู้รับ เราจะเริ่มต้นด้วยการสร้างอาร์เรย์สุ่ม 16 1 วินาทีและ 0 เพื่อจำลองบล็อกข้อมูล และฉันจะตั้งชื่อบิตให้กับมัน แต่แน่นอนว่าในทางปฏิบัติ นี่จะเป็นสิ่งที่เราได้รับจากผู้ส่ง และแทนที่จะเป็น ถ้าสุ่มก็จะบรรทุกข้อมูล 11 บิตพร้อมกับพาริตีบิต 5 บิต ถ้าฉันเรียกใช้ฟังก์ชัน enumerateBits สิ่งที่มันทำคือจับคู่แต่ละบิตเหล่านั้นกับดัชนีที่สอดคล้องกัน ในกรณีนี้คือทำงานตั้งแต่ 0 ถึง 15 ดังนั้นหากเราสร้างรายการที่วนซ้ำคู่เหล่านี้ทั้งหมด คู่ที่ดูเหมือน i แล้วเราดึงเฉพาะค่า i ออกมา แค่ดัชนี มันไม่น่าตื่นเต้นขนาดนั้น เราแค่นำดัชนีเหล่านั้นกลับมา 0 ถึง 15 . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.18,
  "end": 477.94
 },
 {
  "input": "So adding a copy of this position to the total sum has the same effect as we're moving it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.92,
  "end": 484.3
 },
 {
  "input": "And that effect, again, is that the total result at the bottom here spells out the position of the error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.16,
  "end": 490.7
 },
 {
  "input": "To illustrate how elegant this is, let me show that one line of Python code I referenced before, which will capture almost all of the logic on the receiver's end. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.04,
  "end": 501.44
 },
 {
  "input": "We'll start by creating a random array of 16 1s and 0s to simulate the data block, and I'll give it the name bits, but of course in practice this would be something we're receiving from a sender, and instead of being random it would be carrying 11 data bits together with 5 parity bits. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.08,
  "end": 517.4
 },
 {
  "input": "If I call the function enumerateBits, what it does is pair together each of those bits with a corresponding index, in this case running from 0 up to 15. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.12,
  "end": 527.0
 },
 {
  "input": "So if we then create a list that loops over all of these pairs, pairs that look like i, and then we pull out just the i value, just the index, well it's not that exciting, we just get back those indices 0 through 15. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.18,
  "end": 541.34
 },
 {
  "input": "But if we add on the condition to only do this if bit, meaning if that bit is a 1 and not a 0, well then it pulls out only the positions where the corresponding bit is turned on. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 541.68,
  "end": 552.66
 },
 {
  "input": "In this case it looks like those positions are 0, 4, 6, 9, etc. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.38,
  "end": 557.96
 },
 {
  "input": "What we want is to collect together all of those positions, the positions of the bits that are turned on, and then XOR them together. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.98,
  "end": 567.24
 },
 {
  "input": "To do this in Python, let me first import a couple helpful functions. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.18,
  "end": 573.22
 },
 {
  "input": "That way we can call reduce() on this list, and use the XOR function to reduce it. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.9,
  "end": 578.7
 },
 {
  "input": "This basically eats its way through the list, taking XORs along the way. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.1,
  "end": 582.68
 },
 {
  "input": "If you prefer, you can explicitly write out that XOR function without having to import it from anywhere. ",
  "translatedText": "แต่ถ้าเราเพิ่มเงื่อนไขให้ทำสิ่งนี้เฉพาะ if bit ซึ่งหมายความว่าถ้าบิตนั้นเป็น 1 ไม่ใช่ 0 มันก็จะดึงเฉพาะตำแหน่งที่เปิดบิตที่เกี่ยวข้องออกมาเท่านั้น ในกรณีนี้ ดูเหมือนว่าตำแหน่งเหล่านั้นคือ 0, 4, 6, 9 เป็นต้น สิ่งที่เราต้องการคือการรวบรวมตำแหน่งทั้งหมดเหล่านั้น ตำแหน่งของบิตที่เปิดอยู่ จากนั้น XOR เข้าด้วยกัน หากต้องการทำสิ่งนี้ใน Python ก่อนอื่นให้ฉันนำเข้าฟังก์ชันที่เป็นประโยชน์สองสามรายการก่อน ด้วยวิธีนี้เราสามารถเรียกย่อ () ในรายการนี้ และใช้ฟังก์ชัน XOR เพื่อลดค่านั้น โดยพื้นฐานแล้วสิ่งนี้จะกินทางผ่านรายการโดยนำ XOR ไปพร้อมกัน หากต้องการ คุณสามารถเขียนฟังก์ชัน XOR นั้นอย่างชัดเจนโดยไม่ต้องนำเข้าจากที่ใดก็ได้ ดังนั้นในขณะนี้ ดูเหมือนว่าถ้าเราทำเช่นนี้กับบล็อกสุ่มของเราที่มีขนาด 16 บิต มันจะคืนค่า 9 ซึ่งมีเลขฐานสองแทน 1001 เราจะไม่ทำที่นี่ แต่คุณสามารถเขียนฟังก์ชันที่ผู้ส่งใช้การแทนค่าไบนารีนั้นเพื่อตั้งค่าบิตพาริตีทั้งสี่ตามต้องการ ในท้ายที่สุดทำให้บล็อกนี้อยู่ในสถานะที่รันโค้ดบรรทัดนี้ในรายการบิตทั้งหมดส่งคืน 0 นี่ถือเป็นบล็อกที่เตรียมไว้อย่างดี สิ่งที่ยอดเยี่ยมก็คือหากเราสลับบิตใดบิตหนึ่งในรายการนี้ จำลองข้อผิดพลาดแบบสุ่มจากสัญญาณรบกวน จากนั้นหากคุณเรียกใช้โค้ดบรรทัดเดียวกัน มันจะพิมพ์ข้อผิดพลาดนั้นออกมา นั่นไม่เรียบร้อยเหรอ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.8,
  "end": 589.44
 },
 {
  "input": "So at the moment it looks like if we do this on our random block of 16 bits, it returns 9, which has the binary representation 1001. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.94,
  "end": 601.28
 },
 {
  "input": "We won't do it here, but you could write a function where the sender uses that binary representation to set the four parity bits as needed, ultimately getting this block to a state where running this line of code on the full list of bits returns a 0. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.98,
  "end": 615.46
 },
 {
  "input": "This would be considered a well-prepared block. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 616.08,
  "end": 618.2
 },
 {
  "input": "What's cool is that if we toggle any one of the bits in this list, simulating a random error from noise, then if you run this same line of code, it prints out that error. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 619.88,
  "end": 630.22
 },
 {
  "input": "Isn't that neat? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 630.96,
  "end": 631.52
 },
 {
  "input": "You could get this block from out of the blue, run this single line on it, and it'll automatically spit out the position of an error, or a 0 if there wasn't any. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 631.82,
  "end": 641.06
 },
 {
  "input": "And there's nothing special about the size 16 here. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.5,
  "end": 645.2
 },
 {
  "input": "The same line of code would work if you had a list of, say, 256 bits. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.4,
  "end": 649.86
 },
 {
  "input": "Needless to say, there is more code to write here, like doing the meta parity check to detect 2-bit errors, but the idea is that almost all of the core logic from our scheme comes down to a single XOR reduction. ",
  "translatedText": "คุณสามารถดึงบล็อกนี้ขึ้นมาใหม่ รันบรรทัดเดียวบนบล็อกนั้น และมันจะแยกตำแหน่งของข้อผิดพลาดออกโดยอัตโนมัติ หรือจะเป็น 0 หากไม่มีเลย และไม่มีอะไรพิเศษเกี่ยวกับไซส์ 16 ที่นี่ โค้ดบรรทัดเดียวกันนี้จะใช้ได้ถ้าคุณมีรายการ เช่น 256 บิต ไม่จำเป็นต้องพูดว่า มีโค้ดให้เขียนมากกว่านี้ เช่น การตรวจสอบเมตาพาริตี้เพื่อตรวจจับข้อผิดพลาด 2 บิต แต่แนวคิดก็คือตรรกะหลักเกือบทั้งหมดจากโครงการของเราลดลงเหลือเพียงการลด XOR เพียงครั้งเดียว ตอนนี้ ขึ้นอยู่กับความสะดวกสบายของคุณกับไบนารี่และ XOR และซอฟต์แวร์โดยทั่วไป คุณอาจพบว่ามุมมองนี้สับสนเล็กน้อย หรือหรูหราและเรียบง่ายกว่านั้นมากจนคุณสงสัยว่าทำไมเราไม่เพียงแค่เริ่มต้นจากจุดเริ่มต้น -ไป. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.88,
  "end": 663.76
 },
 {
  "input": "Now, depending on your comfort with binary and XORs and software in general, you may either find this perspective a little bit confusing, or so much more elegant and simple that you're wondering why we didn't just start with it from the get-go. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.12,
  "end": 678.42
 },
 {
  "input": "Loosely speaking, the multiple parity check perspective is easier to think about when implementing Hamming codes in hardware very directly, and the XOR perspective is easiest to think about when doing it in software, from kind of a higher level. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 679.14,
  "end": 690.5
 },
 {
  "input": "The first one is easiest to actually do by hand, and I think it does a better job instilling the core intuition underlying all of this, which is that the information required to locate a single error is related to the log of the size of the block, or in other words, it grows one bit at a time as the block size doubles. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.36,
  "end": 710.0
 },
 {
  "input": "The relevant fact here is that that information directly corresponds to how much redundancy we need. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.02,
  "end": 716.06
 },
 {
  "input": "That's really what runs against most people's knee-jerk reaction when they first think about making a message resilient to errors, where usually copying the whole message is the first instinct that comes to mind. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 716.66,
  "end": 726.54
 },
 {
  "input": "And then, by the way, there is this whole other way that you sometimes see Hamming codes presented, where you multiply the message by one big matrix. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 727.5,
  "end": 734.0
 },
 {
  "input": "It's kind of nice because it relates it to the broader family of linear codes, but I think that gives almost no intuition for where it comes from or how it scales. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.67,
  "end": 743.06
 },
 {
  "input": "And speaking of scaling, you might notice that the efficiency of this scheme only gets better as we increase the block size. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.2,
  "end": 751.16
 },
 {
  "input": "For example, we saw that with 256 bits, you're using only 3% of that space for redundancy, and it just keeps getting better from there. ",
  "translatedText": "พูดง่ายๆ ก็คือ มุมมองการตรวจสอบความเท่าเทียมกันหลายรายการจะคิดได้ง่ายกว่าเมื่อใช้โค้ด Hamming ในฮาร์ดแวร์โดยตรง และมุมมอง XOR นั้นคิดได้ง่ายที่สุดเมื่อทำในซอฟต์แวร์จากระดับที่สูงกว่า วิธีแรกนั้นง่ายที่สุดที่ทำด้วยมือจริง ๆ และฉันคิดว่ามันจะทำงานได้ดีกว่าโดยปลูกฝังสัญชาตญาณหลักที่เป็นรากฐานทั้งหมดนี้ ซึ่งก็คือข้อมูลที่จำเป็นต้องใช้ในการค้นหาข้อผิดพลาดเดียวนั้นเกี่ยวข้องกับบันทึกขนาดของบล็อก หรืออีกนัยหนึ่ง มันจะขยายทีละบิตเมื่อขนาดบล็อกเพิ่มขึ้นสองเท่า ข้อเท็จจริงที่เกี่ยวข้องในที่นี้คือข้อมูลนั้นสอดคล้องโดยตรงกับปริมาณความซ้ำซ้อนที่เราต้องการ  นั่นคือสิ่งที่ขัดแย้งกับปฏิกิริยากระตุกเข่าของคนส่วนใหญ่เมื่อพวกเขาคิดถึงการสร้างข้อความที่ยืดหยุ่นต่อข้อผิดพลาด ซึ่งโดยปกติแล้วการคัดลอกข้อความทั้งหมดถือเป็นสัญชาตญาณแรกที่เข้ามาในใจ  แล้ว ยังมีอีกวิธีหนึ่ง ที่บางครั้งคุณจะเห็นโค้ดแฮมมิงนำเสนอ โดยคุณคูณข้อความด้วยเมทริกซ์ขนาดใหญ่ตัวเดียว เป็นเรื่องดีเพราะมันเกี่ยวข้องกับกลุ่มโค้ดเชิงเส้นที่กว้างกว่า แต่ฉันคิดว่านั่นแทบไม่ได้ให้สัญชาตญาณเลยว่ามันมาจากไหนหรือปรับขนาดอย่างไร และเมื่อพูดถึงการปรับขนาด คุณอาจสังเกตเห็นว่าประสิทธิภาพของโครงร่างนี้จะดีขึ้นเมื่อเราเพิ่มขนาดบล็อกเท่านั้น ตัวอย่างเช่น เราเห็นว่าด้วย 256 บิต คุณใช้พื้นที่เพียง 3% ของพื้นที่นั้นในการสำรอง และมันจะดีขึ้นเรื่อยๆ จากจุดนั้น เมื่อจำนวนบิตพาริตีเพิ่มขึ้นทีละบิต ขนาดบล็อกก็จะเพิ่มขึ้นเป็นสองเท่า และถ้าคุณใช้มันสุดโต่ง คุณสามารถมีบล็อกที่มีหนึ่งล้านบิต ซึ่งคุณคงจะเล่นคำถาม 20 ข้อกับการตรวจสอบพาริตีของคุณ และมันใช้เพียง 21 พาริตีบิตเท่านั้น และถ้าคุณย้อนกลับไปคิดถึงการดูล้านบิตและค้นหาข้อผิดพลาดเพียงจุดเดียว นั่นคงรู้สึกบ้าไปแล้วจริงๆ แน่นอนว่าปัญหาก็คือ เมื่อมีบล็อกขนาดใหญ่ ความน่าจะเป็นที่จะเห็นข้อผิดพลาดมากกว่าหนึ่งหรือสองบิตก็จะเพิ่มขึ้น และโค้ด Hamming ก็ไม่สามารถจัดการอะไรนอกเหนือจากนั้นได้ ในทางปฏิบัติ สิ่งที่คุณต้องการคือการหาขนาดที่เหมาะสม เพื่อไม่ให้ความน่าจะเป็นที่จะพลิกบิตมากเกินไป นอกจากนี้ ในทางปฏิบัติ ข้อผิดพลาดมักจะเกิดขึ้นเป็นชุดเล็กๆ น้อยๆ ซึ่งจะทำให้บล็อกเดียวเสียหายโดยสิ้นเชิง ดังนั้นกลวิธีทั่วไปประการหนึ่งที่จะช่วยกระจายข้อผิดพลาดแบบต่อเนื่องไปยังบล็อกต่างๆ มากมายคือการสอดประสานบล็อกเหล่านั้น เช่นนี้ ก่อนที่จะ ส่งหรือเก็บไว้ อีกครั้ง สิ่งเหล่านี้ส่วนใหญ่ถูกโต้แย้งอย่างสมบูรณ์ด้วยโค้ดที่ทันสมัยกว่า เช่น อัลกอริธึม Reed-Solomon ที่ใช้กันทั่วไปมากกว่า ซึ่งจัดการข้อผิดพลาดแบบ Burst ได้ดีเป็นพิเศษ และสามารถปรับให้มีความยืดหยุ่นต่อจำนวนข้อผิดพลาดที่มากขึ้นต่อบล็อก . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.0,
  "end": 762.66
 },
 {
  "input": "As the number of parity bits grows one by one, the block size keeps doubling. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 763.3,
  "end": 767.34
 },
 {
  "input": "And if you take that to an extreme, you could have a block with, say, a million bits, where you would quite literally be playing 20 questions with your parity checks, and it uses only 21 parity bits. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 769.0,
  "end": 780.02
 },
 {
  "input": "And if you step back to think about looking at a million bits and locating a single error, that genuinely feels crazy. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 780.74,
  "end": 787.06
 },
 {
  "input": "The problem, of course, is that with a larger block, the probability of seeing more than one or two bit errors goes up, and Hamming codes do not handle anything beyond that. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 788.2,
  "end": 797.66
 },
 {
  "input": "So in practice, what you'd want is to find the right size so that the probability of too many bit flips isn't too high. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.32,
  "end": 804.3
 },
 {
  "input": "Also, in practice, errors tend to come in little bursts, which would totally ruin a single block, so one common tactic to help spread out a burst of errors across many different blocks is to interlace those blocks, like this, before they're sent out or stored. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.6,
  "end": 820.98
 },
 {
  "input": "Then again, a lot of this is rendered completely moot by more modern codes, like the much more commonly used Reed-Solomon algorithm, which handles burst errors particularly well, and it can be tuned to be resilient to a larger number of errors per block. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.58,
  "end": 838.82
 },
 {
  "input": "But that's a topic for another time. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.36,
  "end": 841.34
 },
 {
  "input": "In his book The Art of Doing Science and Engineering, Hamming is wonderfully candid about just how meandering his discovery of this code was. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.5,
  "end": 849.94
 },
 {
  "input": "He first tried all sorts of different schemes involving organizing the bits into parts of a higher dimensional lattice and strange things like this. ",
  "translatedText": "แต่นั่นเป็นหัวข้อสำหรับอีกครั้ง ในหนังสือของเขา The Art of Doing Science and Engineering แฮมมิงเปิดเผยอย่างตรงไปตรงมาว่าการค้นพบรหัสนี้คดเคี้ยวเพียงใด ขั้นแรกเขาลองใช้แผนงานต่างๆ มากมายที่เกี่ยวข้องกับการจัดชิ้นส่วนให้เป็นส่วนหนึ่งของโครงตาข่ายมิติที่สูงกว่าและสิ่งแปลกประหลาดเช่นนี้ ความคิดที่ว่าอาจเป็นไปได้ที่จะได้รับการตรวจสอบความเท่าเทียมกันเพื่อสมรู้ร่วมคิดในลักษณะที่สะกดตำแหน่งของข้อผิดพลาดเท่านั้นที่มาถึงแฮมมิงเมื่อเขาก้าวถอยหลังหลังจากการวิเคราะห์อื่น ๆ มากมายและถามว่าโอเคอะไรคือสิ่งที่มีประสิทธิภาพมากที่สุดที่ฉันสามารถทำได้ คงจะเกี่ยวกับเรื่องนี้ใช่ไหม? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 850.62,
  "end": 857.78
 },
 {
  "input": "The idea that it might be possible to get parity checks to conspire in a way that spells out the position of an error only came to Hamming when he stepped back after a bunch of other analysis and asked, okay, what is the most efficient I could conceivably be about this? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 858.3,
  "end": 871.52
 },
 {
  "input": "He was also candid about how important it was that parity checks were already on his mind, which would have been way less common back in the 1940s than it is today. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 872.62,
  "end": 881.22
 },
 {
  "input": "There are like half a dozen times throughout this book that he references the Louis Pasteur quote, luck favors a prepared mind. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.92,
  "end": 888.22
 },
 {
  "input": "Clever ideas often look deceptively simple in hindsight, which makes them easy to underappreciate. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.32,
  "end": 894.3
 },
 {
  "input": "Right now my honest hope is that Hamming codes, or at least the possibility of such codes, feels almost obvious to you. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.96,
  "end": 901.3
 },
 {
  "input": "But you shouldn't fool yourself into thinking that they actually are obvious, because they definitely aren't. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 901.66,
  "end": 906.82
 },
 {
  "input": "Part of the reason that clever ideas look deceptively easy is that we only ever see the final result, cleaning up what was messy, never mentioning all of the wrong turns, underselling just how vast the space of explorable possibilities is at the start of a problem solving process, all of that. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.88,
  "end": 922.86
 },
 {
  "input": "But this is true in general. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 923.82,
  "end": 924.9
 },
 {
  "input": "I think for some special inventions, there's a second, deeper reason that we underappreciate them. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.9,
  "end": 930.04
 },
 {
  "input": "Thinking of information in terms of bits had only really coalesced into a full theory by 1948, with Claude Shannon's seminal paper on information theory. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.84,
  "end": 938.64
 },
 {
  "input": "This was essentially concurrent with when Hamming developed his algorithm. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 939.28,
  "end": 942.54
 },
 {
  "input": "This was the same foundational paper that showed, in a certain sense, that efficient error correction is always possible, no matter how high the probability of bit flips, at least in theory. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.3,
  "end": 952.9
 },
 {
  "input": "Shannon and Hamming, by the way, shared an office in Bell Labs, despite working on very different things, which hardly seems coincidental here. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.7,
  "end": 961.16
 },
 {
  "input": "Fast forward several decades, and these days, many of us are so immersed in thinking about bits and information that it's easy to overlook just how distinct this way of thinking was. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.38,
  "end": 972.34
 },
 {
  "input": "Ironically, the ideas that most profoundly shape the ways that a future generation thinks will end up looking to that future generation simpler than they really are. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 973.1,
  "end": 982.26
 }
]