[
 {
  "input": "I'm assuming that everybody here is coming from part 1.",
  "translatedText": "我假设这里的每个人都来自第 1 部分。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 2.56
 },
 {
  "input": "We were talking about Hamming codes, a way to create a block of data where most of the bits carry a meaningful message, while a few others act as a kind of redundancy, in such a way that if any bit gets flipped, either a message bit or a redundancy bit, anything in this block, a receiver is going to be able to identify that there was an error, and how to fix it.",
  "translatedText": "我们讨论的是汉明码，这是一种创建数据块的方法 ，其中大多数位携带有意义的消息，而其他一些 位则充当一种冗余，这样如果任何位被翻转，要么 是一条消息位或冗余位，该块中的任何内容，接 收器将能够识别出存在错误，以及如何修复它。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.06,
  "end": 21.24
 },
 {
  "input": "The basic idea presented there was how to use multiple parity checks to binary search your way down to the error.",
  "translatedText": "那里提出的基本思想是如何使用多个奇 偶校验来进行二进制搜索以找出错误。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 21.88,
  "end": 27.16
 },
 {
  "input": "In that video the goal was to make Hamming codes feel as hands-on and rediscoverable as possible.",
  "translatedText": "在该视频中，我们的目标是让汉明码尽可 能具有动手操作和可重新发现的感觉。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 28.98,
  "end": 34.6
 },
 {
  "input": "But as you start to think about actually implementing this, either in software or hardware, that framing may actually undersell how elegant these codes really are.",
  "translatedText": "但是，当您开始考虑在软件或硬件中实际实现这一点时 ，该框架实际上可能低估了这些代码的真正优雅程度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.18,
  "end": 43.46
 },
 {
  "input": "You might think that you need to write an algorithm that keeps track of all the possible error locations and cuts that group in half with each check, but it's actually way, way simpler than that.",
  "translatedText": "您可能认为您需要编写一个算法来跟踪所 有可能的错误位置，并在每次检查时将该 组切成两半，但实际上比这简单得多。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.92,
  "end": 53.48
 },
 {
  "input": "If you read out the answers to the four parity checks we did in the last video, all as 1s and 0s instead of yeses and nos, it literally spells out the position of the error in binary.",
  "translatedText": "如果你读出我们在上一个视频中所做的四次奇偶校验的答案，全部都是 1 和 0，而不是是和否，它实际上以二进制形式说明了错误的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.94,
  "end": 64.08
 },
 {
  "input": "For example, the number 7 in binary looks like 0111, essentially saying that it's 4 plus 2 plus 1.",
  "translatedText": "例如，二进制中的数字 7 看起来像 011 1，本质上是说它是 4 加 2 加 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 64.78,
  "end": 71.26
 },
 {
  "input": "And notice where the position 7 sits, it does affect the first of our parity groups, and the second, and the third, but not the last.",
  "translatedText": "请注意位置 7 所在的位置，它确实影响我们的第一 个奇偶组，以及第二个和第三个，但不影响最后一个。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.54,
  "end": 81.74
 },
 {
  "input": "So reading the results of those four checks from bottom to top indeed does spell out the position of the error.",
  "translatedText": "因此，从下到上读取这四次检查的 结果确实可以阐明错误的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 82.22,
  "end": 87.54
 },
 {
  "input": "There's nothing special about the example 7, this works in general, and this makes the logic for implementing the whole scheme in hardware shockingly simple.",
  "translatedText": "示例 7 没有什么特别的，这在一般情况下是有效 的，这使得在硬件中实现整个方案的逻辑非常简单。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.32,
  "end": 95.82
 },
 {
  "input": "Now if you want to see why this magic happens, take these 16 index labels for our positions, but instead of writing them in base 10, let's write them all in binary, running from 0000 up to 1111.",
  "translatedText": "现在，如果您想了解为什么会发生这种神奇的情况，请将这 1 6 个索引标签作为我们的位置，但不要将它们写入基数 10 ，而是将它们全部写入二进制，从 0000 到 1111。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.24,
  "end": 109.88
 },
 {
  "input": "As we put these binary labels back into their boxes, let me emphasize that they are distinct from the data that's actually being sent.",
  "translatedText": "当我们将这些二进制标签放回它们的盒子时 ，让我强调它们与实际发送的数据不同。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.56,
  "end": 117.8
 },
 {
  "input": "They're nothing more than a conceptual label to help you and me understand where the four parity groups came from.",
  "translatedText": "它们只不过是一个概念标签，可以 帮助你我理解四个奇偶组的来源。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.32,
  "end": 123.5
 },
 {
  "input": "The elegance of having everything we're looking at be described in binary is maybe undercut by the confusion of having everything we're looking at being described in binary.",
  "translatedText": "用二进制描述我们所看到的一切的优雅可能会因为我 们所看到的一切都以二进制描述的混乱而被削弱。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.14,
  "end": 132.36
 },
 {
  "input": "It's worth it, though.",
  "translatedText": "不过，这是值得的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 133.02,
  "end": 134.12
 },
 {
  "input": "Focus your attention just on that last bit of all of these labels, and then highlight the positions where that final bit is a 1.",
  "translatedText": "将您的注意力集中在所有这些标签的最后一位 上，然后突出显示最后一位为 1 的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 143.22
 },
 {
  "input": "What we get is the first of our four parity groups, which means you can interpret that first check as asking, hey, if there's an error, is the final bit in the position of that error a 1?",
  "translatedText": "我们得到的是四个奇偶校验组中的第一个，这意 味着您可以将第一个检查解释为询问，嘿，如果 有错误，该错误位置的最后一位是否为 1？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.24,
  "end": 155.74
 },
 {
  "input": "Similarly, if you focus on the second to last bit, and highlight all the positions where that's a 1, you get the second parity group from our scheme.",
  "translatedText": "同样，如果您关注倒数第二位，并突出显示所有为 1 的位置，您就会从我们的方案中获得第二个奇偶校验组。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.2,
  "end": 166.16
 },
 {
  "input": "In other words, that second check is asking, hey, me again, if there's an error, is the second to last bit of that position a 1?",
  "translatedText": "换句话说，第二次检查会问，嘿，我再说一次， 如果有错误，该位置的倒数第二位是 1 吗？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.74,
  "end": 174.5
 },
 {
  "input": "And so on.",
  "translatedText": "等等。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.76,
  "end": 176.9
 },
 {
  "input": "The third parity check covers every position whose third to last bit is turned on, and the last one covers the last eight positions, those ones whose highest order bit is a 1.",
  "translatedText": "第三个奇偶校验涵盖倒数第三位打开的每个位置，最后一个 奇偶校验涵盖最后八个位置，即最高位为 1 的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.22,
  "end": 188.74
 },
 {
  "input": "Everything we did earlier is the same as answering these four questions, which in turn is the same as spelling out a position in binary.",
  "translatedText": "我们之前所做的一切都与回答这四个问题相 同，而这又与以二进制拼出一个位置相同。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.74,
  "end": 197.74
 },
 {
  "input": "I hope this makes two things clearer.",
  "translatedText": "我希望这能让两件事变得更清楚。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.62,
  "end": 201.48
 },
 {
  "input": "The first is how to systematically generalize to block sizes that are bigger powers of two.",
  "translatedText": "第一个是如何系统地推广到大于 2 的幂的块大小。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.04,
  "end": 206.46
 },
 {
  "input": "If it takes more bits to describe each position, like six bits to describe 64 spots, then each of those bits gives you one of the parity groups that we need to check.",
  "translatedText": "如果需要更多位来描述每个位置，例如 6 位来描述 64 个点 ，那么其中每一位都会为您提供我们需要检查的奇偶校验组之一。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 216.68
 },
 {
  "input": "Those of you who watched the chessboard puzzle I did with Matt Parker might find all this exceedingly familiar.",
  "translatedText": "那些看过我和马特·帕克一起做的棋盘 拼图的人可能会发现这一切非常熟悉。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.4,
  "end": 223.18
 },
 {
  "input": "It's the same core logic, but solving a different problem, and applied to a 64-squared chessboard.",
  "translatedText": "它是相同的核心逻辑，但解决不同的问 题，并应用于 64 方格的棋盘。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.66,
  "end": 228.78
 },
 {
  "input": "The second thing I hope this makes clear is why our parity bits are sitting in the positions that are powers of two, for example 1, 2, 4, and 8.",
  "translatedText": "我希望这能澄清的第二件事是为什么我们的奇偶校验位 位于 2 的幂的位置，例如 1、2、4 和 8。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.88,
  "end": 237.32
 },
 {
  "input": "These are the positions whose binary representation has just a single bit turned on.",
  "translatedText": "这些位置的二进制表示仅打开了一位。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.0,
  "end": 243.0
 },
 {
  "input": "What that means is each of those parity bits sits inside one and only one of the four parity groups.",
  "translatedText": "这意味着这些奇偶校验位中的每一个都位 于四个奇偶校验组中的一个且仅一个内。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.6,
  "end": 249.46
 },
 {
  "input": "You can also see this in larger examples, where no matter how big you get, each parity bit conveniently touches only one of the groups.",
  "translatedText": "您还可以在更大的示例中看到这一点，无论您有多 大，每个奇偶校验位都只方便地触及其中一个组。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.04,
  "end": 259.34
 },
 {
  "input": "Once you understand that these parity checks that we've focused so much of our time on are nothing more than a clever way to spell out the position of an error in binary, then we can draw a connection with a different way to think about hamming codes, one that is arguably a lot simpler and more elegant, and which can basically be written down with a single line of code.",
  "translatedText": "一旦您明白我们花费大量时间关注的这些奇 偶校验只不过是一种巧妙的方式来阐明二 进制错误的位置，那么我们就可以用不同 的方式来思考汉明代码，可以说更简单、 更优雅，基本上可以用一行代码写下来。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.6,
  "end": 283.24
 },
 {
  "input": "It's based on the XOR function.",
  "translatedText": "它基于 XOR 函数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.66,
  "end": 285.5
 },
 {
  "input": "XOR, for those of you who don't know, stands for exclusive or.",
  "translatedText": "XOR，对于那些不知道的人来说，代表异或。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.94,
  "end": 290.22
 },
 {
  "input": "When you take the XOR of two bits, it's going to return a 1 if either one of those bits is turned on, but not if both are turned on or off.",
  "translatedText": "当您对两位进行异或时，如果其中一位打开，它将返回 1，但如果两者都打开或关闭，则不会返回 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.78,
  "end": 299.36
 },
 {
  "input": "Phrased differently, it's the parity of these two bits.",
  "translatedText": "换句话说，它是这两个位的奇偶校验。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.1,
  "end": 302.98
 },
 {
  "input": "As a math person, I prefer to think about it as addition mod 2.",
  "translatedText": "作为一个数学家，我更喜欢将其视为加法 mod 2。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 303.54,
  "end": 306.76
 },
 {
  "input": "We also commonly talk about the XOR of two different bit strings, which basically does this component by component.",
  "translatedText": "我们还经常谈论两个不同位串的异或， 它基本上是逐个组件地执行此操作。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.36,
  "end": 313.44
 },
 {
  "input": "It's like addition, but where you never carry.",
  "translatedText": "这就像加法，但你永远不会携带。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.68,
  "end": 315.72
 },
 {
  "input": "Again, the more mathematically inclined might prefer to think of this as adding two vectors and reducing mod 2.",
  "translatedText": "同样，更倾向于数学的人可能更愿意将其 视为添加两个向量并减少 mod 2。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.5,
  "end": 322.48
 },
 {
  "input": "If you open up some Python right now and apply the caret operation between two integers, this is what it's doing but to the bit representations of those numbers under the hood.",
  "translatedText": "如果您现在打开一些 Python 并在两个整数之间应用插入符号 操作，这就是它正在做的事情，但只是针对这些数字的位表示形式。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.5,
  "end": 332.94
 },
 {
  "input": "The key point for you and me is that taking the XOR of many different bit strings is effectively a way to compute the parodies of a bunch of separate groups, like so with the columns, all in one fell swoop.",
  "translatedText": "对你和我来说，关键点在于，对许多不同的位 串进行异或运算实际上是一种计算一堆单独 组的模仿的方法，就像列一样，一举完成。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.96,
  "end": 347.14
 },
 {
  "input": "This gives us a rather snazzy way to think about the multiple parity checks from our Hamming code algorithm as all being packaged together into one single operation.",
  "translatedText": "这为我们提供了一种相当时髦的方式来思考汉明码算法中 的多个奇偶校验，因为所有这些都被打包到一个操作中。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.26,
  "end": 358.78
 },
 {
  "input": "Though at first glance it does look very different.",
  "translatedText": "虽然乍一看确实很不一样。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.48,
  "end": 362.18
 },
 {
  "input": "Specifically write down the 16 positions in binary, like we had before, and now highlight the positions where the message bit is turned on to a 1, and then collect these positions into one big column and take the XOR.",
  "translatedText": "像我们之前那样，专门写下二进制的 16 个 位置，现在突出显示消息位变为 1 的位置， 然后将这些位置收集到一大列中并进行异或。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.82,
  "end": 377.1
 },
 {
  "input": "You can probably guess that the 4 bits sitting at the bottom as a result are the same as the 4 parity checks we've come to know and love, but take a moment to actually think about why exactly.",
  "translatedText": "您可能会猜到，结果位于底部的 4 位与 我们所了解和喜爱的 4 个奇偶校验相同 ，但请花点时间思考一下到底是为什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.26,
  "end": 389.2
 },
 {
  "input": "This last column, for example, is counting all of the positions whose last bit is a 1, but we're already limited only to the highlighted positions, so it's effectively counting how many highlighted positions came from the first parity group.",
  "translatedText": "例如，最后一列正在计算最后一位为 1 的所有位置 ，但我们已经仅限于突出显示的位置，因此它有效地 计算有多少突出显示的位置来自第一个奇偶校验组。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.22,
  "end": 405.76
 },
 {
  "input": "Does that make sense?",
  "translatedText": "那有意义吗？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 406.8
 },
 {
  "input": "Likewise, the next column counts how many positions are in the second parity group, the positions whose second to last bit is a 1, and which are also highlighted, and so on.",
  "translatedText": "同样，下一列计算第二个奇偶校验组中有 多少个位置、倒数第二个位为 1 的位 置以及也突出显示的位置，依此类推。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.08,
  "end": 420.0
 },
 {
  "input": "It's really just a small shift in perspective on the same thing we've been doing.",
  "translatedText": "这实际上只是对我们一直在做的同一件事的看法的一个小小的转变。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.26,
  "end": 423.96
 },
 {
  "input": "And so you know where it goes from here.",
  "translatedText": "所以你知道它从这里走向何方。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 427.76,
  "end": 429.6
 },
 {
  "input": "The sender is responsible for toggling some of the special parity bits to make sure the sum works out to be 0000.",
  "translatedText": "发送方负责切换一些特殊奇偶校验 位，以确保总和为 0000。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.0,
  "end": 436.56
 },
 {
  "input": "Now once we have it like this, this gives us a really nice way to think about why these four resulting bits at the bottom directly spell out the position of an error.",
  "translatedText": "现在，一旦我们有了这样的结果，这给了我们一个非常好的方 法来思考为什么底部的这四个结果位直接拼出错误的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.04,
  "end": 447.58
 },
 {
  "input": "Let's say some bit in this block gets toggled from a 0 to a 1.",
  "translatedText": "假设此块中的某些位从 0 切换到 1。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.46,
  "end": 451.86
 },
 {
  "input": "What that means is that the position of that bit is now going to be included in the total XOR, which changes the sum from being 0 to instead being this newly included value, the position of the error.",
  "translatedText": "这意味着该位的位置现在将包含在总 XOR 中，这会将总和从 0 更改 为这个新包含的值，即错误的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.6,
  "end": 463.82
 },
 {
  "input": "Slightly less obviously, the same is true if there's an error that changes a 1 to a 0.",
  "translatedText": "不太明显的是，如果出现将 1 更 改为 0 的错误，情况也是如此。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.46,
  "end": 469.36
 },
 {
  "input": "You see, if you add a bit string together twice, it's the same as not having it there at all, basically because in this world 1 plus 1 equals 0.",
  "translatedText": "你看，如果你将一个位串加在一起两次，那就和根本没有它一 样，基本上是因为在这个世界上 1 加 1 等于 0。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.18,
  "end": 477.94
 },
 {
  "input": "So adding a copy of this position to the total sum has the same effect as we're moving it.",
  "translatedText": "因此，将此位置的副本添加到总和 中与我们移动它具有相同的效果。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.92,
  "end": 484.3
 },
 {
  "input": "And that effect, again, is that the total result at the bottom here spells out the position of the error.",
  "translatedText": "同样，这种效果是底部的总 结果阐明了错误的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.16,
  "end": 490.7
 },
 {
  "input": "To illustrate how elegant this is, let me show that one line of Python code I referenced before, which will capture almost all of the logic on the receiver's end.",
  "translatedText": "为了说明这是多么优雅，让我展示我之前引用的一行 P ython 代码，它将捕获接收器端的几乎所有逻辑。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.04,
  "end": 501.44
 },
 {
  "input": "We'll start by creating a random array of 16 1s and 0s to simulate the data block, and I'll give it the name bits, but of course in practice this would be something we're receiving from a sender, and instead of being random it would be carrying 11 data bits together with 5 parity bits.",
  "translatedText": "我们将首先创建一个由 16 个 1 和 0 组成的随 机数组来模拟数据块，我将给它命名位，但当然，在实践 中，这将是我们从发送方接收的内容，而不是如果是随机 的，它将携带 11 个数据位和 5 个奇偶校验位。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.08,
  "end": 517.4
 },
 {
  "input": "If I call the function enumerateBits, what it does is pair together each of those bits with a corresponding index, in this case running from 0 up to 15.",
  "translatedText": "如果我调用函数 enumerateBits，它的作用是将每 个位与相应的索引配对在一起，在本例中为从 0 到 15。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.12,
  "end": 527.0
 },
 {
  "input": "So if we then create a list that loops over all of these pairs, pairs that look like i, and then we pull out just the i value, just the index, well it's not that exciting, we just get back those indices 0 through 15.",
  "translatedText": "因此，如果我们创建一个列表，循环遍历所有这些对，看起来像 i 的对，然后我们只取出 i 值，只取出索引，好吧，这并 不是那么令人兴奋，我们只是取回那些索引 0 到 15。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.18,
  "end": 541.34
 },
 {
  "input": "But if we add on the condition to only do this if bit, meaning if that bit is a 1 and not a 0, well then it pulls out only the positions where the corresponding bit is turned on.",
  "translatedText": "但是，如果我们添加条件以仅执行此 if 位，即如果该位 是 1 而不是 0，那么它只会提取相应位打开的位置。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 541.68,
  "end": 552.66
 },
 {
  "input": "In this case it looks like those positions are 0, 4, 6, 9, etc.",
  "translatedText": "在本例中，这些位置看起来是 0、4、6、9 等。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.38,
  "end": 557.96
 },
 {
  "input": "What we want is to collect together all of those positions, the positions of the bits that are turned on, and then XOR them together.",
  "translatedText": "我们想要的是将所有这些位置（打开的位的位 置）收集在一起，然后将它们异或在一起。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.98,
  "end": 567.24
 },
 {
  "input": "To do this in Python, let me first import a couple helpful functions.",
  "translatedText": "为了在 Python 中执行此操作，让我首先导入几个有用的函数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.18,
  "end": 573.22
 },
 {
  "input": "That way we can call reduce() on this list, and use the XOR function to reduce it.",
  "translatedText": "这样我们就可以在这个列表上调用reduce()，并使用XOR函数来减少它。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.9,
  "end": 578.7
 },
 {
  "input": "This basically eats its way through the list, taking XORs along the way.",
  "translatedText": "这基本上会遍历列表，并一路进行异或运算。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.1,
  "end": 582.68
 },
 {
  "input": "If you prefer, you can explicitly write out that XOR function without having to import it from anywhere.",
  "translatedText": "如果您愿意，您可以显式写出该 XO R 函数，而无需从任何地方导入它。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.8,
  "end": 589.44
 },
 {
  "input": "So at the moment it looks like if we do this on our random block of 16 bits, it returns 9, which has the binary representation 1001.",
  "translatedText": "所以目前看来，如果我们对 16 位随机块执行此 操作，它会返回 9，其二进制表示为 1001。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.94,
  "end": 601.28
 },
 {
  "input": "We won't do it here, but you could write a function where the sender uses that binary representation to set the four parity bits as needed, ultimately getting this block to a state where running this line of code on the full list of bits returns a 0.",
  "translatedText": "我们不会在这里这样做，但您可以编写一个函数，其中发送方 使用该二进制表示形式根据需要设置四个奇偶校验位，最终 使该块达到在完整位列表上运行这行代码的状态一个 0。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.98,
  "end": 615.46
 },
 {
  "input": "This would be considered a well-prepared block.",
  "translatedText": "这将被认为是一个准备充分的区块。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 616.08,
  "end": 618.2
 },
 {
  "input": "What's cool is that if we toggle any one of the bits in this list, simulating a random error from noise, then if you run this same line of code, it prints out that error.",
  "translatedText": "很酷的是，如果我们切换此列表中的任何一位，模拟噪声引起的 随机错误，那么如果您运行同一行代码，它就会打印出该错误。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 619.88,
  "end": 630.22
 },
 {
  "input": "Isn't that neat?",
  "translatedText": "这不是很整洁吗？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 630.96,
  "end": 631.52
 },
 {
  "input": "You could get this block from out of the blue, run this single line on it, and it'll automatically spit out the position of an error, or a 0 if there wasn't any.",
  "translatedText": "你可以突然得到这个块，在上面运行这一行，它会 自动吐出错误的位置，如果没有错误则吐出 0。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 631.82,
  "end": 641.06
 },
 {
  "input": "And there's nothing special about the size 16 here.",
  "translatedText": "16号没有什么特别的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.5,
  "end": 645.2
 },
 {
  "input": "The same line of code would work if you had a list of, say, 256 bits.",
  "translatedText": "如果您有一个 256 位的列表，那么同一行代码也可以工作。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.4,
  "end": 649.86
 },
 {
  "input": "Needless to say, there is more code to write here, like doing the meta parity check to detect 2-bit errors, but the idea is that almost all of the core logic from our scheme comes down to a single XOR reduction.",
  "translatedText": "不用说，这里需要编写更多代码，例如进行元奇偶校验 来检测 2 位错误，但我们的想法是，我们方案中 的几乎所有核心逻辑都归结为单个 XOR 减少。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.88,
  "end": 663.76
 },
 {
  "input": "Now, depending on your comfort with binary and XORs and software in general, you may either find this perspective a little bit confusing, or so much more elegant and simple that you're wondering why we didn't just start with it from the get-go.",
  "translatedText": "现在，根据您对二进制、异或和软件的熟悉程度，您可能 会发现这种观点有点令人困惑，或者更加优雅和简单，以 至于您想知道为什么我们不从一开始就开始使用它-去。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.12,
  "end": 678.42
 },
 {
  "input": "Loosely speaking, the multiple parity check perspective is easier to think about when implementing Hamming codes in hardware very directly, and the XOR perspective is easiest to think about when doing it in software, from kind of a higher level.",
  "translatedText": "宽松地说，当非常直接地在硬件中实现汉明码时，更 容易考虑多重奇偶校验的观点，而当在软件中从更高 的层次上实现汉明码时，最容易考虑异或的观点。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 679.14,
  "end": 690.5
 },
 {
  "input": "The first one is easiest to actually do by hand, and I think it does a better job instilling the core intuition underlying all of this, which is that the information required to locate a single error is related to the log of the size of the block, or in other words, it grows one bit at a time as the block size doubles.",
  "translatedText": "第一个实际上最容易手动完成，我认为它可以更 好地灌输所有这一切背后的核心直觉，即定位单 个错误所需的信息与块大小的日志相关，或者换 句话说，随着块大小加倍，它一次增长一位。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.36,
  "end": 710.0
 },
 {
  "input": "The relevant fact here is that that information directly corresponds to how much redundancy we need.",
  "translatedText": "这里的相关事实是，该信息直 接对应于我们需要多少冗余。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.02,
  "end": 716.06
 },
 {
  "input": "That's really what runs against most people's knee-jerk reaction when they first think about making a message resilient to errors, where usually copying the whole message is the first instinct that comes to mind.",
  "translatedText": "这确实与大多数人在第一次考虑使消息 能够抵御错误时的下意识反应相悖，通 常复制整个消息是首先想到的本能。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 716.66,
  "end": 726.54
 },
 {
  "input": "And then, by the way, there is this whole other way that you sometimes see Hamming codes presented, where you multiply the message by one big matrix.",
  "translatedText": "然后，顺便说一句，有时您会看到汉明码的另 一种呈现方式，即您将消息乘以一个大矩阵。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 727.5,
  "end": 734.0
 },
 {
  "input": "It's kind of nice because it relates it to the broader family of linear codes, but I think that gives almost no intuition for where it comes from or how it scales.",
  "translatedText": "这很好，因为它将它与更广泛的线性代码家族联系起来， 但我认为这几乎没有给出它来自何处或如何扩展的直觉。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.67,
  "end": 743.06
 },
 {
  "input": "And speaking of scaling, you might notice that the efficiency of this scheme only gets better as we increase the block size.",
  "translatedText": "说到扩展，您可能会注意到，当我们增加 块大小时，该方案的效率只会变得更好。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.2,
  "end": 751.16
 },
 {
  "input": "For example, we saw that with 256 bits, you're using only 3% of that space for redundancy, and it just keeps getting better from there.",
  "translatedText": "例如，我们看到，对于 256 位，您仅使用该空间 的 3% 进行冗余，并且从那里开始变得越来越好。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.0,
  "end": 762.66
 },
 {
  "input": "As the number of parity bits grows one by one, the block size keeps doubling.",
  "translatedText": "随着奇偶校验位的数量逐个增加，块大小不断加倍。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 763.3,
  "end": 767.34
 },
 {
  "input": "And if you take that to an extreme, you could have a block with, say, a million bits, where you would quite literally be playing 20 questions with your parity checks, and it uses only 21 parity bits.",
  "translatedText": "如果你把它发挥到极致，你可能会拥有一个具有 1 00 万位的块，实际上你会用奇偶校验来回答 2 0 个问题，而它只使用 21 个奇偶校验位。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 769.0,
  "end": 780.02
 },
 {
  "input": "And if you step back to think about looking at a million bits and locating a single error, that genuinely feels crazy.",
  "translatedText": "如果你退后一步考虑查看一百万位并 找到一个错误，那真的感觉很疯狂。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 780.74,
  "end": 787.06
 },
 {
  "input": "The problem, of course, is that with a larger block, the probability of seeing more than one or two bit errors goes up, and Hamming codes do not handle anything beyond that.",
  "translatedText": "当然，问题在于，对于较大的块，看到超过一或两个位错误 的概率会上升，而汉明码无法处理超出此范围的任何内容。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 788.2,
  "end": 797.66
 },
 {
  "input": "So in practice, what you'd want is to find the right size so that the probability of too many bit flips isn't too high.",
  "translatedText": "因此，在实践中，您需要找到正确的大 小，以便太多位翻转的概率不会太高。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.32,
  "end": 804.3
 },
 {
  "input": "Also, in practice, errors tend to come in little bursts, which would totally ruin a single block, so one common tactic to help spread out a burst of errors across many different blocks is to interlace those blocks, like this, before they're sent out or stored.",
  "translatedText": "此外，在实践中，错误往往会突然出现，这会完全破坏单个块 ，因此帮助将错误突发分散到许多不同块的一种常见策略是在 这些块被破坏之前将这些块交错，就像这样。 发出或存储。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.6,
  "end": 820.98
 },
 {
  "input": "Then again, a lot of this is rendered completely moot by more modern codes, like the much more commonly used Reed-Solomon algorithm, which handles burst errors particularly well, and it can be tuned to be resilient to a larger number of errors per block.",
  "translatedText": "话又说回来，其中很多内容在更现代的代码中完全没有意义 ，比如更常用的里德-所罗门算法，它可以很好地处理突发 错误，并且可以对其进行调整以适应每个块的更多错误。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.58,
  "end": 838.82
 },
 {
  "input": "But that's a topic for another time.",
  "translatedText": "但这是另一个话题了。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.36,
  "end": 841.34
 },
 {
  "input": "In his book The Art of Doing Science and Engineering, Hamming is wonderfully candid about just how meandering his discovery of this code was.",
  "translatedText": "汉明在他的《科学与工程的艺术》一书中非常坦 诚地讲述了他发现这段代码的过程是多么曲折。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.5,
  "end": 849.94
 },
 {
  "input": "He first tried all sorts of different schemes involving organizing the bits into parts of a higher dimensional lattice and strange things like this.",
  "translatedText": "他首先尝试了各种不同的方案，包括将这些位组织 成更高维晶格的部分以及诸如此类的奇怪事物。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 850.62,
  "end": 857.78
 },
 {
  "input": "The idea that it might be possible to get parity checks to conspire in a way that spells out the position of an error only came to Hamming when he stepped back after a bunch of other analysis and asked, okay, what is the most efficient I could conceivably be about this?",
  "translatedText": "汉明在进行了一系列其他分析后退后一步，问 道：“好吧，我能做到的最有效的方法是什 么”时，他才想到了通过奇偶校验来共谋以 阐明错误位置的想法。 可能是关于这个的？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 858.3,
  "end": 871.52
 },
 {
  "input": "He was also candid about how important it was that parity checks were already on his mind, which would have been way less common back in the 1940s than it is today.",
  "translatedText": "他还坦诚地表示，奇偶校验已经在他的脑海中变得多么重要， 而在 20 世纪 40 年代，奇偶校验比今天要少得多。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 872.62,
  "end": 881.22
 },
 {
  "input": "There are like half a dozen times throughout this book that he references the Louis Pasteur quote, luck favors a prepared mind.",
  "translatedText": "在这本书中，他大约有六次引用了路易斯· 巴斯德的名言：幸运眷顾有准备的头脑。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.92,
  "end": 888.22
 },
 {
  "input": "Clever ideas often look deceptively simple in hindsight, which makes them easy to underappreciate.",
  "translatedText": "事后看来，聪明的想法往往看似简单，这使得它们很容易被低估。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.32,
  "end": 894.3
 },
 {
  "input": "Right now my honest hope is that Hamming codes, or at least the possibility of such codes, feels almost obvious to you.",
  "translatedText": "现在我真诚地希望汉明码，或者至少是这种代 码的可能性，对你来说几乎是显而易见的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.96,
  "end": 901.3
 },
 {
  "input": "But you shouldn't fool yourself into thinking that they actually are obvious, because they definitely aren't.",
  "translatedText": "但你不应该自欺欺人地认为它们实际上 是显而易见的，因为它们绝对不是。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 901.66,
  "end": 906.82
 },
 {
  "input": "Part of the reason that clever ideas look deceptively easy is that we only ever see the final result, cleaning up what was messy, never mentioning all of the wrong turns, underselling just how vast the space of explorable possibilities is at the start of a problem solving process, all of that.",
  "translatedText": "聪明的想法看起来看似简单，部分原因是我们 只看到最终结果，清理混乱的部分，从不提及 所有错误的转折，低估了问题开始时可探索的 可能性空间有多大。 解决过程，所有这一切。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.88,
  "end": 922.86
 },
 {
  "input": "But this is true in general.",
  "translatedText": "但总的来说确实如此。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 923.82,
  "end": 924.9
 },
 {
  "input": "I think for some special inventions, there's a second, deeper reason that we underappreciate them.",
  "translatedText": "我认为对于一些特殊的发明，我们低 估它们还有第二个更深层次的原因。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.9,
  "end": 930.04
 },
 {
  "input": "Thinking of information in terms of bits had only really coalesced into a full theory by 1948, with Claude Shannon's seminal paper on information theory.",
  "translatedText": "直到 1948 年，随着克劳德·香农（Claude Shannon）关于 信息论的开创性论文的出现，用比特来思考信息才真正融合成一个完整的理论。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.84,
  "end": 938.64
 },
 {
  "input": "This was essentially concurrent with when Hamming developed his algorithm.",
  "translatedText": "这基本上与汉明开发他的算法的时间同时发生。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 939.28,
  "end": 942.54
 },
 {
  "input": "This was the same foundational paper that showed, in a certain sense, that efficient error correction is always possible, no matter how high the probability of bit flips, at least in theory.",
  "translatedText": "这篇基础论文在某种意义上表明，无 论位翻转的概率有多高，有效的纠错 总是可能的，至少在理论上是这样。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.3,
  "end": 952.9
 },
 {
  "input": "Shannon and Hamming, by the way, shared an office in Bell Labs, despite working on very different things, which hardly seems coincidental here.",
  "translatedText": "顺便说一句，香农和汉明在贝尔实验室共用一间办公室， 尽管他们从事的工作截然不同，这在这里似乎并非巧合。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.7,
  "end": 961.16
 },
 {
  "input": "Fast forward several decades, and these days, many of us are so immersed in thinking about bits and information that it's easy to overlook just how distinct this way of thinking was.",
  "translatedText": "快进几十年，如今，我们中的许多人都沉浸在对比特和 信息的思考中，很容易忽视这种思维方式的独特性。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.38,
  "end": 972.34
 },
 {
  "input": "Ironically, the ideas that most profoundly shape the ways that a future generation thinks will end up looking to that future generation simpler than they really are.",
  "translatedText": "具有讽刺意味的是，那些最深刻地塑造下一代思维方 式的想法最终会在下一代人看来比实际情况更简单。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 973.1,
  "end": 982.26
 }
]