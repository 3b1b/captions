[
 {
  "input": "I'm assuming that everybody here is coming from part 1.",
  "translatedText": "אני מניח שכולם כאן מגיעים מחלק 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 2.56
 },
 {
  "input": "We were talking about Hamming codes, a way to create a block of data where most of the bits carry a meaningful message, while a few others act as a kind of redundancy, in such a way that if any bit gets flipped, either a message bit or a redundancy bit, anything in this block, a receiver is going to be able to identify that there was an error, and how to fix it.",
  "translatedText": "דיברנו על קודי Hamming, דרך ליצור גוש נתונים שבו רוב הביטים נושאים מסר משמעותי, בעוד שכמה אחרים פועלים כסוג של יתירות, באופן כזה שאם ביט כלשהו יתהפך, או הודעה סיביות או סיביות יתירות, כל דבר בבלוק הזה, מקלט יוכל לזהות שהייתה שגיאה ואיך לתקן אותה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.06,
  "end": 21.24
 },
 {
  "input": "The basic idea presented there was how to use multiple parity checks to binary search your way down to the error.",
  "translatedText": "הרעיון הבסיסי שהוצג שם היה כיצד להשתמש בבדיקות זוגיות מרובות כדי לחפש בינארי בדרך למטה אל השגיאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 21.88,
  "end": 27.16
 },
 {
  "input": "In that video the goal was to make Hamming codes feel as hands-on and rediscoverable as possible.",
  "translatedText": "בסרטון ההוא המטרה הייתה לגרום לקודי האמינג להרגיש מעשיים וניתנים לגילוי מחדש ככל האפשר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 28.98,
  "end": 34.6
 },
 {
  "input": "But as you start to think about actually implementing this, either in software or hardware, that framing may actually undersell how elegant these codes really are.",
  "translatedText": "אבל כשאתה מתחיל לחשוב על יישום זה בפועל, בתוכנה או בחומרה, המסגור הזה עשוי למעשה להמחיש עד כמה הקודים האלה אלגנטיים באמת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.18,
  "end": 43.46
 },
 {
  "input": "You might think that you need to write an algorithm that keeps track of all the possible error locations and cuts that group in half with each check, but it's actually way, way simpler than that.",
  "translatedText": "אולי אתה חושב שאתה צריך לכתוב אלגוריתם שעוקב אחר כל מיקומי השגיאות האפשריים וחותך את הקבוצה הזו לשניים עם כל בדיקה, אבל זה למעשה הרבה יותר פשוט מזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.92,
  "end": 53.48
 },
 {
  "input": "If you read out the answers to the four parity checks we did in the last video, all as 1s and 0s instead of yeses and nos, it literally spells out the position of the error in binary.",
  "translatedText": "אם אתה קורא את התשובות לארבעת בדיקות השוויון שעשינו בסרטון האחרון, כולן בתור 1 ו-0 במקום כן ולא, זה ממש מפרט את מיקום השגיאה בבינארי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.94,
  "end": 64.08
 },
 {
  "input": "For example, the number 7 in binary looks like 0111, essentially saying that it's 4 plus 2 plus 1.",
  "translatedText": "לדוגמה, המספר 7 בבינארי נראה כמו 0111, בעצם אומר שהוא 4 ועוד 2 ועוד 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 64.78,
  "end": 71.26
 },
 {
  "input": "And notice where the position 7 sits, it does affect the first of our parity groups, and the second, and the third, but not the last.",
  "translatedText": "ושימו לב היכן יושבת עמדה 7, היא אכן משפיעה על הראשונה בקבוצות השוויוניות שלנו, והשנייה, והשלישית, אך לא האחרונה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.54,
  "end": 81.74
 },
 {
  "input": "So reading the results of those four checks from bottom to top indeed does spell out the position of the error.",
  "translatedText": "אז קריאת התוצאות של ארבעת הבדיקות הללו מלמטה למעלה אכן מפרטת את מיקומו של השגיאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 82.22,
  "end": 87.54
 },
 {
  "input": "There's nothing special about the example 7, this works in general, and this makes the logic for implementing the whole scheme in hardware shockingly simple.",
  "translatedText": "אין שום דבר מיוחד בדוגמה 7, זה עובד באופן כללי, וזה הופך את ההיגיון ליישום כל הסכימה בחומרה לפשוטה להחריד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.32,
  "end": 95.82
 },
 {
  "input": "Now if you want to see why this magic happens, take these 16 index labels for our positions, but instead of writing them in base 10, let's write them all in binary, running from 0000 up to 1111.",
  "translatedText": "עכשיו אם אתה רוצה לראות למה הקסם הזה קורה, קח את 16 תוויות האינדקס האלה עבור העמדות שלנו, אבל במקום לכתוב אותן בבסיס 10, בוא נכתוב את כולם בבינארי, החל מ-0000 עד 1111.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.24,
  "end": 109.88
 },
 {
  "input": "As we put these binary labels back into their boxes, let me emphasize that they are distinct from the data that's actually being sent.",
  "translatedText": "כשאנחנו מחזירים את התוויות הבינאריות האלה לקופסאות שלהן, הרשו לי להדגיש שהן שונות מהנתונים שנשלחים בפועל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 110.56,
  "end": 117.8
 },
 {
  "input": "They're nothing more than a conceptual label to help you and me understand where the four parity groups came from.",
  "translatedText": "הם לא יותר מאשר תווית מושגית כדי לעזור לך ולי להבין מאיפה הגיעו ארבע קבוצות השוויון.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.32,
  "end": 123.5
 },
 {
  "input": "The elegance of having everything we're looking at be described in binary is maybe undercut by the confusion of having everything we're looking at being described in binary.",
  "translatedText": "האלגנטיות של זה שכל מה שאנחנו מסתכלים עליו יתואר בבינארי הוא אולי תחת הבלבול של זה שכל מה שאנחנו מסתכלים עליו מתואר בבינארי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.14,
  "end": 132.36
 },
 {
  "input": "It's worth it, though.",
  "translatedText": "אבל זה שווה את זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 133.02,
  "end": 134.12
 },
 {
  "input": "Focus your attention just on that last bit of all of these labels, and then highlight the positions where that final bit is a 1.",
  "translatedText": "מקד את תשומת לבך רק לחלק האחרון של כל התוויות הללו, ולאחר מכן הדגש את המיקומים שבהם הקטע האחרון הוא 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 143.22
 },
 {
  "input": "What we get is the first of our four parity groups, which means you can interpret that first check as asking, hey, if there's an error, is the final bit in the position of that error a 1?",
  "translatedText": "מה שאנחנו מקבלים היא הראשונה מבין ארבע קבוצות השוויון שלנו, מה שאומר שאתה יכול לפרש את הסימון הראשון הזה כשואל, היי, אם יש שגיאה, האם הביט האחרון במיקום השגיאה הוא 1?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.24,
  "end": 155.74
 },
 {
  "input": "Similarly, if you focus on the second to last bit, and highlight all the positions where that's a 1, you get the second parity group from our scheme.",
  "translatedText": "באופן דומה, אם אתה מתמקד בחלק השני עד האחרון, ומדגיש את כל המיקומים שבהם זה 1, אתה מקבל את קבוצת השוויון השנייה מהתוכנית שלנו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.2,
  "end": 166.16
 },
 {
  "input": "In other words, that second check is asking, hey, me again, if there's an error, is the second to last bit of that position a 1?",
  "translatedText": "במילים אחרות, הבדיקה השנייה שואלת, היי, שוב אני, אם יש שגיאה, האם החלק השני אחרון במיקום הזה הוא 1?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.74,
  "end": 174.5
 },
 {
  "input": "And so on.",
  "translatedText": "וכולי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 175.76,
  "end": 176.9
 },
 {
  "input": "The third parity check covers every position whose third to last bit is turned on, and the last one covers the last eight positions, those ones whose highest order bit is a 1.",
  "translatedText": "בדיקת השוויון השלישית מכסה כל עמדה שהביט השלישי עד האחרון שלה מופעל, והאחרון מכסה את שמונת העמדות האחרונות, אלה שהביט הסדר הגבוה ביותר שלהן הוא 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.22,
  "end": 188.74
 },
 {
  "input": "Everything we did earlier is the same as answering these four questions, which in turn is the same as spelling out a position in binary.",
  "translatedText": "כל מה שעשינו קודם לכן זהה למענה על ארבע השאלות הללו, וזה בתורו זהה לאיית מיקום בבינארי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.74,
  "end": 197.74
 },
 {
  "input": "I hope this makes two things clearer.",
  "translatedText": "אני מקווה שזה מבהיר שני דברים יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.62,
  "end": 201.48
 },
 {
  "input": "The first is how to systematically generalize to block sizes that are bigger powers of two.",
  "translatedText": "הראשון הוא איך להכליל באופן שיטתי לגדלי בלוקים שהם עצמות גדולות יותר של שניים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 202.04,
  "end": 206.46
 },
 {
  "input": "If it takes more bits to describe each position, like six bits to describe 64 spots, then each of those bits gives you one of the parity groups that we need to check.",
  "translatedText": "אם צריך יותר ביטים כדי לתאר כל מיקום, כמו שישה ביטים כדי לתאר 64 נקודות, אז כל אחד מהסיביות האלה נותן לך אחת מקבוצות הזוגיות שעלינו לבדוק.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.96,
  "end": 216.68
 },
 {
  "input": "Those of you who watched the chessboard puzzle I did with Matt Parker might find all this exceedingly familiar.",
  "translatedText": "אלו מכם שצפו בפאזל לוח השחמט שעשיתי עם מאט פארקר עשויים למצוא את כל זה מוכר מאוד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 218.4,
  "end": 223.18
 },
 {
  "input": "It's the same core logic, but solving a different problem, and applied to a 64-squared chessboard.",
  "translatedText": "זה אותו היגיון הליבה, אבל פתרון בעיה אחרת, מיושם על לוח שחמט של 64 ריבוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.66,
  "end": 228.78
 },
 {
  "input": "The second thing I hope this makes clear is why our parity bits are sitting in the positions that are powers of two, for example 1, 2, 4, and 8.",
  "translatedText": "הדבר השני שאני מקווה שזה מבהיר הוא מדוע סיביות השוויון שלנו יושבות בעמדות שהן חזקות של שתיים, למשל 1, 2, 4 ו-8.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.88,
  "end": 237.32
 },
 {
  "input": "These are the positions whose binary representation has just a single bit turned on.",
  "translatedText": "אלו הן העמדות שהייצוג הבינארי שלהן הופעל רק ביט בודד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.0,
  "end": 243.0
 },
 {
  "input": "What that means is each of those parity bits sits inside one and only one of the four parity groups.",
  "translatedText": "המשמעות היא שכל אחד מאותם סיביות זוגיות יושב בתוך אחת ויחידה מארבע קבוצות הזוגיות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.6,
  "end": 249.46
 },
 {
  "input": "You can also see this in larger examples, where no matter how big you get, each parity bit conveniently touches only one of the groups.",
  "translatedText": "אתה יכול לראות זאת גם בדוגמאות גדולות יותר, שבהן לא משנה כמה גדול אתה מקבל, כל סיביות זוגיות נוגעת בנוחות רק באחת מהקבוצות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.04,
  "end": 259.34
 },
 {
  "input": "Once you understand that these parity checks that we've focused so much of our time on are nothing more than a clever way to spell out the position of an error in binary, then we can draw a connection with a different way to think about hamming codes, one that is arguably a lot simpler and more elegant, and which can basically be written down with a single line of code.",
  "translatedText": "ברגע שתבינו שבדיקות השוויון האלה שהתמקדנו בהן כל כך הרבה מזמננו הן לא יותר מאשר דרך חכמה לאיית את מיקומה של שגיאה בבינארי, אז נוכל ליצור קשר עם דרך אחרת לחשוב על האמינג. קודים, אחד שהוא ללא ספק הרבה יותר פשוט ואלגנטי, ושאפשר לכתוב אותו בעצם עם שורת קוד אחת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.6,
  "end": 283.24
 },
 {
  "input": "It's based on the XOR function.",
  "translatedText": "זה מבוסס על פונקציית XOR.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.66,
  "end": 285.5
 },
 {
  "input": "XOR, for those of you who don't know, stands for exclusive or.",
  "translatedText": "XOR, למי מכם שלא יודע, מייצג בלעדי או.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 286.94,
  "end": 290.22
 },
 {
  "input": "When you take the XOR of two bits, it's going to return a 1 if either one of those bits is turned on, but not if both are turned on or off.",
  "translatedText": "כאשר אתה לוקח את ה-XOR של שני סיביות, זה יחזיר 1 אם אחד מהסיביות האלה מופעל, אבל לא אם שניהם מופעלים או כבויים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.78,
  "end": 299.36
 },
 {
  "input": "Phrased differently, it's the parity of these two bits.",
  "translatedText": "בניסוח שונה, זה השוויון של שני הביטים האלה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 300.1,
  "end": 302.98
 },
 {
  "input": "As a math person, I prefer to think about it as addition mod 2.",
  "translatedText": "כאדם מתמטיקה, אני מעדיף לחשוב על זה כעל מוד 2 של תוספת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 303.54,
  "end": 306.76
 },
 {
  "input": "We also commonly talk about the XOR of two different bit strings, which basically does this component by component.",
  "translatedText": "אנחנו גם מדברים בדרך כלל על XOR של שתי מחרוזות סיביות שונות, שבעצם עושה את זה רכיב אחר רכיב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.36,
  "end": 313.44
 },
 {
  "input": "It's like addition, but where you never carry.",
  "translatedText": "זה כמו תוספת, אבל איפה שאתה אף פעם לא נושא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 313.68,
  "end": 315.72
 },
 {
  "input": "Again, the more mathematically inclined might prefer to think of this as adding two vectors and reducing mod 2.",
  "translatedText": "שוב, בעלי נטייה מתמטית יותר עשויים להעדיף לחשוב על זה כעל הוספת שני וקטורים והקטנת מוד 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.5,
  "end": 322.48
 },
 {
  "input": "If you open up some Python right now and apply the caret operation between two integers, this is what it's doing but to the bit representations of those numbers under the hood.",
  "translatedText": "אם אתה פותח איזה Python עכשיו ומיישם את פעולת ה-caret בין שני מספרים שלמים, זה מה שהוא עושה מלבד ייצוגי הסיביות של המספרים האלה מתחת למכסה המנוע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 323.5,
  "end": 332.94
 },
 {
  "input": "The key point for you and me is that taking the XOR of many different bit strings is effectively a way to compute the parodies of a bunch of separate groups, like so with the columns, all in one fell swoop.",
  "translatedText": "נקודת המפתח עבורך ולי היא שלקיחת ה-XOR של מחרוזות סיביות שונות היא למעשה דרך לחשב את הפרודיות של חבורה של קבוצות נפרדות, כמו כך עם העמודות, הכל במכה אחת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.96,
  "end": 347.14
 },
 {
  "input": "This gives us a rather snazzy way to think about the multiple parity checks from our Hamming code algorithm as all being packaged together into one single operation.",
  "translatedText": "זה נותן לנו דרך די מטופשת לחשוב על בדיקות השוויון המרובות מאלגוריתם קוד Hamming שלנו, כשהם ארוזים יחד לפעולה אחת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.26,
  "end": 358.78
 },
 {
  "input": "Though at first glance it does look very different.",
  "translatedText": "למרות שבמבט ראשון זה נראה שונה מאוד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.48,
  "end": 362.18
 },
 {
  "input": "Specifically write down the 16 positions in binary, like we had before, and now highlight the positions where the message bit is turned on to a 1, and then collect these positions into one big column and take the XOR.",
  "translatedText": "רשום ספציפית את 16 המיקומים בבינארי, כמו שהיה לנו בעבר, ועכשיו סמן את המיקומים שבהם ביט ההודעה מופעל ל-1, ואז אסוף את המיקומים האלה לעמודה אחת גדולה ולקחת את ה-XOR.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 362.82,
  "end": 377.1
 },
 {
  "input": "You can probably guess that the 4 bits sitting at the bottom as a result are the same as the 4 parity checks we've come to know and love, but take a moment to actually think about why exactly.",
  "translatedText": "אתם בוודאי יכולים לנחש ש-4 הביטים שיושבים בתחתית כתוצאה מכך זהים ל-4 בדיקות השוויון שלמדנו להכיר ואוהבים, אבל קחו רגע לחשוב באמת למה בדיוק.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.26,
  "end": 389.2
 },
 {
  "input": "This last column, for example, is counting all of the positions whose last bit is a 1, but we're already limited only to the highlighted positions, so it's effectively counting how many highlighted positions came from the first parity group.",
  "translatedText": "העמודה האחרונה הזו, למשל, סופרת את כל המיקומים שהחלק האחרון שלהם הוא 1, אבל אנחנו כבר מוגבלים רק למיקומים המודגשים, כך שהיא למעשה סופרת כמה עמדות מודגשות הגיעו מקבוצת השוויון הראשונה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.22,
  "end": 405.76
 },
 {
  "input": "Does that make sense?",
  "translatedText": "האם זה הגיוני?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 406.24,
  "end": 406.8
 },
 {
  "input": "Likewise, the next column counts how many positions are in the second parity group, the positions whose second to last bit is a 1, and which are also highlighted, and so on.",
  "translatedText": "כמו כן, העמודה הבאה סופרת כמה עמדות יש בקבוצת השוויון השנייה, המיקומים שהביט השני אחרון שלהם הוא 1, ואשר גם הם מודגשים, וכן הלאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.08,
  "end": 420.0
 },
 {
  "input": "It's really just a small shift in perspective on the same thing we've been doing.",
  "translatedText": "זה באמת רק שינוי קטן בפרספקטיבה על אותו הדבר שעשינו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.26,
  "end": 423.96
 },
 {
  "input": "And so you know where it goes from here.",
  "translatedText": "וכך אתה יודע לאן זה הולך מכאן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 427.76,
  "end": 429.6
 },
 {
  "input": "The sender is responsible for toggling some of the special parity bits to make sure the sum works out to be 0000.",
  "translatedText": "השולח אחראי על החלפת חלק מהסיביות השוויוניות המיוחדות כדי לוודא שהסכום יגיע ל-0000.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 430.0,
  "end": 436.56
 },
 {
  "input": "Now once we have it like this, this gives us a really nice way to think about why these four resulting bits at the bottom directly spell out the position of an error.",
  "translatedText": "עכשיו ברגע שיש לנו את זה ככה, זה נותן לנו דרך ממש נחמדה לחשוב מדוע ארבעת הביטים המתקבלים האלה בתחתית מאייתים ישירות את המיקום של שגיאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.04,
  "end": 447.58
 },
 {
  "input": "Let's say some bit in this block gets toggled from a 0 to a 1.",
  "translatedText": "נניח שחלק מהגוש הזה עובר מ-0 ל-1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.46,
  "end": 451.86
 },
 {
  "input": "What that means is that the position of that bit is now going to be included in the total XOR, which changes the sum from being 0 to instead being this newly included value, the position of the error.",
  "translatedText": "מה שזה אומר הוא שהמיקום של הביט הזה ייכלל כעת ב-XOR הכולל, מה שמשנה את הסכום מ-0 לערך זה החדש שנכלל, מיקום השגיאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 452.6,
  "end": 463.82
 },
 {
  "input": "Slightly less obviously, the same is true if there's an error that changes a 1 to a 0.",
  "translatedText": "מעט פחות ברור, הדבר נכון אם יש שגיאה שמשנה 1 ל-0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 464.46,
  "end": 469.36
 },
 {
  "input": "You see, if you add a bit string together twice, it's the same as not having it there at all, basically because in this world 1 plus 1 equals 0.",
  "translatedText": "אתה מבין, אם אתה מוסיף קצת מחרוזת יחד פעמיים, זה אותו דבר כמו לא להיות שם בכלל, בעיקרון כי בעולם הזה 1 ועוד 1 שווה 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.18,
  "end": 477.94
 },
 {
  "input": "So adding a copy of this position to the total sum has the same effect as we're moving it.",
  "translatedText": "אז להוספת עותק של המיקום הזה לסכום הכולל יש את אותה השפעה כמו שאנחנו מעבירים אותו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 478.92,
  "end": 484.3
 },
 {
  "input": "And that effect, again, is that the total result at the bottom here spells out the position of the error.",
  "translatedText": "והאפקט הזה, שוב, הוא שהתוצאה הכוללת בתחתית כאן מפרטת את מיקום השגיאה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 485.16,
  "end": 490.7
 },
 {
  "input": "To illustrate how elegant this is, let me show that one line of Python code I referenced before, which will capture almost all of the logic on the receiver's end.",
  "translatedText": "כדי להמחיש עד כמה זה אלגנטי, הרשו לי להראות את השורה האחת של קוד Python שהתייחסתי אליה קודם, שתלכוד כמעט את כל ההיגיון בקצה המקלט.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 493.04,
  "end": 501.44
 },
 {
  "input": "We'll start by creating a random array of 16 1s and 0s to simulate the data block, and I'll give it the name bits, but of course in practice this would be something we're receiving from a sender, and instead of being random it would be carrying 11 data bits together with 5 parity bits.",
  "translatedText": "נתחיל ביצירת מערך אקראי של 16 1 ו-0 כדי לדמות את בלוק הנתונים, ואני אתן לו את סיביות השם, אבל כמובן שבפועל זה יהיה משהו שאנחנו מקבלים מהשולח, ובמקום בהיותו אקראי הוא יוביל 11 סיביות נתונים יחד עם 5 סיביות זוגיות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.08,
  "end": 517.4
 },
 {
  "input": "If I call the function enumerateBits, what it does is pair together each of those bits with a corresponding index, in this case running from 0 up to 15.",
  "translatedText": "אם אני קורא לפונקציה enumerateBits, מה שהיא עושה זה לצמד כל אחד מהסיביות האלה עם אינדקס מתאים, במקרה הזה מ-0 עד 15.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 518.12,
  "end": 527.0
 },
 {
  "input": "So if we then create a list that loops over all of these pairs, pairs that look like i, and then we pull out just the i value, just the index, well it's not that exciting, we just get back those indices 0 through 15.",
  "translatedText": "אז אם אנחנו יוצרים רשימה שמסתובבת בלולאה על כל הזוגות האלה, זוגות שנראים כמו i, ואז נוציא רק את ערך i, רק את המדד, ובכן, זה לא כל כך מרגש, אנחנו פשוט מקבלים בחזרה את המדדים האלה 0 עד 15.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.18,
  "end": 541.34
 },
 {
  "input": "But if we add on the condition to only do this if bit, meaning if that bit is a 1 and not a 0, well then it pulls out only the positions where the corresponding bit is turned on.",
  "translatedText": "אבל אם נוסיף את התנאי לעשות את זה רק אם ביט, כלומר אם הביט הזה הוא 1 ולא 0, ובכן, אז הוא שולף רק את המיקומים שבהם הביט המקביל מופעל.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 541.68,
  "end": 552.66
 },
 {
  "input": "In this case it looks like those positions are 0, 4, 6, 9, etc.",
  "translatedText": "במקרה זה נראה שהמיקומים האלה הם 0, 4, 6, 9 וכו'.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.38,
  "end": 557.96
 },
 {
  "input": "What we want is to collect together all of those positions, the positions of the bits that are turned on, and then XOR them together.",
  "translatedText": "מה שאנחנו רוצים זה לאסוף את כל המיקומים האלה, את המיקומים של הביטים המופעלים, ואז XOR אותם יחד.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.98,
  "end": 567.24
 },
 {
  "input": "To do this in Python, let me first import a couple helpful functions.",
  "translatedText": "כדי לעשות זאת ב- Python, תחילה תן לי לייבא כמה פונקציות מועילות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.18,
  "end": 573.22
 },
 {
  "input": "That way we can call reduce() on this list, and use the XOR function to reduce it.",
  "translatedText": "כך נוכל לקרוא ל-reduce() ברשימה זו, ולהשתמש בפונקציה XOR כדי להקטין אותה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.9,
  "end": 578.7
 },
 {
  "input": "This basically eats its way through the list, taking XORs along the way.",
  "translatedText": "זה בעצם אוכל את הדרך ברשימה, ולוקח XORs לאורך הדרך.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.1,
  "end": 582.68
 },
 {
  "input": "If you prefer, you can explicitly write out that XOR function without having to import it from anywhere.",
  "translatedText": "אם אתה מעדיף, אתה יכול לכתוב במפורש את פונקציית XOR מבלי לייבא אותה מכל מקום.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.8,
  "end": 589.44
 },
 {
  "input": "So at the moment it looks like if we do this on our random block of 16 bits, it returns 9, which has the binary representation 1001.",
  "translatedText": "אז כרגע נראה שאם נעשה זאת על הבלוק האקראי שלנו של 16 סיביות, זה מחזיר 9, שיש לו את הייצוג הבינארי 1001.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.94,
  "end": 601.28
 },
 {
  "input": "We won't do it here, but you could write a function where the sender uses that binary representation to set the four parity bits as needed, ultimately getting this block to a state where running this line of code on the full list of bits returns a 0.",
  "translatedText": "לא נעשה את זה כאן, אבל אתה יכול לכתוב פונקציה שבה השולח משתמש בייצוג הבינארי הזה כדי להגדיר את ארבעת סיביות הזוגיות לפי הצורך, ובסופו של דבר להביא את הבלוק הזה למצב שבו הפעלת שורת קוד זו ברשימת הביטים המלאה מחזירה א 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.98,
  "end": 615.46
 },
 {
  "input": "This would be considered a well-prepared block.",
  "translatedText": "זה ייחשב לבלוק מוכן היטב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 616.08,
  "end": 618.2
 },
 {
  "input": "What's cool is that if we toggle any one of the bits in this list, simulating a random error from noise, then if you run this same line of code, it prints out that error.",
  "translatedText": "מה שמגניב הוא שאם נחליף כל אחד מהסיביות ברשימה הזו, המדמה שגיאה אקראית מרעש, אז אם אתה מפעיל את אותה שורת קוד, הוא מדפיס את השגיאה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 619.88,
  "end": 630.22
 },
 {
  "input": "Isn't that neat?",
  "translatedText": "זה לא מסודר?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 630.96,
  "end": 631.52
 },
 {
  "input": "You could get this block from out of the blue, run this single line on it, and it'll automatically spit out the position of an error, or a 0 if there wasn't any.",
  "translatedText": "אתה יכול לקבל את הבלוק הזה ישר, להריץ עליו את השורה הבודדת הזו, והוא ינוק אוטומטית את המיקום של שגיאה, או 0 אם לא הייתה כזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 631.82,
  "end": 641.06
 },
 {
  "input": "And there's nothing special about the size 16 here.",
  "translatedText": "ואין כאן שום דבר מיוחד במידה 16.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 642.5,
  "end": 645.2
 },
 {
  "input": "The same line of code would work if you had a list of, say, 256 bits.",
  "translatedText": "אותה שורת קוד תעבוד אם הייתה לך רשימה של, נניח, 256 סיביות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.4,
  "end": 649.86
 },
 {
  "input": "Needless to say, there is more code to write here, like doing the meta parity check to detect 2-bit errors, but the idea is that almost all of the core logic from our scheme comes down to a single XOR reduction.",
  "translatedText": "מיותר לציין שיש עוד קוד לכתוב כאן, כמו ביצוע בדיקת מטא זוגיות כדי לזהות שגיאות של 2 סיביות, אבל הרעיון הוא שכמעט כל הלוגיקה הליבה מהסכמה שלנו מסתכמת בהפחתת XOR אחת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.88,
  "end": 663.76
 },
 {
  "input": "Now, depending on your comfort with binary and XORs and software in general, you may either find this perspective a little bit confusing, or so much more elegant and simple that you're wondering why we didn't just start with it from the get-go.",
  "translatedText": "כעת, בהתאם לנוחות שלך עם רכיבי בינארי ו-XOR ותוכנה באופן כללי, ייתכן שתמצא את הפרספקטיבה הזו קצת מבלבלת, או הרבה יותר אלגנטי ופשוט שאתה תוהה למה לא התחלנו איתה מההתחלה -ללכת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.12,
  "end": 678.42
 },
 {
  "input": "Loosely speaking, the multiple parity check perspective is easier to think about when implementing Hamming codes in hardware very directly, and the XOR perspective is easiest to think about when doing it in software, from kind of a higher level.",
  "translatedText": "באופן רופף, קל יותר לחשוב על פרספקטיבה של בדיקת זוגיות מרובה בעת יישום קודי Hamming בחומרה באופן ישיר מאוד, ואת פרספקטיבה של XOR קל יותר לחשוב עליה כאשר עושים זאת בתוכנה, מרמה גבוהה יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 679.14,
  "end": 690.5
 },
 {
  "input": "The first one is easiest to actually do by hand, and I think it does a better job instilling the core intuition underlying all of this, which is that the information required to locate a single error is related to the log of the size of the block, or in other words, it grows one bit at a time as the block size doubles.",
  "translatedText": "את הראשון הכי קל לעשות ביד, ולדעתי הוא עושה עבודה טובה יותר בהחדרת האינטואיציה הליבה העומדת בבסיס כל זה, והיא שהמידע הנדרש לאיתור שגיאה בודדת קשור ללוג של גודל הבלוק , או במילים אחרות, הוא גדל טיפה בכל פעם ככל שגודל הבלוק מכפיל את עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.36,
  "end": 710.0
 },
 {
  "input": "The relevant fact here is that that information directly corresponds to how much redundancy we need.",
  "translatedText": "העובדה הרלוונטית כאן היא שהמידע הזה מתאים ישירות לכמות היתירות שאנחנו צריכים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.02,
  "end": 716.06
 },
 {
  "input": "That's really what runs against most people's knee-jerk reaction when they first think about making a message resilient to errors, where usually copying the whole message is the first instinct that comes to mind.",
  "translatedText": "זה באמת מה שנוגד את התגובה המופרכת של רוב האנשים כשהם חושבים לראשונה על הפיכת הודעה לעמידה בפני שגיאות, כאשר בדרך כלל העתקה של כל ההודעה היא האינסטינקט הראשון שעולה בראש.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 716.66,
  "end": 726.54
 },
 {
  "input": "And then, by the way, there is this whole other way that you sometimes see Hamming codes presented, where you multiply the message by one big matrix.",
  "translatedText": "ואז, אגב, יש את כל הדרך האחרת הזו שלפעמים רואים את קודי האמינג מוצגים, שבה אתה מכפיל את המסר במטריצה אחת גדולה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 727.5,
  "end": 734.0
 },
 {
  "input": "It's kind of nice because it relates it to the broader family of linear codes, but I think that gives almost no intuition for where it comes from or how it scales.",
  "translatedText": "זה די נחמד כי זה מקשר את זה למשפחה הרחבה יותר של קודים ליניאריים, אבל אני חושב שזה כמעט לא נותן אינטואיציה מאיפה זה מגיע או איך זה מתרחב.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.67,
  "end": 743.06
 },
 {
  "input": "And speaking of scaling, you might notice that the efficiency of this scheme only gets better as we increase the block size.",
  "translatedText": "ואם כבר מדברים על קנה מידה, אולי תשים לב שהיעילות של תכנית זו רק משתפרת ככל שאנו מגדילים את גודל הבלוק.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.2,
  "end": 751.16
 },
 {
  "input": "For example, we saw that with 256 bits, you're using only 3% of that space for redundancy, and it just keeps getting better from there.",
  "translatedText": "לדוגמה, ראינו שעם 256 סיביות, אתה משתמש רק ב-3% מהשטח הזה עבור יתירות, ומשם זה רק הולך ומשתפר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 755.0,
  "end": 762.66
 },
 {
  "input": "As the number of parity bits grows one by one, the block size keeps doubling.",
  "translatedText": "ככל שמספר סיביות הזוגיות גדל בזה אחר זה, גודל הבלוק ממשיך להכפיל את עצמו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 763.3,
  "end": 767.34
 },
 {
  "input": "And if you take that to an extreme, you could have a block with, say, a million bits, where you would quite literally be playing 20 questions with your parity checks, and it uses only 21 parity bits.",
  "translatedText": "ואם אתה לוקח את זה לקיצוניות, אתה יכול לקבל בלוק עם, נגיד, מיליון ביטים, שבו אתה ממש משחק 20 שאלות עם בדיקות השוויון שלך, והוא משתמש רק ב-21 ביטים זוגיות.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 769.0,
  "end": 780.02
 },
 {
  "input": "And if you step back to think about looking at a million bits and locating a single error, that genuinely feels crazy.",
  "translatedText": "ואם אתה חוזר אחורה כדי לחשוב על להסתכל על מיליון ביטים ולאתר שגיאה בודדת, זה באמת מרגיש מטורף.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 780.74,
  "end": 787.06
 },
 {
  "input": "The problem, of course, is that with a larger block, the probability of seeing more than one or two bit errors goes up, and Hamming codes do not handle anything beyond that.",
  "translatedText": "הבעיה, כמובן, היא שעם בלוק גדול יותר, ההסתברות לראות יותר משגיאת סיביות אחת או שתיים עולה, וקודי Hamming לא מטפלים בשום דבר מעבר לזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 788.2,
  "end": 797.66
 },
 {
  "input": "So in practice, what you'd want is to find the right size so that the probability of too many bit flips isn't too high.",
  "translatedText": "אז בפועל, מה שתרצו זה למצוא את הגודל הנכון כך שההסתברות של יותר מדי ביט לא תהיה גבוהה מדי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.32,
  "end": 804.3
 },
 {
  "input": "Also, in practice, errors tend to come in little bursts, which would totally ruin a single block, so one common tactic to help spread out a burst of errors across many different blocks is to interlace those blocks, like this, before they're sent out or stored.",
  "translatedText": "כמו כן, בפועל, שגיאות נוטות להגיע בהתפרצויות קטנות, מה שיהרוס לחלוטין בלוק בודד, אז טקטיקה נפוצה אחת כדי לעזור להפיץ פרץ של שגיאות על פני בלוקים רבים ושונים היא לשלב את הבלוקים האלה, ככה, לפני שהם נשלח או נשמר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.6,
  "end": 820.98
 },
 {
  "input": "Then again, a lot of this is rendered completely moot by more modern codes, like the much more commonly used Reed-Solomon algorithm, which handles burst errors particularly well, and it can be tuned to be resilient to a larger number of errors per block.",
  "translatedText": "אז שוב, הרבה מזה הופך ללא ספק על ידי קודים מודרניים יותר, כמו אלגוריתם ריד-סולומון הנפוץ הרבה יותר, המטפל בשגיאות פרץ בצורה טובה במיוחד, וניתן לכוון אותו כך שיהיה עמיד למספר גדול יותר של שגיאות בכל בלוק.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.58,
  "end": 838.82
 },
 {
  "input": "But that's a topic for another time.",
  "translatedText": "אבל זה נושא לפעם אחרת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.36,
  "end": 841.34
 },
 {
  "input": "In his book The Art of Doing Science and Engineering, Hamming is wonderfully candid about just how meandering his discovery of this code was.",
  "translatedText": "בספרו The Art of Doing Science and Engineering, האמינג הוא כנה להפליא לגבי מידת הפיתול של גילוי הקוד הזה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 842.5,
  "end": 849.94
 },
 {
  "input": "He first tried all sorts of different schemes involving organizing the bits into parts of a higher dimensional lattice and strange things like this.",
  "translatedText": "תחילה הוא ניסה כל מיני תוכניות שונות שכללו ארגון הסיביות לחלקים של סריג ממדי גבוה יותר ודברים מוזרים כמו זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 850.62,
  "end": 857.78
 },
 {
  "input": "The idea that it might be possible to get parity checks to conspire in a way that spells out the position of an error only came to Hamming when he stepped back after a bunch of other analysis and asked, okay, what is the most efficient I could conceivably be about this?",
  "translatedText": "הרעיון שאולי אפשר לקבל בדיקות זוגיות כדי ליצור קשר בצורה שתפרט את המיקום של שגיאה, הגיע להאמינג רק כשהוא נסוג לאחר שלל ניתוחים אחרים ושאל, בסדר, מה הכי יעיל שיכולתי. אפשר לחשוב על זה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 858.3,
  "end": 871.52
 },
 {
  "input": "He was also candid about how important it was that parity checks were already on his mind, which would have been way less common back in the 1940s than it is today.",
  "translatedText": "הוא גם היה כנה לגבי כמה חשוב שבדיקות זוגיות כבר היו בראש שלו, מה שהיה הרבה פחות נפוץ בשנות הארבעים מאשר היום.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 872.62,
  "end": 881.22
 },
 {
  "input": "There are like half a dozen times throughout this book that he references the Louis Pasteur quote, luck favors a prepared mind.",
  "translatedText": "יש כמו חצי תריסר פעמים במהלך הספר הזה שהוא מתייחס לציטוט של לואי פסטר, המזל מעדיף מוח מוכן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 881.92,
  "end": 888.22
 },
 {
  "input": "Clever ideas often look deceptively simple in hindsight, which makes them easy to underappreciate.",
  "translatedText": "רעיונות חכמים נראים לעתים קרובות פשוטים בצורה מטעה במבט לאחור, מה שמקל על הערכה נמוכה יותר.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 889.32,
  "end": 894.3
 },
 {
  "input": "Right now my honest hope is that Hamming codes, or at least the possibility of such codes, feels almost obvious to you.",
  "translatedText": "כרגע תקוותי הכנה היא שקודי האמינג, או לפחות האפשרות של קודים כאלה, מרגישים לך כמעט ברורים.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 894.96,
  "end": 901.3
 },
 {
  "input": "But you shouldn't fool yourself into thinking that they actually are obvious, because they definitely aren't.",
  "translatedText": "אבל אתה לא צריך להטעות את עצמך לחשוב שהם בעצם ברורים, כי הם בהחלט לא.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 901.66,
  "end": 906.82
 },
 {
  "input": "Part of the reason that clever ideas look deceptively easy is that we only ever see the final result, cleaning up what was messy, never mentioning all of the wrong turns, underselling just how vast the space of explorable possibilities is at the start of a problem solving process, all of that.",
  "translatedText": "חלק מהסיבה שרעיונות חכמים נראים קלים בצורה מטעה היא שאנחנו רואים רק את התוצאה הסופית, מנקים את מה שהיה מבולגן, אף פעם לא מזכירים את כל הפניות הלא נכונות, ומדגישים עד כמה עצום המרחב של האפשרויות הניתנות לחקירה בתחילת בעיה תהליך פתרון, כל זה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 907.88,
  "end": 922.86
 },
 {
  "input": "But this is true in general.",
  "translatedText": "אבל זה נכון באופן כללי.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 923.82,
  "end": 924.9
 },
 {
  "input": "I think for some special inventions, there's a second, deeper reason that we underappreciate them.",
  "translatedText": "אני חושב שלכמה המצאות מיוחדות, יש סיבה שנייה, עמוקה יותר לכך שאנחנו פחות מעריכים אותן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 924.9,
  "end": 930.04
 },
 {
  "input": "Thinking of information in terms of bits had only really coalesced into a full theory by 1948, with Claude Shannon's seminal paper on information theory.",
  "translatedText": "חשיבה על מידע במונחים של ביטים התלכדה לתיאוריה מלאה רק ב-1948, עם המאמר המכונן של קלוד שאנון על תורת המידע.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 930.84,
  "end": 938.64
 },
 {
  "input": "This was essentially concurrent with when Hamming developed his algorithm.",
  "translatedText": "זה היה בעצם במקביל לזמן שבו האמינג פיתח את האלגוריתם שלו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 939.28,
  "end": 942.54
 },
 {
  "input": "This was the same foundational paper that showed, in a certain sense, that efficient error correction is always possible, no matter how high the probability of bit flips, at least in theory.",
  "translatedText": "זה היה אותו מאמר יסוד שהראה, במובן מסוים, שתיקון שגיאות יעיל תמיד אפשרי, לא משנה כמה גבוהה ההסתברות להיפוך סיביות, לפחות בתיאוריה.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 943.3,
  "end": 952.9
 },
 {
  "input": "Shannon and Hamming, by the way, shared an office in Bell Labs, despite working on very different things, which hardly seems coincidental here.",
  "translatedText": "שאנון והאמינג, אגב, חלקו משרד ב-Bell Labs, למרות שעבדו על דברים שונים מאוד, מה שכמעט ולא נראה מקרי כאן.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 953.7,
  "end": 961.16
 },
 {
  "input": "Fast forward several decades, and these days, many of us are so immersed in thinking about bits and information that it's easy to overlook just how distinct this way of thinking was.",
  "translatedText": "הרץ קדימה כמה עשורים, ובימים אלה, רבים מאיתנו שקועים כל כך בחשיבה על פיסות ומידע שקל להתעלם עד כמה הייתה צורת החשיבה הזו מובחנת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.38,
  "end": 972.34
 },
 {
  "input": "Ironically, the ideas that most profoundly shape the ways that a future generation thinks will end up looking to that future generation simpler than they really are.",
  "translatedText": "למרבה האירוניה, הרעיונות שמעצבים בצורה העמוקה ביותר את הדרכים שדור העתיד חושב יסתכלו בסופו של דבר על אותו דור העתיד פשוטות יותר ממה שהם באמת.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 973.1,
  "end": 982.26
 }
]