1
00:00:00,000 --> 00:00:02,560
Presumo che tutti qui provengano dalla parte 1.

2
00:00:03,060 --> 00:00:06,704
Stavamo parlando dei codici di Hamming, un modo per creare un blocco di dati in cui 

3
00:00:06,704 --> 00:00:09,264
la maggior parte dei bit porta un messaggio significativo, 

4
00:00:09,264 --> 00:00:11,824
mentre alcuni altri agiscono come una sorta di ridondanza, 

5
00:00:11,824 --> 00:00:13,950
in modo tale che se qualche bit viene invertito, 

6
00:00:13,950 --> 00:00:17,248
o un messaggio bit o un bit di ridondanza, qualsiasi cosa in questo blocco, 

7
00:00:17,248 --> 00:00:20,762
un ricevitore sarà in grado di identificare che si è verificato un errore e come 

8
00:00:20,762 --> 00:00:21,240
risolverlo.

9
00:00:21,880 --> 00:00:24,561
L'idea di base presentata era come utilizzare più controlli 

10
00:00:24,561 --> 00:00:27,160
di parità per eseguire la ricerca binaria fino all'errore.

11
00:00:28,980 --> 00:00:31,790
In quel video l'obiettivo era rendere i codici 

12
00:00:31,790 --> 00:00:34,600
di Hamming il più pratici e riscopribili possibile.

13
00:00:35,180 --> 00:00:37,849
Ma quando inizi a pensare di implementarlo effettivamente, 

14
00:00:37,849 --> 00:00:40,519
sia nel software che nell'hardware, l'inquadratura 

15
00:00:40,519 --> 00:00:43,460
potrebbe effettivamente sminuire l'eleganza di questi codici.

16
00:00:43,920 --> 00:00:47,106
Potresti pensare di dover scrivere un algoritmo che tenga traccia di 

17
00:00:47,106 --> 00:00:51,217
tutte le possibili posizioni degli errori e divida quel gruppo a metà ad ogni controllo, 

18
00:00:51,217 --> 00:00:53,480
ma in realtà è molto, molto più semplice di così.

19
00:00:53,940 --> 00:00:57,352
Se leggi le risposte ai quattro controlli di parità che abbiamo fatto 

20
00:00:57,352 --> 00:01:00,277
nell'ultimo video, tutte come 1 e 0 invece che sì e no, 

21
00:01:00,277 --> 00:01:04,080
viene letteralmente precisata la posizione dell'errore in formato binario.

22
00:01:04,780 --> 00:01:08,081
Ad esempio, il numero 7 in binario assomiglia a 0111, 

23
00:01:08,081 --> 00:01:11,260
il che significa essenzialmente che è 4 più 2 più 1.

24
00:01:12,540 --> 00:01:18,696
E notate dove si trova la posizione 7, influenza il primo dei nostri gruppi di parità, 

25
00:01:18,696 --> 00:01:21,740
il secondo e il terzo, ma non l'ultimo.

26
00:01:22,220 --> 00:01:24,731
Quindi leggere i risultati di questi quattro controlli dal 

27
00:01:24,731 --> 00:01:27,540
basso verso l’alto effettivamente spiega la posizione dell’errore.

28
00:01:28,320 --> 00:01:30,481
Non c'è niente di speciale nell'esempio 7, 

29
00:01:30,481 --> 00:01:33,997
funziona in generale e questo rende la logica per implementare l'intero schema 

30
00:01:33,997 --> 00:01:35,820
nell'hardware incredibilmente semplice.

31
00:01:37,240 --> 00:01:40,433
Ora se vuoi vedere perché avviene questa magia, 

32
00:01:40,433 --> 00:01:44,557
prendi queste 16 etichette di indice per le nostre posizioni, 

33
00:01:44,557 --> 00:01:49,880
ma invece di scriverle in base 10, scriviamole tutte in binario, da 0000 a 1111.

34
00:01:50,559 --> 00:01:53,889
Mentre rimettiamo queste etichette binarie nelle loro scatole, 

35
00:01:53,889 --> 00:01:57,800
lasciatemi sottolineare che sono distinte dai dati effettivamente inviati.

36
00:01:58,320 --> 00:02:00,846
Non sono altro che un'etichetta concettuale per aiutare 

37
00:02:00,846 --> 00:02:03,500
te e me a capire da dove provengono i quattro gruppi di parità.

38
00:02:04,140 --> 00:02:08,131
L'eleganza di avere tutto ciò che stiamo guardando descritto in binario è forse 

39
00:02:08,131 --> 00:02:12,360
indebolita dalla confusione di avere tutto ciò che stiamo guardando descritto in binario.

40
00:02:13,020 --> 00:02:14,120
Ne vale la pena, però.

41
00:02:14,800 --> 00:02:19,561
Concentra la tua attenzione solo sull'ultima parte di tutte queste etichette, 

42
00:02:19,561 --> 00:02:23,220
quindi evidenzia le posizioni in cui l'ultima parte è un 1.

43
00:02:24,240 --> 00:02:27,583
Ciò che otteniamo è il primo dei nostri quattro gruppi di parità, 

44
00:02:27,583 --> 00:02:31,484
il che significa che puoi interpretare il primo controllo come se chiedessi, 

45
00:02:31,484 --> 00:02:35,740
ehi, se c'è un errore, l'ultimo bit nella posizione di quell'errore è 1?

46
00:02:38,200 --> 00:02:42,022
Allo stesso modo, se ti concentri sul penultimo bit ed evidenzi tutte le 

47
00:02:42,022 --> 00:02:46,160
posizioni in cui è un 1, ottieni il secondo gruppo di parità dal nostro schema.

48
00:02:46,740 --> 00:02:50,560
In altre parole, il secondo controllo chiede, ehi, di nuovo io, 

49
00:02:50,560 --> 00:02:54,500
se c'è un errore, il penultimo bit di quella posizione è un 1?

50
00:02:55,760 --> 00:02:56,900
E così via.

51
00:02:57,220 --> 00:03:02,846
Il terzo controllo di parità copre ogni posizione il cui terzultimo bit è attivato, 

52
00:03:02,846 --> 00:03:08,740
e l'ultimo copre le ultime otto posizioni, quelle il cui bit di ordine più alto è 1.

53
00:03:09,740 --> 00:03:14,098
Tutto quello che abbiamo fatto prima equivale a rispondere a queste quattro domande, 

54
00:03:14,098 --> 00:03:17,740
che a sua volta equivale a descrivere una posizione in formato binario.

55
00:03:19,620 --> 00:03:21,480
Spero che questo renda più chiare due cose.

56
00:03:22,040 --> 00:03:24,168
Il primo è come generalizzare sistematicamente alle 

57
00:03:24,168 --> 00:03:26,460
dimensioni dei blocchi che sono potenze maggiori di due.

58
00:03:26,960 --> 00:03:30,130
Se sono necessari più bit per descrivere ciascuna posizione, 

59
00:03:30,130 --> 00:03:33,405
ad esempio sei bit per descrivere 64 punti, ciascuno di questi 

60
00:03:33,405 --> 00:03:36,680
bit fornisce uno dei gruppi di parità che dobbiamo controllare.

61
00:03:38,400 --> 00:03:40,902
Quelli di voi che hanno guardato il puzzle sulla scacchiera che ho realizzato 

62
00:03:40,902 --> 00:03:43,180
con Matt Parker potrebbero trovare tutto questo estremamente familiare.

63
00:03:43,660 --> 00:03:46,220
È la stessa logica di base, ma risolve un problema 

64
00:03:46,220 --> 00:03:48,780
diverso e applicata a una scacchiera da 64 caselle.

65
00:03:49,880 --> 00:03:53,549
La seconda cosa che spero venga chiarita è perché i nostri bit di parità 

66
00:03:53,549 --> 00:03:57,320
si trovano nelle posizioni che sono potenze di due, ad esempio 1, 2, 4 e 8.

67
00:03:58,000 --> 00:04:03,000
Queste sono le posizioni la cui rappresentazione binaria ha un solo bit attivato.

68
00:04:03,600 --> 00:04:06,458
Ciò significa che ciascuno di questi bit di parità si trova 

69
00:04:06,458 --> 00:04:09,460
all'interno di uno e solo uno dei quattro gruppi di parità.

70
00:04:12,040 --> 00:04:16,450
Puoi vedere questo anche in esempi più grandi, dove non importa quanto diventi grande, 

71
00:04:16,450 --> 00:04:19,339
ogni bit di parità tocca comodamente solo uno dei gruppi.

72
00:04:25,600 --> 00:04:29,035
Una volta compreso che questi controlli di parità su cui abbiamo concentrato gran 

73
00:04:29,035 --> 00:04:32,387
parte del nostro tempo non sono altro che un modo intelligente per precisare la 

74
00:04:32,387 --> 00:04:35,907
posizione di un errore in binario, allora possiamo stabilire una connessione con un 

75
00:04:35,907 --> 00:04:37,918
modo diverso di pensare all'hamming codici, 

76
00:04:37,918 --> 00:04:41,605
uno che è probabilmente molto più semplice ed elegante e che può essere sostanzialmente 

77
00:04:41,605 --> 00:04:43,240
scritto con una singola riga di codice.

78
00:04:43,660 --> 00:04:45,500
Si basa sulla funzione XOR.

79
00:04:46,940 --> 00:04:50,220
XOR, per quelli di voi che non lo sanno, sta per esclusivo o.

80
00:04:50,780 --> 00:04:56,159
Quando prendi lo XOR di due bit, restituirà 1 se uno di questi bit è attivato, 

81
00:04:56,159 --> 00:04:59,360
ma non se entrambi sono attivati o disattivati.

82
00:05:00,100 --> 00:05:02,980
Detto diversamente, è la parità di questi due bit.

83
00:05:03,540 --> 00:05:06,760
Essendo una persona matematica, preferisco pensarlo come addizione mod 2.

84
00:05:07,360 --> 00:05:10,587
Parliamo comunemente anche dello XOR di due diverse stringhe di bit, 

85
00:05:10,587 --> 00:05:13,440
che fondamentalmente esegue questo componente per componente.

86
00:05:13,680 --> 00:05:15,720
È come un'addizione, ma dove non porti mai.

87
00:05:16,500 --> 00:05:19,579
Ancora una volta, i più inclini alla matematica potrebbero preferire 

88
00:05:19,579 --> 00:05:22,480
pensare a questo come addizionare due vettori e ridurre il mod 2.

89
00:05:23,500 --> 00:05:26,793
Se apri un po' di Python in questo momento e applichi l'operazione 

90
00:05:26,793 --> 00:05:30,173
di accento circonflesso tra due numeri interi, questo è ciò che sta facendo, 

91
00:05:30,173 --> 00:05:32,940
ma alle rappresentazioni in bit di quei numeri sotto il cofano.

92
00:05:34,960 --> 00:05:38,926
Il punto chiave per te e me è che prendere lo XOR di molte stringhe di 

93
00:05:38,926 --> 00:05:43,117
bit diverse è effettivamente un modo per calcolare le parodie di un gruppo 

94
00:05:43,117 --> 00:05:47,140
di gruppi separati, come nel caso delle colonne, tutto in un colpo solo.

95
00:05:51,260 --> 00:05:53,857
Questo ci offre un modo piuttosto elegante di pensare ai controlli 

96
00:05:53,857 --> 00:05:56,299
di parità multipli del nostro algoritmo di codice Hamming come 

97
00:05:56,299 --> 00:05:58,780
se fossero tutti raggruppati insieme in un'unica operazione.

98
00:05:59,479 --> 00:06:02,180
Anche se a prima vista sembra molto diverso.

99
00:06:02,820 --> 00:06:07,262
Annota specificamente le 16 posizioni in binario, come avevamo prima, 

100
00:06:07,262 --> 00:06:12,022
e ora evidenzia le posizioni in cui il bit del messaggio è impostato su 1, 

101
00:06:12,022 --> 00:06:17,100
quindi raccogli queste posizioni in un'unica grande colonna e prendi lo XOR.

102
00:06:19,260 --> 00:06:22,715
Probabilmente puoi immaginare che i 4 bit che si trovano in fondo come risultato 

103
00:06:22,715 --> 00:06:26,427
sono gli stessi dei 4 controlli di parità che abbiamo imparato a conoscere e ad amare, 

104
00:06:26,427 --> 00:06:29,200
ma prenditi un momento per pensare davvero al perché esattamente.

105
00:06:32,220 --> 00:06:37,260
Quest'ultima colonna, ad esempio, conta tutte le posizioni il cui ultimo bit è 1, 

106
00:06:37,260 --> 00:06:40,484
ma siamo già limitati solo alle posizioni evidenziate, 

107
00:06:40,484 --> 00:06:45,760
quindi in realtà conta quante posizioni evidenziate provengono dal primo gruppo di parità.

108
00:06:46,240 --> 00:06:46,800
Ha senso?

109
00:06:49,080 --> 00:06:52,739
Allo stesso modo, la colonna successiva conta quante posizioni 

110
00:06:52,739 --> 00:06:56,108
ci sono nel secondo gruppo di parità, le posizioni il cui 

111
00:06:56,108 --> 00:07:00,000
penultimo bit è 1 e che sono anch'esse evidenziate, e così via.

112
00:07:00,260 --> 00:07:02,448
In realtà è solo un piccolo cambiamento di prospettiva 

113
00:07:02,448 --> 00:07:03,960
sulla stessa cosa che stavamo facendo.

114
00:07:07,760 --> 00:07:09,600
E quindi sai dove andrà da qui.

115
00:07:10,000 --> 00:07:12,837
Il mittente è responsabile della commutazione di alcuni bit di 

116
00:07:12,837 --> 00:07:15,720
parità speciali per assicurarsi che la somma corrisponda a 0000.

117
00:07:15,720 --> 00:07:19,571
Ora, una volta ottenuto questo risultato, questo ci dà un modo 

118
00:07:19,571 --> 00:07:23,422
davvero carino di pensare al motivo per cui questi quattro bit 

119
00:07:23,422 --> 00:07:27,580
risultanti in basso indicano direttamente la posizione di un errore.

120
00:07:28,460 --> 00:07:31,860
Diciamo che qualche bit in questo blocco viene commutato da 0 a 1.

121
00:07:32,600 --> 00:07:38,004
Ciò significa che la posizione di quel bit verrà ora inclusa nello XOR totale, 

122
00:07:38,004 --> 00:07:43,820
che cambia la somma da 0 a questo nuovo valore incluso, la posizione dell'errore.

123
00:07:44,460 --> 00:07:46,934
In modo leggermente meno ovvio, lo stesso vale se 

124
00:07:46,934 --> 00:07:49,360
si verifica un errore che modifica un 1 in uno 0.

125
00:07:50,180 --> 00:07:54,515
Vedi, se aggiungi una stringa di bit due volte, è come non averla affatto, 

126
00:07:54,515 --> 00:07:57,580
fondamentalmente perché in questo mondo 1 più 1 fa 0.

127
00:07:57,580 --> 00:08:00,805
Quindi aggiungere una copia di questa posizione 

128
00:08:00,805 --> 00:08:04,300
alla somma totale ha lo stesso effetto di spostarla.

129
00:08:05,160 --> 00:08:07,905
E questo effetto, ancora una volta, è che il risultato 

130
00:08:07,905 --> 00:08:10,700
totale qui in basso indica la posizione dell'errore.

131
00:08:13,039 --> 00:08:17,122
Per illustrare quanto sia elegante, lasciatemi mostrare quella riga di codice Python a 

132
00:08:17,122 --> 00:08:20,923
cui ho fatto riferimento prima, che catturerà quasi tutta la logica sul lato del 

133
00:08:20,923 --> 00:08:21,440
ricevitore.

134
00:08:22,080 --> 00:08:26,500
Inizieremo creando un array casuale di 16 1 e 0 per simulare il blocco di dati, 

135
00:08:26,500 --> 00:08:31,474
e gli darò i bit del nome, ma ovviamente in pratica questo sarebbe qualcosa che riceviamo 

136
00:08:31,474 --> 00:08:36,447
da un mittente, e invece di essendo casuale trasporterebbe 11 bit di dati insieme a 5 bit 

137
00:08:36,447 --> 00:08:37,000
di parità.

138
00:08:37,000 --> 00:08:42,109
Se chiamo la funzione enumerateBits, ciò che fa è accoppiare ciascuno 

139
00:08:42,109 --> 00:08:47,000
di quei bit con un indice corrispondente, in questo caso da 0 a 15.

140
00:08:48,180 --> 00:08:52,070
Quindi, se poi creiamo un elenco che scorre su tutte queste coppie, 

141
00:08:52,070 --> 00:08:55,904
coppie che assomigliano a i, e poi tiriamo fuori solo il valore i, 

142
00:08:55,904 --> 00:09:00,367
solo l'indice, beh non è così eccitante, recuperiamo semplicemente quegli 

143
00:09:00,367 --> 00:09:01,340
indici da 0 a 15.

144
00:09:01,680 --> 00:09:05,230
Ma se aggiungiamo la condizione di farlo solo se bit, 

145
00:09:05,230 --> 00:09:10,687
ovvero se quel bit è un 1 e non uno 0, allora estrarrà solo le posizioni in cui il 

146
00:09:10,687 --> 00:09:12,660
bit corrispondente è attivato.

147
00:09:13,380 --> 00:09:20,360
In questo caso sembra che quelle posizioni siano 0, 4, 6, 9, ecc.

148
00:09:20,720 --> 00:09:24,247
Quello che vogliamo è raccogliere insieme tutte quelle posizioni, 

149
00:09:24,247 --> 00:09:27,240
le posizioni dei bit che sono accesi, e poi XOR insieme.

150
00:09:29,180 --> 00:09:33,220
Per fare ciò in Python, lasciatemi prima importare un paio di funzioni utili.

151
00:09:33,900 --> 00:09:36,396
In questo modo possiamo chiamare reduce() su questo 

152
00:09:36,396 --> 00:09:38,700
elenco e utilizzare la funzione XOR per ridurlo.

153
00:09:39,100 --> 00:09:41,473
Questo sostanzialmente si fa strada attraverso l'elenco, 

154
00:09:41,473 --> 00:09:42,680
portando XOR lungo il percorso.

155
00:09:44,800 --> 00:09:46,959
Se preferisci, puoi scrivere esplicitamente la 

156
00:09:46,959 --> 00:09:49,440
funzione XOR senza doverla importare da nessuna parte.

157
00:09:51,940 --> 00:09:57,502
Quindi al momento sembra che se lo facciamo sul nostro blocco casuale di 16 bit, 

158
00:09:57,502 --> 00:10:01,280
restituisce 9, che ha la rappresentazione binaria 1001.

159
00:10:01,980 --> 00:10:05,479
Non lo faremo qui, ma potresti scrivere una funzione in cui il mittente utilizza 

160
00:10:05,479 --> 00:10:09,324
quella rappresentazione binaria per impostare i quattro bit di parità secondo necessità, 

161
00:10:09,324 --> 00:10:12,608
portando infine questo blocco a uno stato in cui l'esecuzione di questa 

162
00:10:12,608 --> 00:10:15,460
riga di codice sull'elenco completo dei bit restituisce uno 0.

163
00:10:16,080 --> 00:10:20,100
Questo sarebbe considerato un blocco ben preparato.

164
00:10:20,100 --> 00:10:24,273
La cosa interessante è che se attiviamo uno qualsiasi dei bit in questo elenco, 

165
00:10:24,273 --> 00:10:28,550
simulando un errore casuale dovuto al rumore, se esegui la stessa riga di codice, 

166
00:10:28,550 --> 00:10:30,220
viene stampato quell'errore.

167
00:10:30,960 --> 00:10:31,520
Non è carino?

168
00:10:31,820 --> 00:10:34,613
Potresti prendere questo blocco all'improvviso, 

169
00:10:34,613 --> 00:10:39,179
eseguire questa singola riga su di esso e sputerà automaticamente la posizione di un 

170
00:10:39,179 --> 00:10:41,060
errore o uno 0 se non ce n'era.

171
00:10:42,500 --> 00:10:44,840
E qui non c'è niente di speciale nella taglia 16.

172
00:10:44,840 --> 00:10:49,860
La stessa riga di codice funzionerebbe se avessi un elenco di, diciamo, 256 bit.

173
00:10:51,880 --> 00:10:54,582
Inutile dire che c'è più codice da scrivere qui, 

174
00:10:54,582 --> 00:10:58,355
come eseguire il controllo della meta parità per rilevare errori a 2 bit, 

175
00:10:58,355 --> 00:11:02,332
ma l'idea è che quasi tutta la logica di base del nostro schema si riduce 

176
00:11:02,332 --> 00:11:03,760
a una singola riduzione XOR.

177
00:11:06,120 --> 00:11:10,565
Ora, a seconda della tua dimestichezza con il binario, gli XOR e il software in generale, 

178
00:11:10,565 --> 00:11:13,332
potresti trovare questa prospettiva un po' confusa, 

179
00:11:13,332 --> 00:11:17,234
o molto più elegante e semplice da chiederti perché non l'abbiamo iniziata 

180
00:11:17,234 --> 00:11:18,420
dall'inizio -andare.

181
00:11:19,140 --> 00:11:22,940
In parole povere, la prospettiva del controllo di parità multipla è più facile da pensare 

182
00:11:22,940 --> 00:11:26,361
quando si implementano i codici Hamming nell'hardware in modo molto diretto, 

183
00:11:26,361 --> 00:11:29,528
e la prospettiva XOR è più facile da pensare quando lo si fa nel software, 

184
00:11:29,528 --> 00:11:30,500
da un livello più alto.

185
00:11:31,360 --> 00:11:34,977
Il primo è più semplice da eseguire a mano e penso che svolga un lavoro 

186
00:11:34,977 --> 00:11:38,745
migliore instillando l'intuizione fondamentale alla base di tutto ciò, 

187
00:11:38,745 --> 00:11:42,463
ovvero che l'informazione richiesta per individuare un singolo errore 

188
00:11:42,463 --> 00:11:46,131
è correlata al registro della dimensione del blocco , o in altre parole, 

189
00:11:46,131 --> 00:11:50,000
cresce un po' alla volta man mano che la dimensione del blocco raddoppia.

190
00:11:51,020 --> 00:11:53,479
Il fatto rilevante qui è che tali informazioni corrispondono 

191
00:11:53,479 --> 00:11:56,060
direttamente alla quantità di ridondanza di cui abbiamo bisogno.

192
00:11:56,660 --> 00:11:59,838
Questo è proprio ciò che va contro la reazione istintiva della maggior parte delle 

193
00:11:59,838 --> 00:12:03,246
persone quando pensano per la prima volta a rendere un messaggio resistente agli errori, 

194
00:12:03,246 --> 00:12:06,540
mentre di solito copiare l'intero messaggio è il primo istinto che viene in mente.

195
00:12:07,500 --> 00:12:10,809
E poi, a proposito, c'è tutto questo altro modo in cui a volte vedi presentati 

196
00:12:10,809 --> 00:12:14,000
i codici Hamming, dove moltiplichi il messaggio per un'unica grande matrice.

197
00:12:14,670 --> 00:12:18,410
È carino perché lo collega alla più ampia famiglia di codici lineari, 

198
00:12:18,410 --> 00:12:23,060
ma penso che non dia quasi alcuna intuizione sulla sua provenienza o su come si adatta.

199
00:12:25,200 --> 00:12:28,221
E parlando di ridimensionamento, potresti notare che l'efficienza di 

200
00:12:28,221 --> 00:12:31,160
questo schema migliora solo quando aumentiamo la dimensione del blocco.

201
00:12:35,000 --> 00:12:38,908
Ad esempio, abbiamo visto che con 256 bit si utilizza solo il 3% di quello 

202
00:12:38,908 --> 00:12:42,660
spazio per la ridondanza e da lì in poi le cose continuano a migliorare.

203
00:12:43,300 --> 00:12:45,544
Man mano che il numero di bit di parità cresce uno per uno, 

204
00:12:45,544 --> 00:12:47,340
la dimensione del blocco continua a raddoppiare.

205
00:12:49,000 --> 00:12:52,895
E se lo porti all'estremo, potresti avere un blocco con, diciamo, 

206
00:12:52,895 --> 00:12:56,624
un milione di bit, dove giocheresti letteralmente a 20 domande con 

207
00:12:56,624 --> 00:13:00,020
i tuoi controlli di parità, e utilizza solo 21 bit di parità.

208
00:13:00,740 --> 00:13:03,873
E se fai un passo indietro e pensi a guardare un milione di 

209
00:13:03,873 --> 00:13:07,060
bit e individuare un singolo errore, sembra davvero pazzesco.

210
00:13:08,199 --> 00:13:11,195
Il problema, ovviamente, è che con un blocco più grande, 

211
00:13:11,195 --> 00:13:14,611
la probabilità di vedere più di uno o due bit di errore aumenta, 

212
00:13:14,611 --> 00:13:17,660
e i codici di Hamming non gestiscono nulla oltre a questo.

213
00:13:18,320 --> 00:13:21,270
Quindi, in pratica, quello che vorresti è trovare la dimensione giusta in 

214
00:13:21,270 --> 00:13:24,300
modo che la probabilità di troppi capovolgimenti di bit non sia troppo alta.

215
00:13:26,600 --> 00:13:29,795
Inoltre, in pratica, gli errori tendono a verificarsi in piccoli blocchi, 

216
00:13:29,795 --> 00:13:32,041
il che rovinerebbe completamente un singolo blocco, 

217
00:13:32,041 --> 00:13:35,711
quindi una tattica comune per aiutare a distribuire un'ondata di errori su molti 

218
00:13:35,711 --> 00:13:38,820
blocchi diversi è quella di intrecciare questi blocchi, in questo modo, 

219
00:13:38,820 --> 00:13:40,980
prima che vengano eliminati. inviato o archiviato.

220
00:13:45,580 --> 00:13:48,812
D'altra parte, gran parte di questo è reso completamente discutibile 

221
00:13:48,812 --> 00:13:52,620
da codici più moderni, come l'algoritmo Reed-Solomon molto più comunemente usato, 

222
00:13:52,620 --> 00:13:55,986
che gestisce gli errori di burst particolarmente bene e può essere regolato 

223
00:13:55,986 --> 00:13:58,820
per essere resiliente a un numero maggiore di errori per blocco.

224
00:13:59,360 --> 00:14:01,340
Ma questo è un argomento per un'altra volta.

225
00:14:02,500 --> 00:14:05,071
Nel suo libro The Art of Doing Science and Engineering, 

226
00:14:05,071 --> 00:14:08,745
Hamming è meravigliosamente sincero riguardo a quanto tortuosa sia stata la sua 

227
00:14:08,745 --> 00:14:09,940
scoperta di questo codice.

228
00:14:10,620 --> 00:14:13,572
Per prima cosa ha provato tutti i tipi di schemi diversi che prevedevano 

229
00:14:13,572 --> 00:14:17,011
l'organizzazione dei pezzi in parti di un reticolo dimensionale superiore e cose 

230
00:14:17,011 --> 00:14:17,780
strane come questa.

231
00:14:18,300 --> 00:14:21,435
L'idea che potrebbe essere possibile ottenere controlli di parità per 

232
00:14:21,435 --> 00:14:24,825
cospirare in un modo che espliciti la posizione di un errore è venuta a Hamming 

233
00:14:24,825 --> 00:14:28,426
solo quando ha fatto un passo indietro dopo una serie di altre analisi e ha chiesto, 

234
00:14:28,426 --> 00:14:31,520
okay, qual è il modo più efficiente che potrei forse si tratta di questo?

235
00:14:32,620 --> 00:14:35,412
È stato anche sincero nel sottolineare quanto fosse importante 

236
00:14:35,412 --> 00:14:37,850
che i controlli di parità fossero già nella sua mente, 

237
00:14:37,850 --> 00:14:41,220
il che sarebbe stato molto meno comune negli anni ’40 di quanto lo sia oggi.

238
00:14:41,920 --> 00:14:45,260
Ci sono circa una mezza dozzina di volte in questo libro in cui fa riferimento 

239
00:14:45,260 --> 00:14:48,220
alla citazione di Louis Pasteur, la fortuna aiuta una mente preparata.

240
00:14:49,320 --> 00:14:52,640
Le idee intelligenti spesso sembrano ingannevolmente semplici col senno di poi, 

241
00:14:52,640 --> 00:14:54,300
il che le rende facili da sottovalutare.

242
00:14:54,960 --> 00:14:58,274
In questo momento la mia sincera speranza è che i codici di Hamming, 

243
00:14:58,274 --> 00:15:01,300
o almeno la possibilità di tali codici, ti sembrino quasi ovvi.

244
00:15:01,660 --> 00:15:05,081
Ma non dovresti illuderti pensando che in realtà siano ovvi, 

245
00:15:05,081 --> 00:15:06,820
perché sicuramente non lo sono.

246
00:15:07,880 --> 00:15:11,464
Parte del motivo per cui le idee intelligenti sembrano ingannevolmente facili è che 

247
00:15:11,464 --> 00:15:14,793
vediamo sempre e solo il risultato finale, ripulendo ciò che era disordinato, 

248
00:15:14,793 --> 00:15:16,842
senza mai menzionare tutte le svolte sbagliate, 

249
00:15:16,842 --> 00:15:20,555
sottovalutando quanto vasto sia lo spazio delle possibilità esplorabili all'inizio 

250
00:15:20,555 --> 00:15:22,860
di un problema. processo di risoluzione, tutto questo.

251
00:15:23,820 --> 00:15:24,900
Ma questo è vero in generale.

252
00:15:24,900 --> 00:15:27,397
Penso che per alcune invenzioni speciali ci sia una 

253
00:15:27,397 --> 00:15:30,040
seconda ragione più profonda per cui le sottovalutiamo.

254
00:15:30,840 --> 00:15:33,478
Pensare all'informazione in termini di bit si era effettivamente 

255
00:15:33,478 --> 00:15:35,390
consolidato in una teoria completa solo nel 1948, 

256
00:15:35,390 --> 00:15:38,640
con l'articolo fondamentale di Claude Shannon sulla teoria dell'informazione.

257
00:15:39,280 --> 00:15:40,926
Ciò avvenne essenzialmente in concomitanza con il 

258
00:15:40,926 --> 00:15:42,540
momento in cui Hamming sviluppò il suo algoritmo.

259
00:15:43,300 --> 00:15:46,883
Si trattava dello stesso documento fondamentale che mostrava, in un certo senso, 

260
00:15:46,883 --> 00:15:49,670
che una correzione efficiente degli errori è sempre possibile, 

261
00:15:49,670 --> 00:15:52,900
non importa quanto sia alta la probabilità di bit flip, almeno in teoria.

262
00:15:53,700 --> 00:15:57,090
Shannon e Hamming, tra l'altro, condividevano un ufficio ai Bell Labs, 

263
00:15:57,090 --> 00:16:01,160
nonostante lavorassero su cose molto diverse, il che qui non sembra certo una coincidenza.

264
00:16:02,380 --> 00:16:05,747
Andiamo avanti velocemente di diversi decenni e, al giorno d'oggi, 

265
00:16:05,747 --> 00:16:09,067
molti di noi sono così immersi nel pensare a frammenti e informazioni 

266
00:16:09,067 --> 00:16:12,340
che è facile trascurare quanto fosse distinto questo modo di pensare.

267
00:16:13,100 --> 00:16:16,169
Ironicamente, le idee che plasmano più profondamente il modo in 

268
00:16:16,169 --> 00:16:19,046
cui pensa una generazione futura finiranno per apparire più 

269
00:16:19,046 --> 00:16:22,260
semplici a quella generazione futura di quanto non siano in realtà.

