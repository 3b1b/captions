[
 {
  "input": "Some of you may have heard this paradoxical fact about medical tests. ",
  "translatedText": "여러분 중 일부는 의료 검사에 대한 이러한 역설적인 사실을 들어보셨을 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 3.14
 },
 {
  "input": "It's very commonly used to introduce the topic of Bayes' rule in probability. ",
  "translatedText": "이는 베이즈 규칙의 확률 주제를 소개하는 데 매우 일반적으로 사용됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.58,
  "end": 6.74
 },
 {
  "input": "The paradox is that you could take a test which is highly accurate, in the sense that it gives correct results to a large majority of the people taking it. ",
  "translatedText": "역설적인 점은 테스트를 치르는 대다수의 사람들에게 정확한 결과를 제공한다는 점에서 매우 정확한 테스트를 할 수 있다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.5,
  "end": 15.66
 },
 {
  "input": "And yet, under the right circumstances, when assessing the probability that your particular test result is correct, you can still land on a very low number, arbitrarily low, in fact. ",
  "translatedText": "그러나 올바른 상황에서 특정 테스트 결과가 정확할 확률을 평가할 때 여전히 매우 낮은 숫자, 즉 임의적으로 낮은 숫자에 도달할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 16.04,
  "end": 26.3
 },
 {
  "input": "In short, an accurate test is not necessarily a very predictive test. ",
  "translatedText": "즉, 정확한 테스트가 반드시 매우 예측 가능한 테스트는 아닙니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.78,
  "end": 31.82
 },
 {
  "input": "Now when people think about math and formulas, they don't often think of it as a design process. ",
  "translatedText": "이제 사람들은 수학과 공식에 대해 생각할 때 그것을 디자인 프로세스로 생각하지 않는 경우가 많습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 33.06,
  "end": 37.44
 },
 {
  "input": "I mean, maybe in the case of notation it's easy to see that different choices are possible, but when it comes to the structure of the formulas themselves, and how we use them, that's something that people typically view as fixed. ",
  "translatedText": "제 말은, 표기법의 경우 다양한 선택이 가능하다는 것을 쉽게 알 수 있지만 공식 자체의 구조와 사용 방법에 관해서는 사람들이 일반적으로 고정된 것으로 보는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 38.08,
  "end": 49.68
 },
 {
  "input": "In this video, you and I will dig into this paradox, but instead of using it to talk about the usual version of Bayes' rule, I'd like to motivate an alternate version, an alternate design choice. ",
  "translatedText": "이 비디오에서 여러분과 저는 이 역설을 파헤칠 것입니다. 그러나 이를 사용하여 베이즈 규칙의 일반적인 버전에 대해 이야기하는 대신 대체 버전, 대체 디자인 선택에 대한 동기를 부여하고 싶습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.68,
  "end": 60.56
 },
 {
  "input": "Now, what's up on the screen now is a little bit abstract, which makes it difficult to justify that there really is a substantive difference here, especially when I haven't explained either one yet. ",
  "translatedText": "자, 지금 화면에 보이는 것은 약간 추상적이어서 여기에 정말로 실질적인 차이가 있다는 것을 정당화하기 어렵습니다. 특히 제가 아직 둘 중 하나를 설명하지 않았을 때 더욱 그렇습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 61.66,
  "end": 70.54
 },
 {
  "input": "To see what I'm talking about though, we should really start by spending some time a little more concretely, and just laying out what exactly this paradox is. ",
  "translatedText": "하지만 제가 말하는 내용을 보려면 좀 더 구체적으로 시간을 들여서 이 역설이 정확히 무엇인지 설명하는 것부터 시작해야 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.04,
  "end": 78.1
 },
 {
  "input": "1% of women have breast cancer Picture a thousand women and suppose that 1% of them have breast cancer. ",
  "translatedText": "1%의 여성이 유방암에 걸렸습니다. 천 명의 여성을 상상하고 그 중 1%가 유방암에 걸렸다고 가정해 보십시오. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.02,
  "end": 87.94
 },
 {
  "input": "And let's say they all undergo a certain breast cancer screening, and that 9 of those with cancer correctly get positive results, and there's one false negative. ",
  "translatedText": "그리고 그들 모두가 특정 유방암 검진을 받았다고 가정해 보겠습니다. 암에 걸린 사람 중 9명은 양성 결과를 얻었고 나머지 한 명은 거짓 음성 결과를 받았습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.68,
  "end": 96.68
 },
 {
  "input": "And then suppose that among the remainder without cancer, 89 get false positives, and 901 correctly get negative results. ",
  "translatedText": "그리고 암이 없는 나머지 중에서 89명이 위양성 결과를 얻었고 901명은 정확하게 음성 결과를 얻었다고 가정해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.48,
  "end": 104.92
 },
 {
  "input": "So if all you know about a woman is that she does the screening and she gets a positive result, you don't have information about symptoms or anything like that, you know that she's either one of these 9 true positives or one of these 89 false positives. ",
  "translatedText": "따라서 여성에 대해 아는 것이 검사를 하고 양성 결과가 나온다는 것뿐이고 증상이나 그와 유사한 정보가 없다면 그녀는 다음 9가지 진양성 중 하나이거나 다음 89가지 중 하나라는 것을 알 수 있습니다. 거짓 긍정. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 105.72,
  "end": 118.26
 },
 {
  "input": "So the probability that she's in the cancer group given the test result is 9 divided by 9 plus 89, which is approximately 1 in 11. ",
  "translatedText": "따라서 테스트 결과를 기준으로 그녀가 암군에 속할 확률은 9를 9로 나눈 값에 89를 더한 값이며 이는 대략 11분의 1입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.36,
  "end": 128.14
 },
 {
  "input": "In medical parlance, you would call this the positive predictive value of the test, or PPV, the number of true positives divided by the total number of positive test results. ",
  "translatedText": "의학 용어로 이것을 검사의 양성 예측 값, 즉 PPV라고 부르는데, 이는 참 양성 수를 총 양성 검사 결과 수로 나눈 값입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.08,
  "end": 138.62
 },
 {
  "input": "You can see where the name comes from. ",
  "translatedText": "이름이 어디서 유래되었는지 알 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 138.62,
  "end": 140.44
 },
 {
  "input": "To what extent does a positive test result actually predict that you have the disease? ",
  "translatedText": "양성 검사 결과가 실제로 귀하에게 질병이 있다고 예측하는 정도는 어느 정도입니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.74,
  "end": 145.36
 },
 {
  "input": "Now hopefully, as I've presented it this way where we're thinking concretely about a sample population, all of this makes perfect sense. ",
  "translatedText": "이제 제가 표본 집단에 대해 구체적으로 생각하는 방식으로 제시한 것처럼 이 모든 것이 완벽하게 이해되길 바랍니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.82,
  "end": 153.46
 },
 {
  "input": "But where it comes across as counterintuitive is if you just look at the accuracy of the test, present it to people as a statistic, and then ask them to make judgments about their test result. ",
  "translatedText": "그러나 테스트의 정확성을 살펴보고 이를 통계로 사람들에게 제시한 다음 테스트 결과에 대해 판단하도록 요청하는 경우에는 직관에 어긋난다고 생각됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.96,
  "end": 163.2
 },
 {
  "input": "Test accuracy is not actually one number, but two. ",
  "translatedText": "테스트 정확도는 실제로 하나의 숫자가 아니라 두 개의 숫자입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.02,
  "end": 166.26
 },
 {
  "input": "First, you ask, how often is a test correct on those with the disease? ",
  "translatedText": "먼저, 질병이 있는 사람들에 대한 검사가 얼마나 자주 정확합니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.26,
  "end": 171.12
 },
 {
  "input": "This is known as the test sensitivity, as in, how sensitive is it to detecting the presence of the disease? ",
  "translatedText": "이를 테스트 민감도라고 합니다. 질병의 존재를 감지하는 데 얼마나 민감한가요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.7,
  "end": 177.44
 },
 {
  "input": "In our example, test sensitivity is 9 in 10, or 90%. ",
  "translatedText": "이 예에서 테스트 민감도는 9/10, 즉 90%입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.26,
  "end": 181.26
 },
 {
  "input": "And another way to say the same fact would be to say the false negative rate is 10%. ",
  "translatedText": "그리고 같은 사실을 다르게 표현하는 방법은 위음성률이 10%라고 말하는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.02,
  "end": 186.68
 },
 {
  "input": "And then a separate, not necessarily related number, is how often it's correct for those without the disease, which is known as the test specificity, as in, are positive results caused specifically by the disease, or are there confounding triggers giving false positives? ",
  "translatedText": "그리고 반드시 관련이 있는 것은 아니지만 별도의 숫자는 질병이 없는 사람들에게 얼마나 자주 올바른지입니다. 이는 테스트 특이성으로 알려져 있습니다. 예를 들어, 특정 질병으로 인해 긍정적인 결과가 나오는지, 아니면 위양성을 유발하는 교란 유발 요인이 있습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.68,
  "end": 202.06
 },
 {
  "input": "In our example, the specificity is about 91%. ",
  "translatedText": "이 예에서는 특이도가 약 91%입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.08,
  "end": 206.58
 },
 {
  "input": "Or, another way to say the same fact would be to say the false positive rate is 9%. ",
  "translatedText": "또는 동일한 사실을 다르게 표현하면 위양성률이 9%라고 말할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.58,
  "end": 211.66
 },
 {
  "input": "So the paradox here is that, in one sense, the test is over 90% accurate. ",
  "translatedText": "따라서 여기서 역설적인 점은 어떤 의미에서는 테스트가 90% 이상 정확하다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.66,
  "end": 216.76
 },
 {
  "input": "It gives correct results to over 90% of the patients who take it. ",
  "translatedText": "이를 복용하는 환자의 90% 이상이 올바른 결과를 얻습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 217.02,
  "end": 220.66
 },
 {
  "input": "And yet, if you learn that someone gets a positive result without any added information, there's actually only a 1 in 11 chance that that particular result is accurate. ",
  "translatedText": "그러나 추가 정보 없이 누군가가 긍정적인 결과를 얻었다는 사실을 알게 되면 실제로 그 특정 결과가 정확할 확률은 1/11에 불과합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.66,
  "end": 229.6
 },
 {
  "input": "This is a bit of a problem, because of all of the places for math to be counterintuitive, medical tests are one area where it matters a lot. ",
  "translatedText": "수학이 반직관적일 수 있는 모든 부분과 의료 테스트가 매우 중요한 영역이기 때문에 이것은 약간의 문제입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.62,
  "end": 237.18
 },
 {
  "input": "In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics seminars to practicing gynecologists, and he opened with the following example. ",
  "translatedText": "2006년과 2007년에 심리학자 게르트 기거렌처(Gerd Gigerenzer)는 현직 산부인과 의사들을 대상으로 일련의 통계 세미나를 열었고 그는 다음 예를 들고 시작했습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.94,
  "end": 246.8
 },
 {
  "input": "A 50-year-old woman, no symptoms, participates in a routine mammography screening. ",
  "translatedText": "증상이 없는 50세 여성이 정기 유방촬영 검진에 참여했습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.8,
  "end": 251.74
 },
 {
  "input": "She tests positive, is alarmed, and wants to know from you whether she has breast cancer for certain, or what her chances are. ",
  "translatedText": "그녀는 양성 반응을 보이고 놀라며 자신이 확실히 유방암에 걸렸는지, 아니면 가능성이 얼마나 되는지 당신에게 알고 싶어합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.28,
  "end": 258.38
 },
 {
  "input": "Apart from the screening result, you know nothing else about this woman. ",
  "translatedText": "검사 결과 외에는 이 여성에 대해 아는 바가 없습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.88,
  "end": 261.74
 },
 {
  "input": "In that seminar, the doctors were then told that the prevalence of breast cancer for women of this age is about 1%, and then to suppose that the test sensitivity is 90%, and that its specificity was 91%. ",
  "translatedText": "그 세미나에서 의사들은 이 연령대 여성의 유방암 유병률은 약 1%이며, 검사 민감도는 90%, 특이도는 91%라고 가정하라는 말을 들었습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 262.58,
  "end": 274.18
 },
 {
  "input": "You might notice these are exactly the same numbers from the example that you and I just looked at. ",
  "translatedText": "여러분은 이것이 여러분과 제가 방금 본 예의 숫자와 정확히 동일하다는 것을 알 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.18,
  "end": 278.18
 },
 {
  "input": "This is where I got them. ",
  "translatedText": "내가 그것들을 얻은 곳은 바로 이곳이다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.36,
  "end": 279.44
 },
 {
  "input": "So, having already thought it through, you and I know the answer. ",
  "translatedText": "그러므로 이미 곰곰이 생각해 본 결과, 여러분과 저는 답을 알고 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 279.76,
  "end": 282.6
 },
 {
  "input": "It's about 1 in 11. ",
  "translatedText": "11분의 1 정도입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.88,
  "end": 283.84
 },
 {
  "input": "However, the doctors in this session were not primed with the suggestion to picture a concrete sample of a thousand individuals, the way that you and I had. ",
  "translatedText": "그러나 이 세션의 의사들은 당신과 내가 했던 것처럼 수천 명의 구체적인 표본을 상상해 보라는 제안을 준비하지 않았습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.6,
  "end": 291.54
 },
 {
  "input": "All they saw were these numbers. ",
  "translatedText": "그들이 본 것은 이 숫자뿐이었습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.04,
  "end": 293.34
 },
 {
  "input": "They were then asked, how many women who test positive actually have breast cancer? ",
  "translatedText": "그런 다음 양성 반응을 보인 여성 중 실제로 유방암에 걸린 여성은 몇 명입니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.14,
  "end": 298.42
 },
 {
  "input": "What is the best answer? ",
  "translatedText": "가장 좋은 대답은 무엇입니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.62,
  "end": 299.74
 },
 {
  "input": "And they were presented with these four choices. ",
  "translatedText": "그리고 그들은 이 네 가지 선택 사항을 제시받았습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.9,
  "end": 301.68
 },
 {
  "input": "In one of the sessions, over half the doctors present said that the correct answer was 9 in 10, which is way off. ",
  "translatedText": "한 세션에서 참석한 의사 중 절반 이상이 정답이 10분의 9라고 말했는데 이는 전혀 다른 수치입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.68,
  "end": 309.3
 },
 {
  "input": "Only a fifth of them gave the correct answer, which is worse than what it would have been if everybody had randomly guessed. ",
  "translatedText": "그 중 5분의 1만이 정답을 냈는데, 이는 모두가 무작위로 추측했을 경우의 결과보다 더 나빴습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.02,
  "end": 315.38
 },
 {
  "input": "It might seem a little extreme to be calling this a paradox. ",
  "translatedText": "이것을 역설이라고 부르는 것은 다소 극단적인 것처럼 보일 수도 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.66,
  "end": 319.28
 },
 {
  "input": "I mean, it's just a fact. ",
  "translatedText": "내 말은, 그것은 단지 사실일 뿐이라는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.76,
  "end": 321.14
 },
 {
  "input": "It's not something intrinsically self-contradictory. ",
  "translatedText": "그것은 본질적으로 자기모순적인 것이 아닙니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 321.26,
  "end": 323.5
 },
 {
  "input": "But, as these seminars with Gigerenzer show, people, including doctors, definitely find it counterintuitive that a test with high accuracy can give you such a low predictive value. ",
  "translatedText": "그러나 Gigerenzer와 함께한 세미나에서 알 수 있듯이 의사를 포함한 사람들은 정확도가 높은 테스트가 그렇게 낮은 예측 가치를 제공할 수 있다는 것이 직관에 어긋난다는 사실을 분명히 발견했습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 324.2,
  "end": 334.24
 },
 {
  "input": "We might call this a veridical paradox, which refers to facts that are provably true, but which nevertheless can feel false when phrased a certain way. ",
  "translatedText": "우리는 이것을 입증 가능한 사실이지만 특정 방식으로 표현하면 거짓으로 느껴질 수 있는 사실을 가리키는 진정한 역설이라고 부를 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 335.2,
  "end": 343.8
 },
 {
  "input": "It's sort of the softest form of a paradox, saying more about human psychology than about logic. ",
  "translatedText": "그것은 논리보다는 인간 심리학에 대해 더 많은 것을 말하는 일종의 가장 부드러운 형태의 역설입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.3,
  "end": 348.72
 },
 {
  "input": "The question is how we can combat this. ",
  "translatedText": "문제는 우리가 이 문제에 어떻게 대처할 수 있느냐는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.58,
  "end": 351.98
 },
 {
  "input": "Where we're going with this, by the way, is that I want you to be able to look at numbers like this and quickly estimate in your head that it means the predictive value of a positive test should be around 1 in 11. ",
  "translatedText": "그런데 여기서 우리가 할 일은 여러분이 이와 같은 숫자를 보고 긍정적인 테스트의 예측 가치가 11분의 1 정도여야 한다는 것을 머리 속으로 빠르게 추정할 수 있기를 바라는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.8,
  "end": 364.14
 },
 {
  "input": "Or, if I changed things and asked, what if it was 10% of the population who had breast cancer? ",
  "translatedText": "아니면 상황을 바꿔서 유방암에 걸린 인구가 전체 인구의 10%라면 어떨까요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.76,
  "end": 369.72
 },
 {
  "input": "You should be able to quickly turn around and say that the final answer would be a little over 50%. ",
  "translatedText": "재빨리 돌아서서 최종 답은 50%가 조금 넘을 것이라고 말할 수 있어야 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.12,
  "end": 374.98
 },
 {
  "input": "Or, if I said imagine a really low prevalence, something like 0.1% of patients having cancer, you should again quickly estimate that the predictive value of the test is around 1 in 100. ",
  "translatedText": "또는 매우 낮은 유병률, 즉 0과 같은 상황을 상상해 보십시오. 암 환자 중 1%에 해당하는 경우, 테스트의 예측 가치가 약 100분의 1이라는 것을 빠르게 추정해야 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.92,
  "end": 386.14
 },
 {
  "input": "That 1 in 100 of those with positive test results in that case would have cancer. ",
  "translatedText": "이 경우 양성 검사 결과가 나온 사람 중 100명 중 1명은 암에 걸릴 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 386.76,
  "end": 390.6
 },
 {
  "input": "Or, let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "또는 1%의 유병률로 돌아가서 테스트를 더 정확하게 한다고 가정해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.58,
  "end": 395.24
 },
 {
  "input": "I tell you to imagine the specificity is 99%. ",
  "translatedText": "특이도가 99%라고 상상해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.44,
  "end": 398.4
 },
 {
  "input": "There, you should be able to relatively quickly estimate that the answer is a little less than 50%. ",
  "translatedText": "여기서는 대답이 50%보다 약간 낮다는 것을 비교적 빠르게 추정할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.4,
  "end": 403.8
 },
 {
  "input": "The hope is that you're doing all of this with minimal calculations in your head. ",
  "translatedText": "최소한의 계산으로 이 모든 작업을 수행할 수 있기를 바랍니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 404.32,
  "end": 407.74
 },
 {
  "input": "Now, the goals of quick calculations might feel very different from the goals of addressing whatever misconception underlies this paradox, but they actually go hand in hand. ",
  "translatedText": "이제 빠른 계산의 목표는 이 역설의 바탕이 되는 오해를 해결하려는 목표와 매우 다르게 느껴질 수 있지만 실제로는 서로 밀접하게 연관되어 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.54,
  "end": 416.5
 },
 {
  "input": "Let me show you what I mean. ",
  "translatedText": "무슨 뜻인지 보여드리겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.9,
  "end": 417.68
 },
 {
  "input": "On the side of addressing misconceptions, what would you tell to the people in that seminar who answered 9 and 10? ",
  "translatedText": "오해를 해결하는 측면에서, 9번과 10번에 답한 세미나의 사람들에게 무엇을 말해주고 싶나요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.46,
  "end": 423.98
 },
 {
  "input": "What fundamental misconception are they revealing? ",
  "translatedText": "그들은 어떤 근본적인 오해를 드러내고 있습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.48,
  "end": 426.9
 },
 {
  "input": "What I might tell them is that in much the same way that you shouldn't think of tests as telling you deterministically whether you have a disease, you shouldn't even think of them as telling you your chances of having a disease. ",
  "translatedText": "제가 그들에게 말할 수 있는 것은 검사가 당신에게 질병이 있는지 여부를 결정적으로 알려주는 것으로 생각해서는 안 되는 것과 마찬가지로, 질병에 걸릴 가능성을 알려주는 것으로도 생각해서는 안 된다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.18,
  "end": 438.6
 },
 {
  "input": "Instead, the healthy view of what tests do is that they update your chances. ",
  "translatedText": "대신, 테스트가 수행하는 작업에 대한 건전한 관점은 테스트가 기회를 업데이트한다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.56,
  "end": 444.46
 },
 {
  "input": "In our example, before taking the test, a patient's chances of having cancer were 1 in 100. ",
  "translatedText": "우리의 예에서는 검사를 받기 전에 환자가 암에 걸릴 확률은 100분의 1이었습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.04,
  "end": 450.68
 },
 {
  "input": "In Bayesian terms, we call this the prior probability. ",
  "translatedText": "베이지안 용어로 이를 사전 확률이라고 부릅니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 453.64
 },
 {
  "input": "The effect of this test was to update that prior by almost an order of magnitude, up to around 1 in 11. ",
  "translatedText": "이 테스트의 효과는 이전 버전을 거의 1/11까지 업데이트하는 것이었습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.38,
  "end": 460.36
 },
 {
  "input": "The accuracy of a test is telling us about the strength of this updating. ",
  "translatedText": "테스트의 정확성은 이 업데이트의 강점을 알려줍니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.02,
  "end": 464.82
 },
 {
  "input": "It's not telling us a final answer. ",
  "translatedText": "우리에게 최종 답을 알려주는 것은 아닙니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.12,
  "end": 466.74
 },
 {
  "input": "What does this have to do with quick approximations? ",
  "translatedText": "이것이 빠른 근사치와 어떤 관련이 있습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 467.9,
  "end": 469.64
 },
 {
  "input": "Well, a key number for those approximations is something called the Bayes factor, and the very act of defining this number serves to reinforce this central lesson about reframing what it is the tests do. ",
  "translatedText": "글쎄요, 이러한 근사치를 위한 핵심 숫자는 베이즈 요인이라고 불리는 것입니다. 그리고 이 숫자를 정의하는 바로 그 행위는 테스트가 하는 일을 재구성하는 것에 대한 핵심 교훈을 강화하는 역할을 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.3,
  "end": 481.4
 },
 {
  "input": "You see, one of the things that makes test statistics so very confusing is that there are at least 4 numbers that you'll hear associated with them. ",
  "translatedText": "테스트 통계를 매우 혼란스럽게 만드는 것 중 하나는 이와 관련된 숫자가 최소한 4개 있다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.42,
  "end": 488.9
 },
 {
  "input": "For those with the disease, there's the sensitivity and the false negative rate, and then for those without, there's the specificity and the false positive rate, and none of these numbers actually tell you the thing you want to know. ",
  "translatedText": "질병이 있는 사람에게는 민감도와 위음성률이 있고, 질병이 없는 사람에게는 특이성과 위양성률이 있습니다. 이 숫자 중 어느 것도 실제로 여러분이 알고 싶은 것을 말해주지 않습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.9,
  "end": 498.8
 },
 {
  "input": "Luckily, if you want to interpret a positive test result, you can pull out just one number to focus on from all this. ",
  "translatedText": "다행히 긍정적인 테스트 결과를 해석하고 싶다면 이 모든 것 중에서 집중할 숫자 하나만 뽑아내면 됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 499.5,
  "end": 505.62
 },
 {
  "input": "Take the sensitivity divided by the false positive rate. ",
  "translatedText": "민감도를 거짓양성률로 나눈 값을 취합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.04,
  "end": 508.6
 },
 {
  "input": "In other words, how much more likely are you to see the positive test result with cancer versus without? ",
  "translatedText": "즉, 암이 있는 경우와 없는 경우에 비해 양성 검사 결과를 볼 가능성이 얼마나 더 높습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.16,
  "end": 514.74
 },
 {
  "input": "In our example, this number is 10. ",
  "translatedText": "이 예에서 이 숫자는 10입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.74,
  "end": 517.14
 },
 {
  "input": "This is the Bayes factor, also sometimes called the likelihood ratio. ",
  "translatedText": "이것이 베이즈 요인(우도비라고도 함)입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.9,
  "end": 521.72
 },
 {
  "input": "A very handy rule of thumb is that to update a small prior, or at least to approximate the answer, you simply multiply it by the Bayes factor. ",
  "translatedText": "매우 편리한 경험 법칙은 작은 사전 값을 업데이트하거나 적어도 답을 대략적으로 계산하려면 해당 값에 베이즈 인수를 곱하면 된다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.1,
  "end": 530.02
 },
 {
  "input": "So in our example, where the prior was 1 in 100, you would estimate that the final answer should be around 1 in 10, which is in fact slightly above the true correct answer. ",
  "translatedText": "따라서 이전 예가 100분의 1이었던 우리의 예에서 최종 답은 약 10분의 1이 되어야 한다고 추정할 수 있으며 이는 실제로 실제 정답보다 약간 높습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.76,
  "end": 538.82
 },
 {
  "input": "So based on this rule of thumb, if I asked you what would happen if the prior from our example was instead 1 in 1000, you could quickly estimate that the effect of the test should be to update those chances to around 1 in 100. ",
  "translatedText": "따라서 이 경험 법칙을 기반으로, 만약 제가 우리 예의 이전 값이 1000분의 1이라면 어떤 일이 일어날지 묻는다면, 테스트의 효과가 해당 확률을 약 100분의 1로 업데이트해야 한다는 것을 빠르게 추정할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.4,
  "end": 551.42
 },
 {
  "input": "And in fact, take a moment to check yourself by thinking through a sample population. ",
  "translatedText": "그리고 실제로 잠시 시간을 내어 표본 모집단을 통해 자신을 확인해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.36,
  "end": 555.72
 },
 {
  "input": "In this case, you might picture 10,000 patients where only 10 of them really have cancer. ",
  "translatedText": "이 경우 10,000명의 환자 중에서 실제로 암에 걸린 환자는 10명뿐이라고 가정할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.7,
  "end": 560.88
 },
 {
  "input": "And then based on that 90% sensitivity, we would expect 9 of those cancer cases to give true positives. ",
  "translatedText": "그리고 90%의 민감도를 바탕으로 우리는 암 사례 중 9개가 진정한 양성 반응을 보일 것으로 예상합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 562.14,
  "end": 567.9
 },
 {
  "input": "And on the other side, a 91% specificity means that 9% of those without cancer are getting false positives. ",
  "translatedText": "반면에 특이도가 91%라는 것은 암이 없는 사람 중 9%가 위양성(false positives)을 받고 있음을 의미합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.0,
  "end": 575.76
 },
 {
  "input": "So we'd expect 9% of the remaining patients, which is around 900, to give false positive results. ",
  "translatedText": "따라서 우리는 나머지 환자 중 9%(약 900명)가 위양성 결과를 나타낼 것으로 예상합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.66,
  "end": 581.86
 },
 {
  "input": "Here, with such a low prevalence, the false positives really do dominate the true positives. ",
  "translatedText": "여기서는 보급률이 매우 낮기 때문에 거짓 긍정이 실제로 참 긍정을 지배합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.7,
  "end": 587.82
 },
 {
  "input": "So the probability that a randomly chosen positive case from this population actually has cancer is only around 1%, just like the rule of thumb predicted. ",
  "translatedText": "따라서 이 인구 집단에서 무작위로 선택된 양성 사례가 실제로 암에 걸릴 확률은 경험 법칙에서 예측한 것과 마찬가지로 약 1%에 불과합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 587.9,
  "end": 597.02
 },
 {
  "input": "Now, this rule of thumb clearly cannot work for higher priors. ",
  "translatedText": "이제 이 경험 법칙은 더 높은 사전 순위에는 적용되지 않습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.7,
  "end": 601.92
 },
 {
  "input": "For example, it would predict that a prior of 10% gets updated all the way to 100% certainty. ",
  "translatedText": "예를 들어, 10%의 사전 확률이 100% 확실성까지 업데이트된다고 예측합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.42,
  "end": 607.86
 },
 {
  "input": "But that can't be right. ",
  "translatedText": "그러나 그것은 옳을 수 없습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.36,
  "end": 609.32
 },
 {
  "input": "In fact, take a moment to think through what the answer should be, again using a sample population. ",
  "translatedText": "실제로 표본 모집단을 다시 사용하여 답이 무엇인지 생각해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 610.02,
  "end": 614.5
 },
 {
  "input": "Maybe this time we picture 10 out of 100 having cancer. ",
  "translatedText": "어쩌면 이번에는 100명 중 10명이 암에 걸린 모습을 상상해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.06,
  "end": 617.86
 },
 {
  "input": "Again, based on the 90% sensitivity of the test, we'd expect 9 of those true cancer cases to get positive results. ",
  "translatedText": "다시 말하지만, 테스트의 90% 민감도를 바탕으로 실제 암 사례 중 9건이 긍정적인 결과를 얻을 것으로 예상합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.54,
  "end": 624.92
 },
 {
  "input": "But what about the false positives? ",
  "translatedText": "하지만 거짓 긍정은 어떻습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 624.92,
  "end": 626.6
 },
 {
  "input": "How many do we expect there? ",
  "translatedText": "거기에는 몇 명이나 예상되나요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 626.98,
  "end": 628.1
 },
 {
  "input": "About 9% of the remaining 90, about 8. ",
  "translatedText": "나머지 90개 중 약 9%, 약 8개. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 629.88,
  "end": 632.62
 },
 {
  "input": "So, upon seeing a positive test result, it tells you that you're either one of these 9 true positives or one of the 8 false positives. ",
  "translatedText": "따라서 양성 테스트 결과를 보면 귀하가 이 9개의 참양성 중 하나이거나 8개의 거짓양성 중 하나임을 알려줍니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 633.82,
  "end": 641.14
 },
 {
  "input": "So this means the chances are a little over 50%, roughly 9 out of 17, or 53%. ",
  "translatedText": "따라서 이는 확률이 50%를 약간 넘는다는 것을 의미합니다. 대략 17명 중 9명, 즉 53%입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.86,
  "end": 646.92
 },
 {
  "input": "At this point, having dared to dream that Bayesian updating could look as simple as multiplication, you might tear down your hopes and pragmatically acknowledge, sometimes life is just more complicated than that. ",
  "translatedText": "이 시점에서 베이지안 업데이트가 곱셈처럼 단순해 보일 수 있다는 꿈을 꾸었다면 희망을 무너뜨리고 때로는 인생이 그보다 더 복잡하다는 것을 실용적으로 인정할 수도 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.02,
  "end": 657.7
 },
 {
  "input": "Except, it's not. ",
  "translatedText": "하지만 그렇지 않습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 659.92,
  "end": 661.12
 },
 {
  "input": "This rule of thumb turns into a precise mathematical fact, as long as we shift away from talking about probabilities to instead talking about odds. ",
  "translatedText": "이 경험 법칙은 확률에 대한 논의에서 승률에 대한 논의로 전환하는 한 정확한 수학적 사실로 변합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.62,
  "end": 669.0
 },
 {
  "input": "If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1, things like that, you already know about odds. ",
  "translatedText": "누군가가 사건의 확률이 1:1 또는 2:1일 확률에 대해 이야기하는 것을 들어본 적이 있다면 이미 확률에 대해 알고 있는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.32,
  "end": 677.06
 },
 {
  "input": "With probability, we're taking the ratio of the number of positive cases out of all possible cases, right? ",
  "translatedText": "확률을 사용하면 가능한 모든 사례 중에서 긍정적인 사례 수의 비율을 취하는 것입니다. 그렇죠? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.06,
  "end": 683.06
 },
 {
  "input": "Things like 1 in 5 or 1 in 10. ",
  "translatedText": "5분의 1 또는 10분의 1과 같은 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.4,
  "end": 685.28
 },
 {
  "input": "With odds, what you do is take the ratio of all positive cases to all negative cases. ",
  "translatedText": "확률을 사용하면 모든 긍정적인 경우와 모든 부정적인 경우의 비율을 취하는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.88,
  "end": 690.32
 },
 {
  "input": "You commonly see odds written with a colon to emphasize the distinction, but it's still just a fraction, just a number. ",
  "translatedText": "구별을 강조하기 위해 콜론으로 확률을 표시하는 것을 흔히 볼 수 있지만 이는 여전히 분수, 숫자일 뿐입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.54,
  "end": 697.06
 },
 {
  "input": "So an event with a 50% probability would be described as having 1 to 1 odds, a 10% probability is the same as 1 to 9 odds, an 80% probability is the same as 4 to 1 odds, you get the point. ",
  "translatedText": "따라서 50% 확률의 이벤트는 1:1 확률, 10% 확률은 1:9 확률, 80% 확률은 4:1 확률로 설명됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 697.94,
  "end": 710.46
 },
 {
  "input": "It's the same information, it still describes the chances of a random event, but it's presented a little differently, like a different unit system. ",
  "translatedText": "이는 동일한 정보이고 여전히 무작위 사건의 가능성을 설명하지만 다른 단위 시스템처럼 약간 다르게 표시됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.48,
  "end": 718.34
 },
 {
  "input": "Probabilities are constrained between 0 and 1, with even chances sitting at 0.5. ",
  "translatedText": "확률은 0과 1 사이로 제한되며, 짝수 확률은 0입니다. 5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.32,
  "end": 723.68
 },
 {
  "input": "But odds range from 0 up to infinity, with even chances sitting at the number 1. ",
  "translatedText": "그러나 확률은 0부터 무한대까지이며, 짝수가 1이 됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 724.8,
  "end": 729.54
 },
 {
  "input": "The beauty here is that a completely accurate, not even approximating things way to frame Bayes' rule is to say, express your prior using odds, and then just multiply by the Bayes' factor. ",
  "translatedText": "여기서의 장점은 Bayes의 규칙을 구성하는 완전히 정확하고 근사하지도 않은 방법은 확률을 사용하여 사전을 표현한 다음 Bayes의 인수를 곱하는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 731.88,
  "end": 742.36
 },
 {
  "input": "Think about what the prior odds are really saying. ",
  "translatedText": "사전 확률이 실제로 무엇을 의미하는지 생각해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.44,
  "end": 745.22
 },
 {
  "input": "It's the number of people with cancer divided by the number without it. ",
  "translatedText": "암에 걸린 사람의 수를 암이 없는 사람의 수로 나눈 값입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.58,
  "end": 749.26
 },
 {
  "input": "Here, let's just write that down as a normal fraction for a moment so we can multiply it. ",
  "translatedText": "여기서는 이를 곱할 수 있도록 잠시 동안 정규 분수로 적어 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 749.7,
  "end": 753.36
 },
 {
  "input": "When you filter down just to those with positive test results, the number of people with cancer gets scaled down, scaled down by the probability of seeing a positive test result given that someone has cancer. ",
  "translatedText": "긍정적인 테스트 결과가 있는 사람들만 필터링하면 암에 걸린 사람의 수가 줄어들고, 누군가가 암에 걸렸을 때 긍정적인 테스트 결과를 볼 확률이 줄어듭니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 753.36,
  "end": 764.42
 },
 {
  "input": "And then similarly, the number of people without cancer also gets scaled down, this time by the probability of seeing a positive test result, but in that case. ",
  "translatedText": "그리고 마찬가지로, 암이 없는 사람의 수도 이번에는 양성 검사 결과를 볼 확률에 따라 축소되지만, 이 경우에는 그렇습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 765.12,
  "end": 773.44
 },
 {
  "input": "So the ratio between these two counts, the new odds upon seeing the test, looks just like the prior odds except multiplied by this term here, which is exactly the Bayes' factor. ",
  "translatedText": "따라서 이 두 카운트 사이의 비율, 즉 테스트를 볼 때 새로운 확률은 여기 이 항을 곱한 것을 제외하고는 이전 확률과 똑같아 보입니다. 이는 정확히 베이즈 요인입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 774.18,
  "end": 784.76
 },
 {
  "input": "Look back at our example, where the Bayes' factor was 10. ",
  "translatedText": "베이즈 요인이 10이었던 예를 다시 살펴보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.8,
  "end": 790.5
 },
 {
  "input": "And as a reminder, this came from the 90% sensitivity divided by the 9% false positive rate. ",
  "translatedText": "참고로 이는 90% 민감도를 9% 오탐률로 나눈 값입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.0,
  "end": 796.56
 },
 {
  "input": "How much more likely are you to see a positive result with cancer versus without? ",
  "translatedText": "암이 있는 경우와 없는 경우에 비해 긍정적인 결과를 볼 가능성이 얼마나 더 높습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.88,
  "end": 800.74
 },
 {
  "input": "If the prior is 1%, expressed as odds, this looks like 1 to 99. ",
  "translatedText": "사전 확률이 1%이고 확률로 표시되는 경우 이는 1~99처럼 보입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 801.72,
  "end": 805.94
 },
 {
  "input": "So by our rule, this gets updated to 10 to 99, which if you want you could convert back to a probability. ",
  "translatedText": "따라서 우리의 규칙에 따라 이는 10에서 99로 업데이트되며 원하는 경우 확률로 다시 변환할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.9,
  "end": 813.4
 },
 {
  "input": "It would be 10 divided by 10 plus 99, or about 1 in 11. ",
  "translatedText": "10을 10으로 나눈 값에 99를 더하면 11분의 1 정도가 됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.66,
  "end": 817.22
 },
 {
  "input": "If instead the prior was 10%, which was the example that tripped up our rule of thumb earlier, expressed as odds, this looks like 1 to 9. ",
  "translatedText": "대신 사전 확률이 10%였다면(확률로 표현된 이전 경험 법칙을 어긴 예) 이는 1~9처럼 보입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 818.2,
  "end": 826.26
 },
 {
  "input": "By our simple rule, this gets updated to 10 to 9, which you can already read off pretty intuitively. ",
  "translatedText": "간단한 규칙에 따라 이는 10에서 9로 업데이트되며 이미 매우 직관적으로 읽을 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.94,
  "end": 832.44
 },
 {
  "input": "It's a little above even chances, a little above 1 to 1. ",
  "translatedText": "1대1보다 약간 높은 확률입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.44,
  "end": 835.66
 },
 {
  "input": "If you prefer, you can convert it back to a probability. ",
  "translatedText": "원하는 경우 확률로 다시 변환할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 836.34,
  "end": 838.84
 },
 {
  "input": "You would write it as 10 out of 19, or about 53%. ",
  "translatedText": "19개 중 10개, 즉 약 53%로 작성합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.18,
  "end": 843.28
 },
 {
  "input": "And indeed, that is what we already found by thinking things through with a sample population. ",
  "translatedText": "그리고 실제로 그것은 표본 모집단을 통해 사물을 생각함으로써 우리가 이미 발견한 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.28,
  "end": 847.22
 },
 {
  "input": "Let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "1%의 유병률로 돌아가서 테스트를 더 정확하게 한다고 가정해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 848.3,
  "end": 851.7
 },
 {
  "input": "Now what if I told you to imagine that the false positive rate was only 1% instead of 9%? ",
  "translatedText": "이제 위양성률이 9%가 아니라 1%에 불과하다고 상상해 보면 어떨까요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 852.06,
  "end": 856.64
 },
 {
  "input": "What that would mean is that our Bayes' factor is 90 instead of 10. ",
  "translatedText": "이것이 의미하는 바는 Bayes' Factor가 10이 아닌 90이라는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 857.12,
  "end": 860.52
 },
 {
  "input": "The test is doing more work for us. ",
  "translatedText": "테스트는 우리를 위해 더 많은 작업을 수행합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.84,
  "end": 862.46
 },
 {
  "input": "In this case, with the more accurate test, it gets updated to 90 to 99, which is a little less than even chances, something a little under 50%. ",
  "translatedText": "이 경우 더 정확한 테스트를 통해 90에서 99로 업데이트됩니다. 이는 확률보다 약간 낮고 50%에 약간 못 미치는 수치입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 863.16,
  "end": 871.58
 },
 {
  "input": "To be more precise, you could make the conversion back to probability and work out that it's around 48%. ",
  "translatedText": "더 정확하게 말하자면 확률로 다시 변환하여 약 48%라는 것을 알아낼 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.58,
  "end": 877.56
 },
 {
  "input": "But honestly, if you're just going for a gut feel, it's fine to stick with the odds. ",
  "translatedText": "하지만 솔직히 직감만 원한다면 확률을 고수하는 것이 좋습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.56,
  "end": 881.4
 },
 {
  "input": "Do you see what I mean about how just defining this number helps to combat potential misconceptions? ",
  "translatedText": "이 숫자를 정의하는 것만으로도 잠재적인 오해를 방지하는 데 어떻게 도움이 되는지 제가 의미하는 바를 아시나요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.22,
  "end": 887.44
 },
 {
  "input": "For anybody who's a little hasty in connecting test accuracy directly to your probability of having a disease, it's worth emphasizing that you could administer the same test with the same accuracy to multiple different patients who all get the same exact result, but if they're coming from different contexts, that result can mean wildly different things. ",
  "translatedText": "테스트 정확도를 질병 발병 확률과 직접 연결하는 데 다소 성급한 사람이라면 모두 동일한 정확한 결과를 얻는 여러 다른 환자에게 동일한 정확도로 동일한 테스트를 실시할 수 있다는 점을 강조할 가치가 있습니다. 다른 맥락에서 나오므로 그 결과는 매우 다른 것을 의미할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 888.24,
  "end": 906.72
 },
 {
  "input": "However, the one thing that does stay constant in every case is the factor by which each patient's prior odds get updated. ",
  "translatedText": "그러나 모든 경우에 일정하게 유지되는 한 가지는 각 환자의 이전 확률이 업데이트되는 요소입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 906.72,
  "end": 914.66
 },
 {
  "input": "And by the way, this whole time we've been using the prevalence of the disease, which is the proportion of people in a population who have it, as a substitute for the prior, the probability of having it before you see a test. ",
  "translatedText": "그건 그렇고, 지금까지 우리는 질병의 유병률, 즉 인구 중 질병을 앓고 있는 사람들의 비율을 사전 조사 대신에 테스트를 보기 전에 질병에 걸릴 확률을 사용해 왔습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 916.3,
  "end": 926.88
 },
 {
  "input": "However, that's not necessarily the case. ",
  "translatedText": "그러나 반드시 그런 것은 아닙니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 927.52,
  "end": 929.46
 },
 {
  "input": "If there are other known factors, things like symptoms, or in the case of a contagious disease, things like known contacts, those also factor into the prior, and they could potentially make a huge difference. ",
  "translatedText": "증상과 같은 다른 알려진 요인이 있거나 전염병의 경우 알려진 접촉과 같은 요인도 이전 요인에 영향을 미치며 잠재적으로 큰 차이를 만들 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 929.78,
  "end": 939.86
 },
 {
  "input": "As another side note, so far we've only talked about positive test results, but way more often you would be seeing a negative test result. ",
  "translatedText": "또 다른 참고 사항으로, 지금까지 우리는 긍정적인 테스트 결과에 대해서만 이야기했지만 훨씬 더 자주 부정적인 테스트 결과를 보게 될 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 940.76,
  "end": 947.46
 },
 {
  "input": "The logic there is completely the same, but the base factor that you compute is going to look different. ",
  "translatedText": "논리는 완전히 동일하지만 계산하는 기본 요소는 다르게 보일 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 948.1,
  "end": 952.32
 },
 {
  "input": "Instead, you look at the probability of seeing this negative test result with the disease versus without the disease. ",
  "translatedText": "대신, 질병이 있는 경우와 질병이 없는 경우에 대한 부정적인 테스트 결과를 볼 확률을 살펴봅니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 952.76,
  "end": 958.64
 },
 {
  "input": "So in our cancer example, this would have been the 10% false negative rate divided by the 91% specificity, or about 1 in 9. ",
  "translatedText": "따라서 암의 예에서 이는 10% 위음성률을 91% 특이성으로 나눈 값, 즉 9분의 1 정도가 됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 958.64,
  "end": 967.04
 },
 {
  "input": "In other words, seeing a negative test result in that example would reduce your prior odds by about an order of magnitude. ",
  "translatedText": "즉, 해당 예에서 부정적인 테스트 결과를 확인하면 이전 확률이 약 10배 정도 감소합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 967.78,
  "end": 974.46
 },
 {
  "input": "When you write it all out as a formula, here's how it looks. ",
  "translatedText": "이 모든 것을 수식으로 쓰면 다음과 같습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 975.9,
  "end": 978.42
 },
 {
  "input": "It says your odds of having a disease given a test result equals your odds before taking the test, the prior odds, times the base factor. ",
  "translatedText": "검사 결과를 바탕으로 질병에 걸릴 확률은 검사 전 확률, 이전 확률에 기본 요인을 곱한 것과 같습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.76,
  "end": 986.96
 },
 {
  "input": "Now let's contrast this with the usual way that Bayes' Rule is written, which is a bit more complicated. ",
  "translatedText": "이제 이것을 좀 더 복잡한 베이즈 규칙이 작성되는 일반적인 방식과 대조해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.96,
  "end": 992.26
 },
 {
  "input": "In case you haven't seen it before, it's essentially just what we were doing with sample populations, but you wrap it all up symbolically. ",
  "translatedText": "이전에 본 적이 없는 경우를 대비해 본질적으로 표본 모집단을 사용하여 수행한 작업과 동일하지만 모든 것을 상징적으로 마무리합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 993.06,
  "end": 998.78
 },
 {
  "input": "Remember how every time we were counting the number of true positives and then dividing it by the sum of the true positives and the false positives? ",
  "translatedText": "매번 참양성의 수를 세고 이를 참양성과 거짓양성의 합으로 나누는 방법을 기억하시나요? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 999.5,
  "end": 1006.26
 },
 {
  "input": "We do just that, except instead of talking about absolute amounts, we talk of each term as a proportion. ",
  "translatedText": "우리는 절대량에 대해 이야기하는 대신 각 용어를 비율로 이야기하는 것을 제외하고는 그렇게 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1006.8,
  "end": 1012.26
 },
 {
  "input": "So the proportion of true positives in the population comes from the prior probability of having the disease multiplied by the probability of seeing a positive test result in that case. ",
  "translatedText": "따라서 모집단의 참양성 비율은 질병에 걸릴 사전 확률에 해당 경우 양성 검사 결과가 나올 확률을 곱한 값에서 나옵니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1012.26,
  "end": 1022.26
 },
 {
  "input": "Then we copy that term down again into the denominator, and then the proportion of false positives comes from the prior probability of not having the disease times the probability of a positive test in that case. ",
  "translatedText": "그런 다음 해당 용어를 다시 분모에 복사하면 위양성 비율은 질병이 없을 사전 확률과 해당 경우 양성 테스트 확률을 곱한 값에서 나옵니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1023.0,
  "end": 1034.1
 },
 {
  "input": "If you want, you could also write this down with words instead of symbols, if terms like sensitivity and false positive rate are more comfortable. ",
  "translatedText": "원하는 경우 민감도 및 거짓양성률과 같은 용어가 더 편안하다면 기호 대신 단어로 이를 기록할 수도 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.08,
  "end": 1040.86
 },
 {
  "input": "And this is one of those formulas where once you say it out loud it seems like a bit much, but it really is no different from what we were doing with sample populations. ",
  "translatedText": "그리고 이것은 큰 소리로 말하면 약간 많은 것처럼 보이지만 실제로는 표본 모집단을 사용하여 수행한 것과 다르지 않은 공식 중 하나입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.38,
  "end": 1048.4
 },
 {
  "input": "If you wanted to make the whole thing look simpler, you often see this entire denominator written just as the probability of seeing a positive test result, overall. ",
  "translatedText": "모든 것을 더 단순하게 보이도록 하고 싶다면 이 전체 분모가 전반적으로 긍정적인 테스트 결과를 볼 확률로 쓰여진 것을 종종 볼 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1049.22,
  "end": 1057.0
 },
 {
  "input": "While that does make for a really elegant little expression, if you intend to use this for calculations, it's a little disingenuous, because in practice, every single time you do this you need to break down that denominator into two separate parts, breaking down the cases. ",
  "translatedText": "정말 우아한 작은 표현이 되기는 하지만, 이것을 계산에 사용하려는 경우에는 약간 솔직하지 못합니다. 왜냐하면 실제로는 이 작업을 수행할 때마다 분모를 두 개의 개별 부분으로 분해해야 하기 때문입니다. 사례. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.98,
  "end": 1070.58
 },
 {
  "input": "So taking this more honest representation of it, let's compare our two versions of Bayes' rule. ",
  "translatedText": "따라서 이를 좀 더 정직하게 표현하여 두 가지 버전의 베이즈 규칙을 비교해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1071.7,
  "end": 1076.02
 },
 {
  "input": "And again, maybe it looks nicer if we use the words sensitivity and false positive rate. ",
  "translatedText": "그리고 민감도와 거짓양성률이라는 단어를 사용하면 더 좋아 보일 수도 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1076.82,
  "end": 1080.28
 },
 {
  "input": "If nothing else, it helps emphasize which parts of the formula are coming from statistics about the test accuracy. ",
  "translatedText": "다른 것이 없다면 공식의 어느 부분이 테스트 정확도에 대한 통계에서 나오는지 강조하는 데 도움이 됩니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1080.66,
  "end": 1085.64
 },
 {
  "input": "I mean, this actually emphasizes one thing I really like about the framing with odds and a Bayes' factor, which is that it cleanly factors out the parts that have to do with the prior and the parts that have to do with the test accuracy. ",
  "translatedText": "내 말은, 이는 확률과 베이즈 요인을 사용한 프레이밍에 대해 제가 정말 좋아하는 한 가지를 실제로 강조한다는 것입니다. 즉, 사전과 관련된 부분과 테스트 정확도와 관련된 부분을 깔끔하게 제외한다는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.64,
  "end": 1095.84
 },
 {
  "input": "But over in the usual formula, all of those are very intermingled together. ",
  "translatedText": "그러나 일반적인 공식에서는 이 모든 것이 서로 매우 혼합되어 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.66,
  "end": 1100.2
 },
 {
  "input": "And this has a very practical benefit. ",
  "translatedText": "그리고 이것은 매우 실용적인 이점을 가지고 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1100.58,
  "end": 1102.36
 },
 {
  "input": "It's really nice if you want to swap out different priors and easily see their effects. ",
  "translatedText": "다른 사전을 교체하고 그 효과를 쉽게 확인하고 싶다면 정말 좋습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.48,
  "end": 1106.26
 },
 {
  "input": "This is what we were doing earlier. ",
  "translatedText": "이것이 우리가 이전에 하고 있던 일입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1106.6,
  "end": 1107.9
 },
 {
  "input": "But with the other formula, to do that, you have to recompute everything each time. ",
  "translatedText": "하지만 다른 수식을 사용하려면 매번 모든 것을 다시 계산해야 합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.42,
  "end": 1112.2
 },
 {
  "input": "You can't leverage a precomputed Bayes' factor the same way. ",
  "translatedText": "미리 계산된 베이즈 요인을 같은 방식으로 활용할 수는 없습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.38,
  "end": 1115.36
 },
 {
  "input": "The odds framing also makes things really nice if you want to do multiple different Bayesian updates based on multiple pieces of evidence. ",
  "translatedText": "여러 증거를 기반으로 다양한 베이지안 업데이트를 수행하려는 경우 확률 프레이밍도 매우 유용합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.96,
  "end": 1122.12
 },
 {
  "input": "For example, let's say you took not one test, but two. ",
  "translatedText": "예를 들어, 한 번이 아니라 두 번 시험을 쳤다고 가정해 보겠습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.74,
  "end": 1124.86
 },
 {
  "input": "Or you wanted to think about how the presence of symptoms plays into it. ",
  "translatedText": "또는 증상의 존재가 어떻게 작용하는지 생각하고 싶었습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.36,
  "end": 1128.54
 },
 {
  "input": "For each piece of new evidence you see, you always ask the question, how much more likely would you be to see that with the disease versus without the disease? ",
  "translatedText": "당신이 보는 각각의 새로운 증거에 대해 당신은 항상 질문합니다. 질병이 있는 경우와 질병이 없는 경우에 그것을 볼 가능성이 얼마나 더 높습니까? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1129.12,
  "end": 1136.62
 },
 {
  "input": "Each answer to that question gives you a new Bayes' factor, a new thing that you multiply by your odds. ",
  "translatedText": "해당 질문에 대한 각각의 답변은 새로운 베이즈 요인, 즉 확률을 곱하는 새로운 요소를 제공합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1137.24,
  "end": 1142.0
 },
 {
  "input": "Beyond just making calculations easier, there's something I really like about attaching a number to test accuracy that doesn't even look like a probability. ",
  "translatedText": "단순히 계산을 쉽게 하는 것 외에도, 확률처럼 보이지도 않는 정확도를 테스트하기 위해 숫자를 붙이는 것이 제가 정말 좋아하는 점이 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.88,
  "end": 1149.92
 },
 {
  "input": "I mean, if you hear that a test has, for example, a 9% false positive rate, that's just such a disastrously ambiguous phrase. ",
  "translatedText": "예를 들어, 테스트 결과 오탐률이 9%라는 말을 듣는다면 이는 정말 끔찍할 정도로 모호한 표현입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1150.74,
  "end": 1157.34
 },
 {
  "input": "It's so easy to misinterpret it to mean there's a 9% chance that your positive test result is false. ",
  "translatedText": "양성 테스트 결과가 거짓일 확률이 9%라는 뜻으로 잘못 해석하기가 너무 쉽습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.78,
  "end": 1162.58
 },
 {
  "input": "But imagine if instead the number that we heard tacked on to test results was that the Bayes' factor for a positive test result is, say, 10. ",
  "translatedText": "하지만 테스트 결과에 추가된 숫자가 긍정적인 테스트 결과에 대한 베이즈 요인이 10이라고 상상해 보세요. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1163.3,
  "end": 1170.32
 },
 {
  "input": "There's no room to confuse that for your probability of having a disease. ",
  "translatedText": "질병에 걸릴 확률 때문에 이를 혼동할 여지가 없습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1170.82,
  "end": 1174.14
 },
 {
  "input": "The entire framing of what a Bayes' factor is, is that it's something that acts on a prior. ",
  "translatedText": "베이즈 요인이 무엇인지에 대한 전체적인 틀은 그것이 사전에 작용하는 것이라는 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1174.64,
  "end": 1179.04
 },
 {
  "input": "It forces your hand to acknowledge the prior as something that's separate entirely, and highly necessary to drawing any conclusion. ",
  "translatedText": "이는 이전 항목을 완전히 별개의 것으로 인정하고 결론을 도출하는 데 매우 필요한 것으로 손을 강제합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1179.5,
  "end": 1185.44
 },
 {
  "input": "All that said, the usual formula is definitely not without its merits. ",
  "translatedText": "즉, 일반적인 공식에 장점이 없는 것은 아닙니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1187.26,
  "end": 1190.74
 },
 {
  "input": "If you view it not simply as something to plug numbers into, but as an encapsulation of the sample population idea that we've been using throughout, you could very easily argue that that's actually much better for your intuition. ",
  "translatedText": "단순히 숫자를 연결하는 것이 아니라 우리가 전체적으로 사용했던 표본 모집단 아이디어를 캡슐화한 것으로 본다면 그것이 실제로 직관에 훨씬 더 좋다고 쉽게 주장할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1191.08,
  "end": 1201.98
 },
 {
  "input": "After all, it's what we were routinely falling back on in order to check ourselves that the Bayes' factor computation even made sense in the first place. ",
  "translatedText": "결국, Bayes의 요인 계산이 애초에 의미가 있는지 확인하기 위해 우리가 일상적으로 의지했던 것입니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1202.56,
  "end": 1209.18
 },
 {
  "input": "Like any design decision, there is no clear-cut objective best here. ",
  "translatedText": "모든 디자인 결정과 마찬가지로 여기에는 명확한 목표가 없습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1211.6,
  "end": 1215.38
 },
 {
  "input": "But it's almost certainly the case that giving serious consideration to that question will lead you to a better understanding of Bayes' rule. ",
  "translatedText": "그러나 해당 질문을 진지하게 고려하면 베이즈 규칙을 더 잘 이해할 수 있다는 것은 거의 확실합니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.42,
  "end": 1221.72
 },
 {
  "input": "Also, since we're on the topic of kind of paradoxical things, a friend of mine, Matt Cook, recently wrote a book all about paradoxes. ",
  "translatedText": "또한 우리가 일종의 역설적인 주제를 다루고 있기 때문에 내 친구인 Matt Cook이 최근에 역설에 관한 책을 썼습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1230.1,
  "end": 1236.12
 },
 {
  "input": "I actually contributed a small chapter to it with thoughts on the question of whether math is invented or discovered. ",
  "translatedText": "나는 실제로 수학이 발명되었는지 아니면 발견되었는지에 대한 질문에 대한 생각을 담은 작은 장을 기고했습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.04,
  "end": 1241.82
 },
 {
  "input": "And the book as a whole is this really nice connection of thought-provoking paradoxical things ranging from philosophy to math and physics. ",
  "translatedText": "그리고 책 전체는 철학에서 수학과 물리학에 이르기까지 생각을 자극하는 역설적인 것들을 정말 훌륭하게 연결해 줍니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1242.3,
  "end": 1248.4
 },
 {
  "input": "You can, of course, find all the details in the description. ",
  "translatedText": "물론 설명에서 모든 세부정보를 확인할 수 있습니다. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.82,
  "end": 1251.04
 }
]