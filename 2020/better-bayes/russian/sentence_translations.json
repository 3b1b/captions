[
 {
  "input": "Some of you may have heard this paradoxical fact about medical tests. ",
  "translatedText": "Некоторые из вас, возможно, слышали этот парадоксальный факт о медицинских тестах. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 3.14
 },
 {
  "input": "It's very commonly used to introduce the topic of Bayes' rule in probability. ",
  "translatedText": "Его очень часто используют в курсе теории вероятности, чтобы дать введение в правила Байеса. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 3.58,
  "end": 6.74
 },
 {
  "input": "The paradox is that you could take a test which is highly accurate, in the sense that it gives correct results to a large majority of the people taking it. ",
  "translatedText": "Парадокс заключается в том, что вы можете пройти тест, который будет очень точным в том смысле, что он дает правильные результаты подавляющему большинству проходящих его людей. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.5,
  "end": 15.66
 },
 {
  "input": "And yet, under the right circumstances, when assessing the probability that your particular test result is correct, you can still land on a very low number, arbitrarily low, in fact. ",
  "translatedText": "И тем не менее, при определенных обстоятельствах, оценивая вероятность того, что ваш конкретный результат теста верен, вы все равно можете получить очень низкое число, фактически сколь угодно низкое. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 16.04,
  "end": 26.3
 },
 {
  "input": "In short, an accurate test is not necessarily a very predictive test. ",
  "translatedText": "Короче говоря, точный тест не обязательно является очень прогнозирующим тестом. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.78,
  "end": 31.82
 },
 {
  "input": "Now when people think about math and formulas, they don't often think of it as a design process. ",
  "translatedText": "Теперь, когда люди думают о математике и формулах, они не часто думают об этом как о процессе проектирования. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 33.06,
  "end": 37.44
 },
 {
  "input": "I mean, maybe in the case of notation it's easy to see that different choices are possible, but when it comes to the structure of the formulas themselves, and how we use them, that's something that people typically view as fixed. ",
  "translatedText": "Я имею в виду, что, может быть, в случае с обозначениями легко увидеть, что возможны разные варианты, но когда дело доходит до структуры самих формул и того, как мы их используем, люди обычно считают это чем-то фиксированным. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 38.08,
  "end": 49.68
 },
 {
  "input": "In this video, you and I will dig into this paradox, but instead of using it to talk about the usual version of Bayes' rule, I'd like to motivate an alternate version, an alternate design choice. ",
  "translatedText": "В этом видео мы с вами углубимся в этот парадокс, но вместо того, чтобы использовать его для разговора об обычной версии правила Байеса, я хотел бы предложить альтернативную версию, альтернативный выбор дизайна. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 50.68,
  "end": 60.56
 },
 {
  "input": "Now, what's up on the screen now is a little bit abstract, which makes it difficult to justify that there really is a substantive difference here, especially when I haven't explained either one yet. ",
  "translatedText": "То, что сейчас происходит на экране, немного абстрактно, поэтому трудно обосновать наличие существенного отличия, особенно если я еще не объяснил ни одного из них. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 61.66,
  "end": 70.54
 },
 {
  "input": "To see what I'm talking about though, we should really start by spending some time a little more concretely, and just laying out what exactly this paradox is. ",
  "translatedText": "Однако, чтобы понять, о чем я говорю, нам действительно следует сперва потратить немного времени на что-то более конкретное и просто изложить, в чем именно заключается этот парадокс. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 71.04,
  "end": 78.1
 },
 {
  "input": "1% of women have breast cancer Picture a thousand women and suppose that 1% of them have breast cancer. ",
  "translatedText": "1% женщин болеет раком молочной железы. Представьте себе тысячу женщин и предположим, что у 1% из них рак молочной железы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.02,
  "end": 87.94
 },
 {
  "input": "And let's say they all undergo a certain breast cancer screening, and that 9 of those with cancer correctly get positive results, and there's one false negative. ",
  "translatedText": "Допустим, все они прошли определенный скрининг на рак молочной железы, и 9 из больных раком получили правильные положительные результаты, и есть один ложноотрицательный результат. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.68,
  "end": 96.68
 },
 {
  "input": "And then suppose that among the remainder without cancer, 89 get false positives, and 901 correctly get negative results. ",
  "translatedText": "А затем предположим, что среди оставшихся без рака 89 получили ложноположительные результаты, а 901 правильно получили отрицательные результаты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.48,
  "end": 104.92
 },
 {
  "input": "So if all you know about a woman is that she does the screening and she gets a positive result, you don't have information about symptoms or anything like that, you know that she's either one of these 9 true positives or one of these 89 false positives. ",
  "translatedText": "Итак, если все, что вы знаете о женщине, это лишь то, что она прошла обследование и получила положительный результат, и у вас нет информации о симптомах или чем-то подобном, то вы знаете, что она либо одна из этих 9 истинно положительных результатов, либо одна из этих 89 ложных срабатываний. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 105.72,
  "end": 118.26
 },
 {
  "input": "So the probability that she's in the cancer group given the test result is 9 divided by 9 plus 89, which is approximately 1 in 11. ",
  "translatedText": "Таким образом, вероятность того, что она находится в группе рака, учитывая результат теста, равна 9 разделенному на 9, плюс 89, что составляет примерно 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 119.36,
  "end": 128.14
 },
 {
  "input": "In medical parlance, you would call this the positive predictive value of the test, or PPV, the number of true positives divided by the total number of positive test results. ",
  "translatedText": "На медицинском языке вы бы назвали это положительной прогностической ценностью теста, или PPV — числом истинных положительных результатов, разделенным на общее количество положительных результатов теста. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 129.08,
  "end": 138.62
 },
 {
  "input": "You can see where the name comes from. ",
  "translatedText": "Вы можете увидеть, откуда взялось это название. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 138.62,
  "end": 140.44
 },
 {
  "input": "To what extent does a positive test result actually predict that you have the disease? ",
  "translatedText": "В какой степени положительный результат теста действительно предсказывает наличие у вас заболевания? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.74,
  "end": 145.36
 },
 {
  "input": "Now hopefully, as I've presented it this way where we're thinking concretely about a sample population, all of this makes perfect sense. ",
  "translatedText": "Надеюсь, теперь, когда я представил это таким образом, что мы думаем о конкретной выборке населения, все это имеет смысл. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 146.82,
  "end": 153.46
 },
 {
  "input": "But where it comes across as counterintuitive is if you just look at the accuracy of the test, present it to people as a statistic, and then ask them to make judgments about their test result. ",
  "translatedText": "Но это может показаться нелогичным, если вы просто посмотрите на точность теста, представите его людям в виде статистики, а затем попросите их высказать суждение о результате своего теста. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.96,
  "end": 163.2
 },
 {
  "input": "Test accuracy is not actually one number, but two. ",
  "translatedText": "Точность теста на самом деле измеряется не одним числом, а двумя. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.02,
  "end": 166.26
 },
 {
  "input": "First, you ask, how often is a test correct on those with the disease? ",
  "translatedText": "Во-первых, вы спрашиваете, как часто тесты дают правильные результаты у людей с этим заболеванием? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.26,
  "end": 171.12
 },
 {
  "input": "This is known as the test sensitivity, as in, how sensitive is it to detecting the presence of the disease? ",
  "translatedText": "Это известно как чувствительность теста, например, насколько он чувствителен к обнаружению наличия заболевания? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.7,
  "end": 177.44
 },
 {
  "input": "In our example, test sensitivity is 9 in 10, or 90%. ",
  "translatedText": "В нашем примере чувствительность теста составляет 9 из 10, или 90%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.26,
  "end": 181.26
 },
 {
  "input": "And another way to say the same fact would be to say the false negative rate is 10%. ",
  "translatedText": "Другой способ выразить тот же факт — сказать, что уровень ложноотрицательных результатов составляет 10%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.02,
  "end": 186.68
 },
 {
  "input": "And then a separate, not necessarily related number, is how often it's correct for those without the disease, which is known as the test specificity, as in, are positive results caused specifically by the disease, or are there confounding triggers giving false positives? ",
  "translatedText": "И затем отдельное, не обязательно связанное число, это то, как часто он верен для тех, у кого нет заболевания, которое называется специфичностью теста. Например, вызваны ли положительные результаты именно заболеванием, или существуют ли сбивающие с толку триггеры, дающие ложноположительные результаты? ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 186.68,
  "end": 202.06
 },
 {
  "input": "In our example, the specificity is about 91%. ",
  "translatedText": "В нашем примере специфичность составляет около 91%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.08,
  "end": 206.58
 },
 {
  "input": "Or, another way to say the same fact would be to say the false positive rate is 9%. ",
  "translatedText": "Или, другой способ выразить тот же факт — сказать, что уровень ложноположительных результатов составляет 9%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.58,
  "end": 211.66
 },
 {
  "input": "So the paradox here is that, in one sense, the test is over 90% accurate. ",
  "translatedText": "Итак, парадокс заключается в том, что в каком-то смысле тест имеет точность более 90%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.66,
  "end": 216.76
 },
 {
  "input": "It gives correct results to over 90% of the patients who take it. ",
  "translatedText": "Он дает правильные результаты более чем 90% пациентов, которые его принимают. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 217.02,
  "end": 220.66
 },
 {
  "input": "And yet, if you learn that someone gets a positive result without any added information, there's actually only a 1 in 11 chance that that particular result is accurate. ",
  "translatedText": "И все же, если вы узнаете, что кто-то получил положительный результат без какой-либо дополнительной информации, на самом деле вероятность того, что этот конкретный результат окажется точным, составляет только 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.66,
  "end": 229.6
 },
 {
  "input": "This is a bit of a problem, because of all of the places for math to be counterintuitive, medical tests are one area where it matters a lot. ",
  "translatedText": "Это небольшая проблема, поскольку математика всегда противоречит здравому смыслу, а медицинские тесты — это та область, где она имеет большое значение. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.62,
  "end": 237.18
 },
 {
  "input": "In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics seminars to practicing gynecologists, and he opened with the following example. ",
  "translatedText": "В 2006 и 2007 годах психолог Герд Гигеренцер провел серию семинаров по статистике для практикующих гинекологов, начав их со следующего примера. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.94,
  "end": 246.8
 },
 {
  "input": "A 50-year-old woman, no symptoms, participates in a routine mammography screening. ",
  "translatedText": "50-летняя женщина без симптомов проходит плановое маммографическое обследование. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.8,
  "end": 251.74
 },
 {
  "input": "She tests positive, is alarmed, and wants to know from you whether she has breast cancer for certain, or what her chances are. ",
  "translatedText": "У нее положительный результат теста, она встревожена и хочет узнать от вас, действительно ли у нее рак груди и каковы ее шансы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.28,
  "end": 258.38
 },
 {
  "input": "Apart from the screening result, you know nothing else about this woman. ",
  "translatedText": "Кроме результатов проверки, вы больше ничего об этой женщине не знаете. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.88,
  "end": 261.74
 },
 {
  "input": "In that seminar, the doctors were then told that the prevalence of breast cancer for women of this age is about 1%, and then to suppose that the test sensitivity is 90%, and that its specificity was 91%. ",
  "translatedText": "На этом семинаре врачам затем сказали, что распространенность рака молочной железы среди женщин этого возраста составляет около 1%, а затем предположили, что чувствительность теста составляет 90%, а его специфичность - 91%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 262.58,
  "end": 274.18
 },
 {
  "input": "You might notice these are exactly the same numbers from the example that you and I just looked at. ",
  "translatedText": "Вы могли заметить, что это точно такие же числа из примера, который мы с вами только что рассмотрели. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.18,
  "end": 278.18
 },
 {
  "input": "This is where I got them. ",
  "translatedText": "Вот где я их получил. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.36,
  "end": 279.44
 },
 {
  "input": "So, having already thought it through, you and I know the answer. ",
  "translatedText": "Итак, уже все обдумав, мы с вами знаем ответ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 279.76,
  "end": 282.6
 },
 {
  "input": "It's about 1 in 11. ",
  "translatedText": "Это примерно 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.88,
  "end": 283.84
 },
 {
  "input": "However, the doctors in this session were not primed with the suggestion to picture a concrete sample of a thousand individuals, the way that you and I had. ",
  "translatedText": "Однако врачи на этом сеансе не были настроены на предложение представить конкретную выборку из тысячи человек, как это было у нас с вами. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.6,
  "end": 291.54
 },
 {
  "input": "All they saw were these numbers. ",
  "translatedText": "Все, что они видели, были эти цифры. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.04,
  "end": 293.34
 },
 {
  "input": "They were then asked, how many women who test positive actually have breast cancer? ",
  "translatedText": "Затем их спросили, сколько женщин с положительным результатом теста на самом деле страдают раком молочной железы? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.14,
  "end": 298.42
 },
 {
  "input": "What is the best answer? ",
  "translatedText": "Какой лучший ответ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.62,
  "end": 299.74
 },
 {
  "input": "And they were presented with these four choices. ",
  "translatedText": "И им были предложены эти четыре варианта выбора. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.9,
  "end": 301.68
 },
 {
  "input": "In one of the sessions, over half the doctors present said that the correct answer was 9 in 10, which is way off. ",
  "translatedText": "На одном из сеансов более половины присутствовавших врачей сказали, что правильный ответ — 9 из 10, что очень далеко. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.68,
  "end": 309.3
 },
 {
  "input": "Only a fifth of them gave the correct answer, which is worse than what it would have been if everybody had randomly guessed. ",
  "translatedText": "Только пятая часть из них дала правильный ответ, что даже хуже, чем если бы все выбрали наугад. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 310.02,
  "end": 315.38
 },
 {
  "input": "It might seem a little extreme to be calling this a paradox. ",
  "translatedText": "Называть это парадоксом может показаться несколько избыточно. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 316.66,
  "end": 319.28
 },
 {
  "input": "I mean, it's just a fact. ",
  "translatedText": "Я имею в виду, это просто факт. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.76,
  "end": 321.14
 },
 {
  "input": "It's not something intrinsically self-contradictory. ",
  "translatedText": "Это не что-то внутренне противоречивое. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 321.26,
  "end": 323.5
 },
 {
  "input": "But, as these seminars with Gigerenzer show, people, including doctors, definitely find it counterintuitive that a test with high accuracy can give you such a low predictive value. ",
  "translatedText": "Но, как показывают семинары с участием Гигеренцера, люди, в том числе врачи, определенно находят нелогичным, что тест с высокой точностью может дать такую низкую прогностическую ценность. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 324.2,
  "end": 334.24
 },
 {
  "input": "We might call this a veridical paradox, which refers to facts that are provably true, but which nevertheless can feel false when phrased a certain way. ",
  "translatedText": "Мы могли бы назвать это таким парадоксом, который говорит о фактах, которые доказуемо истинны, но, тем не менее, могут показаться ложными, если их представить определенным образом. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 335.2,
  "end": 343.8
 },
 {
  "input": "It's sort of the softest form of a paradox, saying more about human psychology than about logic. ",
  "translatedText": "Это своего рода самая мягкая форма парадокса, говорящая больше о человеческой психологии, чем о логике. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.3,
  "end": 348.72
 },
 {
  "input": "The question is how we can combat this. ",
  "translatedText": "Вопрос в том, как с этим бороться. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.58,
  "end": 351.98
 },
 {
  "input": "Where we're going with this, by the way, is that I want you to be able to look at numbers like this and quickly estimate in your head that it means the predictive value of a positive test should be around 1 in 11. ",
  "translatedText": "Кстати, мы хотим, чтобы вы могли посмотреть на подобные цифры и быстро прикинуть в уме, что это означает, что прогностическая ценность положительного теста должна составлять примерно 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.8,
  "end": 364.14
 },
 {
  "input": "Or, if I changed things and asked, what if it was 10% of the population who had breast cancer? ",
  "translatedText": "Или, если бы я изменил ситуацию и спросил, если бы 10% населения страдали раком молочной железы? ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 364.76,
  "end": 369.72
 },
 {
  "input": "You should be able to quickly turn around and say that the final answer would be a little over 50%. ",
  "translatedText": "Вы должны быть в состоянии быстро передумать и сказать, что окончательный ответ будет чуть больше 50%. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 370.12,
  "end": 374.98
 },
 {
  "input": "Or, if I said imagine a really low prevalence, something like 0.1% of patients having cancer, you should again quickly estimate that the predictive value of the test is around 1 in 100. ",
  "translatedText": "Или, если бы я сказал, представьте себе действительно низкую распространенность, что-то вроде 0.1% пациентов болеют раком, то вам следует снова быстро оценить, что прогностическая ценность теста составляет примерно 1 из 100. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 375.92,
  "end": 386.14
 },
 {
  "input": "That 1 in 100 of those with positive test results in that case would have cancer. ",
  "translatedText": "В этом случае у 1 из 100 людей с положительными результатами тестов будет рак. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 386.76,
  "end": 390.6
 },
 {
  "input": "Or, let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "Или, скажем, мы вернемся к распространенности в 1%, но я сделаю тест более точным. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.58,
  "end": 395.24
 },
 {
  "input": "I tell you to imagine the specificity is 99%. ",
  "translatedText": "Я вам говорю: представьте себе, что специфичность составляет 99%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.44,
  "end": 398.4
 },
 {
  "input": "There, you should be able to relatively quickly estimate that the answer is a little less than 50%. ",
  "translatedText": "Там вы сможете относительно быстро оценить, что ответ составляет чуть меньше 50%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.4,
  "end": 403.8
 },
 {
  "input": "The hope is that you're doing all of this with minimal calculations in your head. ",
  "translatedText": "Мы надеемся, что вы делаете все это с минимальными вычислениями в голове. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 404.32,
  "end": 407.74
 },
 {
  "input": "Now, the goals of quick calculations might feel very different from the goals of addressing whatever misconception underlies this paradox, but they actually go hand in hand. ",
  "translatedText": "Конечно, цели быстрых вычислений могут сильно отличаться от целей устранения любого заблуждения, лежащего в основе этого парадокса, но на самом деле они идут рука об руку. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.54,
  "end": 416.5
 },
 {
  "input": "Let me show you what I mean. ",
  "translatedText": "Позвольте мне показать вам, что я имею в виду. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.9,
  "end": 417.68
 },
 {
  "input": "On the side of addressing misconceptions, what would you tell to the people in that seminar who answered 9 and 10? ",
  "translatedText": "Что касается устранения заблуждений, что бы вы сказали участникам семинара, ответившим 9 и 10? ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 418.46,
  "end": 423.98
 },
 {
  "input": "What fundamental misconception are they revealing? ",
  "translatedText": "Какое фундаментальное заблуждение они раскрывают? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.48,
  "end": 426.9
 },
 {
  "input": "What I might tell them is that in much the same way that you shouldn't think of tests as telling you deterministically whether you have a disease, you shouldn't even think of them as telling you your chances of having a disease. ",
  "translatedText": "Я мог бы сказать им, что во многом так же, как вы не должны думать о тестах как о том, что они детерминированно сообщают вам, есть ли у вас болезнь, вы даже не должны думать о них как о том, что они говорят вам о ваших шансах заболеть болезнью. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 428.18,
  "end": 438.6
 },
 {
  "input": "Instead, the healthy view of what tests do is that they update your chances. ",
  "translatedText": "Вместо этого, здравый взгляд на то, что делают тесты, заключается в том, что они повышают ваши шансы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.56,
  "end": 444.46
 },
 {
  "input": "In our example, before taking the test, a patient's chances of having cancer were 1 in 100. ",
  "translatedText": "В нашем примере до прохождения теста шансы пациента заболеть раком составляли 1 из 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.04,
  "end": 450.68
 },
 {
  "input": "In Bayesian terms, we call this the prior probability. ",
  "translatedText": "В байесовских терминах мы называем это априорной вероятностью. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 453.64
 },
 {
  "input": "The effect of this test was to update that prior by almost an order of magnitude, up to around 1 in 11. ",
  "translatedText": "Результатом этого теста было обновление предыдущего почти на порядок, примерно до 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.38,
  "end": 460.36
 },
 {
  "input": "The accuracy of a test is telling us about the strength of this updating. ",
  "translatedText": "Точность теста говорит нам о силе этого обновления. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.02,
  "end": 464.82
 },
 {
  "input": "It's not telling us a final answer. ",
  "translatedText": "Это не дает нам окончательного ответа. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.12,
  "end": 466.74
 },
 {
  "input": "What does this have to do with quick approximations? ",
  "translatedText": "Какое это имеет отношение к быстрым приближениям? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 467.9,
  "end": 469.64
 },
 {
  "input": "Well, a key number for those approximations is something called the Bayes factor, and the very act of defining this number serves to reinforce this central lesson about reframing what it is the tests do. ",
  "translatedText": "Что ж, ключевым числом для этих приближений является так называемый фактор Байеса, и сам акт определения этого числа служит подкреплением этого центрального урока о переосмыслении того, что именно делают тесты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.3,
  "end": 481.4
 },
 {
  "input": "You see, one of the things that makes test statistics so very confusing is that there are at least 4 numbers that you'll hear associated with them. ",
  "translatedText": "Видите ли, одна из вещей, которая делает статистику тестов такой запутанной, заключается в том, что с ней связаны как минимум 4 числа. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.42,
  "end": 488.9
 },
 {
  "input": "For those with the disease, there's the sensitivity and the false negative rate, and then for those without, there's the specificity and the false positive rate, and none of these numbers actually tell you the thing you want to know. ",
  "translatedText": "Для тех, у кого есть заболевание, есть чувствительность и уровень ложноотрицательных результатов, а для тех, у кого нет, есть специфичность и уровень ложноположительных результатов, и ни одно из этих чисел на самом деле не говорит вам то, что вы хотите знать. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.9,
  "end": 498.8
 },
 {
  "input": "Luckily, if you want to interpret a positive test result, you can pull out just one number to focus on from all this. ",
  "translatedText": "К счастью, если вы хотите интерпретировать положительный результат теста, вы можете выделить из всего этого только одну цифру, на которой можно сосредоточиться. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 499.5,
  "end": 505.62
 },
 {
  "input": "Take the sensitivity divided by the false positive rate. ",
  "translatedText": "Возьмите чувствительность, разделенную на долю ложноположительных результатов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.04,
  "end": 508.6
 },
 {
  "input": "In other words, how much more likely are you to see the positive test result with cancer versus without? ",
  "translatedText": "Другими словами, насколько более вероятно, что вы увидите положительный результат теста при раке, чем при его отсутствии? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.16,
  "end": 514.74
 },
 {
  "input": "In our example, this number is 10. ",
  "translatedText": "В нашем примере это число равно 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.74,
  "end": 517.14
 },
 {
  "input": "This is the Bayes factor, also sometimes called the likelihood ratio. ",
  "translatedText": "Это фактор Байеса, также иногда называемый отношением правдоподобия. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.9,
  "end": 521.72
 },
 {
  "input": "A very handy rule of thumb is that to update a small prior, or at least to approximate the answer, you simply multiply it by the Bayes factor. ",
  "translatedText": "Очень удобное практическое правило заключается в том, что для обновления небольшого априора, или просто для получения приблизительного ответа, вы просто умножаете его на коэффициент Байеса. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 523.1,
  "end": 530.02
 },
 {
  "input": "So in our example, where the prior was 1 in 100, you would estimate that the final answer should be around 1 in 10, which is in fact slightly above the true correct answer. ",
  "translatedText": "Итак, в нашем примере, где предыдущий ответ был 1 из 100, по вашей оценке, окончательный ответ должен быть примерно 1 из 10, что на самом деле немного выше истинно правильного ответа. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.76,
  "end": 538.82
 },
 {
  "input": "So based on this rule of thumb, if I asked you what would happen if the prior from our example was instead 1 in 1000, you could quickly estimate that the effect of the test should be to update those chances to around 1 in 100. ",
  "translatedText": "Итак, основываясь на этом эмпирическом правиле, если бы я спросил вас, что произойдет, если априор из нашего примера будет равен 1 из 1000, вы сможете быстро оценить, что эффект теста должен заключаться в обновлении этих шансов примерно до 1 из 100. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.4,
  "end": 551.42
 },
 {
  "input": "And in fact, take a moment to check yourself by thinking through a sample population. ",
  "translatedText": "И действительно, найдите минутку, чтобы проверить себя, проанализировав выборку населения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.36,
  "end": 555.72
 },
 {
  "input": "In this case, you might picture 10,000 patients where only 10 of them really have cancer. ",
  "translatedText": "В этом случае вы можете представить себе 10 000 пациентов, из которых только 10 действительно больны раком. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.7,
  "end": 560.88
 },
 {
  "input": "And then based on that 90% sensitivity, we would expect 9 of those cancer cases to give true positives. ",
  "translatedText": "И затем, исходя из этой 90% чувствительности, мы ожидаем, что 9 из этих случаев рака дадут истинные положительные результаты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 562.14,
  "end": 567.9
 },
 {
  "input": "And on the other side, a 91% specificity means that 9% of those without cancer are getting false positives. ",
  "translatedText": "С другой стороны, специфичность 91% означает, что 9% людей, не страдающих раком, получают ложноположительные результаты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.0,
  "end": 575.76
 },
 {
  "input": "So we'd expect 9% of the remaining patients, which is around 900, to give false positive results. ",
  "translatedText": "Таким образом, мы ожидаем, что 9% оставшихся пациентов, то есть около 900, дадут ложноположительные результаты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.66,
  "end": 581.86
 },
 {
  "input": "Here, with such a low prevalence, the false positives really do dominate the true positives. ",
  "translatedText": "Здесь, при такой низкой распространенности, ложноположительные результаты действительно доминируют над истинными положительными. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 582.7,
  "end": 587.82
 },
 {
  "input": "So the probability that a randomly chosen positive case from this population actually has cancer is only around 1%, just like the rule of thumb predicted. ",
  "translatedText": "Таким образом, вероятность того, что случайно выбранный положительный случай из этой популяции действительно болен раком, составляет всего около 1%, как и предсказывает эмпирическое правило. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 587.9,
  "end": 597.02
 },
 {
  "input": "Now, this rule of thumb clearly cannot work for higher priors. ",
  "translatedText": "Это эмпирическое правило явно не будет работать для более высоких априорных значений. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 598.7,
  "end": 601.92
 },
 {
  "input": "For example, it would predict that a prior of 10% gets updated all the way to 100% certainty. ",
  "translatedText": "Например, оно прогнозирует, что априорное значение 10% будет обновлено до 100% уверенности. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 602.42,
  "end": 607.86
 },
 {
  "input": "But that can't be right. ",
  "translatedText": "Но это не может быть правдой. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 608.36,
  "end": 609.32
 },
 {
  "input": "In fact, take a moment to think through what the answer should be, again using a sample population. ",
  "translatedText": "На самом деле, подумайте, каким должен быть ответ, снова используя выборку населения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 610.02,
  "end": 614.5
 },
 {
  "input": "Maybe this time we picture 10 out of 100 having cancer. ",
  "translatedText": "Возможно, на этот раз мы представим, что 10 из 100 больных раком. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.06,
  "end": 617.86
 },
 {
  "input": "Again, based on the 90% sensitivity of the test, we'd expect 9 of those true cancer cases to get positive results. ",
  "translatedText": "Опять же, исходя из 90% чувствительности теста, мы ожидаем, что 9 из этих истинных случаев рака получат положительные результаты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.54,
  "end": 624.92
 },
 {
  "input": "But what about the false positives? ",
  "translatedText": "А как насчет ложных срабатываний? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 624.92,
  "end": 626.6
 },
 {
  "input": "How many do we expect there? ",
  "translatedText": "Сколько мы там ожидаем? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 626.98,
  "end": 628.1
 },
 {
  "input": "About 9% of the remaining 90, about 8. ",
  "translatedText": "Около 9% из оставшихся 90, около 8. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 629.88,
  "end": 632.62
 },
 {
  "input": "So, upon seeing a positive test result, it tells you that you're either one of these 9 true positives or one of the 8 false positives. ",
  "translatedText": "Итак, увидев положительный результат теста, он сообщит вам, что вы либо один из этих 9 истинно положительных результатов, либо один из 8 ложноположительных результатов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 633.82,
  "end": 641.14
 },
 {
  "input": "So this means the chances are a little over 50%, roughly 9 out of 17, or 53%. ",
  "translatedText": "Это означает, что шансы составляют чуть более 50%, примерно 9 из 17, или 53%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.86,
  "end": 646.92
 },
 {
  "input": "At this point, having dared to dream that Bayesian updating could look as simple as multiplication, you might tear down your hopes and pragmatically acknowledge, sometimes life is just more complicated than that. ",
  "translatedText": "В этот момент, осмелившись мечтать о том, что байесовское обновление может выглядеть так же просто, как умножение, вы можете разрушить свои надежды и прагматично признать, что иногда жизнь намного сложнее. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.02,
  "end": 657.7
 },
 {
  "input": "Except, it's not. ",
  "translatedText": "Но это не так. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 659.92,
  "end": 661.12
 },
 {
  "input": "This rule of thumb turns into a precise mathematical fact, as long as we shift away from talking about probabilities to instead talking about odds. ",
  "translatedText": "Это эмпирическое правило превращается в точный математический факт, если мы перейдем от разговоров о вероятностях к разговору о шансах. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.62,
  "end": 669.0
 },
 {
  "input": "If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1, things like that, you already know about odds. ",
  "translatedText": "Если вы когда-нибудь слышали, как кто-то говорил о шансах на событие 1 к 1 или 2 к 1 и тому подобном, вы уже знаете о шансах. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.32,
  "end": 677.06
 },
 {
  "input": "With probability, we're taking the ratio of the number of positive cases out of all possible cases, right? ",
  "translatedText": "С вероятностью мы берем соотношение количества положительных случаев из всех возможных случаев, верно? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.06,
  "end": 683.06
 },
 {
  "input": "Things like 1 in 5 or 1 in 10. ",
  "translatedText": "Такие вещи, как 1 из 5 или 1 из 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.4,
  "end": 685.28
 },
 {
  "input": "With odds, what you do is take the ratio of all positive cases to all negative cases. ",
  "translatedText": "Что касается шансов, то вы берете соотношение всех положительных случаев ко всем отрицательным случаям. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.88,
  "end": 690.32
 },
 {
  "input": "You commonly see odds written with a colon to emphasize the distinction, but it's still just a fraction, just a number. ",
  "translatedText": "Обычно вы видите, что коэффициенты пишутся через двоеточие, чтобы подчеркнуть разницу, но это все равно просто дробь, просто число. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.54,
  "end": 697.06
 },
 {
  "input": "So an event with a 50% probability would be described as having 1 to 1 odds, a 10% probability is the same as 1 to 9 odds, an 80% probability is the same as 4 to 1 odds, you get the point. ",
  "translatedText": "Таким образом, событие с вероятностью 50% будет описано как имеющее шансы 1 к 1, вероятность 10% аналогична вероятности 1 к 9, вероятность 80% равна вероятности 4 к 1, вы поняли. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 697.94,
  "end": 710.46
 },
 {
  "input": "It's the same information, it still describes the chances of a random event, but it's presented a little differently, like a different unit system. ",
  "translatedText": "Это та же информация, она по-прежнему описывает вероятность случайного события, но представлена немного иначе, как другая система единиц. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.48,
  "end": 718.34
 },
 {
  "input": "Probabilities are constrained between 0 and 1, with even chances sitting at 0.5. ",
  "translatedText": "Вероятности ограничены значениями от 0 до 1, при этом равные шансы равны 0.5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.32,
  "end": 723.68
 },
 {
  "input": "But odds range from 0 up to infinity, with even chances sitting at the number 1. ",
  "translatedText": "Но шансы варьируются от 0 до бесконечности, причем равные шансы находятся под номером 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 724.8,
  "end": 729.54
 },
 {
  "input": "The beauty here is that a completely accurate, not even approximating things way to frame Bayes' rule is to say, express your prior using odds, and then just multiply by the Bayes' factor. ",
  "translatedText": "Прелесть здесь в том, что совершенно точный, даже не приблизительный способ сформулировать правило Байеса — это выразить свои предыдущие коэффициенты, а затем просто умножить их на коэффициент Байеса. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 731.88,
  "end": 742.36
 },
 {
  "input": "Think about what the prior odds are really saying. ",
  "translatedText": "Подумайте о том, что на самом деле говорят предыдущие коэффициенты. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.44,
  "end": 745.22
 },
 {
  "input": "It's the number of people with cancer divided by the number without it. ",
  "translatedText": "Это количество людей с раком, разделенное на число людей без него. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.58,
  "end": 749.26
 },
 {
  "input": "Here, let's just write that down as a normal fraction for a moment so we can multiply it. ",
  "translatedText": "Давайте на мгновение запишем это как обычную дробь, чтобы мы могли ее умножить. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 749.7,
  "end": 753.36
 },
 {
  "input": "When you filter down just to those with positive test results, the number of people with cancer gets scaled down, scaled down by the probability of seeing a positive test result given that someone has cancer. ",
  "translatedText": "Когда вы выбираете только тех, у кого положительные результаты теста, число людей, больных раком, уменьшается, уменьшается в зависимости от вероятности увидеть положительный результат теста, учитывая, что у кого-то есть рак. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 753.36,
  "end": 764.42
 },
 {
  "input": "And then similarly, the number of people without cancer also gets scaled down, this time by the probability of seeing a positive test result, but in that case. ",
  "translatedText": "И затем аналогичным образом уменьшается число людей, не страдающих раком, на этот раз за счет вероятности увидеть положительный результат теста, но в этом случае. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 765.12,
  "end": 773.44
 },
 {
  "input": "So the ratio between these two counts, the new odds upon seeing the test, looks just like the prior odds except multiplied by this term here, which is exactly the Bayes' factor. ",
  "translatedText": "Таким образом, соотношение между этими двумя значениями, новые шансы после просмотра теста, выглядят точно так же, как и предыдущие шансы, за исключением умножения на этот член, который здесь и есть фактор Байеса. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 774.18,
  "end": 784.76
 },
 {
  "input": "Look back at our example, where the Bayes' factor was 10. ",
  "translatedText": "Вернитесь к нашему примеру, где коэффициент Байеса был равен 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.8,
  "end": 790.5
 },
 {
  "input": "And as a reminder, this came from the 90% sensitivity divided by the 9% false positive rate. ",
  "translatedText": "Напоминаем, что это результат 90% чувствительности, разделенной на 9% ложноположительных результатов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.0,
  "end": 796.56
 },
 {
  "input": "How much more likely are you to see a positive result with cancer versus without? ",
  "translatedText": "Насколько более вероятно, что вы увидите положительный результат при раке, чем при его отсутствии? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.88,
  "end": 800.74
 },
 {
  "input": "If the prior is 1%, expressed as odds, this looks like 1 to 99. ",
  "translatedText": "Если априор равен 1%, выраженному в виде шансов, это выглядит как 1 к 99. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 801.72,
  "end": 805.94
 },
 {
  "input": "So by our rule, this gets updated to 10 to 99, which if you want you could convert back to a probability. ",
  "translatedText": "Итак, по нашему правилу, это значение превращается в 10 к 99, что, если хотите, вы можете преобразовать обратно в вероятность. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 806.9,
  "end": 813.4
 },
 {
  "input": "It would be 10 divided by 10 plus 99, or about 1 in 11. ",
  "translatedText": "Это будет 10 разделить на 10 плюс 99, или примерно 1 из 11. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.66,
  "end": 817.22
 },
 {
  "input": "If instead the prior was 10%, which was the example that tripped up our rule of thumb earlier, expressed as odds, this looks like 1 to 9. ",
  "translatedText": "Если вместо этого априорное значение составляло 10% (что было примером, который нарушил наше эмпирическое правило ранее, выраженное в виде шансов), это будет выглядеть как 1 к 9. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 818.2,
  "end": 826.26
 },
 {
  "input": "By our simple rule, this gets updated to 10 to 9, which you can already read off pretty intuitively. ",
  "translatedText": "По нашему простому правилу это число превращается в 10 к 9, что вы уже можете интуитивно понять. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 826.94,
  "end": 832.44
 },
 {
  "input": "It's a little above even chances, a little above 1 to 1. ",
  "translatedText": "Шансы чуть выше равных, чуть выше 1 к 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.44,
  "end": 835.66
 },
 {
  "input": "If you prefer, you can convert it back to a probability. ",
  "translatedText": "Если хотите, вы можете преобразовать его обратно в вероятность. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 836.34,
  "end": 838.84
 },
 {
  "input": "You would write it as 10 out of 19, or about 53%. ",
  "translatedText": "Вы бы написали это как 10 из 19, или примерно 53%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.18,
  "end": 843.28
 },
 {
  "input": "And indeed, that is what we already found by thinking things through with a sample population. ",
  "translatedText": "И действительно, это то, что мы уже обнаружили, обдумывая ситуацию с выборкой населения. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.28,
  "end": 847.22
 },
 {
  "input": "Let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "Допустим, мы вернемся к распространенности в 1%, но я сделаю тест более точным. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 848.3,
  "end": 851.7
 },
 {
  "input": "Now what if I told you to imagine that the false positive rate was only 1% instead of 9%? ",
  "translatedText": "А что, если я скажу вам представить, что уровень ложноположительных результатов составляет всего 1% вместо 9%? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 852.06,
  "end": 856.64
 },
 {
  "input": "What that would mean is that our Bayes' factor is 90 instead of 10. ",
  "translatedText": "Это будет означать, что наш фактор Байеса равен 90 вместо 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 857.12,
  "end": 860.52
 },
 {
  "input": "The test is doing more work for us. ",
  "translatedText": "Тест делает для нас больше работы. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.84,
  "end": 862.46
 },
 {
  "input": "In this case, with the more accurate test, it gets updated to 90 to 99, which is a little less than even chances, something a little under 50%. ",
  "translatedText": "В этом случае при более точном тесте он становится 90 к 99, что немного меньше даже шансов, чуть меньше 50%. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 863.16,
  "end": 871.58
 },
 {
  "input": "To be more precise, you could make the conversion back to probability and work out that it's around 48%. ",
  "translatedText": "Если быть более точным, вы могли бы снова преобразовать обратно в вероятность и определить, что она составляет около 48%. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 871.58,
  "end": 877.56
 },
 {
  "input": "But honestly, if you're just going for a gut feel, it's fine to stick with the odds. ",
  "translatedText": "Но, честно говоря, если вы просто хотите интуитивно почувствовать, то вполне нормально использовать шансы. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 877.56,
  "end": 881.4
 },
 {
  "input": "Do you see what I mean about how just defining this number helps to combat potential misconceptions? ",
  "translatedText": "Вы понимаете, что я имею в виду, говоря, что простое определение этого числа помогает бороться с потенциальными заблуждениями? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.22,
  "end": 887.44
 },
 {
  "input": "For anybody who's a little hasty in connecting test accuracy directly to your probability of having a disease, it's worth emphasizing that you could administer the same test with the same accuracy to multiple different patients who all get the same exact result, but if they're coming from different contexts, that result can mean wildly different things. ",
  "translatedText": "Для тех, кто немного поторопился связать точность теста непосредственно с вероятностью наличия у вас заболевания, стоит подчеркнуть, что вы можете провести один и тот же тест с одинаковой точностью множеству разных пациентов, которые все получат одинаковый точный результат, но если они исходя из разных контекстов, этот результат может означать совершенно разные вещи. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 888.24,
  "end": 906.72
 },
 {
  "input": "However, the one thing that does stay constant in every case is the factor by which each patient's prior odds get updated. ",
  "translatedText": "Однако единственное, что остается неизменным в каждом случае, — это коэффициент, с помощью которого обновляются предыдущие шансы каждого пациента. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 906.72,
  "end": 914.66
 },
 {
  "input": "And by the way, this whole time we've been using the prevalence of the disease, which is the proportion of people in a population who have it, as a substitute for the prior, the probability of having it before you see a test. ",
  "translatedText": "И, кстати, все это время мы использовали распространенность заболевания, то есть долю людей в популяции, у которых оно есть, вместо априорной вероятности заболевания до того, как вы увидите тест. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 916.3,
  "end": 926.88
 },
 {
  "input": "However, that's not necessarily the case. ",
  "translatedText": "Однако это не обязательно так. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 927.52,
  "end": 929.46
 },
 {
  "input": "If there are other known factors, things like symptoms, or in the case of a contagious disease, things like known contacts, those also factor into the prior, and they could potentially make a huge difference. ",
  "translatedText": "Если есть другие известные факторы, такие как симптомы, или, в случае заразной болезни, такие вещи, как известные контакты, они также влияют на предшествующие события и потенциально могут иметь огромное значение. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 929.78,
  "end": 939.86
 },
 {
  "input": "As another side note, so far we've only talked about positive test results, but way more often you would be seeing a negative test result. ",
  "translatedText": "Еще одно примечание: до сих пор мы говорили только о положительных результатах теста, но гораздо чаще вы будете видеть отрицательный результат теста. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 940.76,
  "end": 947.46
 },
 {
  "input": "The logic there is completely the same, but the base factor that you compute is going to look different. ",
  "translatedText": "Логика здесь совершенно та же, но базовый коэффициент, который вы вычисляете, будет выглядеть иначе. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 948.1,
  "end": 952.32
 },
 {
  "input": "Instead, you look at the probability of seeing this negative test result with the disease versus without the disease. ",
  "translatedText": "Вместо этого вы смотрите на вероятность увидеть этот отрицательный результат теста при наличии заболевания по сравнению с отсутствием заболевания. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 952.76,
  "end": 958.64
 },
 {
  "input": "So in our cancer example, this would have been the 10% false negative rate divided by the 91% specificity, or about 1 in 9. ",
  "translatedText": "Итак, в нашем примере с раком это будет 10% ложноотрицательных результатов, разделенных на специфичность 91%, или примерно 1 из 9. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 958.64,
  "end": 967.04
 },
 {
  "input": "In other words, seeing a negative test result in that example would reduce your prior odds by about an order of magnitude. ",
  "translatedText": "Другими словами, отрицательный результат теста в этом примере уменьшит ваши предыдущие шансы примерно на порядок. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 967.78,
  "end": 974.46
 },
 {
  "input": "When you write it all out as a formula, here's how it looks. ",
  "translatedText": "Когда вы записываете все это в виде формулы, это выглядит вот как. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 975.9,
  "end": 978.42
 },
 {
  "input": "It says your odds of having a disease given a test result equals your odds before taking the test, the prior odds, times the base factor. ",
  "translatedText": "В нем говорится, что ваши шансы заболеть заболеванием, учитывая результат теста, равны вашим шансам до прохождения теста, априорным шансам, умноженным на базовый коэффициент. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.76,
  "end": 986.96
 },
 {
  "input": "Now let's contrast this with the usual way that Bayes' Rule is written, which is a bit more complicated. ",
  "translatedText": "Теперь давайте сравним это с обычным способом написания правила Байеса, который немного сложнее. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.96,
  "end": 992.26
 },
 {
  "input": "In case you haven't seen it before, it's essentially just what we were doing with sample populations, but you wrap it all up symbolically. ",
  "translatedText": "Если вы не видели этого раньше, то, по сути, это то же самое, что мы делали с выборочными совокупностями, но вы записываете все это символами. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 993.06,
  "end": 998.78
 },
 {
  "input": "Remember how every time we were counting the number of true positives and then dividing it by the sum of the true positives and the false positives? ",
  "translatedText": "Помните, как каждый раз мы подсчитывали количество истинных положительных результатов, а затем делили его на сумму истинных положительных и ложных положительных результатов? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 999.5,
  "end": 1006.26
 },
 {
  "input": "We do just that, except instead of talking about absolute amounts, we talk of each term as a proportion. ",
  "translatedText": "Мы делаем именно это, за исключением того, что вместо того, чтобы говорить об абсолютных суммах, мы говорим о каждом члене как о пропорции. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1006.8,
  "end": 1012.26
 },
 {
  "input": "So the proportion of true positives in the population comes from the prior probability of having the disease multiplied by the probability of seeing a positive test result in that case. ",
  "translatedText": "Таким образом, доля истинно положительных результатов в популяции определяется как априорная вероятность наличия заболевания, умноженная на вероятность увидеть положительный результат теста в этом случае. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1012.26,
  "end": 1022.26
 },
 {
  "input": "Then we copy that term down again into the denominator, and then the proportion of false positives comes from the prior probability of not having the disease times the probability of a positive test in that case. ",
  "translatedText": "Затем мы снова копируем этот термин в знаменатель, а затем доля ложноположительных результатов получается из априорной вероятности отсутствия заболевания, умноженной на вероятность положительного теста в этом случае. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1023.0,
  "end": 1034.1
 },
 {
  "input": "If you want, you could also write this down with words instead of symbols, if terms like sensitivity and false positive rate are more comfortable. ",
  "translatedText": "Если хотите, вы также можете записать это словами вместо символов, если вам удобнее использовать такие термины, как чувствительность и уровень ложных срабатываний. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.08,
  "end": 1040.86
 },
 {
  "input": "And this is one of those formulas where once you say it out loud it seems like a bit much, but it really is no different from what we were doing with sample populations. ",
  "translatedText": "И это одна из тех формул, когда, произнеся ее вслух, кажется, что это слишком, но на самом деле она ничем не отличается от того, что мы делали с выборочными совокупностями. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.38,
  "end": 1048.4
 },
 {
  "input": "If you wanted to make the whole thing look simpler, you often see this entire denominator written just as the probability of seeing a positive test result, overall. ",
  "translatedText": "Если вы хотите, чтобы все выглядело проще, вы часто видите весь этот знаменатель, записанный так же, как вероятность увидеть положительный результат теста в целом. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1049.22,
  "end": 1057.0
 },
 {
  "input": "While that does make for a really elegant little expression, if you intend to use this for calculations, it's a little disingenuous, because in practice, every single time you do this you need to break down that denominator into two separate parts, breaking down the cases. ",
  "translatedText": "Хотя из этого получается действительно элегантное маленькое выражение, если вы собираетесь использовать его для вычислений, это немного неискренне, потому что на практике каждый раз, когда вы это делаете, вам нужно разбить знаменатель на две отдельные части, разбивая случаи. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.98,
  "end": 1070.58
 },
 {
  "input": "So taking this more honest representation of it, let's compare our two versions of Bayes' rule. ",
  "translatedText": "Итак, взяв это более честное представление, давайте сравним две наши версии правила Байеса. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1071.7,
  "end": 1076.02
 },
 {
  "input": "And again, maybe it looks nicer if we use the words sensitivity and false positive rate. ",
  "translatedText": "И опять же, возможно, это будет выглядеть лучше, если мы будем использовать слова «чувствительность» и «коэффициент ложных срабатываний». ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1076.82,
  "end": 1080.28
 },
 {
  "input": "If nothing else, it helps emphasize which parts of the formula are coming from statistics about the test accuracy. ",
  "translatedText": "По крайней мере, это помогает подчеркнуть, какие части формулы взяты из статистики точности теста. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1080.66,
  "end": 1085.64
 },
 {
  "input": "I mean, this actually emphasizes one thing I really like about the framing with odds and a Bayes' factor, which is that it cleanly factors out the parts that have to do with the prior and the parts that have to do with the test accuracy. ",
  "translatedText": "Я имею в виду, что это на самом деле подчеркивает одну вещь, которая мне действительно нравится в построении с коэффициентами и фактором Байеса, а именно то, что он четко выделяет части, которые имеют отношение к априорному значению, и части, которые имеют отношение к точности теста. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.64,
  "end": 1095.84
 },
 {
  "input": "But over in the usual formula, all of those are very intermingled together. ",
  "translatedText": "Но в обычной формуле все это очень перемешано. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.66,
  "end": 1100.2
 },
 {
  "input": "And this has a very practical benefit. ",
  "translatedText": "И это имеет очень практическую пользу. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1100.58,
  "end": 1102.36
 },
 {
  "input": "It's really nice if you want to swap out different priors and easily see their effects. ",
  "translatedText": "Это действительно здорово, если вы хотите поменять разные априоры и легко увидеть их эффект. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.48,
  "end": 1106.26
 },
 {
  "input": "This is what we were doing earlier. ",
  "translatedText": "Это то, что мы делали раньше. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1106.6,
  "end": 1107.9
 },
 {
  "input": "But with the other formula, to do that, you have to recompute everything each time. ",
  "translatedText": "Но с другой формулой, чтобы сделать это, вам придется каждый раз все пересчитывать. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.42,
  "end": 1112.2
 },
 {
  "input": "You can't leverage a precomputed Bayes' factor the same way. ",
  "translatedText": "Вы не можете таким же образом использовать заранее рассчитанный фактор Байеса. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.38,
  "end": 1115.36
 },
 {
  "input": "The odds framing also makes things really nice if you want to do multiple different Bayesian updates based on multiple pieces of evidence. ",
  "translatedText": "Использование шансов также делает ситуацию очень удобной, если вы хотите сделать несколько различных байесовских обновлений на основе множества доказательств. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 1115.96,
  "end": 1122.12
 },
 {
  "input": "For example, let's say you took not one test, but two. ",
  "translatedText": "Например, предположим, вы сдали не один тест, а два. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.74,
  "end": 1124.86
 },
 {
  "input": "Or you wanted to think about how the presence of symptoms plays into it. ",
  "translatedText": "Или вы хотели подумать о том, как на это влияет наличие симптомов. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.36,
  "end": 1128.54
 },
 {
  "input": "For each piece of new evidence you see, you always ask the question, how much more likely would you be to see that with the disease versus without the disease? ",
  "translatedText": "При каждом новом факте, который вы видите, вы всегда задаете вопрос: насколько более вероятно, что вы увидите это при наличии заболевания, по сравнению с отсутствием заболевания? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1129.12,
  "end": 1136.62
 },
 {
  "input": "Each answer to that question gives you a new Bayes' factor, a new thing that you multiply by your odds. ",
  "translatedText": "Каждый ответ на этот вопрос дает вам новый коэффициент Байеса, новую величину, на которую вы умножаете свои шансы. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 1137.24,
  "end": 1142.0
 },
 {
  "input": "Beyond just making calculations easier, there's something I really like about attaching a number to test accuracy that doesn't even look like a probability. ",
  "translatedText": "Помимо упрощения вычислений, мне очень нравится привязывать к точности теста число, которое даже не похоже на вероятность. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.88,
  "end": 1149.92
 },
 {
  "input": "I mean, if you hear that a test has, for example, a 9% false positive rate, that's just such a disastrously ambiguous phrase. ",
  "translatedText": "Я имею в виду, если вы слышите, что тест имеет, например, 9% ложноположительных результатов, это просто катастрофически двусмысленная фраза. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1150.74,
  "end": 1157.34
 },
 {
  "input": "It's so easy to misinterpret it to mean there's a 9% chance that your positive test result is false. ",
  "translatedText": "Очень легко ошибочно истолковать это как означающее, что вероятность того, что ваш положительный результат теста окажется ложным, составляет 9%. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.78,
  "end": 1162.58
 },
 {
  "input": "But imagine if instead the number that we heard tacked on to test results was that the Bayes' factor for a positive test result is, say, 10. ",
  "translatedText": "Но представьте, если бы вместо этого к результатам теста было прикреплено число, которое, как мы слышали, было бы, скажем, байесовским фактором положительного результата теста, равным 10. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1163.3,
  "end": 1170.32
 },
 {
  "input": "There's no room to confuse that for your probability of having a disease. ",
  "translatedText": "Невозможно спутать это с вероятностью заболевания. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1170.82,
  "end": 1174.14
 },
 {
  "input": "The entire framing of what a Bayes' factor is, is that it's something that acts on a prior. ",
  "translatedText": "Вся суть того, что такое байесовский фактор, заключается в том, что он действует на априорный уровень. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1174.64,
  "end": 1179.04
 },
 {
  "input": "It forces your hand to acknowledge the prior as something that's separate entirely, and highly necessary to drawing any conclusion. ",
  "translatedText": "Это вынуждает вас признать предыдущее как нечто совершенно отдельное и крайне необходимое для того, чтобы сделать какой-либо вывод. ",
  "model": "google_nmt",
  "n_reviews": 1,
  "start": 1179.5,
  "end": 1185.44
 },
 {
  "input": "All that said, the usual formula is definitely not without its merits. ",
  "translatedText": "Тем не менее, обычная формула определенно не лишена своих достоинств. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1187.26,
  "end": 1190.74
 },
 {
  "input": "If you view it not simply as something to plug numbers into, but as an encapsulation of the sample population idea that we've been using throughout, you could very easily argue that that's actually much better for your intuition. ",
  "translatedText": "Если вы рассматриваете это не просто как нечто, во что можно вставить цифры, а как воплощение идеи выборочной совокупности, которую мы использовали повсюду, вы можете очень легко утверждать, что на самом деле это намного лучше для вашей интуиции. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1191.08,
  "end": 1201.98
 },
 {
  "input": "After all, it's what we were routinely falling back on in order to check ourselves that the Bayes' factor computation even made sense in the first place. ",
  "translatedText": "В конце концов, именно к этому мы обычно прибегали, чтобы убедиться, что вычисление коэффициента Байеса вообще имеет смысл. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1202.56,
  "end": 1209.18
 },
 {
  "input": "Like any design decision, there is no clear-cut objective best here. ",
  "translatedText": "Как и в любом дизайнерском решении, здесь нет четкой цели. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1211.6,
  "end": 1215.38
 },
 {
  "input": "But it's almost certainly the case that giving serious consideration to that question will lead you to a better understanding of Bayes' rule. ",
  "translatedText": "Но почти наверняка серьезное рассмотрение этого вопроса приведет вас к лучшему пониманию правила Байеса. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.42,
  "end": 1221.72
 },
 {
  "input": "Also, since we're on the topic of kind of paradoxical things, a friend of mine, Matt Cook, recently wrote a book all about paradoxes. ",
  "translatedText": "Кроме того, раз уж мы заговорили о парадоксальных вещах, мой друг Мэтт Кук недавно написал книгу, посвященную парадоксам. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1230.1,
  "end": 1236.12
 },
 {
  "input": "I actually contributed a small chapter to it with thoughts on the question of whether math is invented or discovered. ",
  "translatedText": "На самом деле я поместил в него небольшую главу с мыслями о том, изобретена или открыта математика. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.04,
  "end": 1241.82
 },
 {
  "input": "And the book as a whole is this really nice connection of thought-provoking paradoxical things ranging from philosophy to math and physics. ",
  "translatedText": "И книга в целом представляет собой действительно хорошее соединение заставляющих задуматься парадоксальных вещей, начиная от философии и заканчивая математикой и физикой. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1242.3,
  "end": 1248.4
 },
 {
  "input": "You can, of course, find all the details in the description. ",
  "translatedText": "Все подробности вы, конечно, можете найти в описании. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.82,
  "end": 1251.04
 }
]