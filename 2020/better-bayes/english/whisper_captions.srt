1
00:00:00,000 --> 00:00:03,140
Some of you may have heard this paradoxical fact about medical tests.

2
00:00:03,580 --> 00:00:06,740
It's very commonly used to introduce the topic of Bayes' rule in probability.

3
00:00:07,500 --> 00:00:10,800
The paradox is that you could take a test which is highly accurate,

4
00:00:11,140 --> 00:00:15,660
in the sense that it gives correct results to a large majority of the people taking it.

5
00:00:16,040 --> 00:00:22,040
And yet, under the right circumstances, when assessing the probability that your particular test result is correct,

6
00:00:22,440 --> 00:00:26,300
you can still land on a very low number, arbitrarily low, in fact.

7
00:00:26,780 --> 00:00:31,820
In short, an accurate test is not necessarily a very predictive test.

8
00:00:33,060 --> 00:00:37,440
Now when people think about math and formulas, they don't often think of it as a design process.

9
00:00:38,080 --> 00:00:41,900
I mean, maybe in the case of notation it's easy to see that different choices are possible,

10
00:00:41,960 --> 00:00:46,280
but when it comes to the structure of the formulas themselves and how we use them,

11
00:00:46,540 --> 00:00:49,680
that's something that people typically view as fixed.

12
00:00:50,680 --> 00:00:53,040
In this video, you and I will dig into this paradox,

13
00:00:53,040 --> 00:00:56,500
but instead of using it to talk about the usual version of Bayes' rule,

14
00:00:56,860 --> 00:01:00,560
I'd like to motivate an alternate version, an alternate design choice.

15
00:01:01,660 --> 00:01:04,140
Now, what's up on the screen now is a little bit abstract,

16
00:01:04,200 --> 00:01:08,080
which makes it difficult to justify that there really is a substantive difference here,

17
00:01:08,400 --> 00:01:10,540
especially when I haven't explained either one yet.

18
00:01:11,040 --> 00:01:15,360
To see what I'm talking about though, we should really start by spending some time a little more concretely,

19
00:01:15,420 --> 00:01:18,100
and just laying out what exactly this paradox is.

20
00:01:24,020 --> 00:01:27,940
Picture a thousand women and suppose that 1% of them have breast cancer.

21
00:01:28,680 --> 00:01:31,280
And let's say they all undergo a certain breast cancer screening,

22
00:01:31,840 --> 00:01:36,680
and that 9 of those with cancer correctly get positive results, and there's one false negative.

23
00:01:37,480 --> 00:01:41,920
And then suppose that among the remainder without cancer, 89 get false positives,

24
00:01:42,380 --> 00:01:44,920
and 901 correctly get negative results.

25
00:01:45,720 --> 00:01:50,160
So if all you know about a woman is that she does the screening and she gets a positive result,

26
00:01:50,160 --> 00:01:52,900
you don't have information about symptoms or anything like that,

27
00:01:53,300 --> 00:01:58,260
you know that she's either one of these 9 true positives or one of these 89 false positives.

28
00:01:59,360 --> 00:02:06,100
So the probability that she's in the cancer group given the test result is 9 divided by 9 plus 89,

29
00:02:06,300 --> 00:02:08,140
which is approximately 1 in 11.

30
00:02:09,080 --> 00:02:13,980
In medical parlance, you would call this the positive predictive value of the test, or PPV,

31
00:02:14,540 --> 00:02:18,620
the number of true positives divided by the total number of positive test results.

32
00:02:18,620 --> 00:02:20,440
You can see where the name comes from.

33
00:02:20,740 --> 00:02:25,360
To what extent does a positive test result actually predict that you have the disease?

34
00:02:26,820 --> 00:02:31,500
Now, hopefully, as I've presented it this way where we're thinking concretely about a sample population,

35
00:02:32,020 --> 00:02:33,460
all of this makes perfect sense.

36
00:02:33,960 --> 00:02:38,540
But where it comes across as counterintuitive is if you just look at the accuracy of the test,

37
00:02:38,880 --> 00:02:43,200
present it to people as a statistic, and then ask them to make judgments about their test result.

38
00:02:44,020 --> 00:02:46,260
Test accuracy is not actually one number, but two.

39
00:02:46,260 --> 00:02:51,120
First, you ask how often is the test correct on those with the disease.

40
00:02:51,700 --> 00:02:57,440
This is known as the test sensitivity, as in how sensitive is it to detecting the presence of the disease.

41
00:02:58,260 --> 00:03:01,260
In our example, test sensitivity is 9 in 10, or 90%.

42
00:03:02,020 --> 00:03:06,680
And another way to say the same fact would be to say the false negative rate is 10%.

43
00:03:06,680 --> 00:03:12,500
And then a separate, not necessarily related number is how often it's correct for those without the disease,

44
00:03:12,560 --> 00:03:14,800
which is known as the test specificity,

45
00:03:14,800 --> 00:03:22,060
as in are positive results caused specifically by the disease, or are there confounding triggers giving false positives.

46
00:03:23,080 --> 00:03:26,580
In our example, the specificity is about 91%.

47
00:03:26,580 --> 00:03:31,660
Or another way to say the same fact would be to say the false positive rate is 9%.

48
00:03:31,660 --> 00:03:36,760
So the paradox here is that in one sense, the test is over 90% accurate.

49
00:03:37,020 --> 00:03:40,660
It gives correct results to over 90% of the patients who take it.

50
00:03:40,660 --> 00:03:45,360
And yet, if you learn that someone gets a positive result without any added information,

51
00:03:45,960 --> 00:03:49,600
there's actually only a 1 in 11 chance that that particular result is accurate.

52
00:03:50,620 --> 00:03:54,440
This is a bit of a problem, because of all of the places for math to be counterintuitive,

53
00:03:55,020 --> 00:03:57,180
medical tests are one area where it matters a lot.

54
00:03:57,940 --> 00:04:04,700
In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics seminars to practicing gynecologists,

55
00:04:05,060 --> 00:04:06,800
and he opened with the following example.

56
00:04:06,800 --> 00:04:11,740
A 50-year-old woman, no symptoms, participates in a routine mammography screening.

57
00:04:12,280 --> 00:04:18,380
She tests positive, is alarmed, and wants to know from you whether she has breast cancer for certain or what her chances are.

58
00:04:18,880 --> 00:04:21,740
Apart from the screening result, you know nothing else about this woman.

59
00:04:22,580 --> 00:04:27,820
In that seminar, the doctors were then told that the prevalence of breast cancer for women of this age is about 1%,

60
00:04:27,820 --> 00:04:34,180
and then to suppose that the test sensitivity is 90% and that its specificity was 91%.

61
00:04:34,180 --> 00:04:38,180
You might notice these are exactly the same numbers from the example that you and I just looked at.

62
00:04:38,360 --> 00:04:39,440
This is where I got them.

63
00:04:39,760 --> 00:04:42,600
So, having already thought it through, you and I know the answer.

64
00:04:42,880 --> 00:04:43,840
It's about 1 in 11.

65
00:04:44,600 --> 00:04:50,320
However, the doctors in this session were not primed with the suggestion to picture a concrete sample of a thousand individuals,

66
00:04:50,520 --> 00:04:51,540
the way that you and I had.

67
00:04:52,040 --> 00:04:53,340
All they saw were these numbers.

68
00:04:54,140 --> 00:04:58,420
They were then asked, how many women who test positive actually have breast cancer?

69
00:04:58,620 --> 00:04:59,740
What is the best answer?

70
00:04:59,900 --> 00:05:01,680
And they were presented with these four choices.

71
00:05:01,680 --> 00:05:09,300
In one of the sessions, over half the doctors present said that the correct answer was 9 in 10, which is way off.

72
00:05:10,020 --> 00:05:15,380
Only a fifth of them gave the correct answer, which is worse than what it would have been if everybody had randomly guessed.

73
00:05:16,660 --> 00:05:19,280
It might seem a little extreme to be calling this a paradox.

74
00:05:19,760 --> 00:05:21,140
I mean, it's just a fact.

75
00:05:21,260 --> 00:05:23,500
It's not something intrinsically self-contradictory.

76
00:05:24,200 --> 00:05:28,220
But, as these seminars with Gigerenzer show, people, including doctors,

77
00:05:28,220 --> 00:05:34,240
definitely find it counterintuitive that a test with high accuracy can give you such a low predictive value.

78
00:05:35,200 --> 00:05:40,300
We might call this a veridical paradox, which refers to facts that are provably true,

79
00:05:40,720 --> 00:05:43,800
but which nevertheless can feel false when phrased a certain way.

80
00:05:44,300 --> 00:05:48,720
It's sort of the softest form of a paradox, saying more about human psychology than about logic.

81
00:05:49,580 --> 00:05:51,980
The question is how we can combat this.

82
00:05:53,800 --> 00:05:58,020
Where we're going with this, by the way, is that I want you to be able to look at numbers like this

83
00:05:58,020 --> 00:06:04,140
and quickly estimate in your head that it means the predictive value of a positive test should be around 1 in 11.

84
00:06:04,760 --> 00:06:09,720
Or, if I changed things and asked, what if it was 10% of the population who had breast cancer?

85
00:06:10,120 --> 00:06:14,980
You should be able to quickly turn around and say that the final answer would be a little over 50%.

86
00:06:15,920 --> 00:06:21,320
Or, if I said imagine a really low prevalence, something like 0.1% of patients having cancer,

87
00:06:21,320 --> 00:06:26,140
you should again quickly estimate that the predictive value of the test is around 1 in 100,

88
00:06:26,760 --> 00:06:30,600
that 1 in 100 of those with positive test results in that case would have cancer.

89
00:06:31,580 --> 00:06:35,240
Or, let's say we go back to the 1% prevalence, but I make the test more accurate.

90
00:06:35,440 --> 00:06:38,400
I tell you to imagine the specificity is 99%.

91
00:06:38,400 --> 00:06:43,800
There, you should be able to relatively quickly estimate that the answer is a little less than 50%.

92
00:06:44,320 --> 00:06:47,740
The hope is that you're doing all of this with minimal calculations in your head.

93
00:06:48,540 --> 00:06:54,620
Now, the goals of quick calculations might feel very different from the goals of addressing whatever misconception underlies this paradox,

94
00:06:54,880 --> 00:06:57,680
but they actually go hand in hand. Let me show you what I mean.

95
00:06:58,460 --> 00:07:03,980
On the side of addressing misconceptions, what would you tell to the people in that seminar who answered 9 and 10?

96
00:07:04,480 --> 00:07:06,900
What fundamental misconception are they revealing?

97
00:07:08,180 --> 00:07:14,580
What I might tell them is that in much the same way that you shouldn't think of tests as telling you deterministically whether you have a disease,

98
00:07:14,580 --> 00:07:18,600
you shouldn't even think of them as telling you your chances of having a disease.

99
00:07:19,560 --> 00:07:24,460
Instead, the healthy view of what tests do is that they update your chances.

100
00:07:26,040 --> 00:07:30,680
In our example, before taking the test, a patient's chances of having cancer were 1 in 100.

101
00:07:31,120 --> 00:07:33,640
In Bayesian terms, we call this the prior probability.

102
00:07:34,380 --> 00:07:40,360
The effect of this test was to update that prior by almost an order of magnitude, up to around 1 in 11.

103
00:07:41,020 --> 00:07:46,740
The accuracy of a test is telling us about the strength of this updating. It's not telling us a final answer.

104
00:07:47,900 --> 00:07:49,640
What does this have to do with quick approximations?

105
00:07:50,300 --> 00:07:54,580
Well, a key number for those approximations is something called the Bayes factor,

106
00:07:55,040 --> 00:08:01,400
and the very act of defining this number serves to reinforce this central lesson about reframing what it is the tests do.

107
00:08:02,420 --> 00:08:08,900
You see, one of the things that makes test statistics so very confusing is that there are at least 4 numbers that you'll hear associated with them.

108
00:08:08,900 --> 00:08:12,260
For those with the disease, there's the sensitivity and the false negative rate,

109
00:08:12,620 --> 00:08:15,500
and then for those without, there's the specificity and the false positive rate,

110
00:08:15,520 --> 00:08:18,800
and none of these numbers actually tell you the thing you want to know.

111
00:08:19,500 --> 00:08:25,620
Luckily, if you want to interpret a positive test result, you can pull out just one number to focus on from all this.

112
00:08:26,040 --> 00:08:28,600
Take the sensitivity divided by the false positive rate.

113
00:08:29,160 --> 00:08:34,740
In other words, how much more likely are you to see the positive test result with cancer versus without?

114
00:08:34,740 --> 00:08:41,720
In our example, this number is 10. This is the Bayes factor, also sometimes called the likelihood ratio.

115
00:08:43,100 --> 00:08:50,020
A very handy rule of thumb is that to update a small prior, or at least to approximate the answer, you simply multiply it by the Bayes factor.

116
00:08:50,760 --> 00:08:55,900
So in our example, where the prior was 1 in 100, you would estimate that the final answer should be around 1 in 10,

117
00:08:56,200 --> 00:08:58,820
which is in fact slightly above the true correct answer.

118
00:08:59,400 --> 00:09:05,740
So based on this rule of thumb, if I asked you what would happen if the prior from our example was instead 1 in 1000,

119
00:09:06,380 --> 00:09:11,420
you could quickly estimate that the effect of the test should be to update those chances to around 1 in 100.

120
00:09:12,360 --> 00:09:15,720
And in fact, take a moment to check yourself by thinking through a sample population.

121
00:09:16,700 --> 00:09:20,880
In this case, you might picture 10,000 patients where only 10 of them really have cancer.

122
00:09:22,140 --> 00:09:27,900
And then based on that 90% sensitivity, we would expect 9 of those cancer cases to give true positives.

123
00:09:29,000 --> 00:09:35,760
And on the other side, a 91% specificity means that 9% of those without cancer are getting false positives.

124
00:09:36,660 --> 00:09:41,860
So we'd expect 9% of the remaining patients, which is around 900, to give false positive results.

125
00:09:42,700 --> 00:09:47,820
Here, with such a low prevalence, the false positives really do dominate the true positives.

126
00:09:47,900 --> 00:09:55,260
So the probability that a randomly chosen positive case from this population actually has cancer is only around 1%,

127
00:09:55,260 --> 00:09:57,020
just like the rule of thumb predicted.

128
00:09:58,700 --> 00:10:01,920
Now, this rule of thumb clearly cannot work for higher priors.

129
00:10:02,420 --> 00:10:07,860
For example, it would predict that a prior of 10% gets updated all the way to 100% certainty.

130
00:10:08,360 --> 00:10:09,320
But that can't be right.

131
00:10:10,020 --> 00:10:14,500
In fact, take a moment to think through what the answer should be, again, using a sample population.

132
00:10:15,060 --> 00:10:17,860
Maybe this time we picture 10 out of 100 having cancer.

133
00:10:18,540 --> 00:10:24,920
Again, based on the 90% sensitivity of the test, we'd expect 9 of those true cancer cases to get positive results.

134
00:10:24,920 --> 00:10:28,100
But what about the false positives? How many do we expect there?

135
00:10:29,880 --> 00:10:32,620
About 9% of the remaining 90. About 8.

136
00:10:33,820 --> 00:10:41,140
So, upon seeing a positive test result, it tells you that you're either one of these 9 true positives or one of the 8 false positives.

137
00:10:41,860 --> 00:10:46,920
So this means the chances are a little over 50%, roughly 9 out of 17, or 53%.

138
00:10:48,020 --> 00:10:52,500
At this point, having dared to dream that Bayesian updating could look as simple as multiplication,

139
00:10:52,500 --> 00:10:57,700
you might tear down your hopes and pragmatically acknowledge that sometimes life is just more complicated than that.

140
00:10:59,920 --> 00:11:01,120
Except it's not.

141
00:11:01,620 --> 00:11:09,000
This rule of thumb turns into a precise mathematical fact as long as we shift away from talking about probabilities to instead talking about odds.

142
00:11:10,320 --> 00:11:17,060
If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1, things like that, you already know about odds.

143
00:11:17,060 --> 00:11:25,280
With probability, we're taking the ratio of the number of positive cases out of all possible cases, right? Things like 1 in 5 or 1 in 10.

144
00:11:25,880 --> 00:11:30,320
With odds, what you do is take the ratio of all positive cases to all negative cases.

145
00:11:31,540 --> 00:11:37,060
You commonly see odds written with a colon to emphasize the distinction, but it's still just a fraction, just a number.

146
00:11:37,940 --> 00:11:42,520
So an event with a 50% probability would be described as having 1 to 1 odds.

147
00:11:42,520 --> 00:11:50,460
A 10% probability is the same as 1 to 9 odds. An 80% probability is the same as 4 to 1 odds. You get the point.

148
00:11:51,480 --> 00:11:58,340
It's the same information. It still describes the chances of a random event, but it's presented a little differently, like a different unit system.

149
00:11:59,320 --> 00:12:03,680
Probabilities are constrained between 0 and 1, with even chances sitting at 0.5.

150
00:12:04,800 --> 00:12:09,540
But odds range from 0 up to infinity, with even chances sitting at the number 1.

151
00:12:11,880 --> 00:12:22,360
The beauty here is that a completely accurate, not even approximating things way to frame Bayes' rule is to say, express your prior using odds, and then just multiply by the Bayes' factor.

152
00:12:23,440 --> 00:12:29,260
Think about what the prior odds are really saying. It's the number of people with cancer divided by the number without it.

153
00:12:29,700 --> 00:12:33,360
Here, let's just write that down as a normal fraction for a moment so we can multiply it.

154
00:12:33,360 --> 00:12:39,520
When you filter down just to those with positive test results, the number of people with cancer gets scaled down,

155
00:12:39,780 --> 00:12:44,420
scaled down by the probability of seeing a positive test result given that someone has cancer.

156
00:12:45,120 --> 00:12:53,440
And then similarly, the number of people without cancer also gets scaled down, this time by the probability of seeing a positive test result, but in that case.

157
00:12:54,180 --> 00:13:02,900
So the ratio between these two counts, the new odds upon seeing the test, looks just like the prior odds except multiplied by this term here,

158
00:13:02,900 --> 00:13:04,760
which is exactly the Bayes' factor.

159
00:13:07,800 --> 00:13:10,500
Look back at our example, where the Bayes' factor was 10.

160
00:13:11,000 --> 00:13:16,560
And as a reminder, this came from the 90% sensitivity divided by the 9% false positive rate.

161
00:13:16,880 --> 00:13:20,740
How much more likely are you to see a positive result with cancer versus without?

162
00:13:21,720 --> 00:13:25,940
If the prior is 1%, expressed as odds, this looks like 1 to 99.

163
00:13:26,900 --> 00:13:33,400
So by our rule, this gets updated to 10 to 99, which if you want you could convert back to a probability.

164
00:13:33,660 --> 00:13:37,220
It would be 10 divided by 10 plus 99, or about 1 in 11.

165
00:13:38,200 --> 00:13:43,060
If instead, the prior was 10%, which was the example that tripped up our rule of thumb earlier,

166
00:13:43,580 --> 00:13:46,260
expressed as odds, this looks like 1 to 9.

167
00:13:46,940 --> 00:13:52,440
By our simple rule, this gets updated to 10 to 9, which you can already read off pretty intuitively.

168
00:13:52,440 --> 00:13:55,660
It's a little above even chances, a little above 1 to 1.

169
00:13:56,340 --> 00:14:03,280
If you prefer, you can convert it back to a probability. You would write it as 10 out of 19, or about 53%.

170
00:14:03,280 --> 00:14:07,220
And indeed, that is what we already found by thinking things through with a sample population.

171
00:14:08,300 --> 00:14:11,700
Let's say we go back to the 1% prevalence, but I make the test more accurate.

172
00:14:12,060 --> 00:14:16,640
Now what if I told you to imagine that the false positive rate was only 1% instead of 9%?

173
00:14:17,120 --> 00:14:22,460
What that would mean is that our Bayes factor is 90 instead of 10. The test is doing more work for us.

174
00:14:23,160 --> 00:14:31,580
In this case, with the more accurate test, it gets updated to 90 to 99, which is a little less than even chances, something a little under 50%.

175
00:14:31,580 --> 00:14:37,560
To be more precise, you could make the conversion back to probability and work out that it's around 48%.

176
00:14:37,560 --> 00:14:41,400
But honestly, if you're just going for a gut feel, it's fine to stick with the odds.

177
00:14:42,220 --> 00:14:47,440
Do you see what I mean about how just defining this number helps to combat potential misconceptions?

178
00:14:48,240 --> 00:14:53,540
For anybody who's a little hasty in connecting test accuracy directly to your probability of having a disease,

179
00:14:54,160 --> 00:15:02,000
it's worth emphasizing that you could administer the same test with the same accuracy to multiple different patients who all get the same exact result,

180
00:15:02,500 --> 00:15:06,720
but if they're coming from different contexts, that result can mean wildly different things.

181
00:15:06,720 --> 00:15:14,660
However, the one thing that does stay constant in every case is the factor by which each patient's prior odds get updated.

182
00:15:16,300 --> 00:15:22,080
And by the way, this whole time we've been using the prevalence of the disease, which is the proportion of people in a population who have it,

183
00:15:22,320 --> 00:15:26,880
as a substitute for the prior, the probability of having it before you see a test.

184
00:15:27,520 --> 00:15:35,760
However, that's not necessarily the case. If there are other known factors, things like symptoms, or in the case of a contagious disease, things like known contacts,

185
00:15:35,760 --> 00:15:39,860
those also factor into the prior, and they could potentially make a huge difference.

186
00:15:40,760 --> 00:15:47,460
As another side note, so far we've only talked about positive test results, but way more often you would be seeing a negative test result.

187
00:15:48,100 --> 00:15:52,320
The logic there is completely the same, but the base factor that you compute is going to look different.

188
00:15:52,760 --> 00:15:58,640
Instead, you look at the probability of seeing this negative test result with the disease versus without the disease.

189
00:15:58,640 --> 00:16:07,040
So in our cancer example, this would have been the 10% false negative rate divided by the 91% specificity, or about 1 in 9.

190
00:16:07,780 --> 00:16:14,460
In other words, seeing a negative test result in that example would reduce your prior odds by about an order of magnitude.

191
00:16:15,900 --> 00:16:18,420
When you write it all out as a formula, here's how it looks.

192
00:16:18,760 --> 00:16:26,960
It says your odds of having a disease given a test result equals your odds before taking the test, the prior odds, times the base factor.

193
00:16:26,960 --> 00:16:32,260
Now let's contrast this with the usual way Bayes' rule is written, which is a bit more complicated.

194
00:16:33,060 --> 00:16:38,780
In case you haven't seen it before, it's essentially just what we were doing with sample populations, but you wrap it all up symbolically.

195
00:16:39,500 --> 00:16:46,260
Remember how every time we were counting the number of true positives and then dividing it by the sum of the true positives and the false positives?

196
00:16:46,800 --> 00:16:52,260
We do just that, except instead of talking about absolute amounts, we talk of each term as a proportion.

197
00:16:52,260 --> 00:17:02,260
So the proportion of true positives in the population comes from the prior probability of having the disease multiplied by the probability of seeing a positive test result in that case.

198
00:17:03,000 --> 00:17:14,100
Then we copy that term down again into the denominator, and then the proportion of false positives comes from the prior probability of not having the disease times the probability of a positive test in that case.

199
00:17:15,080 --> 00:17:20,860
If you want, you could also write this down with words instead of symbols, if terms like sensitivity and false positive rate are more comfortable.

200
00:17:21,380 --> 00:17:28,400
And this is one of those formulas where once you say it out loud it seems like a bit much, but it really is no different from what we were doing with sample populations.

201
00:17:29,220 --> 00:17:37,000
If you wanted to make the whole thing look simpler, you often see this entire denominator written just as the probability of seeing a positive test result, overall.

202
00:17:37,980 --> 00:17:44,140
While that does make for a really elegant little expression, if you intend to use this for calculations, it's a little disingenuous,

203
00:17:44,140 --> 00:17:50,580
because in practice, every single time you do this you need to break down that denominator into two separate parts, breaking down the cases.

204
00:17:51,700 --> 00:17:56,020
So taking this more honest representation of it, let's compare our two versions of Bayes' rule.

205
00:17:56,820 --> 00:18:00,280
And again, maybe it looks nicer if we use the words sensitivity and false positive rate.

206
00:18:00,660 --> 00:18:05,640
If nothing else, it helps emphasize which parts of the formula are coming from statistics about the test accuracy.

207
00:18:05,640 --> 00:18:10,120
I mean, this actually emphasizes one thing I really like about the framing with odds and a Bayes' factor,

208
00:18:10,580 --> 00:18:15,840
which is that it cleanly factors out the parts that have to do with the prior and the parts that have to do with the test accuracy.

209
00:18:16,660 --> 00:18:20,200
But over in the usual formula, all of those are very intermingled together.

210
00:18:20,580 --> 00:18:26,260
And this has a very practical benefit. It's really nice if you want to swap out different priors and easily see their effects.

211
00:18:26,600 --> 00:18:27,900
This is what we were doing earlier.

212
00:18:28,420 --> 00:18:32,200
But with the other formula, to do that, you have to recompute everything each time.

213
00:18:32,380 --> 00:18:35,360
You can't leverage a precomputed Bayes' factor the same way.

214
00:18:35,960 --> 00:18:42,120
The odds framing also makes things really nice if you want to do multiple different Bayesian updates based on multiple pieces of evidence.

215
00:18:42,740 --> 00:18:48,540
For example, let's say you took not one test, but two. Or you wanted to think about how the presence of symptoms plays into it.

216
00:18:49,120 --> 00:18:52,100
For each piece of new evidence you see, you always ask the question,

217
00:18:52,460 --> 00:18:56,620
how much more likely would you be to see that with the disease versus without the disease?

218
00:18:57,240 --> 00:19:02,000
Each answer to that question gives you a new Bayes' factor, a new thing that you multiply by your odds.

219
00:19:02,880 --> 00:19:09,920
Beyond just making calculations easier, there's something I really like about attaching a number to test accuracy that doesn't even look like a probability.

220
00:19:10,740 --> 00:19:17,340
I mean, if you hear that a test has, for example, a 9% false positive rate, that's just such a disastrously ambiguous phrase.

221
00:19:17,780 --> 00:19:22,580
It's so easy to misinterpret it to mean there's a 9% chance that your positive test result is false.

222
00:19:23,300 --> 00:19:30,320
But imagine if instead the number that we heard tacked on to test results was that the Bayes' factor for a positive test result is, say, 10.

223
00:19:30,820 --> 00:19:34,140
There's no room to confuse that for your probability of having a disease.

224
00:19:34,640 --> 00:19:39,040
The entire framing of what a Bayes' factor is, is that it's something that acts on a prior.

225
00:19:39,500 --> 00:19:45,440
It forces your hand to acknowledge the prior as something that's separate entirely, and highly necessary to drawing any conclusion.

226
00:19:47,260 --> 00:19:50,740
All that said, the usual formula is definitely not without its merits.

227
00:19:51,080 --> 00:19:58,100
If you view it not simply as something to plug numbers into, but as an encapsulation of the sample population idea that we've been using throughout,

228
00:19:58,100 --> 00:20:01,980
you could very easily argue that that's actually much better for your intuition.

229
00:20:02,560 --> 00:20:09,180
After all, it's what we were routinely falling back on in order to check ourselves that the Bayes' factor computation even made sense in the first place.

230
00:20:11,600 --> 00:20:15,380
Like any design decision, there is no clear-cut objective best here.

231
00:20:15,420 --> 00:20:21,720
But it's almost certainly the case that giving serious consideration to that question will lead you to a better understanding of Bayes' rule.

232
00:20:30,100 --> 00:20:36,120
Also, since we're on the topic of kind of paradoxical things, a friend of mine, Matt Cook, recently wrote a book all about paradoxes.

233
00:20:37,040 --> 00:20:41,820
I actually contributed a small chapter to it with thoughts on the question of whether math is invented or discovered.

234
00:20:42,300 --> 00:20:48,400
And the book as a whole is this really nice connection of thought-provoking paradoxical things ranging from philosophy to math and physics.

235
00:20:48,820 --> 00:20:51,040
You can, of course, find all the details in the description.

236
00:20:58,100 --> 00:21:09,700
.

