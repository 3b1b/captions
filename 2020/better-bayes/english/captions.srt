1
00:00:00,000 --> 00:00:03,140
Some of you may have heard this paradoxical fact about medical tests.

2
00:00:03,580 --> 00:00:06,740
It's very commonly used to introduce the topic of Bayes' rule in probability.

3
00:00:07,500 --> 00:00:11,079
The paradox is that you could take a test which is highly accurate, 

4
00:00:11,079 --> 00:00:15,660
in the sense that it gives correct results to a large majority of the people taking it.

5
00:00:16,040 --> 00:00:19,366
And yet, under the right circumstances, when assessing the 

6
00:00:19,366 --> 00:00:22,579
probability that your particular test result is correct, 

7
00:00:22,579 --> 00:00:26,300
you can still land on a very low number, arbitrarily low, in fact.

8
00:00:26,779 --> 00:00:31,820
In short, an accurate test is not necessarily a very predictive test.

9
00:00:33,060 --> 00:00:35,204
Now when people think about math and formulas, 

10
00:00:35,204 --> 00:00:37,440
they don't often think of it as a design process.

11
00:00:38,080 --> 00:00:42,048
I mean, maybe in the case of notation it's easy to see that different choices 

12
00:00:42,048 --> 00:00:45,915
are possible, but when it comes to the structure of the formulas themselves 

13
00:00:45,915 --> 00:00:49,680
and how we use them, that's something that people typically view as fixed.

14
00:00:50,680 --> 00:00:53,365
In this video, you and I will dig into this paradox, 

15
00:00:53,365 --> 00:00:57,013
but instead of using it to talk about the usual version of Bayes' rule, 

16
00:00:57,013 --> 00:01:00,560
I'd like to motivate an alternate version, an alternate design choice.

17
00:01:01,660 --> 00:01:04,306
Now, what's up on the screen now is a little bit abstract, 

18
00:01:04,306 --> 00:01:08,252
which makes it difficult to justify that there really is a substantive difference here, 

19
00:01:08,252 --> 00:01:10,540
especially when I haven't explained either one yet.

20
00:01:11,040 --> 00:01:14,525
To see what I'm talking about though, we should really start by spending some 

21
00:01:14,525 --> 00:01:18,100
time a little more concretely, and just laying out what exactly this paradox is.

22
00:01:24,020 --> 00:01:27,940
Picture a thousand women and suppose that 1% of them have breast cancer.

23
00:01:28,680 --> 00:01:31,959
And let's say they all undergo a certain breast cancer screening, 

24
00:01:31,959 --> 00:01:35,139
and that 9 of those with cancer correctly get positive results, 

25
00:01:35,139 --> 00:01:36,680
and there's one false negative.

26
00:01:37,480 --> 00:01:41,046
And then suppose that among the remainder without cancer, 

27
00:01:41,046 --> 00:01:44,920
89 get false positives, and 901 correctly get negative results.

28
00:01:45,720 --> 00:01:50,081
So if all you know about a woman is that she does the screening and she gets a positive 

29
00:01:50,081 --> 00:01:53,700
result, you don't have information about symptoms or anything like that, 

30
00:01:53,700 --> 00:01:57,764
you know that she's either one of these 9 true positives or one of these 89 false 

31
00:01:57,764 --> 00:01:58,260
positives.

32
00:01:59,360 --> 00:02:03,750
So the probability that she's in the cancer group given the test 

33
00:02:03,750 --> 00:02:08,139
result is 9 divided by 9 plus 89, which is approximately 1 in 11.

34
00:02:09,080 --> 00:02:13,685
In medical parlance, you would call this the positive predictive value of the test, 

35
00:02:13,685 --> 00:02:18,620
or PPV, the number of true positives divided by the total number of positive test results.

36
00:02:18,620 --> 00:02:20,440
You can see where the name comes from.

37
00:02:20,740 --> 00:02:25,360
To what extent does a positive test result actually predict that you have the disease?

38
00:02:26,820 --> 00:02:30,067
Now, hopefully, as I've presented it this way where we're thinking 

39
00:02:30,067 --> 00:02:33,460
concretely about a sample population, all of this makes perfect sense.

40
00:02:33,960 --> 00:02:37,136
But where it comes across as counterintuitive is if you just look 

41
00:02:37,136 --> 00:02:40,312
at the accuracy of the test, present it to people as a statistic, 

42
00:02:40,312 --> 00:02:43,200
and then ask them to make judgments about their test result.

43
00:02:44,020 --> 00:02:46,260
Test accuracy is not actually one number, but two.

44
00:02:46,260 --> 00:02:51,120
First, you ask how often is the test correct on those with the disease.

45
00:02:51,700 --> 00:02:54,353
This is known as the test sensitivity, as in how 

46
00:02:54,353 --> 00:02:57,440
sensitive is it to detecting the presence of the disease.

47
00:02:58,260 --> 00:03:01,260
In our example, test sensitivity is 9 in 10, or 90%.

48
00:03:02,020 --> 00:03:06,680
And another way to say the same fact would be to say the false negative rate is 10%.

49
00:03:06,680 --> 00:03:11,711
And then a separate, not necessarily related number is how often it's correct for those 

50
00:03:11,711 --> 00:03:15,199
without the disease, which is known as the test specificity, 

51
00:03:15,199 --> 00:03:18,801
as in are positive results caused specifically by the disease, 

52
00:03:18,801 --> 00:03:22,060
or are there confounding triggers giving false positives.

53
00:03:23,080 --> 00:03:26,580
In our example, the specificity is about 91%.

54
00:03:26,580 --> 00:03:31,660
Or another way to say the same fact would be to say the false positive rate is 9%.

55
00:03:31,660 --> 00:03:36,760
So the paradox here is that in one sense, the test is over 90% accurate.

56
00:03:37,020 --> 00:03:40,660
It gives correct results to over 90% of the patients who take it.

57
00:03:40,660 --> 00:03:45,396
And yet, if you learn that someone gets a positive result without any added information, 

58
00:03:45,396 --> 00:03:49,600
there's actually only a 1 in 11 chance that that particular result is accurate.

59
00:03:50,620 --> 00:03:54,837
This is a bit of a problem, because of all of the places for math to be counterintuitive, 

60
00:03:54,837 --> 00:03:57,180
medical tests are one area where it matters a lot.

61
00:03:57,940 --> 00:04:02,370
In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics 

62
00:04:02,370 --> 00:04:06,800
seminars to practicing gynecologists, and he opened with the following example.

63
00:04:06,800 --> 00:04:11,740
A 50-year-old woman, no symptoms, participates in a routine mammography screening.

64
00:04:12,280 --> 00:04:15,159
She tests positive, is alarmed, and wants to know from you 

65
00:04:15,159 --> 00:04:18,380
whether she has breast cancer for certain or what her chances are.

66
00:04:18,880 --> 00:04:21,740
Apart from the screening result, you know nothing else about this woman.

67
00:04:22,580 --> 00:04:26,427
In that seminar, the doctors were then told that the prevalence of 

68
00:04:26,427 --> 00:04:29,241
breast cancer for women of this age is about 1%, 

69
00:04:29,241 --> 00:04:34,180
and then to suppose that the test sensitivity is 90% and that its specificity was 91%.

70
00:04:34,180 --> 00:04:36,281
You might notice these are exactly the same numbers 

71
00:04:36,281 --> 00:04:38,180
from the example that you and I just looked at.

72
00:04:38,360 --> 00:04:39,440
This is where I got them.

73
00:04:39,760 --> 00:04:42,600
So, having already thought it through, you and I know the answer.

74
00:04:42,880 --> 00:04:43,840
It's about 1 in 11.

75
00:04:44,600 --> 00:04:47,981
However, the doctors in this session were not primed with the suggestion to 

76
00:04:47,981 --> 00:04:51,540
picture a concrete sample of a thousand individuals, the way that you and I had.

77
00:04:52,040 --> 00:04:53,340
All they saw were these numbers.

78
00:04:54,140 --> 00:04:58,420
They were then asked, how many women who test positive actually have breast cancer?

79
00:04:58,620 --> 00:04:59,740
What is the best answer?

80
00:04:59,900 --> 00:05:01,680
And they were presented with these four choices.

81
00:05:01,680 --> 00:05:05,321
In one of the sessions, over half the doctors present 

82
00:05:05,321 --> 00:05:09,300
said that the correct answer was 9 in 10, which is way off.

83
00:05:10,020 --> 00:05:12,656
Only a fifth of them gave the correct answer, which is worse 

84
00:05:12,656 --> 00:05:15,380
than what it would have been if everybody had randomly guessed.

85
00:05:16,660 --> 00:05:19,280
It might seem a little extreme to be calling this a paradox.

86
00:05:19,760 --> 00:05:21,140
I mean, it's just a fact.

87
00:05:21,260 --> 00:05:23,500
It's not something intrinsically self-contradictory.

88
00:05:24,200 --> 00:05:28,216
But, as these seminars with Gigerenzer show, people, including doctors, 

89
00:05:28,216 --> 00:05:33,068
definitely find it counterintuitive that a test with high accuracy can give you such a 

90
00:05:33,068 --> 00:05:34,240
low predictive value.

91
00:05:35,200 --> 00:05:40,098
We might call this a veridical paradox, which refers to facts that are provably true, 

92
00:05:40,098 --> 00:05:43,800
but which nevertheless can feel false when phrased a certain way.

93
00:05:44,300 --> 00:05:46,648
It's sort of the softest form of a paradox, saying 

94
00:05:46,648 --> 00:05:48,720
more about human psychology than about logic.

95
00:05:49,580 --> 00:05:51,980
The question is how we can combat this.

96
00:05:53,800 --> 00:05:57,246
Where we're going with this, by the way, is that I want you to be able 

97
00:05:57,246 --> 00:06:00,693
to look at numbers like this and quickly estimate in your head that it 

98
00:06:00,693 --> 00:06:04,140
means the predictive value of a positive test should be around 1 in 11.

99
00:06:04,760 --> 00:06:07,187
Or, if I changed things and asked, what if it 

100
00:06:07,187 --> 00:06:09,720
was 10% of the population who had breast cancer?

101
00:06:10,120 --> 00:06:12,574
You should be able to quickly turn around and say 

102
00:06:12,574 --> 00:06:14,980
that the final answer would be a little over 50%.

103
00:06:15,920 --> 00:06:18,504
Or, if I said imagine a really low prevalence, 

104
00:06:18,504 --> 00:06:21,088
something like 0.1% of patients having cancer, 

105
00:06:21,088 --> 00:06:25,871
you should again quickly estimate that the predictive value of the test is around 1 in 

106
00:06:25,871 --> 00:06:30,600
100, that 1 in 100 of those with positive test results in that case would have cancer.

107
00:06:31,580 --> 00:06:35,240
Or, let's say we go back to the 1% prevalence, but I make the test more accurate.

108
00:06:35,440 --> 00:06:38,400
I tell you to imagine the specificity is 99%.

109
00:06:38,400 --> 00:06:41,018
There, you should be able to relatively quickly 

110
00:06:41,018 --> 00:06:43,800
estimate that the answer is a little less than 50%.

111
00:06:44,320 --> 00:06:47,740
The hope is that you're doing all of this with minimal calculations in your head.

112
00:06:48,540 --> 00:06:52,266
Now, the goals of quick calculations might feel very different from the goals of 

113
00:06:52,266 --> 00:06:54,935
addressing whatever misconception underlies this paradox, 

114
00:06:54,935 --> 00:06:56,500
but they actually go hand in hand.

115
00:06:56,900 --> 00:06:57,680
Let me show you what I mean.

116
00:06:58,460 --> 00:07:01,220
On the side of addressing misconceptions, what would you 

117
00:07:01,220 --> 00:07:03,980
tell to the people in that seminar who answered 9 and 10?

118
00:07:04,480 --> 00:07:06,900
What fundamental misconception are they revealing?

119
00:07:08,180 --> 00:07:11,699
What I might tell them is that in much the same way that you shouldn't think 

120
00:07:11,699 --> 00:07:14,898
of tests as telling you deterministically whether you have a disease, 

121
00:07:14,898 --> 00:07:18,600
you shouldn't even think of them as telling you your chances of having a disease.

122
00:07:19,560 --> 00:07:24,460
Instead, the healthy view of what tests do is that they update your chances.

123
00:07:26,040 --> 00:07:28,691
In our example, before taking the test, a patient's 

124
00:07:28,691 --> 00:07:30,680
chances of having cancer were 1 in 100.

125
00:07:31,120 --> 00:07:33,640
In Bayesian terms, we call this the prior probability.

126
00:07:34,380 --> 00:07:39,140
The effect of this test was to update that prior by almost an order of magnitude, 

127
00:07:39,140 --> 00:07:40,360
up to around 1 in 11.

128
00:07:41,020 --> 00:07:44,820
The accuracy of a test is telling us about the strength of this updating.

129
00:07:45,120 --> 00:07:46,740
It's not telling us a final answer.

130
00:07:47,900 --> 00:07:49,640
What does this have to do with quick approximations?

131
00:07:50,300 --> 00:07:54,783
Well, a key number for those approximations is something called the Bayes factor, 

132
00:07:54,783 --> 00:07:58,392
and the very act of defining this number serves to reinforce this 

133
00:07:58,392 --> 00:08:01,400
central lesson about reframing what it is the tests do.

134
00:08:02,420 --> 00:08:05,593
You see, one of the things that makes test statistics so very confusing 

135
00:08:05,593 --> 00:08:08,900
is that there are at least 4 numbers that you'll hear associated with them.

136
00:08:08,900 --> 00:08:12,341
For those with the disease, there's the sensitivity and the false negative rate, 

137
00:08:12,341 --> 00:08:15,783
and then for those without, there's the specificity and the false positive rate, 

138
00:08:15,783 --> 00:08:18,800
and none of these numbers actually tell you the thing you want to know.

139
00:08:19,500 --> 00:08:22,533
Luckily, if you want to interpret a positive test result, 

140
00:08:22,533 --> 00:08:25,620
you can pull out just one number to focus on from all this.

141
00:08:26,040 --> 00:08:28,600
Take the sensitivity divided by the false positive rate.

142
00:08:29,160 --> 00:08:31,950
In other words, how much more likely are you to see 

143
00:08:31,950 --> 00:08:34,740
the positive test result with cancer versus without?

144
00:08:34,740 --> 00:08:37,140
In our example, this number is 10.

145
00:08:37,900 --> 00:08:41,720
This is the Bayes factor, also sometimes called the likelihood ratio.

146
00:08:43,100 --> 00:08:46,023
A very handy rule of thumb is that to update a small prior, 

147
00:08:46,023 --> 00:08:50,020
or at least to approximate the answer, you simply multiply it by the Bayes factor.

148
00:08:50,760 --> 00:08:53,056
So in our example, where the prior was 1 in 100, 

149
00:08:53,056 --> 00:08:56,195
you would estimate that the final answer should be around 1 in 10, 

150
00:08:56,195 --> 00:08:58,820
which is in fact slightly above the true correct answer.

151
00:08:59,400 --> 00:09:03,229
So based on this rule of thumb, if I asked you what would happen if the 

152
00:09:03,229 --> 00:09:07,111
prior from our example was instead 1 in 1000, you could quickly estimate 

153
00:09:07,111 --> 00:09:11,420
that the effect of the test should be to update those chances to around 1 in 100.

154
00:09:12,360 --> 00:09:15,720
And in fact, take a moment to check yourself by thinking through a sample population.

155
00:09:16,700 --> 00:09:20,880
In this case, you might picture 10,000 patients where only 10 of them really have cancer.

156
00:09:22,140 --> 00:09:24,880
And then based on that 90% sensitivity, we would 

157
00:09:24,880 --> 00:09:27,900
expect 9 of those cancer cases to give true positives.

158
00:09:29,000 --> 00:09:32,285
And on the other side, a 91% specificity means that 

159
00:09:32,285 --> 00:09:35,760
9% of those without cancer are getting false positives.

160
00:09:36,660 --> 00:09:40,198
So we'd expect 9% of the remaining patients, which is around 900, 

161
00:09:40,198 --> 00:09:41,860
to give false positive results.

162
00:09:42,700 --> 00:09:45,705
Here, with such a low prevalence, the false positives 

163
00:09:45,705 --> 00:09:47,820
really do dominate the true positives.

164
00:09:47,900 --> 00:09:52,460
So the probability that a randomly chosen positive case from this population 

165
00:09:52,460 --> 00:09:57,020
actually has cancer is only around 1%, just like the rule of thumb predicted.

166
00:09:58,699 --> 00:10:01,920
Now, this rule of thumb clearly cannot work for higher priors.

167
00:10:02,420 --> 00:10:05,110
For example, it would predict that a prior of 

168
00:10:05,110 --> 00:10:07,860
10% gets updated all the way to 100% certainty.

169
00:10:08,360 --> 00:10:09,320
But that can't be right.

170
00:10:10,020 --> 00:10:13,021
In fact, take a moment to think through what the answer should be, 

171
00:10:13,021 --> 00:10:14,500
again, using a sample population.

172
00:10:15,060 --> 00:10:17,860
Maybe this time we picture 10 out of 100 having cancer.

173
00:10:18,540 --> 00:10:21,282
Again, based on the 90% sensitivity of the test, 

174
00:10:21,282 --> 00:10:24,920
we'd expect 9 of those true cancer cases to get positive results.

175
00:10:24,920 --> 00:10:26,600
But what about the false positives?

176
00:10:26,980 --> 00:10:28,100
How many do we expect there?

177
00:10:29,880 --> 00:10:31,740
About 9% of the remaining 90.

178
00:10:32,120 --> 00:10:32,620
About 8.

179
00:10:33,820 --> 00:10:37,370
So, upon seeing a positive test result, it tells you that you're 

180
00:10:37,370 --> 00:10:41,140
either one of these 9 true positives or one of the 8 false positives.

181
00:10:41,860 --> 00:10:46,920
So this means the chances are a little over 50%, roughly 9 out of 17, or 53%.

182
00:10:48,020 --> 00:10:51,201
At this point, having dared to dream that Bayesian updating could look 

183
00:10:51,201 --> 00:10:54,697
as simple as multiplication, you might tear down your hopes and pragmatically 

184
00:10:54,697 --> 00:10:57,700
acknowledge that sometimes life is just more complicated than that.

185
00:10:59,920 --> 00:11:01,120
Except it's not.

186
00:11:01,620 --> 00:11:05,259
This rule of thumb turns into a precise mathematical fact as long as we 

187
00:11:05,259 --> 00:11:09,000
shift away from talking about probabilities to instead talking about odds.

188
00:11:10,320 --> 00:11:14,746
If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1, 

189
00:11:14,746 --> 00:11:17,060
things like that, you already know about odds.

190
00:11:17,060 --> 00:11:20,173
With probability, we're taking the ratio of the number 

191
00:11:20,173 --> 00:11:23,060
of positive cases out of all possible cases, right?

192
00:11:23,400 --> 00:11:25,280
Things like 1 in 5 or 1 in 10.

193
00:11:25,880 --> 00:11:30,320
With odds, what you do is take the ratio of all positive cases to all negative cases.

194
00:11:31,540 --> 00:11:34,926
You commonly see odds written with a colon to emphasize the distinction, 

195
00:11:34,926 --> 00:11:37,060
but it's still just a fraction, just a number.

196
00:11:37,940 --> 00:11:42,520
So an event with a 50% probability would be described as having 1 to 1 odds.

197
00:11:42,520 --> 00:11:46,160
A 10% probability is the same as 1 to 9 odds.

198
00:11:46,760 --> 00:11:49,500
An 80% probability is the same as 4 to 1 odds.

199
00:11:49,940 --> 00:11:50,460
You get the point.

200
00:11:51,480 --> 00:11:52,400
It's the same information.

201
00:11:52,740 --> 00:11:55,073
It still describes the chances of a random event, 

202
00:11:55,073 --> 00:11:58,340
but it's presented a little differently, like a different unit system.

203
00:11:59,320 --> 00:12:03,680
Probabilities are constrained between 0 and 1, with even chances sitting at 0.5.

204
00:12:04,800 --> 00:12:09,540
But odds range from 0 up to infinity, with even chances sitting at the number 1.

205
00:12:11,880 --> 00:12:14,500
The beauty here is that a completely accurate, 

206
00:12:14,500 --> 00:12:18,179
not even approximating things way to frame Bayes' rule is to say, 

207
00:12:18,179 --> 00:12:22,360
express your prior using odds, and then just multiply by the Bayes' factor.

208
00:12:23,440 --> 00:12:25,220
Think about what the prior odds are really saying.

209
00:12:25,580 --> 00:12:29,260
It's the number of people with cancer divided by the number without it.

210
00:12:29,700 --> 00:12:33,360
Here, let's just write that down as a normal fraction for a moment so we can multiply it.

211
00:12:33,360 --> 00:12:36,709
When you filter down just to those with positive test results, 

212
00:12:36,709 --> 00:12:39,421
the number of people with cancer gets scaled down, 

213
00:12:39,421 --> 00:12:43,143
scaled down by the probability of seeing a positive test result given 

214
00:12:43,143 --> 00:12:44,420
that someone has cancer.

215
00:12:45,120 --> 00:12:49,253
And then similarly, the number of people without cancer also gets scaled down, 

216
00:12:49,253 --> 00:12:53,440
this time by the probability of seeing a positive test result, but in that case.

217
00:12:54,180 --> 00:12:58,603
So the ratio between these two counts, the new odds upon seeing the test, 

218
00:12:58,603 --> 00:13:02,667
looks just like the prior odds except multiplied by this term here, 

219
00:13:02,667 --> 00:13:04,760
which is exactly the Bayes' factor.

220
00:13:07,800 --> 00:13:10,500
Look back at our example, where the Bayes' factor was 10.

221
00:13:11,000 --> 00:13:14,263
And as a reminder, this came from the 90% sensitivity 

222
00:13:14,263 --> 00:13:16,560
divided by the 9% false positive rate.

223
00:13:16,880 --> 00:13:20,740
How much more likely are you to see a positive result with cancer versus without?

224
00:13:21,720 --> 00:13:25,940
If the prior is 1%, expressed as odds, this looks like 1 to 99.

225
00:13:26,900 --> 00:13:29,809
So by our rule, this gets updated to 10 to 99, 

226
00:13:29,809 --> 00:13:33,400
which if you want you could convert back to a probability.

227
00:13:33,660 --> 00:13:37,220
It would be 10 divided by 10 plus 99, or about 1 in 11.

228
00:13:38,200 --> 00:13:42,230
If instead, the prior was 10%, which was the example that tripped up 

229
00:13:42,230 --> 00:13:46,260
our rule of thumb earlier, expressed as odds, this looks like 1 to 9.

230
00:13:46,940 --> 00:13:49,690
By our simple rule, this gets updated to 10 to 9, 

231
00:13:49,690 --> 00:13:52,440
which you can already read off pretty intuitively.

232
00:13:52,440 --> 00:13:55,660
It's a little above even chances, a little above 1 to 1.

233
00:13:56,340 --> 00:13:58,840
If you prefer, you can convert it back to a probability.

234
00:13:59,180 --> 00:14:03,280
You would write it as 10 out of 19, or about 53%.

235
00:14:03,280 --> 00:14:05,543
And indeed, that is what we already found by thinking 

236
00:14:05,543 --> 00:14:07,220
things through with a sample population.

237
00:14:08,300 --> 00:14:11,700
Let's say we go back to the 1% prevalence, but I make the test more accurate.

238
00:14:12,060 --> 00:14:16,640
Now what if I told you to imagine that the false positive rate was only 1% instead of 9%?

239
00:14:17,120 --> 00:14:20,520
What that would mean is that our Bayes factor is 90 instead of 10.

240
00:14:20,840 --> 00:14:22,460
The test is doing more work for us.

241
00:14:23,160 --> 00:14:27,399
In this case, with the more accurate test, it gets updated to 90 to 99, 

242
00:14:27,399 --> 00:14:31,580
which is a little less than even chances, something a little under 50%.

243
00:14:31,580 --> 00:14:34,454
To be more precise, you could make the conversion 

244
00:14:34,454 --> 00:14:37,560
back to probability and work out that it's around 48%.

245
00:14:37,560 --> 00:14:41,400
But honestly, if you're just going for a gut feel, it's fine to stick with the odds.

246
00:14:42,220 --> 00:14:44,934
Do you see what I mean about how just defining this 

247
00:14:44,934 --> 00:14:47,440
number helps to combat potential misconceptions?

248
00:14:48,240 --> 00:14:52,925
For anybody who's a little hasty in connecting test accuracy directly to your probability 

249
00:14:52,925 --> 00:14:57,558
of having a disease, it's worth emphasizing that you could administer the same test with 

250
00:14:57,558 --> 00:15:01,930
the same accuracy to multiple different patients who all get the same exact result, 

251
00:15:01,930 --> 00:15:04,377
but if they're coming from different contexts, 

252
00:15:04,377 --> 00:15:06,720
that result can mean wildly different things.

253
00:15:06,720 --> 00:15:10,690
However, the one thing that does stay constant in every case 

254
00:15:10,690 --> 00:15:14,660
is the factor by which each patient's prior odds get updated.

255
00:15:16,300 --> 00:15:20,061
And by the way, this whole time we've been using the prevalence of the disease, 

256
00:15:20,061 --> 00:15:23,024
which is the proportion of people in a population who have it, 

257
00:15:23,024 --> 00:15:26,880
as a substitute for the prior, the probability of having it before you see a test.

258
00:15:27,520 --> 00:15:29,460
However, that's not necessarily the case.

259
00:15:29,780 --> 00:15:32,493
If there are other known factors, things like symptoms, 

260
00:15:32,493 --> 00:15:35,789
or in the case of a contagious disease, things like known contacts, 

261
00:15:35,789 --> 00:15:39,860
those also factor into the prior, and they could potentially make a huge difference.

262
00:15:40,760 --> 00:15:44,449
As another side note, so far we've only talked about positive test results, 

263
00:15:44,449 --> 00:15:47,460
but way more often you would be seeing a negative test result.

264
00:15:48,100 --> 00:15:50,250
The logic there is completely the same, but the base 

265
00:15:50,250 --> 00:15:52,320
factor that you compute is going to look different.

266
00:15:52,760 --> 00:15:55,825
Instead, you look at the probability of seeing this negative 

267
00:15:55,825 --> 00:15:58,640
test result with the disease versus without the disease.

268
00:15:58,640 --> 00:16:02,805
So in our cancer example, this would have been the 10% false 

269
00:16:02,805 --> 00:16:07,040
negative rate divided by the 91% specificity, or about 1 in 9.

270
00:16:07,780 --> 00:16:11,174
In other words, seeing a negative test result in that example 

271
00:16:11,174 --> 00:16:14,460
would reduce your prior odds by about an order of magnitude.

272
00:16:15,900 --> 00:16:18,420
When you write it all out as a formula, here's how it looks.

273
00:16:18,760 --> 00:16:22,949
It says your odds of having a disease given a test result equals your 

274
00:16:22,949 --> 00:16:26,960
odds before taking the test, the prior odds, times the base factor.

275
00:16:26,960 --> 00:16:30,546
Now let's contrast this with the usual way Bayes' rule is written, 

276
00:16:30,546 --> 00:16:32,260
which is a bit more complicated.

277
00:16:33,060 --> 00:16:36,002
In case you haven't seen it before, it's essentially just what we were 

278
00:16:36,002 --> 00:16:38,780
doing with sample populations, but you wrap it all up symbolically.

279
00:16:39,500 --> 00:16:42,880
Remember how every time we were counting the number of true positives and 

280
00:16:42,880 --> 00:16:46,260
then dividing it by the sum of the true positives and the false positives?

281
00:16:46,800 --> 00:16:50,317
We do just that, except instead of talking about absolute amounts, 

282
00:16:50,317 --> 00:16:52,260
we talk of each term as a proportion.

283
00:16:52,260 --> 00:16:55,503
So the proportion of true positives in the population comes 

284
00:16:55,503 --> 00:16:58,746
from the prior probability of having the disease multiplied 

285
00:16:58,746 --> 00:17:02,260
by the probability of seeing a positive test result in that case.

286
00:17:03,000 --> 00:17:05,932
Then we copy that term down again into the denominator, 

287
00:17:05,932 --> 00:17:09,283
and then the proportion of false positives comes from the prior 

288
00:17:09,283 --> 00:17:13,157
probability of not having the disease times the probability of a positive 

289
00:17:13,157 --> 00:17:14,099
test in that case.

290
00:17:15,079 --> 00:17:18,049
If you want, you could also write this down with words instead of symbols, 

291
00:17:18,049 --> 00:17:20,859
if terms like sensitivity and false positive rate are more comfortable.

292
00:17:21,379 --> 00:17:24,910
And this is one of those formulas where once you say it out loud it seems like a bit 

293
00:17:24,910 --> 00:17:28,400
much, but it really is no different from what we were doing with sample populations.

294
00:17:29,220 --> 00:17:31,686
If you wanted to make the whole thing look simpler, 

295
00:17:31,686 --> 00:17:35,576
you often see this entire denominator written just as the probability of seeing a 

296
00:17:35,576 --> 00:17:37,000
positive test result, overall.

297
00:17:37,980 --> 00:17:40,795
While that does make for a really elegant little expression, 

298
00:17:40,795 --> 00:17:44,118
if you intend to use this for calculations, it's a little disingenuous, 

299
00:17:44,118 --> 00:17:47,303
because in practice, every single time you do this you need to break 

300
00:17:47,303 --> 00:17:50,580
down that denominator into two separate parts, breaking down the cases.

301
00:17:51,700 --> 00:17:53,928
So taking this more honest representation of it, 

302
00:17:53,928 --> 00:17:56,020
let's compare our two versions of Bayes' rule.

303
00:17:56,820 --> 00:18:00,280
And again, maybe it looks nicer if we use the words sensitivity and false positive rate.

304
00:18:00,660 --> 00:18:03,062
If nothing else, it helps emphasize which parts of the 

305
00:18:03,062 --> 00:18:05,640
formula are coming from statistics about the test accuracy.

306
00:18:05,640 --> 00:18:09,083
I mean, this actually emphasizes one thing I really like about the framing with 

307
00:18:09,083 --> 00:18:12,440
odds and a Bayes' factor, which is that it cleanly factors out the parts that 

308
00:18:12,440 --> 00:18:15,840
have to do with the prior and the parts that have to do with the test accuracy.

309
00:18:16,660 --> 00:18:20,200
But over in the usual formula, all of those are very intermingled together.

310
00:18:20,580 --> 00:18:22,360
And this has a very practical benefit.

311
00:18:22,480 --> 00:18:26,260
It's really nice if you want to swap out different priors and easily see their effects.

312
00:18:26,600 --> 00:18:27,900
This is what we were doing earlier.

313
00:18:28,420 --> 00:18:32,200
But with the other formula, to do that, you have to recompute everything each time.

314
00:18:32,380 --> 00:18:35,360
You can't leverage a precomputed Bayes' factor the same way.

315
00:18:35,960 --> 00:18:38,861
The odds framing also makes things really nice if you want to do 

316
00:18:38,861 --> 00:18:42,120
multiple different Bayesian updates based on multiple pieces of evidence.

317
00:18:42,740 --> 00:18:44,860
For example, let's say you took not one test, but two.

318
00:18:45,360 --> 00:18:48,540
Or you wanted to think about how the presence of symptoms plays into it.

319
00:18:49,120 --> 00:18:52,374
For each piece of new evidence you see, you always ask the question, 

320
00:18:52,374 --> 00:18:56,620
how much more likely would you be to see that with the disease versus without the disease?

321
00:18:57,240 --> 00:19:00,012
Each answer to that question gives you a new Bayes' factor, 

322
00:19:00,012 --> 00:19:02,000
a new thing that you multiply by your odds.

323
00:19:02,879 --> 00:19:06,400
Beyond just making calculations easier, there's something I really like about 

324
00:19:06,400 --> 00:19:09,920
attaching a number to test accuracy that doesn't even look like a probability.

325
00:19:10,740 --> 00:19:13,379
I mean, if you hear that a test has, for example, 

326
00:19:13,379 --> 00:19:17,340
a 9% false positive rate, that's just such a disastrously ambiguous phrase.

327
00:19:17,780 --> 00:19:20,179
It's so easy to misinterpret it to mean there's a 

328
00:19:20,179 --> 00:19:22,580
9% chance that your positive test result is false.

329
00:19:23,300 --> 00:19:26,609
But imagine if instead the number that we heard tacked on to test 

330
00:19:26,609 --> 00:19:30,320
results was that the Bayes' factor for a positive test result is, say, 10.

331
00:19:30,820 --> 00:19:34,140
There's no room to confuse that for your probability of having a disease.

332
00:19:34,640 --> 00:19:36,912
The entire framing of what a Bayes' factor is, 

333
00:19:36,912 --> 00:19:39,040
is that it's something that acts on a prior.

334
00:19:39,500 --> 00:19:43,308
It forces your hand to acknowledge the prior as something that's separate entirely, 

335
00:19:43,308 --> 00:19:45,440
and highly necessary to drawing any conclusion.

336
00:19:47,260 --> 00:19:50,740
All that said, the usual formula is definitely not without its merits.

337
00:19:51,080 --> 00:19:53,983
If you view it not simply as something to plug numbers into, 

338
00:19:53,983 --> 00:19:58,172
but as an encapsulation of the sample population idea that we've been using throughout, 

339
00:19:58,172 --> 00:20:01,980
you could very easily argue that that's actually much better for your intuition.

340
00:20:02,560 --> 00:20:05,718
After all, it's what we were routinely falling back on in order to check 

341
00:20:05,718 --> 00:20:09,180
ourselves that the Bayes' factor computation even made sense in the first place.

342
00:20:11,600 --> 00:20:15,380
Like any design decision, there is no clear-cut objective best here.

343
00:20:15,420 --> 00:20:18,502
But it's almost certainly the case that giving serious consideration 

344
00:20:18,502 --> 00:20:21,720
to that question will lead you to a better understanding of Bayes' rule.

345
00:20:30,100 --> 00:20:32,906
Also, since we're on the topic of kind of paradoxical things, 

346
00:20:32,906 --> 00:20:36,120
a friend of mine, Matt Cook, recently wrote a book all about paradoxes.

347
00:20:37,040 --> 00:20:39,450
I actually contributed a small chapter to it with thoughts 

348
00:20:39,450 --> 00:20:41,820
on the question of whether math is invented or discovered.

349
00:20:42,300 --> 00:20:45,635
And the book as a whole is this really nice connection of thought-provoking 

350
00:20:45,635 --> 00:20:48,400
paradoxical things ranging from philosophy to math and physics.

351
00:20:48,820 --> 00:20:51,040
You can, of course, find all the details in the description.

352
00:20:58,100 --> 00:20:51,040
.

