[
 {
  "input": "Some of you may have heard this paradoxical fact about medical tests. ",
  "translatedText": "আপনারা কেউ কেউ হয়তো মেডিকেল টেস্ট সম্পর্কে এই বিরোধপূর্ণ ঘটনা শুনেছেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 3.14
 },
 {
  "input": "It's very commonly used to introduce the topic of Bayes' rule in probability. ",
  "translatedText": "এটি খুব সাধারণভাবে সম্ভাব্যতার ক্ষেত্রে বেইসের নিয়মের বিষয়টি প্রবর্তন করতে ব্যবহৃত হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 3.58,
  "end": 6.74
 },
 {
  "input": "The paradox is that you could take a test which is highly accurate, in the sense that it gives correct results to a large majority of the people taking it. ",
  "translatedText": "প্যারাডক্স হল যে আপনি একটি পরীক্ষা দিতে পারেন যা অত্যন্ত নির্ভুল, এই অর্থে যে এটি গ্রহণকারী বৃহত্তর সংখ্যাগরিষ্ঠ লোকদের সঠিক ফলাফল দেয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.5,
  "end": 15.66
 },
 {
  "input": "And yet, under the right circumstances, when assessing the probability that your particular test result is correct, you can still land on a very low number, arbitrarily low, in fact. ",
  "translatedText": "এবং এখনও, সঠিক পরিস্থিতিতে, আপনার নির্দিষ্ট পরীক্ষার ফলাফল সঠিক হওয়ার সম্ভাবনার মূল্যায়ন করার সময়, আপনি এখনও খুব কম নম্বরে অবতরণ করতে পারেন, নির্বিচারে কম, বাস্তবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 16.04,
  "end": 26.3
 },
 {
  "input": "In short, an accurate test is not necessarily a very predictive test. ",
  "translatedText": "সংক্ষেপে, একটি সঠিক পরীক্ষা অগত্যা একটি খুব ভবিষ্যদ্বাণীমূলক পরীক্ষা নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.78,
  "end": 31.82
 },
 {
  "input": "Now when people think about math and formulas, they don't often think of it as a design process. ",
  "translatedText": "এখন যখন লোকেরা গণিত এবং সূত্র সম্পর্কে চিন্তা করে, তারা প্রায়শই এটিকে একটি নকশা প্রক্রিয়া হিসাবে ভাবে না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 33.06,
  "end": 37.44
 },
 {
  "input": "I mean, maybe in the case of notation it's easy to see that different choices are possible, but when it comes to the structure of the formulas themselves, and how we use them, that's something that people typically view as fixed. ",
  "translatedText": "আমি বলতে চাচ্ছি, হয়তো স্বরলিপির ক্ষেত্রে এটা দেখা সহজ যে বিভিন্ন পছন্দ করা সম্ভব, কিন্তু যখন এটি সূত্রগুলির গঠনের ক্ষেত্রে আসে এবং আমরা কীভাবে সেগুলি ব্যবহার করি, তখন এটি এমন কিছু যা লোকেরা সাধারণত স্থির হিসাবে দেখে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 38.08,
  "end": 49.68
 },
 {
  "input": "In this video, you and I will dig into this paradox, but instead of using it to talk about the usual version of Bayes' rule, I'd like to motivate an alternate version, an alternate design choice. ",
  "translatedText": "এই ভিডিওতে, আপনি এবং আমি এই প্যারাডক্সটি খনন করব, কিন্তু বেইসের নিয়মের স্বাভাবিক সংস্করণ সম্পর্কে কথা বলার জন্য এটি ব্যবহার করার পরিবর্তে, আমি একটি বিকল্প সংস্করণ, একটি বিকল্প ডিজাইন পছন্দকে অনুপ্রাণিত করতে চাই৷ এখন, স্ক্রিনে এখন যা হচ্ছে তা একটু বিমূর্ত, যা এখানে সত্যই একটি সারগর্ভ পার্থক্য রয়েছে তা সমর্থন করা কঠিন করে তোলে, বিশেষ করে যখন আমি এখনও ব্যাখ্যা করিনি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.68,
  "end": 60.56
 },
 {
  "input": "Now, what's up on the screen now is a little bit abstract, which makes it difficult to justify that there really is a substantive difference here, especially when I haven't explained either one yet. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 61.66,
  "end": 70.54
 },
 {
  "input": "To see what I'm talking about though, we should really start by spending some time a little more concretely, and just laying out what exactly this paradox is. ",
  "translatedText": "যদিও আমি কি সম্পর্কে কথা বলছি তা দেখতে, আমাদের সত্যিই কিছু সময় আরও দৃঢ়ভাবে ব্যয় করে শুরু করা উচিত এবং ঠিক এই প্যারাডক্সটি কী তা নির্ধারণ করা উচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.04,
  "end": 78.1
 },
 {
  "input": "1% of women have breast cancer Picture a thousand women and suppose that 1% of them have breast cancer. ",
  "translatedText": "1% মহিলার স্তন ক্যান্সার ছবি এক হাজার মহিলা এবং ধরুন তাদের মধ্যে 1% স্তন ক্যান্সারে আক্রান্ত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.02,
  "end": 87.94
 },
 {
  "input": "And let's say they all undergo a certain breast cancer screening, and that 9 of those with cancer correctly get positive results, and there's one false negative. ",
  "translatedText": "এবং ধরা যাক তারা সকলেই একটি নির্দিষ্ট স্তন ক্যান্সারের স্ক্রীনিং এর মধ্য দিয়ে যায়, এবং ক্যান্সারে আক্রান্তদের মধ্যে 9 জন সঠিকভাবে ইতিবাচক ফলাফল পায়, এবং একটি মিথ্যা নেতিবাচক রয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 88.68,
  "end": 96.68
 },
 {
  "input": "And then suppose that among the remainder without cancer, 89 get false positives, and 901 correctly get negative results. ",
  "translatedText": "এবং তারপর ধরুন যে ক্যান্সার ছাড়া বাকিদের মধ্যে, 89 জন মিথ্যা ইতিবাচক এবং 901 সঠিকভাবে নেতিবাচক ফলাফল পান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.48,
  "end": 104.92
 },
 {
  "input": "So if all you know about a woman is that she does the screening and she gets a positive result, you don't have information about symptoms or anything like that, you know that she's either one of these 9 true positives or one of these 89 false positives. ",
  "translatedText": "সুতরাং আপনি যদি একজন মহিলার সম্পর্কে শুধু জানেন যে তিনি স্ক্রীনিং করেন এবং তিনি একটি ইতিবাচক ফলাফল পান, আপনার কাছে উপসর্গ বা এই জাতীয় কিছু সম্পর্কে তথ্য নেই, আপনি জানেন যে তিনি এই 9টি সত্য ইতিবাচক বা এই 89টির মধ্যে একটি।মিথ্যা ইতিবাচক. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 105.72,
  "end": 118.26
 },
 {
  "input": "So the probability that she's in the cancer group given the test result is 9 divided by 9 plus 89, which is approximately 1 in 11. ",
  "translatedText": "তাই পরীক্ষার ফলাফলে তার ক্যান্সার গ্রুপে থাকার সম্ভাবনা 9 কে 9 যোগ 89 দিয়ে ভাগ করা হয়েছে, যা 11 টির মধ্যে প্রায় 1।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.36,
  "end": 128.14
 },
 {
  "input": "In medical parlance, you would call this the positive predictive value of the test, or PPV, the number of true positives divided by the total number of positive test results. ",
  "translatedText": "ডাক্তারি ভাষায়, আপনি এটিকে পরীক্ষার ইতিবাচক ভবিষ্যদ্বাণীমূলক মান, বা PPV বলবেন, প্রকৃত ইতিবাচক সংখ্যাকে ইতিবাচক পরীক্ষার ফলাফলের মোট সংখ্যা দ্বারা ভাগ করা হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.08,
  "end": 138.62
 },
 {
  "input": "You can see where the name comes from. ",
  "translatedText": "নামটি কোথা থেকে এসেছে তা আপনি দেখতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 138.62,
  "end": 140.44
 },
 {
  "input": "To what extent does a positive test result actually predict that you have the disease? ",
  "translatedText": "একটি ইতিবাচক পরীক্ষার ফলাফল আসলে কতটা ভবিষ্যদ্বাণী করে যে আপনার রোগ আছে? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.74,
  "end": 145.36
 },
 {
  "input": "Now hopefully, as I've presented it this way where we're thinking concretely about a sample population, all of this makes perfect sense. ",
  "translatedText": "এখন আশা করছি, যেমন আমি এইভাবে উপস্থাপন করেছি যেখানে আমরা একটি নমুনা জনসংখ্যা সম্পর্কে দৃঢ়ভাবে চিন্তা করছি, এই সবই নিখুঁত অর্থবোধ করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 146.82,
  "end": 153.46
 },
 {
  "input": "But where it comes across as counterintuitive is if you just look at the accuracy of the test, present it to people as a statistic, and then ask them to make judgments about their test result. ",
  "translatedText": "কিন্তু যেখানে এটি বিপরীতমুখী হিসাবে আসে তা হল আপনি যদি পরীক্ষার নির্ভুলতা দেখেন, এটিকে একটি পরিসংখ্যান হিসাবে লোকেদের কাছে উপস্থাপন করুন এবং তারপরে তাদের পরীক্ষার ফলাফল সম্পর্কে বিচার করতে বলুন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 153.96,
  "end": 163.2
 },
 {
  "input": "Test accuracy is not actually one number, but two. ",
  "translatedText": "পরীক্ষার নির্ভুলতা আসলে এক নম্বর নয়, দুই।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.02,
  "end": 166.26
 },
 {
  "input": "First, you ask, how often is a test correct on those with the disease? ",
  "translatedText": "প্রথমত, আপনি জিজ্ঞাসা করুন, রোগে আক্রান্তদের উপর কতবার পরীক্ষা করা সঠিক? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 166.26,
  "end": 171.12
 },
 {
  "input": "This is known as the test sensitivity, as in, how sensitive is it to detecting the presence of the disease? ",
  "translatedText": "এটি পরীক্ষা সংবেদনশীলতা হিসাবে পরিচিত, যেমন, রোগের উপস্থিতি সনাক্ত করার জন্য এটি কতটা সংবেদনশীল? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 171.7,
  "end": 177.44
 },
 {
  "input": "In our example, test sensitivity is 9 in 10, or 90%. ",
  "translatedText": "আমাদের উদাহরণে, পরীক্ষার সংবেদনশীলতা 10 এর মধ্যে 9 বা 90%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.26,
  "end": 181.26
 },
 {
  "input": "And another way to say the same fact would be to say the false negative rate is 10%. ",
  "translatedText": "এবং একই সত্য বলার আরেকটি উপায় হল মিথ্যা নেতিবাচক হার হল 10%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.02,
  "end": 186.68
 },
 {
  "input": "And then a separate, not necessarily related number, is how often it's correct for those without the disease, which is known as the test specificity, as in, are positive results caused specifically by the disease, or are there confounding triggers giving false positives? ",
  "translatedText": "এবং তারপরে একটি পৃথক, অগত্যা সম্পর্কিত সংখ্যা নয়, এটি যে রোগ নেই তাদের জন্য এটি কতবার সঠিক, যা পরীক্ষার নির্দিষ্টতা হিসাবে পরিচিত, যেমন, রোগের কারণে বিশেষভাবে ইতিবাচক ফলাফল হয়, নাকি বিভ্রান্তিকর ট্রিগারগুলি মিথ্যা ইতিবাচক দেয়? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.68,
  "end": 202.06
 },
 {
  "input": "In our example, the specificity is about 91%. ",
  "translatedText": "আমাদের উদাহরণে, নির্দিষ্টতা প্রায় 91%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.08,
  "end": 206.58
 },
 {
  "input": "Or, another way to say the same fact would be to say the false positive rate is 9%. ",
  "translatedText": "অথবা, একই সত্য বলার আরেকটি উপায় হল মিথ্যা ইতিবাচক হার হল 9%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.58,
  "end": 211.66
 },
 {
  "input": "So the paradox here is that, in one sense, the test is over 90% accurate. ",
  "translatedText": "সুতরাং এখানে প্যারাডক্স হল যে, এক অর্থে, পরীক্ষাটি 90% সঠিক।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.66,
  "end": 216.76
 },
 {
  "input": "It gives correct results to over 90% of the patients who take it. ",
  "translatedText": "এটি গ্রহণকারী রোগীদের 90% এরও বেশি সঠিক ফলাফল দেয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 217.02,
  "end": 220.66
 },
 {
  "input": "And yet, if you learn that someone gets a positive result without any added information, there's actually only a 1 in 11 chance that that particular result is accurate. ",
  "translatedText": "এবং তবুও, যদি আপনি জানতে পারেন যে কেউ কোনও অতিরিক্ত তথ্য ছাড়াই একটি ইতিবাচক ফলাফল পায়, আসলে সেই নির্দিষ্ট ফলাফলটি সঠিক হওয়ার সম্ভাবনা 11 টির মধ্যে মাত্র 1 জনের আছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.66,
  "end": 229.6
 },
 {
  "input": "This is a bit of a problem, because of all of the places for math to be counterintuitive, medical tests are one area where it matters a lot. ",
  "translatedText": "এটি একটি বিট সমস্যা, কারণ গণিতের জন্য সমস্ত জায়গার বিপরীতে, মেডিকেল পরীক্ষা এমন একটি ক্ষেত্র যেখানে এটি অনেক গুরুত্বপূর্ণ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.62,
  "end": 237.18
 },
 {
  "input": "In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics seminars to practicing gynecologists, and he opened with the following example. ",
  "translatedText": "2006 এবং 2007 সালে, মনোবিজ্ঞানী গের্ড গিগারেনজার অনুশীলনকারী গাইনোকোলজিস্টদের একটি পরিসংখ্যান সেমিনার দিয়েছিলেন এবং তিনি নিম্নলিখিত উদাহরণ দিয়ে শুরু করেছিলেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.94,
  "end": 246.8
 },
 {
  "input": "A 50-year-old woman, no symptoms, participates in a routine mammography screening. ",
  "translatedText": "একজন 50 বছর বয়সী মহিলা, কোন উপসর্গ নেই, একটি নিয়মিত ম্যামোগ্রাফি স্ক্রীনিংয়ে অংশগ্রহণ করেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.8,
  "end": 251.74
 },
 {
  "input": "She tests positive, is alarmed, and wants to know from you whether she has breast cancer for certain, or what her chances are. ",
  "translatedText": "তিনি ইতিবাচক পরীক্ষা করেছেন, শঙ্কিত, এবং তিনি আপনার কাছ থেকে জানতে চান যে তিনি নিশ্চিতভাবে স্তন ক্যান্সারে আক্রান্ত কিনা বা তার সম্ভাবনা কী।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 252.28,
  "end": 258.38
 },
 {
  "input": "Apart from the screening result, you know nothing else about this woman. ",
  "translatedText": "স্ক্রীনিং ফলাফল ছাড়া, আপনি এই মহিলা সম্পর্কে আর কিছুই জানেন না. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 258.88,
  "end": 261.74
 },
 {
  "input": "In that seminar, the doctors were then told that the prevalence of breast cancer for women of this age is about 1%, and then to suppose that the test sensitivity is 90%, and that its specificity was 91%. ",
  "translatedText": "সেই সেমিনারে, ডাক্তারদের তখন বলা হয়েছিল যে এই বয়সের মহিলাদের জন্য স্তন ক্যান্সারের প্রাদুর্ভাব প্রায় 1%, এবং তারপরে ধরুন যে পরীক্ষার সংবেদনশীলতা 90%, এবং এর নির্দিষ্টতা ছিল 91%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 262.58,
  "end": 274.18
 },
 {
  "input": "You might notice these are exactly the same numbers from the example that you and I just looked at. ",
  "translatedText": "আপনি লক্ষ্য করতে পারেন যে আপনি এবং আমি যে উদাহরণটি দেখেছি তা থেকে এইগুলি ঠিক একই সংখ্যা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.18,
  "end": 278.18
 },
 {
  "input": "This is where I got them. ",
  "translatedText": "এই যেখানে আমি তাদের পেয়েছিলাম. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 278.36,
  "end": 279.44
 },
 {
  "input": "So, having already thought it through, you and I know the answer. ",
  "translatedText": "সুতরাং, ইতিমধ্যে এটি চিন্তা করে, আপনি এবং আমি উত্তরটি জানি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 279.76,
  "end": 282.6
 },
 {
  "input": "It's about 1 in 11. ",
  "translatedText": "এটা প্রায় 11 এর মধ্যে 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.88,
  "end": 283.84
 },
 {
  "input": "However, the doctors in this session were not primed with the suggestion to picture a concrete sample of a thousand individuals, the way that you and I had. ",
  "translatedText": "যাইহোক, এই অধিবেশনে ডাক্তাররা এক হাজার ব্যক্তির একটি কংক্রিট নমুনা চিত্রিত করার পরামর্শ দিয়েছিলেন, যেভাবে আপনি এবং আমার ছিল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.6,
  "end": 291.54
 },
 {
  "input": "All they saw were these numbers. ",
  "translatedText": "তারা শুধু এই সংখ্যাগুলো দেখেছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.04,
  "end": 293.34
 },
 {
  "input": "They were then asked, how many women who test positive actually have breast cancer? ",
  "translatedText": "তখন তাদের জিজ্ঞাসা করা হয়, কতজন নারীর টেস্ট পজিটিভ আসলে স্তন ক্যান্সার হয়? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.14,
  "end": 298.42
 },
 {
  "input": "What is the best answer? ",
  "translatedText": "সেরা উত্তর কি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 298.62,
  "end": 299.74
 },
 {
  "input": "And they were presented with these four choices. ",
  "translatedText": "এবং তাদের এই চারটি পছন্দের সাথে উপস্থাপন করা হয়েছিল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.9,
  "end": 301.68
 },
 {
  "input": "In one of the sessions, over half the doctors present said that the correct answer was 9 in 10, which is way off. ",
  "translatedText": "একটি সেশনে, উপস্থিত অর্ধেকেরও বেশি ডাক্তার বলেছেন যে সঠিক উত্তরটি 10 টির মধ্যে 9টি ছিল, যা বন্ধ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.68,
  "end": 309.3
 },
 {
  "input": "Only a fifth of them gave the correct answer, which is worse than what it would have been if everybody had randomly guessed. ",
  "translatedText": "তাদের মধ্যে মাত্র এক পঞ্চমাংশ সঠিক উত্তর দিয়েছে, যা প্রত্যেকে এলোমেলোভাবে অনুমান করলে যা হতো তার চেয়েও খারাপ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.02,
  "end": 315.38
 },
 {
  "input": "It might seem a little extreme to be calling this a paradox. ",
  "translatedText": "এটাকে প্যারাডক্স বলাটা একটু চরম মনে হতে পারে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.66,
  "end": 319.28
 },
 {
  "input": "I mean, it's just a fact. ",
  "translatedText": "আমি বলতে চাচ্ছি, এটা শুধু একটি সত্য. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.76,
  "end": 321.14
 },
 {
  "input": "It's not something intrinsically self-contradictory. ",
  "translatedText": "এটা অভ্যন্তরীণভাবে স্ব-বিরোধী কিছু নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 321.26,
  "end": 323.5
 },
 {
  "input": "But, as these seminars with Gigerenzer show, people, including doctors, definitely find it counterintuitive that a test with high accuracy can give you such a low predictive value. ",
  "translatedText": "কিন্তু, Gigerenzer-এর সাথে এই সেমিনারগুলি যেমন দেখায়, ডাক্তার সহ লোকেরা অবশ্যই এটিকে বিপরীত মনে করে যে উচ্চ নির্ভুলতার সাথে একটি পরীক্ষা আপনাকে এত কম ভবিষ্যদ্বাণীমূলক মান দিতে পারে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 324.2,
  "end": 334.24
 },
 {
  "input": "We might call this a veridical paradox, which refers to facts that are provably true, but which nevertheless can feel false when phrased a certain way. ",
  "translatedText": "আমরা এটিকে একটি ভেরিডিকাল প্যারাডক্স বলতে পারি, যা এমন তথ্যগুলিকে বোঝায় যা প্রমাণিতভাবে সত্য, কিন্তু তবুও যা একটি নির্দিষ্ট উপায়ে শব্দগুচ্ছ করলে মিথ্যা মনে হতে পারে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 335.2,
  "end": 343.8
 },
 {
  "input": "It's sort of the softest form of a paradox, saying more about human psychology than about logic. ",
  "translatedText": "এটি একটি প্যারাডক্সের নরমতম রূপ, যা যুক্তির চেয়ে মানব মনোবিজ্ঞান সম্পর্কে বেশি বলে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.3,
  "end": 348.72
 },
 {
  "input": "The question is how we can combat this. ",
  "translatedText": "প্রশ্ন হল কিভাবে আমরা এর মোকাবিলা করতে পারি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 349.58,
  "end": 351.98
 },
 {
  "input": "Where we're going with this, by the way, is that I want you to be able to look at numbers like this and quickly estimate in your head that it means the predictive value of a positive test should be around 1 in 11. ",
  "translatedText": "আমরা এটির সাথে যেখানে যাচ্ছি, যাইহোক, আমি চাই যে আপনি এই জাতীয় সংখ্যাগুলি দেখতে সক্ষম হন এবং আপনার মাথায় দ্রুত অনুমান করতে পারেন যে এর অর্থ হল একটি ইতিবাচক পরীক্ষার ভবিষ্যদ্বাণীমূলক মান 11-এর মধ্যে 1 এর কাছাকাছি হওয়া উচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.8,
  "end": 364.14
 },
 {
  "input": "Or, if I changed things and asked, what if it was 10% of the population who had breast cancer? ",
  "translatedText": "অথবা, যদি আমি কিছু পরিবর্তন করি এবং জিজ্ঞাসা করি, যদি 10% জনসংখ্যার স্তন ক্যান্সার হয়? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.76,
  "end": 369.72
 },
 {
  "input": "You should be able to quickly turn around and say that the final answer would be a little over 50%. ",
  "translatedText": "আপনি দ্রুত ঘুরে ঘুরে বলতে সক্ষম হবেন যে চূড়ান্ত উত্তরটি 50% এর একটু বেশি হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.12,
  "end": 374.98
 },
 {
  "input": "Or, if I said imagine a really low prevalence, something like 0.1% of patients having cancer, you should again quickly estimate that the predictive value of the test is around 1 in 100. ",
  "translatedText": "অথবা, যদি আমি বলি সত্যিই কম প্রবণতা কল্পনা করুন, 0 এর মত কিছু।1% রোগীর ক্যান্সার আছে, আপনার আবার দ্রুত অনুমান করা উচিত যে পরীক্ষার ভবিষ্যদ্বাণীমূলক মান 100 টির মধ্যে প্রায় 1।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.92,
  "end": 386.14
 },
 {
  "input": "That 1 in 100 of those with positive test results in that case would have cancer. ",
  "translatedText": "যে ক্ষেত্রে পজিটিভ পরীক্ষার ফলাফল পাওয়া 100 জনের মধ্যে 1 জনের ক্যান্সার হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 386.76,
  "end": 390.6
 },
 {
  "input": "Or, let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "অথবা, ধরা যাক আমরা 1% প্রচলনে ফিরে যাই, কিন্তু আমি পরীক্ষাটিকে আরও নির্ভুল করি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.58,
  "end": 395.24
 },
 {
  "input": "I tell you to imagine the specificity is 99%. ",
  "translatedText": "আমি আপনাকে কল্পনা করতে বলি যে নির্দিষ্টতা হল 99%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.44,
  "end": 398.4
 },
 {
  "input": "There, you should be able to relatively quickly estimate that the answer is a little less than 50%. ",
  "translatedText": "সেখানে, আপনি তুলনামূলকভাবে দ্রুত অনুমান করতে সক্ষম হবেন যে উত্তরটি 50% এর চেয়ে কিছুটা কম।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 398.4,
  "end": 403.8
 },
 {
  "input": "The hope is that you're doing all of this with minimal calculations in your head. ",
  "translatedText": "আশা করা যায় যে আপনি আপনার মাথায় ন্যূনতম গণনার সাথে এই সব করছেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 404.32,
  "end": 407.74
 },
 {
  "input": "Now, the goals of quick calculations might feel very different from the goals of addressing whatever misconception underlies this paradox, but they actually go hand in hand. ",
  "translatedText": "এখন, দ্রুত গণনার লক্ষ্যগুলি এই প্যারাডক্সের অন্তর্গত যাই হোক না কেন ভুল ধারণার সমাধান করার লক্ষ্যগুলি থেকে খুব আলাদা মনে হতে পারে, কিন্তু তারা আসলে একসাথে চলে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.54,
  "end": 416.5
 },
 {
  "input": "Let me show you what I mean. ",
  "translatedText": "আমি কি বলতে চাইছি তা দেখান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.9,
  "end": 417.68
 },
 {
  "input": "On the side of addressing misconceptions, what would you tell to the people in that seminar who answered 9 and 10? ",
  "translatedText": "ভুল ধারণার সমাধানের দিকে, আপনি সেই সেমিনারে যারা 9 এবং 10 উত্তর দিয়েছেন তাদের কী বলবেন? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.46,
  "end": 423.98
 },
 {
  "input": "What fundamental misconception are they revealing? ",
  "translatedText": "তারা কি মৌলিক ভুল ধারণা প্রকাশ করছে? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.48,
  "end": 426.9
 },
 {
  "input": "What I might tell them is that in much the same way that you shouldn't think of tests as telling you deterministically whether you have a disease, you shouldn't even think of them as telling you your chances of having a disease. ",
  "translatedText": "আমি তাদের যা বলতে পারি তা হল যে আপনি পরীক্ষাগুলিকে আপনার রোগ আছে কিনা তা নির্ধারকভাবে বলার মতো আপনার মনে করা উচিত নয়, এমনকি আপনার রোগ হওয়ার সম্ভাবনার কথা বলে মনে করা উচিত নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.18,
  "end": 438.6
 },
 {
  "input": "Instead, the healthy view of what tests do is that they update your chances. ",
  "translatedText": "পরিবর্তে, পরীক্ষাগুলি কী করে তার স্বাস্থ্যকর দৃষ্টিভঙ্গি হ'ল তারা আপনার সম্ভাবনা আপডেট করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.56,
  "end": 444.46
 },
 {
  "input": "In our example, before taking the test, a patient's chances of having cancer were 1 in 100. ",
  "translatedText": "আমাদের উদাহরণে, পরীক্ষা করার আগে, একজন রোগীর ক্যান্সার হওয়ার সম্ভাবনা ছিল 100 জনের মধ্যে 1।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.04,
  "end": 450.68
 },
 {
  "input": "In Bayesian terms, we call this the prior probability. ",
  "translatedText": "Bayesian পরিভাষায়, আমরা এটিকে পূর্ব সম্ভাবনা বলি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 453.64
 },
 {
  "input": "The effect of this test was to update that prior by almost an order of magnitude, up to around 1 in 11. ",
  "translatedText": "এই পরীক্ষার প্রভাব ছিল প্রায় 11 টির মধ্যে 1 পর্যন্ত মাত্রার প্রায় একটি ক্রম দ্বারা এটিকে আপডেট করা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 454.38,
  "end": 460.36
 },
 {
  "input": "The accuracy of a test is telling us about the strength of this updating. ",
  "translatedText": "একটি পরীক্ষার নির্ভুলতা এই আপডেটের শক্তি সম্পর্কে আমাদের বলছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.02,
  "end": 464.82
 },
 {
  "input": "It's not telling us a final answer. ",
  "translatedText": "এটা আমাদের একটি চূড়ান্ত উত্তর বলছে না. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.12,
  "end": 466.74
 },
 {
  "input": "What does this have to do with quick approximations? ",
  "translatedText": "এই দ্রুত অনুমান সঙ্গে কি করতে হবে? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 467.9,
  "end": 469.64
 },
 {
  "input": "Well, a key number for those approximations is something called the Bayes factor, and the very act of defining this number serves to reinforce this central lesson about reframing what it is the tests do. ",
  "translatedText": "ঠিক আছে, এই অনুমানগুলির জন্য একটি মূল সংখ্যাকে বেইস ফ্যাক্টর বলা হয়, এবং এই সংখ্যাটিকে সংজ্ঞায়িত করার কাজটি পরীক্ষাগুলি কী করে তা পুনরায় ফ্রেম করার বিষয়ে এই কেন্দ্রীয় পাঠকে আরও শক্তিশালী করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.3,
  "end": 481.4
 },
 {
  "input": "You see, one of the things that makes test statistics so very confusing is that there are at least 4 numbers that you'll hear associated with them. ",
  "translatedText": "আপনি দেখুন, পরীক্ষার পরিসংখ্যানগুলিকে এত বিভ্রান্তিকর করে তোলে এমন একটি বিষয় হল যে কমপক্ষে 4টি সংখ্যা রয়েছে যা আপনি তাদের সাথে যুক্ত শুনতে পাবেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.42,
  "end": 488.9
 },
 {
  "input": "For those with the disease, there's the sensitivity and the false negative rate, and then for those without, there's the specificity and the false positive rate, and none of these numbers actually tell you the thing you want to know. ",
  "translatedText": "যাদের রোগ আছে তাদের জন্য সংবেদনশীলতা এবং মিথ্যা নেতিবাচক হার রয়েছে, এবং তারপরে যাদের নেই তাদের জন্য নির্দিষ্টতা এবং মিথ্যা ইতিবাচক হার রয়েছে এবং এই সংখ্যাগুলির মধ্যে কোনটিই আপনাকে বলতে পারে না যে আপনি জানতে চান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.9,
  "end": 498.8
 },
 {
  "input": "Luckily, if you want to interpret a positive test result, you can pull out just one number to focus on from all this. ",
  "translatedText": "সৌভাগ্যবশত, যদি আপনি একটি ইতিবাচক পরীক্ষার ফলাফল ব্যাখ্যা করতে চান, তাহলে আপনি এই সমস্ত থেকে ফোকাস করার জন্য শুধুমাত্র একটি সংখ্যা বের করতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 499.5,
  "end": 505.62
 },
 {
  "input": "Take the sensitivity divided by the false positive rate. ",
  "translatedText": "মিথ্যা ইতিবাচক হার দ্বারা বিভক্ত সংবেদনশীলতা নিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 506.04,
  "end": 508.6
 },
 {
  "input": "In other words, how much more likely are you to see the positive test result with cancer versus without? ",
  "translatedText": "অন্য কথায়, ক্যান্সার বনাম ছাড়া ইতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনা কতটা বেশি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.16,
  "end": 514.74
 },
 {
  "input": "In our example, this number is 10. ",
  "translatedText": "আমাদের উদাহরণে, এই সংখ্যাটি 10।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.74,
  "end": 517.14
 },
 {
  "input": "This is the Bayes factor, also sometimes called the likelihood ratio. ",
  "translatedText": "এটি হল বেইস ফ্যাক্টর, যাকে কখনও কখনও সম্ভাবনা অনুপাতও বলা হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.9,
  "end": 521.72
 },
 {
  "input": "A very handy rule of thumb is that to update a small prior, or at least to approximate the answer, you simply multiply it by the Bayes factor. ",
  "translatedText": "থাম্বের একটি খুব সহজ নিয়ম হল যে একটি ছোট আগে আপডেট করতে, বা কমপক্ষে উত্তরটি আনুমানিক করতে, আপনি কেবল এটিকে বেইস ফ্যাক্টর দ্বারা গুণ করুন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.1,
  "end": 530.02
 },
 {
  "input": "So in our example, where the prior was 1 in 100, you would estimate that the final answer should be around 1 in 10, which is in fact slightly above the true correct answer. ",
  "translatedText": "সুতরাং আমাদের উদাহরণে, যেখানে আগেরটি 100-এর মধ্যে 1 ছিল, আপনি অনুমান করবেন যে চূড়ান্ত উত্তরটি 10-এর মধ্যে 1-এর কাছাকাছি হওয়া উচিত, যা প্রকৃতপক্ষে সত্যিকারের সঠিক উত্তরের কিছুটা উপরে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 530.76,
  "end": 538.82
 },
 {
  "input": "So based on this rule of thumb, if I asked you what would happen if the prior from our example was instead 1 in 1000, you could quickly estimate that the effect of the test should be to update those chances to around 1 in 100. ",
  "translatedText": "তাই থাম্বের এই নিয়মের উপর ভিত্তি করে, যদি আমি আপনাকে জিজ্ঞাসা করি যে আমাদের উদাহরণের আগেরটি 1000-এর মধ্যে 1 এর পরিবর্তে হলে কী হবে, আপনি দ্রুত অনুমান করতে পারেন যে পরীক্ষার প্রভাব সেই সম্ভাবনাগুলিকে 100-এর মধ্যে 1-এ আপডেট করা উচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.4,
  "end": 551.42
 },
 {
  "input": "And in fact, take a moment to check yourself by thinking through a sample population. ",
  "translatedText": "এবং আসলে, একটি নমুনা জনসংখ্যার মাধ্যমে চিন্তা করে নিজেকে পরীক্ষা করার জন্য কিছুক্ষণ সময় নিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.36,
  "end": 555.72
 },
 {
  "input": "In this case, you might picture 10,000 patients where only 10 of them really have cancer. ",
  "translatedText": "এই ক্ষেত্রে, আপনি 10,000 রোগীর ছবি দেখতে পারেন যেখানে তাদের মধ্যে মাত্র 10 জনেরই ক্যান্সার রয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.7,
  "end": 560.88
 },
 {
  "input": "And then based on that 90% sensitivity, we would expect 9 of those cancer cases to give true positives. ",
  "translatedText": "এবং তারপরে সেই 90% সংবেদনশীলতার উপর ভিত্তি করে, আমরা সেই ক্যান্সারের ক্ষেত্রে 9টি সত্যিকারের ইতিবাচক দেওয়ার আশা করব।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 562.14,
  "end": 567.9
 },
 {
  "input": "And on the other side, a 91% specificity means that 9% of those without cancer are getting false positives. ",
  "translatedText": "এবং অন্য দিকে, একটি 91% নির্দিষ্টতার মানে হল যে 9% যাদের ক্যান্সার নেই তারা মিথ্যা পজিটিভ পাচ্ছেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.0,
  "end": 575.76
 },
 {
  "input": "So we'd expect 9% of the remaining patients, which is around 900, to give false positive results. ",
  "translatedText": "তাই আমরা আশা করব বাকি 9% রোগী, যা প্রায় 900, মিথ্যা ইতিবাচক ফলাফল দেবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 576.66,
  "end": 581.86
 },
 {
  "input": "Here, with such a low prevalence, the false positives really do dominate the true positives. ",
  "translatedText": "এখানে, এত কম প্রবণতা সহ, মিথ্যা ইতিবাচকগুলি সত্যই সত্য ইতিবাচকের উপর আধিপত্য বিস্তার করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.7,
  "end": 587.82
 },
 {
  "input": "So the probability that a randomly chosen positive case from this population actually has cancer is only around 1%, just like the rule of thumb predicted. ",
  "translatedText": "সুতরাং এই জনসংখ্যার থেকে এলোমেলোভাবে নির্বাচিত ইতিবাচক ক্ষেত্রে প্রকৃতপক্ষে ক্যান্সার হওয়ার সম্ভাবনা প্রায় 1%, ঠিক যেমনটি পূর্বাভাস দেওয়া হয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 587.9,
  "end": 597.02
 },
 {
  "input": "Now, this rule of thumb clearly cannot work for higher priors. ",
  "translatedText": "এখন, থাম্বের এই নিয়মটি স্পষ্টতই উচ্চতর পূর্বের জন্য কাজ করতে পারে না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.7,
  "end": 601.92
 },
 {
  "input": "For example, it would predict that a prior of 10% gets updated all the way to 100% certainty. ",
  "translatedText": "উদাহরণস্বরূপ, এটি ভবিষ্যদ্বাণী করবে যে 10% এর আগে 100% নিশ্চিততায় আপডেট করা হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.42,
  "end": 607.86
 },
 {
  "input": "But that can't be right. ",
  "translatedText": "কিন্তু এটা ঠিক হতে পারে না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.36,
  "end": 609.32
 },
 {
  "input": "In fact, take a moment to think through what the answer should be, again using a sample population. ",
  "translatedText": "প্রকৃতপক্ষে, একটি নমুনা জনসংখ্যা ব্যবহার করে আবার উত্তরটি কী হওয়া উচিত তা ভাবতে কিছুক্ষণ সময় নিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 610.02,
  "end": 614.5
 },
 {
  "input": "Maybe this time we picture 10 out of 100 having cancer. ",
  "translatedText": "হয়তো এবার আমরা 100 জনের মধ্যে 10 জনের ক্যানসারে আক্রান্ত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.06,
  "end": 617.86
 },
 {
  "input": "Again, based on the 90% sensitivity of the test, we'd expect 9 of those true cancer cases to get positive results. ",
  "translatedText": "আবার, পরীক্ষার 90% সংবেদনশীলতার উপর ভিত্তি করে, আমরা সেই সত্য ক্যান্সারের ক্ষেত্রে 9টি ইতিবাচক ফলাফল পাওয়ার আশা করব।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 618.54,
  "end": 624.92
 },
 {
  "input": "But what about the false positives? ",
  "translatedText": "কিন্তু মিথ্যা ইতিবাচক সম্পর্কে কি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 624.92,
  "end": 626.6
 },
 {
  "input": "How many do we expect there? ",
  "translatedText": "আমরা সেখানে কতজন আশা করি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 626.98,
  "end": 628.1
 },
 {
  "input": "About 9% of the remaining 90, about 8. ",
  "translatedText": "বাকি 90 এর প্রায় 9%, প্রায় 8. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 629.88,
  "end": 632.62
 },
 {
  "input": "So, upon seeing a positive test result, it tells you that you're either one of these 9 true positives or one of the 8 false positives. ",
  "translatedText": "সুতরাং, একটি ইতিবাচক পরীক্ষার ফলাফল দেখার পরে, এটি আপনাকে বলে যে আপনি এই 9টি সত্য ইতিবাচক বা 8টি মিথ্যা ইতিবাচকের মধ্যে একটি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 633.82,
  "end": 641.14
 },
 {
  "input": "So this means the chances are a little over 50%, roughly 9 out of 17, or 53%. ",
  "translatedText": "সুতরাং এর মানে হল সম্ভাবনা 50% এর একটু বেশি, মোটামুটি 17 এর মধ্যে 9 বা 53%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.86,
  "end": 646.92
 },
 {
  "input": "At this point, having dared to dream that Bayesian updating could look as simple as multiplication, you might tear down your hopes and pragmatically acknowledge, sometimes life is just more complicated than that. ",
  "translatedText": "এই মুহুর্তে, স্বপ্ন দেখার সাহস করে যে বায়েসিয়ান আপডেটটি গুণনের মতো সহজ দেখাতে পারে, আপনি আপনার আশাগুলি ভেঙে ফেলতে পারেন এবং বাস্তবসম্মতভাবে স্বীকার করতে পারেন, কখনও কখনও জীবন তার চেয়ে আরও জটিল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 648.02,
  "end": 657.7
 },
 {
  "input": "Except, it's not. ",
  "translatedText": "ছাড়া, এটা না. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 659.92,
  "end": 661.12
 },
 {
  "input": "This rule of thumb turns into a precise mathematical fact, as long as we shift away from talking about probabilities to instead talking about odds. ",
  "translatedText": "থাম্বের এই নিয়মটি একটি সুনির্দিষ্ট গাণিতিক সত্যে পরিণত হয়, যতক্ষণ না আমরা সম্ভাব্যতা সম্পর্কে কথা বলা থেকে দূরে সরে গিয়ে প্রতিকূলতা সম্পর্কে কথা বলি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 661.62,
  "end": 669.0
 },
 {
  "input": "If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1, things like that, you already know about odds. ",
  "translatedText": "আপনি যদি কখনও কাউকে 1 থেকে 1 বা 2 থেকে 1 হওয়ার সম্ভাবনা সম্পর্কে কথা বলতে শুনে থাকেন, এইরকম জিনিসগুলি, আপনি ইতিমধ্যেই প্রতিকূলতা সম্পর্কে জানেন৷ সম্ভাব্যতার সাথে, আমরা সম্ভাব্য সমস্ত ক্ষেত্রে ইতিবাচক মামলার সংখ্যার অনুপাত নিচ্ছি, তাই না? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 670.32,
  "end": 677.06
 },
 {
  "input": "With probability, we're taking the ratio of the number of positive cases out of all possible cases, right? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.06,
  "end": 683.06
 },
 {
  "input": "Things like 1 in 5 or 1 in 10. ",
  "translatedText": "5-এর মধ্যে 1 বা 10-এর মধ্যে 1-এর মতো জিনিস।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.4,
  "end": 685.28
 },
 {
  "input": "With odds, what you do is take the ratio of all positive cases to all negative cases. ",
  "translatedText": "প্রতিকূলতার সাথে, আপনি যা করেন তা হল সমস্ত ইতিবাচক ক্ষেত্রের অনুপাত সমস্ত নেতিবাচক ক্ষেত্রে নিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.88,
  "end": 690.32
 },
 {
  "input": "You commonly see odds written with a colon to emphasize the distinction, but it's still just a fraction, just a number. ",
  "translatedText": "আপনি সাধারণত পার্থক্যের উপর জোর দেওয়ার জন্য একটি কোলন দিয়ে লেখা মতভেদ দেখতে পান, কিন্তু এটি এখনও একটি ভগ্নাংশ, শুধুমাত্র একটি সংখ্যা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.54,
  "end": 697.06
 },
 {
  "input": "So an event with a 50% probability would be described as having 1 to 1 odds, a 10% probability is the same as 1 to 9 odds, an 80% probability is the same as 4 to 1 odds, you get the point. ",
  "translatedText": "সুতরাং একটি 50% সম্ভাব্যতা সহ একটি ঘটনাকে 1 থেকে 1 মতভেদ হিসাবে বর্ণনা করা হবে, একটি 10% সম্ভাবনা 1 থেকে 9 সম্ভাবনার সমান, একটি 80% সম্ভাবনা 4 থেকে 1 মতভেদের সমান, আপনি বিন্দু পাবেন৷ এটি একই তথ্য, এটি এখনও একটি র্যান্ডম ইভেন্টের সম্ভাবনা বর্ণনা করে, তবে এটি একটি ভিন্ন ইউনিট সিস্টেমের মতো একটু ভিন্নভাবে উপস্থাপন করা হয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 697.94,
  "end": 710.46
 },
 {
  "input": "It's the same information, it still describes the chances of a random event, but it's presented a little differently, like a different unit system. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.48,
  "end": 718.34
 },
 {
  "input": "Probabilities are constrained between 0 and 1, with even chances sitting at 0.5. ",
  "translatedText": "সম্ভাবনাগুলি 0 এবং 1-এর মধ্যে সীমাবদ্ধ, এমনকি সম্ভাবনা 0-তে বসে।5. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.32,
  "end": 723.68
 },
 {
  "input": "But odds range from 0 up to infinity, with even chances sitting at the number 1. ",
  "translatedText": "কিন্তু প্রতিকূলতার রেঞ্জ 0 থেকে অসীম পর্যন্ত, এমনকি সংখ্যা 1 এ বসার সম্ভাবনা রয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 724.8,
  "end": 729.54
 },
 {
  "input": "The beauty here is that a completely accurate, not even approximating things way to frame Bayes' rule is to say, express your prior using odds, and then just multiply by the Bayes' factor. ",
  "translatedText": "এখানে সৌন্দর্য হল যে একটি সম্পূর্ণ নির্ভুল, এমনকি আনুমানিক জিনিসগুলিকে বেইসের নিয়ম ফ্রেম করার উপায় হল বলা, আপনার পূর্বের মতভেদ ব্যবহার করে প্রকাশ করুন এবং তারপরে কেবল বেইসের ফ্যাক্টর দ্বারা গুণ করুন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 731.88,
  "end": 742.36
 },
 {
  "input": "Think about what the prior odds are really saying. ",
  "translatedText": "পূর্বের মতভেদগুলি আসলে কী বলছে তা নিয়ে ভাবুন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 743.44,
  "end": 745.22
 },
 {
  "input": "It's the number of people with cancer divided by the number without it. ",
  "translatedText": "এটি ক্যান্সারে আক্রান্ত ব্যক্তিদের সংখ্যা ছাড়া সংখ্যা দ্বারা ভাগ করা হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.58,
  "end": 749.26
 },
 {
  "input": "Here, let's just write that down as a normal fraction for a moment so we can multiply it. ",
  "translatedText": "এখানে, আসুন এটিকে একটি সাধারণ ভগ্নাংশ হিসাবে এক মুহূর্তের জন্য লিখে রাখি যাতে আমরা এটিকে গুণ করতে পারি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 749.7,
  "end": 753.36
 },
 {
  "input": "When you filter down just to those with positive test results, the number of people with cancer gets scaled down, scaled down by the probability of seeing a positive test result given that someone has cancer. ",
  "translatedText": "আপনি যখন ইতিবাচক পরীক্ষার ফলাফলের জন্য ফিল্টার ডাউন করেন, তখন ক্যান্সারে আক্রান্ত ব্যক্তিদের সংখ্যা হ্রাস পায়, কারো ক্যান্সার হয়েছে এমন একটি ইতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনা দ্বারা স্কেল করা হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 753.36,
  "end": 764.42
 },
 {
  "input": "And then similarly, the number of people without cancer also gets scaled down, this time by the probability of seeing a positive test result, but in that case. ",
  "translatedText": "এবং তারপর একইভাবে, ক্যান্সারবিহীন লোকের সংখ্যাও হ্রাস পায়, এইবার একটি ইতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনা দ্বারা, কিন্তু সেই ক্ষেত্রে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 765.12,
  "end": 773.44
 },
 {
  "input": "So the ratio between these two counts, the new odds upon seeing the test, looks just like the prior odds except multiplied by this term here, which is exactly the Bayes' factor. ",
  "translatedText": "সুতরাং এই দুটি গণনার মধ্যে অনুপাত, পরীক্ষাটি দেখার পরে নতুন মতভেদ, এখানে এই শব্দটি দ্বারা গুণিত করা ব্যতীত পূর্বের প্রতিকূলতার মতো দেখায়, যা ঠিক বেইসের ফ্যাক্টর।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 774.18,
  "end": 784.76
 },
 {
  "input": "Look back at our example, where the Bayes' factor was 10. ",
  "translatedText": "আমাদের উদাহরণের দিকে ফিরে তাকান, যেখানে বেইসের ফ্যাক্টর ছিল 10।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.8,
  "end": 790.5
 },
 {
  "input": "And as a reminder, this came from the 90% sensitivity divided by the 9% false positive rate. ",
  "translatedText": "এবং একটি অনুস্মারক হিসাবে, এটি এসেছে 90% সংবেদনশীলতা 9% মিথ্যা ইতিবাচক হার দ্বারা বিভক্ত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.0,
  "end": 796.56
 },
 {
  "input": "How much more likely are you to see a positive result with cancer versus without? ",
  "translatedText": "ক্যান্সার বনাম ছাড়া আপনি একটি ইতিবাচক ফলাফল দেখার সম্ভাবনা কত বেশি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 796.88,
  "end": 800.74
 },
 {
  "input": "If the prior is 1%, expressed as odds, this looks like 1 to 99. ",
  "translatedText": "যদি আগেরটি 1% হয়, যাকে মতভেদ হিসাবে প্রকাশ করা হয়, এটি 1 থেকে 99 এর মত দেখায়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 801.72,
  "end": 805.94
 },
 {
  "input": "So by our rule, this gets updated to 10 to 99, which if you want you could convert back to a probability. ",
  "translatedText": "সুতরাং আমাদের নিয়ম অনুসারে, এটি 10 থেকে 99-এ আপডেট হয়, যা আপনি যদি চান তবে আপনি একটি সম্ভাব্যতাতে রূপান্তর করতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.9,
  "end": 813.4
 },
 {
  "input": "It would be 10 divided by 10 plus 99, or about 1 in 11. ",
  "translatedText": "এটি 10 কে 10 যোগ 99 দ্বারা ভাগ করলে বা 11 এর মধ্যে প্রায় 1 হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 813.66,
  "end": 817.22
 },
 {
  "input": "If instead the prior was 10%, which was the example that tripped up our rule of thumb earlier, expressed as odds, this looks like 1 to 9. ",
  "translatedText": "এর পরিবর্তে যদি আগেরটি 10% হয়, যেটি এমন উদাহরণ যা আগে আমাদের থাম্বের নিয়মকে ট্রিপ করেছে, যা মতভেদ হিসাবে প্রকাশ করা হয়েছে, এটি 1 থেকে 9 এর মতো দেখায়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 818.2,
  "end": 826.26
 },
 {
  "input": "By our simple rule, this gets updated to 10 to 9, which you can already read off pretty intuitively. ",
  "translatedText": "আমাদের সাধারণ নিয়ম অনুসারে, এটি 10 থেকে 9 পর্যন্ত আপডেট হয়, যা আপনি ইতিমধ্যেই বেশ স্বজ্ঞাতভাবে পড়তে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 826.94,
  "end": 832.44
 },
 {
  "input": "It's a little above even chances, a little above 1 to 1. ",
  "translatedText": "এটি এমনকি সম্ভাবনার একটু উপরে, 1 থেকে 1 এর একটু উপরে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.44,
  "end": 835.66
 },
 {
  "input": "If you prefer, you can convert it back to a probability. ",
  "translatedText": "আপনি যদি পছন্দ করেন, আপনি এটিকে আবার সম্ভাব্যতায় রূপান্তর করতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 836.34,
  "end": 838.84
 },
 {
  "input": "You would write it as 10 out of 19, or about 53%. ",
  "translatedText": "আপনি এটি 19 এর মধ্যে 10 হিসাবে লিখবেন, বা প্রায় 53%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 839.18,
  "end": 843.28
 },
 {
  "input": "And indeed, that is what we already found by thinking things through with a sample population. ",
  "translatedText": "এবং প্রকৃতপক্ষে, যেটি আমরা ইতিমধ্যেই একটি নমুনা জনসংখ্যার মাধ্যমে চিন্তা করে খুঁজে পেয়েছি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 843.28,
  "end": 847.22
 },
 {
  "input": "Let's say we go back to the 1% prevalence, but I make the test more accurate. ",
  "translatedText": "ধরা যাক আমরা 1% প্রচলনে ফিরে যাই, কিন্তু আমি পরীক্ষাটিকে আরও নির্ভুল করি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 848.3,
  "end": 851.7
 },
 {
  "input": "Now what if I told you to imagine that the false positive rate was only 1% instead of 9%? ",
  "translatedText": "এখন যদি আমি আপনাকে কল্পনা করতে বলি যে মিথ্যা পজিটিভ হার 9% এর পরিবর্তে শুধুমাত্র 1%? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 852.06,
  "end": 856.64
 },
 {
  "input": "What that would mean is that our Bayes' factor is 90 instead of 10. ",
  "translatedText": "এর মানে কি হবে যে আমাদের Bayes এর ফ্যাক্টর 10 এর পরিবর্তে 90।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 857.12,
  "end": 860.52
 },
 {
  "input": "The test is doing more work for us. ",
  "translatedText": "পরীক্ষা আমাদের জন্য আরও কাজ করছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 860.84,
  "end": 862.46
 },
 {
  "input": "In this case, with the more accurate test, it gets updated to 90 to 99, which is a little less than even chances, something a little under 50%. ",
  "translatedText": "এই ক্ষেত্রে, আরও নির্ভুল পরীক্ষার সাথে, এটি 90 থেকে 99-এ আপডেট করা হয়, যা এমনকি সম্ভাবনার চেয়ে কিছুটা কম, 50% এর কিছু কম।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 863.16,
  "end": 871.58
 },
 {
  "input": "To be more precise, you could make the conversion back to probability and work out that it's around 48%. ",
  "translatedText": "আরও সুনির্দিষ্টভাবে বলতে গেলে, আপনি রূপান্তরটিকে সম্ভাব্যতায় ফিরিয়ে আনতে পারেন এবং কাজ করতে পারেন যে এটি প্রায় 48%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.58,
  "end": 877.56
 },
 {
  "input": "But honestly, if you're just going for a gut feel, it's fine to stick with the odds. ",
  "translatedText": "কিন্তু সত্যি বলতে, আপনি যদি শুধু একটি অন্ত্রের অনুভূতির জন্য যাচ্ছেন, তাহলে প্রতিকূলতার সাথে লেগে থাকাই ভালো।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 877.56,
  "end": 881.4
 },
 {
  "input": "Do you see what I mean about how just defining this number helps to combat potential misconceptions? ",
  "translatedText": "আপনি কি দেখতে পাচ্ছেন যে এই সংখ্যাটি কীভাবে সংজ্ঞায়িত করা সম্ভাব্য ভুল ধারণাগুলিকে মোকাবেলা করতে সহায়তা করে সে সম্পর্কে আমি কী বলতে চাইছি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.22,
  "end": 887.44
 },
 {
  "input": "For anybody who's a little hasty in connecting test accuracy directly to your probability of having a disease, it's worth emphasizing that you could administer the same test with the same accuracy to multiple different patients who all get the same exact result, but if they're coming from different contexts, that result can mean wildly different things. ",
  "translatedText": "আপনার রোগ হওয়ার সম্ভাবনার সাথে পরীক্ষার নির্ভুলতা সরাসরি সংযুক্ত করতে একটু তাড়াহুড়ো করে এমন যেকোন ব্যক্তির জন্য, এটা জোর দেওয়া মূল্যবান যে আপনি একই নির্ভুলতার সাথে একই পরীক্ষা পরিচালনা করতে পারেন একাধিক ভিন্ন রোগীর জন্য যারা সবাই একই সঠিক ফলাফল পান, কিন্তু যদি তারা বিভিন্ন প্রেক্ষাপট থেকে আসছে, সেই ফলাফলের অর্থ অনেক ভিন্ন জিনিস হতে পারে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 888.24,
  "end": 906.72
 },
 {
  "input": "However, the one thing that does stay constant in every case is the factor by which each patient's prior odds get updated. ",
  "translatedText": "যাইহোক, একটি জিনিস যা প্রতিটি ক্ষেত্রে স্থির থাকে তা হল সেই ফ্যাক্টর যার দ্বারা প্রতিটি রোগীর পূর্বের সম্ভাবনাগুলি আপডেট হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 906.72,
  "end": 914.66
 },
 {
  "input": "And by the way, this whole time we've been using the prevalence of the disease, which is the proportion of people in a population who have it, as a substitute for the prior, the probability of having it before you see a test. ",
  "translatedText": "এবং যাইহোক, এই পুরো সময় আমরা এই রোগের প্রাদুর্ভাব ব্যবহার করছি, যা একটি জনসংখ্যার লোকেদের অনুপাত যা এটি আছে, পূর্বের বিকল্প হিসাবে, আপনি একটি পরীক্ষা দেখার আগে এটি হওয়ার সম্ভাবনা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 916.3,
  "end": 926.88
 },
 {
  "input": "However, that's not necessarily the case. ",
  "translatedText": "যাইহোক, যে অগত্যা ক্ষেত্রে নয়. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 927.52,
  "end": 929.46
 },
 {
  "input": "If there are other known factors, things like symptoms, or in the case of a contagious disease, things like known contacts, those also factor into the prior, and they could potentially make a huge difference. ",
  "translatedText": "যদি অন্যান্য পরিচিত কারণগুলি থাকে, লক্ষণগুলির মতো জিনিসগুলি, বা একটি সংক্রামক রোগের ক্ষেত্রে, পরিচিত পরিচিতির মতো জিনিসগুলি, সেগুলিও পূর্বের বিষয়গুলিকে প্রভাবিত করে এবং সেগুলি সম্ভবত একটি বিশাল পার্থক্য তৈরি করতে পারে৷ অন্য সাইড নোট হিসাবে, এখন পর্যন্ত আমরা শুধুমাত্র ইতিবাচক পরীক্ষার ফলাফল সম্পর্কে কথা বলেছি, কিন্তু আরো প্রায়ই আপনি একটি নেতিবাচক পরীক্ষার ফলাফল দেখতে পাবেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 929.78,
  "end": 939.86
 },
 {
  "input": "As another side note, so far we've only talked about positive test results, but way more often you would be seeing a negative test result. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 940.76,
  "end": 947.46
 },
 {
  "input": "The logic there is completely the same, but the base factor that you compute is going to look different. ",
  "translatedText": "সেখানে যুক্তি সম্পূর্ণরূপে একই, কিন্তু আপনি গণনা যে বেস ফ্যাক্টর ভিন্ন চেহারা যাচ্ছে. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 948.1,
  "end": 952.32
 },
 {
  "input": "Instead, you look at the probability of seeing this negative test result with the disease versus without the disease. ",
  "translatedText": "পরিবর্তে, আপনি রোগ বনাম রোগ ছাড়া এই নেতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনার দিকে তাকান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 952.76,
  "end": 958.64
 },
 {
  "input": "So in our cancer example, this would have been the 10% false negative rate divided by the 91% specificity, or about 1 in 9. ",
  "translatedText": "সুতরাং আমাদের ক্যান্সারের উদাহরণে, এটি 10% মিথ্যা নেতিবাচক হারকে 91% নির্দিষ্টতার দ্বারা ভাগ করা হত, বা 9-এর মধ্যে 1টি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 958.64,
  "end": 967.04
 },
 {
  "input": "In other words, seeing a negative test result in that example would reduce your prior odds by about an order of magnitude. ",
  "translatedText": "অন্য কথায়, সেই উদাহরণে একটি নেতিবাচক পরীক্ষার ফলাফল দেখা আপনার আগের মতভেদকে প্রায় একটি ক্রম দ্বারা কমিয়ে দেবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 967.78,
  "end": 974.46
 },
 {
  "input": "When you write it all out as a formula, here's how it looks. ",
  "translatedText": "আপনি যখন এটিকে একটি সূত্র হিসাবে লেখেন, তখন এটি কেমন দেখায় তা এখানে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 975.9,
  "end": 978.42
 },
 {
  "input": "It says your odds of having a disease given a test result equals your odds before taking the test, the prior odds, times the base factor. ",
  "translatedText": "এটি বলে যে একটি পরীক্ষার ফলাফল দেওয়া হলে আপনার রোগ হওয়ার সম্ভাবনা পরীক্ষা করার আগে আপনার মতভেদ, পূর্বের মতভেদ, বেস ফ্যাক্টর গুণের সমান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.76,
  "end": 986.96
 },
 {
  "input": "Now let's contrast this with the usual way that Bayes' Rule is written, which is a bit more complicated. ",
  "translatedText": "এখন আসুন এটিকে সাধারণ উপায়ের সাথে বৈসাদৃশ্য করা যাক যা বেইসের নিয়ম লেখা হয়, যা একটু বেশি জটিল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 986.96,
  "end": 992.26
 },
 {
  "input": "In case you haven't seen it before, it's essentially just what we were doing with sample populations, but you wrap it all up symbolically. ",
  "translatedText": "যদি আপনি এটি আগে না দেখে থাকেন তবে এটি মূলত আমরা নমুনা জনসংখ্যার সাথে যা করছিলাম তা ঠিক, তবে আপনি এটি সমস্ত প্রতীকীভাবে মোড়ানো।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 993.06,
  "end": 998.78
 },
 {
  "input": "Remember how every time we were counting the number of true positives and then dividing it by the sum of the true positives and the false positives? ",
  "translatedText": "মনে রাখবেন কিভাবে প্রতিবার আমরা সত্যিকারের ধনাত্মক সংখ্যা গণনা করছিলাম এবং তারপরে সত্যিকারের ধনাত্মক এবং মিথ্যা ইতিবাচকের যোগফল দিয়ে ভাগ করছি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 999.5,
  "end": 1006.26
 },
 {
  "input": "We do just that, except instead of talking about absolute amounts, we talk of each term as a proportion. ",
  "translatedText": "আমরা ঠিক সেটাই করি, পরম পরিমাণের কথা না বলে, আমরা প্রতিটি পদকে একটি অনুপাত হিসেবে বলি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1006.8,
  "end": 1012.26
 },
 {
  "input": "So the proportion of true positives in the population comes from the prior probability of having the disease multiplied by the probability of seeing a positive test result in that case. ",
  "translatedText": "তাই জনসংখ্যার প্রকৃত ইতিবাচকের অনুপাত রোগটি হওয়ার পূর্ব সম্ভাবনা থেকে আসে যে ক্ষেত্রে একটি ইতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনা দ্বারা গুণিত হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1012.26,
  "end": 1022.26
 },
 {
  "input": "Then we copy that term down again into the denominator, and then the proportion of false positives comes from the prior probability of not having the disease times the probability of a positive test in that case. ",
  "translatedText": "তারপরে আমরা সেই শব্দটিকে আবার হর-এ কপি করি, এবং তারপরে মিথ্যা পজিটিভের অনুপাত রোগটি না হওয়ার পূর্ব সম্ভাবনা থেকে আসে সেই ক্ষেত্রে একটি ইতিবাচক পরীক্ষার সম্ভাবনার গুণ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1023.0,
  "end": 1034.1
 },
 {
  "input": "If you want, you could also write this down with words instead of symbols, if terms like sensitivity and false positive rate are more comfortable. ",
  "translatedText": "সংবেদনশীলতা এবং মিথ্যা ইতিবাচক হারের মত পদগুলি যদি আরও আরামদায়ক হয় তবে আপনি যদি চান, আপনি প্রতীকের পরিবর্তে শব্দ দিয়ে এটি লিখতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1035.08,
  "end": 1040.86
 },
 {
  "input": "And this is one of those formulas where once you say it out loud it seems like a bit much, but it really is no different from what we were doing with sample populations. ",
  "translatedText": "এবং এটি সেই সূত্রগুলির মধ্যে একটি যেখানে একবার আপনি এটিকে জোরে জোরে বললে এটি কিছুটা বেশি বলে মনে হয়, তবে আমরা নমুনা জনসংখ্যার সাথে যা করছিলাম তার থেকে এটি সত্যিই আলাদা নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1041.38,
  "end": 1048.4
 },
 {
  "input": "If you wanted to make the whole thing look simpler, you often see this entire denominator written just as the probability of seeing a positive test result, overall. ",
  "translatedText": "আপনি যদি পুরো জিনিসটিকে আরও সহজ দেখাতে চান, আপনি প্রায়শই এই সম্পূর্ণ ডিনোমিনেটরটিকে সামগ্রিকভাবে একটি ইতিবাচক পরীক্ষার ফলাফল দেখার সম্ভাবনা হিসাবে লেখা দেখতে পান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1049.22,
  "end": 1057.0
 },
 {
  "input": "While that does make for a really elegant little expression, if you intend to use this for calculations, it's a little disingenuous, because in practice, every single time you do this you need to break down that denominator into two separate parts, breaking down the cases. ",
  "translatedText": "যদিও এটি সত্যিই একটি মার্জিত সামান্য অভিব্যক্তির জন্য তৈরি করে, আপনি যদি এটিকে গণনার জন্য ব্যবহার করতে চান তবে এটি কিছুটা অযৌক্তিক, কারণ অনুশীলনে, প্রতিবার আপনি এটি করার সময় আপনাকে সেই হরকে দুটি পৃথক অংশে ভেঙ্গে ফেলতে হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1057.98,
  "end": 1070.58
 },
 {
  "input": "So taking this more honest representation of it, let's compare our two versions of Bayes' rule. ",
  "translatedText": "মামলা সুতরাং এটির আরও সৎ উপস্থাপনা গ্রহণ করে, আসুন বেইসের নিয়মের আমাদের দুটি সংস্করণ তুলনা করি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1071.7,
  "end": 1076.02
 },
 {
  "input": "And again, maybe it looks nicer if we use the words sensitivity and false positive rate. ",
  "translatedText": "এবং আবার, যদি আমরা সংবেদনশীলতা এবং মিথ্যা ইতিবাচক হার শব্দগুলি ব্যবহার করি তবে এটি আরও সুন্দর দেখায়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1076.82,
  "end": 1080.28
 },
 {
  "input": "If nothing else, it helps emphasize which parts of the formula are coming from statistics about the test accuracy. ",
  "translatedText": "অন্য কিছু না হলে, এটি পরীক্ষার নির্ভুলতা সম্পর্কে পরিসংখ্যান থেকে সূত্রের কোন অংশগুলি আসছে তা জোর দিতে সাহায্য করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1080.66,
  "end": 1085.64
 },
 {
  "input": "I mean, this actually emphasizes one thing I really like about the framing with odds and a Bayes' factor, which is that it cleanly factors out the parts that have to do with the prior and the parts that have to do with the test accuracy. ",
  "translatedText": "আমি বলতে চাচ্ছি, এটি আসলে একটি জিনিসের উপর জোর দেয় যা আমি সত্যিই মতভেদ সহ ফ্রেমিং এবং একটি বেইস ফ্যাক্টর সম্পর্কে পছন্দ করি, যা হল এটি পরিষ্কারভাবে সেই অংশগুলিকে নির্ণয় করে যা পূর্বের সাথে করতে হবে এবং যে অংশগুলি পরীক্ষা নির্ভুলতার সাথে করতে হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1085.64,
  "end": 1095.84
 },
 {
  "input": "But over in the usual formula, all of those are very intermingled together. ",
  "translatedText": "কিন্তু স্বাভাবিক সূত্রে, সেগুলি সব একসাথে মিশে গেছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1096.66,
  "end": 1100.2
 },
 {
  "input": "And this has a very practical benefit. ",
  "translatedText": "এবং এটি একটি খুব বাস্তব সুবিধা আছে. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1100.58,
  "end": 1102.36
 },
 {
  "input": "It's really nice if you want to swap out different priors and easily see their effects. ",
  "translatedText": "আপনি যদি বিভিন্ন পূর্ববর্তী অদলবদল করতে চান এবং সহজেই তাদের প্রভাব দেখতে চান তবে এটি সত্যিই চমৎকার।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1102.48,
  "end": 1106.26
 },
 {
  "input": "This is what we were doing earlier. ",
  "translatedText": "এই আমরা আগে কি করছিলাম. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1106.6,
  "end": 1107.9
 },
 {
  "input": "But with the other formula, to do that, you have to recompute everything each time. ",
  "translatedText": "কিন্তু অন্য সূত্রের সাথে, এটি করতে, আপনাকে প্রতিবার সবকিছু পুনরায় গণনা করতে হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1108.42,
  "end": 1112.2
 },
 {
  "input": "You can't leverage a precomputed Bayes' factor the same way. ",
  "translatedText": "আপনি একইভাবে একটি পূর্বনির্ধারিত বেইস ফ্যাক্টরকে লিভারেজ করতে পারবেন না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1112.38,
  "end": 1115.36
 },
 {
  "input": "The odds framing also makes things really nice if you want to do multiple different Bayesian updates based on multiple pieces of evidence. ",
  "translatedText": "আপনি যদি প্রমাণের একাধিক অংশের উপর ভিত্তি করে একাধিক ভিন্ন বায়েসিয়ান আপডেট করতে চান তবে অদ্ভুত ফ্রেমিং জিনিসগুলিকে সত্যিই সুন্দর করে তোলে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1115.96,
  "end": 1122.12
 },
 {
  "input": "For example, let's say you took not one test, but two. ",
  "translatedText": "উদাহরণস্বরূপ, ধরা যাক আপনি একটি পরীক্ষা দেননি, দুটি পরীক্ষা দিয়েছেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1122.74,
  "end": 1124.86
 },
 {
  "input": "Or you wanted to think about how the presence of symptoms plays into it. ",
  "translatedText": "অথবা আপনি কীভাবে লক্ষণগুলির উপস্থিতি এতে ভূমিকা পালন করে তা নিয়ে ভাবতে চেয়েছিলেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1125.36,
  "end": 1128.54
 },
 {
  "input": "For each piece of new evidence you see, you always ask the question, how much more likely would you be to see that with the disease versus without the disease? ",
  "translatedText": "আপনি যে নতুন প্রমাণগুলি দেখতে পাচ্ছেন তার প্রতিটি অংশের জন্য, আপনি সর্বদা প্রশ্নটি জিজ্ঞাসা করেন, রোগের সাথে বনাম রোগ ছাড়াই এটি দেখার সম্ভাবনা কতটা বেশি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1129.12,
  "end": 1136.62
 },
 {
  "input": "Each answer to that question gives you a new Bayes' factor, a new thing that you multiply by your odds. ",
  "translatedText": "এই প্রশ্নের প্রতিটি উত্তর আপনাকে একটি নতুন Bayes' ফ্যাক্টর দেয়, একটি নতুন জিনিস যা আপনি আপনার মতভেদ দ্বারা গুণ করেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1137.24,
  "end": 1142.0
 },
 {
  "input": "Beyond just making calculations easier, there's something I really like about attaching a number to test accuracy that doesn't even look like a probability. ",
  "translatedText": "শুধু গণনা সহজ করার বাইরে, সঠিকতা পরীক্ষা করার জন্য একটি সংখ্যা সংযুক্ত করার বিষয়ে আমি সত্যিই পছন্দ করি এমন কিছু আছে যা এমনকি সম্ভাব্যতার মতো দেখায় না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1142.88,
  "end": 1149.92
 },
 {
  "input": "I mean, if you hear that a test has, for example, a 9% false positive rate, that's just such a disastrously ambiguous phrase. ",
  "translatedText": "আমি বলতে চাচ্ছি, আপনি যদি শুনতে পান যে একটি পরীক্ষায়, উদাহরণস্বরূপ, একটি 9% মিথ্যা ইতিবাচক হার রয়েছে, তবে এটি এমন একটি বিপর্যয়মূলকভাবে অস্পষ্ট বাক্যাংশ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1150.74,
  "end": 1157.34
 },
 {
  "input": "It's so easy to misinterpret it to mean there's a 9% chance that your positive test result is false. ",
  "translatedText": "এটির ভুল ব্যাখ্যা করা এত সহজ যে আপনার ইতিবাচক পরীক্ষার ফলাফল মিথ্যা হওয়ার 9% সম্ভাবনা রয়েছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1157.78,
  "end": 1162.58
 },
 {
  "input": "But imagine if instead the number that we heard tacked on to test results was that the Bayes' factor for a positive test result is, say, 10. ",
  "translatedText": "কিন্তু কল্পনা করুন যে আমরা পরীক্ষার ফলাফলে যে সংখ্যাটি শুনেছি তা যদি ইতিবাচক পরীক্ষার ফলাফলের জন্য বেইসের ফ্যাক্টর হয়, বলুন, 10।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1163.3,
  "end": 1170.32
 },
 {
  "input": "There's no room to confuse that for your probability of having a disease. ",
  "translatedText": "আপনার রোগ হওয়ার সম্ভাবনার জন্য এটিকে বিভ্রান্ত করার কোন অবকাশ নেই।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1170.82,
  "end": 1174.14
 },
 {
  "input": "The entire framing of what a Bayes' factor is, is that it's something that acts on a prior. ",
  "translatedText": "একটি Bayes' ফ্যাক্টর কি সম্পূর্ণ ফ্রেমিং, এটা একটি পূর্বে কাজ করে যে কিছু. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1174.64,
  "end": 1179.04
 },
 {
  "input": "It forces your hand to acknowledge the prior as something that's separate entirely, and highly necessary to drawing any conclusion. ",
  "translatedText": "এটি আপনার হাতকে জোর করে পূর্বকে এমন কিছু হিসাবে স্বীকার করতে যা সম্পূর্ণ আলাদা, এবং যেকোন উপসংহারে পৌঁছাতে অত্যন্ত প্রয়োজনীয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1179.5,
  "end": 1185.44
 },
 {
  "input": "All that said, the usual formula is definitely not without its merits. ",
  "translatedText": "যা বলেছে, স্বাভাবিক সূত্রটি অবশ্যই তার যোগ্যতা ছাড়া নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1187.26,
  "end": 1190.74
 },
 {
  "input": "If you view it not simply as something to plug numbers into, but as an encapsulation of the sample population idea that we've been using throughout, you could very easily argue that that's actually much better for your intuition. ",
  "translatedText": "আপনি যদি এটিকে কেবল নম্বরগুলি প্লাগ করার মতো কিছু হিসাবে দেখেন না, তবে নমুনা জনসংখ্যার ধারণার একটি এনক্যাপসুলেশন হিসাবে যা আমরা সর্বত্র ব্যবহার করছি, আপনি খুব সহজেই যুক্তি দিতে পারেন যে এটি আসলে আপনার অন্তর্দৃষ্টির জন্য অনেক ভাল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1191.08,
  "end": 1201.98
 },
 {
  "input": "After all, it's what we were routinely falling back on in order to check ourselves that the Bayes' factor computation even made sense in the first place. ",
  "translatedText": "সর্বোপরি, বেইসের ফ্যাক্টর কম্পিউটেশন এমনকি প্রথম স্থানে অর্থপূর্ণ কিনা তা পরীক্ষা করার জন্য আমরা নিয়মিতভাবে ফিরে আসছিলাম।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1202.56,
  "end": 1209.18
 },
 {
  "input": "Like any design decision, there is no clear-cut objective best here. ",
  "translatedText": "যেকোনো ডিজাইনের সিদ্ধান্তের মতো, এখানে কোন পরিষ্কার-কাট উদ্দেশ্য সেরা নেই।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1211.6,
  "end": 1215.38
 },
 {
  "input": "But it's almost certainly the case that giving serious consideration to that question will lead you to a better understanding of Bayes' rule. ",
  "translatedText": "তবে এটি প্রায় নিশ্চিতভাবেই যে এই প্রশ্নটিকে গুরুত্ব সহকারে বিবেচনা করা আপনাকে বেইসের নিয়ম সম্পর্কে আরও ভাল বোঝার দিকে নিয়ে যাবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1215.42,
  "end": 1221.72
 },
 {
  "input": "Also, since we're on the topic of kind of paradoxical things, a friend of mine, Matt Cook, recently wrote a book all about paradoxes. ",
  "translatedText": "এছাড়াও, যেহেতু আমরা বিভিন্ন ধরণের প্যারাডক্সিক্যাল বিষয়ের বিষয়ে আছি, আমার একজন বন্ধু ম্যাট কুক সম্প্রতি প্যারাডক্স সম্পর্কে একটি বই লিখেছেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1230.1,
  "end": 1236.12
 },
 {
  "input": "I actually contributed a small chapter to it with thoughts on the question of whether math is invented or discovered. ",
  "translatedText": "আমি আসলে গণিত উদ্ভাবিত বা আবিষ্কৃত কিনা এই প্রশ্নে চিন্তাভাবনা সহ এটিতে একটি ছোট অধ্যায় অবদান রেখেছি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1237.04,
  "end": 1241.82
 },
 {
  "input": "And the book as a whole is this really nice connection of thought-provoking paradoxical things ranging from philosophy to math and physics. ",
  "translatedText": "এবং সামগ্রিকভাবে বইটি দর্শন থেকে গণিত এবং পদার্থবিদ্যা পর্যন্ত চিন্তা-প্ররোচনামূলক প্যারাডক্সিক্যাল জিনিসগুলির সত্যিই চমৎকার সংযোগ।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1242.3,
  "end": 1248.4
 },
 {
  "input": "You can, of course, find all the details in the description. ",
  "translatedText": "আপনি, অবশ্যই, বিবরণে সমস্ত বিবরণ খুঁজে পেতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1248.82,
  "end": 1251.04
 }
]