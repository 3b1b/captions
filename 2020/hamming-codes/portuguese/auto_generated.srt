1
00:00:00,000 --> 00:00:02,560
Presumo que todos aqui venham da parte 1.

2
00:00:03,060 --> 00:00:06,788
Estávamos falando sobre códigos de Hamming, uma forma de criar um bloco de dados 

3
00:00:06,788 --> 00:00:09,549
onde a maioria dos bits carrega uma mensagem significativa, 

4
00:00:09,549 --> 00:00:12,403
enquanto alguns outros atuam como uma espécie de redundância, 

5
00:00:12,403 --> 00:00:16,545
de tal forma que se algum bit for invertido, será uma mensagem bit ou bit de redundância, 

6
00:00:16,545 --> 00:00:20,181
qualquer coisa neste bloco, um receptor será capaz de identificar que houve um 

7
00:00:20,181 --> 00:00:21,240
erro e como corrigi-lo.

8
00:00:21,880 --> 00:00:24,221
A ideia básica apresentada foi como usar múltiplas 

9
00:00:24,221 --> 00:00:27,160
verificações de paridade para pesquisar binariamente até o erro.

10
00:00:28,980 --> 00:00:31,580
Nesse vídeo, o objetivo era fazer com que os códigos de 

11
00:00:31,580 --> 00:00:34,600
Hamming parecessem tão práticos e redescobríveis quanto possível.

12
00:00:35,180 --> 00:00:37,984
Mas quando você começa a pensar em realmente implementar isso, 

13
00:00:37,984 --> 00:00:40,967
seja em software ou hardware, esse enquadramento pode, na verdade, 

14
00:00:40,967 --> 00:00:43,460
subestimar o quão elegantes esses códigos realmente são.

15
00:00:43,920 --> 00:00:47,200
Você pode pensar que precisa escrever um algoritmo que monitore todos 

16
00:00:47,200 --> 00:00:50,902
os possíveis locais de erro e corte esse grupo pela metade a cada verificação, 

17
00:00:50,902 --> 00:00:53,480
mas na verdade é muito, muito mais simples do que isso.

18
00:00:53,940 --> 00:00:58,844
Se você ler as respostas às quatro verificações de paridade que fizemos no último vídeo, 

19
00:00:58,844 --> 00:01:02,040
todas como 1s e 0s em vez de sim e não, isso literalmente 

20
00:01:02,040 --> 00:01:04,080
explica a posição do erro em binário.

21
00:01:04,780 --> 00:01:08,174
Por exemplo, o número 7 em binário se parece com 0111, 

22
00:01:08,174 --> 00:01:11,260
significando essencialmente que é 4 mais 2 mais 1.

23
00:01:12,540 --> 00:01:18,577
E observe onde fica a posição 7, ela afeta o primeiro de nossos grupos de paridade, 

24
00:01:18,577 --> 00:01:21,740
e o segundo, e o terceiro, mas não o último.

25
00:01:22,220 --> 00:01:24,880
Portanto, ler os resultados dessas quatro verificações 

26
00:01:24,880 --> 00:01:27,540
de baixo para cima realmente explica a posição do erro.

27
00:01:28,320 --> 00:01:32,222
Não há nada de especial no exemplo 7, ele funciona em geral e torna a lógica 

28
00:01:32,222 --> 00:01:35,820
para implementar todo o esquema em hardware surpreendentemente simples.

29
00:01:37,240 --> 00:01:40,614
Agora se você quiser ver por que essa mágica acontece, 

30
00:01:40,614 --> 00:01:43,989
pegue esses 16 rótulos de índice para nossas posições, 

31
00:01:43,989 --> 00:01:48,530
mas em vez de escrevê-los na base 10, vamos escrevê-los todos em binário, 

32
00:01:48,530 --> 00:01:49,880
indo de 0000 até 1111.

33
00:01:50,559 --> 00:01:53,572
Ao colocarmos esses rótulos binários de volta em suas caixas, 

34
00:01:53,572 --> 00:01:57,800
deixe-me enfatizar que eles são distintos dos dados que estão sendo realmente enviados.

35
00:01:58,320 --> 00:02:00,993
Eles nada mais são do que um rótulo conceitual para ajudar você 

36
00:02:00,993 --> 00:02:03,500
e eu a entender de onde vieram os quatro grupos de paridade.

37
00:02:04,140 --> 00:02:08,196
A elegância de ter tudo o que estamos vendo descrito em binário talvez seja 

38
00:02:08,196 --> 00:02:12,360
prejudicada pela confusão de ter tudo o que estamos vendo descrito em binário.

39
00:02:13,020 --> 00:02:14,120
Vale a pena, no entanto.

40
00:02:14,800 --> 00:02:19,507
Concentre sua atenção apenas na última parte de todos esses rótulos e, 

41
00:02:19,507 --> 00:02:23,220
em seguida, destaque as posições onde a parte final é 1.

42
00:02:24,240 --> 00:02:27,749
O que obtemos é o primeiro dos nossos quatro grupos de paridade, 

43
00:02:27,749 --> 00:02:32,446
o que significa que você pode interpretar essa primeira verificação como uma pergunta: 

44
00:02:32,446 --> 00:02:35,740
ei, se houver um erro, o bit final na posição desse erro é 1?

45
00:02:38,200 --> 00:02:42,987
Da mesma forma, se você focar no penúltimo bit e destacar todas as posições onde é 1, 

46
00:02:42,987 --> 00:02:46,160
você obterá o segundo grupo de paridade do nosso esquema.

47
00:02:46,740 --> 00:02:50,529
Em outras palavras, essa segunda verificação está perguntando, 

48
00:02:50,529 --> 00:02:54,500
ei, de novo, se houver um erro, o penúltimo bit dessa posição é 1?

49
00:02:55,760 --> 00:02:56,900
E assim por diante.

50
00:02:57,220 --> 00:03:02,683
A terceira verificação de paridade cobre todas as posições cujo penúltimo bit está 

51
00:03:02,683 --> 00:03:06,106
ativado, e a última cobre as últimas oito posições, 

52
00:03:06,106 --> 00:03:08,740
aquelas cujo bit de ordem mais alta é 1.

53
00:03:09,740 --> 00:03:14,319
Tudo o que fizemos anteriormente é o mesmo que responder a estas quatro perguntas, 

54
00:03:14,319 --> 00:03:17,740
que por sua vez é o mesmo que soletrar uma posição em binário.

55
00:03:19,620 --> 00:03:21,480
Espero que isso deixe duas coisas mais claras.

56
00:03:22,040 --> 00:03:24,208
A primeira é como generalizar sistematicamente para 

57
00:03:24,208 --> 00:03:26,460
tamanhos de bloco maiores que sejam potências de dois.

58
00:03:26,960 --> 00:03:30,095
Se forem necessários mais bits para descrever cada posição, 

59
00:03:30,095 --> 00:03:33,335
como seis bits para descrever 64 pontos, então cada um desses 

60
00:03:33,335 --> 00:03:36,680
bits fornece um dos grupos de paridade que precisamos verificar.

61
00:03:38,400 --> 00:03:40,858
Aqueles de vocês que assistiram ao quebra-cabeça do tabuleiro de xadrez 

62
00:03:40,858 --> 00:03:43,180
que fiz com Matt Parker podem achar tudo isso extremamente familiar.

63
00:03:43,660 --> 00:03:46,104
É a mesma lógica central, mas resolvendo um problema 

64
00:03:46,104 --> 00:03:48,780
diferente e aplicada a um tabuleiro de xadrez de 64 casas.

65
00:03:49,880 --> 00:03:53,453
A segunda coisa que espero que isso deixe claro é por que nossos bits de 

66
00:03:53,453 --> 00:03:57,320
paridade estão em posições que são potências de dois, por exemplo, 1, 2, 4 e 8.

67
00:03:58,000 --> 00:04:03,000
Estas são as posições cuja representação binária tem apenas um bit ativado.

68
00:04:03,600 --> 00:04:06,505
O que isso significa é que cada um desses bits de paridade 

69
00:04:06,505 --> 00:04:09,460
está dentro de um e apenas um dos quatro grupos de paridade.

70
00:04:12,040 --> 00:04:16,245
Você também pode ver isso em exemplos maiores, onde não importa quão grande você seja, 

71
00:04:16,245 --> 00:04:19,339
cada bit de paridade toca convenientemente apenas um dos grupos.

72
00:04:25,600 --> 00:04:29,093
Depois de entender que essas verificações de paridade nas quais nos concentramos 

73
00:04:29,093 --> 00:04:32,543
tanto em nosso tempo nada mais são do que uma maneira inteligente de explicar a 

74
00:04:32,543 --> 00:04:35,951
posição de um erro em binário, então poderemos estabelecer uma conexão com uma 

75
00:04:35,951 --> 00:04:38,150
maneira diferente de pensar sobre hamming códigos, 

76
00:04:38,150 --> 00:04:40,350
que são sem dúvida muito mais simples e elegantes, 

77
00:04:40,350 --> 00:04:43,240
e que basicamente podem ser escritos com uma única linha de código.

78
00:04:43,660 --> 00:04:45,500
É baseado na função XOR.

79
00:04:46,940 --> 00:04:50,220
XOR, para quem não sabe, significa exclusivo ou.

80
00:04:50,780 --> 00:04:56,211
Quando você pega o XOR de dois bits, ele retornará 1 se um desses bits estiver ativado, 

81
00:04:56,211 --> 00:04:59,360
mas não se ambos estiverem ativados ou desativados.

82
00:05:00,100 --> 00:05:02,980
Em outras palavras, é a paridade desses dois bits.

83
00:05:03,540 --> 00:05:06,760
Como um especialista em matemática, prefiro pensar nisso como um mod de adição 2.

84
00:05:07,360 --> 00:05:10,919
Também costumamos falar sobre o XOR de duas cadeias de bits diferentes, 

85
00:05:10,919 --> 00:05:13,440
que basicamente faz isso componente por componente.

86
00:05:13,680 --> 00:05:15,720
É como uma adição, mas onde você nunca carrega.

87
00:05:16,500 --> 00:05:19,342
Novamente, os mais inclinados à matemática podem preferir 

88
00:05:19,342 --> 00:05:22,480
pensar nisso como a adição de dois vetores e a redução do mod 2.

89
00:05:23,500 --> 00:05:26,392
Se você abrir algum Python agora e aplicar a operação de 

90
00:05:26,392 --> 00:05:29,691
intercalação entre dois inteiros, isso é o que ele está fazendo, 

91
00:05:29,691 --> 00:05:32,940
exceto nas representações de bits desses números nos bastidores.

92
00:05:34,960 --> 00:05:39,074
O ponto principal para você e para mim é que obter o XOR de muitas cadeias 

93
00:05:39,074 --> 00:05:43,080
de bits diferentes é efetivamente uma maneira de calcular as paródias de 

94
00:05:43,080 --> 00:05:47,140
vários grupos separados, como acontece com as colunas, tudo de uma só vez.

95
00:05:51,260 --> 00:05:53,739
Isso nos dá uma maneira bastante elegante de pensar sobre as 

96
00:05:53,739 --> 00:05:56,341
múltiplas verificações de paridade de nosso algoritmo de código 

97
00:05:56,341 --> 00:05:58,780
de Hamming como sendo todas agrupadas em uma única operação.

98
00:05:59,479 --> 00:06:02,180
Embora à primeira vista pareça muito diferente.

99
00:06:02,820 --> 00:06:07,467
Anote especificamente as 16 posições em binário, como fizemos antes, 

100
00:06:07,467 --> 00:06:12,519
e agora destaque as posições onde o bit da mensagem está ativado para 1 e, 

101
00:06:12,519 --> 00:06:17,100
em seguida, reúna essas posições em uma grande coluna e pegue o XOR.

102
00:06:19,260 --> 00:06:22,497
Você provavelmente pode adivinhar que os 4 bits na parte inferior como 

103
00:06:22,497 --> 00:06:25,962
resultado são iguais às 4 verificações de paridade que conhecemos e amamos, 

104
00:06:25,962 --> 00:06:29,200
mas reserve um momento para realmente pensar sobre o porquê exatamente.

105
00:06:32,220 --> 00:06:37,011
Esta última coluna, por exemplo, está contando todas as posições cujo último bit é 1, 

106
00:06:37,011 --> 00:06:40,132
mas já estamos limitados apenas às posições destacadas, 

107
00:06:40,132 --> 00:06:44,757
portanto está contando efetivamente quantas posições destacadas vieram do primeiro 

108
00:06:44,757 --> 00:06:45,760
grupo de paridade.

109
00:06:46,240 --> 00:06:46,800
Isso faz sentido?

110
00:06:49,080 --> 00:06:54,110
Da mesma forma, a próxima coluna conta quantas posições estão no segundo grupo de 

111
00:06:54,110 --> 00:06:58,834
paridade, as posições cujo penúltimo bit é 1, e que também estão destacadas, 

112
00:06:58,834 --> 00:07:00,000
e assim por diante.

113
00:07:00,260 --> 00:07:02,512
Na verdade, é apenas uma pequena mudança de perspectiva 

114
00:07:02,512 --> 00:07:03,960
sobre a mesma coisa que temos feito.

115
00:07:07,760 --> 00:07:09,600
E então você sabe para onde vai a partir daqui.

116
00:07:10,000 --> 00:07:12,808
O remetente é responsável por alternar alguns dos bits 

117
00:07:12,808 --> 00:07:15,720
de paridade especiais para garantir que a soma seja 0000.

118
00:07:15,720 --> 00:07:19,673
Agora, uma vez que temos isto, isto dá-nos uma maneira muito 

119
00:07:19,673 --> 00:07:23,756
boa de pensar sobre porque é que estes quatro bits resultantes 

120
00:07:23,756 --> 00:07:27,580
na parte inferior indicam diretamente a posição de um erro.

121
00:07:28,460 --> 00:07:31,860
Digamos que algum bit neste bloco seja alternado de 0 para 1.

122
00:07:32,600 --> 00:07:38,501
O que isso significa é que a posição desse bit agora será incluída no XOR total, 

123
00:07:38,501 --> 00:07:43,820
o que muda a soma de 0 para esse valor recém-incluído, a posição do erro.

124
00:07:44,460 --> 00:07:49,360
Um pouco menos óbvio, o mesmo acontece se houver um erro que mude 1 para 0.

125
00:07:50,180 --> 00:07:53,267
Veja bem, se você somar uma sequência de bits duas vezes, 

126
00:07:53,267 --> 00:07:57,580
é o mesmo que não tê-la ali, basicamente porque neste mundo 1 mais 1 é igual a 0.

127
00:07:57,580 --> 00:08:04,300
Portanto, adicionar uma cópia desta posição à soma total tem o mesmo efeito que a movemos.

128
00:08:05,160 --> 00:08:07,738
E esse efeito, mais uma vez, é que o resultado 

129
00:08:07,738 --> 00:08:10,700
total na parte inferior aqui indica a posição do erro.

130
00:08:13,039 --> 00:08:17,109
Para ilustrar o quão elegante isso é, deixe-me mostrar aquela linha de código 

131
00:08:17,109 --> 00:08:21,440
Python que mencionei antes, que capturará quase toda a lógica no final do receptor.

132
00:08:22,080 --> 00:08:26,604
Começaremos criando um array aleatório de 16 1s e 0s para simular o bloco de dados, 

133
00:08:26,604 --> 00:08:30,267
e darei a ele o nome de bits, mas é claro que na prática isso seria 

134
00:08:30,267 --> 00:08:33,929
algo que receberíamos de um remetente e, em vez de sendo aleatório, 

135
00:08:33,929 --> 00:08:37,000
carregaria 11 bits de dados junto com 5 bits de paridade.

136
00:08:37,000 --> 00:08:42,000
Se eu chamar a função enumerateBits, o que ela faz é emparelhar cada um 

137
00:08:42,000 --> 00:08:47,000
desses bits com um índice correspondente, neste caso variando de 0 a 15.

138
00:08:48,180 --> 00:08:51,931
Então, se criarmos uma lista que percorre todos esses pares, 

139
00:08:51,931 --> 00:08:55,928
pares que se parecem com i, e então extrairmos apenas o valor i, 

140
00:08:55,928 --> 00:09:01,340
apenas o índice, bem, não é tão emocionante, apenas recuperamos esses índices de 0 a 15.

141
00:09:01,680 --> 00:09:06,132
Mas se adicionarmos a condição de fazer isso apenas se for bit, ou seja, 

142
00:09:06,132 --> 00:09:10,952
se esse bit for 1 e não 0, bem, então ele retira apenas as posições onde o bit 

143
00:09:10,952 --> 00:09:12,660
correspondente está ativado.

144
00:09:13,380 --> 00:09:20,360
Neste caso, parece que essas posições são 0, 4, 6, 9, etc.

145
00:09:20,720 --> 00:09:25,486
O que queremos é reunir todas essas posições, as posições dos bits que estão ativados, 

146
00:09:25,486 --> 00:09:27,240
e então fazer um XOR entre elas.

147
00:09:29,180 --> 00:09:33,220
Para fazer isso em Python, primeiro vou importar algumas funções úteis.

148
00:09:33,900 --> 00:09:38,700
Dessa forma podemos chamar reduzir() nesta lista e usar a função XOR para reduzi-la.

149
00:09:39,100 --> 00:09:42,680
Isso basicamente percorre a lista, levando XORs ao longo do caminho.

150
00:09:44,800 --> 00:09:47,097
Se preferir, você pode escrever explicitamente essa 

151
00:09:47,097 --> 00:09:49,440
função XOR sem precisar importá-la de qualquer lugar.

152
00:09:51,940 --> 00:09:57,625
Então, no momento, parece que se fizermos isso em nosso bloco aleatório de 16 bits, 

153
00:09:57,625 --> 00:10:01,280
ele retornará 9, que tem a representação binária 1001.

154
00:10:01,980 --> 00:10:05,217
Não faremos isso aqui, mas você poderia escrever uma função onde o 

155
00:10:05,217 --> 00:10:08,550
remetente usa essa representação binária para definir os quatro bits 

156
00:10:08,550 --> 00:10:11,788
de paridade conforme necessário, levando esse bloco a um estado em 

157
00:10:11,788 --> 00:10:15,460
que a execução dessa linha de código na lista completa de bits retorna um 0.

158
00:10:16,080 --> 00:10:20,100
Este seria considerado um bloco bem preparado.

159
00:10:20,100 --> 00:10:24,067
O que é legal é que se alternarmos qualquer um dos bits desta lista, 

160
00:10:24,067 --> 00:10:28,840
simulando um erro aleatório de ruído, se você executar essa mesma linha de código, 

161
00:10:28,840 --> 00:10:30,220
esse erro será impresso.

162
00:10:30,960 --> 00:10:31,520
Não é legal?

163
00:10:31,820 --> 00:10:36,377
Você pode obter esse bloco do nada, executar esta única linha nele e ele 

164
00:10:36,377 --> 00:10:41,060
exibirá automaticamente a posição de um erro ou um 0, se não houver nenhum.

165
00:10:42,500 --> 00:10:44,840
E não há nada de especial no tamanho 16 aqui.

166
00:10:44,840 --> 00:10:49,860
A mesma linha de código funcionaria se você tivesse uma lista de, digamos, 256 bits.

167
00:10:51,880 --> 00:10:54,914
Escusado será dizer que há mais código para escrever aqui, 

168
00:10:54,914 --> 00:10:58,617
como fazer a verificação de metaparidade para detectar erros de 2 bits, 

169
00:10:58,617 --> 00:11:02,474
mas a ideia é que quase toda a lógica central do nosso esquema se reduza a 

170
00:11:02,474 --> 00:11:03,760
uma única redução de XOR.

171
00:11:06,120 --> 00:11:09,976
Agora, dependendo do seu conforto com binários, XORs e software em geral, 

172
00:11:09,976 --> 00:11:13,885
você pode achar essa perspectiva um pouco confusa ou muito mais elegante e 

173
00:11:13,885 --> 00:11:18,420
simples que você está se perguntando por que não começamos com ela desde o início. -ir.

174
00:11:19,140 --> 00:11:22,866
Falando livremente, a perspectiva de verificação de paridade múltipla é mais fácil 

175
00:11:22,866 --> 00:11:26,503
de pensar ao implementar códigos de Hamming em hardware de maneira muito direta, 

176
00:11:26,503 --> 00:11:30,500
e a perspectiva XOR é mais fácil de pensar ao fazê-lo em software, de um nível mais alto.

177
00:11:31,360 --> 00:11:36,048
O primeiro é mais fácil de fazer manualmente, e acho que faz um trabalho melhor ao 

178
00:11:36,048 --> 00:11:38,928
incutir a intuição central subjacente a tudo isso, 

179
00:11:38,928 --> 00:11:43,617
que é que a informação necessária para localizar um único erro está relacionada ao 

180
00:11:43,617 --> 00:11:46,384
log do tamanho do bloco , ou em outras palavras, 

181
00:11:46,384 --> 00:11:50,000
cresce um bit de cada vez à medida que o tamanho do bloco dobra.

182
00:11:51,020 --> 00:11:53,657
O fato relevante aqui é que essa informação corresponde 

183
00:11:53,657 --> 00:11:56,060
diretamente à quantidade de redundância necessária.

184
00:11:56,660 --> 00:11:59,939
Isso é realmente o que vai contra a reação instintiva da maioria das pessoas 

185
00:11:59,939 --> 00:12:03,133
quando pensam pela primeira vez em tornar uma mensagem resistente a erros, 

186
00:12:03,133 --> 00:12:06,540
onde geralmente copiar a mensagem inteira é o primeiro instinto que vem à mente.

187
00:12:07,500 --> 00:12:10,790
E então, a propósito, há toda essa outra maneira que às vezes você vê os códigos 

188
00:12:10,790 --> 00:12:14,000
de Hamming apresentados, onde você multiplica a mensagem por uma grande matriz.

189
00:12:14,670 --> 00:12:18,440
É bom porque o relaciona com a família mais ampla de códigos lineares, 

190
00:12:18,440 --> 00:12:23,060
mas acho que isso quase não dá nenhuma intuição de onde ele vem ou como é dimensionado.

191
00:12:25,200 --> 00:12:28,112
E por falar em dimensionamento, você deve notar que a eficiência 

192
00:12:28,112 --> 00:12:31,160
desse esquema só melhora à medida que aumentamos o tamanho do bloco.

193
00:12:35,000 --> 00:12:38,631
Por exemplo, vimos que com 256 bits, você está usando apenas 3% 

194
00:12:38,631 --> 00:12:42,660
desse espaço para redundância, e isso continua melhorando a partir daí.

195
00:12:43,300 --> 00:12:45,764
À medida que o número de bits de paridade aumenta um por um, 

196
00:12:45,764 --> 00:12:47,340
o tamanho do bloco continua duplicando.

197
00:12:49,000 --> 00:12:52,673
E se você levar isso ao extremo, você poderia ter um bloco com, digamos, 

198
00:12:52,673 --> 00:12:56,246
um milhão de bits, onde você estaria literalmente jogando 20 perguntas 

199
00:12:56,246 --> 00:13:00,020
com suas verificações de paridade, e ele usaria apenas 21 bits de paridade.

200
00:13:00,740 --> 00:13:05,106
E se você pensar em olhar para um milhão de bits e localizar um único erro, 

201
00:13:05,106 --> 00:13:07,060
isso realmente parece uma loucura.

202
00:13:08,199 --> 00:13:12,959
O problema, claro, é que com um bloco maior, a probabilidade de ver mais de um ou 

203
00:13:12,959 --> 00:13:17,660
dois erros de bit aumenta, e os códigos de Hamming não lidam com nada além disso.

204
00:13:18,320 --> 00:13:21,353
Então, na prática, o que você deseja é encontrar o tamanho certo para 

205
00:13:21,353 --> 00:13:24,300
que a probabilidade de muitas inversões de bits não seja muito alta.

206
00:13:26,600 --> 00:13:30,108
Além disso, na prática, os erros tendem a ocorrer em pequenas rajadas, 

207
00:13:30,108 --> 00:13:32,776
o que arruinaria totalmente um único bloco, portanto, 

208
00:13:32,776 --> 00:13:36,285
uma tática comum para ajudar a espalhar uma rajada de erros por muitos 

209
00:13:36,285 --> 00:13:38,855
blocos diferentes é entrelaçar esses blocos, assim, 

210
00:13:38,855 --> 00:13:40,980
antes que eles sejam enviado ou armazenado.

211
00:13:45,580 --> 00:13:49,615
Por outro lado, muito disso é completamente discutível por códigos mais modernos, 

212
00:13:49,615 --> 00:13:52,519
como o algoritmo Reed-Solomon, muito mais comumente usado, 

213
00:13:52,519 --> 00:13:56,457
que lida particularmente bem com erros de explosão e pode ser ajustado para ser 

214
00:13:56,457 --> 00:13:58,820
resiliente a um número maior de erros por bloco.

215
00:13:59,360 --> 00:14:01,340
Mas isso é assunto para outra hora.

216
00:14:02,500 --> 00:14:05,361
Em seu livro The Art of Doing Science and Engineering, 

217
00:14:05,361 --> 00:14:09,940
Hamming é maravilhosamente sincero sobre o quão sinuosa foi sua descoberta desse código.

218
00:14:10,620 --> 00:14:14,243
Ele primeiro tentou todos os tipos de esquemas diferentes envolvendo a organização 

219
00:14:14,243 --> 00:14:17,780
dos bits em partes de uma rede dimensional superior e coisas estranhas como esta.

220
00:14:18,300 --> 00:14:21,537
A ideia de que seria possível fazer com que as verificações de paridade 

221
00:14:21,537 --> 00:14:24,865
conspirassem de uma forma que explicitasse a posição de um erro só surgiu 

222
00:14:24,865 --> 00:14:28,192
a Hamming quando ele recuou após um monte de outras análises e perguntou: 

223
00:14:28,192 --> 00:14:31,520
ok, qual é o mais eficiente que eu poderia concebivelmente ser sobre isso?

224
00:14:32,620 --> 00:14:36,865
Ele também foi sincero sobre a importância de já ter em mente as verificações 

225
00:14:36,865 --> 00:14:41,220
de paridade, o que teria sido muito menos comum na década de 1940 do que é hoje.

226
00:14:41,920 --> 00:14:44,824
Há cerca de meia dúzia de vezes ao longo deste livro que ele faz 

227
00:14:44,824 --> 00:14:48,220
referência à citação de Louis Pasteur: a sorte favorece uma mente preparada.

228
00:14:49,320 --> 00:14:52,767
Ideias inteligentes muitas vezes parecem enganosamente simples em retrospectiva, 

229
00:14:52,767 --> 00:14:54,300
o que as torna fáceis de subestimar.

230
00:14:54,960 --> 00:14:57,841
No momento, minha sincera esperança é que os códigos de Hamming, 

231
00:14:57,841 --> 00:15:01,300
ou pelo menos a possibilidade de tais códigos, pareçam quase óbvios para você.

232
00:15:01,660 --> 00:15:05,220
Mas você não deve se enganar pensando que eles são realmente óbvios, 

233
00:15:05,220 --> 00:15:06,820
porque definitivamente não são.

234
00:15:07,880 --> 00:15:11,528
Parte da razão pela qual ideias inteligentes parecem enganosamente fáceis é 

235
00:15:11,528 --> 00:15:14,649
que só vemos o resultado final, limpando o que estava bagunçado, 

236
00:15:14,649 --> 00:15:18,250
nunca mencionando todos os caminhos errados, subestimando o quão vasto é o 

237
00:15:18,250 --> 00:15:22,379
espaço de possibilidades exploráveis no início de um problema. processo de resolução, 

238
00:15:22,379 --> 00:15:22,860
tudo isso.

239
00:15:23,820 --> 00:15:24,900
Mas isso é verdade em geral.

240
00:15:24,900 --> 00:15:27,495
Acho que, para algumas invenções especiais, há uma 

241
00:15:27,495 --> 00:15:30,040
segunda razão mais profunda para as subestimarmos.

242
00:15:30,840 --> 00:15:35,195
Pensar na informação em termos de bits só se consolidou numa teoria completa em 1948, 

243
00:15:35,195 --> 00:15:38,640
com o artigo seminal de Claude Shannon sobre a teoria da informação.

244
00:15:39,280 --> 00:15:42,540
Isso ocorreu essencialmente ao mesmo tempo em que Hamming desenvolveu seu algoritmo.

245
00:15:43,300 --> 00:15:46,422
Este foi o mesmo artigo fundamental que mostrou, em certo sentido, 

246
00:15:46,422 --> 00:15:48,892
que a correção eficiente de erros é sempre possível, 

247
00:15:48,892 --> 00:15:52,900
não importa quão alta seja a probabilidade de inversões de bits, pelo menos em teoria.

248
00:15:53,700 --> 00:15:56,693
Shannon e Hamming, aliás, dividiam um escritório no Bell Labs, 

249
00:15:56,693 --> 00:15:59,069
apesar de trabalharem em coisas muito diferentes, 

250
00:15:59,069 --> 00:16:01,160
o que dificilmente parece coincidência aqui.

251
00:16:02,380 --> 00:16:07,241
Avançando várias décadas, hoje em dia muitos de nós estamos tão imersos em pensar 

252
00:16:07,241 --> 00:16:12,340
sobre bits e informações que é fácil ignorar o quão distinta era essa forma de pensar.

253
00:16:13,100 --> 00:16:17,680
Ironicamente, as ideias que moldam mais profundamente a forma como uma geração futura 

254
00:16:17,680 --> 00:16:22,260
pensa acabarão por parecer para essa geração futura mais simples do que realmente são.

