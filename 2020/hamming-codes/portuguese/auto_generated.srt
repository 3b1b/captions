1
00:00:00,000 --> 00:00:03,120
Presumo que todos aqui venham da parte 1.

2
00:00:03,120 --> 00:00:06,975
Estávamos falando sobre códigos de Hamming, uma forma de criar um bloco de dados

3
00:00:06,975 --> 00:00:09,830
onde a maioria dos bits carrega uma mensagem significativa,

4
00:00:09,830 --> 00:00:12,781
enquanto alguns outros atuam como uma espécie de redundância,

5
00:00:12,781 --> 00:00:17,065
de tal forma que se algum bit for invertido, será uma mensagem bit ou bit de redundância,

6
00:00:17,065 --> 00:00:20,825
qualquer coisa neste bloco, um receptor será capaz de identificar que houve um

7
00:00:20,825 --> 00:00:21,920
erro e como corrigi-lo.

8
00:00:21,920 --> 00:00:25,414
A ideia básica apresentada foi como usar múltiplas

9
00:00:25,414 --> 00:00:29,800
verificações de paridade para pesquisar binariamente até o erro.

10
00:00:29,800 --> 00:00:32,400
Nesse vídeo, o objetivo era fazer com que os códigos de

11
00:00:32,400 --> 00:00:35,420
Hamming parecessem tão práticos e redescobríveis quanto possível.

12
00:00:35,420 --> 00:00:38,366
Mas quando você começa a pensar em realmente implementar isso,

13
00:00:38,366 --> 00:00:41,500
seja em software ou hardware, esse enquadramento pode, na verdade,

14
00:00:41,500 --> 00:00:44,120
subestimar o quão elegantes esses códigos realmente são.

15
00:00:44,120 --> 00:00:47,565
Você pode pensar que precisa escrever um algoritmo que monitore todos

16
00:00:47,565 --> 00:00:51,453
os possíveis locais de erro e corte esse grupo pela metade a cada verificação,

17
00:00:51,453 --> 00:00:54,160
mas na verdade é muito, muito mais simples do que isso.

18
00:00:54,160 --> 00:00:59,306
Se você ler as respostas às quatro verificações de paridade que fizemos no último vídeo,

19
00:00:59,306 --> 00:01:02,660
todas como 1s e 0s em vez de sim e não, isso literalmente

20
00:01:02,660 --> 00:01:04,800
explica a posição do erro em binário.

21
00:01:04,800 --> 00:01:08,906
Por exemplo, o número 7 em binário se parece com 0111,

22
00:01:08,906 --> 00:01:12,640
significando essencialmente que é 4 mais 2 mais 1.

23
00:01:12,640 --> 00:01:18,966
E observe onde fica a posição 7, ela afeta o primeiro de nossos grupos de paridade,

24
00:01:18,966 --> 00:01:22,280
e o segundo, e o terceiro, mas não o último.

25
00:01:22,280 --> 00:01:25,400
Portanto, ler os resultados dessas quatro verificações

26
00:01:25,400 --> 00:01:28,520
de baixo para cima realmente explica a posição do erro.

27
00:01:28,520 --> 00:01:33,160
Não há nada de especial no exemplo 7, ele funciona em geral e torna a lógica

28
00:01:33,160 --> 00:01:37,440
para implementar todo o esquema em hardware surpreendentemente simples.

29
00:01:37,440 --> 00:01:40,985
Agora se você quiser ver por que essa mágica acontece,

30
00:01:40,985 --> 00:01:44,531
pegue esses 16 rótulos de índice para nossas posições,

31
00:01:44,531 --> 00:01:49,301
mas em vez de escrevê-los na base 10, vamos escrevê-los todos em binário,

32
00:01:49,301 --> 00:01:50,720
indo de 0000 até 1111.

33
00:01:50,720 --> 00:01:53,932
Ao colocarmos esses rótulos binários de volta em suas caixas,

34
00:01:53,932 --> 00:01:58,440
deixe-me enfatizar que eles são distintos dos dados que estão sendo realmente enviados.

35
00:01:58,440 --> 00:02:01,412
Eles nada mais são do que um rótulo conceitual para ajudar você

36
00:02:01,412 --> 00:02:04,200
e eu a entender de onde vieram os quatro grupos de paridade.

37
00:02:04,200 --> 00:02:08,621
A elegância de ter tudo o que estamos vendo descrito em binário talvez seja

38
00:02:08,621 --> 00:02:13,160
prejudicada pela confusão de ter tudo o que estamos vendo descrito em binário.

39
00:02:13,160 --> 00:02:15,040
Vale a pena, no entanto.

40
00:02:15,040 --> 00:02:20,205
Concentre sua atenção apenas na última parte de todos esses rótulos e,

41
00:02:20,205 --> 00:02:24,280
em seguida, destaque as posições onde a parte final é 1.

42
00:02:24,280 --> 00:02:28,064
O que obtemos é o primeiro dos nossos quatro grupos de paridade,

43
00:02:28,064 --> 00:02:33,128
o que significa que você pode interpretar essa primeira verificação como uma pergunta:

44
00:02:33,128 --> 00:02:36,680
ei, se houver um erro, o bit final na posição desse erro é 1?

45
00:02:36,680 --> 00:02:42,910
Da mesma forma, se você focar no penúltimo bit e destacar todas as posições onde é 1,

46
00:02:42,910 --> 00:02:47,040
você obterá o segundo grupo de paridade do nosso esquema.

47
00:02:47,040 --> 00:02:51,493
Em outras palavras, essa segunda verificação está perguntando,

48
00:02:51,493 --> 00:02:56,160
ei, de novo, se houver um erro, o penúltimo bit dessa posição é 1?

49
00:02:56,160 --> 00:02:57,160
E assim por diante.

50
00:02:57,160 --> 00:03:03,306
A terceira verificação de paridade cobre todas as posições cujo penúltimo bit está

51
00:03:03,306 --> 00:03:07,157
ativado, e a última cobre as últimas oito posições,

52
00:03:07,157 --> 00:03:10,120
aquelas cujo bit de ordem mais alta é 1.

53
00:03:10,120 --> 00:03:15,660
Tudo o que fizemos anteriormente é o mesmo que responder a estas quatro perguntas,

54
00:03:15,660 --> 00:03:19,800
que por sua vez é o mesmo que soletrar uma posição em binário.

55
00:03:19,800 --> 00:03:22,080
Espero que isso deixe duas coisas mais claras.

56
00:03:22,080 --> 00:03:24,562
A primeira é como generalizar sistematicamente para

57
00:03:24,562 --> 00:03:27,140
tamanhos de bloco maiores que sejam potências de dois.

58
00:03:27,140 --> 00:03:30,849
Se forem necessários mais bits para descrever cada posição,

59
00:03:30,849 --> 00:03:34,683
como seis bits para descrever 64 pontos, então cada um desses

60
00:03:34,683 --> 00:03:38,640
bits fornece um dos grupos de paridade que precisamos verificar.

61
00:03:38,640 --> 00:03:41,088
Aqueles de vocês que assistiram ao quebra-cabeça do tabuleiro de xadrez

62
00:03:41,088 --> 00:03:43,400
que fiz com Matt Parker podem achar tudo isso extremamente familiar.

63
00:03:43,400 --> 00:03:46,494
É a mesma lógica central, mas resolvendo um problema

64
00:03:46,494 --> 00:03:49,880
diferente e aplicada a um tabuleiro de xadrez de 64 casas.

65
00:03:49,880 --> 00:03:53,933
A segunda coisa que espero que isso deixe claro é por que nossos bits de

66
00:03:53,933 --> 00:03:58,320
paridade estão em posições que são potências de dois, por exemplo, 1, 2, 4 e 8.

67
00:03:58,320 --> 00:04:03,640
Estas são as posições cuja representação binária tem apenas um bit ativado.

68
00:04:03,640 --> 00:04:08,102
O que isso significa é que cada um desses bits de paridade

69
00:04:08,102 --> 00:04:12,640
está dentro de um e apenas um dos quatro grupos de paridade.

70
00:04:12,640 --> 00:04:20,291
Você também pode ver isso em exemplos maiores, onde não importa quão grande você seja,

71
00:04:20,291 --> 00:04:25,920
cada bit de paridade toca convenientemente apenas um dos grupos.

72
00:04:25,920 --> 00:04:29,484
Depois de entender que essas verificações de paridade nas quais nos concentramos

73
00:04:29,484 --> 00:04:33,005
tanto em nosso tempo nada mais são do que uma maneira inteligente de explicar a

74
00:04:33,005 --> 00:04:36,482
posição de um erro em binário, então poderemos estabelecer uma conexão com uma

75
00:04:36,482 --> 00:04:38,726
maneira diferente de pensar sobre hamming códigos,

76
00:04:38,726 --> 00:04:40,971
que são sem dúvida muito mais simples e elegantes,

77
00:04:40,971 --> 00:04:43,920
e que basicamente podem ser escritos com uma única linha de código.

78
00:04:43,920 --> 00:04:46,200
É baseado na função XOR.

79
00:04:46,200 --> 00:04:50,960
XOR, para quem não sabe, significa exclusivo ou.

80
00:04:50,960 --> 00:04:56,809
Quando você pega o XOR de dois bits, ele retornará 1 se um desses bits estiver ativado,

81
00:04:56,809 --> 00:05:00,200
mas não se ambos estiverem ativados ou desativados.

82
00:05:00,200 --> 00:05:03,760
Em outras palavras, é a paridade desses dois bits.

83
00:05:03,760 --> 00:05:07,840
Como um especialista em matemática, prefiro pensar nisso como um mod de adição 2.

84
00:05:07,840 --> 00:05:11,469
Também costumamos falar sobre o XOR de duas cadeias de bits diferentes,

85
00:05:11,469 --> 00:05:14,040
que basicamente faz isso componente por componente.

86
00:05:14,040 --> 00:05:16,280
É como uma adição, mas onde você nunca carrega.

87
00:05:16,280 --> 00:05:19,721
Novamente, os mais inclinados à matemática podem preferir

88
00:05:19,721 --> 00:05:23,520
pensar nisso como a adição de dois vetores e a redução do mod 2.

89
00:05:23,520 --> 00:05:27,160
Se você abrir algum Python agora e aplicar a operação de

90
00:05:27,160 --> 00:05:31,312
intercalação entre dois inteiros, isso é o que ele está fazendo,

91
00:05:31,312 --> 00:05:35,400
exceto nas representações de bits desses números nos bastidores.

92
00:05:35,400 --> 00:05:40,778
O ponto principal para você e para mim é que obter o XOR de muitas cadeias

93
00:05:40,778 --> 00:05:46,013
de bits diferentes é efetivamente uma maneira de calcular as paródias de

94
00:05:46,013 --> 00:05:51,320
vários grupos separados, como acontece com as colunas, tudo de uma só vez.

95
00:05:51,320 --> 00:05:54,076
Isso nos dá uma maneira bastante elegante de pensar sobre as

96
00:05:54,076 --> 00:05:56,968
múltiplas verificações de paridade de nosso algoritmo de código

97
00:05:56,968 --> 00:05:59,680
de Hamming como sendo todas agrupadas em uma única operação.

98
00:05:59,680 --> 00:06:02,800
Embora à primeira vista pareça muito diferente.

99
00:06:02,800 --> 00:06:08,202
Anote especificamente as 16 posições em binário, como fizemos antes,

100
00:06:08,202 --> 00:06:14,075
e agora destaque as posições onde o bit da mensagem está ativado para 1 e,

101
00:06:14,075 --> 00:06:19,400
em seguida, reúna essas posições em uma grande coluna e pegue o XOR.

102
00:06:19,400 --> 00:06:23,738
Você provavelmente pode adivinhar que os 4 bits na parte inferior como

103
00:06:23,738 --> 00:06:28,381
resultado são iguais às 4 verificações de paridade que conhecemos e amamos,

104
00:06:28,381 --> 00:06:32,720
mas reserve um momento para realmente pensar sobre o porquê exatamente.

105
00:06:32,720 --> 00:06:37,405
Esta última coluna, por exemplo, está contando todas as posições cujo último bit é 1,

106
00:06:37,405 --> 00:06:40,456
mas já estamos limitados apenas às posições destacadas,

107
00:06:40,456 --> 00:06:44,979
portanto está contando efetivamente quantas posições destacadas vieram do primeiro

108
00:06:44,979 --> 00:06:45,960
grupo de paridade.

109
00:06:45,960 --> 00:06:48,520
Isso faz sentido?

110
00:06:48,520 --> 00:06:54,103
Da mesma forma, a próxima coluna conta quantas posições estão no segundo grupo de

111
00:06:54,103 --> 00:06:59,346
paridade, as posições cujo penúltimo bit é 1, e que também estão destacadas,

112
00:06:59,346 --> 00:07:00,640
e assim por diante.

113
00:07:00,640 --> 00:07:04,900
Na verdade, é apenas uma pequena mudança de perspectiva

114
00:07:04,900 --> 00:07:07,640
sobre a mesma coisa que temos feito.

115
00:07:07,640 --> 00:07:10,000
E então você sabe para onde vai a partir daqui.

116
00:07:10,000 --> 00:07:14,733
O remetente é responsável por alternar alguns dos bits

117
00:07:14,733 --> 00:07:19,640
de paridade especiais para garantir que a soma seja 0000.

118
00:07:19,640 --> 00:07:22,666
Agora, uma vez que temos isto, isto dá-nos uma maneira muito

119
00:07:22,666 --> 00:07:25,792
boa de pensar sobre porque é que estes quatro bits resultantes

120
00:07:25,792 --> 00:07:28,720
na parte inferior indicam diretamente a posição de um erro.

121
00:07:28,720 --> 00:07:32,720
Digamos que algum bit neste bloco seja alternado de 0 para 1.

122
00:07:32,720 --> 00:07:39,073
O que isso significa é que a posição desse bit agora será incluída no XOR total,

123
00:07:39,073 --> 00:07:44,800
o que muda a soma de 0 para esse valor recém-incluído, a posição do erro.

124
00:07:44,800 --> 00:07:49,800
Um pouco menos óbvio, o mesmo acontece se houver um erro que mude 1 para 0.

125
00:07:49,800 --> 00:07:53,638
Veja bem, se você somar uma sequência de bits duas vezes,

126
00:07:53,638 --> 00:07:59,000
é o mesmo que não tê-la ali, basicamente porque neste mundo 1 mais 1 é igual a 0.

127
00:07:59,000 --> 00:08:05,400
Portanto, adicionar uma cópia desta posição à soma total tem o mesmo efeito que a movemos.

128
00:08:05,400 --> 00:08:09,160
E esse efeito, mais uma vez, é que o resultado

129
00:08:09,160 --> 00:08:13,480
total na parte inferior aqui indica a posição do erro.

130
00:08:13,480 --> 00:08:17,665
Para ilustrar o quão elegante isso é, deixe-me mostrar aquela linha de código

131
00:08:17,665 --> 00:08:22,120
Python que mencionei antes, que capturará quase toda a lógica no final do receptor.

132
00:08:22,120 --> 00:08:27,117
Começaremos criando um array aleatório de 16 1s e 0s para simular o bloco de dados,

133
00:08:27,117 --> 00:08:31,163
e darei a ele o nome de bits, mas é claro que na prática isso seria

134
00:08:31,163 --> 00:08:35,208
algo que receberíamos de um remetente e, em vez de sendo aleatório,

135
00:08:35,208 --> 00:08:38,600
carregaria 11 bits de dados junto com 5 bits de paridade.

136
00:08:38,600 --> 00:08:43,420
Se eu chamar a função enumerateBits, o que ela faz é emparelhar cada um

137
00:08:43,420 --> 00:08:48,240
desses bits com um índice correspondente, neste caso variando de 0 a 15.

138
00:08:48,240 --> 00:08:52,139
Então, se criarmos uma lista que percorre todos esses pares,

139
00:08:52,139 --> 00:08:56,294
pares que se parecem com i, e então extrairmos apenas o valor i,

140
00:08:56,294 --> 00:09:01,920
apenas o índice, bem, não é tão emocionante, apenas recuperamos esses índices de 0 a 15.

141
00:09:01,920 --> 00:09:06,575
Mas se adicionarmos a condição de fazer isso apenas se for bit, ou seja,

142
00:09:06,575 --> 00:09:11,614
se esse bit for 1 e não 0, bem, então ele retira apenas as posições onde o bit

143
00:09:11,614 --> 00:09:13,400
correspondente está ativado.

144
00:09:13,400 --> 00:09:20,720
Neste caso, parece que essas posições são 0, 4, 6, 9, etc.

145
00:09:20,720 --> 00:09:27,475
O que queremos é reunir todas essas posições, as posições dos bits que estão ativados,

146
00:09:27,475 --> 00:09:29,960
e então fazer um XOR entre elas.

147
00:09:29,960 --> 00:09:33,960
Para fazer isso em Python, primeiro vou importar algumas funções úteis.

148
00:09:33,960 --> 00:09:39,140
Dessa forma podemos chamar reduzir() nesta lista e usar a função XOR para reduzi-la.

149
00:09:39,140 --> 00:09:44,840
Isso basicamente percorre a lista, levando XORs ao longo do caminho.

150
00:09:44,840 --> 00:09:48,484
Se preferir, você pode escrever explicitamente essa

151
00:09:48,484 --> 00:09:52,200
função XOR sem precisar importá-la de qualquer lugar.

152
00:09:52,200 --> 00:09:58,213
Então, no momento, parece que se fizermos isso em nosso bloco aleatório de 16 bits,

153
00:09:58,213 --> 00:10:02,080
ele retornará 9, que tem a representação binária 1001.

154
00:10:02,080 --> 00:10:05,710
Não faremos isso aqui, mas você poderia escrever uma função onde o

155
00:10:05,710 --> 00:10:09,450
remetente usa essa representação binária para definir os quatro bits

156
00:10:09,450 --> 00:10:13,081
de paridade conforme necessário, levando esse bloco a um estado em

157
00:10:13,081 --> 00:10:17,200
que a execução dessa linha de código na lista completa de bits retorna um 0.

158
00:10:17,200 --> 00:10:20,200
Este seria considerado um bloco bem preparado.

159
00:10:20,200 --> 00:10:24,277
O que é legal é que se alternarmos qualquer um dos bits desta lista,

160
00:10:24,277 --> 00:10:29,181
simulando um erro aleatório de ruído, se você executar essa mesma linha de código,

161
00:10:29,181 --> 00:10:30,600
esse erro será impresso.

162
00:10:30,600 --> 00:10:31,920
Não é legal?

163
00:10:31,920 --> 00:10:37,345
Você pode obter esse bloco do nada, executar esta única linha nele e ele

164
00:10:37,345 --> 00:10:42,920
exibirá automaticamente a posição de um erro ou um 0, se não houver nenhum.

165
00:10:42,920 --> 00:10:45,520
E não há nada de especial no tamanho 16 aqui.

166
00:10:45,520 --> 00:10:52,280
A mesma linha de código funcionaria se você tivesse uma lista de, digamos, 256 bits.

167
00:10:52,280 --> 00:10:55,549
Escusado será dizer que há mais código para escrever aqui,

168
00:10:55,549 --> 00:10:59,538
como fazer a verificação de metaparidade para detectar erros de 2 bits,

169
00:10:59,538 --> 00:11:03,694
mas a ideia é que quase toda a lógica central do nosso esquema se reduza a

170
00:11:03,694 --> 00:11:05,080
uma única redução de XOR.

171
00:11:05,080 --> 00:11:09,545
Agora, dependendo do seu conforto com binários, XORs e software em geral,

172
00:11:09,545 --> 00:11:14,070
você pode achar essa perspectiva um pouco confusa ou muito mais elegante e

173
00:11:14,070 --> 00:11:19,320
simples que você está se perguntando por que não começamos com ela desde o início. -ir.

174
00:11:19,320 --> 00:11:23,276
Falando livremente, a perspectiva de verificação de paridade múltipla é mais fácil

175
00:11:23,276 --> 00:11:27,137
de pensar ao implementar códigos de Hamming em hardware de maneira muito direta,

176
00:11:27,137 --> 00:11:31,380
e a perspectiva XOR é mais fácil de pensar ao fazê-lo em software, de um nível mais alto.

177
00:11:31,380 --> 00:11:36,319
O primeiro é mais fácil de fazer manualmente, e acho que faz um trabalho melhor ao

178
00:11:36,319 --> 00:11:39,355
incutir a intuição central subjacente a tudo isso,

179
00:11:39,355 --> 00:11:44,294
que é que a informação necessária para localizar um único erro está relacionada ao

180
00:11:44,294 --> 00:11:47,211
log do tamanho do bloco , ou em outras palavras,

181
00:11:47,211 --> 00:11:51,020
cresce um bit de cada vez à medida que o tamanho do bloco dobra.

182
00:11:51,020 --> 00:11:53,856
O fato relevante aqui é que essa informação corresponde

183
00:11:53,856 --> 00:11:56,440
diretamente à quantidade de redundância necessária.

184
00:11:56,440 --> 00:12:00,117
Isso é realmente o que vai contra a reação instintiva da maioria das pessoas

185
00:12:00,117 --> 00:12:03,699
quando pensam pela primeira vez em tornar uma mensagem resistente a erros,

186
00:12:03,699 --> 00:12:07,520
onde geralmente copiar a mensagem inteira é o primeiro instinto que vem à mente.

187
00:12:07,520 --> 00:12:11,205
E então, a propósito, há toda essa outra maneira que às vezes você vê os códigos

188
00:12:11,205 --> 00:12:14,800
de Hamming apresentados, onde você multiplica a mensagem por uma grande matriz.

189
00:12:14,800 --> 00:12:19,455
É bom porque o relaciona com a família mais ampla de códigos lineares,

190
00:12:19,455 --> 00:12:25,160
mas acho que isso quase não dá nenhuma intuição de onde ele vem ou como é dimensionado.

191
00:12:25,160 --> 00:12:28,600
E por falar em dimensionamento, você deve notar que a eficiência

192
00:12:28,600 --> 00:12:32,200
desse esquema só melhora à medida que aumentamos o tamanho do bloco.

193
00:12:32,200 --> 00:12:37,547
Por exemplo, vimos que com 256 bits, você está usando apenas 3%

194
00:12:37,547 --> 00:12:43,480
desse espaço para redundância, e isso continua melhorando a partir daí.

195
00:12:43,480 --> 00:12:46,871
À medida que o número de bits de paridade aumenta um por um,

196
00:12:46,871 --> 00:12:49,040
o tamanho do bloco continua duplicando.

197
00:12:49,040 --> 00:12:52,960
E se você levar isso ao extremo, você poderia ter um bloco com, digamos,

198
00:12:52,960 --> 00:12:56,772
um milhão de bits, onde você estaria literalmente jogando 20 perguntas

199
00:12:56,772 --> 00:13:00,800
com suas verificações de paridade, e ele usaria apenas 21 bits de paridade.

200
00:13:00,800 --> 00:13:06,216
E se você pensar em olhar para um milhão de bits e localizar um único erro,

201
00:13:06,216 --> 00:13:08,640
isso realmente parece uma loucura.

202
00:13:08,640 --> 00:13:13,529
O problema, claro, é que com um bloco maior, a probabilidade de ver mais de um ou

203
00:13:13,529 --> 00:13:18,360
dois erros de bit aumenta, e os códigos de Hamming não lidam com nada além disso.

204
00:13:18,360 --> 00:13:22,499
Então, na prática, o que você deseja é encontrar o tamanho certo para

205
00:13:22,499 --> 00:13:26,520
que a probabilidade de muitas inversões de bits não seja muito alta.

206
00:13:26,520 --> 00:13:31,145
Além disso, na prática, os erros tendem a ocorrer em pequenas rajadas,

207
00:13:31,145 --> 00:13:34,664
o que arruinaria totalmente um único bloco, portanto,

208
00:13:34,664 --> 00:13:39,290
uma tática comum para ajudar a espalhar uma rajada de erros por muitos

209
00:13:39,290 --> 00:13:42,678
blocos diferentes é entrelaçar esses blocos, assim,

210
00:13:42,678 --> 00:13:45,480
antes que eles sejam enviado ou armazenado.

211
00:13:45,480 --> 00:13:49,778
Por outro lado, muito disso é completamente discutível por códigos mais modernos,

212
00:13:49,778 --> 00:13:52,870
como o algoritmo Reed-Solomon, muito mais comumente usado,

213
00:13:52,870 --> 00:13:57,064
que lida particularmente bem com erros de explosão e pode ser ajustado para ser

214
00:13:57,064 --> 00:13:59,580
resiliente a um número maior de erros por bloco.

215
00:13:59,580 --> 00:14:03,000
Mas isso é assunto para outra hora.

216
00:14:03,000 --> 00:14:05,961
Em seu livro The Art of Doing Science and Engineering,

217
00:14:05,961 --> 00:14:10,700
Hamming é maravilhosamente sincero sobre o quão sinuosa foi sua descoberta desse código.

218
00:14:10,700 --> 00:14:14,607
Ele primeiro tentou todos os tipos de esquemas diferentes envolvendo a organização

219
00:14:14,607 --> 00:14:18,420
dos bits em partes de uma rede dimensional superior e coisas estranhas como esta.

220
00:14:18,420 --> 00:14:21,956
A ideia de que seria possível fazer com que as verificações de paridade

221
00:14:21,956 --> 00:14:25,590
conspirassem de uma forma que explicitasse a posição de um erro só surgiu

222
00:14:25,590 --> 00:14:29,225
a Hamming quando ele recuou após um monte de outras análises e perguntou:

223
00:14:29,225 --> 00:14:32,860
ok, qual é o mais eficiente que eu poderia concebivelmente ser sobre isso?

224
00:14:32,860 --> 00:14:37,391
Ele também foi sincero sobre a importância de já ter em mente as verificações

225
00:14:37,391 --> 00:14:42,040
de paridade, o que teria sido muito menos comum na década de 1940 do que é hoje.

226
00:14:42,040 --> 00:14:45,543
Há cerca de meia dúzia de vezes ao longo deste livro que ele faz

227
00:14:45,543 --> 00:14:49,640
referência à citação de Louis Pasteur: a sorte favorece uma mente preparada.

228
00:14:49,640 --> 00:14:53,433
Ideias inteligentes muitas vezes parecem enganosamente simples em retrospectiva,

229
00:14:53,433 --> 00:14:55,120
o que as torna fáceis de subestimar.

230
00:14:55,120 --> 00:14:58,165
No momento, minha sincera esperança é que os códigos de Hamming,

231
00:14:58,165 --> 00:15:01,820
ou pelo menos a possibilidade de tais códigos, pareçam quase óbvios para você.

232
00:15:01,820 --> 00:15:06,084
Mas você não deve se enganar pensando que eles são realmente óbvios,

233
00:15:06,084 --> 00:15:08,000
porque definitivamente não são.

234
00:15:08,000 --> 00:15:11,892
Parte da razão pela qual ideias inteligentes parecem enganosamente fáceis é

235
00:15:11,892 --> 00:15:15,221
que só vemos o resultado final, limpando o que estava bagunçado,

236
00:15:15,221 --> 00:15:19,063
nunca mencionando todos os caminhos errados, subestimando o quão vasto é o

237
00:15:19,063 --> 00:15:23,467
espaço de possibilidades exploráveis no início de um problema. processo de resolução,

238
00:15:23,467 --> 00:15:23,980
tudo isso.

239
00:15:23,980 --> 00:15:25,280
Mas isso é verdade em geral.

240
00:15:25,280 --> 00:15:28,188
Acho que, para algumas invenções especiais, há uma

241
00:15:28,188 --> 00:15:31,040
segunda razão mais profunda para as subestimarmos.

242
00:15:31,040 --> 00:15:35,708
Pensar na informação em termos de bits só se consolidou numa teoria completa em 1948,

243
00:15:35,708 --> 00:15:39,400
com o artigo seminal de Claude Shannon sobre a teoria da informação.

244
00:15:39,400 --> 00:15:43,440
Isso ocorreu essencialmente ao mesmo tempo em que Hamming desenvolveu seu algoritmo.

245
00:15:43,440 --> 00:15:46,848
Este foi o mesmo artigo fundamental que mostrou, em certo sentido,

246
00:15:46,848 --> 00:15:49,544
que a correção eficiente de erros é sempre possível,

247
00:15:49,544 --> 00:15:53,920
não importa quão alta seja a probabilidade de inversões de bits, pelo menos em teoria.

248
00:15:53,920 --> 00:15:57,322
Shannon e Hamming, aliás, dividiam um escritório no Bell Labs,

249
00:15:57,322 --> 00:16:00,023
apesar de trabalharem em coisas muito diferentes,

250
00:16:00,023 --> 00:16:02,400
o que dificilmente parece coincidência aqui.

251
00:16:02,400 --> 00:16:07,612
Avançando várias décadas, hoje em dia muitos de nós estamos tão imersos em pensar

252
00:16:07,612 --> 00:16:13,080
sobre bits e informações que é fácil ignorar o quão distinta era essa forma de pensar.

253
00:16:13,080 --> 00:16:15,500
Ironicamente, as ideias que moldam mais profundamente a forma como uma geração futura

254
00:16:15,500 --> 00:16:17,920
pensa acabarão por parecer para essa geração futura mais simples do que realmente são.

