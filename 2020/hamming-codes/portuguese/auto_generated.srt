1
00:00:00,000 --> 00:00:03,120
Presumo que todos aqui venham da parte 1.

2
00:00:03,120 --> 00:00:06,975
Estávamos falando sobre códigos de Hamming, uma forma de criar um bloco de dados

3
00:00:06,975 --> 00:00:10,592
onde a maioria dos bits carrega uma mensagem significativa, enquanto alguns

4
00:00:10,592 --> 00:00:14,400
outros atuam como uma espécie de redundância, de tal forma que se algum bit for

5
00:00:14,400 --> 00:00:18,064
invertido, será uma mensagem bit ou bit de redundância, qualquer coisa neste

6
00:00:18,064 --> 00:00:21,920
bloco, um receptor será capaz de identificar que houve um erro e como corrigi-lo.

7
00:00:21,920 --> 00:00:25,414
A ideia básica apresentada foi como usar múltiplas

8
00:00:25,414 --> 00:00:29,800
verificações de paridade para pesquisar binariamente até o erro.

9
00:00:29,800 --> 00:00:32,400
Nesse vídeo, o objetivo era fazer com que os códigos de

10
00:00:32,400 --> 00:00:35,420
Hamming parecessem tão práticos e redescobríveis quanto possível.

11
00:00:35,420 --> 00:00:38,366
Mas quando você começa a pensar em realmente implementar isso,

12
00:00:38,366 --> 00:00:41,079
seja em software ou hardware, esse enquadramento pode, na

13
00:00:41,079 --> 00:00:44,120
verdade, subestimar o quão elegantes esses códigos realmente são.

14
00:00:44,120 --> 00:00:47,565
Você pode pensar que precisa escrever um algoritmo que monitore todos

15
00:00:47,565 --> 00:00:50,813
os possíveis locais de erro e corte esse grupo pela metade a cada

16
00:00:50,813 --> 00:00:54,160
verificação, mas na verdade é muito, muito mais simples do que isso.

17
00:00:54,160 --> 00:00:57,629
Se você ler as respostas às quatro verificações de paridade

18
00:00:57,629 --> 00:01:01,214
que fizemos no último vídeo, todas como 1s e 0s em vez de sim

19
00:01:01,214 --> 00:01:04,800
e não, isso literalmente explica a posição do erro em binário.

20
00:01:04,800 --> 00:01:08,458
Por exemplo, o número 7 em binário se parece com

21
00:01:08,458 --> 00:01:12,640
0111, significando essencialmente que é 4 mais 2 mais 1.

22
00:01:12,640 --> 00:01:17,460
E observe onde fica a posição 7, ela afeta o primeiro de nossos

23
00:01:17,460 --> 00:01:22,280
grupos de paridade, e o segundo, e o terceiro, mas não o último.

24
00:01:22,280 --> 00:01:25,400
Portanto, ler os resultados dessas quatro verificações

25
00:01:25,400 --> 00:01:28,520
de baixo para cima realmente explica a posição do erro.

26
00:01:28,520 --> 00:01:33,160
Não há nada de especial no exemplo 7, ele funciona em geral e torna a lógica

27
00:01:33,160 --> 00:01:37,440
para implementar todo o esquema em hardware surpreendentemente simples.

28
00:01:37,440 --> 00:01:41,759
Agora se você quiser ver por que essa mágica acontece, pegue esses

29
00:01:41,759 --> 00:01:46,207
16 rótulos de índice para nossas posições, mas em vez de escrevê-los

30
00:01:46,207 --> 00:01:50,720
na base 10, vamos escrevê-los todos em binário, indo de 0000 até 1111.

31
00:01:50,720 --> 00:01:54,398
Ao colocarmos esses rótulos binários de volta em suas caixas, deixe-me

32
00:01:54,398 --> 00:01:58,440
enfatizar que eles são distintos dos dados que estão sendo realmente enviados.

33
00:01:58,440 --> 00:02:01,412
Eles nada mais são do que um rótulo conceitual para ajudar você

34
00:02:01,412 --> 00:02:04,200
e eu a entender de onde vieram os quatro grupos de paridade.

35
00:02:04,200 --> 00:02:08,621
A elegância de ter tudo o que estamos vendo descrito em binário talvez seja

36
00:02:08,621 --> 00:02:13,160
prejudicada pela confusão de ter tudo o que estamos vendo descrito em binário.

37
00:02:13,160 --> 00:02:15,040
Vale a pena, no entanto.

38
00:02:15,040 --> 00:02:19,405
Concentre sua atenção apenas na última parte de todos esses

39
00:02:19,405 --> 00:02:24,280
rótulos e, em seguida, destaque as posições onde a parte final é 1.

40
00:02:24,280 --> 00:02:28,413
O que obtemos é o primeiro dos nossos quatro grupos de paridade, o que

41
00:02:28,413 --> 00:02:32,546
significa que você pode interpretar essa primeira verificação como uma

42
00:02:32,546 --> 00:02:36,680
pergunta: ei, se houver um erro, o bit final na posição desse erro é 1?

43
00:02:36,680 --> 00:02:41,533
Da mesma forma, se você focar no penúltimo bit e destacar todas as

44
00:02:41,533 --> 00:02:47,040
posições onde é 1, você obterá o segundo grupo de paridade do nosso esquema.

45
00:02:47,040 --> 00:02:51,493
Em outras palavras, essa segunda verificação está perguntando,

46
00:02:51,493 --> 00:02:56,160
ei, de novo, se houver um erro, o penúltimo bit dessa posição é 1?

47
00:02:56,160 --> 00:02:57,160
E assim por diante.

48
00:02:57,160 --> 00:03:03,306
A terceira verificação de paridade cobre todas as posições cujo penúltimo bit está

49
00:03:03,306 --> 00:03:09,823
ativado, e a última cobre as últimas oito posições, aquelas cujo bit de ordem mais alta

50
00:03:09,823 --> 00:03:10,120
é 1.

51
00:03:10,120 --> 00:03:14,926
Tudo o que fizemos anteriormente é o mesmo que responder a estas quatro

52
00:03:14,926 --> 00:03:19,800
perguntas, que por sua vez é o mesmo que soletrar uma posição em binário.

53
00:03:19,800 --> 00:03:22,080
Espero que isso deixe duas coisas mais claras.

54
00:03:22,080 --> 00:03:24,562
A primeira é como generalizar sistematicamente para

55
00:03:24,562 --> 00:03:27,140
tamanhos de bloco maiores que sejam potências de dois.

56
00:03:27,140 --> 00:03:30,849
Se forem necessários mais bits para descrever cada posição,

57
00:03:30,849 --> 00:03:34,683
como seis bits para descrever 64 pontos, então cada um desses

58
00:03:34,683 --> 00:03:38,640
bits fornece um dos grupos de paridade que precisamos verificar.

59
00:03:38,640 --> 00:03:41,088
Aqueles de vocês que assistiram ao quebra-cabeça do tabuleiro de xadrez

60
00:03:41,088 --> 00:03:43,400
que fiz com Matt Parker podem achar tudo isso extremamente familiar.

61
00:03:43,400 --> 00:03:46,494
É a mesma lógica central, mas resolvendo um problema

62
00:03:46,494 --> 00:03:49,880
diferente e aplicada a um tabuleiro de xadrez de 64 casas.

63
00:03:49,880 --> 00:03:53,933
A segunda coisa que espero que isso deixe claro é por que nossos bits de

64
00:03:53,933 --> 00:03:58,320
paridade estão em posições que são potências de dois, por exemplo, 1, 2, 4 e 8.

65
00:03:58,320 --> 00:04:03,640
Estas são as posições cuja representação binária tem apenas um bit ativado.

66
00:04:03,640 --> 00:04:08,102
O que isso significa é que cada um desses bits de paridade

67
00:04:08,102 --> 00:04:12,640
está dentro de um e apenas um dos quatro grupos de paridade.

68
00:04:12,640 --> 00:04:19,323
Você também pode ver isso em exemplos maiores, onde não importa quão grande

69
00:04:19,323 --> 00:04:25,920
você seja, cada bit de paridade toca convenientemente apenas um dos grupos.

70
00:04:25,920 --> 00:04:29,484
Depois de entender que essas verificações de paridade nas quais nos concentramos

71
00:04:29,484 --> 00:04:33,005
tanto em nosso tempo nada mais são do que uma maneira inteligente de explicar a

72
00:04:33,005 --> 00:04:36,482
posição de um erro em binário, então poderemos estabelecer uma conexão com uma

73
00:04:36,482 --> 00:04:40,047
maneira diferente de pensar sobre hamming códigos, que são sem dúvida muito mais

74
00:04:40,047 --> 00:04:43,920
simples e elegantes, e que basicamente podem ser escritos com uma única linha de código.

75
00:04:43,920 --> 00:04:46,200
É baseado na função XOR.

76
00:04:46,200 --> 00:04:50,960
XOR, para quem não sabe, significa exclusivo ou.

77
00:04:50,960 --> 00:04:55,679
Quando você pega o XOR de dois bits, ele retornará 1 se um desses bits

78
00:04:55,679 --> 00:05:00,200
estiver ativado, mas não se ambos estiverem ativados ou desativados.

79
00:05:00,200 --> 00:05:03,760
Em outras palavras, é a paridade desses dois bits.

80
00:05:03,760 --> 00:05:07,840
Como um especialista em matemática, prefiro pensar nisso como um mod de adição 2.

81
00:05:07,840 --> 00:05:10,864
Também costumamos falar sobre o XOR de duas cadeias de bits

82
00:05:10,864 --> 00:05:14,040
diferentes, que basicamente faz isso componente por componente.

83
00:05:14,040 --> 00:05:16,280
É como uma adição, mas onde você nunca carrega.

84
00:05:16,280 --> 00:05:19,721
Novamente, os mais inclinados à matemática podem preferir

85
00:05:19,721 --> 00:05:23,520
pensar nisso como a adição de dois vetores e a redução do mod 2.

86
00:05:23,520 --> 00:05:27,160
Se você abrir algum Python agora e aplicar a operação de

87
00:05:27,160 --> 00:05:31,312
intercalação entre dois inteiros, isso é o que ele está fazendo,

88
00:05:31,312 --> 00:05:35,400
exceto nas representações de bits desses números nos bastidores.

89
00:05:35,400 --> 00:05:40,778
O ponto principal para você e para mim é que obter o XOR de muitas cadeias

90
00:05:40,778 --> 00:05:46,013
de bits diferentes é efetivamente uma maneira de calcular as paródias de

91
00:05:46,013 --> 00:05:51,320
vários grupos separados, como acontece com as colunas, tudo de uma só vez.

92
00:05:51,320 --> 00:05:54,076
Isso nos dá uma maneira bastante elegante de pensar sobre as

93
00:05:54,076 --> 00:05:56,968
múltiplas verificações de paridade de nosso algoritmo de código

94
00:05:56,968 --> 00:05:59,680
de Hamming como sendo todas agrupadas em uma única operação.

95
00:05:59,680 --> 00:06:02,800
Embora à primeira vista pareça muito diferente.

96
00:06:02,800 --> 00:06:08,202
Anote especificamente as 16 posições em binário, como fizemos antes,

97
00:06:08,202 --> 00:06:13,683
e agora destaque as posições onde o bit da mensagem está ativado para

98
00:06:13,683 --> 00:06:19,400
1 e, em seguida, reúna essas posições em uma grande coluna e pegue o XOR.

99
00:06:19,400 --> 00:06:23,738
Você provavelmente pode adivinhar que os 4 bits na parte inferior como

100
00:06:23,738 --> 00:06:27,893
resultado são iguais às 4 verificações de paridade que conhecemos e

101
00:06:27,893 --> 00:06:32,720
amamos, mas reserve um momento para realmente pensar sobre o porquê exatamente.

102
00:06:32,720 --> 00:06:37,133
Esta última coluna, por exemplo, está contando todas as posições cujo último bit

103
00:06:37,133 --> 00:06:41,710
é 1, mas já estamos limitados apenas às posições destacadas, portanto está contando

104
00:06:41,710 --> 00:06:45,960
efetivamente quantas posições destacadas vieram do primeiro grupo de paridade.

105
00:06:45,960 --> 00:06:48,520
Isso faz sentido?

106
00:06:48,520 --> 00:06:54,103
Da mesma forma, a próxima coluna conta quantas posições estão no segundo grupo de

107
00:06:54,103 --> 00:07:00,163
paridade, as posições cujo penúltimo bit é 1, e que também estão destacadas, e assim por

108
00:07:00,163 --> 00:07:00,640
diante.

109
00:07:00,640 --> 00:07:04,900
Na verdade, é apenas uma pequena mudança de perspectiva

110
00:07:04,900 --> 00:07:07,640
sobre a mesma coisa que temos feito.

111
00:07:07,640 --> 00:07:10,000
E então você sabe para onde vai a partir daqui.

112
00:07:10,000 --> 00:07:14,733
O remetente é responsável por alternar alguns dos bits

113
00:07:14,733 --> 00:07:19,640
de paridade especiais para garantir que a soma seja 0000.

114
00:07:19,640 --> 00:07:22,666
Agora, uma vez que temos isto, isto dá-nos uma maneira muito

115
00:07:22,666 --> 00:07:25,792
boa de pensar sobre porque é que estes quatro bits resultantes

116
00:07:25,792 --> 00:07:28,720
na parte inferior indicam diretamente a posição de um erro.

117
00:07:28,720 --> 00:07:32,720
Digamos que algum bit neste bloco seja alternado de 0 para 1.

118
00:07:32,720 --> 00:07:38,524
O que isso significa é que a posição desse bit agora será incluída no XOR

119
00:07:38,524 --> 00:07:44,800
total, o que muda a soma de 0 para esse valor recém-incluído, a posição do erro.

120
00:07:44,800 --> 00:07:49,800
Um pouco menos óbvio, o mesmo acontece se houver um erro que mude 1 para 0.

121
00:07:49,800 --> 00:07:54,300
Veja bem, se você somar uma sequência de bits duas vezes, é o mesmo

122
00:07:54,300 --> 00:07:59,000
que não tê-la ali, basicamente porque neste mundo 1 mais 1 é igual a 0.

123
00:07:59,000 --> 00:08:05,400
Portanto, adicionar uma cópia desta posição à soma total tem o mesmo efeito que a movemos.

124
00:08:05,400 --> 00:08:09,160
E esse efeito, mais uma vez, é que o resultado

125
00:08:09,160 --> 00:08:13,480
total na parte inferior aqui indica a posição do erro.

126
00:08:13,480 --> 00:08:17,665
Para ilustrar o quão elegante isso é, deixe-me mostrar aquela linha de código

127
00:08:17,665 --> 00:08:22,120
Python que mencionei antes, que capturará quase toda a lógica no final do receptor.

128
00:08:22,120 --> 00:08:26,165
Começaremos criando um array aleatório de 16 1s e 0s para simular o

129
00:08:26,165 --> 00:08:30,032
bloco de dados, e darei a ele o nome de bits, mas é claro que na

130
00:08:30,032 --> 00:08:34,197
prática isso seria algo que receberíamos de um remetente e, em vez de

131
00:08:34,197 --> 00:08:38,600
sendo aleatório, carregaria 11 bits de dados junto com 5 bits de paridade.

132
00:08:38,600 --> 00:08:43,420
Se eu chamar a função enumerateBits, o que ela faz é emparelhar cada um

133
00:08:43,420 --> 00:08:48,240
desses bits com um índice correspondente, neste caso variando de 0 a 15.

134
00:08:48,240 --> 00:08:52,778
Então, se criarmos uma lista que percorre todos esses pares, pares que

135
00:08:52,778 --> 00:08:57,381
se parecem com i, e então extrairmos apenas o valor i, apenas o índice,

136
00:08:57,381 --> 00:09:01,920
bem, não é tão emocionante, apenas recuperamos esses índices de 0 a 15.

137
00:09:01,920 --> 00:09:07,596
Mas se adicionarmos a condição de fazer isso apenas se for bit, ou seja, se esse bit for

138
00:09:07,596 --> 00:09:12,889
1 e não 0, bem, então ele retira apenas as posições onde o bit correspondente está

139
00:09:12,889 --> 00:09:13,400
ativado.

140
00:09:13,400 --> 00:09:20,720
Neste caso, parece que essas posições são 0, 4, 6, 9, etc.

141
00:09:20,720 --> 00:09:25,223
O que queremos é reunir todas essas posições, as posições

142
00:09:25,223 --> 00:09:29,960
dos bits que estão ativados, e então fazer um XOR entre elas.

143
00:09:29,960 --> 00:09:33,960
Para fazer isso em Python, primeiro vou importar algumas funções úteis.

144
00:09:33,960 --> 00:09:39,140
Dessa forma podemos chamar reduzir() nesta lista e usar a função XOR para reduzi-la.

145
00:09:39,140 --> 00:09:44,840
Isso basicamente percorre a lista, levando XORs ao longo do caminho.

146
00:09:44,840 --> 00:09:48,484
Se preferir, você pode escrever explicitamente essa

147
00:09:48,484 --> 00:09:52,200
função XOR sem precisar importá-la de qualquer lugar.

148
00:09:52,200 --> 00:09:57,354
Então, no momento, parece que se fizermos isso em nosso bloco aleatório

149
00:09:57,354 --> 00:10:02,080
de 16 bits, ele retornará 9, que tem a representação binária 1001.

150
00:10:02,080 --> 00:10:05,710
Não faremos isso aqui, mas você poderia escrever uma função onde o

151
00:10:05,710 --> 00:10:09,450
remetente usa essa representação binária para definir os quatro bits

152
00:10:09,450 --> 00:10:13,081
de paridade conforme necessário, levando esse bloco a um estado em

153
00:10:13,081 --> 00:10:17,200
que a execução dessa linha de código na lista completa de bits retorna um 0.

154
00:10:17,200 --> 00:10:20,200
Este seria considerado um bloco bem preparado.

155
00:10:20,200 --> 00:10:25,340
O que é legal é que se alternarmos qualquer um dos bits desta lista, simulando um erro

156
00:10:25,340 --> 00:10:30,600
aleatório de ruído, se você executar essa mesma linha de código, esse erro será impresso.

157
00:10:30,600 --> 00:10:31,920
Não é legal?

158
00:10:31,920 --> 00:10:37,345
Você pode obter esse bloco do nada, executar esta única linha nele e ele

159
00:10:37,345 --> 00:10:42,920
exibirá automaticamente a posição de um erro ou um 0, se não houver nenhum.

160
00:10:42,920 --> 00:10:45,520
E não há nada de especial no tamanho 16 aqui.

161
00:10:45,520 --> 00:10:52,280
A mesma linha de código funcionaria se você tivesse uma lista de, digamos, 256 bits.

162
00:10:52,280 --> 00:10:56,269
Escusado será dizer que há mais código para escrever aqui, como fazer a

163
00:10:56,269 --> 00:11:00,536
verificação de metaparidade para detectar erros de 2 bits, mas a ideia é que

164
00:11:00,536 --> 00:11:05,080
quase toda a lógica central do nosso esquema se reduza a uma única redução de XOR.

165
00:11:05,080 --> 00:11:09,846
Agora, dependendo do seu conforto com binários, XORs e software em geral, você

166
00:11:09,846 --> 00:11:14,553
pode achar essa perspectiva um pouco confusa ou muito mais elegante e simples

167
00:11:14,553 --> 00:11:19,320
que você está se perguntando por que não começamos com ela desde o início. -ir.

168
00:11:19,320 --> 00:11:23,276
Falando livremente, a perspectiva de verificação de paridade múltipla é mais fácil

169
00:11:23,276 --> 00:11:27,232
de pensar ao implementar códigos de Hamming em hardware de maneira muito direta, e

170
00:11:27,232 --> 00:11:31,380
a perspectiva XOR é mais fácil de pensar ao fazê-lo em software, de um nível mais alto.

171
00:11:31,380 --> 00:11:36,319
O primeiro é mais fácil de fazer manualmente, e acho que faz um trabalho melhor ao

172
00:11:36,319 --> 00:11:41,378
incutir a intuição central subjacente a tudo isso, que é que a informação necessária

173
00:11:41,378 --> 00:11:46,199
para localizar um único erro está relacionada ao log do tamanho do bloco , ou em

174
00:11:46,199 --> 00:11:51,020
outras palavras, cresce um bit de cada vez à medida que o tamanho do bloco dobra.

175
00:11:51,020 --> 00:11:53,856
O fato relevante aqui é que essa informação corresponde

176
00:11:53,856 --> 00:11:56,440
diretamente à quantidade de redundância necessária.

177
00:11:56,440 --> 00:12:00,117
Isso é realmente o que vai contra a reação instintiva da maioria das pessoas

178
00:12:00,117 --> 00:12:03,699
quando pensam pela primeira vez em tornar uma mensagem resistente a erros,

179
00:12:03,699 --> 00:12:07,520
onde geralmente copiar a mensagem inteira é o primeiro instinto que vem à mente.

180
00:12:07,520 --> 00:12:11,205
E então, a propósito, há toda essa outra maneira que às vezes você vê os códigos

181
00:12:11,205 --> 00:12:14,800
de Hamming apresentados, onde você multiplica a mensagem por uma grande matriz.

182
00:12:14,800 --> 00:12:20,045
É bom porque o relaciona com a família mais ampla de códigos lineares, mas acho

183
00:12:20,045 --> 00:12:25,160
que isso quase não dá nenhuma intuição de onde ele vem ou como é dimensionado.

184
00:12:25,160 --> 00:12:28,600
E por falar em dimensionamento, você deve notar que a eficiência

185
00:12:28,600 --> 00:12:32,200
desse esquema só melhora à medida que aumentamos o tamanho do bloco.

186
00:12:32,200 --> 00:12:37,547
Por exemplo, vimos que com 256 bits, você está usando apenas 3%

187
00:12:37,547 --> 00:12:43,480
desse espaço para redundância, e isso continua melhorando a partir daí.

188
00:12:43,480 --> 00:12:46,260
À medida que o número de bits de paridade aumenta

189
00:12:46,260 --> 00:12:49,040
um por um, o tamanho do bloco continua duplicando.

190
00:12:49,040 --> 00:12:52,960
E se você levar isso ao extremo, você poderia ter um bloco com, digamos,

191
00:12:52,960 --> 00:12:56,772
um milhão de bits, onde você estaria literalmente jogando 20 perguntas

192
00:12:56,772 --> 00:13:00,800
com suas verificações de paridade, e ele usaria apenas 21 bits de paridade.

193
00:13:00,800 --> 00:13:04,434
E se você pensar em olhar para um milhão de bits e

194
00:13:04,434 --> 00:13:08,640
localizar um único erro, isso realmente parece uma loucura.

195
00:13:08,640 --> 00:13:13,529
O problema, claro, é que com um bloco maior, a probabilidade de ver mais de um ou

196
00:13:13,529 --> 00:13:18,360
dois erros de bit aumenta, e os códigos de Hamming não lidam com nada além disso.

197
00:13:18,360 --> 00:13:22,499
Então, na prática, o que você deseja é encontrar o tamanho certo para

198
00:13:22,499 --> 00:13:26,520
que a probabilidade de muitas inversões de bits não seja muito alta.

199
00:13:26,520 --> 00:13:31,145
Além disso, na prática, os erros tendem a ocorrer em pequenas rajadas,

200
00:13:31,145 --> 00:13:35,771
o que arruinaria totalmente um único bloco, portanto, uma tática comum

201
00:13:35,771 --> 00:13:40,463
para ajudar a espalhar uma rajada de erros por muitos blocos diferentes

202
00:13:40,463 --> 00:13:45,480
é entrelaçar esses blocos, assim, antes que eles sejam enviado ou armazenado.

203
00:13:45,480 --> 00:13:50,145
Por outro lado, muito disso é completamente discutível por códigos mais modernos, como o

204
00:13:50,145 --> 00:13:54,600
algoritmo Reed-Solomon, muito mais comumente usado, que lida particularmente bem com

205
00:13:54,600 --> 00:13:59,265
erros de explosão e pode ser ajustado para ser resiliente a um número maior de erros por

206
00:13:59,265 --> 00:13:59,580
bloco.

207
00:13:59,580 --> 00:14:03,000
Mas isso é assunto para outra hora.

208
00:14:03,000 --> 00:14:06,500
Em seu livro The Art of Doing Science and Engineering, Hamming é

209
00:14:06,500 --> 00:14:10,700
maravilhosamente sincero sobre o quão sinuosa foi sua descoberta desse código.

210
00:14:10,700 --> 00:14:14,607
Ele primeiro tentou todos os tipos de esquemas diferentes envolvendo a organização

211
00:14:14,607 --> 00:14:18,420
dos bits em partes de uma rede dimensional superior e coisas estranhas como esta.

212
00:14:18,420 --> 00:14:21,956
A ideia de que seria possível fazer com que as verificações de paridade

213
00:14:21,956 --> 00:14:25,590
conspirassem de uma forma que explicitasse a posição de um erro só surgiu

214
00:14:25,590 --> 00:14:29,225
a Hamming quando ele recuou após um monte de outras análises e perguntou:

215
00:14:29,225 --> 00:14:32,860
ok, qual é o mais eficiente que eu poderia concebivelmente ser sobre isso?

216
00:14:32,860 --> 00:14:37,391
Ele também foi sincero sobre a importância de já ter em mente as verificações

217
00:14:37,391 --> 00:14:42,040
de paridade, o que teria sido muito menos comum na década de 1940 do que é hoje.

218
00:14:42,040 --> 00:14:45,543
Há cerca de meia dúzia de vezes ao longo deste livro que ele faz

219
00:14:45,543 --> 00:14:49,640
referência à citação de Louis Pasteur: a sorte favorece uma mente preparada.

220
00:14:49,640 --> 00:14:52,216
Ideias inteligentes muitas vezes parecem enganosamente

221
00:14:52,216 --> 00:14:55,120
simples em retrospectiva, o que as torna fáceis de subestimar.

222
00:14:55,120 --> 00:14:58,540
No momento, minha sincera esperança é que os códigos de Hamming, ou pelo

223
00:14:58,540 --> 00:15:01,820
menos a possibilidade de tais códigos, pareçam quase óbvios para você.

224
00:15:01,820 --> 00:15:04,971
Mas você não deve se enganar pensando que eles são

225
00:15:04,971 --> 00:15:08,000
realmente óbvios, porque definitivamente não são.

226
00:15:08,000 --> 00:15:11,892
Parte da razão pela qual ideias inteligentes parecem enganosamente fáceis é

227
00:15:11,892 --> 00:15:16,143
que só vemos o resultado final, limpando o que estava bagunçado, nunca mencionando

228
00:15:16,143 --> 00:15:20,343
todos os caminhos errados, subestimando o quão vasto é o espaço de possibilidades

229
00:15:20,343 --> 00:15:23,980
exploráveis no início de um problema. processo de resolução, tudo isso.

230
00:15:23,980 --> 00:15:25,280
Mas isso é verdade em geral.

231
00:15:25,280 --> 00:15:28,188
Acho que, para algumas invenções especiais, há uma

232
00:15:28,188 --> 00:15:31,040
segunda razão mais profunda para as subestimarmos.

233
00:15:31,040 --> 00:15:35,220
Pensar na informação em termos de bits só se consolidou numa teoria completa

234
00:15:35,220 --> 00:15:39,400
em 1948, com o artigo seminal de Claude Shannon sobre a teoria da informação.

235
00:15:39,400 --> 00:15:43,440
Isso ocorreu essencialmente ao mesmo tempo em que Hamming desenvolveu seu algoritmo.

236
00:15:43,440 --> 00:15:46,848
Este foi o mesmo artigo fundamental que mostrou, em certo sentido,

237
00:15:46,848 --> 00:15:50,409
que a correção eficiente de erros é sempre possível, não importa quão

238
00:15:50,409 --> 00:15:53,920
alta seja a probabilidade de inversões de bits, pelo menos em teoria.

239
00:15:53,920 --> 00:15:57,862
Shannon e Hamming, aliás, dividiam um escritório no Bell Labs, apesar de

240
00:15:57,862 --> 00:16:02,400
trabalharem em coisas muito diferentes, o que dificilmente parece coincidência aqui.

241
00:16:02,400 --> 00:16:07,612
Avançando várias décadas, hoje em dia muitos de nós estamos tão imersos em pensar

242
00:16:07,612 --> 00:16:13,080
sobre bits e informações que é fácil ignorar o quão distinta era essa forma de pensar.

243
00:16:13,080 --> 00:16:15,500
Ironicamente, as ideias que moldam mais profundamente a forma como uma geração futura

244
00:16:15,500 --> 00:16:17,920
pensa acabarão por parecer para essa geração futura mais simples do que realmente são.

