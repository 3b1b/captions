1
00:00:00,000 --> 00:00:02,560
Je suppose que tout le monde ici vient de la partie 1.

2
00:00:03,060 --> 00:00:06,641
Nous parlions des codes de Hamming, une façon de créer un bloc de données dont 

3
00:00:06,641 --> 00:00:09,044
la plupart des bits portent un message significatif, 

4
00:00:09,044 --> 00:00:12,081
tandis que quelques autres agissent comme une sorte de redondance, 

5
00:00:12,081 --> 00:00:16,026
de telle sorte que si un bit est inversé, soit un message bit ou un bit de redondance, 

6
00:00:16,026 --> 00:00:19,698
n'importe quoi dans ce bloc, un récepteur sera capable d'identifier qu'il y a eu 

7
00:00:19,698 --> 00:00:21,240
une erreur et comment la corriger.

8
00:00:21,880 --> 00:00:24,483
L'idée de base présentée ici était de savoir comment utiliser plusieurs 

9
00:00:24,483 --> 00:00:27,160
contrôles de parité pour effectuer une recherche binaire jusqu'à l'erreur.

10
00:00:28,980 --> 00:00:31,715
Dans cette vidéo, l'objectif était de rendre les codes 

11
00:00:31,715 --> 00:00:34,600
de Hamming aussi pratiques et redécouvrables que possible.

12
00:00:35,180 --> 00:00:38,500
Mais lorsque vous commencez à réfléchir à la mise en œuvre réelle de cela, 

13
00:00:38,500 --> 00:00:41,290
que ce soit au niveau logiciel ou matériel, ce cadrage peut en 

14
00:00:41,290 --> 00:00:43,460
fait sous-estimer l'élégance réelle de ces codes.

15
00:00:43,920 --> 00:00:47,020
Vous pensez peut-être que vous devez écrire un algorithme qui garde une 

16
00:00:47,020 --> 00:00:50,121
trace de tous les emplacements d'erreur possibles et coupe ce groupe de 

17
00:00:50,121 --> 00:00:53,480
moitié à chaque vérification, mais c'est en réalité bien plus simple que cela.

18
00:00:53,940 --> 00:00:57,215
Si vous lisez les réponses aux quatre contrôles de parité que nous avons 

19
00:00:57,215 --> 00:01:00,625
effectués dans la dernière vidéo, toutes sous forme de 1 et de 0 au lieu de 

20
00:01:00,625 --> 00:01:04,080
oui et de non, cela indique littéralement la position de l'erreur en binaire.

21
00:01:04,780 --> 00:01:07,904
Par exemple, le nombre 7 en binaire ressemble à 0111, 

22
00:01:07,904 --> 00:01:11,260
ce qui signifie essentiellement que c'est 4 plus 2 plus 1.

23
00:01:12,540 --> 00:01:16,894
Et remarquez où se situe la position 7, elle affecte le premier de nos 

24
00:01:16,894 --> 00:01:21,740
groupes paritaires, ainsi que le deuxième et le troisième, mais pas le dernier.

25
00:01:22,220 --> 00:01:24,978
Ainsi, la lecture des résultats de ces quatre contrôles 

26
00:01:24,978 --> 00:01:27,540
de bas en haut précise bien la position de l’erreur.

27
00:01:28,320 --> 00:01:31,311
Il n'y a rien de spécial dans l'exemple 7, cela fonctionne en général, 

28
00:01:31,311 --> 00:01:34,935
et cela rend la logique d'implémentation de l'ensemble du schéma matériellement d'une 

29
00:01:34,935 --> 00:01:35,820
simplicité choquante.

30
00:01:37,240 --> 00:01:41,133
Maintenant, si vous voulez voir pourquoi cette magie se produit, 

31
00:01:41,133 --> 00:01:44,308
prenez ces 16 étiquettes d'index pour nos positions, 

32
00:01:44,308 --> 00:01:48,562
mais au lieu de les écrire en base 10, écrivons-les toutes en binaire, 

33
00:01:48,562 --> 00:01:49,880
allant de 0000 à 1111.

34
00:01:50,559 --> 00:01:53,798
Alors que nous remettons ces étiquettes binaires dans leurs boîtes, 

35
00:01:53,798 --> 00:01:57,800
permettez-moi de souligner qu'elles sont distinctes des données réellement envoyées.

36
00:01:58,320 --> 00:02:00,891
Ce n'est rien de plus qu'une étiquette conceptuelle pour nous aider, 

37
00:02:00,891 --> 00:02:03,500
vous et moi, à comprendre d'où viennent les quatre groupes paritaires.

38
00:02:04,140 --> 00:02:08,274
L'élégance d'avoir tout ce que nous regardons soit décrit en binaire est peut-être 

39
00:02:08,274 --> 00:02:12,360
sapée par la confusion d'avoir tout ce que nous regardons étant décrit en binaire.

40
00:02:13,020 --> 00:02:14,120
Mais ça vaut le coup.

41
00:02:14,800 --> 00:02:19,397
Concentrez votre attention uniquement sur le dernier bit de toutes ces étiquettes, 

42
00:02:19,397 --> 00:02:23,220
puis mettez en surbrillance les positions où ce dernier bit est un 1.

43
00:02:24,240 --> 00:02:27,532
Ce que nous obtenons est le premier de nos quatre groupes de parité, 

44
00:02:27,532 --> 00:02:31,827
ce qui signifie que vous pouvez interpréter cette première vérification comme demandant : 

45
00:02:31,827 --> 00:02:35,740
hé, s’il y a une erreur, le dernier bit à la position de cette erreur est-il un 1?

46
00:02:38,200 --> 00:02:40,809
De même, si vous vous concentrez sur l'avant-dernier bit et 

47
00:02:40,809 --> 00:02:43,637
mettez en surbrillance toutes les positions où il s'agit d'un 1, 

48
00:02:43,637 --> 00:02:46,160
vous obtenez le deuxième groupe de parité de notre schéma.

49
00:02:46,740 --> 00:02:50,826
En d’autres termes, cette deuxième vérification demande : hé, encore une fois, 

50
00:02:50,826 --> 00:02:54,500
s’il y a une erreur, l’avant-dernier bit de cette position est-il un 1?

51
00:02:55,760 --> 00:02:56,900
Et ainsi de suite.

52
00:02:57,220 --> 00:03:00,782
Le troisième contrôle de parité couvre chaque position dont 

53
00:03:00,782 --> 00:03:05,711
l'avant-dernier bit est activé, et le dernier couvre les huit dernières positions, 

54
00:03:05,711 --> 00:03:08,740
celles dont le bit de poids le plus élevé est un 1.

55
00:03:09,740 --> 00:03:14,740
Tout ce que nous avons fait plus tôt revient à répondre à ces quatre questions, 

56
00:03:14,740 --> 00:03:17,740
ce qui revient à épeler une position en binaire.

57
00:03:19,620 --> 00:03:21,480
J'espère que cela rend deux choses plus claires.

58
00:03:22,040 --> 00:03:24,233
La première est de savoir comment généraliser systématiquement à 

59
00:03:24,233 --> 00:03:26,460
des tailles de blocs qui sont des puissances de deux plus grandes.

60
00:03:26,960 --> 00:03:29,822
S'il faut plus de bits pour décrire chaque position, 

61
00:03:29,822 --> 00:03:34,358
comme six bits pour décrire 64 points, alors chacun de ces bits vous donne l'un des 

62
00:03:34,358 --> 00:03:36,680
groupes de parité que nous devons vérifier.

63
00:03:38,400 --> 00:03:40,857
Ceux d’entre vous qui ont regardé le puzzle d’échiquier que j’ai réalisé 

64
00:03:40,857 --> 00:03:43,180
avec Matt Parker trouveront peut-être tout cela extrêmement familier.

65
00:03:43,660 --> 00:03:46,901
C'est la même logique de base, mais résolvant un problème différent, 

66
00:03:46,901 --> 00:03:48,780
et appliquée à un échiquier de 64 cases.

67
00:03:49,880 --> 00:03:52,413
La deuxième chose que j'espère que cela clarifie est la raison 

68
00:03:52,413 --> 00:03:54,987
pour laquelle nos bits de parité se trouvent dans des positions 

69
00:03:54,987 --> 00:03:57,320
qui sont des puissances de deux, par exemple 1, 2, 4 et 8.

70
00:03:58,000 --> 00:04:03,000
Ce sont les positions dont la représentation binaire n'a qu'un seul bit activé.

71
00:04:03,600 --> 00:04:06,390
Cela signifie que chacun de ces bits de parité se 

72
00:04:06,390 --> 00:04:09,460
trouve dans un et un seul des quatre groupes de parité.

73
00:04:12,040 --> 00:04:15,189
Vous pouvez également le constater dans des exemples plus grands, 

74
00:04:15,189 --> 00:04:19,339
où quelle que soit votre taille, chaque bit de parité ne touche qu'un seul des groupes.

75
00:04:25,600 --> 00:04:29,128
Une fois que vous comprenez que ces contrôles de parité sur lesquels nous avons consacré 

76
00:04:29,128 --> 00:04:32,378
une grande partie de notre temps ne sont rien de plus qu'une manière intelligente 

77
00:04:32,378 --> 00:04:35,946
d'épeler la position d'une erreur en binaire, nous pouvons alors établir un lien avec une 

78
00:04:35,946 --> 00:04:38,007
manière différente de penser au hamming. des codes, 

79
00:04:38,007 --> 00:04:40,385
qui sont sans doute beaucoup plus simples et plus élégants, 

80
00:04:40,385 --> 00:04:43,240
et qui peuvent essentiellement être écrits avec une seule ligne de code.

81
00:04:43,660 --> 00:04:45,500
Il est basé sur la fonction XOR.

82
00:04:46,940 --> 00:04:50,220
XOR, pour ceux d'entre vous qui ne le savent pas, signifie exclusif ou.

83
00:04:50,780 --> 00:04:55,131
Lorsque vous effectuez le XOR de deux bits, il renvoie un 1 si l'un de 

84
00:04:55,131 --> 00:04:59,360
ces bits est activé, mais pas si les deux sont activés ou désactivés.

85
00:05:00,100 --> 00:05:02,980
Exprimé différemment, c'est la parité de ces deux bits.

86
00:05:03,540 --> 00:05:06,760
En tant que mathématicien, je préfère y penser comme un mod d'addition 2.

87
00:05:07,360 --> 00:05:10,768
Nous parlons aussi couramment du XOR de deux chaînes de bits différentes, 

88
00:05:10,768 --> 00:05:13,440
qui effectue essentiellement cela composant par composant.

89
00:05:13,680 --> 00:05:15,720
C'est comme une addition, mais où l'on ne porte jamais.

90
00:05:16,500 --> 00:05:19,530
Encore une fois, les plus enclins aux mathématiques préféreront peut-être 

91
00:05:19,530 --> 00:05:22,480
considérer cela comme l'ajout de deux vecteurs et la réduction du mod 2.

92
00:05:23,500 --> 00:05:28,329
Si vous ouvrez Python dès maintenant et appliquez l'opération caret entre deux entiers, 

93
00:05:28,329 --> 00:05:32,940
c'est ce qu'il fait, mais aux représentations binaires de ces nombres sous le capot.

94
00:05:34,960 --> 00:05:39,055
Le point clé pour vous et moi est que prendre le XOR de nombreuses chaînes de 

95
00:05:39,055 --> 00:05:42,940
bits différentes est effectivement un moyen de calculer les parodies d'un 

96
00:05:42,940 --> 00:05:47,140
groupe de groupes séparés, comme c'est le cas avec les colonnes, d'un seul coup.

97
00:05:51,260 --> 00:05:55,041
Cela nous donne une façon plutôt élégante de considérer les multiples contrôles de parité 

98
00:05:55,041 --> 00:05:58,780
de notre algorithme de code de Hamming comme étant tous regroupés en une seule opération.

99
00:05:59,479 --> 00:06:02,180
Même si à première vue, cela semble très différent.

100
00:06:02,820 --> 00:06:07,829
Notez spécifiquement les 16 positions en binaire, comme nous l'avions fait auparavant, 

101
00:06:07,829 --> 00:06:13,011
et mettez maintenant en surbrillance les positions où le bit de message est activé sur 1, 

102
00:06:13,011 --> 00:06:17,100
puis rassemblez ces positions dans une grande colonne et prenez le XOR.

103
00:06:19,260 --> 00:06:22,623
Vous pouvez probablement deviner que les 4 bits situés en bas sont 

104
00:06:22,623 --> 00:06:26,238
les mêmes que les 4 contrôles de parité que nous connaissons et aimons, 

105
00:06:26,238 --> 00:06:29,200
mais prenez un moment pour réfléchir à pourquoi exactement.

106
00:06:32,220 --> 00:06:35,666
Cette dernière colonne, par exemple, compte toutes les positions dont 

107
00:06:35,666 --> 00:06:38,916
le dernier bit est un 1, mais nous sommes déjà limités uniquement 

108
00:06:38,916 --> 00:06:42,116
aux positions en surbrillance, elle compte donc effectivement le 

109
00:06:42,116 --> 00:06:45,760
nombre de positions en surbrillance provenant du premier groupe de parité.

110
00:06:46,240 --> 00:06:46,800
Cela a-t-il du sens?

111
00:06:49,080 --> 00:06:52,648
De même, la colonne suivante compte le nombre de positions dans le 

112
00:06:52,648 --> 00:06:56,164
deuxième groupe de parité, les positions dont l'avant-dernier bit 

113
00:06:56,164 --> 00:07:00,000
est un 1 et qui sont également mises en surbrillance, et ainsi de suite.

114
00:07:00,260 --> 00:07:01,912
Il s'agit en réalité d'un petit changement de 

115
00:07:01,912 --> 00:07:03,960
perspective par rapport à la même chose que nous faisons.

116
00:07:07,760 --> 00:07:09,600
Et donc vous savez où cela va à partir de maintenant.

117
00:07:10,000 --> 00:07:12,737
L'expéditeur est responsable d'activer certains bits de 

118
00:07:12,737 --> 00:07:15,720
parité spéciaux pour s'assurer que la somme est égale à 0000.

119
00:07:15,720 --> 00:07:19,713
Maintenant, une fois que nous avons cela, cela nous donne une très 

120
00:07:19,713 --> 00:07:23,706
bonne façon de réfléchir à la raison pour laquelle ces quatre bits 

121
00:07:23,706 --> 00:07:27,580
résultants en bas indiquent directement la position d'une erreur.

122
00:07:28,460 --> 00:07:31,860
Disons qu'un élément de ce bloc passe de 0 à 1.

123
00:07:32,600 --> 00:07:37,960
Cela signifie que la position de ce bit va maintenant être incluse dans le XOR total, 

124
00:07:37,960 --> 00:07:42,323
ce qui fait passer la somme de 0 à cette valeur nouvellement incluse, 

125
00:07:42,323 --> 00:07:43,820
la position de l'erreur.

126
00:07:44,460 --> 00:07:46,832
De manière un peu moins évidente, il en va de 

127
00:07:46,832 --> 00:07:49,360
même s'il y a une erreur qui change un 1 en un 0.

128
00:07:50,180 --> 00:07:52,832
Vous voyez, si vous ajoutez deux fois une petite chaîne, 

129
00:07:52,832 --> 00:07:56,556
cela revient à ne pas l'avoir du tout, essentiellement parce que dans ce monde, 

130
00:07:56,556 --> 00:07:57,580
1 plus 1 est égal à 0.

131
00:07:57,580 --> 00:08:00,940
Ainsi, ajouter une copie de cette position à la 

132
00:08:00,940 --> 00:08:04,300
somme totale a le même effet que de la déplacer.

133
00:08:05,160 --> 00:08:07,985
Et cet effet, encore une fois, est que le résultat 

134
00:08:07,985 --> 00:08:10,700
total en bas indique ici la position de l’erreur.

135
00:08:13,039 --> 00:08:15,796
Pour illustrer à quel point cela est élégant, permettez-moi de 

136
00:08:15,796 --> 00:08:18,815
montrer cette ligne de code Python que j'ai référencée précédemment, 

137
00:08:18,815 --> 00:08:21,440
qui capturera presque toute la logique du côté du récepteur.

138
00:08:22,080 --> 00:08:25,798
Nous allons commencer par créer un tableau aléatoire de 16 1 et 0 pour simuler 

139
00:08:25,798 --> 00:08:29,751
le bloc de données, et je lui donnerai le nom des bits, mais bien sûr, en pratique, 

140
00:08:29,751 --> 00:08:33,987
ce serait quelque chose que nous recevons d'un expéditeur, et au lieu de étant aléatoire, 

141
00:08:33,987 --> 00:08:37,000
il transporterait 11 bits de données ainsi que 5 bits de parité.

142
00:08:37,000 --> 00:08:41,960
Si j'appelle la fonction enumerateBits, elle associe chacun de 

143
00:08:41,960 --> 00:08:47,000
ces bits à un index correspondant, dans ce cas allant de 0 à 15.

144
00:08:48,180 --> 00:08:51,903
Donc, si nous créons ensuite une liste qui boucle sur toutes ces paires, 

145
00:08:51,903 --> 00:08:56,290
des paires qui ressemblent à i, et que nous extrayons ensuite uniquement la valeur i, 

146
00:08:56,290 --> 00:08:58,840
juste l'index, eh bien, ce n'est pas si excitant, 

147
00:08:58,840 --> 00:09:01,340
nous récupérons simplement ces indices de 0 à 15.

148
00:09:01,680 --> 00:09:05,458
Mais si nous ajoutons la condition de ne faire cela que si bit, 

149
00:09:05,458 --> 00:09:09,118
c'est-à-dire si ce bit est un 1 et non un 0, alors il extrait 

150
00:09:09,118 --> 00:09:12,660
uniquement les positions où le bit correspondant est activé.

151
00:09:13,380 --> 00:09:20,360
Dans ce cas, il semble que ces positions soient 0, 4, 6, 9, etc.

152
00:09:20,720 --> 00:09:23,900
Ce que nous voulons, c'est rassembler toutes ces positions, 

153
00:09:23,900 --> 00:09:27,240
les positions des bits qui sont activés, puis les XOR ensemble.

154
00:09:29,180 --> 00:09:33,220
Pour ce faire en Python, permettez-moi d'abord d'importer quelques fonctions utiles.

155
00:09:33,900 --> 00:09:36,187
De cette façon, nous pouvons appeler réduire() sur 

156
00:09:36,187 --> 00:09:38,700
cette liste et utiliser la fonction XOR pour la réduire.

157
00:09:39,100 --> 00:09:42,680
Cela se fraye un chemin à travers la liste, prenant des XORs en cours de route.

158
00:09:44,800 --> 00:09:47,204
Si vous préférez, vous pouvez écrire explicitement cette 

159
00:09:47,204 --> 00:09:49,440
fonction XOR sans avoir à l'importer de n'importe où.

160
00:09:51,940 --> 00:09:56,482
Donc pour le moment, il semble que si nous faisons cela sur notre bloc 

161
00:09:56,482 --> 00:10:01,280
aléatoire de 16 bits, cela renvoie 9, qui a la représentation binaire 1001.

162
00:10:01,980 --> 00:10:05,427
Nous ne le ferons pas ici, mais vous pouvez écrire une fonction dans laquelle 

163
00:10:05,427 --> 00:10:08,697
l'expéditeur utilise cette représentation binaire pour définir les quatre 

164
00:10:08,697 --> 00:10:11,968
bits de parité selon les besoins, amenant finalement ce bloc à un état où 

165
00:10:11,968 --> 00:10:15,460
l'exécution de cette ligne de code sur la liste complète des bits renvoie un 0.

166
00:10:16,080 --> 00:10:20,100
Cela serait considéré comme un bloc bien préparé.

167
00:10:20,100 --> 00:10:24,012
Ce qui est cool, c'est que si nous basculons l'un des bits de cette liste, 

168
00:10:24,012 --> 00:10:27,507
simulant une erreur aléatoire due au bruit, alors si vous exécutez 

169
00:10:27,507 --> 00:10:30,220
cette même ligne de code, cette erreur est affichée.

170
00:10:30,960 --> 00:10:31,520
N'est-ce pas sympa?

171
00:10:31,820 --> 00:10:36,217
Vous pouvez obtenir ce bloc à l'improviste, exécuter cette seule ligne dessus, 

172
00:10:36,217 --> 00:10:41,060
et il crachera automatiquement la position d'une erreur, ou un 0 s'il n'y en avait pas.

173
00:10:42,500 --> 00:10:44,840
Et il n'y a rien de spécial concernant la taille 16 ici.

174
00:10:44,840 --> 00:10:49,860
La même ligne de code fonctionnerait si vous aviez une liste de, disons, 256 bits.

175
00:10:51,880 --> 00:10:54,481
Inutile de dire qu'il y a plus de code à écrire ici, 

176
00:10:54,481 --> 00:10:58,605
comme effectuer la vérification de méta-parité pour détecter les erreurs de 2 bits, 

177
00:10:58,605 --> 00:11:02,483
mais l'idée est que presque toute la logique de base de notre schéma se résume 

178
00:11:02,483 --> 00:11:03,760
à une seule réduction XOR.

179
00:11:06,120 --> 00:11:08,434
Maintenant, selon votre aisance avec les binaires, 

180
00:11:08,434 --> 00:11:11,521
les XOR et les logiciels en général, vous pouvez soit trouver cette 

181
00:11:11,521 --> 00:11:14,698
perspective un peu déroutante, soit tellement plus élégante et simple 

182
00:11:14,698 --> 00:11:18,420
que vous vous demandez pourquoi nous ne l'avons pas commencé dès le début. -aller.

183
00:11:19,140 --> 00:11:22,051
En gros, la perspective du contrôle de parité multiple est plus facile 

184
00:11:22,051 --> 00:11:25,578
à penser lors de l'implémentation très directe des codes de Hamming dans le matériel, 

185
00:11:25,578 --> 00:11:29,228
et la perspective XOR est la plus facile à penser lorsqu'on l'effectue dans le logiciel, 

186
00:11:29,228 --> 00:11:30,500
à partir d'un niveau supérieur.

187
00:11:31,360 --> 00:11:34,030
Le premier est le plus simple à réaliser à la main, 

188
00:11:34,030 --> 00:11:37,573
et je pense qu'il fait un meilleur travail en inculquant l'intuition 

189
00:11:37,573 --> 00:11:41,065
fondamentale qui sous-tend tout cela, à savoir que les informations 

190
00:11:41,065 --> 00:11:45,429
requises pour localiser une seule erreur sont liées au journal de la taille du bloc. 

191
00:11:45,429 --> 00:11:50,000
, ou en d’autres termes, il augmente petit à petit à mesure que la taille du bloc double.

192
00:11:51,020 --> 00:11:53,581
Le fait pertinent ici est que ces informations correspondent 

193
00:11:53,581 --> 00:11:56,060
directement au niveau de redondance dont nous avons besoin.

194
00:11:56,660 --> 00:11:59,085
C'est vraiment ce qui va à l'encontre de la réaction instinctive de 

195
00:11:59,085 --> 00:12:01,582
la plupart des gens lorsqu'ils pensent pour la première fois à rendre 

196
00:12:01,582 --> 00:12:04,007
un message résistant aux erreurs, alors que copier l'intégralité du 

197
00:12:04,007 --> 00:12:06,540
message est généralement le premier instinct qui leur vient à l'esprit.

198
00:12:07,500 --> 00:12:10,813
Et puis, en passant, il y a cette toute autre façon de voir parfois les codes 

199
00:12:10,813 --> 00:12:14,000
de Hamming présentés, où vous multipliez le message par une grande matrice.

200
00:12:14,670 --> 00:12:18,669
C'est plutôt sympa car cela le relie à la famille plus large des codes linéaires, 

201
00:12:18,669 --> 00:12:23,060
mais je pense que cela ne donne presque aucune intuition sur son origine ou son évolution.

202
00:12:25,200 --> 00:12:28,144
Et en parlant de mise à l'échelle, vous remarquerez peut-être que l'efficacité de 

203
00:12:28,144 --> 00:12:31,160
ce système ne fait que s'améliorer à mesure que nous augmentons la taille des blocs.

204
00:12:35,000 --> 00:12:38,684
Par exemple, nous avons vu qu'avec 256 bits, vous n'utilisez que 3 % de cet 

205
00:12:38,684 --> 00:12:42,660
espace pour la redondance, et la situation ne cesse de s'améliorer à partir de là.

206
00:12:43,300 --> 00:12:45,789
À mesure que le nombre de bits de parité augmente un par un, 

207
00:12:45,789 --> 00:12:47,340
la taille du bloc continue de doubler.

208
00:12:49,000 --> 00:12:52,492
Et si vous poussez cela à l'extrême, vous pourriez avoir un bloc avec, 

209
00:12:52,492 --> 00:12:55,985
disons, un million de bits, dans lequel vous joueriez littéralement 20 

210
00:12:55,985 --> 00:13:00,020
questions avec vos contrôles de parité, et il n'utiliserait que 21 bits de parité.

211
00:13:00,740 --> 00:13:03,875
Et si vous prenez du recul et réfléchissez à examiner un million 

212
00:13:03,875 --> 00:13:07,060
de bits et à localiser une seule erreur, cela semble vraiment fou.

213
00:13:08,199 --> 00:13:11,173
Le problème, bien sûr, est qu’avec un bloc plus grand, 

214
00:13:11,173 --> 00:13:14,686
la probabilité de voir plus d’un ou deux bits d’erreur augmente, 

215
00:13:14,686 --> 00:13:17,660
et les codes de Hamming ne gèrent rien d’autre au-delà.

216
00:13:18,320 --> 00:13:21,292
Donc, en pratique, ce que vous voudriez, c'est trouver la bonne taille pour que la 

217
00:13:21,292 --> 00:13:24,300
probabilité d'un trop grand nombre de retournements de bits ne soit pas trop élevée.

218
00:13:26,600 --> 00:13:30,473
De plus, dans la pratique, les erreurs ont tendance à se produire par petites rafales, 

219
00:13:30,473 --> 00:13:33,901
ce qui ruinerait totalement un seul bloc. Une tactique courante pour aider à 

220
00:13:33,901 --> 00:13:37,685
répartir une rafale d'erreurs sur de nombreux blocs différents consiste à entrelacer 

221
00:13:37,685 --> 00:13:40,980
ces blocs, comme ceci, avant qu'ils ne soient générés. envoyés ou stockés.

222
00:13:45,580 --> 00:13:48,836
Là encore, une grande partie de cela est rendue complètement sans objet par 

223
00:13:48,836 --> 00:13:51,450
des codes plus modernes, comme l'algorithme de Reed-Solomon, 

224
00:13:51,450 --> 00:13:55,220
beaucoup plus couramment utilisé, qui gère particulièrement bien les erreurs en rafale, 

225
00:13:55,220 --> 00:13:58,820
et il peut être réglé pour être résilient à un plus grand nombre d'erreurs par bloc.

226
00:13:59,360 --> 00:14:01,340
Mais c'est un sujet pour une autre fois.

227
00:14:02,500 --> 00:14:05,595
Dans son livre The Art of Doing Science and Engineering, 

228
00:14:05,595 --> 00:14:09,940
Hamming est merveilleusement franc sur les méandres de sa découverte de ce code.

229
00:14:10,620 --> 00:14:14,118
Il a d'abord essayé toutes sortes de schémas différents impliquant l'organisation des 

230
00:14:14,118 --> 00:14:17,780
bits en parties d'un réseau de dimension supérieure et des choses étranges comme celle-ci.

231
00:14:18,300 --> 00:14:21,369
L'idée qu'il pourrait être possible d'obtenir des contrôles de parité pour 

232
00:14:21,369 --> 00:14:24,766
conspirer d'une manière qui précise la position d'une erreur n'est venue à Hamming 

233
00:14:24,766 --> 00:14:27,836
que lorsqu'il a pris du recul après un tas d'autres analyses et a demandé, 

234
00:14:27,836 --> 00:14:31,520
d'accord, quelle est la méthode la plus efficace possible. peut-être qu'il s'agisse de ça?

235
00:14:32,620 --> 00:14:35,385
Il a également souligné à quel point il était important que les 

236
00:14:35,385 --> 00:14:37,892
contrôles de parité soient déjà présents dans son esprit, 

237
00:14:37,892 --> 00:14:41,220
ce qui aurait été beaucoup moins courant dans les années 1940 qu'aujourd'hui.

238
00:14:41,920 --> 00:14:45,029
Il y a environ une demi-douzaine de fois tout au long de ce livre où il fait 

239
00:14:45,029 --> 00:14:48,220
référence à la citation de Louis Pasteur, la chance favorise un esprit préparé.

240
00:14:49,320 --> 00:14:52,720
Avec le recul, les idées intelligentes semblent souvent d’une simplicité trompeuse, 

241
00:14:52,720 --> 00:14:54,300
ce qui les rend faciles à sous-estimer.

242
00:14:54,960 --> 00:14:57,994
À l’heure actuelle, j’espère honnêtement que les codes de Hamming, 

243
00:14:57,994 --> 00:15:01,300
ou du moins la possibilité de tels codes, vous semblent presque évidents.

244
00:15:01,660 --> 00:15:05,245
Mais vous ne devriez pas vous tromper en pensant qu’ils sont en réalité évidents, 

245
00:15:05,245 --> 00:15:06,820
car ils ne le sont certainement pas.

246
00:15:07,880 --> 00:15:11,456
Une partie de la raison pour laquelle les idées intelligentes semblent trompeusement 

247
00:15:11,456 --> 00:15:15,243
faciles est que nous ne voyons que le résultat final, nettoyant ce qui était en désordre, 

248
00:15:15,243 --> 00:15:17,305
sans jamais mentionner tous les mauvais virages, 

249
00:15:17,305 --> 00:15:21,050
sous-estimant à quel point l'espace des possibilités explorables est vaste au début d'un 

250
00:15:21,050 --> 00:15:22,860
problème. processus de résolution, tout ça.

251
00:15:23,820 --> 00:15:24,900
Mais cela est vrai en général.

252
00:15:24,900 --> 00:15:27,984
Je pense que pour certaines inventions spéciales, il y a une deuxième raison, 

253
00:15:27,984 --> 00:15:30,040
plus profonde, pour laquelle nous les sous-estimons.

254
00:15:30,840 --> 00:15:33,680
La conception de l'information en termes de bits n'a véritablement 

255
00:15:33,680 --> 00:15:36,096
abouti à une théorie complète qu'en 1948, avec l'article 

256
00:15:36,096 --> 00:15:38,640
fondateur de Claude Shannon sur la théorie de l'information.

257
00:15:39,280 --> 00:15:42,540
Cela correspondait essentiellement au moment où Hamming développait son algorithme.

258
00:15:43,300 --> 00:15:46,741
Il s’agissait du même article fondateur qui montrait, dans un certain sens, 

259
00:15:46,741 --> 00:15:49,413
qu’une correction d’erreur efficace est toujours possible, 

260
00:15:49,413 --> 00:15:52,900
quelle que soit la probabilité de retournements de bits, du moins en théorie.

261
00:15:53,700 --> 00:15:56,808
Shannon et Hamming, d'ailleurs, partageaient un bureau dans les Bell Labs, 

262
00:15:56,808 --> 00:15:59,253
bien qu'ils travaillaient sur des choses très différentes, 

263
00:15:59,253 --> 00:16:01,160
ce qui ne semble pas ici être une coïncidence.

264
00:16:02,380 --> 00:16:04,731
Avance rapide de plusieurs décennies, et de nos jours, 

265
00:16:04,731 --> 00:16:08,150
beaucoup d’entre nous sont tellement plongés dans la réflexion sur des éléments 

266
00:16:08,150 --> 00:16:11,356
et des informations qu’il est facile d’oublier à quel point cette façon de 

267
00:16:11,356 --> 00:16:12,340
penser était distincte.

268
00:16:13,100 --> 00:16:15,982
Ironiquement, les idées qui façonnent le plus profondément la 

269
00:16:15,982 --> 00:16:18,958
façon de penser d’une génération future finiront par considérer 

270
00:16:18,958 --> 00:16:22,260
cette génération future plus simplement qu’elles ne le sont réellement.

