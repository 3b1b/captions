1
00:00:00,000 --> 00:00:03,120
ここにいる皆さんはパート1から来ていると思います。

2
00:00:03,120 --> 00:00:05,258
私たちはハミング コードについて話していました。

3
00:00:05,258 --> 00:00:06,951
これは、ほとんどのビットが意味のあ

4
00:00:06,951 --> 00:00:09,267
るメッセージを運ぶデータ ブロックを作成する方法であ

5
00:00:09,267 --> 00:00:10,693
り、他のいくつかのビットは一種

6
00:00:10,693 --> 00:00:13,010
の冗長性として機能し、ビットが反転した場合、メッセー

7
00:00:13,010 --> 00:00:15,593
ジが送信されるか、メッセージが 送信されるかが決まります。

8
00:00:15,593 --> 00:00:18,266
ビットや冗長ビットなど、このブロック内のあらゆるものによ

9
00:00:18,266 --> 00:00:20,583
って、受信機はエラーがあったことと、それを修正する方

10
00:00:20,583 --> 00:00:21,920
法を識別できるようになります。

11
00:00:21,920 --> 00:00:25,926
そこで提示された基本的なアイデアは、複数のパリティ チェッ

12
00:00:25,926 --> 00:00:29,800
クを使用してエラーに至るまでバイナリ検索を行う方法でした。

13
00:00:29,800 --> 00:00:32,722
このビデオの目標は、ハミング コードをできる限り実

14
00:00:32,722 --> 00:00:35,420
際に操作でき、再発見できるようにすることでした。

15
00:00:35,420 --> 00:00:37,571
しかし、これをソフトウェアまたはハードウェアで

16
00:00:37,571 --> 00:00:39,816
実際に実装することを考え始めると、その枠組みに

17
00:00:39,816 --> 00:00:41,968
よって、これらのコードが実際にどれほどエレガン

18
00:00:41,968 --> 00:00:44,120
トであるかが実際に理解できないかもしれません。

19
00:00:44,120 --> 00:00:47,582
考えられるすべてのエラー位置を追跡し、各チェックでそのグル

20
00:00:47,582 --> 00:00:50,928
ープを半分に分割するアルゴリズムを作成する必要があると思

21
00:00:50,928 --> 00:00:54,160
うかもしれませんが、実際にはそれよりもはるかに簡単です。

22
00:00:54,160 --> 00:00:56,578
前回のビデオで行った 4 つのパリティ

23
00:00:56,578 --> 00:00:59,600
チェックの答えを、すべて「はい」と「いいえ」では

24
00:00:59,600 --> 00:01:03,107
なく「1」と「0」として読み上げると、文字通りエラーの位置

25
00:01:03,107 --> 00:01:04,800
が 2 進数で表示されます。

26
00:01:04,800 --> 00:01:07,370
たとえば、2 進数の 7 は 0111

27
00:01:07,370 --> 00:01:09,940
のように見え、本質的 には 4 プラス

28
00:01:09,940 --> 00:01:12,640
2 プラス 1 であることを示しています。

29
00:01:12,640 --> 00:01:16,042
位置 7 がどこに位置するかに注目してください。

30
00:01:16,042 --> 00:01:19,161
パリティ グループ の最初、2 番目、3

31
00:01:19,161 --> 00:01:22,280
番目には影響しますが、最後には影響しません。

32
00:01:22,280 --> 00:01:25,530
したがって、これら 4 つのチェックの結果を下か

33
00:01:25,530 --> 00:01:28,520
ら上に読むと、エラーの位置が明らかになります。

34
00:01:28,520 --> 00:01:31,032
例 7 には特別なことは何もありません。

35
00:01:31,032 --> 00:01:33,168
これは一般的に機能し、ハードウ

36
00:01:33,168 --> 00:01:36,058
ェアでスキーム全体を実装するためのロジックが驚

37
00:01:36,058 --> 00:01:37,440
くほど単純になります。

38
00:01:37,440 --> 00:01:40,550
この魔法がなぜ起こるのかを知りたい場合は、これらの

39
00:01:40,550 --> 00:01:43,900
16 個のインデック ス ラベルを位置に取ってください。

40
00:01:43,900 --> 00:01:47,370
ただし、それらを 10 進数で書く代わ りに、0000

41
00:01:47,370 --> 00:01:50,720
から 1111 までのバイナリですべて書いてみましょう。

42
00:01:50,720 --> 00:01:54,728
これらのバイナリ ラベルを箱に戻すときに、実際に送信

43
00:01:54,728 --> 00:01:58,440
されるデータとは区別されることを強調しておきます。

44
00:01:58,440 --> 00:02:01,430
これらは、4 つのパリティ グループがどこから来たの

45
00:02:01,430 --> 00:02:04,200
かを理解するのに役立つ概念的なラベルにすぎません。

46
00:02:04,200 --> 00:02:07,186
私たちが見ているものすべてがバイナリで記述されることの

47
00:02:07,186 --> 00:02:10,173
優雅さは、おそらく、私たち が見ているものすべてがバイ

48
00:02:10,173 --> 00:02:13,160
ナリで記述されることの混乱によって損なわれるでしょう。

49
00:02:13,160 --> 00:02:15,040
ただし、それだけの価値はあります。

50
00:02:15,040 --> 00:02:19,754
これらすべてのラベルの最後のビットに注目し、その

51
00:02:19,754 --> 00:02:24,280
最後のビットが 1 である位置を強調表示します。

52
00:02:24,280 --> 00:02:26,304
得られるのは 4 つのパリティ

53
00:02:26,304 --> 00:02:28,582
グループの最初のグループです。 つ

54
00:02:28,582 --> 00:02:31,618
まり、最初のチェックは、エラーがある場合、そのエ

55
00:02:31,618 --> 00:02:34,655
ラーの位置にある 最後のビットは 1 ですか?

56
00:02:34,655 --> 00:02:36,680
という質問であると解釈できます。

57
00:02:36,680 --> 00:02:40,271
同様に、最後から 2 番目のビットに注目し、それが

58
00:02:40,271 --> 00:02:44,139
1 であるすべての位置 を強調表示すると、スキームから

59
00:02:44,139 --> 00:02:47,040
2 番目のパリティ グループが得られます。

60
00:02:47,040 --> 00:02:50,034
言い換えれば、その 2 番目のチェックでは、

61
00:02:50,034 --> 00:02:53,029
エラーがある場合、その 位置の最後から 2

62
00:02:53,029 --> 00:02:56,160
番目のビットは 1 ですか? と尋ねています。

63
00:02:56,160 --> 00:02:57,160
等々。

64
00:02:57,160 --> 00:03:00,265
3 番目のパリティ チェックは、最後から 3

65
00:03:00,265 --> 00:03:03,775
番目のビットがオンになっているすべての位置をカバー

66
00:03:03,775 --> 00:03:07,015
し、最後のパリティ チェックは、最上位ビットが

67
00:03:07,015 --> 00:03:10,120
1 である最後の 8 つの位置をカバーします。

68
00:03:10,120 --> 00:03:13,109
これまでに行ったことはすべて、これら 4

69
00:03:13,109 --> 00:03:16,241
つの質問に答えることと同じ であり、これはバ

70
00:03:16,241 --> 00:03:19,800
イナリでポジションを詳しく説明することと同じです。

71
00:03:19,800 --> 00:03:22,080
これにより 2 つのことが明確になると思います。

72
00:03:22,080 --> 00:03:24,804
1 つ目は、2 の累乗より大きいブロック

73
00:03:24,804 --> 00:03:27,140
サイズに体系的に一般化する方法です。

74
00:03:27,140 --> 00:03:29,242
64 個のスポットを表すのに 6

75
00:03:29,242 --> 00:03:32,951
ビットなど、各位置を表すのにさらに多くのビットが必要な場合

76
00:03:32,951 --> 00:03:36,661
、それらの各ビットによって、チェックする必要があるパリティ

77
00:03:36,661 --> 00:03:38,640
グループの 1 つが得られます。

78
00:03:38,640 --> 00:03:40,180
私がマット・パーカーと一緒にやったチェス盤の

79
00:03:40,180 --> 00:03:41,720
パズルを見たことがある人 なら、これらすべて

80
00:03:41,720 --> 00:03:43,400
に非常に馴染みのあるものに気づくかもしれません。

81
00:03:43,400 --> 00:03:46,787
これは同じコア ロジックですが、別の問題を解

82
00:03:46,787 --> 00:03:49,880
決し、64 マスのチェス盤に適用されます。

83
00:03:49,880 --> 00:03:52,347
これで明らかになることを望みます 2

84
00:03:52,347 --> 00:03:55,333
つ目は、パリティ ビットが 2 の累乗の位置

85
00:03:55,333 --> 00:03:58,320
(たとえば 1、2、4、8) にある理由です。

86
00:03:58,320 --> 00:04:00,980
これらは、バイナリ表現で 1 つのビ

87
00:04:00,980 --> 00:04:03,640
ットだけがオンになっている位置です。

88
00:04:03,640 --> 00:04:06,192
これが意味するのは、これらのパリティ

89
00:04:06,192 --> 00:04:08,744
ビットはそれぞれ、4 つのパ リティ

90
00:04:08,744 --> 00:04:12,640
グループのうちの 1 つのみの中に存在するということです。

91
00:04:12,640 --> 00:04:16,588
これは、より大きな例でも見ることができます。

92
00:04:16,588 --> 00:04:21,254
この例では、どれだけ大きくな っても、各パリティ

93
00:04:21,254 --> 00:04:25,920
ビットは都合よくグループの 1 つだけに影響します。

94
00:04:25,920 --> 00:04:29,520
私たちが多くの時間を費やしてきたパリティ チェックが、バイ

95
00:04:29,520 --> 00:04:33,120
ナリでエラーの位置を詳しく説明するための賢い方法にすぎない

96
00:04:33,120 --> 00:04:36,720
ことを理解すると、ハミングについての別の考え方との関連性を

97
00:04:36,720 --> 00:04:40,320
引き出すことができます。 コードはおそらくはるかにシンプルで

98
00:04:40,320 --> 00:04:43,920
洗練されており、基本的には 1 行のコードで記述できます。

99
00:04:43,920 --> 00:04:46,200
これは XOR 関数に基づいています。

100
00:04:46,200 --> 00:04:49,117
知らない人のために説明すると、XOR

101
00:04:49,117 --> 00:04:50,960
は排他的論理和の略です。

102
00:04:50,960 --> 00:04:54,040
2 つのビットの XOR を計算すると、それらの

103
00:04:54,040 --> 00:04:56,478
ビットのいずれかがオンで あれば 1

104
00:04:56,478 --> 00:05:00,200
が返されますが、両方がオンまたはオフの場合は返されません。

105
00:05:00,200 --> 00:05:03,760
別の言い方をすると、これはこれら 2 ビットのパリティです。

106
00:05:03,760 --> 00:05:05,800
数学者として、私はこれを加算法

107
00:05:05,800 --> 00:05:07,840
2 として考えることを好みます。

108
00:05:07,840 --> 00:05:10,113
また、2 つの異なるビット文字列の XOR

109
00:05:10,113 --> 00:05:13,213
についてもよく話 しますが、これは基本的にコンポーネントごと

110
00:05:13,213 --> 00:05:14,040
に実行されます。

111
00:05:14,040 --> 00:05:16,280
それは足し算のようなものですが、決して持ち歩かない場所です。

112
00:05:16,280 --> 00:05:19,008
繰り返しますが、より数学的な傾向がある人は、これを

113
00:05:19,008 --> 00:05:21,106
2 つのベクトル を加算し、mod 2

114
00:05:21,106 --> 00:05:23,520
を減らすものと考えることを好むかもしれません。

115
00:05:23,520 --> 00:05:26,711
今すぐ Python を開いて 2

116
00:05:26,711 --> 00:05:29,548
つの整数間にキャレット操作を適

117
00:05:29,548 --> 00:05:33,449
用すると、内部でこれらの数値のビット表現が行

118
00:05:33,449 --> 00:05:35,400
われることになります。

119
00:05:35,400 --> 00:05:40,473
あなたと私にとって重要な点は、多くの異なるビット文字列の

120
00:05:40,473 --> 00:05:44,322
X OR をとることは、列の場合と同様に、多

121
00:05:44,322 --> 00:05:48,170
数の別々のグループの パロディを一度に計算す

122
00:05:48,170 --> 00:05:51,320
る効果的な方法であるということです。

123
00:05:51,320 --> 00:05:54,106
これにより、ハミング コード アルゴリズムからの複数の

124
00:05:54,106 --> 00:05:55,758
パリティ チェックがすべて 1

125
00:05:55,758 --> 00:05:58,544
つの操作にパッケージ化されていると考える、かなり気の利

126
00:05:58,544 --> 00:05:59,680
いた方法が得られます。

127
00:05:59,680 --> 00:06:02,800
一見するとかなり違うように見えますが。

128
00:06:02,800 --> 00:06:05,751
具体的には、以前と同様に 16

129
00:06:05,751 --> 00:06:11,100
個の位置をバイナリで書き留め 、メッセージ ビットが 1

130
00:06:11,100 --> 00:06:15,526
に変わる位置を強調表示し、これ らの位置を 1

131
00:06:15,526 --> 00:06:19,400
つの大きな列に集めて XOR をとります。

132
00:06:19,400 --> 00:06:21,765
おそらく、結果として最下位にある 4

133
00:06:21,765 --> 00:06:25,001
ビットが、私たちがよく知っていて 愛用している 4

134
00:06:25,001 --> 00:06:28,611
つのパリティ チェックと同じであると推測できるでしょ う。

135
00:06:28,611 --> 00:06:31,848
しかし、実際になぜなのかを少し時間を取って実際に考

136
00:06:31,848 --> 00:06:32,720
えてください。

137
00:06:32,720 --> 00:06:35,414
たとえば、この最後の列は、最後のビットが 1

138
00:06:35,414 --> 00:06:38,695
であるすべての位置をカウント していますが、すでに強調表

139
00:06:38,695 --> 00:06:41,624
示された位置のみに制限されているため、事実上、最

140
00:06:41,624 --> 00:06:44,905
初のパリティ グループからの強調表示された位置の数がカウ

141
00:06:44,905 --> 00:06:45,960
ントされています。

142
00:06:45,960 --> 00:06:48,520
それは理にかなっていますか？

143
00:06:48,520 --> 00:06:52,715
同様に、次の列では、2 番目のパリティ グループに位

144
00:06:52,715 --> 00:06:56,755
置がいくつあるか、最後から 2 番目のビットが 1

145
00:06:56,755 --> 00:07:00,640
で、強調表示されている位置などがカウントされます。

146
00:07:00,640 --> 00:07:04,140
それは、私たちがこれまでやってきたことと同

147
00:07:04,140 --> 00:07:07,640
じことについて、視点を少し変えただけです。

148
00:07:07,640 --> 00:07:10,000
ここから先はわかります。

149
00:07:10,000 --> 00:07:14,918
送信者は、合計が 0000 になるように特別なパ

150
00:07:14,918 --> 00:07:19,640
リティ ビットの一部を切り替える責任があります。

151
00:07:19,640 --> 00:07:22,914
このようにすると、結果として得られる下部の

152
00:07:22,914 --> 00:07:25,891
4 つのビットが エラーの位置を直接表す

153
00:07:25,891 --> 00:07:28,720
理由を考える非常に良い方法になります。

154
00:07:28,720 --> 00:07:30,602
このブロック内の一部のビットが

155
00:07:30,602 --> 00:07:32,720
0 から 1 に切り替わるとします。

156
00:07:32,720 --> 00:07:36,793
これが意味するのは、そのビットの位置が合計 XOR に含

157
00:07:36,793 --> 00:07:40,866
まれることになり、合計が 0 から、代わりにこの新しく含

158
00:07:40,866 --> 00:07:44,800
まれた値、つまりエラーの位置に変更されるということです。

159
00:07:44,800 --> 00:07:47,404
少しわかりにくいですが、1 を 0 に変更するエ

160
00:07:47,404 --> 00:07:49,800
ラーが発生した場合も同じことが当てはまります。

161
00:07:49,800 --> 00:07:51,595
ご存知のとおり、ビット列を 2

162
00:07:51,595 --> 00:07:54,400
回追加すると、ビット列がまったく存在しないのと同

163
00:07:54,400 --> 00:07:57,317
じになります。 基本的に、この世界では 1 プラス

164
00:07:57,317 --> 00:07:59,000
1 は 0 に等しいためです。

165
00:07:59,000 --> 00:08:02,352
したがって、この位置のコピーを合計に追加す

166
00:08:02,352 --> 00:08:05,400
ると、移動するのと同じ効果が得られます。

167
00:08:05,400 --> 00:08:09,595
そして、その効果は、やはり、ここの一番下にある合計結

168
00:08:09,595 --> 00:08:13,480
果がエラーの位置を詳しく示しているということです。

169
00:08:13,480 --> 00:08:16,602
これがいかに洗練されているかを説明するために、前に参照した

170
00:08:16,602 --> 00:08:18,788
Python コードの 1 行を示します。

171
00:08:18,788 --> 00:08:21,599
これにより、受信側のロジックのほぼすべてがキャプチャ

172
00:08:21,599 --> 00:08:22,120
されます。

173
00:08:22,120 --> 00:08:25,416
まず、データ ブロックをシミュレートするために 16 個の

174
00:08:25,416 --> 00:08:28,602
1 と 0 の ランダムな配列を作成し、それに bits

175
00:08:28,602 --> 00:08:30,360
という名前を付けますが、もちろ

176
00:08:30,360 --> 00:08:33,216
ん実際には、これは送信者から受信するものになります。

177
00:08:33,216 --> 00:08:36,292
ランダムであるため、1 1 個のデータ ビットと 5

178
00:08:36,292 --> 00:08:38,600
個のパリティ ビットを運ぶことになります。

179
00:08:38,600 --> 00:08:41,813
enumerateBits 関数を呼び出すと、こ

180
00:08:41,813 --> 00:08:45,428
れらの各ビットが対応する インデックス (この場合は

181
00:08:45,428 --> 00:08:48,240
0 から 15 まで) とペアになります。

182
00:08:48,240 --> 00:08:51,444
したがって、これらすべてのペア (i に似たペア)

183
00:08:51,444 --> 00:08:53,539
をループするリストを作 成し、i

184
00:08:53,539 --> 00:08:56,374
の値だけ、インデックスだけを取り出すとします。

185
00:08:56,374 --> 00:08:58,715
それほど面白いこ とではありません。

186
00:08:58,715 --> 00:09:01,920
インデックス 0 から 15 が返されるだけです。

187
00:09:01,920 --> 00:09:05,833
しかし、ビットの場合のみ、つまりそのビットが 0 ではなく

188
00:09:05,833 --> 00:09:09,616
1 である場合にのみこれを実 行するという条件を追加すると

189
00:09:09,616 --> 00:09:13,400
、対応するビットがオンになっている位置のみが抽出されます。

190
00:09:13,400 --> 00:09:18,203
この場合、それらの位置は 0、4、6、9

191
00:09:18,203 --> 00:09:20,720
などのように見えます。

192
00:09:20,720 --> 00:09:23,800
私たちが望んでいるのは、これらの位置、つま

193
00:09:23,800 --> 00:09:28,053
りオンになっているビ ットの位置をすべて収集し、それらを

194
00:09:28,053 --> 00:09:29,960
XOR 演算することです。

195
00:09:29,960 --> 00:09:31,908
これを Python で行うには、まず

196
00:09:31,908 --> 00:09:33,960
いくつかの便利な関数をインポートします。

197
00:09:33,960 --> 00:09:36,550
そうすることで、このリストに対してreduce()を呼び

198
00:09:36,550 --> 00:09:39,140
出し、XOR関数を使用してリストを減らすことができます。

199
00:09:39,140 --> 00:09:42,880
これは基本的にリスト全体を処理し、途中で

200
00:09:42,880 --> 00:09:44,840
XOR を取得します。

201
00:09:44,840 --> 00:09:48,687
必要に応じて、XOR 関数をどこからもインポ

202
00:09:48,687 --> 00:09:52,200
ートせずに明示的に書き出すことができます。

203
00:09:52,200 --> 00:09:55,739
したがって、現時点では、16 ビットのランダム

204
00:09:55,739 --> 00:09:58,983
ブロックでこれを実 行すると、バイナリ表現

205
00:09:58,983 --> 00:10:02,080
1001 を持つ 9 が返されるようです。

206
00:10:02,080 --> 00:10:05,860
ここではそれを行いませんが、送信者がそのバイナリ表現を使用し

207
00:10:05,860 --> 00:10:08,002
て必要に応じて 4 つのパリティ

208
00:10:08,002 --> 00:10:11,782
ビットを設定し、最終的にこのブロックをビットの完全なリストに

209
00:10:11,782 --> 00:10:15,562
対して このコード行を実行すると返される状態にする関数を作成

210
00:10:15,562 --> 00:10:17,200
することもできます。 0。

211
00:10:17,200 --> 00:10:20,200
これは、十分に準備されたブロックであると考えられます。

212
00:10:20,200 --> 00:10:23,624
素晴らしいのは、このリストのビットのいずれかを切り替え

213
00:10:23,624 --> 00:10:27,048
て、ノイズによるランダムなエ ラーをシミュレートし、同

214
00:10:27,048 --> 00:10:30,600
じコード行を実行すると、そのエラーが出力されることです。

215
00:10:30,600 --> 00:10:31,920
素敵じゃないですか？

216
00:10:31,920 --> 00:10:35,377
このブロックを突然取得し、その上でこの 1

217
00:10:35,377 --> 00:10:38,991
行を実行すると、エラーの位 置が自動的に出力さ

218
00:10:38,991 --> 00:10:42,920
れ、エラーが存在しない場合は 0 が出力されます。

219
00:10:42,920 --> 00:10:45,520
サイズ 16 については特別なことは何もありません。

220
00:10:45,520 --> 00:10:48,803
たとえば 256 ビットのリストが

221
00:10:48,803 --> 00:10:52,280
ある場合、同じコード行が機能します。

222
00:10:52,280 --> 00:10:55,266
言うまでもなく、2 ビット エラーを検出するためのメタ

223
00:10:55,266 --> 00:10:58,466
パリティ チェックの実行 など、ここで記述するコードはさらに

224
00:10:58,466 --> 00:11:01,026
ありますが、考え方としては、このスキームのコア

225
00:11:01,026 --> 00:11:03,053
ロジックのほぼすべてが単一の XOR

226
00:11:03,053 --> 00:11:05,080
リダクションに帰結するということです。

227
00:11:05,080 --> 00:11:08,550
さて、バイナリ、XOR、およびソフトウェア全般に慣れている

228
00:11:08,550 --> 00:11:12,020
かどうかに応じて、こ の視点が少しわかりにくいと感じるか、

229
00:11:12,020 --> 00:11:14,653
またははるかにエレガントでシンプルなので、

230
00:11:14,653 --> 00:11:18,123
なぜ最初からこの視点を始めなかったのかと不思議に思うかもし

231
00:11:18,123 --> 00:11:19,320
れません。 -行く。

232
00:11:19,320 --> 00:11:22,832
大まかに言うと、複数のパリティ チェックの観点は、ハミング

233
00:11:22,832 --> 00:11:25,759
コードを ハードウェアで直接実装する場合に考えやす

234
00:11:25,759 --> 00:11:28,686
く、XOR の観点は、ソフト ウェアで実行する場合

235
00:11:28,686 --> 00:11:31,380
に、より高いレベルから考えるのが最も簡単です。

236
00:11:31,380 --> 00:11:34,611
最初の方法は実際に手作業で行うのが最も簡単で、これら

237
00:11:34,611 --> 00:11:37,843
すべての根底にある核となる 直感を植え付けるのに効果

238
00:11:37,843 --> 00:11:41,324
的だと思います。 つまり、単一のエラーを見つけるのに必

239
00:11:41,324 --> 00:11:44,556
要な情報はブロックのサイズのログに関連しているという

240
00:11:44,556 --> 00:11:47,663
ことです。 、言い換えれば 、ブロック サイズが

241
00:11:47,663 --> 00:11:51,020
2 倍になると、一度に 1 ビットずつ大きくなります。

242
00:11:51,020 --> 00:11:53,796
ここで重要な事実は、その情報が必要な冗長

243
00:11:53,796 --> 00:11:56,440
性の量に直接対応しているということです。

244
00:11:56,440 --> 00:12:00,177
これは、ほとんどの人が最初にメッセージをエラーに強いも

245
00:12:00,177 --> 00:12:03,915
のにしようと考えたとき、通常はメッセージ全体をコピーす

246
00:12:03,915 --> 00:12:07,520
ることが最初に頭に浮かぶ本能的な反応に反するものです。

247
00:12:07,520 --> 00:12:09,032
そして、ところで、時々ハミング

248
00:12:09,032 --> 00:12:11,207
コードが表示されるのを目にすることがあります

249
00:12:11,207 --> 00:12:13,570
が、これとはまったく別の方法で、メッセージに 1

250
00:12:13,570 --> 00:12:14,800
つの大きな行列を掛けます。

251
00:12:14,800 --> 00:12:17,308
これは、線形コードのより広範なファミリーに関連

252
00:12:17,308 --> 00:12:20,034
付けられているため、ある意味素晴らしいですが、そ

253
00:12:20,034 --> 00:12:22,542
れがどこから来たのか、どのようにスケールするの

254
00:12:22,542 --> 00:12:25,160
かについてはほとんど直観が得られないと思います。

255
00:12:25,160 --> 00:12:27,389
スケーリングについて言えば、ブロック

256
00:12:27,389 --> 00:12:30,909
サイズが増加するにつれ てこのスキームの効率が向上することに

257
00:12:30,909 --> 00:12:32,200
気づくかもしれません。

258
00:12:32,200 --> 00:12:37,104
たとえば、256 ビットでは、冗長性のためにそのスペースの

259
00:12:37,104 --> 00:12:40,864
3% の みが使用されており、そこからさらに改

260
00:12:40,864 --> 00:12:43,480
善され続けることがわかりました。

261
00:12:43,480 --> 00:12:47,018
パリティ ビットの数が 1 つずつ増加すると、ブロック

262
00:12:47,018 --> 00:12:49,040
サイズは 2 倍になり続けます。

263
00:12:49,040 --> 00:12:51,724
これを極端に解釈すると、たとえば 100

264
00:12:51,724 --> 00:12:54,536
万ビットのブロック があり、文字通り 20

265
00:12:54,536 --> 00:12:56,965
問のパリティ チェックを行うことにな

266
00:12:56,965 --> 00:13:00,800
り、使用するパリティ ビットは 21 ビットだけになります。

267
00:13:00,800 --> 00:13:04,855
そして、百万ビットを調べて単一のエラーを見つけることを一歩

268
00:13:04,855 --> 00:13:08,640
下がって考えると、それは本当にクレイジーに感じられます。

269
00:13:08,640 --> 00:13:11,880
もちろん、問題は、ブロックが大きくなると、1 つまたは

270
00:13:11,880 --> 00:13:15,120
2 つ以上のビット エラーが 発生する確率が高くなり、ハ

271
00:13:15,120 --> 00:13:18,360
ミング コードがそれを超えるものを処理できないことです。

272
00:13:18,360 --> 00:13:22,511
したがって、実際には、ビット フリップが多すぎる可能性が

273
00:13:22,511 --> 00:13:26,520
高すぎないように、適切なサイズを見つけることが必要です。

274
00:13:26,520 --> 00:13:30,312
また、実際には、エラーは小さなバーストで発生する傾向があり、

275
00:13:30,312 --> 00:13:32,840
単一のブロックを完全に破壊してしまうた

276
00:13:32,840 --> 00:13:36,632
め、エラーのバーストを多くの異なるブロックに分散させるための

277
00:13:36,632 --> 00:13:39,160
一般的な戦術の 1 つは、ブロックがブ

278
00:13:39,160 --> 00:13:42,952
ロックされる前に、このようにそれらのブロックをインターレース

279
00:13:42,952 --> 00:13:45,480
することです。 発送または保管されます。

280
00:13:45,480 --> 00:13:48,255
しかし、繰り返しになりますが、この多くは、より一般

281
00:13:48,255 --> 00:13:50,365
的に使用されているリードソロモン ア

282
00:13:50,365 --> 00:13:53,140
ルゴリズムなど、バースト エラーを特にうまく処理し

283
00:13:53,140 --> 00:13:55,139
、ブロックあたりのより多くのエラー

284
00:13:55,139 --> 00:13:57,914
に耐性を持つように調整できる、より現代的なコードに

285
00:13:57,914 --> 00:13:59,580
よって完全に無意味になります。

286
00:13:59,580 --> 00:14:03,000
しかし、それはまた別の機会にお話します。

287
00:14:03,000 --> 00:14:04,982
ハミング氏は著書『The Art of Doing

288
00:14:04,982 --> 00:14:06,888
Science and Engineering』

289
00:14:06,888 --> 00:14:08,794
の中で、このコードの発見がどれほど曲がりくねったも

290
00:14:08,794 --> 00:14:10,700
のであったかについて、驚くほど率直に語っています。

291
00:14:10,700 --> 00:14:13,194
彼はまず、ビットを高次元の格子の一部に組織

292
00:14:13,194 --> 00:14:15,688
することや、このような 奇妙なことを含む、

293
00:14:15,688 --> 00:14:18,420
あらゆる種類のさまざまなスキームを試しました。

294
00:14:18,420 --> 00:14:20,649
エラーの位置を明らかにする方法でパリティ

295
00:14:20,649 --> 00:14:23,516
チェックを共謀させること ができるかもしれないという考

296
00:14:23,516 --> 00:14:25,640
えがハミングに思いついたのは、ハミング

297
00:14:25,640 --> 00:14:28,506
が他の一連の分析を終えて一歩下がって、「わかった、私に

298
00:14:28,506 --> 00:14:31,267
できる最も効 率的なものは何か」と尋ねたときでした。

299
00:14:31,267 --> 00:14:32,860
おそらくこれについてですか？

300
00:14:32,860 --> 00:14:35,155
彼はまた、パリティ チェックがすでに頭の中にあ

301
00:14:35,155 --> 00:14:37,849
ったことがいかに重要であるかについても率直に 語った。

302
00:14:37,849 --> 00:14:40,144
1940 年代にはパリティ チェックは現在よ

303
00:14:40,144 --> 00:14:42,040
りもはるかに一般的ではなかったはずだ。

304
00:14:42,040 --> 00:14:45,980
この本の中で、ルイ・パスツールの名言「幸運は準備ができ

305
00:14:45,980 --> 00:14:49,640
た心に味方する」という言葉が何度も引用されています。

306
00:14:49,640 --> 00:14:52,380
賢いアイデアは、後から考えると一見シンプル

307
00:14:52,380 --> 00:14:55,120
に見えることが多く、過小評価されがちです。

308
00:14:55,120 --> 00:14:57,353
今のところ私の正直な願いは、ハミング符号、あ

309
00:14:57,353 --> 00:14:59,586
るいは少なくともそのよ うな符号の可能性が、

310
00:14:59,586 --> 00:15:01,820
皆さんにとってほぼ明白に感じられることです。

311
00:15:01,820 --> 00:15:04,973
しかし、それらは決して明らかではないので、それら

312
00:15:04,973 --> 00:15:08,000
が実際には明白であると思い込む必要はありません。

313
00:15:08,000 --> 00:15:10,625
賢いアイデアが一見簡単そうに見える理由の 1

314
00:15:10,625 --> 00:15:13,821
つは、私たちは最終的な 結果しか見ていないこと、散らかっ

315
00:15:13,821 --> 00:15:15,990
たものを片づけること、間違った方向へ

316
00:15:15,990 --> 00:15:19,186
の言及がまったくないこと、問題の開始時に探索可能な可能性

317
00:15:19,186 --> 00:15:22,382
の空間がいか に広大であるかを過小評価していることです。

318
00:15:22,382 --> 00:15:23,980
解決プロセス、そのすべて。

319
00:15:23,980 --> 00:15:25,280
しかし、これは一般的に真実です。

320
00:15:25,280 --> 00:15:28,275
一部の特別な発明については、私たちがそれらを過小評

321
00:15:28,275 --> 00:15:31,040
価している第二の、より深い理由があると思います。

322
00:15:31,040 --> 00:15:33,570
情報をビットの観点から考えることは、1948

323
00:15:33,570 --> 00:15:35,330
年までにクロード シャノンによ

324
00:15:35,330 --> 00:15:38,080
る情報理論に関する独創的な論文によってようやく完全

325
00:15:38,080 --> 00:15:39,400
な理論に統合されました。

326
00:15:39,400 --> 00:15:41,362
これは基本的に、ハミングがアルゴリ

327
00:15:41,362 --> 00:15:43,440
ズムを開発したときと同時進行でした。

328
00:15:43,440 --> 00:15:47,078
これは、ビット反転の確率がどれほど高くても、少な

329
00:15:47,078 --> 00:15:50,572
くとも理論上は、ある意味、効率的なエラー訂正が

330
00:15:50,572 --> 00:15:53,920
常に可能であることを示した同じ基礎論文でした。

331
00:15:53,920 --> 00:15:56,673
ちなみに、シャノンとハミングは、まったく異なること

332
00:15:56,673 --> 00:15:59,426
に取り組んでいたにもかかわ らず、ベル研究所でオフ

333
00:15:59,426 --> 00:16:02,400
ィスを共有していましたが、ここでは偶然とは思えません。

334
00:16:02,400 --> 00:16:05,960
数十年が経ち、最近では私たちの多くが断片や情報

335
00:16:05,960 --> 00:16:09,520
について考えることに没 頭しているため、この考

336
00:16:09,520 --> 00:16:13,080
え方がいかに独特であったかを見落としがちです。

337
00:16:13,080 --> 00:16:14,645
皮肉なことに、将来の世代の考え方を最も深く形

338
00:16:14,645 --> 00:16:16,211
作っているアイデアは、最 終的にはその将来の

339
00:16:16,211 --> 00:16:17,920
世代にとって実際よりも単純なものになるでしょう。

