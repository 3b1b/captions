1
00:00:00,000 --> 00:00:03,120
ここにいる皆さんはパート1から来ていると思います。

2
00:00:03,120 --> 00:00:06,920
私たちはハミング コードについて話していました。これは、ほとんどのビットが意味のあ

3
00:00:06,920 --> 00:00:11,640
るメッセージを運ぶデータ ブロックを作成する方法であり、他のいくつかのビットは一種

4
00:00:11,640 --> 00:00:15,800
の冗長性として機能し、ビットが反転した場合、メッセージが送信されるか、メッセージが

5
00:00:15,800 --> 00:00:20,560
送信されるかが決まります。ビットや冗長ビットなど、このブロック内のあらゆるものによ

6
00:00:20,560 --> 00:00:21,920
って、受信機はエラーがあったことと、それを修正する方法を識別できるようになります。

7
00:00:21,920 --> 00:00:25,900
そこで提示された基本的なアイデアは、複数のパリティ チェッ

8
00:00:25,900 --> 00:00:29,800
クを使用してエラーに至るまでバイナリ検索を行う方法でした。

9
00:00:29,800 --> 00:00:33,920
このビデオの目標は、ハミング コードをできる限り実

10
00:00:33,920 --> 00:00:35,420
際に操作でき、再発見できるようにすることでした。

11
00:00:35,420 --> 00:00:40,040
しかし、これをソフトウェアまたはハードウェアで実際に実装することを考え始めると、その枠組みに

12
00:00:40,040 --> 00:00:44,120
よって、これらのコードが実際にどれほどエレガントであるかが実際に理解できないかもしれません。

13
00:00:44,120 --> 00:00:47,620
考えられるすべてのエラー位置を追跡し、各チェックでそのグル

14
00:00:47,620 --> 00:00:52,320
ープを半分に分割するアルゴリズムを作成する必要があると思

15
00:00:52,320 --> 00:00:54,160
うかもしれませんが、実際にはそれよりもはるかに簡単です。

16
00:00:54,160 --> 00:00:58,720
前回のビデオで行った 4 つのパリティ チェックの答えを、すべて「はい」と「いいえ」では

17
00:00:58,760 --> 00:01:04,800
なく「1」と「0」として読み上げると、文字通りエラーの位置が 2 進数で表示されます。

18
00:01:04,800 --> 00:01:10,160
たとえば、2 進数の 7 は 0111 のように見え、本質的

19
00:01:10,160 --> 00:01:12,640
には 4 プラス 2 プラス 1 であることを示しています。

20
00:01:12,640 --> 00:01:17,960
位置 7 がどこに位置するかに注目してください。パリティ グループ

21
00:01:17,960 --> 00:01:22,280
の最初、2 番目、3 番目には影響しますが、最後には影響しません。

22
00:01:22,280 --> 00:01:26,560
したがって、これら 4 つのチェックの結果を下か

23
00:01:26,560 --> 00:01:28,000
ら上に読むと、エラーの位置が明らかになります。

24
00:01:28,520 --> 00:01:32,240
例 7 には特別なことは何もありません。これは一般的に機能し、ハードウ

25
00:01:32,240 --> 00:01:37,440
ェアでスキーム全体を実装するためのロジックが驚くほど単純になります。

26
00:01:37,440 --> 00:01:43,380
この魔法がなぜ起こるのかを知りたい場合は、これらの 16 個のインデック

27
00:01:43,380 --> 00:01:48,480
ス ラベルを位置に取ってください。ただし、それらを 10 進数で書く代わ

28
00:01:48,480 --> 00:01:50,720
りに、0000 から 1111 までのバイナリですべて書いてみましょう。

29
00:01:50,720 --> 00:01:55,880
これらのバイナリ ラベルを箱に戻すときに、実際に送信

30
00:01:56,080 --> 00:01:58,440
されるデータとは区別されることを強調しておきます。

31
00:01:58,440 --> 00:02:02,200
これらは、4 つのパリティ グループがどこから来たの

32
00:02:02,200 --> 00:02:04,200
かを理解するのに役立つ概念的なラベルにすぎません。

33
00:02:04,200 --> 00:02:08,840
私たちが見ているものすべてがバイナリで記述されることの優雅さは、おそらく、私たち

34
00:02:08,840 --> 00:02:13,160
が見ているものすべてがバイナリで記述されることの混乱によって損なわれるでしょう。

35
00:02:13,160 --> 00:02:15,040
ただし、それだけの価値はあります。

36
00:02:15,040 --> 00:02:20,740
これらすべてのラベルの最後のビットに注目し、その

37
00:02:20,740 --> 00:02:24,280
最後のビットが 1 である位置を強調表示します。

38
00:02:24,280 --> 00:02:28,800
得られるのは 4 つのパリティ グループの最初のグループです。つ

39
00:02:28,800 --> 00:02:34,480
まり、最初のチェックは、エラーがある場合、そのエラーの位置にある

40
00:02:34,480 --> 00:02:36,680
最後のビットは 1 ですか? という質問であると解釈できます。

41
00:02:36,680 --> 00:02:42,600
同様に、最後から 2 番目のビットに注目し、それが 1 であるすべての位置

42
00:02:42,600 --> 00:02:47,040
を強調表示すると、スキームから 2 番目のパリティ グループが得られます。

43
00:02:47,040 --> 00:02:51,960
言い換えれば、その 2 番目のチェックでは、エラーがある場合、その

44
00:02:51,960 --> 00:02:56,160
位置の最後から 2 番目のビットは 1 ですか? と尋ねています。

45
00:02:56,160 --> 00:02:57,160
等々。

46
00:02:57,160 --> 00:03:03,320
3 番目のパリティ チェックは、最後から 3 番目のビットがオンになっているすべての位置をカバー

47
00:03:03,320 --> 00:03:10,120
し、最後のパリティ チェックは、最上位ビットが 1 である最後の 8 つの位置をカバーします。

48
00:03:10,120 --> 00:03:15,680
これまでに行ったことはすべて、これら 4 つの質問に答えることと同じ

49
00:03:15,680 --> 00:03:18,800
であり、これはバイナリでポジションを詳しく説明することと同じです。

50
00:03:19,800 --> 00:03:22,080
これにより 2 つのことが明確になると思います。

51
00:03:22,080 --> 00:03:27,140
1 つ目は、2 の累乗より大きいブロック サイズに体系的に一般化する方法です。

52
00:03:27,140 --> 00:03:33,180
64 個のスポットを表すのに 6 ビットなど、各位置を表すのにさらに多くのビットが必要な場合

53
00:03:33,180 --> 00:03:38,640
、それらの各ビットによって、チェックする必要があるパリティ グループの 1 つが得られます。

54
00:03:38,640 --> 00:03:42,060
私がマット・パーカーと一緒にやったチェス盤のパズルを見たことがある人

55
00:03:42,060 --> 00:03:43,400
なら、これらすべてに非常に馴染みのあるものに気づくかもしれません。

56
00:03:43,400 --> 00:03:48,200
これは同じコア ロジックですが、別の問題を解

57
00:03:48,200 --> 00:03:49,880
決し、64 マスのチェス盤に適用されます。

58
00:03:49,880 --> 00:03:54,000
これで明らかになることを望みます 2 つ目は、パリティ ビットが

59
00:03:54,000 --> 00:03:58,320
2 の累乗の位置 (たとえば 1、2、4、8) にある理由です。

60
00:03:58,320 --> 00:04:03,640
これらは、バイナリ表現で 1 つのビットだけがオンになっている位置です。

61
00:04:03,640 --> 00:04:09,000
これが意味するのは、これらのパリティ ビットはそれぞれ、4 つのパ

62
00:04:09,000 --> 00:04:12,640
リティ グループのうちの 1 つのみの中に存在するということです。

63
00:04:12,640 --> 00:04:16,840
これは、より大きな例でも見ることができます。この例では、どれだけ大きくな

64
00:04:16,840 --> 00:04:25,920
っても、各パリティ ビットは都合よくグループの 1 つだけに影響します。

65
00:04:25,920 --> 00:04:29,680
私たちが多くの時間を費やしてきたパリティ チェックが、バイ

66
00:04:29,680 --> 00:04:34,320
ナリでエラーの位置を詳しく説明するための賢い方法にすぎない

67
00:04:34,320 --> 00:04:37,880
ことを理解すると、ハミングについての別の考え方との関連性を

68
00:04:37,880 --> 00:04:42,160
引き出すことができます。コードはおそらくはるかにシンプルで

69
00:04:42,160 --> 00:04:43,880
洗練されており、基本的には 1 行のコードで記述できます。

70
00:04:43,920 --> 00:04:46,200
これは XOR 関数に基づいています。

71
00:04:46,200 --> 00:04:50,960
知らない人のために説明すると、XOR は排他的論理和の略です。

72
00:04:50,960 --> 00:04:55,440
2 つのビットの XOR を計算すると、それらのビットのいずれかがオンで

73
00:04:55,440 --> 00:05:00,200
あれば 1 が返されますが、両方がオンまたはオフの場合は返されません。

74
00:05:00,200 --> 00:05:03,760
別の言い方をすると、これはこれら 2 ビットのパリティです。

75
00:05:03,760 --> 00:05:07,840
数学者として、私はこれを加算法 2 として考えることを好みます。

76
00:05:07,840 --> 00:05:12,000
また、2 つの異なるビット文字列の XOR についてもよく話

77
00:05:12,040 --> 00:05:14,040
しますが、これは基本的にコンポーネントごとに実行されます。

78
00:05:14,040 --> 00:05:16,280
それは足し算のようなものですが、決して持ち歩かない場所です。

79
00:05:16,280 --> 00:05:21,240
繰り返しますが、より数学的な傾向がある人は、これを 2 つのベクトル

80
00:05:21,240 --> 00:05:23,520
を加算し、mod 2 を減らすものと考えることを好むかもしれません。

81
00:05:23,520 --> 00:05:28,720
今すぐ Python を開いて 2 つの整数間にキャレット操作を適

82
00:05:28,720 --> 00:05:35,400
用すると、内部でこれらの数値のビット表現が行われることになります。

83
00:05:35,400 --> 00:05:40,920
あなたと私にとって重要な点は、多くの異なるビット文字列の X

84
00:05:40,960 --> 00:05:45,960
OR をとることは、列の場合と同様に、多数の別々のグループの

85
00:05:45,960 --> 00:05:51,320
パロディを一度に計算する効果的な方法であるということです。

86
00:05:51,320 --> 00:05:54,520
これにより、ハミング コード アルゴリズムからの複数のパリティ チェックがすべて

87
00:05:54,520 --> 00:05:59,680
1 つの操作にパッケージ化されていると考える、かなり気の利いた方法が得られます。

88
00:05:59,680 --> 00:06:02,800
一見するとかなり違うように見えますが。

89
00:06:02,800 --> 00:06:08,360
具体的には、以前と同様に 16 個の位置をバイナリで書き留め

90
00:06:08,640 --> 00:06:14,800
、メッセージ ビットが 1 に変わる位置を強調表示し、これ

91
00:06:14,800 --> 00:06:19,400
らの位置を 1 つの大きな列に集めて XOR をとります。

92
00:06:19,400 --> 00:06:23,480
おそらく、結果として最下位にある 4 ビットが、私たちがよく知っていて

93
00:06:23,480 --> 00:06:27,480
愛用している 4 つのパリティ チェックと同じであると推測できるでしょ

94
00:06:27,480 --> 00:06:32,720
う。しかし、実際になぜなのかを少し時間を取って実際に考えてください。

95
00:06:32,720 --> 00:06:37,880
たとえば、この最後の列は、最後のビットが 1 であるすべての位置をカウント

96
00:06:38,400 --> 00:06:42,400
していますが、すでに強調表示された位置のみに制限されているため、事実上、最

97
00:06:42,400 --> 00:06:45,960
初のパリティ グループからの強調表示された位置の数がカウントされています。

98
00:06:45,960 --> 00:06:48,520
それは理にかなっていますか？

99
00:06:48,520 --> 00:06:53,600
同様に、次の列では、2 番目のパリティ グループに位

100
00:06:53,600 --> 00:06:59,640
置がいくつあるか、最後から 2 番目のビットが 1

101
00:06:59,640 --> 00:07:00,640
で、強調表示されている位置などがカウントされます。

102
00:07:00,640 --> 00:07:06,640
それは、私たちがこれまでやってきたことと同じことについて、視点を少し変えただけです。

103
00:07:07,640 --> 00:07:10,000
ここから先はわかります。

104
00:07:10,000 --> 00:07:14,400
送信者は、合計が 0000 になるように特別なパ

105
00:07:14,400 --> 00:07:19,640
リティ ビットの一部を切り替える責任があります。

106
00:07:19,640 --> 00:07:23,600
このようにすると、結果として得られる下部の 4 つのビットが

107
00:07:23,600 --> 00:07:28,720
エラーの位置を直接表す理由を考える非常に良い方法になります。

108
00:07:28,720 --> 00:07:32,680
このブロック内の一部のビットが 0 から 1 に切り替わるとします。

109
00:07:32,720 --> 00:07:37,320
これが意味するのは、そのビットの位置が合計 XOR に含

110
00:07:37,320 --> 00:07:42,960
まれることになり、合計が 0 から、代わりにこの新しく含

111
00:07:42,960 --> 00:07:44,800
まれた値、つまりエラーの位置に変更されるということです。

112
00:07:44,800 --> 00:07:48,800
少しわかりにくいですが、1 を 0 に変更するエ

113
00:07:48,800 --> 00:07:49,800
ラーが発生した場合も同じことが当てはまります。

114
00:07:49,800 --> 00:07:54,720
ご存知のとおり、ビット列を 2 回追加すると、ビット列がまったく存在しないのと同

115
00:07:54,720 --> 00:07:59,000
じになります。基本的に、この世界では 1 プラス 1 は 0 に等しいためです。

116
00:07:59,000 --> 00:08:03,720
したがって、この位置のコピーを合計に追加す

117
00:08:03,720 --> 00:08:05,400
ると、移動するのと同じ効果が得られます。

118
00:08:05,400 --> 00:08:10,080
そして、その効果は、やはり、ここの一番下にある合計結

119
00:08:10,080 --> 00:08:13,480
果がエラーの位置を詳しく示しているということです。

120
00:08:13,480 --> 00:08:17,720
これがいかに洗練されているかを説明するために、前に参照した Python コードの

121
00:08:17,720 --> 00:08:22,120
1 行を示します。これにより、受信側のロジックのほぼすべてがキャプチャされます。

122
00:08:22,120 --> 00:08:27,160
まず、データ ブロックをシミュレートするために 16 個の 1 と 0 の

123
00:08:27,160 --> 00:08:31,160
ランダムな配列を作成し、それに bits という名前を付けますが、もちろ

124
00:08:31,160 --> 00:08:36,160
ん実際には、これは送信者から受信するものになります。ランダムであるため、1

125
00:08:36,160 --> 00:08:38,600
1 個のデータ ビットと 5 個のパリティ ビットを運ぶことになります。

126
00:08:38,600 --> 00:08:43,160
enumerateBits 関数を呼び出すと、これらの各ビットが対応する

127
00:08:43,160 --> 00:08:48,240
インデックス (この場合は 0 から 15 まで) とペアになります。

128
00:08:48,240 --> 00:08:53,200
したがって、これらすべてのペア (i に似たペア) をループするリストを作

129
00:08:53,200 --> 00:08:59,160
成し、i の値だけ、インデックスだけを取り出すとします。それほど面白いこ

130
00:08:59,160 --> 00:09:01,920
とではありません。インデックス 0 から 15 が返されるだけです。 。

131
00:09:01,920 --> 00:09:07,520
しかし、ビットの場合のみ、つまりそのビットが 0 ではなく 1 である場合にのみこれを実

132
00:09:07,520 --> 00:09:13,400
行するという条件を追加すると、対応するビットがオンになっている位置のみが抽出されます。

133
00:09:13,400 --> 00:09:20,320
この場合、それらの位置は 0、4、6、9 などのように見えます。

134
00:09:20,720 --> 00:09:24,640
私たちが望んでいるのは、これらの位置、つまりオンになっているビ

135
00:09:24,640 --> 00:09:29,960
ットの位置をすべて収集し、それらを XOR 演算することです。

136
00:09:29,960 --> 00:09:33,960
これを Python で行うには、まずいくつかの便利な関数をインポートします。

137
00:09:33,960 --> 00:09:39,140
そうすることで、このリストに対してreduce()を呼び出し、XOR関数を使用してリストを減らすことができます。

138
00:09:39,140 --> 00:09:44,840
これは基本的にリスト全体を処理し、途中で XOR を取得します。

139
00:09:44,840 --> 00:09:48,760
必要に応じて、XOR 関数をどこからもインポ

140
00:09:48,800 --> 00:09:52,200
ートせずに明示的に書き出すことができます。

141
00:09:52,200 --> 00:09:56,880
したがって、現時点では、16 ビットのランダム ブロックでこれを実

142
00:09:56,880 --> 00:10:02,080
行すると、バイナリ表現 1001 を持つ 9 が返されるようです。

143
00:10:02,080 --> 00:10:05,960
ここではそれを行いませんが、送信者がそのバイナリ表現を使用して必要に応じて 4

144
00:10:05,960 --> 00:10:11,560
つのパリティ ビットを設定し、最終的にこのブロックをビットの完全なリストに対して

145
00:10:11,560 --> 00:10:16,200
このコード行を実行すると返される状態にする関数を作成することもできます。 0。

146
00:10:17,200 --> 00:10:20,200
これは、十分に準備されたブロックであると考えられます。

147
00:10:20,200 --> 00:10:24,640
素晴らしいのは、このリストのビットのいずれかを切り替えて、ノイズによるランダムなエ

148
00:10:24,640 --> 00:10:30,600
ラーをシミュレートし、同じコード行を実行すると、そのエラーが出力されることです。

149
00:10:30,600 --> 00:10:31,920
素敵じゃないですか？

150
00:10:31,920 --> 00:10:37,200
このブロックを突然取得し、その上でこの 1 行を実行すると、エラーの位

151
00:10:37,200 --> 00:10:42,920
置が自動的に出力され、エラーが存在しない場合は 0 が出力されます。

152
00:10:42,920 --> 00:10:45,520
サイズ 16 については特別なことは何もありません。

153
00:10:45,520 --> 00:10:52,280
たとえば 256 ビットのリストがある場合、同じコード行が機能します。

154
00:10:52,280 --> 00:10:56,280
言うまでもなく、2 ビット エラーを検出するためのメタ パリティ チェックの実行

155
00:10:56,280 --> 00:11:01,440
など、ここで記述するコードはさらにありますが、考え方としては、このスキームのコア

156
00:11:01,440 --> 00:11:05,080
ロジックのほぼすべてが単一の XOR リダクションに帰結するということです。

157
00:11:05,080 --> 00:11:10,600
さて、バイナリ、XOR、およびソフトウェア全般に慣れているかどうかに応じて、こ

158
00:11:10,600 --> 00:11:15,880
の視点が少しわかりにくいと感じるか、またははるかにエレガントでシンプルなので、

159
00:11:15,880 --> 00:11:19,320
なぜ最初からこの視点を始めなかったのかと不思議に思うかもしれません。 -行く。

160
00:11:19,320 --> 00:11:22,880
大まかに言うと、複数のパリティ チェックの観点は、ハミング コードを

161
00:11:22,880 --> 00:11:27,560
ハードウェアで直接実装する場合に考えやすく、XOR の観点は、ソフト

162
00:11:27,560 --> 00:11:31,380
ウェアで実行する場合に、より高いレベルから考えるのが最も簡単です。

163
00:11:31,380 --> 00:11:35,640
最初の方法は実際に手作業で行うのが最も簡単で、これらすべての根底にある核となる

164
00:11:35,640 --> 00:11:40,720
直感を植え付けるのに効果的だと思います。つまり、単一のエラーを見つけるのに必

165
00:11:40,720 --> 00:11:46,840
要な情報はブロックのサイズのログに関連しているということです。 、言い換えれば

166
00:11:46,840 --> 00:11:51,020
、ブロック サイズが 2 倍になると、一度に 1 ビットずつ大きくなります。

167
00:11:51,020 --> 00:11:55,440
ここで重要な事実は、その情報が必要な冗長

168
00:11:55,440 --> 00:11:56,440
性の量に直接対応しているということです。

169
00:11:56,440 --> 00:12:00,320
これは、ほとんどの人が最初にメッセージをエラーに強いも

170
00:12:00,320 --> 00:12:05,280
のにしようと考えたとき、通常はメッセージ全体をコピーす

171
00:12:05,280 --> 00:12:07,520
ることが最初に頭に浮かぶ本能的な反応に反するものです。

172
00:12:07,520 --> 00:12:11,120
そして、ところで、時々ハミング コードが表示されるのを目にすることがあります

173
00:12:11,120 --> 00:12:14,800
が、これとはまったく別の方法で、メッセージに 1 つの大きな行列を掛けます。

174
00:12:14,800 --> 00:12:18,580
これは、線形コードのより広範なファミリーに関連付けられているため、ある意味素晴らしいですが、そ

175
00:12:18,580 --> 00:12:25,160
れがどこから来たのか、どのようにスケールするのかについてはほとんど直観が得られないと思います。

176
00:12:25,160 --> 00:12:29,340
スケーリングについて言えば、ブロック サイズが増加するにつれ

177
00:12:29,340 --> 00:12:32,200
てこのスキームの効率が向上することに気づくかもしれません。

178
00:12:32,200 --> 00:12:40,560
たとえば、256 ビットでは、冗長性のためにそのスペースの 3% の

179
00:12:40,560 --> 00:12:43,480
みが使用されており、そこからさらに改善され続けることがわかりました。

180
00:12:43,480 --> 00:12:49,040
パリティ ビットの数が 1 つずつ増加すると、ブロック サイズは 2 倍になり続けます。

181
00:12:49,040 --> 00:12:53,840
これを極端に解釈すると、たとえば 100 万ビットのブロック

182
00:12:53,840 --> 00:12:58,800
があり、文字通り 20 問のパリティ チェックを行うことにな

183
00:12:58,800 --> 00:13:00,800
り、使用するパリティ ビットは 21 ビットだけになります。

184
00:13:00,800 --> 00:13:05,760
そして、百万ビットを調べて単一のエラーを見つけることを一歩

185
00:13:05,760 --> 00:13:08,640
下がって考えると、それは本当にクレイジーに感じられます。

186
00:13:08,640 --> 00:13:12,680
もちろん、問題は、ブロックが大きくなると、1 つまたは 2 つ以上のビット エラーが

187
00:13:12,680 --> 00:13:18,360
発生する確率が高くなり、ハミング コードがそれを超えるものを処理できないことです。

188
00:13:18,360 --> 00:13:22,020
したがって、実際には、ビット フリップが多すぎる可能性が

189
00:13:22,020 --> 00:13:25,520
高すぎないように、適切なサイズを見つけることが必要です。

190
00:13:26,520 --> 00:13:30,920
また、実際には、エラーは小さなバーストで発生する傾向があり、単一のブロックを完全に破壊してしまうた

191
00:13:30,920 --> 00:13:35,680
め、エラーのバーストを多くの異なるブロックに分散させるための一般的な戦術の 1 つは、ブロックがブ

192
00:13:35,680 --> 00:13:41,720
ロックされる前に、このようにそれらのブロックをインターレースすることです。発送または保管されます。

193
00:13:45,480 --> 00:13:49,920
しかし、繰り返しになりますが、この多くは、より一般的に使用されているリードソロモン ア

194
00:13:49,920 --> 00:13:55,060
ルゴリズムなど、バースト エラーを特にうまく処理し、ブロックあたりのより多くのエラー

195
00:13:55,100 --> 00:13:59,580
に耐性を持つように調整できる、より現代的なコードによって完全に無意味になります。 。

196
00:13:59,580 --> 00:14:03,000
しかし、それはまた別の機会にお話します。

197
00:14:03,000 --> 00:14:07,660
ハミング氏は著書『The Art of Doing Science and Engineering』

198
00:14:07,660 --> 00:14:10,700
の中で、このコードの発見がどれほど曲がりくねったものであったかについて、驚くほど率直に語っています。

199
00:14:10,700 --> 00:14:15,180
彼はまず、ビットを高次元の格子の一部に組織することや、このような

200
00:14:15,180 --> 00:14:18,420
奇妙なことを含む、あらゆる種類のさまざまなスキームを試しました。

201
00:14:18,420 --> 00:14:22,520
エラーの位置を明らかにする方法でパリティ チェックを共謀させること

202
00:14:22,520 --> 00:14:26,360
ができるかもしれないという考えがハミングに思いついたのは、ハミング

203
00:14:26,360 --> 00:14:30,800
が他の一連の分析を終えて一歩下がって、「わかった、私にできる最も効

204
00:14:30,800 --> 00:14:32,860
率的なものは何か」と尋ねたときでした。おそらくこれについてですか？

205
00:14:32,860 --> 00:14:36,760
彼はまた、パリティ チェックがすでに頭の中にあったことがいかに重要であるかについても率直に

206
00:14:36,760 --> 00:14:42,040
語った。1940 年代にはパリティ チェックは現在よりもはるかに一般的ではなかったはずだ。

207
00:14:42,040 --> 00:14:46,040
この本の中で、ルイ・パスツールの名言「幸運は準備ができ

208
00:14:46,040 --> 00:14:49,640
た心に味方する」という言葉が何度も引用されています。

209
00:14:49,640 --> 00:14:55,120
賢いアイデアは、後から考えると一見シンプルに見えることが多く、過小評価されがちです。

210
00:14:55,120 --> 00:14:59,680
今のところ私の正直な願いは、ハミング符号、あるいは少なくともそのよ

211
00:14:59,680 --> 00:15:01,820
うな符号の可能性が、皆さんにとってほぼ明白に感じられることです。

212
00:15:01,820 --> 00:15:05,440
しかし、それらは決して明らかではないので、それら

213
00:15:05,440 --> 00:15:08,000
が実際には明白であると思い込む必要はありません。

214
00:15:08,000 --> 00:15:12,080
賢いアイデアが一見簡単そうに見える理由の 1 つは、私たちは最終的な

215
00:15:12,080 --> 00:15:17,360
結果しか見ていないこと、散らかったものを片づけること、間違った方向へ

216
00:15:17,360 --> 00:15:22,400
の言及がまったくないこと、問題の開始時に探索可能な可能性の空間がいか

217
00:15:22,400 --> 00:15:23,980
に広大であるかを過小評価していることです。解決プロセス、そのすべて。

218
00:15:23,980 --> 00:15:25,280
しかし、これは一般的に真実です。

219
00:15:25,280 --> 00:15:29,880
一部の特別な発明については、私たちがそれらを過小評

220
00:15:29,880 --> 00:15:31,040
価している第二の、より深い理由があると思います。

221
00:15:31,040 --> 00:15:35,040
情報をビットの観点から考えることは、1948 年までにクロード シャノンによ

222
00:15:35,040 --> 00:15:39,400
る情報理論に関する独創的な論文によってようやく完全な理論に統合されました。

223
00:15:39,400 --> 00:15:43,400
これは基本的に、ハミングがアルゴリズムを開発したときと同時進行でした。

224
00:15:43,440 --> 00:15:47,300
これは、ビット反転の確率がどれほど高くても、少な

225
00:15:47,300 --> 00:15:52,080
くとも理論上は、ある意味、効率的なエラー訂正が

226
00:15:52,080 --> 00:15:53,920
常に可能であることを示した同じ基礎論文でした。

227
00:15:53,920 --> 00:15:58,120
ちなみに、シャノンとハミングは、まったく異なることに取り組んでいたにもかかわ

228
00:15:58,120 --> 00:16:02,400
らず、ベル研究所でオフィスを共有していましたが、ここでは偶然とは思えません。

229
00:16:02,400 --> 00:16:06,960
数十年が経ち、最近では私たちの多くが断片や情報について考えることに没

230
00:16:06,960 --> 00:16:13,080
頭しているため、この考え方がいかに独特であったかを見落としがちです。

231
00:16:13,080 --> 00:16:17,920
皮肉なことに、将来の世代の考え方を最も深く形作っているアイデアは、最

232
00:16:17,920 --> 00:16:22,640
終的にはその将来の世代にとって実際よりも単純なものになるでしょう。

