1
00:00:00,000 --> 00:00:03,120
ここにいる皆さんはパート1から来ていると思います。

2
00:00:03,120 --> 00:00:06,920
私たちはハミング

3
00:00:06,920 --> 00:00:11,640
コードについて話していました。これは、ほとんどのビットが意味のあるメッセージを運ぶデータ

4
00:00:11,640 --> 00:00:15,800


5
00:00:15,800 --> 00:00:20,560
ブロックを作成する方法であり、他のいくつかのビットは一種の冗長性として機能し、ビットが反転した場合、メッセージが送信されるか、メッセージが送信されるかが決まります。ビットや冗長ビットなど、このブロック内のあらゆるものによって、受信機はエラーがあったことと、それを修正する方法を識別できるようになります。

6
00:00:20,560 --> 00:00:21,920


7
00:00:21,920 --> 00:00:25,900
そこで提示された基本的なアイデアは、複数のパリティ

8
00:00:25,900 --> 00:00:29,800
チェックを使用してエラーに至るまでバイナリ検索を行う方法でした。

9
00:00:29,800 --> 00:00:33,920
このビデオの目標は、ハミング

10
00:00:33,920 --> 00:00:35,420
コードを可能な限り実践的で再発見できるものにすることでした。

11
00:00:35,420 --> 00:00:40,040
しかし、これをソフトウェアまたはハードウェアで実際に実装することを考え始めると、その枠組みによって、これらのコードが実際にどれほどエレガントであるかが実際に理解できないかもしれません。

12
00:00:40,040 --> 00:00:44,120


13
00:00:44,120 --> 00:00:47,620
考えられるすべてのエラー位置を追跡し、各チェックでそのグループを半分に分割するアルゴリズムを作成する必要があると思うかもしれませんが、実際にはそれよりもはるかに簡単です。

14
00:00:47,620 --> 00:00:52,320


15
00:00:52,320 --> 00:00:54,160


16
00:00:54,160 --> 00:00:58,720
前回のビデオで行った 4 つのパリティ

17
00:00:58,760 --> 00:01:04,800
チェックの答えを、すべて「はい」と「いいえ」ではなく「1」と「0」として読み上げると、文字通りエラーの位置が 2 進数で表示されます。

18
00:01:04,800 --> 00:01:10,160
たとえば、2 進数の 7 は 0111 のように見え、本質的には

19
00:01:10,160 --> 00:01:12,640
4 プラス 2 プラス 1 であることを示しています。

20
00:01:12,640 --> 00:01:17,960
位置 7 がどこに位置するかに注目してください。パリティ

21
00:01:17,960 --> 00:01:22,280
グループの最初、2 番目、3 番目には影響しますが、最後には影響しません。

22
00:01:22,280 --> 00:01:26,560
したがって、これら 4

23
00:01:26,560 --> 00:01:28,000
つのチェックの結果を下から上に読むと、エラーの位置が明らかになります。

24
00:01:28,520 --> 00:01:32,240
例 7

25
00:01:32,240 --> 00:01:37,440
には特別なことは何もありません。これは一般的に機能し、ハードウェアでスキーム全体を実装するためのロジックが驚くほど単純になります。

26
00:01:37,440 --> 00:01:43,380
この魔法がなぜ起こるのかを知りたい場合は、これらの 16 個のインデックス

27
00:01:43,380 --> 00:01:48,480
ラベルを位置に取ってください。ただし、それらを 10 進数で書く代わりに、0000

28
00:01:48,480 --> 00:01:50,720
から 1111 までのバイナリですべて書いてみましょう。

29
00:01:50,720 --> 00:01:55,880
これらのバイナリ

30
00:01:56,080 --> 00:01:58,440
ラベルを箱に戻すときに、実際に送信されるデータとは区別されることを強調しておきます。

31
00:01:58,440 --> 00:02:02,200
これらは、4 つのパリティ

32
00:02:02,200 --> 00:02:04,200
グループがどこから来たのかを理解するのに役立つ概念的なラベルにすぎません。

33
00:02:04,200 --> 00:02:08,840
私たちが見ているものすべてがバイナリで記述されることの優雅さは、おそらく、私たちが見ているものすべてがバイナリで記述されることの混乱によって損なわれるでしょう。

34
00:02:08,840 --> 00:02:13,160


35
00:02:13,160 --> 00:02:15,040
ただし、それだけの価値はあります。

36
00:02:15,040 --> 00:02:20,740
これらすべてのラベルの最後のビットに注目し、その最後のビットが 1

37
00:02:20,740 --> 00:02:24,280
である位置を強調表示します。

38
00:02:24,280 --> 00:02:28,800
得られるのは 4 つのパリティ

39
00:02:28,800 --> 00:02:34,480
グループの最初のグループです。つまり、最初のチェックは、エラーがある場合、そのエラーの位置にある最後のビットは 1

40
00:02:34,480 --> 00:02:36,680
ですか? という質問であると解釈できます。

41
00:02:36,680 --> 00:02:42,600
同様に、最後から 2 番目のビットに注目し、それが 1

42
00:02:42,600 --> 00:02:47,040
であるすべての位置を強調表示すると、スキームから 2 番目のパリティ グループが得られます。

43
00:02:47,040 --> 00:02:51,960
言い換えれば、その 2 番目のチェックでは、エラーがある場合、その位置の最後から 2

44
00:02:51,960 --> 00:02:56,160
番目のビットは 1 ですか? と尋ねています。

45
00:02:56,160 --> 00:02:57,160
等々。

46
00:02:57,160 --> 00:03:03,320
3 番目のパリティ チェックは、最後から 3 番目のビットがオンになっているすべての位置をカバーし、最後のパリティ

47
00:03:03,320 --> 00:03:10,120
チェックは、最上位ビットが 1 である最後の 8 つの位置をカバーします。

48
00:03:10,120 --> 00:03:15,680
これまでに行ったことはすべて、これら 4

49
00:03:15,680 --> 00:03:18,800
つの質問に答えることと同じであり、これはバイナリでポジションを詳しく説明することと同じです。

50
00:03:19,800 --> 00:03:22,080
これにより 2 つのことが明確になると思います。

51
00:03:22,080 --> 00:03:27,140
1 つ目は、2 の累乗より大きいブロック サイズに体系的に一般化する方法です。

52
00:03:27,140 --> 00:03:33,180
64 個のスポットを表すのに 6 ビットなど、各位置を表すのにさらに多くのビットが必要な場合、それらの各ビットによって、チェックする必要があるパリティ

53
00:03:33,180 --> 00:03:38,640
グループの 1 つが得られます。

54
00:03:38,640 --> 00:03:42,060
私がマット・パーカーと一緒にやったチェス盤のパズルを見たことがある人なら、これらすべてに非常に馴染みのあるものに気づくかもしれません。

55
00:03:42,060 --> 00:03:43,400


56
00:03:43,400 --> 00:03:48,200
これは同じコア ロジックですが、別の問題を解決し、64

57
00:03:48,200 --> 00:03:49,880
マスのチェス盤に適用されます。

58
00:03:49,880 --> 00:03:54,000
これで明らかになることを望みます 2 つ目は、パリティ ビットが 2

59
00:03:54,000 --> 00:03:58,320
の累乗の位置 (たとえば 1、2、4、8) にある理由です。

60
00:03:58,320 --> 00:04:03,640
これらは、バイナリ表現で 1 つのビットだけがオンになっている位置です。

61
00:04:03,640 --> 00:04:09,000
これが意味するのは、これらのパリティ ビットはそれぞれ、4 つのパリティ

62
00:04:09,000 --> 00:04:12,640
グループのうちの 1 つのみの中に存在するということです。

63
00:04:12,640 --> 00:04:16,840
これは、より大きな例でも見ることができます。この例では、どれだけ大きくなっても、各パリティ ビットは都合よくグループの

64
00:04:16,840 --> 00:04:25,920
1 つだけに影響します。

65
00:04:25,920 --> 00:04:29,680
私たちが多くの時間を費やしてきたパリティ

66
00:04:29,680 --> 00:04:34,320
チェックが、バイナリでエラーの位置を詳しく説明するための賢い方法にすぎないことを理解すると、ハミングについての別の考え方との関連性を引き出すことができます。コードはおそらくはるかにシンプルで洗練されており、基本的には

67
00:04:34,320 --> 00:04:37,880
1

68
00:04:37,880 --> 00:04:42,160
行のコードで記述できます。

69
00:04:42,160 --> 00:04:43,880


70
00:04:43,920 --> 00:04:46,200
これは XOR 関数に基づいています。

71
00:04:46,200 --> 00:04:50,960
知らない人のために説明すると、XOR は排他的論理和の略です。

72
00:04:50,960 --> 00:04:55,440
2 つのビットの XOR

73
00:04:55,440 --> 00:05:00,200
を計算すると、それらのビットのいずれかがオンであれば 1 が返されますが、両方がオンまたはオフの場合は返されません。

74
00:05:00,200 --> 00:05:03,760
別の言い方をすると、これはこれら 2 ビットのパリティです。

75
00:05:03,760 --> 00:05:07,840
数学者として、私はこれを加算法 2 として考えることを好みます。

76
00:05:07,840 --> 00:05:12,000
また、2 つの異なるビット文字列の

77
00:05:12,040 --> 00:05:14,040
XOR についてもよく話しますが、これは基本的にコンポーネントごとに実行されます。

78
00:05:14,040 --> 00:05:16,280
それは足し算のようなものですが、決して持ち歩かない場所です。

79
00:05:16,280 --> 00:05:21,240
繰り返しますが、より数学的な傾向がある人は、これを 2 つのベクトルを加算し、mod

80
00:05:21,240 --> 00:05:23,520
2 を減らすものと考えることを好むかもしれません。

81
00:05:23,520 --> 00:05:28,720
ここで Python を開いて

82
00:05:28,720 --> 00:05:35,400
2 つの整数間にキャレット操作を適用すると、内部でこれらの数値のビット表現が行われることになります。

83
00:05:35,400 --> 00:05:40,920
あなたと私にとって重要な点は、多くの異なるビット文字列の

84
00:05:40,960 --> 00:05:45,960
XOR

85
00:05:45,960 --> 00:05:51,320
をとることは、列の場合と同様に、多数の別々のグループのパロディを一度に計算する効果的な方法であるということです。

86
00:05:51,320 --> 00:05:54,520
これにより、ハミング コード アルゴリズムからの複数のパリティ

87
00:05:54,520 --> 00:05:59,680
チェックがすべて 1 つの操作にパッケージ化されていると考える、かなり気の利いた方法が得られます。

88
00:05:59,680 --> 00:06:02,800
一見するとかなり違うように見えますが。

89
00:06:02,800 --> 00:06:08,360
具体的には、以前と同様に 16 個の位置をバイナリで書き留め、メッセージ ビットが

90
00:06:08,640 --> 00:06:14,800
1 に変わる位置を強調表示し、これらの位置を 1

91
00:06:14,800 --> 00:06:19,400
つの大きな列に集めて XOR をとります。

92
00:06:19,400 --> 00:06:23,480
おそらく、結果として最下位にある 4

93
00:06:23,480 --> 00:06:27,480
ビットが、私たちがよく知っていて愛用している 4

94
00:06:27,480 --> 00:06:32,720
つのパリティ チェックと同じであると推測できるでしょう。しかし、実際になぜなのかを少し時間を取って実際に考えてください。

95
00:06:32,720 --> 00:06:37,880
たとえば、この最後の列は、最後のビットが 1

96
00:06:38,400 --> 00:06:42,400
であるすべての位置をカウントしていますが、すでに強調表示された位置のみに制限されているため、事実上、最初のパリティ

97
00:06:42,400 --> 00:06:45,960
グループからの強調表示された位置の数をカウントしています。

98
00:06:45,960 --> 00:06:48,520
それは理にかなっていますか？

99
00:06:48,520 --> 00:06:53,600
同様に、次の列では、2 番目のパリティ グループに位置がいくつあるか、最後から

100
00:06:53,600 --> 00:06:59,640
2 番目のビットが

101
00:06:59,640 --> 00:07:00,640
1 で、強調表示されている位置などがカウントされます。

102
00:07:00,640 --> 00:07:06,640
それは、私たちがこれまでやってきたことと同じことについて、視点を少し変えただけです。

103
00:07:07,640 --> 00:07:10,000
ここから先はわかります。

104
00:07:10,000 --> 00:07:14,400
送信者は、合計が 0000

105
00:07:14,400 --> 00:07:19,640
になるように特別なパリティ ビットの一部を切り替える責任があります。

106
00:07:19,640 --> 00:07:23,600
このようにすると、結果として得られる下部の 4

107
00:07:23,600 --> 00:07:28,720
つのビットがエラーの位置を直接表す理由を考える非常に良い方法になります。

108
00:07:28,720 --> 00:07:32,680
このブロック内の一部のビットが 0 から 1 に切り替わるとします。

109
00:07:32,720 --> 00:07:37,320
これが意味するのは、そのビットの位置が合計 XOR

110
00:07:37,320 --> 00:07:42,960
に含まれることになり、合計が 0

111
00:07:42,960 --> 00:07:44,800
から、代わりにこの新しく含まれた値、つまりエラーの位置に変更されるということです。

112
00:07:44,800 --> 00:07:48,800
少しわかりにくいですが、1 を

113
00:07:48,800 --> 00:07:49,800
0 に変更するエラーが発生した場合も同じことが当てはまります。

114
00:07:49,800 --> 00:07:54,720
ご存知のとおり、ビット列を 2 回追加すると、ビット列がまったく存在しないのと同じになります。基本的に、この世界では 1 プラス

115
00:07:54,720 --> 00:07:59,000
1 は 0 に等しいためです。

116
00:07:59,000 --> 00:08:03,720
したがって、この位置のコピーを合計に追加すると、移動するのと同じ効果が得られます。

117
00:08:03,720 --> 00:08:05,400


118
00:08:05,400 --> 00:08:10,080
そして、その効果は、やはり、ここの一番下にある合計結果がエラーの位置を詳しく示しているということです。

119
00:08:10,080 --> 00:08:13,480


120
00:08:13,480 --> 00:08:17,720
これがいかに洗練されているかを説明するために、前に参照した Python コードの

121
00:08:17,720 --> 00:08:22,120
1 行を示します。これにより、受信側のロジックのほぼすべてがキャプチャされます。

122
00:08:22,120 --> 00:08:27,160
まず、データ ブロックをシミュレートするために 16 個の

123
00:08:27,160 --> 00:08:31,160
1 と 0 のランダムな配列を作成し、それに

124
00:08:31,160 --> 00:08:36,160
bits という名前を付けますが、もちろん実際には、これは送信者から受信するものになります。ランダムであるため、11 個のデータ ビットと

125
00:08:36,160 --> 00:08:38,600
5 個のパリティ ビットを運ぶことになります。

126
00:08:38,600 --> 00:08:43,160
enumerateBits 関数を呼び出すと、これらの各ビットが対応するインデックス (この場合は 0

127
00:08:43,160 --> 00:08:48,240
から 15 まで) とペアになります。

128
00:08:48,240 --> 00:08:53,200
したがって、これらすべてのペア (i に似たペア) をループするリストを作成し、i

129
00:08:53,200 --> 00:08:59,160
の値だけ、インデックスだけを取り出すとします。それほど面白いことではありません。インデックス 0 から

130
00:08:59,160 --> 00:09:01,920
15 が返されるだけです。 。

131
00:09:01,920 --> 00:09:07,520
しかし、ビットの場合のみ、つまりそのビットが 0 ではなく

132
00:09:07,520 --> 00:09:13,400
1 である場合にのみこれを実行するという条件を追加すると、対応するビットがオンになっている位置のみが抽出されます。

133
00:09:13,400 --> 00:09:20,320
この場合、それらの位置は 0、4、6、9 などのように見えます。

134
00:09:20,720 --> 00:09:24,640
私たちが望んでいるのは、これらの位置、つまりオンになっているビットの位置をすべて収集し、それらを XOR

135
00:09:24,640 --> 00:09:29,960
演算することです。

136
00:09:29,960 --> 00:09:33,960
これを Python で行うには、まずいくつかの便利な関数をインポートします。

137
00:09:33,960 --> 00:09:39,140
そうすることで、このリストに対してreduce()を呼び出し、XOR関数を使用してリストを減らすことができます。

138
00:09:39,140 --> 00:09:44,840
これは基本的にリスト全体を処理し、途中で XOR を取得します。

139
00:09:44,840 --> 00:09:48,760
必要に応じて、XOR

140
00:09:48,800 --> 00:09:52,200
関数をどこからもインポートせずに明示的に書き出すことができます。

141
00:09:52,200 --> 00:09:56,880
したがって、現時点では、16 ビットのランダム ブロックでこれを実行すると、バイナリ表現 1001

142
00:09:56,880 --> 00:10:02,080
を持つ 9 が返されるようです。

143
00:10:02,080 --> 00:10:05,960
ここではそれを行いませんが、送信者がそのバイナリ表現を使用して必要に応じて 4

144
00:10:05,960 --> 00:10:11,560
つのパリティ ビットを設定し、最終的にこのブロックをビットの完全なリストに対してこのコード行を実行すると返される状態にする関数を作成することもできます。

145
00:10:11,560 --> 00:10:16,200
0。

146
00:10:17,200 --> 00:10:20,200
これは、十分に準備されたブロックであると考えられます。

147
00:10:20,200 --> 00:10:24,640
素晴らしいのは、このリストのビットのいずれかを切り替えて、ノイズによるランダムなエラーをシミュレートし、同じコード行を実行すると、そのエラーが出力されることです。

148
00:10:24,640 --> 00:10:30,600


149
00:10:30,600 --> 00:10:31,920
素敵じゃないですか？

150
00:10:31,920 --> 00:10:37,200
このブロックを突然取得し、その上でこの 1 行を実行すると、エラーの位置が自動的に出力され、エラーが存在しない場合は

151
00:10:37,200 --> 00:10:42,920
0 が出力されます。

152
00:10:42,920 --> 00:10:45,520
サイズ 16 については特別なことは何もありません。

153
00:10:45,520 --> 00:10:52,280
たとえば 256 ビットのリストがある場合、同じコード行が機能します。

154
00:10:52,280 --> 00:10:56,280
言うまでもなく、2 ビット エラーを検出するためのメタ

155
00:10:56,280 --> 00:11:01,440
パリティ チェックの実行など、ここで記述するコードはさらにありますが、考え方としては、このスキームのコア ロジックのほぼすべてが単一の

156
00:11:01,440 --> 00:11:05,080
XOR リダクションに帰結するということです。

157
00:11:05,080 --> 00:11:10,600
さて、バイナリ、XOR、およびソフトウェア全般に慣れているかどうかに応じて、この視点は少しわかりにくいと感じるか、またははるかにエレガントでシンプルなので、なぜ最初からこの視点を始めなかったのかと不思議に思うかもしれません。

158
00:11:10,600 --> 00:11:15,880
-行く。

159
00:11:15,880 --> 00:11:19,320


160
00:11:19,320 --> 00:11:22,880
大まかに言うと、複数のパリティ チェックの観点は、ハミング

161
00:11:22,880 --> 00:11:27,560
コードをハードウェアで直接実装する場合に考えやすく、XOR

162
00:11:27,560 --> 00:11:31,380
の観点は、ソフトウェアで実行する場合に、より高いレベルから考えるのが最も簡単です。

163
00:11:31,380 --> 00:11:35,640
最初の方法は実際に手作業で行うのが最も簡単で、これらすべての根底にある核となる直感を植え付けるのに効果的だと思います。つまり、単一のエラーを見つけるのに必要な情報はブロックのサイズのログに関連しているということです。 、言い換えれば、ブロック

164
00:11:35,640 --> 00:11:40,720
サイズが 2

165
00:11:40,720 --> 00:11:46,840
倍になると、一度に 1

166
00:11:46,840 --> 00:11:51,020
ビットずつ大きくなります。

167
00:11:51,020 --> 00:11:55,440
ここで重要な事実は、その情報が必要な冗長性の量に直接対応しているということです。

168
00:11:55,440 --> 00:11:56,440


169
00:11:56,440 --> 00:12:00,320
これは、ほとんどの人が最初にメッセージをエラーに強いものにしようと考えたとき、通常はメッセージ全体をコピーすることが最初に頭に浮かぶ本能的な反応に反するものです。

170
00:12:00,320 --> 00:12:05,280


171
00:12:05,280 --> 00:12:07,520


172
00:12:07,520 --> 00:12:11,120
そして、ところで、ハミング コードが表示されることがあるのをよく見かけるまったく別の方法があります。これは、メッセージに

173
00:12:11,120 --> 00:12:14,800
1 つの大きな行列を乗算するものです。

174
00:12:14,800 --> 00:12:18,580
これは、線形コードのより広範なファミリーに関連付けられているため、ある意味素晴らしいですが、それがどこから来たのか、どのようにスケールするのかについてはほとんど直観が得られないと思います。

175
00:12:18,580 --> 00:12:25,160


176
00:12:25,160 --> 00:12:29,340
スケーリングについて言えば、ブロック

177
00:12:29,340 --> 00:12:32,200
サイズが増加するにつれてこのスキームの効率が向上することに気づくかもしれません。

178
00:12:32,200 --> 00:12:40,560
たとえば、256 ビットでは、冗長性のためにそのスペースの

179
00:12:40,560 --> 00:12:43,480
3% のみが使用されており、そこからさらに改善され続けることがわかりました。

180
00:12:43,480 --> 00:12:49,040
パリティ ビットの数が 1 つずつ増加すると、ブロック サイズは 2 倍になり続けます。

181
00:12:49,040 --> 00:12:53,840
これを極端に解釈すると、たとえば 100 万ビットのブロックがあり、文字通り

182
00:12:53,840 --> 00:12:58,800
20 問のパリティ チェックを行うことになり、使用するパリティ

183
00:12:58,800 --> 00:13:00,800
ビットは 21 ビットだけになります。

184
00:13:00,800 --> 00:13:05,760
そして、百万ビットを調べて単一のエラーを見つけることを一歩下がって考えると、それは本当にクレイジーに感じられます。

185
00:13:05,760 --> 00:13:08,640


186
00:13:08,640 --> 00:13:12,680
もちろん、問題は、ブロックが大きくなると、1 つまたは 2

187
00:13:12,680 --> 00:13:18,360
つ以上のビット エラーが発生する確率が高くなり、ハミング コードがそれを超えるものを処理できないことです。

188
00:13:18,360 --> 00:13:22,020
したがって、実際には、ビット

189
00:13:22,020 --> 00:13:25,520
フリップが多すぎる可能性が高すぎないように、適切なサイズを見つけることが必要です。

190
00:13:26,520 --> 00:13:30,920
また、実際には、エラーは小さなバーストで発生する傾向があり、単一のブロックを完全に破壊してしまうため、エラーのバーストを多くの異なるブロックに分散させるための一般的な戦術の

191
00:13:30,920 --> 00:13:35,680
1

192
00:13:35,680 --> 00:13:41,720
つは、ブロックがブロックされる前に、このようにそれらのブロックをインターレースすることです。発送または保管されます。

193
00:13:45,480 --> 00:13:49,920
しかし、繰り返しになりますが、この多くは、より一般的に使用されているリードソロモン アルゴリズムなど、バースト

194
00:13:49,920 --> 00:13:55,060
エラーを特にうまく処理し、ブロックあたりのより多くのエラーに耐性を持つように調整できる、より現代的なコードによって完全に無意味になります。

195
00:13:55,100 --> 00:13:59,580
。

196
00:13:59,580 --> 00:14:03,000
しかし、それはまた別の機会にお話します。

197
00:14:03,000 --> 00:14:07,660
ハミング氏は著書『The Art of Doing

198
00:14:07,660 --> 00:14:10,700
Science and Engineering』の中で、このコードの発見がどれほど曲がりくねったものであったかについて、驚くほど率直に語っています。

199
00:14:10,700 --> 00:14:15,180
彼はまず、ビットを高次元の格子の一部に組織することや、このような奇妙なことを含む、あらゆる種類のさまざまなスキームを試しました。

200
00:14:15,180 --> 00:14:18,420


201
00:14:18,420 --> 00:14:22,520
エラーの位置を明らかにする方法でパリティ

202
00:14:22,520 --> 00:14:26,360


203
00:14:26,360 --> 00:14:30,800
チェックを共謀させることができるかもしれないという考えがハミングに思いついたのは、ハミングが他の一連の分析を終えて一歩下がって、「わかった、私にできる最も効率的なものは何か」と尋ねたときでした。おそらくこれについてですか？

204
00:14:30,800 --> 00:14:32,860


205
00:14:32,860 --> 00:14:36,760
彼はまた、パリティ チェックがすでに頭の中にあったことがいかに重要であるかについても率直に語った。1940

206
00:14:36,760 --> 00:14:42,040
年代にはパリティ チェックは現在よりもはるかに一般的ではなかったはずだ。

207
00:14:42,040 --> 00:14:46,040
この本の中で、ルイ・パスツールの名言「幸運は準備ができた心に味方する」という言葉が何度も引用されています。

208
00:14:46,040 --> 00:14:49,640


209
00:14:49,640 --> 00:14:55,120
賢いアイデアは、後から考えると一見シンプルに見えることが多く、過小評価されがちです。

210
00:14:55,120 --> 00:14:59,680
今のところ私の正直な願いは、ハミング符号、あるいは少なくともそのような符号の可能性が、皆さんにとってほぼ明白に感じられることです。

211
00:14:59,680 --> 00:15:01,820


212
00:15:01,820 --> 00:15:05,440
しかし、それらは決して明らかではないので、それらが実際には明白であると思い込む必要はありません。

213
00:15:05,440 --> 00:15:08,000


214
00:15:08,000 --> 00:15:12,080
賢いアイデアが一見簡単そうに見える理由の

215
00:15:12,080 --> 00:15:17,360
1

216
00:15:17,360 --> 00:15:22,400
つは、私たちは最終的な結果しか見ていないこと、散らかったものを片づけること、間違った方向への言及がまったくないこと、問題の開始時に探索可能な可能性の空間がいかに広大であるかを過小評価していることです。解決プロセス、そのすべて。

217
00:15:22,400 --> 00:15:23,980


218
00:15:23,980 --> 00:15:25,280
しかし、これは一般的に真実です。

219
00:15:25,280 --> 00:15:29,880
一部の特別な発明については、私たちがそれらを過小評価している第二の、より深い理由があると思います。

220
00:15:29,880 --> 00:15:31,040


221
00:15:31,040 --> 00:15:35,040
情報をビットの観点から考えることは、1948 年までにクロード

222
00:15:35,040 --> 00:15:39,400
シャノンによる情報理論に関する独創的な論文によってようやく完全な理論に統合されました。

223
00:15:39,400 --> 00:15:43,400
これは基本的に、ハミングがアルゴリズムを開発したときと同時進行でした。

224
00:15:43,440 --> 00:15:47,300
これは、ビット反転の確率がどれほど高くても、少なくとも理論上は、ある意味、効率的なエラー訂正が常に可能であることを示した同じ基礎論文でした。

225
00:15:47,300 --> 00:15:52,080


226
00:15:52,080 --> 00:15:53,920


227
00:15:53,920 --> 00:15:58,120
ちなみに、シャノンとハミングは、まったく異なることに取り組んでいたにもかかわらず、ベル研究所でオフィスを共有していましたが、ここでは偶然とは思えません。

228
00:15:58,120 --> 00:16:02,400


229
00:16:02,400 --> 00:16:06,960
数十年が経ち、最近では私たちの多くが断片や情報について考えることに没頭しているため、この考え方がいかに独特であったかを見落としがちです。

230
00:16:06,960 --> 00:16:13,080


231
00:16:13,080 --> 00:16:17,920
皮肉なことに、将来の世代の考え方を最も深く形作っているアイデアは、最終的にはその将来の世代にとって実際よりも単純なものになるでしょう。

232
00:16:17,920 --> 00:16:22,640


