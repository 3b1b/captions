1
00:00:00,000 --> 00:00:03,120
Je suppose que tout le monde ici vient de la partie 1.

2
00:00:03,120 --> 00:00:06,920
Nous parlions des codes de Hamming, une façon de créer un bloc de données dont

3
00:00:06,920 --> 00:00:11,640
la plupart des bits portent un message significatif, tandis que quelques autres agissent comme

4
00:00:11,640 --> 00:00:15,800
une sorte de redondance, de telle sorte que si un bit est inversé, soit

5
00:00:15,800 --> 00:00:20,560
un message bit ou un bit de redondance, n'importe quoi dans ce bloc, un

6
00:00:20,560 --> 00:00:21,920
récepteur sera capable d'identifier qu'il y a eu une erreur et comment la corriger.

7
00:00:21,920 --> 00:00:25,900
L'idée de base présentée ici était de savoir comment utiliser plusieurs

8
00:00:25,900 --> 00:00:29,800
contrôles de parité pour effectuer une recherche binaire jusqu'à l'erreur.

9
00:00:29,800 --> 00:00:33,920
Dans cette vidéo, l'objectif était de rendre les codes

10
00:00:33,920 --> 00:00:35,420
de Hamming aussi pratiques et redécouvrables que possible.

11
00:00:35,420 --> 00:00:40,040
Mais lorsque vous commencez à réfléchir à la mise en œuvre réelle de cela, que ce soit

12
00:00:40,040 --> 00:00:44,120
au niveau logiciel ou matériel, ce cadrage peut en fait sous-estimer l'élégance réelle de ces codes.

13
00:00:44,120 --> 00:00:47,620
Vous pensez peut-être que vous devez écrire un algorithme qui garde une trace

14
00:00:47,620 --> 00:00:52,320
de tous les emplacements d'erreur possibles et coupe ce groupe de moitié

15
00:00:52,320 --> 00:00:54,160
à chaque vérification, mais c'est en réalité bien plus simple que cela.

16
00:00:54,160 --> 00:00:58,720
Si vous lisez les réponses aux quatre contrôles de parité que nous avons effectués dans la dernière vidéo, toutes sous forme

17
00:00:58,760 --> 00:01:04,800
de 1 et de 0 au lieu de oui et de non, cela indique littéralement la position de l'erreur en binaire.

18
00:01:04,800 --> 00:01:10,160
Par exemple, le nombre 7 en binaire ressemble à 0111, ce

19
00:01:10,160 --> 00:01:12,640
qui signifie essentiellement que c'est 4 plus 2 plus 1.

20
00:01:12,640 --> 00:01:17,960
Et remarquez où se situe la position 7, elle affecte le premier de nos

21
00:01:17,960 --> 00:01:22,280
groupes paritaires, ainsi que le deuxième et le troisième, mais pas le dernier.

22
00:01:22,280 --> 00:01:26,560
Ainsi, la lecture des résultats de ces quatre contrôles de

23
00:01:26,560 --> 00:01:28,000
bas en haut précise bien la position de l’erreur.

24
00:01:28,520 --> 00:01:32,240
Il n'y a rien de spécial dans l'exemple 7, cela fonctionne en général, et

25
00:01:32,240 --> 00:01:37,440
cela rend la logique d'implémentation de l'ensemble du schéma matériellement d'une simplicité choquante.

26
00:01:37,440 --> 00:01:43,380
Maintenant, si vous voulez voir pourquoi cette magie se produit, prenez ces

27
00:01:43,380 --> 00:01:48,480
16 étiquettes d'index pour nos positions, mais au lieu de les écrire

28
00:01:48,480 --> 00:01:50,720
en base 10, écrivons-les toutes en binaire, allant de 0000 à 1111.

29
00:01:50,720 --> 00:01:55,880
Alors que nous remettons ces étiquettes binaires dans leurs boîtes,

30
00:01:56,080 --> 00:01:58,440
permettez-moi de souligner qu'elles sont distinctes des données réellement envoyées.

31
00:01:58,440 --> 00:02:02,200
Ce n'est rien de plus qu'une étiquette conceptuelle pour nous aider,

32
00:02:02,200 --> 00:02:04,200
vous et moi, à comprendre d'où viennent les quatre groupes paritaires.

33
00:02:04,200 --> 00:02:08,840
L'élégance d'avoir tout ce que nous regardons soit décrit en binaire est peut-être sapée

34
00:02:08,840 --> 00:02:13,160
par la confusion d'avoir tout ce que nous regardons étant décrit en binaire.

35
00:02:13,160 --> 00:02:15,040
Mais ça vaut le coup.

36
00:02:15,040 --> 00:02:20,740
Concentrez votre attention uniquement sur le dernier bit de toutes ces étiquettes, puis

37
00:02:20,740 --> 00:02:24,280
mettez en surbrillance les positions où ce dernier bit est un 1.

38
00:02:24,280 --> 00:02:28,800
Ce que nous obtenons est le premier de nos quatre groupes de parité, ce

39
00:02:28,800 --> 00:02:34,480
qui signifie que vous pouvez interpréter cette première vérification comme demandant : hé, s’il y a

40
00:02:34,480 --> 00:02:36,680
une erreur, le dernier bit à la position de cette erreur est-il un 1 ?

41
00:02:36,680 --> 00:02:42,600
De même, si vous vous concentrez sur l'avant-dernier bit et mettez en surbrillance toutes les positions

42
00:02:42,600 --> 00:02:47,040
où il s'agit d'un 1, vous obtenez le deuxième groupe de parité de notre schéma.

43
00:02:47,040 --> 00:02:51,960
En d’autres termes, cette deuxième vérification demande : hé, encore une fois, s’il

44
00:02:51,960 --> 00:02:56,160
y a une erreur, l’avant-dernier bit de cette position est-il un 1 ?

45
00:02:56,160 --> 00:02:57,160
Et ainsi de suite.

46
00:02:57,160 --> 00:03:03,320
Le troisième contrôle de parité couvre chaque position dont l'avant-dernier bit est activé, et le dernier couvre

47
00:03:03,320 --> 00:03:10,120
les huit dernières positions, celles dont le bit de poids le plus élevé est un 1.

48
00:03:10,120 --> 00:03:15,680
Tout ce que nous avons fait plus tôt revient à répondre à

49
00:03:15,680 --> 00:03:18,800
ces quatre questions, ce qui revient à épeler une position en binaire.

50
00:03:19,800 --> 00:03:22,080
J'espère que cela rend deux choses plus claires.

51
00:03:22,080 --> 00:03:27,140
La première est de savoir comment généraliser systématiquement à des tailles de blocs qui sont des puissances de deux plus grandes.

52
00:03:27,140 --> 00:03:33,180
S'il faut plus de bits pour décrire chaque position, comme six bits pour décrire 64 points,

53
00:03:33,180 --> 00:03:38,640
alors chacun de ces bits vous donne l'un des groupes de parité que nous devons vérifier.

54
00:03:38,640 --> 00:03:42,060
Ceux d’entre vous qui ont regardé le puzzle d’échiquier que j’ai

55
00:03:42,060 --> 00:03:43,400
réalisé avec Matt Parker trouveront peut-être tout cela extrêmement familier.

56
00:03:43,400 --> 00:03:48,200
C'est la même logique de base, mais résolvant un problème

57
00:03:48,200 --> 00:03:49,880
différent, et appliquée à un échiquier de 64 cases.

58
00:03:49,880 --> 00:03:54,000
La deuxième chose que j'espère que cela clarifie est la raison pour laquelle nos bits de parité se

59
00:03:54,000 --> 00:03:58,320
trouvent dans des positions qui sont des puissances de deux, par exemple 1, 2, 4 et 8.

60
00:03:58,320 --> 00:04:03,640
Ce sont les positions dont la représentation binaire n'a qu'un seul bit activé.

61
00:04:03,640 --> 00:04:09,000
Cela signifie que chacun de ces bits de parité se trouve

62
00:04:09,000 --> 00:04:12,640
dans un et un seul des quatre groupes de parité.

63
00:04:12,640 --> 00:04:16,840
Vous pouvez également le constater dans des exemples plus grands, où quelle que

64
00:04:16,840 --> 00:04:25,920
soit votre taille, chaque bit de parité ne touche qu'un seul des groupes.

65
00:04:25,920 --> 00:04:29,680
Une fois que vous comprenez que ces contrôles de parité sur lesquels nous avons consacré

66
00:04:29,680 --> 00:04:34,320
une grande partie de notre temps ne sont rien de plus qu'une manière intelligente d'épeler

67
00:04:34,320 --> 00:04:37,880
la position d'une erreur en binaire, nous pouvons alors établir un lien avec une manière

68
00:04:37,880 --> 00:04:42,160
différente de penser au hamming. des codes, qui sont sans doute beaucoup plus simples et

69
00:04:42,160 --> 00:04:43,880
plus élégants, et qui peuvent essentiellement être écrits avec une seule ligne de code.

70
00:04:43,920 --> 00:04:46,200
Il est basé sur la fonction XOR.

71
00:04:46,200 --> 00:04:50,960
XOR, pour ceux d'entre vous qui ne le savent pas, signifie exclusif ou.

72
00:04:50,960 --> 00:04:55,440
Lorsque vous effectuez le XOR de deux bits, il renvoie un 1 si l'un

73
00:04:55,440 --> 00:05:00,200
de ces bits est activé, mais pas si les deux sont activés ou désactivés.

74
00:05:00,200 --> 00:05:03,760
Exprimé différemment, c'est la parité de ces deux bits.

75
00:05:03,760 --> 00:05:07,840
En tant que mathématicien, je préfère y penser comme un mod d'addition 2.

76
00:05:07,840 --> 00:05:12,000
Nous parlons aussi couramment du XOR de deux chaînes de

77
00:05:12,040 --> 00:05:14,040
bits différentes, qui effectue essentiellement cela composant par composant.

78
00:05:14,040 --> 00:05:16,280
C'est comme une addition, mais où l'on ne porte jamais.

79
00:05:16,280 --> 00:05:21,240
Encore une fois, les plus enclins aux mathématiques préféreront peut-être considérer cela

80
00:05:21,240 --> 00:05:23,520
comme l'ajout de deux vecteurs et la réduction du mod 2.

81
00:05:23,520 --> 00:05:28,720
Si vous ouvrez Python dès maintenant et appliquez l'opération caret entre deux entiers, c'est

82
00:05:28,720 --> 00:05:35,400
ce qu'il fait, mais aux représentations binaires de ces nombres sous le capot.

83
00:05:35,400 --> 00:05:40,920
Le point clé pour vous et moi est que prendre le XOR de nombreuses

84
00:05:40,960 --> 00:05:45,960
chaînes de bits différentes est effectivement un moyen de calculer les parodies d'un groupe

85
00:05:45,960 --> 00:05:51,320
de groupes séparés, comme c'est le cas avec les colonnes, d'un seul coup.

86
00:05:51,320 --> 00:05:54,520
Cela nous donne une façon plutôt élégante de considérer les multiples contrôles de parité de

87
00:05:54,520 --> 00:05:59,680
notre algorithme de code de Hamming comme étant tous regroupés en une seule opération.

88
00:05:59,680 --> 00:06:02,800
Même si à première vue, cela semble très différent.

89
00:06:02,800 --> 00:06:08,360
Notez spécifiquement les 16 positions en binaire, comme nous l'avions fait auparavant, et mettez

90
00:06:08,640 --> 00:06:14,800
maintenant en surbrillance les positions où le bit de message est activé sur

91
00:06:14,800 --> 00:06:19,400
1, puis rassemblez ces positions dans une grande colonne et prenez le XOR.

92
00:06:19,400 --> 00:06:23,480
Vous pouvez probablement deviner que les 4 bits situés en bas sont

93
00:06:23,480 --> 00:06:27,480
les mêmes que les 4 contrôles de parité que nous connaissons

94
00:06:27,480 --> 00:06:32,720
et aimons, mais prenez un moment pour réfléchir à pourquoi exactement.

95
00:06:32,720 --> 00:06:37,880
Cette dernière colonne, par exemple, compte toutes les positions dont le dernier bit est

96
00:06:38,400 --> 00:06:42,400
un 1, mais nous sommes déjà limités uniquement aux positions en surbrillance, elle compte

97
00:06:42,400 --> 00:06:45,960
donc effectivement le nombre de positions en surbrillance provenant du premier groupe de parité.

98
00:06:45,960 --> 00:06:48,520
Cela a-t-il du sens?

99
00:06:48,520 --> 00:06:53,600
De même, la colonne suivante compte le nombre de positions dans le

100
00:06:53,600 --> 00:06:59,640
deuxième groupe de parité, les positions dont l'avant-dernier bit est un 1

101
00:06:59,640 --> 00:07:00,640
et qui sont également mises en surbrillance, et ainsi de suite.

102
00:07:00,640 --> 00:07:06,640
Il s'agit en réalité d'un petit changement de perspective par rapport à la même chose que nous faisons.

103
00:07:07,640 --> 00:07:10,000
Et donc vous savez où cela va à partir de maintenant.

104
00:07:10,000 --> 00:07:14,400
L'expéditeur est responsable d'activer certains bits de parité spéciaux

105
00:07:14,400 --> 00:07:19,640
pour s'assurer que la somme est égale à 0000.

106
00:07:19,640 --> 00:07:23,600
Maintenant, une fois que nous avons cela, cela nous donne une très bonne façon de réfléchir à

107
00:07:23,600 --> 00:07:28,720
la raison pour laquelle ces quatre bits résultants en bas indiquent directement la position d'une erreur.

108
00:07:28,720 --> 00:07:32,680
Disons qu'un élément de ce bloc passe de 0 à 1.

109
00:07:32,720 --> 00:07:37,320
Cela signifie que la position de ce bit va maintenant être

110
00:07:37,320 --> 00:07:42,960
incluse dans le XOR total, ce qui fait passer la somme

111
00:07:42,960 --> 00:07:44,800
de 0 à cette valeur nouvellement incluse, la position de l'erreur.

112
00:07:44,800 --> 00:07:48,800
De manière un peu moins évidente, il en va de même s'il

113
00:07:48,800 --> 00:07:49,800
y a une erreur qui change un 1 en un 0.

114
00:07:49,800 --> 00:07:54,720
Vous voyez, si vous ajoutez deux fois une petite chaîne, cela revient à ne pas l'avoir

115
00:07:54,720 --> 00:07:59,000
du tout, essentiellement parce que dans ce monde, 1 plus 1 est égal à 0.

116
00:07:59,000 --> 00:08:03,720
Ainsi, ajouter une copie de cette position à la somme

117
00:08:03,720 --> 00:08:05,400
totale a le même effet que de la déplacer.

118
00:08:05,400 --> 00:08:10,080
Et cet effet, encore une fois, est que le résultat

119
00:08:10,080 --> 00:08:13,480
total en bas indique ici la position de l’erreur.

120
00:08:13,480 --> 00:08:17,720
Pour illustrer à quel point cela est élégant, permettez-moi de montrer cette ligne de code

121
00:08:17,720 --> 00:08:22,120
Python que j'ai référencée précédemment, qui capturera presque toute la logique du côté du récepteur.

122
00:08:22,120 --> 00:08:27,160
Nous allons commencer par créer un tableau aléatoire de 16 1 et 0 pour simuler

123
00:08:27,160 --> 00:08:31,160
le bloc de données, et je lui donnerai le nom des bits, mais bien sûr,

124
00:08:31,160 --> 00:08:36,160
en pratique, ce serait quelque chose que nous recevons d'un expéditeur, et au lieu de

125
00:08:36,160 --> 00:08:38,600
étant aléatoire, il transporterait 11 bits de données ainsi que 5 bits de parité.

126
00:08:38,600 --> 00:08:43,160
Si j'appelle la fonction enumerateBits, elle associe chacun de ces bits à

127
00:08:43,160 --> 00:08:48,240
un index correspondant, dans ce cas allant de 0 à 15.

128
00:08:48,240 --> 00:08:53,200
Donc, si nous créons ensuite une liste qui boucle sur toutes ces paires, des paires qui

129
00:08:53,200 --> 00:08:59,160
ressemblent à i, et que nous extrayons ensuite uniquement la valeur i, juste l'index, eh bien,

130
00:08:59,160 --> 00:09:01,920
ce n'est pas si excitant, nous récupérons simplement ces indices de 0 à 15. .

131
00:09:01,920 --> 00:09:07,520
Mais si nous ajoutons la condition de ne faire cela que si bit, c'est-à-dire si ce bit est

132
00:09:07,520 --> 00:09:13,400
un 1 et non un 0, alors il extrait uniquement les positions où le bit correspondant est activé.

133
00:09:13,400 --> 00:09:20,320
Dans ce cas, il semble que ces positions soient 0, 4, 6, 9, etc.

134
00:09:20,720 --> 00:09:24,640
Ce que nous voulons, c'est rassembler toutes ces positions, les

135
00:09:24,640 --> 00:09:29,960
positions des bits qui sont activés, puis les XOR ensemble.

136
00:09:29,960 --> 00:09:33,960
Pour ce faire en Python, permettez-moi d'abord d'importer quelques fonctions utiles.

137
00:09:33,960 --> 00:09:39,140
De cette façon, nous pouvons appeler réduire() sur cette liste et utiliser la fonction XOR pour la réduire.

138
00:09:39,140 --> 00:09:44,840
Cela se fraye un chemin à travers la liste, prenant des XORs en cours de route.

139
00:09:44,840 --> 00:09:48,760
Si vous préférez, vous pouvez écrire explicitement cette fonction

140
00:09:48,800 --> 00:09:52,200
XOR sans avoir à l'importer de n'importe où.

141
00:09:52,200 --> 00:09:56,880
Donc pour le moment, il semble que si nous faisons cela sur notre bloc

142
00:09:56,880 --> 00:10:02,080
aléatoire de 16 bits, cela renvoie 9, qui a la représentation binaire 1001.

143
00:10:02,080 --> 00:10:05,960
Nous ne le ferons pas ici, mais vous pouvez écrire une fonction dans laquelle l'expéditeur utilise cette représentation

144
00:10:05,960 --> 00:10:11,560
binaire pour définir les quatre bits de parité selon les besoins, amenant finalement ce bloc à un

145
00:10:11,560 --> 00:10:16,200
état où l'exécution de cette ligne de code sur la liste complète des bits renvoie un 0.

146
00:10:17,200 --> 00:10:20,200
Cela serait considéré comme un bloc bien préparé.

147
00:10:20,200 --> 00:10:24,640
Ce qui est cool, c'est que si nous basculons l'un des bits de cette liste, simulant une erreur

148
00:10:24,640 --> 00:10:30,600
aléatoire due au bruit, alors si vous exécutez cette même ligne de code, cette erreur est affichée.

149
00:10:30,600 --> 00:10:31,920
N'est-ce pas sympa ?

150
00:10:31,920 --> 00:10:37,200
Vous pouvez obtenir ce bloc à l'improviste, exécuter cette seule ligne dessus, et il

151
00:10:37,200 --> 00:10:42,920
crachera automatiquement la position d'une erreur, ou un 0 s'il n'y en avait pas.

152
00:10:42,920 --> 00:10:45,520
Et il n'y a rien de spécial concernant la taille 16 ici.

153
00:10:45,520 --> 00:10:52,280
La même ligne de code fonctionnerait si vous aviez une liste de, disons, 256 bits.

154
00:10:52,280 --> 00:10:56,280
Inutile de dire qu'il y a plus de code à écrire ici, comme effectuer la

155
00:10:56,280 --> 00:11:01,440
vérification de méta-parité pour détecter les erreurs de 2 bits, mais l'idée est que presque

156
00:11:01,440 --> 00:11:05,080
toute la logique de base de notre schéma se résume à une seule réduction XOR.

157
00:11:05,080 --> 00:11:10,600
Maintenant, selon votre aisance avec les binaires, les XOR et les logiciels en général, vous

158
00:11:10,600 --> 00:11:15,880
pouvez soit trouver cette perspective un peu déroutante, soit tellement plus élégante et simple

159
00:11:15,880 --> 00:11:19,320
que vous vous demandez pourquoi nous ne l'avons pas commencé dès le début. -aller.

160
00:11:19,320 --> 00:11:22,880
En gros, la perspective du contrôle de parité multiple est plus facile à penser lors de

161
00:11:22,880 --> 00:11:27,560
l'implémentation très directe des codes de Hamming dans le matériel, et la perspective XOR est

162
00:11:27,560 --> 00:11:31,380
la plus facile à penser lorsqu'on l'effectue dans le logiciel, à partir d'un niveau supérieur.

163
00:11:31,380 --> 00:11:35,640
Le premier est le plus simple à réaliser à la main, et je pense qu'il fait un

164
00:11:35,640 --> 00:11:40,720
meilleur travail en inculquant l'intuition fondamentale qui sous-tend tout cela, à savoir que les informations requises

165
00:11:40,720 --> 00:11:46,840
pour localiser une seule erreur sont liées au journal de la taille du bloc. , ou

166
00:11:46,840 --> 00:11:51,020
en d’autres termes, il augmente petit à petit à mesure que la taille du bloc double.

167
00:11:51,020 --> 00:11:55,440
Le fait pertinent ici est que ces informations correspondent

168
00:11:55,440 --> 00:11:56,440
directement au niveau de redondance dont nous avons besoin.

169
00:11:56,440 --> 00:12:00,320
C'est vraiment ce qui va à l'encontre de la réaction instinctive de la plupart des

170
00:12:00,320 --> 00:12:05,280
gens lorsqu'ils pensent pour la première fois à rendre un message résistant aux erreurs, alors

171
00:12:05,280 --> 00:12:07,520
que copier l'intégralité du message est généralement le premier instinct qui leur vient à l'esprit.

172
00:12:07,520 --> 00:12:11,120
Et puis, en passant, il y a cette toute autre façon de voir parfois

173
00:12:11,120 --> 00:12:14,800
les codes de Hamming présentés, où vous multipliez le message par une grande matrice.

174
00:12:14,800 --> 00:12:18,580
C'est plutôt sympa car cela le relie à la famille plus large des codes linéaires, mais

175
00:12:18,580 --> 00:12:25,160
je pense que cela ne donne presque aucune intuition sur son origine ou son évolution.

176
00:12:25,160 --> 00:12:29,340
Et en parlant de mise à l'échelle, vous remarquerez peut-être que l'efficacité de ce

177
00:12:29,340 --> 00:12:32,200
système ne fait que s'améliorer à mesure que nous augmentons la taille des blocs.

178
00:12:32,200 --> 00:12:40,560
Par exemple, nous avons vu qu'avec 256 bits, vous n'utilisez que 3 % de cet

179
00:12:40,560 --> 00:12:43,480
espace pour la redondance, et la situation ne cesse de s'améliorer à partir de là.

180
00:12:43,480 --> 00:12:49,040
À mesure que le nombre de bits de parité augmente un par un, la taille du bloc continue de doubler.

181
00:12:49,040 --> 00:12:53,840
Et si vous poussez cela à l'extrême, vous pourriez avoir un bloc avec,

182
00:12:53,840 --> 00:12:58,800
disons, un million de bits, dans lequel vous joueriez littéralement 20 questions avec

183
00:12:58,800 --> 00:13:00,800
vos contrôles de parité, et il n'utiliserait que 21 bits de parité.

184
00:13:00,800 --> 00:13:05,760
Et si vous prenez du recul et réfléchissez à examiner un million

185
00:13:05,760 --> 00:13:08,640
de bits et à localiser une seule erreur, cela semble vraiment fou.

186
00:13:08,640 --> 00:13:12,680
Le problème, bien sûr, est qu’avec un bloc plus grand, la probabilité de voir plus d’un

187
00:13:12,680 --> 00:13:18,360
ou deux bits d’erreur augmente, et les codes de Hamming ne gèrent rien d’autre au-delà.

188
00:13:18,360 --> 00:13:22,020
Donc, en pratique, ce que vous voudriez, c'est trouver la bonne taille pour que la

189
00:13:22,020 --> 00:13:25,520
probabilité d'un trop grand nombre de retournements de bits ne soit pas trop élevée.

190
00:13:26,520 --> 00:13:30,920
De plus, dans la pratique, les erreurs ont tendance à se produire par petites rafales, ce qui ruinerait

191
00:13:30,920 --> 00:13:35,680
totalement un seul bloc. Une tactique courante pour aider à répartir une rafale d'erreurs sur de nombreux

192
00:13:35,680 --> 00:13:41,720
blocs différents consiste à entrelacer ces blocs, comme ceci, avant qu'ils ne soient générés. envoyés ou stockés.

193
00:13:45,480 --> 00:13:49,920
Là encore, une grande partie de cela est rendue complètement sans objet par des codes plus modernes,

194
00:13:49,920 --> 00:13:55,060
comme l'algorithme de Reed-Solomon, beaucoup plus couramment utilisé, qui gère particulièrement bien les erreurs en rafale, et

195
00:13:55,100 --> 00:13:59,580
il peut être réglé pour être résilient à un plus grand nombre d'erreurs par bloc. .

196
00:13:59,580 --> 00:14:03,000
Mais c'est un sujet pour une autre fois.

197
00:14:03,000 --> 00:14:07,660
Dans son livre The Art of Doing Science and Engineering, Hamming est

198
00:14:07,660 --> 00:14:10,700
merveilleusement franc sur les méandres de sa découverte de ce code.

199
00:14:10,700 --> 00:14:15,180
Il a d'abord essayé toutes sortes de schémas différents impliquant l'organisation des bits

200
00:14:15,180 --> 00:14:18,420
en parties d'un réseau de dimension supérieure et des choses étranges comme celle-ci.

201
00:14:18,420 --> 00:14:22,520
L'idée qu'il pourrait être possible d'obtenir des contrôles de parité pour conspirer d'une manière

202
00:14:22,520 --> 00:14:26,360
qui précise la position d'une erreur n'est venue à Hamming que lorsqu'il a

203
00:14:26,360 --> 00:14:30,800
pris du recul après un tas d'autres analyses et a demandé, d'accord, quelle

204
00:14:30,800 --> 00:14:32,860
est la méthode la plus efficace possible. peut-être qu'il s'agisse de ça ?

205
00:14:32,860 --> 00:14:36,760
Il a également souligné à quel point il était important que les contrôles de parité soient déjà

206
00:14:36,760 --> 00:14:42,040
présents dans son esprit, ce qui aurait été beaucoup moins courant dans les années 1940 qu'aujourd'hui.

207
00:14:42,040 --> 00:14:46,040
Il y a environ une demi-douzaine de fois tout au long de ce livre où

208
00:14:46,040 --> 00:14:49,640
il fait référence à la citation de Louis Pasteur, la chance favorise un esprit préparé.

209
00:14:49,640 --> 00:14:55,120
Avec le recul, les idées intelligentes semblent souvent d’une simplicité trompeuse, ce qui les rend faciles à sous-estimer.

210
00:14:55,120 --> 00:14:59,680
À l’heure actuelle, j’espère honnêtement que les codes de Hamming, ou

211
00:14:59,680 --> 00:15:01,820
du moins la possibilité de tels codes, vous semblent presque évidents.

212
00:15:01,820 --> 00:15:05,440
Mais vous ne devriez pas vous tromper en pensant qu’ils sont

213
00:15:05,440 --> 00:15:08,000
en réalité évidents, car ils ne le sont certainement pas.

214
00:15:08,000 --> 00:15:12,080
Une partie de la raison pour laquelle les idées intelligentes semblent trompeusement faciles est

215
00:15:12,080 --> 00:15:17,360
que nous ne voyons que le résultat final, nettoyant ce qui était en

216
00:15:17,360 --> 00:15:22,400
désordre, sans jamais mentionner tous les mauvais virages, sous-estimant à quel point l'espace des

217
00:15:22,400 --> 00:15:23,980
possibilités explorables est vaste au début d'un problème. processus de résolution, tout ça.

218
00:15:23,980 --> 00:15:25,280
Mais cela est vrai en général.

219
00:15:25,280 --> 00:15:29,880
Je pense que pour certaines inventions spéciales, il y a

220
00:15:29,880 --> 00:15:31,040
une deuxième raison, plus profonde, pour laquelle nous les sous-estimons.

221
00:15:31,040 --> 00:15:35,040
La conception de l'information en termes de bits n'a véritablement abouti à une théorie

222
00:15:35,040 --> 00:15:39,400
complète qu'en 1948, avec l'article fondateur de Claude Shannon sur la théorie de l'information.

223
00:15:39,400 --> 00:15:43,400
Cela correspondait essentiellement au moment où Hamming développait son algorithme.

224
00:15:43,440 --> 00:15:47,300
Il s’agissait du même article fondateur qui montrait, dans un certain

225
00:15:47,300 --> 00:15:52,080
sens, qu’une correction d’erreur efficace est toujours possible, quelle que soit

226
00:15:52,080 --> 00:15:53,920
la probabilité de retournements de bits, du moins en théorie.

227
00:15:53,920 --> 00:15:58,120
Shannon et Hamming, d'ailleurs, partageaient un bureau dans les Bell Labs, bien qu'ils travaillaient

228
00:15:58,120 --> 00:16:02,400
sur des choses très différentes, ce qui ne semble pas ici être une coïncidence.

229
00:16:02,400 --> 00:16:06,960
Avance rapide de plusieurs décennies, et de nos jours, beaucoup d’entre nous sont tellement plongés dans la réflexion sur

230
00:16:06,960 --> 00:16:13,080
des éléments et des informations qu’il est facile d’oublier à quel point cette façon de penser était distincte.

231
00:16:13,080 --> 00:16:17,920
Ironiquement, les idées qui façonnent le plus profondément la façon de penser d’une génération

232
00:16:17,920 --> 00:16:22,640
future finiront par considérer cette génération future plus simplement qu’elles ne le sont réellement.

