1
00:00:00,000 --> 00:00:03,120
Я предполагаю, что все здесь пришли из первой части.

2
00:00:03,120 --> 00:00:06,920
Мы говорили о кодах Хэмминга, способе создания блока данных, в котором

3
00:00:06,920 --> 00:00:11,640
большинство битов несут значимое сообщение, а несколько других действуют как

4
00:00:11,640 --> 00:00:15,800
своего рода избыточность, таким образом, что если какой-либо бит переворачивается,

5
00:00:15,800 --> 00:00:20,560
либо сообщение бит или бит избыточности, что-либо в этом блоке,

6
00:00:20,560 --> 00:00:21,920
получатель сможет определить, что произошла ошибка и как ее исправить.

7
00:00:21,920 --> 00:00:25,900
Основная идея, представленная там, заключалась в том, как использовать

8
00:00:25,900 --> 00:00:29,800
несколько проверок четности для двоичного поиска пути к ошибке.

9
00:00:29,800 --> 00:00:33,920
Целью этого видео было сделать коды Хэмминга

10
00:00:33,920 --> 00:00:35,420
максимально удобными и доступными для повторного открытия.

11
00:00:35,420 --> 00:00:40,040
Но когда вы начинаете думать о реальной реализации этого, будь то в программном или аппаратном

12
00:00:40,040 --> 00:00:44,120
обеспечении, эта структура может на самом деле недооценивать, насколько элегантны эти коды на самом деле.

13
00:00:44,120 --> 00:00:47,620
Вы можете подумать, что вам нужно написать алгоритм, который отслеживает

14
00:00:47,620 --> 00:00:52,320
все возможные места ошибок и сокращает эту группу пополам при

15
00:00:52,320 --> 00:00:54,160
каждой проверке, но на самом деле это намного проще.

16
00:00:54,160 --> 00:00:58,720
Если вы зачитаете ответы на четыре проверки четности, которые мы проводили в последнем видео (все они представляют

17
00:00:58,760 --> 00:01:04,800
собой 1 и 0 вместо «да» и «нет»), то вы буквально определите положение ошибки в двоичном формате.

18
00:01:04,800 --> 00:01:10,160
Например, число 7 в двоичном формате выглядит как 0111, что,

19
00:01:10,160 --> 00:01:12,640
по сути, означает, что это 4 плюс 2 плюс 1.

20
00:01:12,640 --> 00:01:17,960
И обратите внимание, где находится позиция 7: она влияет и на первую из

21
00:01:17,960 --> 00:01:22,280
наших групп четности, и на вторую, и на третью, но не на последнюю.

22
00:01:22,280 --> 00:01:26,560
Таким образом, чтение результатов этих четырех проверок

23
00:01:26,560 --> 00:01:28,000
снизу вверх действительно определяет положение ошибки.

24
00:01:28,520 --> 00:01:32,240
В примере 7 нет ничего особенного, в целом он работает,

25
00:01:32,240 --> 00:01:37,440
и это делает логику аппаратной реализации всей схемы поразительно простой.

26
00:01:37,440 --> 00:01:43,380
Теперь, если вы хотите понять, почему происходит это волшебство, возьмите эти 16 индексных

27
00:01:43,380 --> 00:01:48,480
меток для наших позиций, но вместо того, чтобы записывать их в десятичной системе

28
00:01:48,480 --> 00:01:50,720
счисления, давайте запишем их все в двоичном формате, от 0000 до 1111.

29
00:01:50,720 --> 00:01:55,880
Размещая эти двоичные метки обратно в коробки, позвольте мне

30
00:01:56,080 --> 00:01:58,440
подчеркнуть, что они отличаются от фактически отправляемых данных.

31
00:01:58,440 --> 00:02:02,200
Это не что иное, как концептуальный ярлык, который поможет

32
00:02:02,200 --> 00:02:04,200
вам и мне понять, откуда взялись четыре группы паритета.

33
00:02:04,200 --> 00:02:08,840
Элегантность того, что все, на что мы смотрим, описывается в двоичном формате, возможно, подрывается

34
00:02:08,840 --> 00:02:13,160
путаницей, связанной с тем, что все, на что мы смотрим, описывается в двоичном формате.

35
00:02:13,160 --> 00:02:15,040
Однако оно того стоит.

36
00:02:15,040 --> 00:02:20,740
Сосредоточьте свое внимание только на последнем бите всех этих меток,

37
00:02:20,740 --> 00:02:24,280
а затем выделите позиции, где этот последний бит равен 1.

38
00:02:24,280 --> 00:02:28,800
То, что мы получаем, — это первая из наших четырех групп четности,

39
00:02:28,800 --> 00:02:34,480
что означает, что вы можете интерпретировать эту первую проверку как вопрос: «Эй,

40
00:02:34,480 --> 00:02:36,680
если есть ошибка, последний бит в позиции этой ошибки равен 1?»

41
00:02:36,680 --> 00:02:42,600
Аналогично, если вы сосредоточитесь на предпоследнем бите и выделите все позиции,

42
00:02:42,600 --> 00:02:47,040
где это 1, вы получите вторую группу четности из нашей схемы.

43
00:02:47,040 --> 00:02:51,960
Другими словами, вторая проверка спрашивает: «Эй, еще раз, если есть

44
00:02:51,960 --> 00:02:56,160
ошибка, является ли предпоследний бит этой позиции равным 1?»

45
00:02:56,160 --> 00:02:57,160
И так далее.

46
00:02:57,160 --> 00:03:03,320
Третья проверка четности охватывает каждую позицию, у которой включен третий до последнего бит, а

47
00:03:03,320 --> 00:03:10,120
последняя проверка охватывает последние восемь позиций, те, у которых старший бит равен 1.

48
00:03:10,120 --> 00:03:15,680
Все, что мы делали ранее, аналогично ответу на эти четыре вопроса,

49
00:03:15,680 --> 00:03:18,800
что, в свою очередь, равнозначно написанию позиции в двоичном формате.

50
00:03:19,800 --> 00:03:22,080
Надеюсь, это прояснит две вещи.

51
00:03:22,080 --> 00:03:27,140
Во-первых, как систематически обобщать размеры блоков, превышающие степени двойки.

52
00:03:27,140 --> 00:03:33,180
Если для описания каждой позиции требуется больше битов, например шесть битов для описания 64 точек,

53
00:03:33,180 --> 00:03:38,640
то каждый из этих битов дает вам одну из групп четности, которую нам нужно проверить.

54
00:03:38,640 --> 00:03:42,060
Те из вас, кто смотрел шахматную головоломку, которую я решал

55
00:03:42,060 --> 00:03:43,400
с Мэттом Паркером, возможно, найдут все это чрезвычайно знакомым.

56
00:03:43,400 --> 00:03:48,200
Это та же основная логика, но она решает другую

57
00:03:48,200 --> 00:03:49,880
задачу и применяется к шахматной доске с 64 клетками.

58
00:03:49,880 --> 00:03:54,000
Второе, что, я надеюсь, теперь проясняет, — почему наши биты четности находятся

59
00:03:54,000 --> 00:03:58,320
в позициях, соответствующих степеням двойки, например 1, 2, 4 и 8.

60
00:03:58,320 --> 00:04:03,640
Это позиции, в двоичном представлении которых включен только один бит.

61
00:04:03,640 --> 00:04:09,000
Это означает, что каждый из этих битов четности находится

62
00:04:09,000 --> 00:04:12,640
внутри одной и только одной из четырех групп четности.

63
00:04:12,640 --> 00:04:16,840
Вы также можете увидеть это на более крупных примерах, где независимо от того,

64
00:04:16,840 --> 00:04:25,920
насколько вы велики, каждый бит четности удобно касается только одной из групп.

65
00:04:25,920 --> 00:04:29,680
Как только вы поймете, что эти проверки четности, которым мы уделили

66
00:04:29,680 --> 00:04:34,320
так много времени, являются не чем иным, как умным способом определить

67
00:04:34,320 --> 00:04:37,880
положение ошибки в двоичном формате, тогда мы сможем установить связь с

68
00:04:37,880 --> 00:04:42,160
другим способом мышления о хэмминге. коды, которые, возможно, намного проще и

69
00:04:42,160 --> 00:04:43,880
элегантнее и которые можно записать с помощью одной строки кода.

70
00:04:43,920 --> 00:04:46,200
Он основан на функции XOR.

71
00:04:46,200 --> 00:04:50,960
XOR, для тех из вас, кто не знает, означает «исключающее или».

72
00:04:50,960 --> 00:04:55,440
Когда вы выполняете операцию XOR двух битов, она возвращает 1, если один

73
00:04:55,440 --> 00:05:00,200
из этих битов включен, но не если оба включены или выключены.

74
00:05:00,200 --> 00:05:03,760
Другими словами, это четность этих двух битов.

75
00:05:03,760 --> 00:05:07,840
Как математик, я предпочитаю думать об этом как о моде сложения 2.

76
00:05:07,840 --> 00:05:12,000
Мы также обычно говорим о XOR двух разных битовых

77
00:05:12,040 --> 00:05:14,040
строк, который, по сути, выполняет это компонент за компонентом.

78
00:05:14,040 --> 00:05:16,280
Это как дополнение, но куда не понесешь.

79
00:05:16,280 --> 00:05:21,240
Опять же, более склонные к математике люди могут предпочесть думать об

80
00:05:21,240 --> 00:05:23,520
этом как о добавлении двух векторов и уменьшении модуля 2.

81
00:05:23,520 --> 00:05:28,720
Если вы прямо сейчас откроете какой-нибудь Python и примените операцию курсора между двумя целыми

82
00:05:28,720 --> 00:05:35,400
числами, это то, что он делает, но к битовым представлениям этих чисел под капотом.

83
00:05:35,400 --> 00:05:40,920
Ключевым моментом для нас с вами является то, что выполнение XOR

84
00:05:40,960 --> 00:05:45,960
множества различных битовых строк фактически является способом вычислить пародии на

85
00:05:45,960 --> 00:05:51,320
кучу отдельных групп, как это происходит со столбцами, одним махом.

86
00:05:51,320 --> 00:05:54,520
Это дает нам довольно привлекательный способ представить множественные проверки четности

87
00:05:54,520 --> 00:05:59,680
нашего алгоритма кода Хэмминга как объединенные в одну операцию.

88
00:05:59,680 --> 00:06:02,800
Хотя на первый взгляд все выглядит совсем иначе.

89
00:06:02,800 --> 00:06:08,360
Специально запишите 16 позиций в двоичном формате, как мы делали раньше,

90
00:06:08,640 --> 00:06:14,800
а теперь выделите позиции, где бит сообщения установлен на 1, а

91
00:06:14,800 --> 00:06:19,400
затем соберите эти позиции в один большой столбец и выполните XOR.

92
00:06:19,400 --> 00:06:23,480
Вы, вероятно, можете догадаться, что 4 бита, находящиеся внизу, в

93
00:06:23,480 --> 00:06:27,480
результате совпадают с 4 проверками четности, которые мы знаем

94
00:06:27,480 --> 00:06:32,720
и любим, но найдите время, чтобы подумать, почему именно.

95
00:06:32,720 --> 00:06:37,880
Например, в этом последнем столбце подсчитываются все позиции, последний бит которых

96
00:06:38,400 --> 00:06:42,400
равен 1, но мы уже ограничены только выделенными позициями, поэтому он

97
00:06:42,400 --> 00:06:45,960
эффективно подсчитывает, сколько выделенных позиций пришло из первой группы четности.

98
00:06:45,960 --> 00:06:48,520
Имеет ли это смысл?

99
00:06:48,520 --> 00:06:53,600
Аналогично, в следующем столбце подсчитывается количество позиций во

100
00:06:53,600 --> 00:06:59,640
второй группе четности, позиций, предпоследний бит которых равен

101
00:06:59,640 --> 00:07:00,640
1, которые также выделены и т. д.

102
00:07:00,640 --> 00:07:06,640
На самом деле это всего лишь небольшой сдвиг во взглядах на то же самое, что мы делаем.

103
00:07:07,640 --> 00:07:10,000
Итак, вы знаете, куда это пойдет дальше.

104
00:07:10,000 --> 00:07:14,400
Отправитель отвечает за переключение некоторых специальных битов

105
00:07:14,400 --> 00:07:19,640
четности, чтобы убедиться, что сумма равна 0000.

106
00:07:19,640 --> 00:07:23,600
Теперь, когда у нас это получилось, это дает нам действительно хороший способ задуматься

107
00:07:23,600 --> 00:07:28,720
о том, почему эти четыре результирующих бита внизу непосредственно определяют положение ошибки.

108
00:07:28,720 --> 00:07:32,680
Допустим, какой-то бит в этом блоке переключается с 0 на 1.

109
00:07:32,720 --> 00:07:37,320
Это означает, что позиция этого бита теперь будет

110
00:07:37,320 --> 00:07:42,960
включена в общее исключающее ИЛИ, что изменит сумму

111
00:07:42,960 --> 00:07:44,800
с 0 на новое включенное значение, позицию ошибки.

112
00:07:44,800 --> 00:07:48,800
Чуть менее очевидно то же самое, если произошла

113
00:07:48,800 --> 00:07:49,800
ошибка, из-за которой 1 меняется на 0.

114
00:07:49,800 --> 00:07:54,720
Видите ли, если вы складываете битовую строку дважды, это то же самое, что

115
00:07:54,720 --> 00:07:59,000
ее вообще нет, потому что в этом мире 1 плюс 1 равняется 0.

116
00:07:59,000 --> 00:08:03,720
Таким образом, добавление копии этой позиции к общей сумме

117
00:08:03,720 --> 00:08:05,400
имеет тот же эффект, что и ее перемещение.

118
00:08:05,400 --> 00:08:10,080
И этот эффект, опять же, заключается в том,

119
00:08:10,080 --> 00:08:13,480
что общий результат внизу указывает положение ошибки.

120
00:08:13,480 --> 00:08:17,720
Чтобы проиллюстрировать, насколько это элегантно, позвольте мне показать одну строку кода Python, на

121
00:08:17,720 --> 00:08:22,120
которую я ссылался ранее, которая захватывает почти всю логику на стороне получателя.

122
00:08:22,120 --> 00:08:27,160
Мы начнем с создания случайного массива из 16 единиц и нулей для

123
00:08:27,160 --> 00:08:31,160
имитации блока данных, и я дам ему биты имени, но, конечно, на

124
00:08:31,160 --> 00:08:36,160
практике это будет то, что мы получаем от отправителя, и вместо будучи

125
00:08:36,160 --> 00:08:38,600
случайным, он будет нести 11 бит данных вместе с 5 битами четности.

126
00:08:38,600 --> 00:08:43,160
Если я вызываю функцию enumerateBits, она объединяет каждый из этих битов

127
00:08:43,160 --> 00:08:48,240
с соответствующим индексом, в данном случае от 0 до 15.

128
00:08:48,240 --> 00:08:53,200
Итак, если мы затем создадим список, который будет циклически перебирать все эти пары, пары, которые

129
00:08:53,200 --> 00:08:59,160
выглядят как i, а затем мы вытащим только значение i, только индекс, ну, это не

130
00:08:59,160 --> 00:09:01,920
так уж и интересно, мы просто вернем эти индексы от 0 до 15. .

131
00:09:01,920 --> 00:09:07,520
Но если мы добавим условие делать это только в том случае, если бит, то есть, если этот

132
00:09:07,520 --> 00:09:13,400
бит равен 1, а не 0, то тогда будут выбраны только те позиции, где включен соответствующий бит.

133
00:09:13,400 --> 00:09:20,320
В данном случае это выглядит как позиции 0, 4, 6, 9 и т. д.

134
00:09:20,720 --> 00:09:24,640
Мы хотим собрать вместе все эти позиции, позиции

135
00:09:24,640 --> 00:09:29,960
включенных битов, а затем выполнить XOR их вместе.

136
00:09:29,960 --> 00:09:33,960
Чтобы сделать это в Python, позвольте мне сначала импортировать пару полезных функций.

137
00:09:33,960 --> 00:09:39,140
Таким образом, мы можем вызвать функцию уменьшения() для этого списка и использовать функцию XOR, чтобы уменьшить его.

138
00:09:39,140 --> 00:09:44,840
По сути, это проедает весь список, принимая по пути XOR.

139
00:09:44,840 --> 00:09:48,760
Если хотите, вы можете явно записать эту

140
00:09:48,800 --> 00:09:52,200
функцию XOR без необходимости импортировать ее откуда-либо.

141
00:09:52,200 --> 00:09:56,880
Итак, на данный момент похоже, что если мы сделаем это с нашим случайным

142
00:09:56,880 --> 00:10:02,080
блоком из 16 бит, он вернет 9, что имеет двоичное представление 1001.

143
00:10:02,080 --> 00:10:05,960
Мы не будем этого делать здесь, но вы можете написать функцию, в которой отправитель использует это

144
00:10:05,960 --> 00:10:11,560
двоичное представление для установки четырех битов четности по мере необходимости, в конечном итоге переводя этот блок

145
00:10:11,560 --> 00:10:16,200
в состояние, при котором выполнение этой строки кода для полного списка бит возвращает результат. 0.

146
00:10:17,200 --> 00:10:20,200
Это будет считаться хорошо подготовленным блоком.

147
00:10:20,200 --> 00:10:24,640
Что круто, так это то, что если мы переключим любой из битов в этом списке, имитируя

148
00:10:24,640 --> 00:10:30,600
случайную ошибку из-за шума, то если вы запустите ту же строку кода, она выведет эту ошибку.

149
00:10:30,600 --> 00:10:31,920
Разве это не аккуратно?

150
00:10:31,920 --> 00:10:37,200
Вы можете получить этот блок из ниоткуда, запустить к нему эту единственную строку,

151
00:10:37,200 --> 00:10:42,920
и он автоматически выдаст позицию ошибки или 0, если ее не было.

152
00:10:42,920 --> 00:10:45,520
И в 16 размере здесь нет ничего особенного.

153
00:10:45,520 --> 00:10:52,280
Та же самая строка кода будет работать, если у вас есть список, скажем, из 256 бит.

154
00:10:52,280 --> 00:10:56,280
Излишне говорить, что здесь нужно написать больше кода, например, выполнить мета-проверку

155
00:10:56,280 --> 00:11:01,440
четности для обнаружения 2-битных ошибок, но идея состоит в том, что

156
00:11:01,440 --> 00:11:05,080
почти вся основная логика нашей схемы сводится к одному сокращению XOR.

157
00:11:05,080 --> 00:11:10,600
Теперь, в зависимости от вашего опыта работы с двоичными файлами, операциями XOR и программным обеспечением в

158
00:11:10,600 --> 00:11:15,880
целом, вы можете найти эту точку зрения либо немного запутанной, либо настолько более элегантной и простой,

159
00:11:15,880 --> 00:11:19,320
что вы задаетесь вопросом, почему мы просто не начали с нее с самого начала. -идти.

160
00:11:19,320 --> 00:11:22,880
Грубо говоря, о перспективе множественной проверки четности легче думать при прямой реализации

161
00:11:22,880 --> 00:11:27,560
кодов Хэмминга в аппаратном обеспечении, а о перспективе XOR легче всего

162
00:11:27,560 --> 00:11:31,380
думать, когда она выполняется в программном обеспечении, на более высоком уровне.

163
00:11:31,380 --> 00:11:35,640
Первый проще всего сделать вручную, и я думаю, что он лучше справляется с

164
00:11:35,640 --> 00:11:40,720
задачей, прививая основную интуицию, лежащую в основе всего этого, а именно, что

165
00:11:40,720 --> 00:11:46,840
информация, необходимая для обнаружения единственной ошибки, связана с журналом размера блока. или,

166
00:11:46,840 --> 00:11:51,020
другими словами, он увеличивается по одному биту при увеличении размера блока вдвое.

167
00:11:51,020 --> 00:11:55,440
Важным фактом здесь является то, что эта информация

168
00:11:55,440 --> 00:11:56,440
напрямую соответствует тому, какая избыточность нам нужна.

169
00:11:56,440 --> 00:12:00,320
Именно это на самом деле противоречит коленному рефлексу большинства людей, когда они

170
00:12:00,320 --> 00:12:05,280
впервые задумываются о том, чтобы сделать сообщение устойчивым к ошибкам, когда

171
00:12:05,280 --> 00:12:07,520
обычно копирование всего сообщения является первым инстинктом, который приходит на ум.

172
00:12:07,520 --> 00:12:11,120
И, кстати, есть совершенно другой способ представления кодов

173
00:12:11,120 --> 00:12:14,800
Хэмминга: вы умножаете сообщение на одну большую матрицу.

174
00:12:14,800 --> 00:12:18,580
Это в некоторой степени приятно, потому что соотносит его с более широким семейством линейных кодов, но

175
00:12:18,580 --> 00:12:25,160
я думаю, что это почти не дает понимания того, откуда он взялся и как масштабируется.

176
00:12:25,160 --> 00:12:29,340
Говоря о масштабировании, вы можете заметить, что эффективность этой

177
00:12:29,340 --> 00:12:32,200
схемы становится только выше по мере увеличения размера блока.

178
00:12:32,200 --> 00:12:40,560
Например, мы увидели, что при 256 битах вы используете только 3% этого

179
00:12:40,560 --> 00:12:43,480
пространства для избыточности, и с этого момента ситуация становится все лучше.

180
00:12:43,480 --> 00:12:49,040
По мере того как количество битов четности увеличивается один за другим, размер блока продолжает удваиваться.

181
00:12:49,040 --> 00:12:53,840
А если довести это до крайности, то у вас может получиться блок,

182
00:12:53,840 --> 00:12:58,800
скажем, в миллион битов, в котором вы буквально будете разыгрывать 20 вопросов

183
00:12:58,800 --> 00:13:00,800
с проверками на четность, и он использует только 21 бит четности.

184
00:13:00,800 --> 00:13:05,760
И если вы сделаете шаг назад и подумаете о том, чтобы

185
00:13:05,760 --> 00:13:08,640
просмотреть миллион битов и найти единственную ошибку, это действительно покажется безумием.

186
00:13:08,640 --> 00:13:12,680
Проблема, конечно, в том, что при увеличении блока вероятность увидеть более одного или

187
00:13:12,680 --> 00:13:18,360
двух битовых ошибок возрастает, а коды Хэмминга ничего сверх этого не обрабатывают.

188
00:13:18,360 --> 00:13:22,020
Поэтому на практике вам нужно найти правильный размер, чтобы вероятность

189
00:13:22,020 --> 00:13:25,520
слишком большого количества битовых переворотов не была слишком высокой.

190
00:13:26,520 --> 00:13:30,920
Кроме того, на практике ошибки, как правило, возникают небольшими порциями, что может полностью разрушить один

191
00:13:30,920 --> 00:13:35,680
блок, поэтому одна из распространенных тактик, помогающих распределить пакет ошибок по множеству разных блоков, заключается

192
00:13:35,680 --> 00:13:41,720
в чередовании этих блоков, вот так, прежде чем они будут обработаны. отправлено или сохранено.

193
00:13:45,480 --> 00:13:49,920
Опять же, многое из этого становится совершенно спорным из-за более современных кодов, таких

194
00:13:49,920 --> 00:13:55,060
как гораздо более часто используемый алгоритм Рида-Соломона, который особенно хорошо обрабатывает пакетные ошибки

195
00:13:55,100 --> 00:13:59,580
и может быть настроен на устойчивость к большему количеству ошибок на блок. .

196
00:13:59,580 --> 00:14:03,000
Но это тема для другого раза.

197
00:14:03,000 --> 00:14:07,660
В своей книге «Искусство заниматься наукой и инженерией» Хэмминг удивительно откровенно

198
00:14:07,660 --> 00:14:10,700
рассказывает о том, насколько запутанным было его открытие этого кода.

199
00:14:10,700 --> 00:14:15,180
Сначала он испробовал всевозможные схемы, включающие организацию битов

200
00:14:15,180 --> 00:14:18,420
в части многомерной решетки и подобные странные вещи.

201
00:14:18,420 --> 00:14:22,520
Идея о том, что можно заставить проверки четности сговориться таким

202
00:14:22,520 --> 00:14:26,360
образом, чтобы определить положение ошибки, пришла к Хэммингу только тогда,

203
00:14:26,360 --> 00:14:30,800
когда он отступил после множества других анализов и спросил: «Хорошо,

204
00:14:30,800 --> 00:14:32,860
что я могу наиболее эффективно?» возможно, речь идет об этом?

205
00:14:32,860 --> 00:14:36,760
Он также откровенно говорил о том, насколько важно, чтобы проверки паритета уже были у него

206
00:14:36,760 --> 00:14:42,040
на уме, что в 1940-х годах было бы гораздо менее распространенным явлением, чем сегодня.

207
00:14:42,040 --> 00:14:46,040
В этой книге он примерно полдюжины раз ссылается

208
00:14:46,040 --> 00:14:49,640
на цитату Луи Пастера: удача любит подготовленный ум.

209
00:14:49,640 --> 00:14:55,120
Оглядываясь назад, умные идеи часто кажутся обманчиво простыми, из-за чего их легко недооценить.

210
00:14:55,120 --> 00:14:59,680
Сейчас я искренне надеюсь, что коды Хэмминга или, по крайней

211
00:14:59,680 --> 00:15:01,820
мере, возможность существования таких кодов кажутся вам почти очевидными.

212
00:15:01,820 --> 00:15:05,440
Но не стоит обманывать себя, думая, что они на

213
00:15:05,440 --> 00:15:08,000
самом деле очевидны, потому что это определенно не так.

214
00:15:08,000 --> 00:15:12,080
Одна из причин того, что умные идеи кажутся обманчиво простыми, заключается в

215
00:15:12,080 --> 00:15:17,360
том, что мы всегда видим только конечный результат, убирая то, что

216
00:15:17,360 --> 00:15:22,400
было беспорядочным, никогда не упоминая обо всех неправильных поворотах, преуменьшая, насколько огромно

217
00:15:22,400 --> 00:15:23,980
пространство исследуемых возможностей в начале проблемы. процесс решения и все такое.

218
00:15:23,980 --> 00:15:25,280
Но это правда в целом.

219
00:15:25,280 --> 00:15:29,880
Я думаю, что для некоторых особых изобретений существует вторая,

220
00:15:29,880 --> 00:15:31,040
более глубокая причина, по которой мы их недооцениваем.

221
00:15:31,040 --> 00:15:35,040
Представление об информации в терминах битов по-настоящему сформировалось в полноценную теорию только

222
00:15:35,040 --> 00:15:39,400
к 1948 году, когда появилась основополагающая статья Клода Шеннона по теории информации.

223
00:15:39,400 --> 00:15:43,400
По сути, это совпало с разработкой Хэммингом своего алгоритма.

224
00:15:43,440 --> 00:15:47,300
Это была та же основополагающая статья, которая в определенном смысле

225
00:15:47,300 --> 00:15:52,080
показала, что эффективное исправление ошибок всегда возможно, независимо от того,

226
00:15:52,080 --> 00:15:53,920
насколько высока вероятность переворота битов, по крайней мере теоретически.

227
00:15:53,920 --> 00:15:58,120
Шеннон и Хэмминг, кстати, делили офис в Bell Labs, несмотря на то,

228
00:15:58,120 --> 00:16:02,400
что работали над совершенно разными вещами, что вряд ли здесь кажется случайным.

229
00:16:02,400 --> 00:16:06,960
Перенесемся на несколько десятилетий вперед, и в наши дни многие из нас настолько погружены в размышления

230
00:16:06,960 --> 00:16:13,080
о битах и информации, что легко упустить из виду, насколько особенным был этот образ мышления.

231
00:16:13,080 --> 00:16:17,920
По иронии судьбы, идеи, которые наиболее глубоко формируют образ мышления будущего поколения, в конечном

232
00:16:17,920 --> 00:16:22,640
итоге будут казаться этому будущему поколению проще, чем они есть на самом деле.

