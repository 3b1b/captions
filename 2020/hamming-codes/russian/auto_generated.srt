1
00:00:00,000 --> 00:00:03,120
Я предполагаю, что все здесь пришли из первой части.

2
00:00:03,120 --> 00:00:06,261
Мы говорили о кодах Хэмминга, способе создания блока данных,

3
00:00:06,261 --> 00:00:09,043
в котором большинство битов несут значимое сообщение,

4
00:00:09,043 --> 00:00:12,854
а несколько других действуют как своего рода избыточность, таким образом,

5
00:00:12,854 --> 00:00:17,129
что если какой-либо бит переворачивается, либо сообщение бит или бит избыточности,

6
00:00:17,129 --> 00:00:19,859
что-либо в этом блоке, получатель сможет определить,

7
00:00:19,859 --> 00:00:21,920
что произошла ошибка и как ее исправить.

8
00:00:21,920 --> 00:00:25,095
Основная идея, представленная там, заключалась в том,

9
00:00:25,095 --> 00:00:29,800
как использовать несколько проверок четности для двоичного поиска пути к ошибке.

10
00:00:29,800 --> 00:00:32,910
Целью этого видео было сделать коды Хэмминга максимально

11
00:00:32,910 --> 00:00:35,420
удобными и доступными для повторного открытия.

12
00:00:35,420 --> 00:00:37,943
Но когда вы начинаете думать о реальной реализации этого,

13
00:00:37,943 --> 00:00:40,118
будь то в программном или аппаратном обеспечении,

14
00:00:40,118 --> 00:00:42,249
эта структура может на самом деле недооценивать,

15
00:00:42,249 --> 00:00:44,120
насколько элегантны эти коды на самом деле.

16
00:00:44,120 --> 00:00:46,965
Вы можете подумать, что вам нужно написать алгоритм,

17
00:00:46,965 --> 00:00:50,348
который отслеживает все возможные места ошибок и сокращает эту

18
00:00:50,348 --> 00:00:54,160
группу пополам при каждой проверке, но на самом деле это намного проще.

19
00:00:54,160 --> 00:00:56,870
Если вы зачитаете ответы на четыре проверки четности,

20
00:00:56,870 --> 00:01:00,333
которые мы проводили в последнем видео (все они представляют собой 1

21
00:01:00,333 --> 00:01:04,800
и 0 вместо «да» и «нет»), то вы буквально определите положение ошибки в двоичном формате.

22
00:01:04,800 --> 00:01:09,021
Например, число 7 в двоичном формате выглядит как 0111,

23
00:01:09,021 --> 00:01:12,640
что, по сути, означает, что это 4 плюс 2 плюс 1.

24
00:01:12,640 --> 00:01:17,425
И обратите внимание, где находится позиция 7: она влияет и на первую

25
00:01:17,425 --> 00:01:22,280
из наших групп четности, и на вторую, и на третью, но не на последнюю.

26
00:01:22,280 --> 00:01:25,456
Таким образом, чтение результатов этих четырех проверок

27
00:01:25,456 --> 00:01:28,520
снизу вверх действительно определяет положение ошибки.

28
00:01:28,520 --> 00:01:32,362
В примере 7 нет ничего особенного, в целом он работает,

29
00:01:32,362 --> 00:01:37,440
и это делает логику аппаратной реализации всей схемы поразительно простой.

30
00:01:37,440 --> 00:01:40,992
Теперь, если вы хотите понять, почему происходит это волшебство,

31
00:01:40,992 --> 00:01:44,653
возьмите эти 16 индексных меток для наших позиций, но вместо того,

32
00:01:44,653 --> 00:01:47,495
чтобы записывать их в десятичной системе счисления,

33
00:01:47,495 --> 00:01:50,720
давайте запишем их все в двоичном формате, от 0000 до 1111.

34
00:01:50,720 --> 00:01:55,218
Размещая эти двоичные метки обратно в коробки, позвольте мне подчеркнуть,

35
00:01:55,218 --> 00:01:58,440
что они отличаются от фактически отправляемых данных.

36
00:01:58,440 --> 00:02:02,296
Это не что иное, как концептуальный ярлык, который поможет вам и мне понять,

37
00:02:02,296 --> 00:02:04,200
откуда взялись четыре группы паритета.

38
00:02:04,200 --> 00:02:06,440
Элегантность того, что все, на что мы смотрим,

39
00:02:06,440 --> 00:02:09,537
описывается в двоичном формате, возможно, подрывается путаницей,

40
00:02:09,537 --> 00:02:13,160
связанной с тем, что все, на что мы смотрим, описывается в двоичном формате.

41
00:02:13,160 --> 00:02:15,040
Однако оно того стоит.

42
00:02:15,040 --> 00:02:20,132
Сосредоточьте свое внимание только на последнем бите всех этих меток,

43
00:02:20,132 --> 00:02:24,280
а затем выделите позиции, где этот последний бит равен 1.

44
00:02:24,280 --> 00:02:28,217
То, что мы получаем, — это первая из наших четырех групп четности,

45
00:02:28,217 --> 00:02:32,742
что означает, что вы можете интерпретировать эту первую проверку как вопрос:

46
00:02:32,742 --> 00:02:36,680
«Эй, если есть ошибка, последний бит в позиции этой ошибки равен 1?

47
00:02:36,680 --> 00:02:42,681
» Аналогично, если вы сосредоточитесь на предпоследнем бите и выделите все позиции,

48
00:02:42,681 --> 00:02:47,040
где это 1, вы получите вторую группу четности из нашей схемы.

49
00:02:47,040 --> 00:02:51,211
Другими словами, вторая проверка спрашивает: «Эй, еще раз,

50
00:02:51,211 --> 00:02:56,160
если есть ошибка, является ли предпоследний бит этой позиции равным 1?

51
00:02:56,160 --> 00:02:57,160
» И так далее.

52
00:02:57,160 --> 00:03:00,744
Третья проверка четности охватывает каждую позицию,

53
00:03:00,744 --> 00:03:05,225
у которой включен третий до последнего бит, а последняя проверка

54
00:03:05,225 --> 00:03:10,120
охватывает последние восемь позиций, те, у которых старший бит равен 1.

55
00:03:10,120 --> 00:03:14,854
Все, что мы делали ранее, аналогично ответу на эти четыре вопроса,

56
00:03:14,854 --> 00:03:19,800
что, в свою очередь, равнозначно написанию позиции в двоичном формате.

57
00:03:19,800 --> 00:03:22,080
Надеюсь, это прояснит две вещи.

58
00:03:22,080 --> 00:03:27,140
Во-первых, как систематически обобщать размеры блоков, превышающие степени двойки.

59
00:03:27,140 --> 00:03:30,664
Если для описания каждой позиции требуется больше битов,

60
00:03:30,664 --> 00:03:34,497
например шесть битов для описания 64 точек, то каждый из этих

61
00:03:34,497 --> 00:03:38,640
битов дает вам одну из групп четности, которую нам нужно проверить.

62
00:03:38,640 --> 00:03:41,675
Те из вас, кто смотрел шахматную головоломку, которую я решал с Мэттом Паркером,

63
00:03:41,675 --> 00:03:43,400
возможно, найдут все это чрезвычайно знакомым.

64
00:03:43,400 --> 00:03:46,479
Это та же основная логика, но она решает другую

65
00:03:46,479 --> 00:03:49,880
задачу и применяется к шахматной доске с 64 клетками.

66
00:03:49,880 --> 00:03:53,926
Второе, что, я надеюсь, теперь проясняет, — почему наши биты четности

67
00:03:53,926 --> 00:03:58,320
находятся в позициях, соответствующих степеням двойки, например 1, 2, 4 и 8.

68
00:03:58,320 --> 00:04:03,640
Это позиции, в двоичном представлении которых включен только один бит.

69
00:04:03,640 --> 00:04:08,300
Это означает, что каждый из этих битов четности находится

70
00:04:08,300 --> 00:04:12,640
внутри одной и только одной из четырех групп четности.

71
00:04:12,640 --> 00:04:19,280
Вы также можете увидеть это на более крупных примерах, где независимо от того,

72
00:04:19,280 --> 00:04:25,920
насколько вы велики, каждый бит четности удобно касается только одной из групп.

73
00:04:25,920 --> 00:04:30,394
Как только вы поймете, что эти проверки четности, которым мы уделили так много времени,

74
00:04:30,394 --> 00:04:34,920
являются не чем иным, как умным способом определить положение ошибки в двоичном формате,

75
00:04:34,920 --> 00:04:39,343
тогда мы сможем установить связь с другим способом мышления о хэмминге. коды, которые,

76
00:04:39,343 --> 00:04:43,920
возможно, намного проще и элегантнее и которые можно записать с помощью одной строки кода.

77
00:04:43,920 --> 00:04:46,200
Он основан на функции XOR.

78
00:04:46,200 --> 00:04:50,960
XOR, для тех из вас, кто не знает, означает «исключающее или».

79
00:04:50,960 --> 00:04:55,304
Когда вы выполняете операцию XOR двух битов, она возвращает 1,

80
00:04:55,304 --> 00:05:00,200
если один из этих битов включен, но не если оба включены или выключены.

81
00:05:00,200 --> 00:05:03,760
Другими словами, это четность этих двух битов.

82
00:05:03,760 --> 00:05:07,840
Как математик, я предпочитаю думать об этом как о моде сложения 2.

83
00:05:07,840 --> 00:05:10,940
Мы также обычно говорим о XOR двух разных битовых строк,

84
00:05:10,940 --> 00:05:14,040
который, по сути, выполняет это компонент за компонентом.

85
00:05:14,040 --> 00:05:16,280
Это как дополнение, но куда не понесешь.

86
00:05:16,280 --> 00:05:19,703
Опять же, более склонные к математике люди могут предпочесть

87
00:05:19,703 --> 00:05:23,520
думать об этом как о добавлении двух векторов и уменьшении модуля 2.

88
00:05:23,520 --> 00:05:27,589
Если вы прямо сейчас откроете какой-нибудь Python и примените

89
00:05:27,589 --> 00:05:31,068
операцию курсора между двумя целыми числами, это то,

90
00:05:31,068 --> 00:05:35,400
что он делает, но к битовым представлениям этих чисел под капотом.

91
00:05:35,400 --> 00:05:40,927
Ключевым моментом для нас с вами является то, что выполнение XOR множества

92
00:05:40,927 --> 00:05:46,160
различных битовых строк фактически является способом вычислить пародии

93
00:05:46,160 --> 00:05:51,320
на кучу отдельных групп, как это происходит со столбцами, одним махом.

94
00:05:51,320 --> 00:05:55,691
Это дает нам довольно привлекательный способ представить множественные проверки

95
00:05:55,691 --> 00:05:59,680
четности нашего алгоритма кода Хэмминга как объединенные в одну операцию.

96
00:05:59,680 --> 00:06:02,800
Хотя на первый взгляд все выглядит совсем иначе.

97
00:06:02,800 --> 00:06:08,769
Специально запишите 16 позиций в двоичном формате, как мы делали раньше,

98
00:06:08,769 --> 00:06:13,839
а теперь выделите позиции, где бит сообщения установлен на 1,

99
00:06:13,839 --> 00:06:19,400
а затем соберите эти позиции в один большой столбец и выполните XOR.

100
00:06:19,400 --> 00:06:23,983
Вы, вероятно, можете догадаться, что 4 бита, находящиеся внизу,

101
00:06:23,983 --> 00:06:29,282
в результате совпадают с 4 проверками четности, которые мы знаем и любим,

102
00:06:29,282 --> 00:06:32,720
но найдите время, чтобы подумать, почему именно.

103
00:06:32,720 --> 00:06:36,181
Например, в этом последнем столбце подсчитываются все позиции,

104
00:06:36,181 --> 00:06:40,685
последний бит которых равен 1, но мы уже ограничены только выделенными позициями,

105
00:06:40,685 --> 00:06:45,080
поэтому он эффективно подсчитывает, сколько выделенных позиций пришло из первой

106
00:06:45,080 --> 00:06:45,960
группы четности.

107
00:06:45,960 --> 00:06:48,520
Имеет ли это смысл?

108
00:06:48,520 --> 00:06:54,543
Аналогично, в следующем столбце подсчитывается количество позиций во второй группе

109
00:06:54,543 --> 00:07:00,640
четности, позиций, предпоследний бит которых равен 1, которые также выделены и т. д.

110
00:07:00,640 --> 00:07:07,640
На самом деле это всего лишь небольшой сдвиг во взглядах на то же самое, что мы делаем.

111
00:07:07,640 --> 00:07:10,000
Итак, вы знаете, куда это пойдет дальше.

112
00:07:10,000 --> 00:07:16,398
Отправитель отвечает за переключение некоторых специальных битов четности,

113
00:07:16,398 --> 00:07:19,640
чтобы убедиться, что сумма равна 0000.

114
00:07:19,640 --> 00:07:22,748
Теперь, когда у нас это получилось, это дает нам действительно

115
00:07:22,748 --> 00:07:26,005
хороший способ задуматься о том, почему эти четыре результирующих

116
00:07:26,005 --> 00:07:28,720
бита внизу непосредственно определяют положение ошибки.

117
00:07:28,720 --> 00:07:32,720
Допустим, какой-то бит в этом блоке переключается с 0 на 1.

118
00:07:32,720 --> 00:07:39,440
Это означает, что позиция этого бита теперь будет включена в общее исключающее ИЛИ,

119
00:07:39,440 --> 00:07:44,800
что изменит сумму с 0 на новое включенное значение, позицию ошибки.

120
00:07:44,800 --> 00:07:49,800
Чуть менее очевидно то же самое, если произошла ошибка, из-за которой 1 меняется на 0.

121
00:07:49,800 --> 00:07:54,674
Видите ли, если вы складываете битовую строку дважды, это то же самое,

122
00:07:54,674 --> 00:07:59,000
что ее вообще нет, потому что в этом мире 1 плюс 1 равняется 0.

123
00:07:59,000 --> 00:08:04,069
Таким образом, добавление копии этой позиции к общей сумме имеет тот же эффект,

124
00:08:04,069 --> 00:08:05,400
что и ее перемещение.

125
00:08:05,400 --> 00:08:09,398
И этот эффект, опять же, заключается в том, что

126
00:08:09,398 --> 00:08:13,480
общий результат внизу указывает положение ошибки.

127
00:08:13,480 --> 00:08:15,802
Чтобы проиллюстрировать, насколько это элегантно,

128
00:08:15,802 --> 00:08:18,032
позвольте мне показать одну строку кода Python,

129
00:08:18,032 --> 00:08:22,120
на которую я ссылался ранее, которая захватывает почти всю логику на стороне получателя.

130
00:08:22,120 --> 00:08:27,572
Мы начнем с создания случайного массива из 16 единиц и нулей для имитации блока данных,

131
00:08:27,572 --> 00:08:31,475
и я дам ему биты имени, но, конечно, на практике это будет то,

132
00:08:31,475 --> 00:08:35,130
что мы получаем от отправителя, и вместо будучи случайным,

133
00:08:35,130 --> 00:08:38,600
он будет нести 11 бит данных вместе с 5 битами четности.

134
00:08:38,600 --> 00:08:43,307
Если я вызываю функцию enumerateBits, она объединяет каждый из

135
00:08:43,307 --> 00:08:48,240
этих битов с соответствующим индексом, в данном случае от 0 до 15.

136
00:08:48,240 --> 00:08:53,178
Итак, если мы затем создадим список, который будет циклически перебирать все эти пары,

137
00:08:53,178 --> 00:08:57,889
пары, которые выглядят как i, а затем мы вытащим только значение i, только индекс,

138
00:08:57,889 --> 00:09:01,920
ну, это не так уж и интересно, мы просто вернем эти индексы от 0 до 15.

139
00:09:01,920 --> 00:09:05,621
Но если мы добавим условие делать это только в том случае,

140
00:09:05,621 --> 00:09:08,757
если бит, то есть, если этот бит равен 1, а не 0,

141
00:09:08,757 --> 00:09:13,400
то тогда будут выбраны только те позиции, где включен соответствующий бит.

142
00:09:13,400 --> 00:09:20,720
В данном случае это выглядит как позиции 0, 4, 6, 9 и т. д.

143
00:09:20,720 --> 00:09:26,973
Мы хотим собрать вместе все эти позиции, позиции включенных битов,

144
00:09:26,973 --> 00:09:29,960
а затем выполнить XOR их вместе.

145
00:09:29,960 --> 00:09:33,960
Чтобы сделать это в Python, позвольте мне сначала импортировать пару полезных функций.

146
00:09:33,960 --> 00:09:36,462
Таким образом, мы можем вызвать функцию уменьшения() для

147
00:09:36,462 --> 00:09:39,140
этого списка и использовать функцию XOR, чтобы уменьшить его.

148
00:09:39,140 --> 00:09:44,840
По сути, это проедает весь список, принимая по пути XOR.

149
00:09:44,840 --> 00:09:48,446
Если хотите, вы можете явно записать эту функцию

150
00:09:48,446 --> 00:09:52,200
XOR без необходимости импортировать ее откуда-либо.

151
00:09:52,200 --> 00:09:57,279
Итак, на данный момент похоже, что если мы сделаем это с нашим случайным

152
00:09:57,279 --> 00:10:02,080
блоком из 16 бит, он вернет 9, что имеет двоичное представление 1001.

153
00:10:02,080 --> 00:10:05,066
Мы не будем этого делать здесь, но вы можете написать функцию,

154
00:10:05,066 --> 00:10:08,952
в которой отправитель использует это двоичное представление для установки четырех

155
00:10:08,952 --> 00:10:13,076
битов четности по мере необходимости, в конечном итоге переводя этот блок в состояние,

156
00:10:13,076 --> 00:10:17,200
при котором выполнение этой строки кода для полного списка бит возвращает результат. 0.

157
00:10:17,200 --> 00:10:20,200
Это будет считаться хорошо подготовленным блоком.

158
00:10:20,200 --> 00:10:24,665
Что круто, так это то, что если мы переключим любой из битов в этом списке,

159
00:10:24,665 --> 00:10:29,248
имитируя случайную ошибку из-за шума, то если вы запустите ту же строку кода,

160
00:10:29,248 --> 00:10:30,600
она выведет эту ошибку.

161
00:10:30,600 --> 00:10:31,920
Разве это не аккуратно?

162
00:10:31,920 --> 00:10:38,163
Вы можете получить этот блок из ниоткуда, запустить к нему эту единственную строку,

163
00:10:38,163 --> 00:10:42,920
и он автоматически выдаст позицию ошибки или 0, если ее не было.

164
00:10:42,920 --> 00:10:45,520
И в 16 размере здесь нет ничего особенного.

165
00:10:45,520 --> 00:10:52,280
Та же самая строка кода будет работать, если у вас есть список, скажем, из 256 бит.

166
00:10:52,280 --> 00:10:55,953
Излишне говорить, что здесь нужно написать больше кода, например,

167
00:10:55,953 --> 00:10:59,626
выполнить мета-проверку четности для обнаружения 2-битных ошибок,

168
00:10:59,626 --> 00:11:03,855
но идея состоит в том, что почти вся основная логика нашей схемы сводится к

169
00:11:03,855 --> 00:11:05,080
одному сокращению XOR.

170
00:11:05,080 --> 00:11:08,202
Теперь, в зависимости от вашего опыта работы с двоичными файлами,

171
00:11:08,202 --> 00:11:10,615
операциями XOR и программным обеспечением в целом,

172
00:11:10,615 --> 00:11:13,359
вы можете найти эту точку зрения либо немного запутанной,

173
00:11:13,359 --> 00:11:16,670
либо настолько более элегантной и простой, что вы задаетесь вопросом,

174
00:11:16,670 --> 00:11:19,320
почему мы просто не начали с нее с самого начала. -идти.

175
00:11:19,320 --> 00:11:23,388
Грубо говоря, о перспективе множественной проверки четности легче думать при прямой

176
00:11:23,388 --> 00:11:25,906
реализации кодов Хэмминга в аппаратном обеспечении,

177
00:11:25,906 --> 00:11:30,217
а о перспективе XOR легче всего думать, когда она выполняется в программном обеспечении,

178
00:11:30,217 --> 00:11:31,380
на более высоком уровне.

179
00:11:31,380 --> 00:11:36,188
Первый проще всего сделать вручную, и я думаю, что он лучше справляется с задачей,

180
00:11:36,188 --> 00:11:41,055
прививая основную интуицию, лежащую в основе всего этого, а именно, что информация,

181
00:11:41,055 --> 00:11:45,863
необходимая для обнаружения единственной ошибки, связана с журналом размера блока.

182
00:11:45,863 --> 00:11:51,020
или, другими словами, он увеличивается по одному биту при увеличении размера блока вдвое.

183
00:11:51,020 --> 00:11:55,011
Важным фактом здесь является то, что эта информация напрямую соответствует тому,

184
00:11:55,011 --> 00:11:56,440
какая избыточность нам нужна.

185
00:11:56,440 --> 00:11:59,781
Именно это на самом деле противоречит коленному рефлексу большинства людей,

186
00:11:59,781 --> 00:12:03,474
когда они впервые задумываются о том, чтобы сделать сообщение устойчивым к ошибкам,

187
00:12:03,474 --> 00:12:06,508
когда обычно копирование всего сообщения является первым инстинктом,

188
00:12:06,508 --> 00:12:07,520
который приходит на ум.

189
00:12:07,520 --> 00:12:11,900
И, кстати, есть совершенно другой способ представления кодов Хэмминга:

190
00:12:11,900 --> 00:12:14,800
вы умножаете сообщение на одну большую матрицу.

191
00:12:14,800 --> 00:12:18,088
Это в некоторой степени приятно, потому что соотносит его с

192
00:12:18,088 --> 00:12:20,994
более широким семейством линейных кодов, но я думаю,

193
00:12:20,994 --> 00:12:25,160
что это почти не дает понимания того, откуда он взялся и как масштабируется.

194
00:12:25,160 --> 00:12:28,599
Говоря о масштабировании, вы можете заметить, что эффективность

195
00:12:28,599 --> 00:12:32,200
этой схемы становится только выше по мере увеличения размера блока.

196
00:12:32,200 --> 00:12:37,539
Например, мы увидели, что при 256 битах вы используете только 3% этого

197
00:12:37,539 --> 00:12:43,480
пространства для избыточности, и с этого момента ситуация становится все лучше.

198
00:12:43,480 --> 00:12:47,203
По мере того как количество битов четности увеличивается один за другим,

199
00:12:47,203 --> 00:12:49,040
размер блока продолжает удваиваться.

200
00:12:49,040 --> 00:12:52,697
А если довести это до крайности, то у вас может получиться блок,

201
00:12:52,697 --> 00:12:56,636
скажем, в миллион битов, в котором вы буквально будете разыгрывать 20

202
00:12:56,636 --> 00:13:00,800
вопросов с проверками на четность, и он использует только 21 бит четности.

203
00:13:00,800 --> 00:13:03,377
И если вы сделаете шаг назад и подумаете о том,

204
00:13:03,377 --> 00:13:06,653
чтобы просмотреть миллион битов и найти единственную ошибку,

205
00:13:06,653 --> 00:13:08,640
это действительно покажется безумием.

206
00:13:08,640 --> 00:13:13,414
Проблема, конечно, в том, что при увеличении блока вероятность увидеть более одного

207
00:13:13,414 --> 00:13:18,360
или двух битовых ошибок возрастает, а коды Хэмминга ничего сверх этого не обрабатывают.

208
00:13:18,360 --> 00:13:21,455
Поэтому на практике вам нужно найти правильный размер,

209
00:13:21,455 --> 00:13:26,520
чтобы вероятность слишком большого количества битовых переворотов не была слишком высокой.

210
00:13:26,520 --> 00:13:30,899
Кроме того, на практике ошибки, как правило, возникают небольшими порциями,

211
00:13:30,899 --> 00:13:35,625
что может полностью разрушить один блок, поэтому одна из распространенных тактик,

212
00:13:35,625 --> 00:13:39,371
помогающих распределить пакет ошибок по множеству разных блоков,

213
00:13:39,371 --> 00:13:44,039
заключается в чередовании этих блоков, вот так, прежде чем они будут обработаны.

214
00:13:44,039 --> 00:13:45,480
отправлено или сохранено.

215
00:13:45,480 --> 00:13:49,830
Опять же, многое из этого становится совершенно спорным из-за более современных кодов,

216
00:13:49,830 --> 00:13:53,180
таких как гораздо более часто используемый алгоритм Рида-Соломона,

217
00:13:53,180 --> 00:13:56,480
который особенно хорошо обрабатывает пакетные ошибки и может быть

218
00:13:56,480 --> 00:13:59,580
настроен на устойчивость к большему количеству ошибок на блок.

219
00:13:59,580 --> 00:14:03,000
Но это тема для другого раза.

220
00:14:03,000 --> 00:14:06,752
В своей книге «Искусство заниматься наукой и инженерией» Хэмминг удивительно

221
00:14:06,752 --> 00:14:10,700
откровенно рассказывает о том, насколько запутанным было его открытие этого кода.

222
00:14:10,700 --> 00:14:14,746
Сначала он испробовал всевозможные схемы, включающие организацию

223
00:14:14,746 --> 00:14:18,420
битов в части многомерной решетки и подобные странные вещи.

224
00:14:18,420 --> 00:14:22,448
Идея о том, что можно заставить проверки четности сговориться таким образом,

225
00:14:22,448 --> 00:14:25,953
чтобы определить положение ошибки, пришла к Хэммингу только тогда,

226
00:14:25,953 --> 00:14:29,616
когда он отступил после множества других анализов и спросил: «Хорошо,

227
00:14:29,616 --> 00:14:32,860
что я могу наиболее эффективно? » возможно, речь идет об этом?

228
00:14:32,860 --> 00:14:35,512
Он также откровенно говорил о том, насколько важно,

229
00:14:35,512 --> 00:14:37,960
чтобы проверки паритета уже были у него на уме,

230
00:14:37,960 --> 00:14:42,040
что в 1940-х годах было бы гораздо менее распространенным явлением, чем сегодня.

231
00:14:42,040 --> 00:14:47,404
В этой книге он примерно полдюжины раз ссылается на цитату Луи Пастера:

232
00:14:47,404 --> 00:14:49,640
удача любит подготовленный ум.

233
00:14:49,640 --> 00:14:53,293
Оглядываясь назад, умные идеи часто кажутся обманчиво простыми,

234
00:14:53,293 --> 00:14:55,120
из-за чего их легко недооценить.

235
00:14:55,120 --> 00:14:58,470
Сейчас я искренне надеюсь, что коды Хэмминга или, по крайней мере,

236
00:14:58,470 --> 00:15:01,820
возможность существования таких кодов кажутся вам почти очевидными.

237
00:15:01,820 --> 00:15:05,940
Но не стоит обманывать себя, думая, что они на самом деле очевидны,

238
00:15:05,940 --> 00:15:08,000
потому что это определенно не так.

239
00:15:08,000 --> 00:15:11,971
Одна из причин того, что умные идеи кажутся обманчиво простыми, заключается в том,

240
00:15:11,971 --> 00:15:15,894
что мы всегда видим только конечный результат, убирая то, что было беспорядочным,

241
00:15:15,894 --> 00:15:19,052
никогда не упоминая обо всех неправильных поворотах, преуменьшая,

242
00:15:19,052 --> 00:15:22,640
насколько огромно пространство исследуемых возможностей в начале проблемы.

243
00:15:22,640 --> 00:15:23,980
процесс решения и все такое.

244
00:15:23,980 --> 00:15:25,280
Но это правда в целом.

245
00:15:25,280 --> 00:15:28,400
Я думаю, что для некоторых особых изобретений существует вторая,

246
00:15:28,400 --> 00:15:31,040
более глубокая причина, по которой мы их недооцениваем.

247
00:15:31,040 --> 00:15:33,636
Представление об информации в терминах битов по-настоящему

248
00:15:33,636 --> 00:15:36,100
сформировалось в полноценную теорию только к 1948 году,

249
00:15:36,100 --> 00:15:39,400
когда появилась основополагающая статья Клода Шеннона по теории информации.

250
00:15:39,400 --> 00:15:43,440
По сути, это совпало с разработкой Хэммингом своего алгоритма.

251
00:15:43,440 --> 00:15:47,117
Это была та же основополагающая статья, которая в определенном смысле показала,

252
00:15:47,117 --> 00:15:50,426
что эффективное исправление ошибок всегда возможно, независимо от того,

253
00:15:50,426 --> 00:15:53,920
насколько высока вероятность переворота битов, по крайней мере теоретически.

254
00:15:53,920 --> 00:15:57,785
Шеннон и Хэмминг, кстати, делили офис в Bell Labs, несмотря на то,

255
00:15:57,785 --> 00:16:02,400
что работали над совершенно разными вещами, что вряд ли здесь кажется случайным.

256
00:16:02,400 --> 00:16:05,871
Перенесемся на несколько десятилетий вперед, и в наши дни многие

257
00:16:05,871 --> 00:16:09,235
из нас настолько погружены в размышления о битах и информации,

258
00:16:09,235 --> 00:16:13,080
что легко упустить из виду, насколько особенным был этот образ мышления.

259
00:16:13,080 --> 00:16:14,623
По иронии судьбы, идеи, которые наиболее глубоко формируют

260
00:16:14,623 --> 00:16:16,140
образ мышления будущего поколения, в конечном итоге будут

261
00:16:16,140 --> 00:16:17,920
казаться этому будущему поколению проще, чем они есть на самом деле.

