1
00:00:00,000 --> 00:00:03,120
Я предполагаю, что все здесь пришли из первой части.

2
00:00:03,120 --> 00:00:06,776
Мы говорили о кодах Хэмминга, способе создания блока данных, в котором

3
00:00:06,776 --> 00:00:10,536
большинство битов несут значимое сообщение, а несколько других действуют

4
00:00:10,536 --> 00:00:14,090
как своего рода избыточность, таким образом, что если какой-либо бит

5
00:00:14,090 --> 00:00:17,953
переворачивается, либо сообщение бит или бит избыточности, что-либо в этом

6
00:00:17,953 --> 00:00:21,920
блоке, получатель сможет определить, что произошла ошибка и как ее исправить.

7
00:00:21,920 --> 00:00:26,095
Основная идея, представленная там, заключалась в том, как использовать

8
00:00:26,095 --> 00:00:29,800
несколько проверок четности для двоичного поиска пути к ошибке.

9
00:00:29,800 --> 00:00:32,910
Целью этого видео было сделать коды Хэмминга максимально

10
00:00:32,910 --> 00:00:35,420
удобными и доступными для повторного открытия.

11
00:00:35,420 --> 00:00:38,291
Но когда вы начинаете думать о реальной реализации этого, будь то

12
00:00:38,291 --> 00:00:41,118
в программном или аппаратном обеспечении, эта структура может на

13
00:00:41,118 --> 00:00:44,120
самом деле недооценивать, насколько элегантны эти коды на самом деле.

14
00:00:44,120 --> 00:00:47,395
Вы можете подумать, что вам нужно написать алгоритм, который

15
00:00:47,395 --> 00:00:50,723
отслеживает все возможные места ошибок и сокращает эту группу

16
00:00:50,723 --> 00:00:54,160
пополам при каждой проверке, но на самом деле это намного проще.

17
00:00:54,160 --> 00:00:57,422
Если вы зачитаете ответы на четыре проверки четности, которые мы

18
00:00:57,422 --> 00:01:00,885
проводили в последнем видео (все они представляют собой 1 и 0 вместо

19
00:01:00,885 --> 00:01:04,800
«да» и «нет»), то вы буквально определите положение ошибки в двоичном формате.

20
00:01:04,800 --> 00:01:08,569
Например, число 7 в двоичном формате выглядит как

21
00:01:08,569 --> 00:01:12,640
0111, что, по сути, означает, что это 4 плюс 2 плюс 1.

22
00:01:12,640 --> 00:01:17,425
И обратите внимание, где находится позиция 7: она влияет и на первую

23
00:01:17,425 --> 00:01:22,280
из наших групп четности, и на вторую, и на третью, но не на последнюю.

24
00:01:22,280 --> 00:01:25,456
Таким образом, чтение результатов этих четырех проверок

25
00:01:25,456 --> 00:01:28,520
снизу вверх действительно определяет положение ошибки.

26
00:01:28,520 --> 00:01:32,774
В примере 7 нет ничего особенного, в целом он работает, и это

27
00:01:32,774 --> 00:01:37,440
делает логику аппаратной реализации всей схемы поразительно простой.

28
00:01:37,440 --> 00:01:41,866
Теперь, если вы хотите понять, почему происходит это волшебство, возьмите эти 16

29
00:01:41,866 --> 00:01:46,457
индексных меток для наших позиций, но вместо того, чтобы записывать их в десятичной

30
00:01:46,457 --> 00:01:50,720
системе счисления, давайте запишем их все в двоичном формате, от 0000 до 1111.

31
00:01:50,720 --> 00:01:54,428
Размещая эти двоичные метки обратно в коробки, позвольте мне

32
00:01:54,428 --> 00:01:58,440
подчеркнуть, что они отличаются от фактически отправляемых данных.

33
00:01:58,440 --> 00:02:01,395
Это не что иное, как концептуальный ярлык, который поможет

34
00:02:01,395 --> 00:02:04,200
вам и мне понять, откуда взялись четыре группы паритета.

35
00:02:04,200 --> 00:02:07,107
Элегантность того, что все, на что мы смотрим, описывается в

36
00:02:07,107 --> 00:02:10,014
двоичном формате, возможно, подрывается путаницей, связанной

37
00:02:10,014 --> 00:02:13,160
с тем, что все, на что мы смотрим, описывается в двоичном формате.

38
00:02:13,160 --> 00:02:15,040
Однако оно того стоит.

39
00:02:15,040 --> 00:02:19,623
Сосредоточьте свое внимание только на последнем бите всех этих

40
00:02:19,623 --> 00:02:24,280
меток, а затем выделите позиции, где этот последний бит равен 1.

41
00:02:24,280 --> 00:02:28,452
То, что мы получаем, — это первая из наших четырех групп четности, что

42
00:02:28,452 --> 00:02:32,742
означает, что вы можете интерпретировать эту первую проверку как вопрос:

43
00:02:32,742 --> 00:02:36,680
«Эй, если есть ошибка, последний бит в позиции этой ошибки равен 1?

44
00:02:36,680 --> 00:02:41,752
» Аналогично, если вы сосредоточитесь на предпоследнем бите и выделите

45
00:02:41,752 --> 00:02:47,040
все позиции, где это 1, вы получите вторую группу четности из нашей схемы.

46
00:02:47,040 --> 00:02:51,564
Другими словами, вторая проверка спрашивает: «Эй, еще раз, если

47
00:02:51,564 --> 00:02:56,160
есть ошибка, является ли предпоследний бит этой позиции равным 1?

48
00:02:56,160 --> 00:02:57,160
» И так далее.

49
00:02:57,160 --> 00:03:01,434
Третья проверка четности охватывает каждую позицию, у которой

50
00:03:01,434 --> 00:03:05,983
включен третий до последнего бит, а последняя проверка охватывает

51
00:03:05,983 --> 00:03:10,120
последние восемь позиций, те, у которых старший бит равен 1.

52
00:03:10,120 --> 00:03:14,854
Все, что мы делали ранее, аналогично ответу на эти четыре вопроса,

53
00:03:14,854 --> 00:03:19,800
что, в свою очередь, равнозначно написанию позиции в двоичном формате.

54
00:03:19,800 --> 00:03:22,080
Надеюсь, это прояснит две вещи.

55
00:03:22,080 --> 00:03:27,140
Во-первых, как систематически обобщать размеры блоков, превышающие степени двойки.

56
00:03:27,140 --> 00:03:31,220
Если для описания каждой позиции требуется больше битов, например

57
00:03:31,220 --> 00:03:35,177
шесть битов для описания 64 точек, то каждый из этих битов дает

58
00:03:35,177 --> 00:03:38,640
вам одну из групп четности, которую нам нужно проверить.

59
00:03:38,640 --> 00:03:40,963
Те из вас, кто смотрел шахматную головоломку, которую я решал

60
00:03:40,963 --> 00:03:43,400
с Мэттом Паркером, возможно, найдут все это чрезвычайно знакомым.

61
00:03:43,400 --> 00:03:46,479
Это та же основная логика, но она решает другую

62
00:03:46,479 --> 00:03:49,880
задачу и применяется к шахматной доске с 64 клетками.

63
00:03:49,880 --> 00:03:53,926
Второе, что, я надеюсь, теперь проясняет, — почему наши биты четности

64
00:03:53,926 --> 00:03:58,320
находятся в позициях, соответствующих степеням двойки, например 1, 2, 4 и 8.

65
00:03:58,320 --> 00:04:03,640
Это позиции, в двоичном представлении которых включен только один бит.

66
00:04:03,640 --> 00:04:08,300
Это означает, что каждый из этих битов четности находится

67
00:04:08,300 --> 00:04:12,640
внутри одной и только одной из четырех групп четности.

68
00:04:12,640 --> 00:04:19,280
Вы также можете увидеть это на более крупных примерах, где независимо от того,

69
00:04:19,280 --> 00:04:25,920
насколько вы велики, каждый бит четности удобно касается только одной из групп.

70
00:04:25,920 --> 00:04:30,394
Как только вы поймете, что эти проверки четности, которым мы уделили так много времени,

71
00:04:30,394 --> 00:04:34,920
являются не чем иным, как умным способом определить положение ошибки в двоичном формате,

72
00:04:34,920 --> 00:04:39,343
тогда мы сможем установить связь с другим способом мышления о хэмминге. коды, которые,

73
00:04:39,343 --> 00:04:43,920
возможно, намного проще и элегантнее и которые можно записать с помощью одной строки кода.

74
00:04:43,920 --> 00:04:46,200
Он основан на функции XOR.

75
00:04:46,200 --> 00:04:50,960
XOR, для тех из вас, кто не знает, означает «исключающее или».

76
00:04:50,960 --> 00:04:55,648
Когда вы выполняете операцию XOR двух битов, она возвращает 1, если

77
00:04:55,648 --> 00:05:00,200
один из этих битов включен, но не если оба включены или выключены.

78
00:05:00,200 --> 00:05:03,760
Другими словами, это четность этих двух битов.

79
00:05:03,760 --> 00:05:07,840
Как математик, я предпочитаю думать об этом как о моде сложения 2.

80
00:05:07,840 --> 00:05:10,940
Мы также обычно говорим о XOR двух разных битовых строк,

81
00:05:10,940 --> 00:05:14,040
который, по сути, выполняет это компонент за компонентом.

82
00:05:14,040 --> 00:05:16,280
Это как дополнение, но куда не понесешь.

83
00:05:16,280 --> 00:05:19,703
Опять же, более склонные к математике люди могут предпочесть

84
00:05:19,703 --> 00:05:23,520
думать об этом как о добавлении двух векторов и уменьшении модуля 2.

85
00:05:23,520 --> 00:05:27,589
Если вы прямо сейчас откроете какой-нибудь Python и примените

86
00:05:27,589 --> 00:05:31,527
операцию курсора между двумя целыми числами, это то, что он

87
00:05:31,527 --> 00:05:35,400
делает, но к битовым представлениям этих чисел под капотом.

88
00:05:35,400 --> 00:05:40,927
Ключевым моментом для нас с вами является то, что выполнение XOR множества

89
00:05:40,927 --> 00:05:46,160
различных битовых строк фактически является способом вычислить пародии

90
00:05:46,160 --> 00:05:51,320
на кучу отдельных групп, как это происходит со столбцами, одним махом.

91
00:05:51,320 --> 00:05:55,691
Это дает нам довольно привлекательный способ представить множественные проверки

92
00:05:55,691 --> 00:05:59,680
четности нашего алгоритма кода Хэмминга как объединенные в одну операцию.

93
00:05:59,680 --> 00:06:02,800
Хотя на первый взгляд все выглядит совсем иначе.

94
00:06:02,800 --> 00:06:08,115
Специально запишите 16 позиций в двоичном формате, как мы делали

95
00:06:08,115 --> 00:06:13,594
раньше, а теперь выделите позиции, где бит сообщения установлен на

96
00:06:13,594 --> 00:06:19,400
1, а затем соберите эти позиции в один большой столбец и выполните XOR.

97
00:06:19,400 --> 00:06:23,983
Вы, вероятно, можете догадаться, что 4 бита, находящиеся внизу,

98
00:06:23,983 --> 00:06:28,208
в результате совпадают с 4 проверками четности, которые мы

99
00:06:28,208 --> 00:06:32,720
знаем и любим, но найдите время, чтобы подумать, почему именно.

100
00:06:32,720 --> 00:06:36,950
Например, в этом последнем столбце подсчитываются все позиции, последний бит

101
00:06:36,950 --> 00:06:41,290
которых равен 1, но мы уже ограничены только выделенными позициями, поэтому он

102
00:06:41,290 --> 00:06:45,960
эффективно подсчитывает, сколько выделенных позиций пришло из первой группы четности.

103
00:06:45,960 --> 00:06:48,520
Имеет ли это смысл?

104
00:06:48,520 --> 00:06:54,543
Аналогично, в следующем столбце подсчитывается количество позиций во второй группе

105
00:06:54,543 --> 00:07:00,640
четности, позиций, предпоследний бит которых равен 1, которые также выделены и т. д.

106
00:07:00,640 --> 00:07:07,640
На самом деле это всего лишь небольшой сдвиг во взглядах на то же самое, что мы делаем.

107
00:07:07,640 --> 00:07:10,000
Итак, вы знаете, куда это пойдет дальше.

108
00:07:10,000 --> 00:07:15,033
Отправитель отвечает за переключение некоторых специальных

109
00:07:15,033 --> 00:07:19,640
битов четности, чтобы убедиться, что сумма равна 0000.

110
00:07:19,640 --> 00:07:22,748
Теперь, когда у нас это получилось, это дает нам действительно

111
00:07:22,748 --> 00:07:26,005
хороший способ задуматься о том, почему эти четыре результирующих

112
00:07:26,005 --> 00:07:28,720
бита внизу непосредственно определяют положение ошибки.

113
00:07:28,720 --> 00:07:32,720
Допустим, какой-то бит в этом блоке переключается с 0 на 1.

114
00:07:32,720 --> 00:07:39,040
Это означает, что позиция этого бита теперь будет включена в общее исключающее

115
00:07:39,040 --> 00:07:44,800
ИЛИ, что изменит сумму с 0 на новое включенное значение, позицию ошибки.

116
00:07:44,800 --> 00:07:49,800
Чуть менее очевидно то же самое, если произошла ошибка, из-за которой 1 меняется на 0.

117
00:07:49,800 --> 00:07:54,194
Видите ли, если вы складываете битовую строку дважды, это то же

118
00:07:54,194 --> 00:07:59,000
самое, что ее вообще нет, потому что в этом мире 1 плюс 1 равняется 0.

119
00:07:59,000 --> 00:08:01,978
Таким образом, добавление копии этой позиции к

120
00:08:01,978 --> 00:08:05,400
общей сумме имеет тот же эффект, что и ее перемещение.

121
00:08:05,400 --> 00:08:09,398
И этот эффект, опять же, заключается в том, что

122
00:08:09,398 --> 00:08:13,480
общий результат внизу указывает положение ошибки.

123
00:08:13,480 --> 00:08:16,267
Чтобы проиллюстрировать, насколько это элегантно, позвольте

124
00:08:16,267 --> 00:08:19,054
мне показать одну строку кода Python, на которую я ссылался

125
00:08:19,054 --> 00:08:22,120
ранее, которая захватывает почти всю логику на стороне получателя.

126
00:08:22,120 --> 00:08:27,572
Мы начнем с создания случайного массива из 16 единиц и нулей для имитации блока данных,

127
00:08:27,572 --> 00:08:32,652
и я дам ему биты имени, но, конечно, на практике это будет то, что мы получаем от

128
00:08:32,652 --> 00:08:38,042
отправителя, и вместо будучи случайным, он будет нести 11 бит данных вместе с 5 битами

129
00:08:38,042 --> 00:08:38,600
четности.

130
00:08:38,600 --> 00:08:43,307
Если я вызываю функцию enumerateBits, она объединяет каждый из

131
00:08:43,307 --> 00:08:48,240
этих битов с соответствующим индексом, в данном случае от 0 до 15.

132
00:08:48,240 --> 00:08:52,837
Итак, если мы затем создадим список, который будет циклически перебирать все эти

133
00:08:52,837 --> 00:08:57,435
пары, пары, которые выглядят как i, а затем мы вытащим только значение i, только

134
00:08:57,435 --> 00:09:01,920
индекс, ну, это не так уж и интересно, мы просто вернем эти индексы от 0 до 15.

135
00:09:01,920 --> 00:09:05,621
Но если мы добавим условие делать это только в том случае,

136
00:09:05,621 --> 00:09:09,322
если бит, то есть, если этот бит равен 1, а не 0, то тогда

137
00:09:09,322 --> 00:09:13,400
будут выбраны только те позиции, где включен соответствующий бит.

138
00:09:13,400 --> 00:09:20,720
В данном случае это выглядит как позиции 0, 4, 6, 9 и т. д.

139
00:09:20,720 --> 00:09:25,293
Мы хотим собрать вместе все эти позиции, позиции

140
00:09:25,293 --> 00:09:29,960
включенных битов, а затем выполнить XOR их вместе.

141
00:09:29,960 --> 00:09:33,960
Чтобы сделать это в Python, позвольте мне сначала импортировать пару полезных функций.

142
00:09:33,960 --> 00:09:36,462
Таким образом, мы можем вызвать функцию уменьшения() для

143
00:09:36,462 --> 00:09:39,140
этого списка и использовать функцию XOR, чтобы уменьшить его.

144
00:09:39,140 --> 00:09:44,840
По сути, это проедает весь список, принимая по пути XOR.

145
00:09:44,840 --> 00:09:48,446
Если хотите, вы можете явно записать эту функцию

146
00:09:48,446 --> 00:09:52,200
XOR без необходимости импортировать ее откуда-либо.

147
00:09:52,200 --> 00:09:57,279
Итак, на данный момент похоже, что если мы сделаем это с нашим случайным

148
00:09:57,279 --> 00:10:02,080
блоком из 16 бит, он вернет 9, что имеет двоичное представление 1001.

149
00:10:02,080 --> 00:10:05,540
Мы не будем этого делать здесь, но вы можете написать функцию, в которой

150
00:10:05,540 --> 00:10:09,237
отправитель использует это двоичное представление для установки четырех битов

151
00:10:09,237 --> 00:10:13,076
четности по мере необходимости, в конечном итоге переводя этот блок в состояние,

152
00:10:13,076 --> 00:10:17,200
при котором выполнение этой строки кода для полного списка бит возвращает результат. 0.

153
00:10:17,200 --> 00:10:20,200
Это будет считаться хорошо подготовленным блоком.

154
00:10:20,200 --> 00:10:25,194
Что круто, так это то, что если мы переключим любой из битов в этом списке, имитируя

155
00:10:25,194 --> 00:10:30,188
случайную ошибку из-за шума, то если вы запустите ту же строку кода, она выведет эту

156
00:10:30,188 --> 00:10:30,600
ошибку.

157
00:10:30,600 --> 00:10:31,920
Разве это не аккуратно?

158
00:10:31,920 --> 00:10:37,568
Вы можете получить этот блок из ниоткуда, запустить к нему эту единственную

159
00:10:37,568 --> 00:10:42,920
строку, и он автоматически выдаст позицию ошибки или 0, если ее не было.

160
00:10:42,920 --> 00:10:45,520
И в 16 размере здесь нет ничего особенного.

161
00:10:45,520 --> 00:10:52,280
Та же самая строка кода будет работать, если у вас есть список, скажем, из 256 бит.

162
00:10:52,280 --> 00:10:56,509
Излишне говорить, что здесь нужно написать больше кода, например, выполнить

163
00:10:56,509 --> 00:11:00,627
мета-проверку четности для обнаружения 2-битных ошибок, но идея состоит в

164
00:11:00,627 --> 00:11:05,080
том, что почти вся основная логика нашей схемы сводится к одному сокращению XOR.

165
00:11:05,080 --> 00:11:08,722
Теперь, в зависимости от вашего опыта работы с двоичными файлами, операциями

166
00:11:08,722 --> 00:11:12,176
XOR и программным обеспечением в целом, вы можете найти эту точку зрения

167
00:11:12,176 --> 00:11:15,724
либо немного запутанной, либо настолько более элегантной и простой, что вы

168
00:11:15,724 --> 00:11:19,320
задаетесь вопросом, почему мы просто не начали с нее с самого начала. -идти.

169
00:11:19,320 --> 00:11:23,388
Грубо говоря, о перспективе множественной проверки четности легче думать при прямой

170
00:11:23,388 --> 00:11:27,456
реализации кодов Хэмминга в аппаратном обеспечении, а о перспективе XOR легче всего

171
00:11:27,456 --> 00:11:31,380
думать, когда она выполняется в программном обеспечении, на более высоком уровне.

172
00:11:31,380 --> 00:11:36,188
Первый проще всего сделать вручную, и я думаю, что он лучше справляется с задачей,

173
00:11:36,188 --> 00:11:41,055
прививая основную интуицию, лежащую в основе всего этого, а именно, что информация,

174
00:11:41,055 --> 00:11:45,863
необходимая для обнаружения единственной ошибки, связана с журналом размера блока.

175
00:11:45,863 --> 00:11:51,020
или, другими словами, он увеличивается по одному биту при увеличении размера блока вдвое.

176
00:11:51,020 --> 00:11:53,582
Важным фактом здесь является то, что эта информация

177
00:11:53,582 --> 00:11:56,440
напрямую соответствует тому, какая избыточность нам нужна.

178
00:11:56,440 --> 00:12:00,045
Именно это на самом деле противоречит коленному рефлексу большинства людей, когда

179
00:12:00,045 --> 00:12:03,738
они впервые задумываются о том, чтобы сделать сообщение устойчивым к ошибкам, когда

180
00:12:03,738 --> 00:12:07,520
обычно копирование всего сообщения является первым инстинктом, который приходит на ум.

181
00:12:07,520 --> 00:12:11,283
И, кстати, есть совершенно другой способ представления кодов

182
00:12:11,283 --> 00:12:14,800
Хэмминга: вы умножаете сообщение на одну большую матрицу.

183
00:12:14,800 --> 00:12:18,088
Это в некоторой степени приятно, потому что соотносит его с

184
00:12:18,088 --> 00:12:21,432
более широким семейством линейных кодов, но я думаю, что это

185
00:12:21,432 --> 00:12:25,160
почти не дает понимания того, откуда он взялся и как масштабируется.

186
00:12:25,160 --> 00:12:28,599
Говоря о масштабировании, вы можете заметить, что эффективность

187
00:12:28,599 --> 00:12:32,200
этой схемы становится только выше по мере увеличения размера блока.

188
00:12:32,200 --> 00:12:37,539
Например, мы увидели, что при 256 битах вы используете только 3% этого

189
00:12:37,539 --> 00:12:43,480
пространства для избыточности, и с этого момента ситуация становится все лучше.

190
00:12:43,480 --> 00:12:46,387
По мере того как количество битов четности увеличивается

191
00:12:46,387 --> 00:12:49,040
один за другим, размер блока продолжает удваиваться.

192
00:12:49,040 --> 00:12:52,697
А если довести это до крайности, то у вас может получиться блок,

193
00:12:52,697 --> 00:12:56,636
скажем, в миллион битов, в котором вы буквально будете разыгрывать 20

194
00:12:56,636 --> 00:13:00,800
вопросов с проверками на четность, и он использует только 21 бит четности.

195
00:13:00,800 --> 00:13:04,773
И если вы сделаете шаг назад и подумаете о том, чтобы просмотреть миллион

196
00:13:04,773 --> 00:13:08,640
битов и найти единственную ошибку, это действительно покажется безумием.

197
00:13:08,640 --> 00:13:13,414
Проблема, конечно, в том, что при увеличении блока вероятность увидеть более одного

198
00:13:13,414 --> 00:13:18,360
или двух битовых ошибок возрастает, а коды Хэмминга ничего сверх этого не обрабатывают.

199
00:13:18,360 --> 00:13:22,468
Поэтому на практике вам нужно найти правильный размер, чтобы вероятность

200
00:13:22,468 --> 00:13:26,520
слишком большого количества битовых переворотов не была слишком высокой.

201
00:13:26,520 --> 00:13:31,130
Кроме того, на практике ошибки, как правило, возникают небольшими порциями, что

202
00:13:31,130 --> 00:13:35,625
может полностью разрушить один блок, поэтому одна из распространенных тактик,

203
00:13:35,625 --> 00:13:40,178
помогающих распределить пакет ошибок по множеству разных блоков, заключается в

204
00:13:40,178 --> 00:13:44,903
чередовании этих блоков, вот так, прежде чем они будут обработаны. отправлено или

205
00:13:44,903 --> 00:13:45,480
сохранено.

206
00:13:45,480 --> 00:13:48,880
Опять же, многое из этого становится совершенно спорным из-за более

207
00:13:48,880 --> 00:13:52,430
современных кодов, таких как гораздо более часто используемый алгоритм

208
00:13:52,430 --> 00:13:55,930
Рида-Соломона, который особенно хорошо обрабатывает пакетные ошибки и

209
00:13:55,930 --> 00:13:59,580
может быть настроен на устойчивость к большему количеству ошибок на блок.

210
00:13:59,580 --> 00:14:03,000
Но это тема для другого раза.

211
00:14:03,000 --> 00:14:06,752
В своей книге «Искусство заниматься наукой и инженерией» Хэмминг удивительно

212
00:14:06,752 --> 00:14:10,700
откровенно рассказывает о том, насколько запутанным было его открытие этого кода.

213
00:14:10,700 --> 00:14:14,746
Сначала он испробовал всевозможные схемы, включающие организацию

214
00:14:14,746 --> 00:14:18,420
битов в части многомерной решетки и подобные странные вещи.

215
00:14:18,420 --> 00:14:21,977
Идея о том, что можно заставить проверки четности сговориться таким

216
00:14:21,977 --> 00:14:25,587
образом, чтобы определить положение ошибки, пришла к Хэммингу только

217
00:14:25,587 --> 00:14:29,145
тогда, когда он отступил после множества других анализов и спросил:

218
00:14:29,145 --> 00:14:32,860
«Хорошо, что я могу наиболее эффективно? » возможно, речь идет об этом?

219
00:14:32,860 --> 00:14:37,297
Он также откровенно говорил о том, насколько важно, чтобы проверки паритета уже были у

220
00:14:37,297 --> 00:14:41,632
него на уме, что в 1940-х годах было бы гораздо менее распространенным явлением, чем

221
00:14:41,632 --> 00:14:42,040
сегодня.

222
00:14:42,040 --> 00:14:45,914
В этой книге он примерно полдюжины раз ссылается на

223
00:14:45,914 --> 00:14:49,640
цитату Луи Пастера: удача любит подготовленный ум.

224
00:14:49,640 --> 00:14:52,722
Оглядываясь назад, умные идеи часто кажутся обманчиво

225
00:14:52,722 --> 00:14:55,120
простыми, из-за чего их легко недооценить.

226
00:14:55,120 --> 00:14:58,470
Сейчас я искренне надеюсь, что коды Хэмминга или, по крайней мере,

227
00:14:58,470 --> 00:15:01,820
возможность существования таких кодов кажутся вам почти очевидными.

228
00:15:01,820 --> 00:15:05,031
Но не стоит обманывать себя, думая, что они на самом

229
00:15:05,031 --> 00:15:08,000
деле очевидны, потому что это определенно не так.

230
00:15:08,000 --> 00:15:11,971
Одна из причин того, что умные идеи кажутся обманчиво простыми, заключается в том,

231
00:15:11,971 --> 00:15:15,894
что мы всегда видим только конечный результат, убирая то, что было беспорядочным,

232
00:15:15,894 --> 00:15:19,913
никогда не упоминая обо всех неправильных поворотах, преуменьшая, насколько огромно

233
00:15:19,913 --> 00:15:23,980
пространство исследуемых возможностей в начале проблемы. процесс решения и все такое.

234
00:15:23,980 --> 00:15:25,280
Но это правда в целом.

235
00:15:25,280 --> 00:15:28,016
Я думаю, что для некоторых особых изобретений существует

236
00:15:28,016 --> 00:15:31,040
вторая, более глубокая причина, по которой мы их недооцениваем.

237
00:15:31,040 --> 00:15:33,636
Представление об информации в терминах битов по-настоящему

238
00:15:33,636 --> 00:15:36,364
сформировалось в полноценную теорию только к 1948 году, когда

239
00:15:36,364 --> 00:15:39,400
появилась основополагающая статья Клода Шеннона по теории информации.

240
00:15:39,400 --> 00:15:43,440
По сути, это совпало с разработкой Хэммингом своего алгоритма.

241
00:15:43,440 --> 00:15:47,117
Это была та же основополагающая статья, которая в определенном смысле показала,

242
00:15:47,117 --> 00:15:50,426
что эффективное исправление ошибок всегда возможно, независимо от того,

243
00:15:50,426 --> 00:15:53,920
насколько высока вероятность переворота битов, по крайней мере теоретически.

244
00:15:53,920 --> 00:15:58,015
Шеннон и Хэмминг, кстати, делили офис в Bell Labs, несмотря на то, что

245
00:15:58,015 --> 00:16:02,400
работали над совершенно разными вещами, что вряд ли здесь кажется случайным.

246
00:16:02,400 --> 00:16:05,871
Перенесемся на несколько десятилетий вперед, и в наши дни многие

247
00:16:05,871 --> 00:16:09,448
из нас настолько погружены в размышления о битах и информации, что

248
00:16:09,448 --> 00:16:13,080
легко упустить из виду, насколько особенным был этот образ мышления.

249
00:16:13,080 --> 00:16:14,623
По иронии судьбы, идеи, которые наиболее глубоко формируют

250
00:16:14,623 --> 00:16:16,140
образ мышления будущего поколения, в конечном итоге будут

251
00:16:16,140 --> 00:16:17,920
казаться этому будущему поколению проще, чем они есть на самом деле.

