1
00:00:00,000 --> 00:00:02,560
Я предполагаю, что все здесь пришли из первой части.

2
00:00:03,060 --> 00:00:06,098
Мы говорили о кодах Хэмминга, способе создания блока данных, 

3
00:00:06,098 --> 00:00:08,787
в котором большинство битов несут значимое сообщение, 

4
00:00:08,787 --> 00:00:12,473
а несколько других действуют как своего рода избыточность, таким образом, 

5
00:00:12,473 --> 00:00:16,607
что если какой-либо бит переворачивается, либо сообщение бит или бит избыточности, 

6
00:00:16,607 --> 00:00:19,247
что-либо в этом блоке, получатель сможет определить, 

7
00:00:19,247 --> 00:00:21,240
что произошла ошибка и как ее исправить.

8
00:00:21,880 --> 00:00:24,007
Основная идея, представленная там, заключалась в том, 

9
00:00:24,007 --> 00:00:27,160
как использовать несколько проверок четности для двоичного поиска пути к ошибке.

10
00:00:28,980 --> 00:00:32,090
Целью этого видео было сделать коды Хэмминга максимально 

11
00:00:32,090 --> 00:00:34,600
удобными и доступными для повторного открытия.

12
00:00:35,180 --> 00:00:37,581
Но когда вы начинаете думать о реальной реализации этого, 

13
00:00:37,581 --> 00:00:39,651
будь то в программном или аппаратном обеспечении, 

14
00:00:39,651 --> 00:00:41,679
эта структура может на самом деле недооценивать, 

15
00:00:41,679 --> 00:00:43,460
насколько элегантны эти коды на самом деле.

16
00:00:43,920 --> 00:00:46,629
Вы можете подумать, что вам нужно написать алгоритм, 

17
00:00:46,629 --> 00:00:49,850
который отслеживает все возможные места ошибок и сокращает эту 

18
00:00:49,850 --> 00:00:53,480
группу пополам при каждой проверке, но на самом деле это намного проще.

19
00:00:53,940 --> 00:00:56,522
Если вы зачитаете ответы на четыре проверки четности, 

20
00:00:56,522 --> 00:00:59,823
которые мы проводили в последнем видео (все они представляют собой 1 

21
00:00:59,823 --> 00:01:04,080
и 0 вместо «да» и «нет»), то вы буквально определите положение ошибки в двоичном формате.

22
00:01:04,780 --> 00:01:08,269
Например, число 7 в двоичном формате выглядит как 0111, 

23
00:01:08,269 --> 00:01:11,260
что, по сути, означает, что это 4 плюс 2 плюс 1.

24
00:01:12,540 --> 00:01:17,106
И обратите внимание, где находится позиция 7: она влияет и на первую 

25
00:01:17,106 --> 00:01:21,740
из наших групп четности, и на вторую, и на третью, но не на последнюю.

26
00:01:22,220 --> 00:01:24,928
Таким образом, чтение результатов этих четырех проверок 

27
00:01:24,928 --> 00:01:27,540
снизу вверх действительно определяет положение ошибки.

28
00:01:28,320 --> 00:01:31,550
В примере 7 нет ничего особенного, в целом он работает, 

29
00:01:31,550 --> 00:01:35,820
и это делает логику аппаратной реализации всей схемы поразительно простой.

30
00:01:37,240 --> 00:01:40,621
Теперь, если вы хотите понять, почему происходит это волшебство, 

31
00:01:40,621 --> 00:01:44,106
возьмите эти 16 индексных меток для наших позиций, но вместо того, 

32
00:01:44,106 --> 00:01:46,811
чтобы записывать их в десятичной системе счисления, 

33
00:01:46,811 --> 00:01:49,880
давайте запишем их все в двоичном формате, от 0000 до 1111.

34
00:01:50,559 --> 00:01:54,778
Размещая эти двоичные метки обратно в коробки, позвольте мне подчеркнуть, 

35
00:01:54,778 --> 00:01:57,800
что они отличаются от фактически отправляемых данных.

36
00:01:58,320 --> 00:02:01,788
Это не что иное, как концептуальный ярлык, который поможет вам и мне понять, 

37
00:02:01,788 --> 00:02:03,500
откуда взялись четыре группы паритета.

38
00:02:04,140 --> 00:02:06,195
Элегантность того, что все, на что мы смотрим, 

39
00:02:06,195 --> 00:02:09,037
описывается в двоичном формате, возможно, подрывается путаницей, 

40
00:02:09,037 --> 00:02:12,360
связанной с тем, что все, на что мы смотрим, описывается в двоичном формате.

41
00:02:13,020 --> 00:02:14,120
Однако оно того стоит.

42
00:02:14,800 --> 00:02:19,440
Сосредоточьте свое внимание только на последнем бите всех этих меток, 

43
00:02:19,440 --> 00:02:23,220
а затем выделите позиции, где этот последний бит равен 1.

44
00:02:24,240 --> 00:02:27,891
То, что мы получаем, — это первая из наших четырех групп четности, 

45
00:02:27,891 --> 00:02:32,088
что означает, что вы можете интерпретировать эту первую проверку как вопрос: 

46
00:02:32,088 --> 00:02:35,740
«Эй, если есть ошибка, последний бит в позиции этой ошибки равен 1?

47
00:02:38,200 --> 00:02:42,811
» Аналогично, если вы сосредоточитесь на предпоследнем бите и выделите все позиции, 

48
00:02:42,811 --> 00:02:46,160
где это 1, вы получите вторую группу четности из нашей схемы.

49
00:02:46,740 --> 00:02:50,289
Другими словами, вторая проверка спрашивает: «Эй, еще раз, 

50
00:02:50,289 --> 00:02:54,500
если есть ошибка, является ли предпоследний бит этой позиции равным 1?

51
00:02:55,760 --> 00:02:56,900
» И так далее.

52
00:02:57,220 --> 00:03:00,406
Третья проверка четности охватывает каждую позицию, 

53
00:03:00,406 --> 00:03:04,389
у которой включен третий до последнего бит, а последняя проверка 

54
00:03:04,389 --> 00:03:08,740
охватывает последние восемь позиций, те, у которых старший бит равен 1.

55
00:03:09,740 --> 00:03:13,652
Все, что мы делали ранее, аналогично ответу на эти четыре вопроса, 

56
00:03:13,652 --> 00:03:17,740
что, в свою очередь, равнозначно написанию позиции в двоичном формате.

57
00:03:19,620 --> 00:03:21,480
Надеюсь, это прояснит две вещи.

58
00:03:22,040 --> 00:03:26,460
Во-первых, как систематически обобщать размеры блоков, превышающие степени двойки.

59
00:03:26,960 --> 00:03:29,938
Если для описания каждой позиции требуется больше битов, 

60
00:03:29,938 --> 00:03:33,178
например шесть битов для описания 64 точек, то каждый из этих 

61
00:03:33,178 --> 00:03:36,680
битов дает вам одну из групп четности, которую нам нужно проверить.

62
00:03:38,400 --> 00:03:41,448
Те из вас, кто смотрел шахматную головоломку, которую я решал с Мэттом Паркером, 

63
00:03:41,448 --> 00:03:43,180
возможно, найдут все это чрезвычайно знакомым.

64
00:03:43,660 --> 00:03:46,093
Это та же основная логика, но она решает другую 

65
00:03:46,093 --> 00:03:48,780
задачу и применяется к шахматной доске с 64 клетками.

66
00:03:49,880 --> 00:03:53,447
Второе, что, я надеюсь, теперь проясняет, — почему наши биты четности 

67
00:03:53,447 --> 00:03:57,320
находятся в позициях, соответствующих степеням двойки, например 1, 2, 4 и 8.

68
00:03:58,000 --> 00:04:03,000
Это позиции, в двоичном представлении которых включен только один бит.

69
00:04:03,600 --> 00:04:06,634
Это означает, что каждый из этих битов четности находится 

70
00:04:06,634 --> 00:04:09,460
внутри одной и только одной из четырех групп четности.

71
00:04:12,040 --> 00:04:15,690
Вы также можете увидеть это на более крупных примерах, где независимо от того, 

72
00:04:15,690 --> 00:04:19,339
насколько вы велики, каждый бит четности удобно касается только одной из групп.

73
00:04:25,600 --> 00:04:29,985
Как только вы поймете, что эти проверки четности, которым мы уделили так много времени, 

74
00:04:29,985 --> 00:04:34,420
являются не чем иным, как умным способом определить положение ошибки в двоичном формате, 

75
00:04:34,420 --> 00:04:38,755
тогда мы сможем установить связь с другим способом мышления о хэмминге. коды, которые, 

76
00:04:38,755 --> 00:04:43,240
возможно, намного проще и элегантнее и которые можно записать с помощью одной строки кода.

77
00:04:43,660 --> 00:04:45,500
Он основан на функции XOR.

78
00:04:46,940 --> 00:04:50,220
XOR, для тех из вас, кто не знает, означает «исключающее или».

79
00:04:50,780 --> 00:04:54,813
Когда вы выполняете операцию XOR двух битов, она возвращает 1, 

80
00:04:54,813 --> 00:04:59,360
если один из этих битов включен, но не если оба включены или выключены.

81
00:05:00,100 --> 00:05:02,980
Другими словами, это четность этих двух битов.

82
00:05:03,540 --> 00:05:06,760
Как математик, я предпочитаю думать об этом как о моде сложения 2.

83
00:05:07,360 --> 00:05:10,400
Мы также обычно говорим о XOR двух разных битовых строк, 

84
00:05:10,400 --> 00:05:13,440
который, по сути, выполняет это компонент за компонентом.

85
00:05:13,680 --> 00:05:15,720
Это как дополнение, но куда не понесешь.

86
00:05:16,500 --> 00:05:19,327
Опять же, более склонные к математике люди могут предпочесть 

87
00:05:19,327 --> 00:05:22,480
думать об этом как о добавлении двух векторов и уменьшении модуля 2.

88
00:05:23,500 --> 00:05:26,733
Если вы прямо сейчас откроете какой-нибудь Python и примените 

89
00:05:26,733 --> 00:05:29,497
операцию курсора между двумя целыми числами, это то, 

90
00:05:29,497 --> 00:05:32,940
что он делает, но к битовым представлениям этих чисел под капотом.

91
00:05:34,960 --> 00:05:39,189
Ключевым моментом для нас с вами является то, что выполнение XOR множества 

92
00:05:39,189 --> 00:05:43,192
различных битовых строк фактически является способом вычислить пародии 

93
00:05:43,192 --> 00:05:47,140
на кучу отдельных групп, как это происходит со столбцами, одним махом.

94
00:05:51,260 --> 00:05:55,192
Это дает нам довольно привлекательный способ представить множественные проверки 

95
00:05:55,192 --> 00:05:58,780
четности нашего алгоритма кода Хэмминга как объединенные в одну операцию.

96
00:05:59,479 --> 00:06:02,180
Хотя на первый взгляд все выглядит совсем иначе.

97
00:06:02,820 --> 00:06:07,955
Специально запишите 16 позиций в двоичном формате, как мы делали раньше, 

98
00:06:07,955 --> 00:06:12,316
а теперь выделите позиции, где бит сообщения установлен на 1, 

99
00:06:12,316 --> 00:06:17,100
а затем соберите эти позиции в один большой столбец и выполните XOR.

100
00:06:19,260 --> 00:06:22,680
Вы, вероятно, можете догадаться, что 4 бита, находящиеся внизу, 

101
00:06:22,680 --> 00:06:26,634
в результате совпадают с 4 проверками четности, которые мы знаем и любим, 

102
00:06:26,634 --> 00:06:29,200
но найдите время, чтобы подумать, почему именно.

103
00:06:32,220 --> 00:06:35,759
Например, в этом последнем столбце подсчитываются все позиции, 

104
00:06:35,759 --> 00:06:40,366
последний бит которых равен 1, но мы уже ограничены только выделенными позициями, 

105
00:06:40,366 --> 00:06:44,861
поэтому он эффективно подсчитывает, сколько выделенных позиций пришло из первой 

106
00:06:44,861 --> 00:06:45,760
группы четности.

107
00:06:46,240 --> 00:06:46,800
Имеет ли это смысл?

108
00:06:49,080 --> 00:06:54,507
Аналогично, в следующем столбце подсчитывается количество позиций во второй группе 

109
00:06:54,507 --> 00:07:00,000
четности, позиций, предпоследний бит которых равен 1, которые также выделены и т. д.

110
00:07:00,260 --> 00:07:03,960
На самом деле это всего лишь небольшой сдвиг во взглядах на то же самое, что мы делаем.

111
00:07:07,760 --> 00:07:09,600
Итак, вы знаете, куда это пойдет дальше.

112
00:07:10,000 --> 00:07:13,796
Отправитель отвечает за переключение некоторых специальных битов четности, 

113
00:07:13,796 --> 00:07:15,720
чтобы убедиться, что сумма равна 0000.

114
00:07:15,720 --> 00:07:19,780
Теперь, когда у нас это получилось, это дает нам действительно 

115
00:07:19,780 --> 00:07:24,034
хороший способ задуматься о том, почему эти четыре результирующих 

116
00:07:24,034 --> 00:07:27,580
бита внизу непосредственно определяют положение ошибки.

117
00:07:28,460 --> 00:07:31,860
Допустим, какой-то бит в этом блоке переключается с 0 на 1.

118
00:07:32,600 --> 00:07:38,841
Это означает, что позиция этого бита теперь будет включена в общее исключающее ИЛИ, 

119
00:07:38,841 --> 00:07:43,820
что изменит сумму с 0 на новое включенное значение, позицию ошибки.

120
00:07:44,460 --> 00:07:49,360
Чуть менее очевидно то же самое, если произошла ошибка, из-за которой 1 меняется на 0.

121
00:07:50,180 --> 00:07:54,100
Видите ли, если вы складываете битовую строку дважды, это то же самое, 

122
00:07:54,100 --> 00:07:57,580
что ее вообще нет, потому что в этом мире 1 плюс 1 равняется 0.

123
00:07:57,580 --> 00:08:02,902
Таким образом, добавление копии этой позиции к общей сумме имеет тот же эффект, 

124
00:08:02,902 --> 00:08:04,300
что и ее перемещение.

125
00:08:05,160 --> 00:08:07,901
И этот эффект, опять же, заключается в том, что 

126
00:08:07,901 --> 00:08:10,700
общий результат внизу указывает положение ошибки.

127
00:08:13,039 --> 00:08:15,298
Чтобы проиллюстрировать, насколько это элегантно, 

128
00:08:15,298 --> 00:08:17,465
позвольте мне показать одну строку кода Python, 

129
00:08:17,465 --> 00:08:21,440
на которую я ссылался ранее, которая захватывает почти всю логику на стороне получателя.

130
00:08:22,080 --> 00:08:27,015
Мы начнем с создания случайного массива из 16 единиц и нулей для имитации блока данных, 

131
00:08:27,015 --> 00:08:30,549
и я дам ему биты имени, но, конечно, на практике это будет то, 

132
00:08:30,549 --> 00:08:33,858
что мы получаем от отправителя, и вместо будучи случайным, 

133
00:08:33,858 --> 00:08:37,000
он будет нести 11 бит данных вместе с 5 битами четности.

134
00:08:37,000 --> 00:08:41,883
Если я вызываю функцию enumerateBits, она объединяет каждый из 

135
00:08:41,883 --> 00:08:47,000
этих битов с соответствующим индексом, в данном случае от 0 до 15.

136
00:08:48,180 --> 00:08:52,930
Итак, если мы затем создадим список, который будет циклически перебирать все эти пары, 

137
00:08:52,930 --> 00:08:57,462
пары, которые выглядят как i, а затем мы вытащим только значение i, только индекс, 

138
00:08:57,462 --> 00:09:01,340
ну, это не так уж и интересно, мы просто вернем эти индексы от 0 до 15.

139
00:09:01,680 --> 00:09:05,220
Но если мы добавим условие делать это только в том случае, 

140
00:09:05,220 --> 00:09:08,219
если бит, то есть, если этот бит равен 1, а не 0, 

141
00:09:08,219 --> 00:09:12,660
то тогда будут выбраны только те позиции, где включен соответствующий бит.

142
00:09:13,380 --> 00:09:20,360
В данном случае это выглядит как позиции 0, 4, 6, 9 и т. д.

143
00:09:20,720 --> 00:09:25,132
Мы хотим собрать вместе все эти позиции, позиции включенных битов, 

144
00:09:25,132 --> 00:09:27,240
а затем выполнить XOR их вместе.

145
00:09:29,180 --> 00:09:33,220
Чтобы сделать это в Python, позвольте мне сначала импортировать пару полезных функций.

146
00:09:33,900 --> 00:09:36,218
Таким образом, мы можем вызвать функцию уменьшения() для 

147
00:09:36,218 --> 00:09:38,700
этого списка и использовать функцию XOR, чтобы уменьшить его.

148
00:09:39,100 --> 00:09:42,680
По сути, это проедает весь список, принимая по пути XOR.

149
00:09:44,800 --> 00:09:47,073
Если хотите, вы можете явно записать эту функцию 

150
00:09:47,073 --> 00:09:49,440
XOR без необходимости импортировать ее откуда-либо.

151
00:09:51,940 --> 00:09:56,741
Итак, на данный момент похоже, что если мы сделаем это с нашим случайным 

152
00:09:56,741 --> 00:10:01,280
блоком из 16 бит, он вернет 9, что имеет двоичное представление 1001.

153
00:10:01,980 --> 00:10:04,642
Мы не будем этого делать здесь, но вы можете написать функцию, 

154
00:10:04,642 --> 00:10:08,107
в которой отправитель использует это двоичное представление для установки четырех 

155
00:10:08,107 --> 00:10:11,783
битов четности по мере необходимости, в конечном итоге переводя этот блок в состояние, 

156
00:10:11,783 --> 00:10:15,460
при котором выполнение этой строки кода для полного списка бит возвращает результат. 0.

157
00:10:16,080 --> 00:10:20,100
Это будет считаться хорошо подготовленным блоком.

158
00:10:20,100 --> 00:10:24,445
Что круто, так это то, что если мы переключим любой из битов в этом списке, 

159
00:10:24,445 --> 00:10:28,904
имитируя случайную ошибку из-за шума, то если вы запустите ту же строку кода, 

160
00:10:28,904 --> 00:10:30,220
она выведет эту ошибку.

161
00:10:30,960 --> 00:10:31,520
Разве это не аккуратно?

162
00:10:31,820 --> 00:10:37,064
Вы можете получить этот блок из ниоткуда, запустить к нему эту единственную строку, 

163
00:10:37,064 --> 00:10:41,060
и он автоматически выдаст позицию ошибки или 0, если ее не было.

164
00:10:42,500 --> 00:10:44,840
И в 16 размере здесь нет ничего особенного.

165
00:10:44,840 --> 00:10:49,860
Та же самая строка кода будет работать, если у вас есть список, скажем, из 256 бит.

166
00:10:51,880 --> 00:10:55,289
Излишне говорить, что здесь нужно написать больше кода, например, 

167
00:10:55,289 --> 00:10:58,698
выполнить мета-проверку четности для обнаружения 2-битных ошибок, 

168
00:10:58,698 --> 00:11:02,623
но идея состоит в том, что почти вся основная логика нашей схемы сводится к 

169
00:11:02,623 --> 00:11:03,760
одному сокращению XOR.

170
00:11:06,120 --> 00:11:08,817
Теперь, в зависимости от вашего опыта работы с двоичными файлами, 

171
00:11:08,817 --> 00:11:10,901
операциями XOR и программным обеспечением в целом, 

172
00:11:10,901 --> 00:11:13,271
вы можете найти эту точку зрения либо немного запутанной, 

173
00:11:13,271 --> 00:11:16,131
либо настолько более элегантной и простой, что вы задаетесь вопросом, 

174
00:11:16,131 --> 00:11:18,420
почему мы просто не начали с нее с самого начала. -идти.

175
00:11:19,140 --> 00:11:22,972
Грубо говоря, о перспективе множественной проверки четности легче думать при прямой 

176
00:11:22,972 --> 00:11:25,344
реализации кодов Хэмминга в аппаратном обеспечении, 

177
00:11:25,344 --> 00:11:29,405
а о перспективе XOR легче всего думать, когда она выполняется в программном обеспечении, 

178
00:11:29,405 --> 00:11:30,500
на более высоком уровне.

179
00:11:31,360 --> 00:11:35,923
Первый проще всего сделать вручную, и я думаю, что он лучше справляется с задачей, 

180
00:11:35,923 --> 00:11:40,542
прививая основную интуицию, лежащую в основе всего этого, а именно, что информация, 

181
00:11:40,542 --> 00:11:45,106
необходимая для обнаружения единственной ошибки, связана с журналом размера блока. 

182
00:11:45,106 --> 00:11:50,000
или, другими словами, он увеличивается по одному биту при увеличении размера блока вдвое.

183
00:11:51,020 --> 00:11:54,731
Важным фактом здесь является то, что эта информация напрямую соответствует тому, 

184
00:11:54,731 --> 00:11:56,060
какая избыточность нам нужна.

185
00:11:56,660 --> 00:11:59,639
Именно это на самом деле противоречит коленному рефлексу большинства людей, 

186
00:11:59,639 --> 00:12:02,933
когда они впервые задумываются о том, чтобы сделать сообщение устойчивым к ошибкам, 

187
00:12:02,933 --> 00:12:05,638
когда обычно копирование всего сообщения является первым инстинктом, 

188
00:12:05,638 --> 00:12:06,540
который приходит на ум.

189
00:12:07,500 --> 00:12:11,411
И, кстати, есть совершенно другой способ представления кодов Хэмминга: 

190
00:12:11,411 --> 00:12:14,000
вы умножаете сообщение на одну большую матрицу.

191
00:12:14,670 --> 00:12:17,333
Это в некоторой степени приятно, потому что соотносит его с 

192
00:12:17,333 --> 00:12:19,686
более широким семейством линейных кодов, но я думаю, 

193
00:12:19,686 --> 00:12:23,060
что это почти не дает понимания того, откуда он взялся и как масштабируется.

194
00:12:25,200 --> 00:12:28,111
Говоря о масштабировании, вы можете заметить, что эффективность 

195
00:12:28,111 --> 00:12:31,160
этой схемы становится только выше по мере увеличения размера блока.

196
00:12:35,000 --> 00:12:38,625
Например, мы увидели, что при 256 битах вы используете только 3% этого 

197
00:12:38,625 --> 00:12:42,660
пространства для избыточности, и с этого момента ситуация становится все лучше.

198
00:12:43,300 --> 00:12:46,005
По мере того как количество битов четности увеличивается один за другим, 

199
00:12:46,005 --> 00:12:47,340
размер блока продолжает удваиваться.

200
00:12:49,000 --> 00:12:52,427
А если довести это до крайности, то у вас может получиться блок, 

201
00:12:52,427 --> 00:12:56,118
скажем, в миллион битов, в котором вы буквально будете разыгрывать 20 

202
00:12:56,118 --> 00:13:00,020
вопросов с проверками на четность, и он использует только 21 бит четности.

203
00:13:00,740 --> 00:13:02,817
И если вы сделаете шаг назад и подумаете о том, 

204
00:13:02,817 --> 00:13:05,458
чтобы просмотреть миллион битов и найти единственную ошибку, 

205
00:13:05,458 --> 00:13:07,060
это действительно покажется безумием.

206
00:13:08,199 --> 00:13:12,847
Проблема, конечно, в том, что при увеличении блока вероятность увидеть более одного 

207
00:13:12,847 --> 00:13:17,660
или двух битовых ошибок возрастает, а коды Хэмминга ничего сверх этого не обрабатывают.

208
00:13:18,320 --> 00:13:20,588
Поэтому на практике вам нужно найти правильный размер, 

209
00:13:20,588 --> 00:13:24,300
чтобы вероятность слишком большого количества битовых переворотов не была слишком высокой.

210
00:13:26,600 --> 00:13:29,921
Кроме того, на практике ошибки, как правило, возникают небольшими порциями, 

211
00:13:29,921 --> 00:13:33,505
что может полностью разрушить один блок, поэтому одна из распространенных тактик, 

212
00:13:33,505 --> 00:13:36,346
помогающих распределить пакет ошибок по множеству разных блоков, 

213
00:13:36,346 --> 00:13:39,887
заключается в чередовании этих блоков, вот так, прежде чем они будут обработаны. 

214
00:13:39,887 --> 00:13:40,980
отправлено или сохранено.

215
00:13:45,580 --> 00:13:49,664
Опять же, многое из этого становится совершенно спорным из-за более современных кодов, 

216
00:13:49,664 --> 00:13:52,810
таких как гораздо более часто используемый алгоритм Рида-Соломона, 

217
00:13:52,810 --> 00:13:55,909
который особенно хорошо обрабатывает пакетные ошибки и может быть 

218
00:13:55,909 --> 00:13:58,820
настроен на устойчивость к большему количеству ошибок на блок.

219
00:13:59,360 --> 00:14:01,340
Но это тема для другого раза.

220
00:14:02,500 --> 00:14:06,125
В своей книге «Искусство заниматься наукой и инженерией» Хэмминг удивительно 

221
00:14:06,125 --> 00:14:09,940
откровенно рассказывает о том, насколько запутанным было его открытие этого кода.

222
00:14:10,620 --> 00:14:14,373
Сначала он испробовал всевозможные схемы, включающие организацию 

223
00:14:14,373 --> 00:14:17,780
битов в части многомерной решетки и подобные странные вещи.

224
00:14:18,300 --> 00:14:21,988
Идея о том, что можно заставить проверки четности сговориться таким образом, 

225
00:14:21,988 --> 00:14:25,197
чтобы определить положение ошибки, пришла к Хэммингу только тогда, 

226
00:14:25,197 --> 00:14:28,550
когда он отступил после множества других анализов и спросил: «Хорошо, 

227
00:14:28,550 --> 00:14:31,520
что я могу наиболее эффективно? » возможно, речь идет об этом?

228
00:14:32,620 --> 00:14:35,104
Он также откровенно говорил о том, насколько важно, 

229
00:14:35,104 --> 00:14:37,397
чтобы проверки паритета уже были у него на уме, 

230
00:14:37,397 --> 00:14:41,220
что в 1940-х годах было бы гораздо менее распространенным явлением, чем сегодня.

231
00:14:41,920 --> 00:14:46,367
В этой книге он примерно полдюжины раз ссылается на цитату Луи Пастера: 

232
00:14:46,367 --> 00:14:48,220
удача любит подготовленный ум.

233
00:14:49,320 --> 00:14:52,640
Оглядываясь назад, умные идеи часто кажутся обманчиво простыми, 

234
00:14:52,640 --> 00:14:54,300
из-за чего их легко недооценить.

235
00:14:54,960 --> 00:14:58,130
Сейчас я искренне надеюсь, что коды Хэмминга или, по крайней мере, 

236
00:14:58,130 --> 00:15:01,300
возможность существования таких кодов кажутся вам почти очевидными.

237
00:15:01,660 --> 00:15:05,099
Но не стоит обманывать себя, думая, что они на самом деле очевидны, 

238
00:15:05,099 --> 00:15:06,820
потому что это определенно не так.

239
00:15:07,880 --> 00:15:11,602
Одна из причин того, что умные идеи кажутся обманчиво простыми, заключается в том, 

240
00:15:11,602 --> 00:15:15,280
что мы всегда видим только конечный результат, убирая то, что было беспорядочным, 

241
00:15:15,280 --> 00:15:18,240
никогда не упоминая обо всех неправильных поворотах, преуменьшая, 

242
00:15:18,240 --> 00:15:21,604
насколько огромно пространство исследуемых возможностей в начале проблемы. 

243
00:15:21,604 --> 00:15:22,860
процесс решения и все такое.

244
00:15:23,820 --> 00:15:24,900
Но это правда в целом.

245
00:15:24,900 --> 00:15:27,684
Я думаю, что для некоторых особых изобретений существует вторая, 

246
00:15:27,684 --> 00:15:30,040
более глубокая причина, по которой мы их недооцениваем.

247
00:15:30,840 --> 00:15:33,262
Представление об информации в терминах битов по-настоящему 

248
00:15:33,262 --> 00:15:35,561
сформировалось в полноценную теорию только к 1948 году, 

249
00:15:35,561 --> 00:15:38,640
когда появилась основополагающая статья Клода Шеннона по теории информации.

250
00:15:39,280 --> 00:15:42,540
По сути, это совпало с разработкой Хэммингом своего алгоритма.

251
00:15:43,300 --> 00:15:46,668
Это была та же основополагающая статья, которая в определенном смысле показала, 

252
00:15:46,668 --> 00:15:49,700
что эффективное исправление ошибок всегда возможно, независимо от того, 

253
00:15:49,700 --> 00:15:52,900
насколько высока вероятность переворота битов, по крайней мере теоретически.

254
00:15:53,700 --> 00:15:57,100
Шеннон и Хэмминг, кстати, делили офис в Bell Labs, несмотря на то, 

255
00:15:57,100 --> 00:16:01,160
что работали над совершенно разными вещами, что вряд ли здесь кажется случайным.

256
00:16:02,380 --> 00:16:05,617
Перенесемся на несколько десятилетий вперед, и в наши дни многие 

257
00:16:05,617 --> 00:16:08,754
из нас настолько погружены в размышления о битах и информации, 

258
00:16:08,754 --> 00:16:12,340
что легко упустить из виду, насколько особенным был этот образ мышления.

259
00:16:13,100 --> 00:16:16,021
По иронии судьбы, идеи, которые наиболее глубоко формируют 

260
00:16:16,021 --> 00:16:18,893
образ мышления будущего поколения, в конечном итоге будут 

261
00:16:18,893 --> 00:16:22,260
казаться этому будущему поколению проще, чем они есть на самом деле.

