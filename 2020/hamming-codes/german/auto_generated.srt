1
00:00:00,000 --> 00:00:03,120
Ich gehe davon aus, dass hier alle aus Teil 1 kommen.

2
00:00:03,120 --> 00:00:06,773
Wir sprachen über Hamming-Codes, eine Möglichkeit, einen Datenblock zu erstellen,

3
00:00:06,773 --> 00:00:10,470
bei dem die meisten Bits eine sinnvolle Nachricht enthalten, während einige andere

4
00:00:10,470 --> 00:00:14,301
als eine Art Redundanz fungieren, so dass, wenn ein Bit umgedreht wird, entweder eine

5
00:00:14,301 --> 00:00:17,955
Nachricht entsteht Ob ein Bit oder ein Redundanzbit, irgendetwas in diesem Block,

6
00:00:17,955 --> 00:00:21,920
ein Empfänger kann erkennen, dass ein Fehler aufgetreten ist und wie er ihn beheben kann.

7
00:00:21,920 --> 00:00:25,790
Die dort vorgestellte Grundidee bestand darin, mithilfe

8
00:00:25,790 --> 00:00:29,800
mehrerer Paritätsprüfungen binär bis zum Fehler zu suchen.

9
00:00:29,800 --> 00:00:32,447
In diesem Video bestand das Ziel darin, Hamming-Codes so

10
00:00:32,447 --> 00:00:35,420
praktisch und wiederentdeckbar wie möglich erscheinen zu lassen.

11
00:00:35,420 --> 00:00:38,305
Aber wenn Sie anfangen, darüber nachzudenken, dies tatsächlich zu

12
00:00:38,305 --> 00:00:41,103
implementieren, sei es in Software oder Hardware, kann es sein,

13
00:00:41,103 --> 00:00:44,120
dass dieser Rahmen die Eleganz dieser Codes tatsächlich unterschätzt.

14
00:00:44,120 --> 00:00:47,516
Sie denken vielleicht, dass Sie einen Algorithmus schreiben müssen,

15
00:00:47,516 --> 00:00:50,813
der alle möglichen Fehlerorte verfolgt und diese Gruppe bei jeder

16
00:00:50,813 --> 00:00:54,160
Prüfung halbiert, aber in Wirklichkeit ist es viel, viel einfacher.

17
00:00:54,160 --> 00:00:57,690
Wenn Sie die Antworten auf die vier Paritätsprüfungen, die wir im letzten

18
00:00:57,690 --> 00:01:01,173
Video durchgeführt haben, alle als Einsen und Nullen anstelle von Ja und

19
00:01:01,173 --> 00:01:04,800
Nein vorlesen, wird die Position des Fehlers buchstäblich binär dargestellt.

20
00:01:04,800 --> 00:01:08,785
Beispielsweise sieht die Zahl 7 im Binärformat wie 0111 aus,

21
00:01:08,785 --> 00:01:12,640
was im Wesentlichen bedeutet, dass sie 4 plus 2 plus 1 ist.

22
00:01:12,640 --> 00:01:17,521
Und beachten Sie, wo sich die Position 7 befindet. Sie betrifft zwar die erste

23
00:01:17,521 --> 00:01:22,280
unserer Paritätsgruppen und die zweite und die dritte, aber nicht die letzte.

24
00:01:22,280 --> 00:01:25,330
Wenn man also die Ergebnisse dieser vier Prüfungen von unten nach

25
00:01:25,330 --> 00:01:28,520
oben liest, lässt sich tatsächlich die Position des Fehlers erkennen.

26
00:01:28,520 --> 00:01:33,083
An Beispiel 7 gibt es nichts Besonderes, es funktioniert im Allgemeinen, und dies macht

27
00:01:33,083 --> 00:01:37,440
die Logik zur Implementierung des gesamten Schemas in Hardware erschreckend einfach.

28
00:01:37,440 --> 00:01:41,769
Wenn Sie nun sehen möchten, warum diese Magie geschieht, nehmen Sie diese

29
00:01:41,769 --> 00:01:46,098
16 Indexbezeichnungen für unsere Positionen, aber anstatt sie in Basis 10

30
00:01:46,098 --> 00:01:50,720
zu schreiben, schreiben wir sie alle in Binärform, beginnend von 0000 bis 1111.

31
00:01:50,720 --> 00:01:54,412
Während wir diese binären Etiketten wieder in ihre Boxen stecken, möchte ich

32
00:01:54,412 --> 00:01:58,440
betonen, dass sie sich von den Daten unterscheiden, die tatsächlich gesendet werden.

33
00:01:58,440 --> 00:02:01,240
Sie sind nichts weiter als eine konzeptionelle Bezeichnung, die Ihnen

34
00:02:01,240 --> 00:02:04,200
und mir helfen soll, zu verstehen, woher die vier Paritätsgruppen stammen.

35
00:02:04,200 --> 00:02:07,202
Die Eleganz, alles, was wir betrachten, binär zu beschreiben,

36
00:02:07,202 --> 00:02:10,011
wird möglicherweise durch die Verwirrung untergraben, die

37
00:02:10,011 --> 00:02:13,160
entsteht, wenn alles, was wir betrachten, binär beschrieben wird.

38
00:02:13,160 --> 00:02:15,040
Es lohnt sich jedoch.

39
00:02:15,040 --> 00:02:19,277
Konzentrieren Sie Ihre Aufmerksamkeit nur auf das letzte Bit all dieser

40
00:02:19,277 --> 00:02:24,280
Bezeichnungen und markieren Sie dann die Stellen, an denen das letzte Bit eine 1 ist.

41
00:02:24,280 --> 00:02:28,500
Was wir bekommen, ist die erste unserer vier Paritätsgruppen, was bedeutet, dass

42
00:02:28,500 --> 00:02:32,564
Sie diese erste Prüfung so interpretieren können, dass Sie fragen: „Hey, wenn

43
00:02:32,564 --> 00:02:36,680
es einen Fehler gibt, ist das letzte Bit an der Position dieses Fehlers eine 1?

44
00:02:36,680 --> 00:02:40,096
“ Wenn Sie sich auf das vorletzte Bit konzentrieren und alle

45
00:02:40,096 --> 00:02:43,456
Positionen markieren, an denen das eine 1 ist, erhalten Sie

46
00:02:43,456 --> 00:02:47,040
in ähnlicher Weise die zweite Paritätsgruppe aus unserem Schema.

47
00:02:47,040 --> 00:02:51,511
Mit anderen Worten, bei dieser zweiten Prüfung wird gefragt: „Hey, ich noch

48
00:02:51,511 --> 00:02:56,160
einmal: Wenn ein Fehler vorliegt, ist das vorletzte Bit dieser Position eine 1?

49
00:02:56,160 --> 00:02:57,160
“ Und so weiter.

50
00:02:57,160 --> 00:03:01,718
Die dritte Paritätsprüfung deckt jede Position ab, deren drittletztes

51
00:03:01,718 --> 00:03:05,691
Bit eingeschaltet ist, und die letzte deckt die letzten acht

52
00:03:05,691 --> 00:03:10,120
Positionen ab, also diejenigen, deren höchstwertiges Bit eine 1 ist.

53
00:03:10,120 --> 00:03:15,072
Alles, was wir zuvor getan haben, ist dasselbe wie die Beantwortung dieser vier Fragen,

54
00:03:15,072 --> 00:03:19,800
was wiederum dasselbe ist, als würde man eine Position im Binärsystem buchstabieren.

55
00:03:19,800 --> 00:03:22,080
Ich hoffe, das macht zwei Dinge klarer.

56
00:03:22,080 --> 00:03:24,359
Die erste besteht darin, wie man systematisch auf

57
00:03:24,359 --> 00:03:27,140
Blockgrößen verallgemeinert, die größere Zweierpotenzen sind.

58
00:03:27,140 --> 00:03:30,737
Wenn zur Beschreibung jeder Position mehr Bits erforderlich sind,

59
00:03:30,737 --> 00:03:34,497
beispielsweise sechs Bits zur Beschreibung von 64 Stellen, dann gibt

60
00:03:34,497 --> 00:03:38,640
Ihnen jedes dieser Bits eine der Paritätsgruppen, die wir überprüfen müssen.

61
00:03:38,640 --> 00:03:40,973
Diejenigen von Ihnen, die das Schachbretträtsel gesehen haben, das ich mit

62
00:03:40,973 --> 00:03:43,400
Matt Parker gemacht habe, werden das alles vielleicht überaus vertraut finden.

63
00:03:43,400 --> 00:03:46,773
Es handelt sich um dieselbe Kernlogik, löst jedoch ein anderes

64
00:03:46,773 --> 00:03:49,880
Problem und wird auf ein 64-Felder-Schachbrett angewendet.

65
00:03:49,880 --> 00:03:54,127
Als Zweites hoffe ich, dass dadurch klar wird, warum unsere Paritätsbits an

66
00:03:54,127 --> 00:03:58,320
den Positionen sitzen, die Zweierpotenzen sind, zum Beispiel 1, 2, 4 und 8.

67
00:03:58,320 --> 00:04:01,558
Dies sind die Positionen, bei deren binärer Darstellung

68
00:04:01,558 --> 00:04:03,640
nur ein einzelnes Bit aktiviert ist.

69
00:04:03,640 --> 00:04:08,309
Das bedeutet, dass jedes dieser Paritätsbits innerhalb

70
00:04:08,309 --> 00:04:12,640
einer und nur einer der vier Paritätsgruppen liegt.

71
00:04:12,640 --> 00:04:18,692
Sie können dies auch an größeren Beispielen sehen, bei denen jedes

72
00:04:18,692 --> 00:04:25,920
Paritätsbit praktischerweise nur eine der Gruppen berührt, egal wie groß es ist.

73
00:04:25,920 --> 00:04:29,441
Sobald Sie verstehen, dass diese Paritätsprüfungen, auf die wir uns so viel Zeit

74
00:04:29,441 --> 00:04:33,050
konzentriert haben, nichts anderes als eine clevere Möglichkeit sind, die Position

75
00:04:33,050 --> 00:04:36,659
eines Fehlers im Binärsystem zu buchstabieren, können wir eine Verbindung zu einer

76
00:04:36,659 --> 00:04:40,006
anderen Denkweise über Hamming herstellen Codes, die wohl viel einfacher und

77
00:04:40,006 --> 00:04:43,920
eleganter sind und im Grunde mit einer einzigen Codezeile niedergeschrieben werden können.

78
00:04:43,920 --> 00:04:46,200
Es basiert auf der XOR-Funktion.

79
00:04:46,200 --> 00:04:50,960
XOR steht für diejenigen unter Ihnen, die es nicht wissen, für exklusiv oder.

80
00:04:50,960 --> 00:04:55,420
Wenn Sie die XOR-Verknüpfung zweier Bits verwenden, wird eine 1 zurückgegeben, wenn

81
00:04:55,420 --> 00:05:00,200
eines dieser Bits aktiviert ist, nicht jedoch, wenn beide aktiviert oder deaktiviert sind.

82
00:05:00,200 --> 00:05:03,760
Anders ausgedrückt ist es die Parität dieser beiden Bits.

83
00:05:03,760 --> 00:05:07,840
Als Mathematiker betrachte ich es lieber als Addition Mod 2.

84
00:05:07,840 --> 00:05:10,918
Wir sprechen auch häufig von der XOR-Verknüpfung zweier verschiedener

85
00:05:10,918 --> 00:05:14,040
Bitfolgen, die dies grundsätzlich Komponente für Komponente durchführt.

86
00:05:14,040 --> 00:05:16,280
Es ist wie eine Ergänzung, die man aber nie trägt.

87
00:05:16,280 --> 00:05:19,996
Auch hier gilt: Wer eher mathematisch veranlagt ist, könnte sich dies lieber

88
00:05:19,996 --> 00:05:23,520
so vorstellen, als würde man zwei Vektoren addieren und Mod 2 reduzieren.

89
00:05:23,520 --> 00:05:29,294
Wenn Sie jetzt etwas Python öffnen und die Caret-Operation zwischen zwei ganzen Zahlen

90
00:05:29,294 --> 00:05:35,001
anwenden, geschieht Folgendes, außer auf die Bitdarstellungen dieser Zahlen unter der

91
00:05:35,001 --> 00:05:35,400
Haube.

92
00:05:35,400 --> 00:05:40,729
Der entscheidende Punkt für Sie und mich ist, dass die XOR-Verknüpfung vieler

93
00:05:40,729 --> 00:05:45,785
verschiedener Bitfolgen effektiv eine Möglichkeit ist, die Parodien einer

94
00:05:45,785 --> 00:05:51,320
Reihe separater Gruppen, wie etwa bei den Spalten, auf einen Schlag zu berechnen.

95
00:05:51,320 --> 00:05:54,268
Dies gibt uns eine ziemlich schicke Möglichkeit, uns vorzustellen,

96
00:05:54,268 --> 00:05:57,304
dass die mehreren Paritätsprüfungen unseres Hamming-Code-Algorithmus

97
00:05:57,304 --> 00:05:59,680
alle in einer einzigen Operation zusammengefasst sind.

98
00:05:59,680 --> 00:06:02,800
Obwohl es auf den ersten Blick ganz anders aussieht.

99
00:06:02,800 --> 00:06:08,178
Schreiben Sie konkret die 16 Positionen binär auf, wie wir es zuvor getan haben,

100
00:06:08,178 --> 00:06:13,822
und markieren Sie nun die Positionen, an denen das Nachrichtenbit auf 1 gesetzt ist,

101
00:06:13,822 --> 00:06:19,400
und sammeln Sie diese Positionen dann in einer großen Spalte und nehmen Sie das XOR.

102
00:06:19,400 --> 00:06:23,685
Sie können sich wahrscheinlich vorstellen, dass die 4 Bits, die sich dadurch unten

103
00:06:23,685 --> 00:06:27,970
befinden, die gleichen sind wie die 4 Paritätsprüfungen, die wir kennen und lieben

104
00:06:27,970 --> 00:06:32,410
gelernt haben, aber nehmen Sie sich einen Moment Zeit, um darüber nachzudenken, warum

105
00:06:32,410 --> 00:06:32,720
genau.

106
00:06:32,720 --> 00:06:37,133
In dieser letzten Spalte werden beispielsweise alle Positionen gezählt, deren letztes Bit

107
00:06:37,133 --> 00:06:41,350
eine 1 ist. Da wir uns jedoch bereits auf die hervorgehobenen Positionen beschränken,

108
00:06:41,350 --> 00:06:45,567
zählt sie effektiv, wie viele hervorgehobene Positionen aus der ersten Paritätsgruppe

109
00:06:45,567 --> 00:06:45,960
stammen.

110
00:06:45,960 --> 00:06:48,520
Ist das sinnvoll?

111
00:06:48,520 --> 00:06:52,539
Ebenso zählt die nächste Spalte, wie viele Positionen sich in der

112
00:06:52,539 --> 00:06:56,559
zweiten Paritätsgruppe befinden, die Positionen, deren vorletztes

113
00:06:56,559 --> 00:07:00,640
Bit eine 1 ist und die ebenfalls hervorgehoben sind, und so weiter.

114
00:07:00,640 --> 00:07:04,403
Es ist wirklich nur ein kleiner Perspektivwechsel

115
00:07:04,403 --> 00:07:07,640
in Bezug auf dasselbe, was wir getan haben.

116
00:07:07,640 --> 00:07:10,000
Und so wissen Sie, wohin es von hier aus führt.

117
00:07:10,000 --> 00:07:14,355
Der Absender ist dafür verantwortlich, einige der speziellen

118
00:07:14,355 --> 00:07:19,640
Paritätsbits umzuschalten, um sicherzustellen, dass die Summe 0000 ergibt.

119
00:07:19,640 --> 00:07:24,092
Wenn wir es nun so haben, können wir wirklich gut darüber nachdenken, warum

120
00:07:24,092 --> 00:07:28,720
diese vier resultierenden Bits unten direkt die Position eines Fehlers angeben.

121
00:07:28,720 --> 00:07:32,720
Nehmen wir an, ein Bit in diesem Block wird von 0 auf 1 umgeschaltet.

122
00:07:32,720 --> 00:07:36,704
Das bedeutet, dass die Position dieses Bits nun in die gesamte

123
00:07:36,704 --> 00:07:40,625
XOR-Verknüpfung einbezogen wird, wodurch sich die Summe von 0

124
00:07:40,625 --> 00:07:44,800
in diesen neu einbezogenen Wert, die Position des Fehlers, ändert.

125
00:07:44,800 --> 00:07:47,374
Etwas weniger offensichtlich gilt das Gleiche, wenn

126
00:07:47,374 --> 00:07:49,800
ein Fehler auftritt, der eine 1 in eine 0 ändert.

127
00:07:49,800 --> 00:07:54,369
Sehen Sie, wenn Sie eine Bitfolge zweimal addieren, ist das dasselbe, als

128
00:07:54,369 --> 00:07:59,000
ob sie gar nicht vorhanden wäre, denn in dieser Welt ist 1 plus 1 gleich 0.

129
00:07:59,000 --> 00:08:02,496
Das Hinzufügen einer Kopie dieser Position zur Gesamtsumme

130
00:08:02,496 --> 00:08:05,400
hat also den gleichen Effekt wie das Verschieben.

131
00:08:05,400 --> 00:08:09,180
Und dieser Effekt besteht wiederum darin, dass das

132
00:08:09,180 --> 00:08:13,480
Gesamtergebnis hier unten die Position des Fehlers angibt.

133
00:08:13,480 --> 00:08:16,267
Um zu veranschaulichen, wie elegant das ist, möchte ich die

134
00:08:16,267 --> 00:08:19,240
eine Zeile Python-Code zeigen, auf die ich zuvor verwiesen habe

135
00:08:19,240 --> 00:08:22,120
und die fast die gesamte Logik auf der Empfängerseite erfasst.

136
00:08:22,120 --> 00:08:26,278
Wir beginnen damit, ein zufälliges Array aus 16 Einsen und Nullen zu erstellen,

137
00:08:26,278 --> 00:08:30,334
um den Datenblock zu simulieren, und ich gebe ihm den Namen Bits, aber in der

138
00:08:30,334 --> 00:08:34,389
Praxis würden wir das natürlich von einem Absender erhalten, und statt dessen

139
00:08:34,389 --> 00:08:38,600
Da es zufällig ist, würde es 11 Datenbits zusammen mit 5 Paritätsbits übertragen.

140
00:08:38,600 --> 00:08:43,173
Wenn ich die Funktion enumerateBits aufrufe, verbindet sie jedes

141
00:08:43,173 --> 00:08:48,240
dieser Bits mit einem entsprechenden Index, in diesem Fall von 0 bis 15.

142
00:08:48,240 --> 00:08:52,603
Wenn wir dann also eine Liste erstellen, die alle diese Paare durchläuft,

143
00:08:52,603 --> 00:08:57,379
Paare, die wie i aussehen, und dann nur den i-Wert, nur den Index, herausziehen,

144
00:08:57,379 --> 00:09:01,920
ist das nicht so aufregend, wir bekommen einfach die Indizes 0 bis 15 zurück.

145
00:09:01,920 --> 00:09:05,767
Aber wenn wir die Bedingung hinzufügen, dies nur zu tun, wenn

146
00:09:05,767 --> 00:09:09,676
das Bit eine 1 und keine 0 ist, dann werden nur die Positionen

147
00:09:09,676 --> 00:09:13,400
herausgezogen, an denen das entsprechende Bit aktiviert ist.

148
00:09:13,400 --> 00:09:20,720
In diesem Fall sieht es so aus, als wären diese Positionen 0, 4, 6, 9 usw.

149
00:09:20,720 --> 00:09:24,969
Was wir wollen, ist, alle diese Positionen, die Positionen der

150
00:09:24,969 --> 00:09:29,960
eingeschalteten Bits, zusammenzufassen und sie dann per XOR zu verknüpfen.

151
00:09:29,960 --> 00:09:33,960
Um dies in Python zu tun, möchte ich zunächst einige hilfreiche Funktionen importieren.

152
00:09:33,960 --> 00:09:36,731
Auf diese Weise können wir Reduce() für diese Liste aufrufen

153
00:09:36,731 --> 00:09:39,140
und die XOR-Funktion verwenden, um sie zu reduzieren.

154
00:09:39,140 --> 00:09:44,840
Dies frisst sich im Grunde durch die Liste und nimmt dabei auch XORs mit.

155
00:09:44,840 --> 00:09:48,395
Wenn Sie möchten, können Sie diese XOR-Funktion explizit

156
00:09:48,395 --> 00:09:52,200
ausschreiben, ohne sie von irgendwoher importieren zu müssen.

157
00:09:52,200 --> 00:09:57,357
Im Moment sieht es also so aus, als ob wir, wenn wir dies auf unserem Zufallsblock

158
00:09:57,357 --> 00:10:02,080
von 16 Bits tun, 9 zurückgeben, was der binären Darstellung 1001 entspricht.

159
00:10:02,080 --> 00:10:05,745
Wir werden es hier nicht tun, aber Sie könnten eine Funktion schreiben, bei der

160
00:10:05,745 --> 00:10:09,365
der Absender diese binäre Darstellung verwendet, um die vier Paritätsbits nach

161
00:10:09,365 --> 00:10:13,168
Bedarf zu setzen und diesen Block letztendlich in einen Zustand zu bringen, in dem

162
00:10:13,168 --> 00:10:17,200
die Ausführung dieser Codezeile auf der vollständigen Liste der Bits zurückkehrt eine 0.

163
00:10:17,200 --> 00:10:20,200
Dies würde als gut vorbereiteter Block angesehen werden.

164
00:10:20,200 --> 00:10:23,387
Das Coole ist, dass, wenn wir eines der Bits in dieser Liste

165
00:10:23,387 --> 00:10:26,993
umschalten und so einen zufälligen Fehler durch Rauschen simulieren,

166
00:10:26,993 --> 00:10:30,600
dieser Fehler ausgegeben wird, wenn Sie dieselbe Codezeile ausführen.

167
00:10:30,600 --> 00:10:31,920
Ist das nicht nett?

168
00:10:31,920 --> 00:10:35,470
Sie könnten diesen Block aus heiterem Himmel bekommen, diese

169
00:10:35,470 --> 00:10:39,020
einzelne Zeile darauf ausführen und er würde automatisch die

170
00:10:39,020 --> 00:10:42,920
Position eines Fehlers ausspucken, oder eine 0, wenn es keinen gab.

171
00:10:42,920 --> 00:10:45,520
Und die Größe 16 ist hier nichts Besonderes.

172
00:10:45,520 --> 00:10:48,831
Die gleiche Codezeile würde funktionieren, wenn

173
00:10:48,831 --> 00:10:52,280
Sie eine Liste mit beispielsweise 256 Bits hätten.

174
00:10:52,280 --> 00:10:56,514
Es erübrigt sich zu erwähnen, dass hier noch mehr Code geschrieben werden muss, etwa die

175
00:10:56,514 --> 00:11:00,749
Durchführung der Metaparitätsprüfung zur Erkennung von 2-Bit-Fehlern, aber die Idee ist,

176
00:11:00,749 --> 00:11:04,508
dass fast die gesamte Kernlogik unseres Schemas auf eine einzige XOR-Reduktion

177
00:11:04,508 --> 00:11:05,080
hinausläuft.

178
00:11:05,080 --> 00:11:08,640
Nun, je nachdem, wie gut Sie mit Binär- und XOR-Funktionen und Software

179
00:11:08,640 --> 00:11:12,298
im Allgemeinen vertraut sind, finden Sie diese Perspektive möglicherweise

180
00:11:12,298 --> 00:11:15,710
etwas verwirrend oder so viel eleganter und einfacher, dass Sie sich

181
00:11:15,710 --> 00:11:19,320
fragen, warum wir nicht gleich von Anfang an damit begonnen haben -gehen.

182
00:11:19,320 --> 00:11:22,355
Vereinfacht gesagt lässt sich die Perspektive der Mehrfachparitätsprüfung

183
00:11:22,355 --> 00:11:25,267
leichter in Betracht ziehen, wenn man Hamming-Codes direkt in Hardware

184
00:11:25,267 --> 00:11:28,426
implementiert, und die XOR-Perspektive lässt sich am einfachsten in Betracht

185
00:11:28,426 --> 00:11:31,380
ziehen, wenn man sie in Software von einer höheren Ebene aus durchführt.

186
00:11:31,380 --> 00:11:35,230
Die erste Methode lässt sich am einfachsten per Hand ausführen, und ich denke,

187
00:11:35,230 --> 00:11:39,080
sie eignet sich besser dazu, die dem Ganzen zugrunde liegende Kernintuition zu

188
00:11:39,080 --> 00:11:43,076
vermitteln, nämlich dass die zum Auffinden eines einzelnen Fehlers erforderlichen

189
00:11:43,076 --> 00:11:47,023
Informationen mit dem Protokoll der Blockgröße in Zusammenhang stehen , oder mit

190
00:11:47,023 --> 00:11:51,020
anderen Worten, es wächst um jeweils ein Bit, wenn sich die Blockgröße verdoppelt.

191
00:11:51,020 --> 00:11:53,945
Die relevante Tatsache hierbei ist, dass diese Informationen

192
00:11:53,945 --> 00:11:56,440
direkt mit der benötigten Redundanz korrespondieren.

193
00:11:56,440 --> 00:12:00,149
Das ist es, was den meisten Menschen zuwiderläuft, wenn sie zum ersten Mal

194
00:12:00,149 --> 00:12:03,661
darüber nachdenken, eine Nachricht fehlersicher zu machen, wobei ihnen

195
00:12:03,661 --> 00:12:07,520
normalerweise als erstes in den Sinn kommt, die gesamte Nachricht zu kopieren.

196
00:12:07,520 --> 00:12:10,886
Und dann gibt es übrigens noch eine ganz andere Art und Weise, wie man manchmal

197
00:12:10,886 --> 00:12:14,210
Hamming-Codes präsentiert, bei denen man die Nachricht mit einer großen Matrix

198
00:12:14,210 --> 00:12:14,800
multipliziert.

199
00:12:14,800 --> 00:12:18,469
Es ist ganz nett, weil es es mit der breiteren Familie der linearen

200
00:12:18,469 --> 00:12:21,922
Codes in Verbindung bringt, aber ich denke, das vermittelt kaum

201
00:12:21,922 --> 00:12:25,160
eine Vorstellung davon, woher es kommt oder wie es skaliert.

202
00:12:25,160 --> 00:12:28,803
Apropos Skalierung: Sie werden vielleicht feststellen, dass die Effizienz

203
00:12:28,803 --> 00:12:32,200
dieses Schemas nur dann besser wird, wenn wir die Blockgröße erhöhen.

204
00:12:32,200 --> 00:12:37,721
Wir haben beispielsweise gesehen, dass Sie bei 256 Bit nur 3 % dieses

205
00:12:37,721 --> 00:12:43,480
Speicherplatzes für Redundanz nutzen, und von da an wird es immer besser.

206
00:12:43,480 --> 00:12:46,093
Wenn die Anzahl der Paritätsbits nach und nach

207
00:12:46,093 --> 00:12:49,040
zunimmt, verdoppelt sich die Blockgröße immer weiter.

208
00:12:49,040 --> 00:12:52,992
Und wenn Sie das auf die Spitze treiben, könnten Sie einen Block mit, sagen wir,

209
00:12:52,992 --> 00:12:56,749
einer Million Bits haben, in dem Sie mit Ihren Paritätsprüfungen im wahrsten

210
00:12:56,749 --> 00:13:00,800
Sinne des Wortes 20 Fragen abspielen würden, und der nur 21 Paritätsbits verwendet.

211
00:13:00,800 --> 00:13:04,811
Und wenn man einen Schritt zurücktritt und darüber nachdenkt, wie man sich eine Million

212
00:13:04,811 --> 00:13:08,640
Bits ansieht und einen einzelnen Fehler findet, fühlt sich das wirklich verrückt an.

213
00:13:08,640 --> 00:13:11,712
Das Problem besteht natürlich darin, dass mit einem größeren

214
00:13:11,712 --> 00:13:14,733
Block die Wahrscheinlichkeit steigt, mehr als ein oder zwei

215
00:13:14,733 --> 00:13:18,360
Bitfehler zu sehen, und Hamming-Codes verarbeiten nichts darüber hinaus.

216
00:13:18,360 --> 00:13:22,537
In der Praxis möchten Sie also die richtige Größe finden, damit

217
00:13:22,537 --> 00:13:26,520
die Wahrscheinlichkeit zu vieler Bit-Flips nicht zu hoch ist.

218
00:13:26,520 --> 00:13:31,246
Außerdem kommt es in der Praxis dazu, dass Fehler in kleinen Schüben auftauchen, die

219
00:13:31,246 --> 00:13:35,972
einen einzelnen Block völlig ruinieren würden. Daher besteht eine gängige Taktik, um

220
00:13:35,972 --> 00:13:40,587
einen Schwall von Fehlern auf viele verschiedene Blöcke zu verteilen, darin, diese

221
00:13:40,587 --> 00:13:45,480
Blöcke auf diese Weise zu verschachteln, bevor sie entstehen versendet oder gespeichert.

222
00:13:45,480 --> 00:13:49,122
Andererseits wird vieles davon durch modernere Codes, wie den weitaus

223
00:13:49,122 --> 00:13:52,503
häufiger verwendeten Reed-Solomon-Algorithmus, völlig hinfällig,

224
00:13:52,503 --> 00:13:56,041
der Burst-Fehler besonders gut verarbeitet und so abgestimmt werden

225
00:13:56,041 --> 00:13:59,580
kann, dass er einer größeren Anzahl von Fehlern pro Block standhält.

226
00:13:59,580 --> 00:14:03,000
Aber das ist ein Thema für ein anderes Mal.

227
00:14:03,000 --> 00:14:06,824
In seinem Buch „The Art of Doing Science and Engineering“ spricht Hamming

228
00:14:06,824 --> 00:14:10,700
wunderbar offen darüber, wie kompliziert seine Entdeckung dieses Codes war.

229
00:14:10,700 --> 00:14:13,286
Er probierte zunächst alle möglichen unterschiedlichen Schemata

230
00:14:13,286 --> 00:14:15,469
aus, bei denen es darum ging, die Bits in Teile eines

231
00:14:15,469 --> 00:14:18,420
höherdimensionalen Gitters zu organisieren, und seltsame Dinge wie diese.

232
00:14:18,420 --> 00:14:21,941
Die Idee, dass es möglich sein könnte, Paritätsprüfungen auf eine Art und Weise

233
00:14:21,941 --> 00:14:25,595
zusammenzuführen, die die Position eines Fehlers deutlich macht, kam Hamming erst,

234
00:14:25,595 --> 00:14:29,338
als er nach einer Reihe anderer Analysen einen Schritt zurücktrat und fragte: „Okay,

235
00:14:29,338 --> 00:14:32,860
was ist das effizienteste, was ich konnte. “ könnte es sein, dass es darum geht?

236
00:14:32,860 --> 00:14:37,660
Er äußerte auch offen, wie wichtig es sei, dass er bereits an Paritätsprüfungen

237
00:14:37,660 --> 00:14:42,040
denke, die in den 1940er Jahren weitaus seltener gewesen wären als heute.

238
00:14:42,040 --> 00:14:45,784
In diesem Buch verweist er ungefähr ein halbes Dutzend Mal auf das

239
00:14:45,784 --> 00:14:49,640
Zitat von Louis Pasteur: „Glück begünstigt einen vorbereiteten Geist.

240
00:14:49,640 --> 00:14:52,575
“ Clevere Ideen wirken im Nachhinein oft täuschend einfach,

241
00:14:52,575 --> 00:14:55,120
was dazu führt, dass sie leicht unterschätzt werden.

242
00:14:55,120 --> 00:14:58,564
Im Moment ist meine ehrliche Hoffnung, dass Hamming-Codes oder zumindest

243
00:14:58,564 --> 00:15:01,820
die Möglichkeit solcher Codes für Sie fast offensichtlich erscheinen.

244
00:15:01,820 --> 00:15:04,650
Aber Sie sollten sich nicht der Illusion hingeben, dass sie

245
00:15:04,650 --> 00:15:08,000
tatsächlich offensichtlich sind, denn das ist definitiv nicht der Fall.

246
00:15:08,000 --> 00:15:11,940
Dass kluge Ideen täuschend einfach aussehen, liegt zum Teil daran, dass

247
00:15:11,940 --> 00:15:15,825
wir immer nur das Endergebnis sehen, das Chaos aufräumen, niemals alle

248
00:15:15,825 --> 00:15:19,547
falschen Wendungen erwähnen und unterschätzen, wie groß der Raum an

249
00:15:19,547 --> 00:15:23,980
erforschbaren Möglichkeiten am Anfang eines Problems ist Lösungsprozess, all das.

250
00:15:23,980 --> 00:15:25,280
Aber das gilt im Allgemeinen.

251
00:15:25,280 --> 00:15:28,089
Ich denke, dass es bei einigen besonderen Erfindungen einen

252
00:15:28,089 --> 00:15:31,040
zweiten, tieferen Grund dafür gibt, dass wir sie unterschätzen.

253
00:15:31,040 --> 00:15:33,780
Das Denken von Information in Form von Bits hatte sich erst

254
00:15:33,780 --> 00:15:36,156
1948 mit Claude Shannons bahnbrechender Arbeit über

255
00:15:36,156 --> 00:15:39,400
Informationstheorie wirklich zu einer vollständigen Theorie verdichtet.

256
00:15:39,400 --> 00:15:41,485
Dies geschah im Wesentlichen zeitgleich mit der

257
00:15:41,485 --> 00:15:43,440
Entwicklung seines Algorithmus durch Hamming.

258
00:15:43,440 --> 00:15:46,857
Dabei handelte es sich um dieselbe Grundlagenarbeit, die in gewisser Weise

259
00:15:46,857 --> 00:15:50,274
zeigte, dass eine effiziente Fehlerkorrektur immer möglich ist, unabhängig

260
00:15:50,274 --> 00:15:53,920
davon, wie hoch die Wahrscheinlichkeit von Bit-Flips ist, zumindest theoretisch.

261
00:15:53,920 --> 00:15:58,213
Shannon und Hamming teilten sich übrigens ein Büro in den Bell Labs, obwohl sie

262
00:15:58,213 --> 00:16:02,400
an sehr unterschiedlichen Dingen arbeiteten, was hier kaum zufällig erscheint.

263
00:16:02,400 --> 00:16:07,557
Mehrere Jahrzehnte später sind viele von uns so sehr in das Nachdenken über Bits und

264
00:16:07,557 --> 00:16:12,837
Informationen vertieft, dass man leicht übersieht, wie unterschiedlich diese Denkweise

265
00:16:12,837 --> 00:16:13,080
war.

266
00:16:13,080 --> 00:16:14,534
Ironischerweise werden die Ideen, die die Denkweise einer

267
00:16:14,534 --> 00:16:16,139
zukünftigen Generation am tiefsten prägen, für diese zukünftige

268
00:16:16,139 --> 00:16:17,920
Generation letztendlich einfacher erscheinen, als sie tatsächlich sind.

