1
00:00:00,000 --> 00:00:03,120
Ich gehe davon aus, dass hier alle aus Teil 1 kommen.

2
00:00:03,120 --> 00:00:06,773
Wir sprachen über Hamming-Codes, eine Möglichkeit, einen Datenblock zu erstellen,

3
00:00:06,773 --> 00:00:09,490
bei dem die meisten Bits eine sinnvolle Nachricht enthalten,

4
00:00:09,490 --> 00:00:12,386
während einige andere als eine Art Redundanz fungieren, so dass,

5
00:00:12,386 --> 00:00:16,039
wenn ein Bit umgedreht wird, entweder eine Nachricht entsteht Ob ein Bit oder ein

6
00:00:16,039 --> 00:00:19,247
Redundanzbit, irgendetwas in diesem Block, ein Empfänger kann erkennen,

7
00:00:19,247 --> 00:00:21,920
dass ein Fehler aufgetreten ist und wie er ihn beheben kann.

8
00:00:21,920 --> 00:00:25,168
Die dort vorgestellte Grundidee bestand darin,

9
00:00:25,168 --> 00:00:29,800
mithilfe mehrerer Paritätsprüfungen binär bis zum Fehler zu suchen.

10
00:00:29,800 --> 00:00:32,447
In diesem Video bestand das Ziel darin, Hamming-Codes so

11
00:00:32,447 --> 00:00:35,420
praktisch und wiederentdeckbar wie möglich erscheinen zu lassen.

12
00:00:35,420 --> 00:00:39,004
Aber wenn Sie anfangen, darüber nachzudenken, dies tatsächlich zu implementieren,

13
00:00:39,004 --> 00:00:41,103
sei es in Software oder Hardware, kann es sein,

14
00:00:41,103 --> 00:00:44,120
dass dieser Rahmen die Eleganz dieser Codes tatsächlich unterschätzt.

15
00:00:44,120 --> 00:00:47,516
Sie denken vielleicht, dass Sie einen Algorithmus schreiben müssen,

16
00:00:47,516 --> 00:00:51,712
der alle möglichen Fehlerorte verfolgt und diese Gruppe bei jeder Prüfung halbiert,

17
00:00:51,712 --> 00:00:54,160
aber in Wirklichkeit ist es viel, viel einfacher.

18
00:00:54,160 --> 00:00:56,784
Wenn Sie die Antworten auf die vier Paritätsprüfungen,

19
00:00:56,784 --> 00:01:00,219
die wir im letzten Video durchgeführt haben, alle als Einsen und Nullen

20
00:01:00,219 --> 00:01:03,941
anstelle von Ja und Nein vorlesen, wird die Position des Fehlers buchstäblich

21
00:01:03,941 --> 00:01:04,800
binär dargestellt.

22
00:01:04,800 --> 00:01:08,785
Beispielsweise sieht die Zahl 7 im Binärformat wie 0111 aus,

23
00:01:08,785 --> 00:01:12,640
was im Wesentlichen bedeutet, dass sie 4 plus 2 plus 1 ist.

24
00:01:12,640 --> 00:01:15,791
Und beachten Sie, wo sich die Position 7 befindet.

25
00:01:15,791 --> 00:01:20,920
Sie betrifft zwar die erste unserer Paritätsgruppen und die zweite und die dritte,

26
00:01:20,920 --> 00:01:22,280
aber nicht die letzte.

27
00:01:22,280 --> 00:01:25,885
Wenn man also die Ergebnisse dieser vier Prüfungen von unten nach oben liest,

28
00:01:25,885 --> 00:01:28,520
lässt sich tatsächlich die Position des Fehlers erkennen.

29
00:01:28,520 --> 00:01:32,305
An Beispiel 7 gibt es nichts Besonderes, es funktioniert im Allgemeinen,

30
00:01:32,305 --> 00:01:36,350
und dies macht die Logik zur Implementierung des gesamten Schemas in Hardware

31
00:01:36,350 --> 00:01:37,440
erschreckend einfach.

32
00:01:37,440 --> 00:01:40,774
Wenn Sie nun sehen möchten, warum diese Magie geschieht,

33
00:01:40,774 --> 00:01:44,401
nehmen Sie diese 16 Indexbezeichnungen für unsere Positionen,

34
00:01:44,401 --> 00:01:49,081
aber anstatt sie in Basis 10 zu schreiben, schreiben wir sie alle in Binärform,

35
00:01:49,081 --> 00:01:50,720
beginnend von 0000 bis 1111.

36
00:01:50,720 --> 00:01:54,843
Während wir diese binären Etiketten wieder in ihre Boxen stecken, möchte ich betonen,

37
00:01:54,843 --> 00:01:58,440
dass sie sich von den Daten unterscheiden, die tatsächlich gesendet werden.

38
00:01:58,440 --> 00:02:00,840
Sie sind nichts weiter als eine konzeptionelle Bezeichnung,

39
00:02:00,840 --> 00:02:04,200
die Ihnen und mir helfen soll, zu verstehen, woher die vier Paritätsgruppen stammen.

40
00:02:04,200 --> 00:02:07,202
Die Eleganz, alles, was wir betrachten, binär zu beschreiben,

41
00:02:07,202 --> 00:02:09,818
wird möglicherweise durch die Verwirrung untergraben,

42
00:02:09,818 --> 00:02:13,160
die entsteht, wenn alles, was wir betrachten, binär beschrieben wird.

43
00:02:13,160 --> 00:02:15,040
Es lohnt sich jedoch.

44
00:02:15,040 --> 00:02:19,277
Konzentrieren Sie Ihre Aufmerksamkeit nur auf das letzte Bit all dieser

45
00:02:19,277 --> 00:02:24,280
Bezeichnungen und markieren Sie dann die Stellen, an denen das letzte Bit eine 1 ist.

46
00:02:24,280 --> 00:02:28,239
Was wir bekommen, ist die erste unserer vier Paritätsgruppen, was bedeutet,

47
00:02:28,239 --> 00:02:32,303
dass Sie diese erste Prüfung so interpretieren können, dass Sie fragen: „Hey,

48
00:02:32,303 --> 00:02:36,680
wenn es einen Fehler gibt, ist das letzte Bit an der Position dieses Fehlers eine 1?

49
00:02:36,680 --> 00:02:41,328
“ Wenn Sie sich auf das vorletzte Bit konzentrieren und alle Positionen markieren,

50
00:02:41,328 --> 00:02:44,744
an denen das eine 1 ist, erhalten Sie in ähnlicher Weise die

51
00:02:44,744 --> 00:02:47,040
zweite Paritätsgruppe aus unserem Schema.

52
00:02:47,040 --> 00:02:51,982
Mit anderen Worten, bei dieser zweiten Prüfung wird gefragt: „Hey, ich noch einmal:

53
00:02:51,982 --> 00:02:56,160
Wenn ein Fehler vorliegt, ist das vorletzte Bit dieser Position eine 1?

54
00:02:56,160 --> 00:02:57,160
“ Und so weiter.

55
00:02:57,160 --> 00:03:00,481
Die dritte Paritätsprüfung deckt jede Position ab,

56
00:03:00,481 --> 00:03:04,844
deren drittletztes Bit eingeschaltet ist, und die letzte deckt die

57
00:03:04,844 --> 00:03:10,120
letzten acht Positionen ab, also diejenigen, deren höchstwertiges Bit eine 1 ist.

58
00:03:10,120 --> 00:03:15,072
Alles, was wir zuvor getan haben, ist dasselbe wie die Beantwortung dieser vier Fragen,

59
00:03:15,072 --> 00:03:19,800
was wiederum dasselbe ist, als würde man eine Position im Binärsystem buchstabieren.

60
00:03:19,800 --> 00:03:22,080
Ich hoffe, das macht zwei Dinge klarer.

61
00:03:22,080 --> 00:03:25,681
Die erste besteht darin, wie man systematisch auf Blockgrößen verallgemeinert,

62
00:03:25,681 --> 00:03:27,140
die größere Zweierpotenzen sind.

63
00:03:27,140 --> 00:03:30,737
Wenn zur Beschreibung jeder Position mehr Bits erforderlich sind,

64
00:03:30,737 --> 00:03:33,952
beispielsweise sechs Bits zur Beschreibung von 64 Stellen,

65
00:03:33,952 --> 00:03:38,640
dann gibt Ihnen jedes dieser Bits eine der Paritätsgruppen, die wir überprüfen müssen.

66
00:03:38,640 --> 00:03:40,600
Diejenigen von Ihnen, die das Schachbretträtsel gesehen haben,

67
00:03:40,600 --> 00:03:43,400
das ich mit Matt Parker gemacht habe, werden das alles vielleicht überaus vertraut finden.

68
00:03:43,400 --> 00:03:46,773
Es handelt sich um dieselbe Kernlogik, löst jedoch ein anderes

69
00:03:46,773 --> 00:03:49,880
Problem und wird auf ein 64-Felder-Schachbrett angewendet.

70
00:03:49,880 --> 00:03:52,507
Als Zweites hoffe ich, dass dadurch klar wird,

71
00:03:52,507 --> 00:03:56,810
warum unsere Paritätsbits an den Positionen sitzen, die Zweierpotenzen sind,

72
00:03:56,810 --> 00:03:58,320
zum Beispiel 1, 2, 4 und 8.

73
00:03:58,320 --> 00:04:01,558
Dies sind die Positionen, bei deren binärer Darstellung

74
00:04:01,558 --> 00:04:03,640
nur ein einzelnes Bit aktiviert ist.

75
00:04:03,640 --> 00:04:08,309
Das bedeutet, dass jedes dieser Paritätsbits innerhalb

76
00:04:08,309 --> 00:04:12,640
einer und nur einer der vier Paritätsgruppen liegt.

77
00:04:12,640 --> 00:04:17,247
Sie können dies auch an größeren Beispielen sehen,

78
00:04:17,247 --> 00:04:24,022
bei denen jedes Paritätsbit praktischerweise nur eine der Gruppen berührt,

79
00:04:24,022 --> 00:04:25,920
egal wie groß es ist.

80
00:04:25,920 --> 00:04:28,180
Sobald Sie verstehen, dass diese Paritätsprüfungen,

81
00:04:28,180 --> 00:04:30,311
auf die wir uns so viel Zeit konzentriert haben,

82
00:04:30,311 --> 00:04:32,485
nichts anderes als eine clevere Möglichkeit sind,

83
00:04:32,485 --> 00:04:35,093
die Position eines Fehlers im Binärsystem zu buchstabieren,

84
00:04:35,093 --> 00:04:38,789
können wir eine Verbindung zu einer anderen Denkweise über Hamming herstellen Codes,

85
00:04:38,789 --> 00:04:42,528
die wohl viel einfacher und eleganter sind und im Grunde mit einer einzigen Codezeile

86
00:04:42,528 --> 00:04:43,920
niedergeschrieben werden können.

87
00:04:43,920 --> 00:04:46,200
Es basiert auf der XOR-Funktion.

88
00:04:46,200 --> 00:04:50,960
XOR steht für diejenigen unter Ihnen, die es nicht wissen, für exklusiv oder.

89
00:04:50,960 --> 00:04:55,155
Wenn Sie die XOR-Verknüpfung zweier Bits verwenden, wird eine 1 zurückgegeben,

90
00:04:55,155 --> 00:04:57,916
wenn eines dieser Bits aktiviert ist, nicht jedoch,

91
00:04:57,916 --> 00:05:00,200
wenn beide aktiviert oder deaktiviert sind.

92
00:05:00,200 --> 00:05:03,760
Anders ausgedrückt ist es die Parität dieser beiden Bits.

93
00:05:03,760 --> 00:05:07,840
Als Mathematiker betrachte ich es lieber als Addition Mod 2.

94
00:05:07,840 --> 00:05:11,401
Wir sprechen auch häufig von der XOR-Verknüpfung zweier verschiedener Bitfolgen,

95
00:05:11,401 --> 00:05:14,040
die dies grundsätzlich Komponente für Komponente durchführt.

96
00:05:14,040 --> 00:05:16,280
Es ist wie eine Ergänzung, die man aber nie trägt.

97
00:05:16,280 --> 00:05:18,838
Auch hier gilt: Wer eher mathematisch veranlagt ist,

98
00:05:18,838 --> 00:05:22,506
könnte sich dies lieber so vorstellen, als würde man zwei Vektoren addieren

99
00:05:22,506 --> 00:05:23,520
und Mod 2 reduzieren.

100
00:05:23,520 --> 00:05:29,294
Wenn Sie jetzt etwas Python öffnen und die Caret-Operation zwischen zwei ganzen Zahlen

101
00:05:29,294 --> 00:05:35,001
anwenden, geschieht Folgendes, außer auf die Bitdarstellungen dieser Zahlen unter der

102
00:05:35,001 --> 00:05:35,400
Haube.

103
00:05:35,400 --> 00:05:40,729
Der entscheidende Punkt für Sie und mich ist, dass die XOR-Verknüpfung vieler

104
00:05:40,729 --> 00:05:44,487
verschiedener Bitfolgen effektiv eine Möglichkeit ist,

105
00:05:44,487 --> 00:05:49,270
die Parodien einer Reihe separater Gruppen, wie etwa bei den Spalten,

106
00:05:49,270 --> 00:05:51,320
auf einen Schlag zu berechnen.

107
00:05:51,320 --> 00:05:54,268
Dies gibt uns eine ziemlich schicke Möglichkeit, uns vorzustellen,

108
00:05:54,268 --> 00:05:57,304
dass die mehreren Paritätsprüfungen unseres Hamming-Code-Algorithmus

109
00:05:57,304 --> 00:05:59,680
alle in einer einzigen Operation zusammengefasst sind.

110
00:05:59,680 --> 00:06:02,800
Obwohl es auf den ersten Blick ganz anders aussieht.

111
00:06:02,800 --> 00:06:08,178
Schreiben Sie konkret die 16 Positionen binär auf, wie wir es zuvor getan haben,

112
00:06:08,178 --> 00:06:13,822
und markieren Sie nun die Positionen, an denen das Nachrichtenbit auf 1 gesetzt ist,

113
00:06:13,822 --> 00:06:19,400
und sammeln Sie diese Positionen dann in einer großen Spalte und nehmen Sie das XOR.

114
00:06:19,400 --> 00:06:22,497
Sie können sich wahrscheinlich vorstellen, dass die 4 Bits,

115
00:06:22,497 --> 00:06:26,627
die sich dadurch unten befinden, die gleichen sind wie die 4 Paritätsprüfungen,

116
00:06:26,627 --> 00:06:30,809
die wir kennen und lieben gelernt haben, aber nehmen Sie sich einen Moment Zeit,

117
00:06:30,809 --> 00:06:32,720
um darüber nachzudenken, warum genau.

118
00:06:32,720 --> 00:06:36,250
In dieser letzten Spalte werden beispielsweise alle Positionen gezählt,

119
00:06:36,250 --> 00:06:40,173
deren letztes Bit eine 1 ist. Da wir uns jedoch bereits auf die hervorgehobenen

120
00:06:40,173 --> 00:06:44,488
Positionen beschränken, zählt sie effektiv, wie viele hervorgehobene Positionen aus der

121
00:06:44,488 --> 00:06:45,960
ersten Paritätsgruppe stammen.

122
00:06:45,960 --> 00:06:48,520
Ist das sinnvoll?

123
00:06:48,520 --> 00:06:52,539
Ebenso zählt die nächste Spalte, wie viele Positionen sich in der

124
00:06:52,539 --> 00:06:55,524
zweiten Paritätsgruppe befinden, die Positionen,

125
00:06:55,524 --> 00:07:00,640
deren vorletztes Bit eine 1 ist und die ebenfalls hervorgehoben sind, und so weiter.

126
00:07:00,640 --> 00:07:06,134
Es ist wirklich nur ein kleiner Perspektivwechsel in Bezug auf dasselbe,

127
00:07:06,134 --> 00:07:07,640
was wir getan haben.

128
00:07:07,640 --> 00:07:10,000
Und so wissen Sie, wohin es von hier aus führt.

129
00:07:10,000 --> 00:07:16,283
Der Absender ist dafür verantwortlich, einige der speziellen Paritätsbits umzuschalten,

130
00:07:16,283 --> 00:07:19,640
um sicherzustellen, dass die Summe 0000 ergibt.

131
00:07:19,640 --> 00:07:23,740
Wenn wir es nun so haben, können wir wirklich gut darüber nachdenken,

132
00:07:23,740 --> 00:07:28,720
warum diese vier resultierenden Bits unten direkt die Position eines Fehlers angeben.

133
00:07:28,720 --> 00:07:32,720
Nehmen wir an, ein Bit in diesem Block wird von 0 auf 1 umgeschaltet.

134
00:07:32,720 --> 00:07:36,704
Das bedeutet, dass die Position dieses Bits nun in die gesamte

135
00:07:36,704 --> 00:07:40,625
XOR-Verknüpfung einbezogen wird, wodurch sich die Summe von 0

136
00:07:40,625 --> 00:07:44,800
in diesen neu einbezogenen Wert, die Position des Fehlers, ändert.

137
00:07:44,800 --> 00:07:47,126
Etwas weniger offensichtlich gilt das Gleiche,

138
00:07:47,126 --> 00:07:49,800
wenn ein Fehler auftritt, der eine 1 in eine 0 ändert.

139
00:07:49,800 --> 00:07:54,122
Sehen Sie, wenn Sie eine Bitfolge zweimal addieren, ist das dasselbe,

140
00:07:54,122 --> 00:07:59,000
als ob sie gar nicht vorhanden wäre, denn in dieser Welt ist 1 plus 1 gleich 0.

141
00:07:59,000 --> 00:08:02,496
Das Hinzufügen einer Kopie dieser Position zur Gesamtsumme

142
00:08:02,496 --> 00:08:05,400
hat also den gleichen Effekt wie das Verschieben.

143
00:08:05,400 --> 00:08:09,180
Und dieser Effekt besteht wiederum darin, dass das

144
00:08:09,180 --> 00:08:13,480
Gesamtergebnis hier unten die Position des Fehlers angibt.

145
00:08:13,480 --> 00:08:16,267
Um zu veranschaulichen, wie elegant das ist, möchte ich die

146
00:08:16,267 --> 00:08:19,240
eine Zeile Python-Code zeigen, auf die ich zuvor verwiesen habe

147
00:08:19,240 --> 00:08:22,120
und die fast die gesamte Logik auf der Empfängerseite erfasst.

148
00:08:22,120 --> 00:08:26,278
Wir beginnen damit, ein zufälliges Array aus 16 Einsen und Nullen zu erstellen,

149
00:08:26,278 --> 00:08:29,710
um den Datenblock zu simulieren, und ich gebe ihm den Namen Bits,

150
00:08:29,710 --> 00:08:33,505
aber in der Praxis würden wir das natürlich von einem Absender erhalten,

151
00:08:33,505 --> 00:08:37,352
und statt dessen Da es zufällig ist, würde es 11 Datenbits zusammen mit 5

152
00:08:37,352 --> 00:08:38,600
Paritätsbits übertragen.

153
00:08:38,600 --> 00:08:43,173
Wenn ich die Funktion enumerateBits aufrufe, verbindet sie jedes

154
00:08:43,173 --> 00:08:48,240
dieser Bits mit einem entsprechenden Index, in diesem Fall von 0 bis 15.

155
00:08:48,240 --> 00:08:52,603
Wenn wir dann also eine Liste erstellen, die alle diese Paare durchläuft,

156
00:08:52,603 --> 00:08:57,379
Paare, die wie i aussehen, und dann nur den i-Wert, nur den Index, herausziehen,

157
00:08:57,379 --> 00:09:01,920
ist das nicht so aufregend, wir bekommen einfach die Indizes 0 bis 15 zurück.

158
00:09:01,920 --> 00:09:05,457
Aber wenn wir die Bedingung hinzufügen, dies nur zu tun,

159
00:09:05,457 --> 00:09:10,607
wenn das Bit eine 1 und keine 0 ist, dann werden nur die Positionen herausgezogen,

160
00:09:10,607 --> 00:09:13,400
an denen das entsprechende Bit aktiviert ist.

161
00:09:13,400 --> 00:09:20,720
In diesem Fall sieht es so aus, als wären diese Positionen 0, 4, 6, 9 usw.

162
00:09:20,720 --> 00:09:26,452
Was wir wollen, ist, alle diese Positionen, die Positionen der eingeschalteten Bits,

163
00:09:26,452 --> 00:09:29,960
zusammenzufassen und sie dann per XOR zu verknüpfen.

164
00:09:29,960 --> 00:09:33,960
Um dies in Python zu tun, möchte ich zunächst einige hilfreiche Funktionen importieren.

165
00:09:33,960 --> 00:09:36,731
Auf diese Weise können wir Reduce() für diese Liste aufrufen

166
00:09:36,731 --> 00:09:39,140
und die XOR-Funktion verwenden, um sie zu reduzieren.

167
00:09:39,140 --> 00:09:44,840
Dies frisst sich im Grunde durch die Liste und nimmt dabei auch XORs mit.

168
00:09:44,840 --> 00:09:49,268
Wenn Sie möchten, können Sie diese XOR-Funktion explizit ausschreiben,

169
00:09:49,268 --> 00:09:52,200
ohne sie von irgendwoher importieren zu müssen.

170
00:09:52,200 --> 00:09:57,357
Im Moment sieht es also so aus, als ob wir, wenn wir dies auf unserem Zufallsblock

171
00:09:57,357 --> 00:10:02,080
von 16 Bits tun, 9 zurückgeben, was der binären Darstellung 1001 entspricht.

172
00:10:02,080 --> 00:10:05,378
Wir werden es hier nicht tun, aber Sie könnten eine Funktion schreiben,

173
00:10:05,378 --> 00:10:07,990
bei der der Absender diese binäre Darstellung verwendet,

174
00:10:07,990 --> 00:10:11,656
um die vier Paritätsbits nach Bedarf zu setzen und diesen Block letztendlich in

175
00:10:11,656 --> 00:10:15,642
einen Zustand zu bringen, in dem die Ausführung dieser Codezeile auf der vollständigen

176
00:10:15,642 --> 00:10:17,200
Liste der Bits zurückkehrt eine 0.

177
00:10:17,200 --> 00:10:20,200
Dies würde als gut vorbereiteter Block angesehen werden.

178
00:10:20,200 --> 00:10:23,387
Das Coole ist, dass, wenn wir eines der Bits in dieser Liste

179
00:10:23,387 --> 00:10:26,993
umschalten und so einen zufälligen Fehler durch Rauschen simulieren,

180
00:10:26,993 --> 00:10:30,600
dieser Fehler ausgegeben wird, wenn Sie dieselbe Codezeile ausführen.

181
00:10:30,600 --> 00:10:31,920
Ist das nicht nett?

182
00:10:31,920 --> 00:10:35,121
Sie könnten diesen Block aus heiterem Himmel bekommen,

183
00:10:35,121 --> 00:10:38,787
diese einzelne Zeile darauf ausführen und er würde automatisch

184
00:10:38,787 --> 00:10:42,920
die Position eines Fehlers ausspucken, oder eine 0, wenn es keinen gab.

185
00:10:42,920 --> 00:10:45,520
Und die Größe 16 ist hier nichts Besonderes.

186
00:10:45,520 --> 00:10:48,831
Die gleiche Codezeile würde funktionieren, wenn

187
00:10:48,831 --> 00:10:52,280
Sie eine Liste mit beispielsweise 256 Bits hätten.

188
00:10:52,280 --> 00:10:56,086
Es erübrigt sich zu erwähnen, dass hier noch mehr Code geschrieben werden muss,

189
00:10:56,086 --> 00:10:59,845
etwa die Durchführung der Metaparitätsprüfung zur Erkennung von 2-Bit-Fehlern,

190
00:10:59,845 --> 00:11:03,842
aber die Idee ist, dass fast die gesamte Kernlogik unseres Schemas auf eine einzige

191
00:11:03,842 --> 00:11:05,080
XOR-Reduktion hinausläuft.

192
00:11:05,080 --> 00:11:08,640
Nun, je nachdem, wie gut Sie mit Binär- und XOR-Funktionen und Software

193
00:11:08,640 --> 00:11:12,298
im Allgemeinen vertraut sind, finden Sie diese Perspektive möglicherweise

194
00:11:12,298 --> 00:11:16,106
etwas verwirrend oder so viel eleganter und einfacher, dass Sie sich fragen,

195
00:11:16,106 --> 00:11:19,320
warum wir nicht gleich von Anfang an damit begonnen haben -gehen.

196
00:11:19,320 --> 00:11:22,355
Vereinfacht gesagt lässt sich die Perspektive der Mehrfachparitätsprüfung

197
00:11:22,355 --> 00:11:25,883
leichter in Betracht ziehen, wenn man Hamming-Codes direkt in Hardware implementiert,

198
00:11:25,883 --> 00:11:28,754
und die XOR-Perspektive lässt sich am einfachsten in Betracht ziehen,

199
00:11:28,754 --> 00:11:31,380
wenn man sie in Software von einer höheren Ebene aus durchführt.

200
00:11:31,380 --> 00:11:35,230
Die erste Methode lässt sich am einfachsten per Hand ausführen, und ich denke,

201
00:11:35,230 --> 00:11:39,080
sie eignet sich besser dazu, die dem Ganzen zugrunde liegende Kernintuition zu

202
00:11:39,080 --> 00:11:43,076
vermitteln, nämlich dass die zum Auffinden eines einzelnen Fehlers erforderlichen

203
00:11:43,076 --> 00:11:46,585
Informationen mit dem Protokoll der Blockgröße in Zusammenhang stehen ,

204
00:11:46,585 --> 00:11:49,265
oder mit anderen Worten, es wächst um jeweils ein Bit,

205
00:11:49,265 --> 00:11:51,020
wenn sich die Blockgröße verdoppelt.

206
00:11:51,020 --> 00:11:53,945
Die relevante Tatsache hierbei ist, dass diese Informationen

207
00:11:53,945 --> 00:11:56,440
direkt mit der benötigten Redundanz korrespondieren.

208
00:11:56,440 --> 00:11:58,962
Das ist es, was den meisten Menschen zuwiderläuft,

209
00:11:58,962 --> 00:12:03,068
wenn sie zum ersten Mal darüber nachdenken, eine Nachricht fehlersicher zu machen,

210
00:12:03,068 --> 00:12:07,520
wobei ihnen normalerweise als erstes in den Sinn kommt, die gesamte Nachricht zu kopieren.

211
00:12:07,520 --> 00:12:10,171
Und dann gibt es übrigens noch eine ganz andere Art und Weise,

212
00:12:10,171 --> 00:12:13,916
wie man manchmal Hamming-Codes präsentiert, bei denen man die Nachricht mit einer großen

213
00:12:13,916 --> 00:12:14,800
Matrix multipliziert.

214
00:12:14,800 --> 00:12:18,469
Es ist ganz nett, weil es es mit der breiteren Familie der linearen

215
00:12:18,469 --> 00:12:23,217
Codes in Verbindung bringt, aber ich denke, das vermittelt kaum eine Vorstellung davon,

216
00:12:23,217 --> 00:12:25,160
woher es kommt oder wie es skaliert.

217
00:12:25,160 --> 00:12:27,867
Apropos Skalierung: Sie werden vielleicht feststellen,

218
00:12:27,867 --> 00:12:32,200
dass die Effizienz dieses Schemas nur dann besser wird, wenn wir die Blockgröße erhöhen.

219
00:12:32,200 --> 00:12:37,721
Wir haben beispielsweise gesehen, dass Sie bei 256 Bit nur 3 % dieses

220
00:12:37,721 --> 00:12:43,480
Speicherplatzes für Redundanz nutzen, und von da an wird es immer besser.

221
00:12:43,480 --> 00:12:46,593
Wenn die Anzahl der Paritätsbits nach und nach zunimmt,

222
00:12:46,593 --> 00:12:49,040
verdoppelt sich die Blockgröße immer weiter.

223
00:12:49,040 --> 00:12:52,992
Und wenn Sie das auf die Spitze treiben, könnten Sie einen Block mit, sagen wir,

224
00:12:52,992 --> 00:12:56,749
einer Million Bits haben, in dem Sie mit Ihren Paritätsprüfungen im wahrsten

225
00:12:56,749 --> 00:13:00,800
Sinne des Wortes 20 Fragen abspielen würden, und der nur 21 Paritätsbits verwendet.

226
00:13:00,800 --> 00:13:03,626
Und wenn man einen Schritt zurücktritt und darüber nachdenkt,

227
00:13:03,626 --> 00:13:06,999
wie man sich eine Million Bits ansieht und einen einzelnen Fehler findet,

228
00:13:06,999 --> 00:13:08,640
fühlt sich das wirklich verrückt an.

229
00:13:08,640 --> 00:13:11,712
Das Problem besteht natürlich darin, dass mit einem größeren

230
00:13:11,712 --> 00:13:15,741
Block die Wahrscheinlichkeit steigt, mehr als ein oder zwei Bitfehler zu sehen,

231
00:13:15,741 --> 00:13:18,360
und Hamming-Codes verarbeiten nichts darüber hinaus.

232
00:13:18,360 --> 00:13:22,146
In der Praxis möchten Sie also die richtige Größe finden,

233
00:13:22,146 --> 00:13:26,520
damit die Wahrscheinlichkeit zu vieler Bit-Flips nicht zu hoch ist.

234
00:13:26,520 --> 00:13:31,023
Außerdem kommt es in der Praxis dazu, dass Fehler in kleinen Schüben auftauchen,

235
00:13:31,023 --> 00:13:35,805
die einen einzelnen Block völlig ruinieren würden. Daher besteht eine gängige Taktik,

236
00:13:35,805 --> 00:13:40,253
um einen Schwall von Fehlern auf viele verschiedene Blöcke zu verteilen, darin,

237
00:13:40,253 --> 00:13:42,866
diese Blöcke auf diese Weise zu verschachteln,

238
00:13:42,866 --> 00:13:45,480
bevor sie entstehen versendet oder gespeichert.

239
00:13:45,480 --> 00:13:48,289
Andererseits wird vieles davon durch modernere Codes,

240
00:13:48,289 --> 00:13:51,567
wie den weitaus häufiger verwendeten Reed-Solomon-Algorithmus,

241
00:13:51,567 --> 00:13:55,105
völlig hinfällig, der Burst-Fehler besonders gut verarbeitet und so

242
00:13:55,105 --> 00:13:59,580
abgestimmt werden kann, dass er einer größeren Anzahl von Fehlern pro Block standhält.

243
00:13:59,580 --> 00:14:03,000
Aber das ist ein Thema für ein anderes Mal.

244
00:14:03,000 --> 00:14:06,824
In seinem Buch „The Art of Doing Science and Engineering“ spricht Hamming

245
00:14:06,824 --> 00:14:10,700
wunderbar offen darüber, wie kompliziert seine Entdeckung dieses Codes war.

246
00:14:10,700 --> 00:14:13,488
Er probierte zunächst alle möglichen unterschiedlichen Schemata aus,

247
00:14:13,488 --> 00:14:16,237
bei denen es darum ging, die Bits in Teile eines höherdimensionalen

248
00:14:16,237 --> 00:14:18,420
Gitters zu organisieren, und seltsame Dinge wie diese.

249
00:14:18,420 --> 00:14:21,941
Die Idee, dass es möglich sein könnte, Paritätsprüfungen auf eine Art und Weise

250
00:14:21,941 --> 00:14:25,595
zusammenzuführen, die die Position eines Fehlers deutlich macht, kam Hamming erst,

251
00:14:25,595 --> 00:14:29,338
als er nach einer Reihe anderer Analysen einen Schritt zurücktrat und fragte: „Okay,

252
00:14:29,338 --> 00:14:32,860
was ist das effizienteste, was ich konnte. “ könnte es sein, dass es darum geht?

253
00:14:32,860 --> 00:14:38,080
Er äußerte auch offen, wie wichtig es sei, dass er bereits an Paritätsprüfungen denke,

254
00:14:38,080 --> 00:14:42,040
die in den 1940er Jahren weitaus seltener gewesen wären als heute.

255
00:14:42,040 --> 00:14:45,784
In diesem Buch verweist er ungefähr ein halbes Dutzend Mal auf das

256
00:14:45,784 --> 00:14:49,640
Zitat von Louis Pasteur: „Glück begünstigt einen vorbereiteten Geist.

257
00:14:49,640 --> 00:14:52,575
“ Clevere Ideen wirken im Nachhinein oft täuschend einfach,

258
00:14:52,575 --> 00:14:55,120
was dazu führt, dass sie leicht unterschätzt werden.

259
00:14:55,120 --> 00:14:58,564
Im Moment ist meine ehrliche Hoffnung, dass Hamming-Codes oder zumindest

260
00:14:58,564 --> 00:15:01,820
die Möglichkeit solcher Codes für Sie fast offensichtlich erscheinen.

261
00:15:01,820 --> 00:15:04,225
Aber Sie sollten sich nicht der Illusion hingeben,

262
00:15:04,225 --> 00:15:08,000
dass sie tatsächlich offensichtlich sind, denn das ist definitiv nicht der Fall.

263
00:15:08,000 --> 00:15:11,666
Dass kluge Ideen täuschend einfach aussehen, liegt zum Teil daran,

264
00:15:11,666 --> 00:15:15,114
dass wir immer nur das Endergebnis sehen, das Chaos aufräumen,

265
00:15:15,114 --> 00:15:18,397
niemals alle falschen Wendungen erwähnen und unterschätzen,

266
00:15:18,397 --> 00:15:22,447
wie groß der Raum an erforschbaren Möglichkeiten am Anfang eines Problems

267
00:15:22,447 --> 00:15:23,980
ist Lösungsprozess, all das.

268
00:15:23,980 --> 00:15:25,280
Aber das gilt im Allgemeinen.

269
00:15:25,280 --> 00:15:28,511
Ich denke, dass es bei einigen besonderen Erfindungen einen zweiten,

270
00:15:28,511 --> 00:15:31,040
tieferen Grund dafür gibt, dass wir sie unterschätzen.

271
00:15:31,040 --> 00:15:33,780
Das Denken von Information in Form von Bits hatte sich erst

272
00:15:33,780 --> 00:15:36,156
1948 mit Claude Shannons bahnbrechender Arbeit über

273
00:15:36,156 --> 00:15:39,400
Informationstheorie wirklich zu einer vollständigen Theorie verdichtet.

274
00:15:39,400 --> 00:15:41,485
Dies geschah im Wesentlichen zeitgleich mit der

275
00:15:41,485 --> 00:15:43,440
Entwicklung seines Algorithmus durch Hamming.

276
00:15:43,440 --> 00:15:47,221
Dabei handelte es sich um dieselbe Grundlagenarbeit, die in gewisser Weise zeigte,

277
00:15:47,221 --> 00:15:50,593
dass eine effiziente Fehlerkorrektur immer möglich ist, unabhängig davon,

278
00:15:50,593 --> 00:15:53,920
wie hoch die Wahrscheinlichkeit von Bit-Flips ist, zumindest theoretisch.

279
00:15:53,920 --> 00:15:57,623
Shannon und Hamming teilten sich übrigens ein Büro in den Bell Labs,

280
00:15:57,623 --> 00:16:02,400
obwohl sie an sehr unterschiedlichen Dingen arbeiteten, was hier kaum zufällig erscheint.

281
00:16:02,400 --> 00:16:07,557
Mehrere Jahrzehnte später sind viele von uns so sehr in das Nachdenken über Bits und

282
00:16:07,557 --> 00:16:10,652
Informationen vertieft, dass man leicht übersieht,

283
00:16:10,652 --> 00:16:13,080
wie unterschiedlich diese Denkweise war.

284
00:16:13,080 --> 00:16:14,534
Ironischerweise werden die Ideen, die die Denkweise einer

285
00:16:14,534 --> 00:16:16,139
zukünftigen Generation am tiefsten prägen, für diese zukünftige

286
00:16:16,139 --> 00:16:17,920
Generation letztendlich einfacher erscheinen, als sie tatsächlich sind.

