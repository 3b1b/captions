[
 {
  "input": "Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly.",
  "translatedText": "重み付けされたコインがあると想像してください。そのため、表が反転する確率は正確に 50:50 ではない可能性があります。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 2.8,
  "end": 8.68
 },
 {
  "input": "It could be 20%, or maybe 90%, or 0%, or 31.41592%.",
  "translatedText": "それは 20% かもしれないし、90% かもしれないし、0% かもしれないし、31 かもしれない。41592%。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 9.14,
  "end": 18.48
 },
 {
  "input": "The point is that you just don't know.",
  "translatedText": "重要なのは、あなたが知らないだけだということです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 18.48,
  "end": 20.2
 },
 {
  "input": "But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads.",
  "translatedText": "しかし、このコインを 10 回投げて、そのうち 7 回が表になったと想像してください。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.78,
  "end": 25.58
 },
 {
  "input": "Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads?",
  "translatedText": "このコインの基本的な重みは、各フリップで表が出る 確率が 70% であるようなものだと思いますか? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 25.58,
  "end": 32.02
 },
 {
  "input": "If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say?",
  "translatedText": "私があなたに尋ねるなら、ねえ、表がひっくり返る本当の確率が0である確率はどれく らいですか？7、何と言いますか？",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 32.76,
  "end": 39.62
 },
 {
  "input": "This is a pretty weird question, and for two reasons.",
  "translatedText": "これはかなり奇妙な質問ですが、理由は 2 つあります。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 41.54,
  "end": 44.22
 },
 {
  "input": "First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about.",
  "translatedText": "まず第一に、確率の確率について尋ねています。これは、 私たちが知らない値自体がランダムなイベントの長期的な 頻度であるため、率直に言って考えるのが難しいです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 44.7,
  "end": 55.72
 },
 {
  "input": "But the more pressing weirdness comes from asking about probabilities in the setting of continuous values.",
  "translatedText": "しかし、より差し迫った奇妙さは、連続値の設定 における確率について尋ねることから生じます。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 56.28,
  "end": 61.28
 },
 {
  "input": "Let's give this unknown probability of flipping heads some kind of name, like h.",
  "translatedText": "この未知の表が反転する確率に、h などの名前を付けてみましょう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 62.54,
  "end": 66.78
 },
 {
  "input": "Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads and everything in between.",
  "translatedText": "hは0から1までの任意の実数であり、常に裏が出るコインから常に表が出るコインまで、またその中間のものまであることに留意してほしい。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 67.54,
  "end": 77.32
 },
 {
  "input": "So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.7000001, or any other nearby value, well, there's going to be a strong possibility for paradox if we're not careful.",
  "translatedText": "だから、hが正確に0.7である確率はどれくらいなのか、例えば0.7000001や他の近い値とは違うのか、と問えば、注意深くなければパラドックスが生じる可能性が高くなる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 78.72,
  "end": 94.16
 },
 {
  "input": "It feels like no matter how small the answer to this question, it just wouldn't be small enough.",
  "translatedText": "この質問に対する答えがどんなに小さくても、 十分小さいとは言えないような気がします。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 94.86,
  "end": 99.16
 },
 {
  "input": "If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, well, even if that probability was minuscule, adding them all up to get the total probability of any one of these values will blow up to infinity.",
  "translatedText": "ある範囲内のすべての特定の値、数え切れないほど無限にあるすべての値が、ゼロでない確率を持っているとしたら、たとえその確率が極小であったとしても、それらをすべて足してこれらの値のどれかの確率の合計を求めると、無限大に吹き飛んでしまう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 99.94,
  "end": 114.26
 },
 {
  "input": "On the other hand though, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1.",
  "translatedText": "一方、これらの確率がすべて0であれば、コインに関する有益な情報が何も得られないという事実はさておき、これらの確率の総和は1になるはずのところ0になってしまう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.86,
  "end": 127.66
 },
 {
  "input": "After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1.",
  "translatedText": "結局のところ、コインのこの重量 h は何らかのものなので、それが これらの値のいずれかになる確率は合計して 1 になるはずです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 128.54,
  "end": 136.44
 },
 {
  "input": "So if these values can't all be non-zero, and they can't all be 0, what do you do?",
  "translatedText": "では、これらの値がすべて 0 以外になることはなく、すべて 0 になることもできない場合は、どうすればよいでしょうか。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 137.32,
  "end": 142.22
 },
 {
  "input": "Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions.",
  "translatedText": "ちなみに、この話の目的は、データを使用して、この種の 確率に関する質問に対する意味のある答えを作成するとい う非常に実践的な問題について話したいということです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 144.8,
  "end": 154.6
 },
 {
  "input": "But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox.",
  "translatedText": "しかし、このビデオでは、連続値に対する確率を扱う方法を理解し 、この明らかな矛盾を解決する方法を少し理解してみましょう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 155.68,
  "end": 162.78
 },
 {
  "input": "The key is not to focus on individual values, but ranges of values.",
  "translatedText": "重要なのは、個々の値ではなく、値の範囲に焦点を当てることです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.32,
  "end": 173.96
 },
 {
  "input": "For example, we might make these buckets to represent the probability that h is between, say, 0.8 and 0.85.",
  "translatedText": "例えば、hが0.8から0.85の間にある確率を表すバケツを作ることができる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 174.62,
  "end": 182.16
 },
 {
  "input": "Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability.",
  "translatedText": "また、これは思われているよりも重要ですが、これら の各バーの高さが確率を表すと考えるのではなく、 各バーの面積がその確率を表すと考えてください。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 183.16,
  "end": 193.04
 },
 {
  "input": "Where exactly those areas come from is something that we'll answer later.",
  "translatedText": "その地域がいったいどこから来るのかは、後で答えることにしよう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 193.96,
  "end": 197.48
 },
 {
  "input": "For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges.",
  "translatedText": "現時点では、原理的には、h がこれらの範囲のいずれか内に収ま る確率に対して何らかの答えがあることを知っておいてください。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 197.96,
  "end": 204.14
 },
 {
  "input": "Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input.",
  "translatedText": "私たちの当面の課題は、これらの非常に大まかな質問に対する答えを導 き出し、個々の入力レベルでの分布をより正確に理解することです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.96,
  "end": 214.56
 },
 {
  "input": "The natural thing to do would be consider finer and finer buckets.",
  "translatedText": "もっと細かいバケツを検討するのが自然だろう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 215.46,
  "end": 218.98
 },
 {
  "input": "And when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same.",
  "translatedText": "そうすると、そのどれかに落ちる確率が小さくなる分、それぞれのバーの幅が細くなり、高さはほぼ同じになる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 219.5,
  "end": 228.92
 },
 {
  "input": "That's important, because it means that as you take this process to the limit, you approach some kind of smooth curve.",
  "translatedText": "これは重要なことで、このプロセスを限界まで進めると、ある種の滑らかなカーブに近づくことを意味する。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 229.66,
  "end": 235.22
 },
 {
  "input": "So even though all of the individual probabilities of falling into any one particular bucket will approach zero, the overall shape of the distribution is preserved, and even refined in this limit.",
  "translatedText": "したがって、ある特定のバケツに入る個々の確率がすべてゼロに近づいても、分布の全体的な形は保たれ、この極限ではさらに洗練される。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 235.9,
  "end": 247.22
 },
 {
  "input": "If, on the other hand, we had let the heights of the bars represent probabilities, everything would have gone to zero.",
  "translatedText": "バーの高さで確率を表していたら、すべ てが 0 になってしまうでしょう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.7,
  "end": 254.9
 },
 {
  "input": "So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution.",
  "translatedText": "したがって、極限では、分布の全体的な形状についての情報 がまったく得られない平らな線が得られるだけになります。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 260.04,
  "end": 265.64
 },
 {
  "input": "So, wonderful.",
  "translatedText": "とても素晴らしいことだ。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 267.42,
  "end": 268.14
 },
 {
  "input": "Letting area represent probability helps solve this problem.",
  "translatedText": "面積を確率に置き換えることで、この問題を解決することができる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 268.44,
  "end": 271.26
 },
 {
  "input": "But let me ask you, if the y-axis no longer represents probability, what exactly are the units here?",
  "translatedText": "しかし、Y 軸が確率を表すものではなくなった場合 、ここでの単位は正確には何になるのでしょうか? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 271.9,
  "end": 277.14
 },
 {
  "input": "Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density.",
  "translatedText": "確率はこれらのバーの領域、つまり幅と高さの積に収 まるため、高さは x 方向の単位あたりの確率の一 種、業界で確率密度として知られるものを表します。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.8,
  "end": 289.64
 },
 {
  "input": "The other thing to keep in mind is that the total area of all these bars has to equal one at every level of the process.",
  "translatedText": "もうひとつ注意しなければならないのは、これらのバーの面積の合計は、プロセスのどのレベルでも1つに等しくなければならないということだ。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 290.58,
  "end": 296.54
 },
 {
  "input": "That's something that has to be true for any valid probability distribution.",
  "translatedText": "これは、有効な確率分布には必ず当てはまります。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 297.06,
  "end": 300.5
 },
 {
  "input": "The idea of probability density is actually really clever when you step back to think about it.",
  "translatedText": "確率密度の考え方は、一歩下がって考え ると、実際には非常に賢いものです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 301.98,
  "end": 306.3
 },
 {
  "input": "As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short.",
  "translatedText": "物事を極限まで突き詰めると、0 から 1 までの数え切れないほど多くの h の値のそれぞれに確率を割り当てることに関連するあらゆる種類のパラドッ クスがあるとしても、それらのそれぞれに確率密度を関連付ければ問題はありま せん。確率密度関数 (略して PDF) として知られる関数を与えます。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.3,
  "end": 325.64
 },
 {
  "input": "Anytime you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values.",
  "translatedText": "野生のPDFを見るときはいつでも、それを解釈する方法は、あなたの確率変数が2つの値の間にある確率は、それらの値の間のこの曲線の下の面積に等しいということである。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 326.42,
  "end": 337.52
 },
 {
  "input": "So, for example, what's the probability of getting any one very specific number, like 0.7?",
  "translatedText": "たとえば、0 などの非常に具体的な数値が得られる確率 はどれくらいでしょうか。7？",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 338.22,
  "end": 343.46
 },
 {
  "input": "Well, the area of an infinitely thin slice is 0, so it's 0.",
  "translatedText": "まあ、無限に薄いスライスの面積は0なので0です。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 344.22,
  "end": 348.34
 },
 {
  "input": "What's the probability of all of them put together?",
  "translatedText": "それらをすべて合わせると確率はいくらになるでしょうか? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.9,
  "end": 351.14
 },
 {
  "input": "Well, the area under the full curve is 1.",
  "translatedText": "さて、完全な曲線の下の面積は 1 です。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 351.78,
  "end": 353.96
 },
 {
  "input": "You see?",
  "translatedText": "分かりますか？",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 354.62,
  "end": 354.92
 },
 {
  "input": "Paradox sidestepped.",
  "translatedText": "パラドックスは回避した。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.72,
  "end": 356.4
 },
 {
  "input": "And the way that it's been sidestepped is a bit subtle.",
  "translatedText": "そして、それを回避する方法は少し微妙です。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 357.5,
  "end": 360.22
 },
 {
  "input": "In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them.",
  "translatedText": "サイコロを振る、カードを引くなどの通常の有限な設定 では、ランダムな値が特定の可能性の集合に該当する確 率は、単にそれらのいずれかになる確率の合計です。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 360.22,
  "end": 372.96
 },
 {
  "input": "This feels very intuitive.",
  "translatedText": "これは非常に直感的に感じられる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 373.84,
  "end": 375.02
 },
 {
  "input": "It's even true in a countably infinite context.",
  "translatedText": "これは可算無限コンテクストにおいてさえ当てはまる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 375.24,
  "end": 377.6
 },
 {
  "input": "But to deal with the continuum, the rules themselves have shifted.",
  "translatedText": "しかし、連続体に対処するために、ルール自体が変わりました。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 378.12,
  "end": 381.54
 },
 {
  "input": "The probability of falling into a range of values is no longer the sum of the probabilities of each individual value.",
  "translatedText": "ある値の範囲に該当する確率は、個々の 値の確率の合計ではなくなりました。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 382.1,
  "end": 388.66
 },
 {
  "input": "Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0.",
  "translatedText": "代わりに、範囲に関連付けられた確率が基本的なプリミティブ オ ブジェクトであり、ここで個々の値について話すことに意味があ る唯一の意味は、それを幅 0 の範囲として考えることです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.18,
  "end": 401.22
 },
 {
  "input": "If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well, you'll be happy to know that mathematicians are way ahead of you.",
  "translatedText": "もし、有限の設定と連続的な設定の間でルールが変わるという考えに不安を感じるなら、数学者たちがあなたよりずっと先を行っていることを知っておくといいだろう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 402.18,
  "end": 410.4
 },
 {
  "input": "There's a field of math called measure theory, which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely.",
  "translatedText": "測度論と呼ばれる数学の分野があるが、これはこの2つの設定を統合し、すべての可能性のさまざまな部分集合に確率のような数値をうまく組み合わせたり分配したりする方法で関連付けるという考え方を厳密にするのに役立つ。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 410.82,
  "end": 423.14
 },
 {
  "input": "For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve.",
  "translatedText": "たとえば、50% の確率で 0 に等しい乱数が あり、残りの時間は釣鐘曲線の半分のような分布に 従った正の数であるという設定があるとします。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 424.04,
  "end": 435.88
 },
 {
  "input": "This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one.",
  "translatedText": "これは、1つの値がゼロでない確率を持つ有限の文脈と、連続的な文脈の中間に位置する厄介なものである。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 436.48,
  "end": 444.38
 },
 {
  "input": "where probabilities are found according to areas under the appropriate density function.",
  "translatedText": "ここで確率は、適切な密度関数の下での面積に従って求められる。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 444.64,
  "end": 448.68
 },
 {
  "input": "This is the sort of thing that measure theory handles very smoothly.",
  "translatedText": "このようなことは、測度理論では非常にスムーズに処理されます。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.46,
  "end": 452.6
 },
 {
  "input": "I mention this mainly for the especially curious viewer, and you can find more reading material in the description.",
  "translatedText": "これについては、主に特に好奇心旺盛な視聴者向けに説 明します。説明にはさらに読み物が含まれています。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.04,
  "end": 458.12
 },
 {
  "input": "It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves.",
  "translatedText": "離散的なコンテキストで合計を使用している場合は、連続的なコン テキストで積分を使用するのが非常に一般的な経験則です。これは 、曲線の下の領域を見つけるために使用する微積分のツールです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 460.62,
  "end": 471.8
 },
 {
  "input": "In fact, you could argue this video would be way shorter if I just said that at the front and called it good.",
  "translatedText": "実際、私が最初にそれを言って、それが良いと言っていたら 、このビデオはもっと短くなると主張するかもしれません。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 471.8,
  "end": 477.04
 },
 {
  "input": "For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means.",
  "translatedText": "しかし、私としては、それが実際に何を意味するのかを深く考えずに、 やみくもにこれを行うのは少し満足できないと常に感じていました。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 477.76,
  "end": 483.28
 },
 {
  "input": "And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate more powerful definition that's based on measure theory, this formal foundation of probability.",
  "translatedText": "実際、積分の理論的裏付けを掘り下げてみると、典型的な微積分入門の授業で定義される方法とは別に、測度論に基づく、より強力な定義があることがわかるだろう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 484.08,
  "end": 499.02
 },
 {
  "input": "If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow altogether they have a probability of one.",
  "translatedText": "確率を初めて学んだ頃を振り返ってみると、実数である確率変数やダーツボードにダーツを投げるような連続的な設定では、可能性のある結果がたくさんあるにもかかわらず、それぞれの確率は0であり、どういうわけかそれらを合計すると1の確率になる、という奇妙な考え方に取り組んでいたことを覚えている。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 500.28,
  "end": 519.56
 },
 {
  "input": "Now one step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me.",
  "translatedText": "可能性は確率よりも確率密度と結びついた方が良いということを理解することが、このことを理解するための一つのステップになる。しかし、ただ一方の和を他方の積分に置き換えただけでは、私には痒いところに手が届かない。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 520.82,
  "end": 532.82
 },
 {
  "input": "I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all.",
  "translatedText": "さまざまな集合の確率を組み合わせるルールが私が思っていたもの とまったく異なり、すべての根底にあるのは単に異なる公理系であ ることに気づいたとき、初めてピンと来たことを覚えています。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 533.28,
  "end": 543.24
 },
 {
  "input": "But anyway, steering away from the theory somewhere back in the loose direction of application, look back to our original question about the coin with an unknown weight.",
  "translatedText": "しかし、ともかく、理論から応用の緩やかな方向へと舵を切って、重さのわからないコインについての最初の質問に戻ってみよう。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 544.58,
  "end": 552.44
 },
 {
  "input": "What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses?",
  "translatedText": "ここで学んだことは、数回のトスの結果を見た後でこの値 h を 表す確率密度関数は何か、という質問が正しいということです。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 552.96,
  "end": 562.96
 },
 {
  "input": "If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8?",
  "translatedText": "その PDF を見つけることができれば、それを使用して、表が反転する真の確率が 0 の間に収まる確率はどれくらいか、などの質問に答えることができます。6と0。8? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 563.46,
  "end": 572.8
 },
 {
  "input": "To find that PDF, join me in the next part.",
  "translatedText": "その PDF を見つけるには、次のパートに参加してください。",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 573.68,
  "end": 576.06
 }
]