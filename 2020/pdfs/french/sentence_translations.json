[
 {
  "input": "Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly.",
  "translatedText": "Imaginez que vous ayez une pièce de monnaie pondérée, donc la probabilité de faire tomber face n'est peut-être pas exactement de 50-50. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 2.8,
  "end": 8.68
 },
 {
  "input": "It could be 20%, or maybe 90%, or 0%, or 31.41592%.",
  "translatedText": "Cela pourrait être 20 %, ou peut-être 90 %, ou 0 %, ou 31.41592%. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 9.14,
  "end": 18.48
 },
 {
  "input": "The point is that you just don't know.",
  "translatedText": "Le fait est que vous ne le savez tout simplement pas. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 18.48,
  "end": 20.2
 },
 {
  "input": "But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads.",
  "translatedText": "Mais imaginez que vous lancez cette pièce 10 fois différentes, et 7 de ces fois elle tombe sur face. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 20.78,
  "end": 25.58
 },
 {
  "input": "Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads?",
  "translatedText": "Pensez-vous que le poids sous-jacent de cette pièce est tel que chaque lancer a 70 % de chances de tomber sur face ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 25.58,
  "end": 32.02
 },
 {
  "input": "If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say?",
  "translatedText": "Si je devais vous demander, quelle est la probabilité que la véritable probabilité de faire tomber des têtes soit de 0.7, que diriez-vous ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 32.76,
  "end": 39.62
 },
 {
  "input": "This is a pretty weird question, and for two reasons.",
  "translatedText": "C'est une question assez étrange, et pour deux raisons. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 41.54,
  "end": 44.22
 },
 {
  "input": "First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about.",
  "translatedText": "Tout d'abord, il s'agit de la probabilité d'une probabilité, car la valeur que nous ne connaissons pas est elle-même une sorte de fréquence à long terme pour un événement aléatoire, ce à quoi il est franchement difficile de penser. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 44.7,
  "end": 55.72
 },
 {
  "input": "But the more pressing weirdness comes from asking about probabilities in the setting of continuous values.",
  "translatedText": "Mais l’étrangeté la plus pressante vient du fait de s’interroger sur les probabilités dans le cadre de valeurs continues. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 56.28,
  "end": 61.28
 },
 {
  "input": "Let's give this unknown probability of flipping heads some kind of name, like h.",
  "translatedText": "Donnons à cette probabilité inconnue de faire tomber des têtes un nom, comme h. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 62.54,
  "end": 66.78
 },
 {
  "input": "Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads and everything in between.",
  "translatedText": "N'oublie pas que h peut être n'importe quel nombre réel compris entre 0 et 1, allant d'une pièce qui donne toujours pile à une pièce qui donne toujours face, et tout ce qui se trouve entre les deux.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 67.54,
  "end": 77.32
 },
 {
  "input": "So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.7000001, or any other nearby value, well, there's going to be a strong possibility for paradox if we're not careful.",
  "translatedText": "Donc si je demande, hey, quelle est la probabilité que h soit précisément 0,7, par opposition à, disons, 0,7000001, ou toute autre valeur proche, eh bien, il y aura une forte possibilité de paradoxe si nous ne faisons pas attention.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 78.72,
  "end": 94.16
 },
 {
  "input": "It feels like no matter how small the answer to this question, it just wouldn't be small enough.",
  "translatedText": "J’ai l’impression que, si petite que soit la réponse à cette question, elle ne sera tout simplement pas assez petite. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 94.86,
  "end": 99.16
 },
 {
  "input": "If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, well, even if that probability was minuscule, adding them all up to get the total probability of any one of these values will blow up to infinity.",
  "translatedText": "Si chaque valeur spécifique à l'intérieur d'une certaine plage, toutes infiniment nombreuses, a une probabilité non nulle, eh bien, même si cette probabilité est minuscule, le fait de les additionner toutes pour obtenir la probabilité totale de n'importe laquelle de ces valeurs s'élèvera à l'infini.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 99.94,
  "end": 114.26
 },
 {
  "input": "On the other hand though, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1.",
  "translatedText": "D'un autre côté, si toutes ces probabilités sont égales à 0, outre le fait que cela ne te donne aucune information utile sur la pièce, la somme totale de ces probabilités serait de 0, alors qu'elle devrait être de 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 115.86,
  "end": 127.66
 },
 {
  "input": "After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1.",
  "translatedText": "Après tout, ce poids de la pièce h est quelque chose, donc la probabilité qu'il s'agisse de l'une de ces valeurs devrait totaliser 1. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 128.54,
  "end": 136.44
 },
 {
  "input": "So if these values can't all be non-zero, and they can't all be 0, what do you do?",
  "translatedText": "Donc, si ces valeurs ne peuvent pas toutes être différentes de zéro et qu’elles ne peuvent pas toutes être égales à 0, que faites-vous ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 137.32,
  "end": 142.22
 },
 {
  "input": "Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions.",
  "translatedText": "Soit dit en passant, là où nous voulons en venir, c'est que j'aimerais parler de la question très pratique de l'utilisation des données pour créer des réponses significatives à ce genre de questions de probabilités. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 144.8,
  "end": 154.6
 },
 {
  "input": "But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox.",
  "translatedText": "Mais pour cette vidéo, prenons un moment pour comprendre comment travailler avec des probabilités sur des valeurs continues et résoudre cet apparent paradoxe. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 155.68,
  "end": 162.78
 },
 {
  "input": "The key is not to focus on individual values, but ranges of values.",
  "translatedText": "La clé n’est pas de se concentrer sur des valeurs individuelles, mais sur des plages de valeurs. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.32,
  "end": 173.96
 },
 {
  "input": "For example, we might make these buckets to represent the probability that h is between, say, 0.8 and 0.85.",
  "translatedText": "Par exemple, nous pourrions faire ces seaux pour représenter la probabilité que h soit compris entre, disons, 0,8 et 0,85.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 174.62,
  "end": 182.16
 },
 {
  "input": "Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability.",
  "translatedText": "De plus, et c'est plus important qu'il n'y paraît, plutôt que de considérer la hauteur de chacune de ces barres comme représentant la probabilité, pensez à l'aire de chacune comme représentant cette probabilité. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 183.16,
  "end": 193.04
 },
 {
  "input": "Where exactly those areas come from is something that we'll answer later.",
  "translatedText": "Nous répondrons plus tard à la question de savoir d'où viennent exactement ces zones.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 193.96,
  "end": 197.48
 },
 {
  "input": "For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges.",
  "translatedText": "Pour l'instant, sachez qu'en principe, il existe une réponse à la probabilité que h se situe dans l'une de ces plages. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 197.96,
  "end": 204.14
 },
 {
  "input": "Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input.",
  "translatedText": "Notre tâche à l'heure actuelle est de répondre à ces questions très grossières et d'avoir une compréhension plus exacte de la distribution au niveau de chaque intrant individuel. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 204.96,
  "end": 214.56
 },
 {
  "input": "The natural thing to do would be consider finer and finer buckets.",
  "translatedText": "La chose naturelle à faire serait d'envisager des seaux de plus en plus fins.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 215.46,
  "end": 218.98
 },
 {
  "input": "And when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same.",
  "translatedText": "Et lorsque tu le fais, la probabilité plus faible de tomber dans l'une d'entre elles est prise en compte dans la largeur plus fine de chacune de ces barres, alors que les hauteurs vont rester à peu près les mêmes.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 219.5,
  "end": 228.92
 },
 {
  "input": "That's important, because it means that as you take this process to the limit, you approach some kind of smooth curve.",
  "translatedText": "C'est important, car cela signifie qu'en poussant ce processus à la limite, tu t'approches d'une sorte de courbe lisse.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 229.66,
  "end": 235.22
 },
 {
  "input": "So even though all of the individual probabilities of falling into any one particular bucket will approach zero, the overall shape of the distribution is preserved, and even refined in this limit.",
  "translatedText": "Ainsi, même si toutes les probabilités individuelles de tomber dans un seau particulier s'approcheront de zéro, la forme globale de la distribution est préservée, et même affinée dans cette limite.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 235.9,
  "end": 247.22
 },
 {
  "input": "If, on the other hand, we had let the heights of the bars represent probabilities, everything would have gone to zero.",
  "translatedText": "Si nous avions laissé les hauteurs des barres représenter des probabilités, tout serait tombé à 0. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 248.7,
  "end": 254.9
 },
 {
  "input": "So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution.",
  "translatedText": "Donc à la limite, nous aurions juste eu une ligne plate ne donnant aucune information sur la forme globale de la distribution. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 260.04,
  "end": 265.64
 },
 {
  "input": "So, wonderful.",
  "translatedText": "C'est donc merveilleux.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 267.42,
  "end": 268.14
 },
 {
  "input": "Letting area represent probability helps solve this problem.",
  "translatedText": "Laisser l'aire représenter la probabilité permet de résoudre ce problème.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 268.44,
  "end": 271.26
 },
 {
  "input": "But let me ask you, if the y-axis no longer represents probability, what exactly are the units here?",
  "translatedText": "Mais laissez-moi vous demander, si l’axe des y ne représente plus la probabilité, quelles sont exactement les unités ici ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 271.9,
  "end": 277.14
 },
 {
  "input": "Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density.",
  "translatedText": "Étant donné que la probabilité se situe dans la zone de ces barres, ou la largeur multipliée par la hauteur, la hauteur représente une sorte de probabilité par unité dans la direction x, ce que l'on appelle dans le secteur une densité de probabilité. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 277.8,
  "end": 289.64
 },
 {
  "input": "The other thing to keep in mind is that the total area of all these bars has to equal one at every level of the process.",
  "translatedText": "L'autre chose à garder à l'esprit est que la surface totale de toutes ces barres doit être égale à un à chaque niveau du processus.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 290.58,
  "end": 296.54
 },
 {
  "input": "That's something that has to be true for any valid probability distribution.",
  "translatedText": "C'est quelque chose qui doit être vrai pour toute distribution de probabilité valide. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 297.06,
  "end": 300.5
 },
 {
  "input": "The idea of probability density is actually really clever when you step back to think about it.",
  "translatedText": "L’idée de densité de probabilité est en fait très intelligente quand on y réfléchit avec du recul. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 301.98,
  "end": 306.3
 },
 {
  "input": "As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short.",
  "translatedText": "En poussant les choses à la limite, même s'il y a toutes sortes de paradoxes associés à l'attribution d'une probabilité à chacune de ces innombrables valeurs de h comprises entre 0 et 1, il n'y a pas de problème si nous associons une densité de probabilité à chacune d'elles, donnant ce qu'on appelle une fonction de densité de probabilité, ou PDF en abrégé. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 306.3,
  "end": 325.64
 },
 {
  "input": "Anytime you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values.",
  "translatedText": "Chaque fois que tu vois un PDF dans la nature, la façon de l'interpréter est que la probabilité que ta variable aléatoire se situe entre deux valeurs est égale à l'aire sous cette courbe entre ces valeurs.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 326.42,
  "end": 337.52
 },
 {
  "input": "So, for example, what's the probability of getting any one very specific number, like 0.7?",
  "translatedText": "Par exemple, quelle est la probabilité d’obtenir un nombre très spécifique, comme 0.7? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 338.22,
  "end": 343.46
 },
 {
  "input": "Well, the area of an infinitely thin slice is 0, so it's 0.",
  "translatedText": "Eh bien, l’aire d’une tranche infiniment fine est 0, donc c’est 0. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 344.22,
  "end": 348.34
 },
 {
  "input": "What's the probability of all of them put together?",
  "translatedText": "Quelle est la probabilité que tous ces éléments soient réunis ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 348.9,
  "end": 351.14
 },
 {
  "input": "Well, the area under the full curve is 1.",
  "translatedText": "Eh bien, l’aire sous la courbe complète est de 1. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 351.78,
  "end": 353.96
 },
 {
  "input": "You see?",
  "translatedText": "Tu vois? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 354.62,
  "end": 354.92
 },
 {
  "input": "Paradox sidestepped.",
  "translatedText": "Le paradoxe a été contourné. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 355.72,
  "end": 356.4
 },
 {
  "input": "And the way that it's been sidestepped is a bit subtle.",
  "translatedText": "Et la façon dont cela a été contourné est un peu subtile. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 357.5,
  "end": 360.22
 },
 {
  "input": "In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them.",
  "translatedText": "Dans des contextes normaux et finis, comme lancer un dé ou tirer une carte, la probabilité qu'une valeur aléatoire tombe dans une collection donnée de possibilités est simplement la somme des probabilités d'être l'une d'entre elles. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 360.22,
  "end": 372.96
 },
 {
  "input": "This feels very intuitive.",
  "translatedText": "Cela semble très intuitif.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 373.84,
  "end": 375.02
 },
 {
  "input": "It's even true in a countably infinite context.",
  "translatedText": "C'est même vrai dans un contexte infini.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 375.24,
  "end": 377.6
 },
 {
  "input": "But to deal with the continuum, the rules themselves have shifted.",
  "translatedText": "Mais pour gérer ce continuum, les règles elles-mêmes ont changé. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 378.12,
  "end": 381.54
 },
 {
  "input": "The probability of falling into a range of values is no longer the sum of the probabilities of each individual value.",
  "translatedText": "La probabilité d’appartenir à une plage de valeurs n’est plus la somme des probabilités de chaque valeur individuelle. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 382.1,
  "end": 388.66
 },
 {
  "input": "Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0.",
  "translatedText": "Au lieu de cela, les probabilités associées aux plages sont les objets primitifs fondamentaux, et le seul sens dans lequel il est significatif de parler ici d'une valeur individuelle est de la considérer comme une plage de largeur 0. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 389.18,
  "end": 401.22
 },
 {
  "input": "If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well, you'll be happy to know that mathematicians are way ahead of you.",
  "translatedText": "Si l'idée que les règles changent entre un cadre fini et un cadre continu te semble troublante, tu seras heureux d'apprendre que les mathématiciens ont une longueur d'avance sur toi.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 402.18,
  "end": 410.4
 },
 {
  "input": "There's a field of math called measure theory, which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely.",
  "translatedText": "Il existe un domaine des mathématiques appelé théorie de la mesure, qui permet d'unir ces deux contextes et de rendre rigoureuse l'idée d'associer des nombres comme les probabilités à divers sous-ensembles de toutes les possibilités d'une manière qui les combine et les distribue agréablement.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 410.82,
  "end": 423.14
 },
 {
  "input": "For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve.",
  "translatedText": "Par exemple, disons que vous êtes dans un contexte où vous avez un nombre aléatoire qui est égal à 0 avec une probabilité de 50 %, et le reste du temps, c'est un nombre positif selon une distribution qui ressemble à la moitié d'une courbe en cloche. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 424.04,
  "end": 435.88
 },
 {
  "input": "This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one.",
  "translatedText": "Il s'agit d'un moyen terme délicat entre un contexte fini, où une seule valeur a une probabilité non nulle, et un contexte continu.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 436.48,
  "end": 444.38
 },
 {
  "input": "where probabilities are found according to areas under the appropriate density function.",
  "translatedText": "où les probabilités sont trouvées en fonction des aires sous la fonction de densité appropriée.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 444.64,
  "end": 448.68
 },
 {
  "input": "This is the sort of thing that measure theory handles very smoothly.",
  "translatedText": "C’est le genre de chose que la théorie de la mesure gère très facilement. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 449.46,
  "end": 452.6
 },
 {
  "input": "I mention this mainly for the especially curious viewer, and you can find more reading material in the description.",
  "translatedText": "Je le mentionne principalement pour le spectateur particulièrement curieux, et vous pouvez trouver plus de matériel de lecture dans la description. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 453.04,
  "end": 458.12
 },
 {
  "input": "It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves.",
  "translatedText": "C'est une règle empirique assez courante selon laquelle si vous utilisez une somme dans un contexte discret, utilisez une intégrale dans le contexte continu, qui est l'outil de calcul que nous utilisons pour trouver les aires sous les courbes. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 460.62,
  "end": 471.8
 },
 {
  "input": "In fact, you could argue this video would be way shorter if I just said that at the front and called it good.",
  "translatedText": "En fait, on pourrait dire que cette vidéo serait beaucoup plus courte si je disais simplement cela au début et que je la qualifiais de bonne. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 471.8,
  "end": 477.04
 },
 {
  "input": "For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means.",
  "translatedText": "Pour ma part, j’ai toujours trouvé un peu insatisfaisant de faire cela aveuglément sans réfléchir à ce que cela signifie réellement. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 477.76,
  "end": 483.28
 },
 {
  "input": "And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate more powerful definition that's based on measure theory, this formal foundation of probability.",
  "translatedText": "Et en fait, si tu creuses vraiment les fondements théoriques des intégrales, tu découvriras qu'en plus de la façon dont elles sont définies dans un cours d'introduction au calcul classique, il existe une définition distincte plus puissante qui est basée sur la théorie de la mesure, ce fondement formel de la probabilité.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 484.08,
  "end": 499.02
 },
 {
  "input": "If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow altogether they have a probability of one.",
  "translatedText": "Lorsque j'ai appris les probabilités pour la première fois, je me souviens avoir été confronté à cette idée étrange que dans un contexte continu, comme les variables aléatoires qui sont des nombres réels ou le fait de lancer une fléchette sur un jeu de fléchettes, tu as un tas de résultats possibles, mais chacun a une probabilité de zéro, et d'une manière ou d'une autre, ils ont tous ensemble une probabilité de un.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 500.28,
  "end": 519.56
 },
 {
  "input": "Now one step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me.",
  "translatedText": "L'une des étapes pour accepter cela est de réaliser que la possibilité est mieux liée à la densité de probabilité qu'à la probabilité, mais le simple fait de remplacer les sommes de l'une par des intégrales des autres n'a jamais été suffisant pour me convaincre.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 520.82,
  "end": 532.82
 },
 {
  "input": "I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all.",
  "translatedText": "Je me souviens que le déclic n’a vraiment eu lieu que lorsque j’ai réalisé que les règles permettant de combiner les probabilités de différents ensembles n’étaient pas tout à fait ce que je pensais qu’elles étaient, et qu’il y avait simplement un système d’axiomes différent sous-jacent à tout cela. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 533.28,
  "end": 543.24
 },
 {
  "input": "But anyway, steering away from the theory somewhere back in the loose direction of application, look back to our original question about the coin with an unknown weight.",
  "translatedText": "Mais quoi qu'il en soit, en nous éloignant de la théorie pour revenir à l'application, nous revenons à notre question initiale sur la pièce de monnaie dont le poids n'est pas connu.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 544.58,
  "end": 552.44
 },
 {
  "input": "What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses?",
  "translatedText": "Ce que nous avons appris ici, c'est que la bonne question à se poser est la suivante : quelle est la fonction de densité de probabilité qui décrit cette valeur h après avoir vu les résultats de quelques lancers ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 552.96,
  "end": 562.96
 },
 {
  "input": "If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8?",
  "translatedText": "Si vous pouvez trouver ce PDF, vous pouvez l'utiliser pour répondre à des questions telles que : quelle est la probabilité que la véritable probabilité de retourner la tête se situe entre 0.6 et 0.8 ? ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 563.46,
  "end": 572.8
 },
 {
  "input": "To find that PDF, join me in the next part.",
  "translatedText": "Pour trouver ce PDF, rejoignez-moi dans la partie suivante. ",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 573.68,
  "end": 576.06
 }
]