[
 {
  "input": "Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly.",
  "translatedText": "Stellen Sie sich vor, Sie haben eine gewichtete Münze, sodass die Wahrscheinlichkeit, den Kopf zu werfen, möglicherweise nicht genau 50:50 beträgt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.8,
  "end": 8.68
 },
 {
  "input": "It could be 20%, or maybe 90%, or 0%, or 31.41592%.",
  "translatedText": "Es könnte 20 % sein, oder vielleicht 90 %, oder 0 % oder 31.41592 %.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 9.14,
  "end": 18.48
 },
 {
  "input": "The point is that you just don't know.",
  "translatedText": "Der Punkt ist, dass Sie es einfach nicht wissen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.48,
  "end": 20.2
 },
 {
  "input": "But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads.",
  "translatedText": "Aber stellen Sie sich vor, Sie werfen diese Münze 10 Mal, und 7 Mal davon kommt „Kopf“ heraus.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.78,
  "end": 25.58
 },
 {
  "input": "Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads?",
  "translatedText": "Glauben Sie, dass das zugrunde liegende Gewicht dieser Münze so groß ist, dass bei jedem Wurf eine Wahrscheinlichkeit von 70 % besteht, dass sie Kopf ergibt?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 25.58,
  "end": 32.02
 },
 {
  "input": "If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say?",
  "translatedText": "Wenn ich Sie fragen würde, wie hoch ist die Wahrscheinlichkeit, dass die wahre Wahrscheinlichkeit, den Kopf zu drehen, 0 ist?7, was würdest du sagen?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.76,
  "end": 39.62
 },
 {
  "input": "This is a pretty weird question, and for two reasons.",
  "translatedText": "Das ist eine ziemlich seltsame Frage, und zwar aus zwei Gründen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.54,
  "end": 44.22
 },
 {
  "input": "First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about.",
  "translatedText": "Zunächst geht es um die Frage nach der Wahrscheinlichkeit einer Wahrscheinlichkeit, denn der Wert, den wir nicht kennen, ist selbst eine Art langfristige Häufigkeit für ein zufälliges Ereignis, über das man ehrlich gesagt nur schwer nachdenken kann.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.7,
  "end": 55.72
 },
 {
  "input": "But the more pressing weirdness comes from asking about probabilities in the setting of continuous values.",
  "translatedText": "Die dringlichere Seltsamkeit ergibt sich jedoch aus der Frage nach Wahrscheinlichkeiten bei der Festlegung kontinuierlicher Werte.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.28,
  "end": 61.28
 },
 {
  "input": "Let's give this unknown probability of flipping heads some kind of name, like h.",
  "translatedText": "Geben wir dieser unbekannten Wahrscheinlichkeit, Köpfe umzudrehen, einen Namen, etwa h.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.54,
  "end": 66.78
 },
 {
  "input": "Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads, and everything in between.",
  "translatedText": "Bedenken Sie, dass h jede reelle Zahl von 0 bis 1 sein kann, von einer Münze, die immer „Zahl“ wirft, bis zu einer Münze, die immer „Kopf“ wirft, und alles dazwischen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.54,
  "end": 77.32
 },
 {
  "input": "So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.700000001, or any other nearby value, there's going to be a strong possibility for paradox if we're not careful.",
  "translatedText": "Wenn ich also frage: Wie hoch ist die Wahrscheinlichkeit, dass h genau 0 ist?7, im Gegensatz zu beispielsweise 0. B.700000001 oder einen anderen Wert in der Nähe, besteht die starke Möglichkeit eines Paradoxons, wenn wir nicht aufpassen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.72,
  "end": 94.16
 },
 {
  "input": "It feels like no matter how small the answer to this question, it just wouldn't be small enough.",
  "translatedText": "Es fühlt sich so an, als ob die Antwort auf diese Frage, egal wie klein sie auch sein mag, einfach nicht klein genug wäre.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.86,
  "end": 99.16
 },
 {
  "input": "If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, even if that probability was miniscule, adding them all up to get the total probability of any one of these values will blow up to infinity.",
  "translatedText": "Wenn jeder spezifische Wert innerhalb eines bestimmten Bereichs, von denen es unzählige unendlich viele gibt, eine Wahrscheinlichkeit ungleich Null hat, selbst wenn diese Wahrscheinlichkeit winzig wäre, würde die Addition aller Werte, um die Gesamtwahrscheinlichkeit eines dieser Werte zu erhalten, auf Unendlich explodieren.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.94,
  "end": 114.26
 },
 {
  "input": "On the other hand, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1.",
  "translatedText": "Wenn andererseits alle diese Wahrscheinlichkeiten 0 sind, wäre die Gesamtsumme dieser Wahrscheinlichkeiten 0, obwohl sie 1 sein sollte, abgesehen davon, dass Sie dadurch keine nützlichen Informationen über die Münze erhalten.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.86,
  "end": 127.66
 },
 {
  "input": "After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1.",
  "translatedText": "Schließlich ist dieses Gewicht der Münze h etwas, daher sollte die Wahrscheinlichkeit, dass es sich um einen dieser Werte handelt, 1 ergeben.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.54,
  "end": 136.44
 },
 {
  "input": "So if these values can't all be non-zero, and they can't all be 0, what do you do?",
  "translatedText": "Wenn diese Werte also nicht alle ungleich Null sein können und nicht alle 0 sein können, was tun Sie dann?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.32,
  "end": 142.22
 },
 {
  "input": "Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions.",
  "translatedText": "Was wir hiermit erreichen wollen ist übrigens, dass ich über die sehr praktische Frage der Verwendung von Daten sprechen möchte, um aussagekräftige Antworten auf diese Art von Wahrscheinlichkeitsfragen zu finden.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.8,
  "end": 154.6
 },
 {
  "input": "But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox.",
  "translatedText": "Aber nehmen wir uns für dieses Video einen Moment Zeit, um zu verstehen, wie man mit Wahrscheinlichkeiten über kontinuierlichen Werten arbeitet und dieses scheinbare Paradoxon löst.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 155.68,
  "end": 162.78
 },
 {
  "input": "The key is not to focus on individual values, but ranges of values.",
  "translatedText": "Der Schlüssel liegt nicht darin, sich auf einzelne Werte zu konzentrieren, sondern auf Wertebereiche.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.32,
  "end": 173.96
 },
 {
  "input": "For example, we might make these buckets to represent the probability that h is between, say 0.8 and 0.85.",
  "translatedText": "Beispielsweise könnten wir diese Buckets so gestalten, dass sie die Wahrscheinlichkeit darstellen, dass h zwischen, sagen wir, 0 liegt.8 und 0.85.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.62,
  "end": 182.16
 },
 {
  "input": "Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability.",
  "translatedText": "Und das ist wichtiger, als es den Anschein hat: Anstatt sich die Höhe jedes dieser Balken als Repräsentant der Wahrscheinlichkeit vorzustellen, sollten Sie sich die Fläche jedes Balkens als Repräsentant dieser Wahrscheinlichkeit vorstellen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.16,
  "end": 193.04
 },
 {
  "input": "Where exactly those areas come from is something we'll answer later.",
  "translatedText": "Wo genau diese Bereiche herkommen, werden wir später beantworten.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.96,
  "end": 197.48
 },
 {
  "input": "For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges.",
  "translatedText": "Im Moment müssen Sie nur wissen, dass es im Prinzip eine Antwort auf die Wahrscheinlichkeit gibt, dass h in einem dieser Bereiche liegt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.96,
  "end": 204.14
 },
 {
  "input": "Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input.",
  "translatedText": "Unsere Aufgabe besteht derzeit darin, Antworten auf diese sehr grobkörnigen Fragen zu finden und ein genaueres Verständnis der Verteilung auf der Ebene jedes einzelnen Inputs zu erlangen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.96,
  "end": 214.56
 },
 {
  "input": "The natural thing to do is to consider finer and finer buckets, and when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same.",
  "translatedText": "Es ist natürlich, immer feinere Eimer in Betracht zu ziehen, und wenn Sie das tun, ist die geringere Wahrscheinlichkeit, in einen von ihnen zu fallen, auf die geringere Breite jedes dieser Balken zurückzuführen, während die Höhen ungefähr gleich bleiben Dasselbe.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.46,
  "end": 228.92
 },
 {
  "input": "That's important because it means that as you take this process to the limit, you approach some kind of smooth curve.",
  "translatedText": "Das ist wichtig, denn wenn man diesen Prozess bis an die Grenzen ausreizt, nähert man sich einer Art sanfter Kurve.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.66,
  "end": 235.22
 },
 {
  "input": "So even though all of the individual probabilities of falling into any one particular bucket will approach 0, the overall shape of the distribution is preserved, and even refined in this limit.",
  "translatedText": "Auch wenn also alle einzelnen Wahrscheinlichkeiten, in einen bestimmten Bereich zu fallen, gegen 0 gehen, bleibt die Gesamtform der Verteilung erhalten und wird in diesem Grenzwert sogar verfeinert.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 235.9,
  "end": 247.22
 },
 {
  "input": "If we had let the heights of the bars represent probabilities, everything would have gone to 0.",
  "translatedText": "Hätten wir die Höhen der Balken als Wahrscheinlichkeiten dargestellt, wäre alles auf 0 gegangen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.7,
  "end": 254.9
 },
 {
  "input": "So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution.",
  "translatedText": "Im Grenzfall hätten wir also nur eine flache Linie gehabt, die keine Informationen über die Gesamtform der Verteilung gegeben hätte.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 260.04,
  "end": 265.64
 },
 {
  "input": "So wonderful, letting area represent probability helps solve this problem.",
  "translatedText": "Es ist wunderbar, dass die Darstellung der Wahrscheinlichkeit durch die Fläche zur Lösung dieses Problems beiträgt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 267.42,
  "end": 271.26
 },
 {
  "input": "But let me ask you, if the y-axis no longer represents probability, what exactly are the units here?",
  "translatedText": "Aber ich frage Sie: Wenn die Y-Achse nicht mehr die Wahrscheinlichkeit darstellt, welche genauen Einheiten gibt es hier?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 271.9,
  "end": 277.14
 },
 {
  "input": "Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density.",
  "translatedText": "Da die Wahrscheinlichkeit im Bereich dieser Balken liegt, also Breite mal Höhe, stellt die Höhe eine Art Wahrscheinlichkeit pro Einheit in x-Richtung dar, was in der Fachwelt als Wahrscheinlichkeitsdichte bezeichnet wird.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.8,
  "end": 289.64
 },
 {
  "input": "The other thing to keep in mind is that the total area of all these bars has to equal 1 at every level of the process.",
  "translatedText": "Beachten Sie außerdem, dass die Gesamtfläche aller dieser Balken auf jeder Ebene des Prozesses gleich 1 sein muss.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.58,
  "end": 296.54
 },
 {
  "input": "That's something that has to be true for any valid probability distribution.",
  "translatedText": "Das muss für jede gültige Wahrscheinlichkeitsverteilung zutreffen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.06,
  "end": 300.5
 },
 {
  "input": "The idea of probability density is actually really clever when you step back to think about it.",
  "translatedText": "Die Idee der Wahrscheinlichkeitsdichte ist tatsächlich wirklich clever, wenn man einen Schritt zurücktritt und darüber nachdenkt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.98,
  "end": 306.3
 },
 {
  "input": "As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short.",
  "translatedText": "Wenn man bis an die Grenzen geht, gibt es kein Problem, wenn wir jedem von ihnen eine Wahrscheinlichkeitsdichte zuordnen, auch wenn es allerlei Paradoxien mit sich bringt, jedem dieser unzähligen Werte von h zwischen 0 und 1 eine Wahrscheinlichkeit zuzuordnen. Daraus ergibt sich eine sogenannte Wahrscheinlichkeitsdichtefunktion, kurz PDF.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.3,
  "end": 325.64
 },
 {
  "input": "Any time you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values.",
  "translatedText": "Jedes Mal, wenn Sie ein PDF in freier Wildbahn sehen, können Sie es so interpretieren, dass die Wahrscheinlichkeit, dass Ihre Zufallsvariable zwischen zwei Werten liegt, der Fläche unter dieser Kurve zwischen diesen Werten entspricht.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 326.42,
  "end": 337.52
 },
 {
  "input": "So, for example, what's the probability of getting any one very specific number, like 0.7?",
  "translatedText": "Wie hoch ist beispielsweise die Wahrscheinlichkeit, eine ganz bestimmte Zahl zu erhalten, beispielsweise 0?7?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.22,
  "end": 343.46
 },
 {
  "input": "Well, the area of an infinitely thin slice is 0, so it's 0.",
  "translatedText": "Nun, die Fläche einer unendlich dünnen Scheibe ist 0, also ist sie 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.22,
  "end": 348.34
 },
 {
  "input": "What's the probability of all of them put together?",
  "translatedText": "Wie hoch ist die Wahrscheinlichkeit, dass sie alle zusammenkommen?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.9,
  "end": 351.14
 },
 {
  "input": "Well, the area under the full curve is 1.",
  "translatedText": "Nun, die Fläche unter der Vollkurve beträgt 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.78,
  "end": 353.96
 },
 {
  "input": "You see?",
  "translatedText": "Siehst du?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 354.62,
  "end": 354.92
 },
 {
  "input": "Paradox sidestepped.",
  "translatedText": "Paradox wurde umgangen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.72,
  "end": 356.4
 },
 {
  "input": "And the way that it's been sidestepped is a bit subtle.",
  "translatedText": "Und die Art und Weise, wie es umgangen wurde, ist etwas subtil.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.5,
  "end": 360.22
 },
 {
  "input": "In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them.",
  "translatedText": "In normalen, endlichen Situationen, wie beim Würfeln oder Ziehen einer Karte, ist die Wahrscheinlichkeit, dass ein Zufallswert in eine gegebene Sammlung von Möglichkeiten fällt, einfach die Summe der Wahrscheinlichkeiten, eine davon zu sein.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.22,
  "end": 372.96
 },
 {
  "input": "This feels very intuitive, it's even true in a countably infinite context.",
  "translatedText": "Das fühlt sich sehr intuitiv an, es trifft sogar in einem zählbar unendlichen Kontext zu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 373.84,
  "end": 377.6
 },
 {
  "input": "But to deal with the continuum, the rules themselves have shifted.",
  "translatedText": "Aber um dem Kontinuum gerecht zu werden, haben sich die Regeln selbst verschoben.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.12,
  "end": 381.54
 },
 {
  "input": "The probability of falling into a range of values is no longer the sum of the probabilities of each individual value.",
  "translatedText": "Die Wahrscheinlichkeit, in einen Wertebereich zu fallen, ist nicht mehr die Summe der Wahrscheinlichkeiten jedes einzelnen Wertes.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.1,
  "end": 388.66
 },
 {
  "input": "Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0.",
  "translatedText": "Stattdessen sind mit Bereichen verbundene Wahrscheinlichkeiten die grundlegenden primitiven Objekte, und der einzige Sinn, in dem es hier sinnvoll ist, über einen einzelnen Wert zu sprechen, besteht darin, ihn sich als einen Bereich mit der Breite 0 vorzustellen.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.18,
  "end": 401.22
 },
 {
  "input": "If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well you'll be happy to know that mathematicians are way ahead of you.",
  "translatedText": "Wenn die Vorstellung, dass sich die Regeln zwischen einer endlichen und einer kontinuierlichen Umgebung ändern, beunruhigend ist, dann werden Sie froh sein zu wissen, dass die Mathematiker Ihnen weit voraus sind.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.18,
  "end": 410.4
 },
 {
  "input": "There's a field of math called measure theory which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely.",
  "translatedText": "Es gibt ein Fachgebiet der Mathematik namens Maßtheorie, das dabei hilft, diese beiden Einstellungen zu vereinen und die Idee, Zahlen wie Wahrscheinlichkeiten verschiedenen Teilmengen aller Möglichkeiten auf eine Weise zuzuordnen, die eine gute Kombination und Verteilung ermöglicht, rigoros zu gestalten.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 410.82,
  "end": 423.14
 },
 {
  "input": "For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve.",
  "translatedText": "Nehmen wir zum Beispiel an, Sie befinden sich in einer Situation, in der Sie eine Zufallszahl haben, die mit einer Wahrscheinlichkeit von 50 % gleich 0 ist, und in der übrigen Zeit handelt es sich um eine positive Zahl entsprechend einer Verteilung, die wie eine halbe Glockenkurve aussieht.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.04,
  "end": 435.88
 },
 {
  "input": "This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one, where probabilities are found according to areas under the appropriate density function.",
  "translatedText": "Dies ist ein schwieriger Mittelweg zwischen einem endlichen Kontext, in dem ein einzelner Wert eine Wahrscheinlichkeit ungleich Null hat, und einem kontinuierlichen Kontext, in dem Wahrscheinlichkeiten entsprechend den Flächen unter der entsprechenden Dichtefunktion gefunden werden.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 436.48,
  "end": 448.68
 },
 {
  "input": "This is the sort of thing that measure theory handles very smoothly.",
  "translatedText": "So etwas meistert die Maßtheorie sehr reibungslos.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.46,
  "end": 452.6
 },
 {
  "input": "I mention this mainly for the especially curious viewer, and you can find more reading material in the description.",
  "translatedText": "Ich erwähne dies hauptsächlich für den besonders neugierigen Betrachter, und Sie können in der Beschreibung weiteren Lesestoff finden.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.04,
  "end": 458.12
 },
 {
  "input": "It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves.",
  "translatedText": "Es ist eine weit verbreitete Faustregel: Wenn Sie eine Summe in einem diskreten Kontext verwenden, dann verwenden Sie ein Integral im kontinuierlichen Kontext. Dies ist das Werkzeug aus der Analysis, mit dem wir Flächen unter Kurven ermitteln.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.62,
  "end": 471.8
 },
 {
  "input": "In fact, you could argue this video would be way shorter if I just said that at the front and called it good.",
  "translatedText": "Tatsächlich könnte man argumentieren, dass dieses Video viel kürzer wäre, wenn ich das nur am Anfang sagen und es als gut bezeichnen würde.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.8,
  "end": 477.04
 },
 {
  "input": "For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means.",
  "translatedText": "Ich für meinen Teil fand es jedoch immer ein wenig unbefriedigend, dies blind zu tun, ohne darüber nachzudenken, was es wirklich bedeutet.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 477.76,
  "end": 483.28
 },
 {
  "input": "And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate, more powerful definition that's based on measure theory, this formal foundation of probability.",
  "translatedText": "Und tatsächlich, wenn man sich eingehend mit den theoretischen Grundlagen von Integralen befasst, wird man feststellen, dass es zusätzlich zu der Art und Weise, wie es in einem typischen Einführungskurs in Analysis definiert wird, eine separate, aussagekräftigere Definition gibt, die auf der Maßtheorie basiert , diese formale Grundlage der Wahrscheinlichkeit.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.08,
  "end": 499.02
 },
 {
  "input": "If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow all together they have a probability of one.",
  "translatedText": "Wenn ich auf die Zeit zurückblicke, als ich zum ersten Mal Wahrscheinlichkeitsrechnung gelernt habe, erinnere ich mich noch gut daran, wie ich mich mit der seltsamen Idee auseinandergesetzt habe, dass es in kontinuierlichen Situationen, wie Zufallsvariablen, die reelle Zahlen sind, oder dem Werfen eines Pfeils auf eine Dartscheibe, eine Reihe möglicher Ergebnisse gibt, und Dennoch hat jede einzelne eine Wahrscheinlichkeit von Null, und irgendwie haben sie alle zusammen eine Wahrscheinlichkeit von eins.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.28,
  "end": 519.56
 },
 {
  "input": "One step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me.",
  "translatedText": "Ein Schritt, um damit klarzukommen, besteht darin, zu erkennen, dass die Möglichkeit besser an die Wahrscheinlichkeitsdichte als an die Wahrscheinlichkeit gebunden ist, aber der bloße Austausch der Summen von einem durch Integrale der anderen hat mich nie ganz gereizt.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.82,
  "end": 532.82
 },
 {
  "input": "I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all.",
  "translatedText": "Ich erinnere mich, dass es erst richtig Klick gemacht hat, als mir klar wurde, dass die Regeln für die Kombination von Wahrscheinlichkeiten verschiedener Mengen nicht ganz meinen Vorstellungen entsprachen und dem Ganzen einfach ein anderes Axiomensystem zugrunde lag.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.28,
  "end": 543.24
 },
 {
  "input": "But anyway, steering away from the theory somewhere back in the loose direction of application, let's look back to our original question about the coin with an unknown weight.",
  "translatedText": "Aber wie dem auch sei, lassen Sie uns von der Theorie irgendwo weg und zurück in die lockere Richtung der Anwendung blicken und auf unsere ursprüngliche Frage nach der Münze mit unbekanntem Gewicht zurückblicken.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.58,
  "end": 552.44
 },
 {
  "input": "What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses?",
  "translatedText": "Was wir hier gelernt haben, ist, dass die richtige Frage lautet: Wie lautet die Wahrscheinlichkeitsdichtefunktion, die diesen Wert h beschreibt, nachdem wir die Ergebnisse einiger Würfe gesehen haben?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.96,
  "end": 562.96
 },
 {
  "input": "If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8?",
  "translatedText": "Wenn Sie dieses PDF finden, können Sie damit Fragen beantworten wie: Wie hoch ist die Wahrscheinlichkeit, dass die wahre Wahrscheinlichkeit, den Kopf umzudrehen, zwischen 0 und 0 liegt?6 und 0.8?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.46,
  "end": 572.8
 },
 {
  "input": "To find that PDF, join me in the next part.",
  "translatedText": "Um dieses PDF zu finden, folgen Sie mir im nächsten Teil.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.68,
  "end": 576.06
 }
]