[
 {
  "input": "Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly.",
  "translatedText": "Представьте, что у вас есть взвешенная монета, поэтому вероятность выпадения орла может быть не совсем 50 на 50.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.8,
  "end": 8.68
 },
 {
  "input": "It could be 20%, or maybe 90%, or 0%, or 31.41592%.",
  "translatedText": "Это может быть 20%, а может быть, 90%, или 0%, или 31.41592%.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 9.14,
  "end": 18.48
 },
 {
  "input": "The point is that you just don't know.",
  "translatedText": "Дело в том, что вы просто не знаете.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.48,
  "end": 20.2
 },
 {
  "input": "But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads.",
  "translatedText": "Но представьте, что вы подбрасываете эту монету 10 раз, и в 7 из них выпадает орел.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.78,
  "end": 25.58
 },
 {
  "input": "Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads?",
  "translatedText": "Считаете ли вы, что основной вес этой монеты таков, что при каждом подбрасывании вероятность выпадения орла составляет 70%?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 25.58,
  "end": 32.02
 },
 {
  "input": "If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say?",
  "translatedText": "Если бы я спросил вас, эй, какова вероятность того, что истинная вероятность выпадения орла равна 0.7, что бы ты сказал?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.76,
  "end": 39.62
 },
 {
  "input": "This is a pretty weird question, and for two reasons.",
  "translatedText": "Это довольно странный вопрос, и по двум причинам.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.54,
  "end": 44.22
 },
 {
  "input": "First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about.",
  "translatedText": "Прежде всего, речь идет о вероятности вероятности, поскольку неизвестное нам значение само по себе является своего рода долгосрочной частотой случайного события, о котором, честно говоря, трудно подумать.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.7,
  "end": 55.72
 },
 {
  "input": "But the more pressing weirdness comes from asking about probabilities in the setting of continuous values.",
  "translatedText": "Но еще более серьезная странность связана с вопросом о вероятностях при установке непрерывных значений.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.28,
  "end": 61.28
 },
 {
  "input": "Let's give this unknown probability of flipping heads some kind of name, like h.",
  "translatedText": "Давайте дадим этой неизвестной вероятности выпадения головы какое-нибудь имя, например h.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.54,
  "end": 66.78
 },
 {
  "input": "Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads, and everything in between.",
  "translatedText": "Имейте в виду, что h может быть любым действительным числом от 0 до 1, начиная от монеты, у которой всегда выпадает решка, до монеты, у которой всегда выпадает решка, и всего, что между ними.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.54,
  "end": 77.32
 },
 {
  "input": "So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.700000001, or any other nearby value, there's going to be a strong possibility for paradox if we're not careful.",
  "translatedText": "Итак, если я спрошу: «Эй, какова вероятность того, что h равно 0».7, а не, скажем, 0.700000001 или любое другое близкое значение, если мы не будем осторожны, возникнет большая вероятность парадокса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.72,
  "end": 94.16
 },
 {
  "input": "It feels like no matter how small the answer to this question, it just wouldn't be small enough.",
  "translatedText": "Такое ощущение, что каким бы маленьким ни был ответ на этот вопрос, он все равно будет недостаточно маленьким.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.86,
  "end": 99.16
 },
 {
  "input": "If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, even if that probability was miniscule, adding them all up to get the total probability of any one of these values will blow up to infinity.",
  "translatedText": "Если каждое конкретное значение в некотором диапазоне, а их всех неисчислимо бесконечно много, имеет ненулевую вероятность, даже если эта вероятность была ничтожной, то сложение их всех для получения общей вероятности любого из этих значений увеличится до бесконечности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.94,
  "end": 114.26
 },
 {
  "input": "On the other hand, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1.",
  "translatedText": "С другой стороны, если все эти вероятности равны 0, не считая того факта, что это теперь не дает вам никакой полезной информации о монете, общая сумма этих вероятностей будет равна 0, тогда как должна быть 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.86,
  "end": 127.66
 },
 {
  "input": "After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1.",
  "translatedText": "В конце концов, вес монеты h — это что-то, поэтому вероятность того, что это какое-либо из этих значений, в сумме должна составлять 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.54,
  "end": 136.44
 },
 {
  "input": "So if these values can't all be non-zero, and they can't all be 0, what do you do?",
  "translatedText": "Итак, если все эти значения не могут быть ненулевыми и не могут все быть равными 0, что делать?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.32,
  "end": 142.22
 },
 {
  "input": "Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions.",
  "translatedText": "Кстати, мы собираемся поговорить об очень практическом вопросе использования данных для создания значимых ответов на такого рода вопросы о вероятностях вероятностей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.8,
  "end": 154.6
 },
 {
  "input": "But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox.",
  "translatedText": "Но в этом видео давайте на минутку поймем, как работать с вероятностями над непрерывными значениями, и разрешим этот очевидный парадокс.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 155.68,
  "end": 162.78
 },
 {
  "input": "The key is not to focus on individual values, but ranges of values.",
  "translatedText": "Ключевым моментом является сосредоточение внимания не на отдельных ценностях, а на диапазонах ценностей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.32,
  "end": 173.96
 },
 {
  "input": "For example, we might make these buckets to represent the probability that h is between, say 0.8 and 0.85.",
  "translatedText": "Например, мы могли бы сделать эти сегменты для представления вероятности того, что h находится между, скажем, 0.8 и 0.85.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.62,
  "end": 182.16
 },
 {
  "input": "Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability.",
  "translatedText": "Кроме того, и это более важно, чем может показаться, вместо того, чтобы думать о высоте каждой из этих полосок как о представляющей вероятность, подумайте о площади каждой из них как о представляющей эту вероятность.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.16,
  "end": 193.04
 },
 {
  "input": "Where exactly those areas come from is something we'll answer later.",
  "translatedText": "Откуда именно взялись эти области, мы ответим позже.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.96,
  "end": 197.48
 },
 {
  "input": "For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges.",
  "translatedText": "А пока просто знайте, что в принципе существует некоторый ответ на вероятность того, что h будет находиться внутри одного из этих диапазонов.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.96,
  "end": 204.14
 },
 {
  "input": "Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input.",
  "translatedText": "Наша задача сейчас — взять ответы на эти очень общие вопросы и получить более точное представление о распределении на уровне каждого отдельного входа.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.96,
  "end": 214.56
 },
 {
  "input": "The natural thing to do is to consider finer and finer buckets, and when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same.",
  "translatedText": "Естественно, что следует рассматривать все более тонкие ведра, и когда вы это сделаете, меньшая вероятность попасть в любое из них объясняется уменьшением ширины каждого из этих брусков, в то время как высота останется примерно такой же. такой же.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.46,
  "end": 228.92
 },
 {
  "input": "That's important because it means that as you take this process to the limit, you approach some kind of smooth curve.",
  "translatedText": "Это важно, потому что это означает, что, доведя этот процесс до предела, вы приближаетесь к какой-то плавной кривой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.66,
  "end": 235.22
 },
 {
  "input": "So even though all of the individual probabilities of falling into any one particular bucket will approach 0, the overall shape of the distribution is preserved, and even refined in this limit.",
  "translatedText": "Таким образом, даже несмотря на то, что все отдельные вероятности попадания в какой-либо конкретный блок будут приближаться к 0, общая форма распределения сохраняется и даже уточняется в этом пределе.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 235.9,
  "end": 247.22
 },
 {
  "input": "If we had let the heights of the bars represent probabilities, everything would have gone to 0.",
  "translatedText": "Если бы мы позволили высотам столбцов обозначать вероятности, все превратилось бы в 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.7,
  "end": 254.9
 },
 {
  "input": "So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution.",
  "translatedText": "Таким образом, в пределе у нас была бы просто плоская линия, не дающая никакой информации об общей форме распределения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 260.04,
  "end": 265.64
 },
 {
  "input": "So wonderful, letting area represent probability helps solve this problem.",
  "translatedText": "Замечательно, что если площадь представляет собой вероятность, это помогает решить эту проблему.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 267.42,
  "end": 271.26
 },
 {
  "input": "But let me ask you, if the y-axis no longer represents probability, what exactly are the units here?",
  "translatedText": "Но позвольте мне спросить вас: если ось Y больше не представляет вероятность, какие именно единицы здесь используются?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 271.9,
  "end": 277.14
 },
 {
  "input": "Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density.",
  "translatedText": "Поскольку вероятность находится в области этих столбцов или ширины, умноженной на высоту, высота представляет собой своего рода вероятность на единицу в направлении x, что в бизнесе известно как плотность вероятности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.8,
  "end": 289.64
 },
 {
  "input": "The other thing to keep in mind is that the total area of all these bars has to equal 1 at every level of the process.",
  "translatedText": "Еще следует иметь в виду, что общая площадь всех этих столбцов должна равняться 1 на каждом уровне процесса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.58,
  "end": 296.54
 },
 {
  "input": "That's something that has to be true for any valid probability distribution.",
  "translatedText": "Это то, что должно быть верно для любого допустимого распределения вероятностей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.06,
  "end": 300.5
 },
 {
  "input": "The idea of probability density is actually really clever when you step back to think about it.",
  "translatedText": "Идея плотности вероятности на самом деле очень умна, если задуматься.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.98,
  "end": 306.3
 },
 {
  "input": "As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short.",
  "translatedText": "Когда вы доводите дело до предела, даже если существуют всевозможные парадоксы, связанные с присвоением вероятности каждому из этих несчетно-бесконечно многих значений h между 0 и 1, не будет проблем, если мы свяжем плотность вероятности с каждым из них: давая так называемую функцию плотности вероятности, или сокращенно PDF.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.3,
  "end": 325.64
 },
 {
  "input": "Any time you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values.",
  "translatedText": "Каждый раз, когда вы видите PDF-файл в реальном виде, его можно интерпретировать следующим образом: вероятность того, что ваша случайная величина находится между двумя значениями, равна площади под этой кривой между этими значениями.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 326.42,
  "end": 337.52
 },
 {
  "input": "So, for example, what's the probability of getting any one very specific number, like 0.7?",
  "translatedText": "Так, например, какова вероятность получить какое-то одно очень конкретное число, например 0.7?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.22,
  "end": 343.46
 },
 {
  "input": "Well, the area of an infinitely thin slice is 0, so it's 0.",
  "translatedText": "Ну, площадь бесконечно тонкого среза равна 0, значит, она 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.22,
  "end": 348.34
 },
 {
  "input": "What's the probability of all of them put together?",
  "translatedText": "Какова вероятность того, что они все вместе взятые?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.9,
  "end": 351.14
 },
 {
  "input": "Well, the area under the full curve is 1.",
  "translatedText": "Итак, площадь под полной кривой равна 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.78,
  "end": 353.96
 },
 {
  "input": "You see?",
  "translatedText": "Понимаете?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 354.62,
  "end": 354.92
 },
 {
  "input": "Paradox sidestepped.",
  "translatedText": "Парадокс отошел в сторону.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.72,
  "end": 356.4
 },
 {
  "input": "And the way that it's been sidestepped is a bit subtle.",
  "translatedText": "И то, как это обошли, немного тонкое.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.5,
  "end": 360.22
 },
 {
  "input": "In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them.",
  "translatedText": "В обычных, конечных ситуациях, таких как бросок кубика или вытягивание карты, вероятность того, что случайное значение попадает в заданный набор возможностей, представляет собой просто сумму вероятностей попадания в любую из них.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.22,
  "end": 372.96
 },
 {
  "input": "This feels very intuitive, it's even true in a countably infinite context.",
  "translatedText": "Это кажется очень интуитивным, это верно даже в счетно бесконечном контексте.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 373.84,
  "end": 377.6
 },
 {
  "input": "But to deal with the continuum, the rules themselves have shifted.",
  "translatedText": "Но чтобы иметь дело с континуумом, сами правила изменились.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.12,
  "end": 381.54
 },
 {
  "input": "The probability of falling into a range of values is no longer the sum of the probabilities of each individual value.",
  "translatedText": "Вероятность попадания в диапазон значений больше не является суммой вероятностей каждого отдельного значения.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.1,
  "end": 388.66
 },
 {
  "input": "Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0.",
  "translatedText": "Вместо этого вероятности, связанные с диапазонами, являются фундаментальными примитивными объектами, и единственный смысл говорить здесь об отдельном значении — это думать о нем как о диапазоне шириной 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.18,
  "end": 401.22
 },
 {
  "input": "If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well you'll be happy to know that mathematicians are way ahead of you.",
  "translatedText": "Если идея изменения правил между конечными и непрерывными условиями кажется вам тревожной, вы будете рады узнать, что математики намного опередили вас.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.18,
  "end": 410.4
 },
 {
  "input": "There's a field of math called measure theory which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely.",
  "translatedText": "Существует область математики, называемая теорией меры, которая помогает объединить эти два параметра и сделать более строгой идею связывания чисел, таких как вероятности, с различными подмножествами всех возможностей таким образом, чтобы они хорошо сочетались и распределялись.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 410.82,
  "end": 423.14
 },
 {
  "input": "For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve.",
  "translatedText": "Например, предположим, что вы находитесь в ситуации, когда у вас есть случайное число, равное 0 с вероятностью 50%, а в остальное время это какое-то положительное число в соответствии с распределением, которое выглядит как половина колоколообразной кривой.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.04,
  "end": 435.88
 },
 {
  "input": "This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one, where probabilities are found according to areas under the appropriate density function.",
  "translatedText": "Это неудобная золотая середина между конечным контекстом, где единственное значение имеет ненулевую вероятность, и непрерывным контекстом, где вероятности находятся в соответствии с областями под соответствующей функцией плотности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 436.48,
  "end": 448.68
 },
 {
  "input": "This is the sort of thing that measure theory handles very smoothly.",
  "translatedText": "С такими вещами теория меры справляется очень гладко.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.46,
  "end": 452.6
 },
 {
  "input": "I mention this mainly for the especially curious viewer, and you can find more reading material in the description.",
  "translatedText": "Я упоминаю об этом в основном для особо любопытных зрителей, а больше материала для чтения вы можете найти в описании.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.04,
  "end": 458.12
 },
 {
  "input": "It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves.",
  "translatedText": "Это довольно распространенное практическое правило: если вы используете сумму в дискретном контексте, тогда используйте интеграл в непрерывном контексте, который является инструментом исчисления, который мы используем для поиска площадей под кривыми.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.62,
  "end": 471.8
 },
 {
  "input": "In fact, you could argue this video would be way shorter if I just said that at the front and called it good.",
  "translatedText": "На самом деле, вы могли бы утверждать, что это видео было бы намного короче, если бы я просто сказал это вначале и назвал его хорошим.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.8,
  "end": 477.04
 },
 {
  "input": "For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means.",
  "translatedText": "Однако мне всегда было немного неприятно делать это вслепую, не обдумывая, что это на самом деле означает.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 477.76,
  "end": 483.28
 },
 {
  "input": "And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate, more powerful definition that's based on measure theory, this formal foundation of probability.",
  "translatedText": "И на самом деле, если вы действительно углубитесь в теоретические основы интегралов, вы обнаружите, что в дополнение к тому, как они определяются на типичном вводном курсе по исчислению, существует отдельное, более мощное определение, основанное на теории меры. , это формальное основание вероятности.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.08,
  "end": 499.02
 },
 {
  "input": "If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow all together they have a probability of one.",
  "translatedText": "Если я оглянусь назад, когда я впервые изучил вероятность, я определенно помню, как боролся с этой странной идеей о том, что в непрерывных условиях, таких как случайные величины, которые являются действительными числами, или бросание дротика в мишень, у вас есть множество возможных результатов, и однако вероятность каждого из них равна нулю, а все вместе почему-то имеют вероятность единицы.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.28,
  "end": 519.56
 },
 {
  "input": "One step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me.",
  "translatedText": "Один из шагов, чтобы смириться с этим, — это осознать, что вероятность лучше связана с плотностью вероятности, чем с вероятностью, но простая замена сумм одного на интегралы от других никогда не утоляла меня.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.82,
  "end": 532.82
 },
 {
  "input": "I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all.",
  "translatedText": "Помню, что по-настоящему меня осенило только тогда, когда я понял, что правила объединения вероятностей разных множеств оказались не совсем такими, как я думал, и что в основе всего этого лежала другая система аксиом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.28,
  "end": 543.24
 },
 {
  "input": "But anyway, steering away from the theory somewhere back in the loose direction of application, let's look back to our original question about the coin with an unknown weight.",
  "translatedText": "Но в любом случае, отойдя от теории куда-то назад в сторону свободного применения, вернемся к нашему исходному вопросу о монете неизвестного веса.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.58,
  "end": 552.44
 },
 {
  "input": "What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses?",
  "translatedText": "Здесь мы узнали, что правильный вопрос: какова функция плотности вероятности, которая описывает это значение h после просмотра результатов нескольких бросков?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.96,
  "end": 562.96
 },
 {
  "input": "If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8?",
  "translatedText": "Если вы сможете найти этот PDF-файл, вы сможете использовать его, чтобы ответить на такие вопросы, как, какова вероятность того, что истинная вероятность того, что выпадет решка, упадет между 0.6 и 0.8?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.46,
  "end": 572.8
 },
 {
  "input": "To find that PDF, join me in the next part.",
  "translatedText": "Чтобы найти этот PDF-файл, присоединяйтесь ко мне в следующей части.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.68,
  "end": 576.06
 }
]