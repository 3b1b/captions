[
 {
  "input": "Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly. ",
  "translatedText": "কল্পনা করুন আপনার কাছে একটি ওজনযুক্ত মুদ্রা আছে, তাই মাথা উল্টানোর সম্ভাবনা ঠিক 50-50 নাও হতে পারে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 2.8,
  "end": 8.68
 },
 {
  "input": "It could be 20%, or maybe 90%, or 0%, or 31.41592%. ",
  "translatedText": "এটা হতে পারে 20%, অথবা হতে পারে 90%, অথবা 0%, অথবা 31.41592%।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 9.14,
  "end": 18.48
 },
 {
  "input": "The point is that you just don't know. ",
  "translatedText": "বিন্দু হল যে আপনি শুধু জানেন না. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.48,
  "end": 20.2
 },
 {
  "input": "But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads. ",
  "translatedText": "কিন্তু কল্পনা করুন যে আপনি এই মুদ্রাটি 10টি ভিন্ন বার উল্টান, এবং সেই সময়ের মধ্যে 7টি মাথায় আসে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 20.78,
  "end": 25.58
 },
 {
  "input": "Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads? ",
  "translatedText": "আপনি কি মনে করেন যে এই মুদ্রার অন্তর্নিহিত ওজন এমন যে প্রতিটি ফ্লিপের মাথা উপরে আসার 70% সম্ভাবনা রয়েছে? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 25.58,
  "end": 32.02
 },
 {
  "input": "If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say? ",
  "translatedText": "আমি যদি আপনাকে জিজ্ঞাসা করি, হেই, হেড ফ্লিপ করার সত্যিকারের সম্ভাবনা 0 এর সম্ভাবনা কত? 7, আপনি কি বলবেন? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 32.76,
  "end": 39.62
 },
 {
  "input": "This is a pretty weird question, and for two reasons. ",
  "translatedText": "এটি একটি বেশ অদ্ভুত প্রশ্ন, এবং দুটি কারণে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.54,
  "end": 44.22
 },
 {
  "input": "First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about. ",
  "translatedText": "প্রথমত, এটি একটি সম্ভাব্যতার সম্ভাব্যতা সম্পর্কে জিজ্ঞাসা করছে, কারণ আমরা জানি না যে মানটি একটি র্যান্ডম ইভেন্টের জন্য এক ধরণের দীর্ঘমেয়াদী ফ্রিকোয়েন্সি, যা সম্পর্কে চিন্তা করা কঠিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 44.7,
  "end": 55.72
 },
 {
  "input": "But the more pressing weirdness comes from asking about probabilities in the setting of continuous values. ",
  "translatedText": "কিন্তু ক্রমাগত মান নির্ধারণে সম্ভাব্যতা সম্পর্কে জিজ্ঞাসা করার ফলে আরও চাপা অদ্ভুততা আসে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.28,
  "end": 61.28
 },
 {
  "input": "Let's give this unknown probability of flipping heads some kind of name, like h. ",
  "translatedText": "মাথা উল্টানো এই অজানা সম্ভাবনা দেওয়া যাক কিছু নাম, যেমন h. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.54,
  "end": 66.78
 },
 {
  "input": "Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads, and everything in between. ",
  "translatedText": "মনে রাখবেন h 0 থেকে 1 পর্যন্ত যেকোনো বাস্তব সংখ্যা হতে পারে, একটি মুদ্রা থেকে শুরু করে যেটি সর্বদা মাথা উল্টে যায় এবং এর মধ্যে সবকিছু।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.54,
  "end": 77.32
 },
 {
  "input": "So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.700000001, or any other nearby value, there's going to be a strong possibility for paradox if we're not careful. ",
  "translatedText": "তাই যদি আমি জিজ্ঞাসা করি, আরে, h এর সম্ভাব্যতা কতটা সঠিকভাবে 0।7, এর বিপরীতে, বলুন, 0।700000001, বা অন্য কোন আশেপাশের মান, যদি আমরা সতর্ক না হই তবে প্যারাডক্সের একটি শক্তিশালী সম্ভাবনা হতে চলেছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.72,
  "end": 94.16
 },
 {
  "input": "It feels like no matter how small the answer to this question, it just wouldn't be small enough. ",
  "translatedText": "মনে হচ্ছে এই প্রশ্নের উত্তর যতই ছোট হোক না কেন, এটি যথেষ্ট ছোট হবে না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.86,
  "end": 99.16
 },
 {
  "input": "If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, even if that probability was miniscule, adding them all up to get the total probability of any one of these values will blow up to infinity. ",
  "translatedText": "যদি কিছু পরিসরের মধ্যে প্রতিটি নির্দিষ্ট মান, সবগুলোই অসীমভাবে অনেকের, একটি অ-শূন্য সম্ভাবনা থাকে, এমনকি যদি সেই সম্ভাবনাটি ক্ষুদ্রতর হয়, তাহলে এই মানের যেকোনো একটির মোট সম্ভাব্যতা পাওয়ার জন্য সেগুলিকে যোগ করলে তা অসীম পর্যন্ত উড়িয়ে দেবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.94,
  "end": 114.26
 },
 {
  "input": "On the other hand, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1. ",
  "translatedText": "অন্যদিকে, যদি এই সমস্ত সম্ভাবনাগুলি 0 হয়, এই সত্যটি বাদ দিয়ে যে এটি এখন আপনাকে মুদ্রা সম্পর্কে কোনও দরকারী তথ্য দেয় না, সেই সম্ভাব্যতার মোট যোগফল 0 হবে, যখন এটি 1 হওয়া উচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 115.86,
  "end": 127.66
 },
 {
  "input": "After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1. ",
  "translatedText": "সর্বোপরি, মুদ্রা h এর এই ওজন কিছু, তাই এই মানের যেকোনো একটি হওয়ার সম্ভাবনা 1 পর্যন্ত যোগ করা উচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.54,
  "end": 136.44
 },
 {
  "input": "So if these values can't all be non-zero, and they can't all be 0, what do you do? ",
  "translatedText": "তাই যদি এই মান সব অ-শূন্য হতে পারে না, এবং তারা সব 0 হতে পারে না, আপনি কি করবেন? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.32,
  "end": 142.22
 },
 {
  "input": "Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions. ",
  "translatedText": "যেখানে আমরা এর সাথে যাচ্ছি, যাইহোক, আমি এই ধরণের সম্ভাব্যতার সম্ভাব্যতার প্রশ্নগুলির অর্থপূর্ণ উত্তর তৈরি করতে ডেটা ব্যবহার করার খুব ব্যবহারিক প্রশ্ন সম্পর্কে কথা বলতে চাই।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.8,
  "end": 154.6
 },
 {
  "input": "But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox. ",
  "translatedText": "কিন্তু এই ভিডিওটির জন্য, চলুন এক মুহূর্ত সময় নিই কিভাবে একটানা মানের উপর সম্ভাব্যতা নিয়ে কাজ করা যায় এবং এই আপাত প্যারাডক্সের সমাধান করা যায়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 155.68,
  "end": 162.78
 },
 {
  "input": "The key is not to focus on individual values, but ranges of values. ",
  "translatedText": "মূল বিষয় হল স্বতন্ত্র মানগুলিতে ফোকাস করা নয়, তবে মানগুলির পরিসীমা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.32,
  "end": 173.96
 },
 {
  "input": "For example, we might make these buckets to represent the probability that h is between, say 0.8 and 0.85. ",
  "translatedText": "উদাহরণস্বরূপ, আমরা এই বালতিগুলি তৈরি করতে পারি সম্ভাব্যতা উপস্থাপন করার জন্য যে h এর মধ্যে রয়েছে, বলুন 0।8 এবং 0।85।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.62,
  "end": 182.16
 },
 {
  "input": "Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability. ",
  "translatedText": "এছাড়াও, এবং এটি মনে হতে পারে তার চেয়ে বেশি গুরুত্বপূর্ণ, এই দণ্ডগুলির প্রতিটির উচ্চতাকে সম্ভাব্যতাকে প্রতিনিধিত্ব করে ভাবার পরিবর্তে, প্রতিটিটির ক্ষেত্রফলটিকে সেই সম্ভাবনার প্রতিনিধিত্বকারী হিসাবে ভাবুন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.16,
  "end": 193.04
 },
 {
  "input": "Where exactly those areas come from is something we'll answer later. ",
  "translatedText": "ঠিক সেই অঞ্চলগুলি কোথা থেকে এসেছে তা আমরা পরে উত্তর দেব।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.96,
  "end": 197.48
 },
 {
  "input": "For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges. ",
  "translatedText": "এই মুহুর্তে, শুধু জেনে রাখুন যে নীতিগতভাবে, এই রেঞ্জগুলির মধ্যে একটির মধ্যে h বসার সম্ভাবনার কিছু উত্তর আছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.96,
  "end": 204.14
 },
 {
  "input": "Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input. ",
  "translatedText": "এই মুহূর্তে আমাদের কাজ হল এই অত্যন্ত মোটা দানাদার প্রশ্নের উত্তর নেওয়া এবং প্রতিটি পৃথক ইনপুটের স্তরে বন্টন সম্পর্কে আরও সঠিক ধারণা পাওয়া।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.96,
  "end": 214.56
 },
 {
  "input": "The natural thing to do is to consider finer and finer buckets, and when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same. ",
  "translatedText": "স্বাভাবিক জিনিসটি হল সূক্ষ্ম এবং সূক্ষ্ম বালতিগুলি বিবেচনা করা, এবং আপনি যখন তা করেন, তখন তাদের যেকোনো একটিতে পড়ার ছোট সম্ভাবনা এই বারের প্রতিটির পাতলা প্রস্থের জন্য গণনা করা হয়, যখন উচ্চতাগুলি মোটামুটিভাবে থাকবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.46,
  "end": 228.92
 },
 {
  "input": "That's important because it means that as you take this process to the limit, you approach some kind of smooth curve. ",
  "translatedText": "একই এটি গুরুত্বপূর্ণ কারণ এর মানে হল যে আপনি এই প্রক্রিয়াটিকে সীমাতে নিয়ে যাওয়ার সাথে সাথে আপনি এক ধরণের মসৃণ বক্ররেখার কাছে যাবেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.66,
  "end": 235.22
 },
 {
  "input": "So even though all of the individual probabilities of falling into any one particular bucket will approach 0, the overall shape of the distribution is preserved, and even refined in this limit. ",
  "translatedText": "সুতরাং যদিও কোনো একটি নির্দিষ্ট বালতিতে পড়ার সমস্ত স্বতন্ত্র সম্ভাব্যতা 0-এর কাছে পৌঁছাবে, বিতরণের সামগ্রিক আকৃতি সংরক্ষণ করা হয় এবং এমনকি এই সীমাতে পরিমার্জিত হয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 235.9,
  "end": 247.22
 },
 {
  "input": "If we had let the heights of the bars represent probabilities, everything would have gone to 0. ",
  "translatedText": "যদি আমরা বারের উচ্চতাগুলিকে সম্ভাব্যতা উপস্থাপন করতে দিতাম, তাহলে সবকিছুই 0-এ চলে যেত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.7,
  "end": 254.9
 },
 {
  "input": "So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution. ",
  "translatedText": "তাই সীমার মধ্যে, আমাদের কেবল একটি সমতল লাইন থাকত যা বিতরণের সামগ্রিক আকৃতি সম্পর্কে কোনও তথ্য দেয় না।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 260.04,
  "end": 265.64
 },
 {
  "input": "So wonderful, letting area represent probability helps solve this problem. ",
  "translatedText": "এত বিস্ময়কর, সম্ভাবনার প্রতিনিধিত্বকারী এলাকা এই সমস্যার সমাধান করতে সাহায্য করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 267.42,
  "end": 271.26
 },
 {
  "input": "But let me ask you, if the y-axis no longer represents probability, what exactly are the units here? ",
  "translatedText": "কিন্তু আমি আপনাকে জিজ্ঞাসা করি, যদি y-অক্ষ আর সম্ভাব্যতার প্রতিনিধিত্ব না করে, তাহলে এখানে এককগুলি ঠিক কী? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 271.9,
  "end": 277.14
 },
 {
  "input": "Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density. ",
  "translatedText": "যেহেতু সম্ভাব্যতা এই বারের ক্ষেত্রফল, বা প্রস্থ গুণ উচ্চতার মধ্যে বসে, তাই উচ্চতা x-দিক-নির্দেশে একক প্রতি এক ধরনের সম্ভাব্যতার প্রতিনিধিত্ব করে, যা ব্যবসায় সম্ভাব্য ঘনত্ব হিসাবে পরিচিত।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.8,
  "end": 289.64
 },
 {
  "input": "The other thing to keep in mind is that the total area of all these bars has to equal 1 at every level of the process. ",
  "translatedText": "মনে রাখা অন্য জিনিস হল যে এই সমস্ত বারের মোট ক্ষেত্রফল প্রক্রিয়াটির প্রতিটি স্তরে 1 সমান হতে হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.58,
  "end": 296.54
 },
 {
  "input": "That's something that has to be true for any valid probability distribution. ",
  "translatedText": "এটি এমন কিছু যা কোনো বৈধ সম্ভাব্যতা বিতরণের জন্য সত্য হতে হবে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.06,
  "end": 300.5
 },
 {
  "input": "The idea of probability density is actually really clever when you step back to think about it. ",
  "translatedText": "সম্ভাব্য ঘনত্বের ধারণাটি আসলেই চতুর হয় যখন আপনি এটি সম্পর্কে চিন্তা করার জন্য ফিরে যান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 301.98,
  "end": 306.3
 },
 {
  "input": "As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short. ",
  "translatedText": "যেহেতু আপনি জিনিসগুলিকে সীমার মধ্যে নিয়ে যাচ্ছেন, এমনকি যদি 0 এবং 1 এর মধ্যে এইগুলির প্রতিটির জন্য অগণিতভাবে অসীম বহু মানের h এর সম্ভাব্যতা নির্ধারণের সাথে সমস্ত ধরণের প্যারাডক্স যুক্ত থাকে, তবে কোন সমস্যা নেই যদি আমরা তাদের প্রতিটির সাথে একটি সম্ভাব্য ঘনত্ব যুক্ত করি, একটি সম্ভাব্য ঘনত্ব ফাংশন হিসাবে পরিচিত কি প্রদান, বা সংক্ষেপে PDF. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 306.3,
  "end": 325.64
 },
 {
  "input": "Any time you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values. ",
  "translatedText": "যে কোনো সময় আপনি বন্য মধ্যে একটি PDF দেখতে, এটি ব্যাখ্যা করার উপায় হল যে দুটি মানের মধ্যে থাকা আপনার র্যান্ডম ভেরিয়েবলের সম্ভাব্যতা সেই মানগুলির মধ্যে এই বক্ররেখার নীচে ক্ষেত্রফলের সমান।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 326.42,
  "end": 337.52
 },
 {
  "input": "So, for example, what's the probability of getting any one very specific number, like 0.7? ",
  "translatedText": "সুতরাং, উদাহরণস্বরূপ, কোন একটি খুব নির্দিষ্ট সংখ্যা পাওয়ার সম্ভাবনা কত, যেমন 0।7? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.22,
  "end": 343.46
 },
 {
  "input": "Well, the area of an infinitely thin slice is 0, so it's 0. ",
  "translatedText": "আচ্ছা, একটি অসীম পাতলা স্লাইসের ক্ষেত্রফল 0, তাই এটি 0।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 344.22,
  "end": 348.34
 },
 {
  "input": "What's the probability of all of them put together? ",
  "translatedText": "তাদের সব একসাথে করা সম্ভাবনা কি? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.9,
  "end": 351.14
 },
 {
  "input": "Well, the area under the full curve is 1. ",
  "translatedText": "ওয়েল, পূর্ণ বক্ররেখার অধীনে ক্ষেত্রফল হল 1।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.78,
  "end": 353.96
 },
 {
  "input": "You see? ",
  "translatedText": "দেখেছ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 354.62,
  "end": 354.92
 },
 {
  "input": "Paradox sidestepped. ",
  "translatedText": "প্যারাডক্স পাশ কাটিয়ে গেছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.72,
  "end": 356.4
 },
 {
  "input": "And the way that it's been sidestepped is a bit subtle. ",
  "translatedText": "এবং এটি যেভাবে পাশ কাটিয়ে গেছে তা কিছুটা সূক্ষ্ম।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 357.5,
  "end": 360.22
 },
 {
  "input": "In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them. ",
  "translatedText": "সাধারণভাবে, সীমিত সেটিংসে, যেমন একটি ডাই রোল করা বা একটি কার্ড আঁকা, সম্ভাব্যতার একটি প্রদত্ত সংগ্রহের মধ্যে একটি এলোমেলো মান পড়ে যাওয়ার সম্ভাব্যতা হল তাদের যেকোনো একটি হওয়ার সম্ভাবনার সমষ্টি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 360.22,
  "end": 372.96
 },
 {
  "input": "This feels very intuitive, it's even true in a countably infinite context. ",
  "translatedText": "এটি খুব স্বজ্ঞাত মনে হয়, এটি একটি গণনাযোগ্য অসীম প্রসঙ্গেও সত্য।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 373.84,
  "end": 377.6
 },
 {
  "input": "But to deal with the continuum, the rules themselves have shifted. ",
  "translatedText": "কিন্তু ধারাবাহিকতা মোকাবেলা করার জন্য, নিয়ম নিজেই স্থানান্তরিত হয়েছে. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.12,
  "end": 381.54
 },
 {
  "input": "The probability of falling into a range of values is no longer the sum of the probabilities of each individual value. ",
  "translatedText": "মানগুলির একটি পরিসরে পড়ার সম্ভাবনা আর প্রতিটি পৃথক মানের সম্ভাব্যতার সমষ্টি নয়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.1,
  "end": 388.66
 },
 {
  "input": "Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0. ",
  "translatedText": "পরিবর্তে, ব্যাপ্তির সাথে সম্পৃক্ত সম্ভাব্যতা হল মৌলিক আদিম বস্তু, এবং একমাত্র অর্থ যেখানে এখানে একটি পৃথক মান সম্পর্কে কথা বলা অর্থপূর্ণ তা হল এটিকে প্রস্থ 0 এর একটি পরিসর হিসাবে ভাবা।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 389.18,
  "end": 401.22
 },
 {
  "input": "If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well you'll be happy to know that mathematicians are way ahead of you. ",
  "translatedText": "যদি একটি সীমিত সেটিং এবং একটি ক্রমাগত নিয়মগুলির মধ্যে পরিবর্তনের ধারণাটি অস্বস্তিকর বোধ করে, তাহলে আপনি জেনে খুশি হবেন যে গণিতবিদরা আপনার থেকে অনেক এগিয়ে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.18,
  "end": 410.4
 },
 {
  "input": "There's a field of math called measure theory which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely. ",
  "translatedText": "পরিমাপ তত্ত্ব নামে গণিতের একটি ক্ষেত্র রয়েছে যা এই দুটি সেটিংসকে একত্রিত করতে সাহায্য করে এবং সমস্ত সম্ভাবনার বিভিন্ন উপসেটের সাথে সম্ভাব্যতার মতো সংখ্যাগুলিকে এমনভাবে সংযুক্ত করার ধারণাটিকে কঠোর করে তোলে যা সুন্দরভাবে একত্রিত এবং বিতরণ করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 410.82,
  "end": 423.14
 },
 {
  "input": "For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve. ",
  "translatedText": "উদাহরণ স্বরূপ, ধরা যাক আপনি এমন একটি সেটিংয়ে আছেন যেখানে আপনার কাছে একটি র্যান্ডম সংখ্যা আছে যা 50% সম্ভাবনার সাথে 0 এর সমান, এবং বাকি সময় এটি একটি বিতরণ অনুসারে কিছু ধনাত্মক সংখ্যা যা দেখতে একটি বেল বক্ররেখার অর্ধেকের মতো।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 424.04,
  "end": 435.88
 },
 {
  "input": "This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one, where probabilities are found according to areas under the appropriate density function. ",
  "translatedText": "এটি একটি সীমিত প্রেক্ষাপটের মধ্যে একটি বিশ্রী মাঝামাঝি, যেখানে একটি একক মানের একটি অ-শূন্য সম্ভাবনা রয়েছে এবং একটি অবিচ্ছিন্ন একটি, যেখানে উপযুক্ত ঘনত্ব ফাংশনের অধীনে ক্ষেত্র অনুসারে সম্ভাব্যতা পাওয়া যায়।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 436.48,
  "end": 448.68
 },
 {
  "input": "This is the sort of thing that measure theory handles very smoothly. ",
  "translatedText": "এটি এমন একটি জিনিস যা পরিমাপ তত্ত্ব খুব মসৃণভাবে পরিচালনা করে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 449.46,
  "end": 452.6
 },
 {
  "input": "I mention this mainly for the especially curious viewer, and you can find more reading material in the description. ",
  "translatedText": "আমি বিশেষত কৌতূহলী দর্শকদের জন্য এটি উল্লেখ করছি, এবং আপনি বিবরণে আরও পড়ার উপাদান খুঁজে পেতে পারেন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.04,
  "end": 458.12
 },
 {
  "input": "It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves. ",
  "translatedText": "এটি একটি খুব সাধারণ নিয়ম যে আপনি যদি নিজেকে একটি বিচ্ছিন্ন প্রসঙ্গে একটি যোগফল ব্যবহার করতে দেখেন, তাহলে অবিচ্ছিন্ন প্রসঙ্গে একটি অবিচ্ছেদ্য ব্যবহার করুন, যা ক্যালকুলাসের টুল যা আমরা বক্ররেখার নীচে এলাকাগুলি খুঁজে পেতে ব্যবহার করি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.62,
  "end": 471.8
 },
 {
  "input": "In fact, you could argue this video would be way shorter if I just said that at the front and called it good. ",
  "translatedText": "প্রকৃতপক্ষে, আপনি যুক্তি দিতে পারেন যে এই ভিডিওটি আরও ছোট হবে যদি আমি সামনে এটি বলে থাকি এবং এটিকে ভাল বলি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.8,
  "end": 477.04
 },
 {
  "input": "For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means. ",
  "translatedText": "যদিও আমার অংশের জন্য, আমি সবসময় এটির প্রকৃত অর্থ কী তা চিন্তা না করে অন্ধভাবে এটি করা কিছুটা অসন্তুষ্ট বলে মনে করেছি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 477.76,
  "end": 483.28
 },
 {
  "input": "And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate, more powerful definition that's based on measure theory, this formal foundation of probability. ",
  "translatedText": "এবং প্রকৃতপক্ষে, আপনি যদি সত্যিই পূর্ণাঙ্গগুলির তাত্ত্বিক ভিত্তির মধ্যে খনন করেন, তাহলে আপনি যা পাবেন তা হল একটি সাধারণ ইন্ট্রো ক্যালকুলাস ক্লাসে এটি যেভাবে সংজ্ঞায়িত করা হয়েছে তা ছাড়াও একটি পৃথক, আরও শক্তিশালী সংজ্ঞা রয়েছে যা পরিমাপ তত্ত্বের উপর ভিত্তি করে , সম্ভাব্যতার এই আনুষ্ঠানিক ভিত্তি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.08,
  "end": 499.02
 },
 {
  "input": "If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow all together they have a probability of one. ",
  "translatedText": "আমি যদি প্রথমবার সম্ভাব্যতা শিখেছি সেই দিকে ফিরে তাকাই, আমি অবশ্যই এই অদ্ভুত ধারণার সাথে লড়াই করার কথা মনে করি যে ক্রমাগত সেটিংসে, র্যান্ডম ভেরিয়েবলের মতো যা বাস্তব সংখ্যা বা ডার্টবোর্ডে ডার্ট ছুঁড়ে, আপনার কাছে একগুচ্ছ ফলাফল রয়েছে যা সম্ভব, এবং তবুও প্রত্যেকেরই শূন্যের সম্ভাবনা আছে, এবং কোনো না কোনোভাবে সবাই মিলে একটি সম্ভাবনা আছে।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.28,
  "end": 519.56
 },
 {
  "input": "One step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me. ",
  "translatedText": "এটির সাথে শর্তে আসার একটি ধাপ হল এই উপলব্ধি করা যে সম্ভাবনাটি সম্ভাবনার চেয়ে সম্ভাব্যতার ঘনত্বের সাথে ভালভাবে আবদ্ধ, তবে অন্যের অবিচ্ছেদ্যগুলির জন্য একটির যোগফল অদলবদল করা আমার জন্য কখনই চুলকানি করেনি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 520.82,
  "end": 532.82
 },
 {
  "input": "I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all. ",
  "translatedText": "আমার মনে আছে যে এটি কেবল তখনই ক্লিক হয়েছিল যখন আমি বুঝতে পেরেছিলাম যে বিভিন্ন সেটের সম্ভাব্যতাগুলিকে একত্রিত করার নিয়মগুলি আমি যা ভেবেছিলাম তা পুরোপুরি নয়, এবং এটির অন্তর্নিহিত একটি ভিন্ন স্বতঃসিদ্ধ সিস্টেম ছিল।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 533.28,
  "end": 543.24
 },
 {
  "input": "But anyway, steering away from the theory somewhere back in the loose direction of application, let's look back to our original question about the coin with an unknown weight. ",
  "translatedText": "কিন্তু যাইহোক, তত্ত্ব থেকে দূরে কোথাও প্রয়োগের শিথিল দিক থেকে দূরে সরে আসুন, আসুন একটি অজানা ওজন সহ মুদ্রা সম্পর্কে আমাদের আসল প্রশ্নে ফিরে দেখি।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.58,
  "end": 552.44
 },
 {
  "input": "What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses? ",
  "translatedText": "আমরা এখানে যা শিখেছি তা হল সঠিক প্রশ্ন জিজ্ঞাসা করা হল, সম্ভাব্য ঘনত্বের ফাংশনটি কী যা এই মান h বর্ণনা করে কয়েকটি টসের ফলাফল দেখার পরে? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.96,
  "end": 562.96
 },
 {
  "input": "If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8? ",
  "translatedText": "আপনি যদি সেই PDFটি খুঁজে পান, তাহলে আপনি এটি ব্যবহার করতে পারেন প্রশ্নগুলির উত্তর দিতে, মাথা উল্টানোর প্রকৃত সম্ভাবনা 0 এর মধ্যে পড়ার সম্ভাবনা কত।6 এবং 0।8? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.46,
  "end": 572.8
 },
 {
  "input": "To find that PDF, join me in the next part. ",
  "translatedText": "সেই PDF খুঁজে পেতে, পরবর্তী অংশে আমার সাথে যোগ দিন।",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 573.68,
  "end": 576.06
 }
]