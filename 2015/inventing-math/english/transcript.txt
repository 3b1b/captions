Take 1 plus 2 plus 4 plus 8 and continue on and on adding the next power of 2 up to infinity. 
This might seem crazy, but there's a sense in which this infinite sum equals negative 1. 
If you're like me, this feels strange or obviously false when you first see it, but I promise you, by the end of this video you and I will make it make sense. 
To do this, we need to back up, and you and I will walk through what it might feel like to discover convergent infinite sums, those ones that at least seem to make sense, to define what they really mean, then to discover this crazy equation and stumble upon new forms of math where it makes sense. 
Imagine that you are an early mathematician in the process of discovering that ½ plus 1 fourth plus 1 eighth plus 1 sixteenth on and on up to infinity, whatever that means, equals 1, and imagine that you needed to define what it means to add infinitely many things for your friends to take you seriously. 
What would that feel like? 
Frankly, I have no idea, and I imagine that more than anything it feels like being wrong or stuck most of the time, but I'll give my best guess at one way that the successful parts of it might go. 
One day, you are pondering the nature of distances between objects, and how no matter how close two things are, it seems that they can always be brought a little bit closer together without touching. 
Fond of math as you are, you want to capture this paradoxical feeling with numbers, so you imagine placing the two objects on the number line, the first at 0, the second at 1. 
Then, you march the first object towards the second, such that with each step, the distance between them is cut in half. 
You keep track of the numbers this object touches during its march, writing down ½, ½ plus a fourth, ½ plus a fourth plus an eighth, and so on. 
That is, each number is naturally written as a slightly longer sum with one more power of 2 in it. 
As such, you're tempted to say that if these numbers approach anything, we should be able to write this thing down as a sum that contains the reciprocal of every power of 2. 
On the other hand, we can see geometrically that these numbers approach 1, so what you want to say is that 1 and some kind of infinite sum are the same thing. 
If your education was too formal, you'd write the statement off as ridiculous. 
Clearly, you can't add infinitely many things. 
No human, computer, or physical thing ever could perform such a task. 
If, however, you approach math with a healthy irreverence, you'll stand brave in the face of ridiculousness and try to make sense out of this nonsense you wrote down, since it kind of feels like nature gave it to you. 
So how exactly do you, dear mathematician, go about defining infinite sums? 
Well practiced in math that you are, you know that finding the right definitions is less about generating new thoughts than it is about dissecting old thoughts, so you go back to how you came across this fuzzy discovery. 
At no point did you actually perform infinitely many operations. 
You had a list of numbers, a list that could keep going forever if you had the time, and each number came from a perfectly reasonable finite sum. 
You noticed that the numbers in this list approach 1, but what do you mean by approach? 
It's not just that the distance between each number and 1 gets smaller, because for that matter, the distance between each number and 2 also gets smaller. 
After thinking about it, you realize what makes 1 special is that your numbers can get arbitrarily close to 1, which is to say, no matter how small your desired distance, 1 one-hundredth, 1 one-millionth, or 1 over the largest number you could write down, if you go down your list long enough, the numbers will eventually fall within that tiny distance of 1. 
Retrospectively, this might seem like the clear way to solidify what you mean by approach, but as a first-time endeavor, it's actually incredibly clever. 
Now you pull out your pin, and scribble down the definition for what it means for an infinite sum to equal some number, say x. 
It means that when you generate a list of numbers by cutting off your sum at finite points, the numbers in this list approach x in the sense that no matter how small the distance you choose, at some point down the list, all the numbers start falling within that distance of x. 
In doing this, you just invented some math, but it never felt like you were pulling things out of thin air, you were just trying to justify what it was that the universe gave you in the first place. 
You might wonder if you can find other, more general truths about these infinite sums that you just invented. 
To do so, you look for where you made any arbitrary decisions. 
For instance, when you were shrinking the distance between your objects, cutting the interval into pieces of size ½, ¼, etc., you could have chosen a proportion other than ½. 
You could have instead cut your interval into pieces of size 9 tenths and 1 tenth, and then cut that rightmost piece into the same proportions, giving you smaller pieces of size 9 one hundredths and one one hundredth, then cut that tiny piece of size one one hundredth similarly. 
Continuing on and on, you'd see that 9 tenths plus 9 one hundredths plus 9 one thousandths on and on up to infinity equals 1, a fact more popularly written as 0.9 repeating equals 1. 
To all of your friends who insist that this doesn't equal 1 and it just approaches it, you can now just smile, because you know that with infinite sums, to approach and to equal mean the same thing. 
To be general about it, let's say that you cut your interval into pieces of size p and 1-p, where p represents any number between 0 and 1. 
Cutting the piece of size p in similar proportions, we now get pieces of size p times 1-p and p squared. 
Continuing in this fashion, always cutting up the rightmost piece into those same proportions, you'll find that 1-p plus p times 1-p plus p squared times 1-p on and on always adding p to the next power times 1-p equals 1. 
Dividing both sides by 1-p, we get this nice formula. 
In this formula, the universe has offered a weird form of nonsense. 
Even though the way you discovered it only makes sense for values of p between 0 and 1, the right hand side still makes sense when you replace p with any other number, except maybe for 1. 
For instance, plugging in negative 1, the equation reads 1 minus 1 plus 1 minus 1 on and on forever alternating between the two, equals one half, which feels both silly and kind of like the only thing it could be. 
Plugging in 2, the equation reads 1 plus 2 plus 4 plus 8 on and on to infinity equals negative 1, something which doesn't even seem reasonable. 
On the one hand, Rigger would dictate that you ignore these, since the definition of infinite sums doesn't apply in these cases. 
The list of numbers that you generate by cutting off the sum at finite points doesn't approach anything. 
But you're a mathematician, not a robot, so you don't let the fact that something is nonsensical stop you. 
I will leave this sum for another day, so that we can jump directly into this monster. 
First, to clean things up, notice what you get when you cut off the sum at finite points. 
1, 3, 7, 15, 31, they're all 1 less than a power of 2. 
In general, when you add up the first n powers of 2, you get 2 to the n plus 1 minus 1, which this animation hopefully makes clear. 
You decide to humor the universe and pretend that these numbers, all 1 less than a power of 2, actually do approach negative 1. 
It will prove to be cleaner if we add 1 to everything and say that the powers of 2 approach 0. 
Is there any way that this can make sense? 
In effect, what you're trying to do is make this formula more general, by saying that it applies to all numbers, not just those between 0 and 1. 
Again, to make things more general, you look for any place where you made an arbitrary choice. 
Here, that place turns out to be very sneaky, so sneaky in fact that it took mathematicians until the 20th century to find it. 
It's the way that we define distance between two rational numbers. 
That is to say, organizing them on a line might not be the only reasonable way to organize them. 
The notion of distance is essentially a function that takes in two numbers and outputs a number indicating how far apart they are. 
You could come up with a completely random notion of distance, where 2 is 7 away from 3, and ½ is 4 fifths away from 100, and all sorts of things, but if you want to actually use a new distance function the way you use the familiar distance function, it should share some of the same properties. 
For example, the distance between two numbers shouldn't change if you shift them both by the same amount. 
So 0 and 4 should be the same distance away as 1 and 5, or 2 and 6, even if that same distance is something other than 4 as we're used to. 
Keeping things general, the distance between two numbers shouldn't change if you add the same amount to both of them. 
Let's call this property shift invariance. 
There are other properties that you want your notion of distance to have as well, like the notion of distance could possibly make powers of 2 approach 0, and shift invariant. 
At first you might toil for a while to find a frame of mind where this doesn't feel like utter nonsense, but with enough time and a bit of luck, you might think to organize your numbers into rooms, subrooms, sub-subrooms, and so on. 
You think of 0 as being in the same room as all of the powers of 2 greater than 1, as being in the same sub-room as all powers of 2 greater than 2, as being in the same sub-sub-room as powers of 2 greater than 4, and so on, with infinitely many smaller and smaller rooms. 
It's pretty hard to draw infinitely many things, so I'm only going to draw 4 room sizes, but keep in the back of your mind that this process should be able to go on forever. 
If we think of every number as lying in a hierarchy of rooms, not just 0, shift invariance will tell us where all of the numbers must fall. 
For instance, 1 should be as far away from 3 as 2 is from 0. 
Likewise, the distance between 0 and 4 should be the same as that between 1 and 5, 2 and 6, and 3 and 7. 
Continuing like this, you'll see which rooms, sub-rooms, sub-sub-rooms, and so on, successive numbers must fall into. 
You can also deduce where negative numbers must fall. 
For example, negative 1 has to be in the same room as 1, in the same sub-room as 3, in the same sub-sub-room as 7, and so on, always in smaller and smaller rooms with numbers 1 less than a power of 2, because 0 is in smaller and smaller rooms with the powers of 2. 
So, how do you turn this general idea of closeness based on rooms and sub-rooms into an actual distance function? 
You can't take this drawing too literally, since it makes 1 look very close to 14 and 0 very far from 13, even though shift invariance should imply that they're the same distance away. 
Again, in the actual process of discovery, you might toil away, scribbling through many sheets of paper, but if you have the idea that the only thing which should matter in determining the distance between two objects is the size of the smallest room they share, you might come up with the following. 
Any numbers lying in different large yellow rooms are a distance 1 from each other. 
Those which are in the same large room, but not in the same orange sub-room are a distance ½ from each other. 
And those that are in the same orange sub-room, but not in the same sub-sub-room are a distance ¼ from each other. 
And you continue like this, using the reciprocals of larger and larger powers of 2 to indicate closeness. 
We won't do it in this video, but see if you can reason about which rooms other rational numbers, like ⅓ and ½, should fall into. 
And see if you can prove why this notion of distance satisfies many of the nice properties we expect from a distance function, like the triangle inequality. 
Here, I'll just say that this notion of distance is a perfectly legitimate one, we call it the 2-adic metric, and it falls into a general family of distance functions called the p-adic metrics, where p stands for any prime number. 
These metrics give rise to a completely new type of number, neither real nor complex, and have become a central notion in modern number theory. 
Using the 2-adic metric, the fact that the sum of all powers of 2 equals negative 1 actually makes sense, because the numbers 1, 3, 7, 15, 31, and so on, genuinely approach negative 1. 
This parable does not actually portray the historical trajectory of discoveries, but nevertheless, I still think it's a good illustration of a recurring pattern in the discovery of math. 
First, nature hands you something that's ill-defined or even nonsensical. 
Then you define new concepts that make this fuzzy discovery make sense, and these new concepts tend to yield genuinely useful math and broaden your mind about traditional notions. 
So, in answer to the age-old question of whether math is invention or discovery, my personal belief is that discovery of non-rigorous truths is what leads us to the construction of rigorous terms that are useful, opening the door for more fuzzy discoveries continuing the cycle.