1
00:00:05,120 --> 00:00:09,820
Here, we look at the math behind an animation like this one, what's known as a complex

2
00:00:09,820 --> 00:00:10,700
Fourier series.

3
00:00:11,240 --> 00:00:16,160
Each little vector is rotating at some constant integer frequency, and when you add them together,

4
00:00:16,420 --> 00:00:20,100
tip to tail, the final tip draws out some shape over time.

5
00:00:21,220 --> 00:00:25,980
By tweaking the initial size and angle of each vector, we can make it draw pretty much

6
00:00:25,980 --> 00:00:28,620
anything we want, and here you'll see how.

7
00:00:31,120 --> 00:00:35,620
Before diving into it all, I want you to take a moment to just linger on how striking this

8
00:00:35,620 --> 00:00:36,120
is.

9
00:00:37,200 --> 00:00:40,900
This particular animation has 300 rotating arrows in total.

10
00:00:41,420 --> 00:00:44,960
Go full screen for this if you can, the intricacy is worth it.

11
00:00:50,440 --> 00:00:55,900
Think about this, the action of each individual arrow is perhaps the simplest thing you could

12
00:00:55,900 --> 00:00:57,960
imagine, rotation at a steady rate.

13
00:00:58,600 --> 00:01:03,600
And yet the collection of all added together is anything but simple, and the mind-boggling

14
00:01:03,600 --> 00:01:08,580
complexity is put into an even sharper focus the farther we zoom in, revealing the contributions

15
00:01:08,580 --> 00:01:11,480
of the littlest, quickest, and downright frenetic arrows.

16
00:01:12,300 --> 00:01:16,620
When you consider the chaotic frenzy you're looking at, and the clockwork rigidity underlying

17
00:01:16,620 --> 00:01:21,620
all the motions, it's bizarre how the swarm acts with a kind of coordination to trace

18
00:01:21,620 --> 00:01:23,400
out some very specific shape.

19
00:01:23,840 --> 00:01:28,120
And unlike much of the emergent complexity you find elsewhere in nature, this is something

20
00:01:28,120 --> 00:01:31,080
that we have the math to describe and to control completely.

21
00:01:31,660 --> 00:01:36,940
Just by tuning the starting conditions, nothing more, we can make this swarm conspire in all

22
00:01:36,940 --> 00:01:41,560
of the right ways to draw anything you want, provided you have enough little arrows.

23
00:01:42,180 --> 00:01:46,520
What's even crazier is that the ultimate formula for all of this is incredibly short.

24
00:01:52,960 --> 00:01:56,980
Now often, Fourier series are described in terms of something that looks a little different,

25
00:01:57,440 --> 00:02:00,560
functions of real numbers being broken down as a sum of sine waves.

26
00:02:01,260 --> 00:02:05,100
That turns out to be a special case of this more general rotating vector phenomenon that

27
00:02:05,100 --> 00:02:09,100
we'll build up to, but it's where Fourier himself started, and there's good reason

28
00:02:09,100 --> 00:02:10,780
for us to start the story there as well.

29
00:02:11,420 --> 00:02:15,520
Technically, this is the third video in a sequence about the heat equation, what Fourier

30
00:02:15,520 --> 00:02:17,560
was working on when he developed his big idea.

31
00:02:18,200 --> 00:02:21,780
I would like to teach you about Fourier series in a way that doesn't depend on you coming

32
00:02:21,780 --> 00:02:25,860
from those chapters, but if you have at least a high-level idea for the problem from physics

33
00:02:25,860 --> 00:02:30,440
which originally motivated this piece of math, it gives some indication for just how unexpectedly

34
00:02:30,440 --> 00:02:32,340
far-reaching Fourier series are.

35
00:02:32,820 --> 00:02:37,300
All you need to know is that we had a certain equation which tells us how the temperature

36
00:02:37,300 --> 00:02:43,340
distribution on a rod would evolve over time, and incidentally it also describes many other

37
00:02:43,340 --> 00:02:44,820
phenomena unrelated to heat.

38
00:02:44,820 --> 00:02:49,700
While it's hard to directly use this equation to figure out what will happen to an arbitrary

39
00:02:49,700 --> 00:02:53,940
heat distribution, there's a simple solution if the initial function just happens to look

40
00:02:53,940 --> 00:02:58,120
like a cosine wave, with the frequency tuned so that it's flat at each end point.

41
00:02:58,560 --> 00:03:04,140
Specifically, as you graph what happens over time, these waves simply get scaled down exponentially,

42
00:03:04,460 --> 00:03:07,960
with higher frequency waves having a faster exponential decay.

43
00:03:10,360 --> 00:03:14,660
The heat equation happens to be what's known in the business as a linear equation,

44
00:03:14,720 --> 00:03:20,200
meaning if you know two solutions and add them up, that sum is a new solution.

45
00:03:20,880 --> 00:03:25,400
You can even scale them each by some constant, which gives you some dials to turn to construct

46
00:03:25,400 --> 00:03:27,400
a custom function solving the equation.

47
00:03:29,240 --> 00:03:33,220
This is a fairly straightforward property that you can verify for yourself, but it's

48
00:03:33,220 --> 00:03:34,080
incredibly important.

49
00:03:34,080 --> 00:03:39,220
It means we can take our infinite family of solutions, these exponentially decaying cosine

50
00:03:39,220 --> 00:03:43,760
waves, scale a few of them by some custom constants of our choosing, and combine them

51
00:03:43,760 --> 00:03:49,220
to get a solution for a new, tailor-made initial condition, which is some combination of cosine

52
00:03:49,220 --> 00:03:49,500
waves.

53
00:03:50,200 --> 00:03:54,200
One important thing I'd like you to notice is that when you combine these waves, because

54
00:03:54,200 --> 00:03:59,500
the higher frequency ones decay faster, the sum you construct will tend to smooth out

55
00:03:59,500 --> 00:04:04,500
over time, as all the high frequency terms quickly go to zero, leaving only the low frequency

56
00:04:04,500 --> 00:04:05,380
terms dominating.

57
00:04:06,100 --> 00:04:10,120
So in a funny way, all of the complexity in the evolution of this heat distribution which

58
00:04:10,120 --> 00:04:14,500
the heat equation implies is captured by this difference in the decay rates for the different

59
00:04:14,500 --> 00:04:16,020
pure frequency components.

60
00:04:18,040 --> 00:04:20,480
It's at this point that Fourier gains immortality.

61
00:04:21,280 --> 00:04:26,280
I think most normal people at this stage would say, well, I can solve the heat equation when

62
00:04:26,280 --> 00:04:30,920
the initial distribution just happens to look like a wave, or a sum of waves, but what

63
00:04:30,920 --> 00:04:34,240
a shame it is that most real world distributions don't at all look like that.

64
00:04:34,800 --> 00:04:38,560
I mean, for example, let's say you brought together two rods which were each at some

65
00:04:38,560 --> 00:04:42,780
uniform temperature, and you wanted to know what happens immediately after they come into

66
00:04:42,780 --> 00:04:43,300
contact.

67
00:04:45,060 --> 00:04:49,080
To make the number simple, let's say the temperature of the left rod is 1 degree, and

68
00:04:49,080 --> 00:04:53,960
the right rod is negative 1 degree, and that the total length, L, of the combined two rods

69
00:04:53,960 --> 00:04:54,900
is 1.

70
00:04:54,900 --> 00:05:00,080
What this means is our initial temperature distribution is a step function, which is

71
00:05:00,080 --> 00:05:04,560
so obviously different from a sine wave, or the sum of sine waves, don't you think?

72
00:05:05,100 --> 00:05:09,820
I mean, it's almost entirely flat, not wavy, and for god's sake it's even discontinuous!

73
00:05:10,600 --> 00:05:13,700
And yet Fourier thought to ask a question which seems absurd.

74
00:05:14,300 --> 00:05:16,660
How do you express this as a sum of sine waves?

75
00:05:17,120 --> 00:05:21,340
Even more boldly, how do you express any initial distribution as a sum of sine waves?

76
00:05:21,800 --> 00:05:23,760
And it's more constrained than just that!

77
00:05:24,120 --> 00:05:28,160
You have to restrict yourself to adding waves which satisfy a certain boundary condition,

78
00:05:28,680 --> 00:05:32,800
and as we saw last video, that means working with these cosine functions whose frequencies

79
00:05:32,800 --> 00:05:36,060
are all some whole number multiple of a given base frequency.

80
00:05:36,920 --> 00:05:40,500
And by the way, if you were working with some different boundary condition, say that the

81
00:05:40,500 --> 00:05:43,880
endpoints have to stay fixed, you'd have a different set of waves at your disposal

82
00:05:43,880 --> 00:05:48,540
to piece together, in this case replacing that cosine expression with a sine.

83
00:05:49,560 --> 00:05:53,980
It's strange how often progress in math looks more like asking a new question rather

84
00:05:53,980 --> 00:05:55,560
than simply answering old ones.

85
00:05:56,240 --> 00:06:00,180
Fourier really does have a kind of immortality now, with his name essentially synonymous

86
00:06:00,180 --> 00:06:05,000
with the idea of breaking down functions and patterns as combinations of simple oscillations.

87
00:06:05,700 --> 00:06:10,060
It's really hard to overstate just how important and far-reaching that idea turned out to be,

88
00:06:10,320 --> 00:06:12,940
well beyond anything Fourier himself could have imagined.

89
00:06:13,600 --> 00:06:18,640
And yet, the origin of all this is a piece of physics which, at first glance, has nothing

90
00:06:18,640 --> 00:06:20,600
to do with frequencies and oscillations.

91
00:06:21,280 --> 00:06:25,300
If nothing else, this should give you a hint about the general applicability of Fourier series.

92
00:06:26,040 --> 00:06:29,680
Now hang on, I hear some of you saying, none of these sums of sine waves that you're

93
00:06:29,680 --> 00:06:33,080
showing are actually the step function, they're all just approximations.

94
00:06:33,540 --> 00:06:38,980
And it's true, any finite sum of sine waves will never be perfectly flat, except for a

95
00:06:38,980 --> 00:06:41,500
constant function, nor will it be discontinuous.

96
00:06:42,020 --> 00:06:45,460
But Fourier thought more broadly, considering infinite sums.

97
00:06:46,240 --> 00:06:51,140
In the case of our step function, it turns out to be equal to this infinite sum, where

98
00:06:51,140 --> 00:06:58,520
the coefficients are 1, negative one third, plus one fifth, minus one seventh, and so

99
00:06:58,520 --> 00:07:02,980
on for all the odd frequencies, and all of it is rescaled by 4 divided by pi.

100
00:07:03,800 --> 00:07:05,960
I'll explain where those numbers come from in a moment.

101
00:07:06,400 --> 00:07:10,360
Before that, it's worth being clear about what we mean by a phrase like infinite sum,

102
00:07:10,360 --> 00:07:12,660
which runs the risk of being a little vague.

103
00:07:13,540 --> 00:07:18,300
Consider the simpler context of numbers, where you could say, for example, that this infinite

104
00:07:18,300 --> 00:07:21,080
sum of fractions equals pi divided by 4.

105
00:07:21,680 --> 00:07:27,140
As you keep adding the terms one by one, at all times what you have is rational, it never

106
00:07:27,140 --> 00:07:29,760
actually equals the irrational pi divided by 4.

107
00:07:30,380 --> 00:07:35,840
But this sequence of partial sums approaches pi over 4, which is to say, the numbers you

108
00:07:35,840 --> 00:07:40,940
see, while never equaling pi over 4, get arbitrarily close to that value, and they

109
00:07:40,940 --> 00:07:42,880
stay arbitrarily close to that value.

110
00:07:43,720 --> 00:07:48,240
That's all a mouthful to say, so instead we abbreviate and just say the infinite sum equals

111
00:07:48,240 --> 00:07:49,160
pi over 4.

112
00:07:50,620 --> 00:07:54,700
With functions, you're doing the same thing, but with many different values in parallel.

113
00:07:55,920 --> 00:08:01,100
Consider a specific input, and the value of all of these scaled cosine functions for that

114
00:08:01,100 --> 00:08:01,520
input.

115
00:08:02,120 --> 00:08:07,240
If that input is less than 0.5, as you add more and more terms, the sum will approach

116
00:08:07,240 --> 00:08:07,740
1.

117
00:08:10,000 --> 00:08:14,600
If that input is greater than 0.5, as you add more and more terms, it would approach

118
00:08:14,600 --> 00:08:15,460
negative 1.

119
00:08:17,260 --> 00:08:23,020
At the input 0.5 itself, all of the cosines are 0, so the limit of the partial sums is

120
00:08:23,020 --> 00:08:23,840
also 0.

121
00:08:24,600 --> 00:08:28,900
That means that, somewhat awkwardly, for this infinite sum to be strictly true, we have

122
00:08:28,900 --> 00:08:33,880
to prescribe the value of this set function at the point of discontinuity to be 0, sort

123
00:08:33,880 --> 00:08:35,240
of halfway along the jump.

124
00:08:36,080 --> 00:08:41,460
Analogous to an infinite sum of rational numbers being irrational, the infinite sum of wavy

125
00:08:41,460 --> 00:08:46,740
continuous functions can equal a discontinuous flat function.

126
00:08:47,160 --> 00:08:52,380
Getting limits into the game allows for qualitative changes, which finite sums alone never could.

127
00:08:53,280 --> 00:08:56,660
There are multiple technical nuances that I'm sweeping under the rug here.

128
00:08:56,660 --> 00:09:00,600
Does the fact that we're forced into a certain value for the step function at the point of

129
00:09:00,600 --> 00:09:03,300
discontinuity make any difference for the heat flow problem?

130
00:09:03,820 --> 00:09:07,580
For that matter, what does it really mean to solve a PDE with a discontinuous initial

131
00:09:07,580 --> 00:09:08,020
condition?

132
00:09:09,280 --> 00:09:13,020
Can we be sure that the limit of solutions to the heat equation is also a solution?

133
00:09:13,580 --> 00:09:16,880
And can we be sure that all functions actually have a Fourier series like this?

134
00:09:17,180 --> 00:09:18,400
If not, when not?

135
00:09:19,080 --> 00:09:23,320
These are exactly the kind of questions which real analysis is built to answer, but it falls

136
00:09:23,320 --> 00:09:26,880
a bit deeper in the weeds than I'd like to go here, so I'll relegate that all to

137
00:09:26,880 --> 00:09:28,080
links in the video's description.

138
00:09:28,720 --> 00:09:33,480
The upshot is that when you take the heat equation solutions associated with these cosine

139
00:09:33,480 --> 00:09:39,100
waves and add them all up, all infinitely many of them, you do get an exact solution

140
00:09:39,100 --> 00:09:44,200
describing how the step function will evolve over time, and if you had done this in 1822,

141
00:09:44,680 --> 00:09:46,480
you would have become immortal for doing so.

142
00:09:47,140 --> 00:09:51,240
The key challenge in all of this, of course, is to find these coefficients.

143
00:09:53,880 --> 00:09:58,180
So far, we've been thinking about functions with real number outputs, but for the computations,

144
00:09:58,480 --> 00:10:02,240
I'd like to show you something more general than what Fourier originally did, applying

145
00:10:02,240 --> 00:10:06,700
to functions whose output can be any complex number in the 2D plane, which is where all

146
00:10:06,700 --> 00:10:09,220
these rotating vectors from the opening come back into play.

147
00:10:10,880 --> 00:10:12,260
Why the added complexity?

148
00:10:12,260 --> 00:10:17,020
Well, aside from being more general, in my view, the computations become cleaner, and

149
00:10:17,020 --> 00:10:19,580
it's easier to understand why they actually work.

150
00:10:20,300 --> 00:10:23,780
More importantly, it sets a good foundation for the ideas that will come up later on in

151
00:10:23,780 --> 00:10:27,880
the series, like the Laplace transform, and the importance of exponential functions.

152
00:10:29,300 --> 00:10:33,740
We'll still think of functions whose input is some real number on a finite interval,

153
00:10:34,040 --> 00:10:38,680
say from 0 up to 1 for simplicity, but whereas something like a temperature function will

154
00:10:38,680 --> 00:10:42,800
have outputs on the real number line, this broader view will let the outputs wander anywhere

155
00:10:42,800 --> 00:10:44,540
in the 2D complex plane.

156
00:10:45,120 --> 00:10:49,500
You might think of such a function as a drawing, with a pencil tip tracing out different points

157
00:10:49,500 --> 00:10:52,740
in the complex plane as the input ranges from 0 to 1.

158
00:10:53,340 --> 00:10:57,420
And instead of sine waves being the fundamental building block, as you saw at the start, we'll

159
00:10:57,420 --> 00:11:02,200
focus on breaking these functions down as a sum of little vectors, all rotating at some

160
00:11:02,200 --> 00:11:03,680
constant integer frequency.

161
00:11:03,680 --> 00:11:10,500
Functions with real number outputs are essentially really boring drawings, a one-dimensional

162
00:11:10,500 --> 00:11:11,300
pencil sketch.

163
00:11:11,980 --> 00:11:15,620
You might not be used to thinking of them like this, since usually we visualize such

164
00:11:15,620 --> 00:11:20,820
a function with a graph, but right now the path being drawn is only in the output space.

165
00:11:25,420 --> 00:11:30,360
If you do one of these decompositions into rotating vectors for a boring one-dimensional

166
00:11:30,360 --> 00:11:35,740
drawing, what will happen is that the vectors with frequency 1 and negative 1 will have

167
00:11:35,740 --> 00:11:38,760
the same length, and they'll be horizontal reflections of each other.

168
00:11:39,500 --> 00:11:43,760
When you just look at the sum of these two as they rotate, that sum stays fixed on the

169
00:11:43,760 --> 00:11:46,200
real number line, and it oscillates like a sine wave.

170
00:11:46,920 --> 00:11:49,900
If you haven't seen it before, this might be a really weird way to think about what

171
00:11:49,900 --> 00:11:54,020
a sine wave is, since we're used to looking at its graph rather than the output alone

172
00:11:54,020 --> 00:11:58,280
wandering on the real number line, but in the broader context of functions with complex

173
00:11:58,280 --> 00:12:03,320
number outputs, this oscillation on the horizontal line is what a sine wave looks like.

174
00:12:04,920 --> 00:12:10,500
Similarly, the pair of rotating vectors with frequencies 2 and negative 2 will add another

175
00:12:10,500 --> 00:12:15,720
sine wave component, and so on, with the sine waves we were looking for earlier now corresponding

176
00:12:15,720 --> 00:12:18,760
to pairs of vectors rotating in opposite directions.

177
00:12:19,640 --> 00:12:24,100
So the context that Fourier originally studied, breaking down real-valued functions into sine

178
00:12:24,100 --> 00:12:29,200
waves, is a special case of the more general idea of 2D drawings and rotating vectors.

179
00:12:34,580 --> 00:12:38,460
And at this point, maybe you don't trust me that widening our view to complex functions

180
00:12:38,460 --> 00:12:42,840
makes things easier to understand, but bear with me, it's really worth the added effort

181
00:12:42,840 --> 00:12:46,680
to see the fuller picture, and I think you'll be pleased with how clean the actual computation

182
00:12:46,680 --> 00:12:48,440
is in this broader context.

183
00:12:49,100 --> 00:12:53,260
You may also wonder why, if we're going to bump things up into two dimensions, we

184
00:12:53,260 --> 00:12:56,500
don't just talk about 2D vectors, what does the square root of negative one have

185
00:12:56,500 --> 00:12:57,240
to do with anything?

186
00:12:58,100 --> 00:13:03,420
Well, the heart and soul of Fourier series is the complex exponential, e to the i times

187
00:13:03,420 --> 00:13:03,700
t.

188
00:13:04,480 --> 00:13:10,100
As the input t ticks forward with time, this value walks around the unit circle at a rate

189
00:13:10,100 --> 00:13:11,340
of one unit per second.

190
00:13:12,280 --> 00:13:16,840
In the next video you'll see a quick intuition for why exponentiating imaginary numbers walks

191
00:13:16,840 --> 00:13:20,120
around circles like this from the perspective of differential equations.

192
00:13:20,480 --> 00:13:24,500
And beyond that, as the series progresses, I hope to give you some sense for why complex

193
00:13:24,500 --> 00:13:27,060
exponentials like this are actually very important.

194
00:13:27,740 --> 00:13:32,120
In theory, you could describe all of the Fourier series stuff purely in terms of vectors, and

195
00:13:32,120 --> 00:13:34,640
never breathe a word of i, the square root of negative one.

196
00:13:35,300 --> 00:13:39,540
The formulas would become more convoluted, but beyond that, leaving out the function

197
00:13:39,540 --> 00:13:45,120
e to the x would somehow no longer authentically reflect why this idea turns out to be so useful

198
00:13:45,120 --> 00:13:46,780
for solving differential equations.

199
00:13:47,420 --> 00:13:51,940
For right now, if you want, you can think of e to the i t as a notational shorthand

200
00:13:51,940 --> 00:13:56,120
for describing rotating vectors, but just keep in the back of your mind that it is more

201
00:13:56,120 --> 00:13:57,480
significant than mere shorthand.

202
00:13:58,540 --> 00:14:01,980
You'll notice I'm being a little loose with language using the words vector and complex

203
00:14:01,980 --> 00:14:06,200
numbers somewhat interchangeably, in large part because thinking of complex numbers as

204
00:14:06,200 --> 00:14:10,340
little arrows makes the idea of adding a lot of them together easier to visualize.

205
00:14:11,340 --> 00:14:15,600
Alright, armed with the function e to the i times t, let's write down a formula for

206
00:14:15,600 --> 00:14:17,720
each of these rotating vectors we're working with.

207
00:14:18,120 --> 00:14:22,240
For right now, think of each of them as starting pointing one unit to the right at the number

208
00:14:22,240 --> 00:14:22,580
1.

209
00:14:23,080 --> 00:14:27,840
The easiest vector to describe is the constant one, which stays at the number 1, never moving,

210
00:14:28,420 --> 00:14:32,260
or if you prefer, it's rotating just at a frequency of 0.

211
00:14:33,100 --> 00:14:37,600
Then there will be the vector rotating one cycle every second, which we write as e to

212
00:14:37,600 --> 00:14:39,220
the 2 pi i times t.

213
00:14:39,740 --> 00:14:45,200
That 2 pi is there because as t goes from 0 to 1, it needs to cover a distance of 2

214
00:14:45,200 --> 00:14:46,440
pi along the circle.

215
00:14:47,700 --> 00:14:51,400
Technically it's actually one cycle every 10 seconds so things aren't too dizzying,

216
00:14:51,540 --> 00:14:53,560
I'm slowing everything down by a factor of 10.

217
00:14:55,320 --> 00:14:59,960
We also have a vector rotating at one cycle per second in the other direction, e to the

218
00:14:59,960 --> 00:15:01,740
negative 2 pi i times t.

219
00:15:04,300 --> 00:15:10,380
Similarly, the one going two rotations per second is e to the 2 times 2 pi i times t,

220
00:15:10,840 --> 00:15:16,740
where that 2 times 2 pi in the exponent describes how much distance is covered in one second.

221
00:15:20,600 --> 00:15:24,980
And we go on like this over all integers, both positive and negative, with a general

222
00:15:24,980 --> 00:15:28,800
formula of e to the n times 2 pi times i t.

223
00:15:29,340 --> 00:15:34,940
Notice, this makes it more consistent to write that constant vector as e to the 0 times 2 pi times i t,

224
00:15:35,340 --> 00:15:39,620
which feels like an awfully complicated way to write the number 1, but at least it fits the pattern.

225
00:15:40,500 --> 00:15:45,060
The control that we have, the set of knobs and dials we get to turn, is the initial size

226
00:15:45,060 --> 00:15:46,900
and direction of each of these numbers.

227
00:15:47,480 --> 00:15:52,060
The way we control that is by multiplying each one by some complex constant, which I'll

228
00:15:52,060 --> 00:15:53,240
call c sub n.

229
00:15:53,880 --> 00:15:58,660
For example, if we wanted the constant vector not to be at the number 1, but to have a length

230
00:15:58,660 --> 00:16:01,860
of 0.5, c sub 0 would be 0.5.

231
00:16:02,540 --> 00:16:07,140
If we wanted the vector rotating at 1 cycle per second to start off at an angle of 45

232
00:16:07,140 --> 00:16:11,720
degrees, we'd multiply it by a complex number which has the effect of rotating it by that

233
00:16:11,720 --> 00:16:15,000
much, which you can write as e to the pi fourths times i.

234
00:16:15,640 --> 00:16:20,860
And if its initial length needed to be 0.3, then the coefficient c sub 1 would be 0.3

235
00:16:20,860 --> 00:16:21,800
times that amount.

236
00:16:22,760 --> 00:16:27,460
Likewise, everyone in our infinite family of rotating vectors has some complex constant

237
00:16:27,460 --> 00:16:31,900
being multiplied into it, which determines its initial angle and its total magnitude.

238
00:16:32,820 --> 00:16:38,320
Our goal is to express any arbitrary function f of t, say this one that draws an eighth

239
00:16:38,320 --> 00:16:44,920
note as t goes from 0 to 1, as a sum of terms like this, so we need some way of picking

240
00:16:44,920 --> 00:16:49,440
out these constants one by one, given the data of the function itself.

241
00:16:51,840 --> 00:16:54,540
The easiest of these to find is the constant term.

242
00:16:55,080 --> 00:16:58,480
This term represents a sort of center of mass for the full drawing.

243
00:16:59,000 --> 00:17:03,680
If you were to sample a bunch of evenly spaced values for the input t as it ranges from 0

244
00:17:03,680 --> 00:17:09,580
to 1, the average of all the outputs of the function for those samples would be the constant

245
00:17:09,580 --> 00:17:10,620
term c0.

246
00:17:11,360 --> 00:17:16,080
Or more accurately, as you consider finer and finer samples, the average of the outputs

247
00:17:16,080 --> 00:17:19,240
for these samples approaches c0 in the limit.

248
00:17:20,000 --> 00:17:24,100
What I'm describing, finer and finer sums of a function for samples of t from the input

249
00:17:24,100 --> 00:17:28,500
range, is an integral, an integral of f of t from 0 to 1.

250
00:17:30,820 --> 00:17:34,980
Normally, since I'm framing this all in terms of averages, you would divide the integral

251
00:17:34,980 --> 00:17:39,800
by the length of the input range, but that length is 1, so in this case, taking an integral

252
00:17:39,800 --> 00:17:42,080
and taking an average are the same thing.

253
00:17:42,640 --> 00:17:46,580
There's a very nice way to think about why this integral would pull out c0.

254
00:17:47,380 --> 00:17:52,200
Remember, we want to think of this function as a sum of rotating vectors, so consider

255
00:17:52,200 --> 00:17:56,600
this integral, this continuous average, as being applied to that whole sum.

256
00:17:57,460 --> 00:18:02,580
The average of a sum like this is the same as the sum over the averages of each part.

257
00:18:06,080 --> 00:18:09,240
You can read this move as a sort of subtle shift in perspective.

258
00:18:09,520 --> 00:18:13,840
Rather than looking at the sum of all the vectors at each point in time and taking the

259
00:18:13,840 --> 00:18:18,960
average value they sweep out, look at the average of an individual vector as t goes

260
00:18:18,960 --> 00:18:21,540
from 0 to 1, and then add up all these averages.

261
00:18:22,480 --> 00:18:27,340
But each of these vectors just makes a whole number of rotations around 0, so its average

262
00:18:27,340 --> 00:18:30,800
value as t ranges from 0 to 1 will be 0.

263
00:18:31,340 --> 00:18:33,440
The only exception is the constant term.

264
00:18:33,940 --> 00:18:38,460
Since it stays static and doesn't rotate, its average value is just whatever number

265
00:18:38,460 --> 00:18:40,840
it happened to start on, which is c0.

266
00:18:41,600 --> 00:18:46,280
So doing this average over the whole function is a sort of clever way to kill all the terms

267
00:18:46,280 --> 00:18:47,500
that aren't c0.

268
00:18:48,040 --> 00:18:49,560
But here's the actual clever part.

269
00:18:49,860 --> 00:18:54,120
Let's say you wanted to compute a different term, like c2, sitting in front of the vector

270
00:18:54,120 --> 00:18:55,800
rotating two cycles per second.

271
00:18:56,420 --> 00:19:02,220
The trick is to first multiply f of t by something that makes that vector hold still, sort of

272
00:19:02,220 --> 00:19:05,440
the mathematical equivalent of giving a smartphone to an overactive child.

273
00:19:06,260 --> 00:19:12,060
Specifically, if you multiply the whole function by e to the negative 2 times 2 pi i times

274
00:19:12,060 --> 00:19:14,500
t, think about what happens to each term.

275
00:19:16,640 --> 00:19:21,800
Since multiplying exponentials results in adding what's in the exponent, the frequency

276
00:19:21,800 --> 00:19:25,320
term in each of our exponents gets shifted down by 2.

277
00:19:29,660 --> 00:19:35,640
So now, as we do our averages of each term, that c-1 vector spins around negative 3 times

278
00:19:35,640 --> 00:19:36,720
with an average of 0.

279
00:19:37,560 --> 00:19:44,220
The c0 vector, previously constant, now rotates twice as t ranges from 0 to 1, so its average

280
00:19:44,220 --> 00:19:44,980
is also 0.

281
00:19:46,520 --> 00:19:51,900
And likewise, all vectors other than the c2 term make some whole number of rotations,

282
00:19:52,280 --> 00:19:53,740
meaning they average out to be 0.

283
00:19:55,280 --> 00:20:00,600
So taking the average of this modified function is a clever way to kill all the terms other

284
00:20:00,600 --> 00:20:01,680
than c2.

285
00:20:02,360 --> 00:20:06,080
And of course, there's nothing special about the number 2 here, you could replace it with

286
00:20:06,080 --> 00:20:10,100
any other n, and you have a general formula for cn, which is what we're looking for.

287
00:20:10,660 --> 00:20:14,700
Out of context, this expression might look complicated, but remember, you can read it

288
00:20:14,700 --> 00:20:20,340
as first modifying our function, our 2d drawing, so as to make the nth little vector hold still,

289
00:20:20,860 --> 00:20:24,920
and then performing an average which kills all the moving vectors and leaves you only

290
00:20:24,920 --> 00:20:25,780
with the still part.

291
00:20:26,460 --> 00:20:27,080
Isn't that crazy?

292
00:20:27,500 --> 00:20:32,140
All of the complexity in these decompositions you're seeing of drawings into sums of many

293
00:20:32,140 --> 00:20:35,880
rotating vectors is entirely captured in this little expression.

294
00:20:36,540 --> 00:20:40,820
So when I'm rendering these animations, that's exactly what I'm having the computer do.

295
00:20:41,280 --> 00:20:46,460
It treats the path like a complex function, and for a certain range of values n, it computes

296
00:20:46,460 --> 00:20:49,060
this integral to find the coefficient c of n.

297
00:20:51,080 --> 00:20:54,840
For those of you curious about where the data for a path itself comes from, I'm going

298
00:20:54,840 --> 00:20:59,080
the easy route and just having the program read in an SVG, which is a file format that

299
00:20:59,080 --> 00:21:02,820
defines the image in terms of mathematical curves rather than with pixel values.

300
00:21:03,280 --> 00:21:08,960
So the mapping f of t from a time parameter to points in space basically comes predefined.

301
00:21:10,540 --> 00:21:15,440
In what's shown right now, I'm using 101 rotating vectors, computing the values of

302
00:21:15,440 --> 00:21:17,480
n from negative 50 up to 50.

303
00:21:18,120 --> 00:21:22,720
In practice, each of these integrals is computed numerically, basically meaning it chops up

304
00:21:22,720 --> 00:21:27,560
the unit interval into many small pieces of size delta t, and then adds up this value,

305
00:21:27,560 --> 00:21:32,740
f of t times e to the negative n 2 pi i t times delta t, for each one of them.

306
00:21:33,280 --> 00:21:37,340
There are fancier methods for more efficient numerical integration, but this gives the

307
00:21:37,340 --> 00:21:37,980
basic idea.

308
00:21:38,820 --> 00:21:44,320
And after you compute these 101 constants, each one determines an initial angle and magnitude

309
00:21:44,320 --> 00:21:48,360
for the little vectors, and then you just set them all rotating, adding them tip to

310
00:21:48,360 --> 00:21:53,080
tail as they go, and the path drawn out by the final tip is some approximation of the

311
00:21:53,080 --> 00:21:54,400
original path you fed in.

312
00:21:55,100 --> 00:22:00,020
As the number of vectors used approaches infinity, the approximation path gets more and more

313
00:22:00,020 --> 00:22:00,780
accurate.

314
00:22:14,140 --> 00:22:18,360
To bring this all back down to earth, consider the example we were looking at earlier, of

315
00:22:18,360 --> 00:22:22,340
a step function, which remember was useful for modeling the heat dissipation between

316
00:22:22,340 --> 00:22:25,500
two rods at different temperatures after they come into contact.

317
00:22:26,620 --> 00:22:31,400
Like any real number valued function, the step function is like a boring drawing that's

318
00:22:31,400 --> 00:22:32,500
confined to one dimension.

319
00:22:33,240 --> 00:22:38,980
But this one is an especially dull drawing, since for inputs between 0 and 0.5, the output

320
00:22:38,980 --> 00:22:43,680
just stays static at the number 1, and then it discontinuously jumps to negative 1 for

321
00:22:43,680 --> 00:22:45,820
inputs between 0.5 and 1.

322
00:22:46,440 --> 00:22:51,320
So in the Fourier series approximation, the vector sum stays really close to 1 for the

323
00:22:51,320 --> 00:22:55,540
first half of the cycle, then quickly jumps to negative 1, and stays close to that for

324
00:22:55,540 --> 00:22:56,680
the second half of the cycle.

325
00:22:57,500 --> 00:23:02,500
And remember, each pair of vectors rotating in opposite directions corresponds to one

326
00:23:02,500 --> 00:23:04,680
of the cosine waves we were looking at earlier.

327
00:23:06,080 --> 00:23:10,700
To find the coefficients, you would need to compute this integral, and for the ambitious

328
00:23:10,700 --> 00:23:14,720
viewers among you itching to work out some integrals by hand, this is one where you can

329
00:23:14,720 --> 00:23:19,420
actually do the calculus to get an exact answer, rather than just having a computer do it numerically

330
00:23:19,420 --> 00:23:19,940
for you.

331
00:23:19,940 --> 00:23:24,200
I'll leave it as an exercise to work this out, and to relate it back to the idea of

332
00:23:24,200 --> 00:23:27,880
cosine waves by pairing off the vectors that rotate in opposite directions.

333
00:23:28,780 --> 00:23:32,580
And for the even more ambitious, I'll leave another exercise up on the screen for how

334
00:23:32,580 --> 00:23:36,580
to relate this more general computation with what you might see in a textbook describing

335
00:23:36,580 --> 00:23:40,940
Fourier series only in terms of real valued functions with sines and cosines.

336
00:23:41,840 --> 00:23:45,980
By the way, if you're looking for more Fourier series content, I highly recommend the videos

337
00:23:45,980 --> 00:23:51,680
by Mathologer and The Coding Train, and I'd also recommend this blog post, links in the description.

338
00:23:53,620 --> 00:23:58,560
So on the one hand, this concludes our discussion of the heat equation, which was a little window

339
00:23:58,560 --> 00:24:00,720
into the study of partial differential equations.

340
00:24:01,240 --> 00:24:05,920
But on the other hand, this Fourier-to-Fourier series is a first glimpse at a deeper idea.

341
00:24:06,500 --> 00:24:11,400
Exponential functions, including their generalization into complex numbers and even matrices, play

342
00:24:11,400 --> 00:24:16,240
a very important role for differential equations, especially when it comes to linear equations.

343
00:24:16,920 --> 00:24:21,340
What you just saw, breaking down a function as a combination of these exponentials and

344
00:24:21,340 --> 00:24:25,200
using that to solve a differential equation, comes up again and again in different shapes

345
00:24:25,200 --> 00:24:25,740
and forms.

346
00:24:44,900 --> 00:24:46,080
Thank you.

