1
00:00:00,000 --> 00:00:09,980
Here, we look at the math behind an animation like this one, what's known as a complex

2
00:00:09,980 --> 00:00:11,360
Fourier series.

3
00:00:11,360 --> 00:00:16,440
Each little vector is rotating at some constant integer frequency, and when you add them together,

4
00:00:16,440 --> 00:00:21,280
tip to tail, the final tip draws out some shape over time.

5
00:00:21,280 --> 00:00:25,920
By tweaking the initial size and angle of each vector, we can make it draw pretty much

6
00:00:25,920 --> 00:00:31,440
anything we want, and here you'll see how.

7
00:00:31,440 --> 00:00:35,640
Before diving into it all, I want you to take a moment to just linger on how striking this

8
00:00:35,640 --> 00:00:37,380
is.

9
00:00:37,380 --> 00:00:41,440
This particular animation has 300 rotating arrows in total.

10
00:00:41,440 --> 00:00:50,960
Go full screen for this if you can, the intricacy is worth it.

11
00:00:50,960 --> 00:00:55,820
Think about this, the action of each individual arrow is perhaps the simplest thing you could

12
00:00:55,820 --> 00:00:58,660
imagine, rotation at a steady rate.

13
00:00:58,660 --> 00:01:03,540
And yet the collection of all added together is anything but simple, and the mind-boggling

14
00:01:03,540 --> 00:01:08,640
complexity is put into an even sharper focus the farther we zoom in, revealing the contributions

15
00:01:08,640 --> 00:01:12,420
of the littlest, quickest, and downright frenetic arrows.

16
00:01:12,420 --> 00:01:16,660
When you consider the chaotic frenzy you're looking at, and the clockwork rigidity underlying

17
00:01:16,660 --> 00:01:21,540
all the motions, it's bizarre how the swarm acts with a kind of coordination to trace

18
00:01:21,540 --> 00:01:24,040
out some very specific shape.

19
00:01:24,040 --> 00:01:28,240
And unlike much of the emergent complexity you find elsewhere in nature, this is something

20
00:01:28,240 --> 00:01:31,920
we have the math to describe and control completely.

21
00:01:31,920 --> 00:01:36,840
Just by tuning the starting conditions, nothing more, we can make this swarm conspire in all

22
00:01:36,840 --> 00:01:41,720
the right ways to draw anything you want, provided you have enough little arrows.

23
00:01:41,720 --> 00:01:53,240
What's even crazier is that the ultimate formula for all of this is incredibly short.

24
00:01:53,240 --> 00:01:57,440
Often Fourier series are described in terms of something that looks a little different,

25
00:01:57,440 --> 00:02:01,320
functions of real numbers being broken down as a sum of sine waves.

26
00:02:01,320 --> 00:02:05,360
That turns out to be a special case of this more general rotating vector phenomenon we'll

27
00:02:05,360 --> 00:02:09,360
build up to, but it's where Fourier himself started, and there's good reason for us

28
00:02:09,360 --> 00:02:11,240
to start the story there as well.

29
00:02:11,240 --> 00:02:15,480
Technically, this is the third video in a sequence about the heat equation, what Fourier

30
00:02:15,480 --> 00:02:18,200
was working on when he developed his big idea.

31
00:02:18,200 --> 00:02:21,800
I would like to teach you about Fourier series in a way that doesn't depend on you coming

32
00:02:21,800 --> 00:02:25,880
from those chapters, but if you have at least a high level idea for the problem from physics

33
00:02:25,880 --> 00:02:30,480
which originally motivated this piece of math, it gives some indication for just how unexpectedly

34
00:02:30,480 --> 00:02:33,080
far-reaching Fourier series are.

35
00:02:33,080 --> 00:02:37,320
All you need to know is that we had a certain equation which tells us how the temperature

36
00:02:37,320 --> 00:02:43,260
distribution on a rod would evolve over time, and incidentally it also describes many other

37
00:02:43,260 --> 00:02:45,460
phenomena unrelated to heat.

38
00:02:45,460 --> 00:02:49,000
And while it's hard to directly use this equation to figure out what will happen to

39
00:02:49,000 --> 00:02:52,960
an arbitrary heat distribution, there's a simple solution if the initial function

40
00:02:52,960 --> 00:02:57,800
just happens to look like a cosine wave, with a frequency tuned so that it's flat at each

41
00:02:57,800 --> 00:02:58,800
end point.

42
00:02:58,800 --> 00:03:04,740
Specifically, as you graph what happens over time, these waves simply get scaled down exponentially,

43
00:03:04,740 --> 00:03:10,840
with higher frequency waves having a faster exponential decay.

44
00:03:10,840 --> 00:03:15,300
The heat equation happens to be what's known in the business as a linear equation, meaning

45
00:03:15,300 --> 00:03:21,000
if you know two solutions and add them up, that sum is a new solution.

46
00:03:21,000 --> 00:03:25,380
You can even scale them each by some constant, which gives you some dials to turn to construct

47
00:03:25,380 --> 00:03:29,340
a custom function solving the equation.

48
00:03:29,340 --> 00:03:33,120
This is a fairly straightforward property that you can verify for yourself, but it's

49
00:03:33,120 --> 00:03:34,120
incredibly important.

50
00:03:34,120 --> 00:03:38,680
It means that we can take our infinite family of solutions, these exponentially decaying

51
00:03:38,680 --> 00:03:43,460
cosine waves, scale a few of them by some custom constants of our choosing, and combine

52
00:03:43,460 --> 00:03:48,640
them to get a solution for a new, tailor-made initial condition, which is some combination

53
00:03:48,640 --> 00:03:50,300
of cosine waves.

54
00:03:50,300 --> 00:03:54,140
One important thing I'd like you to notice is that when you combine these waves, because

55
00:03:54,140 --> 00:03:59,420
the higher frequency ones decay faster, the sum you construct will tend to smooth out

56
00:03:59,420 --> 00:04:04,460
over time as all the high frequency terms quickly go to zero, leaving only the low frequency

57
00:04:04,460 --> 00:04:06,100
terms dominating.

58
00:04:06,100 --> 00:04:10,060
So in a funny way, all of the complexity in the evolution of this heat distribution which

59
00:04:10,060 --> 00:04:14,120
the heat equation implies is captured by this difference in the decay rates for the

60
00:04:14,120 --> 00:04:16,540
different pure frequency components.

61
00:04:16,540 --> 00:04:21,280
It's at this point that Fourier gains immortality.

62
00:04:21,280 --> 00:04:26,220
I think most normal people at this stage would say, well, I can solve the heat equation when

63
00:04:26,220 --> 00:04:30,900
the initial distribution just happens to look like a wave, or a sum of waves, but what a

64
00:04:30,900 --> 00:04:34,340
shame it is that most real world distributions don't at all look like that.

65
00:04:34,340 --> 00:04:38,460
I mean, for example, let's say you brought together two rods which were each at some

66
00:04:38,460 --> 00:04:42,940
uniform temperature, and you wanted to know what happens immediately after they come into

67
00:04:42,940 --> 00:04:45,140
contact.

68
00:04:45,140 --> 00:04:49,060
To make the numbers simple, let's say the temperature of the left rod is 1 degree, and

69
00:04:49,060 --> 00:04:54,140
the right rod is negative 1 degree, and that the total length, L, of the combined two rods

70
00:04:54,140 --> 00:04:55,760
is 1.

71
00:04:55,760 --> 00:04:59,960
What this means is that our initial temperature distribution is a step function, which is

72
00:04:59,960 --> 00:05:05,060
so obviously different from a sine wave, or the sum of sine waves, don't you think?

73
00:05:05,060 --> 00:05:10,660
I mean, it's almost entirely flat, not wavy, and for god's sake it's even discontinuous!

74
00:05:10,660 --> 00:05:14,420
And yet Fourier thought to ask a question which seems absurd.

75
00:05:14,420 --> 00:05:17,260
How do you express this as a sum of sine waves?

76
00:05:17,260 --> 00:05:22,020
Even more boldly, how do you express any initial distribution as a sum of sine waves?

77
00:05:22,020 --> 00:05:24,100
And it's more constrained than just that.

78
00:05:24,100 --> 00:05:28,660
You have to restrict yourself to adding waves which satisfy a certain boundary condition,

79
00:05:28,660 --> 00:05:32,840
and as we saw last video, that means working with these cosine functions whose frequencies

80
00:05:32,840 --> 00:05:37,040
are all some whole number multiple of a given base frequency.

81
00:05:37,040 --> 00:05:40,400
And by the way, if you were working with some different boundary condition, say that the

82
00:05:40,400 --> 00:05:43,900
endpoints have to stay fixed, you'd have a different set of waves at your disposal

83
00:05:43,900 --> 00:05:49,280
to piece together, in this case replacing that cosine expression with a sine.

84
00:05:49,280 --> 00:05:53,940
It's strange how often progress in math looks more like asking a new question rather

85
00:05:53,940 --> 00:05:56,120
than simply answering old ones.

86
00:05:56,120 --> 00:06:00,260
Fourier really does have a kind of immortality now, with his name essentially synonymous

87
00:06:00,260 --> 00:06:05,220
with the idea of breaking down functions and patterns as combinations of simple oscillations.

88
00:06:05,220 --> 00:06:10,300
It's really hard to overstate just how important and far-reaching that idea turned out to be,

89
00:06:10,300 --> 00:06:13,800
well beyond anything Fourier himself could have imagined.

90
00:06:13,800 --> 00:06:18,640
And yet the origin of all this is a piece of physics which, at first glance, has nothing

91
00:06:18,640 --> 00:06:21,340
to do with frequencies and oscillations.

92
00:06:21,340 --> 00:06:24,740
If nothing else, this should give you a hint about the general applicability of Fourier

93
00:06:24,740 --> 00:06:25,740
series.

94
00:06:26,220 --> 00:06:30,160
Now hang on, I hear some of you saying, none of these sums of sine waves you're showing

95
00:06:30,160 --> 00:06:33,700
are actually the step function, they're all just approximations.

96
00:06:33,700 --> 00:06:38,780
And it's true, any finite sum of sine waves will never be perfectly flat, except for a

97
00:06:38,780 --> 00:06:42,180
constant function, nor will it be discontinuous.

98
00:06:42,180 --> 00:06:46,260
But Fourier thought more broadly, considering infinite sums.

99
00:06:46,260 --> 00:06:51,080
In the case of our step function, it turns out to be equal to this infinite sum, where

100
00:06:51,080 --> 00:06:58,440
the coefficients are 1, negative one third, plus one fifth, minus one seventh, and so

101
00:06:58,440 --> 00:07:03,440
on for all the odd frequencies, and all of it is rescaled by 4 divided by pi.

102
00:07:03,440 --> 00:07:06,600
I'll explain where those numbers come from in a moment.

103
00:07:06,600 --> 00:07:10,760
Before that, it's worth being clear about what we mean by a phrase like infinite sum,

104
00:07:10,760 --> 00:07:13,820
which runs the risk of being a little vague.

105
00:07:13,820 --> 00:07:18,480
Consider the simpler context of numbers, where you could say, for example, that this infinite

106
00:07:18,480 --> 00:07:21,840
sum of fractions equals pi divided by 4.

107
00:07:21,840 --> 00:07:27,040
As you keep adding the terms one by one, at all times what you have is rational, it never

108
00:07:27,040 --> 00:07:30,560
actually equals the irrational pi divided by 4.

109
00:07:30,560 --> 00:07:35,740
But this sequence of partial sums approaches pi over 4, which is to say, the numbers you

110
00:07:35,740 --> 00:07:41,900
see while never equaling pi over 4 get arbitrarily close to that value, and they stay arbitrarily

111
00:07:41,900 --> 00:07:43,840
close to that value.

112
00:07:43,840 --> 00:07:47,820
That's all a mouthful to say, so instead we abbreviate and just say the infinite sum

113
00:07:47,860 --> 00:07:51,100
equals pi over 4.

114
00:07:51,100 --> 00:07:56,240
With functions, you're doing the same thing, but with many different values in parallel.

115
00:07:56,240 --> 00:08:01,060
Consider a specific input, and the value of all of these scaled cosine functions for that

116
00:08:01,060 --> 00:08:02,320
input.

117
00:08:02,320 --> 00:08:07,160
If that input is less than 0.5, as you add more and more terms, the sum will approach

118
00:08:07,160 --> 00:08:10,280
1.

119
00:08:10,280 --> 00:08:14,720
If that input is greater than 0.5, as you add more and more terms, it would approach

120
00:08:14,720 --> 00:08:17,380
negative 1.

121
00:08:17,620 --> 00:08:23,140
At the input 0.5 itself, all of the cosines are 0, so the limit of the partial sums is

122
00:08:23,140 --> 00:08:24,680
also 0.

123
00:08:24,680 --> 00:08:28,920
That means that, somewhat awkwardly, for this infinite sum to be strictly true, we have

124
00:08:28,920 --> 00:08:33,880
to prescribe the value of this set function at the point of discontinuity to be 0, sort

125
00:08:33,880 --> 00:08:36,140
of halfway along the jump.

126
00:08:36,140 --> 00:08:41,420
Analogous to an infinite sum of rational numbers being irrational, the infinite sum of wavy

127
00:08:41,420 --> 00:08:47,380
continuous functions can equal a discontinuous flat function.

128
00:08:47,380 --> 00:08:53,580
Getting limits into the game allows for qualitative changes, which finite sums alone never could.

129
00:08:53,580 --> 00:08:57,100
There are multiple technical nuances that I'm sweeping under the rug here.

130
00:08:57,100 --> 00:09:00,540
Does the fact that we're forced into a certain value for the step function at the point of

131
00:09:00,540 --> 00:09:03,860
discontinuity make any difference for the heat flow problem?

132
00:09:03,860 --> 00:09:07,580
For that matter, what does it really mean to solve a PDE with a discontinuous initial

133
00:09:07,580 --> 00:09:09,400
condition?

134
00:09:09,400 --> 00:09:13,680
Can we be sure that the limit of solutions to the heat equation is also a solution?

135
00:09:13,680 --> 00:09:17,280
And can we be sure that all functions actually have a Fourier series like this?

136
00:09:17,280 --> 00:09:19,200
If not, when not?

137
00:09:19,200 --> 00:09:23,320
These are exactly the kind of questions which real analysis is built to answer, but it falls

138
00:09:23,320 --> 00:09:26,780
a bit deeper in the weeds than I'd like to go here, so I'll relegate that all to

139
00:09:26,780 --> 00:09:28,760
links in the video's description.

140
00:09:28,760 --> 00:09:33,360
The upshot is that when you take the heat equation solutions associated with these cosine

141
00:09:33,360 --> 00:09:39,400
waves and add them all up, all infinitely many of them, you do get an exact solution

142
00:09:39,400 --> 00:09:44,700
describing how the step function will evolve over time, and if you had done this in 1822,

143
00:09:44,700 --> 00:09:47,560
you would have become immortal for doing so.

144
00:09:47,560 --> 00:09:53,860
The key challenge in all of this, of course, is to find these coefficients.

145
00:09:53,860 --> 00:09:58,120
So far we've been thinking about functions with real number outputs, but for the computations,

146
00:09:58,120 --> 00:10:02,240
I'd like to show you something more general than what Fourier originally did, applying

147
00:10:02,240 --> 00:10:06,760
to functions whose output can be any complex number in the 2d plane, which is where all

148
00:10:06,760 --> 00:10:11,080
these rotating vectors from the opening come back into play.

149
00:10:11,080 --> 00:10:12,960
Why the added complexity?

150
00:10:12,960 --> 00:10:17,080
Well aside from being more general, in my view the computations become cleaner, and

151
00:10:17,080 --> 00:10:20,360
it's easier to understand why they actually work.

152
00:10:20,360 --> 00:10:23,800
More importantly, it sets a good foundation for the ideas that will come up later on in

153
00:10:23,800 --> 00:10:28,640
the series, like the Laplace transform, and the importance of exponential functions.

154
00:10:29,640 --> 00:10:33,960
We'll still think of functions whose input is some real number on a finite interval,

155
00:10:33,960 --> 00:10:36,720
say from 0 up to 1 for simplicity.

156
00:10:36,720 --> 00:10:40,560
But whereas something like a temperature function will have outputs on the real number line,

157
00:10:40,560 --> 00:10:45,180
this broader view will let the outputs wander anywhere in the 2d complex plane.

158
00:10:45,180 --> 00:10:49,500
You might think of such a function as a drawing, with a pencil tip tracing out different points

159
00:10:49,500 --> 00:10:53,480
in the complex plane as the input ranges from 0 to 1.

160
00:10:53,480 --> 00:10:57,700
And instead of sine waves being the fundamental building block, as you saw at the start, we'll

161
00:10:57,760 --> 00:11:02,140
focus on breaking these functions down as a sum of little vectors, all rotating at some

162
00:11:02,140 --> 00:11:05,980
constant integer frequency.

163
00:11:05,980 --> 00:11:10,560
Functions with real number outputs are essentially really boring drawings, a one-dimensional

164
00:11:10,560 --> 00:11:11,980
pencil sketch.

165
00:11:11,980 --> 00:11:15,580
You might not be used to thinking of them like this, since usually we visualize such

166
00:11:15,580 --> 00:11:25,660
a function with a graph, but right now the path being drawn is only in the output space.

167
00:11:25,660 --> 00:11:31,440
If you do one of these decompositions into rotating vectors for a boring drawing, what

168
00:11:31,440 --> 00:11:36,740
will happen is that the vectors with frequency 1 and negative 1 will have the same length,

169
00:11:36,740 --> 00:11:39,580
and they'll be horizontal reflections of each other.

170
00:11:39,580 --> 00:11:43,660
When you just look at the sum of these two as they rotate, that sum stays fixed on the

171
00:11:43,660 --> 00:11:46,980
real number line, and it oscillates like a sine wave.

172
00:11:46,980 --> 00:11:49,900
If you haven't seen it before, this might be a really weird way to think about what

173
00:11:49,900 --> 00:11:54,020
a sine wave is, since we're used to looking at its graph rather than the output alone

174
00:11:54,020 --> 00:11:58,280
wandering on the real number line, but in the broader context of functions with complex

175
00:11:58,280 --> 00:12:04,260
number outputs, this oscillation on the horizontal line is what a sine wave looks like.

176
00:12:04,260 --> 00:12:10,460
Similarly, the pair of rotating vectors with frequencies 2 and negative 2 will add another

177
00:12:10,460 --> 00:12:15,820
sine wave component, and so on, with the sine waves we were looking for earlier now corresponding

178
00:12:15,820 --> 00:12:19,740
to pairs of vectors rotating in opposite directions.

179
00:12:19,740 --> 00:12:24,220
So the context that Fourier originally studied, breaking down real valued functions into sine

180
00:12:24,220 --> 00:12:35,060
waves, is a special case of the more general idea of 2D drawings and rotating vectors.

181
00:12:35,060 --> 00:12:38,580
And at this point, maybe you don't trust me that widening our view to complex functions

182
00:12:38,580 --> 00:12:42,900
makes things easier to understand, but bear with me, it's really worth the added effort

183
00:12:42,900 --> 00:12:46,900
to see the fuller picture, and I think you'll be pleased with how clean the actual computation

184
00:12:46,900 --> 00:12:49,460
is in this broader context.

185
00:12:49,460 --> 00:12:53,260
You may also wonder why, if we're going to bump things up into two dimensions, we

186
00:12:53,260 --> 00:12:56,660
don't just talk about 2D vectors, what does the square root of negative one have to do

187
00:12:56,660 --> 00:12:57,820
with anything?

188
00:12:57,820 --> 00:13:03,580
Well, the heart and soul of Fourier series is the complex exponential e to the i times

189
00:13:03,580 --> 00:13:04,660
t.

190
00:13:04,660 --> 00:13:10,160
As the input t ticks forward with time, this value walks around the unit circle at a rate

191
00:13:10,160 --> 00:13:12,380
of one unit per second.

192
00:13:12,380 --> 00:13:16,860
In the next video you'll see a quick intuition for why exponentiating imaginary numbers walks

193
00:13:16,860 --> 00:13:21,220
around circles like this from the perspective of differential equations, and beyond that,

194
00:13:21,220 --> 00:13:25,300
as the series progresses, I hope to give you some sense for why complex exponentials like

195
00:13:25,300 --> 00:13:27,820
this are actually very important.

196
00:13:27,820 --> 00:13:32,100
In theory, you could describe all of the Fourier series stuff purely in terms of vectors, and

197
00:13:32,100 --> 00:13:35,380
never breathe a word of i, the square root of negative one.

198
00:13:35,380 --> 00:13:39,580
The formulas would become more convoluted, but beyond that, leaving out the function

199
00:13:39,580 --> 00:13:45,140
e to the x would somehow no longer authentically reflect why this idea turns out to be so useful

200
00:13:45,140 --> 00:13:47,580
for solving differential equations.

201
00:13:47,580 --> 00:13:51,980
For right now, if you want, you can think of e to the i t as a notational shorthand

202
00:13:51,980 --> 00:13:56,060
for describing rotating vectors, but just keep in the back of your mind that it is more

203
00:13:56,060 --> 00:13:57,860
significant than mere shorthand.

204
00:13:57,860 --> 00:14:02,220
You'll notice I'm being a little loose with language using the words vector and complex

205
00:14:02,220 --> 00:14:06,100
numbers somewhat interchangeably, in large part because thinking of complex numbers as

206
00:14:06,100 --> 00:14:10,740
little arrows makes the idea of adding a lot of them together easier to visualize.

207
00:14:11,340 --> 00:14:15,580
Alright, armed with the function e to the i times t, let's write down a formula for

208
00:14:15,580 --> 00:14:18,260
each of these rotating vectors we're working with.

209
00:14:18,260 --> 00:14:22,460
For right now, think of each of them as starting pointing one unit to the right at the number

210
00:14:22,460 --> 00:14:23,460
1.

211
00:14:23,460 --> 00:14:28,700
The easiest vector to describe is the constant one, which stays at the number 1, never moving,

212
00:14:28,700 --> 00:14:33,260
or if you prefer, it's quote-unquote rotating just at a frequency of 0.

213
00:14:33,260 --> 00:14:37,540
Then there will be the vector rotating one cycle every second, which we write as e to

214
00:14:37,540 --> 00:14:40,180
the 2 pi i times t.

215
00:14:40,620 --> 00:14:45,260
That 2 pi is there because as t goes from 0 to 1, it needs to cover a distance of 2

216
00:14:45,260 --> 00:14:47,140
pi along the circle.

217
00:14:47,140 --> 00:14:50,700
Technically in what's being shown, it's actually one cycle every 10 seconds so things

218
00:14:50,700 --> 00:14:55,460
aren't too dizzying, I'm slowing everything down by a factor of 10.

219
00:14:55,460 --> 00:14:59,780
We also have a vector rotating at one cycle per second in the other direction, e to the

220
00:14:59,780 --> 00:15:01,500
negative 2 pi i times t.

221
00:15:01,500 --> 00:15:11,100
Similarly, the one going two rotations per second is e to the 2 times 2 pi i times t,

222
00:15:11,100 --> 00:15:20,900
where that 2 times 2 pi in the exponent describes how much distance is covered in one second.

223
00:15:20,900 --> 00:15:24,940
And we go on like this over all integers, both positive and negative, with a general

224
00:15:24,940 --> 00:15:29,380
formula of e to the n times 2 pi times i t.

225
00:15:29,380 --> 00:15:34,020
Notice this makes it more consistent to write that constant vector as e to the 0 times 2

226
00:15:34,020 --> 00:15:38,620
pi times i t, which feels like an awfully complicated way to write the number 1, but

227
00:15:38,620 --> 00:15:40,540
at least it fits the pattern.

228
00:15:40,540 --> 00:15:45,020
The control we have, the set of knobs and dials we get to turn, is the initial size

229
00:15:45,020 --> 00:15:47,540
and direction of each of these numbers.

230
00:15:47,540 --> 00:15:52,180
The way we control that is by multiplying each one by some complex constant, which I'll

231
00:15:52,180 --> 00:15:53,980
call c sub n.

232
00:15:53,980 --> 00:15:58,660
For example, if we wanted the constant vector not to be at the number 1, but to have a length

233
00:15:58,660 --> 00:16:02,660
of 0.5, c sub 0 would be 0.5.

234
00:16:02,660 --> 00:16:07,340
If we wanted the vector rotating at 1 cycle per second to start off at an angle of 45

235
00:16:07,340 --> 00:16:11,780
degrees, we'd multiply it by a complex number which has the effect of rotating it by that

236
00:16:11,780 --> 00:16:15,700
much, which you can write as e to the pi fourths times i.

237
00:16:15,700 --> 00:16:21,180
And if its initial length needed to be 0.3, then the coefficient c sub 1 would be 0.3

238
00:16:21,180 --> 00:16:22,780
times that amount.

239
00:16:22,780 --> 00:16:27,500
Likewise, everyone in our infinite family of rotating vectors has some complex constant

240
00:16:27,500 --> 00:16:32,860
being multiplied into it, which determines its initial angle and its total magnitude.

241
00:16:32,860 --> 00:16:38,260
Our goal is to express any arbitrary function f of t, say this one that draws an eighth

242
00:16:38,260 --> 00:16:44,900
note as t goes from 0 to 1, as a sum of terms like this, so we need some way of picking

243
00:16:44,900 --> 00:16:52,260
out these constants one by one, given the data of the function itself.

244
00:16:52,260 --> 00:16:55,260
The easiest of these to find is the constant term.

245
00:16:55,260 --> 00:16:59,180
This term represents a sort of center of mass for the full drawing.

246
00:16:59,180 --> 00:17:03,780
If you were to sample a bunch of evenly spaced values for the input t as it ranges from 0

247
00:17:03,780 --> 00:17:09,620
to 1, the average of all the outputs of the function for those samples would be the constant

248
00:17:09,620 --> 00:17:11,500
term c0.

249
00:17:11,500 --> 00:17:16,100
Or more accurately, as you consider finer and finer samples, the average of the outputs

250
00:17:16,100 --> 00:17:20,080
for these samples approaches c0 in the limit.

251
00:17:20,080 --> 00:17:24,100
What I'm describing, finer and finer sums of a function for samples of t from the input

252
00:17:24,100 --> 00:17:29,740
range, is an integral, an integral of f of t from 0 to 1.

253
00:17:29,740 --> 00:17:35,220
Normally, since I'm framing this all in terms of averages, you would divide the integral

254
00:17:35,220 --> 00:17:39,820
by the length of the input range, but that length is 1, so in this case, taking an integral

255
00:17:39,820 --> 00:17:42,060
and taking an average are the same thing.

256
00:17:42,060 --> 00:17:47,140
There's a very nice way to think about why this integral would pull out c0.

257
00:17:47,140 --> 00:17:52,180
Remember, we want to think of this function as a sum of rotating vectors, so consider

258
00:17:52,180 --> 00:17:57,500
this integral, this continuous average, as being applied to that whole sum.

259
00:17:57,500 --> 00:18:06,520
The average of a sum like this is the same as the sum over the averages of each part.

260
00:18:06,520 --> 00:18:09,720
You can read this move as a sort of subtle shift in perspective.

261
00:18:09,720 --> 00:18:13,700
Rather than looking at the sum of all the vectors at each point in time and taking the

262
00:18:13,700 --> 00:18:18,940
average value they sweep out, look at the average of an individual vector as t goes

263
00:18:18,940 --> 00:18:22,660
from 0 to 1, and then add up all these averages.

264
00:18:22,660 --> 00:18:27,280
But each of these vectors just makes a whole number of rotations around 0, so its average

265
00:18:27,280 --> 00:18:31,480
value as t ranges from 0 to 1 will be 0.

266
00:18:31,480 --> 00:18:34,140
The only exception is the constant term.

267
00:18:34,140 --> 00:18:38,420
Since it stays static and doesn't rotate, its average value is just whatever number

268
00:18:38,420 --> 00:18:41,660
it happened to start on, which is c0.

269
00:18:41,660 --> 00:18:46,260
So doing this average over the whole function is a sort of clever way to kill all the terms

270
00:18:46,260 --> 00:18:48,300
that aren't c0.

271
00:18:48,300 --> 00:18:49,620
But here's the clever part.

272
00:18:49,620 --> 00:18:54,100
Let's say you wanted to compute a different term, like c2, sitting in front of the vector

273
00:18:54,100 --> 00:18:56,460
rotating two cycles per second.

274
00:18:56,460 --> 00:19:02,180
The trick is to first multiply f of t by something that makes that vector hold still, sort of

275
00:19:02,180 --> 00:19:05,980
the mathematical equivalent of giving a smartphone to an overactive child.

276
00:19:05,980 --> 00:19:12,180
Specifically, if you multiply the whole function by e to the negative 2 times 2 pi i times

277
00:19:12,180 --> 00:19:17,140
t, think about what happens to each term.

278
00:19:17,180 --> 00:19:21,820
Since multiplying exponentials results in adding what's in the exponent, the frequency

279
00:19:21,820 --> 00:19:29,740
term in each of our exponents gets shifted down by 2.

280
00:19:29,740 --> 00:19:35,780
So now, as we do our averages of each term, that c-1 vector spins around negative 3 times

281
00:19:35,780 --> 00:19:37,620
with an average of 0.

282
00:19:37,620 --> 00:19:44,220
The c0 vector, previously constant, now rotates twice as t ranges from 0 to 1, so its average

283
00:19:44,220 --> 00:19:46,700
is also 0.

284
00:19:46,740 --> 00:19:52,460
Likewise, all vectors other than the c2 term make some whole number of rotations, meaning

285
00:19:52,460 --> 00:19:55,620
they average out to be 0.

286
00:19:55,620 --> 00:20:00,580
So taking the average of this modified function is a clever way to kill all the terms other

287
00:20:00,580 --> 00:20:02,580
than c2.

288
00:20:02,580 --> 00:20:06,020
And of course, there's nothing special about the number 2 here, you could replace it with

289
00:20:06,020 --> 00:20:10,920
any other n, and you have a general formula for cn, which is what we're looking for.

290
00:20:10,920 --> 00:20:14,720
Out of context, this expression might look complicated, but remember, you can read it

291
00:20:14,760 --> 00:20:20,880
as first modifying our function, our 2d drawing, so as to make the nth little vector hold still,

292
00:20:20,880 --> 00:20:24,880
and then performing an average which kills all the moving vectors and leaves you only

293
00:20:24,880 --> 00:20:26,120
with the still part.

294
00:20:26,120 --> 00:20:27,560
Isn't that crazy?

295
00:20:27,560 --> 00:20:32,040
All of the complexity in these decompositions you're seeing of drawings into sums of many

296
00:20:32,040 --> 00:20:36,960
rotating vectors is entirely captured in this little expression.

297
00:20:36,960 --> 00:20:40,600
So when I'm rendering these animations, that's exactly what I'm having the computer

298
00:20:40,600 --> 00:20:41,600
do.

299
00:20:41,640 --> 00:20:46,440
It computes the path like a complex function, and for a certain range of values n, it computes

300
00:20:46,440 --> 00:20:51,120
this integral to find the coefficient c of n.

301
00:20:51,120 --> 00:20:54,840
For those of you curious about where the data for a path itself comes from, I'm going

302
00:20:54,840 --> 00:20:59,040
the easy route and just having the program read in an SVG, which is a file format that

303
00:20:59,040 --> 00:21:03,520
defines the image in terms of mathematical curves rather than with pixel values.

304
00:21:03,520 --> 00:21:10,780
So the mapping f of t from a time parameter to points in space basically comes predefined.

305
00:21:10,780 --> 00:21:15,380
In what's shown right now, I'm using 101 rotating vectors, computing the values of

306
00:21:15,380 --> 00:21:18,300
n from negative 50 up to 50.

307
00:21:18,300 --> 00:21:22,680
In practice, each of these integrals is computed numerically, basically meaning it chops up

308
00:21:22,680 --> 00:21:28,000
the unit interval into many small pieces of size delta t, and then adds up this value,

309
00:21:28,000 --> 00:21:33,420
f of t times e to the negative n 2 pi i t times delta t, for each one of them.

310
00:21:33,420 --> 00:21:37,300
There are fancier methods for more efficient numerical integration, but this gives the

311
00:21:37,300 --> 00:21:39,040
basic idea.

312
00:21:39,040 --> 00:21:44,400
And after you compute these 101 constants, each one determines an initial angle and magnitude

313
00:21:44,400 --> 00:21:48,300
for the little vectors, and then you just set them all rotating, adding them tip to

314
00:21:48,300 --> 00:21:53,000
tail as they go, and the path drawn out by the final tip is some approximation of the

315
00:21:53,000 --> 00:21:55,200
original path you fed in.

316
00:21:55,200 --> 00:22:00,160
As the number of vectors used approaches infinity, the approximation path gets more and more

317
00:22:00,160 --> 00:22:14,600
accurate.

318
00:22:14,600 --> 00:22:18,360
To bring this all back down to Earth, consider the example we were looking at earlier, of

319
00:22:18,360 --> 00:22:22,380
a step function, which remember was useful for modeling the heat dissipation between

320
00:22:22,380 --> 00:22:26,720
two rods at different temperatures after they come into contact.

321
00:22:26,720 --> 00:22:31,780
Like any real number valued function, the step function is like a boring drawing confined

322
00:22:31,780 --> 00:22:33,400
to one dimension.

323
00:22:33,400 --> 00:22:39,000
But this one is an especially dull drawing, since for inputs between 0 and 0.5, the output

324
00:22:39,000 --> 00:22:43,600
just stays static at the number 1, and then it discontinuously jumps to negative 1 for

325
00:22:43,600 --> 00:22:46,620
inputs between 0.5 and 1.

326
00:22:46,620 --> 00:22:51,280
So in the Fourier series approximation, the vector sum stays really close to 1 for the

327
00:22:51,280 --> 00:22:55,560
first half of the cycle, then quickly jumps to negative 1 and stays close to that for

328
00:22:55,560 --> 00:22:57,520
the second half of the cycle.

329
00:22:57,520 --> 00:23:02,460
And remember, each pair of vectors rotating in opposite directions corresponds to one

330
00:23:02,460 --> 00:23:06,440
of the cosine waves we were looking at earlier.

331
00:23:06,440 --> 00:23:10,680
To find the coefficients, you would need to compute this integral, and for the ambitious

332
00:23:10,680 --> 00:23:14,640
viewers among you itching to work out some integrals by hand, this is one where you can

333
00:23:14,640 --> 00:23:19,380
actually do the calculus to get an exact answer, rather than just having a computer do it numerically

334
00:23:19,380 --> 00:23:20,380
for you.

335
00:23:20,380 --> 00:23:24,040
I'll leave it as an exercise to work this out, and to relate it back to the idea of

336
00:23:24,040 --> 00:23:28,800
cosine waves by pairing off the vectors that rotate in opposite directions.

337
00:23:28,800 --> 00:23:32,520
And for the even more ambitious, I'll leave another exercise up on the screen for how

338
00:23:32,520 --> 00:23:36,560
to relate this more general computation with what you might see in a textbook describing

339
00:23:36,560 --> 00:23:41,840
Fourier series only in terms of real-valued functions with sines and cosines.

340
00:23:41,840 --> 00:23:45,920
By the way, if you're looking for more Fourier series content, I highly recommend the videos

341
00:23:45,920 --> 00:23:50,920
by Mathologer and The Coding Train, and I'd also recommend this blog post, links of course

342
00:23:50,920 --> 00:23:54,000
in the description.

343
00:23:54,000 --> 00:23:58,520
So on the one hand, this concludes our discussion of the heat equation, which was a little window

344
00:23:58,520 --> 00:24:01,400
into the study of partial differential equations.

345
00:24:01,400 --> 00:24:07,000
But on the other hand, this Fourier into Fourier series is a first glimpse at a deeper idea.

346
00:24:07,000 --> 00:24:11,360
Exponential functions, including their generalization into complex numbers and even matrices, play

347
00:24:11,360 --> 00:24:17,020
a very important role for differential equations, especially when it comes to linear equations.

348
00:24:17,020 --> 00:24:21,320
What you just saw, breaking down a function as a combination of these exponentials and

349
00:24:21,320 --> 00:24:25,200
using that to solve a differential equation, comes up again and again in different shapes

350
00:24:25,200 --> 00:24:25,840
and forms.

