[
 {
  "input": "In a previous video I've talked about linear systems of equations, and I sort of brushed aside the discussion of actually computing solutions to these systems.",
  "translatedText": "Dans une vidéo précédente, j'ai parlé de systèmes d'équations linéaires et j'ai en quelque sorte écarté la discussion sur les solutions informatiques réelles à ces systèmes.",
  "n_reviews": 0
 },
 {
  "input": "And while it's true that number crunching is typically something we leave to the computers, digging into some of these computational methods is a good litmus test for whether or not you actually understand what's going on, since that's really where the rubber meets the road.",
  "translatedText": "Et s'il est vrai que l'analyse des chiffres est généralement quelque chose que nous laissons aux ordinateurs, approfondir certaines de ces méthodes informatiques est un bon test décisif pour savoir si vous comprenez réellement ce qui se passe, car c'est vraiment là que le caoutchouc rencontre la route.",
  "n_reviews": 0
 },
 {
  "input": "Here I want to describe the geometry behind a certain method for computing solutions to these systems, known as Cramer's rule.",
  "translatedText": "Ici, je souhaite décrire la géométrie derrière une certaine méthode de calcul des solutions à ces systèmes, connue sous le nom de règle de Cramer.",
  "n_reviews": 0
 },
 {
  "input": "The relevant background here is understanding determinants, a little bit of dot products, and of course linear systems of equations, so be sure to watch the relevant videos on those topics if you're unfamiliar or rusty.",
  "translatedText": "Le contexte pertinent ici est la compréhension des déterminants, un peu de produits scalaires et bien sûr des systèmes d'équations linéaires, alors assurez-vous de regarder les vidéos pertinentes sur ces sujets si vous n'êtes pas familier ou rouillé.",
  "n_reviews": 0
 },
 {
  "input": "But first I should say up front that this Cramer's rule is not actually the best way for computing solutions to linear systems Gaussian elimination for example will always be faster.",
  "translatedText": "Mais je dois d'abord dire d'emblée que cette règle de Cramer n'est pas réellement le meilleur moyen pour les solutions informatiques des systèmes linéaires. L'élimination de Gauss, par exemple, sera toujours plus rapide.",
  "n_reviews": 0
 },
 {
  "input": "So why learn it?",
  "translatedText": "Alors pourquoi l'apprendre ?",
  "n_reviews": 0
 },
 {
  "input": "Well think of it as a sort of cultural excursion.",
  "translatedText": "Considérez-le comme une sorte d’excursion culturelle.",
  "n_reviews": 0
 },
 {
  "input": "It's a helpful exercise in deepening your knowledge of the theory behind these systems.",
  "translatedText": "C'est un exercice utile pour approfondir vos connaissances de la théorie derrière ces systèmes.",
  "n_reviews": 0
 },
 {
  "input": "Wrapping your mind around this concept is going to help consolidate ideas from linear algebra, like the determinant and linear systems, by seeing how they relate to each other.",
  "translatedText": "Comprendre ce concept aidera à consolider les idées de l'algèbre linéaire, comme les systèmes déterminants et linéaires, en voyant comment ils sont liés les uns aux autres.",
  "n_reviews": 0
 },
 {
  "input": "Also from a purely artistic standpoint the ultimate result here is just really pretty to think about, way more so than Gaussian elimination.",
  "translatedText": "D'un point de vue purement artistique, le résultat final ici est tout simplement vraiment joli à penser, bien plus que l'élimination gaussienne.",
  "n_reviews": 0
 },
 {
  "input": "Alright so the setup here will be some linear system of equations, say with two unknowns x and y and two equations.",
  "translatedText": "Très bien, la configuration ici sera un système linéaire d'équations, disons avec deux inconnues x et y et deux équations.",
  "n_reviews": 0
 },
 {
  "input": "In principle everything we're talking about will also work for systems with larger number of unknowns and the same number of equations, but for simplicity a smaller example is just nicer to hold in our heads.",
  "translatedText": "En principe, tout ce dont nous parlons fonctionnera également pour des systèmes avec un plus grand nombre d'inconnues et le même nombre d'équations, mais pour des raisons de simplicité, il est tout simplement plus agréable de garder en tête un exemple plus petit.",
  "n_reviews": 0
 },
 {
  "input": "So as I talked about in a previous video you can think of this setup geometrically as a certain known matrix transforming an unknown vector x y where you know what the output is going to be, in this case negative 4 negative 2.",
  "translatedText": "Donc, comme je l'ai mentionné dans une vidéo précédente, vous pouvez considérer géométriquement cette configuration comme une certaine matrice connue transformant un vecteur inconnu xy où vous savez quelle sera la sortie, dans ce cas moins 4 moins 2.",
  "n_reviews": 0
 },
 {
  "input": "Remember the columns of this matrix are telling you how that matrix acts as a transform, each one telling you where the basis vectors of the input space land.",
  "translatedText": "N'oubliez pas que les colonnes de cette matrice vous indiquent comment cette matrice agit comme une transformation, chacune vous indiquant où atterrissent les vecteurs de base de l'espace d'entrée.",
  "n_reviews": 0
 },
 {
  "input": "So what we have is a sort of puzzle, which input vector x y is going to land on this output negative 4 negative 2.",
  "translatedText": "Nous avons donc une sorte de puzzle : quel vecteur d’entrée xy va atterrir sur cette sortie moins 4 moins 2.",
  "n_reviews": 0
 },
 {
  "input": "One way to think about our little puzzle here is that we know the given output vector is some linear combination of the columns of the matrix x times the vector where i hat lands plus y times the vector where j hat lands, but what we want is to figure out what exactly that linear combination should be.",
  "translatedText": "Une façon de réfléchir à notre petit casse-tête ici est que nous savons que le vecteur de sortie donné est une combinaison linéaire des colonnes de la matrice x fois le vecteur où i hat atterrit plus y fois le vecteur où j hat atterrit, mais ce que nous voulons, c'est pour comprendre ce que devrait être exactement cette combinaison linéaire.",
  "n_reviews": 0
 },
 {
  "input": "Remember the type of answer you get here can depend on whether or not the transformation squishes all of space into a lower dimension, that is if it has a zero determinant.",
  "translatedText": "N'oubliez pas que le type de réponse que vous obtenez ici peut dépendre du fait que la transformation écrase ou non tout l'espace dans une dimension inférieure, c'est-à-dire si elle a un déterminant nul.",
  "n_reviews": 0
 },
 {
  "input": "In that case either none of the inputs land on our given output, or there's a whole bunch of inputs landing on that output.",
  "translatedText": "Dans ce cas, soit aucune des entrées n'atteint notre sortie donnée, soit tout un tas d'entrées atterrissent sur cette sortie.",
  "n_reviews": 0
 },
 {
  "input": "But for this video we'll limit our view to the case of a non-zero determinant, meaning the outputs of this transformation still span the full in-dimensional space that it started in.",
  "translatedText": "Mais pour cette vidéo, nous limiterons notre vision au cas d'un déterminant non nul, ce qui signifie que les résultats de cette transformation s'étendent toujours sur tout l'espace indimensionnel dans lequel elle a commencé.",
  "n_reviews": 0
 },
 {
  "input": "Every input lands on one and only one output, and every output has one and only one input.",
  "translatedText": "Chaque entrée atterrit sur une et une seule sortie, et chaque sortie a une et une seule entrée.",
  "n_reviews": 0
 },
 {
  "input": "As a first pass let me show you an idea that's wrong but in the right direction.",
  "translatedText": "En guise de premier passage, laissez-moi vous montrer une idée qui est fausse mais qui va dans la bonne direction.",
  "n_reviews": 0
 },
 {
  "input": "The x coordinate of this mystery input vector is what you get by taking its dot product with the first basis vector 1 0.",
  "translatedText": "La coordonnée x de ce vecteur d'entrée mystère est ce que vous obtenez en prenant son produit scalaire avec le premier vecteur de base 1 0.",
  "n_reviews": 0
 },
 {
  "input": "Likewise the y coordinate is what you get by dotting it with the second basis vector 0 1.",
  "translatedText": "De même, la coordonnée y est ce que vous obtenez en la pointant avec le deuxième vecteur de base 0 1.",
  "n_reviews": 0
 },
 {
  "input": "So maybe you hope that after the transformation the dot products with the transformed version of the mystery vector with the transformed version of the basis vectors will also be these coordinates x and y.",
  "translatedText": "Alors peut-être espérez-vous qu'après la transformation, les produits scalaires avec la version transformée du vecteur mystère avec la version transformée des vecteurs de base seront également ces coordonnées x et y.",
  "n_reviews": 0
 },
 {
  "input": "That'd be fantastic because we know what the transformed version of each of those vectors are.",
  "translatedText": "Ce serait fantastique car nous savons quelle est la version transformée de chacun de ces vecteurs.",
  "n_reviews": 0
 },
 {
  "input": "There's just one problem with it, it's not at all true.",
  "translatedText": "Il y a juste un problème, ce n’est pas du tout vrai.",
  "n_reviews": 0
 },
 {
  "input": "For most linear transformations the dot product before and after the transformation will look very different.",
  "translatedText": "Pour la plupart des transformations linéaires, le produit scalaire avant et après la transformation sera très différent.",
  "n_reviews": 0
 },
 {
  "input": "For example you could have two vectors generally pointing in the same direction with a positive dot product which get pulled apart from each other during the transformation in such a way that they have a negative dot product.",
  "translatedText": "Par exemple, vous pourriez avoir deux vecteurs pointant généralement dans la même direction avec un produit scalaire positif qui se séparent l'un de l'autre pendant la transformation de telle manière qu'ils ont un produit scalaire négatif.",
  "n_reviews": 0
 },
 {
  "input": "Likewise things that start off perpendicular with dot product 0, like the two basis vectors, quite often don't stay perpendicular to each other after the transformation, that is they don't preserve that 0 dot product.",
  "translatedText": "De même, les éléments qui commencent perpendiculairement au produit scalaire 0, comme les deux vecteurs de base, ne restent souvent pas perpendiculaires l'un à l'autre après la transformation, c'est-à-dire qu'ils ne préservent pas ce produit scalaire 0.",
  "n_reviews": 0
 },
 {
  "input": "And looking at the example I just showed dot products certainly aren't preserved, they tend to get bigger since most vectors are getting stretched out.",
  "translatedText": "Et en regardant l'exemple que je viens de montrer, les produits scalaires ne sont certainement pas préservés, ils ont tendance à grossir puisque la plupart des vecteurs s'étirent.",
  "n_reviews": 0
 },
 {
  "input": "In fact, worthwhile side note here, transformations which do preserve dot products are special enough to have their own name, orthonormal transformations.",
  "translatedText": "En fait, remarque intéressante ici, les transformations qui préservent les produits scalaires sont suffisamment spéciales pour avoir leur propre nom, transformations orthonormées.",
  "n_reviews": 0
 },
 {
  "input": "These are the ones that leave all of the basis vectors perpendicular to each other and still with unit lengths.",
  "translatedText": "Ce sont ceux qui laissent tous les vecteurs de base perpendiculaires les uns aux autres et toujours avec des longueurs unitaires.",
  "n_reviews": 0
 },
 {
  "input": "You often think of these as the rotation matrices, they correspond to rigid motion with no stretching or squishing or morphing.",
  "translatedText": "On les considère souvent comme des matrices de rotation, elles correspondent à un mouvement rigide sans étirement, ni écrasement, ni morphing.",
  "n_reviews": 0
 },
 {
  "input": "Solving a linear system with an orthonormal matrix is actually super easy.",
  "translatedText": "Résoudre un système linéaire avec une matrice orthonormée est en fait très simple.",
  "n_reviews": 0
 },
 {
  "input": "Because dot products are preserved, taking the dot product between the vector and all the columns of your matrix will be the same as taking the dot product between the mystery input vector and all of the basis vectors, which is the same as just finding the coordinates of that mystery input.",
  "translatedText": "Étant donné que les produits scalaires sont préservés, prendre le produit scalaire entre le vecteur et toutes les colonnes de votre matrice équivaudra à prendre le produit scalaire entre le vecteur d'entrée mystère et tous les vecteurs de base, ce qui équivaut à simplement trouver les coordonnées. de cette entrée mystérieuse.",
  "n_reviews": 0
 },
 {
  "input": "So in that very special case, x would be the dot product of the first column with the output vector, and y would be the dot product of the second column with the output vector.",
  "translatedText": "Ainsi, dans ce cas très particulier, x serait le produit scalaire de la première colonne avec le vecteur de sortie, et y serait le produit scalaire de la deuxième colonne avec le vecteur de sortie.",
  "n_reviews": 0
 },
 {
  "input": "Why am I bringing this up when this idea breaks down for almost all linear systems?",
  "translatedText": "Pourquoi est-ce que j'en parle alors que cette idée ne s'applique pas à presque tous les systèmes linéaires ?",
  "n_reviews": 0
 },
 {
  "input": "Well, it points us in a direction of something to look for.",
  "translatedText": "Eh bien, cela nous indique quelque chose à rechercher.",
  "n_reviews": 0
 },
 {
  "input": "Is there an alternate geometric understanding for the coordinates of our input vector that remains unchanged after the transformation?",
  "translatedText": "Existe-t-il une autre compréhension géométrique des coordonnées de notre vecteur d'entrée qui reste inchangée après la transformation ?",
  "n_reviews": 0
 },
 {
  "input": "If your mind has been mulling over determinants, you might think of the following clever idea.",
  "translatedText": "Si votre esprit a réfléchi aux déterminants, vous pourriez penser à l’idée intelligente suivante.",
  "n_reviews": 0
 },
 {
  "input": "Take the parallelogram defined by the first basis vector i-hat and the mystery input vector xy.",
  "translatedText": "Prenons le parallélogramme défini par le premier vecteur de base i-hat et le vecteur d'entrée mystère xy.",
  "n_reviews": 0
 },
 {
  "input": "The area of this parallelogram is the base, 1, times the height perpendicular to that base, which is the y-coordinate of that input vector.",
  "translatedText": "L'aire de ce parallélogramme est la base, 1, multipliée par la hauteur perpendiculaire à cette base, qui est la coordonnée y de ce vecteur d'entrée.",
  "n_reviews": 0
 },
 {
  "input": "So the area of that parallelogram is a sort of screwy roundabout way to describe the vector's y-coordinate.",
  "translatedText": "Ainsi, l’aire de ce parallélogramme est une sorte de moyen détourné pour décrire la coordonnée y du vecteur.",
  "n_reviews": 0
 },
 {
  "input": "It's a wacky way to talk about coordinates, but run with me.",
  "translatedText": "C'est une façon farfelue de parler de coordonnées, mais suivez-moi.",
  "n_reviews": 0
 },
 {
  "input": "And actually, to be a little more accurate, you should think of this as the signed area of that parallelogram, in the sense described in the determinant video.",
  "translatedText": "Et en fait, pour être un peu plus précis, vous devriez considérer cela comme la zone signée de ce parallélogramme, dans le sens décrit dans la vidéo déterminante.",
  "n_reviews": 0
 },
 {
  "input": "That way, a vector with a negative y-coordinate would correspond to a negative area for this parallelogram, at least if you think of i-hat as in some sense being the first out of these two vectors defining the parallelogram.",
  "translatedText": "De cette façon, un vecteur avec une coordonnée y négative correspondrait à une aire négative pour ce parallélogramme, du moins si vous considérez i-hat comme étant en quelque sorte le premier de ces deux vecteurs définissant le parallélogramme.",
  "n_reviews": 0
 },
 {
  "input": "And symmetrically, if you look at the parallelogram spanned by our mystery input vector and the second basis, j-hat, its area is going to be the x-coordinate of that mystery vector.",
  "translatedText": "Et symétriquement, si vous regardez le parallélogramme engendré par notre vecteur d'entrée mystère et la deuxième base, j-hat, son aire sera la coordonnée x de ce vecteur mystère.",
  "n_reviews": 0
 },
 {
  "input": "Again, it's a strange way to represent the x-coordinate, but see what it buys us in a moment.",
  "translatedText": "Encore une fois, c'est une façon étrange de représenter la coordonnée x, mais voyez ce que cela nous rapporte dans un instant.",
  "n_reviews": 0
 },
 {
  "input": "And just to make sure it's clear how this might generalize, let's look in three dimensions.",
  "translatedText": "Et juste pour être sûr de bien comprendre comment cela pourrait se généraliser, regardons en trois dimensions.",
  "n_reviews": 0
 },
 {
  "input": "Ordinarily, the way you might think about one of a vector's coordinates, say its z-coordinate, would be to take its dot product with the third standard basis vector, often called k-hat.",
  "translatedText": "Habituellement, la façon dont vous pourriez considérer l'une des coordonnées d'un vecteur, par exemple sa coordonnée z, serait de prendre son produit scalaire avec le troisième vecteur de base standard, souvent appelé k-hat.",
  "n_reviews": 0
 },
 {
  "input": "But an alternate geometric interpretation would be to consider the parallelepiped that it creates with the other two basis vectors, i-hat and j-hat.",
  "translatedText": "Mais une autre interprétation géométrique consisterait à considérer le parallélépipède qu’il crée avec les deux autres vecteurs de base, i-hat et j-hat.",
  "n_reviews": 0
 },
 {
  "input": "If you think of the square with area 1 spanned by i-hat and j-hat as the base of this whole shape, then its volume is the same as its height, which is the third coordinate of our vector.",
  "translatedText": "Si vous considérez le carré d'aire 1 englobé par i-hat et j-hat comme base de toute cette forme, alors son volume est le même que sa hauteur, qui est la troisième coordonnée de notre vecteur.",
  "n_reviews": 0
 },
 {
  "input": "And likewise, the wacky way to think about the other coordinates of the vector would be to form a parallelepiped using the vector and then all of the basis vectors other than the one corresponding to the direction you're looking for.",
  "translatedText": "Et de même, la façon farfelue de penser aux autres coordonnées du vecteur serait de former un parallélépipède en utilisant le vecteur puis tous les vecteurs de base autres que celui correspondant à la direction que vous recherchez.",
  "n_reviews": 0
 },
 {
  "input": "Then the volume of this gives you the coordinate.",
  "translatedText": "Ensuite, le volume de celui-ci vous donne les coordonnées.",
  "n_reviews": 0
 },
 {
  "input": "Or rather, we should be talking about the signed volume of parallelepiped in the sense described in the determinant video using the right-hand rule.",
  "translatedText": "Ou plutôt, il faudrait parler du volume signé du parallélépipède au sens décrit dans la vidéo déterminante en utilisant la règle de droite.",
  "n_reviews": 0
 },
 {
  "input": "So the order in which you list these three vectors matters.",
  "translatedText": "L’ordre dans lequel vous répertoriez ces trois vecteurs est donc important.",
  "n_reviews": 0
 },
 {
  "input": "That way, negative coordinates still make sense.",
  "translatedText": "De cette façon, les coordonnées négatives ont toujours un sens.",
  "n_reviews": 0
 },
 {
  "input": "Okay, so why think of coordinates as areas and volumes like this?",
  "translatedText": "D'accord, alors pourquoi considérer les coordonnées comme des zones et des volumes comme celui-ci ?",
  "n_reviews": 0
 },
 {
  "input": "Well, as you apply some sort of matrix transformation, the areas of these parallelograms, well, they don't stay the same, they might get scaled up or down.",
  "translatedText": "Eh bien, lorsque vous appliquez une sorte de transformation matricielle, les aires de ces parallélogrammes ne restent pas les mêmes, elles peuvent être agrandies ou réduites.",
  "n_reviews": 0
 },
 {
  "input": "But, and this is the key idea of determinants, all of the areas get scaled by the same amount, namely the determinant of our transformation matrix.",
  "translatedText": "Mais, et c'est l'idée clé des déterminants, tous les domaines sont mis à l'échelle de la même manière, à savoir le déterminant de notre matrice de transformation.",
  "n_reviews": 0
 },
 {
  "input": "For example, if you look at the parallelogram spanned by the vector where your first basis vector lands, which is the first column of the matrix, and the transformed version of xy, what is its area?",
  "translatedText": "Par exemple, si vous regardez le parallélogramme engendré par le vecteur où atterrit votre premier vecteur de base, qui est la première colonne de la matrice, et la version transformée de xy, quelle est son aire ?",
  "n_reviews": 0
 },
 {
  "input": "Well, this is the transformed version of the parallelogram we were looking at earlier, the one whose area was the y-coordinate of the mystery input vector.",
  "translatedText": "Eh bien, c'est la version transformée du parallélogramme que nous avons examiné plus tôt, celui dont l'aire était la coordonnée y du vecteur d'entrée mystère.",
  "n_reviews": 0
 },
 {
  "input": "So its area is just going to be the determinant of the transformation multiplied by that y-coordinate.",
  "translatedText": "Son aire sera donc simplement le déterminant de la transformation multipliée par cette coordonnée y.",
  "n_reviews": 0
 },
 {
  "input": "So that means we can solve for y by taking the area of this new parallelogram in the output space divided by the determinant of the full transformation.",
  "translatedText": "Cela signifie donc que nous pouvons résoudre y en prenant l'aire de ce nouveau parallélogramme dans l'espace de sortie divisée par le déterminant de la transformation complète.",
  "n_reviews": 0
 },
 {
  "input": "And how do you get that area?",
  "translatedText": "Et comment obtenir cette zone ?",
  "n_reviews": 0
 },
 {
  "input": "Well, we know the coordinates for where the mystery input vector lands, that's the whole point of a linear system of equations.",
  "translatedText": "Eh bien, nous connaissons les coordonnées de l'endroit où atterrit le vecteur d'entrée mystérieux, c'est tout l'intérêt d'un système linéaire d'équations.",
  "n_reviews": 0
 },
 {
  "input": "So what you might do is create a new matrix whose first column is the same as that of our matrix, but whose second column is the output vector, and then you take its determinant.",
  "translatedText": "Donc, ce que vous pourriez faire est de créer une nouvelle matrice dont la première colonne est la même que celle de notre matrice, mais dont la deuxième colonne est le vecteur de sortie, puis de prendre son déterminant.",
  "n_reviews": 0
 },
 {
  "input": "So look at that, just using data from the output of the transformation, namely the columns of the matrix and the coordinates of our output vector, we can recover the y-coordinate of the mystery input vector, which is halfway to solving the system.",
  "translatedText": "Alors regardez ça, en utilisant simplement les données de la sortie de la transformation, à savoir les colonnes de la matrice et les coordonnées de notre vecteur de sortie, nous pouvons récupérer la coordonnée y du vecteur d'entrée mystère, ce qui est à mi-chemin de la résolution du système.",
  "n_reviews": 0
 },
 {
  "input": "Likewise, the same idea can give us the x-coordinate.",
  "translatedText": "De même, la même idée peut nous donner la coordonnée x.",
  "n_reviews": 0
 },
 {
  "input": "Look at the parallelogram we defined earlier, which encodes the x-coordinate of the mystery input vector spanned by that vector and j-hat.",
  "translatedText": "Regardez le parallélogramme que nous avons défini plus tôt, qui code la coordonnée x du vecteur d'entrée mystère engendré par ce vecteur et j-hat.",
  "n_reviews": 0
 },
 {
  "input": "The transformed version of this guy is spanned by the output vector and the second column of the matrix, and its area will have been multiplied by the determinant of that matrix.",
  "translatedText": "La version transformée de ce type est couverte par le vecteur de sortie et la deuxième colonne de la matrice, et son aire aura été multipliée par le déterminant de cette matrice.",
  "n_reviews": 0
 },
 {
  "input": "So to solve for x, you can take this new area divided by the determinant of the full transformation.",
  "translatedText": "Donc, pour résoudre x, vous pouvez prendre cette nouvelle aire divisée par le déterminant de la transformation complète.",
  "n_reviews": 0
 },
 {
  "input": "And similar to what we did before, you can compute the area of that output parallelogram by creating a new matrix whose first column is the output vector and whose second column is the same as the original matrix.",
  "translatedText": "Et comme nous l'avons fait auparavant, vous pouvez calculer l'aire de ce parallélogramme de sortie en créant une nouvelle matrice dont la première colonne est le vecteur de sortie et dont la deuxième colonne est la même que la matrice d'origine.",
  "n_reviews": 0
 },
 {
  "input": "So again, just using data from the output space, the numbers we see in our original linear system, we can solve for what x must be.",
  "translatedText": "Encore une fois, en utilisant simplement les données de l’espace de sortie, les nombres que nous voyons dans notre système linéaire d’origine, nous pouvons déterminer ce que x doit être.",
  "n_reviews": 0
 },
 {
  "input": "This formula for finding the solutions to a linear system of equations is known as Cramer's rule.",
  "translatedText": "Cette formule permettant de trouver les solutions d'un système linéaire d'équations est connue sous le nom de règle de Cramer.",
  "n_reviews": 0
 },
 {
  "input": "Here, just to sanity check ourselves, plug in some numbers here.",
  "translatedText": "Ici, juste pour vérifier notre santé mentale, insérez quelques chiffres ici.",
  "n_reviews": 0
 },
 {
  "input": "The determinant of that top altered matrix is 4 plus 2, which is 6, and the bottom determinant is 2, so the x-coordinate should be 3.",
  "translatedText": "Le déterminant de cette matrice modifiée supérieure est 4 plus 2, soit 6, et le déterminant inférieur est 2, donc la coordonnée x doit être 3.",
  "n_reviews": 0
 },
 {
  "input": "And indeed, looking back at the input vector we started with, the x-coordinate is 3.",
  "translatedText": "Et en effet, en repensant au vecteur d’entrée avec lequel nous avons commencé, la coordonnée x est 3.",
  "n_reviews": 0
 },
 {
  "input": "Likewise, Cramer's rule suggests that the y-coordinate should be 4 divided by 2, or 2, and that is in fact the y-coordinate of the input vector we were starting with.",
  "translatedText": "De même, la règle de Cramer suggère que la coordonnée y devrait être 4 divisée par 2, ou 2, et c'est en fait la coordonnée y du vecteur d'entrée avec lequel nous commencions.",
  "n_reviews": 0
 },
 {
  "input": "The case with three dimensions or more is similar, and I highly recommend you take a moment to pause and think through it yourself.",
  "translatedText": "Le cas avec trois dimensions ou plus est similaire, et je vous recommande fortement de prendre un moment pour faire une pause et y réfléchir vous-même.",
  "n_reviews": 0
 },
 {
  "input": "Here, I'll give you a little bit of momentum.",
  "translatedText": "Ici, je vais vous donner un peu d'élan.",
  "n_reviews": 0
 },
 {
  "input": "What we have is a known transformation given by some 3x3 matrix and a known output vector given by the right side of our linear system, and we want to know what input lands on that output.",
  "translatedText": "Ce que nous avons est une transformation connue donnée par une matrice 3x3 et un vecteur de sortie connu donné par le côté droit de notre système linéaire, et nous voulons savoir quelle entrée atterrit sur cette sortie.",
  "n_reviews": 0
 },
 {
  "input": "And if you think of, say, the z-coordinate of that input vector as the volume of that special parallelepiped we were looking at earlier, spanned by i-hat, j-hat, and the mystery input vector, what happens to that volume after the transformation?",
  "translatedText": "Et si vous considérez, disons, la coordonnée z de ce vecteur d'entrée comme le volume de ce parallélépipède spécial que nous regardions plus tôt, engendré par i-hat, j-hat et le mystérieux vecteur d'entrée, qu'arrive-t-il à ce volume ? après la transformation ?",
  "n_reviews": 0
 },
 {
  "input": "And what are the various ways you can compute that volume?",
  "translatedText": "Et quelles sont les différentes manières de calculer ce volume ?",
  "n_reviews": 0
 },
 {
  "input": "Really, pause and think through the details of generalizing this to higher dimensions, finding an expression for each coordinate of the solution to a larger linear system.",
  "translatedText": "Vraiment, faites une pause et réfléchissez aux détails de la généralisation de cela à des dimensions supérieures, en trouvant une expression pour chaque coordonnée de la solution à un système linéaire plus grand.",
  "n_reviews": 0
 },
 {
  "input": "Thinking through more general cases like this and convincing yourself that it works and why it works is where all the learning really happens, much more so than listening to some dude on YouTube walk you through the same reasoning again.",
  "translatedText": "Réfléchir à des cas plus généraux comme celui-ci et se convaincre que cela fonctionne et pourquoi cela fonctionne est là où tout l'apprentissage se produit réellement, bien plus que d'écouter un mec sur YouTube vous expliquer à nouveau le même raisonnement.",
  "n_reviews": 0
 }
]