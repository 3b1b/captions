[
 {
  "input": "In a previous video I've talked about linear systems of equations, and I sort of brushed aside the discussion of actually computing solutions to these systems.",
  "translatedText": "In einem früheren Video habe ich über lineare Gleichungssysteme gesprochen und die Diskussion über die tatsächliche Berechnung der Lösungen dieser Systeme etwas beiseite geschoben.",
  "model": "DeepL",
  "from_community_srt": "In einem früheren Video habe ich über linear gesprochen Gleichungssysteme, und ich habe irgendwie gebürstet abgesehen von der Diskussion über das eigentliche Rechnen Lösungen für diese Systeme.",
  "n_reviews": 0,
  "start": 11.2,
  "end": 19.14
 },
 {
  "input": "And while it's true that number crunching is typically something we leave to the computers, digging into some of these computational methods is a good litmus test for whether or not you actually understand what's going on, since that's really where the rubber meets the road.",
  "translatedText": "Es stimmt zwar, dass wir das Zahlenrechnen normalerweise den Computern überlassen, aber wenn du dich mit einigen dieser Berechnungsmethoden beschäftigst, ist das ein guter Test dafür, ob du wirklich verstehst, worum es geht, denn hier trifft der Gummi auf die Straße.",
  "model": "DeepL",
  "from_community_srt": "Und während es wahr ist, dass Zahlen knirschen ist etwas, das wir normalerweise den Computern überlassen, einige dieser Berechnungsmethoden untersuchen ist ein guter Lackmustest dafür, ob Sie oder nicht verstehe eigentlich was da los ist Hier trifft der Gummi wirklich auf das",
  "n_reviews": 0,
  "start": 19.7,
  "end": 31.52
 },
 {
  "input": "Here I want to describe the geometry behind a certain method for computing solutions to these systems, known as Cramer's rule.",
  "translatedText": "Hier möchte ich die Geometrie beschreiben, die hinter einer bestimmten Methode zur Berechnung von Lösungen für diese Systeme steht, die als Cramersche Regel bekannt ist.",
  "model": "DeepL",
  "from_community_srt": "Straße. Hier möchte ich die dahinter stehende Geometrie beschreiben eine bestimmte Methode zur Berechnung von Lösungen zu diese Systeme, bekannt als Cramer-Regel.",
  "n_reviews": 0,
  "start": 32.12,
  "end": 38.88
 },
 {
  "input": "The relevant background here is understanding determinants, a little bit of dot products, and of course linear systems of equations, so be sure to watch the relevant videos on those topics if you're unfamiliar or rusty.",
  "translatedText": "Der relevante Hintergrund ist das Verständnis von Determinanten, ein wenig von Punktprodukten und natürlich von linearen Gleichungssystemen, also schau dir unbedingt die entsprechenden Videos zu diesen Themen an, wenn du damit nicht vertraut oder eingerostet bist.",
  "model": "DeepL",
  "from_community_srt": "Der relevante Hintergrund, der hier benötigt wird, ist ein Verständnis von Determinanten, Punktprodukten, und von linearen Gleichungssystemen, so sei Achten Sie darauf, die relevanten Videos auf diesen zu sehen Themen, wenn Sie unbekannt oder rostig sind.",
  "n_reviews": 0,
  "start": 39.68,
  "end": 50.42
 },
 {
  "input": "But first I should say up front that this Cramer's rule is not actually the best way for computing solutions to linear systems Gaussian elimination for example will always be faster.",
  "translatedText": "Zunächst sollte ich aber vorausschicken, dass die Cramersche Regel nicht die beste Methode ist, um Lösungen für lineare Systeme zu berechnen. Die Gaußsche Eliminierung zum Beispiel ist immer schneller.",
  "model": "DeepL",
  "from_community_srt": "Aber zuerst! Ich sollte vorweg sagen, dass Cramer die Regel ist ist nicht der beste Weg für Computerlösungen zu linearen Gleichungssystemen. Gaußsche Eliminierung zum Beispiel wird immer sei schneller.",
  "n_reviews": 0,
  "start": 51.02,
  "end": 61.26
 },
 {
  "input": "So why learn it?",
  "translatedText": "Warum es also lernen?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 61.98,
  "end": 63.52
 },
 {
  "input": "Well think of it as a sort of cultural excursion.",
  "translatedText": "Betrachte es als eine Art kulturellen Ausflug.",
  "model": "DeepL",
  "from_community_srt": "Warum also lernen? Betrachten Sie dies als eine Art kulturellen Ausflug;",
  "n_reviews": 0,
  "start": 63.78,
  "end": 65.84
 },
 {
  "input": "It's a helpful exercise in deepening your knowledge of the theory behind these systems.",
  "translatedText": "Es ist eine hilfreiche Übung, um dein Wissen über die Theorie hinter diesen Systemen zu vertiefen.",
  "model": "DeepL",
  "from_community_srt": "Es ist eine hilfreiche Übung zur Vertiefung Ihrer Kenntnis der Theorie dieser Systeme.",
  "n_reviews": 0,
  "start": 66.42,
  "end": 70.46
 },
 {
  "input": "Wrapping your mind around this concept is going to help consolidate ideas from linear algebra, like the determinant and linear systems, by seeing how they relate to each other.",
  "translatedText": "Wenn du dir dieses Konzept vor Augen führst, kannst du Ideen aus der linearen Algebra, wie die Determinante und lineare Systeme, festigen, indem du siehst, wie sie miteinander zusammenhängen.",
  "model": "DeepL",
  "from_community_srt": "Wenn Sie sich mit diesem Konzept beschäftigen, werden Sie es tun helfen, Ideen aus der linearen Algebra zu konsolidieren, wie die determinanten und linearen Systeme, von sehen, wie sie sich zueinander verhalten.",
  "n_reviews": 0,
  "start": 71.04,
  "end": 79.62
 },
 {
  "input": "Also from a purely artistic standpoint the ultimate result here is just really pretty to think about, way more so than Gaussian elimination.",
  "translatedText": "Auch aus rein künstlerischer Sicht ist das Endergebnis sehr hübsch anzusehen, viel hübscher als die Gaußsche Eliminierung.",
  "model": "DeepL",
  "from_community_srt": "Auch aus rein künstlerischer Sicht ist die Das Endergebnis ist einfach sehr schön zu denken über, viel mehr als die Gaußsche Eliminierung.",
  "n_reviews": 0,
  "start": 80.1,
  "end": 86.88
 },
 {
  "input": "Alright so the setup here will be some linear system of equations, say with two unknowns x and y and two equations.",
  "translatedText": "Also, wir gehen hier von einem linearen Gleichungssystem aus, z. B. mit zwei Unbekannten x und y und zwei Gleichungen.",
  "model": "DeepL",
  "from_community_srt": "Okay, das Setup hier wird also etwas linear sein Gleichungssystem, etwa mit zwei Unbekannten, x und y und zwei Gleichungen.",
  "n_reviews": 0,
  "start": 88.68,
  "end": 95.62
 },
 {
  "input": "In principle everything we're talking about will also work for systems with larger number of unknowns and the same number of equations, but for simplicity a smaller example is just nicer to hold in our heads.",
  "translatedText": "Im Prinzip funktioniert alles, was wir hier besprechen, auch für Systeme mit einer größeren Anzahl von Unbekannten und der gleichen Anzahl von Gleichungen, aber der Einfachheit halber ist ein kleineres Beispiel einfach schöner, um es im Kopf zu behalten.",
  "model": "DeepL",
  "from_community_srt": "Im Prinzip alles, worüber wir sprechen wird Systeme mit einer größeren Anzahl von arbeiten Unbekannte und die gleiche Anzahl von Gleichungen. Der Einfachheit halber ist ein kleineres Beispiel schöner in unseren Köpfen halten.",
  "n_reviews": 0,
  "start": 96.3,
  "end": 105.58
 },
 {
  "input": "So as I talked about in a previous video you can think of this setup geometrically as a certain known matrix transforming an unknown vector x y where you know what the output is going to be, in this case negative 4 negative 2.",
  "translatedText": "Wie ich bereits in einem früheren Video erklärt habe, kannst du dir diesen Aufbau geometrisch als eine bestimmte bekannte Matrix vorstellen, die einen unbekannten Vektor x y transformiert, wobei du weißt, wie das Ergebnis aussehen wird, in diesem Fall negativ 4 negativ 2.",
  "model": "DeepL",
  "from_community_srt": "Also, wie ich in einem vorherigen Video erwähnt habe, Sie können sich dieses Setup geometrisch vorstellen als eine bestimmte bekannte Matrix, die eine unbekannter Vektor, [x; y], wo du was weißt die Ausgabe wird in diesem Fall [-4;",
  "n_reviews": 0,
  "start": 106.32,
  "end": 120.04
 },
 {
  "input": "Remember the columns of this matrix are telling you how that matrix acts as a transform, each one telling you where the basis vectors of the input space land.",
  "translatedText": "Denke daran, dass die Spalten dieser Matrix dir sagen, wie sich diese Matrix als Transformation verhält, denn jede Spalte sagt dir, wo die Basisvektoren des Eingaberaums landen.",
  "model": "DeepL",
  "from_community_srt": "-2]. Denken Sie daran, die Spalten dieser Matrix zeigen Sie, wie die Matrix als Transformation wirkt, jeweils eine, die Ihnen sagt, wo die Basisvektoren von das Eingaberaumland.",
  "n_reviews": 0,
  "start": 120.8,
  "end": 130.08
 },
 {
  "input": "So what we have is a sort of puzzle, which input vector x y is going to land on this output negative 4 negative 2.",
  "translatedText": "Wir haben also eine Art Rätsel: Welcher Eingangsvektor x y wird auf dem Ausgang negative 4 negative 2 landen.",
  "model": "DeepL",
  "from_community_srt": "Das ist also eine Art Rätsel, welche Eingabe [x;",
  "n_reviews": 0,
  "start": 130.86,
  "end": 138.6
 },
 {
  "input": "One way to think about our little puzzle here is that we know the given output vector is some linear combination of the columns of the matrix x times the vector where i hat lands plus y times the vector where j hat lands, but what we want is to figure out what exactly that linear combination should be.",
  "translatedText": "Eine Möglichkeit, unser kleines Rätsel zu lösen, ist, dass wir wissen, dass der Ausgangsvektor eine Linearkombination aus den Spalten der Matrix x mal dem Vektor, in dem das i-Hut landet, plus y mal dem Vektor, in dem das j-Hut landet, ist, aber wir wollen herausfinden, was genau diese Linearkombination sein sollte.",
  "model": "DeepL",
  "from_community_srt": "y], wird dir das geben Ausgabe [-4; -2]? Denken Sie daran, die Die Art der Antwort, die Sie hier erhalten,",
  "n_reviews": 0,
  "start": 139.7,
  "end": 156.22
 },
 {
  "input": "Remember the type of answer you get here can depend on whether or not the transformation squishes all of space into a lower dimension, that is if it has a zero determinant.",
  "translatedText": "Denke daran, dass die Art der Antwort, die du hier erhältst, davon abhängen kann, ob die Transformation den gesamten Raum in eine niedrigere Dimension quetscht oder nicht, d.h. ob sie eine Null-Determinante hat.",
  "model": "DeepL",
  "from_community_srt": "kann davon abhängen ob die Transformation zerquetscht oder nicht den gesamten Raum in eine niedrigere Dimension. Das heißt, wenn es keine Determinante hat.",
  "n_reviews": 0,
  "start": 157.24,
  "end": 166.1
 },
 {
  "input": "In that case either none of the inputs land on our given output, or there's a whole bunch of inputs landing on that output.",
  "translatedText": "In diesem Fall landet entweder keiner der Inputs auf dem gegebenen Output oder ein ganzer Haufen Inputs landet auf diesem Output.",
  "model": "DeepL",
  "from_community_srt": "In diesem Fall landet keiner der Eingänge auf unsere gegebene Ausgabe oder es gibt eine ganze Reihe von Eingaben,",
  "n_reviews": 0,
  "start": 166.1,
  "end": 173.9
 },
 {
  "input": "But for this video we'll limit our view to the case of a non-zero determinant, meaning the outputs of this transformation still span the full in-dimensional space that it started in.",
  "translatedText": "In diesem Video beschränken wir uns auf den Fall, dass die Determinante nicht Null ist. Das bedeutet, dass die Ergebnisse dieser Transformation immer noch den gesamten eindimensionalen Raum umfassen, in dem sie begonnen hat.",
  "model": "DeepL",
  "from_community_srt": "die auf dieser Ausgabe landen. Aber für dieses Video werden wir unsere Sicht einschränken auf den Fall einer Determinante ungleich Null, was bedeutet Die Ausgabe dieser Transformation erstreckt sich immer noch der volle n-dimensionale Raum,",
  "n_reviews": 0,
  "start": 177.06,
  "end": 187.14
 },
 {
  "input": "Every input lands on one and only one output, and every output has one and only one input.",
  "translatedText": "Jeder Input landet auf einem und nur einem Output und jeder Output hat einen und nur einen Input.",
  "model": "DeepL",
  "from_community_srt": "in dem es begann; Jeder Eingang landet auf einem und nur einem Ausgang und jeder Ausgang hat einen und nur einen Eingang.",
  "n_reviews": 0,
  "start": 187.5,
  "end": 192.7
 },
 {
  "input": "As a first pass let me show you an idea that's wrong but in the right direction.",
  "translatedText": "Als ersten Durchgang möchte ich dir eine Idee zeigen, die zwar falsch ist, aber in die richtige Richtung geht.",
  "model": "DeepL",
  "from_community_srt": "Eine Möglichkeit, über unser Rätsel nachzudenken, ist die folgende Wir wissen, dass der gegebene Ausgabevektor linear ist Kombination der Spalten der Matrix; x * (der Vektor, in dem i-hat landet) + y * (der Vektor, wo j-hat landet), aber wir wollen Berechnen Sie, was genau x und y sind. Lassen Sie mich als ersten Durchgang eine Idee zeigen, die ist falsch,",
  "n_reviews": 0,
  "start": 194.18,
  "end": 198.16
 },
 {
  "input": "The x coordinate of this mystery input vector is what you get by taking its dot product with the first basis vector 1 0.",
  "translatedText": "Die x-Koordinate dieses mysteriösen Eingangsvektors erhältst du, wenn du sein Punktprodukt mit dem ersten Basisvektor 1 0 bildest.",
  "model": "DeepL",
  "from_community_srt": "aber in die richtige Richtung. Die x-Koordinate dieses geheimnisvollen Eingabevektors ist das, was Sie erhalten, wenn Sie das Punktprodukt einnehmen mit dem ersten Basisvektor [1;",
  "n_reviews": 0,
  "start": 198.8,
  "end": 205.44
 },
 {
  "input": "Likewise the y coordinate is what you get by dotting it with the second basis vector 0 1.",
  "translatedText": "Die y-Koordinate ist das, was du erhältst, wenn du sie mit dem zweiten Basisvektor 0 1 punktierst.",
  "model": "DeepL",
  "from_community_srt": "0]. Ebenso erhalten Sie die y-Koordinate durch Punktieren mit dem zweiten Basisvektor, [0;",
  "n_reviews": 0,
  "start": 206.16,
  "end": 211.4
 },
 {
  "input": "So maybe you hope that after the transformation the dot products with the transformed version of the mystery vector with the transformed version of the basis vectors will also be these coordinates x and y.",
  "translatedText": "Du hoffst also vielleicht, dass nach der Transformation die Punktprodukte mit der transformierten Version des Mystery-Vektors mit der transformierten Version der Basisvektoren auch diese Koordinaten x und y sind.",
  "model": "DeepL",
  "from_community_srt": "1]. Vielleicht hoffen Sie also, dass nach der Transformation die Punktprodukte mit der transformierten Version des Mystery-Vektors mit dem transformierten Versionen der Basisvektoren werden ebenfalls sein diese Koordinaten x und y.",
  "n_reviews": 0,
  "start": 211.9,
  "end": 223.24
 },
 {
  "input": "That'd be fantastic because we know what the transformed version of each of those vectors are.",
  "translatedText": "Das wäre fantastisch, denn dann wüssten wir, wie die transformierte Version jedes dieser Vektoren aussieht.",
  "model": "DeepL",
  "from_community_srt": "Das wäre fantastisch, weil wir das kennen transformierte Versionen jedes dieser Vektoren.",
  "n_reviews": 0,
  "start": 223.94,
  "end": 228.74
 },
 {
  "input": "There's just one problem with it, it's not at all true.",
  "translatedText": "Es gibt nur ein Problem damit, es stimmt überhaupt nicht.",
  "model": "DeepL",
  "from_community_srt": "Es gibt nur ein Problem damit:",
  "n_reviews": 0,
  "start": 231.18,
  "end": 234.2
 },
 {
  "input": "For most linear transformations the dot product before and after the transformation will look very different.",
  "translatedText": "Bei den meisten linearen Transformationen wird das Punktprodukt vor und nach der Transformation sehr unterschiedlich aussehen.",
  "model": "DeepL",
  "from_community_srt": "es ist überhaupt nicht wahr! Für die meisten linearen Transformationen das Punktprodukt vor und nach der Transformation wird sehr verschieden.",
  "n_reviews": 0,
  "start": 234.64,
  "end": 240.24
 },
 {
  "input": "For example you could have two vectors generally pointing in the same direction with a positive dot product which get pulled apart from each other during the transformation in such a way that they have a negative dot product.",
  "translatedText": "Du könntest zum Beispiel zwei Vektoren haben, die im Allgemeinen in die gleiche Richtung zeigen und ein positives Punktprodukt haben, die aber während der Transformation so auseinandergezogen werden, dass sie ein negatives Punktprodukt haben.",
  "model": "DeepL",
  "from_community_srt": "Beispielsweise könnten Sie im Allgemeinen zwei Vektoren haben in die gleiche Richtung zeigen, mit einem positiven Punktprodukt, das von jedem weggezogen wird andere während der Transformation, in einem solchen Art und Weise, dass sie dann ein negatives Punktprodukt haben.",
  "n_reviews": 0,
  "start": 240.8,
  "end": 251.52
 },
 {
  "input": "Likewise things that start off perpendicular with dot product 0, like the two basis vectors, quite often don't stay perpendicular to each other after the transformation, that is they don't preserve that 0 dot product.",
  "translatedText": "Auch Dinge, die zunächst mit dem Punktprodukt 0 senkrecht zueinander stehen, wie die beiden Basisvektoren, stehen nach der Transformation oft nicht mehr senkrecht zueinander, d.h. sie behalten das Punktprodukt 0 nicht bei.",
  "model": "DeepL",
  "from_community_srt": "Ebenso, wenn die Dinge senkrecht beginnen, mit Punktprodukt Null, wie die beiden Basis Vektoren gibt es keine Garantie dafür bleibt nach der Transformation senkrecht, Erhaltung dieses Nullpunktprodukts.",
  "n_reviews": 0,
  "start": 252.22,
  "end": 263.48
 },
 {
  "input": "And looking at the example I just showed dot products certainly aren't preserved, they tend to get bigger since most vectors are getting stretched out.",
  "translatedText": "Und wenn du dir das Beispiel ansiehst, das ich gerade gezeigt habe, bleiben die Punktprodukte sicherlich nicht erhalten, sondern werden eher größer, da die meisten Vektoren gestreckt werden.",
  "model": "DeepL",
  "from_community_srt": "In dem Beispiel, das wir uns angesehen haben, handelt es sich um Punktprodukte sicherlich nicht erhalten. Sie neigen dazu, größer zu werden, da die meisten Vektoren werden gedehnt.",
  "n_reviews": 0,
  "start": 264.1,
  "end": 270.3
 },
 {
  "input": "In fact, worthwhile side note here, transformations which do preserve dot products are special enough to have their own name, orthonormal transformations.",
  "translatedText": "Eine interessante Randbemerkung: Transformationen, die Punktprodukte erhalten, sind so speziell, dass sie einen eigenen Namen haben: Orthonormaltransformationen.",
  "model": "DeepL",
  "from_community_srt": "In der Tat Transformationen, die erhalten bleiben dot Produkte sind speziell genug, um ihre zu haben eigener Name: Orthonormale Transformationen.",
  "n_reviews": 0,
  "start": 271.04,
  "end": 279.1
 },
 {
  "input": "These are the ones that leave all of the basis vectors perpendicular to each other and still with unit lengths.",
  "translatedText": "Das sind diejenigen, bei denen alle Basisvektoren senkrecht zueinander stehen und immer noch Einheitslängen haben.",
  "model": "DeepL",
  "from_community_srt": "Dies sind diejenigen, die alle Basis verlassen Vektoren senkrecht zueinander mit Einheit Längen.",
  "n_reviews": 0,
  "start": 279.72,
  "end": 284.66
 },
 {
  "input": "You often think of these as the rotation matrices, they correspond to rigid motion with no stretching or squishing or morphing.",
  "translatedText": "Du denkst dabei oft an die Rotationsmatrizen, die einer starren Bewegung ohne Dehnung, Quetschung oder Morphing entsprechen.",
  "model": "DeepL",
  "from_community_srt": "Sie stellen sich diese oft als Rotationsmatrizen vor. Die entsprechen einer starren Bewegung ohne Dehnung,",
  "n_reviews": 0,
  "start": 285.74,
  "end": 292.2
 },
 {
  "input": "Solving a linear system with an orthonormal matrix is actually super easy.",
  "translatedText": "Ein lineares System mit einer orthonormalen Matrix zu lösen ist eigentlich super einfach.",
  "model": "DeepL",
  "from_community_srt": "Quetschen oder Verwandeln. Lösen eines linearen Systems mit einem Orthonormalen Matrix ist sehr einfach:",
  "n_reviews": 0,
  "start": 293.0,
  "end": 296.78
 },
 {
  "input": "Because dot products are preserved, taking the dot product between the vector and all the columns of your matrix will be the same as taking the dot product between the mystery input vector and all of the basis vectors, which is the same as just finding the coordinates of that mystery input.",
  "translatedText": "Da die Punktprodukte erhalten bleiben, ist das Punktprodukt zwischen dem Vektor und allen Spalten deiner Matrix dasselbe wie das Punktprodukt zwischen dem mysteriösen Eingangsvektor und allen Basisvektoren, was dasselbe ist wie das Finden der Koordinaten des mysteriösen Eingangs.",
  "model": "DeepL",
  "from_community_srt": "Da sind Punktprodukte konserviert, wobei das Punktprodukt dazwischen genommen wird den Ausgabevektor und alle Spalten Ihres Die Matrix entspricht der Aufnahme des Punktes Produkte zwischen dem Eingabevektor und allen die Basisvektoren, was dem Finden entspricht die Koordinaten des Eingabevektors.",
  "n_reviews": 0,
  "start": 297.26,
  "end": 312.98
 },
 {
  "input": "So in that very special case, x would be the dot product of the first column with the output vector, and y would be the dot product of the second column with the output vector.",
  "translatedText": "In diesem speziellen Fall wäre x also das Punktprodukt der ersten Spalte mit dem Ausgangsvektor und y wäre das Punktprodukt der zweiten Spalte mit dem Ausgangsvektor.",
  "model": "DeepL",
  "from_community_srt": "In diesem ganz besonderen Fall wäre x also das Punktprodukt der ersten Spalte mit dem Ausgabevektor und y wäre das Punktprodukt der zweiten Spalte mit dem Ausgabevektor.",
  "n_reviews": 0,
  "start": 313.68,
  "end": 323.76
 },
 {
  "input": "Why am I bringing this up when this idea breaks down for almost all linear systems?",
  "translatedText": "Warum erwähne ich das, wenn diese Idee für fast alle linearen Systeme nicht funktioniert?",
  "model": "DeepL",
  "from_community_srt": "Nun, obwohl diese Idee für zusammenbricht Bei den meisten linearen Systemen weist es uns in die Richtung",
  "n_reviews": 0,
  "start": 326.82,
  "end": 330.86
 },
 {
  "input": "Well, it points us in a direction of something to look for.",
  "translatedText": "Nun, es zeigt uns eine Richtung, nach der wir suchen sollten.",
  "model": "DeepL",
  "from_community_srt": "von etwas zu suchen:",
  "n_reviews": 0,
  "start": 331.42,
  "end": 334.08
 },
 {
  "input": "Is there an alternate geometric understanding for the coordinates of our input vector that remains unchanged after the transformation?",
  "translatedText": "Gibt es ein alternatives geometrisches Verständnis für die Koordinaten unseres Eingangsvektors, das nach der Transformation unverändert bleibt?",
  "model": "DeepL",
  "from_community_srt": "Gibt es eine Alternative geometrisches Verständnis für die Koordinaten unseres Eingabevektors,",
  "n_reviews": 0,
  "start": 334.32,
  "end": 341.66
 },
 {
  "input": "If your mind has been mulling over determinants, you might think of the following clever idea.",
  "translatedText": "Wenn du über die Determinanten nachgedacht hast, könnte dir die folgende clevere Idee einfallen.",
  "model": "DeepL",
  "from_community_srt": "der unverändert bleibt nach der Transformation? Wenn Ihr Geist über Determinanten nachgedacht hat, Sie könnten an diese clevere Idee denken:",
  "n_reviews": 0,
  "start": 342.36,
  "end": 346.8
 },
 {
  "input": "Take the parallelogram defined by the first basis vector i-hat and the mystery input vector xy.",
  "translatedText": "Nimm das Parallelogramm, das durch den ersten Basisvektor i-hat und den geheimnisvollen Eingangsvektor xy definiert wird.",
  "model": "DeepL",
  "from_community_srt": "Nehmen Sie das durch die erste Basis definierte Parallelogramm Vektor, i-Hut und der Mystery-Eingabevektor [x;",
  "n_reviews": 0,
  "start": 347.36,
  "end": 353.76
 },
 {
  "input": "The area of this parallelogram is the base, 1, times the height perpendicular to that base, which is the y-coordinate of that input vector.",
  "translatedText": "Der Flächeninhalt dieses Parallelogramms ist die Basis 1 mal die Höhe senkrecht zu dieser Basis, also die y-Koordinate des Eingangsvektors.",
  "model": "DeepL",
  "from_community_srt": "y]. Die Fläche dieses Parallelogramms ist seine Basis, 1, mal die Höhe senkrecht dazu Basis, die die y-Koordinate unserer Eingabe ist Vektor.",
  "n_reviews": 0,
  "start": 354.44,
  "end": 362.96
 },
 {
  "input": "So the area of that parallelogram is a sort of screwy roundabout way to describe the vector's y-coordinate.",
  "translatedText": "Die Fläche des Parallelogramms ist also eine Art verrückter Umweg, um die y-Koordinate des Vektors zu beschreiben.",
  "model": "DeepL",
  "from_community_srt": "Der Bereich dieses Parallelogramms ist also sortiert eines verrückten Kreisverkehrs Weg, um die zu beschreiben y-Koordinate des Vektors;",
  "n_reviews": 0,
  "start": 363.68,
  "end": 369.96
 },
 {
  "input": "It's a wacky way to talk about coordinates, but run with me.",
  "translatedText": "Es ist eine verrückte Art, über Koordinaten zu sprechen, aber mach mit.",
  "model": "DeepL",
  "from_community_srt": "Es ist ein verrückter Weg über Koordinaten sprechen, aber mit mir laufen.",
  "n_reviews": 0,
  "start": 370.42,
  "end": 373.14
 },
 {
  "input": "And actually, to be a little more accurate, you should think of this as the signed area of that parallelogram, in the sense described in the determinant video.",
  "translatedText": "Um genau zu sein, solltest du dir das als den vorzeichenbehafteten Flächeninhalt des Parallelogramms vorstellen, so wie es im Video über die Determinante beschrieben wurde.",
  "model": "DeepL",
  "from_community_srt": "Um genauer zu sein, sollten Sie es tatsächlich tun Denken Sie an den signierten Bereich dieses Parallelogramms. in dem von der Determinante beschriebenen Sinne Video.",
  "n_reviews": 0,
  "start": 373.7,
  "end": 381.64
 },
 {
  "input": "That way, a vector with a negative y-coordinate would correspond to a negative area for this parallelogram, at least if you think of i-hat as in some sense being the first out of these two vectors defining the parallelogram.",
  "translatedText": "Auf diese Weise würde ein Vektor mit einer negativen y-Koordinate einer negativen Fläche für dieses Parallelogramm entsprechen, zumindest wenn du dir i-hat in gewisser Weise als den ersten der beiden Vektoren vorstellst, die das Parallelogramm definieren.",
  "model": "DeepL",
  "from_community_srt": "Auf diese Weise entsteht ein Vektor mit negativer y-Koordinate würde dafür einem negativen Bereich entsprechen Parallelogramm. Symmetrisch,",
  "n_reviews": 0,
  "start": 382.2,
  "end": 394.5
 },
 {
  "input": "And symmetrically, if you look at the parallelogram spanned by our mystery input vector and the second basis, j-hat, its area is going to be the x-coordinate of that mystery vector.",
  "translatedText": "Und wenn du dir das Parallelogramm ansiehst, das von unserem geheimnisvollen Eingangsvektor und der zweiten Basis, j-hat, aufgespannt wird, ist die Fläche die x-Koordinate des geheimnisvollen Vektors.",
  "model": "DeepL",
  "from_community_srt": "wenn Sie Schauen Sie sich das vom Vektor überspannte Parallelogramm an und der zweite Basisvektor, j-hat, seine Fläche wird die x-Koordinate des Vektors sein.",
  "n_reviews": 0,
  "start": 395.16,
  "end": 405.2
 },
 {
  "input": "Again, it's a strange way to represent the x-coordinate, but see what it buys us in a moment.",
  "translatedText": "Auch das ist eine seltsame Art, die x-Koordinate darzustellen, aber wir werden gleich sehen, was wir davon haben.",
  "model": "DeepL",
  "from_community_srt": "Wieder ist es eine seltsame Art, das darzustellen x-Koordinate, aber Sie werden sehen, was es kauft uns in einem Moment.",
  "n_reviews": 0,
  "start": 405.78,
  "end": 410.08
 },
 {
  "input": "And just to make sure it's clear how this might generalize, let's look in three dimensions.",
  "translatedText": "Und um sicherzustellen, dass es klar ist, wie das verallgemeinert werden kann, lass uns in drei Dimensionen schauen.",
  "model": "DeepL",
  "from_community_srt": "So würde dies in drei Dimensionen aussehen: Normalerweise so,",
  "n_reviews": 0,
  "start": 410.68,
  "end": 413.76
 },
 {
  "input": "Ordinarily, the way you might think about one of a vector's coordinates, say its z-coordinate, would be to take its dot product with the third standard basis vector, often called k-hat.",
  "translatedText": "Normalerweise würdest du die Koordinaten eines Vektors, z. B. seine z-Koordinate, als Punktprodukt mit dem dritten Standard-Basisvektor betrachten, der oft k-hat genannt wird.",
  "model": "DeepL",
  "from_community_srt": "wie Sie es sich vorstellen könnten der Koordinate eines Vektors, sagen wir seine Z-Koordinate, wäre, sein Punktprodukt mit dem zu nehmen dritter Standardbasisvektor,",
  "n_reviews": 0,
  "start": 414.3,
  "end": 423.56
 },
 {
  "input": "But an alternate geometric interpretation would be to consider the parallelepiped that it creates with the other two basis vectors, i-hat and j-hat.",
  "translatedText": "Eine andere geometrische Interpretation wäre, das Parallelepiped zu betrachten, das mit den beiden anderen Basisvektoren, i-hat und j-hat, entsteht.",
  "model": "DeepL",
  "from_community_srt": "k-hat. Betrachten Sie stattdessen das Parallelepiped erzeugt mit den anderen beiden Basisvektoren, i-hat und j-hat.",
  "n_reviews": 0,
  "start": 424.28,
  "end": 432.88
 },
 {
  "input": "If you think of the square with area 1 spanned by i-hat and j-hat as the base of this whole shape, then its volume is the same as its height, which is the third coordinate of our vector.",
  "translatedText": "Wenn du dir das Quadrat mit der Fläche 1, die von i-hat und j-hat aufgespannt wird, als Basis dieser ganzen Form vorstellst, dann ist sein Volumen dasselbe wie seine Höhe, die die dritte Koordinate unseres Vektors ist.",
  "model": "DeepL",
  "from_community_srt": "Wenn Sie an das Quadrat denken, dessen Fläche 1 überspannt ist von i-hat und j-hat als Basis dieses Kerls, sein Volumen ist das gleiche wie seine Höhe, die ist die dritte Koordinate unseres Vektors.",
  "n_reviews": 0,
  "start": 433.42,
  "end": 443.58
 },
 {
  "input": "And likewise, the wacky way to think about the other coordinates of the vector would be to form a parallelepiped using the vector and then all of the basis vectors other than the one corresponding to the direction you're looking for.",
  "translatedText": "Die verrückte Art, über die anderen Koordinaten des Vektors nachzudenken, wäre, ein Parallelepiped aus dem Vektor und allen anderen Basisvektoren zu bilden, außer dem, der der gesuchten Richtung entspricht.",
  "model": "DeepL",
  "from_community_srt": "Ebenso die verrückte Art, über irgendetwas nachzudenken andere Koordinate dieses Vektors ist zu bilden das Parallelepiped zwischen diesem Vektor an Alle Basisvektoren außer dem,",
  "n_reviews": 0,
  "start": 444.34,
  "end": 455.44
 },
 {
  "input": "Then the volume of this gives you the coordinate.",
  "translatedText": "Das Volumen davon gibt dir dann die Koordinate.",
  "model": "DeepL",
  "from_community_srt": "den Sie sind suchen und bekommen seine Lautstärke.",
  "n_reviews": 0,
  "start": 455.9,
  "end": 457.9
 },
 {
  "input": "Or rather, we should be talking about the signed volume of parallelepiped in the sense described in the determinant video using the right-hand rule.",
  "translatedText": "Oder besser gesagt, wir sollten über das vorzeichenbehaftete Volumen eines Parallelepipeds in dem Sinne sprechen, wie es im Determinantenvideo mit der Rechtsregel beschrieben wird.",
  "model": "DeepL",
  "from_community_srt": "Oder besser gesagt, wir sollten über das Unterzeichnete sprechen Volumen dieser Parallelepipeds im Sinne im Determinantenvideo beschrieben,",
  "n_reviews": 0,
  "start": 458.44,
  "end": 465.0
 },
 {
  "input": "So the order in which you list these three vectors matters.",
  "translatedText": "Es kommt also auf die Reihenfolge an, in der du diese drei Vektoren auflistest.",
  "model": "DeepL",
  "from_community_srt": "wo die Reihenfolge, in der Sie die drei Vektoren auflisten zählt und du benutzt die rechte Hand Regel.",
  "n_reviews": 0,
  "start": 465.56,
  "end": 468.14
 },
 {
  "input": "That way, negative coordinates still make sense.",
  "translatedText": "Auf diese Weise sind negative Koordinaten immer noch sinnvoll.",
  "model": "DeepL",
  "from_community_srt": "Auf diese Weise sind negative Koordinaten immer noch sinnvoll.",
  "n_reviews": 0,
  "start": 468.8,
  "end": 471.1
 },
 {
  "input": "Okay, so why think of coordinates as areas and volumes like this?",
  "translatedText": "Okay, warum sollte man sich Koordinaten als Flächen und Volumen vorstellen?",
  "model": "DeepL",
  "from_community_srt": "Okay, warum sollten Sie sich Koordinaten als Bereiche vorstellen?",
  "n_reviews": 0,
  "start": 472.04,
  "end": 475.24
 },
 {
  "input": "Well, as you apply some sort of matrix transformation, the areas of these parallelograms, well, they don't stay the same, they might get scaled up or down.",
  "translatedText": "Wenn du eine Art Matrixtransformation anwendest, bleiben die Flächen dieser Parallelogramme nicht gleich, sondern sie werden vielleicht vergrößert oder verkleinert.",
  "model": "DeepL",
  "from_community_srt": "und Bände wie dieses? Wenn Sie eine Matrixtransformation anwenden, wird die Bereiche der Parallelogramme bleiben nicht die Ebenso können sie vergrößert oder verkleinert werden.",
  "n_reviews": 0,
  "start": 475.72,
  "end": 483.78
 },
 {
  "input": "But, and this is the key idea of determinants, all of the areas get scaled by the same amount, namely the determinant of our transformation matrix.",
  "translatedText": "Aber, und das ist der Kerngedanke der Determinanten, alle Flächen werden um den gleichen Betrag skaliert, nämlich um die Determinante unserer Transformationsmatrix.",
  "model": "DeepL",
  "from_community_srt": "Aber (!), Und dies ist eine Schlüsselidee von Determinanten, Alle diese Bereiche werden um den gleichen Betrag skaliert. Die Determinante unserer Transformation Matrix.",
  "n_reviews": 0,
  "start": 484.16,
  "end": 492.64
 },
 {
  "input": "For example, if you look at the parallelogram spanned by the vector where your first basis vector lands, which is the first column of the matrix, and the transformed version of xy, what is its area?",
  "translatedText": "Wenn du dir zum Beispiel das Parallelogramm ansiehst, das von dem Vektor aufgespannt wird, auf dem dein erster Basisvektor landet, der die erste Spalte der Matrix ist, und von der transformierten Version von xy, wie groß ist seine Fläche?",
  "model": "DeepL",
  "from_community_srt": "Zum Beispiel, wenn Sie das Parallelogramm betrachten überspannt von dem Vektor, wo Ihre erste Basis Vektor landet, das ist die erste Spalte von die Matrix und die transformierte Version von [x; y], was ist seine Fläche? Nun,",
  "n_reviews": 0,
  "start": 493.52,
  "end": 504.58
 },
 {
  "input": "Well, this is the transformed version of the parallelogram we were looking at earlier, the one whose area was the y-coordinate of the mystery input vector.",
  "translatedText": "Das ist die transformierte Version des Parallelogramms, das wir uns vorhin angeschaut haben und dessen Fläche die y-Koordinate des geheimnisvollen Eingangsvektors war.",
  "model": "DeepL",
  "from_community_srt": "das ist die transformierte Version davon Parallelogramm, das wir uns früher angesehen haben, dessen Bereich war die y-Koordinate des Mysteriums Eingabevektor.",
  "n_reviews": 0,
  "start": 505.58,
  "end": 513.38
 },
 {
  "input": "So its area is just going to be the determinant of the transformation multiplied by that y-coordinate.",
  "translatedText": "Die Fläche ist also einfach die Determinante der Transformation multipliziert mit der y-Koordinate.",
  "model": "DeepL",
  "from_community_srt": "Sein Gebiet wird also die Determinante des sein Transformation multipliziert mit diesem Wert.",
  "n_reviews": 0,
  "start": 513.7,
  "end": 519.28
 },
 {
  "input": "So that means we can solve for y by taking the area of this new parallelogram in the output space divided by the determinant of the full transformation.",
  "translatedText": "Das bedeutet also, dass wir y lösen können, indem wir die Fläche dieses neuen Parallelogramms im Ausgangsraum durch die Determinante der vollständigen Transformation teilen.",
  "model": "DeepL",
  "from_community_srt": "Also die y-Koordinate unserer Mystery-Eingabe Vektor ist die Fläche dieses Parallelogramms, überspannt von der ersten Spalte der Matrix und der Ausgabevektor, geteilt durch die Determinante der vollständigen Transformation.",
  "n_reviews": 0,
  "start": 520.18,
  "end": 529.88
 },
 {
  "input": "And how do you get that area?",
  "translatedText": "Und wie kommst du in diesen Bereich?",
  "model": "DeepL",
  "from_community_srt": "Und wie bekommt man diesen Bereich? Nun,",
  "n_reviews": 0,
  "start": 530.9,
  "end": 532.42
 },
 {
  "input": "Well, we know the coordinates for where the mystery input vector lands, that's the whole point of a linear system of equations.",
  "translatedText": "Nun, wir kennen die Koordinaten, auf denen der mysteriöse Eingangsvektor landet, das ist der Sinn eines linearen Gleichungssystems.",
  "model": "DeepL",
  "from_community_srt": "wir kennen die Koordinaten für wo die Mystery Input Vector landet, das ist das Ganze Punkt eines linearen Gleichungssystems.",
  "n_reviews": 0,
  "start": 533.24,
  "end": 539.16
 },
 {
  "input": "So what you might do is create a new matrix whose first column is the same as that of our matrix, but whose second column is the output vector, and then you take its determinant.",
  "translatedText": "Du könntest also eine neue Matrix erstellen, deren erste Spalte die gleiche ist wie die unserer Matrix, deren zweite Spalte aber der Ausgangsvektor ist, und dann ihre Determinante nehmen.",
  "model": "DeepL",
  "from_community_srt": "Erstellen Sie also eine Matrix, deren erste Spalte lautet das gleiche wie das unserer Matrix, und wessen Die zweite Spalte ist der Ausgabevektor und take seine Determinante.",
  "n_reviews": 0,
  "start": 539.72,
  "end": 550.32
 },
 {
  "input": "So look at that, just using data from the output of the transformation, namely the columns of the matrix and the coordinates of our output vector, we can recover the y-coordinate of the mystery input vector, which is halfway to solving the system.",
  "translatedText": "Sieh dir das an: Mit den Daten aus der Ausgabe der Transformation, also den Spalten der Matrix und den Koordinaten unseres Ausgabevektors, können wir die y-Koordinate des mysteriösen Eingabevektors herausfinden, womit wir das System halbwegs gelöst haben.",
  "model": "DeepL",
  "from_community_srt": "Also sieh dir das an. nur mit Daten aus dem Ausgabe der Transformation, nämlich die Spalten der Matrix und die Koordinaten unserer Ausgabe Vektor können wir die y-Koordinate von wiederherstellen unser mysteriöser Eingabevektor.",
  "n_reviews": 0,
  "start": 551.26,
  "end": 564.4
 },
 {
  "input": "Likewise, the same idea can give us the x-coordinate.",
  "translatedText": "Auf die gleiche Art und Weise können wir auch die x-Koordinate ermitteln.",
  "model": "DeepL",
  "from_community_srt": "Ebenso können Sie mit derselben Idee die x-Koordinate erhalten.",
  "n_reviews": 0,
  "start": 565.12,
  "end": 567.54
 },
 {
  "input": "Look at the parallelogram we defined earlier, which encodes the x-coordinate of the mystery input vector spanned by that vector and j-hat.",
  "translatedText": "Sieh dir das Parallelogramm an, das wir vorhin definiert haben. Es kodiert die x-Koordinate des geheimnisvollen Eingangsvektors, der von diesem Vektor und j-hat aufgespannt wird.",
  "model": "DeepL",
  "from_community_srt": "Schauen Sie sich das Parallelogramm an, das wir früh definiert haben welches die x-Koordinate des Mysteriums codiert Eingabevektor, überspannt vom Eingabevektor und j-hat.",
  "n_reviews": 0,
  "start": 568.0,
  "end": 575.74
 },
 {
  "input": "The transformed version of this guy is spanned by the output vector and the second column of the matrix, and its area will have been multiplied by the determinant of that matrix.",
  "translatedText": "Die transformierte Version dieses Typs wird durch den Ausgangsvektor und die zweite Spalte der Matrix aufgespannt, und seine Fläche wird mit der Determinante dieser Matrix multipliziert.",
  "model": "DeepL",
  "from_community_srt": "Die transformierte Version dieses Typen ist überspannt durch den Ausgabevektor und die zweite Spalte der Matrix, und ihre Fläche wird gewesen sein multipliziert mit der Determinante der Matrix.",
  "n_reviews": 0,
  "start": 576.4,
  "end": 586.92
 },
 {
  "input": "So to solve for x, you can take this new area divided by the determinant of the full transformation.",
  "translatedText": "Um also x zu lösen, kannst du diese neue Fläche durch die Determinante der vollständigen Transformation teilen.",
  "model": "DeepL",
  "from_community_srt": "Also die x-Koordinate unseres geheimnisvollen Eingabevektors ist dieser Bereich geteilt durch die Determinante von",
  "n_reviews": 0,
  "start": 587.7,
  "end": 592.94
 },
 {
  "input": "And similar to what we did before, you can compute the area of that output parallelogram by creating a new matrix whose first column is the output vector and whose second column is the same as the original matrix.",
  "translatedText": "Und ähnlich wie zuvor kannst du die Fläche dieses Ausgabeparallelogramms berechnen, indem du eine neue Matrix erstellst, deren erste Spalte der Ausgabevektor und deren zweite Spalte die gleiche ist wie die ursprüngliche Matrix.",
  "model": "DeepL",
  "from_community_srt": "die Transformation. Symmetrisch zu dem, was wir zuvor gemacht haben, können Sie berechnen den Bereich dieses Ausgabe-Parallelogramms durch Erstellen eine neue Matrix, deren erste Spalte die Ausgabe ist Vektor, und dessen zweite Spalte ist die gleiche als ursprüngliche Matrix.",
  "n_reviews": 0,
  "start": 593.86,
  "end": 605.66
 },
 {
  "input": "So again, just using data from the output space, the numbers we see in our original linear system, we can solve for what x must be.",
  "translatedText": "Auch hier können wir mit den Daten aus dem Ausgangsraum, also den Zahlen in unserem ursprünglichen linearen System, herausfinden, wie groß x sein muss.",
  "model": "DeepL",
  "from_community_srt": "Also wieder nur Daten aus der Ausgabe verwenden Raum, die Zahlen, die wir in unserem Original sehen lineares System können wir die x-Koordinate wiederherstellen unseres Mystery Input Vektors.",
  "n_reviews": 0,
  "start": 606.24,
  "end": 612.86
 },
 {
  "input": "This formula for finding the solutions to a linear system of equations is known as Cramer's rule.",
  "translatedText": "Diese Formel zum Finden der Lösungen eines linearen Gleichungssystems ist als Cramersche Regel bekannt.",
  "model": "DeepL",
  "from_community_srt": "Diese Formel zum Finden der Lösungen für Ein lineares Gleichungssystem ist als Cramer bekannt",
  "n_reviews": 0,
  "start": 613.42,
  "end": 618.42
 },
 {
  "input": "Here, just to sanity check ourselves, plug in some numbers here.",
  "translatedText": "Um uns zu vergewissern, können wir hier ein paar Zahlen eingeben.",
  "model": "DeepL",
  "from_community_srt": "Regel. Hier, nur um die Vernunft zu überprüfen, stecken Sie in den Zahlen hier.",
  "n_reviews": 0,
  "start": 619.12,
  "end": 621.9
 },
 {
  "input": "The determinant of that top altered matrix is 4 plus 2, which is 6, and the bottom determinant is 2, so the x-coordinate should be 3.",
  "translatedText": "Die Determinante dieser oberen veränderten Matrix ist 4 plus 2, also 6, und die untere Determinante ist 2, also sollte die x-Koordinate 3 sein.",
  "model": "DeepL",
  "from_community_srt": "Die Determinante dieser oben veränderten Matrix ist 4 + 2, was 6 ist, und die untere Determinante ist 2, also sollte die x-Koordinate 3 sein.",
  "n_reviews": 0,
  "start": 622.26,
  "end": 630.82
 },
 {
  "input": "And indeed, looking back at the input vector we started with, the x-coordinate is 3.",
  "translatedText": "Und tatsächlich, wenn wir uns den Eingangsvektor ansehen, mit dem wir angefangen haben, ist die x-Koordinate 3.",
  "model": "DeepL",
  "from_community_srt": "Und tatsächlich, wenn ich auf diesen Eingabevektor zurückblicke Wir haben damit begonnen, dass die x-Koordinate 3 ist.",
  "n_reviews": 0,
  "start": 631.44,
  "end": 635.46
 },
 {
  "input": "Likewise, Cramer's rule suggests that the y-coordinate should be 4 divided by 2, or 2, and that is in fact the y-coordinate of the input vector we were starting with.",
  "translatedText": "Die Cramersche Regel besagt, dass die y-Koordinate 4 geteilt durch 2 oder 2 sein sollte, und das ist in der Tat die y-Koordinate des Eingangsvektors, mit dem wir angefangen haben.",
  "model": "DeepL",
  "from_community_srt": "Ebenso schlägt Cramers Regel die y-Koordinate vor sollte 4/2 oder 2 sein, und das ist in der Tat die y-Koordinate des Eingabevektors,",
  "n_reviews": 0,
  "start": 636.32,
  "end": 646.5
 },
 {
  "input": "The case with three dimensions or more is similar, and I highly recommend you take a moment to pause and think through it yourself.",
  "translatedText": "Der Fall mit drei oder mehr Dimensionen ist ähnlich, und ich empfehle dir, einen Moment innezuhalten und selbst darüber nachzudenken.",
  "model": "DeepL",
  "from_community_srt": "den wir gestartet haben mit hier. Der Fall mit drei Dimensionen ist ähnlich, und ich empfehle Ihnen dringend, eine Pause zum Nachdenken einzulegen es durch dich.",
  "n_reviews": 0,
  "start": 647.38,
  "end": 653.48
 },
 {
  "input": "Here, I'll give you a little bit of momentum.",
  "translatedText": "Hier, ich gebe dir ein bisschen Schwung.",
  "model": "DeepL",
  "from_community_srt": "Hier gebe ich Ihnen einen kleinen Impuls.",
  "n_reviews": 0,
  "start": 654.18,
  "end": 655.9
 },
 {
  "input": "What we have is a known transformation given by some 3x3 matrix and a known output vector given by the right side of our linear system, and we want to know what input lands on that output.",
  "translatedText": "Wir haben eine bekannte Transformation, die durch eine 3x3-Matrix gegeben ist, und einen bekannten Ausgangsvektor, der durch die rechte Seite unseres linearen Systems gegeben ist, und wir wollen wissen, welche Eingabe auf diese Ausgabe trifft.",
  "model": "DeepL",
  "from_community_srt": "Wir haben diese bekannte Transformation gegeben durch eine 3x3-Matrix und ein bekannter Ausgabevektor sind gegeben auf der rechten Seite unseres linearen Systems, und wir wollen wissen, auf welchem ​​Eingabevektor landet dieser Ausgabevektor.",
  "n_reviews": 0,
  "start": 656.34,
  "end": 668.24
 },
 {
  "input": "And if you think of, say, the z-coordinate of that input vector as the volume of that special parallelepiped we were looking at earlier, spanned by i-hat, j-hat, and the mystery input vector, what happens to that volume after the transformation?",
  "translatedText": "Und wenn du dir die z-Koordinate dieses Eingangsvektors als das Volumen des speziellen Parallelepipeds vorstellst, das wir vorhin betrachtet haben und das von i-hat, j-hat und dem mysteriösen Eingangsvektor aufgespannt wird, was passiert dann mit diesem Volumen nach der Transformation?",
  "model": "DeepL",
  "from_community_srt": "Wenn Sie beispielsweise an die Z-Koordinate von denken der Eingabevektor als Volumen dieses Parallelepipeds überspannt von i-hat, j-hat und dem mysteriösen Input Vektor,",
  "n_reviews": 0,
  "start": 669.1,
  "end": 683.78
 },
 {
  "input": "And what are the various ways you can compute that volume?",
  "translatedText": "Und welche verschiedenen Möglichkeiten gibt es, dieses Volumen zu berechnen?",
  "model": "DeepL",
  "from_community_srt": "was passiert mit dem Volumen davon Parallelepiped nach der Transformation? Wie können Sie dieses neue Volume berechnen?",
  "n_reviews": 0,
  "start": 684.8,
  "end": 687.48
 },
 {
  "input": "Really, pause and think through the details of generalizing this to higher dimensions, finding an expression for each coordinate of the solution to a larger linear system.",
  "translatedText": "Halte wirklich inne und denke über die Details der Verallgemeinerung auf höhere Dimensionen nach, indem du einen Ausdruck für jede Koordinate der Lösung eines größeren linearen Systems findest.",
  "model": "DeepL",
  "from_community_srt": "Machen Sie wirklich eine Pause und nehmen Sie sich einen Moment Zeit zum Nachdenken die Details der Verallgemeinerung auf höher Maße; für jeden einen Ausdruck finden Koordinate der Lösung zu größeren linearen Systeme.",
  "n_reviews": 0,
  "start": 688.34,
  "end": 697.42
 },
 {
  "input": "Thinking through more general cases like this and convincing yourself that it works and why it works is where all the learning really happens, much more so than listening to some dude on YouTube walk you through the same reasoning again.",
  "translatedText": "Indem du über allgemeinere Fälle wie diesen nachdenkst und dich selbst davon überzeugst, dass es funktioniert und warum es funktioniert, lernst du wirklich viel mehr, als wenn du dir von irgendeinem Typen auf YouTube anhören musst, wie er die gleiche Argumentation noch einmal durchgeht.",
  "model": "DeepL",
  "from_community_srt": "Allgemeinere Fälle durchdenken und überzeugen selbst, dass es funktioniert, ist, wo all das Lernen wird passieren,",
  "n_reviews": 0,
  "start": 698.06,
  "end": 708.5
 }
]