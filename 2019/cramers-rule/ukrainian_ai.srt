1
00:00:11,590 --> 00:00:15,800
У попередньому відео я
systems of equations, and I sort of brushed

2
говорив про лінійне 00:00:15,800
aside the discussion of actually computing
solutions to these systems.

--&gt; 00:00:19,690 3
00:00:19,690 --> 00:00:23,500
And while it’s true that number-crunching
is something we typically leave to the computers,
є хорошим лакмусовим папірцем
4
00:00:23,500 --> 00:00:27,430
digging into some of these computational methods
для того, чи

5
00:00:27,430 --> 00:00:31,680
дійсно ви розумієте, що
this is really where the rubber meets the

6
відбувається, оскільки 00:00:31,680
road.

7
--&gt; 00:00:32,680 00:00:32,680 --&gt;
Here I want to describe the geometry behind
a certain method for computing solutions to

00:00:36,379 8 9
00:00:36,379 --> 00:00:39,760
these systems, known as Cramer’s rule.

обов’язково подивіться відповідні відео
00:00:39,760 --> 00:00:44,230
The relevant background needed here is an
understanding of determinants, dot products,
на ці теми,
10
00:00:44,230 --> 00:00:48,140
and of linear systems of equations, so be
якщо ви не знайомі

11
00:00:48,140 --> 00:00:50,489
або не знаєте.

12
00:00:50,489 --> 00:00:51,489
Але спочатку!

13
00:00:51,489 --> 00:00:56,379
Попередньо я повинен
is not the best way for computing solutions

14
сказати, що правило
to linear systems of equations.

15
Крамера 00:00:56,379 --&gt;
Gaussian elimination, for example, will always
be faster.

00:00:58,010 00:00:58,010
00:01:01,950 --> 00:01:03,950
So why learn it?

--&gt; 00:01:01,950 16
00:01:03,950 --> 00:01:07,950
Think of this as a sort of cultural excursion;
it’s a helpful exercise in deepening your
17 допомагає консолідувати
18
00:01:07,950 --> 00:01:10,520
knowledge of the theory of these systems.
ідеї лінійної
19
00:01:10,520 --> 00:01:15,500
Wrapping your mind around this concept will
алгебри, такі як

20
00:01:15,500 --> 00:01:19,960
детермінанти та лінійні
seeing how they relate to each other.

21
системи, by
Also, from a purely artistic standpoint, the
ultimate result is just really pretty to think

00:01:19,960 --&gt; 00:01:24,619
00:01:24,619 --> 00:01:28,340
about, much more so that Gaussian elimination.

22 23 працюватимуть
00:01:28,340 --> 00:01:33,740
Alright, so the setup here will be some linear
system of equations, say with two unknowns,
системи з
24
00:01:33,740 --> 00:01:35,990
x and y, and two equations.
більшою кількістю невідомих
25
00:01:35,990 --> 00:01:40,450
In principle, everything we’re talking about
і такою ж

26
00:01:40,450 --> 00:01:41,840
кількістю рівнянь.

27
00:01:41,840 --> 00:01:46,349
Але для простоти
to hold in our heads.

28
менший приклад
So as I talked about in a previous video,
you can think of this setup geometrically

кращий 00:01:46,349
00:01:50,599 --> 00:01:56,599
as a certain known matrix transforming an
unknown vector, [x; y], where you know what
--&gt; 00:01:50,599
30
00:01:56,599 --> 00:02:00,420
the output is going to be, in this case [-4;
29 -2].

31
00:02:00,420 --> 00:02:06,250
Пам’ятайте, що стовпці цієї
you how the matrix acts as a transform, each

32
матриці повідомляють 00:02:06,250
one telling you where the basis vectors of
the input space land.

--&gt; 00:02:10,899 33
00:02:10,899 --> 00:02:23,060
So this is a sort of puzzle, what input [x;
y], is going to give you this
тип відповіді, яку ви
34
00:02:23,060 --> 00:02:28,150
output [-4; -2]?
тут отримаєте, може
35
00:02:28,150 --> 00:02:39,680
Remember, the 
залежати від того,

36
00:02:39,680 --> 00:02:44,299
чи перетворення хлюпає
all of space into a lower dimension.

37
чи ні 00:02:44,299 --&gt;
That is if it has zero determinant.

38
00:02:46,080 00:02:46,080 --&gt;
In that case, either none of the inputs land
on our given output or there are a whole bunch

00:02:51,849 39 40
00:02:51,849 --> 00:02:57,540
of inputs landing on that output.

повний n-вимірний простір, у
00:02:57,540 --> 00:03:01,709
But for this video we’ll limit our view
to the case of a non-zero determinant, meaning
якому він почався;
41
00:03:01,709 --> 00:03:07,790
the output of this transformation still spans
кожен вхід потрапляє

42
00:03:07,790 --> 00:03:12,549
на один і
and every output has one and only one input.

43
тільки один вихід 00:03:12,549
One way to think about our puzzle is that
we know the given output vector is some linear

--&gt; 00:03:14,840 44
00:03:14,840 --> 00:03:15,840
combination of the columns of the matrix;
x*(the vector where i-hat lands) + y*(the
обчислити, що таке
45
00:03:15,840 --> 00:03:16,840
vector where j-hat lands), but we wish to
x і y.

46
00:03:16,840 --> 00:03:18,829
Для початку дозвольте
is wrong, but in the right direction.

47
мені показати ідею,
The x-coordinate of this mystery input vector
is what you get by taking its dot product

що 00:03:18,829
00:03:23,340 --> 00:03:25,939
with the first basis vector, [1; 0].

--&gt; 00:03:23,340 48
00:03:25,939 --> 00:03:30,830
Likewise, the y-coordinate is what you get
by dotting it with the second basis vector,
49 скалярний
50
00:03:30,830 --> 00:03:31,980
[0; 1].
добуток із трансформованою
51
00:03:31,980 --> 00:03:37,439
So maybe you hope that after the transformation,
версією таємничого

52
00:03:37,439 --> 00:03:41,939
вектора з трансформованим
versions of the basis vectors will also be

53
00:03:41,939 --&gt; 00:
these coordinates x and y.

54
03:43,590 00:03:43,590
That’d be fantastic because we know the
transformed versions of each of these vectors.

--&gt; 00:03:50,400 55
00:03:50,400 --> 00:03:54,739
There’s just one problem with this: it’s
not at all true!
до і
56
00:03:54,739 --> 00:03:59,450
For most linear transformations, the dot product
після трансформації будуть

57
00:03:59,450 --> 00:04:00,840
дуже різними.

58
00:04:00,840 --> 00:04:04,959
Наприклад, у вас може
pointing in the same direction, with a positive

59
бути два вектори,
dot product, which get pulled away from each
other during the transformation, in such a

які зазвичай 00:04:04,959
00:04:09,270 --> 00:04:11,909
way that they then have a negative dot product.

--&gt; 00:04:09,270 60
00:04:11,909 --> 00:04:16,840
Likewise, if things start off perpendicular,
with dot product zero, like the two basis
61 залишатимуться перпендикулярними
62
00:04:16,840 --> 00:04:22,040
vectors, there’s no guarantee that they
після перетворення, зберігаючи

63
00:04:22,040 --> 00:04:24,050
нульовий скалярний добуток.

64
00:04:24,050 --> 00:04:27,140
У прикладі, який
certainly aren’t preserved.

65
ми розглядали, скалярний
They tend to get bigger since most vectors
are getting stretched.

добуток 00:04:27,140 --&gt;
00:04:30,950 --> 00:04:36,730
In fact, transformations which do preserve
dot products are special enough to have their
00:04:30,950 66
67
00:04:36,730 --> 00:04:39,800
own name: Orthonormal transformations.
векторів, перпендикулярних один
68
00:04:39,800 --> 00:04:44,259
These are the ones which leave all the basis
до одного з

69
00:04:44,259 --> 00:04:45,810
одиничною довжиною.

70
00:04:45,810 --> 00:04:48,470
Ви часто думаєте про це як про матриці обертання.

71
00:04:48,470 --> 00:04:53,000
Відповідає жорсткому руху, без
squishing or morphing.

72
розтягування, 00:04:53,000 --&gt;
Solving a linear system with an orthonormal
matrix is very easy: Since dot products are

00:04:58,920 73 добутку
00:04:58,920 --> 00:05:03,060
preserved, taking the dot product between
the output vector and all the columns of your
між вхідним вектором
74
00:05:03,060 --> 00:05:08,380
matrix will be the same as taking the dot
і всіма базисними векторами,

75
00:05:08,380 --> 00:05:13,599
що те саме,
the coordinates of the input vector.

76
що знайти 00:05:13,599
So, in that very special case, x would be
the dot product of the first column with the

--&gt; 00 :05:18,690
00:05:18,690 --> 00:05:24,580
output vector, and y would be the dot product
of the second column with the output vector.
77 найбільш лінійних систем,
78
00:05:24,580 --> 00:05:32,880
Now, even though this idea breaks down for
це вказує нам

79
00:05:32,880 --> 00:05:37,780
у напрямку чогось
geometric understanding for the coordinates

80
шукати: чи є
of our input vector which remains unchanged
after the transformation?

альтернативний 00:05:37,780 --&gt; 00:05:42,780
00:05:42,780 --> 00:05:47,631
If your mind has been mulling over determinants,
you might think of this clever idea: Take
81 вектор, i-hat
82
00:05:47,631 --> 00:05:53,200
the parallelogram defined by the first basis
і таємничий вхідний

83
00:05:53,200 --> 00:05:54,590
вектор [x; y].

84
00:05:54,590 --> 00:05:59,990
Площа цього паралелограма є
1, times the height perpendicular to that

85
його основою, 00:05:59,990 --&gt;
base, which is the y-coordinate of our input
vector.

00:06:03,460 86, якщо
00:06:03,460 --> 00:06:09,120
So, the area of this parallelogram is sort
of a screwy roundabout way to describe the
говорити про координати, але
87
00:06:09,120 --> 00:06:13,590
vector’s y-coordinate; it’s a wacky way
біжимо зі мною.

88
00:06:13,590 --> 00:06:19,690
Насправді, щоб бути більш
think of the signed area of this parallelogram,

89
точним, ви повинні
in the sense described by the determinant
video.

00:06:19,690 --&gt; 00:06:22,440
00:06:22,440 --> 00:06:28,110
That way, a vector with negative y-coordinate
would correspond to a negative area for this
90 подивитися на
91
00:06:28,110 --> 00:06:29,110
parallelogram.
паралелограм, натягнутий на вектор
92
00:06:29,110 --> 00:06:39,490
Symmetrically, if you 
і другий базисний

93
00:06:39,490 --> 00:06:45,099
вектор, j-hat, його
will be the x-coordinate of the vector.

94
площу 00:06:45,099 --
Again, it’s a strange way to represent the
x-coordinate, but you’ll see what it buys

&gt; 00:06:49,370 95 96
00:06:49,370 --> 00:06:50,449
us in a moment.

означало б взяти
00:06:50,449 --> 00:06:56,101
Here’s what this would look like in three-dimensions:
Ordinarily the way you might think of one
його скалярний добуток
97
00:06:56,101 --> 00:07:01,060
of a vector’s coordinate, say its z-coordinate,
із третім стандартним

98
00:07:01,060 --> 00:07:04,439
базисним вектором, k-hat.

99
00:07:04,439 --> 00:07:11,870
Але замість цього
creates with the other two basis vectors,

100
розглянемо паралелепіпед, 00:07:11,870
i-hat and j-hat.

101
--&gt; 00:07:13,569
If you think of the square with area 1 spanned
by i-hat and j-hat as the base of this guy,

00:07:13,569 --&gt; 00:07:20,030
00:07:20,030 --> 00:07:24,259
its volume is the same its height, which is
the third coordinate of our vector.
102 інша
103
00:07:24,259 --> 00:07:28,370
Likewise, the wacky way to think about any
координата цього вектора

104
00:07:28,370 --> 00:07:34,950
утворює паралелепіпед між
all the basis vectors other than the one you’re

105
цим вектором
looking for, and get its volume.

106
і 00: 07:34,950
Or, rather, we should talk about the signed
volume of these parallelepipeds, in the sense

--&gt; 00:07:37,900
00:07:42,490 --> 00:07:47,819
described in the determinant video, where
the order in which you list the three vectors
00:07:37,900 --&gt; 00:07:42,490
108
00:07:47,819 --> 00:07:48,900
matters and you’re using the right-hand
107 правило.

109
00:07:48,900 --> 00:07:51,610
Таким чином негативні координати все ще мають сенс.

110
00:07:51,610 --> 00:07:56,000
Гаразд, навіщо думати
and volumes like this?

111
про координати
As you apply some matrix transformation, the
areas of the parallelograms don’t stay the

як про
00:08:02,039 --> 00:08:04,129
same, they may get scaled up or down.

площі 00:07:56,000 --&gt;
00:08:04,129 --> 00:08:09,940
But(!), and this is a key idea of determinants,
all these areas get scaled by the same amount.
00:08:02,039 112
114
00:08:09,940 --> 00:08:13,560
Namely, the determinant of our transformation
113 матриці.

115
00:08:13,560 --> 00:08:17,850
Наприклад, якщо ви
spanned by the vector where your first basis

116
подивіться на
vector lands, which is the first column of
the matrix, and the transformed version of

паралелограм 00:08:17,850
00:08:22,850 --> 00:08:25,180
[x; y], what is its area?

--&gt; 00:08:22,850
00:08:25,180 --> 00:08:30,229
Well, this is the transformed version of that
parallelogram we were looking at earlier,
117 118
119
00:08:30,229 --> 00:08:33,950
whose area was the y-coordinate of the mystery
вхідний вектор.

120
00:08:33,950 --> 00:08:39,080
Тож його площа
transformation multiplied by that value.

121
буде визначником
So, the y-coordinate of our mystery input
vector is the area of this parallelogram,

00:08:39,080 --&gt; 00:08:44,590
00:08:44,590 --> 00:08:48,510
spanned by the first column of the matrix
and the output vector, divided by the determinant
122 таємничих
123
00:08:48,510 --> 00:08:51,120
of the full transformation.
вхідних векторів, у
124
00:08:51,120 --> 00:08:53,090
And how do you get this area?
цьому й
125
00:08:53,090 --> 00:08:57,360
Well, we know the coordinates for where the
полягає суть лінійної

126
00:08:57,360 --> 00:08:59,850
системи рівнянь.

127
00:08:59,850 --> 00:09:05,670
Отже, створивши матрицю, перший
the same as that of our matrix, and whose

128
стовпець якої 00:09:05,670
second column is the output vector, and take
its determinant.

--&gt; 00:09:11,250 129
00:09:11,250 --> 00:09:16,560
So look at that; just using data from the
output of the transformation, namely the columns
вектор, ми можемо
130
00:09:16,560 --> 00:09:21,340
of the matrix and the coordinates of our output
відновити y-координату нашого

131
00:09:21,340 --> 00:09:23,880
таємничого вхідного вектора.

132
00:09:23,880 --> 00:09:28,100
Так само ця сама ідея може отримати координату x.

133
00:09:28,100 --> 00:09:32,580
Подивіться на той паралелограм,
which encodes the x-coordinate of the mystery

134
який ми визначили
input vector, spanned by the input vector
and j-hat.

раніше 00:09:32,580 --&gt;
00:09:36,420 --> 00:09:41,970
The transformed version of this guy is spanned
by the output vector and the second column
00:09:36,420 135 помножений
136
00:09:41,970 --> 00:09:47,710
of the matrix, and its area will have been
на визначник матриці.

137
00:09:47,710 --> 00:09:52,000
Отже, координата x нашого
is this area divided by the determinant of

138
таємничого вхідного вектора 00:09:52,000
the transformation.

139
--&gt; 00:09:53,980 00:09:53,980
Symmetric to what we did before, you can compute
the area of that output parallelogram by creating

--&gt; 00:09:58,900 140 простору,
00:09:58,900 --> 00:10:04,530
a new matrix whose first column is the output
vector, and whose second column is the same
чисел, які ми
141
00:10:04,530 --> 00:10:06,300
as the original matrix.
бачимо в нашій оригінальній
142
00:10:06,300 --> 00:10:10,120
So again, just using data from the output
лінійній системі, ми

143
00:10:10,120 --> 00:10:13,600
можна відновити координату x
of our mystery input vector.

144
00:10:13,600 --&gt; 00:10:18,440 145
This formula for finding the solutions to
a linear system of equations is known as Cramer’s

146 це 4+2,
00:10:18,440 --> 00:10:19,440
rule.

що дорівнює 6, а
00:10:19,440 --> 00:10:22,400
Here, just to sanity check ourselves, plug
in the numbers here.
нижній визначник дорівнює
147
00:10:22,400 --> 00:10:28,430
The determinant of that top altered matrix
2, тому координата x

148
00:10:28,430 --> 00:10:31,430
має бути 3.

149
00:10:31,430 --> 00:10:35,910
І справді, озираючись на
we started with, it’s x-coordinate is 3.

150
цей вхідний вектор
Likewise, Cramer’s rule suggests the y-coordinate
should be 4/2, or 2, and that is indeed the

00:10:35,910 --&gt; 00:10:43,850 151,
00:10:43,850 --> 00:10:47,540
y-coordinate of the input vector we started
with here.
і я настійно
152
00:10:47,540 --> 00:10:52,690
The case with three dimensions is similar,
рекомендую вам зупинитися, щоб

153
00:10:52,690 --> 00:10:53,690
подумати над цим.

154
00:10:53,690 --> 00:10:56,770
Ось, я дам вам трохи імпульсу.

155
00:10:56,770 --> 00:11:02,780
У нас є
a 3x3 matrix, and a known output vector, given

156
це відоме перетворення,
by the right side of our linear system, and
we want to know what input vector lands on

задане 00:11:02,780 --&gt;
00:11:07,580 --> 00:11:09,200
this output vector.

00:11:07,580 157 158
00:11:09,200 --> 00:11:16,700
If you think of, say, the z-coordinate of
the input vector as the volume of this parallelepiped
вектором, що станеться
159
00:11:16,700 --> 00:11:25,530
spanned by i-hat, j-hat, and the mystery input
з об&#39;ємом цього

160
00:11:25,530 --> 00:11:26,530
паралелепіпеда після перетворення?

161
00:11:26,530 --> 00:11:28,190
Як ви можете обчислити цей новий обсяг?

162
00:11:28,190 --> 00:11:32,200
Дійсно, зробіть паузу
the details of generalizing this to higher

163
та обдумайте 00:11:32,200
dimensions; finding an expression for each
coordinate of the solution to larger linear

--&gt; 00:11:37,330
00:11:37,330 --> 00:11:38,330
systems.

164 165 якийсь
00:11:38,330 --> 00:11:44,140
Thinking through more general cases and convincing
yourself that it works is where all the learning
чувак на
166
00:11:44,140 --> 00:11:48,520
will happen, much more so than listening to
YouTube ще раз

167
00:11:48,520 --> 00:12:09,940
пройде міркування.

