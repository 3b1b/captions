1
00:00:11,590 --> 00:00:15,800
בסרטון קודם, דיברתי על
systems of equations, and I sort of brushed

2
ליניארי 00:00:15,800 --&gt;
aside the discussion of actually computing
solutions to these systems.

00:00:19,690 3 הוא
00:00:19,690 --> 00:00:23,500
And while it’s true that number-crunching
is something we typically leave to the computers,
מבחן לקמוס טוב
4
00:00:23,500 --> 00:00:27,430
digging into some of these computational methods
אם אתה באמת

5
00:00:27,430 --> 00:00:31,680
מבין מה קורה
this is really where the rubber meets the

6
או לא, שכן 00:00:31,680
road.

7
--&gt; 00:00:32,680 00:00:32,680
Here I want to describe the geometry behind
a certain method for computing solutions to

--&gt; 00:00:36,379 8
00:00:36,379 --> 00:00:39,760
these systems, known as Cramer’s rule.

9 הקפד לצפות
00:00:39,760 --> 00:00:44,230
The relevant background needed here is an
understanding of determinants, dot products,
בסרטונים הרלוונטיים בנושאים
10
00:00:44,230 --> 00:00:48,140
and of linear systems of equations, so be
אלה אם אינך

11
00:00:48,140 --> 00:00:50,489
מכיר או חלוד.

12
00:00:50,489 --> 00:00:51,489
אבל קודם!

13
00:00:51,489 --> 00:00:56,379
אני צריך לומר
is not the best way for computing solutions

14
מראש שהכלל של
to linear systems of equations.

15
קריימר 00:00:56,379 --&gt;
Gaussian elimination, for example, will always
be faster.

00:00:58,010 00:00:58,010
00:01:01,950 --> 00:01:03,950
So why learn it?

--&gt; 00:01:01,950 16
00:01:03,950 --> 00:01:07,950
Think of this as a sort of cultural excursion;
it’s a helpful exercise in deepening your
17 עוזר לגבש
18
00:01:07,950 --> 00:01:10,520
knowledge of the theory of these systems.
רעיונות מאלגברה לינארית,
19
00:01:10,520 --> 00:01:15,500
Wrapping your mind around this concept will
כמו המערכות

20
00:01:15,500 --> 00:01:19,960
הקובעות והלינאריות, על
seeing how they relate to each other.

21
ידי 00:01:19,960 --&gt;
Also, from a purely artistic standpoint, the
ultimate result is just really pretty to think

00:01:24,619 22 23
00:01:24,619 --> 00:01:28,340
about, much more so that Gaussian elimination.

יעבדו מערכות
00:01:28,340 --> 00:01:33,740
Alright, so the setup here will be some linear
system of equations, say with two unknowns,
עם מספר גדול
24
00:01:33,740 --> 00:01:35,990
x and y, and two equations.
יותר של לא
25
00:01:35,990 --> 00:01:40,450
In principle, everything we’re talking about
ידועים, ומספר זהה

26
00:01:40,450 --> 00:01:41,840
של משוואות.

27
00:01:41,840 --> 00:01:46,349
אבל לשם הפשטות,
to hold in our heads.

28
דוגמה קטנה יותר
So as I talked about in a previous video,
you can think of this setup geometrically

היא נחמדה יותר
00:01:50,599 --> 00:01:56,599
as a certain known matrix transforming an
unknown vector, [x; y], where you know what
00:01:46,349 --&gt; 00:01:50,599
30
00:01:56,599 --> 00:02:00,420
the output is going to be, in this case [-4;
29 -2].

31
00:02:00,420 --> 00:02:06,250
זכור, העמודות של
you how the matrix acts as a transform, each

32
המטריצה הזו מספרות
one telling you where the basis vectors of
the input space land.

00:02:06,250 --&gt; 00:02:10,899
00:02:10,899 --> 00:02:23,060
So this is a sort of puzzle, what input [x;
y], is going to give you this
33 סוג התשובה
34
00:02:23,060 --> 00:02:28,150
output [-4; -2]?
שתקבל כאן יכולה
35
00:02:28,150 --> 00:02:39,680
Remember, the 
להיות תלויה בשאלה

36
00:02:39,680 --> 00:02:44,299
אם הטרנספורמציה נמעכת
all of space into a lower dimension.

37
או לא 00:02:44,299
That is if it has zero determinant.

38
--&gt; 00:02:46,080 00:02:46,080
In that case, either none of the inputs land
on our given output or there are a whole bunch

--&gt; 00:02:51,849 39
00:02:51,849 --> 00:02:57,540
of inputs landing on that output.

40 המרחב ה-n-ממדי
00:02:57,540 --> 00:03:01,709
But for this video we’ll limit our view
to the case of a non-zero determinant, meaning
המלא בו הוא
41
00:03:01,709 --> 00:03:07,790
the output of this transformation still spans
התחיל; כל קלט

42
00:03:07,790 --> 00:03:12,549
נוחת על פלט
and every output has one and only one input.

43
אחד ויחיד 00:03:12,549
One way to think about our puzzle is that
we know the given output vector is some linear

--&gt; 00:03:14,840 44
00:03:14,840 --> 00:03:15,840
combination of the columns of the matrix;
x*(the vector where i-hat lands) + y*(the
חשב מה הם
45
00:03:15,840 --> 00:03:16,840
vector where j-hat lands), but we wish to
בדיוק x ו-y.

46
00:03:16,840 --> 00:03:18,829
כמעבר ראשון, הרשו
is wrong, but in the right direction.

47
לי להראות רעיון
The x-coordinate of this mystery input vector
is what you get by taking its dot product

ש-00:03:18,829 --&gt;
00:03:23,340 --> 00:03:25,939
with the first basis vector, [1; 0].

00:03:23,340 48 49
00:03:25,939 --> 00:03:30,830
Likewise, the y-coordinate is what you get
by dotting it with the second basis vector,
תוצרי הנקודה
50
00:03:30,830 --> 00:03:31,980
[0; 1].
עם הגרסה שעברה
51
00:03:31,980 --> 00:03:37,439
So maybe you hope that after the transformation,
טרנספורמציה של

52
00:03:37,439 --> 00:03:41,939
וקטור המסתורין עם
versions of the basis vectors will also be

53
הטרנספורמציה 00:03:41,939 --&gt;
these coordinates x and y.

54
00: 03:43,590
That’d be fantastic because we know the
transformed versions of each of these vectors.

00:03:43,590 --&gt; 00:03:50,400
00:03:50,400 --> 00:03:54,739
There’s just one problem with this: it’s
not at all true!
55 לפני
56
00:03:54,739 --> 00:03:59,450
For most linear transformations, the dot product
ואחרי השינוי יהיו

57
00:03:59,450 --> 00:04:00,840
שונים מאוד.

58
00:04:00,840 --> 00:04:04,959
לדוגמה, יכול להיות
pointing in the same direction, with a positive

59
שני וקטורים בדרך
dot product, which get pulled away from each
other during the transformation, in such a

כלל 00:04:04,959 --&gt;
00:04:09,270 --> 00:04:11,909
way that they then have a negative dot product.

00:04:09,270 60 61
00:04:11,909 --> 00:04:16,840
Likewise, if things start off perpendicular,
with dot product zero, like the two basis
יישארו מאונכים לאחר
62
00:04:16,840 --> 00:04:22,040
vectors, there’s no guarantee that they
הטרנספורמציה, וישמרו על

63
00:04:22,040 --> 00:04:24,050
מכפלת הנקודה האפסית.

64
00:04:24,050 --> 00:04:27,140
בדוגמה שבה הסתכלנו,
certainly aren’t preserved.

65
dot products
They tend to get bigger since most vectors
are getting stretched.

00:04:27,140 --&gt;
00:04:30,950 --> 00:04:36,730
In fact, transformations which do preserve
dot products are special enough to have their
00:04:30,950 66 וקטורים
67
00:04:36,730 --> 00:04:39,800
own name: Orthonormal transformations.
מאונכים זה
68
00:04:39,800 --> 00:04:44,259
These are the ones which leave all the basis
לזה עם

69
00:04:44,259 --> 00:04:45,810
יחידת אורך.

70
00:04:45,810 --> 00:04:48,470
לעתים קרובות אתה חושב על אלה כמטריצות סיבוב.

71
00:04:48,470 --> 00:04:53,000
תואם לתנועה קשיחה,
squishing or morphing.

72
ללא מתיחה, 00:04:53,000
Solving a linear system with an orthonormal
matrix is very easy: Since dot products are

--&gt; 00:04:58,920 73
00:04:58,920 --> 00:05:03,060
preserved, taking the dot product between
the output vector and all the columns of your
מוצרים בין וקטור
74
00:05:03,060 --> 00:05:08,380
matrix will be the same as taking the dot
הקלט לכל וקטורי

75
00:05:08,380 --> 00:05:13,599
הבסיס, שזהה למציאת
the coordinates of the input vector.

76
00:05:13,599 --&gt; 00
So, in that very special case, x would be
the dot product of the first column with the

:05:18,690 77 רוב
00:05:18,690 --> 00:05:24,580
output vector, and y would be the dot product
of the second column with the output vector.
המערכות הליניאריות, זה
78
00:05:24,580 --> 00:05:32,880
Now, even though this idea breaks down for
מכוון אותנו לכיוון

79
00:05:32,880 --> 00:05:37,780
של משהו לחפש:
geometric understanding for the coordinates

80
האם יש 00:05:37,780
of our input vector which remains unchanged
after the transformation?

--&gt; 00:05:42,780 81
00:05:42,780 --> 00:05:47,631
If your mind has been mulling over determinants,
you might think of this clever idea: Take
וקטור חלופי, i-hat,
82
00:05:47,631 --> 00:05:53,200
the parallelogram defined by the first basis
ווקטור הקלט המסתורין

83
00:05:53,200 --> 00:05:54,590
[איקס; y].

84
00:05:54,590 --> 00:05:59,990
השטח של המקבילית הזו
1, times the height perpendicular to that

85
הוא הבסיס שלה, 00:05:59,990
base, which is the y-coordinate of our input
vector.

--&gt; 00:06:03,460 86
00:06:03,460 --> 00:06:09,120
So, the area of this parallelogram is sort
of a screwy roundabout way to describe the
כדי לדבר על קואורדינטות,
87
00:06:09,120 --> 00:06:13,590
vector’s y-coordinate; it’s a wacky way
אבל רוץ איתי.

88
00:06:13,590 --> 00:06:19,690
למעשה, ליתר דיוק, אתה
think of the signed area of this parallelogram,

89
צריך 00:06:19,690 --&gt;
in the sense described by the determinant
video.

00:06:22,440 90 להסתכל
00:06:22,440 --> 00:06:28,110
That way, a vector with negative y-coordinate
would correspond to a negative area for this
על המקבילית המתפרשת
91
00:06:28,110 --> 00:06:29,110
parallelogram.
על ידי הווקטור
92
00:06:29,110 --> 00:06:39,490
Symmetrically, if you 
ושל וקטור הבסיס

93
00:06:39,490 --> 00:06:45,099
השני, j-hat, השטח שלו
will be the x-coordinate of the vector.

94
00:06:45,099 -- &gt;
Again, it’s a strange way to represent the
x-coordinate, but you’ll see what it buys

00:06:49,370 95 96
00:06:49,370 --> 00:06:50,449
us in a moment.

יהיה לקחת את
00:06:50,449 --> 00:06:56,101
Here’s what this would look like in three-dimensions:
Ordinarily the way you might think of one
תוצר הנקודות שלו
97
00:06:56,101 --> 00:07:01,060
of a vector’s coordinate, say its z-coordinate,
עם וקטור הבסיס

98
00:07:01,060 --> 00:07:04,439
הסטנדרטי השלישי, k-hat.

99
00:07:04,439 --> 00:07:11,870
אבל במקום זאת,
creates with the other two basis vectors,

100
קחו בחשבון את
i-hat and j-hat.

101
המקבילית 00:07:11,870 --&gt;
If you think of the square with area 1 spanned
by i-hat and j-hat as the base of this guy,

00:07:13,569 00:07:13,569 --&gt;
00:07:20,030 --> 00:07:24,259
its volume is the same its height, which is
the third coordinate of our vector.
00:07:20,030 102 קואורדינטה
103
00:07:24,259 --> 00:07:28,370
Likewise, the wacky way to think about any
אחרת של

104
00:07:28,370 --> 00:07:34,950
וקטור זה היא
all the basis vectors other than the one you’re

105
ליצור מקבילית בין
looking for, and get its volume.

106
וקטור זה ל-00:
Or, rather, we should talk about the signed
volume of these parallelepipeds, in the sense

07:34,950 --&gt; 00:07:37,900
00:07:42,490 --> 00:07:47,819
described in the determinant video, where
the order in which you list the three vectors
00:07:37,900 --&gt; 00:07:42,490
108
00:07:47,819 --> 00:07:48,900
matters and you’re using the right-hand
107 כלל.

109
00:07:48,900 --> 00:07:51,610
ככה קואורדינטות שליליות עדיין הגיוניות.

110
00:07:51,610 --> 00:07:56,000
אוקיי, אז למה
and volumes like this?

111
לחשוב על
As you apply some matrix transformation, the
areas of the parallelograms don’t stay the

קואורדינטות כאזורים
00:08:02,039 --> 00:08:04,129
same, they may get scaled up or down.

00:07:56,000 --&gt;
00:08:04,129 --> 00:08:09,940
But(!), and this is a key idea of determinants,
all these areas get scaled by the same amount.
00:08:02,039 112
114
00:08:09,940 --> 00:08:13,560
Namely, the determinant of our transformation
113 מטריצה.

115
00:08:13,560 --> 00:08:17,850
לדוגמה, אם אתה
spanned by the vector where your first basis

116
מסתכל על
vector lands, which is the first column of
the matrix, and the transformed version of

המקבילית 00:08:17,850
00:08:22,850 --> 00:08:25,180
[x; y], what is its area?

--&gt; 00:08:22,850
00:08:25,180 --> 00:08:30,229
Well, this is the transformed version of that
parallelogram we were looking at earlier,
117 118
119
00:08:30,229 --> 00:08:33,950
whose area was the y-coordinate of the mystery
וקטור הקלט.

120
00:08:33,950 --> 00:08:39,080
אז השטח שלו
transformation multiplied by that value.

121
יהיה הקובע של
So, the y-coordinate of our mystery input
vector is the area of this parallelogram,

00:08:39,080 --&gt;
00:08:44,590 --> 00:08:48,510
spanned by the first column of the matrix
and the output vector, divided by the determinant
00:08:44,590 122 ארצות
123
00:08:48,510 --> 00:08:51,120
of the full transformation.
וקטור הקלט המסתורין,
124
00:08:51,120 --> 00:08:53,090
And how do you get this area?
זה כל
125
00:08:53,090 --> 00:08:57,360
Well, we know the coordinates for where the
הפואנטה של מערכת

126
00:08:57,360 --> 00:08:59,850
משוואות לינארית.

127
00:08:59,850 --> 00:09:05,670
אז, צור מטריצה שהעמודה
the same as that of our matrix, and whose

128
הראשונה שלה היא 00:09:05,670
second column is the output vector, and take
its determinant.

--&gt; 00:09:11,250 129
00:09:11,250 --> 00:09:16,560
So look at that; just using data from the
output of the transformation, namely the columns
וקטור, נוכל לשחזר את
130
00:09:16,560 --> 00:09:21,340
of the matrix and the coordinates of our output
קואורדינטת ה-y של וקטור

131
00:09:21,340 --> 00:09:23,880
הקלט המסתורין שלנו.

132
00:09:23,880 --> 00:09:28,100
באופן דומה, אותו רעיון יכול להביא לך את קואורדינטת ה-x.

133
00:09:28,100 --> 00:09:32,580
תראה את המקבילה
which encodes the x-coordinate of the mystery

134
שהגדרנו מוקדם 00:09:32,580
input vector, spanned by the input vector
and j-hat.

--&gt; 00:09:36,420
00:09:36,420 --> 00:09:41,970
The transformed version of this guy is spanned
by the output vector and the second column
135 כפול בדטרמיננטה
136
00:09:41,970 --> 00:09:47,710
of the matrix, and its area will have been
של המטריצה.

137
00:09:47,710 --> 00:09:52,000
אז קואורדינטת ה-x של
is this area divided by the determinant of

138
וקטור הקלט המסתורין
the transformation.

139
שלנו 00:09:52,000 --&gt; 00:09:53,980
Symmetric to what we did before, you can compute
the area of that output parallelogram by creating

00:09:53,980 --&gt; 00:09:58,900
00:09:58,900 --> 00:10:04,530
a new matrix whose first column is the output
vector, and whose second column is the same
140 רווח, המספרים שאנו
141
00:10:04,530 --> 00:10:06,300
as the original matrix.
רואים במערכת הליניארית
142
00:10:06,300 --> 00:10:10,120
So again, just using data from the output
המקורית שלנו, אנו

143
00:10:10,120 --> 00:10:13,600
יכול לשחזר את קואורדינטת
of our mystery input vector.

144
ה-x 00:10:13,600 --&gt;
This formula for finding the solutions to
a linear system of equations is known as Cramer’s

00:10:18,440 145 146 הוא
00:10:18,440 --> 00:10:19,440
rule.

4+2, שזה 6,
00:10:19,440 --> 00:10:22,400
Here, just to sanity check ourselves, plug
in the numbers here.
והקביעה התחתונה היא 2,
147
00:10:22,400 --> 00:10:28,430
The determinant of that top altered matrix
כך שקואורדינטת ה-x

148
00:10:28,430 --> 00:10:31,430
צריכה להיות 3.

149
00:10:31,430 --> 00:10:35,910
ואכן, במבט לאחור על
we started with, it’s x-coordinate is 3.

150
וקטור הקלט ההוא
Likewise, Cramer’s rule suggests the y-coordinate
should be 4/2, or 2, and that is indeed the

00:10:35,910 --&gt; 00:10:43,850
00:10:43,850 --> 00:10:47,540
y-coordinate of the input vector we started
with here.
151 ואני ממליץ לך
152
00:10:47,540 --> 00:10:52,690
The case with three dimensions is similar,
בחום לעצור לחשוב

153
00:10:52,690 --> 00:10:53,690
על זה בעצמך.

154
00:10:53,690 --> 00:10:56,770
הנה, אני אתן לך קצת מומנטום.

155
00:10:56,770 --> 00:11:02,780
יש לנו את הטרנספורמציה
a 3x3 matrix, and a known output vector, given

156
הידועה הזו, הניתנת
by the right side of our linear system, and
we want to know what input vector lands on

על ידי 00:11:02,780
00:11:07,580 --> 00:11:09,200
this output vector.

--&gt; 00:11:07,580 157 158
00:11:09,200 --> 00:11:16,700
If you think of, say, the z-coordinate of
the input vector as the volume of this parallelepiped
וקטור, מה קורה
159
00:11:16,700 --> 00:11:25,530
spanned by i-hat, j-hat, and the mystery input
לנפח של מקבילי

160
00:11:25,530 --> 00:11:26,530
זה לאחר הטרנספורמציה?

161
00:11:26,530 --> 00:11:28,190
איך אתה יכול לחשב את הנפח החדש הזה?

162
00:11:28,190 --> 00:11:32,200
באמת, עצרו והקדישו
the details of generalizing this to higher

163
רגע לחשוב
dimensions; finding an expression for each
coordinate of the solution to larger linear

00:11:32,200 --&gt; 00:11:37,330
00:11:37,330 --> 00:11:38,330
systems.

164 165
00:11:38,330 --> 00:11:44,140
Thinking through more general cases and convincing
yourself that it works is where all the learning
איזה בחור ב-YouTube
166
00:11:44,140 --> 00:11:48,520
will happen, much more so than listening to
יעבור שוב

167
00:11:48,520 --> 00:12:09,940
על ההיגיון.

