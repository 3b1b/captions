[
 {
  "input": "In a previous video, I’ve talked about linear 00:00:15,800 --> 00:00:19,690 3  is a good litmus test for whether or not you actually understand what’s going on, since 00:00:31,680 --> 00:00:32,680 00:00:32,680 --> 00:00:36,379 8 9  sure to watch the relevant videos on those topics if you’re unfamiliar or rusty.",
  "model": "nmt",
  "translatedText": "En un video anterior hablé sobre sistemas lineales de ecuaciones, y en cierto modo dejé de lado la discusión sobre cómo calcular soluciones para estos sistemas. Y si bien es cierto que los cálculos numéricos suelen ser algo que dejamos en manos de las computadoras, profundizar en algunos de estos métodos computacionales es una buena prueba de fuego para saber si realmente se comprende o no lo que está pasando, ya que ahí es donde realmente se pone en marcha el asunto. Aquí quiero describir la geometría detrás de cierto método para calcular soluciones para estos sistemas, conocido como regla de Cramer. La experiencia relevante aquí es comprender los determinantes, un poco de productos escalares y, por supuesto, los sistemas lineales de ecuaciones, así que asegúrese de ver los videos relevantes sobre esos temas si no está familiarizado o está oxidado. Pero primero debo decir desde el principio que esta regla de Cramer no es en realidad la mejor manera de calcular soluciones a sistemas lineales de ecuaciones. La eliminación gaussiana, por ejemplo, siempre será más rápida. Entonces, ¿por qué aprenderlo? Bueno, considérelo como una especie de excursión cultural. Es un ejercicio útil para profundizar su conocimiento de la teoría detrás de estos sistemas."
 },
 {
  "input": "But first!",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "I should say up front that Cramer’s rule 00:00:56,379 --> 00:00:58,010 00:00:58,010 --> 00:01:01,950 16 17   help consolidate ideas from linear algebra, like the determinant and linear systems, by 00:01:19,960 --> 00:01:24,619 22 23   will work systems with a larger number of unknowns, and the same number of equations.",
  "model": "nmt",
  "translatedText": "Entender este concepto te ayudará a consolidar ideas del álgebra lineal, como el determinante y los sistemas lineales, al ver cómo se relacionan entre sí. Además, desde un punto de vista puramente artístico, el resultado final aquí es realmente bonito, mucho más que la eliminación gaussiana. Muy bien, entonces la configuración aquí será un sistema lineal de ecuaciones, digamos con dos incógnitas, xey, y dos ecuaciones. En principio, todo lo que estamos hablando también funcionará para sistemas con un mayor número de incógnitas y el mismo número de ecuaciones, pero por simplicidad es mejor tener un ejemplo más pequeño en la cabeza. Entonces, como mencioné en un video anterior, puedes pensar en esta configuración geométricamente, como una determinada matriz conocida que transforma un vector desconocido, x, y, donde sabes cuál será la salida, en este caso, negativo 4, negativo 2. Recuerde, las columnas de esta matriz le indican cómo esa matriz actúa como una transformación, y cada una le indica dónde aterrizan los vectores base del espacio de entrada. Entonces lo que tenemos es una especie de rompecabezas. ¿Qué vector de entrada, x, y, aterrizará en esta salida, menos 4, menos 2? Una forma de pensar en nuestro pequeño rompecabezas aquí es que sabemos que el vector de salida dado es una combinación lineal de las columnas de la matriz, x multiplicado por el vector donde aterriza i-hat más y multiplicado por el vector donde aterriza j-hat, pero ¿qué Lo que queremos es descubrir cuál debería ser exactamente esa combinación lineal."
 },
 {
  "input": "But for simplicity, a smaller example is nicer 00:01:46,349 --> 00:01:50,599 29  -2].",
  "model": "nmt",
  "translatedText": "Recuerde, el tipo de respuesta que obtenga aquí puede depender de si la transformación aplasta o no todo el espacio en una dimensión inferior, es decir, si tiene un determinante cero. En ese caso, ninguna de las entradas llega a nuestra salida dada, o hay un montón de entradas que llegan a esa salida. Pero para este video, limitaremos nuestra visión al caso de un determinante distinto de cero, lo que significa que los resultados de esta transformación aún abarcan todo el espacio indimensional en el que comenzó. Cada entrada aterriza en una y sólo una salida, y cada salida tiene una y sólo una entrada."
 },
 {
  "input": "Remember, the columns of this matrix tell 00:02:06,250 --> 00:02:10,899 33   type of answer you get here can depend on whether or not the transformation squishes 00:02:44,299 --> 00:02:46,080 00:02:46,080 --> 00:02:51,849 39 40  the full n-dimensional space it started in; every input lands on one and only one output 00:03:12,549 --> 00:03:14,840 44  compute what exactly x and y are.",
  "model": "nmt",
  "translatedText": "Como primer paso, déjame mostrarte una idea que está mal pero que va en la dirección correcta. La coordenada x de este misterioso vector de entrada es lo que se obtiene al tomar su producto escalar con el primer vector base, 1, 0. Del mismo modo, la coordenada y es lo que se obtiene al puntearla con el vector de la segunda base, 0, 1. Entonces, tal vez esperes que después de la transformación, los productos escalares con la versión transformada del vector misterioso con la versión transformada también sean estas coordenadas, x e y. Sería fantástico, porque sabemos cuál es la versión transformada de cada uno de esos vectores. Sólo hay un problema con esto: no es del todo cierto. Para la mayoría de las transformaciones lineales, el producto escalar antes y después de la transformación se verá muy diferente. Por ejemplo, podría tener dos vectores que generalmente apuntan en la misma dirección con un producto escalar positivo, que se separan entre sí durante la transformación de tal manera que terminan teniendo un producto escalar negativo. Del mismo modo, las cosas que comienzan perpendiculares con el producto escalar 0, como los dos vectores base, a menudo no permanecen perpendiculares entre sí después de la transformación, es decir, no conservan ese producto escalar 0. Y mirando el ejemplo que acabo de mostrar, los productos escalares ciertamente no se conservan, tienden a hacerse más grandes ya que la mayoría de los vectores se estiran. De hecho, una nota al margen que vale la pena señalar aquí es que las transformaciones que conservan los productos escalares son lo suficientemente especiales como para tener su propio nombre, transformaciones ortonormales. Estos son los que dejan todos los vectores base perpendiculares entre sí y aún con longitudes unitarias."
 },
 {
  "input": "As a first pass, let me show an idea that 00:03:18,829 --> 00:03:23,340 48 49   the dot products with the transformed version of the mystery vector with the transformed 00:03:41,939 --> 00:03:43,590 00:03:43,590 --> 00:03:50,400 55  before and after the transformation will be very different.",
  "model": "nmt",
  "translatedText": "A menudo se piensa en ellas como matrices de rotación, corresponden a un movimiento rígido sin estiramiento, aplastamiento o transformación. Resolver un sistema lineal con una matriz ortonormal es realmente muy fácil. Debido a que los productos escalares se conservan, tomar el producto escalar entre el vector de salida y todas las columnas de su matriz será lo mismo que tomar el producto escalar entre el vector de entrada misterioso y todos los vectores base, que es lo mismo que simplemente encontrar el coordenadas de esa entrada misteriosa. Entonces, en ese caso tan especial, x sería el producto escalar de la primera columna con el vector de salida, e y sería el producto escalar de la segunda columna con el vector de salida. ¿Por qué menciono esto cuando esta idea fracasa en casi todos los sistemas lineales? Bueno, nos indica la dirección de algo que debemos buscar. ¿Existe una comprensión geométrica alternativa para las coordenadas de nuestro vector de entrada que permanezca sin cambios después de la transformación? Si su mente ha estado reflexionando sobre los determinantes, podría pensar en la siguiente idea inteligente. Tome el paralelogramo definido por el primer vector base, i-hat, y el vector de entrada misterioso, xy. El área de este paralelogramo es la base, 1, multiplicada por la altura perpendicular a esa base, que es la coordenada y de ese vector de entrada."
 },
 {
  "input": "For example, you could have two vectors generally 00:04:04,959 --> 00:04:09,270 60 61  will stay perpendicular after the transformation, preserving that zero dot product.",
  "model": "nmt",
  "translatedText": "Entonces, el área de ese paralelogramo es una especie de forma indirecta de describir la coordenada y del vector. Es una forma rara de hablar de coordenadas, pero sigue conmigo. Y de hecho, para ser un poco más preciso, deberías pensar en esto como el área con signo de ese paralelogramo, en el sentido descrito en el vídeo determinante. De esa manera, un vector con una coordenada y negativa correspondería a un área negativa para este paralelogramo, al menos si piensas que i-hat es, en cierto sentido, el primero de estos dos vectores que definen el paralelogramo. Y simétricamente, si nos fijamos en el paralelogramo abarcado por nuestro misterioso vector de entrada y la segunda base, j-hat, su área será la coordenada x de ese vector misterioso."
 },
 {
  "input": "In the example we were looking at, dot products 00:04:27,140 --> 00:04:30,950 66   vectors perpendicular to each other with unit lengths.",
  "model": "nmt",
  "translatedText": "Nuevamente, es una forma extraña de representar la coordenada x, pero verás lo que nos aporta en un momento. Y sólo para asegurarnos de que quede claro cómo podría generalizarse esto, miremos en tres dimensiones. Normalmente, la forma en que se podría pensar en una de las coordenadas de un vector, digamos su coordenada z, sería tomar su producto escalar con el tercer vector base estándar, a menudo llamado k-hat. Pero una interpretación geométrica alternativa sería considerar el paralelepípedo que crea con los otros dos vectores base, i-hat y j-hat. Si piensas en el cuadrado con área 1 abarcada por i-hat y j-hat como la base de toda esta forma, entonces su volumen es el mismo que su altura, que es la tercera coordenada de nuestro vector."
 },
 {
  "input": "You often think of these as rotation matrices.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "The correspond to rigid motion, with no stretching, 00:04:53,000 --> 00:04:58,920 73  products between the input vector and all the basis vectors, which is the same as finding 00:05:13,599 --> 00:05:18,690 77  most linear systems, it points us in the direction of something to look for: Is there an alternate 00:05:37,780 --> 00:05:42,780 81  vector, i-hat, and the mystery input vector [x; y].",
  "model": "nmt",
  "translatedText": "Y de la misma manera, la forma loca de pensar en las otras coordenadas del vector sería formar un paralelepípedo usando el vector y luego todos los vectores base distintos del correspondiente a la dirección que estás buscando. Entonces el volumen de esto te da la coordenada. O mejor dicho, deberíamos hablar del volumen firmado del paralelepípedo, en el sentido descrito en el vídeo determinante utilizando la regla de la mano derecha. Entonces, el orden en el que enumeras estos tres vectores es importante. De esa forma, las coordenadas negativas siguen teniendo sentido. Bien, entonces ¿por qué pensar en las coordenadas como áreas y volúmenes como este? Bueno, cuando aplicas algún tipo de transformación matricial, las áreas de estos paralelogramos, bueno, no permanecen iguales, pueden aumentar o reducirse. Pero, y esta es la idea clave de los determinantes, todas las áreas se escalan en la misma cantidad, es decir, el determinante de nuestra matriz de transformación. Por ejemplo, si observa el paralelogramo abarcado por el vector donde aterriza su primer vector base, que es la primera columna de la matriz, y la versión transformada de xy, ¿cuál es su área? Bueno, esta es la versión transformada del paralelogramo que estábamos viendo antes, aquel cuyo área era la coordenada y del misterioso vector de entrada. Entonces su área será simplemente el determinante de la transformación multiplicada por esa coordenada y. Eso significa que podemos resolver y tomando el área de este nuevo paralelogramo en el espacio de salida, dividido por el determinante de la transformación completa. ¿Y cómo se consigue esa zona?"
 },
 {
  "input": "The area of this parallelogram is its base, 00:05:59,990 --> 00:06:03,460 86  to talk about coordinates, but run with me.",
  "model": "nmt",
  "translatedText": "Bueno, conocemos las coordenadas donde aterriza el misterioso vector de entrada, ese es el objetivo de un sistema lineal de ecuaciones. Entonces, lo que podrías hacer es crear una nueva matriz cuya primera columna sea la misma que la de nuestra matriz, pero cuya segunda columna sea el vector de salida, y luego tomas su determinante. Mire eso, simplemente usando datos de la salida de la transformación, es decir, las columnas de la matriz y las coordenadas de nuestro vector de salida, podemos recuperar la coordenada y del vector de entrada misterioso, que está a medio camino de resolver el sistema."
 },
 {
  "input": "Actually, to be more accurate, you should 00:06:19,690 --> 00:06:22,440 90   look at the parallelogram spanned by the vector and the second basis vector, j-hat, its area 00:06:45,099 --> 00:06:49,370 95 96  would be to take its dot product with the third standard basis vector, k-hat.",
  "model": "nmt",
  "translatedText": "Asimismo, la misma idea puede darnos la coordenada x. Mire el paralelogramo que definimos anteriormente, que codifica la coordenada x del vector de entrada misterioso, abarcado por ese vector y j-hat. La versión transformada de este tipo está abarcada por el vector de salida y la segunda columna de la matriz, y su área se habrá multiplicado por el determinante de esa matriz. Entonces, para resolver x, puedes dividir esta nueva área por el determinante de la transformación completa. Y de manera similar a lo que hicimos antes, puedes calcular el área de ese paralelogramo de salida creando una nueva matriz cuya primera columna sea el vector de salida y cuya segunda columna sea la misma que la matriz original. De nuevo, simplemente usando datos del espacio de salida, los números que vemos en nuestro sistema lineal original, podemos resolver cuál debe ser x. Esta fórmula para encontrar las soluciones de un sistema lineal de ecuaciones se conoce como regla de Cramer. Aquí, solo para comprobar nuestra cordura, ingrese algunos números aquí. El determinante de esa matriz alterada superior es 4 más 2, que es 6, y el determinante inferior es 2, por lo que la coordenada x debería ser 3."
 },
 {
  "input": "But instead, consider the parallelepiped it 00:07:11,870 --> 00:07:13,569 00:07:13,569 --> 00:07:20,030 102  other coordinate of this vector is to form the parallelepiped between this vector an 00:07:34,950 --> 00:07:37,900 00:07:37,900 --> 00:07:42,490 107  rule.",
  "model": "nmt",
  "translatedText": "Y de hecho, mirando hacia atrás en el vector de entrada con el que comenzamos, la coordenada x es 3. Asimismo, la regla de Cramer sugiere que la coordenada y debe ser 4 dividido por 2, o 2, y esa es la coordenada y del vector de entrada con el que comenzamos. El caso con 3 dimensiones o más es similar, y le recomiendo que se tome un momento para hacer una pausa y pensarlo usted mismo. Aquí les daré un poco de impulso. Lo que tenemos es una transformación conocida dada por una matriz de 3x3 y un vector de salida conocido dado por el lado derecho de nuestro sistema lineal, y queremos saber qué entrada llega a esa salida. Y si piensas, digamos, en la coordenada z de ese vector de entrada como el volumen de ese paralelepípedo especial que estábamos viendo antes, abarcado por i-hat, j-hat y el misterioso vector de entrada, ¿qué sucede con ese volumen? después de la transformación? ¿Y cuáles son las diversas formas en que se puede calcular ese volumen? Realmente, haga una pausa y tómese un momento para pensar en los detalles de generalizar esto a dimensiones superiores, encontrar una expresión para cada coordenada de la solución a un sistema lineal más grande."
 },
 {
  "input": "That way negative coordinates still make sense.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Okay, so why think of coordinates as areas 00:07:56,000 --> 00:08:02,039 112 113  matrix.",
  "model": "nmt",
  "translatedText": "Pensar en casos más generales como este y convencerse de que funciona y de por qué funciona es donde realmente ocurre todo el aprendizaje, mucho más que escuchar a un tipo en YouTube explicarle el mismo razonamiento nuevamente."
 },
 {
  "input": "For example, if you look the parallelogram 00:08:17,850 --> 00:08:22,850 117 118  input vector.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So its area will be the determinant of the 00:08:39,080 --> 00:08:44,590 122    mystery input vector lands, that’s the whole point of a linear system of equations.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So, create a matrix whose first column is 00:09:05,670 --> 00:09:11,250 129  vector, we can recover the y-coordinate of our mystery input vector.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Likewise, the same idea can get you the x-coordinate.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Look at that parallelogram we defined early 00:09:32,580 --> 00:09:36,420 135  multiplied by the determinant of the matrix.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "So the x-coordinate of our mystery input vector 00:09:52,000 --> 00:09:53,980 00:09:53,980 --> 00:09:58,900 140   space, the numbers we see in our original linear system, we can recover the x-coordinate 00:10:13,600 --> 00:10:18,440 145 146  is 4+2, which is 6, and the bottom determinant is 2, so the x-coordinate should be 3.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "And indeed, looking back at that input vector 00:10:35,910 --> 00:10:43,850 151  and I highly recommend you pause to think it through yourself.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Here, I’ll give you a little momentum.",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "We have this known transformation, given by 00:11:02,780 --> 00:11:07,580 157 158  vector, what happens to the volume of this parallelepiped after the transformation?",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "How can you compute that new volume?",
  "model": "nmt",
  "translatedText": ""
 },
 {
  "input": "Really, pause and take a moment to think through 00:11:32,200 --> 00:11:37,330 164 165  some dude on YouTube walk through the reasoning again.",
  "model": "nmt",
  "translatedText": ""
 }
]