[
 {
  "input": "In a previous video, I’ve talked about linear systems of equations, and I sort of brushed aside the discussion of actually computing solutions to these systems. ",
  "translatedText": "In un video precedente, ho parlato di sistemi lineari di equazioni e ho in un certo senso messo da parte la discussione sulle soluzioni effettivamente computazionali per questi sistemi. ",
  "n_reviews": 0,
  "start": 11.2,
  "end": 19.14
 },
 {
  "input": "And while it’s true that number-crunching is something we typically leave to the computers, digging into some of these computational methods is a good litmus test for whether or not you actually understand what’s going on, since this is really where the rubber meets the road. ",
  "translatedText": "E anche se è vero che l'elaborazione dei numeri è qualcosa che di solito lasciamo ai computer, scavare in alcuni di questi metodi computazionali è un buon test del nove per capire se si capisce davvero cosa sta succedendo, dal momento che è proprio qui che la gomma incontra la strada. . ",
  "n_reviews": 0,
  "start": 19.7,
  "end": 31.52
 },
 {
  "input": "Here I want to describe the geometry behind a certain method for computing solutions to these systems, known as Cramer’s rule. ",
  "translatedText": "Qui voglio descrivere la geometria dietro un certo metodo per calcolare le soluzioni a questi sistemi, noto come regola di Cramer. ",
  "n_reviews": 0,
  "start": 32.12,
  "end": 38.88
 },
 {
  "input": "The relevant background needed here is an understanding of determinants, dot products, and of linear systems of equations, so be sure to watch the relevant videos on those topics if you’re unfamiliar or rusty. ",
  "translatedText": "Il background pertinente necessario qui è la comprensione dei determinanti, dei prodotti scalari e dei sistemi lineari di equazioni, quindi assicurati di guardare i video pertinenti su questi argomenti se non hai familiarità o sei arrugginito. ",
  "n_reviews": 0,
  "start": 39.68,
  "end": 50.42
 },
 {
  "input": "But first! ",
  "translatedText": "Ma prima! ",
  "n_reviews": 0,
  "start": 51.02,
  "end": 51.44
 },
 {
  "input": "I should say up front that Cramer’s rule is not the best way for computing solutions to linear systems of equations. ",
  "translatedText": "Dovrei dire subito che la regola di Cramer non è il modo migliore per calcolare soluzioni a sistemi lineari di equazioni. ",
  "n_reviews": 0,
  "start": 51.44,
  "end": 57.26
 },
 {
  "input": "Gaussian elimination, for example, will always be faster. ",
  "translatedText": "L’eliminazione gaussiana, ad esempio, sarà sempre più veloce. ",
  "n_reviews": 0,
  "start": 58.14,
  "end": 61.26
 },
 {
  "input": "So why learn it? ",
  "translatedText": "Allora perché impararlo? ",
  "n_reviews": 0,
  "start": 61.98,
  "end": 63.52
 },
 {
  "input": "Think of this as a sort of cultural excursion; it’s a helpful exercise in deepening your knowledge of the theory of these systems. ",
  "translatedText": "Consideratela una sorta di escursione culturale; è un esercizio utile per approfondire la conoscenza della teoria di questi sistemi. ",
  "n_reviews": 0,
  "start": 63.78,
  "end": 70.46
 },
 {
  "input": "Wrapping your mind around this concept will help consolidate ideas from linear algebra, like the determinant and linear systems, by seeing how they relate to each other. ",
  "translatedText": "Comprendere questo concetto ti aiuterà a consolidare le idee dell'algebra lineare, come il determinante e i sistemi lineari, vedendo come si relazionano tra loro. ",
  "n_reviews": 0,
  "start": 71.04,
  "end": 79.62
 },
 {
  "input": "Also, from a purely artistic standpoint, the ultimate result is just really pretty to think about, much more so that Gaussian elimination. ",
  "translatedText": "Inoltre, da un punto di vista puramente artistico, il risultato finale è davvero carino da pensare, tanto più che l'eliminazione gaussiana. ",
  "n_reviews": 0,
  "start": 80.1,
  "end": 86.88
 },
 {
  "input": "Alright, so the setup here will be some linear system of equations, say with two unknowns, x and y, and two equations. ",
  "translatedText": "Va bene, quindi la configurazione qui sarà un sistema lineare di equazioni, diciamo con due incognite, xey, e due equazioni. ",
  "n_reviews": 0,
  "start": 88.68,
  "end": 95.62
 },
 {
  "input": "In principle, everything we’re talking about will work systems with a larger number of unknowns, and the same number of equations. ",
  "translatedText": "In linea di principio, tutto ciò di cui stiamo parlando funzionerà con sistemi con un numero maggiore di incognite e lo stesso numero di equazioni. ",
  "n_reviews": 0,
  "start": 96.3,
  "end": 101.94
 },
 {
  "input": "But for simplicity, a smaller example is nicer to hold in our heads. ",
  "translatedText": "Ma per semplicità, è più bello tenere in testa un esempio più piccolo. ",
  "n_reviews": 0,
  "start": 102.44,
  "end": 105.58
 },
 {
  "input": "So as I talked about in a previous video, you can think of this setup geometrically as a certain known matrix transforming an unknown vector, [x; y], where you know what the output is going to be, in this case [-4; -2]. ",
  "translatedText": "Quindi, come ho detto in un video precedente, puoi pensare a questa configurazione geometricamente come una certa matrice conosciuta che trasforma un vettore sconosciuto, [x; y], dove sai quale sarà l'output, in questo caso [-4; -2]. ",
  "n_reviews": 0,
  "start": 106.32,
  "end": 120.04
 },
 {
  "input": "Remember, the columns of this matrix tell you how the matrix acts as a transform, each one telling you where the basis vectors of the input space land. ",
  "translatedText": "Ricorda, le colonne di questa matrice ti dicono come la matrice agisce come una trasformazione, ognuna delle quali ti dice dove si fermano i vettori di base dello spazio di input. ",
  "n_reviews": 0,
  "start": 120.8,
  "end": 130.08
 },
 {
  "input": "So this is a sort of puzzle, what input [x; y], is going to give you this output [-4; -2]? ",
  "translatedText": "Quindi questo è una sorta di puzzle, quale input [x; y], ti darà questo output [-4; -2]? ",
  "n_reviews": 0,
  "start": 130.86,
  "end": 137.6
 },
 {
  "input": "Remember, the type of answer you get here can depend on whether or not the transformation squishes all of space into a lower dimension. ",
  "translatedText": "Ricorda, il tipo di risposta che ottieni qui può dipendere dal fatto che la trasformazione schiacci o meno tutto lo spazio in una dimensione inferiore. ",
  "n_reviews": 0,
  "start": 137.6,
  "end": 148.4
 },
 {
  "input": "That is if it has zero determinant. ",
  "translatedText": "Questo se ha determinante zero. ",
  "n_reviews": 0,
  "start": 148.4,
  "end": 151.22
 },
 {
  "input": "In that case, either none of the inputs land on our given output or there are a whole bunch of inputs landing on that output. ",
  "translatedText": "In tal caso, o nessuno degli input arriva al nostro dato output oppure ci sono un sacco di input che arrivano a quell'output. ",
  "n_reviews": 0,
  "start": 151.22,
  "end": 156.22
 },
 {
  "input": "But for this video we’ll limit our view to the case of a non-zero determinant, meaning the output of this transformation still spans the full n-dimensional space it started in; every input lands on one and only one output and every output has one and only one input. ",
  "translatedText": "Ma per questo video limiteremo la nostra visione al caso di un determinante diverso da zero, il che significa che l'output di questa trasformazione si estende ancora nell'intero spazio n-dimensionale in cui è iniziata; ogni input finisce su uno e un solo output e ogni output ha uno e un solo input. ",
  "n_reviews": 0,
  "start": 157.24,
  "end": 168.94
 },
 {
  "input": "One way to think about our puzzle is that we know the given output vector is some linear combination of the columns of the matrix; x*(the vector where i-hat lands) + y*(the vector where j-hat lands), but we wish to compute what exactly x and y are. ",
  "translatedText": "Un modo di pensare al nostro puzzle è che sappiamo che il vettore di output dato è una combinazione lineare delle colonne della matrice; x*(il vettore dove si ferma i-hat) + y*(il vettore dove si ferma j-hat), ma vogliamo calcolare cosa sono esattamente xey. ",
  "n_reviews": 0,
  "start": 168.94,
  "end": 186.72
 },
 {
  "input": "As a first pass, let me show an idea that is wrong, but in the right direction. ",
  "translatedText": "Come primo passo, lasciatemi mostrare un'idea sbagliata, ma nella giusta direzione. ",
  "n_reviews": 0,
  "start": 186.72,
  "end": 198.16
 },
 {
  "input": "The x-coordinate of this mystery input vector is what you get by taking its dot product with the first basis vector, [1; 0]. ",
  "translatedText": "La coordinata x di questo misterioso vettore di input è quella che ottieni prendendo il suo prodotto scalare con il primo vettore base, [1; 0]. ",
  "n_reviews": 0,
  "start": 198.8,
  "end": 205.44
 },
 {
  "input": "Likewise, the y-coordinate is what you get by dotting it with the second basis vector, [0; 1]. ",
  "translatedText": "Allo stesso modo, la coordinata y è ciò che si ottiene punteggiandola con il secondo vettore base, [0; 1]. ",
  "n_reviews": 0,
  "start": 206.16,
  "end": 211.4
 },
 {
  "input": "So maybe you hope that after the transformation, the dot products with the transformed version of the mystery vector with the transformed versions of the basis vectors will also be these coordinates x and y. ",
  "translatedText": "Quindi forse speri che dopo la trasformazione, i prodotti scalari con la versione trasformata del vettore misterioso con le versioni trasformate dei vettori base siano anch'essi queste coordinate xey. ",
  "n_reviews": 0,
  "start": 211.9,
  "end": 223.24
 },
 {
  "input": "That’d be fantastic because we know the transformed versions of each of these vectors. ",
  "translatedText": "Sarebbe fantastico perché conosciamo le versioni trasformate di ciascuno di questi vettori. ",
  "n_reviews": 0,
  "start": 223.94,
  "end": 228.74
 },
 {
  "input": "There’s just one problem with this: it’s not at all true! ",
  "translatedText": "C'è solo un problema: non è affatto vero! ",
  "n_reviews": 0,
  "start": 231.18,
  "end": 234.2
 },
 {
  "input": "For most linear transformations, the dot product before and after the transformation will be very different. ",
  "translatedText": "Per la maggior parte delle trasformazioni lineari, il prodotto scalare prima e dopo la trasformazione sarà molto diverso. ",
  "n_reviews": 0,
  "start": 234.64,
  "end": 240.24
 },
 {
  "input": "For example, you could have two vectors generally pointing in the same direction, with a positive dot product, which get pulled away from each other during the transformation, in such a way that they then have a negative dot product. ",
  "translatedText": "Ad esempio, potresti avere due vettori che puntano generalmente nella stessa direzione, con un prodotto scalare positivo, che vengono allontanati l'uno dall'altro durante la trasformazione, in modo tale da avere poi un prodotto scalare negativo. ",
  "n_reviews": 0,
  "start": 240.8,
  "end": 251.52
 },
 {
  "input": "Likewise, if things start off perpendicular, with dot product zero, like the two basis vectors, there’s no guarantee that they will stay perpendicular after the transformation, preserving that zero dot product. ",
  "translatedText": "Allo stesso modo, se le cose iniziano perpendicolari, con prodotto scalare zero, come i due vettori di base, non c'è garanzia che rimarranno perpendicolari dopo la trasformazione, preservando quel prodotto scalare zero. ",
  "n_reviews": 0,
  "start": 252.22,
  "end": 263.48
 },
 {
  "input": "In the example we were looking at, dot products certainly aren’t preserved. ",
  "translatedText": "Nell'esempio che stavamo guardando, i prodotti scalari non vengono certamente preservati. ",
  "n_reviews": 0,
  "start": 264.1,
  "end": 267.16
 },
 {
  "input": "They tend to get bigger since most vectors are getting stretched. ",
  "translatedText": "Tendono a diventare più grandi poiché la maggior parte dei vettori viene allungata. ",
  "n_reviews": 0,
  "start": 267.5,
  "end": 269.94
 },
 {
  "input": "In fact, transformations which do preserve dot products are special enough to have their own name: Orthonormal transformations. ",
  "translatedText": "In effetti, le trasformazioni che preservano i prodotti scalari sono abbastanza speciali da avere un nome proprio: trasformazioni ortonormali. ",
  "n_reviews": 0,
  "start": 269.94,
  "end": 279.1
 },
 {
  "input": "These are the ones which leave all the basis vectors perpendicular to each other with unit lengths. ",
  "translatedText": "Questi sono quelli che lasciano tutti i vettori base perpendicolari tra loro con lunghezze unitarie. ",
  "n_reviews": 0,
  "start": 279.72,
  "end": 284.66
 },
 {
  "input": "You often think of these as rotation matrices. ",
  "translatedText": "Spesso si pensa a queste come a matrici di rotazione. ",
  "n_reviews": 0,
  "start": 285.74,
  "end": 287.88
 },
 {
  "input": "The correspond to rigid motion, with no stretching, squishing or morphing. ",
  "translatedText": "Corrispondono al movimento rigido, senza allungamento, schiacciamento o morphing. ",
  "n_reviews": 0,
  "start": 288.42,
  "end": 292.2
 },
 {
  "input": "Solving a linear system with an orthonormal matrix is very easy: Since dot products are preserved, taking the dot product between the output vector and all the columns of your matrix will be the same as taking the dot products between the input vector and all the basis vectors, which is the same as finding the coordinates of the input vector. ",
  "translatedText": "Risolvere un sistema lineare con una matrice ortonormale è molto semplice: poiché i prodotti scalari vengono preservati, prendere il prodotto scalare tra il vettore di output e tutte le colonne della matrice sarà come prendere i prodotti scalari tra il vettore di input e tutte le basi vettori, che equivale a trovare le coordinate del vettore di input. ",
  "n_reviews": 0,
  "start": 293.0,
  "end": 312.98
 },
 {
  "input": "So, in that very special case, x would be the dot product of the first column with the output vector, and y would be the dot product of the second column with the output vector. ",
  "translatedText": "Quindi, in quel caso molto speciale, x sarebbe il prodotto scalare della prima colonna con il vettore di output e y sarebbe il prodotto scalare della seconda colonna con il vettore di output. ",
  "n_reviews": 0,
  "start": 313.68,
  "end": 323.76
 },
 {
  "input": "Now, even though this idea breaks down for most linear systems, it points us in the direction of something to look for: Is there an alternate geometric understanding for the coordinates of our input vector which remains unchanged after the transformation? ",
  "translatedText": "Ora, anche se questa idea non funziona per la maggior parte dei sistemi lineari, ci indica la direzione di qualcosa da cercare: esiste una comprensione geometrica alternativa per le coordinate del nostro vettore di input che rimane invariata dopo la trasformazione? ",
  "n_reviews": 0,
  "start": 326.82,
  "end": 341.66
 },
 {
  "input": "If your mind has been mulling over determinants, you might think of this clever idea: Take the parallelogram defined by the first basis vector, i-hat, and the mystery input vector [x; y]. ",
  "translatedText": "Se la tua mente ha riflettuto sui determinanti, potresti pensare a questa idea intelligente: prendi il parallelogramma definito dal primo vettore base, i-hat, e dal misterioso vettore di input [x; y]. ",
  "n_reviews": 0,
  "start": 342.36,
  "end": 353.76
 },
 {
  "input": "The area of this parallelogram is its base, 1, times the height perpendicular to that base, which is the y-coordinate of our input vector. ",
  "translatedText": "L'area di questo parallelogramma è la sua base, 1, moltiplicata per l'altezza perpendicolare a quella base, che è la coordinata y del nostro vettore di input. ",
  "n_reviews": 0,
  "start": 354.44,
  "end": 362.96
 },
 {
  "input": "So, the area of this parallelogram is sort of a screwy roundabout way to describe the vector’s y-coordinate; it’s a wacky way to talk about coordinates, but run with me. ",
  "translatedText": "Quindi, l'area di questo parallelogramma è una specie di modo intricato per descrivere la coordinata y del vettore; è un modo stravagante di parlare di coordinate, ma corri con me. ",
  "n_reviews": 0,
  "start": 363.68,
  "end": 373.14
 },
 {
  "input": "Actually, to be more accurate, you should think of the signed area of this parallelogram, in the sense described by the determinant video. ",
  "translatedText": "In realtà, per essere più precisi, dovresti pensare all'area con segno di questo parallelogramma, nel senso descritto dal video determinante. ",
  "n_reviews": 0,
  "start": 373.7,
  "end": 381.64
 },
 {
  "input": "That way, a vector with negative y-coordinate would correspond to a negative area for this parallelogram. ",
  "translatedText": "In questo modo, un vettore con coordinata y negativa corrisponderebbe ad un'area negativa per questo parallelogramma. ",
  "n_reviews": 0,
  "start": 382.2,
  "end": 388.58
 },
 {
  "input": "Symmetrically, if you look at the parallelogram spanned by the vector and the second basis vector, j-hat, its area will be the x-coordinate of the vector. ",
  "translatedText": "Simmetricamente, se guardi il parallelogramma formato dal vettore e dal secondo vettore base, j-hat, la sua area sarà la coordinata x del vettore. ",
  "n_reviews": 0,
  "start": 388.96,
  "end": 392.96
 },
 {
  "input": "Again, it’s a strange way to represent the x-coordinate, but you’ll see what it buys us in a moment. ",
  "translatedText": "Ancora una volta, è un modo strano di rappresentare la coordinata x, ma vedrai cosa ci offre tra un attimo. ",
  "n_reviews": 0,
  "start": 392.96,
  "end": 398.78
 },
 {
  "input": "Here’s what this would look like in three-dimensions: Ordinarily the way you might think of one of a vector’s coordinate, say its z-coordinate, would be to take its dot product with the third standard basis vector, k-hat. ",
  "translatedText": "Ecco come apparirebbe in tre dimensioni: normalmente il modo in cui potresti pensare a una delle coordinate di un vettore, diciamo la sua coordinata z, sarebbe quello di prendere il suo prodotto scalare con il terzo vettore di base standard, k-hat. ",
  "n_reviews": 0,
  "start": 398.78,
  "end": 410.08
 },
 {
  "input": "But instead, consider the parallelepiped it creates with the other two basis vectors, i-hat and j-hat. ",
  "translatedText": "Consideriamo invece il parallelepipedo che crea con gli altri due vettori base, i-hat e j-hat. ",
  "n_reviews": 0,
  "start": 410.68,
  "end": 412.64
 },
 {
  "input": "If you think of the square with area 1 spanned by i-hat and j-hat as the base of this guy, its volume is the same its height, which is the third coordinate of our vector. ",
  "translatedText": "Se pensi al quadrato con area 1 attraversata da i-hat e j-hat come base di questo ragazzo, il suo volume è uguale alla sua altezza, che è la terza coordinata del nostro vettore. ",
  "n_reviews": 0,
  "start": 412.74,
  "end": 417.14
 },
 {
  "input": "Likewise, the wacky way to think about any other coordinate of this vector is to form the parallelepiped between this vector an all the basis vectors other than the one you’re looking for, and get its volume. ",
  "translatedText": "Allo stesso modo, il modo stravagante di pensare a qualsiasi altra coordinata di questo vettore è formare il parallelepipedo tra questo vettore e tutti i vettori base diversi da quello che stai cercando e ottenerne il volume. ",
  "n_reviews": 0,
  "start": 417.14,
  "end": 429.72
 },
 {
  "input": "Or, rather, we should talk about the signed volume of these parallelepipeds, in the sense described in the determinant video, where the order in which you list the three vectors matters and you’re using the right-hand rule. ",
  "translatedText": "O meglio, dovremmo parlare del volume con segno di questi parallelepipedi, nel senso descritto nel video delle determinanti, dove conta l'ordine in cui elenchi i tre vettori e usi la regola della mano destra. ",
  "n_reviews": 0,
  "start": 429.72,
  "end": 442.38
 },
 {
  "input": "That way negative coordinates still make sense. ",
  "translatedText": "In questo modo le coordinate negative hanno ancora senso. ",
  "n_reviews": 0,
  "start": 442.38,
  "end": 445.24
 },
 {
  "input": "Okay, so why think of coordinates as areas and volumes like this? ",
  "translatedText": "Ok, allora perché pensare alle coordinate come ad aree e volumi in questo modo? ",
  "n_reviews": 0,
  "start": 445.24,
  "end": 447.5
 },
 {
  "input": "As you apply some matrix transformation, the areas of the parallelograms don’t stay the same, they may get scaled up or down. ",
  "translatedText": "Quando applichi una trasformazione della matrice, le aree dei parallelogrammi non rimangono le stesse, potrebbero essere ingrandite o ridotte. ",
  "n_reviews": 0,
  "start": 447.5,
  "end": 450.0
 },
 {
  "input": "But(!), and this is a key idea of determinants, all these areas get scaled by the same amount. ",
  "translatedText": "Ma (!), e questa è un’idea chiave dei determinanti, tutte queste aree vengono ridimensionate nella stessa misura. ",
  "n_reviews": 0,
  "start": 450.0,
  "end": 453.96
 },
 {
  "input": "Namely, the determinant of our transformation matrix. ",
  "translatedText": "Vale a dire, il determinante della nostra matrice di trasformazione. ",
  "n_reviews": 0,
  "start": 453.96,
  "end": 457.9
 },
 {
  "input": "For example, if you look the parallelogram spanned by the vector where your first basis vector lands, which is the first column of the matrix, and the transformed version of [x; y], what is its area? ",
  "translatedText": "Ad esempio, se guardi il parallelogramma attraversato dal vettore in cui si trova il tuo primo vettore base, che è la prima colonna della matrice, e la versione trasformata di [x; y], qual è la sua area? ",
  "n_reviews": 0,
  "start": 458.44,
  "end": 470.72
 },
 {
  "input": "Well, this is the transformed version of that parallelogram we were looking at earlier, whose area was the y-coordinate of the mystery input vector. ",
  "translatedText": "Bene, questa è la versione trasformata del parallelogramma che stavamo guardando prima, la cui area era la coordinata y del misterioso vettore di input. ",
  "n_reviews": 0,
  "start": 470.72,
  "end": 478.28
 },
 {
  "input": "So its area will be the determinant of the transformation multiplied by that value. ",
  "translatedText": "Quindi la sua area sarà la determinante della trasformazione moltiplicata per quel valore. ",
  "n_reviews": 0,
  "start": 478.96,
  "end": 481.96
 },
 {
  "input": "So, the y-coordinate of our mystery input vector is the area of this parallelogram, spanned by the first column of the matrix and the output vector, divided by the determinant of the full transformation. ",
  "translatedText": "Quindi, la coordinata y del nostro misterioso vettore di input è l'area di questo parallelogramma, compresa tra la prima colonna della matrice e il vettore di output, divisa per il determinante della trasformazione completa. ",
  "n_reviews": 0,
  "start": 481.96,
  "end": 492.16
 },
 {
  "input": "And how do you get this area? ",
  "translatedText": "E come si ottiene quest'area? ",
  "n_reviews": 0,
  "start": 492.16,
  "end": 494.88
 },
 {
  "input": "Well, we know the coordinates for where the mystery input vector lands, that’s the whole point of a linear system of equations. ",
  "translatedText": "Bene, conosciamo le coordinate di dove si ferma il misterioso vettore di input, questo è il punto centrale di un sistema lineare di equazioni. ",
  "n_reviews": 0,
  "start": 494.88,
  "end": 499.88
 },
 {
  "input": "So, create a matrix whose first column is the same as that of our matrix, and whose second column is the output vector, and take its determinant. ",
  "translatedText": "Quindi, crea una matrice la cui prima colonna è la stessa della nostra matrice e la cui seconda colonna è il vettore di output e prendi il suo determinante. ",
  "n_reviews": 0,
  "start": 499.88,
  "end": 512.88
 },
 {
  "input": "So look at that; just using data from the output of the transformation, namely the columns of the matrix and the coordinates of our output vector, we can recover the y-coordinate of our mystery input vector. ",
  "translatedText": "Quindi guardalo; semplicemente utilizzando i dati dell'output della trasformazione, vale a dire le colonne della matrice e le coordinate del nostro vettore di output, possiamo recuperare la coordinata y del nostro misterioso vettore di input. ",
  "n_reviews": 0,
  "start": 512.88,
  "end": 522.1
 },
 {
  "input": "Likewise, the same idea can get you the x-coordinate. ",
  "translatedText": "Allo stesso modo, la stessa idea può darti la coordinata x. ",
  "n_reviews": 0,
  "start": 522.1,
  "end": 523.5
 },
 {
  "input": "Look at that parallelogram we defined early which encodes the x-coordinate of the mystery input vector, spanned by the input vector and j-hat. ",
  "translatedText": "Guarda quel parallelogramma che abbiamo definito in precedenza che codifica la coordinata x del misterioso vettore di input, attraversato dal vettore di input e dal j-hat. ",
  "n_reviews": 0,
  "start": 523.5,
  "end": 537.14
 },
 {
  "input": "The transformed version of this guy is spanned by the output vector and the second column of the matrix, and its area will have been multiplied by the determinant of the matrix. ",
  "translatedText": "La versione trasformata di questo tipo è estesa dal vettore di output e dalla seconda colonna della matrice, e la sua area sarà stata moltiplicata per il determinante della matrice. ",
  "n_reviews": 0,
  "start": 537.14,
  "end": 545.04
 },
 {
  "input": "So the x-coordinate of our mystery input vector is this area divided by the determinant of the transformation. ",
  "translatedText": "Quindi la coordinata x del nostro misterioso vettore di input è quest'area divisa per il determinante della trasformazione. ",
  "n_reviews": 0,
  "start": 545.06,
  "end": 555.14
 },
 {
  "input": "Symmetric to what we did before, you can compute the area of that output parallelogram by creating a new matrix whose first column is the output vector, and whose second column is the same as the original matrix. ",
  "translatedText": "Simmetrico a quanto fatto prima, puoi calcolare l'area del parallelogramma di output creando una nuova matrice la cui prima colonna è il vettore di output e la cui seconda colonna è uguale alla matrice originale. ",
  "n_reviews": 0,
  "start": 555.6,
  "end": 563.42
 },
 {
  "input": "So again, just using data from the output space, the numbers we see in our original linear system, we can recover the x-coordinate of our mystery input vector. ",
  "translatedText": "Quindi, ancora una volta, usando solo i dati dallo spazio di output, i numeri che vediamo nel nostro sistema lineare originale, possiamo recuperare la coordinata x del nostro misterioso vettore di input. ",
  "n_reviews": 0,
  "start": 563.42,
  "end": 573.42
 },
 {
  "input": "This formula for finding the solutions to a linear system of equations is known as Cramer’s rule. ",
  "translatedText": "Questa formula per trovare le soluzioni di un sistema lineare di equazioni è nota come regola di Cramer. ",
  "n_reviews": 0,
  "start": 573.42,
  "end": 584.48
 },
 {
  "input": "Here, just to sanity check ourselves, plug in the numbers here. ",
  "translatedText": "Ecco, solo per controllarci, inserisci i numeri qui. ",
  "n_reviews": 0,
  "start": 584.48,
  "end": 585.34
 },
 {
  "input": "The determinant of that top altered matrix is 4+2, which is 6, and the bottom determinant is 2, so the x-coordinate should be 3. ",
  "translatedText": "Il determinante della matrice alterata in alto è 4+2, che è 6, e il determinante inferiore è 2, quindi la coordinata x dovrebbe essere 3. ",
  "n_reviews": 0,
  "start": 585.34,
  "end": 592.94
 },
 {
  "input": "And indeed, looking back at that input vector we started with, it’s x-coordinate is 3. ",
  "translatedText": "E infatti, guardando indietro al vettore di input con cui abbiamo iniziato, la sua coordinata x è 3. ",
  "n_reviews": 0,
  "start": 593.86,
  "end": 604.34
 },
 {
  "input": "Likewise, Cramer’s rule suggests the y-coordinate should be 4/2, or 2, and that is indeed the y-coordinate of the input vector we started with here. ",
  "translatedText": "Allo stesso modo, la regola di Cramer suggerisce che la coordinata y dovrebbe essere 4/2, o 2, e questa è infatti la coordinata y del vettore di input con cui abbiamo iniziato qui. ",
  "n_reviews": 0,
  "start": 604.34,
  "end": 607.72
 },
 {
  "input": "The case with three dimensions is similar, and I highly recommend you pause to think it through yourself. ",
  "translatedText": "Il caso delle tre dimensioni è simile e ti consiglio vivamente di fermarti a pensarci da solo. ",
  "n_reviews": 0,
  "start": 607.72,
  "end": 618.42
 },
 {
  "input": "Here, I’ll give you a little momentum. ",
  "translatedText": "Ecco, ti do un piccolo slancio. ",
  "n_reviews": 0,
  "start": 619.12,
  "end": 621.58
 },
 {
  "input": "We have this known transformation, given by a 3x3 matrix, and a known output vector, given by the right side of our linear system, and we want to know what input vector lands on this output vector. ",
  "translatedText": "Abbiamo questa trasformazione nota, data da una matrice 3x3, e un vettore di output noto, dato dal lato destro del nostro sistema lineare, e vogliamo sapere quale vettore di input si ferma su questo vettore di output. ",
  "n_reviews": 0,
  "start": 621.58,
  "end": 633.26
 },
 {
  "input": "If you think of, say, the z-coordinate of the input vector as the volume of this parallelepiped spanned by i-hat, j-hat, and the mystery input vector, what happens to the volume of this parallelepiped after the transformation? ",
  "translatedText": "Se pensi, ad esempio, alla coordinata z del vettore di input come al volume di questo parallelepipedo attraversato da i-hat, j-hat e dal misterioso vettore di input, cosa succede al volume di questo parallelepipedo dopo la trasformazione? ",
  "n_reviews": 0,
  "start": 633.26,
  "end": 644.64
 },
 {
  "input": "How can you compute that new volume? ",
  "translatedText": "Come puoi calcolare quel nuovo volume? ",
  "n_reviews": 0,
  "start": 644.64,
  "end": 651.66
 },
 {
  "input": "Really, pause and take a moment to think through the details of generalizing this to higher dimensions; finding an expression for each coordinate of the solution to larger linear systems. ",
  "translatedText": "Davvero, fermatevi e prendetevi un momento per pensare ai dettagli di generalizzare questo a dimensioni superiori; trovare un'espressione per ciascuna coordinata della soluzione a sistemi lineari più grandi. ",
  "n_reviews": 0,
  "start": 651.66,
  "end": 664.68
 },
 {
  "input": "Thinking through more general cases and convincing yourself that it works is where all the learning will happen, much more so than listening to some dude on YouTube walk through the reasoning again. ",
  "translatedText": "Pensare a casi più generali e convincersi che funziona è il luogo in cui avverrà tutto l'apprendimento, molto più che ascoltare qualche tizio su YouTube che ripercorre il ragionamento. ",
  "n_reviews": 0,
  "start": 665.1,
  "end": 708.5
 }
]