[
 {
  "translatedText": "In un video precedente, ho parlato di sistemi lineari di equazioni e ho in un certo senso messo da parte la discussione sulle soluzioni effettivamente computazionali per questi sistemi. ",
  "input": "In a previous video, I’ve talked about linear systems of equations, and I sort of brushed aside the discussion of actually computing solutions to these systems. ",
  "time_range": [
   11.59,
   19.69
  ]
 },
 {
  "translatedText": "E anche se è vero che l&#39;elaborazione dei numeri è qualcosa che di solito lasciamo ai computer, scavare in alcuni di questi metodi computazionali è un buon test del nove per capire se si capisce davvero cosa sta succedendo, dal momento che è proprio qui che la gomma incontra la strada. . ",
  "input": "And while it’s true that number-crunching is something we typically leave to the computers, digging into some of these computational methods is a good litmus test for whether or not you actually understand what’s going on, since this is really where the rubber meets the road. ",
  "time_range": [
   19.69,
   32.68
  ]
 },
 {
  "translatedText": "Qui voglio descrivere la geometria dietro un certo metodo per calcolare le soluzioni a questi sistemi, noto come regola di Cramer. ",
  "input": "Here I want to describe the geometry behind a certain method for computing solutions to these systems, known as Cramer’s rule. ",
  "time_range": [
   32.68,
   39.76
  ]
 },
 {
  "translatedText": "Il background pertinente necessario qui è la comprensione dei determinanti, dei prodotti scalari e dei sistemi lineari di equazioni, quindi assicurati di guardare i video pertinenti su questi argomenti se non hai familiarità o sei arrugginito. ",
  "input": "The relevant background needed here is an understanding of determinants, dot products, and of linear systems of equations, so be sure to watch the relevant videos on those topics if you’re unfamiliar or rusty. ",
  "time_range": [
   39.76,
   50.489
  ]
 },
 {
  "translatedText": "Ma prima! ",
  "input": "But first! ",
  "time_range": [
   50.489,
   51.489
  ]
 },
 {
  "translatedText": "Dovrei dire subito che la regola di Cramer non è il modo migliore per calcolare soluzioni a sistemi lineari di equazioni. ",
  "input": "I should say up front that Cramer’s rule is not the best way for computing solutions to linear systems of equations. ",
  "time_range": [
   51.489,
   58.01
  ]
 },
 {
  "translatedText": "L’eliminazione gaussiana, ad esempio, sarà sempre più veloce. ",
  "input": "Gaussian elimination, for example, will always be faster. ",
  "time_range": [
   58.01,
   61.95
  ]
 },
 {
  "translatedText": "Allora perché impararlo? ",
  "input": "So why learn it? ",
  "time_range": [
   61.95,
   63.95
  ]
 },
 {
  "translatedText": "Consideratela una sorta di escursione culturale; è un esercizio utile per approfondire la conoscenza della teoria di questi sistemi. ",
  "input": "Think of this as a sort of cultural excursion; it’s a helpful exercise in deepening your knowledge of the theory of these systems. ",
  "time_range": [
   63.95,
   70.52
  ]
 },
 {
  "translatedText": "Comprendere questo concetto ti aiuterà a consolidare le idee dell&#39;algebra lineare, come il determinante e i sistemi lineari, vedendo come si relazionano tra loro. ",
  "input": "Wrapping your mind around this concept will help consolidate ideas from linear algebra, like the determinant and linear systems, by seeing how they relate to each other. ",
  "time_range": [
   70.52,
   79.96
  ]
 },
 {
  "translatedText": "Inoltre, da un punto di vista puramente artistico, il risultato finale è davvero carino da pensare, tanto più che l&#39;eliminazione gaussiana. ",
  "input": "Also, from a purely artistic standpoint, the ultimate result is just really pretty to think about, much more so that Gaussian elimination. ",
  "time_range": [
   79.96,
   88.34
  ]
 },
 {
  "translatedText": "Va bene, quindi la configurazione qui sarà un sistema lineare di equazioni, diciamo con due incognite, xey, e due equazioni. ",
  "input": "Alright, so the setup here will be some linear system of equations, say with two unknowns, x and y, and two equations. ",
  "time_range": [
   88.34,
   95.99
  ]
 },
 {
  "translatedText": "In linea di principio, tutto ciò di cui stiamo parlando funzionerà con sistemi con un numero maggiore di incognite e lo stesso numero di equazioni. ",
  "input": "In principle, everything we’re talking about will work systems with a larger number of unknowns, and the same number of equations. ",
  "time_range": [
   95.99,
   101.84
  ]
 },
 {
  "translatedText": "Ma per semplicità, è più bello tenere in testa un esempio più piccolo. ",
  "input": "But for simplicity, a smaller example is nicer to hold in our heads. ",
  "time_range": [
   101.84,
   106.349
  ]
 },
 {
  "translatedText": "Quindi, come ho detto in un video precedente, puoi pensare a questa configurazione geometricamente come una certa matrice conosciuta che trasforma un vettore sconosciuto, [x; y], dove sai quale sarà l&#39;output, in questo caso [-4; -2]. ",
  "input": "So as I talked about in a previous video, you can think of this setup geometrically as a certain known matrix transforming an unknown vector, [x; y], where you know what the output is going to be, in this case [-4; -2]. ",
  "time_range": [
   106.349,
   120.42
  ]
 },
 {
  "translatedText": "Ricorda, le colonne di questa matrice ti dicono come la matrice agisce come una trasformazione, ognuna delle quali ti dice dove si fermano i vettori di base dello spazio di input. ",
  "input": "Remember, the columns of this matrix tell you how the matrix acts as a transform, each one telling you where the basis vectors of the input space land. ",
  "time_range": [
   120.42,
   130.899
  ]
 },
 {
  "translatedText": "Quindi questo è una sorta di puzzle, quale input [x; y], ti darà questo output [-4; -2]? ",
  "input": "So this is a sort of puzzle, what input [x; y], is going to give you this output [-4; -2]? ",
  "time_range": [
   130.899,
   148.15
  ]
 },
 {
  "translatedText": "Ricorda, il tipo di risposta che ottieni qui può dipendere dal fatto che la trasformazione schiacci o meno tutto lo spazio in una dimensione inferiore. ",
  "input": "Remember, the type of answer you get here can depend on whether or not the transformation squishes all of space into a lower dimension. ",
  "time_range": [
   148.15,
   164.299
  ]
 },
 {
  "translatedText": "Questo se ha determinante zero. ",
  "input": "That is if it has zero determinant. ",
  "time_range": [
   164.299,
   166.08
  ]
 },
 {
  "translatedText": "In tal caso, o nessuno degli input arriva al nostro dato output oppure ci sono un sacco di input che arrivano a quell&#39;output. ",
  "input": "In that case, either none of the inputs land on our given output or there are a whole bunch of inputs landing on that output. ",
  "time_range": [
   166.08,
   177.54
  ]
 },
 {
  "translatedText": "Ma per questo video limiteremo la nostra visione al caso di un determinante diverso da zero, il che significa che l&#39;output di questa trasformazione si estende ancora nell&#39;intero spazio n-dimensionale in cui è iniziata; ogni input finisce su uno e un solo output e ogni output ha uno e un solo input. ",
  "input": "But for this video we’ll limit our view to the case of a non-zero determinant, meaning the output of this transformation still spans the full n-dimensional space it started in; every input lands on one and only one output and every output has one and only one input. ",
  "time_range": [
   177.54,
   192.549
  ]
 },
 {
  "translatedText": "Un modo di pensare al nostro puzzle è che sappiamo che il vettore di output dato è una combinazione lineare delle colonne della matrice; x*(il vettore dove si ferma i-hat) + y*(il vettore dove si ferma j-hat), ma vogliamo calcolare cosa sono esattamente xey. ",
  "input": "One way to think about our puzzle is that we know the given output vector is some linear combination of the columns of the matrix; x*(the vector where i-hat lands) + y*(the vector where j-hat lands), but we wish to compute what exactly x and y are. ",
  "time_range": [
   192.549,
   196.84
  ]
 },
 {
  "translatedText": "Come primo passo, lasciatemi mostrare un&#39;idea sbagliata, ma nella giusta direzione. ",
  "input": "As a first pass, let me show an idea that is wrong, but in the right direction. ",
  "time_range": [
   196.84,
   198.829
  ]
 },
 {
  "translatedText": "La coordinata x di questo misterioso vettore di input è quella che ottieni prendendo il suo prodotto scalare con il primo vettore base, [1; 0]. ",
  "input": "The x-coordinate of this mystery input vector is what you get by taking its dot product with the first basis vector, [1; 0]. ",
  "time_range": [
   198.829,
   205.939
  ]
 },
 {
  "translatedText": "Allo stesso modo, la coordinata y è ciò che si ottiene punteggiandola con il secondo vettore base, [0; 1]. ",
  "input": "Likewise, the y-coordinate is what you get by dotting it with the second basis vector, [0; 1]. ",
  "time_range": [
   205.939,
   211.98
  ]
 },
 {
  "translatedText": "Quindi forse speri che dopo la trasformazione, i prodotti scalari con la versione trasformata del vettore misterioso con le versioni trasformate dei vettori base siano anch&#39;essi queste coordinate xey. ",
  "input": "So maybe you hope that after the transformation, the dot products with the transformed version of the mystery vector with the transformed versions of the basis vectors will also be these coordinates x and y. ",
  "time_range": [
   211.98,
   223.59
  ]
 },
 {
  "translatedText": "Sarebbe fantastico perché conosciamo le versioni trasformate di ciascuno di questi vettori. ",
  "input": "That’d be fantastic because we know the transformed versions of each of these vectors. ",
  "time_range": [
   223.59,
   230.4
  ]
 },
 {
  "translatedText": "C&#39;è solo un problema: non è affatto vero! ",
  "input": "There’s just one problem with this: it’s not at all true! ",
  "time_range": [
   230.4,
   234.739
  ]
 },
 {
  "translatedText": "Per la maggior parte delle trasformazioni lineari, il prodotto scalare prima e dopo la trasformazione sarà molto diverso. ",
  "input": "For most linear transformations, the dot product before and after the transformation will be very different. ",
  "time_range": [
   234.739,
   240.84
  ]
 },
 {
  "translatedText": "Ad esempio, potresti avere due vettori che puntano generalmente nella stessa direzione, con un prodotto scalare positivo, che vengono allontanati l&#39;uno dall&#39;altro durante la trasformazione, in modo tale da avere poi un prodotto scalare negativo. ",
  "input": "For example, you could have two vectors generally pointing in the same direction, with a positive dot product, which get pulled away from each other during the transformation, in such a way that they then have a negative dot product. ",
  "time_range": [
   240.84,
   251.909
  ]
 },
 {
  "translatedText": "Allo stesso modo, se le cose iniziano perpendicolari, con prodotto scalare zero, come i due vettori di base, non c&#39;è garanzia che rimarranno perpendicolari dopo la trasformazione, preservando quel prodotto scalare zero. ",
  "input": "Likewise, if things start off perpendicular, with dot product zero, like the two basis vectors, there’s no guarantee that they will stay perpendicular after the transformation, preserving that zero dot product. ",
  "time_range": [
   251.909,
   264.05
  ]
 },
 {
  "translatedText": "Nell&#39;esempio che stavamo guardando, i prodotti scalari non vengono certamente preservati. ",
  "input": "In the example we were looking at, dot products certainly aren’t preserved. ",
  "time_range": [
   264.05,
   267.14
  ]
 },
 {
  "translatedText": "Tendono a diventare più grandi poiché la maggior parte dei vettori viene allungata. ",
  "input": "They tend to get bigger since most vectors are getting stretched. ",
  "time_range": [
   267.14,
   270.95
  ]
 },
 {
  "translatedText": "In effetti, le trasformazioni che preservano i prodotti scalari sono abbastanza speciali da avere un nome proprio: trasformazioni ortonormali. ",
  "input": "In fact, transformations which do preserve dot products are special enough to have their own name: Orthonormal transformations. ",
  "time_range": [
   270.95,
   279.8
  ]
 },
 {
  "translatedText": "Questi sono quelli che lasciano tutti i vettori base perpendicolari tra loro con lunghezze unitarie. ",
  "input": "These are the ones which leave all the basis vectors perpendicular to each other with unit lengths. ",
  "time_range": [
   279.8,
   285.81
  ]
 },
 {
  "translatedText": "Spesso si pensa a queste come a matrici di rotazione. ",
  "input": "You often think of these as rotation matrices. ",
  "time_range": [
   285.81,
   288.47
  ]
 },
 {
  "translatedText": "Corrispondono al movimento rigido, senza allungamento, schiacciamento o morphing. ",
  "input": "The correspond to rigid motion, with no stretching, squishing or morphing. ",
  "time_range": [
   288.47,
   293.0
  ]
 },
 {
  "translatedText": "Risolvere un sistema lineare con una matrice ortonormale è molto semplice: poiché i prodotti scalari vengono preservati, prendere il prodotto scalare tra il vettore di output e tutte le colonne della matrice sarà come prendere i prodotti scalari tra il vettore di input e tutte le basi vettori, che equivale a trovare le coordinate del vettore di input. ",
  "input": "Solving a linear system with an orthonormal matrix is very easy: Since dot products are preserved, taking the dot product between the output vector and all the columns of your matrix will be the same as taking the dot products between the input vector and all the basis vectors, which is the same as finding the coordinates of the input vector. ",
  "time_range": [
   293.0,
   313.599
  ]
 },
 {
  "translatedText": "Quindi, in quel caso molto speciale, x sarebbe il prodotto scalare della prima colonna con il vettore di output e y sarebbe il prodotto scalare della seconda colonna con il vettore di output. ",
  "input": "So, in that very special case, x would be the dot product of the first column with the output vector, and y would be the dot product of the second column with the output vector. ",
  "time_range": [
   313.599,
   324.58
  ]
 },
 {
  "translatedText": "Ora, anche se questa idea non funziona per la maggior parte dei sistemi lineari, ci indica la direzione di qualcosa da cercare: esiste una comprensione geometrica alternativa per le coordinate del nostro vettore di input che rimane invariata dopo la trasformazione? ",
  "input": "Now, even though this idea breaks down for most linear systems, it points us in the direction of something to look for: Is there an alternate geometric understanding for the coordinates of our input vector which remains unchanged after the transformation? ",
  "time_range": [
   324.58,
   342.78
  ]
 },
 {
  "translatedText": "Se la tua mente ha riflettuto sui determinanti, potresti pensare a questa idea intelligente: prendi il parallelogramma definito dal primo vettore base, i-hat, e dal misterioso vettore di input [x; y]. ",
  "input": "If your mind has been mulling over determinants, you might think of this clever idea: Take the parallelogram defined by the first basis vector, i-hat, and the mystery input vector [x; y]. ",
  "time_range": [
   342.78,
   354.59
  ]
 },
 {
  "translatedText": "L&#39;area di questo parallelogramma è la sua base, 1, moltiplicata per l&#39;altezza perpendicolare a quella base, che è la coordinata y del nostro vettore di input. ",
  "input": "The area of this parallelogram is its base, 1, times the height perpendicular to that base, which is the y-coordinate of our input vector. ",
  "time_range": [
   354.59,
   363.46
  ]
 },
 {
  "translatedText": "Quindi, l&#39;area di questo parallelogramma è una specie di modo intricato per descrivere la coordinata y del vettore; è un modo stravagante di parlare di coordinate, ma corri con me. ",
  "input": "So, the area of this parallelogram is sort of a screwy roundabout way to describe the vector’s y-coordinate; it’s a wacky way to talk about coordinates, but run with me. ",
  "time_range": [
   363.46,
   373.59
  ]
 },
 {
  "translatedText": "In realtà, per essere più precisi, dovresti pensare all&#39;area con segno di questo parallelogramma, nel senso descritto dal video determinante. ",
  "input": "Actually, to be more accurate, you should think of the signed area of this parallelogram, in the sense described by the determinant video. ",
  "time_range": [
   373.59,
   382.44
  ]
 },
 {
  "translatedText": "In questo modo, un vettore con coordinata y negativa corrisponderebbe ad un&#39;area negativa per questo parallelogramma. ",
  "input": "That way, a vector with negative y-coordinate would correspond to a negative area for this parallelogram. ",
  "time_range": [
   382.44,
   389.11
  ]
 },
 {
  "translatedText": "Simmetricamente, se guardi il parallelogramma formato dal vettore e dal secondo vettore base, j-hat, la sua area sarà la coordinata x del vettore. ",
  "input": "Symmetrically, if you look at the parallelogram spanned by the vector and the second basis vector, j-hat, its area will be the x-coordinate of the vector. ",
  "time_range": [
   389.11,
   405.099
  ]
 },
 {
  "translatedText": "Ancora una volta, è un modo strano di rappresentare la coordinata x, ma vedrai cosa ci offre tra un attimo. ",
  "input": "Again, it’s a strange way to represent the x-coordinate, but you’ll see what it buys us in a moment. ",
  "time_range": [
   405.099,
   410.449
  ]
 },
 {
  "translatedText": "Ecco come apparirebbe in tre dimensioni: normalmente il modo in cui potresti pensare a una delle coordinate di un vettore, diciamo la sua coordinata z, sarebbe quello di prendere il suo prodotto scalare con il terzo vettore di base standard, k-hat. ",
  "input": "Here’s what this would look like in three-dimensions: Ordinarily the way you might think of one of a vector’s coordinate, say its z-coordinate, would be to take its dot product with the third standard basis vector, k-hat. ",
  "time_range": [
   410.449,
   424.439
  ]
 },
 {
  "translatedText": "Consideriamo invece il parallelepipedo che crea con gli altri due vettori base, i-hat e j-hat. ",
  "input": "But instead, consider the parallelepiped it creates with the other two basis vectors, i-hat and j-hat. ",
  "time_range": [
   424.439,
   433.569
  ]
 },
 {
  "translatedText": "Se pensi al quadrato con area 1 attraversata da i-hat e j-hat come base di questo ragazzo, il suo volume è uguale alla sua altezza, che è la terza coordinata del nostro vettore. ",
  "input": "If you think of the square with area 1 spanned by i-hat and j-hat as the base of this guy, its volume is the same its height, which is the third coordinate of our vector. ",
  "time_range": [
   433.569,
   444.259
  ]
 },
 {
  "translatedText": "Allo stesso modo, il modo stravagante di pensare a qualsiasi altra coordinata di questo vettore è formare il parallelepipedo tra questo vettore e tutti i vettori base diversi da quello che stai cercando e ottenerne il volume. ",
  "input": "Likewise, the wacky way to think about any other coordinate of this vector is to form the parallelepiped between this vector an all the basis vectors other than the one you’re looking for, and get its volume. ",
  "time_range": [
   444.259,
   457.9
  ]
 },
 {
  "translatedText": "O meglio, dovremmo parlare del volume con segno di questi parallelepipedi, nel senso descritto nel video delle determinanti, dove conta l&#39;ordine in cui elenchi i tre vettori e usi la regola della mano destra. ",
  "input": "Or, rather, we should talk about the signed volume of these parallelepipeds, in the sense described in the determinant video, where the order in which you list the three vectors matters and you’re using the right-hand rule. ",
  "time_range": [
   457.9,
   468.9
  ]
 },
 {
  "translatedText": "In questo modo le coordinate negative hanno ancora senso. ",
  "input": "That way negative coordinates still make sense. ",
  "time_range": [
   468.9,
   471.61
  ]
 },
 {
  "translatedText": "Ok, allora perché pensare alle coordinate come ad aree e volumi in questo modo? ",
  "input": "Okay, so why think of coordinates as areas and volumes like this? ",
  "time_range": [
   471.61,
   476.0
  ]
 },
 {
  "translatedText": "Quando applichi una trasformazione della matrice, le aree dei parallelogrammi non rimangono le stesse, potrebbero essere ingrandite o ridotte. ",
  "input": "As you apply some matrix transformation, the areas of the parallelograms don’t stay the same, they may get scaled up or down. ",
  "time_range": [
   476.0,
   484.129
  ]
 },
 {
  "translatedText": "Ma (!), e questa è un’idea chiave dei determinanti, tutte queste aree vengono ridimensionate nella stessa misura. ",
  "input": "But(!), and this is a key idea of determinants, all these areas get scaled by the same amount. ",
  "time_range": [
   484.129,
   489.94
  ]
 },
 {
  "translatedText": "Vale a dire, il determinante della nostra matrice di trasformazione. ",
  "input": "Namely, the determinant of our transformation matrix. ",
  "time_range": [
   489.94,
   493.56
  ]
 },
 {
  "translatedText": "Ad esempio, se guardi il parallelogramma attraversato dal vettore in cui si trova il tuo primo vettore base, che è la prima colonna della matrice, e la versione trasformata di [x; y], qual è la sua area? ",
  "input": "For example, if you look the parallelogram spanned by the vector where your first basis vector lands, which is the first column of the matrix, and the transformed version of [x; y], what is its area? ",
  "time_range": [
   493.56,
   505.18
  ]
 },
 {
  "translatedText": "Bene, questa è la versione trasformata del parallelogramma che stavamo guardando prima, la cui area era la coordinata y del misterioso vettore di input. ",
  "input": "Well, this is the transformed version of that parallelogram we were looking at earlier, whose area was the y-coordinate of the mystery input vector. ",
  "time_range": [
   505.18,
   513.95
  ]
 },
 {
  "translatedText": "Quindi la sua area sarà la determinante della trasformazione moltiplicata per quel valore. ",
  "input": "So its area will be the determinant of the transformation multiplied by that value. ",
  "time_range": [
   513.95,
   519.08
  ]
 },
 {
  "translatedText": "Quindi, la coordinata y del nostro misterioso vettore di input è l&#39;area di questo parallelogramma, compresa tra la prima colonna della matrice e il vettore di output, divisa per il determinante della trasformazione completa. ",
  "input": "So, the y-coordinate of our mystery input vector is the area of this parallelogram, spanned by the first column of the matrix and the output vector, divided by the determinant of the full transformation. ",
  "time_range": [
   519.08,
   531.12
  ]
 },
 {
  "translatedText": "E come si ottiene quest&#39;area? ",
  "input": "And how do you get this area? ",
  "time_range": [
   531.12,
   533.09
  ]
 },
 {
  "translatedText": "Bene, conosciamo le coordinate di dove si ferma il misterioso vettore di input, questo è il punto centrale di un sistema lineare di equazioni. ",
  "input": "Well, we know the coordinates for where the mystery input vector lands, that’s the whole point of a linear system of equations. ",
  "time_range": [
   533.09,
   539.85
  ]
 },
 {
  "translatedText": "Quindi, crea una matrice la cui prima colonna è la stessa della nostra matrice e la cui seconda colonna è il vettore di output e prendi il suo determinante. ",
  "input": "So, create a matrix whose first column is the same as that of our matrix, and whose second column is the output vector, and take its determinant. ",
  "time_range": [
   539.85,
   551.25
  ]
 },
 {
  "translatedText": "Quindi guardalo; semplicemente utilizzando i dati dell&#39;output della trasformazione, vale a dire le colonne della matrice e le coordinate del nostro vettore di output, possiamo recuperare la coordinata y del nostro misterioso vettore di input. ",
  "input": "So look at that; just using data from the output of the transformation, namely the columns of the matrix and the coordinates of our output vector, we can recover the y-coordinate of our mystery input vector. ",
  "time_range": [
   551.25,
   563.88
  ]
 },
 {
  "translatedText": "Allo stesso modo, la stessa idea può darti la coordinata x. ",
  "input": "Likewise, the same idea can get you the x-coordinate. ",
  "time_range": [
   563.88,
   568.1
  ]
 },
 {
  "translatedText": "Guarda quel parallelogramma che abbiamo definito in precedenza che codifica la coordinata x del misterioso vettore di input, attraversato dal vettore di input e dal j-hat. ",
  "input": "Look at that parallelogram we defined early which encodes the x-coordinate of the mystery input vector, spanned by the input vector and j-hat. ",
  "time_range": [
   568.1,
   576.42
  ]
 },
 {
  "translatedText": "La versione trasformata di questo tipo è estesa dal vettore di output e dalla seconda colonna della matrice, e la sua area sarà stata moltiplicata per il determinante della matrice. ",
  "input": "The transformed version of this guy is spanned by the output vector and the second column of the matrix, and its area will have been multiplied by the determinant of the matrix. ",
  "time_range": [
   576.42,
   587.71
  ]
 },
 {
  "translatedText": "Quindi la coordinata x del nostro misterioso vettore di input è quest&#39;area divisa per il determinante della trasformazione. ",
  "input": "So the x-coordinate of our mystery input vector is this area divided by the determinant of the transformation. ",
  "time_range": [
   587.71,
   593.98
  ]
 },
 {
  "translatedText": "Simmetrico a quanto fatto prima, puoi calcolare l&#39;area del parallelogramma di output creando una nuova matrice la cui prima colonna è il vettore di output e la cui seconda colonna è uguale alla matrice originale. ",
  "input": "Symmetric to what we did before, you can compute the area of that output parallelogram by creating a new matrix whose first column is the output vector, and whose second column is the same as the original matrix. ",
  "time_range": [
   593.98,
   606.3
  ]
 },
 {
  "translatedText": "Quindi, ancora una volta, usando solo i dati dallo spazio di output, i numeri che vediamo nel nostro sistema lineare originale, possiamo recuperare la coordinata x del nostro misterioso vettore di input. ",
  "input": "So again, just using data from the output space, the numbers we see in our original linear system, we can recover the x-coordinate of our mystery input vector. ",
  "time_range": [
   606.3,
   613.6
  ]
 },
 {
  "translatedText": "Questa formula per trovare le soluzioni di un sistema lineare di equazioni è nota come regola di Cramer. ",
  "input": "This formula for finding the solutions to a linear system of equations is known as Cramer’s rule. ",
  "time_range": [
   613.6,
   619.44
  ]
 },
 {
  "translatedText": "Ecco, solo per controllarci, inserisci i numeri qui. ",
  "input": "Here, just to sanity check ourselves, plug in the numbers here. ",
  "time_range": [
   619.44,
   622.4
  ]
 },
 {
  "translatedText": "Il determinante della matrice alterata in alto è 4+2, che è 6, e il determinante inferiore è 2, quindi la coordinata x dovrebbe essere 3. ",
  "input": "The determinant of that top altered matrix is 4+2, which is 6, and the bottom determinant is 2, so the x-coordinate should be 3. ",
  "time_range": [
   622.4,
   631.43
  ]
 },
 {
  "translatedText": "E infatti, guardando indietro al vettore di input con cui abbiamo iniziato, la sua coordinata x è 3. ",
  "input": "And indeed, looking back at that input vector we started with, it’s x-coordinate is 3. ",
  "time_range": [
   631.43,
   635.91
  ]
 },
 {
  "translatedText": "Allo stesso modo, la regola di Cramer suggerisce che la coordinata y dovrebbe essere 4/2, o 2, e questa è infatti la coordinata y del vettore di input con cui abbiamo iniziato qui. ",
  "input": "Likewise, Cramer’s rule suggests the y-coordinate should be 4/2, or 2, and that is indeed the y-coordinate of the input vector we started with here. ",
  "time_range": [
   635.91,
   647.54
  ]
 },
 {
  "translatedText": "Il caso delle tre dimensioni è simile e ti consiglio vivamente di fermarti a pensarci da solo. ",
  "input": "The case with three dimensions is similar, and I highly recommend you pause to think it through yourself. ",
  "time_range": [
   647.54,
   653.69
  ]
 },
 {
  "translatedText": "Ecco, ti do un piccolo slancio. ",
  "input": "Here, I’ll give you a little momentum. ",
  "time_range": [
   653.69,
   656.77
  ]
 },
 {
  "translatedText": "Abbiamo questa trasformazione nota, data da una matrice 3x3, e un vettore di output noto, dato dal lato destro del nostro sistema lineare, e vogliamo sapere quale vettore di input si ferma su questo vettore di output. ",
  "input": "We have this known transformation, given by a 3x3 matrix, and a known output vector, given by the right side of our linear system, and we want to know what input vector lands on this output vector. ",
  "time_range": [
   656.77,
   669.2
  ]
 },
 {
  "translatedText": "Se pensi, ad esempio, alla coordinata z del vettore di input come al volume di questo parallelepipedo attraversato da i-hat, j-hat e dal misterioso vettore di input, cosa succede al volume di questo parallelepipedo dopo la trasformazione? ",
  "input": "If you think of, say, the z-coordinate of the input vector as the volume of this parallelepiped spanned by i-hat, j-hat, and the mystery input vector, what happens to the volume of this parallelepiped after the transformation? ",
  "time_range": [
   669.2,
   686.53
  ]
 },
 {
  "translatedText": "Come puoi calcolare quel nuovo volume? ",
  "input": "How can you compute that new volume? ",
  "time_range": [
   686.53,
   688.19
  ]
 },
 {
  "translatedText": "Davvero, fermatevi e prendetevi un momento per pensare ai dettagli di generalizzare questo a dimensioni superiori; trovare un&#39;espressione per ciascuna coordinata della soluzione a sistemi lineari più grandi. ",
  "input": "Really, pause and take a moment to think through the details of generalizing this to higher dimensions; finding an expression for each coordinate of the solution to larger linear systems. ",
  "time_range": [
   688.19,
   698.33
  ]
 },
 {
  "translatedText": "Pensare a casi più generali e convincersi che funziona è il luogo in cui avverrà tutto l&#39;apprendimento, molto più che ascoltare qualche tizio su YouTube che ripercorre il ragionamento. ",
  "input": "Thinking through more general cases and convincing yourself that it works is where all the learning will happen, much more so than listening to some dude on YouTube walk through the reasoning again. ",
  "time_range": [
   698.33,
   729.94
  ]
 }
]