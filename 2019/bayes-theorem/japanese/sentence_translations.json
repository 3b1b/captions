[
 {
  "input": "The goal is for you to come away from this video understanding one of the most important formulas in all of probability, Bayes' theorem.",
  "translatedText": "目標は、このビデオを終えて、すべての確率の中で最も重要 な公式の 1 つであるベイズの定理を理解することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.84
 },
 {
  "input": "This formula is central to scientific discovery, it's a core tool in machine learning and AI, and it's even been used for treasure hunting, when in the 1980s a small team led by Tommy Thompson, and I'm not making up that name, used Bayesian search tactics to help uncover a ship that had sunk a century and a half earlier, and the ship was carrying what in today's terms amounts to $700 million worth of gold.",
  "translatedText": "この公式は科学的発見の中心であり、機械学習と AI の中核ツー ルであり、1980 年代にトミー トンプソン率いる小さなチーム が、私がその名前を作ったわけではありませんが、宝探しにも使用さ れました。 1世紀半前に沈没した船を発見するためのベイジアン探 索戦術。 その船には今日の換算で7億ドル相当の金が積まれていた。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.48,
  "end": 30.74
 },
 {
  "input": "So it's a formula worth understanding, but of course there are multiple different levels of possible understanding.",
  "translatedText": "したがって、これは理解する価値のある公式ですが、 もちろん、理解には複数の異なるレベルがあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.34,
  "end": 37.04
 },
 {
  "input": "At the simplest there's just knowing what each one of the parts means, so that you can plug in numbers.",
  "translatedText": "最も単純には、各部分が何を意味するのかを理解し、 数字を当てはめることができるようにするだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 37.6,
  "end": 42.04
 },
 {
  "input": "Then there's understanding why it's true, and later I'm going to show you a certain diagram that's helpful for rediscovering this formula on the fly as needed.",
  "translatedText": "次に、なぜそれが正しいのかを理解します。 後で、必要に応じて この公式をその場で再発見するのに役立つ特定の図を示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.76,
  "end": 50.58
 },
 {
  "input": "But maybe the most important level is being able to recognize when you need to use it.",
  "translatedText": "しかし、おそらく最も重要なレベルは、いつそれを使用する必要があるかを認識できることです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.24,
  "end": 55.54
 },
 {
  "input": "And with the goal of gaining a deeper understanding, you and I are going to tackle these in reverse order.",
  "translatedText": "そして、より深い理解を得るという目標を掲げて、あ なたと私はこれらを逆の順序で取り組んでいきます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.54,
  "end": 60.56
 },
 {
  "input": "So before dissecting the formula or explaining the visual that makes it obvious, I'd like to tell you about a man named Steve.",
  "translatedText": "そこで、公式を分析したり、それを明らかにするビジュアルを説明した りする前に、スティーブという名前の男について話したいと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 61.02,
  "end": 66.86
 },
 {
  "input": "Listen carefully now.",
  "translatedText": "今、よく聞いてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.32,
  "end": 68.72
 },
 {
  "input": "Steve is very shy and withdrawn, invariably helpful but with very little interest in people or the world of reality.",
  "translatedText": "スティーブはとても内気で引っ込み思案で、いつも親切で すが、人々や現実の世界にはほとんど興味がありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.74,
  "end": 79.16
 },
 {
  "input": "A meek and tidy soul, he has a need for order and structure, and a passion for detail.",
  "translatedText": "柔和できちんとした魂を持つ彼は、秩序と構造を必要とし、細部への情熱を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.74,
  "end": 84.1
 },
 {
  "input": "Which of the following do you find more likely?",
  "translatedText": "次のうちどれがより可能性が高いと思いますか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.62,
  "end": 86.78
 },
 {
  "input": "Steve is a librarian, or Steve is a farmer?",
  "translatedText": "スティーブは図書館員ですか、それとも農家ですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.2,
  "end": 90.38
 },
 {
  "input": "Some of you may recognize this as an example from a study conducted by the two psychologists Daniel Kahneman and Amos Tversky.",
  "translatedText": "これは、ダニエル・カーネマンとエイモス・トベルスキーという二人の心理学者 によって行われた研究の一例として認識されている方もいるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 91.4,
  "end": 97.44
 },
 {
  "input": "Their work was a big deal, it won a Nobel Prize, and it's been popularized many times over in books like Kahneman's Thinking Fast and Slow, or Michael Lewis's The Undoing Project.",
  "translatedText": "彼らの研究は大きな話題となり、ノーベル賞を受賞し、カーネマンの『Th ink Fast and Slow』やマイケル・ルイスの『The Undoing Project』などの本で何度も有名になりました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.2,
  "end": 106.56
 },
 {
  "input": "What they researched was human judgments, with a frequent focus on when these judgments irrationally contradict what the laws of probability suggest they should be.",
  "translatedText": "彼らが研究したのは人間の判断であり、これらの判断が確率の法則が 示唆するものに不合理に矛盾する場合に頻繁に焦点を当てました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.42,
  "end": 115.78
 },
 {
  "input": "The example with Steve, our maybe librarian, maybe farmer, illustrates one specific type of irrationality, or maybe I should say alleged irrationality, there are people who debate the conclusion here, but more on that later on.",
  "translatedText": "おそらく図書館員で、おそらく農家であるスティーブの例は、ある特定のタイ プの不合理、あるいは不合理の疑いと言うべきかもしれませんが、ここで結論 について議論する人がいますが、それについては後ほど詳しく説明します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.34,
  "end": 129.62
 },
 {
  "input": "According to Kahneman and Tversky, after people are given this description of Steve as a meek and tidy soul, most say he's more likely to be a librarian.",
  "translatedText": "カーネマンとトベルスキーによると、人々はスティーブを柔和できちんとした魂であ ると説明した後、ほとんどの人が彼は図書館司書である可能性が高いと言います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.98,
  "end": 138.0
 },
 {
  "input": "After all, these traits line up better with the stereotypical view of a librarian than a farmer.",
  "translatedText": "結局のところ、これらの特徴は、農民よりも 図書館員の典型的な見方とよく一致します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 138.0,
  "end": 143.46
 },
 {
  "input": "And according to Kahneman and Tversky, this is irrational.",
  "translatedText": "そしてカーネマンとトベルスキーによれば、これは不合理だという。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.2,
  "end": 146.88
 },
 {
  "input": "The point is not whether people hold correct or biased views about the personalities of librarians and farmers, it's that almost nobody thinks to incorporate information about the ratio of farmers to librarians in their judgments.",
  "translatedText": "重要なのは、人々が図書館員と農民の性格について正しい見方をしているか偏 った見方をしているかということではなく、農民と図書館員の比率に関する情 報を判断材料に組み込もうと考えている人がほとんどいないということだ。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.6,
  "end": 160.24
 },
 {
  "input": "In their paper, Kahneman and Tversky said that in the US, that ratio is about 20 to 1.",
  "translatedText": "カーネマン氏とトベルスキー氏は論文の中で、米 国ではその比率は約20対1であると述べた。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 160.92,
  "end": 165.18
 },
 {
  "input": "The numbers I could find today put that much higher, but let's stick with the 20 to 1 number, since it's a little easier to illustrate and proves the point as well.",
  "translatedText": "今日見つけた数字ではそれよりもはるかに高い数字が示されていますが、説明が少 し簡単で要点も証明できるため、20 対 1 という数字にこだわりましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.58,
  "end": 173.42
 },
 {
  "input": "To be clear, anyone who is asked this question is not expected to have perfect information about the actual statistics of farmers and librarians and their personality traits.",
  "translatedText": "はっきり言っておきますが、この質問をされる人は、農民や図書館員の実際の統 計やその性格的特徴について完璧な情報を持っているとは期待されていません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.28,
  "end": 183.14
 },
 {
  "input": "But the question is whether people even think to consider that ratio enough to at least make a rough estimate.",
  "translatedText": "しかし問題は、人々がその比率を少なくとも大まかな見積もりを 立てるのに十分に考慮しようとさえ考えているかどうかです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.68,
  "end": 189.22
 },
 {
  "input": "Rationality is not about knowing facts, it's about recognizing which facts are relevant.",
  "translatedText": "合理性とは事実を知ることではなく、どの事実が関連しているかを認識することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.04,
  "end": 194.46
 },
 {
  "input": "Now if you do think to make that estimate, there's a pretty simple way to reason about the question, which, spoiler alert, involves all of the essential reasoning behind Bayes' theorem.",
  "translatedText": "さて、実際にその推定をしようと思ったら、この質問について推論 する非常に簡単な方法があります。 ネタバレ注意ですが、これには ベイズの定理の背後にある重要な推論がすべて含まれています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.88,
  "end": 203.9
 },
 {
  "input": "You might start by picturing a representative sample of farmers and librarians, say 200 farmers and 10 librarians.",
  "translatedText": "まず、農民と図書館員の代表的なサンプル、たとえば 200 人の農 民と 10 人の図書館員を想像することから始めるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.66,
  "end": 211.02
 },
 {
  "input": "Then when you hear of this meek and tidy soul description, let's say that your gut instinct is that 40% of librarians would fit that description, and that 10% of farmers would.",
  "translatedText": "次に、この柔和できちんとした魂の説明を聞いたとき、直感的に、図書館員の 40 % がその説明に当てはまり、農民の 10% が当てはまると考えたとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.74,
  "end": 221.36
 },
 {
  "input": "If those are your estimates, it would mean that from your sample you would expect about 4 librarians to fit the description, and about 20 farmers to fit that description.",
  "translatedText": "これらがあなたの推定値である場合、サンプルから約 4 人の図書館員がその説明に 適合し、約 20 人の農民がその説明に適合すると予想されることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.02,
  "end": 230.24
 },
 {
  "input": "So the probability that a random person among those who fit this description is a librarian is 4 out of 24, or 16.7%.",
  "translatedText": "したがって、この説明に当てはまる人の中でランダムに選ばれた人が図書 館員である確率は 24 人中 4 人、つまり 16 人です。7％。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.02,
  "end": 240.1
 },
 {
  "input": "So even if you think that a librarian is 4 times as likely as a farmer to fit this description, that's not enough to overcome the fact that there are way more farmers.",
  "translatedText": "したがって、たとえ図書館員がこの説明に当てはまる可能性が農民の 4 倍であると考えた としても、それは農民の数がはるかに多いという事実を克服するには十分ではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.1,
  "end": 249.02
 },
 {
  "input": "The upshot, and this is the key mantra underlying Bayes' theorem, is that new evidence does not completely determine your beliefs in a vacuum, it should update prior beliefs.",
  "translatedText": "その結論は、これがベイズの定理の根底にある重要な信念ですが、新しい証拠はあなたの 信念を完全に決定するものではなく、以前の信念を更新する必要があるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.72,
  "end": 259.22
 },
 {
  "input": "If this line of reasoning makes sense to you, the way that seeing evidence restricts the space of possibilities and the ratio you need to consider after that, then congratulations, you understand the heart of Bayes' theorem.",
  "translatedText": "この推論があなたにとって意味があり、証拠を見ることで可能性の空間が 制限され、その後考慮する必要がある比率が理解できたなら、おめでと うございます。 ベイズの定理の核心を理解したということになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 261.12,
  "end": 272.36
 },
 {
  "input": "Maybe the numbers you would estimate would be a little different, but what matters is how you fit the numbers together to update your beliefs based on evidence.",
  "translatedText": "おそらく、あなたが推定する数字は少し異なるかもしれませんが、重要なのは、証 拠に基づいて自分の信念を更新するために数字をどのように当てはめるかです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.36,
  "end": 280.6
 },
 {
  "input": "Understanding one example is one thing, but see if you can take a minute to generalize everything we just did and write it all down as a formula.",
  "translatedText": "1 つの例を理解することは別のことですが、今行ったことすべてを一般化し て、すべてを式として書き留めることができるかどうかを確認してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.08,
  "end": 289.74
 },
 {
  "input": "The general situation where Bayes' theorem is relevant is when you have some hypothesis, like Steve is a librarian, and you see some new evidence, say this verbal description of Steve as a meek and tidy soul.",
  "translatedText": "ベイズの定理が関連する一般的な状況は、スティーブが図書館員であ るなどの仮説があり、スティーブが柔和できちんとした魂であるとい う口頭での説明のように、いくつかの新しい証拠を見たときです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.32,
  "end": 303.98
 },
 {
  "input": "You want to know the probability that your hypothesis holds given that the evidence is true.",
  "translatedText": "証拠が正しい場合に、仮説が成り 立つ確率を知りたいとします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.38,
  "end": 309.64
 },
 {
  "input": "In the standard notation, this vertical bar means given that, as in we're restricting our view only to the possibilities where the evidence holds.",
  "translatedText": "標準的な表記法では、この縦棒は、証拠が存在する可 能性のみに視点を限定していることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.44,
  "end": 318.96
 },
 {
  "input": "Remember the first relevant number we used, the probability that the hypothesis holds before considering any of that new evidence.",
  "translatedText": "新しい証拠を検討する前に、最初に使用した関連する数 値、つまり仮説が成立する確率を思い出してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.22,
  "end": 327.34
 },
 {
  "input": "In our example, that was 1 out of 21, and it came from considering the ratio of librarians to farmers in the general population.",
  "translatedText": "私たちの例では、これは 21 人に 1 人であり、一般 人口における図書館員と農民の比率を考慮した結果です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.72,
  "end": 334.64
 },
 {
  "input": "This number is known as the prior.",
  "translatedText": "この数は事前数として知られています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 335.52,
  "end": 336.98
 },
 {
  "input": "After that, we need to consider the proportion of librarians that fit this description, the probability that we would see the evidence given that the hypothesis is true.",
  "translatedText": "その後、この説明に当てはまる図書館員の割合、つまり仮説が正しい と仮定した場合に証拠が見つかる確率を考慮する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.02,
  "end": 347.3
 },
 {
  "input": "Again, when you see this vertical bar, it means we're talking about some proportion of a limited part of the total space of possibilities.",
  "translatedText": "繰り返しになりますが、この縦棒が表示される場合は、可能性の全 空間の限られた部分の一部について話していることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.1,
  "end": 354.84
 },
 {
  "input": "In this case, that limited part is the left side, where the hypothesis holds.",
  "translatedText": "この場合、その限定された部分は仮説が成立する左側です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.32,
  "end": 359.3
 },
 {
  "input": "In the context of Bayes' theorem, this value also has a special name, it's called the likelihood.",
  "translatedText": "ベイズの定理の文脈では、この値にも特 別な名前があり、尤度と呼ばれます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.96,
  "end": 364.64
 },
 {
  "input": "Similarly, you need to know how much of the other side of the space includes the evidence, the probability of seeing the evidence given that the hypothesis isn't true.",
  "translatedText": "同様に、空間の反対側にどれだけの証拠が含まれているか、仮説が 真実ではない場合に証拠が見つかる確率を知る必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.7,
  "end": 373.56
 },
 {
  "input": "This funny little elbow symbol is commonly used in probability to mean not.",
  "translatedText": "この面白い小さな肘のシンボルは、確率ではないことを意味するためによく使用されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.34,
  "end": 378.42
 },
 {
  "input": "So, with the notation in place, remember what our final answer was.",
  "translatedText": "したがって、表記を適切に行った上で、最終的な答えが何であったかを思い出してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.86,
  "end": 383.02
 },
 {
  "input": "The probability that our librarian hypothesis is true given the evidence is the total number of librarians fitting the evidence, 4, divided by the total number of people fitting the evidence, 24.",
  "translatedText": "証拠が与えられた場合に、図書館員の仮説が正しい確 率は、証拠に当てはまる図書館員の総数 4 を、証 拠に当てはまる人の総数 24 で割ったものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.36,
  "end": 394.88
 },
 {
  "input": "But where did that 4 come from?",
  "translatedText": "しかし、その 4 はどこから来たのでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.76,
  "end": 397.18
 },
 {
  "input": "Well, it's the total number of people, times the prior probability of being a librarian, giving us the 10 total librarians, times the probability that one of those fits the evidence.",
  "translatedText": "そうですね、これは人の総数に図書館員である事前確率を掛けたもので、合計 10 人の図書館員が得られ、そのうちの 1 人が証拠に適合する確率を掛けたものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 397.84,
  "end": 408.42
 },
 {
  "input": "That same number shows up again in the denominator, but we need to add in the rest, the total number of people times the proportion who are not librarians, times the proportion of those who fit the evidence, which in our example gives 20.",
  "translatedText": "同じ数字が分母に再び表示されますが、残りを追加する必要があり ます。 合計人数に図書館員ではない人の割合を掛け、証拠に適合す る人の割合を掛けたものです。 この例では 20 となります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.22,
  "end": 422.14
 },
 {
  "input": "Now notice the total number of people here, 210, that gets cancelled out, and of course it should, that was just an arbitrary choice made for the sake of illustration.",
  "translatedText": "ここで、ここでの合計人数 210 人が相殺されていることに注目してください。 も ちろん、当然そうすべきですが、これは説明のために単に恣意的に選択したものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.22,
  "end": 431.04
 },
 {
  "input": "This leaves us finally with a more abstract representation purely in terms of probabilities, and this, my friends, is Bayes' theorem.",
  "translatedText": "これにより、純粋に確率の観点から最終的により抽象 的な表現が得られます。 これがベイズの定理です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 431.62,
  "end": 439.22
 },
 {
  "input": "More often, you see this denominator written simply as P of E, the total probability of seeing the evidence, which in our example would be the 24 out of 210.",
  "translatedText": "より多くの場合、この分母は単純に P of E、つまり証拠が見つかる合計確率として 書かれているのを目にします。 この例では、これは 210 のうち 24 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 440.42,
  "end": 450.46
 },
 {
  "input": "But in practice, to calculate it, you almost always have to break it down into the case where the hypothesis is true, and the one where it isn't.",
  "translatedText": "しかし実際には、それを計算するには、ほとんどの場合、仮説 が正しい場合とそうでない場合に分類する必要があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 458.8
 },
 {
  "input": "Capping things off with one final bit of jargon, this answer is called the posterior, it's your belief about the hypothesis after seeing the evidence.",
  "translatedText": "最後に少し専門用語を使って話を締めくくりますが、この答えは事後分析 と呼ばれるもので、証拠を見た後の仮説についてのあなたの信念です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.06,
  "end": 468.6
 },
 {
  "input": "Writing it out abstractly might seem more complicated than just thinking through the example directly with a representative sample.",
  "translatedText": "抽象的に書き出すと、代表的なサンプルを使って 直接考えるよりも複雑に見えるかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.16,
  "end": 476.5
 },
 {
  "input": "And yeah, it is.",
  "translatedText": "そして、そうです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 476.92,
  "end": 478.78
 },
 {
  "input": "Keep in mind though, the value of a formula like this is that it lets you quantify and systematize the idea of changing beliefs.",
  "translatedText": "ただし、このような公式の価値は、信念を変えるというアイデアを 定量化して体系化できることであることを覚えておいてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.2,
  "end": 486.26
 },
 {
  "input": "Scientists use this formula when they're analyzing the extent to which new data validates or invalidates their models.",
  "translatedText": "科学者は、新しいデータがモデルをどの程度検証または 無効にするかを分析するときにこの公式を使用します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.94,
  "end": 492.84
 },
 {
  "input": "Programmers will sometimes use it in building artificial intelligence, where at times you want to explicitly and numerically model a machine's belief.",
  "translatedText": "プログラマーは人工知能の構築にこれを使用することがあり、機 械の信念を明示的かつ数値的にモデル化したい場合があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 492.84,
  "end": 500.64
 },
 {
  "input": "And honestly, just for the way you view yourself and your own opinions and what it takes for your mind to change, Bayes' theorem has a way of reframing how you even think about thought itself.",
  "translatedText": "そして正直に言うと、自分自身と自分の意見の見方、そして自分の 心を変えるために何が必要かという点だけでも、ベイズの定理は思 考そのものについての考え方を再構築する方法を持っています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 501.4,
  "end": 510.82
 },
 {
  "input": "Putting a formula to it can also be more important as the examples get more and more intricate.",
  "translatedText": "例が複雑になるにつれて、それに公式を当てはめることも重要になる可能性があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.3,
  "end": 516.34
 },
 {
  "input": "However you write it, I actually encourage you not to try memorizing the formula, but to instead draw out this diagram as needed.",
  "translatedText": "どのように書いても、式を暗記しようとするのではな く、必要に応じてこの図を描くことをお勧めします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.08,
  "end": 524.68
 },
 {
  "input": "It's sort of a distilled version of thinking with a representative sample, where we think with areas instead of counts, which is more flexible and easier to sketch on the fly.",
  "translatedText": "これは、代表的なサンプルを使用した思考の蒸留版のようなもので、数ではなく 面積で考えることで、より柔軟でその場でスケッチするのが簡単になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.26,
  "end": 533.62
 },
 {
  "input": "Rather than bringing to mind some specific number of examples, like 210, think of the space of all possibilities as a 1x1 square.",
  "translatedText": "210 のような特定の数の例を思い出すのではなく、すべて の可能性の空間を 1x1 の正方形として考えてください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.26,
  "end": 541.38
 },
 {
  "input": "Then any event occupies some subset of this space, and the probability of that event can be thought about as the area of that subset.",
  "translatedText": "次に、あらゆるイベントはこの空間の一部を占め、そのイベン トの確率はそのサブセットの面積と考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 542.12,
  "end": 550.94
 },
 {
  "input": "For example, I like to think of the hypothesis as living in the left part of the square with a width of p of h.",
  "translatedText": "たとえば、私は仮説が h の幅 p の正方形 の左側の部分に存在すると考えるのが好きです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.54,
  "end": 557.66
 },
 {
  "input": "I recognize I'm being a bit repetitive, but when you see evidence, the space of possibilities gets restricted, and the crucial part is that restriction might not be even between the left and the right, so the new probability for the hypothesis is the proportion it occupies in this restricted wonky shape.",
  "translatedText": "少し繰り返していることは承知していますが、証拠を見ると、可能 性の空間は制限されます。 そして重要な部分は、制限が左と右の間 で均一ではない可能性があるということです。 したがって、仮説の 新しい確率はこの制限された奇妙な形状の中でそれが占める割合。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.32,
  "end": 576.94
 },
 {
  "input": "Now if you think a farmer is just as likely to fit the evidence as a librarian, then the proportion doesn't change, which should make sense, right?",
  "translatedText": "ここで、農家が図書館員と同じくらい証拠に適合する可能性が高いと考 えるなら、その割合は変わらないということは、当然のことでしょう?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.64,
  "end": 586.24
 },
 {
  "input": "And evidence doesn't change your beliefs.",
  "translatedText": "そして、証拠があってもあなたの信念は変わりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.26,
  "end": 588.32
 },
 {
  "input": "But when these likelihoods are very different from each other, that's when your belief changes a lot.",
  "translatedText": "しかし、これらの可能性が互いに大きく異なるとき 、それはあなたの信念が大きく変わるときです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.9,
  "end": 593.48
 },
 {
  "input": "Bayes' theorem spells out what that proportion is, and if you want you can read it geometrically.",
  "translatedText": "ベイズの定理はその比率がどのようなものかを詳しく説明しており、必要に応じて幾何学的に読み取ることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.76,
  "end": 600.52
 },
 {
  "input": "Something like p of h times p of e given h, the probability of both the hypothesis and the evidence occurring together, is the width times the height of this little left rectangle, the area of that region.",
  "translatedText": "h が与えられた場合の h の p と e の p のような もの、仮説と証拠の両方が同時に発生する確率は、この左側の小 さな長方形の幅と高さの積、つまりその領域の面積になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 600.9,
  "end": 613.08
 },
 {
  "input": "Alright, this is probably a good time to take a step back and consider a few of the broader takeaways about how to make probability more intuitive, beyond Bayes' theorem.",
  "translatedText": "さて、これはおそらく、一歩下がって、ベイズの定理を超えて、確率をより直 感的にする方法についてのより広範な要点をいくつか検討する良い機会です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 614.76,
  "end": 623.22
 },
 {
  "input": "First off, notice how the trick of thinking about a representative sample with some specific number of people, like our 210 librarians and farmers, was really helpful.",
  "translatedText": "まず最初に、210 人の図書館員や農民など、特定の人数で代表的なサンプ ルについて考えるというトリックがいかに役に立ったかに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.78,
  "end": 632.4
 },
 {
  "input": "There's actually another Kahneman and Tversky result which is all about this, and it's interesting enough to interject here.",
  "translatedText": "実はこれに関するカーネマンとトベルスキーの別の結果 があり、ここで介入するのに十分興味深いものです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.96,
  "end": 638.38
 },
 {
  "input": "They did this experiment that was similar to the one with Steve, but where people were given the following description of a fictitious woman named Linda.",
  "translatedText": "彼らはスティーブの実験と似た実験を行いましたが、そこでは人々にリ ンダという名前の架空の女性について次のような説明を与えました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 638.52,
  "end": 645.72
 },
 {
  "input": "Linda is 31 years old, single, outspoken, and very bright.",
  "translatedText": "リンダは 31 歳、独身、率直でとても明るいです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.4,
  "end": 650.62
 },
 {
  "input": "She majored in philosophy.",
  "translatedText": "彼女は哲学を専攻しました。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.14,
  "end": 652.16
 },
 {
  "input": "As a student she was deeply concerned with issues of discrimination and social justice, and also participated in the anti-nuclear demonstrations.",
  "translatedText": "学生時代、彼女は差別と社会正義の問題に深 く関心を持ち、反原発デモにも参加した。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.64,
  "end": 659.54
 },
 {
  "input": "After seeing this people were asked what's more likely, 1.",
  "translatedText": "これを見た後、人々はどちらの可能性が高いかと尋ねられました。 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 660.7,
  "end": 664.02
 },
 {
  "input": "That Linda is a bank teller, or 2.",
  "translatedText": "リンダが銀行窓口係であること、または 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 664.34,
  "end": 666.46
 },
 {
  "input": "That Linda is a bank teller and is active in the feminist movement.",
  "translatedText": "リンダは銀行窓口係であり、フェミニスト運動に積極的に参加していること。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.92,
  "end": 669.9
 },
 {
  "input": "85%, 85% of participants said that the latter is more likely than the former, even though the set of bank tellers who are active in the feminist movement is a subset of the set of bank tellers.",
  "translatedText": "参加者の85%は、フェミニスト運動に積極的に参加し ている銀行窓口係は一部の銀行窓口係であるにもかか わらず、前者よりも後者の可能性が高いと回答した。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.22,
  "end": 683.32
 },
 {
  "input": "It has to be smaller.",
  "translatedText": "もっと小さくなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.56,
  "end": 684.68
 },
 {
  "input": "So that's interesting enough, but what's fascinating is that there's a simple way that you can rephrase the question that dropped this error from 85% to 0.",
  "translatedText": "それはそれで十分興味深いのですが、さらに興味深いのは、この誤差を 85% から 0 に落とした質問を言い換えることができる簡単な方法があるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.64,
  "end": 694.1
 },
 {
  "input": "Instead, if participants were told that there are 100 people who fit this description, and then asked to estimate how many of those 100 are bank tellers, and how many are bank tellers active in the feminist movement, nobody makes the error.",
  "translatedText": "代わりに、参加者に、この説明に当てはまる人が 100 人いると伝え、その 100 人のうち何人が銀行窓口係であり、何人がフェミニスト運動に積極的 な銀行窓口係であるかを推定するよう依頼した場合、誰も間違いを犯しません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.96,
  "end": 708.5
 },
 {
  "input": "Everybody correctly assigns a higher number to the first option than to the second.",
  "translatedText": "誰もが、最初のオプションに 2 番目のオプションよりも高い数値を正しく割り当てます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.5,
  "end": 713.18
 },
 {
  "input": "It's weird, somehow phrases like 40 out of 100 kick our intuitions into gear much more effectively than 40%, much less 0.4, and much less abstractly referencing the idea of something being more or less likely.",
  "translatedText": "奇妙なことに、どういうわけか「100 点中 40 点」のようなフレーズは、40% よりも、ましてや 0 よりもはる かに効果的に私たちの直感を動かします。4、ましてや、何かが多かれ少なかれ起こり そうであるという考えを抽象的に言及するものではありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 714.78,
  "end": 728.06
 },
 {
  "input": "That said, representative samples don't easily capture the continuous nature of probability.",
  "translatedText": "とはいえ、代表的なサンプルでは確率の連続的な性質を簡単に捉えることはできません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.4,
  "end": 734.1
 },
 {
  "input": "So turning to area is a nice alternative, not just because of the continuity, but also because it's way easier to sketch out when you're sitting there pencil and paper puzzling over some problem.",
  "translatedText": "したがって、面に目を向けることは、継続性のためだけでなく、そこ に座って鉛筆と紙を使って問題について頭を悩ませているときに、ス ケッチを描くのがはるかに簡単であるため、優れた代替手段です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.1,
  "end": 744.04
 },
 {
  "input": "People often think about probability as being the study of uncertainty, and that is of course how it's applied in science, but the actual math of probability, where all the formulas come from, is just the math of proportions, and in that context turning to geometry is exceedingly helpful.",
  "translatedText": "確率は不確実性の研究であるとよく考えられており、もちろん それが科学での応用方法でもありますが、すべての式の由来 となる実際の確率の数学は単なる比率の数学であり、その文 脈では次のようになります。 幾何学は非常に役に立ちます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.22,
  "end": 761.02
 },
 {
  "input": "I mean, take a look at Bayes' theorem as a statement about proportions, whether that's proportions of people, of areas, whatever.",
  "translatedText": "つまり、ベイズの定理を、人間の比率であれ、面積の 比率であれ、比率に関する記述として見てください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 764.26,
  "end": 770.72
 },
 {
  "input": "Once you digest what it's saying, it's actually kind of obvious.",
  "translatedText": "言っていることを一度理解すれば、それは実際にはある程度明白です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 771.3,
  "end": 774.46
 },
 {
  "input": "Both sides tell you to look at the cases where the evidence is true, and then to consider the proportion of those cases where the hypothesis is also true.",
  "translatedText": "どちらの側も、証拠が正しいケースを調べてから、仮説 も正しいケースの割合を考慮するように指示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 775.04,
  "end": 782.72
 },
 {
  "input": "That's it, that's all it's saying.",
  "translatedText": "それだけです、言っていることはそれだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.24,
  "end": 784.64
 },
 {
  "input": "The right-hand side just spells out how to compute it.",
  "translatedText": "右側は計算方法を説明するだけです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 784.86,
  "end": 786.9
 },
 {
  "input": "What's noteworthy is that such a straightforward fact about proportions can become hugely significant for science, for artificial intelligence, and really any situation where you want to quantify belief.",
  "translatedText": "注目に値するのは、比率に関するこのような単純な事実は、 科学、人工知能、そして信念を数値化したいあらゆる状況 にとって非常に重要になる可能性があるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.54,
  "end": 797.92
 },
 {
  "input": "I hope to give you a better glimpse of that as we get into more examples.",
  "translatedText": "より多くの例を取り上げる際に、それをよりよく垣間見ることができれば幸いです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.54,
  "end": 801.42
 },
 {
  "input": "But before more examples, we have a little bit of unfinished business with Steve.",
  "translatedText": "しかし、さらなる例の前に、スティーブと少しやり残した仕事があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 802.38,
  "end": 805.74
 },
 {
  "input": "As I mentioned, some psychologists debate Kahneman and Tversky's conclusion that the rational thing to do is to bring to mind the ratio of farmers to librarians.",
  "translatedText": "先ほど述べたように、心理学者の中には、農家と図書館員の比率を念頭に置くのが 合理的だというカーネマンとトベルスキーの結論について議論する人もいます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.48,
  "end": 814.8
 },
 {
  "input": "They complain that the context is ambiguous.",
  "translatedText": "彼らは文脈があいまいであると不満を述べています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 815.14,
  "end": 817.26
 },
 {
  "input": "I mean, who is Steve, exactly?",
  "translatedText": "つまり、スティーブとは正確には誰ですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 817.92,
  "end": 819.84
 },
 {
  "input": "Should you expect that he's a randomly sampled American?",
  "translatedText": "彼が無作為に抽出されたアメリカ人であると考えるべきでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.84,
  "end": 822.66
 },
 {
  "input": "Or would you be better to assume that he's a friend of the two psychologists interrogating you?",
  "translatedText": "それとも、彼はあなたを尋問している二人の心理 学者の友人だと考えたほうがよいでしょうか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 823.26,
  "end": 827.0
 },
 {
  "input": "Or maybe that he's someone you're personally likely to know?",
  "translatedText": "それとも、彼はあなたが個人的に知っている可能性が高い人物ですか?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 827.22,
  "end": 829.74
 },
 {
  "input": "This assumption determines the prior.",
  "translatedText": "この仮定により事前確率が決定されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.42,
  "end": 832.4
 },
 {
  "input": "I for one run into way more librarians in a given month than I do farmers.",
  "translatedText": "私は、ある月に農民よりもはるかに多くの図書館員に遭遇します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.96,
  "end": 836.68
 },
 {
  "input": "Needless to say, the probability of a librarian or a farmer fitting this description is highly open to interpretation.",
  "translatedText": "言うまでもなく、図書館員や農家がこの説明に当て はまる可能性は、非常に解釈の余地があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 837.5,
  "end": 843.52
 },
 {
  "input": "For our purposes, understanding the math, what I want to emphasize is that any question worth debating here can be pictured in the context of the diagram.",
  "translatedText": "数学を理解するという私たちの目的のために強調したいのは、ここで議論する 価値のある質問はすべて、図のコンテキストで描写できるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 844.44,
  "end": 852.3
 },
 {
  "input": "Questions about the context shift around the prior, and questions about the personalities and stereotypes shift around the relevant likelihoods.",
  "translatedText": "文脈に関する質問は事前の質問を中心に変化し、性格や固定 観念に関する質問は関連する可能性を中心に変化します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 853.0,
  "end": 860.58
 },
 {
  "input": "All that said, whether or not you buy this particular experiment, the ultimate point that evidence should not determine beliefs, but update them, is worth tattooing in your brain.",
  "translatedText": "そうは言っても、この特定の実験を購入するかどうかに関係なく、 証拠は信念を決定するものではなく、信念を更新すべきであると いう究極のポイントは、あなたの脳に刻み込む価値があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 861.1,
  "end": 871.0
 },
 {
  "input": "I'm in no position to say whether this does or does not run against natural human instinct.",
  "translatedText": "これが人間の自然な本能に反するかどうかについて、私は言う立場にありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.8,
  "end": 876.5
 },
 {
  "input": "We'll leave that to the psychologists.",
  "translatedText": "それは心理学者に任せましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 876.5,
  "end": 878.24
 },
 {
  "input": "What's more interesting to me is how we can reprogram our intuition to authentically reflect the implications of math, and bringing to mind the right image can often do just that.",
  "translatedText": "私にとってさらに興味深いのは、数学の意味を真に反映するために 直観をどのように再プログラムできるかということであり、適切な イメージを思い出すことで、多くの場合それが可能になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 878.92,
  "end": 888.06
 }
]