[
 {
  "input": "The goal is for you to come away from this video understanding one of the most important formulas in all of probability, Bayes' theorem. ",
  "translatedText": "مقصد یہ ہے کہ آپ اس ویڈیو سے دور ہو جائیں اور تمام امکان کے سب سے اہم فارمولوں میں سے ایک، Bayes کے تھیوریم کو سمجھیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.84
 },
 {
  "input": "This formula is central to scientific discovery, it's a core tool in machine learning and AI, and it's even been used for treasure hunting, when in the 1980s a small team led by Tommy Thompson, and I'm not making up that name, used Bayesian search tactics to help uncover a ship that had sunk a century and a half earlier, and the ship was carrying what in today's terms amounts to $700 million worth of gold. ",
  "translatedText": "یہ فارمولہ سائنسی دریافت کے لیے مرکزی حیثیت رکھتا ہے، یہ مشین لرننگ اور اے آئی میں ایک بنیادی ٹول ہے، اور یہاں تک کہ اسے خزانے کی تلاش کے لیے بھی استعمال کیا جاتا ہے، جب 1980 کی دہائی میں ٹومی تھامسن کی قیادت میں ایک چھوٹی ٹیم تھی، اور میں اس نام کو استعمال نہیں کر رہا تھا۔ڈیڑھ صدی قبل ڈوبنے والے جہاز کو ڈھونڈنے میں مدد کرنے کے لیے بایسیئن تلاش کے ہتھکنڈے، اور جہاز لے جا رہا تھا جو آج کی شرائط میں $700 ملین مالیت کا سونا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.48,
  "end": 30.74
 },
 {
  "input": "So it's a formula worth understanding, but of course there are multiple different levels of possible understanding. ",
  "translatedText": "تو یہ سمجھنے کے قابل ایک فارمولہ ہے، لیکن یقیناً ممکنہ تفہیم کی متعدد مختلف سطحیں ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.34,
  "end": 37.04
 },
 {
  "input": "At the simplest there's just knowing what each one of the parts means, so that you can plug in numbers. ",
  "translatedText": "سب سے آسان بات یہ ہے کہ صرف یہ جاننا ہے کہ ہر ایک حصے کا کیا مطلب ہے، تاکہ آپ نمبر لگا سکیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 37.6,
  "end": 42.04
 },
 {
  "input": "Then there's understanding why it's true, and later I'm going to show you a certain diagram that's helpful for rediscovering this formula on the fly as needed. ",
  "translatedText": "پھر سمجھ آتی ہے کہ یہ سچ کیوں ہے، اور بعد میں میں آپ کو ایک مخصوص خاکہ دکھانے جا رہا ہوں جو ضرورت کے مطابق پرواز پر اس فارمولے کو دوبارہ دریافت کرنے میں مددگار ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.76,
  "end": 50.58
 },
 {
  "input": "But maybe the most important level is being able to recognize when you need to use it. ",
  "translatedText": "لیکن ہوسکتا ہے کہ سب سے اہم سطح کو پہچاننے کے قابل ہو جب آپ کو اسے استعمال کرنے کی ضرورت ہو۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.24,
  "end": 55.54
 },
 {
  "input": "And with the goal of gaining a deeper understanding, you and I are going to tackle these in reverse order. ",
  "translatedText": "اور گہری تفہیم حاصل کرنے کے مقصد کے ساتھ، آپ اور میں ان کو الٹ ترتیب میں حل کرنے جا رہے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.54,
  "end": 60.56
 },
 {
  "input": "So before dissecting the formula or explaining the visual that makes it obvious, I'd like to tell you about a man named Steve. ",
  "translatedText": "لہذا فارمولے کو الگ کرنے سے پہلے یا بصری کی وضاحت کرنے سے پہلے جو اسے واضح کرتا ہے، میں آپ کو سٹیو نامی شخص کے بارے میں بتانا چاہوں گا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 61.02,
  "end": 66.86
 },
 {
  "input": "Listen carefully now. ",
  "translatedText": "اب غور سے سنو۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.32,
  "end": 68.72
 },
 {
  "input": "Steve is very shy and withdrawn, invariably helpful but with very little interest in people or the world of reality. ",
  "translatedText": "اسٹیو بہت شرمیلا اور پیچھے ہٹنے والا ہے، ہمیشہ مددگار لیکن لوگوں یا حقیقت کی دنیا میں بہت کم دلچسپی کے ساتھ۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.74,
  "end": 79.16
 },
 {
  "input": "A meek and tidy soul, he has a need for order and structure, and a passion for detail. ",
  "translatedText": "ایک شائستہ اور صاف روح، اسے ترتیب اور ساخت کی ضرورت ہے، اور تفصیل کا جذبہ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.74,
  "end": 84.1
 },
 {
  "input": "Which of the following do you find more likely? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.62,
  "end": 86.78
 },
 {
  "input": "Steve is a librarian, or Steve is a farmer? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.2,
  "end": 90.38
 },
 {
  "input": "Some of you may recognize this as an example from a study conducted by the two psychologists Daniel Kahneman and Amos Tversky. ",
  "translatedText": "آپ کو مندرجہ ذیل میں سے کس کا زیادہ امکان نظر آتا ہے؟ سٹیو ایک لائبریرین ہے، یا سٹیو ایک کسان ہے؟ آپ میں سے کچھ لوگ اسے دو ماہر نفسیات ڈینیئل کاہنیمین اور اموس ٹورسکی کے ذریعہ کئے گئے ایک مطالعہ سے ایک مثال کے طور پر پہچان سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 91.4,
  "end": 97.44
 },
 {
  "input": "Their work was a big deal, it won a Nobel Prize, and it's been popularized many times over in books like Kahneman's Thinking Fast and Slow, or Michael Lewis's The Undoing Project. ",
  "translatedText": "ان کا کام ایک بڑا سودا تھا، اس نے نوبل انعام جیتا، اور اسے Kahneman's Thinking Fast and Slow، یا مائیکل لیوس کی The Undoing Project جیسی کتابوں میں کئی بار مقبول کیا گیا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.2,
  "end": 106.56
 },
 {
  "input": "What they researched was human judgments, with a frequent focus on when these judgments irrationally contradict what the laws of probability suggest they should be. ",
  "translatedText": "انہوں نے جس چیز پر تحقیق کی وہ انسانی فیصلے تھے، اس بات پر کثرت سے توجہ مرکوز کرتے ہوئے کہ جب یہ فیصلے غیر معقول طور پر اس بات سے متصادم ہوتے ہیں کہ امکانات کے قوانین بتاتے ہیں کہ انہیں کیا ہونا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.42,
  "end": 115.78
 },
 {
  "input": "The example with Steve, our maybe librarian, maybe farmer, illustrates one specific type of irrationality, or maybe I should say alleged irrationality, there are people who debate the conclusion here, but more on that later on. ",
  "translatedText": "اسٹیو کے ساتھ مثال، ہمارے شاید لائبریرین، شاید کسان، ایک خاص قسم کی غیر معقولیت کو واضح کرتی ہے، یا شاید مجھے مبینہ غیر معقولیت کہنا چاہئے، ایسے لوگ ہیں جو یہاں نتیجہ پر بحث کرتے ہیں، لیکن اس پر بعد میں مزید۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.34,
  "end": 129.62
 },
 {
  "input": "According to Kahneman and Tversky, after people are given this description of Steve as a meek and tidy soul, most say he's more likely to be a librarian. ",
  "translatedText": "Kahneman اور Tversky کے مطابق، جب لوگوں کو اسٹیو کی یہ وضاحت ایک شائستہ اور صاف روح کے طور پر دی جاتی ہے، تو زیادہ تر کہتے ہیں کہ اس کے لائبریرین ہونے کا زیادہ امکان ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.98,
  "end": 138.0
 },
 {
  "input": "After all, these traits line up better with the stereotypical view of a librarian than a farmer. ",
  "translatedText": "بہر حال، یہ خصلتیں کسان کے مقابلے میں لائبریرین کے دقیانوسی نظریہ کے ساتھ بہتر انداز میں ملتی ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 138.0,
  "end": 143.46
 },
 {
  "input": "And according to Kahneman and Tversky, this is irrational. ",
  "translatedText": "اور Kahneman اور Tversky کے مطابق، یہ غیر معقول ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.2,
  "end": 146.88
 },
 {
  "input": "The point is not whether people hold correct or biased views about the personalities of librarians and farmers, it's that almost nobody thinks to incorporate information about the ratio of farmers to librarians in their judgments. ",
  "translatedText": "بات یہ نہیں ہے کہ لوگ لائبریرین اور کسانوں کی شخصیت کے بارے میں درست یا متعصبانہ خیالات رکھتے ہیں، یہ ہے کہ تقریباً کوئی بھی اپنے فیصلوں میں لائبریرین اور کسانوں کے تناسب کے بارے میں معلومات کو شامل کرنے کے بارے میں نہیں سوچتا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.6,
  "end": 160.24
 },
 {
  "input": "In their paper, Kahneman and Tversky said that in the US, that ratio is about 20 to 1. ",
  "translatedText": "اپنے مقالے میں، Kahneman اور Tversky نے کہا کہ امریکہ میں، یہ تناسب تقریباً 20 سے 1 ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 160.92,
  "end": 165.18
 },
 {
  "input": "The numbers I could find today put that much higher, but let's stick with the 20 to 1 number, since it's a little easier to illustrate and proves the point as well. ",
  "translatedText": "مجھے آج جو نمبر مل سکتے ہیں وہ اس سے کہیں زیادہ ہیں، لیکن آئیے 20 سے 1 نمبر پر قائم رہیں، کیونکہ یہ وضاحت کرنا تھوڑا آسان ہے اور نقطہ کو بھی ثابت کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.58,
  "end": 173.42
 },
 {
  "input": "To be clear, anyone who is asked this question is not expected to have perfect information about the actual statistics of farmers and librarians and their personality traits. ",
  "translatedText": "واضح رہے کہ جس سے بھی یہ سوال پوچھا جاتا ہے اس سے کسانوں اور لائبریرین کے اصل اعدادوشمار اور ان کی شخصیت کی خصوصیات کے بارے میں مکمل معلومات کی توقع نہیں کی جاتی ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.28,
  "end": 183.14
 },
 {
  "input": "But the question is whether people even think to consider that ratio enough to at least make a rough estimate. ",
  "translatedText": "لیکن سوال یہ ہے کہ کیا لوگ اس تناسب کو کم از کم اندازہ لگانے کے لیے کافی سمجھتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.68,
  "end": 189.22
 },
 {
  "input": "Rationality is not about knowing facts, it's about recognizing which facts are relevant. ",
  "translatedText": "عقلیت حقائق کو جاننے کے بارے میں نہیں ہے، یہ اس بات کو تسلیم کرنے کے بارے میں ہے کہ کون سے حقائق متعلقہ ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.04,
  "end": 194.46
 },
 {
  "input": "Now if you do think to make that estimate, there's a pretty simple way to reason about the question, which, spoiler alert, involves all of the essential reasoning behind Bayes' theorem. ",
  "translatedText": "اب اگر آپ یہ اندازہ لگانے کے بارے میں سوچتے ہیں، تو سوال کے بارے میں استدلال کرنے کا ایک بہت آسان طریقہ ہے، جس میں، بگاڑنے والا الرٹ، Bayes کے تھیوریم کے پیچھے تمام ضروری استدلال کو شامل کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.88,
  "end": 203.9
 },
 {
  "input": "You might start by picturing a representative sample of farmers and librarians, say 200 farmers and 10 librarians. ",
  "translatedText": "200 کسانوں اور 10 لائبریرین کا کہنا ہے کہ آپ کسانوں اور لائبریرین کے نمائندہ نمونے کی تصویر لگا کر شروعات کر سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.66,
  "end": 211.02
 },
 {
  "input": "Then when you hear of this meek and tidy soul description, let's say that your gut instinct is that 40% of librarians would fit that description, and that 10% of farmers would. ",
  "translatedText": "پھر جب آپ اس نرم اور صاف روح کی وضاحت کے بارے میں سنتے ہیں، تو آئیے کہ آپ کی آنت کی جبلت یہ ہے کہ 40% لائبریرین اس وضاحت کے مطابق ہوں گے، اور یہ کہ 10% کسان ہوں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.74,
  "end": 221.36
 },
 {
  "input": "If those are your estimates, it would mean that from your sample you would expect about 4 librarians to fit the description, and about 20 farmers to fit that description. ",
  "translatedText": "اگر یہ آپ کے تخمینے ہیں، تو اس کا مطلب یہ ہوگا کہ آپ کے نمونے سے آپ تقریباً 4 لائبریرین سے اس تفصیل کے مطابق ہونے کی توقع کریں گے، اور تقریباً 20 کسان اس تفصیل کے مطابق ہوں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.02,
  "end": 230.24
 },
 {
  "input": "So the probability that a random person among those who fit this description is a librarian is 4 out of 24, or 16.7%. ",
  "translatedText": "لہذا امکان ہے کہ ان لوگوں میں سے جو اس تفصیل کے مطابق ہوں ایک بے ترتیب شخص ایک لائبریرین ہے 24 میں سے 4، یا 16۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.02,
  "end": 240.1
 },
 {
  "input": "So even if you think that a librarian is 4 times as likely as a farmer to fit this description, that's not enough to overcome the fact that there are way more farmers. ",
  "translatedText": "7% لہذا یہاں تک کہ اگر آپ کو لگتا ہے کہ ایک لائبریرین کا اس تفصیل کے مطابق ہونے کا امکان ایک کسان کے مقابلے میں 4 گنا زیادہ ہے، تو یہ اس حقیقت پر قابو پانے کے لیے کافی نہیں ہے کہ اور بھی کسان موجود ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.1,
  "end": 249.02
 },
 {
  "input": "The upshot, and this is the key mantra underlying Bayes' theorem, is that new evidence does not completely determine your beliefs in a vacuum, it should update prior beliefs. ",
  "translatedText": "نتیجہ، اور یہ Bayes کے نظریہ کا بنیادی منتر ہے، یہ ہے کہ نئے شواہد خلا میں آپ کے عقائد کا مکمل تعین نہیں کرتے ہیں، اسے پہلے کے عقائد کو اپ ڈیٹ کرنا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.72,
  "end": 259.22
 },
 {
  "input": "If this line of reasoning makes sense to you, the way that seeing evidence restricts the space of possibilities and the ratio you need to consider after that, then congratulations, you understand the heart of Bayes' theorem. ",
  "translatedText": "اگر استدلال کی یہ سطر آپ کے لیے سمجھ میں آتی ہے، جس طرح سے شواہد کو دیکھنے سے امکانات کی جگہ اور اس کے بعد آپ کو جس تناسب پر غور کرنے کی ضرورت ہے، کو محدود کر دیتا ہے، تو مبارک ہو، آپ Bayes کے نظریے کے دل کو سمجھتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 261.12,
  "end": 272.36
 },
 {
  "input": "Maybe the numbers you would estimate would be a little different, but what matters is how you fit the numbers together to update your beliefs based on evidence. ",
  "translatedText": "ہوسکتا ہے کہ جن نمبروں کا آپ اندازہ کریں گے وہ تھوڑا مختلف ہوگا، لیکن جو بات اہم ہے وہ یہ ہے کہ آپ ثبوتوں کی بنیاد پر اپنے عقائد کو اپ ڈیٹ کرنے کے لیے نمبروں کو کس طرح ایک ساتھ فٹ کرتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.36,
  "end": 280.6
 },
 {
  "input": "Understanding one example is one thing, but see if you can take a minute to generalize everything we just did and write it all down as a formula. ",
  "translatedText": "ایک مثال کو سمجھنا ایک چیز ہے، لیکن دیکھیں کہ کیا آپ ان تمام چیزوں کو عام کرنے میں ایک منٹ لے سکتے ہیں جو ہم نے ابھی کیا ہے اور اسے ایک فارمولے کے طور پر لکھ سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.08,
  "end": 289.74
 },
 {
  "input": "The general situation where Bayes' theorem is relevant is when you have some hypothesis, like Steve is a librarian, and you see some new evidence, say this verbal description of Steve as a meek and tidy soul. ",
  "translatedText": "عمومی صورت حال جہاں Bayes کا نظریہ متعلقہ ہے وہ ہے جب آپ کے پاس کچھ مفروضہ ہے، جیسے کہ اسٹیو ایک لائبریرین ہے، اور آپ کو کچھ نئے شواہد نظر آتے ہیں، اسٹیو کی اس زبانی وضاحت کو ایک حلیم اور صاف روح کے طور پر کہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.32,
  "end": 303.98
 },
 {
  "input": "You want to know the probability that your hypothesis holds given that the evidence is true. ",
  "translatedText": "آپ اس امکان کو جاننا چاہتے ہیں کہ آپ کے مفروضے کے مطابق ثبوت درست ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.38,
  "end": 309.64
 },
 {
  "input": "In the standard notation, this vertical bar means given that, as in we're restricting our view only to the possibilities where the evidence holds. ",
  "translatedText": "معیاری اشارے میں، اس عمودی بار کا مطلب یہ ہے کہ، جیسا کہ ہم اپنے نقطہ نظر کو صرف ان امکانات تک محدود کر رہے ہیں جہاں ثبوت موجود ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.44,
  "end": 318.96
 },
 {
  "input": "Remember the first relevant number we used, the probability that the hypothesis holds before considering any of that new evidence. ",
  "translatedText": "پہلے متعلقہ نمبر کو یاد رکھیں جو ہم نے استعمال کیا تھا، اس امکان کا جو مفروضہ اس نئے ثبوت میں سے کسی پر غور کرنے سے پہلے رکھتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.22,
  "end": 327.34
 },
 {
  "input": "In our example, that was 1 out of 21, and it came from considering the ratio of librarians to farmers in the general population. ",
  "translatedText": "ہماری مثال میں، یہ 21 میں سے 1 تھا، اور یہ عام آبادی میں کسانوں اور لائبریرین کے تناسب پر غور کرنے سے آیا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.72,
  "end": 334.64
 },
 {
  "input": "This number is known as the prior. ",
  "translatedText": "یہ نمبر پہلے کے طور پر جانا جاتا ہے. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 335.52,
  "end": 336.98
 },
 {
  "input": "After that, we need to consider the proportion of librarians that fit this description, the probability that we would see the evidence given that the hypothesis is true. ",
  "translatedText": "اس کے بعد، ہمیں لائبریرین کے تناسب پر غور کرنے کی ضرورت ہے جو اس تفصیل سے مطابقت رکھتے ہیں، اس بات کا امکان کہ ہم ثبوت دیکھیں گے کہ مفروضہ درست ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.02,
  "end": 347.3
 },
 {
  "input": "Again, when you see this vertical bar, it means we're talking about some proportion of a limited part of the total space of possibilities. ",
  "translatedText": "ایک بار پھر، جب آپ اس عمودی بار کو دیکھتے ہیں، تو اس کا مطلب ہے کہ ہم امکانات کی کل جگہ کے محدود حصے کے کچھ تناسب کے بارے میں بات کر رہے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.1,
  "end": 354.84
 },
 {
  "input": "In this case, that limited part is the left side, where the hypothesis holds. ",
  "translatedText": "اس صورت میں، وہ محدود حصہ بائیں جانب ہے، جہاں مفروضہ موجود ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.32,
  "end": 359.3
 },
 {
  "input": "In the context of Bayes' theorem, this value also has a special name, it's called the likelihood. ",
  "translatedText": "Bayes کے نظریہ کے تناظر میں، اس قدر کا بھی ایک خاص نام ہے، اسے امکان کہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.96,
  "end": 364.64
 },
 {
  "input": "Similarly, you need to know how much of the other side of the space includes the evidence, the probability of seeing the evidence given that the hypothesis isn't true. ",
  "translatedText": "اسی طرح، آپ کو یہ جاننے کی ضرورت ہے کہ اسپیس کے دوسرے حصے میں کتنے ثبوت شامل ہیں، ثبوت کو دیکھنے کا امکان یہ ہے کہ مفروضہ درست نہیں ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.7,
  "end": 373.56
 },
 {
  "input": "This funny little elbow symbol is commonly used in probability to mean not. ",
  "translatedText": "یہ مضحکہ خیز چھوٹی کہنی کی علامت عام طور پر امکان میں استعمال ہوتی ہے جس کا مطلب نہیں ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.34,
  "end": 378.42
 },
 {
  "input": "So, with the notation in place, remember what our final answer was. ",
  "translatedText": "لہذا، اشارے کی جگہ کے ساتھ، یاد رکھیں کہ ہمارا حتمی جواب کیا تھا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.86,
  "end": 383.02
 },
 {
  "input": "The probability that our librarian hypothesis is true given the evidence is the total number of librarians fitting the evidence, 4, divided by the total number of people fitting the evidence, 24. ",
  "translatedText": "ثبوت کے پیش نظر ہمارے لائبریرین کا مفروضہ درست ہونے کا امکان ثبوت کو پورا کرنے والے لائبریرین کی کل تعداد ہے، 4، ثبوت کو موزوں کرنے والے لوگوں کی کل تعداد سے تقسیم، 24۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.36,
  "end": 394.88
 },
 {
  "input": "But where did that 4 come from? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.76,
  "end": 397.18
 },
 {
  "input": "Well, it's the total number of people, times the prior probability of being a librarian, giving us the 10 total librarians, times the probability that one of those fits the evidence. ",
  "translatedText": "لیکن وہ 4 کہاں سے آئے؟ ٹھیک ہے، یہ لوگوں کی کل تعداد ہے، لائبریرین ہونے کے پیشگی امکان سے کئی گنا، ہمیں 10 کل لائبریرین فراہم کرتا ہے، اس امکان سے کئی گنا زیادہ کہ ان میں سے ایک ثبوت پر فٹ بیٹھتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 397.84,
  "end": 408.42
 },
 {
  "input": "That same number shows up again in the denominator, but we need to add in the rest, the total number of people times the proportion who are not librarians, times the proportion of those who fit the evidence, which in our example gives 20. ",
  "translatedText": "وہی نمبر ہفت میں دوبارہ ظاہر ہوتا ہے، لیکن ہمیں باقی میں شامل کرنے کی ضرورت ہے، لوگوں کی کل تعداد اس تناسب سے جو لائبریرین نہیں ہیں، ان لوگوں کے تناسب سے گنا جو ثبوت کے مطابق ہیں، جو ہماری مثال میں 20 دیتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.22,
  "end": 422.14
 },
 {
  "input": "Now notice the total number of people here, 210, that gets cancelled out, and of course it should, that was just an arbitrary choice made for the sake of illustration. ",
  "translatedText": "اب یہاں لوگوں کی کل تعداد دیکھیں، 210، جو منسوخ ہو جاتے ہیں، اور یقیناً یہ ہونا چاہیے، یہ محض ایک صوابدیدی انتخاب تھا جو مثال کی خاطر کیا گیا تھا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.22,
  "end": 431.04
 },
 {
  "input": "This leaves us finally with a more abstract representation purely in terms of probabilities, and this, my friends, is Bayes' theorem. ",
  "translatedText": "یہ آخر کار ہمیں ایک اور تجریدی نمائندگی کے ساتھ چھوڑ دیتا ہے خالصتاً امکانات کے لحاظ سے، اور یہ، میرے دوست، Bayes کا نظریہ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 431.62,
  "end": 439.22
 },
 {
  "input": "More often, you see this denominator written simply as P of E, the total probability of seeing the evidence, which in our example would be the 24 out of 210. ",
  "translatedText": "زیادہ کثرت سے، آپ دیکھتے ہیں کہ اس ڈینومینیٹر کو صرف E کے P کے طور پر لکھا گیا ہے، ثبوت کو دیکھنے کا کل امکان، جو ہماری مثال میں 210 میں سے 24 ہوگا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 440.42,
  "end": 450.46
 },
 {
  "input": "But in practice, to calculate it, you almost always have to break it down into the case where the hypothesis is true, and the one where it isn't. ",
  "translatedText": "لیکن عملی طور پر، اس کا حساب لگانے کے لیے، آپ کو اسے تقریباً ہمیشہ اس صورت میں توڑنا پڑتا ہے جہاں مفروضہ درست ہے، اور جہاں یہ نہیں ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 458.8
 },
 {
  "input": "Capping things off with one final bit of jargon, this answer is called the posterior, it's your belief about the hypothesis after seeing the evidence. ",
  "translatedText": "چیزوں کو ایک آخری لفظ کے ساتھ بند کرتے ہوئے، اس جواب کو پوسٹرئیر کہا جاتا ہے، یہ ثبوت دیکھنے کے بعد مفروضے کے بارے میں آپ کا عقیدہ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.06,
  "end": 468.6
 },
 {
  "input": "Writing it out abstractly might seem more complicated than just thinking through the example directly with a representative sample. ",
  "translatedText": "اسے خلاصہ طور پر لکھنا محض نمائندہ نمونے کے ساتھ براہ راست مثال کے ذریعے سوچنے سے زیادہ پیچیدہ معلوم ہو سکتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.16,
  "end": 476.5
 },
 {
  "input": "And yeah, it is. ",
  "translatedText": "اور ہاں، یہ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 476.92,
  "end": 478.78
 },
 {
  "input": "Keep in mind though, the value of a formula like this is that it lets you quantify and systematize the idea of changing beliefs. ",
  "translatedText": "اگرچہ ذہن میں رکھیں، اس طرح کے فارمولے کی قدر یہ ہے کہ یہ آپ کو عقائد کو تبدیل کرنے کے خیال کو مقدار اور منظم کرنے دیتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.2,
  "end": 486.26
 },
 {
  "input": "Scientists use this formula when they're analyzing the extent to which new data validates or invalidates their models. ",
  "translatedText": "سائنس دان اس فارمولے کا استعمال اس وقت کرتے ہیں جب وہ اس حد تک تجزیہ کر رہے ہوتے ہیں کہ نیا ڈیٹا ان کے ماڈلز کو کس حد تک توثیق یا باطل کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.94,
  "end": 492.84
 },
 {
  "input": "Programmers will sometimes use it in building artificial intelligence, where at times you want to explicitly and numerically model a machine's belief. ",
  "translatedText": "پروگرامرز بعض اوقات اسے مصنوعی ذہانت کی تعمیر میں استعمال کریں گے، جہاں بعض اوقات آپ واضح طور پر اور عددی طور پر مشین کے عقیدے کا نمونہ بنانا چاہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 492.84,
  "end": 500.64
 },
 {
  "input": "And honestly, just for the way you view yourself and your own opinions and what it takes for your mind to change, Bayes' theorem has a way of reframing how you even think about thought itself. ",
  "translatedText": "اور ایمانداری سے، جس طرح سے آپ اپنے آپ کو اور اپنی رائے کو دیکھتے ہیں اور آپ کے ذہن کو تبدیل کرنے میں کیا ضرورت ہے، Bayes کے نظریہ میں یہ ریفرم کرنے کا طریقہ ہے کہ آپ خود سوچ کے بارے میں بھی کیسے سوچتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 501.4,
  "end": 510.82
 },
 {
  "input": "Putting a formula to it can also be more important as the examples get more and more intricate. ",
  "translatedText": "اس پر فارمولہ ڈالنا بھی زیادہ اہم ہوسکتا ہے کیونکہ مثالیں زیادہ سے زیادہ پیچیدہ ہوتی جاتی ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.3,
  "end": 516.34
 },
 {
  "input": "However you write it, I actually encourage you not to try memorizing the formula, but to instead draw out this diagram as needed. ",
  "translatedText": "بہر حال آپ اسے لکھتے ہیں، میں درحقیقت آپ کی حوصلہ افزائی کرتا ہوں کہ فارمولہ کو یاد کرنے کی کوشش نہ کریں، بلکہ ضرورت کے مطابق اس خاکہ کو کھینچیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.08,
  "end": 524.68
 },
 {
  "input": "It's sort of a distilled version of thinking with a representative sample, where we think with areas instead of counts, which is more flexible and easier to sketch on the fly. ",
  "translatedText": "یہ نمائندہ نمونے کے ساتھ سوچنے کا ایک ڈسٹل ورژن ہے، جہاں ہم شمار کے بجائے علاقوں کے ساتھ سوچتے ہیں، جو مکھی پر خاکہ بنانا زیادہ لچکدار اور آسان ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.26,
  "end": 533.62
 },
 {
  "input": "Rather than bringing to mind some specific number of examples, like 210, think of the space of all possibilities as a 1x1 square. ",
  "translatedText": "مثالوں کی کچھ مخصوص تعداد کو ذہن میں لانے کے بجائے، جیسے 210، تمام امکانات کی جگہ کو 1x1 مربع کے طور پر سوچیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.26,
  "end": 541.38
 },
 {
  "input": "Then any event occupies some subset of this space, and the probability of that event can be thought about as the area of that subset. ",
  "translatedText": "پھر کوئی بھی واقعہ اس جگہ کے کچھ ذیلی سیٹ پر قبضہ کرتا ہے، اور اس واقعہ کے امکان کو اس سب سیٹ کے رقبے کے طور پر سوچا جا سکتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 542.12,
  "end": 550.94
 },
 {
  "input": "For example, I like to think of the hypothesis as living in the left part of the square with a width of p of h. ",
  "translatedText": "مثال کے طور پر، میں p کی چوڑائی کے ساتھ مربع کے بائیں حصے میں رہنے والے مفروضے کے بارے میں سوچنا پسند کرتا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.54,
  "end": 557.66
 },
 {
  "input": "I recognize I'm being a bit repetitive, but when you see evidence, the space of possibilities gets restricted, and the crucial part is that restriction might not be even between the left and the right, so the new probability for the hypothesis is the proportion it occupies in this restricted wonky shape. ",
  "translatedText": "میں تسلیم کرتا ہوں کہ میں تھوڑا سا دہرایا جا رہا ہوں، لیکن جب آپ ثبوت دیکھتے ہیں، امکانات کی جگہ محدود ہو جاتی ہے، اور اہم بات یہ ہے کہ پابندی بائیں اور دائیں کے درمیان بھی نہیں ہوسکتی ہے، اس لیے مفروضے کے لیے نیا امکان ہے تناسب یہ اس محدود ونکی شکل میں قابض ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.32,
  "end": 576.94
 },
 {
  "input": "Now if you think a farmer is just as likely to fit the evidence as a librarian, then the proportion doesn't change, which should make sense, right? ",
  "translatedText": "اب اگر آپ کو لگتا ہے کہ ایک کسان کا لائبریرین کی طرح شواہد پر فٹ ہونے کا امکان ہے، تو تناسب تبدیل نہیں ہوتا، جس کا مطلب ہونا چاہیے، ٹھیک ہے؟ اور ثبوت آپ کے عقائد کو تبدیل نہیں کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.64,
  "end": 586.24
 },
 {
  "input": "And evidence doesn't change your beliefs. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.26,
  "end": 588.32
 },
 {
  "input": "But when these likelihoods are very different from each other, that's when your belief changes a lot. ",
  "translatedText": "لیکن جب یہ امکانات ایک دوسرے سے بہت مختلف ہوتے ہیں، تب ہی آپ کا یقین بہت بدل جاتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.9,
  "end": 593.48
 },
 {
  "input": "Bayes' theorem spells out what that proportion is, and if you want you can read it geometrically. ",
  "translatedText": "Bayes کا نظریہ یہ بتاتا ہے کہ وہ تناسب کیا ہے، اور اگر آپ چاہیں تو آپ اسے ہندسی طور پر پڑھ سکتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.76,
  "end": 600.52
 },
 {
  "input": "Something like p of h times p of e given h, the probability of both the hypothesis and the evidence occurring together, is the width times the height of this little left rectangle, the area of that region. ",
  "translatedText": "کچھ ایسی چیز ہے جیسے کہ p کا h گنا e دیا گیا ہے، مفروضے اور ثبوت دونوں کا ایک ساتھ ہونے کا امکان، اس چھوٹے بائیں مستطیل کی چوڑائی گنا اونچائی ہے، اس علاقے کا رقبہ۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 600.9,
  "end": 613.08
 },
 {
  "input": "Alright, this is probably a good time to take a step back and consider a few of the broader takeaways about how to make probability more intuitive, beyond Bayes' theorem. ",
  "translatedText": "ٹھیک ہے، شاید یہ ایک اچھا وقت ہے کہ ایک قدم پیچھے ہٹیں اور Bayes کے تھیوریم سے ہٹ کر امکان کو مزید بدیہی بنانے کے بارے میں چند وسیع تر طریقوں پر غور کریں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 614.76,
  "end": 623.22
 },
 {
  "input": "First off, notice how the trick of thinking about a representative sample with some specific number of people, like our 210 librarians and farmers, was really helpful. ",
  "translatedText": "سب سے پہلے، دیکھیں کہ ہمارے 210 لائبریرین اور کسانوں کی طرح کچھ مخصوص لوگوں کے ساتھ نمائندہ نمونے کے بارے میں سوچنے کی چال کس طرح مددگار ثابت ہوئی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.78,
  "end": 632.4
 },
 {
  "input": "There's actually another Kahneman and Tversky result which is all about this, and it's interesting enough to interject here. ",
  "translatedText": "اصل میں ایک اور Kahneman اور Tversky نتیجہ ہے جو اس کے بارے میں ہے، اور یہ یہاں مداخلت کرنا کافی دلچسپ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.96,
  "end": 638.38
 },
 {
  "input": "They did this experiment that was similar to the one with Steve, but where people were given the following description of a fictitious woman named Linda. ",
  "translatedText": "انہوں نے یہ تجربہ کیا جو اسٹیو کے ساتھ کیا گیا تھا، لیکن جہاں لوگوں کو لنڈا نامی ایک فرضی خاتون کی مندرجہ ذیل تفصیل دی گئی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 638.52,
  "end": 645.72
 },
 {
  "input": "Linda is 31 years old, single, outspoken, and very bright. ",
  "translatedText": "لنڈا کی عمر 31 سال ہے، اکیلی، اوٹ پٹانگ اور بہت روشن۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.4,
  "end": 650.62
 },
 {
  "input": "She majored in philosophy. ",
  "translatedText": "اس نے فلسفے میں تعلیم حاصل کی۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.14,
  "end": 652.16
 },
 {
  "input": "As a student she was deeply concerned with issues of discrimination and social justice, and also participated in the anti-nuclear demonstrations. ",
  "translatedText": "ایک طالب علم کے طور پر وہ امتیازی سلوک اور سماجی انصاف کے مسائل پر گہری تشویش رکھتی تھیں، اور ایٹمی مخالف مظاہروں میں بھی حصہ لیتی تھیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.64,
  "end": 659.54
 },
 {
  "input": "After seeing this people were asked what's more likely, 1. ",
  "translatedText": "اس کو دیکھنے کے بعد لوگوں سے پوچھا گیا کہ زیادہ امکان کیا ہے، 1۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 660.7,
  "end": 664.02
 },
 {
  "input": "That Linda is a bank teller, or 2. ",
  "translatedText": "وہ لنڈا ایک بینک ٹیلر ہے، یا 2۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 664.34,
  "end": 666.46
 },
 {
  "input": "That Linda is a bank teller and is active in the feminist movement. ",
  "translatedText": "کہ لنڈا ایک بینک ٹیلر ہے اور حقوق نسواں کی تحریک میں سرگرم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.92,
  "end": 669.9
 },
 {
  "input": "85%, 85% of participants said that the latter is more likely than the former, even though the set of bank tellers who are active in the feminist movement is a subset of the set of bank tellers. ",
  "translatedText": "85%، 85% شرکاء نے کہا کہ مؤخر الذکر کا سابقہ سے زیادہ امکان ہے، حالانکہ بینک ٹیلروں کا سیٹ جو حقوق نسواں کی تحریک میں سرگرم ہیں، بینک ٹیلروں کے سیٹ کا سب سیٹ ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.22,
  "end": 683.32
 },
 {
  "input": "It has to be smaller. ",
  "translatedText": "اسے چھوٹا ہونا چاہیے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.56,
  "end": 684.68
 },
 {
  "input": "So that's interesting enough, but what's fascinating is that there's a simple way that you can rephrase the question that dropped this error from 85% to 0. ",
  "translatedText": "تو یہ کافی دلچسپ ہے، لیکن دلچسپ بات یہ ہے کہ ایک آسان طریقہ ہے کہ آپ اس سوال کو دوبارہ بیان کر سکتے ہیں جس نے اس غلطی کو 85% سے 0 تک گرا دیا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.64,
  "end": 694.1
 },
 {
  "input": "Instead, if participants were told that there are 100 people who fit this description, and then asked to estimate how many of those 100 are bank tellers, and how many are bank tellers active in the feminist movement, nobody makes the error. ",
  "translatedText": "اس کے بجائے، اگر شرکاء کو بتایا جائے کہ 100 لوگ ہیں جو اس تفصیل کے مطابق ہیں، اور پھر اندازہ لگانے کے لیے کہا جائے کہ ان 100 میں سے کتنے بینک ٹیلر ہیں، اور کتنے بینک ٹیلر ہیں جو حقوق نسواں کی تحریک میں سرگرم ہیں، کوئی بھی غلطی نہیں کرتا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.96,
  "end": 708.5
 },
 {
  "input": "Everybody correctly assigns a higher number to the first option than to the second. ",
  "translatedText": "ہر کوئی صحیح طریقے سے پہلے آپشن کو دوسرے سے زیادہ نمبر دیتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.5,
  "end": 713.18
 },
 {
  "input": "It's weird, somehow phrases like 40 out of 100 kick our intuitions into gear much more effectively than 40%, much less 0.4, and much less abstractly referencing the idea of something being more or less likely. ",
  "translatedText": "یہ عجیب ہے، کسی نہ کسی طرح 100 میں سے 40 جیسے جملے ہمارے وجدان کو 40 فیصد سے کہیں زیادہ مؤثر طریقے سے گیئر میں لاتے ہیں، بہت کم 0۔4، اور بہت کم تجریدی طور پر کسی چیز کے زیادہ یا کم امکان ہونے کے خیال کا حوالہ دینا۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 714.78,
  "end": 728.06
 },
 {
  "input": "That said, representative samples don't easily capture the continuous nature of probability. ",
  "translatedText": "اس نے کہا، نمائندہ نمونے امکان کی مسلسل نوعیت کو آسانی سے نہیں پکڑتے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.4,
  "end": 734.1
 },
 {
  "input": "So turning to area is a nice alternative, not just because of the continuity, but also because it's way easier to sketch out when you're sitting there pencil and paper puzzling over some problem. ",
  "translatedText": "اس لیے علاقے کا رخ کرنا ایک اچھا متبادل ہے، نہ صرف تسلسل کی وجہ سے، بلکہ اس لیے بھی کہ جب آپ وہاں بیٹھے ہوئے پنسل اور کاغذ پر کسی مسئلے پر الجھا رہے ہوں تو اس کا خاکہ بنانا آسان ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.1,
  "end": 744.04
 },
 {
  "input": "People often think about probability as being the study of uncertainty, and that is of course how it's applied in science, but the actual math of probability, where all the formulas come from, is just the math of proportions, and in that context turning to geometry is exceedingly helpful. ",
  "translatedText": "لوگ اکثر امکان کے بارے میں سوچتے ہیں کہ یہ غیر یقینی صورتحال کا مطالعہ ہے، اور یقیناً اس کا سائنس میں اطلاق کیا جاتا ہے، لیکن امکان کی اصل ریاضی، جہاں سے تمام فارمولے آتے ہیں، صرف تناسب کی ریاضی ہے، اور اس تناظر میں جیومیٹری بہت مددگار ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.22,
  "end": 761.02
 },
 {
  "input": "I mean, take a look at Bayes' theorem as a statement about proportions, whether that's proportions of people, of areas, whatever. ",
  "translatedText": "میرا مطلب ہے، تناسب کے بارے میں بیان کے طور پر Bayes کے تھیوریم پر ایک نظر ڈالیں، چاہے وہ لوگوں کا تناسب ہو، علاقوں کا، جو بھی ہو۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 764.26,
  "end": 770.72
 },
 {
  "input": "Once you digest what it's saying, it's actually kind of obvious. ",
  "translatedText": "ایک بار جب آپ ہضم کر لیتے ہیں کہ یہ کیا کہہ رہا ہے، تو یہ حقیقت میں ایک طرح سے واضح ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 771.3,
  "end": 774.46
 },
 {
  "input": "Both sides tell you to look at the cases where the evidence is true, and then to consider the proportion of those cases where the hypothesis is also true. ",
  "translatedText": "دونوں فریق آپ کو کہتے ہیں کہ ان مقدمات کو دیکھیں جہاں ثبوت درست ہیں، اور پھر ان مقدمات کے تناسب پر غور کریں جہاں مفروضہ بھی درست ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 775.04,
  "end": 782.72
 },
 {
  "input": "That's it, that's all it's saying. ",
  "translatedText": "بس، بس اتنا ہی کہہ رہا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.24,
  "end": 784.64
 },
 {
  "input": "The right-hand side just spells out how to compute it. ",
  "translatedText": "دائیں طرف صرف یہ بتاتا ہے کہ اس کی گنتی کیسے کی جائے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 784.86,
  "end": 786.9
 },
 {
  "input": "What's noteworthy is that such a straightforward fact about proportions can become hugely significant for science, for artificial intelligence, and really any situation where you want to quantify belief. ",
  "translatedText": "قابل ذکر بات یہ ہے کہ تناسب کے بارے میں ایسی سیدھی حقیقت سائنس، مصنوعی ذہانت اور واقعی کسی بھی ایسی صورت حال کے لیے بہت اہم ہو سکتی ہے جہاں آپ عقیدے کی مقدار درست کرنا چاہتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.54,
  "end": 797.92
 },
 {
  "input": "I hope to give you a better glimpse of that as we get into more examples. ",
  "translatedText": "میں آپ کو اس کی ایک بہتر جھلک دینے کی امید کرتا ہوں جیسا کہ ہم مزید مثالیں دیکھیں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.54,
  "end": 801.42
 },
 {
  "input": "But before more examples, we have a little bit of unfinished business with Steve. ",
  "translatedText": "لیکن مزید مثالوں سے پہلے، ہمارے پاس سٹیو کے ساتھ تھوڑا سا نامکمل کاروبار ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 802.38,
  "end": 805.74
 },
 {
  "input": "As I mentioned, some psychologists debate Kahneman and Tversky's conclusion that the rational thing to do is to bring to mind the ratio of farmers to librarians. ",
  "translatedText": "جیسا کہ میں نے ذکر کیا، کچھ ماہر نفسیات کاہنیمن اور ٹورسکی کے اس نتیجے پر بحث کرتے ہیں کہ عقلی بات یہ ہے کہ کسانوں اور لائبریرین کے تناسب کو ذہن میں لایا جائے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.48,
  "end": 814.8
 },
 {
  "input": "They complain that the context is ambiguous. ",
  "translatedText": "وہ شکایت کرتے ہیں کہ سیاق و سباق مبہم ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 815.14,
  "end": 817.26
 },
 {
  "input": "I mean, who is Steve, exactly? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 817.92,
  "end": 819.84
 },
 {
  "input": "Should you expect that he's a randomly sampled American? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.84,
  "end": 822.66
 },
 {
  "input": "Or would you be better to assume that he's a friend of the two psychologists interrogating you? ",
  "translatedText": "میرا مطلب ہے، بالکل اسٹیو کون ہے؟ کیا آپ کو توقع کرنی چاہئے کہ وہ تصادفی طور پر نمونہ دار امریکی ہے؟ یا آپ کو یہ فرض کرنا بہتر ہوگا کہ وہ آپ سے پوچھ گچھ کرنے والے دو ماہر نفسیات کا دوست ہے؟ یا ہوسکتا ہے کہ وہ کوئی ہے جسے آپ ذاتی طور پر جانتے ہوں گے؟ یہ مفروضہ پہلے کا تعین کرتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 823.26,
  "end": 827.0
 },
 {
  "input": "Or maybe that he's someone you're personally likely to know? ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 827.22,
  "end": 829.74
 },
 {
  "input": "This assumption determines the prior. ",
  "translatedText": "",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.42,
  "end": 832.4
 },
 {
  "input": "I for one run into way more librarians in a given month than I do farmers. ",
  "translatedText": "میں ایک مہینے میں کسانوں سے زیادہ لائبریرین کی طرف بھاگتا ہوں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.96,
  "end": 836.68
 },
 {
  "input": "Needless to say, the probability of a librarian or a farmer fitting this description is highly open to interpretation. ",
  "translatedText": "یہ کہنے کی ضرورت نہیں کہ کسی لائبریرین یا کسان کے اس تفصیل کے مطابق ہونے کا امکان بہت زیادہ تشریح کے لیے کھلا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 837.5,
  "end": 843.52
 },
 {
  "input": "For our purposes, understanding the math, what I want to emphasize is that any question worth debating here can be pictured in the context of the diagram. ",
  "translatedText": "ہمارے مقاصد کے لیے، ریاضی کو سمجھتے ہوئے، میں جس چیز پر زور دینا چاہتا ہوں وہ یہ ہے کہ یہاں بحث کرنے کے قابل کوئی بھی سوال خاکہ کے تناظر میں پیش کیا جا سکتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 844.44,
  "end": 852.3
 },
 {
  "input": "Questions about the context shift around the prior, and questions about the personalities and stereotypes shift around the relevant likelihoods. ",
  "translatedText": "سیاق و سباق کے بارے میں سوالات پہلے کے ارد گرد بدلتے ہیں، اور شخصیات اور دقیانوسی تصورات کے بارے میں سوالات متعلقہ امکانات کے گرد بدلتے ہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 853.0,
  "end": 860.58
 },
 {
  "input": "All that said, whether or not you buy this particular experiment, the ultimate point that evidence should not determine beliefs, but update them, is worth tattooing in your brain. ",
  "translatedText": "جو کچھ کہا گیا ہے، چاہے آپ یہ خاص تجربہ خریدیں یا نہیں، حتمی نکتہ کہ ثبوت کو عقائد کا تعین نہیں کرنا چاہیے، بلکہ ان کو اپ ڈیٹ کرنا چاہیے، آپ کے دماغ میں ٹیٹو بنانے کے قابل ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 861.1,
  "end": 871.0
 },
 {
  "input": "I'm in no position to say whether this does or does not run against natural human instinct. ",
  "translatedText": "میں یہ کہنے کی پوزیشن میں نہیں ہوں کہ آیا یہ فطری انسانی جبلت کے خلاف ہے یا نہیں۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.8,
  "end": 876.5
 },
 {
  "input": "We'll leave that to the psychologists. ",
  "translatedText": "ہم اسے ماہرین نفسیات پر چھوڑ دیں گے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 876.5,
  "end": 878.24
 },
 {
  "input": "What's more interesting to me is how we can reprogram our intuition to authentically reflect the implications of math, and bringing to mind the right image can often do just that. ",
  "translatedText": "میرے لیے سب سے زیادہ دلچسپ بات یہ ہے کہ ہم ریاضی کے مضمرات کو مستند طریقے سے ظاہر کرنے کے لیے اپنے وجدان کو کیسے دوبارہ پروگرام کر سکتے ہیں، اور صحیح تصویر کو ذہن میں لانا اکثر ایسا ہی کر سکتا ہے۔",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 878.92,
  "end": 888.06
 }
]