[
 {
  "input": "The goal is for you to come away from this video understanding one of the most important formulas in all of probability, Bayes' theorem.",
  "translatedText": "Amacınız bu videodan tüm olasılıkların en önemli formüllerinden biri olan Bayes teoremini anlamanızdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 0.0,
  "end": 6.84
 },
 {
  "input": "This formula is central to scientific discovery, it's a core tool in machine learning and AI, and it's even been used for treasure hunting, when in the 1980s a small team led by Tommy Thompson, and I'm not making up that name, used Bayesian search tactics to help uncover a ship that had sunk a century and a half earlier, and the ship was carrying what in today's terms amounts to $700 million worth of gold.",
  "translatedText": "Bu formül bilimsel keşiflerin merkezinde yer alır, makine öğrenimi ve yapay zekada temel bir araçtır ve hatta hazine avcılığı için bile kullanılmıştır, 1980'lerde Tommy Thompson liderliğindeki küçük bir ekip, ben bu ismi uydurmuyorum, kullanılmıştı. Bayesci arama taktikleri, bir buçuk yüzyıl önce batmış bir geminin ortaya çıkarılmasına yardımcı oldu ve gemi, bugünün şartlarıyla 700 milyon dolar değerinde altın taşıyordu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 7.48,
  "end": 30.74
 },
 {
  "input": "So it's a formula worth understanding, but of course there are multiple different levels of possible understanding.",
  "translatedText": "Yani bu, anlamaya değer bir formül, ama elbette, mümkün olan birden fazla farklı anlayış düzeyi var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.34,
  "end": 37.04
 },
 {
  "input": "At the simplest there's just knowing what each one of the parts means, so that you can plug in numbers.",
  "translatedText": "En basitinde, her bir parçanın ne anlama geldiğini bilmek yeterlidir, böylece sayıları girebilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 37.6,
  "end": 42.04
 },
 {
  "input": "Then there's understanding why it's true, and later I'm going to show you a certain diagram that's helpful for rediscovering this formula on the fly as needed.",
  "translatedText": "Daha sonra bunun neden doğru olduğu anlaşılır ve daha sonra size bu formülü gerektiğinde anında yeniden keşfetmenize yardımcı olacak belirli bir diyagram göstereceğim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.76,
  "end": 50.58
 },
 {
  "input": "But maybe the most important level is being able to recognize when you need to use it.",
  "translatedText": "Ama belki de en önemli seviye onu ne zaman kullanmanız gerektiğinin farkına varabilmektir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.24,
  "end": 55.54
 },
 {
  "input": "And with the goal of gaining a deeper understanding, you and I are going to tackle these in reverse order.",
  "translatedText": "Ve daha derin bir anlayış kazanmak amacıyla, sen ve ben bunları ters sırayla ele alacağız.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 55.54,
  "end": 60.56
 },
 {
  "input": "So before dissecting the formula or explaining the visual that makes it obvious, I'd like to tell you about a man named Steve.",
  "translatedText": "Formülü parçalara ayırmadan ya da bunu açıkça ortaya koyan görseli açıklamadan önce size Steve adında bir adamdan bahsetmek istiyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 61.02,
  "end": 66.86
 },
 {
  "input": "Listen carefully now.",
  "translatedText": "Şimdi dikkatlice dinle.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.32,
  "end": 68.72
 },
 {
  "input": "Steve is very shy and withdrawn, invariably helpful but with very little interest in people or the world of reality.",
  "translatedText": "Steve çok utangaç ve içine kapanıktır, her zaman yardımseverdir ancak insanlara ya da gerçeklik dünyasına çok az ilgi duyar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 72.74,
  "end": 79.16
 },
 {
  "input": "A meek and tidy soul, he has a need for order and structure, and a passion for detail.",
  "translatedText": "Uysal ve düzenli bir ruha sahiptir, düzene ve yapıya ihtiyaç duyar ve ayrıntıya tutku duyar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 79.74,
  "end": 84.1
 },
 {
  "input": "Which of the following do you find more likely?",
  "translatedText": "Aşağıdakilerden hangisini daha muhtemel buluyorsunuz?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.62,
  "end": 86.78
 },
 {
  "input": "Steve is a librarian, or Steve is a farmer?",
  "translatedText": "Steve bir kütüphaneci mi yoksa Steve bir çiftçi mi?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.2,
  "end": 90.38
 },
 {
  "input": "Some of you may recognize this as an example from a study conducted by the two psychologists Daniel Kahneman and Amos Tversky.",
  "translatedText": "Bazılarınız bunu iki psikolog Daniel Kahneman ve Amos Tversky tarafından yürütülen bir çalışmadan örnek olarak görebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 91.4,
  "end": 97.44
 },
 {
  "input": "Their work was a big deal, it won a Nobel Prize, and it's been popularized many times over in books like Kahneman's Thinking Fast and Slow, or Michael Lewis's The Undoing Project.",
  "translatedText": "Çalışmaları büyük önem taşıyordu, Nobel Ödülü kazandı ve Kahneman'ın Hızlı ve Yavaş Düşünmek veya Michael Lewis'in Geri Alma Projesi gibi kitaplarda birçok kez popüler hale getirildi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.2,
  "end": 106.56
 },
 {
  "input": "What they researched was human judgments, with a frequent focus on when these judgments irrationally contradict what the laws of probability suggest they should be.",
  "translatedText": "Araştırdıkları şey insan yargılarıydı ve sıklıkla bu yargıların olasılık yasalarının önerdiği şeylerle mantıksız bir şekilde çeliştiği durumlara odaklanılıyordu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.42,
  "end": 115.78
 },
 {
  "input": "The example with Steve, our maybe librarian, maybe farmer, illustrates one specific type of irrationality, or maybe I should say alleged irrationality, there are people who debate the conclusion here, but more on that later on.",
  "translatedText": "Belki kütüphanecimiz, belki de çiftçimiz olan Steve'le verdiğimiz örnek, belirli bir tür mantıksızlığı gösteriyor, ya da belki iddia edilen mantıksızlığı söylemeliyim, burada sonucu tartışan insanlar var, ancak daha sonra buna daha fazla değineceğiz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.34,
  "end": 129.62
 },
 {
  "input": "According to Kahneman and Tversky, after people are given this description of Steve as a meek and tidy soul, most say he's more likely to be a librarian.",
  "translatedText": "Kahneman ve Tversky'ye göre, insanlara Steve'in uysal ve düzenli bir ruhlu olduğu söylendikten sonra çoğu kişi onun bir kütüphaneci olma ihtimalinin daha yüksek olduğunu söylüyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.98,
  "end": 138.0
 },
 {
  "input": "After all, these traits line up better with the stereotypical view of a librarian than a farmer.",
  "translatedText": "Sonuçta, bu özellikler bir çiftçinin yerine bir kütüphanecinin basmakalıp görüşüne daha çok uyuyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 138.0,
  "end": 143.46
 },
 {
  "input": "And according to Kahneman and Tversky, this is irrational.",
  "translatedText": "Kahneman ve Tversky'ye göre bu mantıksızdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.2,
  "end": 146.88
 },
 {
  "input": "The point is not whether people hold correct or biased views about the personalities of librarians and farmers, it's that almost nobody thinks to incorporate information about the ratio of farmers to librarians in their judgments.",
  "translatedText": "Mesele, insanların kütüphanecilerin ve çiftçilerin kişilikleri hakkında doğru veya önyargılı görüşlere sahip olup olmadıkları değil, neredeyse hiç kimsenin çiftçilerin kütüphanecilere oranı hakkındaki bilgileri kararlarına dahil etmeyi düşünmemesidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 147.6,
  "end": 160.24
 },
 {
  "input": "In their paper, Kahneman and Tversky said that in the US, that ratio is about 20 to 1.",
  "translatedText": "Kahneman ve Tversky makalelerinde ABD'de bu oranın yaklaşık 20'ye 1 olduğunu söyledi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 160.92,
  "end": 165.18
 },
 {
  "input": "The numbers I could find today put that much higher, but let's stick with the 20 to 1 number, since it's a little easier to illustrate and proves the point as well.",
  "translatedText": "Bugün bulabildiğim rakamlar çok daha yüksek, ancak 20'ye 1 rakamına sadık kalalım, çünkü bunu açıklamak biraz daha kolay ve aynı zamanda bunu kanıtlıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 165.58,
  "end": 173.42
 },
 {
  "input": "To be clear, anyone who is asked this question is not expected to have perfect information about the actual statistics of farmers and librarians and their personality traits.",
  "translatedText": "Açıkça söylemek gerekirse, bu soruyu soran herkesin çiftçilerin ve kütüphanecilerin gerçek istatistikleri ve kişilik özellikleri hakkında mükemmel bilgiye sahip olması beklenmiyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 174.28,
  "end": 183.14
 },
 {
  "input": "But the question is whether people even think to consider that ratio enough to at least make a rough estimate.",
  "translatedText": "Ancak asıl soru, insanların bu oranı en azından kaba bir tahminde bulunmaya yetecek kadar dikkate almayı düşünüp düşünmedikleridir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.68,
  "end": 189.22
 },
 {
  "input": "Rationality is not about knowing facts, it's about recognizing which facts are relevant.",
  "translatedText": "Mantıklılık gerçekleri bilmekle ilgili değil, hangi gerçeklerin konuyla ilgili olduğunu tanımakla ilgilidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.04,
  "end": 194.46
 },
 {
  "input": "Now if you do think to make that estimate, there's a pretty simple way to reason about the question, which, spoiler alert, involves all of the essential reasoning behind Bayes' theorem.",
  "translatedText": "Şimdi, eğer bu tahmini yapmayı düşünüyorsanız, soru hakkında mantık yürütmenin oldukça basit bir yolu var ki bu, spoiler uyarısı, Bayes teoreminin ardındaki tüm temel akıl yürütmeyi içeriyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.88,
  "end": 203.9
 },
 {
  "input": "You might start by picturing a representative sample of farmers and librarians, say 200 farmers and 10 librarians.",
  "translatedText": "Çiftçilerin ve kütüphanecilerin temsili bir örneğini, örneğin 200 çiftçi ve 10 kütüphaneciyi resmederek başlayabilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 204.66,
  "end": 211.02
 },
 {
  "input": "Then when you hear of this meek and tidy soul description, let's say that your gut instinct is that 40% of librarians would fit that description, and that 10% of farmers would.",
  "translatedText": "O zaman bu uysal ve düzenli ruh tanımını duyduğunuzda, diyelim ki içgüdünüz kütüphanecilerin %40'ının ve çiftçilerin %10'unun bu tanıma uyacağını söylüyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 211.74,
  "end": 221.36
 },
 {
  "input": "If those are your estimates, it would mean that from your sample you would expect about 4 librarians to fit the description, and about 20 farmers to fit that description.",
  "translatedText": "Tahminleriniz bunlarsa, bu, örnekleminizden yaklaşık 4 kütüphanecinin bu tanıma uymasını ve yaklaşık 20 çiftçinin de bu tanıma uymasını beklediğiniz anlamına gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.02,
  "end": 230.24
 },
 {
  "input": "So the probability that a random person among those who fit this description is a librarian is 4 out of 24, or 16.7%.",
  "translatedText": "Yani bu tanıma uyan kişiler arasında rastgele bir kişinin kütüphaneci olma olasılığı 24 üzerinden 4 yani 16'dır.%7.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.02,
  "end": 240.1
 },
 {
  "input": "So even if you think that a librarian is 4 times as likely as a farmer to fit this description, that's not enough to overcome the fact that there are way more farmers.",
  "translatedText": "Yani bir kütüphanecinin bu tanıma uyma olasılığının bir çiftçiden 4 kat daha fazla olduğunu düşünseniz bile, bu, çok daha fazla çiftçinin olduğu gerçeğinin üstesinden gelmek için yeterli değildir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.1,
  "end": 249.02
 },
 {
  "input": "The upshot, and this is the key mantra underlying Bayes' theorem, is that new evidence does not completely determine your beliefs in a vacuum, it should update prior beliefs.",
  "translatedText": "Sonuç, Bayes teoreminin altında yatan anahtar mantradır, yeni kanıt inançlarınızı bir boşlukta tamamen belirlemez, önceki inançları güncellemelidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 249.72,
  "end": 259.22
 },
 {
  "input": "If this line of reasoning makes sense to you, the way that seeing evidence restricts the space of possibilities and the ratio you need to consider after that, then congratulations, you understand the heart of Bayes' theorem.",
  "translatedText": "Eğer bu akıl yürütme tarzı size mantıklı geliyorsa, kanıt görmenin olasılıklar alanını ve bundan sonra dikkate almanız gereken oranı kısıtlaması, o zaman tebrikler, Bayes teoreminin özünü anlıyorsunuz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 261.12,
  "end": 272.36
 },
 {
  "input": "Maybe the numbers you would estimate would be a little different, but what matters is how you fit the numbers together to update your beliefs based on evidence.",
  "translatedText": "Belki tahmin edeceğiniz rakamlar biraz farklı olabilir, ancak önemli olan inançlarınızı kanıta dayalı olarak güncellemek için sayıları nasıl bir araya getirdiğinizdir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.36,
  "end": 280.6
 },
 {
  "input": "Understanding one example is one thing, but see if you can take a minute to generalize everything we just did and write it all down as a formula.",
  "translatedText": "Bir örneği anlamak bir şeydir, ancak az önce yaptığımız her şeyi genelleştirmek ve hepsini bir formül olarak yazmak için bir dakikanızı ayırabilir misiniz bir bakın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 282.08,
  "end": 289.74
 },
 {
  "input": "The general situation where Bayes' theorem is relevant is when you have some hypothesis, like Steve is a librarian, and you see some new evidence, say this verbal description of Steve as a meek and tidy soul.",
  "translatedText": "Bayes teoreminin geçerli olduğu genel durum, Steve'in bir kütüphaneci olduğu gibi bir hipoteziniz olduğunda ve Steve'in uysal ve düzenli bir ruh olarak sözlü tanımı gibi bazı yeni kanıtlar gördüğünüzde ortaya çıkar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 292.32,
  "end": 303.98
 },
 {
  "input": "You want to know the probability that your hypothesis holds given that the evidence is true.",
  "translatedText": "Kanıtın doğru olduğu göz önüne alındığında hipotezinizin geçerli olma olasılığını bilmek istiyorsunuz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.38,
  "end": 309.64
 },
 {
  "input": "In the standard notation, this vertical bar means given that, as in we're restricting our view only to the possibilities where the evidence holds.",
  "translatedText": "Standart gösterimde, bu dikey çubuk şu anlama gelir: Görüşümüzü yalnızca kanıtların geçerli olduğu olasılıklarla sınırlıyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.44,
  "end": 318.96
 },
 {
  "input": "Remember the first relevant number we used, the probability that the hypothesis holds before considering any of that new evidence.",
  "translatedText": "Kullandığımız ilk ilgili sayıyı, yani yeni kanıtlardan herhangi birini dikkate almadan önce hipotezin geçerli olma olasılığını hatırlayın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 320.22,
  "end": 327.34
 },
 {
  "input": "In our example, that was 1 out of 21, and it came from considering the ratio of librarians to farmers in the general population.",
  "translatedText": "Örneğimizde bu 21'de 1'di ve bu, genel nüfusta kütüphanecilerin çiftçilere oranının dikkate alınmasından kaynaklandı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.72,
  "end": 334.64
 },
 {
  "input": "This number is known as the prior.",
  "translatedText": "Bu numara önceki numara olarak bilinir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 335.52,
  "end": 336.98
 },
 {
  "input": "After that, we need to consider the proportion of librarians that fit this description, the probability that we would see the evidence given that the hypothesis is true.",
  "translatedText": "Bundan sonra, bu tanıma uyan kütüphanecilerin oranını, hipotezin doğru olduğunu gösteren kanıtları görme olasılığımızı dikkate almamız gerekiyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.02,
  "end": 347.3
 },
 {
  "input": "Again, when you see this vertical bar, it means we're talking about some proportion of a limited part of the total space of possibilities.",
  "translatedText": "Yine bu dikey çubuğu gördüğünüzde, toplam olasılıklar alanının sınırlı bir kısmından bahsettiğimiz anlamına gelir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 348.1,
  "end": 354.84
 },
 {
  "input": "In this case, that limited part is the left side, where the hypothesis holds.",
  "translatedText": "Bu durumda o sınırlı kısım, hipotezin geçerli olduğu sol taraftır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 355.32,
  "end": 359.3
 },
 {
  "input": "In the context of Bayes' theorem, this value also has a special name, it's called the likelihood.",
  "translatedText": "Bayes teoremi bağlamında bu değerin de özel bir adı vardır, buna olasılık denir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.96,
  "end": 364.64
 },
 {
  "input": "Similarly, you need to know how much of the other side of the space includes the evidence, the probability of seeing the evidence given that the hypothesis isn't true.",
  "translatedText": "Benzer şekilde, uzayın diğer tarafının ne kadarının kanıt içerdiğini, hipotezin doğru olmadığı göz önüne alındığında kanıtları görme olasılığını bilmeniz gerekir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.7,
  "end": 373.56
 },
 {
  "input": "This funny little elbow symbol is commonly used in probability to mean not.",
  "translatedText": "Bu komik küçük dirsek sembolü genellikle olasılık anlamında değil anlamında kullanılır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.34,
  "end": 378.42
 },
 {
  "input": "So, with the notation in place, remember what our final answer was.",
  "translatedText": "Dolayısıyla, notasyonu yerine getirdiğimizde son cevabımızın ne olduğunu hatırlayın.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 379.86,
  "end": 383.02
 },
 {
  "input": "The probability that our librarian hypothesis is true given the evidence is the total number of librarians fitting the evidence, 4, divided by the total number of people fitting the evidence, 24.",
  "translatedText": "Kanıt göz önüne alındığında kütüphaneci hipotezimizin doğru olma olasılığı, kanıta uyan toplam kütüphaneci sayısının (4) kanıta uyan toplam kişi sayısına (24) bölünmesiyle elde edilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 383.36,
  "end": 394.88
 },
 {
  "input": "But where did that 4 come from?",
  "translatedText": "Peki bu 4 nereden geldi?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 395.76,
  "end": 397.18
 },
 {
  "input": "Well, it's the total number of people, times the prior probability of being a librarian, giving us the 10 total librarians, times the probability that one of those fits the evidence.",
  "translatedText": "Bu, toplam insan sayısı çarpı kütüphaneci olma ön olasılığı, bize toplam 10 kütüphaneciyi veriyor, çarpı bunlardan birinin kanıtlara uyma olasılığı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 397.84,
  "end": 408.42
 },
 {
  "input": "That same number shows up again in the denominator, but we need to add in the rest, the total number of people times the proportion who are not librarians, times the proportion of those who fit the evidence, which in our example gives 20.",
  "translatedText": "Aynı sayı yine paydada görünüyor, ancak geri kalanına toplam insan sayısını çarpı kütüphaneci olmayanların oranını, çarpı kanıtlara uyanların oranını eklememiz gerekiyor ki bu bizim örneğimizde 20'yi veriyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.22,
  "end": 422.14
 },
 {
  "input": "Now notice the total number of people here, 210, that gets cancelled out, and of course it should, that was just an arbitrary choice made for the sake of illustration.",
  "translatedText": "Şimdi buradaki toplam insan sayısına dikkat edin, 210, iptal edilen ve elbette öyle olması gereken, bu sadece örnekleme amacıyla yapılan keyfi bir seçimdi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.22,
  "end": 431.04
 },
 {
  "input": "This leaves us finally with a more abstract representation purely in terms of probabilities, and this, my friends, is Bayes' theorem.",
  "translatedText": "Bu bizi nihayet tamamen olasılıklar açısından daha soyut bir temsille bırakıyor ve bu, dostlarım, Bayes teoremidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 431.62,
  "end": 439.22
 },
 {
  "input": "More often, you see this denominator written simply as P of E, the total probability of seeing the evidence, which in our example would be the 24 out of 210.",
  "translatedText": "Daha sık olarak, bu paydanın basitçe P/E olarak yazıldığını görürsünüz, yani kanıtları görmenin toplam olasılığı, bizim örneğimizde bu 210 üzerinden 24 olacaktır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 440.42,
  "end": 450.46
 },
 {
  "input": "But in practice, to calculate it, you almost always have to break it down into the case where the hypothesis is true, and the one where it isn't.",
  "translatedText": "Ancak pratikte bunu hesaplamak için neredeyse her zaman hipotezin doğru olduğu ve olmadığı durumlara ayırmanız gerekir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.12,
  "end": 458.8
 },
 {
  "input": "Capping things off with one final bit of jargon, this answer is called the posterior, it's your belief about the hypothesis after seeing the evidence.",
  "translatedText": "Konuyu son bir jargonla kapatacak olursak, bu cevaba sonsal denir, bu, kanıtı gördükten sonra hipoteze olan inancınızdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 460.06,
  "end": 468.6
 },
 {
  "input": "Writing it out abstractly might seem more complicated than just thinking through the example directly with a representative sample.",
  "translatedText": "Bunu soyut bir şekilde yazmak, temsili bir örnekle doğrudan örnek üzerinden düşünmekten daha karmaşık görünebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.16,
  "end": 476.5
 },
 {
  "input": "And yeah, it is.",
  "translatedText": "Ve evet, öyle.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 476.92,
  "end": 478.78
 },
 {
  "input": "Keep in mind though, the value of a formula like this is that it lets you quantify and systematize the idea of changing beliefs.",
  "translatedText": "Ancak şunu aklınızda bulundurun: Böyle bir formülün değeri, inançları değiştirme fikrini ölçmenize ve sistematik hale getirmenize olanak sağlamasıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.2,
  "end": 486.26
 },
 {
  "input": "Scientists use this formula when they're analyzing the extent to which new data validates or invalidates their models.",
  "translatedText": "Bilim adamları bu formülü, yeni verilerin modellerini ne ölçüde doğruladığını veya geçersiz kıldığını analiz ederken kullanırlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.94,
  "end": 492.84
 },
 {
  "input": "Programmers will sometimes use it in building artificial intelligence, where at times you want to explicitly and numerically model a machine's belief.",
  "translatedText": "Programcılar bazen bunu yapay zeka oluştururken kullanırlar; bazen de bir makinenin inancını açık ve sayısal olarak modellemek istersiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 492.84,
  "end": 500.64
 },
 {
  "input": "And honestly, just for the way you view yourself and your own opinions and what it takes for your mind to change, Bayes' theorem has a way of reframing how you even think about thought itself.",
  "translatedText": "Ve dürüst olmak gerekirse, kendinize ve kendi görüşlerinize bakış açınız ve zihninizin değişmesi için gerekenler açısından Bayes teoremi, düşüncenin kendisi hakkında nasıl düşündüğünüzü bile yeniden çerçevelemenin bir yolunu sunuyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 501.4,
  "end": 510.82
 },
 {
  "input": "Putting a formula to it can also be more important as the examples get more and more intricate.",
  "translatedText": "Örnekler giderek daha karmaşık hale geldikçe buna bir formül koymak da daha önemli olabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 512.3,
  "end": 516.34
 },
 {
  "input": "However you write it, I actually encourage you not to try memorizing the formula, but to instead draw out this diagram as needed.",
  "translatedText": "Nasıl yazarsanız yazın, aslında formülü ezberlememenizi, bunun yerine bu diyagramı gerektiği gibi çizmenizi tavsiye ederim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 517.08,
  "end": 524.68
 },
 {
  "input": "It's sort of a distilled version of thinking with a representative sample, where we think with areas instead of counts, which is more flexible and easier to sketch on the fly.",
  "translatedText": "Bu, temsili bir örnekle düşünmenin damıtılmış bir versiyonudur; burada sayımlar yerine alanlarla düşünürüz; bu daha esnektir ve anında çizimi daha kolaydır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.26,
  "end": 533.62
 },
 {
  "input": "Rather than bringing to mind some specific number of examples, like 210, think of the space of all possibilities as a 1x1 square.",
  "translatedText": "210 gibi belirli sayıda örneği aklınıza getirmek yerine, tüm olasılıkların uzayını 1x1 kare olarak düşünün.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.26,
  "end": 541.38
 },
 {
  "input": "Then any event occupies some subset of this space, and the probability of that event can be thought about as the area of that subset.",
  "translatedText": "O zaman herhangi bir olay bu uzayın bir alt kümesini kaplar ve bu olayın olasılığı o alt kümenin alanı olarak düşünülebilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 542.12,
  "end": 550.94
 },
 {
  "input": "For example, I like to think of the hypothesis as living in the left part of the square with a width of p of h.",
  "translatedText": "Örneğin, hipotezin karenin sol kısmında p h genişliğinde yaşadığını düşünmeyi seviyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 551.54,
  "end": 557.66
 },
 {
  "input": "I recognize I'm being a bit repetitive, but when you see evidence, the space of possibilities gets restricted, and the crucial part is that restriction might not be even between the left and the right, so the new probability for the hypothesis is the proportion it occupies in this restricted wonky shape.",
  "translatedText": "Biraz tekrarlayıcı olduğumun farkındayım, ancak kanıt gördüğünüzde olasılıklar alanı kısıtlanıyor ve en önemli kısım, kısıtlamanın sol ve sağ arasında bile olmayabilir, dolayısıyla hipotez için yeni olasılık şu: bu sınırlı, riskli biçimde kapladığı oran.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.32,
  "end": 576.94
 },
 {
  "input": "Now if you think a farmer is just as likely to fit the evidence as a librarian, then the proportion doesn't change, which should make sense, right?",
  "translatedText": "Şimdi eğer bir çiftçinin de bir kütüphaneci gibi kanıtlara uyma ihtimalinin yüksek olduğunu düşünüyorsanız o zaman oran değişmiyor, bu mantıklı olmalı, değil mi?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.64,
  "end": 586.24
 },
 {
  "input": "And evidence doesn't change your beliefs.",
  "translatedText": "Ve kanıtlar inançlarınızı değiştirmez.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.26,
  "end": 588.32
 },
 {
  "input": "But when these likelihoods are very different from each other, that's when your belief changes a lot.",
  "translatedText": "Ancak bu olasılıklar birbirinden çok farklı olduğunda, işte o zaman inancınız çok değişir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 588.9,
  "end": 593.48
 },
 {
  "input": "Bayes' theorem spells out what that proportion is, and if you want you can read it geometrically.",
  "translatedText": "Bayes teoremi bu oranın ne olduğunu açıklıyor ve eğer isterseniz bunu geometrik olarak okuyabilirsiniz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 595.76,
  "end": 600.52
 },
 {
  "input": "Something like p of h times p of e given h, the probability of both the hypothesis and the evidence occurring together, is the width times the height of this little left rectangle, the area of that region.",
  "translatedText": "p (h) çarpı p (e) gibi bir şey, h verildiğinde, hem hipotezin hem de kanıtın birlikte ortaya çıkma olasılığı, bu küçük sol dikdörtgenin, o bölgenin alanının genişliği çarpı yüksekliğidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 600.9,
  "end": 613.08
 },
 {
  "input": "Alright, this is probably a good time to take a step back and consider a few of the broader takeaways about how to make probability more intuitive, beyond Bayes' theorem.",
  "translatedText": "Pekala, bu muhtemelen bir adım geri atıp Bayes teoreminin ötesinde olasılığı nasıl daha sezgisel hale getirebileceğimize dair daha geniş çıkarımlardan birkaçını düşünmek için iyi bir zaman.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 614.76,
  "end": 623.22
 },
 {
  "input": "First off, notice how the trick of thinking about a representative sample with some specific number of people, like our 210 librarians and farmers, was really helpful.",
  "translatedText": "Öncelikle, 210 kütüphanecimiz ve çiftçimiz gibi belirli sayıda kişiden oluşan temsili bir örnek üzerinde düşünmenin ne kadar yararlı olduğuna dikkat edin.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 623.78,
  "end": 632.4
 },
 {
  "input": "There's actually another Kahneman and Tversky result which is all about this, and it's interesting enough to interject here.",
  "translatedText": "Aslında tamamen bununla ilgili olan başka bir Kahneman ve Tversky sonucu daha var ve burada araya girecek kadar ilginç.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.96,
  "end": 638.38
 },
 {
  "input": "They did this experiment that was similar to the one with Steve, but where people were given the following description of a fictitious woman named Linda.",
  "translatedText": "Steve'le olana benzer bir deney yaptılar, ancak burada insanlara Linda adındaki hayali bir kadının aşağıdaki tanımı verildi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 638.52,
  "end": 645.72
 },
 {
  "input": "Linda is 31 years old, single, outspoken, and very bright.",
  "translatedText": "Linda 31 yaşında, bekar, açık sözlü ve çok zeki bir adam.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.4,
  "end": 650.62
 },
 {
  "input": "She majored in philosophy.",
  "translatedText": "Felsefe alanında uzmanlaştı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 651.14,
  "end": 652.16
 },
 {
  "input": "As a student she was deeply concerned with issues of discrimination and social justice, and also participated in the anti-nuclear demonstrations.",
  "translatedText": "Öğrenciyken ayrımcılık ve sosyal adalet konularıyla derinden ilgileniyordu ve aynı zamanda nükleer karşıtı gösterilere de katıldı.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 652.64,
  "end": 659.54
 },
 {
  "input": "After seeing this people were asked what's more likely, 1.",
  "translatedText": "Bunu gördükten sonra insanlara neyin daha muhtemel olduğu soruldu: 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 660.7,
  "end": 664.02
 },
 {
  "input": "That Linda is a bank teller, or 2.",
  "translatedText": "Linda'nın banka memuru olması veya 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 664.34,
  "end": 666.46
 },
 {
  "input": "That Linda is a bank teller and is active in the feminist movement.",
  "translatedText": "Linda'nın bir banka memuru olduğunu ve feminist harekette aktif olduğunu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 666.92,
  "end": 669.9
 },
 {
  "input": "85%, 85% of participants said that the latter is more likely than the former, even though the set of bank tellers who are active in the feminist movement is a subset of the set of bank tellers.",
  "translatedText": "Feminist harekette aktif olan banka gişe memurları, banka gişe memurlarının bir alt kümesi olmasına rağmen, katılımcıların %85 ila %85'i ikincisinin ilkinden daha olası olduğunu söyledi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.22,
  "end": 683.32
 },
 {
  "input": "It has to be smaller.",
  "translatedText": "Daha küçük olması gerekiyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 683.56,
  "end": 684.68
 },
 {
  "input": "So that's interesting enough, but what's fascinating is that there's a simple way that you can rephrase the question that dropped this error from 85% to 0.",
  "translatedText": "Bu yeterince ilginç, ama büyüleyici olan şu ki, bu hatayı %85'ten 0'a düşüren soruyu yeniden ifade etmenin basit bir yolu var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 685.64,
  "end": 694.1
 },
 {
  "input": "Instead, if participants were told that there are 100 people who fit this description, and then asked to estimate how many of those 100 are bank tellers, and how many are bank tellers active in the feminist movement, nobody makes the error.",
  "translatedText": "Bunun yerine, katılımcılara bu tanıma uyan 100 kişinin olduğu söylense ve bu 100 kişiden kaçının banka gişe memuru olduğunu ve kaçının feminist harekette aktif banka gişe memuru olduğunu tahmin etmeleri istense, kimse hata yapmaz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.96,
  "end": 708.5
 },
 {
  "input": "Everybody correctly assigns a higher number to the first option than to the second.",
  "translatedText": "Herkes ilk seçeneğe ikinciden daha yüksek bir sayıyı doğru bir şekilde atar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 708.5,
  "end": 713.18
 },
 {
  "input": "It's weird, somehow phrases like 40 out of 100 kick our intuitions into gear much more effectively than 40%, much less 0.4, and much less abstractly referencing the idea of something being more or less likely.",
  "translatedText": "Gariptir, bir şekilde 100 üzerinden 40 gibi ifadeler sezgilerimizi %40'tan çok daha etkili bir şekilde harekete geçirir, hatta 0'dan çok daha az.4 ve çok daha az soyut olarak bir şeyin az ya da çok muhtemel olduğu fikrine atıfta bulunuyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 714.78,
  "end": 728.06
 },
 {
  "input": "That said, representative samples don't easily capture the continuous nature of probability.",
  "translatedText": "Bununla birlikte, temsili örnekler olasılığın sürekli doğasını kolaylıkla yakalayamıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.4,
  "end": 734.1
 },
 {
  "input": "So turning to area is a nice alternative, not just because of the continuity, but also because it's way easier to sketch out when you're sitting there pencil and paper puzzling over some problem.",
  "translatedText": "Yani alana dönmek güzel bir alternatif, sadece süreklilik nedeniyle değil, aynı zamanda orada oturup kalem ve kağıtla bir sorun üzerinde kafa yorarken taslak çizmenin çok daha kolay olması nedeniyle.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.1,
  "end": 744.04
 },
 {
  "input": "People often think about probability as being the study of uncertainty, and that is of course how it's applied in science, but the actual math of probability, where all the formulas come from, is just the math of proportions, and in that context turning to geometry is exceedingly helpful.",
  "translatedText": "İnsanlar genellikle olasılığın belirsizliğin incelenmesi olduğunu düşünürler ve bilimde de bu şekilde uygulanır, ancak tüm formüllerin geldiği gerçek olasılık matematiği sadece oranların matematiğidir ve bu bağlamda geometri son derece faydalıdır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 745.22,
  "end": 761.02
 },
 {
  "input": "I mean, take a look at Bayes' theorem as a statement about proportions, whether that's proportions of people, of areas, whatever.",
  "translatedText": "Demek istediğim, Bayes teoremine oranlarla ilgili bir ifade olarak bakın; bu ister insanların, ister alanların oranları olsun, her ne ise.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 764.26,
  "end": 770.72
 },
 {
  "input": "Once you digest what it's saying, it's actually kind of obvious.",
  "translatedText": "Ne dediğini sindirdiğinizde, aslında çok açık.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 771.3,
  "end": 774.46
 },
 {
  "input": "Both sides tell you to look at the cases where the evidence is true, and then to consider the proportion of those cases where the hypothesis is also true.",
  "translatedText": "Her iki taraf da size kanıtın doğru olduğu durumlara bakmanızı ve ardından hipotezin de doğru olduğu durumların oranını düşünmenizi söylüyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 775.04,
  "end": 782.72
 },
 {
  "input": "That's it, that's all it's saying.",
  "translatedText": "İşte bu, tek söylediği bu.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.24,
  "end": 784.64
 },
 {
  "input": "The right-hand side just spells out how to compute it.",
  "translatedText": "Sağ taraf bunun nasıl hesaplanacağını anlatıyor.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 784.86,
  "end": 786.9
 },
 {
  "input": "What's noteworthy is that such a straightforward fact about proportions can become hugely significant for science, for artificial intelligence, and really any situation where you want to quantify belief.",
  "translatedText": "Dikkate değer olan şey, oranlarla ilgili bu kadar basit bir gerçeğin bilim, yapay zeka ve inancı ölçmek istediğiniz herhangi bir durum için son derece önemli hale gelebilmesidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 787.54,
  "end": 797.92
 },
 {
  "input": "I hope to give you a better glimpse of that as we get into more examples.",
  "translatedText": "Daha fazla örnek verdikçe size daha iyi bir fikir verebileceğimi umuyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 798.54,
  "end": 801.42
 },
 {
  "input": "But before more examples, we have a little bit of unfinished business with Steve.",
  "translatedText": "Ancak daha fazla örnek vermeden önce Steve'le bitmemiş bir işimiz var.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 802.38,
  "end": 805.74
 },
 {
  "input": "As I mentioned, some psychologists debate Kahneman and Tversky's conclusion that the rational thing to do is to bring to mind the ratio of farmers to librarians.",
  "translatedText": "Bahsettiğim gibi, bazı psikologlar Kahneman ve Tversky'nin, çiftçilerin kütüphanecilere oranını akla getirmek için yapılacak mantıklı şey olduğu yönündeki sonucunu tartışıyorlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 806.48,
  "end": 814.8
 },
 {
  "input": "They complain that the context is ambiguous.",
  "translatedText": "Bağlamın belirsiz olduğundan şikayet ediyorlar.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 815.14,
  "end": 817.26
 },
 {
  "input": "I mean, who is Steve, exactly?",
  "translatedText": "Yani Steve tam olarak kim?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 817.92,
  "end": 819.84
 },
 {
  "input": "Should you expect that he's a randomly sampled American?",
  "translatedText": "Onun rastgele seçilmiş bir Amerikalı olmasını beklemeli misiniz?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 819.84,
  "end": 822.66
 },
 {
  "input": "Or would you be better to assume that he's a friend of the two psychologists interrogating you?",
  "translatedText": "Yoksa onun sizi sorguya çeken iki psikoloğun arkadaşı olduğunu mu varsayarsınız?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 823.26,
  "end": 827.0
 },
 {
  "input": "Or maybe that he's someone you're personally likely to know?",
  "translatedText": "Ya da belki şahsen tanıma ihtimaliniz olan biri?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 827.22,
  "end": 829.74
 },
 {
  "input": "This assumption determines the prior.",
  "translatedText": "Bu varsayım öncekini belirler.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 830.42,
  "end": 832.4
 },
 {
  "input": "I for one run into way more librarians in a given month than I do farmers.",
  "translatedText": "Ben belirli bir ayda çiftçilerden çok daha fazla kütüphaneciyle karşılaşıyorum.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 832.96,
  "end": 836.68
 },
 {
  "input": "Needless to say, the probability of a librarian or a farmer fitting this description is highly open to interpretation.",
  "translatedText": "Söylemeye gerek yok, bir kütüphanecinin ya da bir çiftçinin bu tanıma uyma ihtimali yoruma oldukça açık.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 837.5,
  "end": 843.52
 },
 {
  "input": "For our purposes, understanding the math, what I want to emphasize is that any question worth debating here can be pictured in the context of the diagram.",
  "translatedText": "Amacımız açısından, matematiği anlamak açısından vurgulamak istediğim şey, burada tartışmaya değer her sorunun diyagram bağlamında resmedilebileceğidir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 844.44,
  "end": 852.3
 },
 {
  "input": "Questions about the context shift around the prior, and questions about the personalities and stereotypes shift around the relevant likelihoods.",
  "translatedText": "Bağlamla ilgili sorular öncekinin etrafında değişir ve kişilikler ve stereotiplerle ilgili sorular ilgili olasılıklar etrafında değişir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 853.0,
  "end": 860.58
 },
 {
  "input": "All that said, whether or not you buy this particular experiment, the ultimate point that evidence should not determine beliefs, but update them, is worth tattooing in your brain.",
  "translatedText": "Bütün bunlar, bu özel deneyi kabul etseniz de etmeseniz de, kanıtların inançları belirlememesi, onları güncellemesi gerektiği şeklindeki nihai noktanın beyninize dövme yapılmasına değer.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 861.1,
  "end": 871.0
 },
 {
  "input": "I'm in no position to say whether this does or does not run against natural human instinct.",
  "translatedText": "Bunun doğal insan içgüdüsüne aykırı olup olmadığını söyleyecek durumda değilim.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.8,
  "end": 876.5
 },
 {
  "input": "We'll leave that to the psychologists.",
  "translatedText": "Bunu psikologlara bırakıyoruz.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 876.5,
  "end": 878.24
 },
 {
  "input": "What's more interesting to me is how we can reprogram our intuition to authentically reflect the implications of math, and bringing to mind the right image can often do just that.",
  "translatedText": "Benim için daha ilginç olan şey, matematiğin sonuçlarını özgün bir şekilde yansıtacak şekilde sezgilerimizi nasıl yeniden programlayabileceğimizdir ve doğru görüntüyü akla getirmek çoğu zaman bunu yapabilir.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 878.92,
  "end": 888.06
 }
]