[
 {
  "input": "Hey folks, I've got a relatively quick video for you today, just sort of a footnote between chapters.",
  "model": "nmt",
  "translatedText": "嘿伙计们，我今天为你们准备了一个相 对较快的视频，只是章节之间的脚注。",
  "time_range": [
   13.460000000000003,
   18.52
  ]
 },
 {
  "input": "In the last two videos I talked about linear transformations and matrices, but I only showed the specific case of transformations that take two-dimensional vectors to other two-dimensional vectors.",
  "model": "nmt",
  "translatedText": "在上两个视频中，我讨论了线性变换和 矩阵，但我只展示了将二维向量转换 为其他二维向量的变换的具体情况。",
  "time_range": [
   19.06,
   28.38
  ]
 },
 {
  "input": "The general throughout this series will work mainly in two dimensions, mostly because it's easier to actually see on the screen and wrap your mind around.",
  "model": "nmt",
  "translatedText": "本系列的一般内容将主要在二维空间中工作，主要是因为 它更容易在屏幕上实际看到并让您的思维更容易理解。",
  "time_range": [
   28.92,
   36.06
  ]
 },
 {
  "input": "But more importantly than that, once you get all the core ideas in two dimensions, they carry over pretty seamlessly to higher dimensions.",
  "model": "nmt",
  "translatedText": "但更重要的是，一旦你获得了二维的所有核心 思想，它们就可以无缝地转移到更高的维度。",
  "time_range": [
   36.5,
   42.8
  ]
 },
 {
  "input": "Nevertheless, it's good to peek our heads outside of flatland now and then to, you know, see what it means to apply these ideas in more than just those two dimensions.",
  "model": "nmt",
  "translatedText": "尽管如此，时不时地把我们的头脑抛向平地之外是件好事，你知 道，看看将这些想法应用到不仅仅是这两个维度意味着什么。",
  "time_range": [
   43.8,
   51.0
  ]
 },
 {
  "input": "For example, consider a linear transformation with three-dimensional vectors as inputs and three-dimensional vectors as outputs.",
  "model": "nmt",
  "translatedText": "例如，考虑以三维向量作为输入、 以三维向量作为输出的线性变换。",
  "time_range": [
   52.34,
   58.88
  ]
 },
 {
  "input": "We can visualize this by smooshing around all the points in three-dimensional space, as represented by a grid, in such a way that keeps the grid lines parallel and evenly spaced, and which fixes the origin in place.",
  "model": "nmt",
  "translatedText": "我们可以通过平滑网格表示的三维空间中的所 有点来可视化这一点，以保持网格线平行且均 匀分布的方式，并将原点固定在适当的位置。",
  "time_range": [
   60.16,
   72.52
  ]
 },
 {
  "input": "And just as with two dimensions, every point of space that we see moving around is really just a proxy for a vector who has its tip at that point, and what we're really doing is thinking about input vectors moving over to their corresponding outputs.",
  "model": "nmt",
  "translatedText": "就像二维一样，我们看到移动的每个空间点实际上只 是一个向量的代理，该向量的尖端位于该点，而我们 真正要做的是考虑输入向量移动到其相应的输出。",
  "time_range": [
   73.46,
   87.16
  ]
 },
 {
  "input": "And just as with two dimensions, one of these transformations is completely described by where the basis vectors go.",
  "model": "nmt",
  "translatedText": "就像二维一样，这些变换之一 完全由基向量的走向来描述。",
  "time_range": [
   87.9,
   93.56
  ]
 },
 {
  "input": "But now, there are three standard basis vectors that we typically use, the unit vector in the x direction, i-hat, the unit vector in the y direction, j-hat, and a new guy, the unit vector in the z direction, called k-hat.",
  "model": "nmt",
  "translatedText": "但是现在，我们通常使用三个标准基向量，x 方向的单位向 量 i-hat，y 方向的单位向量 j-hat，以及 一个新的家伙，z 方向的单位向量，称为 k-hat。",
  "time_range": [
   94.16,
   106.56
  ]
 },
 {
  "input": "In fact, I think it's easier to think about these transformations by only following those basis vectors, since the full 3D grid representing all points can get kind of messy.",
  "model": "nmt",
  "translatedText": "事实上，我认为仅通过遵循这些基本向量来考虑这些变换会更容 易，因为表示所有点的完整 3D 网格可能会变得有点混乱。",
  "time_range": [
   107.14,
   116.02
  ]
 },
 {
  "input": "By leaving a copy of the original axes in the background, we can think about the coordinates of where each of these three basis vectors lands.",
  "model": "nmt",
  "translatedText": "通过在背景中保留原始轴的副本，我们可以 考虑这三个基本向量中的每一个的坐标。",
  "time_range": [
   116.92,
   124.0
  ]
 },
 {
  "input": "Record the coordinates of these three vectors as the columns of a 3x3 matrix.",
  "model": "nmt",
  "translatedText": "将这三个向量的坐标记录为 3x3 矩阵的列。",
  "time_range": [
   125.82,
   130.46
  ]
 },
 {
  "input": "This gives a matrix that completely describes the transformation using only nine numbers.",
  "model": "nmt",
  "translatedText": "这给出了一个仅使用九个数字就可以完整描述变换的矩阵。",
  "time_range": [
   131.26,
   136.16
  ]
 },
 {
  "input": "As a simple example, consider the transformation that rotates space 90 degrees around the y axis.",
  "model": "nmt",
  "translatedText": "作为一个简单的示例，请考虑围绕 y 轴将空间旋转 90 度的变换。",
  "time_range": [
   137.2,
   143.96
  ]
 },
 {
  "input": "So that would mean that it takes i-hat to the coordinates 0, 0, negative 1 on the z axis.",
  "model": "nmt",
  "translatedText": "所以这意味着它需要 i-hat 到 z 轴上的坐标 0, 0, 负 1。",
  "time_range": [
   144.86,
   150.1
  ]
 },
 {
  "input": "It doesn't move j-hat, so it stays at the coordinates 0, 1, 0.",
  "model": "nmt",
  "translatedText": "它不会移动 j-hat，因此它停留在坐标 0, 1, 0。",
  "time_range": [
   150.82,
   154.28
  ]
 },
 {
  "input": "And then k-hat moves over to the x axis at 1, 0, 0.",
  "model": "nmt",
  "translatedText": "然后 k-hat 移动到 x 轴 1,0,0。",
  "time_range": [
   154.88,
   158.84
  ]
 },
 {
  "input": "Those three sets of coordinates become the columns of a matrix that describes that rotation To see where a vector with coordinates x, y, z lands, the reasoning is almost identical to what it was for two dimensions.",
  "model": "nmt",
  "translatedText": "这三组坐标成为描述旋转的矩阵的列。 要查看坐标为 x、y、z 的向量落 在哪里，推理几乎与二维的推理相同。",
  "time_range": [
   160.99,
   176.22
  ]
 },
 {
  "input": "Each of those coordinates can be thought of as instructions for how to scale each basis vector so that they add together to get your vector.",
  "model": "nmt",
  "translatedText": "这些坐标中的每一个都可以被认为是如何缩放每个 基本向量的指令，以便它们加在一起得到向量。",
  "time_range": [
   176.94,
   184.04
  ]
 },
 {
  "input": "And the important part, just like the 2D case, is that this scaling and adding process works both before and after the transformation.",
  "model": "nmt",
  "translatedText": "与 2D 情况一样，重要的部分是此缩 放和添加过程在转换之前和之后都有效。",
  "time_range": [
   186.26,
   194.0
  ]
 },
 {
  "input": "So to see where your vector lands, you multiply those coordinates by the corresponding columns of the matrix, and then you add together the three results.",
  "model": "nmt",
  "translatedText": "因此，要查看向量落在哪里，请将这些坐标乘 以矩阵的相应列，然后将三个结果加在一起。",
  "time_range": [
   196.38,
   204.82
  ]
 },
 {
  "input": "Multiplying two matrices is also similar.",
  "model": "nmt",
  "translatedText": "两个矩阵相乘也类似。",
  "time_range": [
   209.6,
   211.5
  ]
 },
 {
  "input": "Whenever you see two 3x3 matrices getting multiplied together, you should imagine first applying the transformation encoded by the right one, then applying the transformation encoded by the left one.",
  "model": "nmt",
  "translatedText": "每当您看到两个 3x3 矩阵相乘时， 您应该想象首先应用由右侧矩阵编码的变 换，然后应用由左侧矩阵编码的变换。",
  "time_range": [
   212.02,
   223.26
  ]
 },
 {
  "input": "It turns out that 3D matrix multiplication is actually pretty important for fields like computer graphics and robotics, since things like rotations and three dimensions can be pretty hard to describe, but they're easier to wrap your mind around if you can break them down as the composition of separate, easier-to-think-about rotations.",
  "model": "nmt",
  "translatedText": "事实证明，3D 矩阵乘法实际上对于计算机图 形学和机器人学等领域非常重要，因为像旋转和 三维这样的东西可能很难描述，但如果你能将它 们分解为单独的、更容易思考的轮换的组成。",
  "time_range": [
   224.06,
   241.16
  ]
 },
 {
  "input": "Performing this matrix multiplication numerically is, once again, pretty similar to the two-dimensional case.",
  "model": "nmt",
  "translatedText": "以数字方式执行此矩阵乘法 再次与二维情况非常相似。",
  "time_range": [
   244.35999999999999,
   249.86
  ]
 },
 {
  "input": "In fact, a good way to test your understanding of the last video would be to try to reason through what specifically this matrix multiplication should look like, thinking closely about how it relates to the idea of applying two successive transformations in space.",
  "model": "nmt",
  "translatedText": "事实上，测试您对上一个视频的理解的一个好方法是 尝试推理这个矩阵乘法具体应该是什么样子，仔细思 考它与在空间中应用两个连续变换的想法有何关系。",
  "time_range": [
   250.48,
   263.82
  ]
 },
 {
  "input": "In the next video, I'll start getting into the determinant.",
  "model": "nmt",
  "translatedText": "在下一个视频中，我将开始讨论行列式。",
  "time_range": [
   272.14000000000004,
   274.5
  ]
 }
]