[
 {
  "input": "Hey folks, I've got a relatively quick video for you today, just sort of a footnote between chapters.",
  "translatedText": "హే ఫోల్క్స్, నేను ఈరోజు మీ కోసం చాలా శీఘ్ర వీడియోని పొందాను, అధ్యాయాల మధ్య ఒక ఫుట్‌నోట్ మాత్రమే.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.46,
  "end": 18.52
 },
 {
  "input": "In the last two videos I talked about linear transformations and matrices, but I only showed the specific case of transformations that take two-dimensional vectors to other two-dimensional vectors.",
  "translatedText": "గత రెండు వీడియోలలో నేను సరళ పరివర్తనలు మరియు మాత్రికల గురించి మాట్లాడాను, కానీ నేను రెండు డైమెన్షనల్ వెక్టర్‌లను ఇతర టూ డైమెన్షనల్ వెక్టర్‌లకు తీసుకెళ్లే నిర్దిష్ట పరివర్తనలను మాత్రమే చూపించాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 19.06,
  "end": 28.38
 },
 {
  "input": "The general throughout this series will work mainly in two dimensions, mostly because it's easier to actually see on the screen and wrap your mind around.",
  "translatedText": "ఈ సిరీస్ అంతటా సాధారణం ప్రధానంగా రెండు కోణాలలో పని చేస్తుంది, ఎందుకంటే స్క్రీన్‌పై చూడటం మరియు మీ మనస్సును చుట్టుముట్టడం చాలా సులభం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 28.92,
  "end": 36.06
 },
 {
  "input": "But more importantly than that, once you get all the core ideas in two dimensions, they carry over pretty seamlessly to higher dimensions.",
  "translatedText": "కానీ దాని కంటే ముఖ్యంగా, మీరు అన్ని ప్రధాన ఆలోచనలను రెండు కోణాలలో పొందిన తర్వాత, అవి చాలా సజావుగా అధిక కొలతలకు తీసుకువెళతాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 36.5,
  "end": 42.8
 },
 {
  "input": "Nevertheless, it's good to peek our heads outside of flatland now and then to, you know, see what it means to apply these ideas in more than just those two dimensions.",
  "translatedText": "ఏదేమైనా, ఫ్లాట్‌ల్యాండ్ వెలుపల మన తలలను చూడటం మంచిది, మీకు తెలుసా, ఈ ఆలోచనలను ఆ రెండు కోణాల కంటే ఎక్కువగా వర్తింపజేయడం అంటే ఏమిటో చూడండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.8,
  "end": 51.0
 },
 {
  "input": "For example, consider a linear transformation with three-dimensional vectors as inputs and three-dimensional vectors as outputs.",
  "translatedText": "ఉదాహరణకు, త్రిమితీయ వెక్టర్‌లను ఇన్‌పుట్‌లుగా మరియు త్రీ-డైమెన్షనల్ వెక్టర్‌లను అవుట్‌పుట్‌లుగా ఉండే సరళ పరివర్తనను పరిగణించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 52.34,
  "end": 58.88
 },
 {
  "input": "We can visualize this by smooshing around all the points in three-dimensional space, as represented by a grid, in such a way that keeps the grid lines parallel and evenly spaced, and which fixes the origin in place.",
  "translatedText": "గ్రిడ్ ద్వారా ప్రాతినిధ్యం వహించే విధంగా, గ్రిడ్ లైన్‌లను సమాంతరంగా మరియు సమానంగా ఉంచే విధంగా మరియు మూలాన్ని స్థిరంగా ఉంచే విధంగా త్రీ-డైమెన్షనల్ స్పేస్‌లోని అన్ని పాయింట్ల చుట్టూ స్మూష్ చేయడం ద్వారా మనం దీనిని దృశ్యమానం చేయవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 60.16,
  "end": 72.52
 },
 {
  "input": "And just as with two dimensions, every point of space that we see moving around is really just a proxy for a vector who has its tip at that point, and what we're really doing is thinking about input vectors moving over to their corresponding outputs.",
  "translatedText": "మరియు రెండు డైమెన్షన్‌ల మాదిరిగానే, మనం చుట్టూ తిరిగే ప్రతి స్థలం పాయింట్ నిజంగా ఆ సమయంలో దాని చిట్కా ఉన్న వెక్టర్‌కు ప్రాక్సీ మాత్రమే, మరియు మనం నిజంగా చేస్తున్నది ఇన్‌పుట్ వెక్టర్స్ వాటి సంబంధిత అవుట్‌పుట్‌లకు వెళ్లడం గురించి ఆలోచించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 73.46,
  "end": 87.16
 },
 {
  "input": "And just as with two dimensions, one of these transformations is completely described by where the basis vectors go.",
  "translatedText": "మరియు రెండు కోణాల మాదిరిగానే, ఈ పరివర్తనలలో ఒకటి ఆధార వెక్టర్స్ ఎక్కడికి వెళుతుందో పూర్తిగా వివరించబడింది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.9,
  "end": 93.56
 },
 {
  "input": "But now, there are three standard basis vectors that we typically use, the unit vector in the x direction, i-hat, the unit vector in the y direction, j-hat, and a new guy, the unit vector in the z direction, called k-hat.",
  "translatedText": "కానీ ఇప్పుడు, మనం సాధారణంగా ఉపయోగించే మూడు ప్రామాణిక ప్రాతిపదిక వెక్టర్స్ ఉన్నాయి, x దిశలో యూనిట్ వెక్టర్, i-hat, y దిశలో యూనిట్ వెక్టర్, j-hat మరియు కొత్త వ్యక్తి, z దిశలో యూనిట్ వెక్టర్. , k-hat అని పిలుస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.16,
  "end": 106.56
 },
 {
  "input": "In fact, I think it's easier to think about these transformations by only following those basis vectors, since the full 3D grid representing all points can get kind of messy.",
  "translatedText": "వాస్తవానికి, ఆ ప్రాతిపదిక వెక్టార్‌లను మాత్రమే అనుసరించడం ద్వారా ఈ పరివర్తనల గురించి ఆలోచించడం సులభమని నేను భావిస్తున్నాను, ఎందుకంటే అన్ని పాయింట్‌లను సూచించే పూర్తి 3D గ్రిడ్ గందరగోళంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 107.14,
  "end": 116.02
 },
 {
  "input": "By leaving a copy of the original axes in the background, we can think about the coordinates of where each of these three basis vectors lands.",
  "translatedText": "అసలు అక్షాల కాపీని బ్యాక్‌గ్రౌండ్‌లో ఉంచడం ద్వారా, ఈ మూడు ప్రాతిపదిక వెక్టర్‌లలో ప్రతి ఒక్కటి ఎక్కడ ల్యాండ్ అవుతుందనే కోఆర్డినేట్‌ల గురించి మనం ఆలోచించవచ్చు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.92,
  "end": 124.0
 },
 {
  "input": "Record the coordinates of these three vectors as the columns of a 3x3 matrix.",
  "translatedText": "ఈ మూడు వెక్టర్‌ల కోఆర్డినేట్‌లను 3x3 మాతృక నిలువు వరుసలుగా రికార్డ్ చేయండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 125.82,
  "end": 130.46
 },
 {
  "input": "This gives a matrix that completely describes the transformation using only nine numbers.",
  "translatedText": "ఇది కేవలం తొమ్మిది సంఖ్యలను ఉపయోగించి పరివర్తనను పూర్తిగా వివరించే మాతృకను ఇస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.26,
  "end": 136.16
 },
 {
  "input": "As a simple example, consider the transformation that rotates space 90 degrees around the y axis.",
  "translatedText": "ఒక సాధారణ ఉదాహరణగా, y అక్షం చుట్టూ స్పేస్ 90 డిగ్రీలు తిరిగే పరివర్తనను పరిగణించండి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.2,
  "end": 143.96
 },
 {
  "input": "So that would mean that it takes i-hat to the coordinates 0, 0, negative 1 on the z axis.",
  "translatedText": "కనుక ఇది z అక్షంలోని 0, 0, ప్రతికూల 1 అక్షాంశాలకు i-hatని తీసుకుంటుందని అర్థం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 144.86,
  "end": 150.1
 },
 {
  "input": "It doesn't move j-hat, so it stays at the coordinates 0, 1, 0.",
  "translatedText": "ఇది j-hatని తరలించదు, కనుక ఇది 0, 1, 0 అక్షాంశాల వద్ద ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.82,
  "end": 154.28
 },
 {
  "input": "And then k-hat moves over to the x axis at 1, 0, 0.",
  "translatedText": "ఆపై k-hat 1, 0, 0 వద్ద x అక్షం వైపు కదులుతుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 154.88,
  "end": 158.84
 },
 {
  "input": "Those three sets of coordinates become the columns of a matrix that describes that rotation To see where a vector with coordinates x, y, z lands, the reasoning is almost identical to what it was for two dimensions.",
  "translatedText": "ఆ మూడు కోఆర్డినేట్‌లు ఆ భ్రమణాన్ని వివరించే మాతృక యొక్క నిలువు వరుసలుగా మారతాయి, x, y, z కోఆర్డినేట్‌లతో వెక్టార్ ఎక్కడ ల్యాండ్ అవుతుందో చూడటానికి, తార్కికం రెండు కోణాలకు సంబంధించిన దానికి దాదాపు సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 160.99,
  "end": 176.22
 },
 {
  "input": "Each of those coordinates can be thought of as instructions for how to scale each basis vector so that they add together to get your vector.",
  "translatedText": "ఆ కోఆర్డినేట్‌లలో ప్రతి ఒక్కటి ప్రతి ప్రాతిపదిక వెక్టర్‌ను ఎలా స్కేల్ చేయాలనే సూచనల వలె భావించవచ్చు, తద్వారా అవి మీ వెక్టర్‌ని పొందడానికి కలిసి ఉంటాయి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 176.94,
  "end": 184.04
 },
 {
  "input": "And the important part, just like the 2D case, is that this scaling and adding process works both before and after the transformation.",
  "translatedText": "మరియు ముఖ్యమైన భాగం, కేవలం 2D కేసు వలె, ఈ స్కేలింగ్ మరియు జోడించే ప్రక్రియ పరివర్తనకు ముందు మరియు తర్వాత రెండింటిలోనూ పనిచేస్తుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.26,
  "end": 194.0
 },
 {
  "input": "So to see where your vector lands, you multiply those coordinates by the corresponding columns of the matrix, and then you add together the three results.",
  "translatedText": "కాబట్టి మీ వెక్టార్ ఎక్కడ ల్యాండ్ అవుతుందో చూడటానికి, మీరు ఆ కోఆర్డినేట్‌లను మాతృక యొక్క సంబంధిత నిలువు వరుసల ద్వారా గుణించాలి, ఆపై మీరు మూడు ఫలితాలను జతచేస్తారు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.38,
  "end": 204.82
 },
 {
  "input": "Multiplying two matrices is also similar.",
  "translatedText": "రెండు మాత్రికలను గుణించడం కూడా ఒకేలా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 209.6,
  "end": 211.5
 },
 {
  "input": "Whenever you see two 3x3 matrices getting multiplied together, you should imagine first applying the transformation encoded by the right one, then applying the transformation encoded by the left one.",
  "translatedText": "మీరు రెండు 3x3 మాత్రికలు కలిసి గుణించడం చూసినప్పుడల్లా, మీరు ముందుగా కుడివైపు ఎన్‌కోడ్ చేసిన పరివర్తనను వర్తింపజేయాలని, ఆపై ఎడమవైపు ఎన్‌కోడ్ చేసిన పరివర్తనను వర్తింపజేయాలని ఊహించాలి.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.02,
  "end": 223.26
 },
 {
  "input": "It turns out that 3D matrix multiplication is actually pretty important for fields like computer graphics and robotics, since things like rotations and three dimensions can be pretty hard to describe, but they're easier to wrap your mind around if you can break them down as the composition of separate, easier-to-think-about rotations.",
  "translatedText": "కంప్యూటర్ గ్రాఫిక్స్ మరియు రోబోటిక్స్ వంటి ఫీల్డ్‌లకు 3D మ్యాట్రిక్స్ గుణకారం చాలా ముఖ్యమైనదని తేలింది, ఎందుకంటే భ్రమణాలు మరియు మూడు కొలతలు వంటి వాటిని వివరించడం చాలా కష్టం, కానీ మీరు వాటిని విచ్ఛిన్నం చేయగలిగితే అవి మీ మనస్సును చుట్టుముట్టడం సులభం. వేరు వేరు, సులభంగా ఆలోచించగలిగే భ్రమణాల కూర్పు.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 224.06,
  "end": 241.16
 },
 {
  "input": "Performing this matrix multiplication numerically is, once again, pretty similar to the two-dimensional case.",
  "translatedText": "ఈ మాతృక గుణకారాన్ని సంఖ్యాపరంగా అమలు చేయడం, మరోసారి, రెండు-డైమెన్షనల్ కేస్‌తో సమానంగా ఉంటుంది.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 244.36,
  "end": 249.86
 },
 {
  "input": "In fact, a good way to test your understanding of the last video would be to try to reason through what specifically this matrix multiplication should look like, thinking closely about how it relates to the idea of applying two successive transformations in space.",
  "translatedText": "వాస్తవానికి, చివరి వీడియోపై మీ అవగాహనను పరీక్షించడానికి ఒక మంచి మార్గం ఏమిటంటే, ప్రత్యేకంగా ఈ మ్యాట్రిక్స్ గుణకారం ఎలా ఉండాలనే దాని ద్వారా వాదించడానికి ప్రయత్నించడం, అంతరిక్షంలో రెండు వరుస పరివర్తనలను వర్తింపజేయడం అనే ఆలోచనతో ఇది ఎలా సంబంధం కలిగి ఉందో ఆలోచించడం.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.48,
  "end": 263.82
 },
 {
  "input": "In the next video, I'll start getting into the determinant.",
  "translatedText": "తదుపరి వీడియోలో, నేను డిటర్మినేంట్‌లోకి ప్రవేశించడం ప్రారంభిస్తాను.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.14,
  "end": 274.5
 }
]