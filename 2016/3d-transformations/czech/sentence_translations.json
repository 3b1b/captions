[
 {
  "input": "Hey folks, I've got a relatively quick video for you today, just sort of a footnote between chapters.",
  "translatedText": "Ahoj lidi, dnes pro vás mám poměrně rychlé video, jen takovou poznámku pod čarou mezi kapitolami.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In the last two videos I talked about linear transformations and matrices, but I only showed the specific case of transformations that take two-dimensional vectors to other two-dimensional vectors.",
  "translatedText": "V posledních dvou videích jsem mluvil o lineárních transformacích a maticích, ale ukázal jsem pouze konkrétní případ transformací, které převádějí dvourozměrné vektory na jiné dvourozměrné vektory.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In general throughout the series we'll work mainly in two dimensions, mostly because it's easier to actually see on the screen and wrap your mind around.",
  "translatedText": "Obecně budeme v celé sérii pracovat převážně ve dvou rozměrech, hlavně proto, že je snazší je vidět na obrazovce a lépe si je představit.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But more importantly than that, once you get all the core ideas in two dimensions, they carry over pretty seamlessly to higher dimensions.",
  "translatedText": "Ale co je ještě důležitější, jakmile si osvojíte všechny základní myšlenky ve dvou rozměrech, přenesou se bez problémů i do vyšších rozměrů.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Nevertheless, it's good to peek our heads outside of flatland now and then to, you know, see what it means to apply these ideas in more than just those two dimensions.",
  "translatedText": "Přesto je dobré občas nahlédnout mimo rovinu a zjistit, co znamená aplikovat tyto myšlenky ve více než jen v těchto dvou dimenzích.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "For example, consider a linear transformation with three-dimensional vectors as inputs and three-dimensional vectors as outputs.",
  "translatedText": "Uvažujme například lineární transformaci s trojrozměrnými vektory jako vstupy a trojrozměrnými vektory jako výstupy.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "We can visualize this by smooshing around all the points in three-dimensional space, as represented by a grid, in such a way that keeps the grid lines parallel and evenly spaced, and which fixes the origin in place.",
  "translatedText": "Můžeme si to představit tak, že všechny body v trojrozměrném prostoru, znázorněné mřížkou, prohladíme takovým způsobem, aby čáry mřížky byly rovnoběžné a rovnoměrně rozmístěné a aby počátek zůstal na svém místě.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And just as with two dimensions, every point of space that we see moving around is really just a proxy for a vector who has its tip at that point, and what we're really doing is thinking about input vectors moving over to their corresponding outputs.",
  "translatedText": "Stejně jako v případě dvou rozměrů je každý bod prostoru, který vidíme pohybovat se, ve skutečnosti jen zástupným vektorem, který má v tomto bodě svůj hrot, a my ve skutečnosti uvažujeme o vstupních vektorech, které se pohybují k odpovídajícím výstupům.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And just as with two dimensions, one of these transformations is completely described by where the basis vectors go.",
  "translatedText": "A stejně jako u dvou rozměrů je jedna z těchto transformací zcela popsána tím, kam se základní vektory přesunou.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "But now, there are three standard basis vectors that we typically use.",
  "translatedText": "Nyní však existují tři standardní bázové vektory, které obvykle používáme.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "The unit vector in the x direction, i-hat, the unit vector in the y direction, j-hat, and a new guy, the unit vector in the z direction, called k-hat.",
  "translatedText": "Jednotkový vektor ve směru x, i-hat, jednotkový vektor ve směru y, j-hat, a nový člověk, jednotkový vektor ve směru z, zvaný k-hat.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In fact, I think it's easier to think about these transformations by only following those basis vectors, since the full 3D grid representing all points can get kind of messy.",
  "translatedText": "Ve skutečnosti si myslím, že je jednodušší uvažovat o těchto transformacích pouze podle těchto základních vektorů, protože celá 3D mřížka reprezentující všechny body může být poněkud nepřehledná.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "By leaving a copy of the original axes in the background, we can think about the coordinates of where each of these three basis vectors lands.",
  "translatedText": "Když ponecháme kopii původních os v pozadí, můžeme přemýšlet o souřadnicích, kde se nachází každý z těchto tří bázových vektorů.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Record the coordinates of these three vectors as the columns of a 3x3 matrix.",
  "translatedText": "Souřadnice těchto tří vektorů zapište jako sloupce matice 3x3.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "This gives a matrix that completely describes the transformation using only nine numbers.",
  "translatedText": "Tím získáme matici, která kompletně popisuje transformaci pomocí pouhých devíti čísel.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "As a simple example, consider the transformation that rotates space 90 degrees around the y-axis.",
  "translatedText": "Jako jednoduchý příklad uveďme transformaci, která otáčí prostor o 90 stupňů kolem osy y.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So that would mean that it takes i-hat to the coordinates 0,0, negative 1 on the z-axis.",
  "translatedText": "To by tedy znamenalo, že se i-hat dostane na souřadnice 0,0, záporná 1 na ose z.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It doesn't move j-hat, so it stays at the coordinates 0,1,0.",
  "translatedText": "Nepohybuje se j-hat, takže zůstává na souřadnicích 0,1,0.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And then k-hat moves over to the x-axis at 1,0,0.",
  "translatedText": "A pak se klobouk k přesune na osu x do bodu 1,0,0.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Those three sets of coordinates become the columns of a matrix that describes that rotation transformation.",
  "translatedText": "Tyto tři sady souřadnic se stanou sloupci matice, která popisuje transformaci rotace.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "To see where a vector with coordinates x,y,z lands, the reasoning is almost identical to what it was for two dimensions.",
  "translatedText": "Chcete-li zjistit, kde se nachází vektor se souřadnicemi x,y,z, postup je téměř totožný jako v případě dvou rozměrů.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Each of those coordinates can be thought of as instructions for how to scale each basis vector so that they add together to get your vector.",
  "translatedText": "Každou z těchto souřadnic si můžete představit jako návod, jak měřit jednotlivé bázové vektory tak, aby se sečetly a získaly váš vektor.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "And the important part, just like the 2D case, is that this scaling and adding process works both before and after the transformation.",
  "translatedText": "Stejně jako v případě 2D je důležité, že tento proces škálování a sčítání funguje jak před transformací, tak po ní.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "So to see where your vector lands, you multiply those coordinates by the corresponding columns of the matrix, and then you add together the three results.",
  "translatedText": "Chcete-li zjistit, kde se váš vektor nachází, vynásobte tyto souřadnice odpovídajícími sloupci matice a pak tyto tři výsledky sečtěte.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Multiplying two matrices is also similar.",
  "translatedText": "Násobení dvou matic je také podobné.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Whenever you see two 3x3 matrices getting multiplied together, you should imagine first applying the transformation encoded by the right one, then applying the transformation encoded by the left one.",
  "translatedText": "Kdykoli uvidíte dvě matice 3x3, které se násobí dohromady, měli byste si představit, že nejprve použijete transformaci zakódovanou pravou maticí a poté transformaci zakódovanou levou maticí.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "It turns out that 3D matrix multiplication is actually pretty important for fields like computer graphics and robotics, since things like rotations and three dimensions can be pretty hard to describe, but they're easier to wrap your mind around if you can break them down as the composition of separate, easier-to-think-about rotations.",
  "translatedText": "Ukázalo se, že násobení 3D matic je ve skutečnosti docela důležité pro obory, jako je počítačová grafika a robotika, protože věci jako rotace a tři rozměry lze docela těžko popsat, ale je snazší je pochopit, pokud je můžete rozložit jako složení samostatných, snáze představitelných rotací.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "Performing this matrix multiplication numerically is, once again, pretty similar to the two-dimensional case.",
  "translatedText": "Numerické násobení této matice je opět velmi podobné dvourozměrnému případu.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In fact, a good way to test your understanding of the last video would be to try to reason through what specifically this matrix multiplication should look like, thinking closely about how it relates to the idea of applying two successive transformations in space.",
  "translatedText": "Dobrým způsobem, jak si vyzkoušet porozumění poslednímu videu, by bylo zkusit se zamyslet nad tím, jak by konkrétně mělo vypadat násobení matic, a důkladně se zamyslet nad tím, jak souvisí s myšlenkou použití dvou po sobě jdoucích transformací v prostoru.",
  "model": "DeepL",
  "n_reviews": 0
 },
 {
  "input": "In the next video, I'll start getting into the determinant.",
  "translatedText": "V příštím videu se začnu zabývat determinantem.",
  "model": "DeepL",
  "n_reviews": 0
 }
]