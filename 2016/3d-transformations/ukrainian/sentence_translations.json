[
 {
  "input": "Hey folks, I've got a relatively quick video for you today, just sort of a footnote between chapters.",
  "translatedText": "Привіт, друзі, я маю для вас сьогодні відносно швидке відео, просто ніби виноску між розділами.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 13.46,
  "end": 18.52
 },
 {
  "input": "In the last two videos I talked about linear transformations and matrices, but I only showed the specific case of transformations that take two-dimensional vectors to other two-dimensional vectors.",
  "translatedText": "У двох останніх відео я говорив про лінійні перетворення та матриці, але показав лише конкретний випадок перетворень, які перетворюють двовимірні вектори в інші двовимірні вектори.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 19.06,
  "end": 28.38
 },
 {
  "input": "In general throughout the series we'll work mainly in two dimensions, mostly because it's easier to actually see on the screen and wrap your mind around.",
  "translatedText": "Загалом протягом усього серіалу ми працюватимемо переважно у двох вимірах, головним чином тому, що це легше побачити на екрані та сприйняти на слух.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 28.92,
  "end": 36.06
 },
 {
  "input": "But more importantly than that, once you get all the core ideas in two dimensions, they carry over pretty seamlessly to higher dimensions.",
  "translatedText": "Але важливіше те, що як тільки ви отримаєте всі основні ідеї у двох вимірах, вони досить плавно переносяться у вищі виміри.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 36.5,
  "end": 42.8
 },
 {
  "input": "Nevertheless, it's good to peek our heads outside of flatland now and then to, you know, see what it means to apply these ideas in more than just those two dimensions.",
  "translatedText": "Тим не менш, добре час від часу заглядати за межі рівнини, щоб, знаєте, побачити, що означає застосовувати ці ідеї не тільки в цих двох вимірах.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 43.8,
  "end": 51.0
 },
 {
  "input": "For example, consider a linear transformation with three-dimensional vectors as inputs and three-dimensional vectors as outputs.",
  "translatedText": "Наприклад, розглянемо лінійне перетворення з тривимірними векторами як входами та тривимірними векторами як виходами.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 52.34,
  "end": 58.88
 },
 {
  "input": "We can visualize this by smooshing around all the points in three-dimensional space, as represented by a grid, in such a way that keeps the grid lines parallel and evenly spaced, and which fixes the origin in place.",
  "translatedText": "Ми можемо візуалізувати це, згладжуючи всі точки в тривимірному просторі, представленому сіткою, таким чином, щоб лінії сітки залишалися паралельними та рівномірними, і це фіксувало початок координат на місці.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 60.16,
  "end": 72.52
 },
 {
  "input": "And just as with two dimensions, every point of space that we see moving around is really just a proxy for a vector who has its tip at that point, and what we're really doing is thinking about input vectors moving over to their corresponding outputs.",
  "translatedText": "І так само, як у випадку з двома вимірами, кожна точка простору, яку ми бачимо, що рухається, насправді є просто проксі для вектора, який має свою вершину в цій точці, і що ми насправді робимо, це думаємо про те, як вхідні вектори рухаються до відповідних виходів.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 73.46,
  "end": 87.16
 },
 {
  "input": "And just as with two dimensions, one of these transformations is completely described by where the basis vectors go.",
  "translatedText": "І як і у випадку з двома вимірами, одне з цих перетворень повністю описується тим, куди йдуть базисні вектори.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 87.9,
  "end": 93.56
 },
 {
  "input": "But now, there are three standard basis vectors that we typically use.",
  "translatedText": "Але зараз є три стандартні базисні вектори, які ми зазвичай використовуємо.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 94.16,
  "end": 97.68
 },
 {
  "input": "The unit vector in the x direction, i-hat, the unit vector in the y direction, j-hat, and a new guy, the unit vector in the z direction, called k-hat.",
  "translatedText": "Одиничний вектор у напрямку x називається i-капелюх, одиничний вектор у напрямку y називається j-капелюх, і новенький, одиничний вектор у напрямку z, називається k-капелюх.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 98.0,
  "end": 106.56
 },
 {
  "input": "In fact, I think it's easier to think about these transformations by only following those basis vectors, since the full 3D grid representing all points can get kind of messy.",
  "translatedText": "Насправді, я думаю, що легше думати про ці перетворення, дотримуючись лише цих базисних векторів, оскільки повна тривимірна сітка, що представляє всі точки, може стати дещо заплутаною.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 107.14,
  "end": 116.02
 },
 {
  "input": "By leaving a copy of the original axes in the background, we can think about the coordinates of where each of these three basis vectors lands.",
  "translatedText": "Залишивши копію оригінальних осей на задньому плані, ми можемо подумати про координати, де приземляється кожен із цих трьох базисних векторів.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 116.92,
  "end": 124.0
 },
 {
  "input": "Record the coordinates of these three vectors as the columns of a 3x3 matrix.",
  "translatedText": "Запишіть координати цих трьох векторів у вигляді стовпців матриці 3x3.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 125.82,
  "end": 130.46
 },
 {
  "input": "This gives a matrix that completely describes the transformation using only nine numbers.",
  "translatedText": "Це дає матрицю, яка повністю описує перетворення, використовуючи лише дев’ять чисел.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.26,
  "end": 136.16
 },
 {
  "input": "As a simple example, consider the transformation that rotates space 90 degrees around the y-axis.",
  "translatedText": "Як простий приклад, розглянемо перетворення, яке повертає простір на 90 градусів навколо осі y.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 137.2,
  "end": 143.96
 },
 {
  "input": "So that would mean that it takes i-hat to the coordinates 0,0, negative 1 on the z-axis.",
  "translatedText": "Це означає, що він переміщує i-шапку у координати 0,0, від'ємне значення 1 на осі z.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 144.86,
  "end": 150.1
 },
 {
  "input": "It doesn't move j-hat, so it stays at the coordinates 0,1,0.",
  "translatedText": "Капелюх не рухається, тому він стоїть у точці з координатами 0,1,0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.82,
  "end": 154.28
 },
 {
  "input": "And then k-hat moves over to the x-axis at 1,0,0.",
  "translatedText": "А потім k-капелюх пересувається на вісь x на 1,0,0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 154.88,
  "end": 158.84
 },
 {
  "input": "Those three sets of coordinates become the columns of a matrix that describes that rotation transformation.",
  "translatedText": "Ці три набори координат стають стовпчиками матриці, яка описує цю трансформацію обертання.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 160.99,
  "end": 166.76
 },
 {
  "input": "To see where a vector with coordinates x,y,z lands, the reasoning is almost identical to what it was for two dimensions.",
  "translatedText": "Щоб побачити, куди потрапляє вектор з координатами x,y,z, міркування майже ідентичні до тих, що були для двовимірного простору.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 169.76,
  "end": 176.22
 },
 {
  "input": "Each of those coordinates can be thought of as instructions for how to scale each basis vector so that they add together to get your vector.",
  "translatedText": "Кожну з цих координат можна розглядати як інструкцію щодо того, як масштабувати кожен базисний вектор так, щоб вони складалися разом, щоб отримати ваш вектор.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 176.94,
  "end": 184.04
 },
 {
  "input": "And the important part, just like the 2D case, is that this scaling and adding process works both before and after the transformation.",
  "translatedText": "І важливою частиною, як і у випадку 2D, є те, що процес масштабування та додавання працює як до, так і після трансформації.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 186.26,
  "end": 194.0
 },
 {
  "input": "So to see where your vector lands, you multiply those coordinates by the corresponding columns of the matrix, and then you add together the three results.",
  "translatedText": "Отже, щоб побачити, куди потрапляє ваш вектор, ви множите ці координати на відповідні стовпці матриці, а потім додаєте три результати.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 196.38,
  "end": 204.82
 },
 {
  "input": "Multiplying two matrices is also similar.",
  "translatedText": "Перемноження двох матриць також аналогічно.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 209.6,
  "end": 211.5
 },
 {
  "input": "Whenever you see two 3x3 matrices getting multiplied together, you should imagine first applying the transformation encoded by the right one, then applying the transformation encoded by the left one.",
  "translatedText": "Щоразу, коли ви бачите дві матриці 3x3, які перемножуються, вам слід уявити, що спочатку застосовано перетворення, закодоване правою, а потім застосоване перетворення, закодоване лівою.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 212.02,
  "end": 223.26
 },
 {
  "input": "It turns out that 3D matrix multiplication is actually pretty important for fields like computer graphics and robotics, since things like rotations and three dimensions can be pretty hard to describe, but they're easier to wrap your mind around if you can break them down as the composition of separate, easier-to-think-about rotations.",
  "translatedText": "Виявилося, що тривимірне множення матриць насправді є дуже важливим для таких галузей, як комп’ютерна графіка та робототехніка, оскільки такі речі, як обертання та тривимірність, досить важко описати, але їх легше осягнути, якщо ви можете розбити їх як склад окремих, легших для уявлення ротацій.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 224.06,
  "end": 241.16
 },
 {
  "input": "Performing this matrix multiplication numerically is, once again, pretty similar to the two-dimensional case.",
  "translatedText": "Чисельне виконання цього множення матриці знову ж таки дуже схоже на двовимірний випадок.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 244.36,
  "end": 249.86
 },
 {
  "input": "In fact, a good way to test your understanding of the last video would be to try to reason through what specifically this matrix multiplication should look like, thinking closely about how it relates to the idea of applying two successive transformations in space.",
  "translatedText": "Насправді, гарним способом перевірити ваше розуміння останнього відео було б спробувати міркувати, як саме має виглядати це матричне множення, уважно подумавши про те, як воно пов’язане з ідеєю застосування двох послідовних перетворень у просторі.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 250.48,
  "end": 263.82
 },
 {
  "input": "In the next video, I'll start getting into the determinant.",
  "translatedText": "У наступному відео я почну вивчати визначник.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 272.14,
  "end": 274.5
 }
]