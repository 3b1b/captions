[
 {
  "input": "Hey folks, I've got a relatively quick video for you today, just sort of a footnote between chapters.",
  "translatedText": "Hey Leute, ich habe heute ein relativ schnelles Video für euch, nur eine Art Fußnote zwischen den Kapiteln.",
  "model": "DeepL",
  "from_community_srt": "[Klassische Musik] \"Lisa: Und, wo ist mein Dad? Frink: Es sollte selbst für die dämlichste Person, welche eine höheren Abschluss in hyperbolischer Topologie hat, einleuchtend sein, dass Homer Simpson in sich verlaufen hat, und zwar in... ... (dramatische Pause) die dritte Dimension.\" Hey Leute, dies ist ein relativ kurzes Video für Euch heute, nur etwas wie eine kleine Randnotiz zwischen zwei Abschnitten.",
  "n_reviews": 0,
  "start": 13.46,
  "end": 18.52
 },
 {
  "input": "In the last two videos I talked about linear transformations and matrices, but I only showed the specific case of transformations that take two-dimensional vectors to other two-dimensional vectors.",
  "translatedText": "In den letzten beiden Videos habe ich über lineare Transformationen und Matrizen gesprochen, aber ich habe nur den speziellen Fall von Transformationen gezeigt, die zweidimensionale Vektoren in andere zweidimensionale Vektoren überführen.",
  "model": "DeepL",
  "from_community_srt": "In den letzten beiden Videos habe ich über lineare Transformationen und Matrizen geprochen, aber habe dabei nur einen Spezialfall gezeigt, nämlich die Transformation von zwei-dimensionalen Vektoren zu anderen",
  "n_reviews": 0,
  "start": 19.06,
  "end": 28.38
 },
 {
  "input": "In general throughout the series we'll work mainly in two dimensions, mostly because it's easier to actually see on the screen and wrap your mind around.",
  "translatedText": "Im Allgemeinen werden wir in dieser Serie hauptsächlich in zwei Dimensionen arbeiten, weil es einfacher ist, sie auf dem Bildschirm zu sehen und zu begreifen.",
  "model": "DeepL",
  "from_community_srt": "zwei-dimensionalen Vektoren Während dieser Serie werden wir uns hauptsächlich in der zweiten Dimension aufhalten. Vor allem, weil die zweite Dimension sich einfach ansehen und vorstellen lässt, aber wichtiger noch,",
  "n_reviews": 0,
  "start": 28.92,
  "end": 36.06
 },
 {
  "input": "But more importantly than that, once you get all the core ideas in two dimensions, they carry over pretty seamlessly to higher dimensions.",
  "translatedText": "Aber was noch wichtiger ist: Wenn du einmal alle Kernideen in zwei Dimensionen verstanden hast, lassen sie sich ziemlich nahtlos auf höhere Dimensionen übertragen.",
  "model": "DeepL",
  "from_community_srt": "sobald man die Grundidee verstanden hat, kann man diese nahtlos auf höhere Dimensionen übertragen.",
  "n_reviews": 0,
  "start": 36.5,
  "end": 42.8
 },
 {
  "input": "Nevertheless, it's good to peek our heads outside of flatland now and then to, you know, see what it means to apply these ideas in more than just those two dimensions.",
  "translatedText": "Trotzdem ist es gut, ab und zu einen Blick über den Tellerrand zu werfen, um zu sehen, was es bedeutet, diese Ideen in mehr als nur diesen zwei Dimensionen anzuwenden.",
  "model": "DeepL",
  "from_community_srt": "Wie auch immer, sich ab und zu aus dem Flachland herauszutrauen ist hilfreich,... um zu sehen, was diese Konzepte in mehr als zwei Dimensionen bedeuten.",
  "n_reviews": 0,
  "start": 43.8,
  "end": 51.0
 },
 {
  "input": "For example, consider a linear transformation with three-dimensional vectors as inputs and three-dimensional vectors as outputs.",
  "translatedText": "Betrachte zum Beispiel eine lineare Transformation mit dreidimensionalen Vektoren als Eingaben und dreidimensionalen Vektoren als Ausgaben.",
  "model": "DeepL",
  "from_community_srt": "Zum Beispiel: Eine lineare Transformation mit 3D Vektoren als Eingabe und 3D Vektoren als Ausgabe.",
  "n_reviews": 0,
  "start": 52.34,
  "end": 58.88
 },
 {
  "input": "We can visualize this by smooshing around all the points in three-dimensional space, as represented by a grid, in such a way that keeps the grid lines parallel and evenly spaced, and which fixes the origin in place.",
  "translatedText": "Wir können uns das vorstellen, indem wir alle Punkte im dreidimensionalen Raum, die durch ein Gitter dargestellt werden, so verschieben, dass die Gitterlinien parallel und gleichmäßig verteilt bleiben und der Ursprung an seinem Platz bleibt.",
  "model": "DeepL",
  "from_community_srt": "Wir sie uns vorstellen, indem wir alle Punkte im dreidimensionalen Raum herumschieben, durch ein Gitter dargestellt, wobei  wir die Gitterlinien immer parallel und mit gleichbleibenden Abstand zueinander lassen, sowie den Ursprung nicht verändern.",
  "n_reviews": 0,
  "start": 60.16,
  "end": 72.52
 },
 {
  "input": "And just as with two dimensions, every point of space that we see moving around is really just a proxy for a vector who has its tip at that point, and what we're really doing is thinking about input vectors moving over to their corresponding outputs.",
  "translatedText": "Und genau wie in zwei Dimensionen ist jeder Punkt im Raum, der sich bewegt, nur ein Stellvertreter für einen Vektor, dessen Spitze sich an diesem Punkt befindet, und wir denken dabei an Eingangsvektoren, die sich zu ihren entsprechenden Ausgängen bewegen.",
  "model": "DeepL",
  "from_community_srt": "Und wie auch in zwei Dimensionen ist jeder Punkt, der sich hier bewegt, einfach ein Stellvertreter für einen Vektor, der in diesem Punkt endet, und was wir wirklich machen, ist Eingabe-Vektoren anzuschauen, die sich zu ihrem Ausgabe-Vektor *hinbewegen*,",
  "n_reviews": 0,
  "start": 73.46,
  "end": 87.16
 },
 {
  "input": "And just as with two dimensions, one of these transformations is completely described by where the basis vectors go.",
  "translatedText": "Und genau wie bei den zwei Dimensionen wird eine dieser Transformationen vollständig dadurch beschrieben, wohin die Basisvektoren gehen.",
  "model": "DeepL",
  "from_community_srt": "und wie auch in zwei Dimensionen, kann jede dieser Transformationen komplett durch die Veränderung der Basisvektoren beschrieben werden.",
  "n_reviews": 0,
  "start": 87.9,
  "end": 93.56
 },
 {
  "input": "But now, there are three standard basis vectors that we typically use.",
  "translatedText": "Nun gibt es aber drei Standard-Basisvektoren, die wir normalerweise verwenden.",
  "model": "DeepL",
  "from_community_srt": "Aber nun gibt es drei Basisvektoren,",
  "n_reviews": 0,
  "start": 94.16,
  "end": 97.68
 },
 {
  "input": "The unit vector in the x direction, i-hat, the unit vector in the y direction, j-hat, and a new guy, the unit vector in the z direction, called k-hat.",
  "translatedText": "Der Einheitsvektor in x-Richtung, i-hat, der Einheitsvektor in y-Richtung, j-hat, und ein neuer Typ, der Einheitsvektor in z-Richtung, genannt k-hat.",
  "model": "DeepL",
  "from_community_srt": "welche normalerweise gebraucht werden: Der Einheitsvektor in x-Richtung, i-Hut; der Einheitsvektor in y-Richtung, j-Hut; und einen Neuen - den Einheitsvektor in z-Richtung,",
  "n_reviews": 0,
  "start": 98.0,
  "end": 106.56
 },
 {
  "input": "In fact, I think it's easier to think about these transformations by only following those basis vectors, since the full 3D grid representing all points can get kind of messy.",
  "translatedText": "Ich denke, es ist einfacher, diese Transformationen nur anhand der Basisvektoren zu betrachten, da das vollständige 3D-Gitter, das alle Punkte darstellt, ziemlich unübersichtlich werden kann.",
  "model": "DeepL",
  "from_community_srt": "k-Hut. Ich denke, Transformationen sieht man am einfachsten, wenn man nur diesen drei Basisvektoren folgt, da es unübersichtlich ist, wenn sich das gesamte Gitter bewegt.",
  "n_reviews": 0,
  "start": 107.14,
  "end": 116.02
 },
 {
  "input": "By leaving a copy of the original axes in the background, we can think about the coordinates of where each of these three basis vectors lands.",
  "translatedText": "Wenn wir eine Kopie der ursprünglichen Achsen im Hintergrund lassen, können wir uns überlegen, wo jeder dieser drei Basisvektoren landet.",
  "model": "DeepL",
  "from_community_srt": "Daher lassen wir einfach die ursprünglichen Achsen im Hintergrund stehen, und betrachten dann die Koordinaten der drei Basisvektoren.",
  "n_reviews": 0,
  "start": 116.92,
  "end": 124.0
 },
 {
  "input": "Record the coordinates of these three vectors as the columns of a 3x3 matrix.",
  "translatedText": "Schreibe die Koordinaten dieser drei Vektoren als Spalten einer 3x3-Matrix auf.",
  "model": "DeepL",
  "from_community_srt": "Diese Koordinaten schreiben wir dann als Spalten einer 3x3-Matrix.",
  "n_reviews": 0,
  "start": 125.82,
  "end": 130.46
 },
 {
  "input": "This gives a matrix that completely describes the transformation using only nine numbers.",
  "translatedText": "So entsteht eine Matrix, die die Transformation mit nur neun Zahlen vollständig beschreibt.",
  "model": "DeepL",
  "from_community_srt": "Damit erhalten wir eine Matrix, welche die Transformation mit nur 9 Zahlen komplett beschreibt.",
  "n_reviews": 0,
  "start": 131.26,
  "end": 136.16
 },
 {
  "input": "As a simple example, consider the transformation that rotates space 90 degrees around the y-axis.",
  "translatedText": "Ein einfaches Beispiel ist die Transformation, bei der der Raum um 90 Grad um die y-Achse gedreht wird.",
  "model": "DeepL",
  "from_community_srt": "Betrachte als Beispiel die Transformation, welche den Raum 90 Grad um die y-Achse dreht.",
  "n_reviews": 0,
  "start": 137.2,
  "end": 143.96
 },
 {
  "input": "So that would mean that it takes i-hat to the coordinates 0,0, negative 1 on the z-axis.",
  "translatedText": "Das würde also bedeuten, dass es i-hat zu den Koordinaten 0,0, negativ 1 auf der z-Achse bringt.",
  "model": "DeepL",
  "from_community_srt": "Das würde also i-Hut zu den Koordinaten [0,0,-1] auf der z-Achse bewegen, j-Hut bewegt sich nicht,",
  "n_reviews": 0,
  "start": 144.86,
  "end": 150.1
 },
 {
  "input": "It doesn't move j-hat, so it stays at the coordinates 0,1,0.",
  "translatedText": "Es bewegt sich nicht j-hat, also bleibt es bei den Koordinaten 0,1,0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.82,
  "end": 154.28
 },
 {
  "input": "And then k-hat moves over to the x-axis at 1,0,0.",
  "translatedText": "Und dann bewegt sich k-hat auf der x-Achse bei 1,0,0.",
  "model": "DeepL",
  "from_community_srt": "es bleibt also bei den Koordinaten [0,1,0] und dann bewegt sich noch k-Hut zur x-Achse bei [1,0,0].",
  "n_reviews": 0,
  "start": 154.88,
  "end": 158.84
 },
 {
  "input": "Those three sets of coordinates become the columns of a matrix that describes that rotation transformation.",
  "translatedText": "Diese drei Koordinatensätze werden zu den Spalten einer Matrix, die die Rotationstransformation beschreibt.",
  "model": "DeepL",
  "from_community_srt": "Diese drei Koordinatengruppen werden zu den Spalten einer Matrix, welche diese Rotations-Transformation beschreibt.",
  "n_reviews": 0,
  "start": 160.99,
  "end": 166.76
 },
 {
  "input": "To see where a vector with coordinates x,y,z lands, the reasoning is almost identical to what it was for two dimensions.",
  "translatedText": "Um zu sehen, wo ein Vektor mit den Koordinaten x,y,z landet, ist die Argumentation fast identisch mit der, die für zwei Dimensionen gilt.",
  "model": "DeepL",
  "from_community_srt": "Um herauszufinden, wo ein Vektor mit Koordinaten XYZ landet, ist das Vorgehen beinahe identisch mit dem Vorgehen für zwei Dimensionen - jede dieser Koordinaten kann,",
  "n_reviews": 0,
  "start": 169.76,
  "end": 176.22
 },
 {
  "input": "Each of those coordinates can be thought of as instructions for how to scale each basis vector so that they add together to get your vector.",
  "translatedText": "Jede dieser Koordinaten kann man sich als Anleitung vorstellen, wie man jeden Basisvektor so skaliert, dass sie sich zu deinem Vektor addieren.",
  "model": "DeepL",
  "from_community_srt": "als Anleitung angesehen werden, wie jeder Basisvektor skaliert werden soll,",
  "n_reviews": 0,
  "start": 176.94,
  "end": 184.04
 },
 {
  "input": "And the important part, just like the 2D case, is that this scaling and adding process works both before and after the transformation.",
  "translatedText": "Und der wichtige Teil ist, genau wie im 2D-Fall, dass dieser Skalierungs- und Additionsprozess sowohl vor als auch nach der Transformation funktioniert.",
  "model": "DeepL",
  "from_community_srt": "sodass sie zusammengezählt den neuen Vektor ergeben. Wichtig ist, wie auch in 2D, dass dieser Skalierung- & Additionsprozess vor wie auch nach der Transformation funktioniert.",
  "n_reviews": 0,
  "start": 186.26,
  "end": 194.0
 },
 {
  "input": "So to see where your vector lands, you multiply those coordinates by the corresponding columns of the matrix, and then you add together the three results.",
  "translatedText": "Um zu sehen, wo dein Vektor landet, multiplizierst du diese Koordinaten mit den entsprechenden Spalten der Matrix und addierst dann die drei Ergebnisse.",
  "model": "DeepL",
  "from_community_srt": "Um nun zu sehen wo der Vektor landet, multipliziere diese Koordinaten mit den entsprechenden Spalten der Matrix und addiere dann die drei Resultate.",
  "n_reviews": 0,
  "start": 196.38,
  "end": 204.82
 },
 {
  "input": "Multiplying two matrices is also similar.",
  "translatedText": "Auch die Multiplikation zweier Matrizen ist ähnlich.",
  "model": "DeepL",
  "from_community_srt": "Die Multiplikation zweier Matrizen ist auch ähnlich: Jedesmal,",
  "n_reviews": 0,
  "start": 209.6,
  "end": 211.5
 },
 {
  "input": "Whenever you see two 3x3 matrices getting multiplied together, you should imagine first applying the transformation encoded by the right one, then applying the transformation encoded by the left one.",
  "translatedText": "Immer wenn du siehst, dass zwei 3x3-Matrizen miteinander multipliziert werden, solltest du dir vorstellen, zuerst die Transformation anzuwenden, die durch die rechte Matrix kodiert wird, und dann die Transformation, die durch die linke Matrix kodiert wird.",
  "model": "DeepL",
  "from_community_srt": "wenn zwei 3x3-Matrizen zusammenmultipliziert werden, solltest Du dir vorstellen, zuerst die in der rechten Matrix verschlüsselte Transformation anzuwenden, dann die in der linken Matrix verschlüsselten Transformation anzuwenden.",
  "n_reviews": 0,
  "start": 212.02,
  "end": 223.26
 },
 {
  "input": "It turns out that 3D matrix multiplication is actually pretty important for fields like computer graphics and robotics, since things like rotations and three dimensions can be pretty hard to describe, but they're easier to wrap your mind around if you can break them down as the composition of separate, easier-to-think-about rotations.",
  "translatedText": "Es hat sich herausgestellt, dass die 3D-Matrixmultiplikation für Bereiche wie Computergrafik und Robotik ziemlich wichtig ist, da Dinge wie Rotationen und drei Dimensionen ziemlich schwer zu beschreiben sind, aber sie sind leichter zu verstehen, wenn man sie in einzelne, leichter zu denkende Rotationen zerlegen kann.",
  "model": "DeepL",
  "from_community_srt": "3D-Matrix-Multiplikation ist ziemlich wichtig für Bereiche wie Computergrafik und Robotics, da Transformationen wie Rotationen in 3 Dimensionen ziemlich schwierig zu beschreiben sein können, doch sie sind einfach zu verstehen, wenn man sie aufteilt, und zwar als Zusammensetzung getrennter,",
  "n_reviews": 0,
  "start": 224.06,
  "end": 241.16
 },
 {
  "input": "Performing this matrix multiplication numerically is, once again, pretty similar to the two-dimensional case.",
  "translatedText": "Die numerische Durchführung dieser Matrixmultiplikation ist wiederum ziemlich ähnlich wie im zweidimensionalen Fall.",
  "model": "DeepL",
  "from_community_srt": "einfacher vorstellbarer Rotationen. Diese Matrixmultiplikationen numerisch durchzuführen, ist wiederum ziemlich ähnlich zum 2D-Fall.",
  "n_reviews": 0,
  "start": 244.36,
  "end": 249.86
 },
 {
  "input": "In fact, a good way to test your understanding of the last video would be to try to reason through what specifically this matrix multiplication should look like, thinking closely about how it relates to the idea of applying two successive transformations in space.",
  "translatedText": "Ein guter Weg, um dein Verständnis des letzten Videos zu testen, wäre es, zu überlegen, wie diese Matrixmultiplikation aussehen sollte, indem du dir überlegst, wie sie mit der Idee zusammenhängt, zwei aufeinanderfolgende Transformationen im Raum anzuwenden.",
  "model": "DeepL",
  "from_community_srt": "Ein guter Weg, um Euer Verständnis des letzten Videos zu überprüfen, wäre sich zu überlegen, wie genau diese Matrix- Multiplikation aussehen sollte, im Bezug zur Vorstellung, zwei aufeinanderfolgenden Tranformationen im Raum durchzuführen.",
  "n_reviews": 0,
  "start": 250.48,
  "end": 263.82
 },
 {
  "input": "In the next video, I'll start getting into the determinant.",
  "translatedText": "Im nächsten Video werde ich mich mit der Determinante befassen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 272.14,
  "end": 274.5
 }
]