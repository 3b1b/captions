[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "",
  "from_community_srt": "안녕하세요 여러분? 지난 시간에는 선형변환이 어떤 것인지 설명해드렸고 선형변환을 행렬을 이용해 표현하는 방법도 소개해드렸습니다.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "",
  "from_community_srt": "지난 번에 다룬 내용을 다시 요약해드리겠습니다. 왜냐하면 이건 정말 중요한 것이거든요. 물론, 요약만으로 부족하다고 느낀다면 다시 이전 동영상 전체를 시청하는 것도 좋은 방법입니다.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "",
  "from_community_srt": "기술적으로 말하자면, 선형변환은 한마디로 함수입니다. 벡터를 집어넣으면[벡터가 정의역] 벡터가 나오는 것이지요.[벡터가 치역] 지난번에 제가 이것을 시각적으로 보여드렸습니다. 어떻게  선형변환을 생각할 수 있는 지를요. 공간을 이리저리 비틀면서 말이죠. 물론 격자선들은 여전히 평행하고 균등간격을 유지한 채로요. 그리고 원점은 고정되어 있습니다.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "",
  "from_community_srt": "여기서 중요한 점은, 기저벡터가 선형변환에 의해 어떻게 옮겨졌는지를 알면, 그 선형 변환이 무엇인지 파악할 수 있다는 것입니다. 예를 들어, 2차원 공간에서는 i-hat 벡터와 j-hat 벡터로요.",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "",
  "from_community_srt": "왜냐하면 모든 벡터들은 이 i-hat 벡터와 j-hat 벡터의 선형 결합으로 모두 표현이 가능하기 때문이죠.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "",
  "from_community_srt": "좌표값이 (x,y) 인 벡터는 i-hat 벡터의 x 배 + j-hat 벡터의 y 배로 표현됩니다.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "",
  "from_community_srt": "선형변환을 하고 나서도, 격자선들이 여전히 평행을 유지하고 균등간격을 유지한다는 멋진 결론을 얻었죠.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "",
  "from_community_srt": "변환된 벡터는 변환된 i-hat 의 x배 + 변환된 j-hat 의 y 배로 표현된다는 것도요.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "",
  "from_community_srt": "이 말의 뜻은 만약 우리가 변환된 i-hat 의 좌표값과 변환된 j-hat의 좌표값을 안다면, 초기값 (x, y) 에서 시작한 벡터가 변환  후 어디로 갈지 계산해낼 수 있다는 것입니다. 바로 변환된 i-hat 좌표값의 x 배와 변환된 j-hat 좌표값의 y 배를 이용해서 말이죠.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "",
  "from_community_srt": "관례적으로 i-hat 과 j-hat 의 변형후 좌표값을 행렬로 표현합니다. 그리고 이 열들(벡터) 각각을 x, y로 스케일링한 것을 행렬-벡터 곱셈으로 정의합니다.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "",
  "from_community_srt": "이 방법으로 보면, 한 행렬은 하나의 선형변환을 나타냅니다. 그리고 벡터에 행렬을 곱하는 것은 수식적으로 그 벡터를 선형변환하는 것과 같습니다.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "",
  "from_community_srt": "됐습니다. 요약 끝. 새 주제로 넘어갑시다.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "",
  "from_community_srt": "아마도 선형변환을 하고 나서 거기에 다시 선형변환을 하는 것도 설명하고 싶어하는 사람도 있을 것입니다.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "",
  "from_community_srt": "예를 들면, 시계방향으로 90도 회전시키고, 그리고 나서 옆으로 밀면(shearing) 어떻게 되는 지를요.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "",
  "from_community_srt": "전체 효과는 또 다른 하나의 선형변환이라는 것입니다. 회전과 밂과는 구별되는 무언가라는 것이죠.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "",
  "from_community_srt": "이렇게 새로 생겨난 선형변환을 흔히 두 개의 선형변환의 합성이라고 일컫습니다.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "",
  "from_community_srt": "다른 선형변환과 마찬가지로, 이 선형변환도 행렬로 표현이 가능합니다. 위와 같이 i-hat, j-hat을 이용해서요.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "",
  "from_community_srt": "여기서 i-hat 의 최종도착지는 (1,1)입니다. 그럼 이것을 행렬의 첫번째 열로 적으면 됩니다.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "",
  "from_community_srt": "마찬가지로, j-hat 의 최종도착지는 (-1, 0)입니다. 그럼 이걸 행렬의 두번째 열로 적으면 됩니다.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "",
  "from_community_srt": "이 새 행렬이 바로 회전하고 미는 변환의 최종 효과을 나타냅니다. 하지만 연속되는 변환이 아니라,",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "",
  "from_community_srt": "단지 하나의 변환으로서만 표현하고 있죠. 새 행렬을 생각해보는 방법이 있습니다.",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "",
  "from_community_srt": "어떤 벡터를 가져다가 회전시키고 미는 변환을 시키면, 결과가 무엇인기 계산해야되는 이 긴 과정은 다음과 같습니다. 우선 회전을 나타내는 행렬에 벡터를 곱합니다. 그리고 그 결과를 미는 것을 나타내는 행렬 오른쪽에다 놓고 곱하면 이것이 수치적으로 표현된,",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "",
  "from_community_srt": "어떤 벡터에다가 회전 시키고 민 것을 적용한 뒤의 결과입니다.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "",
  "from_community_srt": "하지만 우리가 방금 구한 행렬을 곱해도  같은 결과값을 얻습니다. 어떤 벡터를 고르던지 말이죠. 우리가 구한 새 행렬은 회전하고 미는 것과 같은 효과를 나타내기 때문입니다.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "",
  "from_community_srt": "지금까지 설명한 것들을 기반으로 해서, 이 새 행렬을, 두 원본 행렬의 곱(product)이라고 불러도 될 것 같습니다.",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "",
  "from_community_srt": "그렇지 않나요? 그럼 잠시, 행렬의 곱을 좀 더 일반적으로 계산하는 방법에 대해 생각해보겠습니다. 근데 숫자들 사이에서 헤매기 쉬우므로 조심하십시오.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "",
  "from_community_srt": "항상 여러분들이 기억해야 할 것은, 두 행렬의 곱셈은 기하학적으로 한 변환을 적용하고나서 다른 변환을 적용한 것과 같다는 것입니다.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "",
  "from_community_srt": "근데 이상한 점이 있는데, 읽을 때 오른쪽에서 왼쪽방향으로 봐야합니다.",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "",
  "from_community_srt": "우측의 행렬이 첫번째 변환을 의미하고, 좌측의 행렬로 그 다음 변환 적용을 나타내죠.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "",
  "from_community_srt": "이것은 함수 표기법에서 유래한 것입니다. 함수를 변수의 왼쪽에다 적기 때문이죠. 그래서 두 함수를 합성할 때마다, 오른쪽에서 왼쪽으로 읽어야 합니다.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "",
  "from_community_srt": "히브리어 독자들에게 좋은 소식일 테지만, 우리에게는 나쁜 소식입니다.",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "",
  "from_community_srt": "다른 예를 살펴 보죠.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "",
  "from_community_srt": "행렬 (1, 1), (-2, 0) 이 있을때, 이 변환은 이렇게 보일텐데,",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "",
  "from_community_srt": "이 변환을 M1 이라고 합시다.",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "",
  "from_community_srt": "그 다음 행렬 (0, 1), (2, 0) 을  있을때,",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "",
  "from_community_srt": "이 변환은 이렇게 보일텐데, 이번엔 M2 라고 합시다.",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "",
  "from_community_srt": "M1을 적용하고 나서 M2를 적용한 결과는 우리에게 새로운 변환을 나타내죠. 자, 이 행렬을 찾아봅시다.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "",
  "from_community_srt": "하지만 이번엔, 애니메이션을 보지 않고 찾아내봅시다. 대신에 각 행렬을 나타내는 수치만 가지고 찾아내봅시다.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "",
  "from_community_srt": "우선 i-hat 벡터가 어떻게 되는지 부터 봅시다.",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "",
  "from_community_srt": "M1 변환 적용 후 나타나는 새로운 i-hat 좌표는 정의에 의해, M1의 첫 번째 열에 나타나죠. 즉, (1,",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "",
  "from_community_srt": "1) M2를 적용한 후를 살펴보려면, M2 행렬에 이 벡터 (1,1)를 곱하면 됩니다.",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "",
  "from_community_srt": "지난번에 설명한 방법으로 계산하면, 벡터 (2, 1) 라는 값을 얻을 수 있습니다.",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "",
  "from_community_srt": "이 벡터가 합성행렬의 첫 번째 열입니다.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "",
  "from_community_srt": "마찬가지로, j-hat 에도 적용해보면, M1의 두 번째 열이 첫번째 변환 후인 좌표 (-2,",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "",
  "from_community_srt": "0)가 되고 다음, M2 행렬을 이 벡터에다 곱하면, 행렬-벡터 곱으로 계산해서 (0, -2)이라는 값을 얻을 수 있습니다. 이것이 합성행렬의 두번재 열입니다.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "",
  "from_community_srt": "다시 한 번 설명드리겠습니다. 하지만 이번에는 각 행렬 안에 숫자를 변수로 대체해서 보여드리겠습니다. 아까 전과 같이 진행할 것이라서,",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "",
  "from_community_srt": "기호가 더 많고, 쓸 공간도 더 많이 필요하겠죠. 하지만 이전에 행렬 곱셈을 요령으로 배웠던 사람이라면 꽤 만족할 것입니다.",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "",
  "from_community_srt": "i-hat 벡터가 어떻게 되는 지부터 봅시다. 오른쪽 행렬의 첫째 열부터 보죠. 이것은 첫번째 변환 후의 i-hat의 위치입니다.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "",
  "from_community_srt": "이 열을 왼쪽 행렬에다가 곱하면, 한 번 변환을 거친 i-hat이 최종적으로 어디에 도달하는지 알 수 있습니다.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "",
  "from_community_srt": "그래서 합성행렬의 첫번째 열은 항상 왼쪽 행렬과 오른쪽 행렬의 첫째열의 곱셈과 같습니다.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "",
  "from_community_srt": "마찬가지로,",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "",
  "from_community_srt": "j-hat 은 오른쪽 행렬의 두번째 열의 값을 거쳐 왼쪽 행렬을 곱하여서 최종 위치가 나옵니다. 따라서, 이 값이 합성 행렬의 두번째 열입니다.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "",
  "from_community_srt": "주의할 점은, 기호가 너무 많기 때문에 이것을 기억하기 위해서 어떤 요령으로 많이들 가르치죠. 특정 알고리즘 순서로서 기억하기 쉽게 말이요.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "",
  "from_community_srt": "하지만 그렇게 암기하기 전에 꼭, 행렬 곱셈이 무엇을 나타낸는지 생각해보는 습관을 가졌으면 좋겠습니다. 그것은 한 변환을 적용한 후, 다른 변환을 적용한다는 것.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "",
  "from_community_srt": "방금 제가 설명드린 것들은 여러분들이  행렬의 곱셈에 대해 더 쉽게 이해할 수 있도록 어떤 틀을 제공해 줄것입니다.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "",
  "from_community_srt": "예를들어, 다음과 같은 질문이 있습니다.",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "",
  "from_community_srt": "우리가 두 행렬을 곱할 때 그 두 행렬을 곱하는 순서가 상관있을까요?",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "",
  "from_community_srt": "간단한 예제를 통해 알아봅시다. 앞에서 했었던 방법으로 말이죠.",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "",
  "from_community_srt": "i-hat 은 고정이고 j-hat 만 오른쪽으로 밀어지는 미는 (shear) 변환과 90 ° 회전 변환을 이용해서요.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "",
  "from_community_srt": "만약 먼저 민 후 회전시키면, i-hat 의 결과는 (0, 1)이고 j-hat 의 결과는 (-1, 1) 가 된다는 것을 알 수 있습니다.",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "",
  "from_community_srt": "두 벡터가 서로 가까이 위치하고 있네요.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "",
  "from_community_srt": "이번엔 먼저 회전을 하고 나서 밀면, i-hat 은 (1, 1) j-hat 은 (-1, 0) 위치가 된다는 것을 알 수 있습니다. 이 둘은 보시다시피 서로 멀리 떨어져 있네요.",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "",
  "from_community_srt": "곱하는 순서에 따라 결과가 달라지기 때문에 결론은 곱하는 순서가 중요합니다.",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "",
  "from_community_srt": "주목할 점은 변환에 대해서 떠올릴 때 변환은 시각화함으로써 머릿속으로 떠올릴 수 있는 것들이라는 것이죠.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "",
  "from_community_srt": "행렬 곱셈하는 것 그 자체는 중요하지 않아요.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "",
  "from_community_srt": "제가 선형대수학을 처음 접했을 때가 기억나는 데, 행렬 곱셈의 결합법칙(Asoociativity)에 대해 증명하라는 숙제가 있었습니다.",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "",
  "from_community_srt": "결합법칙은 행렬 A, B, C가 있어서 이것을 모두 곱할 때, AB 먼저 곱하고 나서 오른쪽에 C를 곱하거나 BC 먼저 곱하고나서 왼쪽에  A를 곱하거나 그 순서는 상관이 없다는 것을 의미합니다.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "",
  "from_community_srt": "다시 말해서,",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "",
  "from_community_srt": "괄호를 어디다 집어넣든 크게 상관이 없다는 거죠 여러분들이 결합법칙을 수치적으로 제가 방금 아까 했던 것처럼 증명하려 한다면 그 방법은 아주 끔찍하고 결합법칙이 무엇인지 깨우치는 데 좋지 못합니다.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "",
  "from_community_srt": "하지만 행렬의 곱셈을 한 변환을 적용하고 나서 다시 다른 변환을 적용하는 것이라고 생각한다면, 이 문제는 정말 간단합니다.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "",
  "from_community_srt": "왜 그런지 이해가 되나요?",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "",
  "from_community_srt": "결합법칙이 나타내는 것은 CB, A 순서로 적용하는 것이 C, BA 순서로 적용하는 것과 같다는 겁니다.",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "",
  "from_community_srt": "더이상 증명할 게 없어요.",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "",
  "from_community_srt": "그냥 동일한 세 변환을 같은 순서대로 적용하는 것에 불과합니다.",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "",
  "from_community_srt": "꼼수처럼 느껴질 지도 모르지만 전혀 그렇지 않아요.",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "",
  "from_community_srt": "이 방법은 행렬 곱셈이 결합법칙이 성립된다는 것을 증명하는 아주 좋은 방법입니다. 게다가 이렇게 하면 왜 결합법칙이 참인지 아주 잘 설명해주죠.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "",
  "from_community_srt": "저는 여러분들이 이 아이디어를 잘 활용하시기를 바랍니다. 서로 다른 두 개의 변환을 떠올려서 한 변환을 적용한 후 다른 변환을 적용하는 것과 행렬 곱셈을 수치적으로 하는 것에 대해 한 번 궁구해보십시오.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "",
  "from_community_srt": "이렇게 함으로써 행렬 곱셈에 대해 정말로 깊게 이해할 수 있게 될 것입니다.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "",
  "from_community_srt": "다음 동영상에서는 이 아이디어를 2차원 이상으로 확장해보겠습니다.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]