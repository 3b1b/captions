[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "Hola a todos, donde lo dejamos la última vez, mostré cómo se ven las transformaciones lineales y cómo representarlas usando matrices.",
  "n_reviews": 1,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "Vale la pena hacer un resumen rápido porque es realmente importante, pero, por supuesto, si esto parece algo más que un simple resumen, regresa y mira el video completo.",
  "n_reviews": 1,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "Técnicamente hablando, las transformaciones lineales son funciones con vectores como entradas y vectores como salidas, pero la última vez mostré cómo podemos pensar en ellas visualmente como manipulaciones del espacio tales que las líneas de la cuadrícula permanezcan paralelas y espaciadas uniformemente, y de modo que el origen permanece fijo.",
  "n_reviews": 1,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "La conclusión clave fue que una transformación lineal está completamente determinada por hacia donde lleva los vectores base del espacio, lo que para dos dimensiones significa i-hat y j-hat.",
  "n_reviews": 1,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "Esto se debe a que cualquier otro vector podría describirse como una combinación lineal de esos vectores base.",
  "n_reviews": 1,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "Un vector con coordenadas x, y es multiplicado x veces por i-hat más y veces multiplicado por j-hat.",
  "n_reviews": 1,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "Después de pasar por la transformación, esta propiedad de que las líneas de la cuadrícula permanezcan paralelas y espaciadas uniformemente tiene una consecuencia maravillosa.",
  "n_reviews": 1,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "El lugar donde aterriza tu vector será x veces la versión transformada de i-hat más y veces la versión transformada de j-hat.",
  "n_reviews": 1,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "Esto significa que si mantienes un registro de las coordenadas donde aterriza i-hat y las coordenadas donde aterriza j-hat, puedes calcular que un vector que comienza en x, y debe aterrizar en x multiplicado por las nuevas coordenadas de i-hat más y veces las nuevas coordenadas de j-hat.",
  "n_reviews": 1,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "La convención es registrar las coordenadas de dónde aterrizan i-hat y j-hat como las columnas de una matriz, y definir esta suma de las versiones escaladas de esas columnas por x e y como una multiplicación de matriz-vector.",
  "n_reviews": 1,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "De esta manera, una matriz representa una transformación lineal específica, y multiplicar una matriz por un vector es lo que significa computacionalmente aplicar esa transformación a ese vector.",
  "n_reviews": 1,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "Muy bien, recapitulando, pasando a las cosas nuevas.",
  "n_reviews": 1,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "A menudo, deseas describir los efectos de aplicar una transformación y luego otra.",
  "n_reviews": 1,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "Por ejemplo, tal vez quieras describir lo que sucede cuando giras el plano por primera vez 90 grados en el sentido contrario a las agujas del reloj y luego aplicas un cizallamiento.",
  "n_reviews": 1,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "El efecto general aquí, de principio a fin, es otra transformación lineal, distinta de la rotación y el corte.",
  "n_reviews": 1,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "Esta nueva transformación lineal se denomina comúnmente composición de las dos transformaciones separadas que aplicamos.",
  "n_reviews": 1,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "Y como cualquier transformación lineal, se puede describir con una matriz propia siguiendo i-hat y j-hat.",
  "n_reviews": 1,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "En este ejemplo, el punto de aterrizaje final para i-hat después de ambas transformaciones es 1,1, así que hagámoslo como la primera columna de una matriz.",
  "n_reviews": 1,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "Del mismo modo, j-hat finalmente termina en la ubicación menos 1,0, por lo que la convertimos en la segunda columna de la matriz.",
  "n_reviews": 1,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "Esta nueva matriz captura el efecto general de aplicar una rotación y luego un cizallamiento, pero como una sola acción, en lugar de dos sucesivas.",
  "n_reviews": 1,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "He aquí una forma de pensar en esa nueva matriz.",
  "n_reviews": 1,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "Si tomas un vector y lo pasas a través de la rotación y luego el cizallamiento, la forma más larga de calcular dónde termina es multiplicarlo primero a la izquierda por la matriz de rotación, luego tomar lo que obtengas y multiplicarlo a la izquierda por la matriz de cizallamiento.",
  "n_reviews": 1,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "Esto es, numéricamente hablando, lo que significa aplicar una rotación y luego un cizallamiento a un vector dado.",
  "n_reviews": 1,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "Pero lo que obtengas debería ser lo mismo que aplicar esta nueva matriz de la composición que acabamos de encontrar con ese mismo vector, sin importar qué vector elijas, ya que se supone que esta nueva matriz captura el mismo efecto general que la acción de rotación y luego de cizallamiento.",
  "n_reviews": 1,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "Según cómo están escritas las cosas aquí, creo que es razonable llamar a esta nueva matriz el producto de las dos matrices originales, ¿no?",
  "n_reviews": 1,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "Podemos pensar en cómo calcular ese producto de manera más general en un momento, pero es demasiado fácil perderse en el bosque de los números.",
  "n_reviews": 1,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "Recuerda siempre que multiplicar dos matrices de esta manera tiene el significado geométrico de aplicar una transformación y luego otra.",
  "n_reviews": 1,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "Una cosa que es un poco extraña aquí es que nos hace leer de derecha a izquierda.",
  "n_reviews": 1,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "Primero aplica la transformación representada por la matriz de la derecha, luego aplica la transformación representada por la matriz de la izquierda.",
  "n_reviews": 1,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "Esto surge de la notación de funciones, ya que escribimos funciones a la izquierda de las variables, por lo que cada vez que compones dos funciones, siempre debes leerlas de derecha a izquierda.",
  "n_reviews": 1,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "Buenas noticias para los lectores hebreos, malas noticias para el resto de nosotros.",
  "n_reviews": 1,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "Veamos otro ejemplo.",
  "n_reviews": 1,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "Toma la matriz con las columnas 1,1 y menos 2,0, cuya transformación se ve así.",
  "n_reviews": 1,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "Y llamémosla M1.",
  "n_reviews": 1,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "Luego, toma la matriz con las columnas 0,1 y 2,0, cuya transformación se ve así.",
  "n_reviews": 1,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "Y llamemos a ese tipo M2.",
  "n_reviews": 1,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "El efecto total de aplicar M1 y luego M2 nos da una nueva transformación, así que encontremos su matriz.",
  "n_reviews": 1,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "Pero esta vez, veamos si podemos hacerlo sin mirar las animaciones y, en su lugar, simplemente usando las entradas numéricas en cada matriz.",
  "n_reviews": 1,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "Primero, necesitamos descubrir adónde va i-hat.",
  "n_reviews": 1,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "Después de aplicar M1, las nuevas coordenadas de i-hat, por definición, vienen dadas por esa primera columna de M1, es decir, 1,1.",
  "n_reviews": 1,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "Para ver qué sucede después de aplicar M2, multiplica la matriz de M2 por ese vector 1,1.",
  "n_reviews": 1,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "Al resolverlo, de la manera que describí el último video, obtendrás el vector 2,1.",
  "n_reviews": 1,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "Esta será la primera columna de la matriz de la composición.",
  "n_reviews": 1,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "Del mismo modo, para seguir a j-hat, la segunda columna de M1 nos dice que primero aterriza en menos 2,0.",
  "n_reviews": 1,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "Luego, cuando aplicamos M2 a ese vector, puedes calcular el producto matriz-vector para obtener 0, menos 2, que se convierte en la segunda columna de nuestra matriz de composición.",
  "n_reviews": 1,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "Permíteme hablar del mismo proceso nuevamente, pero esta vez mostraré entradas variables en cada matriz, solo para mostrar que la misma línea de razonamiento funciona para cualquier matriz.",
  "n_reviews": 1,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "Esto tiene más símbolos y requerirá más espacio, pero debería ser bastante satisfactorio para cualquiera a quien previamente se le haya enseñado la multiplicación de matrices de forma más rutinaria.",
  "n_reviews": 1,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "Para seguir hacia dónde va i-hat, comienza mirando la primera columna de la matriz a la derecha, ya que aquí es donde aterriza inicialmente i-hat.",
  "n_reviews": 1,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "Multiplicar esa columna por la matriz de la izquierda es cómo puedes saber dónde termina la versión intermedia de i-hat después de aplicar la segunda transformación.",
  "n_reviews": 1,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "Entonces, la primera columna de la matriz de la composición siempre será igual a la matriz izquierda multiplicada por la primera columna de la matriz derecha.",
  "n_reviews": 1,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "Del mismo modo, j-hat siempre aterrizará inicialmente en la segunda columna de la matriz derecha.",
  "n_reviews": 1,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "Entonces, multiplicar la matriz de la izquierda por esta segunda columna dará su ubicación final y, por lo tanto, esa es la segunda columna de la matriz de composición.",
  "n_reviews": 1,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "Observa que aquí hay muchos símbolos y es común que te enseñen esta fórmula como algo para memorizar, junto con un cierto proceso algorítmico para ayudar a recordarla.",
  "n_reviews": 1,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "Pero realmente creo que antes de memorizar ese proceso, debes acostumbrarte a pensar en lo que realmente representa la multiplicación de matrices, aplicando una transformación tras otra.",
  "n_reviews": 1,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "Créeme, esto te brindará un marco conceptual mucho mejor que hará que las propiedades de la multiplicación de matrices sean mucho más fáciles de entender.",
  "n_reviews": 1,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "Por ejemplo, aquí hay una pregunta.",
  "n_reviews": 1,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "¿Importa en qué orden ponemos las dos matrices cuando las multiplicamos?",
  "n_reviews": 1,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "Bueno, pensemos en un ejemplo sencillo, como el de antes.",
  "n_reviews": 1,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "Toma un cizallamiento, que fija i-hat y aplasta j-hat hacia la derecha, y una rotación de 90 grados.",
  "n_reviews": 1,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "Si primero aplicas el cizallamiento y luego giras, podemos ver que i-hat termina en 0,1 y j-hat termina en menos 1,1.",
  "n_reviews": 1,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "Ambos generalmente apuntan muy juntos.",
  "n_reviews": 1,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "Si primero rotas, luego aplicas el cizallamiento, i-hat termina en 1,1, y j-hat se desvía en una dirección diferente en menos 1,0, y apuntan, ya sabes, más separados.",
  "n_reviews": 1,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "El efecto general aquí es claramente diferente, por lo que evidentemente el orden sí importa.",
  "n_reviews": 1,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "Fíjate, al pensar en términos de transformaciones, ese es el tipo de cosas que puedes hacer en tu cabeza visualizando.",
  "n_reviews": 1,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "No es necesaria la multiplicación de matrices.",
  "n_reviews": 1,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "Recuerdo que cuando tomé álgebra lineal por primera vez, había un problema de tarea que nos pedía que probáramos que la multiplicación de matrices es asociativa.",
  "n_reviews": 1,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "Esto significa que si tienes tres matrices, A, B y C, y las multiplicas todas juntas, no debería importar si primero calculas A por B y luego multiplicas el resultado por C, o si primero multiplicas B por B. C, luego multiplica ese resultado por A a la izquierda.",
  "n_reviews": 1,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "En otras palabras, no importa dónde pongas los paréntesis.",
  "n_reviews": 1,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "Ahora, si intentas resolver esto numéricamente, como lo hice yo en aquel entonces, es horrible, simplemente horrible y, de hecho, poco esclarecedor.",
  "n_reviews": 1,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "Pero cuando piensas la multiplicación de matrices como aplicar una transformación tras otra, esta propiedad es simplemente trivial.",
  "n_reviews": 1,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "¿Puedes ver por qué?",
  "n_reviews": 1,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "Lo que quiere decir es que si primero aplicas C, luego B, luego A, es lo mismo que aplicar C, luego B, luego A.",
  "n_reviews": 1,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "Quiero decir, no hay nada que probar.",
  "n_reviews": 1,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "Simplemente estás aplicando las mismas tres cosas una tras otra, todas en el mismo orden.",
  "n_reviews": 1,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "Esto puede parecer una trampa, pero no lo es.",
  "n_reviews": 1,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "Esta es una prueba sincera de que la multiplicación de matrices es asociativa y, mejor aún, es una buena explicación de por qué esa propiedad debería ser cierta.",
  "n_reviews": 1,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "Realmente te animo a que juegues más con esta idea, imaginando dos transformaciones diferentes, pensando en lo que sucede cuando aplicas una tras otra y luego calculando numéricamente el producto de la matriz.",
  "n_reviews": 1,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "Créeme, este es el tiempo de juego que realmente hace que la idea se asimile.",
  "n_reviews": 1,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "En el siguiente vídeo, empezaré a hablar sobre cómo ampliar estas ideas más allá de sólo dos dimensiones.",
  "n_reviews": 1,
  "start": 587.2,
  "end": 592.18
 }
]