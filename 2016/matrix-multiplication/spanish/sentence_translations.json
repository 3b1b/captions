[
 {
  "translatedText": "Hola a todos, donde lo dejamos la última vez, mostré cómo se ven las transformaciones lineales y cómo representarlas usando matrices.",
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "time_range": [
   10.94,
   16.88
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Vale la pena hacer un resumen rápido porque es realmente importante, pero, por supuesto, si esto parece algo más que un simple resumen, regresa y mira el video completo.",
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "time_range": [
   18.32,
   25.14
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Técnicamente hablando, las transformaciones lineales son funciones con vectores como entradas y vectores como salidas, pero la última vez mostré cómo podemos pensar en ellas visualmente como manipulaciones del espacio tales que las líneas de la cuadrícula permanezcan paralelas y espaciadas uniformemente, y de modo que el origen permanece fijo.",
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "time_range": [
   25.78,
   41.18
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "La conclusión clave fue que una transformación lineal está completamente determinada por hacia donde lleva los vectores base del espacio, lo que para dos dimensiones significa i-hat y j-hat.",
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "time_range": [
   41.82,
   51.34
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto se debe a que cualquier otro vector podría describirse como una combinación lineal de esos vectores base.",
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "time_range": [
   51.34,
   57.34
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Un vector con coordenadas x, y es multiplicado x veces por i-hat más y veces multiplicado por j-hat.",
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "time_range": [
   57.94,
   62.34
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Después de pasar por la transformación, esta propiedad de que las líneas de la cuadrícula permanezcan paralelas y espaciadas uniformemente tiene una consecuencia maravillosa.",
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "time_range": [
   63.46,
   69.86
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "El lugar donde aterriza tu vector será x veces la versión transformada de i-hat más y veces la versión transformada de j-hat.",
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "time_range": [
   70.5,
   77.56
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto significa que si mantienes un registro de las coordenadas donde aterriza i-hat y las coordenadas donde aterriza j-hat, puedes calcular que un vector que comienza en x, y debe aterrizar en x multiplicado por las nuevas coordenadas de i-hat más y veces las nuevas coordenadas de j-hat.",
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "time_range": [
   78.24,
   92.72
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "La convención es registrar las coordenadas de dónde aterrizan i-hat y j-hat como las columnas de una matriz, y definir esta suma de las versiones escaladas de esas columnas por x e y como una multiplicación de matriz-vector.",
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "time_range": [
   93.56,
   105.36
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "De esta manera, una matriz representa una transformación lineal específica, y multiplicar una matriz por un vector es lo que significa computacionalmente aplicar esa transformación a ese vector.",
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "time_range": [
   106.05,
   117.08
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Muy bien, recapitulando, pasando a las cosas nuevas.",
  "input": "Alright, recap over, on to the new stuff.",
  "time_range": [
   118.8,
   120.88
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "A menudo, deseas describir los efectos de aplicar una transformación y luego otra.",
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "time_range": [
   121.6,
   127.0
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Por ejemplo, tal vez quieras describir lo que sucede cuando giras el plano por primera vez 90 grados en el sentido contrario a las agujas del reloj y luego aplicas un cizallamiento.",
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "time_range": [
   127.62,
   134.48
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "El efecto general aquí, de principio a fin, es otra transformación lineal, distinta de la rotación y el corte.",
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "time_range": [
   135.26,
   141.8
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esta nueva transformación lineal se denomina comúnmente composición de las dos transformaciones separadas que aplicamos.",
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "time_range": [
   142.28,
   148.22
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Y como cualquier transformación lineal, se puede describir con una matriz propia siguiendo i-hat y j-hat.",
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "time_range": [
   148.92,
   155.44
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "En este ejemplo, el punto de aterrizaje final para i-hat después de ambas transformaciones es 1,1, así que hagámoslo como la primera columna de una matriz.",
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "time_range": [
   156.02,
   164.12
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Del mismo modo, j-hat finalmente termina en la ubicación menos 1,0, por lo que la convertimos en la segunda columna de la matriz.",
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "time_range": [
   164.96,
   171.86
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esta nueva matriz captura el efecto general de aplicar una rotación y luego un cizallamiento, pero como una sola acción, en lugar de dos sucesivas.",
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "time_range": [
   172.68,
   181.34
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "He aquí una forma de pensar en esa nueva matriz.",
  "input": "Here's one way to think about that new matrix.",
  "time_range": [
   183.04,
   184.88
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Si tomas un vector y lo pasas a través de la rotación y luego el cizallamiento, la forma más larga de calcular dónde termina es multiplicarlo primero a la izquierda por la matriz de rotación, luego tomar lo que obtengas y multiplicarlo a la izquierda por la matriz de cizallamiento.",
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "time_range": [
   185.42,
   199.8
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto es, numéricamente hablando, lo que significa aplicar una rotación y luego un cizallamiento a un vector dado.",
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "time_range": [
   200.46,
   206.06
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Pero lo que obtengas debería ser lo mismo que aplicar esta nueva matriz de la composición que acabamos de encontrar con ese mismo vector, sin importar qué vector elijas, ya que se supone que esta nueva matriz captura el mismo efecto general que la acción de rotación y luego de cizallamiento.",
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "time_range": [
   206.8,
   220.98
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Según cómo están escritas las cosas aquí, creo que es razonable llamar a esta nueva matriz el producto de las dos matrices originales, ¿no?",
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "time_range": [
   222.48,
   229.38
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Podemos pensar en cómo calcular ese producto de manera más general en un momento, pero es demasiado fácil perderse en el bosque de los números.",
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "time_range": [
   230.42,
   236.6
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Recuerda siempre que multiplicar dos matrices de esta manera tiene el significado geométrico de aplicar una transformación y luego otra.",
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "time_range": [
   236.6,
   244.28
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Una cosa que es un poco extraña aquí es que nos hace leer de derecha a izquierda.",
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "time_range": [
   245.86,
   249.66
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Primero aplica la transformación representada por la matriz de la derecha, luego aplica la transformación representada por la matriz de la izquierda.",
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "time_range": [
   250.04,
   256.72
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto surge de la notación de funciones, ya que escribimos funciones a la izquierda de las variables, por lo que cada vez que compones dos funciones, siempre debes leerlas de derecha a izquierda.",
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "time_range": [
   257.4,
   265.46
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Buenas noticias para los lectores hebreos, malas noticias para el resto de nosotros.",
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "time_range": [
   265.92,
   268.98
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Veamos otro ejemplo.",
  "input": "Let's look at another example.",
  "time_range": [
   269.88,
   271.1
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Toma la matriz con las columnas 1,1 y menos 2,0, cuya transformación se ve así.",
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "time_range": [
   271.76,
   276.86
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Y llamémosla M1.",
  "input": "And let's call it M1.",
  "time_range": [
   277.98,
   279.06
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Luego, toma la matriz con las columnas 0,1 y 2,0, cuya transformación se ve así.",
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "time_range": [
   280.1,
   285.7
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Y llamemos a ese tipo M2.",
  "input": "And let's call that guy M2.",
  "time_range": [
   287.52,
   289.24
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "El efecto total de aplicar M1 y luego M2 nos da una nueva transformación, así que encontremos su matriz.",
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "time_range": [
   289.92,
   295.68
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Pero esta vez, veamos si podemos hacerlo sin mirar las animaciones y, en su lugar, simplemente usando las entradas numéricas en cada matriz.",
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "time_range": [
   296.28,
   303.86
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Primero, necesitamos descubrir adónde va i-hat.",
  "input": "First, we need to figure out where i-hat goes.",
  "time_range": [
   304.74,
   307.14
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Después de aplicar M1, las nuevas coordenadas de i-hat, por definición, vienen dadas por esa primera columna de M1, es decir, 1,1.",
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "time_range": [
   308.04,
   315.98
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Para ver qué sucede después de aplicar M2, multiplica la matriz de M2 por ese vector 1,1.",
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "time_range": [
   316.78,
   323.5
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Al resolverlo, de la manera que describí el último video, obtendrás el vector 2,1.",
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "time_range": [
   325.3,
   329.88
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esta será la primera columna de la matriz de la composición.",
  "input": "This will be the first column of the composition matrix.",
  "time_range": [
   330.7,
   333.1
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Del mismo modo, para seguir a j-hat, la segunda columna de M1 nos dice que primero aterriza en menos 2,0.",
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "time_range": [
   334.52,
   340.54
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Luego, cuando aplicamos M2 a ese vector, puedes calcular el producto matriz-vector para obtener 0, menos 2, que se convierte en la segunda columna de nuestra matriz de composición.",
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "time_range": [
   342.7,
   355.2
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Permíteme hablar del mismo proceso nuevamente, pero esta vez mostraré entradas variables en cada matriz, solo para mostrar que la misma línea de razonamiento funciona para cualquier matriz.",
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "time_range": [
   356.64,
   364.92
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto tiene más símbolos y requerirá más espacio, pero debería ser bastante satisfactorio para cualquiera a quien previamente se le haya enseñado la multiplicación de matrices de forma más rutinaria.",
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "time_range": [
   365.54,
   373.66
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Para seguir hacia dónde va i-hat, comienza mirando la primera columna de la matriz a la derecha, ya que aquí es donde aterriza inicialmente i-hat.",
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "time_range": [
   374.46,
   381.06
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Multiplicar esa columna por la matriz de la izquierda es cómo puedes saber dónde termina la versión intermedia de i-hat después de aplicar la segunda transformación.",
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "time_range": [
   382.0,
   390.3
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Entonces, la primera columna de la matriz de la composición siempre será igual a la matriz izquierda multiplicada por la primera columna de la matriz derecha.",
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "time_range": [
   391.62,
   398.1
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Del mismo modo, j-hat siempre aterrizará inicialmente en la segunda columna de la matriz derecha.",
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "time_range": [
   402.16,
   407.14
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Entonces, multiplicar la matriz de la izquierda por esta segunda columna dará su ubicación final y, por lo tanto, esa es la segunda columna de la matriz de composición.",
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "time_range": [
   408.94,
   417.02
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Observa que aquí hay muchos símbolos y es común que te enseñen esta fórmula como algo para memorizar, junto con un cierto proceso algorítmico para ayudar a recordarla.",
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "time_range": [
   420.62,
   429.04
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Pero realmente creo que antes de memorizar ese proceso, debes acostumbrarte a pensar en lo que realmente representa la multiplicación de matrices, aplicando una transformación tras otra.",
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "time_range": [
   429.16,
   438.9
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Créeme, esto te brindará un marco conceptual mucho mejor que hará que las propiedades de la multiplicación de matrices sean mucho más fáciles de entender.",
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "time_range": [
   439.62,
   446.3
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Por ejemplo, aquí hay una pregunta.",
  "input": "For example, here's a question.",
  "time_range": [
   447.06,
   448.36
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "¿Importa en qué orden ponemos las dos matrices cuando las multiplicamos?",
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "time_range": [
   448.88,
   452.84
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Bueno, pensemos en un ejemplo sencillo, como el de antes.",
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "time_range": [
   453.62,
   457.0
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Toma un cizallamiento, que fija i-hat y aplasta j-hat hacia la derecha, y una rotación de 90 grados.",
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "time_range": [
   457.64,
   462.82
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Si primero aplicas el cizallamiento y luego giras, podemos ver que i-hat termina en 0,1 y j-hat termina en menos 1,1.",
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "time_range": [
   463.6,
   470.96
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Ambos generalmente apuntan muy juntos.",
  "input": "Both are generally pointing close together.",
  "time_range": [
   471.32,
   473.06
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Si primero rotas, luego aplicas el cizallamiento, i-hat termina en 1,1, y j-hat se desvía en una dirección diferente en menos 1,0, y apuntan, ya sabes, más separados.",
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "time_range": [
   473.86,
   485.52
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "El efecto general aquí es claramente diferente, por lo que evidentemente el orden sí importa.",
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "time_range": [
   486.38,
   490.66
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Fíjate, al pensar en términos de transformaciones, ese es el tipo de cosas que puedes hacer en tu cabeza visualizando.",
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "time_range": [
   492.2,
   497.84
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "No es necesaria la multiplicación de matrices.",
  "input": "No matrix multiplication necessary.",
  "time_range": [
   498.22,
   499.9
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Recuerdo que cuando tomé álgebra lineal por primera vez, había un problema de tarea que nos pedía que probáramos que la multiplicación de matrices es asociativa.",
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "time_range": [
   501.48,
   509.12
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto significa que si tienes tres matrices, A, B y C, y las multiplicas todas juntas, no debería importar si primero calculas A por B y luego multiplicas el resultado por C, o si primero multiplicas B por B. C, luego multiplica ese resultado por A a la izquierda.",
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "time_range": [
   509.56,
   524.36
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "En otras palabras, no importa dónde pongas los paréntesis.",
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "time_range": [
   524.94,
   527.4
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Ahora, si intentas resolver esto numéricamente, como lo hice yo en aquel entonces, es horrible, simplemente horrible y, de hecho, poco esclarecedor.",
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "time_range": [
   528.38,
   535.76
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Pero cuando piensas la multiplicación de matrices como aplicar una transformación tras otra, esta propiedad es simplemente trivial.",
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "time_range": [
   535.76,
   542.78
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "¿Puedes ver por qué?",
  "input": "Can you see why?",
  "time_range": [
   543.3,
   544.0
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Lo que quiere decir es que si primero aplicas C, luego B, luego A, es lo mismo que aplicar C, luego B, luego A.",
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "time_range": [
   544.86,
   552.38
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Quiero decir, no hay nada que probar.",
  "input": "I mean, there's nothing to prove.",
  "time_range": [
   552.82,
   554.38
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Simplemente estás aplicando las mismas tres cosas una tras otra, todas en el mismo orden.",
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "time_range": [
   554.54,
   558.66
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esto puede parecer una trampa, pero no lo es.",
  "input": "This might feel like cheating, but it's not.",
  "time_range": [
   559.46,
   561.54
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Esta es una prueba sincera de que la multiplicación de matrices es asociativa y, mejor aún, es una buena explicación de por qué esa propiedad debería ser cierta.",
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "time_range": [
   561.54,
   570.68
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Realmente te animo a que juegues más con esta idea, imaginando dos transformaciones diferentes, pensando en lo que sucede cuando aplicas una tras otra y luego calculando numéricamente el producto de la matriz.",
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "time_range": [
   571.56,
   582.14
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "Créeme, este es el tiempo de juego que realmente hace que la idea se asimile.",
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "time_range": [
   582.6,
   586.44
  ],
  "n_reviews": 1
 },
 {
  "translatedText": "En el siguiente vídeo, empezaré a hablar sobre cómo ampliar estas ideas más allá de sólo dos dimensiones.",
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "time_range": [
   587.2,
   592.18
  ],
  "n_reviews": 1
 }
]