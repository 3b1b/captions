[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices. ",
  "translatedText": "আরে সবাই, আমরা শেষ যেখানে ছেড়ে দিয়েছিলাম, আমি দেখিয়েছি রৈখিক রূপান্তরগুলি কেমন দেখায় এবং ম্যাট্রিক্স ব্যবহার করে কীভাবে তাদের উপস্থাপন করা যায়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video. ",
  "translatedText": "এটি একটি দ্রুত রিক্যাপ মূল্যবান কারণ এটি সত্যিই গুরুত্বপূর্ণ, তবে অবশ্যই যদি এটি কেবল একটি রিক্যাপের চেয়ে বেশি মনে হয় তবে ফিরে যান এবং সম্পূর্ণ ভিডিওটি দেখুন৷ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Generally speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed. ",
  "translatedText": "সাধারণভাবে বলতে গেলে, রৈখিক রূপান্তরগুলি হল ভেক্টরগুলির সাথে ইনপুট হিসাবে এবং ভেক্টরগুলি আউটপুট হিসাবে কাজ করে, কিন্তু আমি গতবার দেখিয়েছি যে কীভাবে আমরা তাদের সম্পর্কে দৃশ্যতভাবে ভাবতে পারি মহাকাশের চারপাশে এমনভাবে স্মুশিং করে যাতে গ্রিড লাইনগুলি সমান্তরাল এবং সমানভাবে ব্যবধানে থাকে এবং যাতে উৎপত্তি হয়। স্থির থাকে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat. ",
  "translatedText": "মূল টেকঅ্যাওয়ে ছিল যে একটি রৈখিক রূপান্তর সম্পূর্ণরূপে নির্ধারিত হয় যেখানে এটি স্থানের ভিত্তি ভেক্টর নেয়, যা দুটি মাত্রার জন্য আই-হ্যাট এবং জে-হ্যাট বোঝায়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors. ",
  "translatedText": "কারণ অন্য কোনো ভেক্টরকে সেই ভিত্তি ভেক্টরগুলির একটি রৈখিক সংমিশ্রণ হিসাবে বর্ণনা করা যেতে পারে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat. ",
  "translatedText": "স্থানাঙ্ক x, y সহ একটি ভেক্টর হল x গুণ i-hat প্লাস y গুণ j-hat। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence. ",
  "translatedText": "রূপান্তরের মধ্য দিয়ে যাওয়ার পরে, গ্রিড লাইনগুলি সমান্তরাল এবং সমানভাবে ব্যবধানে থাকা এই বৈশিষ্ট্যটির একটি দুর্দান্ত পরিণতি রয়েছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat. ",
  "translatedText": "যে স্থানে আপনার ভেক্টর ল্যান্ড করবে সেটি i-hat-এর রূপান্তরিত সংস্করণের x গুণ এবং j-হ্যাটের রূপান্তরিত সংস্করণের y গুণ হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat. ",
  "translatedText": "এর মানে আপনি যদি আই-হ্যাট ল্যান্ড এবং কোঅর্ডিনেট যেখানে জে-হ্যাট ল্যান্ড করেন তার রেকর্ড রাখেন, তাহলে আপনি গণনা করতে পারেন যে একটি ভেক্টর যা x, y থেকে শুরু হয় সেটি অবশ্যই i-hat প্লাস y-এর নতুন স্থানাঙ্কের x গুণে অবতরণ করবে। বার j-হ্যাটের নতুন স্থানাঙ্ক। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication. ",
  "translatedText": "কনভেনশনটি হল ম্যাট্রিক্সের কলাম হিসাবে i-hat এবং j-hat ল্যান্ড করার স্থানাঙ্কগুলি রেকর্ড করা এবং x এবং y দ্বারা সেই কলামগুলির স্কেল করা সংস্করণগুলির এই যোগফলকে ম্যাট্রিক্স-ভেক্টর গুণন হিসাবে সংজ্ঞায়িত করা। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector. ",
  "translatedText": "এইভাবে, একটি ম্যাট্রিক্স একটি নির্দিষ্ট রৈখিক রূপান্তরকে প্রতিনিধিত্ব করে এবং একটি ভেক্টর দ্বারা একটি ম্যাট্রিক্সকে গুণ করা মানে সেই ভেক্টরে সেই রূপান্তরটি প্রয়োগ করার জন্য গণনাগতভাবে বোঝায়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff. ",
  "translatedText": "ঠিক আছে, নতুন স্টাফ উপর পুনরায় সংক্ষেপ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes you find yourself wanting to describe the effects of applying one transformation and then another. ",
  "translatedText": "প্রায়শই আপনি নিজেকে একটি রূপান্তর এবং তারপরে অন্যটি প্রয়োগ করার প্রভাবগুলি বর্ণনা করতে চান। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear. ",
  "translatedText": "উদাহরণস্বরূপ, হতে পারে আপনি বর্ণনা করতে চান যখন আপনি প্রথমে প্লেনটিকে ঘড়ির কাঁটার বিপরীত দিকে 90 ডিগ্রি ঘোরান তখন কী ঘটে, তারপর একটি শিয়ার প্রয়োগ করুন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear. ",
  "translatedText": "এখানে সামগ্রিক প্রভাব, শুরু থেকে শেষ পর্যন্ত, আরেকটি রৈখিক রূপান্তর, ঘূর্ণন এবং শিয়ার থেকে আলাদা। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied. ",
  "translatedText": "এই নতুন রৈখিক রূপান্তরকে সাধারণত আমরা প্রয়োগ করেছি দুটি পৃথক রূপান্তরের রচনা বলা হয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat. ",
  "translatedText": "এবং যেকোন রৈখিক রূপান্তরের মতো, এটিকে আই-হ্যাট এবং জে-হ্যাট অনুসরণ করে একটি ম্যাট্রিক্সের সাথে বর্ণনা করা যেতে পারে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix. ",
  "translatedText": "এই উদাহরণে, উভয় রূপান্তরের পরে আই-হ্যাটের জন্য চূড়ান্ত অবতরণ স্থান হল 1,1, তাই আসুন এটিকে একটি ম্যাট্রিক্সের প্রথম কলাম করা যাক। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix. ",
  "translatedText": "একইভাবে, জে-হ্যাট শেষ পর্যন্ত নেতিবাচক 1,0 অবস্থানে শেষ হয়, তাই আমরা এটিকে ম্যাট্রিক্সের দ্বিতীয় কলাম তৈরি করি। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones. ",
  "translatedText": "এই নতুন ম্যাট্রিক্সটি একটি ঘূর্ণন প্রয়োগের সামগ্রিক প্রভাবকে ক্যাপচার করে তারপর একটি শিয়ার, তবে একটি একক ক্রিয়া হিসাবে, বরং দুটি ধারাবাহিকের পরিবর্তে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix. ",
  "translatedText": "এখানে সেই নতুন ম্যাট্রিক্স সম্পর্কে চিন্তা করার একটি উপায়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix. ",
  "translatedText": "আপনি যদি কিছু ভেক্টর নিতে চান এবং ঘূর্ণনের মাধ্যমে এটিকে পাম্প করতে চান, তাহলে শিয়ার, গণনা করার দীর্ঘ পথ যেখানে এটি শেষ হয় তা হল প্রথমে এটিকে ঘূর্ণন ম্যাট্রিক্স দ্বারা বাম দিকে গুণ করতে হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 185.42,
  "end": 194.82
 },
 {
  "input": "Then, take whatever you get and multiply that on the left by the shear matrix. ",
  "translatedText": "তারপর, আপনি যা পাবেন তা নিন এবং বামদিকে শিয়ার ম্যাট্রিক্স দ্বারা গুণ করুন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.32,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector. ",
  "translatedText": "এটি হল, সংখ্যাগতভাবে বলতে গেলে, প্রদত্ত ভেক্টরে একটি ঘূর্ণন তারপর শিয়ার প্রয়োগ করার অর্থ কী। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action. ",
  "translatedText": "কিন্তু আপনি যা পাবেন তা হওয়া উচিত এই নতুন কম্পোজিশন ম্যাট্রিক্স প্রয়োগ করার মতো যা আমরা এইমাত্র সেই একই ভেক্টর দ্বারা পেয়েছি, আপনি যে ভেক্টরটি বেছে নিয়েছেন তা কোন ব্যাপার না, যেহেতু এই নতুন ম্যাট্রিক্সটি ঘূর্ণন তারপর শিয়ার অ্যাকশনের মতো একই সামগ্রিক প্রভাব ক্যাপচার করবে বলে মনে করা হচ্ছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you? ",
  "translatedText": "এখানে জিনিসগুলি কীভাবে লেখা হয়েছে তার উপর ভিত্তি করে, আমি মনে করি এই নতুন ম্যাট্রিক্সটিকে আসল দুটি ম্যাট্রিক্সের গুণফল বলা যুক্তিসঙ্গত, তাই না? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers. ",
  "translatedText": "আমরা ভাবতে পারি কীভাবে সেই পণ্যটিকে সাধারণভাবে এক মুহূর্তের মধ্যে গণনা করা যায়, তবে সংখ্যার বনে হারিয়ে যাওয়া খুব সহজ। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another. ",
  "translatedText": "সর্বদা মনে রাখবেন যে এইভাবে দুটি ম্যাট্রিক্সকে গুণ করার জ্যামিতিক অর্থ হল একটি পরিবর্তনের পরে অন্যটি প্রয়োগ করা। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left. ",
  "translatedText": "এখানে অদ্ভুত এক জিনিস হল যে এটি আমাদের ডান থেকে বামে পড়তে পারে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left. ",
  "translatedText": "আপনি প্রথমে ডানদিকে ম্যাট্রিক্স দ্বারা উপস্থাপিত রূপান্তর প্রয়োগ করুন, তারপর আপনি বাম দিকে ম্যাট্রিক্স দ্বারা প্রতিনিধিত্ব করা রূপান্তর প্রয়োগ করুন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left. ",
  "translatedText": "এটি ফাংশন স্বরলিপি থেকে উদ্ভূত হয়, যেহেতু আমরা ভেরিয়েবলের বাম দিকে ফাংশন লিখি, তাই আপনি যখনই দুটি ফাংশন রচনা করবেন, আপনাকে সর্বদা এটি ডান থেকে বামে পড়তে হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us. ",
  "translatedText": "হিব্রু পাঠকদের জন্য ভাল খবর, আমাদের বাকিদের জন্য খারাপ খবর। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example. ",
  "translatedText": "আরেকটি উদাহরণ দেখা যাক। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this. ",
  "translatedText": "কলাম 1,1 এবং ঋণাত্মক 2,0 সহ ম্যাট্রিক্স নিন, যার রূপান্তরটি এরকম দেখাচ্ছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it m1. ",
  "translatedText": "এবং এর m1 কল করা যাক. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this. ",
  "translatedText": "এর পরে, 0,1 এবং 2,0 কলাম সহ ম্যাট্রিক্স নিন, যার রূপান্তরটি এইরকম দেখাচ্ছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy m2. ",
  "translatedText": "এবং এর যে লোক m2 কল করা যাক. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying m1 then m2 gives us a new transformation, so let's find its matrix. ",
  "translatedText": "m1 তারপর m2 প্রয়োগ করার মোট প্রভাব আমাদের একটি নতুন রূপান্তর দেয়, তাই আসুন এর ম্যাট্রিক্স খুঁজে বের করি। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix. ",
  "translatedText": "কিন্তু এই সময়, আসুন আমরা অ্যানিমেশন না দেখে এটি করতে পারি কিনা তা দেখি, এবং পরিবর্তে প্রতিটি ম্যাট্রিক্সে সংখ্যাসূচক এন্ট্রি ব্যবহার করে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes. ",
  "translatedText": "প্রথমত, আমাদের আই-হ্যাট কোথায় যায় তা বের করতে হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying m1, the new coordinates of i-hat, by definition, are given by that first column of m1, namely 1,1. ",
  "translatedText": "m1 প্রয়োগ করার পর, i-hat-এর নতুন স্থানাঙ্ক, সংজ্ঞা অনুসারে, m1-এর সেই প্রথম কলাম দ্বারা দেওয়া হয়, যথা 1,1। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying m2, multiply the matrix for m2 by that vector 1,1. ",
  "translatedText": "m2 প্রয়োগ করার পরে কী ঘটে তা দেখতে, m2 এর জন্য ম্যাট্রিক্সটিকে সেই ভেক্টর 1,1 দ্বারা গুণ করুন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1. ",
  "translatedText": "এটি কাজ করে, আমি যেভাবে শেষ ভিডিওটি বর্ণনা করেছি, আপনি ভেক্টর 2,1 পাবেন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix. ",
  "translatedText": "এটি রচনা ম্যাট্রিক্সের প্রথম কলাম হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of m1 tells us that it first lands on negative 2,0. ",
  "translatedText": "একইভাবে, j-হ্যাট অনুসরণ করতে, m1-এর দ্বিতীয় কলামটি আমাদের বলে যে এটি প্রথমে ঋণাত্মক 2,0-এ অবতরণ করে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply m2 to that vector, you can work out the matrix vector product to get 0, negative 2, which becomes the second column of our composition matrix. ",
  "translatedText": "তারপর, যখন আমরা সেই ভেক্টরে m2 প্রয়োগ করি, আপনি 0, ঋণাত্মক 2 পেতে ম্যাট্রিক্স ভেক্টর গুণফল বের করতে পারেন, যা আমাদের কম্পোজিশন ম্যাট্রিক্সের দ্বিতীয় কলামে পরিণত হয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices. ",
  "translatedText": "আমাকে আবার সেই একই প্রক্রিয়ার মাধ্যমে কথা বলতে দিন, কিন্তু এবার আমি প্রতিটি ম্যাট্রিক্সে পরিবর্তনশীল এন্ট্রি দেখাব, শুধু দেখানোর জন্য যে যুক্তির একই লাইন যেকোনো ম্যাট্রিক্সের জন্য কাজ করে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way. ",
  "translatedText": "এটি আরও প্রতীক-ভারী এবং এর জন্য আরও কিছু জায়গার প্রয়োজন হবে, তবে এটি এমন যেকোন ব্যক্তির জন্য বেশ সন্তোষজনক হওয়া উচিত যাকে আগে আরও রোট পদ্ধতিতে ম্যাট্রিক্স গুণন শেখানো হয়েছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands. ",
  "translatedText": "আই-হ্যাট কোথায় যায় তা অনুসরণ করতে, ডানদিকে ম্যাট্রিক্সের প্রথম কলামটি দেখে শুরু করুন, যেহেতু এখানেই আই-হ্যাট শুরু হয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation. ",
  "translatedText": "বাম দিকের ম্যাট্রিক্স দ্বারা সেই কলামটিকে গুণ করলে দ্বিতীয় রূপান্তরটি প্রয়োগ করার পরে আই-হ্যাটের মধ্যবর্তী সংস্করণটি কোথায় শেষ হবে তা আপনি কীভাবে বলতে পারেন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix. ",
  "translatedText": "সুতরাং কম্পোজিশন ম্যাট্রিক্সের প্রথম কলামটি সর্বদা ডান ম্যাট্রিক্সের প্রথম কলামের বাম ম্যাট্রিক্স গুণের সমান হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix. ",
  "translatedText": "একইভাবে, j-হ্যাট সর্বদা প্রাথমিকভাবে ডান ম্যাট্রিক্সের দ্বিতীয় কলামে অবতরণ করবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix. ",
  "translatedText": "সুতরাং এই দ্বিতীয় কলাম দ্বারা বাম ম্যাট্রিক্সকে গুণ করলে এর চূড়ান্ত অবস্থান পাওয়া যাবে, এবং তাই এটি রচনা ম্যাট্রিক্সের দ্বিতীয় কলাম। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to kind of help remember it. ",
  "translatedText": "লক্ষ্য করুন এখানে প্রচুর চিহ্ন রয়েছে, এবং এটি মনে রাখতে সাহায্য করার জন্য একটি নির্দিষ্ট অ্যালগরিদমিক প্রক্রিয়া সহ মুখস্থ করার মতো কিছু হিসাবে এই সূত্রটি শেখানো সাধারণ। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another. ",
  "translatedText": "কিন্তু আমি সত্যিই মনে করি যে সেই প্রক্রিয়াটি মুখস্থ করার আগে, আপনাকে ম্যাট্রিক্স গুণন আসলে কী প্রতিনিধিত্ব করে তা নিয়ে চিন্তা করার অভ্যাস করা উচিত, একের পর এক রূপান্তর প্রয়োগ করা। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand. ",
  "translatedText": "আমাকে বিশ্বাস করুন, এটি আপনাকে আরও ভাল ধারণাগত কাঠামো দেবে যা ম্যাট্রিক্স গুণনের বৈশিষ্ট্যগুলিকে বোঝা সহজ করে তোলে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question. ",
  "translatedText": "উদাহরণস্বরূপ, এখানে একটি প্রশ্ন. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them? ",
  "translatedText": "আমরা যখন তাদের গুণ করি তখন আমরা দুটি ম্যাট্রিক্সকে কোন ক্রমে রাখি তা কি গুরুত্বপূর্ণ? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier. ",
  "translatedText": "ঠিক আছে, আসুন একটি সাধারণ উদাহরণের মাধ্যমে চিন্তা করি, যেমন আগেরটির মতো। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smushes j-hat over to the right, and a 90 degree rotation. ",
  "translatedText": "একটি শিয়ার নিন, যা আই-হ্যাটকে ঠিক করে এবং জে-হ্যাটটিকে ডানদিকে ছুঁড়ে দেয় এবং একটি 90 ডিগ্রি ঘূর্ণন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1. ",
  "translatedText": "আপনি যদি প্রথমে শিয়ার করেন, তারপর ঘোরান, আমরা দেখতে পাব যে আই-হ্যাট 0,1 এ শেষ হবে এবং j-হ্যাট নেতিবাচক 1,1 এ শেষ হবে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together. ",
  "translatedText": "উভয় সাধারণত কাছাকাছি কাছাকাছি নির্দেশ করা হয়. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing farther apart. ",
  "translatedText": "আপনি যদি প্রথমে ঘোরান, তারপর শিয়ার করুন, i-hat 1,1-এ শেষ হয়, এবং j-hat বন্ধ হয় একটি ভিন্ন দিকে ঋণাত্মক 1,0 এ, এবং তারা আরও দূরে নির্দেশ করছে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently order totally does matter. ",
  "translatedText": "এখানে সামগ্রিক প্রভাব স্পষ্টভাবে ভিন্ন, তাই স্পষ্টতই অর্ডার সম্পূর্ণভাবে গুরুত্বপূর্ণ। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice by thinking in terms of transformations, that's the kind of thing you can do in your head by visualizing. ",
  "translatedText": "রূপান্তরের পরিপ্রেক্ষিতে চিন্তা করে লক্ষ্য করুন, এটি এমন একটি জিনিস যা আপনি কল্পনা করে আপনার মাথায় করতে পারেন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary. ",
  "translatedText": "কোনো ম্যাট্রিক্স গুণের প্রয়োজন নেই। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative. ",
  "translatedText": "আমার মনে আছে আমি যখন প্রথম রৈখিক বীজগণিত নিয়েছিলাম, তখন এই একটি হোমওয়ার্ক সমস্যা ছিল যা আমাদের প্রমাণ করতে বলেছিল যে ম্যাট্রিক্স গুণনটি সহযোগী। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left. ",
  "translatedText": "এর মানে হল যে আপনার যদি তিনটি ম্যাট্রিক্স থাকে, A, B, এবং C, এবং আপনি সেগুলিকে একসাথে গুণ করেন, তাহলে আপনি যদি প্রথমে A গুন B গণনা করেন, তারপর C দ্বারা ফলাফলকে গুণ করেন, অথবা আপনি যদি প্রথমে B গুণ করেন তবে তাতে কিছু যায় আসে না C, তারপর সেই ফলাফলটিকে বাম দিকে A দ্বারা গুণ করুন। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses. ",
  "translatedText": "অন্য কথায়, আপনি কোথায় বন্ধনী রেখেছেন তা বিবেচ্য নয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter. ",
  "translatedText": "এখন, যদি আপনি এই সংখ্যার মাধ্যমে কাজ করার চেষ্টা করেন, যেমনটি আমি তখন করেছিলাম, এটি সেই বিষয়টির জন্য ভয়ঙ্কর, শুধু ভয়ঙ্কর এবং অপ্রকাশ্য। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial. ",
  "translatedText": "কিন্তু যখন আপনি ম্যাট্রিক্স গুণের কথা ভাবেন যেমন একটার পর একটা ট্রান্সফর্মেশন প্রয়োগ করা হচ্ছে, এই সম্পত্তিটা খুবই তুচ্ছ। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why? ",
  "translatedText": "আপনি কেন দেখতে পারেন? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C then B, then A, it's the same as applying C, then B, then A. ",
  "translatedText": "এটি যা বলছে তা হল যে আপনি যদি প্রথমে C তারপর B, তারপর A প্রয়োগ করেন, এটি C, তারপর B, তারপর A প্রয়োগ করার মতই। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove, you're just applying the same three things one after the other, all in the same order. ",
  "translatedText": "আমি বলতে চাচ্ছি, প্রমাণ করার মতো কিছুই নেই, আপনি শুধু একই তিনটি জিনিস একের পর এক প্রয়োগ করছেন, সব একই ক্রমে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.82,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not. ",
  "translatedText": "এটি প্রতারণার মতো মনে হতে পারে, তবে তা নয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative. ",
  "translatedText": "এটি একটি সৎ-থেকে-ভালোতার প্রমাণ যে ম্যাট্রিক্স গুণনটি সহযোগী। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.54,
  "end": 565.9
 },
 {
  "input": "And even better than that, it's a good explanation for why that property should be true. ",
  "translatedText": "এবং এর চেয়েও ভালো, কেন সেই সম্পত্তি সত্য হওয়া উচিত তার জন্য এটি একটি ভাল ব্যাখ্যা। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.9,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically. ",
  "translatedText": "আমি সত্যিই আপনাকে এই ধারণাটি নিয়ে আরও বেশি খেলার জন্য উত্সাহিত করি, দুটি ভিন্ন রূপান্তর কল্পনা করে, আপনি যখন একের পর এক প্রয়োগ করেন তখন কী ঘটে তা নিয়ে চিন্তাভাবনা করে, এবং তারপর ম্যাট্রিক্স পণ্যটি সংখ্যাগতভাবে কাজ করে। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in. ",
  "translatedText": "আমাকে বিশ্বাস করুন, এটি এমন খেলার সময় যা সত্যিই ধারণাটিকে ডুবিয়ে দেয়। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions. ",
  "translatedText": "পরের ভিডিওতে, আমি এই ধারণাগুলিকে কেবল দুটি মাত্রার বাইরে প্রসারিত করার বিষয়ে কথা বলতে শুরু করব। ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 587.2,
  "end": 591.42
 },
 {
  "input": "See you then! ",
  "translatedText": "দেখা হবে তাহলে! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.02,
  "end": 592.18
 }
]