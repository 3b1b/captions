[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "Ahoj všichni, v minulém díle jsem si ukázal, jak vypadají lineární transformace a jak je znázornit pomocí matic.",
  "model": "DeepL",
  "from_community_srt": "Z mé zkušenosti se dají důkazy o maticích zkrátit na polovinu, když z nich vyhodíte ty matice. -- Emil Artin Ahoj, všichni! Posledně jsme skončili tím, jak vypadají lineární transformace, a jak je reprezentovat pomocí matic.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "Tohle stojí za rychlou rekapitulaci, protože je to opravdu důležité, ale samozřejmě pokud vám to připadá víc než jen rekapitulace, vraťte se a podívejte se na celé video.",
  "model": "DeepL",
  "from_community_srt": "A protože to je dost důležité, tak si to stručně zopakujeme. Jestli máte pocit, že to je něco víc než opakování, vraťte se na minulé video a shlédněte ho znovu.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "Technicky vzato jsou lineární transformace funkce, jejichž vstupem jsou vektory a výstupem vektory, ale minule jsem ukázal, jak si je můžeme vizuálně představit jako rozmístění v prostoru tak, aby čáry mřížky zůstaly rovnoběžné a rovnoměrně rozmístěné a aby počátek zůstal pevný.",
  "model": "DeepL",
  "from_community_srt": "Technicky řečeno jsou lineární transformace funkcemi, které na vstupu berou vektory a vrací opět vektory. Minule jsem vám předvedl, jak si je představovat vizuálně jako takové šoupnutí prostorem, při kterém zůstanou čáry mřížky rovnoběžné s rovnoměrnými rozestupy a počátek zůstane na místě.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "Klíčovým poznatkem bylo, že lineární transformace je zcela určena tím, kde vezme bázové vektory prostoru, což pro dvě dimenze znamená i-hat a j-hat.",
  "model": "DeepL",
  "from_community_srt": "Klíčová pointa spočívala v tom, že lineární transformace je plně určena tím, kam se v prostoru pošlou bázové vektory, to jsou pro dvou rozměrnou rovinu vektory i,",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "To proto, že jakýkoli jiný vektor lze popsat jako lineární kombinaci těchto základních vektorů.",
  "model": "DeepL",
  "from_community_srt": "j. Je tomu tak proto, že všechny ostatní vektory se dají popsat jako lineární kombinace bázových vektorů.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "Vektor se souřadnicemi x, y je x krát i-hat plus y krát j-hat.",
  "model": "DeepL",
  "from_community_srt": "Vektor se souřadnicemi (x, y) je x krát i plus y krát j.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "Po transformaci má tato vlastnost, že čáry mřížky zůstávají rovnoběžné a rovnoměrně rozmístěné, úžasný důsledek.",
  "model": "DeepL",
  "from_community_srt": "Když sledujeme transformaci, tak vlastnost, že čáry mřížky zůstávají rovnoběžné a rovnoměrně rozmístěné, má nadherný důsledek.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "Místo, kam váš vektor dopadne, bude x krát transformovaná verze i-hat plus y krát transformovaná verze j-hat.",
  "model": "DeepL",
  "from_community_srt": "Místo, kde skončí váš vektor bude x krát transformovaná verze i plus y krát transformovaná verze j.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "To znamená, že pokud si uchováte záznam souřadnic, na kterých přistane i-hat, a souřadnic, na kterých přistane j-hat, můžete vypočítat, že vektor, který začíná v bodě x, y, musí přistát na x krát nové souřadnice i-hat plus y krát nové souřadnice j-hat.",
  "model": "DeepL",
  "from_community_srt": "Takže když si zaznamenáte, jak vypadají souřadnice vektorů i, j po transformaci, můžete spočítat, že vektor, který začínal na (x, y) musí přistát na x krát nové souřadnice i plus y krát nové souřadnice j.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "Konvence spočívá v tom, že se souřadnice míst, kde leží i-hat a j-hat, zaznamenají jako sloupce matice a součet měřítkových verzí těchto sloupců podle x a y se definuje jako násobení matice a vektoru.",
  "model": "DeepL",
  "from_community_srt": "Takové souřadnice vektorů i, j je zvykem psát do sloupců matice a definovat ten součet škálovaných sloupečků podle souřadnic x, y jako součin matice a vektoru.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "Matice tak představuje určitou lineární transformaci a násobení matice vektorem znamená výpočetní použití této transformace na daný vektor.",
  "model": "DeepL",
  "from_community_srt": "V tomhle smyslu matice reprezentuje specifickou lineární transformaci a násobit matici vektorem znamená spočítat, jak daná transformace pohne s daným vektorem.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "Dobrá, rekapitulace skončila, přejděme k novým věcem.",
  "model": "DeepL",
  "from_community_srt": "Fajn, opáčko skončilo, jdeme na nové věci.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "Často se vám stává, že chcete popsat účinky jedné a pak druhé transformace.",
  "model": "DeepL",
  "from_community_srt": "Často se setkáte s tím, že chcete popsat výsledek provedení jedné transformace a pak druhé.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "Například chcete popsat, co se stane, když nejprve otočíte rovinu o 90 stupňů proti směru hodinových ručiček a poté použijete smyk.",
  "model": "DeepL",
  "from_community_srt": "Například můžete chtít popsat, co se stane, když napřed otočíte rovinu o 90° proti směru hodinových ručiček, a pak aplikujete zkosení.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "Celkovým efektem je zde od začátku do konce další lineární transformace, odlišná od rotace a střihu.",
  "model": "DeepL",
  "from_community_srt": "Celkový proces, od začátku do konce je jiná lineární transformace, není to ani rotace,",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "Tato nová lineární transformace se běžně nazývá kompozice dvou samostatných transformací, které jsme použili.",
  "model": "DeepL",
  "from_community_srt": "ani zkosení. Taková transformace se obvykle nazývá \"složení\" dvou lineárních transformací, které jsme provedli.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "A jako každá lineární transformace může být popsána vlastní maticí podle i-hat a j-hat.",
  "model": "DeepL",
  "from_community_srt": "A jako každá lineární transformace je i tato plně popsána maticí, která říká, kde skončí i,",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "V tomto příkladu je konečným místem přistání i-hat po obou transformacích 1,1, takže z něj vytvoříme první sloupec matice.",
  "model": "DeepL",
  "from_community_srt": "j. V tomhle případě je konečná stanice pro vektor i po obou transformacích (1, 1). Takže to bude první řádek naší matice.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "Stejně tak j-hat nakonec skončí na místě záporné 1,0, takže z něj vytvoříme druhý sloupec matice.",
  "model": "DeepL",
  "from_community_srt": "Podobně j skončí na souřadnicích (-1, 0), takže máme druhý řádek matice.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "Tato nová matice zachycuje celkový účinek použití rotace a následného střihu, ale jako jediného úkonu, nikoli dvou po sobě jdoucích.",
  "model": "DeepL",
  "from_community_srt": "Tahle nová matice nese výsledek provedení napřed rotace a pak zkosení, ale jako jednu akci namísto dvou po sobě jdoucích.",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "O této nové matici můžete přemýšlet například takto.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "Pokud vezmete nějaký vektor a přečerpáte ho přes rotaci a pak přes smyk, dlouhý způsob, jak vypočítat, kde skončí, je nejprve vynásobit ho zleva maticí rotace, pak vzít cokoli, co dostanete, a vynásobit to zleva maticí smyku.",
  "model": "DeepL",
  "from_community_srt": "Novou matici můžete vnímat třeba takto: Když vezmete nějaký vektor a proženete jej napřed skrz rotaci a pak skrz zkosení, delší způsob, jak spočítat výsledek, je napřed jej vynásobit nalevo maticí rotace; a potom vzít to, co vám vyšlo, a vynásobit to zleva maticí zkosení.",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "Numericky řečeno to znamená, že na daný vektor aplikujeme rotaci a následně střih.",
  "model": "DeepL",
  "from_community_srt": "Takhle se numericky řekne, že napřed provedeme rotaci a pak zkosení daného vektoru.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "Ale cokoli získáte, mělo by být stejné, jako když použijete tuto novou kompoziční matici, kterou jsme právě našli, podle stejného vektoru, bez ohledu na to, jaký vektor jste zvolili, protože tato nová matice by měla zachytit stejný celkový efekt jako rotace a následně smykové působení.",
  "model": "DeepL",
  "from_community_srt": "Ale ať dostanete cokoli, mělo by to vyjít stejně, jako když použijeme tuhle novou matici složení, kterou jsme našli, ten samý vektor, Je jedno, jaký vektor zvolíte, protože naše nová matice zachycuje ten samý celkový proces jako rotace-pak-zkosení.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "Podle toho, jak jsou zde věci zapsány, si myslím, že je rozumné nazývat tuto novou matici součinem původních dvou matic, nemyslíte?",
  "model": "DeepL",
  "from_community_srt": "Podle toho, co jsem teď napsal, je rozumné nazvat novou matici \"součinem\" těch dvou původních matic.",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "Za chvíli se můžeme zamyslet nad tím, jak tento součin vypočítat obecněji, ale je příliš snadné ztratit se v lese čísel.",
  "model": "DeepL",
  "from_community_srt": "Nemyslíte? Za chvilku si rozmyslíme, jak spočítat takový součin pro obecné matice, ale je příliš snadné se ztratit ve změti čísel.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "Vždy si pamatujte, že takovéto násobení dvou matic má geometrický význam použití jedné transformace a následně druhé.",
  "model": "DeepL",
  "from_community_srt": "Mějte na paměti, že takové násobení dvou matic má geometrický význam provedení jedné transformace a pak druhé.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "Jedna věc, která je tu trochu zvláštní, je, že čteme zprava doleva.",
  "model": "DeepL",
  "from_community_srt": "Někomu by mohlo připadat poněkud divné,",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "Nejprve použijete transformaci reprezentovanou maticí vpravo a poté transformaci reprezentovanou maticí vlevo.",
  "model": "DeepL",
  "from_community_srt": "že se to čte zprava doleva: Napřed provedete transformace danou maticí napravo, až potom provedete transformaci danou maticí nalevo.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "To vyplývá ze zápisu funkcí, protože funkce zapisujeme vlevo od proměnných, takže při každém skládání dvou funkcí je vždy nutné číst zprava doleva.",
  "model": "DeepL",
  "from_community_srt": "To pochází ze značení funkcí, funkce píšeme nalevo od proměnných, takže vždycky, když skládáme dvě funkce, musíme je číst zprava doleva.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "Dobrá zpráva pro hebrejské čtenáře, špatná pro nás ostatní.",
  "model": "DeepL",
  "from_community_srt": "Dobrá zpráva pro čtenáře Hebrejštiny, špatná zpráva pro nás ostatní.",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "Podívejme se na jiný příklad.",
  "model": "DeepL",
  "from_community_srt": "Podívejme se na další příklad.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "Vezměme matici se sloupci 1,1 a zápornými 2,0, jejíž transformace vypadá takto.",
  "model": "DeepL",
  "from_community_srt": "Vezmeme matici se sloupci (1,1) a (-2,0), její transformace vypadá takto,",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "A nazvěme ji M1.",
  "model": "DeepL",
  "from_community_srt": "a nazveme ji M1.",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "Dále vezmeme matici se sloupci 0,1 a 2,0, jejíž transformace vypadá takto.",
  "model": "DeepL",
  "from_community_srt": "Teď si vezmeme matici se sloupci (0,1) a (2,0), její transformace vypadá takto,",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "A tomu chlapovi říkejme M2.",
  "model": "DeepL",
  "from_community_srt": "a nazveme ji M2.",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "Celkový efekt aplikace M1 a následně M2 nám dává novou transformaci, takže najděme její matici.",
  "model": "DeepL",
  "from_community_srt": "Výsledný proces aplikování napřed M1, pak M2 nám dává novou transformaci.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "Tentokrát se však podíváme, zda to zvládneme bez sledování animací a místo toho použijeme pouze číselné údaje v jednotlivých maticích.",
  "model": "DeepL",
  "from_community_srt": "Jak najdeme její matici? Ale tentokrát na to chceme přijít bez sledování animace a místo toho jen použít číselné položky v maticích.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "Nejprve musíme zjistit, kam i-čepice patří.",
  "model": "DeepL",
  "from_community_srt": "Napřed musíme přijít na to,",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "Po použití M1 jsou nové souřadnice i-čepice podle definice dány prvním sloupcem M1, tedy 1,1.",
  "model": "DeepL",
  "from_community_srt": "kde skončí vektor i. Po provedení M1 je nová souřadnice vektoru i z definice dána prvním sloupečkem M1, jmenovitě (1,1).",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "Chcete-li zjistit, co se stane po použití M2, vynásobte matici pro M2 tímto vektorem 1,1.",
  "model": "DeepL",
  "from_community_srt": "Abychom zjistili, co se stane po provedení M2, vynásobíme matici M2 tímto vektorem (1,1).",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "Když to vyřešíte tak, jak jsem popsal v minulém videu, získáte vektor 2,1.",
  "model": "DeepL",
  "from_community_srt": "Uděláme to, jak jsem ukazoval v minulém videu a dostaneme vektor (2,",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "Toto bude první sloupec matice složení.",
  "model": "DeepL",
  "from_community_srt": "1). To bude první sloupeček součinu matic.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "Podobně, abychom sledovali j-hat, druhý sloupec M1 nám říká, že nejprve přistane na záporných 2,0.",
  "model": "DeepL",
  "from_community_srt": "Podobně, když sledujeme j, druhý sloupec M1 nám řekne,",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "Když pak na tento vektor aplikujeme M2, můžeme vypočítat maticový vektorový součin a získat hodnotu 0, zápornou 2, která se stane druhým sloupcem naší kompoziční matice.",
  "model": "DeepL",
  "from_community_srt": "že po M1 přistane na (-2,0) a pak, když provedeme M2 na výsledek, a spočítáme součin matice a vektoru, vyjde nám (0, -2), to bude druhý sloupeček součinu matic.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "Dovolte mi, abych stejný postup zopakoval, ale tentokrát ukážu proměnné položky v každé matici, abych ukázal, že stejná úvaha funguje pro všechny matice.",
  "model": "DeepL",
  "from_community_srt": "Teď zkusme projít tím samým procesem znovu, ale tentokrát budou položky matic proměnné, jen, abychom si předvedli, jak toto odvození funguje pro jakékoli matice.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "Tento postup je náročnější na symboly a bude vyžadovat více prostoru, ale měl by být uspokojivý pro každého, kdo se dříve učil násobení matic více rutinním způsobem.",
  "model": "DeepL",
  "from_community_srt": "Je tam o dost víc písmenek a bude to vyžadovat víc místa, ale mělo by to uspokojit všechny, kteří už dřív slyšeli o násobení matic tím více \"psacím\" způsobem.",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "Chcete-li sledovat, kam se i-hat dostane, začněte pohledem na první sloupec matice vpravo, protože zde se i-hat původně nachází.",
  "model": "DeepL",
  "from_community_srt": "Abychom zjistili, kam jde vektor i, začneme tím, že se podíváme na první sloupec matice napravo, to je mezipřistání vektoru i,",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "Vynásobením tohoto sloupce maticí vlevo lze zjistit, kde se nachází meziverze i-hat po použití druhé transformace.",
  "model": "DeepL",
  "from_community_srt": "a tento vektor vynásobíme maticí nalevo, to nám dá konečnou polohu vektoru i po provedení druhé transformace.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "První sloupec kompoziční matice se tedy vždy rovná levé matici krát první sloupec pravé matice.",
  "model": "DeepL",
  "from_community_srt": "Takže, první sloupeček matice složení se bude vždy rovnat \"levá matice krát první sloupec pravé\".",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "Stejně tak j-hat vždy zpočátku přistane na druhém sloupci pravé matice.",
  "model": "DeepL",
  "from_community_srt": "Stejně tak vektor j se napřed přemění na druhý sloupeček pravé matice, takže když jej pak vynásobíme levou maticí,",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "Takže vynásobením levé matice tímto druhým sloupcem získáme její konečnou polohu, a proto je to druhý sloupec kompoziční matice.",
  "model": "DeepL",
  "from_community_srt": "získáme jeho výslednou hodnotu. a tedy druhý sloupec matice složení.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "Všimněte si, že je zde spousta symbolů, a je běžné, že se tento vzorec učíte jako něco, co si máte zapamatovat, spolu s určitým algoritmickým postupem, který vám pomůže si ho zapamatovat.",
  "model": "DeepL",
  "from_community_srt": "Je tady spousta symbolů a je běžné učit tenhle vzoreček jako něco k zapamatování spolu s jistým algoritmem, s kterým se to snáze zapamatuje.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "Ale opravdu si myslím, že než si tento postup zapamatujete, měli byste si zvyknout přemýšlet o tom, co násobení matic skutečně představuje, a aplikovat jednu transformaci za druhou.",
  "model": "DeepL",
  "from_community_srt": "Ale vážně mi připadá, že než se naučíte ten algoritmus, měli byste si zvyknout na představu toho, co součin matic doopravdy znamená: provedení jedné transformace,",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "Věřte mi, že díky tomu získáte mnohem lepší koncepční rámec, který vám usnadní pochopení vlastností násobení matic.",
  "model": "DeepL",
  "from_community_srt": "pak druhé. Věřte mi, dá vám to mnohem lepší koncepční rámec, se kterým se vlastnosti násobení matic mnohem lépe chápou.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "Například tato otázka.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "Záleží na tom, v jakém pořadí obě matice vynásobíme?",
  "model": "DeepL",
  "from_community_srt": "Jako příklad uvedu tuto otázku: Záleží na pořadí,",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "Zkusme se zamyslet nad jednoduchým příkladem, jako byl ten předchozí.",
  "model": "DeepL",
  "from_community_srt": "ve kterém matice násobíme? Tento jednoduchý příklad si rozmyslíme pomocí jednoho příkladu z minula.",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "Vezměme si střih, který upevní i-čepici a přehoupne j-čepici doprava, a otočení o 90 stupňů.",
  "model": "DeepL",
  "from_community_srt": "Vezmeme zkosení, které zafixuje a, a šoupne j doprava a dále otočení o 90°.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "Pokud nejprve provedete střih a poté otáčení, zjistíme, že i-hat končí v bodě 0,1 a j-hat končí v bodě záporné 1,1.",
  "model": "DeepL",
  "from_community_srt": "Když napřed zkosíte, pak otočíte, vidíte, že i skončí na souřadnicích (0, 1) a j na souřadnicích (-1, 1).",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "Obě většinou směřují blízko k sobě.",
  "model": "DeepL",
  "from_community_srt": "Oba vektory jsou si blízko.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "Pokud nejprve otočíte a pak provedete střih, i-čepice skončí na 1,1 a j-čepice je v jiném směru na záporné hodnotě 1,0 a směřují, víte, dále od sebe.",
  "model": "DeepL",
  "from_community_srt": "Když napřed otočíte, pak zkosíte, i skončí na (1, 1) a j skončí v jiném směru: na (-1, 0) a tentokrát míří více od sebe,",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "Celkový efekt je zde zřetelně odlišný, takže na pořadí zjevně zcela záleží.",
  "model": "DeepL",
  "from_community_srt": "svírají tupý úhel. Takže výsledné složení je zjevně jiné, čili na pořadí rozhodně záleží.",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "Všimněte si, že přemýšlení v termínech proměn je druh věcí, které můžete dělat ve své hlavě vizualizací.",
  "model": "DeepL",
  "from_community_srt": "Když se na to díváme z pohledu transformací, tak to je něco, co si můžeme představit v hlavě.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "Není nutné násobení matic.",
  "model": "DeepL",
  "from_community_srt": "Nepotřebujeme žádné maticové násobení.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "Vzpomínám si, že když jsem se poprvé učil lineární algebru, měli jsme za domácí úkol dokázat, že násobení matic je asociativní.",
  "model": "DeepL",
  "from_community_srt": "Pamatuji si, jak jsem poprvé chodil na lineární algebru, a bylo za domácí úkol dokázat, že násobení matic je asociativní.",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "To znamená, že pokud máte tři matice, A, B a C, a násobíte je všechny dohromady, nemělo by záležet na tom, jestli nejprve spočítáte A krát B a pak výsledek vynásobíte C, nebo jestli nejprve vynásobíte B krát C a pak tento výsledek vynásobíte A vlevo.",
  "model": "DeepL",
  "from_community_srt": "To znamená, že když máte tři matice A, B, C, a vynásobíte je mezi sebou, tak by nemělo záležet na tom, jestli tapřed spočtete součin AB, a to pak vynásobíte C, nebo jestli napřed spočtete součin BC a ten pak vynásobíte maticí A zleva.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "Jinými slovy, nezáleží na tom, kam závorky umístíte.",
  "model": "DeepL",
  "from_community_srt": "Jinými slovy, nezáleží na uzávorkování.",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "Když se to teď pokusíte zpracovat číselně, jako jsem to tehdy dělal já, je to hrozné, prostě hrozné a nepoučné.",
  "model": "DeepL",
  "from_community_srt": "Když se to pokusíte provést numericky, jako jsemto tehdy dělal já, je to strašné, prostě strašné, a nic to neobjasňuje.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "Pokud však o násobení matic uvažujeme jako o použití jedné transformace za druhou, je tato vlastnost triviální.",
  "model": "DeepL",
  "from_community_srt": "Ale když si představíte součin matic jako provedení napřed jedné transformace a pak druhé, stane se tahle vlastnost zcela zřejmou.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "Chápete proč?",
  "model": "DeepL",
  "from_community_srt": "Vidíte,",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "Říká, že pokud nejprve použijete C, pak B a pak A, je to stejné jako použít C, pak B a pak A.",
  "model": "DeepL",
  "from_community_srt": "proč? Je to jak říct, že když provedete napřed (C, pak B) a pak A, je to totéž, jako provést C, pak (B,",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "Myslím tím, že není co dokazovat.",
  "model": "DeepL",
  "from_community_srt": "pak A).",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "Pouze používáte tři stejné věci jednu po druhé, všechny ve stejném pořadí.",
  "model": "DeepL",
  "from_community_srt": "Není tu co dokazovat, jenom provádíte ty samé tři věci za sebou v tom samém pořadí.",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "Může to vypadat jako podvod, ale není tomu tak.",
  "model": "DeepL",
  "from_community_srt": "Může to vypadat podvod, ale není!",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "Toto je poctivý důkaz, že násobení matic je asociativní, a co je ještě lepší, je to dobré vysvětlení, proč by tato vlastnost měla platit.",
  "model": "DeepL",
  "from_community_srt": "Je to poctivý důkaz toho, že násobení matic je asociativní, a dokonce něco víc, je to dobré vysvětlení, proč by taková vlastnost měla platit.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "Opravdu vám doporučuji, abyste si s touto myšlenkou více pohráli, představili si dvě různé transformace, přemýšleli o tom, co se stane, když použijete jednu po druhé, a pak numericky vypočítali maticový součin.",
  "model": "DeepL",
  "from_community_srt": "Hrajte si s touhle myšlenkou, představujte si násobení matic jako dvě transformací, napřed provedete jednu, a potom druhou, a až potom spočtěte součin matic numericky.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "Věřte mi, že právě při takovém hraní se vám tato myšlenka opravdu vryje do paměti.",
  "model": "DeepL",
  "from_community_srt": "Věřte mi, čas strávený takovým hraním vám pomůže tu myšlenku pořádně vstřebat.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "V příštím videu začnu mluvit o rozšíření těchto myšlenek nad rámec dvou rozměrů.",
  "model": "DeepL",
  "from_community_srt": "V následujícím videu se pustíme do rozšíření této představy do více rozměrů.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]