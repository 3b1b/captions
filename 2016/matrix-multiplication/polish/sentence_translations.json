[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "Hej wszystkim, tam gdzie ostatnio skończyliśmy, pokazałem jak wyglądają przekształcenia liniowe i jak je przedstawić za pomocą macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Cześć wszystkim! W miejscu gdzie ostatnio skończyliśmy pokazywałem jak wyglądają transformacje liniowe i jak jest przedstawić używając macierzy.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "Warto to szybko podsumować, ponieważ jest to po prostu naprawdę ważne, ale jeśli oczywiście wydaje Ci się to czymś więcej niż tylko podsumowaniem, wróć i obejrzyj cały film.",
  "model": "google_nmt",
  "from_community_srt": "Warto do tego na chwilkę wrócić, ponieważ jest to bardzo istotne. (Lecz jeśli sądzisz że potrzeba więcej niż szybki powrót, obejrzyj raz jeszcze cały film) Mówiąc technicznie,",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "Technicznie rzecz biorąc, przekształcenia liniowe są funkcjami, w których wektory stanowią dane wejściowe, a wektory stanowią dane wyjściowe, ale ostatnim razem pokazałem, jak możemy o nich myśleć wizualnie jako o płynących w przestrzeni w taki sposób, że linie siatki pozostają równoległe i równomiernie rozmieszczone, a początek układu współrzędnych pozostaje stała.",
  "model": "google_nmt",
  "from_community_srt": "transformacje liniowe to funkcje, z wejściami wektorowymi i wektorami na wyjściu. Pokazywałem ostatnio jak możemy sobie to wyobrazić przestrzennie jako zginanie przestrzeni w taki sposób by linie siatki zostały równoległe i równo rozłożone, a do tego środek się nie przemieścił.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "Kluczowym wnioskiem było to, że transformacja liniowa jest całkowicie zdeterminowana przez miejsce, w którym znajdują się wektory bazowe przestrzeni, co dla dwóch wymiarów oznacza i-hat i j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Główny spostrzeżeniem było iż transformacja liniowa jest w całości zdefiniowane przez wektory bazowe wyniku, czyli, dla dwóch wymiarów - i-z-daszkiem i j-z-daszkiem.",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "Dzieje się tak, ponieważ każdy inny wektor można opisać jako liniową kombinację tych wektorów bazowych.",
  "model": "google_nmt",
  "from_community_srt": "Tak jest gdyż każdy inny wektor może być opisany jako kombinacja liniowa tych wektorów bazowych.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "Wektor o współrzędnych x, y to x razy i-hat plus y razy j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Wektor o współrzędnych [x,y] to z razy i-z-daszkiem + y razy j-z-daszkiem.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "Po przejściu transformacji ta właściwość, że linie siatki pozostają równoległe i równomiernie rozmieszczone, ma wspaniałe konsekwencje.",
  "model": "google_nmt",
  "from_community_srt": "Przechodząc przez transformację ta właściwość, iż linie siatki zostają równoległe i równo rozłożone, ma ciekawe konsekwencje.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "Miejsce, w którym wyląduje wektor, będzie x razy przekształcona wersja i-hat plus y razy przekształcona wersja j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Miejsce gdzie znajdzie się wektor to będzie x razy przetransformowane i-z-daszkiem + y razy przetransformowane j-z-daszkiem.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "Oznacza to, że jeśli zapiszesz współrzędne miejsca, w którym wyląduje i-hat i współrzędne, w którym wyląduje j-hat, możesz obliczyć, że wektor zaczynający się od x, y musi wylądować x razy nowe współrzędne i-hat plus y razy nowe współrzędne j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Oznacza to że jak znamy współrzędne miejsca gdzie znajdzie się i-z-daszkiem, oraz współrzędne i-z-daszkiem, możemy obliczyć współrzędne wektora który zaczął jako [x,y] - musi on znaleźć się w miejscu: x razy nowe-współrzędne-i-z-daszkiem, + y razy nowe-współrzędne-j-z-daszkiem.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "Konwencja polega na zapisywaniu współrzędnych miejsc i-hat i j-hat jako kolumn macierzy i zdefiniowaniu tej sumy przeskalowanych wersji tych kolumn przez x i y jako mnożenie wektorów macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Będziemy zapisywać współrzędne gdzie znalazły się i-z-daszkiem oraz j-z-daszkiem jako kolumny macierzy Zdefiniujemy pewne przeskalowane przez x i y wersje tych kolumn za pomocą mnożenia macierz-wektor.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "W ten sposób macierz reprezentuje określoną transformację liniową, a pomnożenie macierzy przez wektor oznacza obliczeniowo zastosowanie tej transformacji do tego wektora.",
  "model": "google_nmt",
  "from_community_srt": "W ten sposób macierz przedstawia konkretną transformację liniową i mnożenie macierzy przez wektor jest, przynajmniej obliczeniowo, nałożeniem transformacji na ten wektor.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "Dobra, podsumujmy i przejdźmy do nowych rzeczy.",
  "model": "google_nmt",
  "from_community_srt": "Dobrze,",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "Często zdarza się, że chcesz opisać skutki zastosowania jednej transformacji, a potem drugiej.",
  "model": "google_nmt",
  "from_community_srt": "koniec powtórki - idziemy dalej! Wielokrotnie będziemy potrzebować opisać efekt nałożenia jednej transformacji na inną.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "Może na przykład chcesz opisać, co się stanie, gdy najpierw obrócisz płaszczyznę o 90 stopni w kierunku przeciwnym do ruchu wskazówek zegara, a następnie zastosujesz ścinanie.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, możemy opisać co się stanie jak wpierw obrócimy płaszczyznę o 90 stopni (przeciwnie do ruchu wskazówek zegara), a następnie nałożymy \"shear\" (ścinanie).",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "Ogólny efekt, od początku do końca, to kolejna transformacja liniowa, różna od rotacji i ścinania.",
  "model": "google_nmt",
  "from_community_srt": "Efektem końcowym będzie kolejna transformacja liniowa, odmienna od obrotu i ścinania.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "Ta nowa transformacja liniowa jest powszechnie nazywana złożeniem dwóch oddzielnych transformacji, które zastosowaliśmy.",
  "model": "google_nmt",
  "from_community_srt": "Ta nowa transformacja liniowa jest nazywana \"kompozycją\" dwóch transformat które nałożyliśmy.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "I jak każdą transformację liniową, można ją opisać za pomocą własnej macierzy, podążając za i-hat i j-hat.",
  "model": "google_nmt",
  "from_community_srt": "I tak jak każda transformacja liniowa, może być opisana przez własną macierz, zadaną przez podążanie za i-z-daszkiem oraz j-z-daszkiem.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "W tym przykładzie ostateczne miejsce lądowania i-hat po obu transformacjach wynosi 1,1, więc uczyńmy to pierwszą kolumną macierzy.",
  "model": "google_nmt",
  "from_community_srt": "W tym przykładzie, końcowe miejsce i-z-daszkiem po obu transformacja to [1,1]. Stwórzmy więc pierwszą kolumnę macierzy.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "Podobnie j-hat ostatecznie kończy się na położeniu ujemnym 1,0, więc tworzymy drugą kolumnę macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Analogicznie, j-z-daszkiem ląduje we współrzędnych [-1, 0]. Tworzymy więc drugą kolumnę macierzy.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "Ta nowa macierz oddaje ogólny efekt zastosowania obrotu, a następnie ścinania, ale jako pojedyncze działanie, a nie dwa kolejne.",
  "model": "google_nmt",
  "from_community_srt": "Macierz ta zawiera złożenie efektów obrotu i ścinania, lecz jako jedno działania,",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "Oto jeden ze sposobów myślenia o tej nowej matrycy.",
  "model": "google_nmt",
  "from_community_srt": "a nie dwa kolejne.",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "Jeśli miałbyś wziąć jakiś wektor i przepompować go przez obrót, to ścinanie. Długa droga do obliczenia, gdzie to się kończy, polega na pomnożeniu go po lewej stronie przez macierz rotacji, następnie wzięciu wszystkiego, co otrzymasz, i pomnożeniu przez pozostawione przez macierz ścinania.",
  "model": "google_nmt",
  "from_community_srt": "Możemy myśleć o nowej macierzy w następujący sposób: gdybyśmy wzięli pewien wektor i przetworzylibyśmy go przez rotację a następnie ścinanie, dłuższym sposobem obliczenia gdzie się znajdzie jest, wpierw, pomnożenie go z lewej przez macierz rotacji, a następnie wzięcie wyniku i pomnożenie go z lewej przez macierz ścinania. Jest to,",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "To jest, mówiąc liczbowo, co to znaczy zastosować obrót, a następnie ścinanie do danego wektora.",
  "model": "google_nmt",
  "from_community_srt": "obliczeniowo mówiąc, dokładnie nałożenie rotacji i ścięcia na dany wektor.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "Ale wszystko, co otrzymasz, powinno być takie samo, jak zastosowanie nowej macierzy kompozycji, którą właśnie znaleźliśmy, według tego samego wektora, bez względu na to, jaki wektor wybierzesz, ponieważ ta nowa macierz ma uchwycić ten sam ogólny efekt, co obrót, a następnie działanie ścinania.",
  "model": "google_nmt",
  "from_community_srt": "Cokolwiek jednak wyjdzie powinno być tym samym co nałożenie macierzy złożonej która właśnie znaleźliśmy na ten sam wektor, niezależnie od tego jaki wektor wybierzemy, gdyż nowa macierz powinna dawać nam ten sam efekt całkowity jak działanie obrót-potem-ścinanie.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "Bazując na tym, jak wszystko jest tu zapisane, myślę, że rozsądne jest nazwanie tej nowej macierzy iloczynem dwóch pierwotnych macierzy, prawda?",
  "model": "google_nmt",
  "from_community_srt": "Patrząc na to jak jest to napisane tutaj, sądzę że sensownie byłoby nazwać tę nową macierz \"produktem\" dwóch macierzy startowych.",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "O tym, jak ogólnie obliczyć ten iloczyn, możemy pomyśleć za chwilę, ale zbyt łatwo jest zgubić się w lesie liczb.",
  "model": "google_nmt",
  "from_community_srt": "Zgadzasz się? Możemy się zastanowić jak obliczyć ten produkt bardziej ogólnie za chwilę, ale jest zbyt łatwo zagubić się w gąszczu liczb.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "Zawsze pamiętaj, że mnożenie dwóch macierzy w ten sposób ma geometryczne znaczenie zastosowania jednej transformacji, a potem drugiej.",
  "model": "google_nmt",
  "from_community_srt": "Warto zapamiętać iż mnożenie dwóch macierzy ma geometryczny sens nałożenia jednej transformacji za drugą.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "Jedną z rzeczy, która jest tutaj trochę dziwna, jest to, że czytamy od prawej do lewej.",
  "model": "google_nmt",
  "from_community_srt": "To co jest tu nieco dziwne, to to iż czytamy to od prawej do lewej. tj.",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "Najpierw stosujesz transformację reprezentowaną przez macierz po prawej stronie, następnie stosujesz transformację reprezentowaną przez macierz po lewej stronie.",
  "model": "google_nmt",
  "from_community_srt": "wpierw nakładamy transformację obrazowaną macierzą po prawej. Następnie nakładamy transformację obrazowaną macierzą po lewej.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "Wynika to z notacji funkcji, ponieważ funkcje piszemy po lewej stronie zmiennych, więc za każdym razem, gdy tworzysz dwie funkcje, zawsze musisz je czytać od prawej do lewej.",
  "model": "google_nmt",
  "from_community_srt": "Pochodzi to z notacji funkcyjnej, gdzie piszemy funkcje na lewo od zmiennych, zatem każdorazowo gdy składamy dwie funkcje, zawsze czytamy jest od prawej do lewej.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "Dobra wiadomość dla czytelników hebrajskich, zła wiadomość dla reszty z nas.",
  "model": "google_nmt",
  "from_community_srt": "(co jest dobrą wiadomością dla czytelników władających Hebrajskim,",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "Spójrzmy na inny przykład.",
  "model": "google_nmt",
  "from_community_srt": "ale gorszą dla reszty) Spójrzmy na inny przykład.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "Weźmy macierz z kolumnami 1,1 i minus 2,0, której przekształcenie wygląda następująco.",
  "model": "google_nmt",
  "from_community_srt": "Weźmy macierz z kolumnami (1,1) i (-2,0) które tworzą przekształcenie takie jak to, i nazwijmy je M1.",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "I nazwijmy to M1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "Następnie weźmy macierz z kolumnami 0,1 i 2,0, której przekształcenie wygląda następująco.",
  "model": "google_nmt",
  "from_community_srt": "Następnie weźmy macierz z kolumnami (0,1) i (2,0) które tworzą przekształcenie takie jak to,",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "I nazwijmy tego gościa M2.",
  "model": "google_nmt",
  "from_community_srt": "i nazwijmy je M2.",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "Całkowity efekt zastosowania M1, a następnie M2 daje nam nową transformację, więc znajdźmy jej macierz.",
  "model": "google_nmt",
  "from_community_srt": "Sumaryczny skutek nałożenia M1 a następnie M2 daje nam nowe przekształcenie. Znajdźmy więc jego macierz.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "Ale tym razem zobaczmy, czy uda nam się to zrobić bez oglądania animacji, a zamiast tego po prostu używając wpisów liczbowych w każdej macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Tym razem, sprawdźmy czy możemy to zrobić bez oglądania animacji, zamiast tego używając tylko wartości liczbowych w każdej macierzy.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "Najpierw musimy dowiedzieć się, dokąd idzie i-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "Po zastosowaniu M1 nowe współrzędne i-hat z definicji są wyznaczane przez pierwszą kolumnę M1, a mianowicie 1,1.",
  "model": "google_nmt",
  "from_community_srt": "Na początku musimy odgadnąć gdzie znajdzie się i-z-daszkiem Po nałożeniu M1 na nowe współrzędne i-z-daszkiem, z definicji, dostaniemy pierwszą z kolumn M1, tj.",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "Aby zobaczyć co się stanie po zastosowaniu M2, pomnóż macierz M2 przez ten wektor 1,1.",
  "model": "google_nmt",
  "from_community_srt": "(1,1) By sprawdzić co się stanie po nałożeniu M2, mnożymy macierzą dla M2 dany wektor (1,1).",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "Rozpracowując to, tak jak opisałem w poprzednim filmie, otrzymasz wektor 2,1.",
  "model": "google_nmt",
  "from_community_srt": "Robiąc to w sposób omówiony w poprzednim filmie, dostaniemy wektor (2,",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "Będzie to pierwsza kolumna macierzy kompozycji.",
  "model": "google_nmt",
  "from_community_srt": "1). Będzie to pierwsza kolumna macierzy złożonej.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "Podobnie, podążając za j-hat, druga kolumna M1 mówi nam, że najpierw wyląduje na minusie 2,0.",
  "model": "google_nmt",
  "from_community_srt": "Podobnie, podążając z j-z-daszkiem, druga kolumna M1 mówi nam gdzie znajdzie się (-2,0).",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "Następnie, gdy zastosujemy M2 do tego wektora, możesz obliczyć iloczyn macierz-wektor, aby otrzymać 0, minus 2, co staje się drugą kolumną naszej macierzy złożenia.",
  "model": "google_nmt",
  "from_community_srt": "Następnie, gdy nałożymy M2 na ten wektor, możemy obliczyć iloraz macierzy z wektorem by dostać (0, -2), które stanie się drugą kolumną naszej macierzy złożonej.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "Pozwólcie, że omówię ten sam proces jeszcze raz, ale tym razem pokażę zmienne wpisy w każdej macierzy, żeby pokazać, że ten sam tok rozumowania sprawdza się w przypadku dowolnej macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Omówmy jeszcze raz ten sam proces, ale tym razem pokażę to na zmiennych w każdej macierzy, tylko by pokazać iż ta sama argumentacja działa dla każdych macierzy.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "To wymaga więcej symboli i będzie wymagało więcej miejsca, ale powinno być całkiem satysfakcjonujące dla każdego, kto był wcześniej nauczony mnożenia macierzy w bardziej wyuczony sposób.",
  "model": "google_nmt",
  "from_community_srt": "Jest to bardziej pracochłonne i będzie potrzebne więcej miejsca, ale powinno to być dość łatwe do przejścia dla każdego kto uczył się mnożenia macierzy w sposób bardziej \"pisany\".",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "Aby śledzić, dokąd zmierza i-hat, zacznij od spojrzenia na pierwszą kolumnę macierzy po prawej stronie, ponieważ to tam początkowo ląduje i-hat.",
  "model": "google_nmt",
  "from_community_srt": "By sprawdzić dokąd pójdzie i-z-daszkiem, zaczynamy od spojrzenia na pierwszą kolumnę macierzy po prawej, gdyż jest to miejsce gdzie wyląduje początkowo i-z-daszkiem.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "Mnożąc tę kolumnę przez macierz po lewej stronie, możesz określić, gdzie kończy się pośrednia wersja i-hat po zastosowaniu drugiej transformacji.",
  "model": "google_nmt",
  "from_community_srt": "Mnożenie tej kolumnę przez macierz po lewej, to sposób policzenia gdzie znajdzie się pośrednia wersja i-z-daszkiem po nałożeniu drugiego przekształcenia.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "Zatem pierwsza kolumna macierzy składu będzie zawsze równa lewej macierzy pomnożonej przez pierwszą kolumnę prawej macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Zatem pierwsza kolumna macierzy złożonej będzie zawsze równa lewej macierzy pomnożonej przez pierwszą kolumnę prawej macierzy.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "Podobnie j-hat zawsze początkowo wyląduje w drugiej kolumnie prawej macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Podobnie, j-z-daszkiem zawsze przemieści się do drugiej kolumny prawej macierzy.",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "Zatem pomnożenie lewej macierzy przez tę drugą kolumnę da jej ostateczną lokalizację, a zatem jest to druga kolumna macierzy kompozycji.",
  "model": "google_nmt",
  "from_community_srt": "Zatem mnożenie lewej macierzy przez tą drugą kolumnę da nam jej końcową lokalizację, i dalej,",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "Zauważ, że jest tu wiele symboli i często uczy się tej formuły jako czegoś do zapamiętania, wraz z pewnym procesem algorytmicznym, który pomaga ją zapamiętać.",
  "model": "google_nmt",
  "from_community_srt": "jest to druga kolumna macierzy złożonej. Jak widać mamy tu dużo zmiennych i zwykle uczy się tego wzoru na pamięć, razem z pewnym algorytmem by wspomóc zapamiętanie tego.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "Ale naprawdę uważam, że zanim zapamiętasz ten proces, powinieneś przyzwyczaić się do myślenia o tym, co tak naprawdę reprezentuje mnożenie macierzy, stosując jedną transformację po drugiej.",
  "model": "google_nmt",
  "from_community_srt": "Ja zaś sądzę że przed zakuciem tego procesu na pamięć lepiej zapamiętać to co mnożenie macierzy faktycznie przedstawia: nałożenie jednego przekształcenia po innym.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "Zaufaj mi, zapewni to znacznie lepsze ramy koncepcyjne, dzięki którym właściwości mnożenia macierzy będą znacznie łatwiejsze do zrozumienia.",
  "model": "google_nmt",
  "from_community_srt": "Uwierz mi, to da nam dużo lepsze zrozumienie całokształtu tego czym jest mnożenie macierzy.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "Oto na przykład pytanie.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu,",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "Czy ma znaczenie, w jakiej kolejności umieścimy obie macierze podczas ich mnożenia?",
  "model": "google_nmt",
  "from_community_srt": "zadajmy pytanie: Czy to ma znaczenie w jakiej kolejności mnożymy macierze?",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "Cóż, przemyślmy prosty przykład, taki jak ten z wcześniej.",
  "model": "google_nmt",
  "from_community_srt": "Zastanówmy się nad prostym przykładem podobnym do wcześniejszych: Weźmy ścięcie które zachowuje i-z-daszkiem i przesuwa j-z-daszkiem w prawo,",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "Weź nożyce, które naprawiają i-hat i przesuwają j-hat w prawo, i obrót o 90 stopni.",
  "model": "google_nmt",
  "from_community_srt": "oraz obrót o 90 stopni.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "Jeśli najpierw wykonasz ścinanie, a następnie obrócisz, zobaczymy, że i-hat kończy się na 0,1, a j-hat kończy się na minusie 1,1.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli pierwsze zetniemy a później obrócimy, widzimy że i-z-daszkiem ląduje w (0, 1) a j-z-daszkiem ląduje w (-1,",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "Obydwa na ogół wskazują blisko siebie.",
  "model": "google_nmt",
  "from_community_srt": "1) Obydwa wskazują w podobnym kierunku.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "Jeśli najpierw się obrócisz, a następnie wykonaj ścinanie, i-hat skończy się na 1,1, a j-hat przesunie się w innym kierunku na minus 1,0 i będą one skierowane, no wiesz, dalej od siebie.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli wpierw obrócimy a później zetniemy, i-z-daszkiem ląduje na (1, 1) a j-z-daszkiem ląduje w inną stronę jako (-1, 0), i wskazują one (jak widać), w odmiennych kierunkach.",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "Ogólny efekt jest tutaj wyraźnie inny, więc najwyraźniej kolejność ma ogromne znaczenie.",
  "model": "google_nmt",
  "from_community_srt": "Widać że efekt nie jest podobny do poprzedniego. Zatem, bez wątpienia, kolejność ma znaczenie.",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "Zauważ, że myśląc w kategoriach transformacji, właśnie tego rodzaju rzeczy możesz zrobić w swojej głowie poprzez wizualizację.",
  "model": "google_nmt",
  "from_community_srt": "Zwróć uwagę, że myśląc w kategoriach transformacji możemy dokonać ich w głowie wyobrażając je sobie graficznie.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "Nie ma potrzeby mnożenia macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Nie jest nam potrzebne mnożenie macierzowe.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "Pamiętam, że kiedy po raz pierwszy zadawałem się z algebrą liniową, było jedno zadanie domowe, które wymagało od nas udowodnienia, że mnożenie macierzy jest łączne.",
  "model": "google_nmt",
  "from_community_srt": "Pamiętam iż pierwszy raz gdy uczyłem się algebry liniowej dostałem w zadaniu domowym udowodnić iż mnożenie macierzy jest łączne. To znaczy,",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "Oznacza to, że jeśli masz trzy macierze A, B i C i pomnożysz je wszystkie przez siebie, nie powinno mieć znaczenia, czy najpierw obliczysz A razy B, a następnie pomnożysz wynik przez C, czy też najpierw pomnożysz B przez B C, a następnie pomnóż wynik przez A po lewej stronie.",
  "model": "google_nmt",
  "from_community_srt": "jeśli mamy trzy macierze A, B i C, i pomnożymy je przez siebie, nie powinno mieć znaczenia czy pierwsze pomnożymy A *B a później wynik przez C, czy pierwsze pomnożymy B*C a później wynik przez A na lewej.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "Innymi słowy, nie ma znaczenia, gdzie umieścisz nawiasy.",
  "model": "google_nmt",
  "from_community_srt": "Innymi słowy, nie ma znaczenia gdzie damy nawiasy.",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "Jeśli spróbujesz przeanalizować to liczbowo, tak jak ja wtedy, to będzie to okropne, po prostu okropne i niepouczające, jeśli o to chodzi.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli spróbujemy przejść przez to liczbowo, jak ja wtedy, jest to okrutnie złożone i bez znaczenia dla sensu tej operacji.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "Ale gdy pomyślimy o mnożeniu macierzy jako o zastosowaniu jednej transformacji po drugiej, ta właściwość jest po prostu trywialna.",
  "model": "google_nmt",
  "from_community_srt": "Lecz kiedy pomyślimy o mnożeniu macierzy jako nałożeniu jednego przekształcenia za drugą, to ta właściwość jest banalna.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "Czy widzisz dlaczego?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "Mówi to o tym, że jeśli najpierw zastosujesz C, potem B, potem A, będzie to to samo, co zastosowanie C, potem B, a potem A.",
  "model": "google_nmt",
  "from_community_srt": "Czy wiesz czemu? Gdyż nałożenie C, później B, później A, jest tym samym co nałożenie C, później B później A.",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "To znaczy, nie ma nic do udowodnienia.",
  "model": "google_nmt",
  "from_community_srt": "Jak mówię,",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "Po prostu stosujesz te same trzy rzeczy, jedna po drugiej, wszystko w tej samej kolejności.",
  "model": "google_nmt",
  "from_community_srt": "nie ma tu co udowadniać, gdyż nakładamy te same trzy rzeczy jedna za drugą w tej samej kolejności.",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "Może się to wydawać oszustwem, ale tak nie jest.",
  "model": "google_nmt",
  "from_community_srt": "Wygląda to na oszukiwanie, ale nim nie jest.",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "Jest to uczciwy dowód na to, że mnożenie macierzy jest łączne, a co więcej, jest to dobre wyjaśnienie, dlaczego ta właściwość powinna być prawdziwa.",
  "model": "google_nmt",
  "from_community_srt": "Jest to uczciwy dowód że mnożenie macierzy jest łączne, a nawet lepiej, jest to dobre uzasadnienie dlaczego ta właściwość powinna być prawdziwa.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "Naprawdę zachęcam Cię do dalszej zabawy z tym pomysłem, wyobrażania sobie dwóch różnych transformacji, myślenia o tym, co się stanie, gdy zastosujesz jedną po drugiej, a następnie numerycznego obliczania iloczynu macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Zachęcam do przemyślenia na spokojnie tej idei, wyobrażenia sobie dwóch różnych transformacji, i zastanowienia się co się stanie gdy nałożymy je jedna za drugą, a następnie przejścia przez to ćwiczenie obliczeniowo.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "Zaufaj mi, to rodzaj zabawy, który naprawdę zapada w pamięć.",
  "model": "google_nmt",
  "from_community_srt": "Ta zabawa sprawi że zapamiętasz tą koncepcję na zawsze.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "W następnym filmie zacznę mówić o rozszerzeniu tych pomysłów poza dwa wymiary.",
  "model": "google_nmt",
  "from_community_srt": "W następnym filmie zacznę omawiać co się stanie przy rozszerzeniu tych idei ponad dwa wymiary. Do zobaczenia zatem!",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]