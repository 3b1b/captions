[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "Salut tout le monde, là où nous nous sommes arrêtés, j'ai montré à quoi ressemblent les transformations linéaires et comment les représenter à l'aide de matrices.",
  "from_community_srt": "Il est de mon expérience que les preuves impliquant des matrices peuvent être raccourcies de 50% si l'on retire les matrices. - Emil Artin Salut tout le monde! Là où nous nous étions arrêtés la fois dernière, j'ai montré à quoi des transformations linéaires ressemblent et comment les représenter à l'aide de matrices.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "Cela mérite un bref récapitulatif car c'est vraiment important, mais bien sûr, si cela vous semble plus qu'un simple récapitulatif, revenez en arrière et regardez la vidéo complète.",
  "from_community_srt": "Ca vaut la peine d'un bref récapitulatif, car c'est vraiment important. Mais bien sûr, si ça semble être plus qu'un rappel, revenez en arrière et regardez la vidéo complète.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "Techniquement parlant, les transformations linéaires sont des fonctions avec des vecteurs comme entrées et des vecteurs comme sorties, mais j'ai montré la dernière fois comment nous pouvons les considérer visuellement comme se déplaçant dans l'espace de telle manière que les lignes de la grille restent parallèles et régulièrement espacées, et de sorte que l'origine reste fixe.",
  "from_community_srt": "Techniquement parlant, les transformations linéaires sont des fonctions, avec des vecteurs en tant qu'entrées et des vecteurs en tant que sorties. Mais, comme je l'ai montré la dernière fois, que nous pouvons les penser visuellement Comme des déformations autour de l'espace de telle façon que les quadrillages restent parallèles et régulièrement espacés, et que l'origine reste fixe.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "L’essentiel à retenir est qu’une transformation linéaire est entièrement déterminée par l’endroit où elle prend les vecteurs de base de l’espace, ce qui, pour deux dimensions, signifie i-hat et j-hat.",
  "from_community_srt": "Le point clé est que une transformation linéaire est complètement déterminée, par là où elle amène les vecteurs de base de l'espace qui, pour deux dimensions, sont i-chapeau et j-chapeau.",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "En effet, tout autre vecteur pourrait être décrit comme une combinaison linéaire de ces vecteurs de base.",
  "from_community_srt": "En effet, tout autre vecteur peut être décrit comme une combinaison linéaire de ces vecteurs de base.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "Un vecteur de coordonnées x, y est x fois i-hat plus y fois j-hat.",
  "from_community_srt": "Un vecteur de coordonnées (x, y) est x fois i-chapeau + y fois j-chapeau.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "Après la transformation, cette propriété selon laquelle les lignes du quadrillage restent parallèles et régulièrement espacées a une conséquence merveilleuse.",
  "from_community_srt": "Après avoir subit cette transformation, cette propriété, les lignes de la grille restent parallèles et régulièrement espacées, a une conséquence merveilleuse.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "L'endroit où votre vecteur atterrit sera x fois la version transformée de i-hat plus y fois la version transformée de j-hat.",
  "from_community_srt": "L'endroit où vos terres vecteur arriveront sera x fois la version transformée de i-chapeau + y fois la version transformée de j-chapeau.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "Cela signifie que si vous conservez une trace des coordonnées où atterrit i-hat et des coordonnées où atterrit j-hat, vous pouvez calculer qu'un vecteur qui commence à x, y doit atterrir sur x fois les nouvelles coordonnées de i-hat plus y. fois les nouvelles coordonnées de j-hat.",
  "from_community_srt": "Cela signifie que si vous gardez un enregistrement des coordonnées où arrive i-chapeau et les coordonnées j-chapeau arrive vous pouvez calculer qu'un vecteur (x, y), doit arriver sur x fois les nouvelles coordonnées d'i-chapeau + y fois les nouvelles coordonnées de  j-chapeau.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "La convention est d'enregistrer les coordonnées de l'endroit où i-hat et j-hat atterrissent comme colonnes d'une matrice, et de définir cette somme des versions mises à l'échelle de ces colonnes par x et y comme étant une multiplication matrice-vecteur.",
  "from_community_srt": "La convention est d'enregistrer les coordonnées où arrivent i-chapeau et j-chapeau dans les colonnes d'une matrice et de définir cette somme des versions mises à l'échelle de ces colonnes par x et y comme étant la multiplication matrice-vecteur.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "De cette façon, une matrice représente une transformation linéaire spécifique, et multiplier une matrice par un vecteur est ce que signifie informatiquement appliquer cette transformation à ce vecteur.",
  "from_community_srt": "De cette façon, une matrice représente une transformation linéaire spécifique et la multiplication d'une matrice par un vecteur est, par le calcul, l'application de cette transformation au vecteur.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "Très bien, récapitulons, passons aux nouveautés.",
  "from_community_srt": "Ok, récapitulons. Sur les nouveautés.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "Souvent, vous avez envie de décrire les effets de l’application d’une transformation, puis d’une autre.",
  "from_community_srt": "Souvent, vous voulez décrire l'effet de l'application d'une transformation puis d'une autre.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "Par exemple, vous souhaitez peut-être décrire ce qui se passe lorsque vous faites d'abord pivoter le plan de 90 degrés dans le sens inverse des aiguilles d'une montre, puis que vous appliquez une cisaille.",
  "from_community_srt": "Par exemple, vous voulez peut-être décrire ce qui se passe quand vous devez d'abord tourner le plan de 90 ° puis appliquez une coupe.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "L'effet global ici, du début à la fin, est une autre transformation linéaire, distincte de la rotation et du cisaillement.",
  "from_community_srt": "L'effet global est, du début à la fin, une autre transformation linéaire, distinct de la rotation et de la coupe.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "Cette nouvelle transformation linéaire est communément appelée la composition des deux transformations distinctes que nous avons appliquées.",
  "from_community_srt": "Cette nouvelle transformation linéaire est communément appelée la « composition » des deux transformations distinctes que nous avons appliqué.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "Et comme toute transformation linéaire, elle peut être décrite avec une matrice qui lui est propre en suivant i-hat et j-hat.",
  "from_community_srt": "Et comme toute transformation linéaire elle peut être décrite par une matrice qui lui est propre, en suivant i-chapeau et j chapeau.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "Dans cet exemple, le point d'atterrissage ultime pour i-hat après les deux transformations est 1,1, faisons donc de cela la première colonne d'une matrice.",
  "from_community_srt": "Dans cet exemple, l'endroit ultime où arrive i-chapeau après les deux transformations est (1, 1). Nous en faisons donc la première colonne de la matrice.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "De même, j-hat se retrouve finalement à l'emplacement moins 1,0, nous en faisons donc la deuxième colonne de la matrice.",
  "from_community_srt": "De même, j-chapeau arrive en fin de compte à la emplacement (-1, 0), donc nous en faisons la deuxième colonne de la matrice.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "Cette nouvelle matrice capture l'effet global de l'application d'une rotation puis d'un cisaillement, mais comme une seule action, plutôt que deux actions successives.",
  "from_community_srt": "Cette nouvelle matrice saisit l'effet complet de l'application d'une rotation puis d'une coupe, mais comme une seule action,",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "Voici une façon de penser à cette nouvelle matrice.",
  "from_community_srt": "au lieu de deux successives.",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "Si vous deviez prendre un vecteur et le pomper à travers la rotation, puis le cisaillement, le long chemin pour calculer où il aboutit est de le multiplier d'abord à gauche par la matrice de rotation, puis de prendre ce que vous obtenez et de le multiplier sur le laissé par la matrice de cisaillement.",
  "from_community_srt": "Voici une façon de penser à cette nouvelle matrice: si vous deviez prendre un certain vecteur et lui appliquer une rotation puis une coupe. La manière longue de calculer où il arrive est de d'abord, le multiplier à gauche par la matrice de rotation; puis, de prendre le résultat et de le multiplier à gauche par la matrice de coupe.",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "C'est, numériquement parlant, ce que signifie appliquer une rotation puis un cisaillement à un vecteur donné.",
  "from_community_srt": "C'est, numériquement parlant, ce que cela signifie d'appliquer une rotation puis une coupe à un vecteur donné.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "Mais tout ce que vous obtenez devrait être la même chose que d'appliquer simplement cette nouvelle matrice de composition que nous venons de trouver par ce même vecteur, quel que soit le vecteur que vous avez choisi, puisque cette nouvelle matrice est censée capturer le même effet global que la rotation puis l'action de cisaillement.",
  "from_community_srt": "Mais, tout ce que vous obtenez devrait être identique à ce que vous obtiendriez en applicant la matrice de composition que nous venons de trouver, par ce même vecteur, peu importe ce que vous avez choisi comme vecteur, puisque cette nouvelle matrice est censée capturer le même effet final. de la rotation-coupe.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "D'après la façon dont les choses sont écrites ici, je pense qu'il est raisonnable d'appeler cette nouvelle matrice le produit des deux matrices originales, n'est-ce pas ?",
  "from_community_srt": "Sur la base dont les choses sont écrites ici Je pense qu'il est raisonnable d'appeler cette nouvelle matrice, le « produit » des deux matrices originales.",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "Nous pouvons réfléchir à la manière de calculer ce produit de manière plus générale en un instant, mais il est bien trop facile de se perdre dans la forêt des chiffres.",
  "from_community_srt": "Pas vous? Nous allons réfléchir à la façon de calculer ce produit plus généralement dans un instant, mais il est trop facile de se perdre dans ce foisonnement de nombres.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "Rappelez-vous toujours que multiplier deux matrices comme celle-ci a le sens géométrique d’appliquer une transformation puis une autre.",
  "from_community_srt": "Rappelez-vous toujours que les deux matrices multipliées ont la signification géométrique de l'application d'une puis d'une autre transformation.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "Ce qui est un peu bizarre ici, c'est que nous lisons de droite à gauche.",
  "from_community_srt": "Une chose qui est ici un peu bizarre,",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "Vous appliquez d’abord la transformation représentée par la matrice de droite, puis vous appliquez la transformation représentée par la matrice de gauche.",
  "from_community_srt": "est la lecture de droite à gauche; vous appliquez d'abord la transformation représentée par la matrice à droite. Ensuite, vous appliquez la transformation représentée par la matrice sur la gauche.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "Cela vient de la notation des fonctions, puisque nous écrivons les fonctions à gauche des variables, donc chaque fois que vous composez deux fonctions, vous devez toujours les lire de droite à gauche.",
  "from_community_srt": "Cette situation découle de la notation fonctionnelle, puisque nous écrivons des fonctions à gauche de variables, donc chaque fois que vous rédigez deux fonctions, vous lisez de droite à gauche.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "Bonne nouvelle pour les lecteurs hébreux, mauvaise nouvelle pour le reste d’entre nous.",
  "from_community_srt": "Bonne nouvelle pour ceux qui lisent en hébreu, mauvaise nouvelle pour le reste d'entre nous.",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "Regardons un autre exemple.",
  "from_community_srt": "Regardons un autre exemple.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "Prenons la matrice avec les colonnes 1,1 et moins 2,0, dont la transformation ressemble à ceci.",
  "from_community_srt": "Prendre la matrice avec des colonnes (1, 1) et (-2,",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "Et appelons-le M1.",
  "from_community_srt": "0) dont la transformation ressemble à ceci, et nous allons l'appeler M1.",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "Ensuite, prenons la matrice avec les colonnes 0,1 et 2,0, dont la transformation ressemble à ceci.",
  "from_community_srt": "Ensuite, prendre la matrice avec des colonnes (0, 1) et (2,",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "Et appelons ce type M2.",
  "from_community_srt": "0) dont la transformation ressemble à ceci, et que nous appellerons cM2.",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "L'effet total de l'application de M1 puis M2 nous donne une nouvelle transformation, trouvons donc sa matrice.",
  "from_community_srt": "L'effet total de l'application M1 puis M2 nous donne une nouvelle transformation. Donc, nous allons trouver sa matrice.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "Mais cette fois, voyons si nous pouvons le faire sans regarder les animations, et en utilisant simplement les entrées numériques de chaque matrice.",
  "from_community_srt": "Mais cette fois, nous allons voir si nous pouvons le faire sans regarder les animations et utiliser les nombres dans chaque matrice à la place.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "Tout d’abord, nous devons déterminer où va mon chapeau.",
  "from_community_srt": "Première,",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "Après application de M1, les nouvelles coordonnées de i-hat, par définition, sont données par cette première colonne de M1, à savoir 1,1.",
  "from_community_srt": "nous devons savoir où i-chapeau va après l'application de M1, les nouvelles coordonnées d'i-chapeau, par définition, sont donnés par cette première colonne de M1, à savoir,",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "Pour voir ce qui se passe après l'application de M2, multipliez la matrice de M2 par ce vecteur 1,1.",
  "from_community_srt": "(1, 1) pour voir ce qui se passe après l'application M2 multiplier la matrice de M2 ​​par ce vecteur (1,1).",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "En y travaillant, comme je l'ai décrit dans la dernière vidéo, vous obtiendrez le vecteur 2,1.",
  "from_community_srt": "En appliquant, la manière que j'ai décrit dans la dernière vidéo vous obtiendrez le vecteur (2,",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "Ce sera la première colonne de la matrice de composition.",
  "from_community_srt": "1). Ce sera la première colonne de la composition matrice.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "De même, pour suivre j-hat, la deuxième colonne de M1 nous indique qu'elle atterrit d'abord sur moins 2,0.",
  "from_community_srt": "De même, pour suivre j-chapeau, la deuxième colonne de M1 qu'il arrive sur (-2,",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "Ensuite, lorsque nous appliquons M2 à ce vecteur, vous pouvez calculer le produit matrice-vecteur pour obtenir 0, moins 2, qui devient la deuxième colonne de notre matrice de composition.",
  "from_community_srt": "0) puis, quand nous appliquons à ce vecteur M2 nous pouvons obtenir sur le produit matrice-vecteur (0, -2) qui devient la deuxième colonne de notre composition de matrice.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "Permettez-moi de reparler du même processus, mais cette fois, je montrerai les entrées de variables dans chaque matrice, juste pour montrer que le même raisonnement fonctionne pour toutes les matrices.",
  "from_community_srt": "Permettez-moi encore parler de ce même processus, mais cette fois, je vais vous montrer les variables d'entrée dans chaque matrice, juste pour montrer que le même raisonnement fonctionne pour toutes les matrices.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "Ceci est plus lourd en symboles et nécessitera un peu plus d'espace, mais cela devrait être assez satisfaisant pour quiconque a déjà appris la multiplication matricielle de manière plus par cœur.",
  "from_community_srt": "Ceci est plus lourd en symbole et prendra un peu plus de place, mais ça devrait être assez satisfaisant pour ceux qui ont déjà étudié la multiplication de matrices dans une manière un peu plus « écrite».",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "Pour savoir où va i-hat, commencez par regarder la première colonne de la matrice de droite, car c'est là que i-hat atterrit initialement.",
  "from_community_srt": "Pour suivre où i-chapeau i il faut commencer par regarder la première colonne de la matrice à droite, car c'est là i-chapeau atterrit au départ.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "En multipliant cette colonne par la matrice de gauche, vous pouvez savoir où se retrouve la version intermédiaire de i-hat après avoir appliqué la deuxième transformation.",
  "from_community_srt": "En multipliant cette colonne par la matrice sur la gauche, on peut voir la version intermédiaire où termine i-chapeau après l'application de la seconde transformation.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "Ainsi, la première colonne de la matrice de composition sera toujours égale à la matrice de gauche multipliée par la première colonne de la matrice de droite.",
  "from_community_srt": "Ainsi, la première colonne de la matrice composée sera toujours égale à la matrice de gauche fois la première colonne de la matrice de droite.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "De même, j-hat atterrira toujours initialement sur la deuxième colonne de la matrice de droite.",
  "from_community_srt": "De même, j-chapeau attirera toujour au début sur la deuxième colonne de la matrice droite.",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "Donc multiplier la matrice de gauche par cette deuxième colonne donnera son emplacement final, et c'est donc la deuxième colonne de la matrice de composition.",
  "from_community_srt": "Ainsi, la multiplication de la matrice gauche par cette seconde colonne donnera son emplacement final et, par conséquent, c'est la deuxième colonne de la matrice composée.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "Remarquez qu'il y a beaucoup de symboles ici, et il est courant d'apprendre cette formule comme quelque chose à mémoriser, ainsi qu'un certain processus algorithmique pour aider à s'en souvenir.",
  "from_community_srt": "Remarquez qu'il y a beaucoup de symboles ici et il est commun d'enseigner cette formule comme quelque chose à mémoriser et aussi qu'un certain algorithme pour aider à s'en souvenir.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "Mais je pense vraiment qu’avant de mémoriser ce processus, il faut prendre l’habitude de réfléchir à ce que représente réellement la multiplication matricielle, en appliquant une transformation après l’autre.",
  "from_community_srt": "Mais je ne pense vraiment que, qu'avant de mémoriser cet algorithme vous devrez prendre l'habitude de penser à ce que la multiplication de matrices représente vraiment: appliquer une transformation après l'autre.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "Croyez-moi, cela vous donnera un bien meilleur cadre conceptuel qui rendra les propriétés de la multiplication matricielle beaucoup plus faciles à comprendre.",
  "from_community_srt": "Croyez-moi, cela vous donnera un bien meilleur cadre conceptuel qui rend les propriétés de la multiplication matricielle beaucoup plus facilse à comprendre.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "Par exemple, voici une question.",
  "from_community_srt": "Par exemple,",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "L'ordre dans lequel nous mettons les deux matrices lorsque nous les multiplions est-il important ?",
  "from_community_srt": "voici une question: Est-ce que l'ordre dans lequel nous avons multiplier les deux matrices est important ?",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "Eh bien, réfléchissons à un exemple simple, comme celui de plus tôt.",
  "from_community_srt": "Et bien,",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "Prenez une cisaille, qui fixe le i-hat et écrase le j-hat vers la droite, ainsi qu'une rotation de 90 degrés.",
  "from_community_srt": "nous allons réfléchir à travers un exemple simple comme celui du début: Prenez une coupe qui fixe i-chapeau et décalle j-chapeau vers la droite et une rotation de 90 °.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "Si vous effectuez d'abord le cisaillement, puis la rotation, nous pouvons voir que i-hat finit à 0,1 et j-hat finit à moins 1,1.",
  "from_community_srt": "Si vous faites d'abord la coupe puis faites la rotation, nous pouvons voir que i-chapeau arrive à (0, 1) et j-chapeau à (-1,",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "Les deux pointent généralement près l’un de l’autre.",
  "from_community_srt": "1) les deux sont généralement rapprochés.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "Si vous faites d'abord une rotation, puis effectuez le cisaillement, i-hat se termine à 1,1, et j-hat est dans une direction différente à moins 1,0, et ils pointent, vous savez, plus loin l'un de l'autre.",
  "from_community_srt": "Si vous faites la rotation d'abord puis faire la coupe i-chapeau arrive à (1, 1) et j-chapeau dans une direction différente à (-1, 0) et ils sont plus éloignés.",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "L’effet global ici est clairement différent, donc évidemment, l’ordre compte totalement.",
  "from_community_srt": "L'effet global ici est clairement différent donc, évidemment, tout à fait pour ne importe.",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "Remarquez qu'en pensant en termes de transformations, c'est le genre de chose que vous pouvez faire dans votre tête en visualisant.",
  "from_community_srt": "En pensant en termes de transformations c'est le genre de chose que vous pouvez faire votre tête, en visualisant.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "Aucune multiplication matricielle nécessaire.",
  "from_community_srt": "Aucune multiplication matricielle nécessaire.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "Je me souviens que lorsque j'ai commencé à étudier l'algèbre linéaire, il y avait ce problème de devoir qui nous demandait de prouver que la multiplication matricielle est associative.",
  "from_community_srt": "Je me souviens quand j'ai pris algèbre linéaire il y avait un devoir qui nous demandait nous de prouver que la multiplication matricielle est associative.",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "Cela signifie que si vous avez trois matrices, A, B et C, et que vous les multipliez toutes ensemble, cela ne devrait pas avoir d'importance si vous calculez d'abord A par B, puis multipliez le résultat par C, ou si vous multipliez d'abord B par C, puis multipliez ce résultat par A à gauche.",
  "from_community_srt": "Cela signifie que si vous avez trois matrices A, B et C, et vous les multipliez toutes ensemble, il ne devrait pas y avoir d'importance si vous deviez d'abord calculez A fois B puis multiplier le résultat par C, ou si vous deviez d'abord multiplier B par C puis multiplier ce résultat par A sur la gauche.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "En d’autres termes, l’endroit où vous placez les parenthèses n’a pas d’importance.",
  "from_community_srt": "En d'autres termes, peu importe où vous mettez les parenthèses.",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "Maintenant, si vous essayez de résoudre ce problème numériquement, comme je l'ai fait à l'époque, c'est horrible, tout simplement horrible, et d'ailleurs peu instructif.",
  "from_community_srt": "Maintenant, si vous essayez de travailler numériquement comme je l'ai fait à l'époque, c'est horrible, tout simplement horrible, et incompréhensible d'ailleurs.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "Mais quand on considère la multiplication matricielle comme l’application d’une transformation après l’autre, cette propriété est tout simplement triviale.",
  "from_community_srt": "Mais quand vous pensez à la multiplication de matrices l'une après l'autre en appliquant une transformation, cette propriété est tout simplement triviale.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "Voyez-vous pourquoi ?",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "Ce que cela veut dire, c'est que si vous appliquez d'abord C, puis B, puis A, cela revient à appliquer C, puis B, puis A.",
  "from_community_srt": "Pouvez-vous voir pourquoi? Ce que ça dit est que si vous appliquez d'abord C puis B, puis A, est la même chose que C, puis B puis A.",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "Je veux dire, il n'y a rien à prouver.",
  "from_community_srt": "Je veux dire,",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "Vous appliquez simplement les trois mêmes choses l’une après l’autre, toutes dans le même ordre.",
  "from_community_srt": "il n'y a rien à prouver, vous êtes juste d'appliquer les mêmes trois choses l'une après l'autre,",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "Cela peut ressembler à de la triche, mais ce n'est pas le cas.",
  "from_community_srt": "toutes dans le même ordre. Ca pourrait se sentir comme de la tricherie.",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "C'est une preuve honnête que la multiplication matricielle est associative, et mieux encore, c'est une bonne explication de la raison pour laquelle cette propriété devrait être vraie.",
  "from_community_srt": "Mais ça n'en est pas! Ceci est preuve honnête que la multiplication est associative, et même mieux que cela, une bonne explication de pourquoi cette propriété devrait être vraie.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "Je vous encourage vraiment à jouer davantage avec cette idée, en imaginant deux transformations différentes, en réfléchissant à ce qui se passe lorsque vous les appliquez l'une après l'autre, puis en élaborant numériquement le produit matriciel.",
  "from_community_srt": "Je vous encourage vraiment à jouer plus avec cette idée en imaginant deux transformations différentes pensez à ce qui se passe lorsque vous appliquez l'une après l'autre puis obtenez le produit matricielle par le calcul.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "Croyez-moi, c'est le genre de récréation qui fait vraiment pénétrer l'idée.",
  "from_community_srt": "Croyez-moi, c'est ce de jeu que fait vraiment entrer d'idée dans vos têtes.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "Dans la prochaine vidéo, je commencerai à parler de l'extension de ces idées au-delà de deux dimensions.",
  "from_community_srt": "Dans la vidéo suivante, je vais commencer à parler l'extension de ces idées au-delà de deux dimensions seulement.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]