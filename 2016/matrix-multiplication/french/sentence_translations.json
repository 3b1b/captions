[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "Salut tout le monde, là où nous nous sommes arrêtés, j'ai montré à quoi ressemblent les transformations linéaires et comment les représenter à l'aide de matrices.",
  "n_reviews": 0
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "Cela mérite un bref récapitulatif car c'est vraiment important, mais bien sûr, si cela vous semble plus qu'un simple récapitulatif, revenez en arrière et regardez la vidéo complète.",
  "n_reviews": 0
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "Techniquement parlant, les transformations linéaires sont des fonctions avec des vecteurs comme entrées et des vecteurs comme sorties, mais j'ai montré la dernière fois comment nous pouvons les considérer visuellement comme se déplaçant dans l'espace de telle manière que les lignes de la grille restent parallèles et régulièrement espacées, et de sorte que l'origine reste fixe.",
  "n_reviews": 0
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "L’essentiel à retenir est qu’une transformation linéaire est entièrement déterminée par l’endroit où elle prend les vecteurs de base de l’espace, ce qui, pour deux dimensions, signifie i-hat et j-hat.",
  "n_reviews": 0
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "En effet, tout autre vecteur pourrait être décrit comme une combinaison linéaire de ces vecteurs de base.",
  "n_reviews": 0
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "Un vecteur de coordonnées x, y est x fois i-hat plus y fois j-hat.",
  "n_reviews": 0
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "Après la transformation, cette propriété selon laquelle les lignes du quadrillage restent parallèles et régulièrement espacées a une conséquence merveilleuse.",
  "n_reviews": 0
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "L'endroit où votre vecteur atterrit sera x fois la version transformée de i-hat plus y fois la version transformée de j-hat.",
  "n_reviews": 0
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "Cela signifie que si vous conservez une trace des coordonnées où atterrit i-hat et des coordonnées où atterrit j-hat, vous pouvez calculer qu'un vecteur qui commence à x, y doit atterrir sur x fois les nouvelles coordonnées de i-hat plus y. fois les nouvelles coordonnées de j-hat.",
  "n_reviews": 0
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "La convention est d'enregistrer les coordonnées de l'endroit où i-hat et j-hat atterrissent comme colonnes d'une matrice, et de définir cette somme des versions mises à l'échelle de ces colonnes par x et y comme étant une multiplication matrice-vecteur.",
  "n_reviews": 0
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "De cette façon, une matrice représente une transformation linéaire spécifique, et multiplier une matrice par un vecteur est ce que signifie informatiquement appliquer cette transformation à ce vecteur.",
  "n_reviews": 0
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "Très bien, récapitulons, passons aux nouveautés.",
  "n_reviews": 0
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "Souvent, vous avez envie de décrire les effets de l’application d’une transformation, puis d’une autre.",
  "n_reviews": 0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "Par exemple, vous souhaitez peut-être décrire ce qui se passe lorsque vous faites d'abord pivoter le plan de 90 degrés dans le sens inverse des aiguilles d'une montre, puis que vous appliquez une cisaille.",
  "n_reviews": 0
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "L'effet global ici, du début à la fin, est une autre transformation linéaire, distincte de la rotation et du cisaillement.",
  "n_reviews": 0
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "Cette nouvelle transformation linéaire est communément appelée la composition des deux transformations distinctes que nous avons appliquées.",
  "n_reviews": 0
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "Et comme toute transformation linéaire, elle peut être décrite avec une matrice qui lui est propre en suivant i-hat et j-hat.",
  "n_reviews": 0
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "Dans cet exemple, le point d'atterrissage ultime pour i-hat après les deux transformations est 1,1, faisons donc de cela la première colonne d'une matrice.",
  "n_reviews": 0
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "De même, j-hat se retrouve finalement à l'emplacement moins 1,0, nous en faisons donc la deuxième colonne de la matrice.",
  "n_reviews": 0
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "Cette nouvelle matrice capture l'effet global de l'application d'une rotation puis d'un cisaillement, mais comme une seule action, plutôt que deux actions successives.",
  "n_reviews": 0
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "Voici une façon de penser à cette nouvelle matrice.",
  "n_reviews": 0
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "Si vous deviez prendre un vecteur et le pomper à travers la rotation, puis le cisaillement, le long chemin pour calculer où il aboutit est de le multiplier d'abord à gauche par la matrice de rotation, puis de prendre ce que vous obtenez et de le multiplier sur le laissé par la matrice de cisaillement.",
  "n_reviews": 0
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "C'est, numériquement parlant, ce que signifie appliquer une rotation puis un cisaillement à un vecteur donné.",
  "n_reviews": 0
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "Mais tout ce que vous obtenez devrait être la même chose que d'appliquer simplement cette nouvelle matrice de composition que nous venons de trouver par ce même vecteur, quel que soit le vecteur que vous avez choisi, puisque cette nouvelle matrice est censée capturer le même effet global que la rotation puis l'action de cisaillement.",
  "n_reviews": 0
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "D'après la façon dont les choses sont écrites ici, je pense qu'il est raisonnable d'appeler cette nouvelle matrice le produit des deux matrices originales, n'est-ce pas ?",
  "n_reviews": 0
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "Nous pouvons réfléchir à la manière de calculer ce produit de manière plus générale en un instant, mais il est bien trop facile de se perdre dans la forêt des chiffres.",
  "n_reviews": 0
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "Rappelez-vous toujours que multiplier deux matrices comme celle-ci a le sens géométrique d’appliquer une transformation puis une autre.",
  "n_reviews": 0
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "Ce qui est un peu bizarre ici, c'est que nous lisons de droite à gauche.",
  "n_reviews": 0
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "Vous appliquez d’abord la transformation représentée par la matrice de droite, puis vous appliquez la transformation représentée par la matrice de gauche.",
  "n_reviews": 0
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "Cela vient de la notation des fonctions, puisque nous écrivons les fonctions à gauche des variables, donc chaque fois que vous composez deux fonctions, vous devez toujours les lire de droite à gauche.",
  "n_reviews": 0
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "Bonne nouvelle pour les lecteurs hébreux, mauvaise nouvelle pour le reste d’entre nous.",
  "n_reviews": 0
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "Regardons un autre exemple.",
  "n_reviews": 0
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "Prenons la matrice avec les colonnes 1,1 et moins 2,0, dont la transformation ressemble à ceci.",
  "n_reviews": 0
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "Et appelons-le M1.",
  "n_reviews": 0
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "Ensuite, prenons la matrice avec les colonnes 0,1 et 2,0, dont la transformation ressemble à ceci.",
  "n_reviews": 0
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "Et appelons ce type M2.",
  "n_reviews": 0
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "L'effet total de l'application de M1 puis M2 nous donne une nouvelle transformation, trouvons donc sa matrice.",
  "n_reviews": 0
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "Mais cette fois, voyons si nous pouvons le faire sans regarder les animations, et en utilisant simplement les entrées numériques de chaque matrice.",
  "n_reviews": 0
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "Tout d’abord, nous devons déterminer où va mon chapeau.",
  "n_reviews": 0
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "Après application de M1, les nouvelles coordonnées de i-hat, par définition, sont données par cette première colonne de M1, à savoir 1,1.",
  "n_reviews": 0
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "Pour voir ce qui se passe après l'application de M2, multipliez la matrice de M2 par ce vecteur 1,1.",
  "n_reviews": 0
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "En y travaillant, comme je l'ai décrit dans la dernière vidéo, vous obtiendrez le vecteur 2,1.",
  "n_reviews": 0
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "Ce sera la première colonne de la matrice de composition.",
  "n_reviews": 0
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "De même, pour suivre j-hat, la deuxième colonne de M1 nous indique qu'elle atterrit d'abord sur moins 2,0.",
  "n_reviews": 0
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "Ensuite, lorsque nous appliquons M2 à ce vecteur, vous pouvez calculer le produit matrice-vecteur pour obtenir 0, moins 2, qui devient la deuxième colonne de notre matrice de composition.",
  "n_reviews": 0
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "Permettez-moi de reparler du même processus, mais cette fois, je montrerai les entrées de variables dans chaque matrice, juste pour montrer que le même raisonnement fonctionne pour toutes les matrices.",
  "n_reviews": 0
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "Ceci est plus lourd en symboles et nécessitera un peu plus d'espace, mais cela devrait être assez satisfaisant pour quiconque a déjà appris la multiplication matricielle de manière plus par cœur.",
  "n_reviews": 0
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "Pour savoir où va i-hat, commencez par regarder la première colonne de la matrice de droite, car c'est là que i-hat atterrit initialement.",
  "n_reviews": 0
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "En multipliant cette colonne par la matrice de gauche, vous pouvez savoir où se retrouve la version intermédiaire de i-hat après avoir appliqué la deuxième transformation.",
  "n_reviews": 0
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "Ainsi, la première colonne de la matrice de composition sera toujours égale à la matrice de gauche multipliée par la première colonne de la matrice de droite.",
  "n_reviews": 0
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "De même, j-hat atterrira toujours initialement sur la deuxième colonne de la matrice de droite.",
  "n_reviews": 0
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "Donc multiplier la matrice de gauche par cette deuxième colonne donnera son emplacement final, et c'est donc la deuxième colonne de la matrice de composition.",
  "n_reviews": 0
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "Remarquez qu'il y a beaucoup de symboles ici, et il est courant d'apprendre cette formule comme quelque chose à mémoriser, ainsi qu'un certain processus algorithmique pour aider à s'en souvenir.",
  "n_reviews": 0
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "Mais je pense vraiment qu’avant de mémoriser ce processus, il faut prendre l’habitude de réfléchir à ce que représente réellement la multiplication matricielle, en appliquant une transformation après l’autre.",
  "n_reviews": 0
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "Croyez-moi, cela vous donnera un bien meilleur cadre conceptuel qui rendra les propriétés de la multiplication matricielle beaucoup plus faciles à comprendre.",
  "n_reviews": 0
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "Par exemple, voici une question.",
  "n_reviews": 0
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "L'ordre dans lequel nous mettons les deux matrices lorsque nous les multiplions est-il important ?",
  "n_reviews": 0
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "Eh bien, réfléchissons à un exemple simple, comme celui de plus tôt.",
  "n_reviews": 0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "Prenez une cisaille, qui fixe le i-hat et écrase le j-hat vers la droite, ainsi qu'une rotation de 90 degrés.",
  "n_reviews": 0
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "Si vous effectuez d'abord le cisaillement, puis la rotation, nous pouvons voir que i-hat finit à 0,1 et j-hat finit à moins 1,1.",
  "n_reviews": 0
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "Les deux pointent généralement près l’un de l’autre.",
  "n_reviews": 0
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "Si vous faites d'abord une rotation, puis effectuez le cisaillement, i-hat se termine à 1,1, et j-hat est dans une direction différente à moins 1,0, et ils pointent, vous savez, plus loin l'un de l'autre.",
  "n_reviews": 0
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "L’effet global ici est clairement différent, donc évidemment, l’ordre compte totalement.",
  "n_reviews": 0
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "Remarquez qu'en pensant en termes de transformations, c'est le genre de chose que vous pouvez faire dans votre tête en visualisant.",
  "n_reviews": 0
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "Aucune multiplication matricielle nécessaire.",
  "n_reviews": 0
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "Je me souviens que lorsque j'ai commencé à étudier l'algèbre linéaire, il y avait ce problème de devoir qui nous demandait de prouver que la multiplication matricielle est associative.",
  "n_reviews": 0
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "Cela signifie que si vous avez trois matrices, A, B et C, et que vous les multipliez toutes ensemble, cela ne devrait pas avoir d'importance si vous calculez d'abord A par B, puis multipliez le résultat par C, ou si vous multipliez d'abord B par C, puis multipliez ce résultat par A à gauche.",
  "n_reviews": 0
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "En d’autres termes, l’endroit où vous placez les parenthèses n’a pas d’importance.",
  "n_reviews": 0
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "Maintenant, si vous essayez de résoudre ce problème numériquement, comme je l'ai fait à l'époque, c'est horrible, tout simplement horrible, et d'ailleurs peu instructif.",
  "n_reviews": 0
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "Mais quand on considère la multiplication matricielle comme l’application d’une transformation après l’autre, cette propriété est tout simplement triviale.",
  "n_reviews": 0
 },
 {
  "input": "Can you see why?",
  "translatedText": "Voyez-vous pourquoi ?",
  "n_reviews": 0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "Ce que cela veut dire, c'est que si vous appliquez d'abord C, puis B, puis A, cela revient à appliquer C, puis B, puis A.",
  "n_reviews": 0
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "Je veux dire, il n'y a rien à prouver.",
  "n_reviews": 0
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "Vous appliquez simplement les trois mêmes choses l’une après l’autre, toutes dans le même ordre.",
  "n_reviews": 0
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "Cela peut ressembler à de la triche, mais ce n'est pas le cas.",
  "n_reviews": 0
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "C'est une preuve honnête que la multiplication matricielle est associative, et mieux encore, c'est une bonne explication de la raison pour laquelle cette propriété devrait être vraie.",
  "n_reviews": 0
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "Je vous encourage vraiment à jouer davantage avec cette idée, en imaginant deux transformations différentes, en réfléchissant à ce qui se passe lorsque vous les appliquez l'une après l'autre, puis en élaborant numériquement le produit matriciel.",
  "n_reviews": 0
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "Croyez-moi, c'est le genre de récréation qui fait vraiment pénétrer l'idée.",
  "n_reviews": 0
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "Dans la prochaine vidéo, je commencerai à parler de l'extension de ces idées au-delà de deux dimensions.",
  "n_reviews": 0
 }
]