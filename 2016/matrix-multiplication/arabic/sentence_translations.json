[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "مرحبًا جميعًا، حيث توقفنا مؤخرًا، أوضحت كيف تبدو التحويلات الخطية وكيفية تمثيلها باستخدام المصفوفات.",
  "model": "google_nmt",
  "from_community_srt": "ومن تجربتي أن الأدلة التي تنطوي على المصفوفات يمكن تقصيصها بنسبة 50٪ إذا ألقى أحد المصفوفات. - اميل ارتين مرحبا جميعا! حيث غادرنا آخر مرة ، أظهر لي ما الخطية تبدو التحولات وكيفية تمثيلهم باستخدام المصفوفات.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "يستحق هذا تلخيصًا سريعًا لأنه مهم جدًا، ولكن بالطبع إذا كان هذا يبدو أكثر من مجرد تلخيص، فارجع وشاهد الفيديو كاملاً.",
  "model": "google_nmt",
  "from_community_srt": "هذا يستحق وصف سريع ، لأنه فقط مهم حقا. ولكن بالطبع ، إذا كان هذا يبدو وكأنه أكثر من مجرد ملخص ، والعودة ومشاهدة الفيديو الكامل.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "من الناحية الفنية، التحويلات الخطية هي دوال ذات متجهات كمدخلات ومتجهات كمخرجات، لكنني أوضحت في المرة الأخيرة كيف يمكننا التفكير فيها بصريًا باعتبارها تنعم حول الفضاء بطريقة تجعل خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ، وبالتالي فإن الأصل يبقى ثابتا.",
  "model": "google_nmt",
  "from_community_srt": "من الناحية الفنية ، التحولات الخطية هي وظائف ، مع المتجهات كمدخلات وناقلات كمخرجات. لكني أظهرت في المرة الأخيرة كيف يمكننا التفكير لهم بصريا كما smooshing حول الفضاء بطريقة مثل خطوط الشبكة ابقوا متوازيين ومتساويين ، وبقي الأصل ثابتًا.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "كانت الفكرة الرئيسية هي أن التحول الخطي يتم تحديده بالكامل من خلال المكان الذي يأخذ فيه المتجهات الأساسية للفضاء، والتي تعني بعدين i-hat وj-hat.",
  "model": "google_nmt",
  "from_community_srt": "المفتاح الرئيسي هو ذلك يتم تحديد التحول الخطي بالكامل ، من حيث يأخذ المتجهات أساس الفضاء والتي ، بالنسبة إلى البعدين ، تعني i-hat و ي-قبعة.",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "وذلك لأن أي متجه آخر يمكن وصفه بأنه مزيج خطي من تلك المتجهات الأساسية.",
  "model": "google_nmt",
  "from_community_srt": "هذا لأنه يمكن وصف أي متجه آخر كمزيج خطي لتلك المتجهات الأساسية.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "المتجه ذو الإحداثيات x، y هو x مضروبًا في i-hat بالإضافة إلى y مضروبًا في j-hat.",
  "model": "google_nmt",
  "from_community_srt": "متجه مع الإحداثيات (س ، ص) هو x مرات i-hat + y times j-hat.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "بعد إجراء عملية التحويل، فإن خاصية بقاء خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ لها نتيجة رائعة.",
  "model": "google_nmt",
  "from_community_srt": "بعد المرور بالتحول هذه الخاصية ، لا تزال خطوط الشبكة متوازية ومتباعد بشكل متساوٍ ، لديه نتيجة رائعة.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "المكان الذي يهبط فيه المتجه الخاص بك سيكون x مضروبًا في النسخة المحولة من i-hat بالإضافة إلى y مضروبًا في النسخة المحولة من j-hat.",
  "model": "google_nmt",
  "from_community_srt": "المكان الذي ستكون فيه أراضي المتجهات الخاصة بك x أضعاف النسخة المحولة من i-hat + y أضعاف النسخة المحولة من j-hat.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "هذا يعني أنه إذا احتفظت بسجل للإحداثيات حيث يهبط i-hat والإحداثيات حيث يهبط j-hat، يمكنك حساب أن المتجه الذي يبدأ عند x، y يجب أن يهبط على x مضروبًا في الإحداثيات الجديدة لـ i-hat زائد y ضرب الإحداثيات الجديدة لـ j-hat.",
  "model": "google_nmt",
  "from_community_srt": "وهذا يعني أنك إذا احتفظت بسجل للإحداثيات حيث الأراضي آي قبعة والإحداثيات التي توجد فيها j-hat يمكنك حساب ذلك المتجه الذي يبدأ في (س ، ص) ، يجب أن تهبط على x مرات الإحداثيات الجديدة من أنا قبعة + y مرات الإحداثيات الجديدة من j-hat.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "تتمثل الاتفاقية في تسجيل إحداثيات المكان الذي تهبط فيه i-hat وj-hat كأعمدة مصفوفة، وتحديد مجموع الإصدارات المقاسة لتلك الأعمدة بواسطة x وy ليكون ضربًا لمصفوفة ومتجه.",
  "model": "google_nmt",
  "from_community_srt": "الاتفاقية هي لتسجيل الإحداثيات من حيث i-hat و j-hat land كأعمدة من المصفوفة ولتحديد هذا المجموع للإصدارات المقاسة من تلك الأعمدة بواسطة س و ص ليكون مضاعفا متجه المضاهاة.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "بهذه الطريقة، تمثل المصفوفة تحويلاً خطيًا محددًا، وضرب المصفوفة في المتجه هو ما يعنيه حسابيًا تطبيق هذا التحويل على ذلك المتجه.",
  "model": "google_nmt",
  "from_community_srt": "في هذا الطريق، تمثل المصفوفة تحول خطي محدد وضرب مصفوفة من قبل ناقل ، هو ما هذا يعني حسابيا ، لتطبيق هذا التحول على هذا المتجه.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "حسنًا، لنلخص الأمر إلى الأشياء الجديدة.",
  "model": "google_nmt",
  "from_community_srt": "حسنا ، تلخيص. على الاشياء الجديدة.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "في كثير من الأحيان، تجد نفسك ترغب في وصف تأثيرات تطبيق تحويل واحد ثم آخر.",
  "model": "google_nmt",
  "from_community_srt": "في كثير من الأحيان تجد نفسك تريد أن تصف التأثير لتطبيق تحويل واحد ثم آخر.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "على سبيل المثال، ربما تريد وصف ما يحدث عند تدوير المستوى لأول مرة بمقدار 90 درجة عكس اتجاه عقارب الساعة، ثم تطبيق القص.",
  "model": "google_nmt",
  "from_community_srt": "فمثلا، ربما تريد أن تصف ما يحدث عندما قمت بتدوير الطائرة 90 درجة عكس عقارب الساعة ثم تطبيق القص.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "التأثير الإجمالي هنا، من البداية إلى النهاية، هو تحول خطي آخر، يختلف عن الدوران والقص.",
  "model": "google_nmt",
  "from_community_srt": "التأثير الكلي هنا ، من البداية إلى النهاية ، هو تحول خطي آخر ، متميزة عن الدوران والشفاف.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "يُطلق على هذا التحويل الخطي الجديد عادةً تركيبة التحويلين المنفصلين اللذين طبقناهما.",
  "model": "google_nmt",
  "from_community_srt": "هذا التحول الخطي الجديد يطلق عليه \"التركيب\" من التحولات المنفصلة التي قمنا بتطبيقها.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "ومثل أي تحويل خطي، يمكن وصفه بمصفوفة خاصة به باتباع i-hat وj-hat.",
  "model": "google_nmt",
  "from_community_srt": "ومثل أي تحول خطي يمكن وصفها مع مصفوفة كل من لها من خلال اتباع i-hat و j-hat.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "في هذا المثال، نقطة الهبوط النهائية لـ i-hat بعد كلا التحويلتين هي 1,1، لذلك دعونا نجعل ذلك العمود الأول من المصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "في هذا المثال ، مكان الهبوط النهائي ل i-hat بعد كل من التحولات هو (1 ، 1). لذلك دعونا نجعل هذا العمود الأول من مصفوفة.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "وبالمثل، ينتهي j-hat في النهاية عند الموقع سالب 1,0، لذلك نجعله العمود الثاني من المصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "وبالمثل ، فإن j-hat ينتهي في نهاية المطاف في الموقع (-1 ، 0) ، حتى نجعل هذا العمود الثاني من المصفوفة.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "تلتقط هذه المصفوفة الجديدة التأثير الإجمالي لتطبيق التدوير ثم القص، ولكن كإجراء واحد، بدلاً من إجراءين متتاليين.",
  "model": "google_nmt",
  "from_community_srt": "هذه المصفوفة الجديدة تلتقط التأثير الكلي من تطبيق التناوب ثم مجرد محض ولكن كعمل واحد ، بدلا من اثنين متتالية.",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "إليك إحدى الطرق للتفكير في تلك المصفوفة الجديدة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "إذا كنت ستأخذ بعض المتجهات وتضخها خلال الدوران، فإن القص، الطريق الطويل لحساب أين ينتهي به الأمر هو ضربه أولاً على اليسار في مصفوفة الدوران، ثم خذ كل ما تحصل عليه واضربه في اليسار بواسطة مصفوفة القص.",
  "model": "google_nmt",
  "from_community_srt": "إليك طريقة واحدة للتفكير في ذلك المصفوفة الجديدة: إذا كنت تأخذ بعض المتجهات وضخها من خلال التناوب ثم الهائل الطريق الطويل لحساب حيث ينتهي هو ، أولا ، اضربها على اليسار من قبل مصفوفة الدوران ثم تأخذ كل ما تحصل عليه وتضاعف ذلك على اليسار من المصفوفة المطلقة.",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "هذا، من الناحية العددية، هو ما يعنيه تطبيق التدوير ثم القص على متجه معين.",
  "model": "google_nmt",
  "from_community_srt": "هذا هو ، من الناحية العددية ، ما يعنيه تطبيق التناوب ثم مجرد محض إلى متجه معين.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "لكن كل ما ستحصل عليه يجب أن يكون هو نفسه مجرد تطبيق مصفوفة التركيب الجديدة هذه التي وجدناها للتو بواسطة نفس المتجه، بغض النظر عن المتجه الذي اخترته، حيث من المفترض أن تلتقط هذه المصفوفة الجديدة نفس التأثير الإجمالي مثل إجراء التدوير ثم القص.",
  "model": "google_nmt",
  "from_community_srt": "ولكن ، ما تحصل عليه يجب أن يكون هو نفسه فقط تطبيق هذه المصفوفة تكوين جديد التي وجدناها للتو هذا المتجه نفسه ، بغض النظر عن المتجه الذي اخترته ، لأن من المفترض أن تلتقط هذه المصفوفة الجديدة نفس التأثير الكلي كعمل دوران ثم مجرد.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "بناءً على كيفية كتابة الأشياء هنا، أعتقد أنه من المعقول أن نطلق على هذه المصفوفة الجديدة حاصل ضرب المصفوفتين الأصليتين، أليس كذلك؟",
  "model": "google_nmt",
  "from_community_srt": "على أساس كيفية كتابة الأشياء هنا أعتقد أنه من المنطقي تسمية هذه المصفوفة الجديدة ، \"المنتج\" للمصفوفتين الأصليتين. أنت ,",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "يمكننا التفكير في كيفية حساب هذا الناتج بشكل عام في لحظة واحدة فقط، ولكن من السهل جدًا أن تضيع في غابة الأرقام.",
  "model": "google_nmt",
  "from_community_srt": "لا؟ يمكننا التفكير في كيفية حساب هذا المنتج بشكل عام في لحظة ، ولكن من السهل للغاية أن تضيع في الغابة من الأرقام.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "تذكر دائمًا أن ضرب مصفوفتين بهذا الشكل له المعنى الهندسي لتطبيق تحويل تلو الآخر.",
  "model": "google_nmt",
  "from_community_srt": "تذكر دائما ، وضرب المصفوفات اثنين مثله لديه المعنى الهندسي لتطبيق واحد التحول ثم آخر.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "الشيء الوحيد الغريب هنا هو أن هذا يجعلنا نقرأ من اليمين إلى اليسار.",
  "model": "google_nmt",
  "from_community_srt": "شيء واحد هذا غريب غريب هنا ، هو ذلك هذا له قراءة من اليمين إلى اليسار.",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "عليك أولاً تطبيق التحويل الذي تمثله المصفوفة الموجودة على اليمين، ثم تطبيق التحويل الذي تمثله المصفوفة الموجودة على اليسار.",
  "model": "google_nmt",
  "from_community_srt": "عليك أولا تطبيق التحول ممثلة من المصفوفة على اليمين. ثم قمت بتطبيق التحول ممثلة من المصفوفة على اليسار.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "ينبع هذا من تدوين الدالة، نظرًا لأننا نكتب الدوال على يسار المتغيرات، لذلك في كل مرة تقوم فيها بتأليف دالتين، عليك دائمًا قراءتها من اليمين إلى اليسار.",
  "model": "google_nmt",
  "from_community_srt": "هذا ينبع من تدوين وظيفي ، بما أننا نكتب الوظائف على يسار المتغيرات ، لذلك في كل مرة تقوم بتأليف وظيفتين ، أنت يجب أن تقرأه من اليمين إلى اليسار.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "أخبار جيدة لقراء اللغة العبرية، وأخبار سيئة لبقيتنا.",
  "model": "google_nmt",
  "from_community_srt": "خبر سار للقراء العبرية ، أخبار سيئة وبالنسبة للبقية منا.",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "دعونا ننظر إلى مثال آخر.",
  "model": "google_nmt",
  "from_community_srt": "دعونا ننظر في مثال آخر.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "خذ المصفوفة ذات الأعمدة 1،1 وسالب 2،0، والتي يبدو تحويلها هكذا.",
  "model": "google_nmt",
  "from_community_srt": "خذ المصفوفة مع الأعمدة (1 ، 1) و (-2 ، 0) الذي يشبه هذا التحول ، ودعنا نسميها M1.",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "ودعونا نسميها M1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "بعد ذلك، خذ المصفوفة ذات الأعمدة 0،1 و2،0، والتي يبدو تحويلها هكذا.",
  "model": "google_nmt",
  "from_community_srt": "بعد ذلك ، خذ المصفوفة مع الأعمدة (0 ، 1) و (2 ، 0) الذي يشبه هذا التحول ، ودعنا ندعو هذا الرجل M2.",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "ودعنا نسمي ذلك الرجل M2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "التأثير الكلي لتطبيق M1 ثم M2 يعطينا تحويلا جديدا، لذلك دعونا نجد مصفوفتها.",
  "model": "google_nmt",
  "from_community_srt": "الأثر الكلي لتطبيق M1 ثم M2 يعطينا تحول جديد. لذلك دعونا العثور على المصفوفة.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "لكن هذه المرة، دعونا نرى ما إذا كان بإمكاننا القيام بذلك دون مشاهدة الرسوم المتحركة، وبدلاً من ذلك فقط استخدام الإدخالات الرقمية في كل مصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "لكن هذه المرة ، دعونا نرى ما إذا كان بإمكاننا القيام بذلك من دونه مشاهدة الرسوم المتحركة وبدلاً من ذلك ، فقط باستخدام الإدخالات الرقمية في كل مصفوفة.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "أولاً، علينا أن نعرف أين تذهب القبعة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "بعد تطبيق M1، يتم إعطاء الإحداثيات الجديدة لـ i-hat، بحكم التعريف، من خلال العمود الأول من M1، أي 1،1.",
  "model": "google_nmt",
  "from_community_srt": "أولاً ، نحتاج إلى معرفة أين تذهب i-hat بعد تطبيق M1 الإحداثيات الجديدة من آي قبعة ، بالتعريف ، يتم تقديمها بواسطة هذا العمود الأول من M1 ،",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "لمعرفة ما يحدث بعد تطبيق M2، اضرب مصفوفة M2 بهذا المتجه 1,1.",
  "model": "google_nmt",
  "from_community_srt": "أي ، (1 ، 1) لمعرفة ما يحدث بعد تطبيق M2 ضرب المصفوفة ل M2 من قبل هذا المتجه (1،1).",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "عند حل هذه المشكلة، بالطريقة التي وصفتها في الفيديو الأخير، ستحصل على المتجه 2،1.",
  "model": "google_nmt",
  "from_community_srt": "العمل بها ، بالطريقة التي وصفتها الماضي فيديو ستحصل على المتجه (2 ، 1).",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "سيكون هذا هو العمود الأول من مصفوفة التكوين.",
  "model": "google_nmt",
  "from_community_srt": "سيكون هذا العمود الأول من التكوين مصفوفة.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "وبالمثل، لمتابعة j-hat، يخبرنا العمود الثاني من M1 أنه وصل أولاً إلى سالب 2,0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "بعد ذلك، عندما نطبق M2 على هذا المتجه، يمكنك إيجاد حاصل ضرب المصفوفة والمتجه للحصول على 0، سالب 2، الذي يصبح العمود الثاني من مصفوفة التركيب.",
  "model": "google_nmt",
  "from_community_srt": "وبالمثل ، لمتابعة j-hat العمود الثاني من M1 يخبرنا الأول الأراضي على (-2 ، 0) ثم ، عندما نطبق M2 إلى ذلك المتجه يمكنك العمل على المنتج مصفوفة متجه للحصول على (0 ، -2) الذي يصبح العمود الثاني من تكويننا مصفوفة.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "اسمحوا لي أن أتحدث عن نفس العملية مرة أخرى، ولكن هذه المرة سأعرض إدخالات متغيرة في كل مصفوفة، فقط لإظهار أن نفس المنطق يعمل مع أي مصفوفات.",
  "model": "google_nmt",
  "from_community_srt": "اسمحوا لي أن أتحدث إلى نفس العملية مرة أخرى ، ولكن هذا الوقت، سوف أعرض إدخالات متغيرة في كل مصفوفة ، فقط لإظهار أن نفس الخط من التفكير يعمل لأي مصفوفات.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "هذا أكثر ثقلًا بالرموز وسيتطلب مساحة أكبر، لكنه يجب أن يكون مُرضيًا جدًا لأي شخص سبق له أن تعلم ضرب المصفوفات بطريقة أكثر روتينية.",
  "model": "google_nmt",
  "from_community_srt": "هذا هو رمز أكثر ثقلا وسوف يتطلب ذلك بعض الغرف الأخرى لكن يجب أن يكون مرضياً جداً لأي شخص الذي سبق أن تعلم تكاثر المصفوفة طريقة أكثر روتينية.",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "لمتابعة اتجاه i-hat، ابدأ بالنظر إلى العمود الأول من المصفوفة على اليمين، حيث أن هذا هو المكان الذي يهبط فيه i-hat في البداية.",
  "model": "google_nmt",
  "from_community_srt": "لمتابعة أين يذهب أي قبعة تبدأ من خلال النظر في العمود الأول من مصفوفة على اليمين ، لأن هذا هو المكان الذي أضع فيه قبعة I-hat في البداية.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "إن ضرب هذا العمود بالمصفوفة الموجودة على اليسار هو الطريقة التي يمكنك من خلالها معرفة أين تنتهي النسخة المتوسطة من i-hat بعد تطبيق التحويل الثاني.",
  "model": "google_nmt",
  "from_community_srt": "ضرب هذا العمود عن طريق المصفوفة على اليسار، كيف يمكنك معرفة المكان المتوسط إصدار i-hat ينتهي بعد التطبيق التحول الثاني.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "وبالتالي فإن العمود الأول من مصفوفة التركيب يساوي دائمًا المصفوفة اليسرى مضروبة في العمود الأول من المصفوفة اليمنى.",
  "model": "google_nmt",
  "from_community_srt": "لذا ، فإن العمود الأول من مصفوفة تكوينها سوف يساوي دائما المصفوفة اليسرى مرات العمود الأول من المصفوفة الصحيحة.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "وبالمثل، فإن j-hat ستهبط دائمًا في العمود الثاني من المصفوفة اليمنى.",
  "model": "google_nmt",
  "from_community_srt": "وبالمثل ، فإن j-hat سوف تهبط دائمًا في البداية في العمود الثاني من المصفوفة الصحيحة.",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "لذا فإن ضرب المصفوفة اليسرى في هذا العمود الثاني سيعطي موقعها النهائي، وبالتالي هذا هو العمود الثاني من مصفوفة التركيب.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ضرب المصفوفة اليسرى من هذا ثانية العمود سيعطي موقعه النهائي وبالتالي ، هذا هو العمود الثاني في مصفوفة التكوين.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "لاحظ أن هناك الكثير من الرموز هنا، ومن الشائع أن يتم تعليم هذه الصيغة كشيء يجب حفظه، إلى جانب عملية خوارزمية معينة للمساعدة في تذكرها.",
  "model": "google_nmt",
  "from_community_srt": "لاحظ ، هناك الكثير من الرموز هنا ومن الشائع أن يتم تدريس هذه الصيغة كشيء لحفظه جنبا إلى جنب مع عملية خوارزمية معينة ل نوع من المساعدة تذكر ذلك.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "لكنني أعتقد حقًا أنه قبل حفظ هذه العملية، يجب أن تعتاد على التفكير في ما يمثله ضرب المصفوفات حقًا، وتطبيق تحويل تلو الآخر.",
  "model": "google_nmt",
  "from_community_srt": "لكنني حقا أعتقد أنه قبل الحفظ هذه العملية يجب أن تتعود على التفكير ما يمثل مضاعفة المصفوفة حقا: تطبيق تحول واحد تلو الآخر.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "ثق بي، سيعطيك هذا إطارًا مفاهيميًا أفضل بكثير مما يجعل فهم خصائص ضرب المصفوفات أسهل بكثير.",
  "model": "google_nmt",
  "from_community_srt": "ثق بي ، هذا سوف يعطيك أفضل بكثير الإطار المفاهيمي الذي يجعل خصائص مضاعفة المصفوفة أسهل بكثير للفهم.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "على سبيل المثال، وهنا سؤال.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "هل يهم الترتيب الذي نضع فيه المصفوفتين عندما نضربهما؟",
  "model": "google_nmt",
  "from_community_srt": "على سبيل المثال ، إليك سؤال: هل يهم أي ترتيب نضع المصفوفات اثنين عندما نضربهم؟",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "حسنًا، دعونا نفكر في مثال بسيط، مثل المثال السابق.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "خذ مقصًا يعمل على تثبيت i-hat وتنعيم j-hat إلى اليمين، ودورانًا بمقدار 90 درجة.",
  "model": "google_nmt",
  "from_community_srt": "حسنا ، دعونا نفكر من خلال مثال بسيط مثل واحد من قبل: خذ القص الذي يثبت أنا قبعة و smooshes ي-قبعة على اليمين ودورة 90 درجة.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "إذا قمت بالقص أولاً، ثم قمت بالتدوير، يمكننا أن نرى أن i-hat ينتهي عند 0,1 وj-hat ينتهي عند سالب 1,1.",
  "model": "google_nmt",
  "from_community_srt": "إذا قمت بعمل القص أولاً ، قم بالتدوير ، يمكننا رؤية أن i-hat ينتهي في (0 ، 1) و j-hat ينتهي في (-1 ، 1)",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "كلاهما يشيران عمومًا إلى مكان قريب من بعضهما البعض.",
  "model": "google_nmt",
  "from_community_srt": "كلاهما يشيران بشكل عام إلى بعضهما البعض.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "إذا قمت بالتدوير أولاً، فقم بالقص، وينتهي i-hat عند 1,1، وj-hat متوقف في اتجاه مختلف عند سالب 1,0، وهم يشيرون، كما تعلمون، إلى مسافة أبعد.",
  "model": "google_nmt",
  "from_community_srt": "إذا قمت بالتدوير لأول مرة فقم بالقص i-hat تنتهي في (1 ، 1) و j-hat متوقف على اتجاه مختلف في 10)",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "من الواضح أن التأثير الإجمالي هنا مختلف، لذلك من الواضح أن النظام مهم تمامًا.",
  "model": "google_nmt",
  "from_community_srt": "وهم يشيرون إلى أبعد من ذلك التأثير العام هنا مختلف بشكل واضح لذا ، من الواضح أن الأمر يهم تمامًا.",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "لاحظ، من خلال التفكير في التحولات، هذا هو الشيء الذي يمكنك القيام به في رأسك من خلال التصور.",
  "model": "google_nmt",
  "from_community_srt": "لاحظ ، من خلال التفكير في التحولات هذا هو نوع الأشياء التي يمكنك القيام بها رأسك ، من خلال التصور.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "ليس من الضروري ضرب المصفوفات.",
  "model": "google_nmt",
  "from_community_srt": "لا الضرب المصفوفة اللازمة.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "أتذكر عندما درست الجبر الخطي لأول مرة، كانت هناك مسألة واجب منزلي طلبت منا إثبات أن ضرب المصفوفات عملية ترابطية.",
  "model": "google_nmt",
  "from_community_srt": "أتذكر عندما أخذت الجبر الخطي لأول مرة هناك هذه المشكلة المنزلية واحدة التي طلبت لنا لإثبات أن الضرب المصفوفة هو ترابطي.",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "هذا يعني أنه إذا كان لديك ثلاث مصفوفات، A وB وC، وقمت بضربهم جميعًا معًا، فلا يهم إذا قمت أولاً بحساب A في B، ثم ضربت النتيجة في C، أو إذا قمت بضرب B في البداية C، ثم اضرب تلك النتيجة بـ A على اليسار.",
  "model": "google_nmt",
  "from_community_srt": "هذا يعني أنه إذا كان لديك ثلاث مصفوفات أ ، ب و ج ، وتضربهم جميعًا معًا ، لا يهم إذا قمت بحساب A أولاً في المرة B ، اضرب النتيجة بـ C ، أو إذا ضربت B مرة B ثم ضاعفت هذه النتيجة من A على اليسار.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "بمعنى آخر، لا يهم أين تضع الأقواس.",
  "model": "google_nmt",
  "from_community_srt": "وبعبارة أخرى ، لا يهم أين أنت ضع الأقواس.",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "الآن، إذا حاولت حل هذا الأمر رقميًا، كما فعلت في ذلك الوقت، فسيكون الأمر فظيعًا، فظيعًا للغاية، وغير مفيد في هذا الشأن.",
  "model": "google_nmt",
  "from_community_srt": "الآن إذا حاولت العمل من خلال هذا العدد كما فعلت في ذلك الوقت ، انها رهيبة ، فقط مرعبة ، وغير مستنيرة لذاك السبب.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "لكن عندما تفكر في ضرب المصفوفات على أنه تطبيق تحويل تلو الآخر، فإن هذه الخاصية تكون تافهة فحسب.",
  "model": "google_nmt",
  "from_community_srt": "ولكن عندما تفكر في الضرب المصفوفة كتطبيق تحول واحد تلو الآخر ، هذه الخاصية مجرد تافهة.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "هل تستطيع أن ترى لماذا؟",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "ما يعنيه هو أنه إذا قمت أولاً بتطبيق C، ثم B، ثم A، فهو نفس تطبيق C، ثم B، ثم A.",
  "model": "google_nmt",
  "from_community_srt": "هل تستطيع أن ترى لماذا؟ ما يقوله هو أنه إذا قمت بتطبيق لأول مرة C ثم B ، ثم A ، هو نفس تطبيق C ، ثم B ثم A.",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "أعني أنه لا يوجد شيء يمكن إثباته.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "أنت فقط تطبق نفس الأشياء الثلاثة واحدًا تلو الآخر، وكلها بنفس الترتيب.",
  "model": "google_nmt",
  "from_community_srt": "أعني ، ليس هناك ما يثبت ، أنت تقوم فقط بتطبيق نفس الأشياء الثلاثة واحد بعد الآخر في نفس الترتيب.",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "قد يبدو هذا مثل الغش، لكنه ليس كذلك.",
  "model": "google_nmt",
  "from_community_srt": "هذا قد يشعر مثل الغش.",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "هذا دليل صادق على أن ضرب المصفوفات هو عملية ترابطية، والأفضل من ذلك، إنه تفسير جيد لماذا يجب أن تكون هذه الخاصية صحيحة.",
  "model": "google_nmt",
  "from_community_srt": "لكنها ليست كذلك! هذا هو دليل صادق إلى أن المصفوفة الضرب جمعي ، وحتى أفضل من ذلك ، إنه تفسير جيد لماذا يجب أن تكون هذه الخاصية صحيحة.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "أنا أشجعك حقًا على تجربة هذه الفكرة أكثر، وتخيل تحويلين مختلفين، والتفكير في ما يحدث عند تطبيق واحد تلو الآخر، ثم حساب منتج المصفوفة عدديًا.",
  "model": "google_nmt",
  "from_community_srt": "أنا حقا أشجعك على اللعب أكثر من ذلك مع هذه الفكرة تخيل تحويلين مختلفين التفكير في ما يحدث عند تقديم الطلب واحد بعد الآخر ثم عمل منتج المصفوفة عدديًا.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "ثق بي، هذا هو نوع وقت اللعب الذي يجعل الفكرة تترسخ في ذهنك.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "في الفيديو التالي، سأبدأ بالحديث عن توسيع هذه الأفكار إلى ما هو أبعد من بعدين فقط.",
  "model": "google_nmt",
  "from_community_srt": "ثق بي ، هذا هو نوع وقت اللعب يجعل حقا الفكرة تغرق في الفيديو التالي سأبدأ بالحديث عنه توسيع هذه الأفكار أبعد من بعدين فقط.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]