[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "",
  "from_community_srt": "\"Em minha experiência, provas envolvendo matrizes podem ser diminuídas em 50% se jogarmos as matrizes fora\". (Emil Artin) Olá todo mundo! No lugar onde paramos da última vez, eu mostrei com o que as transformações lineares se parecem e como representá-las usando matrizes.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "",
  "from_community_srt": "Isso vale uma rápida revisão, porque é simplesmente muito importante. Mas claro, se isto parecer mais do que só uma revisão, volte atrás e assista o vídeo inteiro.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "",
  "from_community_srt": "Falando tecnicamente, transformações lineares são funções, onde entram vetores e saem vetores. Porém, eu mostrei na última vez que nós podemos pensar sobre a visualização como remodelação do espaço, de tal maneira que as grades de linhas permaneçam paralelas e igualmente espaçadas, e que a origem permaneça fixada.",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "",
  "from_community_srt": "O ponto chave dado foi que uma transformação linear é completamente determinada, pela movimentação dos vetores básicos que, para duas dimensões,",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "",
  "from_community_srt": "significa î e ĵ. Isto é porque qualquer outro vetor pode ser descrito como uma combinação linear destes vetores básicos.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "",
  "from_community_srt": "Um vetor com coordenadas (x,y) é x·î+y·ĵ.",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "",
  "from_community_srt": "Depois de percorrer a transformação essa propriedade, que as grades de linhas permaneçam paralelas e igualmente espaçadas, possui uma maravilhosa consequência.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "",
  "from_community_srt": "O local onde seu vetor estacionará será x vezes a versão transformada de î mais y vezes a versão transformada de ĵ.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "",
  "from_community_srt": "Isso significa que se você manter um registro das coordenadas onde î parou e as coordenadas onde ĵ parou você pode computar isto como um vetor que começa em (x,y) mas estaciona em x vezes as novas coordenadas de î mais y vezes as novas coordenadas de ĵ.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "",
  "from_community_srt": "A convenção é de recordar as coordenadas onde î e ĵ estacionam como as colunas de uma matrizes e para definir isso como a soma das versões escalares destas colunas por x e y para uma multiplicação matriz-vetor.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "",
  "from_community_srt": "Desta maneira, uma matriz representa uma transformação linear especifica e multiplicar uma matriz por um vetor é, o que significa computacionalmente, aplicar esta transformação linear para este vetor.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "",
  "from_community_srt": "Tudo bem, revisão terminada. Pronto para  os novos assuntos.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "",
  "from_community_srt": "De vez em quando você se encontra querendo descrever o efeito da aplicação de uma transformação e depois outra .",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "",
  "from_community_srt": "Por exemplo, Talvez você queira descrever o que acontece quando você primeiramente rotaciona o plano em 90º graus no sentido anti-horário e então, aplica um cisalhamento.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "",
  "from_community_srt": "O efeito total aqui, do começo ao fim, é uma outra transformação linear, distinta da rotação e do cisalhamento.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "",
  "from_community_srt": "Esta nova transformação é comumente chamada como a  \"composição\" das duas transformações separadas que aplicamos",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "",
  "from_community_srt": "E como qualquer transformação linear Pode ser completamente descrita por uma matriz, acompanhando î e ĵ.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "",
  "from_community_srt": "Neste exemplo, o último ponto de parada para o î depois das duas transformações é (1,1) Então vamos fazer disto a primeira coluna da matriz",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "",
  "from_community_srt": "analogamente, ĵ termina parando nas coordenadas (-1,0) Logo, nós fazemos destas a segunda coluna da matriz.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "",
  "from_community_srt": "Esta nova matriz captura o efeito total da aplicação da rotação e depois do cisalhamento porém em um único movimento,",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "",
  "from_community_srt": "ao invés de dois sucessivos. Aqui está uma maneira de pensar sobre esta nova matriz:",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "",
  "from_community_srt": "se você fosse pegar um vetor pra fazê-lo passar por uma rotação e depois por um cisalhamento, a maneira mais longa de calcular onde ele vai parar é primeiro multiplicar na esquerda pela matriz de rotação, então pegar o resultado que você obter, e multiplicar ele pela esquerda pela matriz de cisalhamento.",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "",
  "from_community_srt": "Isso é, numericamente falando, o que significa aplicar uma rotação e então um cisalhamento a um vetor.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "",
  "from_community_srt": "Mas o que você obter deve ser o mesmo que aplicar essa nova matriz composta que acabamos de encontrar no mesmo vetor. Não importa o vetor que você escolher, já que esta nova matriz supostamente captura o mesmo efeito geral da rotação seguida do cisalhamento.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "",
  "from_community_srt": "Baseado em como as coisas foram escritas aqui, acho que é razoável chamar essa nova matriz como sendo o produto das duas matrizes originais,",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "",
  "from_community_srt": "não acha? Podemos pensar em como calcular esse produto de maneira mais geral num momento, mas é muito fácil se perder no monte de números.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "",
  "from_community_srt": "Lembre sempre que multiplicar duas matrizes assim tem o significado geométrico de aplicar uma transformação,",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "",
  "from_community_srt": "e depois outra. Uma coisa que é estranha aqui, é que isso se lê da direita para a esquerda,",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "",
  "from_community_srt": "você primeiro aplica a transformação representada pela matriz na direita, então você aplica a transformação representada pela matriz na esquerda.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "",
  "from_community_srt": "Isso vem da notação de funções, já que escrevemos funções à esquerda das variáveis, Então toda vez que você compõe duas funções, você sempre tem que ler da direita para a esquerda.",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "",
  "from_community_srt": "Boas notícias para os leitores de Hebreu, más notícias para o resto de nós.",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "",
  "from_community_srt": "Vamos ver outro exemplo.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "",
  "from_community_srt": "Pegue a matriz com as colunas (1,1) e (-2,0) cuja transformação se parece com isso,",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "",
  "from_community_srt": "e vamos chamá-la de M1.",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "",
  "from_community_srt": "Depois, pegue a matriz com colunas (0,1) e (2,0)",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "",
  "from_community_srt": "cuja transformação se parece com isso, e vamos chamar esse cara de M2.",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "",
  "from_community_srt": "O efeito total de aplicar M1 e depois M2 nos dá uma nova transformação, então vamos achar essa matriz.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "",
  "from_community_srt": "Mas dessa vez, vamos ver se conseguimos fazer sem olhar as animações, as invés disso, vamos usar somente as entradas numéricas de cada matriz.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "",
  "from_community_srt": "Primeiro, devemos descobrir onde î vai.",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "",
  "from_community_srt": "Após aplicarmos M1, as novas coordenadas de î por definição, são dadas pela primeira coluna de M1, no caso,",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "",
  "from_community_srt": "(1,1). Para ver o que acontece depois de aplicarmos M2, multiplique essa matriz M2 pelo vetor (1,1).",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "",
  "from_community_srt": "Calculando do jeito que eu descrevi no último vídeo, você obtém o vetor (2,1).",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "",
  "from_community_srt": "Este será a primeira coluna da matriz composta.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "",
  "from_community_srt": "Da mesmo maneira, para seguir ĵ, a segunda coluna de M1 nos diz que ele para no vetor (-2,0).",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "",
  "from_community_srt": "Então, quando aplicamos M2 neste vetor, você pode calcular o produto da matriz com o vetor para obter (0,-2), que se torna a segunda coluna da nossa matriz composta.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "",
  "from_community_srt": "Deixe-me ir por esse processo de novo, mas dessa vez, eu mostrarei variáveis nas entradas das matrizes, apenas para mostrar que a mesma linha de pensamento funciona para qualquer matriz.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "",
  "from_community_srt": "Isso é mais pesado simbolicamente e precisaremos de mais espaço, mas deve ser muito satisfatório para qualquer um que anteriormente aprendeu multiplicação de matrizes do jeito mais bruto.",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "",
  "from_community_srt": "Para seguir onde î vai comece olhando pela primeira coluna na matriz da direita já que ali é onde î inicialmente para.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "",
  "from_community_srt": "Multiplicando essa coluna pela matriz a esquerda é como você pode dizer onde a versão intermediária de î para após aplicarmos a segunda transformação.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "",
  "from_community_srt": "Então a segunda coluna da matriz composta sempre será igual a matriz da esquerda vezes a primeira coluna da matriz a direita.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "",
  "from_community_srt": "Da mesma maneira, ĵ sempre irá inicialmente parar na segunda coluna da matriz a direita.",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "",
  "from_community_srt": "Então multiplicar a matriz da esquerda por essa segunda coluna dará a sua localização final, então essa será a segunda coluna da matriz composta.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "",
  "from_community_srt": "Perceba, tem vários símbolos aqui, e é comum ensinarem essa fórmula como uma coisa a ser memorizada, junto com um certo processo algorítmico pra ajudar a lembrar,",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "",
  "from_community_srt": "mas eu realmente acho que antes de memorizar esse processo você deve obter o hábito de pensar o que a multiplicação de matrizes realmente representa, que é aplicar uma transformação e depois outra.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "",
  "from_community_srt": "Confie em mim, isto lhe dará um contexto conceitual muito melhor que faz as propriedades da multiplicação de matrizes muito mais fáceis de entender.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "",
  "from_community_srt": "Por exemplo, aqui está uma pergunta:",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "",
  "from_community_srt": "importa em que ordem nós colocamos as duas matrizes quando as multiplicamos?",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "",
  "from_community_srt": "Bem, vamos pensar num simples exemplo, como o anterior.",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "",
  "from_community_srt": "Pegue o cisalhamento, que fixa î e move ĵ para a direita e uma rotação de 90 graus.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "",
  "from_community_srt": "Se você fizer o cisalhamento e depois a rotação podemos ver que î para em (0,1) e ĵ para em (-1,1).",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "",
  "from_community_srt": "Ambos geralmente então apontando em direções próximas.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "",
  "from_community_srt": "Se você primeiro rotacionar e então fizer o cisalhamento, î para em (1,1) e ĵ está em uma direção diferente, em (-1,0), e eles estão apontando, você sabe,",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "",
  "from_community_srt": "distantes um do outro. O efeito geral aqui é claramente diferente, então, evidentemente,",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "",
  "from_community_srt": "a ordem totalmente importa. Perceba, pensando em termos de transformações, este é o tipo de coisa que você pode fazer na sua cabeça, visualizando,",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "",
  "from_community_srt": "nenhuma multiplicação de matrizes é necessária.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "",
  "from_community_srt": "Eu lembro quando eu aprendi Álgebra Linear pela primeira vez, e tinha esse exercício que pedia pra provar que a multiplicação de matrizes é associativa.",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "",
  "from_community_srt": "Isso quer dizer que se você tem três matrizes, A, B e C, e você multiplicá-las juntas não deve importar se você primeiro calcular A vezes B, e multiplicar o resultado por C, ou se você primeiro multiplicar B vezes C, e depois multiplicar esse resultado por A na esquerda.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "",
  "from_community_srt": "Em outras palavras, não importa onde você coloca os parênteses.",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "",
  "from_community_srt": "Agora, se você tentar trabalhar isso numericamente como eu fiz na época, é horrível, simplesmente horrível, e só serve pra confundir.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "",
  "from_community_srt": "Mas quando você pensa sobre a multiplicação de matrizes em termos de aplicar uma transformação e depois outra, essa propriedade é trivial,",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "",
  "from_community_srt": "você consegue ver o por quê?",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "",
  "from_community_srt": "O que ela está dizendo é que se você primeiro aplicar C, depois B, depois A, é a mesma coisa de aplicar C, depois B,",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "",
  "from_community_srt": "depois A. Quero dizer, não tem nada pra provar!",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "",
  "from_community_srt": "Você só está aplicando as mesmas três coisas, uma depois da outra,",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "",
  "from_community_srt": "todas na mesma ordem. Isso pode parecer trapaça, mas,",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "",
  "from_community_srt": "não é! Essa é uma prova legítima que a multiplicação de matrizes é associativa, e melhor do que isso, é uma boa explicação do por que essa propriedade deve ser verdadeira.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "",
  "from_community_srt": "Eu realmente lhe encorajo a brincar mais com essa idéia, imaginando duas transformações diferentes, e pensando sobre o que acontece quando você aplica uma depois da outra, e então trabalhar o produto das matrizes numericamente.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "",
  "from_community_srt": "Confie em mim, esse é o tipo de exercício que realmente faz as idéias fixarem.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "",
  "from_community_srt": "No próximo vídeo, eu começarei a falar sobre estender essas idéias além de somente duas dimensões.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]