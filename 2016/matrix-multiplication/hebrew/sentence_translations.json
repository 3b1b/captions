[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices.",
  "translatedText": "היי לכולם, איפה שהפסקנו בפעם האחרונה, הראיתי איך נראות טרנספורמציות ליניאריות ואיך לייצג אותן באמצעות מטריצות.",
  "model": "google_nmt",
  "from_community_srt": "זהו ניסיוני שמוכיח כי סיבוך של מטריצות יכול להתקצר ב50% אם אותו אחד מעיף את המטריצות. - אמיל ארטין(מתמטיקאי אוסטרי-אמריקאי) שלום לכולם. איפה שהפסקנו פעם שעברה, הראיתי לך איך נראות הטרנספורמציות הלינאריות הללו ואיך הן מיוצגות ע\"י שימוש במטריצות.",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video.",
  "translatedText": "זה שווה סיכום מהיר כי זה פשוט מאוד חשוב, אבל כמובן שאם זה מרגיש כמו יותר מסתם תקציר, חזור וצפה בסרטון המלא.",
  "model": "google_nmt",
  "from_community_srt": "זהו שווה סיכום מהיר , בגלל שזה ממש חשוב אבל כמובן, אם זה מרגיש יותר מסתם סיכום(לא מובן לך) - תחזור אחורה ותצפה בסירטון המלא.",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Technically speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed.",
  "translatedText": "מבחינה טכנית, טרנספורמציות ליניאריות הן פונקציות עם וקטורים ככניסות ווקטורים כפלטים, אבל הראיתי בפעם הקודמת איך אנחנו יכולים לחשוב עליהן בצורה ויזואלית כמשתנות סביב החלל בצורה כזו שקווי רשת יישארו מקבילים ומרווחים באופן שווה, וכך המקור נשאר קבוע.",
  "model": "google_nmt",
  "from_community_srt": "מבחינה טכנית, טרנספורמציות לינאריות הן פונקציות עם קלט של וקטורים. ופלט של וקטורים. אבל הראיתי בפעם האחרונה איך אפשר לחשוב על זה בצורה ויזואלית(על הטרנספורמציות) כנדחפות מסביב למרחב בצורה כזו שהקווי רשת נשארים מקבילים ובמרחקים שווים זה מזה,",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat.",
  "translatedText": "המפתח היה שטרנספורמציה ליניארית נקבעת לחלוטין לפי המקום שבו היא לוקחת את וקטורי הבסיס של החלל, שבשני מימדים פירושו i-hat ו-j-hat.",
  "model": "google_nmt",
  "from_community_srt": "כך שהראשית נשאר קבוע במקום הדבר החשוב לקחת הוא שטרנספורמציה לינארית נקבעת לחלוטין ע\"י איפה שהיא לוקחת את וקטורי הבסיס שלה במרחב כך, שעבור שני מימדים, הכוונה ל-i כובע ו-j כובע.",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors.",
  "translatedText": "הסיבה לכך היא שכל וקטור אחר יכול להיות מתואר כשילוב ליניארי של אותם וקטורים בסיסיים.",
  "model": "google_nmt",
  "from_community_srt": "זה בגלל שכל וקטור אחר יכול להיות מתואר כקומבינציה(צירוף) לינארי של אותם וקטורי הבסיס.",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat.",
  "translatedText": "וקטור עם קואורדינטות x, y הוא x כפול i-hat ועוד y כפול j-hat.",
  "model": "google_nmt",
  "from_community_srt": "וקטור עם הקואורדינטות (x,y) הוא x פעמים i כובע + y פעמים j כובע(x כפול i כובע ועוד y כפול j כובע)",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence.",
  "translatedText": "לאחר שעברו את הטרנספורמציה, לתכונה הזו שקווי רשת נשארים מקבילים ומרווחים שווה יש תוצאה נפלאה.",
  "model": "google_nmt",
  "from_community_srt": "אחרי שעוברים דרך הטרנספורמציה התכונה הזאת, קווי הרשת - נשארים מקבילים שווים זה מזה ומברחקים שווים זה מזה. יש לה השלכה נפלאה.",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat.",
  "translatedText": "המקום בו ינחת הווקטור שלך יהיה פי x מהגרסה שעברה טרנספורמציה של i-hat ועוד כפול y מהגרסה שעברה טרנספורמציה של j-hat.",
  "model": "google_nmt",
  "from_community_srt": "המקום איפה שהוקטור נוחת יהיה x פעמים הגירסה שעברה טרנספורמציה של i כובע ועוד y פעמים הגירסה שעברה טרנספורמציה של j כובע.",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat.",
  "translatedText": "פירוש הדבר שאם אתה שומרת תיעוד של הקואורדינטות היכן שה-i-hat נוחת והקואורדינטות שבהן j-hat נוחת, תוכל לחשב שוקטור שמתחיל ב-x, y חייב לנחות על x כפול הקואורדינטות החדשות של i-hat פלוס y פעמים הקואורדינטות החדשות של j-hat.",
  "model": "google_nmt",
  "from_community_srt": "זה אומר שאם תשמור לך את הקואורדינטות שבהם i כובע נוחת והקואורדינטות של איפה j כובע נוחת אתה תוכל לחשב את הוקטור שמתחיל ב(x,y) חייב לנחות ב-x פעמים הקואורדינטות החדשות של i כובע. ועוד y פעמים הקואורדינטות של j כובע.",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication.",
  "translatedText": "המוסכמה היא לרשום את הקואורדינטות של המקום שבו i-hat ו-j-hat נוחתים כעמודות של מטריצה, ולהגדיר את הסכום הזה של הגירסאות בקנה מידה של אותן עמודות על ידי x ו-y ככפל מטריצה-וקטור.",
  "model": "google_nmt",
  "from_community_srt": "המוסכמה היא לשמור את הקואורדינטות של איפה i כובע ו-j כובע ינחתו כעמודות של מטריצה. ולהגדיר חלק מהגירסאות שעברו מכפלה סקאלרית ע\"י x ו-y. כדי שיהיו מטריצה של כפל וקטורי.",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector.",
  "translatedText": "בדרך זו, מטריצה מייצגת טרנספורמציה ליניארית ספציפית, וכפל מטריצה בוקטור היא המשמעות החישובית להחיל את הטרנספורמציה הזו על אותו וקטור.",
  "model": "google_nmt",
  "from_community_srt": "בדרך זו, המטריצה מייצגת טרנספורמציה לינארית מסויימת והכפלת המטריצה בוקטור, זה מה שאומר מבחינה חישובית - ליישם את הטרנספורמציה הזאתי על אותו הוקטור.",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff.",
  "translatedText": "בסדר, חזור על הדברים החדשים.",
  "model": "google_nmt",
  "from_community_srt": "אוקיי, הסיכום נגמר. קדימה לדברים החדשים.",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes, you find yourself wanting to describe the effects of applying one transformation and then another.",
  "translatedText": "לעתים קרובות, אתה מוצא את עצמך רוצה לתאר את ההשפעות של יישום טרנספורמציה אחת ואחר כך אחרת.",
  "model": "google_nmt",
  "from_community_srt": "לעיתים קרובות, אתה תמצא את עצמך מנסה לתאר את ההשפעות של יישום של טרנספורמציה לינארית אחת ואז ליישם עוד אחת אחרת.",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear.",
  "translatedText": "לדוגמה, אולי אתה רוצה לתאר מה קורה כאשר אתה מסובב לראשונה את המטוס 90 מעלות נגד כיוון השעון, ואז מפעיל גזירה.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, אולי אתה רוצה לתואר מה קורה שאתה מסובב לראשונה את המישור ב90 מעלות כנגד כיוון השעון ואז לגזור אותה.",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear.",
  "translatedText": "ההשפעה הכוללת כאן, מההתחלה ועד הסוף, היא טרנספורמציה ליניארית נוספת, נבדלת מהסיבוב והגזירה.",
  "model": "google_nmt",
  "from_community_srt": "ההשפעה הכללית כאן, מההתחלה לסוף, היא עוד טרנספורמציה לינארית, שונה מהסיבוב והגזירה שלה.",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied.",
  "translatedText": "טרנספורמציה לינארית חדשה זו נקראת בדרך כלל ההרכב של שתי הטרנספורמציות הנפרדות שהחלנו.",
  "model": "google_nmt",
  "from_community_srt": "הטרנספורמציה הלינארית החדשה נקראת לרוב ה\"הרכבה\" של שתי טרנספורמציות(לינאריות) נפרדות שיישמנו.",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat.",
  "translatedText": "וכמו כל טרנספורמציה ליניארית, ניתן לתאר אותו עם מטריצה משלה על ידי מעקב אחר i-hat ו-j-hat.",
  "model": "google_nmt",
  "from_community_srt": "וכמו כל טרנספורמציה לינארית אחרת אפשר לתאר אותה עם מטריצה וכל מה שנלווה אליה - ה-i כובע וה-j כובע.",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix.",
  "translatedText": "בדוגמה זו, נקודת הנחיתה האולטימטיבית של i-hat לאחר שתי הטרנספורמציות היא 1,1, אז בואו נעשה זאת לעמודה הראשונה של מטריצה.",
  "model": "google_nmt",
  "from_community_srt": "בדוגמא הזאת, מקום הנחיתה הכי טוב ל-i כובע לאחר שתי הטרנספורמציות הוא (1,1). אז בוא נעשה את העמודה הראשונה של המטריצה הזו.",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix.",
  "translatedText": "באופן דומה, j-hat בסופו של דבר מסתיים במיקום השלילי 1,0, אז אנו הופכים זאת לעמודה השנייה של המטריצה.",
  "model": "google_nmt",
  "from_community_srt": "באופן דומה, ה-j כובע נוחת בסופו של דבר במיקום (1,0-). אז אנחנו עושים עמודה שניה למטריצה הזאת.",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones.",
  "translatedText": "המטריצה החדשה הזו לוכדת את ההשפעה הכוללת של הפעלת סיבוב ואז גזירה, אבל כפעולה אחת בודדת, ולא שתיים עוקבות.",
  "model": "google_nmt",
  "from_community_srt": "המטריצה החדשה הזאת לוכדת את ההשפעה הכללית של יישום הסיבוב ואז גזירה. אבל כפעולה אחת, במקום שתי פעולות אחת אחרי השניה.",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix.",
  "translatedText": "הנה דרך אחת לחשוב על המטריצה החדשה הזו.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix, then take whatever you get and multiply that on the left by the shear matrix.",
  "translatedText": "אם הייתם לוקחים וקטור כלשהו ומשאבים אותו דרך הסיבוב, אז הגזירה, הדרך הארוכה לחשב היכן הוא מגיע היא תחילה להכפיל אותו משמאל במטריצת הסיבוב, ואז לקחת את מה שתקבל ולהכפיל את זה על השאירה מטריצת הגזירה.",
  "model": "google_nmt",
  "from_community_srt": "הנה דרך אחת לחשוב על המטריצה החדשה הזו: אם היית לוקח וקטור כלשהו ושואב אותו דרך הסיבוב ואז גוזר הדרך הארוכה לחשב איפה הוא ינחת היא קודם להכפיל אותו בצד שמאל ע\"י מטריצת הסיבוב; ואז, תיקח מה שקיבלת ותכפיל את זה בצד שמאל של מטריצת הנגזרת.",
  "n_reviews": 0,
  "start": 185.42,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector.",
  "translatedText": "זה, מבחינה מספרית, המשמעות של הפעלת סיבוב ואז גזירה על וקטור נתון.",
  "model": "google_nmt",
  "from_community_srt": "זה, מבחינה מספרית, מה שאומר ליישם סיבוב ואז גזירה לוקטור נתון כלשהו.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action.",
  "translatedText": "אבל כל מה שתקבל צריך להיות זהה לעצם החלת מטריצת הקומפוזיציה החדשה הזו שמצאנו זה עתה על ידי אותו וקטור, לא משנה באיזה וקטור בחרת, שכן המטריצה החדשה הזו אמורה ללכוד את אותו אפקט כולל כמו פעולת הסיבוב ואז הגזירה.",
  "model": "google_nmt",
  "from_community_srt": "אבל, מה שלא תקבל(כל תוצאה), הוא צריך להיות זהה לשימוש במטריצה המורכבת החדשה. לא משנה איזה וקטור תבחר, מכיוון שהמטריצה החדשה הזו צריכה ללכוד את כל ההשפעה הכללית כמו של פעולת הסיבוב ואז פעולת הגזירה.",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you?",
  "translatedText": "בהתבסס על איך שהדברים כתובים כאן, אני חושב שזה הגיוני לקרוא למטריצה החדשה הזו מכפלה של שתי המטריצות המקוריות, לא?",
  "model": "google_nmt",
  "from_community_srt": "בהתבסס על איך הדברים נכתבו כאן אני חושב שזה הגיוני לקרוא למטריצה החדשה הזאת \"המוצר\" של שתי המטריצות המקוריות(סיבוב וגזירה).",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers.",
  "translatedText": "אנחנו יכולים לחשוב על איך לחשב את המוצר הזה באופן כללי יותר ברגע, אבל זה קל מדי ללכת לאיבוד ביער המספרים.",
  "model": "google_nmt",
  "from_community_srt": "לא כן? אנחנו יכולים לחשוב איך לחשב את המוצר בצורה כללית יותר בעוד רגע, אבל זה קל מדיי ללכת לאיבוד ביער המספרים הזה.",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another.",
  "translatedText": "זכור תמיד שלכפל שתי מטריצות כך יש משמעות גיאומטרית של החלת טרנספורמציה אחת לאחר מכן.",
  "model": "google_nmt",
  "from_community_srt": "תמיד תזכור, הכפלת שתי מטריצות ככה יש להן משמעות גיאומטרית של יישום טרנספורמציה אחת ואז עוד אחת אחרת.",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left.",
  "translatedText": "דבר אחד די מוזר כאן הוא שזה גורם לנו לקרוא מימין לשמאל.",
  "model": "google_nmt",
  "from_community_srt": "דבר אחד שדיי מוזר כאן(מתמטית נהוג לקרוא\\לכתוב משמאל לימין) הוא שהקריאה צריכה להיעשות מימין לשמאל.",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left.",
  "translatedText": "תחילה אתה מיישם את הטרנספורמציה המיוצגת על ידי המטריצה מימין, ואז אתה מיישם את הטרנספורמציה המיוצגת על ידי המטריצה משמאל.",
  "model": "google_nmt",
  "from_community_srt": "אתה קודם מיישם את הטרנספורמציה המיוצגת ע\"י המטריצה בצד ימין. ואז אתה מיישם את הטרנספורמציה המיוצגת ע\"י המטריצה בצד שמאל.",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left.",
  "translatedText": "זה נובע מסימון פונקציות, מכיוון שאנו כותבים פונקציות משמאל למשתנים, כך שבכל פעם שאתה מרכיב שתי פונקציות, אתה תמיד צריך לקרוא את זה מימין לשמאל.",
  "model": "google_nmt",
  "from_community_srt": "זה נובע מסימון פוקנציות, מכיוון שאנחנו כותבים את הפונקציות מצד שמאל של המשתנים, אז כל פעם שאתה מרכיב שתי פונקציות, אתה תמיד חייב לקרוא מימין לשמאל(למשל g(x) של f(x) כאשר g(x) הוא המשתנה ורושמים f(g(x)) חדשות טובות לקוראים בעברית,",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us.",
  "translatedText": "חדשות טובות לקוראי העברית, חדשות רעות לכולנו.",
  "model": "google_nmt",
  "from_community_srt": "אבל חדשות רעות לכל השאר(כי אנחנו קוראים מימין לשמאל באנגלית זה הפוך).",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example.",
  "translatedText": "בואו נסתכל על דוגמה נוספת.",
  "model": "google_nmt",
  "from_community_srt": "בוא נסתכל על עוד דוגמא.",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this.",
  "translatedText": "קח את המטריצה עם עמודות 1,1 ושליליות 2,0, שהטרנספורמציה שלה נראית כך.",
  "model": "google_nmt",
  "from_community_srt": "תיקח את המטריצה עם העמודות (1,1) ו-(2,0-) שהטרנספורמציה שלה נראית ככה, ובוא נקרא לה M1.",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it M1.",
  "translatedText": "ובואו נקרא לזה M1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this.",
  "translatedText": "לאחר מכן, קח את המטריצה עם העמודות 0,1 ו-2,0, שהטרנספורמציה שלה נראית כך.",
  "model": "google_nmt",
  "from_community_srt": "דבר הבא, ניקח את המטריצה עם העמודות (0,1) ו-(2,0) שהטרנספורמציה שלה נראית כך, ובוא נקרא לבחורה הזאתי M2.",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy M2.",
  "translatedText": "ובואו נקרא לבחור הזה M2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying M1 then M2 gives us a new transformation, so let's find its matrix.",
  "translatedText": "האפקט הכולל של החלת M1 ואז M2 נותן לנו טרנספורמציה חדשה, אז בואו נמצא את המטריצה שלה.",
  "model": "google_nmt",
  "from_community_srt": "ההשפעה הכוללת של יישום M1 ואז M2 נותנת לנו טרנספורמציה חדשה. אז בוא נמצא את המטריצה.",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix.",
  "translatedText": "אבל הפעם, בואו נראה אם אנחנו יכולים לעשות את זה בלי לצפות בהנפשות, ובמקום זאת פשוט להשתמש בערכים המספריים בכל מטריצה.",
  "model": "google_nmt",
  "from_community_srt": "אבל הפעם, בוא נראה אם אנחנו יכולים להסתדר מבלי לצפות באנימציות ברקע במקום זאת, נשתמש פשוט בערכים המספריים שרשומים בכל מטריצה.",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes.",
  "translatedText": "ראשית, עלינו להבין לאן הולך ה-i-hat.",
  "model": "google_nmt",
  "from_community_srt": "ראשית, אנחנו צריכים להבין לאיפה הולך ה-i כובע לאחר יישום M1,",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying M1, the new coordinates of i-hat, by definition, are given by that first column of M1, namely 1,1.",
  "translatedText": "לאחר החלת M1, הקואורדינטות החדשות של i-hat, בהגדרה, ניתנות על ידי העמודה הראשונה של M1, כלומר 1,1.",
  "model": "google_nmt",
  "from_community_srt": "הקואורדינטות החדשות של i כובע מהגדרה, הן נתונות קודם ע\"י העמודה הראשונה של M1, בשמה (1,1).",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1.",
  "translatedText": "כדי לראות מה קורה לאחר החלת M2, הכפל את המטריצה עבור M2 בוקטור הזה 1,1.",
  "model": "google_nmt",
  "from_community_srt": "כדי לראות מה קורה לאחר יישום מטריצת M2 הכפלת המטריצה עבור M2 ע\"י הוקטור (1,1), הדרך לפתור זאת,",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1.",
  "translatedText": "אם תסתדר, כמו שתיארתי את הסרטון האחרון, תקבל את הווקטור 2,1.",
  "model": "google_nmt",
  "from_community_srt": "בדרך שתיארתי בסירטון האחרון אתה תקבל את הוקטור (2,1).",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix.",
  "translatedText": "זו תהיה העמודה הראשונה של מטריצת ההרכב.",
  "model": "google_nmt",
  "from_community_srt": "זה יהיה העמודה הראשונה בהרכבת המטריצה.",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of M1 tells us that it first lands on negative 2,0.",
  "translatedText": "באופן דומה, כדי לעקוב אחר j-hat, העמודה השנייה של M1 אומרת לנו שהוא נוחת לראשונה על 2,0 שלילי.",
  "model": "google_nmt",
  "from_community_srt": "באופן דומה, לעקוב אחר j כובע העמודה השניה של M1 אומרת לנו שהוקטור הראשון ינחת ב-(2,0-) ואז,",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply M2 to that vector, you can work out the matrix-vector product to get 0, negative 2, which becomes the second column of our composition matrix.",
  "translatedText": "לאחר מכן, כאשר אנו מיישמים M2 על אותו וקטור, אתה יכול לחשב את מכפלת המטריצה-וקטור כדי לקבל 0, שלילי 2, שהופך לעמודה השנייה של מטריצת ההרכב שלנו.",
  "model": "google_nmt",
  "from_community_srt": "כשאנחנו מיישמים את המטריצה M2 על הוקטור הזה אתה יכול להסיק את המוצר של וקטור-המטריצה כדי לקבל (2-,0) מה שהופך להיות העמודה השניה בהרכבת המטריצה.",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices.",
  "translatedText": "תן לי לדבר שוב על אותו תהליך, אבל הפעם אני אראה ערכים משתנים בכל מטריצה, רק כדי להראות שאותו קו נימוק עובד עבור כל מטריצות.",
  "model": "google_nmt",
  "from_community_srt": "תן לי לדבר שוב על אותו התהליך, אבל הפעם אני אראה מספר ערכים שונים בכל מטריצה, רק כדי להראות שאותו קו היגיון עובד עבור כל סוג של מטריצות.",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way.",
  "translatedText": "זה כבד יותר בסמלים וידרוש קצת יותר מקום, אבל זה אמור להיות מספק למדי עבור כל מי שלימדו בעבר כפל מטריצה בצורה יותר רגילה.",
  "model": "google_nmt",
  "from_community_srt": "זה יותר כבד מבחינה סמלים(פרמטרי) וידרוש קצת יותר מקום, אבל זה צריך להיות מספק עבור כל מי שלמד בעבר כפל מטריצות בדרך היותר \"כתובה\".",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands.",
  "translatedText": "כדי לעקוב אחר המקום שבו ה-i-hat הולך, התחל בהסתכלות על העמודה הראשונה של המטריצה מימין, מכיוון שכאן ה-i-hat נוחת בהתחלה.",
  "model": "google_nmt",
  "from_community_srt": "כדי לעקוב אחר איפה ה-i כובע הולך נתחיל ע\"י כך שנסתכל קודם בעמודה הראשונה של המטריצה בצד ימין, מכיוון ש-i כובע הוא הראשון שנוחת.",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation.",
  "translatedText": "הכפלה של העמודה הזו במטריצה משמאל היא איך אתה יכול לדעת היכן מסתיימת גרסת הביניים של i-hat לאחר החלת השינוי השני.",
  "model": "google_nmt",
  "from_community_srt": "הכפלת העמודה הזאת ע\"י המטריצה מצד שמאל, היא איך שאתה יכול לדעת איפה גירסת התווך של i כובע מסתיים לאחר יישום הטרנספורמציה השניה.",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix.",
  "translatedText": "אז העמודה הראשונה של מטריצת ההרכב תהיה תמיד שווה למטריצה השמאלית כפול העמודה הראשונה של המטריצה הימנית.",
  "model": "google_nmt",
  "from_community_srt": "אז העמודה הראשונה של המטריצה המורכבת תמיד יהיה שווה לצד שמאל של המטריצה כפול הפעמים של העמודה הראשונה של המטריצה הימנית.",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix.",
  "translatedText": "באופן דומה, j-hat תמיד ינחת בתחילה בעמודה השנייה של המטריצה הימנית.",
  "model": "google_nmt",
  "from_community_srt": "באופן דומה, j כובע תמיד ינחת בהתחלה בעמודה השניה של המטריצה הימנית.",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix.",
  "translatedText": "אז הכפלת המטריצה השמאלית בעמודה השנייה תיתן את מיקומה הסופי, ומכאן שזו העמודה השנייה של מטריצת ההרכב.",
  "model": "google_nmt",
  "from_community_srt": "אז הכפלת צד שמאל של המטריצה ע\"י העמודה השניה הזו תיתן לנו את המיקום הסופי. וכך, זאתי העמודה השניה של המטריצה המורכבת.",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to help remember it.",
  "translatedText": "שימו לב שיש כאן הרבה סמלים, ומקובל ללמד את הנוסחה הזו כמשהו שצריך לשנן, יחד עם תהליך אלגוריתמי מסוים שיעזור לזכור אותה.",
  "model": "google_nmt",
  "from_community_srt": "שים לב, יש כאן הרבה סמלים וזה נפוץ שילמדו אותך לזכור את הנוסחה הזאת. כמו סוגים שונים של תהליכים אלגוריתמים(דרך שיטתית) שיועילו לך אם תזכור זאת.",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another.",
  "translatedText": "אבל אני באמת חושב שלפני שאתה משנן את התהליך הזה, אתה צריך להתרגל לחשוב מה באמת מייצג כפל מטריצה, להחיל טרנספורמציה אחת אחרי השנייה.",
  "model": "google_nmt",
  "from_community_srt": "אבל אני באמת חושב שלפני שמשננים את התהליך אתה צריך לקבל את התחביב של לחשוב על מה באמת כפל מטריצה מייצגת: יישום של טרנספורמציה אחת אחרי השניה.",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand.",
  "translatedText": "תאמין לי, זה ייתן לך מסגרת רעיונית הרבה יותר טובה שהופכת את תכונות הכפל המטריצה להרבה יותר קלות להבנה.",
  "model": "google_nmt",
  "from_community_srt": "תסמוך עליי, זה יתן לך שלד רעיוני(בסיס) חזק יותר. שהופך את התכונות של כפל מטריצה להרבה יותר קלות להבנה.",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question.",
  "translatedText": "לדוגמה, הנה שאלה.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא,",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them?",
  "translatedText": "האם זה משנה באיזה סדר נשים את שתי המטריצות כשאנחנו מכפילים אותן?",
  "model": "google_nmt",
  "from_community_srt": "הנה שאלה: האם זה משנה באיזה סדר נשים שתי מטריצות כאשר נכפיל ביניהן?",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier.",
  "translatedText": "ובכן, בואו נחשוב דרך דוגמה פשוטה, כמו זו מלפני כן.",
  "model": "google_nmt",
  "from_community_srt": "ובכן,",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smooshes j-hat over to the right, and a 90 degree rotation.",
  "translatedText": "קח גזירה, שמקבעת את ה-i-hat ומרחיקה את ה-j-hat ימינה, וסיבוב של 90 מעלות.",
  "model": "google_nmt",
  "from_community_srt": "בוא נחשוב דרך דוגמא פשוטה כמו האחת ממקודם: תיקח נגזרת שמקבעת את ה-i כובע ומחליקה את j כובע לצד ימין. וסיבוב ב-90 מעלות.",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1.",
  "translatedText": "אם תחילה מבצעים את הגזירה, ואז מסתובבים, נוכל לראות ש-i-hat מסתיים ב-0,1 ו-j-hat מסתיים ב-1,1 שלילי.",
  "model": "google_nmt",
  "from_community_srt": "אם קודם תבצע את הגזירה ואז תסובב, אנחנו נוכל לראות כי i כובע יהיה ב-(0,1)",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together.",
  "translatedText": "שניהם בדרך כלל מצביעים קרוב זה לזה.",
  "model": "google_nmt",
  "from_community_srt": "ו-j כובע יהיה ב-(1,1-) שניהם באופן כללי מצביעים קרוב אחד לשני.",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing, you know, farther apart.",
  "translatedText": "אם תסתובב קודם, אז תעשה את הגזירה, ה-i-hat מסתיים ב-1,1, וה-j-hat כבוי בכיוון אחר ב-1,0 שלילי, והם מצביעים, אתה יודע, רחוק יותר.",
  "model": "google_nmt",
  "from_community_srt": "אם תסובב ואז תגזור i כובע יהיה ב-(1,1) ו-j כובע יהיה בכיוון שונה ב-(1,0-) ושניהם מצביעים, אתה יודע, רחוק יותר אחד מהשני.",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently, order totally does matter.",
  "translatedText": "ההשפעה הכוללת כאן שונה בבירור, אז ברור שהסדר בהחלט משנה.",
  "model": "google_nmt",
  "from_community_srt": "ההשפעה הכללית כאן היא באופן ברור שונה לגמרי אז, באופן בלתי נמנע,",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice, by thinking in terms of transformations, that's the kind of thing that you can do in your head by visualizing.",
  "translatedText": "שימו לב, על ידי חשיבה במונחים של טרנספורמציות, זה מסוג הדברים שאתם יכולים לעשות בראש שלכם על ידי הדמיה.",
  "model": "google_nmt",
  "from_community_srt": "הסדר כן משנה. שים לב, ע\"י כך שחשבנו במונחים של טרנספורמציות זהו משהו שאתה יכול לעשות בראשך ע\"י כך שתדמיין זאת.",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary.",
  "translatedText": "אין צורך בכפל מטריצת.",
  "model": "google_nmt",
  "from_community_srt": "אין צורך בשום כפל במטריצה.",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative.",
  "translatedText": "אני זוכר שכאשר לקחתי אלגברה לינארית לראשונה, הייתה בעיית שיעורי בית אחת שביקשה מאיתנו להוכיח שכפל מטריצה הוא אסוציאטיבי.",
  "model": "google_nmt",
  "from_community_srt": "אני זוכר שלראשונה לקחתי(את הקורס) אלגברה לינארית יש את השאלה האחת הזאת משיעורי הבית שביקשו להוכיח שכפל מטריצות הוא",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left.",
  "translatedText": "זה אומר שאם יש לך שלוש מטריצות, A, B ו-C, ואתה מכפיל את כולן יחד, זה לא צריך להיות משנה אם תחשוב קודם את A כפול B, ואז תכפיל את התוצאה ב-C, או אם תכפיל תחילה את B פעמים C, ולאחר מכן הכפל את התוצאה ב-A משמאל.",
  "model": "google_nmt",
  "from_community_srt": "הוא אסוציאטיבי(מקיים חוק הקיבוץ) זה אומר שאם יש לך שלוש מטריצות, B, A ו-C, ואתה מכפיל את כולן ביחד, זה לא אמור לשנות אם קודם תחשב את A כפול B ואז תכפיל את התוצאה ב-C, או קודם תכפיל את B ב-C ואז תכפיל את התוצאה ב-A בצד שמאל.",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses.",
  "translatedText": "במילים אחרות, זה לא משנה איפה אתה שם את הסוגריים.",
  "model": "google_nmt",
  "from_community_srt": "במילים אחרות, זה לא משנה איפה תשים את הסוגריים, עכשיו,",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter.",
  "translatedText": "עכשיו, אם אתה מנסה לעבוד על זה באופן מספרי, כמו שעשיתי אז, זה נורא, פשוט נורא, ולא מאיר עיניים לצורך העניין.",
  "model": "google_nmt",
  "from_community_srt": "אם תנסה לפתור זאת בצורה מספרית כמו שאני ניסיתי בזמנו זה נורא, פשוט נורא, וזה לא חכם כלל עבור הבעיה הזאת.",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial.",
  "translatedText": "אבל כשאתה חושב על כפל מטריצה כיישום טרנספורמציה אחת אחרי השנייה, התכונה הזו היא פשוט טריוויאלית.",
  "model": "google_nmt",
  "from_community_srt": "אבל כשאתה חושב על כפל מטריצות כיישום של טרנספורמציה אחת אחרי השניה, התכונה הזאתי היא פשוט מובנת מאליה(טריוויאלית).",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why?",
  "translatedText": "אתה יכול לראות למה?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C, then B, then A, it's the same as applying C, then B, then A.",
  "translatedText": "מה שזה אומר זה שאם אתה מיישם קודם את C, אז B, ואז A, זה אותו דבר כמו החלת C, ואז B, ואז A.",
  "model": "google_nmt",
  "from_community_srt": "האם אתה יכול לראות למה? מה שזה אומר, אם קודם תשתמש ב-C ואז ב-B ואז ב-A, זה כמו ליישם C, ואז B,",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove.",
  "translatedText": "כלומר, אין מה להוכיח.",
  "model": "google_nmt",
  "from_community_srt": "ואז A. אני מתכוון, אין כאן מה להוכיח.",
  "n_reviews": 0,
  "start": 552.82,
  "end": 554.38
 },
 {
  "input": "You're just applying the same three things one after the other, all in the same order.",
  "translatedText": "אתה פשוט מיישם את אותם שלושה דברים בזה אחר זה, כולם באותו סדר.",
  "model": "google_nmt",
  "from_community_srt": "אתה פשוט מיישם את אותם שלושת הדברים, אחד אחרי השני, כולם באותו סדר.",
  "n_reviews": 0,
  "start": 554.54,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not.",
  "translatedText": "זה אולי מרגיש כמו רמאות, אבל זה לא.",
  "model": "google_nmt",
  "from_community_srt": "זה אולי מרגיש כמו לרמות, אבל זה לא!",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative, and even better than that, it's a good explanation for why that property should be true.",
  "translatedText": "זוהי הוכחה כנה לטובה לכך שכפל מטריצה הוא אסוציאטיבי, ואפילו טוב מזה, זה הסבר טוב למה המאפיין הזה צריך להיות נכון.",
  "model": "google_nmt",
  "from_community_srt": "זאתי דרך טוב להוכחה טובה שכפל מטריצות הוא אסוציאטיבי, ואפילו יותר טוב מכך, זהו הסבר טוב ללמה התכונה הזאת צריכה להיות נכונה.",
  "n_reviews": 0,
  "start": 561.54,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically.",
  "translatedText": "אני באמת מעודד אותך לשחק יותר עם הרעיון הזה, לדמיין שתי טרנספורמציות שונות, לחשוב על מה קורה כשאתה מיישם אחד אחרי השני, ואז לחשב את המוצר המטריצה באופן מספרי.",
  "model": "google_nmt",
  "from_community_srt": "אני באמת מעודד אותך לשחק יותר עם הרעיון הזה. מדמיין שתי טרנספורמציות שונות חושב על מה קורה כשאתה מיישם אותן אחת אחרי השניה ואז מנסה להבין את \"מוצר\" המטריצה בצורה מספרית.",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in.",
  "translatedText": "תאמין לי, זה סוג של זמן משחק שבאמת גורם לרעיון לשקוע.",
  "model": "google_nmt",
  "from_community_srt": "תסמוך עליי, זה באמת סוג של כיף לשחק עם זה עד שהרעיון שוקע.",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions.",
  "translatedText": "בסרטון הבא, אתחיל לדבר על הרחבת הרעיונות הללו מעבר לשני ממדים בלבד.",
  "model": "google_nmt",
  "from_community_srt": "בסירטון הבא, אני אתחיל לדבר על הרחבת הרעיונות הללו מעבר לעולם הדו-מימדי.",
  "n_reviews": 0,
  "start": 587.2,
  "end": 592.18
 }
]