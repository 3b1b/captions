1
00:00:04,800 --> 00:00:11,260
"Meiner Erfahrung nach kann man Beweise, die auf Matrizen beruhen, halb so kurz gestalten, indem man die Matrizen weglässt." - Emil Artin

2
00:00:11,260 --> 00:00:12,020
Hallo zusammen!

3
00:00:12,020 --> 00:00:15,129
Das letzte mal habe ich euch gezeigt, wie lineare Transformationen aussehen

4
00:00:15,129 --> 00:00:18,369
und wie man sie mithilfe von Matrizen darstellen kann.

5
00:00:18,369 --> 00:00:20,859
Da es so wichtig ist, sollten wir es auch nochmal schnell wiederholen.

6
00:00:20,859 --> 00:00:25,970
Ist dir jedoch in der Wiederholung einiges unbekannt, schaue dir lieber das letzte Video nochmal an.

7
00:00:25,970 --> 00:00:30,279
Genau genommen sind lineare Transformationen nichts anderes als Funktionen mit Vektoren als Ein-

8
00:00:30,279 --> 00:00:31,789
und Ausgangsgröße.

9
00:00:31,789 --> 00:00:34,239
Aber das letzte Mal habe ich gezeigt, wie man sie grafisch durch

10
00:00:34,239 --> 00:00:39,510
Verzerrung des Raumes darstellen kann, wobei alle Gitterlinien parallel und gleichmäßig verteilt bleiben;

11
00:00:39,510 --> 00:00:41,850
so, dass der Ursprung an seiner Position bleibt.

12
00:00:41,850 --> 00:00:43,129
Die wichtigste Schlussfolgerung war, dass

13
00:00:43,129 --> 00:00:48,030
eine lineare Transformation komplett durch die "Lage" der Basisvektoren im Raum bestimmt ist,

14
00:00:48,030 --> 00:00:49,030
 

15
00:00:49,030 --> 00:00:52,250
was im 2-Dimensionalen Raum auf i-hat und j-hat zutrifft.

16
00:00:52,250 --> 00:00:57,510
Das kommt daher, dass jeder Vektor durch eine lineare Kombination mit diesen Basisvektoren beschrieben werden kann.

17
00:00:57,510 --> 00:00:59,789
Ein Vektor mit den Koordinaten x und y

18
00:00:59,789 --> 00:01:03,690
ist x mal i-hat plus y mal j-hat.

19
00:01:03,690 --> 00:01:05,160
Nach der Ausführung der Transformation

20
00:01:05,160 --> 00:01:08,700
hat die Eigenschaft, dass alle Linien parallel und gleichmäßig verteilt bleiben

21
00:01:08,700 --> 00:01:10,360
eine wundervolle Auswirkung:

22
00:01:10,360 --> 00:01:15,390
Der neue Ort für den Vektor ist dann x mal die transformierte Version von i-hat +

23
00:01:15,390 --> 00:01:18,440
y mal die transformierte Version von j-hat.

24
00:01:18,440 --> 00:01:22,000
Wenn man also alle Koordinaten aufnimmt, auf denen jeweils i-hat

25
00:01:22,000 --> 00:01:24,180
und j-hat landen werden,

26
00:01:24,180 --> 00:01:27,410
kann man ausrechnen, dass ein Vektoren, der bei (x, y) beginnt,

27
00:01:27,410 --> 00:01:30,190
nun bei x mal der neuen Koordinaten von i-hat

28
00:01:30,190 --> 00:01:33,610
+ y mal der neuen Koordinaten von j-hat landen muss.

29
00:01:33,610 --> 00:01:37,160
Die neuen Koordinaten von jeweils i-hat und j-hat schreibt man dann immer

30
00:01:37,160 --> 00:01:39,300
als eine Spalte einer Matrix

31
00:01:39,300 --> 00:01:43,430
und die Summe der mit x und y skalierten Versionen der Spalten

32
00:01:43,430 --> 00:01:46,280
nennt man eine Matrix-Vektor Multiplikation.

33
00:01:46,280 --> 00:01:47,280
Das heißt also, dass

34
00:01:47,280 --> 00:01:50,140
eine Matrix eine bestimmte lineare Transformation darstellt

35
00:01:50,140 --> 00:01:54,540
und diese mit einem Vektor zu multiplizieren ist dasselbe, wie

36
00:01:54,540 --> 00:01:57,970
diese Transformation an einem Vektor auszuführen.

37
00:01:57,970 --> 00:02:00,110
Ok, Wiederholung geschafft!

38
00:02:00,110 --> 00:02:01,640
Auf zu dem neuen Zeug!

39
00:02:01,640 --> 00:02:04,520
Oftmals wirst du dich fragen, was passiert,

40
00:02:04,520 --> 00:02:07,680
wenn man eine Transformation ausführt und im Anschluss eine weitere.

41
00:02:07,680 --> 00:02:08,680
Zum Beispiel:

42
00:02:08,680 --> 00:02:13,099
Vielleicht willst du wissen, was passiert, wenn du nach einer 90° Rotation gegen den Uhrzeigersinn

43
00:02:13,099 --> 00:02:15,439
eine Verformung (Shear) ausführst.

44
00:02:15,439 --> 00:02:17,780
Letztendlich ist es vom Anfang bis zum Ende

45
00:02:17,780 --> 00:02:20,019
nur eine weitere lineare Transformation,

46
00:02:20,019 --> 00:02:22,549
bestehend aus einer Rotation und einer Verformung.

47
00:02:22,549 --> 00:02:26,909
Diese neue lineare Transformation wird die Komposition der beiden angewandten,

48
00:02:26,909 --> 00:02:29,019
separaten Transformationen genannt.

49
00:02:29,019 --> 00:02:30,480
Und wie bei jeder anderen linearen Transformation

50
00:02:30,480 --> 00:02:36,269
kann man diese vollständig durch eine Matrix beschreiben, indem man sich an i-hat und j-hat orientiert.

51
00:02:36,269 --> 00:02:39,269
In diesem Beispiel ist der endgültige Landepunkt für i-hat

52
00:02:39,269 --> 00:02:42,370
nach beiden Transformationen bei (1, 1).

53
00:02:42,370 --> 00:02:45,019
Lass uns das also in die erste Spalte der Matrix schreiben.

54
00:02:45,019 --> 00:02:49,730
Nach diesem Prinzip landet j-hat deshalb letztendlich bei (-1, 0);

55
00:02:49,730 --> 00:02:52,799
das wird dann die zweite Spalte der Matrix.

56
00:02:52,799 --> 00:02:58,030
Diese neue Matrix zeigt nun den allgemeinen Effekt der Rotation, gefolgt von der Verformung,

57
00:02:58,030 --> 00:03:03,430
jedoch als eine einzelne Aktion, statt zwei aufeinander folgende.

58
00:03:03,430 --> 00:03:05,499
So könnte man sich diese neue Matrix noch vorstellen:

59
00:03:05,499 --> 00:03:09,459
Wenn man einen Vektor nimmt und übt die Rotation und dann die Verformung aus,

60
00:03:09,459 --> 00:03:11,560
wäre der lange Weg zur Berechnung des Endpunktes

61
00:03:11,560 --> 00:03:15,430
zunächst die Multiplikation mit der Rotations-Matrix zur Linken;

62
00:03:15,430 --> 00:03:20,480
Dann multiplizierst du letztlich das Resultat noch mit der Verformungs-Matrix.

63
00:03:20,480 --> 00:03:22,280
Das ist, numerisch gesagt,

64
00:03:22,280 --> 00:03:26,530
was es bedeutet, die Rotation und dann Verformung an einen gegebenen Vektor anzuwenden.

65
00:03:26,530 --> 00:03:30,700
Aber: Das Ergebnis sollte immer dasselbe sein, wie bei der Verwendung der Kompositions-Matrix,

66
00:03:30,700 --> 00:03:33,310
die wir für diesen Vektor gefunden haben,

67
00:03:33,310 --> 00:03:35,090
egal, welchen Vektor man nimmt,

68
00:03:35,090 --> 00:03:38,659
zumal diese neue Matrix den gleichen Endeffekt haben muss

69
00:03:38,659 --> 00:03:42,609
wie die Rotation-Dann-Verformung Aktion.

70
00:03:42,609 --> 00:03:44,269
Basierend auf der vorliegenden Schreibweise,

71
00:03:44,269 --> 00:03:49,060
ist es angemessen, die neue Matrix das "Produkt" der beiden ursprünglichen Matrizen zu nennen.

72
00:03:49,060 --> 00:03:50,609
Oder?

73
00:03:50,609 --> 00:03:54,120
Wie man dieses Produkt allgemein berechnet besprechen wir gleich,

74
00:03:54,120 --> 00:03:57,409
aber man verirrt sich viel zu leicht in diesem Zahlenwirrwarr.

75
00:03:57,409 --> 00:04:00,239
Denk immer daran, dass die Multiplikation zweier Matrizen der

76
00:04:00,239 --> 00:04:06,310
geometrischen Anwendung einer Transformation ist, gefolgt von der anderen.

77
00:04:06,310 --> 00:04:10,060
Was hier aber ziemlich komisch ist, ist die Leserichtung von Rechts nach Links;

78
00:04:10,060 --> 00:04:13,730
Man macht erst die Transformation, dargestellt durch die Matrix zur Rechten.

79
00:04:13,730 --> 00:04:17,590
Dann die Transformation, dargestellt durch die Matrix zur Linken.

80
00:04:17,590 --> 00:04:19,600
Das kommt von der Funktions-Schreibweise,

81
00:04:19,600 --> 00:04:21,910
zumal wir Funktionen zur Linken von Variablen schreiben;

82
00:04:21,910 --> 00:04:26,130
Immer wenn du Funktionen zusammenstellst, musst du sie von Rechts nach Links lesen.

83
00:04:26,130 --> 00:04:30,060
Gute Nachricht für die hebräischen Leser, schlechte Nachricht für den Rest von uns.

84
00:04:30,060 --> 00:04:31,850
Lass uns ein anderes Beispiel betrachten.

85
00:04:31,850 --> 00:04:35,450
Nimm eine Matrix mit den Spalten (1, 1) und (-2, 0),

86
00:04:35,450 --> 00:04:38,110
deren Transformation so aussieht,

87
00:04:38,110 --> 00:04:39,760
und wir nennen sie M1.

88
00:04:39,760 --> 00:04:44,050
Jetzt nehmen wir eine Matrix mit den Spalten (0, 1) und (2, 0),

89
00:04:44,050 --> 00:04:47,810
deren Transformation so aussieht,

90
00:04:47,810 --> 00:04:50,010
und wir nennen diese nun M2.

91
00:04:50,010 --> 00:04:53,130
Nach der Anwendung von M1 und dann M2

92
00:04:53,130 --> 00:04:54,690
haben wir eine neue Transformation.

93
00:04:54,690 --> 00:04:56,310
Lass uns deren Matrix herausfinden!

94
00:04:56,310 --> 00:05:00,160
Aber dieses mal schauen wir nicht auf die Animation,

95
00:05:00,160 --> 00:05:04,600
sondern benutzen nur die Zahlen in den einzelnen Matrizen.

96
00:05:04,600 --> 00:05:08,000
Zuerst müssen wir wissen, wo i-hat hingeht.

97
00:05:08,000 --> 00:05:11,200
Nach der Verwendung von M1 sind die neuen Koordinaten von i-hat

98
00:05:11,200 --> 00:05:14,780
- so die Definition - durch die erste Spalte von M1 gegeben;

99
00:05:14,780 --> 00:05:16,920
und zwar (1, 1).

100
00:05:16,920 --> 00:05:20,060
Um zu sehen, was nach M2 passiert,

101
00:05:20,060 --> 00:05:25,810
muss man die Matrix M2 mit dem Vektor (1, 1) multiplizieren.

102
00:05:25,810 --> 00:05:28,180
Nach der Berechnung, wie sie im letzten Video erklärt wurde,

103
00:05:28,180 --> 00:05:30,810
bekommt man den Vektor (2, 1).

104
00:05:30,810 --> 00:05:33,860
Dieser wird die erste Spalte der Kompositions-Matrix.

105
00:05:33,860 --> 00:05:36,300
Gleichermaßen, für j-hat,

106
00:05:36,300 --> 00:05:42,170
beschreibt die zweite Spalte von M1, dass es zunächst auf (-2, 0) landet.

107
00:05:42,170 --> 00:05:48,180
Wenn wir dann M2 an diesen Vektor anwenden,

108
00:05:48,180 --> 00:05:52,740
ergibt das Matrix-Vektor Produkt dieser (0, -2),

109
00:05:52,740 --> 00:05:57,060
was in die zweite Spalte unserer Kompositions-Matrix geschrieben wird.

110
00:05:57,060 --> 00:05:59,590
Lass uns diesen Prozess nochmal durchgehen, aber dieses Mal

111
00:05:59,590 --> 00:06:02,060
nehmen wir variable Einträge in jeder Matrix,

112
00:06:02,060 --> 00:06:05,620
um zu zeigen, dass diese Erklärung auf alle Matrizen zutrifft.

113
00:06:05,620 --> 00:06:08,380
Das ist viel Zeichenlastiger und benötigt mehr Platz,

114
00:06:08,380 --> 00:06:12,460
jedoch wird es ziemlich befriedigend sein für diejenigen, die zuvor schon Matrix Multiplikation

115
00:06:12,460 --> 00:06:14,580
in "geschriebener" Form gelernt haben.

116
00:06:14,580 --> 00:06:16,080
Um i-hat zu folgen,

117
00:06:16,080 --> 00:06:19,180
beginnen wir mit der ersten Spalte von der rechten Matrix,

118
00:06:19,180 --> 00:06:22,440
zumal das der End-Landepunkt für i-hat ist.

119
00:06:22,440 --> 00:06:24,970
Die Multiplikation dieser Spalte mit der Matrix zur Linken

120
00:06:24,970 --> 00:06:29,310
zeigt, wo die zwischenzeitliche Version von i-hat landet, nachdem man die zweite

121
00:06:29,310 --> 00:06:31,080
Transformation angewendet hat.

122
00:06:31,080 --> 00:06:34,000
Die erste Spalte der Kompositions-Matrix ist also

123
00:06:34,000 --> 00:06:40,720
immer gleich der linken Matrix mal der ersten Spalte der rechten Matrix.

124
00:06:40,720 --> 00:06:48,920
Gleichermaßen wird j-hat anfangs immer auf der zweiten Spalte der rechten Matrix landen.

125
00:06:48,920 --> 00:06:54,020
Nach der Multiplikation mit der linken Matrix bekommt man also seine finale Position

126
00:06:54,020 --> 00:06:58,840
und das ist folglich die zweite Spalte der Kompositions-Matrix.

127
00:06:58,840 --> 00:07:02,500
Man sieht, dass hier viele Zeichen sind

128
00:07:02,500 --> 00:07:05,500
und es ist normal, diese Formel zum auswendig-lernen vorgelegt zu bekommen.

129
00:07:05,500 --> 00:07:09,320
Zusammen mit einem algorithmischen Prozess um es sich besser zu merken.

130
00:07:09,320 --> 00:07:12,100
Aber bevor man diesen Prozess auswendig lernt,

131
00:07:12,100 --> 00:07:16,970
sollte man darüber nachdenken, was eine Matrix Multiplikation eigentlich beschreibt:

132
00:07:16,970 --> 00:07:19,670
Anwendung einer Transformation nach der anderen.

133
00:07:19,670 --> 00:07:22,770
Glaub mir, das gibt dir eine viel bessere Gedankenstütze,

134
00:07:22,770 --> 00:07:27,120
um die Eigenschaften von Matrix Multiplikation einfacher zu verstehen.

135
00:07:27,120 --> 00:07:28,340
Zum Beispiel, hier ist eine Frage:

136
00:07:28,340 --> 00:07:33,480
Macht es einen Unterschied, in welcher Reihenfolge wir die Matrizen multiplizieren?

137
00:07:33,480 --> 00:07:36,060
Ok, lass uns an ein einfaches Beispiel denken,

138
00:07:36,060 --> 00:07:37,720
wie das von zuvor:

139
00:07:37,720 --> 00:07:41,450
Mach eine Verformung, welche i-hat fixiert und j-hat nach rechts verzerrt

140
00:07:41,450 --> 00:07:43,670
und dann eine 90°-Rotation.

141
00:07:43,670 --> 00:07:46,480
Wenn man erst verformt und dann rotiert,

142
00:07:46,480 --> 00:07:49,170
ist i-hat nun auf (0, 1)

143
00:07:49,170 --> 00:07:51,300
und j-hat auf (-1, 1);

144
00:07:51,300 --> 00:07:53,970
beide sind in etwa nah bei einander.

145
00:07:53,970 --> 00:07:57,910
Wenn man erst rotiert und dann verformt,

146
00:07:57,910 --> 00:08:00,260
ist i-hat dann auf (1, 1)

147
00:08:00,260 --> 00:08:03,850
und j-hat auf (-1, 0); einer völlig anderen Richtung.

148
00:08:03,850 --> 00:08:06,410
und sie zeigen, naja, viel weiter von einander weg.

149
00:08:06,410 --> 00:08:08,220
Der Endeffekt ist hier eindeutig anders,

150
00:08:08,220 --> 00:08:11,510
also hat die Reihenfolge offensichtlich eine Auswirkung.

151
00:08:11,510 --> 00:08:14,850
Merk dir, dass die Transformation

152
00:08:14,850 --> 00:08:18,330
komplett in deinem Kopf abspielen kann, um sie zu visualisieren.

153
00:08:18,330 --> 00:08:21,780
Man braucht keine Matrix Multiplikation.

154
00:08:21,780 --> 00:08:23,990
Ich weiß noch, als ich das erste mal lineare Algebra hatte:

155
00:08:23,990 --> 00:08:28,250
Es gab ein Hausaufgaben-Problem, bei welchem wir beweisen mussten, dass Matrix Multiplikationen

156
00:08:28,250 --> 00:08:29,740
assoziativ sind.

157
00:08:29,740 --> 00:08:32,839
Das heißt, wenn man drei Matrizen A, B, und C hat

158
00:08:32,839 --> 00:08:34,639
und man alle miteinander multipliziert,

159
00:08:34,639 --> 00:08:39,810
ist es egal, ob man zuerst A mal B und dann das Ergebnis mal C berechnet

160
00:08:39,810 --> 00:08:45,029
oder ob man zuert B mal C multipliziert und das Ergebnis dann mal A nimmt.

161
00:08:45,029 --> 00:08:48,240
In anderen Worten: Es ist egal, wo die Klammern stehen.

162
00:08:48,240 --> 00:08:50,670
Wenn du das nun versuchst, numerisch zu erarbeiten,

163
00:08:50,670 --> 00:08:52,449
wie ich es zuvor gemacht habe:

164
00:08:52,449 --> 00:08:56,399
es ist schrecklich, einfach schrecklich und  unnütz in diesem Fall.

165
00:08:56,399 --> 00:09:01,350
Aber wenn man Matrix Multiplikation als angewandte Transformation nach der anderen sieht,

166
00:09:01,350 --> 00:09:03,420
ist diese Eigenschaft nur belanglos.

167
00:09:03,420 --> 00:09:05,029
Erkennst du warum?

168
00:09:05,029 --> 00:09:09,620
Da heißt: Wenn man erst C anwendet, dann B und dann A,

169
00:09:09,620 --> 00:09:13,019
ist es das gleiche wie C, dann B, dann A.

170
00:09:13,019 --> 00:09:14,620
Eigentlich muss man da nichts beweisen,

171
00:09:14,620 --> 00:09:19,660
man wendet einfach die gleichen drei Dinge eins nach dem anderen an. In der gleichen Reihenfolge.

172
00:09:19,660 --> 00:09:20,970
Es kommt einem vielleicht wie Schummeln vor.

173
00:09:20,970 --> 00:09:22,040
Aber ist es nicht!

174
00:09:22,040 --> 00:09:26,339
Das ist ein echter Beweis dafür, dass Matrix Multiplikation assoziativ ist

175
00:09:26,339 --> 00:09:31,329
und darüber hinaus ist es eine gute Erklärung dafür, warum es wahr sein muss.

176
00:09:31,329 --> 00:09:34,589
Ich empfehle euch wirklich, mit dieser Idee weiter herumzuspielen:

177
00:09:34,589 --> 00:09:36,810
Vorstellung zweier verschiedener Transformationen;

178
00:09:36,810 --> 00:09:39,740
Nachdenken darüber, was nach der Anwendung nacheinander passiert;

179
00:09:39,740 --> 00:09:42,020
Und dann das Matrix Produkt numerisch ausarbeiten.

180
00:09:42,020 --> 00:09:47,339
Vertraue mir, diese Art von Spielchen machen die Idee erst richtig verständlich.

181
00:09:47,339 --> 00:09:54,670
Im nächsten Video werde ich beginnen, diese Ideen über die zwei Dimensionen zu erweitern.

182
00:09:54,670 --> 00:10:00,429
Bis dann!

