[
 {
  "input": "Hey everyone, where we last left off, I showed what linear transformations look like and how to represent them using matrices. ",
  "translatedText": "سلام به همه، جایی که آخرین بار آن را متوقف کردیم، نشان دادم که تبدیل های خطی چگونه هستند و چگونه می توان آنها را با استفاده از ماتریس ها نشان داد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.94,
  "end": 16.88
 },
 {
  "input": "This is worth a quick recap because it's just really important, but of course if this feels like more than just a recap, go back and watch the full video. ",
  "translatedText": "این ارزش یک خلاصه‌نویسی سریع را دارد، زیرا واقعاً مهم است، اما البته اگر چیزی بیش از یک خلاصه‌نویسی ساده به نظر می‌رسد، به عقب برگردید و ویدیوی کامل را تماشا کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 18.32,
  "end": 25.14
 },
 {
  "input": "Generally speaking, linear transformations are functions with vectors as inputs and vectors as outputs, but I showed last time how we can think about them visually as smooshing around space in such a way that grid lines stay parallel and evenly spaced, and so that the origin remains fixed. ",
  "translatedText": "به طور کلی، تبدیل های خطی توابعی هستند با بردارها به عنوان ورودی و بردارها به عنوان خروجی، اما من آخرین بار نشان دادم که چگونه می توانیم به صورت بصری در مورد آنها فکر کنیم، به گونه ای که خطوط شبکه موازی و با فاصله یکسان باقی بمانند و مبدأ ثابت باقی می ماند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 25.78,
  "end": 41.18
 },
 {
  "input": "The key takeaway was that a linear transformation is completely determined by where it takes the basis vectors of the space, which for two dimensions means i-hat and j-hat. ",
  "translatedText": "نکته کلیدی این بود که یک تبدیل خطی کاملاً توسط بردارهای پایه فضا تعیین می شود که برای دو بعد به معنی i-hat و j-hat است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 41.82,
  "end": 51.34
 },
 {
  "input": "This is because any other vector could be described as a linear combination of those basis vectors. ",
  "translatedText": "این به این دلیل است که هر بردار دیگری را می توان به عنوان ترکیبی خطی از آن بردارهای پایه توصیف کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.34,
  "end": 57.34
 },
 {
  "input": "A vector with coordinates x, y is x times i-hat plus y times j-hat. ",
  "translatedText": "بردار با مختصات x، y x ضربدر i-hat به اضافه y ضربدر j-hat است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 57.94,
  "end": 62.34
 },
 {
  "input": "After going through the transformation, this property that grid lines remain parallel and evenly spaced has a wonderful consequence. ",
  "translatedText": "پس از گذر از تبدیل، این ویژگی که خطوط شبکه موازی و با فواصل مساوی باقی می مانند، پیامد شگفت انگیزی دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 63.46,
  "end": 69.86
 },
 {
  "input": "The place where your vector lands will be x times the transformed version of i-hat plus y times the transformed version of j-hat. ",
  "translatedText": "مکانی که بردار شما در آن قرار می گیرد x برابر نسخه تبدیل شده i-hat به اضافه y برابر نسخه تبدیل شده j-hat خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 70.5,
  "end": 77.56
 },
 {
  "input": "This means if you keep a record of the coordinates where i-hat lands and the coordinates where j-hat lands, you can compute that a vector which starts at x, y must land on x times the new coordinates of i-hat plus y times the new coordinates of j-hat. ",
  "translatedText": "این بدان معناست که اگر شما یک رکورد از مختصات جایی که i-hat فرود می آید و مختصات جایی که j-hat فرود می آید، نگه دارید، می توانید محاسبه کنید که برداری که از x شروع می شود، y باید روی x برابر مختصات جدید i-hat به اضافه y فرود بیاید. برابر مختصات جدید j-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.24,
  "end": 92.72
 },
 {
  "input": "The convention is to record the coordinates of where i-hat and j-hat land as the columns of a matrix, and to define this sum of the scaled versions of those columns by x and y to be matrix-vector multiplication. ",
  "translatedText": "قرارداد این است که مختصات جایی که i-hat و j-hat فرود می آیند به عنوان ستون های یک ماتریس ثبت شود و این مجموع نسخه های مقیاس شده آن ستون ها توسط x و y به عنوان ضرب ماتریس-بردار تعریف شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 93.56,
  "end": 105.36
 },
 {
  "input": "In this way, a matrix represents a specific linear transformation, and multiplying a matrix by a vector is what it means computationally to apply that transformation to that vector. ",
  "translatedText": "به این ترتیب، یک ماتریس یک تبدیل خطی خاص را نشان می‌دهد، و ضرب یک ماتریس در یک بردار، معنای محاسباتی اعمال آن تبدیل به آن بردار است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.05,
  "end": 117.08
 },
 {
  "input": "Alright, recap over, on to the new stuff. ",
  "translatedText": "بسیار خوب، خلاصه، در مورد چیزهای جدید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 118.8,
  "end": 120.88
 },
 {
  "input": "Oftentimes you find yourself wanting to describe the effects of applying one transformation and then another. ",
  "translatedText": "اغلب اوقات شما می خواهید اثرات اعمال یک تبدیل و سپس تغییر دیگری را توصیف کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 121.6,
  "end": 127.0
 },
 {
  "input": "For example, maybe you want to describe what happens when you first rotate the plane 90 degrees counterclockwise, then apply a shear. ",
  "translatedText": "برای مثال، شاید بخواهید توضیح دهید که وقتی هواپیما را ابتدا 90 درجه خلاف جهت عقربه‌های ساعت می‌چرخانید، سپس یک برش را اعمال می‌کنید، چه اتفاقی می‌افتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 127.62,
  "end": 134.48
 },
 {
  "input": "The overall effect here, from start to finish, is another linear transformation, distinct from the rotation and the shear. ",
  "translatedText": "اثر کلی در اینجا، از ابتدا تا انتها، تبدیل خطی دیگری است که از چرخش و برش متمایز است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 135.26,
  "end": 141.8
 },
 {
  "input": "This new linear transformation is commonly called the composition of the two separate transformations we applied. ",
  "translatedText": "این تبدیل خطی جدید معمولاً ترکیب دو تبدیل جداگانه ای که ما اعمال کردیم نامیده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 142.28,
  "end": 148.22
 },
 {
  "input": "And like any linear transformation, it can be described with a matrix all of its own by following i-hat and j-hat. ",
  "translatedText": "و مانند هر تبدیل خطی، می توان آن را با یک ماتریس تماماً با پیروی از i-hat و j-hat توصیف کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.92,
  "end": 155.44
 },
 {
  "input": "In this example, the ultimate landing spot for i-hat after both transformations is 1,1, so let's make that the first column of a matrix. ",
  "translatedText": "در این مثال، نقطه فرود نهایی برای i-hat پس از هر دو تبدیل، 1،1 است، بنابراین بیایید آن را اولین ستون ماتریس کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 156.02,
  "end": 164.12
 },
 {
  "input": "Likewise, j-hat ultimately ends up at the location negative 1,0, so we make that the second column of the matrix. ",
  "translatedText": "به همین ترتیب، j-hat در نهایت به مکان منفی 1،0 ختم می شود، بنابراین ما آن را ستون دوم ماتریس می کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.96,
  "end": 171.86
 },
 {
  "input": "This new matrix captures the overall effect of applying a rotation then a shear, but as one single action, rather than two successive ones. ",
  "translatedText": "این ماتریس جدید اثر کلی اعمال یک چرخش و سپس یک برش را به تصویر می‌کشد، اما به‌عنوان یک عمل واحد، به جای دو حرکت متوالی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 172.68,
  "end": 181.34
 },
 {
  "input": "Here's one way to think about that new matrix. ",
  "translatedText": "در اینجا یک راه برای فکر کردن در مورد آن ماتریس جدید وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 183.04,
  "end": 184.88
 },
 {
  "input": "If you were to take some vector and pump it through the rotation, then the shear, the long way to compute where it ends up is to first multiply it on the left by the rotation matrix. ",
  "translatedText": "اگر قرار بود مقداری بردار بگیرید و آن را از طریق چرخش پمپ کنید، سپس برش، راه طولانی برای محاسبه جایی که به پایان می رسد این است که ابتدا آن را در سمت چپ در ماتریس چرخش ضرب کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 185.42,
  "end": 194.82
 },
 {
  "input": "Then, take whatever you get and multiply that on the left by the shear matrix. ",
  "translatedText": "سپس، هر چه به دست می آورید را بردارید و آن را در سمت چپ در ماتریس برشی ضرب کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 195.32,
  "end": 199.8
 },
 {
  "input": "This is, numerically speaking, what it means to apply a rotation then a shear to a given vector. ",
  "translatedText": "از نظر عددی، این به معنای اعمال چرخش و سپس برش بر بردار معین است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.46,
  "end": 206.06
 },
 {
  "input": "But whatever you get should be the same as just applying this new composition matrix that we just found by that same vector, no matter what vector you chose, since this new matrix is supposed to capture the same overall effect as the rotation then shear action. ",
  "translatedText": "اما هر چیزی که به دست می آورید باید مانند استفاده از این ماتریس ترکیب جدید باشد که ما به تازگی با همان بردار پیدا کردیم، صرف نظر از اینکه چه برداری را انتخاب می کنید، زیرا این ماتریس جدید قرار است همان اثر کلی را به عنوان عمل چرخش و سپس برش ثبت کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 206.8,
  "end": 220.98
 },
 {
  "input": "Based on how things are written down here, I think it's reasonable to call this new matrix the product of the original two matrices, don't you? ",
  "translatedText": "بر اساس نحوه نوشتن موارد در اینجا، به نظر من منطقی است که این ماتریس جدید را حاصل ضرب دو ماتریس اصلی بنامیم، نه؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.48,
  "end": 229.38
 },
 {
  "input": "We can think about how to compute that product more generally in just a moment, but it's way too easy to get lost in the forest of numbers. ",
  "translatedText": "ما می‌توانیم به این فکر کنیم که چگونه آن محصول را به طور کلی در یک لحظه محاسبه کنیم، اما گم شدن در جنگل اعداد بسیار آسان است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 230.42,
  "end": 236.6
 },
 {
  "input": "Always remember that multiplying two matrices like this has the geometric meaning of applying one transformation then another. ",
  "translatedText": "همیشه به یاد داشته باشید که ضرب دو ماتریس مانند این به معنای هندسی اعمال یک تبدیل و تبدیل دیگر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.6,
  "end": 244.28
 },
 {
  "input": "One thing that's kind of weird here is that this has us reading from right to left. ",
  "translatedText": "یکی از چیزهایی که در اینجا به نوعی عجیب است این است که ما را وادار به خواندن از راست به چپ می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 245.86,
  "end": 249.66
 },
 {
  "input": "You first apply the transformation represented by the matrix on the right, then you apply the transformation represented by the matrix on the left. ",
  "translatedText": "شما ابتدا تبدیلی را که توسط ماتریس سمت راست نشان داده شده است اعمال می کنید، سپس تبدیلی که توسط ماتریس سمت چپ نشان داده شده است را اعمال می کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.04,
  "end": 256.72
 },
 {
  "input": "This stems from function notation, since we write functions on the left of variables, so every time you compose two functions, you always have to read it right to left. ",
  "translatedText": "این از نشانه گذاری تابع ناشی می شود، زیرا ما توابع را در سمت چپ متغیرها می نویسیم، بنابراین هر بار که دو تابع را می سازید، همیشه باید آن را از راست به چپ بخوانید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 257.4,
  "end": 265.46
 },
 {
  "input": "Good news for the Hebrew readers, bad news for the rest of us. ",
  "translatedText": "خبر خوب برای خوانندگان عبری، خبر بد برای بقیه ما. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.92,
  "end": 268.98
 },
 {
  "input": "Let's look at another example. ",
  "translatedText": "بیایید به مثال دیگری نگاه کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 269.88,
  "end": 271.1
 },
 {
  "input": "Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this. ",
  "translatedText": "ماتریسی با ستون های 1،1 و منفی 2،0 را در نظر بگیرید که تبدیل آن به این شکل است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 271.76,
  "end": 276.86
 },
 {
  "input": "And let's call it m1. ",
  "translatedText": "و بیایید آن را m1 بنامیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.98,
  "end": 279.06
 },
 {
  "input": "Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this. ",
  "translatedText": "بعد، ماتریسی را با ستون های 0،1 و 2،0 بگیرید، که تبدیل آن به این شکل است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 280.1,
  "end": 285.7
 },
 {
  "input": "And let's call that guy m2. ",
  "translatedText": "و بیایید آن مرد را m2 صدا کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 287.52,
  "end": 289.24
 },
 {
  "input": "The total effect of applying m1 then m2 gives us a new transformation, so let's find its matrix. ",
  "translatedText": "اثر کل اعمال m1 و سپس m2 یک تبدیل جدید به ما می دهد، پس بیایید ماتریس آن را پیدا کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 289.92,
  "end": 295.68
 },
 {
  "input": "But this time, let's see if we can do it without watching the animations, and instead just using the numerical entries in each matrix. ",
  "translatedText": "اما این بار، بیایید ببینیم که آیا می‌توانیم این کار را بدون تماشای انیمیشن‌ها انجام دهیم و در عوض فقط از ورودی‌های عددی در هر ماتریس استفاده کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 296.28,
  "end": 303.86
 },
 {
  "input": "First, we need to figure out where i-hat goes. ",
  "translatedText": "ابتدا باید بفهمیم i-hat کجا می رود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.74,
  "end": 307.14
 },
 {
  "input": "After applying m1, the new coordinates of i-hat, by definition, are given by that first column of m1, namely 1,1. ",
  "translatedText": "پس از اعمال m1، مختصات جدید i-hat، طبق تعریف، توسط اولین ستون m1، یعنی 1،1 داده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.04,
  "end": 315.98
 },
 {
  "input": "To see what happens after applying m2, multiply the matrix for m2 by that vector 1,1. ",
  "translatedText": "برای اینکه ببینید بعد از اعمال m2 چه اتفاقی می افتد، ماتریس m2 را در آن بردار 1،1 ضرب کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 316.78,
  "end": 323.5
 },
 {
  "input": "Working it out, the way I described last video, you'll get the vector 2,1. ",
  "translatedText": "با کار کردن، به روشی که آخرین ویدیو را توضیح دادم، وکتور 2،1 را دریافت خواهید کرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.3,
  "end": 329.88
 },
 {
  "input": "This will be the first column of the composition matrix. ",
  "translatedText": "این اولین ستون ماتریس ترکیب خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.7,
  "end": 333.1
 },
 {
  "input": "Likewise, to follow j-hat, the second column of m1 tells us that it first lands on negative 2,0. ",
  "translatedText": "به همین ترتیب، برای دنبال کردن j-hat، ستون دوم m1 به ما می گوید که ابتدا روی منفی 2،0 قرار می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 334.52,
  "end": 340.54
 },
 {
  "input": "Then, when we apply m2 to that vector, you can work out the matrix vector product to get 0, negative 2, which becomes the second column of our composition matrix. ",
  "translatedText": "سپس، هنگامی که m2 را به آن بردار اعمال می کنیم، می توانید حاصل ضرب بردار ماتریس را محاسبه کنید تا 0، منفی 2 را بدست آورید که تبدیل به ستون دوم ماتریس ترکیب ما می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 342.7,
  "end": 355.2
 },
 {
  "input": "Let me talk through that same process again, but this time I'll show variable entries in each matrix, just to show that the same line of reasoning works for any matrices. ",
  "translatedText": "اجازه دهید دوباره درباره همان فرآیند صحبت کنم، اما این بار ورودی های متغیر را در هر ماتریس نشان می دهم، فقط برای اینکه نشان دهم که همان خط استدلال برای هر ماتریس کار می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 356.64,
  "end": 364.92
 },
 {
  "input": "This is more symbol-heavy and will require some more room, but it should be pretty satisfying for anyone who has previously been taught matrix multiplication the more rote way. ",
  "translatedText": "این کار نمادهای سنگین‌تری دارد و به فضای بیشتری نیاز دارد، اما برای هر کسی که قبلاً ضرب ماتریس را به روش ساده‌تر آموزش داده است، باید رضایت‌بخش باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 365.54,
  "end": 373.66
 },
 {
  "input": "To follow where i-hat goes, start by looking at the first column of the matrix on the right, since this is where i-hat initially lands. ",
  "translatedText": "برای دنبال کردن جایی که i-hat می رود، با نگاه کردن به اولین ستون ماتریس در سمت راست شروع کنید، زیرا i-hat ابتدا در اینجا قرار می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 374.46,
  "end": 381.06
 },
 {
  "input": "Multiplying that column by the matrix on the left is how you can tell where the intermediate version of i-hat ends up after applying the second transformation. ",
  "translatedText": "ضرب آن ستون در ماتریس سمت چپ این است که چگونه می توانید بفهمید که نسخه میانی i-hat پس از اعمال تبدیل دوم به کجا ختم می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 382.0,
  "end": 390.3
 },
 {
  "input": "So the first column of the composition matrix will always equal the left matrix times the first column of the right matrix. ",
  "translatedText": "بنابراین ستون اول ماتریس ترکیب همیشه برابر ماتریس چپ ضربدر ستون اول ماتریس سمت راست خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 391.62,
  "end": 398.1
 },
 {
  "input": "Likewise, j-hat will always initially land on the second column of the right matrix. ",
  "translatedText": "به همین ترتیب، j-hat همیشه در ابتدا در ستون دوم ماتریس سمت راست قرار می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 402.16,
  "end": 407.14
 },
 {
  "input": "So multiplying the left matrix by this second column will give its final location, and hence that's the second column of the composition matrix. ",
  "translatedText": "بنابراین ضرب ماتریس سمت چپ در این ستون دوم مکان نهایی آن را نشان می دهد، و از این رو این ستون دوم ماتریس ترکیب است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.94,
  "end": 417.02
 },
 {
  "input": "Notice there's a lot of symbols here, and it's common to be taught this formula as something to memorize, along with a certain algorithmic process to kind of help remember it. ",
  "translatedText": "توجه داشته باشید که نمادهای زیادی در اینجا وجود دارد، و معمولاً این فرمول به عنوان چیزی برای حفظ کردن، همراه با یک فرآیند الگوریتمی خاص برای کمک به یادآوری آن آموزش داده می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 420.62,
  "end": 429.04
 },
 {
  "input": "But I really do think that before memorizing that process, you should get in the habit of thinking about what matrix multiplication really represents, applying one transformation after another. ",
  "translatedText": "اما من واقعاً فکر می‌کنم که قبل از به خاطر سپردن آن فرآیند، باید عادت کنید که به این فکر کنید که ضرب ماتریس واقعاً چه چیزی را نشان می‌دهد و تبدیل‌ها را یکی پس از دیگری اعمال کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 429.16,
  "end": 438.9
 },
 {
  "input": "Trust me, this will give you a much better conceptual framework that makes the properties of matrix multiplication much easier to understand. ",
  "translatedText": "به من اعتماد کنید، این چارچوب مفهومی بسیار بهتری به شما می دهد که درک خواص ضرب ماتریس را بسیار آسان تر می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.62,
  "end": 446.3
 },
 {
  "input": "For example, here's a question. ",
  "translatedText": "به عنوان مثال، اینجا یک سوال است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 447.06,
  "end": 448.36
 },
 {
  "input": "Does it matter what order we put the two matrices in when we multiply them? ",
  "translatedText": "آیا وقتی دو ماتریس را ضرب می کنیم به چه ترتیبی قرار می دهیم مهم است؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.88,
  "end": 452.84
 },
 {
  "input": "Well, let's think through a simple example, like the one from earlier. ",
  "translatedText": "خوب، بیایید از طریق یک مثال ساده، مانند نمونه قبلی، فکر کنیم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.62,
  "end": 457.0
 },
 {
  "input": "Take a shear, which fixes i-hat and smushes j-hat over to the right, and a 90 degree rotation. ",
  "translatedText": "یک قیچی بگیرید که i-hat را ثابت می کند و j-hat را به سمت راست می چرخاند و یک چرخش 90 درجه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.64,
  "end": 462.82
 },
 {
  "input": "If you first do the shear, then rotate, we can see that i-hat ends up at 0,1 and j-hat ends up at negative 1,1. ",
  "translatedText": "اگر ابتدا برش را انجام دهید، سپس بچرخانید، می بینیم که i-hat به 0,1 و j-hat به منفی 1,1 ختم می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.6,
  "end": 470.96
 },
 {
  "input": "Both are generally pointing close together. ",
  "translatedText": "هر دو به طور کلی به هم نزدیک هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.32,
  "end": 473.06
 },
 {
  "input": "If you first rotate, then do the shear, i-hat ends up over at 1,1, and j-hat is off in a different direction at negative 1,0, and they're pointing farther apart. ",
  "translatedText": "اگر ابتدا بچرخانید، سپس برش را انجام دهید، i-hat در 1،1 به پایان می رسد، و j-hat در جهت دیگری در منفی 1.0 خاموش است، و آنها دورتر از هم را نشان می دهند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 473.86,
  "end": 485.52
 },
 {
  "input": "The overall effect here is clearly different, so evidently order totally does matter. ",
  "translatedText": "تأثیر کلی در اینجا به وضوح متفاوت است، بنابراین واضح است که نظم کاملاً مهم است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.38,
  "end": 490.66
 },
 {
  "input": "Notice by thinking in terms of transformations, that's the kind of thing you can do in your head by visualizing. ",
  "translatedText": "با فکر کردن در مورد تحولات توجه کنید، این همان کاری است که می توانید با تجسم در ذهن خود انجام دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 492.2,
  "end": 497.84
 },
 {
  "input": "No matrix multiplication necessary. ",
  "translatedText": "نیازی به ضرب ماتریس نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 498.22,
  "end": 499.9
 },
 {
  "input": "I remember when I first took linear algebra, there was this one homework problem that asked us to prove that matrix multiplication is associative. ",
  "translatedText": "به یاد دارم وقتی برای اولین بار جبر خطی را گرفتم، این یک تکلیف وجود داشت که از ما می خواست ثابت کنیم که ضرب ماتریس تداعی کننده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 501.48,
  "end": 509.12
 },
 {
  "input": "This means that if you have three matrices, A, B, and C, and you multiply them all together, it shouldn't matter if you first compute A times B, then multiply the result by C, or if you first multiply B times C, then multiply that result by A on the left. ",
  "translatedText": "این بدان معناست که اگر سه ماتریس A، B و C دارید و همه آنها را با هم ضرب کنید، مهم نیست که ابتدا A را ضربدر B کنید، سپس نتیجه را در C ضرب کنید، یا اگر ابتدا B را ضرب کنید. C، سپس آن نتیجه را در A در سمت چپ ضرب کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.56,
  "end": 524.36
 },
 {
  "input": "In other words, it doesn't matter where you put the parentheses. ",
  "translatedText": "به عبارت دیگر فرقی نمی کند پرانتز را کجا قرار دهید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 524.94,
  "end": 527.4
 },
 {
  "input": "Now, if you try to work through this numerically, like I did back then, it's horrible, just horrible, and unenlightening for that matter. ",
  "translatedText": "حالا، اگر بخواهید از نظر عددی این موضوع را حل کنید، مانند آنچه من در آن زمان انجام دادم، وحشتناک است، فقط وحشتناک است، و برای آن موضوع غیر روشنگر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 528.38,
  "end": 535.76
 },
 {
  "input": "But when you think about matrix multiplication as applying one transformation after another, this property is just trivial. ",
  "translatedText": "اما وقتی در مورد ضرب ماتریس به عنوان اعمال تبدیل یکی پس از دیگری فکر می کنید، این ویژگی فقط بی اهمیت است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 542.78
 },
 {
  "input": "Can you see why? ",
  "translatedText": "می توانید ببینید چرا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.3,
  "end": 544.0
 },
 {
  "input": "What it's saying is that if you first apply C then B, then A, it's the same as applying C, then B, then A. ",
  "translatedText": "چیزی که می گوید این است که اگر ابتدا C را اعمال کنید سپس B، سپس A را اعمال کنید، مانند اعمال C، سپس B، سپس A است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.86,
  "end": 552.38
 },
 {
  "input": "I mean, there's nothing to prove, you're just applying the same three things one after the other, all in the same order. ",
  "translatedText": "منظورم این است که چیزی برای اثبات وجود ندارد، شما فقط سه مورد را یکی پس از دیگری به کار می برید، همه به یک ترتیب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 552.82,
  "end": 558.66
 },
 {
  "input": "This might feel like cheating, but it's not. ",
  "translatedText": "این ممکن است شبیه تقلب باشد، اما اینطور نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 559.46,
  "end": 561.54
 },
 {
  "input": "This is an honest-to-goodness proof that matrix multiplication is associative. ",
  "translatedText": "این یک اثبات صادقانه به خوبی است که ضرب ماتریس تداعی کننده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.54,
  "end": 565.9
 },
 {
  "input": "And even better than that, it's a good explanation for why that property should be true. ",
  "translatedText": "و حتی بهتر از آن، توضیح خوبی برای این است که چرا آن ویژگی باید درست باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 565.9,
  "end": 570.68
 },
 {
  "input": "I really do encourage you to play around more with this idea, imagining two different transformations, thinking about what happens when you apply one after the other, and then working out the matrix product numerically. ",
  "translatedText": "من واقعاً شما را تشویق می‌کنم که بیشتر با این ایده بازی کنید، دو دگرگونی متفاوت را تصور کنید، به این فکر کنید که وقتی یکی پس از دیگری اعمال می‌کنید چه اتفاقی می‌افتد، و سپس محصول ماتریس را به صورت عددی بررسی کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.56,
  "end": 582.14
 },
 {
  "input": "Trust me, this is the kind of playtime that really makes the idea sink in. ",
  "translatedText": "به من اعتماد کنید، این نوع زمان بازی است که واقعاً ایده را در ذهن فرو می برد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.6,
  "end": 586.44
 },
 {
  "input": "In the next video, I'll start talking about extending these ideas beyond just two dimensions. ",
  "translatedText": "در ویدیوی بعدی، صحبت در مورد گسترش این ایده ها فراتر از دو بعد را شروع می کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 587.2,
  "end": 591.42
 },
 {
  "input": "See you then! ",
  "translatedText": "بعدا می بینمت! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.02,
  "end": 592.18
 }
]