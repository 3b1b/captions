[
 {
  "input": "I'd like to revisit a deceptively simple question that I asked in the very first video of this series.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   17.081,
   22.8
  ]
 },
 {
  "input": "What are vectors?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   22.8,
   24.6
  ]
 },
 {
  "input": "Is a two-dimensional vector, for example, fundamentally an arrow on a flat plane that we can describe with coordinates for convenience?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   24.6,
   31.28
  ]
 },
 {
  "input": "Or is it fundamentally that pair of real numbers which is just nicely visualized as an arrow on a flat plane?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   31.28,
   38.68
  ]
 },
 {
  "input": "Or are both of these just manifestations of something deeper?",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   38.68,
   42.4
  ]
 },
 {
  "input": "On the one hand, defining vectors as primarily being a list of numbers feels clear-cut and unambiguous.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   42.4,
   48.8
  ]
 },
 {
  "input": "It makes things like four-dimensional vectors or 100-dimensional vectors sound like real, concrete ideas that you can actually work with, when otherwise an idea like four dimensions is just a vague geometric notion that's difficult to describe without waving your hands a bit.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   48.8,
   65.72
  ]
 },
 {
  "input": "But on the other hand, a common sensation for those who actually work with linear algebra, especially as you get more fluent with changing your basis, is that you're dealing with a space that exists independently from the coordinates that you give it, and that coordinates are actually somewhat arbitrary, depending on what you happen to choose as your basis vectors.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   65.72,
   84.72
  ]
 },
 {
  "input": "More topics in linear algebra, like determinants and eigenvectors, seem indifferent to your choice of coordinate systems.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   84.72,
   91.4
  ]
 },
 {
  "input": "The determinant tells you how much a transformation scales areas, and eigenvectors are the ones that stay on their own span during a transformation.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   91.4,
   100.16
  ]
 },
 {
  "input": "But both of these properties are inherently spatial, and you can freely change your coordinate system without changing the underlying values of either one.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   100.16,
   111.22
  ]
 },
 {
  "input": "But if vectors are not fundamentally lists of real numbers, and if their underlying essence is something more spatial, that just begs the question of what mathematicians mean when they use a word like space or spatial.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   111.22,
   123.48
  ]
 },
 {
  "input": "To build up to where this is going, I'd actually like to spend the bulk of this video talking about something which is neither an arrow nor a list of numbers, but also has vector-ish qualities, functions.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   123.48,
   134.14
  ]
 },
 {
  "input": "You see, there's a sense in which functions are actually just another type of vector.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   134.14,
   139.82
  ]
 },
 {
  "input": "In the same way that you can add two vectors together, there's also a sensible notion for adding two functions, f and g, to get a new function, f plus g.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   139.82,
   148.42
  ]
 },
 {
  "input": "It's one of those things where you kind of already know what it's going to be, but actually phrasing it is a mouthful.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   148.42,
   154.02
  ]
 },
 {
  "input": "The output of this new function at any given input, like negative four, is the sum of the outputs of f and g when you evaluate them each at that same input, negative four.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   154.02,
   165.58
  ]
 },
 {
  "input": "Or more generally, the value of the sum function at any given input x is the sum of the values f of x plus g of x.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   165.58,
   181.18
  ]
 },
 {
  "input": "This is pretty similar to adding vectors coordinate by coordinate.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   181.18,
   184.42
  ]
 },
 {
  "input": "It's just that there are, in a sense, infinitely many coordinates to deal with.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   184.42,
   188.34
  ]
 },
 {
  "input": "Similarly, there's a sensible notion for scaling a function by a real number.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   188.34,
   195.74
  ]
 },
 {
  "input": "Just scale all of the outputs by that number.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   195.74,
   200.34
  ]
 },
 {
  "input": "And again, this is analogous to scaling a vector coordinate by coordinate.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   200.34,
   204.14
  ]
 },
 {
  "input": "It just feels like there's infinitely many coordinates.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   204.14,
   207.78
  ]
 },
 {
  "input": "Now, given that the only thing vectors can really do is get added together or scaled, it feels like we should be able to take the same useful constructs and problem-solving techniques of linear algebra that were originally thought about in the context of arrows and space and apply them to functions as well.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   207.78,
   226.62
  ]
 },
 {
  "input": "For example, there's a perfectly reasonable notion of a linear transformation for functions, something that takes in one function and turns it into another.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   226.62,
   240.1
  ]
 },
 {
  "input": "One familiar example comes from calculus, the derivative.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   240.1,
   243.72
  ]
 },
 {
  "input": "It's something which transforms one function into another function.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   243.72,
   248.8
  ]
 },
 {
  "input": "Sometimes in this context, you'll hear these called operators instead of transformations, but the meaning is the same.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   248.8,
   256.36
  ]
 },
 {
  "input": "A natural question you might want to ask is what it means for a transformation of functions to be linear.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   256.36,
   262.48
  ]
 },
 {
  "input": "The formal definition of linearity is relatively abstract and symbolically driven compared to the way that I first talked about it in chapter 3 of this series.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   262.48,
   271.1
  ]
 },
 {
  "input": "But the reward of abstractness is that we'll get something general enough to apply to functions as well as arrows.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   271.1,
   279.14
  ]
 },
 {
  "input": "A transformation is linear if it satisfies two properties, commonly called additivity and scaling.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   279.14,
   286.46
  ]
 },
 {
  "input": "Additivity means that if you add two vectors, v and w, then apply a transformation to their sum, you get the same result as if you added the transformed versions of v and w.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   286.46,
   300.1
  ]
 },
 {
  "input": "The scaling property is that when you scale a vector v by some number, then apply the transformation, you get the same ultimate vector as if you scaled the transformed version of v by that same amount.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   300.1,
   321.96
  ]
 },
 {
  "input": "The way you'll often hear this described is that linear transformations preserve the operations of vector addition and scalar multiplication.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   321.96,
   332.48
  ]
 },
 {
  "input": "The idea of gridlines remaining parallel and evenly spaced that I've talked about in past videos is really just an illustration of what these two properties mean in the specific case of points in 2D space.",
  "model": "nmt",
  "translatedText": "میں ایک فریب دینے والے سادہ سوال پر نظرثانی کرنا چاہوں گا جو میں نے اس سیریز کی پہلی ویڈیو میں پوچھا تھا۔ ویکٹر کیا ہیں؟ کیا ایک دو جہتی ویکٹر، مثال کے طور پر، بنیادی طور پر فلیٹ جہاز پر ایک تیر ہے جسے ہم سہولت کے لیے نقاط کے ساتھ بیان کر سکتے ہیں؟ یا کیا یہ بنیادی طور پر حقیقی اعداد کا وہ جوڑا ہے جو فلیٹ ہوائی جہاز پر تیر کے طور پر صرف اچھی طرح سے تصور کیا جاتا ہے؟ یا یہ دونوں محض کسی گہری چیز کے مظہر ہیں؟ ایک طرف، ویکٹر کو بنیادی طور پر اعداد کی فہرست کے طور پر بیان کرنا واضح اور غیر مبہم محسوس ہوتا ہے۔ یہ چار جہتی ویکٹر یا 100 جہتی ویکٹر جیسی چیزوں کو حقیقی، ٹھوس آئیڈیاز کی طرح بناتا ہے جن کے ساتھ آپ حقیقت میں کام کر سکتے ہیں، جب کہ بصورت دیگر چار جہتی جیسا خیال محض ایک مبہم ہندسی تصور ہے جسے اپنے ہاتھ ہلائے بغیر بیان کرنا مشکل ہے۔ لیکن دوسری طرف، ان لوگوں کے لیے ایک عام احساس جو حقیقت میں لکیری الجبرا کے ساتھ کام کرتے ہیں، خاص طور پر جب آپ اپنی بنیاد کو تبدیل کرنے میں زیادہ روانی حاصل کرتے ہیں، یہ ہے کہ آپ ایک ایسی جگہ کے ساتھ معاملہ کر رہے ہیں جو آپ کے فراہم کردہ نقاط سے آزادانہ طور پر موجود ہے، اور وہ نقاط دراصل کسی حد تک صوابدیدی ہیں، اس بات پر منحصر ہے کہ آپ اپنے بنیادی ویکٹر کے طور پر کیا انتخاب کرتے ہیں۔ لکیری الجبرا میں مزید عنوانات، جیسے تعین کرنے والے اور ایجین ویکٹر، آپ کے کوآرڈینیٹ سسٹمز کے انتخاب سے لاتعلق نظر آتے ہیں۔ تعین کنندہ آپ کو بتاتا ہے کہ ایک تبدیلی کے پیمانے پر کتنے حصے ہوتے ہیں، اور eigenvectors وہ ہوتے ہیں جو تبدیلی کے دوران اپنی مدت پر قائم رہتے ہیں۔ لیکن یہ دونوں خصوصیات فطری طور پر مقامی ہیں، اور آپ کسی ایک کی بنیادی اقدار کو تبدیل کیے بغیر اپنے کوآرڈینیٹ سسٹم کو آزادانہ طور پر تبدیل کر سکتے ہیں۔ لیکن اگر ویکٹر بنیادی طور پر حقیقی اعداد کی فہرستیں نہیں ہیں، اور اگر ان کا بنیادی جوہر کچھ زیادہ مقامی ہے، تو اس سے صرف یہ سوال پیدا ہوتا ہے کہ ریاضی دان جب اسپیس یا مقامی جیسے لفظ کا استعمال کرتے ہیں تو اس کا کیا مطلب ہوتا ہے۔ یہ کہاں تک جا رہا ہے، میں اس ویڈیو کا زیادہ تر حصہ کسی ایسی چیز کے بارے میں بات کرنے میں صرف کرنا چاہوں گا جو نہ تو تیر ہے اور نہ ہی نمبروں کی فہرست، بلکہ اس میں ویکٹر کی خصوصیات، افعال بھی ہیں۔ آپ دیکھتے ہیں، ایک احساس ہے جس میں فنکشنز دراصل ویکٹر کی ایک اور قسم ہیں۔ اسی طرح جس طرح آپ دو ویکٹرز کو ایک ساتھ جوڑ سکتے ہیں، ایک نیا فنکشن f اور g حاصل کرنے کے لیے دو فنکشنز، f اور g کو شامل کرنے کا ایک سمجھدار تصور بھی ہے۔ یہ ان چیزوں میں سے ایک ہے جہاں آپ پہلے سے ہی جانتے ہیں کہ یہ کیا ہونے والا ہے، لیکن حقیقت میں اس کا جملہ بولنا منہ کی بات ہے۔ کسی بھی ان پٹ پر اس نئے فنکشن کا آؤٹ پٹ، منفی چار کی طرح، f اور g کے آؤٹ پٹ کا مجموعہ ہے جب آپ ان میں سے ہر ایک کو اسی ان پٹ، منفی چار پر جانچتے ہیں۔ یا زیادہ عام طور پر، کسی بھی دیے گئے ان پٹ x پر sum فنکشن کی قدر x کے x جمع g کے قدروں کا مجموعہ ہے۔ یہ ویکٹر کوآرڈینیٹ بذریعہ کوآرڈینیٹ شامل کرنے کے مترادف ہے۔ یہ صرف اتنا ہے کہ، ایک لحاظ سے، لامحدود طور پر بہت سے نقاط سے نمٹنے کے لیے۔ اسی طرح، ایک حقیقی تعداد کے ذریعہ فنکشن کو اسکیل کرنے کا ایک سمجھدار تصور ہے۔ صرف اس نمبر سے تمام آؤٹ پٹ کو پیمانہ کریں۔ اور ایک بار پھر، یہ ایک ویکٹر کوآرڈینیٹ کو آرڈینیٹ کے ذریعے اسکیل کرنے کے مترادف ہے۔ ایسا لگتا ہے کہ لامحدود طور پر بہت سے نقاط ہیں۔ اب، یہ دیکھتے ہوئے کہ ویکٹر صرف ایک ہی چیز جو واقعی کر سکتے ہیں وہ ہے جوڑنا یا اسکیل کرنا، ایسا محسوس ہوتا ہے کہ ہمیں لکیری الجبرا کی وہی مفید تعمیرات اور مسئلہ حل کرنے کی تکنیکیں لینے کے قابل ہونا چاہئے جن کے بارے میں اصل میں تیر کے تناظر میں سوچا گیا تھا۔ space اور انہیں افعال پر بھی لاگو کریں۔ مثال کے طور پر، فنکشنز کے لیے لکیری تبدیلی کا بالکل معقول تصور ہے، ایسی چیز جو ایک فنکشن میں لیتی ہے اور اسے دوسرے میں بدل دیتی ہے۔ ایک مانوس مثال کیلکولس سے آتی ہے، مشتق۔ یہ ایسی چیز ہے جو ایک فنکشن کو دوسرے فنکشن میں بدل دیتی ہے۔ بعض اوقات اس سیاق و سباق میں، آپ ان کو ٹرانسفارمیشنز کے بجائے آپریٹرز کہلانے والے سنیں گے، لیکن معنی ایک ہی ہے۔ ایک فطری سوال جو آپ پوچھنا چاہتے ہیں وہ یہ ہے کہ افعال کی تبدیلی کا لکیری ہونے کا کیا مطلب ہے۔ لکیریٹی کی رسمی تعریف نسبتاً تجریدی اور علامتی طور پر اس کے مقابلے میں ہے جس طرح میں نے اس سلسلے کے باب 3 میں پہلی بار بات کی تھی۔ لیکن تجریدی کا صلہ یہ ہے کہ ہمیں فنکشنز کے ساتھ ساتھ تیر پر بھی لاگو کرنے کے لیے کافی عام چیز ملے گی۔ ایک تبدیلی لکیری ہوتی ہے اگر یہ دو خصوصیات کو پورا کرتی ہے، جسے عام طور پر additivity اور اسکیلنگ کہا جاتا ہے۔ اضافیت کا مطلب یہ ہے کہ اگر آپ دو ویکٹرز، v اور w کو جوڑتے ہیں، پھر ان کے مجموعے میں تبدیلی کا اطلاق کرتے ہیں، تو آپ کو وہی نتیجہ ملتا ہے جیسے آپ نے v اور w کے تبدیل شدہ ورژنز کو شامل کیا ہے۔ اسکیلنگ کی خاصیت یہ ہے کہ جب آپ کسی ویکٹر v کو کچھ تعداد سے اسکیل کرتے ہیں، پھر تبدیلی کا اطلاق کرتے ہیں، تو آپ کو وہی حتمی ویکٹر ملتا ہے جیسے آپ نے v کے تبدیل شدہ ورژن کو اسی رقم سے اسکیل کیا ہے۔ جس طرح سے آپ اکثر یہ بیان سنتے ہیں وہ یہ ہے کہ لکیری تبدیلیاں ویکٹر کے اضافے اور اسکیلر ضرب کے عمل کو محفوظ رکھتی ہیں۔ گرڈ لائنوں کے متوازی اور یکساں فاصلہ پر رہنے کا خیال جس کے بارے میں میں نے پچھلی ویڈیوز میں بات کی ہے واقعی صرف ایک مثال ہے کہ 2D اسپیس میں پوائنٹس کے مخصوص معاملے میں ان دو خصوصیات کا کیا مطلب ہے۔ ان خصوصیات کے سب سے اہم نتائج میں سے ایک، جو میٹرکس ویکٹر ضرب کو ممکن بناتا ہے، یہ ہے کہ ایک لکیری تبدیلی کو مکمل طور پر بیان کیا جاتا ہے جہاں یہ بنیاد ویکٹر لیتا ہے۔ چونکہ کسی بھی ویکٹر کا اظہار اسکیلنگ اور بنیاد ویکٹر کو کسی نہ کسی طریقے سے شامل کر کے کیا جا سکتا ہے، اس لیے کسی ویکٹر کے تبدیل شدہ ورژن کو تلاش کرنا اسکیلنگ پر آتا ہے اور اسی طرح بیس ویکٹر کے تبدیل شدہ ورژن کو شامل کرتا ہے۔ جیسا کہ آپ صرف ایک لمحے میں دیکھیں گے، یہ فنکشنز کے لیے اتنا ہی درست ہے جتنا کہ تیر کے لیے ہے۔ مثال کے طور پر، کیلکولس کے طلباء ہمیشہ اس حقیقت کو استعمال کرتے رہتے ہیں کہ مشتق اضافی ہے اور اسکیلنگ کی خاصیت ہے، چاہے انہوں نے اسے اس طرح سے فقرے نہیں سنا ہو۔ اگر آپ دو افعال کو شامل کرتے ہیں، تو مشتق لیں، یہ وہی ہے جیسا کہ پہلے ہر ایک کے مشتق کو الگ الگ لیتے ہیں، پھر نتیجہ شامل کرتے ہیں۔ اسی طرح، اگر آپ کسی فنکشن کو اسکیل کرتے ہیں، تو مشتق لیں، یہ ویسا ہی ہے جیسا کہ پہلے مشتق کو لینا، پھر نتیجہ کو اسکیل کرنا۔ متوازی میں واقعی ڈرل کرنے کے لیے، آئیے دیکھتے ہیں کہ میٹرکس کے ساتھ مشتق کو بیان کرنا کیسا لگتا ہے۔ یہ تھوڑا مشکل ہوگا کیونکہ فنکشن اسپیس میں لامحدود جہتی ہونے کا رجحان ہوتا ہے، لیکن میرے خیال میں یہ مشق دراصل کافی تسلی بخش ہے۔ آئیے اپنے آپ کو کثیر الاضلاع تک محدود رکھیں، چیزیں جیسے x مربع جمع 3x جمع 5، یا 4x ساتویں منفی 5x مربع تک۔ ہماری اسپیس میں ہر ایک کثیر الاضلاع کی صرف بہت سی اصطلاحات ہوں گی، لیکن پوری جگہ میں من مانی طور پر بڑی ڈگری والے کثیر الاضلاع شامل ہوں گے۔ سب سے پہلے ہمیں اس جگہ کو کوآرڈینیٹ دینے کی ضرورت ہے، جس کے لیے بنیاد کا انتخاب کرنا ضروری ہے۔ چونکہ کثیر نام پہلے سے ہی متغیر x کی اسکیلڈ طاقتوں کے مجموعے کے طور پر لکھے گئے ہیں، یہ بالکل فطری ہے کہ صرف x کی خالص طاقتوں کو بنیادی فعل کے طور پر منتخب کریں۔ دوسرے لفظوں میں، ہمارا پہلا بنیادی فنکشن مستقل فنکشن ہوگا، b0 کا x برابر 1۔ دوسرا بنیادی فنکشن x کا b1 برابر x، پھر x کا b2 برابر x مربع، پھر x کا b3 برابر x cubed، وغیرہ۔ یہ بنیادی افعال جو کردار ادا کرتے ہیں وہ ویکٹر کی دنیا میں i-hat، j-hat، اور k-hat کے کرداروں کی طرح تیر کے طور پر ہوگا۔ چونکہ ہمارے کثیر الثانیات میں من مانی طور پر بڑی ڈگری ہو سکتی ہے، اس لیے بنیادی افعال کا یہ مجموعہ لامحدود ہے۔ لیکن یہ ٹھیک ہے، اس کا مطلب صرف یہ ہے کہ جب ہم اپنے کثیر الاضلاع کو ویکٹر کے طور پر دیکھتے ہیں، تو ان کے لامحدود بہت سے نقاط ہوں گے۔ ایک کثیر نام جیسے x مربع جمع 3x جمع 5، مثال کے طور پر، نقاط 5، 3، 1 کے ساتھ بیان کیا جائے گا، پھر لامحدود بہت سے صفر۔ آپ اسے یہ کہتے ہوئے پڑھتے ہیں کہ یہ پہلی بنیاد کے فنکشن سے 5 گنا ہے، اس کے علاوہ دوسرے بنیاد کے فنکشن کے 3 گنا، اور تیسرے بنیاد کے فنکشن کے 1 گنا، اور پھر اس مقام سے کسی بھی دوسرے بنیادی فنکشن کو شامل نہیں کیا جانا چاہئے۔ کثیر الجہتی 4x سے ساتویں منفی 5x مربع میں نقاط 0، 0، منفی 5، 0، 0، 0، 0، 4، پھر زیرو کی ایک لامحدود تار ہوگی۔ عام طور پر، چونکہ ہر انفرادی کثیرالاضلاع میں صرف بہت سی اصطلاحات ہوتی ہیں، اس لیے اس کے نقاط صفر کی لامحدود دم کے ساتھ اعداد کی کچھ محدود تار ہوں گے۔ اس کوآرڈینیٹ سسٹم میں، مشتق کو ایک لامحدود میٹرکس کے ساتھ بیان کیا جاتا ہے جو زیادہ تر زیرو سے بھرا ہوتا ہے، لیکن جس میں مثبت انٹیجرز اس آف سیٹ اخترن پر گنتے ہیں۔ میں اس کے بارے میں بات کروں گا کہ آپ اس میٹرکس کو صرف ایک لمحے میں کیسے تلاش کر سکتے ہیں، لیکن اس کا احساس دلانے کا بہترین طریقہ یہ ہے کہ اسے عملی طور پر دیکھیں۔ کثیر الاضلاع x کیوبڈ جمع 5x مربع جمع 4x جمع 5 کی نمائندگی کرنے والے نقاط لیں، پھر ان نقاط کو میٹرکس کے دائیں جانب رکھیں۔ واحد اصطلاح جو نتیجہ کے پہلے کوآرڈینیٹ میں حصہ ڈالتی ہے 1 ضرب 4 ہے، جس کا مطلب ہے کہ نتیجہ میں مستقل اصطلاح 4 ہوگی۔ یہ اس حقیقت سے مطابقت رکھتا ہے کہ 4x کا مشتق مستقل 4 ہے۔ میٹرکس ویکٹر پروڈکٹ کے دوسرے کوآرڈینیٹ میں تعاون کرنے والی واحد اصطلاح 2 ضرب 5 ہے، جس کا مطلب ہے کہ مشتق میں x کے سامنے عدد 10 ہے۔ یہ 5x مربع کے مشتق سے مساوی ہے۔ اسی طرح، میٹرکس ویکٹر پروڈکٹ میں تیسرا کوآرڈینیٹ 3 گنا 1 لینے پر آتا ہے۔ یہ x کیوبڈ 3x مربع ہونے کے مشتق سے مساوی ہے۔ اور اس کے بعد، یہ صفر کے سوا کچھ نہیں ہوگا۔ جو چیز اسے ممکن بناتی ہے وہ یہ ہے کہ مشتق خطی ہے۔ اور آپ میں سے ان لوگوں کے لیے جو توقف اور غور کرنا چاہتے ہیں، آپ اس میٹرکس کو ہر بنیادی فنکشن سے اخذ کرکے اور ہر کالم میں نتائج کے نقاط ڈال کر بنا سکتے ہیں۔ حیرت کی بات یہ ہے کہ میٹرکس ویکٹر ضرب اور اخذ کرنا، جو پہلے بالکل مختلف جانوروں کی طرح لگتا تھا، دونوں واقعی ایک ہی خاندان کے افراد ہیں۔ درحقیقت، میں نے اس سیریز میں جن تصورات کے بارے میں بات کی ہے وہ خلا میں تیر کے طور پر ویکٹر کے حوالے سے، ڈاٹ پروڈکٹ یا ایگین ویکٹر جیسی چیزیں، فنکشنز کی دنیا میں براہ راست اینالاگس رکھتی ہیں، حالانکہ بعض اوقات وہ مختلف ناموں، چیزوں سے جاتے ہیں۔ اندرونی مصنوعات یا eigenfunction کی طرح.",
  "time_range": [
   332.48,
   345.28
  ]
 },
 {
  "input": "One of the most important consequences of these properties, which makes matrix vector multiplication possible, is that a linear transformation is completely described by where it takes the basis vectors.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   345.28,
   357.92
  ]
 },
 {
  "input": "Since any vector can be expressed by scaling and adding the basis vectors in some way, finding the transformed version of a vector comes down to scaling and adding the transformed versions of the basis vectors in that same way.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   357.92,
   372.64
  ]
 },
 {
  "input": "As you'll see in just a moment, this is as true for functions as it is for arrows.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   372.64,
   378.52
  ]
 },
 {
  "input": "For example, calculus students are always using the fact that the derivative is additive and has the scaling property, even if they haven't heard it phrased that way.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   378.52,
   388.3
  ]
 },
 {
  "input": "If you add two functions, then take the derivative, it's the same as first taking the derivative of each one separately, then adding the result.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   388.3,
   398.54
  ]
 },
 {
  "input": "Similarly, if you scale a function, then take the derivative, it's the same as first taking the derivative, then scaling the result.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   398.54,
   410.78
  ]
 },
 {
  "input": "To really drill in the parallel, let's see what it might look like to describe the derivative with a matrix.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   410.78,
   417.06
  ]
 },
 {
  "input": "This will be a little tricky since function spaces have a tendency to be infinite dimensional, but I think this exercise is actually quite satisfying.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   417.06,
   425.02
  ]
 },
 {
  "input": "Let's limit ourselves to polynomials, things like x squared plus 3x plus 5, or 4x to the seventh minus 5x squared.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   425.02,
   432.62
  ]
 },
 {
  "input": "Each of the polynomials in our space will only have finitely many terms, but the full space is going to include polynomials with arbitrarily large degree.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   432.62,
   442.34
  ]
 },
 {
  "input": "The first thing we need to do is give coordinates to this space, which requires choosing a basis.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   442.34,
   448.38
  ]
 },
 {
  "input": "Since polynomials are already written down as the sum of scaled powers of the variable x, it's pretty natural to just choose pure powers of x as the basis function.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   448.38,
   458.54
  ]
 },
 {
  "input": "In other words, our first basis function will be the constant function, b0 of x equals 1.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   458.54,
   464.46
  ]
 },
 {
  "input": "The second basis function will be b1 of x equals x, then b2 of x equals x squared, then b3 of x equals x cubed, and so on.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   464.46,
   474.0
  ]
 },
 {
  "input": "The role that these basis functions serve will be similar to the roles of i-hat, j-hat, and k-hat in the world of vectors as arrows.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   474.0,
   482.42
  ]
 },
 {
  "input": "Since our polynomials can have arbitrarily large degree, this set of basis functions is infinite.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   482.42,
   488.38
  ]
 },
 {
  "input": "But that's okay, it just means that when we treat our polynomials as vectors, they're going to have infinitely many coordinates.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   488.38,
   495.56
  ]
 },
 {
  "input": "A polynomial like x squared plus 3x plus 5, for example, would be described with the coordinates 5, 3, 1, then infinitely many zeros.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   495.56,
   506.2
  ]
 },
 {
  "input": "You'd read this as saying that it's 5 times the first basis function, plus 3 times that second basis function, plus 1 times the third basis function, and then none of the other basis functions should be added from that point on.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   506.2,
   521.0
  ]
 },
 {
  "input": "The polynomial 4x to the seventh minus 5x squared would have the coordinates 0, 0, negative 5, 0, 0, 0, 0, 4, then an infinite string of zeros.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   521.0,
   533.44
  ]
 },
 {
  "input": "In general, since every individual polynomial has only finitely many terms, its coordinates will be some finite string of numbers with an infinite tail of zeros.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   533.44,
   547.32
  ]
 },
 {
  "input": "In this coordinate system, the derivative is described with an infinite matrix that's mostly full of zeros, but which has the positive integers counting down on this offset diagonal.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   547.32,
   558.4
  ]
 },
 {
  "input": "I'll talk about how you could find this matrix in just a moment, but the best way to get a feel for it is to just watch it in action.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   558.4,
   565.28
  ]
 },
 {
  "input": "Take the coordinates representing the polynomial x cubed plus 5x squared plus 4x plus 5, then put those coordinates on the right of the matrix.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   565.28,
   577.32
  ]
 },
 {
  "input": "The only term that contributes to the first coordinate of the result is 1 times 4, which means the constant term in the result will be 4.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   577.32,
   590.72
  ]
 },
 {
  "input": "This corresponds to the fact that the derivative of 4x is the constant 4.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   590.72,
   595.72
  ]
 },
 {
  "input": "The only term contributing to the second coordinate of the matrix vector product is 2 times 5, which means the coefficient in front of x in the derivative is 10.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   595.72,
   606.64
  ]
 },
 {
  "input": "That one corresponds to the derivative of 5x squared.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   606.64,
   610.44
  ]
 },
 {
  "input": "Similarly, the third coordinate in the matrix vector product comes down to taking 3 times 1.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   610.44,
   618.16
  ]
 },
 {
  "input": "This one corresponds to the derivative of x cubed being 3x squared.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   618.16,
   623.2
  ]
 },
 {
  "input": "And after that, it'll be nothing but zeros.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   623.2,
   627.04
  ]
 },
 {
  "input": "What makes this possible is that the derivative is linear.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   627.04,
   632.0
  ]
 },
 {
  "input": "And for those of you who like to pause and ponder, you could construct this matrix by taking the derivative of each basis function and putting the coordinates of the results in each column.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   632.0,
   660.32
  ]
 },
 {
  "input": "So surprisingly, matrix vector multiplication and taking a derivative, which at first seemed like completely different animals, are both just really members of the same family.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   660.32,
   671.72
  ]
 },
 {
  "input": "In fact, most of the concepts I've talked about in this series with respect to vectors as arrows in space, things like the dot product or eigenvectors, have direct analogs in the world of functions, though sometimes they go by different names, things like inner product or eigenfunction.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   671.72,
   688.52
  ]
 },
 {
  "input": "So back to the question of what is a vector.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   688.52,
   691.68
  ]
 },
 {
  "input": "The point I want to make here is that there are lots of vector-ish things in math.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   691.68,
   696.58
  ]
 },
 {
  "input": "As long as you're dealing with a set of objects where there's a reasonable notion of scaling and adding, whether that's a set of arrows in space, lists of numbers, functions, or whatever other crazy thing you choose to define, all of the tools developed in linear algebra regarding vectors, linear transformations, and all that stuff, should be able to apply.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   696.58,
   717.6
  ]
 },
 {
  "input": "Take a moment to imagine yourself right now as a mathematician developing the theory of linear algebra.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   717.6,
   723.32
  ]
 },
 {
  "input": "You want all of the definitions and discoveries of your work to apply to all of the vector-ish things in full generality, not just to one specific case.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   723.32,
   733.56
  ]
 },
 {
  "input": "These sets of vector-ish things, like arrows or lists of numbers or functions, are called vector spaces.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   733.56,
   740.68
  ]
 },
 {
  "input": "And what you as the mathematician might want to do is say, hey everyone, I don't want to have to think about all the different types of crazy vector spaces that y'all might come up with.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   740.68,
   749.8
  ]
 },
 {
  "input": "So what you do is establish a list of rules that vector addition and scaling have to abide by.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   749.8,
   756.56
  ]
 },
 {
  "input": "These rules are called axioms, and in the modern theory of linear algebra, there are eight axioms that any vector space must satisfy if all of the theory and constructs that we've discovered are going to apply.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   756.56,
   767.64
  ]
 },
 {
  "input": "I'll leave them on the screen here for anyone who wants to pause and ponder, but basically it's just a checklist to make sure that the notions of vector addition and scalar multiplication do the things that you'd expect them to do.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   767.64,
   779.16
  ]
 },
 {
  "input": "These axioms are not so much fundamental rules of nature as they are an interface between you, the mathematician discovering results, and other people who might want to apply those results to new sorts of vector spaces.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   779.16,
   790.92
  ]
 },
 {
  "input": "If, for example, someone defines some crazy type of vector space, like the set of all pi creatures with some definition of adding and scaling pi creatures, these axioms are like a checklist of things that they need to verify about their definitions before they can start applying the results of linear algebra.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   790.92,
   808.92
  ]
 },
 {
  "input": "And you, as the mathematician, never have to think about all the possible crazy vector spaces people might define.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   808.92,
   815.06
  ]
 },
 {
  "input": "You just have to prove your results in terms of these axioms so anyone whose definitions satisfy those axioms can happily apply your results, even if you never thought about their situation.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   815.06,
   827.08
  ]
 },
 {
  "input": "As a consequence, you'd tend to phrase all of your results pretty abstractly, which is to say, only in terms of these axioms, rather than centering on a specific type of vector, like arrows in space or functions.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   827.08,
   842.08
  ]
 },
 {
  "input": "For example, this is why just about every textbook you'll find will define linear transformations in terms of additivity and scaling, rather than talking about gridlines remaining parallel and evenly spaced.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   842.08,
   854.08
  ]
 },
 {
  "input": "Even though the latter is more intuitive, and at least in my view, more helpful for first time learners, even if it is specific to one situation.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   854.08,
   862.78
  ]
 },
 {
  "input": "So the mathematician's answer to what are vectors is to just ignore the question.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   862.78,
   867.6
  ]
 },
 {
  "input": "In the modern theory, the form that vectors take doesn't really matter.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   867.6,
   871.56
  ]
 },
 {
  "input": "Arrows, lists of numbers, functions, pi creatures, really, it can be anything, so long as there's some notion of adding and scaling vectors that follows these rules.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   871.56,
   882.38
  ]
 },
 {
  "input": "It's like asking what the number three really is.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   882.38,
   885.48
  ]
 },
 {
  "input": "Whenever it comes up concretely, it's in the context of some triplet of things, but in math, it's treated as an abstraction for all possible triplets of things, and lets you reason about all possible triplets using a single idea.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   885.48,
   899.28
  ]
 },
 {
  "input": "Same goes with vectors, which have many embodiments, but math abstracts them all into a single, intangible notion of a vector space.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   899.28,
   909.46
  ]
 },
 {
  "input": "But as anyone watching this series knows, I think it's better to begin reasoning about vectors in a concrete, visualizable setting, like 2D space with arrows rooted at the origin.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   909.46,
   919.84
  ]
 },
 {
  "input": "But as you learn more linear algebra, know that these tools apply much more generally, and that this is the underlying reason why textbooks and lectures tend to be phrased, well, abstractly.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   919.84,
   932.28
  ]
 },
 {
  "input": "So with that, folks, I think I'll call it an in to this Essence of Linear Algebra series.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   932.28,
   936.92
  ]
 },
 {
  "input": "If you've watched and understood the videos, I really do believe that you have a solid foundation in the underlying intuitions of linear algebra.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   936.92,
   944.74
  ]
 },
 {
  "input": "This is not the same thing as learning the full topic, of course, that's something that can only really come from working through problems, but the learning you do moving forward could be substantially more efficient if you have all the right intuitions in place.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   944.74,
   956.88
  ]
 },
 {
  "input": "So have fun applying those intuitions, and best of luck with your future learning.",
  "model": "nmt",
  "translatedText": "",
  "time_range": [
   956.88,
   956.88
  ]
 }
]