1
00:00:17,081 --> 00:00:19,781
Szeretnék újra feltenni egy megtévesztően egyszerű

2
00:00:19,781 --> 00:00:22,800
kérdést, amelyet a sorozat legelső videójában tettem fel.

3
00:00:22,800 --> 00:00:24,600
Mik azok a vektorok?

4
00:00:24,600 --> 00:00:27,810
Egy kétdimenziós vektor például alapvetően egy sík síkon lévő

5
00:00:27,810 --> 00:00:31,280
nyíl, amelyet a kényelem kedvéért koordinátákkal is le tudunk írni?

6
00:00:31,280 --> 00:00:38,680
Vagy alapvetően az a valós számpár, amely csak egy sík síkon lévő nyílként van ábrázolva?

7
00:00:38,680 --> 00:00:42,400
Vagy mindkettő csak valami mélyebb megnyilvánulása?

8
00:00:42,400 --> 00:00:45,438
Egyrészt egyértelműnek és egyértelműnek tűnik,

9
00:00:45,438 --> 00:00:48,800
hogy a vektorokat elsősorban számlistának tekintjük.

10
00:00:48,800 --> 00:00:53,186
Ez olyan dolgokat tesz lehetővé, mint a négydimenziós vektorok vagy a 100-dimenziós

11
00:00:53,186 --> 00:00:57,260
vektorok, mint valódi, konkrét ötletek, amelyekkel valóban dolgozni is lehet,

12
00:00:57,260 --> 00:01:01,228
miközben egyébként egy olyan ötlet, mint a négy dimenzió, csak egy homályos

13
00:01:01,228 --> 00:01:05,720
geometriai fogalom, amelyet nehéz leírni anélkül, hogy egy kicsit integetne a kezével.

14
00:01:05,720 --> 00:01:10,018
Másrészről azonban azok számára, akik ténylegesen lineáris algebrával dolgoznak,

15
00:01:10,018 --> 00:01:14,530
általános szenzáció, különösen, ha folyékonyabbá válik a bázis megváltoztatása, hogy

16
00:01:14,530 --> 00:01:19,253
olyan térrel van dolgunk, amely az Ön által megadott koordinátáktól függetlenül létezik,

17
00:01:19,253 --> 00:01:23,870
és hogy a koordináták valójában némileg önkényesek, attól függően, hogy mit választasz

18
00:01:23,870 --> 00:01:24,720
bázisvektorként.

19
00:01:24,720 --> 00:01:28,324
A lineáris algebra több témája, például a determinánsok és a sajátvektorok

20
00:01:28,324 --> 00:01:31,400
közömbösnek tűnik a koordinátarendszerek kiválasztását illetően.

21
00:01:31,400 --> 00:01:35,805
A determináns megmondja, hogy egy transzformáció mennyire skálázza a területeket, és

22
00:01:35,805 --> 00:01:40,160
a sajátvektorok azok, amelyek a transzformáció során a saját tartományukon maradnak.

23
00:01:40,160 --> 00:01:45,845
De mindkét tulajdonság eredendően térbeli, és szabadon megváltoztathatja

24
00:01:45,845 --> 00:01:51,220
a koordinátarendszert anélkül, hogy megváltoztatná egyik alapértékét.

25
00:01:51,220 --> 00:01:55,211
De ha a vektorok alapvetően nem valós számok listái, és ha a mögöttes

26
00:01:55,211 --> 00:01:59,317
lényegük valami térbelibb, akkor felveti a kérdést, hogy mire gondolnak

27
00:01:59,317 --> 00:02:03,480
a matematikusok, amikor olyan szavakat használnak, mint a tér vagy a tér.

28
00:02:03,480 --> 00:02:06,856
Ahhoz, hogy továbbfejlődjek, ennek a videónak a nagy részét szeretném

29
00:02:06,856 --> 00:02:10,281
azzal tölteni, hogy valami olyasmiről beszéljek, ami nem egy nyíl, sem

30
00:02:10,281 --> 00:02:14,140
nem számlista, hanem vektorszerű tulajdonságokkal és funkciókkal is rendelkezik.

31
00:02:14,140 --> 00:02:17,288
Látod, van egy olyan értelemben, hogy a függvények

32
00:02:17,288 --> 00:02:19,820
valójában csak egy másik típusú vektorok.

33
00:02:19,820 --> 00:02:24,183
Ugyanúgy, ahogyan két vektort összeadhat, van egy értelmes ötlet két

34
00:02:24,183 --> 00:02:28,420
függvény, f és g összeadására, hogy új f plusz g függvényt kapjunk.

35
00:02:28,420 --> 00:02:31,110
Ez egyike azoknak a dolgoknak, ahol az ember már

36
00:02:31,110 --> 00:02:34,020
tudja, mi lesz, de valójában megfogalmazni egy falat.

37
00:02:34,020 --> 00:02:37,729
Ennek az új függvénynek a kimenete bármely adott bemeneten,

38
00:02:37,729 --> 00:02:41,500
akárcsak a negatív négyes, az f és a g kimeneteinek összege,

39
00:02:41,500 --> 00:02:45,580
ha mindegyiket ugyanazon a bemeneten, a negatív négyen kiértékeli.

40
00:02:45,580 --> 00:02:53,580
Általánosabban fogalmazva, az összegfüggvény értéke bármely

41
00:02:53,580 --> 00:03:01,180
adott x bemeneten az x f értékeinek és x g-jének összege.

42
00:03:01,180 --> 00:03:04,420
Ez nagyon hasonlít a vektorok koordinátánkénti hozzáadásához.

43
00:03:04,420 --> 00:03:06,832
Csak arról van szó, hogy bizonyos értelemben végtelenül

44
00:03:06,832 --> 00:03:08,340
sok koordinátával kell foglalkozni.

45
00:03:08,340 --> 00:03:15,740
Hasonlóképpen, van egy értelmes elképzelés a függvények valós számokkal való skálázására.

46
00:03:15,740 --> 00:03:20,340
Csak méretezheti az összes kimenetet ezzel a számmal.

47
00:03:20,340 --> 00:03:24,140
És ismét, ez analóg egy vektorkoordináta koordinátánkénti skálázásához.

48
00:03:24,140 --> 00:03:27,780
Olyan érzés, mintha végtelenül sok koordináta lenne.

49
00:03:27,780 --> 00:03:31,599
Nos, tekintettel arra, hogy a vektorok egyetlen, amit igazán tehetnek, az

50
00:03:31,599 --> 00:03:35,470
az, hogy összeadják vagy skálázzák, úgy tűnik, képesnek kell lennünk arra,

51
00:03:35,470 --> 00:03:39,600
hogy a lineáris algebra ugyanazokat a hasznos konstrukciókat és problémamegoldó

52
00:03:39,600 --> 00:03:43,058
technikákat alkalmazzuk, amelyeket eredetileg a nyilak és a nyilak

53
00:03:43,058 --> 00:03:46,620
kontextusában gondoltak. teret, és alkalmazza azokat függvényekre is.

54
00:03:46,620 --> 00:03:53,770
Például van egy teljesen ésszerű elképzelés a függvények lineáris transzformációjáról,

55
00:03:53,770 --> 00:04:00,100
valami olyasmiről, amely az egyik függvényt átveszi, és egy másikká alakítja.

56
00:04:00,100 --> 00:04:03,720
Egy ismerős példa a kalkulusból, a deriváltból származik.

57
00:04:03,720 --> 00:04:08,800
Ez olyasmi, ami az egyik funkciót egy másik funkcióvá alakítja át.

58
00:04:08,800 --> 00:04:12,670
Néha ebben az összefüggésben ezeket az úgynevezett operátorokat

59
00:04:12,670 --> 00:04:16,360
fogja hallani transzformációk helyett, de a jelentés ugyanaz.

60
00:04:16,360 --> 00:04:19,334
Természetes kérdés, amit érdemes feltenni, hogy mit

61
00:04:19,334 --> 00:04:22,480
jelent az, hogy a függvények transzformációja lineáris.

62
00:04:22,480 --> 00:04:26,560
A linearitás formális meghatározása viszonylag elvont és szimbolikusan

63
00:04:26,560 --> 00:04:31,100
vezérelt ahhoz képest, ahogyan a sorozat 3. fejezetében először beszéltem róla.

64
00:04:31,100 --> 00:04:35,375
De az absztraktság jutalma az, hogy kapunk valami elég általánosat

65
00:04:35,375 --> 00:04:39,140
ahhoz, hogy a függvényekre és a nyilakra is vonatkoztassuk.

66
00:04:39,140 --> 00:04:42,830
Egy transzformáció lineáris, ha két tulajdonságot teljesít,

67
00:04:42,830 --> 00:04:46,460
amelyeket általában additivitásnak és skálázásnak neveznek.

68
00:04:46,460 --> 00:04:50,853
Az additivitás azt jelenti, hogy ha összeadunk két vektort, v-t és

69
00:04:50,853 --> 00:04:55,312
w-t, majd transzformációt alkalmazunk az összegükre, akkor ugyanazt

70
00:04:55,312 --> 00:05:00,100
az eredményt kapjuk, mintha hozzáadnánk v és w transzformált változatait.

71
00:05:00,100 --> 00:05:06,809
A skálázási tulajdonság az, hogy ha egy v vektort egy számmal

72
00:05:06,809 --> 00:05:13,735
skálázunk, majd alkalmazzuk a transzformációt, ugyanazt a végső

73
00:05:13,735 --> 00:05:21,960
vektort kapjuk, mintha v transzformált változatát ugyanennyivel méreteznénk.

74
00:05:21,960 --> 00:05:27,038
Ezt gyakran hallani az, hogy a lineáris transzformációk

75
00:05:27,038 --> 00:05:32,480
megőrzik a vektorösszeadás és a skaláris szorzás műveleteit.

76
00:05:32,480 --> 00:05:36,418
Az a gondolat, hogy a rácsvonalak párhuzamosak és egyenletesen elosztva

77
00:05:36,418 --> 00:05:40,302
maradjanak, amiről a korábbi videókban beszéltem, valójában csak annak

78
00:05:40,302 --> 00:05:44,350
szemléltetése, hogy mit jelent ez a két tulajdonság a 2D-s tér pontjainak

79
00:05:44,350 --> 00:05:45,280
konkrét esetében.

80
00:05:45,280 --> 00:05:49,449
Ezeknek a tulajdonságoknak az egyik legfontosabb következménye,

81
00:05:49,449 --> 00:05:53,359
ami lehetővé teszi a mátrixvektor szorzást, hogy a lineáris

82
00:05:53,359 --> 00:05:57,920
transzformációt teljesen leírja, hogy hol veszi fel a bázisvektorokat.

83
00:05:57,920 --> 00:06:02,727
Mivel bármely vektor kifejezhető skálázással és a bázisvektorok valamilyen módon

84
00:06:02,727 --> 00:06:07,891
történő összeadásával, a vektor transzformált változatának megtalálása a bázisvektorok

85
00:06:07,891 --> 00:06:12,640
transzformált változatainak skálázásával és összeadásával azonos módon történik.

86
00:06:12,640 --> 00:06:18,520
Amint azt egy pillanat alatt látni fogja, ez ugyanúgy igaz a funkciókra, mint a nyilakra.

87
00:06:18,520 --> 00:06:21,533
Például a számítástechnikai hallgatók mindig azt a tényt

88
00:06:21,533 --> 00:06:24,863
használják, hogy a derivált additív és rendelkezik a skálázási

89
00:06:24,863 --> 00:06:28,300
tulajdonsággal, még akkor is, ha nem hallották így megfogalmazva.

90
00:06:28,300 --> 00:06:33,420
Ha hozzáadunk két függvényt, akkor vegyük a deriváltot, ez ugyanaz, mintha

91
00:06:33,420 --> 00:06:38,540
először mindegyik deriváltját vennénk külön, majd hozzáadnánk az eredményt.

92
00:06:38,540 --> 00:06:44,701
Hasonlóképpen, ha egy függvényt skálázunk, majd vegyük a deriváltot, akkor

93
00:06:44,701 --> 00:06:50,780
ez ugyanaz, mint először a derivált felvétele, majd az eredmény skálázása.

94
00:06:50,780 --> 00:06:53,861
Hogy valóban lefúrjuk a párhuzamosságot, nézzük meg,

95
00:06:53,861 --> 00:06:57,060
hogyan nézhet ki a derivált mátrixszal történő leírása.

96
00:06:57,060 --> 00:07:00,956
Ez egy kicsit trükkös lesz, mivel a függvényterek hajlamosak végtelen

97
00:07:00,956 --> 00:07:05,020
dimenziójúak lenni, de szerintem ez a gyakorlat valójában elég kielégítő.

98
00:07:05,020 --> 00:07:08,748
Korlátozzuk magunkat polinomokra, például x négyzet

99
00:07:08,748 --> 00:07:12,620
plusz 3x plusz 5, vagy 4x a hetedik mínusz 5x négyzet.

100
00:07:12,620 --> 00:07:17,813
A terünkben lévő polinomok mindegyike csak véges sok tagot tartalmaz,

101
00:07:17,813 --> 00:07:22,340
de a teljes térben tetszőlegesen nagy fokú polinomok lesznek.

102
00:07:22,340 --> 00:07:28,380
Először is meg kell adnunk ennek a térnek a koordinátáit, amihez alapot kell választani.

103
00:07:28,380 --> 00:07:33,704
Mivel a polinomok már fel vannak írva az x változó skálázott hatványainak összegeként,

104
00:07:33,704 --> 00:07:38,540
teljesen természetes, hogy az x tiszta hatványait választjuk bázisfüggvényként.

105
00:07:38,540 --> 00:07:44,460
Más szavakkal, az első bázisfüggvényünk az x állandó függvénye lesz, b0 egyenlő 1-gyel.

106
00:07:44,460 --> 00:07:49,196
A második bázisfüggvény az x b1 egyenlő x-szel, majd x-ből b2 egyenlő

107
00:07:49,196 --> 00:07:54,000
x-szel négyzetben, majd x-ből b3 egyenlő x-ből kockával, és így tovább.

108
00:07:54,000 --> 00:07:58,248
Az alapfüggvények szerepe hasonló lesz az i-hat, j-hat

109
00:07:58,248 --> 00:08:02,420
és k-hat szerepéhez a vektorok világában, mint nyilak.

110
00:08:02,420 --> 00:08:05,526
Mivel polinomjaink tetszőlegesen nagy fokszámúak

111
00:08:05,526 --> 00:08:08,380
lehetnek, ez a bázisfüggvénykészlet végtelen.

112
00:08:08,380 --> 00:08:12,368
De ez rendben van, ez csak azt jelenti, hogy ha a polinomjainkat

113
00:08:12,368 --> 00:08:15,560
vektorként kezeljük, végtelen sok koordinátája lesz.

114
00:08:15,560 --> 00:08:20,921
Például egy olyan polinomot, mint az x négyzet plusz 3x plusz 5,

115
00:08:20,921 --> 00:08:26,200
az 5, 3, 1 koordinátákkal, majd végtelen sok nullával írnánk le.

116
00:08:26,200 --> 00:08:31,109
Ezt úgy olvasnád, hogy ez 5-szöröse az első bázisfüggvénynek, plusz

117
00:08:31,109 --> 00:08:35,368
3-szor a második bázisfüggvénynek, plusz 1-szer a harmadik

118
00:08:35,368 --> 00:08:41,000
bázisfüggvénynek, és ettől kezdve a többi bázisfüggvényt sem szabad hozzáadni.

119
00:08:41,000 --> 00:08:47,220
A 4x-től a hetedik mínusz 5x-ig terjedő polinom négyzetére 0,

120
00:08:47,220 --> 00:08:53,440
0, negatív 5, 0, 0, 0, 0, 4, majd végtelen nullák lánca lenne.

121
00:08:53,440 --> 00:09:00,199
Általánosságban elmondható, hogy mivel minden egyedi polinomnak csak véges

122
00:09:00,199 --> 00:09:07,320
sok tagja van, a koordinátái valamilyen véges számsor, végtelen nullák végével.

123
00:09:07,320 --> 00:09:12,519
Ebben a koordináta-rendszerben a derivált egy végtelen mátrixszal van leírva, amely

124
00:09:12,519 --> 00:09:18,028
többnyire tele van nullákkal, de a pozitív egész számok visszaszámolnak ezen az eltolási

125
00:09:18,028 --> 00:09:18,400
átlón.

126
00:09:18,400 --> 00:09:21,680
Arról fogok beszélni, hogyan találhatná meg ezt a mátrixot egy pillanat

127
00:09:21,680 --> 00:09:25,280
alatt, de a legjobb módja annak, hogy átérezhesse, ha csak nézi működés közben.

128
00:09:25,280 --> 00:09:31,340
Vegyük az x kocka polinomot és 5x négyzetet és 4x plusz 5-öt reprezentáló

129
00:09:31,340 --> 00:09:37,320
koordinátákat, majd tegyük ezeket a koordinátákat a mátrix jobb oldalára.

130
00:09:37,320 --> 00:09:43,877
Az egyetlen tag, amely az eredmény első koordinátájához járul hozzá,

131
00:09:43,877 --> 00:09:50,720
az 1-szer 4, ami azt jelenti, hogy az eredményben az állandó tag 4 lesz.

132
00:09:50,720 --> 00:09:55,720
Ez megfelel annak, hogy a 4x deriváltja a 4 állandó.

133
00:09:55,720 --> 00:10:00,983
A mátrix vektorszorzatának második koordinátájához az egyetlen tag

134
00:10:00,983 --> 00:10:06,640
2-szer 5, ami azt jelenti, hogy a deriváltban az x előtti együttható 10.

135
00:10:06,640 --> 00:10:10,440
Ez az 5x-es négyzet deriváltjának felel meg.

136
00:10:10,440 --> 00:10:18,160
Hasonlóképpen, a harmadik koordináta a mátrix vektorszorzatában 3-szor 1-re csökken.

137
00:10:18,160 --> 00:10:23,200
Ez megfelel annak, hogy x kockás deriváltja 3x négyzet.

138
00:10:23,200 --> 00:10:27,040
És utána nem lesz más, mint nullák.

139
00:10:27,040 --> 00:10:32,000
Ezt az teszi lehetővé, hogy a derivált lineáris.

140
00:10:32,000 --> 00:10:40,438
Azok pedig, akik szeretnek szünetet tartani és töprengeni,

141
00:10:40,438 --> 00:10:49,592
elkészíthetik ezt a mátrixot úgy, hogy az egyes bázisfüggvények

142
00:10:49,592 --> 00:11:00,320
deriváltját veszik, és az eredmények koordinátáit minden oszlopba helyezik.

143
00:11:00,320 --> 00:11:06,055
Meglepő módon a mátrixvektor-szorzás és a származékok felvétele, amelyek először

144
00:11:06,055 --> 00:11:11,720
teljesen különböző állatoknak tűntek, valójában ugyanannak a családnak a tagjai.

145
00:11:11,720 --> 00:11:16,163
Valójában a legtöbb fogalom, amelyről ebben a sorozatban beszéltem a vektorokkal,

146
00:11:16,163 --> 00:11:20,445
mint a térben lévő nyilakkal, például a pontszorzattal vagy a sajátvektorokkal

147
00:11:20,445 --> 00:11:24,672
kapcsolatban, közvetlen analógjai vannak a függvények világában, bár néha más

148
00:11:24,672 --> 00:11:28,520
néven, dolgokon szerepelnek. mint a belső szorzat vagy a sajátfüggvény.

149
00:11:28,520 --> 00:11:31,680
Tehát vissza a kérdéshez, hogy mi a vektor.

150
00:11:31,680 --> 00:11:36,580
Itt szeretném leszögezni, hogy sok vektorszerű dolog van a matematikában.

151
00:11:36,580 --> 00:11:40,583
Mindaddig, amíg olyan objektumok halmazával van dolgunk, amelyeknél van ésszerű

152
00:11:40,583 --> 00:11:44,637
elképzelés a méretezésről és a hozzáadásról, legyen szó akár nyilak halmazáról a

153
00:11:44,637 --> 00:11:48,641
térben, számlistákról, függvényekről vagy bármilyen más őrült dologról, amelyet

154
00:11:48,641 --> 00:11:52,645
definiálni választ, az összes a lineáris algebrában kifejlesztett eszközöknek a

155
00:11:52,645 --> 00:11:56,799
vektorokkal, lineáris transzformációkkal és minden ilyesmivel kapcsolatban tudniuk

156
00:11:56,799 --> 00:11:57,600
kell alkalmazni.

157
00:11:57,600 --> 00:12:00,434
Szánjon egy pillanatra, és képzelje el magát, mint egy

158
00:12:00,434 --> 00:12:03,320
matematikus, aki a lineáris algebra elméletét fejleszti.

159
00:12:03,320 --> 00:12:08,776
Azt szeretné, ha munkája összes definíciója és felfedezése az összes vektorszerű

160
00:12:08,776 --> 00:12:13,560
dologra teljes általánosságban vonatkozna, nem csak egy konkrét esetre.

161
00:12:13,560 --> 00:12:17,056
A vektorszerű dolgok ilyen halmazait, például nyilakat

162
00:12:17,056 --> 00:12:20,680
vagy szám- vagy függvénylistákat vektortereknek nevezzük.

163
00:12:20,680 --> 00:12:25,397
És amit matematikusként szeretne tenni, az az, hogy azt mondja, hé, mindenki, nem akarom,

164
00:12:25,397 --> 00:12:29,800
hogy a különféle őrült vektorterekre kelljen gondolnom, amivel mindenki találkozhat.

165
00:12:29,800 --> 00:12:33,180
Tehát azt kell tennie, hogy összeállít egy listát a szabályokról,

166
00:12:33,180 --> 00:12:36,560
amelyeket a vektorösszeadásnak és a méretezésnek be kell tartania.

167
00:12:36,560 --> 00:12:39,936
Ezeket a szabályokat axiómáknak nevezzük, és a lineáris algebra modern

168
00:12:39,936 --> 00:12:43,740
elméletében nyolc axióma van, amelyeknek minden vektortérnek meg kell felelnie,

169
00:12:43,740 --> 00:12:47,640
ha az általunk felfedezett elméletek és konstrukciók mindegyike alkalmazható lesz.

170
00:12:47,640 --> 00:12:51,525
Itt hagyom őket a képernyőn mindenkinek, aki szünetet szeretne tartani és töprengeni,

171
00:12:51,525 --> 00:12:55,094
de alapvetően ez csak egy ellenőrző lista, hogy megbizonyosodjon arról, hogy a

172
00:12:55,094 --> 00:12:59,160
vektorösszeadás és a skaláris szorzás fogalma azt a dolgokat csinálja, amit elvárna tőlük.

173
00:12:59,160 --> 00:13:03,161
Ezek az axiómák nem annyira alapvető természeti szabályok, mint inkább interfészt

174
00:13:03,161 --> 00:13:07,065
jelentenek közted, az eredményeket felfedező matematikus és más emberek között,

175
00:13:07,065 --> 00:13:10,920
akik esetleg újfajta vektorterekre szeretnék alkalmazni ezeket az eredményeket.

176
00:13:10,920 --> 00:13:15,266
Ha például valaki meghatároz egy őrült típusú vektorteret, például az összes pi lény

177
00:13:15,266 --> 00:13:19,664
halmazát a pi lények hozzáadásának és skálázásának valamilyen definíciójával, ezek az

178
00:13:19,664 --> 00:13:23,755
axiómák olyanok, mint a dolgok ellenőrző listája, amelyeket ellenőriznie kell a

179
00:13:23,755 --> 00:13:28,306
definícióikkal kapcsolatban, mielőtt megtehetné. kezdje el alkalmazni a lineáris algebra

180
00:13:28,306 --> 00:13:28,920
eredményeit.

181
00:13:28,920 --> 00:13:31,966
És neked, mint matematikusnak, soha nem kell gondolnod az összes

182
00:13:31,966 --> 00:13:35,060
lehetséges őrült vektortérre, amelyet az emberek meghatározhatnak.

183
00:13:35,060 --> 00:13:39,218
Csak bizonyítania kell az eredményeket ezen axiómák alapján, hogy bárki,

184
00:13:39,218 --> 00:13:42,864
akinek a definíciói megfelelnek ezeknek az axiómáknak, boldogan

185
00:13:42,864 --> 00:13:47,080
alkalmazhassa eredményeit, még akkor is, ha soha nem gondolt a helyzetére.

186
00:13:47,080 --> 00:13:51,711
Következésképpen hajlamos az összes eredményt elég absztrakt módon

187
00:13:51,711 --> 00:13:56,826
megfogalmazni, vagyis csak ezen axiómák szerint, ahelyett, hogy egy adott

188
00:13:56,826 --> 00:14:02,080
típusú vektorra, például térbeli nyilakra vagy függvényekre összpontosítana.

189
00:14:02,080 --> 00:14:06,386
Például ezért van az, hogy szinte minden tankönyv lineáris transzformációt

190
00:14:06,386 --> 00:14:10,233
határoz meg az additív és skálázás szempontjából, nem pedig arról,

191
00:14:10,233 --> 00:14:14,080
hogy a rácsvonalak párhuzamosak és egyenletes távolságban maradnak.

192
00:14:14,080 --> 00:14:18,583
Annak ellenére, hogy az utóbbi intuitívabb, és legalábbis véleményem szerint hasznosabb

193
00:14:18,583 --> 00:14:22,780
az első alkalommal tanulók számára, még akkor is, ha egy adott helyzetre jellemző.

194
00:14:22,780 --> 00:14:25,512
Tehát a matematikus válasza arra, hogy mik a vektorok,

195
00:14:25,512 --> 00:14:27,600
az, hogy figyelmen kívül hagyja a kérdést.

196
00:14:27,600 --> 00:14:31,560
A modern elméletben a vektorok formája nem igazán számít.

197
00:14:31,560 --> 00:14:36,694
Nyilak, számlisták, függvények, pi lények, valójában bármi lehet, feltéve, hogy van

198
00:14:36,694 --> 00:14:41,646
valamiféle vektorok hozzáadásának és skálázásának fogalma, amely követi ezeket a

199
00:14:41,646 --> 00:14:42,380
szabályokat.

200
00:14:42,380 --> 00:14:45,480
Mintha azt kérdeznénk, mi is valójában a hármas szám.

201
00:14:45,480 --> 00:14:49,986
Valahányszor konkrétan felmerül, a dolgok valamilyen hármasával összefüggésben,

202
00:14:49,986 --> 00:14:54,717
de a matematikában a dolgok összes lehetséges hármasának absztrakciójaként kezelik,

203
00:14:54,717 --> 00:14:59,280
és lehetővé teszi az összes lehetséges hármas okoskodását egyetlen ötlet alapján.

204
00:14:59,280 --> 00:15:04,401
Ugyanez vonatkozik a vektorokra, amelyeknek számos megvalósítási formája van, de

205
00:15:04,401 --> 00:15:09,460
a matematika ezeket a vektortér egyetlen, megfoghatatlan fogalmába absztrahálja.

206
00:15:09,460 --> 00:15:12,746
De amint azt bárki, aki ezt a sorozatot nézi, tudja, szerintem

207
00:15:12,746 --> 00:15:16,188
jobb, ha konkrét, megjeleníthető környezetben kezdünk okoskodni a

208
00:15:16,188 --> 00:15:19,840
vektorokról, például 2D térben, ahol a nyilak az origóban gyökereznek.

209
00:15:19,840 --> 00:15:23,888
De ahogy egyre több lineáris algebrát tanul, tudjon arról, hogy ezek

210
00:15:23,888 --> 00:15:27,937
az eszközök sokkal általánosabban alkalmazhatók, és ez az oka annak,

211
00:15:27,937 --> 00:15:32,280
hogy a tankönyveket és előadásokat általában elvont módon fogalmazzák meg.

212
00:15:32,280 --> 00:15:34,670
Szóval ezzel, emberek, azt hiszem, ezt a sorozatot

213
00:15:34,670 --> 00:15:36,920
az Essence of Linear Algebra sorozatnak nevezem.

214
00:15:36,920 --> 00:15:40,715
Ha megnézte és megértette a videókat, akkor tényleg úgy gondolom,

215
00:15:40,715 --> 00:15:44,740
hogy szilárd alapjai vannak a lineáris algebra mögöttes megérzéseinek.

216
00:15:44,740 --> 00:15:48,726
Ez persze nem ugyanaz, mint a teljes téma elsajátítása, ez csak a

217
00:15:48,726 --> 00:15:53,074
problémák megoldásából fakadhat, de az előrehaladott tanulás lényegesen

218
00:15:53,074 --> 00:15:56,880
hatékonyabb lehet, ha minden megfelelő intuícióval rendelkezel.

219
00:15:56,880 --> 00:15:56,880
Szóval jó szórakozást az intuíciók alkalmazásához,

220
00:15:56,880 --> 00:15:56,880
és sok szerencsét a jövőbeni tanuláshoz.

