[
 {
  "input": "Hello, hello again. ",
  "translatedText": "مرحبا، مرحبا مرة أخرى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.98,
  "end": 13.0
 },
 {
  "input": "So moving forward, I'll be assuming that you have a visual understanding of linear transformations and how they're represented with matrices, the way that I've been talking about in the last few videos. ",
  "translatedText": "لذا، للمضي قدمًا، سأفترض أن لديك فهمًا بصريًا للتحولات الخطية وكيفية تمثيلها بالمصفوفات، وهي الطريقة التي كنت أتحدث عنها في مقاطع الفيديو القليلة الماضية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.52,
  "end": 21.84
 },
 {
  "input": "If you think about a couple of these linear transformations, you might notice how some of them seem to stretch space out, while others squish it on in. ",
  "translatedText": "إذا فكرت في اثنين من هذه التحولات الخطية، فقد تلاحظ كيف يبدو بعضها وكأنه يمد الفضاء، بينما البعض الآخر يضغط عليه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.66,
  "end": 30.42
 },
 {
  "input": "One thing that turns out to be pretty useful for understanding one of these transformations is to measure exactly how much it stretches or squishes things. ",
  "translatedText": "أحد الأشياء التي تبين أنها مفيدة جدًا لفهم أحد هذه التحولات هو القياس الدقيق لمدى تمددها أو سحقها للأشياء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.14,
  "end": 38.92
 },
 {
  "input": "More specifically, to measure the factor by which the area of a given region increases or decreases. ",
  "translatedText": "وبشكل أكثر تحديدًا، لقياس العامل الذي تزيد أو تنقص به مساحة منطقة معينة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.52,
  "end": 45.82
 },
 {
  "input": "For example, look at the matrix with columns 3, 0 and 0, 2. ",
  "translatedText": "على سبيل المثال، انظر إلى المصفوفة التي تحتوي على الأعمدة 3، 0 و0، 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.18,
  "end": 50.88
 },
 {
  "input": "It scales i-hat by a factor of 3 and scales j-hat by a factor of 2. ",
  "translatedText": "إنه يقيس i-hat بعامل 3 ويقيس j-hat بعامل 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.32,
  "end": 56.18
 },
 {
  "input": "Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle. ",
  "translatedText": "الآن، إذا ركزنا انتباهنا على المربع 1 × 1 الذي يقع قاعه على i-hat وجانبه الأيسر على j-hat، بعد التحويل، يتحول هذا إلى مستطيل 2 × 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.7,
  "end": 67.52
 },
 {
  "input": "Since this region started out with area 1 and ended up with area 6, we can say the linear transformation has scaled its area by a factor of 6. ",
  "translatedText": "وبما أن هذه المنطقة بدأت بالمنطقة 1 وانتهت بالمنطقة 6، فيمكننا القول إن التحويل الخطي قد زاد مساحتها بعامل 6. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.38,
  "end": 77.28
 },
 {
  "input": "Compare that to a shear whose matrix has columns 1, 0 and 1, 1, meaning i-hat stays in place and j-hat moves over to 1, 1. ",
  "translatedText": "قارن ذلك بالمقص الذي تحتوي مصفوفته على أعمدة 1، 0 و1، 1، مما يعني أن i-hat يبقى في مكانه ويتحرك j-hat إلى 1، 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.18,
  "end": 86.1
 },
 {
  "input": "That same unit square determined by i-hat and j-hat gets slanted and turned into a parallelogram, but the area of that parallelogram is still 1, since its base and height each continue to have length 1. ",
  "translatedText": "نفس مربع الوحدة المحدد بواسطة i-hat وj-hat يصبح مائلًا ويتحول إلى متوازي أضلاع، لكن مساحة متوازي الأضلاع هذا لا تزال 1، نظرًا لأن طول قاعدته وارتفاعه لا يزال يساوي 1. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.0,
  "end": 98.38
 },
 {
  "input": "So, even though this transformation smushes things about, it seems to leave areas unchanged, at least in the case of that 1 unit square. ",
  "translatedText": "لذا، على الرغم من أن هذا التحويل يحطم الأشياء، فإنه يبدو أنه يترك المساحات دون تغيير، على الأقل في حالة وحدة واحدة مربعة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.18,
  "end": 105.62
 },
 {
  "input": "Actually though, if you know how much the area of that one single unit square changes, it can tell you how the area of any possible region in space changes. ",
  "translatedText": "ومع ذلك، في الواقع، إذا كنت تعرف مقدار تغير مساحة تلك الوحدة المربعة الواحدة، فيمكن أن يخبرك ذلك بكيفية تغير مساحة أي منطقة محتملة في الفضاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.82,
  "end": 115.52
 },
 {
  "input": "For starters, notice that whatever happens to one square in the grid has to happen to any other square in the grid, no matter the size. ",
  "translatedText": "بالنسبة للمبتدئين، لاحظ أن كل ما يحدث لمربع واحد في الشبكة يجب أن يحدث لأي مربع آخر في الشبكة، بغض النظر عن الحجم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.3,
  "end": 123.58
 },
 {
  "input": "This follows from the fact that grid lines remain parallel and evenly spaced. ",
  "translatedText": "وينتج هذا من حقيقة أن خطوط الشبكة تظل متوازية ومتباعدة بشكل متساوٍ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.34,
  "end": 128.04
 },
 {
  "input": "Then, any shape that's not a grid square can be approximated by grid squares pretty well, with arbitrarily good approximations if you use small enough grid squares. ",
  "translatedText": "بعد ذلك، يمكن تقريب أي شكل ليس مربعًا شبكيًا بواسطة مربعات شبكية بشكل جيد، مع تقديرات تقريبية جيدة إذا كنت تستخدم مربعات شبكية صغيرة بما يكفي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.76,
  "end": 137.52
 },
 {
  "input": "So, since the areas of all those tiny grid squares are being scaled by some single amount, the area of the blob as a whole will also be scaled by that same single amount. ",
  "translatedText": "لذا، بما أن مساحات كل تلك المربعات الشبكية الصغيرة يتم قياسها بمقدار واحد، فإن مساحة النقطة ككل سيتم قياسها أيضًا بنفس المقدار الفردي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.52,
  "end": 147.82
 },
 {
  "input": "This very special scaling factor, the factor by which a linear transformation changes any area, is called the determinant of that transformation. ",
  "translatedText": "يُطلق على عامل القياس الخاص جدًا هذا، وهو العامل الذي يغير به التحويل الخطي أي منطقة، محدد هذا التحويل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.9,
  "end": 157.12
 },
 {
  "input": "I'll show how to compute the determinant of a transformation using its matrix later on in this video, but understanding what it represents is, trust me, much more important than the computation. ",
  "translatedText": "سأوضح كيفية حساب محدد التحويل باستخدام مصفوفته لاحقًا في هذا الفيديو، لكن فهم ما تمثله، ثق بي، أكثر أهمية بكثير من الحساب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 168.42
 },
 {
  "input": "For example, the determinant of a transformation would be 3 if that transformation increases the area of a region by a factor of 3. ",
  "translatedText": "على سبيل المثال، محدد التحول سيكون 3 إذا كان هذا التحول يزيد من مساحة المنطقة بعامل 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.58,
  "end": 177.04
 },
 {
  "input": "The determinant of a transformation would be 1 half if it squishes down all areas by a factor of 1 half. ",
  "translatedText": "سيكون محدد التحول هو النصف إذا سحق جميع المناطق بعامل النصف. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.18,
  "end": 184.34
 },
 {
  "input": "And the determinant of a 2D transformation is 0 if it squishes all of space onto a line, or even onto a single point. ",
  "translatedText": "ومحدد التحويل ثنائي الأبعاد هو 0 إذا سحق كل المساحة على خط، أو حتى على نقطة واحدة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.0,
  "end": 193.5
 },
 {
  "input": "Since then, the area of any region would become 0. ",
  "translatedText": "ومنذ ذلك الحين، ستصبح مساحة أي منطقة 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.0,
  "end": 196.76
 },
 {
  "input": "That last example will prove to be pretty important. ",
  "translatedText": "سيثبت هذا المثال الأخير أنه مهم جدًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.62,
  "end": 199.6
 },
 {
  "input": "It means that checking if the determinant of a given matrix is 0 will give a way of computing whether or not the transformation associated with that matrix squishes everything into a smaller dimension. ",
  "translatedText": "وهذا يعني أن التحقق مما إذا كان محدد مصفوفة معينة هو 0 سيعطي طريقة لحساب ما إذا كان التحويل المرتبط بتلك المصفوفة سيسحق كل شيء إلى بُعد أصغر أم لا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.02,
  "end": 209.74
 },
 {
  "input": "You'll see in the next few videos why this is even a useful thing to think about, but for now, I just want to lay down all of the visual intuition, which, in and of itself, is a beautiful thing to think about. ",
  "translatedText": "سترون في مقاطع الفيديو القليلة التالية لماذا يعد هذا أمرًا مفيدًا للتفكير فيه، ولكن في الوقت الحالي، أريد فقط أن أضع كل الحدس البصري، والذي، في حد ذاته، شيء جميل للتفكير فيه . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.52,
  "end": 220.1
 },
 {
  "input": "Okay, I need to confess that what I've said so far is not quite right. ",
  "translatedText": "حسنًا، يجب أن أعترف بأن ما قلته حتى الآن ليس صحيحًا تمامًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.12,
  "end": 225.56
 },
 {
  "input": "The full concept of the determinant allows for negative values. ",
  "translatedText": "المفهوم الكامل للمحدد يسمح بالقيم السلبية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 225.88,
  "end": 229.28
 },
 {
  "input": "But what would the idea of scaling an area by a negative amount even mean? ",
  "translatedText": "ولكن ماذا تعني فكرة توسيع مساحة ما بمقدار سلبي؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.72,
  "end": 233.48
 },
 {
  "input": "This has to do with the idea of orientation. ",
  "translatedText": "وهذا له علاقة بفكرة التوجه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 234.94,
  "end": 236.96
 },
 {
  "input": "For example, notice how this transformation gives the sensation of flipping space over. ",
  "translatedText": "على سبيل المثال، لاحظ كيف يعطي هذا التحول الإحساس بقلب الفضاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.8,
  "end": 242.68
 },
 {
  "input": "If you were thinking of 2D space as a sheet of paper, a transformation like that one seems to turn over that sheet onto the other side. ",
  "translatedText": "إذا كنت تفكر في الفضاء ثنائي الأبعاد باعتباره ورقة، فإن تحويلًا مثل هذا يبدو أنه يقلب تلك الورقة على الجانب الآخر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.24,
  "end": 249.86
 },
 {
  "input": "Many transformations that do this are said to invert the orientation of space. ",
  "translatedText": "ويقال إن العديد من التحولات التي تفعل ذلك تعكس اتجاه الفضاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.64,
  "end": 255.04
 },
 {
  "input": "Another way to think about it is in terms of i-hat and j-hat. ",
  "translatedText": "هناك طريقة أخرى للتفكير في الأمر من حيث i-hat وj-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.84,
  "end": 258.6
 },
 {
  "input": "Notice that in their starting positions, j-hat is to the left of i-hat. ",
  "translatedText": "لاحظ أنه في مواضع البداية، يقع j-hat على يسار i-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.16,
  "end": 263.06
 },
 {
  "input": "If after a transformation, j-hat is now on the right of i-hat, the orientation of space has been inverted. ",
  "translatedText": "إذا أصبح j-hat الآن على يمين i-hat بعد التحويل، فهذا يعني أن اتجاه الفضاء قد تم عكسه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.62,
  "end": 270.2
 },
 {
  "input": "Whenever this happens, whenever the orientation of space is inverted, the determinant will be negative. ",
  "translatedText": "كلما حدث هذا، كلما كان اتجاه الفضاء مقلوبًا، سيكون المحدد سالبًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.12,
  "end": 276.58
 },
 {
  "input": "The absolute value of the determinant, though, still tells you the factor by which areas have been scaled. ",
  "translatedText": "ومع ذلك، فإن القيمة المطلقة للمحدد لا تزال تخبرك بالعامل الذي تم من خلاله قياس المساحات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.46,
  "end": 282.4
 },
 {
  "input": "For example, the matrix with columns 1, 1 and 2, negative 1 encodes a transformation that has determinant, I'll just tell you, negative 3. ",
  "translatedText": "على سبيل المثال، المصفوفة ذات الأعمدة 1 و1 و2، سالب 1 تقوم بتشفير تحويل له محدد، سأخبرك فقط، سالب 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.02,
  "end": 290.68
 },
 {
  "input": "And what this means is that space gets flipped over and areas are scaled by a factor of 3. ",
  "translatedText": "وما يعنيه هذا هو أن الفضاء ينقلب ويتم قياس المساحات بعامل 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.46,
  "end": 296.28
 },
 {
  "input": "So why would this idea of a negative area scaling factor be a natural way to describe orientation flipping? ",
  "translatedText": "فلماذا تكون فكرة عامل قياس المساحة السالبة طريقة طبيعية لوصف انقلاب الاتجاه؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.78,
  "end": 303.7
 },
 {
  "input": "Think about the series of transformations you get by slowly letting i-hat get closer and closer to j-hat. ",
  "translatedText": "فكر في سلسلة التحولات التي تحصل عليها من خلال السماح لـ i-hat بالاقتراب ببطء من j-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.26,
  "end": 310.14
 },
 {
  "input": "As i-hat gets closer, all of the areas in space are getting squished more and more, meaning the determinant approaches 0. ",
  "translatedText": "مع اقتراب i-hat، يتم سحق جميع المناطق في الفضاء أكثر فأكثر، مما يعني أن المحدد يقترب من 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.72,
  "end": 317.1
 },
 {
  "input": "Once i-hat lines up perfectly with j-hat, the determinant is 0. ",
  "translatedText": "بمجرد محاذاة i-hat بشكل مثالي مع j-hat، يصبح المحدد 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.82,
  "end": 321.64
 },
 {
  "input": "Then, if i-hat continues the way that it was going, doesn't it kind of feel natural for the determinant to keep decreasing into the negative numbers? ",
  "translatedText": "بعد ذلك، إذا استمرت i-hat بالطريقة التي كانت تسير بها، ألا يبدو من الطبيعي أن يستمر المحدد في التناقص إلى الأرقام السالبة؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.44,
  "end": 329.28
 },
 {
  "input": "So that's the understanding of determinants in two dimensions. ",
  "translatedText": "إذن هذا هو فهم المحددات ذات البعدين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.68,
  "end": 333.56
 },
 {
  "input": "What do you think it should mean for three dimensions? ",
  "translatedText": "ما رأيك يجب أن يعني لثلاثة أبعاد؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.56,
  "end": 335.94
 },
 {
  "input": "It also tells you how much a transformation scales things, but this time it tells you how much volumes get scaled. ",
  "translatedText": "ويخبرك أيضًا بمقدار التحويل الذي يقيس الأشياء، لكنه يخبرك هذه المرة بمقدار الأحجام التي يتم قياسها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.92,
  "end": 343.24
 },
 {
  "input": "Just as in two dimensions, where this is easiest to think about by focusing on one particular square with an area 1 and watching only what happens to it, in three dimensions it helps to focus your attention on the specific 1 by 1 by 1 cube whose edges are resting on the basis vectors i-hat, j-hat, and k-hat. ",
  "translatedText": "تمامًا كما هو الحال في البعدين، حيث يكون من الأسهل التفكير في ذلك من خلال التركيز على مربع معين بمساحة 1 ومشاهدة ما يحدث له فقط، فإن الأبعاد الثلاثة تساعد على تركيز انتباهك على المكعب المحدد 1 × 1 × 1 الذي ترتكز الحواف على المتجهات الأساسية i-hat وj-hat وk-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.34,
  "end": 363.44
 },
 {
  "input": "After the transformation, that cube might get warped into some kind of slanty slanty cube. ",
  "translatedText": "بعد التحويل، قد يتم تشويه هذا المكعب إلى نوع من المكعب المائل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.32,
  "end": 369.3
 },
 {
  "input": "This shape, by the way, has the best name ever, parallel a pipette, a name that's made even more delightful when your professor has a nice thick Russian accent. ",
  "translatedText": "هذا الشكل، بالمناسبة، لديه أفضل اسم على الإطلاق، موازيًا للماصة، وهو الاسم الذي يصبح أكثر إمتاعًا عندما يتحدث أستاذك بلكنة روسية سميكة لطيفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.34,
  "end": 377.44
 },
 {
  "input": "Since this cube starts out with a volume of 1 and the determinant gives the factor by which any volume is scaled, you can think of the determinant simply as being the volume of that parallel a pipette that the cube turns into. ",
  "translatedText": "نظرًا لأن هذا المكعب يبدأ بحجم 1 والمحدد يعطي العامل الذي يتم من خلاله قياس أي حجم، فيمكنك التفكير في المحدد ببساطة على أنه حجم الماصة الموازية التي يتحول إليها المكعب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.52,
  "end": 390.64
 },
 {
  "input": "A determinant of 0 would mean that all of space is squished onto something with 0 volume, meaning either a flat plane, a line, or, in the most extreme case, onto a single point. ",
  "translatedText": "المحدد بـ 0 يعني أن كل الفضاء مضغوط على شيء بحجم 0، مما يعني إما مستوى مسطح، أو خط، أو، في الحالة القصوى، على نقطة واحدة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.38,
  "end": 402.5
 },
 {
  "input": "Those of you who watched chapter 2 will recognize this as meaning that the columns of the matrix are linearly dependent. ",
  "translatedText": "أولئك الذين شاهدوا الفصل الثاني منكم سيدركون أن هذا يعني أن أعمدة المصفوفة تعتمد خطيًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.76,
  "end": 409.24
 },
 {
  "input": "Can you see why? ",
  "translatedText": "هل تستطيع أن ترى لماذا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.76,
  "end": 410.42
 },
 {
  "input": "What about negative determinants? ",
  "translatedText": "ماذا عن المحددات السلبية؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.92,
  "end": 416.64
 },
 {
  "input": "What should that mean for three dimensions? ",
  "translatedText": "ماذا يعني ذلك بالنسبة للأبعاد الثلاثة؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.78,
  "end": 418.1
 },
 {
  "input": "One way to describe orientation in 3D is with the right hand rule. ",
  "translatedText": "إحدى الطرق لوصف الاتجاه ثلاثي الأبعاد هي باستخدام قاعدة اليد اليمنى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.78,
  "end": 422.68
 },
 {
  "input": "Point the forefinger of your right hand in the direction of i-hat, stick out your middle finger in the direction of j-hat, and notice how when you point your thumb up, it's in the direction of k-hat. ",
  "translatedText": "قم بتوجيه إصبع السبابة بيدك اليمنى في اتجاه i-hat، ومد إصبعك الأوسط في اتجاه j-hat، ولاحظ كيف أنه عندما تشير بإبهامك للأعلى، يكون ذلك في اتجاه k-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.3,
  "end": 432.76
 },
 {
  "input": "If you can still do that after the transformation, orientation has not changed, and the determinant is positive. ",
  "translatedText": "إذا كان لا يزال بإمكانك القيام بذلك بعد التحويل، فإن الاتجاه لم يتغير، والمحدد إيجابي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.88,
  "end": 440.9
 },
 {
  "input": "Otherwise, if after the transformation it only makes sense to do that with your left hand, orientation has been flipped, and the determinant is negative. ",
  "translatedText": "بخلاف ذلك، إذا كان من المنطقي بعد التحويل فقط القيام بذلك بيدك اليسرى، فقد انقلب الاتجاه، وأصبح المحدد سلبيًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.54,
  "end": 449.38
 },
 {
  "input": "So if you haven't seen it before, you're probably wondering by now, how do you actually compute the determinant? ",
  "translatedText": "لذا، إذا لم تكن قد رأيت ذلك من قبل، فربما تتساءل الآن، كيف يمكنك حساب المحدد فعليًا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.9,
  "end": 457.04
 },
 {
  "input": "For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c. ",
  "translatedText": "بالنسبة لمصفوفة 2x2 ذات الإدخالات a، b، c، d، الصيغة هي a مضروبًا في d ناقص b مضروبًا في c. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.56,
  "end": 464.42
 },
 {
  "input": "Here's part of an intuition for where this formula comes from. ",
  "translatedText": "إليك جزء من الحدس حول مصدر هذه الصيغة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.74,
  "end": 468.5
 },
 {
  "input": "Let's say that the terms b and c both happened to be 0. ",
  "translatedText": "لنفترض أن الحدين b وc كلاهما يساوي 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.88,
  "end": 471.78
 },
 {
  "input": "Then the term a tells you how much i-hat is stretched in the x direction, and the term d tells you how much j-hat is stretched in the y direction. ",
  "translatedText": "ثم يخبرك المصطلح a بمقدار تمدد i-hat في الاتجاه x، ويخبرك المصطلح d بمقدار تمدد j-hat في الاتجاه y. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.78,
  "end": 481.16
 },
 {
  "input": "So since those other terms are 0, it should make sense that a times d gives the area of the rectangle that our favorite unit square turns into, kind of like the 3, 0, 0, 2 example from earlier. ",
  "translatedText": "لذا بما أن تلك الحدود الأخرى هي 0، فمن المنطقي أن a في d يعطي مساحة المستطيل الذي يتحول إليه مربع الوحدة المفضل لدينا، نوعًا ما مثل مثال 3، 0، 0، 2 السابق. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.76,
  "end": 493.36
 },
 {
  "input": "Even if only one of b or c are 0, you'll have a parallelogram with a base a and a height d, so the area should still be a times d. ",
  "translatedText": "حتى لو كان واحد فقط من b أو c يساوي 0، سيكون لديك متوازي أضلاع قاعدته a وارتفاعه d، لذا يجب أن تظل المساحة مضروبة في d. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.36,
  "end": 504.5
 },
 {
  "input": "Loosely speaking, if both b and c are non-zero, then that b times c term tells you how much this parallelogram is stretched or squished in the diagonal direction. ",
  "translatedText": "بشكل عام، إذا كان كل من b وc غير صفر، فإن الحد b مضروبًا في c يخبرك بمدى تمدد متوازي الأضلاع هذا أو سحقه في الاتجاه القطري. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.46,
  "end": 515.46
 },
 {
  "input": "For those of you hungry for a more precise description of this b times c term, here's a helpful diagram if you'd like to pause and ponder. ",
  "translatedText": "لأولئك منكم المتعطشين للحصول على وصف أكثر دقة لهذا المصطلح b ضرب c، إليك رسم تخطيطي مفيد إذا كنت ترغب في التوقف والتأمل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 516.66,
  "end": 522.88
 },
 {
  "input": "Now if you feel like computing determinants by hand is something that you need to know, the only way to get it down is to just practice it with a few. ",
  "translatedText": "الآن، إذا كنت تشعر أن حساب المحددات يدويًا هو شيء تحتاج إلى معرفته، فإن الطريقة الوحيدة لفهمه هي مجرد التدرب عليه مع القليل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.98,
  "end": 531.2
 },
 {
  "input": "There's really not that much I can say or animate that's going to drill in the computation. ",
  "translatedText": "ليس هناك حقًا الكثير مما يمكنني قوله أو تحريكه والذي سيتم حفره في الحساب. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.2,
  "end": 535.18
 },
 {
  "input": "This is all triply true for three-dimensional determinants. ",
  "translatedText": "وهذا كله صحيح ثلاث مرات بالنسبة للمحددات ثلاثية الأبعاد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.12,
  "end": 538.64
 },
 {
  "input": "There is a formula, and if you feel like that's something you need to know, you should practice with a few matrices, or, you know, go watch Sal Khan work through a few. ",
  "translatedText": "هناك صيغة، وإذا كنت تشعر أن هذا شيء تحتاج إلى معرفته، فيجب عليك التدرب على عدد قليل من المصفوفات، أو، كما تعلم، شاهد سال خان وهو يعمل من خلال عدد قليل منها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.04,
  "end": 546.34
 },
 {
  "input": "Honestly, though, I don't think that those computations fall within the essence of linear algebra, but I definitely think that understanding what the determinant represents falls within that essence. ",
  "translatedText": "بصراحة، لا أعتقد أن تلك الحسابات تقع ضمن جوهر الجبر الخطي، لكنني أعتقد بالتأكيد أن فهم ما يمثله المحدد يقع ضمن هذا الجوهر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 547.24,
  "end": 556.46
 },
 {
  "input": "Here's kind of a fun question to think about before the next video. ",
  "translatedText": "إليك سؤال ممتع يجب التفكير فيه قبل الفيديو التالي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.06,
  "end": 560.64
 },
 {
  "input": "If you multiply two matrices together, the determinant of the resulting matrix is the same as the product of the determinants of the original two matrices. ",
  "translatedText": "إذا قمت بضرب مصفوفتين معًا، فإن محدد المصفوفة الناتجة هو نفس حاصل ضرب محددات المصفوفتين الأصليتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.64,
  "end": 570.08
 },
 {
  "input": "If you tried to justify this with numbers, it would take a really long time, but see if you can explain why this makes sense in just one sentence. ",
  "translatedText": "إذا حاولت تبرير ذلك بالأرقام، فسيستغرق الأمر وقتًا طويلاً حقًا، ولكن انظر ما إذا كان بإمكانك شرح سبب منطقية ذلك في جملة واحدة فقط. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.1,
  "end": 577.88
 },
 {
  "input": "Next up, I'll be relating the idea of linear transformations covered so far to one of the areas where linear algebra is most useful, linear systems of equations. ",
  "translatedText": "بعد ذلك، سأقوم بربط فكرة التحويلات الخطية التي تمت تغطيتها حتى الآن بأحد المجالات التي يكون فيها الجبر الخطي أكثر فائدة، وهي أنظمة المعادلات الخطية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.0,
  "end": 590.96
 },
 {
  "input": "See you then! ",
  "translatedText": "اراك لاحقا! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.48,
  "end": 591.6
 }
]