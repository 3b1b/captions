[
 {
  "input": "Hello, hello again. ",
  "translatedText": "こんにちは、またこんにちは。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.98,
  "end": 13.0
 },
 {
  "input": "So moving forward, I'll be assuming that you have a visual understanding of linear transformations and how they're represented with matrices, the way that I've been talking about in the last few videos. ",
  "translatedText": "したがって、ここから先は、線形変換とそれが行列でどのよう に表現されるか、これまでのいくつかのビデオで説明してき た方法について視覚的に理解していることを前提とします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.52,
  "end": 21.84
 },
 {
  "input": "If you think about a couple of these linear transformations, you might notice how some of them seem to stretch space out, while others squish it on in. ",
  "translatedText": "これらの線形変換のいくつかについて考えると、その 一部は空間を広げているように見え、他のものは空間 を押しつぶしていることに気づくかもしれません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.66,
  "end": 30.42
 },
 {
  "input": "One thing that turns out to be pretty useful for understanding one of these transformations is to measure exactly how much it stretches or squishes things. ",
  "translatedText": "これらの変換の 1 つを理解するのに非常に役立つことが判明した 1 つは、そ れによって物体がどれだけ伸びたり潰されたりするかを正確に測定することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.14,
  "end": 38.92
 },
 {
  "input": "More specifically, to measure the factor by which the area of a given region increases or decreases. ",
  "translatedText": "より具体的には、特定の領域の面積が増加または減少する要因を測定します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.52,
  "end": 45.82
 },
 {
  "input": "For example, look at the matrix with columns 3, 0 and 0, 2. ",
  "translatedText": "たとえば、列 3、0 および列 0、2 を持つ行列を見てください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.18,
  "end": 50.88
 },
 {
  "input": "It scales i-hat by a factor of 3 and scales j-hat by a factor of 2. ",
  "translatedText": "i-hat は 3 倍に拡大縮小され、j-hat は 2 倍に拡大縮小されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.32,
  "end": 56.18
 },
 {
  "input": "Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle. ",
  "translatedText": "ここで、底面が i-hat 上にあり、左側が j-h at 上にある 1 × 1 の正方形に注目すると、 変換後、これは 2 × 3 の長方形に変わります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.7,
  "end": 67.52
 },
 {
  "input": "Since this region started out with area 1 and ended up with area 6, we can say the linear transformation has scaled its area by a factor of 6. ",
  "translatedText": "この領域は領域 1 で始まり、最終的に領域 6 になったため 、線形変換により領域が 6 倍にスケールされたと言えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.38,
  "end": 77.28
 },
 {
  "input": "Compare that to a shear whose matrix has columns 1, 0 and 1, 1, meaning i-hat stays in place and j-hat moves over to 1, 1. ",
  "translatedText": "これを、マトリックスに列 1, 0 および 1, 1 があるシアーと比較してください。これは 、i-hat が所定の位置に留まり、j-hat が 1, 1 に移動することを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.18,
  "end": 86.1
 },
 {
  "input": "That same unit square determined by i-hat and j-hat gets slanted and turned into a parallelogram, but the area of that parallelogram is still 1, since its base and height each continue to have length 1. ",
  "translatedText": "i-hat と j-hat によって決定される同じ単位正方形は 傾いて平行四辺形になりますが、その底辺と高さはそれぞれ長さが 1 のままであるため、その平行四辺形の面積は 1 のままです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.0,
  "end": 98.38
 },
 {
  "input": "So, even though this transformation smushes things about, it seems to leave areas unchanged, at least in the case of that 1 unit square. ",
  "translatedText": "したがって、この変換によって物事はめちゃくちゃになりますが、少なくと もその 1 単位正方形の場合には、面積は変更されないように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.18,
  "end": 105.62
 },
 {
  "input": "Actually though, if you know how much the area of that one single unit square changes, it can tell you how the area of any possible region in space changes. ",
  "translatedText": "しかし、実際には、その 1 つの単位正方形の面積がどのくらい変化するかがわか れば、空間内のあらゆる領域の面積がどのように変化するかを知ることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.82,
  "end": 115.52
 },
 {
  "input": "For starters, notice that whatever happens to one square in the grid has to happen to any other square in the grid, no matter the size. ",
  "translatedText": "まず、グリッド内の 1 つの正方形に起こることは、サイズに関係な く、グリッド内の他の正方形にも必ず起こることに注意してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.3,
  "end": 123.58
 },
 {
  "input": "This follows from the fact that grid lines remain parallel and evenly spaced. ",
  "translatedText": "これは、グリッド線が平行かつ等間隔のままであるという事実からわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.34,
  "end": 128.04
 },
 {
  "input": "Then, any shape that's not a grid square can be approximated by grid squares pretty well, with arbitrarily good approximations if you use small enough grid squares. ",
  "translatedText": "次に、グリッド正方形ではない任意の形状をグリッド正方形でかなりうまく近似することが できます。十分に小さいグリッド正方形を使用すると、任意に適切な近似が得られます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.76,
  "end": 137.52
 },
 {
  "input": "So, since the areas of all those tiny grid squares are being scaled by some single amount, the area of the blob as a whole will also be scaled by that same single amount. ",
  "translatedText": "したがって、これらすべての小さなグリッド正方形の面積は、ある 1 つの量だけスケ ーリングされるため、ブロブ全体の面積も同じ 1 つの量だけスケーリングされます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.52,
  "end": 147.82
 },
 {
  "input": "This very special scaling factor, the factor by which a linear transformation changes any area, is called the determinant of that transformation. ",
  "translatedText": "この非常に特別なスケーリング係数、つまり線形変換が任意の領域を 変更する際に使用される係数は、その変換の行列式と呼ばれます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.9,
  "end": 157.12
 },
 {
  "input": "I'll show how to compute the determinant of a transformation using its matrix later on in this video, but understanding what it represents is, trust me, much more important than the computation. ",
  "translatedText": "このビデオの後半で、行列を使用して変換の行列式を計算す る方法を説明しますが、信じてください、行列式が何を表し ているかを理解することは、計算よりもはるかに重要です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 168.42
 },
 {
  "input": "For example, the determinant of a transformation would be 3 if that transformation increases the area of a region by a factor of 3. ",
  "translatedText": "たとえば、変換によって領域の面積が 3 倍に増 加する場合、変換の行列式は 3 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.58,
  "end": 177.04
 },
 {
  "input": "The determinant of a transformation would be 1 half if it squishes down all areas by a factor of 1 half. ",
  "translatedText": "すべての領域を 1/2 の係数で押しつぶす場 合、変換の決定要因は 1/2 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.18,
  "end": 184.34
 },
 {
  "input": "And the determinant of a 2D transformation is 0 if it squishes all of space onto a line, or even onto a single point. ",
  "translatedText": "そして、2D 変換の行列式は、空間全体を直線上に押し込 むか、単一の点上に押し込む場合でも 0 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.0,
  "end": 193.5
 },
 {
  "input": "Since then, the area of any region would become 0. ",
  "translatedText": "それ以降、どの領域の面積も 0 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.0,
  "end": 196.76
 },
 {
  "input": "That last example will prove to be pretty important. ",
  "translatedText": "最後の例は非常に重要であることがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.62,
  "end": 199.6
 },
 {
  "input": "It means that checking if the determinant of a given matrix is 0 will give a way of computing whether or not the transformation associated with that matrix squishes everything into a smaller dimension. ",
  "translatedText": "これは、特定の行列の行列式が 0 であるかどうかをチェックすること で、その行列に関連付けられた変換によってすべてがより小さい次元に 押しつぶされるかどうかを計算する方法が得られることを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.02,
  "end": 209.74
 },
 {
  "input": "You'll see in the next few videos why this is even a useful thing to think about, but for now, I just want to lay down all of the visual intuition, which, in and of itself, is a beautiful thing to think about. ",
  "translatedText": "これがなぜ考えるのに役立つのかは、次のいくつかのビデオでわ かりますが、今のところは、視覚的な直観をすべて述べておきた いと思います。それ自体、考えるのは素晴らしいことです。。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.52,
  "end": 220.1
 },
 {
  "input": "Okay, I need to confess that what I've said so far is not quite right. ",
  "translatedText": "さて、これまで述べてきたことは完全に正しくないことを告白しなければなりません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.12,
  "end": 225.56
 },
 {
  "input": "The full concept of the determinant allows for negative values. ",
  "translatedText": "行列式の完全な概念では、負の値が許容されます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 225.88,
  "end": 229.28
 },
 {
  "input": "But what would the idea of scaling an area by a negative amount even mean? ",
  "translatedText": "しかし、エリアをマイナスの量で拡大縮小するという考えは一体何を意味するのでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.72,
  "end": 233.48
 },
 {
  "input": "This has to do with the idea of orientation. ",
  "translatedText": "これは方向性の考え方と関係があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 234.94,
  "end": 236.96
 },
 {
  "input": "For example, notice how this transformation gives the sensation of flipping space over. ",
  "translatedText": "たとえば、この変換によって空間がひっくり返る感覚がどのように生じるかに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.8,
  "end": 242.68
 },
 {
  "input": "If you were thinking of 2D space as a sheet of paper, a transformation like that one seems to turn over that sheet onto the other side. ",
  "translatedText": "2D 空間を 1 枚の紙として考えた場合、このような 変換はその紙を反対側にひっくり返すように見えます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.24,
  "end": 249.86
 },
 {
  "input": "Many transformations that do this are said to invert the orientation of space. ",
  "translatedText": "これを行う多くの変換は、空間の方向を反転させると言われています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.64,
  "end": 255.04
 },
 {
  "input": "Another way to think about it is in terms of i-hat and j-hat. ",
  "translatedText": "これを i-hat と j-hat の観点から考えるもう 1 つの方法があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.84,
  "end": 258.6
 },
 {
  "input": "Notice that in their starting positions, j-hat is to the left of i-hat. ",
  "translatedText": "開始位置では、j-hat が i-hat の左側にあることに注意してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.16,
  "end": 263.06
 },
 {
  "input": "If after a transformation, j-hat is now on the right of i-hat, the orientation of space has been inverted. ",
  "translatedText": "変換後、j-hat が i-hat の右側 にある場合、空間の方向は反転しています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.62,
  "end": 270.2
 },
 {
  "input": "Whenever this happens, whenever the orientation of space is inverted, the determinant will be negative. ",
  "translatedText": "これが起こるたびに、空間の方向が反転 するたびに、行列式は負になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.12,
  "end": 276.58
 },
 {
  "input": "The absolute value of the determinant, though, still tells you the factor by which areas have been scaled. ",
  "translatedText": "ただし、行列式の絶対値によって、領域が スケーリングされた係数がわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.46,
  "end": 282.4
 },
 {
  "input": "For example, the matrix with columns 1, 1 and 2, negative 1 encodes a transformation that has determinant, I'll just tell you, negative 3. ",
  "translatedText": "たとえば、列 1、1、2 の行列の負の 1 は、行列式 (ここ で言っておきますが、負の 3) を持つ変換をエンコードします。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.02,
  "end": 290.68
 },
 {
  "input": "And what this means is that space gets flipped over and areas are scaled by a factor of 3. ",
  "translatedText": "これが意味するのは、空間が反転し、領域 が 3 倍に拡大されるということです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.46,
  "end": 296.28
 },
 {
  "input": "So why would this idea of a negative area scaling factor be a natural way to describe orientation flipping? ",
  "translatedText": "では、なぜこの負の面積スケーリング係数という考え方が 向きの反転を説明する自然な方法となるのでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.78,
  "end": 303.7
 },
 {
  "input": "Think about the series of transformations you get by slowly letting i-hat get closer and closer to j-hat. ",
  "translatedText": "i-hat を徐々に j-hat に近づけること で得られる一連の変化について考えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.26,
  "end": 310.14
 },
 {
  "input": "As i-hat gets closer, all of the areas in space are getting squished more and more, meaning the determinant approaches 0. ",
  "translatedText": "i-hat が近づくにつれて、空間内のすべての領域がますま す押しつぶされ、行列式が 0 に近づくことを意味します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.72,
  "end": 317.1
 },
 {
  "input": "Once i-hat lines up perfectly with j-hat, the determinant is 0. ",
  "translatedText": "i-hat が j-hat と完全に一致すると、行列式は 0 になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.82,
  "end": 321.64
 },
 {
  "input": "Then, if i-hat continues the way that it was going, doesn't it kind of feel natural for the determinant to keep decreasing into the negative numbers? ",
  "translatedText": "では、i-hat がこのまま進んでい くと、行列式がマイナスになり続けるの は、ある意味自然ではないでしょうか。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.44,
  "end": 329.28
 },
 {
  "input": "So that's the understanding of determinants in two dimensions. ",
  "translatedText": "これが 2 次元での行列式の理解です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.68,
  "end": 333.56
 },
 {
  "input": "What do you think it should mean for three dimensions? ",
  "translatedText": "それは三次元にとって何を意味すると思いますか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.56,
  "end": 335.94
 },
 {
  "input": "It also tells you how much a transformation scales things, but this time it tells you how much volumes get scaled. ",
  "translatedText": "また、変換によってどの程度スケールされるのかもわかりますが、 今回はボリュームがどのくらいスケールされるのかがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.92,
  "end": 343.24
 },
 {
  "input": "Just as in two dimensions, where this is easiest to think about by focusing on one particular square with an area 1 and watching only what happens to it, in three dimensions it helps to focus your attention on the specific 1 by 1 by 1 cube whose edges are resting on the basis vectors i-hat, j-hat, and k-hat. ",
  "translatedText": "2 次元では、面積 1 の特定の正方形に焦点を 当て、そこに何が起こるかだけを観察することが 最も簡単に考えられますが、3 次元では、特定の 1 x 1 x 1 の立方体に注意を集中さ せると役立ちます。エッジは基底ベクトル i-h at、j-hat、k-hat 上にあります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.34,
  "end": 363.44
 },
 {
  "input": "After the transformation, that cube might get warped into some kind of slanty slanty cube. ",
  "translatedText": "変形後、その立方体は何らかの斜めの 立方体に変形する可能性があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.32,
  "end": 369.3
 },
 {
  "input": "This shape, by the way, has the best name ever, parallel a pipette, a name that's made even more delightful when your professor has a nice thick Russian accent. ",
  "translatedText": "ちなみに、この形には、ピペットに匹敵する史上最 高の名前が付けられています。教授が素敵なロシ ア訛りを話すと、さらに楽しい名前になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.34,
  "end": 377.44
 },
 {
  "input": "Since this cube starts out with a volume of 1 and the determinant gives the factor by which any volume is scaled, you can think of the determinant simply as being the volume of that parallel a pipette that the cube turns into. ",
  "translatedText": "この立方体の体積は 1 から始まり、行列 式は体積をスケールする係数を与えるため 、行列式は単に立方体が変形する平行ピペッ トの体積であると考えることができます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.52,
  "end": 390.64
 },
 {
  "input": "A determinant of 0 would mean that all of space is squished onto something with 0 volume, meaning either a flat plane, a line, or, in the most extreme case, onto a single point. ",
  "translatedText": "行列式 0 は、すべての空間が体積 0 のものに押しつぶされることを意味し ます。つまり、平面、線、または最も極端 な場合は 1 点に押しつぶされます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.38,
  "end": 402.5
 },
 {
  "input": "Those of you who watched chapter 2 will recognize this as meaning that the columns of the matrix are linearly dependent. ",
  "translatedText": "第 2 章をご覧になった方は、これが行列の列が線形に 依存していることを意味していることがわかるでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.76,
  "end": 409.24
 },
 {
  "input": "Can you see why? ",
  "translatedText": "理由がわかりますか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.76,
  "end": 410.42
 },
 {
  "input": "What about negative determinants? ",
  "translatedText": "負の決定要因についてはどうでしょうか？",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.92,
  "end": 416.64
 },
 {
  "input": "What should that mean for three dimensions? ",
  "translatedText": "それは三次元にとって何を意味するのでしょうか? ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.78,
  "end": 418.1
 },
 {
  "input": "One way to describe orientation in 3D is with the right hand rule. ",
  "translatedText": "3D で方向を記述する 1 つの方法は、右手の法則を使用することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.78,
  "end": 422.68
 },
 {
  "input": "Point the forefinger of your right hand in the direction of i-hat, stick out your middle finger in the direction of j-hat, and notice how when you point your thumb up, it's in the direction of k-hat. ",
  "translatedText": "右手の人差し指を i-hat の方向に向け、中指を j-hat の方向に突き出し、親指を上に向けると k-hat の方向になることに注目してください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.3,
  "end": 432.76
 },
 {
  "input": "If you can still do that after the transformation, orientation has not changed, and the determinant is positive. ",
  "translatedText": "変換後もそれが可能であれば、方向は 変化しておらず、行列式は正です。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.88,
  "end": 440.9
 },
 {
  "input": "Otherwise, if after the transformation it only makes sense to do that with your left hand, orientation has been flipped, and the determinant is negative. ",
  "translatedText": "それ以外の場合、変換後に左手でのみ 行うことが意味がある場合は、方向 が反転し、行列式は負になります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.54,
  "end": 449.38
 },
 {
  "input": "So if you haven't seen it before, you're probably wondering by now, how do you actually compute the determinant? ",
  "translatedText": "これまで見たことがなければ、行列式を実際にどのよ うに計算するのか、と疑問に思っているでしょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.9,
  "end": 457.04
 },
 {
  "input": "For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c. ",
  "translatedText": "エントリ a、b、c、d を持つ 2x2 行列の場合、式は a 掛ける d から b 掛ける c を引いたものになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.56,
  "end": 464.42
 },
 {
  "input": "Here's part of an intuition for where this formula comes from. ",
  "translatedText": "この公式がどこから来たのかについての直感の一部を次に示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.74,
  "end": 468.5
 },
 {
  "input": "Let's say that the terms b and c both happened to be 0. ",
  "translatedText": "項 b と項 c が両方ともたまたま 0 だったとしましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.88,
  "end": 471.78
 },
 {
  "input": "Then the term a tells you how much i-hat is stretched in the x direction, and the term d tells you how much j-hat is stretched in the y direction. ",
  "translatedText": "次に、項 a は i-hat が x 方向にどれだけ伸ばされるかを示し、 項 d は j-hat が y 方向にどれだけ伸ばされるかを示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.78,
  "end": 481.16
 },
 {
  "input": "So since those other terms are 0, it should make sense that a times d gives the area of the rectangle that our favorite unit square turns into, kind of like the 3, 0, 0, 2 example from earlier. ",
  "translatedText": "したがって、これらの他の項は 0 であるため、a に d を掛ける と、先ほどの 3, 0, 0, 2 の例のように、お気に入りの単位 正方形が変形する長方形の面積が得られることは理にかなっています。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.76,
  "end": 493.36
 },
 {
  "input": "Even if only one of b or c are 0, you'll have a parallelogram with a base a and a height d, so the area should still be a times d. ",
  "translatedText": "b または c のいずれか 1 つだけが 0 であっても、底辺が a 、高さが d の平行四辺形ができるため、面積は a 倍のはずです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.36,
  "end": 504.5
 },
 {
  "input": "Loosely speaking, if both b and c are non-zero, then that b times c term tells you how much this parallelogram is stretched or squished in the diagonal direction. ",
  "translatedText": "大まかに言うと、b と c の両方がゼロ以外の場合、b と c の項の掛け合わせによって、 この平行四辺形が対角線方向にどの程度伸びているか、または押しつぶされているかがわかります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.46,
  "end": 515.46
 },
 {
  "input": "For those of you hungry for a more precise description of this b times c term, here's a helpful diagram if you'd like to pause and ponder. ",
  "translatedText": "この b 倍 c という用語のより正確な説明を求めている方のた めに、立ち止まって熟考したい場合に役立つ図をここに示します。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 516.66,
  "end": 522.88
 },
 {
  "input": "Now if you feel like computing determinants by hand is something that you need to know, the only way to get it down is to just practice it with a few. ",
  "translatedText": "さて、行列式を手作業で計算することを知っておく必要があると感じたら、 それを理解する唯一の方法は、いくつかの関数を使って練習することです。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.98,
  "end": 531.2
 },
 {
  "input": "There's really not that much I can say or animate that's going to drill in the computation. ",
  "translatedText": "計算を掘り下げるために私が発言したりアニメーションにしたりできることはそれほど多くありません。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.2,
  "end": 535.18
 },
 {
  "input": "This is all triply true for three-dimensional determinants. ",
  "translatedText": "これはすべて、3 次元の行列式に三重に当てはまります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.12,
  "end": 538.64
 },
 {
  "input": "There is a formula, and if you feel like that's something you need to know, you should practice with a few matrices, or, you know, go watch Sal Khan work through a few. ",
  "translatedText": "公式があり、それを知る必要があると感じる場合は、いくつかの行列を使って練習 するか、Sal Khan がいくつかの行列を計算する様子を見てください。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.04,
  "end": 546.34
 },
 {
  "input": "Honestly, though, I don't think that those computations fall within the essence of linear algebra, but I definitely think that understanding what the determinant represents falls within that essence. ",
  "translatedText": "正直なところ、これらの計算は線形代数の本質に含まれるとは思いませんが、行列式 が何を表すかを理解することは線形代数の本質に含まれることは確かだと思います。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 547.24,
  "end": 556.46
 },
 {
  "input": "Here's kind of a fun question to think about before the next video. ",
  "translatedText": "次のビデオの前に、ちょっと考えてみると楽しい質問があります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.06,
  "end": 560.64
 },
 {
  "input": "If you multiply two matrices together, the determinant of the resulting matrix is the same as the product of the determinants of the original two matrices. ",
  "translatedText": "2 つの行列を乗算すると、結果の行列の行列式は、 元の 2 つの行列の行列式の積と同じになります。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.64,
  "end": 570.08
 },
 {
  "input": "If you tried to justify this with numbers, it would take a really long time, but see if you can explain why this makes sense in just one sentence. ",
  "translatedText": "これを数字で正当化しようとすると、非常に長い時間がかかりますが、なぜこれ が意味をなすのかをたった 1 文で説明できるかどうかを考えてみましょう。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.1,
  "end": 577.88
 },
 {
  "input": "Next up, I'll be relating the idea of linear transformations covered so far to one of the areas where linear algebra is most useful, linear systems of equations. ",
  "translatedText": "次に、これまで説明してきた線形変換の考え方を、線形代数が最 も役立つ分野の 1 つである線形方程式系に関連付けます。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.0,
  "end": 590.96
 },
 {
  "input": "See you then! ",
  "translatedText": "それではまた！",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.48,
  "end": 591.6
 }
]