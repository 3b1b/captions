[
 {
  "input": "Hello, hello again.",
  "translatedText": "வணக்கம், மீண்டும் வணக்கம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.98,
  "end": 13.0
 },
 {
  "input": "So moving forward, I'll be assuming that you have a visual understanding of linear transformations and how they're represented with matrices, the way that I've been talking about in the last few videos.",
  "translatedText": "எனவே முன்னோக்கிச் செல்லும்போது, கடந்த சில வீடியோக்களில் நான் பேசிய விதம், லீனியர் உருமாற்றங்கள் மற்றும் அவை மெட்ரிக்குகளுடன் எவ்வாறு குறிப்பிடப்படுகின்றன என்பதைப் பற்றிய காட்சிப் புரிதல் உங்களிடம் இருப்பதாக நான் கருதுகிறேன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.52,
  "end": 21.84
 },
 {
  "input": "If you think about a couple of these linear transformations, you might notice how some of them seem to stretch space out, while others squish it on in.",
  "translatedText": "இந்த இரண்டு நேரியல் மாற்றங்களைப் பற்றி நீங்கள் சிந்தித்தால், அவற்றில் சில எவ்வாறு இடத்தை நீட்டிக்கின்றன, மற்றவை அதை உள்ளே இழுக்கின்றன என்பதை நீங்கள் கவனிக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.66,
  "end": 30.42
 },
 {
  "input": "One thing that turns out to be pretty useful for understanding one of these transformations is to measure exactly how much it stretches or squishes things.",
  "translatedText": "இந்த மாற்றங்களில் ஒன்றைப் புரிந்துகொள்வதற்கு மிகவும் பயனுள்ளதாக இருக்கும் ஒரு விஷயம் என்னவென்றால், அது எவ்வளவு விஷயங்களை நீட்டிக்கிறது அல்லது குறைக்கிறது என்பதை அளவிடுவது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.14,
  "end": 38.92
 },
 {
  "input": "More specifically, to measure the factor by which the area of a given region increases or decreases.",
  "translatedText": "மேலும் குறிப்பாக, கொடுக்கப்பட்ட பகுதியின் பரப்பளவு அதிகரிக்கும் அல்லது குறையும் காரணியை அளவிடுவதற்கு.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.52,
  "end": 45.82
 },
 {
  "input": "For example, look at the matrix with columns 3, 0 and 0, 2.",
  "translatedText": "எடுத்துக்காட்டாக, 3, 0 மற்றும் 0, 2 நெடுவரிசைகளைக் கொண்ட அணியைப் பார்க்கவும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.18,
  "end": 50.88
 },
 {
  "input": "It scales i-hat by a factor of 3 and scales j-hat by a factor of 2.",
  "translatedText": "இது i-hat ஐ 3 காரணியாகவும், j-hat ஐ 2 காரணியாகவும் அளவிடுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.32,
  "end": 56.18
 },
 {
  "input": "Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle.",
  "translatedText": "இப்போது, 1 க்கு 1 சதுரத்தின் மீது நாம் கவனம் செலுத்தினால், அதன் அடிப்பகுதி i-hat மற்றும் இடது பக்கம் j-hat மீது அமர்ந்து, மாற்றத்திற்குப் பிறகு, இது 2 by 3 செவ்வகமாக மாறும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.7,
  "end": 67.52
 },
 {
  "input": "Since this region started out with area 1 and ended up with area 6, we can say the linear transformation has scaled its area by a factor of 6.",
  "translatedText": "இந்தப் பகுதி பகுதி 1 இல் தொடங்கி பகுதி 6 இல் முடிவடைந்ததால், நேரியல் மாற்றம் அதன் பரப்பளவை 6 காரணிகளால் அளவிடுகிறது என்று கூறலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.38,
  "end": 77.28
 },
 {
  "input": "Compare that to a shear whose matrix has columns 1, 0 and 1, 1, meaning i-hat stays in place and j-hat moves over to 1, 1.",
  "translatedText": "அணி 1, 0 மற்றும் 1, 1 நெடுவரிசைகளைக் கொண்ட ஒரு வெட்டுடன் ஒப்பிடவும், அதாவது i-hat இடத்தில் இருக்கும் மற்றும் j-hat 1, 1 க்கு மேல் நகரும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.18,
  "end": 86.1
 },
 {
  "input": "That same unit square determined by i-hat and j-hat gets slanted and turned into a parallelogram, but the area of that parallelogram is still 1, since its base and height each continue to have length 1.",
  "translatedText": "i-hat மற்றும் j-hat ஆகியவற்றால் நிர்ணயிக்கப்பட்ட அதே அலகு சதுரம் சாய்ந்து ஒரு இணையான வரைபடமாக மாறுகிறது, ஆனால் அந்த இணையான வரைபடத்தின் பரப்பளவு இன்னும் 1 ஆக உள்ளது, ஏனெனில் அதன் அடிப்பகுதி மற்றும் உயரம் ஒவ்வொன்றும் நீளம் 1 ஆக தொடர்கிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.0,
  "end": 98.38
 },
 {
  "input": "So, even though this transformation smushes things about, it seems to leave areas unchanged, at least in the case of that 1 unit square.",
  "translatedText": "எனவே, இந்த மாற்றம் விஷயங்களைச் சிதைத்தாலும், குறைந்தபட்சம் அந்த 1 யூனிட் சதுரத்தின் விஷயத்திலாவது பகுதிகள் மாறாமல் இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.18,
  "end": 105.62
 },
 {
  "input": "Actually though, if you know how much the area of that one single unit square changes, it can tell you how the area of any possible region in space changes.",
  "translatedText": "உண்மையில், அந்த ஒற்றை அலகு சதுரத்தின் பரப்பளவு எவ்வளவு மாறுகிறது என்பது உங்களுக்குத் தெரிந்தால், விண்வெளியில் சாத்தியமான எந்தப் பகுதியின் பரப்பளவும் எவ்வாறு மாறுகிறது என்பதை அது உங்களுக்குத் தெரிவிக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.82,
  "end": 115.52
 },
 {
  "input": "For starters, notice that whatever happens to one square in the grid has to happen to any other square in the grid, no matter the size.",
  "translatedText": "தொடங்குபவர்களுக்கு, கட்டத்தின் ஒரு சதுரத்திற்கு என்ன நடந்தாலும், அது எந்த அளவில் இருந்தாலும், கட்டத்தில் உள்ள வேறு எந்த சதுரத்திற்கும் நடக்க வேண்டும் என்பதைக் கவனியுங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.3,
  "end": 123.58
 },
 {
  "input": "This follows from the fact that grid lines remain parallel and evenly spaced.",
  "translatedText": "கட்டக் கோடுகள் இணையாகவும் சமமான இடைவெளியிலும் இருப்பதன் மூலம் இது பின்பற்றப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.34,
  "end": 128.04
 },
 {
  "input": "Then, any shape that's not a grid square can be approximated by grid squares pretty well, with arbitrarily good approximations if you use small enough grid squares.",
  "translatedText": "பின்னர், கட்டம் சதுரம் அல்லாத எந்த வடிவத்தையும் கட்டம் சதுரங்கள் மூலம் தோராயமாக மதிப்பிட முடியும், நீங்கள் போதுமான சிறிய கட்ட சதுரங்களைப் பயன்படுத்தினால், தன்னிச்சையாக நல்ல தோராயங்களுடன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.76,
  "end": 137.52
 },
 {
  "input": "So, since the areas of all those tiny grid squares are being scaled by some single amount, the area of the blob as a whole will also be scaled by that same single amount.",
  "translatedText": "எனவே, அந்த சிறிய கிரிட் சதுரங்களின் பகுதிகள் சில ஒற்றைத் தொகையால் அளவிடப்படுவதால், ஒட்டுமொத்த ப்ளாப்பின் பரப்பளவும் அதே ஒற்றைத் தொகையால் அளவிடப்படும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.52,
  "end": 147.82
 },
 {
  "input": "This very special scaling factor, the factor by which a linear transformation changes any area, is called the determinant of that transformation.",
  "translatedText": "இந்த சிறப்பு அளவிடுதல் காரணி, ஒரு நேரியல் மாற்றம் எந்தப் பகுதியையும் மாற்றும் காரணி, அந்த உருமாற்றத்தின் நிர்ணயம் என்று அழைக்கப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.9,
  "end": 157.12
 },
 {
  "input": "I'll show how to compute the determinant of a transformation using its matrix later on in this video, but understanding what it represents is, trust me, much more important than the computation.",
  "translatedText": "இந்த வீடியோவில் அதன் மேட்ரிக்ஸைப் பயன்படுத்தி உருமாற்றத்தின் தீர்மானிப்பதை எவ்வாறு கணக்கிடுவது என்பதை நான் பின்னர் காண்பிப்பேன், ஆனால் அது எதைக் குறிக்கிறது என்பதைப் புரிந்துகொள்வது, கணக்கீட்டை விட மிகவும் முக்கியமானது, என்னை நம்புங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 168.42
 },
 {
  "input": "For example, the determinant of a transformation would be 3 if that transformation increases the area of a region by a factor of 3.",
  "translatedText": "எடுத்துக்காட்டாக, அந்த உருமாற்றம் ஒரு பிராந்தியத்தின் பரப்பளவை 3 மடங்கு அதிகரித்தால், உருமாற்றத்தின் நிர்ணயம் 3 ஆக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.58,
  "end": 177.04
 },
 {
  "input": "The determinant of a transformation would be 1 half if it squishes down all areas by a factor of 1 half.",
  "translatedText": "எல்லாப் பகுதிகளையும் 1 பாதி மடங்கு குறைத்தால், உருமாற்றத்தின் நிர்ணயம் 1 பாதியாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.18,
  "end": 184.34
 },
 {
  "input": "And the determinant of a 2D transformation is 0 if it squishes all of space onto a line, or even onto a single point.",
  "translatedText": "மேலும் 2D உருமாற்றத்தின் நிர்ணயம் 0 ஆகும், அது அனைத்து இடத்தையும் ஒரு கோட்டில் அல்லது ஒரு புள்ளியில் கூட அழுத்தினால்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.0,
  "end": 193.5
 },
 {
  "input": "Since then, the area of any region would become 0.",
  "translatedText": "அப்போதிருந்து, எந்த பிராந்தியத்தின் பரப்பளவும் 0 ஆக மாறும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.0,
  "end": 196.76
 },
 {
  "input": "That last example will prove to be pretty important.",
  "translatedText": "அந்த கடைசி உதாரணம் மிகவும் முக்கியமானது என்பதை நிரூபிக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.62,
  "end": 199.6
 },
 {
  "input": "It means that checking if the determinant of a given matrix is 0 will give a way of computing whether or not the transformation associated with that matrix squishes everything into a smaller dimension.",
  "translatedText": "கொடுக்கப்பட்ட மேட்ரிக்ஸின் நிர்ணயம் 0 என்பதைச் சரிபார்ப்பது, அந்த மேட்ரிக்ஸுடன் தொடர்புடைய மாற்றம் எல்லாவற்றையும் சிறிய பரிமாணமாக மாற்றுகிறதா இல்லையா என்பதைக் கணக்கிடுவதற்கான வழியைக் கொடுக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.02,
  "end": 209.74
 },
 {
  "input": "You'll see in the next few videos why this is even a useful thing to think about, but for now, I just want to lay down all of the visual intuition, which, in and of itself, is a beautiful thing to think about.",
  "translatedText": "அடுத்த சில வீடியோக்களில் இது ஏன் யோசிக்க பயனுள்ள விஷயம் என்பதை நீங்கள் காண்பீர்கள், ஆனால் இப்போதைக்கு, நான் அனைத்து காட்சி உள்ளுணர்வையும் கீழே வைக்க விரும்புகிறேன், இது தானே, சிந்திக்க ஒரு அழகான விஷயம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.52,
  "end": 220.1
 },
 {
  "input": "Okay, I need to confess that what I've said so far is not quite right.",
  "translatedText": "சரி, நான் இதுவரை சொன்னது சரியாக இல்லை என்பதை ஒப்புக்கொள்ள வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.12,
  "end": 225.56
 },
 {
  "input": "The full concept of the determinant allows for negative values.",
  "translatedText": "தீர்மானிப்பவரின் முழு கருத்து எதிர்மறை மதிப்புகளை அனுமதிக்கிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 225.88,
  "end": 229.28
 },
 {
  "input": "But what would the idea of scaling an area by a negative amount even mean?",
  "translatedText": "ஆனால் ஒரு பகுதியை எதிர்மறையான அளவு மூலம் அளவிடுவது என்றால் என்ன?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.72,
  "end": 233.48
 },
 {
  "input": "This has to do with the idea of orientation.",
  "translatedText": "இது நோக்குநிலை யோசனையுடன் தொடர்புடையது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 234.94,
  "end": 236.96
 },
 {
  "input": "For example, notice how this transformation gives the sensation of flipping space over.",
  "translatedText": "எடுத்துக்காட்டாக, இந்த மாற்றம் எவ்வாறு இடத்தைப் புரட்டுவது போன்ற உணர்வை அளிக்கிறது என்பதைக் கவனியுங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.8,
  "end": 242.68
 },
 {
  "input": "If you were thinking of 2D space as a sheet of paper, a transformation like that one seems to turn over that sheet onto the other side.",
  "translatedText": "நீங்கள் 2டி இடத்தை ஒரு தாள் காகிதமாக நினைத்துக் கொண்டிருந்தால், அது போன்ற ஒரு மாற்றம் அந்தத் தாளை மறுபக்கமாக மாற்றுவது போல் தெரிகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.24,
  "end": 249.86
 },
 {
  "input": "Many transformations that do this are said to invert the orientation of space.",
  "translatedText": "இதைச் செய்யும் பல மாற்றங்கள் விண்வெளியின் நோக்குநிலையைத் தலைகீழாக மாற்றுவதாகக் கூறப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.64,
  "end": 255.04
 },
 {
  "input": "Another way to think about it is in terms of i-hat and j-hat.",
  "translatedText": "இதைப் பற்றி சிந்திக்க மற்றொரு வழி i-hat மற்றும் j-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.84,
  "end": 258.6
 },
 {
  "input": "Notice that in their starting positions, j-hat is to the left of i-hat.",
  "translatedText": "அவற்றின் தொடக்க நிலைகளில், j-hat ஐ-ஹாட்டின் இடதுபுறத்தில் இருப்பதைக் கவனியுங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.16,
  "end": 263.06
 },
 {
  "input": "If after a transformation, j-hat is now on the right of i-hat, the orientation of space has been inverted.",
  "translatedText": "மாற்றத்திற்குப் பிறகு, j-hat இப்போது i-hatக்கு வலதுபுறத்தில் இருந்தால், இடத்தின் நோக்குநிலை தலைகீழாக மாற்றப்பட்டது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.62,
  "end": 270.2
 },
 {
  "input": "Whenever this happens, whenever the orientation of space is inverted, the determinant will be negative.",
  "translatedText": "இது நிகழும் போதெல்லாம், இடத்தின் நோக்குநிலை தலைகீழாக இருக்கும் போதெல்லாம், தீர்மானிப்பான் எதிர்மறையாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.12,
  "end": 276.58
 },
 {
  "input": "The absolute value of the determinant, though, still tells you the factor by which areas have been scaled.",
  "translatedText": "இருப்பினும், தீர்மானிப்பவரின் முழுமையான மதிப்பு, பகுதிகள் அளவிடப்பட்ட காரணியைச் சொல்கிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.46,
  "end": 282.4
 },
 {
  "input": "For example, the matrix with columns 1, 1 and 2, negative 1 encodes a transformation that has determinant, I'll just tell you, negative 3.",
  "translatedText": "எடுத்துக்காட்டாக, நெடுவரிசைகள் 1, 1 மற்றும் 2, எதிர்மறை 1 ஆகியவற்றைக் கொண்ட அணியானது, நிர்ணயம் செய்யும் மாற்றத்தைக் குறியீடாக்குகிறது, நான் உங்களுக்குச் சொல்கிறேன், எதிர்மறை 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.02,
  "end": 290.68
 },
 {
  "input": "And what this means is that space gets flipped over and areas are scaled by a factor of 3.",
  "translatedText": "இதன் பொருள் என்னவென்றால், இடம் புரட்டப்பட்டு, பகுதிகள் 3 காரணிகளால் அளவிடப்படுகின்றன.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.46,
  "end": 296.28
 },
 {
  "input": "So why would this idea of a negative area scaling factor be a natural way to describe orientation flipping?",
  "translatedText": "எதிர்மறை பகுதி அளவிடுதல் காரணி பற்றிய இந்த யோசனை ஏன் நோக்குநிலை புரட்டலை விவரிக்க ஒரு இயற்கையான வழியாகும்?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.78,
  "end": 303.7
 },
 {
  "input": "Think about the series of transformations you get by slowly letting i-hat get closer and closer to j-hat.",
  "translatedText": "மெதுவாக i-hatஐ j-hatக்கு நெருக்கமாகவும் நெருக்கமாகவும் அனுமதிப்பதன் மூலம் நீங்கள் பெறும் தொடர்ச்சியான மாற்றங்களைப் பற்றி சிந்தியுங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.26,
  "end": 310.14
 },
 {
  "input": "As i-hat gets closer, all of the areas in space are getting squished more and more, meaning the determinant approaches 0.",
  "translatedText": "i-hat நெருங்க நெருங்க, விண்வெளியில் உள்ள அனைத்துப் பகுதிகளும் மேலும் மேலும் நசுக்கப்படுகின்றன, அதாவது தீர்மானிப்பான் 0 ஐ நெருங்குகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.72,
  "end": 317.1
 },
 {
  "input": "Once i-hat lines up perfectly with j-hat, the determinant is 0.",
  "translatedText": "j-hat உடன் i-hat வரிசைகள் சரியாக அமைந்தவுடன், தீர்மானிப்பான் 0 ஆகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.82,
  "end": 321.64
 },
 {
  "input": "Then, if i-hat continues the way that it was going, doesn't it kind of feel natural for the determinant to keep decreasing into the negative numbers?",
  "translatedText": "பின்னர், ஐ-ஹாட் அது செல்லும் வழியில் தொடர்ந்தால், தீர்மானிப்பவர் எதிர்மறை எண்களாகக் குறைந்து கொண்டே செல்வது இயல்பானதாக உணரவில்லையா?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.44,
  "end": 329.28
 },
 {
  "input": "So that's the understanding of determinants in two dimensions.",
  "translatedText": "எனவே அது இரு பரிமாணங்களில் தீர்மானிப்பவர்களின் புரிதல்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.68,
  "end": 333.56
 },
 {
  "input": "What do you think it should mean for three dimensions?",
  "translatedText": "முப்பரிமாணத்திற்கு என்ன அர்த்தம் என்று நீங்கள் நினைக்கிறீர்கள்?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.56,
  "end": 335.94
 },
 {
  "input": "It also tells you how much a transformation scales things, but this time it tells you how much volumes get scaled.",
  "translatedText": "ஒரு மாற்றம் எவ்வளவு விஷயங்களை அளவிடுகிறது என்பதையும் இது உங்களுக்குக் கூறுகிறது, ஆனால் இந்த நேரத்தில் எவ்வளவு தொகுதிகள் அளவிடப்படுகின்றன என்பதை இது உங்களுக்குக் கூறுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.92,
  "end": 343.24
 },
 {
  "input": "Just as in two dimensions, where this is easiest to think about by focusing on one particular square with an area 1 and watching only what happens to it, in three dimensions it helps to focus your attention on the specific 1 by 1 by 1 cube whose edges are resting on the basis vectors i-hat, j-hat, and k-hat.",
  "translatedText": "இரண்டு பரிமாணங்களில், ஒரு பகுதி 1 உடன் ஒரு குறிப்பிட்ட சதுரத்தின் மீது கவனம் செலுத்தி, அதற்கு என்ன நடக்கிறது என்பதை மட்டுமே பார்ப்பதன் மூலம் இதைப் பற்றி சிந்திக்க எளிதானது, மூன்று பரிமாணங்களில் இது குறிப்பிட்ட 1 க்கு 1 க்யூப் மீது உங்கள் கவனத்தை செலுத்த உதவுகிறது. விளிம்புகள் i-hat, j-hat மற்றும் k-hat ஆகிய திசையன்களின் அடிப்படையில் தங்கியிருக்கின்றன.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.34,
  "end": 363.44
 },
 {
  "input": "After the transformation, that cube might get warped into some kind of slanty slanty cube.",
  "translatedText": "உருமாற்றத்திற்குப் பிறகு, அந்த கனசதுரமானது ஒருவித ஸ்லாண்டி ஸ்லாண்டி கனசதுரமாக மாறக்கூடும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.32,
  "end": 369.3
 },
 {
  "input": "This shape, by the way, has the best name ever, parallel a pipette, a name that's made even more delightful when your professor has a nice thick Russian accent.",
  "translatedText": "இந்த வடிவம், எப்போதும் சிறந்த பெயரைக் கொண்டுள்ளது, ஒரு பைப்பேட்டிற்கு இணையாக, உங்கள் பேராசிரியருக்கு நல்ல தடித்த ரஷ்ய உச்சரிப்பு இருக்கும்போது இன்னும் மகிழ்ச்சிகரமான ஒரு பெயர்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.34,
  "end": 377.44
 },
 {
  "input": "Since this cube starts out with a volume of 1 and the determinant gives the factor by which any volume is scaled, you can think of the determinant simply as being the volume of that parallel a pipette that the cube turns into.",
  "translatedText": "இந்த கனசதுரம் 1 இன் தொகுதியுடன் தொடங்குவதால், எந்த தொகுதி அளவிடப்படுகிறதோ அந்த காரணியை தீர்மானிப்பான் கொடுப்பதால், கனசதுரமாக மாறும் அந்த இணையான பைபெட்டின் கன அளவு என நீங்கள் தீர்மானிப்பதாக நினைக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.52,
  "end": 390.64
 },
 {
  "input": "A determinant of 0 would mean that all of space is squished onto something with 0 volume, meaning either a flat plane, a line, or, in the most extreme case, onto a single point.",
  "translatedText": "0-ஐ நிர்ணயிப்பதன் அர்த்தம், எல்லா இடமும் 0 தொகுதியில் உள்ள ஏதாவது ஒன்றின் மீது சுருங்குகிறது, அதாவது ஒரு தட்டையான விமானம், ஒரு கோடு அல்லது, மிகவும் தீவிரமான நிலையில், ஒரு புள்ளியில்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.38,
  "end": 402.5
 },
 {
  "input": "Those of you who watched chapter 2 will recognize this as meaning that the columns of the matrix are linearly dependent.",
  "translatedText": "உங்களில் அத்தியாயம் 2 ஐப் பார்த்தவர்கள், மேட்ரிக்ஸின் நெடுவரிசைகள் நேரியல் சார்ந்து இருப்பதைக் குறிக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.76,
  "end": 409.24
 },
 {
  "input": "Can you see why?",
  "translatedText": "ஏன் என்று பார்க்க முடியுமா?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.76,
  "end": 410.42
 },
 {
  "input": "What about negative determinants?",
  "translatedText": "எதிர்மறை தீர்மானிப்பவர்கள் பற்றி என்ன?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.92,
  "end": 416.64
 },
 {
  "input": "What should that mean for three dimensions?",
  "translatedText": "முப்பரிமாணத்திற்கு என்ன அர்த்தம்?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.78,
  "end": 418.1
 },
 {
  "input": "One way to describe orientation in 3D is with the right hand rule.",
  "translatedText": "3D இல் நோக்குநிலையை விவரிக்க ஒரு வழி வலது கை விதி.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.78,
  "end": 422.68
 },
 {
  "input": "Point the forefinger of your right hand in the direction of i-hat, stick out your middle finger in the direction of j-hat, and notice how when you point your thumb up, it's in the direction of k-hat.",
  "translatedText": "உங்கள் வலது கையின் ஆள்காட்டி விரலை i-hat திசையில் சுட்டிக்காட்டவும், உங்கள் நடுவிரலை j-hat திசையில் நீட்டவும், மேலும் உங்கள் கட்டைவிரலை மேலே காட்டும்போது, அது k-hat திசையில் எப்படி இருக்கிறது என்பதைக் கவனியுங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.3,
  "end": 432.76
 },
 {
  "input": "If you can still do that after the transformation, orientation has not changed, and the determinant is positive.",
  "translatedText": "மாற்றத்திற்குப் பிறகும் நீங்கள் அதைச் செய்ய முடிந்தால், நோக்குநிலை மாறவில்லை, மேலும் தீர்மானிப்பான் நேர்மறையானது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.88,
  "end": 440.9
 },
 {
  "input": "Otherwise, if after the transformation it only makes sense to do that with your left hand, orientation has been flipped, and the determinant is negative.",
  "translatedText": "இல்லையெனில், மாற்றத்திற்குப் பிறகு உங்கள் இடது கையால் அதைச் செய்வது அர்த்தமுள்ளதாக இருந்தால், நோக்குநிலை புரட்டப்பட்டது, மேலும் தீர்மானம் எதிர்மறையானது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.54,
  "end": 449.38
 },
 {
  "input": "So if you haven't seen it before, you're probably wondering by now, how do you actually compute the determinant?",
  "translatedText": "நீங்கள் இதை இதற்கு முன் பார்க்கவில்லை என்றால், நீங்கள் இப்போது யோசித்துக்கொண்டிருக்கலாம், உண்மையில் எப்படி தீர்மானிப்பதை கணக்கிடுவது?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.9,
  "end": 457.04
 },
 {
  "input": "For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c.",
  "translatedText": "a, b, c, d உள்ளீடுகளைக் கொண்ட 2x2 அணிக்கு, சூத்திரம் d மைனஸ் b பெருக்கல் c ஆகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.56,
  "end": 464.42
 },
 {
  "input": "Here's part of an intuition for where this formula comes from.",
  "translatedText": "இந்த சூத்திரம் எங்கிருந்து வருகிறது என்பதற்கான உள்ளுணர்வின் ஒரு பகுதி இங்கே.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.74,
  "end": 468.5
 },
 {
  "input": "Let's say that the terms b and c both happened to be 0.",
  "translatedText": "பி மற்றும் சி ஆகிய இரண்டும் 0 ஆக இருந்தது என்று வைத்துக் கொள்வோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.88,
  "end": 471.78
 },
 {
  "input": "Then the term a tells you how much i-hat is stretched in the x direction, and the term d tells you how much j-hat is stretched in the y direction.",
  "translatedText": "x திசையில் i-hat எவ்வளவு நீட்டிக்கப்பட்டுள்ளது என்பதை a என்ற சொல் உங்களுக்குக் கூறுகிறது, மேலும் d என்ற சொல் y திசையில் எவ்வளவு j-hat நீட்டிக்கப்பட்டுள்ளது என்பதைக் கூறுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.78,
  "end": 481.16
 },
 {
  "input": "So since those other terms are 0, it should make sense that a times d gives the area of the rectangle that our favorite unit square turns into, kind of like the 3, 0, 0, 2 example from earlier.",
  "translatedText": "எனவே அந்த மற்ற சொற்கள் 0 என்பதால், 3, 0, 0, 2 போன்ற முந்தைய உதாரணத்தைப் போலவே, நமக்குப் பிடித்த அலகு சதுரமாக மாறும் செவ்வகத்தின் பரப்பளவை ஒரு முறை d கொடுக்கிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.76,
  "end": 493.36
 },
 {
  "input": "Even if only one of b or c are 0, you'll have a parallelogram with a base a and a height d, so the area should still be a times d.",
  "translatedText": "b அல்லது c இல் ஒன்று மட்டும் 0 ஆக இருந்தாலும் கூட, நீங்கள் அடிப்படை a மற்றும் உயரம் d உடன் இணையான வரைபடம் வேண்டும், எனவே பகுதி இன்னும் d ஆக இருக்க வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.36,
  "end": 504.5
 },
 {
  "input": "Loosely speaking, if both b and c are non-zero, then that b times c term tells you how much this parallelogram is stretched or squished in the diagonal direction.",
  "translatedText": "தளர்வாகச் சொன்னால், b மற்றும் c இரண்டும் பூஜ்ஜியம் அல்லாதவை என்றால், அந்த b டைம்ஸ் c சொல், இந்த இணையான வரைபடம் மூலைவிட்டத் திசையில் எவ்வளவு நீட்டிக்கப்பட்டுள்ளது அல்லது சுருக்கப்பட்டுள்ளது என்பதைக் கூறுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.46,
  "end": 515.46
 },
 {
  "input": "For those of you hungry for a more precise description of this b times c term, here's a helpful diagram if you'd like to pause and ponder.",
  "translatedText": "இந்த பி டைம்ஸ் சி காலத்தின் துல்லியமான விளக்கத்திற்காக உங்களில் உள்ளவர்களுக்கு, நீங்கள் இடைநிறுத்தி சிந்திக்க விரும்பினால், இங்கே ஒரு பயனுள்ள வரைபடம் உள்ளது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 516.66,
  "end": 522.88
 },
 {
  "input": "Now if you feel like computing determinants by hand is something that you need to know, the only way to get it down is to just practice it with a few.",
  "translatedText": "இப்போது நீங்கள் தெரிந்து கொள்ள வேண்டிய ஒரு விஷயத்தை கையால் கணிப்பதாக நீங்கள் உணர்ந்தால், அதைக் குறைப்பதற்கான ஒரே வழி, அதை ஒரு சிலரிடம் பயிற்சி செய்வதுதான்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.98,
  "end": 531.2
 },
 {
  "input": "There's really not that much I can say or animate that's going to drill in the computation.",
  "translatedText": "கணிப்பீட்டில் துரப்பணம் செய்யப் போவதை நான் சொல்லவோ உயிர்ப்பிக்கவோ முடியாது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.2,
  "end": 535.18
 },
 {
  "input": "This is all triply true for three-dimensional determinants.",
  "translatedText": "முப்பரிமாண தீர்மானிப்பவர்களுக்கு இது மூன்று மடங்கு உண்மை.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.12,
  "end": 538.64
 },
 {
  "input": "There is a formula, and if you feel like that's something you need to know, you should practice with a few matrices, or, you know, go watch Sal Khan work through a few.",
  "translatedText": "ஒரு ஃபார்முலா உள்ளது, அது உங்களுக்குத் தெரிந்திருக்க வேண்டும் என்று நீங்கள் நினைத்தால், நீங்கள் சில மெட்ரிக்குகளுடன் பயிற்சி செய்ய வேண்டும், அல்லது, உங்களுக்குத் தெரியும், சல் கானின் வேலையைப் பார்க்கவும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.04,
  "end": 546.34
 },
 {
  "input": "Honestly, though, I don't think that those computations fall within the essence of linear algebra, but I definitely think that understanding what the determinant represents falls within that essence.",
  "translatedText": "நேர்மையாக, இருப்பினும், அந்த கணக்கீடுகள் நேரியல் இயற்கணிதத்தின் சாராம்சத்திற்குள் வராது என்று நான் நினைக்கவில்லை, ஆனால் தீர்மானிப்பவர் எதைப் பிரதிநிதித்துவப்படுத்துகிறார் என்பதைப் புரிந்துகொள்வது அந்த சாரத்திற்குள் விழுகிறது என்று நான் நினைக்கிறேன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 547.24,
  "end": 556.46
 },
 {
  "input": "Here's kind of a fun question to think about before the next video.",
  "translatedText": "அடுத்த வீடியோவிற்கு முன் சிந்திக்க ஒரு வேடிக்கையான கேள்வி இங்கே உள்ளது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.06,
  "end": 560.64
 },
 {
  "input": "If you multiply two matrices together, the determinant of the resulting matrix is the same as the product of the determinants of the original two matrices.",
  "translatedText": "நீங்கள் இரண்டு மெட்ரிக்ஸை ஒன்றாகப் பெருக்கினால், அதன் விளைவாக வரும் மேட்ரிக்ஸின் நிர்ணயம் அசல் இரண்டு மெட்ரிக்ஸின் நிர்ணயிப்பாளர்களின் பெருக்கத்தைப் போலவே இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.64,
  "end": 570.08
 },
 {
  "input": "If you tried to justify this with numbers, it would take a really long time, but see if you can explain why this makes sense in just one sentence.",
  "translatedText": "நீங்கள் இதை எண்களைக் கொண்டு நியாயப்படுத்த முயற்சித்தால், அது மிகவும் நீண்ட நேரம் எடுக்கும், ஆனால் ஒரே ஒரு வாக்கியத்தில் இது ஏன் அர்த்தமுள்ளதாக இருக்கிறது என்பதை உங்களால் விளக்க முடியுமா என்று பார்க்கவும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.1,
  "end": 577.88
 },
 {
  "input": "Next up, I'll be relating the idea of linear transformations covered so far to one of the areas where linear algebra is most useful, linear systems of equations.",
  "translatedText": "அடுத்து, நேரியல் இயற்கணிதம் மிகவும் பயனுள்ளதாக இருக்கும், சமன்பாடுகளின் நேரியல் அமைப்புகளில் ஒன்றிற்கு இதுவரை உள்ளடக்கப்பட்ட நேரியல் மாற்றங்களின் யோசனையை நான் தொடர்புபடுத்துகிறேன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.0,
  "end": 590.96
 },
 {
  "input": "See you then!",
  "translatedText": "பிறகு பார்க்கலாம்!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.48,
  "end": 591.6
 }
]