[
 {
  "input": "Hello, hello again. ",
  "translatedText": "سلام دوباره سلام. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 11.98,
  "end": 13.0
 },
 {
  "input": "So moving forward, I'll be assuming that you have a visual understanding of linear transformations and how they're represented with matrices, the way that I've been talking about in the last few videos. ",
  "translatedText": "بنابراین با حرکت رو به جلو، فرض می‌کنم که شما درک بصری از تبدیل‌های خطی و نحوه نمایش آن‌ها با ماتریس‌ها دارید، روشی که من در چند ویدیو اخیر درباره آن صحبت کردم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.52,
  "end": 21.84
 },
 {
  "input": "If you think about a couple of these linear transformations, you might notice how some of them seem to stretch space out, while others squish it on in. ",
  "translatedText": "اگر به چند مورد از این تبدیل های خطی فکر کنید، ممکن است متوجه شوید که چگونه برخی از آنها به نظر می رسد فضا را گسترش می دهند، در حالی که برخی دیگر آن را به داخل فرو می برند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.66,
  "end": 30.42
 },
 {
  "input": "One thing that turns out to be pretty useful for understanding one of these transformations is to measure exactly how much it stretches or squishes things. ",
  "translatedText": "یکی از چیزهایی که برای درک یکی از این دگرگونی‌ها بسیار مفید است، اندازه‌گیری دقیق میزان کشش یا له کردن اشیا است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 31.14,
  "end": 38.92
 },
 {
  "input": "More specifically, to measure the factor by which the area of a given region increases or decreases. ",
  "translatedText": "به طور خاص، برای اندازه گیری عاملی که به وسیله آن مساحت یک منطقه معین افزایش یا کاهش می یابد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 39.52,
  "end": 45.82
 },
 {
  "input": "For example, look at the matrix with columns 3, 0 and 0, 2. ",
  "translatedText": "به عنوان مثال، به ماتریس با ستون های 3، 0 و 0، 2 نگاه کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.18,
  "end": 50.88
 },
 {
  "input": "It scales i-hat by a factor of 3 and scales j-hat by a factor of 2. ",
  "translatedText": "I-hat را با ضریب 3 و j-hat را با ضریب 2 مقیاس می دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.32,
  "end": 56.18
 },
 {
  "input": "Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle. ",
  "translatedText": "حال اگر توجه خود را روی مربع 1 در 1 که قسمت پایین آن روی i-hat و سمت چپ آن روی j-hat قرار دارد متمرکز کنیم، پس از تبدیل به یک مستطیل 2 در 3 تبدیل می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 56.7,
  "end": 67.52
 },
 {
  "input": "Since this region started out with area 1 and ended up with area 6, we can say the linear transformation has scaled its area by a factor of 6. ",
  "translatedText": "از آنجایی که این منطقه با مساحت 1 شروع شد و به ناحیه 6 ختم شد، می توان گفت که تبدیل خطی مساحت خود را با ضریب 6 افزایش داده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 68.38,
  "end": 77.28
 },
 {
  "input": "Compare that to a shear whose matrix has columns 1, 0 and 1, 1, meaning i-hat stays in place and j-hat moves over to 1, 1. ",
  "translatedText": "آن را با برشی مقایسه کنید که ماتریس آن دارای ستون‌های 1، 0 و 1، 1 است، به این معنی که i-hat در جای خود باقی می‌ماند و j-hat به 1 و 1 منتقل می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.18,
  "end": 86.1
 },
 {
  "input": "That same unit square determined by i-hat and j-hat gets slanted and turned into a parallelogram, but the area of that parallelogram is still 1, since its base and height each continue to have length 1. ",
  "translatedText": "همان مربع واحدی که توسط i-hat و j-hat تعیین می شود، مایل می شود و به متوازی الاضلاع تبدیل می شود، اما مساحت آن متوازی الاضلاع همچنان 1 است، زیرا قاعده و ارتفاع هر کدام همچنان دارای طول 1 هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 87.0,
  "end": 98.38
 },
 {
  "input": "So, even though this transformation smushes things about, it seems to leave areas unchanged, at least in the case of that 1 unit square. ",
  "translatedText": "بنابراین، اگرچه این دگرگونی همه چیز را به هم می زند، به نظر می رسد که مناطق را بدون تغییر باقی می گذارد، حداقل در مورد آن مربع 1 واحدی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.18,
  "end": 105.62
 },
 {
  "input": "Actually though, if you know how much the area of that one single unit square changes, it can tell you how the area of any possible region in space changes. ",
  "translatedText": "در واقع، اگر بدانید مساحت آن مربع واحد چقدر تغییر می کند، می تواند به شما بگوید که مساحت هر منطقه ممکن در فضا چگونه تغییر می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.82,
  "end": 115.52
 },
 {
  "input": "For starters, notice that whatever happens to one square in the grid has to happen to any other square in the grid, no matter the size. ",
  "translatedText": "برای شروع، توجه داشته باشید که هر چه برای یک مربع در شبکه بیفتد، بدون توجه به اندازه، باید برای هر مربع دیگر در شبکه نیز اتفاق بیفتد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 116.3,
  "end": 123.58
 },
 {
  "input": "This follows from the fact that grid lines remain parallel and evenly spaced. ",
  "translatedText": "این از این واقعیت ناشی می شود که خطوط شبکه موازی و با فاصله مساوی باقی می مانند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.34,
  "end": 128.04
 },
 {
  "input": "Then, any shape that's not a grid square can be approximated by grid squares pretty well, with arbitrarily good approximations if you use small enough grid squares. ",
  "translatedText": "سپس، هر شکلی که مربع شبکه ای نباشد، می تواند به خوبی با مربع های شبکه ای تقریب شود، اگر از مربع های شبکه ای به اندازه کافی کوچک استفاده کنید، با تقریب های دلخواه خوب می توان آن را تقریب زد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.76,
  "end": 137.52
 },
 {
  "input": "So, since the areas of all those tiny grid squares are being scaled by some single amount, the area of the blob as a whole will also be scaled by that same single amount. ",
  "translatedText": "بنابراین، از آنجایی که مساحت تمام آن مربع‌های شبکه‌ای کوچک با مقداری منفرد مقیاس می‌شوند، مساحت لکه به‌عنوان یک کل نیز با همان مقدار منفرد مقیاس می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 137.52,
  "end": 147.82
 },
 {
  "input": "This very special scaling factor, the factor by which a linear transformation changes any area, is called the determinant of that transformation. ",
  "translatedText": "این ضریب مقیاس بسیار ویژه، عاملی که توسط آن یک تبدیل خطی هر ناحیه را تغییر می دهد، تعیین کننده آن تبدیل نامیده می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.9,
  "end": 157.12
 },
 {
  "input": "I'll show how to compute the determinant of a transformation using its matrix later on in this video, but understanding what it represents is, trust me, much more important than the computation. ",
  "translatedText": "من نحوه محاسبه تعیین کننده یک تبدیل را با استفاده از ماتریس آن بعداً در این ویدیو نشان خواهم داد، اما درک اینکه چه چیزی نشان دهنده آن است، به من اعتماد کنید، بسیار مهمتر از محاسبه است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 168.42
 },
 {
  "input": "For example, the determinant of a transformation would be 3 if that transformation increases the area of a region by a factor of 3. ",
  "translatedText": "به عنوان مثال، تعیین کننده یک تبدیل 3 خواهد بود اگر آن تبدیل مساحت یک منطقه را ضریب 3 افزایش دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 169.58,
  "end": 177.04
 },
 {
  "input": "The determinant of a transformation would be 1 half if it squishes down all areas by a factor of 1 half. ",
  "translatedText": "اگر یک تبدیل تمام نواحی را با ضریب 1 نصف کاهش دهد، تعیین کننده 1 نصف خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 178.18,
  "end": 184.34
 },
 {
  "input": "And the determinant of a 2D transformation is 0 if it squishes all of space onto a line, or even onto a single point. ",
  "translatedText": "و اگر یک تبدیل دوبعدی تمام فضا را روی یک خط یا حتی روی یک نقطه منفرد بکوبد، تعیین کننده 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 186.0,
  "end": 193.5
 },
 {
  "input": "Since then, the area of any region would become 0. ",
  "translatedText": "از آن زمان، مساحت هر منطقه 0 می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.0,
  "end": 196.76
 },
 {
  "input": "That last example will prove to be pretty important. ",
  "translatedText": "این مثال آخر بسیار مهم خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 197.62,
  "end": 199.6
 },
 {
  "input": "It means that checking if the determinant of a given matrix is 0 will give a way of computing whether or not the transformation associated with that matrix squishes everything into a smaller dimension. ",
  "translatedText": "این بدان معنی است که بررسی اینکه آیا تعیین کننده یک ماتریس معین 0 است یا خیر، راهی برای محاسبه اینکه آیا تبدیل مرتبط با آن ماتریس همه چیز را به ابعاد کوچکتر می‌برد یا خیر، ارائه می‌دهد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.02,
  "end": 209.74
 },
 {
  "input": "You'll see in the next few videos why this is even a useful thing to think about, but for now, I just want to lay down all of the visual intuition, which, in and of itself, is a beautiful thing to think about. ",
  "translatedText": "در چند ویدیوی بعدی خواهید دید که چرا فکر کردن به این موضوع حتی مفید است، اما در حال حاضر، من فقط می‌خواهم تمام شهود بصری را کنار بگذارم، که به خودی خود، فکر کردن به آن چیز زیبایی است. . ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.52,
  "end": 220.1
 },
 {
  "input": "Okay, I need to confess that what I've said so far is not quite right. ",
  "translatedText": "بسیار خوب، باید اعتراف کنم که آنچه تاکنون گفته ام کاملاً درست نیست. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 222.12,
  "end": 225.56
 },
 {
  "input": "The full concept of the determinant allows for negative values. ",
  "translatedText": "مفهوم کامل تعیین کننده، مقادیر منفی را امکان پذیر می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 225.88,
  "end": 229.28
 },
 {
  "input": "But what would the idea of scaling an area by a negative amount even mean? ",
  "translatedText": "اما ایده مقیاس بندی یک منطقه با مقدار منفی حتی چه معنایی دارد؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 229.72,
  "end": 233.48
 },
 {
  "input": "This has to do with the idea of orientation. ",
  "translatedText": "این به ایده جهت گیری مربوط می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 234.94,
  "end": 236.96
 },
 {
  "input": "For example, notice how this transformation gives the sensation of flipping space over. ",
  "translatedText": "به عنوان مثال، توجه کنید که چگونه این تبدیل احساس چرخش فضا را ایجاد می کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.8,
  "end": 242.68
 },
 {
  "input": "If you were thinking of 2D space as a sheet of paper, a transformation like that one seems to turn over that sheet onto the other side. ",
  "translatedText": "اگر فضای دوبعدی را به عنوان یک ورق کاغذ در نظر می‌گیرید، به نظر می‌رسد تبدیلی مانند آن، آن ورق را به طرف دیگر می‌چرخاند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 243.24,
  "end": 249.86
 },
 {
  "input": "Many transformations that do this are said to invert the orientation of space. ",
  "translatedText": "گفته می شود بسیاری از تبدیل هایی که این کار را انجام می دهند، جهت فضا را معکوس می کنند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.64,
  "end": 255.04
 },
 {
  "input": "Another way to think about it is in terms of i-hat and j-hat. ",
  "translatedText": "راه دیگری برای فکر کردن در مورد آن از نظر i-hat و j-hat است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.84,
  "end": 258.6
 },
 {
  "input": "Notice that in their starting positions, j-hat is to the left of i-hat. ",
  "translatedText": "توجه کنید که در موقعیت های شروع آنها، j-hat در سمت چپ i-hat قرار دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.16,
  "end": 263.06
 },
 {
  "input": "If after a transformation, j-hat is now on the right of i-hat, the orientation of space has been inverted. ",
  "translatedText": "اگر بعد از یک تبدیل، j-hat اکنون در سمت راست i-hat باشد، جهت فضا معکوس شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 263.62,
  "end": 270.2
 },
 {
  "input": "Whenever this happens, whenever the orientation of space is inverted, the determinant will be negative. ",
  "translatedText": "هر زمان که این اتفاق بیفتد، هر زمان که جهت فضا معکوس شود، تعیین کننده منفی خواهد بود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.12,
  "end": 276.58
 },
 {
  "input": "The absolute value of the determinant, though, still tells you the factor by which areas have been scaled. ",
  "translatedText": "با این حال، قدر مطلق دترمینان، هنوز عاملی را به شما می‌گوید که با چه ناحیه‌ای مقیاس‌گذاری شده‌اند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 277.46,
  "end": 282.4
 },
 {
  "input": "For example, the matrix with columns 1, 1 and 2, negative 1 encodes a transformation that has determinant, I'll just tell you, negative 3. ",
  "translatedText": "به عنوان مثال، ماتریس با ستون های 1، 1 و 2، منفی 1، تبدیلی را رمزگذاری می کند که دارای دترمینان است، فقط به شما می گویم، منفی 3. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.02,
  "end": 290.68
 },
 {
  "input": "And what this means is that space gets flipped over and areas are scaled by a factor of 3. ",
  "translatedText": "و این به این معنی است که فضا برعکس می شود و مناطق با ضریب 3 مقیاس می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 291.46,
  "end": 296.28
 },
 {
  "input": "So why would this idea of a negative area scaling factor be a natural way to describe orientation flipping? ",
  "translatedText": "پس چرا این ایده از ضریب مقیاس پذیری ناحیه منفی راهی طبیعی برای توصیف چرخش جهت است؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 297.78,
  "end": 303.7
 },
 {
  "input": "Think about the series of transformations you get by slowly letting i-hat get closer and closer to j-hat. ",
  "translatedText": "به مجموعه تحولاتی فکر کنید که با اجازه دادن آرام آرام i-hat به j-hat نزدیکتر و نزدیکتر می شوید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 304.26,
  "end": 310.14
 },
 {
  "input": "As i-hat gets closer, all of the areas in space are getting squished more and more, meaning the determinant approaches 0. ",
  "translatedText": "با نزدیک‌تر شدن i-hat، همه نواحی در فضا بیشتر و بیشتر فشرده می‌شوند، به این معنی که تعیین‌کننده به 0 نزدیک می‌شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 310.72,
  "end": 317.1
 },
 {
  "input": "Once i-hat lines up perfectly with j-hat, the determinant is 0. ",
  "translatedText": "هنگامی که i-hat کاملاً با j-hat یکسان شد، تعیین کننده 0 است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 317.82,
  "end": 321.64
 },
 {
  "input": "Then, if i-hat continues the way that it was going, doesn't it kind of feel natural for the determinant to keep decreasing into the negative numbers? ",
  "translatedText": "سپس، اگر i-hat به مسیری که می رفت ادامه دهد، آیا طبیعی نیست که تعیین کننده همچنان به اعداد منفی کاهش یابد؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 322.44,
  "end": 329.28
 },
 {
  "input": "So that's the understanding of determinants in two dimensions. ",
  "translatedText": "بنابراین درک عوامل تعیین کننده در دو بعد است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 330.68,
  "end": 333.56
 },
 {
  "input": "What do you think it should mean for three dimensions? ",
  "translatedText": "به نظر شما برای سه بعدی چه معنایی باید داشته باشد؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 333.56,
  "end": 335.94
 },
 {
  "input": "It also tells you how much a transformation scales things, but this time it tells you how much volumes get scaled. ",
  "translatedText": "همچنین به شما می گوید که یک تبدیل چقدر چیزها را مقیاس می کند، اما این بار به شما می گوید که حجم ها چقدر مقیاس می شوند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 336.92,
  "end": 343.24
 },
 {
  "input": "Just as in two dimensions, where this is easiest to think about by focusing on one particular square with an area 1 and watching only what happens to it, in three dimensions it helps to focus your attention on the specific 1 by 1 by 1 cube whose edges are resting on the basis vectors i-hat, j-hat, and k-hat. ",
  "translatedText": "درست مانند دو بعدی، که با تمرکز بر یک مربع خاص با مساحت 1 و تماشای تنها اتفاقاتی که برای آن اتفاق می افتد، راحت تر فکر می کنید، در سه بعدی نیز کمک می کند تا توجه شما را بر روی مکعب خاص 1 در 1 در 1 متمرکز کنید. لبه ها بر اساس بردارهای i-hat، j-hat و k-hat قرار دارند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 345.34,
  "end": 363.44
 },
 {
  "input": "After the transformation, that cube might get warped into some kind of slanty slanty cube. ",
  "translatedText": "پس از تغییر شکل، آن مکعب ممکن است به نوعی مکعب شیب دار تبدیل شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.32,
  "end": 369.3
 },
 {
  "input": "This shape, by the way, has the best name ever, parallel a pipette, a name that's made even more delightful when your professor has a nice thick Russian accent. ",
  "translatedText": "این شکل، به هر حال، بهترین نام را دارد، به موازات پیپت، نامی که وقتی استاد شما لهجه غلیظ روسی خوبی داشته باشد، بسیار لذت بخش تر می شود. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 370.34,
  "end": 377.44
 },
 {
  "input": "Since this cube starts out with a volume of 1 and the determinant gives the factor by which any volume is scaled, you can think of the determinant simply as being the volume of that parallel a pipette that the cube turns into. ",
  "translatedText": "از آنجایی که این مکعب با حجم 1 شروع می شود و تعیین کننده فاکتوری را نشان می دهد که بر اساس آن هر حجمی مقیاس می شود، می توانید تعیین کننده را به سادگی حجم آن پیپت موازی که مکعب به آن تبدیل می شود در نظر بگیرید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.52,
  "end": 390.64
 },
 {
  "input": "A determinant of 0 would mean that all of space is squished onto something with 0 volume, meaning either a flat plane, a line, or, in the most extreme case, onto a single point. ",
  "translatedText": "تعیین کننده 0 به این معنی است که تمام فضا بر روی چیزی با حجم 0 فشرده می شود، یعنی یک صفحه صاف، یک خط، یا در شدیدترین حالت، روی یک نقطه واحد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 392.38,
  "end": 402.5
 },
 {
  "input": "Those of you who watched chapter 2 will recognize this as meaning that the columns of the matrix are linearly dependent. ",
  "translatedText": "آنهایی از شما که فصل 2 را تماشا کرده‌اید، متوجه می‌شوید که ستون‌های ماتریس به صورت خطی وابسته هستند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.76,
  "end": 409.24
 },
 {
  "input": "Can you see why? ",
  "translatedText": "می توانید ببینید چرا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 409.76,
  "end": 410.42
 },
 {
  "input": "What about negative determinants? ",
  "translatedText": "در مورد عوامل منفی چطور؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.92,
  "end": 416.64
 },
 {
  "input": "What should that mean for three dimensions? ",
  "translatedText": "برای سه بعدی چه معنایی باید داشته باشد؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 416.78,
  "end": 418.1
 },
 {
  "input": "One way to describe orientation in 3D is with the right hand rule. ",
  "translatedText": "یکی از راه‌های توصیف جهت‌گیری در سه بعدی، استفاده از قانون دست راست است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.78,
  "end": 422.68
 },
 {
  "input": "Point the forefinger of your right hand in the direction of i-hat, stick out your middle finger in the direction of j-hat, and notice how when you point your thumb up, it's in the direction of k-hat. ",
  "translatedText": "انگشت سبابه دست راست خود را در جهت i-hat بگیرید، انگشت وسط خود را در جهت j-hat بیرون بیاورید و متوجه شوید که چگونه وقتی شست خود را به سمت بالا می گیرید، در جهت k-hat قرار می گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.3,
  "end": 432.76
 },
 {
  "input": "If you can still do that after the transformation, orientation has not changed, and the determinant is positive. ",
  "translatedText": "اگر بعد از تبدیل هنوز بتوانید این کار را انجام دهید، جهت گیری تغییر نکرده است و تعیین کننده مثبت است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.88,
  "end": 440.9
 },
 {
  "input": "Otherwise, if after the transformation it only makes sense to do that with your left hand, orientation has been flipped, and the determinant is negative. ",
  "translatedText": "در غیر این صورت، اگر بعد از تبدیل، انجام آن با دست چپ منطقی باشد، جهت گیری تغییر کرده است و تعیین کننده منفی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 441.54,
  "end": 449.38
 },
 {
  "input": "So if you haven't seen it before, you're probably wondering by now, how do you actually compute the determinant? ",
  "translatedText": "بنابراین اگر قبلاً آن را ندیده‌اید، احتمالاً تا به حال از خود می‌پرسید که واقعاً چگونه تعیین کننده را محاسبه می‌کنید؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 451.9,
  "end": 457.04
 },
 {
  "input": "For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c. ",
  "translatedText": "برای یک ماتریس 2x2 با ورودی های a، b، c، d، فرمول a ضربدر d منهای b ضربدر c است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 457.56,
  "end": 464.42
 },
 {
  "input": "Here's part of an intuition for where this formula comes from. ",
  "translatedText": "در اینجا بخشی از شهودی است که این فرمول از کجا آمده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.74,
  "end": 468.5
 },
 {
  "input": "Let's say that the terms b and c both happened to be 0. ",
  "translatedText": "فرض کنید که عبارت b و c هر دو 0 بودند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.88,
  "end": 471.78
 },
 {
  "input": "Then the term a tells you how much i-hat is stretched in the x direction, and the term d tells you how much j-hat is stretched in the y direction. ",
  "translatedText": "سپس عبارت a به شما می گوید که i-hat چقدر در جهت x کشیده شده است و عبارت d به شما می گوید که چقدر j-hat در جهت y کشیده شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 471.78,
  "end": 481.16
 },
 {
  "input": "So since those other terms are 0, it should make sense that a times d gives the area of the rectangle that our favorite unit square turns into, kind of like the 3, 0, 0, 2 example from earlier. ",
  "translatedText": "بنابراین از آنجایی که آن عبارات دیگر 0 هستند، منطقی است که ضربدر d مساحت مستطیلی را می دهد که مربع واحد مورد علاقه ما به آن تبدیل می شود، به نوعی مانند مثال 3، 0، 0، 2 قبلی. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.76,
  "end": 493.36
 },
 {
  "input": "Even if only one of b or c are 0, you'll have a parallelogram with a base a and a height d, so the area should still be a times d. ",
  "translatedText": "حتی اگر فقط یکی از b یا c 0 باشد، متوازی الاضلاع با قاعده a و ارتفاع d خواهید داشت، بنابراین مساحت همچنان باید ضربدر d باشد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.36,
  "end": 504.5
 },
 {
  "input": "Loosely speaking, if both b and c are non-zero, then that b times c term tells you how much this parallelogram is stretched or squished in the diagonal direction. ",
  "translatedText": "به زبان ساده، اگر b و c هر دو غیر صفر باشند، آن عبارت b ضربدر c به شما می گوید که این متوازی الاضلاع چقدر در جهت مورب کشیده یا فشرده شده است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.46,
  "end": 515.46
 },
 {
  "input": "For those of you hungry for a more precise description of this b times c term, here's a helpful diagram if you'd like to pause and ponder. ",
  "translatedText": "برای کسانی از شما که تشنه توصیف دقیق تر این عبارت b بار c هستید، اگر می خواهید مکث کنید و فکر کنید، در اینجا یک نمودار مفید وجود دارد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 516.66,
  "end": 522.88
 },
 {
  "input": "Now if you feel like computing determinants by hand is something that you need to know, the only way to get it down is to just practice it with a few. ",
  "translatedText": "حال اگر احساس می‌کنید که محاسبه دستی تعیین‌کننده‌ها چیزی است که باید بدانید، تنها راه برای پایین آوردن آن این است که فقط آن را با تعداد کمی تمرین کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 523.98,
  "end": 531.2
 },
 {
  "input": "There's really not that much I can say or animate that's going to drill in the computation. ",
  "translatedText": "واقعاً چیزهای زیادی وجود ندارد که بتوانم بگویم یا متحرک کنم که بتواند در محاسبات حفاری کند. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 531.2,
  "end": 535.18
 },
 {
  "input": "This is all triply true for three-dimensional determinants. ",
  "translatedText": "این همه سه برابر برای تعیین کننده های سه بعدی صادق است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 536.12,
  "end": 538.64
 },
 {
  "input": "There is a formula, and if you feel like that's something you need to know, you should practice with a few matrices, or, you know, go watch Sal Khan work through a few. ",
  "translatedText": "یک فرمول وجود دارد، و اگر احساس می‌کنید این چیزی است که باید بدانید، باید با چند ماتریس تمرین کنید، یا، می‌دانید، به تماشای کار سال خان بروید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.04,
  "end": 546.34
 },
 {
  "input": "Honestly, though, I don't think that those computations fall within the essence of linear algebra, but I definitely think that understanding what the determinant represents falls within that essence. ",
  "translatedText": "با این حال، صادقانه بگویم، من فکر نمی‌کنم که این محاسبات در جوهره جبر خطی قرار گیرند، اما قطعاً فکر می‌کنم که درک اینکه تعیین کننده چه چیزی را نشان می‌دهد در این ماهیت قرار می‌گیرد. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 547.24,
  "end": 556.46
 },
 {
  "input": "Here's kind of a fun question to think about before the next video. ",
  "translatedText": "در اینجا یک نوع سوال جالب است که باید قبل از ویدیوی بعدی به آن فکر کنید. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 558.06,
  "end": 560.64
 },
 {
  "input": "If you multiply two matrices together, the determinant of the resulting matrix is the same as the product of the determinants of the original two matrices. ",
  "translatedText": "اگر دو ماتریس را با هم ضرب کنید، دترمینان ماتریس حاصل با حاصلضرب دترمینان دو ماتریس اصلی برابر است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 560.64,
  "end": 570.08
 },
 {
  "input": "If you tried to justify this with numbers, it would take a really long time, but see if you can explain why this makes sense in just one sentence. ",
  "translatedText": "اگر بخواهید این را با اعداد توجیه کنید، واقعاً زمان زیادی می برد، اما ببینید آیا می توانید توضیح دهید که چرا این فقط در یک جمله منطقی است. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 571.1,
  "end": 577.88
 },
 {
  "input": "Next up, I'll be relating the idea of linear transformations covered so far to one of the areas where linear algebra is most useful, linear systems of equations. ",
  "translatedText": "در مرحله بعد، من ایده تبدیل‌های خطی را که تاکنون پوشش داده‌ایم، به یکی از حوزه‌هایی که جبر خطی مفیدترین است، یعنی سیستم‌های معادلات خطی، مرتبط می‌کنم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.0,
  "end": 590.96
 },
 {
  "input": "See you then! ",
  "translatedText": "بعدا می بینمت! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 591.48,
  "end": 591.6
 }
]