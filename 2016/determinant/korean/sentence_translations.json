[
 {
  "input": "Hello, hello again.",
  "translatedText": "",
  "from_community_srt": "안녕, 또 만났네. (이번에도 자막싱크가 안맞네요.",
  "n_reviews": 0,
  "start": 11.98,
  "end": 13.0
 },
 {
  "input": "So moving forward, I'll be assuming that you have a visual understanding of linear transformations and how they're represented with matrices, the way that I've been talking about in the last few videos.",
  "translatedText": "",
  "from_community_srt": "자막이 훨빨라요;) 그럼, 이제는 너에게 충분히 설명했다고 생각해. 선형변환에 대한 시각적 이해가 됬을거고, 선형변환을 행렬로 표현하는 방법도 알거야. 지난 동영상들에서 통해서 계속 얘기했었지.",
  "n_reviews": 0,
  "start": 13.52,
  "end": 21.84
 },
 {
  "input": "If you think about a couple of these linear transformations, you might notice how some of them seem to stretch space out, while others squish it on in.",
  "translatedText": "",
  "from_community_srt": "근데 너가 선형변환을 다루다보면, 어떤 것들은 공간을 확대시키는 것 같을거고, 또 어떤 것들은 공간을 축소시키는 것 같을거야.",
  "n_reviews": 0,
  "start": 22.66,
  "end": 30.42
 },
 {
  "input": "One thing that turns out to be pretty useful for understanding one of these transformations is to measure exactly how much it stretches or squishes things.",
  "translatedText": "",
  "from_community_srt": "이런 변환을 이해하는데 꽤 도움이 되는 방법 한가지가 있어. 바로 물체를 얼마나 확장되거나 축소되는지 특정해보는거야.",
  "n_reviews": 0,
  "start": 31.14,
  "end": 38.92
 },
 {
  "input": "More specifically, to measure the factor by which the area of a given region increases or decreases.",
  "translatedText": "",
  "from_community_srt": "더 구체적으로 설명하자면, 특정 지역의 크기를 증가하거나 감소시키는 팩터(factor 요인)값을 측정해보는 거야.",
  "n_reviews": 0,
  "start": 39.52,
  "end": 45.82
 },
 {
  "input": "For example, look at the matrix with columns 3, 0 and 0, 2.",
  "translatedText": "",
  "from_community_srt": "예를 들어 볼게. 열 (3, 0), (0, 2) 로 이루어진 행렬을 봐봐.",
  "n_reviews": 0,
  "start": 47.18,
  "end": 50.88
 },
 {
  "input": "It scales i-hat by a factor of 3 and scales j-hat by a factor of 2.",
  "translatedText": "",
  "from_community_srt": "이 행렬은 i-hat(x 축 단위벡터) 를 팩터 3으로 확장시키고, j-hat(y축 단위벡터)를 팩터2 로 확장시키고 있어.",
  "n_reviews": 0,
  "start": 51.32,
  "end": 56.18
 },
 {
  "input": "Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle.",
  "translatedText": "",
  "from_community_srt": "이번에는, 1x1 짜리 정사각형을 집중해서 봐봐. 이 정사각형 아래는 i-hat 벡터고 왼쪽은 j-hat 벡터야. 변환 후를 보면, 2x3 크기의 직사각형이 되었어.",
  "n_reviews": 0,
  "start": 56.7,
  "end": 67.52
 },
 {
  "input": "Since this region started out with area 1 and ended up with area 6, we can say the linear transformation has scaled its area by a factor of 6.",
  "translatedText": "",
  "from_community_srt": "처음엔 영역(area) 1로 시작했는데, 나중엔 영역(area)크기가 6으로 바뀌었어. 그럼 우리는 이 선형변환은 팩터 6 으로 영역(area) 를 확장시킨다고 말할 수 있어.",
  "n_reviews": 0,
  "start": 68.38,
  "end": 77.28
 },
 {
  "input": "Compare that to a shear, whose matrix has columns 1, 0 and 1, 1, meaning i-hat stays in place and j-hat moves over to 1, 1.",
  "translatedText": "",
  "from_community_srt": "기울이기?(shear) 변환과 비교해보자. 기울이기(shear) 변환을 타나내는 행렬은 (1,0), (1,1) 이야. 좀 풀어서 말하자면, i-hat 은 변하지 않고 j-hat 은 (1,1) 로 이동시켜.",
  "n_reviews": 0,
  "start": 78.18,
  "end": 86.1
 },
 {
  "input": "That same unit square determined by i-hat and j-hat gets slanted and turned into a parallelogram, but the area of that parallelogram is still 1, since its base and height each continue to have length 1.",
  "translatedText": "",
  "from_community_srt": "그러면 i-hat 과 j-hat 에 의해 결정된 단위 정사각형이 기울여지는 변형 후에는 평행사변형이 돼. 그래도 평행사변형의 영역(area) 크기는 여전히 1이야. 밑과 높이 길이가 여전히 1이기 때문이지.",
  "n_reviews": 0,
  "start": 87.0,
  "end": 98.38
 },
 {
  "input": "So even though this transformation smushes things about, it seems to leave areas unchanged, at least in the case of that 1 unit square.",
  "translatedText": "",
  "from_community_srt": "그래서, 이 변환이 마치 눌러서 찌그려뜨리는 것 같아도, 영역(넓이)는 바뀌지 않아. 흠, 적어도 단위 정사각형은 그렇지.",
  "n_reviews": 0,
  "start": 99.18,
  "end": 105.62
 },
 {
  "input": "Actually though, if you know how much the area of that one single unit square changes, it can tell you how the area of any possible region in space changes.",
  "translatedText": "",
  "from_community_srt": "사실은 너가 하나의 단위 정사각형의 영역이 얼마나 변하는지만 알면 공간 상 어떤 지역이 어떻게 변할지를 예측할 수 있게 돼.",
  "n_reviews": 0,
  "start": 106.82,
  "end": 115.52
 },
 {
  "input": "For starters, notice that whatever happens to one square in the grid has to happen to any other square in the grid, no matter the size.",
  "translatedText": "",
  "from_community_srt": "우선 격자에 한 정사각형이 어떻게 바뀌는지 살펴봐봐. 격자의 다른 정사각형들에도 마찬가지 변화가 똑같이 일어난다는 것을 깨닫게 될거야. 크기는 중요하지 않아.",
  "n_reviews": 0,
  "start": 116.3,
  "end": 123.58
 },
 {
  "input": "This follows from the fact that grid lines remain parallel and evenly spaced.",
  "translatedText": "",
  "from_community_srt": "이건 격자선이 평행하고 균등한 거리를 유지한 채 변화하기 때문이야.",
  "n_reviews": 0,
  "start": 124.34,
  "end": 128.04
 },
 {
  "input": "Then, any shape that's not a grid square can be approximated by grid squares pretty well, with arbitrarily good approximations if you use small enough grid squares.",
  "translatedText": "",
  "from_community_srt": "그럼 이제는, 정사각이 아닌 임의 형태를 살펴보자. 임의 형태를 격자의 정사각형으로 꽤 잘 근사할 수 있어. 격자 정사각형을 충분히 작게 만들면,",
  "n_reviews": 0,
  "start": 128.76,
  "end": 137.52
 },
 {
  "input": "So, since the areas of all those tiny grid squares are being scaled by some single amount, the area of the blob as a whole will also be scaled by that same single amount.",
  "translatedText": "",
  "from_community_srt": "원하는 만큼 정확한 근사를 얻을 수 있어. 그리고, 작은 격자 정사각형들이 이루는 영역은 하나의 영역과 동일하게 스케일링되기 때문에, 전체 영역도 또한 한개와 같은 비율만큼 스케일링 되지.",
  "n_reviews": 0,
  "start": 137.52,
  "end": 147.82
 },
 {
  "input": "This very special scaling factor, the factor by which a linear transformation changes any area, is called the determinant of that transformation.",
  "translatedText": "",
  "from_community_srt": "이 특별한 스케일링 팩터는 선형변환에 의한 영역의 변화를 나타내는 팩터로서 행렬식(determinant) 라고 불러. (역자: 행렬식보다 determinant 자체가 이해하기 쉬운듯;)",
  "n_reviews": 0,
  "start": 148.9,
  "end": 157.12
 },
 {
  "input": "I'll show how to compute the determinant of a transformation using its matrix later on in this video, which is also important in the computation.",
  "translatedText": "",
  "from_community_srt": "뒤에서 이 선형변환의 행렬식(determinant) 를 계산하는 방법을 보여줄건데, 그런데 이게 무엇인지 이해하는 것은 계산법을 이해하는 것보다 훨~씬 중요해. 날 믿어봐.",
  "n_reviews": 0,
  "start": 159.12,
  "end": 168.42
 },
 {
  "input": "For example, the determinant of a transformation would be 3 if that transformation increases the area of a region by a factor of 3.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 한 변환의 행렬식(determinant) 값이 3 이라면, 특정 지역의 크기는 팩터 3 만큼 증가해.",
  "n_reviews": 0,
  "start": 169.58,
  "end": 177.04
 },
 {
  "input": "The determinant of a transformation would be ½ if it squishes down all areas by a factor of ½.",
  "translatedText": "",
  "from_community_srt": "행렬식(determinant) 값이 1/2 라면, 영역크기를 1/2 크기로 축소시키는 것을 의미해.",
  "n_reviews": 0,
  "start": 178.18,
  "end": 184.34
 },
 {
  "input": "And the determinant of a 2D transformation is 0 if it squishes all of space onto a line, or even onto a single point.",
  "translatedText": "",
  "from_community_srt": "2차원 변환의 행렬식이 0 이라면, 모든 공간이 찌부려뜨려져서 선이 될 수도 있어. 아니, 어쩌면 한 점이 될 수도 있지.",
  "n_reviews": 0,
  "start": 186.0,
  "end": 193.5
 },
 {
  "input": "Since then, the area of any region would become zero.",
  "translatedText": "",
  "from_community_srt": "그럼 당연히, 어느 영역이든 크기가 0 이 될 거야.",
  "n_reviews": 0,
  "start": 194.0,
  "end": 196.76
 },
 {
  "input": "That last example will prove to be pretty important.",
  "translatedText": "",
  "from_community_srt": "이 마지막 예는 매우 중요한 것이라고 증명됐어.",
  "n_reviews": 0,
  "start": 197.62,
  "end": 199.6
 },
 {
  "input": "It means that checking if the determinant of a given matrix is zero will give a way of computing whether or not the transformation associated with that matrix squishes everything into a smaller dimension.",
  "translatedText": "",
  "from_community_srt": "주어진 행렬의 행렬식(determinant)값이 0 인지 확인하는 것은 계산할 수 있는지 없는지를 알려주는 거야. 이 변환과 관련된 행렬이 모든 것들을 더 작은 차원으로 뭉게버리는지를 말야.",
  "n_reviews": 0,
  "start": 200.02,
  "end": 209.74
 },
 {
  "input": "You'll see in the next few videos why this is even a useful thing to think about, but for now, I just want to lay down all of the visual intuition, which, in and of itself, is a beautiful thing to think about.",
  "translatedText": "",
  "from_community_srt": "앞으로 다음 동영상에서 좀 더 보여줄거야. 왜 이렇게 생각하는게 유용한 방법인지를. 하지만 당장은, 모든 시각적 직관을 잠시 내려놓았으면 좋겠어. 매우 아름다운 것이지만, 지금 일단은 그러자.",
  "n_reviews": 0,
  "start": 210.52,
  "end": 220.1
 },
 {
  "input": "Okay, I need to confess that what I've said so far is not quite right.",
  "translatedText": "",
  "from_community_srt": "좋아, 근데 난 사실 고백할게 있어. 지금까지 꽤 틀리게 말한게 있어.",
  "n_reviews": 0,
  "start": 222.12,
  "end": 225.56
 },
 {
  "input": "The full concept of the determinant allows for negative values.",
  "translatedText": "",
  "from_community_srt": "행렬식의 온전한 개념으로 볼때, 음수(-) 값을 허용해.",
  "n_reviews": 0,
  "start": 225.88,
  "end": 229.28
 },
 {
  "input": "But what would the idea of scaling an area by a negative amount even mean?",
  "translatedText": "",
  "from_community_srt": "그럼 영역을 스케일링할때 음수값은 무엇을 의미하는 걸까?",
  "n_reviews": 0,
  "start": 229.72,
  "end": 233.48
 },
 {
  "input": "This has to do with the idea of orientation.",
  "translatedText": "",
  "from_community_srt": "바로 방향(orientation)과 관계가 있어.",
  "n_reviews": 0,
  "start": 234.94,
  "end": 236.96
 },
 {
  "input": "For example, notice how this transformation gives the sensation of flipping space over.",
  "translatedText": "",
  "from_community_srt": "예를 들면 이런 변환을 살펴봐봐. 공간을 뒤집는 느낌을 주고 있어.",
  "n_reviews": 0,
  "start": 237.8,
  "end": 242.68
 },
 {
  "input": "If you were thinking of 2D space as a sheet of paper, a transformation like that one seems to turn over that sheet onto the other side.",
  "translatedText": "",
  "from_community_srt": "만약 너가 2차원 공간에 있는 한 종이조각을 떠올렸다면, 변환이 마치 종이를 뒤집는 것과 같아.",
  "n_reviews": 0,
  "start": 243.24,
  "end": 249.86
 },
 {
  "input": "Any transformations that do this are said to invert the orientation of space.",
  "translatedText": "",
  "from_community_srt": "이런 종류의 변환들을 일컬어 \"공간의 방향(orientation) 뒤집기\" 라고 불러. (역자: orientation 방향? 방위? 원점?)",
  "n_reviews": 0,
  "start": 250.64,
  "end": 255.04
 },
 {
  "input": "Another way to think about it is in terms of i-hat and j-hat.",
  "translatedText": "",
  "from_community_srt": "i-hat 과 j-hat 을 통해 설명하는 방법도 있어.",
  "n_reviews": 0,
  "start": 255.84,
  "end": 258.6
 },
 {
  "input": "Notice that in their starting positions, j-hat is to the left of i-hat.",
  "translatedText": "",
  "from_community_srt": "이 벡터들이 시작위치를 봐봐. i-hat 의 왼쪽에 j-hat 이 있어.",
  "n_reviews": 0,
  "start": 259.16,
  "end": 263.06
 },
 {
  "input": "If, after a transformation, j-hat is now on the right of i-hat, the orientation of space has been inverted.",
  "translatedText": "",
  "from_community_srt": "변환 후에는, i-hat 의 오른쪽에 j-hat 이 있어. 공간의 방위이 반전되고 있지.",
  "n_reviews": 0,
  "start": 263.62,
  "end": 270.2
 },
 {
  "input": "Whenever this happens, whenever the orientation of space is inverted, the determinant will be negative.",
  "translatedText": "",
  "from_community_srt": "이런 일이 발생할때마다, 공간의 방위(orientation) 이 뒤집힐때마다, 행렬식은 음수가 될 거야.",
  "n_reviews": 0,
  "start": 272.12,
  "end": 276.58
 },
 {
  "input": "The absolute value of the determinant, though, still tells you the factor by which areas have been scaled.",
  "translatedText": "",
  "from_community_srt": "그래도 행렬식의 절대값은 여전히 영역 스케일링 관한 팩터로 볼 수 있어.",
  "n_reviews": 0,
  "start": 277.46,
  "end": 282.4
 },
 {
  "input": "For example, the matrix with columns 1,1 and 2,-1 encodes a transformation that has determinant, I'll just tell you, negative 3.",
  "translatedText": "",
  "from_community_srt": "예를 들면 열 (1,1), (2,-1) 로 구성된 행렬이 나타내는 변환의 행렬값은 바로 -3 이야.",
  "n_reviews": 0,
  "start": 283.02,
  "end": 290.68
 },
 {
  "input": "And what this means is that space gets flipped over and areas are scaled by a factor of 3.",
  "translatedText": "",
  "from_community_srt": "그리고 이것이 의미하는 것은 그 공간이 뒤집어졌다는 거야. 그리고 영역크기는 팩터3 으로 스케일링 됬어.",
  "n_reviews": 0,
  "start": 291.46,
  "end": 296.28
 },
 {
  "input": "So why would this idea of a negative area scaling factor be a natural way to describe orientation flipping?",
  "translatedText": "",
  "from_community_srt": "그럼 왜 음수 스케일링 팩터라는 개념이 방향 반전을 설명하는 자연스런 방법인지 알겠지?",
  "n_reviews": 0,
  "start": 297.78,
  "end": 303.7
 },
 {
  "input": "Think about the series of transformations you get by slowly letting i-hat get closer and closer to j-hat.",
  "translatedText": "",
  "from_community_srt": "이런 연속된 변환들을 생각해보자. i-hat 과 j-hat 이 점점 가까워 지고 있어.",
  "n_reviews": 0,
  "start": 304.26,
  "end": 310.14
 },
 {
  "input": "As i-hat gets closer, all of the areas in space are getting squished more and more, meaning the determinant approaches 0.",
  "translatedText": "",
  "from_community_srt": "i-hat 이 가까워 지면서, 공간의 모든 영역이 점점 찌부려뜨려지고 있어. 그 동안에 행렬식 값은 점점 0 에 가까워져.",
  "n_reviews": 0,
  "start": 310.72,
  "end": 317.1
 },
 {
  "input": "Once i-hat lines up perfectly with j-hat, the determinant is 0.",
  "translatedText": "",
  "from_community_srt": "i-hat 과 j-hat 이 완전히 한 선을 이루게 되면 행렬식은 0 이야.",
  "n_reviews": 0,
  "start": 317.82,
  "end": 321.64
 },
 {
  "input": "Then, if i-hat continues the way that it was going, doesn't it kind of feel natural for the determinant to keep decreasing into the negative numbers?",
  "translatedText": "",
  "from_community_srt": "근데, i-hat 이 계속 이동하게 하면 행렬식 값이 음수가 되는게 자연스럽지 않을까?",
  "n_reviews": 0,
  "start": 322.44,
  "end": 329.28
 },
 {
  "input": "So that's the understanding of determinants in two dimensions.",
  "translatedText": "",
  "from_community_srt": "자, 이것이 2차원에서 행렬식에 대한 설명이야.",
  "n_reviews": 0,
  "start": 330.68,
  "end": 333.56
 },
 {
  "input": "What do you think it should mean for three dimensions?",
  "translatedText": "",
  "from_community_srt": "3차원에서는 어떨것 같아?",
  "n_reviews": 0,
  "start": 333.56,
  "end": 335.94
 },
 {
  "input": "It also tells you how much a transformation scales things, but this time, it tells you how much volumes get scaled.",
  "translatedText": "",
  "from_community_srt": "3 × 3 행렬의 행렬식 값도 역시 얼마나 스케일링 하는지를 알려주지만, 하지만, 이번에는 부피(volume)가 얼마나 스케일링 되는지 알려줘.",
  "n_reviews": 0,
  "start": 336.92,
  "end": 343.24
 },
 {
  "input": "Just as in two dimensions, where this is easiest to think about by focusing on one particular square with an area 1 and watching only what happens to it, in three dimensions, it helps to focus your attention on the specific 1 by 1 by 1 cube whose edges are resting on the basis vectors, i-hat, j-hat and k-hat.",
  "translatedText": "",
  "from_community_srt": "2차원에서 이것을 가장 쉽게 생각해보는 방법은, 영역크기 1 에 해당하는 한 정사각형을 떠올려보는 거야. 그리고 그것의 변화를 쳐다봤지. 3차원에서도 이 방법은 상당히 도움이 돼. 하나의 1x1x1 큐브(정육면체)에 집중하는 거야. 이 정육면체 모서리에 각 단위벡터가 놓여있어. i-hat, j-hat, k-hat 벡터가.",
  "n_reviews": 0,
  "start": 345.34,
  "end": 363.44
 },
 {
  "input": "After the transformation, that cube might get warped into some kind of slanty slanty cube.",
  "translatedText": "",
  "from_community_srt": "변환 후 이 큐브는 기울어지고 기울어진 큐브가 돼.",
  "n_reviews": 0,
  "start": 364.32,
  "end": 369.3
 },
 {
  "input": "This shape, by the way, has the best name ever, parallelipiped, a name that's made even more delightful when your professor has a nice thick Russian accent.",
  "translatedText": "",
  "from_community_srt": "근데 이 모양에 딱 맞는 이름이 있어. 평행육면체 (parallelepiped). 두꺼운 러시아 억양을 가진 발음처럼 들려.",
  "n_reviews": 0,
  "start": 370.34,
  "end": 377.44
 },
 {
  "input": "Since this cube starts out with a volume of 1, and the determinant gives the factor by which any volume is scaled, you can think of the determinant simply as being the volume of that parallelipiped that the cube turns into.",
  "translatedText": "",
  "from_community_srt": "이 큐브는 부피가 1이고, 그리고 행렬식 값은 어떤 부피이든지 스케일링 팩터를 알려주니까 행렬식 값을 마치 평행육면체의 부피값으로 생각해도 될거야. 부피 1짜리 큐브가 바뀐 후의 부피로 말야.",
  "n_reviews": 0,
  "start": 378.52,
  "end": 390.64
 },
 {
  "input": "A determinant of 0 would mean that all of space is squished onto something with 0 volume, meaning either a flat plane, a line, or, in the most extreme case, onto a single point.",
  "translatedText": "",
  "from_community_srt": "행렬식 값이 0 이라면 모든 공간이 찌부려뜨려서 부피 0을 만든다는 의미이고, 찌부려져서 평면이나, 선, 가장 극단적인 경우에는 단일 점이 되는 경우야.",
  "n_reviews": 0,
  "start": 392.38,
  "end": 402.5
 },
 {
  "input": "Those of you who watched chapter 2 will recognize this as meaning that the columns of the matrix are linearly dependent.",
  "translatedText": "",
  "from_community_srt": "챕터 2장을 본 사람들은 이 말을 받아들일때 그 행렬의 열들은 선형의존(linearly dependent) 하다라고 할거야.",
  "n_reviews": 0,
  "start": 403.76,
  "end": 409.24
 },
 {
  "input": "Can you see why?",
  "translatedText": "",
  "from_community_srt": "왜 그런지 알겠어?",
  "n_reviews": 0,
  "start": 409.76,
  "end": 410.42
 },
 {
  "input": "What about negative determinants?",
  "translatedText": "",
  "from_community_srt": "음수 행렬식값일때는 어떨까?",
  "n_reviews": 0,
  "start": 414.92,
  "end": 416.64
 },
 {
  "input": "What should that mean for three dimensions?",
  "translatedText": "",
  "from_community_srt": "3차원에서는 무슨 의미이여야 할까?",
  "n_reviews": 0,
  "start": 416.78,
  "end": 418.1
 },
 {
  "input": "One way to describe orientation in 3D is with the right hand rule.",
  "translatedText": "",
  "from_community_srt": "3차원에서 방향(orientation)을 설명하는 방법으로 오른손 규칙이 있어.",
  "n_reviews": 0,
  "start": 418.78,
  "end": 422.68
 },
 {
  "input": "Point the forefinger of your right hand in the direction of i-hat, stick out your middle finger in the direction of j-hat, and notice how when you point your thumb up, it's in the direction of k-hat.",
  "translatedText": "",
  "from_community_srt": "오른손의 집게손가락이 가리키는 방향이 i-hat 의 방향이 돼. 가운데 손가락이 가리키는 방향은 j-hat 방향, 그리고 알아차렸겠지만, 엄지손가락이 가리키는 방향은 k-hat 의 방향이야.",
  "n_reviews": 0,
  "start": 423.3,
  "end": 432.76
 },
 {
  "input": "If you can still do that after the transformation, orientation has not changed, and the determinant is positive.",
  "translatedText": "",
  "from_community_srt": "여전히 변환 이후에도 이 방향이 유지되려면, 방향(orientation) 이 바뀌지 않고, 양수 행렬식 값을 가진 경우야.",
  "n_reviews": 0,
  "start": 434.88,
  "end": 440.9
 },
 {
  "input": "Otherwise, if after the transformation it only makes sense to do that with your left hand, orientation has been flipped, and the determinant is negative.",
  "translatedText": "",
  "from_community_srt": "그렇지 않으면 변환 이후에 왼손으로 바꿔야 하는 경우에는 방향(orientation)이 반전된거고, 행렬식 값은 음수가 돼.",
  "n_reviews": 0,
  "start": 441.54,
  "end": 449.38
 },
 {
  "input": "So, if you haven't seen it before, you're probably wondering by now, how do you actually compute the determinant?",
  "translatedText": "",
  "from_community_srt": "만약 너가 전에 본 적 없다면 아마 지금쯤 꽤 궁금한게 생겼을꺼야. \"실제로 어떻게 행렬식을 계산하는 걸까?\"",
  "n_reviews": 0,
  "start": 451.9,
  "end": 457.04
 },
 {
  "input": "For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c.",
  "translatedText": "",
  "from_community_srt": "a,b,c,d 변수로 이루어진 2x2 행렬에서 공식은 (a * d) - (b * c) 였어.",
  "n_reviews": 0,
  "start": 457.56,
  "end": 464.42
 },
 {
  "input": "Here's part of an intuition for where this formula comes from.",
  "translatedText": "",
  "from_community_srt": "이 공식이 어떻게 나왔는지는 직관을 발휘할 부분이야.",
  "n_reviews": 0,
  "start": 465.74,
  "end": 468.5
 },
 {
  "input": "Let's say that the terms b and c both happened to be 0.",
  "translatedText": "",
  "from_community_srt": "b, c 둘 다 0 이라고 해보자.",
  "n_reviews": 0,
  "start": 468.88,
  "end": 471.78
 },
 {
  "input": "Then, the term a tells you how much i-hat is stretched in the x direction, and the term d tells you how much j-hat is stretched in the y direction.",
  "translatedText": "",
  "from_community_srt": "그리고, a 를 i-hat 을 x축 방향으로 스케일링하는 요소로 보고, d 의 경우에는 j-hat 을 y 축방향으로 스케일링하는 요소로 보자.",
  "n_reviews": 0,
  "start": 471.78,
  "end": 481.16
 },
 {
  "input": "So, since those other terms are 0, it should make sense that a times d gives the area of the rectangle that our favorite unit square turns into, kind of like the 3, 0, 0, 2 example from earlier.",
  "translatedText": "",
  "from_community_srt": "다른 값들(b,c)은 모두 0이기 때문에 행렬식 결과는 a * d 가 될거야. 그럼 단위 정사각형이 변환 후에 직사각형이 될거야. 앞서나온 행렬 (3, 0, 0, 2) 의 경우와 똑같아.",
  "n_reviews": 0,
  "start": 482.76,
  "end": 493.36
 },
 {
  "input": "Even if only one of b or c are 0, you'll have a parallelogram with a base a and a height d.",
  "translatedText": "",
  "from_community_srt": "b, c 값 중 하나만 0 이라도, 평행사변형을 얻게될거야. 밑변 길이가 a 이고, 높이가 d 야.",
  "n_reviews": 0,
  "start": 495.36,
  "end": 501.76
 },
 {
  "input": "So, the area should still be a times d.",
  "translatedText": "",
  "from_community_srt": "그래서 영역 크기는 똑같이 a * d 가 돼.",
  "n_reviews": 0,
  "start": 501.78,
  "end": 504.5
 },
 {
  "input": "Loosely speaking, if both b and c are non-zero, then that b times c term tells you how much this parallelogram is stretched or squished in the diagonal direction.",
  "translatedText": "",
  "from_community_srt": "비공식적으로 말하자면 b, c 가 둘 다 0 이 아닌 경우엔 b * c 값이 알려주는 것은 이 평행사변형의 얼마나 대각선 방향으로 늘려지거나 찌그러지를 말해줘.",
  "n_reviews": 0,
  "start": 505.46,
  "end": 515.46
 },
 {
  "input": "For those of you hungry for a more precise description of this b times c term, here's a helpful diagram if you'd like to pause and ponder.",
  "translatedText": "",
  "from_community_srt": "아마 b * c 에 대한 좀 더 정확한 설명을 듣고 싶은 사람도 있을텐데 여기에 그런 사람들을 위해 도움될만한 다이어그램을 준비했어.",
  "n_reviews": 0,
  "start": 516.66,
  "end": 522.88
 },
 {
  "input": "Now, if you feel like computing determinants by hand is something that you need to know, the only way to get it down is to just practice it with a few.",
  "translatedText": "",
  "from_community_srt": "만약 손으로 직접 행렬식 값을 계산할 생각이라면 너가 알아야만 할 것이 있어. 그것을 익히는 유일한 방법은 몇번 연습해보는 방법밖에 없어.",
  "n_reviews": 0,
  "start": 523.98,
  "end": 531.2
 },
 {
  "input": "There's really not that much I can say or animate that's going to drill in the computation.",
  "translatedText": "",
  "from_community_srt": "계산에 관해서는 영상이나 준비한 말은 별로 없어.",
  "n_reviews": 0,
  "start": 531.2,
  "end": 535.18
 },
 {
  "input": "This is all triply true for three-dimensional determinants.",
  "translatedText": "",
  "from_community_srt": "이 모든 것들은 3차원에서 행렬식에 대해서도 모두 참이야.",
  "n_reviews": 0,
  "start": 536.12,
  "end": 538.64
 },
 {
  "input": "There is a formula, and if you feel like that's something you need to know, you should practice with a few matrices, or, you know, go watch Sal Khan work through a few.",
  "translatedText": "",
  "from_community_srt": "여기 공식이 있어. 만약 너가 이 공식에 대해 뭔가 알아내고 싶다면 몇가지 행렬들로 연습을 해야만 해. 아니면 살만 칸(Sal Khan) 의 동영상 몇개를 찾아봐봐.",
  "n_reviews": 0,
  "start": 539.04,
  "end": 546.34
 },
 {
  "input": "Honestly, though, I don't think that those computations fall within the essence of linear algebra, but I definitely think that understanding what the determinant represents falls within that essence.",
  "translatedText": "",
  "from_community_srt": "솔직히 말해서 이런 계산은 선형대수의 본질은 아닌 것 같아. 난 행렬식값이 무엇을 나타내는지 아는 것이 본질에 해당한다고 생각해.",
  "n_reviews": 0,
  "start": 547.24,
  "end": 556.46
 },
 {
  "input": "Here's kind of a fun question to think about before the next video.",
  "translatedText": "",
  "from_community_srt": "다음 동영상으로 가기전에 생각해볼만한 재밌는 퀴즈가 있어.",
  "n_reviews": 0,
  "start": 558.06,
  "end": 560.64
 },
 {
  "input": "If you multiply two matrices together, the determinant of the resulting matrix is the same as the product of the determinants of the original two matrices.",
  "translatedText": "",
  "from_community_srt": "두 개의 행렬을 곱한 후 얻어지는 행렬식값은 따로 두 행렬의 행렬식값을 구해서 곱하는 것과 같을까?",
  "n_reviews": 0,
  "start": 560.64,
  "end": 570.08
 },
 {
  "input": "If you tried to justify this with numbers, it would take a really long time, but see if you can explain why this makes sense in just one sentence.",
  "translatedText": "",
  "from_community_srt": "만약 숫자로 이것을 증명하려 한다면, 꽤 오랜 시간이 걸릴거야. 한 문장으로 왜그런지 설명을 한번 해봐.",
  "n_reviews": 0,
  "start": 571.1,
  "end": 577.88
 },
 {
  "input": "Next up, I'll be relating the idea of linear transformations covered so far to one of the areas where linear algebra is most useful, linear systems of equations.",
  "translatedText": "",
  "from_community_srt": "다음에는 지금까지 다룬 선형변환 개념을 다른 것과 엮어볼거야. 선형대수가 가장 유용한 분야들 하나야. 선형 방정식계를 사용하는 분야지.",
  "n_reviews": 0,
  "start": 582.0,
  "end": 591.6
 }
]