[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "translatedText": "تعد المتجهات الذاتية والقيم الذاتية واحدة من تلك المواضيع التي يجدها الكثير من الطلاب غير بديهية بشكل خاص.",
  "model": "google_nmt",
  "from_community_srt": "إذا كان لدي ناقلات يجلس هنا في الفضاء 2D لدينا طريقة قياسية لوصف ذلك ينسق. في هذه الحالة ، يقوم المتجه بتنسيق [3 ، 2]، مما يعني الذهاب من ذيله إلى طرفه ينطوي على نقل 3 وحدات إلى اليمين و 2 يصل وحدات.",
  "n_reviews": 0,
  "start": 19.92,
  "end": 25.76
 },
 {
  "input": "Questions like, why are we doing this and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "translatedText": "أسئلة مثل، لماذا نفعل هذا وماذا يعني هذا في الواقع، غالبًا ما تُترك لتطفو بعيدًا في بحر من الحسابات دون إجابة.",
  "model": "google_nmt",
  "from_community_srt": "الآن ، فإن الطريقة الخطية والجبر أكثر لوصف الإحداثيات هو التفكير في كل من هذه الأرقام ك العددية",
  "n_reviews": 0,
  "start": 25.76,
  "end": 33.26
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "translatedText": "وبينما قمت بطرح مقاطع الفيديو الخاصة بهذه السلسلة، علق الكثير منكم حول التطلع إلى تصور هذا الموضوع على وجه الخصوص.",
  "model": "google_nmt",
  "from_community_srt": "شيء يمتد أو يسحق المتجهات.",
  "n_reviews": 0,
  "start": 33.92,
  "end": 40.06
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "translatedText": "أظن أن السبب في ذلك لا يرجع إلى كون الأشياء الذاتية معقدة بشكل خاص أو سيئة التفسير.",
  "model": "google_nmt",
  "from_community_srt": "أنت تفكر في هذا التنسيق الأول كتقويم أنا قبعة المتجه مع طول 1، مشيرا إلى حق في حين أن تنسيق الإحداثي الثاني j-hat",
  "n_reviews": 0,
  "start": 40.68,
  "end": 46.36
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "translatedText": "في الواقع، إنه أمر واضح ومباشر نسبيًا، وأعتقد أن معظم الكتب تقوم بعمل جيد في شرحه.",
  "model": "google_nmt",
  "from_community_srt": "المتجه مع طول 1 ، مشيرا على التوالي فوق.",
  "n_reviews": 0,
  "start": 46.86,
  "end": 51.18
 },
 {
  "input": "The issue is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "translatedText": "تكمن المشكلة في أنه يكون الأمر منطقيًا فقط إذا كان لديك فهم بصري قوي للعديد من المواضيع التي تسبقه.",
  "model": "google_nmt",
  "from_community_srt": "غيض إلى مجموع ذيل تلك المتجهات المقياس هو ما تهدف الإحداثيات لوصفه.",
  "n_reviews": 0,
  "start": 51.52,
  "end": 58.48
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "translatedText": "الأهم هنا هو أنك تعرف كيفية التفكير في المصفوفات كتحويلات خطية، ولكن عليك أيضًا أن تكون مرتاحًا لأشياء مثل المحددات وأنظمة المعادلات الخطية وتغيير الأساس.",
  "model": "google_nmt",
  "from_community_srt": "يمكنك التفكير في هذين المتجهين الخاصين كما تغليف جميع الافتراضات الضمنية من نظام الإحداثيات لدينا. حقيقة أن الرقم الأول يشير إلى اليمين اقتراح أن الثاني يشير إلى الحركة التصاعدية بالضبط كم وحدة من المسافات.",
  "n_reviews": 0,
  "start": 59.06,
  "end": 69.94
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "translatedText": "عادةً ما يكون الارتباك حول الأشياء الذاتية مرتبطًا بأساس هش في أحد هذه المواضيع أكثر من ارتباطه بالمتجهات الذاتية والقيم الذاتية نفسها.",
  "model": "google_nmt",
  "from_community_srt": "كل ذلك مرتبط باختيار آي-هات و j-hat مثل المتجهات التي هي إحداثيات العددية من المفترض أن نطاقها في الواقع.",
  "n_reviews": 0,
  "start": 70.72,
  "end": 79.24
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "translatedText": "للبدء، فكر في بعض التحولات الخطية في بعدين، مثل ذلك الموضح هنا.",
  "model": "google_nmt",
  "from_community_srt": "على أي حال للترجمة بين المتجهات والمجموعات من الأرقام يسمى نظام الإحداثيات واثنين من المتجهات الخاصة ، آي قبعة وجي هات ، تسمى المتجهات الأساسية",
  "n_reviews": 0,
  "start": 79.98,
  "end": 84.84
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "translatedText": "يقوم بنقل المتجه الأساسي i-hat إلى الإحداثيات 3 و0 وj-hat إلى 1 و2.",
  "model": "google_nmt",
  "from_community_srt": "لدينا نظام الإحداثيات القياسي.",
  "n_reviews": 0,
  "start": 85.46,
  "end": 91.04
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "translatedText": "لذلك يتم تمثيلها بمصفوفة أعمدتها هي 3، 0، و1، 2.",
  "model": "google_nmt",
  "from_community_srt": "ما أود التحدث عنه هنا هي فكرة استخدام مجموعة مختلفة من الأساس ثلاثة أبعاد.",
  "n_reviews": 0,
  "start": 91.78,
  "end": 95.64
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "translatedText": "ركز على ما يفعله بمتجه معين، وفكر في مدى هذا المتجه، أي الخط الذي يمر عبر نقطة الأصل وطرفه.",
  "model": "google_nmt",
  "from_community_srt": "على سبيل المثال ، لنفترض أن لديك صديقًا ، جنيفر الذي يستخدم مجموعة مختلفة من المتجهات الأساسية والتي سأطلق عليها b1 و b2",
  "n_reviews": 0,
  "start": 96.6,
  "end": 104.16
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "translatedText": "سيتم التخلص من معظم المتجهات خلال عملية التحول.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 104.92,
  "end": 108.38
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "translatedText": "أعني أنه قد يبدو من قبيل الصدفة أن المكان الذي هبط فيه المتجه يقع أيضًا في مكان ما على هذا الخط.",
  "model": "google_nmt",
  "from_community_srt": "أول نقطة أساسها ناقل B1 تصل إلى صحيح قليلا ونقطتها الثانية من ناقلات b2 تركت وأعلى الآن ، إلقاء نظرة أخرى على هذا المتجه ذلك لقد اظهرت في وقت سابق",
  "n_reviews": 0,
  "start": 108.78,
  "end": 115.32
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "translatedText": "لكن بعض المتجهات الخاصة تظل في امتدادها الخاص، مما يعني أن تأثير المصفوفة على مثل هذا المتجه هو مجرد تمديده أو سحقه، مثل العددية.",
  "model": "google_nmt",
  "from_community_srt": "الشخص الذي نود وصفه باستخدامه الإحداثيات [3 ، 2] باستخدام لدينا ناقلات أساس i-hat و j-hat. جنيفر تصف فعلا هذا الناقل مع الإحداثيات [5/3، 1/3] ما يعنيه هذا هو أن طريقة معينة للوصول إلى هذا المتجه",
  "n_reviews": 0,
  "start": 117.4,
  "end": 127.04
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "translatedText": "في هذا المثال المحدد، يعتبر المتجه الأساسي i-hat أحد هذه المتجهات الخاصة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 129.46,
  "end": 134.1
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "translatedText": "مدى i-hat هو المحور السيني، ومن العمود الأول للمصفوفة، يمكننا أن نرى أن i-hat يتحرك إلى 3 أضعاف نفسه، ولا يزال على هذا المحور السيني.",
  "model": "google_nmt",
  "from_community_srt": "باستخدام اثنين من ناقلات أساسها هو قياس b1 بمقدار 5/3 ، المقياس b2 بمقدار 1/3 ثم نضيفهما معًا. في القليل ، سأريك كيف يمكنك لقد برزت هذين الرقمين 5/3 و 1/3.",
  "n_reviews": 0,
  "start": 134.64,
  "end": 144.12
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "translatedText": "علاوة على ذلك، نظرًا للطريقة التي تعمل بها التحويلات الخطية، فإن أي متجه آخر على المحور السيني يتم تمديده أيضًا بعامل 3، وبالتالي يبقى في امتداده الخاص.",
  "model": "google_nmt",
  "from_community_srt": "بشكل عام ، عندما تستخدم جينيفر الإحداثيات لوصف المتجه تفكر في تنسيقها الأول كقياس B1 الإحداثي الثاني هو التحجيم b2 وتضيف النتائج.",
  "n_reviews": 0,
  "start": 146.32,
  "end": 156.48
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "translatedText": "المتجه الأكثر تسللًا والذي يبقى على امتداده الخاص أثناء هذا التحويل هو سالب 1، 1.",
  "model": "google_nmt",
  "from_community_srt": "ما ستحصل عليه سيكون طبيعيا تماما مختلف من المتجه الذي نفكر به أنا وأنت من وجود تلك الإحداثيات.",
  "n_reviews": 0,
  "start": 158.5,
  "end": 164.04
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "translatedText": "وينتهي الأمر بالتمدد بعامل 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 164.66,
  "end": 167.14
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "translatedText": "ومرة أخرى، الخطية ستعني ضمنًا أن أي متجه آخر على الخط القطري الممتد بواسطة هذا الشخص سوف يتم تمديده بعامل قدره 2.",
  "model": "google_nmt",
  "from_community_srt": "لتكون أكثر دقة حول الإعداد هنا لها أول ناقلات أساس b1 هو الشيء الذي نود وصفه مع إحداثيات [2 ، 1] و أساسها الثاني ناقلات b2 هو شيء نود وصفه بـ [-1 ، 1].",
  "n_reviews": 0,
  "start": 169.0,
  "end": 178.22
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "translatedText": "وبالنسبة لهذا التحويل، هذه هي جميع المتجهات التي تتمتع بهذه الخاصية الخاصة وهي البقاء على امتدادها.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.82,
  "end": 185.18
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "translatedText": "تلك الموجودة على المحور السيني تتمدد بعامل 3، وتلك الموجودة على هذا الخط القطري تتمدد بعامل 2.",
  "model": "google_nmt",
  "from_community_srt": "ولكن من المهم أن ندرك من وجهة نظرها في نظامها تلك المتجهات لها إحداثيات [1، 0] و [0 ، 1] هم ما يعرف معنى الإحداثيات [1 ، 0] و [0 ، 1] في عالمها.",
  "n_reviews": 0,
  "start": 185.62,
  "end": 191.98
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "translatedText": "سيتم تدوير أي متجه آخر إلى حد ما أثناء التحويل، مما يؤدي إلى إزالته من الخط الذي يمتد عليه.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ، في الواقع ، نحن نتحدث لغات مختلفة نحن جميعا ننظر إلى نفس المتجهات في الفضاء لكن جنيفر تستخدم كلمات وأرقام مختلفة لوصفها.",
  "n_reviews": 0,
  "start": 192.76,
  "end": 198.08
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "translatedText": "كما كنت قد خمنت الآن، تسمى هذه المتجهات الخاصة بالمتجهات الذاتية للتحويل، ويرتبط كل ناقل ذاتي به بما يسمى القيمة الذاتية، وهو مجرد العامل الذي يتم من خلاله تمديده أو سحقه أثناء التحويل.",
  "model": "google_nmt",
  "from_community_srt": "اسمحوا لي أن أقول كلمة سريعة حول كيف أنا أمثل الأشياء هنا عندما تحرك الفضاء 2D أنا عادة استخدام هذه الشبكة المربعة لكن هذه الشبكة هي مجرد بناء طريقة لتصور نظام الإحداثيات لدينا وذلك يعتمد على اختيارنا من الأساس.",
  "n_reviews": 0,
  "start": 202.52,
  "end": 217.38
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing, or the fact that these eigenvalues happen to be positive.",
  "translatedText": "بالطبع، لا يوجد شيء مميز في التمدد مقابل السحق، أو حقيقة أن هذه القيم الذاتية تكون إيجابية.",
  "model": "google_nmt",
  "from_community_srt": "الفضاء نفسه لا يوجد لديه شبكة الجوهرية.",
  "n_reviews": 0,
  "start": 220.28,
  "end": 225.94
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "translatedText": "في مثال آخر، يمكن أن يكون لديك متجه ذاتي قيمته الذاتية سالب 1 نصف، مما يعني أنه يتم قلب المتجه وسحقه بعامل قدره النصف.",
  "model": "google_nmt",
  "from_community_srt": "جنيفر قد ترسم شبكتها الخاصة والتي ستكون بناء متساوٍ يعني ليس أكثر من أداة بصرية للمساعدة في متابعة معنى إحداثياتها.",
  "n_reviews": 0,
  "start": 226.38,
  "end": 235.12
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "translatedText": "لكن الجزء المهم هنا هو أن يظل على الخط الذي يمتد إليه دون أن يدور خارجًا عنه.",
  "model": "google_nmt",
  "from_community_srt": "ومع ذلك ، فإن أصلها سيصطف في الواقع مع لنا لأن الجميع يوافق على ما ينسق [0 ، 0] يجب أن تعني. هذا هو الشيء الذي تحصل عليه عند قياس أي متجه بنسبة 0.",
  "n_reviews": 0,
  "start": 236.98,
  "end": 242.76
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "translatedText": "للحصول على لمحة عن السبب الذي يجعل هذا أمرًا مفيدًا للتفكير فيه، فكر في بعض التدوير ثلاثي الأبعاد.",
  "model": "google_nmt",
  "from_community_srt": "لكن اتجاه محاورها والتباعد بين خطوط الشبكة الخاصة بها سيكون مختلفًا ، اعتمادًا على اختيارها من ناقلات الأساس.",
  "n_reviews": 0,
  "start": 244.46,
  "end": 249.8
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "translatedText": "إذا تمكنت من العثور على متجه ذاتي لهذا الدوران، أي متجه يظل في امتداده الخاص، فإن ما وجدته هو محور الدوران.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ، بعد كل هذا تم إعداده سؤال طبيعي جدا أن نسأل هو كيف نترجم بين أنظمة الإحداثيات؟ إذا ، على سبيل المثال ، تصف جينيفر متجه مع الإحداثيات [-1 ، 2]",
  "n_reviews": 0,
  "start": 251.66,
  "end": 260.5
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3x3 matrix associated with that transformation.",
  "translatedText": "ومن الأسهل التفكير في دوران ثلاثي الأبعاد من حيث بعض محاور الدوران والزاوية التي يدور بها، بدلاً من التفكير في المصفوفة الكاملة 3x3 المرتبطة بهذا التحويل.",
  "model": "google_nmt",
  "from_community_srt": "ماذا سيكون ذلك في نظام الإحداثيات لدينا؟ كيف تترجم من لغتها إلى لنا؟ حسناً ، ما هي إحداثياتنا",
  "n_reviews": 0,
  "start": 262.6,
  "end": 274.74
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "translatedText": "في هذه الحالة، بالمناسبة، يجب أن تكون القيمة الذاتية المقابلة 1، نظرًا لأن الدورات لا تمد أو تسحق أي شيء أبدًا، وبالتالي فإن طول المتجه سيظل كما هو.",
  "model": "google_nmt",
  "from_community_srt": "هو أن هذا المتجه هو -1 b1 + 2 b2.",
  "n_reviews": 0,
  "start": 277.0,
  "end": 285.86
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "translatedText": "يظهر هذا النمط كثيرًا في الجبر الخطي.",
  "model": "google_nmt",
  "from_community_srt": "ومن وجهة نظرنا يحتوي b1 على إحداثيات [2، 1] و b2 لديه إحداثيات [-1، 1] حتى يمكننا حساب -1 b1 + 2 b2 بالفعل",
  "n_reviews": 0,
  "start": 288.08,
  "end": 290.02
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "translatedText": "مع أي تحويل خطي تصفه المصفوفة، يمكنك فهم ما تفعله من خلال قراءة أعمدة هذه المصفوفة كنقاط هبوط للمتجهات الأساسية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 290.44,
  "end": 299.4
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "translatedText": "لكن في كثير من الأحيان، الطريقة الأفضل للوصول إلى قلب ما يفعله التحويل الخطي فعليًا، بشكل أقل اعتمادًا على نظام الإحداثيات الخاص بك، هي العثور على المتجهات الذاتية والقيم الذاتية.",
  "model": "google_nmt",
  "from_community_srt": "كما هي ممثلة في نظام الإحداثيات لدينا ويعمل هذا تحصل على متجه بإحداثيات [-4، 1] إذن ، هكذا سنصف المتجه انها تفكر في [-1 ، 2]",
  "n_reviews": 0,
  "start": 300.02,
  "end": 310.82
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "translatedText": "لن أغطي التفاصيل الكاملة حول طرق حساب المتجهات الذاتية والقيم الذاتية هنا، لكنني سأحاول تقديم نظرة عامة على الأفكار الحسابية الأكثر أهمية للفهم المفاهيمي.",
  "model": "google_nmt",
  "from_community_srt": "هذه العملية هنا من تسلق كل أساس لها ثلاثة أبعاد من الإحداثيات المقابلة لبعض المتجهات ثم إضافتها معًا قد تبدو مألوفة إلى حد ما انها مضاعفة مكافحة ناقلات مع مصفوفة تمثل أعمدةها جينيفر ناقلات الأساس في لغتنا",
  "n_reviews": 0,
  "start": 315.46,
  "end": 326.02
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "translatedText": "رمزيًا، إليك ما تبدو عليه فكرة المتجهات الذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 327.18,
  "end": 330.48
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "translatedText": "A هي المصفوفة التي تمثل بعض التحولات، مع v كمتجه ذاتي، ولامدا رقم، أي القيمة الذاتية المقابلة.",
  "model": "google_nmt",
  "from_community_srt": "في الواقع ، بمجرد فهمك مصفوفة متجه عمليه الضرب كتطبيق تحول خطي معين قل ، من خلال مشاهدة ما كنت لك أن تكون أكثر من غيرها فيديو مهم في هذه السلسلة ، الفصل 3. هناك طريقة بديهية للتفكير ماذا يجري هنا.",
  "n_reviews": 0,
  "start": 331.04,
  "end": 339.74
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "translatedText": "ما يقوله هذا التعبير هو أن حاصل ضرب المصفوفة والمتجه، A في v، يعطي نفس النتيجة مثل مجرد قياس المتجه الذاتي v ببعض قيمة لامدا.",
  "model": "google_nmt",
  "from_community_srt": "مصفوفة تمثل أعمدةها جينيفر ناقلات الأساس يمكن اعتباره بمثابة تحول التي تحرك ناقلات الأساس لدينا ، أنا قبعة وجي هات",
  "n_reviews": 0,
  "start": 340.68,
  "end": 349.9
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "translatedText": "لذا فإن العثور على المتجهات الذاتية وقيمها الذاتية للمصفوفة A يعود إلى إيجاد قيم v وlamda التي تجعل هذا التعبير صحيحًا.",
  "model": "google_nmt",
  "from_community_srt": "الأشياء التي نفكر بها عندما نقول [1،0] و [0 ، 1] لمتجهات أساس جنيفر الأشياء التي تفكر بها عندما تقول [1 ، 0] و [0 ، 1]",
  "n_reviews": 0,
  "start": 351.0,
  "end": 360.1
 },
 {
  "input": "It's a little awkward to work with at first, because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "translatedText": "قد يكون العمل به صعبًا بعض الشيء في البداية، لأن الجانب الأيسر يمثل الضرب بمتجه المصفوفة، لكن الجانب الأيمن هنا يمثل الضرب بالمتجه العددي.",
  "model": "google_nmt",
  "from_community_srt": "لإظهار كيف يعمل هذا دعونا نمشي ما سيعنيه لأخذ المتجه الذي نفكر فيه إحداثيات [-1 ، 2] وتطبيق هذا التحول.",
  "n_reviews": 0,
  "start": 361.92,
  "end": 370.54
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "translatedText": "لذلك دعونا نبدأ بإعادة كتابة الجانب الأيمن كنوع من ضرب المصفوفة والمتجه، باستخدام مصفوفة لها تأثير في قياس أي متجه بمعامل لامدا.",
  "model": "google_nmt",
  "from_community_srt": "قبل التحول الخطي نحن نفكر في هذا الناقل كمجموعة خطية معينة من أساسنا vectors -1 x i-hat + 2 x j-hat.",
  "n_reviews": 0,
  "start": 371.12,
  "end": 380.62
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "translatedText": "ستمثل أعمدة هذه المصفوفة ما يحدث لكل متجه أساسي، ويتم ببساطة ضرب كل متجه أساسي في لامدا، لذلك سيكون لهذه المصفوفة رقم لامدا أسفل القطر، مع وجود أصفار في كل مكان آخر.",
  "model": "google_nmt",
  "from_community_srt": "والميزة الرئيسية للتحول الخطي هو أن المتجه الناتج سيكون ذلك نفس التركيبة الخطية ولكن من ناقلات أساس جديد -1 أضعاف المكان الذي تهبط فيه القبعة + مرتين المكان الذي يوجد فيه j-hat.",
  "n_reviews": 0,
  "start": 381.68,
  "end": 394.32
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with 1s down the diagonal.",
  "translatedText": "الطريقة الشائعة لكتابة هذا الرجل هي تحليل لامدا وكتابتها كـ لامدا في i، حيث i هي مصفوفة الهوية مع 1s أسفل القطر.",
  "model": "google_nmt",
  "from_community_srt": "فماذا تفعل هذه المصفوفة غيرت مفهومنا الخاطئ لما جينيفر يعني في المتجه الفعلي الذي تشير إليه إلى.",
  "n_reviews": 0,
  "start": 396.18,
  "end": 404.86
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "translatedText": "بما أن كلا الطرفين يشبهان ضرب المصفوفة والمتجه، فيمكننا طرح الجانب الأيمن وإخراج عامل v.",
  "model": "google_nmt",
  "from_community_srt": "أتذكر أنني عندما كنت أتعلم لأول مرة هذه لقد شعرت دائما بالوراء. هندسيا ، هذه المصفوفة يحول لدينا الشبكة في شبكة جنيفر.",
  "n_reviews": 0,
  "start": 405.86,
  "end": 411.86
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix times v gives the zero vector.",
  "translatedText": "إذًا ما لدينا الآن هو مصفوفة جديدة، A ناقص لامدا مضروبًا في الهوية، ونحن نبحث عن متجه v بحيث تعطي هذه المصفوفة الجديدة مضروبًا في v المتجه صفرًا.",
  "model": "google_nmt",
  "from_community_srt": "لكن من الناحية العددية ، إنها تترجم المتجه موصوفة بلغتها إلى لغتنا. ما الذي جعله ينقر في النهاية بالنسبة لي كان يفكر في كيف يأخذ الفهم الخاطئ لدينا مما تعنيه جينيفر",
  "n_reviews": 0,
  "start": 414.16,
  "end": 424.92
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "translatedText": "الآن، سيكون هذا صحيحًا دائمًا إذا كان v نفسه هو المتجه الصفري، لكن هذا ممل.",
  "model": "google_nmt",
  "from_community_srt": "المتجه نحصل على نفس الإحداثيات لكن في نظامنا ثم يحوله إلى المتجه ذلك انها تعني حقا.",
  "n_reviews": 0,
  "start": 426.38,
  "end": 431.1
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "translatedText": "ما نريده هو متجه ذاتي غير صفري.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 431.34,
  "end": 433.64
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "translatedText": "وإذا شاهدت الفصلين 5 و6، ستعرف أن الطريقة الوحيدة التي يمكن أن يصبح بها حاصل ضرب مصفوفة ذات متجه غير صفري صفرًا هي أن يؤدي التحويل المرتبط بتلك المصفوفة إلى سحق الفضاء إلى بُعد أقل.",
  "model": "google_nmt",
  "from_community_srt": "ماذا عن الذهاب في الاتجاه الآخر؟ في المثال ، استخدمت هذا الفيديو سابقًا عندما يكون لدي متجه مع الإحداثيات [3 ، 2] في نظامنا",
  "n_reviews": 0,
  "start": 434.42,
  "end": 448.02
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "translatedText": "وهذا السحق يتوافق مع المحدد الصفري للمصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "كيف أحسب أنه سيكون لديه الإحداثيات [5/3، 1/3] في نظام جنيفر؟ عليك أن تبدأ مع هذا التغيير من مصفوفة الأساس",
  "n_reviews": 0,
  "start": 449.3,
  "end": 454.22
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "translatedText": "لنكون واقعيين، لنفترض أن المصفوفة A تحتوي على أعمدة 2، 1 و2، 3، وفكر في طرح مبلغ متغير، لامدا، من كل مدخل قطري.",
  "model": "google_nmt",
  "from_community_srt": "يترجم لغة جينيفر إلى لغتنا ثم تأخذ معكوسها. تذكر ، معكوس التحول هو تحول جديد يتوافق مع لعب ذلك أول واحد إلى الوراء.",
  "n_reviews": 0,
  "start": 455.48,
  "end": 465.52
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "translatedText": "الآن تخيل التغيير والتبديل في لامدا، وتدوير المقبض لتغيير قيمته.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 466.48,
  "end": 470.28
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "translatedText": "ومع تغير قيمة لامدا، تتغير المصفوفة نفسها، وبالتالي يتغير محدد المصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "في الواقع ، خاصة عندما تعمل في أكثر من بعدين كنت تستخدم جهاز كمبيوتر لحساب المصفوفة هذا يمثل هذا العكس.",
  "n_reviews": 0,
  "start": 470.94,
  "end": 477.24
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "translatedText": "الهدف هنا هو العثور على قيمة لامدا التي تجعل هذا المحدد صفرًا، مما يعني أن التحويل المعدل يسحق الفضاء إلى بُعد أقل.",
  "model": "google_nmt",
  "from_community_srt": "في هذه الحالة ، معكوس التغيير أساس الأساس لديها أساس جنيفر كأعمدة لها ينتهي بالعمل على وجود أعمدة [1/3 ، -1/3] و [1/3 ، 2/3]",
  "n_reviews": 0,
  "start": 478.22,
  "end": 487.24
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "translatedText": "في هذه الحالة، تأتي النقطة المثالية عندما تساوي لامدا 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 488.16,
  "end": 491.16
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "translatedText": "بالطبع، إذا اخترنا مصفوفة أخرى، فقد لا تكون القيمة الذاتية بالضرورة 1.",
  "model": "google_nmt",
  "from_community_srt": "هكذا ، على سبيل المثال لمعرفة ما يبدو عليه المتجه [3 ، 2] نظام جنيفر نضرب هذا التغيير العكسي لمصفوفة الأساس من قبل المتجه [3 ، 2]",
  "n_reviews": 0,
  "start": 492.18,
  "end": 496.12
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "translatedText": "قد يتم ضرب النقطة الحلوة بقيمة أخرى من لامدا.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 496.24,
  "end": 498.6
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "translatedText": "إذن هذا كثير نوعًا ما، لكن دعونا نكشف ما يقوله هذا.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 500.08,
  "end": 502.96
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "translatedText": "عندما تساوي لامدا 1، فإن المصفوفة A ناقص لامدا مضروبة في الهوية تسحق المساحة على الخط.",
  "model": "google_nmt",
  "from_community_srt": "الذي يعمل ليكون [5/3 ، 1/3] لذلك ، باختصار هو كيفية ترجمة وصف الفرد ثلاثة أبعاد ذهابا وإيابا بين أنظمة الإحداثيات.",
  "n_reviews": 0,
  "start": 502.96,
  "end": 509.56
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "translatedText": "هذا يعني أن هناك متجهًا غير صفري v بحيث يكون A ناقص lambda مضروبًا في الهوية مضروبًا في v يساوي المتجه الصفري.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 510.44,
  "end": 518.56
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "translatedText": "وتذكر أن سبب اهتمامنا بهذا هو أنه يعني A في v يساوي lambda في v، وهو ما يمكنك قراءته كقول إن المتجه v هو متجه ذاتي لـ A، ويظل في امتداده الخاص أثناء التحويل A.",
  "model": "google_nmt",
  "from_community_srt": "المصفوفة التي تمثل الأعمدة جينيفر ناقلات الأساس لكن مكتوب في إحداثياتنا يترجم نواقل من لغتها إلى لغتنا. والمصفوفة العكسية تفعل العكس. لكن المتجهات ليست الشيء الوحيد الذي نحن وصف باستخدام الاحداثيات.",
  "n_reviews": 0,
  "start": 520.48,
  "end": 537.28
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "translatedText": "في هذا المثال، القيمة الذاتية المقابلة هي 1، لذا فإن v ستبقى ثابتة في مكانها.",
  "model": "google_nmt",
  "from_community_srt": "لهذا الجزء التالي من المهم أن تكون مرتاحًا تمثل التحولات مع المصفوفات وأنك تعرف كيف الضرب المصفوفة",
  "n_reviews": 0,
  "start": 538.32,
  "end": 544.02
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "translatedText": "توقف مؤقتًا وتأمل إذا كنت تريد التأكد من أن هذا النوع من التفكير يبدو جيدًا.",
  "model": "google_nmt",
  "from_community_srt": "يتوافق مع تأليف التحولات المتتالية.",
  "n_reviews": 0,
  "start": 546.22,
  "end": 549.5
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "translatedText": "وهذا هو النوع الذي ذكرته في المقدمة.",
  "model": "google_nmt",
  "from_community_srt": "وقفة بالتأكيد وإلقاء نظرة على الفصول 3 و 4 إذا كان أي من ذلك يشعر بعدم الارتياح.",
  "n_reviews": 0,
  "start": 553.38,
  "end": 555.64
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "translatedText": "إذا لم يكن لديك فهم قوي للمحددات وسبب ارتباطها بأنظمة المعادلات الخطية التي لها حلول غير صفرية، فإن تعبيرًا مثل هذا سيبدو غريبًا تمامًا.",
  "model": "google_nmt",
  "from_community_srt": "خذ بعين الاعتبار بعض التحولات الخطية مثل دوران بمقدار 90 درجة عكس عقارب الساعة. عندما كنت وأنا نمثل هذا مع المصفوفة نتابع حيث المتجهات أساس i-hat و ي-ك كل ذهاب.",
  "n_reviews": 0,
  "start": 556.22,
  "end": 566.3
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "translatedText": "لرؤية ذلك عمليًا، دعنا نعيد النظر في المثال من البداية، مع مصفوفة أعمدتها هي 3، 0 و1، 2.",
  "model": "google_nmt",
  "from_community_srt": "أنا قبعة ينتهي في الحال مع الإحداثيات [0 ، 1] و j-hat في نهاية المطاف مع إحداثيات [- 1 - 0]",
  "n_reviews": 0,
  "start": 568.32,
  "end": 574.54
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "translatedText": "لمعرفة ما إذا كانت قيمة لامدا هي قيمة ذاتية، اطرحها من أقطار هذه المصفوفة واحسب المحدد.",
  "model": "google_nmt",
  "from_community_srt": "بحيث تصبح تلك الإحداثيات أعمدة لدينا المصفوفة لكن هذا التمثيل ترتبط بشدة في اختيارنا من الأساس ثلاثة أبعاد",
  "n_reviews": 0,
  "start": 575.35,
  "end": 583.4
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "translatedText": "عند القيام بذلك، نحصل على كثيرة حدود تربيعية معينة في لامدا، 3 ناقص لامدا في 2 ناقص لامدا.",
  "model": "google_nmt",
  "from_community_srt": "من حقيقة أننا نتبع i-hat و ي-قبعة في المقام الأول إلى حقيقة أننا نسجل هبوطهم بقع في نظام الإحداثيات الخاص بنا.",
  "n_reviews": 0,
  "start": 590.58,
  "end": 596.72
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "translatedText": "نظرًا لأن لامدا لا يمكن أن تكون قيمة ذاتية إلا إذا كان هذا المحدد صفرًا، فيمكنك استنتاج أن القيم الذاتية الوحيدة الممكنة هي لامدا تساوي 2 ولامدا تساوي 3.",
  "model": "google_nmt",
  "from_community_srt": "كيف تصف جينيفر هذا الدوران 90 درجة نفسه من الفضاء؟ قد يميل إلى مجرد ترجم أعمدة مصفوفة الدوران الخاصة بنا في لغة جنيفر. لكن هذا ليس صحيحًا تمامًا.",
  "n_reviews": 0,
  "start": 597.8,
  "end": 608.84
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "translatedText": "لمعرفة المتجهات الذاتية التي لها بالفعل إحدى هذه القيم الذاتية، لنفترض أن لامدا تساوي 2، قم بتوصيل قيمة لامدا هذه إلى المصفوفة ثم حدد المتجهات التي ترسلها هذه المصفوفة المعدلة قطريًا إلى الصفر.",
  "model": "google_nmt",
  "from_community_srt": "تمثل تلك الأعمدة أين متجهنا الأساسي أنا قبعة وجي هات. لكن المصفوفة التي تريدها جنيفر يجب أن تمثل حيث نواقل أساسها الأرض وتحتاج إلى وصف تلك النقاط الهبوط في لغتها. إليك طريقة شائعة للتفكير في كيفية حدوث ذلك فعله.",
  "n_reviews": 0,
  "start": 609.64,
  "end": 623.9
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "translatedText": "إذا قمت بحساب ذلك بنفس الطريقة التي تقوم بها بأي نظام خطي آخر، فسترى أن الحلول هي جميع المتجهات على الخط القطري الممتد بسالب 1، 1.",
  "model": "google_nmt",
  "from_community_srt": "تبدأ مع أي ناقلات مكتوبة في جنيفر لغة. بدلا من محاولة متابعة ما يحدث لها من حيث لغتها أولا ، سنقوم بترجمته إلى موقعنا لغة باستخدام تغيير مصفوفة الأساس",
  "n_reviews": 0,
  "start": 624.94,
  "end": 634.3
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "translatedText": "وهذا يتوافق مع حقيقة أن المصفوفة غير المعدلة، 3، 0، 1، 2، لها تأثير على تمديد كل تلك المتجهات بعامل 2.",
  "model": "google_nmt",
  "from_community_srt": "الشخص الذي تمثل أعمدته أساسًا المتجهات في لغتنا. هذا يعطينا نفس المتجه لكن الآن مكتوبة بلغتنا.",
  "n_reviews": 0,
  "start": 635.22,
  "end": 643.46
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "translatedText": "الآن، ليس من الضروري أن يحتوي التحويل ثنائي الأبعاد على متجهات ذاتية.",
  "model": "google_nmt",
  "from_community_srt": "ثم ، تطبيق مصفوفة التحويل على ما لقد حصلت بضربه على اليسار.",
  "n_reviews": 0,
  "start": 646.32,
  "end": 650.2
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "translatedText": "على سبيل المثال، النظر في دوران بمقدار 90 درجة.",
  "model": "google_nmt",
  "from_community_srt": "هذا يخبرنا أين المتجهات الأراضي ولكن لا يزال في لغتنا.",
  "n_reviews": 0,
  "start": 650.72,
  "end": 653.4
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "translatedText": "لا يحتوي هذا على أي متجهات ذاتية لأنه يقوم بتدوير كل متجه خارج نطاقه.",
  "model": "google_nmt",
  "from_community_srt": "كخطوة أخيرة تطبيق التغيير العكسي لمصفوفة الأساس مضروبة على اليسار كالمعتاد للحصول على ناقل متحول",
  "n_reviews": 0,
  "start": 653.66,
  "end": 658.2
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "translatedText": "إذا حاولت بالفعل حساب القيم الذاتية لدورة كهذه، لاحظ ما يحدث.",
  "model": "google_nmt",
  "from_community_srt": "لكن الآن في لغة جنيفر.",
  "n_reviews": 0,
  "start": 660.8,
  "end": 665.56
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "translatedText": "تحتوي المصفوفة على أعمدة 0، 1 وسالب 1، 0.",
  "model": "google_nmt",
  "from_community_srt": "بما أننا يمكن أن نفعل هذا مع أي متجه مكتوب بلغتها أولا ، تطبيق تغيير الأساس ثم التحول ثم ، وتغير معكوس من الأساس",
  "n_reviews": 0,
  "start": 666.3,
  "end": 670.14
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "translatedText": "اطرح لامدا من العناصر القطرية وابحث عن الوقت الذي يكون فيه المحدد صفرًا.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 671.1,
  "end": 675.8
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "translatedText": "في هذه الحالة، تحصل على كثيرة الحدود لامدا تربيع زائد 1.",
  "model": "google_nmt",
  "from_community_srt": "هذا التكوين من ثلاث المصفوفات يعطينا مصفوفة التحويل في جنيفر لغة.",
  "n_reviews": 0,
  "start": 678.14,
  "end": 681.94
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "translatedText": "الجذور الوحيدة لذلك كثير الحدود هي الأعداد التخيلية، i والسالب i.",
  "model": "google_nmt",
  "from_community_srt": "يأخذ في متجه من لغتها وتبصق النسخة المحولة لذلك متجه بلغتها لهذا المثال بالتحديد عندما تبدو متجهات جينيفر الأساسية مثل [2 ، 1] و [-1 ، 1] بلغتنا",
  "n_reviews": 0,
  "start": 682.68,
  "end": 687.92
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "translatedText": "تشير حقيقة عدم وجود حلول للأعداد الحقيقية إلى عدم وجود متجهات ذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 688.84,
  "end": 693.6
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "translatedText": "مثال آخر مثير للاهتمام يستحق الاحتفاظ به في الجزء الخلفي من عقلك هو القص.",
  "model": "google_nmt",
  "from_community_srt": "وعندما يكون التحول دوران 90 درجة نتاج هذه المصفوفات الثلاثة إذا كنت تعمل من خلال ذلك يحتوي على أعمدة [1/3 ، 5/3] و [-2 / 3 ، -1/3]",
  "n_reviews": 0,
  "start": 695.54,
  "end": 699.82
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "translatedText": "يؤدي هذا إلى تثبيت i-hat في مكانه وتحريك j-hat 1، بحيث تحتوي المصفوفة على أعمدة 1 و0 و1 و1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 700.56,
  "end": 707.84
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "translatedText": "جميع المتجهات الموجودة على المحور السيني هي متجهات ذاتية ذات قيمة ذاتية 1 لأنها تظل ثابتة في مكانها.",
  "model": "google_nmt",
  "from_community_srt": "لذلك إذا ضربت جنيفر تلك المصفوفة من إحداثيات ناقل في نظامها فإنه يعود 90 درجة استدارة من هذا المتجه",
  "n_reviews": 0,
  "start": 708.74,
  "end": 714.54
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "translatedText": "في الواقع، هذه هي المتجهات الذاتية الوحيدة.",
  "model": "google_nmt",
  "from_community_srt": "أعرب في نظام الإحداثيات الخاص بها.",
  "n_reviews": 0,
  "start": 715.68,
  "end": 717.82
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "translatedText": "عندما تطرح لامدا من الأقطار وتحسب المحدد، فإن ما تحصل عليه هو 1 ناقص لامدا تربيع.",
  "model": "google_nmt",
  "from_community_srt": "بشكل عام ، عندما ترى تعبيرًا مثل A ^ (- 1) MA يقترح نوعا رياضيا من التعاطف.",
  "n_reviews": 0,
  "start": 718.76,
  "end": 726.54
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "translatedText": "والجذر الوحيد لهذا التعبير هو لامدا يساوي 1.",
  "model": "google_nmt",
  "from_community_srt": "تمثل تلك المصفوفة الوسطى تحولًا من نوع ما ، كما ترونه والمصفوفات الخارجية تمثل التعاطف ، التحول في المنظور",
  "n_reviews": 0,
  "start": 729.32,
  "end": 732.86
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "translatedText": "وهذا يتماشى مع ما نراه هندسيًا، وهو أن جميع المتجهات الذاتية لها قيمة ذاتية 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 734.56,
  "end": 739.72
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "translatedText": "مع ذلك، ضع في اعتبارك أنه من الممكن أيضًا أن يكون لديك قيمة ذاتية واحدة فقط، ولكن مع أكثر من مجرد سطر مليء بالمتجهات الذاتية.",
  "model": "google_nmt",
  "from_community_srt": "ومنتج المصفوفة الكامل يمثل ذلك نفس التحول ولكن كما يراه شخص آخر. لأولئك من أنت تتساءل لماذا نهتم أنظمة إحداثيات بديلة الفيديو التالي على ناقلات eigen و eigen القيم",
  "n_reviews": 0,
  "start": 741.08,
  "end": 748.02
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "translatedText": "مثال بسيط هو المصفوفة التي تقيس كل شيء بمقدار 2.",
  "model": "google_nmt",
  "from_community_srt": "سوف يعطي مثالا هاما حقا من هذا.",
  "n_reviews": 0,
  "start": 749.9,
  "end": 753.18
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "translatedText": "القيمة الذاتية الوحيدة هي 2، لكن كل متجه في المستوى يجب أن يكون متجهًا ذاتيًا بهذه القيمة الذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 753.9,
  "end": 760.7
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "translatedText": "الآن هو وقت مناسب آخر للتوقف والتأمل في بعض هذه الأمور قبل أن أنتقل إلى الموضوع الأخير.",
  "model": "google_nmt",
  "from_community_srt": "اراك لاحقا!",
  "n_reviews": 0,
  "start": 762.0,
  "end": 766.96
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "translatedText": "أريد أن أنهي هنا بفكرة الأساس الذاتي، الذي يعتمد بشكل كبير على أفكار من الفيديو الأخير.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 783.54,
  "end": 789.88
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "translatedText": "ألقِ نظرة على ما يحدث إذا كانت المتجهات الأساسية هي متجهات ذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.48,
  "end": 796.38
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2.",
  "translatedText": "على سبيل المثال، ربما يتم تحجيم i-hat بمقدار سالب 1 ويتم تحجيم j-hat بمقدار 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 797.12,
  "end": 802.38
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "translatedText": "عند كتابة إحداثياتهم الجديدة كأعمدة مصفوفة، لاحظ أن تلك المضاعفات العددية، سالب 1 و2، وهي القيم الذاتية لـ i-hat وj-hat، تقع على قطري المصفوفة، وكل إدخال آخر هو 0 .",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 803.42,
  "end": 817.18
 },
 {
  "input": "Any time a matrix has zeros everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix.",
  "translatedText": "في أي وقت تحتوي المصفوفة على أصفار في كل مكان غير القطر، يطلق عليها، بشكل معقول، مصفوفة قطرية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 818.88,
  "end": 825.42
 },
 {
  "input": "And the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "translatedText": "وطريقة تفسير ذلك هي أن جميع المتجهات الأساسية هي متجهات ذاتية، والمدخلات القطرية لهذه المصفوفة هي قيمها الذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 825.84,
  "end": 834.4
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "translatedText": "هناك الكثير من الأشياء التي تجعل التعامل مع المصفوفات القطرية أفضل بكثير.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 837.1,
  "end": 841.06
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "translatedText": "أحد أهمها هو أنه من الأسهل حساب ما سيحدث إذا قمت بضرب هذه المصفوفة في نفسها عدة مرات.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 841.78,
  "end": 848.34
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "translatedText": "نظرًا لأن كل ما تفعله إحدى هذه المصفوفات هو قياس كل متجه أساسي بواسطة بعض القيمة الذاتية، فإن تطبيق هذه المصفوفة عدة مرات، على سبيل المثال 100 مرة، سيتوافق فقط مع قياس كل متجه أساسي بمقدار الأس 100 من القيمة الذاتية المقابلة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 849.42,
  "end": 864.6
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "translatedText": "في المقابل، حاول حساب القوة المائة لمصفوفة غير قطرية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 865.7,
  "end": 869.68
 },
 {
  "input": "Really, try it for a moment.",
  "translatedText": "حقا، حاول ذلك للحظة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 869.68,
  "end": 871.32
 },
 {
  "input": "It's a nightmare.",
  "translatedText": "انه كابوس.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 871.74,
  "end": 872.44
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "translatedText": "بالطبع، نادرًا ما تكون محظوظًا لأن تكون المتجهات الأساسية الخاصة بك هي أيضًا متجهات ذاتية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 876.08,
  "end": 881.26
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "translatedText": "لكن إذا كان تحويلك يحتوي على الكثير من المتجهات الذاتية، مثل تلك الموجودة في بداية هذا الفيديو، بما يكفي بحيث يمكنك اختيار مجموعة تغطي المساحة الكاملة، فيمكنك تغيير نظام الإحداثيات الخاص بك بحيث تكون هذه المتجهات الذاتية هي المتجهات الأساسية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 882.04,
  "end": 896.54
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "translatedText": "لقد تحدثت عن تغيير الأساس في الفيديو الأخير، ولكنني سأقوم بتذكير سريع جدًا هنا بكيفية التعبير عن التحويل المكتوب حاليًا في نظامنا الإحداثي إلى نظام مختلف.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 897.14,
  "end": 907.04
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "translatedText": "خذ إحداثيات المتجهات التي تريد استخدامها كأساس جديد، وهو ما يعني في هذه الحالة المتجهات الذاتية لدينا، ثم اجعل تلك الإحداثيات أعمدة مصفوفة، تُعرف باسم مصفوفة تغيير الأساس.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 908.44,
  "end": 919.44
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "translatedText": "عندما تقوم بحصر التحويل الأصلي، واضعًا تغيير مصفوفة الأساس على يمينه ومعكوس تغيير مصفوفة الأساس على يساره، ستكون النتيجة مصفوفة تمثل نفس التحويل، ولكن من منظور متجهات الأساس الجديدة تنسق نظام.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 920.18,
  "end": 936.5
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "translatedText": "بيت القصيد من القيام بذلك مع المتجهات الذاتية هو أن هذه المصفوفة الجديدة مضمونة أن تكون قطرية مع قيمها الذاتية المقابلة أسفل هذا القطر.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 937.44,
  "end": 946.68
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "translatedText": "وذلك لأنه يمثل العمل في نظام إحداثي حيث ما يحدث للمتجهات الأساسية هو أنه يتم قياسها أثناء التحويل.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 946.86,
  "end": 954.32
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "translatedText": "مجموعة من المتجهات الأساسية والتي هي أيضًا متجهات ذاتية تسمى، مرة أخرى، بشكل معقول، الأساس الذاتي.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 955.8,
  "end": 961.56
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "translatedText": "لذا، على سبيل المثال، إذا كنت بحاجة إلى حساب القوة رقم 100 لهذه المصفوفة، فسيكون من الأسهل كثيرًا التحويل إلى الأساس الذاتي، وحساب القوة رقم 100 في هذا النظام، ثم التحويل مرة أخرى إلى نظامنا القياسي.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 962.34,
  "end": 975.68
 },
 {
  "input": "You can't do this with all transformations.",
  "translatedText": "لا يمكنك القيام بذلك مع كل التحولات.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 976.62,
  "end": 978.32
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "translatedText": "القص، على سبيل المثال، لا يحتوي على ما يكفي من المتجهات الذاتية لتغطية المساحة الكاملة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 978.32,
  "end": 982.98
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "translatedText": "ولكن إذا تمكنت من العثور على الأساس الذاتي، فهذا يجعل عمليات المصفوفة رائعة حقًا.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 983.46,
  "end": 988.16
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "translatedText": "لأولئك منكم الذين يرغبون في حل لغز أنيق جدًا لمعرفة كيف يبدو هذا أثناء العمل وكيف يمكن استخدامه لتحقيق بعض النتائج المدهشة، سأترك مطالبة هنا على الشاشة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 989.12,
  "end": 997.32
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "translatedText": "يستغرق الأمر القليل من العمل، ولكن أعتقد أنك ستستمتع به.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 997.6,
  "end": 1000.28
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "translatedText": "الفيديو التالي والأخير من هذه السلسلة سيكون عن المساحات المتجهة المجردة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 1000.84,
  "end": 1006.12
 }
]