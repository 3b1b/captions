[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "translatedText": "Vlastní vektory a vlastní hodnoty jsou jedním z těch témat, která jsou pro mnoho studentů obzvláště neintuitivní.",
  "model": "DeepL",
  "from_community_srt": "Matematika je umění dát jedno jméno různým věcem. -- Henri Poincaré Vektory umíme popisovat standardním způsobem pomocí souřadnic. V tomhle případě má vektor souřadnice (3, 2), což znamená, že abychom se dostali od začátku na špičku, musíme popojít 3 políčka doprava a 2 políčka nahoru.",
  "n_reviews": 0,
  "start": 19.92,
  "end": 25.76
 },
 {
  "input": "Questions like, why are we doing this and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "translatedText": "Otázky typu, proč to děláme a co to vlastně znamená, zůstávají příliš často jen tak plout v moři výpočtů bez odpovědi.",
  "model": "DeepL",
  "from_community_srt": "Pak jsme se naučili více lineárně-algebraický pohled na souřadnice, na každou z nich se díváme jako na skalár,",
  "n_reviews": 0,
  "start": 25.76,
  "end": 33.26
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "translatedText": "A jak jsem zveřejňoval videa z této série, mnoho z vás se vyjádřilo, že se těšíte zejména na vizualizaci tohoto tématu.",
  "model": "DeepL",
  "from_community_srt": "který roztahuje či smršťuje bázové vektory.",
  "n_reviews": 0,
  "start": 33.92,
  "end": 40.06
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "translatedText": "Domnívám se, že důvodem není ani tak to, že by eigenthings byly obzvláště komplikované nebo špatně vysvětlené.",
  "model": "DeepL",
  "from_community_srt": "Můžeme si první souřadnici představit jako škálování 'i', to je jednotkový vektor ukazující doprava,",
  "n_reviews": 0,
  "start": 40.68,
  "end": 46.36
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "translatedText": "Ve skutečnosti je to poměrně jednoduché a myslím, že většina knih to dobře vysvětluje.",
  "model": "DeepL",
  "from_community_srt": "a druhou souřadnici jako škálování 'j', to je jednotkový vektor ukazující nahoru. Pak provedeme součet tím,",
  "n_reviews": 0,
  "start": 46.86,
  "end": 51.18
 },
 {
  "input": "The issue is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "translatedText": "Problémem je, že má smysl pouze tehdy, pokud máte solidní vizuální představu o mnoha tématech, která mu předcházejí.",
  "model": "DeepL",
  "from_community_srt": "že vektory položíme za sebe, a získáme vektor popsaný souřadnicemi (3, 2) Tyto dva speciální vektory, 'i',",
  "n_reviews": 0,
  "start": 51.52,
  "end": 58.48
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "translatedText": "Nejdůležitější je, abyste věděli, jak uvažovat o maticích jako o lineárních transformacích, ale také abyste se dobře orientovali v takových věcech, jako jsou determinanty, lineární soustavy rovnic a změna báze.",
  "model": "DeepL",
  "from_community_srt": "'j' zahrnují všechny naše představy o správném souřadnicovém systému. První číslo značí pohyb doprava, druhé číslo značí pohyb nahoru, měříme podle souřadnic jednotky a vzdálenosti.",
  "n_reviews": 0,
  "start": 59.06,
  "end": 69.94
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "translatedText": "Zmatek ohledně vlastních čísel obvykle souvisí spíše s nejistým základem v některém z těchto témat než se samotnými vlastními vektory a vlastními čísly.",
  "model": "DeepL",
  "from_community_srt": "To vše je spjato s volbou 'i' a 'j' coby těch vektorů, které se při čtení souřadnic mají škálovat.",
  "n_reviews": 0,
  "start": 70.72,
  "end": 79.24
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "translatedText": "Pro začátek uvažujte nějakou lineární transformaci ve dvou rozměrech, jako je ta, která je znázorněna zde.",
  "model": "DeepL",
  "from_community_srt": "Obecně se jakýkoli překlad mezi vektory a n-ticemi čísel nazývá souřadnicový systém a ty dva speciální vektory 'i' a 'j' se nazývají bázové vektory",
  "n_reviews": 0,
  "start": 79.98,
  "end": 84.84
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "translatedText": "Přesune bázový vektor i-hat na souřadnice 3, 0 a j-hat na 1, 2.",
  "model": "DeepL",
  "from_community_srt": "našeho standardního souřadnicového systému.",
  "n_reviews": 0,
  "start": 85.46,
  "end": 91.04
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "translatedText": "Je tedy reprezentován maticí, jejíž sloupce jsou 3, 0 a 1, 2.",
  "model": "DeepL",
  "from_community_srt": "Teď se chci podívat na to, co se stane, když použijeme jinou sadu bázových vektorů.",
  "n_reviews": 0,
  "start": 91.78,
  "end": 95.64
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "translatedText": "Zaměřte se na to, co to udělá s jedním konkrétním vektorem, a přemýšlejte o rozpětí tohoto vektoru, o přímce procházející jeho počátkem a vrcholem.",
  "model": "DeepL",
  "from_community_srt": "Dejme tomu, že máme kamarádku Žanetu, která používá jinou sadu bázových vektorů. Označme je 'b1' a 'b2'.",
  "n_reviews": 0,
  "start": 96.6,
  "end": 104.16
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "translatedText": "Většina vektorů se během transformace vyřadí ze svého rozpětí.",
  "model": "DeepL",
  "from_community_srt": "Její první bázový vektor, 'b1' ukazuje doprava a trochu nahoru, a její druhý bázový vektor,",
  "n_reviews": 0,
  "start": 104.92,
  "end": 108.38
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "translatedText": "Zdálo by se, že je to docela náhoda, kdyby se místo, kam vektor dopadl, nacházelo také někde na této linii.",
  "model": "DeepL",
  "from_community_srt": "'b2', ukazuje doleva nahoru. Teď se vrátíme k tomu vektoru, který jsem ukazoval před chvílí.",
  "n_reviews": 0,
  "start": 108.78,
  "end": 115.32
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "translatedText": "Některé speciální vektory však zůstávají ve svém vlastním rozpětí, což znamená, že vliv matice na takový vektor je pouze jeho roztažení nebo zmačkání, podobně jako u skaláru.",
  "model": "DeepL",
  "from_community_srt": "My jej nazýváme vektorem se souřadnicemi (3, 2) na základě bázových vektorů 'i' a 'j'. Žaneta by ale ten samý vektor popsala jako (5/3, 1/3). To znamená,",
  "n_reviews": 0,
  "start": 117.4,
  "end": 127.04
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "translatedText": "Pro tento konkrétní příklad je jedním z takových speciálních vektorů bázový vektor i-hat.",
  "model": "DeepL",
  "from_community_srt": "že tenhle vektor složíme z jejích bázových vektorů tak, že vyškálujeme 'b1' pěti třetinami,",
  "n_reviews": 0,
  "start": 129.46,
  "end": 134.1
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "translatedText": "Rozpětí i-hat je osa x a z prvního sloupce matice vidíme, že i-hat se přesune na trojnásobek sebe sama, stále na ose x.",
  "model": "DeepL",
  "from_community_srt": "dále vyškálujeme 'b2' jednou třetinou a výsledky sečtem. Za chvíli se dostanu k tomu, jak jsem našel čísla 5/3 a 1/3.",
  "n_reviews": 0,
  "start": 134.64,
  "end": 144.12
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "translatedText": "Navíc, vzhledem k tomu, jak fungují lineární transformace, je jakýkoli jiný vektor na ose x také pouze protažen o faktor 3, a zůstává tedy na svém vlastním rozpětí.",
  "model": "DeepL",
  "from_community_srt": "Kdykoli Žaneta popisuje nějaký vektor pomocí souřadnic, dívá se na první souřadnici jako na škálování 'b1', na druhou souřadnici jako na škálování 'b2' a výsledky sečte.",
  "n_reviews": 0,
  "start": 146.32,
  "end": 156.48
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "translatedText": "Poněkud záludnější vektor, který při této transformaci zůstává na svém vlastním rozpětí, je záporný 1, 1.",
  "model": "DeepL",
  "from_community_srt": "Vyjde jí typický něco úplně jiného, než co si pod danými souřadnicemi představujeme my.",
  "n_reviews": 0,
  "start": 158.5,
  "end": 164.04
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "translatedText": "Nakonec se protáhne na dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "Abychom si naší situaci zpřesnili,",
  "n_reviews": 0,
  "start": 164.66,
  "end": 167.14
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "translatedText": "A opět, linearita bude znamenat, že jakýkoli jiný vektor na úhlopříčce, kterou tento chlapík prochází, se prostě protáhne o dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "dejme tomu, že její první bázový vektor 'b1' je něco, co bychom my popsali jako (2, 1) a její druhý bázový vektor 'b2' je něco, co my vidíme jako (-1,",
  "n_reviews": 0,
  "start": 169.0,
  "end": 178.22
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "translatedText": "A pro tuto transformaci jsou to všechny vektory, které mají tuto zvláštní vlastnost, že zůstávají na svém rozpětí.",
  "model": "DeepL",
  "from_community_srt": "1). Ale je třeba mít na paměti, že z jejího pohledu mají tyto vektory souřadnice (1,",
  "n_reviews": 0,
  "start": 179.82,
  "end": 185.18
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "translatedText": "Ty na ose x se roztáhnou na trojnásobek a ty na této úhlopříčce se roztáhnou na dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "0) a (0, 1). Jsou to ty vektory, které pro ni definují souřadnicím (1, 0) a (0, 1) jejich význam.",
  "n_reviews": 0,
  "start": 185.62,
  "end": 191.98
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "translatedText": "Jakýkoli jiný vektor se při transformaci poněkud pootočí a vyřadí se z přímky, kterou prochází.",
  "model": "DeepL",
  "from_community_srt": "Takže ve výsledku mluví jiným jazykem.",
  "n_reviews": 0,
  "start": 192.76,
  "end": 198.08
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "translatedText": "Jak jste již možná uhodli, tyto speciální vektory se nazývají vlastní vektory transformace a ke každému vlastnímu vektoru je přiřazena tzv. vlastní hodnota, což je právě faktor, o který se během transformace roztáhne nebo smrskne.",
  "model": "DeepL",
  "from_community_srt": "Oba se díváme na ty samé vektory v rovině, ale Žaneta používá jiná slova na to, aby je popsala. Dovolím si ještě krátkou poznámku o tom, jak si vektory reprezentujeme my. Když animuji rovinu, většinou používám čtvercovou mřížku, ale tahle mřížka je jenom konstrukt, způsob, jak zobrazit náš souřadnicový systém, takže závisí na naší volbě báze.",
  "n_reviews": 0,
  "start": 202.52,
  "end": 217.38
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing, or the fact that these eigenvalues happen to be positive.",
  "translatedText": "Na roztahování a mačkání není samozřejmě nic zvláštního, stejně jako na tom, že tato vlastní čísla jsou kladná.",
  "model": "DeepL",
  "from_community_srt": "Samotná rovina v sobě zabudovanou mřížku nemá. Žaneta si může nakreslit svoji mřížku, která bude stejně tak umělý konstrukt jako ta naše,",
  "n_reviews": 0,
  "start": 220.28,
  "end": 225.94
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "translatedText": "V jiném příkladu můžete mít vlastní vektor s vlastní hodnotou zápornou o polovinu, což znamená, že se vektor převrátí a zmenší o polovinu.",
  "model": "DeepL",
  "from_community_srt": "tedy nic víc než grafická pomůcka, jak číst souřadnice vektorů z jejího pohledu.",
  "n_reviews": 0,
  "start": 226.38,
  "end": 235.12
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "translatedText": "Důležité však je, aby zůstal na čáře, kterou se rozprostírá, aniž by se z ní otáčel.",
  "model": "DeepL",
  "from_community_srt": "Ačkoli její počátek bude totožný s našim, protože se všichni shodnou na tom, že souřadnice (0, 0) by měly odpovídat tomu, co dostanete, když jakýkoli vektor vyškálujete nulou.",
  "n_reviews": 0,
  "start": 236.98,
  "end": 242.76
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "translatedText": "Pro představu, proč je užitečné o tom přemýšlet, si vezměte na pomoc trojrozměrnou rotaci.",
  "model": "DeepL",
  "from_community_srt": "Ale směry, kterými vedou její osy, nebo rozestupy mezi linkami mřížky se můžou lišit podle toho, jaké si zvolí bázové vektory.",
  "n_reviews": 0,
  "start": 244.46,
  "end": 249.8
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "translatedText": "Pokud najdete vlastní vektor pro toto natočení, tedy vektor, který zůstává na svém vlastním rozpětí, nalezli jste osu natočení.",
  "model": "DeepL",
  "from_community_srt": "V téhle situaci je docela přirozené se ptát: \"Jak se překládá mezi souřadnicovými systémy?\"",
  "n_reviews": 0,
  "start": 251.66,
  "end": 260.5
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3x3 matrix associated with that transformation.",
  "translatedText": "A je mnohem snazší uvažovat o 3D rotaci v podobě nějaké osy otáčení a úhlu, o který se otáčí, než přemýšlet o celé matici 3x3 spojené s touto transformací.",
  "model": "DeepL",
  "from_community_srt": "Když třeba Žaneta popíše vektor souřadnicemi (-1, 2), jak tenhle vektor vyjádříme v našich souřadnicích? Jak to přeložíme z jejího jazyka do našeho? Inu, její souřadnice říkají, že tento vektor je roven -1 b1 + 2 b2,",
  "n_reviews": 0,
  "start": 262.6,
  "end": 274.74
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "translatedText": "V tomto případě by mimochodem odpovídající vlastní číslo muselo být 1, protože rotace nikdy nic neroztahuje ani nemačká, takže délka vektoru by zůstala stejná.",
  "model": "DeepL",
  "from_community_srt": "Z našeho pohledu má 'b1' souřadnice (2,",
  "n_reviews": 0,
  "start": 277.0,
  "end": 285.86
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "translatedText": "Tento vzorec se často objevuje v lineární algebře.",
  "model": "DeepL",
  "from_community_srt": "1) a 'b2' má souřadnice (-1, 1).",
  "n_reviews": 0,
  "start": 288.08,
  "end": 290.02
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "translatedText": "U jakékoli lineární transformace popsané maticí můžete pochopit, co dělá, když sloupce této matice odečtete jako místa, kde přistávají bázové vektory.",
  "model": "DeepL",
  "from_community_srt": "Takže můžeme spočítat -1 b1 + 2 b2 v našem souřadnicovém systému.",
  "n_reviews": 0,
  "start": 290.44,
  "end": 299.4
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "translatedText": "Často je však lepším způsobem, jak se dostat k jádru toho, co lineární transformace skutečně dělá, méně závislým na konkrétním souřadnicovém systému, nalezení vlastních vektorů a vlastních hodnot.",
  "model": "DeepL",
  "from_community_srt": "Když to vyčíslíme, vyjde vektor se souřadnicemi (-4,1). Takže my bychom popsali vektor, který Žaneta vidí jako (-1, 2).",
  "n_reviews": 0,
  "start": 300.02,
  "end": 310.82
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "translatedText": "Nebudu se zde zabývat všemi podrobnostmi o metodách výpočtu vlastních vektorů a vlastních hodnot, ale pokusím se podat přehled výpočetních myšlenek, které jsou pro koncepční pochopení nejdůležitější.",
  "model": "DeepL",
  "from_community_srt": "Tenhle proces škálování každého bázového vektoru odpovídající souřadnicí nějakého vektoru a následné sečtení by vám mělo něco připomínat. Je to součin matice a vektoru, kde sloupečky matice jsou Žanetiny bázové vektory popsané naším jazykem.",
  "n_reviews": 0,
  "start": 315.46,
  "end": 326.02
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "translatedText": "Symbolicky vypadá představa vlastního vektoru takto.",
  "model": "DeepL",
  "from_community_srt": "A protože si násobení matice a vektoru představujeme jako provádění jistého lineárního zobrazení,",
  "n_reviews": 0,
  "start": 327.18,
  "end": 330.48
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "translatedText": "A je matice představující nějakou transformaci, přičemž v je vlastní vektor, a lambda je číslo, konkrétně příslušná vlastní hodnota.",
  "model": "DeepL",
  "from_community_srt": "tak, jak jsme si to ukázali v nejdůležitějším videu této série, kapitole 3, tak si to tak můžeme představit i v tomto případě. Matice přechodu,",
  "n_reviews": 0,
  "start": 331.04,
  "end": 339.74
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "translatedText": "Tento výraz říká, že maticový vektorový součin A krát v dává stejný výsledek jako pouhé škálování vlastního vektoru v nějakou hodnotou lambda.",
  "model": "DeepL",
  "from_community_srt": "jejíž sloupečky odpovídají Žanetiným bázovým vektorům se dá chápat jako transformace, která přesune naše bázové vektory 'i', 'j', ty, které my považujeme za (1,",
  "n_reviews": 0,
  "start": 340.68,
  "end": 349.9
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "translatedText": "Nalezení vlastních vektorů a jejich vlastních hodnot matice A tedy spočívá v nalezení takových hodnot v a lambda, aby tento výraz platil.",
  "model": "DeepL",
  "from_community_srt": "0) a (0, 1) na Žanetiny bázové vektory, ty, které ona považuje za (1, 0) a (0, 1) Abychom si to ukázali v praxi, zkusíme,",
  "n_reviews": 0,
  "start": 351.0,
  "end": 360.1
 },
 {
  "input": "It's a little awkward to work with at first, because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "translatedText": "Práce s ním je zpočátku trochu nepohodlná, protože levá strana představuje násobení matice a vektoru, ale pravá strana je skalárně-vektorové násobení.",
  "model": "DeepL",
  "from_community_srt": "co se stane, když si vezmeme ukázkový vektor, který má podle nás souřadnice (-1, 2): a provedeme tuto transformaci.",
  "n_reviews": 0,
  "start": 361.92,
  "end": 370.54
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "translatedText": "Začněme tedy přepisem této pravé strany jako určitého druhu maticově-vektorového násobení pomocí matice, která má za následek škálování libovolného vektoru koeficientem lambda.",
  "model": "DeepL",
  "from_community_srt": "Před transformací jsme se na vektor dívali jako na kombinaci našich bázových vektorů -1i+2j.",
  "n_reviews": 0,
  "start": 371.12,
  "end": 380.62
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "translatedText": "Sloupce takové matice budou představovat to, co se děje s každým bázovým vektorem, a každý bázový vektor se jednoduše vynásobí lambdou, takže tato matice bude mít na diagonále číslo lambda a všude jinde nuly.",
  "model": "DeepL",
  "from_community_srt": "Lineární transformace má tu klíčovou vlastnost, že výsledný vektor bude ta samá lineární kombinace, ale nových, bázových vektorů. -1 krát obraz 'i' plus 2 krát obraz 'j'.",
  "n_reviews": 0,
  "start": 381.68,
  "end": 394.32
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with 1s down the diagonal.",
  "translatedText": "Běžný způsob, jak ho zapsat, je vynásobit tuto lambdu a zapsat ji jako lambda krát i, kde i je identická matice s jedničkami na diagonále.",
  "model": "DeepL",
  "from_community_srt": "Takže matice přechodu dělá to, že mění naši mylnou představu toho, co má Žaneta na mysli, na skutečný vektor, který popisuje. Pamatuji si,",
  "n_reviews": 0,
  "start": 396.18,
  "end": 404.86
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "translatedText": "Protože obě strany vypadají jako násobení matice a vektoru, můžeme tuto pravou stranu odečíst a vynásobit v.",
  "model": "DeepL",
  "from_community_srt": "že když jsem se to učil, připadalo mi to vždycky nějak obráceně.",
  "n_reviews": 0,
  "start": 405.86,
  "end": 411.86
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix times v gives the zero vector.",
  "translatedText": "Nyní tedy máme novou matici A minus lambda krát identita a hledáme vektor v takový, že tato nová matice krát v dává nulový vektor.",
  "model": "DeepL",
  "from_community_srt": "Geometricky matice přechodu přesouvá naši mřížku na Žanetinu mřížku, ale numericky přecházíme z vektorů v jejím jazyce do našeho. Pomohlo mi až, když jsem si to představil,",
  "n_reviews": 0,
  "start": 414.16,
  "end": 424.92
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "translatedText": "To platí vždy, pokud je v nulovým vektorem, ale to je nuda.",
  "model": "DeepL",
  "from_community_srt": "že bere naši mylnou představu Žanetina vektoru vektor, který jsme napsali pomocí našeho souřadnicového systému, a promění ho na vektor,",
  "n_reviews": 0,
  "start": 426.38,
  "end": 431.1
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "translatedText": "To, co chceme, je nenulový vlastní vektor.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 431.34,
  "end": 433.64
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "translatedText": "A pokud se podíváte na kapitoly 5 a 6, dozvíte se, že jediný způsob, jak je možné, aby se součin matice s nenulovým vektorem stal nulovým, je ten, že transformace spojená s touto maticí zmačká prostor do nižší dimenze.",
  "model": "DeepL",
  "from_community_srt": "který měla opravdu na mysli. A co obráceně? Jak jsem třeba ukazoval vektor, který má v našem jazyce souřadnice (3, 2). Jak jsem spočítal, že to je (5/3,",
  "n_reviews": 0,
  "start": 434.42,
  "end": 448.02
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "translatedText": "A tato squishifikace odpovídá nulovému determinantu matice.",
  "model": "DeepL",
  "from_community_srt": "1/3) v Žanetiných souřadnicích? Začneme s opět s maticí přechodu,",
  "n_reviews": 0,
  "start": 449.3,
  "end": 454.22
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "translatedText": "Abychom byli konkrétní, řekněme, že vaše matice A má sloupce 2, 1 a 2, 3, a uvažujte o tom, že od každé diagonální položky odečtete proměnnou lambda.",
  "model": "DeepL",
  "from_community_srt": "která překládá z Žanetina jazyka do našeho, a spočteme její inverz. Připoměňme, že inverz dané transformace je transformace,",
  "n_reviews": 0,
  "start": 455.48,
  "end": 465.52
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "translatedText": "Nyní si představte, že lambdu upravujete otáčením knoflíku a měníte její hodnotu.",
  "model": "DeepL",
  "from_community_srt": "která odpovídá přehrání té dané transformace pozpátku. V praxi,",
  "n_reviews": 0,
  "start": 466.48,
  "end": 470.28
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "translatedText": "Se změnou hodnoty lambda se mění i samotná matice, a tím i její determinant.",
  "model": "DeepL",
  "from_community_srt": "obzvlášť, když pracujete ve více než dvou rozměrech, použijete pro výpočet inverzní matice počítač.",
  "n_reviews": 0,
  "start": 470.94,
  "end": 477.24
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "translatedText": "Cílem je najít takovou hodnotu lambda, aby tento determinant byl nulový, což znamená, že upravená transformace zmenší prostor na nižší dimenzi.",
  "model": "DeepL",
  "from_community_srt": "V tomhle případě inverzní matice k matici přechodu, která měla ve sloupcích Žanetinu bázi, vyjde se sloupci (1/3,",
  "n_reviews": 0,
  "start": 478.22,
  "end": 487.24
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "translatedText": "V tomto případě je nejvhodnějším bodem, když se lambda rovná 1.",
  "model": "DeepL",
  "from_community_srt": "-1/3), (1/3, 2/3).",
  "n_reviews": 0,
  "start": 488.16,
  "end": 491.16
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "translatedText": "Kdybychom zvolili nějakou jinou matici, vlastní číslo by samozřejmě nemuselo být 1.",
  "model": "DeepL",
  "from_community_srt": "Takže abychom například určili, jak vypadá vektor (3,",
  "n_reviews": 0,
  "start": 492.18,
  "end": 496.12
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "translatedText": "Sladký bod může být dosažen při jiné hodnotě lambda.",
  "model": "DeepL",
  "from_community_srt": "2) v Žanetiných souřadnicích, vynásobíme jej inverzní maticí přechodu,",
  "n_reviews": 0,
  "start": 496.24,
  "end": 498.6
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "translatedText": "Je toho trochu moc, ale pojďme si říct, co to znamená.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 500.08,
  "end": 502.96
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "translatedText": "Když je lambda rovna 1, matice A minus lambda krát identita rozmělní prostor na přímku.",
  "model": "DeepL",
  "from_community_srt": "to vyjde (5/3, 1/3).",
  "n_reviews": 0,
  "start": 502.96,
  "end": 509.56
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "translatedText": "To znamená, že existuje nenulový vektor v takový, že A minus lambda krát identita krát v se rovná nulovému vektoru.",
  "model": "DeepL",
  "from_community_srt": "Takže takhle se v kostce překládají popisky jednotlivých vektorů mezi jednotlivými souřadnicovými systémy. Matice přechodu, jejíž sloupečky reprezentují Žanetiny bázové  vektory, ale zapsané v našich souřadnicích,",
  "n_reviews": 0,
  "start": 510.44,
  "end": 518.56
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "translatedText": "A nezapomeňte, že nás to zajímá proto, že to znamená, že A krát v se rovná lambda krát v, což můžete vyčíst jako tvrzení, že vektor v je vlastním vektorem A, který zůstává na svém vlastním rozpětí během transformace A.",
  "model": "DeepL",
  "from_community_srt": "překládají vektory z jejího jazyka do našeho. A inverzní matice dělá pravý opak. Ale vektory nejsou to jediné, co popisujeme pomocí souřadnic. V další části bude důležité,",
  "n_reviews": 0,
  "start": 520.48,
  "end": 537.28
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "translatedText": "V tomto příkladu je odpovídající vlastní číslo 1, takže v by vlastně zůstalo na místě.",
  "model": "DeepL",
  "from_community_srt": "abyste si rozuměli s reprezentací transformací pomocí matic a abyste chápali,",
  "n_reviews": 0,
  "start": 538.32,
  "end": 544.02
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "translatedText": "Zastavte se a zamyslete se, jestli se musíte ujistit, že se vám tento způsob uvažování líbí.",
  "model": "DeepL",
  "from_community_srt": "jak násobení matic odpovídá skládání po sobě jdoucích transformací. Jestli vám cokoli z toho dělá problémy,",
  "n_reviews": 0,
  "start": 546.22,
  "end": 549.5
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "translatedText": "O tom jsem se zmínil v úvodu.",
  "model": "DeepL",
  "from_community_srt": "rozhodně se vraťte a zopakujte si kapitoly 3 a 4.",
  "n_reviews": 0,
  "start": 553.38,
  "end": 555.64
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "translatedText": "Kdybyste neměli solidní znalosti o determinantech a jejich vztahu k lineárním soustavám rovnic s nenulovými řešeními, připadal by vám takový výraz úplně mimo mísu.",
  "model": "DeepL",
  "from_community_srt": "Vezměme si nějakou lineární transformaci, jako třeba otočení o 90 stupňů. Když ji reprezentujeme pomocí souřadnic my, díváme se, kde skončí vektory 'i' a 'j'.",
  "n_reviews": 0,
  "start": 556.22,
  "end": 566.3
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "translatedText": "Abychom to viděli v praxi, zopakujme si příklad ze začátku s maticí, jejíž sloupce jsou 3, 0 a 1, 2.",
  "model": "DeepL",
  "from_community_srt": "Vektor 'i' dopadne na souřadnice (0, 1) a vektor 'j' na souřadnice (-1, 0). Takže tyto souřadnice budou sloupečky naší matice.",
  "n_reviews": 0,
  "start": 568.32,
  "end": 574.54
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "translatedText": "Chcete-li zjistit, zda je hodnota lambda vlastní číslo, odečtěte ji od diagonál této matice a vypočítejte determinant.",
  "model": "DeepL",
  "from_community_srt": "Akorát že tato reprezentace těžce závisí na naší volbě bázových vektorů.",
  "n_reviews": 0,
  "start": 575.35,
  "end": 583.4
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "translatedText": "Tímto postupem získáme určitý kvadratický polynom v lambdě, 3 minus lambda krát 2 minus lambda.",
  "model": "DeepL",
  "from_community_srt": "Napřed jsme sledovali naše bázové vektory 'i' a 'j' a pak jsme jejich výsledné pozice zaznamenali naším souřadnicovým systémem. Tak jak by Žaneta popsala to samé otočení o 90° v rovině? Možná vás napadlo",
  "n_reviews": 0,
  "start": 590.58,
  "end": 596.72
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "translatedText": "Protože lambda může být vlastní číslo pouze tehdy, je-li tento determinant nulový, lze dojít k závěru, že jediná možná vlastní čísla jsou lambda rovna 2 a lambda rovna 3.",
  "model": "DeepL",
  "from_community_srt": "přeložit sloupečky v naší matici rotace do Žanetina jazyka. Ale to není úplně ono. Tyhle sloupečky udávají,",
  "n_reviews": 0,
  "start": 597.8,
  "end": 608.84
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "translatedText": "Chcete-li zjistit, které vlastní vektory mají vlastně jednu z těchto vlastních hodnot, řekněme lambda rovnou 2, dosaďte tuto hodnotu lambda do matice a pak vyřešte, které vektory tato diagonálně změněná matice posílá k nule.",
  "model": "DeepL",
  "from_community_srt": "kam se přesunou naše bázové vektory 'i' a 'j'. Ale Žanetu chce matici, ve které jsou transformované verze jejích bázových vektorů, a navíc chce tyto výsledky zaznamenat ve svém jazyce. Běžně se to řeší takto: Začneme s vektorem zapsaným v Žanetině jazyce.",
  "n_reviews": 0,
  "start": 609.64,
  "end": 623.9
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "translatedText": "Kdybyste ji vypočítali stejně jako jakoukoli jinou lineární soustavu, zjistili byste, že řešením jsou všechny vektory na úhlopříčce proložené zápornými čísly 1, 1.",
  "model": "DeepL",
  "from_community_srt": "Než abychom se snažili přijít na to, co se s ním děje v jejím jazyce, napřed jej přeložíme do našeho jazyka",
  "n_reviews": 0,
  "start": 624.94,
  "end": 634.3
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "translatedText": "To odpovídá skutečnosti, že nezměněná matice 3, 0, 1, 2 má za následek protažení všech těchto vektorů o faktor 2.",
  "model": "DeepL",
  "from_community_srt": "pomocí matice přechodu, té, co má ve sloupcích její vektory v našem jazyce. Tak dostaneme ten samý vektor, ale zapsaný v našem jazyce.",
  "n_reviews": 0,
  "start": 635.22,
  "end": 643.46
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "translatedText": "2D transformace nemusí mít vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "Na ten už můžeme provést transformaci, tím že jej zleva vynásobíme naší maticí.",
  "n_reviews": 0,
  "start": 646.32,
  "end": 650.2
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "translatedText": "Uvažujme například otočení o 90 stupňů.",
  "model": "DeepL",
  "from_community_srt": "Tak zjistíme polohu výsledného vektoru, ale stále v našem jazyce.",
  "n_reviews": 0,
  "start": 650.72,
  "end": 653.4
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "translatedText": "Ten nemá žádné vlastní vektory, protože otáčí každý vektor mimo jeho vlastní rozpětí.",
  "model": "DeepL",
  "from_community_srt": "Takže musíme nakonec přeložit vektor zpět tak, že jej zleva vynásobíme inverzní maticí přechodu.",
  "n_reviews": 0,
  "start": 653.66,
  "end": 658.2
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "translatedText": "Pokud se skutečně pokusíte vypočítat vlastní čísla takové rotace, všimněte si, co se stane.",
  "model": "DeepL",
  "from_community_srt": "Tím dostaneme transformovaný vektor v Žanetině jazyce.",
  "n_reviews": 0,
  "start": 660.8,
  "end": 665.56
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "translatedText": "Jeho matice má sloupce 0, 1 a záporné 1, 0.",
  "model": "DeepL",
  "from_community_srt": "Tohle můžeme provést s jakýmkoli vektorem zapsaným v jejím jazyce. Napřed přejít k naší bázi, pak provést transformaci",
  "n_reviews": 0,
  "start": 666.3,
  "end": 670.14
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "translatedText": "Odečtěte lambdu od diagonálních prvků a hledejte, kdy je determinant nulový.",
  "model": "DeepL",
  "from_community_srt": "a pak přejít zpátky k její bázi.",
  "n_reviews": 0,
  "start": 671.1,
  "end": 675.8
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "translatedText": "V tomto případě dostanete polynom lambda na druhou plus 1.",
  "model": "DeepL",
  "from_community_srt": "Toto složení tří matic nám dává matici dané transformace v Žanetině jazyce.",
  "n_reviews": 0,
  "start": 678.14,
  "end": 681.94
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "translatedText": "Jedinými kořeny tohoto polynomu jsou imaginární čísla i a záporné i.",
  "model": "DeepL",
  "from_community_srt": "Bere vektor v jejím jazyce a vyplivne transformovaný vektor, opět v jejím jazyce.",
  "n_reviews": 0,
  "start": 682.68,
  "end": 687.92
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "translatedText": "Skutečnost, že neexistují řešení v reálných číslech, znamená, že neexistují vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "V tomhle konkrétním případě, když je Žanetina báze v našem jazyce (2, 1) a (-1,",
  "n_reviews": 0,
  "start": 688.84,
  "end": 693.6
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "translatedText": "Dalším docela zajímavým příkladem, který stojí za to mít na paměti, je střižník.",
  "model": "DeepL",
  "from_community_srt": "1) a transformace odpovídá rotaci o 90 stupňů, součin těchto tří matic bude mít po vyčíslení sloupečky (1/3,",
  "n_reviews": 0,
  "start": 695.54,
  "end": 699.82
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "translatedText": "Tím se i-hat zafixuje na místě a j-hat se posune o 1, takže jeho matice má sloupce 1, 0 a 1, 1.",
  "model": "DeepL",
  "from_community_srt": "5/3) a (-2/3, -1/3).",
  "n_reviews": 0,
  "start": 700.56,
  "end": 707.84
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "translatedText": "Všechny vektory na ose x jsou vlastní vektory s vlastní hodnotou 1, protože zůstávají na místě.",
  "model": "DeepL",
  "from_community_srt": "Takže když Žaneta touto maticí vynásobí souřadnice vektoru ve svém systému, dostane ten samý vektor otočený o 90 stupňů,",
  "n_reviews": 0,
  "start": 708.74,
  "end": 714.54
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "translatedText": "Ve skutečnosti se jedná o jediné vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "stále ve svém systémů.",
  "n_reviews": 0,
  "start": 715.68,
  "end": 717.82
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "translatedText": "Když od úhlopříček odečtete lambdu a vypočtete determinant, dostanete 1 minus lambda na druhou.",
  "model": "DeepL",
  "from_community_srt": "Když obecně narazíte na výraz tvaru A^(-1) M A, naznačuje to jistý matematický druh empatie.",
  "n_reviews": 0,
  "start": 718.76,
  "end": 726.54
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "translatedText": "A jediným kořenem tohoto výrazu je lambda rovná se 1.",
  "model": "DeepL",
  "from_community_srt": "Prostřední matice reprezentuje nějaký druh transformace z našeho pohledu, a vnější dvě matice reprezentují empatii -- změnu perspektivy,",
  "n_reviews": 0,
  "start": 729.32,
  "end": 732.86
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "translatedText": "To odpovídá tomu, co vidíme geometricky, že všechny vlastní vektory mají vlastní hodnotu 1.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 734.56,
  "end": 739.72
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "translatedText": "Mějte však na paměti, že je také možné mít jen jednu vlastní hodnotu, ale s více než jen řádkem plným vlastních vektorů.",
  "model": "DeepL",
  "from_community_srt": "takže celkový součin reprezentuje tu samou transformaci, ale z pohledu někoho jiného. Jestli vás zajímá, proč nám tak záleží na alternativních souřadnicových systémech, tak následující video o vlastních číslech a vlastních vektorech",
  "n_reviews": 0,
  "start": 741.08,
  "end": 748.02
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "translatedText": "Jednoduchým příkladem je matice, která vše škáluje po 2.",
  "model": "DeepL",
  "from_community_srt": "podává velice důležitý příklad takové situace.",
  "n_reviews": 0,
  "start": 749.9,
  "end": 753.18
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "translatedText": "Jediná vlastní hodnota je 2, ale každý vektor v rovině se stane vlastním vektorem s touto vlastní hodnotou.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 753.9,
  "end": 760.7
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "translatedText": "Nyní je další vhodná chvíle se zastavit a zamyslet se nad některými z nich, než přejdu k poslednímu tématu.",
  "model": "DeepL",
  "from_community_srt": "Nashle příště!",
  "n_reviews": 0,
  "start": 762.0,
  "end": 766.96
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "translatedText": "Na závěr bych rád představil myšlenku vlastní báze, která se do značné míry opírá o myšlenky z minulého videa.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 783.54,
  "end": 789.88
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "translatedText": "Podívejte se, co se stane, když jsou naše základní vektory náhodou vlastními vektory.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 791.48,
  "end": 796.38
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2.",
  "translatedText": "Například i-hat je škálován zápornou hodnotou 1 a j-hat je škálován hodnotou 2.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 797.12,
  "end": 802.38
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "translatedText": "Když zapíšeme jejich nové souřadnice jako sloupce matice, všimneme si, že tyto skalární násobky, záporné 1 a 2, což jsou vlastní čísla i-hat a j-hat, leží na diagonále naší matice a každý další zápis je 0.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 803.42,
  "end": 817.18
 },
 {
  "input": "Any time a matrix has zeros everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix.",
  "translatedText": "Vždy, když má matice nuly všude jinde než na diagonále, nazývá se vcelku rozumně diagonální maticí.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 818.88,
  "end": 825.42
 },
 {
  "input": "And the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "translatedText": "To lze interpretovat tak, že všechny základní vektory jsou vlastními vektory, přičemž diagonální položky této matice jsou jejich vlastní hodnoty.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 825.84,
  "end": 834.4
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "translatedText": "S diagonálními maticemi se pracuje mnohem lépe.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 837.1,
  "end": 841.06
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "translatedText": "Jedním z nich je, že je snazší vypočítat, co se stane, když tuto matici vynásobíte celou řadou.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 841.78,
  "end": 848.34
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "translatedText": "Protože jediné, co jedna z těchto matic dělá, je škálování každého bázového vektoru určitou vlastní hodnotou, bude použití této matice mnohokrát, řekněme stokrát, odpovídat škálování každého bázového vektoru 100. mocninou příslušné vlastní hodnoty.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 849.42,
  "end": 864.6
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "translatedText": "Naproti tomu zkuste vypočítat stou mocninu nediagonální matice.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 865.7,
  "end": 869.68
 },
 {
  "input": "Really, try it for a moment.",
  "translatedText": "Opravdu, zkuste to na chvíli.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 869.68,
  "end": 871.32
 },
 {
  "input": "It's a nightmare.",
  "translatedText": "Je to noční můra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 871.74,
  "end": 872.44
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "translatedText": "Samozřejmě budete mít málokdy takové štěstí, aby vaše základní vektory byly zároveň vlastními vektory.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 876.08,
  "end": 881.26
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "translatedText": "Pokud však vaše transformace obsahuje mnoho vlastních vektorů, jako například transformace ze začátku tohoto videa, a to tolik, že si můžete vybrat množinu, která pokrývá celý prostor, pak můžete změnit souřadnicový systém tak, aby tyto vlastní vektory byly vašimi základními vektory.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 882.04,
  "end": 896.54
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "translatedText": "O změně základu jsem mluvil v minulém videu, ale tady si v rychlosti připomenu, jak vyjádřit transformaci zapsanou v našem souřadnicovém systému do jiného systému.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 897.14,
  "end": 907.04
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "translatedText": "Vezměte souřadnice vektorů, které chcete použít jako novou bázi, což v tomto případě znamená naše dva vlastní vektory, a pak z těchto souřadnic vytvořte sloupce matice, známé jako matice změny báze.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 908.44,
  "end": 919.44
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "translatedText": "Když původní transformaci přepíšete a na její pravou stranu umístíte matici změny báze a na její levou stranu inverzní matici změny báze, výsledkem bude matice reprezentující stejnou transformaci, ale z pohledu souřadnicového systému nových bázových vektorů.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 920.18,
  "end": 936.5
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "translatedText": "Smysl tohoto postupu s vlastními vektory spočívá v tom, že tato nová matice je zaručeně diagonální s odpovídajícími vlastními hodnotami na této diagonále.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 937.44,
  "end": 946.68
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "translatedText": "Je to proto, že se jedná o práci v souřadnicovém systému, kde se s bázovými vektory děje to, že se při transformaci škálují.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 946.86,
  "end": 954.32
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "translatedText": "Soubor bázových vektorů, které jsou zároveň vlastními vektory, se nazývá, opět vcelku rozumně, vlastní báze.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 955.8,
  "end": 961.56
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "translatedText": "Pokud byste tedy například potřebovali vypočítat stou mocninu této matice, bylo by mnohem jednodušší přejít na vlastní základnu, vypočítat stou mocninu v této soustavě a pak ji převést zpět do naší standardní soustavy.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 962.34,
  "end": 975.68
 },
 {
  "input": "You can't do this with all transformations.",
  "translatedText": "To nelze provést u všech transformací.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 976.62,
  "end": 978.32
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "translatedText": "Například smyk nemá dostatek vlastních vektorů, aby obsáhl celý prostor.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 978.32,
  "end": 982.98
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "translatedText": "Ale pokud se vám podaří najít vlastní základnu, jsou operace s maticemi opravdu krásné.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 983.46,
  "end": 988.16
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "translatedText": "Pro ty z vás, kteří jsou ochotni projít si pěknou hádanku, aby viděli, jak to vypadá v akci a jak to lze použít k dosažení překvapivých výsledků, nechám zde na obrazovce výzvu.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 989.12,
  "end": 997.32
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "translatedText": "Dá to trochu práce, ale myslím, že se vám to bude líbit.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 997.6,
  "end": 1000.28
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "translatedText": "Další a poslední video této série se bude věnovat abstraktním vektorovým prostorům.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 1000.84,
  "end": 1006.12
 }
]