[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Come probabilmente avrai già capito, la maggior parte di questa serie riguarda la comprensione delle operazioni su matrici e vettori attraverso la lente più visiva delle trasformazioni lineari.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Questo video non fa eccezione e descrive i concetti di matrici inverse, spazio di colonna, rango e spazio nullo attraverso tale obiettivo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Un avvertimento però: non parlerò dei metodi per calcolare effettivamente queste cose, e alcuni sostengono che sia piuttosto importante.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Ci sono molte ottime risorse per apprendere questi metodi al di fuori di questa serie, le parole chiave eliminazione gaussiana e la forma a scaglioni di riga.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Penso che la maggior parte del valore che devo effettivamente aggiungere qui risieda nella metà dell'intuizione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Inoltre, in pratica, di solito riceviamo comunque un software che calcola queste cose per noi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "Innanzitutto qualche parola sull’utilità dell’algebra lineare.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics, but one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "A questo punto hai già un accenno su come viene utilizzata per descrivere la manipolazione dello spazio, che è utile per cose come la computer grafica e la robotica, ma uno dei motivi principali per cui l'algebra lineare è più ampiamente applicabile e richiesta praticamente per qualsiasi disciplina tecnica è che ci permette di risolvere certi sistemi di equazioni.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.3,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Quando dico sistema di equazioni, intendo che hai un elenco di variabili, cose che non conosci e un elenco di equazioni che le collegano.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated, but if you're lucky, they might take on a certain special form.",
  "translatedText": "In molte situazioni, queste equazioni possono diventare molto complicate, ma se sei fortunato, potrebbero assumere una forma speciale.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.34,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "All'interno di ogni equazione, l'unica cosa che accade a ciascuna variabile è che viene scalata in base a una costante, e l'unica cosa che accade a ciascuna di queste variabili scalate è che vengono sommate l'una all'altra.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Quindi niente esponenti o funzioni fantasiose o moltiplicazione di due variabili insieme, cose del genere.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "Il modo tipico di organizzare questo tipo di sistema speciale di equazioni è di gettare tutte le variabili a sinistra e mettere tutte le costanti persistenti a destra.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "È anche utile allineare verticalmente le variabili comuni e per farlo potrebbe essere necessario inserire alcuni coefficienti pari a zero ogni volta che la variabile non compare in una delle equazioni.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Questo è chiamato sistema lineare di equazioni.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Potresti notare che assomiglia molto alla moltiplicazione matrice-vettore.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "In effetti, puoi raggruppare tutte le equazioni insieme in un'unica equazione vettoriale in cui hai la matrice contenente tutti i coefficienti costanti e un vettore contenente tutte le variabili, e il loro prodotto matrice-vettore è uguale a un vettore costante diverso.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced x, and call the constant vector on the right-hand side v.",
  "translatedText": "Chiamiamo la matrice costante A, denotiamo il vettore che contiene le variabili con una x in grassetto e chiamiamo v il vettore costante sul secondo membro.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "Questo è più di un semplice trucco notazionale per scrivere il nostro sistema di equazioni su una riga.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Fa luce su un'interpretazione geometrica piuttosto interessante del problema.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals v means we're looking for a vector x which, after applying the transformation, lands on v.",
  "translatedText": "La matrice A corrisponde ad una trasformazione lineare, quindi risolvere Ax uguale a v significa che stiamo cercando un vettore x che, dopo aver applicato la trasformazione, si ferma su v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Pensa per un momento a quello che sta succedendo qui.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Puoi tenere in testa questa idea davvero complicata di più variabili tutte mescolate tra loro semplicemente pensando a schiacciare e trasformare lo spazio e cercando di capire quale vettore si ferma su un altro.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Fantastico, vero?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Per iniziare in modo semplice, supponiamo di avere un sistema con due equazioni e due incognite.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix and v and x are each two-dimensional vectors.",
  "translatedText": "Ciò significa che la matrice A è una matrice 2x2 e v e x sono vettori bidimensionali.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "Ora, il modo in cui pensiamo alle soluzioni di questa equazione dipende dal fatto che la trasformazione associata ad A schiacci tutto lo spazio in una dimensione inferiore, come una linea o un punto, o se lasci tutto ciò che abbraccia le due dimensioni complete da dove è iniziato.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "Nel linguaggio dell'ultimo video, suddividiamo nei casi in cui A ha determinante zero e nel caso in cui A ha determinante diverso da zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Cominciamo con il caso più probabile, in cui il determinante è diverso da zero, il che significa che lo spazio non viene schiacciato in una regione ad area zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on v, and you can find it by playing the transformation in reverse.",
  "translatedText": "In questo caso, ci sarà sempre uno ed un solo vettore che si ferma su v, e potrai trovarlo eseguendo la trasformazione al contrario.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where v goes as we rewind the tape like this, you'll find the vector x such that A times x equals v.",
  "translatedText": "Seguendo dove va v mentre riavvolgiamo il nastro in questo modo, troverai il vettore x tale che A per x è uguale a v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Quando esegui la trasformazione al contrario, in realtà corrisponde a una trasformazione lineare separata comunemente chiamata l'inverso di A, indicato con A al negativo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Ad esempio, se A fosse una rotazione di 90 gradi in senso antiorario, l'inverso di A sarebbe una rotazione di 90 gradi in senso orario.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Se A fosse un taglio verso destra che spinge j-hat di un'unità a destra, l'inverso di A sarebbe un taglio verso sinistra che spinge j-hat di un'unità a sinistra.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "In generale, A inversa è l'unica trasformazione con la proprietà che se si applica prima A e poi la si segue con la trasformazione A inversa, si ritorna al punto di partenza.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication.",
  "translatedText": "L'applicazione di una trasformazione dopo l'altra viene catturata algebricamente con la moltiplicazione di matrici.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.54,
  "end": 298.94
 },
 {
  "input": "So the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "Quindi la proprietà principale di questa trasformazione A inversa è che A inversa per A è uguale alla matrice che corrisponde a non fare nulla.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.42,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "La trasformazione che non fa nulla è chiamata trasformazione dell'identità.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "Lascia i-hat e j-hat ciascuno dove sono, immobili, quindi le sue colonne sono 1,0 e 0,1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Una volta trovata questa matrice inversa, cosa che in pratica faresti con un computer, puoi risolvere la tua equazione moltiplicando questa matrice inversa per v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "E ancora, ciò che questo significa geometricamente è che stai interpretando la trasformazione al contrario e seguendo v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Questo caso determinante diverso da zero, che per una scelta casuale di matrice è di gran lunga il più probabile, corrisponde all'idea che se si hanno due incognite e due equazioni, è quasi certamente vero che esiste un'unica soluzione unica.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Questa idea ha senso anche nelle dimensioni superiori, quando il numero di equazioni è uguale al numero di incognite.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Ancora una volta, il sistema di equazioni può essere tradotto nell'interpretazione geometrica in cui hai una trasformazione A e un vettore v, e stai cercando il vettore x che coincide con v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "Finché la trasformazione A non schiaccia tutto lo spazio in una dimensione inferiore, il che significa che il suo determinante è diverso da zero, ci sarà una trasformazione inversa A inversa, con la proprietà che se prima fai A, poi fai A inversa , è come non fare nulla.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "E per risolvere la tua equazione, devi solo moltiplicare la matrice di trasformazione inversa per il vettore v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Ma quando il determinante è zero e la trasformazione associata al sistema di equazioni riduce lo spazio in una dimensione più piccola, non esiste il contrario.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Non è possibile schiacciare una linea per trasformarla in un piano.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "Almeno questo non è qualcosa che una funzione può fare.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Ciò richiederebbe la trasformazione di ogni singolo vettore in un’intera linea piena di vettori.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Ma le funzioni possono portare solo un singolo input su un singolo output.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Allo stesso modo, per tre equazioni e tre incognite, non ci sarà l'inverso se la trasformazione corrispondente schiaccia lo spazio 3D sul piano, o anche se lo schiaccia su una linea o un punto.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Tutti questi corrispondono a un determinante pari a zero, poiché qualsiasi regione è schiacciata in qualcosa con volume zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "È ancora possibile che esista una soluzione anche quando non esiste l'inverso.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "È solo che quando la tua trasformazione schiaccia lo spazio, diciamo, su una linea, devi essere abbastanza fortunato che il vettore v viva da qualche parte su quella linea.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Potresti notare che alcuni di questi casi zero determinanti sembrano molto più restrittivi di altri.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Data una matrice 3x3, ad esempio, sembra molto più difficile che esista una soluzione quando schiaccia lo spazio su una linea rispetto a quando schiaccia le cose su un piano, anche se entrambi sono determinanti pari a zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "Abbiamo un linguaggio un po' più specifico del semplice dire determinante zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Quando l'output di una trasformazione è una linea, ovvero è unidimensionale, diciamo che la trasformazione ha rango uno.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Se tutti i vettori si fermano su un piano bidimensionale, diciamo che la trasformazione ha rango due.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Quindi la parola rango indica il numero di dimensioni nell'output di una trasformazione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank 2 is the best that it can be.",
  "translatedText": "Ad esempio, nel caso di matrici 2x2, il rango 2 è il migliore possibile.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space and the determinant is non-zero.",
  "translatedText": "Significa che i vettori di base continuano ad estendersi su tutte e due le dimensioni dello spazio e il determinante è diverso da zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank 2 means that we've collapsed, but not as much as they would have collapsed for a rank 1 situation.",
  "translatedText": "Ma per le matrici 3x3, il rango 2 significa che siamo crollati, ma non tanto quanto sarebbero collassati per una situazione di rango 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of 3.",
  "translatedText": "Se una trasformazione 3D ha un determinante diverso da zero e il suo output riempie tutto lo spazio 3D, ha rango 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Questo insieme di tutti i possibili output per la tua matrice, che sia una linea, un piano, uno spazio 3D, qualunque cosa, è chiamato spazio delle colonne della tua matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Probabilmente puoi indovinare da dove viene quel nome.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "Le colonne della tua matrice ti dicono dove si fermano i vettori base e l'intervallo di quei vettori base trasformati ti dà tutti i possibili risultati.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "In altre parole, lo spazio delle colonne è l'estensione delle colonne della matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Quindi una definizione più precisa di rango sarebbe che si tratta del numero di dimensioni nello spazio delle colonne.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Quando questo rango è il più alto possibile, ovvero uguale al numero di colonne, chiamiamo rango completo della matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice, the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Si noti che il vettore zero sarà sempre incluso nello spazio colonna, poiché le trasformazioni lineari devono mantenere fissa l'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "Per una trasformazione di rango completo, l'unico vettore che arriva all'origine è il vettore zero stesso.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Ma per le matrici che non hanno il rango completo, che si riducono a una dimensione più piccola, puoi avere un sacco di vettori che finiscono sullo zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Se una trasformazione 2D comprime lo spazio su una linea, ad esempio, c'è una linea separata in una direzione diversa piena di vettori che vengono schiacciati sull'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Se una trasformazione 3D schiaccia lo spazio su un piano, c'è anche una linea completa di vettori che arriva all'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Se una trasformazione 3D comprime tutto lo spazio su una linea, allora c'è un intero piano pieno di vettori che arrivano all'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Questo insieme di vettori che arriva all'origine è chiamato spazio nullo o nucleo della matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "È lo spazio di tutti i vettori che diventano nulli, nel senso che si fermano sul vettore zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "In termini di sistema lineare di equazioni, quando v sembra essere il vettore zero, lo spazio nullo fornisce tutte le possibili soluzioni dell'equazione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high-level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Questa è una panoramica di altissimo livello su come pensare geometricamente ai sistemi lineari di equazioni.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "A ogni sistema è associata una sorta di trasformazione lineare e quando tale trasformazione ha un inverso, puoi usarlo per risolvere il tuo sistema.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "Altrimenti, l'idea di spazio delle colonne ci permette di capire quando esiste una soluzione, e l'idea di spazio nullo ci aiuta a capire come può apparire l'insieme di tutte le soluzioni possibili.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Ancora una volta, ci sono molte cose che non ho trattato qui, in particolare come calcolare queste cose.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Ho anche dovuto limitare il mio ambito agli esempi in cui il numero di equazioni è uguale al numero di incognite.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Ma l'obiettivo qui non è cercare di insegnare tutto, è che tu ne esca con una forte intuizione per le matrici inverse, lo spazio delle colonne e lo spazio nullo, e che quelle intuizioni rendano qualsiasi apprendimento futuro che farai più fruttuoso.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "Il prossimo video, a grande richiesta, sarà una breve nota a piè di pagina sulle matrici non quadrate.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Successivamente vi darò la mia opinione sui prodotti punto e su qualcosa di davvero interessante che accade quando li osservate alla luce delle trasformazioni lineari.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.88,
  "end": 718.92
 },
 {
  "input": "See you then!",
  "translatedText": "Ci vediamo!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.48,
  "end": 719.66
 }
]