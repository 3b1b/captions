[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "",
  "from_community_srt": "지금쯤이면 아마도 알거야 이 동영상 시리즈의 대부분이 행렬과 벡터연산의 이해를 선형변환의 시각화 렌즈를 통해서 본거지.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "",
  "from_community_srt": "이 동영상도 마찬가지야. 역행렬(inverse matrix) 개념을 설명할때나 열공간, 계수(rank), 영공간(null space) 설명할때도 그런 렌즈를 통해서 설명할거야.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "",
  "from_community_srt": "미리 말해두건대, 이런 것들을 실제 계산하는 방법에 대해서는 다루지 않을거야. 누구에게는 그게 꽤 중요할 수도 있지만.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "",
  "from_community_srt": "다른 동영상들을 찾아보면 그런 계산법을 다루는 좋은 게 많이 있을거야. 검색할때 키워드로 \"가우스 소거법(Gaussian elimination)\" 나 \"Row echelon form\" 이라고 검색해봐.",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "",
  "from_community_srt": "내가 여기서 설명하려고 하는 것, 나머지 직관부분이 더 중요하다고 생각해.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "",
  "from_community_srt": "또, 실제로 이런 것들을 계산해주는 소프트웨어를 보통 구할 수 있어.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "",
  "from_community_srt": "우선, 선형대수의 유용성에 몇마디 말하자면",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "",
  "from_community_srt": "지금쯤이면 너는 이미 공간의 조작에 대한 설명이라는 힌트는 가지고 있을거야. 컴퓨터 그래픽이나 로봇 분야에서 유용하지.",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "",
  "from_community_srt": "그러나 선형대수가 훨씬 광범위하게 적용가능하다고 하는 주된 이유는, , 어떤 기술적 분야이든지 필요하다고 하는 이유는, 어떤 방정식계이든지 해결할 수 있기 때문이야.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "",
  "from_community_srt": "여기서 \"방정식계(system of equations)\" 란, 미지수인 변수 리스트와 변수들과 관련된 방정식의 리스트를 가졌을때를 말해.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "",
  "from_community_srt": "많은 상황에서, 이런 방정식들은 상당히 복잡해.",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "",
  "from_community_srt": "하지만, 운이 좋으면 이렇게 어떤 특정한 형태로 다룰 수 있어.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "",
  "from_community_srt": "각 방정식 내에서, 각 변수들의 역할은 어떤 상수를 스케일링하는 거야. 그리고 스케일된 변수들을 서로 더하는게 전부야.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "",
  "from_community_srt": "지수함수나 어떤 특이한 함수같은 건 없어. 두 변수를 서로 곱하는 것도 없고 말야.",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "",
  "from_community_srt": "이런 변수들을 조직화한 게 일종의 특수한 방정식계야. 모든 변수들을 좌항으로 던지고, 오른쪽에는 상수항을 놓아.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "",
  "from_community_srt": "세로 방향으로도 같은 변수끼리 열맞추는 것도 좋아. 이렇게 하다보면 숫자가 0 인 변수도 있어서 하나의 방정식에 어떤 변수가 없을때도 있지.",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "",
  "from_community_srt": "이렇게 놓은 것을 \"선형 방정식계(linear system of equations)\" 라고 해.",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "",
  "from_community_srt": "행렬-벡터 곱셈이랑 많이 비슷해보이는 걸 눈치챘을거야.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "",
  "from_community_srt": "사실, 모든 방정식들을 하나의 벡터방정식으로 표현할 수 있어. 상수 계수만을 모아서 행렬을 만들고, 변수들을 모아서 벡터를 만들어서 행렬 벡터 곱셈하면 다른 상수벡터랑 같아져.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "",
  "from_community_srt": "상수 행렬을 A 라고 하자. 굵은 x 변수는 벡터를 나타내도록 하고 오른쪽의 상수 벡터를 v 라고 하자.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "",
  "from_community_srt": "이렇게 쓴 한 줄은 선형방정식계를 짧게 표현한 것일 뿐이야.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "",
  "from_community_srt": "이렇게 표현하는 것은 문제에 대해 상당히 멋진 기하학적 해석을 들어나게 해줘.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "",
  "from_community_srt": "행렬 A 는 어떤 선형변환을 나타내고, 그럼 Ax = v  를 푸는 것은 변환후에는 벡터 v 가 되는 벡터 x 가 있는지 찾아보는게 돼.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "",
  "from_community_srt": "무슨 말인지 잠깐 생각해보자.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "",
  "from_community_srt": "너는 여러 변수들 모두를 섞은 복잡한 개념을 머리속에 담으려면 그냥 공간을 변형시키는 것으로 생각하고, 어떤 벡터가 어디로 이동하는지만 찾으려고 하면 돼.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "",
  "from_community_srt": "멋지지 않아?",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "",
  "from_community_srt": "간단하게 시작해보자, 2개의 미지수를 가진 두개의 방정식 계를 생각해보자.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "",
  "from_community_srt": "이때 행렬 A는 2 × 2 행렬이 되고, v 와 x 벡터는 2차원 벡터가 돼.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "",
  "from_community_srt": "이제, 이 방정식의 해를 찾는 방법은 행렬 A 변환이 모든 공간을 더 낮은 차원으로 축소시키는지, 선이나 점같은 공간으로, 아니면 공간 전부가 그대로 남는지를 알아보는게 시작점이야.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "",
  "from_community_srt": "지난 동영상에서 다룬 말을 빌리자면, 행렬 A 의 행렬식 값이 0 인지, 아니면 0 값이 아닌지로 나누는 것과 같아.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "",
  "from_community_srt": "우선은 가장 흔한 경우인 행렬식값이 0이 아닌 경우부터 살펴보자., 공간을 제로 영역으로 축소시키지 않는 경우야.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "",
  "from_community_srt": "이 경우, 특정 v 벡터로 변할 수 있는 벡터는 항상 하나만 있어. (역자: 일대일 대응 변환) 변환을 역방향으로 돌리면 찾을 수 있어.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "",
  "from_community_srt": "뒤로감기처럼 플레이하며 벡터 v 가 어디로 가는지 따라가보면 벡터 x 를 찾을 수 있을거야. Ax = v 에서 x 를 말야.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "",
  "from_community_srt": "역으로 변환하는 것, 이것은 일반적으로 \"A의 역행렬(the inverse of A)\" 이라고 해. A 의 윗첨자로 -1 을 표시해놓지.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "",
  "from_community_srt": "예를 들어, A가 반 시계 방향으로 90 ° 회전이라면 그 역은 시계방향으로 90 ° 회전일거야.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "",
  "from_community_srt": "행렬 A 가 j-hat 을 오른쪽 한칸만큼 기울이는 변환이라면 그 역은 j-hat 왼쪽 방향으로 한칸만큼 기울이는 변환이야.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "",
  "from_community_srt": "일반적으로, A 역행렬의 특별한 속성은 A 행렬을 적용한 뒤, 그다음 A 역행렬을 적용하면, 다시 시작한 점으로 돌아오게 돼.",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "",
  "from_community_srt": "이렇게 연달아 적용하는 변환을 행렬 곱셈으로 대수적 축약할 수 있어. 그래서 A역행렬 변환이 가진 핵심속성은 이거야. A역행렬 곱하기 A행렬은 아무 것도 바꾸지 않는 행렬과 같다는 것.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "",
  "from_community_srt": "아무것도하지 않는 변환을 \"항등 변환(identity transformation)\" 이라고 불러.",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "",
  "from_community_srt": "i-hat 과 j-hat 을 이동시키지 않고 놔두지. 그래서 그대로 (1,0),(0,1) 이야.",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "",
  "from_community_srt": "일단 역행렬을 찾았으면, , 수동으로 했든 컴퓨터를 사용했든, 방정식 역행렬을 v 벡터에 곱해서 풀 수 있어.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "",
  "from_community_srt": "자 다시한번, 기하학적으로 이 말이 무슨 뜻이냐면, v 벡터에 역변환을 가한거야.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "",
  "from_community_srt": "이렇게 행렬식 값이 0이 아닌 경우에, 아무렇게나 랜덤하게 행렬을 만들면 대부분 이 경우일텐데, 이게 2개의 미지수에 2개의 방정식을 가진 문제와 똑같아져. 이런 경우 대부분은 확실히 하나의 유일한 해가 존재해.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "이 아이디어는 더 높은 차원에서도 맞아. 미지수 개수와 방정식 개수가 같은 경우",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "",
  "from_community_srt": "또다시, 방정식계는 기하학적 해석으로 변환해서 어떤 변환을 나타내는 A 행렬과 어떤 벡터 v 를 가지고 벡터 v 로 변환되는 벡터 x 를 찾는 게 되지.",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "",
  "from_community_srt": "변환 A 가 공간을 더 낮은 차원으로 뭉게지 않는 한, 즉, 행렬식 값이 0 이 아닌 경우, 역행렬 A 가 존재하게 돼. 이 역행렬의 속성은 A 를 적용한 뒤, A 역행렬을 적용하면, 아무것도 변하지 않는 거지.",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "",
  "from_community_srt": "그리고 이 방정식을 푼다는 것은, 역행렬을 v 벡터에 곱하는 것이고.",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "",
  "from_community_srt": "하지만 행렬식 값이 0이면, 그리고 이 방정식계에 대한 변환이 더 작은 차원으로 뭉게버린다면, 역행렬은 존재하지 않게돼.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "",
  "from_community_srt": "뭉게진 선을 되돌려서 평면으로 만들 수 없어.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "",
  "from_community_srt": "적어도, 그 함수가 할 수 있는 일이 아니야.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "",
  "from_community_srt": "그렇게 하려면 필요한게, 각 벡터를 변환시켜서 하나의 온전한 선, 선을 이루는 모든 벡터로 바꿔야 해.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "",
  "from_community_srt": "하지만, 함수들은 하나의 입력을 받아 하나의 출력만 만들어.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "",
  "from_community_srt": "마찬가지로, 3개 미지수로 구성된 3개의 방정식에서도 이같은 변환을 나타낼 길은 없어. 3차원 공간을 평면으로 축소시키거나 또는 선이나 점으로 뭉게뜨리는 것은 가능해도 말야.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "",
  "from_community_srt": "행렬식 값 0 인 모든 것은 어떤 지역이라도 영부피로 만들기 때문에",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "",
  "from_community_srt": "해는 여전히 존재할 수 있긴 해. 역행렬이 없는 경우라도 말야.",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "",
  "from_community_srt": "어떤 변환이 공간을 하나의 선으로 변환시키는 경우라면, 벡터 v 가 그 선 위에 놓여있는 경우가 다행인 거야. (역자: 이때만 해를 구할 수 있다)",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "",
  "from_community_srt": "너는 아마도 행렬식 0 값인 경우가 다른 경우보다 제한되는 느낌을 받을 거야.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "",
  "from_community_srt": "3x3 행렬을 예를들면, 해가 존재하기 상당히 힘들어 지는 경우가 있어. 공간을 하나의 선으로 수축하는 경우가 공간을 평면으로 수축하는 경우보다 더 말야. 심지어 둘 다 행렬식 값은 0 으로 같은데도 말야.",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "",
  "from_community_srt": "이 경우 우리는 단순히 \"행렬식 0(zero determinant)\" 보다 더 정확한 표현이 필요한 거 같아.",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "",
  "from_community_srt": "변환의 결과가 선이라면, 즉 1차원 이라면, 이 경우 랭크(rank)=1 이라고 해.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "",
  "from_community_srt": "모든 벡터가 2차원 평면에 놓여있다면, 이때는 랭크(rank)=2 라고 말해.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "",
  "from_community_srt": "그래서 단어 \"랭크(rank)\" 의 의미는 변환 결과의 차원의 수를 말해주지.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "",
  "from_community_srt": "예를 들어, 2 × 2 행렬의 경우에, 최대로 될 수 있는 랭크는 2야.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "",
  "from_community_srt": "이 말은 기저벡터들을 확장시켜 온전한 2차원 공간을 만들 수 있다는 거야. 행렬식 값이 0 이 아니라는 뜻이지.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "",
  "from_community_srt": "그러나 3 × 3 행렬에서, 랭크가 2 라는 말은 공간이 붕괴(축소) 했음을 말해. 하지만 랭크 1 만큼 붕괴된 것은 아닌 거지.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "",
  "from_community_srt": "3차원 변환의 행렬식 값이 0 이 아니라면, 3차원 공간의 결과가 온전한 3차원이라면, 이때는 랭크 3 이야.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "",
  "from_community_srt": "행렬의 가능한 결과의 집합을 , 선이든, 평면이든, 3차원 공간이든지 간에, 그 행렬의 \"열 공간(column space)\"라고 불러.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "",
  "from_community_srt": "넌 지금쯤 이 이름이 어떻게 나왔는지 알 수 있을거야.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "",
  "from_community_srt": "행렬의 열들은 기저벡터의 변환 후 위치이고, 이 변환후 기저벡터들의 확장공간은 가능한 모든 결과공간을 알려주지.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "",
  "from_community_srt": "즉, 열 공간(column space) 란, 행렬의 열들의 확장공간이야.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "",
  "from_community_srt": "그래서, 랭크의 좀 더 정확한 정의는 열공간의 차원 수야.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "",
  "from_community_srt": "이 랭크가 높아질 수록, 열의 갯수와 같다는 말이고, 이 때를 \"온전한 랭크(full rank)\" 라고 불러.",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "",
  "from_community_srt": "기억해야할 것은, 영 벡터(zero vector)는 어느 열공간에든지 포함되어 있다는 거야. 선형변환은 반드시 원점이 고정되어 있어야 하기 때문이야. (역자: 앞선 \"linear tranformation\" 챕터 확인)",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "",
  "from_community_srt": "완전한 랭크(full rank) 인 변환에서, 원점으로 변하는 벡터는 영벡터 뿐이야.",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "",
  "from_community_srt": "그렇지만 행렬이 온전한 랭크(full rank) 가 아니라면, 즉 더 작은 차원으로 축소된다면, 제로벡터가 되는 수많은 벡터들을 가지게 될거야.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "",
  "from_community_srt": "2 차원 변환에서 선으로 축소되는 경우를 예를 들게. 서로 다른 방향을 가리키는 벡터들이지만 같이 원점으로 뭉게지는 수 많은 벡터들이 있어.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "3 차원 변환이 평면으로 축소되는 예를 들면, 마찬가지로 원점으로 이동하는 선의 수많은 벡터들이 존재해.",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "3차원 변환이 공간을 선으로 축소시킨다면, 한 평면의 모든 벡터들이 원점으로 이동하게 돼.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "",
  "from_community_srt": "원점으로 이동되는 벡터들의 집합을 그 행렬의 \"영공간(null space)\" 혹은 \"커널(kernel)\" 이라고 불러.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "",
  "from_community_srt": "그것은 널 (null)이 되는 모든 벡터의 공간이라는 뜻이야. 이 벡터들 모두 영벡터로 이동한다는 말이야.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "",
  "from_community_srt": "선형 방정식계 용어로 말하면, 벡터v 가 영벡터인 경우, 영공간(null space) 모두가 해가 될 수 있어.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "",
  "from_community_srt": "그럼 좀 더 높여서 훑어보자. 선형방정식계가 기하학적으로 어떻게 생각할 수 있는지 정리해보자.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "",
  "from_community_srt": "각 계(system)는 선형변환과 같은 것을 가지고 그와 관련된 선형 변환의 일종, 그 변환이 역변환을 가지면, 계(system) 를 풀기 위해 역변환을 사용하면 돼.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "",
  "from_community_srt": "그게 안된다면, 열공간(column space) 이라는 개념이 해의 존재 여부를 알려줄거야. 영공간(null space) 라는 개념이 주는 것은 모든 가능한 해집합이 어떻게 될지를 알려줘.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "",
  "from_community_srt": "다시 말하지만, 여기서 다루지 않은 많은 것들이 남아있어. 특히 이것을 어떻게 계산해야 하는지는 다루지 않았어.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "또 예를들때 제한을 두어서 방정식의 갯수와 미지수 갯수가 동일하게 했어.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "",
  "from_community_srt": "그러나 여기에서 목표는 모든 것을 가르치는게 아니야. 역행렬, 열공간, 영공간에 대한 튼튼한 직관을 따르게 하는 거야. 그리고 이런 직관은 나중에 다른 것들을 학습할때 더 많은 결실을 맺게 해줄거야.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "",
  "from_community_srt": "다음 동영상에는, 많은 요청이 있었는데, 비정사각형 행렬에 대해 간략하게 다룰거야.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "",
  "from_community_srt": "그런 다음, 그 후, 나는 dot product 에 대해 다룰거야. 나중에 너가 보면 알겠지만, 정말 멋질 거야. 선형변환이라는 빛 아래서 살펴보게되면 말야.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]