[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "지금쯤이면 알 수 있듯이 이 시리즈의 대부분은 선형 변환이라는 시각적 렌즈를 통해 행렬과 벡터 연산을 이해하는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "지금쯤이면 아마도 알거야 이 동영상 시리즈의 대부분이 행렬과 벡터연산의 이해를 선형변환의 시각화 렌즈를 통해서 본거지.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "이 영상도 예외는 아니며 역행렬, 컬럼 스페이스, 랭크, 널 스페이스의 개념을 해당 렌즈를 통해 설명합니다.",
  "model": "google_nmt",
  "from_community_srt": "이 동영상도 마찬가지야. 역행렬(inverse matrix) 개념을 설명할때나 열공간, 계수(rank), 영공간(null space) 설명할때도 그런 렌즈를 통해서 설명할거야.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "미리 경고하지만 실제로 이러한 것들을 계산하는 방법에 대해서는 이야기하지 않을 것이며 어떤 사람들은 그것이 매우 중요하다고 주장할 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "미리 말해두건대, 이런 것들을 실제 계산하는 방법에 대해서는 다루지 않을거야. 누구에게는 그게 꽤 중요할 수도 있지만.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "이 시리즈 외에도 가우스 제거 및 행 사다리꼴 키워드와 같은 방법을 학습할 수 있는 매우 유용한 리소스가 많이 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "다른 동영상들을 찾아보면 그런 계산법을 다루는 좋은 게 많이 있을거야. 검색할때 키워드로 \"가우스 소거법(Gaussian elimination)\" 나 \"Row echelon form\" 이라고 검색해봐.",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "제가 실제로 여기에 추가해야 할 가치의 대부분은 직관 절반에 있다고 생각합니다.",
  "model": "google_nmt",
  "from_community_srt": "내가 여기서 설명하려고 하는 것, 나머지 직관부분이 더 중요하다고 생각해.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "게다가 실제로 우리는 대개 이런 것들을 계산하는 소프트웨어를 얻습니다.",
  "model": "google_nmt",
  "from_community_srt": "또, 실제로 이런 것들을 계산해주는 소프트웨어를 보통 구할 수 있어.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "먼저, 선형 대수학의 유용성에 대해 몇 마디 하겠습니다.",
  "model": "google_nmt",
  "from_community_srt": "우선,",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "지금까지 공간 조작을 설명하는 데 이 단어가 어떻게 사용되는지에 대한 힌트가 이미 있습니다. 이는 컴퓨터 그래픽 및 로봇공학과 같은 분야에 유용합니다.",
  "model": "google_nmt",
  "from_community_srt": "선형대수의 유용성에 몇마디 말하자면 지금쯤이면 너는 이미 공간의 조작에 대한 설명이라는 힌트는 가지고 있을거야. 컴퓨터 그래픽이나 로봇 분야에서 유용하지.",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "그러나 선형 대수가 더 광범위하게 적용 가능하고 거의 모든 기술 분야에 필요한 주요 이유 중 하나는 특정 방정식 시스템을 풀 수 있다는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "그러나 선형대수가 훨씬 광범위하게 적용가능하다고 하는 주된 이유는, , 어떤 기술적 분야이든지 필요하다고 하는 이유는, 어떤 방정식계이든지 해결할 수 있기 때문이야.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "내가 방정식 시스템이라고 말할 때, 변수 목록, 모르는 것, 그리고 이들과 관련된 방정식 목록이 있다는 뜻입니다.",
  "model": "google_nmt",
  "from_community_srt": "여기서 \"방정식계(system of equations)\" 란, 미지수인 변수 리스트와 변수들과 관련된 방정식의 리스트를 가졌을때를 말해.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "많은 상황에서 이러한 방정식은 매우 복잡해질 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "많은 상황에서, 이런 방정식들은 상당히 복잡해.",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "하지만 운이 좋다면 특별한 형태를 취할 수도 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "하지만, 운이 좋으면 이렇게 어떤 특정한 형태로 다룰 수 있어.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "각 방정식 내에서 각 변수에 발생하는 유일한 일은 일부 상수에 의해 크기가 조정된다는 것입니다. 그리고 이러한 크기 조정된 각 변수에 발생하는 유일한 일은 서로 추가된다는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "각 방정식 내에서, 각 변수들의 역할은 어떤 상수를 스케일링하는 거야. 그리고 스케일된 변수들을 서로 더하는게 전부야.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "따라서 지수나 고급 함수, 두 변수를 곱하는 등의 작업은 없습니다.",
  "model": "google_nmt",
  "from_community_srt": "지수함수나 어떤 특이한 함수같은 건 없어. 두 변수를 서로 곱하는 것도 없고 말야.",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "이러한 종류의 특별한 방정식 시스템을 구성하는 일반적인 방법은 모든 변수를 왼쪽에 배치하고 남아 있는 상수를 오른쪽에 배치하는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "이런 변수들을 조직화한 게 일종의 특수한 방정식계야. 모든 변수들을 좌항으로 던지고, 오른쪽에는 상수항을 놓아.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "공통 변수를 수직으로 정렬하는 것도 좋은데, 그렇게 하려면 변수가 방정식 중 하나에 표시되지 않을 때마다 일부 0 계수를 입력해야 할 수도 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "세로 방향으로도 같은 변수끼리 열맞추는 것도 좋아. 이렇게 하다보면 숫자가 0 인 변수도 있어서 하나의 방정식에 어떤 변수가 없을때도 있지.",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "이를 선형 방정식 시스템이라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "이렇게 놓은 것을 \"선형 방정식계(linear system of equations)\" 라고 해.",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "이것이 행렬-벡터 곱셈과 매우 유사하다는 것을 알 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬-벡터 곱셈이랑 많이 비슷해보이는 걸 눈치챘을거야.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "실제로 모든 방정식을 하나의 벡터 방정식으로 묶을 수 있습니다. 여기서는 모든 상수 계수를 포함하는 행렬과 모든 변수를 포함하는 벡터를 가지며, 해당 행렬-벡터 곱은 다른 상수 벡터와 같습니다.",
  "model": "google_nmt",
  "from_community_srt": "사실, 모든 방정식들을 하나의 벡터방정식으로 표현할 수 있어. 상수 계수만을 모아서 행렬을 만들고, 변수들을 모아서 벡터를 만들어서 행렬 벡터 곱셈하면 다른 상수벡터랑 같아져.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "해당 상수 행렬의 이름을 A로 지정하고, 변수가 포함된 벡터를 굵은 X로 표시하고, 오른쪽에 있는 상수 벡터를 V라고 부르겠습니다.",
  "model": "google_nmt",
  "from_community_srt": "상수 행렬을 A 라고 하자. 굵은 x 변수는 벡터를 나타내도록 하고 오른쪽의 상수 벡터를 v 라고 하자.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "이는 방정식 시스템을 한 줄에 작성하기 위한 단순한 표기법 이상의 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "이렇게 쓴 한 줄은 선형방정식계를 짧게 표현한 것일 뿐이야.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "그것은 문제에 대한 아주 멋진 기하학적 해석을 밝혀줍니다.",
  "model": "google_nmt",
  "from_community_srt": "이렇게 표현하는 것은 문제에 대해 상당히 멋진 기하학적 해석을 들어나게 해줘.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "행렬 A는 일부 선형 변환에 해당하므로 Ax = V를 풀면 변환을 적용한 후 V에 도달하는 벡터 X를 찾는다는 의미입니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬 A 는 어떤 선형변환을 나타내고, 그럼 Ax = v  를 푸는 것은 변환후에는 벡터 v 가 되는 벡터 x 가 있는지 찾아보는게 돼.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "잠시 여기서 무슨 일이 일어나고 있는지 생각해 보세요.",
  "model": "google_nmt",
  "from_community_srt": "무슨 말인지 잠깐 생각해보자.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "공간을 찌그러뜨리고 모핑하고 어떤 벡터가 다른 벡터에 도달하는지 알아내려고 노력하는 것만으로도 여러 변수가 서로 뒤섞여 있다는 정말 복잡한 아이디어를 머릿속에 담을 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "너는 여러 변수들 모두를 섞은 복잡한 개념을 머리속에 담으려면 그냥 공간을 변형시키는 것으로 생각하고, 어떤 벡터가 어디로 이동하는지만 찾으려고 하면 돼.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "멋지죠?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "간단하게 시작하려면 두 개의 방정식과 두 개의 미지수가 있는 시스템이 있다고 가정해 보겠습니다.",
  "model": "google_nmt",
  "from_community_srt": "멋지지 않아? 간단하게 시작해보자, 2개의 미지수를 가진 두개의 방정식 계를 생각해보자.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "이는 행렬 A가 2x2 행렬이고 V와 X가 각각 2차원 벡터임을 의미합니다.",
  "model": "google_nmt",
  "from_community_srt": "이때 행렬 A는 2 × 2 행렬이 되고, v 와 x 벡터는 2차원 벡터가 돼.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "이제 이 방정식의 해법에 대해 생각하는 방법은 A와 관련된 변환이 모든 공간을 선이나 점과 같은 하위 차원으로 찌그러뜨리는지 아니면 시작했던 전체 2차원에 걸쳐 모든 것을 남겨두는지에 따라 달라집니다.",
  "model": "google_nmt",
  "from_community_srt": "이제, 이 방정식의 해를 찾는 방법은 행렬 A 변환이 모든 공간을 더 낮은 차원으로 축소시키는지, 선이나 점같은 공간으로, 아니면 공간 전부가 그대로 남는지를 알아보는게 시작점이야.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "지난 영상의 언어에서는 A의 행렬식이 0인 경우와 A의 행렬식이 0이 아닌 경우로 세분화됩니다.",
  "model": "google_nmt",
  "from_community_srt": "지난 동영상에서 다룬 말을 빌리자면, 행렬 A 의 행렬식 값이 0 인지, 아니면 0 값이 아닌지로 나누는 것과 같아.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "행렬식이 0이 아닌 가장 가능성이 높은 경우부터 시작하겠습니다. 즉, 공간이 0 영역 영역으로 찌그러지지 않음을 의미합니다.",
  "model": "google_nmt",
  "from_community_srt": "우선은 가장 흔한 경우인 행렬식값이 0이 아닌 경우부터 살펴보자., 공간을 제로 영역으로 축소시키지 않는 경우야.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "이 경우 V에 도달하는 벡터는 항상 단 하나뿐이며 변환을 역으로 실행하여 찾을 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "이 경우, 특정 v 벡터로 변할 수 있는 벡터는 항상 하나만 있어. (역자: 일대일 대응 변환) 변환을 역방향으로 돌리면 찾을 수 있어.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "이렇게 테이프를 되감으면서 V가 가는 곳을 따라가면 A 곱하기 x가 V와 같은 벡터 x를 찾을 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "뒤로감기처럼 플레이하며 벡터 v 가 어디로 가는지 따라가보면 벡터 x 를 찾을 수 있을거야. Ax = v 에서 x 를 말야.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "변환을 역방향으로 실행하면 실제로는 일반적으로 A의 역이라고 불리는 별도의 선형 변환에 해당하며 A에서 음수로 표시됩니다.",
  "model": "google_nmt",
  "from_community_srt": "역으로 변환하는 것, 이것은 일반적으로 \"A의 역행렬(the inverse of A)\" 이라고 해. A 의 윗첨자로 -1 을 표시해놓지.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "예를 들어 A가 시계 반대 방향으로 90도 회전했다면 A의 역회전은 시계 방향으로 90도 회전한 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "예를 들어, A가 반 시계 방향으로 90 ° 회전이라면 그 역은 시계방향으로 90 ° 회전일거야.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "A가 j-hat을 한 단위 오른쪽으로 밀어내는 오른쪽 전단이라면 A의 역전단은 j-hat을 왼쪽으로 한 단위를 밀어내는 왼쪽 전단이 됩니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬 A 가 j-hat 을 오른쪽 한칸만큼 기울이는 변환이라면 그 역은 j-hat 왼쪽 방향으로 한칸만큼 기울이는 변환이야.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "일반적으로 A 역은 먼저 A를 적용한 다음 변환 A 역을 적용하면 결국 시작한 곳으로 돌아가는 속성을 갖는 고유한 변환입니다.",
  "model": "google_nmt",
  "from_community_srt": "일반적으로, A 역행렬의 특별한 속성은 A 행렬을 적용한 뒤, 그다음 A 역행렬을 적용하면, 다시 시작한 점으로 돌아오게 돼.",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "하나의 변환을 연이어 적용하는 것은 행렬 곱셈을 통해 대수적으로 캡처되므로 이 변환 A 역의 핵심 속성은 A 역과 A의 곱이 아무것도 하지 않는 것에 해당하는 행렬과 같다는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "이렇게 연달아 적용하는 변환을 행렬 곱셈으로 대수적 축약할 수 있어. 그래서 A역행렬 변환이 가진 핵심속성은 이거야. A역행렬 곱하기 A행렬은 아무 것도 바꾸지 않는 행렬과 같다는 것.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "아무것도 하지 않는 변환을 항등 변환이라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "아무것도하지 않는 변환을 \"항등 변환(identity transformation)\" 이라고 불러.",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "i-hat과 j-hat은 각각 그대로 그대로 두므로 열은 1,0과 0,1이 됩니다.",
  "model": "google_nmt",
  "from_community_srt": "i-hat 과 j-hat 을 이동시키지 않고 놔두지. 그래서 그대로 (1,0),(0,1) 이야.",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "실제로 컴퓨터를 사용하여 이 역행렬을 찾은 후에는 이 역행렬에 v를 곱하여 방정식을 풀 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "일단 역행렬을 찾았으면, , 수동으로 했든 컴퓨터를 사용했든, 방정식 역행렬을 v 벡터에 곱해서 풀 수 있어.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "그리고 다시, 이것이 기하학적으로 의미하는 것은 v를 따르는 변환을 역으로 수행한다는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "자 다시한번, 기하학적으로 이 말이 무슨 뜻이냐면, v 벡터에 역변환을 가한거야.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "행렬의 무작위 선택에 대해 가장 가능성이 높은 이 0이 아닌 행렬식 사례는 두 개의 미지수와 두 개의 방정식이 있는 경우 단일 고유 솔루션이 있는 경우가 거의 확실하다는 아이디어와 일치합니다.",
  "model": "google_nmt",
  "from_community_srt": "이렇게 행렬식 값이 0이 아닌 경우에, 아무렇게나 랜덤하게 행렬을 만들면 대부분 이 경우일텐데, 이게 2개의 미지수에 2개의 방정식을 가진 문제와 똑같아져. 이런 경우 대부분은 확실히 하나의 유일한 해가 존재해.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "이 아이디어는 방정식의 수가 미지수의 수와 같을 때 더 높은 차원에서도 의미가 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "이 아이디어는 더 높은 차원에서도 맞아. 미지수 개수와 방정식 개수가 같은 경우 또다시,",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "다시 말하지만, 방정식 시스템은 변환 A와 벡터 v가 있고 v에 도달하는 벡터 x를 찾는 기하학적 해석으로 변환될 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "방정식계는 기하학적 해석으로 변환해서 어떤 변환을 나타내는 A 행렬과 어떤 벡터 v 를 가지고 벡터 v 로 변환되는 벡터 x 를 찾는 게 되지.",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "변환 A가 모든 공간을 더 낮은 차원으로 압축하지 않는 한, 즉 행렬식은 0이 아님을 의미하며, A를 먼저 수행하면 A를 역으로 수행하는 속성을 갖는 역변환 A 역이 발생합니다. , 아무것도하지 않는 것과 같습니다.",
  "model": "google_nmt",
  "from_community_srt": "변환 A 가 공간을 더 낮은 차원으로 뭉게지 않는 한, 즉, 행렬식 값이 0 이 아닌 경우, 역행렬 A 가 존재하게 돼. 이 역행렬의 속성은 A 를 적용한 뒤, A 역행렬을 적용하면, 아무것도 변하지 않는 거지.",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "방정식을 풀려면 역변환 행렬에 벡터 v를 곱하면 됩니다.",
  "model": "google_nmt",
  "from_community_srt": "그리고 이 방정식을 푼다는 것은, 역행렬을 v 벡터에 곱하는 것이고.",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "그러나 행렬식이 0이고 방정식 시스템과 관련된 변환이 공간을 더 작은 차원으로 압축하면 역행렬이 없습니다.",
  "model": "google_nmt",
  "from_community_srt": "하지만 행렬식 값이 0이면, 그리고 이 방정식계에 대한 변환이 더 작은 차원으로 뭉게버린다면, 역행렬은 존재하지 않게돼.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "선을 풀어 평면으로 바꿀 수는 없습니다.",
  "model": "google_nmt",
  "from_community_srt": "뭉게진 선을 되돌려서 평면으로 만들 수 없어.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "적어도 그것은 함수가 할 수 있는 일이 아닙니다.",
  "model": "google_nmt",
  "from_community_srt": "적어도, 그 함수가 할 수 있는 일이 아니야.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "이를 위해서는 각 개별 벡터를 벡터로 가득 찬 전체 라인으로 변환해야 합니다.",
  "model": "google_nmt",
  "from_community_srt": "그렇게 하려면 필요한게, 각 벡터를 변환시켜서 하나의 온전한 선, 선을 이루는 모든 벡터로 바꿔야 해.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "그러나 함수는 단일 출력에 대한 단일 입력만 받을 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "하지만, 함수들은 하나의 입력을 받아 하나의 출력만 만들어.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "마찬가지로, 3개의 방정식과 3개의 미지수의 경우 해당 변환이 3D 공간을 평면으로 찌그러뜨리거나 선이나 점으로 찌그러뜨리더라도 역이 발생하지 않습니다.",
  "model": "google_nmt",
  "from_community_srt": "마찬가지로, 3개 미지수로 구성된 3개의 방정식에서도 이같은 변환을 나타낼 길은 없어. 3차원 공간을 평면으로 축소시키거나 또는 선이나 점으로 뭉게뜨리는 것은 가능해도 말야.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "모든 영역은 볼륨이 0인 영역으로 압축되기 때문에 이들 모두는 0의 행렬식에 해당합니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬식 값 0 인 모든 것은 어떤 지역이라도 영부피로 만들기 때문에 해는 여전히 존재할 수 있긴 해.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "역이 없더라도 해가 존재할 가능성은 여전히 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "역행렬이 없는 경우라도 말야.",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "변환이 공간을 예를 들어 선으로 압축할 때 벡터 v가 해당 선의 어딘가에 있을 만큼 운이 좋아야 합니다.",
  "model": "google_nmt",
  "from_community_srt": "어떤 변환이 공간을 하나의 선으로 변환시키는 경우라면, 벡터 v 가 그 선 위에 놓여있는 경우가 다행인 거야. (역자:",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "이러한 제로 결정자 사례 중 일부는 다른 사례보다 훨씬 더 제한적으로 느껴질 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "이때만 해를 구할 수 있다) 너는 아마도 행렬식 0 값인 경우가 다른 경우보다 제한되는 느낌을 받을 거야.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "예를 들어 3x3 행렬이 주어지면 두 가지 모두 행렬식이 0임에도 불구하고 공간을 평면에 뭉개는 경우에 비해 공간을 선에 뭉개는 경우 솔루션이 존재하기가 훨씬 더 어려워 보입니다.",
  "model": "google_nmt",
  "from_community_srt": "3x3 행렬을 예를들면, 해가 존재하기 상당히 힘들어 지는 경우가 있어. 공간을 하나의 선으로 수축하는 경우가 공간을 평면으로 수축하는 경우보다 더 말야. 심지어 둘 다 행렬식 값은 0 으로 같은데도 말야.",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "행렬식이 0이라고 말하는 것보다 좀 더 구체적인 언어가 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "이 경우 우리는 단순히 \"행렬식 0(zero determinant)\" 보다 더 정확한 표현이 필요한 거 같아.",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "변환의 출력이 선(1차원임을 의미)인 경우 변환의 순위가 1이라고 말합니다.",
  "model": "google_nmt",
  "from_community_srt": "변환의 결과가 선이라면, 즉 1차원 이라면, 이 경우 랭크(rank)=1 이라고 해.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "모든 벡터가 2차원 평면에 있는 경우 변환의 순위는 2라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "모든 벡터가 2차원 평면에 놓여있다면, 이때는 랭크(rank)=2 라고 말해.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "따라서 순위라는 단어는 변환 출력의 차원 수를 의미합니다.",
  "model": "google_nmt",
  "from_community_srt": "그래서 단어 \"랭크(rank)\" 의 의미는 변환 결과의 차원의 수를 말해주지.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "예를 들어 2x2 행렬의 경우 2순위가 가장 좋습니다.",
  "model": "google_nmt",
  "from_community_srt": "예를 들어, 2 × 2 행렬의 경우에, 최대로 될 수 있는 랭크는 2야.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "이는 기저 벡터가 공간의 전체 2차원에 걸쳐 계속 확장되고 행렬식은 0이 아니라는 것을 의미합니다.",
  "model": "google_nmt",
  "from_community_srt": "이 말은 기저벡터들을 확장시켜 온전한 2차원 공간을 만들 수 있다는 거야. 행렬식 값이 0 이 아니라는 뜻이지.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "그러나 3x3 행렬의 경우 2순위는 우리가 무너졌음을 의미하지만 1순위 상황만큼 무너지지는 않습니다.",
  "model": "google_nmt",
  "from_community_srt": "그러나 3 × 3 행렬에서, 랭크가 2 라는 말은 공간이 붕괴(축소) 했음을 말해. 하지만 랭크 1 만큼 붕괴된 것은 아닌 거지.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "3D 변환의 행렬식이 0이 아니고 출력이 3D 공간 전체를 채우는 경우 순위는 3입니다.",
  "model": "google_nmt",
  "from_community_srt": "3차원 변환의 행렬식 값이 0 이 아니라면, 3차원 공간의 결과가 온전한 3차원이라면, 이때는 랭크 3 이야.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "선, 평면, 3D 공간 등 행렬에 대해 가능한 모든 출력 집합을 행렬의 열 공간이라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬의 가능한 결과의 집합을 , 선이든, 평면이든, 3차원 공간이든지 간에, 그 행렬의 \"열 공간(column space)\"라고 불러.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "그 이름이 어디서 왔는지 추측할 수 있을 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "넌 지금쯤 이 이름이 어떻게 나왔는지 알 수 있을거야.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "행렬의 열은 기저 벡터가 어디에 있는지 알려주고, 변환된 기저 벡터의 범위는 가능한 모든 출력을 제공합니다.",
  "model": "google_nmt",
  "from_community_srt": "행렬의 열들은 기저벡터의 변환 후 위치이고, 이 변환후 기저벡터들의 확장공간은 가능한 모든 결과공간을 알려주지.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "즉, 열 공간은 행렬 열의 범위입니다.",
  "model": "google_nmt",
  "from_community_srt": "즉, 열 공간(column space) 란, 행렬의 열들의 확장공간이야.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "따라서 순위에 대한 보다 정확한 정의는 열 공간의 차원 수라는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "그래서, 랭크의 좀 더 정확한 정의는 열공간의 차원 수야.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "이 순위가 가능한 한 높을 때(즉, 열 수와 동일함을 의미) 행렬을 전체 순위라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "이 랭크가 높아질 수록, 열의 갯수와 같다는 말이고, 이 때를 \"온전한 랭크(full rank)\" 라고 불러.",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "선형 변환은 원점을 제자리에 고정해야 하기 때문에 영 벡터가 항상 열 공간에 포함됩니다.",
  "model": "google_nmt",
  "from_community_srt": "기억해야할 것은, 영 벡터(zero vector)는 어느 열공간에든지 포함되어 있다는 거야. 선형변환은 반드시 원점이 고정되어 있어야 하기 때문이야. (역자:",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "전체 순위 변환의 경우 원점에 도달하는 유일한 벡터는 0 벡터 자체입니다.",
  "model": "google_nmt",
  "from_community_srt": "앞선 \"linear tranformation\" 챕터 확인) 완전한 랭크(full rank) 인 변환에서, 원점으로 변하는 벡터는 영벡터 뿐이야.",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "그러나 더 작은 차원으로 찌그러지는 전체 순위가 아닌 행렬의 경우 0에 도달하는 벡터 전체를 가질 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "그렇지만 행렬이 온전한 랭크(full rank) 가 아니라면, 즉 더 작은 차원으로 축소된다면, 제로벡터가 되는 수많은 벡터들을 가지게 될거야.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "예를 들어, 2D 변환이 공간을 선으로 찌그러뜨리는 경우 원점에 찌그러지는 벡터로 가득 찬 다른 방향에 별도의 선이 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "2 차원 변환에서 선으로 축소되는 경우를 예를 들게. 서로 다른 방향을 가리키는 벡터들이지만 같이 원점으로 뭉게지는 수 많은 벡터들이 있어.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "3D 변환으로 인해 공간이 평면으로 찌그러지면 원점에 도달하는 전체 벡터 라인도 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "3 차원 변환이 평면으로 축소되는 예를 들면, 마찬가지로 원점으로 이동하는 선의 수많은 벡터들이 존재해.",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "3D 변환으로 인해 모든 공간이 선으로 압축되면 원점에 도달하는 벡터로 가득 찬 전체 평면이 있게 됩니다.",
  "model": "google_nmt",
  "from_community_srt": "3차원 변환이 공간을 선으로 축소시킨다면, 한 평면의 모든 벡터들이 원점으로 이동하게 돼.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "원점에 있는 이 벡터 집합을 널 공간 또는 행렬의 커널이라고 합니다.",
  "model": "google_nmt",
  "from_community_srt": "원점으로 이동되는 벡터들의 집합을 그 행렬의 \"영공간(null space)\" 혹은 \"커널(kernel)\" 이라고 불러.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "0 벡터에 도달한다는 의미에서 null이 되는 모든 벡터의 공간입니다.",
  "model": "google_nmt",
  "from_community_srt": "그것은 널 (null)이 되는 모든 벡터의 공간이라는 뜻이야. 이 벡터들 모두 영벡터로 이동한다는 말이야.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "선형 방정식 시스템의 관점에서 v가 영 벡터일 때 영공간은 방정식에 대한 가능한 모든 해를 제공합니다.",
  "model": "google_nmt",
  "from_community_srt": "선형 방정식계 용어로 말하면, 벡터v 가 영벡터인 경우, 영공간(null space) 모두가 해가 될 수 있어.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "이것은 선형 방정식 시스템을 기하학적으로 생각하는 방법에 대한 매우 높은 수준의 개요입니다.",
  "model": "google_nmt",
  "from_community_srt": "그럼 좀 더 높여서 훑어보자. 선형방정식계가 기하학적으로 어떻게 생각할 수 있는지 정리해보자.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "각 시스템에는 이와 관련된 일종의 선형 변환이 있으며 해당 변환에 역이 있는 경우 해당 역을 사용하여 시스템을 풀 수 있습니다.",
  "model": "google_nmt",
  "from_community_srt": "각 계(system)는 선형변환과 같은 것을 가지고 그와 관련된 선형 변환의 일종, 그 변환이 역변환을 가지면, 계(system) 를 풀기 위해 역변환을 사용하면 돼.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "그렇지 않으면 열 공간의 개념을 통해 해가 언제 존재하는지 이해할 수 있으며, 널 공간의 개념은 가능한 모든 해의 집합이 어떻게 생겼는지 이해하는 데 도움이 됩니다.",
  "model": "google_nmt",
  "from_community_srt": "그게 안된다면, 열공간(column space) 이라는 개념이 해의 존재 여부를 알려줄거야. 영공간(null space) 라는 개념이 주는 것은 모든 가능한 해집합이 어떻게 될지를 알려줘.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "다시 말하지만, 여기서 다루지 않은 내용이 많이 있습니다. 특히 이러한 항목을 계산하는 방법이 가장 두드러집니다.",
  "model": "google_nmt",
  "from_community_srt": "다시 말하지만, 여기서 다루지 않은 많은 것들이 남아있어. 특히 이것을 어떻게 계산해야 하는지는 다루지 않았어.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "또한 방정식의 수가 미지수의 수와 동일한 예로 범위를 제한해야 했습니다.",
  "model": "google_nmt",
  "from_community_srt": "또 예를들때 제한을 두어서 방정식의 갯수와 미지수 갯수가 동일하게 했어.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "그러나 여기서의 목표는 모든 것을 가르치려고 노력하는 것이 아니라 역행렬, 열 공간 및 널 공간에 대한 강력한 직관을 갖고 이러한 직관을 통해 향후 학습을 더욱 유익하게 만드는 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "그러나 여기에서 목표는 모든 것을 가르치는게 아니야. 역행렬, 열공간, 영공간에 대한 튼튼한 직관을 따르게 하는 거야. 그리고 이런 직관은 나중에 다른 것들을 학습할때 더 많은 결실을 맺게 해줄거야.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "다음 비디오는 많은 분들의 요청에 따라 비정사각형 행렬에 대한 간략한 각주가 될 것입니다.",
  "model": "google_nmt",
  "from_community_srt": "다음 동영상에는, 많은 요청이 있었는데, 비정사각형 행렬에 대해 간략하게 다룰거야.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "그런 다음 내적에 대한 내 생각과 이를 선형 변환의 관점에서 볼 때 발생하는 매우 멋진 현상에 대해 설명하겠습니다.",
  "model": "google_nmt",
  "from_community_srt": "그런 다음, 그 후, 나는 dot product 에 대해 다룰거야. 나중에 너가 보면 알겠지만, 정말 멋질 거야. 선형변환이라는 빛 아래서 살펴보게되면 말야.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]