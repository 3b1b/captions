[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Jak już zapewne zauważyłeś, większość tej serii dotyczy zrozumienia operacji na macierzach i wektorach przez bardziej wizualną perspektywę transformacji liniowych.",
  "model": "google_nmt",
  "from_community_srt": "\"Zadać właściwe pytanie jest trudniejsze niż udzielenie na nie odpowiedzi.\" -Georg Cantor Jak już zapewne zauważyłeś, kładę w tych filmach nacisk na rozumienie macierzy i operacji wektorowych i operacji na wektorach z użyciem wyobraźni przestrzennej.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Ten film nie jest wyjątkiem i opisuje koncepcje macierzy odwrotnych, przestrzeni kolumnowej, rangi i przestrzeni zerowej przez tę perspektywę.",
  "model": "google_nmt",
  "from_community_srt": "Ten film nie będzie wyjątkiem, omawiając koncepcje odwracania macierzy, przestrzeni kolumn, rzędu i pustej przestrzeni w ten sposób.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Jednak ostrzegam: nie będę mówił o metodach faktycznego obliczania tych rzeczy, a niektórzy twierdzą, że jest to dość ważne.",
  "model": "google_nmt",
  "from_community_srt": "Uprzedzę jednak: nie zamierzam mówić o metodach obliczeniowych, a niektórzy będą argumentować że to bardzo ważne.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Istnieje wiele bardzo dobrych zasobów do nauki tych metod spoza tej serii, słowa kluczowe eliminacja Gaussa i forma rzutu wierszowego.",
  "model": "google_nmt",
  "from_community_srt": "Jest bardzo dużo dobrych materiałów omawiających metody obliczeniowe poza tą serią filmów. Słowa kluczowe:",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Myślę, że większość wartości, które muszę tu dodać, dotyczy intuicji.",
  "model": "google_nmt",
  "from_community_srt": "\"eliminacja gaussa\" i \"macierz schodkowa\" Uważam że najwięcej mogę tu dodać w kwestii intuicji.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Poza tym w praktyce zwykle dostajemy oprogramowanie, które i tak oblicza nam te rzeczy.",
  "model": "google_nmt",
  "from_community_srt": "Dodatkowo - w praktyce - zazwyczaj mamy programy które to za nas obliczają.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "Najpierw kilka słów o przydatności algebry liniowej.",
  "model": "google_nmt",
  "from_community_srt": "Na wstępie kilka słów o użyteczności algebry liniowej.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "Masz już podpowiedź, jak go używać do opisu manipulacji przestrzenią, co jest przydatne w takich rzeczach, jak grafika komputerowa i robotyka.",
  "model": "google_nmt",
  "from_community_srt": "Póki co, masz już odczucie jak jest używana do opisu manipulacji przestrzennej, co jest przydatne w temacie grafiki komputerowej i robotyki,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "Jednak jednym z głównych powodów, dla których algebra liniowa ma szersze zastosowanie i jest wymagana w niemal każdej dyscyplinie technicznej, jest to, że pozwala nam rozwiązywać określone układy równań.",
  "model": "google_nmt",
  "from_community_srt": "ale jednym z głównych powodów dla których algebra liniowa jest szeroko stosowana, i wymagana w zasadniczo każdej dziedzinie technicznej, jest to że pozwala nam rozwiązywać pewne układy równań.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Kiedy mówię układ równań, mam na myśli listę zmiennych, rzeczy, których nie znasz, i listę równań z nimi związanych.",
  "model": "google_nmt",
  "from_community_srt": "Kiedy mówię \"układ równań\", mam na myśli iż mamy zbiór zmiennych które musimy odgadnąć, i zbiór równań opisujących je.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "W wielu sytuacjach równania te mogą stać się bardzo skomplikowane.",
  "model": "google_nmt",
  "from_community_srt": "W wielu przypadkach te równania mogą stać się bardzo złożone, ale,",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "Ale jeśli masz szczęście, mogą przybrać pewną specjalną formę.",
  "model": "google_nmt",
  "from_community_srt": "przy odrobinie szczęścia,",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "W każdym równaniu jedyną rzeczą, która dzieje się z każdą zmienną jest to, że jest ona skalowana przez jakąś stałą, a jedyną rzeczą, która dzieje się z każdą z tych skalowanych zmiennych jest to, że są one do siebie dodawane.",
  "model": "google_nmt",
  "from_community_srt": "mogą przyjąć pewną specjalną formę. W każdym równaniu jedyną rzeczą która dotyka każdej zmiennej jest to że skaluje się przez pewną stałą, a jedyną rzeczą która spotyka te przeskalowane zmienne jest to że dodają się do siebie.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Żadnych wykładników, wymyślnych funkcji, mnożenia dwóch zmiennych i tym podobnych.",
  "model": "google_nmt",
  "from_community_srt": "Zatem, żadnych potęg lub dziwnych funkcji, mnożenia zmiennych przez siebie - ani innych takich rzeczy.",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "Typowym sposobem zorganizowania tego rodzaju specjalnego układu równań jest przerzucenie wszystkich zmiennych po lewej stronie i umieszczenie pozostałych stałych po prawej stronie.",
  "model": "google_nmt",
  "from_community_srt": "Zwyczajowym sposobem opisu tego systemu równań jest ułożenie wszystkich zmiennych po lewej, i pozostawienie stałych po stronie prawej.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "Przyjemnie jest także ułożyć w pionie wspólne zmienne i w tym celu może zaistnieć potrzeba dodania zerowych współczynników, ilekroć zmienna nie pojawia się w jednym z równań.",
  "model": "google_nmt",
  "from_community_srt": "Jest również wygodne ułożenie w jednej kolumnie tych samych zmiennych, a by to osiągnąć czasem trzeba dodać zerowe współczynniki.",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Nazywa się to liniowym układem równań.",
  "model": "google_nmt",
  "from_community_srt": "Nazywamy to \"liniowym układem równań\".",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Możesz zauważyć, że wygląda to podobnie do mnożenia wektorów macierzowych.",
  "model": "google_nmt",
  "from_community_srt": "Możemy zauważyć, że przypomina to bardzo mnożenie macierzy przez wektor.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "W rzeczywistości możesz spakować wszystkie równania w jedno równanie wektorowe, w którym masz macierz zawierającą wszystkie stałe współczynniki i wektor zawierający wszystkie zmienne, a ich iloczyn macierz-wektor jest równy pewnemu innemu wektorowi stałemu.",
  "model": "google_nmt",
  "from_community_srt": "Rzeczywiście, może spakować te wszystkie równania w jedno równanie wektorowe, w którym macierz zawiera wszystkie stałe współczynniki a wektor zawiera wszystkie zmienne, a iloczyn tej macierzy i wektora jest równy pewnemu innemu wektorowi ze stałymi.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "Nazwijmy tę macierz stałą A, oznaczmy wektor zawierający zmienne pogrubionym X i nazwijmy wektor stały po prawej stronie V.",
  "model": "google_nmt",
  "from_community_srt": "Nazwijmy tę macierz A, a wektor zawierający zmienne nazwijmy x, natomiast wektor stałych po prawej stronie v.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "To coś więcej niż tylko sztuczka z zapisem, pozwalająca zapisać nasz układ równań w jednej linii.",
  "model": "google_nmt",
  "from_community_srt": "Jest to coś więcej niż sprytny sposób zapisu pozwalający zapisać równania w jednej linii.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Rzuca światło na całkiem fajną geometryczną interpretację problemu.",
  "model": "google_nmt",
  "from_community_srt": "Naświetla nam świetny sposób geometrycznego rozumienia tego zagadnienia.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "Macierz A odpowiada pewnej transformacji liniowej, więc rozwiązanie Ax równego V oznacza, że szukamy wektora X, który po zastosowaniu transformacji ląduje na V.",
  "model": "google_nmt",
  "from_community_srt": "Macierz A odpowiada pewnej transformacji liniowej, zatem rozwiązanie Ax = v oznacza iż szukamy wektora x, który po nałożeniu transformacji,",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Pomyśl przez chwilę o tym, co się tutaj dzieje.",
  "model": "google_nmt",
  "from_community_srt": "staje się v. Zastanówmy się przez chwilę co tu się dzieje.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Możesz trzymać w głowie tę naprawdę skomplikowaną koncepcję wielu zmiennych, które przenikają się ze sobą, po prostu myśląc o zgniataniu i przekształcaniu przestrzeni oraz próbując dowiedzieć się, który wektor ląduje na innym.",
  "model": "google_nmt",
  "from_community_srt": "Można sobie wyobrazić ten skomplikowany problem wielu zmiennych mieszających się ze sobą poprzez myślenie o rozciąganiu i ściskaniu przestrzeni tak by zgadnąć który wektor przemieszcza się w inny.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Fajnie, prawda?",
  "model": "google_nmt",
  "from_community_srt": "Fajne,",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Na początek powiedzmy, że masz układ z dwoma równaniami i dwiema niewiadomymi.",
  "model": "google_nmt",
  "from_community_srt": "prawda? Zaczynając od prostego przykładu, weźmy układ dwóch równań z dwoma niewiadomymi.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "Oznacza to, że macierz A jest macierzą 2x2, a V i X są wektorami dwuwymiarowymi.",
  "model": "google_nmt",
  "from_community_srt": "Oznacza to że macierz A jest macierzą 2 na 2, v i x są dwu-wymiarowymi wektorami.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "To, jak myślimy o rozwiązaniach tego równania, zależy od tego, czy transformacja związana z A zgniata całą przestrzeń do niższego wymiaru, na przykład linii lub punktu, czy też pozostawia wszystko rozciągające się na pełne dwa wymiary w miejscu, w którym się zaczęło.",
  "model": "google_nmt",
  "from_community_srt": "Sposób w jaki myślimy o rozwiązaniach tego równania zależy od tego czy transformacja związana z A zmniejsza przestrzeń do mniejszej liczby wymiarów, jak linia czy punkt, czy też zostawia wszystko w przestrzeni dwuwymiarowej od której zaczęliśmy.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "W języku ostatniego filmu dzielimy się na przypadki, w których A ma wyznacznik zerowy i przypadek, w którym A ma wyznacznik niezerowy.",
  "model": "google_nmt",
  "from_community_srt": "W języku poprzedniego filmu, dzielimy to na przypadek gdzie A ma zerowy wyznacznik, oraz przypadek gdzie A ma niezerowy wyznacznik.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Zacznijmy od najbardziej prawdopodobnego przypadku, w którym wyznacznik jest różny od zera, co oznacza, że przestrzeń nie zostaje wciśnięta w obszar o zerowym obszarze.",
  "model": "google_nmt",
  "from_community_srt": "Zacznijmy od bardziej prawdopodobnego przypadku gdzie wyznacznik jest niezerowy, czyli przestrzeń nie zmniejsza się do zerowego rozmiaru.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "W tym przypadku zawsze będzie jeden i tylko jeden wektor, który wyląduje na V i możesz go znaleźć, odtwarzając transformację w odwrotnej kolejności.",
  "model": "google_nmt",
  "from_community_srt": "W tym przypadku będzie jeden i tylko jeden wektor który stanie się v, i możemy go znaleźć odtwarzając transformację od końca.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "Podążając za kierunkiem V podczas przewijania taśmy w ten sposób, znajdziesz wektor x taki, że A razy x równa się V.",
  "model": "google_nmt",
  "from_community_srt": "Podążając za v podczas gdy przewijamy taśmę do tyłu jak tutaj, znajdziemy taki wektor x iż A razy x wynosi v.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Kiedy odtworzysz transformację w odwrotnej kolejności, w rzeczywistości odpowiada ona oddzielnej transformacji liniowej, powszechnie zwanej odwrotnością A, oznaczanej A do liczby ujemnej.",
  "model": "google_nmt",
  "from_community_srt": "Kiedy odtwarzamy transformację do tyłu, zasadniczo odpowiada to innej transformacji liniowej, zazwyczaj nazywanej \"odwrotnością A\" zapisywanej jako A do potęgi -1.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Na przykład, jeśli A oznacza obrót o 90 stopni w kierunku przeciwnym do ruchu wskazówek zegara, wówczas odwrotnością A będzie obrót o 90 stopni w kierunku zgodnym z ruchem wskazówek zegara.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, jeśli A było obrotem przeciwnym do ruchu wskazówek zegara o 90 stopni, wtedy odwrotność A będzie obrotem zgodnym z ruchem wskazówek zegara o 90 stopni.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Jeżeli A byłoby ścinaniem w prawo, które wypycha j-hat o jedną jednostkę w prawo, odwrotnością A byłoby ścinaniem w lewo, które wypycha j-hat o jedną jednostkę w lewo.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli A była ścięciem które przesuwało j-z-daszkiem jedną jednostkę w prawo, wtedy odwrotność A będzie ścięciem przesuwającym j-z-daszkiem jedną jednostkę w lewo.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "Ogólnie rzecz biorąc, odwrotność jest unikalną transformacją mającą tę właściwość, że jeśli najpierw zastosujesz A, a następnie zastosujesz transformację odwrotną A, wrócisz tam, gdzie zacząłeś.",
  "model": "google_nmt",
  "from_community_srt": "Zasadniczo, odwrotność A jest unikalną transformacją mającą tą cechę że gdy pierwsze zaaplikujemy A, a później zaaplikujemy transformację odwrotną A,",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "Stosowanie jednej transformacji po drugiej jest rejestrowane algebraicznie za pomocą mnożenia macierzy, więc podstawową właściwością tej transformacji A jest to, że A odwrotność razy A równa się macierzy, która odpowiada nierobieniu niczego.",
  "model": "google_nmt",
  "from_community_srt": "znajdziemy się z powrotem w miejscu z którego wyszliśmy. Nakładanie jednej transformacji za drugą przedstawiamy algebraicznie za pomocą mnożenia macierzowego, zatem zasadniczą własnością transformacji odwrotność-z-A jest to, że odwrotność A razy A odpowiada macierzy która nic nie robi.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "Transformacja, która nic nie robi, nazywa się transformacją tożsamości.",
  "model": "google_nmt",
  "from_community_srt": "Transformacja która nic nie robi jest nazywana transformacją tożsamościową(identycznościową).",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "Pozostawia i-hat i j-hat tam, gdzie się znajdują, nieporuszone, więc jego kolumny to 1,0 i 0,1.",
  "model": "google_nmt",
  "from_community_srt": "Zostawia ona i-z-daszkiem oraz j-z-daszkiem tam gdzie były, nieruchomo, zatem jest kolumny to 1,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Kiedy już znajdziesz tę odwrotność, co w praktyce zrobiłbyś za pomocą komputera, możesz rozwiązać równanie, mnożąc tę macierz odwrotną przez v.",
  "model": "google_nmt",
  "from_community_srt": "0, i 0, 1. Kiedy już znajdziemy odwrotność, która w praktyce policzy za nas komputer, możemy rozwiązać nasze równanie przez mnożenie macierzy odwrotnej przez v.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "I znowu, geometrycznie oznacza to, że odtwarzasz transformację w odwrotnej kolejności i podążasz za v.",
  "model": "google_nmt",
  "from_community_srt": "Zatem to co oznacza to geometrycznie to odtworzenie transformacji wspak i podążanie za v.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Ten niezerowy przypadek wyznacznika, który w przypadku losowego wyboru macierzy jest zdecydowanie najbardziej prawdopodobny, koresponduje z koncepcją, że jeśli masz dwie niewiadome i dwa równania, prawie na pewno jest tak, że istnieje jedno unikalne rozwiązanie.",
  "model": "google_nmt",
  "from_community_srt": "Przypadek niezerowego wyznacznika, który dla dowolnie wybranej macierzy jest najbardziej prawdopodobny, odpowiada koncepcji dwóch zmiennych i dwóch równań, w której zwykle mamy jedno unikalne rozwiązanie.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Pomysł ten ma również sens w wyższych wymiarach, gdy liczba równań jest równa liczbie niewiadomych.",
  "model": "google_nmt",
  "from_community_srt": "Ta idea ma też sens przy większej ilości wymiarów, gdzie ilość równań jest taka sama jak liczba niewiadomych.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Ponownie, układ równań można przełożyć na interpretację geometryczną, w której masz transformację A i wektor v, i szukasz wektora x, który ląduje na v.",
  "model": "google_nmt",
  "from_community_srt": "I znowu, system równań może być przełożony na interpretację geometryczną, gdzie mamy pewną transformację, A, i pewien wektor,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "Dopóki transformacja A nie zgniecie całej przestrzeni do niższego wymiaru, co oznacza, że jej wyznacznik jest różny od zera, będzie miała miejsce transformacja odwrotna A odwrotna, z tą właściwością, że jeśli najpierw wykonasz A, to zrobisz też A odwrotne , to tak samo, jak nic nie robić.",
  "model": "google_nmt",
  "from_community_srt": "v, i szukamy wektora x który przemieści się w miejsce v. Tak długo jak transformacja A nie redukuje przestrzeni w mniejszą ilość wymiarów, czyli jej wyznacznik jest niezerowy, będzie istnieć transformacja odwrotna, odwrotność z A, mająca taka własność że jeśli pierwsze zrobimy A,",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "Aby rozwiązać równanie, wystarczy pomnożyć macierz odwrotnej transformacji przez wektor v.",
  "model": "google_nmt",
  "from_community_srt": "a potem odwrotność A, będzie to tym samym co zrobienie niczego. I by rozwiązać twoje równanie,",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Ale gdy wyznacznik wynosi zero, a transformacja związana z układem równań zgniata przestrzeń do mniejszego wymiaru, nie ma odwrotności.",
  "model": "google_nmt",
  "from_community_srt": "wystarczy że pomnożysz tą macierz transformacji odwrotnej przez wektor v. Lecz gdy wyznacznik jest zerem, i transformacja związana z tym układem równań redukuje przestrzeń w mniejszą ilość wymiarów, odwrotność nie istnieje.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Nie można rozgnieść linii, aby zamienić ją w płaszczyznę.",
  "model": "google_nmt",
  "from_community_srt": "Nie możesz od-zredukować prostej by przekształcić ją w płaszczyznę.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "Przynajmniej nie jest to coś, co funkcja może zrobić.",
  "model": "google_nmt",
  "from_community_srt": "A w każdym razie, nie jest to coś co może zrobić funkcja.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Wymagałoby to przekształcenia każdego pojedynczego wektora w całą linię pełną wektorów.",
  "model": "google_nmt",
  "from_community_srt": "Wymagałoby to przetworzenia każdego jednego wektora w całą linię pełną wektorów.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Ale funkcje mogą przenosić tylko jedno wejście na jedno wyjście.",
  "model": "google_nmt",
  "from_community_srt": "Lecz funkcje mogą brać tylko jedno wyjście i mieć jedno wyjście.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Podobnie w przypadku trzech równań i trzech niewiadomych nie będzie odwrotności, jeśli odpowiednia transformacja zgniecie przestrzeń 3D na płaszczyźnie lub nawet jeśli zgniecie ją na linii lub punkcie.",
  "model": "google_nmt",
  "from_community_srt": "Podobnie, dla trzech równań z trzema niewiadomymi, nie będzie odwrotności jeśli odpowiadająca transformacja redukuje przestrzeń 3D w płaszczyznę, lub nawet w prostą lub punkt.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Wszystkie odpowiadają wyznacznikowi zerowemu, ponieważ dowolny region jest wciśnięty w coś o zerowej objętości.",
  "model": "google_nmt",
  "from_community_srt": "Wszystkie one mają zerowy wyznacznik, ponieważ każdy obszar jest redukowany do czegoś o zerowej objętości.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "Nadal możliwe jest, że rozwiązanie istnieje, nawet jeśli nie ma odwrotności.",
  "model": "google_nmt",
  "from_community_srt": "Ciągle jest możliwe że rozwiązanie istnieje nawet gdy nie ma odwrotności, po prostu gdy transformacja redukuje przestrzeń w,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "Po prostu, kiedy twoja transformacja zgniata przestrzeń, powiedzmy, na linię, musisz mieć szczęście, że wektor v leży gdzieś na tej prostej.",
  "model": "google_nmt",
  "from_community_srt": "dla przykładu, linię, musisz mieć sporo szczęścia by wektor v znajdował się na tej linii.",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Możesz zauważyć, że niektóre z tych przypadków z determinantą zerową wydają się znacznie bardziej restrykcyjne niż inne.",
  "model": "google_nmt",
  "from_community_srt": "Możesz spostrzec że część z tych przypadków o zerowym wyznaczniku jest bardziej restrykcyjna niż inne.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Na przykład, biorąc pod uwagę macierz 3x3, wydaje się, że znacznie trudniej jest znaleźć rozwiązanie, które zgniata przestrzeń na linii, w porównaniu z sytuacją, gdy zgniata rzeczy na płaszczyźnie, mimo że oba te czynniki są wyznacznikami zerowymi.",
  "model": "google_nmt",
  "from_community_srt": "Mając macierz 3x3 (dla przykładu), wygląda na to że trudniej istnieć rozwiązaniu gdy redukuje ona przestrzeń do linii w porównaniu do sytuacji gdy redukuje przestrzeń do płaszczyzny,",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "Mamy pewien język, który jest nieco bardziej szczegółowy niż samo mówienie o wyznaczniku zera.",
  "model": "google_nmt",
  "from_community_srt": "mimo tego że w obu przypadkach mamy tak samo zerowy wyznacznik. Mamy pewien bardziej dokładny sposób opisania tej sytuacji niż tylko \"zerowy wyznacznik\".",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Kiedy wynikiem transformacji jest linia, co oznacza, że jest jednowymiarowa, mówimy, że transformacja ma stopień jeden.",
  "model": "google_nmt",
  "from_community_srt": "Gdy rezultat transformacji jest linią, tzn. jest jedno-wymiarowy, mówimy że transformacja ma \"rząd\" równy jeden.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Jeśli wszystkie wektory lądują na jakiejś dwuwymiarowej płaszczyźnie, mówimy, że transformacja ma stopień dwa.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli wszystkie wektory lądują na pewnej dwu-wymiarowej płaszczyźnie, mówimy że transformacja ma \"rząd\" równy 2.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Zatem słowo ranga oznacza liczbę wymiarów na wyjściu transformacji.",
  "model": "google_nmt",
  "from_community_srt": "Zatem słowo \"rząd\" oznacza ilość wymiarów wyjściowych z transformacji.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "Na przykład w przypadku macierzy 2x2 pozycja druga jest najlepsza z możliwych.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, gdy mamy macierze 2x2, rząd równy 2 jest największym jaki może być.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "Oznacza to, że wektory bazowe nadal obejmują pełne dwa wymiary przestrzeni, a wyznacznik nie wynosi zero.",
  "model": "google_nmt",
  "from_community_srt": "Oznacza to że wektory bazowe dalej rozpinają pełne dwa wymiary przestrzenne, a wyznacznik jest niezerowy.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "Ale w przypadku macierzy 3x3 stopień drugi oznacza, że zawaliliśmy się, ale nie tak bardzo, jak zawaliłoby się w sytuacji pierwszego rzędu.",
  "model": "google_nmt",
  "from_community_srt": "Lecz dla macierzy 3x3, rząd równy 2 oznacza że nastąpiła redukcja, choć nie aż tak jak by mogła w przypadku rządu równego jeden.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "Jeśli transformacja 3D ma wyznacznik niezerowy, a jej wynik wypełnia całą przestrzeń 3D, ma ona rangę trzecią.",
  "model": "google_nmt",
  "from_community_srt": "Gdy transformacja 3D ma niezerowy wyznacznik, i jej wynik zapełnia całą przestrzeń 3D, ma ona rząd równy 3.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Ten zbiór wszystkich możliwych wyników macierzy, niezależnie od tego, czy jest to linia, płaszczyzna, przestrzeń 3D czy cokolwiek innego, nazywany jest przestrzenią kolumnową macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Zbiór wszystkich możliwych wyników z twojej macierzy, niezależnie czy są one linią, płaszczyzną, przestrzenią 3d, jakkolwiek, nazywamy \"przestrzenią kolumnową\" twojej macierzy.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Pewnie domyślacie się, skąd wzięła się ta nazwa.",
  "model": "google_nmt",
  "from_community_srt": "Możesz prawdopodobnie odgadnąć skąd się bierze ta nazwa.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "Kolumny macierzy informują, gdzie lądują wektory bazowe, a rozpiętość tych przekształconych wektorów bazowych daje wszystkie możliwe wyniki.",
  "model": "google_nmt",
  "from_community_srt": "Kolumny twojej macierzy mówią nam gdzie znajdą się wektory bazowe, a rozpięcie tych przetransformowanych wektorów bazowych da nam wszystkie możliwe wyniki.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "Innymi słowy, przestrzeń kolumn to rozpiętość kolumn macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Innymi słowy, przestrzeń kolumn jest rozpięciem kolumn twojej macierzy.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Zatem bardziej precyzyjna definicja rangi byłaby taka, że jest to liczba wymiarów w przestrzeni kolumn.",
  "model": "google_nmt",
  "from_community_srt": "Zatem, bardziej precyzyjną definicją rzędu będzie to iż jest to ilość wymiarów w przestrzeni kolumn.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Kiedy ten stopień jest tak wysoki, jak to tylko możliwe, czyli równy liczbie kolumn, nazywamy macierz pełną rangą.",
  "model": "google_nmt",
  "from_community_srt": "Gdy rząd jest tak wysoki jak to tylko możliwe, czyli jest równy ilości kolumn,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Zwróć uwagę, że wektor zerowy będzie zawsze uwzględniony w przestrzeni kolumn, ponieważ przekształcenia liniowe muszą utrzymywać początek układu współrzędnych na miejscu.",
  "model": "google_nmt",
  "from_community_srt": "nazywamy macierz \"pełnego rzędu\". Zauważ, wektor zerowy zawsze będzie zawarty w przestrzeni kolumn, gdyż transformacja liniowa musi zachować początek na swoim miejscu.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "W przypadku transformacji pełnego rzędu jedynym wektorem, który trafia do początku, jest sam wektor zerowy.",
  "model": "google_nmt",
  "from_community_srt": "Dla transformacji o pełnym rzędzie, jedyny wektor który ląduje w środku jest sam wektor zerowy, lecz dla macierzy nie mającej pełnego rzędu,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Ale w przypadku macierzy, które nie mają pełnego rzędu i które zmniejszają się do mniejszego wymiaru, możesz mieć całą masę wektorów, które wychodzą na zero.",
  "model": "google_nmt",
  "from_community_srt": "które redukują przestrzeń do mniejszej liczby wymiarów, możemy mieć całe stado wektorów które przemieszczają się do zera.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Jeśli na przykład transformacja 2D zgniata przestrzeń na linię, istnieje oddzielna linia w innym kierunku, pełna wektorów, które są ściskane na początku.",
  "model": "google_nmt",
  "from_community_srt": "Gdy transformacja 2d redukuje przestrzeń do linii, dla przykładu, jest oddzielna linia w innym kierunku pełna wektorów zredukowanych do środka.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Jeśli transformacja 3D zgniata przestrzeń na płaszczyznę, istnieje również pełna linia wektorów, które lądują w początku układu współrzędnych.",
  "model": "google_nmt",
  "from_community_srt": "Gdy transformacja 3d redukuje przestrzeń do płaszczyzny, jest też pełna linia wektorów które lądują w środku.",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Jeśli transformacja 3D zgniata całą przestrzeń w linię, wówczas istnieje cała płaszczyzna pełna wektorów, które lądują w początku układu współrzędnych.",
  "model": "google_nmt",
  "from_community_srt": "Gdy transformacja 3d redukuje przestrzeń do linii, jest płaszczyzna pełna wektorów które lądują w środku.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Ten zbiór wektorów, który ląduje na początku układu współrzędnych, nazywany jest przestrzenią zerową lub jądrem macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Ten zbiór wektorów które lądują w środku jest nazywany jądrem twojej macierzy.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "Jest to przestrzeń wszystkich wektorów, które stają się zerowe, w tym sensie, że lądują na wektorze zerowym.",
  "model": "google_nmt",
  "from_community_srt": "Jest to przestrzeń wszystkich tych wektorów które stają się zerem, w tym sensie że przemieszczają się do wektora zerowego.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "Jeśli chodzi o liniowy układ równań, gdy v jest wektorem zerowym, przestrzeń zerowa daje wszystkie możliwe rozwiązania równania.",
  "model": "google_nmt",
  "from_community_srt": "W rozumieniu układu równań liniowych, gdy v okaże się wektorem zerowym, jądro daje nam wszystkie możliwe rozwiązania tego układu równań.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Jest to więc bardzo ogólny przegląd tego, jak myśleć o liniowych układach równań w sposób geometryczny.",
  "model": "google_nmt",
  "from_community_srt": "Jest to bardzo wysokopoziomowy sposób spojrzenia na to jak myśleć o systemach równań liniowych przestrzennie.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "Z każdym systemem jest powiązany jakiś rodzaj transformacji liniowej, a jeśli ta transformacja ma odwrotność, możesz użyć tej odwrotności do rozwiązania swojego systemu.",
  "model": "google_nmt",
  "from_community_srt": "Każdy układ ma pewną transformację liniową skojarzoną z nim, i gdy ta transformacja ma odwrotność, możesz użyć tej odwrotności do rozwiązania swojego układu.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "W przeciwnym razie idea przestrzeni kolumnowej pozwala nam zrozumieć, kiedy rozwiązanie w ogóle istnieje, a idea przestrzeni zerowej pomaga nam zrozumieć, jak może wyglądać zbiór wszystkich możliwych rozwiązań.",
  "model": "google_nmt",
  "from_community_srt": "W przeciwnym przypadku, koncepcja przestrzeni kolumnowej pozwala nam dojść czy rozwiązanie w ogóle istnieje, a idea jądra pomaga nam zrozumieć jak zbiór wszystkich możliwych rozwiązań może wyglądać.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Ponownie, jest wiele rzeczy, których tutaj nie opisałem, a zwłaszcza sposób obliczania tych rzeczy.",
  "model": "google_nmt",
  "from_community_srt": "Jak zwykle, jest bardzo dużo rzeczy których nie omówiłem tutaj, w szczególności jak obliczać te sprawy.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Musiałem także ograniczyć zakres do przykładów, w których liczba równań jest równa liczbie niewiadomych.",
  "model": "google_nmt",
  "from_community_srt": "Musiałem ograniczyć zakres przykładów do przypadków gdzie ilość równań jest równa ilości nieznanych.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Jednak celem tutaj nie jest próba nauczenia wszystkiego. Chodzi o to, abyś miał silną intuicję dotyczącą macierzy odwrotnych, przestrzeni kolumnowej i przestrzeni zerowej oraz aby ta intuicja uczyniła przyszłą naukę bardziej owocną.",
  "model": "google_nmt",
  "from_community_srt": "Lecz moim celem nie jest nauczenie wszystkiego; Chodzi o to byś miał silną intuicję związaną z macierzami odwrotnymi, przestrzenią kolumn, i jądrem, i te intuicji sprawią że późniejsza nauką będzie bardziej owocna.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "Następny film, zgodnie z popularną prośbą, będzie krótkim przypisem na temat macierzy niekwadratowych.",
  "model": "google_nmt",
  "from_community_srt": "Następny film będzie krótkim omówieniem macierzy nie-kwadratowych.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Potem przedstawię wam moje podejście do produktów skalarnych i coś całkiem fajnego, co się dzieje, gdy spojrzymy na nie w świetle transformacji liniowych.",
  "model": "google_nmt",
  "from_community_srt": "Później po tym opowiem o iloczynie skalarnym, i tym jak świetny jest kiedy patrzysz na niego poprzez perspektywę transformacji liniowych.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]