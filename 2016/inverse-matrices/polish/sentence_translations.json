[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "",
  "from_community_srt": "\"Zadać właściwe pytanie jest trudniejsze niż udzielenie na nie odpowiedzi.\" -Georg Cantor Jak już zapewne zauważyłeś, kładę w tych filmach nacisk na rozumienie macierzy i operacji wektorowych i operacji na wektorach z użyciem wyobraźni przestrzennej.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "",
  "from_community_srt": "Ten film nie będzie wyjątkiem, omawiając koncepcje odwracania macierzy, przestrzeni kolumn, rzędu i pustej przestrzeni w ten sposób.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "",
  "from_community_srt": "Uprzedzę jednak: nie zamierzam mówić o metodach obliczeniowych, a niektórzy będą argumentować że to bardzo ważne.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "",
  "from_community_srt": "Jest bardzo dużo dobrych materiałów omawiających metody obliczeniowe poza tą serią filmów. Słowa kluczowe:",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "",
  "from_community_srt": "\"eliminacja gaussa\" i \"macierz schodkowa\" Uważam że najwięcej mogę tu dodać w kwestii intuicji.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "",
  "from_community_srt": "Dodatkowo - w praktyce - zazwyczaj mamy programy które to za nas obliczają.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "",
  "from_community_srt": "Na wstępie kilka słów o użyteczności algebry liniowej.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "",
  "from_community_srt": "Póki co, masz już odczucie jak jest używana do opisu manipulacji przestrzennej, co jest przydatne w temacie grafiki komputerowej i robotyki,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "",
  "from_community_srt": "ale jednym z głównych powodów dla których algebra liniowa jest szeroko stosowana, i wymagana w zasadniczo każdej dziedzinie technicznej, jest to że pozwala nam rozwiązywać pewne układy równań.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "",
  "from_community_srt": "Kiedy mówię \"układ równań\", mam na myśli iż mamy zbiór zmiennych które musimy odgadnąć, i zbiór równań opisujących je.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "",
  "from_community_srt": "W wielu przypadkach te równania mogą stać się bardzo złożone,",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "",
  "from_community_srt": "ale, przy odrobinie szczęścia, mogą przyjąć pewną specjalną formę.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "",
  "from_community_srt": "W każdym równaniu jedyną rzeczą która dotyka każdej zmiennej jest to że skaluje się przez pewną stałą, a jedyną rzeczą która spotyka te przeskalowane zmienne jest to że dodają się do siebie.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "",
  "from_community_srt": "Zatem, żadnych potęg lub dziwnych funkcji, mnożenia zmiennych przez siebie - ani innych takich rzeczy.",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "",
  "from_community_srt": "Zwyczajowym sposobem opisu tego systemu równań jest ułożenie wszystkich zmiennych po lewej, i pozostawienie stałych po stronie prawej.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "",
  "from_community_srt": "Jest również wygodne ułożenie w jednej kolumnie tych samych zmiennych, a by to osiągnąć czasem trzeba dodać zerowe współczynniki.",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "",
  "from_community_srt": "Nazywamy to \"liniowym układem równań\".",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "",
  "from_community_srt": "Możemy zauważyć, że przypomina to bardzo mnożenie macierzy przez wektor.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "",
  "from_community_srt": "Rzeczywiście, może spakować te wszystkie równania w jedno równanie wektorowe, w którym macierz zawiera wszystkie stałe współczynniki a wektor zawiera wszystkie zmienne, a iloczyn tej macierzy i wektora jest równy pewnemu innemu wektorowi ze stałymi.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "",
  "from_community_srt": "Nazwijmy tę macierz A, a wektor zawierający zmienne nazwijmy x, natomiast wektor stałych po prawej stronie v.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "",
  "from_community_srt": "Jest to coś więcej niż sprytny sposób zapisu pozwalający zapisać równania w jednej linii.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "",
  "from_community_srt": "Naświetla nam świetny sposób geometrycznego rozumienia tego zagadnienia.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "",
  "from_community_srt": "Macierz A odpowiada pewnej transformacji liniowej, zatem rozwiązanie Ax = v oznacza iż szukamy wektora x, który po nałożeniu transformacji,",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "",
  "from_community_srt": "staje się v. Zastanówmy się przez chwilę co tu się dzieje.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "",
  "from_community_srt": "Można sobie wyobrazić ten skomplikowany problem wielu zmiennych mieszających się ze sobą poprzez myślenie o rozciąganiu i ściskaniu przestrzeni tak by zgadnąć który wektor przemieszcza się w inny.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "",
  "from_community_srt": "Fajne,",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "",
  "from_community_srt": "prawda? Zaczynając od prostego przykładu, weźmy układ dwóch równań z dwoma niewiadomymi.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "",
  "from_community_srt": "Oznacza to że macierz A jest macierzą 2 na 2, v i x są dwu-wymiarowymi wektorami.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "",
  "from_community_srt": "Sposób w jaki myślimy o rozwiązaniach tego równania zależy od tego czy transformacja związana z A zmniejsza przestrzeń do mniejszej liczby wymiarów, jak linia czy punkt, czy też zostawia wszystko w przestrzeni dwuwymiarowej od której zaczęliśmy.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "",
  "from_community_srt": "W języku poprzedniego filmu, dzielimy to na przypadek gdzie A ma zerowy wyznacznik,",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "",
  "from_community_srt": "oraz przypadek gdzie A ma niezerowy wyznacznik. Zacznijmy od bardziej prawdopodobnego przypadku gdzie wyznacznik jest niezerowy, czyli przestrzeń nie zmniejsza się do zerowego rozmiaru.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "",
  "from_community_srt": "W tym przypadku będzie jeden i tylko jeden wektor który stanie się v, i możemy go znaleźć odtwarzając transformację od końca.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "",
  "from_community_srt": "Podążając za v podczas gdy przewijamy taśmę do tyłu jak tutaj, znajdziemy taki wektor x iż A razy x wynosi v.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "",
  "from_community_srt": "Kiedy odtwarzamy transformację do tyłu, zasadniczo odpowiada to innej transformacji liniowej, zazwyczaj nazywanej \"odwrotnością A\" zapisywanej jako A do potęgi -1.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "",
  "from_community_srt": "Dla przykładu, jeśli A było obrotem przeciwnym do ruchu wskazówek zegara o 90 stopni, wtedy odwrotność A będzie obrotem zgodnym z ruchem wskazówek zegara o 90 stopni.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "",
  "from_community_srt": "Jeśli A była ścięciem które przesuwało j-z-daszkiem jedną jednostkę w prawo, wtedy odwrotność A będzie ścięciem przesuwającym j-z-daszkiem jedną jednostkę w lewo.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "",
  "from_community_srt": "Zasadniczo, odwrotność A jest unikalną transformacją mającą tą cechę że gdy pierwsze zaaplikujemy A, a później zaaplikujemy transformację odwrotną A,",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "",
  "from_community_srt": "znajdziemy się z powrotem w miejscu z którego wyszliśmy. Nakładanie jednej transformacji za drugą przedstawiamy algebraicznie za pomocą mnożenia macierzowego, zatem zasadniczą własnością transformacji odwrotność-z-A jest to, że odwrotność A razy A odpowiada macierzy która nic nie robi.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "",
  "from_community_srt": "Transformacja która nic nie robi jest nazywana transformacją tożsamościową(identycznościową).",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "",
  "from_community_srt": "Zostawia ona i-z-daszkiem oraz j-z-daszkiem tam gdzie były, nieruchomo, zatem jest kolumny to 1,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "",
  "from_community_srt": "0, i 0, 1. Kiedy już znajdziemy odwrotność, która w praktyce policzy za nas komputer, możemy rozwiązać nasze równanie przez mnożenie macierzy odwrotnej przez v.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "",
  "from_community_srt": "Zatem to co oznacza to geometrycznie to odtworzenie transformacji wspak i podążanie za v.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "",
  "from_community_srt": "Przypadek niezerowego wyznacznika, który dla dowolnie wybranej macierzy jest najbardziej prawdopodobny, odpowiada koncepcji dwóch zmiennych i dwóch równań, w której zwykle mamy jedno unikalne rozwiązanie.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "Ta idea ma też sens przy większej ilości wymiarów, gdzie ilość równań jest taka sama jak liczba niewiadomych.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "",
  "from_community_srt": "I znowu, system równań może być przełożony na interpretację geometryczną, gdzie mamy pewną transformację, A, i pewien wektor, v,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "",
  "from_community_srt": "i szukamy wektora x który przemieści się w miejsce v. Tak długo jak transformacja A nie redukuje przestrzeni w mniejszą ilość wymiarów, czyli jej wyznacznik jest niezerowy, będzie istnieć transformacja odwrotna, odwrotność z A, mająca taka własność że jeśli pierwsze zrobimy A, a potem odwrotność A,",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "",
  "from_community_srt": "będzie to tym samym co zrobienie niczego. I by rozwiązać twoje równanie,",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "",
  "from_community_srt": "wystarczy że pomnożysz tą macierz transformacji odwrotnej przez wektor v. Lecz gdy wyznacznik jest zerem, i transformacja związana z tym układem równań redukuje przestrzeń w mniejszą ilość wymiarów, odwrotność nie istnieje.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "",
  "from_community_srt": "Nie możesz od-zredukować prostej by przekształcić ją w płaszczyznę.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "",
  "from_community_srt": "A w każdym razie, nie jest to coś co może zrobić funkcja.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "",
  "from_community_srt": "Wymagałoby to przetworzenia każdego jednego wektora w całą linię pełną wektorów.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "",
  "from_community_srt": "Lecz funkcje mogą brać tylko jedno wyjście i mieć jedno wyjście.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "",
  "from_community_srt": "Podobnie, dla trzech równań z trzema niewiadomymi, nie będzie odwrotności jeśli odpowiadająca transformacja redukuje przestrzeń 3D w płaszczyznę, lub nawet w prostą lub punkt.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "",
  "from_community_srt": "Wszystkie one mają zerowy wyznacznik, ponieważ każdy obszar jest redukowany do czegoś o zerowej objętości.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "",
  "from_community_srt": "Ciągle jest możliwe że rozwiązanie istnieje nawet gdy nie ma odwrotności,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "",
  "from_community_srt": "po prostu gdy transformacja redukuje przestrzeń w, dla przykładu, linię, musisz mieć sporo szczęścia by wektor v znajdował się na tej linii.",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "",
  "from_community_srt": "Możesz spostrzec że część z tych przypadków o zerowym wyznaczniku jest bardziej restrykcyjna niż inne.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "",
  "from_community_srt": "Mając macierz 3x3 (dla przykładu), wygląda na to że trudniej istnieć rozwiązaniu gdy redukuje ona przestrzeń do linii w porównaniu do sytuacji gdy redukuje przestrzeń do płaszczyzny,",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "",
  "from_community_srt": "mimo tego że w obu przypadkach mamy tak samo zerowy wyznacznik. Mamy pewien bardziej dokładny sposób opisania tej sytuacji niż tylko \"zerowy wyznacznik\".",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "",
  "from_community_srt": "Gdy rezultat transformacji jest linią, tzn. jest jedno-wymiarowy, mówimy że transformacja ma \"rząd\" równy jeden.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "",
  "from_community_srt": "Jeśli wszystkie wektory lądują na pewnej dwu-wymiarowej płaszczyźnie,",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "",
  "from_community_srt": "mówimy że transformacja ma \"rząd\" równy 2. Zatem słowo \"rząd\" oznacza ilość wymiarów wyjściowych z transformacji.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "",
  "from_community_srt": "Dla przykładu, gdy mamy macierze 2x2, rząd równy 2 jest największym jaki może być.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "",
  "from_community_srt": "Oznacza to że wektory bazowe dalej rozpinają pełne dwa wymiary przestrzenne, a wyznacznik jest niezerowy.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "",
  "from_community_srt": "Lecz dla macierzy 3x3, rząd równy 2 oznacza że nastąpiła redukcja, choć nie aż tak jak by mogła w przypadku rządu równego jeden.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "",
  "from_community_srt": "Gdy transformacja 3D ma niezerowy wyznacznik, i jej wynik zapełnia całą przestrzeń 3D,",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "",
  "from_community_srt": "ma ona rząd równy 3. Zbiór wszystkich możliwych wyników z twojej macierzy, niezależnie czy są one linią, płaszczyzną, przestrzenią 3d, jakkolwiek, nazywamy \"przestrzenią kolumnową\" twojej macierzy.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "",
  "from_community_srt": "Możesz prawdopodobnie odgadnąć skąd się bierze ta nazwa.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "",
  "from_community_srt": "Kolumny twojej macierzy mówią nam gdzie znajdą się wektory bazowe, a rozpięcie tych przetransformowanych wektorów bazowych da nam wszystkie możliwe wyniki.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "",
  "from_community_srt": "Innymi słowy, przestrzeń kolumn jest rozpięciem kolumn twojej macierzy.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "",
  "from_community_srt": "Zatem, bardziej precyzyjną definicją rzędu będzie to iż jest to ilość wymiarów w przestrzeni kolumn.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "",
  "from_community_srt": "Gdy rząd jest tak wysoki jak to tylko możliwe, czyli jest równy ilości kolumn,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "",
  "from_community_srt": "nazywamy macierz \"pełnego rzędu\". Zauważ, wektor zerowy zawsze będzie zawarty w przestrzeni kolumn, gdyż transformacja liniowa musi zachować początek na swoim miejscu.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "",
  "from_community_srt": "Dla transformacji o pełnym rzędzie, jedyny wektor który ląduje w środku jest sam wektor zerowy,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "",
  "from_community_srt": "lecz dla macierzy nie mającej pełnego rzędu, które redukują przestrzeń do mniejszej liczby wymiarów,",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "",
  "from_community_srt": "możemy mieć całe stado wektorów które przemieszczają się do zera. Gdy transformacja 2d redukuje przestrzeń do linii, dla przykładu, jest oddzielna linia w innym kierunku pełna wektorów zredukowanych do środka.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "Gdy transformacja 3d redukuje przestrzeń do płaszczyzny,",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "jest też pełna linia wektorów które lądują w środku. Gdy transformacja 3d redukuje przestrzeń do linii,",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "",
  "from_community_srt": "jest płaszczyzna pełna wektorów które lądują w środku. Ten zbiór wektorów które lądują w środku jest nazywany jądrem twojej macierzy.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "",
  "from_community_srt": "Jest to przestrzeń wszystkich tych wektorów które stają się zerem, w tym sensie że przemieszczają się do wektora zerowego.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "",
  "from_community_srt": "W rozumieniu układu równań liniowych, gdy v okaże się wektorem zerowym, jądro daje nam wszystkie możliwe rozwiązania tego układu równań.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "",
  "from_community_srt": "Jest to bardzo wysokopoziomowy sposób spojrzenia na to jak myśleć o systemach równań liniowych przestrzennie.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "",
  "from_community_srt": "Każdy układ ma pewną transformację liniową skojarzoną z nim, i gdy ta transformacja ma odwrotność, możesz użyć tej odwrotności do rozwiązania swojego układu.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "",
  "from_community_srt": "W przeciwnym przypadku, koncepcja przestrzeni kolumnowej pozwala nam dojść czy rozwiązanie w ogóle istnieje, a idea jądra pomaga nam zrozumieć jak zbiór wszystkich możliwych rozwiązań może wyglądać.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "",
  "from_community_srt": "Jak zwykle, jest bardzo dużo rzeczy których nie omówiłem tutaj, w szczególności jak obliczać te sprawy.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "Musiałem ograniczyć zakres przykładów do przypadków gdzie ilość równań jest równa ilości nieznanych.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "",
  "from_community_srt": "Lecz moim celem nie jest nauczenie wszystkiego; Chodzi o to byś miał silną intuicję związaną z macierzami odwrotnymi, przestrzenią kolumn, i jądrem, i te intuicji sprawią że późniejsza nauką będzie bardziej owocna.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "",
  "from_community_srt": "Następny film będzie krótkim omówieniem macierzy nie-kwadratowych.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "",
  "from_community_srt": "Później po tym opowiem o iloczynie skalarnym, i tym jak świetny jest kiedy patrzysz na niego poprzez perspektywę transformacji liniowych.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]