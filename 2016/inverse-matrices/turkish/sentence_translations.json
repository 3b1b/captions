[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Şu ana kadar muhtemelen anlayabileceğiniz gibi, bu serinin büyük kısmı matris ve vektör işlemlerini doğrusal dönüşümlerin daha görsel merceğinden anlamak üzerinedir.",
  "model": "google_nmt",
  "from_community_srt": "Doğru soruyu sormak, Soruyu sormaktan daha zordur. Şu ana kadar ki anlatma biçimimden anlamış olduğunuz gibi, maktrix ve vektörler ile ilgili işlemleri doğrusal cebirin görsel yanı ile anlatmaya çalışıyorum.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Bu video da bir istisna değil; ters matrisler, sütun uzayı, rütbe ve sıfır uzayı kavramlarını bu mercekten anlatıyor.",
  "model": "google_nmt",
  "from_community_srt": "Bu video da farklı olmayacak. Ters Matrix kavramını, Sütun Uzayı, mertebe ve boş uzay kavramlarını da görsel bir şekilde ele alacağım.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Ancak bir ön uyarı, bu şeyleri gerçekten hesaplamanın yöntemlerinden bahsetmeyeceğim ve bazıları bunun oldukça önemli olduğunu iddia edebilir.",
  "model": "google_nmt",
  "from_community_srt": "Bu arada peşinen uyarayım: bunları hesaplamanın nasıl yapıldığını anlatmayacağım... bazılarınız bunun oldukça önemli olduğunu iddia edebilir..",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Bu serinin dışındaki yöntemleri öğrenmek için Gauss eliminasyonu ve satır basamak formu anahtar kelimeleri gibi çok sayıda iyi kaynak vardır.",
  "model": "google_nmt",
  "from_community_srt": "Ama bunları öğrenmek için bir sürü başka kaynak bulabilirsiniz.. Anahtar sözcükler:",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Buraya aslında eklemem gereken değerin çoğunun sezgi kısmında olduğunu düşünüyorum.",
  "model": "google_nmt",
  "from_community_srt": "\"Gaus eliminasyonu\" \"satır dizilimli biçim\" Benim konuya katkı sağlamak istediğim nokta daha ziyade kavramakla ilgili kısım.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Artı, pratikte genellikle bunları bizim için hesaplayacak bir yazılım alırız.",
  "model": "google_nmt",
  "from_community_srt": "Artı, pratikte, genellikle bu hesaplamalar için zaten bilgisayar kullanmaktayız..",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "İlk olarak doğrusal cebirin kullanışlılığı üzerine birkaç söz.",
  "model": "google_nmt",
  "from_community_srt": "ilk olarak doğrusal cebirin kullanışlılığı hakkında konuşmak istiyorum.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "Şimdiye kadar, bilgisayar grafikleri ve robotik gibi şeyler için yararlı olan, uzayın manipülasyonunu tanımlamakta nasıl kullanıldığına dair bir ipucunuz var.",
  "model": "google_nmt",
  "from_community_srt": "Şu an itibariyle, bu işlemlerin uzayı nasıl büktüğümüzü betimlemek için nasıl kullanıldığını biliyorsunuz Ki bu genelde bilgisayar grafiklerinde ve robotik işlerde kullanılıyor demiştik.",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "Ancak doğrusal cebirin daha geniş çapta uygulanabilir olmasının ve hemen hemen her teknik disiplin için gerekli olmasının ana nedenlerinden biri, belirli denklem sistemlerini çözmemize izin vermesidir.",
  "model": "google_nmt",
  "from_community_srt": "Fakat doğrusal cebirin daha geniş ölçekte yararlı olmasını sağlayan ana nedenlerden birisi, tüm teknik alanlarda gerekli olmasının nedeni bize eşitlik sistemlerini çözme konusunda yardımcı olmasıdır.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Denklem sistemi dediğimde, elinizde değişkenlerin, bilmediğiniz şeylerin ve bunlarla ilgili denklemlerin bir listesi olduğunu kastediyorum.",
  "model": "google_nmt",
  "from_community_srt": "Eşitlikler derken, değerlerini bilmediğimiz değişkenler ve ve bu değişkenlerle ilişkilendirilmiş işlemleri ifade ediyorum.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "Çoğu durumda bu denklemler çok karmaşık hale gelebilir.",
  "model": "google_nmt",
  "from_community_srt": "Pek çok durumda bu eşitlikler, çok karmaşık bir hal alabilir, ama ne şans ki,",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "Ancak eğer şanslıysanız özel bir biçim alabilirler.",
  "model": "google_nmt",
  "from_community_srt": "hepsini belirli bir biçime sokmamız mümkün.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "Her denklemde, her değişkenin başına gelen tek şey, bunun bir sabit tarafından ölçeklendirilmesidir ve bu ölçeklenen değişkenlerin her birinin başına gelen tek şey, bunların birbirine eklenmesidir.",
  "model": "google_nmt",
  "from_community_srt": "Her bir eşitlikte, her değişkenin başına gelen işlem, bir değerle genişletilmek , ve ve bu esnetilen değişkenlerin toplanması şeklinde olmalıdır.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Yani üslü sayılar, süslü fonksiyonlar ya da iki değişkenin birbiriyle çarpılması gibi şeyler yok.",
  "model": "google_nmt",
  "from_community_srt": "Tuhaf işlevler, Üstel ifadeler ya da iki değişkenin birbiri ile çarpılması gibi işlemler yok dikkat ediniz.",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "Bu tür özel denklem sistemini düzenlemenin tipik yolu, tüm değişkenleri sola, kalıcı sabitleri ise sağa yerleştirmektir.",
  "model": "google_nmt",
  "from_community_srt": "Bu tipteki eşitlikleri düzenlemenin bir en ideal yolu tüm değişkenleri sola almak, boşta kalan sayıları da sağ tarafa almaktır.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "Ortak değişkenleri dikey olarak sıralamak da güzeldir ve bunu yapmak için, değişken denklemlerden birinde görünmediğinde bazı sıfır katsayıları girmeniz gerekebilir.",
  "model": "google_nmt",
  "from_community_srt": "Ayrıca aynı değişkenleri alt alta getirmek de yararlı olacaktır. Bunu gerçekleştirebilmek için, yanlarına sıfır koyabiliriz şayet ilgili değişken bir eşitlikte yoksa...",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Buna doğrusal denklem sistemi denir.",
  "model": "google_nmt",
  "from_community_srt": "Bu yapıya işte, \"doğrusal eşitlik sistemleri\" denmekte.",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Bunun matris-vektör çarpımına çok benzediğini fark edebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Hemen farkettiğiniz gibi, vektör matrix çarpıma benziyor bu.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "Aslında, tüm denklemleri, tüm sabit katsayıları içeren bir matrise ve tüm değişkenleri içeren bir vektöre sahip olduğunuz ve bunların matris-vektör çarpımının farklı bir sabit vektöre eşit olduğu tek bir vektör denkleminde birlikte paketleyebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Aslında gerçekten de, tüm eşitlikleri bir vektör eşitliğine çevirebiliriz, tek yapmamız gereken, tüm katsayıları bir matrix e doldurmak ve değişkenleri de vektör şeklinde yazmak. Sonuç olarak bu vektör matrix çarpımı başka bir vektöre eşit olmuş olacaktır.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "Bu sabit matrise A adını verelim, değişkenleri tutan vektörü kalın X ile gösterelim ve sağ taraftaki sabit vektöre V adını verelim.",
  "model": "google_nmt",
  "from_community_srt": "Hadi dilerseniz matrix'imize A ismini, değişkenleri tutan vektöre de üzerinde ok olan x (oklu x) ismini, sağdaki vektöre de oklu v vektörü ismini verelim.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "Bu, denklem sistemimizi tek satıra yazmak için kullanılan notasyon hilesinden daha fazlasıdır.",
  "model": "google_nmt",
  "from_community_srt": "Bu eşitlik sistemimizi tek satıra yazmak için kullanılan bir hileden ibaret değil elbette.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Sorunun oldukça hoş bir geometrik yorumuna ışık tutuyor.",
  "model": "google_nmt",
  "from_community_srt": "Bu işlem, Problemle ilgili geometrik yorum hakkında aydınlatıcı olacaktır.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "A matrisi bazı doğrusal dönüşümlere karşılık gelir, dolayısıyla Ax eşittir V'yi çözmek, dönüşümü uyguladıktan sonra V'ye düşen bir X vektörünü aradığımız anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "A matrix'i doğrusal bir dönüşümü ifade edeceğinden, Ax=v çözümünü yaparken \"kendisi üzerinde dönüşüm gerçekleştirdikten sonra v noktasına düşen x vektörünü arıyoruz\" gibi düşünebiliriz.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Bir an burada olup bitenleri düşünün.",
  "model": "google_nmt",
  "from_community_srt": "\"kendisi üzerinde dönüşüm gerçekleştirdikten sonra v noktasına düşen x vektörünü arıyoruz\" gibi düşünebiliriz. Burada ne olduğunu bir durup düşünelim...",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Sadece uzayı sıkıştırmayı ve değiştirmeyi düşünerek ve hangi vektörün diğerine geldiğini bulmaya çalışarak, hepsi birbiriyle karışan çoklu değişkenlere ilişkin bu gerçekten karmaşık fikri aklınızda tutabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Kafanda, bu işlemlerin, birbirleriyle karmaşık ilişkileri olan çok değişkenli bir denklem olduğu fikri yerine, sadece uzayı eğip büküyor olmak gibi bir mana yaratıp hangi vektörün nerede olacağını hesapladığını düşünebilirsin.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Harika, değil mi?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Basit bir başlangıç yapmak gerekirse, diyelim ki iki denklemli ve iki bilinmeyenli bir sisteminiz var.",
  "model": "google_nmt",
  "from_community_srt": "Müthiş değil mi? Kolay bi başlangıç yapalım, diyelim ki iki eşitliğimiz ve iki de bilinmeyenimiz olsun.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "Bu, A matrisinin 2x2'lik bir matris olduğu ve V ve X'in her birinin iki boyutlu vektörler olduğu anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Bu, A matrix'i 2x2 lik bir matrix, v ile x vektörleri de iki boyutlu vektör demek olacak.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "Şimdi, bu denklemin çözümleri hakkında nasıl düşüneceğimiz, A ile ilişkili dönüşümün tüm uzayı bir çizgi veya nokta gibi daha düşük bir boyuta sıkıştırıp sıkıştırmadığına veya iki boyutun tamamını kapsayan her şeyi başladığı yerde bırakıp bırakmadığına bağlıdır.",
  "model": "google_nmt",
  "from_community_srt": "Şimdiii, bu problemin çözümü ile ilgili olarak düşünebileceklerimiz A matrix i ile ilişkili bu dönüşümün tüm uzayı daha düşük boyutlu bir uzaya sıkıştırıp sıkıştıramadığına göre, bu bir çizgi ya da nokta olabilir, ya da uzayın başladığı gibi 2 boyutta kalıp kalmamasına göre değişir.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "Son videonun dilinde A'nın determinantının sıfır olduğu durumlar ve A'nın sıfırdan farklı determinantının olduğu durumlar olarak alt bölümlere ayırıyoruz.",
  "model": "google_nmt",
  "from_community_srt": "Son videoda öğrendiklerimize göre, iki farklı olasılık çerçevesinde düşünebiliriz.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Determinantın sıfır olmadığı, yani uzayın sıfır alan bölgesine sıkışmadığı en olası durumla başlayalım.",
  "model": "google_nmt",
  "from_community_srt": "A matrixinin determinantının sıfır olduğu durum ve sıfır olmadığı durum şeklinde. Yüksek olasılıkla olacak olan, determinantın sıfır olmadığı durum ile başlayalım, demek ki uzay bir çizgiye ya da noktaya çökmemiş..",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "Bu durumda her zaman V'ye düşen tek bir vektör olacaktır ve bunu dönüşümü tersten oynayarak bulabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Bu durumda, bir yalnızca bir vektör v üzerine gelecektir dönüşüm sonrasında. Ve bu değeri, dönüşümü tersine oynatarak bulabiliriz.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "Bandı bu şekilde geri sararken V'nin nereye gittiğini takip ederek, A çarpı x eşittir V olacak şekilde x vektörünü bulacaksınız.",
  "model": "google_nmt",
  "from_community_srt": "animasyonu böyle tersten oynatıp v yi takip ederek, A kere x değerini v ye eşitleyen x i bulabiliriz.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Dönüşümü tersten oynadığınızda, bu aslında ayrı bir doğrusal dönüşüme karşılık gelir; genellikle A'nın tersi olarak adlandırılan ve A'nın negatif olana oranıyla gösterilir.",
  "model": "google_nmt",
  "from_community_srt": "Esasen animasyonu tersten oynatmak, başka bir doğrusal dönüşüm anlamına gelmekte. Bu dönüşüm \"A nın tersi \" olarak adlandırılır ve A üzeri -1 şeklinde gösterilir.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Örneğin, A, saat yönünün tersine 90 derecelik bir dönüş ise, o zaman A'nın tersi, saat yönünde 90 derecelik bir dönüş olacaktır.",
  "model": "google_nmt",
  "from_community_srt": "Örneğin, A saatin tersi yönünde 90º döndürme olsaydı A nın tersi; saat yönünde 90º derece dönüş anlamına gelecekti.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Eğer A, j-hat'ı bir birim sağa iten sağa doğru bir kesme olsaydı, A'nın tersi, j-hat'ı bir birim sola iten sola doğru bir kesme olurdu.",
  "model": "google_nmt",
  "from_community_srt": "Eğer A, j vektörünü sağa bir birim kaydırıyor olsaydı, tersi de j vektörünü sola bir birim kaydırma işlemi olacaktı.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "Genel olarak, A'nın tersi, önce A'yı uygularsanız, ardından onu A'nın tersi dönüşümüyle takip ederseniz başladığınız yere geri dönme özelliğine sahip benzersiz bir dönüşümdür.",
  "model": "google_nmt",
  "from_community_srt": "Genel olarak, A'nın tersi, eşsiz bir dönüşümü ifade eder. Öyle ki A, uygulandıktan sonra A'nın tersini uygularsak eğer, başladığımız yere döneriz.",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "Bir dönüşümün birbiri ardına uygulanması, matris çarpımı ile cebirsel olarak yakalanır, dolayısıyla bu A tersi dönüşümünün temel özelliği, A'nın tersi çarpı A'nın hiçbir şey yapmamaya karşılık gelen matrise eşit olmasıdır.",
  "model": "google_nmt",
  "from_community_srt": "Bir dönüşüm peşi sıra başka bir dönüşüm gerçekleştirmek cebirsel açıdan çarpma işlemidir, dolayısıyla bu dönüşümün temeli, özü: A nın tersi odur ki;",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "Hiçbir şey yapmayan dönüşüme kimlik dönüşümü denir.",
  "model": "google_nmt",
  "from_community_srt": "A kere A'nın tersi eşittir hiçbir dönüşüm yapılmayan matrix! Hiçbir dönüşüm yapmayan dönüşüme \"birim dönüşüm\" denir.",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "i-hat ve j-hat'ı oldukları yerde hareketsiz bırakır, dolayısıyla sütunları 1,0 ve 0,1 olur.",
  "model": "google_nmt",
  "from_community_srt": "i ve j vektörleri olduğu yerde kalır, hareket etmezler, dolayısıyla bu matrixin sütunları:",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Bu tersini bulduğunuzda, ki bunu pratikte bir bilgisayarla yaparsınız, bu ters matrisi v ile çarparak denkleminizi çözebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "[1,0] ve [0,1] dir. A'nın tersini bir kez buldun mu, bunu bilgisayarla yapabilirsiniz, v vektörü ile bu A 'nın tersini çarparak sonucu bulabilirsiniz.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "Ve yine, bunun geometrik olarak anlamı, dönüşümü tersten oynadığınız ve v'yi takip ettiğinizdir.",
  "model": "google_nmt",
  "from_community_srt": "Ve tekrar edeyim, geometrik olarak bunun anlamı: \"dönüşümü tersinden yürütüyorsunuz\"dur.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Rastgele bir matris seçimi için açık ara en olası olan bu sıfır olmayan determinant durumu, iki bilinmeyeniniz ve iki denkleminiz varsa, tek bir benzersiz çözümün neredeyse kesin olduğu fikrine karşılık gelir.",
  "model": "google_nmt",
  "from_community_srt": "v yi takip ederek tabii. Bu ele aldığımız determinant sıfır olmaMA hali, en olası olan seçenek, eğer iki değişkeniniz ve eşitlikleriniz varsa, bu eşitlikleri çözen,",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Bu fikir, denklem sayısının bilinmeyenlerin sayısına eşit olduğu daha yüksek boyutlarda da anlamlıdır.",
  "model": "google_nmt",
  "from_community_srt": "eşsiz değerleri bulmanız neredeyse kesindir. Bu düşünce daha yüksek boyutlar için de geçerlidir. Değişken sayısı ile eşitlik sayısı eşit oldukça elbette.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Yine denklem sistemi, bir A dönüşümüne ve bir v vektörüne sahip olduğunuz ve v'ye gelen x vektörünü aradığınız geometrik yoruma çevrilebilir.",
  "model": "google_nmt",
  "from_community_srt": "Tekrar ediyorum, Eşitlik sistemlerini, geometrik olarak yorumlarsak, A isimli bir dönüşüm yapacağımız, bu dönüşümü v vektörüne uygulayacağımız, ve v üzerinde konumlanan x vektörünü bulacağımızı söyleyebiliriz.",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "A dönüşümü tüm uzayı daha düşük bir boyuta sıkıştırmadığı sürece, yani determinantı sıfırdan farklı olduğu sürece, önce A'yı yaparsanız, sonra A'nın tersini yapacağınız özelliği ile ters bir A dönüşümü olacaktır. , hiçbir şey yapmamakla aynı şey.",
  "model": "google_nmt",
  "from_community_srt": "A dönüşümü, uzayı alt bir boyuta indirgemediği müddetçe, ki bu determinant sıfır değil demekti, A dönüşümünün tersi olan bir \"ters A\" olacaktır. Bu ters A, A uygulandıktan sonra uygulandığında hiçbir şey yapmamak anlamına gelen bir dönüşüm olmalıdır.",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "Denkleminizi çözmek için ters dönüşüm matrisini v vektörüyle çarpmanız yeterli.",
  "model": "google_nmt",
  "from_community_srt": "Ve eşitliği çözmek için tek yapman gereken,",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Ancak determinant sıfır olduğunda ve denklem sistemiyle ilişkili dönüşüm uzayı daha küçük bir boyuta sıkıştırdığında bunun tersi olmaz.",
  "model": "google_nmt",
  "from_community_srt": "dönüşümün tersini v vektörüne uygulaman olacaktır. Fakat determinant sıfır olduğunda, bu eşitlik sistemi ile ilişkili dönüşüm, uzayı daha alt bir boyuta indirgiyor olduğunda ters Matrix olmayacaktır..",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Bir çizgiyi düzleme dönüştürmek için onu gevşetemezsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Bir çizgiyi genişleterek bir düzlem elde edemeyiz...",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "En azından bu bir fonksiyonun yapabileceği bir şey değil.",
  "model": "google_nmt",
  "from_community_srt": "En azından bir fonksiyon bu işlemi gerçekleştiremez.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Bu, her bir vektörün vektörlerle dolu bir çizgiye dönüştürülmesini gerektirir.",
  "model": "google_nmt",
  "from_community_srt": "Çünkü bu işlem her bir vektörü, bir sürü vektör içeren doğrulara dönüştürmek demek olacaktır.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Ancak işlevler yalnızca tek bir girişi tek bir çıkışa götürebilir.",
  "model": "google_nmt",
  "from_community_srt": "Lakin, fonksiyonlar,",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Benzer şekilde, üç denklem ve üç bilinmeyen için, karşılık gelen dönüşüm 3 boyutlu uzayı düzlem üzerine sıkıştırırsa veya hatta onu bir çizgiye veya noktaya sıkıştırsa bile bunun tersi olmayacaktır.",
  "model": "google_nmt",
  "from_community_srt": "aynı girdi için farklı sonuçlar üretemezler! Aynı şekilde üç değişkenli üç bilinmeyenli durumda da ters Matrix olmayacaktır, eğer ilgili dönüşüm 3Boyutlu uzayı, düzleme indirgiyor olursa. hatta bir doğru ya da noktaya sıkıştırsa da olmaz.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Bunların hepsi sıfırın determinantına karşılık gelir, çünkü herhangi bir bölge sıfır hacimli bir şeye sıkıştırılır.",
  "model": "google_nmt",
  "from_community_srt": "Tüm bunlar elbette determinant sıfır olursa geçerli olur, zira herhangi bir alan sıfır hacimli bir bölgeye hapsoldu.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "Tersi olmadığında bile bir çözümün var olması hala mümkündür.",
  "model": "google_nmt",
  "from_community_srt": "Ters matrix olmadığında bile bir çözüm olması hala mümkün, eğer vektör v ,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "Sadece dönüşümünüz uzayı örneğin bir çizgiye sıkıştırdığında, v vektörünün o çizgi üzerinde bir yerde yaşaması için yeterince şanslı olmanız gerekir.",
  "model": "google_nmt",
  "from_community_srt": "dönüşüm sonrasında, diyelim uzay doğruya dönüşürse, ve şansımız yaver gider de,",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Bu sıfır belirleyici durumların bazılarının diğerlerinden çok daha kısıtlayıcı olduğunu fark edebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "bu doğru üzerine denk gelirse v vektörü, çözüm vardır hala. Siz de farketmiş olabilirsiniz ki; kimi sıfır determinant durumları diğer durumlara kıyasla daha kısıtlayıcı gibi.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Örneğin 3x3'lük bir matris göz önüne alındığında, her ikisi de sıfır determinantlı olmasına rağmen, uzayı bir doğru üzerine sıkıştıran bir çözümün var olması, nesneleri bir düzlem üzerine sıkıştırdığı zamana kıyasla çok daha zor görünüyor.",
  "model": "google_nmt",
  "from_community_srt": "Verilen bir 3x3 lük bir matrix düşünelim, bir çözüm olma olasılığı doğru üzerine çöktüğünde uzay daha az iken, düzleme çöktüğünde her iki determinant sıfır olsa da daha fazla gibi.",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "Sıfır determinant demekten biraz daha spesifik bir dilimiz var.",
  "model": "google_nmt",
  "from_community_srt": "Sadece determinantı sıfır demekten ötesini anlatabilmek için yeni bir söylemimiz var aslında.",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Bir dönüşümün çıktısı bir çizgi olduğunda, yani tek boyutlu olduğunda, dönüşümün derecesinin bir olduğunu söyleriz.",
  "model": "google_nmt",
  "from_community_srt": "Bir dönüşümün sonucu eğer doğru ise, ki bu tek-boyutlu anlamına geliyor, dönüşümün \"mertebesi\" 1 dir deriz.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Eğer tüm vektörler iki boyutlu bir düzleme iniyorsa dönüşümün derecesinin iki olduğunu söyleriz.",
  "model": "google_nmt",
  "from_community_srt": "Eğer üm vektörler iki boyutlu biz düzlem üzerine düşerse, Dönüşümün \"mertebesi\" 2 dir deriz.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Yani rütbe kelimesi, bir dönüşümün çıktısındaki boyutların sayısı anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Dolayısıyla, \"mertebe\" dönüşümün sonucundaki boyut anlamına gelmektedir.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "Örneğin, 2x2'lik matrisler söz konusu olduğunda ikinci derece, olabilecek en iyisidir.",
  "model": "google_nmt",
  "from_community_srt": "Misal, 2x2'lik bir matrixte mertebe 2 en yüksek mertebeli sonuçtur.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "Bu, temel vektörlerin uzayın iki boyutunun tamamını kapsamaya devam ettiği ve determinantın sıfır olmadığı anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Bu da asıl vektörlerin tüm 2 boyut uzanımında konumlara gidebileceği anlamına gelir ki; determinant sıfırdan faklıdır.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "Ancak 3x3 matrisler için ikinci derece, çöktüğümüz anlamına gelir, ancak birinci derece bir durum için çökecekleri kadar değil.",
  "model": "google_nmt",
  "from_community_srt": "3x3 matrix için ise; mertebe 2, uzay çöktü demektir. Fakat mertebe 1 olduğunda çöktüğü kadar değil bu çöküş elbette.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "Bir 3B dönüşümün sıfır olmayan bir determinantı varsa ve çıktısı 3B alanın tamamını dolduruyorsa, derecesi üçtür.",
  "model": "google_nmt",
  "from_community_srt": "Eğer 3Boyutlu bir dönüşüm sıfır olmayan bir determinanta sahipse, sonuç tüm 3Boyut uzayını kapsarsa mertebesi 3'tür.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Matrisinizin tüm olası çıktılarının bu kümesine, ister bir çizgi, ister bir düzlem, ister 3 boyutlu uzay, ne olursa olsun, matrisinizin sütun uzayı denir.",
  "model": "google_nmt",
  "from_community_srt": "Matrix'in tüm olası çıktılarını içeren bu set ister doğru olsun, ister düzlem olsun ister 3Boyut olsun, ne olursa olsun... Matrix'imizin \"Sütun Uzayı\" olarak adlandırılır.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Bu ismin nereden geldiğini muhtemelen tahmin edebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Eminim bu ismin nereden geldiğini merak ediyorsunuzdur.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "Matrisinizin sütunları size temel vektörlerin nereye indiğini söyler ve dönüştürülen bu temel vektörlerin aralığı size tüm olası çıktıları verir.",
  "model": "google_nmt",
  "from_community_srt": "Matrix'in sütunları bize asıl vektörlerin dönüşüm sonrası nereye konumlandırını söylüyordu. asıl vektörlerin dönüşümlerinin kapsamı ise olası tüm sonuçların toplamı idi.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "Başka bir deyişle sütun uzayı, matrisinizin sütunlarının aralığıdır.",
  "model": "google_nmt",
  "from_community_srt": "Başka bir deyişle, sütun uzayı, matrix'in sütunlarının alabileceği değerler kapsamıdır.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Yani rütbenin daha kesin bir tanımı, sütun uzayındaki boyutların sayısıdır.",
  "model": "google_nmt",
  "from_community_srt": "Dolayısıyla, daha isabetli bir tarifle; mertebe Sütun uzayındaki boyut anlamı şeklinde ifade edilebilir.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Bu rütbe olabildiğince yüksek olduğunda, yani sütun sayısına eşit olduğunda matrise tam sıra diyoruz.",
  "model": "google_nmt",
  "from_community_srt": "Bu mertebe olabildiğince yüksek olduğunda, yani sütun sayısına eşit olduğunda matrix'imizi Tam Mertebeli ?!",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Doğrusal dönüşümlerin orijini sabit tutması gerektiğinden sıfır vektörünün her zaman sütun uzayına dahil edileceğine dikkat edin.",
  "model": "google_nmt",
  "from_community_srt": "olarak tarif ederiz. (Full Rank) Dikkat et, sıfır vektör daima Sütun Uzayına dahil ediliyor. Çünki, doğrusal dönüşümlerde orijin yerini korumalı.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "Tam dereceli bir dönüşüm için orijine gelen tek vektör sıfır vektörün kendisidir.",
  "model": "google_nmt",
  "from_community_srt": "Tam Mertebeli dönüşümlerde orijinde olan tek vektör sıfır vektörün kendisidir, Tam Mertebeli olmayan matrixlerde ise,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Ancak tam sıralı olmayan, daha küçük bir boyuta sıkışan matrisler için, sıfıra inen bir sürü vektöre sahip olabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "ki uzay alt boyutlara büzüşür, sıfır üzerine düşen bir sürü vektör vardır.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Örneğin, bir 2 boyutlu dönüşüm alanı bir çizgiye sıkıştırırsa, farklı yönde orijine doğru sıkıştırılan vektörlerle dolu ayrı bir çizgi vardır.",
  "model": "google_nmt",
  "from_community_srt": "eğer 2Boyutlu bir vektör doğru üzerine çökerse, örneğin sıfır noktasına sıkışan bir doğru dolusu vektör olacaktır ki hepsi orijine birikecekler.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Bir 3 boyutlu dönüşüm uzayı bir düzlemin üzerine sıkıştırırsa, orijine inen bir dizi vektör de vardır.",
  "model": "google_nmt",
  "from_community_srt": "Eğer 3Boyutlu bir dönüşüm, uzayı düzleme sıkıştırırsa, bir doğru dolusu vektör orijine çöker yine.",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Bir 3 boyutlu dönüşüm tüm uzayı bir çizgiye sıkıştırırsa, orijine inen vektörlerle dolu bir düzlem olur.",
  "model": "google_nmt",
  "from_community_srt": "eğer 3Boyutlu bir dönüşüm bir doğruya sıkışırsa, bir düzlem dolusu vektör orijine sıkışmış demektir.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Orijine inen bu vektörler kümesine sıfır uzayı veya matrisinizin çekirdeği denir.",
  "model": "google_nmt",
  "from_community_srt": "İşte tüm bu orijine (sıfır noktasına)sıkışan vektörler, o matrixin \"boşluk uzayı\" ya da çekirdeği diye anılırlar.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "Sıfır vektörüne inmeleri anlamında sıfır olan tüm vektörlerin uzayıdır.",
  "model": "google_nmt",
  "from_community_srt": "Öyle bir uzay ki tüm vektörleri boşluk, boşluk derken tüm vektörler sıfır üzerinde anlamında.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "Doğrusal denklem sistemi açısından, v sıfır vektörü olduğunda sıfır uzayı size denklemin tüm olası çözümlerini verir.",
  "model": "google_nmt",
  "from_community_srt": "Doğrusal eşitlik sistemleri bakımından, v vektörü zero vektör olduğunda boşluk uzayı eşitlik için tüm olası çözümleri verir.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Bu, doğrusal denklem sistemlerinin geometrik olarak nasıl düşünüleceğine dair çok yüksek düzeyde bir genel bakış.",
  "model": "google_nmt",
  "from_community_srt": "İşte bu, kabaca \"doğrusal eşitlik sistemleri geometrik olarak nedir\" sorusunun cevabı.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "Her sistemin kendisiyle ilişkili bir tür doğrusal dönüşümü vardır ve bu dönüşümün tersi olduğunda, sisteminizi çözmek için bu tersini kullanabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Her sistem kendisi ile ilişkilendirilecek bir doğrusal dönüşüme sahiptir, ve bu dönüşümün tersi mevcut olduğunda, bu ters i kullnarak sistemi çözebiliriz.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "Aksi takdirde, sütun uzayı fikri bir çözümün ne zaman var olduğunu anlamamızı sağlar ve sıfır uzayı fikri tüm olası çözümler kümesinin neye benzeyebileceğini anlamamıza yardımcı olur.",
  "model": "google_nmt",
  "from_community_srt": "Aksi durumda; sütun uzayı fikri ise bize, yine de bir çözüm olacağını bildirir. Boşluk uzayı kavramı ise; tüm olası sonuçların nasıl görünebileceği hakkında fikir verir.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Yine burada ele almadığım pek çok şey var, en önemlisi bunların nasıl hesaplanacağı.",
  "model": "google_nmt",
  "from_community_srt": "Tekrar edeyim, burada ele almadığım bir sürü konu var, en dikkat çekeni ise, bunların nasıl hesaplandığı konusu.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Ayrıca kapsamımı denklem sayısının bilinmeyenlerin sayısına eşit olduğu örneklerle sınırlamak zorunda kaldım.",
  "model": "google_nmt",
  "from_community_srt": "Ayrıca örneklerimi eşitlik sayısı ile bilinmeyen sayısının eşit olduğu durumlara kısıtladım.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Ancak buradaki amaç her şeyi öğretmeye çalışmak değil, ters matrisler, sütun uzayı ve sıfır uzayı hakkında güçlü bir sezgiye sahip olmanız ve bu sezgilerin gelecekte yapacağınız her türlü öğrenmeyi daha verimli hale getirmesidir.",
  "model": "google_nmt",
  "from_community_srt": "Fakat buradaki amacımız herşeyi öğretmek değil zaten; amacımız, ters matrix, sütun uzayı, ve boşluk uzayı konularında kavrama gerçekleştirmeniz. BU kavramalar sayesinde gelecekteki öğrenmeleriniz çok zengin olacaktır.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "Bir sonraki videoda, yoğun istek üzerine, kare olmayan matrisler hakkında kısa bir dipnot olacak.",
  "model": "google_nmt",
  "from_community_srt": "Gelecek videoda, yaygın talep olarak, özetle karesel olmayan matrixlerden bahsedeceğim.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Daha sonra, size nokta çarpımları hakkındaki görüşlerimi anlatacağım ve bunlara doğrusal dönüşümlerin ışığı altında baktığınızda oldukça hoş bir şey oluyor.",
  "model": "google_nmt",
  "from_community_srt": "Sonrasında, Nokta Ürünü hakkında notlarımı aktaracağım. İşlemleri doğrusal dönüşümler ışığında görünce aydınlanma gibi bir duygu yaşayacaksınız.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]