1
00:00:11,143 --> 00:00:15,566
Amint azt valószínűleg mostanra is láthatja, ennek a sorozatnak a nagy része a mátrix-

2
00:00:15,566 --> 00:00:20,040
és vektorműveletek megértése a lineáris transzformációk vizuálisabb lencséjén keresztül.

3
00:00:20,040 --> 00:00:23,598
Ez a videó sem kivétel, és leírja az inverz mátrixok,

4
00:00:23,598 --> 00:00:28,080
az oszloptér, a rang és a nulltér fogalmát ezen a lencsén keresztül.

5
00:00:28,080 --> 00:00:31,193
Figyelmeztetés azonban, hogy nem fogok ezeknek a dolgoknak a tényleges

6
00:00:31,193 --> 00:00:34,920
kiszámításának módszereiről beszélni, és egyesek azt állítják, hogy ez nagyon fontos.

7
00:00:34,920 --> 00:00:39,762
Ezen a sorozaton kívül sok nagyon jó forrás található ezen módszerek megtanulásához,

8
00:00:39,762 --> 00:00:42,440
kulcsszavak Gauss-elimináció és sorlépcsőforma.

9
00:00:42,440 --> 00:00:46,640
Azt hiszem, a legtöbb érték, amit hozzá kell tennem, az intuíció felén van.

10
00:00:46,640 --> 00:00:49,037
Ráadásul a gyakorlatban általában úgyis kapunk olyan szoftvert,

11
00:00:49,037 --> 00:00:50,760
amely ezeket a dolgokat kiszámítja helyettünk.

12
00:00:50,760 --> 00:00:54,460
Először néhány szót a lineáris algebra hasznosságáról.

13
00:00:54,460 --> 00:00:58,578
Mostanra már van egy tippje arra vonatkozóan, hogyan használják a tér manipulációjának

14
00:00:58,578 --> 00:01:02,222
leírására, ami hasznos lehet például számítógépes grafikában és robotikában,

15
00:01:02,222 --> 00:01:06,056
de az egyik fő oka annak, hogy a lineáris algebra szélesebb körben alkalmazható,

16
00:01:06,056 --> 00:01:08,754
és szinte bármilyen műszaki tudományághoz szükséges. az,

17
00:01:08,754 --> 00:01:11,500
hogy lehetővé tesz bizonyos egyenletrendszerek megoldását.

18
00:01:11,500 --> 00:01:13,692
Amikor azt mondom, hogy egyenletrendszer, arra gondolok,

19
00:01:13,692 --> 00:01:15,730
hogy van egy listája a változókról, olyan dolgokról,

20
00:01:15,730 --> 00:01:18,500
amelyeket nem ismer, és egy listája a hozzájuk kapcsolódó egyenletekről.

21
00:01:18,500 --> 00:01:22,675
Sok helyzetben ezek az egyenletek nagyon bonyolultak lehetnek,

22
00:01:22,675 --> 00:01:26,520
de ha szerencséd van, bizonyos speciális formát ölthetnek.

23
00:01:26,520 --> 00:01:30,404
Az egyes egyenleteken belül az egyetlen dolog, ami az egyes változókkal történik,

24
00:01:30,404 --> 00:01:33,910
az az, hogy azokat valamilyen állandóval skálázzák, és az egyetlen dolog,

25
00:01:33,910 --> 00:01:37,700
ami az egyes skálázott változókkal történik, az az, hogy hozzáadódnak egymáshoz.

26
00:01:37,700 --> 00:01:41,066
Tehát nincsenek kitevők vagy képzeletbeli függvények,

27
00:01:41,066 --> 00:01:43,560
vagy két változó összeszorzása, ilyesmi.

28
00:01:43,560 --> 00:01:48,132
Az ilyen speciális egyenletrendszerek rendszerezésének tipikus módja az,

29
00:01:48,132 --> 00:01:51,201
hogy az összes változót a bal oldalra helyezzük,

30
00:01:51,201 --> 00:01:54,020
az esetleges állandókat pedig a jobb oldalra.

31
00:01:54,020 --> 00:01:58,180
Az is jó, ha függőlegesen sorba rendezzük a gyakori változókat,

32
00:01:58,180 --> 00:02:01,430
és ehhez szükség lehet néhány nulla együtthatóra,

33
00:02:01,430 --> 00:02:04,940
amikor a változó nem jelenik meg az egyik egyenletben.

34
00:02:04,940 --> 00:02:08,160
Ezt lineáris egyenletrendszernek nevezzük.

35
00:02:08,160 --> 00:02:11,940
Észreveheti, hogy ez nagyon úgy néz ki, mint a mátrix-vektor szorzás.

36
00:02:11,940 --> 00:02:17,374
Valójában az összes egyenletet összecsomagolhatja egyetlen vektoregyenletbe,

37
00:02:17,374 --> 00:02:22,738
ahol az összes konstans együtthatót tartalmazó mátrix és az összes változót

38
00:02:22,738 --> 00:02:29,020
tartalmazó vektor van, és a mátrix-vektor szorzatuk egy másik konstans vektorral egyenlő.

39
00:02:29,020 --> 00:02:34,268
Nevezzük el az A konstans mátrixot, jelöljük félkövér x-szel a változókat

40
00:02:34,268 --> 00:02:39,020
tartalmazó vektort, és hívjuk meg a jobb oldali konstans vektort v.

41
00:02:39,020 --> 00:02:43,540
Ez több, mint egy jelölési trükk, amellyel egyenletrendszerünket egy sorba írhatjuk.

42
00:02:43,540 --> 00:02:47,620
A probléma egy elég klassz geometriai értelmezésére világít rá.

43
00:02:47,620 --> 00:02:51,863
Az A mátrix valamilyen lineáris transzformációnak felel meg,

44
00:02:51,863 --> 00:02:56,872
így az Ax egyenlő v megoldása azt jelenti, hogy keresünk egy x vektort,

45
00:02:56,872 --> 00:03:00,420
amely a transzformáció alkalmazása után v-re kerül.

46
00:03:00,420 --> 00:03:02,180
Gondolj egy pillanatra, mi történik itt.

47
00:03:02,180 --> 00:03:05,813
Megtarthatja a fejében ezt a nagyon bonyolult elképzelést a több változóról,

48
00:03:05,813 --> 00:03:09,117
amelyek mindegyike keveredik egymással, ha csak a tér szaggatására és

49
00:03:09,117 --> 00:03:12,940
morfondírozására gondol, és megpróbálja kitalálni, melyik vektor kerül a másikba.

50
00:03:12,940 --> 00:03:14,860
Menő, igaz?

51
00:03:14,860 --> 00:03:16,960
Az egyszerű kezdéshez tegyük fel, hogy van egy

52
00:03:16,960 --> 00:03:19,060
rendszere két egyenletből és két ismeretlenből.

53
00:03:19,060 --> 00:03:24,780
Ez azt jelenti, hogy az A mátrix 2x2 mátrix, v és x pedig kétdimenziós vektorok.

54
00:03:24,780 --> 00:03:29,496
Az, hogy miként gondolkodunk ennek az egyenletnek a megoldásairól, attól függ,

55
00:03:29,496 --> 00:03:34,511
hogy az A-val kapcsolatos transzformáció az egész teret egy alacsonyabb dimenzióba,

56
00:03:34,511 --> 00:03:39,765
például egy vonalba vagy egy pontba zúzza-e, vagy hagy mindent a teljes két dimenzióra,

57
00:03:39,765 --> 00:03:40,780
ahol elkezdődött.

58
00:03:40,780 --> 00:03:44,619
Az utolsó videó nyelvén felosztjuk azokra az esetekre,

59
00:03:44,619 --> 00:03:48,528
amikor A-nak nulla determinánsa van, és arra az esetre,

60
00:03:48,528 --> 00:03:51,740
amikor A-nak nullától eltérő determinánsa van.

61
00:03:51,740 --> 00:03:55,045
Kezdjük a legvalószínűbb esettel, ahol a determináns nem nulla,

62
00:03:55,045 --> 00:03:58,660
ami azt jelenti, hogy a tér nem zsugorodik egy nulla területű régióba.

63
00:03:58,660 --> 00:04:02,832
Ebben az esetben mindig csak egy vektor lesz, amely v-re kerül,

64
00:04:02,832 --> 00:04:06,940
és ezt a transzformáció fordított lejátszásával találhatja meg.

65
00:04:06,940 --> 00:04:11,614
Követve, hová megy v, amikor így visszatekerjük a szalagot,

66
00:04:11,614 --> 00:04:15,900
az x vektort úgy találjuk, hogy A szor x egyenlő v-vel.

67
00:04:15,900 --> 00:04:20,119
Ha a transzformációt fordítva játssza le, az valójában egy különálló lineáris

68
00:04:20,119 --> 00:04:23,905
transzformációnak felel meg, amelyet általában A inverzének neveznek,

69
00:04:23,905 --> 00:04:25,420
és A-t a negatívnak jelölik.

70
00:04:25,420 --> 00:04:30,040
Például, ha A az óramutató járásával ellentétes irányú elforgatás 90 fokkal,

71
00:04:30,040 --> 00:04:34,780
akkor A fordítottja az óramutató járásával megegyező 90 fokkal való elforgatás.

72
00:04:34,780 --> 00:04:39,009
Ha A jobb irányú nyírás lenne, amely a j-hat egy egységgel jobbra tolja,

73
00:04:39,009 --> 00:04:42,022
akkor az A fordítottja egy bal irányú nyírás lenne,

74
00:04:42,022 --> 00:04:44,340
amely a j-hat egy egységgel balra tolja.

75
00:04:44,340 --> 00:04:47,154
Általában az A inverz az az egyedi transzformáció,

76
00:04:47,154 --> 00:04:50,355
amelynek tulajdonsága, hogy ha először alkalmazza az A-t,

77
00:04:50,355 --> 00:04:54,660
majd követi az A inverz transzformációt, akkor visszakerül oda, ahol kiindult.

78
00:04:54,660 --> 00:04:57,341
Az egyik transzformációt a másik után alkalmazva

79
00:04:57,341 --> 00:04:59,640
algebrai módon rögzítjük mátrixszorzással.

80
00:04:59,640 --> 00:05:03,817
Tehát ennek az A inverz transzformációnak az alapvető tulajdonsága,

81
00:05:03,817 --> 00:05:08,180
hogy A inverz szor A-val egyenlő a semmittevésnek megfelelő mátrixszal.

82
00:05:08,180 --> 00:05:11,840
Azt az átalakulást, amely nem csinál semmit, identitástranszformációnak nevezzük.

83
00:05:11,840 --> 00:05:20,160
Mozdulatlanul hagyja az i-hat és a j-hat értéket, így oszlopai 1,0 és 0,1.

84
00:05:20,160 --> 00:05:25,172
Ha megtalálta ezt az inverzet, amit a gyakorlatban számítógéppel is megtenne,

85
00:05:25,172 --> 00:05:30,120
megoldhatja az egyenletet úgy, hogy ezt az inverz mátrixot megszorozza v-vel.

86
00:05:30,120 --> 00:05:38,978
És még egyszer, ez geometriailag azt jelenti, hogy fordítva játszod az átalakítást,

87
00:05:38,978 --> 00:05:40,560
és követed a v.

88
00:05:40,560 --> 00:05:44,918
Ez a nem nulla determináns eset, amely a mátrix véletlenszerű megválasztása esetén

89
00:05:44,918 --> 00:05:47,963
messze a legvalószínűbb, megfelel annak az elképzelésnek,

90
00:05:47,963 --> 00:05:52,164
hogy ha két ismeretlen és két egyenlet van, akkor szinte biztosan az a helyzet,

91
00:05:52,164 --> 00:05:54,160
hogy egyetlen egyedi megoldás létezik.

92
00:05:54,160 --> 00:05:56,330
Ez az elképzelés magasabb dimenziókban is értelmes,

93
00:05:56,330 --> 00:05:58,960
amikor az egyenletek száma megegyezik az ismeretlenek számával.

94
00:05:58,960 --> 00:06:06,063
Az egyenletrendszer ismét lefordítható a geometriai értelmezésre,

95
00:06:06,063 --> 00:06:14,350
ahol van egy A transzformáció és egy v vektor, és azt az x vektort keressük,

96
00:06:14,350 --> 00:06:16,180
amely v-re kerül.

97
00:06:16,180 --> 00:06:20,821
Mindaddig, amíg az A transzformáció nem tömöríti az egész teret egy alacsonyabb

98
00:06:20,821 --> 00:06:24,302
dimenzióba, ami azt jelenti, hogy a determinánsa nem nulla,

99
00:06:24,302 --> 00:06:28,422
addig lesz egy inverz A inverz transzformáció, azzal a tulajdonsággal,

100
00:06:28,422 --> 00:06:32,657
hogy ha először megcsinálja A-t, akkor megfordítja az A-t. , ez ugyanaz,

101
00:06:32,657 --> 00:06:33,760
mint a semmittevés.

102
00:06:33,760 --> 00:06:38,700
És az egyenlet megoldásához csak meg kell szorozni

103
00:06:38,700 --> 00:06:43,640
a fordított transzformációs mátrixot a v vektorral.

104
00:06:43,640 --> 00:06:47,881
De ha a determináns nulla, és az egyenletrendszerhez kapcsolódó

105
00:06:47,881 --> 00:06:52,520
transzformáció a teret kisebb dimenzióba tömöríti, akkor nincs inverz.

106
00:06:52,520 --> 00:06:56,040
Egy vonalat nem lehet kicsavarni, hogy síkká változzon.

107
00:06:56,040 --> 00:06:58,500
Legalábbis erre egy függvény nem képes.

108
00:06:58,500 --> 00:07:03,880
Ehhez minden egyes vektort egy vektorokkal teli sorrá kell átalakítani.

109
00:07:03,880 --> 00:07:07,720
De a funkciók csak egyetlen bemenetet tudnak egyetlen kimenetre átvinni.

110
00:07:07,720 --> 00:07:13,031
Hasonlóképpen, három egyenlet és három ismeretlen esetében nem lesz inverz,

111
00:07:13,031 --> 00:07:16,525
ha a megfelelő transzformáció a 3D teret a síkra,

112
00:07:16,525 --> 00:07:19,880
vagy akár egy egyenesre vagy pontra zúzza össze.

113
00:07:19,880 --> 00:07:23,185
Ezek mindegyike a nulla determinánsának felel meg,

114
00:07:23,185 --> 00:07:27,140
mivel bármely régió nulla térfogatú valamivé van összenyomva.

115
00:07:27,140 --> 00:07:31,160
Még mindig lehetséges, hogy létezik megoldás akkor is, ha nincs inverz.

116
00:07:31,160 --> 00:07:37,500
Csak arról van szó, hogy amikor a transzformációd helyet zúdít mondjuk egy vonalra,

117
00:07:37,500 --> 00:07:43,540
akkor elég szerencsésnek kell lenned, hogy a v vektor valahol azon a vonalon él.

118
00:07:43,540 --> 00:07:48,404
Észreveheti, hogy ezen nulla meghatározó esetek némelyike sokkal korlátozóbbnak tűnik,

119
00:07:48,404 --> 00:07:49,020
mint mások.

120
00:07:49,020 --> 00:07:55,403
Ha például egy 3x3-as mátrixot adunk meg, sokkal nehezebbnek tűnik egy megoldás létezése,

121
00:07:55,403 --> 00:08:00,368
amikor egy vonalra húzza a teret, mint amikor a dolgokat síkra vágja,

122
00:08:00,368 --> 00:08:02,780
pedig mindkettő nulla meghatározó.

123
00:08:02,780 --> 00:08:05,230
Van néhány olyan nyelvezetünk, amely egy kicsit konkrétabb,

124
00:08:05,230 --> 00:08:06,660
mint a nulla determináns kimondása.

125
00:08:06,660 --> 00:08:11,415
Ha egy transzformáció kimenete egy vonal, vagyis egydimenziós,

126
00:08:11,415 --> 00:08:15,340
akkor azt mondjuk, hogy a transzformáció rangja egy.

127
00:08:15,340 --> 00:08:19,337
Ha az összes vektor egy kétdimenziós síkon landol,

128
00:08:19,337 --> 00:08:23,100
azt mondjuk, hogy a transzformáció rangja kettő.

129
00:08:23,100 --> 00:08:28,500
Tehát a rang szó a transzformáció kimenetében lévő dimenziók számát jelenti.

130
00:08:28,500 --> 00:08:33,200
Például 2x2-es mátrixok esetén a 2. rang a lehető legjobb.

131
00:08:33,200 --> 00:08:38,060
Ez azt jelenti, hogy a bázisvektorok továbbra is átfogják a tér két dimenzióját,

132
00:08:38,060 --> 00:08:39,680
és a determináns nem nulla.

133
00:08:39,680 --> 00:08:43,389
De a 3x3-as mátrixoknál a 2-es rang azt jelenti, hogy összeestünk,

134
00:08:43,389 --> 00:08:47,320
de nem annyira, mint amennyire 1-es helyzet esetén összeomlottak volna.

135
00:08:47,320 --> 00:08:51,129
Ha egy 3D-s transzformációnak nullától eltérő determinánsa van,

136
00:08:51,129 --> 00:08:54,700
és a kimenete kitölti a teljes 3D-s teret, akkor a rangja 3.

137
00:08:54,700 --> 00:09:00,182
A mátrix összes lehetséges kimenetének ezt a halmazát, legyen az egyenes,

138
00:09:00,182 --> 00:09:04,480
sík, 3D-s tér vagy bármi, a mátrix oszlopterének nevezzük.

139
00:09:04,480 --> 00:09:06,780
Valószínűleg kitalálod, honnan származik ez a név.

140
00:09:06,780 --> 00:09:10,544
A mátrix oszlopai megmondják, hol érnek a bázisvektorok,

141
00:09:10,544 --> 00:09:15,233
és ezeknek a transzformált bázisvektoroknak a spanja megadja az összes

142
00:09:15,233 --> 00:09:16,620
lehetséges kimenetet.

143
00:09:16,620 --> 00:09:23,800
Más szóval, az oszloptér a mátrixod oszlopainak fesztávja.

144
00:09:23,800 --> 00:09:30,240
Tehát a rang pontosabb meghatározása az lenne, ha ez az oszloptérben lévő dimenziók száma.

145
00:09:30,240 --> 00:09:32,993
Ha ez a rang olyan magas, amennyire csak lehet,

146
00:09:32,993 --> 00:09:37,640
vagyis megegyezik az oszlopok számával, akkor a mátrixot teljes rangnak nevezzük.

147
00:09:37,640 --> 00:09:42,175
Figyeljük meg, a nulla vektor mindig benne lesz az oszloptérben,

148
00:09:42,175 --> 00:09:47,060
mivel a lineáris transzformációknak az origót a helyén kell tartaniuk.

149
00:09:47,060 --> 00:09:50,182
Teljes rangú transzformáció esetén az egyetlen vektor,

150
00:09:50,182 --> 00:09:52,680
amely az origóba kerül, maga a nulla vektor.

151
00:09:52,680 --> 00:09:58,530
De a nem teljes rangú mátrixok esetében, amelyek kisebb dimenzióba süllyednek,

152
00:09:58,530 --> 00:10:02,160
egy csomó vektor lehet, amelyek nullára kerülnek.

153
00:10:02,160 --> 00:10:06,141
Ha például egy 2D-s transzformáció teret szaggat egy vonalra,

154
00:10:06,141 --> 00:10:11,920
akkor van egy külön sor egy másik irányban, tele vektorokkal, amelyek az origóba kerülnek.

155
00:10:11,920 --> 00:10:16,491
Ha egy 3D-s transzformáció egy síkra zúzza a teret,

156
00:10:16,491 --> 00:10:20,800
akkor a vektorok teljes sora is az origóba kerül.

157
00:10:20,800 --> 00:10:26,857
Ha egy 3D-s transzformáció az egész teret egy egyenesre préseli,

158
00:10:26,857 --> 00:10:33,380
akkor egy egész sík van tele vektorokkal, amelyek az origóba kerülnek.

159
00:10:33,380 --> 00:10:39,360
Ezt a vektorhalmazt, amely az origóba kerül, nulltérnek vagy a mátrix kernelének nevezzük.

160
00:10:39,360 --> 00:10:42,358
Ez az összes vektor tere, amely nullává válik,

161
00:10:42,358 --> 00:10:45,740
abban az értelemben, hogy a nulla vektoron landolnak.

162
00:10:45,740 --> 00:10:52,048
A lineáris egyenletrendszer szempontjából, amikor v véletlenül a nulla vektor,

163
00:10:52,048 --> 00:10:56,920
a nulla tér megadja az egyenlet összes lehetséges megoldását.

164
00:10:56,920 --> 00:10:59,219
Tehát ez egy nagyon magas szintű áttekintés arról,

165
00:10:59,219 --> 00:11:02,420
hogyan kell geometriailag gondolkodni a lineáris egyenletrendszerekről.

166
00:11:02,420 --> 00:11:05,941
Minden rendszerhez tartozik valamilyen lineáris transzformáció,

167
00:11:05,941 --> 00:11:10,564
és ha ennek a transzformációnak van inverze, akkor ezt az inverzetet használhatja a

168
00:11:10,564 --> 00:11:11,720
rendszer megoldására.

169
00:11:11,720 --> 00:11:15,735
Ellenkező esetben az oszloptér fogalma lehetővé teszi számunkra,

170
00:11:15,735 --> 00:11:20,801
hogy megértsük, mikor létezik megoldás, a nulla tér ötlete pedig segít megérteni,

171
00:11:20,801 --> 00:11:24,200
hogyan nézhet ki az összes lehetséges megoldás halmaza.

172
00:11:24,200 --> 00:11:27,058
Ismét sok mindenre nem tértem ki itt, különösen,

173
00:11:27,058 --> 00:11:29,800
hogy hogyan kell kiszámítani ezeket a dolgokat.

174
00:11:29,800 --> 00:11:32,310
Olyan példákra is korlátoznom kellett a hatókörömet,

175
00:11:32,310 --> 00:11:35,200
ahol az egyenletek száma megegyezik az ismeretlenek számával.

176
00:11:35,200 --> 00:11:38,336
De a cél itt nem az, hogy mindent megtanítson, hanem az,

177
00:11:38,336 --> 00:11:41,362
hogy erős intuícióval rendelkezzen az inverz mátrixok,

178
00:11:41,362 --> 00:11:45,489
az oszloptér és a nulla tér tekintetében, és hogy ezek az intuíciók minden

179
00:11:45,489 --> 00:11:47,800
jövőbeni tanulást gyümölcsözőbbé tegyenek.

180
00:11:47,800 --> 00:11:52,480
A következő videó, közkívánatra, egy rövid lábjegyzet lesz a nem négyzetes mátrixokról.

181
00:11:52,480 --> 00:11:55,030
Aztán ezek után elmondom a véleményemet a ponttermékekről,

182
00:11:55,030 --> 00:11:57,364
és valami nagyon klassz dologról, ami akkor történik,

183
00:11:57,364 --> 00:11:59,440
ha lineáris transzformációk fényében nézed őket.

184
00:11:59,440 --> 00:11:59,440
Majd találkozunk!

