1
00:00:10,240 --> 00:00:14,323
Ahogyan azt már valószínűleg látod, e sorozat nagy része a mátrix- és 

2
00:00:14,323 --> 00:00:19,340
vektorműveletek megértéséről szól a lineáris transzformációk vizuálisabb szemszögéből.

3
00:00:19,980 --> 00:00:24,844
Ez a videó sem kivétel ez alól, és ezen keresztül ismerteti az inverz mátrixok, 

4
00:00:24,844 --> 00:00:27,520
az oszloptér, a rang és a null-tér fogalmát.

5
00:00:27,520 --> 00:00:29,920
Előrebocsátom, hogy nem fogok beszélni a módszerekről, 

6
00:00:29,920 --> 00:00:32,407
amelyekkel ezeket a dolgokat ténylegesen kiszámíthatjuk, 

7
00:00:32,407 --> 00:00:34,240
pedig egyesek szerint ez nagyon is fontos.

8
00:00:34,840 --> 00:00:38,395
Sok nagyon jó forrás áll rendelkezésre a módszerek elsajátításához ezen a 

9
00:00:38,395 --> 00:00:42,000
sorozaton kívül, a kulcsszavak a Gauss-elimináció és a soros echelon-forma.

10
00:00:42,540 --> 00:00:46,340
Azt hiszem, a legtöbb érték, amit hozzá kell tennem, az intuíció felénél van.

11
00:00:46,900 --> 00:00:48,918
Ráadásul a gyakorlatban általában úgyis egy szoftver 

12
00:00:48,918 --> 00:00:50,480
számítja ki ezeket a dolgokat helyettünk.

13
00:00:51,500 --> 00:00:53,920
Először néhány szó a lineáris algebra hasznosságáról.

14
00:00:54,300 --> 00:00:57,894
Mostanra már sejted, hogyan használják a tér manipulálásának leírására, 

15
00:00:57,894 --> 00:01:01,040
ami hasznos például a számítógépes grafikában és a robotikában.

16
00:01:01,500 --> 00:01:04,610
De az egyik fő oka annak, hogy a lineáris algebra szélesebb körben 

17
00:01:04,610 --> 00:01:07,535
alkalmazható és szinte minden műszaki tudományágban szükséges, 

18
00:01:07,535 --> 00:01:10,460
az, hogy lehetővé teszi bizonyos egyenletrendszerek megoldását.

19
00:01:11,380 --> 00:01:13,482
Amikor azt mondom, hogy egyenletrendszer, akkor úgy értem, 

20
00:01:13,482 --> 00:01:16,084
hogy van egy listád változókról, olyan dolgokról, amelyeket nem ismersz, 

21
00:01:16,084 --> 00:01:17,760
és egy listát a hozzájuk tartozó egyenletekről.

22
00:01:18,340 --> 00:01:21,600
Sok helyzetben ezek az egyenletek nagyon bonyolulttá válhatnak.

23
00:01:22,120 --> 00:01:25,300
De ha szerencsés vagy, akkor egy bizonyos különleges formát ölthetnek.

24
00:01:26,440 --> 00:01:30,130
Az egyes egyenleteken belül az egyetlen dolog, ami az egyes változókkal történik, 

25
00:01:30,130 --> 00:01:33,280
az az, hogy valamilyen konstanssal skálázódnak, és az egyetlen dolog, 

26
00:01:33,280 --> 00:01:36,880
ami az egyes skálázott változókkal történik, az az, hogy összeadódnak egymással.

27
00:01:37,540 --> 00:01:40,081
Tehát nincsenek exponensek, vagy furcsa függvények, 

28
00:01:40,081 --> 00:01:42,280
vagy két változó összeszorzása, vagy ilyesmi.

29
00:01:43,420 --> 00:01:47,580
Az ilyen speciális egyenletrendszerek megszervezésének tipikus módja az, 

30
00:01:47,580 --> 00:01:52,140
hogy az összes változót balra dobjuk, a maradék állandókat pedig jobbra tesszük.

31
00:01:53,600 --> 00:01:56,683
Az is jó, ha a közös változókat függőlegesen sorba állítjuk, 

32
00:01:56,683 --> 00:01:59,210
és ehhez szükség lehet néhány nulla együtthatóra, 

33
00:01:59,210 --> 00:02:01,940
amikor a változó nem jelenik meg az egyik egyenletben.

34
00:02:04,540 --> 00:02:07,240
Ezt lineáris egyenletrendszernek nevezzük.

35
00:02:08,100 --> 00:02:11,180
Észreveheti, hogy ez nagyon hasonlít a mátrix-vektor szorzásra.

36
00:02:11,820 --> 00:02:16,314
Valójában az összes egyenletet egyetlen vektoregyenletbe csomagolhatjuk, 

37
00:02:16,314 --> 00:02:20,993
ahol az összes konstans együtthatót tartalmazó mátrix és az összes változót 

38
00:02:20,993 --> 00:02:26,164
tartalmazó vektor van, és a mátrix-vektor szorzatuk egyenlő valamilyen más konstans 

39
00:02:26,164 --> 00:02:26,780
vektorral.

40
00:02:28,640 --> 00:02:33,230
Nevezzük ezt a konstans mátrixot A-nak, a változókat tartalmazó vektort jelöljük 

41
00:02:33,230 --> 00:02:37,480
félkövér X-szel, a jobb oldalon lévő konstans vektort pedig nevezzük V-nek.

42
00:02:38,860 --> 00:02:42,980
Ez több mint egy jegyzetelési trükk, hogy az egyenletrendszerünket egy sorba írjuk.

43
00:02:43,340 --> 00:02:46,780
Ez rávilágít a probléma egy nagyon jó geometriai értelmezésére.

44
00:02:47,620 --> 00:02:51,053
Az A mátrix valamilyen lineáris transzformációnak felel meg, 

45
00:02:51,053 --> 00:02:55,105
így az Ax egyenlő V megoldása azt jelenti, hogy egy X vektort keresünk, 

46
00:02:55,105 --> 00:02:57,920
amely a transzformáció alkalmazása után V-re esik.

47
00:02:59,940 --> 00:03:01,780
Gondoljatok bele egy pillanatra, hogy mi történik itt.

48
00:03:02,060 --> 00:03:04,890
A fejedben tarthatod ezt az igazán bonyolult elképzelést, 

49
00:03:04,890 --> 00:03:08,354
hogy több változó keveredik egymással, ha csak a tér összenyomására és 

50
00:03:08,354 --> 00:03:12,600
morfózisára gondolsz, és megpróbálod kitalálni, hogy melyik vektor melyik másikra esik.

51
00:03:13,160 --> 00:03:13,760
Király, nem?

52
00:03:14,600 --> 00:03:17,074
Kezdjük egyszerűen, tegyük fel, hogy van egy rendszerünk 

53
00:03:17,074 --> 00:03:18,680
két egyenletből és két ismeretlenből.

54
00:03:19,000 --> 00:03:23,960
Ez azt jelenti, hogy az A mátrix egy 2x2 mátrix, V és X pedig egy-egy kétdimenziós vektor.

55
00:03:25,600 --> 00:03:28,805
Az, hogy hogyan gondolkodunk ennek az egyenletnek a megoldásairól, 

56
00:03:28,805 --> 00:03:32,010
attól függ, hogy az A-hoz kapcsolódó transzformáció az egész teret 

57
00:03:32,010 --> 00:03:35,742
egy alacsonyabb dimenzióba, például egy vonalba vagy egy pontba zsugorítja-e, 

58
00:03:35,742 --> 00:03:38,900
vagy pedig mindent ott hagy, ahol a teljes két dimenzióban kezdte.

59
00:03:40,320 --> 00:03:43,545
Az utolsó videó nyelvezetében felosztjuk azokra az esetekre, 

60
00:03:43,545 --> 00:03:48,040
amikor A determináns nulla, és azokra, amikor A nem nulla determinánssal rendelkezik.

61
00:03:51,300 --> 00:03:55,187
Kezdjük a legvalószínűbb esettel, amikor a determináns nem nulla, 

62
00:03:55,187 --> 00:03:57,720
vagyis a tér nem szorul nullás tartományba.

63
00:03:58,600 --> 00:04:02,460
Ebben az esetben mindig lesz egy és csak egy vektor, amelyik V-re esik, 

64
00:04:02,460 --> 00:04:06,160
és ezt úgy találhatjuk meg, ha a transzformációt visszafelé játsszuk.

65
00:04:06,700 --> 00:04:10,056
Ha követjük, hogy hová megy V, miközben így tekerjük vissza a szalagot, 

66
00:04:10,056 --> 00:04:13,460
akkor megtaláljuk azt az x vektort, ahol A szorozva x-szel egyenlő V-vel.

67
00:04:15,400 --> 00:04:19,518
Ha a transzformációt fordítva játsszuk le, az valójában egy külön lineáris 

68
00:04:19,518 --> 00:04:23,362
transzformációnak felel meg, amelyet általában A inverzének neveznek, 

69
00:04:23,362 --> 00:04:24,680
és A negatívra jelölnek.

70
00:04:25,360 --> 00:04:29,134
Például, ha A az óramutató járásával ellentétes irányú 90 fokos elforgatás, 

71
00:04:29,134 --> 00:04:32,760
akkor A fordítottja az óramutató járásával megegyező 90 fokos elforgatás.

72
00:04:34,320 --> 00:04:38,124
Ha A egy jobbra irányuló nyírás lenne, amely a j-hatot egy egységgel jobbra tolja, 

73
00:04:38,124 --> 00:04:40,554
akkor A fordítottja egy balra irányuló nyírás lenne, 

74
00:04:40,554 --> 00:04:42,480
amely a j-hatot egy egységgel balra tolja.

75
00:04:44,100 --> 00:04:47,226
Általánosságban az A inverz transzformáció az egyetlen olyan transzformáció, 

76
00:04:47,226 --> 00:04:49,825
amelynek az a tulajdonsága, hogy ha először alkalmazzuk az A-t, 

77
00:04:49,825 --> 00:04:53,480
majd ezt követi az A inverz transzformáció, akkor visszakerülünk oda, ahonnan elindultunk.

78
00:04:54,540 --> 00:04:58,700
Az egyik transzformáció egymás utáni alkalmazása algebrailag mátrixszorzással 

79
00:04:58,700 --> 00:05:02,539
ragadható meg, így az A inverz transzformáció alapvető tulajdonsága az, 

80
00:05:02,539 --> 00:05:07,340
hogy A inverz szorozva A-val egyenlő azzal a mátrixszal, amely a semmittevésnek felel meg.

81
00:05:08,200 --> 00:05:11,320
Azt a transzformációt, amely nem csinál semmit, identitás-transzformációnak nevezzük.

82
00:05:11,780 --> 00:05:15,251
Az i-hat és a j-hat mindegyiket ott hagyja, ahol van, 

83
00:05:15,251 --> 00:05:18,080
azaz nem mozdul, így az oszlopai 1,0 és 0,1.

84
00:05:19,980 --> 00:05:24,036
Miután megtaláltad ezt az inverzét, amit a gyakorlatban egy számítógéppel tehetsz meg, 

85
00:05:24,036 --> 00:05:27,720
megoldhatod az egyenletedet úgy, hogy ezt az inverz mátrixot megszorozod v-vel.

86
00:05:29,960 --> 00:05:35,380
És ismétlem, ez geometriailag azt jelenti, hogy a transzformációt fordítva játszod le, 

87
00:05:35,380 --> 00:05:36,440
és a v-t követed.

88
00:05:40,200 --> 00:05:44,070
Ez a nem nulla determináns eset, amely egy véletlenszerűen kiválasztott mátrix 

89
00:05:44,070 --> 00:05:47,353
esetében messze a legvalószínűbb, megfelel annak az elképzelésnek, 

90
00:05:47,353 --> 00:05:50,538
hogy ha két ismeretlen és két egyenlet van, akkor szinte biztos, 

91
00:05:50,538 --> 00:05:52,400
hogy egyetlen egyedi megoldás létezik.

92
00:05:53,680 --> 00:05:56,395
Ennek az elképzelésnek magasabb dimenziókban is van értelme, 

93
00:05:56,395 --> 00:05:59,200
amikor az egyenletek száma megegyezik az ismeretlenek számával.

94
00:05:59,380 --> 00:06:04,856
Az egyenletrendszer ismét lefordítható a geometriai értelmezésre, 

95
00:06:04,856 --> 00:06:11,080
ahol van egy A transzformáció és egy vektor, és azt az x vektort keressük, 

96
00:06:11,080 --> 00:06:12,740
amelyik a v-re esik.

97
00:06:15,740 --> 00:06:20,469
Amíg az A transzformáció nem nyomja össze az egész teret egy alacsonyabb dimenzióba, 

98
00:06:20,469 --> 00:06:24,530
vagyis a determinánsa nem nulla, addig lesz egy A inverz transzformáció, 

99
00:06:24,530 --> 00:06:28,758
amelynek az a tulajdonsága, hogy ha először A-t csináljuk, majd A inverzét, 

100
00:06:28,758 --> 00:06:31,040
az ugyanaz, mintha nem csinálnánk semmit.

101
00:06:33,540 --> 00:06:36,516
Az egyenlet megoldásához pedig csak meg kell szoroznunk 

102
00:06:36,516 --> 00:06:39,440
ezt a fordított transzformációs mátrixot a v vektorral.

103
00:06:43,500 --> 00:06:47,593
Ha azonban a determináns nulla, és az egyenletrendszerhez tartozó 

104
00:06:47,593 --> 00:06:52,060
transzformáció kisebb dimenzióba zsugorítja a teret, akkor nincs inverz.

105
00:06:52,480 --> 00:06:55,460
Egy vonalat nem lehet felbontani, hogy síkba alakítsuk.

106
00:06:55,980 --> 00:06:58,060
Legalábbis ez nem olyasmi, amit egy függvény megtehet.

107
00:06:58,360 --> 00:07:02,980
Ehhez minden egyes vektort át kellene alakítani egy egész sornyi vektorrá.

108
00:07:03,740 --> 00:07:06,740
De a függvények csak egyetlen bemenetből egyetlen kimenethez juthatnak.

109
00:07:08,400 --> 00:07:12,993
Hasonlóképpen, három egyenlet és három ismeretlen esetén nem lesz inverz, 

110
00:07:12,993 --> 00:07:16,098
ha a megfelelő transzformáció a 3D teret a síkra, 

111
00:07:16,098 --> 00:07:19,140
vagy akár egy egyenesre vagy egy pontra szorítja.

112
00:07:19,920 --> 00:07:24,000
Ezek mind nulla determinánsnak felelnek meg, mivel minden régiót összenyomnak valamibe, 

113
00:07:24,000 --> 00:07:25,160
amelynek térfogata nulla.

114
00:07:26,700 --> 00:07:30,640
Akkor is lehetséges, hogy létezik megoldás, ha nincs inverz.

115
00:07:30,720 --> 00:07:34,675
Csak amikor a transzformációnk összenyomja a teret mondjuk egy egyenesre, 

116
00:07:34,675 --> 00:07:39,380
akkor elég szerencsésnek kell lennünk, hogy a vektor v valahol ezen az egyenesen legyen.

117
00:07:43,300 --> 00:07:47,732
Észreveheti, hogy néhány ilyen nulla determináns eset sokkal korlátozottabbnak tűnik, 

118
00:07:47,732 --> 00:07:48,300
mint mások.

119
00:07:48,840 --> 00:07:53,411
Egy 3x3-as mátrix esetén például sokkal nehezebbnek tűnik a megoldás létezése, 

120
00:07:53,411 --> 00:07:57,578
ha a teret egy vonalra szorítja, mint ha egy síkra szorítja a dolgokat, 

121
00:07:57,578 --> 00:08:00,240
még akkor is, ha mindkettő nulla determinánsú.

122
00:08:02,600 --> 00:08:04,509
Van néhány olyan nyelvezetünk, amely egy kicsit konkrétabb, 

123
00:08:04,509 --> 00:08:06,100
mintha csak azt mondanánk, hogy nulla determináns.

124
00:08:06,520 --> 00:08:10,343
Ha egy transzformáció kimenete egy vonal, vagyis egydimenziós, 

125
00:08:10,343 --> 00:08:13,500
akkor azt mondjuk, hogy a transzformáció rangja egy.

126
00:08:15,140 --> 00:08:17,918
Ha az összes vektor egy kétdimenziós síkban helyezkedik el, 

127
00:08:17,918 --> 00:08:20,420
akkor azt mondjuk, hogy a transzformáció rangja kettő.

128
00:08:22,920 --> 00:08:27,480
A rang szó tehát a transzformáció kimenetében lévő dimenziók számát jelenti.

129
00:08:28,400 --> 00:08:32,720
Például a 2x2-es mátrixok esetében a kettes rang a legjobb, ami lehet.

130
00:08:33,080 --> 00:08:37,613
Ez azt jelenti, hogy az alapvektorok továbbra is a tér teljes két dimenzióját lefedik, 

131
00:08:37,613 --> 00:08:39,020
és a determináns nem nulla.

132
00:08:39,419 --> 00:08:42,852
De a 3x3-as mátrixok esetében a kettes rang azt jelenti, hogy összeomlottunk, 

133
00:08:42,852 --> 00:08:46,460
de nem annyira, mint amennyire összeomlottak volna egy egyes rangú helyzet esetén.

134
00:08:47,240 --> 00:08:49,808
Ha egy 3D transzformációnak nem nulla determinánsa van, 

135
00:08:49,808 --> 00:08:53,340
és a kimenete kitölti az egész 3D teret, akkor a transzformáció rangja három.

136
00:08:54,520 --> 00:08:58,676
A mátrixod összes lehetséges kimeneteinek halmazát - legyen az egy vonal, 

137
00:08:58,676 --> 00:09:02,720
egy sík, egy 3D tér, vagy bármi más - a mátrixod oszlopterének nevezzük.

138
00:09:04,140 --> 00:09:06,280
Valószínűleg kitalálhatod, honnan származik ez a név.

139
00:09:06,560 --> 00:09:10,537
A mátrix oszlopai megmondják, hogy a bázisvektorok hol helyezkednek el, 

140
00:09:10,537 --> 00:09:15,287
és ezeknek az átalakított bázisvektoroknak a tartománya adja meg az összes lehetséges 

141
00:09:15,287 --> 00:09:15,840
kimenetet.

142
00:09:16,360 --> 00:09:21,140
Más szóval, az oszloptér a mátrix oszlopainak terjedelme.

143
00:09:23,300 --> 00:09:26,212
A rang pontosabb meghatározása tehát az lenne, 

144
00:09:26,212 --> 00:09:28,940
hogy a rang az oszloptér dimenzióinak száma.

145
00:09:29,940 --> 00:09:33,862
Ha ez a rang a lehető legmagasabb, azaz megegyezik az oszlopok számával, 

146
00:09:33,862 --> 00:09:36,120
akkor a mátrixot teljes rangúnak nevezzük.

147
00:09:38,540 --> 00:09:42,110
Vegyük észre, hogy a nullvektor mindig benne lesz az oszloptérben, 

148
00:09:42,110 --> 00:09:45,840
mivel a lineáris transzformációknak az origót a helyén kell tartaniuk.

149
00:09:46,900 --> 00:09:49,711
Teljes rangú transzformáció esetén az egyetlen vektor, 

150
00:09:49,711 --> 00:09:51,960
amely az origóban landol, maga a nullvektor.

151
00:09:52,460 --> 00:09:56,182
De a nem teljes rangú mátrixok esetében, amelyek kisebb dimenzióba szorulnak, 

152
00:09:56,182 --> 00:09:58,760
egy csomó olyan vektorod lehet, amelyik nullán landol.

153
00:10:01,640 --> 00:10:05,294
Ha egy 2D transzformáció például egy egyenesre szorítja a teret, 

154
00:10:05,294 --> 00:10:08,949
akkor egy másik irányban egy külön egyenes van tele vektorokkal, 

155
00:10:08,949 --> 00:10:10,580
amelyek az origóra szorulnak.

156
00:10:11,780 --> 00:10:14,700
Ha egy 3D-s transzformáció a teret egy síkba nyomja, 

157
00:10:14,700 --> 00:10:17,620
akkor a vektorok egy teljes sora is az origón landol.

158
00:10:20,520 --> 00:10:23,834
Ha egy 3D transzformáció az egész teret egy egyenesre szorítja, 

159
00:10:23,834 --> 00:10:27,460
akkor egy egész sík tele van vektorokkal, amelyek az origón landolnak.

160
00:10:32,800 --> 00:10:35,965
A vektoroknak ezt a halmazát, amely az origón landol, 

161
00:10:35,965 --> 00:10:38,780
null-térnek vagy a mátrixod kernelének nevezzük.

162
00:10:39,360 --> 00:10:41,940
Ez az összes olyan vektor tere, amely nullává válik, 

163
00:10:41,940 --> 00:10:44,180
abban az értelemben, hogy a nullvektorra esik.

164
00:10:45,680 --> 00:10:49,914
A lineáris egyenletrendszer szempontjából, ha v történetesen a nullvektor, 

165
00:10:49,914 --> 00:10:53,640
akkor a null-tér az egyenlet összes lehetséges megoldását megadja.

166
00:10:56,420 --> 00:10:58,565
Ez tehát egy nagyon magas szintű áttekintés arról, 

167
00:10:58,565 --> 00:11:01,720
hogyan gondolkodjunk lineáris egyenletrendszerekről geometriai szempontból.

168
00:11:02,300 --> 00:11:05,534
Minden rendszerhez tartozik valamilyen lineáris transzformáció, 

169
00:11:05,534 --> 00:11:09,678
és ha ennek a transzformációnak van inverze, akkor ezt az inverzét használhatja a 

170
00:11:09,678 --> 00:11:10,740
rendszer megoldására.

171
00:11:12,280 --> 00:11:15,925
Egyébként az oszloptér gondolata lehetővé teszi, hogy megértsük, 

172
00:11:15,925 --> 00:11:20,355
mikor létezik egyáltalán megoldás, a null-tér gondolata pedig segít megérteni, 

173
00:11:20,355 --> 00:11:23,440
hogyan nézhet ki az összes lehetséges megoldás halmaza.

174
00:11:24,980 --> 00:11:27,041
Ismétlem, sok minden van, amiről itt nem beszéltem, 

175
00:11:27,041 --> 00:11:29,380
leginkább arról, hogyan kell kiszámítani ezeket a dolgokat.

176
00:11:29,800 --> 00:11:32,058
Olyan példákra kellett korlátoznom a hatáskörömet, 

177
00:11:32,058 --> 00:11:34,760
ahol az egyenletek száma megegyezik az ismeretlenek számával.

178
00:11:34,880 --> 00:11:39,378
A cél azonban nem az, hogy mindent megtanítsunk, hanem az, hogy az inverz mátrixok, 

179
00:11:39,378 --> 00:11:42,483
az oszloptér és a null-tér erős intuícióval rendelkezzen, 

180
00:11:42,483 --> 00:11:46,500
és hogy ezek az intuíciók gyümölcsözőbbé tegyenek minden jövőbeli tanulást.

181
00:11:47,660 --> 00:11:49,813
A következő videóban, népszerű kérésre, egy rövid 

182
00:11:49,813 --> 00:11:51,880
lábjegyzet lesz a nem négyzet alakú mátrixokról.

183
00:11:51,880 --> 00:11:56,805
Ezután elmondom a véleményemet a ponttermékről, és valami nagyon klassz dolog történik, 

184
00:11:56,805 --> 00:11:59,660
ha a lineáris transzformációk fényében nézzük őket.

