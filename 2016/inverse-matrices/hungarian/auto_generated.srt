1
00:00:10,239 --> 00:00:14,764
Amint azt valószínűleg mostanra is láthatja, ennek a sorozatnak a nagy része a mátrix- 

2
00:00:14,764 --> 00:00:19,340
és vektorműveletek megértése a lineáris transzformációk vizuálisabb lencséjén keresztül.

3
00:00:19,980 --> 00:00:23,317
Ez a videó sem kivétel, és leírja az inverz mátrixok, 

4
00:00:23,317 --> 00:00:27,520
az oszloptér, a rang és a nulltér fogalmát ezen a lencsén keresztül.

5
00:00:27,520 --> 00:00:30,578
Figyelmeztetés azonban, hogy nem fogok ezeknek a dolgoknak a tényleges 

6
00:00:30,578 --> 00:00:34,240
kiszámításának módszereiről beszélni, és egyesek azt állítják, hogy ez nagyon fontos.

7
00:00:34,840 --> 00:00:39,450
Ezen a sorozaton kívül sok nagyon jó forrás található ezen módszerek megtanulásához, 

8
00:00:39,450 --> 00:00:42,000
kulcsszavak Gauss-elimináció és sorlépcsőforma.

9
00:00:42,540 --> 00:00:46,340
Azt hiszem, a legtöbb érték, amit hozzá kell tennem, az intuíció felén van.

10
00:00:46,900 --> 00:00:48,982
Ráadásul a gyakorlatban általában úgyis kapunk olyan szoftvert, 

11
00:00:48,982 --> 00:00:50,480
amely ezeket a dolgokat kiszámítja helyettünk.

12
00:00:51,500 --> 00:00:53,920
Először néhány szót a lineáris algebra hasznosságáról.

13
00:00:54,300 --> 00:00:58,205
Mostanra már van egy tippje arra vonatkozóan, hogyan használják a tér manipulációjának 

14
00:00:58,205 --> 00:01:01,661
leírására, ami hasznos lehet például számítógépes grafikában és robotikában, 

15
00:01:01,661 --> 00:01:05,297
de az egyik fő oka annak, hogy a lineáris algebra szélesebb körben alkalmazható, 

16
00:01:05,297 --> 00:01:07,856
és szinte bármilyen műszaki tudományághoz szükséges. az, 

17
00:01:07,856 --> 00:01:10,460
hogy lehetővé tesz bizonyos egyenletrendszerek megoldását.

18
00:01:11,380 --> 00:01:13,378
Amikor azt mondom, hogy egyenletrendszer, arra gondolok, 

19
00:01:13,378 --> 00:01:15,236
hogy van egy listája a változókról, olyan dolgokról, 

20
00:01:15,236 --> 00:01:17,760
amelyeket nem ismer, és egy listája a hozzájuk kapcsolódó egyenletekről.

21
00:01:18,340 --> 00:01:21,963
Sok helyzetben ezek az egyenletek nagyon bonyolultak lehetnek, 

22
00:01:21,963 --> 00:01:25,300
de ha szerencséd van, bizonyos speciális formát ölthetnek.

23
00:01:26,440 --> 00:01:30,067
Az egyes egyenleteken belül az egyetlen dolog, ami az egyes változókkal történik, 

24
00:01:30,067 --> 00:01:33,341
az az, hogy azokat valamilyen állandóval skálázzák, és az egyetlen dolog, 

25
00:01:33,341 --> 00:01:36,880
ami az egyes skálázott változókkal történik, az az, hogy hozzáadódnak egymáshoz.

26
00:01:37,540 --> 00:01:40,262
Tehát nincsenek kitevők vagy képzeletbeli függvények, 

27
00:01:40,262 --> 00:01:42,280
vagy két változó összeszorzása, ilyesmi.

28
00:01:43,420 --> 00:01:47,231
Az ilyen speciális egyenletrendszerek rendszerezésének tipikus módja az, 

29
00:01:47,231 --> 00:01:49,790
hogy az összes változót a bal oldalra helyezzük, 

30
00:01:49,790 --> 00:01:52,140
az esetleges állandókat pedig a jobb oldalra.

31
00:01:53,600 --> 00:01:56,777
Az is jó, ha függőlegesen sorba rendezzük a gyakori változókat, 

32
00:01:56,777 --> 00:01:59,259
és ehhez szükség lehet néhány nulla együtthatóra, 

33
00:01:59,259 --> 00:02:01,940
amikor a változó nem jelenik meg az egyik egyenletben.

34
00:02:04,540 --> 00:02:07,240
Ezt lineáris egyenletrendszernek nevezzük.

35
00:02:08,100 --> 00:02:11,180
Észreveheti, hogy ez nagyon úgy néz ki, mint a mátrix-vektor szorzás.

36
00:02:11,820 --> 00:02:16,579
Valójában az összes egyenletet összecsomagolhatja egyetlen vektoregyenletbe, 

37
00:02:16,579 --> 00:02:21,278
ahol az összes konstans együtthatót tartalmazó mátrix és az összes változót 

38
00:02:21,278 --> 00:02:26,780
tartalmazó vektor van, és a mátrix-vektor szorzatuk egy másik konstans vektorral egyenlő.

39
00:02:28,640 --> 00:02:33,279
Nevezzük el az A konstans mátrixot, jelöljük félkövér x-szel a változókat 

40
00:02:33,279 --> 00:02:37,480
tartalmazó vektort, és hívjuk meg a jobb oldali konstans vektort v.

41
00:02:38,860 --> 00:02:42,980
Ez több, mint egy jelölési trükk, amellyel egyenletrendszerünket egy sorba írhatjuk.

42
00:02:43,340 --> 00:02:46,780
A probléma egy elég klassz geometriai értelmezésére világít rá.

43
00:02:47,620 --> 00:02:51,034
Az A mátrix valamilyen lineáris transzformációnak felel meg, 

44
00:02:51,034 --> 00:02:55,065
így az Ax egyenlő v megoldása azt jelenti, hogy keresünk egy x vektort, 

45
00:02:55,065 --> 00:02:57,920
amely a transzformáció alkalmazása után v-re kerül.

46
00:02:59,940 --> 00:03:01,780
Gondolj egy pillanatra, mi történik itt.

47
00:03:02,060 --> 00:03:05,619
Megtarthatja a fejében ezt a nagyon bonyolult elképzelést a több változóról, 

48
00:03:05,619 --> 00:03:08,855
amelyek mindegyike keveredik egymással, ha csak a tér szaggatására és 

49
00:03:08,855 --> 00:03:12,600
morfondírozására gondol, és megpróbálja kitalálni, melyik vektor kerül a másikba.

50
00:03:13,160 --> 00:03:13,760
Menő, igaz?

51
00:03:14,600 --> 00:03:16,640
Az egyszerű kezdéshez tegyük fel, hogy van egy 

52
00:03:16,640 --> 00:03:18,680
rendszere két egyenletből és két ismeretlenből.

53
00:03:19,000 --> 00:03:23,960
Ez azt jelenti, hogy az A mátrix 2x2 mátrix, v és x pedig kétdimenziós vektorok.

54
00:03:25,600 --> 00:03:29,520
Az, hogy miként gondolkodunk ennek az egyenletnek a megoldásairól, attól függ, 

55
00:03:29,520 --> 00:03:33,689
hogy az A-val kapcsolatos transzformáció az egész teret egy alacsonyabb dimenzióba, 

56
00:03:33,689 --> 00:03:38,056
például egy vonalba vagy egy pontba zúzza-e, vagy hagy mindent a teljes két dimenzióra, 

57
00:03:38,056 --> 00:03:38,900
ahol elkezdődött.

58
00:03:40,320 --> 00:03:43,024
Az utolsó videó nyelvén felosztjuk azokra az esetekre, 

59
00:03:43,024 --> 00:03:45,778
amikor A-nak nulla determinánsa van, és arra az esetre, 

60
00:03:45,778 --> 00:03:48,040
amikor A-nak nullától eltérő determinánsa van.

61
00:03:51,300 --> 00:03:54,366
Kezdjük a legvalószínűbb esettel, ahol a determináns nem nulla, 

62
00:03:54,366 --> 00:03:57,720
ami azt jelenti, hogy a tér nem zsugorodik egy nulla területű régióba.

63
00:03:58,600 --> 00:04:02,409
Ebben az esetben mindig csak egy vektor lesz, amely v-re kerül, 

64
00:04:02,409 --> 00:04:06,160
és ezt a transzformáció fordított lejátszásával találhatja meg.

65
00:04:06,700 --> 00:04:10,226
Követve, hová megy v, amikor így visszatekerjük a szalagot, 

66
00:04:10,226 --> 00:04:13,460
az x vektort úgy találjuk, hogy A szor x egyenlő v-vel.

67
00:04:15,400 --> 00:04:19,512
Ha a transzformációt fordítva játssza le, az valójában egy különálló lineáris 

68
00:04:19,512 --> 00:04:23,203
transzformációnak felel meg, amelyet általában A inverzének neveznek, 

69
00:04:23,203 --> 00:04:24,680
és A-t a negatívnak jelölik.

70
00:04:25,360 --> 00:04:29,012
Például, ha A az óramutató járásával ellentétes irányú elforgatás 90 fokkal, 

71
00:04:29,012 --> 00:04:32,760
akkor A fordítottja az óramutató járásával megegyező 90 fokkal való elforgatás.

72
00:04:34,320 --> 00:04:37,930
Ha A jobb irányú nyírás lenne, amely a j-hat egy egységgel jobbra tolja, 

73
00:04:37,930 --> 00:04:40,501
akkor az A fordítottja egy bal irányú nyírás lenne, 

74
00:04:40,501 --> 00:04:42,480
amely a j-hat egy egységgel balra tolja.

75
00:04:44,100 --> 00:04:46,658
Általában az A inverz az az egyedi transzformáció, 

76
00:04:46,658 --> 00:04:49,567
amelynek tulajdonsága, hogy ha először alkalmazza az A-t, 

77
00:04:49,567 --> 00:04:53,480
majd követi az A inverz transzformációt, akkor visszakerül oda, ahol kiindult.

78
00:04:54,540 --> 00:04:56,909
Az egyik transzformációt a másik után alkalmazva 

79
00:04:56,909 --> 00:04:58,940
algebrai módon rögzítjük mátrixszorzással.

80
00:04:59,420 --> 00:05:03,294
Tehát ennek az A inverz transzformációnak az alapvető tulajdonsága, 

81
00:05:03,294 --> 00:05:07,340
hogy A inverz szor A-val egyenlő a semmittevésnek megfelelő mátrixszal.

82
00:05:08,200 --> 00:05:11,320
Azt az átalakulást, amely nem csinál semmit, identitástranszformációnak nevezzük.

83
00:05:11,780 --> 00:05:18,080
Mozdulatlanul hagyja az i-hat és a j-hat értéket, így oszlopai 1,0 és 0,1.

84
00:05:19,980 --> 00:05:23,874
Ha megtalálta ezt az inverzet, amit a gyakorlatban számítógéppel is megtenne, 

85
00:05:23,874 --> 00:05:27,720
megoldhatja az egyenletet úgy, hogy ezt az inverz mátrixot megszorozza v-vel.

86
00:05:29,960 --> 00:05:35,458
És még egyszer, ez geometriailag azt jelenti, hogy fordítva játszod az átalakítást, 

87
00:05:35,458 --> 00:05:36,440
és követed a v.

88
00:05:40,200 --> 00:05:44,109
Ez a nem nulla determináns eset, amely a mátrix véletlenszerű megválasztása esetén 

89
00:05:44,109 --> 00:05:46,841
messze a legvalószínűbb, megfelel annak az elképzelésnek, 

90
00:05:46,841 --> 00:05:50,610
hogy ha két ismeretlen és két egyenlet van, akkor szinte biztosan az a helyzet, 

91
00:05:50,610 --> 00:05:52,400
hogy egyetlen egyedi megoldás létezik.

92
00:05:53,680 --> 00:05:56,175
Ez az elképzelés magasabb dimenziókban is értelmes, 

93
00:05:56,175 --> 00:05:59,200
amikor az egyenletek száma megegyezik az ismeretlenek számával.

94
00:05:59,380 --> 00:06:04,890
Az egyenletrendszer ismét lefordítható a geometriai értelmezésre, 

95
00:06:04,890 --> 00:06:11,320
ahol van egy A transzformáció és egy v vektor, és azt az x vektort keressük, 

96
00:06:11,320 --> 00:06:12,740
amely v-re kerül.

97
00:06:15,740 --> 00:06:19,779
Mindaddig, amíg az A transzformáció nem tömöríti az egész teret egy alacsonyabb 

98
00:06:19,779 --> 00:06:22,809
dimenzióba, ami azt jelenti, hogy a determinánsa nem nulla, 

99
00:06:22,809 --> 00:06:26,394
addig lesz egy inverz A inverz transzformáció, azzal a tulajdonsággal, 

100
00:06:26,394 --> 00:06:30,080
hogy ha először megcsinálja A-t, akkor megfordítja az A-t. , ez ugyanaz, 

101
00:06:30,080 --> 00:06:31,040
mint a semmittevés.

102
00:06:33,540 --> 00:06:36,490
És az egyenlet megoldásához csak meg kell szorozni 

103
00:06:36,490 --> 00:06:39,440
a fordított transzformációs mátrixot a v vektorral.

104
00:06:43,500 --> 00:06:47,588
De ha a determináns nulla, és az egyenletrendszerhez kapcsolódó 

105
00:06:47,588 --> 00:06:52,060
transzformáció a teret kisebb dimenzióba tömöríti, akkor nincs inverz.

106
00:06:52,480 --> 00:06:55,460
Egy vonalat nem lehet kicsavarni, hogy síkká változzon.

107
00:06:55,980 --> 00:06:58,060
Legalábbis erre egy függvény nem képes.

108
00:06:58,360 --> 00:07:02,980
Ehhez minden egyes vektort egy vektorokkal teli sorrá kell átalakítani.

109
00:07:03,740 --> 00:07:06,740
De a funkciók csak egyetlen bemenetet tudnak egyetlen kimenetre átvinni.

110
00:07:08,400 --> 00:07:13,091
Hasonlóképpen, három egyenlet és három ismeretlen esetében nem lesz inverz, 

111
00:07:13,091 --> 00:07:16,177
ha a megfelelő transzformáció a 3D teret a síkra, 

112
00:07:16,177 --> 00:07:19,140
vagy akár egy egyenesre vagy pontra zúzza össze.

113
00:07:19,920 --> 00:07:22,306
Ezek mindegyike a nulla determinánsának felel meg, 

114
00:07:22,306 --> 00:07:25,160
mivel bármely régió nulla térfogatú valamivé van összenyomva.

115
00:07:26,700 --> 00:07:30,640
Még mindig lehetséges, hogy létezik megoldás akkor is, ha nincs inverz.

116
00:07:30,720 --> 00:07:35,155
Csak arról van szó, hogy amikor a transzformációd helyet zúdít mondjuk egy vonalra, 

117
00:07:35,155 --> 00:07:39,380
akkor elég szerencsésnek kell lenned, hogy a v vektor valahol azon a vonalon él.

118
00:07:43,300 --> 00:07:47,738
Észreveheti, hogy ezen nulla meghatározó esetek némelyike sokkal korlátozóbbnak tűnik, 

119
00:07:47,738 --> 00:07:48,300
mint mások.

120
00:07:48,840 --> 00:07:54,128
Ha például egy 3x3-as mátrixot adunk meg, sokkal nehezebbnek tűnik egy megoldás létezése, 

121
00:07:54,128 --> 00:07:58,242
amikor egy vonalra húzza a teret, mint amikor a dolgokat síkra vágja, 

122
00:07:58,242 --> 00:08:00,240
pedig mindkettő nulla meghatározó.

123
00:08:02,600 --> 00:08:04,810
Van néhány olyan nyelvezetünk, amely egy kicsit konkrétabb, 

124
00:08:04,810 --> 00:08:06,100
mint a nulla determináns kimondása.

125
00:08:06,520 --> 00:08:10,343
Ha egy transzformáció kimenete egy vonal, vagyis egydimenziós, 

126
00:08:10,343 --> 00:08:13,500
akkor azt mondjuk, hogy a transzformáció rangja egy.

127
00:08:15,140 --> 00:08:17,860
Ha az összes vektor egy kétdimenziós síkon landol, 

128
00:08:17,860 --> 00:08:20,420
azt mondjuk, hogy a transzformáció rangja kettő.

129
00:08:22,920 --> 00:08:27,480
Tehát a rang szó a transzformáció kimenetében lévő dimenziók számát jelenti.

130
00:08:28,400 --> 00:08:32,720
Például 2x2-es mátrixok esetén a 2. rang a lehető legjobb.

131
00:08:33,080 --> 00:08:37,534
Ez azt jelenti, hogy a bázisvektorok továbbra is átfogják a tér két dimenzióját, 

132
00:08:37,534 --> 00:08:39,020
és a determináns nem nulla.

133
00:08:39,419 --> 00:08:42,837
De a 3x3-as mátrixoknál a 2-es rang azt jelenti, hogy összeestünk, 

134
00:08:42,837 --> 00:08:46,460
de nem annyira, mint amennyire 1-es helyzet esetén összeomlottak volna.

135
00:08:47,240 --> 00:08:50,388
Ha egy 3D-s transzformációnak nullától eltérő determinánsa van, 

136
00:08:50,388 --> 00:08:53,340
és a kimenete kitölti a teljes 3D-s teret, akkor a rangja 3.

137
00:08:54,520 --> 00:08:59,116
A mátrix összes lehetséges kimenetének ezt a halmazát, legyen az egyenes, 

138
00:08:59,116 --> 00:09:02,720
sík, 3D-s tér vagy bármi, a mátrix oszlopterének nevezzük.

139
00:09:04,140 --> 00:09:06,280
Valószínűleg kitalálod, honnan származik ez a név.

140
00:09:06,560 --> 00:09:10,110
A mátrix oszlopai megmondják, hol érnek a bázisvektorok, 

141
00:09:10,110 --> 00:09:14,532
és ezeknek a transzformált bázisvektoroknak a spanja megadja az összes 

142
00:09:14,532 --> 00:09:15,840
lehetséges kimenetet.

143
00:09:16,360 --> 00:09:21,140
Más szóval, az oszloptér a mátrixod oszlopainak fesztávja.

144
00:09:23,300 --> 00:09:28,940
Tehát a rang pontosabb meghatározása az lenne, ha ez az oszloptérben lévő dimenziók száma.

145
00:09:29,940 --> 00:09:32,239
Ha ez a rang olyan magas, amennyire csak lehet, 

146
00:09:32,239 --> 00:09:36,120
vagyis megegyezik az oszlopok számával, akkor a mátrixot teljes rangnak nevezzük.

147
00:09:38,540 --> 00:09:42,054
Figyeljük meg, a nulla vektor mindig benne lesz az oszloptérben, 

148
00:09:42,054 --> 00:09:45,840
mivel a lineáris transzformációknak az origót a helyén kell tartaniuk.

149
00:09:46,900 --> 00:09:49,711
Teljes rangú transzformáció esetén az egyetlen vektor, 

150
00:09:49,711 --> 00:09:51,960
amely az origóba kerül, maga a nulla vektor.

151
00:09:52,460 --> 00:09:56,348
De a nem teljes rangú mátrixok esetében, amelyek kisebb dimenzióba süllyednek, 

152
00:09:56,348 --> 00:09:58,760
egy csomó vektor lehet, amelyek nullára kerülnek.

153
00:10:01,640 --> 00:10:05,286
Ha például egy 2D-s transzformáció teret szaggat egy vonalra, 

154
00:10:05,286 --> 00:10:10,580
akkor van egy külön sor egy másik irányban, tele vektorokkal, amelyek az origóba kerülnek.

155
00:10:11,780 --> 00:10:14,786
Ha egy 3D-s transzformáció egy síkra zúzza a teret, 

156
00:10:14,786 --> 00:10:17,620
akkor a vektorok teljes sora is az origóba kerül.

157
00:10:20,520 --> 00:10:23,861
Ha egy 3D-s transzformáció az egész teret egy egyenesre préseli, 

158
00:10:23,861 --> 00:10:27,460
akkor egy egész sík van tele vektorokkal, amelyek az origóba kerülnek.

159
00:10:32,800 --> 00:10:38,780
Ezt a vektorhalmazt, amely az origóba kerül, nulltérnek vagy a mátrix kernelének nevezzük.

160
00:10:39,360 --> 00:10:41,625
Ez az összes vektor tere, amely nullává válik, 

161
00:10:41,625 --> 00:10:44,180
abban az értelemben, hogy a nulla vektoron landolnak.

162
00:10:45,680 --> 00:10:50,171
A lineáris egyenletrendszer szempontjából, amikor v véletlenül a nulla vektor, 

163
00:10:50,171 --> 00:10:53,640
a nulla tér megadja az egyenlet összes lehetséges megoldását.

164
00:10:56,420 --> 00:10:58,635
Tehát ez egy nagyon magas szintű áttekintés arról, 

165
00:10:58,635 --> 00:11:01,720
hogyan kell geometriailag gondolkodni a lineáris egyenletrendszerekről.

166
00:11:02,300 --> 00:11:05,496
Minden rendszerhez tartozik valamilyen lineáris transzformáció, 

167
00:11:05,496 --> 00:11:09,691
és ha ennek a transzformációnak van inverze, akkor ezt az inverzetet használhatja a 

168
00:11:09,691 --> 00:11:10,740
rendszer megoldására.

169
00:11:12,280 --> 00:11:15,871
Ellenkező esetben az oszloptér fogalma lehetővé teszi számunkra, 

170
00:11:15,871 --> 00:11:20,401
hogy megértsük, mikor létezik megoldás, a nulla tér ötlete pedig segít megérteni, 

171
00:11:20,401 --> 00:11:23,440
hogyan nézhet ki az összes lehetséges megoldás halmaza.

172
00:11:24,979 --> 00:11:27,225
Ismét sok mindenre nem tértem ki itt, különösen, 

173
00:11:27,225 --> 00:11:29,380
hogy hogyan kell kiszámítani ezeket a dolgokat.

174
00:11:29,800 --> 00:11:32,105
Olyan példákra is korlátoznom kellett a hatókörömet, 

175
00:11:32,105 --> 00:11:34,760
ahol az egyenletek száma megegyezik az ismeretlenek számával.

176
00:11:34,880 --> 00:11:37,772
De a cél itt nem az, hogy mindent megtanítson, hanem az, 

177
00:11:37,772 --> 00:11:40,563
hogy erős intuícióval rendelkezzen az inverz mátrixok, 

178
00:11:40,563 --> 00:11:44,368
az oszloptér és a nulla tér tekintetében, és hogy ezek az intuíciók minden 

179
00:11:44,368 --> 00:11:46,500
jövőbeni tanulást gyümölcsözőbbé tegyenek.

180
00:11:47,660 --> 00:11:51,880
A következő videó, közkívánatra, egy rövid lábjegyzet lesz a nem négyzetes mátrixokról.

181
00:11:51,880 --> 00:11:54,459
Aztán ezek után elmondom a véleményemet a ponttermékekről, 

182
00:11:54,459 --> 00:11:56,821
és valami nagyon klassz dologról, ami akkor történik, 

183
00:11:56,821 --> 00:11:58,920
ha lineáris transzformációk fényében nézed őket.

184
00:11:59,480 --> 00:11:59,660
Majd találkozunk!

