1
00:00:11,143 --> 00:00:15,566
Amint azt valószínűleg mostanra is láthatja, ennek a sorozatnak a nagy része a mátrix-

2
00:00:15,566 --> 00:00:20,040
és vektorműveletek megértése a lineáris transzformációk vizuálisabb lencséjén keresztül.

3
00:00:20,040 --> 00:00:23,796
Ez a videó sem kivétel, és leírja az inverz mátrixok, az

4
00:00:23,796 --> 00:00:28,080
oszloptér, a rang és a nulltér fogalmát ezen a lencsén keresztül.

5
00:00:28,080 --> 00:00:31,193
Figyelmeztetés azonban, hogy nem fogok ezeknek a dolgoknak a tényleges

6
00:00:31,193 --> 00:00:34,920
kiszámításának módszereiről beszélni, és egyesek azt állítják, hogy ez nagyon fontos.

7
00:00:34,920 --> 00:00:38,850
Ezen a sorozaton kívül sok nagyon jó forrás található ezen módszerek

8
00:00:38,850 --> 00:00:42,440
megtanulásához, kulcsszavak Gauss-elimináció és sorlépcsőforma.

9
00:00:42,440 --> 00:00:46,640
Azt hiszem, a legtöbb érték, amit hozzá kell tennem, az intuíció felén van.

10
00:00:46,640 --> 00:00:48,625
Ráadásul a gyakorlatban általában úgyis kapunk olyan

11
00:00:48,625 --> 00:00:50,760
szoftvert, amely ezeket a dolgokat kiszámítja helyettünk.

12
00:00:50,760 --> 00:00:54,460
Először néhány szót a lineáris algebra hasznosságáról.

13
00:00:54,460 --> 00:00:58,578
Mostanra már van egy tippje arra vonatkozóan, hogyan használják a tér manipulációjának

14
00:00:58,578 --> 00:01:02,790
leírására, ami hasznos lehet például számítógépes grafikában és robotikában, de az egyik

15
00:01:02,790 --> 00:01:07,003
fő oka annak, hogy a lineáris algebra szélesebb körben alkalmazható, és szinte bármilyen

16
00:01:07,003 --> 00:01:10,979
műszaki tudományághoz szükséges. az, hogy lehetővé tesz bizonyos egyenletrendszerek

17
00:01:10,979 --> 00:01:11,500
megoldását.

18
00:01:11,500 --> 00:01:13,884
Amikor azt mondom, hogy egyenletrendszer, arra gondolok, hogy

19
00:01:13,884 --> 00:01:16,115
van egy listája a változókról, olyan dolgokról, amelyeket

20
00:01:16,115 --> 00:01:18,500
nem ismer, és egy listája a hozzájuk kapcsolódó egyenletekről.

21
00:01:18,500 --> 00:01:22,675
Sok helyzetben ezek az egyenletek nagyon bonyolultak lehetnek,

22
00:01:22,675 --> 00:01:26,520
de ha szerencséd van, bizonyos speciális formát ölthetnek.

23
00:01:26,520 --> 00:01:30,404
Az egyes egyenleteken belül az egyetlen dolog, ami az egyes változókkal történik,

24
00:01:30,404 --> 00:01:34,099
az az, hogy azokat valamilyen állandóval skálázzák, és az egyetlen dolog, ami

25
00:01:34,099 --> 00:01:37,700
az egyes skálázott változókkal történik, az az, hogy hozzáadódnak egymáshoz.

26
00:01:37,700 --> 00:01:41,066
Tehát nincsenek kitevők vagy képzeletbeli függvények,

27
00:01:41,066 --> 00:01:43,560
vagy két változó összeszorzása, ilyesmi.

28
00:01:43,560 --> 00:01:48,633
Az ilyen speciális egyenletrendszerek rendszerezésének tipikus módja az, hogy az

29
00:01:48,633 --> 00:01:54,020
összes változót a bal oldalra helyezzük, az esetleges állandókat pedig a jobb oldalra.

30
00:01:54,020 --> 00:01:59,285
Az is jó, ha függőlegesen sorba rendezzük a gyakori változókat, és ehhez szükség

31
00:01:59,285 --> 00:02:04,940
lehet néhány nulla együtthatóra, amikor a változó nem jelenik meg az egyik egyenletben.

32
00:02:04,940 --> 00:02:08,160
Ezt lineáris egyenletrendszernek nevezzük.

33
00:02:08,160 --> 00:02:11,940
Észreveheti, hogy ez nagyon úgy néz ki, mint a mátrix-vektor szorzás.

34
00:02:11,940 --> 00:02:17,727
Valójában az összes egyenletet összecsomagolhatja egyetlen vektoregyenletbe, ahol

35
00:02:17,727 --> 00:02:23,514
az összes konstans együtthatót tartalmazó mátrix és az összes változót tartalmazó

36
00:02:23,514 --> 00:02:29,020
vektor van, és a mátrix-vektor szorzatuk egy másik konstans vektorral egyenlő.

37
00:02:29,020 --> 00:02:34,268
Nevezzük el az A konstans mátrixot, jelöljük félkövér x-szel a változókat

38
00:02:34,268 --> 00:02:39,020
tartalmazó vektort, és hívjuk meg a jobb oldali konstans vektort v.

39
00:02:39,020 --> 00:02:43,540
Ez több, mint egy jelölési trükk, amellyel egyenletrendszerünket egy sorba írhatjuk.

40
00:02:43,540 --> 00:02:47,620
A probléma egy elég klassz geometriai értelmezésére világít rá.

41
00:02:47,620 --> 00:02:51,863
Az A mátrix valamilyen lineáris transzformációnak felel meg,

42
00:02:51,863 --> 00:02:56,106
így az Ax egyenlő v megoldása azt jelenti, hogy keresünk egy

43
00:02:56,106 --> 00:03:00,420
x vektort, amely a transzformáció alkalmazása után v-re kerül.

44
00:03:00,420 --> 00:03:02,180
Gondolj egy pillanatra, mi történik itt.

45
00:03:02,180 --> 00:03:05,813
Megtarthatja a fejében ezt a nagyon bonyolult elképzelést a több változóról,

46
00:03:05,813 --> 00:03:09,117
amelyek mindegyike keveredik egymással, ha csak a tér szaggatására és

47
00:03:09,117 --> 00:03:12,940
morfondírozására gondol, és megpróbálja kitalálni, melyik vektor kerül a másikba.

48
00:03:12,940 --> 00:03:14,860
Menő, igaz?

49
00:03:14,860 --> 00:03:16,960
Az egyszerű kezdéshez tegyük fel, hogy van egy

50
00:03:16,960 --> 00:03:19,060
rendszere két egyenletből és két ismeretlenből.

51
00:03:19,060 --> 00:03:24,780
Ez azt jelenti, hogy az A mátrix 2x2 mátrix, v és x pedig kétdimenziós vektorok.

52
00:03:24,780 --> 00:03:29,974
Az, hogy miként gondolkodunk ennek az egyenletnek a megoldásairól, attól függ, hogy az

53
00:03:29,974 --> 00:03:35,227
A-val kapcsolatos transzformáció az egész teret egy alacsonyabb dimenzióba, például egy

54
00:03:35,227 --> 00:03:40,063
vonalba vagy egy pontba zúzza-e, vagy hagy mindent a teljes két dimenzióra, ahol

55
00:03:40,063 --> 00:03:40,780
elkezdődött.

56
00:03:40,780 --> 00:03:45,945
Az utolsó videó nyelvén felosztjuk azokra az esetekre, amikor A-nak nulla

57
00:03:45,945 --> 00:03:51,740
determinánsa van, és arra az esetre, amikor A-nak nullától eltérő determinánsa van.

58
00:03:51,740 --> 00:03:55,251
Kezdjük a legvalószínűbb esettel, ahol a determináns nem nulla, ami

59
00:03:55,251 --> 00:03:58,660
azt jelenti, hogy a tér nem zsugorodik egy nulla területű régióba.

60
00:03:58,660 --> 00:04:02,832
Ebben az esetben mindig csak egy vektor lesz, amely v-re kerül,

61
00:04:02,832 --> 00:04:06,940
és ezt a transzformáció fordított lejátszásával találhatja meg.

62
00:04:06,940 --> 00:04:11,614
Követve, hová megy v, amikor így visszatekerjük a szalagot,

63
00:04:11,614 --> 00:04:15,900
az x vektort úgy találjuk, hogy A szor x egyenlő v-vel.

64
00:04:15,900 --> 00:04:20,119
Ha a transzformációt fordítva játssza le, az valójában egy különálló lineáris

65
00:04:20,119 --> 00:04:24,987
transzformációnak felel meg, amelyet általában A inverzének neveznek, és A-t a negatívnak

66
00:04:24,987 --> 00:04:25,420
jelölik.

67
00:04:25,420 --> 00:04:30,040
Például, ha A az óramutató járásával ellentétes irányú elforgatás 90 fokkal,

68
00:04:30,040 --> 00:04:34,780
akkor A fordítottja az óramutató járásával megegyező 90 fokkal való elforgatás.

69
00:04:34,780 --> 00:04:39,531
Ha A jobb irányú nyírás lenne, amely a j-hat egy egységgel jobbra tolja, akkor az

70
00:04:39,531 --> 00:04:44,340
A fordítottja egy bal irányú nyírás lenne, amely a j-hat egy egységgel balra tolja.

71
00:04:44,340 --> 00:04:47,651
Általában az A inverz az az egyedi transzformáció, amelynek

72
00:04:47,651 --> 00:04:51,017
tulajdonsága, hogy ha először alkalmazza az A-t, majd követi

73
00:04:51,017 --> 00:04:54,660
az A inverz transzformációt, akkor visszakerül oda, ahol kiindult.

74
00:04:54,660 --> 00:04:57,341
Az egyik transzformációt a másik után alkalmazva

75
00:04:57,341 --> 00:04:59,640
algebrai módon rögzítjük mátrixszorzással.

76
00:04:59,640 --> 00:05:03,817
Tehát ennek az A inverz transzformációnak az alapvető tulajdonsága,

77
00:05:03,817 --> 00:05:08,180
hogy A inverz szor A-val egyenlő a semmittevésnek megfelelő mátrixszal.

78
00:05:08,180 --> 00:05:11,840
Azt az átalakulást, amely nem csinál semmit, identitástranszformációnak nevezzük.

79
00:05:11,840 --> 00:05:20,160
Mozdulatlanul hagyja az i-hat és a j-hat értéket, így oszlopai 1,0 és 0,1.

80
00:05:20,160 --> 00:05:25,172
Ha megtalálta ezt az inverzet, amit a gyakorlatban számítógéppel is megtenne,

81
00:05:25,172 --> 00:05:30,120
megoldhatja az egyenletet úgy, hogy ezt az inverz mátrixot megszorozza v-vel.

82
00:05:30,120 --> 00:05:35,498
És még egyszer, ez geometriailag azt jelenti, hogy

83
00:05:35,498 --> 00:05:40,560
fordítva játszod az átalakítást, és követed a v.

84
00:05:40,560 --> 00:05:44,918
Ez a nem nulla determináns eset, amely a mátrix véletlenszerű megválasztása esetén

85
00:05:44,918 --> 00:05:49,329
messze a legvalószínűbb, megfelel annak az elképzelésnek, hogy ha két ismeretlen és

86
00:05:49,329 --> 00:05:53,739
két egyenlet van, akkor szinte biztosan az a helyzet, hogy egyetlen egyedi megoldás

87
00:05:53,739 --> 00:05:54,160
létezik.

88
00:05:54,160 --> 00:05:56,622
Ez az elképzelés magasabb dimenziókban is értelmes, amikor

89
00:05:56,622 --> 00:05:58,960
az egyenletek száma megegyezik az ismeretlenek számával.

90
00:05:58,960 --> 00:06:07,462
Az egyenletrendszer ismét lefordítható a geometriai értelmezésre, ahol van egy

91
00:06:07,462 --> 00:06:16,180
A transzformáció és egy v vektor, és azt az x vektort keressük, amely v-re kerül.

92
00:06:16,180 --> 00:06:20,821
Mindaddig, amíg az A transzformáció nem tömöríti az egész teret egy alacsonyabb

93
00:06:20,821 --> 00:06:25,173
dimenzióba, ami azt jelenti, hogy a determinánsa nem nulla, addig lesz egy

94
00:06:25,173 --> 00:06:29,350
inverz A inverz transzformáció, azzal a tulajdonsággal, hogy ha először

95
00:06:29,350 --> 00:06:33,760
megcsinálja A-t, akkor megfordítja az A-t. , ez ugyanaz, mint a semmittevés.

96
00:06:33,760 --> 00:06:38,700
És az egyenlet megoldásához csak meg kell szorozni

97
00:06:38,700 --> 00:06:43,640
a fordított transzformációs mátrixot a v vektorral.

98
00:06:43,640 --> 00:06:47,881
De ha a determináns nulla, és az egyenletrendszerhez kapcsolódó

99
00:06:47,881 --> 00:06:52,520
transzformáció a teret kisebb dimenzióba tömöríti, akkor nincs inverz.

100
00:06:52,520 --> 00:06:56,040
Egy vonalat nem lehet kicsavarni, hogy síkká változzon.

101
00:06:56,040 --> 00:06:58,500
Legalábbis erre egy függvény nem képes.

102
00:06:58,500 --> 00:07:03,880
Ehhez minden egyes vektort egy vektorokkal teli sorrá kell átalakítani.

103
00:07:03,880 --> 00:07:07,720
De a funkciók csak egyetlen bemenetet tudnak egyetlen kimenetre átvinni.

104
00:07:07,720 --> 00:07:13,380
Hasonlóképpen, három egyenlet és három ismeretlen esetében nem lesz inverz, ha a

105
00:07:13,380 --> 00:07:19,460
megfelelő transzformáció a 3D teret a síkra, vagy akár egy egyenesre vagy pontra zúzza

106
00:07:19,460 --> 00:07:19,880
össze.

107
00:07:19,880 --> 00:07:23,574
Ezek mindegyike a nulla determinánsának felel meg, mivel

108
00:07:23,574 --> 00:07:27,140
bármely régió nulla térfogatú valamivé van összenyomva.

109
00:07:27,140 --> 00:07:31,160
Még mindig lehetséges, hogy létezik megoldás akkor is, ha nincs inverz.

110
00:07:31,160 --> 00:07:37,500
Csak arról van szó, hogy amikor a transzformációd helyet zúdít mondjuk egy vonalra,

111
00:07:37,500 --> 00:07:43,540
akkor elég szerencsésnek kell lenned, hogy a v vektor valahol azon a vonalon él.

112
00:07:43,540 --> 00:07:46,224
Észreveheti, hogy ezen nulla meghatározó esetek

113
00:07:46,224 --> 00:07:49,020
némelyike sokkal korlátozóbbnak tűnik, mint mások.

114
00:07:49,020 --> 00:07:53,346
Ha például egy 3x3-as mátrixot adunk meg, sokkal nehezebbnek

115
00:07:53,346 --> 00:07:57,815
tűnik egy megoldás létezése, amikor egy vonalra húzza a teret,

116
00:07:57,815 --> 00:08:02,780
mint amikor a dolgokat síkra vágja, pedig mindkettő nulla meghatározó.

117
00:08:02,780 --> 00:08:04,740
Van néhány olyan nyelvezetünk, amely egy kicsit

118
00:08:04,740 --> 00:08:06,660
konkrétabb, mint a nulla determináns kimondása.

119
00:08:06,660 --> 00:08:11,415
Ha egy transzformáció kimenete egy vonal, vagyis egydimenziós,

120
00:08:11,415 --> 00:08:15,340
akkor azt mondjuk, hogy a transzformáció rangja egy.

121
00:08:15,340 --> 00:08:19,337
Ha az összes vektor egy kétdimenziós síkon landol,

122
00:08:19,337 --> 00:08:23,100
azt mondjuk, hogy a transzformáció rangja kettő.

123
00:08:23,100 --> 00:08:28,500
Tehát a rang szó a transzformáció kimenetében lévő dimenziók számát jelenti.

124
00:08:28,500 --> 00:08:33,200
Például 2x2-es mátrixok esetén a 2. rang a lehető legjobb.

125
00:08:33,200 --> 00:08:36,680
Ez azt jelenti, hogy a bázisvektorok továbbra is átfogják

126
00:08:36,680 --> 00:08:39,680
a tér két dimenzióját, és a determináns nem nulla.

127
00:08:39,680 --> 00:08:43,555
De a 3x3-as mátrixoknál a 2-es rang azt jelenti, hogy összeestünk, de

128
00:08:43,555 --> 00:08:47,320
nem annyira, mint amennyire 1-es helyzet esetén összeomlottak volna.

129
00:08:47,320 --> 00:08:51,129
Ha egy 3D-s transzformációnak nullától eltérő determinánsa van,

130
00:08:51,129 --> 00:08:54,700
és a kimenete kitölti a teljes 3D-s teret, akkor a rangja 3.

131
00:08:54,700 --> 00:08:59,515
A mátrix összes lehetséges kimenetének ezt a halmazát, legyen az

132
00:08:59,515 --> 00:09:04,480
egyenes, sík, 3D-s tér vagy bármi, a mátrix oszlopterének nevezzük.

133
00:09:04,480 --> 00:09:06,780
Valószínűleg kitalálod, honnan származik ez a név.

134
00:09:06,780 --> 00:09:11,402
A mátrix oszlopai megmondják, hol érnek a bázisvektorok, és ezeknek a

135
00:09:11,402 --> 00:09:16,620
transzformált bázisvektoroknak a spanja megadja az összes lehetséges kimenetet.

136
00:09:16,620 --> 00:09:23,800
Más szóval, az oszloptér a mátrixod oszlopainak fesztávja.

137
00:09:23,800 --> 00:09:30,240
Tehát a rang pontosabb meghatározása az lenne, ha ez az oszloptérben lévő dimenziók száma.

138
00:09:30,240 --> 00:09:34,026
Ha ez a rang olyan magas, amennyire csak lehet, vagyis megegyezik

139
00:09:34,026 --> 00:09:37,640
az oszlopok számával, akkor a mátrixot teljes rangnak nevezzük.

140
00:09:37,640 --> 00:09:42,175
Figyeljük meg, a nulla vektor mindig benne lesz az oszloptérben,

141
00:09:42,175 --> 00:09:47,060
mivel a lineáris transzformációknak az origót a helyén kell tartaniuk.

142
00:09:47,060 --> 00:09:49,728
Teljes rangú transzformáció esetén az egyetlen

143
00:09:49,728 --> 00:09:52,680
vektor, amely az origóba kerül, maga a nulla vektor.

144
00:09:52,680 --> 00:09:57,642
De a nem teljes rangú mátrixok esetében, amelyek kisebb dimenzióba

145
00:09:57,642 --> 00:10:02,160
süllyednek, egy csomó vektor lehet, amelyek nullára kerülnek.

146
00:10:02,160 --> 00:10:07,040
Ha például egy 2D-s transzformáció teret szaggat egy vonalra, akkor van egy

147
00:10:07,040 --> 00:10:11,920
külön sor egy másik irányban, tele vektorokkal, amelyek az origóba kerülnek.

148
00:10:11,920 --> 00:10:16,491
Ha egy 3D-s transzformáció egy síkra zúzza a teret,

149
00:10:16,491 --> 00:10:20,800
akkor a vektorok teljes sora is az origóba kerül.

150
00:10:20,800 --> 00:10:26,857
Ha egy 3D-s transzformáció az egész teret egy egyenesre préseli,

151
00:10:26,857 --> 00:10:33,380
akkor egy egész sík van tele vektorokkal, amelyek az origóba kerülnek.

152
00:10:33,380 --> 00:10:39,360
Ezt a vektorhalmazt, amely az origóba kerül, nulltérnek vagy a mátrix kernelének nevezzük.

153
00:10:39,360 --> 00:10:42,358
Ez az összes vektor tere, amely nullává válik,

154
00:10:42,358 --> 00:10:45,740
abban az értelemben, hogy a nulla vektoron landolnak.

155
00:10:45,740 --> 00:10:51,409
A lineáris egyenletrendszer szempontjából, amikor v véletlenül a nulla

156
00:10:51,409 --> 00:10:56,920
vektor, a nulla tér megadja az egyenlet összes lehetséges megoldását.

157
00:10:56,920 --> 00:10:59,760
Tehát ez egy nagyon magas szintű áttekintés arról, hogyan kell

158
00:10:59,760 --> 00:11:02,420
geometriailag gondolkodni a lineáris egyenletrendszerekről.

159
00:11:02,420 --> 00:11:06,712
Minden rendszerhez tartozik valamilyen lineáris transzformáció, és ha ennek a

160
00:11:06,712 --> 00:11:11,059
transzformációnak van inverze, akkor ezt az inverzetet használhatja a rendszer

161
00:11:11,059 --> 00:11:11,720
megoldására.

162
00:11:11,720 --> 00:11:15,735
Ellenkező esetben az oszloptér fogalma lehetővé teszi számunkra,

163
00:11:15,735 --> 00:11:19,751
hogy megértsük, mikor létezik megoldás, a nulla tér ötlete pedig

164
00:11:19,751 --> 00:11:24,200
segít megérteni, hogyan nézhet ki az összes lehetséges megoldás halmaza.

165
00:11:24,200 --> 00:11:27,058
Ismét sok mindenre nem tértem ki itt, különösen,

166
00:11:27,058 --> 00:11:29,800
hogy hogyan kell kiszámítani ezeket a dolgokat.

167
00:11:29,800 --> 00:11:32,547
Olyan példákra is korlátoznom kellett a hatókörömet, ahol

168
00:11:32,547 --> 00:11:35,200
az egyenletek száma megegyezik az ismeretlenek számával.

169
00:11:35,200 --> 00:11:39,546
De a cél itt nem az, hogy mindent megtanítson, hanem az, hogy erős intuícióval

170
00:11:39,546 --> 00:11:43,673
rendelkezzen az inverz mátrixok, az oszloptér és a nulla tér tekintetében,

171
00:11:43,673 --> 00:11:47,800
és hogy ezek az intuíciók minden jövőbeni tanulást gyümölcsözőbbé tegyenek.

172
00:11:47,800 --> 00:11:52,480
A következő videó, közkívánatra, egy rövid lábjegyzet lesz a nem négyzetes mátrixokról.

173
00:11:52,480 --> 00:11:56,068
Aztán ezek után elmondom a véleményemet a ponttermékekről, és valami nagyon klassz

174
00:11:56,068 --> 00:11:59,440
dologról, ami akkor történik, ha lineáris transzformációk fényében nézed őket.

175
00:11:59,440 --> 00:11:59,440
Majd találkozunk!

