[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Como você provavelmente já pode perceber, a maior parte desta série trata da compreensão das operações matriciais e vetoriais através das lentes mais visuais das transformações lineares.",
  "model": "google_nmt",
  "from_community_srt": "Fazer a pergunta certa é mais difícil que respondê-la. Como você já deve ter percebido, o essencial desta série está no entendimento das operações sobre matrizes e vetores através de uma representação visual das transformações lineares.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Este vídeo não é exceção, descrevendo os conceitos de matrizes inversas, espaço de coluna, classificação e espaço nulo através dessas lentes.",
  "model": "google_nmt",
  "from_community_srt": "Este vídeo não é uma exceção, descrevendo os conceitos de matrizes inversas, espaço coluna, posto (rank) e espaço nulo através de representações visuais.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Porém, um aviso: não vou falar sobre os métodos para realmente calcular essas coisas, e alguns argumentariam que isso é muito importante.",
  "model": "google_nmt",
  "from_community_srt": "É importante esclarecer que não vou falar sobre como realmente calcular estas coisas e algumas pessoas argumentariam que isso é muito importante.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Existem muitos recursos muito bons para aprender esses métodos fora desta série, palavras-chave eliminação gaussiana e forma escalonada de linha.",
  "model": "google_nmt",
  "from_community_srt": "Há recursos muito bons para aprender esses cálculos fora desta série. Procure por: \"eliminação de Gauss\" e \"matriz escalonada\".",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Acho que a maior parte do valor que realmente tenho a agregar aqui está na metade da intuição.",
  "model": "google_nmt",
  "from_community_srt": "Eu acho que minha maior contribuição aqui é na parte da intuição Além disso,",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Além disso, na prática, geralmente obtemos software para calcular essas coisas para nós de qualquer maneira.",
  "model": "google_nmt",
  "from_community_srt": "na prática, nós usamos softwares para calcular essas coisas.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "Primeiro, algumas palavras sobre a utilidade da álgebra linear.",
  "model": "google_nmt",
  "from_community_srt": "Primeiro, algumas palavras sobre a utilidade da álgebra linear.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "Até agora, você já tem uma dica de como ele é usado para descrever a manipulação do espaço, o que é útil para coisas como computação gráfica e robótica.",
  "model": "google_nmt",
  "from_community_srt": "Até agora, você já tem uma ideia de como ela é utilizada para descrever a manipulação do espaço, que é útil para computação gráfica e robótica,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "Mas uma das principais razões pelas quais a álgebra linear é mais amplamente aplicável e necessária para praticamente qualquer disciplina técnica é que ela nos permite resolver certos sistemas de equações.",
  "model": "google_nmt",
  "from_community_srt": "por exemplo, mas uma das principais razões que álgebra linear é amplamente aplicável, e necessária em praticamente qualquer disciplina técnica, é que ela nos permite resolver certos sistemas de equações.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Quando digo sistema de equações, quero dizer que você tem uma lista de variáveis, coisas que você não conhece, e uma lista de equações que as relacionam.",
  "model": "google_nmt",
  "from_community_srt": "Quando eu digo \"sistema de equações\", quero dizer que você tem uma lista de variáveis, coisas que você quer conhecer, e uma lista de equações relacionadas a elas.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "Em muitas situações, essas equações podem ficar muito complicadas.",
  "model": "google_nmt",
  "from_community_srt": "Em muitas situações, essas equações podem ser muito complicadas, mas,",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "Mas, se você tiver sorte, eles poderão assumir uma certa forma especial.",
  "model": "google_nmt",
  "from_community_srt": "se você tiver sorte, elas podem ter uma forma especial.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "Dentro de cada equação, a única coisa que acontece com cada variável é que ela é escalonada por alguma constante, e a única coisa que acontece com cada uma dessas variáveis escalonadas é que elas são adicionadas umas às outras.",
  "model": "google_nmt",
  "from_community_srt": "Dentro de cada equação, a única coisa que está acontecendo com cada variável é que elas são dimensionadas por constantes (escalares) e a única coisa acontecendo com as variáveis dimensionadas é que elas são adicionadas entre si.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Portanto, nada de expoentes, funções sofisticadas ou multiplicação de duas variáveis, coisas assim.",
  "model": "google_nmt",
  "from_community_srt": "Portanto, não há expoentes nem funções bacanas, ou multiplicação de duas variáveis;",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "A maneira típica de organizar esse tipo de sistema especial de equações é colocar todas as variáveis à esquerda e colocar quaisquer constantes remanescentes à direita.",
  "model": "google_nmt",
  "from_community_srt": "coisas desse tipo. A forma como geralmente organizamos esse tipo especial de sistema de equações é colocar todas as variáveis ​​do lado esquerdo, e colocar quaisquer constantes restantes à direita.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "Também é bom alinhar verticalmente as variáveis comuns e, para fazer isso, talvez seja necessário inserir alguns coeficientes zero sempre que a variável não aparecer em uma das equações.",
  "model": "google_nmt",
  "from_community_srt": "Também é bom alinhar verticalmente as variáveis comuns e para isso talvez você precise adicionar alguns coeficientes zero sempre que a variável",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Isso é chamado de sistema linear de equações.",
  "model": "google_nmt",
  "from_community_srt": "não apareça em uma das equações. Isso é chamado de um \"sistema de equações lineares\".",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Você pode notar que isso se parece muito com a multiplicação de vetores de matrizes.",
  "model": "google_nmt",
  "from_community_srt": "Você pode notar que isto se parece muito com multiplicação de matriz por vetor Na verdade,",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "Na verdade, você pode empacotar todas as equações em uma única equação vetorial onde você tem a matriz contendo todos os coeficientes constantes e um vetor contendo todas as variáveis, e seu produto matriz-vetor é igual a algum vetor constante diferente.",
  "model": "google_nmt",
  "from_community_srt": "você pode juntar todas as equações em uma única equação vetorial onde você tem a matriz contendo todos os coeficientes constantes, e um vetor contendo todas as variáveis, e o produto da matriz pelo vetor é igual a outro vetor constante.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "Vamos chamar essa matriz constante de A, denotar o vetor que contém as variáveis com um X em negrito e chamar o vetor constante no lado direito de V.",
  "model": "google_nmt",
  "from_community_srt": "Vamos chamar de A a matriz de constantes, chamar o vetor de variáveis de x (em negrito), e chamar de v o vetor constante da direita.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "Isso é mais do que apenas um truque de notação para escrever nosso sistema de equações em uma linha.",
  "model": "google_nmt",
  "from_community_srt": "Isso é mais do que um simples artifício para escrever nosso sistema de equações em uma única linha.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Ele lança luz sobre uma interpretação geométrica muito interessante para o problema.",
  "model": "google_nmt",
  "from_community_srt": "Isso traz uma luz de uma intepretação geométrica muito bacana para o problema.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "A matriz A corresponde a alguma transformação linear, então resolver Ax igual a V significa que estamos procurando um vetor X, que, após aplicar a transformação, chega a V.",
  "model": "google_nmt",
  "from_community_srt": "A matriz A corresponde a algumas transformações lineares, de modo que resolver Ax = v significa que estamos procurando um vetor x que, depois de aplicada as transformações, param em v.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Pense no que está acontecendo aqui por um momento.",
  "model": "google_nmt",
  "from_community_srt": "Pense sobre o que está acontecendo aqui por um momento.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Você pode ter em mente essa ideia realmente complicada de múltiplas variáveis, todas misturadas umas com as outras, apenas pensando em comprimir e transformar o espaço e tentar descobrir qual vetor pousa em outro.",
  "model": "google_nmt",
  "from_community_srt": "Você pode esquecer um pouco essa ideia realmente complicada de várias variáveis misturando-se umas às outras e pensar apenas em comprimir e rotacionar o espaço para tentar descobrir qual vetor para em outro.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Legal certo?",
  "model": "google_nmt",
  "from_community_srt": "Legal,",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Para começar de forma simples, digamos que você tenha um sistema com duas equações e duas incógnitas.",
  "model": "google_nmt",
  "from_community_srt": "né? Para começar devagar, suponha que você tem um sistema com duas equações e duas incógnitas.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "Isso significa que a matriz A é uma matriz 2x2 e V e X são vetores bidimensionais.",
  "model": "google_nmt",
  "from_community_srt": "Isto significa que a matriz A é uma matriz 2x2, e v e x são vetores bidimensionais.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "Agora, a forma como pensamos sobre as soluções para esta equação depende se a transformação associada a A comprime todo o espaço numa dimensão inferior, como uma reta ou um ponto, ou se deixa tudo que abrange todas as duas dimensões onde começou.",
  "model": "google_nmt",
  "from_community_srt": "Agora, como nós podemos pensar que as soluções para este sistema dependem se as transformações associadas a A comprimem todo o espaço em uma dimensão menor, como uma linha ou um ponto, ou se elas acabam gerando o espaço bidimensional onde elas começaram.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "Na linguagem do último vídeo, subdividimos nos casos em que A tem determinante zero e no caso em que A tem determinante diferente de zero.",
  "model": "google_nmt",
  "from_community_srt": "Na linguagem do último vídeo, nós dividimos no caso no qual A tem determinante zero, e no caso no qual A tem determinante diferente de zero.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Vamos começar com o caso mais provável, onde o determinante é diferente de zero, o que significa que o espaço não fica comprimido numa região de área zero.",
  "model": "google_nmt",
  "from_community_srt": "Vamos começar com o caso mais provável, no qual o determinante é diferente de zero, ou seja, o espaço não se comprime em um região de área zero.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "Nesse caso, sempre haverá um e apenas um vetor que cai em V, e você pode encontrá-lo reproduzindo a transformação ao contrário.",
  "model": "google_nmt",
  "from_community_srt": "Neste caso, haverá sempre um e apenas um vetor que para em v, e você pode encontrá-lo,",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "Seguindo para onde V vai enquanto rebobinamos a fita assim, você encontrará o vetor x tal que A vezes x é igual a V.",
  "model": "google_nmt",
  "from_community_srt": "fazendo a transformação reversa. Seguindo de onde v se encontra e voltando a fita desse jeito você vai encontrar o vetor x tal que A vezes x é igual a v.",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Quando você reproduz a transformação ao contrário, ela na verdade corresponde a uma transformação linear separada, comumente chamada de inversa de A, denotada por A elevado ao negativo.",
  "model": "google_nmt",
  "from_community_srt": "Quando você faz a transformação em sentido inverso, ela corresponde na verdade a uma transformação linear separada que geralmente chamamos de \"a inversa de A\"",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Por exemplo, se A fosse uma rotação de 90 graus no sentido anti-horário, então o inverso de A seria uma rotação de 90 graus no sentido horário.",
  "model": "google_nmt",
  "from_community_srt": "e denotamos A a menos 1 Por exemplo, se A é uma rotação anti-horária de 90º então a inversa de A seria uma rotação horária de 90º",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Se A fosse um cisalhamento para a direita que empurra J-Hat uma unidade para a direita, o inverso de A seria um cisalhamento para a esquerda que empurra J-Hat uma unidade para a esquerda.",
  "model": "google_nmt",
  "from_community_srt": "Se A é um cisalhamento para a direita que empurra ĵ uma unidade para a direita, a inversa de A um cisalhamento para a esquerda que empurra ĵ uma unidade para a esquerda",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "Em geral, A inverso é a transformação única com a propriedade de que se você primeiro aplicar A e depois seguir com a transformação A inversa, você terminará de volta ao ponto de partida.",
  "model": "google_nmt",
  "from_community_srt": "Em geral, a inversa de A é a única transformação com a propriedade de que, se você aplicar primeiro A e, em seguida, aplicar a transformação da inversa de A você acaba no mesmo lugar onde começou.",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "A aplicação de uma transformação após a outra é capturada algebricamente com a multiplicação de matrizes, portanto, a propriedade central desta transformação A inversa é que A inversa vezes A é igual à matriz que corresponde a não fazer nada.",
  "model": "google_nmt",
  "from_community_srt": "Aplicar uma transformação após a outra significa, algebricamente, multiplicar matrizes, portanto, a propriedade principal da inversão de matrizes é que A vezes inversa de A é igual à matriz que corresponde a não fazer nada.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "A transformação que não faz nada é chamada de transformação de identidade.",
  "model": "google_nmt",
  "from_community_srt": "A transformação que não faz nada é chamada de \"transformação de identidade\".",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "Ele deixa i-hat e j-hat onde estão, imóveis, então suas colunas são 1,0 e 0,1.",
  "model": "google_nmt",
  "from_community_srt": "Ele deixa î e ĵ onde estão, sem se mover, suas colunas são então um,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Depois de encontrar essa inversa, o que na prática você faria com um computador, você pode resolver sua equação multiplicando essa matriz inversa por v.",
  "model": "google_nmt",
  "from_community_srt": "zero, e zero, um. Uma vez encontrada esta inversa (que na prática você faz com um computador) você pode resolver sua equação multiplicando esta matriz inversa por v.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "E, novamente, o que isso significa geometricamente é que você está reproduzindo a transformação ao contrário e seguindo v.",
  "model": "google_nmt",
  "from_community_srt": "E, de novo, o que isso significa geometricamente é que você está fazendo a tranformação reversa e seguindo v.",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Este caso de determinante diferente de zero, que para uma escolha aleatória de matriz é de longe o mais provável, corresponde à ideia de que se tivermos duas incógnitas e duas equações, é quase certo que exista uma única solução única.",
  "model": "google_nmt",
  "from_community_srt": "Este caso de determinante diferente de zero, que é de longe a escolha aleatória de matriz mais provável corresponde à idéia de que se você tiver duas incógnitas e duas equações, é quase certo o caso de que há uma única solução.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Esta ideia também faz sentido em dimensões superiores, quando o número de equações é igual ao número de incógnitas.",
  "model": "google_nmt",
  "from_community_srt": "Esta ideia também faz sentido em dimensões maiores, quando o número de equações é igual ao número de incógnitas.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Novamente, o sistema de equações pode ser traduzido para a interpretação geométrica onde você tem alguma transformação A e algum vetor v, e você está procurando o vetor x que cai em v.",
  "model": "google_nmt",
  "from_community_srt": "Mais uma vez, o sistema de equações pode ser traduzido para a interpretação geométrica na qual você tem alguma transformação, A, e algum vetor,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "Contanto que a transformação A não comprima todo o espaço em uma dimensão inferior, o que significa que seu determinante é diferente de zero, haverá uma transformação inversa A inversa, com a propriedade de que se você fizer A primeiro, então fará A inverso , é o mesmo que não fazer nada.",
  "model": "google_nmt",
  "from_community_srt": "v, e você procura o vetor x que para em v. Sempre que a transformação A não comprime todo o espaço em uma dimensão menor, ou seja, seu determinante é diferente de zero, haverá uma transformação inversa, a inversa de A, com a propriedade de que se você primeiro fizer A,",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "E para resolver sua equação, basta multiplicar essa matriz de transformação reversa pelo vetor v.",
  "model": "google_nmt",
  "from_community_srt": "e depois fizer a inversa de A é o mesmo que não fazer nada. E para resolver a equação, você só tem que multiplicar a matriz de transformação reversa pelo vetor v.",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Mas quando o determinante é zero e a transformação associada ao sistema de equações comprime o espaço numa dimensão menor, não há inverso.",
  "model": "google_nmt",
  "from_community_srt": "Mas quando o determinante é zero, e a transformação associada a este sistema de equações comprime o espaço em uma dimensão menor, não existe inversa.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Você não pode cancelar uma linha para transformá-la em um avião.",
  "model": "google_nmt",
  "from_community_srt": "Você não pode \"descomprimir\" uma linha para transformá-la em um plano.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "Pelo menos isso não é algo que uma função possa fazer.",
  "model": "google_nmt",
  "from_community_srt": "Pelo menos, isso não é algo que uma função pode fazer.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Isso exigiria transformar cada vetor individual em uma linha inteira cheia de vetores.",
  "model": "google_nmt",
  "from_community_srt": "Isso exigiria transformar cada vetor individual em toda uma linha cheia de vetores.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Mas as funções só podem levar uma única entrada para uma única saída.",
  "model": "google_nmt",
  "from_community_srt": "Mas funções só pode ter uma única entrada para uma única saída.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Da mesma forma, para três equações e três incógnitas, não haverá inverso se a transformação correspondente comprimir o espaço 3D no plano, ou mesmo se o comprimir sobre uma linha ou ponto.",
  "model": "google_nmt",
  "from_community_srt": "Da mesma forma, para três equações com três incógnitas, não haverá inversa se a transformação correspodente comprime o espaço 3D em um plano, ou mesmo comprime-o em uma linha,",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Tudo isso corresponde a um determinante zero, já que qualquer região é comprimida em algo com volume zero.",
  "model": "google_nmt",
  "from_community_srt": "ou um ponto. Todos esses casos correspondem a um determinante zero, uma vez que qualquer região é comprimida em algo com volume zero.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "Ainda é possível que exista uma solução mesmo quando não há inverso.",
  "model": "google_nmt",
  "from_community_srt": "É possível que ainda exista uma solução mesmo quando não há nenhuma inversa, só que quando a sua transformação comprime o espaço para,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "Acontece que quando sua transformação comprime o espaço em, digamos, uma reta, você precisa ter sorte o suficiente para que o vetor v viva em algum lugar dessa reta.",
  "model": "google_nmt",
  "from_community_srt": "digamos, uma linha, você tem que ter a sorte do vetor v existir em algum lugar nessa linha.",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Você pode notar que alguns desses casos de determinante zero parecem muito mais restritivos do que outros.",
  "model": "google_nmt",
  "from_community_srt": "Você pode notar que alguns casos de determinante zero são ainda mais restritivos que outros.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Dada uma matriz 3x3, por exemplo, parece muito mais difícil existir uma solução quando ela comprime o espaço em uma linha em comparação com quando ela comprime as coisas em um plano, mesmo que ambos sejam determinantes zero.",
  "model": "google_nmt",
  "from_community_srt": "Dada uma matriz 3x3, por exemplo, parece muito mais difícil uma solução existir quando se comprime espaço em uma linha, do que quando se comprime tudo em um plano mesmo que em ambos os casos sejam de determinante zero.",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "Temos uma linguagem um pouco mais específica do que apenas dizer determinante zero.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Quando a saída de uma transformação é uma linha, o que significa que é unidimensional, dizemos que a transformação tem classificação um.",
  "model": "google_nmt",
  "from_community_srt": "Usamos uma linguagem um pouco mais específica ao invés de dizer \"determinante zero\" Quando a saída de uma transformação é uma linha, ou seja, é unidimensional, dizemos que a transformação tem um posto (rank) um.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Se todos os vetores pousarem em algum plano bidimensional, dizemos que a transformação tem classificação dois.",
  "model": "google_nmt",
  "from_community_srt": "Se todos os vetores param em algum plano (bidimensional), Nós dizemos a transformação tem um posto (rank) dois",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Portanto, a palavra classificação significa o número de dimensões na saída de uma transformação.",
  "model": "google_nmt",
  "from_community_srt": "Assim, a palavra posto (rank) significa o número de dimensões do resultado de uma transformação.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "Por exemplo, no caso de matrizes 2x2, a classificação dois é o melhor que pode ser.",
  "model": "google_nmt",
  "from_community_srt": "Por exemplo, no caso de matrizes 2x2, posto 2 é o melhor que podemos conseguir.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "Isso significa que os vetores de base continuam a abranger todas as duas dimensões do espaço e o determinante não é zero.",
  "model": "google_nmt",
  "from_community_srt": "Isso significa que os vetores de base continuam a gerar todo o espaço bidimensional, e o determinante é diferente de zero.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "Mas para matrizes 3x3, a classificação dois significa que entramos em colapso, mas não tanto quanto teriam entrado em colapso em uma situação de classificação um.",
  "model": "google_nmt",
  "from_community_srt": "Mas para matrizes 3x3, posto 2 significa que nós temos uma compressão, mas não tanto quanto seria se comprimíssemos para uma situação de posto 1.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "Se uma transformação 3D tiver um determinante diferente de zero e sua saída preencher todo o espaço 3D, ela terá uma classificação três.",
  "model": "google_nmt",
  "from_community_srt": "Se uma transformação 3D tem um determinante diferente de zero, e sua saída gera todo o espaço 3D,",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Este conjunto de todas as saídas possíveis para a sua matriz, seja uma linha, um plano, um espaço 3D, seja o que for, é chamado de espaço coluna da sua matriz.",
  "model": "google_nmt",
  "from_community_srt": "ela tem posto 3. Este conjunto de todas as saídas possíveis para a sua matriz, quer seja uma linha, um plano, espaço 3D, ou o que for, é chamado de \"espaço coluna\" de sua matriz.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Você provavelmente pode adivinhar de onde vem esse nome.",
  "model": "google_nmt",
  "from_community_srt": "Você provavelmente pode adivinhar de onde vem esse nome.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "As colunas da sua matriz informam onde os vetores de base pousam, e a extensão desses vetores de base transformados fornece todas as saídas possíveis.",
  "model": "google_nmt",
  "from_community_srt": "As colunas da sua matriz lhe dizem onde os vetores básicos param, e o espaço gerado por esses vetores transformados tem todas as saídas possíveis.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "Em outras palavras, o espaço da coluna é a extensão das colunas da sua matriz.",
  "model": "google_nmt",
  "from_community_srt": "Em outras palavras, o espaço coluna é o espaço gerado (span) das colunas da sua matriz.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Portanto, uma definição mais precisa de classificação seria que ela é o número de dimensões no espaço da coluna.",
  "model": "google_nmt",
  "from_community_srt": "Assim, uma definição mais precisa de posto (rank) seria o número de dimensões no espaço coluna.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Quando essa classificação é tão alta quanto possível, o que significa que é igual ao número de colunas, chamamos a matriz de classificação completa.",
  "model": "google_nmt",
  "from_community_srt": "Quando o posto é o máximo que ele poderia ser, ou seja, quando ele é igual ao número de colunas,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Observe que o vetor zero sempre será incluído no espaço coluna, pois as transformações lineares devem manter a origem fixa no lugar.",
  "model": "google_nmt",
  "from_community_srt": "dizemos que a matriz tem \"posto completo.\" Lembre-se que o vetor nulo  sempre está incluído no espaço coluna, uma vez que as transformações lineares devem manter a origem fixa em seu lugar.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "Para uma transformação de classificação completa, o único vetor que chega à origem é o próprio vetor zero.",
  "model": "google_nmt",
  "from_community_srt": "Para uma transformação de posto completo,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Mas para matrizes que não são de classificação completa, que se comprimem em uma dimensão menor, você pode ter um monte de vetores que chegam a zero.",
  "model": "google_nmt",
  "from_community_srt": "o único vetor que para na origem é o próprio vetor nulo mas para matrizes que não são de posto completo, que comprimem em uma dimensão menor, você pode ter um monte de vetores que param em zero.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Se uma transformação 2D comprime o espaço em uma linha, por exemplo, há uma linha separada em uma direção diferente cheia de vetores que são comprimidas na origem.",
  "model": "google_nmt",
  "from_community_srt": "Se uma transformação 2D comprime o espaço em uma linha, por exemplo, há uma linha separada em uma direção diferente, cheia de vetores que são comprimidos na origem.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Se uma transformação 3D comprime o espaço em um plano, há também uma linha completa de vetores que pousa na origem.",
  "model": "google_nmt",
  "from_community_srt": "Se uma transformação 3D comprime o espaço em um plano, há também uma linha cheia de vetores que param sobre a origem.",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Se uma transformação 3D comprimir todo o espaço em uma linha, então haverá um plano inteiro cheio de vetores que pousam na origem.",
  "model": "google_nmt",
  "from_community_srt": "Se uma transformação 3D comprime todo o espaço sobre uma linha, então há um plano cheio de vetores que param sobre a origem.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Esse conjunto de vetores que chega à origem é chamado de espaço nulo ou núcleo da sua matriz.",
  "model": "google_nmt",
  "from_community_srt": "Este conjunto de vetores que param na origem é chamado de \"espaço nulo\" ou \"núcleo\" (kernel) de sua matriz.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "É o espaço de todos os vetores que se tornam nulos, no sentido de que pousam no vetor zero.",
  "model": "google_nmt",
  "from_community_srt": "É o espaço de todos os vetores que se tornam nulos no sentido de que eles param sobre o vetor nulo.",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "Em termos do sistema linear de equações, quando v é o vetor zero, o espaço nulo fornece todas as soluções possíveis para a equação.",
  "model": "google_nmt",
  "from_community_srt": "Em termos do sistema linear de equações, quando v passa a ser o vetor nulo, o espaço nulo dá todas as possíveis soluções para a equação.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Essa é uma visão geral de alto nível de como pensar geometricamente sobre sistemas lineares de equações.",
  "model": "google_nmt",
  "from_community_srt": "Bom, essa é uma visão bem geral de como pensar nas sistemas de equações lineares de forma geométrica.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "Cada sistema tem algum tipo de transformação linear associada a ele, e quando essa transformação tem uma inversa, você pode usar essa inversa para resolver seu sistema.",
  "model": "google_nmt",
  "from_community_srt": "Cada sistema tem algum tipo de transformação linear associada e quando essa transformação tem uma inversa, você pode usar essa inversa para resolver o seu sistema.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "Caso contrário, a ideia de espaço de colunas permite-nos compreender quando existe uma solução, e a ideia de espaço nulo ajuda-nos a compreender como pode ser o conjunto de todas as soluções possíveis.",
  "model": "google_nmt",
  "from_community_srt": "Caso contrário, a idéia de espaço de coluna nos permite entender quando uma solução mesmo existe, e a idéia de um espaço nulo nos ajuda a entender como o conjunto de todas as soluções possíveis se parece.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Novamente, há muitas coisas que não abordei aqui, principalmente como calcular essas coisas.",
  "model": "google_nmt",
  "from_community_srt": "De novo, tem muita coisa que eu não cobri aqui, especialmente como calcular essas coisas.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Também tive que limitar meu escopo a exemplos em que o número de equações é igual ao número de incógnitas.",
  "model": "google_nmt",
  "from_community_srt": "Eu também tive que limitar o meu escopo para exemplos nos quais o número de equações é igual ao número de incógnitas.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Mas o objetivo aqui não é tentar ensinar tudo, é que você tenha uma forte intuição para matrizes inversas, espaço de colunas e espaço nulo, e que essas intuições tornem qualquer aprendizado futuro que você fizer mais frutífero.",
  "model": "google_nmt",
  "from_community_srt": "Mas o objetivo aqui não é tentar ensinar tudo; é que você saia com uma forte intuição sobre: matrizes inversas, espaço coluna e espaço nulo, e que essas intuições possam fazer com que qualquer aprendizado futuro possa ser mais frutífero.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "O próximo vídeo, a pedido popular, será uma breve nota de rodapé sobre matrizes não quadradas.",
  "model": "google_nmt",
  "from_community_srt": "O próximo vídeo, a pedidos, será um breve nota sobre matrizes não quadradas.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Depois disso, vou dar minha opinião sobre produtos escalares e algo muito legal que acontece quando você os vê sob a luz de transformações lineares.",
  "model": "google_nmt",
  "from_community_srt": "E depois dele, vou passar minha visão sobre produto escalar (interno) e algo muito legal que acontece quando você o enxerga sob a luz das transformações lineares.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]