1
00:00:00,500 --> 00:00:11,320
"Fazer a pergunta certa é mais difícil 
do que respondê-la" -- Georg Cantor

2
00:00:11,560 --> 00:00:15,160
Como você vem observando, a maior parte desta série está na compreensão de matrizes.

3
00:00:15,160 --> 00:00:16,470
e de operações com vetores

4
00:00:16,470 --> 00:00:20,040
através de uma forma mais visual das transformações lineares.

5
00:00:20,040 --> 00:00:24,020
Este vídeo não é exceção, descrevendo os conceitos de matrizes inversas,

6
00:00:24,020 --> 00:00:28,100
espaços colunas (espaço imagem), posto e espaço nulo (núcleo) de forma visual.

7
00:00:28,100 --> 00:00:32,230
Um aviso prévio: eu não vou falar sobre os métodos para implementar computacionalmente esses

8
00:00:32,230 --> 00:00:33,230
conceitos.

9
00:00:33,230 --> 00:00:34,910
Alguém até poderia argumentar que tal implementação seria muito importante.

10
00:00:34,910 --> 00:00:38,940
Existem muitas boas fontes para aprender a como implementar esses métodos além do material aqui paresentado.

11
00:00:38,940 --> 00:00:42,290
Palavras chaves: "Eliminação de Gauss" e "Escalonamento de Linhas"

12
00:00:42,290 --> 00:00:46,630
Eu acredito que o maior valor que eu tenho para agregar aqui é na parte intuitiva.

13
00:00:46,630 --> 00:00:50,940
Além disso, na prática, nós usualmente utilizamos programas para computar esses métodos.

14
00:00:50,940 --> 00:00:54,460
Primeiramente, algumas palavras sobre a utilizade da Algebra Linear.

15
00:00:54,460 --> 00:00:57,989
Por hora, você já tem uma ideia de como isso é usado para descrever a manipulação do

16
00:00:57,989 --> 00:00:58,989
espaço,

17
00:00:58,989 --> 00:01:01,559
o que é útil para coisas como computação gráfica e robótica

18
00:01:01,559 --> 00:01:05,210
mas uma das razões principais da álgebra linear ser aplicada de forma mais abrangente

19
00:01:05,210 --> 00:01:07,829
e requisitada para qualquer disciplina técnica

20
00:01:07,829 --> 00:01:11,490
é que ela nos permite resolver certos
 sistemas de equações.

21
00:01:11,490 --> 00:01:15,509
Quando eu digo "sistemas de equações", eu quero dizer que você tem uma lista de variáveis, coisas que você não

22
00:01:15,509 --> 00:01:16,509
conhece

23
00:01:16,509 --> 00:01:18,000
e uma lista de equações relacionando-as

24
00:01:18,000 --> 00:01:21,939
Em muitas situações, essas equações
 podem ser bem complicadas

25
00:01:21,939 --> 00:01:26,520
mas, se você tem sorte, elas podem 
estar em uma certa forma especial

26
00:01:26,520 --> 00:01:31,880
Em cada equação, a única acontecendo com cada variável é que ela está sendo escalada (multiplicada) por

27
00:01:31,880 --> 00:01:32,880
alguma constante

28
00:01:32,880 --> 00:01:36,159
e a única coisa acontecendo com aquelas variáveis escaladas é que elas estão sendo somadas

29
00:01:36,159 --> 00:01:37,209
umas às outras.

30
00:01:37,209 --> 00:01:43,560
Então, sem expoentes ou funções chiques, ou multiplicação de duas variáveis; coisas assim.

31
00:01:43,560 --> 00:01:46,649
A forma típica de organizar esse tipo especial de sistemas de equações

32
00:01:46,649 --> 00:01:50,009
é colocar todas as variáveis na esquerda

33
00:01:50,009 --> 00:01:52,930
e colocar qualquer constante "sobrando" na direita.

34
00:01:52,930 --> 00:01:56,859
Também é bom alinhar verticalmente as variáveis comuns

35
00:01:56,859 --> 00:02:00,249
e para fazer isso você pode precisar colocar alguns coeficientes zeros quando uma variável

36
00:02:00,249 --> 00:02:04,950
não aparece em uma das equações.

37
00:02:04,950 --> 00:02:08,170
Isso é chamado sistema linear de equações.

38
00:02:08,220 --> 00:02:11,360
Você pode ter percebido que isso se assemelha muito à uma multiplicação de matriz por vetor.

39
00:02:11,360 --> 00:02:16,100
Na verdade, você pode agregar todas as equações juntas em uma única equação vetorial,

40
00:02:16,220 --> 00:02:21,260
onde você tem a matriz contendo todos os coeficientes constantes, e um vetor contendo

41
00:02:21,460 --> 00:02:23,040
todas as variáveis,

42
00:02:23,040 --> 00:02:29,020
e seu produto matriz-vetor é igual a um vetor constante diferente.

43
00:02:29,020 --> 00:02:31,319
Chamemos essa matriz constante de A,

44
00:02:31,319 --> 00:02:34,879
denote o vetor com as variáveis x negrito,

45
00:02:34,879 --> 00:02:39,030
e chame o vetor constante do lado direito de 'v'.

46
00:02:39,030 --> 00:02:42,370
Isso é mais que um truque notacional para conseguir que nosso sistema de equações fique escrito em

47
00:02:42,370 --> 00:02:43,549
uma linha.

48
00:02:43,549 --> 00:02:47,629
Ele sugere uma interpretação geométrica muito legal para este problema.

49
00:02:47,629 --> 00:02:52,910
A matriz A corresponde a uma transformação linear, então resolver Ax=v

50
00:02:52,910 --> 00:02:57,470
significa que procuramos por um vetor x que, ao ser aplicado à transformação, vai parar em

51
00:02:57,470 --> 00:02:58,470
v.

52
00:02:58,470 --> 00:03:02,000
Pense sobre o que está acontecendo aqui por um momento.

53
00:03:02,000 --> 00:03:07,129
Você consegue manter em mente esta ideia complicada de múltiplas variáveis todas conectadas

54
00:03:07,129 --> 00:03:08,129
umas com as outras

55
00:03:08,129 --> 00:03:11,769
apenas pensando sobre esmagar e esticar o espaço para pensar em que vetor

56
00:03:11,769 --> 00:03:13,140
aterrissa em outro.

57
00:03:13,140 --> 00:03:14,849
Legal, não é?

58
00:03:14,849 --> 00:03:19,079
Para começar aos poucos, vamos supor que você tenha um sistema com duas equações e duas incógnitas.

59
00:03:19,079 --> 00:03:21,909
Isto significa que a matriz A é uma matriz 2 x 2,

60
00:03:21,909 --> 00:03:24,819
e v e x são dois vetores bidimensionais.

61
00:03:24,819 --> 00:03:28,489
Agora, a forma como pensamos nas soluções dessa equação

62
00:03:28,489 --> 00:03:33,879
depende da transformação linear associada a A apertar o espaço numa

63
00:03:33,879 --> 00:03:34,879
dimensão menor,

64
00:03:34,879 --> 00:03:35,879
como uma reta ou um ponto,

65
00:03:35,879 --> 00:03:40,780
ou se deixa o plano alcançando as duas dimensões de onde partiu.

66
00:03:40,780 --> 00:03:45,650
Na linguagem do último vídeo, dividimos nos casos em que A tem determinante nulo,

67
00:03:45,650 --> 00:03:51,689
em o caso em que A tem determinante não nulo.

68
00:03:51,689 --> 00:03:55,109
Vamos começar com o caso mais provável, que é com o determinante não nulo,

69
00:03:55,109 --> 00:03:58,650
significando que o espaço não é apertado em uma região de área nula.

70
00:03:58,650 --> 00:04:03,409
Nesse caso, sempre haverá um, e apenas um vetor que aterrissa em v,

71
00:04:03,409 --> 00:04:07,420
e você pode achá-lo reproduzindo a transformação ao contrário.

72
00:04:07,420 --> 00:04:10,219
Seguindo 'v' à medida que voltamos a fita assim,

73
00:04:10,219 --> 00:04:15,900
você encontrará o vetor 'x' tal que A vezes 'x' é igual a 'v'.

74
00:04:15,900 --> 00:04:20,500
Quando você reproduz a transformação ao contrário, na verdade corresponde a outra

75
00:04:20,500 --> 00:04:21,500
transformação linear,

76
00:04:21,500 --> 00:04:23,380
comumente chamada "a inversa de A"

77
00:04:23,380 --> 00:04:25,440
denotada "A a menos 1" [Aˆ(-1)].

78
00:04:25,440 --> 00:04:28,640
Por exemplo, se A fosse uma rotação de 90º no sentido anti-horário,

79
00:04:28,640 --> 00:04:34,780
então a inversa de A seria uma rotação de 90º no sentido horário.

80
00:04:34,780 --> 00:04:38,380
Se A fosse um cisalhamento à direita que empurra ĵ uma unidade à direita,

81
00:04:38,380 --> 00:04:43,090
então a inversa de A seria um cisalhamento à esquerda que empurra ĵ uma unidade à esquerda.

82
00:04:43,090 --> 00:04:48,970
Em geral, Aˆ(-1) é a única transformação com a propriedade em que se você primeiro aplica

83
00:04:48,970 --> 00:04:49,970
A,

84
00:04:49,970 --> 00:04:52,370
depois aplica Aˆ(-1),

85
00:04:52,370 --> 00:04:54,760
você volta onde começou.

86
00:04:54,760 --> 00:04:59,640
Aplicar uma transformação após a outra é capturado algebricamente com uma multiplicação matricial,

87
00:04:59,640 --> 00:05:05,160
então a propriedade central desta transformação Aˆ(-1) é que ela vezes A

88
00:05:05,160 --> 00:05:08,190
é igual à matriz que corresponde a fazer nada.

89
00:05:08,190 --> 00:05:11,850
Esta transformação que não faz nada é chamada "transformação identidade".

90
00:05:11,850 --> 00:05:15,060
Ela deixa î e ĵ ambos onde estão, imóveis,

91
00:05:15,060 --> 00:05:20,170
então suas colunas são (1,0) e (0,1).

92
00:05:20,170 --> 00:05:23,600
Uma vez que você encontra essa inversa, o que em geral é feito em computador,

93
00:05:23,600 --> 00:05:30,100
você pode resolver sua equação multiplicando a matriz inversa por 'v'.

94
00:05:30,100 --> 00:05:34,610
Novamente, o que isto significa geometricamente é que você está aplicando a transformação

95
00:05:34,610 --> 00:05:40,550
ao contrário, e seguindo v.

96
00:05:40,550 --> 00:05:44,650
Esse caso em que o determinante é diferente de zero, o qual para uma escolha aleatória de matriz é

97
00:05:44,650 --> 00:05:46,080
de longe o mais provável,

98
00:05:46,080 --> 00:05:49,690
corresponde à ideia de que se você tem duas incógnitas e duas equações,

99
00:05:49,690 --> 00:05:54,160
é quase certo que existe uma única solução.

100
00:05:54,160 --> 00:05:56,190
Esta ideia também faz sentido em dimensões maiores,

101
00:05:56,190 --> 00:05:59,020
quando o número de equações é igual ao número de incógnitas.

102
00:05:59,020 --> 00:06:04,130
Novamente, o sistema de equações pode ser interpretado geometricamente

103
00:06:04,130 --> 00:06:08,470
com uma transformação A,

104
00:06:08,470 --> 00:06:09,680
e algum vetor 'v',

105
00:06:09,680 --> 00:06:16,080
e você procura pelo vetor 'x' que vai parar em 'v'.

106
00:06:16,080 --> 00:06:20,480
Desde que a transformação A não aperte todo o espaço em uma dimensão menor,

107
00:06:20,480 --> 00:06:22,900
ou seja, seu determinante é não-nulo,

108
00:06:22,900 --> 00:06:26,060
então haverá uma transformação inversa, Aˆ(-1),

109
00:06:26,060 --> 00:06:28,360
com a propriedade de que se você fizer antes A,

110
00:06:28,360 --> 00:06:30,020
e depois Aˆ(-1),

111
00:06:30,020 --> 00:06:33,750
é o mesmo que não fazer nada.

112
00:06:33,750 --> 00:06:38,270
E para resolver sua equação, você apenas tem que multiplicar a transformação inversa

113
00:06:38,270 --> 00:06:43,660
pelo vetor 'v'.

114
00:06:43,660 --> 00:06:47,610
Mas quando o determinante é nulo, e a transformação

115
00:06:47,610 --> 00:06:48,610
associada com esse sistema

116
00:06:48,610 --> 00:06:52,500
esmaga o espaço em uma dimensão menor, não há inversa.

117
00:06:52,500 --> 00:06:55,630
Você não pode "desesmagar" uma linha para transformá-la num plano.

118
00:06:55,630 --> 00:06:58,490
Pelo menos não é o que uma função pode fazer.

119
00:06:58,490 --> 00:07:01,060
Isso envolveria transformar cada vetor individual

120
00:07:01,060 --> 00:07:03,860
em uma linha cheia de vetores.

121
00:07:03,860 --> 00:07:07,860
Mas funções só podem tomar uma entrada simples e devolver uma saída simples.

122
00:07:07,860 --> 00:07:11,160
Similarmente, para três equações e incógnitas,

123
00:07:11,160 --> 00:07:14,360
não haverá inversa de a transformação correspondente

124
00:07:14,360 --> 00:07:17,030
apertar o espaço 3D num plano,

125
00:07:17,030 --> 00:07:20,140
ou mesmo se apertar numa linha ou num ponto.

126
00:07:20,140 --> 00:07:22,420
Todos esses casos correspondem ao determinante nulo,

127
00:07:22,420 --> 00:07:27,120
dado que alguma região é apertada em algo com volume nulo.

128
00:07:27,120 --> 00:07:31,150
Ainda é possível que a solução exista mesmo sem inversa,

129
00:07:31,150 --> 00:07:35,070
é só que quando a sua transformação aperta o espaço, digamos, em uma reta,

130
00:07:35,070 --> 00:07:43,490
você tem que ter sorte do vetor 'v' viver em algum local desta reta.

131
00:07:43,490 --> 00:07:48,870
Você pode notar que alguns desses casos de determinante nulo parecem mais restritivos que outros.

132
00:07:48,870 --> 00:07:53,400
Dada uma matriz 3 x 3, por exemplo, parece mais difícil que haja uma solução

133
00:07:53,400 --> 00:07:58,190
quando ela aperta o espaço em uma linha do que quando ela aperta o espaço em um plano,

134
00:07:58,190 --> 00:08:02,750
mesmo que ambos desses casos tenham determinante nulo.

135
00:08:02,750 --> 00:08:06,630
Temos uma linguagem que é um pouco mais específica do que apenas dizer "determinante nulo".

136
00:08:06,630 --> 00:08:10,990
Quando a saída de uma transformação é uma linha, significando que é unidimensional,

137
00:08:10,990 --> 00:08:15,300
dizemos que a transformação tem "posto" 1.

138
00:08:15,300 --> 00:08:18,170
Se todos os vetores aterrissam em um plano bidimensional,

139
00:08:18,170 --> 00:08:23,060
dizemos que a transformação tem "posto" 2.

140
00:08:23,060 --> 00:08:28,470
Então a palavra "posto" significa o número de dimensões na saída da transformação.

141
00:08:28,470 --> 00:08:33,170
Por exemplo, no caso de matrizes 2 x 2, posto 2 é o melhor que dá pra alcançar.

142
00:08:33,170 --> 00:08:37,820
Significa que os vetores da base continuam a alcançar as duas dimensões do espaço,

143
00:08:37,820 --> 00:08:39,640
e o determinante é não-nulo.

144
00:08:39,640 --> 00:08:43,560
Mas para matrizes 3 x 3, posto 2 indica que colapsamos,

145
00:08:43,560 --> 00:08:47,290
mas não tanto quanto numa solução de posto 1.

146
00:08:47,290 --> 00:08:52,500
Se uma transformação 3D tem determinante não-nulo, e sua saída enche todo o espaço 3D,

147
00:08:52,500 --> 00:08:54,650
ela tem posto 3.

148
00:08:54,650 --> 00:08:57,210
Esse conjunto de todas as saídas possíveis para esta matriz,

149
00:08:57,210 --> 00:09:00,180
seja uma linha, um plano, o espaço 3D, o que for,

150
00:09:00,180 --> 00:09:04,450
é chamada "espaço coluna" da sua matriz.

151
00:09:04,450 --> 00:09:06,760
Você provavelmente pode chutar de onde vem esse nome.

152
00:09:06,760 --> 00:09:11,190
As colunas da sua matriz te dizem onde os vetores da base aterrissam,

153
00:09:11,190 --> 00:09:15,780
e o subespaço gerado de todos os vetores de base transformados lhe dá todas as saídas possíveis.

154
00:09:15,780 --> 00:09:22,260
Em outras palavras, o espaço coluna é o subespaço gerado pelas colunas de sua matriz.

155
00:09:22,260 --> 00:09:26,070
Então, uma definição mais precisa de posto seria que

156
00:09:26,070 --> 00:09:30,200
é o número de dimensões no espaço coluna.

157
00:09:30,200 --> 00:09:32,360
Quando este posto é tão alto quanto possível,

158
00:09:32,360 --> 00:09:38,090
significando que é igual ao número de colunas, dizemos que a matriz tem "posto cheio".

159
00:09:38,090 --> 00:09:42,740
Note que o vetor nulo sempre está no espaço coluna.

160
00:09:42,740 --> 00:09:47,040
dado que transformações lineares mantém a origem fixa.

161
00:09:47,040 --> 00:09:51,680
Para uma transformação de posto cheio, o único vetor que para na origem é

162
00:09:51,680 --> 00:09:52,680
o próprio vetor nulo,

163
00:09:52,680 --> 00:09:56,430
mas para matrizes que não são posto cheio, que apertam as coisas em dimensões menores,

164
00:09:56,430 --> 00:10:02,150
você pode ter um monte de vetores
 que vão parar na origem.

165
00:10:02,150 --> 00:10:05,090
Se uma transformação 2D aperta o espaço em uma linha, por exemplo,

166
00:10:05,090 --> 00:10:08,300
há uma outra reta, em uma direção diferente,

167
00:10:08,300 --> 00:10:11,930
cheia de vetores que são apertados na origem.

168
00:10:11,930 --> 00:10:14,680
Se uma transformação 3D aperta o espaço em um plano,

169
00:10:14,680 --> 00:10:20,800
também há uma reta inteira de vetores que aterrissam na origem.

170
00:10:20,800 --> 00:10:24,270
Se uma transformação 3D aperta todo o espaço em uma linha,

171
00:10:24,270 --> 00:10:33,390
então há todo um plano de vetores que são enviados na origem.

172
00:10:33,390 --> 00:10:37,960
Esse conjunto de vetores que aterrissam na origem é chamado "espaço nulo" ou "núcleo"

173
00:10:37,960 --> 00:10:39,370
da sua matriz.

174
00:10:39,370 --> 00:10:42,250
É o (sub)espaço de todos os vetores que se tornam nulos,

175
00:10:42,250 --> 00:10:45,750
no sentido que vão parar no vetor nulo.

176
00:10:45,750 --> 00:10:50,310
Em termos do sistema linear de equações, quando 'v' calha de ser o

177
00:10:50,310 --> 00:10:56,910
vetor nulo, o núcleo te dá todas as soluções possíveis para a equação.

178
00:10:56,910 --> 00:10:58,470
Então essa é uma visão geral em alto nível

179
00:10:58,470 --> 00:11:02,400
sobre como pensar sobre sistemas lineares geometricamente.

180
00:11:02,400 --> 00:11:05,160
Cada sistema tem uma transformação linear associada

181
00:11:05,160 --> 00:11:06,160
com ele.

182
00:11:06,160 --> 00:11:08,150
e quando esta transformação tem um inverso,

183
00:11:08,150 --> 00:11:11,740
você pode usar esse inverso para resolver seu sistema.

184
00:11:11,740 --> 00:11:18,200
Caso contrário, a ideia de um espaço coluna nos deixa entender quando a solução existe,

185
00:11:18,200 --> 00:11:21,370
e a ideia de um espaço nulo nos deixa entender o conjunto de

186
00:11:21,370 --> 00:11:25,110
a forma de todas as possíveis soluções.

187
00:11:25,110 --> 00:11:27,620
Novamente, há muito que eu não cobri aqui,

188
00:11:27,620 --> 00:11:29,560
principalmente como computar estas coisas.

189
00:11:29,560 --> 00:11:32,870
Também tive que limitar meu escopo a exemplos em que o número de equações

190
00:11:32,870 --> 00:11:35,170
é igual ao número de incógnitas.

191
00:11:35,170 --> 00:11:37,480
Mas o objetivo aqui não é tentar ensinar tudo;

192
00:11:37,480 --> 00:11:41,361
e sim que você saia com uma intuição forte para matrizes inversas,

193
00:11:41,361 --> 00:11:43,300
espaço-coluna, núcleo,

194
00:11:43,300 --> 00:11:47,800
e que essas intuições tornem seu aprendizado futuro mais frutífero.

195
00:11:47,800 --> 00:11:51,980
No próximo vídeo, por aclamação popular, farei uma breve nota sobre matrizes não-quadradas.

196
00:11:51,980 --> 00:11:55,130
Depois disso, lhes darei minha visão em produtos internos,

197
00:11:55,130 --> 00:11:56,980
e algo bem legal quando você os vê

198
00:11:56,980 --> 00:11:59,320
sob a luz de transformações lineares.

199
00:11:59,500 --> 00:12:01,060
Até lá!

