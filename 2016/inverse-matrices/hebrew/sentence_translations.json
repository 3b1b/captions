[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "כפי שאתה ודאי יכול לדעת עד עכשיו, עיקר הסדרה הזו נוגעת להבנת פעולות מטריצה ווקטור דרך העדשה החזותית יותר של טרנספורמציות ליניאריות.",
  "model": "google_nmt",
  "from_community_srt": "לשאול את השאלה הנכונה היא יותר קשה מלענות עליה - ג'ורג' קאנטור(מתמטיקאי יהודי ואבי תורת הקבוצות) -כפי שאתה יכול להבין עד עכשיו, מרבית הסידרה(סירטונים) היא על הבנת המטריצה והפעולות הוקטוריות בעזרתן קיבלנו יותר עדשות שונות דרכן ראינו של מהן טרנספורמציות לינאריות.",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "סרטון זה אינו יוצא מן הכלל, ומתאר את המושגים של מטריצות הפוכות, רווח עמודות, דירוג ורווח ריק דרך העדשה הזו.",
  "model": "google_nmt",
  "from_community_srt": "הסירטון הזה לא יוצא דופן, מתואר בו הרעיונות של מטריצות הפיכות. מרחב העמודה, דרגה ומרחב הגרעין דרך אותן עדשות.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "עם זאת, אזהרה מוקדמת, אני לא הולך לדבר על השיטות לחישוב הדברים האלה, ויש שיטענו שזה די חשוב.",
  "model": "google_nmt",
  "from_community_srt": "הנה אזהרה מוקדמת: אני לא הולך לדבר על השיטות איתן אפשר לחשב את הדברים הללו, וחלק מהאנשים יטענו שזה דיי חשוב.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "יש הרבה משאבים טובים מאוד ללימוד השיטות האלה מחוץ לסדרה הזו, מילות מפתח גאוס חיסול וצורת דרג שורה.",
  "model": "google_nmt",
  "from_community_srt": "יש הרבה מקורות טובים כדי ללמוד את השיטות הללו שהן לא במסגרת הסירטונים הללו. מילות מפתח: \"דירוג מטריצות\" ו\"מטריצה מדורגת קנונית\".",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "אני חושב שרוב הערך שאני צריך להוסיף כאן הוא על חצי האינטואיציה.",
  "model": "google_nmt",
  "from_community_srt": "אני חושב שעיקר הערך שהוספתי כאן הוא מהצד האינטואיטיבי של החשיבה.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "בנוסף, בפועל, אנחנו בדרך כלל מקבלים תוכנה כדי לחשב את החומר הזה עבורנו בכל מקרה.",
  "model": "google_nmt",
  "from_community_srt": "בנוסף, באופן מעשי, אנחנו בדרך כלל משתמשים בתוכנה לחשב דברים כאלה בכל מקרה.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "ראשית, כמה מילים על התועלת של אלגברה לינארית.",
  "model": "google_nmt",
  "from_community_srt": "קודם, מספר מילים על השימושיות של אלגברה לינארית.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "עד עכשיו, כבר יש לך רמז לאופן השימוש בו בתיאור המניפולציה של החלל, דבר שימושי עבור דברים כמו גרפיקה ממוחשבת ורובוטיקה.",
  "model": "google_nmt",
  "from_community_srt": "עד עכשיו, אתה כבר קיבלת רמז על איך משתמשים באלגברה לינארית לתיאור השינוי של המרחב, שמאוד שימושי לדברים כמו מחשב,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "אבל אחת הסיבות העיקריות לכך שאלגברה לינארית ישימה יותר ונדרשת כמעט לכל דיסציפלינה טכנית היא שהיא מאפשרת לנו לפתור מערכות מסוימות של משוואות.",
  "model": "google_nmt",
  "from_community_srt": "גראפיקה ורובוטיקה, אבל אחת הסיבות העיקריות שאלגברה לינאריות היא יותר ישימה במובן הרחב ודרושה עבור כמעט כל תחום טכני של מחקר , זה שהיא נותנת לך לפתור מערכות מסויימות של משוואות.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "כשאני אומר מערכת משוואות, אני מתכוון שיש לך רשימה של משתנים, דברים שאתה לא יודע, ורשימת משוואות המתייחסות אליהם.",
  "model": "google_nmt",
  "from_community_srt": "כשאני אומר \"מערכות של משוואות\", אני מתכוון שיש לך רשימה של פרמטרים(משתנים), דברים שאתה לא יודע, ורשימה של משוואות שקשורות אליהם.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "בהרבה מצבים, המשוואות האלה יכולות להסתבך מאוד.",
  "model": "google_nmt",
  "from_community_srt": "בהרבה מקרים, המשוואות הללו נהיות מאוד מסובכות, אבל,",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "אבל, אם יתמזל מזלך, הם עשויים ללבוש צורה מיוחדת מסוימת.",
  "model": "google_nmt",
  "from_community_srt": "אם יש לך מזל, אתה תשתמש בצורה מיוחדת.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "בתוך כל משוואה, הדבר היחיד שקורה לכל משתנה הוא שהוא משתנה לפי קבוע כלשהו, והדבר היחיד שקורה לכל אחד מהמשתנים בקנה מידה זה שהם מתווספים זה לזה.",
  "model": "google_nmt",
  "from_community_srt": "שבתוך כל משוואה, הדבר היחידי שקורה לכל משתנה הוא שהוא מוכפל בסקלר ע\"י קבוע כלשהו, והדבר היחידי שקורה לאותם משתנים שמוכפלים בסקלר, הם שמתווספים אחד לשני.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "אז בלי מעריכים או פונקציות מפוארות או הכפלה של שני משתנים יחד, דברים כאלה.",
  "model": "google_nmt",
  "from_community_srt": "לא, בלי אקספוננט או משוואות מוזרות אחרות, או הכפלת שני משתנים אחד בשני;",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "הדרך האופיינית לארגן סוג כזה של מערכת משוואות מיוחדת היא לזרוק את כל המשתנים בצד שמאל ולשים את כל הקבועים המתמשכים בצד ימין.",
  "model": "google_nmt",
  "from_community_srt": "דברים כאלה. הדרך הרגילה לארגן מערכת מיוחדת כזאת של משוואות היא \"לזרוק\" את כל המשתנים לצד שמאל, ולהשים קבועים כלשהם מצד ימין שלהם.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "זה גם נחמד ליישר אנכית את המשתנים הנפוצים, וכדי לעשות זאת, ייתכן שתצטרך לזרוק כמה מקדמי אפס בכל פעם שהמשתנה לא מופיע באחת מהמשוואות.",
  "model": "google_nmt",
  "from_community_srt": "זה גם מאוד נחמד לסדר את כולם בצורה אנכית בעמודה, וכדי לעשות זאת, אתה אולי תצטרך לזרוק קצת מקדמים של אפס איפה שתראה שהמשתנה לא מופיע באחת מהמשוואות הללו.",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "זה נקרא מערכת משוואות לינארית.",
  "model": "google_nmt",
  "from_community_srt": "זה נקרא \" מערכת משוואות לינארית\".",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "אולי תשים לב שזה דומה מאוד לכפל מטריצה-וקטור.",
  "model": "google_nmt",
  "from_community_srt": "אתה אולי תבחין בכך שזה נראה כמו הכפלת וקטור במטריצה.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "למעשה, אתה יכול לארוז את כל המשוואות יחד למשוואה וקטורית אחת שבה יש לך את המטריצה המכילה את כל המקדמים הקבועים ווקטור המכיל את כל המשתנים, ומכפלת המטריצה-וקטור שלהם שווה לכמה וקטור קבוע שונה.",
  "model": "google_nmt",
  "from_community_srt": "למעשה, אתה יכול לארוז את כל המשוואות יחדיו לתוך משוואה של וקטור בודד, בעוד שהמטריצה מכילה את כל המקדמים הקבועים, הוקטור מכיל את כל המשתנים, והתוצר, שהוא הוקטור מטריצה שלהם - שווה לוקטור שהוא קבוע שונה כלשהו.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "בואו נקרא את המטריצה הקבועה הזו A, נסמן את הווקטור שמחזיק את המשתנים באיקס מודגש, ונקרא לוקטור הקבוע בצד ימין V.",
  "model": "google_nmt",
  "from_community_srt": "בוא נסמן את המטריצה הקבועה הזאת כ-A, נסמן את הוקטור המכיל את המשתנים ב-x מודגש, ונקרא לוקטור הקבוע מצד ימין בסימן v.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "זה יותר מסתם טריק סימון כדי לכתוב את מערכת המשוואות שלנו בשורה אחת.",
  "model": "google_nmt",
  "from_community_srt": "זה יותר מסתם טריק של סימון בו אנו נעזרים כדי לכתוב את המערכת בשורה אחת.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "זה שופך אור על פרשנות גיאומטרית די מגניבה לבעיה.",
  "model": "google_nmt",
  "from_community_srt": "זה שופך אור על פירוש גיאומטרי ממש מגניב עבור הבעיה הזאת.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "המטריצה A מתכתבת עם טרנספורמציה לינארית כלשהי, כך שפתרון Axe שווה ל-V אומר שאנו מחפשים וקטור X, אשר לאחר החלת הטרנספורמציה נוחת על V.",
  "model": "google_nmt",
  "from_community_srt": "המטריצה A מתאימה לטרנספורמציה לינארית כלשהי, כשפותרים A*x = v הכוונה היא, שאנחנו מחפשים וקטור x, איתו,",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "תחשוב על מה שקורה כאן לרגע.",
  "model": "google_nmt",
  "from_community_srt": "לאחר יישום הטרנספורמציה - הוא ינחת על .v תחשוב לרגע מה קורה כאן.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "אתה יכול להחזיק בראש את הרעיון המסובך הזה של משתנים מרובים שכולם מתערבבים זה בזה רק על ידי מחשבה על כיווץ ושינוי חלל וניסיון להבין איזה וקטור נוחת על וקטור אחר.",
  "model": "google_nmt",
  "from_community_srt": "אתה יכול לשמור את זה בראשך, זהו רעיון מסובך עבור מספר משתנים שמתערבבים אחד עם השני רק על לחשוב על כיווץ ושינוי המרחב, ולנסות להבין איזה וקטור נוחת על אחד אחר.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "מגניב נכון?",
  "model": "google_nmt",
  "from_community_srt": "מגניב,",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "כדי להתחיל בפשטות, נניח שיש לך מערכת עם שתי משוואות ושני לא ידועים.",
  "model": "google_nmt",
  "from_community_srt": "נכון? נתחיל בפשטות, בוא נגיד שיש לך מערכת עם שתי משוואות ו-2 נעלמים.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "המשמעות היא שהמטריקס A היא מטריצה 2x2, ו-V ו-X הם כל אחד וקטור דו-ממדי.",
  "model": "google_nmt",
  "from_community_srt": "זה אומר שהמטריצה A היא מטריצה 2 על 2(2x2), ו-v ו-x - כל אחד מהם הוא וקטור ב-2 מימדים.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "כעת, האופן שבו אנו חושבים על הפתרונות למשוואה זו תלוי בשאלה האם הטרנספורמציה הקשורה ל-A מעיכה את כל החלל לממד נמוך יותר, כמו קו או נקודה, או אם היא משאירה את הכל על פני שני הממדים המלאים במקום שבו התחילה.",
  "model": "google_nmt",
  "from_community_srt": "עכשיו, תחשוב על כל הפיתרונות האפשריים של המשוואה תלוי אם הטרנספורמציה הזאת מתקשרת לכך ש-A מכווץ את כל המרחב לתוך מימד נמוך יותר, כמו קו או נקודה, או שזה משאיר את הפרישה של הוקטורים ב-2 מימדים,",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "בשפת הסרטון האחרון, אנו מתחלקים למקרים שבהם ל-A יש אפס דטרמיננט ולמקרה שבו ל-A יש דטרמיננט לא אפס.",
  "model": "google_nmt",
  "from_community_srt": "איפה שהם היו מתלכתחילה. או כמו שאמרנו בשפה של הסירטון האחרון: אנחנו חילקנו את זה למקרה פרטי בו הדטרמיננטה של A היא אפס.",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "נתחיל מהמקרה הסביר ביותר, שבו הקובע אינו אפס, כלומר המרחב לא נדחס לאזור של שטח אפס.",
  "model": "google_nmt",
  "from_community_srt": "ולמקרה פרטי בו הדטרמיננטה של A שונה מאפס. בוא נתחיל עם המקרה שסביר להניח שתתקל בו. המקרה בו הדטרמיננטה שונה מאפס. הכוונה היא, שהמרחב לא מתכווץ לתוך שטח שהוא אפס.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "במקרה זה, תמיד יהיה וקטור אחד ויחיד שינחת על V, ותוכל למצוא אותו על ידי הפעלת הטרנספורמציה לאחור.",
  "model": "google_nmt",
  "from_community_srt": "במקרה הזה, תמיד יהיה וקטור אחד ויחיד שנוחת על v, ואתה יכול למצוא אותו ע\"י כך שתשחק הפוך עם הטרנספורמציה.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "בצע את המקום שבו V הולך כשאנו מגלגלים את הקלטת לאחור כך, תמצא את הווקטור x כך ש-A כפול x שווה ל-V.",
  "model": "google_nmt",
  "from_community_srt": "אם עוקבים אחרי איפה v הולך, כשאנחנו מריצים אחורה ככה את הסירטון, אתה תמצא שהוקטור x,",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "כאשר אתה משחק את הטרנספורמציה הפוך, הוא למעשה מתאים לטרנספורמציה ליניארית נפרדת, הנקראת בדרך כלל היפוך של A, המסומנת A לשלילה.",
  "model": "google_nmt",
  "from_community_srt": "כך ש- A כפול x שווה ל-v. כשאתה משחק עם הטרנספורמציה בצורה הפוכה, זה למען האמת מתאים לטרנספורמציה לינארית נפרדת, הידועה בשם \"ההופכית של A\" מסומן ב-A עם מינוס אחת(כמו 1 חלקי A).",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "לדוגמה, אם A היה סיבוב נגד כיוון השעון ב-90 מעלות, אז ההיפוך של A יהיה סיבוב ב-90 מעלות בכיוון השעון.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, אם הייתי מסובב את A כנגד כיוון השעון בזווית של 90 מעלות, אז ההופכי לכך יהיה לסובב את A ב-90 מעלות בכיוון השעון.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "אם A היה גזירה ימינה שדוחפת את j-hat יחידה אחת ימינה, ההיפוך של A היה גזירה שמאלה שדוחפת את j-hat יחידה אחת שמאלה.",
  "model": "google_nmt",
  "from_community_srt": "אם A היה נגזרת ימנית שדוחפת את j כובע יחידה אחת ימינה, ההפוכי של A יהיה נגזרת שדוחפת את j כובע שמאלה ביחידה אחת.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "באופן כללי, A הפוך הוא הטרנספורמציה הייחודית עם המאפיין שאם אתה מיישם לראשונה A, ואז עקוב אחריו עם הטרנספורמציה A הפוך, אתה בסופו של דבר בחזרה למקום שבו התחלת.",
  "model": "google_nmt",
  "from_community_srt": "באופן כללי, ההופכית של A היא טרנספורמציה מיוחדת עם התכונה שאם קודם תפעיל את A ואז לאחר מכך עם הטרנספורמציה של A הופכית",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "החלת טרנספורמציה אחת אחרי השנייה נתפסת באופן אלגברי עם כפל מטריצה, ולכן תכונת הליבה של טרנספורמציה A הפוך היא ש-A הפוך כפול A שווה למטריצה שמתאימה לא לעשות כלום.",
  "model": "google_nmt",
  "from_community_srt": "אתה חוזר לנקודת ההתחלה. יישום טרנספורמציה אחת אחרי השניה, מיוצגת אלגברה עם כפל מטריצות, אז תכונת הליבה של הטרנספורמציה של A הופכית, היא ש-A הפוך כפול A שווה למטריצה מתאימה אשר לא עושה דבר.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "הטרנספורמציה שלא עושה כלום נקראת הטרנספורמציה של זהות.",
  "model": "google_nmt",
  "from_community_srt": "הטרנספורמציה שלא עושה כלום נקראת \"טרנספורמציית הזהות\".",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "הוא משאיר את i-hat ו-j-hat כל אחד במקום שבו הם נמצאים, ללא תנועה, כך שהעמודות שלו הן 1,0 ו-0,1.",
  "model": "google_nmt",
  "from_community_srt": "היא משאירה את i כובע ו-j כובע איפה שהם היו, בלי להזיז אותם, כך שהעמודות שלה הם אחד,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "ברגע שתמצא את היפוך הזה, מה שבפועל היית עושה עם מחשב, אתה יכול לפתור את המשוואה שלך על ידי הכפלת המטריצה ההפוכה ב-v.",
  "model": "google_nmt",
  "from_community_srt": "אפס ו-אפס, אחת. ברגע שאתה מוצא את ההופכית, אשר, באופן מעשי אתה עושה עם המחשב שלך, אתה יכול לפתור את המשוואה ע\"י כך שתכפיל את המטריצה ההופכית ב-v.",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "ושוב, מה שזה אומר מבחינה גיאומטרית הוא שאתה משחק את הטרנספורמציה הפוך ובעקבות v.",
  "model": "google_nmt",
  "from_community_srt": "ושוב, מה שזה אומר מבחינה גיאומטרית, זה שאתה משחק עם הטרנספורמציה באופן הפוך,",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "מקרה דטרמיננטי זה שאינו אפס, אשר עבור בחירה אקראית של מטריצה הוא ללא ספק הסביר ביותר, מתכתב עם הרעיון שאם יש לך שני לא ידועים ושתי משוואות, זה כמעט בוודאות המקרה שיש פתרון יחיד יחיד.",
  "model": "google_nmt",
  "from_community_srt": "ובעקבותיו גם עם v. המקרה בו הדטרמיננטה שונה מאפס, הוא מקרה בו בבחירה אקראית של מטריצה יותר יותר מסביר שתקבל אחת כזאת(כלומר, קיים סיכוי רב יותר שתקבל מטריצה שהדטרמיננטה שלה שונה מאפס). זה מתאים לרעיון שיש לך שני נעלמים ו-2 משוואות, זה כמעט לבטח המקרה שיש פיתרון אחד ומיוחד.",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "רעיון זה הגיוני גם בממדים גבוהים יותר, כאשר מספר המשוואות שווה למספר הלא ידועים.",
  "model": "google_nmt",
  "from_community_srt": "הרעיון הזה נהיה הגיוני במימדים גבוהים יותר, כשמספר המשוואות שווה למספר הנעלמים.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "שוב, ניתן לתרגם את מערכת המשוואות לפרשנות הגיאומטרית שבה יש לך טרנספורמציה A וקצת וקטור v, ואתה מחפש את הווקטור x שנוחת על v.",
  "model": "google_nmt",
  "from_community_srt": "שוב, אפשר לפרש את מערכת המשוואות בצורה גיאומטרית כשיש לך טרנספורמציה כלשהי A, ווקטור v כלשהו,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "כל עוד הטרנספורמציה A לא מוחצת את כל המרחב למימד נמוך יותר, כלומר הקובע שלו אינו אפס, תהיה טרנספורמציה הפוכה A, עם התכונה שאם אתה קודם עושה A, אז אתה עושה A הפוך , זה אותו דבר כמו לא לעשות כלום.",
  "model": "google_nmt",
  "from_community_srt": "ואתה מחפש וקטור x שינחת על v. כל עוד הטרנספורמציה לא מוחצת את כל המרחב לתוך מימד נמוך יותר, כלומר, הדטרמיננטה שלה שונה מאפס, אז יהיה לה טרנספורמציה הפוכה, A הפוכה. עם התכונה שאם אתה רוצה קודם להפעיל את A ואז תפעיל את A הפיכה, זה כמו לעשות כלום.",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "וכדי לפתור את המשוואה שלך, אתה רק צריך להכפיל את מטריצת הטרנספורמציה ההפוכה בווקטור v.",
  "model": "google_nmt",
  "from_community_srt": "וכדי לפתור את המשוואה, אתה תצטרך להכפיל את המטריצה של הטרנספורמציה ההפוכה ע\"י הוקטור v.",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "אבל כאשר הקובע הוא אפס, והטרנספורמציה הקשורה למערכת המשוואות דוחסת את החלל למימד קטן יותר, אין הפוך.",
  "model": "google_nmt",
  "from_community_srt": "אבל כאשר הדטרמיננטה היא אפס, אז הטרנספורמציה הקשורה למערכת המשוואות מוחצת את כל המרחב למימד נמוך יותר, אז אין הופכי.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "אתה לא יכול לשחרר קו כדי להפוך אותו למטוס.",
  "model": "google_nmt",
  "from_community_srt": "אתה לא יכול לקחת קו ולהפוך אותו למישור.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "לפחות זה לא משהו שפונקציה יכולה לעשות.",
  "model": "google_nmt",
  "from_community_srt": "לפחות, זה לא משהו שפונקציה יכולה לעשות.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "זה ידרוש הפיכת כל וקטור בודד לקו שלם מלא בוקטורים.",
  "model": "google_nmt",
  "from_community_srt": "זה ידרוש טרנספורמציה לכל וקטור בנפרד לקו שלם שיש בו מלא וקטורים.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "אבל פונקציות יכולות לקחת רק קלט בודד לפלט בודד.",
  "model": "google_nmt",
  "from_community_srt": "אבל פונקציות יכולות לקבל רק קלט אחד ולהוציא פלט אחד.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "באופן דומה, עבור שלוש משוואות ושלושה לא ידועים, לא יהיה הפוך אם הטרנספורמציה המקבילה מוחצת את המרחב התלת-ממדי על המישור, או אפילו אם היא מוחצת אותו על קו או נקודה.",
  "model": "google_nmt",
  "from_community_srt": "באופן דומה, עובר שלוש משוואות ב-3 נעלמים, לא יהיה שום טרנספורמציה הופכית, אם הטרנספורמציה המתאימה מוחצת את המרחב התלת-מימדי לתוך מישור. או אפילו אם היא מוחצת אותו לתוך קו או נקודה.",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "כולם תואמים לקובע של אפס, מכיוון שכל אזור נמחץ למשהו בעל נפח אפס.",
  "model": "google_nmt",
  "from_community_srt": "כל אלה מתאימים לכך שהדטרמיננטה היא אפס, מכיוון שכל איזור נמחץ לתוך משהו שנפחו הוא אפס.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "עדיין יתכן שקיים פתרון גם כאשר אין הפוך.",
  "model": "google_nmt",
  "from_community_srt": "זה עדיין סביר להניח שקיים פיתרון,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "רק שכאשר הטרנספורמציה שלך מוחצת את החלל על, נגיד, קו, אתה צריך להיות בר מזל מספיק שהווקטור v חי איפשהו על הקו הזה.",
  "model": "google_nmt",
  "from_community_srt": "אפילו כשאין מטריצה הופכית, העניין הוא כשטרנספורמציה שלך מוחצת את המרחב לתוך, נגיד לדוגמא, לקו, אם יש לך מספיק מזל, הוקטור הזה,",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "אולי תשים לב שחלק מהמקרים האלה עם אפס חשיבות מרגישים הרבה יותר מגבילים מאחרים.",
  "model": "google_nmt",
  "from_community_srt": "v חי איפשהו על הקו הזה. אתה אולי תבחין שחלק מהמקרים של דטרמיננטות שהן אפס - מרגיש כמו משהו שיותר מגביל אותך ממקרים אחרים.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "בהינתן מטריצה 3x3, למשל, נראה שהרבה יותר קשה לפתרון להתקיים כשהוא מועך חלל על קו בהשוואה לכשהוא מועך דברים למישור, למרות ששניהם הם אפס קובעים.",
  "model": "google_nmt",
  "from_community_srt": "בהינתן מטריצה 3x3, לדוגמא, זה נראה שפחות סביר לכך שיהיה פיתרון כאשר זה מוחץ את המרחב לתוך קו ביחס לאם מוחצים את המרחב לתוך מישור,",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "יש לנו איזו שפה שהיא קצת יותר ספציפית מסתם אמירת אפס קובע.",
  "model": "google_nmt",
  "from_community_srt": "למרות שלשניהם של דטרמיננטה שהיא אפס. יש לנו שפה שהיא יותר מרק להגיד באופן ספיציפי \"דטרמיננטה שווה לאפס\".",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "כאשר הפלט של טרנספורמציה הוא קו, כלומר הוא חד מימדי, אנו אומרים שלטרנספורמציה יש דרגה של אחד.",
  "model": "google_nmt",
  "from_community_srt": "כאשר הפלט של הטרנספורמציה הוא קו, כלומר, הוא חד-מימדי(מימד 1) אנחנו אומרים שלטרנספורמציה של \"דרגה\" של אחת.",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "אם כל הווקטורים נוחתים על מישור דו מימדי כלשהו, אנו אומרים שלטרנספורמציה יש דרגה של שתיים.",
  "model": "google_nmt",
  "from_community_srt": "אם כל הוקטורים נוחתים במישור הדו-מימדי, אנחנו אומרים שלטרנספורמציה של \"דרגה\" של 2.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "אז המילה דרגה פירושה מספר הממדים בפלט של טרנספורמציה.",
  "model": "google_nmt",
  "from_community_srt": "אז המילה \"דרגה\" מתייחסת למספר מימדים במקרה של פלט של טרנספורמציה לדוגמא,",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "לדוגמה, במקרה של מטריצות 2x2, הדרגה השנייה היא הטובה ביותר שיכולה להיות.",
  "model": "google_nmt",
  "from_community_srt": "במקרה של מטריצות 2x2, הדרגה 2 היא הכי גבוהה שיכולה להיות.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "זה אומר שווקטורי הבסיס ממשיכים להתפרש על כל שני ממדי המרחב, והקביעה אינה אפס.",
  "model": "google_nmt",
  "from_community_srt": "הכוונה לכך היא: וקטורי הבסיס ממשיכים לפרוש את כל המרחב הדו-מימדי והדטרמיננטה שונה מאפס.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "אבל עבור מטריצות 3x3, דירוג שני אומר שקרסנו, אבל לא כמו שהם היו מתמוטטים במצב של דרגה אחת.",
  "model": "google_nmt",
  "from_community_srt": "אבל עבור מטריצות 3x3, משמעות הדרגה 2 היא שהתמוטטנו(מדרגה 3 לדרגה 2) אבל לא כמו שהיינו מתמוטטים עבור המצב של דרגה 1.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "אם לטרנספורמציה תלת-ממדית יש דטרמיננט שאינו אפס והפלט שלה ממלא את כל החלל התלת-ממדי, יש לה דרגה של שלוש.",
  "model": "google_nmt",
  "from_community_srt": "אם לטרנספורמציה ב-3 מימדים יש דטרמיננטה שונה מאפס, אז הפלט שלה ימלא את כל המרחב התלת-מימדי, ויש לה את הדרגה של 3.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "הסט הזה של כל הפלטים האפשריים עבור המטריצה שלך, בין אם זה קו, מישור, מרחב תלת מימדי, מה שלא יהיה, נקרא מרחב העמודות של המטריצה שלך.",
  "model": "google_nmt",
  "from_community_srt": "הקבוצות של הפלטים הללו של המטריצה, בין אם זה קו, מישור, מרחב תלת-מימדי, מה שלא יהיה זה נקרא \"מרחב העמודה\" של המטריצה שלך.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "אתה בטח יכול לנחש מאיפה השם הזה בא.",
  "model": "google_nmt",
  "from_community_srt": "אתה בטח יכול לנחש מאיפה השם הזה בא.",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "העמודות של המטריצה שלך אומרות לך היכן נוחתים וקטורי הבסיס, והטווח של וקטורי הבסיס שעברו טרנספורמציה נותן לך את כל הפלטים האפשריים.",
  "model": "google_nmt",
  "from_community_srt": "העמודות הללו במטריצה יאמרו לך איפה וקטורי הבסיס הללו ינחתו, והפרישה וקטורי הבסיס שעברו טרנספורמציה, נותנת לך את כל הפלטים האפשריים.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "במילים אחרות, שטח העמודות הוא טווח העמודות של המטריצה שלך.",
  "model": "google_nmt",
  "from_community_srt": "במילים אחרות, העמודה במרחב היא הפרישה של העמודות של המטריצה שלך.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "אז הגדרה מדויקת יותר של דירוג תהיה שזהו מספר הממדים בחלל העמודה.",
  "model": "google_nmt",
  "from_community_srt": "אז, באופן יותר מדויק, ההגדרה של דרגה תהיה: זהו מספר המימדים בעמודה של המרחב.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "כאשר הדרגה הזו גבוהה ככל האפשר, כלומר היא שווה למספר העמודות, אנו קוראים למטריצה דרגה מלאה.",
  "model": "google_nmt",
  "from_community_srt": "כשהדרגה הזאת היא הכי גבוהה שהיא יכולה להיות, כלומר, היא שווה למספר העמודות,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "שים לב שווקטור האפס תמיד ייכלל במרחב העמודה, שכן טרנספורמציות ליניאריות חייבות לשמור על המקור קבוע במקום.",
  "model": "google_nmt",
  "from_community_srt": "אנחנו קוראים למטריצה הזו שהיא מ\"דרגה מלאה\". שים לב, וקטור האפס תמיד יהיה בעמודה במרחב, מכיוון שהטרנספורמציות הלינארות חייבות לשמור את ראשית הצירים במקום.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "עבור טרנספורמציה של דרגה מלאה, הווקטור היחיד שנוחת במקור הוא וקטור האפס עצמו.",
  "model": "google_nmt",
  "from_community_srt": "אבל טרנספורמציה של דרגה מלאה, הוקטור היחיד שנוחת על הראשית הוא וקטור האפס בעצמו, אבל המטריצות שהן לא דרגה מלאה,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "אבל עבור מטריצות שאינן בדרגה מלאה, שנדחסות למימד קטן יותר, אתה יכול לקבל חבורה שלמה של וקטורים שנוחתים על אפס.",
  "model": "google_nmt",
  "from_community_srt": "אשר מוחצות את המרחב למימד קטן יותר אתה יכול לקבל מספר וקטורים שונים שנוחתים על אפס.",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "אם טרנספורמציה דו-ממדית מוחצת את החלל על קו, למשל, יש קו נפרד בכיוון אחר מלא בוקטורים שנדחסים אל המקור.",
  "model": "google_nmt",
  "from_community_srt": "אם טרנספורמציה בעולם הדו-מימדי מוחצת את המרחב לתוך קו, לדוגמא, יש קו נפרד עבור כל כיוון, המכיל מלא וקטורים שנמחצו לתוך הראשית.",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "אם טרנספורמציה תלת-ממדית מוחצת את החלל על מטוס, יש גם שורה מלאה של וקטורים שנוחתים על המוצא.",
  "model": "google_nmt",
  "from_community_srt": "אם טרנספורמציה תלת-מימדית מוחצת את המרחב לתוך מישור, יש גם קווים מלאים של וקטורים שנוחתים על הראשית",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "אם טרנספורמציה תלת מימדית מוחצת את כל החלל על קו, אז יש מישור שלם מלא בוקטורים שנוחתים על המוצא.",
  "model": "google_nmt",
  "from_community_srt": "אם טרנספורמציות ב-3 מימד מוחצת את כל המרחב לקו, אז יש מישור מלא של וקטורים שנוחתים בראשית.",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "קבוצה זו של וקטורים שנוחתת על המקור נקראת מרחב האפס, או הגרעין של המטריצה שלך.",
  "model": "google_nmt",
  "from_community_srt": "קבוצת הוקטורים שנוחתים בראשית נקראים \"הגרעין\" של המטריצה שלך.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "זה המרחב של כל הוקטורים שהופכים לריק, במובן זה שהם נוחתים על וקטור האפס.",
  "model": "google_nmt",
  "from_community_srt": "זהו המרחב שמלא בוקטורים שהופך לאפס, במובן הזה,",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "במונחים של מערכת המשוואות הליניארית, כאשר v הוא במקרה וקטור האפס, הרווח האפס נותן לך את כל הפתרונות האפשריים למשוואה.",
  "model": "google_nmt",
  "from_community_srt": "הם נוחתים על וקטור האפס. במובן של מערכת משוואות לינאריות, כאשר v  הוא וקטור האפס מרחב האפס נותן לך את כל הפיתרונות האפשריים של המשוואה.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "אז זו סקירה ברמה גבוהה מאוד של איך לחשוב על מערכות ליניאריות של משוואות מבחינה גיאומטרית.",
  "model": "google_nmt",
  "from_community_srt": "ככה שזהו סיקור ברמה מאוד גבוהה על איך לחשוב על מערכת משוואות לינאריות באופן גיאומטרי.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "לכל מערכת יש איזושהי טרנספורמציה ליניארית הקשורה אליה, וכאשר לטרנספורמציה הזו יש הפוך, אתה יכול להשתמש בהיפוך כדי לפתור את המערכת שלך.",
  "model": "google_nmt",
  "from_community_srt": "לכל מערכת יש סוג מסויים של טרנספורמציה לינארית הקשורה אליה איתה, ומתי שהטרספורמציה הזאת יש הופכית, אתה יכול להשתמש בהופכית כדי לפתור את המערכת.",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "אחרת, הרעיון של מרחב עמודות מאפשר לנו להבין מתי קיים פתרון, והרעיון של רווח ריק עוזר לנו להבין איך אוסף כל הפתרונות האפשריים יכול להיראות.",
  "model": "google_nmt",
  "from_community_srt": "אחרת, הרעיון שמרחב העמודה יתן לך להבין מתי הפיתרון בכלל קיים, והרעיון של מרחב האפס שעוזר לך להבין מהי איך יכולה להיראות קבוצת כל הפיתרונות האפשריים.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "שוב, יש הרבה שלא כיסיתי כאן, בעיקר איך לחשב את הדברים האלה.",
  "model": "google_nmt",
  "from_community_srt": "שוב, יש כאן הרבה שלא כיסיתי כאן, באופן הכי ברור, לא כיסיתי איך אפשר לחשב את הדברים הללו.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "הייתי צריך גם להגביל את ההיקף שלי לדוגמאות שבהן מספר המשוואות שווה למספר הלא ידועים.",
  "model": "google_nmt",
  "from_community_srt": "אני הייתי חייב לצמצם את היקף הדוגמאות שלי, כאשר מספר המשוואות שווה למספר הנעלמים.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "אבל המטרה כאן היא לא לנסות ללמד הכל, זה שאתה יוצא עם אינטואיציה חזקה למטריצות הפוכות, מרחב עמודות ומרחב ריק, ושהאינטואיציות האלה הופכות כל למידה עתידית שאתה עושה ליותר פורה.",
  "model": "google_nmt",
  "from_community_srt": "אבל המטרה שלי היא לא ללמד הכל; אלא היא לכך שתצא מכך עם אינטואיציה מאוד חזקה עבור מטריצות הפיכות, עמודה במרחב מרחב הגרעין. והאינטואיציות הללו מאפשרות לכך שתפיק את המימד מלמידה עתידית של נושא זה.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "הסרטון הבא, לפי בקשה פופולרית, יהיה הערת שוליים קצרה על מטריצות לא מרובעות.",
  "model": "google_nmt",
  "from_community_srt": "בסירטון הבא, בגלל הבקשות הרבות, יהיה הערת שוליים קצרה על מטריצות שהן לא ריבועיות.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "ואז אחרי זה, אני אתן לך את ההשקפה שלי לגבי מוצרי נקודות, ומשהו די מגניב שקורה כשאתה צופה בהם באור של טרנספורמציות ליניאריות.",
  "model": "google_nmt",
  "from_community_srt": "ואז, לאחר מכן, אני הולך לדבר על מכפלה סקלרית משהו מאוד מגניב כשאתה מראה אותם תחת האור של טרנספורמציות לינאריות",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]