1
00:00:10,240 --> 00:00:12,556
Comme vous pouvez probablement le constater maintenant, 

2
00:00:12,556 --> 00:00:15,575
l'essentiel de cette série porte sur la compréhension des opérations 

3
00:00:15,575 --> 00:00:18,264
matricielles et vectorielles à travers le prisme plus visuel des 

4
00:00:18,264 --> 00:00:19,340
transformations linéaires.

5
00:00:19,980 --> 00:00:23,797
Cette vidéo ne fait pas exception, décrivant les concepts de matrices inverses, 

6
00:00:23,797 --> 00:00:27,520
d'espace de colonnes, de rang et d'espace nul à travers cette optique.

7
00:00:27,520 --> 00:00:30,989
Attention cependant, je ne vais pas parler des méthodes permettant de calculer 

8
00:00:30,989 --> 00:00:34,240
réellement ces choses, et certains diraient que c'est assez important.

9
00:00:34,840 --> 00:00:38,420
Il existe de nombreuses très bonnes ressources pour apprendre ces méthodes en dehors 

10
00:00:38,420 --> 00:00:42,000
de cette série, les mots-clés élimination gaussienne et forme d'échelon de ligne.

11
00:00:42,540 --> 00:00:44,459
Je pense que l’essentiel de la valeur que je dois 

12
00:00:44,459 --> 00:00:46,340
ajouter ici réside dans la moitié de l’intuition.

13
00:00:46,900 --> 00:00:48,706
De plus, dans la pratique, nous obtenons généralement 

14
00:00:48,706 --> 00:00:50,480
un logiciel pour calculer ces éléments à notre place.

15
00:00:51,500 --> 00:00:53,920
Tout d’abord, quelques mots sur l’utilité de l’algèbre linéaire.

16
00:00:54,300 --> 00:00:57,442
À présent, vous avez déjà une idée de la façon dont il est utilisé pour décrire la 

17
00:00:57,442 --> 00:01:00,661
manipulation de l’espace, ce qui est utile pour des choses comme l’infographie et la 

18
00:01:00,661 --> 00:01:01,040
robotique.

19
00:01:01,500 --> 00:01:04,459
Mais l’une des principales raisons pour lesquelles l’algèbre linéaire est 

20
00:01:04,459 --> 00:01:07,380
plus largement applicable et nécessaire à presque toutes les disciplines 

21
00:01:07,380 --> 00:01:10,460
techniques est qu’elle nous permet de résoudre certains systèmes d’équations.

22
00:01:11,380 --> 00:01:14,440
Quand je parle de système d'équations, je veux dire que vous avez une liste de 

23
00:01:14,440 --> 00:01:17,760
variables, de choses que vous ne connaissez pas, et une liste d'équations les reliant.

24
00:01:18,340 --> 00:01:21,600
Dans de nombreuses situations, ces équations peuvent devenir très compliquées.

25
00:01:22,120 --> 00:01:25,300
Mais si vous avez de la chance, ils pourraient prendre une forme particulière.

26
00:01:26,440 --> 00:01:29,960
Dans chaque équation, la seule chose qui arrive à chaque variable est qu'elle est 

27
00:01:29,960 --> 00:01:33,481
mise à l'échelle par une constante, et la seule chose qui arrive à chacune de ces 

28
00:01:33,481 --> 00:01:36,880
variables mises à l'échelle est qu'elles sont ajoutées les unes aux autres.

29
00:01:37,540 --> 00:01:39,852
Donc pas d'exposants ou de fonctions fantaisistes ou de 

30
00:01:39,852 --> 00:01:42,280
multiplication de deux variables ensemble, des choses comme ça.

31
00:01:43,420 --> 00:01:47,780
La manière typique d’organiser ce type de système spécial d’équations consiste 

32
00:01:47,780 --> 00:01:52,140
à placer toutes les variables à gauche et les constantes persistantes à droite.

33
00:01:53,600 --> 00:01:56,686
Il est également intéressant d'aligner verticalement les variables communes et, 

34
00:01:56,686 --> 00:01:59,404
pour ce faire, vous devrez peut-être ajouter des coefficients nuls chaque 

35
00:01:59,404 --> 00:02:01,940
fois que la variable n'apparaît pas dans l'une des équations.

36
00:02:04,540 --> 00:02:07,240
C'est ce qu'on appelle un système linéaire d'équations.

37
00:02:08,100 --> 00:02:09,639
Vous remarquerez peut-être que cela ressemble 

38
00:02:09,639 --> 00:02:11,180
beaucoup à une multiplication matrice-vecteur.

39
00:02:11,820 --> 00:02:15,349
En fait, vous pouvez regrouper toutes les équations dans une seule 

40
00:02:15,349 --> 00:02:19,089
équation vectorielle dans laquelle vous avez la matrice contenant tous 

41
00:02:19,089 --> 00:02:22,934
les coefficients constants et un vecteur contenant toutes les variables, 

42
00:02:22,934 --> 00:02:26,780
et leur produit matrice-vecteur est égal à un vecteur constant différent.

43
00:02:28,640 --> 00:02:32,878
Nommons cette matrice constante A, désignons le vecteur contenant les 

44
00:02:32,878 --> 00:02:37,480
variables avec un X en gras et appelons le vecteur constant du côté droit V.

45
00:02:38,860 --> 00:02:40,839
C’est plus qu’une simple astuce de notation pour 

46
00:02:40,839 --> 00:02:42,980
écrire notre système d’équations sur une seule ligne.

47
00:02:43,340 --> 00:02:46,780
Cela met en lumière une interprétation géométrique plutôt sympa du problème.

48
00:02:47,620 --> 00:02:50,633
La matrice A correspond à une transformation linéaire, 

49
00:02:50,633 --> 00:02:54,906
donc résoudre Ax est égal à V signifie que nous recherchons un vecteur X qui, 

50
00:02:54,906 --> 00:02:57,920
après avoir appliqué la transformation, atterrit sur V.

51
00:02:59,940 --> 00:03:01,780
Pensez un instant à ce qui se passe ici.

52
00:03:02,060 --> 00:03:05,667
Vous pouvez garder en tête cette idée très compliquée de plusieurs variables 

53
00:03:05,667 --> 00:03:08,992
qui s'entremêlent simplement en pensant à écraser et à transformer 

54
00:03:08,992 --> 00:03:12,600
l'espace et en essayant de déterminer quel vecteur atterrit sur un autre.

55
00:03:13,160 --> 00:03:13,760
Cool, non ?

56
00:03:14,600 --> 00:03:16,661
Pour commencer simple, disons que vous avez un 

57
00:03:16,661 --> 00:03:18,680
système avec deux équations et deux inconnues.

58
00:03:19,000 --> 00:03:21,526
Cela signifie que la matrice A est une matrice 2x2 et 

59
00:03:21,526 --> 00:03:23,960
que V et X sont chacun des vecteurs bidimensionnels.

60
00:03:25,600 --> 00:03:28,979
Maintenant, la façon dont nous réfléchissons aux solutions de cette équation 

61
00:03:28,979 --> 00:03:32,271
dépend du fait que la transformation associée à A écrase tout l'espace 

62
00:03:32,271 --> 00:03:34,905
dans une dimension inférieure, comme une ligne ou un point, 

63
00:03:34,905 --> 00:03:38,153
ou si elle laisse tout s'étendre sur les deux dimensions complètes là 

64
00:03:38,153 --> 00:03:38,900
où il a commencé.

65
00:03:40,320 --> 00:03:44,090
Dans le langage de la dernière vidéo, nous subdivisons les cas 

66
00:03:44,090 --> 00:03:48,040
où A a un déterminant nul et le cas où A a un déterminant non nul.

67
00:03:51,300 --> 00:03:54,240
Commençons par le cas le plus probable, où le déterminant est non nul, 

68
00:03:54,240 --> 00:03:57,720
ce qui signifie que l'espace n'est pas écrasé dans une région de zone nulle.

69
00:03:58,600 --> 00:04:02,457
Dans ce cas, il y aura toujours un et un seul vecteur qui atterrira sur V, 

70
00:04:02,457 --> 00:04:06,160
et vous pourrez le retrouver en jouant la transformation à l'envers.

71
00:04:06,700 --> 00:04:10,272
En suivant où va V lorsque nous rembobinons la bande comme ceci, 

72
00:04:10,272 --> 00:04:13,460
vous trouverez le vecteur x tel que A fois x est égal à V.

73
00:04:15,400 --> 00:04:18,178
Lorsque vous jouez la transformation à l'envers, 

74
00:04:18,178 --> 00:04:21,586
elle correspond en fait à une transformation linéaire distincte, 

75
00:04:21,586 --> 00:04:24,680
communément appelée l'inverse de A, notée A au négatif.

76
00:04:25,360 --> 00:04:27,775
Par exemple, si A était une rotation de 90 degrés dans le sens 

77
00:04:27,775 --> 00:04:30,229
inverse des aiguilles d’une montre, alors l’inverse de A serait 

78
00:04:30,229 --> 00:04:32,760
une rotation de 90 degrés dans le sens des aiguilles d’une montre.

79
00:04:34,320 --> 00:04:38,178
Si A était un cisaillement vers la droite qui pousse j-hat d’une unité vers la droite, 

80
00:04:38,178 --> 00:04:41,016
l’inverse de A serait un cisaillement vers la gauche qui pousse 

81
00:04:41,016 --> 00:04:42,480
j-hat d’une unité vers la gauche.

82
00:04:44,100 --> 00:04:47,067
En général, A inverse est l'unique transformation avec la 

83
00:04:47,067 --> 00:04:49,316
propriété que si vous appliquez d'abord A, 

84
00:04:49,316 --> 00:04:53,480
puis suivez-la avec la transformation A inverse, vous revenez là où vous avez commencé.

85
00:04:54,540 --> 00:04:58,822
L'application d'une transformation après l'autre est capturée algébriquement 

86
00:04:58,822 --> 00:05:03,105
avec la multiplication matricielle, donc la propriété principale de cette transformation 

87
00:05:03,105 --> 00:05:07,340
A inverse est que A inverse fois A est égal à la matrice qui correspond à ne rien faire.

88
00:05:08,200 --> 00:05:11,320
La transformation qui ne fait rien s’appelle la transformation identitaire.

89
00:05:11,780 --> 00:05:15,031
Il laisse i-hat et j-hat chacun là où ils sont, 

90
00:05:15,031 --> 00:05:18,080
immobiles, donc ses colonnes sont 1,0 et 0,1.

91
00:05:19,980 --> 00:05:23,648
Une fois que vous avez trouvé cet inverse, ce que vous feriez en pratique avec un 

92
00:05:23,648 --> 00:05:27,451
ordinateur, vous pouvez résoudre votre équation en multipliant cette matrice inverse 

93
00:05:27,451 --> 00:05:27,720
par v.

94
00:05:29,960 --> 00:05:32,807
Et encore une fois, ce que cela signifie géométriquement, 

95
00:05:32,807 --> 00:05:36,440
c'est que vous jouez la transformation à l'envers et en suivant v.

96
00:05:40,200 --> 00:05:44,249
Ce cas déterminant non nul, qui pour un choix aléatoire de matrice est de loin 

97
00:05:44,249 --> 00:05:48,196
le plus probable, correspond à l'idée que si vous avez deux inconnues et 

98
00:05:48,196 --> 00:05:52,400
deux équations, il est presque certain qu'il existe une seule solution unique.

99
00:05:53,680 --> 00:05:56,506
Cette idée a également du sens dans les dimensions supérieures, 

100
00:05:56,506 --> 00:05:59,200
lorsque le nombre d’équations est égal au nombre d’inconnues.

101
00:05:59,380 --> 00:06:03,856
Encore une fois, le système d'équations peut être traduit en 

102
00:06:03,856 --> 00:06:09,227
interprétation géométrique où vous avez une transformation A et un vecteur v, 

103
00:06:09,227 --> 00:06:12,740
et vous recherchez le vecteur x qui atterrit sur v.

104
00:06:15,740 --> 00:06:19,745
Tant que la transformation A n'écrase pas tout l'espace dans une dimension 

105
00:06:19,745 --> 00:06:22,690
inférieure, ce qui signifie que son déterminant est non nul, 

106
00:06:22,690 --> 00:06:25,006
il y aura une transformation inverse A inverse, 

107
00:06:25,006 --> 00:06:28,916
avec la propriété que si vous faites d'abord A, alors vous faites A inverse. 

108
00:06:28,916 --> 00:06:31,040
, c'est la même chose que ne rien faire.

109
00:06:33,540 --> 00:06:36,613
Et pour résoudre votre équation, il vous suffit de multiplier 

110
00:06:36,613 --> 00:06:39,440
cette matrice de transformation inverse par le vecteur v.

111
00:06:43,500 --> 00:06:47,806
Mais lorsque le déterminant est nul et que la transformation associée au système 

112
00:06:47,806 --> 00:06:52,060
d’équations réduit l’espace à une dimension plus petite, il n’y a pas d’inverse.

113
00:06:52,480 --> 00:06:55,460
Vous ne pouvez pas défaire une ligne pour la transformer en avion.

114
00:06:55,980 --> 00:06:58,060
Au moins, ce n'est pas quelque chose qu'une fonction peut faire.

115
00:06:58,360 --> 00:07:00,601
Cela nécessiterait de transformer chaque vecteur 

116
00:07:00,601 --> 00:07:02,980
individuel en une ligne entière remplie de vecteurs.

117
00:07:03,740 --> 00:07:06,740
Mais les fonctions ne peuvent prendre qu’une seule entrée vers une seule sortie.

118
00:07:08,400 --> 00:07:10,933
De même, pour trois équations et trois inconnues, 

119
00:07:10,933 --> 00:07:14,479
il n'y aura pas d'inverse si la transformation correspondante 

120
00:07:14,479 --> 00:07:17,974
écrase l'espace 3D sur le plan, ou même si elle l'écrase sur 

121
00:07:17,974 --> 00:07:19,140
une droite ou un point.

122
00:07:19,920 --> 00:07:22,138
Tout cela correspond à un déterminant de zéro, 

123
00:07:22,138 --> 00:07:25,160
puisque toute région est écrasée en quelque chose de volume nul.

124
00:07:26,700 --> 00:07:28,879
Il est toujours possible qu'une solution existe 

125
00:07:28,879 --> 00:07:30,640
même s'il n'y a pas d'inverse.

126
00:07:30,720 --> 00:07:34,872
C'est juste que lorsque votre transformation écrase l'espace sur, disons, 

127
00:07:34,872 --> 00:07:39,380
une ligne, vous devez avoir la chance que le vecteur v vive quelque part sur cette ligne.

128
00:07:43,300 --> 00:07:45,545
Vous remarquerez peut-être que certains de ces cas à 

129
00:07:45,545 --> 00:07:48,300
déterminant zéro semblent beaucoup plus restrictifs que d’autres.

130
00:07:48,840 --> 00:07:52,548
Étant donné une matrice 3x3, par exemple, il semble beaucoup plus difficile pour 

131
00:07:52,548 --> 00:07:56,256
une solution d'exister lorsqu'elle écrase l'espace sur une ligne que 

132
00:07:56,256 --> 00:08:00,240
lorsqu'elle écrase les choses sur un plan, même si les deux sont déterminants nuls.

133
00:08:02,600 --> 00:08:06,100
Nous avons un langage un peu plus précis que de simplement dire un déterminant zéro.

134
00:08:06,520 --> 00:08:09,272
Lorsque le résultat d’une transformation est une ligne, 

135
00:08:09,272 --> 00:08:13,500
c’est-à-dire qu’elle est unidimensionnelle, on dit que la transformation a un rang un.

136
00:08:15,140 --> 00:08:18,143
Si tous les vecteurs atterrissent sur un plan bidimensionnel, 

137
00:08:18,143 --> 00:08:20,420
on dit que la transformation a un rang de deux.

138
00:08:22,920 --> 00:08:27,480
Ainsi, le mot rang désigne le nombre de dimensions dans le résultat d’une transformation.

139
00:08:28,400 --> 00:08:32,720
Par exemple, dans le cas de matrices 2x2, le rang deux est le meilleur possible.

140
00:08:33,080 --> 00:08:36,073
Cela signifie que les vecteurs de base continuent de couvrir les 

141
00:08:36,073 --> 00:08:39,020
deux dimensions de l’espace et que le déterminant n’est pas nul.

142
00:08:39,419 --> 00:08:43,073
Mais pour les matrices 3x3, le rang deux signifie que nous nous sommes effondrés, 

143
00:08:43,073 --> 00:08:46,460
mais pas autant qu'ils l'auraient été dans une situation de rang un.

144
00:08:47,240 --> 00:08:50,211
Si une transformation 3D a un déterminant non nul et que 

145
00:08:50,211 --> 00:08:53,340
sa sortie remplit tout l’espace 3D, elle a un rang de trois.

146
00:08:54,520 --> 00:08:57,158
Cet ensemble de toutes les sorties possibles pour votre matrice, 

147
00:08:57,158 --> 00:09:00,203
qu'il s'agisse d'une ligne, d'un plan, d'un espace 3D, 

148
00:09:00,203 --> 00:09:02,720
peu importe, est appelé l'espace colonne de votre matrice.

149
00:09:04,140 --> 00:09:06,280
Vous pouvez probablement deviner d'où vient ce nom.

150
00:09:06,560 --> 00:09:10,936
Les colonnes de votre matrice vous indiquent où atterrissent les vecteurs de base, 

151
00:09:10,936 --> 00:09:15,312
et l'étendue de ces vecteurs de base transformés vous donne toutes les sorties 

152
00:09:15,312 --> 00:09:15,840
possibles.

153
00:09:16,360 --> 00:09:21,140
En d’autres termes, l’espace des colonnes est l’étendue des colonnes de votre matrice.

154
00:09:23,300 --> 00:09:25,938
Une définition plus précise du rang serait donc qu'il 

155
00:09:25,938 --> 00:09:28,940
s'agit du nombre de dimensions dans l'espace des colonnes.

156
00:09:29,940 --> 00:09:32,915
Lorsque ce rang est aussi élevé que possible, c’est-à-dire qu’il 

157
00:09:32,915 --> 00:09:36,120
est égal au nombre de colonnes, nous appelons la matrice rang complet.

158
00:09:38,540 --> 00:09:42,167
Notez que le vecteur zéro sera toujours inclus dans l'espace des colonnes, 

159
00:09:42,167 --> 00:09:45,840
car les transformations linéaires doivent maintenir l'origine fixe en place.

160
00:09:46,900 --> 00:09:49,498
Pour une transformation de rang complet, le seul vecteur 

161
00:09:49,498 --> 00:09:51,960
qui atterrit à l’origine est le vecteur zéro lui-même.

162
00:09:52,460 --> 00:09:54,476
Mais pour les matrices qui ne sont pas de rang complet, 

163
00:09:54,476 --> 00:09:56,312
qui s'écrasent dans une dimension plus petite, 

164
00:09:56,312 --> 00:09:58,760
vous pouvez avoir tout un tas de vecteurs qui atterrissent sur zéro.

165
00:10:01,640 --> 00:10:04,508
Si une transformation 2D écrase l'espace sur une ligne, 

166
00:10:04,508 --> 00:10:07,472
par exemple, il existe une ligne distincte dans une direction 

167
00:10:07,472 --> 00:10:10,580
différente pleine de vecteurs qui sont écrasés sur l'origine.

168
00:10:11,780 --> 00:10:14,132
Si une transformation 3D écrase l'espace sur un plan, 

169
00:10:14,132 --> 00:10:17,620
il existe également une ligne complète de vecteurs qui atterrissent sur l'origine.

170
00:10:20,520 --> 00:10:23,631
Si une transformation 3D écrase tout l'espace sur une ligne, 

171
00:10:23,631 --> 00:10:27,460
alors il y a tout un plan rempli de vecteurs qui atterrissent sur l'origine.

172
00:10:32,800 --> 00:10:37,258
Cet ensemble de vecteurs qui atterrit sur l'origine est appelé l'espace nul, 

173
00:10:37,258 --> 00:10:38,780
ou le noyau de votre matrice.

174
00:10:39,360 --> 00:10:42,015
C'est l'espace de tous les vecteurs qui deviennent nuls, 

175
00:10:42,015 --> 00:10:44,180
dans le sens où ils atterrissent sur le vecteur zéro.

176
00:10:45,680 --> 00:10:49,973
En termes de système linéaire d'équations, lorsque v se trouve être le vecteur zéro, 

177
00:10:49,973 --> 00:10:53,640
l'espace nul vous donne toutes les solutions possibles à l'équation.

178
00:10:56,420 --> 00:10:59,023
Voilà donc un aperçu de très haut niveau de la façon de 

179
00:10:59,023 --> 00:11:01,720
penser géométriquement les systèmes d’équations linéaires.

180
00:11:02,300 --> 00:11:05,549
Chaque système est associé à une sorte de transformation linéaire, 

181
00:11:05,549 --> 00:11:09,624
et lorsque cette transformation a un inverse, vous pouvez utiliser cet inverse pour 

182
00:11:09,624 --> 00:11:10,740
résoudre votre système.

183
00:11:12,280 --> 00:11:17,141
Sinon, l’idée d’espace de colonnes nous permet de comprendre quand une solution existe, 

184
00:11:17,141 --> 00:11:20,953
et l’idée d’espace nul nous aide à comprendre à quoi peut ressembler 

185
00:11:20,953 --> 00:11:23,440
l’ensemble de toutes les solutions possibles.

186
00:11:24,980 --> 00:11:27,926
Encore une fois, il y a beaucoup de choses que je n'ai pas abordées ici, 

187
00:11:27,926 --> 00:11:29,380
notamment comment calculer ces choses.

188
00:11:29,800 --> 00:11:32,408
J'ai également dû limiter mon champ d'application aux exemples 

189
00:11:32,408 --> 00:11:34,760
où le nombre d'équations est égal au nombre d'inconnues.

190
00:11:34,880 --> 00:11:37,561
Mais le but ici n'est pas d'essayer de tout enseigner, 

191
00:11:37,561 --> 00:11:41,051
c'est que vous repartiez avec une forte intuition pour les matrices inverses, 

192
00:11:41,051 --> 00:11:43,775
l'espace colonne et l'espace nul, et que ces intuitions 

193
00:11:43,775 --> 00:11:46,500
rendent tout apprentissage futur que vous faites plus fructueux.

194
00:11:47,660 --> 00:11:49,710
La prochaine vidéo, à la demande générale, sera une 

195
00:11:49,710 --> 00:11:51,880
brève note de bas de page sur les matrices non carrées.

196
00:11:51,880 --> 00:11:54,863
Ensuite, je vais vous donner mon point de vue sur les produits scalaires, 

197
00:11:54,863 --> 00:11:57,362
et quelque chose d'assez cool qui se produit lorsque vous 

198
00:11:57,362 --> 00:11:59,660
les visualisez à la lumière de transformations linéaires.

