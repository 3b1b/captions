[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Як ви, мабуть, уже зрозуміли, основна частина цієї серії присвячена розумінню матричних і векторних операцій через цю більш візуальну призму лінійних перетворень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Це відео не є винятком, описуючи поняття обернених матриць, простору стовпця, рангу та нульового простору через цю призму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Але попереджаю: я не збираюся говорити про методи фактичного обчислення цих речей, і дехто стверджує, що це дуже важливо.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Існує багато дуже хороших ресурсів для вивчення цих методів за межами цієї серії, ключові слова Gaussian elimination і row echelon form.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Я вважаю, що більша частина цінності, яку я маю додати тут, пов’язана з інтуїцією.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Крім того, на практиці ми зазвичай отримуємо програмне забезпечення для обчислення цього за нас.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "Спочатку кілька слів про корисність лінійної алгебри.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics, but one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "Наразі ви вже маєте підказку про те, як її використовують для опису маніпулювання простором, що корисно для таких речей, як комп’ютерна графіка та робототехніка, але одна з головних причин того, що лінійна алгебра має більш широке застосування та необхідна майже для будь-якої технічної дисципліни полягає в тому, що він дозволяє нам розв’язувати певні системи рівнянь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.3,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Коли я кажу про систему рівнянь, я маю на увазі, що у вас є список змінних, речей, яких ви не знаєте, і список рівнянь, які їх пов’язують.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated, but if you're lucky, they might take on a certain special form.",
  "translatedText": "У багатьох ситуаціях ці рівняння можуть бути дуже складними, але якщо вам пощастить, вони можуть прийняти певну особливу форму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.34,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "У кожному рівнянні єдине, що відбувається з кожною змінною, це те, що вона масштабується на певну константу, і єдине, що відбувається з кожною з цих масштабованих змінних, це те, що вони додаються одна до одної.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Тож жодних експонент чи хитромудрих функцій чи множення двох змінних разом тощо.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "Типовий спосіб організувати таку спеціальну систему рівнянь полягає в тому, щоб перекинути всі змінні ліворуч і помістити будь-які затримані константи праворуч.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "Також добре вирівнювати загальні змінні вертикально, і для цього вам може знадобитися додавати деякі нульові коефіцієнти щоразу, коли змінна не відображається в одному з рівнянь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Це називається лінійною системою рівнянь.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Ви могли помітити, що це дуже схоже на множення матриці на вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "Фактично, ви можете об’єднати всі рівняння в одне векторне рівняння, де у вас є матриця, що містить усі постійні коефіцієнти, і вектор, що містить усі змінні, а їхній добуток матриця-вектор дорівнює якомусь різному постійному вектору.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced x, and call the constant vector on the right-hand side v.",
  "translatedText": "Давайте назвемо постійну матрицю A, позначимо вектор, що містить змінні, жирним шрифтом x, а постійний вектор у правій частині назвемо v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "Це більше, ніж просто нотний прийом, щоб записати нашу систему рівнянь в один рядок.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Це проливає світло на досить круту геометричну інтерпретацію проблеми.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals v means we're looking for a vector x which, after applying the transformation, lands on v.",
  "translatedText": "Матриця A відповідає деякому лінійному перетворенню, тому розв’язання Ax дорівнює v означає, що ми шукаємо вектор x, який після застосування перетворення потрапляє на v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Подумайте на мить про те, що тут відбувається.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Ви можете тримати в голові цю справді складну ідею багатьох змінних, які перемішуються одна з одною, просто подумавши про стискання та трансформацію простору та спробувавши з’ясувати, який вектор потрапляє на інший.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Круто, правда?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Для початку припустімо, що у вас є система з двома рівняннями та двома невідомими.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix and v and x are each two-dimensional vectors.",
  "translatedText": "Це означає, що матриця A є матрицею 2x2, а v і x є двовимірними векторами.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "Тепер те, як ми думаємо про розв’язки цього рівняння, залежить від того, чи перетворення, пов’язане з А, перетворює весь простір у нижчий вимір, як-от лінію чи точку, чи воно залишає все, що охоплює повні два виміри, де воно почалося.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "Мовою останнього відео ми поділяємо на випадки, коли A має нульовий визначник, і випадок, коли A має ненульовий визначник.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Почнемо з найбільш вірогідного випадку, коли визначник відмінний від нуля, тобто простір не зміщується в область нульової області.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on v, and you can find it by playing the transformation in reverse.",
  "translatedText": "У цьому випадку завжди буде один і тільки один вектор, який потрапляє на v, і ви можете знайти його, виконавши перетворення у зворотному порядку.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where v goes as we rewind the tape like this, you'll find the vector x such that A times x equals v.",
  "translatedText": "Слідкуючи за тим, куди йде v, коли ми перемотуємо стрічку таким чином, ви знайдете вектор x такий, що A помножене на x дорівнює v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Коли ви відтворюєте перетворення у зворотному напрямку, воно фактично відповідає окремому лінійному перетворенню, яке зазвичай називають оберненим до A, позначаючи A до від’ємного.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Наприклад, якщо A було обертанням проти годинникової стрілки на 90 градусів, то зворотним A було б обертанням за годинниковою стрілкою на 90 градусів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Якби A був зсувом вправо, який штовхає j-hat на одиницю вправо, зворотним до A був би зсув вліво, який штовхає j-hat на одиницю вліво.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "Загалом, зворотне перетворення — це унікальне перетворення з властивістю, що якщо ви спочатку застосували A, а потім додали за ним зворотне перетворення A, ви повернетеся з того місця, з якого почали.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication.",
  "translatedText": "Застосування одного перетворення за іншим фіксується алгебраїчно за допомогою множення матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.54,
  "end": 298.94
 },
 {
  "input": "So the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "Отже, основна властивість цього оберненого перетворення A полягає в тому, що A обернене перетворення, помножене на A, дорівнює матриці, яка відповідає нічогонеробленню.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.42,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "Перетворення, яке нічого не робить, називається перетворенням ідентичності.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "Він залишає i-hat і j-hat кожен там, де вони є, без змін, тому його стовпці 1,0 і 0,1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Як тільки ви знайдете цю обернену матрицю, що на практиці ви зробили б за допомогою комп’ютера, ви можете розв’язати своє рівняння, помноживши цю обернену матрицю на v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "І знову ж таки, що геометрично це означає, що ви граєте в перетворення в зворотному напрямку і слідуєте v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Цей випадок ненульового детермінанта, який для випадкового вибору матриці є найбільш імовірним, відповідає ідеї, що якщо у вас є два невідомих і два рівняння, майже напевно існує єдине унікальне рішення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Ця ідея також має сенс у вищих вимірах, коли кількість рівнянь дорівнює кількості невідомих.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Знову ж таки, систему рівнянь можна перевести в геометричну інтерпретацію, де у вас є деяке перетворення A і деякий вектор v, і ви шукаєте вектор x, який потрапляє на v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "До тих пір, поки перетворення A не тисне весь простір у нижчий вимір, тобто його визначник відмінний від нуля, існуватиме зворотне перетворення A, яке має властивість, що якщо ви спочатку виконуєте A, тоді ви виконуєте зворотне A , це все одно, що нічого не робити.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "І щоб вирішити ваше рівняння, вам просто потрібно помножити цю матрицю зворотного перетворення на вектор v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Але коли визначник дорівнює нулю, а перетворення, пов’язане з системою рівнянь, тисне простір у менший вимір, зворотного немає.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Ви не можете знищити лінію, щоб перетворити її на площину.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "Принаймні це не те, що функція може зробити.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Для цього потрібно було б перетворити кожен окремий вектор у цілу лінію, повну векторів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Але функції можуть приймати лише один вхід до одного виходу.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Подібним чином, для трьох рівнянь і трьох невідомих не буде зворотного, якщо відповідне перетворення тисне тривимірний простір на площину або навіть якщо воно тисне його на лінію чи точку.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Усі вони відповідають нульовому детермінанту, оскільки будь-яка область поміщається в щось із нульовим об’ємом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "Все ще можливо, що рішення існує, навіть якщо немає зворотного.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "Просто коли ваше перетворення здавлює простір, скажімо, на лінію, вам має пощастити, щоб вектор v жив десь на цій лінії.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Ви можете помітити, що деякі з цих випадків нульового детермінанта здаються набагато більш обмеженими, ніж інші.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Враховуючи, наприклад, матрицю 3x3, здається, що розв’язку набагато важче існувати, коли воно здавлює простір на пряму, порівняно з тим, коли воно здавлює речі на площину, навіть якщо обидва вони мають нульовий детермінант.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "У нас є мова, яка є трохи більш конкретною, ніж просто сказати нульовий визначник.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Якщо результатом перетворення є рядок, що означає, що воно є одновимірним, ми говоримо, що перетворення має ранг одиниці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Якщо всі вектори потрапляють на деяку двовимірну площину, ми говоримо, що перетворення має ранг два.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Отже, слово ранг означає кількість вимірів у виході перетворення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank 2 is the best that it can be.",
  "translatedText": "Наприклад, у випадку матриць 2x2 ранг 2 є найкращим, що може бути.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space and the determinant is non-zero.",
  "translatedText": "Це означає, що базисні вектори продовжують охоплювати всі два виміри простору, а визначник відмінний від нуля.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank 2 means that we've collapsed, but not as much as they would have collapsed for a rank 1 situation.",
  "translatedText": "Але для матриць 3x3 ранг 2 означає, що ми зазнали краху, але не так сильно, як вони б зазнали краху за ситуації рангу 1.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of 3.",
  "translatedText": "Якщо 3D-перетворення має ненульовий визначник і його результат заповнює весь 3D-простір, воно має ранг 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Цей набір усіх можливих результатів для вашої матриці, будь то лінія, площина, тривимірний простір тощо, називається простором стовпців вашої матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Ви, мабуть, здогадуєтеся, звідки ця назва.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "Стовпці вашої матриці повідомляють вам, де знаходяться базисні вектори, а діапазон цих трансформованих базисних векторів дає вам усі можливі результати.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "Іншими словами, простір стовпців - це проміжок стовпців вашої матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Отже, більш точним визначенням рангу було б те, що це кількість вимірів у просторі стовпців.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Коли цей ранг максимально високий, тобто він дорівнює кількості стовпців, ми називаємо матрицю повним рангом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice, the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Зауважте, що нульовий вектор завжди буде включено в простір стовпців, оскільки лінійні перетворення повинні тримати початок координат фіксованим.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "Для повного рангового перетворення єдиним вектором, який потрапляє в початок координат, є сам нульовий вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Але для матриць неповного рангу, які хлюпають до меншої розмірності, ви можете мати цілу купу векторів, які потрапляють на нуль.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Наприклад, якщо двовимірне перетворення здавлює простір на лінію, існує окрема лінія в іншому напрямку, повна векторів, які здавлюються на початок координат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Якщо тривимірне перетворення тисне простір на площину, то також є повна лінія векторів, які приземляються на початок координат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Якщо тривимірне перетворення тисне весь простір на пряму, то буде ціла площина, повна векторів, які приземляються на початок координат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Цей набір векторів, який потрапляє в початок координат, називається нульовим простором або ядром вашої матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "Це простір усіх векторів, які стають нульовими, у тому сенсі, що вони потрапляють на нульовий вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "З точки зору лінійної системи рівнянь, коли v є нульовим вектором, нульовий простір дає вам усі можливі рішення рівняння.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high-level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Отже, це дуже високий огляд того, як думати про лінійні системи рівнянь геометрично.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "Кожна система має якесь лінійне перетворення, пов’язане з нею, і коли це перетворення має обернене, ви можете використовувати це обернене перетворення для вирішення вашої системи.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "В іншому випадку ідея простору стовпця дозволяє нам зрозуміти, чи взагалі існує рішення, а ідея нульового простору допомагає нам зрозуміти, як може виглядати набір усіх можливих рішень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Знову ж таки, є багато чого, про що я тут не розповів, особливо про те, як обчислити ці речі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Мені також довелося обмежити свій діапазон прикладами, де кількість рівнянь дорівнює кількості невідомих.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Але тут мета полягає не в тому, щоб намагатися навчити всьому, а в тому, щоб у вас виникла сильна інтуїція щодо обернених матриць, простору стовпців і нульового простору, і щоб ця інтуїція зробила будь-яке майбутнє навчання, яке ви проводите, більш плідним.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "У наступному відео, на прохання багатьох, буде коротка виноска про неквадратні матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Тоді після цього я збираюся дати вам свій погляд на точкові добутки, і щось дуже класне, що відбувається, коли ви розглядаєте їх у світлі лінійних перетворень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.88,
  "end": 718.92
 },
 {
  "input": "See you then!",
  "translatedText": "Побачимось!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.48,
  "end": 719.66
 }
]