1
00:00:04,880 --> 00:00:10,520
Гораздо сложнее задать правильный вопрос, чем ответить на него. - Георг Кантор

2
00:00:10,880 --> 00:00:16,360
Как вы уже смогли догадаться, основная тема в этом видео -
 понимание операций с матрицами и векторами

3
00:00:16,480 --> 00:00:20,040
в более визуальном ключе - через призму линейных преобразований

4
00:00:20,040 --> 00:00:24,020
Это видео не является исключением, ведь здесь мы описываем 
понятия обратных матриц,

5
00:00:24,020 --> 00:00:28,100
пространства столбцов, ранга и линейной оболочки ('нулевого пространства")

6
00:00:28,100 --> 00:00:32,230
Предупреждение: я не буду говорить о методах вычисления этих вещей

7
00:00:33,230 --> 00:00:34,910
несмотря на то, что некоторые посчитают это очень важным.

8
00:00:34,910 --> 00:00:38,940
Есть много хороших ресурсов для
изучения методов вычисления вне этого курса.

9
00:00:38,940 --> 00:00:42,280
Ключевые слова: «Метод Гаусса» и "Треугольная форма" (или "Ступенчатый вид по строкам")

10
00:00:42,280 --> 00:00:46,640
Я думаю, что здесь я могу больше рассказать об интуитивной стороне вопроса.

11
00:00:46,640 --> 00:00:50,940
Кроме того, на практике у нас обычно есть компьютерные программы, для того чтобы все это вычислять.

12
00:00:50,940 --> 00:00:54,460
Во-первых, несколько слов о пользе линейной алгебры

13
00:00:54,460 --> 00:00:57,989
К настоящему времени у вас уже есть подсказка к тому, как это
используется при описании манипуляций с пространством

14
00:00:58,989 --> 00:01:01,559
(а эти операции полезны для таких вещей, как компьютерная графика
и робототехника)

15
00:01:01,559 --> 00:01:05,210
но одна из основных причин большей применимости линейной алгебры,

16
00:01:05,210 --> 00:01:07,829
и того, почему она требуется практически для любой технической специальности,

17
00:01:07,829 --> 00:01:11,490
заключается в том, что она позволяет нам решать некоторые системы
уравнений.

18
00:01:11,490 --> 00:01:15,509
Когда я говорю «система уравнений», я имею в виду вот что. 
У вас есть список переменных

19
00:01:15,509 --> 00:01:16,509
(величины, которые вам неизвестны)

20
00:01:16,509 --> 00:01:18,000
и список уравнений, связывающих их.

21
00:01:18,000 --> 00:01:21,939
Во многих ситуациях эти уравнения могут
становиться очень сложными,

22
00:01:21,939 --> 00:01:26,520
но, если вам повезет, они могут принять один конкретный внешний вид.

23
00:01:26,520 --> 00:01:31,880
Единственное, что происходит с
каждой переменной в уравнении - умножение ее на какую-то константу.

24
00:01:32,880 --> 00:01:36,159
и вот то, что происходит с каждым таким произведением переменной и числа - они складываются между собой

25
00:01:37,209 --> 00:01:43,560
Таким образом, у нас нет никаких экспонент, странных функции, перемножения
нескольких переменных и под.

26
00:01:43,560 --> 00:01:46,649
Типичный способ организации такого рода специальных
систем уравнений

27
00:01:46,649 --> 00:01:50,009
это перебросить все переменные влево

28
00:01:50,009 --> 00:01:52,930
и поместить все отбившиеся константы вправо

29
00:01:52,930 --> 00:01:56,859
Также удобно вертикально выстраивать общие
переменные,

30
00:01:56,859 --> 00:02:00,249
и для этого вам может понадобиться добавить
пару нулевых коэффициентов всякий раз, когда переменная

31
00:02:00,249 --> 00:02:04,950
не появляется ни в одном из уравнений.

32
00:02:04,950 --> 00:02:08,170
Это называется «линейной системой уравнений».

33
00:02:08,170 --> 00:02:11,370
Вы можете заметить, что это очень похоже на
умножение матрицы на вектор.

34
00:02:11,370 --> 00:02:17,190
Вообще, вы можете запаковать все уравнения
вместе в одно векторное уравнение,

35
00:02:17,190 --> 00:02:21,459
где у вас есть матрица, содержащая все
постоянные коэффициенты и вектор, содержащий

36
00:02:21,459 --> 00:02:23,040
все переменные,

37
00:02:23,040 --> 00:02:29,020
и их матрично-векторное произведение равно некоторому
вектору с константами

38
00:02:29,020 --> 00:02:31,319
Назовем эту матрицу с константами буквой A,

39
00:02:31,319 --> 00:02:34,879
обозначим вектор, содержащий переменные буквой x жирным шрифтом со стрелочкой

40
00:02:34,879 --> 00:02:39,030
и назовем вектор с константами в правой части уравнения v.

41
00:02:39,030 --> 00:02:42,370
Возможность разместить целую систему уравнений на одной линии - не просто новая хитрая нотация.

42
00:02:43,549 --> 00:02:47,629
Это проливает свет на довольно крутую геометрическую
интерпретацию нашей задачи.

43
00:02:47,629 --> 00:02:52,910
Матрица А соответствует некоторому линейной
преобразованию. Поэтому решение уравнения 
Ax = v

44
00:02:52,910 --> 00:02:57,470
означает, что мы ищем вектор x, который,
после применения преобразования,

45
00:02:57,470 --> 00:02:58,470
оказывается совпадающим с вектором v

46
00:02:58,470 --> 00:03:02,000
Подумайте немного о том, что происходит здесь.

47
00:03:02,000 --> 00:03:07,129
Вы можете держать в своей голове эту действительно сложную
идею тесной связи нескольких переменных

48
00:03:07,129 --> 00:03:08,129
друг с другом

49
00:03:08,129 --> 00:03:11,769
просто подумав о сплющивании или растягивании
пространства, и попытаться выяснить,

50
00:03:11,769 --> 00:03:13,140
какой вектор окажется на месте другого.

51
00:03:13,140 --> 00:03:14,849
Круто, правда?

52
00:03:14,849 --> 00:03:19,079
Начнем с простого. Скажем, у вас есть система
с двумя уравнениями и двумя неизвестными.

53
00:03:19,079 --> 00:03:21,909
Это означает, что матрица A является матрицей 2x2,

54
00:03:21,909 --> 00:03:24,819
и v и x - два двумерных вектора.

55
00:03:24,819 --> 00:03:28,489
Теперь, то как мы думаем о решениях этого
уравнения

56
00:03:28,489 --> 00:03:31,800
зависит от ответа на следующий вопрос. Что делает преобразование, записываемое матрицей А:

57
00:03:32,000 --> 00:03:35,800
оно сплющивает все пространство в пространство меньшей размерности (например, в точку или линию)?

58
00:03:35,879 --> 00:03:40,780
или же оно оставляет плоскость всех возможных векторов в той же размерности?

59
00:03:40,780 --> 00:03:45,650
На языке последнего видео мы подразделяем
это на два случая:
1 - А имеет нулевой определитель,

60
00:03:45,650 --> 00:03:51,689
2 - А имеет ненулевой определитель

61
00:03:51,689 --> 00:03:55,109
Начнем с наиболее вероятного случая, когда
детерминант отличен от нуля,

62
00:03:55,109 --> 00:03:58,650
т.е. пространство не сплющивается в ноль

63
00:03:58,650 --> 00:04:03,409
В этом случае всегда будет один и
только один вектор, который приземляется на v,

64
00:04:03,409 --> 00:04:07,420
и вы можете найти его, проиграв преобразование
в обратном порядке.

65
00:04:07,420 --> 00:04:10,219
Следуя за тем, куда идет v, когда мы перематываем наше преобразование назад

66
00:04:10,219 --> 00:04:15,900
вы найдете вектор x такой, что A умножить на x равно v.

67
00:04:15,900 --> 00:04:20,500
Когда вы перематываете назад преобразование
это фактически соответствует отдельному линейному преобразованию

68
00:04:21,500 --> 00:04:23,380
Обычно такую трансформацию наывают "обратной к матрице A"

69
00:04:23,380 --> 00:04:25,440
обозначается "A в степени -1"

70
00:04:25,440 --> 00:04:28,640
Например, если A обозначала поворот на 90º против часовой стрелки

71
00:04:28,640 --> 00:04:34,780
то обратной к А будет поворот по часовой стрелке на 90º.

72
00:04:34,780 --> 00:04:38,380
Если A - наклон вправо, который толкает вектор  j на одну единицу вправо.

73
00:04:38,380 --> 00:04:43,090
обратным к а будет наклон влево
который сдвигает j на единицу влево.

74
00:04:43,090 --> 00:04:48,970
В общем случае A обратное является единственным преобразованием
с тем свойством, что если вы сначала примените трансформацию А

75
00:04:49,970 --> 00:04:52,370
затем примените обратную трансформацию к А

76
00:04:52,370 --> 00:04:54,760
вы возвращаетесь туда, откуда вы начали.

77
00:04:54,760 --> 00:04:59,640
Применение одного преобразования за другим
записывается алгебраически с помощью умножения матриц.

78
00:04:59,640 --> 00:05:05,160
поэтому основное свойство этого преобразования A^-1
является то, что A * A^-1

79
00:05:05,160 --> 00:05:08,190
равно преобразованию, которое не делает ничего

80
00:05:08,190 --> 00:05:11,850
Преобразование, которое ничего не делает, называется
«преобразование идентичности».

81
00:05:11,850 --> 00:05:15,060
Он оставляет i и j там же, где они были до этого, не двигает их.

82
00:05:15,060 --> 00:05:20,170
поэтому столбцы такой матрицы равны единице, нулю и нулю.

83
00:05:20,170 --> 00:05:23,600
Когда вы найдете эту обратную матрицу (что на практике,
вы делаете в компьютере)

84
00:05:23,600 --> 00:05:30,040
вы можете решить свое уравнение, умножив
эту обратную матрица на v. 
(Применив свойство ассоциативности умножения)

85
00:05:30,080 --> 00:05:34,600
И снова, геометрически это означает
что вы перематываете преобразование назад,

86
00:05:34,600 --> 00:05:36,600
пристально следя за вектором v

87
00:05:40,550 --> 00:05:44,650
Этот случай с det != 0 (безусловно, самый вероятный, т.к. у случайно взятой матрицы скорее всего

88
00:05:44,650 --> 00:05:46,080
будет именно такое свойство)

89
00:05:46,080 --> 00:05:49,690
соответствует идее, что если у вас есть
две неизвестных и два уравнения,

90
00:05:49,690 --> 00:05:54,160
это почти наверняка, что есть
единственное, уникальное решение.

91
00:05:54,160 --> 00:05:56,190
Эта идея также имеет смысл в более высоких измерениях,

92
00:05:56,190 --> 00:05:59,020
когда число уравнений равно числу
неизвестных.

93
00:05:59,020 --> 00:06:04,130
Опять же, систему уравнений можно перевести
на язык геометрии

94
00:06:04,130 --> 00:06:08,470
Вот у вас есть трансформация, A,

95
00:06:08,470 --> 00:06:09,680
и некоторый вектор, v,

96
00:06:09,680 --> 00:06:16,080
и вы ищете вектор x, который приземляется
на v.

97
00:06:16,080 --> 00:06:20,480
До тех пор пока преобразование А не скукоживает
все пространство в более низкое измерение,

98
00:06:20,480 --> 00:06:22,900
т.к., его определитель отличен от нуля det (A)  != 0

99
00:06:22,900 --> 00:06:26,060
будет обратное преобразование A^-1

100
00:06:26,060 --> 00:06:28,360
с тем свойством, что если вы сначала примените A,

101
00:06:28,360 --> 00:06:30,020
а затем применяете A^-1

102
00:06:30,020 --> 00:06:33,750
это то же самое, что ничего не делать с пространством

103
00:06:33,750 --> 00:06:38,270
И чтобы решить ваше уравнение, вы просто должнв
умножить эту матрицу обратного преобразования

104
00:06:38,270 --> 00:06:43,660
на вектор v.

105
00:06:43,660 --> 00:06:47,610
Но когда определитель равен нулю, а
преобразование, связанное с этой системой

106
00:06:47,610 --> 00:06:48,610
уравнений

107
00:06:48,610 --> 00:06:52,500
схлопывает пространство в меньшую размерность,  то обратного преобразования не существует

108
00:06:52,500 --> 00:06:55,630
Вы не можете раскукожить линию обратно в плоскость.

109
00:06:55,630 --> 00:06:58,490
По крайней мере, это не то, что [любая] функция способна сделать

110
00:06:58,490 --> 00:07:01,060
Для этого тогда бы пришлось преобразовывать каждый отдельный вектор

111
00:07:01,060 --> 00:07:03,860
в целую серию векторов

112
00:07:03,860 --> 00:07:07,860
Но функции только могут сопоставлять один вход одному выходу

113
00:07:07,860 --> 00:07:11,160
Аналогично, для трех уравнений с тремя неизвестными,

114
00:07:11,160 --> 00:07:14,360
не будет обратного преобразования, если соответствующее
преобразование

115
00:07:14,360 --> 00:07:17,030
схлопывает 3D-пространство в плоскость,

116
00:07:17,030 --> 00:07:20,140
или даже если оно схлопывает его в линию или
точку.

117
00:07:20,140 --> 00:07:22,420
Все они соответствуют детерминанту, равному нулю

118
00:07:22,420 --> 00:07:27,120
так как любой кусок пространство плоскости зажат во что-то
с нулевым объемом.

119
00:07:27,120 --> 00:07:31,150
Возможно, существует решение
даже если нет обратного,

120
00:07:31,150 --> 00:07:35,070
это просто, когда ваша трансформация схлопывает
пространство в, например, линию,

121
00:07:35,070 --> 00:07:43,490
вам должно сильно повезти, чтобы вектор v оказался на одной из огромного числа линий.

122
00:07:43,490 --> 00:07:48,870
Вы могли заметить, что некоторые такие случаи с det = 0 на вид имеют гораздо больше ограничений, чем другие.

123
00:07:48,870 --> 00:07:53,400
Например, для матрицы 3x3, кажется что решение очень вряд ли существует,

124
00:07:53,400 --> 00:07:58,190
когда преобразование схлопывает пространство в линию, по сравнению
с плоскостью.

125
00:07:58,190 --> 00:08:02,750
хотя оба они соответствуют условию det = 0

126
00:08:02,750 --> 00:08:06,630
У нас есть некоторый язык, который немного конкретнее
чем просто сказать «нулевой детерминант».

127
00:08:06,630 --> 00:08:10,990
Когда выход преобразования является линией,
что означает одномерность,

128
00:08:10,990 --> 00:08:15,300
мы говорим, что преобразование имеет «ранг»
один.

129
00:08:15,300 --> 00:08:18,170
Если все векторы приземляются на какой-то двумерной плоскости

130
00:08:18,170 --> 00:08:23,060
Мы говорим, что преобразование имеет «ранг»
два.

131
00:08:23,060 --> 00:08:28,470
Таким образом, слово «ранг» означает количество измерений
на выходе преобразования.

132
00:08:28,470 --> 00:08:33,170
Например, в случае 2x2-матриц,
ранг 2 - лучшее, что может быть.

133
00:08:33,170 --> 00:08:37,820
Это означает, что базисные векторы продолжают задавать полное двухмерное векторное пространство

134
00:08:37,820 --> 00:08:39,640
и детерминант отличен от нуля.

135
00:08:39,640 --> 00:08:43,560
Но для матриц 3x3 ранг 2 означает, что мы схлопнулись,

136
00:08:43,560 --> 00:08:47,290
но не настолько, как было бы в
ситуации ранга 1.

137
00:08:47,290 --> 00:08:52,500
Если трехмерное преобразование имеет ненулевой определитель,
а вывод преобразования заполняет все трехмерное пространство,

138
00:08:52,500 --> 00:08:54,650
оно имеет ранг 3.

139
00:08:54,650 --> 00:08:57,210
Этот набор всех возможных выводов для вашей матрицы

140
00:08:57,210 --> 00:09:00,180
будь то линия, плоскость, 3D-пространство, что угодно,

141
00:09:00,180 --> 00:09:04,450
называется «пространством столбцов» вашей матрицы.

142
00:09:04,450 --> 00:09:06,760
Вероятно, вы можете догадаться, откуда это имя
из.

143
00:09:06,760 --> 00:09:11,190
Столбцы вашей матрицы
говорят вам, где лежат основополагающие векторы,

144
00:09:11,190 --> 00:09:15,780
и пространство векторов, задаваемое этими преобразованными базисными векторами дают вам все возможные результаты.

145
00:09:15,780 --> 00:09:22,260
Другими словами, пространство столбцов является векторным пространством, которое задают векторы в столбцах матрицы

146
00:09:22,260 --> 00:09:26,070
Итак, более точное определение ранга
было бы следующее:

147
00:09:26,070 --> 00:09:30,200
это число измерений пространстве столбцов

148
00:09:30,200 --> 00:09:32,360
Когда этот ранг настолько высок, насколько это возможно,

149
00:09:32,360 --> 00:09:38,090
то есть он равен числу столбцов, мы
называем матрицу «полный ранг».

150
00:09:38,090 --> 00:09:42,740
Обратите внимание, что нулевой вектор всегда будет
включен в пространство столбцов,

151
00:09:42,740 --> 00:09:47,040
так как линейные преобразования должны оставлять начало координат на месте

152
00:09:47,040 --> 00:09:51,680
Для преобразования полного ранга единственный вектор,
что окажется начале координат, - это сам нулевой вектор

153
00:09:52,680 --> 00:09:56,430
но для матриц, которые не являются полным рангом,
которые схлопывают пространство до меньшего размерности,

154
00:09:56,430 --> 00:10:02,150
вы можете иметь целую кучу векторов, которые
приземляются в начало координат.

155
00:10:02,150 --> 00:10:05,090
Если двумерное преобразование схлопывает пространство в
прямую,

156
00:10:05,090 --> 00:10:08,300
есть отдельная прямая в другом направлении,

157
00:10:08,300 --> 00:10:11,930
полная векторов, которые схлопнулись к
началу координат

158
00:10:11,930 --> 00:10:14,680
Если 3D-преобразование сжимает пространство в
плоскость,

159
00:10:14,680 --> 00:10:20,800
также существует целая прямая с векторами, которые
попали на начало координат.

160
00:10:20,800 --> 00:10:24,270
Если 3D-преобразование схлопывает все пространство
в линию,

161
00:10:24,270 --> 00:10:33,390
то есть целая плоскость, полная векторов,
что попали в начало координат.

162
00:10:33,390 --> 00:10:37,960
Этот набор векторов, которые попали в начало координат, называется «нулевым пространством» или «линейной оболочкой"

163
00:10:37,960 --> 00:10:39,370
вашей матрицы.

164
00:10:39,370 --> 00:10:42,250
Это пространство всех векторов, которые становятся
нулевыми.

165
00:10:42,250 --> 00:10:45,750
в том смысле, что они приземляются на нулевой вектор.

166
00:10:45,750 --> 00:10:50,310
В терминах линейной системы
уравнения, когда v оказывается нулевым вектором,

167
00:10:50,310 --> 00:10:56,910
нулевое пространство дает вам все
возможные решения уравнения.

168
00:10:56,910 --> 00:10:58,470
Так что это очень высокий уровень обзора

169
00:10:58,470 --> 00:11:02,400
о том, как думать о линейных системах уравнений
геометрически.

170
00:11:02,400 --> 00:11:05,160
Каждая система имеет
связанное с ней линейное преобразование

171
00:11:06,160 --> 00:11:08,150
и когда это
преобразование имеет обратное себе,

172
00:11:08,150 --> 00:11:11,740
вы можете использовать обратное для решения вашей системы.

173
00:11:11,740 --> 00:11:18,200
В противном случае идея пространства столбцов позволяет нам понять, существует ли решение вообще.

174
00:11:18,200 --> 00:11:21,370
и идея нулевого пространства
помогает нам понять, что

175
00:11:21,370 --> 00:11:25,110
как возможные решения могут выглядеть.

176
00:11:25,110 --> 00:11:27,620
Опять же. Есть много всего, о чем я не рассказал.

177
00:11:27,620 --> 00:11:29,560
в первую очередь, как все это вычислить.

178
00:11:29,560 --> 00:11:32,870
Мне также пришлось ограничить сферу охвата примерами, где
число уравнений

179
00:11:32,870 --> 00:11:35,170
равно числу неизвестных.

180
00:11:35,170 --> 00:11:37,480
Но цель здесь - не пытаться научить всему;

181
00:11:37,480 --> 00:11:41,361
Цель -  чтобы вы ушли с
сильной интуицией по поводу обратных матриц, рангов

182
00:11:41,361 --> 00:11:43,300
пространством столбцов и линейной оболочкой

183
00:11:43,300 --> 00:11:47,800
и чтобы эти озарения делают любое ваше дальнейшее обучение
более плодотворным.

184
00:11:47,800 --> 00:11:51,980
Следующее видео, по многочисленным просьбам,
будет краткая сноска о неквадратных матрицах.

185
00:11:51,980 --> 00:11:55,130
Затем, после этого, я попробую вам объяснить поэлементное умножение матриц

186
00:11:55,130 --> 00:11:56,990
и то крутое, что с ним происходит, когда вы это рассматриваете

187
00:11:56,990 --> 00:12:00,550
под углом линейных преобразований.

188
00:12:00,550 --> 00:12:05,570
Увидимся!

