1
00:00:11,143 --> 00:00:15,160
Amint azt valószínűleg mostanra is láthatja, ennek a sorozatnak a nagy része

2
00:00:15,160 --> 00:00:20,040
a mátrix- és vektorműveletek megértése a lineáris transzformációk vizuálisabb lencséjén keresztül.

3
00:00:20,040 --> 00:00:24,760
Ez a videó sem kivétel, és leírja az inverz mátrixok, az

4
00:00:24,760 --> 00:00:28,080
oszloptér, a rang és a nulltér fogalmát ezen a lencsén keresztül.

5
00:00:28,080 --> 00:00:32,000
Figyelmeztetés azonban, hogy nem fogok ezeknek a dolgoknak a tényleges kiszámításának

6
00:00:32,000 --> 00:00:34,920
módszereiről beszélni, és egyesek azt állítják, hogy ez nagyon fontos.

7
00:00:34,920 --> 00:00:38,960
Ezen a sorozaton kívül sok nagyon jó forrás

8
00:00:38,960 --> 00:00:42,440
található ezen módszerek megtanulásához, kulcsszavak Gauss-elimináció és sorlépcsőforma.

9
00:00:42,440 --> 00:00:46,640
Azt hiszem, a legtöbb érték, amit hozzá kell tennem, az intuíció felén van.

10
00:00:46,640 --> 00:00:50,760
Ráadásul a gyakorlatban általában úgyis kapunk olyan szoftvert, amely ezeket a dolgokat kiszámítja helyettünk.

11
00:00:50,760 --> 00:00:54,460
Először néhány szót a lineáris algebra hasznosságáról.

12
00:00:54,460 --> 00:00:58,580
Mostanra már van egy tippje arra vonatkozóan, hogyan használják a tér manipulációjának

13
00:00:58,580 --> 00:01:02,580
leírására, ami hasznos lehet például számítógépes grafikában és robotikában, de az egyik

14
00:01:02,580 --> 00:01:06,920
fő oka annak, hogy a lineáris algebra szélesebb körben alkalmazható, és szinte

15
00:01:06,920 --> 00:01:11,500
bármilyen műszaki tudományághoz szükséges. az, hogy lehetővé tesz bizonyos egyenletrendszerek megoldását.

16
00:01:11,500 --> 00:01:15,500
Amikor azt mondom, hogy egyenletrendszer, arra gondolok, hogy van egy listája a változókról,

17
00:01:15,500 --> 00:01:18,500
olyan dolgokról, amelyeket nem ismer, és egy listája a hozzájuk kapcsolódó egyenletekről.

18
00:01:18,500 --> 00:01:23,600
Sok helyzetben ezek az egyenletek nagyon bonyolultak lehetnek,

19
00:01:23,600 --> 00:01:26,520
de ha szerencséd van, bizonyos speciális formát ölthetnek.

20
00:01:26,520 --> 00:01:31,920
Az egyes egyenleteken belül az egyetlen dolog, ami az egyes változókkal történik,

21
00:01:31,920 --> 00:01:35,740
az az, hogy azokat valamilyen állandóval skálázzák, és az egyetlen dolog,

22
00:01:35,740 --> 00:01:37,700
ami az egyes skálázott változókkal történik, az az, hogy hozzáadódnak egymáshoz.

23
00:01:37,700 --> 00:01:43,560
Tehát nincsenek kitevők vagy képzeletbeli függvények, vagy két változó összeszorzása, ilyesmi.

24
00:01:43,560 --> 00:01:47,820
Az ilyen speciális egyenletrendszerek rendszerezésének tipikus módja az, hogy az összes változót

25
00:01:47,820 --> 00:01:54,020
a bal oldalra helyezzük, az esetleges állandókat pedig a jobb oldalra.

26
00:01:54,020 --> 00:01:57,720
Az is jó, ha függőlegesen sorba rendezzük a gyakori változókat, és ehhez szükség

27
00:01:57,720 --> 00:02:04,940
lehet néhány nulla együtthatóra, amikor a változó nem jelenik meg az egyik egyenletben.

28
00:02:04,940 --> 00:02:08,160
Ezt lineáris egyenletrendszernek nevezzük.

29
00:02:08,160 --> 00:02:11,940
Észreveheti, hogy ez nagyon úgy néz ki, mint a mátrix-vektor szorzás.

30
00:02:11,940 --> 00:02:17,220
Valójában az összes egyenletet összecsomagolhatja egyetlen vektoregyenletbe, ahol az összes

31
00:02:17,220 --> 00:02:21,460
konstans együtthatót tartalmazó mátrix és az összes változót tartalmazó vektor

32
00:02:21,460 --> 00:02:29,020
van, és a mátrix-vektor szorzatuk egy másik konstans vektorral egyenlő.

33
00:02:29,020 --> 00:02:33,940
Nevezzük el az A konstans mátrixot, jelöljük félkövér x-szel a változókat

34
00:02:33,940 --> 00:02:39,020
tartalmazó vektort, és hívjuk meg a jobb oldali konstans vektort v.

35
00:02:39,020 --> 00:02:42,360
Ez több, mint egy jelölési trükk,

36
00:02:42,360 --> 00:02:43,540
amellyel egyenletrendszerünket egy sorba írhatjuk.

37
00:02:43,540 --> 00:02:47,620
A probléma egy elég klassz geometriai értelmezésére világít rá.

38
00:02:47,620 --> 00:02:52,940
Az A mátrix valamilyen lineáris transzformációnak felel meg, így az Ax egyenlő v megoldása

39
00:02:52,940 --> 00:03:00,420
azt jelenti, hogy keresünk egy x vektort, amely a transzformáció alkalmazása után v-re kerül.

40
00:03:00,420 --> 00:03:02,180
Gondolj egy pillanatra, mi történik itt.

41
00:03:02,180 --> 00:03:07,120
Megtarthatja a fejében ezt a nagyon bonyolult elképzelést a több változóról,

42
00:03:07,120 --> 00:03:11,200
amelyek mindegyike keveredik egymással, ha csak a tér szaggatására és

43
00:03:11,200 --> 00:03:12,900
morfondírozására gondol, és megpróbálja kitalálni, melyik vektor kerül a másikba.

44
00:03:12,940 --> 00:03:14,860
Menő, igaz?

45
00:03:14,860 --> 00:03:19,060
Az egyszerű kezdéshez tegyük fel, hogy van egy rendszere két egyenletből és két ismeretlenből.

46
00:03:19,060 --> 00:03:24,780
Ez azt jelenti, hogy az A mátrix 2x2 mátrix, v és x pedig kétdimenziós vektorok.

47
00:03:24,780 --> 00:03:30,240
Az, hogy miként gondolkodunk ennek az egyenletnek a megoldásairól, attól függ, hogy az

48
00:03:30,240 --> 00:03:35,820
A-val kapcsolatos transzformáció az egész teret egy alacsonyabb dimenzióba, például egy vonalba vagy

49
00:03:35,820 --> 00:03:40,780
egy pontba zúzza-e, vagy hagy mindent a teljes két dimenzióra, ahol elkezdődött.

50
00:03:40,780 --> 00:03:45,540
Az utolsó videó nyelvén felosztjuk azokra az esetekre, amikor A-nak nulla determinánsa

51
00:03:45,540 --> 00:03:48,180
van, és arra az esetre, amikor A-nak nullától eltérő determinánsa van.

52
00:03:51,740 --> 00:03:55,460
Kezdjük a legvalószínűbb esettel, ahol a determináns nem nulla, ami azt

53
00:03:55,460 --> 00:03:58,660
jelenti, hogy a tér nem zsugorodik egy nulla területű régióba.

54
00:03:58,660 --> 00:04:03,740
Ebben az esetben mindig csak egy vektor lesz, amely v-re

55
00:04:03,740 --> 00:04:06,940
kerül, és ezt a transzformáció fordított lejátszásával találhatja meg.

56
00:04:06,940 --> 00:04:11,940
Követve, hová megy v, amikor így visszatekerjük a szalagot, az

57
00:04:11,940 --> 00:04:15,900
x vektort úgy találjuk, hogy A szor x egyenlő v-vel.

58
00:04:15,900 --> 00:04:19,780
Ha a transzformációt fordítva játssza le, az valójában egy különálló lineáris transzformációnak

59
00:04:19,780 --> 00:04:25,420
felel meg, amelyet általában A inverzének neveznek, és A-t a negatívnak jelölik.

60
00:04:25,420 --> 00:04:30,440
Például, ha A az óramutató járásával ellentétes irányú elforgatás 90 fokkal,

61
00:04:30,440 --> 00:04:34,780
akkor A fordítottja az óramutató járásával megegyező 90 fokkal való elforgatás.

62
00:04:34,780 --> 00:04:39,200
Ha A jobb irányú nyírás lenne, amely a j-hat egy egységgel jobbra tolja, akkor az

63
00:04:39,200 --> 00:04:44,340
A fordítottja egy bal irányú nyírás lenne, amely a j-hat egy egységgel balra tolja.

64
00:04:44,340 --> 00:04:48,860
Általában az A inverz az az egyedi transzformáció, amelynek tulajdonsága, hogy ha először alkalmazza

65
00:04:48,860 --> 00:04:54,660
az A-t, majd követi az A inverz transzformációt, akkor visszakerül oda, ahol kiindult.

66
00:04:54,660 --> 00:04:59,640
Az egyik transzformációt a másik után alkalmazva algebrai módon rögzítjük mátrixszorzással.

67
00:04:59,640 --> 00:05:05,480
Tehát ennek az A inverz transzformációnak az alapvető tulajdonsága, hogy

68
00:05:05,480 --> 00:05:08,180
A inverz szor A-val egyenlő a semmittevésnek megfelelő mátrixszal.

69
00:05:08,180 --> 00:05:11,840
Azt az átalakulást, amely nem csinál semmit, identitástranszformációnak nevezzük.

70
00:05:11,840 --> 00:05:20,160
Mozdulatlanul hagyja az i-hat és a j-hat értéket, így oszlopai 1,0 és 0,1.

71
00:05:20,160 --> 00:05:24,240
Ha megtalálta ezt az inverzet, amit a gyakorlatban számítógéppel is megtenne,

72
00:05:24,240 --> 00:05:30,120
megoldhatja az egyenletet úgy, hogy ezt az inverz mátrixot megszorozza v-vel.

73
00:05:30,120 --> 00:05:34,400
És még egyszer, ez geometriailag azt jelenti, hogy

74
00:05:34,400 --> 00:05:40,560
fordítva játszod az átalakítást, és követed a v.

75
00:05:40,560 --> 00:05:44,640
Ez a nem nulla determináns eset, amely a mátrix véletlenszerű megválasztása esetén messze

76
00:05:44,640 --> 00:05:49,680
a legvalószínűbb, megfelel annak az elképzelésnek, hogy ha két ismeretlen és két egyenlet

77
00:05:49,680 --> 00:05:54,160
van, akkor szinte biztosan az a helyzet, hogy egyetlen egyedi megoldás létezik.

78
00:05:54,160 --> 00:05:57,780
Ez az elképzelés magasabb dimenziókban is értelmes, amikor

79
00:05:57,780 --> 00:05:58,960
az egyenletek száma megegyezik az ismeretlenek számával.

80
00:05:58,960 --> 00:06:04,360
Az egyenletrendszer ismét lefordítható a geometriai értelmezésre, ahol van

81
00:06:04,360 --> 00:06:11,700
egy A transzformáció és egy v vektor, és

82
00:06:11,700 --> 00:06:16,180
azt az x vektort keressük, amely v-re kerül.

83
00:06:16,180 --> 00:06:20,720
Mindaddig, amíg az A transzformáció nem tömöríti az egész teret egy alacsonyabb dimenzióba, ami azt jelenti,

84
00:06:20,720 --> 00:06:26,060
hogy a determinánsa nem nulla, addig lesz egy inverz A inverz transzformáció, azzal a tulajdonsággal,

85
00:06:26,060 --> 00:06:33,760
hogy ha először megcsinálja A-t, akkor megfordítja az A-t. , ez ugyanaz, mint a semmittevés.

86
00:06:33,760 --> 00:06:38,280
És az egyenlet megoldásához csak meg kell szorozni

87
00:06:38,280 --> 00:06:43,640
a fordított transzformációs mátrixot a v vektorral.

88
00:06:43,640 --> 00:06:47,600
De ha a determináns nulla, és az egyenletrendszerhez kapcsolódó

89
00:06:47,600 --> 00:06:52,520
transzformáció a teret kisebb dimenzióba tömöríti, akkor nincs inverz.

90
00:06:52,520 --> 00:06:56,040
Egy vonalat nem lehet kicsavarni, hogy síkká változzon.

91
00:06:56,040 --> 00:06:58,500
Legalábbis erre egy függvény nem képes.

92
00:06:58,500 --> 00:07:03,880
Ehhez minden egyes vektort egy vektorokkal teli sorrá kell átalakítani.

93
00:07:03,880 --> 00:07:07,720
De a funkciók csak egyetlen bemenetet tudnak egyetlen kimenetre átvinni.

94
00:07:07,720 --> 00:07:13,320
Hasonlóképpen, három egyenlet és három ismeretlen esetében nem lesz

95
00:07:13,320 --> 00:07:18,560
inverz, ha a megfelelő transzformáció a 3D teret a

96
00:07:18,560 --> 00:07:19,880
síkra, vagy akár egy egyenesre vagy pontra zúzza össze.

97
00:07:19,880 --> 00:07:24,200
Ezek mindegyike a nulla determinánsának felel meg, mivel

98
00:07:24,200 --> 00:07:27,140
bármely régió nulla térfogatú valamivé van összenyomva.

99
00:07:27,140 --> 00:07:31,160
Még mindig lehetséges, hogy létezik megoldás akkor is, ha nincs inverz.

100
00:07:31,160 --> 00:07:35,780
Csak arról van szó, hogy amikor a transzformációd helyet zúdít mondjuk egy vonalra, akkor

101
00:07:35,780 --> 00:07:43,540
elég szerencsésnek kell lenned, hogy a v vektor valahol azon a vonalon él.

102
00:07:43,540 --> 00:07:49,020
Észreveheti, hogy ezen nulla meghatározó esetek némelyike sokkal korlátozóbbnak tűnik, mint mások.

103
00:07:49,020 --> 00:07:53,620
Ha például egy 3x3-as mátrixot adunk meg, sokkal nehezebbnek tűnik

104
00:07:53,620 --> 00:07:58,460
egy megoldás létezése, amikor egy vonalra húzza a teret, mint

105
00:07:58,460 --> 00:08:02,780
amikor a dolgokat síkra vágja, pedig mindkettő nulla meghatározó.

106
00:08:02,780 --> 00:08:06,660
Van néhány olyan nyelvezetünk, amely egy kicsit konkrétabb, mint a nulla determináns kimondása.

107
00:08:06,660 --> 00:08:11,300
Ha egy transzformáció kimenete egy vonal, vagyis egydimenziós,

108
00:08:11,300 --> 00:08:15,340
akkor azt mondjuk, hogy a transzformáció rangja egy.

109
00:08:15,340 --> 00:08:19,840
Ha az összes vektor egy kétdimenziós síkon landol,

110
00:08:19,840 --> 00:08:23,100
azt mondjuk, hogy a transzformáció rangja kettő.

111
00:08:23,100 --> 00:08:28,500
Tehát a rang szó a transzformáció kimenetében lévő dimenziók számát jelenti.

112
00:08:28,500 --> 00:08:33,200
Például 2x2-es mátrixok esetén a 2. rang a lehető legjobb.

113
00:08:33,200 --> 00:08:38,340
Ez azt jelenti, hogy a bázisvektorok továbbra is átfogják

114
00:08:38,340 --> 00:08:39,680
a tér két dimenzióját, és a determináns nem nulla.

115
00:08:39,680 --> 00:08:44,580
De a 3x3-as mátrixoknál a 2-es rang azt jelenti, hogy összeestünk,

116
00:08:44,580 --> 00:08:47,320
de nem annyira, mint amennyire 1-es helyzet esetén összeomlottak volna.

117
00:08:47,320 --> 00:08:52,660
Ha egy 3D-s transzformációnak nullától eltérő determinánsa van, és a

118
00:08:52,660 --> 00:08:54,700
kimenete kitölti a teljes 3D-s teret, akkor a rangja 3.

119
00:08:54,700 --> 00:08:59,900
A mátrix összes lehetséges kimenetének ezt a halmazát, legyen az

120
00:08:59,900 --> 00:09:04,480
egyenes, sík, 3D-s tér vagy bármi, a mátrix oszlopterének nevezzük.

121
00:09:04,480 --> 00:09:06,780
Valószínűleg kitalálod, honnan származik ez a név.

122
00:09:06,780 --> 00:09:12,160
A mátrix oszlopai megmondják, hol érnek a bázisvektorok, és ezeknek

123
00:09:12,160 --> 00:09:16,620
a transzformált bázisvektoroknak a spanja megadja az összes lehetséges kimenetet.

124
00:09:16,620 --> 00:09:23,800
Más szóval, az oszloptér a mátrixod oszlopainak fesztávja.

125
00:09:23,800 --> 00:09:28,040
Tehát a rang pontosabb meghatározása az lenne,

126
00:09:28,040 --> 00:09:30,240
ha ez az oszloptérben lévő dimenziók száma.

127
00:09:30,240 --> 00:09:34,840
Ha ez a rang olyan magas, amennyire csak lehet, vagyis

128
00:09:34,840 --> 00:09:37,640
megegyezik az oszlopok számával, akkor a mátrixot teljes rangnak nevezzük.

129
00:09:37,640 --> 00:09:44,040
Figyeljük meg, a nulla vektor mindig benne lesz az oszloptérben,

130
00:09:44,040 --> 00:09:47,060
mivel a lineáris transzformációknak az origót a helyén kell tartaniuk.

131
00:09:47,060 --> 00:09:51,640
Teljes rangú transzformáció esetén az egyetlen vektor, amely

132
00:09:51,640 --> 00:09:52,640
az origóba kerül, maga a nulla vektor.

133
00:09:52,680 --> 00:09:56,720
De a nem teljes rangú mátrixok esetében, amelyek kisebb

134
00:09:56,720 --> 00:10:02,160
dimenzióba süllyednek, egy csomó vektor lehet, amelyek nullára kerülnek.

135
00:10:02,160 --> 00:10:06,760
Ha például egy 2D-s transzformáció teret szaggat egy vonalra, akkor van egy

136
00:10:06,760 --> 00:10:11,920
külön sor egy másik irányban, tele vektorokkal, amelyek az origóba kerülnek.

137
00:10:11,920 --> 00:10:16,460
Ha egy 3D-s transzformáció egy síkra zúzza a teret,

138
00:10:16,460 --> 00:10:20,800
akkor a vektorok teljes sora is az origóba kerül.

139
00:10:20,800 --> 00:10:25,540
Ha egy 3D-s transzformáció az egész teret egy egyenesre préseli, akkor

140
00:10:25,540 --> 00:10:33,380
egy egész sík van tele vektorokkal, amelyek az origóba kerülnek.

141
00:10:33,380 --> 00:10:38,160
Ezt a vektorhalmazt, amely az origóba kerül,

142
00:10:38,160 --> 00:10:39,360
nulltérnek vagy a mátrix kernelének nevezzük.

143
00:10:39,360 --> 00:10:43,760
Ez az összes vektor tere, amely nullává válik,

144
00:10:43,760 --> 00:10:45,740
abban az értelemben, hogy a nulla vektoron landolnak.

145
00:10:45,740 --> 00:10:50,320
A lineáris egyenletrendszer szempontjából, amikor v véletlenül a nulla vektor,

146
00:10:50,360 --> 00:10:56,920
a nulla tér megadja az egyenlet összes lehetséges megoldását.

147
00:10:56,920 --> 00:11:00,920
Tehát ez egy nagyon magas szintű áttekintés arról,

148
00:11:00,920 --> 00:11:02,420
hogyan kell geometriailag gondolkodni a lineáris egyenletrendszerekről.

149
00:11:02,420 --> 00:11:06,980
Minden rendszerhez tartozik valamilyen lineáris transzformáció, és ha ennek a transzformációnak

150
00:11:06,980 --> 00:11:11,720
van inverze, akkor ezt az inverzetet használhatja a rendszer megoldására.

151
00:11:11,720 --> 00:11:18,240
Ellenkező esetben az oszloptér fogalma lehetővé teszi számunkra, hogy megértsük,

152
00:11:18,240 --> 00:11:22,640
mikor létezik megoldás, a nulla tér ötlete pedig segít

153
00:11:22,640 --> 00:11:24,200
megérteni, hogyan nézhet ki az összes lehetséges megoldás halmaza.

154
00:11:24,200 --> 00:11:29,800
Ismét sok mindenre nem tértem ki itt, különösen, hogy hogyan kell kiszámítani ezeket a dolgokat.

155
00:11:29,800 --> 00:11:33,680
Olyan példákra is korlátoznom kellett a hatókörömet, ahol

156
00:11:33,680 --> 00:11:35,200
az egyenletek száma megegyezik az ismeretlenek számával.

157
00:11:35,200 --> 00:11:39,700
De a cél itt nem az, hogy mindent megtanítson, hanem az, hogy

158
00:11:39,700 --> 00:11:44,720
erős intuícióval rendelkezzen az inverz mátrixok, az oszloptér és a nulla tér

159
00:11:44,720 --> 00:11:47,760
tekintetében, és hogy ezek az intuíciók minden jövőbeni tanulást gyümölcsözőbbé tegyenek.

160
00:11:47,800 --> 00:11:52,480
A következő videó, közkívánatra, egy rövid lábjegyzet lesz a nem négyzetes mátrixokról.

161
00:11:52,480 --> 00:11:55,580
Aztán ezek után elmondom a véleményemet a ponttermékekről, és valami nagyon

162
00:11:55,580 --> 00:11:59,440
klassz dologról, ami akkor történik, ha lineáris transzformációk fényében nézed őket.

163
00:11:59,440 --> 00:11:59,940
Majd találkozunk!

