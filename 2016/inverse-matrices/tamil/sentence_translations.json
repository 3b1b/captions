[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "ஒருவேளை நீங்கள் இப்போது சொல்லக்கூடியது போல, இந்த தொடரின் பெரும்பகுதி மேட்ரிக்ஸ் மற்றும் வெக்டார் செயல்பாடுகளை நேரியல் மாற்றங்களின் அதிக காட்சி லென்ஸ் மூலம் புரிந்துகொள்வதாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "இந்த வீடியோ விதிவிலக்கல்ல, அந்த லென்ஸ் மூலம் தலைகீழ் மெட்ரிக்குகள், நெடுவரிசை இடம், தரவரிசை மற்றும் பூஜ்ய இடம் ஆகியவற்றின் கருத்துகளை விவரிக்கிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "ஒரு முன்னறிவிப்பு என்றாலும், உண்மையில் இந்த விஷயங்களைக் கணக்கிடுவதற்கான முறைகளைப் பற்றி நான் பேசப் போவதில்லை, அது மிகவும் முக்கியமானது என்று சிலர் வாதிடுவார்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "இந்தத் தொடருக்கு வெளியே அந்த முறைகளைக் கற்றுக்கொள்வதற்கு நிறைய நல்ல ஆதாரங்கள் உள்ளன, முக்கிய வார்த்தைகள் காசியன் நீக்குதல் மற்றும் வரிசை எச்செலன் வடிவம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "நான் உண்மையில் இங்கே சேர்க்க வேண்டிய மதிப்பின் பெரும்பகுதி உள்ளுணர்வு பாதியில் உள்ளது என்று நினைக்கிறேன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "கூடுதலாக, நடைமுறையில், இந்த விஷயங்களை எப்படியும் எங்களுக்காக கணக்கிடுவதற்கான மென்பொருளைப் பெறுகிறோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "முதலில், நேரியல் இயற்கணிதத்தின் பயன் பற்றி சில வார்த்தைகள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics, but one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "கணினி வரைகலை மற்றும் ரோபாட்டிக்ஸ் போன்ற விஷயங்களுக்குப் பயன்படும் இடத்தின் கையாளுதலை விவரிப்பதில் இது எவ்வாறு பயன்படுத்தப்படுகிறது என்பதற்கான குறிப்பு இப்போது உங்களிடம் உள்ளது, ஆனால் நேரியல் இயற்கணிதம் மிகவும் பரவலாகப் பொருந்தும் மற்றும் எந்தவொரு தொழில்நுட்பத் துறைக்கும் தேவைப்படும் முக்கிய காரணங்களில் ஒன்றாகும். இது சில சமன்பாடு அமைப்புகளை தீர்க்க உதவுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.3,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "சமன்பாடுகளின் அமைப்பு என்று நான் கூறும்போது, உங்களிடம் மாறிகள், உங்களுக்குத் தெரியாத விஷயங்கள் மற்றும் அவை தொடர்பான சமன்பாடுகளின் பட்டியல் ஆகியவை உள்ளன.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated, but if you're lucky, they might take on a certain special form.",
  "translatedText": "பல சூழ்நிலைகளில், அந்த சமன்பாடுகள் மிகவும் சிக்கலானதாக இருக்கும், ஆனால் நீங்கள் அதிர்ஷ்டசாலி என்றால், அவை ஒரு குறிப்பிட்ட சிறப்பு வடிவத்தை எடுக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.34,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "ஒவ்வொரு சமன்பாட்டிற்குள்ளும், ஒவ்வொரு மாறிக்கும் நிகழும் ஒரே விஷயம் அது சில மாறிலிகளால் அளவிடப்படுகிறது, மேலும் அந்த அளவிடப்பட்ட மாறிகள் ஒவ்வொன்றிற்கும் நடக்கும் ஒரே விஷயம் அவை ஒன்றுடன் ஒன்று சேர்க்கப்படும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "எனவே அடுக்குகள் அல்லது ஆடம்பரமான செயல்பாடுகள் அல்லது இரண்டு மாறிகளை ஒன்றாகப் பெருக்குதல், அது போன்ற விஷயங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "இந்த வகையான சிறப்பு சமன்பாடுகளை ஒழுங்கமைப்பதற்கான பொதுவான வழி, அனைத்து மாறிகளையும் இடதுபுறத்தில் எறிந்து, எந்த நீடித்த மாறிலிகளையும் வலதுபுறத்தில் வைப்பதாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "பொதுவான மாறிகளை செங்குத்தாக வரிசைப்படுத்துவது மிகவும் நல்லது, மேலும் அதைச் செய்ய, சமன்பாடுகளில் ஒன்றில் மாறி காண்பிக்காத போதெல்லாம் நீங்கள் சில பூஜ்ஜிய குணகங்களை உள்ளிட வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "இது சமன்பாடுகளின் நேரியல் அமைப்பு என்று அழைக்கப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "இது மேட்ரிக்ஸ்-வெக்டார் பெருக்கல் போல் தெரிகிறது என்பதை நீங்கள் கவனிக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "உண்மையில், நீங்கள் அனைத்து சமன்பாடுகளையும் ஒரே திசையன் சமன்பாட்டில் தொகுக்கலாம், அங்கு உங்களிடம் அனைத்து நிலையான குணகங்கள் மற்றும் அனைத்து மாறிகள் கொண்ட ஒரு திசையன் இருக்கும் அணி உள்ளது, மேலும் அவற்றின் மேட்ரிக்ஸ்-வெக்டர் தயாரிப்பு சில வேறுபட்ட நிலையான வெக்டருக்கு சமம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced x, and call the constant vector on the right-hand side v.",
  "translatedText": "அந்த மாறிலி மேட்ரிக்ஸ் A க்கு பெயரிடுவோம், ஒரு தடித்த முகம் கொண்ட மாறிகளை வைத்திருக்கும் வெக்டரைக் குறிக்கவும், மேலும் வலது புறத்தில் உள்ள மாறிலி திசையனை v என்று அழைக்கவும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "இது நமது சமன்பாடுகளின் அமைப்பை ஒரு வரியில் எழுதுவதற்கான ஒரு குறியீடான தந்திரம் அல்ல.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "இது சிக்கலுக்கான அழகான வடிவியல் விளக்கத்தை வெளிச்சம் போட்டுக் காட்டுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals v means we're looking for a vector x which, after applying the transformation, lands on v.",
  "translatedText": "மேட்ரிக்ஸ் A சில நேர்கோட்டு மாற்றங்களுடன் ஒத்துப்போகிறது, எனவே Ax சமம் v ஐத் தீர்ப்பது என்பது ஒரு திசையன் x ஐத் தேடுகிறோம், இது மாற்றத்தைப் பயன்படுத்திய பிறகு, v இல் இறங்குகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "இங்கே என்ன நடக்கிறது என்று ஒரு கணம் யோசித்துப் பாருங்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "ஸ்க்விஷிங் மற்றும் மார்ஃபிங் இடத்தைப் பற்றி சிந்தித்து, எந்த திசையன் மற்றொன்றில் இறங்குகிறது என்பதைக் கண்டுபிடிக்க முயற்சிப்பதன் மூலம், பல மாறிகள் அனைத்தும் ஒன்றோடொன்று இணைந்திருக்கும் இந்த மிகவும் சிக்கலான யோசனையை உங்கள் தலையில் வைத்திருக்க முடியும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "குளிர், சரியா?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "எளிமையாகத் தொடங்க, உங்களிடம் இரண்டு சமன்பாடுகள் மற்றும் இரண்டு தெரியாதவைகளைக் கொண்ட அமைப்பு உள்ளது என்று வைத்துக்கொள்வோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix and v and x are each two-dimensional vectors.",
  "translatedText": "இதன் பொருள் அணி A என்பது 2x2 அணி மற்றும் v மற்றும் x இரண்டும் இரு பரிமாண திசையன்கள் ஆகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "இப்போது, இந்த சமன்பாட்டிற்கான தீர்வுகளைப் பற்றி நாம் எவ்வாறு சிந்திக்கிறோம் என்பது, A உடன் தொடர்புடைய மாற்றம் ஒரு கோடு அல்லது ஒரு புள்ளி போன்ற அனைத்து இடத்தையும் குறைந்த பரிமாணமாக மாற்றுகிறதா அல்லது அது தொடங்கிய முழு இரு பரிமாணங்களில் அனைத்தையும் விட்டுவிட்டதா என்பதைப் பொறுத்தது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "கடைசி வீடியோவின் மொழியில், A இல் பூஜ்ஜிய நிர்ணயிப்பான் மற்றும் A பூஜ்ஜியமற்ற தீர்மானிப்பான் கொண்ட வழக்குகளாகப் பிரிக்கிறோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "நிர்ணயிப்பானது பூஜ்ஜியமற்றதாக இருக்கும், அதாவது இடம் பூஜ்ஜியப் பகுதிக்குள் நுழைவதில்லை என்று பொருள்படும் சாத்தியக்கூறுடன் ஆரம்பிக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on v, and you can find it by playing the transformation in reverse.",
  "translatedText": "இந்த வழக்கில், எப்போதும் ஒரே ஒரு திசையன் v இல் இறங்கும், மேலும் மாற்றத்தை தலைகீழாக இயக்குவதன் மூலம் அதைக் கண்டறியலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where v goes as we rewind the tape like this, you'll find the vector x such that A times x equals v.",
  "translatedText": "இப்படி டேப்பை ரிவைண்ட் செய்யும்போது v செல்லும் இடத்தைத் தொடர்ந்து, A முறை x vக்கு சமமான திசையன் xஐக் காண்பீர்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "நீங்கள் மாற்றத்தை தலைகீழாக இயக்கும்போது, அது உண்மையில் A இன் தலைகீழ் எனப்படும் ஒரு தனி நேரியல் மாற்றத்திற்கு ஒத்திருக்கிறது, இது எதிர்மறையான ஒன்றைக் குறிக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "எடுத்துக்காட்டாக, A என்பது 90 டிகிரிக்கு எதிரெதிர் திசையில் சுழற்சியாக இருந்தால், A இன் தலைகீழ் 90 டிகிரி கடிகாரச் சுழற்சியாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "A என்பது j-hat ஒரு அலகை வலப்புறமாகத் தள்ளும் வலதுபுறக் கத்தரிப்பாக இருந்தால், A இன் தலைகீழ் j-hat ஒரு அலகை இடதுபுறமாகத் தள்ளும் இடதுபுறக் கத்தரிப்பாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "பொதுவாக, A தலைகீழ் என்பது பண்புடன் கூடிய தனித்துவமான மாற்றமாகும், நீங்கள் முதலில் A ஐப் பயன்படுத்தினால், A தலைகீழ் மாற்றத்துடன் அதைப் பின்பற்றினால், நீங்கள் தொடங்கிய இடத்திலேயே நீங்கள் முடிவடையும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication.",
  "translatedText": "ஒரு உருமாற்றத்தை ஒன்றன் பின் ஒன்றாகப் பயன்படுத்துவது இயற்கணிதப்படி அணி பெருக்கத்துடன் எடுக்கப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.54,
  "end": 298.94
 },
 {
  "input": "So the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "எனவே இந்த மாற்றம் A தலைகீழின் முக்கிய பண்பு என்னவென்றால், A தலைகீழ் முறை A என்பது ஒன்றும் செய்யாமல் இருக்கும் அணிக்கு சமம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.42,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "எதுவும் செய்யாத மாற்றம் அடையாள மாற்றம் எனப்படும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "இது ஐ-ஹாட் மற்றும் ஜே-ஹாட் ஒவ்வொன்றையும் அவை இருக்கும் இடத்தில் அசையாமல் விட்டுவிடுகிறது, எனவே அதன் நெடுவரிசைகள் 1,0 மற்றும் 0,1 ஆகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "இந்த தலைகீழ் கணக்கை நீங்கள் கண்டறிந்ததும், நடைமுறையில் நீங்கள் கணினியில் செய்ய விரும்புகிறீர்கள், இந்த தலைகீழ் மேட்ரிக்ஸை v ஆல் பெருக்குவதன் மூலம் உங்கள் சமன்பாட்டை நீங்கள் தீர்க்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "மீண்டும், இது வடிவியல் ரீதியாக என்ன அர்த்தம் என்றால், நீங்கள் மாற்றத்தை தலைகீழாக இயக்குகிறீர்கள் மற்றும் v ஐப் பின்பற்றுகிறீர்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "இந்த பூஜ்ஜியம் அல்லாத நிர்ணயம் செய்யும் கேஸ், ஒரு சீரற்ற மேட்ரிக்ஸைத் தேர்ந்தெடுப்பதற்கு இது மிகவும் சாத்தியம், உங்களிடம் இரண்டு அறியப்படாதவை மற்றும் இரண்டு சமன்பாடுகள் இருந்தால், அது நிச்சயமாக ஒரே ஒரு தனித்துவமான தீர்வு உள்ளது என்ற கருத்துடன் ஒத்துப்போகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "சமன்பாடுகளின் எண்ணிக்கை தெரியாதவர்களின் எண்ணிக்கைக்கு சமமாக இருக்கும்போது, இந்த யோசனை உயர் பரிமாணங்களிலும் அர்த்தமுள்ளதாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "மீண்டும், சமன்பாடுகளின் அமைப்பை வடிவியல் விளக்கத்திற்கு மொழிபெயர்க்கலாம், அங்கு உங்களுக்கு சில மாற்றம் A மற்றும் சில திசையன் v இருக்கும், மேலும் v இல் இறங்கும் திசையன் x ஐ நீங்கள் தேடுகிறீர்கள்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "மாற்றம் A அனைத்து இடத்தையும் குறைந்த பரிமாணமாக மாற்றாத வரை, அதாவது அதன் நிர்ணயம் பூஜ்ஜியமற்றது, ஒரு தலைகீழ் மாற்றம் A தலைகீழ் இருக்கும், நீங்கள் முதலில் A செய்தால், நீங்கள் A தலைகீழாக செய்வீர்கள். , ஒன்றும் செய்யாமல் இருப்பதும் ஒன்றுதான்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "உங்கள் சமன்பாட்டை தீர்க்க, நீங்கள் அந்த தலைகீழ் உருமாற்ற அணியை வெக்டார் v ஆல் பெருக்க வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "ஆனால் தீர்மானிப்பான் பூஜ்ஜியமாக இருக்கும்போது, சமன்பாடுகளின் அமைப்புடன் தொடர்புடைய மாற்றம் இடத்தை சிறிய பரிமாணமாக மாற்றும் போது, தலைகீழ் எதுவும் இல்லை.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "ஒரு கோட்டை விமானமாக மாற்ற நீங்கள் அதை அவிழ்க்க முடியாது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "குறைந்தபட்சம் அது ஒரு செயல்பாடு செய்யக்கூடிய ஒன்று அல்ல.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "அதற்கு ஒவ்வொரு திசையனையும் திசையன்கள் நிறைந்த முழு வரியாக மாற்ற வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "ஆனால் செயல்பாடுகள் ஒரு வெளியீட்டிற்கு ஒரு உள்ளீட்டை மட்டுமே எடுக்க முடியும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "இதேபோல், மூன்று சமன்பாடுகள் மற்றும் மூன்று தெரியாதவற்றிற்கு, தொடர்புடைய உருமாற்றம் 3D இடத்தை விமானத்தின் மீது செலுத்தினாலும், அல்லது அது ஒரு கோடு அல்லது ஒரு புள்ளியில் அதை அழுத்தினாலும் தலைகீழ் இருக்காது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "அவை அனைத்தும் பூஜ்ஜியத்தை நிர்ணயிக்கும் பொருளுடன் ஒத்துப்போகின்றன, ஏனெனில் எந்தப் பகுதியும் பூஜ்ஜிய அளவு கொண்டதாக மாற்றப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "தலைகீழ் இல்லாவிட்டாலும் ஒரு தீர்வு இருப்பது இன்னும் சாத்தியம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "உங்கள் மாற்றம் ஒரு கோட்டின் மீது இடத்தைப் பிடிக்கும் போது, வெக்டார் v அந்த வரியில் எங்காவது வசிக்கும் அளவுக்கு நீங்கள் அதிர்ஷ்டசாலியாக இருக்க வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "இந்த பூஜ்ஜியத்தை தீர்மானிக்கும் சில நிகழ்வுகள் மற்றவர்களை விட மிகவும் கட்டுப்பாடாக இருப்பதை நீங்கள் கவனிக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "எடுத்துக்காட்டாக, 3x3 மேட்ரிக்ஸ் கொடுக்கப்பட்டால், இரண்டும் பூஜ்ஜியத்தை தீர்மானிக்கும் தன்மை கொண்டவை என்றாலும், ஒரு விமானத்தில் பொருட்களைக் கசக்கும் போது ஒப்பிடும்போது, ஒரு கோட்டில் இடத்தை அழுத்தும் போது ஒரு தீர்வு இருப்பது மிகவும் கடினமாகத் தெரிகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "எங்களிடம் சில மொழிகள் உள்ளன, அது பூஜ்ஜியத்தை தீர்மானிப்பதைக் காட்டிலும் சற்று அதிகமாக உள்ளது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "ஒரு உருமாற்றத்தின் வெளியீடு ஒரு கோடாக இருக்கும் போது, அது ஒரு பரிமாணமானது என்று பொருள்படும் போது, மாற்றம் ஒன்றின் தரவரிசையைக் கொண்டுள்ளது என்று கூறுகிறோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "அனைத்து திசையன்களும் ஏதேனும் இரு பரிமாண விமானத்தில் தரையிறங்கினால், மாற்றம் இரண்டு தரவரிசையில் உள்ளது என்று கூறுகிறோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "எனவே ரேங்க் என்ற வார்த்தையின் அர்த்தம் ஒரு உருமாற்றத்தின் வெளியீட்டில் உள்ள பரிமாணங்களின் எண்ணிக்கை.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank 2 is the best that it can be.",
  "translatedText": "உதாரணமாக, 2x2 மெட்ரிக்குகளின் விஷயத்தில், ரேங்க் 2 தான் சிறந்ததாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space and the determinant is non-zero.",
  "translatedText": "இதன் அர்த்தம், அடிப்படை திசையன்கள் விண்வெளியின் முழு இரு பரிமாணங்களையும் தொடர்ந்து பரப்புகின்றன மற்றும் தீர்மானிப்பான் பூஜ்ஜியம் அல்ல.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank 2 means that we've collapsed, but not as much as they would have collapsed for a rank 1 situation.",
  "translatedText": "ஆனால் 3x3 மெட்ரிக்குகளுக்கு, ரேங்க் 2 என்பது நாம் சரிந்துவிட்டோம் என்று அர்த்தம், ஆனால் ரேங்க் 1 சூழ்நிலையில் அவை சரிந்திருக்காது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of 3.",
  "translatedText": "ஒரு 3D உருமாற்றம் பூஜ்ஜியமற்ற நிர்ணயிப்பைக் கொண்டிருந்தால் மற்றும் அதன் வெளியீடு 3D இடத்தை முழுவதுமாக நிரப்பினால், அது 3 வது இடத்தைப் பெறுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "ஒரு கோடு, விமானம், 3D இடம் என எதுவாக இருந்தாலும், உங்கள் மேட்ரிக்ஸிற்கான அனைத்து சாத்தியமான வெளியீடுகளின் தொகுப்பு, உங்கள் மேட்ரிக்ஸின் நெடுவரிசை இடம் என்று அழைக்கப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "அந்தப் பெயர் எங்கிருந்து வந்தது என்பதை நீங்கள் யூகிக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "உங்கள் மேட்ரிக்ஸின் நெடுவரிசைகள் அடிப்படை திசையன்கள் எங்கு இறங்குகின்றன என்பதைக் கூறுகின்றன, மேலும் அந்த மாற்றப்பட்ட அடிப்படை திசையன்களின் இடைவெளி உங்களுக்கு சாத்தியமான அனைத்து வெளியீடுகளையும் வழங்குகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "வேறு வார்த்தைகளில் கூறுவதானால், நெடுவரிசை இடைவெளி என்பது உங்கள் மேட்ரிக்ஸின் நெடுவரிசைகளின் இடைவெளியாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "எனவே தரவரிசையின் மிகவும் துல்லியமான வரையறை என்பது நெடுவரிசை இடைவெளியில் உள்ள பரிமாணங்களின் எண்ணிக்கையாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "இந்த ரேங்க் எவ்வளவு அதிகமாக இருக்க முடியுமோ, அது நெடுவரிசைகளின் எண்ணிக்கைக்கு சமமாக இருக்கும்போது, மேட்ரிக்ஸை முழு தரவரிசை என்று அழைக்கிறோம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice, the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "கவனிக்கவும், பூஜ்ஜிய திசையன் எப்போதும் நெடுவரிசை இடைவெளியில் சேர்க்கப்படும், ஏனெனில் நேரியல் உருமாற்றங்கள் மூலத்தை நிலையாக வைத்திருக்க வேண்டும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "முழு தரநிலை மாற்றத்திற்கு, தோற்றத்தில் இறங்கும் ஒரே திசையன் பூஜ்ஜிய திசையன் ஆகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "ஆனால் முழு தரவரிசையில் இல்லாத, சிறிய பரிமாணத்திற்குச் செல்லும் மெட்ரிக்குகளுக்கு, பூஜ்ஜியத்தில் தரையிறங்கும் திசையன்களின் மொத்தக் கூட்டத்தை நீங்கள் வைத்திருக்கலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "ஒரு 2D உருமாற்றம் ஒரு கோட்டின் மீது இடத்தை அழுத்தினால், எடுத்துக்காட்டாக, வேறு திசையில் ஒரு தனிக் கோடு உள்ளது, அவை வெக்டார்களால் நிரம்பியுள்ளன.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "ஒரு 3D உருமாற்றம் ஒரு விமானத்தில் இடத்தை அழுத்தினால், தோற்றத்தில் தரையிறங்கும் திசையன்களின் முழு வரிசையும் இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "ஒரு 3D உருமாற்றம் அனைத்து இடத்தையும் ஒரு கோட்டில் கசக்கிவிட்டால், தோற்றத்தில் தரையிறங்கும் திசையன்கள் நிறைந்த ஒரு முழு விமானம் உள்ளது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "தோற்றத்தில் வரும் திசையன்களின் இந்த தொகுப்பு பூஜ்ய இடம் அல்லது உங்கள் மேட்ரிக்ஸின் கர்னல் என்று அழைக்கப்படுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "இது பூஜ்ஜிய திசையன் மீது தரையிறங்கும் அர்த்தத்தில் பூஜ்யமாக மாறும் அனைத்து திசையன்களின் இடமாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "சமன்பாடுகளின் நேரியல் அமைப்பின் அடிப்படையில், v பூஜ்ஜிய வெக்டராக இருக்கும் போது, பூஜ்ய இடம் சமன்பாட்டிற்கு சாத்தியமான அனைத்து தீர்வுகளையும் வழங்குகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high-level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "எனவே சமன்பாடுகளின் நேரியல் அமைப்புகளைப் பற்றி வடிவியல் ரீதியாக எவ்வாறு சிந்திக்க வேண்டும் என்பதற்கான மிக உயர்நிலைக் கண்ணோட்டம் இதுவாகும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "ஒவ்வொரு அமைப்பும் அதனுடன் தொடர்புடைய ஒருவித நேரியல் மாற்றத்தைக் கொண்டுள்ளது, மேலும் அந்த மாற்றம் தலைகீழாக இருக்கும்போது, உங்கள் கணினியைத் தீர்க்க அந்த தலைகீழ் பயன்படுத்தலாம்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "இல்லையெனில், நெடுவரிசை இடத்தின் யோசனை ஒரு தீர்வு இருக்கும் போது நமக்குப் புரிய வைக்கிறது, மேலும் ஒரு பூஜ்ய இடத்தின் யோசனை சாத்தியமான அனைத்து தீர்வுகளின் தொகுப்பு எப்படி இருக்கும் என்பதைப் புரிந்துகொள்ள உதவுகிறது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "மீண்டும், நான் இங்கு குறிப்பிடாத பல விஷயங்கள் உள்ளன, குறிப்பாக இந்த விஷயங்களை எவ்வாறு கணக்கிடுவது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "சமன்பாடுகளின் எண்ணிக்கை தெரியாதவர்களின் எண்ணிக்கைக்கு சமமாக இருக்கும் உதாரணங்களுக்கு எனது நோக்கத்தை மட்டுப்படுத்த வேண்டியிருந்தது.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "ஆனால் இங்கே இலக்கு எல்லாவற்றையும் கற்பிக்க முயற்சிப்பதல்ல, தலைகீழ் மெட்ரிக்குகள், நெடுவரிசை இடம் மற்றும் பூஜ்ய இடைவெளி ஆகியவற்றிற்கான வலுவான உள்ளுணர்வை நீங்கள் கொண்டு வருகிறீர்கள், மேலும் அந்த உள்ளுணர்வுகள் நீங்கள் எந்த எதிர்கால கற்றலையும் அதிக பலனளிக்கின்றன.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "அடுத்த வீடியோ, பிரபலமான கோரிக்கையின்படி, சதுரம் அல்லாத மெட்ரிக்குகளைப் பற்றிய சுருக்கமான அடிக்குறிப்பாக இருக்கும்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "அதன் பிறகு, நான் டாட் தயாரிப்புகளை உங்களுக்கு வழங்கப் போகிறேன், மேலும் நேரியல் மாற்றங்களின் வெளிச்சத்தில் நீங்கள் அவற்றைப் பார்க்கும்போது நடக்கும் அழகான ஒன்றைத் தருகிறேன்.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.88,
  "end": 718.92
 },
 {
  "input": "See you then!",
  "translatedText": "பிறகு பார்க்கலாம்!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.48,
  "end": 719.66
 }
]