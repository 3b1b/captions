[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations. ",
  "translatedText": "您现在可能已经知道，本系列的大部分内容是通过 更直观的线性变换镜头来理解矩阵和向量运算。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens. ",
  "translatedText": "该视频也不例外，通过该镜头描述了逆 矩阵、列空间、秩和零空间的概念。",
  "model": "google_nmt",
  "from_community_srt": "估计你现在也了解到了 这个系列的大部分旨在透过直观的线性变换来理解矩阵与向量运算 这个视频也不例外 我们要透过线性变换来了解逆矩阵、列空间、秩和零空间的概念 预先提醒一下，",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important. ",
  "translatedText": "不过，预先警告一下，我不会谈论实际计算这 些东西的方法，有些人会认为这非常重要。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form. ",
  "translatedText": "有很多非常好的资源可以学习本系列之外的 方法，关键词高斯消去法和行梯队形式。",
  "model": "google_nmt",
  "from_community_srt": "我并不打算讨论计算的方法 即便你们有人会说这部分很重要 这个系列外还有很多优质资源帮助你学习这些方法 例如关键字“高斯消元法”和“行阶梯型” 我认为我最需要在这里添加的是直觉这一部分",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half. ",
  "translatedText": "我认为我实际上必须在这里添加的大部分价值都在于直觉。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway. ",
  "translatedText": "另外，在实践中，我们通常会使用软件来为我们计算这些东西。",
  "model": "google_nmt",
  "from_community_srt": "再说，",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra. ",
  "translatedText": "首先，简单介绍一下线性代数的用处。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics, but one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations. ",
  "translatedText": "到目前为止，您已经了解了如何使用它来描述空间操 纵，这对于计算机图形学和机器人学等领域很有用， 但线性代数更广泛适用并且几乎任何技术学科都需要 它的主要原因之一是它让我们能够求解某些方程组。",
  "model": "google_nmt",
  "from_community_srt": "实践中我们有软件来计算这些东西 首先说一说线性代数的有用之处 目前你已经体会到它能用来描述对空间的操纵 这对计算机图形学和机器人学很有用 但是线性代数在几乎所有技术领域中都有所体现 并被广泛应用的一个主要原因是",
  "n_reviews": 0,
  "start": 54.3,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them. ",
  "translatedText": "当我说方程组时，我的意思是你有一个变量列表， 你不知道的事情，以及与它们相关的方程列表。",
  "model": "google_nmt",
  "from_community_srt": "它能帮助我们求解特定的方程组 当我说“方程组”时 我是在说你有一系列未知量和一系列与之相关的方程 大部分情况下，",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated, but if you're lucky, they might take on a certain special form. ",
  "translatedText": "在很多情况下，这些方程可能会变得非常复杂，但 如果幸运的话，它们可能会呈现某种特殊的形式。",
  "model": "google_nmt",
  "from_community_srt": "这些方程会显得非常复杂 但如果你幸运的话，",
  "n_reviews": 0,
  "start": 78.34,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other. ",
  "translatedText": "在每个方程中，每个变量发生的唯一事 情是它按某个常数缩放，而每个缩放变 量发生的唯一事情是它们相互相加。",
  "model": "google_nmt",
  "from_community_srt": "它们可能具有一个特定的形式 在每一个方程中， 所有的未知量只具有常系数 这些未知量之间只进行加和 也就是说没有幂次，",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that. ",
  "translatedText": "所以没有指数或奇特的函数或将两个变量相乘之类的东西。",
  "model": "google_nmt",
  "from_community_srt": "没有奇怪的函数，",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right. ",
  "translatedText": "组织这种特殊方程组的典型方法是将所有变量放 在左侧，并将任何挥之不去的常数放在右侧。",
  "model": "google_nmt",
  "from_community_srt": "没有未知量间的乘积等等 要整理这一特定的方程组， 一个典型的方法是 将未知量放在等号左边 剩余的常数项放在等号右边 并且将同一个未知量竖直对齐也是极好的 要做到这一点，",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations. ",
  "translatedText": "将公共变量垂直排列也很好，为此，当变量没有出 现在方程之一时，您可能需要添加一些零系数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations. ",
  "translatedText": "这称为线性方程组。",
  "model": "google_nmt",
  "from_community_srt": "你可能需要在某个未知量不出现时添加0这个系数 这就被称为“线性方程组” 你可能注意到了，",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication. ",
  "translatedText": "您可能会注意到，这看起来很像矩阵向量乘法。",
  "model": "google_nmt",
  "from_community_srt": "这和矩阵向量乘法非常相似 实际上，",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector. ",
  "translatedText": "事实上，您可以将所有方程打包成一个向量方程，其 中包含所有常数系数的矩阵和包含所有变量的向量， 并且它们的矩阵向量乘积等于某个不同的常数向量。",
  "model": "google_nmt",
  "from_community_srt": "你可以将所有的方程合并为一个向量方程 这个方程有一个包含所有常数系数的矩阵 一个包含所有未知量的向量 以及它们乘积所得到的一个常数向量 我们称系数矩阵为A 包含未知量的向量为粗体的x",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced x, and call the constant vector on the right-hand side v. ",
  "translatedText": "我们将该常数矩阵命名为 A，用粗体 x 表示 包含变量的向量，并将右侧的常数向量称为 v。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line. ",
  "translatedText": "这不仅仅是一种将方程组 写在一行上的符号技巧。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem. ",
  "translatedText": "它揭示了这个问题的一个非常酷的几何解释。",
  "model": "google_nmt",
  "from_community_srt": "右侧的常数向量为v 这不仅仅是将方程组写进一行的书写技巧 它还阐明了这个问题中优美的几何直观部分 矩阵A代表一种线性变换 所以求解Ax=v意味着我们去寻找一个向量x 使得它在变换后与v重合",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals v means we're looking for a vector x which, after applying the transformation, lands on v. ",
  "translatedText": "矩阵 A 对应于某种线性变换，因此求解 Ax 等于 v 意味 着我们正在寻找一个向量 x，该向量在应用变换后落在 v 上。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment. ",
  "translatedText": "想一想这里发生了什么。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another. ",
  "translatedText": "只需考虑挤压和变形空间并尝试找出哪个向 量落在另一个向量上，你就可以在头脑中记 住多个变量相互混合的非常复杂的想法。",
  "model": "google_nmt",
  "from_community_srt": "思考一下这一过程 你完全可以只考虑对空间变形， 以及变换前后向量的重叠 就将多个未知量相互混合的复杂方程组印入脑中 很酷，",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right? ",
  "translatedText": "很酷，对吧？",
  "model": "google_nmt",
  "from_community_srt": "对吧？",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns. ",
  "translatedText": "首先，假设您有一个包含两个方程和两个未知数的系统。",
  "model": "google_nmt",
  "from_community_srt": "先举一个简单的例子，",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix and v and x are each two-dimensional vectors. ",
  "translatedText": "这意味着矩阵 A 是一个 2x2 矩阵，v 和 x 都是二维向量。",
  "model": "google_nmt",
  "from_community_srt": "你有两个方程和两个未知量构成的方程组 意味着A是一个2×2的矩阵，",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started. ",
  "translatedText": "现在，我们如何思考这个方程的解取决于与 A 相关的变 换是否将所有空间压缩到较低的维度，如一条线或一个点 ，或者它是否让所有东西都跨越它开始的整个二维空间。",
  "model": "google_nmt",
  "from_community_srt": "v和x都是二维向量 现在， 这个方程的解依赖于矩阵A所代表的变换 是将空间挤压到一条线或一个点等低维空间 还是保持像初始状态一样的完整二维空间 用上期视频中的语言来说 我们将它们分为两种情况：A的行列式为零和A的行列式不为零",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant. ",
  "translatedText": "用上一个视频的语言，我们细分为A具有零 行列式的情况和A具有非零行列式的情况。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region. ",
  "translatedText": "让我们从最可能的情况开始，其中行列式不为 零，这意味着空间不会被压缩成零面积区域。",
  "model": "google_nmt",
  "from_community_srt": "先来看看最可能发生的情况， 即A的行列式不为零 此时空间并未被挤压为零面积的区域 在这种情况下，",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on v, and you can find it by playing the transformation in reverse. ",
  "translatedText": "在这种情况下，总会有且只有一个向量落在 v 上，您可以通过反向变换来找到它。",
  "model": "google_nmt",
  "from_community_srt": "有且仅有一个向量（在变换后）与v重合 并且你可以通过逆向进行变换来找到这个向量 如同倒带一样，",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where v goes as we rewind the tape like this, you'll find the vector x such that A times x equals v. ",
  "translatedText": "当我们像这样倒带时，沿着 v 的位置，您将找 到向量 x，使得 A 乘以 x 等于 v。",
  "model": "google_nmt",
  "from_community_srt": "通过跟踪v的动向 你就能找到满足Ax=v的向量x 当你逆向进行变换时，",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation commonly called the inverse of A, denoted A to the negative one. ",
  "translatedText": "当你反向执行变换时，它实际上对应于一个单独的线性 变换，通常称为 A 的逆变换，用 A 表示负数。",
  "model": "google_nmt",
  "from_community_srt": "它实际上对应了另一个线性变换 通常被称为“A的逆”， 记为A^(-1) 比如说，",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees. ",
  "translatedText": "例如，如果 A 是逆时针旋转 90 度，那 么 A 的反转就是顺时针旋转 90 度。",
  "model": "google_nmt",
  "from_community_srt": "如果A是逆时针旋转90度的变换 那么A的逆就是顺时针旋转90度的变换 如果A向右剪切的变换，",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left. ",
  "translatedText": "如果 A 是向右剪切，将 j-hat 向右推一个单位，则 A 的逆将是向左剪切，将 j-hat 向左推一个单位。",
  "model": "google_nmt",
  "from_community_srt": "将j帽向右移动一个单位 A的逆就是向左剪切的变换，",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started. ",
  "translatedText": "一般来说，逆 A 是一种独特的变换，其属性是，如果您首先 应用 A，然后使用变换 A 逆，您最终会回到开始的地方。",
  "model": "google_nmt",
  "from_community_srt": "将j帽向左移动一个单位 总的来说， A逆是满足以下性质的唯一变换 首先应用A代表的变换，",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication. ",
  "translatedText": "通过矩阵乘法以代数方式捕获一个又一个变换的应用。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.54,
  "end": 298.94
 },
 {
  "input": "So the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing. ",
  "translatedText": "所以这个变换 A 逆的核心属性是 A 的 逆乘以 A 等于对应于什么都不做的矩阵。",
  "model": "google_nmt",
  "from_community_srt": "再应用A逆代表的变换 你会回到原始状态 两个变换相继作用在代数上体现为矩阵乘法 所以A逆的核心性质在于 A逆乘以A等于一个“什么都不做”的矩阵 这个“什么都不做”的变换被称为“恒等变换”",
  "n_reviews": 0,
  "start": 299.42,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation. ",
  "translatedText": "不执行任何操作的变换称为恒等变换。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1. ",
  "translatedText": "它将 i-hat 和 j-hat 留在原地不动，因此它的列是 1,0 和 0,1。",
  "model": "google_nmt",
  "from_community_srt": "它保持i帽和j帽不变， 所以它的列就是(1, 0)和(0,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v. ",
  "translatedText": "一旦你找到了这个逆矩阵（实际上你可以用计算机来完 成），你可以通过将该逆矩阵乘以 v 来求解方程。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v. ",
  "translatedText": "再说一次，这在几何上意味着你 正在反向进行变换并遵循 v。",
  "model": "google_nmt",
  "from_community_srt": "1) 一旦你找到了A的逆 （实践中你可以用计算机完成） 你就能在两边同乘A的逆矩阵来求解向量方程 这个过程在几何上 就对应于逆向进行变换并跟踪v的动向 随机选一个矩阵，",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution. ",
  "translatedText": "对于随机选择的矩阵来说，这种非零行列式情况是迄今为 止最有可能的情况，它与这样的想法相对应：如果有两个 未知数和两个方程，则几乎可以肯定存在一个唯一解。",
  "model": "google_nmt",
  "from_community_srt": "有很大可能会遇到这一非零行列式的情况 也就是说， 对于两个未知量和两个方程构成的方程组 几乎可以确定它存在唯一解 当方程数目与未知量数目相同时，",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns. ",
  "translatedText": "当方程的数量等于未知数的数量时， 这个想法在更高的维度上也有意义。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v. ",
  "translatedText": "同样，方程组可以转换为几何解释，其中 您有一些变换 A 和一些向量 v，并 且您正在寻找落在 v 上的向量 x。",
  "model": "google_nmt",
  "from_community_srt": "这一思想在高维情况下也有意义 同样地可以给方程组赋予几何意义 也就是你有线性变换A 某个向量v 并且你在寻找向量x，",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing. ",
  "translatedText": "只要变换 A 不会将所有空间压缩到较低的维度，这意味着它的行列式 不为零，就会存在逆变换 A inverse，其属性是如果您先执行 A，然后执行 A inverse ，这与什么都不做是一样的。",
  "model": "google_nmt",
  "from_community_srt": "在变换后与v重合 只要变换A不将空间压缩到一个更低的维度上 也就是它的行列式不为零 那它就存在逆变换 - A逆 使得应用A变换再应用A逆变换之后，",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v. ",
  "translatedText": "要解方程，只需将该逆变换 矩阵乘以向量 v 即可。",
  "model": "google_nmt",
  "from_community_srt": "结果与恒等变换无异 要想求解方程，",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse. ",
  "translatedText": "但是，当行列式为零时，并且与方程组相关的变 换将空间压缩为更小的维度，则不存在逆矩阵。",
  "model": "google_nmt",
  "from_community_srt": "你只需要将A逆与向量v相乘即可 但是当行列式为零时 与这个方程组相关的变换将空间压缩到更低的维度上 此时没有逆变换 你不能将一条线“解压缩”为一个平面 至少这不是一个函数能做的 这样就会要求将一个单独的向量变换为一整条线的向量",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane. ",
  "translatedText": "你无法通过压扁一条线来将其变成平面。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do. ",
  "translatedText": "至少这不是函数可以做到的事情。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors. ",
  "translatedText": "这需要将每个单独的向量转换为一整行向量。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output. ",
  "translatedText": "但函数只能将单个输入传递到单个输出。",
  "model": "google_nmt",
  "from_community_srt": "但是函数只能将一个输入变换为一个输出 类似地，",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point. ",
  "translatedText": "类似地，对于三个方程和三个未知数，如果相应的 变换将 3D 空间压缩到平面上，或者即使将其 压缩到一条线或一个点上，也不会出现逆矩阵。",
  "model": "google_nmt",
  "from_community_srt": "对于三个方程和三个未知量 如果变换将三维空间压缩为一个平面， 甚至是一条直线或一个点，",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume. ",
  "translatedText": "这些都对应于行列式为零，因为任何 区域都会被压缩成体积为零的东西。",
  "model": "google_nmt",
  "from_community_srt": "那么它也没有逆变换 它们都对应行列式为零的情况，",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse. ",
  "translatedText": "即使没有逆矩阵，解仍然可能存在。",
  "model": "google_nmt",
  "from_community_srt": "因为此时所有区域都被压缩到零体积 即便不存在逆变换， 解仍然可能存在 比如说，",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line. ",
  "translatedText": "只是当你的变换将空间压缩到一条线上时，你必须 足够幸运，向量 v 位于该线上的某个位置。",
  "model": "google_nmt",
  "from_community_srt": "一个变换将空间压缩为一条直线 你得足够幸运，",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others. ",
  "translatedText": "您可能会注意到，其中一些零行列式案例感觉比其他案例更具限制性。",
  "model": "google_nmt",
  "from_community_srt": "让向量v恰好处于这条直线上 你可能注意到一些零行列式的情况比其他的更加严格 比如说一个3×3的矩阵 当它将空间压缩为一条直线时，",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant. ",
  "translatedText": "例如，给定一个 3x3 矩阵，当将空间压缩到一条 线上时，与将事物压缩到一个平面上时相比，解决方案 的存在似乎要困难得多，即使这两者都是零行列式。",
  "model": "google_nmt",
  "from_community_srt": "与平面相比， 解存在的难度更高了 即使这两种情况下行列式均为零 除了零行列式之外，",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant. ",
  "translatedText": "我们有一些比仅仅说零行列式更具体的语言。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one. ",
  "translatedText": "当变换的输出是一条线（意味着它是 一维）时，我们说变换的秩为 1。",
  "model": "google_nmt",
  "from_community_srt": "我们还有特定术语来描述它们 当变换的结果为一条直线时，",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two. ",
  "translatedText": "如果所有向量都落在某个二维平 面上，我们就说变换的秩为二。",
  "model": "google_nmt",
  "from_community_srt": "也就是说结果是一维的 我们称这个变换的秩为1 如果变换后的向量落在某个二维平面上 我们称这个变换的秩为2 所以说“秩”代表着变换后空间的维数 比如说对于2×2的矩阵，",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation. ",
  "translatedText": "因此，“排名”一词表示转换输出中的维数。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank 2 is the best that it can be. ",
  "translatedText": "例如，对于 2x2 矩阵，等级 2 是最好的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space and the determinant is non-zero. ",
  "translatedText": "这意味着基向量继续跨越整个二 维空间，并且行列式不为零。",
  "model": "google_nmt",
  "from_community_srt": "它的秩最大为2 意味着基向量仍旧能张成整个二维空间 并且矩阵的行列式不为零 但是对于3×3的矩阵，",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank 2 means that we've collapsed, but not as much as they would have collapsed for a rank 1 situation. ",
  "translatedText": "但对于 3x3 矩阵，2 级意味着我们已经 崩溃了，但没有 1 级情况下崩溃的那么多。",
  "model": "google_nmt",
  "from_community_srt": "秩为2意味着空间被压缩了 但是和秩为1的情况相比，",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of 3. ",
  "translatedText": "如果 3D 变换具有非零行列式并且其输出 填充所有 3D 空间，则其等级为 3。",
  "model": "google_nmt",
  "from_community_srt": "压缩并不是那么严重 如果一个三维变换的行列式不为零，",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix. ",
  "translatedText": "矩阵的所有可能输出的集合，无论是直线、平面 、3D 空间还是其他，都称为矩阵的列空间。",
  "model": "google_nmt",
  "from_community_srt": "变换结果仍旧充满整个三维空间 那么它的秩为3 不管是一条直线、一个平面还是三维空间等，",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from. ",
  "translatedText": "你大概能猜到这个名字的由来。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs. ",
  "translatedText": "矩阵的列告诉您基向量落在哪里，而这些变换 后的基向量的跨度给出了所有可能的输出。",
  "model": "google_nmt",
  "from_community_srt": "所有可能的变换结果的集合 被称为矩阵的“列空间” 你大概也能猜到这个名字从哪来了 矩阵的列告诉你基向量变换后的位置 这些变换后的基向量张成的空间就是所有可能的变换结果 换句话说，",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix. ",
  "translatedText": "换句话说，列空间是矩阵列的跨度。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space. ",
  "translatedText": "因此，排名的更精确定义是 它是列空间中的维度数。",
  "model": "google_nmt",
  "from_community_srt": "列空间就是矩阵的列所张成的空间 所以更精确的秩的定义是列空间的维数 当秩达到最大值时，",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank. ",
  "translatedText": "当这个秩尽可能高时，意味着它等 于列数，我们将矩阵称为满秩。",
  "model": "google_nmt",
  "from_community_srt": "意味着秩与列数相等 我们称之为“满秩” 注意，",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice, the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place. ",
  "translatedText": "请注意，零向量将始终包含在列空间中， 因为线性变换必须保持原点固定到位。",
  "model": "google_nmt",
  "from_community_srt": "零向量一定会被包含在列空间中 因为线性变换必须保持原点位置不变 对一个满秩变换来说，",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself. ",
  "translatedText": "对于满秩变换，落在原点的 唯一向量是零向量本身。",
  "model": "google_nmt",
  "from_community_srt": "唯一能在变换后落在原点的就是零向量自身 但是对一个非满秩的矩阵来说，",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero. ",
  "translatedText": "但对于非满秩矩阵，即压缩到较小维度的矩 阵，您可以拥有一大堆落在零上的向量。",
  "model": "google_nmt",
  "from_community_srt": "它将空间压缩到一个更低的维度上 也就是说会有一系列向量在变换后成为零向量 举个例子，",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin. ",
  "translatedText": "例如，如果 2D 变换将空间压缩到一条线上，那么在不同方 向上就会有一条单独的线，其中充满了被压缩到原点上的向量。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin. ",
  "translatedText": "如果 3D 变换将空间压缩到平面上， 则还会有一条完整的矢量落在原点上。",
  "model": "google_nmt",
  "from_community_srt": "如果一个二维线性变换将空间压缩到一条直线上 那么沿某个不同方向直线上的所有向量就被压缩到原点 如果一个三维线性变换将空间压缩到一个平面上 同样也会有一整条线上的向量在变换后落在原点 如果一个三维线性变换将空间压缩到一条直线上",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin. ",
  "translatedText": "如果 3D 变换将所有空间压缩到一条线上， 那么就会有一个充满矢量的平面落在原点上。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix. ",
  "translatedText": "这组位于原点的向量称为 零空间，或矩阵的内核。",
  "model": "google_nmt",
  "from_community_srt": "那么就有一整个平面上的向量在变换后落在原点 变换后落在原点的向量的集合 被称为矩阵的“零空间”或“核” 变换后一些向量落在零向量上，",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector. ",
  "translatedText": "这是所有向量都变为空的空间，从某 种意义上说，它们落在零向量上。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation. ",
  "translatedText": "就线性方程组而言，当 v 恰好为零向 量时，零空间给出了方程的所有可能解。",
  "model": "google_nmt",
  "from_community_srt": "而“零空间”正是这些向量所构成的空间 对线性方程组来说，",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high-level overview of how to think about linear systems of equations geometrically. ",
  "translatedText": "这是如何从几何角度思考线性 方程组的非常高层次的概述。",
  "model": "google_nmt",
  "from_community_srt": "当向量v恰好为零向量时 零空间给出的就是这个向量方程所有可能的解 以上就是从几何角度理解线性方程组的一个高水平概述 每个方程组都有一个线性变换与之联系 当逆变换存在时，",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system. ",
  "translatedText": "每个系统都有某种与之相关的线性变换，当该变换有 逆矩阵时，您可以使用该逆矩阵来求解您的系统。",
  "model": "google_nmt",
  "from_community_srt": "你就能用这个逆变换求解方程组 否则，",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like. ",
  "translatedText": "否则，列空间的想法可以让我们了解解决方案 何时存在，而零空间的想法可以帮助我们了 解所有可能的解决方案的集合是什么样的。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things. ",
  "translatedText": "同样，这里还有很多内容我没有介绍，尤其是如何计算这些东西。",
  "model": "google_nmt",
  "from_community_srt": "列空间的概念让我们清楚什么时候存在解 零空间的概念有助于我们理解所有可能的解的集合是什么样的 这里有不少我没有涉及到的内容 尤其是如何进行计算 我还得把范围限制在方程数目与未知量数目相等的情况内",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns. ",
  "translatedText": "我还必须将我的范围限制在方程 数量等于未知数数量的示例上。",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful. ",
  "translatedText": "但这里的目标不是试图教授所有内容，而是让 你对逆矩阵、列空间和零空间有强烈的直觉， 并且这些直觉使你未来的学习更加富有成效。",
  "model": "google_nmt",
  "from_community_srt": "但是我的目标并不是尝试教所有内容 而是让你留下对逆矩阵、列空间和零空间的深刻直观印象 并且让这些直观让你未来学习的收获更加丰硕 应观众要求，",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices. ",
  "translatedText": "应大众要求，下一个视频将是关于非方阵的简短脚注。",
  "model": "google_nmt",
  "from_community_srt": "下期视频是关于非方阵的简短补充内容 在此之后，",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations. ",
  "translatedText": "然后，我将向您介绍我对点积的看法，以及当您在线 性变换下查看它们时会发生的一些非常酷的事情。",
  "model": "google_nmt",
  "from_community_srt": "我会开始讲讲我对点积的看法 并且以线性变换的眼光看待点积时， 会出现有意思的现象 到时候再见！",
  "n_reviews": 0,
  "start": 711.88,
  "end": 718.92
 },
 {
  "input": "See you then! ",
  "translatedText": "回头见！",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.48,
  "end": 719.66
 }
]