[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations. ",
  "translatedText": "جیسا کہ آپ اب تک بتا سکتے ہیں، اس سیریز کا بڑا حصہ لکیری تبدیلیوں کے اس زیادہ بصری لینس کے ذریعے میٹرکس اور ویکٹر آپریشنز کو سمجھنے پر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens. ",
  "translatedText": "یہ ویڈیو کوئی استثناء نہیں ہے، اس عینک کے ذریعے معکوس میٹرکس، کالم اسپیس، رینک، اور خالی جگہ کے تصورات کو بیان کرتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important. ",
  "translatedText": "ایک پیشگوئی اگرچہ، میں اصل میں ان چیزوں کو کمپیوٹنگ کرنے کے طریقوں کے بارے میں بات نہیں کروں گا، اور کچھ لوگ بحث کریں گے کہ یہ بہت اہم ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form. ",
  "translatedText": "اس سیریز سے باہر ان طریقوں کو سیکھنے کے لیے بہت سارے اچھے وسائل موجود ہیں، کلیدی الفاظ Gaussian elemination اور row echelon form۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half. ",
  "translatedText": "میرے خیال میں زیادہ تر قدر جو مجھے اصل میں یہاں شامل کرنی ہے وہ انترجشتھان نصف پر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway. ",
  "translatedText": "اس کے علاوہ، عملی طور پر، ہم عام طور پر ہمارے لیے اس چیز کی گنتی کرنے کے لیے سافٹ ویئر حاصل کرتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra. ",
  "translatedText": "سب سے پہلے، لکیری الجبرا کی افادیت پر چند الفاظ۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics, but one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations. ",
  "translatedText": "اب تک آپ کے پاس پہلے سے ہی اشارہ ہے کہ اس کا استعمال جگہ کی ہیرا پھیری کو بیان کرنے میں کیا جاتا ہے، جو کمپیوٹر گرافکس اور روبوٹکس جیسی چیزوں کے لیے مفید ہے، لیکن ایک اہم وجہ یہ ہے کہ لکیری الجبرا زیادہ وسیع پیمانے پر لاگو ہوتا ہے اور کسی بھی تکنیکی نظم و ضبط کے لیے ضروری ہے۔ یہ ہے کہ یہ ہمیں مساوات کے کچھ نظاموں کو حل کرنے دیتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 54.3,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them. ",
  "translatedText": "جب میں مساوات کا نظام کہتا ہوں تو میرا مطلب ہے کہ آپ کے پاس متغیرات کی فہرست ہے، وہ چیزیں جو آپ نہیں جانتے، اور ان سے متعلق مساوات کی فہرست ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated, but if you're lucky, they might take on a certain special form. ",
  "translatedText": "بہت سے حالات میں، وہ مساوات بہت پیچیدہ ہو سکتی ہیں، لیکن اگر آپ خوش قسمت ہیں، تو وہ ایک خاص خاص شکل اختیار کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 78.34,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other. ",
  "translatedText": "ہر ایک مساوات کے اندر، ہر متغیر کے ساتھ صرف ایک چیز ہوتی ہے کہ اسے کسی مستقل کے ذریعے پیمانہ کیا جاتا ہے، اور ان میں سے ہر ایک متغیر کے ساتھ صرف وہی ہوتا ہے کہ وہ ایک دوسرے میں شامل ہوتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that. ",
  "translatedText": "تو کوئی ایکسپوننٹ یا فینسی فنکشن یا دو متغیرات کو ایک ساتھ ضرب کرنا، اس طرح کی چیزیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right. ",
  "translatedText": "مساوات کے اس طرح کے خصوصی نظام کو ترتیب دینے کا عام طریقہ یہ ہے کہ تمام متغیرات کو بائیں طرف پھینک دیا جائے اور کسی بھی دیرپا مستقل کو دائیں طرف رکھا جائے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations. ",
  "translatedText": "عام متغیرات کو عمودی طور پر ترتیب دینا بھی اچھا ہے، اور ایسا کرنے کے لیے جب بھی متغیر مساوات میں سے کسی ایک میں ظاہر نہیں ہوتا ہے تو آپ کو کچھ صفر کوفیشینٹس ڈالنے کی ضرورت پڑ سکتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations. ",
  "translatedText": "اسے مساوات کا خطی نظام کہا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication. ",
  "translatedText": "آپ دیکھ سکتے ہیں کہ یہ بہت زیادہ میٹرکس ویکٹر ضرب کی طرح لگتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector. ",
  "translatedText": "درحقیقت، آپ تمام مساواتوں کو ایک ساتھ ایک واحد ویکٹر مساوات میں پیک کر سکتے ہیں جہاں آپ کے پاس میٹرکس ہے جس میں تمام مستقل عدد اور ایک ویکٹر ہے جس میں تمام متغیرات ہیں، اور ان کا میٹرکس ویکٹر پروڈکٹ کچھ مختلف مستقل ویکٹر کے برابر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced x, and call the constant vector on the right-hand side v. ",
  "translatedText": "آئیے اس مستقل میٹرکس کو A کا نام دیتے ہیں، متغیرات کو بولڈ چہرے والے x کے ساتھ رکھنے والے ویکٹر کی نشاندہی کرتے ہیں، اور دائیں ہاتھ کی طرف والے مستقل ویکٹر کو v کہتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line. ",
  "translatedText": "یہ ہمارے مساوات کے نظام کو ایک لائن پر لکھنے کے لیے محض ایک نوٹیشنل چال سے زیادہ ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem. ",
  "translatedText": "یہ مسئلہ کے لئے ایک خوبصورت ٹھنڈی ہندسی تشریح پر روشنی ڈالتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals v means we're looking for a vector x which, after applying the transformation, lands on v. ",
  "translatedText": "میٹرکس A کچھ لکیری تبدیلی کے ساتھ مطابقت رکھتا ہے، لہذا Ax کے مساوی v کو حل کرنے کا مطلب ہے کہ ہم ایک ویکٹر x کی تلاش کر رہے ہیں جو تبدیلی کو لاگو کرنے کے بعد، v پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment. ",
  "translatedText": "ایک لمحے کے لیے سوچیں کہ یہاں کیا ہو رہا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another. ",
  "translatedText": "آپ ایک دوسرے کے ساتھ گھل مل جانے والے متعدد متغیرات کے اس پیچیدہ خیال کو اپنے ذہن میں رکھ سکتے ہیں صرف اسکویشنگ اور اسپیس کو مورف کرنے کے بارے میں سوچ کر اور یہ جاننے کی کوشش کر کے کہ کون سا ویکٹر دوسرے پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right? ",
  "translatedText": "ٹھنڈا، ٹھیک ہے؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns. ",
  "translatedText": "آسان شروع کرنے کے لیے، فرض کریں کہ آپ کے پاس دو مساوات اور دو نامعلوم کے ساتھ ایک نظام ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix and v and x are each two-dimensional vectors. ",
  "translatedText": "اس کا مطلب ہے کہ میٹرکس A ایک 2x2 میٹرکس ہے اور v اور x ہر دو جہتی ویکٹر ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started. ",
  "translatedText": "اب، ہم اس مساوات کے حل کے بارے میں کس طرح سوچتے ہیں اس بات پر منحصر ہے کہ آیا A کے ساتھ منسلک تبدیلی تمام جگہ کو ایک نچلی جہت، جیسے ایک لکیر یا ایک نقطہ میں نچوڑ دیتی ہے، یا اگر یہ ہر چیز کو مکمل دو جہتوں پر پھیلا دیتی ہے جہاں سے اس کا آغاز ہوتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant. ",
  "translatedText": "آخری ویڈیو کی زبان میں، ہم ان صورتوں میں تقسیم کرتے ہیں جہاں A میں صفر کا تعین ہوتا ہے اور وہ صورت جہاں A میں غیر صفر کا تعین ہوتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region. ",
  "translatedText": "آئیے سب سے زیادہ ممکنہ صورت کے ساتھ شروع کریں، جہاں تعین کنندہ غیر صفر ہے، یعنی جگہ صفر کے علاقے میں نہیں بٹتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on v, and you can find it by playing the transformation in reverse. ",
  "translatedText": "اس صورت میں، ہمیشہ ایک اور صرف ایک ویکٹر ہوگا جو v پر اترتا ہے، اور آپ اسے ریورس میں ٹرانسفارمیشن چلا کر تلاش کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where v goes as we rewind the tape like this, you'll find the vector x such that A times x equals v. ",
  "translatedText": "اس کے بعد جب ہم اس طرح ٹیپ کو ریوائنڈ کرتے ہیں تو v جہاں جاتا ہے، آپ کو ویکٹر x اس طرح ملے گا کہ A اوقات x برابر v۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation commonly called the inverse of A, denoted A to the negative one. ",
  "translatedText": "جب آپ تبدیلی کو ریورس میں کھیلتے ہیں، تو یہ دراصل ایک الگ لکیری تبدیلی سے مطابقت رکھتا ہے جسے عام طور پر A کا الٹا کہا جاتا ہے، A کو منفی سے ظاہر کیا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees. ",
  "translatedText": "مثال کے طور پر، اگر A 90 ڈگری کی مخالف گھڑی کی سمت میں گردش کرتا ہے، تو A کا الٹا گھڑی کی سمت میں 90 ڈگری کی گردش ہوگی۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left. ",
  "translatedText": "اگر A ایک دائیں طرف کی قینچی تھی جو j-hat کی ایک اکائی کو دائیں طرف دھکیلتی ہے تو A کا الٹا بائیں طرف کی قینچی ہوگی جو j-hat ون یونٹ کو بائیں طرف دھکیلتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started. ",
  "translatedText": "عام طور پر، A الٹا خاصیت کے ساتھ انوکھی تبدیلی ہے جسے اگر آپ پہلے A کا اطلاق کرتے ہیں، پھر A الٹا تبدیلی کے ساتھ اس کی پیروی کرتے ہیں، آپ وہیں سے ختم ہوجاتے ہیں جہاں آپ نے شروع کیا تھا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication. ",
  "translatedText": "ایک کے بعد دوسری تبدیلی کو لاگو کرنا میٹرکس ضرب کے ساتھ الجبری طور پر پکڑا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 294.54,
  "end": 298.94
 },
 {
  "input": "So the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing. ",
  "translatedText": "تو اس تبدیلی A الٹا کی بنیادی خاصیت یہ ہے کہ A الٹا اوقات A میٹرکس کے برابر ہے جو کچھ نہ کرنے کے مساوی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.42,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation. ",
  "translatedText": "وہ تبدیلی جو کچھ نہیں کرتی اسے شناخت کی تبدیلی کہا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1. ",
  "translatedText": "یہ i-hat اور j-hat ہر ایک کو چھوڑ دیتا ہے جہاں وہ ہیں، غیر متحرک، لہذا اس کے کالم 1,0 اور 0,1 ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v. ",
  "translatedText": "ایک بار جب آپ کو یہ الٹا مل جائے، جو عملی طور پر آپ کمپیوٹر کے ساتھ کرتے ہیں، تو آپ اس معکوس میٹرکس کو v سے ضرب دے کر اپنی مساوات کو حل کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v. ",
  "translatedText": "اور ایک بار پھر، ہندسی طور پر اس کا کیا مطلب ہے کہ آپ تبدیلی کو ریورس اور فالو کرنے والے v میں کھیل رہے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution. ",
  "translatedText": "یہ غیر صفر کا تعین کرنے والا کیس، جو کہ میٹرکس کے بے ترتیب انتخاب کے لیے اب تک سب سے زیادہ امکان ہے، اس خیال سے مطابقت رکھتا ہے کہ اگر آپ کے پاس دو نامعلوم اور دو مساواتیں ہیں، تو یہ تقریباً یقینی طور پر ایک واحد منفرد حل ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns. ",
  "translatedText": "یہ خیال اعلیٰ جہتوں میں بھی معنی رکھتا ہے، جب مساوات کی تعداد نامعلوم افراد کی تعداد کے برابر ہوتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v. ",
  "translatedText": "ایک بار پھر، مساوات کے نظام کا ہندسی تشریح میں ترجمہ کیا جا سکتا ہے جہاں آپ کے پاس کچھ تبدیلی A اور کچھ ویکٹر v ہے، اور آپ ویکٹر x کی تلاش کر رہے ہیں جو v پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing. ",
  "translatedText": "جب تک کہ تبدیلی A تمام جگہ کو نچلی جہت میں نہیں کھینچتی ہے، یعنی اس کا تعین کنندہ غیر صفر ہے، وہاں ایک معکوس تبدیلی A الٹی ہوگی، اس خاصیت کے ساتھ کہ اگر آپ پہلے A کرتے ہیں، تو آپ A الٹا کرتے ہیں۔ ، یہ کچھ نہ کرنے کے مترادف ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v. ",
  "translatedText": "اور اپنی مساوات کو حل کرنے کے لیے، آپ کو صرف اس ریورس ٹرانسفارمیشن میٹرکس کو ویکٹر v سے ضرب دینا ہوگا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse. ",
  "translatedText": "لیکن جب تعین کنندہ صفر ہو، اور مساوات کے نظام سے وابستہ تبدیلی خلا کو ایک چھوٹی جہت میں نچوڑ دیتی ہے، تو کوئی الٹا نہیں ہوتا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane. ",
  "translatedText": "آپ اسے ہوائی جہاز میں تبدیل کرنے کے لئے ایک لائن کو ختم نہیں کرسکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do. ",
  "translatedText": "کم از کم یہ ایسی چیز نہیں ہے جو ایک فنکشن کر سکتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors. ",
  "translatedText": "اس کے لیے ہر انفرادی ویکٹر کو ویکٹر سے بھری ایک پوری لائن میں تبدیل کرنے کی ضرورت ہوگی۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output. ",
  "translatedText": "لیکن فنکشنز صرف ایک ہی ان پٹ کو ایک آؤٹ پٹ میں لے سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point. ",
  "translatedText": "اسی طرح، تین مساواتوں اور تین نامعلوموں کے لیے، کوئی الٹا نہیں ہوگا اگر متعلقہ تبدیلی 3D اسپیس کو ہوائی جہاز پر نچوڑ دے، یا یہاں تک کہ اگر یہ اسے کسی لکیر یا ایک نقطے پر نچوڑ دے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume. ",
  "translatedText": "یہ سب صفر کے تعین کنندہ سے مطابقت رکھتے ہیں، کیونکہ کسی بھی خطے کو صفر والیوم والی چیز میں نچوڑ دیا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse. ",
  "translatedText": "یہ اب بھی ممکن ہے کہ حل موجود ہو تب بھی جب کوئی الٹا نہ ہو۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line. ",
  "translatedText": "یہ صرف اتنا ہے کہ جب آپ کی تبدیلی ایک لکیر پر جگہ کو دباتی ہے، تو آپ کو کافی خوش قسمت ہونا پڑے گا کہ ویکٹر v اس لائن پر کہیں رہتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others. ",
  "translatedText": "آپ محسوس کر سکتے ہیں کہ ان میں سے کچھ صفر فیصلہ کن معاملات دوسروں کے مقابلے میں بہت زیادہ پابندی محسوس کرتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant. ",
  "translatedText": "3x3 میٹرکس کو دیکھتے ہوئے، مثال کے طور پر، حل کا موجود ہونا بہت مشکل معلوم ہوتا ہے جب یہ کسی لائن پر جگہ کو اسکویش کرتا ہے اس کے مقابلے میں جب وہ چیزوں کو جہاز پر نچوڑتا ہے، حالانکہ یہ دونوں صفر کا تعین کرنے والے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant. ",
  "translatedText": "ہمارے پاس کچھ ایسی زبان ہے جو صفر کا تعین کرنے والے کہنے سے کہیں زیادہ مخصوص ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one. ",
  "translatedText": "جب تبدیلی کا آؤٹ پٹ ایک لائن ہے، یعنی یہ ایک جہتی ہے، تو ہم کہتے ہیں کہ تبدیلی کا ایک درجہ ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two. ",
  "translatedText": "اگر تمام ویکٹر کسی دو جہتی جہاز پر اترتے ہیں، تو ہم کہتے ہیں کہ تبدیلی کا درجہ دو ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation. ",
  "translatedText": "لہذا لفظ رینک کا مطلب ہے تبدیلی کے آؤٹ پٹ میں طول و عرض کی تعداد۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank 2 is the best that it can be. ",
  "translatedText": "مثال کے طور پر، 2x2 میٹرکس کے معاملے میں، درجہ 2 بہترین ہے جو یہ ہو سکتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space and the determinant is non-zero. ",
  "translatedText": "اس کا مطلب ہے کہ بنیاد ویکٹر خلا کی مکمل دو جہتوں کو پھیلاتے رہتے ہیں اور تعین کنندہ غیر صفر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank 2 means that we've collapsed, but not as much as they would have collapsed for a rank 1 situation. ",
  "translatedText": "لیکن 3x3 میٹرکس کے لیے، درجہ 2 کا مطلب ہے کہ ہم گر گئے ہیں، لیکن اتنا نہیں جتنا کہ وہ درجہ 1 کی صورت حال کے لیے گرے ہوں گے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of 3. ",
  "translatedText": "اگر 3D ٹرانسفارمیشن میں غیر صفر کا تعین ہوتا ہے اور اس کا آؤٹ پٹ تمام 3D جگہ کو بھرتا ہے، تو اس کا درجہ 3 ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix. ",
  "translatedText": "آپ کے میٹرکس کے لیے تمام ممکنہ آؤٹ پٹس کا یہ سیٹ، چاہے وہ لائن ہو، ہوائی جہاز، 3D اسپیس، جو بھی ہو، آپ کے میٹرکس کی کالم اسپیس کہلاتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from. ",
  "translatedText": "آپ شاید اندازہ لگا سکتے ہیں کہ یہ نام کہاں سے آیا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs. ",
  "translatedText": "آپ کے میٹرکس کے کالم آپ کو بتاتے ہیں کہ بنیاد ویکٹر کہاں اترتے ہیں، اور ان تبدیل شدہ بنیاد ویکٹرز کا دورانیہ آپ کو تمام ممکنہ نتائج فراہم کرتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix. ",
  "translatedText": "دوسرے لفظوں میں، کالم کی جگہ آپ کے میٹرکس کے کالموں کا دورانیہ ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space. ",
  "translatedText": "لہذا درجہ کی ایک زیادہ درست تعریف یہ ہوگی کہ یہ کالم کی جگہ میں طول و عرض کی تعداد ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank. ",
  "translatedText": "جب یہ رینک جتنا اونچا ہو سکتا ہے، یعنی یہ کالموں کی تعداد کے برابر ہو، تو ہم میٹرکس کو فل رینک کہتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice, the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place. ",
  "translatedText": "نوٹ کریں، صفر ویکٹر کو ہمیشہ کالم کی جگہ میں شامل کیا جائے گا، کیونکہ لکیری تبدیلیوں کو اصل کو اپنی جگہ پر رکھنا چاہیے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself. ",
  "translatedText": "مکمل درجہ کی تبدیلی کے لیے، واحد ویکٹر جو اصل پر اترتا ہے وہ صفر ویکٹر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero. ",
  "translatedText": "لیکن میٹرکس کے لیے جو مکمل رینک نہیں ہیں، جو کہ ایک چھوٹی جہت تک پہنچتے ہیں، آپ کے پاس صفر پر اترنے والے ویکٹرز کا ایک پورا گروپ ہو سکتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin. ",
  "translatedText": "اگر 2D تبدیلی کسی لکیر پر جگہ کو نچوڑ دیتی ہے، مثال کے طور پر، ویکٹروں سے بھری ایک مختلف سمت میں ایک الگ لائن ہے جو اصل پر دب جاتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin. ",
  "translatedText": "اگر ایک 3D تبدیلی کسی ہوائی جہاز پر جگہ کو نچوڑ دیتی ہے، تو ویکٹر کی ایک پوری لائن بھی ہوتی ہے جو اصل پر اترتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin. ",
  "translatedText": "اگر ایک 3D تبدیلی تمام جگہ کو ایک لکیر پر دھکیل دیتی ہے، تو وہاں ایک پورا طیارہ ویکٹر سے بھرا ہوا ہے جو اصل پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix. ",
  "translatedText": "ویکٹرز کا یہ مجموعہ جو اصل پر اترتا ہے اسے null space یا آپ کے میٹرکس کا دانا کہا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector. ",
  "translatedText": "یہ تمام ویکٹرز کی جگہ ہے جو صفر ہو جاتی ہے، اس معنی میں کہ وہ صفر ویکٹر پر اترتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation. ",
  "translatedText": "مساوات کے لکیری نظام کے لحاظ سے، جب v صفر ویکٹر ہوتا ہے، خالی جگہ آپ کو مساوات کے تمام ممکنہ حل فراہم کرتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high-level overview of how to think about linear systems of equations geometrically. ",
  "translatedText": "تو یہ ایک بہت ہی اعلیٰ سطحی جائزہ ہے کہ ہندسی طور پر مساوات کے لکیری نظاموں کے بارے میں کیسے سوچا جائے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system. ",
  "translatedText": "ہر سسٹم کے ساتھ کسی نہ کسی قسم کی لکیری تبدیلی وابستہ ہوتی ہے، اور جب اس تبدیلی میں الٹا ہوتا ہے، تو آپ اپنے سسٹم کو حل کرنے کے لیے اس الٹا کو استعمال کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like. ",
  "translatedText": "دوسری صورت میں، کالم اسپیس کا آئیڈیا ہمیں یہ سمجھنے دیتا ہے کہ جب کوئی حل بھی موجود ہوتا ہے، اور null اسپیس کا خیال ہمیں یہ سمجھنے میں مدد کرتا ہے کہ تمام ممکنہ حلوں کا سیٹ کیسا نظر آتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things. ",
  "translatedText": "ایک بار پھر، بہت ساری چیزیں ہیں جن کا میں نے یہاں احاطہ نہیں کیا ہے، خاص طور پر ان چیزوں کی گنتی کیسے کی جائے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns. ",
  "translatedText": "مجھے اپنے دائرہ کار کو ان مثالوں تک محدود کرنا پڑا جہاں مساوات کی تعداد نامعلوم افراد کی تعداد کے برابر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful. ",
  "translatedText": "لیکن یہاں مقصد یہ نہیں ہے کہ ہر چیز کو سکھانے کی کوشش کی جائے، یہ ہے کہ آپ معکوس میٹرکس، کالم اسپیس، اور null اسپیس کے لیے ایک مضبوط وجدان کے ساتھ آتے ہیں، اور یہ کہ وہ انترجات مستقبل کے کسی بھی سیکھنے کو بناتے ہیں جسے آپ زیادہ نتیجہ خیز بناتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices. ",
  "translatedText": "اگلی ویڈیو، مقبول درخواست کے مطابق، غیر مربع میٹرس کے بارے میں ایک مختصر فوٹ نوٹ ہوگا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations. ",
  "translatedText": "پھر اس کے بعد، میں آپ کو ڈاٹ پروڈکٹس کے بارے میں اپنا نقطہ نظر پیش کرنے جا رہا ہوں، اور کچھ بہت اچھا ہوتا ہے جب آپ انہیں لکیری تبدیلیوں کی روشنی میں دیکھتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 711.88,
  "end": 718.92
 },
 {
  "input": "See you then! ",
  "translatedText": "پھر آپ دیکھیں! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 719.48,
  "end": 719.66
 }
]