[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "",
  "from_community_srt": "Som du sikkert har opdaget nu, handler hovedparten af ​​denne serie om at forstå matrix- og vektoroperationer gennem en mere visuel linse af lineære transformationer. Denne video er ingen undtagelse, og beskriver begreberne inverse matricer,",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "",
  "from_community_srt": "søjlerum, rang, og nulrum gennem denne linse. En lille advarsel dog: Jeg har ikke tænkt mig at tale om metoder til rent faktisk at beregne disse ting,",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "",
  "from_community_srt": "og nogle vil hævde, at det er temmelig vigtigt. Der er mange meget gode ressourcer til at lære disse metoder uden denne serie.",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "",
  "from_community_srt": "Nøgleord: \"Gauss elimination\" og \"Reduceret echelon form.\" Jeg tror, ​​at intuitionen er der hvor jeg tilfører mest værdi.",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "",
  "from_community_srt": "Plus, i praksis, får vi normalt software til at beregne disse ting for os alligevel.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "",
  "from_community_srt": "Først et par ord om nytten af ​​lineær algebra. Du har allerede nu en idé om,",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "",
  "from_community_srt": "hvordan det bruges til at beskrive manipulation af rummet,",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "",
  "from_community_srt": "som er nyttig til ting som computergrafik og robotteknik, men en af ​​de vigtigste årsager til, at lineær algebra er mere bredt anvendelig,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "",
  "from_community_srt": "og krævet indenfor næsten enhver teknisk disciplin, er, at det lader os med at løse visse systemer af ligninger. Når jeg siger \"system af ligninger,\" mener jeg, du har en liste over variabler,",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "",
  "from_community_srt": "ting, du ikke kender, og en liste over ligninger vedrørende dem. I mange situationer kan disse ligninger blive meget komplicerede, men,",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "",
  "from_community_srt": "hvis du er heldig, kan de se ud på en bestemt særlig form.",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "",
  "from_community_srt": "Inden for hver ligning, er det eneste, der sker med hver variabel,",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "",
  "from_community_srt": "dét at den er skaleres med en konstant, og det eneste, der sker til hver af disse skalerede variabler er, at de er lægges sammen. Så ikke noget med eksponenter eller smarte funktioner eller at gange to variabler sammen;",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "",
  "from_community_srt": "den slags ting. Den typiske måde at organisere denne form for særlige ligningssystemer er at skrive alle variabler til venstre,",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "",
  "from_community_srt": "og skrive de resterende konstanter til højre. Det er også rart at centrere de fælles variable lodret under hinanden,",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "",
  "from_community_srt": "og for at gøre det, er du måske nødt til at skrive nogle nulkoefficienter, der hvor variablen ikke vises i en af ​​ligningerne. Dette kaldes et \"lineært ligningssystem.\" Du vil måske bemærke,",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "",
  "from_community_srt": "at dette ligner matrix-vektor multiplikation meget.",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "",
  "from_community_srt": "Faktisk kan man samle alle ligningerne sammen til en enkelt vektorligning,",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "",
  "from_community_srt": "hvor du har matricen, der indeholder alle de konstante koefficienter, og en vektor, der indeholder alle variablerne, og deres matrix-vektor produkt er lig en anden konstant vektor. Lad os kalde matricen med konstanter for A,",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "",
  "from_community_srt": "og kalde vektoren der holder variablerne med en fed x, og kalde den konstante vektor på højre side v. Dette er mere end blot et notationstrick for at få vores system af ligninger skrevet på én linje.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "",
  "from_community_srt": "Det kaster lys over en temmelig cool geometrisk fortolkning for problemet.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "",
  "from_community_srt": "Matricen A svarer til en lineær transformation,",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "",
  "from_community_srt": "så at løse Ax = v betyder, at vi leder efter en vektor x, der, efter anvendelse af transformationen, lander på v. Tænk over, hvad der sker her et øjeblik.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "",
  "from_community_srt": "Du kan i dit hoved holde den virkelig komplicerede idé om flere variabler alle sammenblandede med hinanden bare ved at tænke på at klemme og strække rum og forsøge at finde ud af, hvilken vektor der lander på en anden. Sejt, ikke? For at starte enkelt, lad os sige du har et system med to ligninger og to ubekendte.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "",
  "from_community_srt": "Dette betyder, at matricen A er en 2x2 matrix, og v og x er hver todimensionelle vektorer.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "",
  "from_community_srt": "Hvordan vi tænker på løsningerne på denne ligning afhænger af,",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "",
  "from_community_srt": "om transformationen i forbindelse med A klemmer hele rummet ned i en lavere dimension, som en linje eller et punkt, eller om det efterlader alt udspændende de fulde to dimensioner, hvor det startede. I sprogbrugen fra forrige video, inddeler vi i det tilfælde,",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "",
  "from_community_srt": "hvor A har determinant nul, og det tilfælde, hvor A har determinant forskellig fra nul. Lad os starte med det mest sandsynlige tilfælde,",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "",
  "from_community_srt": "hvor determinanten er forskellig fra nul, hvilket betyder rummet ikke bliver klemt ind i et område med et areal på nul. I dette tilfælde vil der altid være en og kun en vektor,",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "",
  "from_community_srt": "der lander på v, og du kan finde den ved at spille transformationen baglæns. Ved at følge hvor v går hen når vi spoler båndet baglæns som her,",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "",
  "from_community_srt": "finder du vektoren x således at A gange x er lig med v. Når du spiller transformationen baglæns,",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "",
  "from_community_srt": "svarer det reelt til en separat lineær transformation, almindeligvis kaldet \"den inverse af A\" betegnet A i minus første. For eksempel,",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "",
  "from_community_srt": "hvis A var en 90º rotation mod uret så ville den inverse af A ville være en rotation på 90º med uret. Hvis A var en forskydning mod højre, der skubber j-hat en enhed til højre,",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "",
  "from_community_srt": "så er den inverse af A en forskydning mod venstre, der skubber j-hat en enhed til venstre. Generelt - den inverse af A er den unikke transformation med den egenskab,",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "",
  "from_community_srt": "at hvis du først anvender A, og derefter anvender den inverse af A, så ender du tilbage hvor du startede. Anvendelsen af en transformation efter den anden indfanges algebraisk med matrixmultiplikation,",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "",
  "from_community_srt": "så kernenegenskaben af transformationen A invers er, at A invers gange A lig med matricen, der svarer til ikke at gøre noget. Transformationen, der ikke gør noget kaldes \"identitetstransformation.\" Den efterlader i-hat og j-hat hver hvor de er,",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "",
  "from_community_srt": "uberørt, så dets søjler er én,",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "",
  "from_community_srt": "nul, og nul, en. Når du finder denne inverse, som du i praksis gør med en computer,",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "",
  "from_community_srt": "kan du løse din ligning ved at gange denne inverse matrix med v. Og igen, hvad det betyder geometrisk er,",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "",
  "from_community_srt": "at du spiller transformationen baglæns, og følger efter v. Dette tilfælde med determinant forskellig fra nul,",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "",
  "from_community_srt": "hvilket for et tilfældigt valg af matrix er langt det mest sandsynlige, svarer til den idé, at hvis du har to ligninger med to ubekendte, det er næsten helt sikkert sådan, at der er en enkelt, entydig løsning. Denne idé giver også mening i højere dimensioner,",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "når antallet af ligninger er lig med antallet af ubekendte. Igen, ligningssystemet kan oversættes til den geometriske fortolkning hvor du har en given transformation,",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "",
  "from_community_srt": "A, og en given vektor, v, og du leder efter vektoren x, der lander på v. Så længe transformationen A ikke klemmer hele rummet i en lavere dimension,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "",
  "from_community_srt": "hvilket betyder, dens determinant er forskellig fra nul, vil der være en invers transformation, A invers, med den egenskab, at hvis du først anvender A, og så anvender A invers, det er det samme som ikke at gøre noget. Og for at løse din ligning,",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "",
  "from_community_srt": "er du bare nødt til at gange den inverse transformationsmatrix med vektoren v. Men når determinanten er nul,",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "",
  "from_community_srt": "og transformationen foranledet af dette system af ligninger klemmer rummet ned i en lavere dimension, er der ingen invers. Du kan ikke hive en linje op og lave det til en plan. I det mindste,",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "",
  "from_community_srt": "det er ikke noget, som en funktion kan gøre.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "",
  "from_community_srt": "Det ville kræve at omdanne hver enkelt vektor til en hel linie fuld af vektorer.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "",
  "from_community_srt": "Men funktioner kan kun tage et enkelt argument til et enkelt output.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "",
  "from_community_srt": "Tilsvarende for tre ligninger i tre ubekendte,",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "",
  "from_community_srt": "vil der ikke være omvendt, hvis den tilsvarende transformation klemmer 3D-rummet ned på en plan, eller helt ned på en linie eller et punkt. Disse svarer alle til tilfældet hvor deternimanten er nul,",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "",
  "from_community_srt": "da enhvert område bliver klemt til noget med et volumen på nul. Det er stadig muligt, at der findes en løsning,",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "",
  "from_community_srt": "selv når der ikke er en invers, det er bare, at når din transformation klemmer rummet ned på, lad os sige, en linje,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "",
  "from_community_srt": "så skal du skal være heldig at vektoren v bor et sted på denne linje. Du vil måske bemærke,",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "",
  "from_community_srt": "at nogle af disse nul determinant tilfælde føles meget mere restriktive end andre. Givet en 3x3 matrix, for eksempel,",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "",
  "from_community_srt": "synes det meget sværere for en løsning til at eksistere når den klemmer rummet ned på en linie sammenlignet med, når den klemmer ting ned på en plan, selv om de begge har determinant nul. Vi har sprogbrug,",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "",
  "from_community_srt": "der er lidt mere specifik end bare at sige \"nul determinant.\" Når værdimængden af ​​en transformation er en linje, hvilket betyder at det er endimensional,",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "",
  "from_community_srt": "siger vi at transformationen har \"rang\" en. Hvis alle vektorerne lander på en todimensional plan,",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "",
  "from_community_srt": "siger vi at transformationen har \"rang\" to. Så ordet \"rang\" betyder antallet af dimensioner i værdirummet af ​​en transformation.",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "",
  "from_community_srt": "For eksempel i tilfældet med 2x2 matricer, er rang 2 er det bedste,",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "",
  "from_community_srt": "det kan være. Det betyder basisvektorer fortsat spænder de fulde to dimensioner af rummet,",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "",
  "from_community_srt": "og determinanten er forskellig fra nul. Men for 3x3 matricer, betyder rang 2, at vi har kollapset,",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "",
  "from_community_srt": "men ikke så meget som de ville have kollapset i rang 1 situationen. Hvis en 3D transformation har en determinant forskellig fra nul,",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "",
  "from_community_srt": "og dens output fylder hele 3D rummet, har den rang 3. Dette sæt af alle mulige værdier for din matrix, uanset om det er en linje,",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "",
  "from_community_srt": "en plan, 3D-rum, eller noget fjerde, kaldes \"søjlerummet\" af din matrix. Du kan sikkert gætte, hvor det navn kommer fra.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "",
  "from_community_srt": "Søjlerne i din matrix fortælle dig, hvor basisvektorerne havner,",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "",
  "from_community_srt": "og spandet af ​​disse tranformerede basisvektorer giver dig alle mulige outputs. Med andre ord, søjlerummet er spandet af kolonnerne i din matrix.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "",
  "from_community_srt": "Så en mere præcis definition af rang ville være,",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "",
  "from_community_srt": "at det er antallet af dimensioner i søjlerummet. Når denne rang er så højt som det kan være, hvilket betyder at det er lig med antallet af kolonner,",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "",
  "from_community_srt": "siger vi at matricen har \"fuld rang.\" Bemærk at nulvektoren altid vil være i søjlerummet,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "",
  "from_community_srt": "da lineære transformationer altid holder origo på plads. For en transformation med fuld rang er den eneste vektor, der lander på nulvektoren,",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "",
  "from_community_srt": "nulvektoren selv, men for matricer, der ikke har fuld rang, som klemmer til en lavere dimension,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "",
  "from_community_srt": "kan du kan have en hel masse af vektorer, der lander på nul. Hvis en 2D transformation klemmer rummet ned på en linje,",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "",
  "from_community_srt": "for eksempel, er der er en separat linie i en anden retning, fuld af vektorer der bliver klemt ned på origo. Hvis en 3D transformation klemmer rummet ned på en plan,",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "er der også en hel linie af vektorer, som havner på nulvektoren. Hvis et 3D transformation klemmer hele rummet ned på en linje,",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "",
  "from_community_srt": "så er der en hel plan fuld af vektorer, der lander på nulvektoren. Dette sæt af vektorer,",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "",
  "from_community_srt": "der lander i nul kaldes \"nulrummet\" eller \"kernen\" af din matrix. Det er rummet af alle vektorer, der bliver nul, i den forstand,",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "",
  "from_community_srt": "at de lander på nulvektoren. Med hensyn til det lineære ligningssystem,",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "",
  "from_community_srt": "når v er nulvektoren, giver nulrummet dig alle de mulige løsninger til ligningen. Så det er en meget overfladisk oversigt om,",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "",
  "from_community_srt": "hvordan man kan tænke lineære ligningssystemer geometrisk. Hvert system har en slags lineær transformation associeret  med det,",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "",
  "from_community_srt": "og når den transformation har en invers, kan du bruge denne inverse til at løse dit system. Tanken om søjlerum lader os forstå,",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "",
  "from_community_srt": "hvornår en løsning eksisterer, og tanken om et nulrum hjælper os til at forstå, hvordan sættet af alle mulige løsninger kan se ud. Igen er der en masse, som jeg ikke har dækket her,",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "",
  "from_community_srt": "især hvordan man kan beregne disse ting. Jeg var også nødt til til at begrænse mit indhold til eksempler, hvor antallet af ligninger er lig med antallet af ubekendte.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "",
  "from_community_srt": "Men målet her er ikke at forsøge at lære alt; det er,",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "",
  "from_community_srt": "at du kommer herfra med en stærk intuition for inverse matricer, søjlerum, og nulrum, og at disse intuitioner vil gøre enhver fremtidig læring, som du gør mere frugtbar. Næste video, ved populær anmodning, vil være en kort fodnote om ikke-kvadratiske matricer.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "",
  "from_community_srt": "Så efter det, vil jeg give dig mit bud på prikprodukter, og noget temmelig cool der sker,",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "",
  "from_community_srt": "når du se dem i lyset af lineære transformationer. Vi ses!",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]