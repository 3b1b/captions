[
 {
  "input": "As you can probably tell by now, the bulk of this series is on understanding matrix and vector operations through that more visual lens of linear transformations.",
  "translatedText": "Wie du wahrscheinlich schon gemerkt hast, geht es in dieser Reihe hauptsächlich darum, Matrix- und Vektoroperationen durch die visuelle Linse der linearen Transformationen zu verstehen.",
  "model": "DeepL",
  "from_community_srt": "Wie ihr inzwischen vermutlich erkennst, liegt der Fokus dieser Serie auf dem Verstehen von Matrix- und Vektor-Operationen mithilfe des visuelleren Blickwinkels linearer Abbildungen",
  "n_reviews": 0,
  "start": 10.24,
  "end": 19.34
 },
 {
  "input": "This video is no exception, describing the concepts of inverse matrices, column space, rank, and null space through that lens.",
  "translatedText": "Dieses Video ist keine Ausnahme, denn es beschreibt die Konzepte der inversen Matrizen, des Spaltenraums, des Rangs und des Nullraums durch diese Brille.",
  "model": "DeepL",
  "from_community_srt": "Dieses Video ist keine Ausnahme, denn es beschreibt Konzepte von Inversen, Lösungsraum (\"Spaltenraum\"), Rang und Kern anhand dieses Blickwinkels.",
  "n_reviews": 0,
  "start": 19.98,
  "end": 27.52
 },
 {
  "input": "A forewarning though, I'm not going to talk about the methods for actually computing these things, and some would argue that that's pretty important.",
  "translatedText": "Eine Vorwarnung: Ich werde nicht über die Methoden sprechen, mit denen diese Dinge tatsächlich berechnet werden, und manche würden sagen, dass das ziemlich wichtig ist.",
  "model": "DeepL",
  "from_community_srt": "Vorwarnung: Ich werde nicht über die eigentlichen Berechnungsmethoden für diese Dinger reden und manche würden sagen,",
  "n_reviews": 0,
  "start": 27.52,
  "end": 34.24
 },
 {
  "input": "There are a lot of very good resources for learning those methods outside this series, keywords Gaussian elimination and row echelon form.",
  "translatedText": "Es gibt viele sehr gute Ressourcen, um diese Methoden außerhalb dieser Reihe zu erlernen, Stichwort Gaußsche Eliminierung und Reihenechelonform.",
  "model": "DeepL",
  "from_community_srt": "dass das recht wichtig sei. Es gibt viele andere sehr gute Quellen, um diese Methoden abseits dieser Reihe zu lernen. Stichwörter: \"Gauss'sches Eliminationsverfahren\" und \"Stufenform\".",
  "n_reviews": 0,
  "start": 34.84,
  "end": 42.0
 },
 {
  "input": "I think most of the value that I actually have to add here is on the intuition half.",
  "translatedText": "Ich denke, der größte Teil des Wertes, den ich hier hinzufügen muss, liegt in der Intuition.",
  "model": "DeepL",
  "from_community_srt": "Ich denke, der meiste Mehrwert, den ich vermitteln kann, liegt auf der intuitiven Seite.",
  "n_reviews": 0,
  "start": 42.54,
  "end": 46.34
 },
 {
  "input": "Plus, in practice, we usually get software to compute this stuff for us anyway.",
  "translatedText": "Außerdem lassen wir diese Dinge in der Praxis meist sowieso von einer Software für uns berechnen.",
  "model": "DeepL",
  "from_community_srt": "Außerdem berechnet das in der Realität sowieso meistens ein Programm für uns.",
  "n_reviews": 0,
  "start": 46.9,
  "end": 50.48
 },
 {
  "input": "First, a few words on the usefulness of linear algebra.",
  "translatedText": "Zunächst ein paar Worte zur Nützlichkeit der linearen Algebra.",
  "model": "DeepL",
  "from_community_srt": "Zunächst ein paar Worte über die Nützlichkeit von linearer Algebra.",
  "n_reviews": 0,
  "start": 51.5,
  "end": 53.92
 },
 {
  "input": "By now, you already have a hint for how it's used in describing the manipulation of space, which is useful for things like computer graphics and robotics.",
  "translatedText": "Inzwischen hast du schon eine Ahnung davon, wie er zur Beschreibung der Manipulation des Raums verwendet wird, was für Dinge wie Computergrafik und Robotik nützlich ist.",
  "model": "DeepL",
  "from_community_srt": "Mittlerweile haben Sie bereits eine Vermutung, dass es für die Beschreibung von Raummanipulationen benutzt wird, was praktisch ist für Dinge wie Computergrafik und Robotik,",
  "n_reviews": 0,
  "start": 54.3,
  "end": 61.04
 },
 {
  "input": "But one of the main reasons that linear algebra is more broadly applicable and required for just about any technical discipline is that it lets us solve certain systems of equations.",
  "translatedText": "Einer der Hauptgründe dafür, dass die lineare Algebra breiter anwendbar ist und für fast jede technische Disziplin benötigt wird, ist jedoch, dass wir mit ihr bestimmte Gleichungssysteme lösen können.",
  "model": "DeepL",
  "from_community_srt": "aber einer der Hauptgründe, dass Lineare Algebra breiter anwendbar ist und für nahezu jede technische Disziplin benötigt wird, ist, dass sie uns bestimmte Systeme von Gleichungen lösen lasst.",
  "n_reviews": 0,
  "start": 61.5,
  "end": 70.46
 },
 {
  "input": "When I say system of equations, I mean you have a list of variables, things you don't know, and a list of equations relating them.",
  "translatedText": "Wenn ich von Gleichungssystemen spreche, meine ich damit, dass du eine Liste von Variablen hast, die du nicht kennst, und eine Liste von Gleichungen, die sie miteinander verbinden.",
  "model": "DeepL",
  "from_community_srt": "Wenn ich Gleichungssysteme sagen, meine ich, dass ihr eine Liste von Variablen habt, Sachen, die ihr nicht kennt, und Gleichungen, die diese verwenden.",
  "n_reviews": 0,
  "start": 71.38,
  "end": 77.76
 },
 {
  "input": "In a lot of situations, those equations can get very complicated.",
  "translatedText": "In vielen Situationen können diese Gleichungen sehr kompliziert werden.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 78.34,
  "end": 81.6
 },
 {
  "input": "But, if you're lucky, they might take on a certain special form.",
  "translatedText": "Aber wenn du Glück hast, nehmen sie vielleicht eine besondere Form an.",
  "model": "DeepL",
  "from_community_srt": "In vielen Situationen können diese Gleichungen sehr kompliziert werden, aber mit etwas Glück nehmen sie eine bestimmte besondere Form an.",
  "n_reviews": 0,
  "start": 82.12,
  "end": 85.3
 },
 {
  "input": "Within each equation, the only thing happening to each variable is that it's scaled by some constant, and the only thing happening to each of those scaled variables is that they're added to each other.",
  "translatedText": "In jeder Gleichung wird jede Variable nur durch eine Konstante skaliert, und jede dieser skalierten Variablen wird nur addiert.",
  "model": "DeepL",
  "from_community_srt": "In jeder Gleichung ist jede Variable nur  um irgendeine Konstante skaliert, und das Einzige, was mit den skalierten Variablen gemacht wird, ist dass sie aufeinander aufaddiert werden.",
  "n_reviews": 0,
  "start": 86.44,
  "end": 96.88
 },
 {
  "input": "So no exponents or fancy functions or multiplying two variables together, things like that.",
  "translatedText": "Also keine Exponenten oder ausgefallenen Funktionen oder das Multiplizieren zweier Variablen und so weiter.",
  "model": "DeepL",
  "from_community_srt": "Also, keine Exponenten oder besondere Funktionen, oder Multiplikation zweier Variablen,",
  "n_reviews": 0,
  "start": 97.54,
  "end": 102.28
 },
 {
  "input": "The typical way to organize this sort of special system of equations is to throw all the variables on the left and put any lingering constants on the right.",
  "translatedText": "Die typische Art, solche speziellen Gleichungssysteme zu organisieren, ist, alle Variablen auf die linke Seite zu setzen und alle verbleibenden Konstanten auf die rechte.",
  "model": "DeepL",
  "from_community_srt": "oder derartiges. Der typische Weg, um dieses spezielle Gleichungssystem zu organisieren, ist, alle Variablen nach links zu packen, und alle übrigen Konstanten nach rechts.",
  "n_reviews": 0,
  "start": 103.42,
  "end": 112.14
 },
 {
  "input": "It's also nice to vertically line up the common variables, and to do that, you might need to throw in some zero coefficients whenever the variable doesn't show up in one of the equations.",
  "translatedText": "Es ist auch gut, die gemeinsamen Variablen vertikal aufzustellen. Um das zu erreichen, musst du vielleicht ein paar Nullkoeffizienten einfügen, wenn die Variable nicht in einer der Gleichungen auftaucht.",
  "model": "DeepL",
  "from_community_srt": "Es ist auch schön, die gemeinsamen Variablen untereinanderzuschreiben, und dafür muss man eventuell ein paar Null-Koeffizienten einbauen,",
  "n_reviews": 0,
  "start": 113.6,
  "end": 121.94
 },
 {
  "input": "This is called a linear system of equations.",
  "translatedText": "Das nennt man ein lineares Gleichungssystem.",
  "model": "DeepL",
  "from_community_srt": "sobald die Variable in einer der Gleichungen nicht auftaucht. Das nennt man ein \"Lineares Gleichungssystem\".",
  "n_reviews": 0,
  "start": 124.54,
  "end": 127.24
 },
 {
  "input": "You might notice that this looks a lot like matrix-vector multiplication.",
  "translatedText": "Vielleicht fällt dir auf, dass dies sehr nach einer Matrix-Vektor-Multiplikation aussieht.",
  "model": "DeepL",
  "from_community_srt": "Euch fällt vielleicht auf, dass das sehr nach einer Matrix-Vektor-Multiplikation aussieht.",
  "n_reviews": 0,
  "start": 128.1,
  "end": 131.18
 },
 {
  "input": "In fact, you can package all of the equations together into a single vector equation where you have the matrix containing all of the constant coefficients and a vector containing all of the variables, and their matrix-vector product equals some different constant vector.",
  "translatedText": "Tatsächlich kannst du alle Gleichungen in eine einzige Vektorgleichung packen, in der du eine Matrix mit allen konstanten Koeffizienten und einen Vektor mit allen Variablen hast, deren Matrix-Vektor-Produkt einem anderen konstanten Vektor entspricht.",
  "model": "DeepL",
  "from_community_srt": "Tatsächlich kann man all die Gleichungen in eine einzige Vektorgleichung verpacken, in der die Matrix alle Koeffizienten enthält, und ein Vektor alle Variablen, und das Matrix-Vektor-Produkt gleich einem anderen konstanten Vektor ist.",
  "n_reviews": 0,
  "start": 131.82,
  "end": 146.78
 },
 {
  "input": "Let's name that constant matrix A, denote the vector holding the variables with a bold-faced X, and call the constant vector on the right-hand side V.",
  "translatedText": "Nennen wir diese konstante Matrix A, bezeichnen wir den Vektor, der die Variablen enthält, mit einem fettgedruckten X und nennen wir den konstanten Vektor auf der rechten Seite V.",
  "model": "DeepL",
  "from_community_srt": "Nennen wir die Konstanten-Matrix A, bezeichen den Variablen-Vektor mit einem fettgeschriebenen x, und nennen den Konstantenvektor rechts v.",
  "n_reviews": 0,
  "start": 148.64,
  "end": 157.48
 },
 {
  "input": "This is more than just a notational trick to get our system of equations written on one line.",
  "translatedText": "Dies ist mehr als nur ein Notationstrick, um unser Gleichungssystem auf eine Zeile zu bekommen.",
  "model": "DeepL",
  "from_community_srt": "Das ist mehr als nur ein Notationstrick, um unser Gleichungssystem in einer einzigen Zeile schreiben zu können.",
  "n_reviews": 0,
  "start": 158.86,
  "end": 162.98
 },
 {
  "input": "It sheds light on a pretty cool geometric interpretation for the problem.",
  "translatedText": "Das wirft ein Licht auf eine ziemlich coole geometrische Interpretation des Problems.",
  "model": "DeepL",
  "from_community_srt": "Es gibt Aufschluss über eine ziemlich coole geometrische Interpretation dieses Problems.",
  "n_reviews": 0,
  "start": 163.34,
  "end": 166.78
 },
 {
  "input": "The matrix A corresponds with some linear transformation, so solving Ax equals V means we're looking for a vector X, which, after applying the transformation, lands on V.",
  "translatedText": "Die Matrix A entspricht einer linearen Transformation. Ax gleich V zu lösen bedeutet also, dass wir nach einem Vektor X suchen, der nach Anwendung der Transformation auf V liegt.",
  "model": "DeepL",
  "from_community_srt": "Die Matrix A korrespondiert mit irgendeiner linearen Abbildung, also bedeutet das Lösen von Ax=v, dass wir einen Vektor x suchen, der nach Anwendung der Abbildung auf v landet.",
  "n_reviews": 0,
  "start": 167.62,
  "end": 177.92
 },
 {
  "input": "Think about what's happening here for a moment.",
  "translatedText": "Denke einen Moment darüber nach, was hier passiert.",
  "model": "DeepL",
  "from_community_srt": "Denkt einen Moment lang darüber nach, was hier passiert.",
  "n_reviews": 0,
  "start": 179.94,
  "end": 181.78
 },
 {
  "input": "You can hold in your head this really complicated idea of multiple variables all intermingling with each other just by thinking about squishing and morphing space and trying to figure out which vector lands on another.",
  "translatedText": "Du kannst dir diese wirklich komplizierte Vorstellung von mehreren Variablen, die sich alle miteinander vermischen, in den Kopf setzen, indem du dir vorstellst, wie der Raum gequetscht und gemorpht wird und du versuchst herauszufinden, welcher Vektor auf einem anderen landet.",
  "model": "DeepL",
  "from_community_srt": "Folgende wirklich komplexe Vorstellung ist greifbar: Eine Vielzahl von Variablen, die sich alle miteinander vermischen, einfach, indem man über das Quetschen und Verformen eines Raumes nachdenkt und probiert herauszufinden, welcher Vektor auf welchem landet.",
  "n_reviews": 0,
  "start": 182.06,
  "end": 192.6
 },
 {
  "input": "Cool, right?",
  "translatedText": "Cool, nicht wahr?",
  "model": "DeepL",
  "from_community_srt": "Cool,",
  "n_reviews": 0,
  "start": 193.16,
  "end": 193.76
 },
 {
  "input": "To start simple, let's say you have a system with two equations and two unknowns.",
  "translatedText": "Um ganz einfach zu beginnen, nehmen wir an, du hast ein System mit zwei Gleichungen und zwei Unbekannten.",
  "model": "DeepL",
  "from_community_srt": "oder? Um simpel anzufangen; sagen wir, wir haben ein System mit zwei Gleichungen und zwei Unbekannten.",
  "n_reviews": 0,
  "start": 194.6,
  "end": 198.68
 },
 {
  "input": "This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors.",
  "translatedText": "Das heißt, die Matrix A ist eine 2x2-Matrix und V und X sind jeweils zweidimensionale Vektoren.",
  "model": "DeepL",
  "from_community_srt": "Das heißt, dass die Matrix A eine 2x2-Matrix ist, und v und x sind beides zweidimensionale Vektoren.",
  "n_reviews": 0,
  "start": 199.0,
  "end": 203.96
 },
 {
  "input": "Now, how we think about the solutions to this equation depends on whether the transformation associated with A squishes all of space into a lower dimension, like a line or a point, or if it leaves everything spanning the full two dimensions where it started.",
  "translatedText": "Wie wir nun über die Lösungen dieser Gleichung denken, hängt davon ab, ob die mit A verbundene Transformation den gesamten Raum in eine niedrigere Dimension, wie eine Linie oder einen Punkt, quetscht, oder ob sie alles in den vollen zwei Dimensionen belässt, wo es begonnen hat.",
  "model": "DeepL",
  "from_community_srt": "Wie wir jetzt über die Lösungen dieser Gleichung nachdenken, hängt davon ab, ob die Abbildung, die zu A gehört, den Raum in eine niedrigere Dimension quetscht, z.B. eine Gerade oder ein Punkt, oder ob sie die ganzen beiden Anfangsdimensionen beibehält.",
  "n_reviews": 0,
  "start": 205.6,
  "end": 218.9
 },
 {
  "input": "In the language of the last video, we subdivide into the cases where A has zero determinant and the case where A has non-zero determinant.",
  "translatedText": "In der Sprache des letzten Videos unterteilen wir in den Fall, in dem A die Determinante Null hat, und den Fall, in dem A eine Determinante ungleich Null hat.",
  "model": "DeepL",
  "from_community_srt": "Mithilfe den Begriffen des letzten Videos, unterscheiden wir den Fall, in dem die Determinante von A 0 ist, und den Fall,",
  "n_reviews": 0,
  "start": 220.32,
  "end": 228.04
 },
 {
  "input": "Let's start with the most likely case, where the determinant is non-zero, meaning space does not get squished into a zero-area region.",
  "translatedText": "Beginnen wir mit dem wahrscheinlichsten Fall, in dem die Determinante ungleich Null ist, was bedeutet, dass der Raum nicht in eine Null-Flächen-Region gequetscht wird.",
  "model": "DeepL",
  "from_community_srt": "in dem die Determinante von A ungleich 0 ist. Lasst uns mit dem wahrscheinlicheren Fall starten, in dem die Determinante ungleich 0 ist, was heißt, dass der Raum nicht in eine Region mit Fläche 0 gequetscht wird.",
  "n_reviews": 0,
  "start": 231.3,
  "end": 237.72
 },
 {
  "input": "In this case, there will always be one and only one vector that lands on V, and you can find it by playing the transformation in reverse.",
  "translatedText": "In diesem Fall gibt es immer nur einen einzigen Vektor, der auf V landet, und du kannst ihn finden, indem du die Transformation rückwärts durchspielst.",
  "model": "DeepL",
  "from_community_srt": "In diesem Fall wird es immer genau einen Vektor geben, der auf v landet, und man kann ihn finden, indem man die Abbildung rückwärts ablaufen lässt.",
  "n_reviews": 0,
  "start": 238.6,
  "end": 246.16
 },
 {
  "input": "Following where V goes as we rewind the tape like this, you'll find the vector x such that A times x equals V.",
  "translatedText": "Wenn du verfolgst, wohin V geht, wenn wir das Band so zurückspulen, findest du den Vektor x so, dass A mal x gleich V ist.",
  "model": "DeepL",
  "from_community_srt": "Wenn man den Verlauf von v während dieses Rückwärtsspulens nachvollzieht, kommt man auf den Vektor x,",
  "n_reviews": 0,
  "start": 246.7,
  "end": 253.46
 },
 {
  "input": "When you play the transformation in reverse, it actually corresponds to a separate linear transformation, commonly called the inverse of A, denoted A to the negative one.",
  "translatedText": "Wenn du die Transformation rückwärts abspielst, entspricht sie tatsächlich einer separaten linearen Transformation, die gemeinhin als Umkehrung von A bezeichnet wird, also A zum Negativen.",
  "model": "DeepL",
  "from_community_srt": "bei dem A mal x gleich v ist. Das Rückwärtsspulen entspricht übrigens einer anderen linearen Abbildung, die meist \"Inverses von A\" genannt wird, geschrieben als A hoch minus 1.",
  "n_reviews": 0,
  "start": 255.4,
  "end": 264.68
 },
 {
  "input": "For example, if A was a counterclockwise rotation by 90 degrees, then the inverse of A would be a clockwise rotation by 90 degrees.",
  "translatedText": "Wenn A zum Beispiel eine Drehung um 90 Grad gegen den Uhrzeigersinn wäre, dann wäre die Umkehrung von A eine Drehung um 90 Grad im Uhrzeigersinn.",
  "model": "DeepL",
  "from_community_srt": "Zum Beispiel, wenn A einer Drehung gegen den Uhrzeigersinn um 90° entspricht, dann wäre das Inverse von A eine Drehung im Uhrzeigersinn um 90°.",
  "n_reviews": 0,
  "start": 265.36,
  "end": 272.76
 },
 {
  "input": "If A was a rightward shear that pushes j-hat one unit to the right, the inverse of A would be a leftward shear that pushes j-hat one unit to the left.",
  "translatedText": "Wenn A eine Scherung nach rechts wäre, die j-hat eine Einheit nach rechts schiebt, wäre die Umkehrung von A eine Scherung nach links, die j-hat eine Einheit nach links schiebt.",
  "model": "DeepL",
  "from_community_srt": "Wenn A eine Rechtsscherung wäre, das j-hat eine Einheit nach rechts verschiebt, dann wäre das Inverse von a eine Linksscherung, die j-hat eine Einheit nach links verschiebt.",
  "n_reviews": 0,
  "start": 274.32,
  "end": 282.48
 },
 {
  "input": "In general, A inverse is the unique transformation with the property that if you first apply A, then follow it with the transformation A inverse, you end up back where you started.",
  "translatedText": "Im Allgemeinen ist die Umkehrung von A die einzige Transformation, die die Eigenschaft hat, dass du, wenn du zuerst A anwendest und dann die Umkehrung von A folgen lässt, wieder dort landest, wo du angefangen hast.",
  "model": "DeepL",
  "from_community_srt": "Allgemein ist das Inverse von A die eindeutige Abbildung mit der Eigenschaft, dass wenn man zuerst A anwendet, und danach die Abbildung Inverses von A, landet man dort,",
  "n_reviews": 0,
  "start": 284.1,
  "end": 293.48
 },
 {
  "input": "Applying one transformation after another is captured algebraically with matrix multiplication, so the core property of this transformation A inverse is that A inverse times A equals the matrix that corresponds to doing nothing.",
  "translatedText": "Die Anwendung einer Transformation nach der anderen wird algebraisch mit der Matrixmultiplikation erfasst. Die Kerneigenschaft dieser Transformation A invers ist also, dass A invers mal A gleich der Matrix ist, die dem Nichtstun entspricht.",
  "model": "DeepL",
  "from_community_srt": "wo man angefangen hat. Eine Abbildung nach der anderen anzuwenden, kann man algebraisch mit Matrixmultiplikation darstellen, also ist die Kerneigenschaft dieser Abbildung \"Inverses von A\", dass \"Inverses von A\" mal A die Matrix ergibt, die dem Nichtstun entspricht.",
  "n_reviews": 0,
  "start": 294.54,
  "end": 307.34
 },
 {
  "input": "The transformation that does nothing is called the identity transformation.",
  "translatedText": "Die Transformation, die nichts bewirkt, wird als Identitätstransformation bezeichnet.",
  "model": "DeepL",
  "from_community_srt": "Diese Abbildung, die nichts tut, heißt Identitätsabbildung.",
  "n_reviews": 0,
  "start": 308.2,
  "end": 311.32
 },
 {
  "input": "It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1.",
  "translatedText": "Sie lässt i-hat und j-hat jeweils dort, wo sie sind, also in den Spalten 1,0 und 0,1.",
  "model": "DeepL",
  "from_community_srt": "Sie lässt i-hat und j-hat beide dort, wo sie sind, unbewegt, also sind ihre Spalten 1,0 und 0,1.",
  "n_reviews": 0,
  "start": 311.78,
  "end": 318.08
 },
 {
  "input": "Once you find this inverse, which in practice you'd do with a computer, you can solve your equation by multiplying this inverse matrix by v.",
  "translatedText": "Wenn du diesen Kehrwert gefunden hast, was du in der Praxis mit einem Computer machen würdest, kannst du deine Gleichung lösen, indem du diese inverse Matrix mit v multiplizierst.",
  "model": "DeepL",
  "from_community_srt": "Sobald man dieses Inverse findet, was in der Praxis mit einem Computer gemacht wird, kann man die Gleichung lösen,",
  "n_reviews": 0,
  "start": 319.98,
  "end": 327.72
 },
 {
  "input": "And again, what this means geometrically is that you're playing the transformation in reverse and following v.",
  "translatedText": "Geometrisch bedeutet das wiederum, dass du die Transformation rückwärts und nach v durchführst.",
  "model": "DeepL",
  "from_community_srt": "indem man die inverse Matrix mit v multipliziert. Nochmal, was das geometrisch heißt, ist dass man diese Abbildung rückwärts abspielt,",
  "n_reviews": 0,
  "start": 329.96,
  "end": 336.44
 },
 {
  "input": "This non-zero determinant case, which for a random choice of matrix is by far the most likely one, corresponds with the idea that if you have two unknowns and two equations, it's almost certainly the case that there's a single unique solution.",
  "translatedText": "Dieser Fall der Determinante ungleich Null, der bei einer zufälligen Wahl der Matrix bei weitem am wahrscheinlichsten ist, entspricht der Vorstellung, dass es bei zwei Unbekannten und zwei Gleichungen mit ziemlicher Sicherheit eine einzige Lösung gibt.",
  "model": "DeepL",
  "from_community_srt": "und v beobachtet. Der Nicht-Null-Determinanten Fall, der für eine zufällig gewählte Matrix mit Abstand der wahrscheinlichste ist, korrespondiert mit der Idee, dass wenn man zwei Unbekannte und zwei Gleichungen hat, es fast immer der Fall sein wird, dass es eine einzige,",
  "n_reviews": 0,
  "start": 340.2,
  "end": 352.4
 },
 {
  "input": "This idea also makes sense in higher dimensions, when the number of equations equals the number of unknowns.",
  "translatedText": "Diese Idee ist auch in höheren Dimensionen sinnvoll, wenn die Anzahl der Gleichungen die Anzahl der Unbekannten übersteigt.",
  "model": "DeepL",
  "from_community_srt": "einzigartige Lösung gibt. Diese Idee ergibt auch in höheren Dimensionen Sinn, wenn die Anzahl der Gleichungen der Anzahl der Unbekannten entspricht.",
  "n_reviews": 0,
  "start": 353.68,
  "end": 359.2
 },
 {
  "input": "Again, the system of equations can be translated to the geometric interpretation where you have some transformation A and some vector v, and you're looking for the vector x that lands on v.",
  "translatedText": "Auch hier kann das Gleichungssystem in die geometrische Interpretation übertragen werden: Du hast eine Transformation A und einen Vektor v und suchst den Vektor x, der auf v liegt.",
  "model": "DeepL",
  "from_community_srt": "Nochmal, das Gleichungssystem kann in die geometrische Interpretation übersetzt werden, in der man irgendeine Abbildung A hat, und irgendeinen Vektor v, und man sucht den Vektor x,",
  "n_reviews": 0,
  "start": 359.38,
  "end": 372.74
 },
 {
  "input": "As long as the transformation A doesn't squish all of space into a lower dimension, meaning its determinant is non-zero, there will be an inverse transformation A inverse, with the property that if you first do A, then you do A inverse, it's the same as doing nothing.",
  "translatedText": "Solange die Transformation A nicht den gesamten Raum in eine niedrigere Dimension quetscht, d.h. ihre Determinante ungleich Null ist, gibt es eine inverse Transformation A invers, mit der Eigenschaft, dass es dasselbe ist, nichts zu tun, wenn du zuerst A machst und dann A invers machst.",
  "model": "DeepL",
  "from_community_srt": "der auf v landet. Solange diese Abbildung A den Raum nicht in einer kleinere Dimension quetscht, also wenn ihre Determinante nicht-null ist, wird es eine Inverse Abbildung, A^-1 geben, mit der Eigenschaft, dass wenn man erst A anwendet, und dann A^-1 anwendet,",
  "n_reviews": 0,
  "start": 375.74,
  "end": 391.04
 },
 {
  "input": "And to solve your equation, you just have to multiply that reverse transformation matrix by the vector v.",
  "translatedText": "Um deine Gleichung zu lösen, musst du die Rücktransformationsmatrix nur mit dem Vektor v multiplizieren.",
  "model": "DeepL",
  "from_community_srt": "das das Gleiche ist wie Nichtstun. Und um die Gleichung zu lösen,",
  "n_reviews": 0,
  "start": 393.54,
  "end": 399.44
 },
 {
  "input": "But when the determinant is zero, and the transformation associated with the system of equations squishes space into a smaller dimension, there is no inverse.",
  "translatedText": "Aber wenn die Determinante Null ist und die mit dem Gleichungssystem verbundene Transformation den Raum in eine kleinere Dimension quetscht, gibt es keine Umkehrung.",
  "model": "DeepL",
  "from_community_srt": "muss man nur diese Umkehr-Abbildungs-Matrix mit dem Vektor v multiplizieren. Aber wenn die Determinante 0 ist, und die Abbildung, die dem Gleichungssystem entspricht, den Raum in eine kleinere Dimension quetscht, dann gibt es kein Inverses.",
  "n_reviews": 0,
  "start": 403.5,
  "end": 412.06
 },
 {
  "input": "You cannot unsquish a line to turn it into a plane.",
  "translatedText": "Du kannst eine Linie nicht aufheben, um sie in eine Ebene zu verwandeln.",
  "model": "DeepL",
  "from_community_srt": "Man kann keine Gerade zu einer Ebene ent-quetschen.",
  "n_reviews": 0,
  "start": 412.48,
  "end": 415.46
 },
 {
  "input": "At least that's not something that a function can do.",
  "translatedText": "Zumindest ist das nicht etwas, das eine Funktion tun kann.",
  "model": "DeepL",
  "from_community_srt": "Zumindest eine Funktion kann das nicht.",
  "n_reviews": 0,
  "start": 415.98,
  "end": 418.06
 },
 {
  "input": "That would require transforming each individual vector into a whole line full of vectors.",
  "translatedText": "Dazu müsste jeder einzelne Vektor in eine ganze Zeile voller Vektoren umgewandelt werden.",
  "model": "DeepL",
  "from_community_srt": "Das würde bedeuten, einen einzelnen Vektor auf eine ganze Gerade voller Vektoren abzubilden.",
  "n_reviews": 0,
  "start": 418.36,
  "end": 422.98
 },
 {
  "input": "But functions can only take a single input to a single output.",
  "translatedText": "Aber Funktionen können nur eine einzige Eingabe mit einer einzigen Ausgabe verbinden.",
  "model": "DeepL",
  "from_community_srt": "Aber Funktionen können aus einer einzigen Eingabe nur eine einzige Ausgabe machen.",
  "n_reviews": 0,
  "start": 423.74,
  "end": 426.74
 },
 {
  "input": "Similarly, for three equations and three unknowns, there will be no inverse if the corresponding transformation squishes 3D space onto the plane, or even if it squishes it onto a line or a point.",
  "translatedText": "Ebenso gibt es bei drei Gleichungen und drei Unbekannten keine Umkehrung, wenn die entsprechende Transformation den 3D-Raum in die Ebene quetscht, oder sogar wenn sie ihn auf eine Linie oder einen Punkt quetscht.",
  "model": "DeepL",
  "from_community_srt": "Analog, wird es für drei Gleichungen mit drei Unbekannten kein Inverses geben, wenn die entsprechende Abbildung 3D-Raum in eine Ebene quetscht, oder sogar in eine Gerade,",
  "n_reviews": 0,
  "start": 428.4,
  "end": 439.14
 },
 {
  "input": "Those all correspond to a determinant of zero, since any region is squished into something with zero volume.",
  "translatedText": "Diese entsprechen alle einer Determinante von Null, da jede Region in etwas mit dem Volumen Null zerquetscht wird.",
  "model": "DeepL",
  "from_community_srt": "oder einen Punkt. All diese entsprechen einer Determinante von 0, da jede Region in etwas mit Volumen 0 gequetscht wird.",
  "n_reviews": 0,
  "start": 439.92,
  "end": 445.16
 },
 {
  "input": "It's still possible that a solution exists even when there is no inverse.",
  "translatedText": "Es ist immer noch möglich, dass es eine Lösung gibt, auch wenn es keine Umkehrung gibt.",
  "model": "DeepL",
  "from_community_srt": "Es ist immer noch möglich, dass es auch ohne Inverses eine Lösung gibt, es ist nur so,",
  "n_reviews": 0,
  "start": 446.7,
  "end": 450.64
 },
 {
  "input": "It's just that when your transformation squishes space onto, say, a line, you have to be lucky enough that the vector v lives somewhere on that line.",
  "translatedText": "Es ist nur so, dass, wenn deine Transformation den Raum auf, sagen wir, eine Linie quetscht, du das Glück haben musst, dass der Vektor v irgendwo auf dieser Linie liegt.",
  "model": "DeepL",
  "from_community_srt": "dass wenn die Abbildung den Raum auf, sagen wir eine Gerade quetscht, muss man sehr viel Glück haben,",
  "n_reviews": 0,
  "start": 450.72,
  "end": 459.38
 },
 {
  "input": "You might notice that some of these zero determinant cases feel a lot more restrictive than others.",
  "translatedText": "Du wirst feststellen, dass sich einige dieser Null-Bestimmungsfälle viel restriktiver anfühlen als andere.",
  "model": "DeepL",
  "from_community_srt": "wenn der Vektor v irgendwo auf dieser Geraden leben soll. Euch fällt vielleicht auf, dass manche der Null-Determinanten-Fälle sich viel restriktiver anfühlen als andere.",
  "n_reviews": 0,
  "start": 463.3,
  "end": 468.3
 },
 {
  "input": "Given a 3x3 matrix, for example, it seems a lot harder for a solution to exist when it squishes space onto a line compared to when it squishes things onto a plane, even though both of those are zero determinant.",
  "translatedText": "Bei einer 3x3-Matrix scheint es zum Beispiel viel schwieriger zu sein, eine Lösung zu finden, wenn der Raum auf eine Linie gequetscht wird, als wenn die Dinge auf eine Ebene gequetscht werden, obwohl in beiden Fällen die Determinante null ist.",
  "model": "DeepL",
  "from_community_srt": "Gegeben eine 3x3-Matrix ist es z.B. viel unwahrscheinlicher, dass eine Lösung existiert wenn sie den Raum auf eine Gerade anstatt auf eine Ebene zusammenquetscht.",
  "n_reviews": 0,
  "start": 468.84,
  "end": 480.24
 },
 {
  "input": "We have some language that's a bit more specific than just saying zero determinant.",
  "translatedText": "Wir haben eine Sprache, die etwas spezifischer ist, als nur zu sagen, dass die Determinante Null ist.",
  "model": "DeepL",
  "from_community_srt": "obwohl beide Determinante 0 haben. Es gibt eine Ausdrucksweise, die spezifischer ist, als einfach \"Determinante 0\" zu sagen.",
  "n_reviews": 0,
  "start": 482.6,
  "end": 486.1
 },
 {
  "input": "When the output of a transformation is a line, meaning it's one-dimensional, we say the transformation has a rank of one.",
  "translatedText": "Wenn das Ergebnis einer Transformation eine Linie ist, d.h. eindimensional, sagen wir, die Transformation hat den Rang eins.",
  "model": "DeepL",
  "from_community_srt": "Wenn die Ausgabe einer Abbildung eine Gerade ist, also eindimensional, sagen wir,",
  "n_reviews": 0,
  "start": 486.52,
  "end": 493.5
 },
 {
  "input": "If all the vectors land on some two-dimensional plane, we say the transformation has a rank of two.",
  "translatedText": "Wenn alle Vektoren auf einer zweidimensionalen Ebene landen, sagen wir, dass die Transformation einen Rang von zwei hat.",
  "model": "DeepL",
  "from_community_srt": "dass die Abbildung einen \"Rang\" von 1 hat. Wenn all die Vektoren auf einer zwei-dimensionalen Ebene landen, sagen wir,",
  "n_reviews": 0,
  "start": 495.14,
  "end": 500.42
 },
 {
  "input": "So the word rank means the number of dimensions in the output of a transformation.",
  "translatedText": "Das Wort Rang bezeichnet also die Anzahl der Dimensionen in der Ausgabe einer Transformation.",
  "model": "DeepL",
  "from_community_srt": "dass die Abbildung einen \"Rang\" von 2 hat. Also steht das Wort \"Rang\" für die Anzahl der Dimensionen in der Ausgabe einer Abbildung.",
  "n_reviews": 0,
  "start": 502.92,
  "end": 507.48
 },
 {
  "input": "For instance, in the case of 2x2 matrices, rank two is the best that it can be.",
  "translatedText": "Bei 2x2-Matrizen zum Beispiel ist Rang zwei das Beste, was es geben kann.",
  "model": "DeepL",
  "from_community_srt": "Zum Beispiel ist im Fall von 2x2-Matrizen Rang 2 das Beste, das passieren kann.",
  "n_reviews": 0,
  "start": 508.4,
  "end": 512.72
 },
 {
  "input": "It means the basis vectors continue to span the full two dimensions of space, and the determinant is not zero.",
  "translatedText": "Das bedeutet, dass die Basisvektoren weiterhin die vollen zwei Dimensionen des Raums aufspannen und die Determinante nicht Null ist.",
  "model": "DeepL",
  "from_community_srt": "Er bedeutet, dass die Basisvektoren immer noch die vollen zwei Raumdimensionen aufspannen, und dass die Determinante ungleich 0 ist.",
  "n_reviews": 0,
  "start": 513.08,
  "end": 519.02
 },
 {
  "input": "But for 3x3 matrices, rank two means that we've collapsed, but not as much as they would have collapsed for a rank one situation.",
  "translatedText": "Aber für 3x3-Matrizen bedeutet Rang zwei, dass wir kollabiert sind, aber nicht so sehr, wie es bei Rang eins der Fall gewesen wäre.",
  "model": "DeepL",
  "from_community_srt": "Aber für 3x3-Matrizen, heißt Rang 2, dass wir zusammengefallen sind, wenn auch nicht soviel wie wenn wir in einer Rang-1-Situation zusammengefallen wären.",
  "n_reviews": 0,
  "start": 519.42,
  "end": 526.46
 },
 {
  "input": "If a 3D transformation has a non-zero determinant and its output fills all of 3D space, it has a rank of three.",
  "translatedText": "Wenn eine 3D-Transformation eine Determinante ungleich Null hat und ihr Ergebnis den gesamten 3D-Raum ausfüllt, hat sie den Rang drei.",
  "model": "DeepL",
  "from_community_srt": "Wenn eine 3D-Abbildung eine Determinante ungleich 0 hat, und ihre Ausgabe den gesamten 3D-Raum ausfüllt, hat sie einen Rang von 3.",
  "n_reviews": 0,
  "start": 527.24,
  "end": 533.34
 },
 {
  "input": "This set of all possible outputs for your matrix, whether it's a line, a plane, 3D space, whatever, is called the column space of your matrix.",
  "translatedText": "Diese Menge aller möglichen Ausgaben für deine Matrix, egal ob es sich um eine Linie, eine Ebene, einen 3D-Raum oder etwas anderes handelt, wird als Spaltenraum deiner Matrix bezeichnet.",
  "model": "DeepL",
  "from_community_srt": "Diese Menge aller möglichen Ausgaben Ihrer Matrix, ob Gerade, Ebene, 3D-Raum, was auch immer, heißt der \"Lösungsraum\" (hier \"Zeilenraum\") Ihrer Matrix.",
  "n_reviews": 0,
  "start": 534.52,
  "end": 542.72
 },
 {
  "input": "You can probably guess where that name comes from.",
  "translatedText": "Du kannst dir wahrscheinlich denken, woher der Name kommt.",
  "model": "DeepL",
  "from_community_srt": "Ihr können euch vermutlich denken,",
  "n_reviews": 0,
  "start": 544.14,
  "end": 546.28
 },
 {
  "input": "The columns of your matrix tell you where the basis vectors land, and the span of those transformed basis vectors gives you all possible outputs.",
  "translatedText": "Die Spalten deiner Matrix sagen dir, wo die Basisvektoren landen, und die Spannweite dieser transformierten Basisvektoren gibt dir alle möglichen Ausgaben.",
  "model": "DeepL",
  "from_community_srt": "wo der Name herkommt. Die Spalten eurer Matrix sagen euch, wo die Basisvektoren landen, und die lineare Hülle der Abbildungen dieser Basisvektoren enthält alle möglichen Ausgaben.",
  "n_reviews": 0,
  "start": 546.56,
  "end": 555.84
 },
 {
  "input": "In other words, the column space is the span of the columns of your matrix.",
  "translatedText": "Mit anderen Worten: Der Spaltenraum ist die Spannweite der Spalten in deiner Matrix.",
  "model": "DeepL",
  "from_community_srt": "Mit anderen Worten, der Spaltenraum ist die lineare Hülle der Spalten der Matrix.",
  "n_reviews": 0,
  "start": 556.36,
  "end": 561.14
 },
 {
  "input": "So a more precise definition of rank would be that it's the number of dimensions in the column space.",
  "translatedText": "Eine genauere Definition des Rangs wäre also, dass es die Anzahl der Dimensionen im Spaltenraum ist.",
  "model": "DeepL",
  "from_community_srt": "Also wäre eine präzisere Definition des Rangs, dass er die Anzahl der Dimensionen im Spaltenraum/Lösungsraum bezeichnet.",
  "n_reviews": 0,
  "start": 563.3,
  "end": 568.94
 },
 {
  "input": "When this rank is as high as it can be, meaning it equals the number of columns, we call the matrix full rank.",
  "translatedText": "Wenn dieser Rang so hoch wie möglich ist, d.h. er entspricht der Anzahl der Spalten, nennen wir die Matrix Full Rank.",
  "model": "DeepL",
  "from_community_srt": "Wenn dieser Rang maximal hoch ist, also der Anzahl an Spalten entspricht,",
  "n_reviews": 0,
  "start": 569.94,
  "end": 576.12
 },
 {
  "input": "Notice the zero vector will always be included in the column space, since linear transformations must keep the origin fixed in place.",
  "translatedText": "Beachte, dass der Nullvektor immer im Spaltenraum enthalten ist, da lineare Transformationen den Ursprung festhalten müssen.",
  "model": "DeepL",
  "from_community_srt": "hat die Matrix \"vollen Rang\". Merke: Der Nullvektor wird immer im Lösungsraum enthalten sein, da lineare Transformationen den Ursprung nicht verschieben dürfen.",
  "n_reviews": 0,
  "start": 578.54,
  "end": 585.84
 },
 {
  "input": "For a full rank transformation, the only vector that lands at the origin is the zero vector itself.",
  "translatedText": "Bei einer vollständigen Rangtransformation ist der einzige Vektor, der im Ursprung landet, der Nullvektor selbst.",
  "model": "DeepL",
  "from_community_srt": "Für eine Abbildung mit vollem Rang ist der einzige Vektor, der auf dem Ursprung landet,",
  "n_reviews": 0,
  "start": 586.9,
  "end": 591.96
 },
 {
  "input": "But for matrices that aren't full rank, which squish to a smaller dimension, you can have a whole bunch of vectors that land on zero.",
  "translatedText": "Aber bei Matrizen, die nicht vollwertig sind und die sich auf eine kleinere Dimension verkleinern, kannst du eine ganze Reihe von Vektoren haben, die auf Null landen.",
  "model": "DeepL",
  "from_community_srt": "der Nullvektor selbst, aber für Matrizen, die nicht vollen Rang haben, also auf eine kleinere Dimension quetschen, kann es ganz viele Vektoren geben,",
  "n_reviews": 0,
  "start": 592.46,
  "end": 598.76
 },
 {
  "input": "If a 2D transformation squishes space onto a line, for example, there is a separate line in a different direction full of vectors that get squished onto the origin.",
  "translatedText": "Wenn eine 2D-Transformation den Raum zum Beispiel auf eine Linie quetscht, gibt es eine separate Linie in eine andere Richtung voller Vektoren, die auf den Ursprung gequetscht werden.",
  "model": "DeepL",
  "from_community_srt": "die auf 0 landen. Wenn eine 2D-Transformation den Raum z.B. auf eine Gerade quetscht, dann gibt es eine separate Gerade in eine andere Richtung, voller Vektoren,",
  "n_reviews": 0,
  "start": 601.64,
  "end": 610.58
 },
 {
  "input": "If a 3D transformation squishes space onto a plane, there's also a full line of vectors that land on the origin.",
  "translatedText": "Wenn eine 3D-Transformation den Raum auf eine Ebene quetscht, gibt es auch eine ganze Reihe von Vektoren, die auf dem Ursprung landen.",
  "model": "DeepL",
  "from_community_srt": "die auf den Ursprung abgebildet werden. Wenn eine 3D-Abbildung den Raum auf eine Ebene quetscht, gibt es auch eine ganze Gerade voller Vektoren,",
  "n_reviews": 0,
  "start": 611.78,
  "end": 617.62
 },
 {
  "input": "If a 3D transformation squishes all of space onto a line, then there's a whole plane full of vectors that land on the origin.",
  "translatedText": "Wenn eine 3D-Transformation den gesamten Raum auf eine Linie quetscht, dann gibt es eine ganze Ebene voller Vektoren, die auf dem Ursprung landen.",
  "model": "DeepL",
  "from_community_srt": "die auf dem Ursprung landen. Wenn eine 3D-Abbildung den gesamten Raum auf eine Ebene abbildet, gibt es eine ganze Ebene voller Vektoren,",
  "n_reviews": 0,
  "start": 620.52,
  "end": 627.46
 },
 {
  "input": "This set of vectors that lands on the origin is called the null space, or the kernel of your matrix.",
  "translatedText": "Die Menge der Vektoren, die auf dem Ursprung landet, nennt man den Nullraum oder den Kern deiner Matrix.",
  "model": "DeepL",
  "from_community_srt": "die auf dem Ursprung landen. Diese Vektor-Menge, die auf dem Ursprung landet, nennt man  \"Nullraum\" oder \"Kern\" dieser Matrix.",
  "n_reviews": 0,
  "start": 632.8,
  "end": 638.78
 },
 {
  "input": "It's the space of all vectors that become null, in the sense that they land on the zero vector.",
  "translatedText": "Es ist der Raum aller Vektoren, die null werden, in dem Sinne, dass sie auf dem Nullvektor landen.",
  "model": "DeepL",
  "from_community_srt": "Es ist der Raum aller Vektoren, die zu Null werden, was heißt,",
  "n_reviews": 0,
  "start": 639.36,
  "end": 644.18
 },
 {
  "input": "In terms of the linear system of equations, when v happens to be the zero vector, the null space gives you all of the possible solutions to the equation.",
  "translatedText": "In Bezug auf das lineare Gleichungssystem gibt dir der Nullraum alle möglichen Lösungen der Gleichung, wenn v der Nullvektor ist.",
  "model": "DeepL",
  "from_community_srt": "dass sie auf dem Nullvektor landen. Was das lineare Gleichungssystem angeht, sollte  v der Nullvektor sein, gibt der Nullraum aller möglichen Lösungen dieser Gleichung an.",
  "n_reviews": 0,
  "start": 645.68,
  "end": 653.64
 },
 {
  "input": "So that's a very high level overview of how to think about linear systems of equations geometrically.",
  "translatedText": "Das ist also ein sehr grober Überblick darüber, wie man über lineare Gleichungssysteme geometrisch denkt.",
  "model": "DeepL",
  "from_community_srt": "Das war ein recht hochsprachlicher Überblick, wie man sich lineare Gleichungssysteme geometrisch vorstellen kann.",
  "n_reviews": 0,
  "start": 656.42,
  "end": 661.72
 },
 {
  "input": "Each system has some kind of linear transformation associated with it, and when that transformation has an inverse, you can use that inverse to solve your system.",
  "translatedText": "Jedem System ist eine lineare Transformation zugeordnet, und wenn diese Transformation eine Umkehrung hat, kannst du diese Umkehrung verwenden, um dein System zu lösen.",
  "model": "DeepL",
  "from_community_srt": "Jedes System besitzt irgendeine lineare Abbildung und wenn diese Abbildung ein Inverses hat, kann man dieses Inverse nutzen,",
  "n_reviews": 0,
  "start": 662.3,
  "end": 670.74
 },
 {
  "input": "Otherwise, the idea of column space lets us understand when a solution even exists, and the idea of a null space helps us to understand what the set of all possible solutions can look like.",
  "translatedText": "Ansonsten hilft uns die Idee des Spaltenraums zu verstehen, wann eine Lösung überhaupt existiert, und die Idee des Nullraums hilft uns zu verstehen, wie die Menge aller möglichen Lösungen aussehen kann.",
  "model": "DeepL",
  "from_community_srt": "um das System zu lösen. Andererseits lässt uns die Idee eines Lösungsraums verstehen, wann es eine Lösung überhaupt gibt, und die Idee des Nullraums hilft uns zu verstehen, wie die Menge aller möglichen Lösungen  aussehen kann.",
  "n_reviews": 0,
  "start": 672.28,
  "end": 683.44
 },
 {
  "input": "Again, there's a lot that I haven't covered here, most notably how to compute these things.",
  "translatedText": "Auch hier gibt es vieles, was ich nicht behandelt habe, vor allem, wie man diese Dinge berechnet.",
  "model": "DeepL",
  "from_community_srt": "Nochmal, es gibt vieles, das ich hier nicht behandelt habe, vor allem, wie man diese Dinger berechnet.",
  "n_reviews": 0,
  "start": 684.98,
  "end": 689.38
 },
 {
  "input": "I also had to limit my scope to examples where the number of equations equals the number of unknowns.",
  "translatedText": "Außerdem musste ich mich auf Beispiele beschränken, bei denen die Anzahl der Gleichungen gleich der Anzahl der Unbekannten ist.",
  "model": "DeepL",
  "from_community_srt": "Ich musste mich auch auf Beispiele beschränken, in denen die Anzahl der Gleichungen der Anzahl der Unbekannten entsprach.",
  "n_reviews": 0,
  "start": 689.8,
  "end": 694.76
 },
 {
  "input": "But the goal here is not to try to teach everything, it's that you come away with a strong intuition for inverse matrices, column space, and null space, and that those intuitions make any future learning that you do more fruitful.",
  "translatedText": "Das Ziel ist nicht, dir alles beizubringen, sondern dass du ein starkes Gespür für inverse Matrizen, Spaltenraum und Nullraum bekommst und dass dieses Gespür dein weiteres Lernen fruchtbarer macht.",
  "model": "DeepL",
  "from_community_srt": "Aber das Ziel ist nicht, alles zu behandeln; sondern dass ihr ein starkes Gefühl dafür bekommt, was Inverse Matrizen, Lösungsraum und Nullraum sind, und dass dieses Gefühl euch euer weiteres Lernen erleichtert.",
  "n_reviews": 0,
  "start": 694.88,
  "end": 706.5
 },
 {
  "input": "Next video, by popular request, will be a brief footnote about non-square matrices.",
  "translatedText": "Das nächste Video wird auf vielfachen Wunsch eine kurze Fußnote über nicht-quadratische Matrizen sein.",
  "model": "DeepL",
  "from_community_srt": "Das nächste Video wird aufgrund der großen Nachfrage eine kurze Fußnote zu nichtquadratischen Matrizen sein.",
  "n_reviews": 0,
  "start": 707.66,
  "end": 711.88
 },
 {
  "input": "Then after that, I'm going to give you my take on dot products, and something pretty cool that happens when you view them under the light of linear transformations.",
  "translatedText": "Danach werde ich dir meine Sicht auf Punktprodukte erläutern und dir etwas ziemlich Cooles zeigen, das passiert, wenn du sie unter dem Licht von linearen Transformationen betrachtest.",
  "model": "DeepL",
  "from_community_srt": "Dann, danach, werde ich meinen Versuch mit Kreuzprodukten liefern. und etwas ziemlich cooles, das passiert, wenn man sie aus dem Blickwinkel linearer Abbildungen sieht.",
  "n_reviews": 0,
  "start": 711.88,
  "end": 719.66
 }
]