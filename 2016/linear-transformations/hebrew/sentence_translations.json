[
 {
  "input": "Hey everyone!",
  "translatedText": "היי לכולם!",
  "model": "google_nmt",
  "from_community_srt": "למרצה הצער, אי אפשר להגיד לאף אחד מהו ה\"מטריקס\". אתה חייב לראות זאת בעצמך. -מורפיאוס(מהסרט \"מטריקס\") (למרבה הפלא, אלה הלן מילים מתאימות לתיאור חשיבות ההבנה הויזואלית של פעולות על המטריצה(שבאנגלית זה \"מטריקס\")). שלום לכולם!",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "אם הייתי צריך לבחור רק נושא אחד שגורם לכל האחרים באלגברה ליניארית להתחיל ללחוץ, ולעתים קרובות מדי לא נלמד בפעם הראשונה שתלמיד לוקח אלגברה ליניארית, זה היה זה.",
  "model": "google_nmt",
  "from_community_srt": "אם הייתי צריך לבחור רק נושא אחד שיגרום לכל שאר הנושאים באלגברה הלינארית להתחבר. שלעיתים קרובות מדיי לא מלמדים סטודנט בפעם הראשונה שהוא בוחר לעשות אלגברה לינארית. זה היה הנושא הזה:",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "הרעיון של טרנספורמציה לינארית והקשר שלה למטריצות.",
  "model": "google_nmt",
  "from_community_srt": "הרעיון של טרנספורמציה לינארית(ט\"ל) והקשר של זה למטריצות.",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "עבור הסרטון הזה, אני רק הולך להתמקד איך הטרנספורמציות האלה נראות במקרה של שני מימדים, וכיצד הן קשורות לרעיון של כפל וקטור מטריצה.",
  "model": "google_nmt",
  "from_community_srt": "בסירטון זה, אני רק הולך לדבר על איך הטרנספורמציות הללו נראות במרחב הדו-מימדי. ואיך הן מתקשרות לרעיון של כפל מטריצות.",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "במיוחד, אני רוצה להראות לכם דרך לחשוב על כפל וקטור מטריצה שאינו מסתמך על שינון.",
  "model": "google_nmt",
  "from_community_srt": "במיוחד, אני רוצה להראות לך דרך לחשוב על כפל מטריצה בוקטור שלא מסתמך על זיכרון.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "כדי להתחיל, בואו ננתח את המונח הזה, טרנספורמציה ליניארית.",
  "model": "google_nmt",
  "from_community_srt": "בתור התחלה, בוא פשוט ננסח את המושג \"טרנספורמציה לינארית\".",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "טרנספורמציה היא בעצם מילה מפוארת לפונקציה.",
  "model": "google_nmt",
  "from_community_srt": "\"טרנספורמציה\" היא פשוט שם מפוצץ עבור המילה \"פונקציה\".",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "זה משהו שקולט תשומות ויורק פלט לכל אחד.",
  "model": "google_nmt",
  "from_community_srt": "זה משהו שמקבל(קלט) נתונים שונים ומוציא(פלט) תוצאה עבור כל אחד מאותם נתונים.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "באופן ספציפי, בהקשר של אלגברה לינארית, אנחנו אוהבים לחשוב על טרנספורמציות שמקבלות וקטור כלשהו וירוקות וקטור אחר.",
  "model": "google_nmt",
  "from_community_srt": "באופן מפורש בהקשר של אלגברה לינארית, אנחנו אוהבים לחשוב על טרנספורמציה שקולטת וקטור מסוים ופולטת וקטור אחר.",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "אז למה להשתמש במילה טרנספורמציה במקום פונקציה אם הם מתכוונים לאותו הדבר?",
  "model": "google_nmt",
  "from_community_srt": "אז למה אנחנו משתמשים במילה \"טרנספורמציה\" במקום \"פונקציה\" אם הם בעצם אותו דבר? ובכן..",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "ובכן, זה לרמז על דרך מסוימת להמחיש את יחס הקלט-פלט הזה.",
  "model": "google_nmt",
  "from_community_srt": "בדרך מסויימת זה יהיה מפתה לדמיין את היחס בין הקלט והפלט.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "אתה מבין, דרך מצוינת להבין פונקציות של וקטורים היא להשתמש בתנועה.",
  "model": "google_nmt",
  "from_community_srt": "אתה מבין, דרך טובה להבין פונקציות של וקטורים היא להשתמש בתנועה.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "אם טרנספורמציה לוקחת וקטור קלט כלשהו לוקטור פלט כלשהו, אנו מדמיינים אותו וקטור קלט עובר לוקטור הפלט.",
  "model": "google_nmt",
  "from_community_srt": "אם טרנספורמציה לוקחת קלט של וקטור בשביל פלט של וקטור אחר, אנחנו מדמיינים קלט של וקטור שנע לעבר הוקטור בפלט.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "ואז כדי להבין את הטרנספורמציה בכללותה, אנו עשויים לדמיין לראות כל וקטור קלט אפשרי עובר לוקטור הפלט המתאים לו.",
  "model": "google_nmt",
  "from_community_srt": "אז כדי להבין את הטרנספורמציה באופן מלא, אנחנו אולי נצטרך לדמיין כל אפשרות בה קלט של וקטור נע לכיוון הוקטור המתאים לו בפלט.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "זה נהיה ממש צפוף לחשוב על כל הוקטורים בבת אחת, כל אחד כחץ.",
  "model": "google_nmt",
  "from_community_srt": "זה נהיה ממש צפוף לחשוב על כל הוקטורים הללו בבת אחת, לכל אחד מהם יש חץ, אז,",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "אז כפי שציינתי את הסרטון האחרון, טריק נחמד הוא להמשיג כל וקטור לא כחץ, אלא כנקודה בודדת, הנקודה שבה הקצה שלו יושב.",
  "model": "google_nmt",
  "from_community_srt": "כמו שהזכרתי בסירטון הקודם, טריק נחמד כדי לפשט את הרעיון. זה לא לחשוב על וקטור כחץ, אלא כנקודה בודדת. נקודה בה הקצה שלה יושב.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "בדרך זו, כדי לחשוב על טרנספורמציה שלוקחת כל וקטור קלט אפשרי לוקטור פלט כלשהו, אנו צופים בכל נקודה בחלל נעה לנקודה אחרת.",
  "model": "google_nmt",
  "from_community_srt": "הדרך הזו לחשוב על טרנספורמציה שבה נכניס(קלט) כל וקטור אפשרי ונקבל וקטור כלשהו(פלט), ע\"י כך אנחנו מסתכלים על כל נקודה שנעה במרחב לנקודה מסויימת אחרת.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "במקרה של טרנספורמציות בשני מימדים, כדי לקבל תחושה טובה יותר של כל הצורה של הטרנספורמציה, אני אוהב לעשות זאת עם כל הנקודות על רשת אינסופית.",
  "model": "google_nmt",
  "from_community_srt": "במקרה הזה, הטרנספורמציה היא בשני-מימדים. כדי לקבל תחושה יותר טובה עבור כל ה\"הצורה\" כולה של הטרנספורמציה, אני רוצה לעשות זאת עם כל הנקודות שנמצאות על רשת אינסופית.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "אני גם אוהב לפעמים לשמור עותק של הרשת ברקע, רק כדי לעזור לעקוב אחר היכן הכל נגמר ביחס למקום שבו הוא מתחיל.",
  "model": "google_nmt",
  "from_community_srt": "אני לפעמים אוהב לשמור עותק של הרשת ברקע, זה פשוט עוזר לשמור על מעקב איפה שכל דבר שהסתיים נמצא יחסית לאיפה שהתחיל.",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "ההשפעה של טרנספורמציות שונות הנעות סביב כל הנקודות בחלל היא, אתה חייב להודות, יפה.",
  "model": "google_nmt",
  "from_community_srt": "ההשפעה של הטרנספורמציות השונות, זזות סביב הנקודות במרחב, הוא, אתה חייב להודות,",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "זה נותן תחושה של מעיכה ושינוי החלל עצמו.",
  "model": "google_nmt",
  "from_community_srt": "יפיפה. זה נותן את ההרגשה של למחוץ ולשנות את המרחב עצמו.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "כפי שאתה יכול לדמיין, טרנספורמציות שרירותיות יכולות להיראות די מסובכות.",
  "model": "google_nmt",
  "from_community_srt": "כפי שתוכל לדמיין,",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "אבל למרבה המזל, אלגברה לינארית מגבילה את עצמה לסוג מיוחד של טרנספורמציה, כאלה שקל יותר להבין, הנקראות טרנספורמציות ליניאריות.",
  "model": "google_nmt",
  "from_community_srt": "למרות שטרנספורמציות שרירותיות יכולות להיראות מסובכות, אבל למזלנו אלגברה לינארית בעצמה היא סוג של טרנספורמציה מיוחדת, כאלה שקל יותר להבינן, נקראות טרנספורמציות \"לינארית\".",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "מבחינה ויזואלית, טרנספורמציה היא ליניארית אם יש לה שתי תכונות.",
  "model": "google_nmt",
  "from_community_srt": "מתוך נקודת מבט חזותית,",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "כל הקווים חייבים להישאר קווים מבלי להתעקם, והמקור חייב להישאר קבוע במקומו.",
  "model": "google_nmt",
  "from_community_srt": "טרנספורמציה היא לינארית אם יש לה שתי תכונות: כל הקווים נשארים קווים, בלי שיתעקמו, והראשית שלהם נשאר מקובע במקום.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "לדוגמה, זה כאן לא יהיה טרנספורמציה ליניארית, מכיוון שהקווים מתעקלים לגמרי.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, מה שכאן לא יהיה טרנספורמציה לינארית מכיוון שכל הקווים מתעקמים ומה שנמצא כאן,",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "וזה כאן, למרות שהוא שומר על הקווים ישרים, הוא לא טרנספורמציה ליניארית, כי הוא מזיז את המקור.",
  "model": "google_nmt",
  "from_community_srt": "למרות שזה שומר על קוו ישר, זה לא טרנספורמציה לינארית בגלל שזה נע מהראשית(לא מקובע למקום).",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "זה כאן מתקן את המקור, וזה אולי נראה כאילו הוא שומר קווים ישרים, אבל זה רק בגלל שאני מראה רק את קווי הרשת האופקיים והאנכיים.",
  "model": "google_nmt",
  "from_community_srt": "מה שכאן מקובע לראשית ונראה שזה ישמור על קו ישר, אבל זה רק בגלל שאני מראה לכם את הקווים האנכיים והאופקיים,",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "כאשר אתה רואה מה זה עושה לקו אלכסוני, מתברר שהוא בכלל לא ליניארי, מכיוון שהוא הופך את הקו הזה לעקום כולו.",
  "model": "google_nmt",
  "from_community_srt": "כשתראה מה זה עושה לקו אלכסוני, זה נהיה ברור שזה בכלל לא לינארי בגלל שהכל כולו נהיה עקום.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "באופן כללי, עליך לחשוב על טרנספורמציות ליניאריות כשמירה על קווי רשת מקבילים ומרווחים באופן שווה.",
  "model": "google_nmt",
  "from_community_srt": "באופן כללי, אתה צריך לחשוב על טרנספורמציות לינארית בתור דרך לשמור על הרשת מקבילה(אנכי ואופקי) ומחולקת באופן שווה.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "כמה טרנספורמציות ליניאריות קלות לחשוב עליהן, כמו סיבובים לגבי המקור.",
  "model": "google_nmt",
  "from_community_srt": "יש כמה טרנספורמציות לינאריות שקל לחשוב עליהן, כמו סיבוב ראשית הצירים.",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "אחרים קצת יותר מסובכים לתאר במילים.",
  "model": "google_nmt",
  "from_community_srt": "יש כאלה שקצת מסובך יותר להסביר אותן במילים.",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "אז איך אתה חושב שאתה יכול לתאר את התמורות הללו באופן מספרי?",
  "model": "google_nmt",
  "from_community_srt": "אז איך אתתה חושב שתוכל לתאר את הטרנספורמציות האלה בצורה מספרית? בוא נניח שאתה,",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "אם הייתם, נניח, מתכנתים כמה אנימציות כדי ליצור סרטון שמלמד את הנושא, איזו נוסחה אתם נותנים למחשב כדי שאם תתנו לו את הקואורדינטות של וקטור, הוא יוכל לתת לכם את הקואורדינטות של המקום שבו אותו וקטור נוחת?",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, מתכנן אנימציות כדי לעשות סירטון שמדבר על הנושא הנ\"ל איזו נוסחה היית נותן למחשב כך שאם תיתן לו קואורדינטות של וקטור,",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "מסתבר שאתה רק צריך לרשום איפה שני וקטורי הבסיס, i-hat ו-j-hat, כל ארץ, וכל השאר יבואו בעקבות זה.",
  "model": "google_nmt",
  "from_community_srt": "זה יתן לך קואורדינטות של איפה שהוקטור הזה ינחת? מסתבר שאתה לשמור רק על וקטורי הבסיס, i כובע ו-j כובע, כל אחד מהם נוחת וכל דבר אחר ימשיך משם.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "לדוגמה, קחו בחשבון את הווקטור v עם קואורדינטות שליליות 1, 2, כלומר הוא שווה לשלילי 1 כפול i-hat ועוד 2 כפול j-hat.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, ניקח את הוקטור v עם הקואורדינטות (1,2-), הכוונה שזה שווה -1 כפול ה-i כובע 2+ כפול ה-j כובע.",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "אם נשחק טרנספורמציה כלשהי ונעקוב לאן הולכים כל שלושת הוקטורים הללו, לתכונה שקווי הרשת נשארים מקבילים ומרווחים באופן שווה יש תוצאה חשובה מאוד.",
  "model": "google_nmt",
  "from_community_srt": "אם נשחק קצת עם הטרנספורמציה ונעקוב אחרי איפה שהוקטורים הללו ממשיכים התכונה של קווי הרשת ישמרו עליהם(וקטורים) מקבילים ומרווחים בצורה שווה היא בעלת השלכה חשובה:",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "המקום בו ינחת v יהיה שלילי פי 1 מהווקטור שבו נחת i-hat ועוד פי 2 מהווקטור שבו נחת j-hat.",
  "model": "google_nmt",
  "from_community_srt": "המקום בו v נוחת יהיה 1- כפול הוקטור איפה ש-i כובע נחת 2+ כפול הוקטור איפה ש-j כובע נחת.",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "במילים אחרות, זה התחיל כשילוב ליניארי מסוים של i-hat ו-j-hat, והוא מסתיים באותו שילוב ליניארי של המקום שבו שני הוקטורים הללו נחתו.",
  "model": "google_nmt",
  "from_community_srt": "במילים אחרות, זה התחיל כצירוף לינארי ודאי של i כובע ו-j כובע וזה נגמר  עם הצירוף הלינארי - איפה ששני הוקטורים הללו נחתו.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "זה אומר שאתה יכול להסיק לאן v חייב ללכת רק על סמך היכן i-hat ו-j-hat כל ארץ.",
  "model": "google_nmt",
  "from_community_srt": "זה אומר שאתה יכול להסיק מכך איפה הוקטור v צריך להיות על סמך איפה ש-i כובע ו-j כובע נחתו.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "זו הסיבה שאני אוהב לשמור עותק של הרשת המקורית ברקע.",
  "model": "google_nmt",
  "from_community_srt": "זה למה אני אוהב לשמור עותק של הרשת המקורית ברקע(עם המשבצות); עבור הטרנספורמציה שאני מראה כאן,",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "עבור הטרנספורמציה המוצגת כאן, אנו יכולים לקרוא ש-i-hat נוחת על הקואורדינטות 1, שלילית 2, ו-j-hat נוחת על ציר ה-x מעל בקואורדינטות 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "אנחנו יכולים לקרוא ש-i כובע נוחת על הקוארדינטות (2-,1) ו- j כובע נוחת על ציר ה-x על הקוארדינטות (3,0).",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "משמעות הדבר היא שהווקטור המיוצג על ידי שלילי 1 i-hat פלוס 2 כפול j-hat מסתיים בשלילי 1 כפול הווקטור 1, שלילי 2 פלוס 2 כפול הווקטור 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "זה אומר שאפשר להציג את הוקטור כ(1-) i כובע + 2 כפול j כובע שנגמר ב-(1-) כפול הוקטור (2-,1) ועוד 2 כפול הוקטור (3,0)",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "אם מוסיפים את זה ביחד, אתה יכול להסיק שהוא צריך לנחות על הווקטור 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "ע\"י חיבור כל הדברים האלה יחדיו,",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "זו נקודה טובה לעצור ולהרהר, כי זה די חשוב.",
  "model": "google_nmt",
  "from_community_srt": "אתה יכול להסיק מכך שזה נחתד על הוקטור (5,2). זו נקודה טובה להשתהות בה קצת ולהרהר,",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "עכשיו, בהתחשב בכך שאני בעצם מראה לך את השינוי המלא, יכולת פשוט להסתכל כדי לראות של-v יש את הקואורדינטות 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "בגלל שזה מאוד חשוב. עכשיו, בהנחה שאני באמת מראה לך את הטרנספורמציה המלאה,",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "אבל החלק המגניב כאן הוא שזה נותן לנו טכניקה להסיק היכן כל הווקטורים נוחתים כל עוד יש לנו תיעוד של היכן i-hat ו-j-hat כל ארץ מבלי שנצטרך לצפות בטרנספורמציה עצמה.",
  "model": "google_nmt",
  "from_community_srt": "אתה פשוט יכולת להסתכל על הוקטור v בעל הקוארדינטות (5,2), אבל החלק המגניב כאן שזה נותן לנו טכניקה להסיק איפה הוקטורים ינחתו, כל עוד ידוע לנו איפה i כובע ו-j כובע ינחתו, מבלי להצטרך לצפות בטרנספורמציה עצמה.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "כתוב את הווקטור עם קואורדינטות כלליות יותר, x ו-y, והוא ינחת על x כפול הווקטור שבו נוחת i-hat, 1, שלילי 2, פלוס y כפול הווקטור שבו j-hat נוחת, 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "תכתוב את הוקטור עם קוארדינטות יותר כלליות - x ו-y, זה ינחת על x כפול הוקטור איפה ש-i כובע נוחת (2-,1), ועוד y כפול הוקטור איפה ש-j כובע נוחת (3,0) ע\"י ביצוע חישוב הסכום,",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "ביצוע הסכום הזה, אתה רואה שהוא נוחת ב-1x פלוס 3y, שלילי 2x פלוס 0y.",
  "model": "google_nmt",
  "from_community_srt": "אתה יכול לראות שזה נוחת ב- (1x+3y,",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "אני נותן לך כל וקטור, ואתה יכול להגיד לי איפה הווקטור הזה נוחת באמצעות הנוסחה הזו.",
  "model": "google_nmt",
  "from_community_srt": "-2x+0y) אני אתן לך כל וקטור, ואתה תוכל להגיד לי, ע\"י שימוש בנוסחה,",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "מה שכל זה אומר הוא שטרנספורמציה ליניארית דו-ממדית מתוארת לחלוטין על ידי ארבעה מספרים בלבד, שתי הקואורדינטות למקום שבו נוחת i-hat ושתי הקואורדינטות למקום שבו נוחת j-hat.",
  "model": "google_nmt",
  "from_community_srt": "איפה הוקטור הזה ינחת מה שכל זה אומר זה שטרנספורמציה לינארית דו-מימדית היא מתוארת לחלוטין רק ע\"י ארבעה מספרים: ה-2 קוארדינטות איפה ש-i כובע נוחת ו-2 קוארדינטות איפה ש-j כובע נוחת.",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "זה לא מגניב?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "מקובל לארוז את הקואורדינטות הללו לרשת של מספרים בגודל 2x2 הנקראת מטריצה 2x2, שבה אתה יכול לפרש את העמודות כשני הוקטורים המיוחדים שבהם i-hat ו-j-hat כל אחד נחת.",
  "model": "google_nmt",
  "from_community_srt": "האם זה לא מגניב? זה נפוץ ל\"ארוז\" את הקוארדינטות האלה בארגז של מספרים 2 על 2, שנקרא מטריצה 2 על 2(2x2). בעוד שאתה יכול לפרש את העמודות כ-2 וקטורים מיוחדים איפה ש-i כובע ו-j כובע נוחתים.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "אם ניתנת לך מטריצה 2x2 המתארת טרנספורמציה ליניארית וקטור ספציפי כלשהו, ואתה רוצה לדעת היכן אותה טרנספורמציה לינארית לוקחת את הווקטור הזה, תוכל לקחת את הקואורדינטות של הווקטור, להכפיל אותן בעמודות המתאימות של המטריצה, ואז תחבר את מה שאתה מקבל.",
  "model": "google_nmt",
  "from_community_srt": "אם נתון לך מטריצה 2 על 2, המתארת טרנספורמציה לינארית ואיזשהו וקטור מסוים ואתה רוצה לדעת איפה הטרנספורמציה הלינארית הזאת לוקחת את הוקטור, אתה יכול לקחת את הקוארדינטות של הוקטור להכפיל אותן בעמודות המתאימות של המטריצה ואז לחבר ביחד את מה שתקבל.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "זה מתאים לרעיון של הוספת הגרסאות המוקטנות של וקטורי הבסיס החדשים שלנו.",
  "model": "google_nmt",
  "from_community_srt": "זה מתאים לרעיון של חיבור גירסאות שונות של וקטורי הבסיס שלנו אשר הוכפלו בסקלר.",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "בוא נראה איך זה נראה במקרה הכללי ביותר, שבו המטריצה שלך מכילה ערכים A, B, C, D.",
  "model": "google_nmt",
  "from_community_srt": "בוא נסתכל איך זה נראה עבור המקרה הכללי ביותר. כשלמטריצה יש ערכים:",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "וזכרו, המטריצה הזו היא רק דרך לארוז את המידע הדרוש לתיאור טרנספורמציה ליניארית.",
  "model": "google_nmt",
  "from_community_srt": "a,b,c,d ותזכור, המטריצה היא רק דרך אחת לארוז את המידע שאתה צריך תאר שהוא טרנספורמציה לינארית תמיד תזכור שפירוש העמודה הראשונה (a,c),",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "זכור תמיד לפרש את העמודה הראשונה, AC, כמקום בו וקטור הבסיס הראשון נוחת, ואת העמודה השנייה, BD, כמקום בו וקטור הבסיס השני נוחת.",
  "model": "google_nmt",
  "from_community_srt": "בתור המקום איפה שוקטור הבסיס הראשון נוחת ושהעמודה השניה, (b,d) היא המקום איפה שהוקטור הבסיס השני נוחת.",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "כאשר אנו מיישמים את הטרנספורמציה הזו על xy וקטור כלשהו, מה אתה מקבל?",
  "model": "google_nmt",
  "from_community_srt": "כשאנחנו משתמשים בטרנספורמציה לינארית לוקטור כלשהו (x,y),",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "ובכן, זה יהיה x פעמים AC פלוס y פעמים BD.",
  "model": "google_nmt",
  "from_community_srt": "מה אנחנו נקבל? ובכן, זה יהיה x כפול (a,c) ועוד y כפול (b,d).",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "חיבור זה יחד, אתה מקבל וקטור Axe פלוס By, Cx פלוס Dy.",
  "model": "google_nmt",
  "from_community_srt": "תחשב אותם יחד ותקבל וקטור (ax+by,",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "אתה יכול אפילו להגדיר זאת ככפל וקטור מטריצה, כאשר אתה שם את המטריצה בצד שמאל של הווקטור כאילו זו פונקציה.",
  "model": "google_nmt",
  "from_community_srt": "cx+dy). אתה תוכל אפילו להגדיר את זה בתור הכפלה של מטריצה בוקטור. כשאתה שם מטריצה מצד שמאל של הוקטור כאילו זה פונקציה.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "לאחר מכן, אתה יכול לגרום לתיכוניסטים לשנן את זה מבלי להראות להם את החלק המכריע שגורם לזה להרגיש אינטואיטיבי.",
  "model": "google_nmt",
  "from_community_srt": "ואז, אתה יכול לעשות כמו שהרבה מורים עושים - וזה לשנן זאת, מבלי להראות להם את החלק הקריטי שהופך את זה למשהו אינטואיטיבי.",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "אבל, האם לא כיף יותר לחשוב על העמודות הללו כעל הגרסאות המומרות של וקטורי הבסיס שלך, ולחשוב על התוצאה כשילוב הליניארי המתאים של אותם וקטורים?",
  "model": "google_nmt",
  "from_community_srt": "אבל, האם זה לא יותר כיף כאשר אתה חושב על העמודות הללו בתור גירסאות שונות של וקטורי הבסיס שלך שעברו טרנספורמציה ולחשוב על כל התוצאות בתור צירוף לינארי מתאים של הוקטורים הללו?",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "בואו נתאמן בתיאור כמה טרנספורמציות ליניאריות עם מטריצות.",
  "model": "google_nmt",
  "from_community_srt": "בוא נתאמן על תיאור כמה טרנספורמציה לינאריות ע\"י מטריצה.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "לדוגמה, אם נסובב את כל החלל ב-90 מעלות נגד כיוון השעון, אז i-hat נוחת על הקואורדינטות 0, 1.",
  "model": "google_nmt",
  "from_community_srt": "לדוגמא, אם נסובב את המרחב ב-90 מעלות כנגד כיוון השעון",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "ו-j-hat נוחת על הקואורדינטות השליליות 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "ואז ה-i כובע נוחת על הקוארדינטות (0,1) ו-j כובע נוחת על הקוארדינטות (1,0-) אז העמודות במטריצה שנקבל היא:",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "אז למטריצה שאיתה אנחנו מסיימים יש עמודות 0, 1, שליליות 1, 0.",
  "model": "google_nmt",
  "from_community_srt": ".(0, 1),",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "כדי להבין מה קורה לכל וקטור לאחר סיבוב של 90 מעלות, אתה יכול פשוט להכפיל את הקואורדינטות שלו במטריצה הזו.",
  "model": "google_nmt",
  "from_community_srt": "(-1, 0) כדי להבין מה יקרה לכל וקטור, לאחר סיבוב של 90 מעלות אתה פשוט יכול להכפיל את הקוארדינטות הללו במטריצה.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "הנה מהפך מהנה עם שם מיוחד, הנקרא גזירה.",
  "model": "google_nmt",
  "from_community_srt": "הנה טרנספורמציה כיפית עם שם מיוחד,",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "בו, i-hat נשאר קבוע, כך שהעמודה הראשונה של המטריצה היא 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "נקראת \"Shear\" בטרנספורמציה הזו,",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "אבל j-hat עובר לקואורדינטות 1, 1, שהופכות לעמוד השני של המטריצה.",
  "model": "google_nmt",
  "from_community_srt": "ה-i כובע נשאר במקום כך שהעמודה הראשונה של המטריצה היא (1,0), אבל ה-j כובע נע על הקוארדינטות (1,1) מה שהופך להיות העמודה השניה של המטריצה.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "ובסיכון להיות מיותר כאן, להבין כיצד גזירה הופכת וקטור נתון מסתכם בהכפלת המטריצה הזו בוקטור הזה.",
  "model": "google_nmt",
  "from_community_srt": "ו... , בסיכון שזה יהיה מיותר כאן, ההבנה של איך הטרנספורמציית SHEAR עובדת(עושה טרנספורמציה) על וקטור נתון בסופו של דבר היא הכפלה של המטריצה בוקטור הזה.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "נניח שאנחנו רוצים ללכת הפוך, החל ממטריצה, נניח עם עמודות 1, 2 ו-3, 1, ואנחנו רוצים להסיק איך נראית הטרנספורמציה שלה.",
  "model": "google_nmt",
  "from_community_srt": "בוא נגיד שאנחנו רוצים ללכת בדרך השניה מסביב, נתחיל עם המטריצה, למשל עם העמודות (1,2) ו-(3,1), ואנחנו רוצים להסיק איך הטרנספורמציה הזאת נראית בכלל.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "השהה וקח רגע כדי לראות אם אתה יכול לדמיין את זה.",
  "model": "google_nmt",
  "from_community_srt": "תפסיק לרגע את הסירטון ותיקח רגע לראות אם אתה יכול לדמיין את זה.",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "אחת הדרכים לעשות זאת היא תחילה להעביר את i-hat ל-1, 2, ואז להעביר את j-hat ל-3, 1.",
  "model": "google_nmt",
  "from_community_srt": "דרך אחת לעשות זאת זה קודם להזיז את i-כובע ל-(1,2). ואז, להזיז את j-כובע ל-(3,1).",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "הזזת תמיד את שאר החלל בצורה כזו שתשמור על קווי רשת מקבילים ומרווחים באופן שווה.",
  "model": "google_nmt",
  "from_community_srt": "תמיד להזיז את שאר המרחב בצורה כזו ש..",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "אם הוקטורים שעליהם נוחתים i-hat ו-j-hat תלויים ליניארית, מה שאם אתה זוכר מהסרטון האחרון, אומר שאחד הוא גרסה מוקטנת של השני, זה אומר שהטרנספורמציה הליניארית מוחצת את כל המרחב הדו-ממדי על קו שבו יושבים שני הוקטורים הללו, הידוע גם בתור הטווח החד-ממדי של שני הוקטורים התלויים ליניארית.",
  "model": "google_nmt",
  "from_community_srt": "שהיא שומרת על קווי הרשת מקבילים והמרווחים בין הקווים נשארים שווים אם הוקטורים של i-כובע ו-j-כובע נוחתים הם תלויים לינארית מכיוון, שאם אתה זוכר מהסירטון האחרון, זה אומר שאחד מהם הוא גירסה של הוקטור השני שפשוט הוכפל בסקלר(למשל בסירטון העמודה הימנית היא כפל בסקלר מינוס אחד של הוקטור בעמודה השמאלית). זה אומר שטרנספורמציה לינארית מועכת את כל המרחב הדו-מימדי לקו איפה שהשני וקטורים הללו יושבים, ידוע בתור הקבוצה הפורשת במרחב החד-מימדי של שני הוקטורים הללו שתלויים לינארית.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "לסיכום, טרנספורמציות ליניאריות הן דרך לנוע במרחב כך שקווי רשת יישארו מקבילים ומרווחים באופן שווה, וכזה שהמקור יישאר קבוע.",
  "model": "google_nmt",
  "from_community_srt": "לסיכום, טרנספורמציות לינארית הן דרך לזוז במרחב כך שהקווי הרשת נשארית מקבילים ועם מרווחים שווים זה מזה וכך שראשית הצירים שלהם נשאר במקום.",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "באופן מענג, ניתן לתאר את התמורות הללו באמצעות קומץ מספרים בלבד, הקואורדינטות של המקום שבו כל וקטור בסיס נוחת.",
  "model": "google_nmt",
  "from_community_srt": "באופן משמח. אפשר לתאר את הטרנספורמציות הללו ע\"י שימוש בכמה מספרים בלבד. הקוארדינטות שיגידו לנו איפה כל וקטורי הבסיס נוחתים.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "מטריצות נותנות לנו שפה לתאר את הטרנספורמציות הללו, כאשר העמודות מייצגות את הקואורדינטות הללו, וכפל מטריצה-וקטור היא רק דרך לחשב מה הטרנספורמציה הזו עושה לווקטור נתון.",
  "model": "google_nmt",
  "from_community_srt": "מטריצות שיתנו לנו שפה לתאר את הטרנספורמציות הללו כאשר העמודות מייצגות לנו את הקוארדינטות הללו והכפלה של מטריצה בוקטור זה פשוט דרך לחשב מה הטרנספורמציה עושה לוקטור נותן.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "הנקודה החשובה כאן היא שבכל פעם שאתה רואה מטריצה, אתה יכול לפרש אותה כטרנספורמציה מסוימת של החלל.",
  "model": "google_nmt",
  "from_community_srt": "דבר חשוב לקחת מכאן זה ש.. כל פעם שאתה רואה מטריצה, אתה יכול לפרש אותה כטרנספורמציה מסויימת של המרחב",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "ברגע שאתה באמת מעכל את הרעיון הזה, אתה בעמדה מצוינת להבין אלגברה לינארית לעומק.",
  "model": "google_nmt",
  "from_community_srt": "ברגע שאתה באמת מעכל את הרעיון, אתה בעמדה מצויינת להבין אלגברה לינארית בצורה עמוקה",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "כמעט כל הנושאים שעולים, מכפל מטריצה ועד דטרמיננטים, שינוי בסיס, ערכים עצמיים, כל אלה יהיו קלים יותר להבנה ברגע שתתחיל לחשוב על מטריצות כעל טרנספורמציות של מרחב.",
  "model": "google_nmt",
  "from_community_srt": "כמעט כל הנושאים שיבואו בהמשך, מכפל מטריצות לדטרמיננטה, שינוי בסיס, ערכים עצמיים(ע\"ע), כל אלה יהפכו להיות קלים יותר להבנה ברגע שאתה מתחיל לחשוב על מטריצות כטרנספורמציות של המרחב.",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "הכי מיד, בסרטון הבא, אדבר על הכפלת שתי מטריצות יחד.",
  "model": "google_nmt",
  "from_community_srt": "באופן הכי מיידי, בסירטון הבא אני אדבר על הכפלה 2 מטריצות ביחד.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]