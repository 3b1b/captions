[
 {
  "input": "Hey everyone! ",
  "translatedText": "مرحبا جميعا! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one. ",
  "translatedText": "إذا اضطررت إلى اختيار موضوع واحد فقط يجعل جميع المواضيع الأخرى في الجبر الخطي تبدأ في النقر، والتي غالبًا ما يتم تجاهلها في المرة الأولى التي يدرس فيها الطالب الجبر الخطي، فسيكون هذا الموضوع. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices. ",
  "translatedText": "فكرة التحويل الخطي وعلاقتها بالمصفوفات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication. ",
  "translatedText": "في هذا الفيديو، سأركز فقط على الشكل الذي تبدو عليه هذه التحويلات في حالة البعدين، وكيفية ارتباطها بفكرة ضرب متجهات المصفوفات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization. ",
  "translatedText": "على وجه الخصوص، أريد أن أوضح لك طريقة للتفكير في ضرب متجهات المصفوفات التي لا تعتمد على الحفظ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation. ",
  "translatedText": "للبدء، دعونا نحلل هذا المصطلح، التحويل الخطي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function. ",
  "translatedText": "التحول هو في الأساس كلمة خيالية للوظيفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one. ",
  "translatedText": "إنه شيء يأخذ المدخلات ويخرج مخرجات لكل منها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector. ",
  "translatedText": "على وجه التحديد، في سياق الجبر الخطي، نود أن نفكر في التحويلات التي تأخذ متجهًا ما وتنتج متجهًا آخر. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing? ",
  "translatedText": "فلماذا نستخدم كلمة &quot;تحويل&quot; بدلاً من &quot;وظيفة&quot; إذا كانت تعني نفس الشيء؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation. ",
  "translatedText": "حسنًا، هذا يشير إلى طريقة معينة لتصور العلاقة بين المدخلات والمخرجات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement. ",
  "translatedText": "كما ترى، إحدى الطرق الرائعة لفهم وظائف المتجهات هي استخدام الحركة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector. ",
  "translatedText": "إذا أخذ التحويل بعض متجهات الإدخال إلى بعض متجهات المخرجات، فإننا نتخيل أن متجه الإدخال ينتقل إلى متجه المخرجات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector. ",
  "translatedText": "ومن ثم، لفهم التحويل ككل، قد نتخيل مشاهدة كل متجهات الإدخال المحتملة تتحرك إلى متجهات المخرجات المقابلة لها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow. ",
  "translatedText": "يصبح الأمر مزدحمًا جدًا عند التفكير في جميع المتجهات في وقت واحد، كل منها على شكل سهم. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits. ",
  "translatedText": "لذا، كما ذكرت في الفيديو السابق، هناك خدعة رائعة وهي تصور كل متجه ليس كسهم ولكن كنقطة واحدة، النقطة التي يقع فيها طرفه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point. ",
  "translatedText": "بهذه الطريقة، للتفكير في تحويل ينقل كل متجه مدخلات محتمل إلى متجه مخرج ما، فإننا نشاهد كل نقطة في الفضاء تتحرك إلى نقطة أخرى. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid. ",
  "translatedText": "في حالة التحويلات في بعدين، للحصول على فكرة أفضل عن شكل التحويل بأكمله، أحب أن أفعل ذلك مع جميع النقاط الموجودة على شبكة لا نهائية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts. ",
  "translatedText": "أرغب أيضًا في بعض الأحيان في الاحتفاظ بنسخة من الشبكة في الخلفية فقط للمساعدة في تتبع المكان الذي ينتهي فيه كل شيء بالنسبة إلى المكان الذي يبدأ فيه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful. ",
  "translatedText": "إن تأثير التحولات المختلفة التي تتحرك حول جميع النقاط في الفضاء هو، عليك أن تعترف، بأنه جميل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself. ",
  "translatedText": "إنه يعطي شعوراً بالسحق وتحول الفضاء نفسه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated. ",
  "translatedText": "كما يمكنك أن تتخيل، يمكن أن تبدو التحولات التعسفية معقدة للغاية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations. ",
  "translatedText": "لكن لحسن الحظ، يقتصر الجبر الخطي على نوع خاص من التحويلات، تلك التي يسهل فهمها، والتي تسمى التحولات الخطية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties. ",
  "translatedText": "من الناحية المرئية، يكون التحويل خطيًا إذا كان له خاصيتين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place. ",
  "translatedText": "يجب أن تظل جميع الخطوط خطوطًا دون أن تنحني، ويجب أن يظل الأصل ثابتًا في مكانه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy. ",
  "translatedText": "على سبيل المثال، هذا هنا لن يكون تحويلًا خطيًا، نظرًا لأن الخطوط تصبح كلها متعرجة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin. ",
  "translatedText": "وهذا هنا، على الرغم من أنه يبقي الخطوط مستقيمة، إلا أنه ليس تحويلاً خطيًا، لأنه يحرك نقطة الأصل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines. ",
  "translatedText": "هذا هنا يصلح الأصل، وقد يبدو وكأنه يبقي الخطوط مستقيمة، ولكن هذا فقط لأنني أعرض فقط خطوط الشبكة الأفقية والعمودية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy. ",
  "translatedText": "عندما ترى ما يفعله بالخط القطري، يصبح من الواضح أنه ليس خطيًا على الإطلاق، لأنه يجعل هذا الخط متعرجًا بالكامل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced. ",
  "translatedText": "بشكل عام، يجب أن تفكر في التحويلات الخطية على أنها إبقاء خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin. ",
  "translatedText": "من السهل التفكير في بعض التحولات الخطية، مثل الدوران حول نقطة الأصل. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words. ",
  "translatedText": "البعض الآخر أصعب قليلاً في وصفه بالكلمات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So how do you think you could describe these transformations numerically? ",
  "translatedText": "إذًا، كيف تعتقد أنه يمكنك وصف هذه التحولات عدديًا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands? ",
  "translatedText": "إذا كنت، على سبيل المثال، تبرمج بعض الرسوم المتحركة لإنشاء مقطع فيديو يشرح الموضوع، ما هي الصيغة التي تعطيها للكمبيوتر بحيث إذا أعطيته إحداثيات متجه، فيمكنه أن يعطيك إحداثيات مكان وصول هذا المتجه؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that. ",
  "translatedText": "اتضح أنك تحتاج فقط إلى تسجيل مكان المتجهين الأساسيين، i-hat وj-hat، وكل أرض، وكل شيء آخر سيتبع ذلك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat. ",
  "translatedText": "على سبيل المثال، فكر في المتجه v بإحداثيات سالبة 1، 2، مما يعني أنه يساوي سالب 1 في i-hat زائد 2 في j-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence. ",
  "translatedText": "إذا أجرينا بعض التحويلات وتتبعنا أين تذهب هذه المتجهات الثلاثة، فإن خاصية بقاء خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ لها نتيجة مهمة حقًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed. ",
  "translatedText": "المكان الذي يهبط فيه v سيكون سالبًا 1 مضروبًا في المتجه الذي هبطت فيه i-hat بالإضافة إلى 2 مضروبًا في المتجه الذي هبطت فيه j-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed. ",
  "translatedText": "بعبارة أخرى، بدأ الأمر كتركيبة خطية معينة من i-hat وj-hat، وينتهي الأمر كمجموعة خطية نفسها التي هبط فيها هذان المتجهان. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land. ",
  "translatedText": "هذا يعني أنه يمكنك استنتاج المكان الذي يجب أن تذهب إليه v استنادًا فقط إلى مكان كل من i-hat وj-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background. ",
  "translatedText": "ولهذا السبب أحب الاحتفاظ بنسخة من الشبكة الأصلية في الخلفية. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0. ",
  "translatedText": "بالنسبة للتحويل الموضح هنا، يمكننا قراءة أن i-hat يقع على الإحداثيات 1، سالب 2، وj-hat يقع على المحور السيني عند الإحداثيات 3، 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0. ",
  "translatedText": "هذا يعني أن المتجه الذي يمثله سالب 1 i-hat زائد 2 مرات j-hat ينتهي عند سالب 1 ضرب المتجه 1، سالب 2 زائد 2 ضرب المتجه 3، 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2. ",
  "translatedText": "بإضافة كل ذلك معًا، يمكنك استنتاج أنه يجب أن يهبط على المتجه 5، 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important. ",
  "translatedText": "هذه نقطة جيدة للتوقف والتأمل، لأنها مهمة جدًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2. ",
  "translatedText": "الآن، بما أنني أعرض لكم التحويل الكامل، كان من الممكن أن تنظروا لتروا أن v لها الإحداثيات 5، 2. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself. ",
  "translatedText": "لكن الجزء الرائع هنا هو أن هذا يمنحنا تقنية لاستنتاج مكان هبوط أي متجهات طالما أن لدينا سجلًا لمكان هبوط كل من i-hat وj-hat، دون الحاجة إلى مشاهدة التحول نفسه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0. ",
  "translatedText": "اكتب المتجه بإحداثيات أكثر عمومية، x وy، وسيستقر على x مضروبًا في المتجه حيث هبط i-hat، 1، سالب 2، بالإضافة إلى y مضروبًا في المتجه حيث هبط j-hat، 3، 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y. ",
  "translatedText": "بتنفيذ هذا المجموع، ترى أنه يصل إلى 1x زائد 3y، سالب 2x زائد 0y. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula. ",
  "translatedText": "سأعطيك أي متجه، ويمكنك أن تخبرني أين يقع هذا المتجه باستخدام هذه الصيغة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands. ",
  "translatedText": "ما يعنيه كل هذا هو أن التحويل الخطي ثنائي الأبعاد موصوف بالكامل بأربعة أرقام فقط، الإحداثيان للمكان الذي يهبط فيه i-hat، والإحداثيان للمكان الذي يهبط فيه j-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool? ",
  "translatedText": "أليس هذا رائعا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land. ",
  "translatedText": "من الشائع تجميع هذه الإحداثيات في شبكة 2x2 من الأرقام تسمى مصفوفة 2x2، حيث يمكنك تفسير الأعمدة على أنها متجهين خاصين حيث يستقر كل من i-hat وj-hat. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get. ",
  "translatedText": "إذا حصلت على مصفوفة 2x2 تصف تحويلًا خطيًا وبعض المتجهات المحددة، وتريد معرفة أين يأخذ هذا التحويل الخطي هذا المتجه، فيمكنك أخذ إحداثيات المتجه، وضربها في الأعمدة المقابلة للمصفوفة، ثم أضف ما تحصل عليه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors. ",
  "translatedText": "يتوافق هذا مع فكرة إضافة الإصدارات المقاسة من المتجهات الأساسية الجديدة لدينا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D. ",
  "translatedText": "دعونا نرى كيف يبدو هذا في الحالة الأكثر عمومية، حيث تحتوي المصفوفة على الإدخالات A، B، C، D. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation. ",
  "translatedText": "وتذكر أن هذه المصفوفة هي مجرد وسيلة لتجميع المعلومات اللازمة لوصف التحويل الخطي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands. ",
  "translatedText": "تذكر دائمًا تفسير العمود الأول، AC، على أنه المكان الذي يستقر فيه متجه الأساس الأول، والعمود الثاني، BD، على أنه المكان الذي يستقر فيه متجه الأساس الثاني. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get? ",
  "translatedText": "عندما نطبق هذا التحويل على بعض المتجهات x، y، ماذا تحصل؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD. ",
  "translatedText": "حسنًا، سيكون x مضروبًا في AC بالإضافة إلى y مضروبًا في BD. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy. ",
  "translatedText": "بتجميع هذا معًا، تحصل على المتجه Ax plus By، Cx plus Dy. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function. ",
  "translatedText": "يمكنك أيضًا تعريف ذلك على أنه ضرب المصفوفة والمتجه عندما تضع المصفوفة على يسار المتجه كما لو كانت دالة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive. ",
  "translatedText": "ثم يمكنك أن تجعل طلاب المدارس الثانوية يحفظون هذا دون أن تبين لهم الجزء الحاسم الذي يجعله يبدو بديهيًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors? ",
  "translatedText": "لكن أليس من الممتع أكثر التفكير في هذه الأعمدة باعتبارها الإصدارات المحولة من المتجهات الأساسية، والتفكير في النتيجة باعتبارها المجموعة الخطية المناسبة لتلك المتجهات؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices. ",
  "translatedText": "دعونا نتدرب على وصف بعض التحويلات الخطية باستخدام المصفوفات. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0. ",
  "translatedText": "على سبيل المثال، إذا قمنا بتدوير كل الفضاء بمقدار 90 درجة عكس اتجاه عقارب الساعة، فإن I-hat تهبط على الإحداثيات 0، 1، وJ-hat تهبط على الإحداثيات سالب 1، 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.58,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0. ",
  "translatedText": "إذن المصفوفة التي وصلنا إليها تحتوي على أعمدة 0، 1، سالب 1، 0. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix. ",
  "translatedText": "لمعرفة ما يحدث لأي متجه بعد دورانه بمقدار 90 درجة، يمكنك فقط ضرب إحداثياته في هذه المصفوفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear. ",
  "translatedText": "إليك تحولًا ممتعًا باسم خاص، يسمى القص. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix. ",
  "translatedText": "في ذلك، يظل I-hat ثابتًا، وبالتالي فإن العمود الأول من المصفوفة هو 1، 0، لكن J-hat ينتقل إلى الإحداثيات 1، 1، والتي تصبح العمود الثاني من المصفوفة. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.0,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector. ",
  "translatedText": "وعلى الرغم من عدم المبالغة هنا، فإن معرفة كيفية تحويل القص لمتجه معين يعني ضرب هذه المصفوفة في ذلك المتجه. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like. ",
  "translatedText": "لنفترض أننا نريد أن نسير في الاتجاه المعاكس، بدءًا بمصفوفة، مثل الأعمدة 1 و2 و3 و1، ونريد أن نستنتج كيف يبدو تحويلها. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it. ",
  "translatedText": "توقف مؤقتًا وتوقف لحظة لترى ما إذا كان بإمكانك تخيل ذلك. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced. ",
  "translatedText": "إحدى الطرق للقيام بذلك هي أولاً تحريك I-hat إلى 1، 2، ثم تحريك J-hat إلى 3، 1، مع تحريك بقية المساحة دائمًا بطريقة تجعل خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.42,
  "end": 560.22
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors. ",
  "translatedText": "إذا كانت المتجهات التي تهبط عليها I-hat وJ-hat تعتمد خطيًا، وهو ما يعني، إذا كنت تتذكر من الفيديو الأخير، أن أحدهما عبارة عن نسخة مصغرة من الآخر، فهذا يعني أن التحويل الخطي يسحق كل المساحة ثنائية الأبعاد على الخط الذي يقع فيه هذين المتجهين، والمعروف أيضًا باسم النطاق أحادي البعد لهذين المتجهين المعتمدين خطيًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed. ",
  "translatedText": "باختصار، التحويلات الخطية هي وسيلة للتنقل في الفضاء بحيث تظل خطوط الشبكة متوازية ومتباعدة بشكل متساوٍ، ويظل الأصل ثابتًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands. ",
  "translatedText": "ومن الممكن وصف هذه التحولات باستخدام عدد قليل فقط من الأرقام، وهي إحداثيات المكان الذي يهبط فيه كل متجه أساسي. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector. ",
  "translatedText": "توفر لنا المصفوفات لغة لوصف هذه التحويلات، حيث تمثل الأعمدة تلك الإحداثيات، وضرب المصفوفة والمتجه هو مجرد وسيلة لحساب ما يفعله هذا التحويل لمتجه معين. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space. ",
  "translatedText": "الفكرة المهمة هنا هي أنه في كل مرة ترى فيها مصفوفة، يمكنك تفسيرها على أنها تحول معين في الفضاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply. ",
  "translatedText": "بمجرد أن تستوعب هذه الفكرة حقًا، ستكون في وضع رائع لفهم الجبر الخطي بعمق. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space. ",
  "translatedText": "تقريبًا جميع المواضيع القادمة، بدءًا من ضرب المصفوفات إلى المحددات، وتغيير الأساس، والقيم الذاتية، كل هذه المواضيع ستصبح أسهل في الفهم بمجرد أن تبدأ في التفكير في المصفوفات باعتبارها تحولات في الفضاء. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together. ",
  "translatedText": "على الفور، في الفيديو التالي، سأتحدث عن ضرب مصفوفتين معًا. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.3,
  "end": 645.66
 },
 {
  "input": "See you then! ",
  "translatedText": "اراك لاحقا! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 645.66
 },
 {
  "input": "Thank you for watching! ",
  "translatedText": "شكرا لمشاهدتك! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 646.32
 }
]