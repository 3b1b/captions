[
 {
  "input": "Hey everyone!",
  "translatedText": "",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "",
  "from_community_srt": "Eğer doğrusal cebir konuları içerisinden, diğer tüm konuları anlamaya yol açan bir konu seçmem gerekse idi ki sıkça ilk defa lineer cebir dersini alan  bir öğrenci tarafından öğrenilmeden geçilir, bu şu olurdu: \"Doğrusal dönüşüm mantığı ve bunun matrisler ile ilişkisi.\" Bu videoda, bu dönüşümlerin iki boyutta nasıl göründüklerine ve matris - vektör çarpımları mantığıyla nasıl ilişkilendiğine değineğim.",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "",
  "from_community_srt": "Özellikle, matris-vektör çarpımlarını; ezbere dayalı olmayan bir düşünme yolu göstermek istiyorum.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "",
  "from_community_srt": "Başlangıç olarak, hadi \"doğrusal dönüşümler\" kavramını anlamlandıralım.",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "",
  "from_community_srt": "\"Dönüşüm\" aslında \"fonksiyon\"  için havalı bir isimden ibarettir.",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "",
  "from_community_srt": "Bu girdiler alan ver her biri için bir çıktı veren bir şeydir.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "",
  "from_community_srt": "Özellikle doğrusal cebir bağlamında dönüşümleri, \"bir vektör al ve başka bir vektör çıkar\" şeklinde düşünmeyi severiz.",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "",
  "from_community_srt": "Madem aynı anlama geliyor, öyleyse neden \"fonksiyon\" kelimesi yerine \"dönüşüm\"  kelimesini kullanıyoruz?",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "",
  "from_community_srt": "Çünkü Bu girdi-çıktı ilişkisini, doğru bir şekilde görselleştirmek için anlamlı olacaktır.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "",
  "from_community_srt": "Gördüğünüz üzere, vektör fonksiyonlarını anlamanın mükemmel bir yolu hareketi kullanmaktır.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "",
  "from_community_srt": "Eğer bir dönüşüm bir girdi vektörünü bir çıktı vektörüne dönüştürüyorsa bu girdi vektörünün çıktı vektörüne taşındığını hayal ederiz.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "",
  "from_community_srt": "Sonra, dönüşümü bütünüyle anlamak için, tüm olası vektör girdisinin, kendi çıktı vektörüne hareketini izlediğimizi hayal edebiliriz.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "",
  "from_community_srt": "tüm vektörleri ok olarak düşünüp, hepsine birden bakmak dikkat dağıtıyor, Haliyle, son videoda dediğim gibi,  her vektörü ok olarak değil de okun ucundaki bir nokta gibi düşünmek şeklinde güzel bir numara yapabiliriz.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "",
  "from_community_srt": "Her olası girdi vektörünü alıp bir çıktı vektörü üreten dönüşümü bu şekilde düşünerek, boşluktaki her noktanın çıktı noktasına harekeini izleyebiliriz.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "",
  "from_community_srt": "iki boyuttaki dönüşümlerde, dönüşüm \"şekli\" hakkında daha yerinde bir düşünüş geliştirmek için, bunu sınırsız bir ızgara ile yapmayı daha çok seviyorum.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "",
  "from_community_srt": "Bazen de u ızgaranın bir kopyasını da arka planda tutmayı yeğliyorum ki her şeyin sonlandığı noktanın başladığı noktaya göre nerede olduğunu takip edebileyim.",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "",
  "from_community_srt": "Boşluktaki tüm noktaların çeşitli dönüşümlerinden doğan görsel etki, kabul etmelisiniz ki, güzelll!",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "",
  "from_community_srt": "uzayı büküyor, büzüyor ya da yapısal olarak dönüştürüyor gibi hissettiriyor.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "",
  "from_community_srt": "Tahmin edebileceğiniz gibi, kimi dönüşümler oldukça karmaşık görünebilir, fakat şansımıza, doğrusal cebir, kendisini özel bir takım dönüşümlere kısıtlar ki bunlar anlaması oldukça kolay, \"doğrusal\" olarak adlandırılan dönüşümlerdir.",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "",
  "from_community_srt": "Görsel olarak anlatmak gerekirse, bir dönüşüm eğer iki özelliği haiz ise doğrusaldır: 1.",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "",
  "from_community_srt": "tüm doğrular, bükülmeden doğru olarak kalıp, merkezi olduğu yerden kaymamalıdır.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "",
  "from_community_srt": "Örneğin, bu izlediğiniz doğrusal bir dönüşüm olamaz, çünkü tüm doğrular bükülüyor.",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "",
  "from_community_srt": "bu ise, doğruları bükmese de merkezi yerinden oynattığı için doğrusal değildir!",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "",
  "from_community_srt": "bu ise, merkezi yerinde tutuyor, doğruları da bükmüyor görünüyor, ama esasen bu yalnızca benim dikey ve yatay çizgileri göstermemde ötürü öyle, çapraz çizgi içzdiğimizde anlıyoruz ki bu çizgi doğru olarak kalmıyor, çapraz olan yamuklaştı.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "",
  "from_community_srt": "Genel olarak, doğrusal dönüşümleri, ızgara görünümünü, doğrular paralel, ve aralarındaki boşlık eşit aralıklı düşünmek gerekli.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "",
  "from_community_srt": "Merkez etrafında dönme gibi bazı doğrusal dönüşümler hakkında düşünmek basit Diğer bazısını ise sözel tarif etmek yanıltıcı olabilir.",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "",
  "from_community_srt": "Dolayısıyla, bu dönüşümleri \"sayılarla\" nasıl tarif ederdiniz?",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "",
  "from_community_srt": "Eğer, diyelim ki; eğitim videosu hazırlıyorsunuz bu konuyu anlatmak için, bilgisayara nasıl bir formül verirdiniz ki size vektörün gideceği yerin koordinatlarını versin?",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "",
  "from_community_srt": "Görünüşe göre, bunun için kaydını tutman gereken tek şey iki asıl vektör! i ve j ve geriye kalan herşey peşinden geliyor.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "",
  "from_community_srt": "Örneğin, (-1,2) koordinatlı v vektörünü düşünelim, bu vektör şu anlama geliyordu: -1 kere i vektörü, +2 kere  j vektörü.",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "",
  "from_community_srt": "Eğer bir dönüşüm gerçekleştirir ve bu vektörlerin nereye gittiklerini takip edersek, \"ızgara zeminin doğruları paralel ve aralarındaki boşluk eşit uzunluklu olmalı\" kuralımız çok önemli bir sonuç doğurur: v vektörünün dönüşeceği nokta; i vektörü her nereye dönüştü ise onun -1 katı olan noktanın, ve j vektörü neredeyse onun da 2 olan noktanın toplamı olan nokta olacaktır.",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "",
  "from_community_srt": "Diğer bir deyişle, i ve j vektörlerinin belirli bir birleşimi olarak başlayarak, dönüşüm sonrası i ve j vektörlerinin yine aynı katlı birleşimi olmuş oldu.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "",
  "from_community_srt": "Yani, her iki diyarda v vektörünün yerini yalnızca i ve j vektörlerine dayalı olarak bilebilirsin.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "",
  "from_community_srt": "Bu, arka planda bir kopya ızgara tutmayı sevmemin nedeni; burada gösterilen dönüşüm için, görüyoruz ki, i vektörü (1,-2) noktasına, j vektörü ise x ekseni üzerine, (3,0) noktasına dönüşüyor.",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "",
  "from_community_srt": "Bu da şu anlama geliyor: (-1) i + 2 kere j vektörü sonuç itibari ile de (-1) kere [1,-2] + 2 kere [3,0] oluyor.",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "",
  "from_community_srt": "Tümünü toplarsak, vektörün (5,2) noktasına dönüştüğünü sonucuna varabiliriz.",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "",
  "from_community_srt": "Burası, durup düşünmek için iyi bir nokta. Çünkü oldukça önemli!",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "",
  "from_community_srt": "Şimdi, size tüm dönüşümü gösterdiğim için, yalnızca bakarak, v vektörünün (5,2) noktasına dönüştüğünü söyleyebilirdiniz, ama burada asıl havalı olan asıl vektörlerin kaydını tuttuğumuz sürece, (i ve j vektörleri) animasyonu izlemeden de v nin dönüşeceği noktayı söyleyebilmemizdir.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "",
  "from_community_srt": "Vektörü daha genel koordinat değerleri olarak x ve y ile yazalım, verilen bir vektörün dönüşeceği değer, x kere i vektörün denk geldiği nokta [1,-2], artı y kere j vektörünün düştüğü nokta [3,0] olacaktır.",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "",
  "from_community_srt": "Tüm bu anlattıklarım ışığında, iki boyutlu doğrusal dönüşüm, sadece dört sayı ile tarif edilir: i vektörünün düştüğü yer için 2 koordinat, j vektörünün düştüğü yer için 2 koordinat.",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "",
  "from_community_srt": "Havalı değil mi?",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "",
  "from_community_srt": "bu koordinatları 2 ye 2 lik kutulara koymak yaygındır. Bu kutulara 2'ye 2'lik. matrix denir. Burada her bir sütunu, i ve j vektörlerinin nereye düştüklerini anlatan özel iki vektör olarak yorumlayabilirsiniz.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "",
  "from_community_srt": "Eğer bir doğrusal dönüşümü tarif eden bir 2 ye 2 lik bir matrix varsa elinizde verilen bir vektörün doğrusal dönüşümle nereye konumlanacağını bilmek isterseniz bu vektörün koordinatlarını alıp, matrix içerisindeki karşılık gelen sütunlarla çarpıp, toplamlarını alırsan, dönüşüm sonrası yerini bulursun bu vektörün.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "",
  "from_community_srt": "Bu işlem, iki esnetilmiş asıl vektörün \"toplanması\" fikrine tekabül eder.",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "",
  "from_community_srt": "Daha genel bir şekilde bunun ne anlama geldiğine bakalım. Bu durumda matrix; a,b,c,d değerlerine sahip olsun.",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "",
  "from_community_srt": "Unutma! bu matrix yalnızca bir doğrusal dönüşümü tarif etmek için gerekli, bilgiyi paketleme yöntemi.",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "",
  "from_community_srt": "Daima birinci sütunu (a,c) birinci asıl vektörün dönüşüm konumu, ikinci sütunu ise (b,d) ikinci asıl vektörün düştüğü nokta olarak düşünmelisin.",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "",
  "from_community_srt": "Ve bu dönüşümü (x,y) vektörüne uyguladığımızda vektörün dönüştüğü konum ne olur?",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "",
  "from_community_srt": "Pekala, x kere (a,c) + y kere (b,d) olur tabii ki.",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "",
  "from_community_srt": "iki vektörü birleştirip, (ax+by, cx+dy) vektörünü elde ederiz.",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "",
  "from_community_srt": "Hatta bunu vektör matrix çarpımı biçiminde de tanımlayabilirsin. matrix i vektörün sol tarafına koyunca bir işlev gibi olur.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "",
  "from_community_srt": "Sonra, liselilere bunu ezberletebilir, onlara konuyu kavramaları için gerekli içgörüyü kazandırmadan göstermiş olursun!",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "",
  "from_community_srt": "Fakat şimdi, bu sütunları asıl vektörlerin dönüşmüş biçimleri gibi düşünmek, ve işlemin sonucunu uygun doğrusal dönüşüm şeklinde düşünmek daha keyifli değil mi?",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "",
  "from_community_srt": "Matrislerle bir takım doğrusal dönüşümler tarif ederek alıştırma yapalım.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "",
  "from_community_srt": "Örneğin, eğer, tüm uzayı saatin tersi yönünde 90° döndürürsek, i vektörü (0,1) koordinatına, ve j vektörü de (-1,0) koordinatına dönüşür.",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "",
  "from_community_srt": "Dolayısıyla, bu dönüşüm için gerekli matrix (0,1),(-1,0) olur.",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "",
  "from_community_srt": "Herhangi bir vektör, 90° lik bir dönüş sonrası nerede oluru bulmak için, vektörün koordinatlarını bu matrix ile çarpmak yeterlidir.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "",
  "from_community_srt": "Özel, \"shear\" isminde ismi de olan bir dönüşüm, buyrun.",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "",
  "from_community_srt": "i vektörü yerinde kalır, bu durumda, matrix in ilk sütunu (1,0) olur, fakat j vektörü, (1,1) notkasına gider ki, matrix in ikinci noktası da bu olur.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "",
  "from_community_srt": "Gereksiz olması riskini de alarak tekrar söyleyeyim, bu dönüşümün verilen bir vektör için nasıl olduğunu bulmak, matrix in bu vektör ile çarpımı ile mümkün olur.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "",
  "from_community_srt": "Bir de diğer açıdan bakmak istesek; sütunları (1,2) (3,1) olan matrix i ile başlayıp, dönüşümün nasıl olduğunu tespit edelim.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "",
  "from_community_srt": "Videoyu durdurup düşün istersen, bakalım aklında canlanıyor mu?",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "",
  "from_community_srt": "Bunu yapmanın bir yolu, i vektörünü, (1,2) noktasına götürmek, sonra da j noktasını (3,1) noktasına taşımak.",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "",
  "from_community_srt": "Bunları yaparken de tüm ızgarayı öyle bir taşımalıyız ki, doğrular paralel ve eşit aralıklı kalmalı.",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "",
  "from_community_srt": "Eğer i ve j vektörleri doğrusal bağımlı ise, yani, önceki videodan hatırlarsanız, bu bir vektörün diğerinin sündürülmüş hali olması demekti, bu, doğrusal dönüşümün tüm 2 boyutlu uzayı, bir doğruya sıkıştırdığı anlamına gelir ki bu doğru doğrusal bağımlı vektörlerin, tek boyutlu kapsamı olarak da bilinir.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "",
  "from_community_srt": "Özetlemek gerekirse, doğrusal dönüşümler, boşlukta hareket biçimidir ki bu hareket esnasında, ızgara doğruları paralel ve aralarındaki boşluk eşit kalırken, orijin(merkez) de yerinden ayrılmaz!",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "",
  "from_community_srt": "Şahane bir şekilde, bu dönüşümler, bir avuç sayı ile tarif edilebilirler. Yalnızca asıl vektörlerin duracakları yerlerin koordinatları.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "",
  "from_community_srt": "Matrisler ise bize bu dönüşümleri anlatmak için bir dil sağlar, matrix içerisinde, sütunlar asıl vektörlerin konumlarını paket biçiminde tutar. Matrix - vektör çarpımı sadece bir hesaplama aracıdır, sayesinde, dönüşümün vektörü nereye taşıdığnı anlarız.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "",
  "from_community_srt": "Elde edebileceğiniz önemli bir çıkarım; her matrix gördüğünüzde, bunu \"uzayın bir dönüşümü olarak düşünmek\" olabilir.",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "",
  "from_community_srt": "Bu fikri bir kez sindirdiğinizde, doğrusal cebiri anlama konusunda şahane bir noktadasınız demektir.",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "",
  "from_community_srt": "Gelecek konuların neredeyse tümü, matrix çarpımından determinant'a oradan asıl vektörlerin değişimine, asıl-köklere... tüm bunları anlamak çok daha kolay olacak şayet matrisleri uzayın dönüşümü olarak düşünmeye başlarsan!",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "",
  "from_community_srt": "En kısa sürede, sonraki video'da iki matrisi çarpmak hakkında konuşacağım.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]