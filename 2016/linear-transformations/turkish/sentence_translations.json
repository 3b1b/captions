[
 {
  "input": "Hey everyone!",
  "translatedText": "Selam millet!",
  "model": "google_nmt",
  "from_community_srt": "Maalesef! Kimse sana Matrix'in ne olduğunu söyleyemez. Onu kendin görmek zorundasın. ( Matris işlemlerini görsel olarak anlamanın önemi için şaşırtıcı derecede uygun sözcükler.)",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "Eğer lineer cebirdeki diğer konuların ilgisini çekecek ve bir öğrencinin lineer cebiri ilk kez aldığında çoğunlukla unutulan tek bir konuyu seçmek zorunda kalsaydım, o bu olurdu.",
  "model": "google_nmt",
  "from_community_srt": "Merhaba Millet! Eğer doğrusal cebir konuları içerisinden, diğer tüm konuları anlamaya yol açan bir konu seçmem gerekse idi ki sıkça ilk defa lineer cebir dersini alan  bir öğrenci tarafından öğrenilmeden geçilir, bu şu olurdu:",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "Doğrusal dönüşüm fikri ve matrislerle ilişkisi.",
  "model": "google_nmt",
  "from_community_srt": "\"Doğrusal dönüşüm mantığı ve bunun matrisler ile ilişkisi.\" Bu videoda,",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "Bu video için, iki boyut durumunda bu dönüşümlerin neye benzediğine ve bunların matris vektör çarpımı fikriyle nasıl bağlantılı olduğuna odaklanacağım.",
  "model": "google_nmt",
  "from_community_srt": "bu dönüşümlerin iki boyutta nasıl göründüklerine ve matris - vektör çarpımları mantığıyla nasıl ilişkilendiğine değineğim.",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "Özellikle size matris vektör çarpımını ezberlemeye dayanmayan bir şekilde düşünmenin bir yolunu göstermek istiyorum.",
  "model": "google_nmt",
  "from_community_srt": "Özellikle, matris-vektör çarpımlarını; ezbere dayalı olmayan bir düşünme yolu göstermek istiyorum.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "Başlamak için şu terimi, yani doğrusal dönüşümü analiz edelim.",
  "model": "google_nmt",
  "from_community_srt": "Başlangıç olarak, hadi \"doğrusal dönüşümler\" kavramını anlamlandıralım.",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "Dönüşüm aslında işlev için süslü bir kelimedir.",
  "model": "google_nmt",
  "from_community_srt": "\"Dönüşüm\" aslında \"fonksiyon\"  için havalı bir isimden ibarettir.",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "Bu, girdileri alan ve her biri için bir çıktı veren bir şeydir.",
  "model": "google_nmt",
  "from_community_srt": "Bu girdiler alan ver her biri için bir çıktı veren bir şeydir.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "Spesifik olarak, doğrusal cebir bağlamında, bir vektörü alıp başka bir vektörü dışarı çıkaran dönüşümler hakkında düşünmeyi severiz.",
  "model": "google_nmt",
  "from_community_srt": "Özellikle doğrusal cebir bağlamında dönüşümleri, \"bir vektör al ve başka bir vektör çıkar\" şeklinde düşünmeyi severiz.",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "Peki aynı anlama geliyorsa neden işlev yerine dönüşüm kelimesini kullanalım ki?",
  "model": "google_nmt",
  "from_community_srt": "Madem aynı anlama geliyor, öyleyse neden \"fonksiyon\" kelimesi yerine \"dönüşüm\"  kelimesini kullanıyoruz? Çünkü",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "Bu girdi-çıktı ilişkisini görselleştirmenin belirli bir yolunu akla getiriyor.",
  "model": "google_nmt",
  "from_community_srt": "Bu girdi-çıktı ilişkisini, doğru bir şekilde görselleştirmek için anlamlı olacaktır.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "Görüyorsunuz, vektörlerin fonksiyonlarını anlamanın harika bir yolu hareketi kullanmaktır.",
  "model": "google_nmt",
  "from_community_srt": "Gördüğünüz üzere, vektör fonksiyonlarını anlamanın mükemmel bir yolu hareketi kullanmaktır.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "Bir dönüşüm bazı girdi vektörlerini bazı çıktı vektörlerine götürüyorsa, bu girdi vektörünün çıktı vektörüne doğru hareket ettiğini hayal ederiz.",
  "model": "google_nmt",
  "from_community_srt": "Eğer bir dönüşüm bir girdi vektörünü bir çıktı vektörüne dönüştürüyorsa bu girdi vektörünün çıktı vektörüne taşındığını hayal ederiz.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "Daha sonra dönüşümü bir bütün olarak anlamak için, olası her girdi vektörünün karşılık gelen çıktı vektörüne geçişini izlediğimizi hayal edebiliriz.",
  "model": "google_nmt",
  "from_community_srt": "Sonra, dönüşümü bütünüyle anlamak için, tüm olası vektör girdisinin, kendi çıktı vektörüne hareketini izlediğimizi hayal edebiliriz.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "Tüm vektörleri aynı anda, her biri bir ok gibi düşünmek gerçekten kalabalık oluyor.",
  "model": "google_nmt",
  "from_community_srt": "tüm vektörleri ok olarak düşünüp, hepsine birden bakmak dikkat dağıtıyor, Haliyle,",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "Geçen videoda da bahsettiğim gibi, her vektörü bir ok olarak değil, tek bir nokta, yani ucunun bulunduğu nokta olarak kavramsallaştırmak güzel bir püf noktasıdır.",
  "model": "google_nmt",
  "from_community_srt": "son videoda dediğim gibi, her vektörü ok olarak değil de okun ucundaki bir nokta gibi düşünmek şeklinde güzel bir numara yapabiliriz.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "Bu şekilde, mümkün olan her girdi vektörünü bir çıktı vektörüne alan bir dönüşümü düşünmek için, uzaydaki her noktanın başka bir noktaya hareketini izleriz.",
  "model": "google_nmt",
  "from_community_srt": "Her olası girdi vektörünü alıp bir çıktı vektörü üreten dönüşümü bu şekilde düşünerek, boşluktaki her noktanın çıktı noktasına harekeini izleyebiliriz.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "İki boyuttaki dönüşümler durumunda, dönüşümün şeklinin tamamını daha iyi anlamak için bunu sonsuz bir ızgara üzerindeki tüm noktalarla yapmayı seviyorum.",
  "model": "google_nmt",
  "from_community_srt": "iki boyuttaki dönüşümlerde, dönüşüm \"şekli\" hakkında daha yerinde bir düşünüş geliştirmek için, bunu sınırsız bir ızgara ile yapmayı daha çok seviyorum.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "Ayrıca bazen her şeyin başladığı yere göre nerede bittiğini takip etmeye yardımcı olmak için kılavuzun bir kopyasını arka planda tutmayı da severim.",
  "model": "google_nmt",
  "from_community_srt": "Bazen de u ızgaranın bir kopyasını da arka planda tutmayı yeğliyorum ki her şeyin sonlandığı noktanın başladığı noktaya göre nerede olduğunu takip edebileyim.",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "Kabul etmelisiniz ki, uzaydaki tüm noktalar etrafında hareket eden çeşitli dönüşümlerin etkisi çok güzel.",
  "model": "google_nmt",
  "from_community_srt": "Boşluktaki tüm noktaların çeşitli dönüşümlerinden doğan görsel etki, kabul etmelisiniz ki,",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "Alanın kendisini ezme ve değiştirme hissi verir.",
  "model": "google_nmt",
  "from_community_srt": "güzelll! uzayı büküyor, büzüyor ya da yapısal olarak dönüştürüyor gibi hissettiriyor.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "Tahmin edebileceğiniz gibi keyfi dönüşümler oldukça karmaşık görünebilir.",
  "model": "google_nmt",
  "from_community_srt": "Tahmin edebileceğiniz gibi, kimi dönüşümler oldukça karmaşık görünebilir, fakat şansımıza,",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "Ancak neyse ki, doğrusal cebir kendisini, doğrusal dönüşümler adı verilen, anlaşılması daha kolay olan özel bir dönüşüm türüyle sınırlandırıyor.",
  "model": "google_nmt",
  "from_community_srt": "doğrusal cebir, kendisini özel bir takım dönüşümlere kısıtlar ki bunlar anlaması oldukça kolay, \"doğrusal\" olarak adlandırılan dönüşümlerdir.",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "Görsel olarak konuşursak, bir dönüşüm iki özelliğe sahipse doğrusaldır.",
  "model": "google_nmt",
  "from_community_srt": "Görsel olarak anlatmak gerekirse, bir dönüşüm eğer iki özelliği haiz ise doğrusaldır: 1.",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "Tüm çizgiler eğrilmeden çizgi olarak kalmalı ve başlangıç noktası yerinde sabit kalmalıdır.",
  "model": "google_nmt",
  "from_community_srt": "tüm doğrular, bükülmeden doğru olarak kalıp, merkezi olduğu yerden kaymamalıdır.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "Örneğin, buradaki çizgiler doğrusal bir dönüşüm olmayacaktır çünkü çizgiler tamamen kıvrımlıdır.",
  "model": "google_nmt",
  "from_community_srt": "Örneğin, bu izlediğiniz doğrusal bir dönüşüm olamaz, çünkü tüm doğrular bükülüyor.",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "Ve buradaki, çizgileri düz tutmasına rağmen doğrusal bir dönüşüm değil çünkü orijini hareket ettiriyor.",
  "model": "google_nmt",
  "from_community_srt": "bu ise, doğruları bükmese de merkezi yerinden oynattığı için doğrusal değildir! bu ise,",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "Buradaki, orijini sabitliyor ve çizgileri düz tutuyor gibi görünebilir, ancak bunun nedeni yalnızca yatay ve dikey kılavuz çizgilerini gösteriyor olmamdır.",
  "model": "google_nmt",
  "from_community_srt": "merkezi yerinde tutuyor, doğruları da bükmüyor görünüyor, ama esasen bu yalnızca benim dikey ve yatay çizgileri göstermemde ötürü öyle,",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "Çapraz bir çizgiye ne yaptığını gördüğünüzde, bunun hiç de doğrusal olmadığı açıkça ortaya çıkıyor, çünkü o çizgiyi tamamen kıvrımlı hale getiriyor.",
  "model": "google_nmt",
  "from_community_srt": "çapraz çizgi içzdiğimizde anlıyoruz ki bu çizgi doğru olarak kalmıyor, çapraz olan yamuklaştı.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "Genel olarak doğrusal dönüşümleri ızgara çizgilerinin paralel ve eşit aralıklarla tutulması olarak düşünmelisiniz.",
  "model": "google_nmt",
  "from_community_srt": "Genel olarak, doğrusal dönüşümleri, ızgara görünümünü, doğrular paralel, ve aralarındaki boşlık eşit aralıklı düşünmek gerekli.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "Orijin etrafında dönmeler gibi bazı doğrusal dönüşümlerin düşünülmesi kolaydır.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "Diğerlerini kelimelerle anlatmak biraz daha zordur.",
  "model": "google_nmt",
  "from_community_srt": "Merkez etrafında dönme gibi bazı doğrusal dönüşümler hakkında düşünmek basit Diğer bazısını ise sözel tarif etmek yanıltıcı olabilir.",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "Peki bu dönüşümleri sayısal olarak nasıl tanımlayabileceğinizi düşünüyorsunuz?",
  "model": "google_nmt",
  "from_community_srt": "Dolayısıyla, bu dönüşümleri \"sayılarla\" nasıl tarif ederdiniz? Eğer,",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "Diyelim ki, konuyu öğreten bir video hazırlamak için bazı animasyonlar programlıyorsanız, bilgisayara bir vektörün koordinatlarını verirseniz, o vektörün düştüğü yerin koordinatlarını vermesi için bilgisayara hangi formülü verirsiniz?",
  "model": "google_nmt",
  "from_community_srt": "diyelim ki; eğitim videosu hazırlıyorsunuz bu konuyu anlatmak için, bilgisayara nasıl bir formül verirdiniz ki size vektörün gideceği yerin koordinatlarını versin? Görünüşe göre,",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "Görünen o ki, yalnızca iki temel vektörün, i-hat ve j-hat'ın, her bir yerin ve diğer her şeyin bundan sonra nereye geleceğini kaydetmeniz gerekiyor.",
  "model": "google_nmt",
  "from_community_srt": "bunun için kaydını tutman gereken tek şey iki asıl vektör! i ve j ve geriye kalan herşey peşinden geliyor.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "Örneğin, koordinatları negatif 1, 2 olan v vektörünü düşünün; bu, negatif 1 çarpı i-hat artı 2 çarpı j-hat'a eşit olduğu anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Örneğin, (-1,2) koordinatlı v vektörünü düşünelim, bu vektör şu anlama geliyordu:",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "Eğer biraz dönüşüm yaparsak ve bu üç vektörün de nereye gittiğini takip edersek, ızgara çizgilerinin paralel ve eşit aralıklı kalması özelliğinin gerçekten önemli bir sonucu olur.",
  "model": "google_nmt",
  "from_community_srt": "-1 kere i vektörü, +2 kere  j vektörü. Eğer bir dönüşüm gerçekleştirir ve bu vektörlerin nereye gittiklerini takip edersek, \"ızgara zeminin doğruları paralel ve aralarındaki boşluk eşit uzunluklu olmalı\" kuralımız çok önemli bir sonuç doğurur:",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "V'nin düştüğü yer, i-hat'ın indiği vektörün 1 katı artı j-hat'ın indiği vektörün 2 katı negatif olacaktır.",
  "model": "google_nmt",
  "from_community_srt": "v vektörünün dönüşeceği nokta; i vektörü her nereye dönüştü ise onun -1 katı olan noktanın, ve j vektörü neredeyse onun da 2 olan noktanın toplamı olan nokta olacaktır.",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "Başka bir deyişle, i-hat ve j-hat'ın belirli bir doğrusal birleşimi olarak başladı ve bu iki vektörün indiği yerin aynı doğrusal birleşimi olarak sona erdi.",
  "model": "google_nmt",
  "from_community_srt": "Diğer bir deyişle, i ve j vektörlerinin belirli bir birleşimi olarak başlayarak, dönüşüm sonrası i ve j vektörlerinin yine aynı katlı birleşimi olmuş oldu.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "Bu, v'nin nereye gitmesi gerektiğini yalnızca i-hat ve j-hat'ın her birinin nereye indiğine bağlı olarak çıkarabileceğiniz anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Yani, her iki diyarda v vektörünün yerini yalnızca i ve j vektörlerine dayalı olarak bilebilirsin.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "Bu yüzden orijinal ızgaranın bir kopyasını arka planda tutmayı seviyorum.",
  "model": "google_nmt",
  "from_community_srt": "Bu,",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "Burada gösterilen dönüşüm için, i-hat'ın 1, negatif 2 koordinatlarına ve j-hat'ın x ekseninde 3, 0 koordinatlarına indiğini okuyabiliriz.",
  "model": "google_nmt",
  "from_community_srt": "arka planda bir kopya ızgara tutmayı sevmemin nedeni; burada gösterilen dönüşüm için, görüyoruz ki, i vektörü (1,-2) noktasına, j vektörü ise x ekseni üzerine, (3,0) noktasına dönüşüyor.",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "Bu, negatif 1 i-hat artı 2 çarpı j-hat ile temsil edilen vektörün, negatif 1 çarpı vektör 1, negatif 2 artı 2 çarpı vektör 3, 0 ile sonuçlandığı anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Bu da şu anlama geliyor: (-1) i + 2 kere j vektörü sonuç itibari ile de (-1) kere [1,-2] + 2 kere [3,0] oluyor.",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "Hepsini topladığımızda 5, 2 vektörüne inmesi gerektiği sonucunu çıkarabiliriz.",
  "model": "google_nmt",
  "from_community_srt": "Tümünü toplarsak, vektörün (5,2) noktasına dönüştüğünü sonucuna varabiliriz.",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "Bu, durup düşünmek için iyi bir nokta çünkü oldukça önemli.",
  "model": "google_nmt",
  "from_community_srt": "Burası, durup düşünmek için iyi bir nokta.",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "Şimdi size dönüşümün tamamını gösterdiğime göre, v'nin koordinatlarının 5, 2 olduğunu görebilirdiniz.",
  "model": "google_nmt",
  "from_community_srt": "Çünkü oldukça önemli! Şimdi, size tüm dönüşümü gösterdiğim için, yalnızca bakarak,",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "Ancak buradaki güzel kısım, dönüşümün kendisini izlemeye gerek kalmadan, i-hat ve j-hat her birinin nereye indiğine dair bir kaydımız olduğu sürece, herhangi bir vektörün nereye indiğini çıkarsamamız için bize bir teknik vermesidir.",
  "model": "google_nmt",
  "from_community_srt": "v vektörünün (5,2) noktasına dönüştüğünü söyleyebilirdiniz, ama burada asıl havalı olan asıl vektörlerin kaydını tuttuğumuz sürece, (i ve j vektörleri) animasyonu izlemeden de v nin dönüşeceği noktayı söyleyebilmemizdir.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "Daha genel koordinatlara sahip x ve y vektörünü yazarsanız, x çarpı i-hat'ın indiği vektör, 1, negatif 2, artı y çarpı j-hat'ın indiği vektör, 3, 0'a inecektir.",
  "model": "google_nmt",
  "from_community_srt": "Vektörü daha genel koordinat değerleri olarak x ve y ile yazalım, verilen bir vektörün dönüşeceği değer, x kere i vektörün denk geldiği nokta [1,-2], artı y kere j vektörünün düştüğü nokta [3,0] olacaktır.",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "Bu toplamı yaptığımızda, 1x artı 3y, eksi 2x artı 0y'ye indiğini görüyorsunuz.",
  "model": "google_nmt",
  "from_community_srt": "Toplamayı yapınca, göreceğimiz şey: sonuç vektörü= [ 1x + 3y ]                            -2x + 0y Size herhangi bir vektör vereceğim,",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "Size herhangi bir vektör veriyorum ve siz de bu formülü kullanarak o vektörün nereye indiğini bana söyleyebilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "sizse bana o vektörün nereye düştüğünü bu formülle söyleyebileceksiniz.",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "Tüm bunların söylediği şey, iki boyutlu bir doğrusal dönüşümün tamamen yalnızca dört sayıyla tanımlandığıdır; iki koordinat i-hat'ın indiği yer ve iki koordinat da j-hat'ın indiği yer.",
  "model": "google_nmt",
  "from_community_srt": "Tüm bu anlattıklarım ışığında, iki boyutlu doğrusal dönüşüm, sadece dört sayı ile tarif edilir: i vektörünün düştüğü yer için 2 koordinat, j vektörünün düştüğü yer için 2 koordinat.",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Çok hoş değil mi?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "Bu koordinatları, 2x2 matris adı verilen 2x2'lik bir sayı ızgarasında paketlemek yaygındır; burada sütunları, her birinin i-hat ve j-hat olduğu iki özel vektör olarak yorumlayabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Havalı değil mi? bu koordinatları 2 ye 2 lik kutulara koymak yaygındır. Bu kutulara 2'ye 2'lik. matrix denir. Burada her bir sütunu, i ve j vektörlerinin nereye düştüklerini anlatan özel iki vektör olarak yorumlayabilirsiniz.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "Size doğrusal bir dönüşümü ve belirli bir vektörü tanımlayan 2x2'lik bir matris verilirse ve bu doğrusal dönüşümün bu vektörü nereye götürdüğünü bilmek istiyorsanız, vektörün koordinatlarını alıp bunları matrisin karşılık gelen sütunlarıyla çarpabilir ve ardından elde ettiklerinizi bir araya getirin.",
  "model": "google_nmt",
  "from_community_srt": "Eğer bir doğrusal dönüşümü tarif eden bir 2 ye 2 lik bir matrix varsa elinizde verilen bir vektörün doğrusal dönüşümle nereye konumlanacağını bilmek isterseniz bu vektörün koordinatlarını alıp, matrix içerisindeki karşılık gelen sütunlarla çarpıp, toplamlarını alırsan, dönüşüm sonrası yerini bulursun bu vektörün.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "Bu, yeni temel vektörlerimizin ölçekli versiyonlarını ekleme fikrine karşılık gelir.",
  "model": "google_nmt",
  "from_community_srt": "Bu işlem, iki esnetilmiş asıl vektörün \"toplanması\" fikrine tekabül eder.",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "Matrisinizin A, B, C, D girişlerine sahip olduğu en genel durumda bunun nasıl göründüğünü görelim.",
  "model": "google_nmt",
  "from_community_srt": "Daha genel bir şekilde bunun ne anlama geldiğine bakalım. Bu durumda matrix; a,b,c,d değerlerine sahip olsun.",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "Ve unutmayın, bu matris sadece doğrusal bir dönüşümü tanımlamak için gereken bilgiyi paketlemenin bir yoludur.",
  "model": "google_nmt",
  "from_community_srt": "Unutma! bu matrix yalnızca bir doğrusal dönüşümü tarif etmek için gerekli, bilgiyi paketleme yöntemi.",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "Her zaman ilk sütun olan AC'yi birinci temel vektörün bulunduğu yer olarak ve ikinci sütun olan BD'yi de ikinci temel vektörün düştüğü yer olarak yorumlamayı unutmayın.",
  "model": "google_nmt",
  "from_community_srt": "Daima birinci sütunu (a,c) birinci asıl vektörün dönüşüm konumu, ikinci sütunu ise (b,d) ikinci asıl vektörün düştüğü nokta olarak düşünmelisin.",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "Bu dönüşümü bir xy vektörüne uyguladığımızda ne elde edersiniz?",
  "model": "google_nmt",
  "from_community_srt": "Ve bu dönüşümü (x,y) vektörüne uyguladığımızda vektörün dönüştüğü konum ne olur? Pekala,",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "Bu x çarpı AC artı y çarpı BD olacak.",
  "model": "google_nmt",
  "from_community_srt": "x kere (a,c) + y kere (b,d) olur tabii ki.",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "Bunları bir araya getirdiğimizde Ax artı By, Cx artı Dy vektörünü elde ederiz.",
  "model": "google_nmt",
  "from_community_srt": "iki vektörü birleştirip, (ax+by, cx+dy) vektörünü elde ederiz.",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "Matrisi bir fonksiyon gibi vektörün soluna koyduğunuzda bunu matris vektör çarpımı olarak bile tanımlayabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Hatta bunu vektör matrix çarpımı biçiminde de tanımlayabilirsin. matrix i vektörün sol tarafına koyunca bir işlev gibi olur.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "Daha sonra, lise öğrencilerine bunu sezgisel hissettiren önemli kısmı göstermeden bunu ezberlemelerini sağlayabilirsiniz.",
  "model": "google_nmt",
  "from_community_srt": "Sonra, liselilere bunu ezberletebilir, onlara konuyu kavramaları için gerekli içgörüyü kazandırmadan göstermiş olursun!",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "Ancak bu sütunları temel vektörlerinizin dönüştürülmüş versiyonları olarak düşünmek ve sonucu bu vektörlerin uygun doğrusal birleşimi olarak düşünmek daha eğlenceli değil mi?",
  "model": "google_nmt",
  "from_community_srt": "Fakat şimdi, bu sütunları asıl vektörlerin dönüşmüş biçimleri gibi düşünmek, ve işlemin sonucunu",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "Birkaç doğrusal dönüşümü matrislerle tanımlamaya çalışalım.",
  "model": "google_nmt",
  "from_community_srt": "uygun doğrusal dönüşüm şeklinde düşünmek daha keyifli değil mi? Matrislerle bir takım doğrusal dönüşümler tarif ederek alıştırma yapalım.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "Örneğin, uzayın tamamını saat yönünün tersine 90 derece döndürürsek i-hat 0, 1 koordinatlarına iner.",
  "model": "google_nmt",
  "from_community_srt": "Örneğin, eğer, tüm uzayı saatin tersi yönünde 90° döndürürsek, i vektörü (0,1) koordinatına,",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "Ve j-hat koordinatları negatif 1, 0'a iniyor.",
  "model": "google_nmt",
  "from_community_srt": "ve j vektörü de (-1,0) koordinatına dönüşür.",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "Böylece elde ettiğimiz matrisin sütunları 0, 1, negatif 1, 0'dır.",
  "model": "google_nmt",
  "from_community_srt": "Dolayısıyla, bu dönüşüm için gerekli matrix (0,1),(-1,0) olur.",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "90 derecelik bir dönüşten sonra herhangi bir vektöre ne olacağını bulmak için koordinatlarını bu matrisle çarpmanız yeterlidir.",
  "model": "google_nmt",
  "from_community_srt": "Herhangi bir vektör, 90° lik bir dönüş sonrası nerede oluru bulmak için, vektörün koordinatlarını bu matrix ile çarpmak yeterlidir.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "İşte kesme adı verilen özel bir isimle eğlenceli bir dönüşüm.",
  "model": "google_nmt",
  "from_community_srt": "Özel, \"shear\" isminde ismi de olan bir dönüşüm,",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "İçinde i-hat sabit kalır, dolayısıyla matrisin ilk sütunu 1, 0'dır.",
  "model": "google_nmt",
  "from_community_srt": "buyrun. i vektörü yerinde kalır, bu durumda,",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "Ancak j-hat, matrisin ikinci sütunu olan 1, 1 koordinatlarına doğru hareket eder.",
  "model": "google_nmt",
  "from_community_srt": "matrix in ilk sütunu (1,0) olur, fakat j vektörü, (1,1) notkasına gider ki, matrix in ikinci noktası da bu olur.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "Ve burada gereksiz olma riskini göze alarak, bir kesmenin belirli bir vektörü nasıl dönüştürdüğünü bulmak, bu matrisi bu vektörle çarpmak anlamına gelir.",
  "model": "google_nmt",
  "from_community_srt": "Gereksiz olması riskini de alarak tekrar söyleyeyim, bu dönüşümün verilen bir vektör için nasıl olduğunu bulmak, matrix in bu vektör ile çarpımı ile mümkün olur.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "Diyelim ki, bir matrisle başlayarak, örneğin 1, 2 ve 3, 1 numaralı sütunlarla başlayarak diğer tarafa gitmek istiyoruz ve dönüşümünün neye benzediğini çıkarmak istiyoruz.",
  "model": "google_nmt",
  "from_community_srt": "Bir de diğer açıdan bakmak istesek; sütunları (1,2) (3,1) olan matrix i ile başlayıp, dönüşümün nasıl olduğunu tespit edelim.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "Durun ve hayal edip edemediğinizi görmek için bir dakikanızı ayırın.",
  "model": "google_nmt",
  "from_community_srt": "Videoyu durdurup düşün istersen,",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "Bunu yapmanın bir yolu önce i-hat'ı 1, 2'ye, ardından j-hat'ı 3, 1'e taşımaktır.",
  "model": "google_nmt",
  "from_community_srt": "bakalım aklında canlanıyor mu? Bunu yapmanın bir yolu, i vektörünü, (1,2) noktasına götürmek, sonra da j noktasını (3,1) noktasına taşımak.",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "Alanın geri kalanını her zaman kılavuz çizgilerini paralel ve eşit aralıklı tutacak şekilde hareket ettirin.",
  "model": "google_nmt",
  "from_community_srt": "Bunları yaparken de tüm ızgarayı öyle bir taşımalıyız ki, doğrular paralel ve eşit aralıklı kalmalı.",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "Eğer i-hat ve j-hat'ın indiği vektörler doğrusal olarak bağımlıysa, ki bu, önceki videodan hatırlarsanız, birinin diğerinin ölçekli bir versiyonu olduğu anlamına gelir, bu, doğrusal dönüşümün tüm 2 boyutlu alanı yüzeyin üzerine sıkıştırdığı anlamına gelir. Bu iki vektörün bulunduğu çizgi, aynı zamanda bu iki doğrusal bağımlı vektörün tek boyutlu açıklığı olarak da bilinir.",
  "model": "google_nmt",
  "from_community_srt": "Eğer i ve j vektörleri doğrusal bağımlı ise, yani, önceki videodan hatırlarsanız, bu bir vektörün diğerinin sündürülmüş hali olması demekti, bu, doğrusal dönüşümün tüm 2 boyutlu uzayı, bir doğruya sıkıştırdığı anlamına gelir ki bu doğru doğrusal bağımlı vektörlerin, tek boyutlu kapsamı olarak da bilinir.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "Özetlemek gerekirse, doğrusal dönüşümler, kılavuz çizgilerinin paralel ve eşit aralıklı kalacağı ve başlangıç noktasının sabit kalacağı şekilde uzayda hareket etmenin bir yoludur.",
  "model": "google_nmt",
  "from_community_srt": "Özetlemek gerekirse, doğrusal dönüşümler, boşlukta hareket biçimidir ki bu hareket esnasında, ızgara doğruları paralel ve aralarındaki boşluk eşit kalırken, orijin(merkez) de yerinden ayrılmaz!",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "Keyifli bir şekilde, bu dönüşümler, her temel vektörün düştüğü yerin koordinatları olan yalnızca bir avuç sayı kullanılarak açıklanabilir.",
  "model": "google_nmt",
  "from_community_srt": "Şahane bir şekilde, bu dönüşümler, bir avuç sayı ile tarif edilebilirler. Yalnızca asıl vektörlerin duracakları yerlerin koordinatları.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "Matrisler bize bu dönüşümleri tanımlamamız için bir dil verir; burada sütunlar bu koordinatları temsil eder ve matris-vektör çarpımı, bu dönüşümün belirli bir vektöre ne yaptığını hesaplamanın bir yoludur.",
  "model": "google_nmt",
  "from_community_srt": "Matrisler ise bize bu dönüşümleri anlatmak için bir dil sağlar, matrix içerisinde, sütunlar asıl vektörlerin konumlarını paket biçiminde tutar. Matrix - vektör çarpımı sadece bir hesaplama aracıdır, sayesinde, dönüşümün vektörü nereye taşıdığnı anlarız.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "Buradaki önemli çıkarım, bir matrisi her gördüğünüzde, onu uzayın belirli bir dönüşümü olarak yorumlayabilmenizdir.",
  "model": "google_nmt",
  "from_community_srt": "Elde edebileceğiniz önemli bir çıkarım; her matrix gördüğünüzde, bunu \"uzayın bir dönüşümü olarak düşünmek\" olabilir.",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "Bu fikri gerçekten özümsediğinizde, doğrusal cebiri derinlemesine anlamak için harika bir konumdasınız demektir.",
  "model": "google_nmt",
  "from_community_srt": "Bu fikri bir kez sindirdiğinizde, doğrusal cebiri anlama konusunda şahane bir noktadasınız demektir.",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "Matris çarpımından determinantlara, taban değişiminden özdeğerlere kadar hemen hemen tüm konuların anlaşılması, matrisleri uzayın dönüşümleri olarak düşünmeye başladığınızda daha kolay anlaşılacaktır.",
  "model": "google_nmt",
  "from_community_srt": "Gelecek konuların neredeyse tümü, matrix çarpımından determinant'a oradan asıl vektörlerin değişimine, asıl-köklere... tüm bunları anlamak çok daha kolay olacak şayet matrisleri uzayın dönüşümü olarak düşünmeye başlarsan!",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "Hemen bir sonraki videoda iki matrisin birbiriyle çarpılmasından bahsedeceğim.",
  "model": "google_nmt",
  "from_community_srt": "En kısa sürede, sonraki video'da iki matrisi çarpmak hakkında konuşacağım.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]