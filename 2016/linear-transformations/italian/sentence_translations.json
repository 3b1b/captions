[
 {
  "input": "Hey everyone!",
  "translatedText": "Ciao a tutti!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "Se dovessi scegliere un solo argomento che faccia appassionare tutti gli altri argomenti di algebra lineare, e che troppo spesso non venga appreso la prima volta che uno studente affronta l'algebra lineare, sarebbe questo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "L'idea di trasformazione lineare e la sua relazione con le matrici.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "Per questo video, mi concentrerò semplicemente su come appaiono queste trasformazioni nel caso di due dimensioni e su come si collegano all'idea di moltiplicazione dei vettori di matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "In particolare, voglio mostrarti un modo di pensare alla moltiplicazione dei vettori di matrice che non si basa sulla memorizzazione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "Per iniziare, analizziamo semplicemente questo termine, trasformazione lineare.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "Trasformazione è essenzialmente una parola elegante per indicare funzione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "È qualcosa che riceve input e produce un output per ognuno di essi.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "Nello specifico, nel contesto dell'algebra lineare, ci piace pensare a trasformazioni che introducono alcuni vettori e ne emettono un altro.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "Allora perché usare la parola trasformazione invece di funzione se significano la stessa cosa?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "Ebbene, significa suggerire un certo modo di visualizzare questa relazione input-output.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "Vedi, un ottimo modo per comprendere le funzioni dei vettori è usare il movimento.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "Se una trasformazione porta un vettore di input in un vettore di output, immaginiamo che il vettore di input si sposti sul vettore di output.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "Quindi, per comprendere la trasformazione nel suo insieme, potremmo immaginare di osservare ogni possibile vettore di input spostarsi verso il corrispondente vettore di output.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "Diventa davvero affollato pensare a tutti i vettori tutti insieme, ognuno come una freccia.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits.",
  "translatedText": "Quindi, come ho menzionato nell'ultimo video, un bel trucco è concettualizzare ogni vettore non come una freccia ma come un singolo punto, il punto in cui si trova la sua punta.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "In questo modo, per pensare a una trasformazione che porti ogni possibile vettore di input in un vettore di output, osserviamo ogni punto nello spazio che si sposta verso qualche altro punto.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "Nel caso delle trasformazioni in due dimensioni, per avere un'idea migliore dell'intera forma della trasformazione, mi piace farlo con tutti i punti su una griglia infinita.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "A volte mi piace anche tenere una copia della griglia in background solo per tenere traccia di dove finisce tutto rispetto a dove inizia.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "L'effetto delle varie trasformazioni che si muovono attorno a tutti i punti dello spazio è, devi ammetterlo, bellissimo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "Dà la sensazione di schiacciare e trasformare lo spazio stesso.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "Come puoi immaginare, però, le trasformazioni arbitrarie possono sembrare piuttosto complicate.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "Ma fortunatamente, l’algebra lineare si limita a un tipo speciale di trasformazioni, più facili da comprendere, chiamate trasformazioni lineari.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "Visivamente parlando, una trasformazione è lineare se ha due proprietà.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "Tutte le linee devono rimanere linee senza curvarsi e l'origine deve rimanere fissa sul posto.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "Ad esempio, questa qui non sarebbe una trasformazione lineare, poiché le linee diventano tutte curve.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "E questa qui, anche se mantiene le linee dritte, non è una trasformazione lineare, perché sposta l'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "Questo qui fissa l'origine e potrebbe sembrare che mantenga le linee dritte, ma è solo perché sto mostrando solo le linee della griglia orizzontale e verticale.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "Quando vedi cosa fa a una linea diagonale, diventa chiaro che non è affatto lineare, poiché rende la linea tutta sinuosa.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "In generale, dovresti pensare alle trasformazioni lineari come al mantenimento delle linee della griglia parallele e spaziate uniformemente.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "Alcune trasformazioni lineari sono semplici da pensare, come le rotazioni attorno all'origine.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "Altri sono un po’ più difficili da descrivere a parole.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So how do you think you could describe these transformations numerically?",
  "translatedText": "Allora come pensi di poter descrivere numericamente queste trasformazioni?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "Se, ad esempio, dovessi programmare alcune animazioni per realizzare un video che insegni l'argomento, quale formula daresti al computer in modo che se gli dai le coordinate di un vettore, possa darti le coordinate di dove si trova quel vettore?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "Si scopre che devi solo registrare dove atterrano i due vettori base, i-hat e j-hat, e tutto il resto seguirà da quello.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "Ad esempio, considera il vettore v con coordinate negative 1, 2, il che significa che è uguale a -1 per i-hat più 2 per j-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "Se eseguiamo qualche trasformazione e seguiamo dove vanno tutti e tre questi vettori, la proprietà secondo cui le linee della griglia rimangono parallele e spaziate uniformemente ha una conseguenza davvero importante.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "Il punto in cui v atterra sarà negativo 1 volta il vettore in cui è atterrato i-hat più 2 volte il vettore in cui è atterrato j-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "In altre parole, è iniziato come una certa combinazione lineare di i-hat e j-hat, e finisce come la stessa combinazione lineare di dove sono finiti questi due vettori.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "Ciò significa che puoi dedurre dove v deve andare basandosi solo su dove i-hat e j-hat cadono ciascuna.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "Questo è il motivo per cui mi piace mantenere una copia della griglia originale sullo sfondo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "Per la trasformazione mostrata qui, possiamo leggere che i-hat si trova sulle coordinate 1, meno 2, e j-hat si trova sull'asse x alle coordinate 3, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "Ciò significa che il vettore rappresentato da meno 1 i-hat più 2 volte j-hat finisce con meno 1 volte il vettore 1, meno 2 più 2 volte il vettore 3, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "Sommando tutto insieme, puoi dedurre che deve atterrare sul vettore 5, 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "Questo è un buon punto su cui fermarsi e riflettere, perché è piuttosto importante.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "Ora, dato che ti sto mostrando la trasformazione completa, avresti potuto semplicemente vedere che v ha le coordinate 5, 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself.",
  "translatedText": "Ma la parte interessante qui è che questo ci dà una tecnica per dedurre dove atterrano i vettori purché abbiamo una registrazione di dove atterrano i-hat e j-hat, senza bisogno di osservare la trasformazione stessa.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "Scrivi il vettore con coordinate più generali, x e y, e si fermerà su x volte il vettore dove si ferma i-hat, 1, meno 2, più y volte il vettore dove si ferma j-hat, 3, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "Eseguendo tale somma, vedi che risulta 1x più 3y, meno 2x più 0y.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "Ti do qualsiasi vettore e tu puoi dirmi dove si ferma quel vettore usando questa formula.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands.",
  "translatedText": "Ciò che tutto questo dice è che una trasformazione lineare bidimensionale è completamente descritta da soli quattro numeri, le due coordinate di dove si ferma i-hat e le due coordinate di dove si ferma j-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Non è bello?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "È prassi comune raggruppare queste coordinate in una griglia di numeri 2x2 chiamata matrice 2x2, in cui è possibile interpretare le colonne come i due vettori speciali in cui i-hat e j-hat finiscono ciascuno.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "Se ti viene data una matrice 2x2 che descrive una trasformazione lineare e un vettore specifico, e vuoi sapere dove quella trasformazione lineare porta quel vettore, puoi prendere le coordinate del vettore, moltiplicarle per le colonne corrispondenti della matrice, quindi somma quello che ottieni.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "Ciò corrisponde all'idea di aggiungere le versioni scalate dei nostri nuovi vettori base.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "Vediamo come appare nel caso più generale, dove la tua matrice ha elementi A, B, C, D.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "E ricorda, questa matrice è solo un modo per confezionare le informazioni necessarie per descrivere una trasformazione lineare.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "Ricorda sempre di interpretare la prima colonna, AC, come il luogo in cui si ferma il primo vettore base, e la seconda colonna, BD, come il luogo in cui si ferma il secondo vettore base.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get?",
  "translatedText": "Quando applichiamo questa trasformazione a qualche vettore x, y, cosa ottieni?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "Beh, sarà x volte AC più y volte BD.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "Mettendo insieme questo, ottieni un vettore Ax più By, Cx più Dy.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "Potresti anche definirlo come moltiplicazione matrice-vettore quando metti la matrice a sinistra del vettore come se fosse una funzione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "Quindi potresti farlo memorizzare agli studenti delle scuole superiori senza mostrare loro la parte cruciale che lo fa sembrare intuitivo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "Ma non è più divertente pensare a queste colonne come alle versioni trasformate dei vettori base e pensare al risultato come alla combinazione lineare appropriata di tali vettori?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "Esercitiamoci a descrivere alcune trasformazioni lineari con le matrici.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0.",
  "translatedText": "Ad esempio, se ruotiamo tutto lo spazio di 90 gradi in senso antiorario, allora I-hat si posiziona sulle coordinate 0, 1 e J-hat si posiziona sulle coordinate negative 1, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.58,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "Quindi la matrice con cui otteniamo ha colonne 0, 1, negativo 1, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "Per capire cosa succede a qualsiasi vettore dopo una rotazione di 90 gradi, potresti semplicemente moltiplicare le sue coordinate per questa matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "Ecco una trasformazione divertente con un nome speciale, chiamata cesoia.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "In esso, I-hat rimane fisso, quindi la prima colonna della matrice è 1, 0, ma J-hat si sposta alle coordinate 1, 1, che diventano la seconda colonna della matrice.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.0,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "E a rischio di essere ridondante in questo caso, capire come un taglio trasforma un dato vettore si riduce a moltiplicare questa matrice per quel vettore.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "Diciamo che vogliamo fare il contrario, iniziando con una matrice, diciamo con le colonne 1, 2 e 3, 1, e vogliamo dedurre come appare la sua trasformazione.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "Fermati e prenditi un momento per vedere se riesci a immaginarlo.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "Un modo per farlo è spostare prima I-hat su 1, 2, quindi spostare J-hat su 3, 1, spostando sempre il resto dello spazio in modo tale da mantenere le linee della griglia parallele e spaziate uniformemente.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.42,
  "end": 560.22
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "Se i vettori su cui atterrano I-hat e J-hat sono linearmente dipendenti, il che, se ricordi l'ultimo video, significa che uno è una versione in scala dell'altro, significa che la trasformazione lineare schiaccia tutto lo spazio 2D sul linea dove si trovano questi due vettori, nota anche come estensione unidimensionale di questi due vettori linearmente dipendenti.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "Per riassumere, le trasformazioni lineari sono un modo per spostarsi nello spazio in modo tale che le linee della griglia rimangano parallele e spaziate uniformemente e in modo tale che l'origine rimanga fissa.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "Volutamente, queste trasformazioni possono essere descritte utilizzando solo una manciata di numeri, le coordinate di dove si ferma ciascun vettore di base.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "Le matrici ci forniscono un linguaggio per descrivere queste trasformazioni, dove le colonne rappresentano quelle coordinate e la moltiplicazione matrice-vettore è solo un modo per calcolare cosa fa quella trasformazione a un dato vettore.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "La conclusione importante qui è che ogni volta che vedi una matrice, puoi interpretarla come una certa trasformazione dello spazio.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "Una volta che hai veramente digerito questa idea, sei in un'ottima posizione per comprendere a fondo l'algebra lineare.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "Quasi tutti gli argomenti in arrivo, dalla moltiplicazione delle matrici ai determinanti, al cambio di base, agli autovalori, diventeranno tutti più facili da comprendere una volta che inizierai a pensare alle matrici come trasformazioni dello spazio.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "Più immediatamente, nel prossimo video, parlerò della moltiplicazione di due matrici tra loro.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.3,
  "end": 645.66
 },
 {
  "input": "See you then!",
  "translatedText": "Ci vediamo!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 645.66
 },
 {
  "input": "Thank you for watching!",
  "translatedText": "Grazie per aver guardato!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 646.32
 }
]