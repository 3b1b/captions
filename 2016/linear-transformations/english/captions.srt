1
00:00:12,040 --> 00:00:12,920
Hey everyone!

2
00:00:13,320 --> 00:00:16,276
If I had to choose just one topic that makes all of the others in 

3
00:00:16,276 --> 00:00:19,233
linear algebra start to click, and which too often goes unlearned 

4
00:00:19,233 --> 00:00:22,280
the first time a student takes linear algebra, it would be this one.

5
00:00:22,700 --> 00:00:26,200
The idea of a linear transformation and its relation to matrices.

6
00:00:26,950 --> 00:00:30,981
For this video, I'm just going to focus on what these transformations look like in the 

7
00:00:30,981 --> 00:00:35,060
case of two dimensions, and how they relate to the idea of matrix vector multiplication.

8
00:00:35,880 --> 00:00:39,137
In particular, I want to show you a way to think about matrix 

9
00:00:39,137 --> 00:00:42,080
vector multiplication that doesn't rely on memorization.

10
00:00:43,160 --> 00:00:46,580
To start, let's just parse this term, linear transformation.

11
00:00:47,420 --> 00:00:49,880
Transformation is essentially a fancy word for function.

12
00:00:50,260 --> 00:00:53,980
It's something that takes in inputs and spits out an output for each one.

13
00:00:53,980 --> 00:00:56,414
Specifically, in the context of linear algebra, 

14
00:00:56,414 --> 00:00:59,862
we like to think about transformations that take in some vector and 

15
00:00:59,862 --> 00:01:01,080
spit out another vector.

16
00:01:02,500 --> 00:01:06,380
So why use the word transformation instead of function if they mean the same thing?

17
00:01:07,120 --> 00:01:11,340
Well, it's to be suggestive of a certain way to visualize this input-output relation.

18
00:01:11,860 --> 00:01:15,800
You see, a great way to understand functions of vectors is to use movement.

19
00:01:16,780 --> 00:01:20,976
If a transformation takes some input vector to some output vector, 

20
00:01:20,976 --> 00:01:24,860
we imagine that input vector moving over to the output vector.

21
00:01:25,680 --> 00:01:28,498
Then to understand the transformation as a whole, 

22
00:01:28,498 --> 00:01:32,501
we might imagine watching every possible input vector move over to its 

23
00:01:32,501 --> 00:01:34,080
corresponding output vector.

24
00:01:34,980 --> 00:01:38,164
It gets really crowded to think about all of the vectors all at once, 

25
00:01:38,164 --> 00:01:39,120
each one as an arrow.

26
00:01:39,500 --> 00:01:43,625
So as I mentioned last video, a nice trick is to conceptualize each vector 

27
00:01:43,625 --> 00:01:47,420
not as an arrow, but as a single point, the point where its tip sits.

28
00:01:48,030 --> 00:01:52,105
That way, to think about a transformation taking every possible input vector 

29
00:01:52,105 --> 00:01:56,340
to some output vector, we watch every point in space moving to some other point.

30
00:01:57,220 --> 00:01:59,665
In the case of transformations in two dimensions, 

31
00:01:59,665 --> 00:02:02,796
to get a better feel for the whole shape of the transformation, 

32
00:02:02,796 --> 00:02:05,780
I like to do this with all of the points on an infinite grid.

33
00:02:06,560 --> 00:02:09,445
I also sometimes like to keep a copy of the grid in the background, 

34
00:02:09,445 --> 00:02:12,840
just to help keep track of where everything ends up relative to where it starts.

35
00:02:14,460 --> 00:02:19,295
The effect for various transformations moving around all of the points in space is, 

36
00:02:19,295 --> 00:02:21,080
you've got to admit, beautiful.

37
00:02:21,880 --> 00:02:24,640
It gives the feeling of squishing and morphing space itself.

38
00:02:25,600 --> 00:02:29,920
As you can imagine though, arbitrary transformations can look pretty complicated.

39
00:02:30,380 --> 00:02:34,684
But luckily, linear algebra limits itself to a special type of transformation, 

40
00:02:34,684 --> 00:02:38,280
ones that are easier to understand, called linear transformations.

41
00:02:39,120 --> 00:02:43,060
Visually speaking, a transformation is linear if it has two properties.

42
00:02:43,700 --> 00:02:46,963
All lines must remain lines without getting curved, 

43
00:02:46,963 --> 00:02:49,600
and the origin must remain fixed in place.

44
00:02:50,620 --> 00:02:54,018
For example, this right here would not be a linear transformation, 

45
00:02:54,018 --> 00:02:55,540
since the lines get all curvy.

46
00:02:56,100 --> 00:02:59,050
And this one right here, although it keeps the lines straight, 

47
00:02:59,050 --> 00:03:01,860
is not a linear transformation, because it moves the origin.

48
00:03:02,680 --> 00:03:05,960
This one here fixes the origin, and it might look like it keeps lines straight, 

49
00:03:05,960 --> 00:03:09,240
but that's just because I'm only showing the horizontal and vertical grid lines.

50
00:03:09,540 --> 00:03:12,407
When you see what it does to a diagonal line, it becomes clear 

51
00:03:12,407 --> 00:03:15,320
that it's not at all linear, since it turns that line all curvy.

52
00:03:16,760 --> 00:03:19,658
In general, you should think of linear transformations 

53
00:03:19,658 --> 00:03:22,240
as keeping grid lines parallel and evenly spaced.

54
00:03:23,400 --> 00:03:27,540
Some linear transformations are simple to think about, like rotations about the origin.

55
00:03:28,120 --> 00:03:30,600
Others are a little trickier to describe with words.

56
00:03:32,040 --> 00:03:35,480
So, how do you think you could describe these transformations numerically?

57
00:03:35,480 --> 00:03:39,654
If you were, say, programming some animations to make a video teaching the topic, 

58
00:03:39,654 --> 00:03:44,236
what formula do you give the computer so that if you give it the coordinates of a vector, 

59
00:03:44,236 --> 00:03:47,240
it can give you the coordinates of where that vector lands?

60
00:03:48,480 --> 00:03:52,568
It turns out that you only need to record where the two basis vectors, 

61
00:03:52,568 --> 00:03:56,600
i-hat and j-hat, each land, and everything else will follow from that.

62
00:03:57,500 --> 00:04:01,662
For example, consider the vector v with coordinates negative 1, 2, 

63
00:04:01,662 --> 00:04:05,700
meaning that it equals negative 1 times i-hat plus 2 times j-hat.

64
00:04:08,680 --> 00:04:12,973
If we play some transformation and follow where all three of these vectors go, 

65
00:04:12,973 --> 00:04:17,647
the property that grid lines remain parallel and evenly spaced has a really important 

66
00:04:17,647 --> 00:04:18,300
consequence.

67
00:04:19,100 --> 00:04:22,198
The place where v lands will be negative 1 times the vector 

68
00:04:22,198 --> 00:04:25,400
where i-hat landed plus 2 times the vector where j-hat landed.

69
00:04:25,980 --> 00:04:30,332
In other words, it started off as a certain linear combination of i-hat and j-hat, 

70
00:04:30,332 --> 00:04:34,580
and it ends up as that same linear combination of where those two vectors landed.

71
00:04:35,620 --> 00:04:40,920
This means you can deduce where v must go based only on where i-hat and j-hat each land.

72
00:04:41,580 --> 00:04:44,540
This is why I like keeping a copy of the original grid in the background.

73
00:04:45,080 --> 00:04:50,591
For the transformation shown here, we can read off that i-hat lands on the coordinates 1, 

74
00:04:50,591 --> 00:04:54,940
negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.

75
00:04:55,540 --> 00:05:00,707
This means that the vector represented by negative 1 i-hat plus 2 times j-hat 

76
00:05:00,707 --> 00:05:06,140
ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.

77
00:05:07,100 --> 00:05:11,680
Adding that all together, you can deduce that it has to land on the vector 5, 2.

78
00:05:14,260 --> 00:05:17,240
This is a good point to pause and ponder, because it's pretty important.

79
00:05:18,520 --> 00:05:21,900
Now, given that I'm actually showing you the full transformation, 

80
00:05:21,900 --> 00:05:25,280
you could have just looked to see that v has the coordinates 5, 2.

81
00:05:25,760 --> 00:05:29,576
But the cool part here is that this gives us a technique to deduce 

82
00:05:29,576 --> 00:05:33,335
where any vectors land so long as we have a record of where i-hat 

83
00:05:33,335 --> 00:05:37,380
and j-hat each land without needing to watch the transformation itself.

84
00:05:38,600 --> 00:05:42,442
Write the vector with more general coordinates, x and y, 

85
00:05:42,442 --> 00:05:47,364
and it will land on x times the vector where i-hat lands, 1, negative 2, 

86
00:05:47,364 --> 00:05:50,600
plus y times the vector where j-hat lands, 3, 0.

87
00:05:51,860 --> 00:05:58,100
Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.

88
00:05:58,740 --> 00:06:03,580
I give you any vector, and you can tell me where that vector lands using this formula.

89
00:06:04,860 --> 00:06:09,037
What all of this is saying is that a two-dimensional linear transformation 

90
00:06:09,037 --> 00:06:12,935
is completely described by just four numbers, the two coordinates for 

91
00:06:12,935 --> 00:06:16,500
where i-hat lands and the two coordinates for where j-hat lands.

92
00:06:17,080 --> 00:06:17,640
Isn't that cool?

93
00:06:18,380 --> 00:06:23,826
It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, 

94
00:06:23,826 --> 00:06:27,681
where you can interpret the columns as the two special vectors 

95
00:06:27,681 --> 00:06:29,640
where i-hat and j-hat each land.

96
00:06:30,380 --> 00:06:35,536
If you're given a 2x2 matrix describing a linear transformation and some specific vector, 

97
00:06:35,536 --> 00:06:39,719
and you want to know where that linear transformation takes that vector, 

98
00:06:39,719 --> 00:06:44,245
you can take the coordinates of the vector, multiply them by the corresponding 

99
00:06:44,245 --> 00:06:47,340
columns of the matrix, then add together what you get.

100
00:06:48,180 --> 00:06:52,720
This corresponds with the idea of adding the scaled versions of our new basis vectors.

101
00:06:54,720 --> 00:06:58,105
Let's see what this looks like in the most general case, 

102
00:06:58,105 --> 00:07:00,540
where your matrix has entries A, B, C, D.

103
00:07:01,100 --> 00:07:03,715
And remember, this matrix is just a way of packaging the 

104
00:07:03,715 --> 00:07:06,240
information needed to describe a linear transformation.

105
00:07:06,240 --> 00:07:09,219
Always remember to interpret that first column, AC, 

106
00:07:09,219 --> 00:07:13,632
as the place where the first basis vector lands, and that second column, BD, 

107
00:07:13,632 --> 00:07:16,440
as the place where the second basis vector lands.

108
00:07:17,500 --> 00:07:21,000
When we apply this transformation to some vector xy, what do you get?

109
00:07:22,060 --> 00:07:26,980
Well, it'll be x times AC plus y times BD.

110
00:07:28,060 --> 00:07:33,300
Putting this together, you get a vector Ax plus By, Cx plus Dy.

111
00:07:33,980 --> 00:07:37,167
You could even define this as matrix vector multiplication, 

112
00:07:37,167 --> 00:07:40,940
when you put the matrix on the left of the vector like it's a function.

113
00:07:41,660 --> 00:07:44,118
Then, you could make high schoolers memorize this without 

114
00:07:44,118 --> 00:07:46,620
showing them the crucial part that makes it feel intuitive.

115
00:07:48,300 --> 00:07:51,331
But, isn't it more fun to think about these columns as the 

116
00:07:51,331 --> 00:07:54,568
transformed versions of your basis vectors, and to think about 

117
00:07:54,568 --> 00:07:57,960
the result as the appropriate linear combination of those vectors?

118
00:08:00,720 --> 00:08:03,780
Let's practice describing a few linear transformations with matrices.

119
00:08:04,580 --> 00:08:09,358
For example, if we rotate all of space 90 degrees counterclockwise, 

120
00:08:09,358 --> 00:08:12,240
then i-hat lands on the coordinates 0, 1.

121
00:08:13,980 --> 00:08:17,180
And j-hat lands on the coordinates negative 1, 0.

122
00:08:17,980 --> 00:08:21,960
So the matrix we end up with has columns 0, 1, negative 1, 0.

123
00:08:22,880 --> 00:08:26,630
To figure out what happens to any vector after a 90-degree rotation, 

124
00:08:26,630 --> 00:08:29,620
you could just multiply its coordinates by this matrix.

125
00:08:31,560 --> 00:08:34,299
Here's a fun transformation with a special name, called a shear.

126
00:08:35,000 --> 00:08:39,159
In it, i-hat remains fixed, so the first column of the matrix is 1, 0.

127
00:08:39,600 --> 00:08:42,481
But j-hat moves over to the coordinates 1, 1, 

128
00:08:42,481 --> 00:08:45,300
which become the second column of the matrix.

129
00:08:45,300 --> 00:08:49,962
And at the risk of being redundant here, figuring out how a shear transforms 

130
00:08:49,962 --> 00:08:54,080
a given vector comes down to multiplying this matrix by that vector.

131
00:08:55,760 --> 00:08:59,616
Let's say we want to go the other way around, starting with a matrix, 

132
00:08:59,616 --> 00:09:04,520
say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.

133
00:09:04,960 --> 00:09:07,440
Pause and take a moment to see if you can imagine it.

134
00:09:08,420 --> 00:09:15,100
One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.

135
00:09:15,100 --> 00:09:17,605
Always moving the rest of space in such a way 

136
00:09:17,605 --> 00:09:20,220
that keeps gridlines parallel and evenly spaced.

137
00:09:21,680 --> 00:09:26,228
If the vectors that i-hat and j-hat land on are linearly dependent, which, 

138
00:09:26,228 --> 00:09:31,079
if you recall from last video, means that one is a scaled version of the other, 

139
00:09:31,079 --> 00:09:36,234
it means that the linear transformation squishes all of 2D space onto the line where 

140
00:09:36,234 --> 00:09:41,328
those two vectors sit, also known as the one-dimensional span of those two linearly 

141
00:09:41,328 --> 00:09:42,420
dependent vectors.

142
00:09:44,420 --> 00:09:48,910
To sum up, linear transformations are a way to move around space such that 

143
00:09:48,910 --> 00:09:53,940
gridlines remain parallel and evenly spaced, and such that the origin remains fixed.

144
00:09:54,540 --> 00:09:58,992
Delightfully, these transformations can be described using only a handful of numbers, 

145
00:09:58,992 --> 00:10:01,530
the coordinates of where each basis vector lands.

146
00:10:02,760 --> 00:10:06,230
Matrices give us a language to describe these transformations, 

147
00:10:06,230 --> 00:10:08,820
where the columns represent those coordinates, 

148
00:10:08,820 --> 00:10:12,566
and matrix-vector multiplication is just a way to compute what that 

149
00:10:12,566 --> 00:10:14,660
transformation does to a given vector.

150
00:10:15,360 --> 00:10:18,805
The important takeaway here is that every time you see a matrix, 

151
00:10:18,805 --> 00:10:21,880
you can interpret it as a certain transformation of space.

152
00:10:22,580 --> 00:10:24,827
Once you really digest this idea, you're in a 

153
00:10:24,827 --> 00:10:27,320
great position to understand linear algebra deeply.

154
00:10:27,660 --> 00:10:32,287
Almost all of the topics coming up, from matrix multiplication to determinants, 

155
00:10:32,287 --> 00:10:36,684
change of basis, eigenvalues, all of these will become easier to understand 

156
00:10:36,684 --> 00:10:40,560
once you start thinking about matrices as transformations of space.

157
00:10:41,300 --> 00:10:44,160
Most immediately, in the next video, I'll be talking 

158
00:10:44,160 --> 00:10:46,320
about multiplying two matrices together.

