1
00:00:12,040 --> 00:00:12,920
Hey everyone!

2
00:00:13,320 --> 00:00:17,180
If I had to choose just one topic that makes all of the others in linear algebra start

3
00:00:17,180 --> 00:00:21,200
to click, and which too often goes unlearned the first time a student takes linear algebra,

4
00:00:21,540 --> 00:00:22,280
it would be this one.

5
00:00:22,700 --> 00:00:26,200
The idea of a linear transformation and its relation to matrices.

6
00:00:26,950 --> 00:00:31,820
For this video, I'm just going to focus on what these transformations look like in the case of two dimensions,

7
00:00:32,100 --> 00:00:35,060
and how they relate to the idea of matrix vector multiplication.

8
00:00:35,880 --> 00:00:40,400
In particular, I want to show you a way to think about matrix vector multiplication that

9
00:00:40,400 --> 00:00:42,080
doesn't rely on memorization.

10
00:00:43,160 --> 00:00:46,580
To start, let's just parse this term, linear transformation.

11
00:00:47,420 --> 00:00:49,880
Transformation is essentially a fancy word for function.

12
00:00:50,260 --> 00:00:53,980
It's something that takes in inputs and spits out an output for each one.

13
00:00:53,980 --> 00:00:58,460
Specifically, in the context of linear algebra, we like to think about transformations that

14
00:00:58,460 --> 00:01:01,080
take in some vector and spit out another vector.

15
00:01:02,500 --> 00:01:06,380
So why use the word transformation instead of function if they mean the same thing?

16
00:01:07,120 --> 00:01:11,340
Well, it's to be suggestive of a certain way to visualize this input-output relation.

17
00:01:11,860 --> 00:01:15,800
You see, a great way to understand functions of vectors is to use movement.

18
00:01:16,780 --> 00:01:22,240
If a transformation takes some input vector to some output vector, we imagine that input

19
00:01:22,240 --> 00:01:24,860
vector moving over to the output vector.

20
00:01:25,680 --> 00:01:30,360
Then to understand the transformation as a whole, we might imagine watching every possible

21
00:01:30,360 --> 00:01:34,080
input vector move over to its corresponding output vector.

22
00:01:34,980 --> 00:01:38,860
It gets really crowded to think about all of the vectors all at once, each one as an

23
00:01:38,860 --> 00:01:39,120
arrow.

24
00:01:39,500 --> 00:01:44,140
So as I mentioned last video, a nice trick is to conceptualize each vector not as an

25
00:01:44,140 --> 00:01:47,420
arrow, but as a single point, the point where its tip sits.

26
00:01:48,030 --> 00:01:52,180
That way, to think about a transformation taking every possible input vector to some

27
00:01:52,180 --> 00:01:56,340
output vector, we watch every point in space moving to some other point.

28
00:01:57,220 --> 00:02:01,820
In the case of transformations in two dimensions, to get a better feel for the whole shape of

29
00:02:01,820 --> 00:02:05,780
the transformation, I like to do this with all of the points on an infinite grid.

30
00:02:06,560 --> 00:02:10,100
I also sometimes like to keep a copy of the grid in the background, just to help keep

31
00:02:10,100 --> 00:02:12,840
track of where everything ends up relative to where it starts.

32
00:02:14,460 --> 00:02:19,760
The effect for various transformations moving around all of the points in space is, you've

33
00:02:19,760 --> 00:02:21,080
got to admit, beautiful.

34
00:02:21,880 --> 00:02:24,640
It gives the feeling of squishing and morphing space itself.

35
00:02:25,600 --> 00:02:29,920
As you can imagine though, arbitrary transformations can look pretty complicated.

36
00:02:30,380 --> 00:02:34,840
But luckily, linear algebra limits itself to a special type of transformation, ones

37
00:02:34,840 --> 00:02:38,280
that are easier to understand, called linear transformations.

38
00:02:39,120 --> 00:02:43,060
Visually speaking, a transformation is linear if it has two properties.

39
00:02:43,700 --> 00:02:49,600
All lines must remain lines without getting curved, and the origin must remain fixed in place.

40
00:02:50,620 --> 00:02:55,540
For example, this right here would not be a linear transformation, since the lines get all curvy.

41
00:02:56,100 --> 00:03:00,440
And this one right here, although it keeps the lines straight, is not a linear transformation,

42
00:03:00,660 --> 00:03:01,860
because it moves the origin.

43
00:03:02,680 --> 00:03:06,440
This one here fixes the origin, and it might look like it keeps lines straight, but that's

44
00:03:06,440 --> 00:03:09,240
just because I'm only showing the horizontal and vertical grid lines.

45
00:03:09,540 --> 00:03:13,420
When you see what it does to a diagonal line, it becomes clear that it's not at all linear,

46
00:03:13,580 --> 00:03:15,320
since it turns that line all curvy.

47
00:03:16,760 --> 00:03:22,240
In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.

48
00:03:23,400 --> 00:03:27,540
Some linear transformations are simple to think about, like rotations about the origin.

49
00:03:28,120 --> 00:03:30,600
Others are a little trickier to describe with words.

50
00:03:32,040 --> 00:03:35,480
So, how do you think you could describe these transformations numerically?

51
00:03:35,480 --> 00:03:39,700
If you were, say, programming some animations to make a video teaching the topic,

52
00:03:40,140 --> 00:03:43,940
what formula do you give the computer so that if you give it the coordinates of a vector,

53
00:03:44,380 --> 00:03:47,240
it can give you the coordinates of where that vector lands?

54
00:03:48,480 --> 00:03:54,500
It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land,

55
00:03:54,560 --> 00:03:56,600
and everything else will follow from that.

56
00:03:57,500 --> 00:04:01,340
For example, consider the vector v with coordinates negative 1, 2,

57
00:04:01,340 --> 00:04:05,700
meaning that it equals negative 1 times i-hat plus 2 times j-hat.

58
00:04:08,680 --> 00:04:12,800
If we play some transformation and follow where all three of these vectors go,

59
00:04:13,380 --> 00:04:18,300
the property that grid lines remain parallel and evenly spaced has a really important consequence.

60
00:04:19,100 --> 00:04:22,800
The place where v lands will be negative 1 times the vector where i-hat landed

61
00:04:22,800 --> 00:04:25,400
plus 2 times the vector where j-hat landed.

62
00:04:25,980 --> 00:04:30,100
In other words, it started off as a certain linear combination of i-hat and j-hat,

63
00:04:30,100 --> 00:04:34,580
and it ends up as that same linear combination of where those two vectors landed.

64
00:04:35,620 --> 00:04:40,920
This means you can deduce where v must go based only on where i-hat and j-hat each land.

65
00:04:41,580 --> 00:04:44,540
This is why I like keeping a copy of the original grid in the background.

66
00:04:45,080 --> 00:04:50,900
For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2,

67
00:04:51,340 --> 00:04:54,940
and j-hat lands on the x-axis over at the coordinates 3, 0.

68
00:04:55,540 --> 00:04:59,920
This means that the vector represented by negative 1 i-hat plus 2 times j-hat

69
00:04:59,920 --> 00:05:06,140
ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.

70
00:05:07,100 --> 00:05:11,680
Adding that all together, you can deduce that it has to land on the vector 5, 2.

71
00:05:14,260 --> 00:05:17,240
This is a good point to pause and ponder, because it's pretty important.

72
00:05:18,520 --> 00:05:21,580
Now, given that I'm actually showing you the full transformation,

73
00:05:21,580 --> 00:05:25,280
you could have just looked to see that v has the coordinates 5, 2.

74
00:05:25,760 --> 00:05:30,700
But the cool part here is that this gives us a technique to deduce where any vectors land

75
00:05:30,700 --> 00:05:34,680
so long as we have a record of where i-hat and j-hat each land

76
00:05:34,680 --> 00:05:37,380
without needing to watch the transformation itself.

77
00:05:38,600 --> 00:05:41,520
Write the vector with more general coordinates, x and y,

78
00:05:41,600 --> 00:05:46,280
and it will land on x times the vector where i-hat lands, 1, negative 2,

79
00:05:47,080 --> 00:05:50,600
plus y times the vector where j-hat lands, 3, 0.

80
00:05:51,860 --> 00:05:58,100
Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.

81
00:05:58,740 --> 00:06:03,580
I give you any vector, and you can tell me where that vector lands using this formula.

82
00:06:04,860 --> 00:06:08,520
What all of this is saying is that a two-dimensional linear transformation

83
00:06:08,520 --> 00:06:11,760
is completely described by just four numbers,

84
00:06:11,760 --> 00:06:16,500
the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.

85
00:06:17,080 --> 00:06:17,640
Isn't that cool?

86
00:06:18,380 --> 00:06:23,500
It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix,

87
00:06:23,960 --> 00:06:29,640
where you can interpret the columns as the two special vectors where i-hat and j-hat each land.

88
00:06:30,380 --> 00:06:35,380
If you're given a 2x2 matrix describing a linear transformation and some specific vector,

89
00:06:35,580 --> 00:06:39,720
and you want to know where that linear transformation takes that vector,

90
00:06:39,720 --> 00:06:45,580
you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix,

91
00:06:45,900 --> 00:06:47,340
then add together what you get.

92
00:06:48,180 --> 00:06:52,720
This corresponds with the idea of adding the scaled versions of our new basis vectors.

93
00:06:54,720 --> 00:07:00,540
Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.

94
00:07:01,100 --> 00:07:06,240
And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.

95
00:07:06,240 --> 00:07:12,200
Always remember to interpret that first column, AC, as the place where the first basis vector lands,

96
00:07:12,440 --> 00:07:16,440
and that second column, BD, as the place where the second basis vector lands.

97
00:07:17,500 --> 00:07:21,000
When we apply this transformation to some vector xy, what do you get?

98
00:07:22,060 --> 00:07:26,980
Well, it'll be x times AC plus y times BD.

99
00:07:28,060 --> 00:07:33,300
Putting this together, you get a vector Ax plus By, Cx plus Dy.

100
00:07:33,980 --> 00:07:40,940
You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.

101
00:07:41,660 --> 00:07:46,620
Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.

102
00:07:48,300 --> 00:07:53,280
But, isn't it more fun to think about these columns as the transformed versions of your basis vectors,

103
00:07:53,680 --> 00:07:57,960
and to think about the result as the appropriate linear combination of those vectors?

104
00:08:00,720 --> 00:08:03,780
Let's practice describing a few linear transformations with matrices.

105
00:08:04,580 --> 00:08:12,240
For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.

106
00:08:13,980 --> 00:08:17,180
And j-hat lands on the coordinates negative 1, 0.

107
00:08:17,980 --> 00:08:21,960
So the matrix we end up with has columns 0, 1, negative 1, 0.

108
00:08:22,880 --> 00:08:29,620
To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.

109
00:08:31,560 --> 00:08:34,300
Here's a fun transformation with a special name, called a shear.

110
00:08:35,000 --> 00:08:39,160
In it, i-hat remains fixed, so the first column of the matrix is 1, 0.

111
00:08:39,600 --> 00:08:45,300
But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.

112
00:08:45,300 --> 00:08:54,080
And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.

113
00:08:55,760 --> 00:09:01,540
Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1,

114
00:09:01,560 --> 00:09:04,520
and we want to deduce what its transformation looks like.

115
00:09:04,960 --> 00:09:07,440
Pause and take a moment to see if you can imagine it.

116
00:09:08,420 --> 00:09:15,100
One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.

117
00:09:15,100 --> 00:09:20,220
Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.

118
00:09:21,680 --> 00:09:30,240
If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other,

119
00:09:30,700 --> 00:09:37,160
it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit,

120
00:09:37,580 --> 00:09:42,420
also known as the one-dimensional span of those two linearly dependent vectors.

121
00:09:44,420 --> 00:09:51,780
To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced,

122
00:09:52,100 --> 00:09:53,940
and such that the origin remains fixed.

123
00:09:54,540 --> 00:10:01,530
Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.

124
00:10:02,760 --> 00:10:08,660
Matrices give us a language to describe these transformations, where the columns represent those coordinates,

125
00:10:08,660 --> 00:10:14,660
and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.

126
00:10:15,360 --> 00:10:21,880
The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.

127
00:10:22,580 --> 00:10:27,320
Once you really digest this idea, you're in a great position to understand linear algebra deeply.

128
00:10:27,660 --> 00:10:33,900
Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues,

129
00:10:33,900 --> 00:10:40,560
all of these will become easier to understand once you start thinking about matrices as transformations of space.

130
00:10:41,300 --> 00:10:45,660
Most immediately, in the next video, I'll be talking about multiplying two matrices together.

131
00:10:46,120 --> 00:10:46,540
See you then!

