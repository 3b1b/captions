[
 {
  "input": "Hey everyone!",
  "translatedText": "Olá a todos!",
  "model": "google_nmt",
  "from_community_srt": "Infelizmente, é impossível dizer o que é a Matriz. Você tem de ver por si mesmo. - Morpheus Palavras surpreendente adeptas para como é importante entender operações de matrizes visualmente",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "Se eu tivesse que escolher apenas um tópico que faz todos os outros em álgebra linear começarem a clicar, e que muitas vezes fica desaprendido na primeira vez que um aluno faz álgebra linear, seria este.",
  "model": "google_nmt",
  "from_community_srt": "Olá tudo mundo! Se eu precisasse escolher só um assunto que fizesse todos os outros assuntos na álgebra linear ficarem claros na minha mente - Um que muitas vezes não é ensinado na primeira vez que um estudante estuda álgebra linear - seria esse:",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "A ideia de uma transformação linear e sua relação com matrizes.",
  "model": "google_nmt",
  "from_community_srt": "A ideia de uma transformação linear e sua relação com matrizes.",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "Neste vídeo, vou focar apenas na aparência dessas transformações no caso de duas dimensões e como elas se relacionam com a ideia de multiplicação de matrizes vetoriais.",
  "model": "google_nmt",
  "from_community_srt": "Pra esse video, eu só vou focar no que essas transformações se parecem em duas dimensões e no que essas transformações tem a ver com a ideia de multiplicar um vetor com uma matriz.",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "Em particular, quero mostrar uma maneira de pensar sobre a multiplicação de vetores de matrizes que não depende de memorização.",
  "model": "google_nmt",
  "from_community_srt": "Em particular, eu quero te mostrar um jeito de pensar sobre multiplicação de matrizes com vetores que não depende de memorização.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "Para começar, vamos analisar este termo, transformação linear.",
  "model": "google_nmt",
  "from_community_srt": "Para começar,",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "Transformação é essencialmente uma palavra sofisticada para função.",
  "model": "google_nmt",
  "from_community_srt": "vamos tentar entender esse termo \"transformação linear\" \"Transformação\" é basicamente uma palavra chique pra função.",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "É algo que recebe entradas e produz uma saída para cada uma.",
  "model": "google_nmt",
  "from_community_srt": "É uma coisa que pega umas entradas e devolve uma saída pra cada.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "Especificamente, no contexto da álgebra linear, gostamos de pensar em transformações que pegam algum vetor e geram outro vetor.",
  "model": "google_nmt",
  "from_community_srt": "Sendo mais específico, quando estamos falando de álgebra linear, transfomações são umas coisas que pegam um vetor e devolvem outro vetor.",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "Então, por que usar a palavra transformação em vez de função se significam a mesma coisa?",
  "model": "google_nmt",
  "from_community_srt": "Então por que usar a palavra \"Transformação\" no lugar de função se é tudo a mesma coisa? Bem,",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "Bem, é para sugerir uma certa maneira de visualizar essa relação entrada-saída.",
  "model": "google_nmt",
  "from_community_srt": "é mais para sugerir uma maneira de visualizar essa relação entre entrada e saída.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "Veja, uma ótima maneira de entender as funções dos vetores é usar o movimento.",
  "model": "google_nmt",
  "from_community_srt": "Olha só, uma boa maneira de entender funções de vetores é usar movimento.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "Se uma transformação leva algum vetor de entrada para algum vetor de saída, imaginamos esse vetor de entrada passando para o vetor de saída.",
  "model": "google_nmt",
  "from_community_srt": "Se uma transformação põe tal vetor de entrada em tal vetor de saída, a gente pode imaginar esse vetor de entrada indo até o vetor de saída.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "Então, para compreender a transformação como um todo, podemos imaginar observar cada vetor de entrada possível passar para o seu vetor de saída correspondente.",
  "model": "google_nmt",
  "from_community_srt": "Daí para entender a transformação inteira a gente pode imaginar cada um dos vetores de entrada indo pro seu devido vetor de saída.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "Fica muito complicado pensar em todos os vetores de uma vez, cada um como uma flecha.",
  "model": "google_nmt",
  "from_community_srt": "Fica muito difícil imaginar todos os vetores de uma vez quando cada um é uma seta.",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "Então, como mencionei no último vídeo, um bom truque é conceituar cada vetor não como uma seta, mas como um único ponto, o ponto onde fica sua ponta.",
  "model": "google_nmt",
  "from_community_srt": "então como eu disse no último video, um truque legal é não ver os vetores como setas, mas como pontos: O ponto onde fica a ponta da seta.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "Dessa forma, para pensar numa transformação que leva todos os vetores de entrada possíveis para algum vetor de saída, observamos cada ponto no espaço se movendo para algum outro ponto.",
  "model": "google_nmt",
  "from_community_srt": "Desse jeito pra imaginar uma transformação que leva cada vetor da entrada pra um vetor da saída, a gente vê cada ponto no espaço ir pra algum outro ponto no espaço.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "No caso de transformações em duas dimensões, para ter uma ideia melhor de toda a forma da transformação, gosto de fazer isso com todos os pontos de uma grade infinita.",
  "model": "google_nmt",
  "from_community_srt": "Quando temos transformações em duas dimensões, eu gosto de fazer isso em todos os pontos nesse plano infinito, para ter uma visão melhor do \"formato\" da transformação.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "Às vezes também gosto de manter uma cópia da grade em segundo plano, apenas para ajudar a controlar onde tudo termina em relação a onde começa.",
  "model": "google_nmt",
  "from_community_srt": "Eu também gosto de deixar uma cópia desse plano no fundo, só pra ajudar a saber onde cada coisa estava antes e depois da transformação.",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "O efeito das várias transformações que se movem em torno de todos os pontos do espaço é, você tem que admitir, lindo.",
  "model": "google_nmt",
  "from_community_srt": "O efeito de várias transformações movendo todos os pontos do espaço, você tem que admitir,",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "Dá a sensação de esmagar e transformar o próprio espaço.",
  "model": "google_nmt",
  "from_community_srt": "é lindo. Dá a sensação de espremer e modelar o  espaço em si.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "Como você pode imaginar, transformações arbitrárias podem parecer bastante complicadas.",
  "model": "google_nmt",
  "from_community_srt": "Porém, como vocês podem imaginar, transformações ilimitadas podem ser bem complicadas.",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "Mas, felizmente, a álgebra linear limita-se a um tipo especial de transformação, mais fácil de entender, chamado de transformações lineares.",
  "model": "google_nmt",
  "from_community_srt": "Por sorte, álgebra linear só lida com um tipo especial de transformação, um tipo mais fácil de entender, que se chama transformação \"linear\".",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "Visualmente falando, uma transformação é linear se tiver duas propriedades.",
  "model": "google_nmt",
  "from_community_srt": "Visualmente falando,",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "Todas as linhas devem permanecer retas sem serem curvas e a origem deve permanecer fixa no lugar.",
  "model": "google_nmt",
  "from_community_srt": "uma transformação é linear quando ela segue duas regras: Todas as linhas têm de continuar sendo linhas, sem se curvarem e a origem tem sempre que ficar no mesmo lugar.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "Por exemplo, isto aqui não seria uma transformação linear, já que as linhas ficam todas curvas.",
  "model": "google_nmt",
  "from_community_srt": "Por exemplo, isso aqui não seria uma transformação linear, já que as linhas ficaram todas curvadas e essa aqui,",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "E esta aqui, embora mantenha as retas retas, não é uma transformação linear, porque move a origem.",
  "model": "google_nmt",
  "from_community_srt": "embora ela deixe as linhas retas, também não é uma transformação linear porque ela mexe a origem.",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "Este aqui fixa a origem e pode parecer que mantém as linhas retas, mas isso é só porque estou mostrando apenas as linhas de grade horizontais e verticais.",
  "model": "google_nmt",
  "from_community_srt": "Essa aqui deixa a origem quieta e até parece que deixa as linhas retas, mas só parece porque eu estou mostrando só as linhas verticais e horizontais.",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "Quando você vê o que isso faz com uma linha diagonal, fica claro que não é nada linear, pois torna essa linha toda curva.",
  "model": "google_nmt",
  "from_community_srt": "Quando você vê o que ela faz com uma linha diagonal fica claro que ela não é linear mesmo, já que a linha fica toda curvada.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "Em geral, você deve pensar nas transformações lineares como manter as linhas da grade paralelas e espaçadas uniformemente.",
  "model": "google_nmt",
  "from_community_srt": "em geral, as transformações lineares mantêm as linhas paralelas e com a mesma distância umas das outras.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "Algumas transformações lineares são simples de pensar, como rotações em torno da origem.",
  "model": "google_nmt",
  "from_community_srt": "Algumas transformações são fáceis de imaginar, como rotações ao redor da origem.",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "Outros são um pouco mais difíceis de descrever com palavras.",
  "model": "google_nmt",
  "from_community_srt": "Outras são um pouquinho mais difíceis de descrever com palavras.",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "Então, como você acha que poderia descrever numericamente essas transformações?",
  "model": "google_nmt",
  "from_community_srt": "Então como você acha que você poderia descrever essas transformações de um jeito numérico? Se você estivesse,",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "Se você estivesse, digamos, programando algumas animações para fazer um vídeo ensinando o assunto, que fórmula você daria ao computador para que, se você der a ele as coordenadas de um vetor, ele possa lhe dar as coordenadas de onde esse vetor pousa?",
  "model": "google_nmt",
  "from_community_srt": "digamos, programando umas animações pra fazer um video que ensina isso. Que fórmula você daria para um computador para que quando você der as coordenadas de um vetor",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "Acontece que você só precisa registrar onde estão os dois vetores de base, i-hat e j-hat, cada terreno, e todo o resto seguirá a partir disso.",
  "model": "google_nmt",
  "from_community_srt": "ele vá te dar o lugar onde esse vetor vai cair depois da transformação? Termina que você só precisa lembrar onde os dois vetores base (versores ou i e j com chapéu, os que valem 1 em cada direção) terminam depois da transformação e o resto você descobre a partir deles.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "Por exemplo, considere o vetor v com coordenadas negativas 1, 2, o que significa que é igual a 1 negativo vezes i-hat mais 2 vezes j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Por exemplo, imagine um vetor v com as coordenadas menos um (-1) e dois (2), o que quer dizer que ele é igual a menos um vezes i mais dois vezes j (-1i + 2j).",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "Se fizermos alguma transformação e seguirmos para onde vão todos esses três vetores, a propriedade de que as linhas da grade permanecem paralelas e espaçadas uniformemente tem uma consequência realmente importante.",
  "model": "google_nmt",
  "from_community_srt": "Se a gente fizer alguma transformação e seguir esses três vetores, a regra das as linhas paralelas continuarem paralelas e com a mesma distância umas das outras tem uma consequência interessante:",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "O local onde v pousa será negativo 1 vezes o vetor onde i-hat pousou mais 2 vezes o vetor onde j-hat pousou.",
  "model": "google_nmt",
  "from_community_srt": "O lugar onde o vetor v vai parar vai ser menos um (-1) vezes o vetor onde i parou mais duas (2) vezes o vetor onde j parou.",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "Em outras palavras, começou como uma certa combinação linear de i-hat e j-hat, e termina como a mesma combinação linear de onde esses dois vetores pousaram.",
  "model": "google_nmt",
  "from_community_srt": "(-1i + 2j). em outras palavras, o vetor v começou como uma certa combinação linear de i e j e terminou como a mesma combinação de onde i e j terminaram.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "Isso significa que você pode deduzir para onde v deve ir com base apenas em onde i-hat e j-hat cada um pousa.",
  "model": "google_nmt",
  "from_community_srt": "(-1*i + 2*j) Isso quer dizer que se você souber onde i e j terminam depois da transformação você também vai saber onde o vetor v terminou.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "É por isso que gosto de manter uma cópia da grade original em segundo plano.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "Para a transformação mostrada aqui, podemos ler que i-hat pousa nas coordenadas 1, menos 2, e j-hat pousa no eixo x nas coordenadas 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "É por isso que eu gosto de manter uma cópia do plano original no fundo; na transformação que a gente viu aqui a gente pode ler que i cai nas coordenadas um, menos dois (1, -2) e j cai no eixo x nas coordenadas três, zero (3,",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "Isso significa que o vetor representado por menos 1 i-hat mais 2 vezes j-hat termina em menos 1 vezes o vetor 1, menos 2 mais 2 vezes o vetor 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "0) Isso quer dizer que o vetor que é igual a menos um vezes i mais dois vezes j  (-1*i + 2*j) termina em menos um vezes o vetor um, menos dois mais dois vezes o vetor três, zero. -1*(1,",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "Somando tudo isso, você pode deduzir que ele deve pousar no vetor 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "-2) + 2*(3, 0) Adicionando isso tudo, você descobre que v tem que terminar no vetor cinco,",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "Este é um bom ponto para fazer uma pausa e refletir, porque é muito importante.",
  "model": "google_nmt",
  "from_community_srt": "dois (5, 2) Essa é uma boa hora para pausar e pensar um pouco, porque isso é bem importante.",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "Agora, dado que estou mostrando a transformação completa, você poderia apenas ter olhado para ver que v tem as coordenadas 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "Agora, já que eu estou te mostrando a transformação toda, você poderia só olhar pra ver que v tem coordenadas cinco e dois,",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "Mas a parte interessante aqui é que isso nos dá uma técnica para deduzir onde qualquer vetor pousa, desde que tenhamos um registro de onde i-hat e j-hat cada um pousa sem precisar observar a transformação em si.",
  "model": "google_nmt",
  "from_community_srt": "(5, 2) mas a parte legal é que isso aqui te dá uma técnica para descobrir onde qualquer vetor termina, enquanto você souber onde i e j terminaram, sem precisar assistir a transformação.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "Escreva o vetor com coordenadas mais gerais, xey, e ele pousará em x vezes o vetor onde i-hat pousa, 1, menos 2, mais y vezes o vetor onde j-hat pousa, 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "Escreva o vetor com coordenadas mais generalizadas, como x e y, e ele vai cair em x vezes o vetor onde i caiu, um, menos dois (1, -2), mais y vezes o vetor onde j caiu, três,",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "Fazendo essa soma, você vê que ela chega a 1x mais 3y, menos 2x mais 0y.",
  "model": "google_nmt",
  "from_community_srt": "zero (3, 0). terminando a soma, você vê que ele cai em um vezes x mais três vezes y, menos 2 vezes x mais zero vezes y. (1*x + 3*y,",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "Eu lhe dou qualquer vetor e você pode me dizer onde esse vetor vai parar usando esta fórmula.",
  "model": "google_nmt",
  "from_community_srt": "2*x + 0*y) Eu te dou qualquer vetor e você pode me dizer onde ele cai depois da transformação usando essa fórmula.",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "O que tudo isso quer dizer é que uma transformação linear bidimensional é completamente descrita por apenas quatro números, as duas coordenadas para onde o i-hat pousa e as duas coordenadas para onde o j-hat pousa.",
  "model": "google_nmt",
  "from_community_srt": "O que tudo isso tá dizendo é que toda uma transformação linear de duas dimensões pode ser representada só com quatro números: As duas coordenadas de onde i termina depois da transformação e as duas coordenadas de onde j termina depois da transformação.",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Não é legal?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "É comum empacotar essas coordenadas em uma grade de números 2x2 chamada matriz 2x2, onde você pode interpretar as colunas como os dois vetores especiais onde i-hat e j-hat pousam.",
  "model": "google_nmt",
  "from_community_srt": "Isso não é legal? É comum a gente embalar essas coordenadas em uma matriz chamada matriz dois por dois (2x2), onde você pode entender as colunas como dois vetores especiais onde i e j caem depois da transformação.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "Se você receber uma matriz 2x2 descrevendo uma transformação linear e algum vetor específico, e quiser saber onde essa transformação linear leva esse vetor, você pode pegar as coordenadas do vetor, multiplicá-las pelas colunas correspondentes da matriz, então some o que você obtém.",
  "model": "google_nmt",
  "from_community_srt": "se você recebe uma matriz dois por dois que representa uma transformação linear e algum vetor particular e você quer saber pra onde essa transformação leva esse vetor, você pode pegar as coordenadas do vetor e multiplicá-las pela coluna adequada da matriz, depois adicionar os resultados.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "Isto corresponde à ideia de adicionar as versões escalonadas dos nossos novos vetores de base.",
  "model": "google_nmt",
  "from_community_srt": "Isso é o mesmo que adicionar as versões multiplicadas dos nossos novos versores (i e j).",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "Vamos ver como fica no caso mais geral, onde sua matriz possui entradas A, B, C, D.",
  "model": "google_nmt",
  "from_community_srt": "Vamos ver como isso fica no caso mais generalizado onde sua matriz tem os termos a, b,",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "E lembre-se, esta matriz é apenas uma forma de empacotar as informações necessárias para descrever uma transformação linear.",
  "model": "google_nmt",
  "from_community_srt": "c e d. e lembre-se, essa matriz é só um jeito de embalar a informação que a gente precisa para representar uma transformação linear.",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "Lembre-se sempre de interpretar a primeira coluna, AC, como o local onde o vetor da primeira base pousa, e a segunda coluna, BD, como o local onde o vetor da segunda base pousa.",
  "model": "google_nmt",
  "from_community_srt": "Sempre se lembre de entender a primeira coluna (a, c) como as coordenadas onde o primeiro vetor base (versor i) cai e a segunda coluna (b,",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "Quando aplicamos esta transformação a algum vetor xy, o que obtemos?",
  "model": "google_nmt",
  "from_community_srt": "d) como as coordenadas do segundo vetor base (versor j) Quando a gente aplicar essa transformação àquele vetor (x, y),",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "Bem, será x vezes AC mais y vezes BD.",
  "model": "google_nmt",
  "from_community_srt": "o que a gente consegue? Bem, será x vezes (a, c) mais y vezes (b,",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "Juntando tudo isso, você obtém um vetor Ax mais By, Cx mais Dy.",
  "model": "google_nmt",
  "from_community_srt": "d). colocando tudo junto você consegue o vetor (ax+by,",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "Você pode até definir isso como multiplicação de vetores de matrizes, quando coloca a matriz à esquerda do vetor como se fosse uma função.",
  "model": "google_nmt",
  "from_community_srt": "cx+dy) Você pode até definir isso como uma multiplicação de um vetor com uma matriz ao colocar a matriz à esquerda do vetor, como se fosse uma função.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "Então, você poderia fazer com que os alunos do ensino médio memorizassem isso sem mostrar a parte crucial que faz com que pareça intuitivo.",
  "model": "google_nmt",
  "from_community_srt": "Daí você pode fazer estudantes do Ensino Médio memorizarem isso, sem mostrar pra eles a parte crucial que faz isso ser intuitivo.",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "Mas não é mais divertido pensar nessas colunas como as versões transformadas dos seus vetores de base e pensar no resultado como a combinação linear apropriada desses vetores?",
  "model": "google_nmt",
  "from_community_srt": "Mas não é mais divertido pensar nessas colunas como versões transformadas dos seus versores",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "Vamos praticar a descrição de algumas transformações lineares com matrizes.",
  "model": "google_nmt",
  "from_community_srt": "e pensar sobre os resultados como a combinação linear apropriada desses vetores? Vamos praticar representar algumas transformações lineares com matrizes.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "Por exemplo, se girarmos todo o espaço 90 graus no sentido anti-horário, então o i-hat pousará nas coordenadas 0, 1.",
  "model": "google_nmt",
  "from_community_srt": "Por exemplo, se a gente rodar todo o espaço noventa graus pro sentido anti-horário; daí i cai nas coordenadas zero,",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "E j-hat pousa nas coordenadas menos 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "um (0, 1) e j cai nas coordenadas menos um, zero.",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "Portanto, a matriz que obtemos tem colunas 0, 1, menos 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "(-1, 0) Então a matriz que a gente consegue tem as colunas (0, 1) e (-1,",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "Para descobrir o que acontece com qualquer vetor após uma rotação de 90 graus, basta multiplicar suas coordenadas por esta matriz.",
  "model": "google_nmt",
  "from_community_srt": "0). Para entender o que acontece com qualquer vetor depois de um giro de noventa graus, você só precisa multiplicar esse vetor com essa matriz.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "Aqui está uma transformação divertida com um nome especial, chamado tesoura.",
  "model": "google_nmt",
  "from_community_srt": "Essa aqui é uma transformação divertida com uma nome especial,",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "Nele, i-hat permanece fixo, então a primeira coluna da matriz é 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "que infelizmente não tem uma tradução para português nela, i fica no lugar então a primeira coluna da matriz é um,",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "Mas j-hat passa para as coordenadas 1, 1, que se tornam a segunda coluna da matriz.",
  "model": "google_nmt",
  "from_community_srt": "zero (1, 0) mas j vai pra coordenada um, um (1, 1), que vira a segunda coluna da matriz.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "E correndo o risco de ser redundante aqui, descobrir como um cisalhamento transforma um determinado vetor se resume a multiplicar esta matriz por aquele vetor.",
  "model": "google_nmt",
  "from_community_srt": "E correndo o risco de ser redundante aqui, para descobrir como essa transformação afeta algum vetor é só multiplicar essa matriz por esse vetor.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "Digamos que queremos fazer o contrário, começando com uma matriz, digamos, com as colunas 1, 2 e 3, 1, e queremos deduzir como é a sua transformação.",
  "model": "google_nmt",
  "from_community_srt": "Digamos que queremos fazer o contrário, começando com uma matriz, digamos, com colunas um, dois e três, um (1, 2), (3, 1) e nós queremos descobrir como essa transformação se parece.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "Faça uma pausa e pare um momento para ver se você consegue imaginar isso.",
  "model": "google_nmt",
  "from_community_srt": "Pause e dê um minuto pra ver se você consegue imaginá-la.",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "Uma maneira de fazer isso é primeiro mover o i-hat para 1, 2 e, em seguida, mover o j-hat para 3, 1.",
  "model": "google_nmt",
  "from_community_srt": "Uma maneira de fazer isso é mover i para (1, 2) depois mover j para (3,",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "Sempre movendo o resto do espaço de forma a manter as linhas de grade paralelas e espaçadas uniformemente.",
  "model": "google_nmt",
  "from_community_srt": "1) sempre movendo o resto do espaço de um jeito que mantenha as linhas paralelas paralelas e com o mesmo espaço umas das outras",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "Se os vetores em que i-hat e j-hat pousam são linearmente dependentes, o que, se você se lembra do último vídeo, significa que um é uma versão em escala do outro, isso significa que a transformação linear comprime todo o espaço 2D no linha onde esses dois vetores estão, também conhecida como extensão unidimensional desses dois vetores linearmente dependentes.",
  "model": "google_nmt",
  "from_community_srt": "se os vetores em que i e j caem são linearmente dependentes, o que, se você lembra do último video, significa que um é uma versão paralela e multiplicada do outro isso significa que a transformação linear espreme todo o espaço 2D para dentro da linha onde ficam esses vetores, também conhecida como o espaço gerado unidimensional desses dois vetores linearmente dependentes.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "Resumindo, as transformações lineares são uma forma de se mover pelo espaço de forma que as linhas de grade permaneçam paralelas e espaçadas uniformemente, e de forma que a origem permaneça fixa.",
  "model": "google_nmt",
  "from_community_srt": "Resumindo, transformações lineares são uma maneira de mover o espaço por aí de forma que linhas paralelas continuem paralelas e na mesma distância umas das outras e a origem fique no lugar.",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "Felizmente, essas transformações podem ser descritas usando apenas alguns números, as coordenadas de onde cada vetor de base pousa.",
  "model": "google_nmt",
  "from_community_srt": "Deliciosamente, essas transformações podem ser representadas com apenas um punhado de números. As coordenadas de onde cada vetor base termina depois de tal transformação.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "As matrizes nos fornecem uma linguagem para descrever essas transformações, onde as colunas representam essas coordenadas, e a multiplicação de vetores de matrizes é apenas uma maneira de calcular o que essa transformação faz com um determinado vetor.",
  "model": "google_nmt",
  "from_community_srt": "Matrizes nos dão uma linguagem para representar essas transformações, onde as colunas representam essas coordenadas e a multiplicação de vetores com matrizes é só um jeito de calcular o que aquela transformação faz com dado vetor.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "A conclusão importante aqui é que cada vez que você vê uma matriz, você pode interpretá-la como uma certa transformação do espaço.",
  "model": "google_nmt",
  "from_community_srt": "O que é importante lembrar aqui é que cada vez que você vê uma matriz, você pode interpletá-la como uma certa transformação no espaço.",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "Depois de realmente digerir essa ideia, você estará em uma ótima posição para compreender profundamente a álgebra linear.",
  "model": "google_nmt",
  "from_community_srt": "quando você realmente entende esta ideia, você está em uma ótima posição para entender álgebra linear profundamente.",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "Quase todos os tópicos que surgirão, desde multiplicação de matrizes até determinantes, mudança de base, autovalores, todos eles se tornarão mais fáceis de entender quando você começar a pensar em matrizes como transformações de espaço.",
  "model": "google_nmt",
  "from_community_srt": "Quase todos dos tópicos que estão chegando, de multiplicação de matrizes à determinantes, mudança de bases à eigenvalues... Todos esses assuntos se tornarão mais fáceis de entender uma vez que você começe a pensar sobre matrizes como transformações no espaço.",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "Mais imediatamente, no próximo vídeo, falarei sobre a multiplicação de duas matrizes.",
  "model": "google_nmt",
  "from_community_srt": "Quase imediatamente, no próximo video, Eu falarei sobre multiplicação de duas matrizes.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]