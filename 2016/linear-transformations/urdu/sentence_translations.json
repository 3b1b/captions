[
 {
  "input": "Hey everyone! ",
  "translatedText": "سلام سب کو! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one. ",
  "translatedText": "اگر مجھے صرف ایک موضوع کا انتخاب کرنا ہو جس سے لکیری الجبرا میں موجود باقی سبھی پر کلک کرنا شروع ہو جائے، اور جو اکثر طالب علم کے پہلی بار لکیری الجبرا لینے کے بعد سیکھا نہیں جاتا ہے، تو یہ وہی ہوگا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices. ",
  "translatedText": "لکیری تبدیلی کا نظریہ اور میٹرکس سے اس کا تعلق۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication. ",
  "translatedText": "اس ویڈیو کے لیے، میں صرف اس بات پر توجہ مرکوز کرنے جا رہا ہوں کہ یہ تبدیلیاں دو جہتوں کے معاملے میں کیسی نظر آتی ہیں، اور ان کا میٹرکس ویکٹر ضرب کے خیال سے کیا تعلق ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization. ",
  "translatedText": "خاص طور پر، میں آپ کو میٹرکس ویکٹر ضرب کے بارے میں سوچنے کا ایک طریقہ دکھانا چاہتا ہوں جو حفظ پر انحصار نہیں کرتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation. ",
  "translatedText": "شروع کرنے کے لیے، آئیے صرف اس اصطلاح کو پارس کرتے ہیں، لکیری تبدیلی۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function. ",
  "translatedText": "تبدیلی بنیادی طور پر فنکشن کے لیے ایک فینسی لفظ ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one. ",
  "translatedText": "یہ ایسی چیز ہے جو ان پٹ لیتی ہے اور ہر ایک کے لیے آؤٹ پٹ نکالتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector. ",
  "translatedText": "خاص طور پر، لکیری الجبرا کے تناظر میں، ہم ان تبدیلیوں کے بارے میں سوچنا پسند کرتے ہیں جو کچھ ویکٹر میں لے جاتے ہیں اور دوسرے ویکٹر کو تھوک دیتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing? ",
  "translatedText": "تو فنکشن کے بجائے تبدیلی کا لفظ کیوں استعمال کریں اگر ان کا مطلب ایک ہی ہے؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation. ",
  "translatedText": "ٹھیک ہے، اس ان پٹ-آؤٹ پٹ تعلق کو تصور کرنے کے لیے ایک خاص طریقہ کا مشورہ دینا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement. ",
  "translatedText": "آپ دیکھتے ہیں، ویکٹر کے افعال کو سمجھنے کا ایک بہترین طریقہ حرکت کا استعمال ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector. ",
  "translatedText": "اگر کوئی تبدیلی کچھ ان پٹ ویکٹر کو کچھ آؤٹ پٹ ویکٹر میں لے جاتی ہے، تو ہم تصور کرتے ہیں کہ ان پٹ ویکٹر آؤٹ پٹ ویکٹر پر منتقل ہوتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector. ",
  "translatedText": "پھر تبدیلی کو مجموعی طور پر سمجھنے کے لیے، ہم تصور کر سکتے ہیں کہ ہر ممکنہ ان پٹ ویکٹر کو اس کے متعلقہ آؤٹ پٹ ویکٹر پر منتقل کرتے ہوئے دیکھیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow. ",
  "translatedText": "تمام ویکٹرز کے بارے میں ایک ساتھ سوچنے کے لیے بہت ہجوم ہو جاتا ہے، ہر ایک کو تیر کی طرح۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits. ",
  "translatedText": "لہذا، جیسا کہ میں نے پچھلی ویڈیو کا ذکر کیا ہے، ایک اچھی چال یہ ہے کہ ہر ویکٹر کو تیر کے طور پر نہیں بلکہ ایک نقطہ کے طور پر تصور کیا جائے، وہ نقطہ جہاں اس کی نوک بیٹھتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point. ",
  "translatedText": "اس طرح، ہر ممکنہ ان پٹ ویکٹر کو کسی آؤٹ پٹ ویکٹر میں لے جانے والی تبدیلی کے بارے میں سوچنے کے لیے، ہم خلا میں ہر نقطہ کو کسی دوسرے مقام پر منتقل ہوتے دیکھتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid. ",
  "translatedText": "دو جہتوں میں ہونے والی تبدیلیوں کے معاملے میں، تبدیلی کی پوری شکل کو بہتر محسوس کرنے کے لیے، میں یہ ایک لامحدود گرڈ پر موجود تمام پوائنٹس کے ساتھ کرنا پسند کرتا ہوں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts. ",
  "translatedText": "میں کبھی کبھی گرڈ کی ایک کاپی کو پس منظر میں رکھنا بھی پسند کرتا ہوں صرف اس بات پر نظر رکھنے میں مدد کے لیے کہ ہر چیز کہاں سے شروع ہوتی ہے اس کے مقابلے میں کہاں ختم ہوتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful. ",
  "translatedText": "خلا میں تمام پوائنٹس کے گرد گھومنے والی مختلف تبدیلیوں کا اثر ہے، آپ کو تسلیم کرنا پڑے گا، خوبصورت۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself. ",
  "translatedText": "یہ خود کو squishing اور morphing جگہ کا احساس دیتا ہے. ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated. ",
  "translatedText": "جیسا کہ آپ تصور کر سکتے ہیں، صوابدیدی تبدیلیاں کافی پیچیدہ لگ سکتی ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations. ",
  "translatedText": "لیکن خوش قسمتی سے، لکیری الجبرا خود کو ایک خاص قسم کی تبدیلی تک محدود رکھتا ہے، جنہیں سمجھنا آسان ہے، جسے لکیری تبدیلی کہتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties. ",
  "translatedText": "بصری طور پر، ایک تبدیلی لکیری ہے اگر اس میں دو خصوصیات ہوں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place. ",
  "translatedText": "تمام لکیروں کو خمیدہ ہوئے بغیر لائنوں میں رہنا چاہیے، اور اصل جگہ پر قائم رہنا چاہیے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy. ",
  "translatedText": "مثال کے طور پر، یہاں یہ لکیری تبدیلی نہیں ہوگی، کیونکہ لائنیں تمام منحنی ہو جاتی ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin. ",
  "translatedText": "اور یہ یہاں پر، اگرچہ یہ لکیروں کو سیدھا رکھتا ہے، لیکن یہ لکیری تبدیلی نہیں ہے، کیونکہ یہ اصل کو حرکت دیتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines. ",
  "translatedText": "یہ یہاں اصل کو ٹھیک کرتا ہے، اور ایسا لگتا ہے کہ یہ لائنوں کو سیدھا رکھتا ہے، لیکن یہ صرف اس لیے ہے کہ میں صرف افقی اور عمودی گرڈ لائنیں دکھا رہا ہوں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy. ",
  "translatedText": "جب آپ دیکھتے ہیں کہ یہ ترچھی لکیر کے ساتھ کیا کرتا ہے، تو یہ واضح ہو جاتا ہے کہ یہ بالکل لکیری نہیں ہے، کیونکہ یہ اس لکیر کو تمام منحنی کر دیتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced. ",
  "translatedText": "عام طور پر، آپ کو لکیری تبدیلیوں کے بارے میں سوچنا چاہیے کہ گرڈ لائنوں کو متوازی اور یکساں طور پر فاصلہ رکھتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin. ",
  "translatedText": "کچھ لکیری تبدیلیوں کے بارے میں سوچنا آسان ہے، جیسے کہ اصل کے بارے میں گردش۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words. ",
  "translatedText": "دوسرے الفاظ کے ساتھ بیان کرنے میں تھوڑا مشکل ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So how do you think you could describe these transformations numerically? ",
  "translatedText": "تو آپ کیسے سوچتے ہیں کہ آپ ان تبدیلیوں کو عددی طور پر بیان کر سکتے ہیں؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands? ",
  "translatedText": "اگر آپ کسی موضوع کو سکھانے والی ویڈیو بنانے کے لیے کچھ اینیمیشن پروگرام کر رہے تھے، تو آپ کمپیوٹر کو کیا فارمولہ دیتے ہیں تاکہ اگر آپ اسے کسی ویکٹر کے کوآرڈینیٹ دیں، تو یہ آپ کو اس کے نقاط دے سکے جہاں وہ ویکٹر اترتا ہے؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that. ",
  "translatedText": "اس سے پتہ چلتا ہے کہ آپ کو صرف یہ ریکارڈ کرنے کی ضرورت ہے کہ دو بنیادوں کے ویکٹر، i-hat اور j-hat، ہر ایک زمین، اور باقی سب کچھ اس سے کہاں چلے گا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat. ",
  "translatedText": "مثال کے طور پر، نقاط منفی 1، 2 کے ساتھ ویکٹر v پر غور کریں، یعنی یہ منفی 1 گنا i-hat کے علاوہ 2 گنا j-hat کے برابر ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence. ",
  "translatedText": "اگر ہم کچھ تبدیلی کرتے ہیں اور اس کی پیروی کرتے ہیں کہ یہ تینوں ویکٹر کہاں جاتے ہیں، تو وہ خاصیت جو گرڈ لائنیں متوازی رہتی ہیں اور یکساں طور پر فاصلہ رکھتی ہیں اس کا واقعی ایک اہم نتیجہ ہوتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed. ",
  "translatedText": "وہ جگہ جہاں v لینڈ کرتا ہے اس ویکٹر سے 1 گنا منفی ہوگا جہاں i-hat اترا ہے اور اس ویکٹر سے 2 گنا جہاں j-hat اترا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed. ",
  "translatedText": "دوسرے لفظوں میں، یہ i-hat اور j-hat کے ایک مخصوص لکیری امتزاج کے طور پر شروع ہوا، اور یہ اسی لکیری امتزاج کے طور پر ختم ہوتا ہے جہاں وہ دو ویکٹر اترے تھے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land. ",
  "translatedText": "اس کا مطلب ہے کہ آپ اندازہ لگا سکتے ہیں کہ v کو کہاں جانا چاہیے صرف اس بنیاد پر کہ i-hat اور j-hat ہر ایک زمین پر۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background. ",
  "translatedText": "یہی وجہ ہے کہ مجھے اصل گرڈ کی ایک کاپی پس منظر میں رکھنا پسند ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0. ",
  "translatedText": "یہاں دکھائی جانے والی تبدیلی کے لیے، ہم پڑھ سکتے ہیں کہ i-hat نقاط 1، منفی 2، اور j-ہیٹ کوآرڈینیٹ 3، 0 پر x-axis پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0. ",
  "translatedText": "اس کا مطلب ہے کہ منفی 1 i-hat جمع 2 بار j-hat سے ظاہر ہونے والا ویکٹر ویکٹر 1 کے منفی 1 گنا، منفی 2 جمع 2 گنا ویکٹر 3، 0 پر ختم ہوتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2. ",
  "translatedText": "ان سب کو ملا کر، آپ اندازہ لگا سکتے ہیں کہ اسے ویکٹر 5، 2 پر اترنا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important. ",
  "translatedText": "یہ توقف اور غور کرنے کا ایک اچھا نقطہ ہے، کیونکہ یہ بہت اہم ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2. ",
  "translatedText": "اب، یہ دیکھتے ہوئے کہ میں اصل میں آپ کو مکمل تبدیلی دکھا رہا ہوں، آپ صرف یہ دیکھ سکتے تھے کہ v میں نقاط 5، 2 ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself. ",
  "translatedText": "لیکن یہاں اچھی بات یہ ہے کہ اس سے ہمیں یہ اندازہ لگانے کی ایک تکنیک ملتی ہے کہ کوئی بھی ویکٹر اس وقت تک کہاں اترتا ہے جب تک کہ ہمارے پاس اس بات کا ریکارڈ موجود ہے کہ ہر زمین کہاں آئی-ہیٹ اور جے-ہیٹ ہے، بغیر تبدیلی کو دیکھنے کی ضرورت ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0. ",
  "translatedText": "ویکٹر کو مزید عمومی نقاط کے ساتھ لکھیں، x اور y، اور یہ اس ویکٹر کے x گنا پر اترے گا جہاں i-hat اترتا ہے، 1، منفی 2، اور y بار اس ویکٹر پر جہاں j-hat اترتا ہے، 3، 0۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y. ",
  "translatedText": "اس رقم کو لے کر، آپ دیکھیں گے کہ یہ 1x جمع 3y، منفی 2x جمع 0y پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula. ",
  "translatedText": "میں آپ کو کوئی ویکٹر دیتا ہوں، اور آپ مجھے بتا سکتے ہیں کہ اس فارمولے کو استعمال کرتے ہوئے وہ ویکٹر کہاں اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands. ",
  "translatedText": "یہ سب جو کچھ کہہ رہا ہے وہ یہ ہے کہ ایک دو جہتی لکیری تبدیلی کو مکمل طور پر صرف چار نمبروں سے بیان کیا گیا ہے، دو کوآرڈینیٹ اس کے لیے جہاں i-hat اترتے ہیں، اور دو کوآرڈینیٹ جہاں j-hat اترتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool? ",
  "translatedText": "کیا یہ ٹھنڈا نہیں ہے؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land. ",
  "translatedText": "ان نقاط کو نمبروں کے 2x2 گرڈ میں پیک کرنا ایک عام بات ہے جسے 2x2 میٹرکس کہا جاتا ہے، جہاں آپ کالموں کو دو خاص ویکٹرز کے طور پر تشریح کر سکتے ہیں جہاں ہر زمین میں i-hat اور j-hat ہوتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get. ",
  "translatedText": "اگر آپ کو ایک لکیری تبدیلی اور کچھ مخصوص ویکٹر کو بیان کرنے والا 2x2 میٹرکس دیا گیا ہے، اور آپ جاننا چاہتے ہیں کہ لکیری تبدیلی اس ویکٹر کو کہاں لے جاتی ہے، تو آپ ویکٹر کے نقاط لے سکتے ہیں، انہیں میٹرکس کے متعلقہ کالموں سے ضرب دے سکتے ہیں، پھر جو کچھ آپ کو ملتا ہے اسے شامل کریں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors. ",
  "translatedText": "یہ ہمارے نئے بنیادی ویکٹرز کے سکیلڈ ورژن کو شامل کرنے کے خیال سے مطابقت رکھتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D. ",
  "translatedText": "آئیے دیکھتے ہیں کہ یہ سب سے عام صورت میں کیسا لگتا ہے، جہاں آپ کے میٹرکس میں A, B, C, D کے اندراجات ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation. ",
  "translatedText": "اور یاد رکھیں، یہ میٹرکس لکیری تبدیلی کو بیان کرنے کے لیے درکار معلومات کو پیک کرنے کا صرف ایک طریقہ ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands. ",
  "translatedText": "ہمیشہ یاد رکھیں کہ پہلے کالم، AC، کو اس جگہ کے طور پر جہاں پہلا بنیاد ویکٹر اترتا ہے، اور اس دوسرے کالم، BD کو، اس جگہ کے طور پر جہاں دوسرا بنیاد ویکٹر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get? ",
  "translatedText": "جب ہم اس تبدیلی کو کسی ویکٹر x, y پر لاگو کرتے ہیں تو آپ کو کیا ملتا ہے؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD. ",
  "translatedText": "ٹھیک ہے، یہ ایکس گنا AC پلس y گنا BD ہوگا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy. ",
  "translatedText": "اسے اکٹھا کرنے سے، آپ کو ایک ویکٹر Ax Plus By، Cx پلس Dy ملتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function. ",
  "translatedText": "آپ اسے میٹرکس ویکٹر ضرب کے طور پر بھی بیان کر سکتے ہیں جب آپ میٹرکس کو ویکٹر کے بائیں طرف رکھتے ہیں جیسے یہ ایک فنکشن ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive. ",
  "translatedText": "پھر آپ ہائی اسکول والوں کو وہ اہم حصہ دکھائے بغیر اسے حفظ کروا سکتے ہیں جو اسے بدیہی محسوس کرتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors? ",
  "translatedText": "لیکن کیا ان کالموں کے بارے میں اپنے بنیادی ویکٹر کے تبدیل شدہ ورژن کے طور پر سوچنا اور ان ویکٹروں کے مناسب لکیری امتزاج کے طور پر نتیجہ کے بارے میں سوچنا زیادہ مزہ نہیں آتا؟ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices. ",
  "translatedText": "آئیے میٹرکس کے ساتھ چند لکیری تبدیلیوں کو بیان کرنے کی مشق کریں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0. ",
  "translatedText": "مثال کے طور پر، اگر ہم پوری جگہ کو 90 ڈگری مخالف گھڑی کی سمت میں گھمائیں، تو I-hat نقاط 0، 1 پر اترتا ہے، اور J-hat نقاط منفی 1، 0 پر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.58,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0. ",
  "translatedText": "لہذا ہم جس میٹرکس کے ساتھ ختم ہوتے ہیں اس میں کالم 0، 1، منفی 1، 0 ہوتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix. ",
  "translatedText": "یہ جاننے کے لیے کہ 90 ڈگری کی گردش کے بعد کسی بھی ویکٹر کا کیا ہوتا ہے، آپ اس میٹرکس سے اس کے نقاط کو ضرب دے سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear. ",
  "translatedText": "یہاں ایک خاص نام کے ساتھ ایک تفریحی تبدیلی ہے، جسے شیئر کہتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix. ",
  "translatedText": "اس میں، I-ہیٹ فکس رہتا ہے، لہذا میٹرکس کا پہلا کالم 1، 0 ہے، لیکن J-hat کوآرڈینیٹ 1، 1 پر منتقل ہوتا ہے، جو میٹرکس کا دوسرا کالم بن جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.0,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector. ",
  "translatedText": "اور یہاں بے کار ہونے کے خطرے پر، یہ معلوم کرنا کہ کس طرح ایک قینچ دیے گئے ویکٹر کو تبدیل کرتی ہے اس میٹرکس کو اس ویکٹر سے ضرب دینے پر۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like. ",
  "translatedText": "آئیے کہتے ہیں کہ ہم میٹرکس سے شروع کرتے ہوئے، کالم 1، 2، اور 3، 1 کے ساتھ کہیں اور جانا چاہتے ہیں، اور ہم یہ اندازہ لگانا چاہتے ہیں کہ اس کی تبدیلی کیسی نظر آتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it. ",
  "translatedText": "توقف کریں اور ایک لمحہ نکال کر دیکھیں کہ کیا آپ اس کا تصور کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced. ",
  "translatedText": "ایسا کرنے کا ایک طریقہ یہ ہے کہ پہلے I-hat کو 1, 2 پر منتقل کریں، پھر J-hat کو 3, 1 پر منتقل کریں، باقی جگہ کو ہمیشہ اس طرح منتقل کریں کہ گرڈ لائنوں کو متوازی اور یکساں فاصلہ بنائے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.42,
  "end": 560.22
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors. ",
  "translatedText": "اگر I-hat اور J-hat پر اترنے والے ویکٹر لکیری طور پر منحصر ہیں، جو اگر آپ کو پچھلی ویڈیو سے یاد ہے، تو اس کا مطلب ہے کہ ایک دوسرے کا سکیلڈ ورژن ہے، تو اس کا مطلب ہے کہ لکیری تبدیلی تمام 2D اسپیس کو اسکوئیش کر دیتی ہے۔ وہ لکیر جہاں وہ دو ویکٹر بیٹھتے ہیں، جسے ان دو لکیری طور پر منحصر ویکٹرز کا ایک جہتی اسپین بھی کہا جاتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed. ",
  "translatedText": "خلاصہ یہ ہے کہ لکیری تبدیلیاں خلا کے گرد گھومنے کا ایک طریقہ ہیں جیسے کہ گرڈ لائنیں متوازی اور یکساں فاصلہ پر رہیں، اور اس طرح کہ اصلیت قائم رہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands. ",
  "translatedText": "پرواز کے ساتھ، ان تبدیلیوں کو صرف مٹھی بھر نمبروں کا استعمال کرتے ہوئے بیان کیا جا سکتا ہے، اس کے نقاط جہاں ہر بنیاد ویکٹر اترتا ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector. ",
  "translatedText": "میٹرکس ہمیں ان تبدیلیوں کو بیان کرنے کے لیے ایک زبان فراہم کرتا ہے، جہاں کالم ان نقاط کی نمائندگی کرتے ہیں، اور میٹرکس-ویکٹر ضرب یہ شمار کرنے کا ایک طریقہ ہے کہ یہ تبدیلی کسی دیے گئے ویکٹر میں کیا کرتی ہے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space. ",
  "translatedText": "یہاں اہم بات یہ ہے کہ جب بھی آپ میٹرکس دیکھتے ہیں، تو آپ اسے جگہ کی ایک خاص تبدیلی سے تعبیر کر سکتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply. ",
  "translatedText": "ایک بار جب آپ واقعی اس خیال کو ہضم کر لیتے ہیں، تو آپ لکیری الجبرا کو گہرائی سے سمجھنے کے لیے بہت اچھی پوزیشن میں ہوتے ہیں۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space. ",
  "translatedText": "آنے والے تقریباً تمام موضوعات، میٹرکس ضرب سے لے کر تعین کرنے والے، بنیاد کی تبدیلی، ایگنی ویلیوز، ان سب کو سمجھنا آسان ہو جائے گا جب آپ میٹرکس کے بارے میں خلا کی تبدیلی کے طور پر سوچنا شروع کر دیں گے۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together. ",
  "translatedText": "فوری طور پر، اگلی ویڈیو میں، میں دو میٹرک کو ایک ساتھ ضرب کرنے کے بارے میں بات کروں گا۔ ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.3,
  "end": 645.66
 },
 {
  "input": "See you then! ",
  "translatedText": "پھر آپ دیکھیں! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 645.66
 },
 {
  "input": "Thank you for watching! ",
  "translatedText": "دیکھنے کا شکریہ! ",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 646.32
 }
]