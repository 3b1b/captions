[
 {
  "input": "Hey everyone! ",
  "translatedText": "嘿大家！",
  "model": "nmt",
  "time_range": [
   12.040000000000004,
   12.92
  ]
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one. ",
  "translatedText": "如果我必须选择一个主题，让线性代数中的所有其 他主题都开始吸引人，并且学生第一次学习线性 代数时往往会忘记这个主题，那么它就是这个。",
  "model": "nmt",
  "time_range": [
   13.32,
   22.28
  ]
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices. ",
  "translatedText": "线性变换的思想及其与矩阵的关系。",
  "model": "nmt",
  "time_range": [
   22.7,
   26.2
  ]
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication. ",
  "translatedText": "在本视频中，我将重点介绍这些变换在二维情况下的 样子，以及它们与矩阵向量乘法的概念有何关系。",
  "model": "nmt",
  "time_range": [
   26.95,
   35.06
  ]
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization. ",
  "translatedText": "特别是，我想向您展示一种不依赖 于记忆的矩阵向量乘法思考方法。",
  "model": "nmt",
  "time_range": [
   35.88,
   42.08
  ]
 },
 {
  "input": "To start, let's just parse this term, linear transformation. ",
  "translatedText": "首先，我们来解析一下线性变换这个术语。",
  "model": "nmt",
  "time_range": [
   43.16,
   46.58
  ]
 },
 {
  "input": "Transformation is essentially a fancy word for function. ",
  "translatedText": "转变本质上是功能的一个花哨的词。",
  "model": "nmt",
  "time_range": [
   47.42,
   49.88
  ]
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one. ",
  "translatedText": "它接收输入并为每个输入输出一个输出。",
  "model": "nmt",
  "time_range": [
   50.26,
   53.98
  ]
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector. ",
  "translatedText": "具体来说，在线性代数的背景下，我们喜欢考 虑接受某个向量并输出另一个向量的变换。",
  "model": "nmt",
  "time_range": [
   53.98,
   61.08
  ]
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing? ",
  "translatedText": "那么，如果它们的含义相同，为什么要使用“转换”一词而不是“函数”呢？",
  "model": "nmt",
  "time_range": [
   62.5,
   66.38
  ]
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation. ",
  "translatedText": "嗯，它暗示了一种可视化这种输入-输出关系的某种方式。",
  "model": "nmt",
  "time_range": [
   67.12,
   71.34
  ]
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement. ",
  "translatedText": "你看，理解向量函数的一个好方法是使用运动。",
  "model": "nmt",
  "time_range": [
   71.86,
   75.8
  ]
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector. ",
  "translatedText": "如果转换将某个输入向量转换为某个输出向量 ，我们可以想象该输入向量移动到输出向量。",
  "model": "nmt",
  "time_range": [
   76.78,
   84.86
  ]
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector. ",
  "translatedText": "然后，为了理解整个变换，我们可以想象观察每 个可能的输入向量移动到其相应的输出向量。",
  "model": "nmt",
  "time_range": [
   85.68,
   94.08
  ]
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow. ",
  "translatedText": "一次性考虑所有向量（每个向量 都是一支箭头）真的很拥挤。",
  "model": "nmt",
  "time_range": [
   94.98,
   99.12
  ]
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits. ",
  "translatedText": "因此，正如我在上一个视频中提到的，一个很好的技巧是将每 个向量概念化为一个点，而不是箭头，即其尖端所在的点。",
  "model": "nmt",
  "time_range": [
   99.5,
   107.42
  ]
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point. ",
  "translatedText": "这样，为了考虑将每个可能的输入向量转换为某个输出 向量的变换，我们观察空间中的每个点移动到其他点。",
  "model": "nmt",
  "time_range": [
   108.03,
   116.34
  ]
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid. ",
  "translatedText": "在二维变换的情况下，为了更好地了解变换的整体 形状，我喜欢对无限网格上的所有点执行此操作。",
  "model": "nmt",
  "time_range": [
   117.22,
   125.78
  ]
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts. ",
  "translatedText": "有时我还喜欢在后台保留网格的副本，以帮助 跟踪所有内容相对于其开始位置的结束位置。",
  "model": "nmt",
  "time_range": [
   126.56,
   132.84
  ]
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful. ",
  "translatedText": "你必须承认，围绕空间中所有点移 动的各种变换的效果是美丽的。",
  "model": "nmt",
  "time_range": [
   134.46,
   141.08
  ]
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself. ",
  "translatedText": "它给人一种空间本身被挤压和变形的感觉。",
  "model": "nmt",
  "time_range": [
   141.88,
   144.64
  ]
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated. ",
  "translatedText": "正如您可以想象的那样，任意转换可能看起来非常复杂。",
  "model": "nmt",
  "time_range": [
   145.6,
   149.92
  ]
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations. ",
  "translatedText": "但幸运的是，线性代数将自己限制为一种特殊类型 的变换，这种变换更容易理解，称为线性变换。",
  "model": "nmt",
  "time_range": [
   150.38,
   158.28
  ]
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties. ",
  "translatedText": "从视觉上来说，如果一个变换具有两个属性，那么它就是线性的。",
  "model": "nmt",
  "time_range": [
   159.12,
   163.06
  ]
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place. ",
  "translatedText": "所有线条都必须保持直线而不会弯曲，并且原点必须保持固定。",
  "model": "nmt",
  "time_range": [
   163.7,
   169.6
  ]
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy. ",
  "translatedText": "例如，这里不会是线性变换 ，因为线条都是弯曲的。",
  "model": "nmt",
  "time_range": [
   170.62,
   175.54
  ]
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin. ",
  "translatedText": "这里的这个虽然保持了直线，但不 是线性变换，因为它移动了原点。",
  "model": "nmt",
  "time_range": [
   176.1,
   181.86
  ]
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines. ",
  "translatedText": "这里修复了原点，看起来可能使线条保持直线 ，但这只是因为我只显示水平和垂直网格线。",
  "model": "nmt",
  "time_range": [
   182.68,
   189.24
  ]
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy. ",
  "translatedText": "当你看到它对对角线的作用时，你会发现它根 本不是线性的，因为它使那条线变成了曲线。",
  "model": "nmt",
  "time_range": [
   189.54,
   195.32
  ]
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced. ",
  "translatedText": "一般来说，您应该将线性变换视 为保持网格线平行且均匀分布。",
  "model": "nmt",
  "time_range": [
   196.76,
   202.24
  ]
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin. ",
  "translatedText": "一些线性变换很容易理解，例如绕原点的旋转。",
  "model": "nmt",
  "time_range": [
   203.4,
   207.54
  ]
 },
 {
  "input": "Others are a little trickier to describe with words. ",
  "translatedText": "其他的则难以用语言来描述。",
  "model": "nmt",
  "time_range": [
   208.12,
   210.6
  ]
 },
 {
  "input": "So how do you think you could describe these transformations numerically? ",
  "translatedText": "那么您认为如何用数字来描述这些转变呢？",
  "model": "nmt",
  "time_range": [
   212.04,
   215.48
  ]
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands? ",
  "translatedText": "比如说，如果你正在编写一些动画来制作一个教授该 主题的视频，你会给计算机什么公式，以便如果你给 它一个向量的坐标，它可以给你该向量落地的坐标？",
  "model": "nmt",
  "time_range": [
   215.48,
   227.24
  ]
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that. ",
  "translatedText": "事实证明，您只需要记录两个基向量（i-hat 和 j -hat）各自的着陆点，其他所有内容都将随之而来。",
  "model": "nmt",
  "time_range": [
   228.48,
   236.6
  ]
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat. ",
  "translatedText": "例如，考虑坐标为负 1, 2 的向量 v，这意味着它等 于负 1 乘以 i-hat 加 2 乘以 j-hat。",
  "model": "nmt",
  "time_range": [
   237.5,
   245.7
  ]
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence. ",
  "translatedText": "如果我们进行一些变换并跟踪所有这三个向量的走向，则网 格线保持平行且均匀分布的属性会产生非常重要的结果。",
  "model": "nmt",
  "time_range": [
   248.68,
   258.3
  ]
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed. ",
  "translatedText": "v 落地的位置将为负 1 乘以 i-hat 落 地向量加上 2 乘以 j-hat 落地向量。",
  "model": "nmt",
  "time_range": [
   259.1,
   265.4
  ]
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed. ",
  "translatedText": "换句话说，它开始时是 i-hat 和 j-hat 的 某种线性组合，最终是这两个向量落地的相同线性组合。",
  "model": "nmt",
  "time_range": [
   265.98,
   274.58
  ]
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land. ",
  "translatedText": "这意味着您可以仅根据 i-hat 和 j-hat 各自着陆的位置来推断 v 必须去的位置。",
  "model": "nmt",
  "time_range": [
   275.62,
   280.92
  ]
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background. ",
  "translatedText": "这就是为什么我喜欢在后台保留原始网格的副本。",
  "model": "nmt",
  "time_range": [
   281.58,
   284.54
  ]
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0. ",
  "translatedText": "对于此处显示的变换，我们可以读出 i-hat 落在坐标 1、负 2 上，而 j-hat 落在 x 轴上的坐标 3、0 处。",
  "model": "nmt",
  "time_range": [
   285.08,
   294.94
  ]
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0. ",
  "translatedText": "这意味着由负 1 i-hat 加上 2 乘以 j-hat 表示的向 量最终为负 1 乘以向量 1、负 2 加上 2 乘以向量 3、0。",
  "model": "nmt",
  "time_range": [
   295.53999999999996,
   306.14
  ]
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2. ",
  "translatedText": "将所有这些加在一起，您可以推断出它必须落在向量 5, 2 上。",
  "model": "nmt",
  "time_range": [
   307.1,
   311.68
  ]
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important. ",
  "translatedText": "这是一个值得停下来思考的好点，因为它非常重要。",
  "model": "nmt",
  "time_range": [
   314.26,
   317.24
  ]
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2. ",
  "translatedText": "现在，鉴于我实际上向您展示了完整的变换， 您可以只查看 v 的坐标为 5, 2。",
  "model": "nmt",
  "time_range": [
   318.52,
   325.28
  ]
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself. ",
  "translatedText": "但这里最酷的部分是，这为我们提供了一种技术，只要我们 有 i-hat 和 j-hat 每个落地位置的记录， 就可以推断出任何向量落地的位置，而无需观察转换本身。",
  "model": "nmt",
  "time_range": [
   325.76,
   337.38
  ]
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0. ",
  "translatedText": "用更通用的坐标 x 和 y 写入向量，它将落在 x 乘以 i-hat 落在 的向量上，1，负 2，加上 y 乘以 j-hat 落在的向量，3, 0。",
  "model": "nmt",
  "time_range": [
   338.6,
   350.6
  ]
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y. ",
  "translatedText": "执行该求和，您会发现结果为 1x 加 3y，负 2x 加 0y。",
  "model": "nmt",
  "time_range": [
   351.86,
   358.1
  ]
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula. ",
  "translatedText": "我给你任何向量，你可以使用这个公式告诉我该向量落在哪里。",
  "model": "nmt",
  "time_range": [
   358.74,
   363.58
  ]
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands. ",
  "translatedText": "所有这些的意思是，二维线性变换完全由四个数 字描述，即 i-hat 所在位置的两个坐标 ，以及 j-hat 所在位置的两个坐标。",
  "model": "nmt",
  "time_range": [
   364.86,
   376.5
  ]
 },
 {
  "input": "Isn't that cool? ",
  "translatedText": "这不是很酷吗？",
  "model": "nmt",
  "time_range": [
   377.08,
   377.64
  ]
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land. ",
  "translatedText": "通常将这些坐标打包到称为 2x2 矩阵的 2x 2 数字网格中，您可以将其中的列解释为 i-h at 和 j-hat 各自所在的两个特殊向量。",
  "model": "nmt",
  "time_range": [
   378.38,
   389.64
  ]
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get. ",
  "translatedText": "如果给定一个描述线性变换和某个特定向量的 2x2 矩阵，并且您想知道该线性变换将该 向量带到哪里，则可以获取向量的坐标，将它们 乘以矩阵的相应列，然后把你得到的加起来。",
  "model": "nmt",
  "time_range": [
   390.38,
   407.34
  ]
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors. ",
  "translatedText": "这与添加新基向量的缩放版本的想法相对应。",
  "model": "nmt",
  "time_range": [
   408.18,
   412.72
  ]
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D. ",
  "translatedText": "让我们看看在最一般的情况下， 矩阵有条目 A、B、C、D。",
  "model": "nmt",
  "time_range": [
   414.72,
   420.54
  ]
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation. ",
  "translatedText": "请记住，该矩阵只是打包描述线 性变换所需信息的一种方式。",
  "model": "nmt",
  "time_range": [
   421.1,
   426.24
  ]
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands. ",
  "translatedText": "始终记住将第一列 AC 解释为第一个基向量落地的位 置，将第二列 BD 解释为第二个基向量落地的位置。",
  "model": "nmt",
  "time_range": [
   426.24,
   436.44
  ]
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get? ",
  "translatedText": "当我们将此变换应用于某个向量 x、y 时，您会得到什么？",
  "model": "nmt",
  "time_range": [
   437.5,
   441.0
  ]
 },
 {
  "input": "Well, it'll be x times AC plus y times BD. ",
  "translatedText": "嗯，就是 x 乘以 AC 加 y 乘以 BD。",
  "model": "nmt",
  "time_range": [
   442.06,
   446.98
  ]
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy. ",
  "translatedText": "把它们放在一起，你得到一个向量 Ax 加 By，Cx 加 Dy。",
  "model": "nmt",
  "time_range": [
   448.06,
   453.3
  ]
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function. ",
  "translatedText": "当您将矩阵像函数一样放在向量的左侧时 ，您甚至可以将其定义为矩阵向量乘法。",
  "model": "nmt",
  "time_range": [
   453.98,
   460.94
  ]
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive. ",
  "translatedText": "然后你可以让高中生记住这一点，而不 向他们展示使其感觉直观的关键部分。",
  "model": "nmt",
  "time_range": [
   461.66,
   466.62
  ]
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors? ",
  "translatedText": "但是，将这些列视为基向量的转换 版本，并将结果视为这些向量的 适当线性组合，不是更有趣吗？",
  "model": "nmt",
  "time_range": [
   468.3,
   477.96
  ]
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices. ",
  "translatedText": "让我们练习描述一些矩阵线性变换。",
  "model": "nmt",
  "time_range": [
   480.72,
   483.78
  ]
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0. ",
  "translatedText": "例如，如果我们将整个空间逆时针旋转 90 度，则 I-hat 落在坐标 0, 1 上，J-hat 落在坐标负 1, 0 上。",
  "model": "nmt",
  "time_range": [
   484.58,
   497.18
  ]
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0. ",
  "translatedText": "所以我们最终得到的矩阵有列 0、1，负列 1、0。",
  "model": "nmt",
  "time_range": [
   497.98,
   501.96
  ]
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix. ",
  "translatedText": "要弄清楚任何向量旋转 90 度后会发 生什么，只需将其坐标乘以该矩阵即可。",
  "model": "nmt",
  "time_range": [
   502.88,
   509.62
  ]
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear. ",
  "translatedText": "这是一个有趣的变换，有一个特殊的名称，称为剪切。",
  "model": "nmt",
  "time_range": [
   511.56,
   514.3
  ]
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix. ",
  "translatedText": "其中，I-hat 保持固定，因此矩阵的第一列是 1, 0， 但 J-hat 移动到坐标 1, 1，成为矩阵的第二列。",
  "model": "nmt",
  "time_range": [
   515.0,
   525.3
  ]
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector. ",
  "translatedText": "这里冒着多余的风险，弄清楚剪切如何变换 给定向量可以归结为将该矩阵乘以该向量。",
  "model": "nmt",
  "time_range": [
   525.3,
   534.08
  ]
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like. ",
  "translatedText": "假设我们想要反其道而行之，从一个矩阵开始，比如第 1, 2 和 3, 1 列，我们想要推断出它的变换是什么样的。",
  "model": "nmt",
  "time_range": [
   535.76,
   544.52
  ]
 },
 {
  "input": "Pause and take a moment to see if you can imagine it. ",
  "translatedText": "暂停一下，看看你是否能想象得到。",
  "model": "nmt",
  "time_range": [
   544.96,
   547.44
  ]
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced. ",
  "translatedText": "一种方法是首先将 I-hat 移动到 1、2，然后将 J-hat 移动到 3、1，始终以保持网格线平行且均匀分布的方式移动其余空间。",
  "model": "nmt",
  "time_range": [
   548.42,
   560.22
  ]
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors. ",
  "translatedText": "如果 I-hat 和 J-hat 所落在的向量是线性相 关的（如果您还记得上一个视频），这意味着一个是另一个的 缩放版本，这意味着线性变换将所有 2D 空间压缩到这两 个向量所在的线，也称为这两个线性相关向量的一维跨度。",
  "model": "nmt",
  "time_range": [
   561.68,
   582.42
  ]
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed. ",
  "translatedText": "总而言之，线性变换是一种在空间中移动的方法，使 得网格线保持平行且均匀分布，并且原点保持固定。",
  "model": "nmt",
  "time_range": [
   584.4200000000001,
   593.94
  ]
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands. ",
  "translatedText": "轻率地说，这些变换只需使用少数数字 即可描述，即每个基向量落地的坐标。",
  "model": "nmt",
  "time_range": [
   594.54,
   601.5300000000001
  ]
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector. ",
  "translatedText": "矩阵为我们提供了一种描述这些变换的语言， 其中列代表这些坐标，而矩阵向量乘法只是 计算该变换对给定向量的作用的一种方法。",
  "model": "nmt",
  "time_range": [
   602.76,
   614.66
  ]
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space. ",
  "translatedText": "这里重要的一点是，每次看到矩阵时， 您都可以将其解释为某种空间变换。",
  "model": "nmt",
  "time_range": [
   615.36,
   621.88
  ]
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply. ",
  "translatedText": "一旦你真正理解了这个想法， 你就能够深入理解线性代数。",
  "model": "nmt",
  "time_range": [
   622.58,
   627.32
  ]
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space. ",
  "translatedText": "几乎所有即将出现的主题，从矩阵乘法到行列 式、基础变化、特征值，一旦您开始将矩阵视 为空间变换，所有这些都会变得更容易理解。",
  "model": "nmt",
  "time_range": [
   627.66,
   640.56
  ]
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together. ",
  "translatedText": "最直接的是，在下一个视频中 ，我将讨论两个矩阵相乘。",
  "model": "nmt",
  "time_range": [
   641.3,
   645.66
  ]
 },
 {
  "input": "See you then! ",
  "translatedText": "回头见！",
  "model": "nmt",
  "time_range": [
   646.12,
   645.22
  ]
 },
 {
  "input": "Thank you for watching! ",
  "translatedText": "感谢您的观看！",
  "model": "nmt",
  "time_range": [
   645.22,
   646.32
  ]
 }
]