[
 {
  "input": "Hey everyone!",
  "translatedText": "Hej wszystkim!",
  "model": "google_nmt",
  "from_community_srt": "Niestety, nie da się wytłumaczyć, czym jest Matrix. Sam musisz się przekonać. - Morfeusz Witajcie!",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "Gdybym miał wybrać tylko jeden temat, który sprawia, że wszystkie inne algebry liniowej zaczynają działać, i którego zbyt często nie uczy się, gdy uczeń podejmuje się algebry liniowej po raz pierwszy, byłby to ten.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli miałbym wybrać jeden temat dzięki któremu wszystkie inne w algebrze liniowej zaczynają być spójne a który zbyt często zostaje przeoczony przy pierwszym podejściu do algebry liniowej byłby to ten:",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "Idea transformacji liniowej i jej związek z macierzami.",
  "model": "google_nmt",
  "from_community_srt": "idea transformacji liniowej i jej związek z macierzami.",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "W tym filmie skupię się tylko na tym, jak te transformacje wyglądają w przypadku dwóch wymiarów i jak odnoszą się one do idei mnożenia wektorów macierzowych.",
  "model": "google_nmt",
  "from_community_srt": "W tym filmie skupię się na tym jak wyglądają te transformacje w przestrzeni 2 wymiarowej i jak się mają one w stosunku do mnożenia wektorów przez macierz.",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "W szczególności chcę pokazać sposób myślenia o mnożeniu wektorów macierzy, który nie opiera się na zapamiętywaniu.",
  "model": "google_nmt",
  "from_community_srt": "Właściwie, chciałbym Ci pokazać sposób myślenia o mnożeniu macierzy przez wektor w którym nie chodzi o zakuwanie na pamięć.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "Na początek przeanalizujmy ten termin, transformację liniową.",
  "model": "google_nmt",
  "from_community_srt": "Na początek, rozszyfrujmy nazwę: \"transformacja liniowa\".",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "Transformacja to w zasadzie fantazyjne określenie funkcji.",
  "model": "google_nmt",
  "from_community_srt": "\"Transformacja\" to zasadniczo fantazyjna nazwa \"Funkcji\".",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "Jest to coś, co pobiera dane wejściowe i wypluwa dane wyjściowe dla każdego z nich.",
  "model": "google_nmt",
  "from_community_srt": "To coś co bierze wejścia i wyrzuca z siebie wyjścia dla każdego z nich.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "W szczególności w kontekście algebry liniowej lubimy myśleć o transformacjach, które przyjmują pewien wektor i wypluwają inny wektor.",
  "model": "google_nmt",
  "from_community_srt": "Specyficznie w kontekście algebry liniowej, myślimy o transformacji które biorą jakiś wektor i wyrzucają inny wektor.",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "Po co więc używać słowa transformacja zamiast funkcji, skoro oznaczają to samo?",
  "model": "google_nmt",
  "from_community_srt": "Dlaczego więc używać słowa \"transformacja\" zamiast \"funkcja\" jeśli oznaczają to samo? Cóż,",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "Cóż, ma to sugerować pewien sposób wizualizacji tej relacji wejście-wyjście.",
  "model": "google_nmt",
  "from_community_srt": "to dlatego by zasugerować konkretny sposób wyobrażania sobie tej relacji wejścia-wyjścia.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "Widzisz, świetnym sposobem na zrozumienie funkcji wektorów jest użycie ruchu.",
  "model": "google_nmt",
  "from_community_srt": "Widzisz, wspaniały sposobem rozumienia funkcji wektorowych jest użycie przemieszczenia.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "Jeśli transformacja przenosi pewien wektor wejściowy na jakiś wektor wyjściowy, wyobrażamy sobie, że wektor wejściowy przechodzi do wektora wyjściowego.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli transformacja przekłada pewien wektor wejściowy w pewien wektor wyjściowy, wyobrażamy sobie wektor wejściowy przechodzący w wektor wyjściowy.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "Następnie, aby zrozumieć transformację jako całość, możemy wyobrazić sobie obserwowanie, jak każdy możliwy wektor wejściowy przechodzi do odpowiadającego mu wektora wyjściowego.",
  "model": "google_nmt",
  "from_community_srt": "Następnie, żeby zrozumieć transformację całościowo, możemy sobie wyobrazić obserwowanie jak każdy możliwy wektor wejściowy przechodzi w jego wektor wyjściowy.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "Myślenie o wszystkich wektorach na raz, każdy jako strzałka, robi się naprawdę zatłoczone.",
  "model": "google_nmt",
  "from_community_srt": "Robi się tu pewien \"tłok\" , przy myśleniu o wszystkich tych wektorach na raz,",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "Jak wspomniałem w poprzednim filmie, dobrą sztuczką jest konceptualizacja każdego wektora nie jako strzałki, ale jako pojedynczego punktu, czyli punktu, w którym znajduje się jego wierzchołek.",
  "model": "google_nmt",
  "from_community_srt": "każdym jako strzałka Więc, tak jak wspominałem w poprzednim filmie, niezłą sztuczką jest wyobrażenie sobie każdego wektora nie jako strzałkę, lecz jako pojedynczy punkt: punkt na który wskazuje koniec strzałki.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "W ten sposób, myśląc o transformacji polegającej na przekształceniu każdego możliwego wektora wejściowego w jakiś wektor wyjściowy, obserwujemy, jak każdy punkt w przestrzeni przemieszcza się do innego punktu.",
  "model": "google_nmt",
  "from_community_srt": "Myśląc w ten sposób o transformacji każdego możliwego wektora wejściowego w wektor wyjściowy, patrzymy jak każdy punkt w przestrzeni przemieszcza się w inne miejsce.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "W przypadku transformacji w dwóch wymiarach, aby lepiej poznać cały kształt transformacji, lubię to robić ze wszystkimi punktami na nieskończonej siatce.",
  "model": "google_nmt",
  "from_community_srt": "W przypadku transformacji w dwu wymiarach, by uzyskać lepsze czucie całego \"kształtu\" transformacji, lubię to robić z wszystkimi punktami nieskończonej siatki.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "Czasami lubię też trzymać kopię siatki w tle, aby pomóc w śledzeniu, gdzie wszystko się kończy w stosunku do miejsca, w którym się zaczyna.",
  "model": "google_nmt",
  "from_community_srt": "Lubię też czasami zachować oryginalną kopie siatki w tle, tylko aby móc śledzić gdzie wszystko ląduje w relacji do początku.",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "Efekt rozmaitych transformacji poruszających się po wszystkich punktach przestrzeni jest, trzeba przyznać, piękny.",
  "model": "google_nmt",
  "from_community_srt": "Efekt różnych transformacji, przesuwanie wszystkich punktów przestrzeni, jest, musisz przyznać piękne.",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "Daje poczucie ściskania i przekształcania samej przestrzeni.",
  "model": "google_nmt",
  "from_community_srt": "Oddaje uczucie rozciągania i zginania przestrzeni.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "Jak jednak możesz sobie wyobrazić, dowolne przekształcenia mogą wyglądać dość skomplikowanie.",
  "model": "google_nmt",
  "from_community_srt": "Jak możesz sobie wyobrazić, dowolne transformacje mogą wyglądać skomplikowanie.",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "Ale na szczęście algebra liniowa ogranicza się do specjalnego rodzaju transformacji, łatwiejszego do zrozumienia, zwanego transformacjami liniowymi.",
  "model": "google_nmt",
  "from_community_srt": "szczęśliwie jednak algebra liniowa ogranicza się do konkretnego typu transformacji. są one łatwiejsze do zrozumienia, nazywamy je \"liniowymi\" transformacjami.",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "Wizualnie transformacja jest liniowa, jeśli ma dwie właściwości.",
  "model": "google_nmt",
  "from_community_srt": "Mówiąc obrazowo, transformacja jest liniowa jeśli spełnia dwa warunki: wszystkie linie muszą pozostać liniami,",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "Wszystkie linie muszą pozostać liniami bez zakrzywiania się, a początek musi pozostać nieruchomy.",
  "model": "google_nmt",
  "from_community_srt": "nie zakrzywiając się, i początek układu musi pozostać na swoim miejscu.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "Na przykład to tutaj nie byłoby transformacją liniową, ponieważ linie stają się kręte.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, ta tutaj to nie jest transformacja liniowa ponieważ linie zakrzywiają się.",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "A ta tutaj, chociaż utrzymuje proste linie, nie jest transformacją liniową, ponieważ przesuwa początek układu współrzędnych.",
  "model": "google_nmt",
  "from_community_srt": "A ta tutaj, jakkolwiek zachowuje proste linie, nie jest transformacją liniową ponieważ przesuwa środek.",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "Ten tutaj ustala początek i może wyglądać, jakby utrzymywał linie proste, ale dzieje się tak tylko dlatego, że pokazuję tylko poziome i pionowe linie siatki.",
  "model": "google_nmt",
  "from_community_srt": "Ta z kolei utrzymuje środek i może wydawać się że również linie pozostają proste, ale to tylko dlatego iż pokazuje tylko linie poziome i pionowe,",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "Kiedy zobaczysz, co to robi z linią ukośną, staje się jasne, że wcale nie jest to linia liniowa, ponieważ sprawia, że ta linia jest całkowicie zakrzywiona.",
  "model": "google_nmt",
  "from_community_srt": "natomiast gdy zobaczysz co się dzieje z linią pochyłą, staje się jasne że nie jest liniowa ponieważ linia ta staje się pokręcona.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "Ogólnie rzecz biorąc, należy myśleć o przekształceniach liniowych jako o równoległych i równomiernie rozmieszczonych liniach siatki.",
  "model": "google_nmt",
  "from_community_srt": "Zasadniczo, możesz myśleć o transformacji liniowej jako o zachowującej linie siatki równolegle i w stałych odległościach.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "Niektóre przekształcenia liniowe są łatwe do przemyślenia, jak na przykład obroty wokół początku.",
  "model": "google_nmt",
  "from_community_srt": "Pewne transformacje liniowe są proste do wyobrażenia, jak obrót dookoła środka.",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "Inne są nieco trudniejsze do opisania słowami.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "Jak myślisz, jak można opisać liczbowo te transformacje?",
  "model": "google_nmt",
  "from_community_srt": "Inne są nieco trudniejsze do opisania słowami Jak możemy zatem opisać te transformacje liczbowo?",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "Jeśli, powiedzmy, programujesz animacje, aby stworzyć film instruujący na ten temat, jaką formułę podajesz komputerowi, aby po podaniu współrzędnych wektora mógł podać współrzędne miejsca, w którym ten wektor ląduje?",
  "model": "google_nmt",
  "from_community_srt": "Gdybyś, na przykład, programował animacje do nauki tej tematyki, jakiego użyłbyś wzoru by wytłumaczyć komputerowi jak przetłumaczyć koordynaty wejściowe wektora",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "Okazuje się, że wystarczy zapisać, gdzie dwa wektory bazowe, i-hat i j-hat, każdy z nich wyląduje i wszystko inne z tego wyniknie.",
  "model": "google_nmt",
  "from_community_srt": "na koordynaty miejsca gdzie wektor przejdzie po transformacji? Okazuje się że musisz tylko zapisać gdzie każdy z wektorów bazowych, i-z-daszkiem i j-z-daszkiem lądują. A wszystko inne będzie wynikać z tego.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "Rozważmy na przykład wektor v o współrzędnych ujemnych 1, 2, co oznacza, że jest on równy minus 1 razy i-hat plus 2 razy j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, weźmy wektor v o koordynatach (-1,2) tzn. jest on równy -1 razy i-z-daszkiem + 2 razy j-z-daszkiem.",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "Jeśli zastosujemy jakąś transformację i podążymy tam, gdzie idą wszystkie trzy wektory, właściwość polegająca na tym, że linie siatki pozostają równoległe i równomiernie rozmieszczone, ma naprawdę ważne konsekwencje.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli odtworzymy transformacje i będziemy patrzeć gdzie te 3 wektory przechodzą, właściwość iż linie siatki zostają równoległe i równo rozłożone daje jedną ważną cechę:",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "Miejsce, w którym wyląduje v, będzie ujemne 1 razy wektor, w którym wylądował i-hat plus 2 razy wektor, w którym wylądował j-hat.",
  "model": "google_nmt",
  "from_community_srt": "miejsce gdzie wyląduje v będzie -1 razy wektor gdzie j-z-daszkiem wylądował + 2 razy miejsce gdzie j-z-daszkiem wyładował.",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "Innymi słowy, zaczęło się jako pewna liniowa kombinacja i-hat i j-hat, a skończyło jako ta sama liniowa kombinacja miejsca, w którym wylądowały te dwa wektory.",
  "model": "google_nmt",
  "from_community_srt": "Innymi słowy, zaczęliśmy jako konkretna kombinacja liniowa i-z-daszkiem i j-z-daszkeim, i kończymy w tej samej kombinacji liniowej tych wektorów po przekształceniu.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "Oznacza to, że możesz wydedukować, gdzie v musi się udać, tylko na podstawie tego, gdzie wylądują i-hat i j-hat.",
  "model": "google_nmt",
  "from_community_srt": "To znaczy że możemy wymyślić gdzie v się znajdzie wiedząc tylko gdzie i-z-daszkiem i j-z-daszkiem wylądowały.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "Dlatego lubię trzymać kopię oryginalnej siatki w tle.",
  "model": "google_nmt",
  "from_community_srt": "Dlatego właśnie lubię mieć kopię oryginalnej siatki w tle.",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "W przypadku pokazanej tutaj transformacji możemy odczytać, że i-hat ląduje na współrzędnych 1, minus 2, a j-hat ląduje na osi x wokół współrzędnych 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "Dla transformacji pokazanej tutaj możemy przeczytać że i-z-daszkiem ląduje na koordynatach (1, -2), a j-z-daszkiem ląduje na osi X na współrzędnych (3,0).",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "Oznacza to, że wektor reprezentowany przez minus 1 i-hat plus 2 razy j-hat kończy się na minus 1 razy wektor 1, minus 2 plus 2 razy wektor 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "Oznacza to że wektor reprezentowany przez: (-1)* i^ + 2*j^ kończy jako (-1) razy wektor (1,-2) +2 razy wektor (3,",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "Dodając to wszystko, możesz wywnioskować, że musi wylądować na wektorze 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "0). Składając to razem, możemy zgadnąć że musi wylądować na wektorze (5,2).",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "To dobry moment, aby zatrzymać się i zastanowić, ponieważ jest to dość ważne.",
  "model": "google_nmt",
  "from_community_srt": "To dobry moment by się zatrzymać i zastanowić, gdyż jest to niezwykle ważne.",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "Biorąc pod uwagę, że faktycznie pokazuję ci pełną transformację, mogłeś po prostu sprawdzić, czy v ma współrzędne 5, 2.",
  "model": "google_nmt",
  "from_community_srt": "Zatem, biorąc pod uwagę że właściwe pokazuję Ci teraz pełną transformację, możesz stwierdzić iż v ma współrzędne (5,2),",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "Ale fajne jest to, że daje nam to technikę dedukowania, gdzie lądują dowolne wektory, o ile mamy zapis, gdzie lądują i-hat i j-hat, bez konieczności obserwowania samej transformacji.",
  "model": "google_nmt",
  "from_community_srt": "ale wspaniałą właściwością w tym momencie jest to iż daje nam to technikę odgadnięcia gdzie wyląduje każdy wektor, tak długo jak mamy wiedzę gdzie i-z-daszkem i j-z-daszkiem lądują, bez konieczności patrzenia na samą transformację.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "Zapisz wektor o bardziej ogólnych współrzędnych, x i y, a wyląduje on x razy wektor, w którym ląduje i-hat, 1, minus 2, plus y razy wektor, w którym ląduje j-hat, 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "Napiszmy wektor z ogólnymi współrzędnymi x i y, i wylądują on x razy wektor w którym wylądował i-z-daszkiem: (1,-2), dodać y razy wektor gdzie j-z-daszkiem wylądował (3,0).",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "Przeprowadzając tę sumę, widzisz, że wychodzi 1x plus 3y, minus 2x plus 0y.",
  "model": "google_nmt",
  "from_community_srt": "Dodając, widać że wylądował w (1x+3y, -2x+0u).",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "Dam ci dowolny wektor, a ty możesz mi powiedzieć, gdzie ten wektor ląduje, korzystając ze wzoru.",
  "model": "google_nmt",
  "from_community_srt": "Mogę Ci podać każdy wektor, a Ty odgadniesz gdzie wektor wyląduje używając tego wzoru.",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "Wszystko to mówi, że dwuwymiarowa transformacja liniowa jest całkowicie opisana przez zaledwie cztery liczby, dwie współrzędne miejsca wylądowania i-hat i dwie współrzędne miejsca wylądowania j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Podsumowywując, dwu-wymiarowa transformacja liniowa może być całkowicie opisana z użyciem tylko 4 liczb: dwóch współrzędnych miejsca gdzie i-z-daszkiem wyląduje,",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Czy to nie fajne?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "Często pakuje się te współrzędne w siatkę liczb 2x2 zwaną macierzą 2x2, gdzie można zinterpretować kolumny jako dwa specjalne wektory, w których lądują i-hat i j-hat.",
  "model": "google_nmt",
  "from_community_srt": "i dwóch współrzędnych miejsca gdzie j-z-daszkiem wyląduje Czy to nie wspaniałe? Zwykle układamy te współrzędne w tabliczkę 2 na 2, nazywaną macierzą 2-na-2, gdzie można rozumieć kolumny jako dwa specjalne wektory w których wylądują i-z-daszkiem i j-z-daszkiem.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "Jeśli masz macierz 2x2 opisującą przekształcenie liniowe i jakiś konkretny wektor i chcesz wiedzieć, dokąd prowadzi to przekształcenie liniowe, możesz wziąć współrzędne wektora, pomnożyć je przez odpowiednie kolumny macierzy, a następnie dodaj razem to, co otrzymasz.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli dostaniesz macierz 2-na-2 opisującą transformację liniową i pewien konkretny wektor i będziesz chciał wiedzieć gdzie transformacja liniowa zabierze ten wektor, możesz wziąć współrzędne wektora, pomnożyć je przez odpowiednie kolumny macierzy, a na koniec dodać do siebie rezultat.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "Odpowiada to idei dodania skalowanych wersji naszych nowych wektorów bazowych.",
  "model": "google_nmt",
  "from_community_srt": "Odpowiada to idei dodawania przeskalowanych wersji naszych wektorów bazowych.",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "Zobaczmy, jak to wygląda w najbardziej ogólnym przypadku, gdy twoja macierz ma wpisy A, B, C, D.",
  "model": "google_nmt",
  "from_community_srt": "Spójrzmy jak to wygląda w najbardziej ogólnym przypadku gdy nasza macierz ma wpisy a,b,c,d i pamiętaj,",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "I pamiętajcie, że ta macierz to tylko sposób pakowania informacji potrzebnych do opisania transformacji liniowej.",
  "model": "google_nmt",
  "from_community_srt": "ta macierz to tylko sposób ułożenia informacji potrzebnej do opisania transformacji liniowej.",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "Zawsze pamiętaj, aby zinterpretować pierwszą kolumnę AC jako miejsce, w którym ląduje pierwszy wektor bazowy, a drugą kolumnę BD jako miejsce, w którym ląduje drugi wektor bazowy.",
  "model": "google_nmt",
  "from_community_srt": "Zawsze pamiętaj by wyobrażać sobie pierwszej kolumny, (a,c), jako miejsca gdzie ląduje pierwszy wektor bazowy, i drugiej kolumny, (b,d) jako miejsca gdzie ląduje drugi wektor bazowy.",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "Kiedy zastosujemy tę transformację do jakiegoś wektora xy, co otrzymamy?",
  "model": "google_nmt",
  "from_community_srt": "Kiedy zastosujemy tę transformatę dla pewnego wektora (x,y),",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "Cóż, to będzie x razy AC plus y razy BD.",
  "model": "google_nmt",
  "from_community_srt": "co otrzymamy? Cóż, będzie to x razy (a,c) plus y razy (b,d).",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "Łącząc to, otrzymasz wektor Ax plus By, Cx plus Dy.",
  "model": "google_nmt",
  "from_community_srt": "Łącząc to razem, dostajesz wektor (ax+by,",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "Można to nawet zdefiniować jako mnożenie wektorów macierzy, gdy umieścisz macierz po lewej stronie wektora, jakby była to funkcja.",
  "model": "google_nmt",
  "from_community_srt": "cd+dy) Możemy to zdefiniować jako mnożenie macierzy przez wektor, takie że dajemy macierz na lewo od wektora tak jakby to była funkcja.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "Następnie możesz zmusić uczniów szkół średnich do zapamiętania tego, nie pokazując im kluczowej części, która sprawia, że wydaje się to intuicyjne.",
  "model": "google_nmt",
  "from_community_srt": "W ten sposób możemy sprawić by studenci zapamiętali to, bez pokazywania zasadniczej części która sprawia że staje się to intuicyjne.",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "Ale czy nie jest zabawniej myśleć o tych kolumnach jako o przekształconych wersjach wektorów bazowych i myśleć o wyniku jako odpowiedniej liniowej kombinacji tych wektorów?",
  "model": "google_nmt",
  "from_community_srt": "Ale, czy nie jest zabawniej myśleć o tych kolumnach jako o przetransformowanych wersjach wektorów bazowych i myśleć o wyniku jako właściwej kombinacji liniowej tych wektorów?",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "Poćwiczmy opisywanie kilku przekształceń liniowych za pomocą macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Poćwiczmy opisując kilka transformacji liniowych z macierzami.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "Na przykład, jeśli obrócimy całą przestrzeń o 90 stopni w kierunku przeciwnym do ruchu wskazówek zegara, wówczas i-hat wyląduje na współrzędnych 0, 1.",
  "model": "google_nmt",
  "from_community_srt": "Dla przykładu, jeśli obrócimy przestrzeń o 90° w kierunku przeciwnym do ruchu wskazówek zegara,",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "I j-hat ląduje na współrzędnych ujemnych 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "wtedy i-z-daszkeim ląduje we współrzędnych (0,1), a j-z-daszkiem ląduje na współrzędnych (-1,0).",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "Zatem macierz, którą otrzymamy, ma kolumny 0, 1, minus 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "Zatem wynikowa macierz ma kolumny: (0,1),",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "Aby dowiedzieć się, co dzieje się z dowolnym wektorem po obrocie o 90 stopni, można po prostu pomnożyć jego współrzędne przez tę macierz.",
  "model": "google_nmt",
  "from_community_srt": "(-1,0). By obliczyć co się stanie z dowolnym wektorem po obrocie o 90°, możemy po prostu pomnożyć jego współrzędne przez tą macierz.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "Oto zabawna transformacja o specjalnej nazwie, zwanej ścinaniem.",
  "model": "google_nmt",
  "from_community_srt": "Ta z kolei zabawna transformacja ma specjalną nazwę:",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "W nim i-hat pozostaje stały, więc pierwsza kolumna macierzy to 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "\"shear\" (ścinanie) W niej i-z-daszkiem pozostaje na swoim miejscu, stąd pierwsza kolumna macierzy to (1,0),",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "Ale j-hat przechodzi do współrzędnych 1, 1, które stają się drugą kolumną macierzy.",
  "model": "google_nmt",
  "from_community_srt": "ale j-z-daszkiem przesuwa się na współrzędne (1,1), i staje się drugą kolumną macierzy.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "I choć może to być tutaj zbędne, ustalenie, jak ścinanie przekształca dany wektor, sprowadza się do pomnożenia tej macierzy przez ten wektor.",
  "model": "google_nmt",
  "from_community_srt": "I na ryzyko bycia niepotrzebnym tutaj, odgadnięcie jak \"shear\" (ścinanie) transformuje dany wektor sprowadza się do pomnożenia macierzy przez ten wektor.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "Powiedzmy, że chcemy pójść w drugą stronę, zaczynając od macierzy, powiedzmy od kolumn 1, 2 i 3, 1, i chcemy wydedukować, jak wygląda jej przekształcenie.",
  "model": "google_nmt",
  "from_community_srt": "Idąc od tyłu, moglibyśmy zacząć od macierzy, dla przykładu, z kolumnami (1,2) i (3,1), i chcieć odgadnąć jak ta transformacja wygląda.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "Zatrzymaj się i poświęć chwilę, aby sprawdzić, czy możesz to sobie wyobrazić.",
  "model": "google_nmt",
  "from_community_srt": "Zatrzymaj się i poświęć chwilę, aby sprawdzić, czy możesz to sobie wyobrazić.",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "Jednym ze sposobów, aby to zrobić, jest najpierw przesunięcie i-hat na 1, 2, a następnie przesunięcie j-hat na 3, 1.",
  "model": "google_nmt",
  "from_community_srt": "Jednym ze sposobów na zrobienie tego jest przesunięcie i-z-daszkiem na (1,2), a następnie przesunięcie j-z-daszkiem na (3,1).",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "Zawsze przesuwaj resztę przestrzeni w taki sposób, aby linie siatki były równoległe i równomiernie rozmieszczone.",
  "model": "google_nmt",
  "from_community_srt": "Zawsze przemieszczając resztę przestrzeni w sposób zachowujący linie siatki równolegle i równomiernie rozłożone.",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "Jeśli wektory, na których lądują i-hat i j-hat, są liniowo zależne, co, jeśli pamiętasz z poprzedniego filmu, oznacza, że jeden jest przeskalowaną wersją drugiego, oznacza to, że transformacja liniowa zgniata całą przestrzeń 2D na linia, na której znajdują się te dwa wektory, znana również jako jednowymiarowa rozpiętość tych dwóch liniowo zależnych wektorów.",
  "model": "google_nmt",
  "from_community_srt": "Jeśli wektory na których i-z-daszkiem oraz j-z-daszkiem wylądowały są liniowo zależne, co oznacza (jeśli pamiętasz z poprzedniego filmu), że są one przeskalowanymi wersjami siebie nawzajem, Oznacza to, że transformacja liniowa powoduje przycięcie całej przestrzeni 2D w linię na której mieszczą się te dwa wektory. Zwaną też jako 1-wymiarowa podprzestrzeń tych dwóch liniowo zależnych wektorów.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "Podsumowując, przekształcenia liniowe to sposób poruszania się po przestrzeni w taki sposób, że linie siatki pozostają równoległe i równomiernie rozmieszczone, a początek pozostaje stały.",
  "model": "google_nmt",
  "from_community_srt": "Podsumowując, transformacje liniowe są sposobem takiego przemieszczenia przestrzeni że linie siatki pozostają równoległe i równomiernie rozmieszczone a do tego środek się nie przemieszcza.",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "Co zaskakujące, transformacje te można opisać za pomocą zaledwie kilku liczb, czyli współrzędnych miejsca, w którym ląduje każdy wektor bazowy.",
  "model": "google_nmt",
  "from_community_srt": "Urocze w tym jest iż te transformacje mogą być opisane tylko garstką liczb: współrzędnymi miejsca gdzie każdy z wektorów bazowych ląduje.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "Macierze dają nam język do opisu tych transformacji, w którym kolumny reprezentują te współrzędne, a mnożenie wektorów macierzy to tylko sposób obliczenia, co ta transformacja robi z danym wektorem.",
  "model": "google_nmt",
  "from_community_srt": "Macierze dają nam język opisu tych transformacji, gdzie kolumny opisują te współrzędne a mnożenie macierzy przez wektor jest jedynie sposobem obliczenia co robi ta transformacja mając podany konkretny wektor.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "Ważnym wnioskiem jest to, że za każdym razem, gdy widzisz matrycę, możesz zinterpretować ją jako pewną transformację przestrzeni.",
  "model": "google_nmt",
  "from_community_srt": "Ważnym wnioskiem na przyszłość tutaj jest to, że za każdym razem gdy widzisz macierz, możesz ją rozumieć jako konkretne przekształcenie przestrzeni.",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "Kiedy już naprawdę przetrawisz tę ideę, będziesz w doskonałej sytuacji, aby głęboko zrozumieć algebrę liniową.",
  "model": "google_nmt",
  "from_community_srt": "Jak już przetrawisz ten pomysł na spokojnie, będziesz mógł dogłębnie zrozumieć algebrę liniową.",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "Prawie wszystkie pojawiające się tematy, od mnożenia macierzy po wyznaczniki, zmianę podstawy, wartości własne, wszystkie staną się łatwiejsze do zrozumienia, gdy zaczniesz myśleć o macierzach jako o przekształceniach przestrzeni.",
  "model": "google_nmt",
  "from_community_srt": "Praktycznie wszystkie nadchodzące tematy, od mnożenia macierzy przez wyznaczniki, zmianę bazy, wartości własne, wszystkie z nich staną się łatwiejsze do zrozumienia jak tylko będziesz myśleć o macierzach jako o przekształceniach przestrzeni.",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "W następnym filmie od razu opowiem o mnożeniu dwóch macierzy przez siebie.",
  "model": "google_nmt",
  "from_community_srt": "W następnym filmie będę mówić o mnożeniu dwóch macierzy przez siebie.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]