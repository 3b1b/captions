[
 {
  "input": "Hey everyone!",
  "translatedText": "हे सर्वजण!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "जर मला फक्त एकच विषय निवडायचा असेल ज्यामुळे रेखीय बीजगणितातील इतर सर्व क्लिक करणे सुरू होईल आणि जे विद्यार्थी पहिल्यांदा रेखीय बीजगणित घेते तेव्हा ते बरेचदा शिकले नाही तर ते हेच असेल.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "रेखीय परिवर्तनाची कल्पना आणि मॅट्रिक्सशी त्याचा संबंध.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "या व्हिडिओसाठी, मी फक्त दोन आयामांच्या बाबतीत ही परिवर्तने कशी दिसतात आणि ते मॅट्रिक्स वेक्टर गुणाकाराच्या कल्पनेशी कसे संबंधित आहेत यावर लक्ष केंद्रित करणार आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "विशेषतः, मी तुम्हाला मॅट्रिक्स वेक्टर गुणाकार बद्दल विचार करण्याचा एक मार्ग दाखवू इच्छितो जे लक्षात ठेवण्यावर अवलंबून नाही.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "सुरू करण्यासाठी, या शब्दाचे विश्लेषण करूया, रेखीय परिवर्तन.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "परिवर्तन हा मूलत: कार्यासाठी एक फॅन्सी शब्द आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "हे असे काहीतरी आहे जे इनपुट घेते आणि प्रत्येकासाठी एक आउटपुट थुंकते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "विशेषत:, रेखीय बीजगणिताच्या संदर्भात, आम्हाला अशा परिवर्तनांबद्दल विचार करायला आवडतो जे काही वेक्टर घेतात आणि दुसर्या वेक्टरला थुंकतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "तर फंक्शन ऐवजी ट्रान्सफॉर्मेशन हा शब्द का वापरायचा जर त्यांचा अर्थ समान असेल तर?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "बरं, या इनपुट-आउटपुट संबंधाची कल्पना करण्याचा एक विशिष्ट मार्ग सुचवावा लागेल.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "तुम्ही पहा, व्हेक्टरची कार्ये समजून घेण्याचा एक उत्तम मार्ग म्हणजे हालचाल वापरणे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "जर परिवर्तन काही इनपुट व्हेक्टरला काही आउटपुट वेक्टरमध्ये घेते, तर आम्ही कल्पना करतो की इनपुट वेक्टर आउटपुट वेक्टरवर जातो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "मग संपूर्ण रूपांतर समजून घेण्यासाठी, आपण प्रत्येक संभाव्य इनपुट वेक्टरला त्याच्या संबंधित आउटपुट वेक्टरकडे जाताना पाहण्याची कल्पना करू शकतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "एकाच वेळी सर्व सदिशांचा विचार करण्यासाठी खरोखर गर्दी होते, प्रत्येक एक बाण म्हणून.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits.",
  "translatedText": "म्हणून, मी शेवटचा व्हिडिओ सांगितल्याप्रमाणे, एक छान युक्ती म्हणजे प्रत्येक वेक्टरला बाण म्हणून नव्हे तर एकल बिंदू म्हणून संकल्पना करणे, त्याचे टोक जिथे बसते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "अशा प्रकारे, प्रत्येक संभाव्य इनपुट व्हेक्टरला काही आउटपुट वेक्टरमध्ये घेऊन जाणाऱ्या परिवर्तनाचा विचार करण्यासाठी, आपण अंतराळातील प्रत्येक बिंदू दुसऱ्या बिंदूकडे जाताना पाहतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "दोन मितींमधील परिवर्तनांच्या बाबतीत, परिवर्तनाच्या संपूर्ण आकाराचा अधिक चांगला अनुभव घेण्यासाठी, मला हे सर्व बिंदूंसह अनंत ग्रिडवर करायला आवडते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "मला कधीकधी ग्रिडची एक प्रत बॅकग्राउंडमध्ये ठेवायला आवडते फक्त ते कुठे सुरू होते याच्या सापेक्ष सर्वकाही कुठे संपते याचा मागोवा ठेवण्यासाठी.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "अंतराळातील सर्व बिंदूंभोवती फिरत असलेल्या विविध परिवर्तनांचा परिणाम म्हणजे, तुम्ही मान्य केलेच पाहिजे, सुंदर.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "हे स्क्विशिंग आणि मॉर्फिंग स्पेसची भावना देते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "आपण कल्पना करू शकता की, अनियंत्रित परिवर्तने खूपच क्लिष्ट दिसू शकतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "पण सुदैवाने, रेखीय बीजगणित स्वतःला एका विशिष्ट प्रकारच्या परिवर्तनापुरते मर्यादित करते, जे समजण्यास सोपे असते, ज्याला रेखीय परिवर्तन म्हणतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "दृष्यदृष्ट्या बोलायचे झाल्यास, परिवर्तन हे रेखीय असते जर त्यात दोन गुणधर्म असतील.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "सर्व रेषा वक्र न होता रेषा राहिल्या पाहिजेत आणि मूळ जागेवर स्थिर राहिले पाहिजे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "उदाहरणार्थ, येथे हे रेखीय परिवर्तन होणार नाही, कारण रेषा सर्व वक्र आहेत.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "आणि हे इथेच, जरी ते रेषा सरळ ठेवत असले तरी ते रेषीय परिवर्तन नाही, कारण ते मूळ हलवते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "हे येथे मूळ निश्चित करते, आणि ते सरळ रेषा ठेवते असे दिसते, परंतु मी फक्त क्षैतिज आणि उभ्या ग्रिड रेषा दर्शवित आहे म्हणून.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "ती कर्णरेषेशी काय करते हे पाहिल्यावर, ती अजिबात रेषीय नाही हे स्पष्ट होते, कारण ती रेषा सर्व वक्र बनते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "सर्वसाधारणपणे, तुम्ही ग्रीड रेषा समांतर आणि समान अंतरावर ठेवून रेखीय परिवर्तनाचा विचार केला पाहिजे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "काही रेखीय परिवर्तने विचार करणे सोपे असते, जसे की उत्पत्तीबद्दलची रोटेशन.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "इतर शब्दांनी वर्णन करणे थोडे अवघड आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So how do you think you could describe these transformations numerically?",
  "translatedText": "तर तुम्हाला असे वाटते की तुम्ही या परिवर्तनांचे संख्यात्मक वर्णन कसे करू शकता?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "जर तुम्ही विषय शिकवणारा व्हिडिओ बनवण्यासाठी काही अॅनिमेशन प्रोग्रामिंग करत असाल, तर तुम्ही कॉम्प्युटरला कोणते फॉर्म्युला द्याल जेणेकरून तुम्ही त्याला वेक्टरचे कोऑर्डिनेट्स दिले तर ते तुम्हाला ते व्हेक्टर कुठे उतरेल याचे निर्देशांक देऊ शकेल?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "असे दिसून आले की तुम्हाला फक्त दोन आधारभूत व्हेक्टर, i-hat आणि j-hat, प्रत्येक जमीन आणि इतर सर्व गोष्टी त्यापासून कुठे असतील ते रेकॉर्ड करणे आवश्यक आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "उदाहरणार्थ, ऋण 1, 2 सह समन्वयक v चा विचार करा, याचा अर्थ ते ऋण 1 पट i-hat अधिक 2 पट j-hat च्या बरोबरीचे आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "जर आपण काही परिवर्तन घडवून आणले आणि हे तिन्ही वेक्टर कुठे जातात त्याचे अनुसरण केल्यास, ग्रिड रेषा समांतर आणि समान अंतरावर राहणाऱ्या गुणधर्माचा खरोखरच महत्त्वाचा परिणाम होतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "ज्या ठिकाणी v उतरेल ते वेक्टरच्या 1 पट ऋण असेल जेथे i-hat उतरले अधिक वेक्टर जेथे j-hat उतरले त्याच्या 2 पट.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "दुस-या शब्दात, आय-हॅट आणि j-हॅटच्या एका विशिष्ट रेषीय संयोगाने त्याची सुरुवात झाली आणि ते दोन व्हेक्टर जिथे उतरले त्याच रेखीय संयोगाने ते संपते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "याचा अर्थ तुम्ही v ने कुठे जायचे आहे ते फक्त i-hat आणि j-hat प्रत्येक जमिनीवर आधारित आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "यामुळे मला मूळ ग्रिडची प्रत पार्श्वभूमीत ठेवणे आवडते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "येथे दर्शविलेल्या परिवर्तनासाठी, आपण हे वाचू शकतो की आय-हॅट निर्देशांक 1, ऋण 2, आणि j-हॅट 3, 0 वर x-अक्षावर उतरते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "याचा अर्थ असा की ऋण 1 i-hat अधिक 2 पट j-hat ने दर्शविलेला सदिश ऋण 1 पट वेक्टर 1, ऋण 2 अधिक 2 पट वेक्टर 3, 0 वर संपतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "हे सर्व एकत्र जोडल्यास, आपण हे काढू शकता की ते वेक्टर 5, 2 वर उतरले पाहिजे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "विराम आणि विचार करण्यासाठी हा एक चांगला मुद्दा आहे, कारण ते खूप महत्वाचे आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "आता, मी तुम्हाला पूर्ण रूपांतर दाखवत आहे हे लक्षात घेऊन, v मध्ये 5, 2 निर्देशांक आहेत हे तुम्ही पाहू शकता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself.",
  "translatedText": "पण इथला छान भाग असा आहे की हे आपल्याला परिवर्तन पाहण्याची गरज न पडता प्रत्येक जमिनीवर आय-हॅट आणि जे-हॅट कोठे आहे याची नोंद आहे तोपर्यंत कोणतेही वेक्टर कुठे उतरतात हे काढण्याचे तंत्र देते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "अधिक सामान्य निर्देशांकांसह वेक्टर लिहा, x आणि y, आणि ते व्हेक्टरच्या x पटावर उतरेल जेथे i-hat उतरेल, 1, ऋण 2, अधिक y वेक्टर जेथे j-hat उतरेल, 3, 0.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "ती बेरीज पूर्ण केल्यावर, तुम्ही पहाल की ती 1x अधिक 3y, ऋण 2x अधिक 0y वर येते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "मी तुम्हाला कोणताही सदिश देतो, आणि तुम्ही मला सांगू शकता की हा फॉर्म्युला वापरून तो वेक्टर कुठे उतरतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands.",
  "translatedText": "हे सर्व काय सांगत आहे ते असे आहे की द्विमितीय रेषीय परिवर्तनाचे वर्णन फक्त चार संख्यांनी केले आहे, दोन समन्वय जेथे i-hat उतरतात आणि दोन समन्वय जेथे j-hat उतरतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "मस्त आहे ना?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "या निर्देशांकांना 2x2 मॅट्रिक्स म्हटल्या जाणार्‍या संख्यांच्या 2x2 ग्रिडमध्ये पॅकेज करणे सामान्य आहे, जेथे तुम्ही स्तंभांचा अर्थ दोन विशेष वेक्टर म्हणून लावू शकता जेथे प्रत्येक जमीन i-hat आणि j-hat आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "तुम्हाला रेखीय परिवर्तन आणि काही विशिष्ट वेक्टरचे वर्णन करणारे 2x2 मॅट्रिक्स दिले असल्यास, आणि तुम्हाला हे जाणून घ्यायचे असेल की ते रेखीय परिवर्तन ते व्हेक्टर कुठे घेते, तुम्ही वेक्टरचे निर्देशांक घेऊ शकता, त्यांना मॅट्रिक्सच्या संबंधित स्तंभांनी गुणाकार करू शकता. तुम्हाला जे मिळेल ते जोडा.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "हे आमच्या नवीन आधारभूत व्हेक्टरच्या स्केल केलेल्या आवृत्त्या जोडण्याच्या कल्पनेशी सुसंगत आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "आपल्या मॅट्रिक्समध्ये A, B, C, D अशा नोंदी असलेल्या सर्वात सामान्य प्रकरणात हे कसे दिसते ते पाहू या.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "आणि लक्षात ठेवा, हे मॅट्रिक्स रेखीय परिवर्तनाचे वर्णन करण्यासाठी आवश्यक असलेली माहिती पॅकेजिंग करण्याचा एक मार्ग आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "नेहमी लक्षात ठेवा की पहिल्या स्तंभाचा, AC चा, ज्या ठिकाणी पहिला आधार वेक्टर उतरतो, आणि तो दुसरा स्तंभ, BD, जेथे दुसरा आधार वेक्टर उतरतो ते स्थान.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get?",
  "translatedText": "जेव्हा आम्ही हे परिवर्तन काही वेक्टर x, y वर लागू करतो, तेव्हा तुम्हाला काय मिळेल?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "बरं, ते एक्स पट एसी अधिक y पट बीडी असेल.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "हे एकत्र ठेवल्यास, तुम्हाला एक वेक्टर Ax Plus By, Cx अधिक Dy मिळेल.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "जेव्हा तुम्ही मॅट्रिक्सला वेक्टरच्या डावीकडे फंक्शनप्रमाणे ठेवता तेव्हा तुम्ही हे मॅट्रिक्स-वेक्टर गुणाकार म्हणून देखील परिभाषित करू शकता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "मग तुम्ही हायस्कूलच्या विद्यार्थ्यांना हे लक्षात ठेवण्यास भाग पाडू शकता जो त्यांना अंतर्ज्ञानी वाटेल असा महत्त्वपूर्ण भाग न दाखवता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "परंतु या स्तंभांचा तुमच्या आधारभूत व्हेक्टरच्या रूपांतरित आवृत्त्या म्हणून विचार करणे आणि त्या सदिशांचे योग्य रेखीय संयोजन म्हणून परिणामांचा विचार करणे अधिक मनोरंजक नाही का?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "मॅट्रिक्ससह काही रेखीय परिवर्तनांचे वर्णन करण्याचा सराव करूया.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0.",
  "translatedText": "उदाहरणार्थ, जर आपण सर्व जागा ९० अंश घड्याळाच्या उलट दिशेने फिरवली, तर आय-हॅट ०, १, आणि जे-हॅट निर्देशांक ऋण १, ० वर उतरते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 484.58,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "म्हणून आपण ज्या मॅट्रिक्ससह समाप्त होतो त्यात स्तंभ 0, 1, ऋण 1, 0 आहेत.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "90-डिग्री रोटेशन नंतर कोणत्याही व्हेक्टरचे काय होते हे शोधण्यासाठी, तुम्ही या मॅट्रिक्सद्वारे त्याचे निर्देशांक गुणाकार करू शकता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "येथे एक विशेष नाव असलेले एक मजेदार परिवर्तन आहे, ज्याला कातरणे म्हणतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "त्यात, आय-हॅट स्थिर राहते, त्यामुळे मॅट्रिक्सचा पहिला स्तंभ 1, 0 आहे, परंतु J-हॅट निर्देशांक 1, 1 वर जातो, जो मॅट्रिक्सचा दुसरा स्तंभ बनतो.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 515.0,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "आणि येथे निरर्थक असण्याच्या जोखमीवर, कातरणे दिलेल्या वेक्टरचे रूपांतर कसे करते हे शोधणे या मॅट्रिक्सला त्या वेक्टरने गुणाकारण्यापर्यंत खाली येते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "मानू या की आपल्याला मॅट्रिक्सपासून सुरुवात करून, स्तंभ 1, 2, आणि 3, 1 सह म्हणायचे आहे, आणि त्याचे परिवर्तन कसे दिसते ते काढायचे आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "थांबा आणि तुम्ही त्याची कल्पना करू शकता का ते पहा.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "हे करण्याचा एक मार्ग म्हणजे प्रथम I-hat ला 1, 2 वर हलवा, नंतर J-hat ला 3, 1 वर हलवा, नेहमी उर्वरित जागा अशा प्रकारे हलवा की ज्यामुळे ग्रिडलाइन समांतर आणि समान अंतरावर राहतील.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 548.42,
  "end": 560.22
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "जर आय-हॅट आणि जे-हॅट वर उतरणारे वेक्टर रेखीयरित्या अवलंबून असतील, जे तुम्हाला शेवटच्या व्हिडिओवरून आठवत असेल, तर याचा अर्थ असा आहे की एक दुसऱ्याची स्केल केलेली आवृत्ती आहे, तर याचा अर्थ असा होतो की रेखीय रूपांतर सर्व 2D जागेवर स्क्विश करते. रेषा जिथे ते दोन वेक्टर बसतात, ज्याला त्या दोन रेषीय अवलंबित व्हेक्टरचा एक-आयामी स्पॅन देखील म्हणतात.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "सारांश, रेखीय परिवर्तन हा अवकाशाभोवती फिरण्याचा एक मार्ग आहे जसे की ग्रिडलाइन समांतर आणि समान अंतरावर राहतात आणि मूळ स्थिर राहते.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "फ्लाइटली, या परिवर्तनांचे वर्णन फक्त मोजक्या संख्यांचा वापर करून केले जाऊ शकते, प्रत्येक आधार वेक्टर कुठे उतरतो याचे निर्देशांक.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "मॅट्रिक्स आपल्याला या परिवर्तनांचे वर्णन करण्यासाठी एक भाषा देतात, जिथे स्तंभ त्या निर्देशांकांचे प्रतिनिधित्व करतात आणि मॅट्रिक्स-वेक्टर गुणाकार हा केवळ दिलेल्या वेक्टरमध्ये परिवर्तन काय करते याची गणना करण्याचा एक मार्ग आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "येथे महत्त्वाची गोष्ट अशी आहे की प्रत्येक वेळी तुम्ही मॅट्रिक्स पाहता तेव्हा तुम्ही स्पेसचे विशिष्ट परिवर्तन म्हणून त्याचा अर्थ लावू शकता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "एकदा तुम्ही ही कल्पना खरोखर पचली की, तुम्ही रेखीय बीजगणित सखोलपणे समजून घेण्याच्या चांगल्या स्थितीत असता.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "मॅट्रिक्स गुणाकारापासून ते निर्धारकांपर्यंत, आधारातील बदल, इजिनव्हॅल्यूजपर्यंत येणारे जवळजवळ सर्व विषय, एकदा तुम्ही मॅट्रिक्सचा जागेचे परिवर्तन म्हणून विचार करायला सुरुवात केलीत की हे सर्व समजून घेणे सोपे होईल.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "लगेचच, पुढील व्हिडिओमध्ये, मी दोन मॅट्रिक्स एकत्र गुणाकार करण्याबद्दल बोलणार आहे.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.3,
  "end": 645.66
 },
 {
  "input": "See you then!",
  "translatedText": "मग भेटूया आपण!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 645.66
 },
 {
  "input": "Thank you for watching!",
  "translatedText": "पाहिल्याबद्दल आभारी आहे!",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 646.12,
  "end": 646.32
 }
]