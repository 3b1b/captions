[
 {
  "input": "Hey everyone! ",
  "translatedText": "こんにちは、みなさん！",
  "model": "nmt",
  "time_range": [
   12.040000000000004,
   12.92
  ],
  "n_reviews": 0
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one. ",
  "translatedText": "線形代数の他のすべてのトピックがピンとくるトピックを 1 つだけ選 択しなければならないとしたら、学生が初めて線形代数を学ぶときにあ まりにも頻繁に学習されなくなるトピックは、このトピックでしょう。",
  "model": "nmt",
  "time_range": [
   13.32,
   22.28
  ],
  "n_reviews": 0
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices. ",
  "translatedText": "線形変換の考え方と行列との関係。",
  "model": "nmt",
  "time_range": [
   22.7,
   26.2
  ],
  "n_reviews": 0
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication. ",
  "translatedText": "このビデオでは、これらの変換が 2 次元の場合にどのように見えるか、および それらが行列ベクトルの乗算の概念にどのように関連するかに焦点を当てます。",
  "model": "nmt",
  "time_range": [
   26.95,
   35.06
  ],
  "n_reviews": 0
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization. ",
  "translatedText": "特に、暗記に頼らない行列ベクトルの乗 算の考え方を紹介したいと思います。",
  "model": "nmt",
  "time_range": [
   35.88,
   42.08
  ],
  "n_reviews": 0
 },
 {
  "input": "To start, let's just parse this term, linear transformation. ",
  "translatedText": "まず、線形変換という用語を解析してみましょう。",
  "model": "nmt",
  "time_range": [
   43.16,
   46.58
  ],
  "n_reviews": 0
 },
 {
  "input": "Transformation is essentially a fancy word for function. ",
  "translatedText": "トランスフォーメーションとは、本質的には機能を意味する派手な言葉です。",
  "model": "nmt",
  "time_range": [
   47.42,
   49.88
  ],
  "n_reviews": 0
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one. ",
  "translatedText": "入力を受け取り、それぞれに対して出力を吐き出すものです。",
  "model": "nmt",
  "time_range": [
   50.26,
   53.98
  ],
  "n_reviews": 0
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector. ",
  "translatedText": "具体的には、線形代数のコンテキストでは、あるベクトルを取り込 んで別のベクトルを吐き出す変換について考えるのが好きです。",
  "model": "nmt",
  "time_range": [
   53.98,
   61.08
  ],
  "n_reviews": 0
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing? ",
  "translatedText": "では、同じ意味であるのに、なぜ関数ではなく変換という言葉を使うのでしょうか? ",
  "model": "nmt",
  "time_range": [
   62.5,
   66.38
  ],
  "n_reviews": 0
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation. ",
  "translatedText": "そうですね、この入出力関係を視覚化するための特定の方法を示唆するためです。",
  "model": "nmt",
  "time_range": [
   67.12,
   71.34
  ],
  "n_reviews": 0
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement. ",
  "translatedText": "ベクトルの機能を理解するための優れた方法は、動きを利用することです。",
  "model": "nmt",
  "time_range": [
   71.86,
   75.8
  ],
  "n_reviews": 0
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector. ",
  "translatedText": "変換によって入力ベクトルが出力ベクトルに変換される場合、そ の入力ベクトルが出力ベクトルに移動することを想像します。",
  "model": "nmt",
  "time_range": [
   76.78,
   84.86
  ],
  "n_reviews": 0
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector. ",
  "translatedText": "次に、変換を全体として理解するために、考えられるすべての入力ベクトルが対 応する出力ベクトルに移動するのを観察することを想像するかもしれません。",
  "model": "nmt",
  "time_range": [
   85.68,
   94.08
  ],
  "n_reviews": 0
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow. ",
  "translatedText": "すべてのベクトルを一度に、それぞれを 矢印として考えるのは非常に面倒です。",
  "model": "nmt",
  "time_range": [
   94.98,
   99.12
  ],
  "n_reviews": 0
 },
 {
  "input": "So, as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow but as a single point, the point where its tip sits. ",
  "translatedText": "前回のビデオで述べたように、優れたトリックは、各ベクトルを矢印では なく単一の点、つまりその先端が位置する点として概念化することです。",
  "model": "nmt",
  "time_range": [
   99.5,
   107.42
  ],
  "n_reviews": 0
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point. ",
  "translatedText": "このようにして、考えられるすべての入力ベクトルを何らかの出力ベクトルに変換す ることを考えるために、空間内のすべての点が他の点に移動するのを観察します。",
  "model": "nmt",
  "time_range": [
   108.03,
   116.34
  ],
  "n_reviews": 0
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid. ",
  "translatedText": "2 次元での変換の場合、変換の全体的な形状をよりよく理解する ために、無限グリッド上のすべての点でこれを行うのが好きです。",
  "model": "nmt",
  "time_range": [
   117.22,
   125.78
  ],
  "n_reviews": 0
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background just to help keep track of where everything ends up relative to where it starts. ",
  "translatedText": "また、開始位置に対するすべての終了位置を追跡しやすくするために、グ リッドのコピーをバックグラウンドに保存しておきたい場合もあります。",
  "model": "nmt",
  "time_range": [
   126.56,
   132.84
  ],
  "n_reviews": 0
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful. ",
  "translatedText": "空間内のすべての点を移動するさまざまな変換 の効果は、認められるとおり、美しいです。",
  "model": "nmt",
  "time_range": [
   134.46,
   141.08
  ],
  "n_reviews": 0
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself. ",
  "translatedText": "空間自体を押しつぶして変形させるような感覚を与えます。",
  "model": "nmt",
  "time_range": [
   141.88,
   144.64
  ],
  "n_reviews": 0
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated. ",
  "translatedText": "ただし、ご想像のとおり、任意の変換は非常に複雑に見える場合があります。",
  "model": "nmt",
  "time_range": [
   145.6,
   149.92
  ],
  "n_reviews": 0
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations. ",
  "translatedText": "しかし幸いなことに、線形代数は、線形変換と呼ばれる、 より理解しやすい特殊な種類の変換に限定されています。",
  "model": "nmt",
  "time_range": [
   150.38,
   158.28
  ],
  "n_reviews": 0
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties. ",
  "translatedText": "視覚的に言えば、変換に 2 つのプロパティがある場合、変換は線形です。",
  "model": "nmt",
  "time_range": [
   159.12,
   163.06
  ],
  "n_reviews": 0
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place. ",
  "translatedText": "すべての線は曲がらずに線のままでなければならず、原点は所定の位置に固定されていなければなりません。",
  "model": "nmt",
  "time_range": [
   163.7,
   169.6
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy. ",
  "translatedText": "たとえば、ここでは線がすべて曲線になっ ているため、線形変換ではありません。",
  "model": "nmt",
  "time_range": [
   170.62,
   175.54
  ],
  "n_reviews": 0
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin. ",
  "translatedText": "そして、ここにあるものは、線を真っ直ぐに保ちます が、原点を移動するため、線形変換ではありません。",
  "model": "nmt",
  "time_range": [
   176.1,
   181.86
  ],
  "n_reviews": 0
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines. ",
  "translatedText": "これは原点を固定しており、線がまっすぐに保たれているように見えるかもしれま せんが、それは水平と垂直のグリッド線だけを表示しているだけであるためです。",
  "model": "nmt",
  "time_range": [
   182.68,
   189.24
  ],
  "n_reviews": 0
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy. ",
  "translatedText": "対角線がどうなるかを見ると、その線がすべて曲線に なるため、まったく直線ではないことがわかります。",
  "model": "nmt",
  "time_range": [
   189.54,
   195.32
  ],
  "n_reviews": 0
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced. ",
  "translatedText": "一般に、線形変換はグリッド線を平行かつ等 間隔に保つことと考える必要があります。",
  "model": "nmt",
  "time_range": [
   196.76,
   202.24
  ],
  "n_reviews": 0
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin. ",
  "translatedText": "原点を中心とした回転など、一部の線形変換は考えるのが簡単です。",
  "model": "nmt",
  "time_range": [
   203.4,
   207.54
  ],
  "n_reviews": 0
 },
 {
  "input": "Others are a little trickier to describe with words. ",
  "translatedText": "言葉で説明するのが少し難しいものもあります。",
  "model": "nmt",
  "time_range": [
   208.12,
   210.6
  ],
  "n_reviews": 0
 },
 {
  "input": "So how do you think you could describe these transformations numerically? ",
  "translatedText": "では、これらの変化を数値的に説明するにはどうすればよいでしょうか? ",
  "model": "nmt",
  "time_range": [
   212.04,
   215.48
  ],
  "n_reviews": 0
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands? ",
  "translatedText": "たとえば、トピックを教えるビデオを作成するためにアニメーションをプログラミ ングしている場合、コンピュータにベクトルの座標を与えると、そのベクトルが到 達する位置の座標が得られるように、どのような式をコンピュータに与えますか? ",
  "model": "nmt",
  "time_range": [
   215.48,
   227.24
  ],
  "n_reviews": 0
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that. ",
  "translatedText": "2 つの基底ベクトル、i-hat と j-hat、それぞれの着地がどこに あるかを記録するだけでよく、その他すべてはそこから続くことがわかります。",
  "model": "nmt",
  "time_range": [
   228.48,
   236.6
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat. ",
  "translatedText": "たとえば、座標が負の 1、2 であるベクトル v を考えます。これは、負の 1 倍 i-hat と 2 倍 j-hat に等しいことを意味します。",
  "model": "nmt",
  "time_range": [
   237.5,
   245.7
  ],
  "n_reviews": 0
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence. ",
  "translatedText": "何らかの変換を実行して、これら 3 つのベクトルすべてがどこに行くのかを追跡すると 、グリッド線が平行かつ等間隔に保たれるという特性が非常に重要な結果をもたらします。",
  "model": "nmt",
  "time_range": [
   248.68,
   258.3
  ],
  "n_reviews": 0
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed. ",
  "translatedText": "v が着地する場所は、i-hat が着地したベクトルの 1 倍に、 j-hat が着地したベクトルの 2 倍を加えた負の値になります。",
  "model": "nmt",
  "time_range": [
   259.1,
   265.4
  ],
  "n_reviews": 0
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed. ",
  "translatedText": "言い換えれば、それは i-hat と j-hat の特定の線形結合として始 まり、最終的にはこれら 2 つのベクトルが着地した同じ線形結合になります。",
  "model": "nmt",
  "time_range": [
   265.98,
   274.58
  ],
  "n_reviews": 0
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land. ",
  "translatedText": "これは、i-hat と j-hat がそれぞれ着地する場所のみに基づいて v がどこに行くべきかを推測できることを意味します。",
  "model": "nmt",
  "time_range": [
   275.62,
   280.92
  ],
  "n_reviews": 0
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background. ",
  "translatedText": "これが、私が元のグリッドのコピーをバックグラウンドに保持しておくのが好きな理由です。",
  "model": "nmt",
  "time_range": [
   281.58,
   284.54
  ],
  "n_reviews": 0
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0. ",
  "translatedText": "ここに示す変換では、i-hat が座標 1、負の 2 に着地し、j -hat が座標 3、0 の x 軸に着地することが読み取れます。",
  "model": "nmt",
  "time_range": [
   285.08,
   294.94
  ],
  "n_reviews": 0
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0. ",
  "translatedText": "これは、負の 1 i-hat と j-hat の 2 倍で表されるベクトルは、最終的にベクトル 1 の負の 1 倍、負の 2 プラス ベクトル 3 の 2 倍、0 になることを意味します。",
  "model": "nmt",
  "time_range": [
   295.53999999999996,
   306.14
  ],
  "n_reviews": 0
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2. ",
  "translatedText": "これらをすべて合計すると、ベクトル 5、2 に着地する必要があると推測できます。",
  "model": "nmt",
  "time_range": [
   307.1,
   311.68
  ],
  "n_reviews": 0
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important. ",
  "translatedText": "これは非常に重要なことなので、立ち止まって熟考するのに良いポイントです。",
  "model": "nmt",
  "time_range": [
   314.26,
   317.24
  ],
  "n_reviews": 0
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2. ",
  "translatedText": "ここで、実際に完全な変換を示していることを考えると、 v の座標が 5、2 であることがわかるはずです。",
  "model": "nmt",
  "time_range": [
   318.52,
   325.28
  ],
  "n_reviews": 0
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land, without needing to watch the transformation itself. ",
  "translatedText": "しかし、ここでの素晴らしい点は、i-hat と j-hat がそれ ぞれどこに着地するか記録があれば、変換自体を観察する必要がなく、ベ クトルがどこに着地するかを推定するテクニックが得られることです。",
  "model": "nmt",
  "time_range": [
   325.76,
   337.38
  ],
  "n_reviews": 0
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0. ",
  "translatedText": "より一般的な座標 x と y を使用してベクトルを記述すると、i-hat が着地するベクトルの x 倍、1、負の 2、および j-hat が着地するベクトルの y 倍、3、0 に着地します。",
  "model": "nmt",
  "time_range": [
   338.6,
   350.6
  ],
  "n_reviews": 0
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y. ",
  "translatedText": "この合計を実行すると、1x プラス 3y、マイナス 2x プラス 0y になることがわかります。",
  "model": "nmt",
  "time_range": [
   351.86,
   358.1
  ],
  "n_reviews": 0
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula. ",
  "translatedText": "任意のベクトルを与えると、この公式を使用してそのベクトルがどこに着地するかを教えてもらえます。",
  "model": "nmt",
  "time_range": [
   358.74,
   363.58
  ],
  "n_reviews": 0
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands, and the two coordinates for where j-hat lands. ",
  "translatedText": "これらすべてが言っているのは、2 次元の線形変換は、i-hat が着地する 2 つの座標と j-hat が着地する 2 つの 座標という 4 つの数値だけで完全に記述できるということです。",
  "model": "nmt",
  "time_range": [
   364.86,
   376.5
  ],
  "n_reviews": 0
 },
 {
  "input": "Isn't that cool? ",
  "translatedText": "それはクールじゃないですか？",
  "model": "nmt",
  "time_range": [
   377.08,
   377.64
  ],
  "n_reviews": 0
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land. ",
  "translatedText": "これらの座標を 2x2 行列と呼ばれる数値の 2x2 グリッドにパッ ケージ化するのが一般的です。ここで、列を i-hat と j-ha t がそれぞれ着地する 2 つの特別なベクトルとして解釈できます。",
  "model": "nmt",
  "time_range": [
   378.38,
   389.64
  ],
  "n_reviews": 0
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get. ",
  "translatedText": "線形変換を記述する 2x2 行列と特定のベクトルが与 えられ、その線形変換がそのベクトルをどこに取るかを知 りたい場合は、ベクトルの座標を取得し、それらを行列の 対応する列で乗算します。得られたものを合計します。",
  "model": "nmt",
  "time_range": [
   390.38,
   407.34
  ],
  "n_reviews": 0
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors. ",
  "translatedText": "これは、新しい基底ベクトルのスケーリングされたバージョンを追加するという考えに対応します。",
  "model": "nmt",
  "time_range": [
   408.18,
   412.72
  ],
  "n_reviews": 0
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D. ",
  "translatedText": "行列にエントリ A、B、C、D がある最も一般的な ケースでこれがどのようになるかを見てみましょう。",
  "model": "nmt",
  "time_range": [
   414.72,
   420.54
  ],
  "n_reviews": 0
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation. ",
  "translatedText": "この行列は、線形変換を記述するために必要な情報をパッケ ージ化する単なる方法であることを覚えておいてください。",
  "model": "nmt",
  "time_range": [
   421.1,
   426.24
  ],
  "n_reviews": 0
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands. ",
  "translatedText": "最初の列 AC を最初の基底ベクトルが到着する場所として解釈し、2 番目の列 BD を 2 番目の基底ベクトルが到着する場所として解釈することを常に忘れないでください。",
  "model": "nmt",
  "time_range": [
   426.24,
   436.44
  ],
  "n_reviews": 0
 },
 {
  "input": "When we apply this transformation to some vector x, y, what do you get? ",
  "translatedText": "この変換をベクトル x、y に適用すると、何が得られるでしょうか? ",
  "model": "nmt",
  "time_range": [
   437.5,
   441.0
  ],
  "n_reviews": 0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD. ",
  "translatedText": "そうですね、AC の x 倍と BD の y 倍になります。",
  "model": "nmt",
  "time_range": [
   442.06,
   446.98
  ],
  "n_reviews": 0
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy. ",
  "translatedText": "これをまとめると、ベクトル Ax と By、Cx と Dy が得られます。",
  "model": "nmt",
  "time_range": [
   448.06,
   453.3
  ],
  "n_reviews": 0
 },
 {
  "input": "You could even define this as matrix-vector multiplication when you put the matrix on the left of the vector like it's a function. ",
  "translatedText": "行列を関数のようにベクトルの左側に置くと、これを行 列とベクトルの乗算として定義することもできます。",
  "model": "nmt",
  "time_range": [
   453.98,
   460.94
  ],
  "n_reviews": 0
 },
 {
  "input": "Then you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive. ",
  "translatedText": "そうすれば、直感的に感じられる重要な部分を見せ ずに、高校生にこれを暗記させることができます。",
  "model": "nmt",
  "time_range": [
   461.66,
   466.62
  ],
  "n_reviews": 0
 },
 {
  "input": "But isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors? ",
  "translatedText": "しかし、これらの列を基底ベクトルの変換バージョン として考え、その結果をそれらのベクトルの適切な 線形結合として考える方が楽しいと思いませんか? ",
  "model": "nmt",
  "time_range": [
   468.3,
   477.96
  ],
  "n_reviews": 0
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices. ",
  "translatedText": "行列を使用していくつかの線形変換を記述する練習をしてみましょう。",
  "model": "nmt",
  "time_range": [
   480.72,
   483.78
  ],
  "n_reviews": 0
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then I-hat lands on the coordinates 0, 1, and J-hat lands on the coordinates negative 1, 0. ",
  "translatedText": "たとえば、空間全体を反時計回りに 90 度回転すると、I ハットは座標 0、1 に着地し、J ハットは座標のマイナス 1、0 に着地します。",
  "model": "nmt",
  "time_range": [
   484.58,
   497.18
  ],
  "n_reviews": 0
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0. ",
  "translatedText": "したがって、最終的に得られる行列の列は 0、1、負の 1、0 になります。",
  "model": "nmt",
  "time_range": [
   497.98,
   501.96
  ],
  "n_reviews": 0
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix. ",
  "translatedText": "90 度回転したベクトルに何が起こるかを調べる には、その座標にこの行列を乗算するだけです。",
  "model": "nmt",
  "time_range": [
   502.88,
   509.62
  ],
  "n_reviews": 0
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear. ",
  "translatedText": "ここでは、ハサミと呼ばれる特別な名前が付いた楽しい変身を紹介します。",
  "model": "nmt",
  "time_range": [
   511.56,
   514.3
  ],
  "n_reviews": 0
 },
 {
  "input": "In it, I-hat remains fixed, so the first column of the matrix is 1, 0, but J-hat moves over to the coordinates 1, 1, which become the second column of the matrix. ",
  "translatedText": "ここでは、I ハットは固定されたままであるため、行列の最初の列は 1, 0 で すが、J ハットは座標 1, 1 に移動し、それが行列の 2 列目になります。",
  "model": "nmt",
  "time_range": [
   515.0,
   525.3
  ],
  "n_reviews": 0
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector. ",
  "translatedText": "そして、ここで冗長になる危険がありますが、せん断が与えられたベクトルをどのように変 換するかを理解することは、結局、この行列とそのベクトルを乗算することになります。",
  "model": "nmt",
  "time_range": [
   525.3,
   534.08
  ],
  "n_reviews": 0
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2, and 3, 1, and we want to deduce what its transformation looks like. ",
  "translatedText": "逆に、列 1、2、および 3、1 の行列から始めて 、その変換がどのようになるかを推定したいとします。",
  "model": "nmt",
  "time_range": [
   535.76,
   544.52
  ],
  "n_reviews": 0
 },
 {
  "input": "Pause and take a moment to see if you can imagine it. ",
  "translatedText": "少し立ち止まって、想像できるかどうかを確認してください。",
  "model": "nmt",
  "time_range": [
   544.96,
   547.44
  ],
  "n_reviews": 0
 },
 {
  "input": "One way to do this is to first move I-hat to 1, 2, then move J-hat to 3, 1, always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced. ",
  "translatedText": "これを行う 1 つの方法は、まず I ハットを 1、2 に移動し、次に J ハットを 3 、1 に移動し、常にグリッド線が平行かつ等間隔になるように残りのスペースを移動します。",
  "model": "nmt",
  "time_range": [
   548.42,
   560.22
  ],
  "n_reviews": 0
 },
 {
  "input": "If the vectors that I-hat and J-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors. ",
  "translatedText": "I ハットと J ハットが着地するベクトルが線形依存している場合、これは、前回のビデオを思 い出していただけると、一方が他方のスケーリングされたバージョンであることを意味し、線形変換 によって 2D 空間全体が 2D 空間に押しつぶされることを意味します。これら 2 つのベ クトルが位置するライン。これら 2 つの線形依存ベクトルの 1 次元スパンとも呼ばれます。",
  "model": "nmt",
  "time_range": [
   561.68,
   582.42
  ],
  "n_reviews": 0
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed. ",
  "translatedText": "要約すると、線形変換は、グリッド線が平行かつ等間隔に保たれ、 原点が固定されたままになるように空間内を移動する方法です。",
  "model": "nmt",
  "time_range": [
   584.4200000000001,
   593.94
  ],
  "n_reviews": 0
 },
 {
  "input": "Flightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands. ",
  "translatedText": "これらの変換は、少数の数値、つまり各基底ベクトル が着地する座標のみを使用して簡単に記述できます。",
  "model": "nmt",
  "time_range": [
   594.54,
   601.5300000000001
  ],
  "n_reviews": 0
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector. ",
  "translatedText": "行列は、これらの変換を記述するための言語を提供します。列は それらの座標を表し、行列とベクトルの乗算は、その変換が特 定のベクトルに対して何を行うかを計算する単なる方法です。",
  "model": "nmt",
  "time_range": [
   602.76,
   614.66
  ],
  "n_reviews": 0
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space. ",
  "translatedText": "ここで重要なのは、マトリックスを見るたびに、それを 空間の特定の変換として解釈できるということです。",
  "model": "nmt",
  "time_range": [
   615.36,
   621.88
  ],
  "n_reviews": 0
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply. ",
  "translatedText": "この考え方をしっかり理解すると、線形 代数を深く理解できるようになります。",
  "model": "nmt",
  "time_range": [
   622.58,
   627.32
  ],
  "n_reviews": 0
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space. ",
  "translatedText": "行列の乗算から行列式、基底の変更、固有値に至るまで、今 後出てくるほぼすべてのトピックは、行列を空間の変換とし て考え始めると、より簡単に理解できるようになります。",
  "model": "nmt",
  "time_range": [
   627.66,
   640.56
  ],
  "n_reviews": 0
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together. ",
  "translatedText": "すぐに、次のビデオで 2 つの 行列の乗算について説明します。",
  "model": "nmt",
  "time_range": [
   641.3,
   645.66
  ],
  "n_reviews": 0
 },
 {
  "input": "See you then! ",
  "translatedText": "それではまた！",
  "model": "nmt",
  "time_range": [
   646.12,
   645.22
  ],
  "n_reviews": 0
 },
 {
  "input": "Thank you for watching! ",
  "translatedText": "ご清覧ありがとうございました！",
  "model": "nmt",
  "time_range": [
   645.22,
   646.32
  ],
  "n_reviews": 0
 }
]