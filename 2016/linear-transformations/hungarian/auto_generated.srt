1
00:00:12,040 --> 00:00:12,920
Sziasztok!

2
00:00:13,320 --> 00:00:16,374
Ha egyetlen témát kellene választanom, ami miatt a lineáris algebra összes 

3
00:00:16,374 --> 00:00:19,510
többi témája elkezd kattogni, és amit túl gyakran nem tanulnak meg a diákok, 

4
00:00:19,510 --> 00:00:22,280
amikor először vesznek részt lineáris algebrában, akkor ez lenne az.

5
00:00:22,700 --> 00:00:26,200
A lineáris transzformáció fogalma és kapcsolata a mátrixokkal.

6
00:00:26,950 --> 00:00:29,166
Ebben a videóban csak arra fogok koncentrálni, 

7
00:00:29,166 --> 00:00:32,278
hogy két dimenzió esetén hogyan néznek ki ezek a transzformációk, 

8
00:00:32,278 --> 00:00:35,060
és hogyan kapcsolódnak a mátrixvektor-szorzás gondolatához.

9
00:00:35,880 --> 00:00:40,224
Különösen a mátrix-vektor szorzásról való gondolkodás olyan módját szeretném megmutatni, 

10
00:00:40,224 --> 00:00:42,080
amely nem a memorizálásra támaszkodik.

11
00:00:43,160 --> 00:00:46,580
Kezdjük azzal, hogy elemezzük ezt a kifejezést, a lineáris transzformációt.

12
00:00:47,420 --> 00:00:49,880
A transzformáció lényegében egy divatos szó a funkcióra.

13
00:00:50,260 --> 00:00:53,980
Ez egy olyan dolog, amely bemeneti adatokat vesz fel, és mindegyikhez kiad egy kimenetet.

14
00:00:53,980 --> 00:00:58,145
Konkrétan, a lineáris algebra kontextusában szeretünk olyan transzformációkra gondolni, 

15
00:00:58,145 --> 00:01:01,080
amelyek egy vektort vesznek be, és egy másik vektort adnak ki.

16
00:01:02,500 --> 00:01:06,380
Akkor miért használjuk a transzformáció szót a funkció helyett, ha ugyanazt jelentik?

17
00:01:07,120 --> 00:01:09,209
Nos, ez egy bizonyos módot sugall arra, hogy ezt a 

18
00:01:09,209 --> 00:01:11,340
bemeneti-kimeneti kapcsolatot szemléltetni lehessen.

19
00:01:11,860 --> 00:01:15,800
Látod, a vektorok függvényeinek megértéséhez nagyszerű módszer a mozgás használata.

20
00:01:16,780 --> 00:01:20,792
Ha egy transzformáció egy bemeneti vektort egy kimeneti vektorba visz át, 

21
00:01:20,792 --> 00:01:24,860
akkor azt képzeljük el, hogy a bemeneti vektor átkerül a kimeneti vektorba.

22
00:01:25,680 --> 00:01:29,426
Ezután, hogy megértsük az átalakítás egészét, elképzelhetjük, 

23
00:01:29,426 --> 00:01:34,080
hogy minden lehetséges bemeneti vektor átkerül a megfelelő kimeneti vektorba.

24
00:01:34,980 --> 00:01:37,753
Nagyon zsúfolttá válik, ha egyszerre gondolunk az összes vektorra, 

25
00:01:37,753 --> 00:01:39,120
mindegyikre, mint egy-egy nyílra.

26
00:01:39,500 --> 00:01:42,420
Tehát, ahogy a múltkori videóban említettem, egy jó trükk, 

27
00:01:42,420 --> 00:01:46,628
ha minden vektort nem nyílként, hanem egyetlen pontként fogalmazunk meg, a pontként, 

28
00:01:46,628 --> 00:01:47,420
ahol a hegye ül.

29
00:01:48,030 --> 00:01:52,137
Így, ha egy olyan transzformációra gondolunk, amely minden lehetséges bemeneti vektort 

30
00:01:52,137 --> 00:01:56,340
valamilyen kimeneti vektorba visz, akkor a tér minden pontját egy másik pontba mozgatjuk.

31
00:01:57,220 --> 00:02:01,472
A kétdimenziós transzformációk esetében, hogy jobban érezzük a transzformáció 

32
00:02:01,472 --> 00:02:05,780
teljes alakját, szeretem ezt egy végtelen rácson lévő összes ponttal elvégezni.

33
00:02:06,560 --> 00:02:09,151
Néha szeretem a háttérben tartani a rács egy másolatát is, 

34
00:02:09,151 --> 00:02:12,840
hogy könnyebben nyomon követhessem, hol végződik minden a kiindulási helyhez képest.

35
00:02:14,460 --> 00:02:19,209
A tér összes pontja körül mozgó különböző transzformációk hatása, 

36
00:02:19,209 --> 00:02:21,080
el kell ismerni, gyönyörű.

37
00:02:21,880 --> 00:02:24,640
Azt az érzést kelti, mintha maga a tér összenyomódna és morfondírozódna.

38
00:02:25,600 --> 00:02:29,920
Amint azt el tudja képzelni, az önkényes transzformációk elég bonyolultnak tűnhetnek.

39
00:02:30,380 --> 00:02:34,382
De szerencsére a lineáris algebra a transzformációk egy speciális típusára, 

40
00:02:34,382 --> 00:02:38,280
a könnyebben érthető, úgynevezett lineáris transzformációkra korlátozódik.

41
00:02:39,120 --> 00:02:43,060
Vizuálisan egy transzformáció akkor lineáris, ha két tulajdonsággal rendelkezik.

42
00:02:43,700 --> 00:02:46,503
Minden vonalnak vonalnak kell maradnia anélkül, 

43
00:02:46,503 --> 00:02:49,600
hogy görbülne, és az origónak a helyén kell maradnia.

44
00:02:50,620 --> 00:02:55,540
Például ez itt nem lenne lineáris transzformáció, mivel a vonalak görbék lesznek.

45
00:02:56,100 --> 00:02:58,810
Ez itt pedig, bár egyenesen tartja a vonalakat, 

46
00:02:58,810 --> 00:03:01,860
nem lineáris transzformáció, mert áthelyezi az origót.

47
00:03:02,680 --> 00:03:05,855
Ez itt rögzíti az origót, és úgy tűnhet, hogy egyenesen tartja a vonalakat, 

48
00:03:05,855 --> 00:03:09,240
de ez csak azért van, mert csak a vízszintes és függőleges rácsvonalakat mutatom.

49
00:03:09,540 --> 00:03:12,473
Ha megnézed, mit csinál egy átlós vonallal, akkor világossá válik, 

50
00:03:12,473 --> 00:03:15,320
hogy egyáltalán nem lineáris, mivel az egész vonal görbévé válik.

51
00:03:16,760 --> 00:03:19,301
Általánosságban a lineáris transzformációkra úgy kell gondolni, 

52
00:03:19,301 --> 00:03:22,240
hogy a rácsvonalak párhuzamosak és egyenletes távolságra vannak egymástól.

53
00:03:23,400 --> 00:03:25,690
Néhány lineáris transzformációra egyszerű gondolni, 

54
00:03:25,690 --> 00:03:27,540
mint például az origó körüli forgatásokra.

55
00:03:28,120 --> 00:03:30,600
Másokat kicsit nehezebb szavakkal leírni.

56
00:03:32,040 --> 00:03:35,480
Szóval, mit gondolsz, hogyan tudnád ezeket a transzformációkat numerikusan leírni?

57
00:03:35,480 --> 00:03:39,550
Ha mondjuk animációkat programoznál, hogy készíts egy videót a téma oktatásához, 

58
00:03:39,550 --> 00:03:43,772
milyen képletet adsz a számítógépnek, hogy ha megadod neki egy vektor koordinátáit, 

59
00:03:43,772 --> 00:03:47,240
akkor meg tudja adni neked a koordinátákat, hogy hol landol a vektor?

60
00:03:48,480 --> 00:03:52,571
Kiderül, hogy csak azt kell feljegyezni, hogy a két alapvektor, 

61
00:03:52,571 --> 00:03:56,600
az i-hat és a j-hat hol landol, és minden más ebből következik.

62
00:03:57,500 --> 00:04:01,448
Vegyük például a v v vektort, amelynek koordinátái negatív 1, 2, 

63
00:04:01,448 --> 00:04:05,700
ami azt jelenti, hogy egyenlő negatív 1-szer i-hat plusz 2-szer j-hat.

64
00:04:08,680 --> 00:04:12,386
Ha eljátszunk néhány transzformációt, és követjük, hogy hová megy mindhárom vektor, 

65
00:04:12,386 --> 00:04:15,740
akkor annak a tulajdonságnak, hogy a rácsvonalak párhuzamosak és egyenletes 

66
00:04:15,740 --> 00:04:18,300
távolságban maradnak, van egy igazán fontos következménye.

67
00:04:19,100 --> 00:04:22,057
Az a hely, ahol v landol, negatív lesz, 1-szerese annak a vektornak, 

68
00:04:22,057 --> 00:04:25,400
ahol i-kalap landolt, plusz 2-szerese annak a vektornak, ahol j-kalap landolt.

69
00:04:25,980 --> 00:04:30,391
Más szóval, az i-hat és a j-hat egy bizonyos lineáris kombinációjaként indult, 

70
00:04:30,391 --> 00:04:34,580
és ugyanez a lineáris kombinációja annak, hogy hol landolt ez a két vektor.

71
00:04:35,620 --> 00:04:38,147
Ez azt jelenti, hogy csak az i-hat és a j-hat helyére történő 

72
00:04:38,147 --> 00:04:40,920
levonás alapján következtethetünk arra, hogy v-nek hova kell mennie.

73
00:04:41,580 --> 00:04:44,540
Ezért szeretem az eredeti rács másolatát a háttérben tartani.

74
00:04:45,080 --> 00:04:49,532
Az itt látható transzformációnál leolvashatjuk, hogy az i-kalap az 1, 

75
00:04:49,532 --> 00:04:54,940
negatív 2 koordinátákon landol, a j-kalap pedig az x-tengelyen a 3, 0 koordinátáknál.

76
00:04:55,540 --> 00:05:00,840
Ez azt jelenti, hogy a negatív 1 i-hat plusz 2-szer j-hat által képviselt 

77
00:05:00,840 --> 00:05:06,140
vektor a negatív 1-szer 1, negatív 2 plusz 2-szer 3, 0 vektorban végződik.

78
00:05:07,100 --> 00:05:11,680
Ha mindezt összeadjuk, akkor arra következtethetünk, hogy az 5, 2 vektoron kell landolnia.

79
00:05:14,260 --> 00:05:17,240
Ezen a ponton érdemes megállni és elgondolkodni, mert ez elég fontos.

80
00:05:18,520 --> 00:05:22,392
Most, hogy valójában a teljes transzformációt mutatom meg, 

81
00:05:22,392 --> 00:05:25,280
megnézhetted volna, hogy v koordinátái 5, 2.

82
00:05:25,760 --> 00:05:28,822
De a legjobb az egészben az, hogy ez egy olyan technikát ad nekünk, 

83
00:05:28,822 --> 00:05:31,615
amiből következtethetünk arra, hogy hol landolnak a vektorok, 

84
00:05:31,615 --> 00:05:35,353
amíg van egy feljegyzésünk arról, hogy hol landolnak az i-hat és a j-hat, anélkül, 

85
00:05:35,353 --> 00:05:37,380
hogy magát az átalakítást kellene figyelnünk.

86
00:05:38,600 --> 00:05:41,888
Írjuk fel a vektort általánosabb koordinátákkal, x és y, 

87
00:05:41,888 --> 00:05:46,100
és az x-szeresén fog landolni annak a vektornak, ahol az i-kalap landol, 

88
00:05:46,100 --> 00:05:50,600
1, negatív 2, plusz y-szeresén annak a vektornak, ahol a j-kalap landol, 3, 0.

89
00:05:51,860 --> 00:05:58,100
Az összeget elvégezve láthatjuk, hogy 1x plusz 3y, negatív 2x plusz 0y.

90
00:05:58,740 --> 00:06:01,218
Megadok neked egy tetszőleges vektort, és te meg tudod mondani, 

91
00:06:01,218 --> 00:06:03,580
hogy az a vektor hol landol ennek a képletnek a segítségével.

92
00:06:04,860 --> 00:06:10,576
Mindez azt jelenti, hogy egy kétdimenziós lineáris transzformáció teljes mértékben 

93
00:06:10,576 --> 00:06:16,500
leírható mindössze négy számmal, az i-kalap és a j-kalap helyének két koordinátájával.

94
00:06:17,080 --> 00:06:17,640
Hát nem király?

95
00:06:18,380 --> 00:06:21,532
Általában ezeket a koordinátákat egy 2x2-es számrácsba, 

96
00:06:21,532 --> 00:06:25,586
egy 2x2-es mátrixba csomagoljuk, ahol az oszlopokat úgy értelmezhetjük, 

97
00:06:25,586 --> 00:06:29,640
mint a két speciális vektort, ahol az i-hat és a j-hat egyenként landol.

98
00:06:30,380 --> 00:06:34,471
Ha kapunk egy 2x2-es mátrixot, amely egy lineáris transzformációt és 

99
00:06:34,471 --> 00:06:38,860
egy adott vektort ír le, és tudni akarjuk, hogy a lineáris transzformáció 

100
00:06:38,860 --> 00:06:42,299
hova viszi a vektort, akkor fogjuk a vektor koordinátáit, 

101
00:06:42,299 --> 00:06:47,340
megszorozzuk őket a mátrix megfelelő oszlopaival, majd összeadjuk a kapott eredményt.

102
00:06:48,180 --> 00:06:50,402
Ez megfelel annak az elképzelésnek, hogy az új 

103
00:06:50,402 --> 00:06:52,720
alapvektoraink skálázott változatait adjuk hozzá.

104
00:06:54,720 --> 00:06:57,861
Nézzük meg, hogy ez hogyan néz ki a legáltalánosabb esetben, 

105
00:06:57,861 --> 00:07:00,540
amikor a mátrixunknak A, B, C, D bejegyzései vannak.

106
00:07:01,100 --> 00:07:03,258
És ne feledjük, hogy ez a mátrix csak egy módja annak, 

107
00:07:03,258 --> 00:07:06,240
hogy a lineáris transzformáció leírásához szükséges információt csomagoljuk.

108
00:07:06,240 --> 00:07:10,017
Ne feledje, hogy az első oszlopot (AC) úgy kell értelmezni, 

109
00:07:10,017 --> 00:07:14,299
mint az első bázisvektor helyét, a második oszlopot (BD) pedig úgy, 

110
00:07:14,299 --> 00:07:16,440
mint a második bázisvektor helyét.

111
00:07:17,500 --> 00:07:21,000
Ha ezt a transzformációt alkalmazzuk egy xy vektorra, mit kapunk?

112
00:07:22,060 --> 00:07:26,980
Nos, ez x-szer AC plusz y-szor BD lesz.

113
00:07:28,060 --> 00:07:33,300
Ha ezt összerakjuk, kapunk egy Ax plusz By, Cx plus Dy vektort.

114
00:07:33,980 --> 00:07:36,893
Ezt akár mátrixvektor-szorzatként is definiálhatnánk, 

115
00:07:36,893 --> 00:07:40,940
amikor a mátrixot a vektor bal oldalára tesszük, mintha egy függvény lenne.

116
00:07:41,660 --> 00:07:43,808
Aztán a középiskolásokkal memorizálhatnád ezt anélkül, 

117
00:07:43,808 --> 00:07:46,620
hogy megmutatnád nekik azt a döntő részt, ami intuitívvá teszi a dolgot.

118
00:07:48,300 --> 00:07:51,193
De nem szórakoztatóbb, ha úgy gondolunk ezekre az oszlopokra, 

119
00:07:51,193 --> 00:07:55,020
mint az alapvektoraid transzformált változataira, és az eredményre úgy gondolunk, 

120
00:07:55,020 --> 00:07:57,960
mint ezeknek a vektoroknak a megfelelő lineáris kombinációjára?

121
00:08:00,720 --> 00:08:03,780
Gyakoroljuk néhány lineáris transzformáció leírását mátrixokkal.

122
00:08:04,580 --> 00:08:09,686
Például, ha az egész teret 90 fokkal az óramutató járásával ellentétes irányba forgatjuk, 

123
00:08:09,686 --> 00:08:12,240
akkor az i-kalap a 0, 1 koordinátákon landol.

124
00:08:13,980 --> 00:08:17,180
És j-hat landol a koordináták negatív 1, 0.

125
00:08:17,980 --> 00:08:21,960
Tehát a mátrix, amit kapunk, 0, 1, negatív 1, 0 oszlopokkal rendelkezik.

126
00:08:22,880 --> 00:08:26,905
Ahhoz, hogy kitaláljuk, mi történik bármelyik vektorral egy 90 fokos elforgatás után, 

127
00:08:26,905 --> 00:08:29,620
egyszerűen megszorozzuk a koordinátáit ezzel a mátrixszal.

128
00:08:31,560 --> 00:08:34,299
Íme egy mókás átalakítás, amelynek különleges neve van: nyírás.

129
00:08:35,000 --> 00:08:39,159
Ebben az i-hat fix marad, így a mátrix első oszlopa 1, 0.

130
00:08:39,600 --> 00:08:45,300
De a j-hat átmegy az 1, 1 koordinátákra, amelyek a mátrix második oszlopává válnak.

131
00:08:45,300 --> 00:08:48,586
És kockáztatva, hogy feleslegesen fogalmazok, annak kitalálása, 

132
00:08:48,586 --> 00:08:51,769
hogy a nyírás hogyan alakít át egy adott vektort, úgy jön ki, 

133
00:08:51,769 --> 00:08:54,080
hogy ezt a mátrixot megszorozzuk a vektorral.

134
00:08:55,760 --> 00:09:00,407
Tegyük fel, hogy fordítva akarunk eljárni, és egy mátrixból indulunk ki, mondjuk az 1, 

135
00:09:00,407 --> 00:09:04,520
2 és 3, 1 oszlopokkal, és szeretnénk levezetni, hogyan néz ki az átalakítása.

136
00:09:04,960 --> 00:09:07,440
Álljon meg, és szánjon rá egy pillanatot, hogy megnézze, el tudja-e képzelni.

137
00:09:08,420 --> 00:09:15,100
Ennek egyik módja, hogy először az i-hatot az 1, 2-re, majd a j-hatot a 3, 1-re mozgatjuk.

138
00:09:15,100 --> 00:09:17,871
A tér többi részét mindig úgy mozgatja, hogy a rácsvonalak 

139
00:09:17,871 --> 00:09:20,220
párhuzamosak és egyenletes távolságban maradjanak.

140
00:09:21,680 --> 00:09:25,393
Ha az i-hat és j-hat vektorok lineárisan függnek egymástól, ami, 

141
00:09:25,393 --> 00:09:30,535
ha emlékszel a múltkori videóból, azt jelenti, hogy az egyik a másik skálázott változata, 

142
00:09:30,535 --> 00:09:34,592
akkor ez azt jelenti, hogy a lineáris transzformáció az egész 2D teret 

143
00:09:34,592 --> 00:09:38,134
arra a vonalra szorítja, ahol ez a két vektor helyezkedik el, 

144
00:09:38,134 --> 00:09:42,420
ami a két lineárisan függő vektor egydimenziós kiterjedésének is nevezhető.

145
00:09:44,420 --> 00:09:48,929
Összefoglalva, a lineáris transzformációk segítségével úgy mozoghatunk a térben, 

146
00:09:48,929 --> 00:09:53,940
hogy a rácsvonalak párhuzamosak és egyenletes távolságban maradnak, és az origó fix marad.

147
00:09:54,540 --> 00:09:59,220
Csodálatos módon ezek a transzformációk mindössze néhány számmal írhatók le, 

148
00:09:59,220 --> 00:10:01,530
az egyes bázisvektorok koordinátáival.

149
00:10:02,760 --> 00:10:06,533
A mátrixok egy nyelvet adnak nekünk ezeknek a transzformációknak a leírására, 

150
00:10:06,533 --> 00:10:09,048
ahol az oszlopok képviselik ezeket a koordinátákat, 

151
00:10:09,048 --> 00:10:12,289
és a mátrix-vektor szorzás csak egy módja annak, hogy kiszámítsuk, 

152
00:10:12,289 --> 00:10:14,660
mit tesz ez a transzformáció egy adott vektorral.

153
00:10:15,360 --> 00:10:19,100
A fontos tanulság az, hogy minden alkalommal, amikor egy mátrixot látunk, 

154
00:10:19,100 --> 00:10:21,880
a tér egy bizonyos transzformációjaként értelmezhetjük.

155
00:10:22,580 --> 00:10:24,357
Ha ezt a gondolatot egyszer igazán megemészted, 

156
00:10:24,357 --> 00:10:27,320
akkor nagyszerű helyzetben vagy ahhoz, hogy mélyen megértsd a lineáris algebrát.

157
00:10:27,660 --> 00:10:31,880
Szinte az összes következő téma, a mátrixszorzástól a determinánsokig, 

158
00:10:31,880 --> 00:10:36,398
a bázisváltásig, a sajátértékekig, mindezek könnyebben megérthetővé válnak, 

159
00:10:36,398 --> 00:10:40,560
ha a mátrixokról mint a tér transzformációiról kezdesz el gondolkodni.

160
00:10:41,300 --> 00:10:46,320
A következő videóban két mátrix összeszorzásáról fogok beszélni.

