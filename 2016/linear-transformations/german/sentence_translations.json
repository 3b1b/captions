[
 {
  "input": "Hey everyone!",
  "translatedText": "Hallo alle miteinander!",
  "model": "google_nmt",
  "from_community_srt": "Dummerweise kann man niemandem erklären, was die Matrix ist. Du musst sie selbst erleben. Morpheus Erstaunlich zutreffende Worte über die Wichtigkeit des visuellen Verständnisses von Matrix–Operationen.",
  "n_reviews": 0,
  "start": 12.04,
  "end": 12.92
 },
 {
  "input": "If I had to choose just one topic that makes all of the others in linear algebra start to click, and which too often goes unlearned the first time a student takes linear algebra, it would be this one.",
  "translatedText": "Wenn ich nur ein Thema auswählen müsste, das alle anderen in der linearen Algebra zum Klicken bringt und das allzu oft verlernt wird, wenn ein Schüler zum ersten Mal lineare Algebra belegt, dann wäre es dieses.",
  "model": "google_nmt",
  "from_community_srt": "Hallo zusammen! Wenn ich ein Thema auswählen müsste durch das alle anderen Themen der linearen Algebra auf einmal logisch erscheinen und das viel zu oft in den Einführungskursen nicht gelehrt wird dann wäre es dieses:",
  "n_reviews": 0,
  "start": 13.32,
  "end": 22.28
 },
 {
  "input": "The idea of a linear transformation and its relation to matrices.",
  "translatedText": "Die Idee einer linearen Transformation und ihre Beziehung zu Matrizen.",
  "model": "google_nmt",
  "from_community_srt": "die Idee einer linearen Transformation und ihre Verbindungen zu Matritzen.",
  "n_reviews": 0,
  "start": 22.7,
  "end": 26.2
 },
 {
  "input": "For this video, I'm just going to focus on what these transformations look like in the case of two dimensions, and how they relate to the idea of matrix vector multiplication.",
  "translatedText": "In diesem Video werde ich mich nur darauf konzentrieren, wie diese Transformationen im Fall von zwei Dimensionen aussehen und wie sie mit der Idee der Matrixvektormultiplikation zusammenhängen.",
  "model": "google_nmt",
  "from_community_srt": "In diesem Video beschränke ich mich auf das Aussehen dieser Transformationen im zweidimensionalen Raum und wie sie mit Matrix–Vektor–Multiplikation zusammenhängen.",
  "n_reviews": 0,
  "start": 26.95,
  "end": 35.06
 },
 {
  "input": "In particular, I want to show you a way to think about matrix vector multiplication that doesn't rely on memorization.",
  "translatedText": "Insbesondere möchte ich Ihnen eine Möglichkeit zeigen, über die Matrixvektormultiplikation nachzudenken, die nicht auf dem Auswendiglernen beruht.",
  "model": "google_nmt",
  "from_community_srt": "Vor allem möchte ich euch eine Möglichkeit geben über Matrix–Vektor–Multiplikation zu denken die nicht auf Auswendiglernen basiert.",
  "n_reviews": 0,
  "start": 35.88,
  "end": 42.08
 },
 {
  "input": "To start, let's just parse this term, linear transformation.",
  "translatedText": "Lassen Sie uns zunächst diesen Begriff, die lineare Transformation, analysieren.",
  "model": "google_nmt",
  "from_community_srt": "Lasst uns zunächst erst einmal den Begriff \"Lineare Transformation\" genauer ansehen.",
  "n_reviews": 0,
  "start": 43.16,
  "end": 46.58
 },
 {
  "input": "Transformation is essentially a fancy word for function.",
  "translatedText": "Transformation ist im Wesentlichen ein schickes Wort für Funktion.",
  "model": "google_nmt",
  "from_community_srt": "\"Transformation\" ist letztendlich nur ein hochgestochenes Wort für \"Funktion\".",
  "n_reviews": 0,
  "start": 47.42,
  "end": 49.88
 },
 {
  "input": "It's something that takes in inputs and spits out an output for each one.",
  "translatedText": "Es ist etwas, das Inputs aufnimmt und für jeden einen Output ausgibt.",
  "model": "google_nmt",
  "from_community_srt": "Es ist etwas, dass eine Eingabe akzeptiert und eine Ausgabe zurückgibt.",
  "n_reviews": 0,
  "start": 50.26,
  "end": 53.98
 },
 {
  "input": "Specifically, in the context of linear algebra, we like to think about transformations that take in some vector and spit out another vector.",
  "translatedText": "Insbesondere im Kontext der linearen Algebra denken wir gerne über Transformationen nach, die einen Vektor aufnehmen und einen anderen Vektor ausspucken.",
  "model": "google_nmt",
  "from_community_srt": "Im Kontext der linearen Algebra akzeptieren Transformationen in der Regel einen bestimmen Vektor als Eingabe",
  "n_reviews": 0,
  "start": 53.98,
  "end": 61.08
 },
 {
  "input": "So why use the word transformation instead of function if they mean the same thing?",
  "translatedText": "Warum also das Wort „Transformation“ anstelle von „Funktion“ verwenden, wenn beides dasselbe bedeutet?",
  "model": "google_nmt",
  "from_community_srt": "und geben einen anderen Vektor als Ausgabe zurück- Warum sagen wir dann überhaupt \"Transformation\" anstelle von \"Funktion\" – wenn doch beide dasselbe sind?",
  "n_reviews": 0,
  "start": 62.5,
  "end": 66.38
 },
 {
  "input": "Well, it's to be suggestive of a certain way to visualize this input-output relation.",
  "translatedText": "Nun, es soll einen Hinweis auf eine bestimmte Art geben, diese Input-Output-Beziehung zu visualisieren.",
  "model": "google_nmt",
  "from_community_srt": "Nun ja, weil wir damit eine bestimmte Visualisierung dieses Eingabe–Ausgabe–Verhältnisses andeuten.",
  "n_reviews": 0,
  "start": 67.12,
  "end": 71.34
 },
 {
  "input": "You see, a great way to understand functions of vectors is to use movement.",
  "translatedText": "Sie sehen, eine gute Möglichkeit, Funktionen von Vektoren zu verstehen, ist die Verwendung von Bewegung.",
  "model": "google_nmt",
  "from_community_srt": "Weißt du, eine schöne Art und Weise Vektor–Funktionen zu verstehen ist Bewegung.",
  "n_reviews": 0,
  "start": 71.86,
  "end": 75.8
 },
 {
  "input": "If a transformation takes some input vector to some output vector, we imagine that input vector moving over to the output vector.",
  "translatedText": "Wenn eine Transformation einen Eingabevektor in einen Ausgabevektor umwandelt, stellen wir uns vor, dass dieser Eingabevektor in den Ausgabevektor übergeht.",
  "model": "google_nmt",
  "from_community_srt": "Wenn eine Transformation einen bestimmten Eingabe–Vektor auf einen bestimmten Ausgabe–Vektor abbildet, dann stellen wir uns vor, dass der Eingabe–Vektor sich zum Ausgabe–Vektor bewegt.",
  "n_reviews": 0,
  "start": 76.78,
  "end": 84.86
 },
 {
  "input": "Then to understand the transformation as a whole, we might imagine watching every possible input vector move over to its corresponding output vector.",
  "translatedText": "Um die Transformation als Ganzes zu verstehen, könnten wir uns dann vorstellen, zu beobachten, wie sich jeder mögliche Eingabevektor zu seinem entsprechenden Ausgabevektor bewegt.",
  "model": "google_nmt",
  "from_community_srt": "Um dann die Transformation als Ganzes zu verstehen, könnten wir uns jeden möglichen Eingabe–Vektor vorstellen, wie er sich zum entsprechenden Ausgabe–Vektor bewegt.",
  "n_reviews": 0,
  "start": 85.68,
  "end": 94.08
 },
 {
  "input": "It gets really crowded to think about all of the vectors all at once, each one as an arrow.",
  "translatedText": "Es wird wirklich überladen, sich alle Vektoren auf einmal vorzustellen, jeden einzelnen als Pfeil.",
  "model": "google_nmt",
  "from_community_srt": "Es wird ganz schön voll hier wenn wir uns alle Vektoren gleichzeitig als Pfeile vorstellen.",
  "n_reviews": 0,
  "start": 94.98,
  "end": 99.12
 },
 {
  "input": "So as I mentioned last video, a nice trick is to conceptualize each vector not as an arrow, but as a single point, the point where its tip sits.",
  "translatedText": "Wie ich im letzten Video erwähnt habe, besteht ein guter Trick darin, sich jeden Vektor nicht als Pfeil vorzustellen, sondern als einen einzelnen Punkt, den Punkt, an dem seine Spitze sitzt.",
  "model": "google_nmt",
  "from_community_srt": "Wie bereits im letzten Video erwähnt: Ein praktischer Trick um alle Vektoren zu visualisieren ist sie uns als Punkte vorzustellen, die an der Spitze dieser Pfeile liegen.",
  "n_reviews": 0,
  "start": 99.5,
  "end": 107.42
 },
 {
  "input": "That way, to think about a transformation taking every possible input vector to some output vector, we watch every point in space moving to some other point.",
  "translatedText": "Wenn wir also über eine Transformation nachdenken, die jeden möglichen Eingabevektor in einen Ausgabevektor umwandelt, beobachten wir, wie sich jeder Punkt im Raum zu einem anderen Punkt bewegt.",
  "model": "google_nmt",
  "from_community_srt": "Wenn wir und so vorstellen wie eine Transformation alle Eingabe–Vektoren zu ihren Ausgabe–Vektoren bewegt dann sehen wir jeden Punkt im Raum wie er sich zu einem anderen Punkt bewegt.",
  "n_reviews": 0,
  "start": 108.03,
  "end": 116.34
 },
 {
  "input": "In the case of transformations in two dimensions, to get a better feel for the whole shape of the transformation, I like to do this with all of the points on an infinite grid.",
  "translatedText": "Bei Transformationen in zwei Dimensionen mache ich das gerne mit allen Punkten auf einem unendlichen Gitter, um ein besseres Gefühl für die gesamte Form der Transformation zu bekommen.",
  "model": "google_nmt",
  "from_community_srt": "Um bei zweidimensionalen Transformationen ein besseres Gefühl für die \"Form\" der Transformation zu bekommen tue ich genau das mit allen Punkten eines unendlichen Rasters.",
  "n_reviews": 0,
  "start": 117.22,
  "end": 125.78
 },
 {
  "input": "I also sometimes like to keep a copy of the grid in the background, just to help keep track of where everything ends up relative to where it starts.",
  "translatedText": "Manchmal behalte ich auch gerne eine Kopie des Rasters im Hintergrund, um den Überblick zu behalten, wo alles im Vergleich zu seinem Anfang endet.",
  "model": "google_nmt",
  "from_community_srt": "Manchmal behalte ich eine Kopie des Rasters im Hintergrund um im Kopf zu behalten wo alles landet,",
  "n_reviews": 0,
  "start": 126.56,
  "end": 132.84
 },
 {
  "input": "The effect for various transformations moving around all of the points in space is, you've got to admit, beautiful.",
  "translatedText": "Der Effekt verschiedener Transformationen, die sich um alle Punkte im Raum bewegen, ist, das muss man zugeben, wunderschön.",
  "model": "google_nmt",
  "from_community_srt": "relativ zum Anfangspunkt. Der Effekt einiger Transformationen die alle Punkte im Raum bewegen ist, das musst du zugeben,",
  "n_reviews": 0,
  "start": 134.46,
  "end": 141.08
 },
 {
  "input": "It gives the feeling of squishing and morphing space itself.",
  "translatedText": "Es vermittelt das Gefühl, den Raum selbst zu quetschen und zu verändern.",
  "model": "google_nmt",
  "from_community_srt": "schön. Es erweckt den Eindruck, den Raum selbst zu dehnen und zu verbiegen.",
  "n_reviews": 0,
  "start": 141.88,
  "end": 144.64
 },
 {
  "input": "As you can imagine though, arbitrary transformations can look pretty complicated.",
  "translatedText": "Wie Sie sich jedoch vorstellen können, können beliebige Transformationen ziemlich kompliziert aussehen.",
  "model": "google_nmt",
  "from_community_srt": "Wie du dir sicher vorstellen kannst, können arbiträre Transformationen ziemlich kompliziert aussehen.",
  "n_reviews": 0,
  "start": 145.6,
  "end": 149.92
 },
 {
  "input": "But luckily, linear algebra limits itself to a special type of transformation, ones that are easier to understand, called linear transformations.",
  "translatedText": "Aber glücklicherweise beschränkt sich die lineare Algebra auf eine spezielle Art von Transformation, die einfacher zu verstehen ist und als lineare Transformationen bezeichnet wird.",
  "model": "google_nmt",
  "from_community_srt": "Aber glücklicherweise beschränkt sich die lineare Algebra auf eine bestimmte Art Transformationen. Transformationen, die einfacher zu verstehen sind. Gennant \"lineare\" Transformationen.",
  "n_reviews": 0,
  "start": 150.38,
  "end": 158.28
 },
 {
  "input": "Visually speaking, a transformation is linear if it has two properties.",
  "translatedText": "Optisch gesehen ist eine Transformation linear, wenn sie zwei Eigenschaften hat.",
  "model": "google_nmt",
  "from_community_srt": "Aus visueller Perspektive ist eine Transformation linear wenn sie folgende zwei Eigenschaften hat:",
  "n_reviews": 0,
  "start": 159.12,
  "end": 163.06
 },
 {
  "input": "All lines must remain lines without getting curved, and the origin must remain fixed in place.",
  "translatedText": "Alle Linien müssen Linien bleiben, ohne sich zu krümmen, und der Ursprung muss an seinem Platz bleiben.",
  "model": "google_nmt",
  "from_community_srt": "Alle Linien müssen Linien bleiben ohne sich zu krümmen und der Ursprungspunkt muss fixiert bleiben.",
  "n_reviews": 0,
  "start": 163.7,
  "end": 169.6
 },
 {
  "input": "For example, this right here would not be a linear transformation, since the lines get all curvy.",
  "translatedText": "Dies hier wäre beispielsweise keine lineare Transformation, da die Linien alle kurvig werden.",
  "model": "google_nmt",
  "from_community_srt": "Das hier zum Beispiel ist keine lineare Transformation, weil alle Linien gekrümmt werden.",
  "n_reviews": 0,
  "start": 170.62,
  "end": 175.54
 },
 {
  "input": "And this one right here, although it keeps the lines straight, is not a linear transformation, because it moves the origin.",
  "translatedText": "Und diese hier, obwohl sie die Linien gerade hält, ist keine lineare Transformation, weil sie den Ursprung verschiebt.",
  "model": "google_nmt",
  "from_community_srt": "Und diese hier, obwohl die Linien gerade bleiben, ist auch keine lineare Transformation, da sich der Ursprungspunkt bewegt.",
  "n_reviews": 0,
  "start": 176.1,
  "end": 181.86
 },
 {
  "input": "This one here fixes the origin, and it might look like it keeps lines straight, but that's just because I'm only showing the horizontal and vertical grid lines.",
  "translatedText": "Dieses hier legt den Ursprung fest und es sieht vielleicht so aus, als ob die Linien gerade bleiben, aber das liegt nur daran, dass ich nur die horizontalen und vertikalen Gitterlinien zeige.",
  "model": "google_nmt",
  "from_community_srt": "Diese hier fixiert den Ursprungspunkt und mag so aussehen als krümme sie die Linien nicht. Das liegt aber nur daran, dass ich nur horizontale und vertikale Linien zeige.",
  "n_reviews": 0,
  "start": 182.68,
  "end": 189.24
 },
 {
  "input": "When you see what it does to a diagonal line, it becomes clear that it's not at all linear, since it turns that line all curvy.",
  "translatedText": "Wenn man sieht, was es mit einer diagonalen Linie macht, wird klar, dass sie überhaupt nicht linear ist, da die Linie dadurch völlig kurvig wird.",
  "model": "google_nmt",
  "from_community_srt": "Wenn du siehst was diese Transformation mit diagonalen Linien macht wird klar, dass sie nicht linear ist, da sie diese Linie komplett verbiegt.",
  "n_reviews": 0,
  "start": 189.54,
  "end": 195.32
 },
 {
  "input": "In general, you should think of linear transformations as keeping grid lines parallel and evenly spaced.",
  "translatedText": "Im Allgemeinen sollten Sie sich lineare Transformationen so vorstellen, dass die Gitterlinien parallel und gleichmäßig beabstandet bleiben.",
  "model": "google_nmt",
  "from_community_srt": "Allgemein belassen lineare Transformationen die Linien parallel und gleichmäßig verteilt.",
  "n_reviews": 0,
  "start": 196.76,
  "end": 202.24
 },
 {
  "input": "Some linear transformations are simple to think about, like rotations about the origin.",
  "translatedText": "Einige lineare Transformationen sind einfach zu bedenken, beispielsweise Drehungen um den Ursprung.",
  "model": "google_nmt",
  "from_community_srt": "Manche lineare Transformationen kann man sich leicht vorstellen, wie Rotationen um den Ursprungspunkt.",
  "n_reviews": 0,
  "start": 203.4,
  "end": 207.54
 },
 {
  "input": "Others are a little trickier to describe with words.",
  "translatedText": "Andere sind etwas schwieriger mit Worten zu beschreiben.",
  "model": "google_nmt",
  "from_community_srt": "Andere sind gar nicht so einfach mit Worten zu beschreiben.",
  "n_reviews": 0,
  "start": 208.12,
  "end": 210.6
 },
 {
  "input": "So, how do you think you could describe these transformations numerically?",
  "translatedText": "Wie könnten Sie diese Transformationen Ihrer Meinung nach numerisch beschreiben?",
  "model": "google_nmt",
  "from_community_srt": "Wie, glaubst du,",
  "n_reviews": 0,
  "start": 212.04,
  "end": 215.48
 },
 {
  "input": "If you were, say, programming some animations to make a video teaching the topic, what formula do you give the computer so that if you give it the coordinates of a vector, it can give you the coordinates of where that vector lands?",
  "translatedText": "Wenn Sie beispielsweise einige Animationen programmieren würden, um ein Video zu erstellen, das das Thema vermittelt, welche Formel geben Sie dem Computer vor, damit er, wenn Sie ihm die Koordinaten eines Vektors geben, die Koordinaten der Landung dieses Vektors erhalten kann?",
  "model": "google_nmt",
  "from_community_srt": "könnte man diese Transformationen numerisch beschreiben? Sagen wir zum Beispiel du programmierst ein paar Animationen für ein Lehrvideo über das Thema – welche Formeln gibst du dem Computer damit er, wenn du ihm die Koordinaten eines Vektors gibst, dir sagen kann auf welchen Koordinaten dieser Vektor landet?",
  "n_reviews": 0,
  "start": 215.48,
  "end": 227.24
 },
 {
  "input": "It turns out that you only need to record where the two basis vectors, i-hat and j-hat, each land, and everything else will follow from that.",
  "translatedText": "Es stellt sich heraus, dass Sie nur aufzeichnen müssen, wo die beiden Basisvektoren i-hat und j-hat jeweils landen, und alles andere ergibt sich daraus.",
  "model": "google_nmt",
  "from_community_srt": "Letztendlich musst du hierfür nur wissen wo die zwei Basisvektoren î und ĵ landen. Alles andere wird sich daraus ergeben.",
  "n_reviews": 0,
  "start": 228.48,
  "end": 236.6
 },
 {
  "input": "For example, consider the vector v with coordinates negative 1, 2, meaning that it equals negative 1 times i-hat plus 2 times j-hat.",
  "translatedText": "Betrachten Sie beispielsweise den Vektor v mit den Koordinaten negativ 1, 2, was bedeutet, dass er gleich negativ 1 mal i-hat plus 2 mal j-hat ist.",
  "model": "google_nmt",
  "from_community_srt": "Nimm als Beispiel den Vektor v mit den Koordinaten (–1, 2). Das bedeutet er ist gleich –1 · î + 2 · ĵ.",
  "n_reviews": 0,
  "start": 237.5,
  "end": 245.7
 },
 {
  "input": "If we play some transformation and follow where all three of these vectors go, the property that grid lines remain parallel and evenly spaced has a really important consequence.",
  "translatedText": "Wenn wir eine Transformation durchführen und verfolgen, wohin alle drei dieser Vektoren gehen, hat die Eigenschaft, dass die Gitterlinien parallel und gleichmäßig verteilt bleiben, eine wirklich wichtige Konsequenz.",
  "model": "google_nmt",
  "from_community_srt": "Wenn wir eine Transformation abspielen und allen Vektoren folgen, dann hat die Eigenschaft, dass Rasterlinien parallel und gleichmäßig verteilt bleiben,",
  "n_reviews": 0,
  "start": 248.68,
  "end": 258.3
 },
 {
  "input": "The place where v lands will be negative 1 times the vector where i-hat landed plus 2 times the vector where j-hat landed.",
  "translatedText": "Der Ort, an dem v landet, ist negativ 1-mal der Vektor, an dem i-hat gelandet ist, plus 2-mal der Vektor, an dem j-hat gelandet ist.",
  "model": "google_nmt",
  "from_community_srt": "eine wichtige Konsequenz: Der Ort an dem v landet ist -1 mal der Vektor auf dem î landet plus 2 mal der Vektor auf dem  ĵ landet.",
  "n_reviews": 0,
  "start": 259.1,
  "end": 265.4
 },
 {
  "input": "In other words, it started off as a certain linear combination of i-hat and j-hat, and it ends up as that same linear combination of where those two vectors landed.",
  "translatedText": "Mit anderen Worten, es begann als eine bestimmte lineare Kombination von i-hat und j-hat und endete als dieselbe lineare Kombination, in der diese beiden Vektoren landeten.",
  "model": "google_nmt",
  "from_community_srt": "Das heißt, die lineare Kombination von v ist gleich der linearen Kombination von î und ĵ.",
  "n_reviews": 0,
  "start": 265.98,
  "end": 274.58
 },
 {
  "input": "This means you can deduce where v must go based only on where i-hat and j-hat each land.",
  "translatedText": "Das bedeutet, dass Sie nur anhand der Landungen von i-hat und j-hat ableiten können, wohin v gehen muss.",
  "model": "google_nmt",
  "from_community_srt": "Das heißt wir können wissen wo v landet, nur durch unser Wissen wo î und ĵ landen.",
  "n_reviews": 0,
  "start": 275.62,
  "end": 280.92
 },
 {
  "input": "This is why I like keeping a copy of the original grid in the background.",
  "translatedText": "Aus diesem Grund behalte ich gerne eine Kopie des Originalrasters im Hintergrund.",
  "model": "google_nmt",
  "from_community_srt": "Das ist der Grund weswegen ich gerne eine Kopie des ursprünglichen Rasters im Hintergrund behalte.",
  "n_reviews": 0,
  "start": 281.58,
  "end": 284.54
 },
 {
  "input": "For the transformation shown here, we can read off that i-hat lands on the coordinates 1, negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0.",
  "translatedText": "Für die hier gezeigte Transformation können wir ablesen, dass i-hat auf den Koordinaten 1, minus 2 landet und j-hat auf der x-Achse drüben bei den Koordinaten 3, 0 landet.",
  "model": "google_nmt",
  "from_community_srt": "Für die hier gezeigte Transformation können wir ablesen, dass î auf den Koordinaten (1, –2) und ĵ auf der X-Achse auf den Koordinaten (3,",
  "n_reviews": 0,
  "start": 285.08,
  "end": 294.94
 },
 {
  "input": "This means that the vector represented by negative 1 i-hat plus 2 times j-hat ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0.",
  "translatedText": "Dies bedeutet, dass der durch minus 1 i-hat plus 2 mal j-hat dargestellte Vektor bei minus 1 mal dem Vektor 1, negativ 2 plus 2 mal dem Vektor 3, 0 endet.",
  "model": "google_nmt",
  "from_community_srt": "0) landet. Das heißt, dass der Vektor repräsentiert durch –1 · î + 2 · ĵ, landet bei –1 mal der Vektor (1, –2) plus 2 mal der Vektor (3,",
  "n_reviews": 0,
  "start": 295.54,
  "end": 306.14
 },
 {
  "input": "Adding that all together, you can deduce that it has to land on the vector 5, 2.",
  "translatedText": "Wenn man das alles zusammenzählt, kann man daraus schließen, dass es auf dem Vektor 5, 2 landen muss.",
  "model": "google_nmt",
  "from_community_srt": "0). Wenn wir das addieren, wissen wir, dass v auf dem Vektor (5,",
  "n_reviews": 0,
  "start": 307.1,
  "end": 311.68
 },
 {
  "input": "This is a good point to pause and ponder, because it's pretty important.",
  "translatedText": "Dies ist ein guter Punkt zum Innehalten und Nachdenken, denn es ist ziemlich wichtig.",
  "model": "google_nmt",
  "from_community_srt": "2) landet. Jetzt wäre ein guter Zeitpunkt um Kurz innezuhalten, denn das ist ziemlich wichtig.",
  "n_reviews": 0,
  "start": 314.26,
  "end": 317.24
 },
 {
  "input": "Now, given that I'm actually showing you the full transformation, you could have just looked to see that v has the coordinates 5, 2.",
  "translatedText": "Da ich Ihnen nun tatsächlich die vollständige Transformation zeige, hätten Sie einfach nachschauen können, ob v die Koordinaten 5, 2 hat.",
  "model": "google_nmt",
  "from_community_srt": "Da ich euch hier tatsächlich die komplette Transformation zeige, hättet ihr einfach schauen und direkt sehen können, dass v auf den Koordinaten (5,",
  "n_reviews": 0,
  "start": 318.52,
  "end": 325.28
 },
 {
  "input": "But the cool part here is that this gives us a technique to deduce where any vectors land so long as we have a record of where i-hat and j-hat each land without needing to watch the transformation itself.",
  "translatedText": "Aber das Coole daran ist, dass wir dadurch eine Technik erhalten, mit der wir ableiten können, wo irgendwelche Vektoren landen, solange wir eine Aufzeichnung darüber haben, wo i-hat und j-hat jeweils landen, ohne die Transformation selbst beobachten zu müssen.",
  "model": "google_nmt",
  "from_community_srt": "2) landet. Aber das coole an der Sache ist, dass wir mit dieser Technik wissen können wo irgendein beliebiger Vektor landet, solange wir nur wissen, wo î und ĵ landen, ohne die Transformation selbst sehen zu müssen.",
  "n_reviews": 0,
  "start": 325.76,
  "end": 337.38
 },
 {
  "input": "Write the vector with more general coordinates, x and y, and it will land on x times the vector where i-hat lands, 1, negative 2, plus y times the vector where j-hat lands, 3, 0.",
  "translatedText": "Schreiben Sie den Vektor mit den allgemeineren Koordinaten x und y, und er landet auf x-mal dem Vektor, auf dem i-hat landet, 1, negativ 2, plus y-mal dem Vektor, auf dem j-hat landet, 3, 0.",
  "model": "google_nmt",
  "from_community_srt": "Schreibt diesen Vektor mit den allgemeineren Koordinaten x und y und er landet auf x mal dem Vektor, auf dem î landet, plus y mal dem Vektor,",
  "n_reviews": 0,
  "start": 338.6,
  "end": 350.6
 },
 {
  "input": "Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y.",
  "translatedText": "Wenn Sie diese Summe berechnen, sehen Sie, dass sie bei 1x plus 3y, minus 2x plus 0y, landet.",
  "model": "google_nmt",
  "from_community_srt": "auf dem ĵ landet. Wenn wir diese Summe ausschreiben, sehen wir, dass der Vektor auf (1x + 3y, –2x + 0y) landet.",
  "n_reviews": 0,
  "start": 351.86,
  "end": 358.1
 },
 {
  "input": "I give you any vector, and you can tell me where that vector lands using this formula.",
  "translatedText": "Ich gebe Ihnen einen beliebigen Vektor und Sie können mir mithilfe dieser Formel sagen, wo dieser Vektor landet.",
  "model": "google_nmt",
  "from_community_srt": "Ich gebe euch irgendeinen Vektor und ihr könnt mir sagen wo er landen wird,",
  "n_reviews": 0,
  "start": 358.74,
  "end": 363.58
 },
 {
  "input": "What all of this is saying is that a two-dimensional linear transformation is completely described by just four numbers, the two coordinates for where i-hat lands and the two coordinates for where j-hat lands.",
  "translatedText": "Das alles bedeutet, dass eine zweidimensionale lineare Transformation vollständig durch nur vier Zahlen beschrieben wird, die beiden Koordinaten für die Landung von i-hat und die beiden Koordinaten für die Landung von j-hat.",
  "model": "google_nmt",
  "from_community_srt": "nur indem ihr diese Formel benutzt. Das alles sagt letztendlich aus, dass eine zweidimensionale lineare Transformation mit nur vier Zahlen vollständig beschrieben ist: die zwei Koordinaten für î und die zwei Koordinaten für ĵ.",
  "n_reviews": 0,
  "start": 364.86,
  "end": 376.5
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Ist das nicht cool?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 377.08,
  "end": 377.64
 },
 {
  "input": "It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix, where you can interpret the columns as the two special vectors where i-hat and j-hat each land.",
  "translatedText": "Es ist üblich, diese Koordinaten in ein 2x2-Zahlengitter, eine sogenannte 2x2-Matrix, zu packen, wobei Sie die Spalten als die beiden speziellen Vektoren interpretieren können, auf denen i-hat und j-hat jeweils landen.",
  "model": "google_nmt",
  "from_community_srt": "Ist das nicht cool? Allgemein schreibt man diese beiden Koordinaten in einem 2x2 Netz, genannt eine 2x2 Matrix, deren Spalten ihr interpretieren könnt als die besonderen Vektoren auf denen î und ĵ landen.",
  "n_reviews": 0,
  "start": 378.38,
  "end": 389.64
 },
 {
  "input": "If you're given a 2x2 matrix describing a linear transformation and some specific vector, and you want to know where that linear transformation takes that vector, you can take the coordinates of the vector, multiply them by the corresponding columns of the matrix, then add together what you get.",
  "translatedText": "Wenn Sie eine 2x2-Matrix erhalten, die eine lineare Transformation und einen bestimmten Vektor beschreibt, und Sie wissen möchten, wohin diese lineare Transformation diesen Vektor führt, können Sie die Koordinaten des Vektors nehmen und sie dann mit den entsprechenden Spalten der Matrix multiplizieren Addieren Sie, was Sie erhalten.",
  "model": "google_nmt",
  "from_community_srt": "Wenn dir eine 2x2 Matrix gegeben ist, die eine lineare Transformation beschreibt und irgendeinen bestimmten Vektor und du wissen willst, wo die lineare Transformation diesen Vektor hinschiebt, kannst du die Koordinaten des Vektors nehmen und sie mit den entsprechenden Spalten der Matrix multiplizieren und dann die Ergebnisse addieren.",
  "n_reviews": 0,
  "start": 390.38,
  "end": 407.34
 },
 {
  "input": "This corresponds with the idea of adding the scaled versions of our new basis vectors.",
  "translatedText": "Dies entspricht der Idee, die skalierten Versionen unserer neuen Basisvektoren hinzuzufügen.",
  "model": "google_nmt",
  "from_community_srt": "Das entspricht der Idee, die skalierten Basisvektoren zu addieren.",
  "n_reviews": 0,
  "start": 408.18,
  "end": 412.72
 },
 {
  "input": "Let's see what this looks like in the most general case, where your matrix has entries A, B, C, D.",
  "translatedText": "Sehen wir uns an, wie das im allgemeinsten Fall aussieht, wenn Ihre Matrix die Einträge A, B, C, D hat.",
  "model": "google_nmt",
  "from_community_srt": "Lasst uns das mal für den allgemeinsten Fall betrachten, wo die Matrix die Einträge a, b, c und d besitzt.",
  "n_reviews": 0,
  "start": 414.72,
  "end": 420.54
 },
 {
  "input": "And remember, this matrix is just a way of packaging the information needed to describe a linear transformation.",
  "translatedText": "Und denken Sie daran, dass diese Matrix lediglich eine Möglichkeit ist, die Informationen zu bündeln, die zur Beschreibung einer linearen Transformation erforderlich sind.",
  "model": "google_nmt",
  "from_community_srt": "Und vergiss nicht, diese Matrix ist nur ein Weg um die notwendigen Information einer linearen Transformation zu verpacken.",
  "n_reviews": 0,
  "start": 421.1,
  "end": 426.24
 },
 {
  "input": "Always remember to interpret that first column, AC, as the place where the first basis vector lands, and that second column, BD, as the place where the second basis vector lands.",
  "translatedText": "Denken Sie immer daran, die erste Spalte, AC, als den Ort zu interpretieren, an dem der erste Basisvektor landet, und die zweite Spalte, BD, als den Ort, an dem der zweite Basisvektor landet.",
  "model": "google_nmt",
  "from_community_srt": "Erinnere dich immer daran, die erste Spalte der Matrix (a,c) als Landeort für den ersten Basisvektor und die zweite Spalte, (b,d) als Landeort des zweiten Basisvektors,",
  "n_reviews": 0,
  "start": 426.24,
  "end": 436.44
 },
 {
  "input": "When we apply this transformation to some vector xy, what do you get?",
  "translatedText": "Was erhalten wir, wenn wir diese Transformation auf einen Vektor xy anwenden?",
  "model": "google_nmt",
  "from_community_srt": "zu interpretieren. Wenn wir diese Transformation auf eine Vektor (x,y) anwenden, was erhalten wir dann?",
  "n_reviews": 0,
  "start": 437.5,
  "end": 441.0
 },
 {
  "input": "Well, it'll be x times AC plus y times BD.",
  "translatedText": "Nun, es wird x mal AC plus y mal BD sein.",
  "model": "google_nmt",
  "from_community_srt": "Es kommt x*(a,c)+y*(b,d) heraus.",
  "n_reviews": 0,
  "start": 442.06,
  "end": 446.98
 },
 {
  "input": "Putting this together, you get a vector Ax plus By, Cx plus Dy.",
  "translatedText": "Wenn man dies zusammenfügt, erhält man einen Vektor Ax plus By, Cx plus Dy.",
  "model": "google_nmt",
  "from_community_srt": "Wenn man dies zusammenfasst, erhält man den Vektor (ax+by,",
  "n_reviews": 0,
  "start": 448.06,
  "end": 453.3
 },
 {
  "input": "You could even define this as matrix vector multiplication, when you put the matrix on the left of the vector like it's a function.",
  "translatedText": "Sie könnten dies sogar als Matrix-Vektor-Multiplikation definieren, wenn Sie die Matrix links vom Vektor platzieren, als wäre es eine Funktion.",
  "model": "google_nmt",
  "from_community_srt": "cx+dy) Man kann das auch als Matrix-Vektor-Multiplikation definieren, wenn man die Matrix links vom Vektor setzt, als wäre es eine Funktion.",
  "n_reviews": 0,
  "start": 453.98,
  "end": 460.94
 },
 {
  "input": "Then, you could make high schoolers memorize this without showing them the crucial part that makes it feel intuitive.",
  "translatedText": "Dann könnte man Gymnasiasten das auswendig lernen, ohne ihnen den entscheidenden Teil zu zeigen, der dafür sorgt, dass es sich intuitiv anfühlt.",
  "model": "google_nmt",
  "from_community_srt": "Dann kann man das Abiturienten zum Auswendiglernen geben, ohne ihnen den entscheidenden Teil zu zeigen, der es intuitiv erscheinen lässt.",
  "n_reviews": 0,
  "start": 461.66,
  "end": 466.62
 },
 {
  "input": "But, isn't it more fun to think about these columns as the transformed versions of your basis vectors, and to think about the result as the appropriate linear combination of those vectors?",
  "translatedText": "Aber macht es nicht mehr Spaß, sich diese Spalten als transformierte Versionen Ihrer Basisvektoren vorzustellen und sich das Ergebnis als die entsprechende Linearkombination dieser Vektoren vorzustellen?",
  "model": "google_nmt",
  "from_community_srt": "Ist es aber nicht interessanter, die Spalten als die transformierten Versionen der Basisvektoren anzusehen? Und das Ergebnis als die entsprechende",
  "n_reviews": 0,
  "start": 468.3,
  "end": 477.96
 },
 {
  "input": "Let's practice describing a few linear transformations with matrices.",
  "translatedText": "Üben wir die Beschreibung einiger linearer Transformationen mit Matrizen.",
  "model": "google_nmt",
  "from_community_srt": "lineare Kombination der Vektoren anzusehen? Lasst uns mal üben, wie man lineare Transformationen mit Matrizen beschreibt.",
  "n_reviews": 0,
  "start": 480.72,
  "end": 483.78
 },
 {
  "input": "For example, if we rotate all of space 90 degrees counterclockwise, then i-hat lands on the coordinates 0, 1.",
  "translatedText": "Wenn wir beispielsweise den gesamten Raum um 90 Grad gegen den Uhrzeigersinn drehen, landet i-hat auf den Koordinaten 0, 1.",
  "model": "google_nmt",
  "from_community_srt": "Zum Beispiel: Wenn wir den gesamten Raum um 90° gegen den Uhrzeigersinn drehen",
  "n_reviews": 0,
  "start": 484.58,
  "end": 492.24
 },
 {
  "input": "And j-hat lands on the coordinates negative 1, 0.",
  "translatedText": "Und j-hat landet auf den Koordinaten negativ 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "dann landet î auf den Koordinaten (0,1) und ĵ landet auf den Koordinaten (-1,0).",
  "n_reviews": 0,
  "start": 493.98,
  "end": 497.18
 },
 {
  "input": "So the matrix we end up with has columns 0, 1, negative 1, 0.",
  "translatedText": "Die Matrix, die wir erhalten, hat also die Spalten 0, 1, negativ 1, 0.",
  "model": "google_nmt",
  "from_community_srt": "Also ergibt sich die Matrix mit den Spalten (0,1) und (-1,0) Um herauszufinden,",
  "n_reviews": 0,
  "start": 497.98,
  "end": 501.96
 },
 {
  "input": "To figure out what happens to any vector after a 90-degree rotation, you could just multiply its coordinates by this matrix.",
  "translatedText": "Um herauszufinden, was mit einem Vektor nach einer 90-Grad-Drehung passiert, können Sie einfach seine Koordinaten mit dieser Matrix multiplizieren.",
  "model": "google_nmt",
  "from_community_srt": "was mit irgendeinem Vektor nach einer 90° Drehung passiert, kann man einfach die Koordinaten des Vektors mit der Matrix multiplizieren.",
  "n_reviews": 0,
  "start": 502.88,
  "end": 509.62
 },
 {
  "input": "Here's a fun transformation with a special name, called a shear.",
  "translatedText": "Hier ist eine lustige Transformation mit einem besonderen Namen, der Schere genannt wird.",
  "model": "google_nmt",
  "from_community_srt": "Hier ist mal eine lustige Transformation, die den besonderen Namen \"Schere\" trägt.",
  "n_reviews": 0,
  "start": 511.56,
  "end": 514.3
 },
 {
  "input": "In it, i-hat remains fixed, so the first column of the matrix is 1, 0.",
  "translatedText": "Darin bleibt i-hat fest, sodass die erste Spalte der Matrix 1, 0 ist.",
  "model": "google_nmt",
  "from_community_srt": "In dieser, bleibt î fixiert, so dass die erste Spalte der Matrix (1,0) ist.",
  "n_reviews": 0,
  "start": 515.0,
  "end": 519.16
 },
 {
  "input": "But j-hat moves over to the coordinates 1, 1, which become the second column of the matrix.",
  "translatedText": "Aber j-hat geht zu den Koordinaten 1, 1 über, die zur zweiten Spalte der Matrix werden.",
  "model": "google_nmt",
  "from_community_srt": "Aber ĵ landet bei den Koordinaten (1,1) was zur zweiten Spalte der Matrix wird.",
  "n_reviews": 0,
  "start": 519.6,
  "end": 525.3
 },
 {
  "input": "And at the risk of being redundant here, figuring out how a shear transforms a given vector comes down to multiplying this matrix by that vector.",
  "translatedText": "Und auf die Gefahr hin, hier überflüssig zu sein: Um herauszufinden, wie eine Scherung einen bestimmten Vektor transformiert, kommt es darauf an, diese Matrix mit diesem Vektor zu multiplizieren.",
  "model": "google_nmt",
  "from_community_srt": "Ohne etwas wichtiges weglassen zu wollen, um herauszufinden wie die \"Schere\" einen gegebenen Vektor transformiert muss man die Matrix mit dem gegebenen Vektor multiplizieren.",
  "n_reviews": 0,
  "start": 525.3,
  "end": 534.08
 },
 {
  "input": "Let's say we want to go the other way around, starting with a matrix, say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like.",
  "translatedText": "Nehmen wir an, wir möchten umgekehrt vorgehen, beginnend mit einer Matrix, beispielsweise mit den Spalten 1, 2 und 3, 1, und wir möchten ableiten, wie ihre Transformation aussieht.",
  "model": "google_nmt",
  "from_community_srt": "Sagen wir, wir wollen den umgekehrten Weg gehen. Sei die Matrix schon gegeben, mit den Spalten (1,2) und (3,1) und wir nun herausfinden wollen, wie dessen Transformation aussieht.",
  "n_reviews": 0,
  "start": 535.76,
  "end": 544.52
 },
 {
  "input": "Pause and take a moment to see if you can imagine it.",
  "translatedText": "Halten Sie inne und nehmen Sie sich einen Moment Zeit, um zu sehen, ob Sie es sich vorstellen können.",
  "model": "google_nmt",
  "from_community_srt": "Pausiere das Video und versuche dir vorzustellen wie sowas aussehen könnte.",
  "n_reviews": 0,
  "start": 544.96,
  "end": 547.44
 },
 {
  "input": "One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1.",
  "translatedText": "Eine Möglichkeit, dies zu tun, besteht darin, zuerst i-hat auf 1, 2 und dann j-hat auf 3, 1 zu verschieben.",
  "model": "google_nmt",
  "from_community_srt": "Ein möglicher Weg ist, î nach (1,2) zu verschieben und dann ĵ nach (3,1) zu verschieben.",
  "n_reviews": 0,
  "start": 548.42,
  "end": 555.1
 },
 {
  "input": "Always moving the rest of space in such a way that keeps gridlines parallel and evenly spaced.",
  "translatedText": "Verschieben Sie den Rest des Raums immer so, dass die Gitterlinien parallel und gleichmäßig verteilt bleiben.",
  "model": "google_nmt",
  "from_community_srt": "Dabei muss der restliche Raum so bewegt werden, so dass die Gitterlinien parallel und im gleichen Abstand bleiben.",
  "n_reviews": 0,
  "start": 555.1,
  "end": 560.22
 },
 {
  "input": "If the vectors that i-hat and j-hat land on are linearly dependent, which, if you recall from last video, means that one is a scaled version of the other, it means that the linear transformation squishes all of 2D space onto the line where those two vectors sit, also known as the one-dimensional span of those two linearly dependent vectors.",
  "translatedText": "Wenn die Vektoren, auf denen i-hat und j-hat landen, linear abhängig sind, was, wenn Sie sich an das letzte Video erinnern, bedeutet, dass einer eine skalierte Version des anderen ist, bedeutet dies, dass die lineare Transformation den gesamten 2D-Raum auf den Vektoren quetscht Linie, auf der diese beiden Vektoren liegen, auch als eindimensionale Spanne dieser beiden linear abhängigen Vektoren bekannt.",
  "model": "google_nmt",
  "from_community_srt": "Wenn die Vektoren wo î und ĵ landen linear abhängig sind was - wenn man sich an das letzte Video erinnert bedeutet - dass der eine, eine skalierte Version des anderen ist, wird durch die lineare Transformation, der gesamte 2-Dimensionale Raum auf die Gerade zerdrückt auf welcher die Vektoren liegen. Auch bekannt, als der eindimensionale Span der linear abhängigen Vektoren.",
  "n_reviews": 0,
  "start": 561.68,
  "end": 582.42
 },
 {
  "input": "To sum up, linear transformations are a way to move around space such that gridlines remain parallel and evenly spaced, and such that the origin remains fixed.",
  "translatedText": "Zusammenfassend lässt sich sagen, dass lineare Transformationen eine Möglichkeit sind, sich im Raum so zu bewegen, dass Gitterlinien parallel und gleichmäßig verteilt bleiben und der Ursprung fest bleibt.",
  "model": "google_nmt",
  "from_community_srt": "Um es zusammenzufassen: Lineare Transformationen sind eine Möglichkeit um den Raum zu bewegen, so dass die Gitterlinien parallel und den gleichen Abstand zu einander haben und dass der Ursprung fixiert bleibt.",
  "n_reviews": 0,
  "start": 584.42,
  "end": 593.94
 },
 {
  "input": "Delightfully, these transformations can be described using only a handful of numbers, the coordinates of where each basis vector lands.",
  "translatedText": "Erfreulicherweise können diese Transformationen mit nur einer Handvoll Zahlen beschrieben werden, den Koordinaten, an denen jeder Basisvektor landet.",
  "model": "google_nmt",
  "from_community_srt": "Wunderbarer Weise, können diese Transformationen mit nur einer Handvoll Zahlen beschrieben werden, und zwar mit den Koordinaten der transformierten Basisvektoren.",
  "n_reviews": 0,
  "start": 594.54,
  "end": 601.53
 },
 {
  "input": "Matrices give us a language to describe these transformations, where the columns represent those coordinates, and matrix-vector multiplication is just a way to compute what that transformation does to a given vector.",
  "translatedText": "Matrizen geben uns eine Sprache zur Beschreibung dieser Transformationen, wobei die Spalten diese Koordinaten darstellen und die Matrix-Vektor-Multiplikation nur eine Möglichkeit ist, zu berechnen, was diese Transformation mit einem bestimmten Vektor bewirkt.",
  "model": "google_nmt",
  "from_community_srt": "Matrizen geben uns eine \"Sprache\" diese Transformationen zu beschrieben, wobei die Spalten die Koordinaten der Basisvektoren darstellen. Und die Matrix-Vektor-Multiplikation ist nur eine Methode, um berechnen zu können, was die Transformation mit einen gegebenen Vektor macht.",
  "n_reviews": 0,
  "start": 602.76,
  "end": 614.66
 },
 {
  "input": "The important takeaway here is that every time you see a matrix, you can interpret it as a certain transformation of space.",
  "translatedText": "Die wichtige Erkenntnis hierbei ist, dass Sie jedes Mal, wenn Sie eine Matrix sehen, diese als eine bestimmte Transformation des Raums interpretieren können.",
  "model": "google_nmt",
  "from_community_srt": "Das wichtige zum mitnehmen ist, dass jedesmal wenn du eine Matrix siehst, du diese als eine Transformation des Raumes interpretieren kannst.",
  "n_reviews": 0,
  "start": 615.36,
  "end": 621.88
 },
 {
  "input": "Once you really digest this idea, you're in a great position to understand linear algebra deeply.",
  "translatedText": "Sobald Sie diese Idee wirklich verstanden haben, sind Sie in der Lage, die lineare Algebra gründlich zu verstehen.",
  "model": "google_nmt",
  "from_community_srt": "Sobald du dir diese Vorstellung verinnerlicht hast, hast du sehr gute Voraussetzungen um lineare Algebra tiefgründig zu verstehen.",
  "n_reviews": 0,
  "start": 622.58,
  "end": 627.32
 },
 {
  "input": "Almost all of the topics coming up, from matrix multiplication to determinants, change of basis, eigenvalues, all of these will become easier to understand once you start thinking about matrices as transformations of space.",
  "translatedText": "Fast alle anstehenden Themen, von der Matrizenmultiplikation bis hin zu Determinanten, Basiswechsel und Eigenwerten, werden leichter verständlich, wenn Sie beginnen, über Matrizen als Raumtransformationen nachzudenken.",
  "model": "google_nmt",
  "from_community_srt": "Fast alle der kommenden Themen von Matrixmultiplikation über Determinanten, Basiswechsel, bis hin zu Eigenwerten. All diese Themen werden einfacher zu verstehen sein, sobald du anfängst, Matrizen als Transformationen im Raum zu verstehen.",
  "n_reviews": 0,
  "start": 627.66,
  "end": 640.56
 },
 {
  "input": "Most immediately, in the next video, I'll be talking about multiplying two matrices together.",
  "translatedText": "Gleich im nächsten Video werde ich über die Multiplikation zweier Matrizen sprechen.",
  "model": "google_nmt",
  "from_community_srt": "Im nächsten Video, bespreche ich wie man zwei Matrizen miteinander multipliziert.",
  "n_reviews": 0,
  "start": 641.3,
  "end": 646.32
 }
]