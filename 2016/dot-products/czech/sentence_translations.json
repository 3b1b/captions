[
 {
  "input": "[\"Ode to Joy\", by Beethoven, plays to the end of the piano.] Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "",
  "model": "DeepL",
  "from_community_srt": "Skalární součiny se v lineární algebře běžně zavádí celkem brzo  typicky rovnou na začátku, tak může vypadat zvláštně, že jsou až takto daleko v této sérii.",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "Proto se může zdát divné, že jsem je v sérii posunul tak daleko.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "Udělal jsem to proto, že existuje standardní způsob, jak toto téma představit, který nevyžaduje nic víc než základní znalosti vektorů, ale plnější pochopení úlohy, kterou v matematice hrají bodové součinové součinů, lze skutečně nalézt pouze ve světle lineárních transformací.",
  "model": "DeepL",
  "from_community_srt": "Je tomu tak proto, že běžný způsob, jak toto téma uvést nevyžaduje hlubší porozumění vektorům, zatímco pro plné pochopení role skalárního součinu v matematice je třeba se na něj dívat ve světle lineárních transformací.",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "Ještě předtím mi však dovolte, abych se krátce zmínil o standardním způsobu zavedení bodových součinů, o kterém předpokládám, že je pro řadu diváků alespoň částečně přehledný.",
  "model": "DeepL",
  "from_community_srt": "Napřed mě ale nechte stručně uvést, běžný způsob, jak se zavádí skalární součin, a předpokládám, že to bude pro část posluchačů opakování.",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "Pokud máme dva vektory stejného rozměru, dva seznamy čísel se stejnou délkou, jejich bodový součin znamená, že všechny souřadnice spárujeme, tyto dvojice vynásobíme a výsledek sečteme.",
  "model": "DeepL",
  "from_community_srt": "Numericky, když máte dva vektory stejné dimenze; dva seznamy čísel stejné délky, tak jejich skalární součin znamená, že popárujete odpovídající souřadnice v každém páru čísla vynásobíte a výsledky sečtete.",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "Takže vektor 1, 2 s tečkou 3, 4 by byl 1 krát 3 plus 2 krát 4.",
  "model": "DeepL",
  "from_community_srt": "Takže vektor (1, 2) krát (3, 4) vyjde 1*3 + 2*4.",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "Vektor 6, 2, 8, 3 s tečkami 1, 8, 5, 3 by byl 6 krát 1 plus 2 krát 8 plus 8 krát 5 plus 3 krát 3.",
  "model": "DeepL",
  "from_community_srt": "Vektor (6, 2, 8, 3) krát (1, 8, 5, 3) vyjde 6*1 + 2*8 + 8*5 + 3*3.",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "Naštěstí má tento výpočet opravdu pěknou geometrickou interpretaci.",
  "model": "DeepL",
  "from_community_srt": "Naštěstí má tento výpočet geometrický význam.",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "Chcete-li uvažovat o tečkovém součinu dvou vektorů v a w, představte si, že promítnete w na přímku, která prochází počátkem a vrcholem v.",
  "model": "DeepL",
  "from_community_srt": "Abychom našli skalární součin vektorů 'v', 'w', představíme si 'w' promítnutý na přímku, která prochází počátkem a špičkou 'v'.",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "Vynásobením délky tohoto průmětu délkou v získáme tečkový součin v tečka w.",
  "model": "DeepL",
  "from_community_srt": "Vynásobíme délku této projekce délkou 'v' a získáme skalární součin 'v' krát 'w'.",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "Až na to, že pokud tato projekce w směřuje opačným směrem než v, bude tento bodový součin ve skutečnosti záporný.",
  "model": "DeepL",
  "from_community_srt": "Až na to, že když tato projekce 'w' míří opačným směrem než 'v', bude skalární součin záporný.",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "Pokud tedy dva vektory směřují obecně stejným směrem, je jejich tečkový součin kladný.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "Pokud jsou kolmé, což znamená, že průmětem jednoho z nich do druhého je nulový vektor, je jejich tečkový součin roven nule.",
  "model": "DeepL",
  "from_community_srt": "Takže dva vektory, které míří spíše stejným směrem, mají kladný skalární součin, když jsou kolmé, neboli projekce jednoho na druhý je nulový vektor, tak je skalární součin nula, a když svírají tupý úhel, jejich skalární součin je záporný.",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "A pokud směřují obecně opačným směrem, je jejich bodový součin záporný.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "Tento výklad je podivně asymetrický.",
  "model": "DeepL",
  "from_community_srt": "Tahle interpretace je podivně asymetrická.",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "K oběma vektorům přistupuje velmi odlišně.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "Když jsem se to dozvěděl poprvé, překvapilo mě, že na pořadí nezáleží.",
  "model": "DeepL",
  "from_community_srt": "Zachází s jednotlivými vektory odlišně, takže když jsem se s tím poprvé setkal, překvapilo mě, že na pořadí nezáleží.",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "Místo toho můžete promítnout v na w, vynásobit délku promítnutého v délkou w a získat stejný výsledek.",
  "model": "DeepL",
  "from_community_srt": "Co místo toho bychom mohli promítnout 'v' na 'w'; vynásobit délky promítnutého 'v' se skutečnou délkou 'w'; a získat stejný výsledek.",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "Nepřipadá vám to jako úplně jiný proces?",
  "model": "DeepL",
  "from_community_srt": "To přece vypadá jako dost jiný výpočet.",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "Zde je intuice, proč na pořadí nezáleží.",
  "model": "DeepL",
  "from_community_srt": "Tak napřed ukážu, proč by nemělo záležet na pořadí.",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "Pokud by v a w měly stejnou délku, mohli bychom využít symetrie.",
  "model": "DeepL",
  "from_community_srt": "V případě, že jsou 'v' a 'w' stejně dlouhé, můžeme využít symetrie.",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "Protože promítnutí w do v a následné vynásobení délky tohoto promítnutí délkou v je úplným zrcadlovým obrazem promítnutí v do w a následného vynásobení délky tohoto promítnutí délkou w.",
  "model": "DeepL",
  "from_community_srt": "Protože, když promítneme 'w' na 'v' a vynásobíme tuhle projekci a délkou 'v' je to zcela symetrické jako kdybychom promítli 'v' na 'w' a vynásobili délku této projekce délkou vektoru 'w'.",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "Pokud jednu z nich, řekněme v, zvětšíte o nějakou konstantu, například 2, takže nebudou mít stejnou délku, symetrie se naruší.",
  "model": "DeepL",
  "from_community_srt": "Když teď jeden z vektorů, třeba v,  vyškálujete nějakou konstantou, třeba 2, tak už můžou mít různé délky a symetrie se rozbije.",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "Promysleme si však, jak interpretovat tečkový součin mezi tímto novým vektorem, 2 krát v, a w.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "Pokud si představíte, že se w promítá na v, pak bodový součin 2v dot w bude přesně dvojnásobkem bodového součinu v dot w.",
  "model": "DeepL",
  "from_community_srt": "Ale můžeme se na součin mezi novým vektorem '2v' a 'w' dívat takto:  Když promítneme 'w' na 'v', tak skalární součin 2v*w vyjde přesně jako dvojnásobek součinu v*w.",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "Je to proto, že když měříte v o 2, nezmění se délka projekce w, ale zdvojnásobí se délka vektoru, do kterého se promítá.",
  "model": "DeepL",
  "from_community_srt": "To proto, že jak jsme 'v' vyškálovali dvakrát, nezměnila se délka promítnutého 'w', ale zdvojnásobila se délka vektoru, na který jsme promítali.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "Ale na druhou stranu, řekněme, že jste uvažovali o tom, že se v promítne do w.",
  "model": "DeepL",
  "from_community_srt": "Co kdybychom na druhou stranu promítli 'v' na 'w'?",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "V tomto případě se délka projekce zmenší, když v vynásobíme 2, ale délka vektoru, na který promítáme, zůstává konstantní.",
  "model": "DeepL",
  "from_community_srt": "V tomto případě se škáluje délka projekce, jak násobíme 'v' dvěma.",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "Celkový efekt je tedy stále jen zdvojnásobení bodového součinu.",
  "model": "DeepL",
  "from_community_srt": "Délka vektoru, na který promítáme, zůstává stejná, takže se výsledný skalární součin zase zdvojnásobí.",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "Přestože je tedy v tomto případě symetrie porušena, vliv tohoto škálování na hodnotu bodového součinu je při obou interpretacích stejný.",
  "model": "DeepL",
  "from_community_srt": "Takže i když se symetrie už rozbije, tak škálování jednoho vektoru má na skalární součin stejný vliv v obou interpretacích.",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "Je tu ještě jedna velká otázka, která mě zmátla, když jsem se o tom učil poprvé.",
  "model": "DeepL",
  "from_community_srt": "Když jsem se o tom učil, ještě jedna věc mě mátla.",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "Proč má tento numerický proces porovnávání souřadnic, násobení dvojic a jejich sčítání proboha něco společného s promítáním?",
  "model": "DeepL",
  "from_community_srt": "Co má u všech všudy tenhle numerický proces párování souřadnic, násobení v párech a následné sečtení, společného s projekcemi?",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "Abychom mohli uspokojivě odpovědět a také plně pochopit význam bodového součinu, musíme odhalit něco trochu hlubšího, co se zde děje a co se často nazývá dualita.",
  "model": "DeepL",
  "from_community_srt": "Abychom dali uspokojivou odpověď, a současně abychom obhájili důležitost skalárního součinu, musíme něco odkrýt a jít trochu hlouběji k čemusi obvykle zvaného \"dualita\".",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "Než se k tomu ale dostaneme, musím se chvíli věnovat lineárním transformacím z více rozměrů do jednoho rozměru, kterým je právě číselná přímka.",
  "model": "DeepL",
  "from_community_srt": "Než se do toho pustíme, musíme se na chvíli podívat na lineární zobrazení vedoucí z vícerozměrného prostoru do jednorozměrného, tedy do číselné osy.",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "Jedná se o funkce, které přijmou 2D vektor a vyplivnou nějaké číslo, ale lineární transformace jsou samozřejmě mnohem omezenější než běžné funkce s 2D vstupem a 1D výstupem.",
  "model": "DeepL",
  "from_community_srt": "To jsou funkce, které berou 2D vektor a vyplivnou nějaké číslo. Ale lineární zobrazení samozřejmě musí splňovat něco víc než obecná funkce s 2D vstupem a 1D výstupem.",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "Stejně jako u transformací ve vyšších dimenzích, o kterých jsem mluvil v kapitole 3, existují určité formální vlastnosti, které činí tyto funkce lineárními, ale ty zde budu záměrně ignorovat, abych neodváděl pozornost od našeho konečného cíle, a místo toho se zaměřím na určitou vizuální vlastnost, která je ekvivalentní všem formálním věcem.",
  "model": "DeepL",
  "from_community_srt": "Stejně jako s transformacemi ve vyšších dimenzích, o kterých jsme mluvili v kapitole 3, máme pro lineární zobrazení jisté formální požadavky. Ale zatím je budu schválně ignorovat, abychom se zbytečně nerozptylovali, a jenom ukážu, jak si tuhle formální definici vizuálně představovat.",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "Pokud vezmete řadu rovnoměrně rozmístěných bodů a použijete transformaci, lineární transformace zachová tyto body rovnoměrně rozmístěné, jakmile se dostanou do výstupního prostoru, kterým je číselná řada.",
  "model": "DeepL",
  "from_community_srt": "Když si vezmete přímku bodů s rovnoměrnými rozestupy, tak po lineární transformaci musí stále udržovat rovnoměrné rozestupy jak přistanou na číselné ose.",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "V opačném případě, pokud je nějaká řada bodů nerovnoměrně rozmístěna, není transformace lineární.",
  "model": "DeepL",
  "from_community_srt": "Kdyby body na výsledné přímce neměly rovnoměrné rozestupy, zobrazení by nebylo lineární.",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "Stejně jako v předchozích případech je jedna z těchto lineárních transformací zcela určena tím, kde se nachází i-hat a j-hat, ale tentokrát každý z těchto bázových vektorů prostě dopadá na číslo, takže když zaznamenáme, kde dopadají jako sloupce matice, každý z těchto sloupců má jen jedno číslo.",
  "model": "DeepL",
  "from_community_srt": "A stejně jako lineární zobrazení, která už známe, i takovéto je jednoznačně určeno výslednou polohou 'i' a 'j', akorát se v tomto případě jedná o samotná čísla. Když tedy zaznamenáváme zobrazení do matice, každý sloupeček je jen jednoprvkový.",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "Jedná se o matici 1x2.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "Ukážeme si na příkladu, co znamená použít jednu z těchto transformací na vektor.",
  "model": "DeepL",
  "from_community_srt": "Projděme si pár příkladů, jak to vypadá, když proženeme vektor takovým zobrazením.",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "Řekněme, že máte lineární transformaci, která přenese i-hat na hodnotu 1 a j-hat na zápornou hodnotu 2.",
  "model": "DeepL",
  "from_community_srt": "Dejme tomu, že máme lineární zobrazení, které posílá 'i' na 1 a 'j' na -2.",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "Chcete-li sledovat, kde skončí vektor se souřadnicemi například 4, 3, představte si, že tento vektor rozdělíte jako 4 krát i-hat plus 3 krát j-hat.",
  "model": "DeepL",
  "from_community_srt": "Když chceme zjistit, kde skončí vektor se souřadnicemi (4, 3), rozepíšeme jej jako 4i+3j.",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "Důsledkem linearity je, že po transformaci bude mít vektor 4násobek místa, kde dopadne i-čepice, tedy 1, plus 3násobek místa, kde dopadne j-čepice, tedy záporné 2, což v tomto případě znamená, že dopadne na záporné 2.",
  "model": "DeepL",
  "from_community_srt": "A díky linearitě přistane na 4 krát to, kam dopadlo 'i', to jest 1 plus 3 krát to, kam dopadlo 'j', to jest -2, což se v tomhle případě sečte na -2.",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "Pokud tento výpočet provedete čistě numericky, jedná se o maticové násobení vektorů.",
  "model": "DeepL",
  "from_community_srt": "Když takový výpočet provedete čistě numericky, je to součin matice a vektoru.",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "Tato numerická operace násobení matice 1x2 vektorem se nyní podobá tečkovému součinu dvou vektorů.",
  "model": "DeepL",
  "from_community_srt": "Současně ale tento numerický výpočet součinu matice 1 x 2 s vektorem vypadá jako numerický skalární součin dvou vektorů.",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "Nevypadá ta matice 1x2 jako vektor, který jsme převrátili na bok?",
  "model": "DeepL",
  "from_community_srt": "Není matice 1 x 2 vlastně jen vektor naležato?",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "Ve skutečnosti bychom mohli hned teď říci, že existuje pěkná asociace mezi maticemi 1x2 a 2D vektory, definovaná nakloněním číselné reprezentace vektoru na jeho stranu, abychom získali přidruženou matici, nebo nakloněním matice zpět nahoru, abychom získali přidružený vektor.",
  "model": "DeepL",
  "from_community_srt": "Měli bychom si rovnou říct, že tu máme pěknou korespondenci mezi maticemi 1 x 2 a 2D vektory, definovanou tak, že příslušný vektor jenom přepíšeme ze sloupce na řádek a dostaneme tím matici  nebo naopak matici přepíšeme do sloupce a dostaneme původní vektor.",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "Vzhledem k tomu, že se nyní zabýváme pouze číselnými výrazy, může se nám zdát, že přecházet mezi vektory a maticemi 1x2 je hloupost.",
  "model": "DeepL",
  "from_community_srt": "Jak se teď díváme jenom na numerické výrazy, může takové přecházení tam a zpátky vypadat malicherně.",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "To však naznačuje něco, co je z geometrického hlediska opravdu úžasné.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "Mezi lineárními transformacemi, které převádějí vektory na čísla, a vektory samotnými existuje určitá souvislost.",
  "model": "DeepL",
  "from_community_srt": "Ale naznačuje to, že z geometrického pohledu máme něco překvapivého, je tu jakási korespondence mezi lineárními zobrazeními, které z vektoru udělají číslo, a samotnými vektory.",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "Dovolte mi ukázat příklad, který objasňuje význam a který shodou okolností odpovídá i na hádanku o bodovém součinu z dřívějška.",
  "model": "DeepL",
  "from_community_srt": "Ukažme si příklad, který objasní, jak je to podstatné a který taky odpoví na záhadu skalárního součinu z dřívějška.",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "Odnaučte se, co jste se naučili, a představte si, že ještě nevíte, že bodový součin souvisí s promítáním.",
  "model": "DeepL",
  "from_community_srt": "Zapomeňte, co jste se naučili a představte si, že ještě nevíte, jak skalární součin souvisí s projekcemi.",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "Udělám to tak, že vezmu kopii číselné přímky a umístím ji nějak šikmo do prostoru, přičemž číslo 0 bude v počátku.",
  "model": "DeepL",
  "from_community_srt": "Vezmu si teď kopii číselně osy a umístím ji šikmo do prostoru tak, aby bod 0 ležel v počátku.",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "Nyní si představte dvourozměrný jednotkový vektor, jehož vrchol se nachází v místě, kde je na čísle 1.",
  "model": "DeepL",
  "from_community_srt": "Teď si vezměme dvourozměrný vektor jednotkové délky, jehož špička leží v bodě 1 na této šikmé ose.",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "Chtěl bych tomu chlápkovi dát jméno, u-hat.",
  "model": "DeepL",
  "from_community_srt": "Pojmenujeme ten vektor 'u'.",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "Tenhle človíček hraje důležitou roli v tom, co se bude dít, takže ho mějte na paměti.",
  "model": "DeepL",
  "from_community_srt": "Tenhle vektor bude představovat důležitou roli v tom, co bude následovat, tak si ho zapamatujte.",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "Promítneme-li 2d vektory přímo na tuto diagonální číselnou přímku, v podstatě jsme právě definovali funkci, která přenáší 2d vektory na čísla.",
  "model": "DeepL",
  "from_community_srt": "Když promítneme všechny vektory kolmo na tuhle šikmou osu, definujeme tím funkci, která 2D vektoru přiřadí číslo.",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "Navíc je tato funkce skutečně lineární, protože projde naším vizuálním testem, podle kterého zůstane jakákoli řada rovnoměrně rozmístěných bodů rovnoměrně rozmístěná, jakmile se ocitne na číselné řadě.",
  "model": "DeepL",
  "from_community_srt": "Ba co víc, tahle funkce je lineární, protože projde naší vizuální zkouškou, že každá přímka bodů s rovnoměrnými rozestupy bude mít i po zobrazení rovnoměrné rozestupy.",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "Aby bylo jasno, i když jsem takto vložil číselnou řadu do 2d prostoru, výstupy funkce jsou čísla, nikoli 2d vektory.",
  "model": "DeepL",
  "from_community_srt": "Aby bylo jasno, i když takto zobrazujeme číselnou osu ve 2D, jsou výstupy z naší funkce čísla, nikoli 2D vektory.",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "Měli byste si představit funkci, která přijme dvě souřadnice a vypíše jednu souřadnici.",
  "model": "DeepL",
  "from_community_srt": "Měli byste si představovat funkci, která sebere dvě souřadnice a vyhodí jednu.",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "Vektor u-hat je však dvourozměrný vektor, který se nachází ve vstupním prostoru.",
  "model": "DeepL",
  "from_community_srt": "Vektor 'u' je ale dvourozměrný vektor žijící v rovině.",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "Jen je umístěn tak, že se překrývá s vložením číselné řady.",
  "model": "DeepL",
  "from_community_srt": "Je jen umístěný tak, že se překrývá s číselnou osou.",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "Pomocí této projekce jsme právě definovali lineární transformaci z 2d vektorů na čísla, takže budeme schopni najít nějakou matici 1x2, která tuto transformaci popisuje.",
  "model": "DeepL",
  "from_community_srt": "Touhle projekcí jsme definovali lineární zobrazení z roviny do čísel, takže můžeme najít odpovídající matici matici 1 x 2.",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "Abychom zjistili matici 1x2, přiblížíme si tuto diagonální číselnou řadu a zamyslíme se nad tím, kde přistane i-hat a j-hat, protože tato místa přistání budou sloupci matice.",
  "model": "DeepL",
  "from_community_srt": "Abychom ji našli, podíváme se na tuhle šikmou číselnou osu zblízka, a zamyslíme se, kam půjde 'i' a 'j', to budou sloupce výsledné matice.",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "Tahle část je super.",
  "model": "DeepL",
  "from_community_srt": "Tahle část je nejlepší.",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "Můžeme to zdůvodnit opravdu elegantní symetrií.",
  "model": "DeepL",
  "from_community_srt": "Můžeme totiž matici najít pomocí trošky elegantní symetrie.",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "Protože i-hat a u-hat jsou oba jednotkové vektory, promítnutí i-hat na přímku procházející u-hat vypadá zcela symetricky k promítnutí u-hat na osu x.",
  "model": "DeepL",
  "from_community_srt": "Vektory 'i' a 'u' jsou oba jednotkové, takže když promítneme 'i' na přímku procházející skrz 'u', dopadne to symetricky k tomu, kdybychom promítli 'u' na osu 'x'.",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "Když se tedy zeptáme, na jakém čísle přistane i-klobouk, když se promítne, odpověď bude stejná jako u-klobouk, když se promítne na osu x.",
  "model": "DeepL",
  "from_community_srt": "Takže když nás zajímá, na jaké číslo se při projekci dostane 'i', stačí nám spočítat, kam přijde 'u', když jej promítneme na osu 'x'.",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "Promítnutí u-hat na osu x však znamená pouze vzít x-ovou souřadnici u-hat.",
  "model": "DeepL",
  "from_community_srt": "Projekce na osu 'x' ale jenom znamená, že si vezmeme x-ovou souřadnici 'u'.",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "Takže podle symetrie bude číslo, na které se i-čepice promítne na diagonální číselnou přímku, x-ová souřadnice u-čepice.",
  "model": "DeepL",
  "from_community_srt": "Takže ze symetrie, to číslo, kam se zobrazí 'i', když jej promítneme na šikmou číselnou osu, bude x-ová souřadnice vektoru 'u'.",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Není to skvělé?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "Argumentace je téměř totožná pro případ j-hat.",
  "model": "DeepL",
  "from_community_srt": "Stejným způsobem to zdůvodníme i pro druhou souřadnici 'j'.",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "Chvíli o tom přemýšlejte.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "Ze stejných důvodů nám y-ová souřadnice u-čepice udává číslo, kam se j-čepice promítne na kopii číselné přímky.",
  "model": "DeepL",
  "from_community_srt": "Přesně z toho samého důvodu, y-ová souřadnice 'u' určuje číslo, kam dopadne 'j', když jej promítneme na kopii číselné osy.",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "Na chvíli se zastavte a zamyslete se nad tím.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "Myslím, že je to opravdu skvělé.",
  "model": "DeepL",
  "from_community_srt": "Na chvilku si zastavte video a zamyslete se, tohle je vážně ohromné.",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "Takže položky matice 1x2 popisující projekční transformaci budou souřadnice u-čepice.",
  "model": "DeepL",
  "from_community_srt": "Takže položky matice 1x2 popisující projekci jsou přesně souřadnice vektoru 'u'.",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "A výpočet této projekční transformace pro libovolné vektory v prostoru, který vyžaduje vynásobení této matice těmito vektory, je výpočetně totožný s tečkovým součinem s u-hat.",
  "model": "DeepL",
  "from_community_srt": "A příslušnou projekci pro obecný vektor v rovině spočítáme tak, že vynásobíme tuhle matici daným vektorem, což numericky znamená skalární součin s vektorem 'u'.",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "Proto lze tečkový součin s jednotkovým vektorem interpretovat jako promítnutí vektoru do rozpětí tohoto jednotkového vektoru a odečtení jeho délky.",
  "model": "DeepL",
  "from_community_srt": "To je důvod, proč můžeme skalární součin s jednotkovým vektorem interpretovat jako projekci vektoru na lineární obal toho jednotkového vektoru a změření délky.",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "Jak je to tedy s nejednotkovými vektory?",
  "model": "DeepL",
  "from_community_srt": "A co teď s vektory, které nemají jednotkovou délku?",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "Řekněme například, že vezmeme jednotkový vektor u-hat, ale zvětšíme ho o trojnásobek.",
  "model": "DeepL",
  "from_community_srt": "Pro příklad si vezmeme jednotkový vektor 'u', ale vyškálujeme jej koeficientem 3.",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "Číselně se každá jeho složka vynásobí třemi.",
  "model": "DeepL",
  "from_community_srt": "To numericky znamená, že každou složku vynásobíme třemi.",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "Když se podíváme na matici spojenou s tímto vektorem, zjistíme, že i-hat a j-hat nabývají třikrát vyšších hodnot než předtím.",
  "model": "DeepL",
  "from_community_srt": "Takže položená matice odpovídající tomuto vektoru zobrazí vektory 'i' a 'j' třikrát dál než před tím.",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "Protože je to všechno lineární, znamená to obecněji, že novou matici lze interpretovat jako promítnutí libovolného vektoru na kopii číselné přímky a vynásobení místa, kam dopadne, číslem 3.",
  "model": "DeepL",
  "from_community_srt": "A protože je zobrazení lineární, tak obecněji dostáváme, že se každý vektor promítne na šikmou číselnou osu  a vynásobí se třemi.",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "Proto lze tečkový součin s nejednotkovým vektorem interpretovat tak, že se nejprve promítne do tohoto vektoru a poté se délka tohoto promítnutí zvětší o délku vektoru.",
  "model": "DeepL",
  "from_community_srt": "To je důvod, proč můžeme skalární součin s obecným vektorem 'v' interpretovat jako projekci na vektor 'v' a následné vynásobení délkou vektoru 'v'.",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "Chvíli přemýšlejte o tom, co se zde stalo.",
  "model": "DeepL",
  "from_community_srt": "Zamyslete se na chvíli, co se stalo.",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "Měli jsme lineární transformaci z 2D prostoru na číselnou přímku, která nebyla definována v termínech číselných vektorů nebo číselných bodových součinů, ale byla definována pouze promítnutím prostoru na diagonální kopii číselné přímky.",
  "model": "DeepL",
  "from_community_srt": "Měli jsme lineární zobrazení z roviny na číselnou osu, kterou jsme ale nedefinovali jazykem numerického skalárního součinu. Popsali jsme to jako promítání roviny na šikmou číselnou osu.",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "Protože je však transformace lineární, byla nutně popsána nějakou maticí 1x2.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "A protože násobení matice 1x2 2D vektorem je totéž jako otočení této matice na bok a provedení tečkového součinu, byla tato transformace nevyhnutelně spojena s nějakým 2D vektorem.",
  "model": "DeepL",
  "from_community_srt": "Protože je však toto zobrazení lineární, je popsáno nějakou maticí 1 x 2 a protože násobení maticí 1 x 2 vektorem je to samé jako počítání skalárního součinu, bude tohle zobrazení odpovídat nějakému vektoru.",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "Z toho plyne ponaučení, že kdykoli máte jednu z těchto lineárních transformací, jejímž výstupním prostorem je číselná přímka, bez ohledu na to, jak byla definována, bude existovat nějaký jedinečný vektor v odpovídající této transformaci v tom smyslu, že použití transformace je totéž, jako když s tímto vektorem provedete tečkový součin.",
  "model": "DeepL",
  "from_community_srt": "Ponaučení: kdykoli máte nějaké takové lineární zobrazení, jehož výstup je číselná osa, bez ohledu na to, jak jste ho definovali, vždycky najdete jednoznačný vektor 'v', který mu odpovídá v tom smyslu, že se dané zobrazení chová jako skalární součin s vektorem 'v'.",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "Pro mě je to naprosto nádherné.",
  "model": "DeepL",
  "from_community_srt": "Mě to připadá naprosto nádherné.",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "Je to příklad něčeho, čemu se v matematice říká dualita.",
  "model": "DeepL",
  "from_community_srt": "Je to příklad něčeho, čemu se v matematice říká \"dualita\".",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "Dualita se v matematice projevuje mnoha různými způsoby a formami a je velmi složité ji definovat.",
  "model": "DeepL",
  "from_community_srt": "\"Dualita\" se vyskytuje ve všemožných formách napříč matematikou, a obecně ji není snadné definovat.",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "Volně řečeno se týká situací, kdy existuje přirozená, ale překvapivá shoda mezi dvěma typy matematických věcí.",
  "model": "DeepL",
  "from_community_srt": "Vágně řečeno dualitou myslíme případy přirozené, ale přesto překvapivé korespondence mezi dvěma typy matematických objektů.",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "V případě lineární algebry, o které jste se právě učili, byste řekli, že duál vektoru je lineární transformace, kterou kóduje, a duál lineární transformace z nějakého prostoru do jedné dimenze je určitý vektor v tomto prostoru.",
  "model": "DeepL",
  "from_community_srt": "V případě lineární algebry, který jsme se právě naučili, můžeme říct, že duál vektoru je to lineární zobrazení, které odpovídá skalárnímu součinu s ním. A duál lineárního zobrazení do číselné osy je opět ten původní vektor v prostoru.",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "Na první pohled je tedy bodový součin velmi užitečným geometrickým nástrojem pro pochopení promítání a pro testování, zda vektory mají tendenci směřovat stejným směrem.",
  "model": "DeepL",
  "from_community_srt": "Abychom si to shrnuli, skalární součin je velmi užitečný geometrický nástroj pro uchopení projekcí a pro ověřování, zda dva vektory míří stejným směrem nebo ne.",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "A to je pravděpodobně to nejdůležitější, co byste si měli o tečkovém součinu zapamatovat.",
  "model": "DeepL",
  "from_community_srt": "A to je pravděpodobně to nejdůležitější, co si můžete ze skalárního součinu odnést.",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "Na hlubší úrovni je však spojení dvou vektorů tečkou způsob, jak jeden z nich převést do světa transformací.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "Z číselného hlediska se může zdát, že je to hloupé zdůrazňovat.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "Jsou to jen dva výpočty, které náhodou vypadají podobně.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "Důvod, proč to považuji za tak důležité, je ten, že v matematice, když se zabýváte vektorem, jakmile skutečně poznáte jeho osobnost, někdy si uvědomíte, že je snazší chápat ho ne jako šipku v prostoru, ale jako fyzické ztělesnění lineární transformace.",
  "model": "DeepL",
  "from_community_srt": "Ale podtrhuji to proto, že když někde v matice narazíte na vektor, a chcete poznat jeho osobnost, někdy může být jednodušší jej vnímat nikoli jako šipku v prostoru, ale jako fyzické ztělesnění lineárního zobrazení.",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "Jako by vektor byl ve skutečnosti jen pojmovou zkratkou pro určitou transformaci, protože je pro nás jednodušší přemýšlet o šipkách v prostoru, než přesouvat celý tento prostor na číselnou přímku.",
  "model": "DeepL",
  "from_community_srt": "Jako by byl vektor jenom zkratka pro jisté zobrazení, protože se snáze představují šipky v prostoru než splácnutí celého prostoru na číselnou osu.",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.97
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "V příštím videu uvidíte další skvělý příklad této duality v akci, když budu mluvit o křížovém součinu.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 822.61,
  "end": 829.19
 }
]