[
 {
  "input": "Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "[„Oda do radości” Beethovena gra do końca fortepianu.] Tradycyjnie iloczyny kropkowe są czymś, co wprowadza się bardzo wcześnie w kursie algebry liniowej, zazwyczaj zaraz na początku.",
  "model": "google_nmt",
  "from_community_srt": "Calvin: Wiesz co, moim zdaniem matematyka nie jest nauką. Myślę, że to religia. Hobbes: Religia? Calvin: Tak. Wszystkie te równania są jak cuda. Bierzesz dwie liczby i kiedy je dodasz, nagle magicznie stają się jedną, NOWĄ liczbą! Nikt nie wie, jak to się dzieje. Albo w to wierzysz, albo nie. Zazwyczaj iloczyny skalarne wprowadzane są bardzo wcześnie w kursach Algebry Liniowej zwykle na samym początku.",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "Może więc wydawać się dziwne, że odsunąłem je tak daleko w serii.",
  "model": "google_nmt",
  "from_community_srt": "Więc może wydawać się dziwne, że odłożyłem je tak daleko w tej serii.",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "Zrobiłem to, ponieważ istnieje standardowy sposób wprowadzenia tematu, który wymaga jedynie podstawowego zrozumienia wektorów, ale pełniejsze zrozumienie roli, jaką iloczyny skalarne odgrywają w matematyce, można naprawdę znaleźć tylko w świetle przekształceń liniowych.",
  "model": "google_nmt",
  "from_community_srt": "Zrobiłem to, ponieważ istnieje standardowa metoda wprowadzania pojęcia które wymaga zrozumienia tylko pojęcia wektorów ale pełniejsze zrozumienie roli, jaką iloczyny skalarne odgrywają w matematyce może być osiągnięte jedynie, gdy jest to w kontekście  przekształceń liniowych.",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "Zanim jednak to nastąpi, pozwólcie, że pokrótce omówię standardowy sposób wprowadzania produktów kropkowych, który, jak zakładam, jest przynajmniej częściowo sprawdzony przez wielu widzów.",
  "model": "google_nmt",
  "from_community_srt": "Najpierw, jednak, szybko pokażę standardową metodę wprowadzania iloczynu skalarnego. Co jest, jak zakładam, przynajmniej częściową powtórką dla pewnych z was.",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "Liczbowo, jeśli masz dwa wektory o tym samym wymiarze, dwie listy liczb o tej samej długości, wzięcie ich iloczynu skalarnego oznacza sparowanie wszystkich współrzędnych, pomnożenie tych par przez siebie i dodanie wyniku.",
  "model": "google_nmt",
  "from_community_srt": "Numerycznie, gdy mamy dwa wektory tego samego wymiaru; (listy liczb tej samej długości), ich iloczyn skalarny oznacza parowanie odpowiednich współrzędnych, przemnożenie ich,",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "Zatem wektor 1, 2 z kropkami 3, 4 będzie wynosił 1 razy 3 dodać 2 razy 4.",
  "model": "google_nmt",
  "from_community_srt": "oraz dodanie do siebie tych wyników.",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "Wektor 6, 2, 8, 3 z 1, 8, 5, 3 będzie wynosił 6 razy 1 plus 2 razy 8 plus 8 razy 5 plus 3 razy 3.",
  "model": "google_nmt",
  "from_community_srt": "Więc liczonyn skalarny wektora [1,2] oraz [3,4] to 1 x 3 + 2 x 4 A iloczyn skalarny [6,2,8,3] oraz [1,8,5,3] to 6 x 1 + 2 x 8 +  8 x 5 + 3 x 3.",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "Na szczęście to obliczenie ma naprawdę dobrą interpretację geometryczną.",
  "model": "google_nmt",
  "from_community_srt": "Na szczęście, te obliczenia mają przyjemną geometryczną interpretację.",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "Aby pomyśleć o iloczynie skalarnym między dwoma wektorami v i w, wyobraź sobie rzutowanie w na linię przechodzącą przez początek i wierzchołek v.",
  "model": "google_nmt",
  "from_community_srt": "Aby wyobrazić sobie iloczyn skalarny wektorów v i w, rzuć geometrycznie wektor w na prostą zawierającą wektor v,",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "Mnożąc długość tego rzutu przez długość v, otrzymujesz iloczyn skalarny v kropka w.",
  "model": "google_nmt",
  "from_community_srt": "zaczepiony w (0,0) Mnożąc długość tego rzutu przez długość v, otrzymujemy iloczyn skalarny v・w.",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "Z wyjątkiem sytuacji, gdy rzut w jest skierowany w stronę przeciwną do v, ten iloczyn skalarny będzie w rzeczywistości ujemny.",
  "model": "google_nmt",
  "from_community_srt": "Trzeba dodać, że jeżeli w wskazuje przeciwną stronę niż v, to ich iloczyn skalarny będzie ujemny.",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "Jeśli więc dwa wektory są skierowane w tym samym kierunku, ich iloczyn skalarny jest dodatni.",
  "model": "google_nmt",
  "from_community_srt": "Więc gdy wektory wskazują z grubsza ten sam kierunek, to ich iloczyn jest dodatni.",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "Kiedy są prostopadłe, co oznacza, że rzut jednego na drugi jest wektorem zerowym, ich iloczyn skalarny wynosi zero.",
  "model": "google_nmt",
  "from_community_srt": "Gdy są prostopadłe, to znaczy rzut jednego na drugi to wektor zerowy, to ich iloczyn też jest 0.",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "A jeśli wskazują generalnie w przeciwnym kierunku, ich iloczyn skalarny jest ujemny.",
  "model": "google_nmt",
  "from_community_srt": "A gdy wskazują z grubsza przeciwne kierunki,",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "Ta interpretacja jest dziwnie asymetryczna.",
  "model": "google_nmt",
  "from_community_srt": "to ich iloczyn jest ujemny. Ta interpretacja jest podejrzanie asymetryczna - traktuje te dwa wektory w bardzo różny sposób",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "Traktuje te dwa wektory bardzo różnie.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "Kiedy więc dowiedziałem się o tym po raz pierwszy, byłem zaskoczony, że kolejność nie ma znaczenia.",
  "model": "google_nmt",
  "from_community_srt": "więc gdy pierwszy raz się o tym dowiedziałem, byłem zaskoczony,",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "Zamiast tego możesz rzutować v na w, pomnożyć długość rzutowanego v przez długość w i uzyskać ten sam wynik.",
  "model": "google_nmt",
  "from_community_srt": "że ich kolejność nie ma znaczenia. Można zamiast tego rzucić v na w; przemnożyć długość rzutu v przez długość w i otrzymać dokładnie ten sam wynik.",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "Czy nie wydaje się to zupełnie innym procesem?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "Oto intuicja, dlaczego porządek nie ma znaczenia.",
  "model": "google_nmt",
  "from_community_srt": "Czy to nie wydaje się kompletnie czymś innym? Intiucyjne uzasadnienie faktu, że kolejność nie ma znaczenia,",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "Gdyby v i w miały tę samą długość, moglibyśmy wykorzystać pewną symetrię.",
  "model": "google_nmt",
  "from_community_srt": "jest następujące: jeżeli v oraz w miałyby tę samą długość,",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "Ponieważ rzutowanie w na v, a następnie pomnożenie długości tego rzutu przez długość v, jest całkowitym lustrzanym odbiciem rzutowania v na w, a następnie pomnożenie długości tego rzutu przez długość w.",
  "model": "google_nmt",
  "from_community_srt": "moglibyśmy wymyślić pewną symetrię. Skoro rzucenie w na v i przemnożenie rzutu przez dlugość v jest lustrzanym odbiciem rzucenia v na w i przemnożenia długości rzutu przez długość w.",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "Teraz, jeśli przeskalujesz jeden z nich, powiedzmy v, przez jakąś stałą, na przykład 2, tak że nie będą miały równej długości, symetria zostanie złamana.",
  "model": "google_nmt",
  "from_community_srt": "Jednak, gdy przeskalujesz jeden z nich, na przykład v, przez stałą 2 tak, żeby nie miały równych długości, to nie mamy już symetrii.",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "Ale zastanówmy się, jak zinterpretować iloczyn skalarny pomiędzy tym nowym wektorem, 2 razy v i w.",
  "model": "google_nmt",
  "from_community_srt": "Pomyślmy jednak, jak interpretować iloczyn skalarny naszego nowego wektora 2v oraz w.",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "Jeśli pomyślisz o w jako o rzutowaniu na v, to iloczyn skalarny 2v kropka w będzie dokładnie dwa razy większy od iloczynu skalarnego v kropka w.",
  "model": "google_nmt",
  "from_community_srt": "Jeżeli rzucamy w na v, to iloczyn skalarny 2v・w będzie dokładnie podwojonych iloczynem v・w.",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "Dzieje się tak, ponieważ skalowanie v o 2 nie zmienia długości rzutu w, ale podwaja długość wektora, na który rzutujesz.",
  "model": "google_nmt",
  "from_community_srt": "To dlatego, że gdy skalujesz v przez 2, to nie zmienia długości rzutu w, ale podwaja długość wektora, na który rzucasz.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "Ale z drugiej strony, powiedzmy, że zastanawiałeś się nad rzutowaniem v na w.",
  "model": "google_nmt",
  "from_community_srt": "Z drugiej strony, powiedzmy że rzucamy v na w.",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "Cóż, w tym przypadku długość rzutowania jest tym, co się skaluje, gdy pomnożymy v przez 2, ale długość wektora, na który rzutujesz, pozostaje stała.",
  "model": "google_nmt",
  "from_community_srt": "W tym przypadku, to właśnie długość rzutu jest przeskalowana gdy mnożymy v przez 2. Długość wektora, który rzucasz pozostaje ta sama.",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "Zatem ogólny efekt to nadal podwojenie iloczynu skalarnego.",
  "model": "google_nmt",
  "from_community_srt": "Więc cały wpływ przeskalowania to znów podwojenie iloczynu skalarnego.",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "Zatem nawet jeśli w tym przypadku symetria została złamana, wpływ tego skalowania na wartość iloczynu skalarnego jest taki sam w obu interpretacjach.",
  "model": "google_nmt",
  "from_community_srt": "Więc, mimo że tracimy symetrię, wpływ skalowania wektora na iloczyn skalarny jest taki sam",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "Jest jeszcze jedno ważne pytanie, które mnie zdezorientowało, kiedy po raz pierwszy dowiedziałem się o tych rzeczach.",
  "model": "google_nmt",
  "from_community_srt": "w obu przypadkach. Istnieje także inne pytanie, które chciałem zadać, gdy pierwszy raz się o tym uczyłem.",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "Dlaczego, do cholery, ten numeryczny proces dopasowywania współrzędnych, mnożenia par i dodawania ich razem ma cokolwiek wspólnego z projekcją?",
  "model": "google_nmt",
  "from_community_srt": "Jakim cudem ten numeryczny proces dodawania iloczynów współrzędnych ma cokolwiek wspólnego z pojęciem geometrycznego rzutu?",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "Cóż, aby dać zadowalającą odpowiedź, a także w pełni oddać znaczenie iloczynu skalarnego, musimy wydobyć na światło dzienne coś nieco głębszego, co często nazywa się dualizmem.",
  "model": "google_nmt",
  "from_community_srt": "Cóż, żeby dać satysfakcjonyjącą odpowiedź, oraz podkreślić wagę roli, jaką odgrywa iloczyn skalarny, musimy wspomnieć o zagadnieniu, które często określa się jako \"dualność\".",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "Ale zanim do tego przejdę, muszę poświęcić trochę czasu na omówienie transformacji liniowych z wielu wymiarów do jednego wymiaru, który jest po prostu osią liczbową.",
  "model": "google_nmt",
  "from_community_srt": "Jednak, zanim do tego przejdziemy, muszę przeznaczyć chwilę na przekształcenia liniowe z wielu wymiarów w jeden wymiar który jest zwykłą prostą rzeczywistą.",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "Są to funkcje, które pobierają wektor 2D i wyrzucają pewną liczbę, ale transformacje liniowe są oczywiście znacznie bardziej ograniczone niż zwykła funkcja z wejściem 2D i wyjściem 1D.",
  "model": "google_nmt",
  "from_community_srt": "Są to funkcje, które biorą dwuwymiarowy wektor i wypluwają pewną liczbę. Przekształcenia liniowe mają, oczywiście, o wiele bardziej rygorystycznie określone niż dowolna funkcja z dwóch wymiarów w jeden.",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "Podobnie jak w przypadku transformacji w wyższych wymiarach, takich jak te, o których mówiłem w rozdziale 3, istnieją pewne formalne właściwości, które sprawiają, że te funkcje są liniowe, ale zamierzam je tutaj celowo zignorować, aby nie odwracać uwagi od naszego celu końcowego, i zamiast tego skoncentruj się na określonej właściwości wizualnej, która jest odpowiednikiem wszystkich rzeczy formalnych.",
  "model": "google_nmt",
  "from_community_srt": "Tak jak z przekształceniami w wyższych wymiarach, na przykład tych, o których mówiliśmy w rozdziale 3, istnieją pewne własności, które czynią te funkcje liniowymi. Zamierzam jednak celowo pomijać te własności, aby nie odrywać naszej uwagi od głownego celu, i w zamian koncentrować się na pewnej właności, którą możemy zobaczyć gołym okiem,",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "Jeśli weźmiesz linię równomiernie rozmieszczonych kropek i zastosujesz transformację, transformacja liniowa sprawi, że kropki będą równomiernie rozmieszczone, gdy znajdą się w przestrzeni wyjściowej, czyli osi liczbowej.",
  "model": "google_nmt",
  "from_community_srt": "równoważnej całemu temu formalizmowi. Jeżeli weźmiemy linię równoodległych punktów i zastosujemy do nich przekształcenie, to przekształcenie liniowe sprawi, że odległości między nimi nadal będą równe, gdy znajdą się już w przestrzeni, w którą prowadzi to przekształcenie (u nas to prosta rzeczywista) W drugą stronę,",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "W przeciwnym razie, jeśli istnieje linia kropek rozmieszczonych nierównomiernie, transformacja nie jest liniowa.",
  "model": "google_nmt",
  "from_community_srt": "jeżeli pewna linia równoodległych punktów przestanie być równoodległa, to to przekształcenie nie jest liniowe.",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "Podobnie jak w przypadkach, które widzieliśmy wcześniej, jedna z tych transformacji liniowych jest całkowicie zdeterminowana przez to, gdzie zajmie i-hat i j-hat, ale tym razem każdy z tych wektorów bazowych po prostu ląduje na liczbie, więc kiedy zapiszemy, gdzie lądują jako kolumny macierzy, każda z tych kolumn ma tylko jedną liczbę.",
  "model": "google_nmt",
  "from_community_srt": "Tak jak widzieliśmy wcześniej, każde przekształcenie liniowe jest w pełni określone przez wektory, na które przechodzą i-z-daszkiem oraz j-z-daszkiem. jednak tym razem, każdemu wektorowi bazowemu przyporządkowujemy po prostu liczbę. Więc jeżeli ustawimy w kolumnach wektory, na które przechodzi każdy z nich, to w każdej kolumnie będzie tylko jedna liczba.",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "To jest macierz 1x2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "Przeanalizujmy przykład, co to znaczy zastosować jedną z tych transformacji do wektora.",
  "model": "google_nmt",
  "from_community_srt": "To jest macierz 1 na 2. Pokażmy przykład, co oznacza działanie przekształceniem liniowym na wektor.",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "Powiedzmy, że masz transformację liniową, która przenosi i-hat do 1 i j-hat do minus 2.",
  "model": "google_nmt",
  "from_community_srt": "Powiedzmy, że masz przekształcenie, które przeprowadza i-z-daszkiem na 1,",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "Aby śledzić, gdzie kończy się wektor o współrzędnych, powiedzmy 4, 3, pomyśl o podzieleniu tego wektora na 4 razy i-hat plus 3 razy j-hat.",
  "model": "google_nmt",
  "from_community_srt": "a j-z-daszkiem na 2. Aby dowiedzieć się, jak zachowa się dowolny wektor, powiedzmy, [4,3], pomyślmy o nim jako o sumie 4 razy i-z-daszkiem oraz 3 razy j-z-daszkiem.",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "Konsekwencją liniowości jest to, że po przekształceniu wektor będzie 4-krotnością miejsca, w którym wyląduje i-hat, 1, plus 3-krotność miejsca, w którym wyląduje j-hat, minus 2, co w tym przypadku oznacza, że wyląduje na minusie 2.",
  "model": "google_nmt",
  "from_community_srt": "Ponieważ przekształcenie jest liniowe, to w wyniku otrzymamy 4 razy wynik i-z-daszkiem, czyli 1 plus 3 razy wynik j-z-daszkiem, czyli -2. Więc cały wektor ląduje na -2.",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "Kiedy wykonujesz to obliczenie wyłącznie numerycznie, jest to mnożenie wektora macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Gdy robimy to zadanie czysto numerycznie,",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "Ta numeryczna operacja mnożenia macierzy 1x2 przez wektor przypomina branie iloczynu skalarnego dwóch wektorów.",
  "model": "google_nmt",
  "from_community_srt": "to jest to mnożenie wektora przez macierz. Ta numeryczna operacja mnożenia wektora przez macierz 1 na 2 bardzo przypomina iloczyn skalarny dwóch wektorów.",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "Czy ta macierz 1x2 nie wygląda jak wektor, który przewróciliśmy na bok?",
  "model": "google_nmt",
  "from_community_srt": "Czy macierz 1 x 2 nie wygląda jak wektor przewrócony na bok? W istocie,",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "Właściwie moglibyśmy już teraz powiedzieć, że istnieje dobre powiązanie między macierzami 1x2 a wektorami 2D, zdefiniowane przez przechylenie numerycznej reprezentacji wektora na bok, aby uzyskać powiązaną macierz, lub przechylenie macierzy z powrotem do góry, aby uzyskać powiązany wektor .",
  "model": "google_nmt",
  "from_community_srt": "możemy powiedzieć, że istnieje ładne utożsamienie macierzy 1 x 2 oraz wektorów dwuwymiarowych, zdefiniowane jako \"przewrócenie\" numerycznej reprezentacji wektora, z macierzą, którą otrzymamy, albo jako \"postawienie\" macierzy pionowo,",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "Ponieważ w tej chwili zajmujemy się tylko wyrażeniami liczbowymi, przechodzenie między wektorami i macierzami 1x2 może wydawać się głupie.",
  "model": "google_nmt",
  "from_community_srt": "aby otrzymać tożsamy z nią wekor. Skoro patrzymy teraz jedynie na numeryczne wyrażenia, używanie wymiennie wektorów i macierzy może wydawać się głupie.",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "Ale to sugeruje coś, co jest naprawdę niesamowite z geometrycznego punktu widzenia.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "Istnieje jakiś związek pomiędzy transformacjami liniowymi, które przekształcają wektory w liczby, a samymi wektorami.",
  "model": "google_nmt",
  "from_community_srt": "Ale to implikuje coś niesamowitego z geometrycznego punktu widzenia: istnieje pewne połączenie między przekształceniami liniowymi które przekształcają wektory w liczby,",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "Pozwólcie, że pokażę przykład, który wyjaśnia znaczenie i który tak się składa, że również odpowiada na wcześniejszą zagadkę iloczynu skalarnego.",
  "model": "google_nmt",
  "from_community_srt": "a samymi wektorami. Pokażę przykład który ilustruje znaczenie tego utożsamienia, a przy okazji daje odpowiedź na problem z iloczynami skalarnymi z wcześniej.",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "Oducz się tego, czego się nauczyłeś i wyobraź sobie, że jeszcze nie wiesz, że iloczyn skalarny ma związek z projekcją.",
  "model": "google_nmt",
  "from_community_srt": "Zapomnijmy to, czego się nauczyliśmy, i wyobraźmy sobie, że nie znamy związku między rzutem a iloczynem skalarnym.",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "Zamierzam tutaj zrobić kopię osi liczbowej i umieścić ją w jakiś sposób po przekątnej w przestrzeni, tak aby liczba 0 znajdowała się w początku.",
  "model": "google_nmt",
  "from_community_srt": "Teraz wezmę kopię prostej rzeczywistej i umieszczę ją po pewnej przekątnej tak, żeby punkt 0 był w początku układu.",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "Teraz pomyśl o dwuwymiarowym wektorze jednostkowym, którego wierzchołek znajduje się w miejscu cyfry 1 na liczbie.",
  "model": "google_nmt",
  "from_community_srt": "Teraz pomyślmy o dwuwymiaruwym wektorze jednostkowym którego koniec to 1 na naszej prostej.",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "Chcę nadać temu facetowi imię, u-hat.",
  "model": "google_nmt",
  "from_community_srt": "Nazwijmy tego gościa u-z-daszkiem.",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "Ten mały chłopiec odgrywa ważną rolę w tym, co się wydarzy, więc pamiętaj o nim.",
  "model": "google_nmt",
  "from_community_srt": "Odgrywa on ważną rolę w tym, co zaraz się wydarzy, więc miejmy go cały czas z tyłu głowy.",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "Jeśli rzutujemy wektory 2d bezpośrednio na tę ukośną oś liczbową, w efekcie właśnie zdefiniowaliśmy funkcję, która przenosi wektory 2d na liczby.",
  "model": "google_nmt",
  "from_community_srt": "Jeżeli określimy rzut dwuwymiarowych wektorów na tę prostą, to dostaniemy funkcję, króra przeprowadza wektory 2D w liczby.",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "Co więcej, ta funkcja jest w rzeczywistości liniowa, ponieważ spełnia nasz test wizualny, stwierdzając, że dowolna linia złożona z równomiernie rozmieszczonych kropek pozostaje równomiernie rozmieszczona po wylądowaniu na osi liczbowej.",
  "model": "google_nmt",
  "from_community_srt": "Co więcej, ta funkcja jest liniowa, ponieważ przechodzi nasz \"oczny\" test mówiący, że dowolna linia równoodległych punktów ma przejść na równoodległe punkty.",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "Żeby było jasne, mimo że osadziłem oś liczbową w przestrzeni 2D w ten sposób, wynikami funkcji są liczby, a nie wektory 2D.",
  "model": "google_nmt",
  "from_community_srt": "Żeby było jasne, mimo że położyłem naszą prostą prostą w ten sposób na płaszczyźnie, to wynikiem funkcji są liczby, nie wektory dwuwymiarowe.",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "Powinieneś pomyśleć o funkcji, która przyjmuje dwie współrzędne i wyprowadza jedną współrzędną.",
  "model": "google_nmt",
  "from_community_srt": "Powininniśmy myśleć o funkcji, która bierze współrzędne,",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "Ale ten wektorowy kapelusz w kształcie litery U jest wektorem dwuwymiarowym, żyjącym w przestrzeni wejściowej.",
  "model": "google_nmt",
  "from_community_srt": "i wypluwa pojedynczą współrzędną. Nasz wektor u-z-daszkiem jest natomiast wektorem dwuwymiarowym, leżącym w przestrzeni,",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "Jest po prostu umiejscowiony w taki sposób, że pokrywa się z osadzeniem osi liczbowej.",
  "model": "google_nmt",
  "from_community_srt": "którą dopiero przekształcamy. Jest po prostu położony na rysunku w taki sposób,",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "Za pomocą tego rzutowania właśnie zdefiniowaliśmy transformację liniową wektorów 2d na liczby, więc będziemy w stanie znaleźć jakąś macierz 1x2 opisującą tę transformację.",
  "model": "google_nmt",
  "from_community_srt": "że pokrywa się z naszą prostą. Tym sposobem zdefiniowaliśmy liniowe przekształcenie wektorów dwuwymiarowych w liczby, więc będziemy w stanie znaleźć pewną macierz 1 x 2  która określa to przekształcenie.",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "Aby znaleźć macierz 1x2, powiększmy układ ukośnej osi liczbowej i zastanówmy się, gdzie wylądują i-hat i j-hat, ponieważ te miejsca lądowania będą kolumnami macierzy.",
  "model": "google_nmt",
  "from_community_srt": "Aby znaleźć tę macierz, spójrzmy bliżej na początek układu współrzędnych i sprawdźmy, gdzie lądują i-z-daszkiem oraz j-z-daszkiem, skoro punkty na których lądują te wektory będą kolumnami naszej macierzy.",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "Ta część jest super fajna.",
  "model": "google_nmt",
  "from_community_srt": "Co super ciekawe,",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "Możemy to uzasadnić za pomocą naprawdę eleganckiej symetrii.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "Ponieważ oba i-hat i u-hat są wektorami jednostkowymi, rzutowanie i-hat na linię przechodzącą przez u-hat wygląda całkowicie symetrycznie do rzutowania u-hat na oś x.",
  "model": "google_nmt",
  "from_community_srt": "możemy zastosować tutaj pewną elegancką symetrię: skoro i-z-daszkiem oraz u-z-daszkiem są wektorami jednostkowymi, rzut i-z-daszkiem na linię przechodzącą przez u-z-daszkiem wygląda symetrycznie do rzutu u-z-daszkiem na oś OX.",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "Kiedy więc zapytamy, na jakiej liczbie wyląduje i-hat po wyświetleniu, odpowiedź będzie taka sama, jak na dowolnej liczbie, na której wyląduje u-hat po rzucie na oś x.",
  "model": "google_nmt",
  "from_community_srt": "więc gdy pytamy na jakiej liczbie ląduje i-z-daszkiem po rzucie na u, odpowiedź będzie taka sama jak to, na czym ląduje u-z-daszkiem przy rzucie na OX.",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "Ale rzutowanie u-hata na oś x oznacza po prostu wzięcie współrzędnej x u-hata.",
  "model": "google_nmt",
  "from_community_srt": "Ale rzut u-z-daszkiem na OX to po prostu współrzędna x-owa u-z-daszkiem.",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "Zatem zgodnie z symetrią liczba, w której wyląduje i-hat, rzucona na ukośną oś liczbową, będzie współrzędną x u-hat.",
  "model": "google_nmt",
  "from_community_srt": "Więc, z symetrii, liczba na której ląduje -z-daszkiem po rzucie na naszą prostą to pierwsza współrzędna wektora u-z-daszkiem.",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Czy to nie fajne?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "Rozumowanie jest prawie identyczne w przypadku przypadku j-hat.",
  "model": "google_nmt",
  "from_community_srt": "Czy to nie jest super? Rozumowanie jest niemal identyczna dla j-z-daszkiem.",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "Pomyśl o tym przez chwilę.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "Z tych samych powodów współrzędna y u-hat daje nam liczbę, w której wyląduje j-hat, gdy zostanie rzucona na kopię osi liczbowej.",
  "model": "google_nmt",
  "from_community_srt": "Pomyślmy o tym chwilę. Z tych samych powodów, współrzędna y wektora u-z-daszkiem daje nam liczbę, na której ląduje j-z-daszkiem, gdy rzucamy go na naszą prostą.",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "Zatrzymaj się i zastanów nad tym przez chwilę.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "Po prostu myślę, że to naprawdę fajne.",
  "model": "google_nmt",
  "from_community_srt": "Zapauzuj i pomyśl o tym chwilę - ja po prostu myślę że to jest naprawdę cool.",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "Zatem wpisy macierzy 1x2 opisującej transformację projekcji będą współrzędnymi u-hat.",
  "model": "google_nmt",
  "from_community_srt": "Więc elementy macierzy opisujące rzut na naszą prostą to dokładnie współrzędne wektora u-z-daszkiem.",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "Obliczenie tej transformacji rzutowania dla dowolnych wektorów w przestrzeni, która wymaga pomnożenia tej macierzy przez te wektory, jest obliczeniowo identyczne z obliczeniem iloczynu skalarnego za pomocą kapelusza w kształcie litery U.",
  "model": "google_nmt",
  "from_community_srt": "A obliczanie tego przekształcenia dla dowolnych wektorów co wymaga mnożenia wektorów przez tę macierz, jest obliczeniowo dokładnie tym samym co obliczanie iloczynu skalarnego z u-z-daszkiem.",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "Dlatego wzięcie iloczynu skalarnego z wektorem jednostkowym można zinterpretować jako rzutowanie wektora na rozpiętość tego wektora jednostkowego i przyjęcie długości.",
  "model": "google_nmt",
  "from_community_srt": "Dlatego iloczyn skalarny z wektorem jednostkowym może być interpretowany jako rzut wektora na przestrzeń rozpiętą przez ten wektor jednostkowy",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "A co z wektorami niejednostkowymi?",
  "model": "google_nmt",
  "from_community_srt": "i obliczenie długości tego rzutu. Co więc z wektorami,",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "Załóżmy na przykład, że bierzemy ten wektor jednostkowy u-hat, ale zwiększamy go 3-krotnie.",
  "model": "google_nmt",
  "from_community_srt": "które nie są jednostkowe? Na przykład, powiedzmy że bierzemy nasz wektor u-z-daszkiem, i skalujemy go 3 razy.",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "Liczbowo każdy z jego składników zostaje pomnożony przez 3.",
  "model": "google_nmt",
  "from_community_srt": "Numerycznie,",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "Zatem patrząc na macierz powiązaną z tym wektorem, i-hat i j-hat osiągają trzykrotność wartości, przy których lądowały wcześniej.",
  "model": "google_nmt",
  "from_community_srt": "każda współrzędna jest mnożona przez 3, więc patrząc na macierz tożsamą z tym wektorem, przeprowadza ona i-z-daszkiem oraz j-z-daszkiem na 3 razy tę wartości,",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "Ponieważ wszystko to ma charakter liniowy, oznacza to bardziej ogólnie, że nową macierz można zinterpretować jako rzutowanie dowolnego wektora na kopię osi liczbowej i mnożenie w miejscu, w którym się znajdzie, przez 3.",
  "model": "google_nmt",
  "from_community_srt": "na których lądowały wcześniej. Skoro to wszystko jest liniowe, wynika z tego ogólnie, że nowa macierz może być interpretowana jako rzut dowolnego wektora na naszą prostą, i mnożenie tego,",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "Dlatego iloczyn skalarny z wektorem niejednostkowym można interpretować jako rzutowanie najpierw na ten wektor, a następnie zwiększanie długości tego rzutowania o długość wektora.",
  "model": "google_nmt",
  "from_community_srt": "gdzie wyląduje razy 3. To dlatego o iloczynie skalarnym z wektorem, który nie jest jednostkowy można myśleć jako o rzucie tego wektora, a następnie przemnożeniu rzutu przez długość wektora.",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "Pomyśl przez chwilę o tym, co się tutaj wydarzyło.",
  "model": "google_nmt",
  "from_community_srt": "Pomyślmy chwilę o tym, co właśnie się stało.",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "Mieliśmy transformację liniową z przestrzeni 2D na oś liczbową, która nie została zdefiniowana w kategoriach wektorów numerycznych ani numerycznych iloczynów skalarnych, została po prostu zdefiniowana poprzez rzutowanie przestrzeni na ukośną kopię osi liczbowej.",
  "model": "google_nmt",
  "from_community_srt": "Mieliśmy liniowe przekształcenie z dwóch wymiarów na prostą, które nie było zdefiniowane w języku wektorów ani iloczynów skalarnych. Było zdefiniowane po prostu jako rzut przestrzeni 2D na pewną prostą.",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "Ponieważ jednak transformacja jest liniowa, z konieczności została opisana jakąś macierzą 1x2.",
  "model": "google_nmt",
  "from_community_srt": "Jednak ponieważ przekształcenie jest liniowe, musiało być opisane pewną macierzą 1 x 2,",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "A ponieważ pomnożenie macierzy 1x2 przez wektor 2D jest równoznaczne z przewróceniem tej macierzy na bok i wzięciem iloczynu skalarnego, transformacja ta była nieuchronnie powiązana z jakimś wektorem 2D.",
  "model": "google_nmt",
  "from_community_srt": "a skoro mnożenie macierzy 1 x 2 przez wektor dwuwymiarowy to to samo co przewrócenie macierzy i wzięcie iloczynu skalarnego, to to przekształcenie było, jak by nie patrzeć,",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "Lekcja z tego jest taka, że za każdym razem, gdy mamy do czynienia z jedną z tych transformacji liniowych, której przestrzenią wyjściową jest oś liczbowa, niezależnie od tego, jak została zdefiniowana, będzie istniał pewien unikalny wektor v odpowiadający tej transformacji, w tym sensie, że zastosowanie transformacji to samo, co wzięcie iloczynu skalarnego z tym wektorem.",
  "model": "google_nmt",
  "from_community_srt": "powiązane z pewnym wektorem dwuwymiarowym. Lekcja z tego jest taka, że kiedykolwiek gdy mamy liniowe przekształcenie, którego wynikiem jest prosta, to nie ważne jak byłoby zdefiniowane, zawsze będzie istniał pewien wektor v odpowiadający temu przekształceniu, w tym sensie, że użycie tego przekształcenia to to samo co wzięcie iloczynu skalarnego z tym wektorem.",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "Dla mnie to jest absolutnie piękne.",
  "model": "google_nmt",
  "from_community_srt": "Dla mnie to jest absolutnie piękne.",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "To przykład czegoś w matematyce zwanego dualnością.",
  "model": "google_nmt",
  "from_community_srt": "To przykład czegoś, co w matematyce określane jest jako dualność.",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "Dualizm pojawia się w matematyce na wiele różnych sposobów i form, a jego zdefiniowanie jest bardzo trudne.",
  "model": "google_nmt",
  "from_community_srt": "Dualność pojawia się w wielu formach w matematyce a jej porządna definicja może okazać się nietrywialna.",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "Mówiąc luźno, odnosi się to do sytuacji, w których istnieje naturalna, ale zaskakująca zgodność między dwoma typami rzeczy matematycznych.",
  "model": "google_nmt",
  "from_community_srt": "Mówiąc nieformalnie, mówi ona o sytuacjach gdzie mamy naturalną, lecz zaskakującą odpowiedniość między dwoma matematycznymi tworami.",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "W przypadku algebry liniowej, o którym właśnie się dowiedziałeś, można powiedzieć, że dualność wektora jest zakodowaną w nim transformacją liniową, a dualność liniowej transformacji z pewnej przestrzeni do jednego wymiaru jest pewnym wektorem w tej przestrzeni.",
  "model": "google_nmt",
  "from_community_srt": "W przypadku Algebry liniowej, o którym właśnie mówiliśmy, możemy powiedzieć, że dualnym do wektora jest przekształcenie, które jest z nim tożsame. A dualnym do przekształcenia liniowego w jeden wymiar jest właśnie pewien wektor w przestrzeni,",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "Podsumowując, na pozór iloczyn skalarny jest bardzo użytecznym narzędziem geometrycznym do zrozumienia rzutów i sprawdzenia, czy wektory mają tendencję do wskazywania tego samego kierunku.",
  "model": "google_nmt",
  "from_community_srt": "z której zaczynamy. Więc, podsumowując, iloczyn skalarny jest bardzo użytecznym narzędziem geometrycznym, pomagającym zrozumieć rzuty oraz sprawdzać czy dwa wektory wskazują z grubsza ten sam kierunek.",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "I to jest prawdopodobnie najważniejsza rzecz, o której musisz pamiętać w przypadku iloczynu skalarnego.",
  "model": "google_nmt",
  "from_community_srt": "To jest prawdopodobnie najważniejsza rzecz,",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "Ale na głębszym poziomie, rozsianie razem dwóch wektorów jest sposobem na przełożenie jednego z nich w świat przekształceń.",
  "model": "google_nmt",
  "from_community_srt": "którą musicie pamiętać o iloczynie skalarnym, ale bardziej niskopoziomowo, iloczyn skalarny dwóch wektorów to sposób przeniesienia jednego z nich w świat przekształceń:",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "Ponownie, liczbowo, podkreślanie tego może wydawać się głupie.",
  "model": "google_nmt",
  "from_community_srt": "tak jak wcześniej, numerycznie,",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "To tylko dwa obliczenia, które wyglądają podobnie.",
  "model": "google_nmt",
  "from_community_srt": "to może wydawać się głupie, to po prostu dwa sposoby liczenia, które wyglądają podobnie.",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "Ale powodem, dla którego uważam to za tak ważne, jest to, że w matematyce, gdy masz do czynienia z wektorem, kiedy naprawdę poznasz jego osobowość, czasami zdajesz sobie sprawę, że łatwiej jest go zrozumieć nie jako strzałkę w przestrzeni, ale jako fizyczne ucieleśnienie transformacji liniowej.",
  "model": "google_nmt",
  "from_community_srt": "Ale powód, dla którego uważam to za ważne, to fakt, że w wielu dziedzinach matematyki, gdy działamy na wektorach, kiedy poznamy już jego \"osobowość\" czasami okazuje się że łatwiej jest ją zrozumieć nie jako strzałkę w przestrzeni, lecz jako fizyczną reprezentację przekształcenia liniowego.",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "To tak, jakby wektor był w rzeczywistości tylko skrótem pojęciowym pewnej transformacji, ponieważ łatwiej jest nam myśleć o strzałkach w przestrzeni, niż przenosić całą tę przestrzeń na oś liczbową.",
  "model": "google_nmt",
  "from_community_srt": "To tak, jakby wektor był tylko skrótem myślowym dla pewnego przekształcenia, ponieważ łatwiej jest myśleć o strzałkach w przestrzeni, niż przenosić w głowie całą przestrzeń na prostą.",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.97
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "W następnym filmie zobaczysz kolejny naprawdę fajny przykład tej dwoistości w działaniu, ponieważ mówię o produkcie krzyżowym.",
  "model": "google_nmt",
  "from_community_srt": "W następnym filmie zobaczymy inny,",
  "n_reviews": 0,
  "start": 822.61,
  "end": 829.19
 }
]