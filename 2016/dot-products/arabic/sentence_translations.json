[
 {
  "input": "Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "[&quot;قصيدة الفرح&quot;، لبيتهوفن، تُعزف حتى نهاية البيانو.] تقليديًا، المنتجات النقطية هي شيء تم تقديمه في وقت مبكر جدًا في دورة الجبر الخطي، عادةً في البداية.",
  "model": "google_nmt",
  "from_community_srt": "تقليديا ، والمنتجات نقطة أو شيء من هذا القبيل قدم في وقت مبكر حقا في الجبر الخطي دورة عادة في البداية.",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "لذلك قد يبدو غريبًا أنني دفعتهم إلى هذا الحد في السلسلة.",
  "model": "google_nmt",
  "from_community_srt": "لذلك قد يبدو من الغريب أن أدفعهم العودة هذا بعيد في هذه السلسلة.",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "لقد فعلت ذلك لأن هناك طريقة قياسية لتقديم الموضوع، والتي لا تتطلب أكثر من فهم أساسي للمتجهات، لكن الفهم الكامل للدور الذي تلعبه المنتجات النقطية في الرياضيات لا يمكن العثور عليه إلا في ضوء التحولات الخطية.",
  "model": "google_nmt",
  "from_community_srt": "أنا فعلت هذا لأن هناك طريقة قياسية لعرض الموضوع الذي لا يتطلب أكثر من فهم أساسي من المتجهات ، ولكن الفهم الكامل للدور تلعب المنتجات النقطية في الرياضيات ، يمكن فقط حقا أن تكون تحت ضوء التحولات الخطية.",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "قبل ذلك، اسمحوا لي أن أغطي بإيجاز الطريقة القياسية التي يتم بها تقديم المنتجات النقطية، والتي أفترض أنها مراجعة جزئية على الأقل لعدد من المشاهدين.",
  "model": "google_nmt",
  "from_community_srt": "قبل ذلك ، دعني أغلق بإيجاز الطريقة القياسية التي يتم تقديم المنتجات. الذي أفترضه هو مراجعة جزئية على الأقل لعدد من المشاهدين.",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "من الناحية العددية، إذا كان لديك متجهين لهما نفس البعد، وقائمتين من الأرقام بنفس الأطوال، فإن أخذ حاصل الضرب النقطي الخاص بهما يعني إقران جميع الإحداثيات، وضرب هذه الأزواج معًا، وإضافة النتيجة.",
  "model": "google_nmt",
  "from_community_srt": "عدديا ، إذا كان لديك متجهين لل نفس البعد إلى قائمة الأرقام بنفس الطول ، أخذ المنتج نقطة ، يعني ، الإقران جميع الإحداثيات ، بضرب تلك الأزواج معا ، وإضافة النتيجة.",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "إذن المتجه 1، 2 المنقط بـ 3، 4 سيكون 1 ضرب 3 زائد 2 ضرب 4.",
  "model": "google_nmt",
  "from_community_srt": "لذا فإن المتجه [1 ، 2] منقّط بـ [3 ، 4] ، سيكون 1 × 3 + 2 × 4.",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "المتجه 6، 2، 8، 3 المنقط بـ 1، 8، 5، 3 سيكون 6 ضرب 1 زائد 2 ضرب 8 زائد 8 ضرب 5 زائد 3 ضرب 3.",
  "model": "google_nmt",
  "from_community_srt": "المتجه [6 ، 2 ، 8 ، 3] المنقط مع [1 ، 8 ، 5 ، 3] سيكون: 6 × 1 + 2 × 8 + 8 × 5 + 3 × 3.",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "ولحسن الحظ، فإن هذا الحساب له تفسير هندسي رائع حقًا.",
  "model": "google_nmt",
  "from_community_srt": "لحسن الحظ ، هذا الحساب له حقًا رائع تفسير هندسي.",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "للتفكير في حاصل الضرب النقطي بين متجهين، v وw، تخيل إسقاط w على الخط الذي يمر عبر نقطة الأصل ورأس v.",
  "model": "google_nmt",
  "from_community_srt": "للتفكير في المنتج نقطة بين اثنين المتجهات v و ​​w ، تخيل إسقاط w على الخط الذي يمر من خلال أصل وغيض الخامس.",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "بضرب طول هذا الإسقاط في طول v، تحصل على حاصل الضرب النقطي v نقطة w.",
  "model": "google_nmt",
  "from_community_srt": "ضرب طول هذا الإسقاط من خلال طول v ، لديك منتج نقطة ع · ث.",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "باستثناء عندما يشير إسقاط w هذا في الاتجاه المعاكس من v، فإن منتج الضرب النقطي هذا سيكون في الواقع سالبًا.",
  "model": "google_nmt",
  "from_community_srt": "إلا عندما يشير هذا الإسقاط من ث في الاتجاه المعاكس من v ، هذا المنتج نقطة سيكون في الواقع سلبي.",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "لذا، عندما يشير متجهان عمومًا إلى الاتجاه نفسه، يكون حاصل الضرب القياسي لهما موجبًا.",
  "model": "google_nmt",
  "from_community_srt": "لذلك عندما يشير متجهان بشكل عام في نفس الاتجاه، منتجهم نقطة إيجابية.",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "عندما يكونا متعامدين، مما يعني أن إسقاط أحدهما على الآخر هو المتجه الصفري، فإن حاصل الضرب النقطي لهما يساوي صفرًا.",
  "model": "google_nmt",
  "from_community_srt": "عندما تكون متعامدة ، بمعنى ، إسقاط واحد على الآخر هو 0 متجه ، والمنتج نقطة هو 0.",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "وإذا أشارا إلى الاتجاه المعاكس بشكل عام، فإن حاصل الضرب القياسي يكون سالبًا.",
  "model": "google_nmt",
  "from_community_srt": "واذا كانوا يشيرون عكس ذلك بشكل عام الاتجاه ، والمنتج نقطة سلبي.",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "الآن، هذا التفسير غير متماثل بشكل غريب.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "إنه يعامل المتجهين بشكل مختلف تمامًا.",
  "model": "google_nmt",
  "from_community_srt": "الآن ، هذا التفسير غريب بشكل غير متجانس ، يعامل المتجهين بشكل مختلف جدا ، لذلك عندما علمت بهذا أولاً ، فوجئت هذا الأمر لا يهم.",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "لذلك عندما علمت هذا لأول مرة، فوجئت بأن الترتيب لا يهم.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "يمكنك بدلاً من ذلك إسقاط v على w، وضرب طول v المسقط بطول w، والحصول على نفس النتيجة.",
  "model": "google_nmt",
  "from_community_srt": "هل يمكن بدلا من ذلك مشروع v على ث. مضاعفة طول v المتوقعة من قبل طول ث والحصول على نفس النتيجة.",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "أعني، ألا تبدو هذه عملية مختلفة حقًا؟",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "هذا هو الحدس لماذا لا يهم النظام.",
  "model": "google_nmt",
  "from_community_srt": "أعني ، لا أشعر أني مختلف تمامًا معالجة؟ وهنا الحدس لماذا لا يحدث ذلك شيء: إذا حدث v و w أن يكون لهما نفس الطول ،",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "إذا كان v وw لهما نفس الطول، فيمكننا الاستفادة من بعض التماثل.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "نظرًا لأن إسقاط w على v، فإن ضرب طول هذا الإسقاط في طول v، هو صورة معكوسة كاملة لإسقاط v على w، ثم ضرب طول هذا الإسقاط في طول w.",
  "model": "google_nmt",
  "from_community_srt": "يمكننا الاستفادة من بعض التماثل. منذ إسقاط ث على v ثم ضرب طول هذا الإسقاط بطول الخامس ، هي صورة مرآة كاملة من إسقاط v على ث ثم ضرب طول ذلك الإسقاط من طول ث.",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "الآن، إذا قمت بقياس أحدهما، على سبيل المثال v، بواسطة ثابت مثل 2، بحيث لا يكون لهما نفس الطول، فسيتم كسر التماثل.",
  "model": "google_nmt",
  "from_community_srt": "الآن ، إذا قمت \"بتوسيع\" واحد منهم ، قل v من قبل بعض ثابت مثل 2 ، بحيث لا تكون متساوية الطول ، التماثل مكسور.",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "لكن دعونا نفكر في كيفية تفسير حاصل الضرب النقطي بين هذا المتجه الجديد، 2 ضرب v وw.",
  "model": "google_nmt",
  "from_community_srt": "ولكن دعونا نفكر من خلال كيفية تفسير نقطة المنتج بين هذا ناقلات جديدة 2V و ث.",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "إذا فكرت في إسقاط w على v، فإن حاصل الضرب النقطي 2v dot w سيكون بالضبط ضعف حاصل الضرب النقطي v dot w.",
  "model": "google_nmt",
  "from_community_srt": "إذا كنت تفكر في الوصول إلى w الخامس ثم سيكون المنتج نقطة 2V ・ w بالضبط مرتين المنتج نقطة v ・ ث.",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "هذا لأنه عندما تقوم بقياس v بمقدار 2، فإن ذلك لا يغير طول إسقاط w، ولكنه يضاعف طول المتجه الذي تقوم بالإسقاط عليه.",
  "model": "google_nmt",
  "from_community_srt": "هذا لأنه عندما \"مقياس\" من قبل 2 لا يغير طول العرض من ث لكنه يضاعف طول المتجه ذلك كنت تسقط على.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "ولكن من ناحية أخرى، لنفترض أنك كنت تفكر في إسقاط v على w.",
  "model": "google_nmt",
  "from_community_srt": "ولكن ، من ناحية أخرى ، دعنا نفترض أنك تفكر حول الحصول على v المتوقعة على ث.",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "حسنًا، في هذه الحالة، طول الإسقاط هو الشيء الذي يتم قياسه عندما نضرب v في 2، لكن طول المتجه الذي تسقط عليه يظل ثابتًا.",
  "model": "google_nmt",
  "from_community_srt": "حسنا ، في هذه الحالة ، طول الإسقاط هو الشيء الذي يجب أن يتم \"قياسه\" عندما نتكاثر ت بنسبة 2. طول المتجه الذي تتوقعه على إقامة ثابتة.",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "وبالتالي فإن التأثير الإجمالي لا يزال مجرد مضاعفة المنتج النقطي.",
  "model": "google_nmt",
  "from_community_srt": "لذلك لا يزال التأثير الكلي مضاعفًا المنتج نقطة.",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "لذلك، على الرغم من كسر التماثل في هذه الحالة، فإن تأثير هذا القياس على قيمة حاصل الضرب النقطي هو نفسه في كلا التفسيرين.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ، على الرغم من تماثل التماثل في هذا قضية، تأثير هذا \"التحجيم\" على قيمة المنتج نقطة ، هو نفسه",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "هناك أيضًا سؤال كبير آخر حيرني عندما تعلمت هذه الأشياء لأول مرة.",
  "model": "google_nmt",
  "from_community_srt": "تحت كل من التفسيرات.",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "لماذا بحق السماء هذه العملية الرقمية لمطابقة الإحداثيات وضرب الأزواج وجمعها معًا لها علاقة بالإسقاط؟",
  "model": "google_nmt",
  "from_community_srt": "هناك أيضا سؤال كبير آخر مشوش لي عندما علمت هذه الأشياء لأول مرة: لماذا على الأرض هذه العملية العددية من الإحداثيات المطابقة وضرب الأزواج و",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "حسنًا، لكي نعطي إجابة مرضية، وأيضًا لتحقيق العدالة الكاملة لأهمية حاصل الضرب النقطي، نحتاج إلى اكتشاف شيء أعمق قليلًا يحدث هنا، والذي غالبًا ما يُطلق عليه اسم الازدواجية.",
  "model": "google_nmt",
  "from_community_srt": "مضيفا لهم معا ، لديك أي علاقة مع الإسقاط؟ حسنا ، لإعطاء إجابة مرضية ، وأيضا لتحقيق العدالة الكاملة للأهمية من المنتج نقطة ، نحن بحاجة إلى اكتشاف شيء ما قليلاً أعمق يحدث هنا التي غالبًا ما يطلق عليها اسم \"الازدواجية\".",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "لكن قبل الخوض في ذلك، أحتاج إلى قضاء بعض الوقت في الحديث عن التحولات الخطية من أبعاد متعددة إلى بُعد واحد، وهو مجرد خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "لكن قبل الدخول في ذلك ، أحتاج إلى قضاء بعض الوقت في الحديث عن الخطية التحولات من أبعاد متعددة إلى بعد واحد",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "هذه هي الوظائف التي تأخذ متجهًا ثنائي الأبعاد وتطلق بعض الأرقام، لكن التحويلات الخطية تكون بالطبع أكثر تقييدًا من الدالة العادية ذات المدخلات ثنائية الأبعاد والمخرجات أحادية البعد.",
  "model": "google_nmt",
  "from_community_srt": "وهو مجرد رقم الخط. هذه هي الوظائف التي تأخذ في المتجه 2D وابصق بعض الأرقام. لكن التحولات الخطية هي ، بالطبع ، أكثر تقييدًا من طاحونة الخاص بك وظيفة مع إدخال 2D وإخراج 1D.",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "كما هو الحال مع التحولات في الأبعاد الأعلى، مثل تلك التي تحدثت عنها في الفصل 3، هناك بعض الخصائص الشكلية التي تجعل هذه الوظائف خطية، لكنني سأتجاهل تلك الخصائص هنا عمدًا حتى لا تصرف انتباهنا عن هدفنا النهائي، وبدلاً من ذلك ركز على خاصية بصرية معينة تعادل جميع الأشياء الرسمية.",
  "model": "google_nmt",
  "from_community_srt": "كما هو الحال مع التحولات ذات الأبعاد العالية ، مثل تلك التي تحدثت عنها في الفصل 3 ، هناك بعض الخصائص الرسمية التي تجعل هذه الوظائف الخطية. لكنني سأتجاهل عن قصد أولئك الموجودين هنا حتى لا يصرف انتباهنا عن هدفنا النهائي ، وبدلا من ذلك التركيز على خاصية بصرية معينة هذا يعادل كل الاشياء الرسمية.",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "إذا أخذت خطًا من النقاط المتباعدة بشكل متساوٍ وقمت بتطبيق تحويل، فإن التحويل الخطي سيبقي تلك النقاط متباعدة بشكل متساوٍ بمجرد وصولها إلى مساحة الإخراج، وهو خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "إذا كنت تأخذ خط من النقاط متباعدة بشكل متساو وتطبيق تحول ، التحول الخطي سيحافظ على هذه النقاط متباعدة بالتساوي ، بمجرد هبوطها في مساحة الإخراج ، والتي هو خط الرقم.",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "بخلاف ذلك، إذا كان هناك خط من النقاط متباعد بشكل غير متساو، فإن تحويلك ليس خطيًا.",
  "model": "google_nmt",
  "from_community_srt": "خلاف ذلك ، إذا كان هناك خط من النقاط يحصل على مسافات متفاوتة ثم التحول الخاص بك ليس خطي.",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "كما هو الحال مع الحالات التي رأيناها من قبل، يتم تحديد أحد هذه التحويلات الخطية تمامًا من خلال المكان الذي يأخذ فيه i-hat وj-hat، ولكن هذه المرة كل واحد من تلك المتجهات الأساسية يستقر على رقم فقط، لذلك عندما نسجل أين إنها تهبط كأعمدة مصفوفة، كل عمود من هذه الأعمدة يحتوي على رقم واحد فقط.",
  "model": "google_nmt",
  "from_community_srt": "كما هو الحال مع الحالات التي رأيناها من قبل ، واحدة من هذه التحولات الخطية يتم تحديده بالكامل من حيث يأخذ أنا قبعة وجي هات لكن هذه المرة ، كل واحد من تلك المتجهات الأساسية مجرد أرض على عدد. لذلك عندما نسجل المكان الذي تهبط فيه الأعمدة من المصفوفة كل من هذه الأعمدة لديها فقط رقم واحد.",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "هذه مصفوفة 1x2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "دعونا نتناول مثالاً لما يعنيه تطبيق أحد هذه التحويلات على المتجه.",
  "model": "google_nmt",
  "from_community_srt": "هذه مصفوفة 1 × 2. دعونا نسير على مثال لما يعنيه لتطبيق واحد من هذه التحولات إلى قوه موجهة.",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "لنفترض أن لديك تحويلًا خطيًا ينقل i-hat إلى 1 وj-hat إلى سالب 2.",
  "model": "google_nmt",
  "from_community_srt": "لنفترض أن لديك تحولًا خطيًا يأخذ i-hat إلى 1 و j-hat إلى -2.",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "لمتابعة المكان الذي ينتهي فيه متجه ذو إحداثيات، 4، 3، فكر في تقسيم هذا المتجه إلى 4 ضرب i-hat زائد 3 ضرب j-hat.",
  "model": "google_nmt",
  "from_community_srt": "لمتابعة المكان المتجه بالإحداثيات ، لنقل ، [4 ، 3] ينتهي ، فكر في تحطيم هذا الموجه 4 مرات i-hat + 3 مرات j-hat.",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "نتيجة الخطية هي أنه بعد التحويل، سيكون المتجه 4 أضعاف المكان الذي يهبط فيه i-hat، 1، بالإضافة إلى 3 أضعاف المكان الذي يهبط فيه j-hat، سالب 2، وهو ما يعني في هذه الحالة أنه يهبط على السالب 2.",
  "model": "google_nmt",
  "from_community_srt": "نتيجة الخطي ، هو بعد ذلك التحول سيكون المتجه: 4 أضعاف المكان أنا قبعة الأراضي ، 1 ، بالإضافة إلى 3 أضعاف المكان الذي تقع فيه j-hat ، -2. وهو ما يعني في هذه الحالة أنه يهبط -2.",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "عندما تقوم بهذا الحساب عدديًا بحتًا، فهذا يعني ضرب متجهات المصفوفات.",
  "model": "google_nmt",
  "from_community_srt": "عندما تفعل هذا الحساب بحتة عدديا ، انها مضاعفة مكافحة ناقلات.",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "الآن، هذه العملية العددية لضرب مصفوفة 1×2 في متجه تبدو وكأنها تأخذ حاصل الضرب القياسي لمتجهين.",
  "model": "google_nmt",
  "from_community_srt": "الآن ، هذه العملية العددية للضرب مصفوفة 1 في 2 بواسطة ناقل ، يشعر تماما مثل أخذ المنتج نقطة متجهين.",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "ألا تبدو تلك المصفوفة 1x2 مثل المتجه الذي وضعناه على جانبه؟",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "في الواقع، يمكننا القول الآن أن هناك ارتباطًا جيدًا بين المصفوفات 1x2 والمتجهات ثنائية الأبعاد، والتي يتم تحديدها عن طريق إمالة التمثيل العددي للمتجه على جانبه للحصول على المصفوفة المرتبطة، أو إمالة المصفوفة مرة أخرى للحصول على المتجه المرتبط .",
  "model": "google_nmt",
  "from_community_srt": "لا يبدو أن مصفوفة 1 × 2 فقط مثل المتجه الذي رأيناه على جانبه؟ في الواقع ، يمكن أن نقول الآن أن هناك ارتباط جيد بين مصفوفات 1 × 2 وناقلات ثنائية الأبعاد ، محددة عن طريق إمالة التمثيل العددي من متجه على جانبه للحصول على المقترنة مصفوفة، أو تلميح المصفوفة مرة أخرى للحصول على المقترنة قوه موجهة.",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "نظرًا لأننا ننظر فقط إلى التعبيرات العددية في الوقت الحالي، فقد يبدو التنقل ذهابًا وإيابًا بين المتجهات والمصفوفات 1x2 أمرًا سخيفًا.",
  "model": "google_nmt",
  "from_community_srt": "بما أننا ننظر فقط في التعبيرات العددية الآن، الذهاب ذهابا وإيابا بين ناقلات و 1 x 2 قد تبدو المصفوفات وكأنها شيء سخيف",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "لكن هذا يوحي بشيء رائع حقًا من وجهة النظر الهندسية.",
  "model": "google_nmt",
  "from_community_srt": "لكى يفعل.",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "هناك نوع من الارتباط بين التحويلات الخطية التي تأخذ المتجهات إلى أرقام والمتجهات نفسها.",
  "model": "google_nmt",
  "from_community_srt": "لكن هذا يشير إلى شيء رائع حقًا من وجهة النظر الهندسية: هناك نوع من الاتصال بين الخطي التحولات التي تأخذ المتجهات إلى الأرقام",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "اسمحوا لي أن أعرض مثالاً يوضح الأهمية، والذي يصادف أنه يجيب أيضًا على لغز الضرب النقطي الذي تم طرحه سابقًا.",
  "model": "google_nmt",
  "from_community_srt": "وناقلات نفسها. اسمحوا لي أن أعرض مثالا يوضح ذلك الدلالة والذي يحدث حتى يجيب أيضا لغز المنتج نقطة من وقت سابق.",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "تخلص من ما تعلمته، وتخيل أنك لا تعرف بالفعل أن حاصل الضرب النقطي يتعلق بالإسقاط.",
  "model": "google_nmt",
  "from_community_srt": "اكتشف ما تعلمته وتخيل أنك لا تعرف ذلك بالفعل المنتج نقطة تتعلق الإسقاط.",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "ما سأفعله هنا هو أخذ نسخة من خط الأعداد ووضعها قطريًا في الفضاء بطريقة ما، مع وجود الرقم 0 في نقطة الأصل.",
  "model": "google_nmt",
  "from_community_srt": "ما سأفعله هنا هو أخذ نسخة من خط الرقم ووضعه قطريا والفضاء بطريقة أو بأخرى مع الرقم 0 يجلس في الأصل.",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "فكر الآن في متجه الوحدة ثنائي الأبعاد الذي يقع طرفه حيث يوجد الرقم 1 على الرقم.",
  "model": "google_nmt",
  "from_community_srt": "الآن فكر في ناقل الوحدة ثنائي الأبعاد ، التي تجلس نصائح فيها الرقم 1 على الرقم الخط هو.",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "أريد أن أعطي هذا الرجل اسمًا، يو هات.",
  "model": "google_nmt",
  "from_community_srt": "أريد أن أعطي هذا الرجل اسم يو قبعة.",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "يلعب هذا الرجل الصغير دورًا مهمًا فيما سيحدث، لذا احتفظ به في الجزء الخلفي من عقلك.",
  "model": "google_nmt",
  "from_community_srt": "هذا الرجل الصغير يلعب دورا هاما في ما الذي سيحدث ، فقط احتفظ بها في الجزء الخلفي من عقلك.",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "إذا قمنا بإسقاط متجهات ثنائية الأبعاد مباشرة على خط الأعداد القطري هذا، في الواقع، فقد قمنا للتو بتعريف دالة تأخذ المتجهات ثنائية الأبعاد إلى أرقام.",
  "model": "google_nmt",
  "from_community_srt": "إذا كنا نعرض ناقلات ثنائية الأبعاد مباشرة على هذا خط الرقم القطري في الواقع ، لقد قمنا للتو بتعريف وظيفة يأخذ المتجهات 2D إلى الأرقام.",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "علاوة على ذلك، هذه الدالة خطية في الواقع، لأنها تجتاز اختبارنا البصري بأن أي خط من النقاط المتباعدة بشكل متساوٍ يبقى متباعدًا بشكل متساوٍ بمجرد وصوله إلى خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "ما هو أكثر من ذلك ، هذه الوظيفة هي في الواقع خطي لأنه يمر اختبار بصري لدينا أن أي خط من النقاط متباعدة بالتساوي يبقى متباعدة بالتساوي عندما تهبط على الرقم",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "فقط للتوضيح، على الرغم من أنني قمت بتضمين خط الأعداد في مساحة ثنائية الأبعاد مثل هذا، فإن مخرجات الدالة هي أرقام، وليست متجهات ثنائية الأبعاد.",
  "model": "google_nmt",
  "from_community_srt": "خط. فقط لأكون واضحا، على الرغم من أنني قمت بتضمين خط الرقم في الفضاء 2D مثل هذا ، ناتج الدالة هي أرقام ، وليس ناقلات ثنائية الأبعاد.",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "يجب أن تفكر في دالة تأخذ إحداثيين وتخرج إحداثيًا واحدًا.",
  "model": "google_nmt",
  "from_community_srt": "يجب أن تفكر في وظيفة تأخذها في إحداثيات وإخراج إحداثي واحد.",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "لكن هذا المتجه u-hat هو متجه ثنائي الأبعاد، يعيش في مساحة الإدخال.",
  "model": "google_nmt",
  "from_community_srt": "لكن هذا المتجه u-hat هو ثنائي الأبعاد قوه موجهة الذين يعيشون في مساحة الإدخال.",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "لقد تم وضعه بطريقة تتداخل مع تضمين خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "انها تقع فقط في مثل هذه الطريقة التي تتداخل مع تضمين خط الأعداد.",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "مع هذا الإسقاط، قمنا للتو بتعريف التحول الخطي من المتجهات ثنائية الأبعاد إلى الأرقام، لذلك سنكون قادرين على العثور على نوع من المصفوفة 1x2 التي تصف هذا التحويل.",
  "model": "google_nmt",
  "from_community_srt": "مع هذا الإسقاط ، قمنا فقط بتعريف خطي التحول من ناقلات ثنائية الأبعاد إلى أرقام ، لذلك سنكون قادرين على العثور على نوع ما من 1 × 2 المصفوفة التي تصف هذا التحول.",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "للعثور على مصفوفة 1x2، دعونا نكبر إعداد خط الأعداد القطري هذا ونفكر في مكان هبوط كل من i-hat وj-hat، نظرًا لأن نقاط الهبوط هذه ستكون أعمدة المصفوفة.",
  "model": "google_nmt",
  "from_community_srt": "للعثور على ذلك المصفوفة 1 × 2 ، فلنقم بالتكبير هذا خط رقم قطري الإعداد والتفكير في مكان كل من i-hat و j-hat أرض، لأن هذه البقع ستكون أعمدة المصفوفة.",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "هذا الجزء رائع للغاية.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "يمكننا التفكير من خلال ذلك بقطعة تناظر أنيقة حقًا.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "نظرًا لأن i-hat وu-hat كلاهما متجهان للوحدة، فإن إسقاط i-hat على الخط الذي يمر عبر u-hat يبدو متماثلًا تمامًا لإسقاط u-hat على المحور السيني.",
  "model": "google_nmt",
  "from_community_srt": "هذا الجزء رائع ، يمكننا التفكير فيه مع قطعة أنيقة من التناظر: بما أن i-hat و u-hat هما موجهات وحدة ، إسقاط i-hat على الخط المار ش قبعة يبدو متناظرا تماما لحماية u-hat على المحور السيني.",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "لذلك عندما نسأل ما هو الرقم الذي ستهبط عليه القبعة عندما يتم إسقاطها، ستكون الإجابة هي نفس الرقم الذي ستهبط عليه القبعة عندما يتم إسقاطها على المحور السيني.",
  "model": "google_nmt",
  "from_community_srt": "لذلك عندما سألنا ما هو الرقم I-hat الأرض في وقت الحصول عليها الجواب سيكون هو نفسه أيا كان يو على الأراضي عندما يقال على",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "لكن إسقاط u-hat على المحور x يعني فقط أخذ الإحداثي x لـ u-hat.",
  "model": "google_nmt",
  "from_community_srt": "محور س ولكن إبراز u-hat على المحور x يعني فقط أخذ تنسيق x-of u-hat.",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "إذن بالتناظر، الرقم الذي ستهبط فيه i-hat عندما يتم إسقاطها على خط الأعداد القطري هذا سيكون إحداثي x لـ u-hat.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ، عن طريق التماثل ، وعدد أى قبعات الأراضي عندما يتم عرضه على هذا الرقم القطري خط ستكون إحداثي x من u-hat.",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "أليس هذا رائعا؟",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "المنطق مطابق تقريبًا لقضية j-hat.",
  "model": "google_nmt",
  "from_community_srt": "أليس هذا رائع؟ المنطق هو تقريبا متطابقة ل قضية j-hat.",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "فكر في الأمر للحظة.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "ولجميع الأسباب نفسها، فإن إحداثي y لـ u-hat يعطينا الرقم الذي تهبط فيه j-hat عندما يتم إسقاطه على نسخة خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "فكر في الأمر للحظة. لجميع نفس الأسباب ، تنسيق y من يو القبعة يعطينا الرقم الذي تقع فيه j-hat عندما يتم عرضه على نسخة خط الأرقام.",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "توقف وتأمل في ذلك للحظة.",
  "model": "google_nmt",
  "from_community_srt": "وقفة والتأمل ذلك للحظة.",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "أعتقد أن هذا رائع حقًا.",
  "model": "google_nmt",
  "from_community_srt": "أنا فقط اعتقد ان هذا رائع حقا.",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "وبالتالي فإن إدخالات المصفوفة 1x2 التي تصف تحويل الإسقاط ستكون إحداثيات u-hat.",
  "model": "google_nmt",
  "from_community_srt": "إذن إدخالات المصفوفة 1 × 2 تصف تحويل الإسقاط ستكون إحداثيات ش القبعة.",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "وحساب تحويل الإسقاط هذا لمتجهات عشوائية في الفضاء، والذي يتطلب ضرب تلك المصفوفة في تلك المتجهات، مطابق حسابيًا لأخذ حاصل الضرب النقطي باستخدام u-hat.",
  "model": "google_nmt",
  "from_community_srt": "وحساب هذا التحول الإسقاط للمتجهات التعسفية في الفضاء ، الأمر الذي يتطلب مضاعفة تلك المصفوفة بواسطة تلك المتجهات ، هي مطابقة حسابيا لأخذ نقطة المنتج مع قبعة يو.",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "ولهذا السبب يمكن تفسير أخذ حاصل الضرب النقطي باستخدام متجه الوحدة على أنه إسقاط متجه على مدى متجه الوحدة هذا وأخذ الطول.",
  "model": "google_nmt",
  "from_community_srt": "هذا هو السبب في أخذ المنتج نقطة مع حتى النصر، يمكن تفسيره كإسقاط متجه على مدى وحدة مكافحة ناقلات وأخذ",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "فماذا عن المتجهات غير الوحدة؟",
  "model": "google_nmt",
  "from_community_srt": "الطول.",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "على سبيل المثال، لنفترض أننا أخذنا متجه الوحدة هذا، ولكننا قمنا بتوسيع نطاقه بعامل 3.",
  "model": "google_nmt",
  "from_community_srt": "ماذا عن المتجهات غير الوحدة؟ فمثلا، دعونا نقول أننا نأخذ تلك الوحدة المتجه u-hat ، لكننا \"نوسع\" هذا الرقم بمقدار 3.",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "عددياً، يتم ضرب كل مكون من مكوناته في 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "إذن، بالنظر إلى المصفوفة المرتبطة بهذا المتجه، نجد أن قيمة i-hat وj-hat تصل إلى ثلاثة أضعاف القيم التي وصلتا إليها من قبل.",
  "model": "google_nmt",
  "from_community_srt": "عدديا ، كل مكون من مكوناته يتضاعف بنسبة 3 ، حتى النظر في المصفوفة المرتبطة بذلك قوه موجهة، يأخذ i-hat و j-hat إلى 3 أضعاف القيم حيث هبطوا من قبل",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "نظرًا لأن كل هذا خطي، فهذا يعني بشكل عام أنه يمكن تفسير المصفوفة الجديدة على أنها إسقاط أي متجه على نسخة خط الأعداد وضرب مكان وصوله بمقدار 3.",
  "model": "google_nmt",
  "from_community_srt": "بما أن هذا كله خطي ، هذا يعني بشكل عام ، أن المصفوفة الجديدة يمكن تفسيرها على أنها إسقاط أي متجه على خط الأعداد نسخ وضرب المكان الذي تهبط فيه 3.",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "ولهذا السبب يمكن تفسير حاصل الضرب النقطي مع متجه غير وحدة على أنه إسقاط أولًا على هذا المتجه، ثم زيادة طول هذا الإسقاط بطول المتجه.",
  "model": "google_nmt",
  "from_community_srt": "هذا هو السبب في المنتج نقطة مع وحدة غير قوه موجهة يمكن تفسيره على أنه أول إسقاط على هذا المتجه ثم زيادة طول هذا الإسقاط على طول المتجه.",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "خذ لحظة للتفكير فيما حدث هنا.",
  "model": "google_nmt",
  "from_community_srt": "خذ لحظة للتفكير في ما حدث هنا.",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "كان لدينا تحويل خطي من الفضاء ثنائي الأبعاد إلى خط الأعداد، والذي لم يتم تعريفه من حيث المتجهات العددية أو منتجات النقاط العددية، تم تعريفه فقط من خلال إسقاط الفضاء على نسخة قطرية من خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "كان لدينا تحول خطي من الفضاء 2D إلى خط الأعداد التي لم يتم تعريفها من حيث العدد المتجهات أو المنتجات الرقمية. تم تعريفه فقط من خلال إسقاط الفضاء على نسخة قطرية من خط الأعداد.",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "ولكن نظرًا لأن التحويل خطي، فقد تم وصفه بالضرورة بواسطة مصفوفة 1x2.",
  "model": "google_nmt",
  "from_community_srt": "ولكن لأن التحول خطي ، كان يوصف بالضرورة من قبل بعض 1 × 2 مصفوفة، ومنذ ضرب المصفوفة 1 × 2 من قبل ناقل ثنائي الأبعاد",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "وبما أن ضرب مصفوفة 1×2 في متجه ثنائي الأبعاد هو نفس تحويل تلك المصفوفة على جانبها والحصول على حاصل الضرب النقطي، فإن هذا التحويل كان مرتبطًا بشكل لا مفر منه ببعض المتجهات ثنائية الأبعاد.",
  "model": "google_nmt",
  "from_community_srt": "هو نفسه تحويل تلك المصفوفة على جانب وأخذ منتج نقطة ، كان هذا التحول مرتبطا بشكل لا مفر منه لبعض ناقلات 2D.",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "الدرس المستفاد هنا هو أنه في أي وقت يكون لديك أحد هذه التحويلات الخطية التي تكون مساحة مخرجاتها هي خط الأعداد، بغض النظر عن كيفية تعريفها، سيكون هناك متجه v فريد يتوافق مع هذا التحويل، بمعنى أن تطبيق التحويل هو نفس الشيء مثل أخذ منتج نقطي مع هذا المتجه.",
  "model": "google_nmt",
  "from_community_srt": "الدرس هنا ، هو أنه في أي وقت لديك واحدة من هذه التحولات الخطية مساحة الإخراج الخاصة بها هي خط الأرقام ، بغض النظر عن كيف تم تعريفها هناك ليكون بعض ناقلات فريدة ضد v المقابلة لهذا التحول ، بمعنى أن تطبيق التحول هو نفس الشيء مثل أخذ منتج نقطة",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "بالنسبة لي، هذا جميل تمامًا.",
  "model": "google_nmt",
  "from_community_srt": "مع هذا المتجه. بالنسبة لي ، هذا جميل للغاية.",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "إنه مثال لشيء في الرياضيات يسمى الازدواجية.",
  "model": "google_nmt",
  "from_community_srt": "إنه مثال لشيء في الرياضيات يسمى \"ازدواجية\".",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "تظهر الازدواجية في العديد من الطرق والأشكال المختلفة في جميع أنحاء الرياضيات، ومن الصعب جدًا تحديدها فعليًا.",
  "model": "google_nmt",
  "from_community_srt": "تظهر \"الثنائية\" بعدة طرق مختلفة ونماذج في جميع أنحاء الرياضيات ومن الصعب جدًا تحديدها فعليًا.",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "بشكل فضفاض، يشير هذا المصطلح إلى المواقف التي يكون لديك فيها تطابق طبيعي ولكن مفاجئ بين نوعين من الأشياء الرياضية.",
  "model": "google_nmt",
  "from_community_srt": "يتحدث بشكل فضفاض ، فإنه يشير إلى المواقف حيث لديك مراسلات طبيعية ولكن مفاجئة بين نوعين من الشيء الرياضي.",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "بالنسبة لحالة الجبر الخطي التي تعلمتها للتو، يمكنك القول أن ثنائي المتجه هو التحويل الخطي الذي يشفره، وثنائي التحويل الخطي من بعض الفضاء إلى بعد واحد هو متجه معين في ذلك الفضاء.",
  "model": "google_nmt",
  "from_community_srt": "لحالة الجبر الخطي التي أنت فقط تعلم عن، كنت أقول أن \"المزدوج\" من ناقلات هو التحويل الخطي الذي يشفره. والثنائي للتحول الخطي من الفضاء إلى بعد واحد ، هو متجه معين في تلك المساحة.",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "خلاصة القول، ظاهريًا، يعتبر حاصل الضرب النقطي أداة هندسية مفيدة جدًا لفهم الإسقاطات ولاختبار ما إذا كانت المتجهات تميل إلى الإشارة في نفس الاتجاه أم لا.",
  "model": "google_nmt",
  "from_community_srt": "لذلك ، لتلخيص ، على السطح ، والمنتج نقطة هي أداة هندسية مفيدة جدًا لفهمها التوقعات ولغرض اختبار ما إذا كانت النواقل تميل أم لا للإشارة في نفس الاتجاه.",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "وربما هذا هو أهم شيء عليك أن تتذكره بشأن حاصل الضرب النقطي.",
  "model": "google_nmt",
  "from_community_srt": "وربما هذا هو الشيء الأكثر أهمية لتتذكر حول المنتج نقطة ، ولكن على مستوى أعمق ، تنقيط اثنين من المتجهات معا",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "لكن على مستوى أعمق، فإن تنقيط متجهين معًا هو وسيلة لترجمة أحدهما إلى عالم التحولات.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "مرة أخرى، من الناحية العددية، قد تبدو هذه نقطة سخيفة يجب التركيز عليها.",
  "model": "google_nmt",
  "from_community_srt": "هي طريقة لترجمة واحد منهم في عالم التحولات: مرة أخرى ، عدديا ، قد يبدو هذا مثل نقطة سخيفة للتأكيد ،",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "إنها مجرد حسابين يبدوان متشابهين.",
  "model": "google_nmt",
  "from_community_srt": "إنه مجرد حسابين يحدثان يبدو مشابه.",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "لكن السبب الذي يجعلني أجد هذا مهمًا جدًا هو أنه خلال الرياضيات، عندما تتعامل مع متجه، بمجرد أن تتعرف حقًا على شخصيته، تدرك أحيانًا أنه من الأسهل فهمه ليس كسهم في الفضاء، ولكن كسهم في الفضاء. التجسيد المادي للتحول الخطي.",
  "model": "google_nmt",
  "from_community_srt": "لكن السبب في أنني أجد هذا مهمًا جدًا ، هو أنه خلال الرياضيات ، عندما تتعامل مع متجه ، بمجرد أن تتعرف على شخصيتها في بعض الأحيان تدرك أنه من الأسهل فهمه ، وليس كسهم في الفضاء ، ولكن كما التجسيد المادي للخطية تحويل.",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "يبدو الأمر كما لو أن المتجه هو في الواقع مجرد اختصار مفاهيمي لتحول معين، لأنه من الأسهل بالنسبة لنا التفكير في الأسهم في الفضاء بدلاً من نقل كل هذا الفضاء إلى خط الأعداد.",
  "model": "google_nmt",
  "from_community_srt": "إنه كما لو أن المتجه هو في الواقع مجرد مفاهيمي الاختزال لبعض التحول ، لأنه من الأسهل علينا التفكير في الأسهم والفضاء بدلا من نقل كل تلك المساحة إلى رقم الخط.",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.97
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "في الفيديو التالي، سترون مثالًا رائعًا آخر لهذه الازدواجية أثناء العمل، بينما أتحدث عن المنتج التبادلي.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 822.61,
  "end": 829.19
 }
]